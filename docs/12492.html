<html>
<head>
<title>New TF2 Object Detection API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新 TF2 对象检测 API</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/new-tf2-object-detection-api-5c6ea8362a8c?source=collection_archive---------16-----------------------#2020-08-28">https://towardsdatascience.com/new-tf2-object-detection-api-5c6ea8362a8c?source=collection_archive---------16-----------------------#2020-08-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="38ab" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">ML 提示和技巧/ TF2 OD API</h2><div class=""/><div class=""><h2 id="2da0" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">欢迎新动物进入动物园——模型评估</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/34bc746be8a236e5d80d862875cdd6ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7wBq3r1A9JdXGFXiph-tvA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><blockquote class="lh li lj"><p id="843e" class="lk ll lm ln b lo lp kd lq lr ls kg lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">Tensorflow 对象检测 API (TF OD API)刚刚变得更好。最近，Google 发布了新版本的 TF OD API，现在支持 Tensorflow 2.x，这是我们一直在等待的巨大改进！</p></blockquote><h1 id="94a8" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">介绍</h1><p id="3a98" class="pw-post-body-paragraph lk ll it ln b lo mz kd lq lr na kg lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated"><strong class="ln jd">物体检测(OD)技术的最新进展是由行业广泛采用该技术推动的。</strong>汽车制造商使用物体检测来帮助车辆在道路上自主导航，医生使用它来改善他们的诊断过程，农民使用它来检测各种作物疾病……<strong class="ln jd">和</strong> <strong class="ln jd">还有许多其他的使用案例(有待发现)，在这些案例中，OD 可以提供巨大的价值。</strong></p><p id="7ce2" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jd"> Tensorflow </strong>是一个深度学习框架，为自然语言处理(NLP)、语音合成、语义分割和<strong class="ln jd">对象检测</strong>中的许多最先进的(SOTA)模型提供支持。TF OD API 是一个<strong class="ln jd">开源的对象检测模型集合</strong>，由深度学习爱好者和该领域的不同专家使用。</p><p id="5ccf" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">现在，当我们介绍了基本术语后，<strong class="ln jd">让我们看看新的 TF OD API 提供了什么！</strong></p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="c395" class="mh mi it bd mj mk no mm mn mo np mq mr ki nq kj mt kl nr km mv ko ns kp mx my bi translated">新的 TF OD API</h1><p id="4406" class="pw-post-body-paragraph lk ll it ln b lo mz kd lq lr na kg lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">新的 TF2 OD API 引入了<strong class="ln jd">急切执行</strong>，使得对象检测模型的调试更加容易；它还包括 TF2 模型动物园支持的新 SOTA 模型。对于 Tensorflow 1.x .用户来说，好消息是新的 OD API 是向后兼容的，所以如果你喜欢，你仍然可以使用 TF1，尽管强烈建议切换到 TF2！</p><p id="f41a" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">除了之前 TF1 模型动物园有的 SSD (MobileNet/ResNet)、更快的 R-CNN (ResNet/Inception ResNet)、Mask R-CNN 模型外，TF2 模型动物园还推出<a class="ae nt" href="https://arxiv.org/abs/1904.08189" rel="noopener ugc nofollow" target="_blank"><strong class="ln jd">CenterNet</strong></a><strong class="ln jd">、</strong><a class="ae nt" href="https://arxiv.org/abs/1901.08043" rel="noopener ugc nofollow" target="_blank"><strong class="ln jd">ExtremeNet</strong></a><strong class="ln jd">、</strong><a class="ae nt" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"><strong class="ln jd">efficent det</strong></a>等<strong class="ln jd">新 SOTA 模型。</strong></p><p id="f23c" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><a class="ae nt" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="noopener ugc nofollow" target="_blank"> TF2 OD API 模型动物园</a>中的模型在<a class="ae nt" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO 2017 </a>数据集上进行了预训练。如果你对这个数据集中已经包含的类别感兴趣，预先训练的模型可以用于<strong class="ln jd">开箱即用的推理</strong>，或者在新数据集上训练时用于<strong class="ln jd">初始化你的模型</strong>。使用 TF OD API 模型而不是自己实现 SOTA 模型<strong class="ln jd">可以让您有更多的时间关注数据</strong>，这是实现 OD 模型高性能的另一个关键因素。然而，即使您决定自己构建模型，<strong class="ln jd"> TF OD API 模型提供了一个很好的性能基准</strong>！</p><p id="486e" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">您可以根据自己的需求(速度与精度)从一长串不同的型号中进行选择:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nu nv l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae nt" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="noopener ugc nofollow" target="_blank"> TF2 OD API 模型动物园</a>中包含的模型。</p></figure><p id="8ada" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">在上表中，您可以看到<strong class="ln jd">表</strong>中仅给出了平均 COCO mAP 指标。尽管对于模型的性能来说，这可能是一个相当好的方向，但是如果您对模型在不同大小的对象或不同类型的对象上的表现感兴趣，那么<strong class="ln jd">附加统计信息</strong>可能会很有用。例如，如果你对开发你的<strong class="ln jd">高级驾驶辅助系统</strong> ( <strong class="ln jd"> ADAS </strong>)感兴趣，你不会真的关心探测器探测香蕉的能力是否差！</p><p id="c6b3" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">在这篇博客中，我们将重点解释如何对 TF2 模型动物园中现成的不同预训练<a class="ae nt" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"><strong class="ln jd">efficient det</strong></a><strong class="ln jd">检查站进行<strong class="ln jd">详细评估。</strong></strong></p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="62c6" class="mh mi it bd mj mk no mm mn mo np mq mr ki nq kj mt kl nr km mv ko ns kp mx my bi translated">效率检测— SOTA OD 模型</h1><p id="8a1a" class="pw-post-body-paragraph lk ll it ln b lo mz kd lq lr na kg lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated"><a class="ae nt" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> EfficientDet </a>是一个与 RetinaNet 模型非常相似的单次检测器，有几处改进:<a class="ae nt" href="https://arxiv.org/pdf/1905.11946.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ln jd"> EfficientNet 主干</strong> </a> <strong class="ln jd">、加权双向特征金字塔网络(BiFPN)和复合缩放方法</strong>。</p><p id="a1ff" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">BiFPN 是非常流行的 FPN 的改进版本。它学习表示不同输入特征重要性的权重，同时重复应用自上而下和自下而上的多尺度特征融合。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/79293c0bdf8fe2dcda9b4fe94548f659.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*KHVyKpyc-0LSvSt_-drDXw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd nx">特征网络设计</strong> : a) FPN 引入自上而下的路径融合多尺度特征，b) BiFPN 在现有自上而下的路径上增加自下而上的路径，创建双向 FPN。来源:https://arxiv.org/pdf/1911.09070.pdf<a class="ae nt" href="https://arxiv.org/pdf/1911.09070.pdf" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="c043" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">提高目标检测模型精度的常用方法是增加输入图像的大小或使用更大的主干网络。<strong class="ln jd">复合缩放不是在单个维度或有限的缩放维度上操作，而是联合放大主干、特征网络和盒/类预测网络的分辨率/深度/宽度。</strong></p><p id="952b" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jd">TF2 OD API Model Zoo</strong>中包含了具有不同缩放因子的 EfficientDet 模型，缩放因子在模型名称中用{ <em class="lm"> X} </em>表示，而输入图像分辨率用<em class="lm">{ RES }</em>X {<em class="lm">RES }</em>efficient det D {<em class="lm">X }</em>{<em class="lm">RES }</em>X {<em class="lm">RES }</em>表示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/1f2657ea601dc905f1f3097d95978bea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*ys8ljeulvALLIPEbOQE-HQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd nx">用于高效检测的复合缩放配置</strong>。来源:<a class="ae nt" href="https://arxiv.org/pdf/1911.09070.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1911.09070.pdf</a></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/d9a74462d1b3251f70a6fe8d3b86c6de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yzz4-1binPn29D4TrwAHqA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd nx"> EfficientDet 架构</strong>采用 EfficientNet 作为主干网络，BiFPN 作为特征网络，以及共享类/箱预测网络。来源:<a class="ae nt" href="https://arxiv.org/pdf/1911.09070.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1911.09070.pdf</a></p></figure></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="469a" class="mh mi it bd mj mk no mm mn mo np mq mr ki nq kj mt kl nr km mv ko ns kp mx my bi translated">预训练 EfficientDet 模型的评估</h1><p id="d7cd" class="pw-post-body-paragraph lk ll it ln b lo mz kd lq lr na kg lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">我们希望进行详细的精度比较，以研究复合扩展配置对网络本身性能的影响。出于这个原因，我们创建了一个<a class="ae nt" href="https://colab.research.google.com/drive/1h9fJm6D6VhGpJqpCxOklEWmtH-luLtCM?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Colab 笔记本</a>，在其中我们解释了如何对模型进行评估，以及如何有效地比较评估结果。我们对<strong class="ln jd">详细的评估统计感兴趣，包括每个类和不同对象大小的统计</strong>。</p><p id="2860" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">不幸的是，TF OD API 不支持这种现成的统计数据。这就是为什么我们创建了 TF OD repo 的一个分支<a class="ae nt" href="https://github.com/qraleq/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">，并更新了相关脚本，以按照本期</a><a class="ae nt" href="https://github.com/tensorflow/models/issues/4778#issuecomment-430262110" rel="noopener ugc nofollow" target="_blank">中给出的说明引入该功能。</a></p><p id="b21f" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">在笔记本中，我们提供了<strong class="ln jd">如何设置</strong><a class="ae nt" href="https://colab.research.google.com/drive/1h9fJm6D6VhGpJqpCxOklEWmtH-luLtCM#scrollTo=a3oHKsyCB9Jc&amp;line=1&amp;uniqifier=1" rel="noopener ugc nofollow" target="_blank"><strong class="ln jd">tensor flow 2</strong></a><strong class="ln jd">和</strong><a class="ae nt" href="https://colab.research.google.com/drive/1h9fJm6D6VhGpJqpCxOklEWmtH-luLtCM#scrollTo=U7wVe_nICeWa&amp;line=9&amp;uniqifier=1" rel="noopener ugc nofollow" target="_blank"><strong class="ln jd">TF2 OD API</strong></a>的说明。我们还包括<strong class="ln jd">脚本，可以轻松下载 EfficientDet 检查点</strong>，以及额外的<strong class="ln jd">脚本，可以帮助您获取 COCO 2017 Val 数据集，并创建<em class="lm"> tfrecord </em>文件</strong>，供 TF OD API 在评估阶段使用。</p><p id="9872" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">最后，我们修改 EfficientDet 检查点的<code class="fe oa ob oc od b">pipeline.config</code>文件，为后续评估<strong class="ln jd"> 8 EfficientDet 检查点</strong>做好准备。TF OD API 使用它们来配置培训和评估过程。培训管道的模式可在<code class="fe oa ob oc od b">object_detection/protos/pipeline.proto</code>中找到。在高层次上，配置文件分为 5 个部分:</p><ol class=""><li id="4672" class="oe of it ln b lo lp lr ls nb og nd oh nf oi mg oj ok ol om bi translated"><code class="fe oa ob oc od b">model</code>的配置。这定义了将被训练的模型的类型(即，元架构、特征提取器……)。</li><li id="8ef9" class="oe of it ln b lo on lr oo nb op nd oq nf or mg oj ok ol om bi translated"><code class="fe oa ob oc od b">train_config</code>，决定用什么参数来训练模型参数(即 SGD 参数、输入预处理、特征提取器初始化值……)。</li><li id="efb5" class="oe of it ln b lo on lr oo nb op nd oq nf or mg oj ok ol om bi translated"><code class="fe oa ob oc od b">eval_config</code>，它决定将报告什么样的<strong class="ln jd">组指标进行评估。</strong></li><li id="097a" class="oe of it ln b lo on lr oo nb op nd oq nf or mg oj ok ol om bi translated"><code class="fe oa ob oc od b">train_input_config</code>，它定义了模型应该在哪个数据集上进行训练。</li><li id="f900" class="oe of it ln b lo on lr oo nb op nd oq nf or mg oj ok ol om bi translated"><code class="fe oa ob oc od b">eval_input_config</code>，其中<strong class="ln jd">定义了模型将在</strong>上评估的数据集。通常，这应该不同于训练输入数据集。</li></ol><pre class="ks kt ku kv gt os od ot ou aw ov bi"><span id="dc9a" class="ow mi it od b gy ox oy l oz pa">model {<br/>(... Add model config here...)<br/>}</span><span id="967d" class="ow mi it od b gy pb oy l oz pa">train_config : {<br/>(... Add train_config here...)<br/>}</span><span id="82ed" class="ow mi it od b gy pb oy l oz pa">train_input_reader: {<br/>(... Add train_input configuration here...)<br/>}</span><span id="a4f9" class="ow mi it od b gy pb oy l oz pa">eval_config: {<br/>}</span><span id="e934" class="ow mi it od b gy pb oy l oz pa">eval_input_reader: {<br/>(... Add eval_input configuration here...)<br/>}</span></pre><p id="b309" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">我们只对配置文件的<code class="fe oa ob oc od b">eval_config</code>和<code class="fe oa ob oc od b">eval_input_config</code>部分感兴趣。仔细查看 Google Colab 中的<a class="ae nt" href="https://colab.research.google.com/drive/1h9fJm6D6VhGpJqpCxOklEWmtH-luLtCM#scrollTo=20taX9u9rBq0&amp;line=1&amp;uniqifier=1" rel="noopener ugc nofollow" target="_blank">单元格</a>，了解我们如何设置评估参数的更多详细信息。TF OD API 中另外两个没有启用的标志是<code class="fe oa ob oc od b">include_metrics_per_category</code>和<code class="fe oa ob oc od b">all_metrics_per_category</code>。在应用了 Colab 笔记本中给出的补丁后，当设置为<code class="fe oa ob oc od b">true</code>时，这两个选项将启用我们感兴趣的<strong class="ln jd">详细统计(按类别和大小)</strong>！</p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="10cc" class="mh mi it bd mj mk no mm mn mo np mq mr ki nq kj mt kl nr km mv ko ns kp mx my bi translated">Allegro Trains —高效的实验管理</h1><p id="bb23" class="pw-post-body-paragraph lk ll it ln b lo mz kd lq lr na kg lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">为了能够有效地比较模型评估，我们使用一个名为 <a class="ae nt" href="https://allegro.ai/trains-open-source/?utm_source=i_blog&amp;utm_medium=referral&amp;utm_campaign=trains_c" rel="noopener ugc nofollow" target="_blank"> <strong class="ln jd">的<strong class="ln jd">开源实验管理工具来训练</strong> </strong></a> <strong class="ln jd">。很容易将它集成到您的代码中，并且它支持开箱即用的不同功能。它可以作为<a class="ae nt" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank">张量板</a>的替代品，用于可视化实验结果。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl pc"><img src="../Images/f1965d61bf717c93001c9aa3d8950f04.png" data-original-src="https://miro.medium.com/v2/format:webp/1*gMiZoALtXCjf_2ARl7n5CA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae nt" href="https://allegro.ai/wp-content/uploads/2019/11/allegro-logo-1.jpg" rel="noopener ugc nofollow" target="_blank">https://allegro . ai/WP-content/uploads/2019/11/allegro-logo-1 . jpg</a></p></figure><p id="afba" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">OD API 中的主脚本是<code class="fe oa ob oc od b">object_detection/model_main_tf2.py</code>。它处理训练和评估阶段。我们创建了一个<a class="ae nt" href="https://colab.research.google.com/drive/1h9fJm6D6VhGpJqpCxOklEWmtH-luLtCM#scrollTo=VWvp0CrjyASm&amp;line=2&amp;uniqifier=1" rel="noopener ugc nofollow" target="_blank">小脚本</a>，它在一个循环中调用<code class="fe oa ob oc od b">model_main_tf2.py</code>来评估所有 EfficientDet 检查点。</p><p id="a146" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">为了将<a class="ae nt" href="https://allegro.ai/trains-open-source/?utm_source=i_blog&amp;utm_medium=referral&amp;utm_campaign=trains_c" rel="noopener ugc nofollow" target="_blank"> Allegro Trains </a>实验管理集成到评估脚本中，我们必须添加 2 (+1)行代码。在<code class="fe oa ob oc od b">model_main_tf2.py</code>脚本中，我们添加了以下几行:</p><pre class="ks kt ku kv gt os od ot ou aw ov bi"><span id="dbf1" class="ow mi it od b gy ox oy l oz pa">from trains import Task</span><span id="6fa5" class="ow mi it od b gy pb oy l oz pa">task = Task.init(project_name="<em class="lm">NAME_OF_THE_PROJECT</em>", task_name="<em class="lm">NAME_OF_THE_TASK</em>")</span><span id="3477" class="ow mi it od b gy pb oy l oz pa"># OPTIONAL - logs the pipeline.config into the Trains dashboard<br/>task.connect_configuration(FLAGS.pipeline_config_path)</span></pre><p id="a826" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">火车会自动开始为你记录许多事情。你可以在这里找到全面的特性列表<a class="ae nt" href="https://allegro.ai/docs/concepts_arch/concepts_arch/" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="36ad" class="mh mi it bd mj mk no mm mn mo np mq mr ki nq kj mt kl nr km mv ko ns kp mx my bi translated">比较不同的效率检测模型</h1><p id="9581" class="pw-post-body-paragraph lk ll it ln b lo mz kd lq lr na kg lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated"><strong class="ln jd">在这个</strong> <a class="ae nt" href="https://demoapp.trains.allegro.ai/projects/8d752f81080b46cb9bf6ebcaf35bc8d2/experiments?columns=selected&amp;columns=type&amp;columns=name&amp;columns=tags&amp;columns=status&amp;columns=project.name&amp;columns=users&amp;columns=started&amp;columns=last_update&amp;columns=last_iteration&amp;order=-name" rel="noopener ugc nofollow" target="_blank"> <strong class="ln jd">链接</strong> </a> <strong class="ln jd">上，可以找到 TF2 OD API </strong>收录的 8 款 EfficientDet 车型的评测结果。我们将实验命名为<code class="fe oa ob oc od b">efficientdet_d{X}_coco17_tpu-32</code>，其中<code class="fe oa ob oc od b">{x}</code>表示 EfficientDet 模型的复合比例因子。如果您运行示例 Colab 笔记本，您将得到相同的结果，并且您的实验将显示在<a class="ae nt" href="https://demoapp.trains.allegro.ai/" rel="noopener ugc nofollow" target="_blank">演示训练服务器</a>上。</p><p id="e79e" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jd">在本节中，我们将向您展示如何有效地比较不同的模型，并验证它们在评估数据集上的性能。</strong>我们使用<strong class="ln jd"> COCO 2017 Val 数据集</strong>，因为它是 TF OD API 中评估对象检测模型的标准数据集。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pd"><img src="../Images/c3fde4151a35c830a2a0f5ea5f1c859f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YGMVhVL7Ynv73yjmD600iA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Trains 自动捕获代码、超参数和度量(图片由作者提供)。</p></figure><p id="bca6" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jd">我们感兴趣的是</strong> <a class="ae nt" href="https://cocodataset.org/#detection-eval" rel="noopener ugc nofollow" target="_blank"> <strong class="ln jd"> COCO 对象检测模型评价指标</strong> </a> <strong class="ln jd">。</strong>按下<a class="ae nt" href="https://demoapp.trains.allegro.ai/projects/8d752f81080b46cb9bf6ebcaf35bc8d2/experiments/950e39d811aa413d81aa0f2c8cbf0e5a/info-output/metrics/scalar?columns=selected&amp;columns=type&amp;columns=name&amp;columns=tags&amp;columns=status&amp;columns=project.name&amp;columns=users&amp;columns=started&amp;columns=last_update&amp;columns=last_iteration&amp;order=-name" rel="noopener ugc nofollow" target="_blank">这里的</a>查看实验结果。该页面包含我们感兴趣的所有指标的图表。</p><p id="fe23" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">我们可以先看一下<code class="fe oa ob oc od b">DetectionBoxes_Precision</code>图，它包含数据集中所有类别的<strong class="ln jd">平均精度度量。地图度量的值对应于<a class="ae nt" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="noopener ugc nofollow" target="_blank"> TF2 动物园模型</a>的表格中报告的地图度量。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/7d1daa9e968c3fef07b87fd4cd2416cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*71Pi64VieSIY6MPy1Ugetw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">COCO 2017 评估数据集中所有类别的 detection boxes _ Precision metrics(图片由作者提供)。</p></figure><p id="1e32" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">多亏了我们对<code class="fe oa ob oc od b">pycocotools</code>应用的补丁，我们还可以得到每个类别的<strong class="ln jd">地图度量</strong>。由于 COCO 数据集中有 90 个类别，我们想知道每个类别对平均准确度的贡献。通过这种方式，我们可以对被评估模型的性能有更加<strong class="ln jd">的深入了解。</strong>例如，您可能只对某个类别中的小对象的模型表现感兴趣。从汇总的统计数据来看，不可能获得这样的洞察力，而建议的补丁可以做到这一点！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/e1569639d20a0bd058f8da14bad92d9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*NOkw9BHl4s5IYU40Of-7WA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">EfficientDet D0 模型的每个类别映射指标(图片由作者提供)。</p></figure><p id="f231" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jd">我们还使用 Allegro Trains 的功能来比较多个实验。实验对比显示了模型之间的所有差异。</strong>我们首先可以获得相关统计数据的详细标量和绘图比较。在我们的示例中，我们将比较 EfficientDet D0、D1 和 D2 模型的性能。<strong class="ln jd">显然，复合缩放对模型的性能有积极影响。</strong></p><p id="a246" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">拥有每个类别的统计数据的额外好处之一是，您可以<strong class="ln jd">分析复合比例因子对某个感兴趣类别的准确性的影响。</strong>例如，如果您对检测监控视频中的公交车感兴趣，您可以<strong class="ln jd">分析显示公交车类别的地图性能与 EfficientDet 模型的复合比例因子的图表。</strong>这有助于决定使用哪种模型，以及性能和计算复杂性之间的最佳平衡点在哪里！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/002058efc725e08a0da43e6653039c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*G1nsrZhgz6O7aA0F"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">“bus”<strong class="bd nx"/>类别的映射指标与 EfficientDet 模型的复合比例因子(图片由作者提供)。</p></figure><p id="b30c" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">您还可以<strong class="ln jd">比较的一件有趣的事情是模型配置文件</strong> <code class="fe oa ob oc od b">pipeline.config.</code>您可以看到 EfficientDet 模型之间的基本差异在于输入图像的尺寸和滤波器的数量/深度，如前所述。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pd"><img src="../Images/f38630ce0ef33adf487ef82c92747a52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ktDxOo49XbnbLQFMlDmmnw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="ced7" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">下一个图包含 3 个 EfficientDet 模型的 mAP 值。有一个<strong class="ln jd">明显的好处是增加输入图像的分辨率，以及增加模型</strong>中的滤镜数量。虽然 D0 模型实现了 33.55%的平均动脉压，但 D2 模型优于它，它实现了 41.79%的平均动脉压。您还可以尝试执行每个类的比较、其他 EfficientDet 模型的比较，或者您对应用程序感兴趣的任何事情。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ph"><img src="../Images/474aae7046f4980602f14f96a8ddcb77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uCFZqlOACDKzYENszITCHg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">EfficientDet D0、D1 和 D2 车型的地图对比(图片由作者提供)。</p></figure></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="bc30" class="mh mi it bd mj mk no mm mn mo np mq mr ki nq kj mt kl nr km mv ko ns kp mx my bi translated">TF OD API 是如何用于提高工地安全的？</h1><p id="e9c0" class="pw-post-body-paragraph lk ll it ln b lo mz kd lq lr na kg lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">Forsight 是一家早期创业公司，我们的使命是将建筑工地变成工人的安全环境。<a class="ae nt" href="https://forsight.ai/" rel="noopener ugc nofollow" target="_blank"> Forsight </a>利用计算机视觉和机器学习，处理实时闭路电视镜头，帮助安全工程师监控个人防护设备(PPE)的正确使用，以保持现场安全。</p><p id="4507" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">我们的施工现场监控管道建立在 TF OD API 之上，其功能包括<strong class="ln jd"> PPE 检测和监控、社交距离跟踪、虚拟地理围栏监控、禁止停车区监控和火灾探测</strong>。在 Forsight，我们还使用 Trains 来跟踪我们的实验，在团队成员之间分享它们，并记录一切，以便我们可以重现它。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/8416aac5f7442fd1eef22abf2b2df913.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*fvF17b2hwbs_MMlLWILvDg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="f7a6" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">随着新冠肺炎疫情的继续，世界各地的建筑项目都在积极寻找在保证工人安全的同时重启或继续项目的方法。计算机视觉和机器学习可以帮助建筑经理确保他们的建筑工地是安全的。我们建立了一个实时监控渠道，跟踪员工之间的社交距离。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/f6f194677c2f8f9353c22a6418d1e46b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*PURx4SqSYGgsk2KYxd3AKQ.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用 TF OD API 进行社交距离监控(图片由作者提供)。</p></figure><p id="fc4c" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">除了新的无形的 COVID 威胁之外，所有建筑工人每天都面临一些古老的危险，特别是<strong class="ln jd">“致命四大危险”:坠落、被物体击中、夹在物体之间以及触电危险。确保工人穿戴个人防护装备对建筑工地的整体安全至关重要。TF OD API 是构建自主 PPE 监控管道的一个很好的起点。<strong class="ln jd">我们的下一篇博客将讨论如何使用新的 TF OD API 训练一个基本的头盔探测器。</strong></strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/20bd04d9764c386e797b982a6cd487db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*iwIWuyJsRha_UTIL-j0Evg.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用 TF OD API 的个人防护装备(PPE)监测(图片由作者提供)。</p></figure><p id="c58f" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">建筑工地的某些区域比其他区域更危险。创建虚拟地理围栏区域并使用 CCTV 摄像机对其进行监控，为施工经理增加了巨大的价值，因为他们可以专注于其他任务，同时了解工地上发生的任何地理围栏违规事件。此外，地理围栏可以很容易地扩展到监控机器和重型设备的访问。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/b154c1612c7f6f9c23c7342d1683233c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*bN0o_xfxRKDbLCPYXBu7FQ.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用 OD API 进行地理围栏监测(图片由作者提供)。</p></figure></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><h1 id="f784" class="mh mi it bd mj mk no mm mn mo np mq mr ki nq kj mt kl nr km mv ko ns kp mx my bi translated">结论</h1><p id="e6d4" class="pw-post-body-paragraph lk ll it ln b lo mz kd lq lr na kg lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">在这篇博客中，我们讨论了使用新的 TF2 OD API 的<strong class="ln jd">好处。我们已经展示了如何<strong class="ln jd">有效地评估 TF2 OD API 模型动物园</strong>中现成的预训练 OD 模型。我们还展示了如何使用<strong class="ln jd"> Allegro Trains 作为高效的实验管理解决方案，实现强大的洞察力和统计</strong>。最后，我们展示了一些<strong class="ln jd">建筑环境中物体检测的真实应用</strong>。</strong></p><blockquote class="lh li lj"><p id="a603" class="lk ll lm ln b lo lp kd lq lr ls kg lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated">这个博客是提供关于使用 TF2 OD API 的指导和建议的博客系列中的第<strong class="ln jd">个博客。在下一篇博客中，我们将展示<strong class="ln jd">如何训练一个定制的对象检测器，使您能够检测穿着 PPE 的工人</strong>。请关注我们，获取更多实践教程！此外，如果您有任何问题或意见，请随时联系我们！</strong></p></blockquote></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="d5c1" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">[1]“现代卷积物体探测器的速度/精度权衡”<br/>黄 J、拉特霍德 V、孙 C、朱 M、科拉迪卡拉 A、法蒂 A、菲舍尔 I、沃伊娜 Z、<br/>宋 Y、S、墨菲 K、2017</p><p id="117a" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">[2] TensorFlow 对象检测 API，<a class="ae nt" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/models/tree/master/research/Object _ Detection</a></p><p id="68ad" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">[3]“Efficient det:可扩展和高效的对象检测”谭明兴，庞若明，郭诉乐，<a class="ae nt" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"/></p><p id="fe94" class="pw-post-body-paragraph lk ll it ln b lo lp kd lq lr ls kg lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">[4]“efficient net:卷积神经网络模型缩放的再思考”谭明星和郭诉乐，2019，<a class="ae nt" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>