<html>
<head>
<title>Generate Novel Artistic Artworks with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用深度学习生成新颖的艺术作品</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generate-novel-artistic-artworks-with-deep-learning-f2f61da69e6e?source=collection_archive---------42-----------------------#2020-05-03">https://towardsdatascience.com/generate-novel-artistic-artworks-with-deep-learning-f2f61da69e6e?source=collection_archive---------42-----------------------#2020-05-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1ea2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">深度学习与艺术:神经类型转移</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a87b31a3ce8ad01cc1c17cd57766cb2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nB3jfbbU-9_IPhpGb_jcSQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ku"><img src="../Images/6189802dfe30e616d3b0f47fd50a12da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R3dFWV6AiHobC8jqGbV_nQ.jpeg"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd kz">神经类型转移的一个例子</strong></p></figure><h1 id="b1f1" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">1.问题陈述</h1><p id="5986" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">在这篇文章中，我将继续使用深度学习以另一幅图像的风格创作图像(曾经希望你能像毕加索或梵高一样画画吗？).这就是所谓的<strong class="lu iu">神经风格转移</strong>！这是一种在<a class="ae mo" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">莱昂·A·加蒂斯的论文中概述的技术，一种艺术风格的神经算法</a>，这是一本很棒的读物，你绝对应该去看看。</p><p id="18c3" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">但是，什么是神经风格转移呢？</p><p id="fd2c" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">神经风格转移是一种优化技术，用于拍摄三幅图像，一幅<strong class="lu iu">内容</strong>图像，一幅<strong class="lu iu">风格参考</strong>图像(如著名画家的艺术作品)，以及您想要设计风格的<strong class="lu iu">输入</strong>图像——并将它们混合在一起，以便输入图像被转换为看起来像内容图像，但以风格图像的风格“绘制”,从而桥接深度学习和艺术的轨道！</p><p id="852a" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">例如，让我们来看看这只海龟和葛饰北斋的<em class="mu">神奈川</em>外的巨浪:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/b6311c09008dffe43a9d44940e745056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*546uWZudwA3aqkVQaH1xTw.jpeg"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><a class="ae mo" href="https://commons.wikimedia.org/wiki/File:Green_Sea_Turtle_grazing_seagrass.jpg" rel="noopener ugc nofollow" target="_blank">绿海龟图片</a>——P . Lindgren【CC By-SA 3.0(<a class="ae mo" href="https://creativecommons.org/licenses/by-sa/3.0)%5D" rel="noopener ugc nofollow" target="_blank">https://creative Commons . org/licenses/By-SA/3.0)】</a>，来自维基共享资源。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/97ac83c4d4bceb2a46f2824d8e600b9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*uM4DZ7_FE9ZZUKSv.jpg"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><a class="ae mo" href="https://en.wikipedia.org/wiki/The_Great_Wave_off_Kanagawa" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/The_Great_Wave_off_Kanagawa</a></p></figure><p id="910f" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">现在，如果Hokusai决定用这种风格来画这只海龟，会是什么样子呢？类似这样的？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/9ef516976d34ac88412a4f3515de2298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*3KsTqX1lozA20qoc.png"/></div></figure><p id="cc83" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">这是魔法还是只是深度学习？幸运的是，这不涉及任何巫术:风格转移是一种有趣的技术，展示了神经网络的能力和内部表示。</p><p id="01ed" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">神经风格转移的原理是定义两个距离函数，一个描述两幅图像的内容如何不同的𝐿𝑐𝑜𝑛𝑡𝑒𝑛𝑡，另一个描述两幅图像在风格方面的差异的𝐿𝑠𝑡𝑦𝑙𝑒.然后，给定三个图像，期望的样式图像、期望的内容图像和输入图像(用内容图像初始化)，我们尝试变换输入图像，以最小化内容图像的内容距离和样式图像的样式距离。总之，我们将获取基本输入图像、我们想要匹配的内容图像和我们想要匹配的样式图像。我们将通过反向传播最小化内容和样式距离(损失)来转换基本输入图像，创建一个匹配内容图像的内容和样式图像的样式的图像。</p><p id="05bc" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">在本文中，我们将生成一幅巴黎卢浮宫博物馆的图像(内容图像C)，混合了印象派运动领袖克洛德·莫内的一幅画(风格图像S)。</p><h1 id="8663" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">2.迁移学习</h1><p id="ae73" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">神经风格转移(NST)使用先前训练的卷积网络，并在此基础上构建。使用在不同任务上训练的网络并将其应用于新任务的想法被称为<a class="ae mo" href="https://www.coursera.org/learn/convolutional-neural-networks/lecture/4THzO/transfer-learning" rel="noopener ugc nofollow" target="_blank">迁移学习</a>。</p><p id="02d7" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">根据<a class="ae mo" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">NST的原始论文</a>，我将使用VGG网络。具体来说，<strong class="lu iu"> VGG-19 </strong>，19层版本的VGG网络。该模型已经在非常大的ImageNet数据库上被训练，因此已经学会识别各种低级特征(在较浅的层)和高级特征(在较深的层)。</p><p id="7306" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">下面的代码从VGG模型中加载参数(更多信息请参考Github repo):</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="f4db" class="nb lb it mx b gy nc nd l ne nf">pp = pprint.PrettyPrinter(indent=4)<br/>model = load_vgg_model(“pretrained-model/imagenet-vgg-verydeep-19.mat”)<br/>pp.pprint(model)</span></pre><p id="0611" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">模型存储在python字典中。python字典包含每个图层的键-值对，其中“键”是该图层的变量名，“值”是该图层的张量。</p><h1 id="91bb" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">3.神经类型转移</h1><p id="c75c" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">我们将分三步构建神经类型转移(NST)算法:</p><ul class=""><li id="e10f" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn nl nm nn no bi translated">构建内容成本函数<em class="mu"> J_content </em> (C，G)。</li><li id="6c58" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">构建风格成本函数<em class="mu"> J_style </em> (S，G)。</li><li id="c739" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">放在一起得到J(G) = α * <em class="mu"> J_content </em> (C，G) + β * <em class="mu"> J_style </em> (S，G)。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/d4bd7cb8ae0ae25c51cdaf048756e6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-YfcQi-hnu9cEwU8S1fuSw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd kz">神经风格转移算法的总成本函数</strong></p></figure><h2 id="f301" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">3.1计算内容成本</h2><p id="7a9f" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">在我们运行的例子中，内容图像C将是巴黎卢浮宫博物馆的图片(缩放到400 x 300)</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="5d27" class="nb lb it mx b gy nc nd l ne nf">content_image = scipy.misc.imread(“images/louvre.jpg”)<br/>imshow(content_image);</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/b29b99d9f4f6fc22c706e1f40cddb127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w0FPme32yhYC_EaOccjt6w.png"/></div></div></figure><p id="8d3f" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">内容图片(C)显示了卢浮宫博物馆的金字塔，周围环绕着古老的巴黎建筑，背景是晴朗的天空和几朵云。</p><h2 id="2adb" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated"><strong class="ak"> 3.1.1将生成的图像G的内容与图像C进行匹配</strong></h2><p id="e45a" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">如前所述，ConvNet的较浅层倾向于检测较低级别的特征，如边缘和简单纹理；更深的层倾向于检测更高级的特征，例如更复杂的纹理以及对象类别。</p><p id="4713" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">我们希望<strong class="lu iu">生成的图像G </strong>具有与输入图像C 相似的<strong class="lu iu">内容</strong>。假设你已经选择了一些层的激活来代表图像的内容。实际上，如果你在网络的中间选择一个图层，你会得到最令人满意的视觉效果——既不太浅也不太深。</p><p id="5c92" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><strong class="lu iu">注意</strong>:在你完成了这篇文章的例子之后，你可以自由地尝试不同的层，看看结果如何变化。</p><p id="0146" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">首先，我们将图像C设置为预训练的VGG网络的输入，并运行前向传播。让一个<strong class="lu iu"> ᶜ </strong>成为你选择的层中的隐藏层激活。这将是一个<em class="mu"> nH × nW × nC </em>张量。</p><p id="035e" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">使用图像G重复此过程—将G设置为输入，并运行正向传播。让一个<strong class="lu iu"> ᴳ </strong>被相应的隐藏层激活。</p><p id="d2a6" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">然后我们将定义<strong class="lu iu">内容成本函数</strong>为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/50c556494d9dc5d030610a03a8528dcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jLsdmw3vDbRrAuHYKg8GxQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">内容成本函数</p></figure><p id="7508" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">这里，<em class="mu"> nH </em>、<em class="mu"> nW、</em>和<em class="mu"> nC </em>分别是您选择的隐藏层的高度、宽度和通道数。这些术语出现在成本中的规范化术语中。</p><p id="b38d" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">为了清楚起见，请注意，<strong class="lu iu"> ᶜ </strong>和<strong class="lu iu"> ᴳ </strong>是对应于隐藏层激活的3D体积。为了计算成本<em class="mu"> J_content </em> (C，G)，也可以方便地将这些3D体积展开成2D矩阵，如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/523b1d95f7605cc1badfcb728fab4c7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NDSV5qAAkprp71pIewABcw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd kz">将激活层的3D体积展开成2D矩阵。</strong></p></figure><p id="2453" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">从技术上来说，计算<em class="mu"> J_content </em>并不需要这个展开步骤，但是当您稍后需要执行类似的操作来计算样式成本<em class="mu"> J_style </em>时，这将是一个很好的实践。</p><blockquote class="oi oj ok"><p id="92a2" class="ls lt mu lu b lv mp ju lx ly mq jx ma ol mr md me om ms mh mi on mt ml mm mn im bi translated"><strong class="lu iu">实现</strong>T0】</p></blockquote><p id="b42a" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><code class="fe oo op oq mx b"><strong class="lu iu"><em class="mu">compute_content_cost()</em></strong></code>函数使用TensorFlow计算<strong class="lu iu">内容成本</strong>。</p><p id="bc5e" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">实现该功能的3个步骤是:</p><ol class=""><li id="cc06" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn or nm nn no bi translated">从<code class="fe oo op oq mx b">a_G</code>中检索尺寸。</li><li id="2cc4" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">展开<code class="fe oo op oq mx b">a_C</code>和<code class="fe oo op oq mx b">a_G</code>，如上图所示。</li><li id="26b5" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">计算内容成本。</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="os ot l"/></div></figure><p id="bdf4" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">总之，内容成本采用神经网络的隐藏层激活，并测量a <strong class="lu iu"> ᶜ </strong>和a <strong class="lu iu"> ᴳ </strong>有多不同。当我们稍后最小化内容成本时，这将有助于确保<strong class="lu iu"> G </strong>拥有与<strong class="lu iu"> C </strong>相似的内容。</p><h2 id="bc0d" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">3.2计算风格成本</h2><p id="f70b" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">对于我们的运行示例，我们将使用以下样式图像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/9872d92a8015dc6e459f57a1eabff5d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2QU1hsX6Vn67PqGhQ67Xrw.png"/></div></div></figure><p id="c069" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">由印象派运动的领袖克洛德·莫内以<a class="ae mo" href="https://en.wikipedia.org/wiki/Impressionism" rel="noopener ugc nofollow" target="_blank"> <em class="mu">印象派</em> </a>的风格作画。</p><h2 id="67c5" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">风格矩阵</h2><p id="c7bf" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">样式矩阵也被称为<strong class="lu iu"> Gram矩阵</strong>。线性代数中，一组向量(v₁,…，v <em class="mu"> n </em>)的格拉姆矩阵g是点积矩阵，其项为G <em class="mu"> ij = </em> vᵢᵀ vⱼ= np.dot(vᵢ，vⱼ)</p><p id="3965" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">换句话说，G <em class="mu"> ij </em>比较vᵢ和vⱼ.有多相似如果它们非常相似，你会期望它们有一个大的点积，因此G <em class="mu"> ij </em>会很大。</p><p id="07dc" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">请注意，这里使用的变量名中有一个不幸的冲突。我们遵循文献中使用的通用术语。<strong class="lu iu"> <em class="mu"> G </em> </strong>用于表示样式矩阵(或克矩阵)；<strong class="lu iu"> <em class="mu"> G </em> </strong>也表示生成的图像。对于这个例子，我们将用<strong class="lu iu"><em class="mu">G</em></strong><em class="mu">gram</em>来指代Gram矩阵，用<strong class="lu iu"> <em class="mu"> G </em> </strong>来表示生成的图像。</p><p id="fed4" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">在神经风格传递(NST)中，您可以通过将“展开的”过滤器矩阵与其转置相乘来计算风格矩阵:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/22b8ac913c07f6547a3f39642fb9d11f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2pQf9dmD8NR3Jd6sYbhRfw.png"/></div></div></figure><p id="e29e" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><strong class="lu iu"><em class="mu">G</em></strong><em class="mu">G</em>测量两个滤波器之间的<strong class="lu iu">相关性</strong>:</p><p id="c761" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">结果是一个维数矩阵(<em class="mu"> nC，nC </em>)，其中<em class="mu"> nC </em>是滤波器(通道)的数量。值<strong class="lu iu"><em class="mu">G</em></strong><em class="mu">gram(I，j) </em>测量滤波器<em class="mu"> i </em>的激活与滤波器<em class="mu"> j </em>的激活有多相似。</p><p id="f5d7" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><strong class="lu iu"> <em class="mu">克</em> </strong> <em class="mu">克</em>也衡量<strong class="lu iu">图案或纹理的流行程度:</strong></p><p id="1b3e" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">对角线元素<strong class="lu iu"><em class="mu">G</em></strong><em class="mu">gram(I，i) </em>测量过滤器<em class="mu"> i </em>的“活动”程度。例如，假设过滤器<em class="mu"> i </em>正在检测图像中的垂直纹理。然后<strong class="lu iu"><em class="mu">G</em></strong><em class="mu">gram(I，i) </em>度量图像整体上垂直纹理有多常见。如果<strong class="lu iu"><em class="mu">G</em></strong><em class="mu">gram(I，i) </em>大，这意味着图像有很多垂直纹理。</p><blockquote class="oi oj ok"><p id="9855" class="ls lt mu lu b lv mp ju lx ly mq jx ma ol mr md me om ms mh mi on mt ml mm mn im bi translated"><strong class="lu iu">实现</strong>T0】</p></blockquote><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="os ot l"/></div></figure><h2 id="35fe" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">风格成本</h2><p id="f8cc" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">目标是最小化<strong class="lu iu">样式</strong>图像S的gram矩阵和<strong class="lu iu">生成的</strong>图像g的Gram矩阵之间的距离。</p><p id="0573" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">现在，我们只使用一个单独的隐藏层<em class="mu">一个</em> ˡ.该层的相应样式成本定义为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/c3cff347e715f3a7486a3a0bef005da1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LJ4GwagYXu47BoQQsLoFqQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd kz">款式成本</strong></p></figure><blockquote class="oi oj ok"><p id="cf0c" class="ls lt mu lu b lv mp ju lx ly mq jx ma ol mr md me om ms mh mi on mt ml mm mn im bi translated"><strong class="lu iu">实施</strong> <code class="fe oo op oq mx b"><strong class="lu iu">compute_layer_style_cost()</strong></code></p></blockquote><p id="3226" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">实现该功能的3个步骤是:</p><ol class=""><li id="f042" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn or nm nn no bi translated">从隐藏层激活中检索尺寸<code class="fe oo op oq mx b">a_G</code>。</li><li id="e917" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">将隐藏层激活<code class="fe oo op oq mx b">a_S</code>和<code class="fe oo op oq mx b">a_G</code>展开成2D矩阵，如上图所示。</li><li id="e124" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">用我们之前写的函数计算图像S和G的样式矩阵。</li><li id="d82d" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">计算风格成本。</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="os ot l"/></div></figure><h2 id="cae4" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">样式重量</h2><p id="b488" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">到目前为止，我们只从一层捕捉到了风格。如果我们从几个不同的层“合并”风格成本，我们会得到更好的结果。每一层将被赋予权重(<em class="mu"> λˡ </em> ) <em class="mu"> </em>)，以反映每一层对风格的贡献。默认情况下，我们会给每个层相同的权重，权重加起来是1。完成这个例子后，可以随意试验不同的权重，看看它如何改变生成的图像<strong class="lu iu"> <em class="mu"> G </em> </strong>。</p><p id="d182" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">您可以组合不同图层的样式成本，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/992cd9390115f8415bdeddc3bac9f796.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mVyAHI7dkKU8ZbrK4MJJbA.png"/></div></div></figure><p id="93af" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">其中<em class="mu"> λˡ </em>的值在<code class="fe oo op oq mx b">STYLE_LAYERS</code>中给出。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="4d71" class="nb lb it mx b gy nc nd l ne nf">STYLE_LAYERS = [<br/> (‘conv1_1’, 0.2),<br/> (‘conv2_1’, 0.2),<br/> (‘conv3_1’, 0.2),<br/> (‘conv4_1’, 0.2),<br/> (‘conv5_1’, 0.2)]</span></pre><blockquote class="oi oj ok"><p id="abde" class="ls lt mu lu b lv mp ju lx ly mq jx ma ol mr md me om ms mh mi on mt ml mm mn im bi translated"><strong class="lu iu">实现</strong> <code class="fe oo op oq mx b"><strong class="lu iu">compute_style_cost()</strong></code></p></blockquote><p id="1850" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">该函数多次调用<code class="fe oo op oq mx b">compute_layer_style_cost(...)</code>函数，并使用<code class="fe oo op oq mx b">STYLE_LAYERS</code>中的值对结果进行加权。</p><p id="fde6" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><strong class="lu iu">对</strong>的描述<code class="fe oo op oq mx b"><strong class="lu iu">compute_style_cost</strong></code></p><p id="27ba" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">对于每一层:</p><ul class=""><li id="690c" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn nl nm nn no bi translated">选择当前层的激活(输出张量)。</li><li id="319c" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">从当前图层中获取<strong class="lu iu">样式图像S </strong>的样式。</li><li id="ed95" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">从当前图层获取<strong class="lu iu">生成的图像G </strong>的样式。</li><li id="fe5a" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">计算当前层的<strong class="lu iu">样式成本</strong></li><li id="12f2" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">将加权风格成本加到总风格成本上(<em class="mu"> J_style </em>)</li></ul><p id="c921" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">完成循环后:</p><ul class=""><li id="0c09" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn nl nm nn no bi translated">返还整体风格成本。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="os ot l"/></div></figure><p id="3073" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><strong class="lu iu">注意</strong>:在上面for循环的内循环中，<code class="fe oo op oq mx b">a_G</code>是一个张量，还没有求值。当我们在下面的model_nn()中运行张量流图时，它将在每次迭代中被评估和更新。</p><p id="d4db" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">总之，图像的风格可以使用隐藏层激活的Gram矩阵来表示。通过组合来自多个不同层的这种表示，我们甚至可以获得更好的结果。这与内容表示形成对比，在内容表示中通常只使用一个隐藏层就足够了。此外，最小化样式成本会导致图像<strong class="lu iu"> <em class="mu"> G </em> </strong>跟随图像<strong class="lu iu"> <em class="mu"> S </em> </strong>的样式。</p><h2 id="b7ed" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">3.3定义优化的总成本</h2><p id="26de" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">最后，让我们创建一个最小化样式和内容成本的成本函数。公式是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/3d8076de1123ac2c9c6e3344b33d3e94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EYgR_1v9DIbV73k0j4UgmA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd kz">NST的总成本函数</strong></p></figure><blockquote class="oi oj ok"><p id="42c1" class="ls lt mu lu b lv mp ju lx ly mq jx ma ol mr md me om ms mh mi on mt ml mm mn im bi translated"><strong class="lu iu">实现</strong>T1】</p></blockquote><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="os ot l"/></div></figure><p id="b82b" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">总成本是内容成本<em class="mu"> J_content </em> (C，G)和样式成本<em class="mu"> J_style </em> (S，G)的线性组合。</p><p id="9051" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><em class="mu"> α </em>和<em class="mu"> β </em>是控制内容和风格之间相对权重的超参数。</p><h1 id="f481" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">4.解决最优化问题</h1><p id="e2db" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">最后，让我们把所有的东西放在一起实现神经风格转移！</p><p id="52ca" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">以下是该程序必须要做的事情:</p><ol class=""><li id="9bb2" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn or nm nn no bi translated">创建交互式会话</li><li id="4771" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">加载内容图像</li><li id="1e3d" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">加载样式图像</li><li id="f612" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">随机初始化要生成的图像</li><li id="a285" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">加载VGG19型号</li><li id="7cbb" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">构建张量流图:</li></ol><ul class=""><li id="24fb" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn nl nm nn no bi translated">通过VGG19模型运行内容映像，并计算内容成本</li><li id="731a" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">通过VGG19模型运行样式图像，并计算样式成本</li><li id="0517" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">计算总成本</li><li id="0193" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">定义优化器和学习率</li></ul><p id="80c0" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">7.初始化张量流图并运行它进行大量迭代，在每一步更新生成的图像。</p><p id="1cf5" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">让我们详细介绍一下各个步骤。</p><h2 id="4d16" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">互动会议</h2><p id="adfa" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">我们之前已经实现了总成本<em class="mu"> J(G) </em>。我们现在将设置TensorFlow来针对<strong class="lu iu"> <em class="mu"> G </em> </strong>进行优化。</p><p id="3d15" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">为此，我们的程序必须重置图形并使用一个“<a class="ae mo" href="https://www.tensorflow.org/api_docs/python/tf/InteractiveSession" rel="noopener ugc nofollow" target="_blank">交互会话</a>”。与常规会话不同，“交互式会话”将自己安装为默认会话来构建图表。这允许我们运行变量，而不需要经常引用会话对象(调用<code class="fe oo op oq mx b">sess.run()</code>)，这简化了代码。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="15c6" class="nb lb it mx b gy nc nd l ne nf"># Reset the graph<br/>tf.reset_default_graph()</span><span id="0d73" class="nb lb it mx b gy ow nd l ne nf"># Start interactive session<br/>sess = tf.InteractiveSession()</span></pre><h2 id="bc80" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">内容图像</h2><p id="5099" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">让我们加载、重塑和规范化我们的<strong class="lu iu">内容</strong>图像(卢浮宫博物馆图片):</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="24aa" class="nb lb it mx b gy nc nd l ne nf">content_image = scipy.misc.imread(“images/w_hotel.jpg”)<br/>content_image = reshape_and_normalize_image(content_image)</span></pre><h2 id="3ce1" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">风格图像</h2><p id="ed2d" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">让我们载入、重塑并正常化我们的<strong class="lu iu">风格</strong>形象(克洛德·莫内的画):</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="89e9" class="nb lb it mx b gy nc nd l ne nf">style_image = scipy.misc.imread(“images/starry_night.jpg”)<br/>style_image = reshape_and_normalize_image(style_image)</span></pre><h2 id="ba84" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">生成的图像与内容图像相关</h2><p id="5f5f" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">现在，我们将<strong class="lu iu">生成的</strong>图像初始化为从<code class="fe oo op oq mx b">content_image</code>创建的噪声图像。</p><p id="7222" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><strong class="lu iu">生成的</strong>图像与<strong class="lu iu">内容</strong>图像略有关联。通过将<strong class="lu iu">生成的</strong>图像的像素初始化为主要是噪声但与<strong class="lu iu">内容</strong>图像稍微相关，这将有助于<strong class="lu iu">生成的</strong>图像的内容更快速地匹配<strong class="lu iu">内容</strong>图像的内容。</p><p id="7add" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">请随意在<code class="fe oo op oq mx b">nst_utils.py</code>中查看Github回购中的<code class="fe oo op oq mx b">generate_noise_image(...)</code>细节。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="272a" class="nb lb it mx b gy nc nd l ne nf">generated_image = generate_noise_image(content_image)<br/>imshow(generated_image[0]);</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/011f47422cbcaa44426fda967af97721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*opSu19sWLGTazKLTEH7tJA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd kz">生成_噪声_图像(内容_图像)</strong></p></figure><h2 id="3a05" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">加载预训练的VGG19模型</h2><p id="e91b" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">接下来，如前所述，我们将加载VGG19模型。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="483c" class="nb lb it mx b gy nc nd l ne nf">model = load_vgg_model(“pretrained-model/imagenet-vgg-verydeep-19.mat”)</span></pre><h2 id="d8ea" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">内容成本</h2><p id="ba73" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">为了让程序计算内容成本，我们现在将指定<code class="fe oo op oq mx b">a_C</code>和<code class="fe oo op oq mx b">a_G</code>为适当的隐藏层激活。我们将使用层<code class="fe oo op oq mx b">conv4_2</code>来计算内容成本。下面的代码执行以下操作:</p><ol class=""><li id="9038" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn or nm nn no bi translated">将内容图像指定为VGG模型的输入。</li><li id="e5f9" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">设置<code class="fe oo op oq mx b">a_C</code>为张量，激活<code class="fe oo op oq mx b">conv4_2</code>层的隐藏层。</li><li id="c98b" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">将<code class="fe oo op oq mx b">a_G</code>设置为激活同一层隐藏层的张量。</li><li id="04ce" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn or nm nn no bi translated">使用<code class="fe oo op oq mx b">a_C</code>和<code class="fe oo op oq mx b">a_G</code>计算内容成本。</li></ol><p id="c2b8" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><strong class="lu iu">注</strong>:此时，<code class="fe oo op oq mx b">a_G</code>是张量，还没有求值。当我们运行下面<code class="fe oo op oq mx b">model_nn()</code>中的张量流图时，将在每次迭代中对其进行评估和更新。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="81b3" class="nb lb it mx b gy nc nd l ne nf"># Assign the content image to be the input of the VGG model. <br/>sess.run(model[‘input’].assign(content_image))</span><span id="12b8" class="nb lb it mx b gy ow nd l ne nf"># Select the output tensor of layer conv4_2<br/>out = model[‘conv4_2’]</span><span id="db2f" class="nb lb it mx b gy ow nd l ne nf"># Set a_C to be the hidden layer activation from the layer we have selected<br/>a_C = sess.run(out)</span><span id="daf6" class="nb lb it mx b gy ow nd l ne nf"># Set a_G to be the hidden layer activation from same layer. Here, a_G references model[‘conv4_2’] <br/># and isn’t evaluated yet. Later in the code, we’ll assign the image G as the model input, so that<br/># when we run the session, this will be the activations drawn from the appropriate layer, with G as input.<br/>a_G = out</span><span id="8200" class="nb lb it mx b gy ow nd l ne nf"># Compute the content cost<br/>J_content = compute_content_cost(a_C, a_G)</span></pre><h2 id="cac8" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">风格成本</h2><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="0247" class="nb lb it mx b gy nc nd l ne nf"># Assign the input of the model to be the “style” image <br/>sess.run(model[‘input’].assign(style_image))</span><span id="09c5" class="nb lb it mx b gy ow nd l ne nf"># Compute the style cost<br/>J_style = compute_style_cost(model, STYLE_LAYERS)</span></pre><h2 id="e2d6" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">总成本</h2><p id="8246" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">现在我们有了<strong class="lu iu">内容成本</strong> ( <em class="mu"> J_content) </em>和<strong class="lu iu">样式成本</strong> ( <em class="mu"> J_style </em>)，通过调用<code class="fe oo op oq mx b">total_cost()</code>计算总成本J。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="0267" class="nb lb it mx b gy nc nd l ne nf">J = total_cost(J_content, J_style, alpha=10, beta=40)</span></pre><h2 id="9658" class="nb lb it bd lc nv nw dn lg nx ny dp lk mb nz oa lm mf ob oc lo mj od oe lq of bi translated">【计算机】优化程序</h2><p id="4ced" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">这里，我使用Adam优化器来最小化总成本<code class="fe oo op oq mx b">J</code>。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="f751" class="nb lb it mx b gy nc nd l ne nf"># define optimizer<br/>optimizer = tf.train.AdamOptimizer(2.0)</span><span id="fff6" class="nb lb it mx b gy ow nd l ne nf"># define train_step<br/>train_step = optimizer.minimize(J)</span></pre><blockquote class="oi oj ok"><p id="5d1b" class="ls lt mu lu b lv mp ju lx ly mq jx ma ol mr md me om ms mh mi on mt ml mm mn im bi translated"><strong class="lu iu"> <em class="it">实施</em> </strong> <code class="fe oo op oq mx b"><strong class="lu iu"><em class="it">model_nn()</em></strong></code></p></blockquote><p id="955f" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">函数<strong class="lu iu">初始化</strong>张量流图的变量，<strong class="lu iu">将输入图像(初始生成的图像)分配给</strong>作为VGG19模型的输入，<strong class="lu iu">运行</strong>张量(它是在该函数上面的代码中创建的)大量步骤。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="os ot l"/></div></figure><p id="0652" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">运行以下代码片段来生成艺术图像。每20次迭代应该花费大约3分钟的CPU时间，但是在大约140次迭代之后，您开始观察到有吸引力的结果。神经类型转移通常使用GPU来训练。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="a777" class="nb lb it mx b gy nc nd l ne nf">model_nn(sess, generated_image)</span></pre><p id="5b64" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">你完了！运行此程序后，您应该会看到下图右侧所示的内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/ec156dea4d93002ad280692d816c0a55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aE1l2KUDsgE_WuUZhYLcJA.png"/></div></div></figure><p id="54f9" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">以下是其他几个例子:</p><ul class=""><li id="9cf8" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn nl nm nn no bi translated">具有梵高风格(星夜)的波斯波利斯(伊朗)古城的美丽遗迹</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ku"><img src="../Images/7d10dbb078cbbace9c2add7c00313061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k5Q_NYr1niC-qjWMr-lUCg.png"/></div></div></figure><ul class=""><li id="a46b" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn nl nm nn no bi translated">Pasargadae的居鲁士大帝墓，采用来自伊斯法罕的陶瓷Kashi风格。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/6a89e23a236f3b401bef8155356e925e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rfOejfaHDKfDlAIhYE_GMw.png"/></div></div></figure><ul class=""><li id="061a" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn nl nm nn no bi translated">具有抽象蓝色流体绘画风格的湍流的科学研究。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/dcb5f3196455ecbfbb4a1803d52b346f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0cElR2EleFbHgyNGBvntVQ.png"/></div></div></figure><h1 id="258c" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">6.结论</h1><p id="5ae5" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">你现在能够使用神经风格转移来生成艺术图像。神经风格转移是一种算法，即给定一个<strong class="lu iu">内容图像C </strong>和一个<strong class="lu iu">风格图像S </strong>，可以生成一个艺术图像。</p><p id="f5f2" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">它使用基于预训练的ConvNet的表示(隐藏层激活)。使用一个隐藏层的激活来计算<strong class="lu iu">内容成本函数</strong>;一层的<strong class="lu iu">样式成本函数</strong>使用该层激活的Gram矩阵来计算。使用几个隐藏层获得整体风格成本函数。</p><p id="00d1" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">最后，优化总成本函数导致合成新图像。</p><h1 id="e82c" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">7.引用和参考文献</h1><p id="545d" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated"><strong class="lu iu"> Github回购</strong>:<a class="ae mo" href="https://github.com/TheClub4/artwork-neural-style-transfer" rel="noopener ugc nofollow" target="_blank">https://github.com/TheClub4/artwork-neural-style-transfer</a></p><p id="c73f" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">特别感谢<a class="ae mo" href="https://www.deeplearning.ai/" rel="noopener ugc nofollow" target="_blank"><strong class="lu iu">deep learning . ai</strong></a>。图片由<strong class="lu iu"> deeplearning.ai </strong>提供。</p><p id="9dd0" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">神经风格转移算法源于Gatys等人(2015年)。Harish Narayanan和Github用户“log0”也有可读性很高的文章，我们从中获得了灵感。在该实现中使用的预训练网络是VGG网络，这是由于Simonyan和Zisserman (2015)。预训练的权重来自MathConvNet团队的工作。</p><ul class=""><li id="cc6a" class="ng nh it lu b lv mp ly mq mb ni mf nj mj nk mn nl nm nn no bi translated">利昂·a·加蒂斯、亚历山大·s·埃克、马蒂亚斯·贝赫(2015年)。<a class="ae mo" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">艺术风格的神经算法</a></li><li id="e8d2" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated"><a class="ae mo" href="https://harishnarayanan.org/writing/artistic-style-transfer/" rel="noopener ugc nofollow" target="_blank">用于艺术风格转移的卷积神经网络。</a></li><li id="300a" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">Log0，<a class="ae mo" href="http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style" rel="noopener ugc nofollow" target="_blank"> TensorFlow实现的“一种艺术风格的神经算法”。</a></li><li id="e1ef" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated">卡伦·西蒙扬和安德鲁·齐泽曼(2015)。<a class="ae mo" href="https://arxiv.org/pdf/1409.1556.pdf" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的极深度卷积网络</a></li><li id="4d0f" class="ng nh it lu b lv np ly nq mb nr mf ns mj nt mn nl nm nn no bi translated"><a class="ae mo" href="http://www.vlfeat.org/matconvnet/pretrained/" rel="noopener ugc nofollow" target="_blank"> MatConvNet。</a></li></ul></div></div>    
</body>
</html>