<html>
<head>
<title>Object Detection using GluonCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 GluonCV 的目标检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-using-gluoncv-b7940670ba54?source=collection_archive---------38-----------------------#2020-05-15">https://towardsdatascience.com/object-detection-using-gluoncv-b7940670ba54?source=collection_archive---------38-----------------------#2020-05-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7285" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在本文中，我们将演示如何使用 GluonCV 使用预训练模型进行对象检测。</h2></div><ol class=""><li id="f61c" class="ki kj it kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="kk iu">导入库</strong></li></ol><p id="6e53" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">我们将从导入所需的库开始。我们需要导入 MXNet、GluonCV 和 Pyplot。</p><pre class="ln lo lp lq gt lr ls lt lu aw lv bi"><span id="31a4" class="lw lx it ls b gy ly lz l ma mb">import mxnet as mx<br/>import gluoncv as gcv<br/>import matplotlib.pyplot as plt</span></pre><p id="8272" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated"><strong class="kk iu"> 2。测试图像</strong></p><p id="3f71" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">我们将使用下面的图像进行对象检测。该图像有几个明显的对象。在前景中，我们有一只在自行车前面的狗。在背景中，我们有一棵树和一辆车。我们想要一个模型来探测这些物体。</p><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mc"><img src="../Images/bc0597e09b0f1556be80a9c1470fc103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5jqqcfUiT7cBiYlDJunlEw.jpeg"/></div></div></figure><p id="f16a" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated"><strong class="kk iu"> 3。加载图像</strong></p><p id="aeab" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">因此，让我们使用<em class="mk"> imread()加载图像。</em></p><pre class="ln lo lp lq gt lr ls lt lu aw lv bi"><span id="284f" class="lw lx it ls b gy ly lz l ma mb">image = mx.image.imread(image_path)<br/>print('data type: ', image.dtype)<br/>print('shape: ', image.shape)<br/>print('type: ', type(image))<br/>plt.imshow(image.asnumpy())<br/>plt.show()</span></pre><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ml"><img src="../Images/9554508e30f04bca6c4722c676d6d6df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C473XTHUum3WOpr_H4_gFQ.png"/></div></div></figure><p id="3d42" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated"><strong class="kk iu"> 4。变换图像</strong></p><p id="4287" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">如上所示，该图像具有 HWC 的数据布局。我们的图像高度为 576 像素，宽度为 768 像素。这是一个有三个通道的彩色图像。因此，让我们将图像转换成所需的格式。</p><p id="02d2" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">CV 提供了一个为 yolo 网络应用所有必要的预处理步骤的函数。我们用我们的图像调用<em class="mk"> yolo.transform_test </em>,并用 short 参数提供输出图像的短长度。我们输入的图像是高度小于宽度的风景。使用此功能，高度将被调整为 512 像素，同时保持图像的纵横比。</p><pre class="ln lo lp lq gt lr ls lt lu aw lv bi"><span id="4485" class="lw lx it ls b gy ly lz l ma mb">image, chw_image = gcv.data.transforms.presets.yolo.transform_test(image, short=512)<br/><br/>print('data type: ', image.dtype)<br/>print('shape: ', image.shape)<br/>print('minimum value: ', image.min().asscalar())<br/>print('maximum value: ', image.max().asscalar())</span></pre><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mm"><img src="../Images/be796adf597ec03e6d8c71997017d656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zWTUj119J08zffiMzvcX1g.png"/></div></div></figure><p id="d683" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">转换测试函数返回两个对象。我们的第一个对象是准备好提供给网络的转换图像。我们的第二个对象只是调整了大小的图像，我们使用这个图像来绘制结果。</p><p id="a479" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated"><em class="mk">调整大小后的图像是一批单幅图像。这是 NCHW 格式，而不是 NHWC 格式，并且是 32 位浮点数组，而不是 8 位整数。最后，返回的 resize 图像是一个规范化的图像。</em></p><p id="a949" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">我们可以绘制调整后的 CHW 图像。</p><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mn"><img src="../Images/2f631257496b34069739e1ed83330de1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T3rnZ9UFYv3fWtVTxenAjw.png"/></div></div></figure><p id="355a" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">我们可以看到调整大小的效果。我们的短边现在是 512 像素而不是 576 像素，而宽度仍然是高度的三分之一。</p><p id="af94" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated"><strong class="kk iu"> 5。负载预训练模型</strong></p><p id="95cb" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">我们可以使用<em class="mk"> get_model() </em>函数从 CV 模型动物园加载我们的预训练模型。我们将使用带有 darknet53 主干网的 yolo3 网络，该主干网已经在 coco 数据集上进行了训练。</p><p id="807d" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated"><em class="mk">不要忘记将 pretrained 参数设置为 true。</em></p><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mo"><img src="../Images/1c4782b76752488e2e36cc9ee52b3562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cQrARsn694vzNquPi15Rww.png"/></div></div></figure><p id="38df" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">6。做出预测</p><p id="ce5d" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">我们可以再次像函数一样调用网络。给网络和图像和一个预测将被返回。当使用检测模型时，我们可以预期返回三个 MXNet ndarrays。我们可以遍历元组并打印出这些数组的形状。</p><ol class=""><li id="dfdc" class="ki kj it kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><em class="mk">第一个数组包含对象类索引。</em></li><li id="e132" class="ki kj it kk b kl mp kn mq kp mr kr ms kt mt kv kw kx ky kz bi translated"><em class="mk">第二个数组包含对象类别概率。</em></li><li id="a506" class="ki kj it kk b kl mp kn mq kp mr kr ms kt mt kv kw kx ky kz bi translated"><em class="mk">最后一个数组包含了物体边界框的坐标。</em></li></ol><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ml"><img src="../Images/69fd69155709cad24e86eb592ccfc0b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RogupKOhQzv_0HrDvCoXRA.png"/></div></div></figure><p id="42f2" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">请注意，这些数组的形状都是从 1，100 开始的。这是因为我们的模型可以预测单个图像中多达 100 个对象。因此，对于第一个数组，形状为 1，100，1，这意味着我们有 1 个图像，100 个潜在对象，每个对象有 1 个类别索引。</p><p id="9bd5" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">对于最后一个数组，形状为 1，100，4，我们有 1 个图像，100 个潜在的对象。和 4 个值来定义其边界框。</p><p id="022d" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">因为我们只对一个图像执行对象检测，所以我们可以删除所有数组的额外批处理维度，然后解包元组。我们将赋予每个数组自己的变量。</p><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mu"><img src="../Images/0b36b06e8b2ad61510e9cfd70e1eddb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MlFxAdbWhpARFQznCKpETA.png"/></div></div></figure><p id="7f27" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">7 .<strong class="kk iu">。对象类别</strong></p><p id="2eed" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">让我们仔细看看对象<em class="mk"> class_indexes </em>。虽然我们的模型可以潜在地检测每幅图像中的 100 个对象，但是让我们来看看前十个对象的类索引。</p><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mu"><img src="../Images/949ca24dc1fbbbcb16199af8dc53a34a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e215lVtPOeRiniWjvhjVEA.png"/></div></div></figure><p id="4917" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">我们检测到的第一个对象的预测类别为 16，我们看到了更多类别为 1、7、2、13 和 0 的对象。在这之后，我们有许多类索引为-1 的对象。</p><p id="87f6" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">-1 是一个特殊的类索引，用于指示没有检测到对象。</p><p id="1915" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">因此，我们总共有六个检测到的对象，剩下的 94 个潜在对象用-1 值填充。我们可以使用网络的类别属性来查找类别标签。顶部的对象是 class 16，在查看 class 标签时，我们可以看到 dog 的索引是 16。</p><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mn"><img src="../Images/fcf74b501bd700f4d4c8c1d48a18b0a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*shRT-ajheX20WCLSrI42Qg.png"/></div></div></figure><p id="4659" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated"><strong class="kk iu"> 8。物体概率</strong></p><p id="f8e1" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">类似于对象<em class="mk"> class_indexes </em>，我们可以得到相关的对象类概率。我们可以把这理解为我们相信类索引是正确的。</p><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mn"><img src="../Images/00ce612a028290337c905bad816ab7ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JFmAaTB4MthNqvEoDPCE1Q.png"/></div></div></figure><p id="dae7" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">如果我们使用 50%的置信度阈值，我们可以看到已经检测到三个对象。我们的模型对它的两个检测非常有信心，概率得分在 90%以上。这可能是两个前景物体。我们还会看到-1。我们没有填充物体的置信度。</p><p id="1118" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated"><strong class="kk iu"> 9。包围盒坐标</strong></p><p id="81a7" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">四个值用于定义每个对象的边界框。给出了边界框左上角和右下角的坐标，总共有四个值。</p><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mn"><img src="../Images/b1971f845c6f63f565c019cbcaf1f7ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZcKGD6E9S3TGRQngxAjaCw.png"/></div></div></figure><p id="1d99" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated"><strong class="kk iu"> 10。可视化</strong></p><p id="8588" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">让我们来做可视化，而不是解释表格中的边界框。CV 带有边界框绘图功能。我们可以提供之前调整过大小的图像(<em class="mk"> chw_image </em>)。以及每个网络输出。可选地，我们可以提供类标签来为我们的绘图添加注释。</p><figure class="ln lo lp lq gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mo"><img src="../Images/a198a2e6374599ef5ffce2d57c9ceb33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TSMsSlVeoa_uataZXyoGLQ.png"/></div></div></figure><figure class="ln lo lp lq gt md gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/6a38bf7938ba2b866fdd7fd77c09a76a.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*KvjyrKuG3zXogxSzhBldWg.png"/></div></figure><p id="759c" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">预训练的网络在检测图像中的对象方面做得很好。它成功地检测到了一只狗、一辆自行车和一辆卡车(置信区间为 50%)。预训练的网络错过了背景中的树，因为它是在 coco 上预训练的，而 coco 没有树的对象类。</p><p id="dc7a" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">总之，我们从预处理输入图像开始。然后，我们从模型动物园加载一个对象检测模型，并使用它来生成预测。最后，我们解释了网络输出并可视化了检测到的目标。</p><p id="46a8" class="pw-post-body-paragraph la lb it kk b kl km ju lc kn ko jx ld kp le lf lg kr lh li lj kt lk ll lm kv im bi translated">在下一篇文章的<a class="ae mw" rel="noopener" target="_blank" href="/image-classification-using-gluoncv-f6ae5401d6ae">中，我们将讨论使用 GluonCV 的图像分类问题。</a></p><blockquote class="mx my mz"><p id="9da9" class="la lb mk kk b kl km ju lc kn ko jx ld na le lf lg nb lh li lj nc lk ll lm kv im bi translated">在这里成为媒体会员<a class="ae mw" href="https://medium.com/@rmesfrmpkr/membership" rel="noopener">，支持独立写作，每月 5 美元，可以在媒体上看到所有的故事。</a></p></blockquote></div></div>    
</body>
</html>