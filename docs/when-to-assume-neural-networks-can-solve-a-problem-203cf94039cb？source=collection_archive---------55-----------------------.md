# 何时假设神经网络可以解决问题

> 原文：<https://towardsdatascience.com/when-to-assume-neural-networks-can-solve-a-problem-203cf94039cb?source=collection_archive---------55----------------------->

## 实用指南

![](img/42f6c987b231989c13ac57be42468c86.png)

来源于 Wikimedia Common，最初来自 Maggie Black 的“Den medeltida kokboken”，是中世纪食谱的瑞典语翻译

问题:“我们应该假设哪些问题可以用机器学习来解决？”，甚至更狭隘，更专注于当前的发展“我们应该假设神经网络能够解决什么问题？”，是一个我没怎么见过的称呼。

有像 PAC learning 和 AIX 这样的理论，乍看起来似乎围绕着这一点，因为它一般属于机器学习，但如果实际应用于实践，不会产生任何有意义的答案。

但是，当有人就某个具体问题问我这个问题时，只要我能看一看数据，我往往能给出一个相当合理的自信回答。

因此，我认为写下产生这种答案的启发法可能是有帮助的。我绝不认为这些在科学意义上是精确的或基于证据的，但我认为它们可能是有帮助的，甚至可能是进一步讨论该主题的良好起点。

# 1.如果另一个最大似然算法已经成功，那么神经网络几乎肯定可以解决问题。

给定一个可以通过现有的最大似然技术解决的问题，我们可以假设一个稍微通用的神经网络，如果允许它明显更大，也可以解决它。

比如体面的下棋，也是已经解决的问题。这可以使用小型决策树和一些非常简单的定制搜索试探法来完成(例如参见[https://github . com/AdnanZahid/Chess-AI-TDD)。](https://github.com/AdnanZahid/Chess-AI-TDD%29.)因此，我们应该假设一个相当通用的神经网络，使用比基于 DT 的原始模型多得多的参数。

事实上，这似乎是[的情况](https://blog.cerebralab.com/%5Bhttps://github.com/pbaer/neural-chess%5D%28https://github.com/pbaer/neural-chess%29)，你可以使用一个相当普通的全连接网络来下棋，而不需要任何额外的内置试探法或专门用于此目的的架构。

或者，使用任何“玩具”数据集，例如在 [UCI](https://blog.cerebralab.com/%5Bhttps://archive.ics.uci.edu/ml/index.php%5D%28https://archive.ics.uci.edu/ml/index.php%29) 上的数据集，使用像 Sklearn 这样的库找到最合适的经典 ML 模型，然后尝试使用[sk learn 提供的相当简单的神经网络](https://blog.cerebralab.com/%5Bhttps://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html%5D%28https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html%29)，如果你将 _hidden_layer_sizes 设置得足够大，无论你在比较什么模型，你几乎肯定会获得匹配的性能。

这个假设并不总是成立的，因为:

*   a)取决于架构，神经网络可能很容易无法优化给定的问题。例如，对于具有大窗口和步长的卷积网络来说，下棋可能是不可能的，即使它非常大。
*   b)某些最大似然技术有许多内置的启发法，对于神经网络来说可能很难学习。现有的最大似然技术不能有任何关键的启发性，或者至少你必须能够将同样的启发性包含到你的神经网络模型中。

由于我们主要关注可推广的神经网络架构(例如，全连接网络，这是大多数人听到“神经网络”时首先想到的)，a)点是非常不相关的。

考虑到大多数启发式算法同样适用于任何模型，甚至是像国际象棋这样的模型，并且这个规模有时足以让网络能够学习启发式算法，这个规则基本上每次都适用。

我实在想不出一个反例…也许是一些特定类型的数字投影？

这是一个相当无聊的第一条规则，但值得作为一个起点来阐述。

# 2.神经网络几乎肯定能解决与已经解决的问题非常相似的问题

假设您有一个基于几个参数来预测给定债权人风险的模型，例如当前余额、以前的信用记录、年龄、驾照状态、犯罪记录、年收入、就业时间、{关于当前经济环境的各种信息}、孩子数量、婚姻状况、过去 60 天访问的色情网站。

假设这个模型“解决”了你的问题，也就是说，它比 80%的人类分析师更好地预测了风险。

但是 GDPR 滚滚向前，你不能再合法地通过购买那些数据来窥探你的一些客户的互联网历史。你需要为这些客户建立一个新的模式。

您的输入现在被截断，客户的在线色情历史不再可用(或者说无可否认是可用的)。

假设你仍然可以建立一个合理的模型来解决这个问题，这安全吗？

答案几乎肯定是“是的；鉴于我们对这个世界的了解，我们可以有把握地假设某人的色情浏览历史与他们的信用评级没有其他参数那么相关。

另一个例子:假设你知道别人在用一个模型，但是他们的数据和你的略有不同。

你知道一家总部位于美国的专注于蛇的宠物店，它利用以前的购买来推荐产品，他们告诉你这对他们的底线来说做得很好。你是一家总部设在英国的鹦鹉宠物店。如果根据你的数据进行训练，你能相信他们的模型或类似的模型能解决你的问题吗？

同样，正确答案很可能是“是”，因为数据足够相似。这就是为什么建立一个产品推荐算法在 20 年前是一个热门话题，但现在每个人和他们的妈妈都可以为它获得一个 WordPress 插件，并接近亚马逊的水平。

或者，更严重的是，假设你有一个检测乳腺癌的给定算法，如果对 100，000 张图像进行训练，并进行后续检查以确认真正的诊断，该算法的表现比普通放射科医生更好。

你能假设，如果有能力把它变大，你能建立一个模型来检测其他类型的软组织中的癌症，也比放射科医生更好吗？

同样，答案是肯定的。这里的论证更长，因为我们不太确定，主要是因为缺乏数据。我差不多花了一整篇文章论证答案仍然是肯定的。

在 NLP 中，完全相同的神经网络架构似乎在任何语言中都能很好地进行翻译或文本生成，只要它属于印欧语系并且有针对它的大量数据(即，相当于用于训练现有英语模型的数据)。

现代的自然语言处理技术似乎能够处理所有的语系，而且他们是用越来越少的数据来处理的。然而，在某种程度上，数据的相似性和训练样本的数量与模型快速概括许多语言的能力紧密相关。

或者看看图像识别和对象检测/装箱模型，主要的瓶颈是大量良好标记的数据，而不是图像的内容。边缘情况是存在的，但是一般来说，如果足够多的例子被输入到最初为不同图像任务设计的架构中(例如，为 Imagenet 设计的卷积残差网络)，所有类型的对象和图像都可以被识别和分类。

此外，给定一个在 Imagenet 上训练的网络，我们可以保留初始权重和偏差(本质上是网络“已经学习的”)，而不是从头开始，并且它将能够从该起点更快地在不同的数据集上“学习”。

# 3.神经网络可以解决人类可以用小数据点和很少或没有上下文来解决的问题

假设我们有两个从未见过的物体的 20x20px 黑白图像；它们“明显不同”，只是不为我们所知。有理由假设，给定一堆训练例子，人类将相当擅长区分这两者。

给定一堆例子(比如说 100 个)，假设几乎任何有数百万个参数的神经网络都会像人类一样面对这个问题也是合理的。

你可以把这想象成要学习的信息量。在这种情况下，我们有 400 个像素，每个像素有 255 个值，因此有理由假设每个可能的模式都可以用我们方程中的几百万个参数来解释。

但是“小数据点”在这里的意思是这个定义的关键。

简而言之，“小”是以下各项的函数:

*   你模型的尺寸。模型越大，它能学习的模式越复杂，你可能的输入/输出就越大。
*   答案的粒度(输出)。例如 1，000 个类别对 10 个类别，或者 0 到 1，000 的整数范围对 0 到 100，000 的整数范围。在本例中为 2。
*   输入的大小。在本例中为 400，因为我们有一个 20x20 的图像。

以 MNIST 这样的经典图像分类任务为例。尽管已经做了一些小的改进，MNIST 的艺术水平并没有多大进步。在过去的 8 年中，已经从大约 98.5%提高到大约 99.4%，两者都在通常的[“人为误差范围”](https://www.quora.com/What-is-human-accuracy-on-the-MNIST-test-set-Are-there-any-quotable-sources)内。

相比之下，在输入和输出规模方面，一些更大的公司，如 ImageNet，[在过去的 8 年里，其份额从 50%跃升至近 90%](https://paperswithcode.com/sota/image-classification-on-imagenet) 。

事实上，即使使用前 CNN 技术， [MNIST 基本上是可以解决的](https://www.semanticscholar.org/paper/Efficient-Handwritten-Digit-Recognition-based-on-of-Ebrahimzadeh-Jampour/b44c7a87888b46e37bae571db7e2355a1eeca46d)。

但是，即使把“小”定义为上述的函数，我们也没有实际函数的公式。我认为这要困难得多，但我们可以想出一个适用于大多数情况的“廉价”答案——事实上，这正是我们所需要的:

*   当相同或更大输入和输出大小的其他任务已经通过机器学习在单个 GPU 上使用多个架构解决时，给定的任务可以被视为小任务

这可能听起来像一个愚蠢的启发，但它惊人地适用于大多数“简单”的机器学习问题。例如，现在许多 NLP 任务比大多数“视频”任务更先进的原因是大小，尽管在网络架构方面图像有了巨大的进步(更接近视频领域)。视频上有意义的任务的输入和输出大小要大得多；另一方面，即使 NLP 是在一个完全不同的领域，它在大小上更接近图像处理。

那么，“很少到没有上下文”是什么意思？

这是一个比较难的问题，但是我们可以依靠“大”和“小”上下文的例子。

*   预测股市可能需要大量的背景知识。一个人必须能够更深入地挖掘要投资的公司；查看市场基本面、最近的盈利电话、高管层的历史；了解公司的产品；也许从它的雇员和顾客那里得到一些信息，如果可能的话，得到关于即将到来的销售和合并的内部消息，等等。

你可以尝试纯粹根据股市的指标来预测股市，但这不是大多数人解决问题的方式。

*   另一方面，基于环境中的温度和湿度来预测给定印刷机的产量至少在某种程度上可以通过上下文来解决。在机器上工作的工程师可能知道某些部件在某些条件下表现不同。然而，在实践中，工程师基本上会让打印机运行，改变条件，观察产量，然后得出一个方程。因此，给定这些数据，机器学习算法也可能提出同样好的解决方案，甚至更好的解决方案。

在这种意义上，ML 算法可能会产生类似于数学家在[解方程](https://blog.cerebralab.com/If_Van_der_Waals_was_a_neural_network)的结果，因为对于人类来说，上下文基本上是不存在的。

当然有一些限制。除非我们在 4000℃下测试我们的机器，否则算法无法知道产量将为 0，因为机器会熔化；工程师可能会怀疑这一点。

因此，我可以将第三个原则表述为:

在下列情况下，通用神经网络可能解决问题:

*   人类可以解决它
*   具有相似规模的输出和输入的任务已经被同等规模的网络解决了
*   人类拥有的大部分相关上下文数据都包含在我们算法的输入数据中。

随意改变我的想法(用例子)。

然而，这仍然需要根据人的表现进行评估。但是机器学习的许多应用之所以有趣，正是因为它们可以解决人类无法解决的问题。因此，我认为我们可以更进一步。

# 4.当我们合理地确定神经网络是确定性的，我们提供任何相关的上下文作为输入数据的一部分，并且数据相当小时，神经网络可以解决问题

这里我将回到我最喜欢的一个例子——蛋白质折叠。科学中为数不多的几个问题之一，在这些问题中，数据很容易获得，解释和意义不会被大量的理论包袱所混淆，并且根据我们以前的定义，数据点的大小足够小。你可以把这个问题归结为:

*   大约 2000 个输入特征(三级结构中的氨基酸)，尽管这意味着我们的领域将只覆盖 99.x%的蛋白质，而不是字面上所有的蛋白质。
*   大约 18，000 个相应的输出特征(三级结构中的原子位置数，又名形状，需要预测具有该结构)。

这是一个例子。像大多数 NLP 问题一样,“大小”变得非常主观，我们可以很容易地认为这种类型的输入需要热编码；然后大小突然变成 40000(有 20 个蛋白质氨基酸可以被 DNA 编码)或者 42000(如果你关心硒蛋白，如果你关心真核生物中不出现的小生境蛋白就变成 44000)。

也可以认为，输入和输出的大小要小得多，因为在大多数情况下，蛋白质要小得多，因此我们可以屏蔽和丢弃大多数情况下的大多数输入和输出。尽管如此，从一个 255x255 像素的图像到生成另一个 255x255 像素的图像还有许多任务(样式变换、分辨率增强、样式转换、轮廓映射等)。因此，基于这一点，我认为蛋白质折叠数据相当少，过去几年也是如此。

事实上，通过神经网络的分辨率增强和通过神经网络的蛋白质折叠几乎是同时出现的(请注意，每种架构都是相似的)。但是我跑题了；我把相关性误认为是产生它的因果过程。话又说回来，这是当今大多数自封的“科学”的基础，那么，违背科学方法又算什么呢？

根据我自己对这个问题的研究，似乎即使是一个[非常简单的模型](https://github.com/George3d6/focusfold)，比 VGG 之类的东西简单，也能学到一些关于蛋白质折叠的“有意义”的东西。如果给定足够的(1.35 亿)参数并在 RTX2080 上进行半天的训练，它可以比随机猜测更好，并且经常与原子的实际位置相差 1%。我不能确定准确的准确性，因为对于非领域专家的人来说，这里的准确评估标准显然很难找到和/或理解和/或实现…或者我只是愚蠢，也有很大的可能性。

据我所知，第一个广泛成功的蛋白质折叠网络 [AlphaFold](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery) 虽然使用了一些特定领域的试探法，但却使用了剩余的 CNN，这是一种为图像分类而设计的架构，与蛋白质折叠没有任何关系。

这并不是说任何架构都可以解决这个问题。这意味着我们不需要建立一个全新的技术来处理这类问题。这是一种神经网络可以解决的问题，尽管它可能需要一点时间来寻找可以做到这一点的确切网络。

这里另一个重要的事情是，这个问题似乎是确定性的。即:

*   a)我们知道，在我们大多数模型假设的惰性环境中，肽可以折叠成蛋白质，因为我们一直观察到它们是这样做的。
*   b)我们知道氨基酸是能够完整描述肽的一种成分
*   c)因为我们假设环境总是相同的，并且我们假设折叠过程本身不会改变它，所以问题不是环境的函数(注意，显然在体外折叠的情况下，在体内问题变得更加困难)

问题出现在思考 b)的时候，也就是说，我们知道宇宙可以确定性地折叠肽；我们知道氨基酸足以准确描述一种肽。然而，宇宙并不与“氨基酸”一起工作，它与小得多的粒子之间的万亿次相互作用一起工作。

因此，虽然这个问题是确定性的和独立的，但不能保证学习折叠蛋白质不需要学习一个完整的粒子物理模型，这个模型能够将每个氨基酸分解成更小的功能组件。几百万个参数不足以完成这项任务。

这就是第四个最普通的定义最难应用的原因。

这里的一些其他例子是像[预测维护](https://gallery.azure.ai/Experiment/df7c518dcba7407fb855377339d6589f)这样的事情，机器学习模型[被积极地用于解决人类无法解决的问题](https://sustainability.google/projects/machine-learning/)，至少没有数学模型是不行的。对于这些类型的问题，基于现有的数据，有充分的理由假设这些问题是部分(大部分？)确定性。

这里有更简单的例子，但是我想不出任何一个，在它们出现的时候，不属于前面的三个类别。至少，没有不属于强化学习的。

绝大多数例子都属于强化学习，一旦人们能够模拟它们，就可以解决大量的问题。

人们可以找到最佳的空气动力学形状，设计怪异的天线以提供更有效的接收/覆盖，击败像 DOT 和 [Starcraft](https://www.youtube.com/watch?v=HcZ48JDamyk) 这样比象棋或围棋复杂得多(就自由度而言)的视频游戏。

RL 的问题在于，设计实际的模拟往往比用它来寻找有意义的答案要复杂得多。RL 做起来很有趣，但通常不会产生有用的结果。然而，边缘情况确实存在，设计模拟似乎比从中提取推论更容易。除此之外，基于我们对有效模拟物理的理解，模拟的进步越多(这本身就得到 ML 的帮助)，这样的问题就越多。

# 最后

我试图提供一些简单的启发式方法来回答“什么时候我们应该期待神经网络可以解决问题？”。给定足够的[架构搜索](https://en.wikipedia.org/wiki/Neural_architecture_search)和当前的 GPU 能力，我们的默认假设应该包括哪些问题的可解性？

概括一下，神经网络什么时候能解决你的问题？

1.  [几乎可以肯定]如果其他 ML 模型已经解决了这个问题。
2.  【非常高的概率】如果一个类似的问题已经被一个最大似然算法解决了，而这个问题和你的问题之间的差别似乎并不显著。
3.  [高概率]如果输入和输出足够小，在大小上可以与其他工作的 ML 模型相比，并且如果我们知道除了输入和输出之外，一个人可以用很少的上下文来解决问题。
4.  [合理概率]如果输入和输出足够小，在大小上与其他工作的 ML 模型相当，并且我们对问题的确定性有很高的把握(也就是说，输入足以推断输出)。

我不确定这些规则中的任何一个，但是这回到了能够说一些有意义的事情的问题。PACL 可以给我们几乎完美的确定性，并且在数学上是有效的，但是它不能解决简单的分类问题。

提出这种规则并不能提供一个精确的确定度，它们来自于经验观察。然而，我认为它们实际上可以应用于现实世界的问题。

事实上，在某种程度上，当客户或朋友问我某个问题是否“可行”时，这些就是我应用于现实世界问题的规则。这些似乎非常接近我注意到的其他人在思考什么问题可以解决时使用的规则。

我希望这可以作为该领域新手的实际实践指南，或者对于不想过多参与 ML 本身但有一些数据集需要处理的人。

本文原载于我的博客:[https://blog . cerebral ab . com/When _ to _ assume _ neural _ networks _ can _ solve _ a _ problem](https://blog.cerebralab.com/When_to_assume_neural_networks_can_solve_a_problem)

如果您喜欢这篇文章，您可能也会喜欢:

*   [如果范德瓦尔斯是一个神经网络](https://blog.cerebralab.com/If_Van_der_Waals_was_a_neural_network)
*   [作为无泄漏数学抽象的神经网络](https://blog.cerebralab.com/Neural_networks_as_non-leaky_mathematical_abstraction)
*   [人工通用智能在这里，没用](https://blog.cerebralab.com/Artificial_general_intelligence_is_here,_and_it%27s_useless)