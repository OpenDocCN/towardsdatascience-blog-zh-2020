<html>
<head>
<title>Nested Cross-Validation — Hyperparameter Optimization and Model Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">嵌套交叉验证—超参数优化和模型选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nested-cross-validation-hyperparameter-optimization-and-model-selection-5885d84acda?source=collection_archive---------8-----------------------#2020-09-17">https://towardsdatascience.com/nested-cross-validation-hyperparameter-optimization-and-model-selection-5885d84acda?source=collection_archive---------8-----------------------#2020-09-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0aa2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">深入研究嵌套交叉验证</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7487d469c431dcb095438054f2dc44d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O7lBS4koY-riqrWtUdxqSQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/users/mohamed_hassan-5229782/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3239623" rel="noopener ugc nofollow" target="_blank">穆罕默德·哈桑</a>来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3239623" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="6627" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">交叉验证</strong>也被称为<strong class="lb iu">抽样外技术</strong>是数据科学项目的一个基本要素。这是一个重采样程序，用于<strong class="lb iu">评估机器学习模型</strong>并评估该模型在独立测试数据集上的表现。</p><p id="3e0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">超参数优化或调整</strong>是为机器学习算法选择一组超参数的过程，该算法对特定数据集表现最佳。</p><p id="82a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">交叉验证和超参数优化都是数据科学项目的一个重要方面。交叉验证用于评估机器学习算法的性能，超参数调整用于找到该机器学习算法的最佳超参数集。</p><p id="a146" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">没有嵌套交叉验证的模型选择使用相同的数据来调整模型参数和评估模型性能，这可能导致模型的乐观偏置评估。由于信息泄露，我们对训练或测试数据中的错误估计很差。为了解决这个问题，嵌套交叉验证应运而生。</p><p id="7bd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用支持向量分类器比较虹膜数据集的非嵌套和嵌套 CV 策略的性能。你可以观察下面的性能图，从<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/0fb011a5137cdcbd9b25b3c78f2d91f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*cIVZED_3gsith4Dr24GBCw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html" rel="noopener ugc nofollow" target="_blank">来源</a>:sci kit-了解嵌套与非嵌套交叉验证</p></figure><h1 id="dc3e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">什么是嵌套交叉验证及其实现？</h1><p id="95dd" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><strong class="lb iu">嵌套交叉验证</strong> ( <strong class="lb iu"> Nested-CV </strong>)嵌套交叉验证和超参数调整。它用于评估机器学习算法的性能，还用于估计底层模型及其超参数搜索的泛化误差。</p><p id="afe4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了嵌套循环外，还有几种循环策略，阅读下面提到的文章以了解更多关于不同循环程序的信息。</p><div class="mt mu gp gr mv mw"><a rel="noopener follow" target="_blank" href="/understanding-8-types-of-cross-validation-80c935a4976d"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd iu gy z fp nb fr fs nc fu fw is bi translated">了解 8 种交叉验证</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">交叉验证及其类型的深入解释</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">towardsdatascience.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk ks mw"/></div></div></a></div></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><h2 id="a61c" class="ns lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">第 1 步:列车测试分离:</h2><p id="4036" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">将给定的预处理数据集分割成<strong class="lb iu">训练</strong>和<strong class="lb iu">测试</strong>数据，训练数据可用于训练模型，测试数据被隔离以评估最终模型的性能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/67cb38214694884495c2ed2e9890a3ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*DI-x5fkmklETZGJ5BP2CRA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，将数据分为训练和测试数据</p></figure><p id="62ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这不是一个强制步骤，整个数据可以用作训练数据。将数据分为训练数据和测试数据对于观察未知测试数据的模型性能至关重要。用测试数据评估最终模型表明了该模型对于未来未知点的性能。</p><h2 id="1914" class="ns lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">第二步:外部简历:</h2><p id="7c00" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">基于机器学习算法在嵌套交叉验证的外环上的性能来选择机器学习算法。<strong class="lb iu"> k 倍</strong>交叉验证或<strong class="lb iu"> StaratifiedKfold </strong>过程可以根据数据的不平衡性在外环实现，将数据平均分成 k 倍或组。</p><ul class=""><li id="5a8f" class="of og it lb b lc ld lf lg li oh lm oi lq oj lu ok ol om on bi translated"><strong class="lb iu"> k 倍 CV: </strong>此程序将数据分割成 k 倍或组。(k-1)组将被分配用于培训，其余组用于验证数据。对 k 个步骤重复该步骤，直到所有组都参与了验证数据。</li><li id="2675" class="of og it lb b lc oo lf op li oq lm or lq os lu ok ol om on bi translated"><strong class="lb iu"> StatifiedKfold CV: </strong>该程序类似于 k-fold CV。这里，数据集被划分成 k 个组或折叠，使得验证和训练数据具有相同数量的目标类标签实例。这确保了一个特定的类不会过度出现在验证或训练数据中，尤其是当数据集不平衡时。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/ce1dc9e0ba702f95165a46ed199b1b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-TM7PluKWcD-ccAmy1_r-w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd ou">左:</strong> k-fold 交叉验证，<strong class="bd ou">右:</strong>分层 k-fold 交叉验证，每个 fold 都有相同的目标类实例</p></figure><p id="d586" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据数据集的不平衡程度，可以为外部 CV 选择 k-fold 或 Stratifiedkfold CV。</p><h2 id="61fa" class="ns lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">第三步:内部简历:</h2><p id="6488" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">然后，将内部 CV 应用于来自外部 CV 的(k-1)个折叠或组数据集。使用 GridSearch 优化参数集，然后用于配置模型。然后使用最后一个折叠或组来评估从 GridSearchCV 或 RandomSearchCV 返回的最佳模型。该方法重复 k 次，通过取所有 k 个分数的平均值来计算最终 CV 分数。</p><h2 id="69e8" class="ns lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">步骤 4:调整超参数:</h2><p id="8495" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Scikit-learn 包提供了<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank"> GridSearchCV </a>和<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html" rel="noopener ugc nofollow" target="_blank">randomsearccv</a>实现。这些搜索技术通过调整给定的参数返回最佳的机器学习模型。</p><h2 id="108b" class="ns lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">第五步:拟合最终模型:</h2><p id="3aa6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在，您已经有了最佳模型和一组超参数，它们对该数据集表现最佳。您可以针对看不见的测试数据评估模型的性能。</p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><h1 id="6694" class="lw lx it bd ly lz ov mb mc md ow mf mg jz ox ka mi kc oy kd mk kf oz kg mm mn bi translated">Python 实现:</h1><blockquote class="pa pb pc"><p id="e31a" class="kz la pd lb b lc ld ju le lf lg jx lh pe lj lk ll pf ln lo lp pg lr ls lt lu im bi translated">信用卡欺诈数据集用于从<a class="ae ky" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载的以下实现中。</p></blockquote><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><h2 id="a72f" class="ns lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">嵌套 CV 的成本:</h2><p id="a52c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">使用 Nested-CV 极大地增加了模型的训练和评估。如果为非嵌套 CV 训练 n*k 个模型，那么要训练的模型的数量增加到 k*n*k</p><h1 id="9c9e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论:</h1><p id="9d61" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">当同一个数据集用于使用 CV 调整和选择模型时，很可能会导致对模型性能的乐观偏见评估。因此，嵌套 CV 比非嵌套 CV 更常用，因为它有助于克服偏差。</p><p id="7b04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 nested-CV 极大地增加了模型评估的数量，从而增加了时间复杂度。当数据集太大或者您的系统功能不强大时，不建议使用它。</p><blockquote class="pj"><p id="7463" class="pk pl it bd pm pn po pp pq pr ps lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>