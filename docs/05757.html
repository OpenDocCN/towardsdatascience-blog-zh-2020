<html>
<head>
<title>Multiple Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多元线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b?source=collection_archive---------4-----------------------#2020-05-13">https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b?source=collection_archive---------4-----------------------#2020-05-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4344" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个完整的研究—模型解释→假设检验→特征选择</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6465857f395c46ecfe4aa8376c65a52f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*e8DeRYfcUtMuJ_Jt"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@steve_j?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯蒂夫·约翰森</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="d081" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性回归是最受欢迎和讨论最多的模型之一，当然是深入机器学习(ML)的门户。这种简单、直接的建模方法值得作为您进入ML的第一步来学习。</p><p id="feba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在继续之前，让我们回忆一下，线性回归可以大致分为两类。</p><ul class=""><li id="77ea" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">简单线性回归</strong>:这是线性回归的最简单形式，当输出变量只有一个输入变量时使用。</li></ul><p id="900e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你是回归的新手，那么我强烈建议你首先从下面的链接中阅读简单的线性回归，在那里你会理解背后的数学原理以及使用有趣的数据和亲自动手编码的方法。</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/simple-linear-regression-35b3d940950e"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">简单线性回归</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">关于简单线性回归你需要知道的一切</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv ks mh"/></div></div></a></div><ul class=""><li id="ae02" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">多元线性回归:</strong>是线性回归的一种形式<strong class="lb iu"> </strong>，当有两个或两个以上的预测因子时使用。</li></ul><p id="1658" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将看到多个输入变量如何一起影响输出变量，同时也了解计算如何不同于简单的LR模型。我们还将使用Python构建一个回归模型。</p><p id="ee86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们将更深入地学习线性回归，并将学习诸如共线性、假设检验、特征选择等等。</p><p id="ab40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在有人可能会想，我们也可以使用简单的线性回归来分别研究所有独立变量的输出。那会让生活变得容易得多，对吗？</p><p id="aa8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不，不会的。</p><h2 id="3325" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">为什么要多元线性回归？</h2><p id="6771" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">“从多个输入变量中预测结果。咄！”。但是，就这样吗？好吧，保持这种想法。</p><p id="e8d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑一下这个，假设你要估算你想买的某套房子的价格。你知道建筑面积，房子的年龄，离你工作地点的距离，这个地方的犯罪率等等。</p><p id="2f21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，这些因素中的一些会积极地影响房价。例如面积越大，价格越高。另一方面，距离工作场所的距离和犯罪率等因素会对你对房子的估计产生负面影响(除非你是一个对机器学习感兴趣的有钱罪犯，正在寻找藏身之处，是的，我不这么认为)。</p><p id="659d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nu">简单线性回归的缺点</em> →当我们只对一个感兴趣时，运行单独的简单线性回归会导致不同的结果。除此之外，可能还有一个输入变量本身与其他一些预测因素相关或依赖于其他一些预测因素。这会导致错误的预测和不令人满意的结果。</p><p id="a2d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是多元线性回归发挥作用的地方。</p><h2 id="6518" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">数学上…</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/8bc1646cae77949125e012652cd6cff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*uAZtCWSJIWoWhSCyGpHnng.png"/></div></figure><p id="c8ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，<strong class="lb iu"> <em class="nu"> Y </em> </strong>为输出变量，<strong class="lb iu"> <em class="nu"> X </em> </strong>项为对应的输入变量。注意，这个方程只是简单线性回归的扩展，每个预测因子都有一个对应的斜率系数(<strong class="lb iu"><em class="nu">【β】</em></strong>)。</p><p id="ec3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一个<em class="nu"> β </em>项(<em class="nu"> βo </em>)是截距常数，是没有所有预测值时<em class="nu"> Y </em>的值(即当所有<em class="nu"> X </em>项都为0时)。在给定的回归问题中，它可能有意义，也可能没有意义。它通常在那里给回归的线/平面一个相关的推动。</p><p id="16d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们借助一些数据来理解这一点。</p><h2 id="e8a8" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">可视化数据</h2><p id="2355" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">我们将使用南加州大学马歇尔商学院网站上的广告数据。你可以在这里下载<a class="ae ky" href="http://faculty.marshall.usc.edu/gareth-james/ISL/Advertising.csv" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="530c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你看过我关于<a class="ae ky" rel="noopener" target="_blank" href="/simple-linear-regression-35b3d940950e">简单线性回归</a>的帖子，那么你对这个数据已经很熟悉了。如果你没有，让我给你一个简短的介绍。</p><p id="1b1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">广告数据集包括一种产品在200个不同市场的销售额，以及三种不同媒体的广告预算:电视、广播和报纸。它看起来是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/77b1566456ce2544000716b8c5b8b2ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/0*Jbv-qX83IyAMVPYD.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">销售额(*1000台)与广告预算(*1000美元)</p></figure><p id="e8ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据的第一行表示电视、广播和报纸的广告预算分别为230.1k美元、37.8k美元和69.2k美元，相应的售出数量为22.1k(或22，100)。</p><p id="252b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在简单的线性回归中，我们可以看到在没有其他两种媒体的情况下，每种广告媒体是如何影响销售的。然而，在实践中，这三者可能会共同影响净销售额。我们没有考虑这些媒体对销售的综合影响。</p><p id="0965" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">多元线性回归通过在一个表达式中考虑所有变量来解决这个问题。因此，我们的线性回归模型现在可以表示为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/4e856fc45206e86109f12794a0a61299.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*v6RLfzTXXqmpvEUoNuOFCw.png"/></div></figure><p id="78d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">求这些常数的值(<em class="nu">β</em>)<strong class="lb iu">)</strong>就是回归模型通过最小化误差函数，拟合最佳直线或超平面(取决于输入变量的数量)所做的事情。</p><p id="0364" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是通过最小化<a class="ae ky" rel="noopener" target="_blank" href="/simple-linear-regression-35b3d940950e/#32ff">残差平方和</a> (RSS)来实现的，残差平方和是通过对实际结果和预测结果之间的差求平方来获得的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ebabf383ae3f25bcf1d043f29011a594.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*RixUmCeCe2xq8U-K.png"/></div></figure><h2 id="165c" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">普通最小二乘法</h2><p id="995c" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">因为这种方法求最小平方和，所以也被称为普通最小二乘法(OLS法)。在Python中，有两种实现OLS算法的主要方法。</p><ul class=""><li id="f066" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> SciKit Learn: </strong>只需从Sklearn包中导入线性回归模块，并在数据上拟合模型。这个方法非常简单，你可以在下面看到如何使用它。</li></ul><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="cc96" class="mw mx it oa b gy oe of l og oh">from sklearn.linear_model import LinearRegression</span><span id="8925" class="mw mx it oa b gy oi of l og oh">model = LinearRegression()<br/>model.fit(data.drop('sales', axis=1), data.sales)</span></pre><ul class=""><li id="7449" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> StatsModels: </strong>另一种方法是使用StatsModels包来实现OLS。Statsmodels是一个Python包，允许对数据执行各种统计测试。我们将在这里使用它，以便您可以了解这个伟大的Python库，因为它将在后面的章节中对我们有所帮助。</li></ul><h2 id="76a5" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">建立模型并解释系数</h2><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="cb15" class="mw mx it oa b gy oe of l og oh"><strong class="oa iu"># Importing required libraries<br/></strong>import pandas as pd<strong class="oa iu"><br/></strong>import statsmodels.formula.api as sm</span><span id="7eed" class="mw mx it oa b gy oi of l og oh"><strong class="oa iu"># Loading data - You can give the complete path to your data here</strong><br/>ad = pd.read_csv("Advertising.csv")</span><span id="fa24" class="mw mx it oa b gy oi of l og oh"><strong class="oa iu"># Fitting the OLS on data</strong><br/>model = sm.ols('sales ~ TV + radio + newspaper', ad).fit()<br/>print(model.params)</span></pre><p id="0497" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您应该得到以下输出。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="b052" class="mw mx it oa b gy oe of l og oh">Intercept    2.938889<br/>TV           0.045765<br/>radio        0.188530<br/>newspaper   -0.001037</span></pre><p id="c41f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我鼓励您也使用Scikit Learn运行回归模型，并使用<em class="nu">model . coef _</em>&amp;<em class="nu">model . intercept _找到上述参数。</em>你看到了同样的结果吗？</p><p id="e18f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然有了这些价值观，又该如何解读呢？方法如下:</p><ul class=""><li id="ee5f" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">如果我们固定电视和报纸的预算，那么增加1000美元的广播预算将导致销售额增加约189台(0.189*1000)。</li><li id="a95a" class="lv lw it lb b lc oj lf ok li ol lm om lq on lu ma mb mc md bi translated">类似地，通过修正广播和报纸，我们推断电视预算每增加1000美元，大约会增加46个产品单位。</li><li id="b3dd" class="lv lw it lb b lc oj lf ok li ol lm om lq on lu ma mb mc md bi translated">然而，对于报纸预算来说，由于这个系数可以忽略不计(接近于零)，很明显报纸没有影响销售。事实上，它在零的负侧(-0.001)，如果幅度足够大，可能意味着该代理导致销售下降。但是我们不能用如此微不足道的价值来做这样的推论。</li></ul><p id="0f0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在这里告诉你一件有趣的事。如果我们运行<a class="ae ky" rel="noopener" target="_blank" href="/simple-linear-regression-35b3d940950e">简单线性回归</a>，仅使用报纸预算对比销售额，我们将观察到约为0.055的系数值，这与我们在上面看到的相比非常显著。这是为什么呢？</p><h2 id="46a3" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">共线性</h2><p id="8198" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">为了理解这一点，让我们看看这些变量是如何相互关联的。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="d7a1" class="mw mx it oa b gy oe of l og oh">ad.corr()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/900a5717e225ed44e9034e538cdea34f.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*aszadBMBbt1BBquLkhdRqQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">广告数据的相关矩阵</p></figure><p id="ce82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用热图来形象化这些数字。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="e385" class="mw mx it oa b gy oe of l og oh">import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="1970" class="mw mx it oa b gy oi of l og oh">&gt; plt.imshow(ad.corr(), cmap=plt.cm.GnBu,        interpolation='nearest',data=True)<br/>&gt; plt.colorbar()<br/>&gt; tick_marks = [i for i in range(len(ad.columns))]<br/>&gt; plt.xticks(tick_marks, data.columns, rotation=45)<br/>&gt; plt.yticks(tick_marks, data.columns, rotation=45)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/c7e139022645d7796836c8b548743a54.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*YwCpqGREOPOUzUIqZDFz1w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">广告数据的关联热图</p></figure><p id="4d70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，深色方块代表强相关性(接近1)，而浅色方块代表弱相关性(接近0)。就是这个原因，所有的对角线都是深蓝色的，作为一个变量与自身完全相关。</p><p id="5477" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里值得注意的是报纸和广播的相关性是0.35。这表明了报纸和广播预算之间的公平关系。因此，可以推断出，当一种产品的广播预算增加时，也有在报纸上花更多钱的趋势。</p><p id="989b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这被称为<strong class="lb iu"> <em class="nu">共线性</em> </strong>，是指两个或多个输入变量线性相关的情况。</p><p id="e1fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，即使多元回归模型显示对报纸的销售没有影响，简单回归模型仍然有影响，因为多重共线性和其他输入变量的缺乏。</p><blockquote class="oq"><p id="5d71" class="or os it bd ot ou ov ow ox oy oz lu dk translated">销售和广播→可能的原因</p><p id="9d86" class="or os it bd ot ou ov ow ox oy oz lu dk translated">报纸和广播→多重共线性</p><p id="33cd" class="or os it bd ot ou ov ow ox oy oz lu dk translated">销售和报纸→传递相关性</p></blockquote><p id="a342" class="pw-post-body-paragraph kz la it lb b lc pa ju le lf pb jx lh li pc lk ll lm pd lo lp lq pe ls lt lu im bi translated">好吧！我们理解线性回归，我们建立模型，甚至解释结果。到目前为止，我们所学的是线性回归的基础。然而，在处理现实世界的问题时，我们通常会超越这一点，对我们的模型进行统计分析，并在需要时进行必要的更改。</p><h2 id="bedc" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">预测值的假设检验</h2><p id="256b" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">运行多元线性回归时应该回答的一个基本问题是，<em class="nu">是否至少有一个预测因子对预测输出有用。</em></p><p id="ceb3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到电视、广播和报纸这三个预测因素与销售有不同程度的线性关系。但是，如果这种关系只是偶然的，并且由于任何预测因素而对销售没有实际影响，那该怎么办呢？</p><p id="8a62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型只能给我们一些数字，以便在响应变量和预测变量之间建立足够密切的线性关系。但是，它不能证明这些关系的可信度。</p><p id="a5fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了获得一些信心，我们从统计学中获得帮助，做一些被称为<strong class="lb iu"> <em class="nu">假设检验的事情。</em> </strong>我们首先形成一个<strong class="lb iu"> <em class="nu">零假设</em> </strong>和一个相应的<strong class="lb iu"> <em class="nu">替代假设</em> </strong>。</p><p id="2e98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们的目标是找出是否至少有一个预测因子对预测输出有用，所以我们希望至少有一个系数(不是截距)非零，这不仅仅是随机的，而是由于实际原因。</p><p id="108a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了做到这一点，我们首先形成一个零假设:所有的系数都等于零。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/8ba638447ef73e6baf122f786664a1ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*z5ji08h4nzy9-VJAzVj42g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多元线性回归的一般零假设</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/1474bbfe9991b22613a657f03a94b9de.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*WhAD3egiuZA80bXSP5JZpQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">广告数据的零假设</p></figure><p id="56c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，另一个假设是:至少有一个系数不为零。通过寻找强有力的统计证据来拒绝零假设，从而证明了这一点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/eb85355c813f78abaa098b4bdf34bae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*1wWoCXX4i3lyqA3VG4uICg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">替代假设</p></figure><p id="adcd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<strong class="lb iu"> <em class="nu"> F统计量进行假设检验。</em> </strong>这个统计量的公式包含残差平方和(RSS)和总平方和(TSS)，我们不必担心，因为Statsmodels包会处理这些。上面我们拟合的OLS模型摘要包含了所有此类统计信息的摘要，可以通过下面简单的代码行获得:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="343e" class="mw mx it oa b gy oe of l og oh">print(model.summary2())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/b598f2c76e7663fe1b8fc11b638a4ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*ygowbH3BaNaWR1MZ10oMmA.png"/></div></figure><p id="3268" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nu">如果F统计量的值等于或非常接近1，那么结果是有利于零假设的，我们无法拒绝它。</em></p><p id="bab6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是正如我们可以看到的，F统计量比1大很多倍，因此提供了反对零假设(所有系数都为零)的有力证据。因此，我们拒绝零假设，并且确信至少有一个预测因子在预测输出时是有用的。</p><blockquote class="pi pj pk"><p id="3baf" class="kz la nu lb b lc ld ju le lf lg jx lh pl lj lk ll pm ln lo lp pn lr ls lt lu im bi translated">注意，当预测值(<em class="it"> p </em>)的数量很大时，或者如果<em class="it"> p </em>大于数据样本的数量(<em class="it"> n </em>)时，F统计量不适用。</p></blockquote><p id="1896" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们可以说，三个广告代理商中至少有一个对预测销售是有用的。</p><p id="e00c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是哪一个或者哪两个重要呢？它们都很重要吗？为此，我们将执行<strong class="lb iu"> <em class="nu">特征选择或变量选择。</em> </strong>现在，一种方法是尝试所有可能的组合，即</p><ul class=""><li id="eef1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">只有电视</li><li id="2cd4" class="lv lw it lb b lc oj lf ok li ol lm om lq on lu ma mb mc md bi translated">只有收音机</li><li id="8793" class="lv lw it lb b lc oj lf ok li ol lm om lq on lu ma mb mc md bi translated">只有报纸</li><li id="a355" class="lv lw it lb b lc oj lf ok li ol lm om lq on lu ma mb mc md bi translated">电视和广播</li><li id="52fb" class="lv lw it lb b lc oj lf ok li ol lm om lq on lu ma mb mc md bi translated">电视和报纸</li><li id="4d5b" class="lv lw it lb b lc oj lf ok li ol lm om lq on lu ma mb mc md bi translated">广播和报纸</li><li id="a56e" class="lv lw it lb b lc oj lf ok li ol lm om lq on lu ma mb mc md bi translated">电视、广播和报纸</li></ul><p id="613b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，尝试所有7种组合看起来仍然可行，但如果有更多的预测因素，组合的数量将呈指数增长。例如，在我们的案例研究中只增加一个预测因子，总的组合将变成15个。想象一下有十几个预测者。</p><p id="20e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们需要更有效的方法来执行特征选择。</p><h2 id="71b4" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">特征选择</h2><p id="2049" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">进行特征选择的两种最流行的方法是:</p><ul class=""><li id="0952" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">正向选择:</strong>我们从一个没有任何预测器，只有截距项的模型开始。然后，我们对每个预测值进行简单的线性回归，以找到最佳表现(最低RSS)。然后，我们向它添加另一个变量，并通过计算最低RSS(残差平方和)再次检查最佳的2变量组合。之后，检查最佳的三变量组合，依此类推。当满足某个停止规则时，停止该方法。</li><li id="5b99" class="lv lw it lb b lc oj lf ok li ol lm om lq on lu ma mb mc md bi translated"><strong class="lb iu">反向选择:</strong>我们从模型中的所有变量开始，去掉统计意义最小的变量(更大的p值:查看上面的模型摘要，找出变量的p值)。重复这一过程，直到达到停止规则。例如，当模型分数没有进一步提高时，我们可以停止。</li></ul><p id="6c6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将带你了解正向选择方法。首先，让我们了解如何选择或拒绝添加的变量。</p><p id="1668" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在每次添加之后，我们将使用2个度量来评估我们的新模型:<strong class="lb iu"> RSS </strong>和<strong class="lb iu"> R </strong>。</p><p id="6bb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经熟悉了RSS，它是残差平方和，通过对实际输出和预测结果之间的差值求平方来计算。这应该是模型性能良好的最低要求。</p><p id="7e29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">r是模型解释数据差异的程度的量度。从数学上讲，它是实际结果和预测结果之间相关性的平方。r接近1表明模型是好的，并且很好地解释了数据中的差异。接近零的值表示模型不佳。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/0bbc107b3af0e0eb4acabd7c786305b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*q2H6CRgawEBAb-WU6XniIw.png"/></div></figure><p id="2bfe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，它是由Statsmodels中的OLS模块为我们计算出来的。让我们开始吧。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="a3a9" class="mw mx it oa b gy oe of l og oh"><strong class="oa iu"># Defining a function to evaluate a model</strong><br/>def evaluateModel(model):<br/>    print("RSS = ", ((ad.sales - model.predict())**2).sum())<br/>    print("R2 = ", model.rsquared)</span></pre><p id="0da2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们先从电视开始，一个一个的评估单个预测器的模型。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="387e" class="mw mx it oa b gy oe of l og oh"><strong class="oa iu"># For TV</strong><br/>model_TV = sm.ols('sales ~ TV', ad).fit()<br/>evaluateModel(model_TV)</span></pre><blockquote class="pi pj pk"><p id="0bbc" class="kz la nu lb b lc ld ju le lf lg jx lh pl lj lk ll pm ln lo lp pn lr ls lt lu im bi translated">r^2 = 0.605831313512<br/>19986.866686666667</p></blockquote><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="7dc2" class="mw mx it oa b gy oe of l og oh"><strong class="oa iu"># For radio</strong><br/>model_radio = sm.ols('sales ~ radio', ad).fit()<br/>evaluateModel(model_radio)</span></pre><blockquote class="pi pj pk"><p id="5cff" class="kz la nu lb b lc ld ju le lf lg jx lh pl lj lk ll pm ln lo lp pn lr ls lt lu im bi translated">r^2 = 0。46860 . 86686868686</p></blockquote><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="5f30" class="mw mx it oa b gy oe of l og oh"><strong class="oa iu"># For newspaper</strong><br/>model_newspaper = sm.ols('sales ~ newspaper', ad).fit()<br/>evaluateModel(model_newspaper)</span></pre><blockquote class="pi pj pk"><p id="000d" class="kz la nu lb b lc ld ju le lf lg jx lh pl lj lk ll pm ln lo lp pn lr ls lt lu im bi translated">r^2 = 0.00000000001</p></blockquote><p id="1ebe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们发现，在所有模型中，model_TV的RSS最小，R值最大。因此，我们选择model_TV作为我们前进的基础模型。</p><p id="875b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们将逐个添加收音机和报纸，并检查新值。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="5d04" class="mw mx it oa b gy oe of l og oh"><strong class="oa iu"># For TV &amp; radio<br/></strong>model_TV_radio = sm.ols('sales ~ TV + radio', ad).fit()<br/>evaluateModel(model_TV_radio)</span></pre><blockquote class="pi pj pk"><p id="c96d" class="kz la nu lb b lc ld ju le lf lg jx lh pl lj lk ll pm ln lo lp pn lr ls lt lu im bi translated">rss =，76184。18667 . 868686868667</p></blockquote><p id="bb7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，我们的价值观有了巨大的提高。与model_TV相比，RSS下降，R进一步增加。这是个好兆头。现在让我们看看电视和报纸也是如此。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="7760" class="mw mx it oa b gy oe of l og oh"><strong class="oa iu"># For TV &amp; newspaper<br/></strong>model_TV_radio = sm.ols('sales ~ TV + newspaper', ad).fit()<br/>evaluateModel(model_TV_newspaper)</span></pre><blockquote class="pi pj pk"><p id="d08e" class="kz la nu lb b lc ld ju le lf lg jx lh pl lj lk ll pm ln lo lp pn lr ls lt lu im bi translated">r^2 = 0。19860 . 9868275。19867 . 888686868667</p></blockquote><p id="e7c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过增加报纸，价值也有所提高，但没有收音机提高得多。因此，在这一步，我们将继续使用电视和广播模型，并在将报纸添加到该模型时观察差异。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="c58a" class="mw mx it oa b gy oe of l og oh"><strong class="oa iu"># For TV, radio &amp; newspaper<br/></strong>model_all = sm.ols('sales ~ TV + radio + newspaper', ad).fit()<br/>evaluateModel(model_all)</span></pre><blockquote class="pi pj pk"><p id="be23" class="kz la nu lb b lc ld ju le lf lg jx lh pl lj lk ll pm ln lo lp pn lr ls lt lu im bi translated">r^2 = 0。18960 . 866868686867</p></blockquote><p id="4ffe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些值没有任何显著的提高。因此，当务之急是不要添加报纸，并最终确定以电视和广播为选择功能的模式。</p><p id="c379" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们的最终模型可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/56441a4b84b909376e79fab23c948272.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*KsGpQMnJXTcGpb7jJN1OQg.png"/></div></figure><p id="ffa7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在3D图中绘制变量TV、radio和sales，我们可以直观地看到我们的模型如何将回归平面拟合到数据中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/4ee0c0fca54524bf510cad0f9a2f829c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pC6blleQsgvR0wVVs1rMKA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd pr"> 3D绘图了解回归平面</strong>。图片由<a class="ps pt ep" href="https://medium.com/u/db3258338f2f?source=post_page-----8cf3bee21d8b--------------------------------" rel="noopener" target="_blank"> Sangeet Aggarwal </a>提供</p></figure><p id="ee29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">多元线性回归就是这样。你可以在这里找到这篇文章<a class="ae ky" href="https://github.com/datasciencewithsan/Multiple-Linear-Regression" rel="noopener ugc nofollow" target="_blank">后面的完整代码。我希望你在阅读和学习中过得愉快。欲知详情，敬请关注。</a></p></div><div class="ab cl pu pv hx pw" role="separator"><span class="px bw bk py pz qa"/><span class="px bw bk py pz qa"/><span class="px bw bk py pz"/></div><div class="im in io ip iq"><p id="871a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你是数据科学和机器学习的新手，不知道从哪里开始你的旅程，请查看下面的链接，在那里我提到了学习数据科学的一步一步的方法，有很多资源可供你选择。</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/data-science-from-scratch-4343d63c1c66"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">从零开始的数据科学</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">作为一个完全的初学者如何步入数据科学</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="qb l ms mt mu mq mv ks mh"/></div></div></a></div><p id="335e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">等不及了？如果你想一头扎进一门课程，请点击下面的<a class="ae ky" href="https://www.datacamp.com/?tap_a=5644-dce66f&amp;tap_s=910084-843f05&amp;utm_medium=affiliate&amp;utm_source=sangeetaggarwal" rel="noopener ugc nofollow" target="_blank">链接</a>查看适合你的数据科学职业轨迹。</p><div class="me mf gp gr mg mh"><a href="https://www.datacamp.com/?tap_a=5644-dce66f&amp;tap_s=910084-843f05&amp;utm_medium=affiliate&amp;utm_source=sangeetaggarwal" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">在线学习R、Python和数据科学</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">使用DataCamp的视频教程&amp;编码，按照您自己的步调，在您的浏览器中舒适地学习数据科学</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">www.datacamp.com</p></div></div><div class="mq l"><div class="qc l ms mt mu mq mv ks mh"/></div></div></a></div></div></div>    
</body>
</html>