<html>
<head>
<title>Decision Tree</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策图表</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decision-tree-ba64f977f7c3?source=collection_archive---------30-----------------------#2020-06-08">https://towardsdatascience.com/decision-tree-ba64f977f7c3?source=collection_archive---------30-----------------------#2020-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="854c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的日常生活中，我们与各种机器学习应用程序进行交互，并在不知不觉中使用它。最好的例子是从任何一个在线购物门户购买东西，在那里我们可以根据我们购买的东西得到几个推荐。</p><p id="e2be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一种类型的机器学习算法是决策树，它是监督分类下的一种分类算法。</p><p id="952d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">决策树是我们可能有意或无意使用过的东西。考虑一下买车的情况。我们会在考虑预算、安全性、颜色和价格等各种因素后选择汽车。我们首先检查了低于 X 的价格，然后是颜色，最后是安全性，然后得出了一个结论。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/9ca40597d1c4c3fd24a99f33fb5b1027.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*zKQR9FYEZm7Ud6vfL3tUyg.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</p></figure><p id="0a22" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">查看上图，我们可以定义<strong class="jp ir"> <em class="kx">决策树</em> </strong>是一个树形图的图形表示，用于确定行动过程。树的每个分支代表一个决定。</p><p id="6513" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kx">决策树能解决的问题？</em> </strong></p><p id="d849" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它可以解决两类问题。</p><ol class=""><li id="fb66" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">分类:根据 if-then 条件进行分类。如果一种花的颜色是红色，那么它就是玫瑰色，如果是白色，那么它就是百合色。</li><li id="b1bb" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">回归:有连续数据时使用回归树。</li></ol><p id="7da6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kx">决策树的优势</em> </strong></p><ol class=""><li id="ba95" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">简单易懂。</li><li id="5c51" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">在数据准备方面很少努力。</li><li id="58ad" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">非线性参数不影响性能。</li></ol><p id="6114" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kx">缺点:</em> </strong></p><ol class=""><li id="91be" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">过拟合:在数据中有噪声的情况下。</li><li id="4245" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">不稳定性:由于数据的变化，模型可能变得不稳定。</li></ol><p id="2bfb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kx">决策树中使用的重要术语。</em>T19】</strong></p><ol class=""><li id="f37d" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">熵:它是对数据集中不可预测性的度量。例如，我们有一桶水果。这里所有的东西都是混合的，因此它的熵非常高。</li><li id="bb52" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">信息增益:熵值降低了。例如，如果我们有一桶 5 种不同的水果。如果所有信息都保存在一个地方，那么获得的信息是最少的。但是如果我们将所有 5 种水果分开，我们会看到熵最小，因为它没有混合，而获得的信息最大。</li><li id="ba99" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">叶节点:它是承载信息的决策树的末端。在上图中，我们可以说“购买”是叶节点。</li><li id="1f6f" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">决策节点:它是决策树的中间节点，在这里出现两个或更多新的分裂。在上图中，颜色是一个决策节点，因为它进一步分裂为红色和蓝色。</li><li id="2111" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">根节点:它是图中最顶层的节点，所有的信息都存储在这里，或者具有最高的熵。在图中，“汽车”是根节点。</li></ol><p id="88ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如前所述，决策树可用于两种情况。让我们检查一下回归环境中的使用情况。</p><p id="1c15" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kx">决策树:回归</em> </strong></p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="a2da" class="lr ls iq ln b gy lt lu l lv lw">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>df = pd.read_csv("../input/automobileEDA.csv")<br/>df.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/24bf194809e40faa8b4dbc0a9727085f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*ETt-T0H5wyCSiS-yf7vuow.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</p></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/f5d2f26dbcc7fb539f28038ff212a30b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*OFfShFbl6vNO4wsJp_H6Dw.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</p></figure><p id="2431" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">df.head()将给出每一列的前 5 行的详细信息。我们可以使用 df.tail()获得最后 5 行，类似地，使用 df.head(10)获得前 10 行。</p><p id="2be5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据是关于汽车的，我们需要使用上面的数据来预测汽车的价格</p><p id="2194" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用决策树来预测汽车的价格。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="a6f2" class="lr ls iq ln b gy lt lu l lv lw">df.dtypes</span></pre><p id="e810" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出局:</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="9306" class="lr ls iq ln b gy lt lu l lv lw">symboling              int64<br/>normalized-losses      int64<br/>make                  object<br/>aspiration            object<br/>num-of-doors          object<br/>body-style            object<br/>drive-wheels          object<br/>engine-location       object<br/>wheel-base           float64<br/>length               float64<br/>width                float64<br/>height               float64<br/>curb-weight            int64<br/>engine-type           object<br/>num-of-cylinders      object<br/>engine-size            int64<br/>fuel-system           object<br/>bore                 float64<br/>stroke               float64<br/>compression-ratio    float64<br/>horsepower           float64<br/>peak-rpm             float64<br/>city-mpg               int64<br/>highway-mpg            int64<br/>price                float64<br/>city-L/100km         float64<br/>horsepower-binned     object<br/>diesel                 int64<br/>gas                    int64<br/>dtype: object</span></pre><p id="c2b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">dtypes 给出列的数据类型。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="c63e" class="lr ls iq ln b gy lt lu l lv lw">df.describe()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/469cdee068f34083ed11783fbe342539.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*OrDwBMFKOJbD2cx_nfBpkQ.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</p></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/ae5bacf0f8495123d91927d3eb50f5fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*A-0eGRbGUrBP9cgUyMViGg.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</p></figure><p id="551f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在上面的数据框中，列数据类型是 object、float 和 int64 的混合。因此，我们将只考虑那些数值为数字的列，并使所有的数字都浮动。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="923c" class="lr ls iq ln b gy lt lu l lv lw">df.dtypes<br/>for x <strong class="ln ir">in</strong> df:<br/>    if df[x].dtypes == "int64":<br/>        df[x] = df[x].astype(float)<br/>        print (df[x].dtypes)</span><span id="3976" class="lr ls iq ln b gy ma lu l lv lw">float64<br/>float64<br/>float64<br/>float64<br/>float64<br/>float64<br/>float64<br/>float64</span></pre><p id="fddf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准备数据。</strong></p><p id="a5d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与分类任务一样，在本节中，我们将把数据划分为属性和标签，从而划分为训练集和测试集。我们将创建 2 个数据集，一个用于价格，另一个用于(df-price)。由于我们的数据框包含大量对象格式的数据，因此在本次分析中，我们将移除所有对象类型的列，对于所有 NaN 值，我们将移除该行。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="3d0c" class="lr ls iq ln b gy lt lu l lv lw">df = df.select_dtypes(exclude=['object'])<br/>df=df.fillna(df.mean())<br/>X = df.drop('price',axis=1)<br/>y = df['price']</span></pre><p id="3dca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，X 变量包含数据集中的所有列，除了标签“价格”列。y 变量包含“价格”列中的值，这意味着 X 变量包含属性集，y 变量包含相应的标签。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="2a90" class="lr ls iq ln b gy lt lu l lv lw">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)</span></pre><p id="11f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了训练该算法，我们将使用 DecisionTreeRegressor 类和 fit 方法。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="2362" class="lr ls iq ln b gy lt lu l lv lw">from sklearn.tree import DecisionTreeRegressor<br/>regressor = DecisionTreeRegressor()<br/>regressor.fit(X_train, y_train)</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/c36a439f08553212aeed03ec2cbd347b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*ECyYU3ZmLMNnUXS_oGF_nw.png"/></div></figure><p id="ae84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们来预测一下价格。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="bf7a" class="lr ls iq ln b gy lt lu l lv lw">y_pred = regressor.predict(X_test)</span></pre><p id="7e20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们检查实际值和预测值之间的差异。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="ab22" class="lr ls iq ln b gy lt lu l lv lw">df=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})<br/>df</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/b6b29f11b19831d20f1bba9aaf097f72.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*KSpJnfI7FeoF9oRRQb15ig.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">实际值和预测值</p></figure><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="36d1" class="lr ls iq ln b gy lt lu l lv lw">from sklearn import metrics<br/>print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))<br/>print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))<br/>print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/447006306c78afdb2860981012a3fd96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*E_cAAJrrgr6ck_YLWE-4aw.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</p></figure><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="4595" class="lr ls iq ln b gy lt lu l lv lw">import seaborn as sns<br/>plt.figure(figsize=(5, 7))<br/></span><span id="372a" class="lr ls iq ln b gy ma lu l lv lw">ax = sns.distplot(y, hist=False, color="r", label="Actual Value")<br/>sns.distplot(y_pred, hist=False, color="b", label="Fitted Values" , ax=ax)<br/></span><span id="358a" class="lr ls iq ln b gy ma lu l lv lw">plt.title('Actual vs Fitted Values for Price')<br/>plt.xlabel('Price (in dollars)')<br/>plt.ylabel('Proportion of Cars')</span><span id="c24d" class="lr ls iq ln b gy ma lu l lv lw">plt.show()<br/>plt.close()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi md"><img src="../Images/eaa70320f7590ca420a77ec98b10b809.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*6PCw1i4ZifCgDDHgUqRnIQ.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">实际与预测</p></figure><p id="bb7f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以上是实际值和预测值之间的曲线图。</p><p id="5b7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kx">决策树:分类</em> </strong></p><p id="97d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用决策树分类来预测模型的结果。</p><p id="ab8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们导入所需的库。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="24a9" class="lr ls iq ln b gy lt lu l lv lw">import numpy as np <br/>import pandas as pd<br/>from sklearn.tree import DecisionTreeClassifier</span></pre><p id="3a02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关于数据:</p><p id="c69d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些数据是关于一系列疾病的患者名单。通过该模型，我们将预测应该向患者提供哪种药物。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="7c57" class="lr ls iq ln b gy lt lu l lv lw">df = pd.read_csv("../input/drug200.csv")<br/>df.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi me"><img src="../Images/b524b5a7066e4c83696ec80cadb9c8ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*eUuTi-z9Y6rNz7q2DEfCCg.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</p></figure><p id="84db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">计算数据的大小。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="3b9f" class="lr ls iq ln b gy lt lu l lv lw">np.size(df)</span></pre><p id="c729" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出局:</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="5e16" class="lr ls iq ln b gy lt lu l lv lw">1200</span></pre><p id="b607" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">准备数据</p><p id="235d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将选取一些分析所需的列。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="701c" class="lr ls iq ln b gy lt lu l lv lw">X = df[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values<br/>X[0:5]</span></pre><p id="f5fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出局:</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="8ad2" class="lr ls iq ln b gy lt lu l lv lw">array([[23, 'F', 'HIGH', 'HIGH', 25.355],<br/>       [47, 'M', 'LOW', 'HIGH', 13.093],<br/>       [47, 'M', 'LOW', 'HIGH', 10.113999999999999],<br/>       [28, 'F', 'NORMAL', 'HIGH', 7.797999999999999],<br/>       [61, 'F', 'LOW', 'HIGH', 18.043]], dtype=object)</span></pre><p id="55d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在上面的数组中，数据集中的一些值不是数值，例如性别或 BP。不幸的是，Sklean 决策树不能处理这些变量。因此，我们需要将其转换成数字。pandas.get_dummies()将非数字变量转换为虚拟/指示变量。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="5592" class="lr ls iq ln b gy lt lu l lv lw">from sklearn import preprocessing<br/>le_sex = preprocessing.LabelEncoder()<br/>le_sex.fit(['F','M'])<br/>X[:,1] = le_sex.transform(X[:,1]) <br/></span><span id="4629" class="lr ls iq ln b gy ma lu l lv lw">le_BP = preprocessing.LabelEncoder()<br/>le_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])<br/>X[:,2] = le_BP.transform(X[:,2])<br/></span><span id="1b74" class="lr ls iq ln b gy ma lu l lv lw">le_Chol = preprocessing.LabelEncoder()<br/>le_Chol.fit([ 'NORMAL', 'HIGH'])<br/>X[:,3] = le_Chol.transform(X[:,3]) </span><span id="9a23" class="lr ls iq ln b gy ma lu l lv lw">X[0:5]</span></pre><p id="77d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出局:</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="4cbf" class="lr ls iq ln b gy lt lu l lv lw">array([[23, 0, 0, 0, 25.355],<br/>       [47, 1, 1, 0, 13.093],<br/>       [47, 1, 1, 0, 10.113999999999999],<br/>       [28, 0, 2, 0, 7.797999999999999],<br/>       [61, 0, 1, 0, 18.043]], dtype=object)</span></pre><p id="49af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面我们已经把数值改成了 0，1，2。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="b569" class="lr ls iq ln b gy lt lu l lv lw"><em class="kx">#target value</em><br/>y = df["Drug"]<br/>y</span></pre><p id="fd8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出局:</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="24c8" class="lr ls iq ln b gy lt lu l lv lw">0      drugY<br/>1      drugC<br/>2      drugC<br/>3      drugX<br/>4      drugY<br/>       ...  <br/>195    drugC<br/>196    drugC<br/>197    drugX<br/>198    drugX<br/>199    drugX<br/>Name: Drug, Length: 200, dtype: object</span></pre><p id="8bd8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将在我们的决策树中使用训练/测试分割。让我们从 sklearn.cross_validation 导入 train_test_split。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="e12e" class="lr ls iq ln b gy lt lu l lv lw">from sklearn.model_selection import train_test_split</span><span id="a3f2" class="lr ls iq ln b gy ma lu l lv lw">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)</span></pre><p id="8bf1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将创建一个测试和训练数据</p><p id="809a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将首先创建一个名为 Tree 的决策树分类器实例。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="6929" class="lr ls iq ln b gy lt lu l lv lw">Tree = DecisionTreeClassifier(criterion="entropy", max_depth = 4)<br/>Tree <em class="kx"># it shows the default parameters</em></span></pre><p id="2a09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出局:</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="af20" class="lr ls iq ln b gy lt lu l lv lw">DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',<br/>                       max_depth=4, max_features=None, max_leaf_nodes=None,<br/>                       min_impurity_decrease=0.0, min_impurity_split=None,<br/>                       min_samples_leaf=1, min_samples_split=2,<br/>                       min_weight_fraction_leaf=0.0, presort='deprecated',<br/>                       random_state=None, splitter='best')</span></pre><p id="e9e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们预测一下我们的价值观。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="085f" class="lr ls iq ln b gy lt lu l lv lw">pred =Tree.predict(X_test)<br/>pred</span></pre><p id="46de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在外</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="8c6a" class="lr ls iq ln b gy lt lu l lv lw">array(['drugY', 'drugX', 'drugX', 'drugX', 'drugX', 'drugC', 'drugY',<br/>       'drugA', 'drugB', 'drugA', 'drugY', 'drugA', 'drugY', 'drugY',<br/>       'drugX', 'drugY', 'drugX', 'drugX', 'drugB', 'drugX', 'drugX',<br/>       'drugY', 'drugY', 'drugY', 'drugX', 'drugB', 'drugY', 'drugY',<br/>       'drugA', 'drugX', 'drugB', 'drugC', 'drugC', 'drugX', 'drugX',<br/>       'drugC', 'drugY', 'drugX', 'drugX', 'drugX', 'drugA', 'drugY',<br/>       'drugC', 'drugY', 'drugA', 'drugY', 'drugY', 'drugY', 'drugY',<br/>       'drugY', 'drugB', 'drugX', 'drugY', 'drugX', 'drugY', 'drugY',<br/>       'drugA', 'drugX', 'drugY', 'drugX'], dtype=object)</span></pre><p id="59d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们检查测试并预测值。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="1400" class="lr ls iq ln b gy lt lu l lv lw">print (pred [0:5])<br/>print (y_test [0:5])</span></pre><p id="20b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出局:</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="e064" class="lr ls iq ln b gy lt lu l lv lw">['drugY' 'drugX' 'drugX' 'drugX' 'drugX']<br/>40     drugY<br/>51     drugX<br/>139    drugX<br/>197    drugX<br/>170    drugX<br/>Name: Drug, dtype: object</span></pre><p id="eb44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们检查模型的准确性。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="10b5" class="lr ls iq ln b gy lt lu l lv lw">from sklearn import metrics<br/>import matplotlib.pyplot as plt<br/>print("DecisionTrees's Accuracy: ", metrics.accuracy_score(y_test,pred))</span></pre><p id="7e27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出局:</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="a787" class="lr ls iq ln b gy lt lu l lv lw">DecisionTrees's Accuracy:  0.9833333333333333</span></pre><p id="9153" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">创建一个决策树并将其可视化。</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="4ec4" class="lr ls iq ln b gy lt lu l lv lw">from sklearn import tree<br/>plt.figure(figsize=(25,10))<br/>tree.plot_tree(Tree,filled=True, <br/>              rounded=True, <br/>              fontsize=14);</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mf"><img src="../Images/dd3755a0ab598893d8eb98d1fd9cec09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ivO3raxb6j06HkksnE8ZA.png"/></div></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</p></figure><p id="8bc1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">实际代码可在以下位置查看:</p><p id="98f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mk" href="https://www.kaggle.com/adityakumar529/decision-tree-classification" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/adityakumar 529/决策树分类</a></p></div></div>    
</body>
</html>