<html>
<head>
<title>Dealing With High Bias and Variance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理高偏差和方差</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/contents-9b2e49f49fe9?source=collection_archive---------10-----------------------#2020-06-26">https://towardsdatascience.com/contents-9b2e49f49fe9?source=collection_archive---------10-----------------------#2020-06-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a1eb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过方程解释正则化</h2></div><h1 id="8c9a" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">内容</h1><p id="c70a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在本帖中，我们将了解:</p><p id="4758" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">(I)评估机器学习模型性能的方法</p><p id="7eac" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">㈡适配不足和适配过度的问题</p><p id="97e0" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">(三)偏差-方差权衡</p><p id="20fc" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">㈣解决高偏差和高差异问题</p><p id="b1b1" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在<a class="ae mb" href="https://medium.com/analytics-vidhya/machine-learning-ii-logistic-regression-explained-data-pre-processing-hands-on-kaggle-728e6a9d4bbf" rel="noopener">之前的</a>帖子中，我们研究了逻辑回归、数据预处理，并在Kaggle上的titanic数据集上进行了实际操作，获得了不错的结果。在到目前为止的两篇帖子中，你一定已经注意到我在这里和那里抛出了过度拟合这个术语，并且还提到它会导致机器学习模型的性能不佳。现在，我们将详细了解机器学习模型可能遇到的问题，以及它们可能的解决方案。在这篇文章中，我们不会亲自动手，但是在接下来的文章中，我们将应用我们在这篇文章中学到的概念。</p><h1 id="0a87" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">评估模型的性能</h1><p id="7a3c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在直接进入机器学习模型中出现的问题之前，我们如何知道我们的模型有问题？为此，我们需要一个模型的评估指标。我们已经看过一些了。我们使用决定系数(r分数)来评估线性回归模型，使用精确度来评估逻辑回归模型。这两个指标都是由我们通过它们各自的成本函数得到的潜在误差计算出来的。为了解决机器学习模型的问题，我们将使用这个<strong class="lc iu">错误</strong>来做决定。</p><p id="5020" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">线性回归和逻辑回归的误差计算方式不同。为了让事情更容易理解和发展直觉，我们将从线性回归的角度来看待事情，但我们将定义的术语和它们扮演的角色将与任何其他机器学习模型完全相同。</p><p id="e112" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">一个错误就是一个“错误”,这个错误的程度可以量化为真实值和估计值之间的绝对差值。对于“n”个数量，它可以表示为:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/2d3a755656cc8cbec90e7b92df42a007.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*LbGh5BbW5AAXiWP3Y0CX-w.png"/></div></figure><p id="d123" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在训练和测试集上计算模型性能的误差有助于我们识别模型所面临的问题。考虑以下场景:</p><p id="7a56" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">(I)低训练集误差，低测试集误差</p><p id="f6ab" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">(ii)低训练集误差，高测试集误差</p><p id="b62c" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">(iii)高训练集误差，高测试集误差</p><p id="4d8f" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">(iv)高训练集误差，低测试集误差</p><p id="09f1" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">让我们一个一个地看看这些场景。</p><p id="05ff" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">如果训练集误差和测试集误差都很低，这意味着模型在训练集上很好地学习了输入-输出映射，并且也能够很好地将其推广到测试集。这是一个好的机器学习模型的期望输出。我们在上一篇文章中训练的逻辑回归模型就是这种情况。</p><p id="b102" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">当训练集误差较低但测试集误差较高时，我们说模型过度拟合了训练集。这意味着在训练集上训练机器学习模型后，它对训练集的输入输出映射学习得非常好，但不能将这些映射推广到测试集。让我们试着理解为什么会发生这种情况。为任何任务收集的数据都不可能没有错误，不管过程有多仔细。一个好的机器学习模型应该总是对噪声进行采样，并且只生成那些排除了噪声数据点的输入-输出映射，即一个好的机器模型对噪声是鲁棒的。考虑一场音乐会的情况，艺术家的旋律和人群的噪音都有，但我们只关注艺术家的旋律(输入)，因为它使我们愉快(输出)，忽略了人群的所有<em class="mk">噪音</em>。如果我们注意所有的声音(艺术家+噪音)，我们可能不会那么快乐。过度拟合是指机器学习模型关注每一个声音(艺术家+噪音)，而实际上我们只需要专注于旋律。对训练数据过度拟合的机器学习模型据说会遭受<strong class="lc iu">高方差。</strong>在这篇文章的后面，我们将看到如何处理过度拟合。</p><p id="ad6d" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">如果训练集和测试集的误差都很高，则表明机器学习模型没有正确地学习训练集上的输入-输出映射，并且也不能在测试集上进行推广。换句话说，我们可以说我们的机器学习模型处于原始状态。据说这种模型在训练和测试数据集上都存在不足，并且存在<strong class="lc iu">高偏差</strong>。</p><p id="4f29" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">具有高训练集误差和低测试集误差的机器学习模型很少出现，但是当训练和测试数据没有被适当地采样时(例如，在分类问题中每个类的样本数量几乎相等)会出现这种情况，这导致测试集的统计特性的显著差异。考虑一个二元分类问题，其中对A类的预测给出10%的训练误差，而对B类的预测给出40%的训练误差。平均分类精度在整个数据集上给我们25%的误差。但这不是一个好的措施。在现实生活的测试集中，A类的出现次数很可能多于B类。这意味着现实生活数据集中的实际预测误差将大大低于25%。发生这种情况的另一种情况是，当测试集明显小于训练集时，尽管与训练集相似，但我们在测试集上得到的错误较少，因为与训练集相比，它没有那么多噪声。除了在对数据应用任何机器学习算法之前研究和采样数据之外，没有什么可以避免这种情况。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/6e9b4e69892818ffd69f8e14d9c3be75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*z8AtfeawLH2ffP4G9jC8Kw.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">高偏差、完美拟合和高方差的直观表示(<a class="ae mb" href="https://www.pinterest.com/pin/52706258122128665/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="919d" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">偏差和方差的定义</h1><p id="3b51" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">对于熟悉统计学的读者来说，偏差和方差这两个术语一定不陌生。标准差衡量的是数据点离中心位置有多近或多远，从数学上来说，方差就是标准差的平方。因此，方差衡量的是一组数据分布的范围。用于机器学习任务的数据没有特定的输入-输出映射，这些模型的任务是找到足够好的映射来概括结果。一个机器学习模型，它(过)适合所有的数据点，包括有噪声的数据点，或者换句话说，适合所有的数据点，不管它们分布得有多广，都被称为遭受高方差。</p><p id="5a7b" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在统计学中，估计量(这里是机器学习模型)的偏差(或偏差函数)是估计量的期望值和给定输入的真实值之间的差异。零偏差的估计量或决策规则称为无偏的。机器学习模型的高偏差是机器学习模型的输出与实际输出相差甚远的情况。这是因为模型简单。我们之前看到，具有高偏差的模型在训练集和测试集上都具有高误差。</p><h1 id="6617" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">偏差-方差权衡</h1><p id="e217" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">偏差-方差权衡是监督机器学习算法的核心属性。理想情况下，我们需要一个机器学习模型，它考虑所有模式以及训练数据中的异常值，并将它们推广到测试(看不见的真实世界)数据，以便实现非常小的误差和非常高的准确性。我们之前看到，高方差模型非常复杂，可以很好地表示训练集的所有特征，从而使训练集的误差最小，但无法推广到看不见的数据。相比之下，高偏差模型表示极其简单的映射，并且可以将一些特征推广到看不见的数据，但是这些模型的简单性导致对训练集的欠拟合，并且当应用于训练集之外的数据时，生成具有较低方差(高偏差)的预测。特定机器学习模型应该具有的偏差和方差的理想量取决于误差(包括偏差误差、方差误差和噪声)的最小化。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/5209ddc2cc5605bf494adc5bc9cb6547.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*2RNoedJQVL1Ex3gmAvQxBQ.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">偏差-方差权衡(<a class="ae mb" href="https://www.ncbi.nlm.nih.gov/books/NBK543534/figure/ch8.Fig3/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="54e4" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">解决机器学习中的问题</h1><p id="6b28" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">建立机器学习模型是一个迭代的过程。看过数据集后，我们应该总是从简单的模型开始，然后不断增加它们的复杂性，直到我们在看不见的数据上得到想要的结果。极其简单的机器学习模型遭受高偏差，而极其复杂的机器学习模型遭受高方差。由于我们是从简单模型逐步过渡到复杂模型的，因此我们消除了高偏差的问题，但消除高方差并不容易，因为有些情况下，使用给定的一组参数和方法，我们无法获得最佳模型，而高方差模型需要经过处理才能获得最佳模型。所以先讨论几种解决方差大的方法。</p><h2 id="08f9" class="mr kj it bd kk ms mt dn ko mu mv dp ks lj mw mx ku ln my mz kw lr na nb ky nc bi translated">解决高差异</h2><p id="c9f3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">考虑逻辑回归分类器的例子。如果我们说分类器过拟合训练数据，这意味着等式y = sigmoid(Wx + b)的输出非常接近实际训练数据值。那么，过度拟合的根本原因是什么呢？显然，是我们在构建分类器时训练的参数值造成了机器学习模型的高方差(过拟合)。调整这些参数值有助于消除过度拟合，这个过程称为正则化。在正式术语中，正则化是添加信息以解决不适定问题或防止过度拟合的过程。正则化使参数值变小，这可以防止过度拟合。在这篇文章的后面，我们会看到为什么会这样。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/3236bf45feaab0a858f2ead3f13c9e93.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*E581ySiDPEdAHJki9Yhlqw.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">高方差模型训练和测试误差</p></figure><h2 id="45d5" class="mr kj it bd kk ms mt dn ko mu mv dp ks lj mw mx ku ln my mz kw lr na nb ky nc bi translated">正规化</h2><p id="6436" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">因为我们正在修改参数值，所以我们需要更新我们的成本函数，以便看到正则化的效果。<strong class="lc iu"> L2正则化</strong>最常用于成本函数，并产生相当好的结果。L2正则化后的成本函数为:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/d0c20bec475bdeebf5c89fa1ae493b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*ZwIeOdXdBNF_ku__GxdhqA.png"/></div></figure><p id="86a3" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">其中y(i)表示训练示例I的实际输出，φ(z(I))是通过逻辑回归对训练示例I的预测值，<strong class="lc iu"> λ </strong>是正则化参数，||w||是权重w的向量的<strong class="lc iu"> L2范数</strong>。权重的矢量化只不过是由向量包围的彼此堆叠的所有Wi。Python的机器库使用矢量化参数方程来加速计算。</p><p id="cb7b" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">假设向量W具有3个值W1、W2、W3，则向量W的L2范数计算如下:</p><p id="4e0b" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">||W|| = sqrt(W1 + W2 + W3)</p><p id="d18e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">请注意，我们没有像在一般逻辑回归分类器中那样正则化参数b，每个特征都有一个相应的W值，因此有多个W值和一个偏差b值，正则化偏差参数实际上没有任何区别。为了完整起见，我们通过在成本函数的末尾添加(<strong class="lc iu"> λ/2)*||b|| </strong>来正则化b，并对两者使用单独的<strong class="lc iu"> λ </strong>值。</p><h2 id="e31d" class="mr kj it bd kk ms mt dn ko mu mv dp ks lj mw mx ku ln my mz kw lr na nb ky nc bi translated">为什么以及如何正规化工作？</h2><p id="71fd" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在，在执行梯度下降以更新参数时，更新将如下所示:</p><p id="5ce5" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">W = W — alpha * dJ/dW</p><p id="da58" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">b = b—α* dJ/db</p><p id="f484" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">dJ/dW项由由于正则化而产生的附加项组成，并且在数值上是正值，即当代价函数被正则化时，代价函数wrt W的偏导数值比没有正则化时更大。因此，在更新参数时，我们从W的先前状态中减去一个更大的块，并且我们进行多次迭代，W的最终值小于我们在没有正则化的情况下获得的值。同样，我们可以通过正则化来计算dJ/db。</p><p id="bd35" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">现在我们知道，正则化导致小的参数值，这导致收敛于代价函数的全局最小值。我们将使用带有“n”个例子的逻辑回归来看看为什么正则化有效。我们知道y = sigmoid(w1x 1+w2x 2+w3x 3+…………+ Wnxn + b)。因为正则化导致比非正则化更小的参数值，所以让我们考虑参数值Wi非常小并且非常接近于0。因此，逻辑回归分类器的输出将简单地为y = sigmoid(b ),这是一个非常简单且非常差的输出估计。换句话说，这个输出非常简单，以至于它有一个极高的<strong class="lc iu">偏置</strong>。从偏差-方差权衡中，我们知道高偏差和高方差是机器学习模型的两个相反端，理想情况下，我们希望我们的模型处于两者之间。为了实现这一点，我们必须非常明智地选择正则化参数<strong class="lc iu"> λ </strong>。<strong class="lc iu"> λ </strong>是使用开发集设置的，其中我们尝试各种<strong class="lc iu"> λ </strong>值，并选择一个为我们的机器学习模型产生最佳性能的值，然后使用该模型在测试集上进行预测。</p><p id="8eb8" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">像L2正则化一样，还有另一种类型的正则化项可以添加到成本函数中。添加此<strong class="lc iu"> L1正则化</strong>项后的成本函数如下:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/6cc7a81ebeebb81ab43785df8ef6d39c.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*vGcFtTL3NjJIGMOOUQkbUg.png"/></div></figure><p id="30cb" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">其中||w||是矢量W的<strong class="lc iu"> L1范数</strong>，具有3个元素的矢量W的L1范数计算如下:</p><p id="3389" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">||W|| = |W1| + |W2| + |W3|其中，|Wi|代表Wi的绝对值。</p><h2 id="93b1" class="mr kj it bd kk ms mt dn ko mu mv dp ks lj mw mx ku ln my mz kw lr na nb ky nc bi translated">添加更多培训数据</h2><p id="b656" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">处理机器学习模型过度拟合的另一种方式是向训练集添加更多数据。这背后的原因很简单。如果机器学习模型在训练集上过度拟合，它也在学习数据中的噪声输入。添加更多的数据将导致数据中更多的噪声，并且机器学习模型变得难以考虑如此多的噪声，以至于它最终离开有噪声的输入，并且更加关注输入-输出对的一般模式。这导致模型不会过度拟合训练数据，并且没有高方差的问题。要添加到训练集中的数据量取决于机器学习模型的过拟合程度。</p><h2 id="2a62" class="mr kj it bd kk ms mt dn ko mu mv dp ks lj mw mx ku ln my mz kw lr na nb ky nc bi translated">解决高偏置</h2><p id="42f3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">机器学习模型中的偏见不是我们前面看到的大问题，并且很容易消除。由于高偏差导致极其简单的机器学习模型，该模型不能捕获所有必要的特征来进行更准确的预测，因此我们可以做以下事情来消除高偏差:</p><p id="f528" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">(I)使用比现有模型更复杂的机器学习模型(通过引入多项式特征而不是线性特征，如y = Wx + b ),因为它可以很好地捕捉训练数据中的所有重要特征和模式。</p><p id="72f1" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">(ii)我们看到正则化大幅缩小了参数值，这也可能导致高偏差。因此，减小正则化参数有助于消除高偏差。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/ea05730cdd8dedecf7c1180591db14de.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*ELCci29mbdPDyoC9Tn6zcw.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">高偏差模型训练和测试误差</p></figure><p id="eb2e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在这篇文章中，我们首先发展了对高偏差和高方差的直觉，然后理解了当其中一个或两个都出现时，机器学习模型可能遇到的问题。后来，我们研究了从机器学习模型中消除高偏差和高方差的方法，并对正则化的工作提出了见解。</p><p id="020a" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在下一篇文章的<a class="ae mb" href="https://medium.com/analytics-vidhya/machine-learning-iv-support-vector-machines-kaggle-dataset-with-svms-57d7c885652a" rel="noopener">中，我们将看看另一种被称为支持向量机的监督机器学习方法，并将使用它来解决Kaggle的数据集。</a></p></div></div>    
</body>
</html>