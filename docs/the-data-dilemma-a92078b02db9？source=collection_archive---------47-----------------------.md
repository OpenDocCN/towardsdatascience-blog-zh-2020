# 数据困境

> 原文：<https://towardsdatascience.com/the-data-dilemma-a92078b02db9?source=collection_archive---------47----------------------->

## 意见

## 从一开始就从伦理上思考

作为一名目前沉浸在数据科学训练营中的有抱负的数据科学家，“我如何从一开始就合乎道德地工作？”当我观看《社交困境》时，当我听到特里斯坦·哈里斯(Tristan Harris)和凯茜·奥尼尔(Cathy O'Neil)以及其他许多人讨论大数据和这些无人驾驶的黑盒算法的危险时，这个问题弥漫在我的脑海中，这些算法渗透到我们的潜意识中，为我们做出我们不再理解的决定。这些告密者被归入一个不存在的团体，非正式地称为“硅谷的良心”，他们的故事令人不安。但他们并没有错，他们是在用事后诸葛亮的权威说话。整部纪录片中采访的许多数据科学家和程序员都提到，他们对这些算法可能会变成什么缺乏远见，或者当出现道德困境时，财务底线是致命的一击。换句话说，已经太晚了。所以我的问题是:

> “我(我们)如何进入数据科学领域，了解我们现在所知道的，并受益于前人的经验教训？”

![](img/32bf88d53795272bc799866546f24735.png)

[imgix](https://unsplash.com/@imgix?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

# 我个人的困境

明确一点，这不是影评。我真的很欣赏这部电影，并从中学到了很多东西，唯一比这篇文章的标题更令人畏缩的是穿插在一些最有趣的采访中的一些我能想到的最有趣的技术人员。但这篇文章更多的是个人对数据科学行业日益增长的力量的危险的思考，也是我自己(也许还有其他人)在寻求对给我的工具负责时要记住的路线图。我需要什么样的工具和指导原则才能继续走这条路？听着关于大数据在每次点击和滚动背后做什么的令人痛心的讨论令人生畏，但我被人性化技术的理念以及技术如何能够并且应该被用于比牟取暴利更伟大的目的而振奋。

我个人没有夸大其词的错觉，也不认为下一款会很快显著改变社会运行方式的车型会投入生产，甚至永远不会。但我讨厌有一天发现自己处于这样一种境地，希望自己早点问自己和别人这些问题。在我看来，权力有这种独特的能力来改变我们，而且往往是以我们不总是喜欢的方式，除非我们立足于现实，一路上有制衡。在这里，我没有太多的哲学思想，我已经冒昧地研究了一些关于数据伦理的其他观点，并编制了一些最重要的考虑因素的清单。如果你对了解可怕的黑匣子和科技公司破坏社会结构的方式更感兴趣，我绝对推荐给*社会困境*一个手表，或者阅读凯茜·奥尼尔的书*数学毁灭的武器。*它们会让你看到你可能已经意识到的力量，并帮助你理解它们是如何运作的。

# **我的数据来自哪里？**

这是一个关于我们的数据的来源和质量的多方面的问题，并且有一大堆的问题源于这种最初的数据收集的想法。我的同学 Sidney Kung 让我见识了很多关于数据收集和数据隐私的道德规范。根据她的发现，世界上其他地方的私人或个人数据收集者都有更高的标准，而在美国，公司正在存储大量数据，除了“有一天可能会用到”之外，他们自己没有任何意图或计划。事实是，我们制作的模型的好坏取决于我们提供给它们的信息，以及我们判断模型的标准。“垃圾进，垃圾出”这句话在这里再合适不过了。如果一个模型是在一个已经损坏的系统上训练的，该模型将继续以类似的方式预测或分类，并且将潜在地加剧那些偏差，因为它们变得越来越机械一致。

# **我的模型使用情况如何，如果出错会有什么后果？**

我们可以问自己的一个最好的问题是，犯错的代价是什么？这方面最常见的例子是在司法系统和医疗领域提出第一类和第二类错误。在这两种情况下，犯 1 型或 2 型错误的代价更高吗？在司法系统中，应该在“无罪推定”的假设下运作，理论上犯下“假阴性”的第二类错误比指控一个无辜的人犯下他们没有犯下的罪行要好。另一方面，在医学领域，犯 2 型错误的后果要昂贵得多，在这种情况下，检测到实际上并不存在的疾病比错过真正存在的疾病要好。但是每个问题，不管是商业问题还是其他问题，都有它自己的细微差别和成本/收益分析。风险因素和你的研究或建模的含义应该从一开始就进行评估。这类问题的答案不可避免地会影响我们的过程，并帮助我们获得最终想要的结果。

# 我的模型哪里出现了偏差，我能从中学到什么？

我在熨斗学校的几位老师从第一天起就向我重复了一个概念，那就是“缺少数据本身就是数据。”我们能够从数据集中的空值或缺失值中得出什么结论或推断出什么(同样，也许这又回到了我们的数据来自哪里)。不要嘲笑我的锡帽子，问这样的问题:这个数据集是完整的吗？是否被篡改甚至审查过？谁会从这些数据的分析中获益？可能有助于理解数据集，应被视为任何探索性数据分析步骤的一部分。艾瑞克·希格尔写了一篇非常有用的文章，介绍了[在预测性警务中对算法的使用](https://blogs.scientificamerican.com/voices/how-to-fight-bias-with-predictive-policing/)，他在文章中直面一种被称为 COMPAS 的算法的观察到的偏差，指出:

> "为此，让我们就观察到的不公平现象对执法决策者进行教育和指导."

同样，Cathy O'Neil(根据我在博客中提到她的次数，我认为她是我的新英雄)，在她着手审计算法的方式上是开创性的。她在奥尼尔风险咨询和算法审计公司(ORCAA)的工作为[的法律制定者设定界限](https://algorithmwatch.org/en/story/cathy-oneil-orcaa/)铺平了道路，在给定某些偏见的情况下，算法可以做什么，不可以做什么。

# 是否有不止一种方法来解释我的结果？

答案可能是肯定的，正因为如此，这意味着什么呢？反馈在任何领域都很重要，用你的眼睛和头脑以外的东西来看待问题是至关重要的。鉴于在一个以客观为荣的领域中存在大量的主观性，合作将总是有助于我们从多个角度看待问题，并且理解我的解释不是唯一可能的结果是提问和深入的重要一步。

我越深入这个领域，就越能看到模型构建过程的每一个环节都包含着主观性、偶然性和人类决策，统计学家乔治·博克斯(George Box)的名言对我越来越有意义:“*所有的模型都是错误的，但有些是有用的。*“我希望将这些想法和问题写下来有助于将它们固化在我的脑海中，帮助我建立*有用的*模型，并给你比你带来的更多的问题。

**那些努力监管这些强大工具的人的一些链接:**

人道技术中心

[算法观察](https://algorithmwatch.org/en/)

[ORCAA](https://orcaarisk.com/)