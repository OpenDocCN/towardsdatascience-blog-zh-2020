# 同态加密简介:第 1 部分:概述和用例

> 原文：<https://towardsdatascience.com/homomorphic-encryption-intro-part-1-overview-and-use-cases-a601adcff06c?source=collection_archive---------14----------------------->

![](img/f4285dcee2ebb52ec6a0133ba8007411.png)

来源:[博通](http://www.bluecoat.com/)

**同态加密简介:**

第 1 部分:概述和用例

[第二部:何山水与](https://medium.com/@dhuynh95/homomorphic-encryption-intro-part-2-he-landscape-and-ckks-8b32ba5b04dd)

[第三部分:CKKS 的编码和解码](/homomorphic-encryption-intro-part-3-encoding-and-decoding-in-ckks-69a5e281fee?source=friends_link&sk=f5f395522d78853747e9f1b913092d4e)

**简介**

机器学习算法的进步导致了各行各业的广泛采用。然而，由于保护用户数据的监管限制，处理敏感和私人数据的领域，如医疗保健或金融，已经落后了。

随着机器学习作为服务的出现，实体正在作为服务提供模型推理。在这种情况下，我们可以区分三方，一方是模型所有者(如培训模型的医院)，一方是主机(如提供计算能力的云提供商)，另一方是希望从服务中受益的客户端。在某些情况下，模型所有者也可以是宿主。必须在这些方之间建立信任，因为客户不希望她的数据被泄露，而模型所有者希望保护她的模型。

在本文中，我们将快速了解机器学习及其带来的进步。然后我们将看到机器学习的数据依赖性如何使其不适合一些敏感的用例，以及新的解决方案如何使模型在加密数据上的训练和推断成为可能。最后，我们将关注同态加密，看看它能涵盖哪些用例。

本文是非技术性的，面向广大读者。接下来的文章将深入探讨同态加密的技术细节，包括同态加密方案的理论和 Python 实现。

**一、围绕数据利用的隐私问题**

机器学习，特别是深度学习，它是机器学习的子领域，集中在深度神经网络(DNNs)上，已经证明在几个不同的任务上推进了技术发展水平。不同的领域，如使用 ResNet 的图像识别[，使用 BERT](https://arxiv.org/abs/1512.03385) 的文本处理[，甚至使用 WaveNet](https://arxiv.org/abs/1810.04805) 的语音生成，都在使用深度学习方面取得了巨大的进步，而其他模型则远远落后。

深度学习的基本原理是在海量数据上训练模型，并通过优化模型的损失。通过这样做，深度学习已经成功地获得了类似人类的性能，因为它能够找到人眼看不见的复杂模式。

因此，机器学习似乎为未来新的技术飞跃铺平了道路，但它严重依赖于数据的使用，无论是用于训练还是用于推理。

这些深度学习模型中使用的大部分数据通常来自公共的非个人数据，如 Wikitext 或 Imagenet。尽管如此，其他场景可能需要更合理的训练数据。例如，语音到文本模型可能需要人们记录他们的声音，诊断工具将需要发送私人健康数据，或者信用分析工具可能需要查看财务信息。

虽然我们看到了机器学习的强大，但我们在这里看到，一些敏感的用例无法通过这种方法直接回答，因为数据太敏感，无法共享，无论是用于训练还是用于推理。因此，在数据隐私和数据效率之间似乎存在一种权衡，在这种意义上，人们可以通过实施严格的过程来维护私有数据的更好的保密性，在这些过程中，数据只能由可信任的人类专家查看，代价是使该过程漫长且昂贵，或者使用经过训练的模型，这些模型可以具有优异的性能和可扩展性，但代价是需要在训练和推断期间查看数据。

然而，在过去的几年中，出现了几种技术，可以兼顾隐私和效率。其中，三个似乎最有希望:

*   **同态加密** (HE)是一种公钥密码方案。用户创建一对秘密和公共密钥，使用公共密钥加密她的数据，然后将其发送给第三方，第三方将对加密的数据进行计算。由于加密和解密的同态属性，用户可以得到加密的结果并用她自己的密钥对其进行解码，以查看对她的数据的计算的输出，而无需向第三方清楚地展示一次。
*   **安全多方计算** (SMPC)是一个不同的范例，它更依赖于参与者之间的通信。数据可以拆分，模型也是如此，每个参与者只发送她数据的一小部分，这样其他人就不能重建初始数据，但可以参与进来，并对数据部分进行一些计算。然后，一旦每一方都完成了，所有的东西都可以被聚合，输出的结果对每一方都是已知的。
*   **可信执行环境** (TEE)由于硬件隐私保证，软件开发得以实现。英特尔的 SGX 技术提供了这种系统的实现。enclave 技术允许程序独立于其他程序执行。所有入站和出站数据都是加密的，明文计算只发生在 enclave 内。然后可以从外部检查 enclave 代码和完整性。

**SMPC** 提供了一些有趣的功能，比如可以让不同的参与者在隐藏各自数据的同时进行合作。SMPC 的主要优势之一是它计算复杂运算的能力，例如比较或 argmax，而这些在 he 中是不可能的。此外，与 he 相比，使用 SMPC 评估深度模型更容易，因为大多数 HE 方案都是分级的。

然而，SMPC 要求各方遵守协议。此外，它需要一个可信的第三方不与任何一方合作。如果是这样，一方或多方的数据可能会受到损害。最后，因为 SMPC 依赖于各方之间的通信和计算，这需要更多的计算和更多的带宽，这不一定适合通常的客户机/服务器范例，在这种范例中，服务器在很少通信的情况下执行大多数操作。

**TEE** 提供硬件保障，保证敏感数据在受控环境下处理。在这个被称为 enclave 的安全空间中，数据被解密，并被明文用于计算。在飞地之外，数据仍然是加密的。这使得效率大大提高，因为我们不需要在计算之前加密数据，但是我们可以直接计算明文，并在输出离开 enclave 之前加密输出。

然而，为 tee 编写安全代码是一项艰巨的任务，已经在英特尔 SGX 上发现了几次攻击。[“对英特尔 SGX 已发布攻击的调查”](https://portal.research.lu.se/portal/files/78016451/sgx_attacks.pdf)涵盖了对英特尔 SGX 的几种类型的攻击，例如旁路攻击，即操作系统内核利用其对平台近乎完全的控制，对依赖内核服务的飞地发起攻击。还存在其他攻击，如缓存攻击、分支攻击或推测性动作攻击，但我们让感兴趣的读者在上面的文章中了解更多。

一旦加密完成，他就可以将几乎所有的计算外包给服务器。使用同态属性，可以在不泄露任何隐私的情况下对加密数据进行计算，并且用户可以安全地解密输出。此外，他不需要像 SMPC 那样多的交流，也不需要比发球台更特殊的硬件。

虽然他相对简单，并且与其他方法相比几乎没有依赖性，但是他不能有效地执行任意多次乘法，并且他只能执行加法和乘法，这使得一些计算更难以执行。

虽然每种方法都有自己的优缺点，但这些技术共有的一个可取的特性是，它们都允许加密模型和数据。这可能为“私人机器学习”的新实践开辟道路，用户将能够共享私人数据，如医疗或财务记录，以便从机器学习服务中受益，而不必实际展示他们的数据。

在本文的其余部分，我们将集中讨论同态加密，因为它是三种方法中最容易部署的。事实上，SMPC 和发球台需要额外的基础设施部署，因为发球台需要使用特殊的硬件，而 SMPC 依赖于可信的第三方(可以是发球台)，而他非常简单，可以在没有任何特殊依赖的情况下实现。

**二。同态加密的隐私友好用例**

我们现在将看到如何在实践中应用这些概念，以及这些隐私友好的方法可能实现的不同用例。

在这一节中，我们将探索他打开的不同用例。正如我们将在另一篇文章中看到的，he 方案使用户能够将明文消息加密成密文，以便用于计算。可以在密文和密文之间，或者在密文和明文之间进行运算。最后，只有加密数据的用户才能解密输出。

因此，该方案可以允许模型和数据被加密，并且结果必须总是返回到秘密密钥的所有者以获得最终结果。使用这些假设，我们将了解如何涵盖不同的场景。

**A .模型保密性:来自公开数据的财务指标**

学习受益于一个非常活跃的研究和开源社区。这使得许多最先进的模型可以为非研究人员所用。例如， [**Fastai**](https://www.fast.ai/) 一个众所周知的深度学习框架已经实现了民主化的强大模型，如用于图像识别的 ResNet，或用于文本分类的 ULMFiT。

因此，这种模型的价值不在于通常为大多数人所知的架构，而在于训练后获得的权重，因此也在于训练数据。

在这里，我们将探索一个场景，其中用户已经设法收集、清理和预处理了用于给定模型的训练的数据集。虽然训练中使用的数据可以安全存储，但如果用户想在云平台上部署模型，她必须信任云提供商不会窃取权重，也不会有意或无意地泄露模型。

因此，可以想象，通过加密权重，云主机将无法获得关于模型的任何洞察，并且用户在云上部署她的模型变得安全。

![](img/ba8bc104f9324eb8500b5c959f38db77.png)

CKKS 概况(来源:Daniel Huynh)

上图说明了这一点。场景如下:

*   客户端将她未加密的数据发送到云提供商托管的模型。
*   云主机使用加密的模型和未加密的数据执行计算，然后将结果发送给模型提供者。
*   模型提供者解密结果，然后将其发送给客户端。

因为模型提供者仍然需要解密结果，这在混合云的情况下会更有趣，在混合云的情况下，基础设施的非关键部分托管在公共云上，而更关键的部分隔离在私有云中。在这里，人们可以想象公共云部分负责大部分计算并管理负载平衡，而私有云部分仅解密结果并将其发送给客户端(最终通过公共云)。

这种情况的一个例子是，例如，一家公司分析公共市场的指标，并向其客户汇总数据。然后，将大部分计算托管在公共云上是有意义的，但在将计算发送到云之前，通过加密来保护所有算法。结果可以由该公司解密，然后发送给他们的客户。

**B .私有推断:私有集合交集**

在私有推断设置中，我们现在将假设相反的情况，用户持有的数据是私有的，但是模型提供者持有的模型不需要加密。例如，在模型所有者和云提供商是同一个实体的情况下，或者在这种情况下，他们相互信任。

在这种情况下，我们的目标是提供一个可伸缩的、隐私友好的解决方案，这样用户就可以用私有数据查询服务器，而不会暴露给服务器。

例如，Private Set Intersection (PSI)是这样一种场景，其中一个用户持有私人信息，但希望检查她的数据是否与更大的相同性质的数据库相交。然后，服务器将操作这个数据库，并且服务器的数据不一定需要加密。他提供了这样做的可能性，同时保护用户的数据隐私。"[同态加密的快速私有集合交集](https://eprint.iacr.org/2017/299.pdf)"探讨了这种情况，并展示了可以使用 PSI 进行联系发现。在这种情况下，像 Whatsapp 这样的服务提供商拥有关于谁在使用他们的服务的大型数据库，而一个低收入的新客户想知道他们的联系人中谁在使用 Whatsapp。然后这个客户端只需要要求服务器将她与所有用户的联系人列表私下相交，并解密结果，就可以知道她联系人中有谁在使用 Whatsapp。

作为另一个例子，在最近围绕 Covid19 的危机的情况下，人们可以检查用户和已知的感染患者群体之间是否有过接触。这可以在客户端服务器场景中完成，其中用户共享她的位置数据，并且服务器可以对其执行计算以向客户端输出客户端可能遇到的最终患者。

**C .三方保密计算:云上托管的医院模型**

我们将讨论的最后一个场景是数据和模型都被加密的情况。这可能是一个三方设置的情况，其中一个用户希望对其数据进行分析，一个模型所有者希望提供其模型，一个云提供商提供托管该服务的基础架构。

在标准的 he 方案中，只有由同一公钥生成的密文才能一起用于加法和乘法。这将使得不可能计算由两个不同的客户端生成的任何东西，因此使他相当受限。然而“[应用于不经意神经网络推理的具有打包密文的高效多密钥同态加密](https://eprint.iacr.org/2019/524.pdf)”提供了一种对来自不同所有者的几个输入进行计算的方法。

![](img/6c80622338a9e23dba2bd5e5c65f1084.png)

多方 HE 概述(来源:[利用打包密文的高效多密钥同态加密，应用于不经意神经网络推理](https://eprint.iacr.org/2019/524.pdf)

上图概述了这一过程。主要思想是，客户机和模型所有者都可以在将数据发送到服务器之前加密它们的数据。这个将能够使用这两个输入进行计算，然后向每一方发送部分结果。然后，模型所有者将使用她的私钥移除他引入的噪声的一部分，并将其发送给客户端，客户端将移除剩余的噪声并获得输出。

这个场景对于医疗场景特别有意思。客户可能是提供其数据的患者，而模型所有者可能是训练了模型的医院。为了更好地为患者服务，该模型可以安全地部署在公共云上，同时保留医院训练的权重。根据推断，数据将由患者加密，并在上述两步过程中解密。

**结论**

在这篇文章中，我们已经看到了为什么我们需要更加隐私友好的解决方案，以及何、和 TEE 目前采用的方法。然后，我们看到他可以解决哪些不同的使用案例。

在 GDPR 和 Covid19 的背景下，他似乎是一个非常有前途的领域，我们需要快速发展，但要谨慎对待人们的数据。

我们将在下一篇文章中讨论更多的技术部分，在那里我们将看到如何从头开始构建我们自己的 he 方案。

所以，我希望你喜欢读这篇文章，如果能得到你的反馈，那就太好了，我会在未来试着发布更多的文章。

如果您有任何问题，请随时在 [Linkedin](https://www.linkedin.com/in/dhuynh95/) 上联系我，您也可以在 [Twitter 上找到我！](https://twitter.com/dhuynh95)