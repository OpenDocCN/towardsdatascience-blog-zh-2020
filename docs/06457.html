<html>
<head>
<title>Generate Nick Cave’s Lyrics in 2 mins</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">两分钟内生成尼克·凯夫的歌词</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generate-nick-caves-lyrics-in-2-mins-e265f8fc78e2?source=collection_archive---------66-----------------------#2020-05-22">https://towardsdatascience.com/generate-nick-caves-lyrics-in-2-mins-e265f8fc78e2?source=collection_archive---------66-----------------------#2020-05-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5a32" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在这篇文章中，我们将使用GPT-2语言模型来开发一个简单的歌曲歌词生成器，以尼克·凯夫为例，他是我最喜欢的艺术家之一。</h2></div><h1 id="0e11" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">GPT-2</h1><p id="8279" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">GPT-2是一个大型的基于转换器的语言模型，有15亿个参数。它的训练有一个简单的目标:给定某个文本中所有的前一个单词，预测下一个单词。由800万个网页组成的数据集的多样性，导致这个简单的目标包含跨不同领域的许多任务的自然发生的演示。有关详细信息，请访问<a class="ae lu" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="noopener ugc nofollow" target="_blank">open ai出版物</a>。让我们集中精力练习吧！</p><h1 id="ae0a" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">解析歌词</h1><p id="3da6" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">首先，我们需要使用众所周知的<code class="fe lw lx ly lz b">BeautifulSoup</code>库解析来自<em class="lv">尼克·凯夫</em> <a class="ae lu" href="https://www.nickcave.com/lyrics/" rel="noopener ugc nofollow" target="_blank">官方网页</a>的歌词。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">解析尼克·凯夫的歌曲</p></figure><p id="fe86" class="pw-post-body-paragraph ky kz iq la b lb ml jr ld le mm ju lg lh mn lj lk ll mo ln lo lp mp lr ls lt ij bi translated">运行上面的代码后，我们在<code class="fe lw lx ly lz b">songs.txt</code>文件中保存了来自20张专辑的201首歌曲。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/91cf41bd57c1f7935cfcd4ff4b5c3087.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*4bRD_H-kz5cRlqhP_iHSfQ.png"/></div></figure><h1 id="6039" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">火车模型</h1><h2 id="2897" class="mt kh iq bd ki mu mv dn km mw mx dp kq lh my mz ks ll na nb ku lp nc nd kw ne bi translated">构建标记器</h2><p id="01a3" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">使用<code class="fe lw lx ly lz b"><a class="ae lu" href="https://github.com/minimaxir/aitextgen" rel="noopener ugc nofollow" target="_blank">aitextgen</a></code> <a class="ae lu" href="https://github.com/minimaxir/aitextgen" rel="noopener ugc nofollow" target="_blank">库</a>在下载的歌曲上训练一个自定义标记器。这将保存两个文件:<code class="fe lw lx ly lz b">aitextgen-vocab.json</code>和<code class="fe lw lx ly lz b">aitextgen-merges.txt</code>，它们是重新构建分词器所需要的。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><h2 id="46f2" class="mt kh iq bd ki mu mv dn km mw mx dp kq lh my mz ks ll na nb ku lp nc nd kw ne bi translated">列车GPT-2变压器模型</h2><p id="048c" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">使用创建的tokenizer启动aitextgen</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="78f7" class="pw-post-body-paragraph ky kz iq la b lb ml jr ld le mm ju lg lh mn lj lk ll mo ln lo lp mp lr ls lt ij bi translated">创建TokenDatasets，构建用于训练的数据集，以适当的大小处理它们。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="0310" class="pw-post-body-paragraph ky kz iq la b lb ml jr ld le mm ju lg lh mn lj lk ll mo ln lo lp mp lr ls lt ij bi translated">训练时间到了！</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><h1 id="3fde" class="kg kh iq bd ki kj kk kl km kn ko kp kq jw kr jx ks jz kt ka ku kc kv kd kw kx bi translated">生成歌曲</h1><p id="c766" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">从“我们淹死了”开始生成3个段落，并将它们保存到文件中。您可以修改<code class="fe lw lx ly lz b">max_length</code>和<code class="fe lw lx ly lz b">temperature</code>参数。温度是随机性相关的超参数。当其值较小时(如0，2)，GPT-2模型更有信心，但也更保守。当温度是一个大值(例如1)时，GPT-2模型产生更多的差异，也产生更多的错误。在我看来，当你想生成一件艺术品时，第二种选择要好得多；).</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="648f" class="pw-post-body-paragraph ky kz iq la b lb ml jr ld le mm ju lg lh mn lj lk ll mo ln lo lp mp lr ls lt ij bi translated">下面你可以看到样本结果。看起来挺有前途的，尤其是考虑到需要多少编码量:)。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/5b235f6633ea98bed311bfc2de92b325.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*8O_bWy2Bri87rgwWlCKWJg.png"/></div></figure><p id="7b58" class="pw-post-body-paragraph ky kz iq la b lb ml jr ld le mm ju lg lh mn lj lk ll mo ln lo lp mp lr ls lt ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>