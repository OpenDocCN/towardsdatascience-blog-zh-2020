<html>
<head>
<title>Model Evaluation and Parameter Tuning for Neural Network Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络优化的模型评估和参数调整</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ann-classification-model-evaluation-and-parameter-tuning-9174fd5ad0c2?source=collection_archive---------30-----------------------#2020-04-05">https://towardsdatascience.com/ann-classification-model-evaluation-and-parameter-tuning-9174fd5ad0c2?source=collection_archive---------30-----------------------#2020-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0bbd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Keras 的交叉验证和网格搜索的分步走查</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d5de4ff5791827a40eac87e31eabad38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gaIhNKDL7m6XW1UUcSxdyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Img 改编自 pixabay 通过<a class="ae ky" href="https://pixabay.com/photos/seo-sem-google-marketing-793035/" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="384c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在之前的<a class="ae ky" href="https://medium.com/@vistaxjtu/ann-classification-banking-customer-leave-or-stay-1cba16441185" rel="noopener">文章</a>中，我们构建了一个人工神经网络来解决一个二元分类问题。<strong class="lb iu">如果你还记得的话，留做家庭作业的一个问题是为什么我们对新客户数据使用[[]]。</strong> <em class="lv">答案是我们需要将客户数据放入一个水平向量中，而不是垂直向量中，因为输入数据中的所有观察值都是行而不是列。希望你没弄错😎<em class="lv">。</em></em></p><p id="f795" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文主要关注模型优化的交叉验证和网格搜索，分为两个部分:</p><ol class=""><li id="fbba" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">模型评估</li><li id="a48d" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">参数调谐</li><li id="c710" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">摘要</li></ol><p id="69f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们开始旅程🏃‍♀️🏃‍♂️.</p><ol class=""><li id="d214" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><strong class="lb iu">模型评估</strong></li></ol><p id="47be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">你可能想知道为什么我们要花精力在模型评估上</em>🤔<em class="lv">？</em>问题是如果我们重新运行 ANN，每次模型不仅在训练集和测试集上产生不同的精度。因此，在一次测试中评估模型性能并不是最恰当的方式。</p><p id="7eb2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">典型的方法是使用 K-fold 交叉验证。图 1 展示了它是如何工作的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/3013659f589f55f69637d439faf15462.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*ii4x43OzVVVJkpwCemh0Wg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1 K 倍交叉验证图(作者创建的 Img)</p></figure><p id="48b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将训练集分成 K 个折叠(例如，K=10)。然后在 9 个褶皱上训练模型，在最后剩下的褶皱上测试。10 折，我们用 9 个训练集和 1 个测试集做 10 个不同的组合，训练/测试模型 10 次。之后，我们取 10 次评估的平均值，并计算标准偏差。这样，我们可以确定模型属于哪个类别，如图 2 所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/e96f21be360a219594576382696626a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*br4FJU2RkfCXFLZtHTfsGA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2 偏差-方差权衡图(Img 由作者创建)</p></figure><p id="b159" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了实现 K-fold 交叉验证，我们在<em class="lv">Keras</em>:<strong class="lb iu"><em class="lv">Keras classifier</em></strong>中使用了一个<strong class="lb iu"> <em class="lv"> scikit_learn </em> </strong>包装器。具体来说，我们使用<strong class="lb iu"> <em class="lv"> Keras </em> </strong>构建模型，使用<strong class="lb iu"> <em class="lv"> scikit_learn </em> </strong>进行交叉验证。首先要为模型架构构建一个函数，因为该函数是<strong class="lb iu"> <em class="lv"> Keras </em> </strong>包装器的必需参数。正如你在下面注意到的，这和我们之前建立的人工神经网络结构是一样的。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="2ac3" class="mr ms it mn b gy mt mu l mv mw">from keras.wrappers.scikit_learn import KerasClassifier<br/>from sklearn.model_selection import cross_val_score<br/>from keras.models import Sequential<br/>from keras.layers import Dense</span><span id="4123" class="mr ms it mn b gy mx mu l mv mw">def build_classifier():<br/> classifier = Sequential()<br/> classifier.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’, input_dim = 11))<br/> classifier.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’))<br/> classifier.add(Dense(units = 1, kernel_initializer = ‘uniform’, activation = ‘sigmoid’))<br/> classifier.compile(optimizer = ‘adam’, loss = ‘binary_crossentropy’, metrics = [‘accuracy’])<br/> return classifier</span></pre><p id="7936" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过使用上述函数构建的分类器，我们创建了一个<em class="lv"> KerasClassifier </em>对象。下面我们指定批量大小为 10，需要训练的模型的时期数为 100。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="6e75" class="mr ms it mn b gy mt mu l mv mw">classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)</span></pre><p id="b4d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们使用<strong class="lb iu"><em class="lv">cross _ val _ score()</em></strong>方法对分类器应用 K-fold 交叉验证。这个函数返回一个训练精度列表。参数<strong class="lb iu"> <em class="lv"> cv </em> </strong>是我们用于交叉验证的折叠数。这里，分类器将在 10 个不同的训练集上进行训练，这些训练集是从初始训练集中分离出来的。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="97e5" class="mr ms it mn b gy mt mu l mv mw">accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)<br/>mean = accuracies.mean()<br/>std = accuracies.std()</span></pre><p id="ed3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，交叉验证可能需要一段时间。最终，我们得到了如图 2 所示的准确度为 10 的评估。平均准确度为 0.843，标准偏差为 1.60%🤪。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/ea7e7d3427ef9e375143b5877e6c85a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*LHK2s2NAi9ZVF0r5r93jCw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2 交叉验证的准确性</p></figure><p id="bfed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<strong class="lb iu">参数调谐</strong></p><p id="f256" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了可靠的模型准确性，让我们尝试使用两种技术来提高它。</p><p id="0319" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.1 辍学正规化</p><p id="236e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们没有提到的一个技术是<strong class="lb iu">退出</strong>正则化。<strong class="lb iu">这是与高方差相关的过拟合的解决方案。</strong>辍学是如何进行的？在每次训练迭代中，一些神经元被随机禁用，以防止它们相互依赖。通过覆盖这些神经元，神经网络每次都会保留不同的神经元配置，帮助神经网络学习数据的独立相关性。这可以防止神经元过度学习。</p><p id="1755" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用<strong class="lb iu"> <em class="lv"> Keras </em> </strong>来实现它。基本上，我们在每个隐藏层后添加一个退出层。注意<em class="lv"> p </em> =0.1 意味着每次迭代将禁用 10%的神经元。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="545f" class="mr ms it mn b gy mt mu l mv mw">from keras.layers import Dropout<br/>classifier.add(Dense(output_dim = 6, init = ‘uniform’, activation = ‘relu’, input_dim = 11))<br/>#add dropout layer<br/><strong class="mn iu">classifier.add(Dropout(p =0.1))<br/></strong>classifier.add(Dense(output_dim = 6, init = ‘uniform’, activation = ‘relu’))<br/>#add dropout layer<br/><strong class="mn iu">classifier.add(Dropout(p =0.1))<br/></strong>#add output layer<br/>classifier.add(Dense(output_dim = 1, init = ‘uniform’, activation = ‘sigmoid’))</span></pre><p id="e594" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.2 参数调整</p><blockquote class="mz"><p id="2140" class="na nb it bd nc nd ne nf ng nh ni lu dk translated">神经网络有一些超参数，如时期数、批量大小和学习速率。参数调整就是找到模型的最佳参数。这里我们使用<strong class="ak">网格搜索</strong>来测试参数的不同组合。</p></blockquote><p id="0cff" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">为了实现它，我们在<em class="lv">Keras</em>:<strong class="lb iu"><em class="lv">Keras classifier</em></strong>中使用一个<strong class="lb iu"> <em class="lv"> scikit_learn </em> </strong>包装器来包装神经网络。然后创建一个网格搜索对象，并在包装的分类器上应用参数调整。首先，如下构建分类器函数。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="9dc4" class="mr ms it mn b gy mt mu l mv mw">def build_classifier(optimizer):<br/> classifier = Sequential()<br/> classifier.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’, input_dim = 11))<br/> classifier.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’))<br/> classifier.add(Dense(units = 1, kernel_initializer = ‘uniform’, activation = ‘sigmoid’))<br/> classifier.compile(optimizer = optimizer, loss = ‘binary_crossentropy’, metrics = [‘accuracy’])<br/> return classifier</span><span id="2cb1" class="mr ms it mn b gy mx mu l mv mw">classifier = KerasClassifier(build_fn = build_classifier)</span></pre><p id="b93d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">上面注意，没有指定历元数和批量大小，因为它们是我们计划调优的参数，将在</strong>下面的网格搜索对象中指定。</p><p id="5bff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们为参数创建一个字典，其中包含我们希望模型尝试的值。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="049f" class="mr ms it mn b gy mt mu l mv mw">parameters = {‘batch_size’: [25, 32], ‘nb_epoch’: [100, 500], ‘optimizer’: [‘adam’, ‘rmsprop’]}</span></pre><p id="f2b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你注意到上面，我们有一个参数<strong class="lb iu">优化器</strong>用于<em class="lv"> build_classifier() </em>函数。该参数提供了一种调优优化器的方法。为了实现网格搜索，我们首先用分类器和参数创建一个<em class="lv"> GridSearchCV </em>类的对象。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="f9e9" class="mr ms it mn b gy mt mu l mv mw">grid_search = GridSearchCV(estimator=classifier, param_grid =parameters, scoring = ‘accuracy, cv = 10’)</span></pre><p id="bfe4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们在运行网格搜索以找到最佳参数的同时，在训练集上拟合 ANN。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="8b53" class="mr ms it mn b gy mt mu l mv mw">grid_search = grid_search.fit(X_train, y_train)</span></pre><p id="1aec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们最感兴趣的是产生最高精度的最佳参数。所以有了下文:</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="8ea7" class="mr ms it mn b gy mt mu l mv mw">best_parameters = grid_search.best_params_<br/>best_accuracy = grid_search.best_score_</span></pre><p id="167d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，几个小时后，我们的精确度提高到了 0.849 ✨✨.最佳参数是批处理大小 25、纪元编号 500 和优化器 Adam，如图 3 所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/58e8e7fa7bf6f6fcdbd52243d0a284f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*EsiqC2tujwI4f7XhKKwczA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3 参数调整的精度</p></figure><p id="d324" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.<strong class="lb iu">总结</strong></p><p id="e8e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">综上所述，通过交叉验证，我们发现该模型的精度约为 0.843。通过使用随机丢弃正则化和网格搜索，我们将模型精度提高到 0.849。通常，网格搜索可以分两步进行，第一步是找到大致范围，另一小步是细化最佳范围。</p><p id="c52b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">太好了！仅此而已！✨✨If 你需要一些额外的，访问我的</strong> <a class="ae ky" href="https://github.com/luke4u/Customer_Behaviour_Prediction" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Github </strong> </a> <strong class="lb iu">页面。(仅供参考，回购得到积极维护💕💕)</strong></p></div></div>    
</body>
</html>