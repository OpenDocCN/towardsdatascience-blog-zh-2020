<html>
<head>
<title>Single-Parameter Models | Pyro vs. STAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单参数模型| Pyro 与 STAN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/single-parameter-models-pyro-vs-stan-e7e69b45d95c?source=collection_archive---------32-----------------------#2020-07-15">https://towardsdatascience.com/single-parameter-models-pyro-vs-stan-e7e69b45d95c?source=collection_archive---------32-----------------------#2020-07-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dd8e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用两种贝叶斯方法模拟美国癌症死亡率:斯坦的 MCMC 和 T2 的 SVI。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/72712276bf7847c568f4fd5f40f2cb87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37NAnn3-M23Agso-b6Gwqg.jpeg"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">模拟美国各县的死亡率——照片由 Joey Csunyo 在 Unsplash 上拍摄</p></figure><p id="234f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">单参数模型是开始概率建模主题的极好方法。这些模型包括一个影响我们观察的参数，我们可以从给定的数据中推断出来。在本文中，我们着眼于性能并比较两个成熟的框架——统计语言 STAN 和 Pyro 概率编程语言(PPL)。</p><h1 id="5659" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">肾癌数据</h1><p id="a0ba" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">一个古老而确定的数据集是美国 1980-1989 年的肾癌病例，可在<a class="ae kf" href="http://www.stat.columbia.edu/~gelman/book/data/cancer/" rel="noopener ugc nofollow" target="_blank">这里</a>获得(见【1】)。给出了美国各县、其总人口和报告的癌症死亡病例。我们的任务是用贝叶斯方法从给定的数据中推断出死亡率。<br/> <em class="mp">任务的详细走查可以在“贝叶斯数据分析 3”【1】的 2.8 节中找到。</em> <br/>我们的数据帧看起来像这样:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/d6b576123ce9d47b6777a0300f120c01.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*zGGTWg7LTWGTIWgT_fpx4w.png"/></div></figure><p id="2e3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们有数据点总数<strong class="ky ir"> N </strong>(数据框中的所有行)，每个县有观察到的死亡数(dc)，我们称之为<strong class="ky ir"> y </strong>和人口数(pop)，我们稍后称之为<strong class="ky ir"> n </strong>。<br/>鉴于我们有流行病学数据，我们认为泊松分布为估计我们想要计算的比率提供了良好的基础。因此，我们的观察值<strong class="ky ir"> y </strong>是从<strong class="ky ir">泊松分布</strong>中采样的。有趣的参数是泊松的λ，我们称之为速率。这个死亡率来自伽马分布(见第 2 章[1]的解释)。一个非常简短的解释，为什么我们在这里使用γ，是因为它是关于泊松的共轭先验。<br/>尽管这些分布有更多的特殊关系<a class="ae kf" href="http://www.math.ntu.edu.tw/~hchen/teaching/StatInference/notes/lecture17.pdf" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="f4ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">把它放在一起，我们得出死亡病例的观察公式:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/9d8f6e000e6aa174d5858971fe03ca64.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*Rdl0pxPMXWQdTd-FcIunpg.png"/></div></figure><p id="c485" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">而对于想要的<em class="mp">单参数</em>速率:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/176f21c242cdcb0997437a7e6e99528e.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*EkSjdx8x8iQPAZfD0YfyLQ.png"/></div></figure><p id="c4ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经看到了任务，让我们启动工具开始工作。</p><h1 id="7369" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">STAN——经典统计模型</h1><p id="4404" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">统计学家公认的工作语言是统计语言。<br/>你把你的问题写成模型代码，斯坦会在幕后编译一个高效的 C++模型。从一个编译的模型中，你可以取样并执行推理。该框架提供了不同的<a class="ae kf" href="https://mc-stan.org/users/interfaces/" rel="noopener ugc nofollow" target="_blank">接口</a>，例如 Python (PyStan)、R (RStan)、Julia 等。对于本文，我们将使用<strong class="ky ir"> PyStan </strong>，这样我们就可以将两种模型整齐地并排放在一个笔记本中。<br/>我们开始定义我们在 STAN 中给出的数据。这意味着整数<strong class="ky ir"> N </strong>表示数据集的总大小，<strong class="ky ir"> y </strong>表示观察到的死亡人数，<strong class="ky ir"> n </strong>表示每个县的人口数。这样我们每个人都有 N 次。</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="75a3" class="my lt iq mu b gy mz na l nb nc">kidney_cancer_code="""<br/>data {<br/>   int N; // total observations<br/>   int y[N]; // observed death-count<br/>   vector[N] n; // population<br/>}<br/>...</span></pre><p id="144b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们已经知道，像死亡率θ这样的速率参数有界在[0，1]内。这意味着利率不能小于 0 或大于 1。<br/>该θ参数是实际比率的基础，即一个县的人口数。因此，由于我们转换了我们的参数，我们将其放入<em class="mp">转换参数</em>括号中。：</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="baee" class="my lt iq mu b gy mz na l nb nc">...<br/>parameters {<br/>   vector&lt;lower=0,upper=1&gt;[N] theta; // bounded deathrate estimate<br/>}</span><span id="d408" class="my lt iq mu b gy nd na l nb nc">transformed parameters {<br/>   vector[N] rate=n .* theta;<br/>}<br/>...</span></pre><p id="6a52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在到了神奇的推理部分，这就是后验概率的意义所在。我们从伽玛分布中对θ进行采样。α (=20)和β (=430000)在[1]中给出，但人们可以很容易地从基础数据集计算出它们。请注意，模型实际上采用了转换后的参数，而不仅仅是θ。这将在稍后的输出中变得明显。</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="d11b" class="my lt iq mu b gy mz na l nb nc">...<br/>model {<br/>   theta ~ gamma(20,430000);<br/>   y ~ poisson(rate);<br/>}<br/>"""</span></pre><p id="869f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们有了一个字符串形式的 STAN 模型，我们需要正确格式的数据。这意味着数据中的整数数组，就像这样:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="b8ed" class="my lt iq mu b gy mz na l nb nc">dc = data["dc"].to_numpy().astype(int)<br/>pop = data['pop'].to_numpy().astype(int)<br/>kidney_cancer_dat = {'N': N,<br/>                    'y': dc[0:N],<br/>                    'n': pop[0:N]}</span></pre><p id="a014" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于一切都已设置好，我们可以使用 PyStan 将我们的模型转换成 C++代码，并使用采样来执行推理。推理过程是马尔可夫链蒙特卡罗或 MCMC。必要的参数是我们采集的样本量(迭代)和我们绘制样本的链的数量。每条链都是有序的抽奖序列。</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="ee58" class="my lt iq mu b gy mz na l nb nc">sm = pystan.StanModel(model_code=kidney_cancer_code)<br/>fit = sm.sampling(data=kidney_cancer_dat, iter=5000, chains=4)</span></pre><p id="c341" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">拟合完成后，首先要检查的是模型是否收敛。这意味着 R(-hat)&gt; = 1，或者我们可以直接询问诊断工具:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="4adb" class="my lt iq mu b gy mz na l nb nc">stan_utility.check_all_diagnostics(fit)</span><span id="00de" class="my lt iq mu b gy nd na l nb nc">### the below lines are output:<br/>n_eff / iter looks reasonable for all parameters<br/>Rhat looks reasonable for all parameters<br/>0.0 of 10000 iterations ended with a divergence (0.0%)<br/>0 of 10000 iterations saturated the maximum tree depth of 10 (0.0%)<br/>E-BFMI indicated no pathological behavior</span></pre><p id="698a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还可以从执行的推理的轨迹中看到链已经收敛(右图):</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="23a9" class="my lt iq mu b gy mz na l nb nc">az.plot_trace(fit,var_names=['theta'])</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/1e8f98d621b57b4208841187a5f63467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*6K-6nqqMMu2pnd-G6dAjzQ.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated"><em class="nf">图 1——θ后验计算的轨迹图。右侧的采样链显示收敛。每条链都有一个 theta 的密度函数(左侧)，显示了数值的一致性。</em></p></figure><p id="391f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">链条(图 1 右侧)应该看起来像“疯狂相爱的毛毛虫”，诊断看起来也不错。这意味着我们的模型已经收敛。我们现在可以看看推断的θ值和个体密度:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="47ee" class="my lt iq mu b gy mz na l nb nc">az.plot_density(fit, var_names=["theta"])</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/b9574e6268bd3752f241e406c08cb752.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*CsrnFQIRelVyObuQoD6L2w.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated"><em class="nf">图 2——推断后拟合单参数θ的后验密度。</em></p></figure><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="94b7" class="my lt iq mu b gy mz na l nb nc">Warning: Do not use the complete dataset as input! This will lead to errors,<br/>we went with N=25 samples for testing purposes. Feel free to test how many samples it takes to break PyStan (or STAN).</span></pre><p id="f566" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了完成贝叶斯回归任务，也有不同的模块让你跳过“写一个精心制作的统计模型”的部分。<a class="ae kf" href="https://github.com/paul-buerkner/brms" rel="noopener ugc nofollow" target="_blank"><em class="mp">【BRMS】</em></a><em class="mp">在 R 就是那些优秀的工具之一。</em></p><h1 id="eeae" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">概率规划方法</h1><p id="d8da" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">提供一个完全不同的范例是 Pyro。我们不是通过采样来执行 MCMC，而是将我们的任务视为优化问题。<br/>为此，我们制定了一个模型，它计算我们的后验概率(<strong class="ky ir"> p </strong>)。此外，我们还制定了一个所谓的指南，为我们提供了一个参数化分布(<strong class="ky ir"> q </strong>)，用于模型拟合过程。<br/> <em class="mp">在之前的故事中，我们已经了解了这种优化的工作原理，并推荐一个简短的回顾。</em></p><div class="nh ni gp gr nj nk"><a rel="noopener follow" target="_blank" href="/compute-the-incomputable-how-svi-and-elbo-work-505ce0868fdd"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd ir gy z fp np fr fs nq fu fw ip bi translated">计算无法计算的| SVI 和艾尔波是如何工作的</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">贝叶斯建模与真实世界数据一起工作的一个原因。随机海洋中的近似灯塔。</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny kq nk"/></div></div></a></div><p id="38cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型不太直观的部分是，我们不是简单地拟合一个参数，而是由四个 Pyro 参数组成。：</p><ol class=""><li id="2b1a" class="nz oa iq ky b kz la lc ld lf ob lj oc ln od lr oe of og oh bi translated">首先，α和β是常数，它们赋予我们的伽马分布形状，就像我们在 STAN 部分所做的那样，</li><li id="cd51" class="nz oa iq ky b kz oi lc oj lf ok lj ol ln om lr oe of og oh bi translated">我们添加了两个钻孔可训练参数 p1 和 p2，这允许在 SVI 步骤中进行优化。两个参数都是正的，因此约束=约束。</li><li id="def7" class="nz oa iq ky b kz oi lc oj lf ok lj ol ln om lr oe of og oh bi translated">当浏览数据时，观察本身是独立的事件。<br/>这是通过 Pyro 的平板建模完成的，它也支持从我们的数据集中进行二次采样。在[2]中可以找到对此的很好的介绍。</li></ol><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="9383" class="my lt iq mu b gy mz na l nb nc">ϵ = 10e-3<br/>def model(population, deathcount):<br/>    α = pyro.param('α', torch.tensor(20.))<br/>    β = pyro.param('β', torch.tensor(430000.))<br/>    p1= pyro.param('p1', torch.ones(data.shape[0]), constraint=constraints.positive)<br/>    p2 = pyro.param('p2', torch.ones(data.shape[0]), constraint=constraints.positive)<br/>    with pyro.plate('data', data.shape[0], subsample_size=32) as idx:<br/>        n_j = population[idx]<br/>        y_j = deathcount[idx]<br/>        α_j = α + p1[idx]*y_j<br/>        β_j = β + p2[idx]*n_j<br/>        θ_j = pyro.sample("θ", Gamma(α_j, β_j))<br/>        λ_j = 10*n_j*θ_j + ϵ<br/>        pyro.sample('obs', Poisson(λ_j), obs=y_j)</span></pre><p id="f9b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型对给定泊松分布的观测值进行采样。这与 STAN 所做的工作相当，不同之处在于构成λ和底层分布的参数现在是可训练的 Pyro 参数。<br/>为了使我们的模型不被烧毁，我们必须在速率中加入一个小数值ϵ，否则泊松对象在后面的计算中将会不稳定:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="8ad5" class="my lt iq mu b gy mz na l nb nc">λ_j = 10*n_j*θ_j + ϵ</span><span id="06ea" class="my lt iq mu b gy nd na l nb nc">This is not the best way to model this task, but it is closest to the STAN model. One can find a model and guide that do not rely on <strong class="mu ir">y</strong> and <strong class="mu ir">n</strong> for computing α and β.</span></pre><p id="5f14" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，指南为我们提供了一个参数化分布<strong class="ky ir"> q </strong>，我们可以使用它来执行优化，以最小化证据下限或 ELBO。参数是可训练的烟火参数，我们已经在模型中看到了。</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="3d03" class="my lt iq mu b gy mz na l nb nc">def guide(population, deathcount):<br/>    α = pyro.param('α', torch.tensor(20.))<br/>    β = pyro.param('β', torch.tensor(430000.))<br/>    p1 = pyro.param('p1', torch.ones(data.shape[0]), constraint=constraints.positive)<br/>    p2 = pyro.param('p2', torch.ones(data.shape[0]), constraint=constraints.positive)<br/>    with pyro.plate('data', data.shape[0], subsample_size=32) as idx:<br/>        n_j = population[idx]<br/>        y_j = deathcount[idx]<br/>        α_j = α + p1[idx]*y_j<br/>        β_j = β + p2[idx]*n_j<br/>        θ_j = pyro.sample("θ", Gamma(α_j, β_j))</span></pre><p id="1685" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以像这样继续运行我们的随机变分推理:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="16a4" class="my lt iq mu b gy mz na l nb nc">svi = SVI(model, guide, Adam({'lr': 0.025}), JitTrace_ELBO(3))<br/>for i in tqdm(range(1000)):<br/>    loss = svi.step(population, deathcount)<br/>    print(f"Loss: {loss}")</span></pre><p id="3a2a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们绘制损失图时(见图 3)，我们可以看到模型随着时间的推移而改进。界限越低越好。损失是迭代过程中的 ELBO 轨迹。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi on"><img src="../Images/95235aa8000cc9e4f536f43cdd7dadd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*nwPmffdZw8otT-_LfStsZw.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated"><em class="nf">图 3——迭代过程中的 SVI 损失。Loss 是经过 1000 次迭代后从 SVI 步骤返回的 ELBO。</em></p></figure><p id="c71f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在进行最后的检查，我们可以看到我们已经安装了合适的参数。我们的模型发现的α和β变量为我们的后验推断提供了一个很好的基础伽马分布。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/f7551cbbcd90a200788ec828569f18e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*SojxP1R3uf_1vqXtqX3pDA.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">优化步骤后拟合的 Pyro 参数</p></figure><h1 id="1266" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论——什么方法是最好的？</h1><p id="ff27" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">斯坦有一种简单明了的方式来推理这个模型。如果后验概率的数学公式是已知的，那么实现一个模型是非常简单的。然而，STAN 及其 MCMC 采样有其局限性。在<em class="mp">默认配置</em>下，不可能在所有数据上运行我们的模型。<br/> Pyro 在高效处理大型数据集和执行变分推理方面表现出色。作为一种概率编程语言，它可以像任何其他 Python 代码一样编写。模型和指南也提供了丰富的信息，很好地概括了问题。通过这种方法，我们将后验计算转化为优化任务，并得到合理的输出。</p><p id="2748" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">既然您已经熟悉了单参数模型，那么就享受处理更大、更复杂任务的乐趣吧。<a class="ae kf" href="https://pyro.ai/examples/" rel="noopener ugc nofollow" target="_blank">烟火示例</a>是一个很好的起点。</p><p id="6e19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快乐推断！</p><h1 id="b126" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="f034" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">[1] A .盖尔曼、J.B .卡林等人。艾尔。、<a class="ae kf" href="http://www.stat.columbia.edu/~gelman/book/" rel="noopener ugc nofollow" target="_blank"> <em class="mp">贝叶斯数据分析</em> </a>。第三版。<br/>【2】Pyro 文档<a class="ae kf" href="https://pyro.ai/examples/svi_part_ii.html" rel="noopener ugc nofollow" target="_blank"> <em class="mp"> SVI 第二部</em> </a></p></div></div>    
</body>
</html>