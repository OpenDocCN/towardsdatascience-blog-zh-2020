<html>
<head>
<title>Baby Steps Towards Data Science: Random Forest Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">迈向数据科学的一小步:Python 中的随机森林回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/baby-steps-towards-data-science-random-forest-regression-in-python-d896fca5665a?source=collection_archive---------52-----------------------#2020-07-31">https://towardsdatascience.com/baby-steps-towards-data-science-random-forest-regression-in-python-d896fca5665a?source=collection_archive---------52-----------------------#2020-07-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8557" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解随机森林回归背后的直觉，并用 python 实现。提供源代码和数据集。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a48536cc7fb592e17cd2f4de9ce46704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2EqZC4xf0HZUJ6JW"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基思·琼森在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="8c32" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">什么是随机森林回归？</h1><p id="e2a7" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">随机森林算法是我的最爱之一。它可用于分类和回归。用更简单的语言来说，随机森林收集来自各种决策树的预测，并给出这些预测的平均值。这样，预测就有可能实际上收敛到真实值。每个决策树仅在数据子集上实现。该子集由算法随机选择，其中随机选取一个观察值并替换回数据集中，随机选择另一个观察值，添加到数据子集；这就是通常所说的自举。因此，您可以理解，单个观察可以多次成为决策树的一部分，因为我们替换了数据集中的观察并进行随机选择。对于多个决策树，这个过程重复多次。所有这些决策树统称为随机森林，现在，你确切地知道为什么使用随机和森林这两个词了。</p><p id="f78d" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这里的基本思想是在不同的数据样本上训练每棵树，并使用它们预测的平均值作为最终输出。这个输出的方差很小，很容易理解。</p><p id="936c" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我可以强烈地说，随机森林比单一决策树更好。为什么？这是因为结果更加稳健。每一棵决策树都有自己的信息，并做出相应的预测。当我们组合所有这样的树时，结果预计会更加准确，并且接近平均真实值。</p><p id="2dd0" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我将使用我在决策树文章中使用的相同数据集，这样您可以看到预测中的差异。</p><h1 id="b9d8" class="lg lh it bd li lj mz ll lm ln na lp lq jz nb ka ls kc nc kd lu kf nd kg lw lx bi translated">用 Python 实现</h1><p id="bba3" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">让我们深入研究 python，建立一个随机森林回归模型，并尝试预测一个 6.5 级别的员工的工资(假设)。</p><p id="26e7" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在您继续之前，请从我的 GitHub Gist 下载 CSV 数据文件。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="75ff" class="nj lh it nf b gy nk nl l nm nn"><a class="ae ky" href="https://gist.github.com/tharunpeddisetty/8c3213de90fdc50c5814dbadcba181ac" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/tharunpeddisetty/8c3213de90fdc50c5814dbadcba181ac</a><br/>Once you open the link, you can find "Download Zip" button on the top right corner of the window. Go ahead and download the files.<br/>You can download 1) python file 2)data file (.csv)<br/>Rename the folder accordingly and store it in desired location and you are all set.If you are a beginner I highly recommend you to open your python IDE and follow the steps below because here, I write detailed comments(statements after #.., these do not compile when our run the code) on the working of code. You can use the actual python as your backup file or for your future reference.</span></pre><p id="28d5" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma iu"> <em class="no">导入库</em> </strong></p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="c505" class="nj lh it nf b gy nk nl l nm nn">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd</span></pre><p id="3c32" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma iu"> <em class="no">导入数据并定义 X 和 Y 变量</em> </strong></p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="01a5" class="nj lh it nf b gy nk nl l nm nn">dataset = pd.read_csv(‘/Users/tharunpeddisetty/Desktop/Position_Salaries.csv’) #add your file path</span><span id="2078" class="nj lh it nf b gy np nl l nm nn">X = dataset.iloc[:,1:-1].values<br/>y = dataset.iloc[:, -1].values</span><span id="b4de" class="nj lh it nf b gy np nl l nm nn">#iloc takes the values from the specified index locations and stores them in the assigned variable as an array</span></pre><p id="ede7" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma iu">让我们看看我们的数据，了解变量:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/2e7b6c01f37c646b6c4973e7acef3f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/0*_6zTEv8-CvpS1zPL.png"/></div></figure><p id="6cfc" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">该数据描述了员工的职位/级别及其工资。这与我在决策树回归文章中使用的数据集相同。</p><p id="0843" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma iu"> <em class="no">训练模型</em> </strong></p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="2817" class="nj lh it nf b gy nk nl l nm nn">from sklearn.ensemble import RandomForestRegressor<br/>regressor = RandomForestRegressor(random_state=0,n_estimators=10)<br/>regressor.fit(X,y)</span><span id="bcde" class="nj lh it nf b gy np nl l nm nn">#random_state is the seed value, just to make sure we both get same results.<br/>#n_estimators defines the number of trees you want to implement </span></pre><p id="fd17" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma iu"> <em class="no">可视化决策树回归的结果</em> </strong></p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="b9e8" class="nj lh it nf b gy nk nl l nm nn">X_grid = np.arange(min(X), max(X), 0.1)<br/>X_grid = X_grid.reshape((len(X_grid), 1))<br/>plt.scatter(X, y, color = 'red')<br/>plt.plot(X_grid,regressor.predict(X_grid), color = 'blue')<br/>plt.title('Random Forest Tree')<br/>plt.xlabel('Position level')<br/>plt.ylabel('Salary')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/0ee947fd99af75a385671cf2a16a300a.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*bxXgHG6vbBW56UMenp5LZw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/ecc53fd4cbae7ccdabba83fad04224f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*1moc1GV6TI6VpkSrJ5g9mg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片(不包括代码)</p></figure><p id="8e8b" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这个可视化没有太多需要解释的。为了让你更好的理解和比较，我已经把我上一篇文章中决策树的可视化和预测结果包括进来了。</p><p id="45a2" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma iu"> <em class="no">使用决策树回归预测 6.5 级结果</em> </strong></p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="2af8" class="nj lh it nf b gy nk nl l nm nn">print(regressor.predict([[6.5]]))<br/># predict method expects a 2D array thats the reason you see [[6.5]]</span></pre><p id="60f1" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma iu"> <em class="no">结果</em> </strong></p><p id="4ff8" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">随机森林回归:167000</p><p id="4f82" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">决策树回归:150000(不属于代码的输出)</p><h1 id="08de" class="lg lh it bd li lj mz ll lm ln na lp lq jz nb ka ls kc nc kd lu kf nd kg lw lx bi translated">结论</h1><p id="3625" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">你可以亲眼看到随机森林回归比决策树预测的结果更真实。决策树对一个 6.5 级的员工预测了同样的工资，这似乎不太公平。当您查看随机森林预测时，它预测了 16.7 万美元，介于第 6 级和第 7 级之间，只要查看它，您就会发现它是有道理的。记住一件事，回归是所有关于平均行为和因素如何平均影响解释变量。</p><p id="e3d2" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">恭喜你！您已经用最少的代码行实现了随机森林回归。这很简单，对吗？。现在您有了代码的模板，您可以在其他数据集上实现它并观察结果。机器学习快乐！</p></div></div>    
</body>
</html>