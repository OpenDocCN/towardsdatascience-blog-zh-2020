<html>
<head>
<title>Custom NLP Approaches to Data Anonymization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据匿名化的定制 NLP 方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-approaches-to-data-anonymization-1fb5bde6b929?source=collection_archive---------6-----------------------#2020-01-08">https://towardsdatascience.com/nlp-approaches-to-data-anonymization-1fb5bde6b929?source=collection_archive---------6-----------------------#2020-01-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2492" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">消除真实世界私人数据身份的实用方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/87bb8f27674f18c2114b4cb9e61813a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZFJTLvxqvquk6Y74cd7Xhg.png"/></div></div></figure><p id="1f15" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着互联网服务变得无处不在，对互联网隐私的渴望持续增长。近年来，不同的法律，如 GDPR，开始规范服务收集私人信息的方式。这引起了每个公司对隐私方面的关注，并增加了在处理和匿名私人数据方面的投资。</p><p id="df0f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我在微软商业软件工程(CSE)团队的工作是与微软最具战略意义的客户合作。我们共同开发人工智能、大规模数据、物联网等领域的新工作负载。在与这些客户打交道的过程中，我们意识到 PII(个人身份信息)问题是许多希望扩展其解决方案集(无论是内部部署还是在云中)的公司反复提到的话题和障碍。</p><p id="0568" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，我们决定创建<a class="ae lq" href="https://aka.ms/presidio" rel="noopener ugc nofollow" target="_blank"> Presidio </a>，这是一个生产就绪的开源服务，免费提供给任何希望解决数据隐私问题的人。</p><p id="13cf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Presidio 允许任何用户创建标准且透明的流程，用于匿名化结构化和非结构化数据上的 PII 实体。为此，它公开了一组预定义的 PII 识别器(用于姓名、信用卡号和电话号码等常见实体)，以及一些工具，用于使用新的逻辑对其进行扩展，以识别更具体的 PII 实体。在这篇博文中，我们将关注如何利用自然语言处理来识别不同类型的私有实体。</p><h1 id="4455" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">PII 探测过程</h1><p id="3abb" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">Presidio 利用了一组识别器，每个识别器都能够检测一种或多种语言中的一个或多个 PII 实体。图 1 中描述的过程通常包括 8 个不同的步骤:</p><ol class=""><li id="3469" class="mo mp it kw b kx ky la lb ld mq lh mr ll ms lp mt mu mv mw bi translated">从用户处获取匿名化请求</li><li id="dd5e" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">将请求传递给预识别分析器以识别 PII 实体</li><li id="7875" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">提取自然语言处理特征(词条、命名实体、关键词、词性等。)，供各种识别器使用</li><li id="96f4" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">获取所有 PII 识别器(预定义+来自识别器存储服务的自定义)</li><li id="9398" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">运行所有识别器</li><li id="07c1" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">汇总结果</li><li id="4016" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">传递给预识别匿名器进行身份识别</li><li id="59c2" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated">将去标识的文本返回给呼叫者</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/95a02f670b57be37aac452e2fa17e711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*j1U_1OYeD9Q8i_crg4E9sQ.gif"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated"><em class="nh">图 1——presi dio</em>中识别过程的动画</p></figure><p id="17f4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">图 2 中的动画演示了一个特定示例的相同过程。请注意，当我们将上下文从“电话号码”更改为“pool card number”时，电话号码识别器的可信度会降低。这是 Presidio 演示的截图。<a class="ae lq" href="https://aka.ms/presidio-demo" rel="noopener ugc nofollow" target="_blank">看看这个</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/7764d8150ae36046236ab86ac715030e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*OQNkIqeAu-Zq1Kkz9R742Q.gif"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated"><em class="nh">图 2 —输入和输出示例</em></p></figure><h1 id="2f56" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">数据匿名的 NLP</h1><p id="a5f7" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">需要 PII 识别器来检测自由文本中不同类型的实体。对于这样的任务，不同的 NLP 方法浮现在脑海中:</p><ul class=""><li id="428b" class="mo mp it kw b kx ky la lb ld mq lh mr ll ms lp nj mu mv mw bi translated">对于共享一个模式的实体，我们可以利用周围单词的<strong class="kw iu">正则表达式</strong>、<strong class="kw iu">验证</strong>(例如<a class="ae lq" href="https://en.wikipedia.org/wiki/Checksum" rel="noopener ugc nofollow" target="_blank">校验和</a>)和<strong class="kw iu">上下文</strong>。例如，这种逻辑可以用来检测信用卡号或电话号码。</li><li id="3b18" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated">对于有限的选项列表，我们可以使用<strong class="kw iu">黑名单。</strong>它可以是静态黑名单(例如，所有头衔:<em class="nk">先生、女士、小姐、博士、教授……</em>)或动态黑名单(即，连接到数据库并查询所有可能的选项)。</li><li id="7f41" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated">对于可以使用特定逻辑识别的实体，我们可以编写基于<strong class="kw iu">规则的</strong>识别器。</li><li id="b3f3" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated">对于需要自然语言理解输入的实体，我们可以训练<strong class="kw iu">机器学习</strong>模型，特别是针对<strong class="kw iu">命名实体识别</strong> (NER)，或者使用预先训练好的模型。</li></ul><p id="3bdb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在下一节中，我们将重点介绍我们在提高人名、地点和组织的命名实体识别率方面所做的工作。</p><h1 id="3ab7" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">人名、地点和组织的 NER</h1><p id="5ccb" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">为了提高这三个实体的检测率，我们用不同的模型进行了实验。以下部分描述了使用的数据集、评估的不同模型和结果。运行这个过程的代码可以在我们的<a class="ae lq" href="https://github.com/microsoft/presidio-research" rel="noopener ugc nofollow" target="_blank"> GitHub repo for research </a>上找到。</p><h2 id="89ba" class="nl ls it bd lt nm nn dn lx no np dp mb ld nq nr md lh ns nt mf ll nu nv mh nw bi translated">数据集</h2><p id="3373" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">虽然有一些标注数据集可用，但我们希望增加名称、组织和位置的覆盖范围。因此，我们从一个带标签的数据集开始(例如，<a class="ae lq" href="https://catalog.ldc.upenn.edu/LDC2013T19" rel="noopener ugc nofollow" target="_blank"> OntoNotes </a>或<a class="ae lq" href="https://www.aclweb.org/anthology/W03-0419.pdf" rel="noopener ugc nofollow" target="_blank"> CoNLL-2003 </a>)，并对其进行处理以提取模板。这些例子后来被用来生成比原始数据集具有更广泛的实体值(名称、组织和位置)的新句子。</p><p id="e47d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">比如来自句子“谢谢你<strong class="kw iu"> <em class="nk">乔治</em> </strong>！”，其中 George 被手动标记为 person，我们提取了以下模板:“谢谢[PERSON]！”。图 3 提供了另一个例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/30990a63b334ed6bc1a743d200e5df78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1nYOPSHiu7cDJv9t5JXDGA.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated"><em class="nh">图 3 —数据扩充示例</em></p></figure><p id="1e32" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用了一个假的 PII 数据集和多个假的 PII 生成器来对实体进行采样并创建新的句子。这些句子在生成过程中被自动标记，因此训练新的 NER 模型很容易应用。</p><p id="0505" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，这一过程要求我们对数据集进行一些预处理，并针对不同的问题提出创造性的解决方案。仅举几个例子:</p><ul class=""><li id="2ee6" class="mo mp it kw b kx ky la lb ld mq lh mr ll ms lp nj mu mv mw bi translated">如何看待<em class="nk">国家</em>vs<em class="nk">国籍</em>？在许多情况下,“位置”实体指的是国籍(或民族男子或民族女子)。例如，在句子“<em class="nk">萨尔瓦多[LOC]拳手赢得世界冠军</em>”中，我们不能用“<em class="nk">埃塞尔比亚</em>”替换“<em class="nk">萨尔瓦多</em>”，因为这会使句子不正确。因此，我们为国家、民族、民族-男人和民族-女人创造了新的中间实体。</li><li id="69d3" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated"><em class="nk">性别</em>应该如何处理？有些句子最初谈论的是男性或女性，但在数据生成过程中，我们可能会用异性的名字替换一个名字。</li><li id="64ec" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated">现实生活中的知识重要吗？如果原句描述的是两个国家之间的冲突，是不是就应该用任意的国名来代替这些国家？</li><li id="eec2" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated">数据集中的一些人名是机构或组织的名称，如“艾伦人工智能研究所”或“特朗普政府”。在这种情况下，我们是否应该用一个任意的名字来代替“特朗普”？</li></ul><p id="b2da" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从 8000 个独特的模板中，我们提取了 80000 个不同的标记句子。我们还获得了比以前更干净的数据集，因为在这个过程中处理了许多未标记的实体。新数据集被分成训练/测试/验证集，来自同一模板的样本不会出现在多个集中。此外，我们将 10%的样本设为小写，因为这通常代表了部署模型时我们可能遇到的小写文本的比例。<strong class="kw iu">据我们所知，这是迄今为止最大的 PII 数据集</strong>。</p><h2 id="b4bc" class="nl ls it bd lt nm nn dn lx no np dp mb ld nq nr md lh ns nt mf ll nu nv mh nw bi translated">模型</h2><p id="1f83" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">评估了不同的建模方法。具体来说，我们研究了条件随机场、基于空间的模型和基于天赋的模型。</p><p id="e475" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> spaCy: </strong> spaCy 是一个生产级的 NLP 库，用于标记化、词性标注、实体提取、文本分类等。它包含了一个卷积神经网络模型<a class="ae lq" href="https://spacy.io/usage/facts-figures#benchmarks" rel="noopener ugc nofollow" target="_blank">，被认为是最快的深度学习 NLP 模型</a>。虽然其他模型在公共数据集上具有更高的准确性，但它们可能需要更长的训练和推理时间。spaCy 还提供了快速标记化和词条化，用于 Presidio 中的上下文分析模块。我们评估了不同风格的空间:首先，我们查看了预训练空间模型(2.1.0 和 2.2.0)的结果，然后，我们查看了预训练空间模型的微调，最后，在利用预训练单词嵌入(FastText)的同时，从头开始训练空间模型。</p><p id="c310" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> Flair: </strong> Flair 是一个深度学习 NLP 工具包，在公共数据集上有很好的结果。它建立在 PyTorch 之上，具有特殊的嵌入技术(称为<a class="ae lq" href="https://drive.google.com/file/d/17yVpFA7MmXaQFTe-HDpZuqw9fJlmzg56/view" rel="noopener ugc nofollow" target="_blank"> Flair 嵌入</a>)和预测模型。此外，它还提供了与其他嵌入模型(如 BERT、ELMo)的轻松集成，以及来自不同模型和来源的嵌入的堆叠。我们评估了两种不同的基于 Flair 的模型:具有 BERT 嵌入的 Flair 模型，以及具有 Flair 嵌入和手套嵌入的堆叠的 Flair 模型。</p><p id="6729" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">条件随机场(CRF):</strong>CRF 是一类用于序列标记的方法。这些有区别的图形模型学习预测之间的依赖性，并且是命名实体识别任务的自然适合。在引入递归和卷积神经网络之前，CRFs 在公共数据集上的 NER 任务上取得了最先进的性能。它们在训练和预测方面比基于神经网络的模型快得多，并且提供相对可解释的结果。我们使用 L-BGFS 优化，使用<a class="ae lq" href="https://sklearn-crfsuite.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> sklearn-crfsuite Python 包</a>，只评估了普通的 CRF 模型。</p><p id="fb4e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">总之，以下是我们试验过的模型:</p><ol class=""><li id="650a" class="mo mp it kw b kx ky la lb ld mq lh mr ll ms lp mt mu mv mw bi translated">使用默认的预训练模型进行评估:</li></ol><ul class=""><li id="c0b4" class="mo mp it kw b kx ky la lb ld mq lh mr ll ms lp nj mu mv mw bi translated">空间<strong class="kw iu">2 . 1 . 0</strong></li><li id="282f" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated"><strong class="kw iu"> spaCy </strong> 2.2.0(其中<a class="ae lq" href="https://explosion.ai/blog/spacy-v2-2#models" rel="noopener ugc nofollow" target="_blank">对小写实体</a>有更好的支持)</li></ul><p id="3f17" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">2.从头开始训练:</p><ul class=""><li id="78cf" class="mo mp it kw b kx ky la lb ld mq lh mr ll ms lp nj mu mv mw bi translated"><strong class="kw iu">条件随机字段</strong> (CRF)</li></ul><p id="9233" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">3.使用预训练嵌入进行训练:</p><ul class=""><li id="4bbf" class="mo mp it kw b kx ky la lb ld mq lh mr ll ms lp nj mu mv mw bi translated"><strong class="kw iu">带有<strong class="kw iu">快速文本</strong>嵌入的空间</strong></li><li id="a5dd" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated"><strong class="kw iu">天赋</strong>与<strong class="kw iu">伯特</strong>嵌入</li><li id="7621" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated"><strong class="kw iu">天赋</strong>带<strong class="kw iu">手套</strong>和<strong class="kw iu">天赋</strong>嵌入</li></ul><p id="a726" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">4.微调现有的已训练模型:</p><ul class=""><li id="2f04" class="mo mp it kw b kx ky la lb ld mq lh mr ll ms lp nj mu mv mw bi translated">版本 2.2.0</li></ul><h2 id="44ba" class="nl ls it bd lt nm nn dn lx no np dp mb ld nq nr md lh ns nt mf ll nu nv mh nw bi translated">韵律学</h2><p id="911c" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">我们关注 PII/诺-PII 二元决策的 F2(回忆比精确更重要)。我们还研究了特定的 F2 类和计算性能。最后，可解释性是需要考虑的另一个因素。</p><h2 id="c591" class="nl ls it bd lt nm nn dn lx no np dp mb ld nq nr md lh ns nt mf ll nu nv mh nw bi translated">结果</h2><p id="51b9" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">如图 4 所示，所有模型都取得了不错的结果，但基于 Flair 的模型更胜一筹。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/17932beff4b733df5bf5cf863f5eda06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qxYa9fnVkT5pRpzuro3yNw.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图 4 —各种模型和实体的 F2 结果</p></figure><p id="5965" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">来自这些结果的一些见解:</p><ul class=""><li id="5d7e" class="mo mp it kw b kx ky la lb ld mq lh mr ll ms lp nj mu mv mw bi translated">基于 Flair 的模型比基于 spaCy 的模型获得了更高的结果，基于 spaCy 的模型在所有实体上获得了比 CRF 更高的结果。</li><li id="0174" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated">我们可以看到 spaCy 2.2.0 比 2.1.0 提供了更好的结果，但并没有太多。</li><li id="6246" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated">spaCy 和 CRF 模型与 Org 实体相冲突，Org 实体经常与人名相混淆。Flair 模型在 Org 上实现了更高的结果，这可能暗示对 Org 生成的假 PII 实体的过度拟合。</li><li id="1324" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp nj mu mv mw bi translated">训练空间模型或对其进行微调无法提高模型的 F2 分数。这可能是由于训练集的性质，它是从 spaCy 最初训练的同一数据集(OntoNotes)中导出的。其他数据来源可能会从微调或训练这些模型中受益。</li></ul><h2 id="3507" class="nl ls it bd lt nm nn dn lx no np dp mb ld nq nr md lh ns nt mf ll nu nv mh nw bi translated">计算性能</h2><p id="fcc5" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">虽然 Flair 模型获得了更高的 F2 分数，但是它们的训练和预测速度也慢得多。表 1 显示了使用各种评估方法的近似训练和推理时间。分析是在一台 GPU 机器<a class="ae lq" href="#_ftn1" rel="noopener ugc nofollow">【1】</a>上进行的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fe0e9a2659b33333c273c2ea8e0037d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VeeIi4-EKxZRd-QfDcFuFQ.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated"><em class="nh">表 1 —不同模型的推理和训练时间</em></p></figure><p id="0046" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="#_ftnref1" rel="noopener ugc nofollow">【1】</a>Azure 上的 NC6 实例:6 个 vCPU，56GiB 内存，半个 NVIDIA Tesla K80，GPU 内存 12GiB</p><h1 id="a9f4" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">结论</h1><p id="4c89" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">在这项工作中，我们评估了各种模型在 Presidio 中更好的检出率。我们考虑了检测率和计算性能之间的权衡，这在许多用例中是至关重要的。对于我们评估的数据集，我们发现没有实际的理由来替换我们在 Presidio 中使用的当前空间模型。然而，可以将数据扩充框架和不同的评估模型应用于新数据，并使 Presidio 面向更多特定领域的数据集。我们还看到，通过用 CRF 模型代替 spaCy，我们可以潜在地提高 Presidio 的运行时间。如果性能不是问题，例如对于离线作业，我们应该考虑使用基于 Flair 的方法，可能使用 Flair 嵌入+手套，以提高 Presidio 中的检测率。</p><p id="0085" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Presidio 是完全开源的，对任何希望解决数据隐私问题的人都是免费的。我们也欢迎贡献者，拉请求或任何类型的反馈。<a class="ae lq" href="https://github.com/microsoft/presidio" rel="noopener ugc nofollow" target="_blank">点击这里开始</a>。</p><h1 id="8e42" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">了解更多信息</h1><ol class=""><li id="4aaa" class="mo mp it kw b kx mj la mk ld nz lh oa ll ob lp mt mu mv mw bi translated"><a class="ae lq" href="https://aka.ms/presidio" rel="noopener ugc nofollow" target="_blank"> Presidio 的 GitHub 回购</a></li><li id="5c44" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated"><a class="ae lq" href="https://microsoft.github.io/presidio/" rel="noopener ugc nofollow" target="_blank">通用 Presidio 文档</a></li><li id="aa4c" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated"><a class="ae lq" href="https://github.com/microsoft/presidio-research" rel="noopener ugc nofollow" target="_blank">研究、数据集创建和建模代码</a></li></ol><h1 id="f19d" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">其他参考文献</h1><ol class=""><li id="fcf2" class="mo mp it kw b kx mj la mk ld nz lh oa ll ob lp mt mu mv mw bi translated"><a class="ae lq" href="https://spacy.io" rel="noopener ugc nofollow" target="_blank">空间</a></li><li id="0a6e" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated"><a class="ae lq" href="https://github.com/flairnlp/flair" rel="noopener ugc nofollow" target="_blank">天赋</a></li><li id="4181" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated"><a class="ae lq" href="https://www.fakenamegenerator.com/" rel="noopener ugc nofollow" target="_blank">假名字生成器</a></li><li id="36f2" class="mo mp it kw b kx mx la my ld mz lh na ll nb lp mt mu mv mw bi translated"><a class="ae lq" href="https://github.com/joke2k/faker" rel="noopener ugc nofollow" target="_blank">骗子</a></li></ol><h1 id="5364" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">关于作者</h1><p id="1501" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">Omri Mendels 是微软的高级数据科学家。你可以在<a class="ae lq" href="https://www.linkedin.com/in/omrimendels/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae lq" href="https://github.com/omri374/" rel="noopener ugc nofollow" target="_blank"> GitHub </a>或者<a class="ae lq" href="https://www.quora.com/profile/Omri-Mendels-1" rel="noopener ugc nofollow" target="_blank"> Quora </a>上和他联系。</p></div></div>    
</body>
</html>