<html>
<head>
<title>Extracting information from user commands</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从用户命令中提取信息</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/making-your-own-alexa-entity-extraction-8c7f23eb65a?source=collection_archive---------29-----------------------#2020-02-28">https://towardsdatascience.com/making-your-own-alexa-entity-extraction-8c7f23eb65a?source=collection_archive---------29-----------------------#2020-02-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="32dd" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/tag/making-your-own-alexa" rel="noopener">制作自己的 Alexa </a></h2><div class=""/><div class=""><h2 id="2bea" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">Alexa 怎么知道你想让她弹哪首歌</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/0fc7fe88a9c38e63178edbf9d34bda64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qRg8FDBF_db9o2-qgDgu2w.jpeg"/></div></div></figure><p id="5fac" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi lw translated">在过去的几年里，虚拟助理风靡了全世界。从像<a class="ae mf" href="https://developer.amazon.com/alexa" rel="noopener ugc nofollow" target="_blank"> Alexa </a>和<a class="ae mf" href="https://assistant.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Assistant </a>这样的虚拟家庭助手，到更专业的助手，比如美国银行的<a class="ae mf" href="https://promo.bankofamerica.com/erica/" rel="noopener ugc nofollow" target="_blank"> Erica </a>。这些助手的迅速崛起表明，我们与机器互动的方式正在发生变化和演变。</p><p id="16fd" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在这个由 3 部分组成的系列文章中，我们将介绍如何使用 Amazon Alexa 使用的域无关解析器<a class="ae mf" href="https://developer.amazon.com/blogs/alexa/post/36ca7d4c-cd98-40a9-a9c5-0cde2ab922ab/how-alexa-knows-that-peanut-butter-is-one-shopping-list-item-not-two?fbclid=IwAR0ctwBfmE7JUV7BR6Un_Fp54cMG9OdoLC2BurWk-HUxwbKYZShpqacm4lI" rel="noopener ugc nofollow" target="_blank">的一个较小版本和一个命令分类模型，在 Keras 中自下而上地编写自己的简单虚拟助手或聊天机器人。</a></p><p id="ecfa" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">阅读完本系列后，您将学会如何创建自己的虚拟助手，该助手足够简单，可以在 Raspberry Pi 或 AWS Lambda 上运行，但功能足够强大，可以用作企业解决方案的基础。</p><p id="2892" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial" rel="noopener ugc nofollow" target="_blank"> Github 懒人链接</a></p><h1 id="714c" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">概观</h1><p id="7a93" class="pw-post-body-paragraph la lb iq lc b ld my ka lf lg mz kd li lj na ll lm ln nb lp lq lr nc lt lu lv ij bi translated">该系列将分为三个部分:</p><ol class=""><li id="914d" class="nd ne iq lc b ld le lg lh lj nf ln ng lr nh lv ni nj nk nl bi translated">从用户命令中提取重要的值和信息</li><li id="e9b9" class="nd ne iq lc b ld nm lg nn lj no ln np lr nq lv ni nj nk nl bi translated">意图分类</li><li id="a3df" class="nd ne iq lc b ld nm lg nn lj no ln np lr nq lv ni nj nk nl bi translated">语音命令、唤醒词、知识图表和应用程序</li></ol><p id="9ab6" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">每篇文章将涵盖一个单独的主题，这是制作语音导航虚拟助理不可或缺的。这第一篇文章将教你如何从用户发送的命令中提取实体。第二部分将教你如何构建一个网络，对命令进行分类，以便它们可以被发送到正确的意图处理器，允许你的助手处理多个意图。第三部分将介绍一些不同的想法，关于如何在你的助手中加入对语音命令的支持以及其他各种改进。</p><h1 id="6865" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">背景</h1><p id="ff61" class="pw-post-body-paragraph la lb iq lc b ld my ka lf lg mz kd li lj na ll lm ln nb lp lq lr nc lt lu lv ij bi translated">想象一下，你在一家银行工作，你的工作是为客户在账户之间转账。一天，一位顾客走进来，提出了以下要求:</p><blockquote class="nr"><p id="0e8b" class="ns nt iq bd nu nv nw nx ny nz oa lv dk translated">"你能从我的储蓄账户转 50 美元到马克的账户上吗"</p></blockquote><p id="a254" class="pw-post-body-paragraph la lb iq lc b ld ob ka lf lg oc kd li lj od ll lm ln oe lp lq lr of lt lu lv ij bi translated">为了能够满足这个请求，作为一名工作人员，您需要能够从请求中提取三个关键值。您需要提取:</p><ul class=""><li id="d348" class="nd ne iq lc b ld le lg lh lj nf ln ng lr nh lv og nj nk nl bi translated">他们想转账多少(50 美元)</li><li id="124b" class="nd ne iq lc b ld nm lg nn lj no ln np lr nq lv og nj nk nl bi translated">从哪个账户(你的储蓄账户)</li><li id="0132" class="nd ne iq lc b ld nm lg nn lj no ln np lr nq lv og nj nk nl bi translated">谁应该收到钱(马克)</li></ul><p id="1e1a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">由于我们从出生起就被训练从语言中提取信息，这项任务对一个人来说很容易，但对一台计算机来说却很棘手。模拟这一过程并准确提取这一信息是我们的模型将面临的挑战。为此，我们将使用<a class="ae mf" href="https://en.wikipedia.org/wiki/Named-entity_recognition" rel="noopener ugc nofollow" target="_blank">命名实体识别</a>。</p><h2 id="31d1" class="oh mh iq bd mi oi oj dn mm ok ol dp mq lj om on ms ln oo op mu lr oq or mw iw bi translated">命名实体识别</h2><p id="5e04" class="pw-post-body-paragraph la lb iq lc b ld my ka lf lg mz kd li lj na ll lm ln nb lp lq lr nc lt lu lv ij bi translated">命名实体识别(NER)是信息抽取的一个子任务，它试图在非结构化文本(或半结构化文本)中定位命名实体。NER 的目标是给序列中的每一个单词加上标签，代表这个单词所属的实体的种类。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi os"><img src="../Images/ff97242c6a794e109e1f751f089b7c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UxAv63SMoSpg5-TaTZG0Rw.png"/></div></div><p class="ot ou gj gh gi ov ow bd b be z dk translated">图 1:给音乐服务的命令中的命名实体的例子</p></figure><p id="f569" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">图 1 展示了一个通过 NER 模型解析的句子的例子。使用<a class="ae mf" href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)" rel="noopener ugc nofollow" target="_blank"> IOB 方案</a>(内部-外部-开始)标记句子中的每个单词，并附加一个连接标签来标记用于连接不同命名实体的单词。这些标签然后被用来从我们的命令中提取实体。从图 1 中的标签，我们可以提取出我们希望服务播放的歌曲是“波西米亚狂想曲”，艺术家是“女王”。</p><p id="cc72" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">既然我们知道了问题以及我们将使用什么方法来解决它，那么是时候开始编码了！</p><h1 id="bef7" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">履行</h1><h2 id="ddfb" class="oh mh iq bd mi oi oj dn mm ok ol dp mq lj om on ms ln oo op mu lr oq or mw iw bi translated">数据</h2><p id="9e0c" class="pw-post-body-paragraph la lb iq lc b ld my ka lf lg mz kd li lj na ll lm ln nb lp lq lr nc lt lu lv ij bi translated">在我们写真正的代码之前，我们需要一些实际的数据来处理。幸运的是，我们准备了<a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/tree/master/commands" rel="noopener ugc nofollow" target="_blank">示例数据</a>，我们将在本文中使用这些数据。</p><pre class="kp kq kr ks gt ox oy oz pa aw pb bi"><span id="3c95" class="oh mh iq oy b gy pc pd l pe pf">{<br/> "labels": [<br/>      "O", <br/>      "CC", <br/>      "B-song", <br/>      "I-song", <br/>      "B-artist", <br/>      "I-artist",          <br/>      "B-playlist", <br/>      "I-playlist"<br/> ], <br/> "training_data": [<br/> {<br/>      "words": [<br/>          "play", <br/>          "don't", <br/>          "pan", <br/>          "me", <br/>          "by", <br/>          "alberta", <br/>          "hunter"<br/>      ], <br/>      "labels": [<br/>          "O", <br/>          "B-song", <br/>          "I-song", <br/>          "I-song", <br/>          "CC", <br/>          "B-artist", <br/>          "I-artist"<br/>      ]<br/> }<br/> ]<br/>}</span></pre><p id="9c64" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">上面的摘录展示了我们将要使用的数据模式的一个例子。我们已经将该命令所有可能的标签编译到<code class="fe pg ph pi oy b">labels </code>中，并将所有命令标记化并标注到<code class="fe pg ph pi oy b">training_data</code>中，其中<code class="fe pg ph pi oy b">training_data['words']</code>是模型的输入序列，<code class="fe pg ph pi oy b">training_data['labels’]</code>是预期的输出序列。</p><h2 id="708d" class="oh mh iq bd mi oi oj dn mm ok ol dp mq lj om on ms ln oo op mu lr oq or mw iw bi translated">准备数据</h2><p id="2c37" class="pw-post-body-paragraph la lb iq lc b ld my ka lf lg mz kd li lj na ll lm ln nb lp lq lr nc lt lu lv ij bi translated">正如任何涉及神经网络的项目一样，我们需要在使用它们之前准备好序列。神经网络不喜欢被输入字符串或字符。他们喜欢冷冰冰的硬数字！</p><p id="0d94" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">所以首先，我们需要建立一个词汇表。词汇表是我们网络中所有已知单词的容器。这个词汇表将被我们的模型用来创建一个嵌入层(稍后会详细介绍)。</p><p id="9552" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">你可以使用一个预建的词汇和标记器，比如<a class="ae mf" href="https://fasttext.cc/" rel="noopener ugc nofollow" target="_blank"> FastText </a>或<a class="ae mf" href="https://github.com/google/sentencepiece" rel="noopener ugc nofollow" target="_blank"> SentencePiece </a>来为你的模型提供词汇，但是对于小型虚拟助手来说这是不必要的，只会导致模型变得臃肿，而不会有任何有意义的准确性增加。只有当您的用例需要更大的词汇表并从它们的包含中受益时，才使用它们！</p><p id="1005" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">例如，在我们对 FastText 的实验中，其中一个模型的大小约为 1GB。但是，对于较小的自定义词汇表，模型大小约为 15MB。两个版本在准确度、精确度和召回率上的差异几乎不存在。</p><p id="06aa" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">也就是说，让我们创建自己的自定义词汇表吧！</p><pre class="kp kq kr ks gt ox oy oz pa aw pb bi"><span id="75d3" class="oh mh iq oy b gy pc pd l pe pf">dataset = <a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/datautils.py#L9" rel="noopener ugc nofollow" target="_blank">Dataset</a>(schema_path, name)<br/>labels, data = dataset.get_data()</span><span id="f8e9" class="oh mh iq oy b gy pj pd l pe pf">X = [x['words'] for x in data]<br/>y = [x['labels'] for x in data]</span><span id="4504" class="oh mh iq oy b gy pj pd l pe pf"># Word vocabulary<br/>word_vocab = <a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/datautils.py#L83" rel="noopener ugc nofollow" target="_blank">Vocabulary</a>()<br/>word_vocab.build_vocab([w for command in X for w in command])</span><span id="8d61" class="oh mh iq oy b gy pj pd l pe pf"># Character vocabulary<br/>char_vocab = <a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/datautils.py#L83" rel="noopener ugc nofollow" target="_blank">Vocabulary</a>()<br/>char_vocab.build_vocab([ch for w in word_vocab for ch in w])</span></pre><p id="f6d5" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在上面的代码中，我们加载数据，并从数据集中的命令中收集所有唯一的单词和字符。除了所有的单词之外，我们还为以前没有见过的单词和字符在词汇表中添加了<code class="fe pg ph pi oy b">&lt;unk&gt;</code>和<code class="fe pg ph pi oy b">&lt;pad&gt;</code>标记。<code class="fe pg ph pi oy b">&lt;unk&gt;</code>令牌允许我们将词汇量保持在一个固定的大小，它允许模型处理它不认识的单词。<code class="fe pg ph pi oy b">&lt;pad&gt;</code>标记允许我们屏蔽序列中的填充，这样它就不会被误认为是命令的一部分。这个标记是必要的，因为我们的命令的长度可以变化，但是模型期望它们都是相同的长度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pk"><img src="../Images/0e4d0e81e848244ae7b8509d19f302c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XndFWwEfuMiauHai6jFLGw.jpeg"/></div></div><p class="ot ou gj gh gi ov ow bd b be z dk translated">图 2:一个映射函数的例子</p></figure><p id="f46a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在我们有了词汇表，我们需要创建一个映射函数来从单词映射到整数。这允许我们将数据集中的单词序列转换成整数序列。幸运的是，当单词被添加到字典中时，我们的<a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/datautils.py#L33" rel="noopener ugc nofollow" target="_blank">词汇表</a>类的实现已经为我们完成了这项工作。</p><p id="58d3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">最后，我们将为标签创建一个映射函数。</p><pre class="kp kq kr ks gt ox oy oz pa aw pb bi"><span id="8dfa" class="oh mh iq oy b gy pc pd l pe pf">labels2idx =  {label: idx for idx, label in enumerate(labels)}</span></pre><p id="6381" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果您想知道为什么我们同时使用字符词汇表和单词词汇表，那是因为字符嵌入对于跨上下文的概括非常有用。这有助于我们的模型预测一个词的标签，当这个词不在我们的词汇表中时，就像获得<code class="fe pg ph pi oy b">&lt;unk&gt;</code>令牌的词的情况一样。这是因为该单词的所有字符都应该出现在字符词汇表中。</p><p id="495c" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在我们的数据准备工作已经完成，我们可以开始制作模型了。</p><h2 id="0bcd" class="oh mh iq bd mi oi oj dn mm ok ol dp mq lj om on ms ln oo op mu lr oq or mw iw bi translated">模型</h2><p id="d51d" class="pw-post-body-paragraph la lb iq lc b ld my ka lf lg mz kd li lj na ll lm ln nb lp lq lr nc lt lu lv ij bi translated">我们将用来实现 NER 的模型被称为带有字符嵌入的双向 LSTM-CRF 模型。我们将要使用的模块可以在<a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/model.py" rel="noopener ugc nofollow" target="_blank">这里</a>找到。在模型中，我们将使用七种不同类型的层。</p><p id="c591" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">嵌入层</strong>是由整数 id 表示的文本数据(单词/字符/句子)被转换成密集的固定大小向量的层。然后可以训练这一层，使向量代表单词背后的意思，意思是具有相似意思的单词将得到相似的向量。</p><p id="9d1a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja"> LSTM 层</strong>是递归层，将序列作为输入，可以返回序列(return_sequences=True)或展平输出。</p><p id="7b01" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">双向层</strong>是将两个方向相反的隐藏层连接到同一输出的包装层。当需要输入的上下文时，例如标记单词序列时，它们很有用。本质上，它们允许序列中的一个位置拥有序列中在它之前和之后的所有信息。</p><p id="77e3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">时间分布层</strong>是包装层，允许我们将一个层应用到输入的每个时间片。Jason Brownlee 在他关于时间分布层的文章中比我更好地解释了这个概念。</p><p id="8c52" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">丢弃层</strong>是一种正则化技术，包括在训练期间的每次更新时将一部分权重设置为 0，以防止过度拟合。该分数由图层使用的超参数决定。</p><p id="cfcb" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">密集层</strong>或<strong class="lc ja">全连接层</strong>是全连接神经网络层，其中每个输入节点连接到每个输出节点。它们对输入进行简单的线性变换。</p><p id="dcf2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ja">条件随机场(CRF)层</strong>学习哪个标签序列最有可能。例如，它可以了解到在序列中 O 标签不应该直接出现在 I-Song 标签之前，并且 I-Song 只能出现在 B-Song 或 I-Song 之前。</p><pre class="kp kq kr ks gt ox oy oz pa aw pb bi"><span id="d21e" class="oh mh iq oy b gy pc pd l pe pf"># Word Embeddings<br/>word_in = <strong class="oy ja">Input</strong>(shape=(None,))<br/>word_emb = <strong class="oy ja">Embedding</strong>(input_dim=self.n_words+1, output_dim=100)(word_in)</span><span id="7794" class="oh mh iq oy b gy pj pd l pe pf"># Character Embeddings<br/>char_in = <strong class="oy ja">Input</strong>(shape=(None, None,))<br/>char_emb = <strong class="oy ja">TimeDistributed</strong>(<strong class="oy ja">Embedding</strong>(input_dim=self.n_chars + 2,<br/>           output_dim=10, mask_zero=True))(char_in)<br/>char_enc = <strong class="oy ja">TimeDistributed</strong>(<strong class="oy ja">LSTM</strong>(units=20, return_sequences=False,<br/>           recurrent_dropout=0.5))(char_emb)</span><span id="a446" class="oh mh iq oy b gy pj pd l pe pf">concat = <strong class="oy ja">concatenate</strong>([word_emb, char_enc])<br/>concat = <strong class="oy ja">SpatialDropout1D</strong>(0.3)(concat)<br/>bi_lstm = <strong class="oy ja">Bidirectional</strong>(<strong class="oy ja">LSTM</strong>(units=256, return_sequences=True,<br/>                       recurrent_dropout=0.3))(concat)<br/>bi_lstm = <strong class="oy ja">Bidirectional</strong>(<strong class="oy ja">LSTM</strong>(units=256, return_sequences=True,<br/>                       recurrent_dropout=0.3))(bi_lstm)</span><span id="3ef4" class="oh mh iq oy b gy pj pd l pe pf">fully_conn = <strong class="oy ja">Dense</strong>(self.n_labels, activation="relu")(bi_lstm)</span><span id="36eb" class="oh mh iq oy b gy pj pd l pe pf">crf = <strong class="oy ja">CRF</strong>(self.n_labels, sparse_target=False)<br/>pred = crf(fully_conn)</span><span id="e766" class="oh mh iq oy b gy pj pd l pe pf">self.model = Model(inputs=[word_in, char_in], outputs=pred)<br/>self.loss = crf.loss_function<br/>self.accuracy = crf.accuracy</span></pre><p id="48b4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在我们的模型中，我们有两个输入:</p><ol class=""><li id="3d3d" class="nd ne iq lc b ld le lg lh lj nf ln ng lr nh lv ni nj nk nl bi translated">单词 id 的数组。</li><li id="5aa9" class="nd ne iq lc b ld nm lg nn lj no ln np lr nq lv ni nj nk nl bi translated">一个字符 id 矩阵，其中每一行映射到我们的单词序列中的一个单词。</li></ol><p id="16fc" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们要做的第一件事是将两个输入输入到一个<strong class="lc ja">嵌入</strong>层，该层将每个数组中的 id 转换成密集的固定大小的向量。这个过程的一个例子可以在图 3 中看到。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/299b70c8364f6874f3086c9f6f7872b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*lLNBujI15SMwT5HfHqYI5g.png"/></div><p class="ot ou gj gh gi ov ow bd b be z dk translated">图 3:嵌入层将整数 id 数组转换为固定大小向量数组的示例。</p></figure><p id="ca65" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">您可能会注意到，<strong class="lc ja"> LSTM </strong>层将字符嵌入向量作为输入，它被一个<strong class="lc ja">时间分布式</strong>包装器所包装。这使得 LSTM 层被应用于输入的时间切片，而不是整个输入张量。图 4 直观地解释了包装器是如何工作的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pm"><img src="../Images/ace49411fe2b1e171281852d720838c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aXTJeEXhhL39u3R91vfkMw.png"/></div></div><p class="ot ou gj gh gi ov ow bd b be z dk translated">图 4: a)显示了如果一个常规的 LSTM 层被应用到我们的字符嵌入层的输出会发生什么。b)显示当我们用时间分布来包装层时，LSTM 层被应用于秩 3 张量[word，timestep，char]而不是秩 4 张量[batch，word，timestep，char]。</p></figure><p id="2423" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">因为我们有了<code class="fe pg ph pi oy b">return_sequences=False</code>我们的<strong class="lc ja">时间分布 LSTM </strong>层减少了平坦化它的输出，所以输出张量的秩从 4 到 3。现在我们可以把它和单词 embeddings 连接起来。</p><pre class="kp kq kr ks gt ox oy oz pa aw pb bi"><span id="6641" class="oh mh iq oy b gy pc pd l pe pf">char_enc = <strong class="oy ja">TimeDistributed</strong>(<strong class="oy ja">LSTM</strong>(units=20, return_sequences=False,<br/>           recurrent_dropout=0.5))(char_emb)</span></pre><p id="afa8" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">接下来，我们将级联的输入馈送到一个双向 LSTM 层。该层输出输入句子中每个单词的上下文嵌入。这将捕获单词在句子中的位置信息。</p><p id="9897" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">其次，我们将上下文嵌入提供给一个完全连接的层，该层将每个上下文单词嵌入映射到输出标签上的分布。</p><p id="3464" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">最后，我们将<strong class="lc ja">密集</strong>层的结果反馈给<strong class="lc ja"> CRF </strong>层。该层从从<strong class="lc ja">密集</strong>层获得的张量中选择最可能的输出标签序列。</p><p id="2fd9" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">图 5 显示了模型的图表以及输入和输出维度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pn"><img src="../Images/0abd8f6fd69d7eabfce87c355512bff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2sdyscGN1CZ6V_b0J-9eow.png"/></div></div><p class="ot ou gj gh gi ov ow bd b be z dk translated">图 5:bil STM-CRF 模型的图表。特别注意字符嵌入的输入和输出是如何变化的(左侧)。此外，如果一个尺寸的大小是<strong class="bd po"> None </strong>，那么这意味着模型不关心该尺寸的大小，只要它在每批中是一致的。</p></figure><p id="1748" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">关于 Keras 中<strong class="lc ja">双向</strong>的实现，需要注意的一点是，组合正向传递和反向传递的默认配置是将它们连接在一起。这意味着我们为 LSTM 层选择的输出尺寸加倍了。但也有其他选项，例如让图层将结果相加或返回平均值，从而保持输出大小不变，而不是翻倍。</p><h1 id="a9fc" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">培养</h1><p id="e79c" class="pw-post-body-paragraph la lb iq lc b ld my ka lf lg mz kd li lj na ll lm ln nb lp lq lr nc lt lu lv ij bi translated">既然我们已经介绍了如何准备我们需要的所有数据和模型的结构，现在是开始培训的时候了。</p><p id="a4b3" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">首先，我们将创建一个<a class="ae mf" href="https://keras.io/utils/" rel="noopener ugc nofollow" target="_blank">序列</a> <strong class="lc ja"> </strong>对象来为模型准备迷你批处理。通过使用序列对象，我们可以在将每批数据发送到网络之前对其进行预处理。这简化了我们的代码，因为它允许我们一次只准备一批，而不是担心整个数据集。我们的 Sequence 对象相对简单，它与<a class="ae mf" href="https://keras.io/utils/" rel="noopener ugc nofollow" target="_blank"> Keras 文档</a>给出的例子基本相同。</p><pre class="kp kq kr ks gt ox oy oz pa aw pb bi"><span id="1f79" class="oh mh iq oy b gy pc pd l pe pf">preprocessor = <a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/preprocessing.py" rel="noopener ugc nofollow" target="_blank">Preprocessor</a>(word_vocab, labels2idx, char_vocab)</span></pre><p id="553d" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">接下来，我们将创建一个<a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/preprocessing.py" rel="noopener ugc nofollow" target="_blank">预处理器</a>来处理批处理的预处理。它将我们的映射函数作为参数，以便它们可以用来将我们的单词、字符和标签标记转换成整数 ID 标记。</p><pre class="kp kq kr ks gt ox oy oz pa aw pb bi"><span id="40a8" class="oh mh iq oy b gy pc pd l pe pf">model = <a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/model.py#L11" rel="noopener ugc nofollow" target="_blank">BiLSTMCRF</a>(labels, len(word_vocab), len(char_vocab))<br/>trainer = <a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/trainer.py#L7" rel="noopener ugc nofollow" target="_blank">Trainer</a>(model, X, y, [0.75, 0.95])</span><span id="01fd" class="oh mh iq oy b gy pj pd l pe pf">batch_size = 64<br/>trainer.train(batch_size, preprocessor)</span></pre><p id="365b" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在让我们初始化模型，并创建一个<a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/trainer.py#L7" rel="noopener ugc nofollow" target="_blank"> Trainer </a>对象来负责训练和评估模型。训练集和验证集将在训练过程中使用，以提高我们的 NER 模型的质量，测试集将在最后使用，以查看模型在以前没有见过的数据上的表现。训练集将包含 75%的数据，验证集将包含 20%，而我们的测试集将包含 5%。这些比率一点也不神圣，所以你可以随意使用不同的比率，看看什么最适合你。</p><pre class="kp kq kr ks gt ox oy oz pa aw pb bi"><span id="5c24" class="oh mh iq oy b gy pc pd l pe pf">train_seq = <a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/datautils.py#L83" rel="noopener ugc nofollow" target="_blank">DataSequence</a>(self.x_train, self.y_train, batch_size, preprocessor)<br/>val_seq = <a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/datautils.py#L83" rel="noopener ugc nofollow" target="_blank">DataSequence</a>(self.x_val, self.y_val, batch_size, preprocessor)</span><span id="07b5" class="oh mh iq oy b gy pj pd l pe pf">self.model.train(train_seq, val_seq)</span></pre><p id="3678" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">一旦我们分割了数据并创建了训练者对象，我们就可以训练模型了。我们的<a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/datautils.py#L83" rel="noopener ugc nofollow" target="_blank"> DataSequence </a>对象接受一个输入、一个输出、每个批处理的大小和一个预处理函数作为参数。</p><p id="584a" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在我们可以开始训练模型了！</p><pre class="kp kq kr ks gt ox oy oz pa aw pb bi"><span id="cc29" class="oh mh iq oy b gy pc pd l pe pf">self.model.compile(<br/>    loss=self.loss, <br/>    optimizer='adam', <br/>    metrics=[self.accuracy]<br/>)</span><span id="e185" class="oh mh iq oy b gy pj pd l pe pf">self.model.fit_generator(<br/>    generator=train_seq,<br/>    epochs=10,<br/>    verbose=1,<br/>    shuffle=True,<br/>    validation_data=test_seq,<br/>)</span></pre><p id="f458" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了计算模型的损失，我们将使用 CRF 损失函数。我们将使用具有默认设置的 Adam 优化器，我们要跟踪的指标是模型的准确性。为了训练模型，我们将使用 Keras 中的<code class="fe pg ph pi oy b"><a class="ae mf" href="https://keras.io/models/sequential/#fit_generator" rel="noopener ugc nofollow" target="_blank">fit_generator()</a></code>方法。这个方法允许我们使用由序列对象逐批生成的数据来训练模型。从而让我们对训练过程有更多的控制。</p><p id="1ed2" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">图 6 显示了四个时期的训练示例。正如你所看到的，我们的模型在维基数据集的第二个时期达到了 100%的准确率。这意味着我们的模型能够从每个给定的命令中提取正确的信息。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pp"><img src="../Images/4f473f6eeca323841881a49ba09d8e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CRfOuebjSiM7NlCyzfo31w.png"/></div></div><p class="ot ou gj gh gi ov ow bd b be z dk translated">图 6:关于<a class="ae mf" href="https://github.com/Skuldur/virtual-assistant-tutorial/blob/master/commands/wiki_commands.json" rel="noopener ugc nofollow" target="_blank"> Wiki 数据集</a>的四个时期的训练会议</p></figure><p id="2268" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在我们自己的虚拟助手中，使用的方法与本文中展示的方法相同，我们对任何单一意图的最低准确率约为 99.5%。其余的有大约 100%的准确性。因此，我们可以看到，这个模型在从文本命令中检索实体方面非常有效。</p><h1 id="fa6e" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">结论</h1><p id="28ad" class="pw-post-body-paragraph la lb iq lc b ld my ka lf lg mz kd li lj na ll lm ln nb lp lq lr nc lt lu lv ij bi translated">祝贺您完成了本系列的信息提取部分。读完这篇文章后，你应该明白 Alexa 和其他虚拟助手和聊天机器人是如何从你的请求中提取信息的，以及你如何创建模型来做同样的事情。如有任何问题，欢迎联系我或留言。</p><p id="55e4" class="pw-post-body-paragraph la lb iq lc b ld le ka lf lg lh kd li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在下一部分中，我们将研究我们的助手如何选择哪个 NER 模型来处理传入的命令。</p><h1 id="0e4c" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">给读者的建议</h1><ul class=""><li id="2ab0" class="nd ne iq lc b ld my lg mz lj pq ln pr lr ps lv og nj nk nl bi translated">尝试用 FastText 和 SentencePiece 替换自定义词汇表，看看是否有什么改进。它可能有助于更复杂的意图。</li><li id="6dd6" class="nd ne iq lc b ld nm lg nn lj no ln np lr nq lv og nj nk nl bi translated">尝试使用变压器(BERT)代替双向 LSTM 网络。请注意网络质量和模型大小之间的权衡。模型对 Lambdas 或你的树莓派来说变得太大了吗？</li><li id="feff" class="nd ne iq lc b ld nm lg nn lj no ln np lr nq lv og nj nk nl bi translated">在我们的模型以目前的规模开始挣扎之前，一个意图可以有多少不同的命令？</li><li id="deb7" class="nd ne iq lc b ld nm lg nn lj no ln np lr nq lv og nj nk nl bi translated">在 Pytorch 中实现模型。</li></ul></div></div>    
</body>
</html>