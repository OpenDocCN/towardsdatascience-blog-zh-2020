<html>
<head>
<title>A Tour of the Most Popular Machine Learning Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最流行的机器学习算法之旅</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-tour-of-the-most-popular-machine-learning-algorithms-b57d50c2eb51?source=collection_archive---------31-----------------------#2020-05-18">https://towardsdatascience.com/a-tour-of-the-most-popular-machine-learning-algorithms-b57d50c2eb51?source=collection_archive---------31-----------------------#2020-05-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0edb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">对机器学习的组成、学习风格和算法的全方位快速概述</h2></div></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/897fb4ee3e0688d3c9cf4bb47344a173.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VmcRvqK-zz9JcTxD"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">阿道夫·费利克斯在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="103a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi mc translated"><span class="l md me mf bm mg mh mi mj mk di"> M </span>机器学习可以说是目前计算机科学领域最热门、讨论最多的话题，但是你如何跟踪似乎从无到有的不同算法的无尽级联呢？</p><p id="3eeb" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">从个人经验来看，当算法的名字被抛来抛去的时候，你可能会觉得非常难以理解，你只需要知道它们是什么以及它们是如何工作的。如果你在同一条船上，你就来对地方了！</p><p id="f18e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，我们将对最流行的机器学习算法进行一次高层次的浏览，以便了解该领域的真实范围。首先，我们将研究算法的学习风格，然后是算法本身及其功能。最后，你应该对机器学习涵盖的所有算法以及它们之间的相互关系有一个坚实的认识。让我们开始吧！</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="1875" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated"><strong class="ak">学习风格</strong></h1><p id="b8c4" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">在机器学习中，传统的做法是根据算法的学习风格对其进行分类。一般来说，学习风格只是一种花哨的方式，用来说明你有什么数据可以用来训练你的算法。我们来看一些！</p><h2 id="a428" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated">1.<strong class="ak">监督学习</strong></h2><p id="4eca" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">在监督学习中，输入数据被称为<strong class="li iu">训练数据</strong>，并且具有<strong class="li iu">已知标签</strong>/结果。输入的一个例子可以是动物的图片，标签可以是它的名字(例如，大象、猫等。).另一个例子可以是电子邮件作为输入，以及它们是否是垃圾邮件作为标签。</p><p id="b700" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然后通过对输入数据进行迭代<strong class="li iu">训练</strong>来学习一个模型，其中它不断地进行预测，并且当那些预测是错误的时候<strong class="li iu">自我校正</strong>。这里有一个更简单的思考方式。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nu"><img src="../Images/40d66d5f25f130225a1a79a5539a5a5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JJCHWF9vslmaOS4k"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@jovana0909?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Jovana Askrabic </a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="af2c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">每当我想到机器学习，我都喜欢想到<strong class="li iu">婴儿</strong>。想象一下，教一个婴儿什么是猫，它偶尔会指着一只狗大叫“猫”任何理智的父母都会纠正孩子，并告诉婴儿这个动物实际上是一只狗；同样，经过<strong class="li iu">的反复试验</strong>，婴儿最终会很好地了解其中的区别。</p><p id="6134" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这正是监督学习的工作方式；电脑是婴儿。当它看到一张猫的照片，并说“狗”，你作为父母告诉它，这实际上是一只猫。经过上千次告诉电脑或孩子什么是猫或不是猫，机器/孩子最终将能够很好地预测标签。</p><p id="3e4e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这个训练/校正过程一直进行到模型在数据上达到<strong class="li iu">期望的精度水平</strong>。</p><h2 id="14af" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated">2.<strong class="ak">无监督学习</strong></h2><p id="3dc4" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">与监督学习不同，非监督学习<strong class="li iu">没有标签</strong>——只有输入数据。</p><p id="25a9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">通过<strong class="li iu">推断输入中存在的相似性</strong>和其他结构来学习模型。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nv"><img src="../Images/74681ffaabd0810850ea7b79075849fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yuXJmVenV-1PU_D-yFeg5Q.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">帕特里克·福尔在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="9c0f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">作为对我们之前类比的赞美，想象一下在一个婴儿面前倾倒一吨不同的M &amp; Ms巧克力豆。有可能孩子会根据颜色和形状有效地将巧克力块分类(假设里面有花生巧克力豆:)，而不会被明确告知它们属于哪一类。</p><p id="cfcf" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这是ML工程师在无监督学习中努力做的事情。我们希望将大量数据转储到计算机中，并根据各个数据点之间存在的相似性和差异性对其进行有效的分组。</p><h2 id="af3f" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated">3.<strong class="ak">半监督学习</strong></h2><p id="f3e1" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">顾名思义，半监督学习的输入数据混合了有标签和无标签的例子。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nw"><img src="../Images/645d95f7f8111871dd1f651b9b6e448c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-wFGkwnd6UtG7cHy"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">里克·梅森在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="3771" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在半监督学习中，我们希望机器能够<strong class="li iu">做出预测</strong> <strong class="li iu">，同时学习结构</strong>来组织手头的数据。</p><p id="133e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这种类型的学习不太常见，但仍然是一个非常酷的领域，在这个领域正在进行大量的研究。然而，当使用ML进行商业决策时，由于可靠性和准确性，您通常会看到团队和个人使用无监督和有监督的学习方法，而不是半监督的方法。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="ad50" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated"><strong class="ak">机器学习算法概述</strong></h1><p id="76d0" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">现在我们对学习风格有了一个坚实的了解，让我们来看看最流行的算法本身。</p><p id="a42a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当你通读它们的时候，我强烈建议你思考可以用这些方法解决的问题，以及问题所属的学习风格；这样做不仅会激励你，还会让算法坚持下去。</p><h2 id="719b" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">回归算法</strong></h2><p id="494e" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">回归算法关注的是输入和输出之间关系的建模；这是<strong class="li iu">迭代</strong>通过使用预测中的误差度量来改进(回想一下猫宝宝的例子)。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nx"><img src="../Images/79abef750342bf5c2e7e9beaaccaf606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aU0W4XSCKPM0BJzk"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">Tatiana Rodriguez 在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="02b2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最流行的回归算法包括:</p><ul class=""><li id="759a" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated"><a class="ae lf" rel="noopener" target="_blank" href="/linear-regression-made-easy-702e5dc01f03">线性回归</a></li><li id="281a" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">逻辑回归</li><li id="aaf0" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">逐步回归</li><li id="8dc7" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">普通最小二乘回归(OLSR)</li><li id="1b43" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated"><em class="om">多元自适应回归样条(MARS) </em></li><li id="8adc" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated"><em class="om">局部估计散点图平滑(黄土)</em></li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="0bf4" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">基于实例的算法</strong></h2><p id="4fca" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">基于实例的算法涉及<strong class="li iu">将新实例与已经存储在内存中的实例进行比较</strong>。正如该过程所示，这种算法的另一个名字是基于记忆的学习。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi on"><img src="../Images/9ea18b618f95a3152cd0d1d0cad23eb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mW3X_CzccANsH5VK"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来自<a class="ae lf" href="https://unsplash.com/@jankolar?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">推特:<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的@jankolario </a></p></figure><p id="4a33" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这些算法通常依赖于建立示例数据的数据库。然后<strong class="li iu">比较</strong>提交给数据库内数据的新输入数据，并使用<strong class="li iu">相似性度量</strong>，以便找到最佳匹配并做出预测。当编程和实现这些算法时，重点放在存储实例的<strong class="li iu">表示</strong>以及用于确定关系的<strong class="li iu">相似性度量</strong>上。</p><p id="7e8f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最流行的基于实例的算法包括:</p><ul class=""><li id="355f" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated">k-最近邻</li><li id="2385" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">支持向量机(SVM)</li><li id="82eb" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">学习矢量量化(LVQ)</li><li id="76ad" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">自组织映射(SOM)</li><li id="93e9" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">局部加权学习</li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="7a25" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">正则化算法</strong></h2><p id="8738" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">尽管正则化算法在本文中自成一类，但它们主要是与其他算法一起使用的。在高层次上，正则化基于模型的复杂性来惩罚模型；这反过来导致了更简单的模型，也证明了更好的一般化模型。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oo"><img src="../Images/8d3299bdf3c120857ef45330eed03a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Cn1xfznmf0NWfjDY"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@magict1911?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">蒂莫·沃尔茨</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="1711" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">举个例子，想象一下被问到“<em class="om">你会怎么把一个数x翻倍？</em>”。你可能会想到用2 ( <code class="fe op oq or os b">x * 2</code>)乘以数字<code class="fe op oq or os b">x</code>，但是你也可以通过做<code class="fe op oq or os b">((4x + 8)/4 — 2) * 2</code>来使数字翻倍。显然，第二种方法更复杂，也不是理想的方法；正则化不利于这种复杂性，并导致模型偏向简单性，例如将数字乘以2。</p><p id="fd1f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最流行的正则化算法包括:</p><ul class=""><li id="7063" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated">弹性网(L1)</li><li id="2064" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">岭回归(L2)</li><li id="aa20" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">最小绝对收缩和选择算子(LASSO)</li><li id="d071" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">最小角度回归</li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="8ec8" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">决策树算法</strong></h2><p id="d2f8" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">决策树方法关注的是基于数据中的值构建“决策”模型。</p><p id="f9e6" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">“决策树”的“树”部分来自于这样一个事实，即<strong class="li iu">决策在树结构中向下分叉</strong>，直到做出决策/预测。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ot"><img src="../Images/7da0b444e6e9ceba2475c30df2a81eb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BdxiOvgjMPoSKSco"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@_zachreiner_?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">扎克·赖纳</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="4138" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我最喜欢的解释决策树的方法是将算法与20个问题进行比较。在20个问题中，猜测的人问一系列是或否的问题，最终落在另一个人的脑海中(应用程序<a class="ae lf" href="https://en.akinator.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="li iu"> Akinator </strong> </a>是这一概念的另一个例子)。类似地，计算机询问关于输入的某些特征的“问题”,以遍历树并最终做出决定。</p><p id="6a25" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最流行的决策树算法包括:</p><ul class=""><li id="e263" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated">迭代二分法3 (ID3)</li><li id="36d5" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">分类和回归树</li><li id="dbec" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">C4.5和C5.0</li><li id="ff00" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">卡方自动交互检测(CHAID)</li><li id="8123" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">决策树桩</li><li id="1f1e" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">M5</li><li id="c1b9" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">条件决策树</li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="6b5e" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">贝叶斯算法</strong></h2><p id="aadd" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">贝叶斯算法关注于将<strong class="li iu">贝叶斯定理</strong>明确应用于回归和分类等问题。如果你不熟悉贝叶斯定理，这里是:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ou"><img src="../Images/ce1856095de7572b543bdafcd29d40f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OCoB9immS_JLCNvkd1Tzyw.png"/></div></div></figure><p id="e7b6" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">简而言之，它计算给定事件<strong class="li iu"> B </strong>的情况下，事件<strong class="li iu"> A </strong>的概率。例如，“<em class="om">假设是阴天，下雨的概率有多大？</em>”将表示为P( <strong class="li iu">雨</strong> | <strong class="li iu">阴</strong>)。同样，它将通过使用下雨时天气多云的概率(P(多云|下雨))乘以一般下雨的概率(P(下雨))并除以天气多云的概率(P(多云))来计算。</p><p id="443e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最流行的贝叶斯算法包括:</p><ul class=""><li id="e6f2" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated">朴素贝叶斯</li><li id="a551" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">高斯朴素贝叶斯</li><li id="a980" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">多项式朴素贝叶斯</li><li id="9563" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">平均单相依估计量(AODE)</li><li id="8220" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">贝叶斯信念网络(BNN)</li><li id="8c73" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">贝叶斯网络</li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="036d" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">聚类算法</strong></h2><p id="3dca" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">顾名思义，聚类算法关注的是<strong class="li iu">将相似数据点聚类在一起</strong>。采取的所有方法(即分级、基于质心等。)使用数据中的<strong class="li iu">固有结构</strong>以便最好地<strong class="li iu">将点</strong>组织成具有<strong class="li iu">最大相似度</strong>的组。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ov"><img src="../Images/e4317a8d5a281577003541cf0fc9d87d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AKdHSRXCeEv4kFX7HtQTjg.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@patrickian4" rel="noopener ugc nofollow" target="_blank">帕特里克·福尔</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="4234" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">还记得我们很久以前提到的M&amp;Ms类比吗？想象一下，把一袋彩色M &amp; Ms巧克力豆倒在一个人面前，告诉他们“分组”。他们很可能会用颜色、形状等将巧克力块很好地组合在一起。</p><p id="d674" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">类似地，计算机查看输入的数据点之间的相似性，并根据最大相似性将它们分组。</p><p id="d54d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最流行的聚类算法包括:</p><ul class=""><li id="c71d" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated">k均值</li><li id="d073" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">k-中间值</li><li id="3bcc" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">期望最大化</li><li id="b76f" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">分层聚类</li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="bd61" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">降维算法</strong></h2><p id="3218" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">降维，顾名思义，就是<strong class="li iu">对输入数据的特征</strong>进行降维的过程。例如，如果我们的每个数据条目有100列特征，我们可以将列减少到20列。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ow"><img src="../Images/2836ec1c117a5d2b0182e99aba4196f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1Ak11l9UEAzg8ZkS"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">由<a class="ae lf" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="8e7b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">但是你可能会问，为什么不用所有的列呢？这是因为<strong class="li iu">维度的诅咒</strong> ( <em class="om">哦，阴森森的</em> …对不起，这远没有听起来那么酷)。</p><p id="9ded" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">没有太多的细节，维度的诅咒基本上说明了数据有太多的维度<strong class="li iu"/>会导致过于<strong class="li iu">复杂的模型</strong>，这些模型不能<strong class="li iu">很好地概括</strong>；换句话说，该模型冒着<strong class="li iu">过度拟合</strong>我们的训练数据的风险，并导致<strong class="li iu">在真实世界数据上表现不佳</strong>。</p><p id="c81f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最流行的降维算法包括:</p><ul class=""><li id="7c4c" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated">主成分分析</li><li id="95ac" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">主成分回归</li><li id="4401" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">偏最小二乘回归(PLSR)</li><li id="2406" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">线性判别分析(LDA)</li><li id="c81b" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">混合判别分析</li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="c439" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">集成算法</strong></h2><p id="9c8c" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">集成算法涉及<strong class="li iu">组合多个较弱的独立训练模型及其预测</strong>，以便产生最终的、更准确的预测。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ox"><img src="../Images/80de2e8e5cf44958a69462245857af13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BhEXZJK4mAEROiIP"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">亚历山大·安德鲁斯在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="6627" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">正如亚里士多德所说，“整体大于部分之和”。“谁想到哲学会适用于ML，嗯？</p><p id="9e20" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">一般来说，这是一类非常强大的算法和技术，在机器学习社区中经常使用。</p><p id="f645" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最流行的集合方法包括:</p><ul class=""><li id="87dc" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated">助推</li><li id="0a9b" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">引导聚合(Bagging)</li><li id="d264" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">adaboost算法</li><li id="2378" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">随机森林</li><li id="b55b" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">加权平均(混合)</li><li id="464f" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">堆叠概化(堆叠)</li><li id="da19" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">梯度增压机(GBM)</li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="e81a" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">神经网络算法</strong></h2><p id="c485" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">神经网络是由我们的生物大脑和神经连接<strong class="li iu">激发</strong>的模型(强调<strong class="li iu">激发</strong>，而不是<strong class="li iu">模仿</strong>……@ elon musk)。虽然它们超级浮华，看起来闪闪发光，但神经网络实际上已经存在几十年了！</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oy"><img src="../Images/99223925f10be38216966d2ea05a1a71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hQp-3VmgkBvu2ZD5"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@ante_kante?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">安特·哈默斯特</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="40b5" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">一般来说，神经网络可以被归入<strong class="li iu">模式匹配</strong>保护伞之下，其中它被用于<strong class="li iu">回归</strong>和<strong class="li iu">分类</strong>。正如我们将在接下来的章节中看到的，神经网络具有非常强大的现代计算能力，并且已经进入了他们自己的领域，称为<strong class="li iu">深度学习</strong>。</p><p id="bf77" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然而，将这部分称为神经网络“算法”是不正确的，因为神经网络是一个<strong class="li iu">非常大的子领域</strong>，由数百种不同的算法和满足特定方面和问题(即计算机视觉、语言处理、分类等)的变体组成。).</p><p id="8691" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">构成神经网络的基础和最流行的算法包括:</p><ul class=""><li id="64eb" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated">感知器</li><li id="e80c" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">多层感知器(MLP)</li><li id="0f7b" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">反向传播</li><li id="a919" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">梯度下降(随机)</li><li id="f76f" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">Hopfield网络</li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="9897" class="ni mm it bd mn nj nk dn mr nl nm dp mv lp nn no mx lt np nq mz lx nr ns nb nt bi translated"><strong class="ak">深度学习算法</strong></h2><p id="2bf5" class="pw-post-body-paragraph lg lh it li b lj nd ju ll lm ne jx lo lp nf lr ls lt ng lv lw lx nh lz ma mb im bi translated">深度学习是神经网络的现代转世<strong class="li iu">，它利用了当前的<strong class="li iu">“廉价”计算</strong>。</strong></p><p id="55b8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">总的来说，深度学习努力使用同样<strong class="li iu">大的数据集</strong>的标签数据(图像、文本、视频、音频等)来创建<strong class="li iu">大得多的</strong>和<strong class="li iu">更健壮的</strong>神经网络。).</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oz"><img src="../Images/e76e4f3b68e5ca3433af27f011a124a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VL2DJArhgkLRYFYq"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://unsplash.com/@averey?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Robina Weermeijer </a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="ca11" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">深度学习最流行的基本算法和结构包括:</p><ul class=""><li id="28f4" class="ny nz it li b lj lk lm ln lp oa lt ob lx oc mb od oe of og bi translated">卷积神经网络(CNN)</li><li id="7595" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">递归神经网络</li><li id="1b3d" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">长短期记忆网络</li><li id="9cdb" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">堆叠式自动编码器</li><li id="c39f" class="ny nz it li b lj oh lm oi lp oj lt ok lx ol mb od oe of og bi translated">深度信仰网络(DBN)</li></ul></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="38b7" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated"><strong class="ak">其他ML算法</strong></h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pa"><img src="../Images/6b2c0685aa3940b704cb6a63bdd8f0e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a1VFL3HOTwe7r3bw"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">安妮·斯普拉特在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="2997" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">尽管我们在这篇文章中所涉及的内容看起来相当广泛，但我很遗憾/很高兴地说，我们仅仅触及了的皮毛！例如，我没有涉及任何与ML子领域相关的算法，如自然语言处理、推荐系统、强化学习、图形模型等。这个列表还在继续，但希望这能激起你足够的好奇心，让你冒险去发现当今这个领域中正在实现的所有非常酷的算法。</p><p id="c362" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了对我们正在浏览的所有机器学习算法有所了解，看看这个<a class="ae lf" href="https://en.wikipedia.org/wiki/List_of_machine_learning_algorithms" rel="noopener ugc nofollow" target="_blank">维基百科页面</a>。</p><p id="9232" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">但是不要烦恼！这个维基页面相当广泛，了解我在本文中提到的算法应该会给你足够多的强大基础，以开始你在机器学习方面的新职业:)。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="6c33" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated"><strong class="ak">结论</strong></h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pb"><img src="../Images/614c36709d1f8f5b9012bded041a48b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dfCXUdv1cxrkoVvH"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae lf" href="https://unsplash.com/@capturethemoment?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰尼斯·奥普里格</a>的照片</p></figure><p id="992f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi mc translated">现在，为了总结我们在一起的时间，让我们看看我们都复习了些什么。我们从学习机器学习中的三种核心学习风格开始；你能记住他们吗？(如果没有，是时候重读了！)</p><p id="ac97" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然后，我们花了文章的大部分时间来研究不同类别的机器学习算法，并在每个类别中提到最流行的算法。</p><p id="6532" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你有一个没有提到的算法，并且你想解释/把它放在列出的类别中，那么<strong class="li iu">把它放在回复</strong>中让所有读者看到；毕竟，我们是在一起学习:)</p><p id="532d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在接下来的文章中，我们将更深入地研究这些特定的算法，以及我们如何从头开始制作它们；一定要拍一个跟拍，这样你就知道他们什么时候出来了！但是现在，我希望你喜欢这次旅行，并且学到一些新的东西。</p><p id="0ab4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">编辑:<a class="ae lf" rel="noopener" target="_blank" href="/linear-regression-made-easy-702e5dc01f03">解说系列</a>第一部出来了！绝对零经验学习<a class="ae lf" rel="noopener" target="_blank" href="/linear-regression-made-easy-702e5dc01f03">线性回归和梯度下降</a>！</p></div></div>    
</body>
</html>