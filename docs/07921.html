<html>
<head>
<title>How to Serve your PyTorch Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何服务您的PyTorch模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-deploy-your-pytorch-models-with-torchserve-2452163871d3?source=collection_archive---------15-----------------------#2020-06-12">https://towardsdatascience.com/how-to-deploy-your-pytorch-models-with-torchserve-2452163871d3?source=collection_archive---------15-----------------------#2020-06-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d99a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">TorchServe的最新版本离GA又近了一步。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d69053d1a076d7039f6812bcc825c7cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LktjPFsFIm2E2FnvoNoTvQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由BENCE BOROS在Unsplash上拍摄的照片</p></figure><p id="b247" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你已经收集了你的数据，处理了它们，训练了你的模型，微调了它，结果是有希望的。接下来去哪里？你如何让公众获得它？</p><p id="e4ca" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">嗯，如果你是一个<a class="ae lu" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>用户，你可能想摆弄一下<a class="ae lu" href="https://www.tensorflow.org/tfx" rel="noopener ugc nofollow" target="_blank"> TFX </a>。TFX是一个优秀的工具集，帮助数据科学家创建和管理机器学习生产管道。但是如果你是PyTorch用户呢？嗯，你很幸运；截至2020年4月，你获得了<a class="ae lu" href="https://pytorch.org/serve/" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">torch serve</strong></a><strong class="la iu">。</strong></p><blockquote class="lv lw lx"><p id="19e5" class="ky kz ly la b lb lc ju ld le lf jx lg lz li lj lk ma lm ln lo mb lq lr ls lt im bi translated"><a class="ae lu" href="https://www.dimpo.me/newsletter" rel="noopener ugc nofollow" target="_blank">学习率</a>是我每周给那些对AI和MLOps世界好奇的人发的简讯。你会在每周五收到我关于最新人工智能新闻、研究、回购和书籍的更新和想法。在这里订阅<a class="ae lu" href="https://www.dimpo.me/newsletter" rel="noopener ugc nofollow" target="_blank"/>！</p></blockquote></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="7cd8" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">火炬服务是什么</h1><p id="344e" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">TorchServe是一个灵活易用的工具，用于服务PyTorch模型。它没有TFX的复杂性，因此也没有提供那么多的功能。然而，这是完成工作的直接方法！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/7d5161371851a821351fbf52eea33af9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8AaAYxLb-VOgGUW8V8JXQA.png"/></div></div></figure><p id="2695" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">TorchServe提供了一组必要的特性，比如服务器、模型归档工具、API端点规范、日志记录、度量、批量推断和模型快照等等。它还提供了一系列高级特性，例如，支持定制推理服务、单元测试和通过JMeter收集基准数据的简单方法。目前，它还处于试验阶段，但它在大多数情况下都很有效。事实上，在本文的后面部分，我们将对它进行测试。</p><h1 id="489e" class="mj mk it bd ml mm nh mo mp mq ni ms mt jz nj ka mv kc nk kd mx kf nl kg mz na bi translated">最新版本</h1><p id="9d02" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">TorchServe在两天前(2020年6月10日)发布了最新版本(0.1.1)。这是向GA(全面上市)迈出的一步，包括一系列有希望的新功能。除其他外，TorchServe的最新版本包括:</p><ul class=""><li id="77fe" class="nm nn it la b lb lc le lf lh no ll np lp nq lt nr ns nt nu bi translated">支持<a class="ae lu" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> HuggingFace </a>，这是一个深度学习库，其任务是为每个人推进和民主化NLP，提供文档和示例</li><li id="3503" class="nm nn it la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated">支持<a class="ae lu" href="https://github.com/NVIDIA/waveglow" rel="noopener ugc nofollow" target="_blank"> Nvidia Waveglow </a>，一个基于流的语音合成生成网络，有文档和例子</li><li id="db10" class="nm nn it la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated">与Model Zoo紧密集成，Model Zoo是一个深度学习注册表，具有从流行的预训练模型创建的模型档案</li><li id="e8ad" class="nm nn it la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated">支持<a class="ae lu" href="https://aws.amazon.com/cloudformation/" rel="noopener ugc nofollow" target="_blank"> AWS云形成</a>，它提供了在EC2实例上运行服务器的能力，并提供了一个简单的配置文件(YAML或JSON)</li><li id="4e95" class="nm nn it la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated">支持通过<a class="ae lu" href="https://jiffyclub.github.io/snakeviz/" rel="noopener ugc nofollow" target="_blank"> snakevize </a>分析器分析TorchServe Python执行，以获得详细的执行时间报告</li><li id="bd96" class="nm nn it la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated">具有清晰说明的重构文档</li></ul><p id="6c87" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有关可用功能的详细列表，请阅读<a class="ae lu" href="https://github.com/pytorch/serve/releases" rel="noopener ugc nofollow" target="_blank">发行说明</a>。</p><h1 id="53af" class="mj mk it bd ml mm nh mo mp mq ni ms mt jz nj ka mv kc nk kd mx kf nl kg mz na bi translated">装置</h1><p id="993e" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">安装TorchServe很简单。您可以使用<a class="ae lu" href="http://pytorch.org/serve/install.html" rel="noopener ugc nofollow" target="_blank">文档</a>中提供的说明，但是让我们使用<a class="ae lu" href="https://www.anaconda.com/" rel="noopener ugc nofollow" target="_blank"> conda </a>在Ubuntu上安装它:</p><ol class=""><li id="eb83" class="nm nn it la b lb lc le lf lh no ll np lp nq lt oa ns nt nu bi translated">为您的TorchServe安装创建一个新环境(可选但推荐)。</li></ol><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="3d5e" class="og mk it oc b gy oh oi l oj ok">conda create -n torch python=3.8</span></pre><p id="e40e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.激活新环境。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="ef77" class="og mk it oc b gy oh oi l oj ok">conda activate torch</span></pre><p id="b1d4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.运行以下脚本来安装TorchServe及其依赖项。这个脚本在您的机器上安装CPU专用的PyTorch、torchvision和torchtext模块。如果你不需要的话，可以跳过这些。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="3377" class="og mk it oc b gy oh oi l oj ok">conda install pytorch torchvision torchtext torchserve torch-model-archiver psutil future cpuonly -c pytorch -c powerai</span></pre><p id="d06f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您现在已经准备好开始使用TorchServe，并通过REST端点使您的模型可用。</p><h1 id="1a03" class="mj mk it bd ml mm nh mo mp mq ni ms mt jz nj ka mv kc nk kd mx kf nl kg mz na bi translated">简单的例子</h1><p id="1bfc" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">在这个例子中，我们部署了一个<a class="ae lu" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>分类器。我们通过TorchServe文档中的代码示例来完成所需的步骤。</p><ul class=""><li id="7f91" class="nm nn it la b lb lc le lf lh no ll np lp nq lt nr ns nt nu bi translated">首先，我们需要定义一个PyTorch模型来解决MNIST挑战。下面的代码只是一种方法；将其复制并粘贴到一个名为<code class="fe ol om on oc b">model.py</code>的文件中:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><ul class=""><li id="33fa" class="nm nn it la b lb lc le lf lh no ll np lp nq lt nr ns nt nu bi translated">然后，我们需要创建一个训练模型的脚本。将以下代码复制到一个名为<code class="fe ol om on oc b">main.py</code>的文件中。你可以运行<code class="fe ol om on oc b">python main.py -h</code>来查看可用选项列表。训练新模型并保存(<code class="fe ol om on oc b">python main.py --save-model True</code>)或在此下载可用的预训练模型<a class="ae lu" href="https://github.com/dpoulopoulos/medium/blob/master/torch_serve/artefacts/model.pt" rel="noopener ugc nofollow" target="_blank">。不管怎样，把保存的模型移到一个名为<code class="fe ol om on oc b">artefacts</code>的新文件夹中。</a></li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><ul class=""><li id="80bc" class="nm nn it la b lb lc le lf lh no ll np lp nq lt nr ns nt nu bi translated">接下来，我们需要编写一个定制的处理程序来在您的模型上运行推理。将以下代码复制并粘贴到一个名为handler.py的新文件中。该代码对灰度图像进行推理，就像MNIST图像一样:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><ul class=""><li id="bd66" class="nm nn it la b lb lc le lf lh no ll np lp nq lt nr ns nt nu bi translated">接下来，我们需要使用torch-model-archiver实用程序创建torch模型归档。该命令将提供的模型(<code class="fe ol om on oc b">artefacts/model.pt</code>)归档到一个<code class="fe ol om on oc b">.mar</code>文件中:</li></ul><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="6d75" class="og mk it oc b gy oh oi l oj ok">torch-model-archiver --model-name mnist --version 1.0 --model-file model.py --serialized-file artefacts/model.pt --handler handler.py</span></pre><ul class=""><li id="cb58" class="nm nn it la b lb lc le lf lh no ll np lp nq lt nr ns nt nu bi translated">创建一个<code class="fe ol om on oc b">model_store</code>文件夹，并将存档的模型移入其中:</li></ul><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="77d4" class="og mk it oc b gy oh oi l oj ok">mkdir model_store<br/>mv mnist.mar model_store/</span></pre><ul class=""><li id="cd9b" class="nm nn it la b lb lc le lf lh no ll np lp nq lt nr ns nt nu bi translated">最后，启动服务器并向其查询答案。你可以在这里下载一些<a class="ae lu" href="https://github.com/pytorch/serve/tree/master/examples/image_classifier/mnist/test_data" rel="noopener ugc nofollow" target="_blank">的测试数据。要使用它们，只需将它们放在一个名为<code class="fe ol om on oc b">test_data</code>的新文件夹中:</a></li></ul><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="f638" class="og mk it oc b gy oh oi l oj ok">torchserve --start --model-store model_store --models mnist=mnist.mar</span><span id="4549" class="og mk it oc b gy oq oi l oj ok">curl http://127.0.0.1:8080/predictions/mnist -T test_data/0.png</span></pre><ul class=""><li id="6eb5" class="nm nn it la b lb lc le lf lh no ll np lp nq lt nr ns nt nu bi translated">完成后，停止服务器:</li></ul><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="d947" class="og mk it oc b gy oh oi l oj ok">torchserve --stop</span></pre><h1 id="14cf" class="mj mk it bd ml mm nh mo mp mq ni ms mt jz nj ka mv kc nk kd mx kf nl kg mz na bi translated">结论</h1><p id="51c0" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">在这个故事中，我们介绍了TorchServe，这是一个灵活易用的工具，用于服务PyTorch模型。我们看到了它是什么，它提供了什么，以及我们如何通过REST端点利用它的工具来服务PyTorch模型。最后，我们检查了它的最新版本(版本0.1.1)和最新支持的特性，并用一个MNIST例子对它进行了测试。为了让您的手变脏，请阅读<a class="ae lu" href="https://pytorch.org/serve/" rel="noopener ugc nofollow" target="_blank">文档</a>和<a class="ae lu" href="https://github.com/pytorch/serve/tree/master/examples" rel="noopener ugc nofollow" target="_blank">官方示例</a>。</p><blockquote class="lv lw lx"><p id="b6f5" class="ky kz ly la b lb lc ju ld le lf jx lg lz li lj lk ma lm ln lo mb lq lr ls lt im bi translated"><a class="ae lu" href="https://www.dimpo.me/newsletter" rel="noopener ugc nofollow" target="_blank">学习率</a>是我每周给那些对AI和MLOps世界好奇的人发的简讯。你会在每周五收到我关于最新人工智能新闻、研究、回购和书籍的更新和想法。在这里订阅<a class="ae lu" href="https://www.dimpo.me/newsletter" rel="noopener ugc nofollow" target="_blank"/>！</p></blockquote><p id="9d7c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="ly">我叫Dimitris Poulopoulos，是希腊比雷埃夫斯大学</em></strong><a class="ae lu" href="https://bigdatastack.eu/" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"><em class="ly">BigDataStack</em></strong></a><strong class="la iu"><em class="ly">和博士(c)的机器学习研究员。我曾为欧洲委员会、欧盟统计局、国际货币基金组织、欧洲中央银行、经合组织和宜家等主要客户设计和实施人工智能和软件解决方案。如果你有兴趣阅读更多关于机器学习、深度学习、数据科学和DataOps的帖子关注我上</em> </strong> <a class="ae lu" href="https://medium.com/@dpoulopoulos" rel="noopener"> <strong class="la iu"> <em class="ly">中</em> </strong> </a> <strong class="la iu"> <em class="ly">、</em></strong><a class="ae lu" href="https://www.linkedin.com/in/dpoulopoulos/" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"><em class="ly">LinkedIn</em></strong></a><strong class="la iu"><em class="ly">或</em></strong><a class="ae lu" href="https://twitter.com/james2pl" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"><em class="ly">@ James 2pl</em></strong></a><strong class="la iu"><em class="ly"/> </strong></p></div></div>    
</body>
</html>