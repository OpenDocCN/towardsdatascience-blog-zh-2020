<html>
<head>
<title>Performance Metrics: Confusion matrix, Precision, Recall, and F1 Score</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">性能指标:混淆矩阵、精确度、召回率和 F1 分数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/performance-metrics-confusion-matrix-precision-recall-and-f1-score-a8fe076a2262?source=collection_archive---------1-----------------------#2020-09-14">https://towardsdatascience.com/performance-metrics-confusion-matrix-precision-recall-and-f1-score-a8fe076a2262?source=collection_archive---------1-----------------------#2020-09-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e58d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">解开困惑矩阵背后的困惑</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/56fdc7c3b92b61a78f4d19277f108547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vu3W3Z6-U3XGNLwFkc25fQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由乔恩·泰森拍摄，来自 Unsplash</p></figure><p id="5cbe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在处理不平衡数据时，准确性性能指标可能是决定性的。在这篇博客中，我们将学习混淆矩阵及其相关术语，这些术语看起来令人困惑，但却很琐碎。与准确性相比，混淆矩阵、精确度、回忆和 F1 分数给出了更好的预测结果的直觉。为了理解这些概念，我们将把本文仅限于二进制分类。</p><h2 id="3dfb" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">什么是混淆矩阵？</h2><p id="f450" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">它是一个大小为 2×2 的矩阵，用于二进制分类，实际值在一个轴上，而预测值在另一个轴上。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/6e99244ba21e3755f83f9ddbce2311c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*UsOWxGhFMhkfkFZivPFlpQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">混淆矩阵</p></figure><p id="37d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来理解混淆矩阵中容易混淆的术语:<strong class="ky ir">真阳性、真阴性、假阴性、假阳性</strong>并举例说明。</p><p id="9481" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">举例</strong></p><p id="8054" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练机器学习模型来预测患者中的肿瘤。测试数据集由 100 人组成。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/d41dc72e510eae109ee6619fd68b9d37.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*m72tZYerDLXEm0GnamIQVg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用于肿瘤检测的混淆矩阵</p></figure><p id="6bdd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">真正</strong> <strong class="ky ir"> (TP) </strong> —模型正确预测正类(预测和实际均为正)。在上面的例子中，<strong class="ky ir"> 10 个患有肿瘤的人</strong>被模型预测为阳性。<br/> <strong class="ky ir">【真负(TN)】</strong>—模型正确预测负类(预测和实际均为负)。在上面的例子中，<strong class="ky ir"> 60 个没有肿瘤的人</strong>被模型预测为阴性。<br/> <strong class="ky ir">假阳性(FP) </strong> —模型给出了阴性类别的错误预测(预测阳性，实际阴性)。在上面的例子中，<strong class="ky ir"> 22 个人</strong>被预测为患有肿瘤的阳性，尽管他们没有肿瘤。FP 也被称为<strong class="ky ir">类型 I </strong>错误。<br/> <strong class="ky ir">【假阴性(FN) </strong> —模型错误预测阳性类别(预测-阴性，实际-阳性)。在上面的例子中，8 个患有肿瘤的人被预测为阴性。FN 也被称为<strong class="ky ir">类型 II </strong>错误。</p><p id="f467" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">借助这四个值，我们可以计算真阳性率(TPR)、假阴性率(FPR)、真阴性率(TNR)和假阴性率(FNR)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/3d99044ee54547602c6d364e3e3d2fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*k6qWU7kXeCfk2KK2y3Cysg.png"/></div></figure><p id="aff5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">即使数据不平衡，我们也能判断出我们的模型是否运行良好。为此，<strong class="ky ir">TPR 和 TNR 的值应该高，FPR 和 FNR 的值应该尽可能低。</strong></p><p id="27be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在 TP、TN、FN 和 FP 的帮助下，可以计算其他性能指标。</p><h2 id="6862" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">精确度，回忆</h2><p id="ae1b" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">精确度和召回率对于信息检索都是至关重要的，其中正面类别比负面类别更重要。<strong class="ky ir">为什么？</strong></p><p id="757e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当在网络上搜索某些东西时，模型不关心与<strong class="ky ir">无关的</strong>和<strong class="ky ir">未被检索到的</strong>(这是真正的否定情况)。因此，只有 TP、FP、FN 用于精度和召回。</p><p id="0f99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">精度</strong></p><p id="789e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在所有积极的预测中，真正积极的占百分之几。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/2f473a82d6b1b4a938d2499c85373f5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*tHf0NHWGMwZTNe7TkylyYA.png"/></div></figure><p id="a9b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">精度值介于 0 和 1 之间。</p><p id="e9a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">回忆</strong></p><p id="1850" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在全部阳性中，有多少百分比被预测为阳性。与 TPR(真阳性率)相同。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/085bf5d641b3f0037b4c01393f0a3f07.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*ynGz0zu8ZlpgZ5voYRKfLg.png"/></div></figure><p id="20b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">精确和召回有什么用？</strong>我们通过例子来看。</p><p id="a74a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">示例 1-信用卡欺诈检测</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/ff8b23fb1b18a5ef73a4a48b3f5ae0c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*basHQK-PwsDupyiobifYbw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用于信用卡欺诈检测的混淆矩阵</p></figure><p id="c39d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们不想<strong class="ky ir">错过任何欺诈交易</strong>。因此，我们希望假阴性尽可能低。在这些情况下，我们可以向低精度妥协，但召回率应该很高。同样，在医疗应用中，我们也不想漏掉任何一个患者。因此，我们注重高召回率。</p><p id="11fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">到目前为止，我们已经讨论了什么时候召回比精确更重要。<strong class="ky ir">但是，什么时候精度比回忆更重要？</strong></p><p id="02ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">示例 2 —垃圾邮件检测</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/e162121a573f750dc8103c15d3c1e79b.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*AZCje2me1CRZEIf6eNs9jA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">垃圾邮件检测的混淆矩阵</p></figure><p id="5fa2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在垃圾邮件的检测中，如果有任何垃圾邮件未被检测到(假阴性)，这是可以的，但是如果我们错过了任何重要的邮件，因为它被归类为垃圾邮件(假阳性)，那该怎么办呢？在这种情况下，<strong class="ky ir">假阳性</strong>应该尽可能的低。在这里，精确比回忆更重要。</p><p id="af7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当比较不同的模型时，将很难决定哪个更好(高精度和低召回或反之亦然)。因此，应该有一个将这两者结合起来的指标。一个这样的指标是 F1 分数。</p><h2 id="a29e" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">F1 分数</h2><p id="2033" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">这是精确和回忆的调和平均值。它同时考虑了假阳性和假阴性。因此，它在不平衡数据集上表现良好。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/06d74905686c8961dc37cf681f6d5506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*aKtcqDvfMQxwTc1TeAbW5w.png"/></div></figure><p id="ac30" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">F1 分数给予回忆和精确相同的权重。</p><p id="f892" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有一个<strong class="ky ir">加权 F1 分数</strong>，其中我们可以给召回率和精确度不同的权重。正如上一节所讨论的，不同的问题给召回率和精确度不同的权重。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/b6f3030487ccec1cd2cd77b2ebcb03b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*XbRzdFC2-pxiuUQQnVhhYw.png"/></div></figure><p id="23bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Beta 代表多少次回忆比精度更重要</strong>。如果召回的重要性是精确的两倍，那么 Beta 的值就是 2。</p><h2 id="5a78" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">结论</h2><p id="7efa" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">与准确性性能指标相比，混淆矩阵、精确度、召回率和 F1 分数为预测提供了更好的见解。精确度、召回率和 F1 分数的应用是在信息检索、分词、命名实体识别和许多其他方面。</p></div></div>    
</body>
</html>