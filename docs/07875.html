<html>
<head>
<title>ROC vs. TOC</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ROC 与 TOC</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/roc-vs-toc-bccb7d70ef07?source=collection_archive---------36-----------------------#2020-06-11">https://towardsdatascience.com/roc-vs-toc-bccb7d70ef07?source=collection_archive---------36-----------------------#2020-06-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9bea" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">可视化分析二元分类器的两种方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/9ac0889a51d67cafe3b09658c1714447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A06ELnZHAyTK_9P9yjvelw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">开始了。(来源:作者)</p></figure><p id="bff8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最近，在撰写一篇关于如何优化配置二元分类器的文章时，我遇到了一个很有前途的替代方法，称为 TOC 分析。在这篇文章中，我将向您介绍这两种可视化工具背后的概念，并讨论它们的相似之处和不同之处。</p><h1 id="56e5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">动机</h1><p id="7744" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">当谈到评估二元预测器的性能时，<em class="mp">接收器操作特性</em> (ROC)曲线几十年来一直是一种主要形式，实际上早在机器学习时代之前就已经存在了(关于 20 世纪 50 年代的早期示例，请参见 Peterson 等人[1])。它允许我们评估和比较分类器的性能，因此是模型选择的有用工具。</p><p id="706b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一个分类器完全可以用一条在二维空间中画出的曲线来描述，也就是说，在你的监视器或一张纸上画出的曲线，这是基于这样一个事实:对于任何给定的测试集，2×2 混淆矩阵只有两个自由度。当且仅当你知道你的测试集的组成时，ROC 曲线上的每个点决定了相应的混淆矩阵，也就是说，你知道它包含多少阳性和阴性样本。然而，ROC 图本身<em class="mp">不</em>包含作为视觉信息的成分。</p><p id="d067" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">鉴于 ROC 分析的悠久历史，这一缺点最近通过 2014 年 Pontius 和 Si 引入的<a class="ae lr" href="https://en.wikipedia.org/wiki/Total_operating_characteristic" rel="noopener ugc nofollow" target="_blank"><em class="mp"/></a>(TOC)得以解决[2]。TOC 图包含完整的 ROC 信息，并允许您读取曲线上每个点的全部信息，即测试集的组成和混淆矩阵的所有四个条目。</p><p id="5d88" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们了解其工作原理之前，让我们快速回顾一下二进制分类的基本概念和符号。</p><h1 id="c5f5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">二元分类基础</h1><p id="7e46" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">在<a class="ae lr" href="https://en.wikipedia.org/wiki/Binary_classification" rel="noopener ugc nofollow" target="_blank">二进制分类</a>中，模型性能通常通过将其对来自测试集的数据点的预测与已知的正确结果进行比较来评估，即与测试集的标签进行比较。每个数据点的预测分为四类:真阳性(TP)、真阴性(TN)、假阳性(TP)或假阴性(FN ),每类中的样本数在<a class="ae lr" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank"> <em class="mp">混淆矩阵</em> </a>中表示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/65dceb2613fdd7752098890713cb8725.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*qdKAbIPP-XBM_I8wBRGQkw@2x.png"/></div></figure><p id="4c80" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">尽管混淆矩阵有 4 个分量，但实际上只有两个分量是独立的。这是因为每个实际测试集都有一定数量的 P 个实际为正的样本和一定数量的 N 个实际为负的样本。因此，不管特定分类器的性能如何，最终，我们总是得到 TP + FN = P 和 TN+FP = n。<br/>这就产生了两个含有四个未知数的方程，并留给我们两个自由度。参数化这些自由度的一种常见方式(但不是唯一的方式)是借助于<em class="mp">真阳性率</em> (TPR)和<em class="mp">假阳性率</em> (FPR)。数学上，它们被定义为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/6b3879643904d77e85983aec9044ff64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U9n3pEAFvqDf_cFXy23qNg@2x.png"/></div></div></figure><p id="63be" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从这些定义出发，你可以很容易地用很少的代数说服自己，TPR 和 FPR 足以确定所有四个 TP、FP、FN 和 TN，注意</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/71ffb61012869d825a04d68ab2f82138.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a4TxcgQW-iG7tpoOCcdF9g@2x.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/9d928c1ed5bda16ecc077f2739e167c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A4t0iswwO-3v7uPHrbDFOw@2x.png"/></div></div></figure><p id="835f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在许多情况下，分类器基于概率分类。这意味着他们根据数据点 x 的特征来计算每个类别的概率。在二元分类的情况下，这是两个概率 p(1|x)和 p(0|x)。由于样本必须属于这两类中的任何一类，即 p(1|x)+p(0|x)=1，所以只需查看两个概率中的一个，比如 p(1|x)。为了获得二元预测，使用判别阈值将连续概率 p(1|x)离散化为两类中的任一类:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/4cfeadfdd34449550043483c5bd9f9dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*twwsC-r8wUx74XifvKj4fw@2x.png"/></div></div></figure><p id="ea40" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，TPR 和 FPR 以及混淆矩阵中的所有四个数字都依赖于阈值。这种依赖性就是 ROC 和 TOC 图的设计目的。</p><h1 id="32b6" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">ROC 和 TOC 图</h1><p id="69b1" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">ROC 图和 TOC 图都是在单个图中可视化所有可能阈值选择的分类器性能的工具。但是，它们基于两个不同的坐标系。</p><p id="c4a2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ROC 曲线被绘制到 FPR-TPR 坐标系中，也就是说，您为 0%和 100%之间的所有阈值绘制(FPR(阈值)，TPR(阈值))。另一方面，TOC 图绘制在(TP+FP)-TP 坐标系中，也就是说，您绘制每个阈值的点(TP(阈值)+FP(阈值)，TP(阈值))。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/cb573234524157939234852c6ee41648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v5o4S8YaSSj6Jjiw1OKeRQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 1: </strong>两个分类器的 ROC 曲线(蓝色和绿色线条)和代表不知情(随机)分类器的曲线(橙色圆点)。</p></figure><p id="b6d9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TOC 图的主要吸引力在于，您可以读出 TOC 空间中每个点的完整混淆矩阵。这不仅可以通过绘制曲线来实现，还可以通过用角(0，0)、(N，0)、(N+P，P)、(P，P)来绘制周围的平行四边形框来实现。</p><p id="1900" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将在下面更详细地讨论这个平行四边形的性质，但是现在，我们注意到从 TOC 曲线上的任何点到盒子左边界的距离对应于 FP，到右边界的距离对应于 TN，到顶部的距离对应于 FN，到底部的距离对应于 TP。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/be0cd631ae8839404c1502ada914024e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SVlhdT4UTLg6qpdsmLO7nA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 2: </strong>对于 TOC 曲线上的每个点，您都可以读出混淆矩阵的所有四个分量，TP、FP、FN 和 TN，同时还可以获得 ROC 图中的所有信息。(来源:作者)</p></figure><p id="b5b5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与 ROC 图不同，ROC 图不允许在不知道 P 和 N 的情况下重建混淆矩阵，P 和 N 不包含在图本身中，TOC 图包含每个给定阈值选择的混淆矩阵<em class="mp">。此外，您可以轻松地读取测试集的大小和组成，例如，揭示数据中的偏斜度，这些偏斜度在 ROC 图中是“隐藏”的。</em></p><h1 id="7012" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">ROC 空间与 TOC 空间</h1><p id="bfc2" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">ROC 曲线被绑定到一个被称为<em class="mp"> ROC 空间</em>的正方形区域，其点对应于 TPR 和 FPR 在 0 和 1 之间的所有可能值【3】。这个正方形被从 TPR=FPR=0 到 TPR=FPR=1 的对角线切成两半。<br/>这条对角线上的点代表所谓的<em class="mp">未知</em>分类器。<br/>这种分类器只是对数据点进行随机分类，完全不顾其实际特征值。例如，在 TPR=FPR=0.7 时，不知情的分类器会将 10 个数据点中的 7 个数据点分类为阳性，将 10 个数据点中的 3 个数据点分类为阴性。</p><p id="9dfc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这条对角线的两端是两个非常特殊的决定者的家。<br/>在左下方，当 TPR=FPR=0 时，我们有一个分类器，它简单地将每一个数据点归类为负面。ROC 空间右上角的分类器将每个数据点分类为阳性。</p><p id="676a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ROC 空间的另外两个角落同样有趣。在左上角，我们有完美的分类器。它将正确的类别分配给测试集的每个单个数据点，对应于一个对角混淆矩阵，其中 TP=P，TN=N，FP=FN=0，也就是说，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/21145e1df1515ade75f72ce40ad2c7e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*4HBuEuL8An4976gxGmCStg@2x.png"/></div></figure><p id="69e7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过翻转它的每个响应，你可以使完美的分类器变得完全不完美。这种最差的分类器给每个数据点分配了错误的类别，导致混淆矩阵 TP=TN=0，FP=N，FN=P，即</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/cc239d3490001a477f76db236c7ba788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*KbqkUxzWfMzFQDSKGR_Mfg@2x.png"/></div></figure><p id="20b7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在 ROC 空间中，这对应于右下角，TPR=0，FPR=1。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/8da2e2c9e14fd3578b41617b835c3f78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DPcKuRH2CqhYlM1LQZZP5A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 3:</strong>ROC 曲线(蓝色)与无信息(随机)分类器性能的比较(橙色对角线)。ROC 空间的四个极端角是:(1)完美分类器，(2)全正分类器，(3)最差可能分类器，和(4)全负分类器。(来源:作者)</p></figure><p id="0d23" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TOC 空间在两个基本方面不同于 ROC 空间。首先，它不是正方形而是平行四边形，其次，它的形状取决于测试集的组成。这是选择轴的直接结果，因为与速率 TPR 和 FPR 不同，绝对值 TP 和 FP 不包含在从 0 到 1 的范围内。为了理解平行四边形，选择 TP 的任意固定值。然后，您的选择自动成为 TP+FP 的下限，TP+FP 是 TOC 图的横坐标(也称为 x 轴)，因为 FP 是一个计数，因此永远不会为负。TP+FP 的上限也由您的选择决定。就是 TP+N，因为 FP 不能大于 N，TP+FP 的这些上下界形成了平行四边形的倾斜的左右边界。TP 本身也是一个计数，并且限制在从 0 到 P 的范围内，分别确定平行四边形的上下边界。因此，整个 TOC 空间可以嵌入一个 N+P 乘 P 的矩形中。</p><p id="e2b8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">尽管有这些差异，TOC 空间只是 ROC 空间的一个(非均匀)<a class="ae lr" href="https://en.wikipedia.org/wiki/Scaling_(geometry)" rel="noopener ugc nofollow" target="_blank">缩放</a>和<a class="ae lr" href="https://en.wikipedia.org/wiki/Shearing_(physics)" rel="noopener ugc nofollow" target="_blank">剪切</a>版本。ROC 空间中的任何点都可以使用线性变换映射到 TOC 空间</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/875e3a230af9aba143437106f42066ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dYiA6msLeawamwvdDk69RQ@2x.png"/></div></div></figure><p id="538c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种转换是缩放的组合</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/905999587c54787a37446831c61f09d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*-Klwrlt-7HS7kQvNfMrlgA@2x.png"/></div></figure><p id="19f2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">和剪切</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/c053e222b992803f50e622b8f61251b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*hjNsCLcHdkcTaeVJyYKNSg@2x.png"/></div></figure><p id="6cff" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，我们可以通过使用</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/bf274d3ffcdb2328bf935b53cfc64b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u7DcBgG9NBihNfNiyvCelQ@2x.png"/></div></div></figure><p id="38d4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于这种变换的简单性质，ROC 空间的基本几何结构被带到 TOC 空间。因此，就像 ROC 空间一样，TOC 空间也被表示无信息分类器的对角线减半。TOC 空间的角也保留了它们在 ROC 空间中的含义:左上角是完美的分类器，右下角是最差的分类器，右上角是全肯定的分类器，左下角是全否定的分类器(见图 4)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/f10dea9951d3db52fc99a8218e1e53a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xVaUbdZU23JTzQEkeRv2xA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 4:</strong>TOC 空间的四个极端角分别是(1)完美分类器，(2)全正分类器，(3)最差可能分类器，(4)全负分类器。在第(5)点，患病率(阳性数)被正确估计。(5)(灰色区域)左边 TP+FP &lt; P，这样患病率被低估，右边(5) TP+FP &gt; FP，这样患病率被高估。(来源:作者)</p></figure><p id="348e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其他派生属性在转换过程中也保持不变。例如，让我们考虑 ROC 曲线下的面积(AUROCC ),这是一个使用单个数字描述 ROC 曲线整体的典型指标。TOC 曲线下的面积(AUTOCC)与 ROC 曲线下的面积(AUROCC)成正比，可以用同样的方式解释。我们有</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/c85ec0b5663ea2b5e79fc3f3e97a8f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*Kbn3ckBA13LTwVeF51XYig@2x.png"/></div></figure><p id="6be5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此 ROC 曲线下的 ROC 空间部分(1 乘 1 的正方形)与 TOC 曲线下的 TOC 空间部分(N 乘 P 的平行四边形)相同。</p><p id="1ce4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在 Pontius 和 Si [2]的原始出版物中有这种关系的冗长证明，但我发现更直接的考虑是只有<br/> ϕₛcₐₗₑ影响该区域(ϕₛₕₑₐᵣ是面积保持的)并且它的<a class="ae lr" href="https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant" rel="noopener ugc nofollow" target="_blank">雅可比矩阵</a>是 N⋅P，因此很明显，在变换下，AUROCC 被相应地放大。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/9965ad8b652b18143660fc3cc120a611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EJqRZgMt98mZc0qHJxWDsg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 5:</strong>TOC 曲线下的平行四边形(蓝色区域)相对于整个平行四边形面积(蓝色+橙色部分)的分数等于 ROC 曲线下的面积。比较图 3 所示 ROC 图中的彩色区域。(来源:作者)</p></figure><p id="0a41" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TOC 空间有一个值得注意的点是 ROC 空间无法识别的。它是点(P，TP)，如图 4 中的点(5)所示。它是曲线上平行四边形左边界上端正下方的点。在这一点上操作的分类器产生与测试集中的阳性和阴性样本完全相同的阳性和阴性预测比率。这样的分类器可以说是正确地代表了实际的<a class="ae lr" href="https://en.wikipedia.org/wiki/Prevalence" rel="noopener ugc nofollow" target="_blank">流行度</a>。该点左侧的所有分类器都低估了阳性率，而其右侧的所有分类器都高估了阳性率。</p><h1 id="4c36" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">TOC 空间的形状</h1><p id="8184" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">虽然 ROC 空间在测试集组成变化的情况下保持几何静态，但是 TOC 空间变化强烈。Pontius 和 Si 建议通过重新调整图形的比例来“提高视觉清晰度”，这样在纸上(或你的显示器上)，TP 轴和 TP+FP 轴具有相同的长度[2]。然而，用相同的比例绘制 TP 和 TP+FP 轴，并观察 TOC 空间如何随着测试集组成的变化而展开和折叠，有助于理解 TOC 空间的概念。</p><p id="1da1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于任何非空测试集，有五种可能的情况:</p><p id="f712" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">1.0=N <p/> 2。0 &lt; N &lt; P <br/> 3。0 &lt; P=N <br/> 4。0 &lt; P &lt; N <br/> 5。0=P &lt; N</p><p id="3e0f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了说明，让我们考虑一个在“成人”数据集[4]上训练的玩具分类器，并用同样多的阳性和阴性样本编译一个主测试集。然后，我们可以通过控制这个集合的子集来创建所有五种可能的情况。具体来说，我们从 N=0，P=1552(情况 1)开始，增加 N(情况 2)，直到达到 N=P=1552(情况 3)。从那里，我们减少 P(情况 4)，直到我们最终达到 P=0，N=1552(情况 5)。图 6 说明了 TOC 空间如何由于测试集组成的这些变化而改变其形状。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/ca279aa6198bd70188ccd5a6019cce7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*sIyRnFPsRugLaHfm-99JdQ.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 6: </strong>显示各种测试集构成的 TOC 空间形状的动画。请注意，在 N=0 和 P=0 这两种极端情况下，从二维坍缩到一维。(来源:作者)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/b4cacd5248adb46552a70df9bd826465.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*_F96h5Hd47pluDO9Brwtwg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 7: </strong>对于 0=N &lt; P(情况 1)，TOC 空间是一维的。它对应于从(0，0)到(P，P)的对角线。(来源:作者)</p></figure><p id="0947" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们更详细地讨论情况 1 到 5。</p><p id="5095" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于 N=0 &lt; P, TOC space is one-dimensional! Its left and right boundaries collapse into a single diagonal line from (0, 0) to (P, P) (see Figure 7).</p><p id="2dbb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Although this might seem strange at first glance, it is sensible, since in absence of negatives, the performance of a classifier is in fact one-dimensional, completely determined by a single parameter, its TPR.</p><p id="3873" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Going away from this extreme situation, we increase the number of negatives in the test set.</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/2708523a098d1967a2a09f8ac674beb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mMtlUaLoihYq-ns9bfVlGQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 8 </strong>:对于 0 &lt; N &lt; P(情况 2)，TOC 空间是一个相当窄的对角线带。(来源:作者)</p></figure><p id="bcc2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对角线分成左右边界，打开了一个有限的区域，即“正常的”二维 TOC 空间。</p><p id="9b7d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，TOC 空间保留了一个相当窄的对角线形状，因为它的右边界从 TP+FP=N 开始，在 TP+FP=P 的左边很远的地方，它的左边界在这里结束(见图 8)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/c786de1f3260a8dc906e182c2f8b8c29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RNeTcmcIUnBBUiQyEC4GaA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 9: </strong>对于 0 &lt; N=P 左边界在右边界起点的正上方结束。(来源:作者)</p></figure><p id="c060" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">进一步增加否定的比例，然后我们接近 P=N 的情况，也就是说，在测试集中否定和肯定是完全平衡的。</p><p id="a74f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，右边的 TOC 空间边界直接从左边界的端点下面开始(参见图 9)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/d0a1dcc684e6c90a5082cfa75c4c56e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T-moXCczP_lgDHPi_qUhXw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 10: </strong>对于 0 &lt; P &lt; N，TOC 空间相当宽广。(来源:作者)</p></figure><p id="2155" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当我们增加负数的数量超过这一点时，我们会遇到这样一种情况，左边界和右边界的对角线不再在彼此之上，在(P，0)、(N，0)、(N，P)和(P，P)之间有一个矩形区域。</p><p id="1b28" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，TOC 空间现在显得相当大(参见图 10)。</p><p id="e21e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最终，我们接近了另一个极端:整个测试集都充满了否定。同样，TOC 空间的两个边界将两个折叠成一条线。</p><p id="5a61" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这一次，是上限和下限，因此 TOC 空间变成了从 0 到 N 的水平线段(参见图 11)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/b96ffce5b49d679b14c82166072db0a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*NGuujRTfyA0J5LfHNQSLlQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mv">图 11: </strong> A 0=P &lt; N，TOC 空间是从 0 到 N 的一维线段(来源:作者)</p></figure><p id="1337" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">同样，这种崩溃是合理的，因为分类器的结果现在完全由 TN 和 FP 组成，其性能完全由一个参数定义，即其 FPR。</p><p id="549e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们通过注意到对于 N=P=0 的完全空的测试集的情况(实际上不相关，但是病理上有趣), TOC 空间将进一步折叠，成为单个点，来结束我们的 TOC 空间的往返行程。</p><h1 id="e664" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">讨论</h1><p id="a17e" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">TOC 图是统计师工具箱的有用补充。习惯于 ROC 分析的读者可以很快学会解释 TOC 图，因为这两种表示共享许多属性。</p><p id="64ad" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TOC 曲线比 ROC 曲线包含更多的信息。然而，ROC 图的信息稀疏性也可以被看作是有利的。正如 Fawcett 在他的<em class="mp">ROC 分析简介</em>【3】:<em class="mp">ROC 图的一个优点是，它们能够可视化和组织分类器性能，而不用考虑类别分布或错误成本。当研究具有偏斜分布的学习或成本敏感学习时，这种能力变得非常重要。研究人员可以绘制一组分类器的性能图，并且该图相对于操作条件(类偏斜和错误成本)保持不变。随着这些条件的改变，感兴趣的区域可能会改变，但是图形本身不会改变。</em></p><p id="8fa7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，ROC 曲线在 TOC 不是合适替代品的某些情况下仍然适用。</p><p id="12b0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当涉及到库支持时，ROC 曲线具有明显的优势。尽管在任何主要的机器学习或统计库中都有现成的用于 ROC 分析的库函数，但由于 TOC 出现的时间相对较短，对它的支持仍然相当有限。有一个由最初 TOC 出版物的作者策划的<a class="ae lr" href="https://cran.r-project.org/web/packages/TOC/" rel="noopener ugc nofollow" target="_blank"> TOC R 包</a>。然而，如果你愿意多做一点，一个根据概率绘制 TOC 图的函数可以很快用你最喜欢的编程语言实现。</p><p id="1bbd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，我们必须考虑到，图表最终是一种交流的手段。在统计学和机器学习社区，ROC 分析是一个众所周知的标准，ROC 图是直接理解的。相比之下，TOC 分析仍然相对年轻，可能仍然会困扰你的一部分听众。如果你在一个重要的会议上有 10 分钟的时间，你不会想花 5 分钟来解释一个不寻常的图表类型(TOC)，特别是当有一个可供选择的(ROC ),你的听众会马上得到。</p><p id="8430" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">尽管 TOC 分析还远未被广泛采用，但我希望这篇文章能让你相信，在分析分类器的性能时，这是一个值得尝试的工具。</p><h1 id="0652" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="177f" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">[1] W. Peterson、T. Birdsall 和 W. Fox，信号可检测性理论(1954)，信息理论 IRE 专业组汇刊，<strong class="kx ir"> 4 </strong> (4)，第 171–212 页。</p><p id="b1d0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2] R. G. Pontius Jr 和 K. Si，<a class="ae lr" href="http://dx.doi.org/10.1080/13658816.2013.862623" rel="noopener ugc nofollow" target="_blank">测量多阈值诊断能力的总操作特性</a> (2014)，国际地理信息科学杂志<strong class="kx ir"> 28 </strong> (3)，第 570-583 页</p><p id="6b5f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3] T. Fawcett，<a class="ae lr" href="https://doi.org/10.1016/j.patrec.2005.10.010" rel="noopener ugc nofollow" target="_blank">ROC 分析介绍</a> (2006)，模式识别字母<strong class="kx ir"> 27 </strong>，861–874 页</p><p id="964d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[4] <a class="ae lr" href="http://archive.ics.uci.edu/ml/datasets/Adult" rel="noopener ugc nofollow" target="_blank">成人数据集</a> (1996)，通过 Dua，d .和 Graff，C. (2019)，<a class="ae lr" href="http://archive.ics.uci.edu/ml" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习知识库</a>提供</p></div></div>    
</body>
</html>