<html>
<head>
<title>Predicting happiness using Random Forest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用随机森林预测幸福</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-happiness-using-random-forest-1e6477affc24?source=collection_archive---------51-----------------------#2020-09-14">https://towardsdatascience.com/predicting-happiness-using-random-forest-1e6477affc24?source=collection_archive---------51-----------------------#2020-09-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3c3e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用机器学习探索影响人们幸福水平的因素</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/05bb56d22ff6880161ccacecd44e50d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6TPp-xkxZzQgjxalV3BmGw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">迈克·彼得鲁奇在<a class="ae kv" href="https://unsplash.com/@mikepetrucci?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c71d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为什么我们试图预测幸福？能够预测幸福意味着我们能够操纵或试图改善某些因素，以增加我们自己的幸福，也可能增加政府的国民幸福。我发现随机森林(RF)是最简单和最有效的软件包，所以让我们开始吧！</p><h2 id="1032" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">内容:</h2><ol class=""><li id="e35b" class="ml mm iq ky b kz mn lc mo lf mp lj mq ln mr lr ms mt mu mv bi translated">数据</li><li id="e990" class="ml mm iq ky b kz mw lc mx lf my lj mz ln na lr ms mt mu mv bi translated">随机森林模型</li><li id="6966" class="ml mm iq ky b kz mw lc mx lf my lj mz ln na lr ms mt mu mv bi translated">数据清理</li><li id="2273" class="ml mm iq ky b kz mw lc mx lf my lj mz ln na lr ms mt mu mv bi translated">培训和测试</li><li id="67cd" class="ml mm iq ky b kz mw lc mx lf my lj mz ln na lr ms mt mu mv bi translated">特征重要性</li><li id="8025" class="ml mm iq ky b kz mw lc mx lf my lj mz ln na lr ms mt mu mv bi translated">修改变量的数量</li><li id="2090" class="ml mm iq ky b kz mw lc mx lf my lj mz ln na lr ms mt mu mv bi translated">评估模型</li></ol><h2 id="4ba4" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">数据:</strong></h2><p id="8f07" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">从<a class="ae kv" href="http://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp" rel="noopener ugc nofollow" target="_blank"> #WorldValuesSurvey </a>获得的数据包含了&gt; 290 个问题&amp;在去除了缺失的幸福水平数据后，由大约 69k 个回答组成。是跨年度的跨国调查，问卷可以在网站上找到。特别是，我们将关注 2017 年至 2020 年的数据集。数据集的大小使其成为机器学习的最佳选择。</p><h2 id="d326" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">随机森林模型:</strong></h2><p id="3f5f" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">首先，我们将使用 RF 分类器*，因为我们希望机器能够预测群体的幸福水平(非常幸福、相当幸福、不太幸福、一点也不幸福)。<br/></p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="123f" class="ls lt iq ng b gy nk nl l nm nn">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split<br/>from sklearn import metrics</span></pre><h2 id="310c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">数据清理:选择数据</strong></h2><p id="1d05" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">让我们先从问题栏开始，去掉 Q46 关于幸福水平的回答中的负值。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="5f00" class="ls lt iq ng b gy nk nl l nm nn">var="Q46"<br/>df=df[df.columns[32:349]]<br/>df=df[df[var]&gt;0]</span></pre><p id="e543" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ne">*负值表示受访者表示不知道、没有答案、没有被问到或回答缺失。这些值将使机器更难对它们进行分类，因为它增加了类别的数量，而不是我们所寻找的。</em></p><p id="6fe3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">剩余的数据集如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/55caad9212e6d183c8ad47ea51461c6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sXB1OYE9dfjx73JjyOv9Qg.png"/></div></div></figure><h2 id="f75c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">进一步的数据清理:</strong></h2><p id="0fa8" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">下一个问题是，我们必须处理其他列中缺失的值。有 3 个选项可供考虑:</p><ol class=""><li id="c902" class="ml mm iq ky b kz la lc ld lf np lj nq ln nr lr ms mt mu mv bi translated">用 0 替换丢失的值</li><li id="c89a" class="ml mm iq ky b kz mw lc mx lf my lj mz ln na lr ms mt mu mv bi translated">用平均值替换缺失的值</li><li id="eca8" class="ml mm iq ky b kz mw lc mx lf my lj mz ln na lr ms mt mu mv bi translated">删除缺少值的行(数据集变为空)。</li></ol><p id="4234" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于第三个选项不可行，我们必须检查选项 1 或 2 中哪一个会给出最高的精度。在这种情况下，我发现用 0 替换会更准确。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="e515" class="ls lt iq ng b gy nk nl l nm nn">df.fillna(0, inplace=True)</span></pre><h2 id="69aa" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">准备列车标签:</strong></h2><p id="5937" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">现在，我们为机器设置“标签”,以识别我希望它预测的特征，并将数据分为训练集和测试集。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="c52b" class="ls lt iq ng b gy nk nl l nm nn">train_labels = pd.DataFrame(df[var])<br/>train_labels = np.array(df[var])<br/>train_features= df.drop(var, axis = 1)<br/>feature_list = list(train_features.columns)<br/>train_features = np.array(train_features)<br/>train_features, test_features, train_labels, test_labels = train_test_split(train_features, train_labels, test_size = 0.25, random_state = 42)</span></pre><h2 id="30d0" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">训练并测试模型:</strong></h2><p id="717c" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">培训和测试的过程很简单。为了提高预测能力和/或模型速度，我们可以简单地修改 RF 分类器中的参数。</p><h2 id="597c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">增加精度:</strong></h2><p id="21b5" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">n_estimators —多数表决前算法构建的树的数量</p><p id="6df3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">max _ features 随机森林考虑分割节点的最大要素数</p><p id="0b8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">min _ sample _ leaf 分割内部节点所需的最小叶子数。</p><h2 id="8b09" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">增加速度:</strong></h2><p id="7523" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">n_jobs —允许使用的处理器数量。如果= 1，只使用一个处理器。If =-1，无限制</p><p id="17e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">random _ state 使模型的输出可复制，即给定相同的超参数和训练数据，总是产生相同的结果</p><p id="1153" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">oob_score:随机森林交叉验证方法</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="bded" class="ls lt iq ng b gy nk nl l nm nn">rf=RandomForestClassifier(n_estimators = 1000, oob_score = True, n_jobs = -1,random_state =42,max_features = “auto”, min_samples_leaf = 12)<br/>rf.fit(train_features, train_labels)<br/>predictions = rf.predict(test_features)<br/>print(metrics.accuracy_score(test_labels, predictions))</span></pre><p id="48ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型需要 1.3 分钟来训练~52k 训练行和&gt; 290 列，并需要 1 秒来测试。准确率为<strong class="ky ir"> 63.70% </strong>。如果我们选择用平均值<strong class="ky ir">来填充缺失值</strong>，精确度将是<strong class="ky ir"> 63.55% </strong>。但重要的是找出是什么影响了机器的预测，因为这些是我们想要研究的变量。我们当然不能指望每个人都回答 290 多个问题，或者试图在所有 290 个方面努力提高幸福感(这将花费很多)。因此，我们将着眼于特性的重要性。</p><h2 id="309f" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">特性重要性:</strong></h2><p id="df5f" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">如果您还记得，feature_list 包含除 Q46 之外的所有其他变量的列。目标是了解影响预测的变量。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="0be7" class="ls lt iq ng b gy nk nl l nm nn">importances = list(rf.feature_importances_)<br/>feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]<br/>feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)<br/>[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]<br/>x_values = list(range(len(importances)))</span><span id="3ca8" class="ls lt iq ng b gy ns nl l nm nn"># Make a bar chart<br/>plt.bar(x_values, importances, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)<br/># Tick labels for x axis<br/>plt.xticks(x_values, feature_list, rotation='vertical')<br/># Axis labels and title<br/>plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/1ace7932373f05b466c40849fb7c4c18.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*2M2u9Nw1ShKq2yOmZjepcQ.png"/></div></figure><p id="983c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特征重要性总和为 1，我们注意到，与其他变量相比，某些变量对预测的影响更大，几乎每个变量都有某种形式的影响，尽管由于变量太多而非常小。接下来的事情是继续改进我们的模型，让我们更好地理解幸福。</p><h2 id="f9e4" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">修改变量数量:</strong></h2><p id="4ec3" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">让我们来看看前 20 个特征，并用这 20 个变量(+ var 本身)建立一个新模型。我们将重复数据清理和相同的 RF 模型。我得到了<strong class="ky ir"> 64.47%的准确率。</strong>如果我们选择用平均值替换缺失值，则精确度将为<strong class="ky ir"> 64.41% </strong>。这里令人惊讶的是，随着变量数量的减少，模型变得更加精确(从<strong class="ky ir"> 63.70% </strong>到<strong class="ky ir"> 64.47% </strong>)。这可能是因为其他变量在模型中产生噪声，导致模型不太准确。</p><h2 id="c0b1" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">让我们再来看看特性的重要性:</strong></h2><p id="7dff" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">这一次，可以更清楚地看出哪些变量更重要。你可以参考 WVS 网站上的调查问卷了解更多详细信息。我将总结一下这些问题所涉及的主题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/757255de5e3b8c62d6ab1d80135ffada.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*Y6BA3uIhks87NbUd_Lbnxw.png"/></div></figure><h2 id="83e0" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">评估模型:</strong></h2><p id="1ca7" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">让我们看看前 200 个测试值的实际值与预测值的图表。为了更好地了解整个测试集，让我们简单地计算一下预测值和实际值之间的差异(预测值减去实际值)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/210a00c1d16a8c6635fbb07419a68793.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6n7D4k7cDDQYyXlghn9eSA.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/7ba75e6686d76a5752e3500e30aac4db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*KGyB3JU163PIgBH8xiySVQ.png"/></div></figure><p id="b4ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型在预测幸福水平方面似乎是消极的多于积极的，但在其他方面仍然被认为是平衡的！</p><h2 id="2fe0" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">感悟:</strong></h2><p id="b9ce" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">我所做的是检查 WVS 中 290 多个与幸福水平更相关的关键问题。这将意味着我们在研究幸福时可以试着特别关注这些方面。</p><p id="8a4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在调查问卷中，我们还会注意到 Q261 和 Q262 是同一个东西(年龄和出生年份)，因此我们可以删除其中一个以包含另一个特征。对于问题 266，267，268(回答者和父母的出生国)，它们似乎是重复的，但并不完全相同，因为移民/跨文化婚姻可能会发生。尽管如此，我们可以考虑删除其中两个，因为这种情况很少发生。</p><h2 id="614b" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">一般话题有:</strong></h2><p id="2431" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated"><strong class="ky ir">个人层面:</strong> <br/>生活满意度、健康、财务、自由、年龄、安全、宗教、婚姻、家庭。<br/> <strong class="ky ir">国家层面:</strong> <br/>国家、对腐败的看法、民主/政治影响力、民族自豪感</p><p id="b3e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特别是，健康、财务和年龄是机器认为最重要的特征。从这个意义上说，个人层面的因素比国家层面的因素对一个人的幸福水平有更大的影响。</p><p id="2789" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，我注意到 WVS 没有关于睡眠时间的数据，这是我在之前的文章中观察到的一个关键因素。尽管如此，它仍然非常有用，因为我们可以考虑这些方面进行进一步的分析！我会带着对这些方面和幸福之间的相关性的更多见解回来，以确定我们如何才能提高我们的幸福水平。在那之前，记得保持快乐！</p></div></div>    
</body>
</html>