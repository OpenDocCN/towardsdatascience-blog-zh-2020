<html>
<head>
<title>Identifying Emotions from Voice using Transfer Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用迁移学习从声音中识别情感</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-emotions-from-voice-clips-f1f7cc5d4827?source=collection_archive---------22-----------------------#2020-05-22">https://towardsdatascience.com/detecting-emotions-from-voice-clips-f1f7cc5d4827?source=collection_archive---------22-----------------------#2020-05-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4aa5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用迁移学习训练神经网络从语音剪辑中识别情绪。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/9522e4239a8cd175c65c402ecf5ce0a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*A5E1QR51Uu5BrcbItTvPVg.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">一个快乐的人的声音片段的声谱图</p></figure><blockquote class="kr ks kt"><p id="c246" class="ku kv kw kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在经典情景喜剧《生活大爆炸》中题为“情感检测自动化”的一集里，霍华德设法获得了一个设备，可以帮助谢尔顿(他很难读懂别人的情感暗示)通过将设备指向周围的人来理解他们的感受…</p></blockquote><p id="a062" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">人类不仅倾向于用口语来传达信息，还会用音调、肢体语言和表情来传达信息。同样的信息以两种不同的方式说出来，可能会有非常不同的含义。因此，牢记这一点，我考虑着手一个项目，利用音调、响度和各种其他因素来识别语音剪辑中的情绪，以确定说话者的感受。</p><p id="7a80" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">这篇文章基本上是一个简短但完整的教程，它解释了如何训练一个神经网络来预测一个人的情绪。该过程将分为 3 个步骤:</p><ol class=""><li id="175a" class="lu lv iq kx b ky kz lb lc lr lw ls lx lt ly lq lz ma mb mc bi translated">理解数据</li><li id="fe6b" class="lu lv iq kx b ky md lb me lr mf ls mg lt mh lq lz ma mb mc bi translated">数据预处理</li><li id="e6a1" class="lu lv iq kx b ky md lb me lr mf ls mg lt mh lq lz ma mb mc bi translated">训练神经网络</li></ol><p id="781e" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">我们将需要以下库。fastai <br/> 2。numpy <br/> 3。matplotlib <br/> 4。天秤座<br/> 5。pytorch</p><p id="2c0a" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">您还需要一个 jupyter 笔记本电脑环境。</p><h1 id="212b" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">理解数据</h1><p id="03d2" class="pw-post-body-paragraph ku kv iq kx b ky na jr la lb nb ju ld lr nc lg lh ls nd lk ll lt ne lo lp lq ij bi translated">我们将一起使用两个数据集来训练神经网络:</p><h2 id="8a90" class="nf mj iq bd mk ng nh dn mo ni nj dp ms lr nk nl mu ls nm nn mw lt no np my nq bi translated">RAVDESS 数据集</h2><p id="4f13" class="pw-post-body-paragraph ku kv iq kx b ky na jr la lb nb ju ld lr nc lg lh ls nd lk ll lt ne lo lp lq ij bi translated">RAVDESS 数据集是 24 个演员用 8 种不同的情绪(中性、平静、快乐、悲伤、愤怒、恐惧、厌恶、惊讶)说同样的两句台词的音频和视频剪辑的集合。在本教程中，我们将只使用音频剪辑。您可以从这里的<a class="ae nr" href="https://zenodo.org/record/1188976" rel="noopener ugc nofollow" target="_blank">获取数据集。</a></p><h2 id="004a" class="nf mj iq bd mk ng nh dn mo ni nj dp ms lr nk nl mu ls nm nn mw lt no np my nq bi translated">TESS 数据集</h2><p id="f3c0" class="pw-post-body-paragraph ku kv iq kx b ky na jr la lb nb ju ld lr nc lg lh ls nd lk ll lt ne lo lp lq ij bi translated">TESS 数据集是两个女人表达 7 种不同情绪(愤怒、厌恶、恐惧、快乐、惊喜、悲伤和中性)的音频剪辑的集合。你可以从<a class="ae nr" href="https://tspace.library.utoronto.ca/handle/1807/24487" rel="noopener ugc nofollow" target="_blank">这里</a>获取数据集。</p><p id="9579" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">我们将声音剪辑转换成图形格式，然后将两个数据集合并成一个，然后我们将把它分成 8 个不同的文件夹，每个文件夹对应 RAVDESS 数据集部分中提到的一种情绪(我们将把惊讶和惊喜合并成一个组件)。</p><h1 id="5d94" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">数据预处理</h1><p id="6646" class="pw-post-body-paragraph ku kv iq kx b ky na jr la lb nb ju ld lr nc lg lh ls nd lk ll lt ne lo lp lq ij bi translated">我们将把声音剪辑转换成图形数据，这样它就可以用于神经网络的训练。为此，请查看下面的代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="bbe3" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">上面的笔记本显示了如何将声音文件转换为图形数据，以便神经网络可以解释它。我们正在使用名为 librosa 的库来做这件事。我们正在用 MEL 标度将声音数据转换成频谱图，因为这个标度的设计是为了使它更容易解释。这个笔记本包含应用于一个声音文件的代码。包含将初始数据集转换为最终输入数据的全部代码的笔记本可以在<a class="ae nr" href="https://github.com/shaan2909/Emotion-Detection-from-Sound/blob/master/Sound%20Preprocessing%20.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="2abb" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">因此，在运行上面笔记本中给出的每个声音文件的代码，然后根据需要划分文件后，你应该有 8 个单独的文件夹，分别标有相应的情绪。每个文件夹应该包含所有声音剪辑的图形输出，这些声音剪辑表达了文件夹所标注的情感。</p><h1 id="a8a5" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">训练神经网络</h1><p id="6bb7" class="pw-post-body-paragraph ku kv iq kx b ky na jr la lb nb ju ld lr nc lg lh ls nd lk ll lt ne lo lp lq ij bi translated">我们现在将开始训练神经网络，通过观察声音片段产生的频谱来识别情绪。我们将使用 fastai 库训练神经网络。我们将使用一个预训练的 CNN ( resnet34)，然后在我们的数据上训练它。<br/>我们将要做的如下:</p><p id="2480" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">1.制作具有适当数据扩充的数据加载器，以输入到神经网络。每幅图像的大小为 432×288。</p><p id="2251" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">2.我们将使用在 imagenet 数据集上预先训练的神经网络(resnet34)。然后，我们将通过适当的裁剪将我们的图像缩小到 144 乘 144 的大小，然后在该数据集上训练我们的神经网络。</p><p id="4c1e" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">3.然后，我们将在尺寸为 288×288 的图像上再次训练神经网络。</p><p id="518a" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">4.然后，我们将分析神经网络在验证集上的性能。</p><p id="d9d4" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">5.瞧啊。训练过程将会完成，你将拥有一个可以从声音片段中识别情绪的神经网络。</p><p id="42c3" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">开始训练吧！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="7422" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">在上面的部分中，我们已经使用我们的数据创建了一个数据加载器。我们对图像进行了适当的变换，以减少过度拟合，并将其缩小到 144 乘 144 的大小。我们还将其分为验证集和训练集，并根据文件夹名称标记数据。如您所见，数据有 8 个类别，因此这是一个简单的影像数据集分类问题。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="0050" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">在上面的部分中，我们使用了一个预训练的神经网络，然后在大小为 144×144 的图像上训练它来识别情绪。在训练结束时，我们的准确率达到了 80.1 %。<br/>现在我们有了一个神经网络，它非常擅长通过查看 144×144 大小的图像来识别情绪。因此，现在我们将使用相同的神经网络，并训练它通过查看 288×288 大小的图像来识别情绪(它应该已经很擅长了)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="c208" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">在上面的部分中，我们在 288×288 大小的图像上训练神经网络(我们已经在 144×144 大小的图像上训练过)。瞧，瞧！它现在可以从声音片段中识别情绪，而不管语音的内容如何，准确率为 83.1 %(在验证集上)。<br/>在下一节中，我们将使用混淆矩阵分析神经网络的结果。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="e52b" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">上面的部分包含了我们数据集的混淆矩阵。</p><p id="230e" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">完整的培训用笔记本可以在<a class="ae nr" href="https://github.com/shaan2909/Emotion-Detection-from-Sound/blob/master/Training%20.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到，从预处理到培训的所有笔记本都可以在<a class="ae nr" href="https://github.com/shaan2909/Emotion-Detection-from-Sound" rel="noopener ugc nofollow" target="_blank">这里找到。</a></p><p id="6b9a" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated">感谢你阅读这篇文章，希望你喜欢！</p><h1 id="bf8d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">引文</h1><p id="f0b0" class="pw-post-body-paragraph ku kv iq kx b ky na jr la lb nb ju ld lr nc lg lh ls nd lk ll lt ne lo lp lq ij bi translated"><strong class="kx ir">RAVDESS:<br/></strong>living stone SR，Russo FA (2018)瑞尔森情感语音和歌曲视听数据库(rav dess):北美英语中一组动态、多模态的面部和声音表情。PLoS ONE 13(5): e0196391。<a class="ae nr" href="https://doi.org/10.1371/journal.pone.0196391" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1371/journal.pone.0196391</a>。</p><p id="1de0" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld lr lf lg lh ls lj lk ll lt ln lo lp lq ij bi translated"><strong class="kx ir">多伦多情感演讲集(苔丝):<br/> </strong>皮乔拉-富勒，m .凯思琳；杜普斯，凯特，2020，《多伦多情感演讲集(TESS)》，<a class="ae nr" href="https://doi.org/10.5683/SP2/E8H2MF" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.5683/SP2/E8H2MF</a>，学者门户网站 Dataverse，V1</p></div></div>    
</body>
</html>