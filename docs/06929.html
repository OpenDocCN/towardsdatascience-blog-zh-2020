<html>
<head>
<title>Improving Classifier Performance by Changing the Difficulty of Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过改变图像的难度来提高分类器性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/improving-classifier-performance-by-changing-the-difficulty-of-images-cae33464e8d3?source=collection_archive---------80-----------------------#2020-05-28">https://towardsdatascience.com/improving-classifier-performance-by-changing-the-difficulty-of-images-cae33464e8d3?source=collection_archive---------80-----------------------#2020-05-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9c80" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我们提出了一个难度转换模型，该模型修改了结肠直肠组织病理学图像，使分类变得更具挑战性，发现用生成的图像作为增强数据训练的图像分类器表现更好。</h2></div><p id="4875" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">概述。</strong>在这项研究中，我与一组研究人员合作，为组织病理学图像创建了一个难度翻译模型。换句话说，给定一些癌症的图像，我们将其修改成一个更难分类的图像。这是基于这样的动机，即这些图像具有一系列决定它们将如何被分类的特征，这不同于像ImageNet这样的一般计算机视觉数据集(例如，没有猫和狗的范围)。</p><p id="cf0d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想更详细地了解我们的工作，可以在<a class="ae lb" href="https://arxiv.org/pdf/2004.12535.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>找到全文。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/b15171eac2e358f811beac0b204b31fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*dlrSr3h--lRvASEsR3Agrw.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">病理学家对生成的图像的认同度较低。左边的一组图片显示的是更难分类的翻译图片。右边的一组图像显示了图像翻译，并没有变得更难分类。</p></figure><p id="7108" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">数据集。</strong>数据集由来自达特茅斯-希区柯克医疗中心的结肠直肠癌图像组成，它已被分为2，051个图像的训练集和1，101个图像的测试集。这些图像中的每一个都被标记为过度增生性息肉(HP)或无柄锯齿状腺瘤(SSA)。</p><p id="bf17" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">模型。</strong>我们的模块由一个评分器和一个循环一致的生成对抗网络(CycleGAN)图像翻译器组成，前者预测给定图像的难度，后者将容易分类的图像翻译成较难分类的图像。通过这种配置，该模块能够将给定的图像翻译成类似的示例，该示例将被分类为具有相同的标签，但是将更加难以分类。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><p id="56d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">生成更难的训练数据。</strong>在本模块中，我们将image translator的源域设置为简单惠普映像，并将目标域设置为硬惠普映像。通过这样做，图像翻译器学会了将简单的HP图像转换成硬的HP图像。</p><p id="3f61" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了评估翻译图像的难度，我们与三位病理学家一起进行了图灵测试。每个病理学家被给予75个随机采样的真实简易HP图像、75个随机采样的真实硬HP图像、75个从选择的简易HP图像翻译的生成的HP图像和75个SSA图像。病理学家被要求将每个图像分类为HP或SSA。我们发现病理学家在生成的图像上比他们真正的对手有更多的分歧，这意味着生成的图像确实更难分类。完整的结果可以在下面看到。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lw"><img src="../Images/27d90f705f586b8a836efb3bcb31588f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e4QESxkK6RcgQP5vj72NZg.png"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">与真实图像相比，病理学家对生成的HP图像的真实标签认同较少。大多数生成的图像保留了它们的HP标签，因为源图像和它们相应的生成图像都被大多数病理学家分类为HP。</p></figure><p id="c5a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">提高分类器的性能。</strong>生成的图像也可以作为附加数据，更好地训练深度学习分类器。为了测试这一点，我们首先将生成的HP图像添加回原始训练数据集中。然后，我们在这个新的训练数据集上训练了一个新的分类器，并将其性能与我们以前的分类器进行了比较。我们将我们的方法与一种更简单的数据增强方法进行了比较，在该方法中，简单图像和困难图像被拼接在一起，发现我们优于基线增强，并且使用生成的图像作为增强数据始终提高了性能。完整的结果可以在下面看到。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mb"><img src="../Images/451bed4d9b2b7aeb2f12658e86278cf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g6WKLpMMRolYuNTojTUPaQ.png"/></div></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">图像分类器的性能(% AUC)使用生成的图像作为具有高注释者一致性(即，容易图像)、低注释者一致性(即，困难图像)和所有测试集图像的增强数据进行训练。</p></figure></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><p id="6717" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">总结。</strong>在我们的研究中，我们证明了改变图像的难度并使用困难的例子作为附加数据是一种改善深度学习分类器性能的有前途的方法。在我们的数据集上，我们的方法能够将性能提高大约2%，这是一个显著的改进。我们希望这些结果鼓励其他人探索在其他环境中使用改变图像难度，如课程学习或对抗性攻击。</p><p id="3271" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想阅读我们的全文，可以在这里找到<a class="ae lb" href="https://arxiv.org/pdf/2004.12535.pdf" rel="noopener ugc nofollow" target="_blank"/>。</p></div></div>    
</body>
</html>