<html>
<head>
<title>Data Scraping and Analysis using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行数据采集和分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/competitive-price-data-scraping-and-analysis-using-python-a1f34758155?source=collection_archive---------27-----------------------#2020-05-24">https://towardsdatascience.com/competitive-price-data-scraping-and-analysis-using-python-a1f34758155?source=collection_archive---------27-----------------------#2020-05-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2162" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用数据收集的竞争性定价</h2></div><p id="4dad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">数据</strong> <strong class="kh ir">抓取</strong>是一种从互联网上检索大量数据的技术。这个技巧在<strong class="kh ir">竞争</strong> <strong class="kh ir">定价</strong>中非常有用。为了确定我们产品的最佳价格，我们可以比较市场上的类似产品。这些价格变化很大。因此，在这篇博客中，我将展示我们如何丢弃关于特定产品的数据。</p><p id="95b2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最常见的数据抓取技术是使用<strong class="kh ir"> BeautifulSoup </strong>。它提取页面的html并将其存储为非结构化数据。我们必须把它转换成结构化的格式。</p><p id="afd2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们导入我们将需要的所有必要的库:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="0b5f" class="lk ll iq lg b gy lm ln l lo lp">import requests<br/>from fake_useragent import UserAgent<br/>import pandas as pd<br/>import bs4</span></pre><p id="0d42" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们提取的数据是非结构化数据。所以我们将创建空列表，以结构化的形式存储它们，</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="d5b5" class="lk ll iq lg b gy lm ln l lo lp">products=[] #List to store name of the product<br/>prices=[] #List to store price of the product<br/>ratings=[] #List to store rating of the product<br/>specifications = [] #List to store specifications of the product<br/>df=pd.DataFrame()</span></pre><p id="b753" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">创建用户代理。参考此链接<a class="ae lq" href="https://pypi.org/project/fake-useragent/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/fake-useragent/</a></p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="f1d2" class="lk ll iq lg b gy lm ln l lo lp">user_agent = UserAgent()</span></pre><p id="4361" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将产品名称作为输入。提取的数据将与该产品相关。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="3283" class="lk ll iq lg b gy lm ln l lo lp">product_name = input("Product Name- ")</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/a2cd2d6decb1ceab78a5b8d465fd0cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*p5QYP_xcVw2ss0s7bl3pWw.png"/></div></figure><p id="a5c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了从产品列表的多个页面中提取数据，我们将使用一个for循环。该范围将指定要提取的页数。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="08a6" class="lk ll iq lg b gy lm ln l lo lp">for i in range(1,11):<br/>    url = "<a class="ae lq" href="https://www.flipkart.com/search?q={0}&amp;page={1" rel="noopener ugc nofollow" target="_blank">https://www.flipkart.com/search?q={0}&amp;page={1</a>}"</span><span id="0123" class="lk ll iq lg b gy lv ln l lo lp">    url = url.format(product_name,i)</span><span id="b0be" class="lk ll iq lg b gy lv ln l lo lp">    ## getting the reponse from the page using get method of requests module<br/>    page = requests.get(url, headers={"user-agent": user_agent.chrome})</span><span id="1e41" class="lk ll iq lg b gy lv ln l lo lp">    ## storing the content of the page in a variable<br/>    html = page.content</span><span id="711b" class="lk ll iq lg b gy lv ln l lo lp">    ## creating BeautifulSoup object<br/>    page_soup = bs4.BeautifulSoup(html, "html.parser")</span><span id="01e5" class="lk ll iq lg b gy lv ln l lo lp">    for containers in page_soup.findAll('div',{'class':'_3liAhj'}):<br/>        name=containers.find('a', attrs={'class':'_2cLu-l'})<br/>        price=containers.find('div', attrs={'class':'_1vC4OE'})<br/>        rating=containers.find('div', attrs={'class':'hGSR34'})<br/>        specification = containers.find('div', attrs {'class':'_1rcHFq'})<br/>        products.append(name.text)<br/>        prices.append(price.text)<br/>        specifications.append(specification.text) if type(specification) == bs4.element.Tag  else specifications.append('NaN')<br/>        ratings.append(rating.text) if type(rating) == bs4.element.Tag  else ratings.append('NaN')<br/>    df = pd.DataFrame({'Product Name':products,'Price':prices, 'specification':specifications, 'Rating':ratings})</span></pre><p id="2880" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了从soup中提取数据，您需要指定要从中检索数据的html标签。你可以在网页上使用inspect元素。</p><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/f7f9e49e3e994f40ca2d39898f2ab848.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*1XEnaZghiyhtgqn3YIe5Iw.png"/></div></figure><p id="9ca6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上述代码将以结构化格式存储数据。当您打印df时，您将获得:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="99b5" class="lk ll iq lg b gy lm ln l lo lp">df.head()</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi lx"><img src="../Images/c61d9fa0bea8ebde002b1486588fcebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dfKeKkW5W-SYa65QCoo_jg.png"/></div></div></figure><h1 id="6a16" class="mc ll iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">清理数据</h1><p id="5358" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">因为所有的产品都是一样的，我们可以把它们写成“瓶子”。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="4df1" class="lk ll iq lg b gy lm ln l lo lp">df['Product Name'] = 'bottle'<br/>df.head()</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi my"><img src="../Images/e02af19fcfe0544fdf7b985b00996269.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*ONi66xI5ZI9-lW2GO0VvvA.png"/></div></figure><p id="1a1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，我们可以找到不同产品的数据。</p><p id="e8d5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们将从Price中删除符号，并清理specification列。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="6850" class="lk ll iq lg b gy lm ln l lo lp">df[‘Price’] = df[‘Price’].str.lstrip(‘₹’)<br/>df[‘Price’] = df[‘Price’].replace({‘,’:’’}, regex=True)<br/>df.head()</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/521b7cff2df4cb3125308ce726aa2468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*b0tpr0XYjoNa4lAsOHp3Ew.png"/></div></figure><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="0903" class="lk ll iq lg b gy lm ln l lo lp">df[‘Pack’], df[‘color’] = df[‘specification’].str.split(‘,’, 1).str<br/>del df[‘specification’]<br/>df.head()</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi na"><img src="../Images/cbaac526499889bc19aaf44ac55bc3aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*Zvh48K7QABg0vNOzUuC3kg.png"/></div></figure><h1 id="e03d" class="mc ll iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">我们得到的数据的一些基本分析</strong></h1><h2 id="3559" class="lk ll iq bd md nb nc dn mh nd ne dp ml ko nf ng mn ks nh ni mp kw nj nk mr nl bi translated">绘制箱线图</h2><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="e0ce" class="lk ll iq lg b gy lm ln l lo lp">import numpy as np<br/>import seaborn as sns<br/>df[‘Price’] = df[‘Price’].astype(np.float)<br/>sns.boxplot(x=df[‘Price’])</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/3794f44876aa72a6c97ca444e99799c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*uEwptzcncvJRY6RuO5u7Nw.png"/></div></figure><p id="bdbe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所看到的，在价格范围非常高的地方有一些异常值。</p><h2 id="8d4a" class="lk ll iq bd md nb nc dn mh nd ne dp ml ko nf ng mn ks nh ni mp kw nj nk mr nl bi translated">绘制条形图</h2><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="f160" class="lk ll iq lg b gy lm ln l lo lp">sns.barplot(x=df[‘Price’], y=df[‘color’])</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/0cba9a634de9a78f7c61757cb25c2c1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*7ReQVyPtQlcV4VmQONp3Lg.png"/></div></figure><p id="6683" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以观察到某种颜色的价格是如何变化的。多种颜色的行是成包的，如4个一包或6个一包等。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="2abe" class="lk ll iq lg b gy lm ln l lo lp">df[‘Rating’] = df[‘Rating’].astype(np.float)<br/>sns.barplot(x=df[‘Rating’], y=df[‘color’])</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi no"><img src="../Images/3c7c0c814ac41bda9edb6843fa2f1030.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*z3hhTD9LMruO0vj_xji3Vw.png"/></div></figure><p id="6630" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以观察到，颜色对产品的评级几乎没有影响。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="606d" class="lk ll iq lg b gy lm ln l lo lp">sns.barplot(x=df[‘Rating’], y=df[‘Price’])</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi np"><img src="../Images/e2e993c7682847223487a4bf3b2c4b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*EQ3oYq4f41pkW-wahghJBg.png"/></div></figure><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="8da3" class="lk ll iq lg b gy lm ln l lo lp">sns.lineplot(x=df[‘Rating’], y=df[‘Price’])</span></pre><figure class="lb lc ld le gt ls gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/0b18c7dc93aafba2eca3cc2a53d4edf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*Y7jyu372xGpenMd9G-kZoQ.png"/></div></figure><p id="4cb8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从这里我们可以得出结论，价格较低的产品在某种程度上有较高的收视率。</p><p id="1d54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">谢谢大家，我希望你们对我们如何使用数据收集来获得有竞争力的价格有所了解。除了博客中提到的，你还可以尝试不同的EDA技术。</p></div></div>    
</body>
</html>