<html>
<head>
<title>Architecture comparison of AlexNet, VGGNet, ResNet, Inception, DenseNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AlexNet、VGGNet、ResNet、Inception、DenseNet的架构比较</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/architecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d?source=collection_archive---------8-----------------------#2020-03-08">https://towardsdatascience.com/architecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d?source=collection_archive---------8-----------------------#2020-03-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="25e2" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">内部人工智能</h2><div class=""/><div class=""><h2 id="1779" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">ILSVRC挑战结果中具有超参数和准确性的图层描述</h2></div><blockquote class="kr"><p id="7e99" class="ks kt it bd ku kv kw kx ky kz la lb dk translated">你好，读者，如果你正在寻找一个完美的指南来获得关于AlexNet，VGGNet，ResNet，Inception和DenseNet的所有信息，那么你在正确的地方。仔细阅读博客，你会得到关于所有架构的详细信息。尽情享受吧！！！</p></blockquote><figure class="ld le lf lg lh li gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/7de6310f3a3083cb22351e37a466fbda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lOYiFA8EfYUJHRi93ppuow.jpeg"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">来源:<a class="ae lp" href="https://www.techleer.com/articles/259-concepts-of-advanced-deep-learning-architectures/" rel="noopener ugc nofollow" target="_blank">https://www . tech leer . com/articles/259-concepts-of-advanced-deep-learning-architectures/</a></p></figure><h1 id="4811" class="lq lr it bd ls lt lu lv lw lx ly lz ma ki mb kj mc kl md km me ko mf kp mg mh bi translated">AlexNet</h1><figure class="mj mk ml mm gt li gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mi"><img src="../Images/8d365c9c1b283c5be5180bee00e0c396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e2UBHHx9seb5291gX0tDEw.png"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">AlexNet架构[1]</p></figure><figure class="mj mk ml mm gt li gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/f66dde9ffd058e3938b576f17c9bbf0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*Hryc0QgfSN65flSH0Me16A.png"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">AlexNet图层详细信息[2]</p></figure><p id="65ca" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">AlexNet是第一个大规模卷积神经网络架构，在图像网络分类上表现良好。AlexNet参加了比赛，并能够以显著的优势超越所有之前的非深度学习模型。</p><p id="580d" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">AlexNet架构是一个conv层，然后是池层、标准化、conv池规范，然后是几个conv层、一个池层，然后是几个完全连接的层。实际上看起来很像LeNet网络。总共只是多了几层而已。共有五个conv层，在最终的全连接层到达输出类之前，还有两个全连接层。</p><p id="4c32" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">AlexNet在ImageNet上接受训练，输入大小为227 x 227 x 3的图像。如果我们看看第一层，这是AlexNet的conv层，它是11 x 11个过滤器，其中96个应用于stride 4。我在输出中有55 x 55 x 96，在第一层中有35K参数。第二层是池层，在这种情况下，我们在步长2处应用了3个3 x 3的过滤器。汇集层的输出体积为27 x 27 x 96，要学习的参数为0。池层不学习任何东西，因为参数是试图学习的权重。卷积层具有我们学习的权重，但汇集我们所做的只是有一个规则，我们查看汇集区域，并取最大值。因此没有学习到的参数。</p><p id="deda" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">开始有11×11个过滤器，然后是5×5和一些3×3个过滤器。最后，我们有两个大小为4096的完全连接的层，最后一层是FC8，它连接到softmax，soft max连接到1000个ImageNet类。这种结构是ReLu非线性的首次应用。</p><h2 id="86ab" class="nn lr it bd ls no np dn lw nq nr dp ma nb ns nt mc nf nu nv me nj nw nx mg iz bi translated">超参数:</h2><p id="d3a2" class="pw-post-body-paragraph ms mt it mu b mv ny kd mx my nz kg na nb oa nd ne nf ob nh ni nj oc nl nm lb im bi translated">这种结构是ReLU非线性的首次应用。AlexNet也使用了一层标准化。在数据扩充中，ALexNet使用了翻转、抖动、裁剪、颜色标准化等等。其他参数是0.5的辍学、0.9的SGD +动量、1e-2的初始学习率，并且当验证准确度变得平坦时再次减少10。该网络中使用的正则化是权重衰减为5e-4的L2。它是在包含3GB内存的GTX580 GPU上训练的。</p><p id="73d0" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">它在ImageNet大规模视觉识别挑战(ILSVRC)中的错误率为16.4。</p><blockquote class="kr"><p id="b8bc" class="ks kt it bd ku kv od oe of og oh lb dk translated">AlexNet是2012年ImageNet大规模视觉识别挑战(ILSVRC)基准分类的获胜者。</p></blockquote><h1 id="9415" class="lq lr it bd ls lt lu lv lw lx ly lz ma ki oi kj mc kl oj km me ko ok kp mg mh bi translated">VGGNet</h1><figure class="mj mk ml mm gt li gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/bf14e8e28334a24a8ae22c55a4e1de6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*3-TqqkRQ4rWLOMX-gvkYwA.png"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">VGG16架构[3]</p></figure><figure class="mj mk ml mm gt li gh gi paragraph-image"><div class="gh gi om"><img src="../Images/240ea3995cd1a8185c21236a5ab8348b.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*dNYBNBDP7ZvckfOSYzHxIw.jpeg"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">VGG 16层和VGG 19层细节[2]</p></figure><p id="bbfc" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">在2014年，有几个架构有了显著的不同，在性能上又有了一次飞跃，这些网络与更深层网络的主要区别是。</p><p id="a1be" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">VGG 16是16层体系结构，具有一对卷积层、池化层和最后的全连接层。VGG网络是更深层次的网络和更小的过滤器。VGGNet从AlexNet的八层增加了层数。现在它有16到19层的VGGNet版本。一个关键的事情是，这些模型始终保持非常小的3 x 3 conv过滤器，这基本上是最小的conv过滤器大小，查看一点点相邻像素。他们只是保持了这种非常简单的3 x 3 convs结构，并通过网络定期进行池化。</p><p id="a9a9" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">VGG使用小过滤器，因为参数更少，并堆叠更多的过滤器，而不是更大的过滤器。VGG有更小更深的过滤器，而不是大过滤器。它最终具有相同的有效感受野，就好像只有一个7 x 7卷积层一样。</p><p id="3aa9" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">VGGNet有conv层和一个池层，还有几个conv层，池层，几个conv层等等。VGG架构总共有16个卷积和全连接层。在这种情况下，VGG 16有16层，VGG 19有19层，这只是一个非常相似的架构，但其中多了几个conv层。</p><figure class="mj mk ml mm gt li gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi on"><img src="../Images/4dc93c051537c7c893d407ec1054168e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WcuD1pqLjBJamW_UHdTqJA.jpeg"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">VGG16参数[2]</p></figure><p id="66f8" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">因此，这是相当昂贵的计算，总共有138M参数，每个图像有96MB的内存，这比常规图像大得多。它在ILSVRC挑战中只有7.3的错误率。</p><blockquote class="kr"><p id="b4f7" class="ks kt it bd ku kv od oe of og oh lb dk translated">VGGNet是2014年ImageNet大规模视觉识别挑战(ILSVRC)分类基准的亚军。</p></blockquote><h1 id="c159" class="lq lr it bd ls lt lu lv lw lx ly lz ma ki oi kj mc kl oj km me ko ok kp mg mh bi translated">雷斯内特</h1><figure class="mj mk ml mm gt li gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oo"><img src="../Images/d1ccc9f08e9be813258680a40cebf27b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_nmPcwwnsHE-AC69ASkj9w.jpeg"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">ResNet架构和层细节[2]</p></figure><p id="429d" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">ResNet的主要基本元素是剩余块。随着我们深入到具有大量层的网络中，计算变得更加复杂。这些层放在彼此之上，每一层都试图学习所需函数的一些底层映射，而不是拥有这些块，我们试图拟合一个残差映射。</p><figure class="mj mk ml mm gt li gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi op"><img src="../Images/1c4706fe8919400ac855957cba9ebdac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8PKbjxkDj_Zq3KYZzXv8oQ.jpeg"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">普通层与残余块[2]</p></figure><p id="2e1a" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">在右边，这些模块的输入只是进来的输入，而在另一边，我们将使用我们的层来尝试拟合H(X) - X的一些残差，而不是直接拟合所需的函数H(X)。基本上，在这个模块的末尾，它会跳过这里的连接，在这里，它只接受输入，并将其作为一个身份传递，因此，如果中间没有权重层，它就只是一个身份。这和输出是一样的，但是现在我们使用额外的权重层来学习一些delta，一些来自x的残差。</p><p id="f4ab" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">简而言之，随着我们深入网络，学习H(X)是如此困难，因为我们有大量的层。所以这里我们用了跳过连接和学习F(x)直接输入x作为最终输出。所以F(x)被称为残差。</p><p id="86f5" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">在ResNet中，将所有这些块非常深入地堆叠在一起。这种非常深的架构的另一个特点是，它支持高达150层的深度，然后我们定期堆叠所有这些层。我们还将滤波器数量增加一倍，并使用步长2进行空间下采样。最后，只有完全连接的第1000层才能输出类。</p><h2 id="fa08" class="nn lr it bd ls no np dn lw nq nr dp ma nb ns nt mc nf nu nv me nj nw nx mg iz bi translated"><strong class="ak">超参数:</strong></h2><p id="013b" class="pw-post-body-paragraph ms mt it mu b mv ny kd mx my nz kg na nb oa nd ne nf ob nh ni nj oc nl nm lb im bi translated">在ResNet中，它在每个conv图层后使用批量归一化。它还使用SGD + Momentum的Xavier初始化。学习率为0.1，当验证误差变为常数时，学习率除以10。此外，批量大小为256，重量衰减为1e-5。重要的是，在ResNet中没有使用辍学。</p><blockquote class="kr"><p id="10ee" class="ks kt it bd ku kv od oe of og oh lb dk translated">ResNet以3.6%的错误率在ILSVRC和COCO 2015比赛中获得第一名。(比人类的表现还要好！！！)</p></blockquote><h1 id="bb06" class="lq lr it bd ls lt lu lv lw lx ly lz ma ki oi kj mc kl oj km me ko ok kp mg mh bi translated">开始</h1><figure class="mj mk ml mm gt li gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mi"><img src="../Images/22278d43c9813a996edf3d6e4e99ad98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nJ6IoHRvG_MSVIfxfRy2Ug.png"/></div></div></figure><p id="fb38" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">Inception v3是一种广泛使用的图像识别模型，已被证明在ImageNet数据集上获得了超过78.1%的准确率。该模型是多年来由多名研究人员开发的许多想法的结合。</p><p id="ca20" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">模型本身由对称和非对称构建块组成，包括卷积、平均池、最大池、漏失和完全连接层。Batchnorm在整个模型中广泛使用，并应用于激活输入。损耗通过Softmax计算。</p><p id="e642" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">初始阶段的工作是分解卷积。分解卷积用于减少要学习的连接和参数的数量。这将提高速度并提供良好的性能。</p><figure class="mj mk ml mm gt li gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/4a37e9fb69c61d11406af9fe2f01f69e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*ipPtHV5Z13WJ_25jXYctvA.png"/></div></figure><p id="15f4" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">GoogleNet使用5x5卷积层，而在inception中使用两个3x3层来减少学习参数的数量。在5×5中共有25个参数，3×3+3×3中共有18个参数要学习。因此，无学习参数显著减少了28%。</p><p id="aae3" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">分解成非对称卷积也用于初始阶段，这也有助于减少学习参数。</p><figure class="mj mk ml mm gt li gh gi paragraph-image"><div class="gh gi or"><img src="../Images/3fb61a0bb69123256974873e6e765a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*rwsQedbcwJIh6ZF1jzoM-A.png"/></div></figure><p id="d4df" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">一个3×1卷积后跟一个1×3卷积代替一个3×3卷积。在一个3×3中总共有9个参数，而3×1+1×3总共有6个参数，所以它将减少33%。这种方法不太可能在您深入训练时过度拟合模型。[4]</p><p id="2974" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">在42层深度的情况下，计算成本仅比GoogleNet高2.5倍左右，比VGGNet效率高得多。</p><blockquote class="kr"><p id="0585" class="ks kt it bd ku kv od oe of og oh lb dk translated"><strong class="ak"> Inception-v3用144个作物和4个模型集合，得到3.58% </strong>的前5名错误率，最终在ILSVRC 2015获得<strong class="ak">亚军(影像分类)。</strong></p></blockquote><h1 id="ada4" class="lq lr it bd ls lt lu lv lw lx ly lz ma ki oi kj mc kl oj km me ko ok kp mg mh bi translated">DenseNet</h1><p id="1dac" class="pw-post-body-paragraph ms mt it mu b mv ny kd mx my nz kg na nb oa nd ne nf ob nh ni nj oc nl nm lb im bi translated">DenseNet由如下所示的密集块组成。在这些块中，图层紧密地连接在一起:每一层都从以前的图层获得输入输出要素地图。残差的这种极端重用创建了深度监督，因为每一层都从前一层接收更多的监督，因此损失函数将做出相应的反应，并且由于这种方法，它使其成为更强大的网络。</p><figure class="mj mk ml mm gt li gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi os"><img src="../Images/53eb9a935f0e02ee860f3a51929dab8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*17YUdAEAfbtYXwjB7so31w.png"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">DenseNet框图</p></figure><p id="9c6c" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">DenseNet由两个模块组成:</p><ol class=""><li id="07b4" class="ot ou it mu b mv mw my mz nb ov nf ow nj ox lb oy oz pa pb bi translated">致密块体:单个块体由这些层组成:</li></ol><ul class=""><li id="b7e2" class="ot ou it mu b mv mw my mz nb ov nf ow nj ox lb pc oz pa pb bi translated">批量标准化</li><li id="ded1" class="ot ou it mu b mv pd my pe nb pf nf pg nj ph lb pc oz pa pb bi translated">ReLU激活</li><li id="2f2d" class="ot ou it mu b mv pd my pe nb pf nf pg nj ph lb pc oz pa pb bi translated">3x3卷积</li></ul><p id="a154" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">2.过渡层:在ResNet中将执行残差求和，而不是将残差求和Densenet连接所有的特征映射。这一层是由</p><ul class=""><li id="aa7f" class="ot ou it mu b mv mw my mz nb ov nf ow nj ox lb pc oz pa pb bi translated">批量标准化</li><li id="65e6" class="ot ou it mu b mv pd my pe nb pf nf pg nj ph lb pc oz pa pb bi translated">1x1卷积</li><li id="2d7d" class="ot ou it mu b mv pd my pe nb pf nf pg nj ph lb pc oz pa pb bi translated">平均池</li></ul><p id="abc3" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">基本上，Densenet的卷积生成较少数量的特征图。DenseNet对宽层的需求较低，因为层是紧密连接的，所以在学习的特征中几乎没有冗余。多层密集的块共享一块集体知识。层的输出特征地图的数量被定义为增长率。最终，增长率控制着每一层向全球贡献多少新信息。</p><figure class="mj mk ml mm gt li gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi pi"><img src="../Images/b565dcfc70c47ff019b7c2f9d17876a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EJXA4coxbvrbJJBO3nwxfQ.png"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">DenseNet建筑</p></figure><p id="e4cf" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">简而言之，DenseNet架构最大限度地利用剩余机制，使每一层都与其后续层紧密相连。模型的紧凑性使得学习到的特征不冗余，因为它们都通过集体知识共享。以训练由于隐式深度监督而紧密连接的深度网络，其中梯度由于短连接而更容易回流。</p><p id="27aa" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">参考资料:</p><p id="17a6" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">[1]https://mc.ai/alexnet-review-and-implementation/<a class="ae lp" href="https://mc.ai/alexnet-review-and-implementation/" rel="noopener ugc nofollow" target="_blank"/></p><p id="6824" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">[2]<a class="ae lp" href="http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture09.pdf" rel="noopener ugc nofollow" target="_blank">http://cs 231n . Stanford . edu/slides/2019/cs 231n _ 2019 _ lecture 09 . pdf</a></p><p id="2a9a" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">[3]<a class="ae lp" href="https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/</a></p><p id="6c8a" class="pw-post-body-paragraph ms mt it mu b mv mw kd mx my mz kg na nb nc nd ne nf ng nh ni nj nk nl nm lb im bi translated">[4]<a class="ae lp" href="https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c" rel="noopener">https://medium . com/@ sh . tsang/review-inception-v3-第一名-亚军-图片-分类-in-ils vrc-2015-17915421 f77c</a></p></div></div>    
</body>
</html>