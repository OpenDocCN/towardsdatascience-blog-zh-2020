<html>
<head>
<title>Detecting Document Similarity With Doc2vec</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Doc2vec 检测文档相似度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-document-similarity-with-doc2vec-f8289a9a7db7?source=collection_archive---------7-----------------------#2020-07-10">https://towardsdatascience.com/detecting-document-similarity-with-doc2vec-f8289a9a7db7?source=collection_archive---------7-----------------------#2020-07-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="53dd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Python 的分步实践介绍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d927789c7ad5e24fca42b43e97361934.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8RO-G98-jKKvWoqm"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">“什锦浆果”由<a class="ae ky" href="https://unsplash.com/@gndclouds?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">威廉·费尔克</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上演唱</p></figure><p id="345a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以用很多方法来分析和理解文本数据。这种方法通常处理称为自然语言处理(NLP)的人工智能领域。</p><p id="4e47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">NLP 允许我们执行大量的任务，其中我们的数据由文本或语音组成。情感分析、机器翻译和信息检索只是我们日常使用的 NLP 应用的几个例子。今天，通过结合使用 NLP 和机器学习技术，这些任务中的许多都可以很成功地解决。</p><p id="4e5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我想举例说明一个这样的方法，doc2vec，并希望提供一些关于它如何工作以及如何实现它的基本见解。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="a33c" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">任务</h1><p id="9439" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">简而言之，给定大量的文本文档，我们希望能够:</p><ol class=""><li id="f748" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">衡量文档在语义上的相似程度。</li><li id="056b" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">使用此信息根据相似性对文档进行聚类。</li></ol><h1 id="ec1a" class="mc md it bd me mf nn mh mi mj no ml mm jz np ka mo kc nq kd mq kf nr kg ms mt bi translated">我们将涵盖的内容</h1><p id="b736" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我知道这是一个较长的职位。因此，在我们开始之前，这里有一个我们将涵盖的所有内容的大纲:</p><ol class=""><li id="e8de" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">数据集介绍</li><li id="fccc" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">doc2vec 和矢量表示概述</li><li id="1b27" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">训练 doc2vec 模型</li><li id="99f0" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">可视化生成的文档向量</li><li id="302b" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">评估模型</li></ol><p id="7d9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以随意阅读，以你觉得舒服的速度。我甚至鼓励你把它分成几部分，在你认为合适的时候反复阅读，以保持专注。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="5134" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">数据</h1><p id="4599" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">为了训练和测试我们的模型，我们将使用<a class="ae ky" href="http://qwone.com/~jason/20Newsgroups/" rel="noopener ugc nofollow" target="_blank">20 个新闻组</a>数据集。这个数据集由 20 个不同主题的大约 18000 个新闻组帖子组成:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/0ba700512ebe46fb2771e3eed3c19d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j1GVqiiGvVsjAWsNptgObw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="http://qwone.com/~jason/20Newsgroups/" rel="noopener ugc nofollow" target="_blank">20 个新闻组</a>数据集的结构</p></figure><p id="5bb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了加快训练速度，也为了让我们以后的评估更加清晰，我们把自己限制在四个类别。此外，为了确保这些类别尽可能不同，这四个类别被选择为不属于同一个分区。</p><p id="41e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，这意味着我们可能想用例如<em class="nt"> soc.religion.christian </em>替换其中一个，而不是选择<em class="nt"> rec.sport.baseball </em>和<em class="nt"> rec.sport.hockey </em>。在这里，我决定使用类别<em class="nt">足球.宗教.基督教</em>，<em class="nt">科学.空间</em>，<em class="nt">谈话.政治.中东</em>，以及<em class="nt">娱乐.体育.棒球</em>。</p><p id="2324" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">选择类别后，他们的文档被分成训练集和测试集，同时跟踪哪些文档属于哪个类别，以便以后更容易判断模型的性能。</p><p id="7f4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 Python 中，我们可以使用<a class="ae ky" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>来获取数据:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按类别组织培训和测试数据</p></figure><p id="9533" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基本上，我们正在做的是创建两个字典，每个字典有 4 个关键字(即 4 个类别)。每个键包含属于该类别的所有文档作为其值，其中一个字典包含训练文档，另一个包含测试文档。此外，参数<code class="fe nw nx ny nz b">remove=('headers', 'footers', 'quotes')</code>从文档中移除元数据，如页眉、页脚和引用，以防止我们的模型<a class="ae ky" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">过度适应它们的</a>。</p><h1 id="2f29" class="mc md it bd me mf nn mh mi mj no ml mm jz np ka mo kc nq kd mq kf nr kg ms mt bi translated">生成向量</h1><p id="5bc3" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在我们有了数据，让我们重新审视我们的任务。请记住，我们首先要弄清楚我们的文档以及它们的上下文是如何相互关联的。</p><p id="0e0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们希望能够衡量文档在语义上的相似程度</p><p id="e2a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，我们想要做的是将我们的文本文档转换成数字的、矢量化的形式，稍后聚类算法可以使用这种形式将相似的文档分组在一起。</p><h2 id="8194" class="oa md it bd me ob oc dn mi od oe dp mm li of og mo lm oh oi mq lq oj ok ms ol bi translated">Doc2vec</h2><p id="e13c" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">产生这种载体的一种算法是 doc2vec [1]。在 Gidi Shperber 的文章中可以找到对这个概念的很好的介绍。本质上，doc2vec 使用神经网络方法来创建可变长度文本片段的向量表示，例如句子、段落或文档。这些矢量表示的优点在于，它们捕捉了输入文本的语义，即含义。这意味着在向量空间中，意义或上下文相似的文本比不一定相关的文本彼此更接近。</p><p id="2fcd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Doc2vec 建立在另一种叫做 word2vec 的算法之上[2]。正如您可能已经从名称中猜到的那样，word2vec 的功能与 doc2vec 非常相似，除了我们得到的不是文档向量，而是单词向量。例如，这意味着像“fast”和“quick”这样的词在向量空间中比“London”彼此更接近。不仅如此，这些向量表示还可以用来执行简单的向量运算。例如，<code class="fe nw nx ny nz b">vector("King") - vector("Man") + vector("Woman")</code>产生与“Queen”的矢量表示最相似的矢量。</p><p id="c5ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于 word2vec 的更深入的介绍，我推荐看看这篇由<a class="om on ep" href="https://medium.com/u/2fc7b9c3f02a?source=post_page-----f8289a9a7db7--------------------------------" rel="noopener" target="_blank"> Kung-Hsiang，Huang (Steeve) </a>撰写的<a class="ae ky" rel="noopener" target="_blank" href="/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c">文章</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/3c26cb0ac6b686089dc6b1a8609efc26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kgAEm_T7U5h0W3Vh.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示向量空间中单词之间的关系— <a class="ae ky" href="https://www.tensorflow.org/tutorials/representation/word2vec" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a></p></figure><h1 id="16b3" class="mc md it bd me mf nn mh mi mj no ml mm jz np ka mo kc nq kd mq kf nr kg ms mt bi translated">培养</h1><p id="5a7e" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在我们对 doc2vec 的作用有了一个概念，让我们看看如何在我们的数据上训练一个 doc2vec 模型。下面的实现很大程度上受到了这个<a class="ae ky" href="https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb" rel="noopener ugc nofollow" target="_blank">教程</a>的启发，我强烈推荐你去看看。</p><p id="e4f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们需要稍微调整一下原始数据，为训练做准备。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">组织和预处理培训和测试文档</p></figure><p id="73a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，我们使用字典来跟踪哪些文档属于哪个类别。为了训练 doc2vec 模型，训练文档需要采用<em class="nt"> TaggedDocument </em>的形式，这基本上意味着每个文档接收一个惟一的 id，由变量<code class="fe nw nx ny nz b">offset</code>提供。</p><p id="0cc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，函数<code class="fe nw nx ny nz b">tokenize()</code>将文档从一个字符串转换成由文档单词组成的字符串列表。它还允许选择<strong class="lb iu">停用词</strong>以及超过一定长度的词进行删除。</p><p id="fa56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">停用词通常是对一段文本没有上下文意义的常用词，因此会被删除。你会注意到，在这里，我选择不删除任何停用词，因为这样做性能似乎会稍微好一点。</p><p id="f0b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，停用词的移除高度依赖于手头的任务，并且找出要移除的停用词(如果有的话)并不总是简单明了的。</p><p id="2e99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们最后得到的是以下变量:</p><ul class=""><li id="13ba" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu op nf ng nh bi translated"><code class="fe nw nx ny nz b">train_corpus</code>:培训就绪文档列表</li><li id="c101" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu op nf ng nh bi translated"><code class="fe nw nx ny nz b">cat_dict_test_clean</code>:包含按类别组织的标记化测试文档</li></ul><p id="cdbe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nt">请注意，只有实际用于培训的文档才需要标记。</em></p><p id="4989" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">准备好培训文档后，我们现在可以开始培训我们的模型了。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练模型</p></figure><p id="b06b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们首先创建一个<em class="nt"> doc2vec </em>对象，它将作为我们的模型，并用不同的超参数值初始化它。</p><p id="35ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nw nx ny nz b">epochs</code>的值决定了训练过程中使用训练语料的次数。<code class="fe nw nx ny nz b">vector_size</code>决定了生成的文档向量有多大。此外，任何出现频率低于<code class="fe nw nx ny nz b">min_count</code>的单词都将被丢弃。在不涉及太多细节的情况下，<code class="fe nw nx ny nz b">window</code>在训练中用于确定在检查给定单词的上下文时要包含多少个单词。更多信息请参见第 2.2 节。[1]的。</p><p id="43ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当从头开始训练这样的模型时，这些参数的最佳值通过称为<a class="ae ky" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization" rel="noopener ugc nofollow" target="_blank"> <em class="nt">超参数调整</em> </a>的过程找到。</p><p id="7b27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在这里使用的价值观绝不是最佳的，也不是一成不变的。请随意使用不同的超参数集来试验训练不同的模型。</p><p id="2713" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们构建词汇表，它基本上是一个字典，包含训练语料库中所有唯一单词的出现次数。最后，对模型进行训练。</p><p id="ea53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以从测试集中推断出未知文档的新向量，并使用它们来评估我们的模型。这就是跟踪我们的文档属于哪个类别的用处。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">推断测试文档的文档向量，并组织它们以保存到文件中</p></figure><p id="164b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在<code class="fe nw nx ny nz b">inferred_vectors_test</code>中按类别保存这些向量。同时，我们初始化另一个字典<code class="fe nw nx ny nz b">metadata</code>，它将每个类别映射到一个整数，该整数对应于该类别的推断向量的数量。如果这看起来很奇怪，一会儿就会明白了。这两个变量现在可以用来创建两个文件，如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将向量和元数据写入文件</p></figure><p id="92b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两个文件中的第一个文件<code class="fe nw nx ny nz b">doc2vec_20Newsgroups_vectors.csv</code>，每行包含一个推断的文档向量，用制表符分隔的值表示，向量按类别排序。</p><p id="93d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二个文件<code class="fe nw nx ny nz b">doc2vec_20Newsgroups_vectors_metadata.csv</code>，每行包含第一个文件中相应向量的类别。这可能看起来像这样:</p><pre class="kj kk kl km gt oq nz or os aw ot bi"><span id="aa0e" class="oa md it nz b gy ou ov l ow ox">talk.politics.mideast<br/>talk.politics.mideast<br/>.<br/>.<br/>.<br/>talk.politics.mideast<br/>rec.sport.baseball<br/>rec.sport.baseball<br/>.<br/>.<br/>.<br/>rec.sport.baseball<br/>sci.space<br/>sci.space<br/>.<br/>.<br/>.<br/>sci.space<br/>soc.religion.christian<br/>soc.religion.christian<br/>.<br/>.<br/>.<br/>soc.religion.christian</span></pre><h1 id="bda6" class="mc md it bd me mf nn mh mi mj no ml mm jz np ka mo kc nq kd mq kf nr kg ms mt bi translated">形象化</h1><p id="870c" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">那么我们为什么要把向量和它们的元数据保存到文件中呢？好了，我们现在可以使用这两个文件，使用<a class="ae ky" href="http://projector.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow 的投影工具</a>来可视化我们文档之间的相似之处。在投影仪工具中，您可以选择不同的降维方法，即 t-SNE、PCA 和自定义轴标记，来表示 2D 或 3D 空间中的矢量。</p><p id="62f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">投影仪尝试对数据点进行聚类，以便相似的点彼此更接近。每种方法都将表示数据点之间的关系，也就是说，以不同的方式分配数据点。例如，一种方法将更侧重于表示各个点之间的局部相似性，而另一种方法可能侧重于保持数据集的整体结构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/6f590ef91a2f17981a47b39285d6fdee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*z0rnbGBIbhNcSke2w-yvrw.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用 2D t-SNE 图可视化文档向量</p></figure><p id="2c30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了看起来非常酷之外，我们可以用这些可视化来判断矢量的质量。通过搜索元数据文件中每个向量的类别名称，我们可以看到图上每个点属于哪个类别。</p><p id="8607" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，你会注意到，你可能有很多点位于中间的某个地方，并不真正属于任何集群。一个原因可能是你选择的降维方法；特别是对于 t-SNE，使用的参数值对数据点的分布有很大的影响。</p><p id="c9a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，不能忽视的事实是，一些文件可能只是在上下文中含糊不清。例如，来自一个类别的特定文档可能使用大量在来自另一个类别的文档中大量使用的术语，因此它们的向量彼此之间可能比它们自己类别的向量更相似。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/22e7234e7ee790b3fb42268f228eb9ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O6jJvcoatkE5VLFCCyvKZg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多次显示相同的数据点分布，突出显示每个类别的点</p></figure><p id="518c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以通过点击这个<a class="ae ky" href="http://projector.tensorflow.org/?config=https://gist.githubusercontent.com/osharaki/f620e141ccc36753449dc20f761e5bef/raw/6b0cd9848e6b0cc44d0c54a7f02deb2fa74cf1a4/test.json" rel="noopener ugc nofollow" target="_blank">链接</a>，使用上面例子中使用的矢量和元数据自己尝试投影仪。</p><p id="bb38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了从数字上检查文档之间的关系，我们可以通过使用<code class="fe nw nx ny nz b">similarity_unseen_docs()</code>函数来计算它们的推断向量之间的余弦距离。</p><p id="e16b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个函数将我们刚刚训练的 doc2vec 模型和要比较的两个文档作为其参数。作为文档相似性的度量，该函数返回一个介于 0 和 1 之间的值，该值越大，文档越相似。</p><p id="6420" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们想要比较单个文档，这是非常有用的，但是如果我们需要评估我们的模型的性能，我们将不得不扩展它，不仅包括单个文档，还包括我们数据集的一部分。</p><h1 id="eba8" class="mc md it bd me mf nn mh mi mj no ml mm jz np ka mo kc nq kd mq kf nr kg ms mt bi translated">评估我们的模型</h1><p id="27c6" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">直观上，人们会期望属于同一类别的文档比属于其他类别的文档彼此更相似。这正是我们用来判断模型的标准。一个好的模型应该为同一类别的文档给出比跨类别文档更高的相似性值。因此，在深入了解代码的本质之前，让我们先来看看如何构建比较。</p><p id="9b56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们要做的第一件事是为所有类别创建文档对集。更具体地说，给定我们的四个类别，我们用 C₁来表示，..,C₄，其中每个类别是一组文档，我们得到以下类别对:</p><ul class=""><li id="4f8f" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu op nf ng nh bi translated">(C₁、C₁)、(C₁、C₂)、(C₁、C₃)、(C₁、C₄)</li><li id="7a76" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu op nf ng nh bi translated">(C₂、C₂)、(C₂、C₃)、(C₂、C₄)</li><li id="f563" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu op nf ng nh bi translated">(C₃、C₃)，(C₃、C₄)</li><li id="4f65" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu op nf ng nh bi translated">(c₄c₄)</li></ul><p id="061a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nt">注意，当测量余弦相似性时，像(such)和(such)这样的对是等价的，因此为了避免冗余，只考虑两个组合中的一个。</em></p><p id="d0c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对(Ca，Cb)对应于包含类别 a 中所有文档的集合和包含类别 b 中所有文档的集合的笛卡尔积。更正式地说:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/c79207e350c0055b02bc1f1bdeffbee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x1WvqtgDFZGw8OpDYyZoWg.png"/></div></div></figure><p id="0182" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，对于每个文档对，我们计算文档的相似度。对于每个类别对，这会产生一个介于 0 和 1 之间的值的矩阵(每个文档对一个值)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/37ff340a0ebd4326d203ff807b00029f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0rBSIBL99tJLm8A-hcC_wg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">可能的相似度矩阵假设有两类<strong class="bd pc"> <em class="pd"> a </em> </strong> <em class="pd">和</em> <strong class="bd pc"> <em class="pd"> b </em> </strong> <em class="pd">分别包含</em><strong class="bd pc"><em class="pd"/></strong><em class="pd">和</em> <strong class="bd pc"> <em class="pd"> m </em> </strong> <em class="pd">文档。</em></p></figure><p id="c56c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们使用这些矩阵来判断两个类别中的文档总体上有多相似，所以将一个矩阵中的所有值浓缩成一个值作为相似性的度量无疑会使我们的工作容易得多。因此，我们将对每个矩阵做的是将矩阵中的所有值相加，得到一个值，我们称之为<em class="nt">相似度总计</em>，然后将这个值除以矩阵中的元素总数，得到一个<em class="nt">平均相似度</em>值。</p><p id="ae09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请记住，我们判断我们的模型不是根据它告诉我们来自相同类别的文档有多相似，而是根据这些相同类别的文档彼此之间比来自其他类别的文档有多相似。因此，我们真正追求的价值不仅仅是(C₃，C₃)的平均相似度(T30)有多高，而是相对于(C₁，C₃)，(C₂，C₃)和(C₃，C₄).)的平均相似度有多高</p><p id="1990" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此给定我们的四个类别，这留给我们每个类别四个<em class="nt">平均相似度</em>；一个用于同类文档，三个用于跨类文档。</p><p id="b23f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是我们要为每个类别做的事情。使用每个类别的四个<em class="nt">平均相似度</em>值，我们将计算跨类别<em class="nt">平均相似度</em>和同类别<em class="nt">平均相似度</em>之间的平均相似度差异。更正式地说:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/f25c8a7f14ae1352eec28aca912bd0e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fnpF9ItNZTnSnYv0_7YCKQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">计算类别 3 的平均相似性差异。s()表示两个类别的余弦相似性。请注意 j=3 是如何被跳过的，因为由此产生的减法是多余的。</p></figure><p id="dac3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">较高的平均差异告诉我们，该模型能够识别某个类别的文档与其他类别的文档更加不同。当然，如果一个类别的文档确实与另一个类别的文档相似，情况可能并不总是如此。例如，这在诸如<em class="nt"> comp.os.ms-windows.misc </em>和<em class="nt"> comp.windows.x </em>的类别中可能比在<em class="nt">comp . OS . ms-windows . misc</em>和<em class="nt"> soc.religion.christian </em>中更容易识别。</p><p id="32ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">评估结果可总结如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/3db28c7bb5d49e116a7d4b3174f38375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M34CrACnJj40NMuq-_xtPw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示的平均相似度是同类文档的平均相似度。一个好的模型应该是给出高的平均差<strong class="bd pc"><em class="pd"/></strong><em class="pd"/>和平均相似度  <em class="pd">值</em>的模型。</p></figure><p id="861d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以如此紧凑的形式表示结果使得用不同的超参数训练多个模型并比较它们的性能更加有效。</p><p id="d314" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们来看看如何对此进行编码。首先，我们创建一个字典，将文档对列表映射到它们所属的类别对。考虑到结果对的数量很大，我们需要限制这个数量，以便在合理的时间内执行我们的评估。为此，我们从每个字典条目中随机抽取 500 个文档对，并计算每个文档对的余弦相似度。</p><p id="eb72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nt">注意 500 是任意选择。理想情况下，样本越大，表示越准确。</em></p><p id="f861" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就产生了类似于我们之前看到的相似矩阵。最后，我们将这些矩阵作为列表保存在一个新的字典中，每个列表都被映射到它所代表的类别对。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成相似性矩阵</p></figure><p id="9df6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步是使用这些相似性值来计算我们上面讨论的紧凑表示。我们首先检查所有的类别对。如果我们找到一个相同类别的配对，我们保存它的平均相似度，以备以后计算平均差异时使用。对于跨类别对，我们简单地将它们的平均相似度保存在一个列表中。</p><p id="f23e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一步是使用<em class="nt">平均相似度</em>列表和之前保存的同类<em class="nt">平均相似度</em>计算<em class="nt">平均差异</em>。这个数字，加上同类的平均相似度，作为模型描述这个类别的一个度量。然后对每个类别重复这一过程。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h1 id="7633" class="mc md it bd me mf nn mh mi mj no ml mm jz np ka mo kc nq kd mq kf nr kg ms mt bi translated">摘要</h1><p id="fb11" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">所以可能需要消化很多东西。以下是我们在本文中讨论的所有内容的总结:</p><ul class=""><li id="b079" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu op nf ng nh bi translated">我们看了一下<em class="nt"> doc2vec </em>这是一种常用于生成文本文档的向量表示的方法。</li><li id="69f4" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu op nf ng nh bi translated">我们看到了如何使用 Gensim 在 Python 中准备数据和训练 doc2vec 模型。</li><li id="650f" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu op nf ng nh bi translated">我们看到了使用 TensorFlow 的投影仪来可视化我们的矢量是多么有用。</li><li id="c70a" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu op nf ng nh bi translated">最后，我们讨论了一种评估 doc2vec 模型的可能方法，它允许对多个模型进行有效的比较。</li></ul><p id="aa30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nt">谢谢你留下来！希望听到您的反馈，并回答您的任何问题。</em></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="f059" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">参考</h1><p id="273a" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">[1] Q. V. Le 和 T. Mikolov，<a class="ae ky" href="https://arxiv.org/abs/1405.4053" rel="noopener ugc nofollow" target="_blank">句子和文档的分布式表示</a>(2014)<br/>【2】t . miko lov，K. Chen，G. Corrado 和 J. Dean，<a class="ae ky" href="https://arxiv.org/abs/1301.3781" rel="noopener ugc nofollow" target="_blank">向量空间中单词表示的有效估计</a>，【2013】</p></div></div>    
</body>
</html>