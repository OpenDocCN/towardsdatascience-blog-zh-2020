# 情感分析:习语及其重要性

> 原文：<https://towardsdatascience.com/%EF%B8%8F-sentiment-analysis-idioms-and-their-importance-2f547f2e646c?source=collection_archive---------19----------------------->

## 习语在情感分析中的作用研究

***注:*** *本文讨论的方法背后的方法论源于我的博士论文，可以在这篇* [*学术论文*](https://www.sciencedirect.com/science/article/pii/S0957417415003759) *中找到。*

# 介绍

情感分析(或观点挖掘)旨在自动提取和分类文本中表达的情感(观点的主观部分)和/或情绪(感觉的投射或显示)。

我们用几种语言特征来表示文本中的情感。特征的形式可以是单个单词(uniGRams)、短语(bigrams)和更长的短语(n-grams)、表情符号(例如:)通常用于表示积极的情绪)、俚语(例如 chuffed、do one's nut)、缩写(例如 great — GR8)、拟声词元素(例如 gr、hm)，以及大写字母、标点符号(例如！！, ?！)，以及字母的重复(如 sweeeeet)来强调情感。这些特征通常从文本中提取出来，并呈现给机器学习模型，这些模型经过训练，可以根据文本中包含的特征对文本中表达的情感进行分类。

尽管这些特征在情感分析中得到了广泛的应用，但是忽略习语作为特征的影响却很少被关注。在这种情况下，这篇文章通过比较两种最先进的工具在有习语和没有习语时的性能，研究了将习语作为特征包含在情感分析中的重要性。实现这一点有两个要求:1)需要识别与习语相关联的情感，以及 2)需要自动识别文本中的习语。

# 什么是成语？

在进入技术层面之前，我们先来定义一下什么是成语。

成语通常被定义为多词表达[](https://aclweb.org/aclwiki/Multiword_Expressions)**s*(由至少两个词组成的表达或短语)。但是使它们与其他短语不同的是，它们的整体意思不能从构成习语的每个单词的字面意思中猜测出来。例如，*离开水的鱼*是用来指在某个特定情境下感到不舒服的人，而不是它的字面意思。下图提供了英语习语的其他例子。*

*![](img/13f3f79a9b57fffe5d95481e42ccf57e.png)*

*卡普兰关于货币和金融的习语示例*

*但正因为如此，习语对语言学习者来说是一个挑战。因此，相对于学习它们的结构而言，它们和它们的意义被教授和记忆是很常见的。*

*为了将习语与其他短语和谚语区分开来，可以考虑以下属性:*

*   *惯例:一个习语的整体意思不能(完全)从组成它们的每个单词的字面意思中预测出来。*
*   **不灵活*:它们的语法是受限制的，也就是说，它们的构成方式没有太大变化。*
*   **比喻*:它们通常具有源于隐喻、夸张和其他类型比喻的比喻意义。*
*   *众所周知:它们通常描述一种反复出现的社会状况。*
*   *非正式:它们与不太正式的语言如口语联系在一起。*
*   *影响:他们通常暗示对某事的情感态度，而不是中立的态度。*

*最后一个属性， *affect* ，意味着习语本身可以用于确定一段文本中表达的情感。例如，“我对结果感到欣喜若狂”表达了一种积极的情绪。*

# *数据收集*

## *风格*

*为了使用习语作为情感分析的特征，我们需要更多关于它们潜在情感的信息。在这种情况下，我们求助于 [Learn English Today](https://www.learn-english-today.com/) 网站，该网站按主题整理了 580 个习语，其中许多可以直接(例如*快乐、悲伤*)或间接(例如*成功、失败*)映射到一种情绪。我们特别关注与情感相关的习语，因为它们预计会对情感分析结果产生一些影响。我们从总共 60 个可用主题中选择了 16 个，并在下表中列出了相关习语的数量。*

*![](img/d76d47e76adb6b7344b0f7cef1ff1bbd.png)*

*跨主题的习语分布([表 1](https://www.sciencedirect.com/science/article/pii/S0957417415003759)*

## *文集*

*除了一系列习语，我们还需要它们在上下文中使用的例子。在这种情况下，我们搜索了英国国家语料库(一个从各种来源收集的书面和口头英语的大型文本语料库)，寻找在不同上下文中使用的 580 个习语的例子。总的来说，我们收集了 2521 个句子，其中包含一个可以与习语匹配的表达式。*

*在大多数情况下，习语都有与之相关的比喻意义。但在其他情况下，他们传达的是字面意思。从这个意义上说，有些句子是误报的。例如:*

*“威尔士农民的儿子已经将 1988 年有条件骑师的头衔收入囊中。”*

*“我看了看袋子，里面全是鱼。”*

*有必要包括假阳性，这样我们就可以评估错误识别的习语会如何影响情感分析的结果。*

## *手动注释习惯用法*

*虽然习语已经在许多学科得到了广泛的研究，但到目前为止，还没有一套完整的习语被系统地映射到他们的情感上。这就是为什么习语在情感分析中作为特征的代表性不足的主要原因。*

*在这种情况下，至少需要 3 名注释者来标记上下文中使用的每个成语示例是否反映了积极、消极、中立或模糊的情绪。同样，要求 5 名注释者断章取义地标记每个习语表达的情感。*

*为了测量带注释的数据集的可靠性，我们使用 [Krippendorff 的 alpha 系数](https://en.wikipedia.org/wiki/Krippendorff%27s_alpha)来测量注释者之间的一致性。还有其他协议度量，但是，这种度量被认为是可靠的，因为它考虑了任意数量的注释者(不仅仅是两个)、任意数量的类别，并且考虑了不完整或缺失的数据。*

*Krippendorff 的α系数根据以下公式计算:*

*![](img/32ba6aa4ede65f16e50a972457385825.png)*

*克里彭多夫阿尔法系数*

*其中 *Do* 是观察到的不一致(两个注释者都同意的项目的比例)，而 *De* 是随机给出注释时预期的不一致。Krippendorff 建议将α = 0.667 作为最低可接受值，以将数据集视为训练模型的可靠数据集。Krippendorff 的α系数 1 表示完全一致，而 0 直观地表示不一致。因此，较高的值表示更好的一致性。*

*在习语数据集上的一致性计算为 *De* = 0.606， *Do* = 0.205，α = 0.662。在上下文中使用的成语语料库的一致度计算为 *De* = 0.643， *Do* = 0.414，α = 0.355。*

*仅习语的一致性(α = 0.662)就说明了它们在某种程度上可以映射到它们的情感极性。然而，在成语的上下文例子上显著较低的一致性(α = 0.355)说明了注释者的主观情感解释。*

*Krippendorff 的 alpha 系数的值可以使用计算注释者协议的在线工具获得，例如 [ReCal](http://dfreelon.org/utils/recalfront/) ，或者可以在 [Python](https://github.com/grrrr/krippendorff-alpha) 中实现。*

## *金本位*

*然后，带注释的上下文实例被用来为情感分析实验创建一个黄金标准(被认为是最有效的标准)。为了创造一个黄金标准，至少 50%的注释者中的相对多数同意的每一句注释都被视为基本真理。也就是说，如果两个注释者同意“好吧，不要*打断我的话”*反映了负面情绪，而第三个注释者注意到它反映了正面情绪，则与该句子相关联的基本事实被确定为负面的。*

# *习语认可*

*为了将习语作为情感分析的特征，我们需要在文本中自动识别它们的方法。事实上，大多数习语的结构都是不灵活的*，这使得这一点变得可行。**

**词汇句法模式(一种基于文本标记和句法结构的字符串匹配模式)可以用于计算建模习语，以自动识别它们在文本中的出现。许多习语是冻结的短语(它们的结构不变)，可以通过简单的字符串匹配来识别。但是句法上的变化，如词形变化(如动词时态的变化)，也会在习语中出现。这些可以使用正则表达式(RegEx)来建模，例如 *spill[s|t|ed] the beans，*或者对于更复杂的习语，使用词汇句法模式(例如*将 NP 放在 PRN 的位置*)。**

**在这种情况下，习语识别规则被实现为一种简单的模式匹配语言 [Mixup](http://minorthird.sourceforge.net/old/doc/tutorials/Mixup%20Tutorial.htm) (我的信息提取和理解包)中的表达式。例如，下面的语法:**

**《习语》: =《VB》《PRP》《PRP 袖上的心》**

**﹔VB ﹔: = wear | wear | wear | wear | wear**

**〈PRP$〉 ::=我的，你的，他的，她的，它的，我们的，他们的**

**被用来成功地识别出习语*下面这句话中的穿心*:**

**“与其把你的心放在袖子上，而不是放在帽子下面，你不如把它藏起来。”**

**将模式匹配规则应用于 500 个句子的测试数据集(原始数据集的 40%)，其中注释者标记所有习语出现，区分比喻和字面意义。例如:**

**“唷，那真是一次〈习语〉 *千钧一发* 〈习语】。”**

**“他的鞋子擦得锃亮，胡子刮得很干净，而且太骄傲了，不想喝免费的酒。”**

**识别习语的表现以 97.14%的 F1 分数记录，其中如果建议的文本跨度与注释者标记的文本跨度完全匹配，则认为习语被正确识别。**

**![](img/f18cb5876a0d98354d0f4ba0e2a7f102.png)**

**使用 Mixup 识别习语**

# **特征工程**

**为每个习语收集的 5 个注释用于计算它们的特征向量。每个习语被表示为一个三元组:(正、负、其他)，其中每个值表示相应类别中注释的百分比。比如习语*穿心*收到了 1 个正面，0 个负面，4 个其他注解。因此，它被表示为以下三元组:(20，0，80)。**

**由于我们想要调查习语作为情感分析中的特征的影响，我们进行了两个实验，其中我们将习语的三重表示与两种流行的情感分析方法的结果相结合: [SentiStrength](http://sentistrength.wlv.ac.uk/) 和 [Stanford CoreNLP 的情感注释器](https://stanfordnlp.github.io/CoreNLP/sentiment.html)。**

**在第一个实验中，我们使用了 SentiStrength，这是一种词袋方法，它通过聚合单个词的极性来为句子分配情感极性**

***输入:*晚会结束*。***

***解析:当事人[1]超过了[1]。***

***输出:结果= 0，正= 1，负= 1***

**如给定示例所示，短语 *party is over* 将被识别为习语，它映射到以下三元组:(0，100，0)表示所有注释者都认为它是否定的。我们将这两个向量相加，为给定的句子创建一个单一的特征向量，如下所示:**

**![](img/ca41bb72a07c0b1560335c00e6cf134c.png)**

**在第二个实验中，我们使用了作为 Stanford CoreNLP(一套核心 NLP 工具)的一部分分发的情感注释器。该方法使用递归神经网络，通过在 5 点尺度上对每个子树进行分类(非常负面、负面、中性、正面和非常正面),在解析树的所有组成级别上执行情感分析。除了分类之外，它还提供了跨 5 个类别的概率分布，通过将它们转换成 5 维向量，我们在我们的方法中将其用作特征。如前所述，习语*聚会结束了*将被识别，并且其三元组被附加以创建给定句子的单个特征向量，如下所示:**

**![](img/56f899c54555718d8e86e3ef41164c42.png)**

**对于这两个实验，为每个句子产生的特征向量与它们的基础真实类标签连接在一起:**

**![](img/50196bfd5886e2a5fe79aa84fc97b616.png)**

# **情感分类**

**一旦我们将习语和习语的上下文实例作为特征向量来表示和组合，我们就使用一套流行的机器学习软件 [Weka](https://www.cs.waikato.ac.nz/ml/weka/) 来训练分类器并进行分类实验。我们基于对训练数据集(原始数据集的 60%)的交叉验证实验的结果来选择机器学习方法。贝叶斯网络分类器优于其他方法。**

**分类性能根据三个指标进行评估——精确度(P)、召回率(R)和基于真阳性(TP)、假阳性(FP)和假阴性(FN)数量的 F1 分数。**

**![](img/96dbed5d255dbe52d52afa915b23f7d4.png)**

**[使用 SentiStrength 作为基线方法的评估结果](https://www.sciencedirect.com/science/article/pii/S0957417415003759)**

**![](img/17faa6058f32d15a13e876f255ddb4d6.png)**

**[使用 Stanford CoreNLP 情感标注器作为基线方法的评估结果](https://www.sciencedirect.com/science/article/pii/S0957417415003759)**

# **结论**

**那么，我们从这个分析中学到了什么？**

**我们证明了习语作为情感分析特征的价值，通过表明当习语存在时，基于习语的特征显著地改善了情感分类结果。F1 分数的整体表现在一个实验中从 45%提高到 64%，在另一个实验中从 46%提高到 61%。**

**下一步是探索如何使用正则表达式在 Python 中实现习语识别规则。这是为了使习语识别规则更易于使用并且与使用 [Scikit-learn](https://scikit-learn.org/stable/) 构建情感分类器兼容。**

**对于完整的数据集和混淆规则，请查看下面我的 GitHub repo:[https://github.com/LowriWilliams/Idiom_Sentiment_Analysis](https://github.com/LowriWilliams/Idiom_Sentiment_Analysis)**