<html>
<head>
<title>Logistic Regression: Discover the Powerful Classification Technique</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归:发现强大的分类技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-discover-the-powerful-classification-technique-d60c0ae4d3b1?source=collection_archive---------75-----------------------#2020-06-15">https://towardsdatascience.com/logistic-regression-discover-the-powerful-classification-technique-d60c0ae4d3b1?source=collection_archive---------75-----------------------#2020-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="89b4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解最广泛使用的分类技术之一</h2></div><p id="f523" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用预测技术区分分类数据的过程称为<strong class="kk iu">分类</strong>。在由已知类别成员的观察组成的训练数据的基础上，<strong class="kk iu">分类器</strong>(实现分类的算法)<strong class="kk iu"> </strong>应该在<strong class="kk iu">解释变量</strong>(特征)的基础上学习新观察属于哪个类别。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/795f5fd1d098b86b1e708da63f14d837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*rwzCTAzTdnodSe0lcsSYEg.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">二元分类程序</p></figure><p id="3cd6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们考虑<strong class="kk iu">逻辑回归</strong>，它是最基本和最广泛使用的分类方法之一。</p><h1 id="b504" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated"><strong class="ak">逻辑回归——我们在建模什么？</strong></h1><p id="6ecb" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">逻辑回归模拟一个二元分类因变量<strong class="kk iu">Y，它可以取两个可能的值；“0”或“1”。这两个值代表观察结果所属的两个类别(真/假、赢/输、健康/生病)。逻辑回归通过使用<strong class="kk iu">逻辑(sigmoid)函数</strong>估计概率，测量分类因变量和一个或多个解释变量(特征)X之间的关系。</strong></p><p id="d1ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">例如</strong>，当我们想要预测一家银行未来的贷款违约时，我们可以使用逻辑回归，使用违约者与未违约者的某些特征进行比较。这里，分类因变量的默认值为1，无默认值为0。X中的解释变量是人民的特征。</p><h1 id="78bc" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">逻辑回归—预测概率</h1><p id="a218" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">现在，让我们利用前面提到的逻辑(sigmoid)函数，给定X中的解释变量的值，对因变量Y达到值1的<strong class="kk iu">预测概率</strong>进行建模:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/242ee29d1d6e6704aaf18d7925445198.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*qRtt2OKt0j-DK2r35qckVQ.png"/></div></figure><p id="4cdb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中“exp”是指数(因此，将exp(z)读作e的z次方)，β0是截距，β1是包含每个解释变量系数的向量。通过使用逻辑函数，我们保证预测的概率在0和1之间。这正是我们在这里不能使用线性回归模型的原因，因为那时预测的概率被建模为在-无穷大和+无穷大之间，这违反了概率规则(概率应该总是在0和1之间)。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/2196f0e9a238f7521180e41adb243e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*02hW-hpXUvOZXGvrh1QXAQ.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">Sigmoid函数</p></figure><p id="19d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分类是通过使用判定边界来执行的，判定边界有助于区分这两个类别。在最简单的情况下，使用0.5的判定边界，以便在下列情况下，新的观察值被放置在“正”类(Y=1)中</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/4eaa9977e6c38aa3f4f9caf9ff73ddd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:218/format:webp/1*BHXfcOqxH0Rm5LvXvrR4qA.png"/></div></figure><p id="4d7f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">否则属于“负”类(Y=0)。</p><h1 id="c79c" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">最大似然估计-估计系数</h1><p id="926d" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">利用<strong class="kk iu">最大似然估计(MLE) </strong>来估计逻辑回归模型的系数。当使用MLE时，通过最大化一个<strong class="kk iu">似然函数</strong>来估计模型的参数，从而在假设的逻辑回归模型下，训练数据是最可能的。</p><p id="007b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了防止这篇文章“太数学化”，我们不会深入MLE过程。尽管如此，如果你感兴趣，我鼓励你查找似然函数的推导，对数似然函数和最优化过程。</p><h1 id="d61d" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated"><strong class="ak">逻辑回归—(对数)比值比</strong></h1><p id="dc0f" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated"><strong class="kk iu">比值比</strong>计算如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/e4ff3806ab7597744cf407e8c53ad65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*QmiCpRR7NKJx8aQnJHA2qw.png"/></div></figure><p id="cb1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过取对数，我们得到<strong class="kk iu">对数比值比</strong>:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/b75911819635cf722fb34996cb883474.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*QhbAnZTLsp68y2yq16_zEg.png"/></div></figure><p id="848b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比值比是一个事件发生在一组中的几率与发生在另一组中的几率之比。假设我们正在对贷款违约进行建模，其中Y=1表示违约。那么，举例来说，如果10个人中有1个人违约，赔率就是1/9。</p><p id="dd6f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">标有“1”的值的对数概率是解释变量的线性组合。</p><p id="c387" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，与线性回归相反，解释变量的系数并不对应于X增加一个单位时p(X)的变化。但是，p(X)的变化量仍然取决于X。</p><h1 id="ba50" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">逻辑回归——超过两个类别？</h1><p id="fdac" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">回想一下，逻辑回归分类器是一个二元分类器。然而，我们可能希望对两个以上的类别使用逻辑回归(<strong class="kk iu">多类分类</strong>)。幸运的是，有逻辑回归的巧妙扩展可以做到这一点。其中一个扩展是<strong class="kk iu"> one-vs-rest逻辑回归</strong>，为每个类别训练一个单独的模型，以预测一个看不见的观察值是否在该特定类别中(从而使其成为一个二元分类问题)。它假设每个单独的分类问题都是独立的。通过运行所有这些独立的逻辑回归模型，对于每一类，我们都可以获得该观测值属于该特定类的预测概率。然后，将观察值分配给获得最高预测概率的类别。</p><h1 id="95bd" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">感谢阅读！</h1><p id="b7dc" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">在本文中，我们发现了用于机器学习和预测建模的逻辑回归算法。祝你在未来的项目中应用逻辑回归好运！</p></div></div>    
</body>
</html>