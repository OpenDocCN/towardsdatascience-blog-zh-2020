<html>
<head>
<title>The Easy Way to Web Scrape Articles Online</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网上搜集文章的简单方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-easy-way-to-web-scrape-articles-online-d28947fc5979?source=collection_archive---------27-----------------------#2020-06-11">https://towardsdatascience.com/the-easy-way-to-web-scrape-articles-online-d28947fc5979?source=collection_archive---------27-----------------------#2020-06-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a27357c4cb4e0681902c814f19e5b856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*paXuxAM9PZYkIBOEuE3-UA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">文章刮刀截图由安德鲁贝里</p></figure><div class=""/><div class=""><h2 id="aae5" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">在我的朋友newspaper3k插件的一点帮助下，我们可以将来自不同新闻媒体的文章语料库放入熊猫数据框架。</h2></div><p id="7522" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">前几天，我在做一个项目，需要我在网上搜集一堆新闻文章。我了解自己，我想找出最简单快捷的方法来完成这个任务。</p><p id="6662" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">有一些著名的python插件可以帮我完成这项工作，其中一个是<a class="ae lq" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>。这是一个很棒的插件，但是我不想深入了解每个在线新闻平台独特的html结构。</p><p id="11f4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">通过大量的谷歌搜索，我确实找到了解决问题的简单方法。我找到了<a class="ae lq" href="https://newspaper.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">报社3k </a>！</p><p id="e45f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在本教程中，我将向你展示如何快速地将来自不同新闻媒体的大量新闻文章整合到一个简单的python脚本中。</p><h1 id="68e4" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">如何使用Newspaper3k抓取网上文章</h1><p id="7918" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">首先，我们需要将python插件安装到您的环境中。</p><p id="c5d5" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">专业提示:创建另一个虚拟python环境，这被认为是最佳实践。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="e936" class="my ls jf mu b gy mz na l nb nc">$ pip install newspaper3k</span></pre><h2 id="8656" class="my ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated">基础知识</h2><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="cfaf" class="my ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated">高级:从一个新闻网站下载多篇文章</h2><p id="72dd" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">当我抓取一堆新闻文章时，我想从一个新闻网站抓取一堆文章，然后把所有的东西放在一个熊猫数据框架中，这样我就可以把数据导出到一个<em class="mo">中。csv </em>文件。<strong class="kw jg">在这个插件的帮助下做起来其实挺简单的。</strong></p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="fc05" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">….这就对了。你就是这样轻松刮出一堆文章的。</p><p id="c9d4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">使用上面的代码，您可以实现一个for循环，来循环访问一堆报纸源。创建一个巨大的最终数据框架，你可以导出它，然后用它来玩。</p><h2 id="3dbd" class="my ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated">发烧友:多线程网页抓取</h2><p id="0f11" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">然而，我上面提出的解决方案对某些人来说可能有点慢，因为它一篇接一篇地下载每篇文章。如果你有很多新闻来源，这可能会有点费时。然而，<strong class="kw jg">有一种方法可以加速这一切</strong>。我们可以在多线程技术的帮助下做到这一点。</p><p id="6ccf" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="mo">注意:在下面的代码中，我实现了每个源的下载限制。在运行这个脚本时，您可能想去掉它。限制was的实现是为了让用户在运行时测试他们的代码。</em></p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="192a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我喜欢<strong class="kw jg">边做边学</strong>，所以我建议任何阅读本书的人去<strong class="kw jg">玩上面的代码</strong>。从这里开始，你现在可以使用newspaper3k来抓取文章。快乐的网页抓取！</p><p id="2f15" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">注意事项:</strong></p><p id="63f1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="mo">注意:从每个在线新闻渠道抓取大量文章的成功因渠道而异。</em></p><p id="54c9" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="mo">注意:Newspaper3k的多线程特性有时会出错。取决于新闻渠道。网络抓取文章每个新闻出口使用。构建功能是最可靠的。</em></p><p id="d281" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">然而，在大多数情况下，它工作得很好！</p></div><div class="ab cl nq nr hu ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ij ik il im in"><p id="2a9d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">一定要看看我的其他网页抓取媒体帖子。</p><div class="ip iq gp gr ir nx"><a rel="noopener follow" target="_blank" href="/how-to-collect-comments-from-any-new-york-times-article-to-a-pandas-dataframe-a595ec6a1ddf"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd jg gy z fp oc fr fs od fu fw je bi translated">如何从《纽约时报》的任何一篇文章中收集对熊猫数据框架的评论</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">《纽约时报》( NYT)最精彩的部分是他们对文章积极且高度节制的评论部分。</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="oh l oi oj ok og ol ix nx"/></div></div></a></div></div><div class="ab cl nq nr hu ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ij ik il im in"><h2 id="e153" class="my ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated">参考</h2><p id="5c59" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">[1] Newspaper3k:文章搜集与整理文档，<a class="ae lq" href="https://newspaper.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://newspaper.readthedocs.io/en/latest/</a></p></div></div>    
</body>
</html>