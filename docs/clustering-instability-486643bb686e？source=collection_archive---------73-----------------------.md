# 聚集不稳定性

> 原文：<https://towardsdatascience.com/clustering-instability-486643bb686e?source=collection_archive---------73----------------------->

## S 选举集群数量

聚类是一种无监督的学习技术，用于创建数据点的聚类。营销中的客户细分就是一个例子。

有几种聚类算法可用。然而，它们需要给定聚类数(k)作为输入。选择聚类的数量可能是困难的，因为这是一个无监督的问题，没有标签。

给定 k，可以测量聚类不稳定性以确定聚类算法的性能。我们更希望聚类是稳定的，但这意味着什么呢？

![](img/4a98768f28591d01fdcf4813e3bcd337.png)

假设你有一个观察样本(X)，我们可以打乱这个数据集，取三个子样本。这三个子样本来自同一个样本 X，因此它们应该遵循相同的结构。

我们选择聚类算法并训练两个不同版本的模型。首先，在数据集 z1 上拟合模型。第二，在数据集 z2 上拟合不同的模型。在这两种情况下，给定特定的 k 值，即聚类数，应用相同的算法。

> 型号 1.fit(z1)
> 
> 模型 2 .拟合(z2)

在两个模型都被训练之后，我们预测第三个(验证)子样本 z3 的标签。

> 预测模型 1(z3)
> 
> 预测模型 2(z3)

为了测量该聚类映射的不稳定性，我们计算如下:

*   对于每一个观察点 ***i*** 和它的邻居 ***j = i+1***
*   检查模型 1 是否同意它们具有相同的标签:标签 1(xi) =标签 1(xj)
*   检查模型 2 是否同意它们具有相同的标签:标签 2(xi) =标签 2(xj)

如果模型 1 将观察值 I 和 j 标记为相等，但是另一方面，模型 2 将两者标记为不同，这将导致聚类映射的不稳定性。

> 如果同意 1！=同意 2:
> 
> 不稳定性+= 1

这就引出了这个 k 和这些子样本的不稳定性分数。我们希望对 k 的范围重复这一过程，以评估所有的聚类不稳定性。

最后，我们选择使不稳定性最小化的聚类数(k)。

## *如有任何关于理论或如何编码的问题，请随时回复。*

*我目前正在开发一个应用程序，通过潜在的狄利克雷分配来选择主题建模中的主题数量，如果您想看后续报道，请告诉我！*

![](img/fb36ffbc47b1eeafb0f04ec3e695a671.png)