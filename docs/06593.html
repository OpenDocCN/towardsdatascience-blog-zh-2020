<html>
<head>
<title>How are Americans reacting to Covid-19?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">美国人对新冠肺炎的反应如何？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-are-americans-reacting-to-covid-19-700eb4d5b597?source=collection_archive---------65-----------------------#2020-05-24">https://towardsdatascience.com/how-are-americans-reacting-to-covid-19-700eb4d5b597?source=collection_archive---------65-----------------------#2020-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2d47" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Twitter和情感分析来回答这个问题</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/08f8721d7a6ad430ac995eb307d194d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*G7hhNbwwhrbLlfTw5IPSSg.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片来源:推特</p></figure><p id="12de" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">新冠肺炎疫情对整个世界构成了前所未有的挑战。由于确诊病例和死亡人数最多，美国是受病毒打击最严重的国家之一。随着各州开始部分重新开放，这个国家在这个问题上变得非常两极分化。一些人坚决支持这项措施，认为这对国家的经济健康非常重要。然而，其他人对此强烈反对，认为重新开放的人力成本是不合理的。在局势高度紧张的时候，我试图更好地了解美国人对新冠肺炎当前局势的真实感受。</p><p id="b2e4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了回答这个问题，<a class="ae lq" href="https://medium.com/@smediboina1" rel="noopener">斯里汉·梅迪博纳</a>和我一起从推特上搜集与新冠肺炎有关的推文，并对它们进行情感分析。为了了解美国各地的反应如何不同，我们使用了来自纽约、德克萨斯州和加利福尼亚州的推特。让我们进入项目吧！</p><h1 id="1e69" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">获取Twitter数据</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mj"><img src="../Images/d319695d8b08ff788f52baff6ec040b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UKiOVwTLOHADu_Lk13nkaQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片来源:Tweepy</p></figure><p id="f702" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在访问我们的Twitter API凭证之前，我们需要申请一个Twitter开发者帐户。一旦我们的应用程序被批准，我们就可以使用Tweepy访问API并下载一个标签的所有tweets。调用<code class="fe mo mp mq mr b">search_for_hashtag</code>函数允许我们快速抓取标签中的数据(#冠状病毒、#新冠肺炎、#纽约、#加州、#德克萨斯是我们使用的一些标签)。要更深入地了解Tweepy，请查看这篇<a class="ae lq" rel="noopener" target="_blank" href="/tweepy-for-beginners-24baf21f2c25">文章</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="ebc0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用朴素贝叶斯分类器进行情感分析，这需要标记数据，因为它是一种监督学习算法。因此，我们手动标记了来自这三个州的500条推文，总共1500条推文。每条推文要么负面情绪得分为-1，中性情绪得分为0，正面情绪得分为1。如果你有兴趣进行自己的分析，这里有一个<a class="ae lq" href="https://github.com/Srihan-Mediboina/Twitter-Sentiment-Analysis" rel="noopener ugc nofollow" target="_blank">链接</a>到数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mu"><img src="../Images/fa170db864366e9e458ba851ca024d10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*auhtVdWnPEAEiQZkI61gKA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">加利福尼亚推特数据集的前5行</p></figure><h1 id="a8a2" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">符号化</h1><p id="8140" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">现在，我们通过将推文拆分成单独的单词(称为令牌)来对推文进行令牌化。没有令牌，我们就无法执行情感分析的后续步骤。当我们从自然语言工具包(<code class="fe mo mp mq mr b">nltk</code>)中导入<code class="fe mo mp mq mr b">TweetTokenizer</code>时，这个过程就变得简单了。<code class="fe mo mp mq mr b">tokenize_tweets</code>函数只有两行代码，我们可以将它应用于数据帧来分解推文。<code class="fe mo mp mq mr b">nltk</code>是一个非常强大的情感分析包，因此我们将在整篇文章中使用它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mu"><img src="../Images/0453da2dac0009620ffc2f90db4758e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4leDTGc5h4E1eO3udJ0A9w.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">令牌化后的CA数据集</p></figure><h1 id="a846" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">停用词</h1><p id="3881" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">停用词是常见的词，如“the”、“a”和“an”。因为这些词不能加深我们对文本情感的理解，我们把它们过滤掉。通过从<code class="fe mo mp mq mr b">ntlk</code>导入停用词，这一步变得非常简单:<code class="fe mo mp mq mr b">remove_stopwords</code>函数也是两行代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mu"><img src="../Images/8a367bc4a26d395192af2bb67709d097.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WarAUl_0f3UZHBzwJQAweA.png"/></div></div></figure><p id="b87d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从我们的California数据集的前几行中删除的一些停用词包括“Some”、“can”、“just”和“for”。</p><h1 id="827a" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">清理文本</h1><p id="d06d" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">除了移除停用字词之外，我们还希望确保移除数据框中的任何随机字符。例如，在我们抓取推文后，csv文件中出现了几个字符，如“x97”和“xa3”。通过迭代找到这些杂项字符后，我们将它们复制粘贴到<code class="fe mo mp mq mr b">CleanTxt</code>函数中。然后，我们对每个数据帧应用该函数来移除它们。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mu"><img src="../Images/7bd94748d42141b381698b2dc488ff4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QAZWG8Tf-bsx-bJ0q54j9w.png"/></div></div></figure><p id="b533" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如我们所见，标签是被删除的最普遍的字符。通过清理文本，我们可以提高模型的性能。</p><h1 id="0df6" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">词汇化</h1><p id="0e86" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">通常，指同一事物的词以不同的形式出现(例如。麻烦，困扰，困扰，麻烦本质上都是指麻烦)。通过对文本进行词条分类，我们将一个单词的各种词形变化组合在一起，作为该单词的词条(它在词典中的出现方式)进行分析。这个过程防止计算机将一个单词的不同形式误认为不同的单词。我们从<code class="fe mo mp mq mr b">nltk</code>导入<code class="fe mo mp mq mr b">WordNetLemmatizer</code>，并为此调用<code class="fe mo mp mq mr b">lemmatize_tweets</code>函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h1 id="f622" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">主数据集</h1><p id="02bb" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">既然我们已经完成了预处理步骤，我们可以继续创建一个包含所有1，500条推文的主数据集。通过使用<code class="fe mo mp mq mr b">df.itertuples</code>，我们可以将dataframe行作为元组进行迭代，以将<code class="fe mo mp mq mr b">‘tweet text’</code>和<code class="fe mo mp mq mr b">‘values’</code>属性添加到我们的数据集。然后，我们使用<code class="fe mo mp mq mr b">random.shuffle </code>打乱我们的数据集，以防止我们的模型成为过度拟合的牺牲品。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="1e27" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">接下来，我们遍历所有的数据帧，并将每个单词添加到<code class="fe mo mp mq mr b">all_words list</code>中。接下来，我们使用<code class="fe mo mp mq mr b">nltk.FreqDist</code>来创建每个单词的频率分布。由于一些单词比其他单词更常见，我们希望确保使用最相关的单词来训练我们的朴素贝叶斯分类器。目前，每条推文都是一个单词列表。然而，我们可以将每条tweet表示为一个字典，而不是一个列表:关键字是单词特征，值是真或假，取决于tweet是否包含该单词特征。这个代表推文的字典被称为特征集。我们将为每条推文生成特征集，并在特征集上训练我们的朴素贝叶斯分类器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h1 id="378a" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">训练/测试模型</h1><p id="6efe" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">feature_sets将被分别分成80/20个训练集和测试集。在训练集上训练了朴素贝叶斯分类器之后，我们可以通过将它对推文情绪的预测(<code class="fe mo mp mq mr b">results[i]</code>)与推文的标签情绪(<code class="fe mo mp mq mr b">testing_set[i][0]</code>)进行比较来检查它的性能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/dd508cd8e06ce0dd41cdf72f08f2e19a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*0FzWzT68Nr5TqWyajKTSjA.png"/></div></figure><p id="3bda" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的输出在左边显示预测值，在右边显示实际值。40%的误差百分比非常高，这意味着我们的模型只有5次中的3次是准确的。一些可以使我们的模型更准确的改进是使用更大的训练集或使用验证集来测试不同的模型，然后选择最有效的模型。</p><h1 id="3dc3" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">使用模型</h1><p id="c31f" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">有了经过训练/测试的模型，我们现在可以用它来对一批新的推文进行预测。我们收集了更多的tweets，并对新的数据帧执行了与之前相同的预处理步骤:<code class="fe mo mp mq mr b">ca_new_df</code>、<code class="fe mo mp mq mr b">ny_new_df</code>和<code class="fe mo mp mq mr b">tx_new_df</code>。我们的分类器的预测存储在<code class="fe mo mp mq mr b">results_new_ca</code>、<code class="fe mo mp mq mr b">results_new_ny</code>和<code class="fe mo mp mq mr b">results_new_tx</code>中。我们的最后一步是使用<code class="fe mo mp mq mr b">sentiment_percent</code>函数来量化百分比。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><pre class="kj kk kl km gt nb mr nc nd aw ne bi"><span id="e2d9" class="nf ls it mr b gy ng nh l ni nj">sentiment_percent(results_new_ca)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/8daabb9fe8b490a70f3c1a51c3557512.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*0YGzJyG7Ra5wEtjbFBzvbQ.png"/></div></figure><pre class="kj kk kl km gt nb mr nc nd aw ne bi"><span id="6db1" class="nf ls it mr b gy ng nh l ni nj">sentiment_percent(results_new_ny)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/63092545e6e0d28fd58764dbab83425c.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*dgT90lXSf02i9GyBwnHhTg.png"/></div></figure><pre class="kj kk kl km gt nb mr nc nd aw ne bi"><span id="1b85" class="nf ls it mr b gy ng nh l ni nj">sentiment_percent(results_new_tx)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/60b672a24be5cf1936e8d7ef98d80cc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*C62qRD5NOtbY4kx72hxVGA.png"/></div></figure><p id="8d20" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我们的结果中，加利福尼亚州只有大约6%的推文是正面的，而德克萨斯州有大约27%的推文是负面的。加州和纽约都有73%的推文是中性的，其正负百分比相差约4%。德克萨斯州的确有最多的负面推文，但他们也有最多的正面推文，约为10%，因为他们的中立推文比例较低。重要的是要记住，我们的模型只有60%的准确性，所以这些结果可能不是这些推文中表达的真实情绪的最大指示。</p><p id="55e6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了简洁起见，本文省略了一些代码。点击<a class="ae lq" href="https://github.com/Srihan-Mediboina/Twitter-Sentiment-Analysis/blob/master/sentiment_analysis.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a>查看完整代码。</p><h1 id="c5d2" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">参考</h1><p id="8bc1" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">[1]计算机科学频道，<a class="ae lq" href="https://www.youtube.com/watch?v=ujId4ipkBio" rel="noopener ugc nofollow" target="_blank">使用Python的Twitter情绪分析</a>，Youtube</p><p id="1e31" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[2]薇琪·钱，<a class="ae lq" href="https://gist.github.com/vickyqian/f70e9ab3910c7c290d9d715491cde44c" rel="noopener ugc nofollow" target="_blank"> Twitter爬虫</a>，Github</p><p id="2f20" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[3]Mohamed Afham，<a class="ae lq" rel="noopener" target="_blank" href="/twitter-sentiment-analysis-classification-using-nltk-python-fa912578614c">使用NLTK的Twitter情感分析，Python </a>，走向数据科学</p><p id="2c0c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[4]亚当·马伊穆达尔，<a class="ae lq" href="https://medium.com/@mr.adam.maj/machines-key-to-understanding-humans-how-i-used-natural-language-processing-to-analyze-human-9745d04e534b" rel="noopener">机器理解人类的钥匙</a>，中型</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="2a33" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">感谢您阅读文章！我是Roshan，16岁，对人工智能的各种应用充满热情。在这个项目上，我与另一个对人工智能有浓厚兴趣的青少年斯里汉·梅迪博纳密切合作。</p><p id="22ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在Linkedin上联系我们:</p><p id="298a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://www.linkedin.com/in/roshan-adusumilli/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/roshan-adusumilli/</a></p><p id="285e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://www.linkedin.com/in/srihanmediboina/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/srihanmediboina/</a></p></div></div>    
</body>
</html>