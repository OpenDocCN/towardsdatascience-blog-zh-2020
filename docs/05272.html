<html>
<head>
<title>Trump VS Trudeau: Who Makes Better Use of Twitter During COVID-19 Crisis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">川普VS特鲁多:新冠肺炎危机期间谁更好地利用了推特</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/trump-vs-trudeau-who-makes-better-use-of-twitter-during-covid-19-crisis-16b360131e22?source=collection_archive---------68-----------------------#2020-05-04">https://towardsdatascience.com/trump-vs-trudeau-who-makes-better-use-of-twitter-during-covid-19-crisis-16b360131e22?source=collection_archive---------68-----------------------#2020-05-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="636c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在新冠肺炎疫情期间，人们将他们的担忧、担忧、沮丧和爱带到社交媒体上与世界其他地方分享。Twitter已经成为世界领导人与其支持者和追随者交流的官方渠道之一。</p><p id="0518" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了了解他们在忙什么，我们摘录了两位世界领导人唐纳德·川普(美国总统)和贾斯廷·特鲁多(加拿大总理)的推特。通过应用自然语言处理技术和潜在狄利克雷分配(LDA)算法，可以学习他们推文的主题。因此，我们可以看到危机期间他们在想什么。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/527ac2cc0957a002c05daa127bae020e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YHihvPV_8SY-m4VXYyNHHQ.jpeg"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">由<a class="ae lb" href="https://unsplash.com/@chris_robert" rel="noopener ugc nofollow" target="_blank">克里斯·罗伯特</a>上<a class="ae lb" href="https://unsplash.com/license" rel="noopener ugc nofollow" target="_blank">的Unsplash </a></p></figure><p id="46f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用Python 3.6和以下软件包:</p><ul class=""><li id="6cac" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lh li lj lk bi translated"><a class="ae lb" href="https://github.com/taspinar/twitterscraper" rel="noopener ugc nofollow" target="_blank"> TwitterScraper </a>，一个抓取推文的Python脚本</li><li id="b60d" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">NLTK(自然语言工具包)，一个用于文本处理的NLP包，例如停用词、标点符号、标记化、词条化等。</li><li id="d04a" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">Gensim ，“生成相似”，一个流行的用于主题建模的NLP包</li><li id="b9af" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated"><a class="ae lb" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank">潜在狄利克雷分配</a> (LDA)，一种用于主题聚类/建模的生成式概率模型</li><li id="ada7" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated"><a class="ae lb" href="https://github.com/bmabey/pyLDAvis" rel="noopener ugc nofollow" target="_blank"> pyLDAvis </a>，一个交互式LDA可视化软件包，旨在帮助解释在文本数据语料库上训练的主题模型中的主题</li></ul><h1 id="b789" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">数据采集</h1><p id="dabb" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">我们使用<a class="ae lb" href="https://github.com/taspinar/twitterscraper" rel="noopener ugc nofollow" target="_blank"> TwitterScraper </a>从Twitter handle @realDonaldTrump和@JustineTrudeau收集推文。仅收集2020年3月1日至4月27日发布的原创推文，不转发他人推文。只有英语。</p><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="e6e9" class="my lr iq mu b gy mz na l nb nc"><strong class="mu ir">from</strong> <strong class="mu ir">twitterscraper</strong> <strong class="mu ir">import</strong> query_tweets<br/><strong class="mu ir">import</strong> <strong class="mu ir">datetime</strong> <br/><strong class="mu ir">import</strong> <strong class="mu ir">pandas</strong> <strong class="mu ir">as</strong> <strong class="mu ir">pd</strong><br/><strong class="mu ir">import</strong> <strong class="mu ir">re</strong>, <strong class="mu ir">pickle</strong>, <strong class="mu ir">os</strong><br/><strong class="mu ir">import</strong> <strong class="mu ir">matplotlib.pyplot</strong> <strong class="mu ir">as</strong> <strong class="mu ir">plt</strong></span><span id="c102" class="my lr iq mu b gy nd na l nb nc">KEYWORD = 'realDonaldTrump'   <em class="ne">#Twitter handle  </em><br/>BEGINDATE = datetime.date(2020, 3, 1)<br/>ENDDATE = datetime.date(2020, 4, 27)       <br/>LANG = 'en'<br/>TWEET_QUERY = 'from:'+ KEYWORD<br/>ORIG_TWEET_FILE = r'./data/'+ KEYWORD+'/' + 'all_tweets'</span><span id="3ba0" class="my lr iq mu b gy nd na l nb nc"><strong class="mu ir">if</strong> os.path.isfile(ORIG_TWEET_FILE):        <br/>    <strong class="mu ir">with</strong> open (ORIG_TWEET_FILE, 'rb') <strong class="mu ir">as</strong> fp:<br/>        all_tweets_df = pickle.load(fp)<br/>    print('Loaded tweet extracts from file<strong class="mu ir">\n</strong>')<br/><strong class="mu ir">else</strong>:<br/>    print('Start scraping tweets from twitter.com...<strong class="mu ir">\n</strong>')<br/>    <em class="ne"># https://twitter.com/search-advanced</em><br/>    list_of_tweets = query_tweets(TWEET_QUERY, <br/>                                  begindate=BEGINDATE, <br/>                                  enddate=ENDDATE, <br/>                                  lang=LANG)<br/>    <em class="ne"># Convert list of tweets to DataFrame</em><br/>    all_tweets_df = pd.DataFrame([vars(x) <strong class="mu ir">for</strong> x <strong class="mu ir">in</strong> list_of_tweets])<br/>    all_tweets_df.drop_duplicates(subset=['id'], inplace=<strong class="mu ir">True</strong>)<br/>    all_tweets_df.reset_index(drop=<strong class="mu ir">True</strong>, inplace=<strong class="mu ir">True</strong>)<br/>    <em class="ne"># Save tweet extracts to file</em><br/>    save_data_to_pickle(ORIG_TWEET_FILE, all_tweets_df)<br/>    print ('Tweet extracts saved<strong class="mu ir">\n</strong>')</span></pre><h1 id="2c61" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">按周、日和小时统计的推文数量</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nf"><img src="../Images/c39e91d8b020a160275d2d5257b3e205.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0KxF7JuVrmD1mpiSozwqLg.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nf"><img src="../Images/df7aa7a1c13a40aa167b3510de15d652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IdT02g-GG0VjumXlOCSabg.png"/></div></div></figure><p id="a330" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">似乎特朗普喜欢在下午1点到4点发推文，而特鲁多喜欢在下午3点左右发推文。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ng"><img src="../Images/ac497e6063fa98aef703426955312848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ip13dysVReFjhFKy_sK13Q.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nf"><img src="../Images/783585858d1374bc1b463de40f82f044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IOdK6B_E1S3UMbnOymqXvw.png"/></div></div></figure><p id="c1e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">特朗普和特鲁多都在一周内定期发推特。特朗普似乎更喜欢在周日发推特！</p><h1 id="0ff8" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">推文长度</h1><p id="9d3a" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">2020年3月1日至4月27日，特朗普发了673条推文，平均一条推文27个字，特鲁多发了386条推文，平均一条推文41个字。特朗普有许多短推文(不到10个字)，也有一些长推文(超过40个字)。特鲁多的推文最多，有40到50个单词。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/1afcaf510ec67ff224653c0a14027aaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*OCKv-CxT1cpkhISaJoqasw.png"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/05d15527ec929987a6816bf779dcbaaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*wbWlk4EATU22d2i3YOVk4w.png"/></div></figure><h1 id="66b3" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">数据预处理</h1><p id="4931" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">文本预处理是将文本从人类语言转换成机器可读格式以便进一步处理的过程。以下预处理步骤适用于我们的Twitter文本。</p><ol class=""><li id="97c2" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk ni li lj lk bi translated">将所有单词转换成小写</li><li id="a6ff" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk ni li lj lk bi translated">删除非字母字符</li><li id="ef46" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk ni li lj lk bi translated">删除短单词(长度小于3)</li><li id="d0dc" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk ni li lj lk bi translated">标记化:将句子分解成单词</li><li id="ffe6" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk ni li lj lk bi translated">词性标注:将单词按其语法类别分类的过程，目的是理解它们在句子中的作用，如动词、名词、形容词等。词性标注为词汇化提供了语法环境。</li><li id="2dc1" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk ni li lj lk bi translated">词汇化:将一个单词转换成它的基本形式，例如<code class="fe nj nk nl mu b">car, cars, car’s</code> <em class="ne"> </em>到<code class="fe nj nk nl mu b">car</code></li><li id="767f" class="lc ld iq jp b jq ll ju lm jy ln kc lo kg lp kk ni li lj lk bi translated">去掉常见的英语单词，如a，the，of等。，并删除对我们的分析没有什么价值的常用词，如com、twitter、pic等。</li></ol><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="a0a5" class="my lr iq mu b gy mz na l nb nc"><strong class="mu ir">import</strong> <strong class="mu ir">nltk</strong><br/><strong class="mu ir">from</strong> <strong class="mu ir">nltk.corpus</strong> <strong class="mu ir">import</strong> stopwords, wordnet <br/><strong class="mu ir">from</strong> <strong class="mu ir">nltk.stem</strong> <strong class="mu ir">import</strong> WordNetLemmatizer<br/><br/><em class="ne"># Additional stop words to be removed from text</em><br/>additional_stop_words=['twitter','com','pic','rt','via']<br/><br/><strong class="mu ir">def</strong> get_wordnet_pos(word):<br/>    <em class="ne">"""</em><br/><em class="ne">    Map POS tag to first character lemmatize() accepts</em><br/><em class="ne">    """</em><br/>    tag = nltk.pos_tag([word])[0][1][0].upper()<br/>    tag_dict = {"J": wordnet.ADJ,<br/>                "N": wordnet.NOUN,<br/>                "V": wordnet.VERB,<br/>                "R": wordnet.ADV}<br/><br/>    <strong class="mu ir">return</strong> tag_dict.get(tag, wordnet.NOUN)<br/><br/><strong class="mu ir">def</strong> text_cleanup(text): <br/>    <em class="ne"># Convert to lowercase</em><br/>    text_clean = text.lower()<br/>    <em class="ne"># Remove non-alphabet</em><br/>    text_clean = re.sub(r'[^a-zA-Z]|(\w+:\/\/\S+)',' ', text_clean).split()    <br/>    <em class="ne"># Remove short words (length &lt; 3)</em><br/>    text_clean = [w <strong class="mu ir">for</strong> w <strong class="mu ir">in</strong> text_clean <strong class="mu ir">if</strong> len(w)&gt;2]<br/>    <em class="ne"># Lemmatize text with the appropriate POS tag</em><br/>    lemmatizer = WordNetLemmatizer()<br/>    text_clean = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) <strong class="mu ir">for</strong> w <strong class="mu ir">in</strong> text_clean]<br/>    <em class="ne"># Filter out stop words in English </em><br/>    stops = set(stopwords.words('english')).union(additional_stop_words)<br/>    text_clean = [w <strong class="mu ir">for</strong> w <strong class="mu ir">in</strong> text_clean <strong class="mu ir">if</strong> w <strong class="mu ir">not</strong> <strong class="mu ir">in</strong> stops]<br/><br/>    <strong class="mu ir">return</strong> text_clean<br/>    <br/>cleaned_tweets_df = all_tweets_df.copy(deep=<strong class="mu ir">True</strong>)<br/><em class="ne"># parsing tweets </em><br/>cleaned_tweets_df['token'] = [text_cleanup(x) <strong class="mu ir">for</strong> x <strong class="mu ir">in</strong> all_tweets_df['text']]     <br/><br/>print ('Tweets cleanup done')</span></pre><p id="537e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还从文本中提取二元模型(成对的连续单词)。</p><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="ddf6" class="my lr iq mu b gy mz na l nb nc"><strong class="mu ir">from</strong> <strong class="mu ir">nltk.util</strong> <strong class="mu ir">import</strong> ngrams<br/><br/><strong class="mu ir">def</strong> word_grams(words, min=1, max=2):<br/>    word_list = []<br/>    <strong class="mu ir">for</strong> n <strong class="mu ir">in</strong> range(min, max):<br/>        <strong class="mu ir">for</strong> ngram <strong class="mu ir">in</strong> ngrams(words, n):<br/>            word_list.append(' '.join(str(i) <strong class="mu ir">for</strong> i <strong class="mu ir">in</strong> ngram))<br/>    <strong class="mu ir">return</strong> word_list<br/><br/><em class="ne"># Generate bigram tokens</em><br/>cleaned_tweets_df['bigram_token'] = [word_grams(x, min=2, max=3) <strong class="mu ir">for</strong> <br/>                     x <strong class="mu ir">in</strong> cleaned_tweets_df['token']]</span></pre><p id="9b6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">经过预处理后，我们的推文看起来像这样:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nm"><img src="../Images/9a8e88aacbf973fe35656a474a43d504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kc0fpBcwyI9wjNaWmK4keA.jpeg"/></div></div></figure><h1 id="3732" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">单词计数和单词云</h1><p id="2ba9" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">我们使用二元模型进行单词计数和单词云，因为二元模型比单个单词提供了更有意义的见解。</p><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="a372" class="my lr iq mu b gy mz na l nb nc"># Convert series to list for word count<br/>tweets_text = [word for one_tweet in cleaned_tweets_df['token'] for word in one_tweet]</span><span id="c75b" class="my lr iq mu b gy nd na l nb nc">from collections import Counter</span><span id="4ddb" class="my lr iq mu b gy nd na l nb nc">n_grams = list(ngrams(tweets_text, 2))<br/>common_words = Counter(n_grams).most_common()<br/>word_count = pd.DataFrame(data = common_words, columns=['word','frequency']) <br/># Convert list to string<br/>word_count['word'] = word_count['word'].apply(' '.join)</span><span id="0308" class="my lr iq mu b gy nd na l nb nc"># Plot word count graph<br/>title = "Word Frequency: Twitter @{} {} - {}".format(KEYWORD, BEGINDATE, ENDDATE)<br/>word_count.head(20).sort_values('frequency').plot.barh(x='word', y='frequency', title=title,figsize=(16,10), fontsize=16)</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nn"><img src="../Images/a29cff39bde71a943e5803e5254d3d41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i9-6Xii3wSiWOcnyYvkoEg.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi no"><img src="../Images/ee5a49ca06b99afb2dfc90f96b6e7410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AfgizIJ8jD67Hjqtl9Ypow.png"/></div></div></figure><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="8ce9" class="my lr iq mu b gy mz na l nb nc">word_count.head(20)</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi np"><img src="../Images/ac45c96d5b1527bf6ba292da860dccf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*YoLtu9ILgbTbmh7UydjJ7g.png"/></div></figure><p id="2d1d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">特朗普推文中最常见的前5个词是:<br/> <code class="fe nj nk nl mu b"><strong class="jp ir">fake news<br/>white house<br/>united state<br/>news conference<br/>mini mik</strong>e</code></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/643314090b826be0562e085e0ebc5c7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*4005uVe-xtb8h9R_fkpIAQ.png"/></div></figure><p id="3733" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">特鲁多推文中最常见的前5个词是:<br/> <code class="fe nj nk nl mu b"><strong class="jp ir">make sure<br/>across country<br/>keep safe<br/>canada emergency<br/>health car</strong>e</code></p><p id="98c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是特朗普推文的词云:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nr"><img src="../Images/285272d9830c06818f1fdc17697aab29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2G0VqBOtp7dwmdOD_v-P_Q.png"/></div></div></figure><p id="97e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是特鲁多推文的词云:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nr"><img src="../Images/abcf9101fc86b4cc57792c1858b0dfc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RWqsjbcCAJUIt7jVlK7JyA.png"/></div></div></figure><h1 id="08f5" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">主题建模</h1><p id="765b" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">主题建模是一种无监督的机器学习技术，广泛用于发现文档集合中的抽象主题。它认为每个文档由几个主题表示，每个主题由一组频繁出现的单词表示。例如，对于<code class="fe nj nk nl mu b">cloud, rain, wind</code>的群集，我们可以知道相关联的主题可能与<code class="fe nj nk nl mu b">weather</code>相关。</p><p id="4460" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于主题建模，我们使用<a class="ae lb" href="http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/" rel="noopener ugc nofollow" target="_blank"> LDA算法</a>，使用从我们的<a class="ae lb" href="https://ai-journey.com/2020/05/trump-and-trudeau-twitter-analysis-during-covid-19-crisis-part-1/" rel="noopener ugc nofollow" target="_blank">预处理</a>中获得的unigrams为每个tweet创建TF-IDF向量。</p><p id="8485" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如何知道我们所学的题目是否最能代表原文？我们计算和测量一致性分数。</p><blockquote class="ns nt nu"><p id="b3f3" class="jn jo ne jp b jq jr js jt ju jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj kk ij bi translated">话题连贯性——意思是语义连贯性——是一种人类判断的质量，它取决于单词的语义。[ <a class="ae lb" href="https://papers.nips.cc/paper/4291-improving-topic-coherence-with-regularized-topic-models" rel="noopener ugc nofollow" target="_blank">用正则化的话题模型提高话题连贯性</a></p></blockquote><p id="25bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">连贯性评分根据主题本身内高评分单词之间的语义相似度来衡量主题的可解释性。为了找出我们推文中的最佳主题数量，我们计算了不同数量主题的一致性分数。分数越高，主题的数量越符合文本。</p><p id="78c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">选择大量能产生较高连贯分数的话题可以提供有意义和可解释的话题。更多的主题通常会提供更高的连贯分数，但意义却相当零散。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ny"><img src="../Images/d1fd3e08fa282a5e67befeab7688988a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1au-oUf8KfSR6Ch61Pkkpg.png"/></div></div></figure><p id="cabd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于特朗普的推文，具有8个主题的LDA模型产生最高的一致性值。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ny"><img src="../Images/bb3111ec54bd360c23b82e2064b0f80e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KsJmfatJ5invI_xjhGsSkQ.png"/></div></div></figure><p id="4f75" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于特鲁多的推文，具有6个主题的LDA模型产生最高的一致性值。</p><h1 id="0033" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">话题生成</h1><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="9845" class="my lr iq mu b gy mz na l nb nc">top_n_keywords = 4<br/>topics_pd = pd.DataFrame() <br/># Label topics using top 4 keywords of the topic<br/>for idx, topic in lda_model.print_topics():<br/> topic_desc = ‘-’.join([x[0] for x in lda_model.show_topic(idx,top_n_keywords)])<br/> topics_pd = topics_pd.append(pd.Series([idx,topic_desc, topic]), ignore_index=True) <br/>topics_pd.columns = [‘topic_num’,’topic_desc’,’topic_keywords’]<br/>topics_pd</span></pre><p id="51f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们为特朗普的推文生成以下8个主题。<code class="fe nj nk nl mu b">topic_keywords</code>显示热门关键词及其对主题的重要性(权重)值。我们将前4个单词连接起来作为主题的标签，希望它能代表主题的含义。例如，<code class="fe nj nk nl mu b">conference-white-news-house</code>可以解释为与白宫新闻发布会相关的话题。<code class="fe nj nk nl mu b">thank-deal-great-call</code>可能与向某人道谢、打了一个很棒的电话或做了一笔大生意有关。</p><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="bc49" class="my lr iq mu b gy mz na l nb nc">topic_num                    topic_desc   topic_keywords</span><span id="c922" class="my lr iq mu b gy nd na l nb nc">0.0        federal-government-full-test    0.066*"federal" + 0.059*"government" + 0.037*"full" + 0.033*"test" + 0.030*"general" + 0.026*"bill" + 0.023*"hospital" + 0.022*"low" + 0.022*"know" + 0.021*"continue"  <br/>      <br/>1.0        conference-white-news-house     0.089*"conference" + 0.085*"white" + 0.082*"news" + 0.081*"house" + 0.072*"eastern" + 0.056*"today" + 0.039*"press" + 0.036*"million" + 0.032*"thank" + 0.031*"world"       <br/>  <br/>2.0        thank-deal-great-call           0.285*"thank" + 0.053*"deal" + 0.052*"great" + 0.038*"call" + 0.035*"company" + 0.026*"act" + 0.025*"leader" + 0.024*"together" + 0.021*"go" + 0.021*"work"       <br/>            <br/>3.0        joe-bernie-mike-sleepy          0.060*"joe" + 0.057*"bernie" + 0.056*"mike" + 0.053*"sleepy" + 0.049*"mini" + 0.036*"biden" + 0.033*"long" + 0.032*"democrat" + 0.030*"foxnews" + 0.027*"also"    <br/>            <br/>4.0        fake-news-state-people          0.022*"fake" + 0.020*"news" + 0.017*"state" + 0.017*"people" + 0.017*"get" + 0.017*"country" + 0.017*"united" + 0.017*"say" + 0.016*"time" + 0.015*"medium"    <br/>               <br/>5.0        keep-total-complete-safe        0.035*"keep" + 0.034*"total" + 0.034*"complete" + 0.031*"safe" + 0.029*"endorsement" + 0.029*"small" + 0.026*"strong" + 0.026*"business" + 0.025*"great" + 0.024*"amendment"  </span><span id="ad8a" class="my lr iq mu b gy nd na l nb nc">6.0        great-day-book-history          0.107*"great" + 0.043*"day" + 0.039*"book" + 0.038*"history" + 0.032*"wonderful" + 0.031*"hard" + 0.031*"end" + 0.029*"national" + 0.028*"american" + 0.027*"situation"  <br/>     <br/>7.0        kag-thank-ventilator-need       0.162*"kag" + 0.093*"thank" + 0.067*"ventilator" + 0.042*"need" + 0.038*"spoke" + 0.032*"good" + 0.032*"help" + 0.028*"every" + 0.022*"deliver" + 0.018*"work"</span></pre><p id="69df" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是从特鲁多的推文中了解到的6个话题。例如，<code class="fe nj nk nl mu b">business-small-help-owner</code>很可能与向小企业主提供帮助有关。</p><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="8610" class="my lr iq mu b gy mz na l nb nc">topic_num topic_desc topic_keywords</span><span id="7c8a" class="my lr iq mu b gy nd na l nb nc">0 0.0 business-small-help-owner 0.054*"business" + 0.034*"small" + 0.026*"help" + 0.025*"owner" + 0.024*"support" + 0.023*"announce" + 0.020*"non" + 0.020*"detail" + 0.019*"announcement" + 0.019*"emergency"</span><span id="0de1" class="my lr iq mu b gy nd na l nb nc">1 1.0 spoke-international-talk-spread 0.040*"spoke" + 0.034*"international" + 0.031*"talk" + 0.030*"spread" + 0.029*"call" + 0.029*"impact" + 0.029*"today" + 0.028*"covid" + 0.026*"leader" + 0.025*"economy"</span><span id="205f" class="my lr iq mu b gy nd na l nb nc">2 2.0 benefit-test-lose-apply 0.051*"benefit" + 0.036*"test" + 0.034*"lose" + 0.033*"apply" + 0.033*"emergency" + 0.029*"month" + 0.028*"receive" + 0.025*"response" + 0.025*"year" + 0.023*"invest"</span><span id="3a41" class="my lr iq mu b gy nd na l nb nc">3 3.0 make-work-need-sure 0.024*"make" + 0.022*"work" + 0.020*"need" + 0.018*"sure" + 0.018*"continue" + 0.018*"country" + 0.018*"keep" + 0.017*"health" + 0.016*"home" + 0.016*"safe"</span><span id="3b00" class="my lr iq mu b gy nd na l nb nc">4 4.0 celebrate-hope-life-around 0.053*"celebrate" + 0.042*"hope" + 0.038*"life" + 0.037*"around" + 0.036*"clock" + 0.031*"please" + 0.030*"full" + 0.026*"year" + 0.022*"late" + 0.022*"world"</span><span id="7751" class="my lr iq mu b gy nd na l nb nc">5 5.0 one-update-watch-family 0.026*"one" + 0.024*"update" + 0.023*"watch" + 0.023*"family" + 0.022*"time" + 0.021*"friend" + 0.021*"kid" + 0.019*"give" + 0.019*"great" + 0.018*"live"</span></pre><p id="894a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将这些主题应用到推文中，并分配概率最高的主题。以下是特朗普的一些可能的话题。</p><blockquote class="ns nt nu"><p id="6333" class="jn jo ne jp b jq jr js jt ju jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj kk ij bi translated">他们正在对伯尼发动政变！</p></blockquote><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="9ea7" class="my lr iq mu b gy mz na l nb nc">Topic: joe-bernie-mike-sleepy<br/>Probability: 0.544840<br/>Token: [stag, coup, bernie]</span></pre><blockquote class="ns nt nu"><p id="cf78" class="jn jo ne jp b jq jr js jt ju jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj kk ij bi translated">米歇尔正在明尼苏达州竞选国会议员。米歇尔将保护未出生的孩子，坚决打击犯罪&amp;边境，减税，你的#2A，热爱我们的军队，退伍军人，&amp;将支持我们伟大的农民。米歇尔得到了我的全力支持！<a class="ae lb" href="https://secure.winred.com/MichelleFischbach/website-donations" rel="noopener ugc nofollow" target="_blank">https://secure . winred . com/MichelleFischbach/website-捐赠</a> …</p></blockquote><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="b21e" class="my lr iq mu b gy mz na l nb nc">Topic: keep-total-complete-safe<br/>Probability: 0.808480<br/>Token: [michelle, fischbachmn, run, congress, minnesota, michelle, protect, unborn, strong, crime, border, cut, tax, love, military, vet, stand, great, farmer, michelle, complete, total, endorsement]</span></pre><blockquote class="ns nt nu"><p id="8aed" class="jn jo ne jp b jq jr js jt ju jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj kk ij bi translated">正文:<a class="ae lb" href="http://twitter.com/FoxNews" rel="noopener ugc nofollow" target="_blank"> @FoxNews </a>正在努力推动激进左派，无为民主党。不像他们的竞争对手，<a class="ae lb" href="http://twitter.com/CNN" rel="noopener ugc nofollow" target="_blank"> @CNN </a> &amp; MSDNC(康卡斯特)，公平&amp;平衡。他们什么时候才能明白？激进左派甚至从未允许@FoxNews 参与他们的低收视率辩论！</p></blockquote><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="4928" class="my lr iq mu b gy mz na l nb nc">Topic: fake-news-state-people<br/>Probability: 0.802032<br/>Token: [foxnews, work, hard, push, radical, left, nothing, democrat, want, unlike, competitor, cnn, msdnc, comcast, fair, balance, ever, learn, radical, left, never, even, give, foxnews, permission, partake, low, rat, debate]</span></pre><p id="20fc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是特鲁多的一些可能的话题。</p><blockquote class="ns nt nu"><p id="23b4" class="jn jo ne jp b jq jr js jt ju jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj kk ij bi translated">长期以来，矿业一直是加拿大经济的基石。现在，在我们向更清洁的未来过渡的过程中，它比以往任何时候都更加重要。今天在#PDAC2020上，我们谈到了加拿大成为世界上最清洁的金属和minerals.pic.twitter.com/cs27PXMMmD供应商的机会</p></blockquote><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="9d23" class="my lr iq mu b gy mz na l nb nc">Topic: make-work-need-sure<br/>Probability: 0.876077<br/>Token: [mining, long, building, block, canadian, economy, ever, important, role, play, transition, cleaner, future, today, pdac, spoke, opportunity, canada, world, cleanest, supplier, metal, mineral, pxmmmd]</span></pre><blockquote class="ns nt nu"><p id="b7d4" class="jn jo ne jp b jq jr js jt ju jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj kk ij bi translated">哈维尔·佩雷斯·德奎利亚尔一生致力于促进普遍人权&amp;建设一个更加和平的世界，他的遗产将代代相传。我向他的家人和所有那些其生活受到他杰出工作影响的人致以最深切的慰问。</p></blockquote><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="dbe0" class="my lr iq mu b gy mz na l nb nc">Topic: celebrate-hope-life-around<br/>Probability: 0.791011<br/>Token: [javier, rez, llar, dedicate, life, promote, universal, human, right, building, peaceful, world, legacy, live, generation, deepest, condolence, family, whose, life, touch, remarkable, work]</span></pre><blockquote class="ns nt nu"><p id="2743" class="jn jo ne jp b jq jr js jt ju jv jw jx nv jz ka kb nw kd ke kf nx kh ki kj kk ij bi translated">我们的首要任务是保证加拿大人的安全。随着新冠肺炎病毒在世界各地的传播，我们正在建立一个新的内阁委员会，以我们一直在做的工作为基础，预防和限制病毒在加拿大的传播，并监测其经济影响。https://pm . GC . ca/en/news/news-releases/2020/03/04/prime-minister-creates-Committee-新冠肺炎…</p></blockquote><pre class="km kn ko kp gt mt mu mv mw aw mx bi"><span id="ea3a" class="my lr iq mu b gy mz na l nb nc">Topic: spoke-international-talk-spread<br/>Probability: 0.612871<br/>Token: [top, priority, keep, canadian, safe, covid, spread, around, world, create, new, cabinet, committee, build, work, prevent, limit, spread, virus, canada, monitor, economic, impact]</span></pre><p id="c868" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图是2020年3月1日至4月27日，特朗普不同话题的推文比例。话题<code class="fe nj nk nl mu b">fake-news-state-people</code>的推文占46%。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nz"><img src="../Images/355c56c75db8bbf919ea5925aa586048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6WJU83jYVh8OXVGhAxynow.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/47c1b7c64b3f8feabd38d104aee910c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*GhKIQSVRrEksKA3QRvzacw.png"/></div></figure><p id="e94a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了特鲁多不同话题的推文比例。话题<code class="fe nj nk nl mu b">make-work-need-sure</code>的推文占38%。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ob"><img src="../Images/69fcaccacf4c0ce3257b643556061921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R-5FAEZG0UT9Kt4R7v_Y3g.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/37478988092434b76f2017b9d2f503e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*MGOJecavzJ282f3BiMLypA.png"/></div></figure><h1 id="c24e" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">主题可视化</h1><p id="bff2" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">我们使用<a class="ae lb" href="https://github.com/bmabey/pyLDAvis" rel="noopener ugc nofollow" target="_blank"> pyLDAvis </a>，一个交互式LDA可视化包，来绘制所有生成的主题及其关键字。这里是<a class="ae lb" href="https://ai-journey.com/wp-content/uploads/2020/05/lda_Trump.html" rel="noopener ugc nofollow" target="_blank">特朗普推文话题</a>的链接，以及<a class="ae lb" href="https://ai-journey.com/wp-content/uploads/2020/05/lda_Trudeau.html" rel="noopener ugc nofollow" target="_blank">特鲁多推文话题</a>的链接。</p><p id="028d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">左边的每个气泡代表一个主题。气泡的大小代表主题的流行程度。气泡之间的距离反映了主题之间的相似性。两个圈越近，话题越相似。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi od"><img src="../Images/80006f9e817f5be0a8cb1798c7c0c1dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vJm6imu93qr1U6DrestWvg.jpeg"/></div></div></figure><h1 id="41e0" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">结束语</h1><p id="5a99" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">为了了解我们的世界领导人如何处理新冠肺炎危机，并与他们的追随者沟通，我们转向Twitter，搜集了过去两个月唐纳德·特朗普和贾斯廷·特鲁多的推文。我们生成了词云来显示出现最多的词，通过开发不同主题数量的LDA模型来学习他们推文的主题。</p><p id="e0b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在危机时刻，你认为谁能更好地利用Twitter并与他的人民沟通？</p><p id="657e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所有代码都可以在<a class="ae lb" href="https://github.com/wangpengcn/Trump-And-Trudeau-Twitter-Analysis-During-COVID-19-Crisis" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</p></div><div class="ab cl oe of hu og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="ij ik il im in"><p id="9c95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">感谢阅读。如果您有任何反馈，请在下面留言，通过我的博客【https://ai-journey.com/<a class="ae lb" href="https://ai-journey.com/" rel="noopener ugc nofollow" target="_blank">联系我</a>，或者通过<a class="ae lb" href="https://www.linkedin.com/in/peng-wang-cpa/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>给我发消息。</p></div></div>    
</body>
</html>