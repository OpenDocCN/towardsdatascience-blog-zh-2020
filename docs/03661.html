<html>
<head>
<title>Feature Engineering for Election Result Prediction (in Python)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">选举结果预测的特征工程(Python语言)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-engineering-for-election-result-prediction-python-943589d89414?source=collection_archive---------22-----------------------#2020-04-06">https://towardsdatascience.com/feature-engineering-for-election-result-prediction-python-943589d89414?source=collection_archive---------22-----------------------#2020-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/beccfd6020f1f983138b53c340763cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lH3keb8YgVTa8cxT"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">詹姆斯·哈里逊在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="96a1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我最近参加了一个Kaggle比赛，我们必须使用机器学习来预测选举结果。该数据集来自2019年印度大选(<a class="ae kf" href="https://www.kaggle.com/prakrutchauhan/indian-candidates-for-general-election-2019" rel="noopener ugc nofollow" target="_blank">见此</a>)。本文介绍了如何清理和准备数据集，从现有要素中创建新要素，然后使用流行的机器学习算法预测结果。大多数基本的预处理、数据可视化和机器学习步骤在这里还没有解释清楚；相反，我关注的是特征工程以及它如何影响模型的性能。如果你对什么是特征工程没有清晰的认识，请参考我之前的文章《<a class="ae kf" rel="noopener" target="_blank" href="/basic-feature-engineering-to-reach-more-efficient-machine-learning-6294022e17a5">基础特征工程达到更高效的机器学习</a>》。</p><p id="c36a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们应该将数据集加载到笔记本中。大多数ML工程师和专家更喜欢在初始阶段使用笔记本进行机器学习和数据工程任务，因为用笔记本进行数据可视化和所有其他步骤真的很容易。我更喜欢使用pandas库来加载数据集，因为它使所有的数据处理步骤变得非常容易，不需要太多的努力。下面是我在笔记本中使用的python库。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="4e2c" class="ln lo it lj b gy lp lq l lr ls">import numpy as np<br/>import pandas as pd<br/>import os<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/><br/>from sklearn.preprocessing import LabelEncoder<br/>from sklearn.preprocessing import MinMaxScaler<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.feature_selection import SelectKBest, chi2</span></pre><p id="c871" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，让我们运行下面的命令，对数据集和原始数据有一个基本的了解。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="de29" class="ln lo it lj b gy lp lq l lr ls">dataset = pd.read_csv('/kaggle/input/indian-candidates-for-general-election-2019/LS_2.0.csv')<br/>dataset.head()</span></pre><figure class="le lf lg lh gt ju gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/c51c4179e5ca3ade90ff0417ffdaef4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*hTsszUidWnW04l3Rwk_UVw.png"/></div></figure><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="6b64" class="ln lo it lj b gy lp lq l lr ls">dataset.info()</span><span id="596a" class="ln lo it lj b gy lu lq l lr ls">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 2263 entries, 0 to 2262<br/>Data columns (total 19 columns):<br/>STATE                                       2263 non-null object<br/>CONSTITUENCY                                2263 non-null object<br/>NAME                                        2263 non-null object<br/>WINNER                                      2263 non-null int64<br/>PARTY                                       2263 non-null object<br/>SYMBOL                                      2018 non-null object<br/>GENDER                                      2018 non-null object<br/>CRIMINAL<br/>CASES                              2018 non-null object<br/>AGE                                         2018 non-null float64<br/>CATEGORY                                    2018 non-null object<br/>EDUCATION                                   2018 non-null object<br/>ASSETS                                      2018 non-null object<br/>LIABILITIES                                 2018 non-null object<br/>GENERAL<br/>VOTES                               2263 non-null int64<br/>POSTAL<br/>VOTES                                2263 non-null int64<br/>TOTAL<br/>VOTES                                 2263 non-null int64<br/>OVER TOTAL ELECTORS <br/>IN CONSTITUENCY        2263 non-null float64<br/>OVER TOTAL VOTES POLLED <br/>IN CONSTITUENCY    2263 non-null float64<br/>TOTAL ELECTORS                              2263 non-null int64<br/>dtypes: float64(3), int64(5), object(11)<br/>memory usage: 336.0+ KB</span></pre><p id="296c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上面的分析中我们可以看出，数据集包含很少的数字列，大多数列都是非数字的。WINNER列包含表明候选人赢得或输掉选举的标签。另外，请注意，数据集包含一些“NaN”值，这些值基本上是缺失值。有些列名包含' \n '字符，这很烦人。此外，资产和负债列值也包含' \n '字符。</p><p id="d652" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">仅考虑可用数据，我们可以将州、选区、政党、性别、类别和教育视为分类特征。此外，您可以运行dataset.describe()命令来对数字列进行一些统计汇总。</p><p id="2cc8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们应该清理数据集，修复列名并处理丢失的值。首先，我修复了不正确的列名，并用下划线(' _ ')替换了列名中的所有空格。这不是一个强制的步骤，但是不正确的列名让我很烦。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="9809" class="ln lo it lj b gy lp lq l lr ls"><em class="lv"># rename invalid column names</em><br/>dataset = dataset.rename(columns={'CRIMINAL<strong class="lj iu">\n</strong>CASES': 'CRIMINAL_CASES', 'GENERAL<strong class="lj iu">\n</strong>VOTES': 'GENERAL_VOTES', 'POSTAL<strong class="lj iu">\n</strong>VOTES': 'POSTAL_VOTES', 'TOTAL<strong class="lj iu">\n</strong>VOTES': 'TOTAL_VOTES', 'OVER TOTAL ELECTORS <strong class="lj iu">\n</strong>IN CONSTITUENCY': 'OVER_TOTAL_ELECTORS_IN_CONSTITUENCY', 'OVER TOTAL VOTES POLLED <strong class="lj iu">\n</strong>IN CONSTITUENCY': 'OVER_TOTAL_VOTES_POLLED_IN_CONSTITUENCY', 'TOTAL ELECTORS': 'TOTAL_ELECTORS'})</span></pre><p id="2504" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后让我们搜索每一列中缺少的值。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="5ad7" class="ln lo it lj b gy lp lq l lr ls">dataset.isna().sum()</span><span id="0961" class="ln lo it lj b gy lu lq l lr ls">STATE                                        0<br/>CONSTITUENCY                                 0<br/>NAME                                         0<br/>WINNER                                       0<br/>PARTY                                        0<br/>SYMBOL                                     245<br/>GENDER                                     245<br/>CRIMINAL_CASES                             245<br/>AGE                                        245<br/>CATEGORY                                   245<br/>EDUCATION                                  245<br/>ASSETS                                     245<br/>LIABILITIES                                245<br/>GENERAL_VOTES                                0<br/>POSTAL_VOTES                                 0<br/>TOTAL_VOTES                                  0<br/>OVER_TOTAL_ELECTORS_IN_CONSTITUENCY          0<br/>OVER_TOTAL_VOTES_POLLED_IN_CONSTITUENCY      0<br/>TOTAL_ELECTORS                               0<br/>dtype: int64</span></pre><p id="0e2b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以看到10%的行值丢失了。处理缺失值有多种方法，如删除、使用后填或前填、常量值插补、均值/中值或众数插补等。但是，为了简单起见，我在这里删除了这些行(只丢失了10%)，但是请始终记住，删除值会使预测模型不太准确。你应该尽可能多地估算缺失值。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="886f" class="ln lo it lj b gy lp lq l lr ls"><em class="lv"># drop rows with NA values</em><br/>dataset = dataset[dataset['GENDER'].notna()]</span></pre><p id="914f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们将资产、负债和CRIMINAL_CASES列转换为数字，因为它们代表金钱和计数，并且数字对模型有意义。为此，我们必须删除每个值字段中的“Rs”符号、“\n”字符和逗号。而且这些列包含“无”和“不可用”作为值。因此，在将它们变成数值之前，我们必须用一些有意义的值来替换它们(目前我用0来替换它们)。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="eecd" class="ln lo it lj b gy lp lq l lr ls"><em class="lv"># replace Nil values with 0</em><br/>dataset['ASSETS'] = dataset['ASSETS'].replace(['Nil', '`', 'Not Available'], '0')<br/>dataset['LIABILITIES'] = dataset['LIABILITIES'].replace(['NIL', '`', 'Not Available'], '0')<br/>dataset['CRIMINAL_CASES'] = dataset['CRIMINAL_CASES'].replace(['Not Available'], '0')<br/><br/><em class="lv"># clean ASSETS and LIABILITIES column values</em><br/>dataset['ASSETS'] = dataset['ASSETS'].map(lambda x: x.lstrip('Rs ').split('<strong class="lj iu">\n</strong>')[0].replace(',', ''))<br/>dataset['LIABILITIES'] = dataset['LIABILITIES'].map(lambda x: x.lstrip('Rs ').split('<strong class="lj iu">\n</strong>')[0].replace(',', ''))<br/><br/><em class="lv"># convert ASSETS, LIABILITIES and CRIMINAL_CASES column values into numeric</em><br/>dataset['ASSETS'] = dataset['ASSETS'].astype(str).astype(float)<br/>dataset['LIABILITIES'] = dataset['LIABILITIES'].astype(str).astype(float)<br/>dataset['CRIMINAL_CASES'] = dataset['CRIMINAL_CASES'].astype(str).astype(int)</span></pre><p id="a357" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们将非数字列改为数字列，以获得更好的性能。请注意，某些模型类型不能处理非数字数据。在这里，我将重点放在分类算法上，它当然不能在非数字数据上进行训练。所以我使用sklearn LabelEncoder对这些非数字列进行了标签编码。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="6f20" class="ln lo it lj b gy lp lq l lr ls"><em class="lv"># label encode categorical columns</em><br/><br/>lblEncoder_state = LabelEncoder()<br/>lblEncoder_state.fit(dataset['STATE'])<br/>dataset['STATE'] = lblEncoder_state.transform(dataset['STATE'])<br/><br/>lblEncoder_cons = LabelEncoder()<br/>lblEncoder_cons.fit(dataset['CONSTITUENCY'])<br/>dataset['CONSTITUENCY'] = lblEncoder_cons.transform(dataset['CONSTITUENCY'])<br/><br/>lblEncoder_name = LabelEncoder()<br/>lblEncoder_name.fit(dataset['NAME'])<br/>dataset['NAME'] = lblEncoder_name.transform(dataset['NAME'])<br/><br/>lblEncoder_party = LabelEncoder()<br/>lblEncoder_party.fit(dataset['PARTY'])<br/>dataset['PARTY'] = lblEncoder_party.transform(dataset['PARTY'])<br/><br/>lblEncoder_symbol = LabelEncoder()<br/>lblEncoder_symbol.fit(dataset['SYMBOL'])<br/>dataset['SYMBOL'] = lblEncoder_symbol.transform(dataset['SYMBOL'])<br/><br/>lblEncoder_gender = LabelEncoder()<br/>lblEncoder_gender.fit(dataset['GENDER'])<br/>dataset['GENDER'] = lblEncoder_gender.transform(dataset['GENDER'])<br/><br/>lblEncoder_category = LabelEncoder()<br/>lblEncoder_category.fit(dataset['CATEGORY'])<br/>dataset['CATEGORY'] = lblEncoder_category.transform(dataset['CATEGORY'])<br/><br/>lblEncoder_edu = LabelEncoder()<br/>lblEncoder_edu.fit(dataset['EDUCATION'])<br/>dataset['EDUCATION'] = lblEncoder_edu.transform(dataset['EDUCATION'])</span></pre><p id="3d81" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们训练一个K-最近邻模型，并查看其准确性。KNN是一个有监督的机器学习模型，根据分类算法进行分类。该算法通过获取一个数据点并找出k个最接近的数据点来工作。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="dc94" class="ln lo it lj b gy lp lq l lr ls"><em class="lv"># separate train features and label</em><br/>y = dataset["WINNER"]<br/>X = dataset.drop(labels=["WINNER"], axis=1)</span><span id="c795" class="ln lo it lj b gy lu lq l lr ls"><em class="lv"># split dataset into train and test data</em><br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)</span><span id="b302" class="ln lo it lj b gy lu lq l lr ls"># train and test knn model<br/>knn = KNeighborsClassifier()<br/>knn.fit(X_train, y_train)</span><span id="da11" class="ln lo it lj b gy lu lq l lr ls">knn.predict(X_test)<br/>print("Testing Accuracy is: ", knn.score(X_test, y_test)*100, "%")</span><span id="bed5" class="ln lo it lj b gy lu lq l lr ls"><strong class="lj iu">Testing Accuracy is:  70.79207920792079 %</strong></span></pre><p id="3b4f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型在没有太大影响的情况下实现了70%的准确率。让我们归一化数据集，看看精度如何提高。我使用scikit-learn库中的MinMaxScaler将所有值缩小到0-1的范围内。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="6470" class="ln lo it lj b gy lp lq l lr ls"># scaling values into 0-1 range</span><span id="d2c1" class="ln lo it lj b gy lu lq l lr ls">scaler = MinMaxScaler(feature_range=(0, 1))<br/>features = [<br/>    'STATE', 'CONSTITUENCY', 'NAME', 'PARTY', 'SYMBOL', 'GENDER', 'CRIMINAL_CASES', 'AGE', 'CATEGORY', 'EDUCATION', 'ASSETS', 'LIABILITIES', 'GENERAL_VOTES', 'POSTAL_VOTES', 'TOTAL_VOTES', 'OVER_TOTAL_ELECTORS_IN_CONSTITUENCY', 'OVER_TOTAL_VOTES_POLLED_IN_CONSTITUENCY', 'TOTAL_ELECTORS']</span><span id="67dc" class="ln lo it lj b gy lu lq l lr ls">dataset[features] = scaler.fit_transform(dataset[features])</span></pre><p id="0218" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如您在下面看到的，通过规范化列值，准确性得到了很大的提高。然而，我们可以通过应用一些其他的特征工程技术来进一步提高精度。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="ec55" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj iu">Testing Accuracy is:  90.5940594059406 %</strong></span></pre><h1 id="f0d8" class="lw lo it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated"><strong class="ak">对现有特征进行更有意义的编码</strong></h1><p id="adbb" class="pw-post-body-paragraph kg kh it ki b kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld im bi translated">如果我们考虑教育列，它包含特定候选人可以拥有的11个分类值。</p><blockquote class="my mz na"><p id="f975" class="kg kh lv ki b kj kk kl km kn ko kp kq nb ks kt ku nc kw kx ky nd la lb lc ld im bi translated">文盲、识字、第5次通过、第8次通过、第10次通过、第12次通过、毕业生、研究生、专业毕业生、博士学位、其他</p></blockquote><p id="e115" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们仔细想想，这些价值观中的每一个都代表了一种特定的教育水平。通过标签编码，我们只是为这些值中的每一个分配一些随机整数，而不考虑它们的层次级别。然而，如果我们根据教育资格有意义地分配该整数，则该模型有望表现得更好。注意，有一个名为“其他”的字段值，我们不知道它的层次位置。我只是给它分配了一个中间值。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="2838" class="ln lo it lj b gy lp lq l lr ls">dataset['EDUCATION'].value_counts()</span><span id="0328" class="ln lo it lj b gy lu lq l lr ls">Post Graduate            502<br/>Graduate                 441<br/>Graduate Professional    336<br/>12th Pass                256<br/>10th Pass                196<br/>8th Pass                  78<br/>Doctorate                 73<br/>Others                    50<br/>Literate                  30<br/>5th Pass                  28<br/>Not Available             22<br/>Illiterate                 5<br/>Post Graduate\n            1<br/>Name: EDUCATION, dtype: int64<br/></span><span id="b1dc" class="ln lo it lj b gy lu lq l lr ls"># encode education column<br/>encoded_edu = []</span><span id="c006" class="ln lo it lj b gy lu lq l lr ls"># iterate through each row in the dataset<br/>for row in dataset.itertuples():<br/>    education = row.EDUCATION</span><span id="1f05" class="ln lo it lj b gy lu lq l lr ls">if education == "Illiterate":<br/>        encoded_edu.append(0)<br/>    elif education == "Literate":<br/>        encoded_edu.append(1)<br/>    elif education == "5th Pass":<br/>        encoded_edu.append(2)<br/>    elif education == "8th Pass":<br/>        encoded_edu.append(3)<br/>    elif education == "10th Pass":<br/>        encoded_edu.append(4)<br/>    elif education == "12th Pass":<br/>        encoded_edu.append(7)<br/>    elif education == "Graduate":<br/>        encoded_edu.append(8)<br/>    elif education == "Post Graduate":<br/>        encoded_edu.append(9)<br/>    elif education == "Graduate Professional":<br/>        encoded_edu.append(10)<br/>    elif education == "Doctorate":<br/>        encoded_edu.append(11)<br/>    else:<br/>        encoded_edu.append(5)</span><span id="4556" class="ln lo it lj b gy lu lq l lr ls">dataset['EDUCATION'] = encoded_edu</span></pre><p id="0bc7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来分析一下党的专栏。如果我们在每个政党前面列出候选人的人数，我们可以看到只有几个政党的候选人人数很多。将政党列包括在内的全部目的是让候选人的政党对赢得选举产生影响。如果该党没有大量的候选人，该党对候选人获胜的影响就很低。因此，我们可以将它们全部编码到一个通用类别中(我将它们编码为“其他”)。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="ea68" class="ln lo it lj b gy lp lq l lr ls">dataset['PARTY'].value_counts()</span><span id="c6c8" class="ln lo it lj b gy lu lq l lr ls">BJP       420<br/>INC       413<br/>IND       201<br/>BSP       163<br/>CPI(M)    100<br/>         ... <br/>AINRC       1<br/>SKM         1<br/>ANC         1<br/>YKP         1<br/>AJSUP       1<br/>Name: PARTY, Length: 132, dtype: int64<br/></span><span id="0bbc" class="ln lo it lj b gy lu lq l lr ls"># change party of the less frequent parties as Other<br/># 'BJP','INC','IND','BSP', 'CPI(M)', 'AITC', 'MNM': high frequent<br/># 'TDP', 'VSRCP', 'SP', 'DMK', 'BJD': medium frequent</span><span id="5300" class="ln lo it lj b gy lu lq l lr ls">dataset.loc[~dataset["PARTY"].isin(['BJP','INC','IND','BSP', 'CPI(M)', 'AITC', 'MNM', 'TDP', 'VSRCP', 'SP', 'DMK', 'BJD']), "PARTY"] = "Other"<br/>dataset['PARTY'].value_counts()</span></pre><p id="0009" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个步骤都应该在标记编码列之前执行。让我们再次训练我们的模型，看看准确性。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="f8d5" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj iu">Testing Accuracy is:  92.07920792079209 %</strong></span></pre><p id="3f73" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以看到精确度提高了一点点。到目前为止，我们只考虑了现有的功能。然而，我们可以从现有的特性中创造出新的特性。</p><h1 id="e060" class="lw lo it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated"><strong class="ak">制作新功能</strong></h1><p id="9640" class="pw-post-body-paragraph kg kh it ki b kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld im bi translated">为了创建新的特性，我们应该对可用的原始特性以及它们如何影响给定场景有一个大致的了解。此外，还需要对问题领域有很好的理解。所以在这里，我们应该思考一下，在一次选举中，影响候选人获胜的因素是什么，我们投票给一个候选人或一个政党的考虑是什么。对于给定的场景，我不知道他们在投票给候选人之前考虑的国家因素(哪些特定国家的因素影响候选人获胜)。例如，我不知道类别如何影响选举结果。但是，通过假设一般的用例，我提出了以下特性。</p><p id="4bd5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据集包含大量原始特征，这些特征将直接影响候选人的获胜机会(例如，州、选区、政党、犯罪记录、教育资格、资产等)。然而，特定的候选人也可能赢得选举，这取决于被提名政党的地位。以下是一些可以代表政党对候选人获胜概率的重要性的特征。</p><p id="c8e8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 1。该党赢得的席位总数</strong></p><p id="7b5c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在投票之前，我们可能会考虑候选人的党派。如果一个政党有很高的胜算，那么这个政党的候选人也有同样的胜算(并不总是如此)。我们可以通过制作一个表示政党赢得的席位数的特征来突出显示该场景(获胜概率将通过计数来突出显示)。</p><p id="1f29" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 2。政党在选区赢得的席位数</strong></p><p id="7da2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有些政党总是会赢得某个特定的州或选区。我在这里考虑了选区，因为这是可用的最小区域。</p><p id="e2e3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 3。针对当事人的刑事案件</strong></p><p id="5aed" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在投票之前，我们通常会考虑针对一个政党的犯罪记录数量。如果一个政党有更多的刑事案件(更多的腐败政客)，该党赢得选举的机会可能会更小(反之亦然；-) ).我们可以通过制作一个表示某一方犯罪记录数量的特征来突出这种情况。</p><p id="2578" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 4。每个选区政党的刑事案件数量</strong></p><p id="25b4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还可以通过考虑每个选区的犯罪记录，将上述场景划分为子案例。这可能很好地代表了上述特征。</p><p id="3675" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 5。党内候选人的教育水平</strong></p><p id="2597" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在投票之前，我们还会考虑该党候选人的教育背景。如果一个政党提名更多受过教育的候选人，该政党可能会赢得选举(更高的概率)。在更早的步骤中，我们已经对教育资格进行了有意义的编码。所以如果我们统计一个政党中每个候选人的数量，这个特征将代表这个政党的教育水平。</p><p id="4061" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 6。各选区党内候选人的教育水平</strong></p><p id="79e5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我们对刑事案件所做的那样，我们也可以考虑每个选区政党的教育水平。</p><p id="ce5b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 7。按党派划分的选区候选人人数</strong></p><p id="217d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我已经提到的，一个特定的政党可能有更高的胜算，这取决于选区。如果一个政党为一个选区提名更多的候选人，选票将在候选人之间分配，每个候选人的百分比将减少。那会直接影响中奖概率。</p><p id="c3ab" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是我创建的一些可能影响候选人获胜概率的更多功能。</p><p id="be75" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">1.每个州的选民总数</p><p id="1472" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.每个选区的选民总数</p><p id="6726" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.每个州的选区总数</p><p id="c508" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我在现有功能的基础上总共创建了10个新功能。其中一些功能可能不会影响模型的性能。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="68c5" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj iu"># Preparing feature values</strong></span><span id="9b73" class="ln lo it lj b gy lu lq l lr ls">cons_per_state = {}<br/>voters_per_state = {}<br/>party_winningSeats = {}<br/>party_criminal = {}<br/>party_education = {}<br/>party_totalCandidates_per_cons = {}<br/>party_winningSeats_per_cons = {}<br/>party_criminal_per_cons = {}<br/>party_education_per_cons = {}<br/>voters_per_cons = {}</span><span id="4e64" class="ln lo it lj b gy lu lq l lr ls"># group by state<br/>subset = dataset[['STATE', 'CONSTITUENCY', 'TOTAL_ELECTORS']]<br/>gk = subset.groupby('STATE')</span><span id="2a61" class="ln lo it lj b gy lu lq l lr ls"># for each state<br/>for name,group in gk:<br/>    # total constituencies per state<br/>    cons_per_state[name] = len(group)<br/>    <br/>    # total voters per state<br/>    voters_per_state[name] = group['TOTAL_ELECTORS'].sum()</span><span id="8698" class="ln lo it lj b gy lu lq l lr ls"># group by party<br/>subset = dataset[['PARTY', 'CONSTITUENCY', 'CRIMINAL_CASES', 'EDUCATION', 'WINNER']]<br/>gk = subset.groupby('PARTY')</span><span id="761f" class="ln lo it lj b gy lu lq l lr ls"># for each party<br/>for name,group in gk:<br/>    # winning seats by party<br/>    party_winningSeats[name] = group[group['WINNER'] == 1.0].shape[0]<br/>    <br/>    # criminal cases by party<br/>    party_criminal[name] = group['CRIMINAL_CASES'].sum()<br/>    <br/>    # education qualification by party (sum of candidates)<br/>    party_education[name] = group['EDUCATION'].sum()<br/>    <br/>    # group by constituency<br/>    gk2 = group.groupby('CONSTITUENCY')<br/>    <br/>    # for each constituency<br/>    for name2, group2 in gk2:<br/>        key = name2 + '_' + name    # cons_party<br/>        <br/>        # total candidates by party in constituency<br/>        party_totalCandidates_per_cons[key] = len(group2)<br/>        <br/>        # party winning seats in the constituency<br/>        party_winningSeats_per_cons[key] = group2[group2['WINNER'] == 1.0].shape[0]<br/>        <br/>        # criminal cases by party in the constituency<br/>        party_criminal_per_cons[key] = group2['CRIMINAL_CASES'].sum()</span><span id="7103" class="ln lo it lj b gy lu lq l lr ls"># education qualification by party in constituency (sum of candidates)<br/>        party_education_per_cons[key] = group2['EDUCATION'].sum()</span><span id="66ba" class="ln lo it lj b gy lu lq l lr ls"># Total voters per constituency<br/>subset = dataset[['CONSTITUENCY', 'TOTAL_ELECTORS']]<br/>gk = subset.groupby('CONSTITUENCY')</span><span id="56b1" class="ln lo it lj b gy lu lq l lr ls"># for each constituency<br/>for name,group in gk:<br/>    voters_per_cons[name] = len(group)<br/></span><span id="5b10" class="ln lo it lj b gy lu lq l lr ls"><strong class="lj iu"># Applying feature values</strong></span><span id="1f8c" class="ln lo it lj b gy lu lq l lr ls"># new feature columns<br/>total_cons_per_state = []<br/>total_voters_per_state = []<br/>total_voters_per_cons = []</span><span id="b804" class="ln lo it lj b gy lu lq l lr ls">winning_seats_by_party = []<br/>criminal_by_party = []<br/>education_by_party = []</span><span id="d1b2" class="ln lo it lj b gy lu lq l lr ls">total_candidates_by_party_per_cons = []<br/>winning_seats_by_party_per_cons = []<br/>criminal_by_party_per_cons = []<br/>education_by_party_per_cons = []</span><span id="e5d1" class="ln lo it lj b gy lu lq l lr ls"># iterate through each row in the dataset<br/>for row in dataset.itertuples():<br/>    subkey = row.CONSTITUENCY + '_' + row.PARTY</span><span id="2f70" class="ln lo it lj b gy lu lq l lr ls">total_cons_per_state.append(cons_per_state.get(row.STATE))<br/>    total_voters_per_state.append(voters_per_state.get(row.STATE))<br/>    total_voters_per_cons.append(voters_per_cons.get(row.CONSTITUENCY))<br/>    winning_seats_by_party.append(party_winningSeats.get(row.PARTY))<br/>    criminal_by_party.append(party_criminal.get(row.PARTY))<br/>    education_by_party.append(party_education.get(row.PARTY))<br/>    total_candidates_by_party_per_cons.append(party_totalCandidates_per_cons.get(subkey))<br/>    winning_seats_by_party_per_cons.append(party_winningSeats_per_cons.get(subkey))<br/>    criminal_by_party_per_cons.append(party_criminal_per_cons.get(subkey))<br/>    education_by_party_per_cons.append(party_education_per_cons.get(subkey))</span><span id="a66e" class="ln lo it lj b gy lu lq l lr ls"># append columns to dataset<br/>dataset['total_cons_per_state'] = total_cons_per_state<br/>dataset['total_voters_per_state'] = total_voters_per_state<br/>dataset['total_voters_per_cons'] = total_voters_per_cons<br/>dataset['winning_seats_by_party'] = winning_seats_by_party<br/>dataset['criminal_by_party'] = criminal_by_party<br/>dataset['education_by_party'] = education_by_party<br/>dataset['total_candidates_by_party_per_cons'] = total_candidates_by_party_per_cons<br/>dataset['winning_seats_by_party_per_cons'] = winning_seats_by_party_per_cons<br/>dataset['criminal_by_party_per_cons'] = criminal_by_party_per_cons<br/>dataset['education_by_party_per_cons'] = education_by_party_per_cons</span></pre><p id="c07c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们再次训练我们的模型，看看准确性如何提高。无需对任何已创建的要素进行标注编码，因为它们都是数字。然而，在训练模型之前，我将它们标准化为0-1范围。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="3f8b" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj iu">Testing Accuracy is:  96.78217821782178 %</strong></span></pre><h1 id="aa1c" class="lw lo it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated"><strong class="ak">功能重要性</strong></h1><p id="b4c1" class="pw-post-body-paragraph kg kh it ki b kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld im bi translated">移除不相关的特征或不太重要的特征将提高模型的准确性。到目前为止，我们已经在28个特性上训练了我们的最新模型，包括新创建的10个。然而，这些特征中的一些可能对基于训练数据得出结论没有太大贡献。移除那些特征不会降低模型的准确性，希望会提高它，因为不相关的特征可能为模型得出无效的推论。</p><p id="1665" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们可以通过分析它们的贡献来删除一些特征。NAME列不会对模型做出任何有用的推断，因为理想情况下，名称应该是惟一的。然而，在某些情况下，姓氏可能很重要，因为一些姓氏可能会对赢得选举产生影响。此外，PARTY和SYMBOL这两个变量将表示相同的特征，我们将能够在不影响准确性的情况下移除它们中的一个。TOTAL_VOTES列包含GENERAL_VOTES列和POSTAL_VOTES列的总和。所以我们也可以去掉这两个。如果我们绘制代表相关矩阵的热图，我们将看到这3个特征高度相关。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="f156" class="ln lo it lj b gy lp lq l lr ls"># remove unnecessary columns</span><span id="a38e" class="ln lo it lj b gy lu lq l lr ls">X.drop(labels=["NAME"], axis=1, inplace=True)<br/>X.drop(labels=["SYMBOL"], axis=1, inplace=True)<br/>X.drop(labels=["POSTAL_VOTES"], axis=1, inplace=True)<br/>X.drop(labels=["GENERAL_VOTES"], axis=1, inplace=True)</span></pre><p id="5840" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有一些技术可以根据重要性来选择特性。我将使用单变量选择方法来识别最重要的特征，并删除其他特征。我将使用Scikit learn库中的SelectKBest和卡方检验来评估特性的重要性。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="22c9" class="ln lo it lj b gy lp lq l lr ls"># apply SelectKBest class to extract top most features<br/>bestfeatures = SelectKBest(score_func=chi2, k=10)<br/>fit = bestfeatures.fit(X, y)<br/>dfscores = pd.DataFrame(fit.scores_)<br/>dfcolumns = pd.DataFrame(X.columns)</span><span id="0678" class="ln lo it lj b gy lu lq l lr ls"># concat two dataframes for better visualization <br/>featureScores = pd.concat([dfcolumns, dfscores], axis=1)<br/>featureScores.columns = ['Specs', 'Score']<br/>print(featureScores.nlargest(30, 'Score'))<br/></span><span id="39b0" class="ln lo it lj b gy lu lq l lr ls">                                      Specs       Score<br/>25          winning_seats_by_party_per_cons  486.207788<br/>16  OVER_TOTAL_VOTES_POLLED_IN_CONSTITUENCY  285.347141<br/>15      OVER_TOTAL_ELECTORS_IN_CONSTITUENCY  262.177373<br/>14                              TOTAL_VOTES  216.937788<br/>12                            GENERAL_VOTES  216.138799<br/>21                   winning_seats_by_party  199.662525<br/>13                             POSTAL_VOTES   65.126864<br/>22                        criminal_by_party   36.519437<br/>3                                     PARTY   35.416433<br/>23                       education_by_party    6.576548<br/>11                              LIABILITIES    6.330339<br/>24       total_candidates_by_party_per_cons    5.755538<br/>20                    total_voters_per_cons    5.302656<br/>4                                    SYMBOL    4.128283<br/>8                                  CATEGORY    4.047031<br/>10                                   ASSETS    3.755575<br/>7                                       AGE    2.077768<br/>9                                 EDUCATION    0.888330<br/>27              education_by_party_per_cons    0.840185<br/>18                     total_cons_per_state    0.481673<br/>6                            CRIMINAL_CASES    0.436667<br/>19                   total_voters_per_state    0.292948<br/>26               criminal_by_party_per_cons    0.178720<br/>5                                    GENDER    0.145870<br/>1                              CONSTITUENCY    0.143250<br/>0                                     STATE    0.076833<br/>17                           TOTAL_ELECTORS    0.054486<br/>2                                      NAME    0.003039</span></pre><p id="bf6e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们去掉所有分数小于3的列。请注意，我之前创建的一些特性对于KNN模型也不重要。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="f99b" class="ln lo it lj b gy lp lq l lr ls">X.drop(labels=["TOTAL_ELECTORS"], axis=1, inplace=True)<br/>X.drop(labels=["STATE"], axis=1, inplace=True)<br/>X.drop(labels=["CONSTITUENCY"], axis=1, inplace=True)<br/>X.drop(labels=["GENDER"], axis=1, inplace=True)<br/>X.drop(labels=["criminal_by_party_per_cons"], axis=1, inplace=True)<br/>X.drop(labels=["total_voters_per_state"], axis=1, inplace=True)<br/>X.drop(labels=["CRIMINAL_CASES"], axis=1, inplace=True)<br/>X.drop(labels=["total_cons_per_state"], axis=1, inplace=True)<br/>X.drop(labels=["EDUCATION"], axis=1, inplace=True)<br/>X.drop(labels=["education_by_party_per_cons"], axis=1, inplace=True)<br/>X.drop(labels=["AGE"], axis=1, inplace=True)</span></pre><p id="fce5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们用最重要的特征再次训练我们的模型，并评估准确性。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="48f8" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj iu">Testing Accuracy is:  99.5049504950495 %</strong></span></pre><h1 id="50fc" class="lw lo it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated"><strong class="ak">结论</strong></h1><p id="671f" class="pw-post-body-paragraph kg kh it ki b kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld im bi translated">从上面的结果可以看出，特征工程步骤极大地提高了模型的性能。从0.7的初始精度开始，我们已经达到了0.99的精度。首先，我们清理数据集并将所有值转换成数字格式。然后，我们使用现有的功能创建一些新功能，并删除所有不太重要的功能。最后，我们将这些值缩小到0–1的范围，并训练一个K-最近邻模型。请注意，我们可以通过应用交叉验证来进一步提高准确性。作为结论，我想把每个主要步骤后的准确性总结如下。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="bdc7" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj iu">Feature Engineering Step                   Testing Accuracy</strong></span><span id="6681" class="ln lo it lj b gy lu lq l lr ls">Initially without any data processing                0.7079<br/>Scale down values into 0-1 range                     0.9059<br/>Basic encoding of two columns                        0.9208<br/>Creating new features                                0.9678<br/>Removing unnecessary features                        0.9950</span></pre></div></div>    
</body>
</html>