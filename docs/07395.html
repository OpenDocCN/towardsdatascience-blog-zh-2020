<html>
<head>
<title>Stacked Capsule Autoencoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">堆叠胶囊自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stacked-capsule-autoencoders-f632c44be496?source=collection_archive---------33-----------------------#2020-06-04">https://towardsdatascience.com/stacked-capsule-autoencoders-f632c44be496?source=collection_archive---------33-----------------------#2020-06-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="620a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用无监督学习和有限数量的训练数据对图像和视频中的对象检测的未来进行展望。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d9ee9e24946c68bff5f2760ba20da4be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XfosbY2xJCLpQlCC"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@willbro?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">将</a>放在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="kz la l"/></div></figure><h1 id="b4e6" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">介绍</h1><p id="b17c" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在过去的几年里，<a class="ae ky" href="https://en.wikipedia.org/wiki/Geoffrey_Hinton" rel="noopener ugc nofollow" target="_blank"> Geoffrey Hinton </a>和一组研究人员开始研究一种基于胶囊的革命性的新型神经网络。</p><p id="91c3" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">这项研究背后的一些主要动机是，当前的神经网络，如<a class="ae ky" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络(CNN)</a>，只有在提供大量数据的情况下，才能在<a class="ae ky" rel="noopener" target="_blank" href="/roadmap-to-computer-vision-79106beb8be4">计算机视觉</a>任务(如对象检测)中实现最先进的精度。</p><p id="7b9b" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">像 CNN 这样的模型需要如此大量的数据的一个主要原因是它们无法捕捉组成图像的不同元素之间的方向和空间关系。事实上，用于改善 CNN 性能的主要技术之一是数据增强。当应用数据扩充时，我们通过从原始图像创建额外的数据，例如旋转、裁剪、翻转等，帮助我们的模型更深入、更全面地了解不同对象的特征。这样，即使从不同的角度看，我们的模型也更有可能识别同一物体(图 1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/0122c99bb32883e7c059857b0cfe8b3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*raMNsT7H947BObauwCRttQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:从不同的角度看同一个物体会引起误解[1]。</p></figure><p id="6008" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">CNN 能够通过首先识别图像中的边缘和形状，然后将它们组合在一起来检测物体。尽管这种方法没有考虑构建整个图像的空间层次，因此导致需要创建大的数据集以便很好地执行(因此也增加了训练模型所需的计算成本)。</p><h1 id="1b1f" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">胶囊</h1><p id="f3d3" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">杰弗里·辛顿使用胶囊的方法紧紧遵循相反的逆图形原理。事实上，根据 Hinton 的说法，我们的大脑每次处理一个新的物体时，它的表征都不依赖于视角。因此，为了创建能够像我们的大脑一样好地执行对象识别的模型，我们需要能够捕捉组成对象的不同部分的层次关系，并将它们与坐标框架相关联。</p><p id="2273" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">这可以通过将我们的网络建立在一种叫做胶囊的结构上来实现。胶囊是一种数据结构，它以矢量形式包含了我们正在检测的特征的所有主要信息。它的主要成分是:</p><ol class=""><li id="00cf" class="mv mw it lv b lw mp lz mq mc mx mg my mk mz mo na nb nc nd bi translated">表示图像中是否存在形状的逻辑单位。</li><li id="7e6d" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo na nb nc nd bi translated">代表形状的<a class="ae ky" href="http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MARBLE/high/pose/express.htm" rel="noopener ugc nofollow" target="_blank">姿态</a>的矩阵。</li><li id="c5d4" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo na nb nc nd bi translated">嵌入颜色、变形等其他信息的向量…</li></ol><p id="416b" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">在过去几年中，Hinton 研究小组提出了不同的方法来创建胶囊网络，例如:</p><ul class=""><li id="1233" class="mv mw it lv b lw mp lz mq mc mx mg my mk mz mo nj nb nc nd bi translated">2017: <a class="ae ky" href="https://arxiv.org/abs/1710.09829" rel="noopener ugc nofollow" target="_blank">动态路由</a>(判别学习和部分整体关系)。</li><li id="3899" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated">2018: <a class="ae ky" href="https://www.cs.toronto.edu/~hinton/absps/EMcapsules.pdf" rel="noopener ugc nofollow" target="_blank">期望-最大化算法</a>(判别学习和部分-整体关系)。</li><li id="b8b6" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated">2019: <a class="ae ky" href="https://arxiv.org/abs/1906.06818" rel="noopener ugc nofollow" target="_blank">堆叠胶囊网络</a>(无监督学习，整体部分关系)。</li></ul><p id="72ac" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">在胶囊网络中，不同的神经元相互竞争，以找到组成图像中对象的一致部分。可以使用三种不同的方法来测量不同胶囊之间的一致性:</p><ul class=""><li id="fa99" class="mv mw it lv b lw mp lz mq mc mx mg my mk mz mo nj nb nc nd bi translated">使用余弦距离作为一致性的度量。</li><li id="bb8f" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated">期望最大化。</li><li id="ea2e" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated">混合模型。</li></ul><p id="d40a" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">如图 2 所示，将我们的系统建立在基于几何关系理解对象的基础上，我们可以使我们的模型能够可靠地检测对象(即使从不同的角度或在不同的光照条件下捕捉)，在训练期间只提供它的一个实例(不需要数据增强)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/53e8203c094e1840dcb82de199835584.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gHnUO-A3vYj0qtqHXSkGPw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2:不同视角的物体检测[2]</p></figure><h1 id="ffca" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">堆叠胶囊网络</h1><p id="cdcc" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">2019 年创建胶囊网络的方法的一个新增功能是以无人监管的方式执行对象检测的能力，因此不需要标记我们的数据。</p><p id="8f2e" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">该模型架构可分为 3 个主要的不同阶段，例如:</p><ul class=""><li id="0b12" class="mv mw it lv b lw mp lz mq mc mx mg my mk mz mo nj nb nc nd bi translated">Constellation Autoencoder (CCAE):在这个阶段，以无监督的方式训练自动编码器模型，以最大化零件胶囊可能性。</li><li id="c7fd" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated">部分胶囊自动编码器(PCAE):我们的输入图像被分成组成部分，以推断物体的姿态。</li><li id="d9de" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated">对象胶囊自动编码器(OCAE):创建的部分按照它们相应的姿势组织在一起，以重新创建对象。</li></ul><p id="53e2" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">将这三个阶段结合在一起，我们就可以得到最终的堆叠胶囊网络。整个过程可以概括为图 3 中的工作流程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/e0b23ee0c7a9edf7c2a9f8b828d723e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W_mGUOZzEYyeZnUchnq0WQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3:堆叠胶囊网络一般工作流程[3]</p></figure><p id="c2c9" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">如果你有兴趣了解更多关于堆叠胶囊网络的信息，Geoff Hinton 在 AAAI 2020 图灵奖上从第 3 分钟到第 34 分钟的视频演示中提供了关于该主题的更多信息。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm la l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">视频 1: AAAI 2020 图灵奖</p></figure></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="1364" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated"><em class="nu">我希望你喜欢这篇文章，谢谢你的阅读！</em></p><h1 id="4fed" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">联系人</h1><p id="ea60" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">如果你想了解我最新的文章和项目<a class="ae ky" href="https://medium.com/@pierpaoloippolito28?source=post_page---------------------------" rel="noopener">，请通过媒体</a>关注我，并订阅我的<a class="ae ky" href="http://eepurl.com/gwO-Dr?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">邮件列表</a>。以下是我的一些联系人详细信息:</p><ul class=""><li id="8a16" class="mv mw it lv b lw mp lz mq mc mx mg my mk mz mo nj nb nc nd bi translated"><a class="ae ky" href="https://uk.linkedin.com/in/pier-paolo-ippolito-202917146?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="3fdd" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated"><a class="ae ky" href="https://pierpaolo28.github.io/blog/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">个人博客</a></li><li id="4a16" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated"><a class="ae ky" href="https://pierpaolo28.github.io/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">个人网站</a></li><li id="b80b" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated"><a class="ae ky" href="https://towardsdatascience.com/@pierpaoloippolito28?source=post_page---------------------------" rel="noopener" target="_blank">中等轮廓</a></li><li id="0f22" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated"><a class="ae ky" href="https://github.com/pierpaolo28?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li><li id="05f8" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo nj nb nc nd bi translated"><a class="ae ky" href="https://www.kaggle.com/pierpaolo28?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">卡格尔</a></li></ul><h1 id="e404" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">文献学</h1><p id="8250" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">[1]关于真相的 10 个确定性，KOET，Lisa Beebe。访问网址:<a class="ae ky" href="https://www.kcet.org/arts-entertainment/10-certainties-about-the-truth" rel="noopener ugc nofollow" target="_blank">https://www . kcet . org/arts-entertainment/10-真相的确定性</a></p><p id="1310" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">[2]带有 EM 路由的矩阵胶囊，Geoffrey Hinton，Sara Sabour，Nicholas Frosst-Google Brain。访问地点:<a class="ae ky" href="https://openreview.net/pdf?id=HJWLfGWRb" rel="noopener ugc nofollow" target="_blank">https://openreview.net/pdf?id=HJWLfGWRb</a></p><p id="c63f" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">[3]堆叠胶囊自动编码器，Adam Kosiorek。访问网址:<a class="ae ky" href="http://akosiorek.github.io/ml/2019/06/23/stacked_capsule_autoencoders.html" rel="noopener ugc nofollow" target="_blank">http://akosiorek . github . io/ml/2019/06/23/stacked _ capsule _ auto encoders . html</a></p></div></div>    
</body>
</html>