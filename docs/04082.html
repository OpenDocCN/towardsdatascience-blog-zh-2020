<html>
<head>
<title>PCA explained and implemented in 2 minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在2分钟内解释并实施PCA</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pca-explained-and-implemented-in-2-minutes-e024c832bb9c?source=collection_archive---------33-----------------------#2020-04-14">https://towardsdatascience.com/pca-explained-and-implemented-in-2-minutes-e024c832bb9c?source=collection_archive---------33-----------------------#2020-04-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0933" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">【警告】超级容易！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6aeb0ea8f8b28d9b3c39901a8e94eeed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HdqBz07y7KKUlAyWYnDPZQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/photos/8P4TXHFB-Vo" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><p id="92cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PCA或主成分分析是最著名的降维算法之一。它的主要目的是减少给定数据的大小，根据需要保留尽可能多的信息。在本文中，我将简要解释PCA算法并实现它。我们走吧！</p><ol class=""><li id="65ff" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">作为第一步，让我们准备数据。我将使用Iris数据集作为一个玩具示例。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi me"><img src="../Images/e25ddf063122c5b519c23d7d4a000714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2lcrnPCWKm1W23b0PbNAmA.png"/></div></div></figure><p id="f435" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.现在，让我们将数据集居中，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mf"><img src="../Images/c3c084d8debe0ad1183ecb9c80ea1504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Xfowrjd64NfFfenrh1uXg.png"/></div></div></figure><p id="98b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在代码中，它看起来就像这样(我不仅从相应的列中减去了每一列的平均值，还除以标准偏差以标准化数据)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/c16a115c6456b9d1a10a50ac128a1b6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*3GaVorX0mrSzPZ_QJ4lxJQ.png"/></div></figure><p id="26a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.现在，我们应该找到数据的协方差矩阵。</p><p id="8d49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">协方差只是两个特征之间的线性相关性度量。因此，我们正在计算每对特征之间的线性相关性度量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/4e66803c617cf794eb0d61d100775788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*z-Vb5AM31DfuqXILm8iQ3g.png"/></div></figure><p id="063d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.已知协方差矩阵，让我们找到它的特征分解(即找到它的特征值和相应的特征向量)</p><p id="1e23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特征向量是一个向量，当应用线性变换时，它不会改变方向。在下图中，你可以看到两个红色的特征向量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mi"><img src="../Images/31a3c54abfb57e6ce396fbc2cce43b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-0SGSAs8GDayKkiC0mNGxQ.png"/></div></div></figure><p id="a3b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，每个特征向量有一个相应的特征值，它等于特征向量的大小。</p><p id="7e20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们借助numpy.linalg模块来寻找特征分解。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/c2af60356145450defa7c120b6c428a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*hEbd-dX3Zarj6hz4tIMbjA.png"/></div></figure><p id="4d2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从协方差矩阵中找到的特征值越大，对应的特征向量的方差就越大。因此，为了选择k个最佳分量，我们需要选择k个具有最大特征值的特征向量。</p><p id="87ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5.我现在将选择协方差矩阵的前2个特征值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/52900d3bfd9f450966084e995aca13f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*Kfanz7qY4xiQ-qlxc4ePJA.png"/></div></figure><p id="3077" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">6.最后一步是将初始数据集投影到这两个向量所跨越的子空间上。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ml"><img src="../Images/0c3572904a8a1277e4da0a75952302c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*xv8muFlheooZXwytnoF9Fw.png"/></div></div></figure><p id="ec6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，得到的x_reduced值是数据集初始列的某种线性组合，这导致了方差最大的两个分量。</p><p id="88c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">7.最后，让我们画出我们的2个分量，来检验结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/97510a23ecd9e6833f2aa278b03fcb60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*dD15WdnXp3vC4WYm0YWHXg.png"/></div></figure><p id="a461" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望，这篇短文对你有帮助。感谢您的阅读！</p><p id="1833" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">你可以在我的</strong> <a class="ae ky" href="http://artkulakov.com" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">网站</strong> </a>上查看其他帖子</p></div></div>    
</body>
</html>