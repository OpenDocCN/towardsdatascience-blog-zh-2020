<html>
<head>
<title>Unifying remote and local AzureML environments</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">统一远程和本地AzureML环境</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unifying-remote-and-local-azureml-environments-bcea1292e37f?source=collection_archive---------40-----------------------#2020-06-23">https://towardsdatascience.com/unifying-remote-and-local-azureml-environments-bcea1292e37f?source=collection_archive---------40-----------------------#2020-06-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a9d7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">微软和Python机器学习:现代爱情故事，第2部分，共2部分</h2></div><p id="5b61" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">微软Azure正在征服我们作为人工智能从业者的心，并通过对PyTorch、Tensorflow和Scikit-learn等开源框架的支持来吸引我们。在这里，我们围绕MS给我们的工具建立了一个工作流程，由我们来决定我们是否受到诱惑。在<a class="ae le" rel="noopener" target="_blank" href="/vscode-devcontainers-and-the-python-azureml-sdk-323dec18a675">第1部分</a>中，我们在我们的AzureML远程计算目标上启动了一个Python脚本，而我们的VSCode devcontainer对此毫不在意。这也意味着远程环境的大部分配置不在我们的掌控之中。这里我们将深入AzureML环境来配置PyTorch GPU工作负载。最后，我们努力统一开发和远程环境，使我们在AzureML上更有效地开发和测试AI模型。</p><h1 id="b29a" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">1计算目标环境</h1><h1 id="bc66" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">1.1 Docker图像管理</h1><p id="e80d" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在下图中，我们看到Python工作负载在计算目标上的远程docker容器中运行。如果我们创建一个CPU集群，并且除了指向计算目标的RunConfiguration之外没有指定任何东西(参见<a class="ae le" rel="noopener" target="_blank" href="/vscode-devcontainers-and-the-python-azureml-sdk-323dec18a675">第1部分</a>，那么AzureML将在第一次运行时选择一个CPU基础docker映像(<a class="ae le" href="https://github.com/Azure/AzureML-Containers" rel="noopener ugc nofollow" target="_blank">https://github.com/Azure/AzureML-Containers</a>)。</p><p id="2fca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在基础映像之上，创建了conda环境，并安装了默认的python依赖项，以创建支持AzureML-SDK的Python运行时。在构建映像之后，它被推送到链接到AzureML工作空间的docker存储库，其名称中有一个随机的UUID(模式:azureml/azureml_ <uuid>)。在代码运行期间，计算实例将提取自定义图像。如果环境配置发生变化，运行开始时会触发重建。请注意，这些图像不是垃圾收集的，随着存储更多的图像，您的成本会增加。</uuid></p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mc"><img src="../Images/e5e3595c2081b1ff90fbe3b46fb457f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sAqNb_mjK0P6q2mWsdtVqA.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">使用VSCode devcontainer的Azure-ml工作流(图片由作者提供)</p></figure><h1 id="2703" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">1.2环境等级</h1><p id="c54e" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">Environment类是各种配置环境变量、编程语言、计算框架和Docker的类的组合。该环境由Docker、Python、R和Spark部分组成。例如，PythonSection公开了多种方法来从现有的conda环境、conda规范文件、pip需求文件或以编程方式添加的依赖项创建Python环境。AzureML环境可以注册到工作区供以后使用。目标是用azure ml(<a class="ae le" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments" rel="noopener ugc nofollow" target="_blank">how-to-environments</a>)创建可重用的培训和部署环境。在我们的DIY MLOps中，这将类似于压缩你的整个conda virtualenv，并将其上传到artifactory以供以后部署。Python SDK中MLOps API的细节令人印象深刻，它们最近向环境驱动配置的转变为用户提供了透明性和灵活性。</p><h1 id="f7f0" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">2使用AzureML在GPU上训练PyTorch</h1><p id="0c1c" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在接下来的章节中，我们将使用PyTorch创建一个适合GPU计算的运行时环境。我们参考<a class="ae le" rel="noopener" target="_blank" href="/vscode-devcontainers-and-the-python-azureml-sdk-323dec18a675">第1部分</a>来创建计算集群。与第1部分的唯一变化是，我们使用“NC6_standard”虚拟机大小来获得一个带有一个GPU的虚拟机。选择一个带有GPU的虚拟机运行我们的带有<a class="ae le" href="https://github.com/NVIDIA/nvidia-docker" rel="noopener ugc nofollow" target="_blank"> nvidea_docker </a>的容器，而不是标准的docker引擎。这种自动检测相当新，我发现它是针对单个计算实例的(<a class="ae le" href="https://social.msdn.microsoft.com/Forums/azure/en-US/4b52d8b9-e110-4ae7-8212-da75058a5c10/azure-ml-pipeline-estimator-gpu-support-broken?forum=AzureMachineLearningService" rel="noopener ugc nofollow" target="_blank"> msdn-post </a>)。对于计算集群，GPU自动检测运行良好。</p><h1 id="b34e" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">2.1使用GPU支持创建运行时PyTorch环境</h1><p id="1095" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">出于我们的目的，我们在Python 3.6上运行PyTorch &gt;=1.4.0和Cuda 10.1。作为我们的基本docker映像，我们采用官方AzureML映像，基于Ubuntu 18.04 ( <a class="ae le" href="https://github.com/Azure/AzureML-Containers/tree/master/base/gpu" rel="noopener ugc nofollow" target="_blank"> gpu-images </a>)，包含原生gpu库和其他框架。</p><p id="9760" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了在我们的远程Conda环境中管理Python包，我们操作一个CondaDependencies对象，并将其附加到我们的环境对象。我们在这个对象上调用“add_conda_package ”,它有一个包名和可选的版本和内部版本。在PyTorch的例子中，我们需要一个特定的构建来启用GPU后端。我们还需要添加“py torch”conda通道和“add_channel”来安装这些包。虽然您可能更喜欢使用conda或pip需求文件，但我喜欢这种依赖管理的编程方法。</p><pre class="md me mf mg gt ms mt mu mv aw mw bi"><span id="402a" class="mx lg it mt b gy my mz l na nb"><strong class="mt iu"># settings.py<br/>from</strong> <strong class="mt iu">azureml.core</strong> <strong class="mt iu">import</strong> Environment<br/><strong class="mt iu">from</strong> <strong class="mt iu">azureml.core.conda_dependencies</strong> <strong class="mt iu">import</strong> CondaDependencies</span><span id="c51c" class="mx lg it mt b gy nc mz l na nb">PYTORCH_VERSION = "1.4.0"<br/>TORCH_ENVIRONMENT = Environment(name="torch-env")<br/>TORCH_ENVIRONMENT.docker.base_image = (<br/>    "mcr.microsoft.com/azureml/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04"<br/>)<br/>TORCH_ENVIRONMENT.docker.enabled = <strong class="mt iu">True</strong>  <em class="nd"># forced to True on AMLcompute targets<br/></em>TORCH_ENVIRONMENT.docker.gpu_support = <strong class="mt iu">True</strong>  <em class="nd"># deprecated as it is auto-detected<br/></em>torch_conda_dep = CondaDependencies()<br/>torch_conda_dep.add_channel("pytorch")<br/>torch_conda_dep.add_conda_package(<br/>    f"pytorch==<strong class="mt iu">{</strong>PYTORCH_VERSION<strong class="mt iu">}</strong>=py3.6_cuda10.1.243_cudnn7.6.3_0"<br/>)<br/>torch_conda_dep.add_conda_package("cudatoolkit==10.1.243")</span><span id="f1ac" class="mx lg it mt b gy nc mz l na nb"># add the conda dependencies to the environment<br/>TORCH_ENVIRONMENT.python.conda_dependencies = torch_conda_dep</span></pre><h1 id="f85a" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">2.2在环境中训练评估员</h1><h2 id="317d" class="mx lg it bd lh ne nf dn ll ng nh dp lp kr ni nj lr kv nk nl lt kz nm nn lv no bi translated">2.2.1评估者类别</h2><p id="3058" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">为了训练我们的PyTorch模型，我们使用了<a class="ae le" href="https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.estimator.estimator" rel="noopener ugc nofollow" target="_blank">估计器类</a>，它是机器学习模型的AzureML抽象。估计器可以提交给AzureML实验，该实验在计算目标上运行它。请注意，自2019–2020年起，PyTorch、Tensorflow和SKLearn的预配置估值器已被弃用。这些对于配置运行时环境来说太含蓄了，这使得它们不灵活，难以维护，并且对用户来说很神奇。建议所有新用户将vanilla Estimator类与Environment类结合使用。</p><h2 id="9328" class="mx lg it bd lh ne nf dn ll ng nh dp lp kr ni nj lr kv nk nl lt kz nm nn lv no bi translated">2.2.2将评估者提交给实验</h2><p id="c7c4" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">我们创建一个评估器，并把它传递给我们之前定义的环境。使用<a class="ae le" rel="noopener" target="_blank" href="/vscode-devcontainers-and-the-python-azureml-sdk-323dec18a675">第1部分</a>中所示的功能检索计算目标。我们创建(或检索)一个名为“estimator-test”的实验，并向它提交我们的评估器进行运行。</p><pre class="md me mf mg gt ms mt mu mv aw mw bi"><span id="b8f1" class="mx lg it mt b gy my mz l na nb"><strong class="mt iu">from</strong> <strong class="mt iu">azureml.core</strong> <strong class="mt iu">import</strong> Experiment, Workspace<br/><strong class="mt iu">from</strong> <strong class="mt iu">azureml.train.estimator</strong> <strong class="mt iu">import</strong> Estimator</span><span id="4d6f" class="mx lg it mt b gy nc mz l na nb"><strong class="mt iu">import</strong> <strong class="mt iu">settings<br/>from</strong> <strong class="mt iu">tools</strong> <strong class="mt iu">import</strong> get_compute</span><span id="fe4d" class="mx lg it mt b gy nc mz l na nb">workspace = Workspace.from_config()<br/>script_params = {<br/>     "--epochs": 10,<br/>}<br/>estimator = Estimator(<br/>    source_directory=settings.SOURCE_DIRECTORY,<br/>    compute_target=get_compute(workspace, settings.CLUSTER_NAME),<br/>    entry_script="relative/path/to/train_model.py",<br/>    script_param=script_params,<br/>    environment_definition=settings.TORCH_ENVIRONMENT,<br/>)<br/>experiment = Experiment(workspace=workspace, name="estimator-test")<br/>run = experiment.submit(estimator)</span></pre><h1 id="5cd7" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">3 .本地开发与远程培训相结合</h1><p id="77c3" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在我们的工作流程中，Docker容器同时在本地和远程运行。Docker的承诺之一是统一开发和生产之间的运行时环境。按照这些思路，我们希望针对远程环境在本地调试我们的训练代码。换句话说，我们希望使用相同的Docker映像进行本地开发和模型的远程训练。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi np"><img src="../Images/b6a2d62cc498149f6690a15d5e8eb53e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XoHsJ4VmrLxjlZrCoW67ww.jpeg"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">弗朗切斯科·温加罗摄影</p></figure><h1 id="1536" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">3.1基于AzureML生成的图像的VScode devcontainer</h1><p id="455d" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">VSCode devcontainer需要两个文件；一个Dockerfile和一个devcontainer.json。devcontainer/"文件夹。Dockerfile描述了我们的Docker映像，我们从它构造一个容器。devcontainer.json文件特定于VSCode，并配置与Docker容器的集成，如Python解释器路径、林挺可执行文件路径、VSCode扩展和绑定挂载。</p><h2 id="226f" class="mx lg it bd lh ne nf dn ll ng nh dp lp kr ni nj lr kv nk nl lt kz nm nn lv no bi translated">3.1.1从AzureML映像派生的Dockerfile</h2><p id="3e18" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在我们的Dockerfile(见下文)中，我们继承了AzureML ContainerRepository中的基本映像。我们可以通过用我们的AzureML docker注册中心对我们的本地Docker进行认证，在本地获取AzureML构建的Docker映像，并将其推送到我们的工作区。VSCode的docker和azure帐户扩展可以简化这种身份验证和拉取。</p><p id="77d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们希望在容器中安装Python dev依赖项，如black、pylint和pytest。我们将它们安装在AzureML用来运行代码的同一个Python环境中，尽管也可以有其他选择。AzureML生成的Conda环境位于映像上的“/azureml-envs/”中。Conda env的名称包含另一个随机UUID，其模式为:“azureml_ <uuid>”。在我们的docker文件中，我们使用与这个env相关联的pip来安装我们的Python dev依赖项，我们使用apt-get来安装vim和git，同时确保在这些操作之后进行清理。</uuid></p><pre class="md me mf mg gt ms mt mu mv aw mw bi"><span id="b243" class="mx lg it mt b gy my mz l na nb">FROM &lt;DOCKER_LOGIN_SERVER&gt;.azurecr.io/azureml/azureml_&lt;UUID&gt;:latest<br/>LABEL maintainer="luuk@codebeez.nl"</span><span id="0942" class="mx lg it mt b gy nc mz l na nb">ARG DEFAULT_UTILS="\<br/>  pylint \<br/>  flake8 \<br/>  autopep8 \<br/>  pytest \<br/>  mypy \<br/>  pydocstyle"</span><span id="a47e" class="mx lg it mt b gy nc mz l na nb">RUN /azureml-envs/azureml_&lt;UUID&gt;/bin/pip install --no-cache-dir ${DEFAULT_UTILS} \<br/>  &amp;&amp; apt-get update \<br/>  &amp;&amp; apt-get install -y \<br/>  vim \<br/>  git \<br/>  &amp;&amp; apt-get autoremove -y \<br/>  &amp;&amp; apt-get clean -y \<br/>  &amp;&amp; rm -rf /var/lib/apt/lists/*</span></pre><h2 id="5d82" class="mx lg it bd lh ne nf dn ll ng nh dp lp kr ni nj lr kv nk nl lt kz nm nn lv no bi translated">3.1.2将VSCode与容器集成</h2><p id="7d92" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">json定义了VSCode和Docker容器之间的集成。我们为devcontainer定义一个名称，后跟Dockerfile的路径(您也可以直接设置一个图像)。接下来是VSCode设置，带有我们的Python解释器和各种devtools的路径。我们完成了我们想要安装在devcontainer中的VSCode扩展。</p><pre class="md me mf mg gt ms mt mu mv aw mw bi"><span id="f8e8" class="mx lg it mt b gy my mz l na nb">{<br/>  "name": "unified-azureml",<br/>  "dockerFile": "Dockerfile",<br/>  // Set container specific VSCode settings<br/>  "settings": {<br/>    "terminal.integrated.shell.linux": "/bin/bash",<br/>    "python.pythonPath": "/azureml-envs/azureml_&lt;UUID&gt;/bin/python",<br/>    "python.linting.enabled": true,<br/>    "python.linting.pylintEnabled": true,<br/>    "python.linting.flake8Path": "/azureml-envs/azureml_&lt;UUID&gt;/bin flake8",<br/>    "python.linting.pycodestylePath": "/azureml-envs/azureml_&lt;UUID&gt;/bin pycodestyle",<br/>    "python.linting.pydocstylePath": "/azureml-envs/azureml_&lt;UUID&gt;/bin pydocstyle",<br/>    "python.linting.pylintPath": "/azureml-envs/azureml_&lt;UUID&gt;/bin pylint",<br/>    "python.testing.pytestPath": "/azureml-envs/azureml_&lt;UUID&gt;/bin pytest"<br/>  },<br/>  // Add the VSCode extensions you want installed<br/>  "extensions": [<br/>    "ms-python.python",<br/>    "ms-azure-devops.azure-pipelines",<br/>  ],<br/>}</span></pre><h2 id="f773" class="mx lg it bd lh ne nf dn ll ng nh dp lp kr ni nj lr kv nk nl lt kz nm nn lv no bi translated">3.1.3自动化的潜在断点</h2><p id="325f" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">当在基础映像之上以Docker存储库的名义创建Conda env时，AzureML生成的两个随机UUIDs是在我们的AzureML环境的迭代中自动化该工作流的潜在突破点。AzureML生成的docker库的名称可以在<a class="ae le" href="https://ml.azure.com" rel="noopener ugc nofollow" target="_blank"> AzureML studio </a>中运行的实验的“20_image_build_log.txt”日志文件中找到，可以在portal.azure.com上与AzureML工作区关联的Docker注册表的接口中找到，也可以通过使用其API找到。通过运行以下命令，可以获得映像中的Conda环境列表。</p><pre class="md me mf mg gt ms mt mu mv aw mw bi"><span id="8a1f" class="mx lg it mt b gy my mz l na nb">docker run &lt;DOCKER_LOGIN_SERVER&gt;.azurecr.io/azureml/azureml_&lt;UUID&gt; /bin/bash -c "conda env list"</span></pre><h1 id="bbc9" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">3.2摘要:AzureML统一的工作流</h1><p id="ee1c" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">使用AzureML环境类，我们基于支持GPU的docker映像定义了远程计算目标的运行时配置。这个环境被AzureML整合为一个定制的docker映像，并被推送到docker注册中心。我们使用这个定制映像来创建一个VSCode devcontainer，以统一我们的开发和远程环境。这允许我们在本地测试远程运行的相同环境。感谢您的关注，我期待着写更多与Python、机器学习和数据工程相关的话题。</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="f544" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nd">最初发布于</em><a class="ae le" href="https://codebeez.nl/blogs/azureml-pytorch-gpu-enabled-compute-target-unifying-remote-and-local-environments/" rel="noopener ugc nofollow" target="_blank"><em class="nd">https://codebeez . nl</em></a><em class="nd">。</em></p></div></div>    
</body>
</html>