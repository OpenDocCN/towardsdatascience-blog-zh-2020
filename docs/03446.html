<html>
<head>
<title>Does Deep Learning always have to Reinvent the Wheel?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习总是要重新发明轮子吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/does-deep-learning-always-have-to-reinvent-the-wheel-2c526018c5c5?source=collection_archive---------39-----------------------#2020-04-01">https://towardsdatascience.com/does-deep-learning-always-have-to-reinvent-the-wheel-2c526018c5c5?source=collection_archive---------39-----------------------#2020-04-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/8088ae57561471a1ba82acbeb252eeaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QKVBAdXDe0gGZZfDSLak6Q.png"/></div></div></figure><p id="98ad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">机器学习，特别是深度学习，彻底改变了我们今天所知道的世界。我们已经看到了语音和图像识别方面的巨大进步，随后是深度学习在许多其他领域的应用。在其中的许多领域，深度学习现在是最先进的，甚至正在超越它。一个明显的趋势是网络变得越来越复杂，计算要求越来越高。</p><p id="0276" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">今天，我们正在构建越来越多的网络，这些网络建立在前几代网络拓扑之上。由于神经网络固有地与其他神经网络兼容，我们能够将它们结合并适应新的目的。如果你的目标是解决一个新问题，没有明确的准则来定义一个合适的网络拓扑。最常见的方法是看看其他人试图解决类似问题的工作，或者自己设计一个全新的拓扑。这种新设计通常受到经典方法的启发，但它取决于网络和训练数据来学习正确的权重，以便它们收敛到似乎合理的解决方案。因此，它们甚至是从零开始学习众所周知的函数的网络，例如<a class="ae kz" href="https://www.nature.com/articles/nature25988" rel="noopener ugc nofollow" target="_blank">傅立叶变换</a>。由于离散傅立叶变换是一种矩阵乘法，因此它通常被建模为完全连接的层。使用这种方法，很明显有两个缺点是无法避免的:首先，全连接层引入了许多自由参数，这些参数可以模拟完全不同的功能。第二，用这种方法永远达不到快速傅立叶变换的计算效率。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi la"><img src="../Images/163bf25eab177cfc59563811db7e7445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VxEQTnFFogXREDH0HA35yg.png"/></div></div><p class="lf lg gj gh gi lh li bd b be z dk translated"><a class="ae kz" href="https://www.nature.com/articles/s42256-019-0077-5" rel="noopener ugc nofollow" target="_blank">已知操作员学习的可视化</a></p></figure><p id="1498" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果我们已经知道解决一个特定的问题需要一个特定的函数，我们就会想到这样一个问题:把它作为一种先验知识包含到我们的网络结构中是否会有好处。<a class="ae kz" href="https://www.nature.com/articles/s42256-019-0077-5" rel="noopener ugc nofollow" target="_blank">已知操作员学习</a>的方法在一个新的理论框架中研究了这个过程。虽然这个想法看起来简单而直观，但是理论分析也确定了明显的优点:首先，将已知操作引入神经网络总是导致较低或相等的最大训练误差界限。第二，减少了模型中自由参数的数量，从而也减少了所需训练数据的大小。另一个有趣的观察结果是，任何允许计算相对于输入的梯度的操作都可以嵌入到神经网络中。事实上，如我们从例如最大汇集操作中所知，即使是次梯度也已经足够了。</p><p id="0a76" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">有趣的是，这段理论是 2019 年才发表的。它是为将物理先验知识嵌入神经网络的理论分析而开发的。然而，这些观察也很好地解释了为什么我们看到卷积神经网络和池层的巨大成功。与生物学类似，我们可以认为卷积和汇集运算是感知的先验知识。最近的工作甚至走得更远:有一些方法甚至将复杂的滤波器功能，如<a class="ae kz" href="https://arxiv.org/abs/1711.03345" rel="noopener ugc nofollow" target="_blank">血管性滤波器</a>或<a class="ae kz" href="https://arxiv.org/abs/1803.05619" rel="noopener ugc nofollow" target="_blank">导向滤波器</a>纳入神经网络。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lj"><img src="../Images/ecb29610aca4cf15125666d7205a7045.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EWQcY3LhNX19HQsiaz9eZw.png"/></div></div><p class="lf lg gj gh gi lh li bd b be z dk translated">Frangi-Net 是<a class="ae kz" href="https://arxiv.org/abs/1711.03345" rel="noopener ugc nofollow" target="_blank">血管性过滤器</a>的可微分版本。在我们的<a class="ae kz" href="https://doi.org/10.24433/CO.5016803.v2" rel="noopener ugc nofollow" target="_blank">代码海洋实验环境</a>中测试代码。</p></figure><p id="9e3d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">理论分析还表明，前几层的建模误差会被后几层放大。这个观察结果也符合特征提取在经典机器学习和模式分析中的重要性。在深度学习中进行的特征提取和分类的组合，允许我们同步这两个过程，从而减少训练后的预期误差。</p><p id="1f49" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">由于精确学习允许结合经典理论方法和深度学习，我们现在能够将这些想法更进一步:最近的一篇<a class="ae kz" href="https://arxiv.org/abs/1807.03057" rel="noopener ugc nofollow" target="_blank">出版物</a>提出从底层物理方程中推导出特定问题的整个神经网络拓扑。这种方法的美妙之处在于，拓扑的许多操作符和构建块都是众所周知的，并且可以有效地实现。然而，它们仍然是计算效率非常低的操作。然而，我们从类似问题的其他解决方案中知道，特定的矩阵求逆或其他不太容易处理的运算可以用其他函数来表示。在这个例子中，昂贵的矩阵逆矩阵被循环矩阵代替，即卷积层，它是所提出的网络的唯一可学习部分。在他们的实验中，他们证明了所提出的架构确实解决了以前只能近似解决的问题。虽然他们只在模拟数据上进行训练，但在真实数据上的应用也是成功的。因此，包含先验知识也有助于构建针对特定问题的通用网络架构。</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lk"><img src="../Images/018941827122638785ae3fff873ac27f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*HmLQcF9UCrzratsPzCkB2A.gif"/></div></div><p class="lf lg gj gh gi lh li bd b be z dk translated">该动画示出了用于投影重排的已知操作者网络的拟合，该投影重排仅在合成数据上训练并应用于来自真实扫描仪的拟人幻像数据。代码可在我们的<a class="ae kz" href="https://doi.org/10.24433/CO.8086142.v2" rel="noopener ugc nofollow" target="_blank">代码海洋实验环境</a>中获得。</p></figure><p id="4dd8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们认为这些新方法对深度学习社区很有意思，深度学习社区今天已经远远超出了仅仅对感知任务进行建模。对我们来说，看到传统方法与今天在深度学习中所做的一切内在兼容是令人兴奋的。因此，我们相信在不久的将来，在机器和深度学习领域会有更多新的发展，跟踪这些发展将是令人兴奋的。</p><p id="a48d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果你认为这些观察是有趣和令人兴奋的，我们建议阅读我们的<a class="ae kz" href="https://www.sciencedirect.com/science/article/pii/S093938891830120X" rel="noopener ugc nofollow" target="_blank">深度学习温和介绍</a>作为这篇文章的后续，我们的<a class="ae kz" href="https://lme.tf.fau.de/teaching/free-deep-learning-resources/" rel="noopener ugc nofollow" target="_blank">免费深度学习资源</a>或<a class="ae kz" href="https://www.youtube.com/channel/UCoiMqX5FHfk_KDow7xSe7pg" rel="noopener ugc nofollow" target="_blank">我的 YouTube 频道</a>。</p><p id="b60f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本文的文本和图像根据知识共享许可 4.0 署名进行许可。因此，请随意重用和共享这项工作的任何部分。这篇文章最初发表在 MarkTechPost.com。</p></div></div>    
</body>
</html>