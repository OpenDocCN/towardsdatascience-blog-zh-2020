<html>
<head>
<title>Create Amazing Image Style Effects with only a few lines of code in Deep Learning!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在深度学习中只用几行代码就能创造出惊人的图像风格效果！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/create-amazing-image-style-effects-with-only-a-few-lines-of-code-in-deep-learning-b3869f24145c?source=collection_archive---------50-----------------------#2020-06-21">https://towardsdatascience.com/create-amazing-image-style-effects-with-only-a-few-lines-of-code-in-deep-learning-b3869f24145c?source=collection_archive---------50-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="99e8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习使用 CNN 实现神经类型转移</h2></div><p id="c7a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">神经风格转移是一种优化技术，其中将<strong class="kk iu"> <em class="le">原始图像</em> </strong>和<strong class="kk iu"> <em class="le">风格图像</em> </strong>(如著名画家的艺术品或图案)混合在一起，以获得样式图像的设计或图案中的<strong class="kk iu"> <em class="le">输出图像</em> </strong>。换句话说，它也可以被称为图像风格转移。</p><p id="72f4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们将应用<strong class="kk iu"> <em class="le">卷积神经网络</em> </strong> (CNN)的深度学习方法来创建一个图像效果，其中一个图像的设计或风格可以应用到另一个图像上，以查看创意效果。</p><div class="lf lg lh li gt ab cb"><figure class="lj lk ll lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/7ed05f1cbbb616d6a099200638e7cf27.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*rK_-M9WQ8TeyPVXExZMhRw.png"/></div></figure><figure class="lj lk ll lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/96366d35bd2365eca0756a870bd6f55c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*p39RiPg0ZmEHYzqjnxYzDg.png"/></div></figure><figure class="lj lk ll lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/c26d799a6e311bc483ba40cda5d6a63a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*b3y5SEvSdqWZwZ80BSR7UQ.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk ma di mb mc translated">主图像、风格图像和输出图像</p></figure></div><p id="4ff1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面分享的图片是使用 CNN 实现图像的风格转换的图片。</p><h2 id="a14c" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">概述—</h2><p id="bac8" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">对于我们的实验，我们将使用下面的'<strong class="kk iu"> <em class="le">原始图像</em> </strong>'和'<strong class="kk iu"> <em class="le">风格图像</em> </strong>'分享如下。</p><figure class="lf lg lh li gt lk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/7f8800f4afd489317ab5abe53444aabd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Mn5rUI9vaIspvG6ee6WW_Q.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">原象</p></figure><figure class="lf lg lh li gt lk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/6bf21e84d3ac1981d49a2c38264a425a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*gWNdZFoBOUdfrjP0DMvAaA.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">风格图像</p></figure><p id="6d27" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上面分享的图片来看，‘<strong class="kk iu"><em class="le">原始图片</em></strong>’是我们将应用“<strong class="kk iu"> <em class="le">风格图片</em> </strong>”的设计得到最终主输出的图片。整个程序的详细代码可以在本文末尾找到。</p><h2 id="8984" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">初始步骤—</h2><p id="6308" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">在程序代码的初始步骤中，我们将<em class="le">原始图像</em>和<em class="le">样式图像</em>的大小调整为<strong class="kk iu"> <em class="le"> 512X512 </em> </strong>。输出大小会是<strong class="kk iu"><em class="le">【512，512，3】</em></strong>。其中 3 表示图像是 RGB 或彩色图像。</p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="bb7d" class="md me it ne b gy ni nj l nk nl">main_image=main_image.resize((512,512))<br/>style_image=style_image.resize((512,512))</span><span id="8b65" class="md me it ne b gy nm nj l nk nl">main_array=np.asarray(main_image,dtype='float32')<br/>main_array=np.expand_dims(main_array,axis=0)<br/>style_array=np.asarray(style_image,dtype='float32')<br/>style_array=np.expand_dims(style_array,axis=0)</span></pre><p id="3c04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一步是通过使用<code class="fe nn no np ne b">expand_dims</code> <em class="le">将图像整形为形状<strong class="kk iu"> <em class="le"> (1，512，512，3) </em> </strong>的 4D 张量。然后我们创建一个新的变量'<strong class="kk iu"> <em class="le"> final_image </em> </strong>'，这将是我们最终的输出图像。</em></p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="cd8b" class="md me it ne b gy ni nj l nk nl">height=512<br/>width=512<br/>main_image=backend.variable(main_array)<br/>style_image=backend.variable(style_array)<br/>final_image=backend.placeholder((1,height,width,3))</span><span id="adf8" class="md me it ne b gy nm nj l nk nl">input_tensor=backend.concatenate([main_image,style_image,final_image],axis=0)</span></pre><h2 id="3540" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">CNN 架构—</h2><p id="f8ed" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">在这种方法中，我们将利用<strong class="kk iu"> <em class="le">迁移学习</em> </strong>的概念，应用预先训练好的<strong class="kk iu"> <em class="le"> VGG16 </em> </strong> CNN 模型。</p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="995d" class="md me it ne b gy ni nj l nk nl">model=VGG16(input_tensor=input_tensor,weights='imagenet', include_top=<strong class="ne iu">False</strong>)</span></pre><figure class="lf lg lh li gt lk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/0e9efbe9ae411bcf868f4a2a15b4545d.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/0*BUDlY_MsykcuKBZm.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">VGG16 架构(<a class="ae nr" rel="noopener" target="_blank" href="/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c">来源</a>)</p></figure><p id="4ed4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">据消息来源<a class="ae nr" href="https://arxiv.org/abs/1603.08155" rel="noopener ugc nofollow" target="_blank">强生等人</a>。，为了提取<strong class="kk iu">主图像内容层</strong>的特征，我们应该选择<code class="fe nn no np ne b">block1_conv2 </code>，对于<strong class="kk iu">样式层</strong>，我们需要选择<code class="fe nn no np ne b">block1_conv2, block2_conv2, block3_conv3, block4_conv3, block5_conv3</code>。这些层可以准确地从两幅图像中提取特征。</p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="b33a" class="md me it ne b gy ni nj l nk nl">layer_features=layers['block2_conv2']</span><span id="e9ee" class="md me it ne b gy nm nj l nk nl">feature_layers = ['block1_conv2', 'block2_conv2',<br/>                  'block3_conv3', 'block4_conv3',<br/>                  'block5_conv3']</span></pre><p id="4eb6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如论文中所给出的，所选择的层的组合正确地工作，以获得所需的风格转换。但是，你可以尝试不同的组合，以获得更准确的风格转移。</p><h2 id="65d1" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">主要损失—</h2><p id="907f" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">一旦我们最终确定了 CNN 模型，我们现在可以定义一个<strong class="kk iu">主损失</strong>函数。这是<strong class="kk iu">主图像</strong>和我们的<strong class="kk iu">输出图像</strong>之间的距离。</p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="871c" class="md me it ne b gy ni nj l nk nl"><strong class="ne iu">def</strong> main_loss(content, combination):     <br/>    <strong class="ne iu">return</strong> backend.sum(backend.square(content-combination))</span></pre><h2 id="ca57" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">风格丧失—</h2><p id="ad72" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated"><strong class="kk iu">风格损失</strong>类似于主损失，因为它是<strong class="kk iu">风格图像</strong>和我们的<strong class="kk iu">输出图像</strong>之间的距离。</p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="bfea" class="md me it ne b gy ni nj l nk nl"><strong class="ne iu">def</strong> style_loss(style,combination):<br/>    S=gram_matrix(style)<br/>    C=gram_matrix(combination)<br/>    channels=3<br/>    size=height * width<br/>    st=backend.sum(backend.square(S - C)) / (4. * (channels ** 2) * (size ** 2))<br/>    <strong class="ne iu">return</strong> st</span></pre><h2 id="3a96" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">最终损失—</h2><p id="0715" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">最后，我们将定义另一个损失，称为<strong class="kk iu">最终损失</strong>，这将调整最终图像。</p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="b39f" class="md me it ne b gy ni nj l nk nl"><strong class="ne iu">def</strong> final_loss(x):<br/>    a=backend.square(x[:,:height-1,:width-1,:]-x[:,1:,:width-1,:])<br/>    b = backend.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])<br/>    <strong class="ne iu">return</strong> backend.sum(backend.pow(a + b, 1.25))</span></pre><h2 id="9443" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">优化—</h2><p id="dd88" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">一旦我们定义了这三种损失，我们可以将风格转换表述为一个优化问题，其中我们的目标是最小化上面定义的所有三种损失，这统称为<strong class="kk iu">全局损失</strong>。</p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="64e3" class="md me it ne b gy ni nj l nk nl"><strong class="ne iu">def</strong> eval_loss_and_grads(x):     <br/>    x = x.reshape((1, height, width, 3))     <br/>    outs = f_outputs([x])     <br/>    loss_value = outs[0]     <br/>    grad_values = outs[1].flatten().astype('float64')     <br/>    <strong class="ne iu">return</strong> loss_value, grad_values</span></pre><h2 id="727a" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">评估员—</h2><p id="081d" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">在这之后，我们定义了一个类<code class="fe nn no np ne b">Evaluator()</code>,在这个类中，我们共同组合了上面定义的所有函数，并在主迭代中使用它进行样式转换。</p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="ef1e" class="md me it ne b gy ni nj l nk nl"><strong class="ne iu">class</strong> <strong class="ne iu">Evaluator</strong>(object):<br/>    <strong class="ne iu">def</strong> __init__(self):<br/>        self.loss_value=<strong class="ne iu">None</strong><br/>        self.grads_values=<strong class="ne iu">None</strong><br/>    <br/>    <strong class="ne iu">def</strong> loss(self, x):<br/>        <strong class="ne iu">assert</strong> self.loss_value <strong class="ne iu">is</strong> <strong class="ne iu">None</strong><br/>        loss_value, grad_values = eval_loss_and_grads(x)<br/>        self.loss_value = loss_value<br/>        self.grad_values = grad_values<br/>        <strong class="ne iu">return</strong> self.loss_value</span><span id="bbae" class="md me it ne b gy nm nj l nk nl">    <strong class="ne iu">def</strong> grads(self, x):<br/>        <strong class="ne iu">assert</strong> self.loss_value <strong class="ne iu">is</strong> <strong class="ne iu">not</strong> <strong class="ne iu">None</strong><br/>        grad_values = np.copy(self.grad_values)<br/>        self.loss_value = <strong class="ne iu">None</strong><br/>        self.grad_values = <strong class="ne iu">None</strong><br/>        <strong class="ne iu">return</strong> grad_values</span></pre><h2 id="6250" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">结果—</h2><p id="5db5" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">在这种情况下，我们将使用有限内存 BFGS，这是一种优化算法来执行 10 次迭代的风格转移。</p><pre class="lf lg lh li gt nd ne nf ng aw nh bi"><span id="f1cd" class="md me it ne b gy ni nj l nk nl">evaluator=Evaluator()<br/>iterations = 10<br/><strong class="ne iu">for</strong> i <strong class="ne iu">in</strong> range(iterations):<br/>    print('Start of iteration -', i)<br/>    ta = time.time()<br/>    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),<br/>                           fprime=evaluator.grads, maxfun=20)<br/>    print(min_val)<br/>    tb = time.time()<br/>    print('Iteration <strong class="ne iu">%d</strong> done in <strong class="ne iu">%d</strong> seconds' % (i, tb - ta))</span></pre><p id="7ab8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对可视化结果用<strong class="kk iu"><em class="le"/></strong><a class="ae nr" href="https://en.wikipedia.org/wiki/Limited-memory_BFGS" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu"><em class="le">L-BFGS</em></strong></a><strong class="kk iu"><em class="le">算法</em> </strong>我们得到如下图像。</p><figure class="lf lg lh li gt lk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/5b4b386f032ab5f8a7a8ced56780b9c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*StPb1DCp9ZGNoX_i8dvyMg.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">最终图像</p></figure><p id="1a0f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上图中，我们可以看到'<strong class="kk iu"> <em class="le">样式图像</em> </strong>'的样式已经成功的被施加到'<strong class="kk iu"> <em class="le">原始图像</em> </strong>'上。因此，我们成功地实现了使用 CNN 的图像风格转换。</p><p id="ad1c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我分享了我的 github 库的链接，在那里你可以找到完整的代码供你参考。</p><div class="ns nt gp gr nu nv"><a href="https://github.com/mk-gurucharan/Image-Style-Transfer" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">MK-gurucharan/图像-风格-转移</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">这是一个由代码组成的库，用于执行图像风格转换，以动画的形式显示真实的图像…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">github.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj lu nv"/></div></div></a></div><h2 id="150c" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">其他例子—</h2><p id="6af0" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">这里有更多的图像风格转换的例子，已经用这个程序实现了。</p><div class="lf lg lh li gt ab cb"><figure class="lj lk ll lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/d2bd034a846c98e90665228b485b9f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ZTT-V7zd5704JAtln4Ufbg.png"/></div></figure><figure class="lj lk ll lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/b18ffe0f0e5b0b0a61f07dafb79c5262.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*MmSglT9MSkyQz75sZnXg1A.png"/></div></figure><figure class="lj lk ll lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/ea24630b9df54eff0f17f6455fac1502.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*3lIxKkc4HVjwiwiQE9a-zw.png"/></div></figure></div><div class="ab cb"><figure class="lj lk ok lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/b762cf81429022c2f80566ea4d0cd913.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*1zxRRvriQ3ouxiESRfBOLQ.png"/></div></figure><figure class="lj lk ol lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/e057f96a8b5dfaff4f4b222ab93a8b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*pJoWW9dHUr0Fk44VuV94DQ.png"/></div></figure><figure class="lj lk om lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/1f86ff7178205a3a3253fc6966719b89.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*m4OnlhI4GZSnbvy-UZbJxQ.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk on di oo mc translated">图像风格转移的示例</p></figure></div><h2 id="7aac" class="md me it bd mf mg mh dn mi mj mk dp ml kr mm mn mo kv mp mq mr kz ms mt mu mv bi translated">结论—</h2><p id="dbbf" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">从这篇文章中，我们已经能够利用深度学习，特别是 CNN，来创建惊人的风格转移效果。尝试调整超参数，优化器和其他 CNN 架构，以获得新的和不同的结果。到那时，快乐的机器学习！</p></div></div>    
</body>
</html>