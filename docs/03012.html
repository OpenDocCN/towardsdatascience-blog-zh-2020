<html>
<head>
<title>Stylistic differences between R and Python in modelling data through the Naïve Bayes classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R 和 Python 在通过朴素贝叶斯分类器建模数据方面的风格差异</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stylistic-differences-between-r-and-python-in-modelling-data-through-the-na%C3%AFve-bayes-classifier-b7a30e6a1715?source=collection_archive---------41-----------------------#2020-03-22">https://towardsdatascience.com/stylistic-differences-between-r-and-python-in-modelling-data-through-the-na%C3%AFve-bayes-classifier-b7a30e6a1715?source=collection_archive---------41-----------------------#2020-03-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="95ab" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/data-science-stylistics" rel="noopener" target="_blank">数据</a>科学文体学</h2><div class=""/><div class=""><h2 id="9371" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">如何使用 R 和 Python，根据与事件相关的条件的先验知识，预测事件的概率</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/42f9b220636da9bce0a98fcd942bbdbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gq37KAqfK3pTeX_DHIgEhA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">通过作者组合来自<a class="ae le" href="https://analyticsprofile.com/wp-content/uploads/2019/06/naive-bayes-algorithm-1140x660.jpg" rel="noopener ugc nofollow" target="_blank">源 1 </a>、<a class="ae le" href="https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svghttps://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg" rel="noopener ugc nofollow" target="_blank">源 2 </a>和<a class="ae le" href="https://commons.wikimedia.org/wiki/File:R_logo.svg" rel="noopener ugc nofollow" target="_blank">源 3 </a>的图像</p></figure><p id="5b26" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于数据科学方法的最具决定性的方面是对数据进行建模，以产生估计和强大的预测，因此有大量的方法和算法可以探索这一目标。这篇博客提出了另一种建模数据的方法，超越了之前关于<a class="ae le" href="https://levelup.gitconnected.com/stylistic-differences-between-r-and-python-in-modelling-data-through-decision-trees-ea6f7c98e6e8" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">决策树</strong></a><strong class="lh ja"/>的博客中所解释的方法，即朴素贝叶斯分类方法。</p><p id="1b9e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这种分类方法是<strong class="lh ja">贝叶斯定理</strong>的衍生，贝叶斯定理描述了基于可能与事件相关的条件的先验知识的事件概率。这个定理的构想者是英国统计学家、哲学家和长老会牧师托马斯·贝叶斯(1701-1761)。这个定理成为他最著名的成就。贝叶斯定理的一个应用也是基于对概率的解释，即认知置信度的大小(信念、假设等的强度)。)而不是一个频率。这允许将概率应用于各种领域，而不仅仅是引用类附带的领域。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mb"><img src="../Images/494c4af6c9fbeede2994dab2177a0c9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mpc-gvjPPqI71oZ6d58mYg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">托马斯·贝叶斯<code class="fe mc md me mf b"><br/>Wikimedia Commons via <a class="ae le" href="https://en.wikipedia.org/wiki/Thomas_Bayes#/media/File:Thomas_Bayes.gif" rel="noopener ugc nofollow" target="_blank">Wikipedia</a></code></p></figure><h1 id="825c" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated"><strong class="ak"> 1。贝叶斯定理</strong></h1><p id="3f6a" class="pw-post-body-paragraph lf lg iq lh b li my ka lk ll mz kd ln lo na lq lr ls nb lu lv lw nc ly lz ma ij bi translated">在数据科学中，通过将我们以前的知识(称为先验分布)与从观察数据中获得的新信息相结合，贝叶斯定理被应用于更新我们关于特定数据参数的知识。这导致更新的参数知识，也称为后验分布。</p><p id="877e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">解释该定理的主要公式考虑了两个事件。在数据科学中，这两个事件可以是变量类型(预测值和目标值)。我们可以考虑由两个预测值(X*=X1，X2)组成的数据集，响应变量 Y 可以由多个类别(y1，y2，y3…)组成。通过贝叶斯定理，我们可以确定对于预测变量的特定组合，哪个类最有可能。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/0c16d93bd906ef75e92ded897639c69c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*yvXP2oAO7DCXZT7SyotGQw.jpeg"/></div></figure><p id="22f9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由分析前类值 y*的可能性给出的<strong class="lh ja">先验概率</strong>和当响应对应于特定类时数据如何表现的表示的组合产生了<strong class="lh ja">后验概率</strong>。等式左侧的分母描述了数据在不参考目标变量的类值的情况下如何表现，也称为数据的<strong class="lh ja">边际概率</strong>。在没有关于参数的先验知识的情况下，我们可以使用一个<strong class="lh ja">无信息先验</strong>，它表示所有类值都是同等可能的。在后一种情况下，后验概率仅基于数据。</p><p id="87d9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在 Y 的 3 个不同的可能类值的情况下，对于常数 X 值，我们可以计算 Y 的三个可能值中的每一个的贝叶斯概率，如下式所示。最大后验假设告诉我们将所选预测值 X 的记录分类为具有最高后验概率的目标变量 Y 的值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/4cb03c5bab22a0243b08fe52c65b96a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*EMSgT19Z_NyprX8Ik6poqg.jpeg"/></div></figure><p id="ee8a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">重要的是，即使我们有一个以上的预测变量，类条件独立性假设将各种事件或变量描述为独立的。因此，我们预测因子的选择应该考虑这一假设，确保 X1 和 X2 之间没有关系。</p><h1 id="1d0a" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">2.Python 中的朴素贝叶斯定理</h1><p id="f8ce" class="pw-post-body-paragraph lf lg iq lh b li my ka lk ll mz kd ln lo na lq lr ls nb lu lv lw nc ly lz ma ij bi translated">在<strong class="lh ja"> Python </strong>中应用贝叶斯定理的起点是上传相关的库，其中有一个名为<code class="fe mc md me mf b">MultinomialNB</code>的多项式朴素贝叶斯分类器，它适用于具有离散特征的分类(例如文本分类的字数)。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="850d" class="nj mh iq mf b gy nk nl l nm nn">import pandas as pd<br/>import numpy as np<br/>from sklearn.naive_bayes import MultinomialNB<br/>import statsmodels.tools.tools as stattools</span></pre><p id="19cd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其次，上传或创建相关数据框架是进行分析的基础。在这种情况下，为了模拟定理，我们可以随机生成一个数据集。在数据集中，预测因子和目标变量的选择可以源于特定的分析需要。在这个例子中，对收到多少援助的预测(Y)被探索为冲击类型和位置(X1，X2)的函数。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="09cd" class="nj mh iq mf b gy nk nl l nm nn">df = pd.DataFrame(np.random.randint(0,1000,size=(1000,1)), columns= ['AidMillion'])</span><span id="04a8" class="nj mh iq mf b gy no nl l nm nn">category = pd.cut(df.AidMillion,bins=[0,500,1000],labels=['Below_500_Mill','Above_500_Mill'])<br/>df.insert(2,'Aid_Given',category)<br/>df.Aid_Given = df.Aid_Given.tolist()</span><span id="0e70" class="nj mh iq mf b gy no nl l nm nn">df["TypeShock"] = np.random.choice(TypeShock, p=[0.40, 0.30, 0.30], size=len(df))</span><span id="d77d" class="nj mh iq mf b gy no nl l nm nn">Location = (['Urban','Rural'])<br/>df["Location"] = np.random.choice(Location, size=len(df))</span><span id="3284" class="nj mh iq mf b gy no nl l nm nn">df.head()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi np"><img src="../Images/46672fab098b4628f78499ef33ed66d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*P1ChsDIoMEC2SfKuklIIJw.jpeg"/></div></figure><p id="6f39" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了在<strong class="lh ja"> Python </strong>中进行分析，我们需要考虑一个测试和一个训练数据帧。可以分割主数据框架，或者选择具有相同变量的另一个信息源。在这种情况下，可以使用<code class="fe mc md me mf b">train_test_split</code>命令分割主数据帧。此外，如果打算手动执行贝叶斯计算，我们可以通过<code class="fe mc md me mf b">pd.crosstab</code>导出预测值的边际概率和条件概率。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="7041" class="nj mh iq mf b gy nk nl l nm nn">df_train, df_test=train_test_split(df, test_size=0.40, random_state=8)</span><span id="73aa" class="nj mh iq mf b gy no nl l nm nn">t1=pd.crosstab(df_train['Aid_Given'], df_train['TypeShock'])<br/>t1['Total']=t1.sum(axis=1)<br/>t1.loc['Total']=t1.sum()<br/>t1</span><span id="f38c" class="nj mh iq mf b gy no nl l nm nn">t2=pd.crosstab(df_train['Aid_Given'], df_train['Location'])<br/>t2['Total']=t2.sum(axis=1)<br/>t2.loc['Total']=t2.sum()<br/>t2</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/44687d670ccd3f15a49c3c2bf3b44dad.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*w17ugtX5SKXFIGsxzc9WUA.jpeg"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/5876900a5bf0bff9d49d679928e87360.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*bEmykb0kS5j3dRn9Q8ZPvQ.jpeg"/></div></figure><p id="a663" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了在<strong class="lh ja"> Python </strong>中应用贝叶斯算法，我们需要将每个预测器转换成哑元。这可以通过对解释目标变量所需的每个变量(冲击类型、位置)使用<code class="fe mc md me mf b">stattools.categorical </code>命令来完成，并通过命令<code class="fe mc md me mf b"> pd.concat</code>将它们连接成一个数据帧。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="211e" class="nj mh iq mf b gy nk nl l nm nn">x_loc_ind= np.array(df_train['Location'])<br/>(x_loc_ind, x_loc_dict)= stattools.categorical(x_loc_ind, drop= True, dictnames=True)<br/>x_loc_ind= pd.DataFrame(x_loc_ind)</span><span id="ee69" class="nj mh iq mf b gy no nl l nm nn">x_shock_ind= np.array(df_train['TypeShock'])<br/>(x_shock_ind, x_shock_dict)= stattools.categorical(x_shock_ind, drop=True, dictnames= True)<br/>x_shock_ind=pd.DataFrame(x_shock_ind)</span><span id="f194" class="nj mh iq mf b gy no nl l nm nn">X=pd.concat((x_loc_ind, x_shock_ind), axis=1)</span><span id="6e8a" class="nj mh iq mf b gy no nl l nm nn">X.head()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/ccf014f211f5286d23de364cd4a47a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*lpzljxyLg13laSviIyeFzw.jpeg"/></div></figure><p id="5b7c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">将预测变量转换成虚拟矩阵后，为了清晰起见，定义 Y 变量是有用的。在预测器和目标变量被很好地定义后，就可以将代表<strong class="lh ja">朴素贝叶斯</strong>算法的<code class="fe mc md me mf b">MultinomialNB</code>命令应用于训练数据集。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="4a11" class="nj mh iq mf b gy nk nl l nm nn">Y= df_train['Aid_Given']<br/>Bayes_01=MultinomialNB().fit(X,Y)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nt"><img src="../Images/8b90ae3e4c56b261b51e3099214e7b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Y3Sp-MUX26xN1Bz4b9QEQ.jpeg"/></div></div></figure><p id="3fc1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">决定性的一步是在测试数据集上测试<strong class="lh ja">朴素贝叶斯估计器</strong>。为了做到这一点，我们需要像以前一样将测试数据中的 X 变量设置为虚拟变量。一旦为测试数据集设置了预测变量，就可以使用命令<code class="fe mc md me mf b">predict</code>生成预测，该命令为测试数据集中的每条记录生成一个预测值数组。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="ea16" class="nj mh iq mf b gy nk nl l nm nn">x_loc_ind_test= np.array(df_test['Location'])<br/>(x_loc_ind_test, x_loc_dict_test)= stattools.categorical(x_loc_ind_test, drop=True, dictnames= True)<br/>x_loc_ind_test= pd.DataFrame(x_loc_ind_test)</span><span id="8b2d" class="nj mh iq mf b gy no nl l nm nn">x_shock_ind_test= np.array(df_test['TypeShock'])<br/>(x_shock_ind_test, x_shock_dict_test)= stattools.categorical(x_shock_ind_test, drop= True, dictnames= True)<br/>x_shock_ind_test=pd.DataFrame(x_shock_ind_test)</span><span id="77bf" class="nj mh iq mf b gy no nl l nm nn">X_test= pd.concat((x_loc_ind_test, x_shock_ind_test), axis=1)</span><span id="3623" class="nj mh iq mf b gy no nl l nm nn">Y_predicted= Bayes_01.predict(X_test)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nu"><img src="../Images/320a95849202260c87dd43ee5fd84ba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zMESNBEM7TvClx6onp4oDA.jpeg"/></div></div></figure><p id="4469" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在对 Bayes 对象(在本例中命名为 Bayes_01)使用了<code class="fe mc md me mf b">predict</code>命令之后，我们最终可以创建一个实际和预测目标类(高于和低于 5 亿)的列联表，这可以帮助我们理解我们的模型的准确性。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="7bfb" class="nj mh iq mf b gy nk nl l nm nn">ypred = pd.crosstab(df_test['Aid_Given'], Y_predicted, rownames=['Actual'], colnames=['Predicted'])</span><span id="3b1b" class="nj mh iq mf b gy no nl l nm nn">ypred['Total'] = ypred.sum(axis=1); ypred.loc['Total']=ypred.sum(); ypred</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/97870f3fadc6d2b01ae67248a6df34a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*PdZ_8GncvT5WUp6W71tE6g.jpeg"/></div></figure><p id="fdac" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了测试<strong class="lh ja"> Python </strong>的准确性水平，我们可以简单地对测试数据集中记录总数中实际条目与预测条目相对应的频率进行求和。总的来说，该模型只有 51%的准确率，这意味着只有 1/2 的预测是正确的。该模型在预测 500 Mill 以上级别时比基线模型表现更好(58.3%对 48%)，而在预测 500 Mill 以下级别时比基线模型表现差(44.3%对 48%)。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="c10d" class="nj mh iq mf b gy nk nl l nm nn">PerformanceGlobal=(112+92)/400<br/>PerformanceAbove500=(112/192)<br/>PerformanceBelow500=(92/208)<br/>PerformanceGlobal, PerformanceAbove500, PerformanceBelow500</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/3be701b398a55b050fa6b601712c9308.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*fys-aoH15y7afus9hkaqGA.jpeg"/></div></figure><h1 id="b436" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">3.R 中的朴素贝叶斯定理</h1><p id="d803" class="pw-post-body-paragraph lf lg iq lh b li my ka lk ll mz kd ln lo na lq lr ls nb lu lv lw nc ly lz ma ij bi translated">就像我们在前面的例子中所做的一样，在<strong class="lh ja"> R </strong>中应用贝叶斯定理的第一步也需要上传或生成包含预测值和目标变量的数据集。在这种情况下，建议使用相同的数据集结构，预测值仍然是冲击类型和位置，而目标变量是给定 aid 的分解。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="4aee" class="nj mh iq mf b gy nk nl l nm nn">df &lt;- data.frame(replicate(1,sample(0:1000, 1000, rep=TRUE)))<br/>colnames(df) &lt;- c("AidMillion")</span><span id="f90d" class="nj mh iq mf b gy no nl l nm nn">df$Aid_Given &lt;- ifelse(df$AidMillion &lt;= 500, "Above_500_Mill", "Below_500_Mill")</span><span id="607e" class="nj mh iq mf b gy no nl l nm nn">df$TypeShock &lt;- sample(c('Draught','Floods','Famine'), size = nrow(df), replace = TRUE)</span><span id="0232" class="nj mh iq mf b gy no nl l nm nn">df$Location &lt;- sample(c('Urban','Rural'), size = nrow(df), replace = TRUE)</span><span id="8a5f" class="nj mh iq mf b gy no nl l nm nn">df$Aid_Given &lt;- as.factor(df$Aid_Given)<br/>head(df)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/e30052de480db71378d0a74edc42b1d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*wo957vgduzvCzoiYpXILMg.jpeg"/></div></figure><p id="6fa8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一旦选择了数据帧，我们要么将它分成两部分，要么上传一个具有相同变量的相似数据集。为了将从训练数据集生成的预测值应用于测试数据集，有必要使用两个数据框架。如果我们决定使用相同的数据帧，那么<code class="fe mc md me mf b">runif</code>命令可以帮助我们做到这一点。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="07a3" class="nj mh iq mf b gy nk nl l nm nn">set.seed(8)<br/>n&lt;- dim(df)[1]<br/>train_df&lt;-runif(n)&lt;0.60<br/>df_train&lt;- df[train_df, ]<br/>df_test&lt;- df[!train_df, ]</span></pre><p id="70de" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一旦数据帧准备好进行分析，我们就可以创建两个表来手工计算概率(如果我们愿意的话)。<strong class="lh ja">列联表</strong>也有助于理解预测值的分类属性在各类目标变量中的<strong class="lh ja">分布</strong>。请注意与 Python 的区别，在<strong class="lh ja"> R </strong>中，我们必须为每个表指定列名和行名，而没有轴的指定。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="64be" class="nj mh iq mf b gy nk nl l nm nn">t1&lt;- table(df_train$Aid_Given, df_train$TypeShock) <br/>colnames(t1)&lt;- c("Draught","Floods","Famine")<br/>rownames(t1)&lt;- c("Above_500_Mill","Below_500_Mill")<br/>addmargins(A=t1, FUN=list(Total=sum), quiet=TRUE)</span><span id="93ed" class="nj mh iq mf b gy no nl l nm nn">t2&lt;- table(df_train$Aid_Given, df_train$Location) <br/>colnames(t2)&lt;- c("Urban","Rural")<br/>rownames(t2)&lt;- c("Above_500_Mill","Below_500_Mill")<br/>addmargins(A=t2, FUN=list(Total=sum), quiet=TRUE)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/34309af44b09ce6eb7c985e0b44edb4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*PFSNliGX55e9hJWRiN707A.jpeg"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/fa9ec9b3dd01286374132784c1c136c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*NalK0dqDpseXXXJhPd6NYQ.jpeg"/></div></figure><p id="a609" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一旦我们创建了列联表，下一步就是通过库<code class="fe mc md me mf b">e1071</code>应用贝叶斯算法。命令<code class="fe mc md me mf b">naiveBayes</code>比 Python 中的对等命令产生了更多关于<strong class="lh ja">先验</strong>和<strong class="lh ja">条件</strong> <strong class="lh ja">概率</strong>的信息。之间的另一个风格差异是在 Bayes 命令中明确指定了解释预测值和目标变量之间关系的公式。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="4a2a" class="nj mh iq mf b gy nk nl l nm nn">library(e1071)<br/>Bayes01 &lt;- naiveBayes(formula= Aid_Given~ TypeShock+ Location, data=df_train)</span><span id="71f9" class="nj mh iq mf b gy no nl l nm nn">Bayes01</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/65e19d205c2fdc39299b3511621b9daf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*x8v3J5BFZ3keZYOEUOmh_Q.jpeg"/></div></figure><p id="f13a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> R </strong>中的最后一步是通过命令<code class="fe mc md me mf b">predict</code>将 object Bayes01 中生成的目标变量的预测类应用于测试数据集，生成<strong class="lh ja">最终列联表</strong>。和前面的表格一样，我们需要定义<code class="fe mc md me mf b">rownames</code>、<code class="fe mc md me mf b">colnames</code>和边距来创建一个可读的表格。这是与 Python 风格的一个关键区别。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="9e57" class="nj mh iq mf b gy nk nl l nm nn">ypred &lt;- predict(object=Bayes01, newdata=df_test)<br/>test.preds &lt;- table (df_test$Aid_Given, ypred)</span><span id="0868" class="nj mh iq mf b gy no nl l nm nn">rownames(test.preds)&lt;- c("Actual:Above_500_Mill","Actual:Below_500_Mill")<br/>colnames(test.preds)&lt;- c("Predicted:Above_500_Mill","Predicted:Below_500_Mill")<br/>addmargins(A=test.preds, FUN=list(Total=sum), quiet=TRUE)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/e80a643f2f391e24a87e0ff4a302dde3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*VpoBYaadp_1iiAXD7BHvYA.jpeg"/></div></figure><p id="a063" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一旦生成列联表，我们就可以评估模型的性能与先验计算中规定的基线值。总体而言，该模型的准确率为 50.4%，这意味着只有 1/2 的预测是正确的，就像我们前面的例子一样。与基线模型相比，该模型在预测 500 Mill 以下级别方面表现更好(51.8%对 46.5%)，而在预测 500 Mill 以上级别方面，该模型表现稍差(49.62%对 53.4%)。</p><pre class="kp kq kr ks gt nf mf ng nh aw ni bi"><span id="6254" class="nj mh iq mf b gy nk nl l nm nn">PerformanceGlobal=(131+71)/401<br/>PerformanceAbove500=131/264<br/>PerformanceBelow500=71/137<br/>PerformanceGlobal; PerformanceAbove500; PerformanceBelow500</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/815d61ba830713357a4c46d05f311b39.png" data-original-src="https://miro.medium.com/v2/resize:fit:412/format:webp/1*hK6I3DAm8aAzgzZQ8RqRFw.jpeg"/></div></figure><p id="2989" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于数据集是随机生成的，这些结果的唯一目的是说明性的。遵循之前博客中强调的所有步骤，以确保相关的专业知识与精心准备的数据框架相结合，从而产生有意义的分析，这仍然是非常关键的。</p><h1 id="9b83" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">在这另一种建模方法之后，下一篇博客将继续解释建模数据的其他方法。敬请关注即将推出的方法！</h1></div></div>    
</body>
</html>