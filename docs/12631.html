<html>
<head>
<title>Chained multi-output regression solution with Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带 Scikit-Learn 的链式多输出回归解决方案</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/chained-multi-output-regression-solution-with-scikit-learn-4f44bf9c8c5b?source=collection_archive---------27-----------------------#2020-08-31">https://towardsdatascience.com/chained-multi-output-regression-solution-with-scikit-learn-4f44bf9c8c5b?source=collection_archive---------27-----------------------#2020-08-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="cd2e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" rel="noopener" target="_blank" href="https://towardsdatascience.com/machine-learning/home">内部 AI </a></h2><div class=""/><div class=""><h2 id="f141" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">按顺序运行回归模型，以利用目标之间的相关性来预测多个因变量</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/3e97f512f3f80287aa55a32841b9a3cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JhVscTcPSZ8V6tQDGr3Hvg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者插图——链式多输出回归</p></figure><p id="bdd6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在典型的回归或分类场景中，我们有一组自变量和一个或多个因变量。有时，不可能一起预测所有因变量的值。由于目标之间的相关性，我们需要考虑序列中其他因变量的预测值来预测下一个目标值。屏住呼吸，通过本文讨论的详细解释和例子就变得清晰了。所有变量也称为特征，因变量称为目标。</p><p id="7777" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了在这种情况下使用机器学习进行预测，我们可以将序列回归模型与 Scikit-Learn 中的<strong class="lj jd">回归链</strong>放在一起</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi md"><img src="../Images/4c6eb5499e3501a3b1903406ad30e5ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lVltf_uycgRJjPtv8IRn8w.png"/></div></div></figure><p id="fe6c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基于独立特征和目标变量序列中的第一因变量来训练第一模型。在训练第一个模型时，不考虑其他因变量值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi me"><img src="../Images/c028adc3bda54aafd76aab325f3e8e69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*_F_b8GoA3GFuKGZBorIpyA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者举例说明—基于独立特征训练数据和第一从属训练数据实际值训练第一模型</p></figure><p id="9ae0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第二模型根据训练数据集中的独立特征值、第一和第二因变量值进行拟合和训练。该模型用于随后用测试数据集预测第二目标值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mf"><img src="../Images/e77e4a43112468f8c548db1af02b0e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ocNYBJUOSYTzlYUc0Fs3Lg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者的说明-基于独立特征训练数据、第一和第二相关训练数据实际值来训练第二模型</p></figure><p id="a6d1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后，为了预测第三因变量，基于独立特征值和所有因变量值训练最后的模型。最后一个模型将用于预测变量序列中最后一个因变量(目标)的值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mg"><img src="../Images/be30e5bca4d3a3adaaa668c2eef5fc7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vPYSc-Q-yudVft6JXTtSZA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者举例说明-根据独立特征训练数据和所有三个相关训练数据实际值训练最后一个模型</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/ad4b50e6fb2515d4ee19400e1d3045f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*bp1pJS3QQW_R3nfLK48WDw.png"/></div></figure><p id="44da" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">所有三个经过训练的模型将与不同的输入数据一起使用，以预测序列中的因变量值。</p><p id="9eb9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">将独立特征测试值作为输入的第一训练模型用于根据从属特征的指定顺序来预测第一从属变量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/87c331a4659c9b2764bfa51dd4a18952.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*dU_4Ie5ElnOd4_ndt-0dcQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者插图-测试第一个训练模型的数据集独立特征值输入</p></figure><p id="c618" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第一因变量的预测值和独立特征测试值被训练的第二模型用作输入，以预测下一因变量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mj"><img src="../Images/f2987724d7a441ae4346f02bc9d2a60e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9M-D5vXn-9t4uSZJR_uihA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者的说明-测试数据集独立特征值和第一目标预测值是第二训练模型的输入</p></figure><p id="87bd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">前两个因变量预测值与测试独立特征值一起用作第三训练模型的输入，用于预测最后一个因变量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mk"><img src="../Images/49689df8c694f449b7e5aa3a308491d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ElqQetmLT5Gp98Xfa0qr-g.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者的说明-测试数据集独立特征值和两个目标预测值是第三个训练模型的输入</p></figure><p id="3c0c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">步骤 1: </strong>在 Scikit-Learn 包中，<strong class="lj jd"> RegressorChain </strong>在 multioutput 模块中实现。我们将使用 make_regression、math 和 NumPy 来创建测试数据。</p><pre class="ks kt ku kv gt ml mm mn mo aw mp bi"><span id="eeb7" class="mq mr it mm b gy ms mt l mu mv"><strong class="mm jd">from sklearn.linear_model import LinearRegression<br/>from sklearn.multioutput import RegressorChain<br/>import math<br/>import numpy as np<br/>from sklearn.datasets import make_regression</strong></span></pre><p id="1bff" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">第二步:</strong>生成 20000 条记录的样本测试数据，包含 10 个独立特征和 1 个相关特征。</p><pre class="ks kt ku kv gt ml mm mn mo aw mp bi"><span id="10fa" class="mq mr it mm b gy ms mt l mu mv"><strong class="mm jd">X, y,coef  = make_regression(n_samples=20000, n_features=10, random_state=0, noise=4.0,coef=True, bias=200)</strong></span></pre><p id="c0b4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">步骤 3: </strong>创建相关的第二个和第三个因变量 y2 和 y3，所有三个因变量在下面的代码中被转换成一个 2000 x 3 的数组。</p><pre class="ks kt ku kv gt ml mm mn mo aw mp bi"><span id="64e0" class="mq mr it mm b gy ms mt l mu mv"><strong class="mm jd">y2=(y*math.sin(45))+(math.pi/3)<br/>y3=y*y<br/>y= np.vstack((y,y2,y3)).T</strong></span></pre><p id="e1f2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">第四步:</strong>根据<strong class="lj jd">回归链</strong>中的“顺序”参数考虑连续的因变量，用于训练不同的模型。在我们的示例中，基于独立特征训练值和第二因变量值来训练第一模型。然后，独立特征值、第二和第三从属值被用作训练第二模型的输入。最后，利用独立特征测试值和所有三个因变量测试数据集值，训练第三个模型。</p><pre class="ks kt ku kv gt ml mm mn mo aw mp bi"><span id="5568" class="mq mr it mm b gy ms mt l mu mv"><strong class="mm jd">reg = LinearRegression()</strong></span><span id="3bde" class="mq mr it mm b gy mw mt l mu mv"><strong class="mm jd">ChainRegression= RegressorChain(reg, order=[1,2,0])<br/>ChainRegression.fit(X,y)</strong></span><span id="3a05" class="mq mr it mm b gy mw mt l mu mv"><strong class="mm jd">print(ChainRegression.score(X, y))</strong></span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mx"><img src="../Images/1b3973368c94f83bbdbcbdc0c1d3069a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1lfpPsrPKz89sWloBTU-DA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">已训练模型的准确度分数</p></figure><p id="11ed" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如前所述，以独立特征测试值作为输入的第一模型预测第二相关值。那么独立特征测试值和第二从属预测值将被用作预测第三从属值的输入。最后，独立特征测试值连同第二和第三预测值被用作预测第一相关值的输入。</p><p id="7dce" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这样，如果我们有一个以上的目标(因变量)值，并且目标特征(因变量)以一定的顺序相关，我们就可以实现序列回归。</p><pre class="ks kt ku kv gt ml mm mn mo aw mp bi"><span id="add3" class="mq mr it mm b gy ms mt l mu mv">"Full Code"</span><span id="9441" class="mq mr it mm b gy mw mt l mu mv"><strong class="mm jd">from sklearn.linear_model import LinearRegression<br/>from sklearn.multioutput import RegressorChain<br/>import math<br/>import numpy as np<br/>from sklearn.datasets import make_regression</strong></span><span id="474e" class="mq mr it mm b gy mw mt l mu mv"><strong class="mm jd">X, y,coef  = make_regression(n_samples=20000, n_features=10, random_state=0, noise=4.0,coef=True, bias=200)</strong></span><span id="ea6e" class="mq mr it mm b gy mw mt l mu mv"><strong class="mm jd">y2=(y*math.sin(45))+(math.pi/3)<br/>y3=y*y<br/>y= np.vstack((y,y2,y3)).T<br/></strong></span><span id="a429" class="mq mr it mm b gy mw mt l mu mv"><strong class="mm jd">reg = LinearRegression()<br/>ChainRegression= RegressorChain(reg, order=[1,2,0])<br/>ChainRegression.fit(X,y)</strong></span><span id="8cac" class="mq mr it mm b gy mw mt l mu mv"><strong class="mm jd">print(ChainRegression.score(X, y))</strong></span></pre></div></div>    
</body>
</html>