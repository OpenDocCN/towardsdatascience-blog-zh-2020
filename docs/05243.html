<html>
<head>
<title>Using Distributed Machine Learning to Model Big Data Efficiently</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用分布式机器学习对大数据进行高效建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-distributed-machine-learning-to-model-big-data-efficiently-546491aec11e?source=collection_archive---------39-----------------------#2020-05-04">https://towardsdatascience.com/using-distributed-machine-learning-to-model-big-data-efficiently-546491aec11e?source=collection_archive---------39-----------------------#2020-05-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/c49c895524daa6e8037ffc2233bca3b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*6isFeitX_HXSfhGQrE4wSQ.jpeg"/></div><p class="ju jv gj gh gi jw jx bd b be z dk translated">图像<a class="ae jy" href="https://yurongfan.wordpress.com/2017/01/10/sparkml-demo-car-classification-using-sparkml-pysparkpython-api/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="7e4f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">随着分布式计算成为数据科学家越来越受欢迎的技能，在AWS EMR集群上运行Apache Spark逐渐成为业内处理大数据的常用方式。</p><p id="3197" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">PySpark API允许我们轻松地用Python编写Spark，同时让Spark在后台并行计算数据。在本文中，我们将使用来自<a class="ae jy" href="https://www.kaggle.com/benhamner/sf-bay-area-bike-share" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的4g旧金山自行车共享数据集来实时模拟共享自行车的可用性。</p><p id="a489" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这篇文章将涵盖:</p><ol class=""><li id="70bb" class="kx ky iq kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated">AWS EMR或本地环境上的火花初始化</li><li id="c232" class="kx ky iq kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">用Spark和Plotly进行探索性数据分析</li><li id="4045" class="kx ky iq kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">使用Spark SQL对数据进行预处理</li><li id="3f41" class="kx ky iq kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">建模:在Spark ML中使用随机Fores回归器</li><li id="7d01" class="kx ky iq kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated">为优化运行时间配置您的AWS EMR集群</li></ol></div><div class="ab cl ll lm hu ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="ij ik il im in"><h1 id="9630" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">1.AWS EMR或本地环境上的火花初始化</h1><p id="e6ec" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">要使用spark，我们可以在AWS EMR集群上运行它，或者如果您只是想试用它，也可以在您本地的Jupiter笔记本上运行它。有很多关于如何在AWS EMR上设置你的笔记本以使用PySpark的文章，比如<a class="ae jy" rel="noopener" target="_blank" href="/getting-started-with-pyspark-on-amazon-emr-c85154b6b921">这篇</a>。EMR集群配置也将在很大程度上影响您的运行时，我将在最后一部分提到这一点。</p><h1 id="2abe" class="ls lt iq bd lu lv mv lx ly lz mw mb mc md mx mf mg mh my mj mk ml mz mn mo mp bi translated"><strong class="ak"> 2。探索性数据分析</strong></h1><p id="4627" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">为了预处理数据，我将使用Spark RDD操作来执行探索性的数据分析和可视化。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ng"><img src="../Images/dad2cf40a8f90a961d92f7080143d061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-8-CylmMYy5H_9jSAWgj9g.png"/></div></div><p class="ju jv gj gh gi jw jx bd b be z dk translated">温度对订户的影响比对非订户的影响小</p></figure><p id="79fc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">其余的Spark <a class="ae jy" href="https://github.com/estheryl/sf_bike_share_spark/blob/master/EDA_preprocessing.ipynb" rel="noopener ugc nofollow" target="_blank">预处理代码</a>和<a class="ae jy" href="https://github.com/estheryl/sf_bike_share_spark/blob/master/EDA_visulization.ipynb" rel="noopener ugc nofollow" target="_blank"> Plotly可视化代码</a>可以在Github repo上找到，但这里是我们最初探索性分析的图表。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nl"><img src="../Images/bda29a0b2186301fa0b4740ebe468ed3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ltaEitD98PPJIWIA6yNtDQ.png"/></div></div><p class="ju jv gj gh gi jw jx bd b be z dk translated">用户倾向于在工作日更频繁地使用共享自行车。</p></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nm"><img src="../Images/960a9e9beb2ecdfe291c1fd9e62b042c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nvAdkHPhpuq8jK6krlDbtw.png"/></div></div><p class="ju jv gj gh gi jw jx bd b be z dk translated">非订户每次出行使用自行车的时间要长得多，这可能是因为订户大多是通勤者，而不是游客。</p></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nn"><img src="../Images/729a516568c3c7d955393377933e6220.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uqPeLAtOfKTxML8oyQMt4w.png"/></div></div><p class="ju jv gj gh gi jw jx bd b be z dk translated">用户的行程持续时间范围较小，集中在10分钟左右。</p></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi no"><img src="../Images/6a035b5440179b68ef3c337da7caf070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vda_SmQorVxxJhVmBdGbKA.png"/></div></div><p class="ju jv gj gh gi jw jx bd b be z dk translated">显然，你可以把共享单车带上火车</p></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi np"><img src="../Images/ee731d4c2283a24724223c698be7e94c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0im4QwJUY_GlDUrw4FhnJA.png"/></div></div><p class="ju jv gj gh gi jw jx bd b be z dk translated">最常见的出行路线是通勤者在办公室和地铁站之间使用它。</p></figure><h1 id="6e38" class="ls lt iq bd lu lv mv lx ly lz mw mb mc md mx mf mg mh my mj mk ml mz mn mo mp bi translated"><strong class="ak"> 3。使用Spark SQL对数据进行预处理</strong></h1><p id="3aed" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">正如我们在步骤2中看到的，使用火花RDD进行数据预处理可能很难理解或可视化。这里，我们将使用Spark SQL，它允许我们从RDD创建数据帧。</p><p id="13be" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">为此，我们首先创建一个模式，并用列名、数据类型和nullable定义StructField。或者，您也可以在RDD上使用<em class="nq"> toDF() </em>让Spark推断模式。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nr"><img src="../Images/df783d2268b0db15b989b7e980e08f68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f1olW_KnfQ6QhbRR51ckQg.png"/></div></div><p class="ju jv gj gh gi jw jx bd b be z dk translated">weather_df(显示在Jupyter笔记本中)</p></figure><p id="4cd0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然后，我们可以使用像<strong class="kb ir"> select()、agg()、join() </strong>这样的函数来操作Spark SQL数据帧，就像处理熊猫数据帧一样。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ns"><img src="../Images/ca1750254b37d9de5b1d5e080d1a3356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vBwIJcK5KlrgLxJ9X5UlUA.png"/></div></div></figure><p id="d018" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">经过更多的数据预处理后，我们为机器学习模型准备好了数据框架。我们希望通过以下功能预测特定时间内给定站点的可用自行车数量:</p><p id="61d3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">○车站信息</p><p id="232b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">○天气状况</p><p id="0c29" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">○一天的类型</p><p id="f8e8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">○一天中的某个小时</p><p id="d1d0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">○该地区的人口</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nt"><img src="../Images/8191425980aef6126537f5ee07f0d39c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NIZDIJ73cLifHr7uYsFEWg.png"/></div></div></figure><h1 id="7362" class="ls lt iq bd lu lv mv lx ly lz mw mb mc md mx mf mg mh my mj mk ml mz mn mo mp bi translated"><strong class="ak"> 4。建模:使用Spark ML中的随机森林回归器</strong></h1><p id="7686" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated"><strong class="kb ir"> a)特征工程</strong></p><p id="4a7b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">PySpark支持许多常用函数来做<a class="ae jy" href="https://spark.apache.org/docs/latest/ml-features" rel="noopener ugc nofollow" target="_blank">特性工程</a>，我们将使用<strong class="kb ir"> StringIndexer() </strong>来对我们的分类变量rain_identifier执行标签编码。</p><p id="d378" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在将特性转换成数字类型后，我们可以使用<strong class="kb ir"> VectorAssembler() </strong>将所有特性组合成一个向量列。这对于训练ML模型很有用，因为您将在后面的<strong class="kb ir"> RandomForestRegressor </strong>中看到，它只接受一个<em class="nq"> inputCol </em>参数。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7c442815af25934c10377395f0f84bba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*2eUyPvxY4jZ4ZVHLwdRr8w.png"/></div></figure><p id="fdeb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，DataFrame将我们所有的特征转换成一个向量，还有我们的目标变量:可用自行车的数量。</p><p id="6a4f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> b)创建模型和模型评估</strong></p><p id="3554" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">创建训练和测试集时，调用<strong class="kb ir">。cache() </strong>将数据帧缓存到内存中以加速训练过程。(这里有一个关于什么时候在Spark 中使用缓存的更全面的阅读。)</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="aea8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> c)模型调整</strong></p><p id="ab1f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">Spark ML还支持使用<strong class="kb ir"> CrossValidator() </strong>和<strong class="kb ir"> ParamGridBuilder() </strong>进行交叉验证和超参数调优。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="2743" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我也在全笔记本里玩过Spark ML的梯度提升回归器，决策树，线性回归，但是随机森林回归器在这些模型中表现最好。</p><h1 id="787e" class="ls lt iq bd lu lv mv lx ly lz mw mb mc md mx mf mg mh my mj mk ml mz mn mo mp bi translated"><strong class="ak"> 5。</strong>配置您的AWS EMR集群以获得最佳运行时间</h1><p id="f9cd" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">选择集群节点的实例类型和节点数量可能很棘手，这取决于数据的大小和代码所需的计算能力。根据AWS的<a class="ae jy" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html" rel="noopener ugc nofollow" target="_blank">文档</a>，</p><blockquote class="nv nw nx"><p id="1c17" class="jz ka nq kb b kc kd ke kf kg kh ki kj ny kl km kn nz kp kq kr oa kt ku kv kw ij bi translated">计算密集型集群可能受益于在高CPU实例上运行，这些实例的CPU比RAM多。数据库和内存缓存应用程序可能会受益于在高内存实例上运行。</p><p id="c7d2" class="jz ka nq kb b kc kd ke kf kg kh ki kj ny kl km kn nz kp kq kr oa kt ku kv kw ij bi translated">规划集群实例的一种方法是用一组有代表性的样本数据运行一个测试集群，并监视集群中节点的利用率。</p></blockquote><p id="6313" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">为了进行简单的比较，我运行了同一个jupyter笔记本，其中包括这四个不同EMR集群的所有预处理和ML建模代码。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ob"><img src="../Images/4ec6c342359b1b3e14d737fb03b3053d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TY9Nj_2OW1sOnUvhPk-3Nw.png"/></div></div></figure><p id="8968" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们可以看到，增加节点数量(每个节点代表EMR集群下的一个EC2实例)并不一定意味着内存优化实例的运行时间更短。</p><h1 id="78f6" class="ls lt iq bd lu lv mv lx ly lz mw mb mc md mx mf mg mh my mj mk ml mz mn mo mp bi translated">摘要</h1><p id="402c" class="pw-post-body-paragraph jz ka iq kb b kc mq ke kf kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw ij bi translated">希望本文对您使用Spark处理Python中的大数据和大规模运行机器学习模型有所帮助。Spark SQL和基于数据帧的Spark ML API也省去了我们处理Spark RDD的麻烦，因为我们可以将数据存储在数据帧中。</p><p id="cbe2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果你对SF共享自行车可用性建模的预测结果和关键发现感兴趣，这里有<a class="ae jy" href="https://github.com/estheryl/sf_bike_share_spark" rel="noopener ugc nofollow" target="_blank"> Github repo </a>。也可以在<a class="ae jy" href="https://www.linkedin.com/in/esther-yihui-liu/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上给我发消息。</p><p id="b35f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这是三藩市大学MSDS 697与黛安·伍德布里奇教授的一个小组项目。小组成员是阿坎卡莎。、刘品言、孙清怡和林海洋。</p></div></div>    
</body>
</html>