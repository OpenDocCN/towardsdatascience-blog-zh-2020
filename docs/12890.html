<html>
<head>
<title>Machine Learning: Some notes about Cross-Validation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习:关于交叉验证的一些注意事项</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-some-notes-about-cross-validation-4a0315599f2?source=collection_archive---------35-----------------------#2020-09-04">https://towardsdatascience.com/machine-learning-some-notes-about-cross-validation-4a0315599f2?source=collection_archive---------35-----------------------#2020-09-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="11bf" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">交叉验证的不同方法概述</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6cff56b82a885c1962514a680092f87d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n3yERMhGi61EGXzmLs9bdw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">制造者在<a class="ae ky" href="https://unsplash.com/collections/4545574/it?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae ky" href="https://unsplash.com/@nesabymakers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> NESA 的照片</a></p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="43a8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">简介</strong></p><p id="e535" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如您所知，当我们将数据分为训练集和测试集时，我们的主要目标是了解模型在面对与训练阶段使用的数据不同的新数据时的预测能力。</p><p id="dbb2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">无论如何，有一个可靠的方法来评估我们的模型的性能。这种方式被称为交叉验证。交叉验证是一种评估泛化性能的统计技术，它比使用分为训练集和测试集的方法更稳定。</p><p id="f313" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，我们将了解一些交叉验证方法，如 K 倍交叉验证、分层 K 倍交叉验证和留一交叉验证。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="32c2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">第一部分:K 倍交叉验证</strong></p><p id="0db9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">k 重交叉验证是最常用的交叉验证方法之一。在这个方法中，<strong class="li iu"> <em class="mc"> k </em> </strong>表示为了测试和训练我的数据，我想要尝试的实验(或折叠)次数。</p><p id="0015" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">例如，假设我们想要用由 1000 条记录组成的数据进行 5 次实验(或性能)。因此，在第一个实验中，我们测试或验证前 200 条记录，然后训练剩余的 800 条记录。当第一个实验完成时，我获得了一定的精度。然后，我们进行第二个实验，测试我之前测试的记录之后的 200 条记录，并训练剩余的 800 条记录。</p><p id="23f0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我用一组 200 个记录继续实验，直到我完成所有 5 个实验。请记住，我们总是测试先前记录的下 200 个记录，并训练剩余的记录直到结束。</p><p id="cd06" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在我的 5 次实验结束时，我将获得 5 次精度，最终精度将是所有精度的平均值。</p><p id="7833" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">下面你可以看到一个直观的例子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi md"><img src="../Images/cf60aa2f9465a18d7d6fe05ef203d84d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KtiqrHAvU7Xd5NnFcMMJlg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4b11" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">交叉验证是在 scikit-learn 中使用来自<strong class="li iu"> model_selecion </strong>模块的<strong class="li iu"> cross_val_score </strong>函数实现的。<strong class="li iu"> cross_val_score </strong>函数的参数是我们想要评估的模型、训练数据和目标。下面是一个逻辑回归的例子:</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="f6ca" class="mj mk it mf b gy ml mm l mn mo">from <strong class="mf iu">sklearn.model_selection</strong> import <strong class="mf iu">cross_val_score</strong></span><span id="48be" class="mj mk it mf b gy mp mm l mn mo">from <strong class="mf iu">sklearn.linear_model</strong> import <strong class="mf iu">LogisticRegression</strong></span><span id="9fea" class="mj mk it mf b gy mp mm l mn mo">logreg = LogisticRegression()</span><span id="287f" class="mj mk it mf b gy mp mm l mn mo">scores = cross_val_score(logreg, X,y,cv=5)</span></pre></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="b0fa" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">第二部分:分层 K 褶交叉验证</strong></p><p id="3a7c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">考虑到前面 1000 条记录的例子，有时从测试前 200 条记录开始并不总是一个好主意。事实上，在一个数据集中，我们可以发现前三分之一的数据指向同一个类。</p><p id="e434" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">假设我们有三个类(0、1 和 2)，如下所示:</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="ad4c" class="mj mk it mf b gy ml mm l mn mo">[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]</span></pre><p id="c8a5" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">可以看到，第一个第三类是 0，第二个是 1，第三个是 2。现在想象做 3 个实验(k=3)。在我们的第一个实验中，测试集只在类 0 中，训练集只在类 1 和 2 中。所以，你可以知道精度是 0。</p><p id="a03c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了处理这个问题，我们可以使用<strong class="li iu">分层 k 倍交叉验证</strong>。在分层交叉验证中，我们对数据进行分割，使每个折叠中的类之间的比例与它们在整个数据集中的比例相同，如下图所示。在该图中，对 k 倍交叉验证和分层交叉验证进行了比较:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mq"><img src="../Images/276ff8ed2b11223c7ef363590e735934.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rW9I6BFbzub8-peMnZFFlQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="9022" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Scikit-learn 帮助我们进行分层折叠。所以:</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="4c6f" class="mj mk it mf b gy ml mm l mn mo">from <strong class="mf iu">sklearn.model_selection</strong> import <strong class="mf iu">StratifiedKFold</strong></span><span id="744b" class="mj mk it mf b gy mp mm l mn mo">skf = StratifiedKFold(n_split=5, random_state=None)</span><span id="06df" class="mj mk it mf b gy mp mm l mn mo"># X is the feature set and y is the target<br/>for train_index, test_index in skf.split(X,y): <br/>    print("Train:", train_index, "Test:", test_index) <br/>    X_train, X_test = X.iloc[train_index], X.iloc[test_index] <br/>    y_train, y_test = y[train_index], y[test_index]</span></pre></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="cea2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">第三部分:留一交叉验证</strong></p><p id="5dc5" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">另一个有趣的交叉验证方法是<strong class="li iu">留一法。</strong>这种方法类似于我们之前看到的 k-fold，但是对于每个实验(或表演),我们只取一个样本进行测试，而不是像以前那样取 200 个记录。</p><p id="d327" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">下面，我们可以用<strong class="li iu"> LeaveOneOut </strong>在 scikit-learn 中找到实现。</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="7e61" class="mj mk it mf b gy ml mm l mn mo">from <strong class="mf iu">sklearn.model_selection</strong> import <strong class="mf iu">LeaveOneOut</strong></span><span id="6586" class="mj mk it mf b gy mp mm l mn mo">loo = LeaveOneOut()</span><span id="90c7" class="mj mk it mf b gy mp mm l mn mo">cross_val_score(logreg, X, y, cv=loo)</span></pre></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="b0fc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">结论</strong></p><p id="03eb" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，您已经看到了机器学习中用于评估模型准确性的最常见的交叉验证方法。无论如何，还有一些其他的方法，如混洗-分裂交叉验证，分组交叉验证和时间序列交叉验证，在某些情况下非常有用。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="7c0f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">感谢你阅读这篇文章。您还可以通过其他方式与我保持联系并关注我的工作:</p><ul class=""><li id="7fa3" class="mr ms it li b lj lk lm ln lp mt lt mu lx mv mb mw mx my mz bi translated">订阅我的时事通讯。</li><li id="93ae" class="mr ms it li b lj na lm nb lp nc lt nd lx ne mb mw mx my mz bi translated">也可以通过我的电报群<a class="ae ky" href="https://t.me/DataScienceForBeginners" rel="noopener ugc nofollow" target="_blank"> <em class="mc">数据科学初学者</em> </a>联系。</li></ul></div></div>    
</body>
</html>