<html>
<head>
<title>mlmachine - Crowd-Sourced Feature Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">mlmachine -众包特征选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mlmachine-crowd-sourced-feature-selection-50cd2bbda1b7?source=collection_archive---------54-----------------------#2020-04-22">https://towardsdatascience.com/mlmachine-crowd-sourced-feature-selection-50cd2bbda1b7?source=collection_archive---------54-----------------------#2020-04-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/b7ed0416a7c707afb851a22ce8ea352e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HTczjsfQiliG-hxyIK-I8A.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="https://pixabay.com/users/qimono-1962238/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=1872665" rel="noopener ugc nofollow" target="_blank">阿雷克索查</a>从<a class="ae jd" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=1872665" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>发来</p></figure><h2 id="e1fe" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">多层机器</h2><div class=""/><div class=""><h2 id="6009" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">这个新的 Python 包加速了基于笔记本的机器学习实验</h2></div><h2 id="7ccb" class="le lf jg bd lg lh li dn lj lk ll dp lm ln lo lp lq lr ls lt lu lv lw lx ly jm bi translated">TL；速度三角形定位法(dead reckoning)</h2><p id="6863" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated">mlmachine 是一个 Python 库，用于组织和加速基于笔记本的机器学习实验。</p><p id="3934" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">在本文中，我们使用 mlmachine 来完成原本需要大量编码和工作的操作，包括:</p><ul class=""><li id="fa09" class="mx my jg mb b mc ms mf mt ln mz lr na lv nb mr nc nd ne nf bi translated">众包特征重要性估计</li><li id="2bf8" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">通过迭代交叉验证的特征选择</li></ul><p id="e8d9" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">查看这篇文章的<a class="ae jd" href="https://github.com/petersontylerd/mlmachine/blob/master/notebooks/mlmachine_part_3.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>。</p><p id="4db1" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">在 GitHub 上查看<a class="ae jd" href="https://github.com/petersontylerd/mlmachine" rel="noopener ugc nofollow" target="_blank">项目</a>。</p><p id="6874" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">并查看过去的 mlmachine 文章:</p><div class="ip iq gp gr ir nl"><a rel="noopener follow" target="_blank" href="/mlmachine-clean-ml-experiments-elegant-eda-pandas-pipelines-daba951dde0a"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd jq gy z fp nq fr fs nr fu fw jp bi translated">mlmachine -干净的 ML 实验，优雅的 EDA 和 Pandas 管道</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">这个新的 Python 包加速了基于笔记本的机器学习实验</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz ix nl"/></div></div></a></div><div class="ip iq gp gr ir nl"><a rel="noopener follow" target="_blank" href="/mlmachine-groupbyimputer-kfoldencoder-and-skew-correction-357f202d2212"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd jq gy z fp nq fr fs nr fu fw jp bi translated">ml machine-group by inputr、KFoldEncoder 和倾斜校正</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">这个新的 Python 包加速了基于笔记本的机器学习实验</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="oa l nw nx ny nu nz ix nl"/></div></div></a></div></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="baf0" class="oi lf jg bd lg oj ok ol lj om on oo lm kv op kw lq ky oq kz lu lb or lc ly os bi translated">众包特征重要性估计</h1><h2 id="dd90" class="le lf jg bd lg lh li dn lj lk ll dp lm ln lo lp lq lr ls lt lu lv lw lx ly jm bi translated">技术目录</h2><p id="3bc2" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated">以下是特征重要性估计技术的非穷尽列表:</p><ul class=""><li id="6cb6" class="mx my jg mb b mc ms mf mt ln mz lr na lv nb mr nc nd ne nf bi translated">基于树的特征重要性</li><li id="7065" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">递归特征消除</li><li id="a3e0" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">顺序向前选择</li><li id="32c8" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">顺序向后选择</li><li id="78b7" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">f 值/ p 值</li><li id="dad6" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">差异</li><li id="4b40" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">目标相关性</li></ul><p id="542e" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">这一系列技术来自几个不同的库。理想情况下，我们使用<em class="ot">所有的</em>这些技术(在适用的情况下)来广泛理解每个特征在机器学习问题中扮演的角色。这是一系列繁琐的任务。</p><p id="2a15" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">即使我们花时间去执行每一种方法，不同的执行会导致不同的变量，使整体评估变得乏味。</p><p id="ecc1" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">mlmachine 的<code class="fe ou ov ow ox b"><strong class="mb jq">FeatureSelector()</strong></code>类使得运行上面列出的所有特性重要性评估技术变得容易。此外，我们可以同时对各种估计量和各种度量进行这样的操作。让我们看看 mlmachine 的运行情况。</p><h2 id="fe5f" class="le lf jg bd lg lh li dn lj lk ll dp lm ln lo lp lq lr ls lt lu lv lw lx ly jm bi translated">准备数据</h2><p id="0d27" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated">首先，我们应用数据预处理技术来清理数据。我们将首先创建两个<code class="fe ou ov ow ox b"><strong class="mb jq">Machine()</strong></code>对象——一个用于训练数据，另一个用于验证数据:</p><figure class="oy oz pa pb gt is"><div class="bz fp l di"><div class="pc pd l"/></div></figure><p id="7e5e" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">现在，我们通过输入空值并应用各种宁滨和编码技术来处理数据:</p><figure class="oy oz pa pb gt is"><div class="bz fp l di"><div class="pc pd l"/></div></figure><p id="b323" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">这里是输出，仍然在一个<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>:</p><figure class="oy oz pa pb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pe"><img src="../Images/5a9c1ecc721bb4a41d4955dcfbeb2be4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nonr2qmpiAwmSiB5n_GhdQ.jpeg"/></div></div></figure><h2 id="23c3" class="le lf jg bd lg lh li dn lj lk ll dp lm ln lo lp lq lr ls lt lu lv lw lx ly jm bi translated">特征选择器</h2><p id="4bdd" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated">我们的<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>已经被估算，以多种方式编码，并且有几个新特性。我们准备好迎接<code class="fe ou ov ow ox b"><strong class="mb jq">FeatureSelector()</strong></code>。</p><p id="ecf4" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated"><strong class="mb jq">示例 1 -评估员类别</strong></p><figure class="oy oz pa pb gt is"><div class="bz fp l di"><div class="pc pd l"/></div></figure><p id="f966" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">为了实例化一个<code class="fe ou ov ow ox b"><strong class="mb jq">FeatureSelector()</strong></code>对象，我们传递训练数据、标签和一个评估者列表。这个估计器列表可以包含估计器类名、实例化模型的变量或两者的组合。在这个例子中，我们传递了<code class="fe ou ov ow ox b"><strong class="mb jq">LogisticRegression()</strong></code>和<code class="fe ou ov ow ox b"><strong class="mb jq">XGBClassifier()</strong></code>的类名，这利用了估计器的默认设置。</p><p id="1ac6" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">我们的<code class="fe ou ov ow ox b"><strong class="mb jq">FeatureSelector()</strong></code>对象包含上述每个特性重要性技术的内置方法，以及一个名为<code class="fe ou ov ow ox b"><strong class="mb jq">feature_selector_suite()</strong></code>的方法，该方法将所有技术合并到一次执行中。</p><p id="d849" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">为了执行<code class="fe ou ov ow ox b"><strong class="mb jq">feature_selector_suite()</strong></code>，我们将“准确性”传递给参数<code class="fe ou ov ow ox b"><strong class="mb jq">sequential_scoring</strong></code>，将 0 传递给参数<code class="fe ou ov ow ox b"><strong class="mb jq">sequential_n_folds</strong></code>。这些参数影响顺序向后/向前算法。我们还将<code class="fe ou ov ow ox b"><strong class="mb jq">save_to_csv</strong></code>设置为 True，以将结果<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>保存到 CSV。这是我们的结果:</p><figure class="oy oz pa pb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pf"><img src="../Images/2f95c3193fb759b51d3b968b4a65f5af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YaB5z3fbDpmAwCuQ-g4-Ew.jpeg"/></div></div></figure><p id="8fe1" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">在<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>中，一些列捕获指标的值，包括 F 值、P 值、方差、目标相关性和基于树的特征重要性。其余的列根据底层算法捕获选择或消除某个特征的顺序。</p><p id="50d8" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated"><strong class="mb jq">示例 2 -实例化模型</strong></p><p id="df8c" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">这是另一个例子。这一次，我们使用包含<code class="fe ou ov ow ox b"><strong class="mb jq">RandomForestClassifier()</strong></code>类和三个实例化模型的估计器列表来实例化<code class="fe ou ov ow ox b"><strong class="mb jq">FeatureSelector()</strong></code>。每个<code class="fe ou ov ow ox b"><strong class="mb jq">RandomForestClassifier()</strong></code>用<code class="fe ou ov ow ox b"><strong class="mb jq">max_depth</strong></code>超参数的不同值来实例化。最后，我们将“roc_auc”而不是“accuracy”作为我们的评分标准传递给<code class="fe ou ov ow ox b"><strong class="mb jq">sequential_scoring</strong></code>。</p><figure class="oy oz pa pb gt is"><div class="bz fp l di"><div class="pc pd l"/></div></figure><figure class="oy oz pa pb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pg"><img src="../Images/1cda15a768fbcefd322a0d031a0a1625.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lZQLUHqbgpke-iGOUaIn2g.jpeg"/></div></div></figure><p id="ad31" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">注意，在这个<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>中，我们有递归特性消除和基于树的特性重要性的列，它们是专门为我们的评估列表中的实例化模型命名的。</p><p id="ed83" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">我们已经整理了一份描述特性重要性的摘要，但是我们才刚刚开始。</p><h2 id="df48" class="le lf jg bd lg lh li dn lj lk ll dp lm ln lo lp lq lr ls lt lu lv lw lx ly jm bi translated">众包</h2><p id="7d72" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated">将所有这些信息放在一个地方的价值是显而易见的，但是为了实现对特征重要性的众包式、集合式评估，我们首先需要将这些值标准化。这样便于排名。</p><p id="6f31" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">除了将价值观放在同一尺度上，我们还需要确保始终如一地处理价值观的方向性。例如，高 F 值表示重要特征，而低 p 值表示重要特征。</p><p id="9599" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">mlmachine 让这一切变得简单。<code class="fe ou ov ow ox b"><strong class="mb jq">FeatureSelector()</strong></code>包含一个名为<code class="fe ou ov ow ox b"><strong class="mb jq">feature_selector_stats()</strong></code>的方法，它逐列应用这个排序。作为一个额外的好处，<code class="fe ou ov ow ox b"><strong class="mb jq">feature_selector_stats()</strong></code>添加了几个描述每个特性排名的汇总统计列，并自动按照最佳排名对特性进行排序。</p><figure class="oy oz pa pb gt is"><div class="bz fp l di"><div class="pc pd l"/></div></figure><figure class="oy oz pa pb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ph"><img src="../Images/41ba9396bfd9a2eeb9752a183c5c3850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O-YVBYDmKCDGsK-FK29DtA.jpeg"/></div></div></figure><p id="fdf6" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">请注意这次更新的<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>(延伸到屏幕外)中的 3 个关键差异:</p><ol class=""><li id="7728" class="mx my jg mb b mc ms mf mt ln mz lr na lv nb mr pi nd ne nf bi translated">原始<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>中每列的值现在显示为等级，其中较低的值表示较高重要性的特性。</li><li id="c6a6" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr pi nd ne nf bi translated">在<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>的左侧插入额外的汇总统计栏。</li><li id="d975" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr pi nd ne nf bi translated"><code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>按平均排名升序排序。</li></ol><p id="f36d" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">根据这一总结，这些模型中最重要的前三个特征是“票价”、“性别”的平均目标编码版本和“年龄”。</p><p id="47a4" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">在这个例子中，我们执行了第二步<code class="fe ou ov ow ox b"><strong class="mb jq">feature_selector_stats()</strong></code>，但是我们可以通过将<code class="fe ou ov ow ox b"><strong class="mb jq">feature_selector_suite()</strong></code>中的<code class="fe ou ov ow ox b"><strong class="mb jq">add_stats</strong></code>参数设置为 True 来跳过这一步。</p></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="512c" class="oi lf jg bd lg oj ok ol lj om on oo lm kv op kw lq ky oq kz lu lb or lc ly os bi translated">通过迭代交叉验证的特征选择</h1><p id="8f3a" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated">特性重要性本身是一个好的开始，但是我们的最终目标是只为我们即将到来的模型训练阶段选择最有意义的特性。</p><p id="21f0" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">我们的分级和排序的特性重要性总结是下一步的基础。为了评估每个子集，<code class="fe ou ov ow ox b"><strong class="mb jq">FeatureSelector()</strong></code>使用了一种类似于递归特征消除的方法:</p><ul class=""><li id="39c8" class="mx my jg mb b mc ms mf mt ln mz lr na lv nb mr nc nd ne nf bi translated">使用交叉验证训练具有所有特征的模型</li><li id="4e6b" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">获取训练和验证数据集的平均性能</li><li id="efff" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">从剩余的可用特征中移除最不重要的(1 倍步长)特征</li><li id="724f" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated">重复此操作，直到特性列表耗尽</li></ul><p id="2a28" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">为了确定“最不重要”，我们依赖于已排序的特征重要性汇总。每次我们删除功能时，我们会从剩余的功能中删除排名最低的功能。</p><h2 id="2911" class="le lf jg bd lg lh li dn lj lk ll dp lm ln lo lp lq lr ls lt lu lv lw lx ly jm bi translated">简历摘要</h2><p id="7f00" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated">让我们看看 mlmachine 的运行情况:</p><figure class="oy oz pa pb gt is"><div class="bz fp l di"><div class="pc pd l"/></div></figure><p id="abe2" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">我们的<code class="fe ou ov ow ox b"><strong class="mb jq">FeatureSelector()</strong></code>对象包含一个名为<code class="fe ou ov ow ox b"><strong class="mb jq">feature_selector_cross_val()</strong></code>的方法。这将执行迭代特征子集评估并存储结果。让我们回顾一下参数:</p><ul class=""><li id="6f5f" class="mx my jg mb b mc ms mf mt ln mz lr na lv nb mr nc nd ne nf bi translated"><code class="fe ou ov ow ox b"><strong class="mb jq">feature_selector_summary</strong></code>:我们排名排序后的功能重要性汇总</li><li id="e942" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated"><code class="fe ou ov ow ox b"><strong class="mb jq">estimators</strong></code>:我们想要用来评估特性的评估器列表</li><li id="114d" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated"><code class="fe ou ov ow ox b"><strong class="mb jq">scoring</strong></code>:一个或多个评分标准</li><li id="66d6" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated"><code class="fe ou ov ow ox b"><strong class="mb jq">n_folds</strong></code>:交叉验证程序中的折叠数</li><li id="a3c2" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated"><code class="fe ou ov ow ox b"><strong class="mb jq">step</strong></code>:每次迭代后要移除的特征数量</li><li id="c50b" class="mx my jg mb b mc ng mf nh ln ni lr nj lv nk mr nc nd ne nf bi translated"><code class="fe ou ov ow ox b"><strong class="mb jq">save_to_csv</strong></code>:指定是否将结果保存在 CSV 中</li></ul><p id="47d6" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">让我们回顾一下我们的结果:</p><figure class="oy oz pa pb gt is gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/7c110a72de66c8683866628173ce0804.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*mkQZniR49ZyvFqJee7M3cA.jpeg"/></div></figure><p id="8b0f" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">在<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>的每一行，我们可以看到单个评估者基于特定评分标准对某个特性子集的性能。“删除的功能”列描述了从全部功能集中删除了多少功能。记住，在每次迭代之后，<code class="fe ou ov ow ox b"><strong class="mb jq">feature_selector_cross_val()</strong></code>删除(1 x 步)最不重要的特征，其中重要性基于<code class="fe ou ov ow ox b"><strong class="mb jq">feature_selection_summary</strong></code>的排名和排序。</p><h2 id="957f" class="le lf jg bd lg lh li dn lj lk ll dp lm ln lo lp lq lr ls lt lu lv lw lx ly jm bi translated">可视化性能曲线</h2><p id="2195" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated"><code class="fe ou ov ow ox b"><strong class="mb jq">FeatureSelector()</strong></code>还有一个内置方法，用于可视化每个子集的训练和验证分数:</p><figure class="oy oz pa pb gt is"><div class="bz fp l di"><div class="pc pd l"/></div></figure><figure class="oy oz pa pb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pk"><img src="../Images/c255c93c47e68ccc08737b92bebe82d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VRGblTRz_F_F9p6E2q_YyA.gif"/></div></div></figure><p id="9bfb" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">在这里，我们可以看到 4 个<code class="fe ou ov ow ox b"><strong class="mb jq">RandomForestClassifier()</strong></code>模型的训练和验证准确性分数趋势。每个图表标题都清楚地告诉我们最佳验证准确性分数，以及达到该分数时从完整功能集中删除了多少功能。</p><h2 id="4273" class="le lf jg bd lg lh li dn lj lk ll dp lm ln lo lp lq lr ls lt lu lv lw lx ly jm bi translated">结果摘要</h2><p id="df97" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated">最后，<code class="fe ou ov ow ox b">FeatureSelector()</code>中有几个实用程序可以帮助我们总结和利用交叉验证程序的结果。</p><p id="5bbd" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">首先，方法<code class="fe ou ov ow ox b"><strong class="mb jq">create_cross_val_features_df()</strong></code>总结了每个模型在获得最佳验证分数时所使用的特性:</p><figure class="oy oz pa pb gt is"><div class="bz fp l di"><div class="pc pd l"/></div></figure><figure class="oy oz pa pb gt is gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/f6d8a342bb834c2592a0a539ecbb5b1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*tU7PWF2y8-B79RqA4mjNJQ.jpeg"/></div></figure><p id="e64e" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">我们的特性构成了这个<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>的索引，我们的估计器被表示为列。在每个特征/估计值对的交叉点，X 表示该特征是否用于达到最佳验证分数的子集中。“计数”列合计了使用某个特性的评估者的数量，而<code class="fe ou ov ow ox b"><strong class="mb jq">DataFrame</strong></code>在该列中按降序排列。</p><p id="9dbb" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">第二，方法<code class="fe ou ov ow ox b"><strong class="mb jq">create_cross_val_features_df()</strong></code>为每个模型编译最佳特征子集，并在字典中返回结果。估计量是关键，相关值是包含每个估计量的最佳特征子集的列表。</p><figure class="oy oz pa pb gt is"><div class="bz fp l di"><div class="pc pd l"/></div></figure><figure class="oy oz pa pb gt is gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/4fd6b9912e2f824398dae84c96d77f0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*viLXq9L1fUPiS93-p7Q96w.jpeg"/></div></figure><p id="6ee6" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">该字典有助于在模型训练阶段快速利用这些特征子集。</p></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="0346" class="oi lf jg bd lg oj ok ol lj om on oo lm kv op kw lq ky oq kz lu lb or lc ly os bi translated">最后</h1><p id="b42c" class="pw-post-body-paragraph lz ma jg mb b mc md kq me mf mg kt mh ln mi mj mk lr ml mm mn lv mo mp mq mr ij bi translated">mlmachine 使得执行各种各样的特征重要性估计技术变得容易，并且有助于彻底的筛选过程来为各种估计器确定最佳特征子集。</p><p id="dd7a" class="pw-post-body-paragraph lz ma jg mb b mc ms kq me mf mt kt mh ln mu mj mk lr mv mm mn lv mw mp mq mr ij bi translated">查看<a class="ae jd" href="https://github.com/petersontylerd/mlmachine" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>，并继续关注其他专栏条目。</p></div></div>    
</body>
</html>