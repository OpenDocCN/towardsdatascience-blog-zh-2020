<html>
<head>
<title>Explainable Deep Learning in Breast Cancer Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">乳腺癌预测中的可解释深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explainable-deep-learning-in-breast-cancer-prediction-ae36c638d2a4?source=collection_archive---------16-----------------------#2020-02-02">https://towardsdatascience.com/explainable-deep-learning-in-breast-cancer-prediction-ae36c638d2a4?source=collection_archive---------16-----------------------#2020-02-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4b77" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解医疗保健中的卷积神经网络预测结果</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ce447dc2cb8262d4caefd97084f4b78e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7dydKmnlxYYzQf9o6f-jVQ.jpeg"/></div></div></figure><p id="9201" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">高级机器学习模型(例如随机森林、深度学习模型等。)通常被认为是不可解释的[1][2]。如[1][2][3][4]中所述，这些模型在很大程度上仍然是黑盒，如果医生计划根据预测结果采取措施治疗疾病(如癌症)，那么理解其医疗保健预测结果背后的原因对于评估信任度非常重要。在[2]中，我使用了威斯康星州乳腺癌诊断(WBCD)表格数据集来介绍如何使用局部可解释模型不可知解释(LIME)方法来解释随机森林模型在乳腺癌诊断中的预测结果。</p><p id="8cf3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本文中，我使用 Kaggle 乳腺癌组织学图像(BCHI)数据集[5]来演示如何使用 LIME 来解释用于浸润性导管癌(IDC)乳腺癌诊断的 2D <a class="ae lq" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络(ConvNet) </a>的图像预测结果。</p><h1 id="0995" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">1.准备乳腺癌组织学图像数据集</h1><p id="de9e" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">BCHI 数据集[5]可以从<a class="ae lq" href="https://www.kaggle.com/kernels/scriptcontent/2064134/data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载。如[5]中所述，数据集由 5，547 个 50x50 像素的 H &amp; E 染色乳腺组织病理学样本的 RGB 数字图像组成。这些图像被标记为 IDC 或非 IDC。有 2，788 个 IDC 图像和 2，759 个非 IDC 图像。这些图像已经被转换成 Numpy 数组，并存储在文件<em class="mo"> X.npy </em>中。类似地，相应的标签以 Numpy 数组格式存储在文件<em class="mo"> Y.npy </em>中。</p><h2 id="1efc" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">1.1 加载数据</h2><p id="daad" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">将<em class="mo"> X.npy </em>和<em class="mo"> Y.npy </em>文件下载到本地计算机后，它们可以作为 Numpy 数组加载到内存中，如下所示:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="8386" class="mp ls it nc b gy ng nh l ni nj">X = np.load('./data/X.npy') # images<br/>Y = np.load('./data/Y.npy') # labels (0 = Non IDC, 1 = IDC)</span></pre><p id="91a1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是其中两个数据样本，左边的图像标记为 0(非 IDC)，右边的图像标记为 1 (IDC)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/77d3151b886880c468e62307519cb0c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DcT4_oxQ-kmIJKkX3f3KCA.png"/></div></div><p class="nl nm gj gh gi nn no bd b be z dk translated"><strong class="bd np">图一。两个样本:左边的标为 0(非 IDC)，右边的标为 1 (IDC)。</strong></p></figure><h2 id="71fa" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">1.2 混洗数据</h2><p id="3457" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">在原始数据集文件中，所有标记为 0(非 IDC)的数据样本都放在标记为 1 (IDC)的数据样本之前。为了避免人为的数据模式，数据集被随机打乱如下:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="cb2d" class="mp ls it nc b gy ng nh l ni nj">indices = np.arange(Y.shape[0])<br/>np.random.shuffle(indices)<br/>indices = list(indices)<br/>X = X[indices]<br/>Y = Y[indices]</span></pre><h2 id="8101" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">1.3 转换数据集</h2><p id="6f4e" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">IDC 图像中的像素值在[0，255]的范围内，而当输入数据的值在[0，1]或[-1，1]的范围内时，典型的深度学习模型工作得最好。下面的类<em class="mo"> Scale </em>是将 IDC 图像的像素值转换到[0，1]的范围内。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="d8a6" class="mp ls it nc b gy ng nh l ni nj">class Scale(BaseEstimator, TransformerMixin):<br/>    def __init__(self):<br/>        pass <br/>        <br/>    def fit(self, X, y):<br/>        return self<br/>    <br/>    def transform(self, X): <br/>        X1 = X.copy()<br/>        X1 = X1 / 255.0<br/>        return X1</span></pre><h2 id="6383" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">1.4 划分数据集用于模型训练和测试</h2><p id="df3a" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">数据集分为三部分，80%用于模型训练和验证(1，000 用于验证，其余 80%用于训练)，20%用于模型测试。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="1154" class="mp ls it nc b gy ng nh l ni nj">X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, Y, test_size=0.2)</span><span id="8e2e" class="mp ls it nc b gy nq nh l ni nj">X_train = X_train_raw.copy()<br/>X_val   = X_train[:1000]<br/>X_train = X_train[1000:]<br/>X_test  = X_test_raw.copy()</span><span id="7160" class="mp ls it nc b gy nq nh l ni nj">y_train = y_train_raw.copy()<br/>y_val   = y_train[:1000]<br/>y_train = y_train[1000:]<br/>y_test  = y_test_raw.copy()</span></pre><h1 id="39fe" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">2.训练 2D ConvNet 模型</h1><p id="a22f" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">BCHI 数据集[5]由图像组成，因此选择 2D ConvNet 模型进行 IDC 预测。</p><h2 id="a673" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">2.1 创建 2D 通信网</h2><p id="ff0d" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">与[5]类似，下面的函数<em class="mo"> getKerasCNNModel </em>()为 IDC 图像分类创建 2D ConvNet。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="f50a" class="mp ls it nc b gy ng nh l ni nj">def getKerasCNNModel():<br/>    batch_size = BATCH_SIZE<br/>    epochs = EPOCH_SIZE  <br/>    img_rows, img_cols = X_train.shape[1], X_train.shape[2]<br/>    input_shape = (img_rows, img_cols, 3) <br/>    model = Sequential()<br/>    model.add(Conv2D(16, kernel_size=(3,3), activation='relu', input_shape=input_shape))<br/>    model.add(MaxPooling2D(pool_size=(2, 2)))  <br/>    model.add(Dropout(0.25)) <br/>    model.add(Conv2D(32, (3,3),  activation='relu')) <br/>    model.add(MaxPooling2D(pool_size=(2, 2)))  <br/>    model.add(Dropout(0.25)) <br/>    model.add(Flatten())<br/>    model.add(Dense(128, activation='relu'))  <br/>    model.add(Dropout(0.5)) <br/>    model.add(Dense(1, activation='sigmoid'))<br/>    <br/>    model.compile(loss= keras.losses.binary_crossentropy, <br/>                  optimizer=keras.optimizers.rmsprop(), <br/>                  metrics=['accuracy'])<br/>    <br/>    return model</span></pre><h2 id="5e01" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">2.2 创建管道组件</h2><p id="62d9" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">类<em class="mo"> KerasCNN </em>是将 2D ConvNet 模型包装成一个 sklearn 管道组件，这样它就可以与其他数据预处理组件如<em class="mo"> Scale </em>组合成一个管道。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="7720" class="mp ls it nc b gy ng nh l ni nj">class KerasCNN(BaseEstimator, TransformerMixin):<br/>    def __init__(self, X_val=None, y_val=None):<br/>        self._model      = getKerasCNNModel()<br/>        self._batch_size = BATCH_SIZE<br/>        self._epochs     = EPOCH_SIZE<br/>        self._X_val      = X_val / 255.0<br/>        self._y_val      = y_val<br/>    <br/>    def fit(self, X, y):  <br/>        self.history = self._model.fit(X, y,<br/>                        batch_size=self._batch_size,<br/>                        verbose=1,<br/>                        epochs=self._epochs,<br/>                        validation_data=(self._X_val, self._y_val))<br/>        return self<br/>    <br/>    def transform(self, X): <br/>        return X</span><span id="ea90" class="mp ls it nc b gy nq nh l ni nj">    def predict_proba(self, X):<br/>        y_pred = self._model.predict(X) <br/>        return y_pred  <br/>    <br/>    def evaluate(self, X, y):<br/>        return self._model.evaluate(X,y)</span></pre><h1 id="583a" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">3.解释模型预测结果</h1><p id="426c" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">如前所述，我在本文中使用 LIME 来解释 ConvNet 模型预测结果。</p><h2 id="32e9" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">3.1 设置管道</h2><p id="1874" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">与[1][2]类似，我制作了一个管道来包装 ConvNet 模型，以便与 LIME API 集成。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="3b94" class="mp ls it nc b gy ng nh l ni nj">from sklearn.pipeline import Pipeline</span><span id="f45e" class="mp ls it nc b gy nq nh l ni nj">simple_cnn_pipeline = Pipeline([<br/>    ('scale', Scale()),<br/>    ('CNN', KerasCNN(X_val=X_val, y_val=y_val))<br/>    ])</span></pre><h2 id="f97d" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">3.2 训练 ConvNet 模型</h2><p id="1745" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">ConvNet 模型的训练如下，以便它可以被 LIME 调用，用于以后的模型预测。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="4799" class="mp ls it nc b gy ng nh l ni nj">simple_cnn_pipeline.fit(X_train, y_train)</span></pre><h2 id="2991" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">3.3 选择石灰解释器</h2><p id="b395" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">如[1][2]所述，LIME 方法支持不同类型的机器学习模型解释器，用于不同类型的数据集，如图像、文本、表格数据等。本文选择了 LIME image 解释器，因为数据集由图像组成。</p><p id="97b5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">2D 图像分割算法<a class="ae lq" href="https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_segmentations.html" rel="noopener ugc nofollow" target="_blank"><em class="mo">quick shift</em></a><em class="mo"/>用于生成石灰超像素(即片段)[1]。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="799c" class="mp ls it nc b gy ng nh l ni nj">from lime import lime_image<br/>from lime.wrappers.scikit_image import SegmentationAlgorithm</span><span id="03a4" class="mp ls it nc b gy nq nh l ni nj">explainer = lime_image.LimeImageExplainer() </span><span id="f6f6" class="mp ls it nc b gy nq nh l ni nj">segmenter = SegmentationAlgorithm(‘quickshift’, kernel_size=1, max_dist=200, ratio=0.2)</span></pre><h2 id="a768" class="mp ls it bd lt mq mr dn lx ms mt dp mb ld mu mv md lh mw mx mf ll my mz mh na bi translated">3.4 解释模型预测</h2><p id="36ea" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">一旦训练了 ConvNet 模型，给定一个新的 IDC 图像，就可以调用 LIME 图像解释器的<em class="mo"> explain_instance </em>()方法来生成模型预测的解释。</p><p id="6088" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">图像预测的说明由模板图像和相应的掩模图像组成。这些图像可用于以不同方式解释 ConvNet 模型预测结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/be9a0cb6522a583b2960ae61bffa31a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oK1Y23ndoEhxE9b8SB9SVQ.png"/></div></div><p class="nl nm gj gh gi nn no bd b be z dk translated"><strong class="bd np">图二。将解释上述两个样本的预测。ConvNet 模型预测左图像为负(IDC: 0)，右图像为正(IDC: 0)。</strong></p></figure><p id="a97d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">说明 1:正 IDC 的预测(IDC: 1) </strong></p><p id="5014" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">图 3 显示了用于解释通过石灰的模型预测的正 IDC 图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/4a8257ea6c7269e108e9c28f3e5d1380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*v0HjfDDOmmAuJuWwstXUQw.png"/></div><p class="nl nm gj gh gi nn no bd b be z dk translated"><strong class="bd np">图 3。IDC_1_sample:待解释的正 IDC 样本的预测</strong></p></figure><p id="80a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码是为图 3 中的图像<em class="mo"> IDC_1_sample (IDC: 1)生成模型预测的解释对象<em class="mo">explain _ 1</em>。</em></p><p id="fccd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本说明中，白色用于指示支持模型预测的图像部分(<em class="mo"> IDC: 1) </em>。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="5141" class="mp ls it nc b gy ng nh l ni nj">explanation_1 = explainer.explain_instance(IDC_1_sample, <br/>                classifier_fn = simple_cnn_pipeline.predict_proba, <br/>                top_labels=2, <br/>                hide_color=0, <br/>                num_samples=10000,<br/>                segmentation_fn=segmenter)</span></pre><p id="11f9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦得到模型预测的解释，就可以调用它的方法<em class="mo"> get_image_and_mask </em>()来得到模板图像和对应的掩膜图像(超像素):</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="0c12" class="mp ls it nc b gy ng nh l ni nj">from skimage.segmentation import mark_boundaries</span><span id="ed21" class="mp ls it nc b gy nq nh l ni nj">temp, mask = explanation_1.get_image_and_mask(explanation_1.top_labels[0], <br/>                                            positive_only=True, <br/>                                            num_features=20, <br/>                                            hide_rest=True)<br/>plt.imshow(mark_boundaries(temp, mask))</span></pre><p id="7f96" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">图 4 以灰色显示了给定 IDC 图像的隐藏部分。图像的白色部分表示给定 IDC 图像中支持正 IDC 模型预测的区域。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/51b36a47dc038f83c61d71d8f1397dd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*DwFOqSTnEq1iq_ajLdODeQ.png"/></div><p class="nl nm gj gh gi nn no bd b be z dk translated"><strong class="bd np">图 4:通过隐藏原始图像细节来解释图 3 中的正 IDC 的模型预测。白色表示支持模型预测的区域。灰色部分不支持或与模型预测无关。</strong></p></figure><p id="36bc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码以黄色显示 IDC 图像区域的边界，支持正 IDC 的模型预测(见图 5)。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="0bab" class="mp ls it nc b gy ng nh l ni nj">temp, mask = explanation_1.get_image_and_mask(explanation_1.top_labels[0], <br/>                                            positive_only=True, <br/>                                            num_features=20, <br/>                                            hide_rest=False)<br/>plt.imshow(mark_boundaries(temp, mask))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/23a19347bfaa715ec1a2d7e507564d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*gDfG1dBAC7V1WauAhUgRxw.png"/></div><p class="nl nm gj gh gi nn no bd b be z dk translated"><strong class="bd np">图 5:用原始图像细节解释图 3 中的正 IDC 的模型预测。黄色表示图 4 中支持模型预测的白色区域的边界。灰色区域要么不支持，要么与预测无关。</strong></p></figure><p id="57ea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">说明 2:非 IDC (IDC: 0)的预测</strong></p><p id="b267" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">图 6 示出了用于解释经由石灰的模型预测的非 IDC 图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/eb5d3020f71174e3beae7ba6f5dcf1d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*0SFXCW4uctuo8-2te-uhcw.png"/></div><p class="nl nm gj gh gi nn no bd b be z dk translated"><strong class="bd np">图六。IDC_0_sample:要解释的负 IDC 样本的预测</strong></p></figure><p id="be63" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码是为图 6 中的图像<em class="mo"> IDC_0_sample 生成模型预测的解释对象<em class="mo">explain _ 2</em>。</em>在本说明中，白色用于表示支持非 IDC 的模型预测的图像部分。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="e04d" class="mp ls it nc b gy ng nh l ni nj">explanation_2 = explainer.explain_instance(IDC_0_sample, <br/>                                         classifier_fn = simple_cnn_pipeline.predict_proba, <br/>                                         top_labels=2, <br/>                                         hide_color=0, <br/>                                         num_samples=10000,<br/>                                         segmentation_fn=segmenter<br/>                                        )</span></pre><p id="51d3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦获得了模型预测的解释，就可以调用其方法<em class="mo"> get_image_and_mask </em>()来获得模板图像和对应的掩膜图像(超像素):</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="2f35" class="mp ls it nc b gy ng nh l ni nj">temp, mask = explanation_2.get_image_and_mask(explanation_2.top_labels[0], <br/>                                            positive_only=True, <br/>                                            num_features=20, <br/>                                            hide_rest=True)<br/>plt.imshow(mark_boundaries(temp, mask))</span></pre><p id="b4a5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">图 7 以灰色显示了非 IDC 图像的隐藏区域。图像的白色部分表示给定非 IDC 图像中支持非 IDC 模型预测的区域。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/c99aad0423efe4d9046186796d935a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*Bd2TWtdoTA2LMCJqkox9pQ.png"/></div><p class="nl nm gj gh gi nn no bd b be z dk translated"><strong class="bd np">图 7:通过隐藏原始图像细节对图 6 的负 IDC (IDC: 0)的模型预测的解释。白色表示支持模型预测的区域。灰色部分不支持或与模型预测无关。</strong></p></figure><p id="b27c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码以黄色显示 IDC 图像区域的边界，支持非 IDC 的模型预测(参见图 8)。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="44e5" class="mp ls it nc b gy ng nh l ni nj">temp, mask = explanation_2.get_image_and_mask(explanation_2.top_labels[0], <br/>                                            positive_only=True, <br/>                                            num_features=20, <br/>                                            hide_rest=False)<br/>plt.imshow(mark_boundaries(temp, mask))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/05a7ff7f77d3ca0b32d11d754378b3c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*7u35N94oA_6CUb8uhFo3Qg.png"/></div><p class="nl nm gj gh gi nn no bd b be z dk translated"><strong class="bd np">图 8。用原始图像细节解释图 6 的非 IDC(IDC:0)的模型预测。黄色表示图 7 中支持模型预测的白色区域的边界。灰色区域要么不支持，要么与预测无关。</strong></p></figure><h1 id="45be" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">结论</h1><p id="7cde" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">在本文中，我使用 Kaggle BCHI 数据集[5]来展示如何使用石灰图像解释器[3]来解释 IDC 乳腺癌诊断中 2D <a class="ae lq" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">康文内特</a>模型的 IDC 图像预测结果。通过将超像素/特征的数量(即方法<em class="mo"> get_image_and_mask </em>())中的 num_features 参数)设置为 20，提供了对 IDC 和非 IDC 的模型预测的解释。</p><p id="8406" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我观察到解释结果对超级像素/特征的数量的选择很敏感。需要领域知识来调整该参数，以实现适当的模型预测解释。输入数据(在这种情况下是图像)的质量对于合理的结果也非常重要。增加更多的样本可以提高精确度。</p><p id="75d3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Github [6]中提供了一个 Jupyter 笔记本，其中包含了本文中使用的所有源代码。</p><h1 id="18bb" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">参考</h1><p id="eb06" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">[1] M. T. Ribeiro，S. Singh，C. Guestrin，<a class="ae lq" href="https://arxiv.org/pdf/1602.04938.pdf" rel="noopener ugc nofollow" target="_blank">“我为什么要相信你？”解释任何分类器的预测</a></p><p id="1b25" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[2] Y. Huang，<a class="ae lq" rel="noopener" target="_blank" href="/explainable-machine-learning-for-healthcare-7e408f8e5130">面向医疗保健的可解释机器学习</a></p><p id="08ac" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[3] <a class="ae lq" href="https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20Image%20Classification%20Keras.ipynb" rel="noopener ugc nofollow" target="_blank">关于图像分类的石灰教程</a></p><p id="a5fe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[4] <a class="ae lq" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">可解释的机器学习，使黑盒模型可解释的指南</a></p><p id="5b35" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[5] <a class="ae lq" href="https://www.kaggle.com/paultimothymooney/predicting-idc-in-breast-cancer-histology-images/data" rel="noopener ugc nofollow" target="_blank">预测乳腺癌组织学图像中的 IDC</a></p><p id="90dd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[6] Y .黄，<a class="ae lq" href="https://github.com/yuhuang3/machine-learning/tree/master/lime/image_explainer" rel="noopener ugc nofollow" target="_blank">朱庇特笔记本</a></p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><p id="d75e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">披露声明:2020 年。本文中表达的观点仅代表作者的观点，不代表阿贡国家实验室的观点。</p></div></div>    
</body>
</html>