<html>
<head>
<title>Optimizing genomic data processing on Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优化 Apache Spark 上的基因组数据处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6?source=collection_archive---------46-----------------------#2020-07-15">https://towardsdatascience.com/optimizing-genomics-data-processing-on-apache-spark-3333d6d41ed6?source=collection_archive---------46-----------------------#2020-07-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bd9e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">宏基因组序列数据的低记忆 k-mer 分析</h2></div><p id="d92f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di"> B </span>生物信息学产生大量数据。特别是“组学”(基因组学、转录组学、蛋白质组学……)及其相关的序列数据(如 NGS、下一代测序)可能在计算上具有挑战性。处理它会消耗大量的 CPU、内存和磁盘空间。人们可能想要运行的许多工作负载甚至经常不被考虑。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/25d54d7543b9d06ce5a8cd0d3a521739.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ya8OK0B_AOz56wTb"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated"><a class="ae md" href="https://unsplash.com/@5tep5?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">亚历山大·波波夫</a>在<a class="ae md" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="fbd6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中一个原因是，许多重要的组学工具是为在单台机器上运行而设计的，而不是为分布式(集群)处理而设计的。这是可以理解的，因为分布式处理给已经棘手的软件开发工艺增加了新的难度。然而，这导致了一种情况，有时我们需要访问具有 100 GB RAM 的机器，以便执行例如宏基因组学的分类学分类(其中我们识别 DNA 样本中存在的所有不同物种)。即使是拥有如此强大机器的人也无法回避这样一个事实，即它的内存对可运行的分析规模有着严格的限制。在一个负担得起的云计算服务和商用硬件的时代，我们应该能够做得更好。我们希望能够选择以高效的方式在集群或云中运行我们的计算。</p><h1 id="13e4" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">火花</h1><p id="38ef" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">Apache Spark 是一个强大的大数据分析框架，近年来已被广泛接受。它结合了函数式编程、MapReduce 编程模型的优点，对于那些想要它的人来说，它还结合了现代的<a class="ae md" href="https://www.scala-lang.org/" rel="noopener ugc nofollow" target="_blank"> Scala 编程语言</a>(也可以使用 Python、Java 和 R)。它处理大型分布式数据集合，并包含一个查询优化引擎，有助于充分利用硬件。它也受到主要云提供商的支持，比如 AWS 和 Google Cloud，当然你也可以在你自己的机器上运行它。鉴于所有这些好处，似乎我们应该尝试在 Spark 上运行一些繁重的组学分析。</p><p id="32b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，我们不能简单地将现有的工具(如 BLAST in Spark)包装起来，并期望它能够工作。在分布式计算中，我们必须将问题分解成相对独立的部分，以便从中获益。当我们能够以这种方式表达算法时，Spark 就可以为我们完成繁重的工作，并在集群上平稳地运行工作负载。当然，这是否可能取决于每种情况下所考虑的算法或问题。</p><h1 id="998c" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated"><em class="nb"> k </em> -mer 计数</h1><p id="c4b0" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">为了理解这个领域的基本原理，我们实现了一个用于<em class="nc">k</em>mer 计数的工具。K-mers 是长度为<em class="nc"> k </em>的 DNA 序列的短片段。因此，我们可以说三聚体、四聚体、三十一聚体等等。mer 分析形成了许多组学方法的主干，包括基因组组装、短阅读的质量控制、基因组大小估计和分类学分类。对我们来说，mer 计数似乎是这个领域中最简单的问题，解决起来很有意义，但在计算上仍然具有挑战性，一个好的基于 Spark 的解决方案应该是解决其他组学相关问题的良好基础。本质上，在给定的 DNA 序列数据集中，我们必须识别每个不同的<em class="nc"> k- </em> mer，并计算每个 mer 出现的次数。在一台机器上，传统上你可以使用一个工具，比如<a class="ae md" href="http://www.genome.umd.edu/jellyfish.html" rel="noopener ugc nofollow" target="_blank">水母</a>来解决这个问题。下面是 k=28 时的输出示例(整个表将有数十亿行)。</p><pre class="lo lp lq lr gt nd ne nf ng aw nh bi"><span id="0114" class="ni mf it ne b gy nj nk l nl nm">ATAATAATAGGAAGGCATTTTCGGACGA 1<br/>ATAATAGGAAGGCATTTTCGGACGATTA 8<br/>ATAATAGGCAGCCATGCCCGGACGGTGC 1<br/>ATAATGTAGGTTCCATATTCAGGACATC 1<br/>ATAGGAAACGCTTCTCGGACGGAAAGGT 2</span></pre><p id="2854" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你将如何以一种分散的方式计算 k 个 mers？我们不能简单地使用一个大的分布式阵列，因为潜在的 31 聚体(例如)的数量是巨大的:4。我们不能在内存或磁盘上维护那么多的计数器，而且<em class="nc"> k </em>可能比 31 大得多。这些计数器中只有一小部分会在实践中使用。有了这样稀疏的键，<em class="nc">宁滨</em>将是必不可少的。如果你知道你的算法，你就会知道<em class="nc">散列函数</em>通常被用来将数据分配到 bin 中。这就是我们如何创建数据结构，如地图和字典。在 Spark 上，这是<em class="nc">分区的基础。良好的分区是激发性能的关键之一，因为它控制着如何将工作分配给不同的工作机器。不良的分区会导致数据倾斜，在这种情况下，例如，一个工作节点可能会收到大量数据，使其不堪重负。这不仅会降低它的速度，还可能会迫使所有其他节点等待速度慢的节点完成。此外，这可能会大大增加该节点(以及所有节点)的 RAM 需求，因为我们无法控制大块数据的最终位置。这样我们又回到了起点。</em></p><p id="1cb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">打个比方，假设分布式管道实际上是一个管道系统，您的工作负载由您希望通过管道发送的球组成。如果有许多高尔夫球而只有一个保龄球，所有的管道都必须非常宽。但是如果所有的球都是高尔夫球，那么窄的管道就足够了。因此，均匀地划分数据将是有效利用资源的关键。</p><h1 id="983a" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">分担工作量</h1><p id="34a9" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">不需要太多的细节，将 k- 个 mers 散列到 bin 的公认方法是一种叫做<a class="ae md" href="https://homolog.us/blogs/bioinfo/2017/10/25/intro-minimizer/" rel="noopener ugc nofollow" target="_blank"> <em class="nc">最小化器</em> </a>的方法，这也是水母之类的工具倾向于使用的方法。(您可能想知道为什么不能简单地使用编程语言自带的标准字符串散列。主要原因是单独散列每个<em class="nc">k</em>mer 会导致输入数据的大小在计数前的中间阶段爆炸 50 倍或更多。在 Spark 中，这将导致网络上的大量缓慢移动。最小化者通过将许多相邻的 k 个聚在一起来避免这种情况，这是我们寻求保持的特性。)</p><p id="e358" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最小化机在单台机器上适用于宁滨，但可以生产尺寸相差很大的箱子。对于分布式应用程序，这并不理想，因为我们会有数据倾斜。为了解决这个问题，我们开发了一个新的哈希函数(一篇论文正在准备中)，它取代了最小化器，产生了更加均匀的分区。这可以通过给定箱总数的最大箱的大小来测量。我们的测试案例是奶牛瘤胃宏基因组数据，从<a class="ae md" href="https://www.ebi.ac.uk/ena/browser/view/PRJNA60251" rel="noopener ugc nofollow" target="_blank"> PRJNA60251 </a>运行 SRR094926。在大约 1，000，000 个箱时，我们的“最差”箱不到最小箱的 1/100，如下图所示(<em class="nc"> k </em> = 28)。<strong class="kk iu">这是非常有价值的，因为最大的 bin 大体上决定了整个应用程序的内存需求。</strong></p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi nn"><img src="../Images/94e62833de1f5354061ab47f11ad7321.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7bMt0yywBtxkDrJhqGznCw.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">最大箱大小(k-mers 数)与箱数的关系。越小越好。奶牛瘤胃宏基因组学数据(k=28)。新方法有更多的数据点，因为它有许多可能的参数组合。</p></figure><p id="fe9c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这允许我们将工作负载平滑地划分成大量的小分区，然后简单地遍历每个分区并计算那里的<em class="nc">k</em>-mer。当我们应用了这种哈希并优化了其他瓶颈时，与用于分布式<em class="nc">k</em>mer 计数的领先工具(使用最小化器)相比，我们的运行时间稍微快了一些，并且当应用于奶牛瘤胃宏基因组数据集时，内存使用率大约是竞争工具的 10%。如此低的内存使用率允许我们使用，例如，Google Cloud 上的“高 cpu”节点，它的内存更少，每小时比普通节点更便宜。这项创新节约了成本。或者，我们可以使用普通节点，但分析 10 倍以上的数据，而不会耗尽资源。因此，我们实现了一种高效、经济、可扩展的分布式计算<em class="nc"> k- </em> mers 的方法，并有望成为该领域其他有用工具的基础。</p><p id="31fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，对于<em class="nc"> k </em> =28，此时我们能够在 1.5 小时内在 4 个工作“highcpu”节点上计算 2.94x10 个⁰非重复<em class="nc">k</em>-mer(总共 7.23x10 个⁰)，这 4 个工作“high cpu”节点总共有 57.6 GB RAM 和 64 个 CPU。这相当于十亿分之 1.33 个 CPU 小时。</p><h1 id="dd96" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">结论</h1><p id="9697" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">在这一过程中，我们学到了很多经验，但我们目前的主要观点是，找到消除数据不对称的方法对 Spark 性能非常有帮助。通过这样做，我们能够提高性能并减少 90%的内存使用。根据具体情况，开发自己的散列函数或自定义分区方案可能是非常值得的。对于组学数据中的<em class="nc"> k- </em> mers，可以完全改变权衡。</p><p id="1058" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">更一般地说，当我们从在单台机器上运行算法转移到在集群上运行时，全新的问题可能会出现。为了从 Spark 获得最佳结果，有必要在这些问题出现时理解并解决它们。如果能够解决这些问题，Spark 可能是组学数据分布式(云或集群)处理的一个非常好的选择。</p><p id="79fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我要感谢 U.F. Petrillo 等人的 FastKmer(<a class="ae md" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2694-8" rel="noopener ugc nofollow" target="_blank">BMC bio informatics 2019</a>)，它为我们的 k-mer 计数实现提供了一些重要的启发和思路。</p><p id="c385" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nc">更新(2020 年 11 月):这项工作背后的代码经过进一步开发后，已经作为应用折扣的一部分发布(GitHub </em>  <em class="nc">上的</em> <a class="ae md" href="https://github.com/jtnystrom/discount" rel="noopener ugc nofollow" target="_blank"> <em class="nc">)。我上面描述的散列函数现在已经发展成为最小化者的“通用频率排序”。BioRXiv </em> </a> <em class="nc">上的</em> <a class="ae md" href="https://www.biorxiv.org/content/10.1101/2020.10.12.335364v5" rel="noopener ugc nofollow" target="_blank"> <em class="nc">是一篇相关论文，它描述了我们的最新结果，并包含了关于该主题的更多细节。</em></a></p></div></div>    
</body>
</html>