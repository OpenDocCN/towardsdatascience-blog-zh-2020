<html>
<head>
<title>Binary Classification of Disaster Tweets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">灾难微博的二元分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/binary-classification-of-disaster-tweets-73efc6744712?source=collection_archive---------39-----------------------#2020-06-28">https://towardsdatascience.com/binary-classification-of-disaster-tweets-73efc6744712?source=collection_archive---------39-----------------------#2020-06-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7fb5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">预测哪些推文是关于真实灾难的，哪些不是。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/10bd6c00e2c3ac661f0be3a46096ee52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cXFEMIkQy7dFrMG-pDx3UA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@yoshginsu?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Yosh Ginsu </a>在<a class="ae kv" href="/s/photos/disaster?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="d7c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">近年来，社交媒体因其在时空事件中的潜在用途而受到广泛关注。Twitter 是其中之一，它已经成为不同情况下的重要沟通渠道，例如在紧急情况下。智能手机使人们能够实时宣布他们看到的紧急情况。正因为如此，越来越多的机构对监控 Twitter 感兴趣(例如，救灾组织)。这项工作背后的想法是，我们可以从大量的推文中提取有用的摘要，这在灾难情况下可能是有用的。</p><p id="60d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集可以从<a class="ae kv" href="https://www.kaggle.com/c/nlp-getting-started/data" rel="noopener ugc nofollow" target="_blank">这里</a>下载。我们有 7613 条观察结果，我们正在预测一条给定的推文是否是关于一场真正的灾难。如果是，预测一个 1。如果没有，预测 0。功能及其描述如下所述。</p><p id="08c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">id</code> -每条推文的标识符</p><ul class=""><li id="401b" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated"><code class="fe ls lt lu lv b">text</code> -推文的文本</li><li id="fc98" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated"><code class="fe ls lt lu lv b">location</code>——推文发出的地点(可能是南)</li><li id="1a7d" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated"><code class="fe ls lt lu lv b">keyword</code> -推文中的特定关键词(可能是 NaN)</li><li id="c219" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated"><code class="fe ls lt lu lv b">target</code>——判断一条推文是否是关于一场真正的灾难(<code class="fe ls lt lu lv b">1</code>)的输出结果(<code class="fe ls lt lu lv b">0</code>)</li></ul><p id="a4e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是我们如何分析这类问题呢？</p><h1 id="b195" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">数据</h1><p id="9aa5" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">让我们看看数据集中包含的要素:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><pre class="kg kh ki kj gt nj lv nk nl aw nm bi"><span id="1945" class="nn ml iq lv b gy no np l nq nr">There are 7613 observations and 5 features in this dataset.</span></pre><p id="23e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如图所示，该数据集由 7613 条评论组成。在这个数据集中有五种不同的特性，但是我们只分别使用“文本”和“目标”列作为输入/输出。现在，让我们看看数据集中包含的要素:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/ea96f511f5c5e3018ddb5dd253001f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j7j1cpaY5nS_3IgJ76KVQw.png"/></div></div></figure><p id="c2fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在关键字和位置列中有许多丢失的值，但是我们不需要担心它们。为了使我们的生活更容易，我们需要清除文本特征中的噪声。我们将在下面的部分中讨论它。</p><h1 id="4611" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">数据探索</h1><p id="d25b" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">如果我们将灾难性推文的数量与非灾难性推文的数量对比如下，很明显数据集是不平衡的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/8599d0f51590cf6a9a58c547b3b05466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*nBxiLHieHhPaSmYIQM57lQ.png"/></div></figure><p id="109e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决这个问题，我们将使用分层抽样，其中数据集被划分为称为地层的同质子组，并且从每个地层中抽样正确数量的实例，以保证测试集能够代表总体。我们可以看到，训练和测试数据集都有近 41%的灾难推文。分层抽样的代码如下。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="088d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练和测试数据集不平衡。但是有几种方法可以处理不平衡的数据集，如过采样和欠采样。幸运的是，这里的许多应用算法可以为您解决这个问题。有一个名为“<strong class="ky ir"> class_weight </strong>”的超参数使用目标的值来自动调整与数据集中的类频率成反比的权重。</p><p id="78b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看熊猫的每个特征的类型。info()函数，它也可以让您对特性有一个大致的了解。了解每一列是否有任何缺失值会很有帮助，这样您将能够有效地处理它。</p><pre class="kg kh ki kj gt nj lv nk nl aw nm bi"><span id="32eb" class="nn ml iq lv b gy no np l nq nr">train.info()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/52aa483817c1d61259fb466aa412816d.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*0qiKuR2cjF0Mw1w_mvdGEw.png"/></div></figure><p id="feac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于我们只处理两列，即(“文本”和“目标”)，并且没有缺失值，因此我们不需要移除任何观察值或使用插补转换器来完成缺失值。</p><h1 id="a129" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">文本表示</h1><p id="766d" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">下面显示了几条推文。请记住，我们将使用它们来预测是否有灾难推文。究竟什么能帮助我们去掉多余的单词、数字等。不会给文本增加任何价值，例如，标签、https、数字。因此，我们将删除干扰我们的文本分析的字符数字和文本片段。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/3a8b71ff9b4f1d0cac2226d0f726301b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QGDRcwX-4IHI8wi3U-WdPQ.png"/></div></div></figure><p id="bd36" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用下面的代码，我删除了数字、非 ASCII 字符、标点符号和 https，并将所有文本改为小写。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="a3ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面，你可以看到几个干净的文本，我们将用于文本分析。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/c83e91710d2453e14b73ec8bb5ff24b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*EkoINjz_QeR0VLrHre6RTg.png"/></div></figure><p id="67fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的目标是找到输入和输出之间的关系。我使用“已清理”特征作为输入，使用“目标”作为输出。所以我的第一步是把推文转换成矢量。</p><p id="3334" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们需要将 tweets 转换为令牌计数矩阵，以便从文本内容中提取数字特征。这样，计数的稀疏表示就产生了。这是非常有益的，因为你可以想象独特的映射词到向量创建一个矩阵的巨大规模。CountVectorizer 用于此目的，它可以按如下方式导入。</p><pre class="kg kh ki kj gt nj lv nk nl aw nm bi"><span id="1bd2" class="nn ml iq lv b gy no np l nq nr"><strong class="lv ir">from</strong> <strong class="lv ir">sklearn.feature_extraction.text</strong> <strong class="lv ir">import</strong> CountVectorizer</span></pre><p id="faf8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有许多像“the”、“them”、“are”这样的词对上下文的意思没有任何影响，这些词被称为停用词。它们不提供信息，可以通过选择 step_words='english '作为 CountVectorizer 函数中的超参数来删除。</p><p id="0918" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是使用 tf-idf 表示来规范化计数矩阵。标准化频率而不是使用原始频率的主要原因是为了减少在文本中出现几次的标记的影响，并且没有出现几次的标记信息量大。例如，单词“document”在给定的语料库中出现一千次，而“awesome”出现两次。tf-idf 在这种情况下工作，就像预处理数据，将原始特征向量变成更适合机器学习算法的表示。</p><pre class="kg kh ki kj gt nj lv nk nl aw nm bi"><span id="c08a" class="nn ml iq lv b gy no np l nq nr"><strong class="lv ir">from</strong> <strong class="lv ir">sklearn.feature_extraction.text</strong> <strong class="lv ir">import</strong> TfidfTransformer</span></pre><h1 id="82be" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">管道</h1><p id="1dcc" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">我使用管道功能来完成所有步骤。顺序应用变换列表和最终估计器。因此，它开始询问 CountVectorizer 和 Tfidf。您可以拥有管道工作所需的任意数量的变压器。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="216c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我只在“cleaned”特性上应用了管道，因为目标是二进制的。</p><h1 id="236a" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">模型评估</h1><p id="6dc2" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">我使用了 20%的数据进行测试，其余的用于训练。这里涉及到很多超参数。因此，你的工作就像一个建筑师，寻找最佳的价值，以最大限度地提高准确性。一些技术是有益的，包括 Hyperopt、GridSearchCV 和 RandomizedSearchCV。在这个问题中，我随机选取了超参数。</p><p id="6aac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我使用了下面代码片段中提到的十二种不同的监督算法。曲线下面积(AUC)分数和训练时间用于比较。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="a511" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个接一个地，每个监督算法都在训练数据集上训练，然后在测试数据集上推广。最后，根据 AUC 值对结果进行排序。还显示了每种方法的培训时间。我已经用这个<a class="ae kv" href="https://www.kaggle.com/janiobachmann/bank-marketing-campaign-opening-a-term-deposit" rel="noopener ugc nofollow" target="_blank">内核</a>写下了下面的分类代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/8d3577d75dc946df1b297ea5276005e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*k2ifjaq57buJ93sXidMFVA.png"/></div></figure><p id="0af2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，线性支持向量机有一个最大的 AUC 分数，但没有最小的训练时间。由于我们没有优化超参数，您可以更改它们来平衡精度和速度。</p><h1 id="2936" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">结论</h1><p id="b451" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">SVM 没有在最快的时间内训练出来。尽管超参数没有被优化，文本清理可以减少文本数据集中的非索引词、标点符号和数字等形式的噪声。在现实世界的问题中，速度比准确性更重要。因此，随着数据量的增加，我们可能需要关注速度。深度学习也可以用于比较。一些算法也使用像 Lightgbm 这样的 GPU，所以如果你有大量的数据，你可以考虑使用这种方法。</p><p id="d39d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文使用的所有代码都可以从我的<a class="ae kv" href="https://github.com/shosseini811/Binary-Classification-of-Disaster-Tweets-TWS/blob/master/binary-classification-of-disaster-tweets.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> GitHub </strong> </a>中访问。我期待听到反馈或问题。</p></div></div>    
</body>
</html>