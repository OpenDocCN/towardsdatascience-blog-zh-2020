<html>
<head>
<title>Understand and Implement ResNet-50 with TensorFlow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解并使用TensorFlow 2.0实现ResNet-50</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691?source=collection_archive---------3-----------------------#2020-06-16">https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691?source=collection_archive---------3-----------------------#2020-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9cbe" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于深度神经网络的图像分类</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/62594031503f0c3dc4bb464a18a854de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tfCl0CS567CVJgKCGNbC1g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">京都的清晨:来源(作者)</p></figure><p id="9071" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的直觉可能表明，较深的神经网络应该能够捕捉更复杂的特征，因此与较浅的神经网络相比，它们可以用于表示更复杂的功能。应该出现的问题是——如果学习一个更好的网络就等同于越堆越多的层？这种方法有什么问题和好处？这些问题和一些非常重要的其他概念在2017年K. He等人的<a class="ae lu" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a>论文中讨论过。这种架构被称为ResNet，本文介绍了许多与深度神经网络(DNN)相关的重要概念，这些都将在本文中讨论，包括在TensorFlow 2.0中实现50层ResNet。你可以从这篇文章中学到什么—</p><ol class=""><li id="242d" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">深度神经网络的问题。</li><li id="4796" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">ResNet背后的数学直觉。</li><li id="75a6" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">剩余块和跳过连接。</li><li id="19d2" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">构造ResNet和1×1卷积的重要性。</li><li id="99c5" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">用TensorFlow实现ResNet。</li></ol><p id="ec86" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们开始吧！</p><p id="0746" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">**使用<code class="fe mj mk ml mm b">tf.data</code>的图像分类管道的更快版本在这里<a class="ae lu" rel="noopener" target="_blank" href="/time-to-choose-tensorflow-data-over-imagedatagenerator-215e594f2435">讨论</a>。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="2fc5" class="mu mv it bd mw mx my dn mz na nb dp nc lh nd ne nf ll ng nh ni lp nj nk nl nm bi translated">退化问题:</h2><p id="004a" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">ResNet最初工作的主要动机是解决深层网络中的退化问题。向足够深的神经网络添加更多层将首先看到精度饱和，然后精度下降。何等人展示了以下使用普通网络的Cifar-10数据集的训练和测试误差图</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/e03e7644e28c6da9e36a1136a2225b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5jesyboQzDqOxddUCccqpw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:在平原DNN，Cifar-10数据的分类误差随着训练(左)和测试数据(右)的层数的增加而增加。参考:[1]</p></figure><p id="90a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们可以看到的，较深网络(56层)的训练(左)和测试误差(右)高于20层网络。深度越大，历元越多，误差越大。首先，似乎随着层数的增加，参数的数量也增加，因此这是一个过拟合的问题。但其实不是，我们来理解一下。</p><p id="d8ad" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">思考这个问题的一种方式是考虑深度DNN，它可以计算手头任务所需的足够强的特征集(例如:图像分类)。如果我们在已经非常DNN的基础上再增加一层网络，这一层会有什么作用呢？<strong class="la iu">如果网络已经可以计算强特征，则该附加层不需要计算任何额外的特征，而是，仅复制已经计算的特征，即<em class="nt">执行身份映射</em>(添加层中的内核产生与先前内核完全相同的特征)</strong>。这似乎是一个非常简单的操作，但在一个深层的神经网络中，这与我们的预期相差甚远。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="88c4" class="mu mv it bd mw mx my dn mz na nb dp nc lh nd ne nf ll ng nh ni lp nj nk nl nm bi translated">ResNet背后的数学直觉:</h2><p id="095f" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">让我们考虑一个包括学习率和其他超参数的DNN架构，它可以达到一类函数<em class="nt"> F </em>。因此，对于所有的<em class="nt"> f∈ F，</em>存在参数<em class="nt"> W </em>，我们可以在针对特定数据集训练网络之后获得这些参数。如果<em class="nt"> f* </em>表示我们真正想要找到的函数(最佳可能优化的结果)，但是如果它不在<em class="nt"> F </em>内，那么我们试图找到在F内的最佳情况<em class="nt"> f1，</em>，如果我们设计一个更强大的架构G，我们应该会得到更好的结果<em class="nt"> g1 </em>，这比<em class="nt"> f1 </em>更好。但是如果f·⊈g，那么就不能保证上述假设会成立。事实上<em class="nt"> g1 </em>可能比<em class="nt"> f1 </em>更差，这是退化问题。所以要点是——<em class="nt">如果更深的神经网络函数类包含更简单和更浅的网络函数类，那么我们可以保证更深的网络将增加原始浅网络的特征发现能力。</em>一旦我们在下一节介绍残差块，这将变得更加清楚。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="0acf" class="mu mv it bd mw mx my dn mz na nb dp nc lh nd ne nf ll ng nh ni lp nj nk nl nm bi translated">剩余块:</h2><p id="f0ec" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">剩余块的想法完全基于之前解释的直觉。较简单的函数(较浅的网络)应该是复杂函数(较深的网络)的子集，以便可以解决退化问题。让我们考虑输入<em class="nt"> x </em>，并且从输入到输出的期望映射由<em class="nt"> g(x) </em>表示。我们将处理一个更简单的函数<em class="nt"> f(x) = g(x)-x </em>，而不是处理这个函数。然后，原始映射被重新转换为<em class="nt"> f(x)+x </em>。在ResNet论文中He et al. <strong class="la iu"> <em class="nt">假设优化残差f(x)比优化原g本身更容易。</em> </strong>优化残差还考虑到了这样一个事实，即我们不需要担心在非常深的网络中可怕的身份映射<em class="nt"> f(y)→ y </em>。让我们看看下面剩余部分的示意图—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/562595706c4ba758be3e7970d10f2dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gjoenc3yvXhPMRpoPn4xtA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:用于身份映射的剩余块和跳过连接。已重新创建以下引用:[3]</p></figure><p id="d529" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">残差学习公式确保当恒等式映射是最优的(即<em class="nt"> g(x) = x </em>)时，该优化将使残差函数的权重趋向于零。ResNet由许多残差块组成，其中残差学习被采用到每几个(通常2或3层)堆叠层。构建模块如图2所示，最终输出可以认为是<em class="nt"> y = f(x，W) + x </em>。这里的<em class="nt"> W的</em>是重量，这些是在训练中学会的。运算<em class="nt"> f + x </em>通过快捷方式(“跳过”2/3层)连接和元素相加来执行。这是一个最简单的块，跳过连接中不涉及任何附加参数。只有当<em class="nt"> f </em>和<em class="nt"> x </em>的尺寸相同时，元素相加才是可能的，如果不是这种情况，那么我们将输入<em class="nt"> x </em>乘以投影矩阵<em class="nt"> Ws，</em>使得<em class="nt"> f </em>和<em class="nt"> x </em>的尺寸匹配。在这种情况下，输出将从之前的等式变为<em class="nt"> y = f(x，W) + Ws * x </em>。投影矩阵中的元素也是可训练的。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="cbe8" class="mu mv it bd mw mx my dn mz na nb dp nc lh nd ne nf ll ng nh ni lp nj nk nl nm bi translated">构建ResNet和1× 1卷积:</h2><p id="7446" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">我们将按照何在原论文中所采用的方法建立一个50层的ResNet。ResNet-50采用的体系结构不同于34层体系结构。快捷连接跳过了3个街区而不是2个，下面的示意图将帮助我们澄清一些问题-</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/354fd6fbf07e2cab2fe2b28dfaef59e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*kwQcNkPe7guJy1qC0mpENA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3:左:跳过2层，ResNet-34。右图:跳过3层，包括ResNet-50中的1× 1卷积。参考:[1]</p></figure><p id="3149" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在ResNet-50中，残差块中的堆叠层将始终具有1×1、3×3和1×1卷积层。1×1卷积首先降低维度，然后在瓶颈3×3层中计算特征，然后在下一个1×1层中再次增加维度。使用1×1过滤器来减少和增加瓶颈层前后的特征图的维度，如Szegedy等人在其<a class="ae lu" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">初始论文</a>中的GoogLeNet模型所述。由于残差块内没有汇聚层，<strong class="la iu"> <em class="nt">用步长2 </em> </strong>进行1×1卷积降维。记住这几点，让我们使用TensorFlow 2.0构建ResNet-50。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="8bf7" class="mu mv it bd mw mx my dn mz na nb dp nc lh nd ne nf ll ng nh ni lp nj nk nl nm bi translated">建筑ResNet-50:</h2><p id="5cf0" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">在编码之前，让我们看看原始论文中呈现的ResNet-34架构—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/500cbfefe3eb8a7d4f97d42007c6a8de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YQgpwj-Wde7r8bFqXy2ruw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">ResNet-34(摘自K. He等人的《<a class="ae lu" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">深度剩余学习</a>》)</p></figure><p id="e6e2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nt">仅池化层放置在架构末端的最开始和密集连接之前。</em>如前所述，使用1×1卷积来改变其他地方的尺寸。对于过滤器的数量和其他参数，我遵循了<a class="ae lu" href="https://keras.io/examples/cifar10_resnet/" rel="noopener ugc nofollow" target="_blank"> Keras的例子</a>。现在是编码的时候了。首先，我们定义一个最简单的单位块，其中输入的维度不变，只有深度，下面是代码块-</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最简单的残余块，尺寸没有任何变化，只有深度。</p></figure><p id="8a9b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过使用步长为2的1×1卷积，另一个残差块将包括输入维度的变化。因此，跳过连接也将经历尺寸变化——</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">与步幅2卷积。输入变化的维度</p></figure><p id="4713" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结合这两个剩余模块，我们现在可以构建完整的50层ResNet，如下所示</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="5a1d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用64，160个时期的批量大小和数据扩充，在训练数据和测试数据上实现了85%和82%的准确度。下面是训练和验证曲线—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/abf00a542a095f753b38e79deea853a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*666YsA4J-YqB39CqzBKI5w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">示出了Cifar-10数据50层ResNet的训练和验证精度/损失。(来源:作者)</p></figure><p id="c678" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，可以绘制Cifar-10数据中所有10个类别的混淆矩阵</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/b4ce6b426ee51a8ca27dc7e0bfdf7f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LjLOEEkBx3sDfqVbISpHYg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用ResNet-50训练的用于Cifar-10数据的CM。(来源:作者)</p></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="f03f" class="mu mv it bd mw mx my dn mz na nb dp nc lh nd ne nf ll ng nh ni lp nj nk nl nm bi translated">讨论:</h2><p id="84ba" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">在这里，我们看到了一个使用TensorFlow实现ResNet-50并使用Cifar-10数据训练模型的示例。一个重要的讨论点是卷积-批处理-激活的顺序，这仍然是一个争论点。许多人认为最初的<a class="ae lu" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank">批次标准文件</a>中使用的顺序不是最好的。看GitHub的一个问题<a class="ae lu" href="https://github.com/titu1994/Wide-Residual-Networks/issues/4" rel="noopener ugc nofollow" target="_blank">这里</a>。我建议您尝试不同于笔记本中使用的参数，以了解它们的效果。</p><p id="f86a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你能从中得到的几个要点是—</p><ol class=""><li id="d42c" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">退化和过度拟合之间的区别以及为什么退化发生在非常深的网络中。</li><li id="711f" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">使用1×1卷积来增加和减少特征图的维数。</li><li id="f5d9" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">残余块如何有助于防止退化问题？</li></ol><p id="983e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">暂时就这样吧！希望这能帮到你一点，保持坚强！！</p><p id="4c63" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">页（page的缩写）如果你想使用<code class="fe mj mk ml mm b">tf.data</code>建立一个更快的图像分类管道，那么查看<a class="ae lu" rel="noopener" target="_blank" href="/time-to-choose-tensorflow-data-over-imagedatagenerator-215e594f2435">这篇文章</a>。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="39e3" class="mu mv it bd mw mx my dn mz na nb dp nc lh nd ne nf ll ng nh ni lp nj nk nl nm bi translated">参考:</h2><p id="aeaf" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">[1] <a class="ae lu" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet原创论文</a>:何等。</p><p id="72f4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[2] <a class="ae lu" href="https://keras.io/examples/cifar10_resnet/" rel="noopener ugc nofollow" target="_blank"> Keras示例实现</a>。</p><p id="3ce4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[3] Alex Smola: <a class="ae lu" href="https://www.youtube.com/watch?v=lugkZaFj4x8" rel="noopener ugc nofollow" target="_blank"> ResNet直觉讲座</a></p><p id="6864" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[4]笔记本所用代码:<a class="ae lu" href="https://github.com/suvoooo/Learn-TensorFlow/blob/master/resnet/Implement_Resnet_TensorFlow.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub Link </a>。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="ae09" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="nt">如果你对更深入的基础机器学习概念感兴趣，可以考虑加盟Medium使用</em> </strong> <a class="ae lu" href="https://saptashwa.medium.com/membership" rel="noopener"> <strong class="la iu"> <em class="nt">我的链接</em> </strong> </a> <strong class="la iu"> <em class="nt">。你不用额外付钱，但我会得到一点佣金。感谢大家！！</em>T19】</strong></p><div class="ob oc gp gr od oe"><a href="https://medium.com/@saptashwa/membership?source=publishing_settings-------------------------------------" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">通过我的推荐链接加入媒体</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">更多来自Saptashwa(以及Medium上的许多其他作者)。你的会员费直接支持Saptashwa和其他…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="oo l op oq or on os ks oe"/></div></div></a></div></div></div>    
</body>
</html>