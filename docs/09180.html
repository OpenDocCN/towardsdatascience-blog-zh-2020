<html>
<head>
<title>Train a TensorFlow Model in Amazon SageMaker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Amazon SageMaker 中训练 TensorFlow 模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-a-tensorflow-model-in-amazon-sagemaker-e2df9b036a8?source=collection_archive---------24-----------------------#2020-07-01">https://towardsdatascience.com/train-a-tensorflow-model-in-amazon-sagemaker-e2df9b036a8?source=collection_archive---------24-----------------------#2020-07-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a4c700cac08eebe0420103b8f675073f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YA5b0BZTk4TSt0W9pLVF2A.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">数据集中的交通标志示例</p></figure><h1 id="2c8d" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">介绍</h1><p id="ef20" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">Amazon SageMaker 是一个云机器学习平台，允许开发人员在云中创建、训练和部署机器学习模型。我之前用 TensorFlow 2 通过我的板载 CPU 对交通标志进行分类。今天我打算在亚马逊 SageMaker 上做。SageMaker 有几个优点:它为计算能力提供了更多的选择(并行计算的不同 CPU 和 GPU)，我可以将模型部署为端点。</p><p id="f305" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">整个分析是在 SageMaker 的笔记本上完成的，而训练和预测是通过调用更强大的 GPU 实例来完成的。为了完整起见，本文将包括从预处理到端点部署的整个流程。</p><h1 id="a980" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">探索性分析和预处理</h1><p id="18ce" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">数据集可以从 Kaggle: <a class="ae ly" href="https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign" rel="noopener ugc nofollow" target="_blank"> GTSRB —德国交通标志识别基准</a>下载。</p><p id="6e00" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">以下是数据集的概述:</p><ul class=""><li id="5b71" class="me mf iq lc b ld lz lh ma ll mg lp mh lt mi lx mj mk ml mm bi translated">每个图像的大小略有不同</li><li id="e563" class="me mf iq lc b ld mn lh mo ll mp lp mq lt mr lx mj mk ml mm bi translated">训练示例数= 39209</li><li id="1947" class="me mf iq lc b ld mn lh mo ll mp lp mq lt mr lx mj mk ml mm bi translated">测试示例数量= 12630</li><li id="e6a4" class="me mf iq lc b ld mn lh mo ll mp lp mq lt mr lx mj mk ml mm bi translated">班级数量= 43</li></ul><p id="8366" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">这些图像的大小从 20x20 到 70x70 不等，都有 3 个通道:RGB。</p><p id="be39" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">所以我要做的第一件事是将所有图像的大小调整为 32x32x3，并将它们读入 numpy 数组作为训练特征。同时，我创建了另一个 numpy 数组，其中包含每个图像的标签，这些标签来自加载图像的文件夹名称。</p><p id="4df5" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">我为一个类创建了一个调整大小和标记的函数。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="9a7a" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">对所有的类重复该过程。为了避免在笔记本断开连接的情况下再次进行预处理，我以 pickle 形式存储了数据。下次我想获得处理过的数据时，我可以简单地从 pickle 加载它们。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="9d34" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">测试数据集也是如此。现在，我可以看到训练和测试数据集中的类分布。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/e2165fdbedae233a1431d6079c7cf417.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-pvj9hk0akRGPikDZbwlDA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">训练和测试数据集的类分布</p></figure><p id="d950" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">正如我们所看到的，在训练集中，样本的最大和最小数量分别为 2200 和 210 个。相差 10 倍。大约有 60%的课程只有&lt; 1000 个例子。阶级分布不均衡。如果按原样使用，则存在一些示例数量较少的类别可能无法很好分类的风险。这将在后面的章节中详细讨论。</p><p id="2c5a" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">然后，我将训练数据分为训练集和验证集。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="f5f1" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">最后，我将数据标准化并转换成灰度。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="9ea6" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">以下是预处理后数据集的摘要。</p><ul class=""><li id="621d" class="me mf iq lc b ld lz lh ma ll mg lp mh lt mi lx mj mk ml mm bi translated">训练示例数= 31367</li><li id="9fbf" class="me mf iq lc b ld mn lh mo ll mp lp mq lt mr lx mj mk ml mm bi translated">验证示例数量= 7842</li><li id="8948" class="me mf iq lc b ld mn lh mo ll mp lp mq lt mr lx mj mk ml mm bi translated">测试示例数量= 12630</li><li id="db69" class="me mf iq lc b ld mn lh mo ll mp lp mq lt mr lx mj mk ml mm bi translated">图像数据形状= (32，32，1)</li><li id="61c2" class="me mf iq lc b ld mn lh mo ll mp lp mq lt mr lx mj mk ml mm bi translated">班级数量= 43</li></ul><h1 id="387b" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">模型构建</h1><p id="c5bb" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">我使用卷积神经网络(CNN)作为分类模型。总的来说，与传统的神经网络或其他传统的机器学习模型相比，CNN 在对大型数据集上的图像进行分类方面做得更好。</p><p id="fc22" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">最大池层用于减少前一层输出的大小，从而使训练更快。脱落层也用于减少过度拟合。</p><p id="4605" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">网络架构类似于 LeNet，每层的详细信息如下:</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h1 id="c8e1" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">培养</h1><p id="e51e" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><code class="fe mz na nb nc b">sagemaker.tensorflow.TensorFlow</code>估算器处理定位脚本模式容器、上传脚本到 S3 位置和创建 SageMaker 培训任务。</p><p id="9fff" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">为了让模型访问数据，我将它们保存为。npy 文件并上传到 s3 bucket。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="cc57" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">训练脚本是一个独立的 python 文件。在培训作业期间，SageMaker 将在指定的实例上运行这个脚本。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="8bff" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">现在，我可以定义训练作业并训练模型。我使用了一个<code class="fe mz na nb nc b">ml.p2xlarge </code>实例。10 个历元后，验证精度为 0.979。完成这项工作花费了实例 158 秒。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h1 id="e032" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">端点部署和预测</h1><p id="2afc" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">模型已部署。我再次使用了一个<code class="fe mz na nb nc b">ml.p2xlarge </code>实例。现在我们可以评估模型的性能了。一个度量是整个模型的准确性。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="1dba" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">然而，更好的方法是查看每个类的准确性。由于某些类别的示例比其他类别少 10 倍，因此预计模型会偏向那些示例较多的类别。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="bcb2" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">从下图可以看出，大部分类的准确率&gt; 90%。只有 5 个职业有 90%的准确率&lt; 80%. Going back the class distribution plot, we can see all these 5 classes have no. of examples ~ 200. It is also noted that not all classes with ~ 200 examples has a lower accuracy.</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/019b1b249d0ad247728bbfd841812a70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CDBSmzV9irWvGwYxKLF8_Q.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">Accuracy per class</p></figure><h1 id="2b32" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">Conclusion and Future Improvement</h1><p id="2cd8" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">I used the latest TensorFlow framework to train a model for traffic sign classification. The pipeline includes pre-processing, model construction, training, prediction and endpoint deployment. The validation accuracy is 0.979 and testing accuracy is 0.924. Most of the classes have accuracy &gt;而只有 5 个职业有准确率&lt; 80%. The root cause is likely to be the small training size for these classes. Future improvement for this model could include image augmentation.</p></div><div class="ab cl ne nf hu ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ij ik il im in"><p id="0ddf" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><em class="nl">你可以从</em> <a class="ae ly" href="https://github.com/JunWorks/TensorFlow-in-SageMaker" rel="noopener ugc nofollow" target="_blank"> <em class="nl">这里</em> </a> <em class="nl">访问笔记本和训练脚本。</em></p></div></div>    
</body>
</html>