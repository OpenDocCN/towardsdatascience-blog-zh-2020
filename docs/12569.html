<html>
<head>
<title>Machine Learning Basics: Support Vector Machine (SVM) Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习基础:支持向量机(SVM)分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-basics-support-vector-machine-svm-classification-205ecd28a09d?source=collection_archive---------9-----------------------#2020-08-30">https://towardsdatascience.com/machine-learning-basics-support-vector-machine-svm-classification-205ecd28a09d?source=collection_archive---------9-----------------------#2020-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1e19" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解支持向量机制，并将其应用于实时示例。</h2></div><p id="cb35" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在之前的<a class="ae le" rel="noopener" target="_blank" href="/machine-learning-basics-simple-linear-regression-bc83c01baa07">故事</a>中，我已经解释了各种<strong class="kk iu"> <em class="lf">回归</em> </strong>模型的实现程序。此外，我还描述了逻辑回归和 KNN 分类模型的实现。在本文中，我们将通过一个清晰的例子来了解 SVM 分类的算法和实现。</p><h2 id="a136" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">SVM 分类概述</h2><p id="85ac" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">支持向量机(SVM)分类类似于我在之前的<a class="ae le" rel="noopener" target="_blank" href="/machine-learning-basics-support-vector-regression-660306ac5226">故事</a>中解释过的支持向量机。在 SVM，用来分隔类的线被称为<strong class="kk iu"> <em class="lf">超平面</em> </strong>。超平面任意一侧最接近超平面的数据点称为<strong class="kk iu"> <em class="lf">支持向量</em> </strong>，用于绘制边界线。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi me"><img src="../Images/f24ef98eb98f5cc19609b03ac4306f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/0*hUAVXd1XaQSsrK-9.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated"><a class="ae le" href="https://gdcoder.com/support-vector-machine-vs-logistic-regression/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="b935" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 SVM 分类中，数据可以是线性的，也可以是非线性的。在 SVM 分类器中可以设置不同的内核。对于线性数据集，我们可以将内核设置为'<em class="lf"> linear </em>'。</p><p id="3298" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一方面，对于非线性数据集，有两个核，即'<em class="lf"> rbf </em>和'<em class="lf">多项式</em>'。在这种情况下，数据被映射到更高的维度，这使得绘制超平面更容易。之后，它被降低到较低的维度。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mq"><img src="../Images/8d0f18f71082eb4dc226fe69a2a6da41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*42-kMXV-471YCI-01pS0Ug.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">SVM 机制(信息来源——本人)</p></figure><p id="68b6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上图中，我们可以看到有两类形状，矩形和圆形。由于很难在 2D 平面中绘制 SVM 线，我们将数据点映射到更高维度(3D 平面)，然后绘制超平面。然后，用红色绘制的 SVM 分类器将它还原到原始平面。</p><p id="a03c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过这种方式，SVM 分类器可用于从给定的数据集中对数据点进行分类，确定其所属的类别。让我们用这个算法来解决一个现实世界的问题。</p><h2 id="c875" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">问题分析</h2><p id="5c1b" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在 SVM 分类模型的这个实现中，我们将使用由三列组成的社交网络广告数据集。前两列是自变量，即'<strong class="kk iu"> <em class="lf">【年龄】'</em> </strong>和'<strong class="kk iu"> <em class="lf">【估计销售额】'</em> </strong>，最后一列是因变量'<strong class="kk iu"> <em class="lf">【购买量】'</em> </strong>，以二进制格式表示个人是否购买了产品(1)或(0)。</p><p id="f319" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个问题中，我们必须为一家公司建立一个 SVM 分类模型，该模型将对特定年龄和特定工资的用户是否会购买他们的特定产品进行分类。现在让我们来看一下模型的实现。</p><h2 id="c597" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 1:导入库</h2><p id="4177" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">和往常一样，第一步总是包括导入库，即 NumPy、Pandas 和 Matplotlib。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="7fcf" class="lg lh it mw b gy na nb l nc nd">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd</span></pre><h2 id="a403" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 2:导入数据集</h2><p id="319f" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，我们将从我的 github 存储库中获取存储为<code class="fe ne nf ng mw b"><a class="ae le" href="https://github.com/mk-gurucharan/Classification/blob/master/SocialNetworkAds.csv" rel="noopener ugc nofollow" target="_blank">SocialNetworkAds.csv</a> </code>的数据集，并将其存储到变量<em class="lf"> dataset </em>中。然后我们将相应的变量赋给 X 和 y。最后，我们将看到数据集<em class="lf">的前 5 行。</em></p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="0524" class="lg lh it mw b gy na nb l nc nd">dataset = pd.read_csv('<a class="ae le" href="https://raw.githubusercontent.com/mk-gurucharan/Classification/master/SocialNetworkAds.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/mk-gurucharan/Classification/master/SocialNetworkAds.csv'</a>)</span><span id="20ad" class="lg lh it mw b gy nh nb l nc nd">X = dataset.iloc[:, [0, 1]].values<br/>y = dataset.iloc[:, 2].values</span><span id="f7c9" class="lg lh it mw b gy nh nb l nc nd">dataset.head(5)</span><span id="5fde" class="lg lh it mw b gy nh nb l nc nd">&gt;&gt;<br/>Age   EstimatedSalary   Purchased<br/>19    19000             0<br/>35    20000             0<br/>26    43000             0<br/>27    57000             0<br/>19    76000             0</span></pre><h2 id="2f4c" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 3:将数据集分为训练集和测试集</h2><p id="da31" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">该数据集中有 400 行。我们将把数据分成训练集和测试集。这里的<code class="fe ne nf ng mw b">test_size=0.25</code>表示<strong class="kk iu"><em class="lf"/></strong>数据的 25%将作为<strong class="kk iu"> <em class="lf">测试集</em> </strong>保存，剩余的 75%<strong class="kk iu"><em class="lf"/></strong>将作为<strong class="kk iu"> <em class="lf">训练集</em> </strong>用于训练。因此，测试集中大约有 100 个数据点。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="e086" class="lg lh it mw b gy na nb l nc nd">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)</span></pre><h2 id="97ff" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 4:特征缩放</h2><p id="5c56" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">这个特征缩放步骤是一个额外的步骤，当我们将 X 的值缩小到一个更小的范围时，它可以提高程序的速度。在这里，我们将<code class="fe ne nf ng mw b">X_train</code>和<code class="fe ne nf ng mw b">X_test</code>缩小到-2 到+2 的小范围。例如，工资 75000 按比例缩减为 0.16418997。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="1743" class="lg lh it mw b gy na nb l nc nd">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span></pre><h2 id="42da" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 5:在训练集上训练 SVM 分类模型</h2><p id="f561" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">一旦训练测试准备就绪，我们就可以导入 SVM 分类类并使训练集适合我们的模型。类别<code class="fe ne nf ng mw b">SVC</code>被分配给变量<code class="fe ne nf ng mw b">classifier</code>。这里用的核是“<strong class="kk iu"><em class="lf">RBF”</em></strong>核，代表径向基函数。还有其他几种核，例如线性核和高斯核，也可以实现。然后使用<code class="fe ne nf ng mw b">classifier.fit() </code>功能来训练模型。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="9a53" class="lg lh it mw b gy na nb l nc nd">from sklearn.svm import SVC<br/>classifier = SVC(kernel = 'rbf', random_state = 0)<br/>classifier.fit(X_train, y_train)</span></pre><h2 id="ea7c" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 6:预测测试集结果</h2><p id="f31b" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，<code class="fe ne nf ng mw b">classifier.predict()</code>函数用于预测测试集的值，这些值被存储到变量<code class="fe ne nf ng mw b">y_pred.</code></p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="4fb2" class="lg lh it mw b gy na nb l nc nd">y_pred = classifier.predict(X_test) <br/>y_pred</span></pre><h2 id="0d33" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 7:混淆矩阵和准确性</h2><p id="95f7" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">这是分类技术中最常用的一步。在这里，我们看到了训练模型的准确性，并绘制了混淆矩阵。</p><p id="37ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">混淆矩阵是一个表，用于显示当测试集的真实值已知时，对分类问题的正确和错误预测的数量。它的格式如下</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/74881daa5f3eb9f2b0c834afe2b00c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*aDcJceSYfH7GBxJJpzwvKA.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">来源—自己</p></figure><p id="f506" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">真实值是正确预测的次数。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="2086" class="lg lh it mw b gy na nb l nc nd">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix(y_test, y_pred)</span><span id="91d7" class="lg lh it mw b gy nh nb l nc nd">from sklearn.metrics import accuracy_score <br/>print ("Accuracy : ", accuracy_score(y_test, y_pred))<br/>cm</span><span id="10bc" class="lg lh it mw b gy nh nb l nc nd">&gt;&gt;Accuracy :  0.9</span><span id="d988" class="lg lh it mw b gy nh nb l nc nd">&gt;&gt;array([[59,  6],<br/>       [ 4, 31]])</span></pre><p id="c917" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上面的混淆矩阵中，我们推断，在 100 个测试集数据中，90 个被正确分类，10 个被错误分类，留给我们 90%的准确率。</p><h2 id="28d3" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 8:将实际值与预测值进行比较</h2><p id="9813" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这个步骤中，创建一个 Pandas DataFrame 来比较原始测试集(<strong class="kk iu"> <em class="lf"> y_test </em> </strong>)和预测结果(<strong class="kk iu"> <em class="lf"> y_pred </em> </strong>)的分类值。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="39c0" class="lg lh it mw b gy na nb l nc nd">df = pd.DataFrame({'Real Values':y_test, 'Predicted Values':y_pred})<br/>df</span><span id="1e61" class="lg lh it mw b gy nh nb l nc nd">&gt;&gt; <br/>Real Values   Predicted Values<br/>1             1<br/>0             0<br/>0             0<br/>1             1<br/>0             0<br/>... ...  ... ...<br/>1             1<br/>1             1<br/>0             0<br/>0             0<br/>1             1</span></pre><p id="e10f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个步骤是一个额外的步骤，它不像混淆矩阵那样提供很多信息，并且主要用于回归以检查预测值的准确性。</p><h2 id="eadd" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 9:可视化结果</h2><p id="90a1" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在最后一步中，我们将 SVM 分类模型的结果可视化在一个沿着两个区域绘制的图上。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="afc7" class="lg lh it mw b gy na nb l nc nd">from matplotlib.colors import ListedColormap<br/>X_set, y_set = X_test, y_test<br/>X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),<br/>                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))<br/>plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),<br/>             alpha = 0.75, cmap = ListedColormap(('red', 'green')))<br/>plt.xlim(X1.min(), X1.max())<br/>plt.ylim(X2.min(), X2.max())<br/>for i, j in enumerate(np.unique(y_set)):<br/>    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],<br/>                c = ListedColormap(('red', 'green'))(i), label = j)<br/>plt.title('SVM Classification')<br/>plt.xlabel('Age')<br/>plt.ylabel('EstimatedSalary')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/7251dedf79af3f219a8b1fe54f136e4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*dCsbR1i_q1mCdDj95yR9RQ.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">SVM 分类</p></figure><p id="6cde" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个图中，有两个区域。<strong class="kk iu"> <em class="lf">红色</em> </strong>区域表示<strong class="kk iu"> <em class="lf"> 0 </em> </strong>，由未购买该产品的人组成，<strong class="kk iu"> <em class="lf">绿色</em> </strong>区域表示<strong class="kk iu"> <em class="lf"> 1 </em> </strong>，由已购买该产品的人组成。由于我们选择了非线性核(rbf ),我们得到的区域没有被线性线分开。</p><p id="b341" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您仔细观察，我们可以看到测试集中的 10 个错误分类的数据点，它们在特定区域的颜色有所不同。</p><h2 id="a785" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">结论—</h2><p id="0caa" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">因此，在这个故事中，我们已经成功地建立了一个<strong class="kk iu"> <em class="lf"> SVM 分类</em> </strong>模型，它能够根据一个人的年龄和工资来预测他是否会购买一件产品。请随意尝试网上其他各种常见的分类数据集。</p><p id="e41a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我还附上了我的 github 资源库的链接，你可以在那里下载这个 Google Colab 笔记本和数据文件供你参考。</p><div class="nk nl gp gr nm nn"><a href="https://github.com/mk-gurucharan/Classification" rel="noopener  ugc nofollow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">MK-guru charan/分类</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">这是一个由 Python 代码组成的知识库，用于构建不同类型的分类模型，以评估和…</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">github.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob mk nn"/></div></div></a></div><p id="80c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还可以在下面找到该程序对其他分类模型的解释:</p><ul class=""><li id="76f8" class="oc od it kk b kl km ko kp kr oe kv of kz og ld oh oi oj ok bi translated"><a class="ae le" rel="noopener" target="_blank" href="/machine-learning-basics-logistic-regression-890ef5e3a272">逻辑回归</a></li><li id="fe62" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated"><a class="ae le" rel="noopener" target="_blank" href="/machine-learning-basics-k-nearest-neighbors-classification-6c1e0b209542">K-最近邻(KNN)分类</a></li><li id="ee02" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated">支持向量机(SVM)分类</li><li id="ecf2" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated">朴素贝叶斯分类(即将推出)</li><li id="1a1d" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated">随机森林分类(即将推出)</li></ul><p id="6940" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在接下来的文章中，我们将会遇到更复杂的回归、分类和聚类模型。到那时，快乐的机器学习！</p></div></div>    
</body>
</html>