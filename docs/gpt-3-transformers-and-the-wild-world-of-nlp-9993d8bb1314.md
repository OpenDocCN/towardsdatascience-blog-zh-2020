# GPT 3ï¼Œå˜å½¢é‡‘åˆšå’Œè‡ªç„¶è¯­è¨€å¤„ç†çš„é‡Žç”Ÿä¸–ç•Œ

> åŽŸæ–‡ï¼š<https://towardsdatascience.com/gpt-3-transformers-and-the-wild-world-of-nlp-9993d8bb1314?source=collection_archive---------14----------------------->

![](img/506b5a200894a40eff19ff42e1c1c2b8.png)

å…°äº­é›†åº Image from: [https://zh.wikipedia.org/wiki/%E8%98%AD%E4%BA%AD%E9%9B%86%E5%BA%8F](https://zh.wikipedia.org/wiki/%E8%98%AD%E4%BA%AD%E9%9B%86%E5%BA%8F)

# ä»‹ç»

ç§‘æŠ€ä¸–ç•Œå……æ»¡äº†è¿·äººçš„æ¶é­”ã€‚æ—¶ä¸æ—¶åœ°ï¼Œæˆ‘ä»¬ä¼šå¯¹ä¸€ä¸ªæ–°çš„å‘å±•æ„Ÿåˆ°æ•¬ç•ï¼Œè€Œä¸æ˜¯æ²¡æœ‰ä¸€ä¸ææƒ§ã€‚OpenAI æœ€è¿‘å¼€å‘çš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)æ¨¡åž‹ GPT-3 æ­£æ˜¯è¿™æ ·ä¸€ç§ç”Ÿç‰©ã€‚ã€Šå«æŠ¥ã€‹å‘è¡¨äº†ä¸€æ•´ç¯‡ç”± GPT 3 å·ç”Ÿæˆçš„æ–‡ç« ã€‚è™½ç„¶æ²¡æœ‰çœŸæ­£è¾¾åˆ°ã€Šå«æŠ¥ã€‹çš„æ ‡å‡†ï¼Œä½†è¿™ç¯‡æ–‡ç« ä»¤äººä¿¡æœåœ°è¿žè´¯èµ·æ¥ï¼Œè€Œä¸”å¯èƒ½å¾ˆåƒäººç±»ã€‚æƒè¡¡æ½œåœ¨çš„å½±å“ï¼ŒOpenAI å†³å®šåªå‘å°‘æ•°é€‰å®šçš„åˆä½œä¼™ä¼´å¼€æ”¾ API è®¿é—®ã€‚ä¸€ä¸ªå¯ä»¥ç†è§£çš„é€‰æ‹©ï¼Œæœ‰äººå¯èƒ½ä¼šè¯´:æˆ‘ä»¬è¿˜ä¸æƒ³é‡Šæ”¾æ¶é­”ã€‚

GPT-3 ç¡®å®žæ˜¯æ·±åº¦å­¦ä¹  NLP æ¨¡åž‹å®¶æ—ä¸­æœ€æ–°ä¹Ÿå¯ä»¥è¯´æ˜¯æœ€å¼ºå¤§çš„æˆå‘˜ï¼ŒåŒ…æ‹¬ä½œä¸ºå…¶è¶…çº§æ˜Žæ˜Ÿçš„**å˜å½¢é‡‘åˆš** (2017)ã€**ä¼¯ç‰¹** (2018)ã€ **GPT ç³»åˆ—** (2018ã€2019ã€2020)å’Œ **T5** (2019)ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶å›¢ä½“æå‡ºäº†è®¸å¤šå˜åŒ–å’Œæ”¹è¿›ï¼Œåœ¨è®¸å¤š NLP åŸºå‡†ä»»åŠ¡ä¸ŠæŽ¥è¿‘ç”šè‡³è¶…è¿‡äº†äººç±»çš„è¡¨çŽ°ã€‚

ä¸Žæ­¤åŒæ—¶ï¼Œ**Huggingface.co**å’Œ**è‰¾ä¼¦äººå·¥æ™ºèƒ½ç ”ç©¶æ‰€**å·²ç»åšäº†ä¸€é¡¹ä¼Ÿå¤§çš„å·¥ä½œï¼Œå°†ä¸åŒçš„æ¨¡åž‹æ‰“åŒ…åœ¨ä¸€èµ·ï¼Œé™ä½Žäº†å®žé™…åº”ç”¨çš„é—¨æ§›ã€‚çªç„¶ï¼Œæ„Ÿè§‰æ‰€æœ‰æœ€é…·çš„åŽ¨æˆ¿å°å·¥å…·(ç›®å‰é™¤äº† GPT-3)éƒ½åœ¨ç­‰ç€ä½ è°ƒåˆ¶æœ€ç¾Žå‘³çš„é£Ÿç‰©ã€‚è‡ªç„¶é—®é¢˜æ¥äº†ï¼Œç”¨ä»€ä¹ˆï¼Œç…®ä»€ä¹ˆï¼Ÿ

ä½œä¸ºä¸€ä¸ª NLP å’Œæ·±åº¦å­¦ä¹ çˆ±å¥½è€…ï¼Œæˆ‘ä¸€ç›´åœ¨åšæˆ‘çš„å°ç ”ç©¶ã€‚æˆ‘è®¤ä¸ºï¼Œå†™ä¸€ç¯‡å°æ–‡ç« æ¥å›žé¡¾ä¸åŒçš„å˜å½¢é‡‘åˆš(åˆååŽ¨æˆ¿å°å·¥å…·)ä¼šå¾ˆæœ‰è¶£ï¼Œæ ¹æ®å®ƒä»¬çš„ç‰¹ç‚¹å°†å®ƒä»¬ä¸Žè¶‹åŠ¿ç”¨ä¾‹(åˆåé£Ÿè°±)ç›¸åŒ¹é…ã€‚ä¸ºäº†å¢žåŠ ä¸€ç‚¹å’¨è¯¢çš„æ°›å›´ï¼Œæˆ‘å°†ä»Žä¸€ä¸ªç®€å•çš„æ¡†æž¶å¼€å§‹ï¼Œå¸®åŠ©æˆ‘ä»¬è¿›è¡ŒæŽ¨ç†ã€‚ä½†æ˜¯å¦‚æžœä½ å·²ç»äº†è§£è¿™ä¸ªé¢†åŸŸï¼Œå¹¶ä¸”ç»å¯¹è®¨åŽŒæ¡†æž¶ï¼Œå¯ä»¥ç›´æŽ¥è¿›å…¥**æŠ€æœ¯éƒ¨åˆ†**(ç¬¬ 2 éƒ¨åˆ†)ã€‚å¦‚æžœä½ åªæ˜¯æƒ³è¦ä¸€ä¸ªè¦ç‚¹æ‘˜è¦ï¼Œæˆ–è€…å¥½å¥‡â€œæœºå™¨â€èƒ½å†™å¾—å¤šå¥½ï¼Œè¯·å¾€ä¸‹çœ‹**æœ€åŽçš„è¯**(ç¬¬ 3 éƒ¨åˆ†)ã€‚

*ã€å’Œå¾€å¸¸ä¸€æ ·ï¼Œæ‰€æœ‰å¹»ç¯ç‰‡éƒ½å¯ä»¥ç›´æŽ¥æ‰¾åˆ°* [***è¿™é‡Œ***](https://docs.google.com/presentation/d/e/2PACX-1vRzCqfKCppd00Mgaj_lQoqZqzJHlk14TJ67xjKYnj5xOpzpHtF1gDZA9uEmvbvMjoBVV8TnQjOInwOC/pub?start=false&loop=false&delayms=3000)

# *ç¬¬ä¸€éƒ¨åˆ†ã€‚NLP ç”¨ä¾‹çš„ç®€å•æ¡†æž¶*

*NLP çš„ç›®æ ‡æ˜¯æž„å»ºç³»ç»Ÿ(æœºå™¨ã€ç®—æ³•)æ¥ç†è§£è¯­è¨€å¹¶æ‰§è¡Œä¸Žè¯­è¨€ç›¸å…³çš„ä»»åŠ¡ã€‚ç”±äºŽè¯­è¨€åœ¨æˆ‘ä»¬çš„ç¤¾ä¼šä¸­èµ·ç€å¦‚æ­¤é‡è¦çš„ä½œç”¨ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨é¢†åŸŸä¼¼ä¹Žæ˜¯æ— é™çš„ã€‚ä»Žç½‘ä¸Šè´­ç‰©åˆ°æŠ¥ç¨Žï¼Œæˆ‘ä»¬ä¸æ–­åœ°é˜…è¯»æ–‡æœ¬å¹¶é‡‡å–åŽç»­è¡ŒåŠ¨ã€‚ä¸€ä¸ªå®Œç¾Žçš„ NLP æœºå™¨äººï¼Œè®©æˆ‘ä»¬ç§°ä»–ä¸ºå†…ç‰¹ï¼Œå°†èƒ½å¤Ÿåƒäººç±»ä¸€æ ·ç†è§£å’Œé‡‡å–è¡ŒåŠ¨ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œå†…ç‰¹éœ€è¦å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ã€‚*

*   ***æ„ŸçŸ¥**:è¿™æ˜¯å†…ç‰¹çš„è€³æœµå’Œçœ¼ç›ã€‚å®ƒæ•æ‰çŽ°å®žä¸–ç•Œä¸­çš„å£°éŸ³æˆ–å›¾åƒï¼Œå¹¶å°†å®ƒä»¬è½¬æ¢æˆè®¡ç®—æœºçš„è¾“å…¥ä¿¡å·(æ–‡æœ¬)ã€‚è¯­éŸ³è¯†åˆ«å’Œå…‰å­¦å­—ç¬¦è¯†åˆ«(OCR)æ–¹æ³•é€šå¸¸ç”¨äºŽè¿™ä¸€éƒ¨åˆ†ã€‚*
*   ***ç†è§£**:è¿™æ˜¯å†…ç‰¹çš„å¤§è„‘ã€‚è¿™ä¸ªç»„ä»¶è´Ÿè´£æå–ä¿¡æ¯ï¼Œå½¢æˆçŸ¥è¯†ã€‚ä»Žå•è¯åµŒå…¥ã€LSTM åˆ°å˜å½¢é‡‘åˆšï¼Œæ·±åº¦å­¦ä¹ æŠ€æœ¯è¿‘å¹´æ¥å¾—åˆ°äº†å‘å±•ï¼Œä»¥å®žçŽ°æ›´é«˜æ°´å¹³çš„ç†è§£ã€‚*
*   ***æ‰§è¡Œ**:è¿™æ˜¯å†…ç‰¹æ ¹æ®è‡ªå·±çš„ç†è§£é‡‡å–è¡ŒåŠ¨å’Œæ²Ÿé€šçš„æ–¹å¼ã€‚æ‰§è¡Œè¿‡ç¨‹å¯ä»¥åƒåšäºŒå…ƒé€‰æ‹©ä¸€æ ·ç®€å•ï¼Œä¹Ÿå¯ä»¥åƒå†™è®ºæ–‡ä¸€æ ·å¤æ‚ã€‚*

*ç”±äºŽè¿™ä¸ªæ¦‚å¿µä¸Ž transformer ç³»åˆ—æ— å…³ï¼Œæˆ‘ä»¬å°†åªè®¨è®ºç†è§£å’Œæ‰§è¡Œç»„ä»¶ã€‚*

## ***1.1 äºŒç»´ç”¨ä¾‹åŠä»»åŠ¡***

*ç†è§£å’Œæ‰§è¡Œçš„å¤æ‚æ€§å°†æž„æˆæˆ‘ä»¬æ¡†æž¶çš„ä¸¤ä¸ªç»´åº¦ã€‚æ­¤å¤–ï¼Œå•è¯ã€å¥å­å’Œæ–‡æ¡£å°†åœ¨ä¸¤ä¸ªç»´åº¦ä¸Šä»£è¡¨å¤æ‚æ€§é€’å¢žçš„ 3 ä¸ªçº§åˆ«ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨äºŒç»´æ•£ç‚¹å›¾ä¸Šå®‰æŽ’ä¸€äº› NLP ç”¨ä¾‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚è‡ªç„¶ï¼Œä½äºŽå³ä¸Šè§’çš„ä»»åŠ¡æ˜¯æœ€éš¾å¤„ç†çš„ï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ·±åº¦å­¦ä¹ çš„é­”æ³•ã€‚*

*![](img/d8e804ea5ae3bcb285b1884ca2684761.png)*

*å¦‚æžœä½ è®¨åŽŒæ¨¡ç³Šçš„å›¾ç‰‡ï¼Œç‚¹å‡» [***è¿™é‡Œ***](https://docs.google.com/presentation/d/e/2PACX-1vRzCqfKCppd00Mgaj_lQoqZqzJHlk14TJ67xjKYnj5xOpzpHtF1gDZA9uEmvbvMjoBVV8TnQjOInwOC/pub?start=false&loop=false&delayms=3000)**å¯»æ‰¾åŽŸå§‹å¹»ç¯ç‰‡ã€‚***

**åœ¨å­¦æœ¯ç•Œï¼Œä¸Žâ€œç”¨ä¾‹â€æœ€æŽ¥è¿‘çš„è¯æ˜¯â€œä»»åŠ¡â€ã€‚ç»å…¸çš„è¯­è¨€ä»»åŠ¡åŒ…æ‹¬æƒ…æ„Ÿåˆ†æžã€è¯æ€§æ ‡æ³¨(POS)ã€è‡ªç„¶è¯­è¨€æŽ¨ç†(NLI)ã€æ–‡æœ¬è•´æ¶µè¯†åˆ«(RTE)ã€é—®ç­”ç­‰ã€‚æ¯ä¸ªä»»åŠ¡éƒ½æœ‰è‡ªå·±çš„ç›®æ ‡ã€åŸºå‡†æ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡( **PapersWithCode** æœ‰ä¸€ä¸ªå¾ˆå¥½çš„æ€»ç»“[è¿™é‡Œ](https://paperswithcode.com/area/natural-language-processing))ã€‚ä»»åŠ¡æœ‰æ—¶è¢«é›†ä¸­åœ¨ä¸€èµ·ï¼Œä»¥ç»™å‡ºæ¨¡åž‹çš„ä¸€èˆ¬è¯„ä¼°ã€‚ [GLUE](https://gluebenchmark.com) ã€ [BLEU](http://nlpprogress.com/english/machine_translation.html) ã€ [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) å’Œ [RACE](http://www.qizhexie.com/data/RACE_leaderboard.html) éƒ½æ˜¯æœ€å—æ¬¢è¿Žçš„ï¼Œæ–°è½¦åž‹å¾€å¾€ä»¥æ‰“ç ´è¿™æ ·æˆ–é‚£æ ·çš„æµ‹è¯•è®°å½•è€Œè‡ªè±ªã€‚**

**ä¸ºäº†ç»™ä½ çš„ç”¨ä¾‹æ‰¾åˆ°ä¸€ä¸ªå¥½çš„æ¨¡åž‹ï¼Œæ£€æŸ¥æ¨¡åž‹åœ¨æœ€èƒ½åæ˜ ä½ çš„ç”¨ä¾‹éœ€æ±‚çš„ä»»åŠ¡(æˆ–è€…æ ‡å‡†åŒ–æµ‹è¯•)ä¸Šçš„è¡¨çŽ°æ˜¯å¾ˆæœ‰å¸®åŠ©çš„ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬çš„äºŒç»´æ•£ç‚¹å›¾å¯èƒ½ä¼šå†æ¬¡æœ‰æ‰€å¸®åŠ©ã€‚**

**![](img/017d6375a99159ed08955135b536e460.png)**

**å¦‚æžœä½ è®¨åŽŒæ¨¡ç³Šçš„å›¾ç‰‡ï¼Œç‚¹å‡» [***è¿™é‡Œ***](https://docs.google.com/presentation/d/e/2PACX-1vRzCqfKCppd00Mgaj_lQoqZqzJHlk14TJ67xjKYnj5xOpzpHtF1gDZA9uEmvbvMjoBVV8TnQjOInwOC/pub?start=false&loop=false&delayms=3000)**å¯»æ‰¾åŽŸå§‹å¹»ç¯ç‰‡ã€‚****

## *****1.2 æ·»åŠ çº¦æŸ*****

***é™¤äº†ç®€å•çš„ 2D æ¡†æž¶ï¼Œæˆ‘ä»¬ä¸åº”è¯¥å¿˜è®°çŽ°å®žä¸–ç•Œçš„çº¦æŸã€‚ä»–ä»¬è¿«ä½¿æˆ‘ä»¬é€šè¿‡æŽ’é™¤æ³•æ¥ç¼©å°å°å·¥å…·çš„é€‰æ‹©èŒƒå›´ã€‚ä¸€äº›æœ€å¸¸è§çš„æ˜¯:***

*   *****å»¶è¿Ÿ**:ç³»ç»Ÿéœ€è¦å¯¹æœ€ç»ˆç”¨æˆ·åšå‡ºå¿«é€Ÿååº”å—ï¼Ÿå¦‚æžœæ˜¯è¿™æ ·çš„è¯ï¼Œä½ å°±å¤„äºŽä½Žå»¶è¿ŸçŠ¶æ€ï¼Œè¿™éœ€è¦ä¸€ä¸ªå¿«é€Ÿçš„æ¨¡åž‹ï¼Œå¹¶ä¸”å¾ˆå¯èƒ½ä¼šæŽ’é™¤ transformer å®¶æ—ä¸­çš„ä¸€äº›çŸ®èƒ–çš„å®¶ä¼™ã€‚***
*   ***è®¡ç®—èƒ½åŠ›:è®¡ç®—èƒ½åŠ›çš„é—®é¢˜æœ‰æ—¶æ˜¯é¢„ç®—é—®é¢˜ï¼Œæœ‰æ—¶æ˜¯è®¾è®¡é€‰æ‹©ã€‚ä½†æ— è®ºå¦‚ä½•ï¼Œåœ¨ iPhone å’Œäº‘ TPU ä¸Šè¿è¡Œç›¸åŒçš„æ¨¡åž‹å¯èƒ½ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚***
*   *****å‡†ç¡®æ€§**:å¦‚æžœæœŸæœ›æ¨¡åž‹è¿›è¡ŒåŒ»ç–—è¯Šæ–­ï¼Œæˆ‘ä»¬åº”è¯¥å¯¹è¯¯å·®æœ‰æžä½Žçš„å®¹å¿åº¦ï¼Œå¹¶ä¸”åº”è¯¥æ€»æ˜¯ä¼˜å…ˆé€‰æ‹©æ›´é«˜æ€§èƒ½çš„æ¨¡åž‹ã€‚å¦ä¸€æ–¹é¢ï¼Œå¯¹äºŽæ–°é—»æŽ¨èè€…æ¥è¯´ï¼Œ90%å’Œ 92%çš„å‡†ç¡®çŽ‡ä¹‹é—´çš„å·®å¼‚å¯èƒ½æ ¹æœ¬ä¸æ˜¯é—®é¢˜ã€‚***

## *****1.3 å¥¥å¡å§†å‰ƒåˆ€*****

***è¿™ä¸€éƒ¨åˆ†å®žé™…ä¸Šæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„å…è´£å£°æ˜Žã€‚å°½ç®¡å®ƒä»¬å¯èƒ½å¾ˆå¥‡ç‰¹ï¼Œä½†æ·±åº¦å­¦ä¹ æ¨¡åž‹é€šå¸¸ä¸æ˜¯æ­£ç¡®çš„è§£å†³æ–¹æ¡ˆã€‚transformer ç³»åˆ—éžå¸¸é€‚åˆå¥å­å’Œæ–‡æ¡£çº§åˆ«çš„ç†è§£ã€‚æ‰€ä»¥ï¼Œå¦‚æžœä½ çš„ç”¨ä¾‹åªéœ€è¦å•è¯çº§åˆ«çš„ç†è§£å’Œæ‰§è¡Œï¼Œä½ å¯èƒ½ä¸éœ€è¦å˜å½¢é‡‘åˆšè¿™ç§ç¬¨é‡çš„æœºå™¨ã€‚***

***äº‹å®žä¸Šï¼Œå¯¹äºŽè®¸å¤š NLP ç”¨ä¾‹æ¥è¯´ï¼Œåƒ TF-IDF è¿™æ ·çš„è€æ´¾ç‰¹å¾å·¥ç¨‹æŠ€æœ¯ç»“åˆéšæœºæ£®æž—å¯èƒ½å·²ç»è¶³å¤Ÿå¥½äº†ã€‚è™½ç„¶æ–°æŠ€æœ¯å¯èƒ½ä¼šå¸¦æ¥ç²¾ç¡®åº¦çš„å·¨å¤§æé«˜ï¼Œä½†å®žé™…ä»·å€¼å½±å“å¯èƒ½ä¸å€¼å¾—åŠªåŠ›æ”¹è¿›ç³»ç»Ÿè®¾è®¡æˆ–æ‰©å¤§è®¡ç®—èƒ½åŠ›ã€‚å¯¹æˆ‘æ¥è¯´ï¼ŒçŽ°å®žç”Ÿæ´»ä¸­ä¸€ä¸ªä¼Ÿå¤§çš„è§£å†³æ–¹æ¡ˆåº”è¯¥æ°¸è¿œæ˜¯æœ€ç®€å•çš„ï¼Œæ»¡è¶³æ‰€æœ‰è¦æ±‚çš„æ–¹æ¡ˆã€‚***

***å¥½äº†ï¼Œè®°ä½è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬ä»”ç»†çœ‹çœ‹å˜å½¢é‡‘åˆšç³»åˆ—ã€‚***

# ***ç¬¬äºŒéƒ¨åˆ†ã€‚å¤§èƒ†å°è¯•æ›´æŠ€æœ¯æ€§çš„ä¸œè¥¿***

***ä¸ºäº†ä¿æŒè¿™ç¯‡æ–‡ç« çš„åˆç†é•¿åº¦ï¼Œæˆ‘ä»¬å°†æŠŠæˆ‘ä»¬çš„è®¨è®ºé™åˆ¶åœ¨ Huggingface.co çš„åŒ… **transformer** ä¸­æä¾›çš„æ¨¡åž‹ã€‚Huggingface.co ä¸ä»…æä¾›äº†è¶…è¿‡ [20 ä¸ªæž¶æž„](https://huggingface.co/transformers/model_summary.html)çš„æºä»£ç ï¼Œè¿˜æä¾›äº† 90 ä¸ª[é¢„è®­ç»ƒæ¨¡åž‹](https://huggingface.co/transformers/pretrained_models.html)ï¼Œè¿˜ä¸åŒ…æ‹¬ç¤¾åŒºè´¡çŒ®ã€‚ä»–ä»¬è¿˜ç®€åŒ–äº†ç•Œé¢ï¼Œè¿™æ ·ä½ å°±å¯ä»¥ç”¨å‡ è¡Œä»£ç æµ‹è¯• GPT-2ï¼Œæˆ–è€…ç”¨ä¸€ä¸ªç®€çŸ­çš„è„šæœ¬å¾®è°ƒ T5ã€‚è½¯ä»¶åŒ…çš„ç¨³å®šæ€§è¿˜æœ‰å¾…å…¨é¢æµ‹è¯•ï¼Œä½†å®ƒä»¬æ— ç–‘ä¸ºä½¿ç”¨ä¸åŒçš„ NLP æ¨¡åž‹å’Œè¯•éªŒæ‚¨è‡ªå·±çš„æƒ³æ³•æä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚(æœ¬æ–‡ä¸æ˜¯ Huggingface.co èµžåŠ©çš„ï¼Œè™½ç„¶æˆ‘ä¸ä¼šä»‹æ„â€¦â€¦)***

## ***2.1 å…±åŒä¸»é¢˜***

***æ·±åº¦å­¦ä¹ æŠ€æœ¯å·²ç»ç”¨äºŽ NLP æœ‰ä¸€æ®µæ—¶é—´äº†ï¼Œä½†ç›´åˆ° transformer çš„è¯žç”Ÿï¼Œæˆ‘ä»¬æ‰çœ‹åˆ°äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚Jay Alammar å·²ç»å†™äº†ä¸€ç³»åˆ—ç²¾å½©çš„æ–‡ç« æ¥è¯´æ˜Žè¿™äº›æ¨¡åž‹æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚æŠ›å¼€æŠ€æœ¯ç»†èŠ‚ï¼Œæˆ‘ä»¬å¯ä»¥æ³¨æ„åˆ°ä¸€äº›å¯èƒ½å¯¼è‡´ä»–ä»¬æˆåŠŸæ•…äº‹çš„å…±åŒå› ç´ :***

*   *****æ³¨æ„åŠ›å¤´**:æ³¨æ„åŠ›å¤´æ˜¯ transformer ç³»åˆ—çš„å®šä¹‰ç‰¹å¾ä¹‹ä¸€ï¼Œè‡ªç¬¬ä¸€ç¯‡ Transformer è®ºæ–‡(Vasvani 2017)é¦–æ¬¡æå‡ºä»¥æ¥ä¸€ç›´è¢«ä½¿ç”¨ã€‚å®ƒæä¾›äº†ä¸€ç§é«˜åº¦çµæ´»çš„æ–¹æ³•æ¥åˆå¹¶ä¸Šä¸‹æ–‡ä¿¡æ¯(å³ï¼Œå•è¯/ä»¤ç‰Œå¦‚ä½•ä¸Žå¥å­æˆ–æ–‡æ¡£ä¸­çš„å…¶ä»–å•è¯ç›¸é“¾æŽ¥)ï¼Œå–ä»£äº† RNN å’Œ LSTM ç­‰é€’å½’è§£å†³æ–¹æ¡ˆã€‚***
*   *****è¿ç§»å­¦ä¹ **:é™¤äº†ç¿»è¯‘ï¼Œé’ˆå¯¹ç‰¹å®šè¯­è¨€ä»»åŠ¡çš„æ ‡æ³¨æ•°æ®å¾ˆå°‘ï¼Œå¯¹äºŽå¤æ‚çš„æ·±åº¦å­¦ä¹ æ¨¡åž‹æ ¹æœ¬ä¸å¤Ÿç”¨ã€‚é¢„è®­ç»ƒå’Œå¾®è°ƒèŒƒä¾‹é€šè¿‡å…è®¸ä¸åŒä»»åŠ¡ä¹‹é—´çš„çŸ¥è¯†è½¬ç§»å…‹æœäº†è¿™ä¸ªé—®é¢˜ã€‚ä¾‹å¦‚ï¼Œåˆ©ç”¨å¤§é‡æœªæ ‡è®°æ•°æ®çš„é¢„è®­ç»ƒé˜¶æ®µçš„ä¸€èˆ¬ä»»åŠ¡ï¼Œä»¥åŠä½¿ç”¨å°‘é‡ä½†æœ‰ç›®æ ‡ä¸”æœ‰æ ‡è®°çš„æ•°æ®çš„å¾®è°ƒé˜¶æ®µçš„ç‰¹å®šä»»åŠ¡ã€‚è¿˜æŽ¢ç´¢äº†å…¶ä»–ç±»åž‹çš„çŸ¥è¯†è½¬ç§»(T5ï¼ŒGPT-3)ï¼Œå¹¶è¯æ˜Žéžå¸¸æœ‰ç›Šã€‚***
*   *****ç ´åå’Œé‡å»ºç­–ç•¥** : BERT æœ‰ä¸€ä¸ªå·§å¦™çš„æƒ³æ³•ï¼Œç”¨å¡«ç©ºç»ƒä¹ æ¥é¢„å…ˆè®­ç»ƒæ¨¡åž‹ï¼Œåœ¨å¡«ç©ºç»ƒä¹ ä¸­ï¼Œæ–‡æœ¬é¦–å…ˆé€šè¿‡å±è”½ä¸€äº›å•è¯(è®°å·)æ¥ç ´åï¼Œç„¶åŽç”±æ¨¡åž‹æ¥é‡å»ºã€‚è¿™ä¸ªç»ƒä¹ ä¿ƒè¿›äº†æ‰€æœ‰è¯­è¨€ä»»åŠ¡çš„æ˜¾è‘—è¿›æ­¥ã€‚ä»Žé‚£æ—¶èµ·ï¼ŒæŽ©è”½å‡ ä¹Žæˆä¸ºä¸€ç§æ ‡å‡†çš„è®­ç»ƒå‰ç­–ç•¥ï¼Œå¯¼è‡´äº†å‡ ä¸ªåˆ›æ–°çš„å˜åŒ–(XLNetï¼ŒRoBertaï¼ŒBART)ã€‚***

## ***2.2 æž¶æž„***

***åœ¨æž¶æž„æ–¹é¢ï¼Œtransformer æ¨¡åž‹éžå¸¸ç›¸ä¼¼ã€‚å¤§å¤šæ•°æ¨¡åž‹éµå¾ªä¸Žâ€œå¼€å›½å…ƒå‹‹â€ä¹‹ä¸€ï¼Œæœ€åˆçš„å˜å½¢é‡‘åˆšï¼Œä¼¯ç‰¹å’Œ GPT ç›¸åŒçš„æž¶æž„ã€‚å®ƒä»¬ä»£è¡¨ä¸‰ç§åŸºæœ¬æž¶æž„:ä»…ç¼–ç å™¨ã€ä»…è§£ç å™¨ä»¥åŠä¸¤è€…çš†æœ‰ã€‚***

*   *****Encoder only(BERT):**Encoder é€šå¸¸æ˜¯ä¸€å †æ³¨æ„åŠ›å’Œå‰é¦ˆå±‚ï¼Œå°†è¾“å…¥çš„æ–‡æœ¬åºåˆ—ç¼–ç æˆä¸Šä¸‹æ–‡åŒ–çš„éšè—çŠ¶æ€ã€‚ä¸ºäº†ç”Ÿæˆä¸åŒè¾“å‡ºæ ¼å¼çš„è¯­è¨€ä»»åŠ¡ï¼Œé€šå¸¸ä¼šåœ¨ç¼–ç å™¨ä¸Šæ·»åŠ ä¸€ä¸ªç‰¹å®šäºŽä»»åŠ¡çš„å¤´ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªå› æžœè¯­è¨€æ¨¡åž‹(CLMï¼Œæˆ–ç®€ç§° LM)å¤´æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œæˆ–ä¸€ä¸ªå‰é¦ˆ(çº¿æ€§)å±‚æ¥äº§ç”Ÿåˆ†ç±»æ ‡ç­¾ã€‚***
*   ***ä»…è§£ç å™¨(GPT ):åœ¨è®¸å¤šæ–¹é¢ï¼Œå¸¦æœ‰ CLM ç£å¤´çš„ç¼–ç å™¨å¯ä»¥è¢«è®¤ä¸ºæ˜¯è§£ç å™¨ã€‚è§£ç å™¨ä¸æ˜¯è¾“å‡ºéšè—çŠ¶æ€ï¼Œè€Œæ˜¯ä»¥è‡ªåŠ¨å›žå½’çš„æ–¹å¼ç”Ÿæˆåºåˆ—ï¼Œä»Žè€Œå°†å…ˆå‰ç”Ÿæˆçš„å­—ç”¨ä½œè¾“å…¥æ¥ç”Ÿæˆä¸‹ä¸€ä¸ªå­—ã€‚***
*   *****Both (Transformer)** :å½“ç¼–ç å™¨å’Œè§£ç å™¨å­˜åœ¨äºŽç›¸åŒçš„ç»“æž„ä¸­æ—¶ï¼Œå®ƒä»¬ä¹‹é—´çš„åŒºåˆ«æœ€æœ‰æ„ä¹‰ï¼Œå°±åƒåœ¨ Transformer ä¸­ä¸€æ ·ã€‚åœ¨ç¼–ç å™¨-è§£ç å™¨ç»“æž„ä¸­ï¼Œè¾“å…¥åºåˆ—é¦–å…ˆè¢«â€œç¼–ç â€æˆéšè—çŠ¶æ€ï¼Œç„¶åŽè¢«â€œè§£ç â€ä»¥ç”Ÿæˆè¾“å‡ºåºåˆ—ã€‚ç¼–ç å™¨å’Œè§£ç å™¨ç”šè‡³å¯ä»¥å…±äº«ç›¸åŒçš„æƒé‡ï¼Œä»¥æé«˜è®­ç»ƒæ•ˆçŽ‡ã€‚***

***![](img/fbdfa63b0ab0a7c456eda14bebb839da.png)***

***å¦‚æžœä½ è®¨åŽŒæ¨¡ç³Šçš„å›¾ç‰‡ï¼Œç‚¹å‡» [***è¿™é‡Œ***](https://docs.google.com/presentation/d/e/2PACX-1vRzCqfKCppd00Mgaj_lQoqZqzJHlk14TJ67xjKYnj5xOpzpHtF1gDZA9uEmvbvMjoBVV8TnQjOInwOC/pub?start=false&loop=false&delayms=3000)**å¯»æ‰¾åŽŸå§‹å¹»ç¯ç‰‡ã€‚*****

***è¯¥æ¨¡åž‹çš„æž¶æž„é€šå¸¸ä¼šé™åˆ¶å®ƒå¯ä»¥æ‰§è¡Œçš„ä»»åŠ¡ç±»åž‹:ç¼–ç å™¨(æ²¡æœ‰ä»»ä½•ç‰¹å®šäºŽä»»åŠ¡çš„å¤´)åªè¾“å‡ºéšè—çŠ¶æ€ï¼Œè¿™äº›éšè—çŠ¶æ€å¯ä»¥ä½œä¸ºåŠŸèƒ½åˆå¹¶åˆ°å…¶ä»–æ¨¡åž‹ä¸­ã€‚è§£ç å™¨(æˆ–ç¼–ç å™¨+è§£ç å™¨)æ˜¯ä¸ºæ–‡æœ¬ç”Ÿæˆè€Œåˆ›å»ºçš„ï¼Œè¿™ä½¿å®ƒä»¬é€‚åˆäºŽæœºå™¨ç¿»è¯‘ã€æ‘˜è¦å’ŒæŠ½è±¡é—®ç­”ç­‰ä»»åŠ¡ã€‚ç‰¹å®šäºŽä»»åŠ¡çš„æ ‡é¢˜åœ¨è¾“å‡ºæ ¼å¼ä¸Šæä¾›äº†é¢å¤–çš„çµæ´»æ€§ï¼Œå…è®¸å¯¹åˆ†ç±»ç›¸å…³çš„ä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚***

***![](img/dfe3ae7a857f8022929a39a09b384893.png)***

***å¦‚æžœä½ è®¨åŽŒæ¨¡ç³Šçš„å›¾ç‰‡ï¼Œç‚¹å‡» [***è¿™é‡Œ***](https://docs.google.com/presentation/d/e/2PACX-1vRzCqfKCppd00Mgaj_lQoqZqzJHlk14TJ67xjKYnj5xOpzpHtF1gDZA9uEmvbvMjoBVV8TnQjOInwOC/pub?start=false&loop=false&delayms=3000)**å¯»æ‰¾åŽŸå§‹å¹»ç¯ç‰‡ã€‚*****

## ***2.3 è¶‹åŠ¿***

***é™¤äº† 3 ä¸ªåŸºæœ¬æž¶æž„ä¹‹å¤–ï¼Œè¿˜æœ‰å‡ ä¸ªåˆ›æ–°çš„ä¿®æ”¹ï¼Œæˆ‘ä»¬ç¨åŽä¼šè®¨è®ºã€‚ä¸è¿‡æ€»çš„æ¥è¯´ï¼Œæˆ‘æ„Ÿè§‰å˜å½¢é‡‘åˆšæ–¹é¢çš„ç ”ç©¶éµå¾ªäº†å‡ ä¸ªå¤§è¶‹åŠ¿ã€‚å½±å“æœ€å¤§çš„æ˜¾ç„¶æ˜¯:æ‰©å¤§è§„æ¨¡ã€‚***

*   *****è¶‹åŠ¿ 1:æ‰©å¤§è§„æ¨¡*****

***æ·±åº¦å­¦ä¹ æ¨¡åž‹å˜å¾—è¶Šæ¥è¶Šå¤§ï¼Œè¶Šæ¥è¶Šæ·±å…¥ï¼Œæ¶ˆè€—è¶Šæ¥è¶Šå¤šçš„æ•°æ®å’Œè®¡ç®—èƒ½åŠ›ã€‚å˜å½¢é‡‘åˆšä¹Ÿä¸ä¾‹å¤–ã€‚è‡ªä»Ž BERT çš„æ— ç›‘ç£é¢„è®­ç»ƒé‡Šæ”¾äº†æ•°åƒäº¿åœ¨çº¿æ•°æ®çš„åŠ›é‡ï¼Œè®­ç»ƒæ›´å¤§çš„æ¨¡åž‹æˆä¸ºå¯èƒ½ã€‚æœ€å¤§çš„ GPT-3 æœ‰ 1750 äº¿ä¸ªå‚æ•°ï¼Œæ˜¯æœ€å¤§çš„ BERT çš„ 500 å¤šå€ã€‚å¦‚æžœæˆ‘ä»¬å°†ä¸åŒæ¨¡åž‹(GLUE å’Œ SQuAD 1.1)çš„æ€§èƒ½ä¸Žå®ƒä»¬çš„å‚æ•°æ•°é‡è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ä¸ªå¤§è‡´çš„å¯¹æ•°çº¿æ€§è¶‹åŠ¿ã€‚(GPT ç³»åˆ—æ²¡æœ‰åŒ…æ‹¬åœ¨å†…ï¼Œå› ä¸ºå®ƒä»¬æ²¡æœ‰é’ˆå¯¹è¿™äº›ä»»åŠ¡è¿›è¡Œå¾®è°ƒï¼Œåªèƒ½äº§ç”Ÿå¹³åº¸çš„ç»“æžœï¼Œè¿™å¹¶ä¸æ˜¯ä»–ä»¬çš„é”™ã€‚)ç”±äºŽåŸºå‡†æ•°æ®é›†ä¸­çš„å¤šæ ·æ€§ï¼Œæ›´éš¾èŽ·å¾—è¯¸å¦‚æ€»ç»“æˆ–ç¿»è¯‘ç­‰ä»»åŠ¡çš„å®šé‡è§†å›¾ã€‚ç„¶è€Œï¼ŒGPT-3 åœ¨ã€Šå«æŠ¥ã€‹ä¸Šçš„æ–‡ç« ä¼¼ä¹Žè¯æ˜Žäº†â€œè¶Šå¤§è¶Šèªæ˜Žâ€ã€‚***

***![](img/9e1b8b35f61e74468e1be55f359bad88.png)***

***å¦‚æžœä½ è®¨åŽŒæ¨¡ç³Šçš„å›¾ç‰‡ï¼Œç‚¹å‡» [***è¿™é‡Œ***](https://docs.google.com/presentation/d/e/2PACX-1vRzCqfKCppd00Mgaj_lQoqZqzJHlk14TJ67xjKYnj5xOpzpHtF1gDZA9uEmvbvMjoBVV8TnQjOInwOC/pub?start=false&loop=false&delayms=3000)**å¯»æ‰¾åŽŸå§‹å¹»ç¯ç‰‡ã€‚*****

***![](img/eb735b6b674da939f2da18b753e954bf.png)***

***å¦‚æžœä½ è®¨åŽŒæ¨¡ç³Šçš„å›¾ç‰‡ï¼Œç‚¹å‡» [***è¿™é‡Œ***](https://docs.google.com/presentation/d/e/2PACX-1vRzCqfKCppd00Mgaj_lQoqZqzJHlk14TJ67xjKYnj5xOpzpHtF1gDZA9uEmvbvMjoBVV8TnQjOInwOC/pub?start=false&loop=false&delayms=3000)**å¯»æ‰¾åŽŸå§‹å¹»ç¯ç‰‡ã€‚*****

*   *****è¶‹åŠ¿äºŒ:æ— ç¼è½¬ç§»*****

***ç¬¬äºŒä¸ªè¶‹åŠ¿æ˜¯è¿ç§»å­¦ä¹ çš„æ™®éåŒ–ã€‚è¿™æ˜¯äº‹æƒ…å˜å¾—æ›´æœ‰è¶£çš„åœ°æ–¹ã€‚æˆ‘ä»¬å·²ç»æåˆ°äº†é¢„è®­ç»ƒ+å¾®è°ƒèŒƒå¼å¦‚ä½•åŠ é€Ÿäº†è¿™ä¸€é¢†åŸŸçš„ç ”ç©¶ã€‚ç„¶è€Œï¼Œä¸åŒä»»åŠ¡ä¹‹é—´çš„çŸ¥è¯†è½¬ç§»ï¼Œæˆ–æ‰€è°“çš„â€œå¤šä»»åŠ¡â€ï¼Œä»ç„¶ä¸æ˜Žæ˜¾ï¼Œä¸»è¦æ˜¯ä¸åŒçš„ä»»åŠ¡éœ€è¦ä¸åŒçš„ä»»åŠ¡ç‰¹å®šçš„å¤´ã€‚ç„¶è€Œï¼Œ **T5** å¾ˆå¥½åœ°è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œå®ƒå°†æ‰€æœ‰ä»»åŠ¡é‡æ–°ç»„ç»‡æˆä¸€ä¸ªç»Ÿä¸€çš„â€œ**æ–‡æœ¬åˆ°æ–‡æœ¬**æ ¼å¼ï¼Œä»Žè€Œæ¶ˆé™¤äº†å¯¹ç‰¹å®šäºŽä»»åŠ¡çš„æž¶æž„çš„éœ€æ±‚ã€‚ä½¿ç”¨ç›¸åŒçš„æž¶æž„ï¼Œé€šè¿‡ç®€å•åœ°æ”¹å˜æ•°æ®å’ŒæŸå¤±å‡½æ•°ï¼ŒçŸ¥è¯†å¯ä»¥åœ¨é¢„è®­ç»ƒå’Œä¸åŒçš„å¾®è°ƒä»»åŠ¡ä¹‹é—´â€œå¹³æ»‘åœ°â€è½¬ç§»ã€‚***

***![](img/0874b5fc62d17dd0c1acb44035041686.png)***

***è¿™æ˜¯è°·æ­Œåœ¨ T5 å‘å¸ƒçš„è®ºæ–‡ä¸­çš„ä¸€å¼ å›¾ç‰‡***

***å¦ä¸€æ–¹é¢ï¼ŒGPT ç³»åˆ—é€‰æ‹©äº†å®Œå…¨ä¸åŒçš„æ–¹å¼ã€‚äº‹å®žä¸Šï¼ŒGPT-3 å®Œå…¨æ‹’ç»äº†â€œå¾®è°ƒâ€çš„æƒ³æ³•ï¼Œæå‡ºäº†ä¸€ä¸ªå‡è®¾ï¼Œå³ç»™å®šè¶³å¤Ÿå¤šçš„æ•°æ®å’Œè¶³å¤Ÿå¤šçš„å‚æ•°(æ•°é‡å¤§å¾—ç¦»è°±)ï¼Œä¸€ä¸ªæ¨¡åž‹æ ¹æœ¬ä¸éœ€è¦å¾®è°ƒã€‚è¿™æ„å‘³ç€ä¸ä»…æž¶æž„åœ¨ä¸åŒçš„ä»»åŠ¡ä¸­ä¿æŒä¸å˜ï¼Œè€Œä¸”æ•´ä¸ªæ¨¡åž‹å‚æ•°ä¹Ÿä¿æŒä¸å˜ã€‚å®ƒå¸Œæœ›åˆ›é€ ä¸€ç§å¤šé¢æ‰‹æœºå™¨ï¼Œèƒ½å¤Ÿåƒäººç±»ä¸€æ ·ç†è§£æŒ‡å®šä¸ºè‡ªç„¶è¯­è¨€çš„æ–°ä»»åŠ¡ã€‚å°½ç®¡è¿˜æ²¡æœ‰å®Œå…¨èƒœåˆ©ï¼ŒGPT 3 å·å·²ç»å–å¾—äº†æƒŠäººçš„æˆç»©ã€‚å¾®è°ƒçš„è‡ªç”±çŸ¥è¯†è½¬ç§»åœ¨å„ç§è¯­è¨€ä»»åŠ¡ä¸­æˆ–å¤šæˆ–å°‘æˆåŠŸåœ°å‘æŒ¥äº†ä½œç”¨ã€‚åœ¨å®žè·µä¸­ï¼Œé™¤äº†å°‘æ•°æœ‰æƒåŠ¿çš„äºº(GAFA)ä¹‹å¤–ï¼Œå‡ ä¹Žæ‰€æœ‰äººéƒ½éƒ¨ç½²è¿™æ ·ä¸€ä¸ªåºžå¤§çš„æ¨¡åž‹æ˜¯å¾ˆä¸çŽ°å®žçš„ï¼Œæ›´ä¸ç”¨è¯´å®ƒæ‰€å¼•å‘çš„æ•´ä¸ªä¼¦ç†é—®é¢˜äº†ã€‚ä½† GPT-3 æ— ç–‘åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸåˆ›é€ äº†è‡ªå·±çš„æ—¶å°šã€‚***

> ***å¯¹äºŽæ‰€æœ‰çš„ä»»åŠ¡ï¼ŒGPT-3 è¢«åº”ç”¨**ï¼Œæ²¡æœ‰ä»»ä½•æ¢¯åº¦æ›´æ–°** **æˆ–å¾®è°ƒ**ï¼Œä»»åŠ¡å’Œå°‘æ•°é•œå¤´æ¼”ç¤ºçº¯ç²¹é€šè¿‡ä¸Žæ¨¡åž‹çš„æ–‡æœ¬äº¤äº’æ¥æŒ‡å®šã€‚GPT-3 åœ¨è®¸å¤š NLP æ•°æ®é›†ä¸Šå®žçŽ°äº†**å¼ºå¤§çš„æ€§èƒ½**â€¦â€¦â€***
> 
> ***â€” [è¯­è¨€æ¨¡åž‹æ˜¯ä¸€æ¬¡æ€§å­¦ä¹ è€…](https://arxiv.org/abs/2005.14165)***

*   *****è¶‹åŠ¿ 3:æ™ºèƒ½æ•ˆçŽ‡*****

***åœ¨å·¨äººå®¶æ—ä¸­ï¼Œæœ‰å°‘æ•°ç¦»ç¾¤è€…å¯¹æ•ˆçŽ‡æ›´æ„Ÿå…´è¶£ï¼Œå¹¶è®¾æ³•ç”¨è¾ƒå°çš„æ¡†æž¶å–å¾—äº†è‰¯å¥½çš„ç»“æžœã€‚ä»–ä»¬æ˜¯ç”Ÿæ´»åœ¨å—é™äºŽæœ‰é™æ•°æ®å’Œè®¡ç®—èµ„æº(T21)çš„ä¸–ç•Œä¸­çš„å®žé™…çŽ©å®¶ï¼Œå°±åƒæˆ‘ä»¬ä¸­çš„è®¸å¤šäººä¸€æ ·ã€‚***

*****XLNet** æå‡ºäº†ä¸€ä¸ªå¾ˆå¥½çš„è§£å†³ç”±æ³¨æ„åŠ›é¢å…·å¼•èµ·çš„ä¼¯ç‰¹å·®å¼‚é—®é¢˜çš„æ–¹æ³•ï¼Œ**ç½—ä¼¯å¡”**è°ƒæ•´äº†é¢å…·å’Œè®­ç»ƒç¨‹åºï¼Œ**å·´ç‰¹**è¯•éªŒäº†å„ç§é¢å…·ç­–ç•¥ã€‚å®ƒä»¬éƒ½åœ¨ä¸å¢žåŠ æ¨¡åž‹è§„æ¨¡çš„æƒ…å†µä¸‹æˆåŠŸåœ°æé«˜äº† BERT çš„æ€§èƒ½ã€‚***

***åœ¨å¦ä¸€ä¸ªæ–¹å‘ï¼Œåˆ›æ–°çš„æ–¹æ³•è¢«åˆ›é€ å‡ºæ¥ï¼Œåœ¨ä¸æŸå®³æ€§èƒ½çš„æƒ…å†µä¸‹ç¼©å°æ¨¡åž‹çš„å¤§å°: **ALBERT** åœ¨å‚æ•°å…±äº«æ–¹é¢èµ°å¾—å¾ˆæ¿€è¿›ï¼Œ**ä¼ŠèŽ±å…‹ç‰¹**åœ¨ GAN èº«ä¸Šæ‰¾åˆ°äº†çµæ„Ÿï¼Œ **MobileBERT** åˆ©ç”¨æ•™å¸ˆçš„å¼ºåˆ¶åŠ›ä½¿ç½‘ç»œå˜å¾—åˆæ·±åˆç»†ã€‚**é‡æ•´å™¨**å°†æ³¨æ„åŠ›å¤´çš„å¤æ‚åº¦ä»Ž O(N)é™ä½Žåˆ° O(N *log* N)ã€‚è¿™äº›æ¨¡åž‹æ˜¯æ€§èƒ½ä¸Žè§„æ¨¡å›¾è¡¨ä¸Šçš„å¼‚å¸¸å€¼ã€‚å®ƒä»¬å¯èƒ½ä¹Ÿæ˜¯æœ€å‹å¥½çš„åº”ç”¨ç¨‹åºã€‚***

***![](img/a07cbcbc93b2e4d2b9f5cfcbc154c31e.png)***

***XLNetã€RoBERTaã€ALBERT å’Œä¼ŠèŽ±å…‹ç‰¹ä»¥å°å¾—å¤šçš„æž¶æž„å®žçŽ°äº†ä¸Ž T5â€“3B ä¸ç›¸ä¸Šä¸‹çš„æ€§èƒ½ã€‚å¦‚æžœä½ è®¨åŽŒæ¨¡ç³Šçš„å›¾ç‰‡ï¼Œç‚¹å‡» [***è¿™é‡Œ***](https://docs.google.com/presentation/d/e/2PACX-1vRzCqfKCppd00Mgaj_lQoqZqzJHlk14TJ67xjKYnj5xOpzpHtF1gDZA9uEmvbvMjoBVV8TnQjOInwOC/pub?start=false&loop=false&delayms=3000)**å¯»æ‰¾åŽŸå§‹å¹»ç¯ç‰‡ã€‚*****

*   *****è¶‹åŠ¿å››:ä¸“å®¶ä»¬*****

***æœ€åŽä¸€ä¸ªè¶‹åŠ¿å¾ˆå¯èƒ½ä¸æ˜¯è¶‹åŠ¿ã€‚å®ƒä»¬æ˜¯ä¸ºäº†ç‰¹æ®Šç›®çš„è€Œä¿®æ”¹å’Œè°ƒæ•´çš„ BERTã€GPT æˆ– Transformer:**long former**å’Œ **Transformer-XL** ä¸“æ³¨äºŽå†—é•¿çš„æ–‡æ¡£ï¼Œ **CamemBERT** å’Œ **FlauBERT** æ— ç–‘å…·æœ‰æ³•è¯­æ ¹æºï¼Œ **Ctrl** åœ¨æ–‡æœ¬ç”Ÿæˆæ–¹é¢æä¾›æ›´å¤šæŽ§åˆ¶ï¼Œ **DialoGPT** æ—¨åœ¨æˆä¸ºæ‚¨å¥è°ˆçš„æœ‹å‹ï¼Œ **Pegasus** ä¸ºæ‘˜è¦è€Œç”Ÿåƒåœ¨ä»»ä½•å…¶ä»–é¢†åŸŸä¸€æ ·ï¼Œä¸“å®¶ä»¬åœ¨ä»–ä»¬çš„é¢†åŸŸé‡Œå¤§æ”¾å¼‚å½©ï¼Œè€Œä¸”å¾ˆå¯èƒ½åªåœ¨ä»–ä»¬è‡ªå·±çš„é¢†åŸŸé‡Œã€‚å› æ­¤ï¼Œæ‰¾åˆ°æœ€ä½³åŒ¹é…å¯¹æˆ‘ä»¬æ¥è¯´è‡³å…³é‡è¦ã€‚***

## ***2.4 å®žè·µèµ„æº***

***Huggingface.co æä¾›çš„å˜å½¢é‡‘åˆšå¥—è£…éžå¸¸å®¹æ˜“ä½¿ç”¨ã€‚[ç®¡é“ API](https://huggingface.co/transformers/quicktour.html) æä¾›äº†ä¸€ä¸ªç®€å•çš„é«˜çº§æŽ¥å£æ¥åº”ç”¨é¢„å®šä¹‰çš„ä»»åŠ¡ï¼Œå®žé™…ä¸Šåªæœ‰ 3 è¡Œä»£ç ã€‚***

```
***from transformers import pipeline
classifier = pipeline('sentiment-analysis')
classifier('We are very happy to show you the ðŸ¤— Transformers library.')***
```

***æ‚¨è¿˜å¯ä»¥æ‰¾åˆ°æ›´å¤šå…³äºŽé¢„åŸ¹è®­æˆ–å¾®è°ƒä¸åŒåž‹å·çš„[ç¬”è®°æœ¬ç¤ºä¾‹](https://huggingface.co/transformers/notebooks.html)ã€‚***

***é™¤äº† Huggingface.coï¼Œæˆ‘è¿˜åœ¨ä»¥ä¸‹åœ°æ–¹æ‰¾åˆ°äº†éžå¸¸æœ‰ç”¨çš„èµ„æ–™ã€‚***

*   ***[è‰¾ä¼¦äººå·¥æ™ºèƒ½ç ”ç©¶æ‰€](https://allennlp.org)***
*   ***[çº¸å¼ ç¼–ç ](https://paperswithcode.com)***
*   ***æ°Â·é˜¿æ‹‰çŽ›***
*   ***[OpenAI](https://openai.com)***

***ä¸è¿‡å¹³å¿ƒè€Œè®ºï¼Œ**arXiv.org**å’Œ **Github** å¤§æ¦‚è¿˜æ˜¯æœ€å¥½çš„ã€‚***

# ***ç¬¬ä¸‰éƒ¨åˆ†ã€‚æœ€åŽçš„è¯***

***è¿™ç¯‡æ–‡ç« æ¯”æˆ‘é¢„æƒ³çš„è¦é•¿å¾—å¤šï¼Œå†™è¿™ç¯‡æ–‡ç« èŠ±è´¹çš„æ—¶é—´ä¹Ÿæ¯”æˆ‘é¢„æœŸçš„è¦å¤šã€‚å¦‚æžœä½ å·²ç»è®¾æ³•åˆ°è¾¾è¿™é‡Œï¼Œæ„Ÿè°¢ä½ æ°å‡ºçš„è€å¿ƒã€‚***

***æ¯æ¬¡å½“æˆ‘è¯»ä¸€ç¯‡é•¿æ–‡ç« æ—¶ï¼Œæˆ‘æ€»æ˜¯æ¢¦æƒ³å¾—åˆ°å®ƒçš„è¦ç‚¹æ‘˜è¦ã€‚æ‡’æƒ°å¯èƒ½æ˜¯ç ”ç©¶çš„æœ€å¤§åŠ¨æœºä¹‹ä¸€ã€‚åœ¨åŽè§ä¹‹ä¸‹ï¼Œä¹Ÿè®¸è®© T5 ä¸ºæˆ‘æ€»ç»“äºŒåå¤šç¯‡è®ºæ–‡ä¼šæ›´æ–¹ä¾¿ã€‚ä¸ºäº†å¼¥è¡¥å¤±åŽ»çš„æœºä¼šï¼Œä¸‹é¢æ˜¯**T5-large**(110 äº¿å‚æ•°)ç»™å‡ºçš„æ€»ç»“ã€‚ä½ è§‰å¾—è¿™æ ·å¤Ÿå¥½äº†å—ï¼Ÿ***

```
***GPT-3 is the latest and arguably the most powerful member of a family of deep learning NLP models . the model has been developed by openAI, but only API access is available for pre-selected partners . sam saunders: "it feels like all the coolest kitchen gadgets" are just waiting for you to concoct the finest meal .a perfect NLP robot, let's call him Nate, would be able to understand and take actions like a human-being . to make that happen, Nate needs to have several components . word, sentence and document represents 3 levels of increasing complexities in reading (comprehension) and writing (execution)a great solution in real life should always be the simplest one that satisfies all the requirements . the transformer family provides powerful tools to solve sentence and document level comprehension tasks . if your use case only requires word level comprehension and execution, chances are you may not need the heavy machinery of transformer .transformer provides the source code of more than 21 architectures and 90 pre-trained models . attention head is one of the defining features of the transformer family . the pre-train and fine-tuning paradigm allows knowledge transfer between different tasks .transformer models follow the same architecture as one of the "founding fathers", the original transformer, BERT and GPT . the distinction between encoder and decoder makes most sense when they both exist in the same structure, as in transformer . encoders are usually a stack of attention and feed-forward layers, which encode the input text sequence into contextualised hidden states . a task specific head is often added on top of the encoder .transformers models are becoming larger and deeper, consuming ever more data and computation power . the largest GPT-3 has 175 billion parameters, which is more than 500 times the largest BERT . in practice, it would be quite unrealistic for almost everyone except the powerful few to deploy such a gigantic model .a few outliers are more interested in efficiency, and managed to achieve good results with smaller frames . the last trend is probably not a trend. they are the BERTs, GPTs or Transformers that have been modified and tweaked for a special purpose .pipeline API provides a simple high-level interface to apply pre-defined tasks . pipeline classifier = pipeline('sentiment-analysis') classifier('We are very happy to show you the  Transformers library')***
```

***è„šæœ¬:***

```
***from transformers import pipelinesummarizer = pipeline("summarization", model="t5-large", tokenizer="t5-large", framework="pt")with open('nlp_article.txt', 'r') as file:
    article = file.read()paragraphs = article.split(r"*****")
len(paragraphs)paragraphs = [par for par in paragraphs if len(par.split(" ")) >= 10][len(par.split(" ")) for par in paragraphs]results = summarizer(paragraphs, min_length=5, max_length=100)for x in results:
    print(x["summary_text"] + "\n")***
```