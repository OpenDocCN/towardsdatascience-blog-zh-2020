<html>
<head>
<title>Topic Modeling Articles with NMF</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主题建模文章与NMF</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45?source=collection_archive---------1-----------------------#2020-04-16">https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45?source=collection_archive---------1-----------------------#2020-04-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="0501" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">抽取主题是发现文本之间潜在关系的一种很好的无监督数据挖掘技术。有许多不同的方法，最流行的可能是LDA，但我将集中讨论NMF。我在这方面取得了更大的成功，而且它通常比LDA更具可扩展性。</p><p id="f903" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文介绍了如何:</p><ul class=""><li id="18a4" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated">为主题建模准备文本</li><li id="68f0" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">从文章中提取主题</li><li id="cb8f" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">总结这些主题</li><li id="8332" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">自动查找用于模型的最佳主题数量</li><li id="cf63" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">在所有主题中找到质量最高的主题</li><li id="cca7" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">预测一篇新文章的主题</li></ul><p id="a420" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">和往常一样，所有代码和数据都可以在我的GitHub <a class="ae lc" href="https://github.com/robsalgado/personal_data_science_projects/tree/master/topic_modeling_nmf" rel="noopener ugc nofollow" target="_blank">页面</a>的存储库中找到。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/912d4e1cc2605c804dd49f87acf1d9cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oAwFKQm3DJG_heudbBOY0Q.jpeg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">由<a class="ae lc" href="https://unsplash.com/@rvignes?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">罗曼·维尼斯</a>在<a class="ae lc" href="https://unsplash.com/s/photos/text?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="3c9c" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">数据</h1><p id="7ccd" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">我用的是CNN的'<a class="ae lc" href="https://www.cnn.com/business" rel="noopener ugc nofollow" target="_blank">商业</a>'栏目的全文文章。文章出现在2020年3月下旬到2020年4月上旬的那个页面，被刮了。每天早上8点运行一次刮刀，刮刀包含在存储库中。“商业”页面上的文章关注几个不同的主题，包括投资、银行、成功、视频游戏、科技、市场等。</p><p id="c029" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们做一些快速的探索性数据分析来熟悉数据。共301篇，平均字数732字，标准差363字。这是前五行。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mw"><img src="../Images/05c19004fc4939aca091c2c533ea0c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vX2vG1G-6VxCfiWMbCBzOw.png"/></div></div></figure><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/6405f3dbbfd5d5f70a698529145a020d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*4sMcsbQsunalnAXp3roVkw.png"/></div></figure><p id="ab2f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">就字数的分布而言，它有点偏正，但总体而言，它是一个非常正常的分布，第25百分位为473个单词，第75百分位为966个单词。大约有4个异常值(高于第75百分位1.5倍)，最长的文章有2.5K个单词。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi my"><img src="../Images/659c9036537320d353d8108f8ba9788a.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*mOK2MrHS1rz7v7sE06mitA.png"/></div></figure><p id="b308" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是对文本进行处理后，所有文章中出现频率最高的20个词。“公司”、“商业”、“人”、“工作”和“冠状病毒”是前5名，考虑到页面的焦点和数据被抓取的时间框架，这是有道理的。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mz"><img src="../Images/962b66ee3ae073ac821c43ac400a0fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T21E6myryrjVUwiz_-VYNg.png"/></div></div></figure><h1 id="2ba8" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">NMF</h1><p id="e9c6" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">非负矩阵分解(NMF)是一种无监督的技术，因此没有模型将被训练的主题的标签。它的工作方式是，NMF将高维向量分解(或因式分解)成一个低维表示。这些低维向量是非负的，这也意味着它们的系数是非负的。</p><p id="b34b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">利用原始矩阵(A)，NMF会给你两个矩阵(W和H)。w是它找到的主题，H是这些主题的系数(权重)。换句话说，A是按词排序的文章(原创)，H是按主题排序的文章，W是按词排序的主题。</p><p id="f56a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，假设有301篇文章、5000个单词和30个主题，我们将得到以下3个矩阵:</p><pre class="le lf lg lh gt na nb nc nd aw ne bi"><span id="782b" class="nf lu it nb b gy ng nh l ni nj">A = tfidf_vectorizer.transform(texts)<br/>W = nmf.components_<br/>H = nmf.transform(A)</span><span id="0d80" class="nf lu it nb b gy nk nh l ni nj">A = 301 x 5000<br/>W = 30 x 5000<br/>H = 301 x 30</span></pre><p id="3e0d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">NMF将修改W和H的初始值，使得乘积接近A，直到逼近误差收敛或者达到最大迭代次数。</p><p id="a5b6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的例子中，高维向量将是tf-idf权重，但它实际上可以是任何东西，包括单词向量或简单的单词原始计数。</p><h1 id="9613" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">文本处理</h1><p id="abf1" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">这是该过程中最关键的步骤之一。俗话说，“垃圾进来，垃圾出去”。当处理文本作为我们的特征时，尝试减少独特的单词(即特征)的数量是非常关键的，因为会有很多。这是我们对太多特性的第一次防御。</p><p id="2b7f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">抓取的数据真的很干净(CNN拥有好的html，但并不总是如此)。你应该总是手动浏览文本，并确保没有错误的html或换行符等。这肯定会出现并伤害模特。</p><p id="9f93" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是我正在使用的函数:</p><ul class=""><li id="63ea" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated"><a class="ae lc" href="https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization" rel="noopener ugc nofollow" target="_blank">标记化</a>文本</li><li id="35da" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">小写文本</li><li id="055b" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">展开收缩</li><li id="25e3" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://en.wikipedia.org/wiki/Stemming" rel="noopener ugc nofollow" target="_blank">茎</a>正文</li><li id="b927" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">删除标点符号、停用词、数字、单个字符和带有额外空格的单词(由展开缩写造成的假象)</li></ul><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nl"><img src="../Images/2262d31bb33a7b6bb878148ef9bd9144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F1-YC081ESgrFWDo50zO5Q.png"/></div></div></figure><p id="db66" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是我在文章开始时使用的默认设置(在这种情况下效果很好)，但我建议将它修改为您自己的数据集。例如，我在一些数据集中添加了特定的停用词，如“cnn”和“ad ”,所以你应该经常浏览并查找类似的内容。这些是经常出现的词，很可能不会增加模型解释主题的能力。</p><p id="5b06" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是处理前后的文本示例:</p><ul class=""><li id="4e67" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated">在新体制下，“广州变成广州，天津变成天津。”最重要的是，报纸现在将把中国的首都称为北京，而不是北京。对一些美国出版物来说，这一步走得太远了。大约在这个时候，芝加哥论坛报在一篇关于拼音的文章中说，虽然它将对大多数汉字采用拼音，但一些名字已经“根深蒂固”</li><li id="793e" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">新州变成广州天津变成天津进口报纸西班牙语参考国首都北京北京大步远美国公众文章拼音时代芝加哥论坛报采用中文单词变得根深蒂固</li></ul><h1 id="fdd5" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">特征创建、选择和更多缩减</h1><p id="2e55" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">既然文本已经被处理了，我们可以用它来创建特征，把它们变成数字。有几种不同的方法可以做到这一点，但总的来说，我发现从文本中创建tf-idf权重工作得很好，并且在计算上不是很昂贵(即运行速度快)。</p><p id="afe3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可以在这里阅读更多关于tf-idf <a class="ae lc" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank">的内容。一些其他的文本特征创建技术有</a><a class="ae lc" href="https://en.wikipedia.org/wiki/Bag-of-words_model" rel="noopener ugc nofollow" target="_blank">单词袋</a>和<a class="ae lc" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank">单词向量</a>，所以你可以随意探索这两种技术。</p><p id="06e6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于特征选择，我们将“min_df”设置为3，这将告诉模型忽略出现在少于3篇文章中的单词。我们将“max_df”设置为. 85，这将告诉模型忽略出现在超过85%的文章中的单词。这将帮助我们消除对模型没有积极贡献的单词。</p><p id="bde7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">经过处理后，我们有9K多一点的唯一单词，因此我们将设置max_features，以便只包括文章中词频最高的5K个单词，以便进一步减少特征。</p><p id="d6e3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了单个单词的tf-idf权重，我们还可以为<a class="ae lc" href="https://en.wikipedia.org/wiki/N-gram" rel="noopener ugc nofollow" target="_blank"> n-grams </a>(二元模型、三元模型等)创建tf-idf权重。).为此，我们将n_gram的范围设置为(1，2 ),它将包括一元和二元。</p><p id="7a96" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还需要使用一个预处理程序来连接标记化的单词，因为默认情况下模型会标记化所有内容。</p><pre class="le lf lg lh gt na nb nc nd aw ne bi"><span id="43bf" class="nf lu it nb b gy ng nh l ni nj">texts = df['processed_text']</span><span id="b247" class="nf lu it nb b gy nk nh l ni nj">tfidf_vectorizer = TfidfVectorizer(<br/>    min_df=3,<br/>    max_df=0.85,<br/>    max_features=5000,<br/>    ngram_range=(1, 2),<br/>    preprocessor=' '.join<br/>)</span><span id="3142" class="nf lu it nb b gy nk nh l ni nj">tfidf = tfidf_vectorizer.fit_transform(texts)</span></pre><p id="f3d6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们有了这些特性，我们可以创建一个主题模型。👍</p><h1 id="0561" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">人工主题建模</h1><p id="e1c8" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">首先是一个主题模型的例子，我们手动选择主题的数量。之后我将展示如何自动选择最佳数量的主题。艰难的工作已经完成，所以我们需要做的就是运行模型。</p><pre class="le lf lg lh gt na nb nc nd aw ne bi"><span id="d357" class="nf lu it nb b gy ng nh l ni nj">nmf = NMF(<br/>    n_components=20,<br/>    init='nndsvd'<br/>).fit(tfidf)</span></pre><p id="e283" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">唯一需要的参数是组件的数量，即我们想要的主题数量。这是整个主题建模过程中最关键的一步，将极大地影响你最终主题的好坏。现在，我们将它设置为20，稍后我们将使用一致性分数来自动选择最佳数量的主题。</p><p id="c0f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我还用“nndsvd”初始化了模型，它最适合我们这里的稀疏数据。其他一切我们将保留为默认的工作良好。但是，可以随意试验不同的参数<a class="ae lc" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="8901" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">连贯性得分</h1><p id="e3d1" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">为了评估主题的最佳数量，我们可以使用连贯性分数。解释它是如何计算的超出了本文的范围，但一般来说，它测量的是一个主题中单词之间的相对距离。<a class="ae lc" href="http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf" rel="noopener ugc nofollow" target="_blank">这里的</a>是关于如何在gensim中实现它的原文。</p><p id="331a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有几种不同类型的连贯性评分，其中最受欢迎的是<em class="nm"> c_v </em>和<em class="nm"> u_mass </em>。<em class="nm"> c_v </em>更精确，而<em class="nm"> u_mass </em>更快。我将在这里使用<em class="nm"> c_v </em>，范围从0到1，1是完全一致的主题。</p><p id="8f32" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我喜欢sklearn的NMF实现，因为它可以使用tf-idf权重，我发现这比gensim的实现只能使用的原始字数更好(据我所知)。然而，sklearn的NMF实现没有一致性分数，我还没有找到如何使用<em class="nm"> c_v </em>手动计算的示例(有<a class="ae lc" href="https://github.com/derekgreene/topic-model-tutorial/blob/master/3%20-%20Parameter%20Selection%20for%20NMF.ipynb" rel="noopener ugc nofollow" target="_blank">这个</a>使用<em class="nm"> TC-W2V </em>)。如果有人知道一个例子，请让我知道！</p><p id="9fba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，我们将使用gensim获得具有一致性分数的最佳主题数量，然后将该数量的主题用于NMF的sklearn实现。</p><h1 id="3e52" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">自动选择最佳数量的主题</h1><p id="9236" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">显然，有一种自动选择最佳主题数量的方法是非常关键的，尤其是如果这将进入生产阶段。使用一致性分数，我们可以针对不同数量的主题运行模型，然后使用具有最高一致性分数的主题。这当然不是完美的，但它通常工作得很好。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="f7c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于要尝试的主题数量，我选择了5到75的范围，步长为5。这只是来自一些试验和错误，文章的数量和文章的平均长度。每个数据集都是不同的，所以你必须手动运行几次来找出你想要搜索的主题号的范围。运行太多的主题会花费很长时间，特别是如果你有很多文章，所以要意识到这一点。</p><p id="5eaa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我不打算详细介绍我在这里使用的NMF模型的所有参数，但它们确实会影响每个主题的总体得分，所以再次强调，找到适合您数据集的良好参数。你也可以网格搜索不同的参数，但这显然是相当昂贵的计算。</p><p id="8967" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">模型运行后，我们可以通过主题直观地检查一致性分数</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi np"><img src="../Images/d7c44ab0093ac7cec66058f38bfcef51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fzl-78rF_NwTHyL_69amcg.png"/></div></div></figure><p id="627f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">30是返回最高一致性分数(. 435)的主题数量，之后它下降得相当快。总的来说，这是一个不错的分数，但我不太关心实际价值。真正的考验是你自己浏览主题，确保它们对文章有意义。</p><p id="e120" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">10 topics在一致性得分(. 432)方面紧随其后，因此您可以看到，它也可以通过一组不同的参数来选择。所以，就像我说的，这不是一个完美的解决方案，因为这是一个相当广泛的范围，但从图表中可以明显看出，10到40个主题将产生良好的结果。也就是说，你可能想要平均前5个主题数，取前5个中的中间主题数，等等。现在我们只要30英镑。</p><h1 id="f6df" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">总结主题</h1><p id="e26c" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">另一个挑战是总结主题。这里最好的解决方案是让一个人浏览文本并手动创建主题。这显然不太理想。另一种选择是使用每个主题中得分最高的单词，然后将这些单词映射回特性名称。我用的是前8个词。看起来是这样的:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nq"><img src="../Images/2ef077391e48fe563b9ea868cc0e1d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5soiJmDbTcTTOd1HdeEmJg.png"/></div></div></figure><p id="feea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以通过索引将这些主题映射回文章。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nr"><img src="../Images/e8509d97844fd761fc10a76dcc690fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vVAKSfQ1seqHUsqfK79Z-g.png"/></div></div></figure><h1 id="949c" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">比较主题的质量</h1><p id="943a" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">对于一些主题，发现的潜在因素将很好地接近文本，而对于一些主题，它们可能不是。我们可以计算每篇文章和主题的残差，以判断主题有多好。</p><p id="43ef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">残差是数据的观测值和预测值之间的差异。残差为0意味着主题与文章的正文非常接近，所以越低越好。</p><p id="e151" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了计算残差，可以采用tf-idf权重(A)的Frobenius范数减去主题(H)和主题(W)的系数的点积。然后我们可以得到每个主题的平均残差，看看哪个主题的平均残差最小。</p><pre class="le lf lg lh gt na nb nc nd aw ne bi"><span id="cd33" class="nf lu it nb b gy ng nh l ni nj"># Get the residuals for each document<br/>r = np.zeros(A.shape[0])</span><span id="2598" class="nf lu it nb b gy nk nh l ni nj">for row in range(A.shape[0]):<br/>    r[row] = np.linalg.norm(A[row, :] - H[row, :].dot(W), 'fro')</span><span id="cfed" class="nf lu it nb b gy nk nh l ni nj"># Add the residuals to the df<br/>df_topics['resid'] = r</span></pre><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ns"><img src="../Images/1d58a86ecee84a62c748672ddf39c6dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V_pbHaRBxXXrYgg2C4Hnjw.png"/></div></div></figure><p id="920d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">主题#9具有最低的残差，因此意味着主题最接近文本，而主题#18具有最高的残差。</p><p id="421e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">主题#9的摘要是“<em class="nm">insta cart worker shopper custom order gig company</em>”，有5篇文章属于该主题。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nt"><img src="../Images/54ae72c8fb453cb0d688eb06c9e78426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HYJrhAJURPijbGwLkDb__w.png"/></div></div></figure><p id="b12c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">文章链接:</p><ul class=""><li id="7435" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/03/16/tech/delivery-workers-coronavirus/index.html" rel="noopener ugc nofollow" target="_blank">工人称零工公司在冠状病毒爆发期间做得“非常少”</a></li><li id="91ea" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/03/29/tech/instacart-strike-hand-sanitizer-tips/index.html" rel="noopener ugc nofollow" target="_blank"> Instacart在计划的工人罢工前做出更多改变</a></li><li id="2901" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/03/28/tech/instacart-planned-strike/index.html" rel="noopener ugc nofollow" target="_blank"> Instacart购物者计划在疫情罢工</a></li><li id="8d35" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/03/30/tech/instacart-amazon-worker-strikes/index.html" rel="noopener ugc nofollow" target="_blank">这就是为什么亚马逊和Instacart的工人在你最需要他们的时候罢工</a></li><li id="97dc" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/03/23/tech/instacart-hiring/index.html" rel="noopener ugc nofollow" target="_blank">随着食品杂货配送需求激增，Instacart计划再雇佣30万名工人</a></li></ul><p id="c931" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是一个非常连贯的话题，所有的文章都是关于instacart和gig workers的。我们自动创建的摘要也很好地解释了主题本身。</p><p id="8b55" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们来看看最糟糕的话题(#18)。总结就是“<em class="nm">鸡蛋销售零售价格复活节产品鞋市场</em>”。这个主题总共有16篇文章，所以我们只关注残差最高的前5篇。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nu"><img src="../Images/2c6160b78930013cc12cdadb319f9d0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j1pzP4-qAF7Y6twRVL5hAA.png"/></div></div></figure><p id="fd49" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">文章链接:</p><ul class=""><li id="5dcd" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/03/26/business/crocs-donation-coronavirus/index.html" rel="noopener ugc nofollow" target="_blank">鳄鱼向医护人员捐赠鞋子</a></li><li id="01b8" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/03/26/investing/gold-demand-supply-coronavirus/index.html" rel="noopener ugc nofollow" target="_blank">想买金币还是金条？祝你找到任何</a></li><li id="a0c6" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/03/02/business/rothys-bags/index.html" rel="noopener ugc nofollow" target="_blank">罗斯对海洋塑料垃圾有了新想法:手袋</a></li><li id="074b" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">你真的每个月都需要新衣服吗？订阅盒新鲜感已经消失</li><li id="f8b0" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">美国人正在为他们的宠物抢购食物</li></ul><p id="87ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如你所见，这些文章到处都是。一般来说，它们大多是关于零售产品和购物的(除了关于黄金的文章)，crocs的文章是关于鞋子的，但没有一篇文章与复活节或鸡蛋有关。他们仍然联系在一起，尽管相当松散。</p><h1 id="3126" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">预测新文章的主题</h1><p id="8025" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">一旦你符合这个模型，你可以给它一篇新文章，让它预测主题。你只需要通过之前安装在原始文章上的tf-idf和NMF模型来转换新的文本。注意，我在这里只是调用了transform，而不是fit或fit transform。</p><pre class="le lf lg lh gt na nb nc nd aw ne bi"><span id="1c09" class="nf lu it nb b gy ng nh l ni nj"># Transform the new data with the fitted models<br/>tfidf_new = tfidf_vectorizer.transform(new_texts)<br/>X_new = nmf.transform(tfidf_new)</span><span id="3a8f" class="nf lu it nb b gy nk nh l ni nj"># Get the top predicted topic<br/>predicted_topics = [np.argsort(each)[::-1][0] for each in X_new]</span><span id="6aa7" class="nf lu it nb b gy nk nh l ni nj"># Add to the df<br/>df_new['pred_topic_num'] = predicted_topics</span></pre><p id="47a5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我收集了初始集并随机选择了5篇文章后，我继续刮文章。所以这些以前从未被模型看到过。总的来说，它在预测主题方面做得很好。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nv"><img src="../Images/2a30678526d4e165350a5efb97928ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wuep5qPclSYqZZ2AKktvhw.png"/></div></div></figure><ul class=""><li id="c04f" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/02/06/tech/nuro-self-driving-vehicle-houston-dot/index.html" rel="noopener ugc nofollow" target="_blank">美国为这种没有方向盘或踏板的自动驾驶汽车扫清道路</a> -主题:<em class="nm">太阳能计算技术spacex energi power ibm vehicl </em></li><li id="f8b6" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/04/10/success/managing-a-team-remotely-in-a-crisis/index.html" rel="noopener ugc nofollow" target="_blank">如何在这场危机中远程管理一个团队</a> -主题:<em class="nm">工作家庭办公室儿童办公桌人员学校</em></li><li id="44bc" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">国会将失业援助扩展到临时工。但是他们很难访问它 -主题:<em class="nm">优步工人雇佣自治的自由司机</em></li><li id="4af9" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/04/06/media/federal-response-coronavirus-reliable-sources/index.html" rel="noopener ugc nofollow" target="_blank">斯特尔特:联邦政府对疫情的反应是9/11级别的失败</a> -主题:<em class="nm">川普福克斯新闻简报汉尼提·怀特·豪斯总统</em></li><li id="ee81" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><a class="ae lc" href="https://www.cnn.com/2020/04/10/tech/nintendo-switch-shipment-pause-shortage/index.html" rel="noopener ugc nofollow" target="_blank">全球缺货，任天堂暂停任天堂Switch对日出货</a> -主题:<em class="nm">游戏xbox视频播放图文nbc olymp doom </em></li></ul></div></div>    
</body>
</html>