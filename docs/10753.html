<html>
<head>
<title>GPT-3 is the future. But what can NLP do in the present?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GPT 3 号是未来。但是 NLP 在当下能做什么呢？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gpt-3-is-the-future-but-what-can-nlp-do-in-the-present-7aae3f21e8ed?source=collection_archive---------43-----------------------#2020-07-27">https://towardsdatascience.com/gpt-3-is-the-future-but-what-can-nlp-do-in-the-present-7aae3f21e8ed?source=collection_archive---------43-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="55d9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">GPT 3 号闪闪发光，但仍有一段距离。让我们使用当今最先进的语言模型。再加点《星际迷航》来找乐子</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cf7393281e9065059584a8c6d3875440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ylhkf8Fn3u5BI0OQKsyFEg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Jelleke Vanooteghem 在<a class="ae ky" href="https://unsplash.com/s/photos/words?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="065e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于 OpenAI 最新和最伟大的语言模型 GPT 3 的奇迹，已经有很多笔墨(或像素照明)了。用<a class="ae ky" href="https://venturebeat.com/2020/05/29/openai-debuts-gigantic-gpt-3-language-model-with-175-billion-parameters/" rel="noopener ugc nofollow" target="_blank">风投</a>的话说:</p><blockquote class="lv lw lx"><p id="0a5b" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">由 30 多名 OpenAI 研究人员组成的<!-- -->团队发布了一篇关于<strong class="lb iu"> GPT </strong> - <strong class="lb iu"> 3 </strong>的论文，这是一种语言模型，能够在一系列基准和独特的自然语言处理任务上实现最先进的结果，这些任务从语言翻译到生成新闻文章到回答 SAT 问题。</p></blockquote><p id="33ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">麻省理工学院在推特上写道:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="6993" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">公平地说，有些例子很惊人:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="42aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是像大多数由语言模型产生的例子一样，几乎所有的例子都是经过多次运行后由人类手工选择的。因为不太好的结果不会成为新闻。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi me"><img src="../Images/6a5cc64d4e5a92525c6a7ceb2a0fab07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jh9OqDrz-5m-aWcFw2m8RQ.png"/></div></div></figure><p id="adb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">即使考虑到这一点，我仍然被我所看到的 GPT 3 号震撼了。但是现在我没有办法得到它的任何实际用途——目前它只对少数研究人员开放。我们这些凡人呢？当然除了玩<a class="ae ky" href="https://play.aidungeon.io/" rel="noopener ugc nofollow" target="_blank"> AI 地牢</a>之外…</p><h1 id="e24a" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">玩 GPT 2！</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/eb5fe0d7de64d100b77dcaf459ed73e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*U2zpeje_bG7vi_3efpJUCQ.gif"/></div></div></figure><p id="73eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以和 GPT 3 号的哥哥 GPT 2 号一起玩。几周前我写了<a class="ae ky" href="https://github.com/alexcg1/easy_text_generator" rel="noopener ugc nofollow" target="_blank"> easy_text_generator </a>，这是一个在浏览器中从语言模型生成任意长度文本的工具。你可以使用 GPT-2 或几个预先训练或提炼的版本(从<a class="ae ky" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> huggingface </a>下载)来生成不同类型的文本，如<a class="ae ky" href="https://huggingface.co/cpierse/gpt2_film_scripts" rel="noopener ugc nofollow" target="_blank">电影脚本</a>、<a class="ae ky" href="https://huggingface.co/alexcg1/trekbot" rel="noopener ugc nofollow" target="_blank">星际旅行脚本</a>、<a class="ae ky" href="https://huggingface.co/lvwerra/gpt2-imdb-pos" rel="noopener ugc nofollow" target="_blank"> IMDB 电影评论</a>，或者只是一般的文本。</p><p id="8d94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者如果你想零安装，你可以直接从 huggingface 的网站生成文本，只是长度有限。例如，在这里试试<a class="ae ky" href="https://huggingface.co/gpt2" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a>。</p><h1 id="d200" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">让我们生成一些文本！</h1><p id="e7d8" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">正如我所说，你可能见过的大多数 GPT-3 的例子都是精心挑选的。为了进行合理的比较，我将每个语言模型运行 5 次，并为每个模型挑选一个输出。其他的我会放在另一篇博文里，否则，这篇博文会太长。</p><p id="57a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们先来看看通用文本。由于我刚开始在一家公司从事神经搜索，我们将使用一些适当的种子文本:</p><blockquote class="lv lw lx"><p id="3625" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><code class="fe nd ne nf ng b">In short, neural search is a new approach to retrieving information.</code></p></blockquote><h2 id="5896" class="nh mg it bd mh ni nj dn ml nk nl dp mp li nm nn mr lm no np mt lq nq nr mv ns bi translated">GPT-2</h2><p id="c927" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">GPT-2 可以创造惊人的结果(查看<a class="ae ky" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank">说英语的独角兽的例子</a>)，但它需要它的甜蜜时间，吞噬 CPU 和内存。大约 10 分钟后，它吐出了以下内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/7f7cdd32a09587017f9aa9a22fdd7651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bc56cq6aH89Q5wIuYFflRQ.png"/></div></div></figure><blockquote class="lv lw lx"><p id="2b89" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">简而言之，神经搜索是一种检索信息的新方法。在理想的情况下，应该有很多新的数据需要搜索，但是大部分数据已经存储在关系数据库中。这就是为什么大多数时候最好不要在数据库中存储任何信息。在未来，我们想要的是信息可以被简单地搜索到。但是，即使信息很容易被搜索到，仍然存在如何在数据库中组合多个搜索词的问题。组合搜索词的一种方法是使用搜索引擎，但当我们在谷歌或任何其他搜索引擎上搜索某个东西时，它们通常会很好，但有时它们会出错，它们只会显示部分结果，有时它们不会显示所有结果，或者它们会说一些非常具体的东西，但你无法在特定的搜索中找到它。神经搜索最重要的目标之一是让他们更容易地搜索，以便他们能够做出更好的决定。但仍然有一个问题:一些类型的问题并不适合它，如果搜索引擎没有在正确的地方使用正确的工具，这可能会导致大量信息丢失。现在，我认为我们可以从神经搜索中吸取一些教训来解决这个问题...</p></blockquote><p id="0d91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对我来说看起来有点连贯，虽然它没有保持一个清晰的叙述，亲爱的上帝，其中一些连续的句子！</p><h2 id="306e" class="nh mg it bd mh ni nj dn ml nk nl dp mp li nm nn mr lm no np mt lq nq nr mv ns bi translated">蒸馏 2</h2><p id="905e" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">distilGPT2 是 GPT-2 的一个更有效的版本，删除了一些多余的神经元。从它的输出来看，也许神经元太多了！生成每个结果大约需要一分钟:</p><blockquote class="lv lw lx"><p id="76a5" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">简而言之，神经搜索是一种检索信息的新方法。但近年来，该领域鲜有进展，现在有证据表明，它在检测和分析人类皮肤上的神经网络方面更加准确。这是这个故事的要点。中国国家科学研究基金会(CSRF)的研究人员与加州大学圣地亚哥分校的研究人员合作，他们正在研究一种神经成像和学习网络，该网络将绘制和重建人类皮肤上的神经网络。这个大脑项目旨在研究大脑的视觉皮层，以便它可以在不丢失信息的情况下向个人学习。CSRF 还将使用神经网络绘制大脑的感觉皮层和大脑皮层，以及前部和尾部皮层，这是大脑中央皮层的一部分。但这可能不是探索破译神经网络的第一步，神经网络是一种用于搜索各种人的信息模式的方法，包括那些不在药物接受端的人。加州大学圣地亚哥分校(USDA)的研究人员与中国国家科学研究基金会(CSRF)的科学家合作，与 CSRF 合作，开发了一种允许科学家搜索皮肤信息模式的技术。研究人员分析了大脑的感觉...</p></blockquote><p id="57e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们把种子文本扔向一些旨在产生不同东西的东西，比如电影剧本，会怎么样？</p><h2 id="2869" class="nh mg it bd mh ni nj dn ml nk nl dp mp li nm nn mr lm no np mt lq nq nr mv ns bi translated">gpt2 _ 电影 _ 剧本</h2><p id="d360" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">gpt2_film_scripts 是通过<a class="ae ky" rel="noopener" target="_blank" href="/film-script-generation-with-gpt-2-58601b00d371">在 1，300 个剧本上微调 GPT-2，</a>完成的，与常规文本相比，它们有着怪异的间距和边距。当你生成例子时，这真的显示出来了。像 GPT-2(这个模型就是基于它)一样，每个例子需要 10 分钟:</p><blockquote class="lv lw lx"><p id="c3a5" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">简而言之，神经搜索是一种检索信息的新方法。已经有很多很多的研究表明，我们找到的，我们寻找的。这是一种计算机辅助搜索。</p><p id="46cb" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">艾丽斯<br/>我不喜欢那样。我觉得自己像个傻瓜。</p><p id="36d6" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">她还在起床，已经上了一上午的课。她坐在书桌前，研究着电脑屏幕。这是一大堆文件，她很快浏览了一遍，很快注意到一只猫的照片。她盯着照片，拿出一个小文件。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/dabcc658102b673a8e975ae093dbf895.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/1*c18siOLHiuzDtnrIKQ3Ovg.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Via <a class="ae ky" href="https://gfycat.com/thoseevenkinkajou" rel="noopener ugc nofollow" target="_blank"> gfycat </a></p></figure><p id="8e4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所看到的，语言模型已经学会了如何骂人，而且不怕这么做！(我不得不手动审查它的便壶嘴)。我们还可以看到它理解角色台词和舞台方向。就像每个网民一样，它对猫情有独钟。(如果与其他样品相比，它看起来有点短，那是因为它增加了许多间隔(对于 magins ),所以 Medium 剥离了。</p><h2 id="2515" class="nh mg it bd mh ni nj dn ml nk nl dp mp li nm nn mr lm no np mt lq nq nr mv ns bi translated">trekbot</h2><p id="3467" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">我的一个梦想是创作完全由人工智能生成的《星际迷航》剧集。少校数据科学，如果你愿意的话。所以我在《t2》上训练了 gpt2_film_scripts，这是我能找到的每一个《星际迷航》剧本。</p><p id="5773" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">然后……在说了那句悲惨的《星际迷航》双关语后，我的 easy_text_generator 崩溃了。我有一种感觉，这些人工智能可能比我们想象的更聪明(也更情绪化)。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/9069b5018197bab7c5c5908aed9697dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*GqZ74cHMxsRI-QgFn-qlKQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">通过<a class="ae ky" href="https://gfycat.com/scratchycalculatinggerbil-reactions-star-trek-the-next-generation" rel="noopener ugc nofollow" target="_blank"> gfycat </a></p></figure><p id="98e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重新启动后:</p><blockquote class="lv lw lx"><p id="f00c" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">简而言之，神经搜索是一种检索信息的新方法。新的前进方向。</p><p id="9f3b" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">法里斯:关键是神经模式本身，而不是计算机。</p><p id="88dc" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">西斯科:但是电脑可以做到这一点。</p><p id="e306" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">法里斯:这是计算神经网络理论的突破。很明显，它们需要被设计成能够学习、复制，然后分享它们的知识以用于实际应用。</p><p id="2f7d" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">西斯科:那你就有问题了。我们怎么知道会有用？</p><p id="a637" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">法里斯:我们可能永远不会在纸上看到它，但从各方面考虑，神经模式发生器是我见过的最有前途的硬件。</p><p id="a3c5" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">西斯科:我们最终会到达那里的。当我们这么做的时候，我们能相信这个吗？</p><p id="5174" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">[法里斯的办公室]</p><p id="937d" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">法里斯:神经模式发生器将是我见过的最有前途的硬件。</p><p id="2430" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">[船长办公室]</p><p id="d030" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">(莫恩正在星际舰队总部发表演讲，雷丁。)</p><p id="01e1" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">法里斯:我和我的同事花了一年时间开发原型，将于今年年底推出。</p><p id="cbbc" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">西斯科:那会如何影响星际舰队的运作？</p></blockquote><p id="ab42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一点也不差。对于任何了解《星际迷航》的人来说，这听起来很有说服力(尽管 Morn 发表演讲显然很搞笑。)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/1d49a60a9542b1209893beb3a5ef96c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*UraJ9Yav9cxmjVhE8_5I-A.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不太爱说话的早晨。Via <a class="ae ky" href="https://gfycat.com/smartuntimelyangora-star-trek-deep-space-nine-who-mourns-for-morn" rel="noopener ugc nofollow" target="_blank"> gfycat </a></p></figure><h1 id="def3" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">这是一个总结(目前)</h1><p id="b212" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">正如我们在上面看到的，GPT 2 号相当强大。既用于生成通用文本，也用于更具体的用例(如 Star Trek 脚本)。</p><p id="8b68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是对于这些特定的用例，GPT-2 需要大量的数据，以及大量的历元来检查所有的数据。GPT-3 承诺“少量学习”,所以我们只需向它扔几个例子，它就会很快学会这种风格。因此，如果你喜欢《指环王》系列的新书，或者关于<insert product="" here="">的新闻稿，GPT-3 可能是你的语言模型！</insert></p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="b1ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想要一个简单的方法来开始生成你自己的语言，看看<a class="ae ky" href="https://github.com/alexcg1/easy_text_generator" rel="noopener ugc nofollow" target="_blank">easy _ text _ generator repo</a>。我很想看看会有什么结果！</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="8f2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Alex 是纪娜人工智能公司的开源倡导者，电子蝴蝶的建造者，编写糟糕的星际旅行脚本的 janky 语言模型的训练者。</p></div></div>    
</body>
</html>