<html>
<head>
<title>How I created the Workout Movement Counting App using Deep Learning and Optical Flow Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何使用深度学习和光流算法创建锻炼运动计数应用程序</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-i-created-the-workout-movement-counting-app-using-deep-learning-and-optical-flow-89f9d2e087ac?source=collection_archive---------14-----------------------#2020-04-10">https://towardsdatascience.com/how-i-created-the-workout-movement-counting-app-using-deep-learning-and-optical-flow-89f9d2e087ac?source=collection_archive---------14-----------------------#2020-04-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="54e6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">不要自己跟踪动作，让人工智能替你做！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ae712f39b195e6e621d6684185e45e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qh7dpfN70vkrTFatd5HZcg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源<a class="ae ky" href="https://unsplash.com/@aloragriffiths" rel="noopener ugc nofollow" target="_blank">阿洛拉·格里菲斯</a>，经由<a class="ae ky" href="https://unsplash.com/photos/ymBZhfHwEPM" rel="noopener ugc nofollow" target="_blank"> unsplash </a> (CC0)</p></figure><p id="fecd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我喜欢进行锻炼和不同类型的训练，如crossfit，但当训练强度太大或时间太长时，我注意到我经常在计算每次锻炼的运动次数时出错，这可能是因为在训练期间没有专注于运动计数任务，或者下意识地高估了完成的运动次数。作为一名计算机科学理学士三年级的学生，我决定在我的课程工作中解决这个问题，并创建了一个Web应用程序来计算锻炼过程中进行的移动次数。在这篇文章中，我想分享我解决这个问题的方法。你可以在<a class="ae ky" href="https://github.com/artkulak/workout-movement-counting" rel="noopener ugc nofollow" target="_blank"> github库</a>中找到该应用的完整代码。</p><p id="2dc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">算法</strong></p><p id="57b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了执行运动计数，您必须知道身体在每一帧上是向上还是向下运动。通常，为了完成这样的任务，我需要使用一些RNN架构，因为，很明显，你不能只使用一帧来检测运动的方向。他在这张照片上是向上还是向下移动？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/b8cca39aa31c56098fd27ab4ee5e8368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kpN6jGX87geY6DjVSXmYMA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.youtube.com/watch?v=7wblGkVQx3U" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=7wblGkVQx3U</a></p></figure><p id="2887" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但我没有足够的训练数据来建立一个稳健的RNN模型，因为我必须自己准备和标注数据。我试着朝PoseNet模型的方向看，以获得每一帧上每个身体部位的坐标。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/f2eee38a690f12de98eae0228312ead9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/0*E5d6orKItBcs9l0T.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5" rel="noopener">https://medium . com/tensor flow/real-time-human-pose-estimation-in-the-tensor flow-js-7 DD 0 BC 881 cd5</a></p></figure><p id="32b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法也没有好处，原因有几个:</p><ol class=""><li id="fbf7" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu mc md me mf bi translated">如果我在它被训练的相同环境(相同的房间，相同的视频角度，相同的人)中尝试，该模型表现良好，但是要为一个练习制作一个健壮的模型，我仍然需要大量的训练数据。</li><li id="4282" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">没有使用GPU卡的PoseNet的FPS真的很低。</li><li id="8c4a" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">在某些帧上，检测到的身体部位的质量很低。</li></ol><p id="14ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总而言之，我玩了很多不同的模型，它们都在某种程度上给出了一个糟糕的结果。直到有一天我了解了光流算法，尤其是密集光流实现(下图的右边部分)。简而言之，这种算法跟踪像素沿着一定数量的连续帧的运动。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/b5730a029fe8fd37605136c8396c9a00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*9xNmuPiUvtKMspWZ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://nanonets.com/blog/optical-flow/" rel="noopener ugc nofollow" target="_blank">https://nanonets.com/blog/optical-flow/</a></p></figure><p id="8585" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以使用一些数学模型(例如，在OpenCV库中实现)来估计光流，或者可以使用深度学习来直接预测光流，这在复杂的视频场景中给出更好的结果。在我的实现中，我决定坚持使用密集光流算法，它是在python-opencv包中实现的。</p><p id="a4a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是如何用密集光流对一个俯卧撑进行颜色编码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mm"><img src="../Images/aedecd64f5fed776d95b2574d50cf069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aW4WANSVreNvkRhO6Rytaw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">【https://www.youtube.com/watch?v=xoCKHx8Yyj4 T2】号</p></figure><p id="1870" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如你所见，密集光流将向下运动编码为绿色，将向上运动编码为紫色。因此，知道了每个帧的颜色编码表示，我可以很容易地构建一个简单的CNN网络来执行帧的多类分类。我只是在PyTorch中堆叠了一些Conv +池层，这导致了下面的简单架构。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="74eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了训练这个模型，我加载并按帧标记了几个YouTube视频，我自己也准备了一些俯卧撑视频。最后，我有一个彩色编码图像的训练集，包括252个向下移动的帧，202个非上推帧和206个向上移动的帧。我还准备了一个由140个不同动作的帧组成的小验证集。在运行了10个时期的训练循环后，我得到了一个非常令人印象深刻的模型对数损失图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/dc3cc3b0484c1d9b46316b620ae4a283.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*npOvvQwj3NKShYEDLWhovQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练与验证集的对数损失</p></figure><p id="bea9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然，对于模型来说，预测这三个类别并不太难，因为只需用眼睛观察彩色编码的图像就可以很容易地做到。</p><p id="c3e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更重要的是，经过训练的模型能够对框架进行分类，不仅是俯卧撑，还包括俯卧撑、深蹲和引体向上。一般来说，我想这个精确的模型可以很容易地对所有高振幅的运动进行分类，包括上下运动。</p><p id="83ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不过，要对一些练习进行分类，如仰卧起坐或一些低幅度的哑铃运动，最好收集一套新的训练集，并重新训练当前的模型。</p><p id="8022" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">App</strong></p><p id="8475" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了在现实生活中应用我的模型，我使用Django创建了一个小的Web应用程序，在那里我可以创建一个新的锻炼，并在“战斗”环境中尝试我的模型。这是它的样子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e29e2061f0b474aa9b36eafacc8a5429.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Eyqar4acVDdz6NEeVnxLA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">web应用程序的主屏幕</p></figure><p id="e803" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总的来说，在训练的时候，我注意到俯卧撑、深蹲、引体向上的误差在<strong class="lb iu"> 2.5% </strong>左右。对于burpee来说，误差大约在<strong class="lb iu"> 5% </strong>左右，这是因为练习涉及到不止一个上下运动。以下是模型在锻炼过程中计算俯卧撑的方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mm"><img src="../Images/d3c00f8739d997d9ad501281f7db556d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*C_iRZ1vCaW38gmnDk5N8dQ.gif"/></div></div></figure><p id="7760" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p><p id="9d6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，这项工作对我来说是一次很好的经历，因为我必须做大量的研究，并测试锻炼过程中运动计数问题的不同假设。我的时间跟踪器显示，现在我已经在这个应用程序开发上花了大约75个小时，但谁知道呢，如果我决定继续这个项目，让它变得更大，我可能会花更多的时间。谢谢你的阅读！</p><p id="d68e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在我的 <a class="ae ky" href="http://artkulakov.com" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">网站</strong> </a>上查看其他帖子</p></div></div>    
</body>
</html>