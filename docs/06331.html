<html>
<head>
<title>How I built a Face Mask Detector for COVID-19 using PyTorch Lightning (updated PL V.1.3.5)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何使用PyTorch Lightning为新冠肺炎构建了一个面具检测器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-i-built-a-face-mask-detector-for-covid-19-using-pytorch-lightning-67eb3752fd61?source=collection_archive---------6-----------------------#2020-05-21">https://towardsdatascience.com/how-i-built-a-face-mask-detector-for-covid-19-using-pytorch-lightning-67eb3752fd61?source=collection_archive---------6-----------------------#2020-05-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/2c1dd68d72956be339a8c34dfd1f0232.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/1*hqwDqZZp8NSJlh6DYhk19A.gif"/></div></figure><h1 id="16ee" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">动机</h1><p id="ea4e" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在法国隔离结束的前几天，我在看新闻，无意中发现了一篇文章:<a class="ae lq" href="https://www.theverge.com/2020/5/7/21250357/france-masks-public-transport-mandatory-ai-surveillance-camera-software" rel="noopener ugc nofollow" target="_blank">法国正在使用人工智能检查人们是否在公共交通工具上戴口罩</a>。</p><blockquote class="lr ls lt"><p id="7f58" class="ks kt lu ku b kv lv kx ky kz lw lb lc lx ly lf lg lz ma lj lk mb mc ln lo lp ij bi translated">创建该项目的法国初创公司DatakaLab表示，目标不是识别或惩罚不戴口罩的人，而是生成匿名统计数据，帮助当局预测未来新冠肺炎疫情的爆发</p></blockquote><p id="1a6b" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">于是我决定试一试，自己搭建一个口罩检测仪，检测某人是否戴口罩。</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi md"><img src="../Images/850df496a01070b30c03bdcd0b227221.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*n_pbux8wHoXQ1XAjTGrcnQ.jpeg"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated"><a class="ae lq" href="https://mc.ai/deep-dive-into-deep-learning%E2%80%8A-%E2%80%8Apart-1-demystifying-deep-learning-using-6-jars/" rel="noopener ugc nofollow" target="_blank">信号源</a></p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="f049" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">1.资料组</h1><p id="3da7" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为了训练深度学习模型来分类一个人是否戴着面具，我们需要找到一个好的数据集，其中包含两个类别的大量图像:</p><ul class=""><li id="cdf4" class="my mz iq ku b kv lv kz lw ld na lh nb ll nc lp nd ne nf ng bi translated">戴着面具</li><li id="5ef1" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp nd ne nf ng bi translated">没有戴面具</li></ul><p id="4f5e" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated"><a class="ae lq" href="https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset" rel="noopener ugc nofollow" target="_blank">真实世界蒙面人脸数据集(RMFD) </a>提供了我们所需要的！该数据集是为面部识别目的而创建的。然而，我们将使用它来检测面具。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="9a3b" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.步伐</h1><p id="8306" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这篇文章的其余部分按以下方式组织:</p><p id="14b2" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated"><strong class="ku ir"> 2.1。数据提取<br/> 2.2。构建数据集类<br/> 2.3。构建我们的面罩检测器模型<br/> 2.4。训练我们的模型<br/> 2.5。在真实数据上测试我们的模型。结果</strong></p><p id="f15a" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">事不宜迟，让我们直接开始吧！</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="nm nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated"><a class="ae lq" href="https://tenor.com/0EFO.gif" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="fdce" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.1.数据析取</h1><p id="0d8f" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">RMFD提供了两个数据集:</p><ol class=""><li id="d5f8" class="my mz iq ku b kv lv kz lw ld na lh nb ll nc lp no ne nf ng bi translated">真实世界蒙面人脸识别数据集:包含525人的5000张蒙面人脸和90000张正常人脸。</li><li id="cbcc" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp no ne nf ng bi translated">模拟掩蔽人脸识别数据集。</li></ol><p id="3570" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">在这个实验中，我们将使用第一个数据集。下载并解压缩数据集后，其结构如下所示:</p><pre class="me mf mg mh gt np nq nr ns aw nt bi"><span id="da49" class="nu jv iq nq b gy nv nw l nx ny">self-built-masked-face-recognition-dataset<br/>├AFDB_masked_face_dataset<br/>│ ├subject-id<br/>│ │ ├image-id.jpg<br/>│ │ └...<br/>│ └...<br/>└AFDB_face_dataset<br/>  ├subject-id<br/>  │ ├image-id.jpg<br/>  │ └...<br/>  └...</span></pre><p id="0ddb" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">我们通过迭代图像来创建我们的熊猫<code class="fe nz oa ob nq b">DataFrame</code>,如果脸部没有被遮罩，则给每张图像分配一个标签<code class="fe nz oa ob nq b">0</code>,如果脸部被遮罩，则分配一个标签<code class="fe nz oa ob nq b">1</code>。这个数据集的图像已经在人脸周围被裁剪了，所以我们不需要从每个图像中提取人脸。<br/>以下代码说明了数据提取过程:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">将图片存储在熊猫数据框中，并贴上相应的标签</p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="e659" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.2.构建数据集类</h1><p id="9f25" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">现在我们已经准备好了pandas数据框架，是时候构建Dataset类了，它将用于以PyTorch可解释的方式批量查询样本。我们的模型将接受100x100的图像作为输入，因此我们在查询它时转换每个样本图像，将它的大小调整为100x100，然后将其转换为一个<code class="fe nz oa ob nq b">Tensor</code>，这是PyTorch可以操作的基本数据类型:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">数据集模块</p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="95c6" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.3.建立我们的面罩检测器模型</h1><p id="43c8" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">现在是有趣的部分！</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="nm nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated"><a class="ae lq" href="https://tenor.com/9oLA.gif" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="5826" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">我们将使用<a class="ae lq" href="https://github.com/PyTorchLightning/pytorch-lightning" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning </a>，它是PyTorch的一个薄包装。PyTorch Lightning在一个类中有效地构建了您的代码，该类包含了我们定义和训练模型所需的所有内容，并且您可以覆盖根据您的需求提供的任何方法，从而在避免意大利面条式代码的同时使其易于扩展。</p><p id="2009" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">PyTorch Lightning公开了许多用于训练/验证循环的方法。但是，我们将根据需要使用其中一些。以下是我们将要覆盖的方法，并且将在内部按以下顺序调用:</p><p id="bdbb" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated"><strong class="ku ir"> 1。设置:</strong></p><ul class=""><li id="851e" class="my mz iq ku b kv lv kz lw ld na lh nb ll nc lp nd ne nf ng bi translated">__init__()</li><li id="e3c0" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp nd ne nf ng bi translated">准备_数据()</li><li id="a552" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp nd ne nf ng bi translated">configure_optimizer()</li><li id="fd56" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp nd ne nf ng bi translated">train_dataloader()</li><li id="0bbc" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp nd ne nf ng bi translated">val_dataloader()</li></ul><p id="24ff" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated"><strong class="ku ir"> 2。训练循环:</strong></p><ul class=""><li id="917b" class="my mz iq ku b kv lv kz lw ld na lh nb ll nc lp nd ne nf ng bi translated">训练_步骤()</li><li id="2bdf" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp nd ne nf ng bi translated">training_epoch_end()</li></ul><p id="2e4f" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated"><strong class="ku ir"> 3。验证循环:</strong></p><ul class=""><li id="95fc" class="my mz iq ku b kv lv kz lw ld na lh nb ll nc lp nd ne nf ng bi translated">验证_步骤()</li><li id="f8ab" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp nd ne nf ng bi translated">validation_epoch_end()</li></ul></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="bb3c" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.3.1.定义模型和正向传递</h1><p id="16ea" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为了定义我们的模型，我们对PyTorch Lightning的<code class="fe nz oa ob nq b">LightningModule</code>进行了子类化，并定义了我们的模型架构以及向前传递。我们还使用由<code class="fe nz oa ob nq b">TorchMetrics</code>包提供的<code class="fe nz oa ob nq b">Accuracy</code>类，它将负责为我们计算训练/验证的准确性。我们将保持简单，使用4个卷积层，然后是2个线性层。我们将使用<code class="fe nz oa ob nq b">ReLU</code>作为激活函数，使用<code class="fe nz oa ob nq b">MaxPool2d</code>作为池层。然后我们用<code class="fe nz oa ob nq b">xavier_uniform</code>初始化这些层的权重，因为这将使网络训练更好:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">CNN模型定义</p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="7e7c" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.3.2.为模型准备数据</h1><p id="3a5e" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们的数据集是不平衡的(5，000个蒙面人脸对90，000个非蒙面人脸)。因此，当将数据集划分为训练/验证时，我们需要在训练/验证中保持与整个数据集相同的样本比例。我们通过使用<code class="fe nz oa ob nq b">sklearn</code>的<code class="fe nz oa ob nq b">train_test_split</code>函数来完成，我们将数据集的标签传递给它的<code class="fe nz oa ob nq b">stratisfy</code>参数，它将为我们完成剩下的工作。我们将数据集的70%用于训练，30%用于验证:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">prepare_data()方法</p></figure><p id="64cd" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">在处理不平衡数据时，我们需要将这些信息传递给损失函数，以避免优化器的步长不成比例。为此，我们根据每个类在数据集中的可表示性为其分配一个权重。</p><p id="8fba" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">我们给样本数量少的类分配更多的权重，这样，如果网络在预测这些类的标签时出错，它将受到更多的惩罚。而样本数量多的类，我们给它们分配一个较小的权重。这使得我们的网络训练与班级比例无关。为每个类别选择权重的一个好的经验法则是使用以下公式:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">不平衡数据的类权重</p></figure><p id="fda5" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">这转化为以下代码:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">具有适应的类权重的交叉熵</p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="01ee" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.3.3.数据加载器</h1><p id="b30e" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们将定义用于培训和验证的数据加载器。我们使用一批尺寸为32的产品来训练我们的模型。我们每次都会打乱我们的训练批次样本，以便我们的模型可以通过以非重复的方式接收数据来更好地训练。为了减少加载批量样本的时间(这可能是训练循环中的瓶颈),我们将workers的数量设置为4，这将执行多进程数据加载:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">培训/验证数据加载器</p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="afc1" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.3.4.配置优化程序</h1><p id="9536" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们通过覆盖<code class="fe nz oa ob nq b">configure_optimizers()</code>方法并返回所需的优化器来定义我们的优化器。出于本文的目的，我们将使用<code class="fe nz oa ob nq b">Adam</code>，我们将学习率固定为<code class="fe nz oa ob nq b">0.00001</code>:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">configure _ optimizers()方法</p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="b49f" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.3.5.训练步骤</h1><p id="8471" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在训练步骤中，我们接收一批样本，通过正向传递将它们传递给我们的模型，并计算该批样本的损失。我们还可以记录损失，PyTorch Lightning会自动为我们创建TensorBoard的日志文件:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">培训_步骤()方法</p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="488a" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.3.6.训练时期结束</h1><p id="f17f" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在<code class="fe nz oa ob nq b">training_epoch_end()</code>中，我们计算训练精度并记录下来，以便稍后在TensorBoard中可视化。然后，我们重置训练精度变量，以便在下一个时期，精度不携带来自先前时期的值:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="9434" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.3.7.验证步骤</h1><p id="611e" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在每个训练时期结束时，对每批验证数据调用<code class="fe nz oa ob nq b">validation_step()</code>,我们计算准确度和损失，并在字典中返回损失。返回值将用于下一部分:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">validation_step()方法</p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="475c" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.3.8.验证时期结束</h1><p id="4257" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在<code class="fe nz oa ob nq b">validation_epoch_end()</code>中，我们接收从<code class="fe nz oa ob nq b">validation_step()</code>(来自前一部分)返回的所有数据。我们计算平均精度和损耗，并记录下来，以便稍后在TensorBoard中直观显示:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">validation_epoch_end()方法</p></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="3cac" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.4.训练我们的模型</h1><p id="b75b" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为了训练我们的模型，我们简单地初始化我们的<code class="fe nz oa ob nq b">MaskDetector</code>对象，并将其传递给PyTorch Lightning提供的<code class="fe nz oa ob nq b">Trainer</code>类的<code class="fe nz oa ob nq b">fit()</code>方法。我们还定义了一个模型检查点回调和一个TensorBoard logger，我们希望以最好的准确性和最低的损失保存模型。我们将为10个时期训练我们的模型:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">培训模式</p></figure><p id="5231" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">我们可以看到，验证损失在各个时期都在减少:</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi od"><img src="../Images/9816467cae4a12a880e7e4fafa010957.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OYOOIvHiNgBKphWfTuQh8w.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">验证损失</p></figure><p id="67f2" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">我们的模型的验证精度在第8个纪元达到最高峰，达到99%的精度。</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="oe of di og bf oh"><div class="gh gi oi"><img src="../Images/d20fa6916eec3706c01ee447949448f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rOCR12Ncdl27_XAmkX9c9Q.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">验证准确性—保存最佳模型</p></figure><p id="3ea9" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">在纪元8(红色箭头所指的地方)之后，我们的模型开始过度拟合。因此，验证准确性开始下降。因此，我们将采用epoch 8的保存模型，并使用它在真实数据上进行测试！</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="6acb" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.5.在真实视频上测试我们的模型</h1><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="nm nn l"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated"><a class="ae lq" href="https://tenor.com/view/the-moment-of-truth-baby-truth-facts-reveal-gif-8357516" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="8dfb" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">为了在真实数据上测试我们的模型，我们需要使用一个对人脸遮挡具有鲁棒性的人脸检测模型。幸运的是，OpenCV有一个深度学习人脸检测模型，我们可以使用。这种深度学习模型是对Haar-Cascade模型的更准确的替代，它的检测框架是矩形而不是正方形。因此，面部框架可以适合整个面部，而不捕获背景的部分，这可能干扰我们的面部掩模模型预测。</p><p id="dc4c" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">关于如何使用OpenCV的深度学习人脸检测的一个很好的教程如下:</p><div class="oj ok gp gr ol om"><a href="https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd ir gy z fp or fr fs os fu fw ip bi translated">基于OpenCV和深度学习的人脸检测——PyImageSearch</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">今天，我将与您分享一个关于OpenCV库的鲜为人知的秘密:您可以快速、准确地执行…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">www.pyimagesearch.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa js om"/></div></div></a></div></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="3402" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">为了对视频进行推理，我们将使用上一节中保存的模型，并处理每一帧:</p><ul class=""><li id="4b44" class="my mz iq ku b kv lv kz lw ld na lh nb ll nc lp nd ne nf ng bi translated">提取人脸</li><li id="6aa4" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp nd ne nf ng bi translated">把它们传给我们的面罩探测器模型</li><li id="32a4" class="my mz iq ku b kv nh kz ni ld nj lh nk ll nl lp nd ne nf ng bi translated">在检测到的人脸周围绘制一个边界框，以及由我们的模型计算的预测。</li></ul><p id="4968" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">以下是处理视频代码的摘录:</p><figure class="me mf mg mh gt jr"><div class="bz fp l di"><div class="oc nn l"/></div></figure></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="5919" class="ju jv iq bd jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn mx kp kq kr bi translated">2.6.结果</h1><p id="29ed" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我让几个朋友给自己拍照，戴上面具，然后摘下来。这些就是结果！看起来我们的模特即使带着定制的面具也很棒！我们模型的权重文件大小约为8 Mb，在CPU上的推理几乎是实时的！！👌</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/3c888ebf1ec6c2adf85e0ee1d694233d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/1*FdOe2xya4Ozh_2x5d-H-Zw.gif"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">演职员表:<a class="ae lq" href="https://www.instagram.com/elisa_diagostino/" rel="noopener ugc nofollow" target="_blank">伊莉莎</a>和<a class="ae lq" href="https://www.instagram.com/veronicamatar/" rel="noopener ugc nofollow" target="_blank">维罗妮卡</a></p></figure><p id="74e4" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated">完整的代码可以在<a class="ae lq" href="https://github.com/JadHADDAD92/covid-mask-detector" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到😃</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="d3c4" class="pw-post-body-paragraph ks kt iq ku b kv lv kx ky kz lw lb lc ld ly lf lg lh ma lj lk ll mc ln lo lp ij bi translated"><strong class="ku ir"> <em class="lu">编者按:</em> </strong> <em class="lu"> </em> <a class="ae lq" href="http://towardsdatascience.com/" rel="noopener" target="_blank"> <em class="lu">走向数据科学</em> </a> <em class="lu">是一份以数据科学和机器学习研究为主的中型刊物。我们不是健康专家或流行病学家，本文的观点不应被解释为专业建议。想了解更多关于疫情冠状病毒的信息，可以点击</em> <a class="ae lq" href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports" rel="noopener ugc nofollow" target="_blank"> <em class="lu">这里</em> </a> <em class="lu">。</em></p></div></div>    
</body>
</html>