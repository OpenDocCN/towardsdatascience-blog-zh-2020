<html>
<head>
<title>Making big moves in Big Data with Hadoop, Hive, Parquet, Hue and Docker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用 Hadoop、Hive、Parquet、Hue 和 Docker 在大数据领域取得重大进展</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/making-big-moves-in-big-data-with-hadoop-hive-parquet-hue-and-docker-320a52ca175?source=collection_archive---------7-----------------------#2020-01-24">https://towardsdatascience.com/making-big-moves-in-big-data-with-hadoop-hive-parquet-hue-and-docker-320a52ca175?source=collection_archive---------7-----------------------#2020-01-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2976" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在这篇大数据简介中跳跃和奔跑</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5febd67bd6367e42da560b89ee7dc333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nK8paS9zt_LqsU7fqSAuhw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">2020 年大多数大公司的数据是什么样的。说真的。</p></figure><p id="95a2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文的目标是向您介绍大数据领域的一些关键概念。在阅读完这篇文章之后——可能还需要一些额外的谷歌搜索——你应该能够(或多或少)理解整个 Hadoop 是如何工作的。</p><p id="0817" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，在本文中更准确地说，您将:</p><ul class=""><li id="8cf7" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">学习很多定义(耶)</li><li id="3585" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">通过 docker-compose，使用一些附加功能构建一个 Hadoop 集群。</li><li id="738d" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">了解拼花文件以及如何将 csv 数据集转换为拼花文件。</li><li id="2dfe" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">对您的拼花文件运行 SQL(技术上是 HiveQL，但它非常类似)查询，就像与 Hive 无关一样。</li><li id="fe3a" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">此外，预计有一些 Docker 和 docker-compose，运行 Python 脚本等基本知识。—没什么疯狂的，但如果你事先知道会更好。</li></ul><p id="771b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你已经在使用 Hadoop 生态系统的替代产品——cool——这篇文章更适合那些由于工作、大学等原因必须熟悉 Hadoop 的读者。这只是大数据难题的一个“解决方案”,各有利弊。</p><p id="0672" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">大数据:</strong>这是一个大数据。<em class="mf">大数据通常包括数据集，其大小超出了常用软件工具在可容忍的运行时间内捕获、筛选、管理和处理数据的能力。</em>现在你可能会问一个简单的问题(很多人都问过):“大数据有多大？”坦率地说，这是一个非常困难的问题，取决于技术发展的速度，今天被认为是“大”数据的东西明天可能就是“小”数据。尽管如此，上面的定义是非常永恒的，因为它指的是超出常用工具能力的尺寸——这是你的参考线；因此，在 2020 年，让我们咬紧牙关，假设以下情况属实:当您开始处理数据库及以上数据库中两位数的 TB 数据集时，您可能会触及一些更普通的工具的极限，也许是时候研究分布式计算了，可能还有本文。</p><p id="e020" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Hadoop: 一个框架，允许使用简单的编程模型在计算机集群上分布式处理大型数据集。它旨在从单个服务器扩展到数千台机器，每台机器都提供本地计算和存储。您应该了解的 3 个最重要的核心模块是:</p><ul class=""><li id="8964" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">(存储)HDFS:一种分布式文件系统，同时具有高吞吐量访问和冗余(跨集群维护所有文件的副本)</li><li id="8192" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">又一个资源协商者:一个作业调度和集群资源管理的框架，例如哪些节点是可用的等等。</li><li id="a940" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">(处理)MapReduce:一个基于 YARN 的大数据集并行处理系统。这是用于跨集群节点无缝分配计算任务的主要算法。你可以在网上阅读 MapReduce 的起源。流行的替代品是 TEZ 和 Spark，它们后来被开发出来用于更有效地处理数据。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/97028d9c5d4e1ae0b53ef8993b7fc26e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*UqX1E9xO8dPaCGbMAU0pHw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在一张图中展示 Hadoop 生态系统的各个部分。现在关注 HDFS，纱，MapReduce 和蜂巢。</p></figure><p id="1895" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> Hive: </strong>一个数据仓库软件，使用 SQL 帮助读取、写入和管理驻留在分布式存储中的大型数据集。结构可以被投影到已经存储的数据上。提供了命令行工具和 JDBC 驱动程序来将用户连接到 Hive。因此，基本上 Hive 位于前面提到的 Hadoop 堆栈之上，它允许您在集群上直接使用 SQL。</p><p id="c9ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> Hue: </strong>一个用于数据库的开源 SQL 助手&amp;数据仓库，即一个用于查看 HDFS、Hive 等的简单 GUI。对于初学者来说非常方便！它由 Cloudera 维护，你可以在 GitHub 上找到它。</p><p id="27a4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> Parquet: </strong>一种柱状存储*格式，适用于 Hadoop 生态系统中的任何项目。你可以在下面的解释中了解为什么这是一个关于大数据集的好主意。同样，有许多替代方案，但这项技术是免费的、开源的，并在整个行业的生产中广泛使用。</p><p id="97de" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">*列存储:在普通的基于行的数据库(如 MySQL)中，数据是按行存储的，如果无法将数据存储在一个块中，这些数据将分布在不同的块中。现在，如果您的数据中有许多列和行分布在多个块中，那么事情会变得非常慢。这就是为什么您可以将每一列存储在单独的块中。在这种情况下，你可以通过访问一个块来访问一列的所有数据。此处对概念<a class="ae mh" href="https://docs.aws.amazon.com/redshift/latest/dg/c_columnar_storage_disk_mem_mgmnt.html" rel="noopener ugc nofollow" target="_blank">有更长的解释。正如 AWS 所言(与 Parquet 无关，但仍然正确):<em class="mf">“数据库表的列存储是优化分析查询性能的一个重要因素，因为它大大降低了整体磁盘 I/O 需求，并减少了需要从磁盘加载的数据量。”</em> </a><a class="ae mh" href="https://databricks.com/glossary/what-is-parquet" rel="noopener ugc nofollow" target="_blank">这里的</a>也是对 CSV 的另一种比较，它显示了你可以节省多少存储空间，以及你可以期待什么样的加速<em class="mf">。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/6ea2a0735e62300bbf216f5bf34f24b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*1o_8p76qaV-dYSgVtkg3aA.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">只是一个伟大的大白鲨参考，这是在这里只是为了照亮你的心情，如果文章已经太多了。</p></figure><p id="e148" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">建造某物</strong></p><p id="1171" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">好的。是时候做点什么了！即一个 Hadoop 集群，上面有 Hive，可以对存储在 HDFS 的 Parquet 文件运行 SQL 查询，同时在 Hue 中可视化所有内容。这句话现在比文章开头更有意义吗？酷毙了。</p><p id="c717" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有很多方法可以做到这一点，Hadoop 以运行基于“商用硬件”构建的计算机集群而闻名，但由于这只是一个学习练习，所以使用 docker-compose 在 Docker 中快速构建一个具有上述堆栈的小型 Hadoop 集群会更容易一些——当然，您也可以在 Kubernetes 中这样做，但这超出了本文的范围。这里的设置甚至不会接近生产，但本文应该只是作为您大数据之旅的一个门户。</p><p id="816a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是这篇文章的回复:</p><div class="mj mk gp gr ml mm"><a href="https://github.com/tech4242/docker-hadoop-hive-parquet" rel="noopener  ugc nofollow" target="_blank"><div class="mn ab fo"><div class="mo ab mp cl cj mq"><h2 class="bd ir gy z fp mr fr fs ms fu fw ip bi translated">tech 4242/docker-Hadoop-hive-parquet</h2><div class="mt l"><h3 class="bd b gy z fp mr fr fs ms fu fw dk translated">这个项目将展示如何用 Hive 启动 Hadoop 集群，以便在 Parquet 文件上运行 SQL 查询…</h3></div><div class="mu l"><p class="bd b dl z fp mr fr fs ms fu fw dk translated">github.com</p></div></div><div class="mv l"><div class="mw l mx my mz mv na kp mm"/></div></div></a></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/b9fad75d9cd942f42b5335eea280c7df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X-TiP3PJPrkndqNxw88IgQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">资源库中 docker-compose 文件的更好视图，它应该粗略地勾勒出项目的架构。</p></figure><p id="e992" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">Docker</strong>中实现的一些亮点</p><p id="a1d1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这并不像最初想的那么简单，所以如果你想进一步定制的话，这里有一些来自开发的提示。本文的重点也不是给你一个 Docker 和 docker-compose 的速成课程，所以这一节很简短，只强调一些你可能遇到困难的地方。</p><ul class=""><li id="c0a9" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">如果您想让任何东西与 Hue 一起工作，您需要通过挂载 hue-overrides.ini 文件来覆盖 Hue 的默认配置(您可以在 repo 和 docker-compose 中的覆盖中找到它)。很明显对吗？眨眼眨眼。</li><li id="2383" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">在 hue-overrides.ini 中，您应该看到:[[database]] = &gt;这是内部的 hue 数据库，[[hdfs_clusters]] = &gt;连接到 hdfs 以查看 Hue 中的文件，[[yarn_clusters]] = &gt;设置 yarn 和[bewax]= &gt;连接到 Hive 以运行 Hue 中的 SQL 查询。</li><li id="0f3d" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">如果在 hue-overrides.ini 中没有这一行<em class="mf"> thrift_version=7 </em>，hue 将拒绝连接到 Hive (=Thrift)服务器，因为它默认为过高的 Hive 服务器版本。这花了几个小时。</li><li id="400a" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">如果您使用 Hue 的默认 SQLite DB，当您尝试连接到 Hive 时，将会得到“database locked”消息= &gt;这就是 docker-compose 文件中有 db-hue Postgres DB 的原因。关于 SQLite 不适合多线程环境的一些事情在这里<a class="ae mh" href="https://mapr.com/community/s/question/0D50L00006BIsdlSAD/database-is-locked-in-hue" rel="noopener ugc nofollow" target="_blank">描述</a>。Cloudera 应该处理他们的错误信息…</li><li id="9520" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">hadoop-hive.env 中的 POSTGRES_DB、POSTGRES_USER、POSTGRES_PASSWORD 可以与官方 postgres Docker 映像一起使用，以便在启动容器时直接创建 DB 用户。检查。</li><li id="db9b" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">注意你的 5432 端口，不要多次暴露它，因为 PGDB 为这个项目运行了不止一次(一次作为 Hive 的 metastore，一次作为 hue 的 DB)</li></ul><p id="1bc7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">TL；博士接下来的步骤</strong></p><p id="cf50" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">好的。对没有耐心的工程师来说，接下来会发生什么的简短总结:</p><ol class=""><li id="f8e9" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq nc lx ly lz bi translated">用 docker-compose up 启动 Hue、Hive 和你的 Hadoop 节点</li><li id="b7cf" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq nc lx ly lz bi translated">从 Kaggle 下载一个. csv 数据集，并使用提供的 Python 脚本进行转换</li><li id="3f9b" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq nc lx ly lz bi translated">导入所说的拼花文件到 HDFS 通过色调和预览它，以确保一切正常</li><li id="8f42" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq nc lx ly lz bi translated">在使用 parquet-tools CLI 工具检查模式后，使用 Parquet 文件模式创建空的配置单元表</li><li id="5137" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq nc lx ly lz bi translated">将文件从 HDFS 导入到 Hive 的表中</li><li id="9032" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq nc lx ly lz bi translated">运行一些 SQL 查询！</li></ol><p id="4ca0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">启动集群，用 docker-compose 启动 Hue</strong></p><p id="e5c0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">好了，既然一切都已经设置好了，只需在您的计算机上克隆存储库，并在您的终端中键入 docker-compose up。就是这样。然后转到 localhost:8888，您应该(在设置 Hue 的初始密码后)看到这个屏幕:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/18037247960c003808591bb4b33224db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mDnU-J3JjauEkSi1KmgryA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">这个屏幕显示了您的 Hadoop 集群的 HDFS，而侧栏显示了 Hive 的 metastore 中的 DB 表——在本例中这两个表都是空的。</p></figure><p id="6623" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">在 HDFS 上传拼花文件并在 Hue 中预览</strong></p><p id="3631" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当试图在 Hue 中打开一些(相当多的)拼花文件时，您会得到以下错误消息:</p><p id="cbb8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mf">“无法读取拼花文件”</em></p><p id="b035" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在您的 docker-compose 日志中:</p><p id="47ed" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mf">名称错误:全局名称‘snappy’未定义</em></p><p id="92a4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">事实证明，Hue 不支持 snappy 压缩，这是 pandas 等许多拼花转换工具的默认设置。除了重新创建您的拼花文件(如果他们使用 snappy)之外，没有其他解决方法。Cloudera 有史以来最差的 UX…</p><p id="eed0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在 GitHub 存储库中，您将找到一个 parquet_converter.py，它使用 pandas 并指定压缩为 None，因此不会默认为 snappy，因为这会破坏 Hue。这意味着你可以从 Kaggle 中获取任何数据集。csv 格式，并使用提供的 Python 模块将其转换为 Parquet。</p><p id="f3bd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这一点上——如果你不喜欢 CLI——最好的建议是你忘记色调，直接使用配置单元和 HDFS 为你的拼花文件。但是如果你像我一样坚持使用 Hue，你可以看到一份来自 Kaggle 的<a class="ae mh" href="https://www.kaggle.com/ferhat00/uk-flight-stats-2018/data" rel="noopener ugc nofollow" target="_blank">英国守时统计报告，它是用上面提到的 Python 脚本转换的，然后上传为一个文件:</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/3e4cc6800697bb6cc45ee3adfa6c9dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MMHhrG_LitLVSUeuhvUP0w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">当您单击成功导入的拼花文件时，文件浏览器显示为 Hue。你可以从左边黑色的边栏进入文件浏览器。</p></figure><p id="dbc6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">从您的 Parquet 文件和模式创建一个配置单元表</strong></p><p id="ad2a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在看到您的数据被正确导入后，您可以创建您的 Hive 表。为此，您应该在您转换文件的文件夹(可能是/your_github_clone/data)中的命令行中运行以下命令:</p><p id="da31" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">工具模式 201801 _ 守时 _ 统计 _ 完整 _ 分析</p><p id="3d2f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这将输出创建色调表所需的模式(UTF8 =色调字符串):</p><p id="6c25" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mf">消息模式{ <br/>可选二进制 run _ date(UTF8)；<br/>可选 int64 reporting _ period<br/>可选二进制报告 _ airport(UTF8)；<br/>可选二进制 origin _ destination _ country(UTF8)；</em></p><p id="660f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">创建表格的时间:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/5344c842a92a073f61b935a805d2adc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2am9jMchWp7LsCHRmrB1cQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">您创建的新表格的预览。转到黑色侧边栏中的 DB 图标，使用上面描述的模式手动创建一个新表。然后点击黑色侧边栏中的导入按钮，将您的拼花文件导入到空桌子中。之后，您应该会看到上面的屏幕。</p></figure><p id="1d5c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">运行 SQL 查询</strong></p><p id="b145" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">运行 SQL 查询是承诺过的，应该会实现。Hue 侧边栏的第一个图标是它的查询编辑器。</p><p id="9744" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果您想找到所有从波兰起飞的平均延误超过 10 分钟的航班，该怎么办？</p><p id="07ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">SELECT * FROM ` 2018 _ 守时 _ 统计`其中始发地 _ 目的地 _ 国家= '波兰'，平均 _ 延误 _ 分钟&gt; = 10；</p><p id="6798" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">编辑器中的自动完成特性非常棒，所以即使您是 SQL 新手，也应该能够轻松地处理数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/4fee0fd2e6a190b93ab48982bad7799a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P_aR3ptRqeqVNJf_Zi8WDA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">最后。</p></figure><p id="399f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">该放手了</strong></p><p id="5385" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">亲爱的读者，很遗憾你已经到了这篇文章的结尾。如果你觉得这个旅程应该有续集，请在下面的评论中写下。因此，概括地说，您学习了如何使用 Hive 运行 Hadoop 集群来运行 SQL 查询，同时使用 docker-compose 可视化 Hue 中的所有内容。还不错。</p><p id="ecdd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这当然是对 Hadoop 可能实现的功能的一个非常<em class="mf">非常</em>简化的介绍，但是您可能刚刚开始涉足这一领域，所以请给自己一些时间，在这些知识和基础设施的基础上进行构建。此外，还有很棒的在线课程，你接下来可以去看看。</p><p id="69e1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">展望 2020 年及以后</strong></p><p id="ccdc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，如果你在过去几年中一直在收听 Hadoop 的生态系统，你就会看到市场上最大的两家公司——cloud era 和 Hortonworks — <a class="ae mh" href="https://techcrunch.com/2019/01/03/cloudera-and-hortonworks-finalize-their-merger/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAFdWl96BCgH521hvgxIYTl5hVRxsg-B6Nj6_q5C9nY3_SVtz7qmGHpnGmuLxoZhv7_OXLaYSmtuQlD2BcGGKqyaT_Vz_mgfpTaE7JZZ241vBM43dLmYQsoSiqK8lidE-92bDNI69PaxqA1Z6tnjx-kUAGfvrD9zL3Bvt6j4uufAo" rel="noopener ugc nofollow" target="_blank">大约在一年前合并了</a>,当时 Hadoop 大数据市场发展缓慢。事实上，人们似乎对 Kubernetes 比对更老的 Hadoop 特定技术更感兴趣，如用于资源管理和编排的 YARN，对 PyTorch 等 DL 框架的快速采用，以及对老化的 Hadoop 堆栈的完美风暴的形成。尽管如此，像 Apache Spark 这样的项目仍在稳步前进，例如引入 Kubernetes 作为纱线的替代品。生态系统激动人心的时刻！</p><p id="c9dd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">来源:</p><ul class=""><li id="6d6b" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">2020 年 1 月 17 日，<a class="ae mh" href="https://unsplash.com/@egnaro?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">里克·梅森</a>在<a class="ae mh" href="https://unsplash.com/s/photos/lego-bricks?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</li><li id="b73c" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">Hadoop 架构图:<a class="ae mh" href="https://2.bp.blogspot.com/-w7KeAnwWnBQ/WfYBJzgtvQI/AAAAAAAAAMk/D58SpZfK7lkJ8QnKnQZW268mKzRvuOOnACLcBGAs/s640/HadoopStack.png" rel="noopener ugc nofollow" target="_blank">https://2 . BP . blogspot . com/-w7 keanwwnbq/WfYBJzgtvQI/aaaaaaaaaaamk/d 58 spzfk 7 lkj 8 qnknqzw 268 mkzrvuoonaclcbgas/s640/Hadoop stack . png</a>，2020 年 1 月 23 日</li><li id="df99" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><a class="ae mh" href="https://hadoop.apache.org/" rel="noopener ugc nofollow" target="_blank">https://hadoop.apache.org/</a>，2020 年 1 月 17 日</li><li id="1575" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">2020 年 1 月 17 日，https://hive.apache.org/</li><li id="07c8" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">2020 年 1 月 17 日，http://parquet.apache.org/</li><li id="b27b" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><a class="ae mh" href="https://docs.aws.amazon.com/redshift/latest/dg/c_columnar_storage_disk_mem_mgmnt.html" rel="noopener ugc nofollow" target="_blank">https://docs . AWS . Amazon . com/redshift/latest/DG/c _ column _ storage _ disk _ mem _ MGM nt . html</a>，17.01.2020</li><li id="7e49" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">斯尼德斯角；Matzat，u；美国大学 reips(2012 年)。“‘大数据’:互联网领域的知识大空白”。<em class="mf">国际互联网科学杂志</em>。7:1–5.</li><li id="4c4d" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">2020 年 1 月 19 日，https://pbs.twimg.com/media/BiZiNmXCAAA2n8U.jpg</li></ul></div></div>    
</body>
</html>