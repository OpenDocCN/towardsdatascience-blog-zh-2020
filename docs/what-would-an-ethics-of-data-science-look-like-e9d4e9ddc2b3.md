# 数据科学的伦理会是什么样的？

> 原文：<https://towardsdatascience.com/what-would-an-ethics-of-data-science-look-like-e9d4e9ddc2b3?source=collection_archive---------33----------------------->

![](img/7bb52d5a50ef5ec747f7af43cc4d2a8a.png)

卢克·迈克尔在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

自从 2016 年[通用数据保护条例](https://en.wikipedia.org/wiki/General_Data_Protection_Regulation) (GDPR)首次公开制定以来，我们见证了对机器学习道德相关主题的兴趣和工作的激增。现在世界各地都有[公平、负责、透明的机器学习(FATML)](https://www.fatml.org/) 会议。最近，杰出的机器学习者、[统计学家、](https://www.liebertpub.com/doi/full/10.1089/big.2018.0083)、社会学家、律师和哲学家多次呼吁，根据数据科学对个人和社会的伦理影响，重新评估数据科学实践。除此之外，梭伦·巴罗卡斯、安德鲁·塞尔伯斯特、鲁宾·宾斯、雅各布·梅特卡夫、凯特·克劳福德、[丹娜·博伊德](https://www.danah.org/name.html)等人正在进行重要的跨学科研究。

然而，尽管做了这么多伟大的工作，我仍然没有看到任何人为数据科学制定一个全面而一致的道德框架，将数据科学实践的深刻知识与严格的道德论证相结合。我看过的许多论文都提出了基本的、一般的关于伦理的哲学观点，为了吸引普通读者而“简化”了。也许是因为害怕看起来“太主观”，这些作者从来没有真正为数据科学提出过独到的观点。这种方法很难激励人们。通过试图取悦每个人，他们实际上取悦不了任何人。讽刺的是，相对主义者没有列出各种伦理“选项”(*这里有一份伦理系统的“自助餐”,你可以选择！各有同等效力！我希望看到有人对一种观点或系统采取强硬立场，不管是好是坏。然后我们可以讨论什么可行，什么不可行。*

做*有益于社会的数据科学*而不与来自不同社区和文化的参与者就*什么是好的*进行实质性讨论，就好比在没有测量两岸距离的情况下在河上建一座桥。在我看来，数据科学伦理目前缺少一个苏格拉底式的牛虻，一个愿意质疑公认的智慧并支持新思想的人，即使被当权者视为“不虔诚”。话说回来，我们都知道苏格拉底发生了什么…

也许我是错的，但我认为(至少一些)数据科学家希望并且应该对数据科学的艺术和实践进行严格而复杂的伦理审查。他们已经准备好坐在“成人桌”前进行讨论。

## 全面的数据科学伦理需要涵盖哪些内容？

当然，像这样的中等职位并不是制定这种道德规范的合适地方。相反，我想提出三个简单的问题来指导数据科学的未来伦理。换句话说，数据科学伦理需要解决哪些关键的**问题**、**问题**和**概念**？这些问题是受牛津信息哲学家卢西亚诺·弗洛里迪的启发。

## 1)我应该成为什么样的数据科学家？

这与古希腊“自我生成”的概念有关，或者说，在我们的一生中，我们如何成为善良和有道德的人。为了正确回答这个问题，我们需要一些关于*目的论*的概念，或者数据科学家的功能以及她在一个公共或私人组织中的角色。思考这个问题的一种方式是问自己，“在数据科学漫长而成功的职业生涯结束时，对我的成功贡献最大的是什么？作为一名数据科学家，为了过上充实的生活，我发展的关键技能是什么，我参与的最重要的实践是什么？”

或者，正如[阿利斯泰尔·麦金太尔](https://en.wikipedia.org/wiki/Alasdair_MacIntyre)或[查尔斯·泰勒](https://en.wikipedia.org/wiki/Charles_Taylor_(philosopher))可能会问的，“数据科学界的价值观、传统和实践是什么？”这个问题是复杂的，因为该领域的混合谱系。数据科学家来自不同的领域，如物理、工程、计算机科学、统计和社会科学。一方面，数据科学家是数据管理员，受托管理关于个人及其行为的私人信息。他们有相当明确的业务目标要实现。另一方面，他们是科学家和研究人员，必须在科学知识的积累与公认的联邦政府规定的人体研究伦理之间取得平衡。雅各布·梅特卡夫(Jacob Metcalf)和凯特·克劳福德(Kate Crawford)在他们的文章 [*中捕捉到了这一困境:大数据研究中的人类主体在哪里？*](https://journals.sagepub.com/doi/full/10.1177/2053951716650211)

反过来，研究数据科学家的角色要求我们问自己这样一个问题，*以数据为中心的公司的社会角色是什么*，它服务于什么目标或目的？例如，从脸书的大规模在线实验(例如，关于[社会传染](https://www.forbes.com/sites/gregorymcneal/2014/06/28/facebook-manipulated-user-news-feeds-to-create-emotional-contagion/#5c64f92439dc))中收集的社会科学见解应该与更大的社会科学界共享吗？无形知识产权止于何处，科学知识始于何处？

关于公司的目标和更普遍的商业道德，法律学者如 Lynn Stout 已经著书推翻了股东价值神话。在她看来，除了股东价值最大化这一狭隘目标之外，现代美国公司确实有很大的余地去追求其他目标。托马斯·唐纳森和托马斯·邓菲共同开发了[综合社会契约理论](https://www.jstor.org/stable/25074332)，作为在现代企业环境中整合社群主义和契约主义伦理的一种方式。利益相关者理论加上新的有趣的“业务目标函数”可能成为数据科学伦理领域肥沃的知识土壤。

## 2)我该怎么办？

什么样的动作好？什么决定了行为的对错？它与行为本身的*性质*或其(可能的)*后果*有关，还是两者都有？我的动机和意图重要吗？这是一个实用数据科学知识非常重要的领域。数据科学家共有的特定惯例和行为将使数据科学的伦理与社会科学的伦理不同。

汉娜·阿伦特在她的书《艾希曼在耶路撒冷》中揭露了*平庸的邪恶*。她记录了这个完全平凡而通情达理的人，阿道夫·艾希曼，一个第三帝国的后勤经理，是如何明知故犯地参与了对数百万犹太人的种族灭绝。现在这是一个极端的例子，但尽管如此，当个体行为者未能反思他们正在做什么以及他们的工作如何融入一个更大、更复杂的系统时，必须让数据科学家意识到系统性的邪恶潜力。玛德琳·埃利什写了她所谓的“道德崩溃区”，在那里，人类行为者对复杂的自动化系统的行为控制非常有限。当这种系统失败时，数据科学家应该在多大程度上承担道德和法律责任？谁定义失败？

## 3)**我为什么要做？**

**对于*为什么关心*这个问题，有一个简单的答案。 **GDPR** 。如果没有强有力的论据来证明某种行为的对错，那么至少有实际的、合法的理由来解释为什么我们应该关心我们作为数据科学家所做的事情。更多细节可以查看我们的文章 [*适应 GDPR:对数据科学家和行为研究者的影响*](https://www.liebertpub.com/doi/full/10.1089/big.2018.0176?casa_token=jHS1Y8ank2gAAAAA%3AC5ta2j2f-vEkjsqXlvwvMV0b4KgaJMF06dGPqm4dyCr7nRE6oXiBpA_9VPGS8Z66rkx7US4gG0-MEQ) *。简而言之，现在我只想说，GDPR 基于欧洲人对确保人类繁荣所需的最低人权的理解，展示了人工智能/人工智能的道德愿景。***

**但是除此之外，如果你不在欧盟的土地上，你很可能仍然反对没有好的理由成为一个好的数据科学家或者避免可能伤害算法决策系统的最终用户的行为。他们可能会说，作为一门科学，数据科学是没有价值和客观的。“我只是一名工程师。我解决问题。应用这些解决方案是其他人的工作；这不在我的工作范围内。”**

**我在另一篇关于[数据科学家和权力伦理](/data-scientists-and-the-ethics-of-power-ae91e6dd188)的博客文章中探讨了这种想法的某些方面。简而言之，我们应该培养我称之为*的激进数据科学家*。我们必须努力不让新的数据科学家倒向相对主义、虚无主义或伦理利己主义。**

## **缩小伦理利己主义**

> **数据科学伦理必须克服的最大哲学障碍是[安·兰德的客观主义](https://en.wikipedia.org/wiki/Objectivism)，它似乎已经渗透到[美国政治和工业](https://www.theguardian.com/books/2017/apr/10/new-age-ayn-rand-conquered-trump-white-house-silicon-valley)，尤其是硅谷。**

**在我看来，客观主义可以比作一种意识形态，这种意识形态很可能来自唐纳德·川普、史蒂夫·乔布斯、弗里德里希·尼采和亚里斯多德之间的一次醉酒对话。现在，对兰德的客观主义的适当回应将是另一个帖子本身。但是我会列出一些应对的方法，这样你就可以知道如何去做了。**

## **客观主义的基本观点:做一个自私的天才**

**首先，支撑兰德客观主义的伦理利己主义的主要教义是什么？我们可以把它的主要原则总结为“每个人都应该只追求他或她自己的利益”在她 1961 年写的《自私的美德》中，安·兰德写道，“获得自己的幸福是人类最高的道德目标。”根据亚里士多德对人类是理性动物的描述，兰德直言不讳地宣称利他主义违背了人性的本质。对她来说，我们的理性能力意味着我们应该将我们的能量导向伟大思想和目标的产生，这让人想起尼采的***übermensch***。我们不能被社会规则的限制和披着“利他主义”外衣的软弱表现所束缚。**

**在她有影响力的书《阿特拉斯耸耸肩》中，她记录了如果社会的“有头脑的人”——社会的“主要推动者”、哲学家、科学家和商业巨头——突然罢工会发生什么。兰德对理性计算的推崇，以及她对体现英雄理想的工业(即硅谷)巨头的描述，如今已经转化为超人类主义运动，作者[梅雷迪思·布鲁萨德](https://mitpress.mit.edu/books/artificial-unintelligence) (2018)称之为“技术至上主义”:坚定不移地认为人类所有问题的解决方案是更多新技术的应用。**

**第二次世界大战后，也许许多技术专家并不知道，[霍克海默、阿多诺、马尔库塞](https://en.wikipedia.org/wiki/Critical_theory)和[维纳](https://en.wikipedia.org/wiki/Norbert_Wiener)阐明了当我们目光短浅地追求 [*工具理性*](https://en.wikipedia.org/wiki/Instrumental_and_value_rationality) 的冷酷逻辑时，等待人类的可能后果。技术没有像启蒙思想家梦想的那样打开人类解放的闸门，而是被法西斯分子所控制。我们必须提醒自己，这是一种永恒的可能性，否则就有被自己的乐观蒙蔽的风险。**

**翻译成机器学习的语言和对象，我们可以说**

> **具有讽刺意味的是，盲目技术进步的“贪婪”算法将我们带到了一个局部静止点，在这个点上，我们有能力播下毁灭人类的种子。如果没有一点随机因素——由对我们目标的道德反思带来的——我们就有永远追逐局部最优的风险。**

## **库尔特·拜尔对伦理利己主义的回应**

**我将留给你们一个对伦理利己主义者或客观主义者的回应。道德哲学家库尔特·拜尔认为，道德利己主义至少在两个方面存在问题。首先，作为一种伦理理论，它是失败的，因为它没有提供更高的原则——它的最高原则是“做对你最有利的事情！”—我们可能用它来裁决党派之间的冲突。第二，也许更重要的是，伦理利己主义实际上并不构成伦理理论。伦理利己主义所支持的道德并不满足任何道德体系的一个基本条件:它为裁决由追求自身利益的人引起的争端提供了理由。换句话说，伦理利己主义并没有满足道德存在的一个关键原因:作为个人和社区的行动指南，根据理性的要求，以公正的方式解决争端。**

**大多数哲学家，至少在西方分析传统中，会同意任何系统被认为是道德系统，它必须建立一个所有理性人都会同意的行为准则。这种道德观是由康德开创的，最近出现在一些著作中，如[约翰·罗尔斯的](https://en.wikipedia.org/wiki/John_Rawls) *正义理论、* [大卫·高蒂耶的](https://en.wikipedia.org/wiki/David_Gauthier) *契约道德*和 [T.M .斯坎伦的](https://en.wikipedia.org/wiki/T._M._Scanlon) *我们欠对方的*。为了更清楚地理解理性一致的重要性，我们可以看看威廉·弗兰克纳在他 1969 年的论文《道德的概念》中对道德的描述:**

> **“AG(行动指南)是一种道德(道德 AG 相对于非道德 AG)，当且仅当它满足如下形式标准时，不管其内容如何:
> (A) X 认为它是规定性的。
> (B) X 将其普遍化。(C) X 认为它是决定性的，最终的，凌驾于一切之上的，或至高无上的权威。**

**我们现在可以开始解析拜尔早先的观点了。如果我们假设命题 A、B 和 C(假设道德利己主义是指导我们行动的规定的、普遍的和最高的原则)，那么利己主义不可能被说成是构成道德体系或行动指南。想象一下，从普遍的观点来看(即，从不同于你自己的各种人类角色、地位和职位来看)，一个每个道德主体都遵循道德利己主义的世界。同时，从普遍的观点来看，想象一个世界，其中每个道德主体*都不遵循道德利己主义。哪个世界会更好？道德理性战胜利己理性的世界，还是利己理性战胜道德理性的世界？***

***拜尔的论点是，如果我们生活在一个以追求私利为终极行动原则的世界，那么我们的境况不会比霍布斯笔下的自然状态好到哪里去。除了我们当中最幸运的人之外，生活对所有人来说都是肮脏的、野蛮的和短暂的。然而，普遍性标准要求我们寻找每个人都能接受的原则，不管他们在社会中的实际地位如何。即使我们可能在*这个*基因彩票的特别抽奖中幸运地如愿以偿，我们也会意识到，在一个反事实的世界里，事情*可能会朝着另一个方向发展。****

***伦理利己主义把自己钉在自己逻辑的利剑上，因为它没有也不可能为我们提供权威性的最终理由——作为一种决策程序——来裁决人们之间遵循自身利益的争端。当然，当道德利己主义符合你的利益时，当你缺乏身体力量来执行你的意志时，你会支持道德利己主义，但想象一下所有情况都是相反的，你会让最大和最强的人行使他的私利来反对你自己的私利。强权即公理是一个伟大的原则，以防你碰巧是房间里最强壮的人。但是当你不在的时候呢？拜尔对伦理利己主义的反驳有一个明显的长期频繁主义逻辑。***

***对于那些熟悉道德哲学的人来说，我们可能会说伦理利己主义失败了，因为它不能以康德的形式表达为绝对命令。这最终会弄巧成拙，*在* *最少*作为一种伦理理论或作为一种道德。但是，伦理利己主义的支持者可能会说，这一事实并不妨碍它作为非道德的行动指南而存在。也许这样的行动原则没有达到道德的地位，但它可能仍然有价值的其他原因。事实上，伦理利己主义，被[米尔顿·弗里德曼](https://en.wikipedia.org/wiki/Milton_Friedman)和其他人重新表述为“[公司的社会责任是增加其利润](http://umich.edu/~thecore/doc/Friedman.pdf)”的观点，似乎仍然驱动着现代商业和经济中的许多决策。***

***那么，如果伦理利己主义作为一种行动指南和道德体系最终会弄巧成拙，我们该用什么来取代它呢？这就是我认为未来数据科学伦理学的主要任务。不过，有一件事是肯定的。如果我们不能坚持某些东西，我们就有陷入一切的风险——无论是虚无主义、相对主义还是安·兰德的客观主义。***