<html>
<head>
<title>Your Guide to Web Scrape Quora Q&amp;As</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的网刮 Quora 问答指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/your-guide-to-web-scrape-quora-q-as-92b802f6dd9?source=collection_archive---------43-----------------------#2020-04-29">https://towardsdatascience.com/your-guide-to-web-scrape-quora-q-as-92b802f6dd9?source=collection_archive---------43-----------------------#2020-04-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e6a1" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">数据科学</h2><div class=""/><div class=""><h2 id="8620" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">只需几行代码，你就能抓取 Quora 的数据</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/24c0162e782e05b2ff51ccd53e4750ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*UDNjFeE86M_eSg6Im_2H9A.jpeg"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">来源:由<a class="ae la" href="https://www.flickr.com/photos/thomashawk/5370003859" rel="noopener ugc nofollow" target="_blank"> Flickr </a>中的<a class="ae la" href="https://www.flickr.com/photos/thomashawk/" rel="noopener ugc nofollow" target="_blank">托马斯·霍克</a>(CC By-NC 2.0)</p></figure><p id="968e" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">在本教程中，我将向您展示如何使用<a class="ae la" href="https://www.anaconda.com/" rel="noopener ugc nofollow" target="_blank"> Anaconda </a> Jupyter 笔记本和<a class="ae la" href="https://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>库来执行 web 抓取。</p><p id="6b1f" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">我们将从 Quora 搜集问题和答案，然后我们将它们导出到<a class="ae la" href="http://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">Pandas</a>library data frame，然后导出到一个. CSV 文件。</p><p id="ecf0" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">让我们直接进入正题，然而，如果你正在寻找一个指南来理解网络抓取，我建议你阅读来自<a class="ae la" href="https://www.dataquest.io/blog/web-scraping-tutorial-python/" rel="noopener ugc nofollow" target="_blank"> Dataquest </a>的这篇文章。</p><h1 id="1732" class="lx ly iq bd lz ma mb mc md me mf mg mh kf mi kg mj ki mk kj ml kl mm km mn mo bi translated">1-使用一个 URL</h1><p id="3c86" class="pw-post-body-paragraph lb lc iq ld b le mp ka lg lh mq kd lj lk mr lm ln lo ms lq lr ls mt lu lv lw ij bi translated">让我们导入我们的库</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="4616" class="mz ly iq mv b gy na nb l nc nd">import urllib<br/>import requests<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</span></pre><p id="3105" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">插入你的 Quora 网址，一个例子显示。</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="e188" class="mz ly iq mv b gy na nb l nc nd">url = ‘<a class="ae la" href="https://www.quora.com/Should-I-move-to-London'" rel="noopener ugc nofollow" target="_blank">https://www.quora.com/Should-I-move-to-London'</a></span></pre><p id="ba70" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">然后让我们向 web 服务器发出一个<code class="fe ne nf ng mv b">GET</code>请求，它将为我们下载给定网页的 HTML 内容。</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="621c" class="mz ly iq mv b gy na nb l nc nd">page = requests.get(url)</span></pre><p id="f530" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">现在，我们可以使用 BeautifulSoup 库来解析这个页面，并从中提取文本。我们首先必须创建一个<code class="fe ne nf ng mv b">BeautifulSoup</code>类的实例来解析我们的文档:</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="fedd" class="mz ly iq mv b gy na nb l nc nd">soup = BeautifulSoup(page.content, ‘html.parser’)</span></pre><p id="c345" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">然后，我们将创建熊猫数据框架来包含我们想要的问答。</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="ea2a" class="mz ly iq mv b gy na nb l nc nd">df = pd.DataFrame({‘question’: [],’answers’:[]})</span></pre><p id="9961" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">现在是从网页中选择问答类的时候了，类在抓取时被用来指定我们想要抓取的特定元素。</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="8b1a" class="mz ly iq mv b gy na nb l nc nd">question = soup.find(‘span’, {‘class’: ‘ui_qtext_rendered_qtext’})<br/>answers = soup.find_all(‘div’, attrs={‘class’: ‘ui_qtext_expanded’})</span></pre><p id="e272" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">然后，我们可以通过将结果添加到之前创建的数据框架中来得出结论。</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="b27b" class="mz ly iq mv b gy na nb l nc nd">for answer in answers:<br/>     df = df.append({‘question’: question.text,<br/>         ‘answers’: answer.text<br/>          }, ignore_index=True)<br/>df</span></pre><p id="c0b5" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">将结果导出到 CSV 文件的时间。</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="9f9c" class="mz ly iq mv b gy na nb l nc nd">df.to_csv(‘One_URLs.csv’)</span></pre><h1 id="ba16" class="lx ly iq bd lz ma mb mc md me mf mg mh kf mi kg mj ki mk kj ml kl mm km mn mo bi translated">2-使用多个 URL</h1><p id="e614" class="pw-post-body-paragraph lb lc iq ld b le mp ka lg lh mq kd lj lk mr lm ln lo ms lq lr ls mt lu lv lw ij bi translated">这一次我们将一起努力在同一时间内刮出不止一页。这一过程几乎与相对变化相同。</p><p id="5250" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">从导入库开始</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="6842" class="mz ly iq mv b gy na nb l nc nd">import urllib<br/>import requests<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</span></pre><p id="2d31" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">添加所有你需要的网址，我们现在有 2 个</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="3b24" class="mz ly iq mv b gy na nb l nc nd">url = [‘<a class="ae la" href="https://www.quora.com/What-are-best-places-to-relocate-and-settle-in-UK'" rel="noopener ugc nofollow" target="_blank">https://www.quora.com/What-are-best-places-to-relocate-and-settle-in-UK'</a>, ‘<a class="ae la" href="https://www.quora.com/Should-I-relocate-to-the-UK'" rel="noopener ugc nofollow" target="_blank">https://www.quora.com/Should-I-relocate-to-the-UK'</a>]</span></pre><p id="7072" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">创建我们的数据框架</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="15d6" class="mz ly iq mv b gy na nb l nc nd">df = pd.DataFrame({‘question’: [],’answers’:[]})</span></pre><p id="6694" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">现在，我们将执行一个 for 循环，该循环将迭代两个 URL 来执行相同的过程，然后它可以将结果保存到 DataFrame 中。</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="f52e" class="mz ly iq mv b gy na nb l nc nd">for i in url:<br/>   page = requests.get(i)<br/>   soup = BeautifulSoup(page.content, “html.parser”)<br/>   question = soup.find(‘span’, <br/>            {‘class’:      ‘ui_qtext_rendered_qtext’})<br/>   answers = soup.find_all(‘div’, <br/>                attrs={‘class’:    ‘ui_qtext_expanded’})<br/>   for answer in answers:<br/>        df = df.append({‘question’: question.text,<br/>          ‘answers’: answer.text<br/>            }, ignore_index=True)<br/>df</span></pre><p id="2017" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">现在，让我们将数据帧导出到 CSV 文件。</p><pre class="kp kq kr ks gt mu mv mw mx aw my bi"><span id="e106" class="mz ly iq mv b gy na nb l nc nd">df.to_csv(‘Two_URLs.csv’)</span></pre><p id="a5a0" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">您现在应该对如何从 Quora 中抓取和提取数据有了很好的理解。一个很好的下一步，如果你对网络抓取有点熟悉，你可以选择一个网站，自己尝试一些网络抓取。</p><p id="3a61" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">快乐编码:)</p></div></div>    
</body>
</html>