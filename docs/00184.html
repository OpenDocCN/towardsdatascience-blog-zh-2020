<html>
<head>
<title>Estimators and their efficiency</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">估计量及其效率</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/is-your-model-efficient-845abce5c2f3?source=collection_archive---------25-----------------------#2020-01-06">https://towardsdatascience.com/is-your-model-efficient-845abce5c2f3?source=collection_archive---------25-----------------------#2020-01-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d06c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">无偏估计量的方差/均方误差的Cramer-Rao下界介绍</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/009a16f997467b6083ec733ab171335a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8wRDcs6bV0y1A7TJVV4tcA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@macauphotoagency?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">澳门图片社</a>在<a class="ae kv" href="https://unsplash.com/s/photos/casino?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="4863" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">简介——什么是评估者？</h1><p id="1117" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">假设你在抛硬币，你想凭经验估计正面的概率。为此，你决定抛硬币<strong class="lx ir"> n </strong>次，根据你得到的是正面还是反面，记录1或0。</p><p id="df4c" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">估计概率最直接的方法是计算你在<strong class="lx ir"> n </strong>次投掷中获得的正面的比例，我们称之为<em class="mw"> </em> <strong class="lx ir"> p̂.</strong>n<strong class="lx ir">变得越大，你就越确定<strong class="lx ir"> p̂ </strong>准确地估计了<strong class="lx ir"> p </strong>，即获得正面的真实概率。在统计学中，我们说<strong class="lx ir"> p̂ </strong>是<strong class="lx ir"> p </strong>的<strong class="lx ir">估计量</strong>。直观地说，<strong class="lx ir">估计器</strong>只是在给定一些数据的情况下，估计统计模型中未知参数的一种方式。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/33ab817ef6836b00abe1f72d49a7f5d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fj3IrbvxG04o_8TFp3295g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">维吉尔·卡亚萨在<a class="ae kv" href="https://unsplash.com/s/photos/coin?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="9f32" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">估计量是统计学的基础。在上面的例子中，我们的估计量是<strong class="lx ir">无偏的</strong>，这意味着它的期望值就是我们试图估计的参数。除了让我们的估计量无偏之外，我们的估计量尽可能接近期望值也非常重要，即<strong class="lx ir">方差</strong>最小化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/ab4aec08a95353e04ae89117917b9016.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*0Qo1byfzgYuRQh_vJQPvlQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">hat的方差，θ的估计量</p></figure><p id="2c7c" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">当使用无偏估计量时，方差与<strong class="lx ir">均方误差(MSE) </strong>相同，这对于之前有机器学习经验的人来说应该很熟悉。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/c463239478ce7893b9b4f3ab12b2f9a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r5mJd2NwNGb8Hkh69bx8eA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">马克A在<a class="ae kv" href="https://unsplash.com/s/photos/darts?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="262a" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">这里有一个非常直观的例子，通常用来解释估计量。假设你在射箭。目标是击中靶心(参数)。粘在棋盘上的单个飞镖是你的评估者(你，扔飞镖的人)做出的评估。不偏不倚只是意味着你的飞镖的预期位置是靶心，实际上并没有说你平均会有多接近靶心。这就是我们关注MSE的原因。在这种情况下，高MSE只是意味着从单个飞镖到靶心的平均距离相当高。成为一个好的玩家(评估者)意味着你的飞镖聚集在中心周围——也就是说，你的MSE非常小。</p><p id="e673" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">既然我们理解了为什么我们需要我们的估计量具有最小的MSE，问题就变成了:给定一个估计量，我们如何知道它是否是最<strong class="lx ir">有效的</strong>估计量，即具有最小MSE的估计量？这就是Cramer-Rao界派上用场的地方。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="afea" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">克莱姆-拉奥界</h1><p id="e10b" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">Cramer-Rao界产生于20世纪40年代，它给出了无偏估计量的方差/均方误差的一个下界。这意味着给定参数的最佳可能估计量将具有由界限规定的MSE。</p><p id="40bf" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">假设我们想从<strong class="lx ir"> n </strong>个样本中估计<strong class="lx ir"> θ </strong>。克莱姆-拉奥定理陈述如下(在iid假设和其他正则性条件下):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/553de4af18f82701cd9c37551a026a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*pyUOHrvqhCNOF0ToCrWO_A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">克莱姆-拉奥界</p></figure><p id="f55b" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">如果我们在界上有等式，那么我们知道估计量是有效的！这并不意味着总是存在这样的估计量；然而，它确实声明了最佳可能估计量的MSE将大于或等于由界限给出的MSE。</p><h2 id="0e33" class="nb le iq bd lf nc nd dn lj ne nf dp ln me ng nh lp mi ni nj lr mm nk nl lt nm bi translated">费希尔信息</h2><p id="cf39" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">现在，你可能想知道等式中的<strong class="lx ir"> I(θ) </strong>到底代表什么。它被称为<strong class="lx ir">费希尔信息</strong>，直观地说，它是我们对样本来自哪个数据分布有多少信息的一种度量。</p><p id="1e95" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">在<em class="mw"> iid </em>假设下，大小为<strong class="lx ir"> n </strong>的样本中的费希尔信息是单个样本中的信息乘以<strong class="lx ir"> n </strong>。我们期望，随着我们获得更多的数据和<strong class="lx ir"> n </strong>变得更大，我们应该有更多的关于数据是从什么分布抽样的“信息”，因此，我们应该能够更好地估计<strong class="lx ir"> θ </strong>。</p><p id="8971" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">现在让我们努力理解费雪信息的公式。我们首先需要定义什么叫做<strong class="lx ir">得分函数</strong>。如果我们考虑一个随机变量<strong class="lx ir">X∞f(X；θ) </strong>，则得分由下式给出</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/0ff058dd99994bda0611ad5f86caf067.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*EKQxid1JdOG47tgzUdwKuw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">分数函数</p></figure><p id="b7f1" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">然后，Fisher信息被定义为得分平方的期望值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/e01731ec02736893852ea11c6a28b5ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*WRzaRgiWtxsmQu341oW8DA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">费希尔信息</p></figure><p id="d1c8" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">或者，通过一些简单的操作，我们可以获得Fisher信息的替代表达式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/2e3861acdbf210d0f6f788f69f6bcc76.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*8wWXRqeHsEqgmPL9ysvGlw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Fisher信息的替代表达</p></figure><p id="44ea" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">根据这些表达式，计算费希尔信息相对简单。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="253e" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">结论</h1><p id="90ae" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">我希望你现在对估计量的Cramer-Rao界有了更好的理解。此外，我希望你现在准备好计算和评估你自己的估算器的效率。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="3400" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">参考文献</strong></h1><p id="4f11" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">[1]马丁，《统计理论讲义》(2015)，<a class="ae kv" href="http://homepages.math.uic.edu/~rgmartin/Teaching/Stat411/Notes/411notes.pdf" rel="noopener ugc nofollow" target="_blank">http://home pages . math . UIC . edu/~ rg Martin/Teaching/stat 411/Notes/411 Notes . pdf</a></p></div></div>    
</body>
</html>