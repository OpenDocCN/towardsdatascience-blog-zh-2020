<html>
<head>
<title>Neural Style Transfer With TensorFlow Hub</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流中枢神经式传递</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-style-transfer-with-tensorflow-hub-dfe003df0ea7?source=collection_archive---------22-----------------------#2020-03-28">https://towardsdatascience.com/neural-style-transfer-with-tensorflow-hub-dfe003df0ea7?source=collection_archive---------22-----------------------#2020-03-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3383" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我不会画画，但是机器学习可以…</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/30924e643afde86895e464338d617d7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nNOBDXmcnLeiq1NVI-7QIQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">阿德里安娜<a class="ae ky" href="https://unsplash.com/@adrigeo_?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> geo </a>在<a class="ae ky" href="https://unsplash.com/s/photos/painting?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><h1 id="5849" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="c70f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated">我不是艺术鉴赏家，但上面这幅画看起来不错。</p><p id="b3c6" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我也不是画家，但在本文结束时，我将创建一个与上面的图像具有相似绘画风格的图像。</p><p id="5b56" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu">本文将涵盖以下内容:</strong></p><ul class=""><li id="135b" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated"><strong class="lt iu">神经类型转移的描述</strong></li><li id="0a37" class="nb nc it lt b lu nk lx nl ma nm me nn mi no mm ng nh ni nj bi translated"><strong class="lt iu">神经类型转移如何工作</strong></li><li id="fc30" class="nb nc it lt b lu nk lx nl ma nm me nn mi no mm ng nh ni nj bi translated"><strong class="lt iu">样式传递的代码实现</strong></li></ul><p id="f6e1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><em class="np">对于热心的读者，请随意向下滚动到</em> <code class="fe nq nr ns nt b"><em class="np">code</em></code> <em class="np">部分。</em></p></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h1 id="bdf3" class="kz la it bd lb lc ob le lf lg oc li lj jz od ka ll kc oe kd ln kf of kg lp lq bi translated">什么是神经类型转移</h1><p id="d8f6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">神经风格转移(NST)是一种涉及利用深度卷积神经网络和算法从一幅图像中提取内容信息并从另一幅参考图像中提取风格信息的技术。在提取样式和内容之后，生成组合图像，其中所得图像的内容和样式源自不同的图像。</p><p id="91c5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">NST 是一种图像风格化的方法，这是一种涉及使用输入参考图像来提供具有从输入图像导出的风格差异的输出图像的过程。</p><p id="2219" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">NST 技术出现在 Leon A Gatys 等人的论文“艺术风格的神经算法”中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/496f3f2fd7c7483bb458612e7a22647f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*X4YoZkXH0QNAjhSjy4RAQw.png"/></div></figure></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h1 id="fa39" class="kz la it bd lb lc ob le lf lg oc li lj jz od ka ll kc oe kd ln kf of kg lp lq bi translated">它是如何工作的</h1><p id="261c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">深度神经网络(DNN)，更具体地说，卷积神经网络(CNN)具有一个至关重要的特征，即能够学习图像内内容和风格的空间表示。这一特性使得 NST 技术成为可能。</p><p id="2483" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">由 CNN 生成的输入图像的空间表示捕获了图像的风格和内容的统计信息。NST 将提取的样式和内容组合成一个生成的输出图像。</p><p id="c51e" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">CNN 层结构内的中间层中的激活功能提供了捕获输入图像的内容和风格统计信息的能力。</p><p id="db4c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在卷积操作之后，CNN 图层输出一个特征图，卷积操作包括在输入图像上滑动一个过滤器。<strong class="lt iu">一幅图像的内容其实就在生成的每一层的特征图之内。</strong></p><p id="96ea" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">从中间层的特征图中提取内容将提供输入图像的高级结构和几何信息。</p><p id="96dd" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">特征图获得输入图像的风格。<strong class="lt iu">为了获得图像的风格，需要评估中间层中特征图的均值和相关性。</strong>该过程提供的信息提供了输入图像的纹理图案信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/757add19851cb8ae5ae577c99fccacfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yegx6QyUius8c8aasT3ouQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1508.06576.pdf" rel="noopener ugc nofollow" target="_blank">风格和内容重建</a></p></figure></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h1 id="fc48" class="kz la it bd lb lc ob le lf lg oc li lj jz od ka ll kc oe kd ln kf of kg lp lq bi translated">密码</h1><p id="74f3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">精彩的部分来了。</p><p id="991a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们将创建一个图像的内容和下面的图像风格。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/b8a6f6fe0f69f658c37dd6afe3eb4616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lDaZX7nEzlq3HqnDYCaHfQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">左:内容图片(在<a class="ae ky" href="https://unsplash.com/s/photos/human?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@cikstefan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">斯特凡·斯特凡·基克</a>拍摄)，右:风格图片(在<a class="ae ky" href="https://unsplash.com/s/photos/painting?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@adrigeo_?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">阿德里安娜·吉奥</a>拍摄)</p></figure><p id="29f3" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">为了使用两个参考图像成功实现神经类型转移的过程，我们将利用<a class="ae ky" href="https://www.tensorflow.org/hub" rel="noopener ugc nofollow" target="_blank"> TensorFlow Hub </a>上的模块</p><p id="c0de" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">TensorFlow hub 提供了一套可重用的机器学习组件，如数据集、权重、模型等。</p><p id="d089" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">对于本文的实现部分，我们将利用一系列工具和库来加载图像和执行数据转换。</p><ul class=""><li id="d7db" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated"><a class="ae ky" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> TensorFlow </strong> </a>:机器学习模型的实现、训练、部署的开源平台。</li><li id="25a8" class="nb nc it lt b lu nk lx nl ma nm me nn mi no mm ng nh ni nj bi translated"><a class="ae ky" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> Matplotlib </strong> </a>:用于在 Python 中创建可视化绘图的工具，如图表、图形等</li><li id="688b" class="nb nc it lt b lu nk lx nl ma nm me nn mi no mm ng nh ni nj bi translated"><a class="ae ky" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> Numpy </strong> </a>:启用数组数据结构的几种数学计算和运算。</li><li id="7a4c" class="nb nc it lt b lu nk lx nl ma nm me nn mi no mm ng nh ni nj bi translated"><a class="ae ky" href="https://www.tensorflow.org/hub" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu">tensor flow Hub</strong></a>:模型、数据集等可重用机器学习组件的库</li></ul><h2 id="3a38" class="oj la it bd lb ok ol dn lf om on dp lj ma oo op ll me oq or ln mi os ot lp ou bi translated">我们将使用<a class="ae ky" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> Jupyter Notebook </a>进行代码实现。本文末尾还包含了一个到笔记本 Github 资源库的链接。</h2><p id="20f1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">首先，我们将导入所需的工具和库。</p><pre class="kj kk kl km gt ov nt ow ox aw oy bi"><span id="231c" class="oj la it nt b gy oz pa l pb pc">import tensorflow as tf<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import PIL.Image<br/>import tensorflow_hub as hub</span></pre><p id="ff64" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">接下来，我们声明两个变量，保存输出结果的内容和样式的图像的目录路径。此外，我们将显示图像。</p><pre class="kj kk kl km gt ov nt ow ox aw oy bi"><span id="5515" class="oj la it nt b gy oz pa l pb pc">content_path = 'images/human.jpg'<br/>style_path = 'images/painting.jpg'</span><span id="d3a3" class="oj la it nt b gy pd pa l pb pc">content_image = plt.imread(content_path)<br/>style_image = plt.imread(style_path)</span><span id="f7c2" class="oj la it nt b gy pd pa l pb pc">plt.subplot(1, 2, 1)<br/>plt.title('Content Image')<br/>plt.axis('off')<br/>imshow(content_image)</span><span id="4b0f" class="oj la it nt b gy pd pa l pb pc">plt.subplot(1, 2, 2)<br/>plt.title('Style Image')<br/>plt.axis('off')<br/>imshow(style_image)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/f8967f421f7f4917883da3069857045f.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*V7Qc6UzA8hKO3hB_FMu0ig.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">内容和风格图像</p></figure><p id="e39f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">要求将图像转换成张量表示。下一步，我们将利用 TensorFlow 的图像处理方法。</p><p id="1959" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们将创建一个接受图像路径的函数，然后使用“tf.io.read_file”将图像转换为张量。我们进一步使用“tf.image.decode_image”将张量中值的数据类型更改为介于 0 和 1 之间的浮点数。</p><pre class="kj kk kl km gt ov nt ow ox aw oy bi"><span id="6008" class="oj la it nt b gy oz pa l pb pc">def image_to_tensor(path_to_img):<br/>    img = tf.io.read_file(path_to_img)<br/>    img = tf.image.decode_image(img, channels=3, dtype=tf.float32)<br/>    <br/>    # Resize the image to specific dimensions<br/>    img = tf.image.resize(img, [720, 512])<br/>    img = img[tf.newaxis, :]<br/>    return img</span></pre><p id="bfe8" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">需要与上述相反的实现来可视化 TensorFlow Hub 模块的结果。我们需要将返回的张量转换成我们可以可视化的图像。</p><p id="e89a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们只是通过将每个元素乘以 255，将包含 0 和 1 之间的值的张量反规格化为实际像素值。下一步是使用 Numpy 创建一个数组，其中包含我们需要的适当数据类型。</p><p id="5e72" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们从张量返回一个图像对象。</p><pre class="kj kk kl km gt ov nt ow ox aw oy bi"><span id="d182" class="oj la it nt b gy oz pa l pb pc">def tensor_to_image(tensor):<br/>    tensor = tensor*255<br/>    tensor = np.array(tensor, dtype=np.uint8)<br/>    tensor = tensor[0]<br/>    plt.figure(figsize=(20,10))<br/>    plt.axis('off')<br/>    return plt.imshow(tensor)</span></pre><p id="9188" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">到目前为止，我们已经完成了以下工作:</p><ul class=""><li id="64dc" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated">查看内容和样式图像参考</li><li id="7d87" class="nb nc it lt b lu nk lx nl ma nm me nn mi no mm ng nh ni nj bi translated">创建一个函数，将图像转换为张量，并将张量转换为图像</li></ul><p id="2dc5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">现在我们将把图像转换成张量，并通过。TensorFlow Hub 包中的 load()'方法。</p><p id="d55f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们期望从我们的参考图像中得到样式和内容的组合结果；因此，我们将创建一个变量来保存模块的操作结果。</p><p id="9f40" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">为了可视化结果，我们只需利用我们之前创建的“张量到图像”函数。</p><pre class="kj kk kl km gt ov nt ow ox aw oy bi"><span id="2b45" class="oj la it nt b gy oz pa l pb pc">content_image_tensor = image_to_tensor(content_path)<br/>style_image_tensor = image_to_tensor(style_path)</span><span id="bc53" class="oj la it nt b gy pd pa l pb pc">hub_module = hub.load('<a class="ae ky" href="https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'" rel="noopener ugc nofollow" target="_blank">https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'</a>)<br/>combined_result = hub_module(tf.constant(content_image_tensor), tf.constant(style_image_tensor))[0]<br/>tensor_to_image(combined_result)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/62f2d331c9fbd4f8fd2bf00767389d3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*lxQFcO55usI6smaRHRVwXg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">神经类型转移结果</p></figure></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h1 id="5a77" class="kz la it bd lb lc ob le lf lg oc li lj jz od ka ll kc oe kd ln kf of kg lp lq bi translated">结论</h1><p id="dc44" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们已经成功地结合了两个参考图像的风格和内容，并生成了一个网格图像。</p><p id="2fdc" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">接下来，我建议你更详细地探讨神经类型转移的话题。</p><p id="ed05" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">下面是一个 GitHub repo 的链接，它提供了本文中的代码。</p><div class="pg ph gp gr pi pj"><a href="https://github.com/RichmondAlake/tensorflow_2_tutorials/blob/master/03_neural_style_transfer.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">Richmond alake/tensor flow _ 2 _ 教程</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">permalink dissolve GitHub 是 4000 多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">github.com</p></div></div><div class="ps l"><div class="pt l pu pv pw ps px ks pj"/></div></div></a></div><p id="dac6" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我建议您探索的另一个主题是图像分类。下面是一篇文章的链接，其中我介绍了如何使用 TensorFlow 和 Keras 实现图像分类。</p><div class="pg ph gp gr pi pj"><a rel="noopener follow" target="_blank" href="/in-depth-machine-learning-image-classification-with-tensorflow-2-0-a76526b32af8"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">使用 TensorFlow 2.0 进行(深入)机器学习图像分类</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">理解实现用于图像分类的神经网络的过程。</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="py l pu pv pw ps px ks pj"/></div></div></a></div></div></div>    
</body>
</html>