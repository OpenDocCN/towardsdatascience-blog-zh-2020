<html>
<head>
<title>Netflix Movie Recommendation — Using Collaborative Filtering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网飞电影推荐—使用协同过滤</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-for-recommendation-model-part-1-19f6b6dc207d?source=collection_archive---------19-----------------------#2020-03-20">https://towardsdatascience.com/tensorflow-for-recommendation-model-part-1-19f6b6dc207d?source=collection_archive---------19-----------------------#2020-03-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1e8c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们将了解如何使用TensorFlow构建一个<a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank">电影推荐</a>模型。</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/08be9a6207e1d96ccc030389e47d5622.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VaJk10rzIqhfT-sl"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><a class="ae ki" href="https://unsplash.com/@hngstrm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">亨利&amp;公司</a>在<a class="ae ki" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="d783" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是推荐模型？</h1><p id="d2a9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank">推荐模型</a>，简而言之，是一种算法，旨在根据用户的行为向用户提供最相关和最相关的信息。像网飞和谷歌这样的公司有一个收集数据行为的巨大数据库，能够执行最先进的推荐，以便他们可以向用户显示最相关的内容或服务，以增加参与度。在第1部分中，我们将构建一个推荐模型，使用<a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> <em class="mn">协同过滤</em> </strong> </a>向用户推荐电影。</p><div class="mo mp gp gr mq mr"><a href="https://colab.research.google.com/drive/1GV4lg3LRN-ghtAwJbN_Xy9tQmpAEykPY" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd iu gy z fp mw fr fs mx fu fw is bi translated">Google Colab</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">笔记本</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">colab.research.google.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf kt mr"/></div></div></a></div><h1 id="2751" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">协同过滤？</h1><p id="8c71" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">协同过滤处理用户和项目之间的相似性以执行<a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank">推荐</a>。这意味着<a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank">算法</a>不断地发现用户之间的关系，并依次进行<a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank">推荐</a>。<a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank">算法</a>学习用户之间的嵌入，而不必调整特征。最常见的技术是通过执行矩阵分解来找到构成特定用户兴趣的<a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank">嵌入</a>或特征。</p><h2 id="240a" class="ng la it bd lb nh ni dn lf nj nk dp lj ma nl nm ll me nn no ln mi np nq lp nr bi translated">矩阵分解</h2><p id="370f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">矩阵分解是一种嵌入。假设我们有一个用户电影矩阵或<em class="mn">反馈矩阵，一个</em> ᴺᴹ，模型学习分解成:</p><ul class=""><li id="9182" class="ns nt it lt b lu nu lx nv ma nw me nx mi ny mm nz oa ob oc bi translated">A <strong class="lt iu"> <em class="mn">用户</em> </strong>嵌入向量<strong class="lt iu"> U </strong>，其中第N行是项目m的嵌入</li><li id="886f" class="ns nt it lt b lu od lx oe ma of me og mi oh mm nz oa ob oc bi translated">An <strong class="lt iu"> <em class="mn">项</em> </strong>嵌入<strong class="lt iu"> <em class="mn"> </em> </strong>向量<strong class="lt iu"> V </strong>，其中M行是对项N的嵌入</li></ul><p id="5546" class="pw-post-body-paragraph lr ls it lt b lu nu ju lw lx nv jx lz ma oi mc md me oj mg mh mi ok mk ml mm im bi translated">学习嵌入向量，使得通过执行UVᵀ，可以形成反馈矩阵的近似。</p><h2 id="104a" class="ng la it bd lb nh ni dn lf nj nk dp lj ma nl nm ll me nn no ln mi np nq lp nr bi translated">损失函数</h2><p id="8c9e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了逼近反馈矩阵，需要一个损失函数。直观的<a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank">损失函数</a>之一是使用均方误差(MSE)。MSE计算反馈矩阵a和近似UVᵀ矩阵的差值。简单来说:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/c7cc8754f18e1db0ab62ffb27462e500.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*v4Iv2GF8_QXt7j6Hn9ENfA.png"/></div></figure><p id="12b0" class="pw-post-body-paragraph lr ls it lt b lu nu ju lw lx nv jx lz ma oi mc md me oj mg mh mi ok mk ml mm im bi translated">其中:</p><ul class=""><li id="1b63" class="ns nt it lt b lu nu lx nv ma nw me nx mi ny mm nz oa ob oc bi translated"><strong class="lt iu"> <em class="mn"> n </em> </strong>代表用户总数</li><li id="3094" class="ns nt it lt b lu od lx oe ma of me og mi oh mm nz oa ob oc bi translated"><strong class="lt iu"> <em class="mn"> Yᵢ </em> </strong>代表反馈矩阵a</li><li id="5cb3" class="ns nt it lt b lu od lx oe ma of me og mi oh mm nz oa ob oc bi translated"><strong class="lt iu"> <em class="mn"> Yᵢ_bar </em> </strong>代表UVᵀ的近似矩阵</li></ul><h2 id="9617" class="ng la it bd lb nh ni dn lf nj nk dp lj ma nl nm ll me nn no ln mi np nq lp nr bi translated">正则化函数</h2><p id="de91" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">训练模型最常见的问题之一是<strong class="lt iu"> <em class="mn">过度拟合。</em>如果这个特定的异常特征具有大的“幅度”或偏差，那么可以说该模型对于这些特定特征是过度拟合的。为了减少这种情况，我们可以在MSE损失中增加一个惩罚项。最常用的模型是<strong class="lt iu">套索回归</strong>和<strong class="lt iu">岭回归</strong>。</strong></p><div class="mo mp gp gr mq mr"><a rel="noopener follow" target="_blank" href="/regularization-in-machine-learning-76441ddcf99a"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd iu gy z fp mw fr fs mx fu fw is bi translated">机器学习中的正则化</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">训练机器学习模型的一个主要方面是避免过度拟合。该模型将有一个低…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">towardsdatascience.com</p></div></div><div class="na l"><div class="om l nc nd ne na nf kt mr"/></div></div></a></div><p id="a0ab" class="pw-post-body-paragraph lr ls it lt b lu nu ju lw lx nv jx lz ma oi mc md me oj mg mh mi ok mk ml mm im bi translated"><strong class="lt iu">岭回归(L2) </strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi on"><img src="../Images/dadca3e352d1bbb4cf9d0443e3bee3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Ip1dld4EDwR-_9MT_C0tA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">岭公式</p></figure><ul class=""><li id="af4e" class="ns nt it lt b lu nu lx nv ma nw me nx mi ny mm nz oa ob oc bi translated">取系数的<strong class="lt iu">平方</strong>、<strong class="lt iu">T43、w、</strong>。因此，任何大的<strong class="lt iu"> <em class="mn"> w </em> </strong>值都将被扣分，以减少过度拟合。</li></ul><p id="9b61" class="pw-post-body-paragraph lr ls it lt b lu nu ju lw lx nv jx lz ma oi mc md me oj mg mh mi ok mk ml mm im bi translated"><strong class="lt iu">拉索回归(L1) </strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oo"><img src="../Images/5f147f36dfb8c8243c7b5748767f37be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lJ0IFi99QIM2XpcT8FJE0g.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">套索公式</p></figure><ul class=""><li id="1aec" class="ns nt it lt b lu nu lx nv ma nw me nx mi ny mm nz oa ob oc bi translated">取系数的<strong class="lt iu">大小</strong>，<strong class="lt iu">，<em class="mn"> w </em>，</strong>。因此，任何大的<strong class="lt iu"> w </strong>值都会被扣分，以减少过度拟合。</li><li id="8f80" class="ns nt it lt b lu od lx oe ma of me og mi oh mm nz oa ob oc bi translated">如果你有一个稀疏矩阵，收缩系数和执行特征选择是有用的，这正是我们所需要的。</li></ul><h1 id="aec8" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><a class="ae ki" href="https://www.allcodingtutorial.com/posts/netflix-deep-learning-part-1" rel="noopener ugc nofollow" target="_blank">提出建议</a></h1><p id="afd8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一般来说，步骤<em class="mn">(和功能)</em>如下:</p><ul class=""><li id="d51d" class="ns nt it lt b lu nu lx nv ma nw me nx mi ny mm nz oa ob oc bi translated">创建一个<strong class="lt iu">稀疏张量</strong> : <em class="mn"> tf。SparseTensor() </em>，用于随机初始化的<strong class="lt iu"><em class="mn"/></strong>和<strong class="lt iu"> <em class="mn"> V </em> </strong>矩阵</li><li id="e8d6" class="ns nt it lt b lu od lx oe ma of me og mi oh mm nz oa ob oc bi translated">创建<strong class="lt iu">损失函数和优化器</strong>:<em class="mn">TF . losses . mean _ squared _ error()，</em>来估计带有正则化惩罚和SGD作为优化器的总损失</li><li id="2718" class="ns nt it lt b lu od lx oe ma of me og mi oh mm nz oa ob oc bi translated">创建<strong class="lt iu">模型</strong> : <em class="mn"> tf。Session() </em>，初始化超参数、学习率和嵌入</li><li id="4ca4" class="ns nt it lt b lu od lx oe ma of me og mi oh mm nz oa ob oc bi translated"><strong class="lt iu">列车</strong>车型:<em class="mn"> tf。Session.run()，</em>学习反馈矩阵的嵌入并返回<strong class="lt iu"> <em class="mn"> v </em> </strong>和<strong class="lt iu"> <em class="mn"> k </em> </strong>作为嵌入向量</li><li id="a82d" class="ns nt it lt b lu od lx oe ma of me og mi oh mm nz oa ob oc bi translated"><strong class="lt iu">展示</strong>推荐:<em class="mn"> df。DataFrame()，</em>显示与被查询用户最近的电影</li></ul><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="op oq l"/></div></figure><blockquote class="or os ot"><p id="4c8c" class="lr ls mn lt b lu nu ju lw lx nv jx lz ou oi mc md ov oj mg mh ow ok mk ml mm im bi translated">准备好模型后，让我们尝试计算用户ID: <strong class="lt iu"> 500 </strong>的推荐值</p></blockquote><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ox"><img src="../Images/a7d6cb557cf012634dacb2a38ca380bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t3-0VJySPHlwZOcvs1p0Bw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">决赛成绩</p></figure><p id="647b" class="pw-post-body-paragraph lr ls it lt b lu nu ju lw lx nv jx lz ma oi mc md me oj mg mh mi ok mk ml mm im bi translated">我们可以看到，该模型已经学习了用户500的嵌入，并且它推荐了用户ID: 500可能喜欢的前5部电影。</p><h1 id="8fcb" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">最后</h1><p id="736c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果您成功地保持了对这一点的关注，如果您对本系列有任何建议，或者有任何尝试使用NN的MF构建推荐模型的经验，请留下评论。</p></div><div class="ab cl oy oz hx pa" role="separator"><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd"/></div><div class="im in io ip iq"><p id="92d7" class="pw-post-body-paragraph lr ls it lt b lu nu ju lw lx nv jx lz ma oi mc md me oj mg mh mi ok mk ml mm im bi translated"><a class="ae ki" href="https://medium.com/@premstroke95" rel="noopener"> <em class="mn">普雷姆·库马尔</em> </a> <em class="mn">是一个无私的学习者，对我们身边的日常数据充满热情。在</em><a class="ae ki" href="https://www.linkedin.com/in/premstrk/" rel="noopener ugc nofollow" target="_blank"><em class="mn">LinkedIn</em></a><em class="mn">上与我联系，当你写信谈论这个故事和等待的未来发展时，提及这个故事。</em></p></div></div>    
</body>
</html>