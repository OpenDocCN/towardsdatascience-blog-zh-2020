<html>
<head>
<title>How to Create Simple News Summarization from Scratch using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Python从头开始创建简单的新闻摘要</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-create-simple-news-summarization-from-scratch-using-python-83adc33a409c?source=collection_archive---------26-----------------------#2020-05-15">https://towardsdatascience.com/how-to-create-simple-news-summarization-from-scratch-using-python-83adc33a409c?source=collection_archive---------26-----------------------#2020-05-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ab8c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">新闻摘要入门</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/766200f14dcb25cca24688f4fd5b6be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j3g8wHRiecEBqPij"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@aaronburden?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Aaron Burden </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="ec04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你是机器学习领域的新手，特别是自然语言处理(NLP ),你听说过自动新闻摘要，并且对它感兴趣。你一定在想，比如“如何做出一个好的模型？”，“我该学什么？”以及“我应该从哪里开始？”。</p><p id="889f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后你开始搜索哪些方法有利于自动摘要，并找到诸如<a class="ae ky" href="https://huggingface.co/transformers/model_doc/bart.html" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"/></a><strong class="lb iu">，</strong>的方法，然后你尝试预先训练的模型，并对其结果留下深刻印象。那么你有兴趣为你的母语训练模型。但有一个问题，你生活在第三世界国家，没有预先训练好的模型可用，或者你没有任何超级计算机可以运行，或者你甚至没有找到你的语言的数据集，你也懒得单独给它贴上标签。</p><p id="94c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以在这篇文章中，我会给你一个简单的方法来制作简单的新闻摘要。首先，让我们谈谈新闻摘要的方法。</p><p id="4f78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，新闻摘要方法分为两种，即提取的和抽象的。提取摘要意味着识别文本的重要部分，并使其从原始文本中逐字产生句子的子集；而抽象概括在使用先进的自然语言技术解释和检查文本之后，以新的方式再现重要的材料，以产生新的、更短的文本，该文本传达来自原始文本的最关键的信息。</p><p id="d389" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们最初的目标是做一个简单的摘要，这里我们将使用提取摘要的方法。开始吧，如果想看这篇文章的完整代码，请访问我的<a class="ae ky" href="https://github.com/fahmisalman/Summarizer-Indo" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> github </strong> </a>。</p><p id="5eb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，导入将要使用的包</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="c634" class="ma mb it lw b gy mc md l me mf">import numpy as np<br/>import nltk<br/>import re</span></pre><p id="3ada" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里我们使用了<a class="ae ky" href="https://numpy.org" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> NumPy </strong> </a>，<a class="ae ky" href="https://www.nltk.org" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> nltk </strong> </a>，以及<a class="ae ky" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> re </strong> </a>库。NumPy是用于数值计算的库，nltk是广泛用于NLP的库，re是用于正则表达式的库。</p><p id="a9fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们定义将要执行的预处理功能。它旨在集中单词并消除不需要的字符。这里有3个预处理功能，即:</p><ul class=""><li id="b248" class="mg mh it lb b lc ld lf lg li mi lm mj lq mk lu ml mm mn mo bi translated">大小写折叠:将所有字母改为小写</li><li id="5f2b" class="mg mh it lb b lc mp lf mq li mr lm ms lq mt lu ml mm mn mo bi translated">清除:删除所有标点和数字，仅保留字母字符</li><li id="9986" class="mg mh it lb b lc mp lf mq li mr lm ms lq mt lu ml mm mn mo bi translated">标记化:将句子转换成标记</li></ul><p id="5a19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是预处理过程的代码</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="aab2" class="ma mb it lw b gy mc md l me mf">def casefolding(sentence):<br/>    return sentence.lower()</span><span id="67f6" class="ma mb it lw b gy mu md l me mf">def cleaning(sentence):<br/>    return re.sub(r'[^a-z]', ' ', re.sub("’", '', sentence))</span><span id="8b7c" class="ma mb it lw b gy mu md l me mf">def tokenization(sentence):<br/>    return sentence.split()</span></pre><p id="8b91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，您还可以添加其他功能，如停用词移除、词干提取或词汇化。但是，因为每种语言的用法可能不同，所以本文将不解释该功能，但我提供的Github链接中有一个示例。</p><p id="afb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们还需要一个函数将整个故事转换成句子的集合</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="914b" class="ma mb it lw b gy mc md l me mf">def sentence_split(paragraph):<br/>    return nltk.sent_tokenize(paragraph)</span></pre><p id="7eea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将定义一个函数来计算文档中每个单词的数量。执行这个过程是为了给单词加权，目的是确定该单词是否有效果。以下是该过程的代码</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="59b0" class="ma mb it lw b gy mc md l me mf">def word_freq(data):<br/>    w = []<br/>    for sentence in data:<br/>        for words in sentence:<br/>            w.append(words)<br/>    bag = list(set(w))<br/>    res = {}<br/>    for word in bag:<br/>        res[word] = w.count(word)<br/>    return res</span></pre><p id="995d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们会做一个函数来计算每个句子的权重。这个过程是为了确定哪一个句子被认为最能代表整个故事。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="bc97" class="ma mb it lw b gy mc md l me mf">def sentence_weight(data):<br/>    weights = []<br/>    for words in data:<br/>        temp = 0<br/>        for word in words:<br/>            temp += wordfreq[word]<br/>        weights.append(temp)<br/>    return weights</span></pre><p id="c34a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们将使用的所有函数都已定义。我们举个案例吧。例如，我将使用一篇来自<a class="ae ky" href="https://www.politico.com" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"/></a>的文章，标题为“<a class="ae ky" href="https://www.politico.com/news/magazine/2020/05/14/bret-stephens-new-york-times-outrage-backlash-256494" rel="noopener ugc nofollow" target="_blank">《纽约时报》向一群愤怒的暴民投降了”。新闻业将会因此而遭殃。</a></p><p id="ee48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将从手动复制粘贴将网站上的新闻插入变量开始。如果你不想做复制粘贴，对网页抓取感兴趣，可以看我之前的文章《用Python  做4行的<a class="ae ky" rel="noopener" target="_blank" href="/scraping-a-website-with-4-lines-using-python-200d5c858bb1"> <strong class="lb iu">网页抓取新闻》。</strong></a></p><div class="mv mw gp gr mx my"><a rel="noopener follow" target="_blank" href="/scraping-a-website-with-4-lines-using-python-200d5c858bb1"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd iu gy z fp nd fr fs ne fu fw is bi translated">用Python实现4行新闻的网络抓取</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">抓取网站的简单方法</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">towardsdatascience.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm ks my"/></div></div></a></div><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="5f27" class="ma mb it lw b gy mc md l me mf">news = """<br/>IIn a time in which even a virus has become the subject of partisan disinformation and myth-making, it’s essential that mainstream journalistic institutions reaffirm their bona fides as disinterested purveyors of fact and honest brokers of controversy. In this regard, a recent course of action by the New York Times is cause for alarm.</span><span id="0dd5" class="ma mb it lw b gy mu md l me mf">On December 27, 2019, the Times published a column by their opinion journalist Bret Stephens, “The Secrets of Jewish Genius,” and the ensuing controversy led to an extraordinary response by the editors.</span><span id="03ec" class="ma mb it lw b gy mu md l me mf">Stephens took up the question of why Ashkenazi Jews are statistically overrepresented in intellectual and creative fields. This disparity has been documented for many years, such as in the 1995 book Jews and the New American Scene by the eminent sociologists Seymour Martin Lipset and Earl Raab. In his Times column, Stephens cited statistics from a more recent peer-reviewed academic paper, coauthored by an elected member of the National Academy of Sciences. Though the authors of that paper advanced a genetic hypothesis for the overrepresentation, arguing that Ashkenazi Jews have the highest average IQ of any ethnic group because of inherited traits, Stephens did not take up that argument. In fact, his essay quickly set it aside and argued that the real roots of Jewish achievement are culturally and historically engendered habits of mind.</span><span id="3189" class="ma mb it lw b gy mu md l me mf">Nonetheless, the column incited a furious and ad hominem response. Detractors discovered that one of the authors of the paper Stephens had cited went on to express racist views, and falsely claimed that Stephens himself had advanced ideas that were “genetic” (he did not), “racist” (he made no remarks about any race) and “eugenicist” (alluding to the discredited political movement to improve the human species by selective breeding, which was not remotely related to anything Stephens wrote).</span><span id="35b3" class="ma mb it lw b gy mu md l me mf">It would have been appropriate for the New York Times to acknowledge the controversy, to publish one or more replies, and to allow Stephens and his critics to clarify the issues. Instead, the editors deleted parts of the column—not because anything in it had been shown to be factually incorrect but because it had become controversial.</span><span id="60f9" class="ma mb it lw b gy mu md l me mf">Worse, the explanation for the deletions in the Editors’ Note was not accurate about the edits the paper made after publication. The editors did not just remove “reference to the study.” They expurgated the article’s original subtitle (which explicitly stated “It’s not about having higher IQs”), two mentions of Jewish IQs, and a list of statistics about Jewish accomplishment: “During the 20th century, [Ashkenazi Jews] made up about 3 percent of the U.S. population but won 27 percent of the U.S. Nobel science prizes and 25 percent of the ACM Turing awards. They account for more than half of world chess champions.” These statistics about Jewish accomplishments were quoted directly from the study, but they originated in other studies. So, even if the Times editors wanted to disavow the paper Stephens referenced, the newspaper could have replaced the passage with quotes from the original sources.</span><span id="b758" class="ma mb it lw b gy mu md l me mf">The Times’ handling of this column sets three pernicious precedents for American journalism.</span><span id="69b7" class="ma mb it lw b gy mu md l me mf">First, while we cannot know what drove the editors’ decision, the outward appearance is that they surrendered to an outrage mob, in the process giving an imprimatur of legitimacy to the false and ad hominem attacks against Stephens. The Editors’ Note explains that Stephens “was not endorsing the study or its authors’ views,” and that it was not his intent to “leave an impression with many readers that [he] was arguing that Jews are genetically superior.” The combination of the explanation and the post-publication revision implied that such an impression was reasonable. It was not.</span><span id="8866" class="ma mb it lw b gy mu md l me mf">Unless the Times reverses course, we can expect to see more such mobs, more retractions, and also preemptive rejections from editors fearful of having to make such retractions. Newspapers risk forfeiting decisions to air controversial or unorthodox ideas to outrage mobs, which are driven by the passions of their most ideological police rather than the health of the intellectual commons.</span><span id="8d0b" class="ma mb it lw b gy mu md l me mf">Second, the Times redacted a published essay based on concerns about retroactive moral pollution, not about accuracy. While it is true that an author of the paper Stephens mentioned, the late anthropologist Henry Harpending, made some deplorable racist remarks, that does not mean that every point in every paper he ever coauthored must be deemed radioactive. Facts and arguments must be evaluated on their content. Will the Times and other newspapers now monitor the speech of scientists and scholars and censor articles that cite any of them who, years later, say something offensive? Will it crowdsource that job to Twitter and then redact its online editions whenever anyone quoted in the Times is later “canceled”?</span><span id="9536" class="ma mb it lw b gy mu md l me mf">Third, for the Times to “disappear” passages of a published article into an inaccessible memory hole is an Orwellian act that, thanks to the newspaper’s actions, might now be seen as acceptable journalistic practice. It is all the worse when the editors’ published account of what they deleted is itself inaccurate. This does a disservice to readers, historians and journalists, who are left unable to determine for themselves what the controversy was about, and to Stephens, who is left unable to defend himself against readers’ worst suspicions.</span><span id="cb02" class="ma mb it lw b gy mu md l me mf">We strongly oppose racism, anti-Semitism and all forms of bigotry. And we believe that the best means of combating them is the open exchange of ideas. The Times’ retroactive censoring of passages of a published article appears to endorse a different view. And in doing so, it hands ammunition to the cynics and obfuscators who claim that every news source is merely an organ for its political coalition.</span><span id="7589" class="ma mb it lw b gy mu md l me mf">"""</span></pre><p id="aa86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们将通过把新闻切割成句子的形式来处理它，然后使用我们上面定义的函数对每个句子进行预处理。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="3194" class="ma mb it lw b gy mc md l me mf">sentence_list = sentence_split(news)<br/>data = []<br/>for sentence in sentence_list:<br/>    data.append(tokenization(cleaning(casefolding(sentence))))<br/>data = (list(filter(None, data)))</span></pre><p id="4321" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们将从我们定义的函数中统计文档中每个单词的数量。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="bace" class="ma mb it lw b gy mc md l me mf">wordfreq = word_freq(data)</span></pre><p id="6db9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，从单词计算的结果我们只需要计算每个句子的权重。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="7776" class="ma mb it lw b gy mc md l me mf">rank = sentence_rank(data)</span></pre><p id="9f28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们决定要输出多少个主要句子来表示新闻。例如，我将输出2个句子，所以这里我用2填充n。然后，系统将选择权重最高的前两个句子。要看你选择多少个句子出现。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="6f97" class="ma mb it lw b gy mc md l me mf">n = 2<br/>result = ''<br/>sort_list = np.argsort(ranking)[::-1][:n]<br/>for i in range(n):<br/>    result += '{} '.format(sentence_list[sort_list[i]])</span></pre><p id="d1fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要显示结果，请使用以下代码</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="bc52" class="ma mb it lw b gy mc md l me mf">print(result)</span></pre><p id="c6a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以结果会是这样的。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="9bab" class="ma mb it lw b gy mc md l me mf">The editors did not just remove “reference to the study.” They expurgated the article’s original subtitle (which explicitly stated “It’s not about having higher IQs”), two mentions of Jewish IQs, and a list of statistics about Jewish accomplishment: “During the 20th century, [Ashkenazi Jews] made up about 3 percent of the U.S. population but won 27 percent of the U.S. Nobel science prizes and 25 percent of the ACM Turing awards. Detractors discovered that one of the authors of the paper Stephens had cited went on to express racist views, and falsely claimed that Stephens himself had advanced ideas that were “genetic” (he did not), “racist” (he made no remarks about any race) and “eugenicist” (alluding to the discredited political movement to improve the human species by selective breeding, which was not remotely related to anything Stephens wrote).</span></pre><p id="3e91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不错吧？虽然它可能不如我们使用最先进的方法，但我们可以很好地理解我们简短新闻的本质。根据我的提示，通过使用这种方法，您可以生成自己的数据集，尽管它仍然有局限性，因为获得的结果并不总是您想要的方式。</p><p id="9963" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">祝你好运！</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="cd5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢这个帖子，我想推荐一篇启发了我 的<a class="ae ky" href="https://medium.com/sciforce/towards-automatic-text-summarization-extractive-methods-e8439cd54715" rel="noopener"> <strong class="lb iu">文章。</strong></a></p></div></div>    
</body>
</html>