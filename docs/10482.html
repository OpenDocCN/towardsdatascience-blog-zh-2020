<html>
<head>
<title>YOLOv4 on Google Colab: Train your Custom Dataset (Traffic signs) with ease</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google Colab 上的 YOLOv4:轻松训练你的自定义数据集(交通标志)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yolov4-in-google-colab-train-your-custom-dataset-traffic-signs-with-ease-3243ca91c81d?source=collection_archive---------2-----------------------#2020-07-23">https://towardsdatascience.com/yolov4-in-google-colab-train-your-custom-dataset-traffic-signs-with-ease-3243ca91c81d?source=collection_archive---------2-----------------------#2020-07-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="feac" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 YOLOv4 在 Google Colab 上训练您的自定义数据集的有效而简单的方法！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/10b20ec4f4c73a01db48ed3898742412.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ksabU5SMMQIuZFcJDdq3mQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源图片由汉斯·阿德里安·伯麦在 Unsplash 上提供</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi kz"><img src="../Images/8f3134eb2fce7f0c661cc831f51b09c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*7t8nc0QyggiIKW8PUBo63Q.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用 YOLOv4 检测交通标志</p></figure><ul class=""><li id="ecfc" class="la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><a class="ae ky" href="https://colab.research.google.com/drive/1VNc-Ywrs1XmfHcsq-BWpXZ5Zv_A2FcFn?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">用于训练 YOLOv4 的 Colab 笔记本，带有自定义数据集(交通标志)</strong> </a></li></ul><h1 id="2779" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">概述</h1><ul class=""><li id="6dc5" class="la lb it lc b ld mk lf ml lh mm lj mn ll mo ln lo lp lq lr bi translated"><a class="ae ky" href="#4f2f" rel="noopener ugc nofollow"> <strong class="lc iu">简介</strong> </a></li><li id="594b" class="la lb it lc b ld mp lf mq lh mr lj ms ll mt ln lo lp lq lr bi translated"><a class="ae ky" href="#1c23" rel="noopener ugc nofollow"> <strong class="lc iu">为什么是 YOLOv4？</strong> </a></li><li id="c29c" class="la lb it lc b ld mp lf mq lh mr lj ms ll mt ln lo lp lq lr bi translated"><a class="ae ky" href="#658f" rel="noopener ugc nofollow"> <strong class="lc iu">数据准备</strong> </a></li><li id="3a16" class="la lb it lc b ld mp lf mq lh mr lj ms ll mt ln lo lp lq lr bi translated"><a class="ae ky" href="#eb53" rel="noopener ugc nofollow"> <strong class="lc iu">与 Colab 一起训练</strong> </a></li><li id="816a" class="la lb it lc b ld mp lf mq lh mr lj ms ll mt ln lo lp lq lr bi translated"><a class="ae ky" href="#03b5" rel="noopener ugc nofollow"> <strong class="lc iu">用 YOLOv4 </strong> </a>预测</li><li id="340b" class="la lb it lc b ld mp lf mq lh mr lj ms ll mt ln lo lp lq lr bi translated"><a class="ae ky" href="#783a" rel="noopener ugc nofollow"> <strong class="lc iu">结论</strong> </a></li></ul><h1 id="4f2f" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">一.导言</h1><p id="81b5" class="pw-post-body-paragraph mu mv it lc b ld mk ju mw lf ml jx mx lh my mz na lj nb nc nd ll ne nf ng ln im bi translated">前阵子我用 Google Colab 提供的免费 GPU 写了一篇用自定义数据集(枪械检测)训练 YOLOv3 的<a class="ae ky" href="https://medium.com/@quangnhatnguyenle/how-to-train-yolov3-on-google-colab-to-detect-custom-objects-e-g-gun-detection-d3a1ee43eda1" rel="noopener">教程。在发布教程后，许多人发邮件给我，询问他们在培训过程中面临的问题。我注意到的是，这些问题中的大部分来自于修改不适当的层架构、在不正确的目录路径中运行单元或者缺少一个/一些必需的配置步骤。我也意识到设置过程可能需要时间，而且经常会很混乱。</a></p><p id="2736" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">出于这些原因，我提出了一种新的方法，其中大多数设置步骤都是通过 python 脚本自动完成的(Colab 允许您直接在其环境中修改和运行 python 脚本)。有了这个新的程序，你唯一需要在本地执行的事情就是按照 YOLO 格式准备你的自定义数据集，而所有的剩余部分将在 Colab 环境中执行。</p><h1 id="1c23" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">二。为什么是 YOLOv4？</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/d68bf58a4822397b8d8aeac45cbabab7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/0*5TBOZVzq6sGY_BCJ.png"/></div></figure><p id="15c5" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">YOLOv4 由阿列克谢·博奇科夫斯基(Alexey Bochkovskiy)、钱和廖宏远(Hong-Yuan Mark Liao)开发。它于 2020 年 4 月发布，并被称为当时最先进的实时物体探测器之一。根据其论文，YOLOv4 比 YOLOv3 快 12%，准确 10%。YOLOV4 的新架构以 CSPDarknet54 为骨干构建，提升了 CNN 的学习能力。此外，通用特征的实现包括加权剩余连接(WRC)、跨阶段部分连接(CSP)、跨小批量归一化(CmBN)、自我对抗训练(SAT)和 Mish 激活，帮助 YOLOv4 获得了非常令人印象深刻的结果。想了解更多关于 YOLOv4 的细节，可以参考原文<a class="ae ky" href="https://arxiv.org/pdf/2004.10934.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。[1]</p><h1 id="658f" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">三。数据集准备</h1><p id="3730" class="pw-post-body-paragraph mu mv it lc b ld mk ju mw lf ml jx mx lh my mz na lj nb nc nd ll ne nf ng ln im bi translated">为了能够用 YOLOv4 训练我们的定制数据集，我们的数据集必须遵循 YOLO 格式。数据集中的每幅图像都会与一个<strong class="lc iu">相关联。txt </strong>同名文件，其中包含的对象类及其坐标遵循以下语法:<strong class="lc iu"> <em class="nl"> &lt;对象类&gt;&lt;x _ center&gt;&lt;y _ center&gt;&lt;宽度&gt; &lt;高度&gt; </em> </strong></p><p id="2820" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">有很多开源的 GUI 工具可以帮助你轻松地从图像生成标签文件，比如<a class="ae ky" href="https://github.com/developer0hye/Yolo_Label" rel="noopener ugc nofollow" target="_blank"> Yolo_label </a>、<a class="ae ky" href="https://github.com/Cartucho/OpenLabeling" rel="noopener ugc nofollow" target="_blank"> OpenLabeling </a>、<a class="ae ky" href="https://github.com/AlexeyAB/Yolo_mark" rel="noopener ugc nofollow" target="_blank"> Yolo_mark </a>、<a class="ae ky" href="https://github.com/puzzledqs/BBox-Label-Tool" rel="noopener ugc nofollow" target="_blank"> BBox-Label-Tool </a>等。只需简单地拖放你的鼠标来创建一个包围你的对象，然后工具会自动生成标签文件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/35ca9b428c683e1e6bef1fbec7d1e052.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/0*bNrxRICNhLyP4eg8"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带有开放标签的 YOLO 格式图像标签(<a class="ae ky" href="https://github.com/Cartucho/OpenLabeling" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="fc60" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">接下来，你需要创建 3 个文件:<strong class="lc iu"><em class="nl">classes . names</em></strong>，<em class="nl"/><strong class="lc iu"><em class="nl">train . txt</em></strong>和<strong class="lc iu"> <em class="nl"> test.txt </em> </strong>。<strong class="lc iu"><em class="nl">classes . names</em></strong>包含以下格式的对象名称:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="6c31" class="ns lt it no b gy nt nu l nv nw">object1_name<br/>object2_name<br/>object3_name<br/>...</span><span id="addf" class="ns lt it no b gy nx nu l nv nw">objectn_name</span></pre><p id="8f93" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">确保您的<strong class="lc iu"> <em class="nl"> &lt;对象类&gt; </em> </strong>的索引来自标签文件<strong class="lc iu"> <em class="nl">。txt </em> </strong>是对应于你的类名的索引，例如<strong class="lc iu"><em class="nl">&lt;object-class&gt;</em></strong><em class="nl"/><strong class="lc iu"><em class="nl">object 1 _ name，object2_name，</em></strong>object 3 _ name 分别是<strong class="lc iu"> 0，1，2<em class="nl"/></strong><strong class="lc iu"><em class="nl">。</em>T25】</strong></p><p id="f39c" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated"><strong class="lc iu"> <em class="nl"> train.txt </em> </strong>和<strong class="lc iu"> <em class="nl"> test.txt </em> </strong>包含您的训练图像和测试图像的文件路径。其思想是将数据集分为训练集和测试集，以便在训练集上训练模型，并在测试集上验证模型。如果你的训练集中的损失很高，这意味着你的模型<strong class="lc iu">不适合</strong>，你将需要训练更长时间。如果训练集的损失较低，测试集的损失较高，这意味着您的模型<strong class="lc iu">过度拟合，您需要添加更多数据。根据数据集中图像的数量，可以从总数据集中提取大约 5%(小数据集)到 30%(大数据集)的验证集。这两个文件的格式语法与<strong class="lc iu"><em class="nl">data/&lt;image _ path&gt;</em></strong><em class="nl">相同。</em></strong></p><p id="313f" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">在本教程中，我将使用来自<a class="ae ky" href="https://www.kaggle.com/valentynsichkar/traffic-signs-dataset-in-yolo-format" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的<strong class="lc iu">YOLO 格式的交通标志数据集</strong>。您不必现在下载它，因为我们稍后会直接从 Colab 环境下载它。它的一些图像和标签的例子如下所示(注意，一个图像可以有多个对象):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/a9c70f75e95282f0ecfb8b2368f96585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a0TK-SiZ0Z9gGPiniCeLqA.jpeg"/></div></div></figure><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="35bf" class="ns lt it no b gy nt nu l nv nw">00058.txt: 3 0.5919117647058824 0.518125 0.027941176470588237 0.05125 </span><span id="bf86" class="ns lt it no b gy nx nu l nv nw">00011.txt: 0 0.5477941176470589 0.46 0.03676470588235294 0.075 1 0.5477941176470589 0.379375 0.051470588235294115 0.09625 </span><span id="d825" class="ns lt it no b gy nx nu l nv nw">00334.txt: 0 0.25441176470588234 0.59375 0.033823529411764704 0.0575 0 0.5724264705882353 0.566875 0.027205882352941177 0.04625 </span><span id="171c" class="ns lt it no b gy nx nu l nv nw">00136.txt: 1 0.6150735294117647 0.52375 0.030147058823529412 0.045</span></pre><p id="ad17" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">总之，我们将在本教程中使用的交通标志数据集是:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="5290" class="ns lt it no b gy nt nu l nv nw">|- ts/<br/>|   |- <!-- -->00000.jpg<strong class="no iu"><br/></strong>|   |- <!-- -->00000.txt<br/>|   |- ...<br/>|- classes.names<br/>|- train.txt<br/>|- test.txt</span></pre><h1 id="eb53" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">四。与 Colab 一起培训</h1><p id="f482" class="pw-post-body-paragraph mu mv it lc b ld mk ju mw lf ml jx mx lh my mz na lj nb nc nd ll ne nf ng ln im bi translated">对于已经熟悉 Colab 的人来说，你可以直接跳到我的 Colab 笔记本<a class="ae ky" href="https://colab.research.google.com/drive/1VNc-Ywrs1XmfHcsq-BWpXZ5Zv_A2FcFn?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>开始摆弄它。但是，请确保您通过选择<strong class="lc iu">运行时- &gt;更改运行时类型&gt;硬件加速器</strong> &gt; <strong class="lc iu"> GPU、</strong>创建目录<strong class="lc iu"><em class="nl">yolov 4 _ weight/backup</em></strong>在您的<strong class="lc iu"> Google Drive </strong>和<a class="ae ky" href="https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/" rel="noopener ugc nofollow" target="_blank"><strong class="lc iu">mount Drive with Colab environment</strong></a><strong class="lc iu">。</strong></p><p id="0c03" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">如前所述，我实施了一些修改，帮助培训过程更加简单明了:</p><ul class=""><li id="5ada" class="la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="lc iu"> assert 函数</strong>:检查您是否在正确的目录路径下运行单元格的函数。如果你在错误的目录，它会提示你应该在哪个目录。如果你不知道如何改变目录，请参考 Linux 终端  <strong class="lc iu">中的这个<a class="ae ky" href="https://www.cyberciti.biz/faq/how-to-change-directory-in-linux-terminal/" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> cd 命令。</strong></a></strong></li><li id="db95" class="la lb it lc b ld mp lf mq lh mr lj ms ll mt ln lo lp lq lr bi translated"><strong class="lc iu">darknet _ for _ colab</strong>:darknet 文件夹，专门修改以适应 Colab 环境(不需要修改 MAKEFILE)。</li><li id="5c6a" class="la lb it lc b ld mp lf mq lh mr lj ms ll mt ln lo lp lq lr bi translated"><strong class="lc iu"> yolov4_config.py </strong>:利用 Colab 上的直接 python 编辑特性，您现在只需双击<strong class="lc iu"> yolov4_config.py </strong>并编辑它即可定义训练参数(<em class="nl">图 1 </em>)。比如我会设置我的<strong class="lc iu">类=4 </strong>(我们的交通标志数据集有 4 个类)<strong class="lc iu"> max_batches=8000 </strong>(训练迭代次数)<strong class="lc iu"> batch=64 </strong>(一批样本数)<strong class="lc iu"> subdivisions=16 </strong>(一批 mini_batches 数)等。你可以参考本页找到更多关于每个参数含义的细节。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/0ebcb3c6b5cce46c5ca8b4d29358cf3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jXvkWNrfrMomtGWyb4CAnw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:在 yolov4_config.py 中编辑 YOLOv4 架构及其训练参数</p></figure><ul class=""><li id="c1cc" class="la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="lc iu">yolov4 _ setup . py(cell[6]):</strong>一个 python 脚本，它根据<strong class="lc iu"> yolov4_config.py. </strong>中用户输入的参数自动生成 yolo v4 架构配置文件(<strong class="lc iu">yolo v4 _ custom _ train . CFG</strong>和<strong class="lc iu">yolo v4 _ custom _ test . CFG)</strong></li></ul><p id="f5b9" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">下面的笔记本演示了 Colab 上 YOLOv4 培训程序的流程。我会推荐你看一下我的<a class="ae ky" href="https://colab.research.google.com/drive/1VNc-Ywrs1XmfHcsq-BWpXZ5Zv_A2FcFn?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a>看看你应该期待的每个电池的输出是什么样的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="508e" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">虽然我确实定义了我的<strong class="lc iu"> max_batches=8000 </strong>，但是在 2000 次迭代之后，精度和训练结果的损失都没有太大的改善(<em class="nl">图 2 </em>)。如果使用更多的类或更难学习的数据集进行训练，迭代次数可能会增加。确保您通过双击文件<strong class="lc iu"><em class="nl">【chart.png】</em></strong>来监控损失和准确性，或者只是简单地查看来自输出单元的训练统计。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/d74f80cc58cc5d89e7a30c0db6e92b07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dzp7TbOrWK-IcceCJspy4A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2:2000 次迭代后的训练结果</p></figure><h1 id="03b5" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">动词 （verb 的缩写）用 YOLOv4 预测</h1><p id="a65b" class="pw-post-body-paragraph mu mv it lc b ld mk ju mw lf ml jx mx lh my mz na lj nb nc nd ll ne nf ng ln im bi translated">获得训练权重后，有几种方法可以用第三方框架部署 YOLOv4，包括<a class="ae ky" href="https://github.com/quangnhat185/Machine_learning_projects/blob/master/YOLOv4_traffic_signs_detection/YOLOV4_traffic_sign_detection.ipynb" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>、<a class="ae ky" href="https://github.com/Ma-Dan/keras-yolo4" rel="noopener ugc nofollow" target="_blank"> Keras </a>、<a class="ae ky" href="https://github.com/Tianxiaomo/pytorch-YOLOv4" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>等。然而，这些超出了本教程的范围。您可以使用用于训练过程的相同 Colab 工作空间来预测图像或视频(<em class="nl">图 3 和图 4 </em>)。<strong class="lc iu">单元格 13 和 15 </strong>分别为您提供了预测图像和视频的明确方法。默认情况下，预测图像保存在<strong class="lc iu"><em class="nl">predictions.jpg</em></strong>，而预测视频将保存在<strong class="lc iu"><em class="nl">output.mp4。</em> </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/5fcf995071976eecdce763d7add0422a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*651uIuqFkySmpnc9YFYihQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3:用 YOLOv4 预测图像</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi kz"><img src="../Images/8f3134eb2fce7f0c661cc831f51b09c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*7t8nc0QyggiIKW8PUBo63Q.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用 YOLOv4 预测视频流中的交通标志</p></figure><h1 id="783a" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">不及物动词结论</h1><p id="3d09" class="pw-post-body-paragraph mu mv it lc b ld mk ju mw lf ml jx mx lh my mz na lj nb nc nd ll ne nf ng ln im bi translated">本教程介绍了一种新的方法，允许您在 Google Colab 上使用 YOLOv4 轻松训练您的自定义数据集。<strong class="lc iu">所有与神经网络架构和训练参数相关的修改都是自动化的，可以在 Colab 环境中执行，同时集成单元测试以调试常见的编译错误。</strong></p><p id="16da" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated">然而，我想指出的是，使用自动化工具是有代价的。事实上，你不知道背后发生了什么可能会令人不安，尤其是那些想对 YOLOv4 架构有更好的直觉的人。既然如此，你可以参考 YOLOv4 的<a class="ae ky" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">原 GitHub 资源库或者阅读</a><a class="ae ky" href="https://medium.com/@quangnhatnguyenle/how-to-train-yolov3-on-google-colab-to-detect-custom-objects-e-g-gun-detection-d3a1ee43eda1" rel="noopener">我在 Colab </a>上训练 YOLOv3 的文章。</p><h1 id="3fec" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">资源</h1><p id="1e00" class="pw-post-body-paragraph mu mv it lc b ld mk ju mw lf ml jx mx lh my mz na lj nb nc nd ll ne nf ng ln im bi translated"><a class="ae ky" href="https://colab.research.google.com/drive/1VNc-Ywrs1XmfHcsq-BWpXZ5Zv_A2FcFn?usp=sharing" rel="noopener ugc nofollow" target="_blank">在 Colab 笔记本上训练 yolov 4</a></p><p id="81c2" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated"><a class="ae ky" href="https://github.com/quangnhat185/darknet_for_colab" rel="noopener ugc nofollow" target="_blank">colab 知识库的暗网</a></p><p id="6f75" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated"><a class="ae ky" href="https://drive.google.com/file/d/1-OGmSXd-CIOLRXWeth8UD21ssVhm-113/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">交通标志检测的 YOLOv4 权重(2000 次迭代)</a></p><p id="d45e" class="pw-post-body-paragraph mu mv it lc b ld le ju mw lf lg jx mx lh nh mz na lj ni nc nd ll nj nf ng ln im bi translated"><a class="ae ky" href="https://1drv.ms/u/s!AmvAoTF_vGyoeTqJMD2K1Ec9DO4?e=Laizbv" rel="noopener ugc nofollow" target="_blank">YOLO 格式的交通标志数据集</a></p><h1 id="3425" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">参考</h1><p id="9411" class="pw-post-body-paragraph mu mv it lc b ld mk ju mw lf ml jx mx lh my mz na lj nb nc nd ll ne nf ng ln im bi translated">[1] Bochkovskiy，Alexey，钱，和廖宏远." YOLOv4:物体探测的最佳速度和精确度."arXiv 预印本 arXiv:2004.10934  (2020)。</p></div></div>    
</body>
</html>