<html>
<head>
<title>Food for Thought — Paper Tuesday</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">思考的食粮——纸星期二</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/food-for-thought-paper-tuesday-de81f92c3e3?source=collection_archive---------44-----------------------#2020-01-28">https://towardsdatascience.com/food-for-thought-paper-tuesday-de81f92c3e3?source=collection_archive---------44-----------------------#2020-01-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9b7f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种增强图像的新方法</h2></div><p id="a082" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每周二，我都会强调我在研究或工作中遇到的一篇有趣的论文。希望我的评论能帮助你在2分钟内获得论文中最多汁的部分！</p><h2 id="a0ae" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">基本思想</h2><p id="99e8" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">深度神经网络在许多计算机视觉任务中具有无与伦比的性能，如图像分类、对象分割和图像生成。许多人会认为，正是数百万个参数赋予了模型学习困难任务的能力。然而，天下没有免费的午餐。如果我们想训练更多的参数，我们就需要更多的数据。数据扩充是一种通过简单的转换从收集的数据中生成新数据的方法。更具体地说，当涉及到图像时，人们习惯于随机旋转和翻转图像或者改变亮度和色调。</p><p id="fca6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最近，香港中文大学的一组研究人员开发了一种惊人简单而有效的增强方法，可以与最复杂的自动增强算法相媲美。这是这篇论文的链接:</p><p id="4022" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lz"> GridMask数据增强</em>，【https://arxiv.org/pdf/2001.04086.pdf】T2</p><p id="3fd5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">信息丢弃通过去除图像中的像素，迫使网络更少地关注输入数据的琐碎细节。这里有一个例子:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/33787bb42077941fa150a536190474eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*n8t7rj9Kb1KM3iFvxpx8ew.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">来自<a class="ae ma" href="https://arxiv.org/pdf/2001.04086.pdf" rel="noopener ugc nofollow" target="_blank"> GridMask数据增强</a></p></figure><p id="3fd1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据作者的观点，现有解决方案如随机擦除、剪切和捉迷藏的两个问题是连续区域的过度删除和保留。例如，在上面的图像中，第二个和第四个地块(左起)遭受了过度删除，第一个遭受了连续区域的保留(我们希望删除狗的某个部分，而不仅仅是草)</p><p id="88d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者发现了一种更好地避免这两个问题的直接方法——从图像中移除网格块。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/46bc69714b0dce7bb499501df5e40798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*HYpGnA6HJ50U9-HCJlWw7Q.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">来自<a class="ae ma" href="https://arxiv.org/pdf/2001.04086.pdf" rel="noopener ugc nofollow" target="_blank"> GridMask数据增强</a></p></figure><p id="16d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">算法就是这么简单！创建一个遮罩(上图中的第二行)并将其与原始图像相乘。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/9eda1ddd18b85d6d192ef3f4eee81ffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*OCZO09ScDZxUSGIU4FWblg.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">来自<a class="ae ma" href="https://arxiv.org/pdf/2001.04086.pdf" rel="noopener ugc nofollow" target="_blank"> GridMask数据增强</a></p></figure><h2 id="b49f" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">结果</h2><p id="2287" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">作者证明，与当前方法相比，GridMask不太可能移除(过度删除)或保留99+%(过度保留)目标对象。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mp"><img src="../Images/ebe4d3af125cef3811ca3e010b580c96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mFP2aswvHzqAFpttj5VrCg.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">来自<a class="ae ma" href="https://arxiv.org/pdf/2001.04086.pdf" rel="noopener ugc nofollow" target="_blank"> GridMask数据增强</a></p></figure><p id="c1ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者还在ImageNet -1K和CIFAR10等标准数据集上测试了GridMask，并展示了这种简单算法的潜力。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/45a15d4105ad55b2ed86840c94f017f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*rHl6NvxJScCYnjYp0dN0-g.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">来自<a class="ae ma" href="https://arxiv.org/pdf/2001.04086.pdf" rel="noopener ugc nofollow" target="_blank"> GridMask数据增强</a></p></figure><p id="cfde" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">令人惊讶的是，GridMask不断超越所有其他信息丢弃方法！</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/8d40176ac0b337d8788801150308871a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*0jLcgIm6xcowKL5VJ6KX0w.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">来自<a class="ae ma" href="https://arxiv.org/pdf/2001.04086.pdf" rel="noopener ugc nofollow" target="_blank"> GridMask数据增强</a></p></figure><p id="6d3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我在文章前面提到的，信息丢弃是一种有效的正则化方式。GridMask也是一个很好的正则化方法。</p><h2 id="413d" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">一些想法</h2><p id="65a9" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">虽然1%的改善在现实生活中并不显著，但在Kaggle这样的数据科学竞赛中却非常有用，在这些竞赛中，人们创建了巨大的集合模型，只是为了小幅增加。这篇文章提醒所有人，我们应该花更多的时间探索简单的技巧，而不是参与“军备竞赛”，在这场竞赛中，人们只是堆积更多的参数。</p></div></div>    
</body>
</html>