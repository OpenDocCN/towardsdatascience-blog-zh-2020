<html>
<head>
<title>Quick and Easy Explanation of Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">快速简单地解释逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/quick-and-easy-explanation-of-logistics-regression-709df5cc3f1e?source=collection_archive---------5-----------------------#2020-04-06">https://towardsdatascience.com/quick-and-easy-explanation-of-logistics-regression-709df5cc3f1e?source=collection_archive---------5-----------------------#2020-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1284" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">对逻辑回归的简单解释，我们为什么需要它，如何评估它的性能，以及在 python 中使用逻辑回归构建多类分类</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9fd8be95cbc0c96c4a659defc7161bcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0qaEaMZYOJ90cJ4puZcg8w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:Muskaan Arshad</p></figure><h1 id="6aa7" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">逻辑回归</h1><p id="850d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">它是一种使用自变量预测因变量的预测算法，就像线性回归一样，但不同之处在于因变量应该是分类变量。</p><p id="ae78" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">自变量可以是数字或分类变量，但因变量总是分类的</strong></p><p id="1860" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">逻辑回归是一种统计模型，它使用逻辑函数来模拟条件概率。</p><p id="41d5" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">对于二元回归，给定自变量 X，我们计算因变量 Y 的条件概率</p><p id="bb5a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">可以写成<strong class="ls iu"> <em class="mr"> P(Y=1|X)或者 P(Y=0|X) </em> </strong></p><p id="f2de" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu"> <em class="mr">这读作 Y=1，给定 X 的条件概率或者 Y=0，给定 X 的条件概率</em> </strong></p><p id="82e1" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu"> <em class="mr"> P(Y |X)近似为应用于输入特征的线性组合的 sigmoid 函数</em> </strong></p><p id="e139" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">逻辑回归的一个例子是发现一个人是否会拖欠他们的信用卡付款。一个人拖欠信用卡付款的概率可以基于未决的信用卡余额和收入等。</p><p id="5b4e" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">于是，我们可以写出<strong class="ls iu"><em class="mr">【P(默认=是|余额)</em> </strong></p><p id="aeb9" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">当<strong class="ls iu"><em class="mr">【P(default = yes)≥0.5，</em> </strong>那么我们就说这个人会拖欠自己的货款。</p><p id="3c6d" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">当<strong class="ls iu"><em class="mr">P(default = yes)&lt;</em></strong>0.4 时，那么我们就说这个人不会拖欠他们的付款。</p><p id="18d1" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">概率总是在 0 和 1 之间。在二元分类的情况下，拖欠付款和不拖欠付款的概率总和为 1 </p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/0bb4d5727eccfe8f42f4b55d55eb0f2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*rkLXw84xaYxPf_jmKnJePw.png"/></div></figure><p id="0ffd" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu"> Logistic 回归可用于二元分类或多类分类。</strong></p><p id="3fb8" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><em class="mr">二元分类是指当我们有两种可能的结果时，比如一个人感染了新冠肺炎或者没有感染新冠肺炎。在多类分类中，我们有多种结果，比如一个人可能患了流感或过敏，或者感冒或新冠肺炎。</em></p><h1 id="d17b" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">逻辑回归的假设</h1><ul class=""><li id="46c3" class="mt mu it ls b lt lu lw lx lz mv md mw mh mx ml my mz na nb bi translated">数据中没有异常值。<a class="ae nc" href="https://medium.com/datadriveninvestor/finding-outliers-in-dataset-using-python-efc3fce6ce32" rel="noopener">异常值</a>可以通过分析独立变量来识别</li><li id="ce99" class="mt mu it ls b lt nd lw ne lz nf md ng mh nh ml my mz na nb bi translated">独立变量之间没有相关性(多重共线性)。</li></ul><h1 id="aa84" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">逻辑回归函数</h1><p id="9986" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated"><strong class="ls iu"> Logistic 回归使用 logit 函数，也称为 log-odds</strong>；它是几率的对数。比值比是存在事件 B 时事件 A 的比值和不存在事件 B 时事件 A 的比值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/ac20c7c3b03022b13ba1d4f924fa9157.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*J3ydXZrpJdXefOmx9YIdaQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">logit 或逻辑函数</p></figure><ul class=""><li id="1ab8" class="mt mu it ls b lt mm lw mn lz nj md nk mh nl ml my mz na nb bi translated">p 是事件 Y 发生的概率。P(Y=1)</li><li id="418d" class="mt mu it ls b lt nd lw ne lz nf md ng mh nh ml my mz na nb bi translated">P/(1-P)是优势比</li><li id="ac3a" class="mt mu it ls b lt nd lw ne lz nf md ng mh nh ml my mz na nb bi translated">θ是一个长度为 m 的参数</li></ul><p id="10e3" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">Logit 函数估计 0 到 1 之间的概率，因此逻辑回归是一种非线性变换，看起来像下面显示的 S 函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/6f924acee292a17802a5c71b3b27fc02.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*LOre2iyY2Q64VR2_AareWA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">逻辑回归函数</p></figure><p id="6d2a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">可以使用最大似然估计(MLE)框架来估计逻辑函数的参数“θ”。MLE 搜索与独立变量 x 的联合概率最匹配的参数。</p><p id="7a93" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">MLE 将为我们提供参数“θ”的值，该值将使拖欠付款的人的概率最大化，接近 1，使所有不拖欠付款的人的概率最大化，接近 0。</p><h1 id="9032" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">评价二元分类性能的混淆矩阵</h1><p id="dfff" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">混淆矩阵是一个表格，它告诉我们模型预测的不同类别存在多少实际值和预测值。也被称为<strong class="ls iu">误差矩阵。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/772fe2a1aa8b7cd8f91e7b5f967ab14e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MJPj3pIkrFGiLbgW.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">混淆矩阵或误差矩阵以及不同的度量标准</p></figure><p id="907d" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">解释关键术语</p><p id="6a47" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">真阳性</strong>:当一个女性怀孕了，而我们预测她怀孕了</p><p id="ac9b" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">真否定</strong>:当一个男性没有怀孕，而我们预测他没有怀孕</p><p id="ebe1" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">假阴性</strong>:当女性怀孕，但我们预测她没有怀孕。又称<strong class="ls iu">2 型错误。</strong></p><p id="a252" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">假阳性</strong>:男性不可能怀孕，但我们预测他怀孕了。也称为<strong class="ls iu">类型 1 错误</strong></p><h1 id="2549" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">在 Iris 数据集上实现逻辑回归</h1><p id="f633" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">数据可以从<a class="ae nc" href="http://archive.ics.uci.edu/ml/machine-learning-databases/iris/" rel="noopener ugc nofollow" target="_blank">这里</a>下载</p><p id="59d4" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">导入所需的库</strong></p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="f385" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">import pandas as pd<br/>import numpy as np<br/>from matplotlib import pyplot as plt<br/>import seaborn as sns<br/>from sklearn.model_selection import train_test_split</strong></span><span id="b4f5" class="nt kz it np b gy ny nv l nw nx"><strong class="np iu">%matplotlib inline</strong></span></pre><p id="c326" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">读取数据</strong></p><p id="420a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">从<a class="ae nc" href="http://from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split" rel="noopener ugc nofollow" target="_blank">链接</a>下载数据，保存在 CSV 文件中，并添加标题。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="44dd" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">dataset=pd.read_csv("iris.csv")</strong><br/>dataset.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/cd537c25bbb2f8d84938e78daa2ba70a.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*qeMW8ASIxr6KhCBoMpoIRQ.png"/></div></figure><p id="c90d" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">显示数据集中的几行</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="0b0d" class="nt kz it np b gy nu nv l nw nx">dataset.head(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/64c3e1f915cd36760a833c83d369a9a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*FrShW3cb-Pvn1qlpjvqOAg.png"/></div></figure><p id="89a9" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">使用可视化进行数据分析</strong></p><p id="fdd3" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">将数据可视化，以便更好地理解自变量和因变量</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="95d0" class="nt kz it np b gy nu nv l nw nx">sns.boxplot(x="class",y="petal length",data=dataset)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/2ad6aae47e2e3eb4777d6864b1581d93.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*G5foPfSLHR0GQS58QohxUw.png"/></div></figure><p id="01df" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">使用花瓣长度和花瓣宽度的不同种类鸢尾的散点图</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="251e" class="nt kz it np b gy nu nv l nw nx">sns.scatterplot(x='petal length', y='petal width', hue="class", data=dataset)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/8a4252bd9716671a696fcddca633a359.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*7WMMX5Edf1rdQTkE7USvFA.png"/></div></figure><p id="754d" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">利用萼片长度和萼片宽度绘制不同种类鸢尾的散点图</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="6b4e" class="nt kz it np b gy nu nv l nw nx">sns.scatterplot(x='sepal length', y='sepal width', hue="class", data=dataset)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/88899ce36b0463749536be6ffc8a0fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*hCpqEfw2dMjWrwbZco3hLw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">E</p></figure><p id="a701" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">将虹膜的类别从分类编码为数值</strong></p><p id="dc53" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">目标变量是代表鸢尾植物类别的字符串。我们将分类字符串数据编码成数值，以便模型理解</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="70e8" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">from sklearn.preprocessing import LabelEncoder<br/>le= LabelEncoder()<br/>y_encoded=le.fit_transform(y)</strong></span></pre><p id="f220" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">打印目标变量的编码值。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="42ca" class="nt kz it np b gy nu nv l nw nx">y_encoded</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/9f6a6e15501586eaf1db45004b2493f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U_h-nUd0ASmaLW6v8AkTww.png"/></div></div></figure><p id="379f" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu"> <em class="mr">我们有一个多类分类问题，因为鸢尾植物</em> </strong>类有三个不同的值</p><p id="02c6" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">将数据集分为训练和测试数据集</strong></p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="55e6" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test= train_test_split(X,y_encoded,test_size=0.2)</strong></span></pre><h2 id="8bae" class="nt kz it bd la of og dn le oh oi dp li lz oj ok lk md ol om lm mh on oo lo op bi translated">使用逻辑回归训练数据集</h2><p id="ec44" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我们正在使用逻辑回归为多类分类训练数据集</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="42e7" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">from sklearn.linear_model import LogisticRegression<br/>clf = LogisticRegression(random_state=0).fit(X_train, y_train)</strong></span></pre><p id="de0f" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">预测测试数据的虹膜类别</strong></p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="b829" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">y_pred=clf.predict(X_test)</strong></span></pre><p id="4b14" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">评估逻辑回归模型的性能</strong></p><p id="3217" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">使用混淆矩阵来评估多类分类的性能</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="6a11" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">from sklearn.metrics import confusion_matrix<br/>cnf_matrix=confusion_matrix(y_test, y_pred, labels=[0,1,2])<br/>cnf_matrix</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/143c26163514f9446fb27c43c568020b.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*0F9aikam-Tl_7oLDmJrQGQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">混淆矩阵</p></figure><p id="0ec5" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这个输出没有太大帮助，所以我们将数字目标变量反向转换回原来的类名</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="d2c0" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">y_pred_orig= le.inverse_transform(y_pred)</strong></span></pre><p id="1ab3" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我们还编写了一个函数，以更易读的格式显示混淆矩阵</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="f187" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">def plot_confusion_matrix(cm, classes,<br/>                          title='Confusion Matrix',<br/>                          cmap=plt.cm.Greens)</strong>:<br/>   <br/>    import itertools<br/>    <br/>    print('Confusion Matrix')<br/>    plt.imshow(cm, interpolation='nearest', cmap=cmap)<br/>    plt.title(title)<br/>    tick_marks = np.arange(len(classes))<br/>    plt.xticks(tick_marks, classes, rotation=90)<br/>    plt.yticks(tick_marks, classes)<br/>    fmt = '.2f' <br/>    thresh = cm.max() / 2.<br/>    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):<br/>        plt.text(j, i, format(cm[i, j], fmt),<br/>                 horizontalalignment="center",<br/>                 color="white" if cm[i, j] &gt; thresh else "black")</span><span id="aafa" class="nt kz it np b gy ny nv l nw nx">plt.ylabel('Actual label')<br/>    plt.xlabel('Predicted label')<br/>    plt.tight_layout()</span></pre><p id="a54a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">显示混淆矩阵</strong></p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="cc97" class="nt kz it np b gy nu nv l nw nx"><strong class="np iu">plt.figure()<br/>plot_confusion_matrix(cnf_matrix, classes=le.classes_,<br/>                      title='Confusion matrixfor Iris test data')</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/340f64efb8280ef0ca6a06f479f7d2e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*E9rKVabpDsYj0I0D66Z80g.png"/></div></figure><h2 id="e23a" class="nt kz it bd la of og dn le oh oi dp li lz oj ok lk md ol om lm mh on oo lo op bi translated">结论:</h2><p id="6e77" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">逻辑回归用于二元或多类分类，目标变量必须是分类变量。</p><h2 id="ff10" class="nt kz it bd la of og dn le oh oi dp li lz oj ok lk md ol om lm mh on oo lo op bi translated">参考资料:</h2><p id="89b3" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated"><a class="ae nc" href="https://web.stanford.edu/class/archive/cs/cs109/cs109.1178/lectureHandouts/220-logistic-regression.pdf" rel="noopener ugc nofollow" target="_blank">https://web . Stanford . edu/class/archive/cs/cs 109/cs 109.1178/讲师讲义/220-logistic-regression . pdf</a></p></div></div>    
</body>
</html>