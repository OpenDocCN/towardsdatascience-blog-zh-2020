<html>
<head>
<title>Automated Machine Learning using Python3.7: Improving Efficiency in Model Development</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python3.7 的自动机器学习:提高模型开发的效率</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automated-machine-learning-using-python3-7-improving-efficiency-in-model-development-8c3574febc0b?source=collection_archive---------10-----------------------#2020-02-08">https://towardsdatascience.com/automated-machine-learning-using-python3-7-improving-efficiency-in-model-development-8c3574febc0b?source=collection_archive---------10-----------------------#2020-02-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2436" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">作者:<a class="ae ki" href="https://www.linkedin.com/in/saleh-alkhalifa" rel="noopener ugc nofollow" target="_blank">萨利赫·阿勒哈利法</a>和<a class="ae ki" href="https://www.linkedin.com/in/conclancy" rel="noopener ugc nofollow" target="_blank">康纳·克兰西</a></h2></div></div><div class="ab cl kj kk hx kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="im in io ip iq"><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kq"><img src="../Images/c1f69cef2720a54cb9e56a01df318a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R9L-w-Kk_aiQ5m9R4XLcLg.png"/></div></div></figure><h1 id="d346" class="lc ld it bd le lf lg lh li lj lk ll lm jz ln ka lo kc lp kd lq kf lr kg ls lt bi translated">介绍</h1><p id="390c" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">随着过去几年数据科学的兴起，已经开发了各种 Python 工具和库来提高效率和扩展该领域科学家、分析师和程序员的能力。在<strong class="lw iu"> 2018 </strong>中，一些最受欢迎的<strong class="lw iu">技能组合</strong>包括<em class="mq">熊猫</em>和<em class="mq"> Scikit-learn </em>的高级使用。在<strong class="lw iu"> 2019 </strong>中，一些最可雇佣的技能组合包括使用<em class="mq"> PyTorch </em>和<em class="mq"> Keras </em>。也就是说，2020 年的新年对我们有什么需求？在 2020 年，最受欢迎的技能之一将是自动化概念(T21)。</p><p id="41ab" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">从数据科学的角度来看，大部分自动化通常是在机器学习模型的部署阶段观察到的。数据科学家准备数据、训练模型和部署解决方案，以循环的方式完成特定的任务。自动化的思想很少用在模型开发过程中。然而，考虑到我们已经看到的有利于自动化的转变，本文将展示如何在模型开发阶段使用自动化，使用<em class="mq"> GridSearchCV </em>和<em class="mq"> TPOT </em> Python 库来识别准确的模型，以实现更快的模型部署。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi mw"><img src="../Images/2ba62d3e33880952d8b160c5f0d4d177.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CGNmzGv0SfQKBVv1DK2dg.png"/></div></div><p class="mx my gj gh gi mz na bd b be z dk translated">图 1-机器学习模型开发过程。自动化通常出现在项目的部署阶段。然而，本文将展示自动化在过程的开发和验证阶段的使用。</p></figure></div><div class="ab cl kj kk hx kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="im in io ip iq"><h1 id="3182" class="lc ld it bd le lf nb lh li lj nc ll lm jz nd ka lo kc ne kd lq kf nf kg ls lt bi translated">标准算法选择</h1><p id="3b35" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">机器学习算法，如<em class="mq">决策树</em>、<em class="mq">支持向量机</em>或<em class="mq">K-最近邻</em>，都需要输入数据和各种参数或超参数的调整。超参数通常是由数据科学家选择的参数，如邻居的数量或树的最大深度。参数是由模型选择的内部值，例如权重。按照图 2 的原理图，采集数据，通过迭代每个算法并微调参数和超参数，开发多个模型。基于所需的标准对每个迭代进行评分，例如<em class="mq">准确性</em>和<em class="mq">F1-分数</em>，并选择得分最高的模型进行部署。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi ng"><img src="../Images/9ec50523bd98bf99ac2c0715e5aa48da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F3RjcHxMFtDqrEQw7b85Uw.png"/></div></div><p class="mx my gj gh gi mz na bd b be z dk translated">图 2——以传送带方式筛选算法的标准流程。</p></figure><p id="14b6" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">在开发和验证阶段，可能会使用 8-10 种不同的算法对每个数据集进行训练和评分，图 2 中列出了其中几种算法。在每种算法中，通常有 6-10 个超参数需要优化，其中许多参数的范围是无限的。假设每个模型都系统地尝试了超参数的每种可能的逻辑组合，则需要创建和测试大约 800 个模型。如果每个程序平均运行 2-3 分钟(取决于数据集的大小)，那么算法选择的参数优化将需要 2600 分钟，即每周 40 小时的标准工作时间。想象一下，如果在某种程度上，这个过程可以通过开源 Python 库实现自动化，将会取得多大的成就。</p></div><div class="ab cl kj kk hx kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="im in io ip iq"><h1 id="890e" class="lc ld it bd le lf nb lh li lj nc ll lm jz nd ka lo kc ne kd lq kf nf kg ls lt bi translated">自动化机器学习</h1><p id="677c" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">在<em class="mq"> Pypi </em>中有许多允许自动算法选择和调整的库。一些著名的库包括<a class="ae ki" href="https://pypi.org/project/automl/" rel="noopener ugc nofollow" target="_blank"> <em class="mq"> AutoML </em> </a>，<a class="ae ki" href="https://pypi.org/project/mlbox/" rel="noopener ugc nofollow" target="_blank"> <em class="mq"> MLBox </em> </a>，<em class="mq"/><a class="ae ki" href="https://pypi.org/project/auto-sklearn/" rel="noopener ugc nofollow" target="_blank"><em class="mq">Auto-sk learn</em></a>，<a class="ae ki" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection" rel="noopener ugc nofollow" target="_blank"> <em class="mq"> GridSearchCV </em> </a>，以及<a class="ae ki" href="https://pypi.org/project/TPOT/" rel="noopener ugc nofollow" target="_blank"><em class="mq">【TPOT</em></a>——其中最后两个将是本文的重点。</p><p id="0798" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">我们将从 scikit-learn 自己的四个超参数优化器开始:</p><pre class="kr ks kt ku gt nh ni nj nk aw nl bi"><span id="f620" class="nm ld it ni b gy nn no l np nq">[1] <a class="ae ki" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection" rel="noopener ugc nofollow" target="_blank">model_selection.<strong class="ni iu">GridSearchCV </strong><br/>[2] model_selection.<strong class="ni iu">ParameterGrid</strong><br/>[3] model_selection.<strong class="ni iu">ParameterSampler</strong><br/>[4] model_selection.<strong class="ni iu">RandomizedSearchCV</strong></a></span></pre><p id="54c9" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">选择超参数范围的方法是这些优化器之间的主要区别。第一个选项<a class="ae ki" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" rel="noopener ugc nofollow" target="_blank"> <em class="mq"> GridSearchCV </em> </a>利用了一种穷举方法，其中尝试了参数的每一种可能的组合。另一方面，<em class="mq"> RandomizedSearchCV </em>尝试相同的方法，然而，尝试的是全部可能组合的随机子集。让我们在下面的例子中仔细看看<em class="mq"> GridSearchCV </em>。</p><h2 id="9570" class="nm ld it bd le nr ns dn li nt nu dp lm md nv nw lo mh nx ny lq ml nz oa ls ob bi translated">数据创建和基线识别</h2><p id="e01a" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">我们将继续导入<em class="mq"> make_blobs </em>库来生成一些数据供我们使用。我们将创建一个具有 4 个中心的 3D 数据集，并使用标准差 2 将它们更紧密地聚集在一起。这将确保数据没有很好地分离，并且需要开发更复杂的模型。</p><pre class="kr ks kt ku gt nh ni nj nk aw nl bi"><span id="1aa1" class="nm ld it ni b gy nn no l np nq">import pandas as pd<br/>from sklearn.datasets import make_blobs</span><span id="06a1" class="nm ld it ni b gy oc no l np nq">X, y = make_blobs(n_samples=600, # Total number of samples.<br/>                      centers=4, # Number of centers.<br/>                   n_features=3, # Number of columns of features.<br/>                random_state=42, # The random seed state.<br/>                cluster_std = 2, # The standard deviation.<br/>                  )<br/><br/>df = pd.DataFrame(X)<br/>df.columns = ["col_1", "col_2", "col_3"]<br/>df["Label"] = y<br/></span></pre><p id="2cfd" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">为了确认我们的数据的形状和整体外观，我们可以将它绘制成 3D 散点图，如下所示。</p><pre class="kr ks kt ku gt nh ni nj nk aw nl bi"><span id="8687" class="nm ld it ni b gy nn no l np nq">from mpl_toolkits.mplot3d import Axes3D<br/><br/>fig = plt.figure()<br/>ax = fig.add_subplot(111, projection='3d')<br/>ax.scatter(df["col_1"],   # X <br/>           df["col_2"],   # Y<br/>           df["col_3"],   # Z<br/>       c = df["Label"],   # Color By<br/>         cmap='Accent',   # Colors<br/>                   s=5,   # Size<br/>          )<br/><br/>ax.set_xlabel('X Axis')<br/>ax.set_ylabel('Y Axis')<br/>ax.set_zlabel('Z Axis')<br/><br/>plt.show()</span></pre><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi od"><img src="../Images/76d53eaf80076d0a702f6454d5bea56d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EoxWS9SXcD8IHaq9DDPrNw.png"/></div></div><p class="mx my gj gh gi mz na bd b be z dk translated">图 3 —手边数据集的 3D 表示。</p></figure><p id="325f" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">随着数据集的构建和准备就绪，我们可以继续选择一个模型。给定数据的形状、质心的位置和可分性，我们将尝试使用支持向量机(<em class="mq"> SVM </em>)算法来训练分类器。</p><pre class="kr ks kt ku gt nh ni nj nk aw nl bi"><span id="7c14" class="nm ld it ni b gy nn no l np nq">## SVM Classifier:</span><span id="5399" class="nm ld it ni b gy oc no l np nq">from sklearn.svm import SVC<br/>svc_clf = SVC(gamma='auto',<br/>              kernel = "poly",<br/>              C = 0.1,<br/>              degree = 4,<br/>              tol = 0.01,<br/>              random_state=42<br/>              )</span><span id="1973" class="nm ld it ni b gy oc no l np nq">svc_clf.fit(X_train, y_train)</span><span id="8e68" class="nm ld it ni b gy oc no l np nq"># SVM  Results:</span><span id="f1b4" class="nm ld it ni b gy oc no l np nq">     precision    recall  f1-score   support</span><span id="5cac" class="nm ld it ni b gy oc no l np nq">0       0.58      0.91      0.71        35<br/>1       0.92      0.59      0.72        41<br/>2       1.00      0.86      0.93        44<br/>3       0.97      1.00      0.98        30</span><span id="936f" class="nm ld it ni b gy oc no l np nq">    accuracy                           0.83       150<br/>   macro avg       0.87      0.84      0.83       150<br/>weighted avg       0.87      0.83      0.83       150</span><span id="13bb" class="nm ld it ni b gy oc no l np nq">print("SVM Accuracy: ", accuracy_score(y_test, svc_predictions, normalize=True, sample_weight=None)*100)</span><span id="5137" class="nm ld it ni b gy oc no l np nq">SVM Accuracy: 82.6%</span></pre><p id="8bd7" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">我们的第一次尝试显示，使用上面显示的参数，一个<em class="mq"> SVM </em>算法的准确率大约为 82%。现在可以迭代上面显示的各种参数来提高精度；然而，<em class="mq"> GridSearchCV </em>可以更有效、更系统地处理这些问题。</p><h2 id="e494" class="nm ld it bd le nr ns dn li nt nu dp lm md nv nw lo mh nx ny lq ml nz oa ls ob bi translated">GridSearchCV</h2><p id="19aa" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">将尝试使用以下方法准备<em class="mq"> GridSearchCV </em>。将设置可能的参数范围，并且模型将尝试选择产生最佳结果的参数集。</p><pre class="kr ks kt ku gt nh ni nj nk aw nl bi"><span id="5063" class="nm ld it ni b gy nn no l np nq"><br/>from sklearn.svm import SVC<br/>from sklearn.model_selection import GridSearchCV<br/>svc_clf = SVC(gamma = 'auto')<br/>parameters = {'kernel':('linear', 'rbf'), 'C':[1, 2, 5, 10], "degree" : [1,2,3,4,5], "tol" : [0.001, 0.01, 0.1, 1]}<br/>clf = GridSearchCV(svc_clf, parameters, cv = 5)<br/>clf.fit(X_train, y_train)<br/>print ("Best Params: ", clf.best_params_)</span><span id="4bf4" class="nm ld it ni b gy oc no l np nq">Best Params: {'C': 1, 'degree': 1, 'kernel': 'linear', 'tol': 0.001}</span></pre><p id="82e3" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">随后使用推荐的参数重新运行<em class="mq"> SVM </em>算法，我们可以达到 96%的准确率，比我们上面设定的基准高出 14%!</p><p id="365e" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">总结该过程，允许该库迭代所有可能的参数条件，并选择显示最有希望得分的条件集。这个过程太棒了。但是，这仍然需要为 7–9 个其他算法进行设置。这就是像<em class="mq"> TPOT </em>这样的库可以用于进一步开发自动化的地方！</p><h2 id="7ad9" class="nm ld it bd le nr ns dn li nt nu dp lm md nv nw lo mh nx ny lq ml nz oa ls ob bi translated">TPOT 图书馆</h2><p id="37b3" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated"><a class="ae ki" href="http://epistasislab.github.io/tpot/using/#tpot-with-code" rel="noopener ugc nofollow" target="_blank"> <em class="mq"> TPOT </em> </a>库执行类似上面所示的搜索；在感兴趣的各种算法中的每一个上，迭代和调整后续参数。下面的图 4 描述了<em class="mq"> TPOT </em>库运行的过程。该库导入数据集，并处理与特征预处理、特征选择和特征构造相关的所有项目。然后，TPOT 专注于算法选择、参数调整和模型验证，以优化模型。<em class="mq"> TPOT </em>实现了<a class="ae ki" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <em class="mq"> XGBoost </em> </a>的使用，这是一个优化的分布式梯度增强库，旨在提高您的流程的效率和灵活性。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi oe"><img src="../Images/bccb500a1880455293b155d4c11115b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c60M30QbqQLeUbjrOxrzLw.png"/></div></div><p class="mx my gj gh gi mz na bd b be z dk translated">图 4——TPOT 图书馆运作流程示意图。</p></figure><p id="6431" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">出于本教程的目的，<em class="mq"> TPOT </em>将通过下面这段代码确定算法和参数。</p><pre class="kr ks kt ku gt nh ni nj nk aw nl bi"><span id="33b8" class="nm ld it ni b gy nn no l np nq">from tpot import TPOTClassifier<br/><br/>pipeline_optimizer = TPOTClassifier(<br/>    generations=5,         # Number of iterations<br/>    population_size=30,    # number of individuals <br/>    cv=5,                  # Cross validationpipelines<br/>    random_state=42,       # The seed of the pseudo random generator<br/>    verbosity=3,           # Level of communication <br/>    scoring="f1_weighted"  # Scoring evaluation<br/>)<br/><br/>pipeline_optimizer.fit(X_train, y_train)<br/>pipeline_optimizer.score(X_test, y_test)<br/><br/>pipeline_optimizer.export('tpot_exported_pipeline.py')<br/>print(pipeline_optimizer.fitted_pipeline_)</span></pre><p id="754a" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">完成此过程后，管道将导出一个名为<em class="mq">tpot _ exported _ pipeline . py</em>的文件，其中包含模型和结果。我们可以从打印在最后一行的拟合管道中看到，正确分类数据集数据点的最佳参数应该使用以下内容:</p><pre class="kr ks kt ku gt nh ni nj nk aw nl bi"><span id="c065" class="nm ld it ni b gy nn no l np nq">Pipeline(memory=None,<br/>         steps=[('gaussiannb', <br/>                   GaussianNB(priors = None,<br/>                       var_smoothing = 1e-09))],verbose=False)</span></pre><p id="f520" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">使用<em class="mq">高斯算法</em>重新运行数据集后，我们达到了<strong class="lw iu"> 98% </strong>的准确率！大约比我们上一个型号高 2%。</p></div><div class="ab cl kj kk hx kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="im in io ip iq"><h1 id="98ba" class="lc ld it bd le lf nb lh li lj nc ll lm jz nd ka lo kc ne kd lq kf nf kg ls lt bi translated">结论</h1><p id="b366" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">在机器学习模型开发过程的模型开发和验证阶段，可以使用<em class="mq"> GridSearchCV </em>和<em class="mq"> TPOT </em>库。<em class="mq"> GridSearchCV </em>专门用于识别给定算法的最佳超参数；我们成功地将准确率提高了 14%,而没有明显的召回损失，总准确率达到 96%。<em class="mq"> TPOT </em>用于自动算法和超参数选择，从而成功地将我们的准确率提高到 98%。<strong class="lw iu">在模型开发阶段实施这两种方法</strong> <strong class="lw iu">将有助于提高模型的准确性，减少总的开发时间。</strong></p><p id="e11a" class="pw-post-body-paragraph lu lv it lw b lx mr ju lz ma ms jx mc md mt mf mg mh mu mj mk ml mv mn mo mp im bi translated">我们希望这篇文章既有益又有趣。一如既往，我们试图迎合我们的文章，以满足经验和非经验用户的需求。对于未来文章的建议，请随时通过文章顶部的 LinkedIn 个人资料联系我们。</p></div></div>    
</body>
</html>