<html>
<head>
<title>Generative Adversarial Network (GAN) for Dummies — A Step By Step Tutorial</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">虚拟生成对抗网络(GAN)——循序渐进教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391?source=collection_archive---------1-----------------------#2020-04-20">https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391?source=collection_archive---------1-----------------------#2020-04-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="563d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解、构建和训练具有防弹Python代码的GANs的终极初学者指南。</h2></div><p id="1454" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章介绍了你需要从生成性敌对网络中获得的一切。不需要预先了解GANs。我们提供了如何在大型图像数据集上训练GANs并使用它们通过Keras生成新的名人脸的分步指南。</p><blockquote class="le"><p id="f8b5" class="lf lg it bd lh li lj lk ll lm ln ld dk translated">人工智能教父、脸书副总裁兼首席人工智能科学家Yann LeCun的“生成对抗网络——过去十年机器学习中最有趣的想法”。</p></blockquote><figure class="lp lq lr ls lt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lo"><img src="../Images/07403d5738dbbcf31ef50efe0edde18f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZsBahmJpzKU9dcMN"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">Alex Iby 在Unsplash上拍摄的照片</p></figure><p id="1d02" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然生成对抗网络(GAN)是一个源于博弈论的旧思想，但它们是由Ian J. Goodfellow和合著者在文章<a class="ae mf" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">生成对抗网络</a>中于2014年引入机器学习社区的。GAN是如何工作的，它有什么用途？</p><blockquote class="le"><p id="f8e5" class="lf lg it bd lh li lj lk ll lm ln ld dk translated">甘斯可以创造出看起来像人脸照片的图像，尽管这些人脸并不属于任何真实的人。</p></blockquote><figure class="lp lq lr ls lt lu gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/a946b71e6868d2966050d1bdb786d5ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*ttKg44j9FTelAChiuUL_WA.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">阿甘创造的仿真人脸(<a class="ae mf" href="https://research.nvidia.com/sites/default/files/pubs/2017-10_Progressive-Growing-of/karras2018iclr-paper.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="ec02" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在上一篇文章的<a class="ae mf" rel="noopener" target="_blank" href="/variational-autoencoders-vaes-for-dummies-step-by-step-tutorial-69e6d1c9d8e9">中看到了如何使用可变自动编码器生成新的照片级逼真图像。我们的VAE是在著名的</a><a class="ae mf" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" rel="noopener ugc nofollow" target="_blank">名人面孔数据集</a>上接受训练的。</p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mh"><img src="../Images/73636963e3b2349b7aa600466d227819.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WhMFSptTVKlEIQ55KHi36A.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">使用我们的VAE码(自创)的图像及其重建的例子</p></figure><p id="460b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">VAEs通常会产生模糊和非真实感的人脸。这是建立生成性对抗网络的动机。</p><p id="7c7b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们将研究GANs如何提供一种完全不同的方法来生成与训练数据相似的数据。</p><h1 id="a5e0" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">概率游戏</h1><p id="6397" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">生成新数据是一个概率游戏。当我们观察周围的世界并收集数据时，我们正在进行一项实验。一个简单的例子就是<strong class="kk iu">拍一张名人的脸。</strong></p><p id="b7c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这可以认为是一个概率实验，有一个未知的结果<em class="nj"> X </em>，也叫<strong class="kk iu">随机变量</strong>。</p><p id="c3d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果实验重复多次，我们通常将随机变量<em class="nj"> X </em>得到值小<em class="nj"> x </em>的<strong class="kk iu">概率</strong>定义为小<em class="nj"> x </em>发生的次数的分数。</p><p id="6bb9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，我们可以定义这张脸是著名歌手泰瑞斯的概率。</p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/a726cf20fed08b7adeb17289a257b204.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*idI7l3JkxRXxoI8xiqLzlA.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">泰瑞斯·吉布森</p></figure><p id="a9e7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种实验的所有可能结果构建了所谓的<strong class="kk iu">样本空间</strong>，表示为ω(所有可能的名人面孔)。</p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/7cf7178e28c3a42263f8ae9e1dc2b8f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/0*9_sm2wxAUGclWjEA.png"/></div></figure><p id="5578" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们可以将概率视为一个函数，它获取一个结果，即来自样本空间(一张照片)的一个元素，并将该结果映射到一个非负实数，使得所有这些数字的总和等于1。</p><p id="5899" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也称此为<strong class="kk iu">概率分布函数</strong> <em class="nj"> P(X) </em>。当我们知道样本空间(所有可能的名人面孔)和概率分布(每个面孔出现的概率)时，我们就有了实验的完整描述，我们可以对不确定性进行推理。</p><p id="859f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以通过下面的文章来更新你的概率知识。</p><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/understanding-probability-finally-576d54dccdb5"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd iu gy z fp nu fr fs nv fu fw is bi translated">理解概率。终于！</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">数据科学家概率概念实用指南</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od lz np"/></div></div></a></div><h2 id="7a9c" class="oe mn it bd mo of og dn ms oh oi dp mw kr oj ok my kv ol om na kz on oo nc op bi translated">名人脸概率分布</h2><p id="3af1" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">生成新面孔可以用一个随机变量生成问题来表示。脸部由随机变量描述，通过其RGB值表示，展平成一个由<em class="nj"> N </em>个数字组成的向量。</p><p id="31d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">名人头像的高度为218像素，宽度为178像素，有3个颜色通道。因此每个向量是116412维的。</p><p id="3718" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们建立一个有116412 ( <em class="nj"> N </em>)个轴的空间，那么每个面都将是那个空间中的一个点。<strong class="kk iu">名人脸概率分布函数</strong> <em class="nj"> P(X) </em>会将每个脸映射到一个非负实数，使得所有脸的所有这些数字的总和等于1。</p><p id="fbf3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该空间的一些点很可能代表名人的脸，而对于其他一些人来说，这是极不可能的。</p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/a604701f0124fceb462af4f11d326fee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*XLCCQeGArsYHrcd9CJWkSg.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">名人脸概率分布函数(自创)</p></figure><p id="d3ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">GAN通过在N维向量空间上生成遵循名人面部概率分布的新向量来生成新的名人面部。</p><blockquote class="le"><p id="156c" class="lf lg it bd lh li lj lk ll lm ln ld dk translated">简单地说，<strong class="ak"> GAN会产生一个关于特定概率分布的随机变量。</strong></p></blockquote><h2 id="09f3" class="oe mn it bd mo of or dn ms oh os dp mw kr ot ok my kv ou om na kz ov oo nc op bi translated">如何从复杂分布中生成随机变量？</h2><p id="88e6" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">N维向量空间上的名人脸概率分布非常复杂，我们不知道如何直接生成复杂的随机变量。</p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ow"><img src="../Images/9a6e635a96cadfb8a04a92f198ada55e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZEXYsmGYbOG8_eT84oaYjw.jpeg"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片来自<a class="ae mf" href="https://pixabay.com/illustrations/fractal-3d-construction-industry-1120769/" rel="noopener ugc nofollow" target="_blank">像素点</a>上的数码相机</p></figure><p id="2b4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">幸运的是，我们可以用一个适用于均匀随机变量的函数来表示复杂的随机变量。这就是<strong class="kk iu">变换方法</strong>的思想。它首先产生N个不相关的均匀随机变量，这很容易。然后它对这个简单的随机变量应用一个非常复杂的函数！<strong class="kk iu">非常复杂的函数自然地被神经网络近似</strong>。训练后，网络将能够接受一个简单的N维均匀随机变量作为输入，并返回另一个N维随机变量，该变量将遵循我们的名人脸概率分布。<strong class="kk iu">这是生成性敌对网络背后的核心动机。</strong></p><h1 id="4182" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">为什么是生成性对抗网络？</h1><p id="678c" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">在变换神经网络的每次训练迭代中，我们可以将名人训练集中的人脸样本与生成的人脸样本进行比较。</p><p id="a3d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">理论上，我们将使用<strong class="kk iu">最大平均差异(MMD)方法</strong>比较真实分布和基于样本生成的分布。</p><p id="ced9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这将给出分布匹配误差，该误差可用于通过反向传播来更新网络。这种直接方法实际上实现起来非常复杂。</p><blockquote class="le"><p id="5087" class="lf lg it bd lh li lj lk ll lm ln ld dk translated">GANs不是直接比较真实分布和生成分布，而是解决真实样本和生成样本之间的无差别任务。</p></blockquote><p id="9f85" class="pw-post-body-paragraph ki kj it kk b kl ox ju kn ko oy jx kq kr oz kt ku kv pa kx ky kz pb lb lc ld im bi translated">一个GAN有三个主要组件:一个用于生成新数据的<em class="nj">生成器模型</em>，一个用于对生成的数据是真实人脸还是虚假人脸进行分类的<em class="nj">鉴别器模型</em>，以及使它们相互对抗的<em class="nj">对抗网络</em>。</p><p id="b696" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">生成部分</strong>负责将N维均匀随机变量(噪声)作为输入，生成假面。生成器捕获概率<em class="nj"> P(X) </em>，其中<em class="nj"> X </em>为输入<em class="nj">。</em></p><p id="7427" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">鉴别部分</strong>是一个简单的分类器，用于评估和区分生成的人脸和真正的名人人脸。鉴别器捕获条件概率<em class="nj"> P(Y|X) </em>，其中<em class="nj"> X </em>为输入，<em class="nj"> Y </em>为标签<em class="nj">。</em></p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pc"><img src="../Images/f8730169ae9870ed70c4ca8ab44944af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xdHhUJxBagBJdF6aVBJJ7g.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">名人脸生成对抗网络(自创)</p></figure><h1 id="92f8" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">训练生成性对抗网络</h1><p id="e5ba" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">生成网络被训练成最大化最终分类误差(真实数据和生成数据之间)，而判别网络被训练成最小化最终分类误差。这就是对抗性网络概念的来源。</p><p id="2692" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从博弈论的角度来看，当生成器产生遵循名人脸概率分布的样本，并且鉴别器以相等的概率预测假货或非假货时，就达到了<strong class="kk iu">均衡</strong>,就好像它只是抛硬币一样。</p><p id="0774" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">重要的是，两个网络在训练期间平等地学习，并且<strong class="kk iu">将</strong> <strong class="kk iu">汇聚到一起</strong>。一种典型的情况是，当鉴别网络在识别假货方面变得更好时，导致生成网络被卡住。</p><p id="2fa2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<strong class="kk iu">鉴别器训练</strong>过程中，我们忽略发生器损耗，只使用鉴别器损耗，这是对鉴别器将真实人脸误分类为假或将生成的人脸误分类为真实人脸的惩罚。生成器的权重通过反向传播来更新。发电机的重量没有更新。</p><p id="18c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<strong class="kk iu">生成器训练</strong>时，我们使用生成器损耗，惩罚生成器未能骗过鉴别器，生成一张被鉴别器归类为假的脸。鉴别器在生成器训练期间被冻结，并且只有生成器的权重通过反向传播被更新。</p><p id="b18c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是用GANs合成名人脸的魔术。收敛经常被认为是短暂的，而不是稳定的。当你把一切都做对了，GANs会提供令人难以置信的结果，如下所示。</p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pd"><img src="../Images/332989ddedc1cae214f1fbe594ac2034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SFSZFv3eTeofEnCK.gif"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated"><a class="ae mf" rel="noopener" target="_blank" href="/build-an-app-to-synthesize-photorealistic-faces-using-tensorflow-and-streamlit-dd2545828021">通过细流合成GAN-App(来源)</a></p></figure><h1 id="6c34" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">构建和训练DCGAN模型</h1><p id="2c0b" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">在本节中，我们将介绍为名人面孔数据集创建、编译和训练DCGAN模型所需的所有步骤。深度卷积生成对抗网络(DCGANs)是使用卷积层的gan。</p><h2 id="e4d0" class="oe mn it bd mo of og dn ms oh oi dp mw kr oj ok my kv ol om na kz on oo nc op bi translated"><strong class="ak">鉴别器</strong></h2><p id="8321" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">鉴别器可以是任何图像分类器，甚至是决策树。我们使用一个卷积神经网络来代替，它有4层。每个块都包括一个卷积、批量归一化和另一个卷积，该卷积将图像缩小一倍，并进行另一个批量归一化。结果通过平均池，然后是返回单一输出概率的密集sigmoid层。</p><figure class="mi mj mk ml gt lu"><div class="bz fp l di"><div class="pe pf l"/></div></figure><h2 id="34af" class="oe mn it bd mo of og dn ms oh oi dp mw kr oj ok my kv ol om na kz on oo nc op bi translated"><strong class="ak">发电机</strong></h2><p id="6f96" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">生成器获取潜在维度的噪声向量并生成图像。图像的形状应该与鉴别器输入的形状相同(<em class="nj">spatial _ dim</em>x<em class="nj">spatial _ dim</em>)。</p><p id="f14a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">发生器首先用密集层对噪声向量进行上采样，以便有足够的值来整形到第一个发生器块中。投影的目标是与鉴别器架构中的最后一个模块具有相同的维数。这相当于鉴频器最后一个卷积层中的4 x 4 x数量的滤波器，我们将在本文后面演示。</p><p id="c13b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每个生成器模块应用去卷积来对图像进行上采样和批量归一化。我们使用4个解码器块和一个最终卷积层来获得一个3D张量，它表示一个具有3个通道的伪图像。</p><figure class="mi mj mk ml gt lu"><div class="bz fp l di"><div class="pe pf l"/></div></figure><h2 id="f556" class="oe mn it bd mo of og dn ms oh oi dp mw kr oj ok my kv ol om na kz on oo nc op bi translated"><strong class="ak">甘</strong></h2><p id="5e2d" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">通过在生成器顶部添加鉴别器来构建联合DCGAN。</p><p id="909a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在编译完整设置之前，我们必须将鉴别器模型设置为不可训练。这将冻结其权重，并告知整个网络中唯一需要训练的部分是发电机。</p><p id="3138" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管我们编译了鉴别器，但我们不需要编译生成器模型，因为我们不单独使用生成器。</p><p id="53e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个顺序确保鉴别器在正确的时间被更新，并在必要时被冻结。因此，如果我们训练整个模型，它将只更新生成器，而当我们训练鉴别器时，它将只更新鉴别器。</p><figure class="mi mj mk ml gt lu"><div class="bz fp l di"><div class="pe pf l"/></div></figure><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/85aa1b02acca4078338dc6260654122a.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*cBE-Ah-x9uLU7_3ln-b27w.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">发电机架构</p></figure><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/aad2d0cb907a1b58f4954e1947b3521d.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*YoJ-UWlBzsueavbimZ48SA.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">DCGAN架构</p></figure><h2 id="84f5" class="oe mn it bd mo of og dn ms oh oi dp mw kr oj ok my kv ol om na kz on oo nc op bi translated">甘培训</h2><p id="b28c" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">现在是艰难而缓慢的部分:训练一个生成性的对抗网络。因为GAN由两个独立训练的网络组成，收敛很难识别。</p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ow"><img src="../Images/13e8fe9e45bcdbd93cb6da2e824a2270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M4dhHPIbQPc85V388cniNA.jpeg"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图像由024–657–834在<a class="ae mf" href="https://pixabay.com/illustrations/man-face-facial-expression-body-845847/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上显示</p></figure><p id="751d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面的步骤来回执行，让甘斯处理其他棘手的生殖问题。</p><p id="9ff8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">步骤1 </strong> —从训练集中选择若干真实图像。</p><p id="49aa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第二步</strong> —生成一些假图像。这是通过采样随机噪声向量并使用发生器从它们创建图像来完成的。</p><p id="ff27" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">步骤3 </strong> —使用假图像和真实图像训练鉴别器一个或多个时期。这将通过将所有真实图像标记为1并将虚假图像标记为0来仅更新鉴别器的权重。</p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pi"><img src="../Images/c78695827d07b1db146f6f3d328b2841.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dkt6-Jxrq18ZTJinu4j6HA.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">鉴别器训练模式(自行创建)-不更新生成器的权重。仅调整鉴别器的权重。真假数据都用。鉴别器学会检测假图像。</p></figure><p id="2141" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">步骤4 </strong> —生成另一批伪图像。</p><p id="e4e8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">步骤5 </strong> —仅使用伪图像训练一个或多个时期的完整GAN模型。这将通过将所有假图像标记为1来仅更新生成器的权重。</p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pj"><img src="../Images/9559df91c5c477c89825af02c42729a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*07aAbZF-qTichNGbS3SkoQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">生成器训练模式(自行创建)-鉴别器权重未更新。仅调整发生器的权重。发电机学会愚弄鉴别器。</p></figure><figure class="mi mj mk ml gt lu"><div class="bz fp l di"><div class="pe pf l"/></div></figure><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/ee0acd45f6e0d2b72ec61bab6eedc019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*aUtDbS2GpshXoSrqce0p4Q.jpeg"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">甘训练时生成器生成的假面</p></figure><p id="050e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面我们可以看到我们的甘表现很好。即使照片质量不如CelebA训练集中的照片质量好，生成的人脸看起来也很合理。这是因为我们在重新调整的64x64图像上训练我们的GAN，这些图像变得比原始的218x178更小更模糊。</p><h2 id="5200" class="oe mn it bd mo of og dn ms oh oi dp mw kr oj ok my kv ol om na kz on oo nc op bi translated">与甘的区别</h2><p id="6e42" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">与我们上一篇文章中的<a class="ae mf" rel="noopener" target="_blank" href="/variational-autoencoders-vaes-for-dummies-step-by-step-tutorial-69e6d1c9d8e9">中的variable auto encoder生成的人脸相比，DCGAN生成的人脸看起来足够生动，足以代表足够接近现实的有效人脸。</a></p><figure class="mi mj mk ml gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pl"><img src="../Images/f52298a070fa85da56f8d504bb5956a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aeEkzmhw16zHS5oD.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">训练时由一个可变自动编码器生成的假脸(<a class="ae mf" rel="noopener" target="_blank" href="/variational-autoencoders-vaes-for-dummies-step-by-step-tutorial-69e6d1c9d8e9">来源</a></p></figure><p id="65bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与vae相比，gan是典型的高级深度生成模型。尽管vae注定要在一个潜在的空间工作，他们训练起来更容易也更快。VAEs可以被认为是半监督学习器，因为它们被训练来最小化再现某个图像的损失。另一方面，GAN正在解决一个无监督的学习问题。</p><h1 id="6cfd" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">结论</h1><p id="9f79" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">在这篇文章中，我解释了生成敌对网络如何能够近似一大组图像的概率分布，并使用它来生成照片级的图像。</p><p id="c0af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我提供了可以工作的Python代码，允许您构建和训练一个GAN来解决您自己的任务。</p><p id="ce3e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以通过<a class="ae mf" href="https://developers.google.com/machine-learning/gan/gan_structure" rel="noopener ugc nofollow" target="_blank">谷歌开发者</a>或<a class="ae mf" rel="noopener" target="_blank" href="/understanding-generative-adversarial-networks-gans-cd6e4651a29"> Joseph Rocca的文章</a>了解更多关于GANs的信息。变型自动编码器将在我下面的文章中进一步探讨。</p><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/variational-autoencoders-vaes-for-dummies-step-by-step-tutorial-69e6d1c9d8e9"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd iu gy z fp nu fr fs nv fu fw is bi translated">用于假人的可变自动编码器(VAEs)——循序渐进教程</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">DIY实践指南与实践证明代码建设和培训与Keras的名人脸上的VAEs。</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="pm l oa ob oc ny od lz np"/></div></div></a></div><p id="2557" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢《走向数据科学》的Amber Teng的编辑评论。</p><p id="3a65" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读。注意安全。好好呆着。</p></div></div>    
</body>
</html>