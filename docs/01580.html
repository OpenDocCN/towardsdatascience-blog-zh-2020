<html>
<head>
<title>Energy consumption time series forecasting with python and LSTM deep learning model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于python和LSTM深度学习模型的能源消费时间序列预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/energy-consumption-time-series-forecasting-with-python-and-lstm-deep-learning-model-7952e2f9a796?source=collection_archive---------1-----------------------#2020-02-13">https://towardsdatascience.com/energy-consumption-time-series-forecasting-with-python-and-lstm-deep-learning-model-7952e2f9a796?source=collection_archive---------1-----------------------#2020-02-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="806e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何利用时间序列进行深度学习</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b3401564cb103e0e899959fbd2a6a901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kusqkIuKdj6VJtPA"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">戴维·赫尔曼在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="4b25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文的目的是向读者展示python中的一个类，该类具有非常直观和简单的输入，可以使用深度学习对时间序列数据进行建模和预测。理想情况下，读者应该能够复制本文或GitHub资源库中的代码，根据自己的需要对其进行裁剪(例如，向模型中添加更多层),并在工作中使用它。</p><p id="afb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文中使用的所有代码都可以在这里找到:</p><p id="eecd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【https://github.com/Eligijus112/deep-learning-ts T4】</p><p id="83a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章的数据可以在这里找到:</p><p id="c11f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.kaggle.com/robikscube/hourly-energy-consumption" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/robikscube/hourly-energy-consumption</a></p><p id="9209" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用于深度建模的包是TensorFlow和Keras。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="f93c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">时间序列是按连续顺序排列的数字数据点序列。这些点通常定期测量(每月、每天、每小时等)。).本文中使用的数据频率是每小时一次，测量时间是从2004年10月1日到2018年8月3日。原始数据点的总数为<strong class="lb iu"> 121271 </strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/2d4ee650e6b66f81dd6a76afee02ce53.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*L6ho_7mC_DnzkJilDd9gGA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Python中的时间序列示例</p></figure><p id="e781" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">时间序列的可视化:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi md"><img src="../Images/884139a3137887b9535932e0309aac98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jwb5EmhtOPg8y5E7cHwFVw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">能源消耗时间序列的折线图</p></figure><p id="b00d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于给定的时间序列，深度学习算法的主要目标是找到函数<strong class="lb iu"> f </strong>,使得:</p><p id="123c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Yₜ = f(Yₜ₋₁，Yₜ₋₂，…，Yₜ₋ₚ) </strong></p><p id="be2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，我们希望基于相同能耗的<strong class="lb iu"> p </strong>滞后估计一个解释能耗当前值的函数。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="4b27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章不是要解释为什么长期短期记忆(LSTM)深度学习网络有利于时间序列建模或它是如何工作的。有关这方面的资源，请查看以下精彩文章:</p><div class="me mf gp gr mg mh"><a href="https://pathmind.com/wiki/lstm" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">LSTMs和递归神经网络初学者指南</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">数据只能反向理解；但它必须向前看。-索伦·克尔凯郭尔，期刊*</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">pathmind.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv ks mh"/></div></div></a></div><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">LSTM和GRU的图解指南:一步一步的解释</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">嗨，欢迎来到长短期记忆(LSTM)和门控循环单位(GRU)的图解指南。我是迈克尔…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="mw l ms mt mu mq mv ks mh"/></div></div></a></div><p id="a5cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有关Keras中LSTM(或任何RNN图层)的实现，请参见官方文档:</p><div class="me mf gp gr mg mh"><a href="https://keras.io/layers/recurrent/" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">重复层- Keras文档</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">用于递归层的keras . engine . Base _ layer . wrapped _ fn()基类。Arguments单元格:RNN单元格实例。一个RNN细胞…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">keras.io</p></div></div><div class="mq l"><div class="mx l ms mt mu mq mv ks mh"/></div></div></a></div></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="d386" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们需要读取数据:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="my mz l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">读取每小时数据的代码示例</p></figure><p id="4b7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们需要一个函数，将时间序列转换成X和Y矩阵，供深度学习模型开始学习。假设我们想要创建一个使用<strong class="lb iu"> 3 </strong>滞后解释当前时间序列值的函数:</p><h1 id="ae1f" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated"><strong class="ak"> Yₜ = f(Yₜ₋₁，Yₜ₋₂，Yₜ₋₃) </strong></h1><p id="9df0" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">我们有这样的数据:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="308c" class="oc nb it ny b gy od oe l of og">ts = [1621.0, 1536.0, 1500.0, 1434.0, 1489.0, 1620.0]</span></pre><p id="1c19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们想要创建两个矩阵:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="73ef" class="oc nb it ny b gy od oe l of og">X = [<br/>[1621.0, 1536.0, 1500.0], # First three lags<br/>[1536.0, 1500.0, 1434.0], # Second three lags<br/>[1500.0, 1434.0, 1489.0], # Third three lags<br/>]</span><span id="3780" class="oc nb it ny b gy oh oe l of og">Y = [1434.0, 1489.0, 1620.0]</span></pre><p id="b41f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">这是对时间序列使用深度学习时最重要的技巧。</strong>你不仅可以将这些X和Y矩阵提供给递归神经网络系统(如LSTM)，还可以提供给任何普通的深度学习算法。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="my mz l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">函数从时间序列中创建X和Y矩阵</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="f08e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">深度学习模型有一个LSTM层(也用作输入层)和一个输出层。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="my mz l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">定义LSTM深度学习模型</p></figure><p id="5ff8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我在互联网上搜索一个易于使用的时间序列深度学习模型的过程中，我看到了各种文章，这些文章将建模的几个部分分开，如如何定义模型，如何为模型创建矩阵等。我没有找到一个包或一个类，把所有东西都打包成一个易于使用的实体。所以我决定自己来做:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="my mz l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">建模类</p></figure><p id="6e2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">开始上课:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="7d6b" class="oc nb it ny b gy od oe l of og"># Initiating the class</span><span id="3388" class="oc nb it ny b gy oh oe l of og">deep_learner = DeepModelTS(<br/>data = d,<br/>Y_var = 'DAYTON_MW',<br/>lag = 6,<br/>LSTM_layer_depth = 50,<br/>epochs = 10,<br/>batch_size = 256,<br/>train_test_split = 0.15<br/>)</span></pre><p id="bbe8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该类的参数是:</p><p id="1e03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据</strong> -用于建模的数据。</p><p id="2ad1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Y_var </strong> -我们要建模/预测的变量名。</p><p id="3f8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">滞后</strong> -用于建模的滞后数量。</p><p id="09b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">LSTM _层_深度</strong>-LSTM层中神经元的数量。</p><p id="c2c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">时期</strong> -训练循环的数量(正向传播到反向传播循环)。</p><p id="f53c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> batch_size </strong> -深度学习模型在寻找参数时使用的梯度下降的数据样本的大小。所有数据都被分成batch_size大小的块，并通过网络传送。在每个batch_size的数据在模型中前进和后退之后，模型的内部参数被更新。</p><p id="6757" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要了解更多关于时期和批量大小的信息，请访问:</p><div class="me mf gp gr mg mh"><a href="https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">神经网络中批次和时期之间的差异</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">随机梯度下降是一种具有多个超参数的学习算法。两个超参数…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">machinelearningmastery.com</p></div></div><div class="mq l"><div class="oi l ms mt mu mq mv ks mh"/></div></div></a></div><p id="bdd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> train_test_split </strong> -用于测试的数据份额。1 - train_test_split用于模型的训练。</p><p id="e680" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">拟合模型:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="a284" class="oc nb it ny b gy od oe l of og"># Fitting the model</span><span id="cff3" class="oc nb it ny b gy oh oe l of og">model = deep_learner.LSTModel()</span></pre><p id="1d4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的命令之后，你可以看到球迷最喜欢的训练画面:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/d043ce1ed36504376792f1e4c8004915.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aU3LeSWTB88eiOAcU7EGwQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Keras中模型的训练</p></figure><p id="2582" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用更多的滞后(因此，更大的X矩阵)训练模型增加了训练时间:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="6190" class="oc nb it ny b gy od oe l of og">deep_learner = DeepModelTS(<br/>data = d,<br/>Y_var = 'DAYTON_MW',<br/>lag = 24, # 24 past hours are used<br/>LSTM_layer_depth = 50,<br/>epochs = 10,<br/>batch_size = 256,<br/>train_test_split = 0.15<br/>)</span><span id="7389" class="oc nb it ny b gy oh oe l of og">model = deep_learner.LSTModel()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/a15ff1594b8189978376538d269ed1ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RuB1QBoZCDjldNYRVYG_8w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多滞后模型的训练</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="6f9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们已经创建了一个模型，我们可以开始预测。使用用<strong class="lb iu"> p </strong> lags训练的模型进行预测的公式:</p><h1 id="ac91" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">Yₜ₊₁ = f(Yₜ，Yₜ₋₁，…，Yₜ₋ₚ₊₁)</h1><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="50b7" class="oc nb it ny b gy od oe l of og"># Defining the lag that we used for training of the model <br/>lag_model = 24</span><span id="c46a" class="oc nb it ny b gy oh oe l of og"># Getting the last period<br/>ts = d['DAYTON_MW'].tail(lag_model).values.tolist()</span><span id="97d9" class="oc nb it ny b gy oh oe l of og"># Creating the X matrix for the model<br/>X, _ = deep_learner.create_X_Y(ts, lag=lag_model)</span><span id="5b80" class="oc nb it ny b gy oh oe l of og"># Getting the forecast<br/>yhat = model.predict(X)</span></pre><p id="499a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果数据被分成训练集和测试集，那么<strong class="lb iu"> deep_learner.predict() </strong>方法将预测测试集中的点，以查看我们的模型在样本外的表现。</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="fd24" class="oc nb it ny b gy od oe l of og">yhat = deep_learner.predict()</span><span id="4913" class="oc nb it ny b gy oh oe l of og"># Constructing the forecast dataframe<br/>fc = d.tail(len(yhat)).copy()<br/>fc.reset_index(inplace=True)<br/>fc['forecast'] = yhat</span><span id="df4e" class="oc nb it ny b gy oh oe l of og"># Ploting the forecasts<br/>plt.figure(figsize=(12, 8))<br/>for dtype in ['DAYTON_MW', 'forecast']:</span><span id="9b76" class="oc nb it ny b gy oh oe l of og">  plt.plot(<br/>    'Datetime',<br/>    dtype,<br/>    data=fc,<br/>    label=dtype,<br/>    alpha=0.8<br/>  )</span><span id="a314" class="oc nb it ny b gy oh oe l of og">plt.legend()<br/>plt.grid()<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/e574c51e6ac5e8439a5321990834f62f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iuj02ij8NtqQrgGp6Y-14g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">时间序列预测</p></figure><p id="0ed9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所看到的，模型创建中隐藏的15%数据的预测值接近真实值。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="9cfd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们通常希望提前预测最后的原始时间序列数据。类<strong class="lb iu"> DeepModelTS </strong>有方法<strong class="lb iu"> predict_n_ahead(n_ahead) </strong>预测<strong class="lb iu"> n_ahead </strong>时间步。</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="e3ef" class="oc nb it ny b gy od oe l of og"># Creating the model using full data and forecasting n steps aheaddeep_learner = DeepModelTS(<br/>data=d,<br/>Y_var='DAYTON_MW',<br/>lag=48,<br/>LSTM_layer_depth=64,<br/>epochs=10,<br/>train_test_split=0<br/>)</span><span id="24da" class="oc nb it ny b gy oh oe l of og"># Fitting the model<br/>deep_learner.LSTModel()</span><span id="b8a4" class="oc nb it ny b gy oh oe l of og"># Forecasting n steps ahead<br/>n_ahead = 168</span><span id="01f7" class="oc nb it ny b gy oh oe l of og">yhat = deep_learner.predict_n_ahead(n_ahead)<br/>yhat = [y[0][0] for y in yhat]</span></pre><p id="d249" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码预测了未来一周的步骤(168小时)。与之前的400小时相比:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/dd09965a20fb73726f898c18887e7627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MsEuIN_izATuu3Wo_E_56w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">超出时间范围的预测</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="7eea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，本文给出了一个简单的管道示例，用于时间序列数据的建模和预测:</p><p id="fc26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">读取和清除数据(1行1时间步)</strong></p><p id="8cbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">选择滞后数量和模型深度</strong></p><p id="a3c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">初始化DeepModelTS()类</strong></p><p id="8bad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">拟合模型</strong></p><p id="fce0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">提前n _步预测</strong></p><p id="e669" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望读者可以在他/她的专业和学术工作中使用本文展示的代码。</p></div></div>    
</body>
</html>