# 如何提高你的机器学习模型质量？

> 原文：<https://towardsdatascience.com/how-can-you-improve-your-machine-learning-model-quality-b22737d4fe5f?source=collection_archive---------31----------------------->

![](img/2bd7097dba0da44c9752daacd83926b3.png)

照片由 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的 [Jp Valery](https://unsplash.com/@jpvalery?utm_source=medium&utm_medium=referral)

## 数据科学家减少分类 ML 模型错误的逐步方法

# 为什么要看这篇文章？

有时候，你的分类机器学习模型并没有预期的那么好。当面对这种情况时，许多人所做的就是随机或多或少地尝试不同的方法，或者跟着感觉走。它可能是添加更多的数据，尝试一个新的模型，或者调整一些变量，但是有一个选择首先尝试什么的方法是很不寻常的。

本文所展示的正是:根据您所面临的模型错误类型，选择最佳策略的明确定义的方法。

这种方法基于 Coursera 上的[结构化机器学习项目](https://www.coursera.org/learn/machine-learning-projects/home/welcome)课程，但在格式、方法和术语上有所调整。如果你喜欢这篇文章，它可能值得参加这个课程，但是，它不是太长，而且它有一些额外的有用的提示。

# 一步一步来

您的模型应该符合一些标准才能被视为好模型，通常一次符合一个标准，顺序如下:

*   很好地适应训练集
*   很好地适应验证集
*   很好地安装测试集
*   在现实世界中表现出色

对于这些步骤中的每一步，都有不同的策略可以让您提高性能，应该相应地应用这些策略。如果您的模型在您的训练集中表现不佳，它在现实世界中表现不佳的可能性很小，因此当您看到事情开始出错时，您应该能够找到错误的来源并首先修复它。

# “独一无二的”

为了能够衡量你的模型做得好不好，你应该有一个**单一数字评估指标**，这个指标将使你能够比较不同的模型。当你开始尝试优化多个指标时，你并没有真正优化，你也不会得到任何客观的答案。

> "好吧，但是如果我真的需要不止一个指标呢？"

然后，选择一个单一的数字指标作为你的“唯一”，其他的将成为你的*满意度指标*，这些指标你将设定一个截止值，但你不必优化。

比方说，你有两个模型，A 和 b。模型 A 有 95%的准确性，它需要 1 秒钟来获得一个新的观察值。模型 B 的准确率为 98%，获得一个新的观察值需要 8 秒钟。

从理论上讲，如果您正在优化准确性，您应该选择模型 b。但是想象一下运行时间对于您的应用程序也很重要，因此您不能拥有一个需要 8 秒钟来对每个观察结果进行评分的模型。但是，只要不到 2 秒，对你来说就没问题。然后，您将优化准确性，运行时间的最大限制为 2 秒，这将导致您选择模型 a。请注意，您可以有多个令人满意的指标。

# 错误管道

既然你已经有了误差的定义，为了理解它的来源并优化我们选择的度量，我们必须使用一种误差管道将误差分成不同的部分。

## 人的工作效率

> 永远不要派人去做机器的工作。—电影《黑客帝国》中的特工史密斯

对于一些任务，如图像识别，我们通常使用人类作为获得模型准确性的基线:如果人类有 1%的错误，通常我们实际上不能期望做得更好。这就是为什么我们使用人的表现作为[贝叶斯误差](https://en.wikipedia.org/wiki/Bayes_error_rate)的代理，贝叶斯误差是一项任务的最小理论误差，因此将是我们管道的起点。

## 模型误差

在定义训练、验证和测试集时，通常会有很多困惑和争论，但我认为行业标准倾向于使用*训练*用于训练模型的数据集(这里没有太多争论)，使用*验证*用于首先验证模型和微调参数的数据集，使用*测试*数据集用于测试模型的最终数据集。重要的是，验证和测试观察来自相同的分布，并且它们都反映了您将在现实世界中遇到的数据。

训练和测试之间的默认划分通常是 70% / 30%，而训练、验证和测试之间的默认划分大约是 60% / 20% / 20%。然而，当你有大量的数据时，使用 98% / 1% / 1%的分割是很好的，只要你在每个验证和测试集中至少有大约 10 000 个观察值。

最后，如果您的训练集和验证集来自不同的分布，您可以将训练集分成两部分:*训练*和*训练-开发*，并使用第一部分来训练您的模型，使用第二部分来测试来自与训练集相同的分布的数据，以便隔离由于您的模型无法概括而产生的错误和由于分布不同而产生的错误。

最后，您的误差度量将有 5 个连续的值(这是上面定义的一个度量)。它们之间的差异有不同的来源，查看最大的误差来源将会告诉您应该首先解决哪一个:

![](img/9331c99ee094e450500bb377e2219b53.png)

我们现在将解决这些误差源中的每一个，以及处理每个误差源的最佳策略。

![](img/014293b056ffe5996c53ec844aeffa1e.png)

亚伦·胡贝尔在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

# 改进您的模型

## 可避免的偏见

可避免的偏差应该尽可能接近零，因为训练集中的误差很可能是您最小的误差，并且您希望它至少与人的表现相等(如果不是更好的话)。解决这一问题的一些策略包括:

*   训练一个更大的模型(这可能包括尝试不同的神经网络架构和扩大你的超参数搜索空间)
*   训练更长/更好的优化算法

## 差异

另一方面，方差来自于这样一个事实，即您的模型过度拟合了训练集，并且还不能将其结论推广到它尚未看到的数据。您可以通过以下方式减少它:

*   获取更多数据
*   尝试不同的[正规化技术](/regularization-techniques-for-neural-networks-e55f295f2866)
*   再次尝试不同的神经网络架构，扩大你的超参数搜索空间

## 数据不匹配

有时，您不能让训练和测试数据来自相同的分布:假设您想训练一个面部识别算法，专门用于手机的前置摄像头，但您没有足够的具有这些完全相同特征的标记数据。然后，你求助于已经标记好的公开可用数据来训练你的模型，并在来自前置摄像头的图片上进行测试。在这种情况下，可能会发生数据不匹配错误，主要通过使您的训练数据与验证和测试集更相似来减少这种错误。

一种方法是进行**手动错误分析**。在我们之前的例子中，这可能意味着从验证集中随机选取一些(约 100 张)标签错误的图片，并通过与训练集中的一些图片进行比较，试图理解算法为什么会出错。由于前置摄像头质量差，有些可能会失真或分辨率低，有些可能比你的火车组更接近面部，有些甚至可能是正确的，但它们只是首先被人类贴错了标签。尝试将 100 张图片中的每一张归入一个错误类别，最后，你可以知道每一个类别产生的错误百分比。然后，您可以考虑归因于每个类别的错误百分比以及修复它们的难度/成本，这有助于您决定首先解决哪些类别。在我们的例子中，假设模型的大部分误差发生在图片分辨率较低的时候。也许您可以尝试人为降低训练集的一些图片的分辨率，使其与验证集更相似，或者只是从验证集中取出一些图片，然后将它们放入训练集中。

这一步可能看起来有点麻烦，但它实际上可以为您节省很多不必要的工作。

## 过度适应验证集

如果您的模型过拟合，那么尝试通过添加数据使验证集更大。

# 最终考虑

总结一下工作流程:

*   **定义一个数字评估指标**来优化你的模型，也许还可以定义一些令人满意的指标
*   **将您的数据分成 4 个数据集** : *训练*、*训练开发*、*验证*和*测试*，确保训练集有足够的观察值，并且验证集和测试集来自相同的分布
*   **根据您的评估标准测量所有这些项目的误差**，并将人为误差作为基准
*   **通过查看 5 个误差之间的差异，找出误差的最大来源**
*   利用上述策略，相应地解决这些问题

如果你想了解这个工作流程的更多信息，我建议你参加 Coursera 上的[结构化机器学习项目](https://www.coursera.org/learn/machine-learning-projects/home/welcome)课程。