<html>
<head>
<title>An Introduction to Knowledge Graphs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">知识图导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-knowledge-graphs-841bbc0e796e?source=collection_archive---------11-----------------------#2020-05-11">https://towardsdatascience.com/an-introduction-to-knowledge-graphs-841bbc0e796e?source=collection_archive---------11-----------------------#2020-05-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7ae6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何以图表形式表示和操作数据</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3d22f89b9d2b6af3bd1b0238a5a3942e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aU0-Jhmd9CaAOfbWadX81w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@clintadair?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">克林特·王茂林</a>拍摄</p></figure><p id="4dec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是论文<a class="ae ky" href="https://arxiv.org/abs/1503.00759" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="lv">“知识图的关系机器学习综述(2015 年 9 月 28 日)”</em></strong></a><strong class="lb iu"><em class="lv"/></strong>【1】中一些要点的<strong class="lb iu">总结</strong>，它很好地介绍了知识图以及用于构建和扩展它们的一些方法。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="6109" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">关键的外卖</h1><p id="84f3" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">信息可以以图形的形式组织，节点代表实体，边代表实体之间的关系。知识图可以手动构建，也可以在某些源文本(例如维基百科)上使用自动信息提取方法构建。给定一个知识图，统计模型可以用来通过推断缺失的事实来扩展和完善它。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="1e2b" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">真相</h1><p id="aef0" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">涵盖的主题:</p><ol class=""><li id="89e8" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nf ng nh ni bi translated"><strong class="lb iu">知识图表的基础知识</strong></li><li id="b1e3" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nf ng nh ni bi translated"><strong class="lb iu">统计关系学习</strong> <br/> <strong class="lb iu"> 2.1 潜在特征模型</strong> <br/> 2.1.1 重标度<br/> 2.1.2 多层感知器<br/> 2.1.3 潜在距离模型<br/> <strong class="lb iu"> 2.2 图特征模型</strong> <br/> 2.2.1 路径排序算法<br/> <strong class="lb iu"> 2.3 结合潜在和图特征模型</strong></li><li id="783b" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nf ng nh ni bi translated">一些更酷的东西</li></ol></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="7a70" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">1.知识图的基础</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/68bc1982eaebdad825c19a546ea9018c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AtV9tkp02hGI2YdJ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摘自论文[1]</p></figure><p id="cddb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">知识图(KGs)是一种以图表形式组织信息的方式，通过将<strong class="lb iu">实体</strong>(例如:人、地点、物体)表示为节点，将实体之间的<strong class="lb iu">关系</strong>(例如:结婚、位于)表示为边。<strong class="lb iu">事实</strong>典型表示为“SPO”三元组:<em class="lv">(主语、谓语、宾语)</em>。本质上，由关系连接的两个节点形成一个事实。例如，上图中的一个事实可能是:“斯波克是《星际迷航》中的一个角色”。这个事实是由两个节点<code class="fe np nq nr ns b">Spock</code>和<code class="fe np nq nr ns b">Star Trek</code>以及关系<code class="fe np nq nr ns b">characterIn</code>形成的 SPO 三元组<em class="lv"> (Spock，characterIn，Star Trek) </em>。</p><p id="ccf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，现有的边表示已知的事实。缺边怎么办？<br/>有两种可能:</p><ul class=""><li id="fa4c" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nt ng nh ni bi translated"><strong class="lb iu"> <em class="lv">封闭世界假设</em>【CWA】</strong>:不存在的三元组/边表示虚假关系:例如，既然《伦纳德·尼莫伊到星球大战》中没有<code class="fe np nq nr ns b">starredIn</code> <em class="lv"> </em>边，我们就推断《星球大战》中伦纳德·尼莫伊<em class="lv">没有</em>星</li><li id="82a6" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu"> <em class="lv">开放世界假设</em> (OWA) </strong>:不存在的三元组/边简单代表未知数:由于从伦纳德·尼莫伊到星战没有<code class="fe np nq nr ns b">starredIn</code> <em class="lv"> </em>边，我们<em class="lv">不知道</em>伦纳德·尼莫伊是否出演过星战</li></ul><p id="7c1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">KGs 一般包括各种类型的<strong class="lb iu">等级制度</strong>(<em class="lv">伦纳德·尼莫伊是演员，是人，是活物</em>)<strong class="lb iu">约束</strong>(<em class="lv">一个人只能娶另一个人，不能娶一个东西</em>)。</p><h2 id="2ab2" class="nu me it bd mf nv nw dn mj nx ny dp mn li nz oa mp lm ob oc mr lq od oe mt of bi translated">构建知识图表的方法:</h2><ul class=""><li id="e827" class="na nb it lb b lc mv lf mw li og lm oh lq oi lu nt ng nh ni bi translated">由专家或志愿者手动操作</li><li id="284d" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated">通过从半结构化文本中自动提取它们(例如:维基百科信息框)</li><li id="11eb" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated">通过从非结构化文本中自动提取它们(使用自然语言处理技术)</li></ul><h2 id="5676" class="nu me it bd mf nv nw dn mj nx ny dp mn li nz oa mp lm ob oc mr lq od oe mt of bi translated">知识图管理的主要任务:</h2><ul class=""><li id="f99a" class="na nb it lb b lc mv lf mw li og lm oh lq oi lu nt ng nh ni bi translated"><strong class="lb iu">链接预测</strong>:预测图中缺失的边(即:缺失的事实)</li><li id="1c72" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu">实体解析</strong>:寻找实际上指同一事物的不同节点和/或不同边。例如，一个系统可能包含三元组，如(<em class="lv">奥巴马，博宁，夏威夷</em>)和(<em class="lv">巴拉克·奥巴马，普莱瑟夫伯斯，檀香山</em>)。我们可能想要合并<code class="fe np nq nr ns b">Obama</code>和<code class="fe np nq nr ns b">Barack Obama</code>节点，因为它们可能指的是同一个实体。</li><li id="3baf" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu">基于链接的聚类</strong>:根据链接的相似性对实体进行分组</li></ul></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="a11a" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">2.知识密集型企业的统计关系学习(SRL)</h1><p id="8fd6" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated"><strong class="lb iu">假设</strong>:一个图中所有的实体和<em class="lv">类型</em>的关系都是已知的(有 N_e 个实体和 N_r 种类型的关系)。然而，三元组是<em class="lv">不完全的</em>:也就是说，图中的一些节点是连接的，但也有一些节点对<em class="lv">应该</em>连接但没有连接。这意味着:有一定数量的真实事实，但我们只知道其中的一部分。还可能存在实体和关系的副本。</p><p id="1670" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们姑且称<em class="lv"> e_i </em>为主语节点(例如:<code class="fe np nq nr ns b">Spock</code>)，<em class="lv"> e_j </em>为宾语节点(<code class="fe np nq nr ns b">Star Trek</code>)，而<em class="lv"> r_k </em>为关系类型(<code class="fe np nq nr ns b">characterIn</code>)。我们现在可以将每个可能的三元组 x_ijk = ( <em class="lv"> e_i，r_k，e_j </em>)建模为一个二元随机变量<em class="lv"> y_ijk </em> ∈ {0，1}。这里，如果三元组存在，<em class="lv"> y_ijk </em>为 1，否则为 0。在封闭世界假设中，0 表示错误的三元组，而在开放世界中，它表示未知。这些随机变量彼此相关，因为某些三联体的存在可以预测其他三联体的存在/不存在。</p><p id="7f5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以把所有可能的三元组组合成一个维度为 N_e x N_e x N_r 的三阶张量<strong class="lb iu"> Y </strong> ∈ {0，1}，见下图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/7412ca790f04f7105212df24e4a2e0c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*uF7IkD6flCeFxTDYsZaumA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ok">摘自论文[1] </em></p></figure><p id="1f73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对<strong class="lb iu"> Y </strong>的每一个可能的实现都是一个可能的“世界”，是事实的某种组合。我们想弄清楚，在已知的有限数量的三元组中，哪一种实现最有可能是准确的。为此，我们需要从 N_d 个观察到的三元组的子集𝒟中估计分布 P( <strong class="lb iu"> Y </strong>)。Y 可能非常大，所以这个任务可能非常复杂。例如，<a class="ae ky" href="https://en.wikipedia.org/wiki/Freebase_(database)" rel="noopener ugc nofollow" target="_blank"> <em class="lv"> Freebase </em> </a>有大约 4000 万个实体和 35k 个关系，给出 10 个⁹可能的三元组。</p><p id="f50a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，由于某些限制，这些三元组中只有一小部分是可行的。例如，我们知道关系<code class="fe np nq nr ns b">marriedTo</code>只能链接指向人的两个节点，所以我们已经可以排除所有的三元组(<em class="lv"> e_i，r _ marriedTo，e_j </em>)，其中一个或两个实体都不是人。理想情况下，我们希望找到一种方法来轻松识别并丢弃所有这些“不可能的”三元组。</p><h2 id="77a5" class="nu me it bd mf nv nw dn mj nx ny dp mn li nz oa mp lm ob oc mr lq od oe mt of bi translated">知识图的统计性质</h2><p id="d8d2" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">正如已经看到的，kg 通常遵循一组<strong class="lb iu">确定性规则</strong>，例如:</p><ul class=""><li id="4706" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nt ng nh ni bi translated"><strong class="lb iu">类型约束</strong>:关系<code class="fe np nq nr ns b">marriedTo</code>只能指一个人</li><li id="60fc" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu">传递性</strong>:如果 A 位于 B and B 位于 C，那么 A 位于 C</li></ul><p id="a8d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他们也经常松散地遵循一套统计模式:</p><ul class=""><li id="7fb0" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nt ng nh ni bi translated"><strong class="lb iu">同向</strong>(或“<strong class="lb iu">自相关</strong>”):实体倾向于与具有相似特征的实体相关</li><li id="507e" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu">块结构</strong>:一些实体可以被分组为“块”，使得一个块的所有成员与另一个块的成员具有相似的关系</li></ul><h2 id="7c9f" class="nu me it bd mf nv nw dn mj nx ny dp mn li nz oa mp lm ob oc mr lq od oe mt of bi translated">SRL 模型的类型</h2><p id="e874" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">本文涵盖了 3 种主要类型的统计关系学习模型:</p><ol class=""><li id="cbf0" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nf ng nh ni bi translated"><strong class="lb iu">潜在特征模型</strong>:我们假设给定一些潜在特征和附加参数，所有 y_ijk 都是独立的</li><li id="7bfa" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nf ng nh ni bi translated"><strong class="lb iu">图形特征模型</strong>:我们假设给定观察到的图形特征和附加参数，所有 y_ijk 都是独立的</li><li id="d03b" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nf ng nh ni bi translated">马尔可夫随机场:我们假设所有的 y_ijk 都有局部相互作用[不在本概述中]</li></ol><p id="f8c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">潜在特征模型</em>和<em class="lv">图形特征模型</em>使用评分函数 f(x _ ijk；θ)，其中θ是某组参数。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="ffca" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">2.1 潜在特征模型</h1><p id="7053" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在潜在特征模型中，我们通过潜在变量来解释三元组。例如，我们可以用“亚历克·伊兹高尼是一个好演员”这一潜在变量来解释“亚历克·伊兹高尼获得奥斯卡奖”这一事实。</p><p id="51f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给定一个实体 e_i，我们用向量<strong class="lb iu"> e </strong> _i ∈ ℝ^{H_e}.来表达它的潜在特征例如，假设我们有两个潜在的特征(H_e = 2):成为一个好演员，和获得一个有声望的奖项。我们可以将实体<code class="fe np nq nr ns b">AlecGuinness</code>和<code class="fe np nq nr ns b">AcademyAward</code>的潜在特征向量表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/d8b1d9613e97db061942f8d65fbc694b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h7l_zYVlxUDJ2M8oMNqlWw.png"/></div></div></figure><p id="b72b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，潜在向量的第一元素表示“好演员”，第二元素表示“有声望的奖项”。</p><p id="97a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了预测三元组，我们需要对这些潜在变量之间的相互作用进行建模。本文回顾了已开发的几种方法，我将总结其中的主要方法:</p><ul class=""><li id="6c1e" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nt ng nh ni bi translated">重新校准</li><li id="a6bf" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated">多层感知器</li><li id="f43c" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated">潜在距离模型</li></ul></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h2 id="2f44" class="nu me it bd mf nv nw dn mj nx ny dp mn li nz oa mp lm ob oc mr lq od oe mt of bi translated">重新校准</h2><p id="085f" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">也许最直观的是，RESCAL“通过潜在特征的成对相互作用来解释三元组”，因此三元组的得分由下式给出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/ab9d7a4c1c58ba6f5c9a7c9a93001e8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e07cx0hPua93ai8QxOSPdQ.png"/></div></div></figure><p id="9f8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"> W </strong> _k 是维数为 H_e x H_e 的权重矩阵“其条目<em class="lv"> w_abk </em>指定了潜在特征<em class="lv"> a </em>和<em class="lv"> b </em>在<em class="lv"> k 个</em>关系中相互作用的程度”。以亚历克·伊兹高尼获得奥斯卡奖为例，第 k 个关系是<code class="fe np nq nr ns b">receivedAward</code>，其权重矩阵可以是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/3474b4d0f42617497030eb5df92e876c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZpCdhC7xFtAWI-rQeW-4QQ.png"/></div></div></figure><p id="a7e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中右上元素指示“好演员”和“有声望的奖项”的组合(使用之前的潜在向量的结构)。这将模拟一个潜在的事实，即好演员会获得有声望的奖项。</p><p id="4c3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在 RESCAL 中，每个实体有一个潜在向量，每个关系类型有一个权重矩阵，因此参数θ为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/2f597a11d03ab6aa63a1ddbc22e6dbd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kPOWkb1UE8ufkP5RizyMRQ.png"/></div></div></figure><p id="8242" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">重写评分函数</strong> <br/>我们也可以用不同的方式编写 RESCAL 的评分函数。正如我们将看到的，这将有助于稍后比较 RESCAL 与其他方法。以前我们有:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/ab9d7a4c1c58ba6f5c9a7c9a93001e8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e07cx0hPua93ai8QxOSPdQ.png"/></div></div></figure><p id="6c12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，我们可以通过首先创建一个包含潜在特征向量元素的所有组合的向量来重写这个(在上面的公式中，这些都是组合<em class="lv"> e_ia </em> x <em class="lv"> e_jb </em>)。我们可以这样得到这个向量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/ccad96ede6d28c9ab7fc7d0bd8269997.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dEXcnjVGl0d8Mc434Fsqpg.png"/></div></div></figure><p id="70bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，⊗是两个向量<strong class="lb iu"> a </strong> ∈ ℝ^N 和<strong class="lb iu"> b </strong> ∈ ℝ^M 的克罗内克乘积，这给出了维度为<em class="lv"> NM </em>的向量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/0f8b72885216958c5f48b62b5562ef22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9QPAgsth9CGBx4DgPx8A6A.png"/></div></div></figure><p id="f269" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，使用克罗内克乘积，我们可以重写评分函数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/dfc7d586136b472ba2abce97cc72eb3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CnbTYTjGbm3Vx2gkUiEoIA.png"/></div></div></figure><p id="eb58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"> w </strong> _k = vec( <strong class="lb iu"> W </strong> _k)(即:矩阵<strong class="lb iu"> W </strong>的元素存储为一个向量)。</p><p id="6f05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总而言之，我们可以将重标模型改写如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/6b3b57ecd110f7a1697996b75f18541f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EcMhOmNDq6lHT3JXgRprKg.png"/></div></div></figure><p id="f4c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">直观地表示出来(这里，潜在向量的大小是 H_e = 3):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/1bd6c9ce697dfa81140b665d6b5ecf87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HUgEcICP6Jt0BiQslnZwfQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摘自论文[1]</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h2 id="cb91" class="nu me it bd mf nv nw dn mj nx ny dp mn li nz oa mp lm ob oc mr lq od oe mt of bi translated">2.1.2 多层感知器(MLP)</h2><p id="4cec" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated"><strong class="lb iu">实体多层感知器(E-MLP) </strong></p><p id="4474" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也可以选择使用标准的 MLP，以主体和客体实体的潜在向量作为输入，来模拟潜在特征的相互作用。因此，我们将有一个输入层，它接受潜在向量的串联:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/b06e702d2dbca8c08290444c37cb9edc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hICzmu1bou8zRBaNix4jMA.png"/></div></div></figure><p id="4638" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们有一个大小为 H_a 的隐藏层<strong class="lb iu"> h </strong> _{ijk}^a，它通过一个矩阵<strong class="lb iu">a</strong>k 来模拟潜在特征之间的相互作用:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/d532712760e3bcfdc233382b6d9e4dc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*apa-v-sy_BNmwEkt0ntPUQ.png"/></div></div></figure><p id="ed4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意 RESCAL 总是通过产品<strong class="lb iu"> e </strong> _i ⊗ <strong class="lb iu"> e </strong> _j 考虑潜在特征的所有可能的交互，而 E-MLP 模型<em class="lv">通过<strong class="lb iu"> A </strong> _k 学习</em>这些交互。最后，我们输出分数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/c5713a2f6e9d3d540c54bb827c743c00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y97uXxpoA8bDFsstAoiJRg.png"/></div></div></figure><p id="cc21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"> g </strong> (⋅)是某个激活函数。</p><p id="5951" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以形象地表示这一点(这里，潜在向量的大小是 H_e = 3，隐藏层的大小是 H_a = 2):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/7e0ac376ffeba10ea309dbdb0ebba94d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G2YAFsfQ1rk3WOr_748_CA.png"/></div></div></figure><p id="aaf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据我们对 H_a 的选择，与 RESCAL 相比，这可以减少所需的参数数量。</p><p id="87a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">实体关系多层感知器(ER-MLP) </strong></p><p id="5939" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如何进一步减少所需的参数数量？</p><p id="f0ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以将关系的潜在向量嵌入向量<strong class="lb iu"> r </strong> _k ∈ ℝ^{H_r}，并将其与输入中的主体和客体向量连接在一起:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/ff2465961d66676aa7e252c223dc0832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WYdrlkfppzNOVHf5t7kK4g.png"/></div></div></figure><p id="3b76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们建立我们的隐藏层:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/4d31ffbd7141e366455cfb65aeb38e50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHWUWPLMcua-QyBzTIaasA.png"/></div></div></figure><p id="1d8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的输出层:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/5bddd612052eefe79fdcee213cef07f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tjwdflQqqlYd1FiZkzONAg.png"/></div></div></figure><p id="dcfb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，通过嵌入关系，我们现在有了一个<strong class="lb iu">全局</strong>矩阵<strong class="lb iu"> C </strong>而不是 k 相关的<strong class="lb iu"> A </strong> _k，以及一个<strong class="lb iu">全局</strong>向量<strong class="lb iu"> w </strong>而不是<strong class="lb iu"> w </strong> _k。这可以大大减少所需的参数数量。</p><p id="2748" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以直观地表示这一点(这里潜向量的大小为 H_e = 3，H_r = 3，隐藏层的大小为 H_c = 3):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/dc88b64053a30d4356cadf5d2a9ba9f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CBt7YFvGqM2MSVkiA8bfAA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摘自论文[1]</p></figure><p id="5bed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">比较这三种不同模型的结构:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/657319b4fbecb07aa68823b2c361091b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IB7bzehfHruXbDUA.png"/></div></div></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h2 id="77a4" class="nu me it bd mf nv nw dn mj nx ny dp mn li nz oa mp lm ob oc mr lq od oe mt of bi translated">2.1.3 潜在距离模型</h2><p id="7e76" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在这些模型中，两个实体之间存在关系的概率由它们潜在表示的<em class="lv">距离</em>给出。这些表示越接近，这两个实体就越有可能处于关系中。对于单关系数据(因此当只有一种关系时)，这是相当简单的:我们可以通过一个得分函数来模拟成对关系 x_ij 的概率</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/fee43a9520ec559040fa213e8d982589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w4BcIRHylQ2iERq3OMbXFA.png"/></div></div></figure><p id="1a5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中 d(⋅，⋅)是一些距离的措施(如:欧几里德距离)。</p><p id="fd6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们如何将此扩展到多关系数据？<br/>一种可能的解决方案是<strong class="lb iu">结构化嵌入</strong> (SE)模型，该模型对三重 x_ijk 使用以下评分函数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/daf08834043dd253081ea634deb10d39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lk27KjIljnamKTSdec09Wg.png"/></div></div></figure><p id="0916" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，潜在特征通过矩阵<strong class="lb iu"> A </strong> _k^s 和<strong class="lb iu"> A </strong> _k^o 进行转换并进行比较。这些矩阵是“以现有关系中的实体对比不存在关系中的实体对彼此更接近的方式”学习的</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="036d" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">2.2 图形特征模型</h1><p id="d7c7" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">潜在特征模型使用潜在变量来预测图中的新链接。相比之下，图特征模型直接根据观察到的三元组进行预测。</p><p id="d60e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一些类型的图形特征模型:</p><ul class=""><li id="5d37" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nt ng nh ni bi translated"><strong class="lb iu">单一关系数据的相似性度量</strong>:这里的想法是使用某种相似性度量来预测两个节点之间的链接，因为相似的实体很可能是相关的。这种相似性可以以各种方式导出，例如通过查看节点的邻居(例如:“这两个节点有许多共同的邻居吗？”)</li><li id="9ae0" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu">规则挖掘和归纳逻辑编程</strong>:如果我们能从观察到的三元组中提取出一些逻辑规则，就可以用它们来预测图中新的三元组。这可以使模型具有高度的可解释性，因为它只是由一组规则给出的。然而，学会所有的规则和模式并不容易</li><li id="f310" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu">路径排序算法</strong>，如下所述</li></ul></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h2 id="603c" class="nu me it bd mf nv nw dn mj nx ny dp mn li nz oa mp lm ob oc mr lq od oe mt of bi translated">路径排序算法(PRA)</h2><p id="70f9" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">路径排序算法实质上是在图中寻找<em class="lv">路径</em>，这些路径对于预测某些新边是有用的。例如，假设有两个节点<em class="lv"> e_i </em>和<em class="lv"> e_j </em>，它们都从第三个节点接收类型为<code class="fe np nq nr ns b">bossOf</code>的输入链接。那么 PRA 可能了解到<em class="lv"> e_i </em>和<em class="lv"> e_j </em>被边<code class="fe np nq nr ns b">colleagueOf</code>连接的概率很高。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/68584fca3cad32ce930049d479f317d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P9z3e_QUw0VXCKCjfpaO0w.png"/></div></div></figure><p id="e291" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更一般地说，我们对构建一个模型感兴趣，该模型可以使用两个节点之间的更长路径来预测连接它们的某条直接边。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/b65d7d31fd6b5786acb6a45f63577585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TgPLCqW8Kc8MHyesu50o6A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">连接 e_i 和 e_j 的更长的路径能帮助我们预测它们之间直接关系 r_k 的存在吗？</p></figure><p id="9917" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用逻辑回归模型来构建评分函数</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/498ab2901e788fcea07465fc0d4470e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nrinRsTqe3uq0JDSMMxGbg.png"/></div></div></figure><p id="55ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，ϕ_ij 是对应于 e_i 和 e_j 之间所有可能路径的特征。<br/> [ <em class="lv">注</em>:我使用的符号与本文中用于路径特征的符号略有不同。我发现这与其他论文中使用的路径排序算法更清晰、更一致。]</p><p id="e221" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我们现在需要找到一些方法来表达这些不同的路径，用一种数字的，可量化的形式，我们可以用它作为ϕ_ij.</p><p id="e1f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">设π=⟨R1，r_2,…,r_L⟩是一个长度为 l 的<em class="lv">路类型</em>，即:一个确定的边类型序列【2】。我们如何表达 e_i 和 e_j 之间的路径，该路径遵循路径类型π作为特征？如果我们从 e_i 开始，沿着严格遵循π定义的边类型的路径，假设在每个交叉点，我们将随机均匀地选择一个可能的输出链接，我们可以使用我们将在 e_j 结束的概率。<br/>我们可以把这个概率表示为 P(i → j，π)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/870da1588e5d3e7e1b1ddaac529fd0a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dMkkqZJYfSARqOGR3aHXjA.png"/></div></div></figure><p id="d7c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，让我们定义一个路径类型π=⟨f <em class="lv">里恩多夫，⟩.</em>的父母如果我们看上面的图表，我们可以看到 P(i → j，π) = 0.5。事实上，从 e_i 开始，只有一条链路满足关系<code class="fe np nq nr ns b">frienfOf</code>，所以我们将以 1 的概率到达节点 e_b。然而，从 e_b 有两个可能的<code class="fe np nq nr ns b">parentOf</code>链接，所以从这里我们将以 1/2 的概率到达 e_j。</p><p id="fed0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们称π= {π₁，π₂，…，π_n}为我们要考虑的所有路径类型的集合，我们可以将我们的特征向量定义为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/34cb7c36c4a089d29d4489b1578d0d58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5QNkknTA-7C997ULzEmkHA.png"/></div></div></figure><p id="1d39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的评分函数是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/40af957fab413759ca0d06fded803a95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FhOkcbOOTsv4X8-O-kRw0w.png"/></div></div></figure><p id="1b33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用这个模型的一个优点是它很容易解释。事实上，我们可以查看获得最高权重的路径类型，并将它们视为模型已经识别的“规则”。论文以学习到的权重为例，预测三元组<em class="lv"> (p，college，c) </em>，从而预测一个人上过哪所大学。其中权重最高的是由⟩、<em class="lv">学校</em>起草的路径类型⟨ <em class="lv">，这意味着如果一个人是由某个<em class="lv">学校</em>(学院)所属的</em>团队起草的<em class="lv">，那么他很可能去了那个学院。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/fa94d81afa8c454d6de8b33c25fe58b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KS7IkaAl27PslBN7h_7kpg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摘自论文[1]</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="10b6" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">2.3 结合潜在和图形特征模型</h1><p id="d46d" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">潜在特征模型和图形特征模型具有不同的优势:</p><ul class=""><li id="6613" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nt ng nh ni bi translated">潜在特征模型适用于建模全球关系模式，当只有少量潜在变量足以解释三元组时</li><li id="2678" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu">图形特征模型</strong>适用于本地关系模式的建模，当三元组可以用图形中实体的邻域或短路径来解释时</li></ul><p id="8973" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，将这两种类型的方法结合起来利用它们各自的优势是很有用的。一种可能的方法是通过<strong class="lb iu">加性关系效应</strong> (ARE)模型。例如，我们可以将 RESCAL 和 PRA 结合起来:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/78c0c92a061f68f76c5ef5302d768dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ReTxDfiQun32CckkOhF2rw.png"/></div></div></figure><p id="de5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过这种方式，PRA 可以模拟<em class="lv">可观察的图形模式</em>，而 RESCAL 可以模拟 PRA 无法模拟的“残余误差”。这意味着，与必须自己对所有事物建模相比，RESCAL 需要的潜在特征数量要少得多。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="4abd" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">3.一些更酷的东西</h1><p id="9a56" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我会给你留下一些潜在的主题来研究，以扩展我在这篇文章中提到的内容:</p><ul class=""><li id="2cfd" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nt ng nh ni bi translated"><strong class="lb iu">马尔可夫随机场</strong>:另一种值得研究的统计关系学习模型。这在论文中有所涉及，不过如果你以前从未见过它们，我会建议你寻找一些对初学者更友好的资源</li><li id="7531" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu">高阶关系</strong>:本文关注的是二元关系(我相信这是知识图的默认设置)，但是也可以构建包含两个以上术语的关系图</li><li id="694f" class="na nb it lb b lc nj lf nk li nl lm nm lq nn lu nt ng nh ni bi translated"><strong class="lb iu">时间呢？有些事实只在某个时刻或某个时间间隔内成立，我们如何对此建模？</strong></li></ul></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h2 id="9b43" class="nu me it bd mf nv nw dn mj nx ny dp mn li nz oa mp lm ob oc mr lq od oe mt of bi translated"><strong class="ak">参考文献</strong></h2><p id="ce9c" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">[1] Nickel，m .，Murphy，k .，Tresp，v .和 Gabrilovich，E. <a class="ae ky" href="https://arxiv.org/abs/1503.00759" rel="noopener ugc nofollow" target="_blank">知识图的关系机器学习综述</a> (2015)。IEEE 会议录，104(1)。<br/>【2】Gardner，m .、Talukdar，p .、Kisiel，b .和 Mitchell，T. <a class="ae ky" href="https://www.aclweb.org/anthology/D13-1080.pdf" rel="noopener ugc nofollow" target="_blank">利用潜在的句法线索提高大型知识库中的学习和推理</a> (2013)。2013 年自然语言处理经验方法会议录。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="1b8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">觉得这个故事有帮助？考虑</em> <a class="ae ky" href="https://chiaracampagnola.medium.com/membership" rel="noopener"> <em class="lv">订阅</em> </a> <em class="lv">到媒体支持作家！</em></p></div></div>    
</body>
</html>