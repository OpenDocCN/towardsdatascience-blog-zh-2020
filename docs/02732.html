<html>
<head>
<title>Predicting AirBnB prices in Lisbon: Trees and Random Forests</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测里斯本 AirBnB 的价格:树木和随机森林</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-airbnb-prices-in-lisbon-trees-and-random-forests-336d19cdf5a2?source=collection_archive---------32-----------------------#2020-03-16">https://towardsdatascience.com/predicting-airbnb-prices-in-lisbon-trees-and-random-forests-336d19cdf5a2?source=collection_archive---------32-----------------------#2020-03-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/7f347760be8c391b8fb899542dc4b111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dy1govK1aYxnnKPd"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">安德烈亚斯·布吕克尔在<a class="ae kf" href="https://unsplash.com/photos/8Nd3GY8z-iU?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3c39" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇小文章中，我们将快速启动一个预测模型，预测里斯本 AirBnB 的夜间价格。本指南希望通过使用真实数据和开发真实模型，为机器学习数据分析提供简单实用的介绍。</p><p id="fc6b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它还假设对 Python 和机器学习库<a class="ae kf" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>有基本的了解，并且是在运行 Python 3.6 和 sklearn 0.21 的 Jupyter 笔记本上编写的。数据集和笔记本都可以在我的<a class="ae kf" href="https://github.com/josetapadas/airbnb-lisbon-model-trees" rel="noopener ugc nofollow" target="_blank"> Github 账户</a>上获得，或者通过<a class="ae kf" href="https://datasetsearch.research.google.com/search?query=lisbon%20airbnb&amp;docid=c6zMqHvIlOwEwlHEAAAAAA%3D%3D" rel="noopener ugc nofollow" target="_blank">谷歌的数据集搜索</a>获得。</p><h1 id="3f45" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">1.数据探索和清理</h1><p id="7cbc" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">作为第一步，我们从加载数据集开始。下载文件后，用 Pandas 打开并解析它是很简单的事情，并提供一个我们可以从中期待的快速列表:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="af0a" class="ms lf it mo b gy mt mu l mv mw">Index(['room_id', 'survey_id', 'host_id', 'room_type', 'country', 'city', 'borough', 'neighborhood', 'reviews', 'overall_satisfaction', 'accommodates', 'bedrooms', 'bathrooms', 'price', 'minstay', 'name', 'last_modified', 'latitude', 'longitude', 'location'], dtype='object')</span></pre><p id="66da" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管我们可以确认数据集已被正确加载和解析，但对数据统计描述的快速分析可以让我们快速了解其本质:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mx"><img src="../Images/515c36f5800ff988a80bdedc26d43543.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0OhfqtAo2gAr70OCim3--w.png"/></div></div></figure><p id="6f8b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从这个表中，我们实际上可以推断出每个参数的基本统计观察值。因为我们的模型打算根据我们将提供给它的任何一组输入来预测价格，所以我们可以检查例如:</p><ul class=""><li id="b6f3" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">每晚价格的平均值约为 88 欧元</li><li id="a882" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">价格从最低<strong class="ki iu"> 10 欧元</strong>到<strong class="ki iu"> 4203 欧元</strong>不等</li><li id="1370" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">价格的标准偏差约为<strong class="ki iu"> 123 欧元</strong>(!)</li></ul><p id="fcf2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">价格分布可以表示如下:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/93a40f368859be1f808a1fb853b029a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/0*OAtkBHlLPNbrNOc4.png"/></div></figure><p id="a87e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如我们所见，我们的价格分布集中在<strong class="ki iu"> 300 欧元</strong>区间下，有一些条目对应<strong class="ki iu"> 4000 欧元</strong>的值。绘制出大部分价格所在的位置:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/d84c264356e5f8544f456909b174115b.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/0*-kMjidTqk_TfPeYw.png"/></div></figure><p id="7ac6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上面的描述中我们可以清楚地看到，在里斯本住一晚的大部分价格在 0-150 欧元之间。</p><p id="8bb5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们窥探一下实际数据集，以便了解我们将要处理的参数类型:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/3f1a24badd848bec43c5c4223302cd3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sK_Ut2wu3EfDeCCgjh64Zw.png"/></div></div></figure><p id="bb4e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上面的描述中，我们应该能够推断出一些关于数据性质的统计数据。除了分布参数集(我们现在不寻找)，我们清楚地确定了两组相关的见解:</p><ul class=""><li id="4ab5" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">有空列:<code class="fe np nq nr mo b">country</code>、<code class="fe np nq nr mo b">borough</code>、<code class="fe np nq nr mo b">bathrooms</code>、<code class="fe np nq nr mo b">minstay</code></li><li id="bd9f" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">像<code class="fe np nq nr mo b">host_id</code>、<code class="fe np nq nr mo b">survey_id</code>、<code class="fe np nq nr mo b">room_id</code>、<code class="fe np nq nr mo b">name</code>、<code class="fe np nq nr mo b">city</code>、<code class="fe np nq nr mo b">last_modified</code>和<code class="fe np nq nr mo b">survey_id</code>这样的条目可能与我们的价格预测器不太相关</li><li id="6feb" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">有一些分类数据，我们最初无法添加到价格回归中，例如<code class="fe np nq nr mo b">room_type</code>和<code class="fe np nq nr mo b">neighborhood</code>(但我们稍后会回到这两个数据)</li><li id="016d" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated"><code class="fe np nq nr mo b">location</code>现在可能是多余的，因为我们既有<code class="fe np nq nr mo b">latitude</code>又有<code class="fe np nq nr mo b">longitude</code>，我们可能需要进一步推断该字段格式的性质</li></ul><p id="f757" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，让我们继续将数据集分为:</p><ul class=""><li id="0ea4" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">一个向量<strong class="ki iu"> Y </strong>将包含数据集的所有真实价格</li><li id="0aa9" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">在矩阵<strong class="ki iu"> X </strong>上，包含我们认为与我们的模型相关的所有特征</li></ul><p id="2596" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这可以通过下面的代码片段来实现:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/fa8bb2a7e11140d5a33dcfba4620afb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*EqjpaZ9D6qY9vvH3d5Qa-A.png"/></div></figure><p id="6805" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有了新的子集，我们现在可以尝试了解这些参数在最常见价格范围内的总体满意度方面的相关性:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/ba185e4dac3bd5180fe4554124122591.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CR4yUy6V0brtrD78.png"/></div></div></figure><p id="6772" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上述图表允许我们检查所有单个变量的分布，并试图推断它们之间的关系。我们可以根据我们选择的每个参数的审核值自由应用色调。上图中一些简单易懂的例子，来自可能表示正相关的关系:</p><ul class=""><li id="7a33" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">对于住宿较少的房间，评论的数量更常见。这可能意味着大多数评论的客人都租了较小的房间。</li><li id="453a" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">大多数评论都是针对价格较低的房间的</li><li id="f709" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">考虑到黄色的视觉优势，大多数评论实际上是 5 分。要么这意味着大多数住宿实际上是非常令人满意的，或者最有可能的是，大量的人实际上审查，这样做是为了给 5 分的评级。</li></ul><p id="ca42" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个奇怪的观察是，位置严重影响价格和评级。绘制经度和纬度时，我们可以获得里斯本沿线评级的准地理/空间分布:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/e158c00a859c23d9d33313d0b0433deb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/0*PyZJDKOLGKo8ezb3.png"/></div></figure><p id="e1de" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们可以将这些数据添加到里斯本的实际地图上，以检查分布情况:</p><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/932ec8394b618d9f38e49490ca0ca515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*hl_sQAYpiOzQpBL1.png"/></div></figure><p id="4276" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如预期的那样，大多数评论都是关于市中心的，一些评论已经与最近的 Parque das Na es 相关。北部更多的次城区，尽管它有一些分散的地方，但评论没有中心那么高和普遍。</p><h1 id="9874" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">2.分割数据集</h1><p id="ba7d" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">现在我们的数据集已被正确清除，我们将首先把它分成两部分:</p><ul class=""><li id="e49e" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">将负责训练我们的模型的集合，因此称为<strong class="ki iu">训练集合</strong></li><li id="1374" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">一个<strong class="ki iu">验证集</strong>，它将被用来验证我们的模型</li></ul><p id="7a3f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个集合基本上都是<strong class="ki iu"> X </strong>和<strong class="ki iu"> Y </strong>的子集，包含租赁空间及其相应价格的子集。然后，在训练我们的模型之后，我们将使用验证集作为输入，然后推断我们的模型在归纳成除了用于训练的数据集之外的数据集方面有多好。当一个模型在训练集上表现很好，但不能很好地推广到其他数据时，我们说该模型对数据集<strong class="ki iu">过度拟合</strong>。</p><p id="7982" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有关过度配合的更多信息，请参考<a class="ae kf" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Overfitting</a></p><p id="b23b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了避免我们的模型对测试数据的这种<strong class="ki iu">过度拟合</strong>，我们将使用 sklearn 的一个名为<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . model _ selection . train _ test _ split . html</a>的工具，该工具基本上将我们的数据分割成一系列随机的训练和测试子集:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="b4f7" class="ms lf it mo b gy mt mu l mv mw">Training set: Xt:(10183, 6) Yt:(10183,) <br/>Validation set: Xv:(3395, 6) Yv:(3395,) <br/>- <br/>Full dataset: X:(13578, 6) Y:(13578,)</span></pre><p id="5e09" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们已经有了数据集，我们现在可以继续创建一个简单的回归模型，根据我们选择的参数，尝试预测里斯本 AirBnb 的每夜费用。</p><h1 id="3a4a" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">3.种植决策树</h1><p id="98a0" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">作为最简单的监督 ML 模型之一，决策树通常用于通过从所有可用的特征数据中学习和推断决策规则来预测结果。通过获取我们的数据参数，这些树可以学习一系列有知识的“问题”,以便以某种方式划分我们的数据，我们可以使用得到的数据结构对分类数据进行分类，或者简单地为数值创建回归模型(就像我们对价格的情况一样)。</p><p id="08d5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个可视化的例子，取自维基百科，可以是围绕泰坦尼克号乘客生存预测的决策树:</p><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/2eef36de2e39105369d9b8b3818a9ab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/0*bpxepHwlE4EQaWiM.png"/></div></figure><p id="a38e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基于这些数据，树建立在根上，并且将通过将每个节点分成两个子节点来(递归地)划分。这些生成的节点将根据我们向模型提供的统计数据推断出的决策进行拆分，直到我们达到数据拆分产生最大信息增益的点，这意味着我们可以根据我们迭代创建的类对所有样本进行正确分类。我们称之为“叶子”的末端顶点。</p><p id="d240" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在上面的维基百科示例中，遵循决策过程是微不足道的，因为存活概率是这里的估计参数，所以我们可以很容易地获得当“他没有兄弟姐妹”时，“9.5 岁以上的男性”存活的概率。</p><p id="4fc6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(为了更深入地理解决策树是如何为回归构建的，我推荐由<a class="ae kf" href="https://statquest.org/2018/01/22/statquest-decision-trees/" rel="noopener ugc nofollow" target="_blank"> StatQuest 制作的名为决策树</a>的视频。</p><p id="1260" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后让我们通过利用<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html?highlight=decisiontreeregressor#sklearn.tree.DecisionTreeRegressor" rel="noopener ugc nofollow" target="_blank"> sklearn 实现</a>来创建我们的决策树回归:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="abf6" class="ms lf it mo b gy mt mu l mv mw">DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=42, splitter='best')</span></pre><p id="9c1b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了便于说明，我们可以在下图中验证树是如何构建的:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="849b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请<a class="ae kf" href="https://github.com/josetapadas/airbnb-lisbon-model-trees/blob/master/output_24_0.png" rel="noopener ugc nofollow" target="_blank">在这里找到生成树的图形表示</a> @ Github。</p><p id="f0a9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还可以显示预测的片段，以及训练数据集样本的相应参数。所以对于以下住宿:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/e6fbda568c0fd810d4d50ce8113a8a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*FIBrv0qEzPKtNefEHEXPBw.png"/></div></figure><p id="7214" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们获得以下价格:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="4e37" class="ms lf it mo b gy mt mu l mv mw">array([ 30., 81., 60., 30., 121.])</span></pre><p id="bf36" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在将我们的模型拟合到训练数据之后，我们现在可以对验证集运行预测，并评估我们的模型的当前绝对误差，以评估当不针对它所测试的数据运行时它的概括程度。</p><p id="e6d7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，我们将使用<strong class="ki iu">平均绝对误差</strong> (MAE)度量。我们可以将这一指标视为预测集中的平均误差幅度。它可以这样表示:</p><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/bbd1b6c18aa02e6de58e34ed64af22f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*-DjPfVosxmxHUAlDE6hUOQ.png"/></div></figure><p id="95e2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它基本上是我们的模型预测(y)和实际观测值(<em class="nz"> y-hat </em>)之间差异的平均值，考虑到所有个体差异具有同等的权重。</p><p id="435d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，让我们使用<a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html" rel="noopener ugc nofollow" target="_blank"> Scikit Learn </a>实现将这一指标应用于我们的模型:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="514d" class="ms lf it mo b gy mt mu l mv mw">42.91664212076583</span></pre><p id="7b49" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这一结果基本上意味着，当暴露于测试数据时，我们的模型给出的绝对误差约为每间客房<strong class="ki iu"> 42.935 欧元</strong>，而我们在初始数据探索期间收集的平均值为<strong class="ki iu"> 88.38 欧元</strong>。</p><p id="de83" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要么是因为我们的数据集太小，要么是因为我们的模型太天真，这个结果并不令人满意。</p><p id="8612" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管这在这一点上看起来令人担忧，但总是建议尽快创建一个生成结果的模型，然后开始迭代优化。因此，现在让我们继续尝试改进我们模型的预测。</p><p id="0e11" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">目前，我们确实为测试数据的过度拟合而痛苦。如果我们想象正在构建的决策树，由于我们没有为要分割的决策指定限制，因此我们将生成一个决策树，该决策树一直深入到测试特征，而不是在任何测试集上很好地概括。</p><p id="78a8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于 sklearn 的<code class="fe np nq nr mo b">DecisionTreeRegressor</code>允许我们指定叶节点的最大数量作为超参数，因此让我们快速尝试评估是否存在降低 MAE 的值:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="c8d5" class="ms lf it mo b gy mt mu l mv mw">(Size: 5, MAE: 42.6016036138866) <br/>(Size: 10, MAE: 40.951013502542885) <br/>(Size: 20, MAE: 40.00407688450048) <br/>(Size: 30, MAE: 39.6249335490541) <br/>(Size: 50, MAE: 39.038730827750555) <br/>(Size: 100, MAE: 37.72578309289501) <br/>(Size: 250, MAE: 36.82474862034445) <br/>(Size: 500, MAE: 37.58889602439078) 250</span></pre><p id="3403" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，让我们尝试生成我们的模型，但包括计算的最大树大小，然后用新的限制检查其预测:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="1e56" class="ms lf it mo b gy mt mu l mv mw">36.82474862034445</span></pre><p id="6b99" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，通过简单地调整我们的最大叶节点数超参数，我们就可以获得模型预测的显著增加。我们现在已经改进了我们模型的平均误差(<code class="fe np nq nr mo b">42.935 - 36.825</code> ) **~ 6.11 欧元**。</p><h1 id="3a0a" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">4.分类数据</h1><p id="80dc" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">如上所述，即使我们能够继续优化我们非常简单的模型，我们仍然放弃了两个可能的相关字段，它们可能(也可能不会)有助于我们模型的更好的泛化和参数化:<code class="fe np nq nr mo b">room_type</code>和<code class="fe np nq nr mo b">neighborhood</code>。</p><p id="2ccf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些非数字数据字段通常被称为<strong class="ki iu">分类数据</strong>，通常我们可以通过三种方式接近它们:</p><p id="87c3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 1)下降</strong></p><p id="09e0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有时，处理分类数据最简单的方法是…将其从数据集中删除。我们这样做是为了快速建立我们的项目，但是我们必须一个案例一个案例地去推断这些字段的性质，以及它们是否有意义被删除。</p><p id="9f19" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是我们到目前为止分析过的场景，MAE 为:<strong class="ki iu">36445</strong></p><p id="409f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 2)标签编码</strong></p><p id="37f9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以对于标签编码，我们假设每个值被分配给一个唯一的整数。我们还可以考虑任何可能与数据相关的顺序/数量级(例如，评级、浏览量等)来进行这种转换。让我们使用 sklearn 预处理器检查一个简单的示例:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="5ad3" class="ms lf it mo b gy mt mu l mv mw">array([3, 3, 1, 0, 2])</span></pre><p id="6b3b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过分配拟合数据的数组索引来评估<code class="fe np nq nr mo b">LabelEncoder</code>正在进行的转换是很简单的:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="54b2" class="ms lf it mo b gy mt mu l mv mw">array(['double room', 'shared room', 'single room', 'suite'], dtype='&lt;U11')</span></pre><p id="245e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，让我们将这种预处理技术应用于分类数据，并验证这如何影响我们的模型预测。因此，我们的新数据集将是:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oa"><img src="../Images/59dc190db1c2a16b16b60f57cc5ebd49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qq6HfSEgbEeKAYqvTv1Vbw.png"/></div></div></figure><p id="c223" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的分类数据在 panda 的数据帧上表示为一个<code class="fe np nq nr mo b">object</code>，可以通过以下方式提取:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="4945" class="ms lf it mo b gy mt mu l mv mw">['room_type', 'neighborhood']</span></pre><p id="104f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们有了列，接下来让我们在训练集和验证集上转换它们:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/3ffeee300651b417e52779ed492cd3ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A76HrEgeWUUtNCURXJh9oA.png"/></div></div></figure><p id="856d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们用转换后的数据来训练和拟合模型:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="a113" class="ms lf it mo b gy mt mu l mv mw">35.690195084932355</span></pre><p id="8560" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们改进了我们的预测器，对我们的分类数据进行编码，将我们的 MAE 降低到<strong class="ki iu"> ~ 35.69 欧元</strong>。</p><p id="4521" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 3)一键编码</strong></p><p id="38a3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一次性编码不是枚举字段的可能值，而是创建新的列来指示编码值是否存在。让我们用一个小例子来展示这一点:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="6d30" class="ms lf it mo b gy mt mu l mv mw">array([[0., 0., 0., 1., 0., 0., 1.], [0., 1., 0., 0., 0., 1., 0.]])</span></pre><p id="e1b7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上面的结果我们可以看到，二进制编码在每个特性数组实际启用的特性上提供了<code class="fe np nq nr mo b">1</code>，在不存在时提供了<code class="fe np nq nr mo b">0</code>。然后，让我们尝试在我们的模型上使用这种预处理:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/94579284d11b227f6639d07f5109ce45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*_ek4d5Ox3NEDlfOJ1WXSog.png"/></div></figure><p id="37a0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以上面的结果乍一看可能很奇怪，但是对于 26 个可能的类别，我们现在有一个二进制编码来检查它的存在。我们现在将:</p><ul class=""><li id="75f9" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">添加回转换过程中丢失的原始行索引</li><li id="b44f" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">从原始集合<code class="fe np nq nr mo b">train_X</code>和<code class="fe np nq nr mo b">validation_X</code>中删除原始分类列</li><li id="d64b" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">用包含所有 26 个可能类别的新数据框架替换删除的列</li></ul><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><figure class="mh mi mj mk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi od"><img src="../Images/3effe0cea515b65fc534c600cf9a2d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k9d83hBnIs5UU3HNZMHRaA.png"/></div></div></figure><p id="a3f0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们可以继续在模型中使用新的编码集:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="9f3d" class="ms lf it mo b gy mt mu l mv mw">36.97010930367817</span></pre><p id="f13a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过对我们的分类数据使用一个热编码，我们获得了 MAE to ~ <strong class="ki iu"> 36.97EUR </strong>。</p><p id="7f0d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个结果可以证明，当与标签编码相比较时，对于我们的分类参数以及同时对于这两个参数来说，一键编码不是最佳的。然而，这个结果仍然允许我们将分类参数包括在初始 MAE 的减少中。</p><h1 id="dd9f" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">5.随机森林</h1><p id="e1a1" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">从上一节我们可以看到，使用决策树，我们总是在以下两者之间保持平衡:</p><ul class=""><li id="1627" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">一棵有很多叶子的深树，在我们的例子中，每片叶子上只有很少的 AirBnB 位置，对我们的测试集来说太多了(它们呈现了我们所说的<strong class="ki iu">高方差</strong></li><li id="a34c" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">一棵浅树，叶子很少，无法区分一个项目的各种特征</li></ul><p id="db85" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以将“随机森林”想象为决策树的集合，为了试图减少上述差异，决策树以允许算法以减少误差的方式选择剩余树的方式生成树。如何创建随机森林的一些示例如下:</p><ul class=""><li id="8507" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">用不同的数据子集生成树。例如，根据上面分析的我们的参数集，将生成仅具有它们的随机集的树(例如，仅具有“评论”和“卧室”的决策树，另一个具有除“纬度”之外的所有参数</li><li id="a60a" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">通过对不同的数据样本进行训练来生成其他树(不同的大小，训练和验证数据集之间的不同划分等等)</li></ul><p id="0e10" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了减少方差，增加的随机性使得生成的单个树的误差不太可能相关。然后，通过组合不同的决策树预测，从所有预测的平均值中提取预测，这具有甚至消除一些错误的有趣效果，从而降低整个预测的方差。</p><p id="beb8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">更深入地解释该算法的原始出版物可以在本文末尾的参考书目部分找到。</p><p id="de2e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，让我们使用随机森林来实现我们的预测器:</p><figure class="mh mi mj mk gt ju"><div class="bz fp l di"><div class="ml mm l"/></div></figure><pre class="mh mi mj mk gt mn mo mp mq aw mr bi"><span id="cccf" class="ms lf it mo b gy mt mu l mv mw">33.9996500736377</span></pre><p id="f4fe" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，当使用随机森林时，我们的 MAE 显著降低。</p><h1 id="497d" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">6.摘要</h1><p id="07e0" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">尽管决策树是机器学习中非常简单(可能是最简单)的回归技术，我们可以在我们的模型中使用，但我们希望演示一个分析数据集以生成预测的样本过程。很明显，通过小的优化步骤(如清理数据、对分类数据进行编码)和将单棵树抽象为随机森林，我们可以显著降低模型预测的平均绝对误差。</p><p id="363a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们希望这个例子作为机器学习的实践经验变得有用，如果我可以澄清或纠正上面演示的一些内容，请不要联系我。在未来的一些文章中，我们还计划使用其他方法和工具进一步优化我们对这个特定数据集的预测，敬请关注:)</p><h1 id="48dd" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">7.进一步阅读</h1><p id="23a3" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">请在下面找到一些资源，它们对于理解一些公开的概念非常有用:</p><ul class=""><li id="7e60" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">StatQuest，决策树:<a class="ae kf" href="https://statquest.org/2018/01/22/statquest-decision-trees/" rel="noopener ugc nofollow" target="_blank">https://statquest.org/2018/01/22/statquest-decision-trees/</a></li><li id="2e60" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">偏差-方差权衡:<a class="ae kf" href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Bias % E2 % 80% 93 方差 _ 权衡</a></li><li id="d13c" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">布雷曼，随机森林，机器学习，45(1)，5–32，2001:<a class="ae kf" href="https://www.stat.berkeley.edu/users/breiman/randomforest2001.pdf" rel="noopener ugc nofollow" target="_blank">https://www . stat . Berkeley . edu/users/布雷曼/randomforest2001.pdf </a></li></ul></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><p id="2333" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nz">欢迎随时联系我@</em><a class="ae kf" href="https://jose.tapadas.eu" rel="noopener ugc nofollow" target="_blank"><em class="nz">https://Jose . tapadas . eu</em></a></p></div></div>    
</body>
</html>