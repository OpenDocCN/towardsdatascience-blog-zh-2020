<html>
<head>
<title>Reasoning Using Modular Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用模块化神经网络进行推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reasoning-using-modular-neural-networks-f003cb6109a2?source=collection_archive---------55-----------------------#2020-05-14">https://towardsdatascience.com/reasoning-using-modular-neural-networks-f003cb6109a2?source=collection_archive---------55-----------------------#2020-05-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="353d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种解决人工智能问题的创新解决方案</h2></div><p id="c276" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">模块化背后的基本思想是:应对复杂挑战的最佳方法不是执行一个巨大的任务，而是一个由独立且基本独立的子任务组成的系统，这些子任务朝着一个大目标共同工作。这个概念有一个<strong class="kk iu">生物学基础</strong>。大脑中有专门的功能区域，它们是不同认知过程的特定领域。外侧膝状体(LGN)位于大脑的丘脑部分，分为几层，分别处理颜色和对比度:这两个视觉的主要组成部分。<strong class="kk iu">模块化神经网络</strong>利用这种思想解决<strong class="kk iu">复杂</strong> <strong class="kk iu">人工智能问题</strong>。几个<strong class="kk iu">独立的</strong>神经网络被同时训练用于特定的子任务，并且它们的结果在最后被组合以执行单个任务。模块化神经网络的优势包括:</p><ul class=""><li id="3259" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">简单</li><li id="63c3" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">技术组合</li><li id="f57e" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">可量测性</li><li id="46d8" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">效率</li></ul><p id="b20d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">众所周知，人工智能天生没有语言，所以我们的工作就是训练我们的模型对给定的文本进行推理。所谓推理，我们指的是算术、排序、比较和计数等任务。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/453c953b8d27fa0f69149072f4cdf803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D8p7vIIYAcChIzBSoYBvjw.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">图1:视觉问答是回答关于图像的问题的任务，以表明系统理解图像。</p></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/38aad3ac9dc31d6383f4093e6eef4ab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-OSDLfNRROESQYJfHedAJg.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">图2:阅读理解是回答关于一段文字的问题，以表明系统理解了这段文字。</p></figure><p id="00d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们要创建一个<strong class="kk iu">问答系统</strong>，<strong class="kk iu"> </strong>图1和图2说明了QA模型是如何工作的！</p><p id="648a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑这个问题“交通灯旁边的标志说什么？”在图1中。<strong class="kk iu">回答这样一个问题需要多个推理</strong>步骤:找到图像中的所有“标志”，找到“红绿灯”，选择“红绿灯旁边”的标志，然后找到“它说的是什么”。或者图2中的问题:首先我们需要找出给定文本中所有的逃课率，挑出最高的一个，然后找出“并列哪个区域”。我们希望开发能够理解此类复杂问题的<strong class="kk iu">组合语义</strong>的模型，以便提供<strong class="kk iu">正确答案</strong>。</p><p id="e722" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">NMNs 能够提供这样的推理。使用给定的问题，模型组装一个具体的网络架构，然后执行组装的神经模块网络以输出答案，如图3和图4所示。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mi"><img src="../Images/71b00fdb04776759f3e990ba9c9303f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u_d7iFSgbj3fisTnO3GMGA.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">图3:对于每个实例，模型首先预测布局，然后使用图像特征，它执行组装的神经模块网络来输出答案。</p></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mj"><img src="../Images/0830b9b4e2bd8c3a8cdc0e7a7eb49771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xib47zZoMJQO7NAqqx0d4w.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">图4:对于每个实例，模型首先预测布局，然后使用文本特征，它执行组装的神经模块网络来输出答案。</p></figure><h1 id="c39a" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">布局预测器</h1><p id="6dda" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">为了解决质量保证问题，制作了许多不同的模型布局。最近一篇关于这一主题的文献综述发现，他们中的大多数在特定形式的问题上表现突出。创建灵活布局组件是为了利用所有这些不同的模型。为了找到特定问题<strong class="kk iu"> <em class="nh"> q </em> </strong>的最佳布局<strong class="kk iu"> <em class="nh"> l </em> </strong>，需要先计算概率分布p(<strong class="kk iu"><em class="nh">l</em></strong>|<strong class="kk iu">|<em class="nh">q</em></strong>)，然后使用<strong class="kk iu">波束搜索</strong>，<strong class="kk iu">最大概率布局</strong>将在后面定义。假设每一层都是一系列模块:</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/3c96d07a402b7523fae61f2e4d8a3d05.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*BHm7AeqcnNub0IlzkEpnrA.png"/></div></figure><p id="360c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于我们有一个序列形式的模块，注意LSTM模型可以用来寻找每个可能的布局的概率分布。首先，我们把问题特征fQ(q)交给LSTM模型来生成一个隐藏状态:</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nj"><img src="../Images/69aa838dec62477173b1f635df3f377c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cXG4cNAXOAc74KbYtCwtyw.png"/></div></div></figure><p id="408c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输入问题单词的注意权重被预测为:</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/7859cc852330f1954cda079faf29589f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*iP_l9GVrBNvsxhambslHeA.png"/></div></figure><p id="2e9f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<strong class="kk iu"> <em class="nh"> e_ti </em> </strong>为对准模型，其定义为</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/8d6b0e6b68531a96b05752f92b340cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*EVxPQa8KjxkX2khgFKxR2A.png"/></div></figure><p id="5231" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<strong class="kk iu"> <em class="nh"> h_i </em> </strong>和<strong class="kk iu"> <em class="nh"> h_t </em> </strong>分别是编码器和解码器的LSTM输出。则上下文向量被计算为</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/b03a810f29ae540b941e394e1c4afecc.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*MN87P7YjDdxcInv2jfLuuA.png"/></div></figure><p id="d70b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该上下文向量将用于计算下一个模块的概率</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nn"><img src="../Images/7adf79e75d6ba83bcb87e825a761d2aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aVOjKIYhQ3EgQ5ZsmdQJtA.png"/></div></div></figure><p id="d6d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，<strong class="kk iu"> <em class="nh"> l </em> </strong>的概率分布定义如下</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi no"><img src="../Images/122f6299dcbfcac2972769b2f45d5007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*Xy4uiyhiLFawSmPOxa-c0A.png"/></div></figure><h1 id="564d" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">模块</h1><p id="e170" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">创建模块是为了独立执行基本的推理任务。把它们想象成接受注意力向量、文本或图像特征的函数，它们有一些内部参数来执行某种计算。让我们来看一些例子:</p><h2 id="632f" class="np ml it bd mm nq nr dn mq ns nt dp mu kr nu nv mw kv nw nx my kz ny nz na oa bi translated">查找[x]</h2><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ob"><img src="../Images/adefe11057dedef9294907fb763366b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SlqVsYpMEPTcrqjUim1WCQ.png"/></div></div></figure><p id="056b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"><em class="nh">VQA的</em> </strong>模块<strong class="kk iu">将输入图像中的每个位置与一个权重向量</strong>进行卷积(对每个x都不同)以产生一个关注。</p><h2 id="2a2a" class="np ml it bd mm nq nr dn mq ns nt dp mu kr nu nv mw kv nw nx my kz ny nz na oa bi translated">查找最大数量</h2><p id="0972" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">给定一段话，这个模块首先计算一个数字<strong class="kk iu">记号分布T </strong>，然后用这个来计算每个数字记号是具有最大值的那个的概率<strong class="kk iu"/>。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi oc"><img src="../Images/440fc4bc4d8ee57ec2c0bf3d9bb90ffc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yCUVkYpLwFM1ixJQ-PURIQ.png"/></div></div></figure><h2 id="bc84" class="np ml it bd mm nq nr dn mq ns nt dp mu kr nu nv mw kv nw nx my kz ny nz na oa bi translated"><strong class="ak">和/或</strong></h2><p id="e349" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated"><strong class="kk iu"> <em class="nh">和</em> </strong> <em class="nh"> </em>和<strong class="kk iu"> <em class="nh">或</em> </strong> <em class="nh">模块</em>以两幅图像注意力为输入，分别返回它们的<strong class="kk iu">交集</strong>或<strong class="kk iu">并集</strong>。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi od"><img src="../Images/c78497ef697891ae20e348205e049720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nOlg_NFnYkdvvlHMfe7HCQ.png"/></div></div></figure><h2 id="eade" class="np ml it bd mm nq nr dn mq ns nt dp mu kr nu nv mw kv nw nx my kz ny nz na oa bi translated">重新安置</h2><p id="0fe3" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">重定位模块将输入图像映射改变为<strong class="kk iu">新的注意力映射</strong>，这对于<strong class="kk iu">空间关系</strong>是有用的。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi oe"><img src="../Images/f5e36ae364d8c9e4502bb08b8e222284.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OA-6eO9LXB97d36DznrFAw.png"/></div></div></figure><h1 id="f50d" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">端到端培训</h1><p id="2558" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">像其他神经网络一样，在训练过程中，目标是最小化损失。但这里不同的是，模型<strong class="kk iu">共同学习</strong><strong class="kk iu">预测布局</strong> p(l|q)和各个模块中的<strong class="kk iu">参数</strong>。</p><h1 id="bf22" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">参考资料:</h1><p id="0c41" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">Hu R，Andreas J，Rohrbach M，Darrell T，Saenko K .学习推理:用于视觉问题回答的端到端模块网络。IEEE 2017年计算机视觉国际会议论文集(第804–813页)。</p><p id="45b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用于文本推理的神经模块网络。arXiv预印本arXiv:1912.049712019年12月10日。</p><p id="d197" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae of" href="https://arxiv.org/pdf/1511.02799.pdf" rel="noopener ugc nofollow" target="_blank"> Andreas J，Rohrbach M，Darrell T，Klein D .神经模块网络。2016年IEEE计算机视觉和模式识别会议论文集(第39–48页)。</a></p><p id="f90b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae of" href="https://www.jneurosci.org/content/jneuro/10/7/2223.full.pdf" rel="noopener ugc nofollow" target="_blank"> Hubel DH，Livingstone MS .猕猴外侧膝状体和初级视皮层的颜色和对比敏感度。神经科学杂志。1990年7月1日；10(7):2223–37.</a></p></div></div>    
</body>
</html>