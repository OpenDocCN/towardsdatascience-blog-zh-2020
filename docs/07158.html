<html>
<head>
<title>License Plate Image Enhancement</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">车牌图像增强</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/license-plate-image-enhancement-5a170475bec1?source=collection_archive---------21-----------------------#2020-06-01">https://towardsdatascience.com/license-plate-image-enhancement-5a170475bec1?source=collection_archive---------21-----------------------#2020-06-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6a7a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从银幕到现实</h2></div><p id="7a29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在好莱坞的犯罪电影中，我们经常看到侦探在一个电脑高手的帮助下突破一个难题，这个电脑高手可以从模糊的低质量图像中揭示隐藏的信息。用专业术语来说，电影中的黑魔法叫做<strong class="kh ir">单幅图像超分辨率(SISR) </strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/3ae0028fe6c93466241cdb8fd3367cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ehauCZ_ggYOQbfnHRnodOQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">https://www.youtube.com/watch?v=Vxq9yj2pVWk<a class="ae lr" href="https://www.youtube.com/watch?v=Vxq9yj2pVWk" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="a269" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在各种 SISR 应用中，汽车牌照的超分辨率无疑是潜力最大的。例如，它可以用于执法。它还可用于提高车牌识别和街道名称识别的准确性(地图服务)。在本文中，我将向您介绍我用 Python 实现的图版增强。Jupyter 笔记本教程可以在<a class="ae lr" href="https://github.com/zzxvictor/License-super-resolution" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="4a32" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">走廊</h1><p id="9376" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在深入模型架构和培训策略的本质细节之前，我想向您展示该模型的能力:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mp"><img src="../Images/dfa74ce34c5887b3ad4c44154ed3a4b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xFu4YZyfh_0F7o5jMpJIIw.png"/></div></div></figure><p id="4df2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在失控事故案例中看到的一个问题是，车牌通常是在黑暗条件下由低质量相机拍摄的。因此，我们的模型被训练成不仅增加分辨率，而且通过对图像去噪并调整其亮度和对比度来增强车牌号码的易读性。</p><h1 id="2f81" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">系统结构</h1><h2 id="25bd" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">预处理</h2><p id="d5e0" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">我们在这个项目中使用的数据集叫做<a class="ae lr" href="https://github.com/detectRecog/CCPD" rel="noopener ugc nofollow" target="_blank">中国城市停车数据集</a>，它包含了各种条件下汽车的 200k+图像。然而，原始数据不能被我们的模型消耗，它只想要车牌的图像而不是街景和汽车。因此，第一步是使用数据集提供的注释从图像中裁剪出板。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/b968dfbeda80238fb61a6d9503e7586a.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*hNwWptDlR4tygBBHQp2HWQ.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">剪下车牌</p></figure><p id="56ea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还想过滤掉亮度和对比度不好的图像，只保留好的部分作为标签。我们人工生成(输入，标签)对，其中输入被下采样，被噪声和随机亮度和对比度破坏，而标签处于良好状态。</p><h2 id="7ccc" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">模型细节</h2><p id="801e" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">我们的模型灵感来自于<a class="ae lr" href="https://arxiv.org/abs/1809.00219" rel="noopener ugc nofollow" target="_blank"> ESRGAN </a>模型。顾名思义，我们的模型是以对抗的方式训练的——在一个极小极大的游戏中，生成器对鉴别器。</p><p id="6578" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">发电机</strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nd"><img src="../Images/1439b05c0f38a2f327b192a3dce929b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Esw73TgU3QqxdqYtZZLKg.png"/></div></div></figure><p id="d471" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的发电机建立在两个最先进的模型之上——ESR gan<a class="ae lr" href="https://arxiv.org/abs/1809.00219" rel="noopener ugc nofollow" target="_blank">中的 RRDB 网</a>和<a class="ae lr" href="https://arxiv.org/abs/1802.08797" rel="noopener ugc nofollow" target="_blank">剩余密集网络</a>。发生器使用子像素卷积(在<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/nn/depth_to_space" rel="noopener ugc nofollow" target="_blank"> tensorflow </a>中也称为深度到空间，在<a class="ae lr" href="https://pytorch.org/docs/master/generated/torch.nn.PixelShuffle.html" rel="noopener ugc nofollow" target="_blank"> pyTorch </a>中称为像素混洗)将低分辨率图像向上采样 8 倍。本质上，子像素卷积所做的是将一个大小为 10×10×64 的特征图挤压成另一个更大的浅深度特征图(如果上采样率为 8，则为 80×80×1)。</p><p id="22bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">鉴别器</strong></p><p id="99dc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鉴别器是一个简单的 VGG 式网络，输出 0(假)或 1(真)。理想情况下，鉴别器应该能够区分图像重建和地面真实图像。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ne"><img src="../Images/b564f88459e51a5ba45e76ef4fb8491e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4J9084DsyfwDnzOx8NEe7g.png"/></div></div></figure><p id="d2d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">增加一个鉴别器而不是三角化一个最小化均方误差的生成器的好处是，后者往往会产生过度平滑的伪像，一点也不像合法的字母。使用鉴别器来约束输出空间有助于创建类似字母的重建。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nf"><img src="../Images/13314bdfdc8d20ce86a5ef4e26d433ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aU3W81QvGt-W_QTLviip5w.png"/></div></div></figure><p id="0737" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">损失函数和评估</strong></p><p id="9308" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">板重建的一个问题是，像均方误差或峰值信噪比这样的常用指标在描述高水平特征方面不是特别好。例如，与具有偏离亮度和高对比度的良好重建相比，模糊重建可以实现更高的 PSNR。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ng"><img src="../Images/16aaea80d14702b230db41ef545ccdcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9CycDpNo2KuvMGNC9HTFLg.png"/></div></div></figure><p id="4893" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，关注边缘和字母方向等高级特征至关重要。在 SRGAN 的论文中，研究人员发现了一种新的内容损失函数，它在 VGG 网络的特征空间中计算 MSE，突出图像特征，而不是在图像空间中。他们将<strong class="kh ir"> VGG 损失</strong>定义为</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nh"><img src="../Images/2f13001a06fae11ba297677bcb7683c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N1DYit7n4f__FHZTQyb6kg.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://arxiv.org/pdf/1609.04802.pdf" rel="noopener ugc nofollow" target="_blank"> SRGAN </a>，在麻省理工学院许可下复制</p></figure><p id="9611" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的模型被优化以最小化被称为<strong class="kh ir">内容损失</strong>的 VGG 损失和 MSE 的混合:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/efa4d9534ccbc08ac06aec48eeeae7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*oNMsWyA-Bp3DnbFGjDXhiQ.png"/></div></figure><p id="b2e9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">内容损失迫使模型注意重建中的边缘，确保高级骨架与地面真相相匹配。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nj"><img src="../Images/3d0321c05d68283cf8edd2f2afda89f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C0WkoH0HpDHRy0imqV4Gjg.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">内容丢失的好处</p></figure><h1 id="5f75" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结束了</h1><p id="a3cf" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">就是这样！如你所见，重建车牌并不难！如果您对模型的详细实现感兴趣，请查看我们在 Github 上的回购！</p><p id="677b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lr" href="https://github.com/zzxvictor/License-super-resolution" rel="noopener ugc nofollow" target="_blank">https://github.com/zzxvictor/License-super-resolution</a></p><p id="c2d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢您阅读我的文章，并保持安全！</p></div></div>    
</body>
</html>