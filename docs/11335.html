<html>
<head>
<title>Machine Learning Basics: Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习基础:逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-basics-logistic-regression-890ef5e3a272?source=collection_archive---------16-----------------------#2020-08-06">https://towardsdatascience.com/machine-learning-basics-logistic-regression-890ef5e3a272?source=collection_archive---------16-----------------------#2020-08-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1e19" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习逻辑回归基本分类模型的算法及其实现</h2></div><p id="cb35" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在之前的<a class="ae le" rel="noopener" target="_blank" href="/machine-learning-basics-simple-linear-regression-bc83c01baa07">故事</a>中，我已经解释了各种<strong class="kk iu"> <em class="lf">回归</em> </strong>模型的实现程序。当我们继续讨论<strong class="kk iu"> <em class="lf">分类</em> </strong>时，为什么这个算法的名称仍然是回归，这难道不令人惊讶吗？让我们了解逻辑回归的机制，并通过一个例子学习建立分类模型。</p><h2 id="a136" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">逻辑回归概述</h2><p id="85ac" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">逻辑回归是一种分类模型，在因变量(输出)为二进制格式时使用，如 0(假)或 1(真)。例子包括例如预测是否有肿瘤(1)或没有肿瘤(0)以及电子邮件是否是垃圾邮件(1)或没有垃圾邮件(0)。</p><p id="93e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">逻辑函数，也称为 sigmoid 函数，最初由统计学家用来描述生态学中人口增长的特性。sigmoid 函数是一种数学函数，用于将预测值映射到概率。逻辑回归有一个 S 形曲线，可以取 0 到 1 之间的值，但永远不会精确到这些极限。它有<code class="fe me mf mg mh b">1 / (1 + e^-value)</code>的公式。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/ac479a03e25430169bdcc6f3895400ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*iUwONggpllv3-Tq2.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">Sigmoid 函数(<a class="ae le" href="https://www.javatpoint.com/logistic-regression-in-machine-learning" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="9330" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">逻辑回归是线性回归模型的扩展。让我们用一个简单的例子来理解这一点。如果我们想要分类一封电子邮件是否是垃圾邮件，如果我们应用线性回归模型，我们将只得到 0 和 1 之间的连续值，如 0.4、0.7 等。另一方面，逻辑回归通过将阈值设置为 0.5 来扩展该线性回归模型，因此如果输出值大于 0.5，则数据点将被分类为垃圾邮件，如果输出值小于 0.5，则不是垃圾邮件。</p><p id="1912" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这样就可以用逻辑回归对问题进行分类，得到准确的预测。</p><h2 id="c875" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">问题分析</h2><p id="5c1b" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">为了在实际使用中应用逻辑回归模型，让我们考虑由三列组成的 DMV 测试数据集。前两列由两个 DMV 书面测试(<strong class="kk iu"> <em class="lf"> DMV_Test_1 </em> </strong>和<strong class="kk iu"> <em class="lf"> DMV_Test_2 </em> </strong>)组成，这两个测试是自变量，最后一列由因变量<strong class="kk iu"> <em class="lf">结果</em> </strong>组成，这两个结果表示驾驶员已获得驾照(1)或未获得驾照(0)。</p><p id="e89d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，我们必须使用这些数据建立一个逻辑回归模型，以预测参加了两次 DMV 笔试的司机是否会获得驾照，并使用他们在笔试中获得的分数对结果进行分类。</p><h2 id="c597" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 1:导入库</h2><p id="4177" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">和往常一样，第一步总是包括导入库，即 NumPy、Pandas 和 Matplotlib。</p><pre class="mj mk ml mm gt mu mh mv mw aw mx bi"><span id="7fcf" class="lg lh it mh b gy my mz l na nb">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd</span></pre><h2 id="a403" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 2:导入数据集</h2><p id="319f" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，我们将从我的 GitHub 存储库中以“DMVWrittenTests.csv”的形式获取数据集。变量<strong class="kk iu"> <em class="lf"> X </em> </strong>将存储两个<strong class="kk iu"> <em class="lf"> DMV 测试</em> </strong>，变量<strong class="kk iu"> <em class="lf"> Y </em> </strong>将最终输出存储为<strong class="kk iu"> <em class="lf">结果</em></strong><strong class="kk iu"><em class="lf">。</em></strong><code class="fe me mf mg mh b">dataset.head(5)</code>用于可视化前 5 行数据。</p><pre class="mj mk ml mm gt mu mh mv mw aw mx bi"><span id="2846" class="lg lh it mh b gy my mz l na nb">dataset = pd.read_csv('<a class="ae le" href="https://raw.githubusercontent.com/mk-gurucharan/Classification/master/DMVWrittenTests.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/mk-gurucharan/Classification/master/DMVWrittenTests.csv'</a>)</span><span id="0524" class="lg lh it mh b gy nc mz l na nb">X = dataset.iloc[:, [0, 1]].values<br/>y = dataset.iloc[:, 2].values</span><span id="f7c9" class="lg lh it mh b gy nc mz l na nb">dataset.head(5)</span><span id="5fde" class="lg lh it mh b gy nc mz l na nb">&gt;&gt;<br/>DMV_Test_1   DMV_Test_2   Results<br/>34.623660    78.024693    0<br/>30.286711    43.894998    0<br/>35.847409    72.902198    0<br/>60.182599    86.308552    1<br/>79.032736    75.344376    1</span></pre><h2 id="2f4c" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 3:将数据集分为训练集和测试集</h2><p id="da31" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，我们必须将数据集分为训练集和测试集，在训练集上将训练逻辑回归模型，在测试集上将应用训练模型对结果进行分类。其中的<code class="fe me mf mg mh b">test_size=0.25</code>表示<strong class="kk iu"><em class="lf"/></strong>数据的 25%将作为<strong class="kk iu"> <em class="lf">测试集</em> </strong>保存，剩余的 75%<strong class="kk iu"><em class="lf"/></strong>将作为<strong class="kk iu"> <em class="lf">训练集</em> </strong>用于训练。</p><pre class="mj mk ml mm gt mu mh mv mw aw mx bi"><span id="e086" class="lg lh it mh b gy my mz l na nb">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)</span></pre><h2 id="97ff" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 4:特征缩放</h2><p id="5c56" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">这是一个附加步骤，用于对特定范围内的数据进行标准化。它也有助于加速计算。由于数据变化很大，我们使用此函数将数据范围限制在一个小范围内(-2，2)。例如，分数 62.0730638 被规范化为-0.21231162，分数 96.51142588 被规范化为 1.55187648。这样 X_train 和 X_test 的分数就归一化到一个更小的范围。</p><pre class="mj mk ml mm gt mu mh mv mw aw mx bi"><span id="1743" class="lg lh it mh b gy my mz l na nb">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span></pre><h2 id="42da" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 5:在训练集上训练逻辑回归模型</h2><p id="f561" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，类<code class="fe me mf mg mh b">LogisticRegression</code>被导入并分配给变量<strong class="kk iu"> <em class="lf">【分类器】</em> </strong>。<code class="fe me mf mg mh b">classifier.fit()</code>功能配有<strong class="kk iu"> X_train </strong>和<strong class="kk iu"> <em class="lf"> Y_train </em> </strong>对模型进行训练。</p><pre class="mj mk ml mm gt mu mh mv mw aw mx bi"><span id="9a53" class="lg lh it mh b gy my mz l na nb">from sklearn.linear_model import LogisticRegression<br/>classifier = LogisticRegression()<br/>classifier.fit(X_train, y_train)</span></pre><h2 id="ea7c" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 6:预测测试集结果</h2><p id="f31b" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，<code class="fe me mf mg mh b">classifier.predict()</code>函数用于预测测试集的值，这些值被存储到变量<code class="fe me mf mg mh b">y_pred.</code></p><pre class="mj mk ml mm gt mu mh mv mw aw mx bi"><span id="4fb2" class="lg lh it mh b gy my mz l na nb">y_pred = classifier.predict(X_test) <br/>y_pred</span></pre><h2 id="0d33" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 7:混淆矩阵和准确性</h2><p id="95f7" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">这是分类技术中最常用的一步。在这里，我们看到了训练模型的准确性，并绘制了混淆矩阵。</p><p id="37ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">混淆矩阵是一个表，用于显示当测试集的真实值已知时，对分类问题的正确和错误预测的数量。它的格式如下</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/74881daa5f3eb9f2b0c834afe2b00c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*aDcJceSYfH7GBxJJpzwvKA.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">来源—自己</p></figure><p id="f506" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">真实值是正确预测的次数。</p><pre class="mj mk ml mm gt mu mh mv mw aw mx bi"><span id="2086" class="lg lh it mh b gy my mz l na nb">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix(y_test, y_pred)</span><span id="91d7" class="lg lh it mh b gy nc mz l na nb">from sklearn.metrics import accuracy_score <br/>print ("Accuracy : ", accuracy_score(y_test, y_pred))<br/>cm</span><span id="10bc" class="lg lh it mh b gy nc mz l na nb">&gt;&gt;Accuracy :  0.88<br/><br/>&gt;&gt;array([[11,  0],<br/>       [ 3, 11]])</span></pre><p id="c917" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上面的混淆矩阵，我们推断，在 25 个测试集数据中，22 个被正确分类，3 个被错误分类。很好的开始，不是吗？</p><h2 id="28d3" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 8:将实际值与预测值进行比较</h2><p id="9813" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这个步骤中，创建一个 Pandas DataFrame 来比较原始测试集(<strong class="kk iu"> <em class="lf"> y_test </em> </strong>)和预测结果(<strong class="kk iu"> <em class="lf"> y_pred </em> </strong>)的分类值。</p><pre class="mj mk ml mm gt mu mh mv mw aw mx bi"><span id="39c0" class="lg lh it mh b gy my mz l na nb">df = pd.DataFrame({'Real Values':y_test, 'Predicted Values':y_pred})<br/>df</span><span id="1e61" class="lg lh it mh b gy nc mz l na nb">&gt;&gt; <br/>Real Values   Predicted Values<br/>1             1<br/>0             0<br/>0             0<br/>0             0<br/>1             1<br/>1             1<br/>1             0<br/>1             1<br/>0             0<br/>1             1<br/>0             0<br/>0             0<br/>0             0<br/>1             1<br/>1             0<br/>1             1<br/>0             0<br/>1             1<br/>1             0<br/>1             1<br/>0             0<br/>0             0<br/>1             1<br/>1             1<br/>0             0</span></pre><p id="e10f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然这种可视化可能没有回归那么有用，但从这一点上，我们可以看到，该模型能够以 88%的正确率对测试集值进行分类，如上所述。</p><h2 id="eadd" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 9:可视化结果</h2><p id="90a1" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在最后一步中，我们将逻辑回归模型的结果可视化在一个图表上，该图表与两个区域一起绘制。</p><pre class="mj mk ml mm gt mu mh mv mw aw mx bi"><span id="afc7" class="lg lh it mh b gy my mz l na nb">from matplotlib.colors import ListedColormap<br/>X_set, y_set = X_test, y_test<br/>X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),<br/>                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))<br/>plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),<br/>             alpha = 0.75, cmap = ListedColormap(('red', 'green')))<br/>plt.xlim(X1.min(), X1.max())<br/>plt.ylim(X2.min(), X2.max())<br/>for i, j in enumerate(np.unique(y_set)):<br/>    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],<br/>                c = ListedColormap(('red', 'green'))(i), label = j)<br/>plt.title('Logistic Regression')<br/>plt.xlabel('DMV_Test_1')<br/>plt.ylabel('DMV_Test_2')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/aa7d59d24d5a4b59c513d131b32b70cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*Vr3Kyz5E85M_SeWucG6bAQ.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">逻辑回归</p></figure><p id="6cde" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在该图中，值<strong class="kk iu"> <em class="lf"> 1(即，是)</em> </strong>以“<strong class="kk iu"><em class="lf"/></strong>红色绘制，值<strong class="kk iu"> <em class="lf"> 0(即，否)</em> </strong>以“<strong class="kk iu"><em class="lf"/></strong>绿色绘制。逻辑回归线将这两个区域分开。因此，具有给定的两个数据点(DMV_Test_1 和 DMV_Test_2)的任何数据都可以绘制在图上，并且根据属于哪个区域，结果(获得驾驶执照)可以分类为是或否。</p><p id="0dfb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据上面的计算，我们可以看到测试集中有三个值被错误地归类为“否”,因为它们位于线的另一端。</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="nf ng l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">逻辑回归</p></figure><h2 id="6d11" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">结论—</h2><p id="0caa" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">因此，在这个故事中，我们已经成功地建立了一个<strong class="kk iu"> <em class="lf">逻辑回归</em> </strong>模型，该模型能够预测一个人是否能够通过笔试获得驾驶执照，并可视化结果。</p><p id="e41a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我还附上了我的 GitHub 资源库的链接，你可以在那里下载这个 Google Colab 笔记本和数据文件供你参考。</p><div class="nh ni gp gr nj nk"><a href="https://github.com/mk-gurucharan/Classification" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">MK-guru charan/分类</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">这是一个由 Python 代码组成的知识库，用于构建不同类型的分类模型，以评估和…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">github.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny mo nk"/></div></div></a></div><p id="80c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还可以在下面找到该程序对其他分类模型的解释:</p><ul class=""><li id="76f8" class="nz oa it kk b kl km ko kp kr ob kv oc kz od ld oe of og oh bi translated">逻辑回归</li><li id="fe62" class="nz oa it kk b kl oi ko oj kr ok kv ol kz om ld oe of og oh bi translated">k-最近邻(KNN)分类(即将推出)</li><li id="ee02" class="nz oa it kk b kl oi ko oj kr ok kv ol kz om ld oe of og oh bi translated">支持向量机(SVM)分类(即将推出)</li><li id="ecf2" class="nz oa it kk b kl oi ko oj kr ok kv ol kz om ld oe of og oh bi translated">朴素贝叶斯分类(即将推出)</li><li id="1a1d" class="nz oa it kk b kl oi ko oj kr ok kv ol kz om ld oe of og oh bi translated">随机森林分类(即将推出)</li></ul><p id="6940" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在接下来的文章中，我们将会遇到更复杂的回归、分类和聚类模型。到那时，快乐的机器学习！</p></div></div>    
</body>
</html>