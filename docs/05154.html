<html>
<head>
<title>Face landmarks detection with MediaPipe Facemesh</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于MediaPipe人脸网格的人脸标志点检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/face-landmarks-detection-with-mediapipe-facemesh-555fa2e10b06?source=collection_archive---------11-----------------------#2020-05-03">https://towardsdatascience.com/face-landmarks-detection-with-mediapipe-facemesh-555fa2e10b06?source=collection_archive---------11-----------------------#2020-05-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f99d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用tfjs facemesh模型，我做了一个面具网络应用，你可以在上面试你最喜欢的面具</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/21233a1a497187b87d3c18616189e4f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oUr68UTNN6H_iFw08J7O9Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://pixabay.com/illustrations/hand-robot-human-machine-face-1571851/" rel="noopener ugc nofollow" target="_blank">pixabay.com</a></p></figure><p id="1d68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Tensorflow.js在3月份发布了<a class="ae ky" href="https://github.com/tensorflow/tfjs-models/tree/master/facemesh" rel="noopener ugc nofollow" target="_blank"> MediaPipe Facemesh </a>模型，这是一个轻量级的机器学习管道，可以预测<strong class="lb iu"> 486个3D面部标志</strong>来推断人脸的近似表面几何形状。</p><p id="58cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在疫情期间，我呆在家里玩这个facemesh模型。我想提醒人们戴口罩的重要性。于是我搭建了一个虚拟的口罩试衣间，它可以在一个图像或者网络摄像头流中检测到人脸地标，把选中的口罩戴在你的脸上。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/4c6852ebc38f01451692c9bc5d44e7df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VcbpknGjODmRli2txI7sTw.gif"/></div></div></figure><p id="22be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">点击下面的链接亲自尝试一下:</p><div class="lw lx gp gr ly lz"><a href="https://bensonruan.com/face-mask-for-trump-with-face-landmark-detection/" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">特朗普的面具-带有面部标志检测-本森技术</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">疾病控制和预防中心(CDC)建议美国人在公共场合戴口罩，以防止…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">bensonruan.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn ks lz"/></div></div></a></div></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="e036" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">履行</h1><p id="17b4" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">戴口罩是关心社区的一种表现。它可以防止佩戴者无意中将疾病传染给他人。虚拟面具试衣间利用了一种称为<strong class="lb iu">面部标志检测</strong>的先进技术，可以在图像或视频流中识别人脸。</p><p id="bde1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有兴趣建立一个面部标志检测应用程序，请在下面跟随我，了解我是如何实现它的。</p><h2 id="8464" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">#步骤1:包括tfjs和facemesh模型</h2><p id="09e6" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">首先，简单的在html文件的&lt; head &gt;部分包含脚本<code class="fe oe of og oh b">Tensorflow.js</code>及其<code class="fe oe of og oh b">facemesh</code>模型。</p><pre class="kj kk kl km gt oi oh oj ok aw ol bi"><span id="7582" class="ns mw it oh b gy om on l oo op">&lt;script src="<a class="ae ky" href="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core" rel="noopener ugc nofollow" target="_blank">https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core</a>"&gt;&lt;/script&gt;</span><span id="8248" class="ns mw it oh b gy oq on l oo op">&lt;script src="<a class="ae ky" href="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter" rel="noopener ugc nofollow" target="_blank">https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter</a>"&gt;&lt;/script&gt;</span><span id="e3af" class="ns mw it oh b gy oq on l oo op">&lt;script src="<a class="ae ky" href="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh" rel="noopener ugc nofollow" target="_blank">https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh</a>"&gt;&lt;/script&gt;</span></pre><p id="02b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者您可以通过npm安装它，以便在TypeScript / ES6项目中使用</p><pre class="kj kk kl km gt oi oh oj ok aw ol bi"><span id="1e95" class="ns mw it oh b gy om on l oo op">npm install @tensorflow-models/facemesh</span><span id="4539" class="ns mw it oh b gy oq on l oo op">//import in js<br/>const facemesh = require('@tensorflow-models/facemesh');</span></pre><h2 id="c003" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">#步骤2: HTML图像和视频元素</h2><p id="120b" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">接下来我们需要做的是添加html <code class="fe oe of og oh b">&lt;img&gt;</code>或<code class="fe oe of og oh b">&lt;video&gt;</code>元素作为源，这样我们就可以在图像或网络摄像头视频流上执行面部标志检测。</p><pre class="kj kk kl km gt oi oh oj ok aw ol bi"><span id="9c44" class="ns mw it oh b gy om on l oo op">&lt;img id="faces" src="images/Donal_Thrump_White_House.jpg"&gt;</span><span id="aefd" class="ns mw it oh b gy oq on l oo op">&lt;video id="webcam" autoplay playsinline width="640" height="480"&gt;&lt;/video&gt;</span></pre><p id="f07e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了让你的网络摄像头进入浏览器，我使用了npm JavaScript模块<code class="fe oe of og oh b">webcam-easy.js</code>，它提供了一个易于使用的模块，可以访问网络摄像头并拍照。要了解更多细节，请参考我之前的博客:</p><div class="lw lx gp gr ly lz"><a href="https://medium.com/swlh/how-to-access-webcam-and-take-picture-with-javascript-b9116a983d78" rel="noopener follow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">如何使用JavaScript访问网络摄像头并拍照</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">介绍网络摄像头-简易npm模块</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">medium.com</p></div></div><div class="mi l"><div class="or l mk ml mm mi mn ks lz"/></div></div></a></div><h2 id="7ea1" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">#步骤3:加载面网格模型</h2><p id="c223" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">为了执行人脸地标检测，我们首先需要通过调用<code class="fe oe of og oh b">facemesh.load(modelParams)</code>的API来加载预先训练好的Facemesh模型。FaceMesh附带了一些可选的模型参数:</p><ul class=""><li id="551f" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated"><strong class="lb iu"> maxContinuousChecks </strong>(默认值:5)</li></ul><p id="c74e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—在不运行边界框检测器的情况下要运行多少帧。仅当maxFaces &gt; 1时相关</p><ul class=""><li id="76a6" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated"><strong class="lb iu">检测置信度</strong>(默认值:0.9)</li></ul><p id="e69d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—丢弃预测的阈值</p><ul class=""><li id="c9a3" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated"><strong class="lb iu"> maxFaces </strong>(默认值:10)</li></ul><p id="429e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—输入中检测到的最大面数。应设置为性能的最小数字</p><ul class=""><li id="b3fa" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated"><strong class="lb iu"> iouThreshold </strong>(默认值:0.3)</li></ul><p id="1287" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—一个浮点值，表示在非最大值抑制中决定框是否重叠过多的阈值。必须在[0，1]之间</p><ul class=""><li id="2ed3" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated"><strong class="lb iu">得分阈值</strong>(默认值:0.75)</li></ul><p id="2abc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—根据非最大抑制中的分数决定何时移除框的阈值</p><pre class="kj kk kl km gt oi oh oj ok aw ol bi"><span id="46e7" class="ns mw it oh b gy om on l oo op">facemesh.load().then(mdl =&gt; { <br/>    model = mdl;<br/>    console.log("model loaded");<br/>    cameraFrame =  detectFaces();<br/>});</span></pre><h2 id="98ab" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">#步骤4:面部标志检测</h2><p id="9b48" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">接下来，我们通过调用<code class="fe oe of og oh b">model.estimateFaces(inputElement)</code>的API，开始通过Facemesh模型馈送图像或网络摄像头流来执行面部标志检测。它接受一个输入图像元素(可以是张量、DOM元素图像、视频或画布),并返回面部标志关键点、边界框和置信度的数组。</p><p id="bb37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oe of og oh b">estimateFaces</code> API附带了模型的几个参数:</p><ul class=""><li id="0db8" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated"><strong class="lb iu">输入</strong></li></ul><p id="1b9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> — </strong>要分类的图像。可以是张量、DOM元素图像、视频或画布。</p><ul class=""><li id="8d4c" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated"><strong class="lb iu">返回张量</strong>(默认值:假)</li></ul><p id="7b61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—是否返回张量而不是值</p><ul class=""><li id="d7cb" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated"><strong class="lb iu"> flipHorizontal </strong>(默认值:假)</li></ul><p id="40c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—是否水平翻转/镜像面部关键点。对于面向网络摄像机流的用户来说应该是真的</p><pre class="kj kk kl km gt oi oh oj ok aw ol bi"><span id="aadf" class="ns mw it oh b gy om on l oo op">let inputElement = isVideo? webcamElement : imageElement;<br/>let flipHorizontal = isVideo;<br/>model.estimateFaces(inputElement, false, flipHorizontal).then(predictions =&gt; {<br/>    console.log(predictions);<br/>    drawMask(predictions);<br/>});</span></pre><p id="d723" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预测的返回看起来像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/210e8f1a84cc9bf28396f7c4c7744eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ezO0rEimHA_AIQPLq6G9tw.jpeg"/></div></div></figure><p id="96d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于每一个面部标志关键点，它包含x，y轴的位置和深度。</p><pre class="kj kk kl km gt oi oh oj ok aw ol bi"><span id="b381" class="ns mw it oh b gy om on l oo op">0: Array(3)<br/>    0: 202.05661010742188<br/>    1: 207.98629760742188<br/>    2: -5.985757827758789<br/>    length: 3</span></pre><h2 id="39f6" class="ns mw it bd mx nt nu dn nb nv nw dp nf li nx ny nh lm nz oa nj lq ob oc nl od bi translated">#第五步:戴上面具</h2><p id="54fd" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">在上面的函数中，我们得到了468个人脸地标关键点。对于我们的面罩应用，我使用了其中的4个标志:</p><ul class=""><li id="a803" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated">额头:10</li><li id="3e91" class="os ot it lb b lc pc lf pd li pe lm pf lq pg lu ox oy oz pa bi translated">左脸颊:234</li><li id="9228" class="os ot it lb b lc pc lf pd li pe lm pf lq pg lu ox oy oz pa bi translated">下巴:152</li><li id="b4cc" class="os ot it lb b lc pc lf pd li pe lm pf lq pg lu ox oy oz pa bi translated">右脸颊:454</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/7c5a49b4275ce078bfbf84bbcef27324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gQBBRW-y-h2lTikyY4P9dg.jpeg"/></div></div></figure><p id="f440" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以使用这些关键点来计算我们应该在哪里覆盖人脸面具PNG图像。我们需要计算以下3个数字:</p><ul class=""><li id="6b96" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated">遮罩图像左上角的(x，y)位置</li><li id="e9dc" class="os ot it lb b lc pc lf pd li pe lm pf lq pg lu ox oy oz pa bi translated">遮罩图像的宽度</li><li id="f247" class="os ot it lb b lc pc lf pd li pe lm pf lq pg lu ox oy oz pa bi translated">遮罩图像的高度</li></ul><p id="dd3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是我如何得到蒙版图像:使用右脸颊标志的x轴值-左脸颊标志的x轴值</p><pre class="kj kk kl km gt oi oh oj ok aw ol bi"><span id="d619" class="ns mw it oh b gy om on l oo op">maskWidth =(dots[rightCheekIndex].left - dots[leftCheekIndex].left);</span></pre><p id="031f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于高度和左上角位置，半遮罩和全遮罩之间存在差异。</p><ul class=""><li id="65b3" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated">全面罩</li></ul><p id="e892" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—左上角:{x:额头x轴值；y:左脸颊y轴值}</p><p id="82b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—身高:[下巴y轴值]—[额头y轴值]</p><ul class=""><li id="436d" class="os ot it lb b lc ld lf lg li ou lm ov lq ow lu ox oy oz pa bi translated">半截面罩</li></ul><p id="6ab0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—左上角:{x，y:左界标的x，y轴值}</p><p id="176f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—身高:[下巴y轴值]—[左脸颊y轴值]</p><pre class="kj kk kl km gt oi oh oj ok aw ol bi"><span id="06f4" class="ns mw it oh b gy om on l oo op">switch(maskType) {<br/>  case 'full':<br/>    maskCoordinate= { top: dots[foreheadIndex].top, left: dots[leftCheekIndex].left};<br/>    maskHeight = (dots[chinIndex].top - dots[foreheadIndex].top) ;<br/>    break;<br/>  case 'half':<br/>    maskCoordinate = dots[leftCheekIndex];<br/>    maskHeight = (dots[chinIndex].top - dots[leftCheekIndex].top) ;<br/>    break;<br/>}</span></pre><p id="feff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一步是将人脸蒙版PNG图像叠加到人脸上。</p><pre class="kj kk kl km gt oi oh oj ok aw ol bi"><span id="9b15" class="ns mw it oh b gy om on l oo op">maskElement = $("&lt;img src='"+selectedMask.attr('src')+"' class='mask' /&gt;");<br/>maskElement.appendTo($("#canvas"));<br/>maskElement.css({<br/>    top: maskCoordinate.top, <br/>    left: maskCoordinate.left, <br/>    width: maskWidth ,<br/>    height: maskHeight,<br/>    position:'absolute'<br/>});</span></pre><p id="5e30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">代码就这么多了！现在选择你最喜欢的面膜，自己试一试吧！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/247888cd631de8c785c324964c97428c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*3NBkG3zv8qPpfv-036nqJA.gif"/></div></div></figure></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="01fe" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">GitHub知识库</h1><p id="ac98" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">您可以通过下面的链接下载上述演示的完整代码:</p><div class="lw lx gp gr ly lz"><a href="https://github.com/bensonruan/Face-Mask" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">面罩</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">图像和实时网络摄像头人脸检测，使用虚拟面罩保护自己免受COVID19攻击。利用张量流…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">github.c</p></div></div><div class="mi l"><div class="pj l mk ml mm mi mn ks lz"/></div></div></a></div></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="7184" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">结论</h1><p id="b339" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">Facemesh模型是为移动设备上的前置摄像头设计的，在这种情况下，视图中的人脸往往会占据画布的相对较大部分。MediaPipe Facemesh可能很难识别远处的人脸。</p><p id="3fd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于每个人都担心冠状病毒的传播，面部检测和识别系统可能是比传统的生物识别门禁系统更安全、更清洁的选择。这项技术不仅可以降低交叉感染的风险，还可以提高交通效率10倍以上，从而节省时间，减少拥堵。</p><p id="f48c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我希望每个人在疫情期间保持健康，呆在家里，让我们利用最新的机器学习技术来帮助我们对抗病毒。</p><p id="80f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。如果你喜欢这篇文章，请在脸书或推特上分享。如果你有任何问题，请在评论中告诉我。在<a class="ae ky" href="https://github.com/bensonruan/" rel="noopener ugc nofollow" target="_blank"> GitHub </a>和<a class="ae ky" href="https://www.linkedin.com/in/benson-ruan/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>关注我。</p></div></div>    
</body>
</html>