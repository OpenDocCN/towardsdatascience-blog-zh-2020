<html>
<head>
<title>Build InfoGAN From Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始构建 InfoGAN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-infogan-from-scratch-f20ee85cba03?source=collection_archive---------19-----------------------#2020-08-18">https://towardsdatascience.com/build-infogan-from-scratch-f20ee85cba03?source=collection_archive---------19-----------------------#2020-08-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d3b5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解 InfoGAN 并构建自己的 InfoGAN 网络，以生成特定功能的 MNIST 手写数字</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d75b427bd69284a279c7f110d463b568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wX4G6oDA1ut_GpC4CffJxA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自论文“<em class="kv"> InfoGAN:通过信息最大化生成对抗网络的可解释表示学习”</em></p></figure><p id="ebf1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上图中，你能看出哪些手写数字是机器合成的，哪些是人类做的吗？答案是:都是机器合成的！事实上，这张图片来自于一篇科学论文<em class="ls">“info gan:通过信息最大化生成对抗网络进行的可解释表征学习”</em>，其中作者开发了一个特殊的生成对抗网络，命名为<a class="ae lt" href="https://arxiv.org/abs/1606.03657" rel="noopener ugc nofollow" target="_blank"> InfoGAN(信息最大化生成对抗网络)</a>，并使用它来合成 MNIST 手写数字。如你所知，GANs 广泛用于合成新数据，尤其是图像。然而，普通 GANs 的一个缺点是我们无法控制 GANs 产生的图像。例如，一个被训练产生假的手写数字图像的 GAN 可能能够产生非常真实的手写数字图像，但是我们无法控制它产生哪个数字。<strong class="ky ir"> InfoGAN 解决了这个问题:网络可以学习以无监督的方式产生具有特定分类特征(如数字 0 到 9)和连续特征(如数字的旋转角度)的图像。此外，由于学习是无监督的，它能够发现隐藏在图像中的模式，并生成遵循这些隐藏模式的图像。</strong>有时候模特可以学到超乎你想象的非常有趣的模式(比如我的一个模特就学会了从 2 号过渡到 8 号。你以后会看到的！).在这本笔记本中，我将介绍 InfoGAN 如何实现对正在生成的图像的控制，以及如何从头构建一个 InfoGAN 来合成特定功能的 MNIST 手写数字，就像上面的图像一样。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="c7b7" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">InfoGAN 的结构</h1><p id="674b" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">一个正常的 GAN 有两个基本元素:一个接受随机噪声并产生假图像的发生器，以及一个接受假图像和真图像并识别图像是真是假的鉴别器。在训练过程中，如果鉴别器成功检测出生成的图像是假的，生成器就会受到“惩罚”。因此，生成器会学习产生与真实图像越来越相似的假图像来“愚弄”鉴别器。</p><p id="f169" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在 InfoGAN 中，为了控制生成的图像类型，我们需要向生成器提供随机噪声之上的附加信息，并迫使它在制作假图像时使用这些信息。我们提供的附加信息应该与我们希望图像具有的特征类型相关。例如，如果我们想产生特定的 MNIST 数字，我们需要输入一个包含从 0 到 9 的整数的分类向量；如果我们想要产生具有不同旋转角度的 MNIST 数字，我们可能想要输入在-1 到 1 之间随机选择的浮点数。</p><p id="7dd8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输入额外的信息很容易，因为我们只需要向生成器模型添加额外的输入。但是我们如何确保生成器会使用这些信息，而不是完全忽略它呢？如果我们仍然简单地基于鉴别器的响应来训练生成器，则生成器不会使用附加信息，因为附加信息不会帮助生成器创建更真实的图像(它只对生成图像的特定特征有帮助)。因此，如果生成器不使用附加信息，我们需要对它施加额外的“惩罚”。一种方法是添加一个额外的网络(通常称为辅助网络，表示为 Q ),该网络获取假图像并再现我们输入到生成器中的额外信息。这样，生成器被迫使用附加信息，就好像它不使用一样，辅助网络没有办法正确地再现附加信息，并且生成器将被“惩罚”。下图总结了 GAN(左)和 InfoGAN(右)的结构。</p><blockquote class="my mz na"><p id="5d73" class="kw kx ls ky b kz la jr lb lc ld ju le nb lg lh li nc lk ll lm nd lo lp lq lr ij bi translated">注:在本文中，理论上应该通过最大化<a class="ae lt" href="https://en.wikipedia.org/wiki/Mutual_information" rel="noopener ugc nofollow" target="_blank">互信息</a>来训练生成器。然而，互信息实际上是无法计算的。因此，作者近似互信息，并且该近似变成附加信息和再现信息的输入之间的交叉熵(即，差)。如果你对互信息以及它是如何近似的感兴趣，可以去查一下<a class="ae lt" href="https://arxiv.org/abs/1606.03657" rel="noopener ugc nofollow" target="_blank">原创论文</a>，或者是<a class="ae lt" rel="noopener" target="_blank" href="/infogan-generative-adversarial-networks-part-iii-380c0c6712cd"> Zak Jost </a>和<a class="ae lt" href="https://medium.com/@jonathan_hui/gan-cgan-infogan-using-labels-to-improve-gan-8ba4de5f9c3d" rel="noopener"> Jonathan Hui </a>两篇非常好的 medium 文章。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/6d238fc843122220d99f2ecbc98d1f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ws6L5Oflt4n9aCxxWgF6hw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">GAN(左)和 InfoGAN(右)的结构。作者图片</p></figure><h1 id="5c70" class="mb mc iq bd md me nf mg mh mi ng mk ml jw nh jx mn jz ni ka mp kc nj kd mr ms bi translated">构建 InfoGAN</h1><p id="3a3c" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">理解了 InfoGAN 的结构之后，让我们动手构建一个 InfoGAN 来生成特定于功能的 MNIST 数字！如上图所示，InfoGAN 包含三个模型:生成器(G)、鉴别器(D)和辅助模型(Q)。生成器的输入包括三个部分:大小为 62 的噪声向量、大小为 10 的分类向量(表示 10 个数字)和大小为 1 的连续向量。噪声向量通过正态分布生成，分类向量通过从 0 到 9 选取一个整数生成，连续向量通过从-1 到 1 选取一个浮点值生成。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="309c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">InfoGAN 中的发生器与普通 GAN 中的发生器具有完全相同的结构。它首先包含两个完全连接的层，以将输入形状扩展到 6272 个单元。然后，6272 个单元被改造成 128 个 7×7 层。之后，经过整形的图层通过三个转置卷积层进行处理，形成最终的 28x28 像素图像(如果你对转置卷积层不熟悉，我有一篇<a class="ae lt" rel="noopener" target="_blank" href="/understand-transposed-convolutions-and-build-your-own-transposed-convolution-layer-from-scratch-4f5d97b2967">文章解释它</a>)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="1967" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">鉴别器也与普通 GANs 中的相同。它包含两个卷积层和两个全连接层。最后一个全连接层生成一个具有“sigmoid”激活函数的输出，以表示真实图像(1)或虚假图像(0)。</p><p id="664b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">辅助模型共享来自鉴别器的所有层，除了最后一个完全连接的层，因此这两个模型被一起定义。辅助模型有两个额外的全连接层来标识附加信息。由于我们的生成器有两个额外的输入(一个分类向量和一个连续向量)，我们还需要来自辅助模型的两个不同的输出。因此，我设置了一个具有“softmax”激活函数的全连接层来标识分类输出，两个全连接层来表示高斯分布的<em class="ls">【mu】</em>(均值)和<em class="ls">【sigma】</em>(标准差):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/19172207f6cbd6584fd1bc17670c0aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*U5L9Z3liqWu_gB64ZFKuRg.png"/></div></figure><blockquote class="my mz na"><p id="15b2" class="kw kx ls ky b kz la jr lb lc ld ju le nb lg lh li nc lk ll lm nd lo lp lq lr ij bi translated">注意:由于我们的连续向量是从-1 和 1 之间的均匀分布中随机选择的浮点数，因此可以有无限多的浮点数可供选择。因此，要求辅助模型预测发电机取的确切数字是不实际的。相反，我们可以预测一个高斯分布，并要求模型最大化连续向量在分布中的可能性。</p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="414a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">定义了这三个模型之后，我们就可以构建我们的 InfoGAN 网络了！我用 Keras 做网络建设:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="c863" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我知道这是一个相当长的代码，所以让我们一步一步地消化它:</p><ul class=""><li id="9f2a" class="nn no iq ky b kz la lc ld lf np lj nq ln nr lr ns nt nu nv bi translated">InfoGAN_Continuous 是一个 Keras 模型类，应该通过给定鉴别器、生成器、辅助模型、噪声向量的大小和分类向量的类的数量来初始化。</li><li id="e11b" class="nn no iq ky b kz nw lc nx lf ny lj nz ln oa lr ns nt nu nv bi translated"><em class="ls"> compile </em>函数编译 InfoGAN_Continuous 模型(对于我使用的三个优化器都是 Adam)。</li><li id="6807" class="nn no iq ky b kz nw lc nx lf ny lj nz ln oa lr ns nt nu nv bi translated"><em class="ls"> create_gen_input </em>是我们之前定义的为发电机生成输入的函数。</li><li id="87e4" class="nn no iq ky b kz nw lc nx lf ny lj nz ln oa lr ns nt nu nv bi translated"><em class="ls"> concat_inputs </em>将三个输入向量(大小 62、大小 10、大小 1)连接成一个大小为 73 的向量。</li><li id="bad5" class="nn no iq ky b kz nw lc nx lf ny lj nz ln oa lr ns nt nu nv bi translated"><em class="ls"> train_step </em>函数定义了训练步骤。它只需要成批的真实图像。首先，通过鉴别半批真实图像和半批伪图像来训练鉴别器。鉴别器的损失是鉴别真实图像和虚假图像的损失的总和。权重通过基于损失的梯度下降算法来更新。然后，使用整批伪图像来训练生成器和辅助模型。辅助模型损失包含分类损失和连续损失。分类损失就是预测标签和输入分类向量之间的分类交叉熵；连续损失是连续矢量输入的高斯分布的负对数概率密度函数。<a class="ae lt" href="https://engineering.taboola.com/predicting-probability-distributions/" rel="noopener ugc nofollow" target="_blank">最小化负对数概率密度函数与最大化我们位于预测高斯分布</a>内的连续向量的概率是一样的，这就是我们想要的。发电机损耗包括来自鉴别器的损耗和来自辅助模型的损耗。通过这样做，生成器将学习生成具有更具体特征的更真实的图像。请注意，我们将鉴别器中的变量设置为不可训练，因为我们不想在训练生成器和辅助模型时修改鉴别器中的神经元。</li></ul><p id="5fc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，你只需要用几行代码来训练它！！！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><h1 id="b7a4" class="mb mc iq bd md me nf mg mh mi ng mk ml jw nh jx mn jz ni ka mp kc nj kd mr ms bi translated">结果</h1><p id="478a" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">现在，让我们看看我从 InfoGAN 模型中得到的一些非常有趣的结果！</p><h2 id="6f95" class="ob mc iq bd md oc od dn mh oe of dp ml lf og oh mn lj oi oj mp ln ok ol mr om bi translated">变化分类向量</h2><p id="28fb" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">首先，如果您更改分类向量输入，您可以生成不同的数字。但是，模型不会知道标签 0 对应数字 0！它只知道不同的标签对应不同的数字(相信我，我不知怎么用了一整天才意识到这一点。我一直以为我输了当喂养标签 0 为我生成数字 9)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/5bd77891764c086b1be005c161edd5b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_qOBTSlNLBpomWthoOuLCw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1e02" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，您可能需要重新排列标签:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/ed2d3f2c23d5639ddcf8e94eb5156b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XiUaJ6fnx6CCUuKvms2m9Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="903b" class="ob mc iq bd md oc od dn mh oe of dp ml lf og oh mn lj oi oj mp ln ok ol mr om bi translated">变化连续向量</h2><p id="c72a" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">改变连续向量可以产生不同形状的相同数字。例如，对于数字 1，当增加连续向量值时，数字以顺时针方向旋转。请注意，即使我们使用从-1 到 1 的值来训练模型，通过输入-1.5 和 1.5，我们仍然可以获得有意义的结果！</p><blockquote class="my mz na"><p id="5433" class="kw kx ls ky b kz la jr lb lc ld ju le nb lg lh li nc lk ll lm nd lo lp lq lr ij bi translated">请注意，标签与上面的不同。这是因为我再次训练了模型，模型总是随机地将标签与数字相关联。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/cd012ac20a2b0fe799c4d15d5883bb68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aL3hY_RvBmRbsV2Xrx4EnQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="5948" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">5 号更有趣。似乎模型试图旋转数字，但由于其形状更复杂，数字被剪切。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/a47875d17e3dcc8ba545edeadf830540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IbM_prdIV5HPdoNhJID08g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="44c0" class="ob mc iq bd md oc od dn mh oe of dp ml lf og oh mn lj oi oj mp ln ok ol mr om bi translated">增加体重以持续减肥</h2><p id="0df9" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">您可能会注意到，在将连续损耗添加到发电机总损耗和辅助设备总损耗时，我将连续损耗的比率设置为 0.1。这是为了避免混淆模型。如果连续损失与分类损失具有相似的比率(即接近 1)，则模型会将其视为确定数字类型的另一个因素。例如，下面的图像是在我使用 0.5 的比率时生成的:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/58bee734fc54ad53099adc1c125e5cf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xUT0TJJbFijs4dY6u6omuA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/2f208dd4a50fbd3dd3d98e72ccb209d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EQ2LSAEGxtCVFxkZe4H6MA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="e8c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如你所见，即使我使用相同的标签，通过改变连续向量值，数字逐渐从 2 变为 4，或者 2 变为 8！这也意味着计算机实际上可以找到数字 2 到数字 4，数字 2 到数字 8 之间的相似之处，并且知道如何从一个数字转换到另一个数字。是不是很神奇？</p><h1 id="c370" class="mb mc iq bd md me nf mg mh mi ng mk ml jw nh jx mn jz ni ka mp kc nj kd mr ms bi translated">结论</h1><p id="5c93" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">InfoGAN 是一个非常强大的 GAN，它可以以无监督的方式在图像中学习模式，并通过遵循模式产生图像。玩起来也很有趣，因为你可以通过操作输入变量来生成各种各样的图像。使用本故事中的代码，您可以构建自己的 InfoGAN，看看您能制作出多么令人惊叹的图像！</p><h1 id="0342" class="mb mc iq bd md me nf mg mh mi ng mk ml jw nh jx mn jz ni ka mp kc nj kd mr ms bi translated">参考资料:</h1><p id="43de" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">陈曦、严端、雷因·胡特夫特、约翰·舒尔曼、伊利亚·苏茨基弗和彼得·阿比尔，<a class="ae lt" href="https://arxiv.org/abs/1606.03657" rel="noopener ugc nofollow" target="_blank"> InfoGAN:通过信息最大化生成对抗网络的可解释表征学习</a> (2016)，康乃尔大学</p><div class="oo op gp gr oq or"><a href="https://engineering.taboola.com/predicting-probability-distributions/" rel="noopener  ugc nofollow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd ir gy z fp ow fr fs ox fu fw ip bi translated">使用神经网络预测概率分布</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">Shaked 是 Taboola 的算法工程师，从事推荐系统的机器学习应用。他…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">engineering.taboola.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf kp or"/></div></div></a></div><div class="oo op gp gr oq or"><a href="https://machinelearningmastery.com/how-to-develop-an-information-maximizing-generative-adversarial-network-infogan-in-keras/" rel="noopener  ugc nofollow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd ir gy z fp ow fr fs ox fu fw ip bi translated">如何开发 Keras 中的信息最大化 GAN(info GAN)——机器学习掌握</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">生成对抗网络，或 GAN，是一种用于训练深度卷积模型的架构，用于生成…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">machinelearningmastery.com</p></div></div><div class="pa l"><div class="pg l pc pd pe pa pf kp or"/></div></div></a></div></div></div>    
</body>
</html>