<html>
<head>
<title>Exploring the Trump Twitter Archive with SpaCy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 SpaCy 探索特朗普推特档案</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploring-the-trump-twitter-archive-with-spacy-fe557810717c?source=collection_archive---------56-----------------------#2020-06-08">https://towardsdatascience.com/exploring-the-trump-twitter-archive-with-spacy-fe557810717c?source=collection_archive---------56-----------------------#2020-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0076" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/exploring-trump" rel="noopener" target="_blank">探索川普</a></h2><div class=""/><div class=""><h2 id="7100" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">适合喜欢冒险的 NLP 初学者。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/59df3b2f65796279e9026f602b98f2c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c-Y1Mn0_GI8DQtq3OD6qiw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">莱昂·塞伯特在<a class="ae lh" href="https://unsplash.com/s/photos/dark-iphone?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="21cf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">在前一篇</em> <a class="ae lh" rel="noopener" target="_blank" href="/exploring-the-trump-twitter-archive-6242e5100a74"> <em class="me">的帖子</em> </a> <em class="me">中，我们着手探索</em> <a class="ae lh" href="http://www.trumptwitterarchive.com/archive" rel="noopener ugc nofollow" target="_blank"> <em class="me"> Trump Twitter 提供的数据集</em> </a> <em class="me">。这是</em> <a class="ae lh" href="https://towardsdatascience.com/tagged/exploring-trump" rel="noopener" target="_blank"> <em class="me">探索王牌</em> </a> <em class="me">系列的第二部。</em></p><p id="a332" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇文章中，我们将继续我们的旅程，但这次我们将使用 spaCy。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="8208" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于这个项目，我们将使用 pandas 进行数据操作，使用 spaCy 进行自然语言处理，使用 joblib 加快速度。</p><p id="0fa2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们从启动 Jupyter 笔记本开始吧！</p><h1 id="361b" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">家政</h1><p id="3a49" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">让我们导入熊猫并设置显示选项，这样 Jupyter 就不会截断我们的列和行。让我们也为可重复性设置一个随机种子。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="440e" class="no mn it nk b gy np nq l nr ns"># for manipulating data<br/>import pandas as pd</span><span id="33ee" class="no mn it nk b gy nt nq l nr ns"># setting the random seed for reproducibility<br/>import random<br/>random.seed(493)</span><span id="1ac0" class="no mn it nk b gy nt nq l nr ns"># to print out all the outputs<br/>from IPython.core.interactiveshell import InteractiveShell<br/>InteractiveShell.ast_node_interactivity = "all"</span><span id="ea1a" class="no mn it nk b gy nt nq l nr ns"># set display options<br/>pd.set_option('display.max_columns', None)<br/>pd.set_option('display.max_rows', None)<br/>pd.set_option('display.max_colwidth', -1)</span></pre><h1 id="ad6a" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">获取数据</h1><p id="255e" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">让我们把数据读入数据帧。如果您想继续，您可以在这里下载清理过的数据集<a class="ae lh" href="https://github.com/ecdedios/into-heart-of-darkness" rel="noopener ugc nofollow" target="_blank">和停用词文件</a>。这个数据集包含了特朗普从 2017 年 1 月 20 日上任那一刻到 2020 年 5 月 30 日的推文。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="84de" class="no mn it nk b gy np nq l nr ns">df = pd.read_csv('trump_20200530_clean.csv', parse_dates=True, index_col='datetime')</span></pre><p id="3edd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们快速看一下数据。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="3788" class="no mn it nk b gy np nq l nr ns">df.head()<br/>df.info()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/63f1cddbc13421c14ef4e4670645a7fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6wIK_eZR-qmTPTDdPPdVJQ.png"/></div></div></figure><h1 id="47af" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">使用空间</h1><p id="8f9a" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">现在让我们导入 spaCy 并开始自然语言处理。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="2b82" class="no mn it nk b gy np nq l nr ns"># for natural language processing: named entity recognition<br/>import spacy<br/>import en_core_web_sm</span></pre><p id="5ef9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将只使用 spaCy 的 ner 功能或命名实体识别，因此我们将禁用其余功能。这将节省我们大量的装货时间。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="6eae" class="no mn it nk b gy np nq l nr ns">nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'textcat'])</span></pre><p id="b43a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在让我们将停用词文件的内容加载到变量<code class="fe nv nw nx nk b">stopswords</code>中。请注意，我们将列表转换为集合，也是为了节省以后的处理时间。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="67ea" class="no mn it nk b gy np nq l nr ns">with open('twitter-stopwords — TA — Less.txt') as f:<br/> contents = f.read().split(',')<br/>stopwords = set(contents)</span></pre><p id="4b97" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我们将导入 joblib 并定义一些函数来帮助并行处理。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="fa24" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的代码中，函数<code class="fe nv nw nx nk b">preprocess_parallel</code>并行执行另一个函数<code class="fe nv nw nx nk b">process_chunks</code>来帮助提高速度。函数<code class="fe nv nw nx nk b">process_chunks</code>遍历一系列文本——在我们的例子中是<code class="fe nv nw nx nk b">df</code>数据框架的列<code class="fe nv nw nx nk b">'tweet'</code>——并检查实体是否属于 NORP、PERSON、FAC、ORG、GPE、LOC、PRODUCT 或 EVENT。如果是，那么实体被附加到<code class="fe nv nw nx nk b">'preproc_pipe'</code>并随后返回给它的调用者。<a class="oa ob ep" href="https://medium.com/u/efdb4f4a0d1b?source=post_page-----fe557810717c--------------------------------" rel="noopener" target="_blank"> Prashanth Rao </a>有一篇关于让 spaCy 超快的非常好的文章。</p><div class="oc od gp gr oe of"><a rel="noopener follow" target="_blank" href="/turbo-charge-your-spacy-nlp-pipeline-551435b664ad"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd jd gy z fp ok fr fs ol fu fw jc bi translated">加速您的空间 NLP 管道</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">使用自定义管道和 joblib 显著加快 spaCy 中文本预处理的技巧和诀窍</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">towardsdatascience.com</p></div></div><div class="oo l"><div class="op l oq or os oo ot lb of"/></div></div></a></div><p id="f233" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在让我们调用函数的主驱动程序。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="d049" class="no mn it nk b gy np nq l nr ns">df['entities'] = preprocess_parallel(df['tweet'], chunksize=1000)</span></pre><p id="8b00" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">快速执行<code class="fe nv nw nx nk b">df.head()</code>将显示我们之前添加的新列<code class="fe nv nw nx nk b">'entities'</code>，以保存在<code class="fe nv nw nx nk b">'tweet'</code>列中找到的实体。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ou"><img src="../Images/01cf51a1f6ad1914dad8f7a8739a24db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xmh-PTjmdAGivHKX3TxeJg.png"/></div></div></figure><h1 id="13bb" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">美化结果</h1><p id="c371" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">在下面的代码中，我们制作了一个名为<code class="fe nv nw nx nk b">'entities'</code>的列表，然后将其展平以便于处理。我们还将它转换成一个名为<code class="fe nv nw nx nk b">'entities_set'</code>的集合。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="10e9" class="no mn it nk b gy np nq l nr ns">entities = [entity for entity in df.entities if entity != []]<br/>entities = [item for sublist in entities for item in sublist]</span><span id="e137" class="no mn it nk b gy nt nq l nr ns">entities_set = set(entities)</span></pre><p id="2fa7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，让我们统计实体的频率，并将其添加到元组列表<code class="fe nv nw nx nk b">entities_counts</code>中。然后让我们将结果转换成数据帧<code class="fe nv nw nx nk b">df_counts</code>。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="3769" class="no mn it nk b gy np nq l nr ns">df_counts = pd.Series(entities).value_counts()[:20].to_frame().reset_index()<br/>df_counts.columns=['entity', 'count']<br/>df_counts</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/7fc5fe5ade8e43afcaab33fbe1366cbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*6oRUGHwrflcaZZeNfWFD1w.png"/></div></figure><p id="064b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于这一步，我们将重新初始化一个空列表<code class="fe nv nw nx nk b">entity_counts</code>，并手动构建一个元组列表，该列表包含一组组合的实体及其频率或计数的总和。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="ac30" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在继续之前，让我们快速浏览一下。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/63d657f5eacde4de5195734cb329c1f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*cGtSrDlIjyBZ4gdjQHd5mQ.png"/></div></figure><p id="efd4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，让我们将元组列表转换成数据帧。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="e154" class="no mn it nk b gy np nq l nr ns">df_ner = pd.DataFrame(entity_counts, columns=["entity", "count"]).sort_values('count', ascending=False).reset_index(drop=True)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/1e2251d365e9d983fbae8afad8c3a026.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*Bmy4Ov5Vs5UPrgEw7ohtWA.png"/></div></figure><p id="1645" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">就是这样！</p><p id="c77d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们已经成功地创建了特朗普总统自上任以来在推特上最常谈论的命名实体的排名。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="f56a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">感谢您的阅读！探索性数据分析使用了很多技术，我们在这篇文章中只探讨了其中的一些。我鼓励你坚持练习，并使用其他技术从数据中获得洞察力。</p><p id="1a34" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">在下一篇</em><a class="ae lh" rel="noopener" target="_blank" href="/exploring-the-trump-twitter-archive-with-pycaret-5c9e065acd6f"><em class="me"/></a><em class="me">中，我们将继续我们的旅程，进入 Trump Twitter 存档，并使用 PyCaret </em>  <em class="me">进行一些</em> <a class="ae lh" rel="noopener" target="_blank" href="/exploring-the-trump-twitter-archive-with-pycaret-5c9e065acd6f"> <em class="me">主题建模。</em></a></p><p id="395b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">如果你想了解更多关于我从懒鬼到数据科学家的旅程，请查看下面的文章:</em></p><div class="oc od gp gr oe of"><a rel="noopener follow" target="_blank" href="/from-slacker-to-data-scientist-b4f34aa10ea1"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd jd gy z fp ok fr fs ol fu fw jc bi translated">从懒鬼到数据科学家</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">我的无学位数据科学之旅。</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">towardsdatascience.com</p></div></div><div class="oo l"><div class="oy l oq or os oo ot lb of"/></div></div></a></div><p id="7e05" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">敬请期待！</em></p><p id="5643" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你可以在推特<a class="ae lh" href="https://twitter.com/ecdedios" rel="noopener ugc nofollow" target="_blank">或 LinkedIn </a>上找到我。</p><p id="f4ab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[1]龚伟的主页。(2020 年 5 月 30 日)。<em class="me">为推文停字。</em><a class="ae lh" href="https://sites.google.com/site/iamgongwei/home/sw" rel="noopener ugc nofollow" target="_blank">https://sites.google.com/site/iamgongwei/home/sw</a></p><p id="632f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[2]走向数据科学。(2020 年 5 月 30 日)。给你的空间 NLP 管道增压。<a class="ae lh" rel="noopener" target="_blank" href="/turbo-charge-your-spacy-nlp-pipeline-551435b664ad">https://towards data science . com/turbo-charge-your-spacy-NLP-pipeline-551435 b 664 ad</a></p></div></div>    
</body>
</html>