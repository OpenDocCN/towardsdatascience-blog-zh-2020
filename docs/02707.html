<html>
<head>
<title>Categorical Feature Selection via Chi-Square</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过卡方进行分类特征选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/categorical-feature-selection-via-chi-square-fc558b09de43?source=collection_archive---------7-----------------------#2020-03-16">https://towardsdatascience.com/categorical-feature-selection-via-chi-square-fc558b09de43?source=collection_archive---------7-----------------------#2020-03-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="15ea" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">分析和选择用于创建预测模型的分类特征</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ab8c232f6b0ea49eaf3770b36868b18f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MBKyvH_vsFPjL_y-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@siora18?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Siora 摄影</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="faeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们日常的数据科学工作中，我们经常会遇到分类特征。有些人会对如何处理这些特性感到困惑，特别是当我们想要创建一个预测模型，而这些模型基本上是一个接受数字的方程时；不是一个类别。</p><p id="d579" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一种方法是使用 OneHotEncoding 方法对所有 category 变量进行编码(将所有 category 类编码为数值 0 和 1，其中 0 表示不存在，1 表示存在)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/b3f53f5681a61590405d2e3b7ef2bf68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*t65XOBC6xy_GIo2sI2ey1A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一种热编码方法的例子</p></figure><p id="4dd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">许多人更喜欢这种方法，因为信息仍然存在，并且很容易理解概念。当我们拥有许多高基数的分类特征时，一个酒店编码过程后的特征数量将是巨大的。为什么我们不希望我们的训练数据集中有很多特征？这是因为维度的诅咒。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lw"><img src="../Images/27fd1ce8fd8371a6d22968a9606f76c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FpLjCKw1noWkl2OGYEnx7g.png"/></div></div></figure><p id="daa0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然增加特征可以减少我们的预测模型中的误差，但它只会减少到一定数量的特征；之后，误差会再次增大。这就是维数灾难的概念。</p><p id="ac26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有很多方法可以缓解这个问题，但我的一个方法是通过卡方独立性测试进行特征选择。</p><h1 id="03bd" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">独立性卡方检验</h1><p id="53cb" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">独立性卡方检验用于确定两个分类(名义)变量之间是否存在显著关系。这意味着独立性的卡方检验是一个假设检验，有两个假设；零假设和替代假设。假设写在下面。</p><p id="fe85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">零假设(H0): </strong>变量之间没有关系</p><p id="5a0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">替代假设(H1): </strong>变量之间有关系</p><p id="3e15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就像任何统计测试一样，我们根据我们选择的 p 值(通常是 0.05)进行测试。如果 p 值显著，我们可以拒绝零假设，并声称研究结果支持替代假设。我不会过多地讨论统计理论，因为本文的目的是展示使用卡方检验的特征选择在实际应用中是如何工作的。</p><p id="18d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，我将使用来自<a class="ae ky" href="https://www.kaggle.com/burak3ergun/loan-data-set" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的贷款数据集来解决分类问题。这里，数据集包括各种数值、序数和名义变量，如下所述(出于文章目的，我将删除所有实际上需要另一次分析的空值)。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="1ce0" class="mz ly it mv b gy na nb l nc nd">import pandas as pd<br/>loan = pd.read_csv('loan_data_set.csv')</span><span id="e679" class="mz ly it mv b gy ne nb l nc nd">#Dropping the uninformative feature<br/>loan.drop('Loan_ID')</span><span id="fa69" class="mz ly it mv b gy ne nb l nc nd">#Transform the numerical feature into categorical feature<br/>loan['Loan_Amount_Term'] = loan['Loan_Amount_Term'].astype('object')<br/>loan['Credit_History'] = loan['Credit_History'].astype('object')</span><span id="2346" class="mz ly it mv b gy ne nb l nc nd">#Dropping all the null value<br/>loan.dropna(inplace = True)</span><span id="527e" class="mz ly it mv b gy ne nb l nc nd">#Getting all the categorical columns except the target<br/>categorical_columns = loan.select_dtypes(exclude = 'number').drop('Loan_Status', axis = 1).columns</span><span id="3900" class="mz ly it mv b gy ne nb l nc nd">loan.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/530c043248e1aac8a0ff231f6f13bb4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*rFaVwYbGLx4WqaYyK76IZA.png"/></div></figure><p id="f484" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在卡方检验中，我们以交叉列表(应急)格式显示数据，每行代表一个变量的水平(组)，每列代表另一个变量的水平(组)。让我们尝试在性别和 Loan_Status 列之间创建一个交叉制表表。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="7f9d" class="mz ly it mv b gy na nb l nc nd">pd.crosstab(loan['Gender'], loan['Loan_Status'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/4297571ef3a776cbcebfac9b1d061c3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/1*-YSMqeQxG3bP9yYlDc98Iw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">交叉标签示例</p></figure><p id="dd23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们尝试使用卡方独立性检验来测试这两个特征之间的关系。幸运的是 python 库 scipy 已经包含了测试函数供我们使用。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="15f7" class="mz ly it mv b gy na nb l nc nd"># Import the function<br/>from scipy.stats import chi2_contingency</span><span id="97f8" class="mz ly it mv b gy ne nb l nc nd">#Testing the relationship<br/>chi_res = chi2_contingency(pd.crosstab(loan['Loan_Status'], loan['Gender']))</span><span id="dc5b" class="mz ly it mv b gy ne nb l nc nd">print('Chi2 Statistic: {}, p-value: {}'.format(chi_res[0], chi_res[1]))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/9cf1709cb801c4cdb61e6bcf534242f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*P_CO1tfMWDPAWpmvBfe7Og.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">独立性结果的卡方检验</p></figure><p id="21c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们选择 p 值水平为 0.05，由于 p 值测试结果大于 0.05，我们无法拒绝零假设。这意味着，基于独立性的卡方检验，性别和贷款状态特征之间没有关系。</p><p id="9033" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以尝试在所有分类特征都存在的情况下使用这个测试。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="29cb" class="mz ly it mv b gy na nb l nc nd">chi2_check = []<br/>for i in categorical_columns:<br/>    if chi2_contingency(pd.crosstab(loan['Loan_Status'], loan[i]))[1] &lt; 0.05:<br/>        chi2_check.append('Reject Null Hypothesis')<br/>    else:<br/>        chi2_check.append('Fail to Reject Null Hypothesis')</span><span id="8045" class="mz ly it mv b gy ne nb l nc nd">res = pd.DataFrame(data = [categorical_columns, chi2_check] <br/>             ).T <br/>res.columns = ['Column', 'Hypothesis']<br/>print(res)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/744a56879b0b56a269bb541cd6c531f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*Zb_woFqZVuoAZZPRzemC1Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对所有分类特征进行独立卡方检验的结果</p></figure><h1 id="8f8b" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak">事后测试</strong></h1><p id="418a" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">独立性的卡方检验是一个综合检验，这意味着它将数据作为一个整体进行检验。如果我们在一个类别中有多个类，并且卡方表大于 2×2，那么我们将无法轻易辨别哪个类的要素负责这种关系。为了确定哪个类是负责任的，我们需要一个事后测试。</p><p id="b8e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了进行多重 2×2 卡方独立性测试，我们需要对每个测试的特征进行重新分组，使其成为一个相对于其他类别的类别。为此，我们可以对每个类应用 OneHotEncoding，并针对另一个特性创建一个新的交叉表。</p><p id="9aeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，让我们试着对 Property_Area 特性做一个事后测试。首先，我们需要对 Property_Area 特性进行 OneHotEncoding。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="460d" class="mz ly it mv b gy na nb l nc nd">property_dummies = pd.get_dummies(data = loan[['Property_Area', 'Loan_Status']], columns = ['Property_Area'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/88eeab9a179aff4035b9598b5e82386e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G6m1KEC_T2nzWamqhArkJA.png"/></div></div></figure><p id="47a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们根据目标 Loan_Status 为每个 Property_Area 类创建交叉表。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="1b58" class="mz ly it mv b gy na nb l nc nd">#Example<br/>pd.crosstab(property_dummies['Loan_Status'], property_dummies['Property_Area_Rural'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/38498e585b67369eef3f88dcc0b448d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*3uOR942dYaOxPcMu8Ett7Q.png"/></div></figure><p id="9b9b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们可以对这一对进行卡方检验。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/342d33698e1ee94d44d1cc92d19180f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*V8B4edZhkgGy7HI0vjA7DA.png"/></div></figure><p id="6e6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，有一点要记住。将多个类别相互比较意味着每次测试的假阳性错误率。例如，如果我们选择 p 值水平为 0.05 的第一个测试，意味着有 5%的机会出现假阳性；如果我们有多个类，那么之后的测试会使错误增加，有 10%的机会成为假阳性，等等。每进行一次后续测试，错误率都会增加 5%。在我们上面的例子中，我们有 3 个成对的比较。这意味着我们的卡方检验会有 15%的错误率。这意味着我们测试的 p 值等于 0.15，这相当高。</p><p id="d8e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，我们可以使用 Bonferroni 调整方法来校正我们使用的 p 值。我们通过想要进行的成对比较的数量来调整我们的 P 值。公式为 p/N，其中 p=原始测试的 p 值，N=计划的成对比较的次数。例如，在我们的例子中，我们在 Property_Area 特性中有 3 个类；这意味着如果我们根据 Loan_Status 特性测试所有的类，我们将有 3 个成对的比较。我们的 P 值是 0.05/3 = 0.0167</p><p id="a492" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用调整后的 P 值，我们可以测试所有以前的重要结果，以查看哪个类负责创建重要的关系。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="b49e" class="mz ly it mv b gy na nb l nc nd">check = {}<br/>for i in res[res['Hypothesis'] == 'Reject Null Hypothesis']['Column']:<br/>    dummies = pd.get_dummies(loan[i])<br/>    bon_p_value = 0.05/loan[i].nunique()<br/>    for series in dummies:<br/>        if chi2_contingency(pd.crosstab(loan['Loan_Status'], dummies[series]))[1] &lt; bon_p_value:<br/>            check['{}-{}'.format(i, series)] = 'Reject Null Hypothesis'<br/>        else:<br/>            check['{}-{}'.format(i, series)] = 'Fail to Reject Null Hypothesis'</span><span id="e4c9" class="mz ly it mv b gy ne nb l nc nd">res_chi_ph = pd.DataFrame(data = [check.keys(), check.values()]).T<br/>res_chi_ph.columns = ['Pair', 'Hypothesis']<br/>res_chi_ph</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/9399a52ad7fc640031aab5bcc020b530.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*6HyVLMT5rO3EMpVbgnxnBw.png"/></div></figure><p id="3487" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我还包括了用于成对比较的二元特性。正如我们所看到的，许多类实际上并不重要。甚至在事后测试导致所有类之前显著的 Loan_Amount_Term 也不显著。</p><h1 id="ad53" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">预测模型</h1><p id="f617" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">这种特征选择技术的目的是看它如何影响我们的预测模型。让我们用最简单的模型；作为基准的逻辑回归。首先，我会使用所有的数据，并在初始阶段查看模型性能。在这里，我将所有分类数据视为名义数据(甚至是序数数据)。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="1afc" class="mz ly it mv b gy na nb l nc nd">#OneHotEncoding all the categorical variable except the target; Also drop_first = True to avoid multicollinearity for Logistic Regression</span><span id="3004" class="mz ly it mv b gy ne nb l nc nd">data_log = pd.get_dummies(data = loan, columns = loan.select_dtypes(exclude = 'number').drop('Loan_Status', axis =1).columns, drop_first =True)</span><span id="53d3" class="mz ly it mv b gy ne nb l nc nd">#Change the class into numerical value</span><span id="9244" class="mz ly it mv b gy ne nb l nc nd">data_log['Loan_Status'] = data_log['Loan_Status'].apply(lambda x: 0 if x == 'N' else 1)</span><span id="acf4" class="mz ly it mv b gy ne nb l nc nd">#Splitting the data into Training and Test data</span><span id="8b67" class="mz ly it mv b gy ne nb l nc nd">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(data_log.drop('Loan_Status', axis =1), data_log['Loan_Status'], test_size = 0.30, random_state = 101)</span><span id="2716" class="mz ly it mv b gy ne nb l nc nd">#Creating the prediction model<br/>from sklearn.linear_model import LogisticRegression<br/>log_model = LogisticRegression(max_iter = 1000)<br/>log_model.fit(X_train, y_train)</span><span id="1879" class="mz ly it mv b gy ne nb l nc nd">#Performance Check<br/>from sklearn.metrics import classification_report, confusion_matrix, roc_curve,auc, accuracy_score</span><span id="a0db" class="mz ly it mv b gy ne nb l nc nd">predictions = log_model.predict(X_test)<br/>print(accuracy_score(y_test, predictions))<br/>Out: 0.7708333333333334</span><span id="bfa9" class="mz ly it mv b gy ne nb l nc nd">print(classification_report(y_test,predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/0f9602bd9722f902cb20072d1ea955fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*8CB-knAo6jFKUWk4ycEc6w.png"/></div></figure><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="149a" class="mz ly it mv b gy na nb l nc nd">#Creating the ROC-AUC plot</span><span id="494b" class="mz ly it mv b gy ne nb l nc nd">preds = log_model.predict_proba(X_test)[:,1]<br/>fpr, tpr, threshold = roc_curve(y_test, preds)<br/>roc_auc = auc(fpr, tpr)<br/>plt.figure(figsize=(10,8))<br/>plt.title('Receiver Operator Characteristic')<br/>plt.plot(fpr, tpr, 'b', label = 'AUC = {}'.format(round(roc_auc, 2)))<br/>plt.legend(loc = 'lower right')<br/>plt.plot([0,1], [0,1], 'r--')<br/>plt.xlim([0,1])<br/>plt.ylim([0,1])<br/>plt.ylabel('True Positive Rate')<br/>plt.xlabel('False Positive Rate')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/49aaf6bee8da5cc2fa0434392c5ccb43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xYoCKHyXiVDgsPcCX0toYA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将所有数据作为训练数据的模型的 ROC-AUC</p></figure><p id="1be1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以上是我们使用所有数据时的模型性能，让我们将其与我们通过独立性卡方检验选择的数据进行比较。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="2a5d" class="mz ly it mv b gy na nb l nc nd">#Get the list of all the significant pairwise</span><span id="7d2c" class="mz ly it mv b gy ne nb l nc nd">significant_chi = []<br/>for i in res_chi[res_chi['Hypothesis'] == 'Reject Null Hypothesis']['Pair']:<br/>    significant_chi.append('{}_{}'.format(i.split('-')[0],i.split('-')[1]))</span><span id="f6bd" class="mz ly it mv b gy ne nb l nc nd">#Drop the data with duplicate information</span><span id="ec61" class="mz ly it mv b gy ne nb l nc nd">for i in ['Married_No', 'Credit_History_0.0']:<br/>    significant_chi.remove(i)</span><span id="bfd4" class="mz ly it mv b gy ne nb l nc nd">#Including the numerical data, as I have not analyze any of this feature</span><span id="9f68" class="mz ly it mv b gy ne nb l nc nd">for i in loan.select_dtypes('number').columns:<br/>    significant_chi.append(i)</span><span id="2439" class="mz ly it mv b gy ne nb l nc nd">print(significant_chi)</span><span id="6eac" class="mz ly it mv b gy ne nb l nc nd">Out: ['Married_Yes', 'Credit_History_1.0','Property_Area_Semiurban',<br/> 'ApplicantIncome','CoapplicantIncome', 'LoanAmount']</span></pre><p id="336d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以前，如果我们使用所有的数据，我们最终会得到 21 个独立变量。通过功能选择，我们只有 6 个功能可以使用。我不会再次进行训练测试分割，因为我想用相同的训练数据和测试数据来测试数据。让我们看看我们的模型性能如何与这些选定的功能。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="e5d4" class="mz ly it mv b gy na nb l nc nd">#Training the model only with the significant features and the numerical features</span><span id="ad38" class="mz ly it mv b gy ne nb l nc nd">log_model = LogisticRegression(max_iter = 1000)<br/>log_model.fit(X_train[significant_chi], y_train)</span><span id="bdee" class="mz ly it mv b gy ne nb l nc nd">#Metrics check<br/>predictions = log_model.predict(X_test[significant_chi])<br/>print(accuracy_score(y_test, predictions))</span><span id="4bb1" class="mz ly it mv b gy ne nb l nc nd">Out: 0.7847222222222222</span><span id="b09b" class="mz ly it mv b gy ne nb l nc nd">print(classification_report(y_test,predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/784b05bf6b78372863e3dda5b6913cac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*R62QD-WtKaZefo714ZWvrw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/c4269852ce033093e375df55ec2fc5d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FuiQ3suv-_Pw-KCIpS-j1A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有唯一选定特征的 ROC-AUC</p></figure><h1 id="4216" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak">结论</strong></h1><p id="769e" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">就度量标准而言，具有所选特征的模型比使用所有特征训练的模型表现稍好。从理论上讲，这是可能发生的，因为我们消除了数据中的所有噪声，只得到最重要的模式。虽然，我们还没有分析可能也很重要的数字数据。总的来说，我已经表明，通过卡方独立性检验，我们最终只能得到最重要的分类特征。</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h1 id="93b3" class="lx ly it bd lz ma nx mc md me ny mg mh jz nz ka mj kc oa kd ml kf ob kg mn mo bi translated">如果你喜欢我的内容，并想获得更多关于数据或作为数据科学家的日常生活的深入知识，请考虑在这里订阅我的<a class="ae ky" href="https://cornellius.substack.com/welcome" rel="noopener ugc nofollow" target="_blank">时事通讯。</a></h1><blockquote class="oc"><p id="4168" class="od oe it bd of og oh oi oj ok ol lu dk translated">如果您没有订阅为中等会员，请考虑通过<a class="ae ky" href="https://cornelliusyudhawijaya.medium.com/membership" rel="noopener">我的推荐</a>订阅。</p></blockquote></div></div>    
</body>
</html>