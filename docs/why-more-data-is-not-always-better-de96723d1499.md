# 为什么数据越多并不总是越好

> 原文：<https://towardsdatascience.com/why-more-data-is-not-always-better-de96723d1499?source=collection_archive---------23----------------------->

## 即使是“大数据”也有局限性

![](img/0841c203069425b1b4c80ff859afbe68.png)

来源:图片来自 [Pixabay](https://pixabay.com/illustrations/analytics-information-innovation-3088958/)

在过去的几年里，越来越多的人认为，数据越多，最终的分析就越好。

然而，正如人类会被太多的信息淹没一样，机器学习模型也是如此。

# 以酒店取消为例

最近，在反思我过去一年一直在做的一个副业项目时，我也在思考这个问题——用机器学习预测酒店取消预订**。**

我已经写了许多关于媒体主题的文章，很明显，在过去的一年里，酒店业的格局已经发生了根本性的变化。

随着对“居家度假”或当地假期的日益重视，这从根本上改变了任何机器学习模型在预测酒店取消时应该做出的假设。

来自 [Antonio、Almeida 和 Nunes (2016)](https://www.researchgate.net/publication/309379684_Using_Data_Science_to_Predict_Hotel_Booking_Cancellations) 的原始数据使用了来自葡萄牙酒店的数据集，这些数据集带有一个指示客户是否取消预订的响应变量，以及该客户的其他信息，如来源国、细分市场等。

在这两个数据集里，大约 55-60%的客户是国际客户。

然而，让我们假设一下这个场景。明年这个时候——酒店入住率恢复到正常水平——但绝大多数顾客都是国内顾客，这次是来自葡萄牙。为了这个例子的目的，让我们假设一个极端的场景，即 **100%** 的客户都是国内的。

这种假设将从根本上影响任何先前训练的模型准确预测取消的能力。我们举个例子。

# 使用 SVM 模型分类

SVM 模型最初用于预测酒店取消率，该模型在一个数据集(H1)上进行训练，然后使用测试集的特征数据将预测结果与该测试集(H2)进行比较。响应变量是分类变量(1 =预订被客户取消，0 =预订未被客户取消)。

以下是三种不同场景下混淆矩阵显示的结果。

## 场景 1:在 H1(完整数据集)上训练，在 H2(完整数据集)上测试

```
[[25217 21011]
 [ 8436 24666]]
              precision    recall  f1-score   support

           0       0.75      0.55      0.63     46228
           1       0.54      0.75      0.63     33102

    accuracy                           0.63     79330
   macro avg       0.64      0.65      0.63     79330
weighted avg       0.66      0.63      0.63     79330
```

总体准确率为 63%，而积极类(取消)的召回率为 75%。澄清一下，在这种情况下，召回意味着在所有取消事件中，模型正确地识别了其中的 75%。

现在，让我们来看看当我们在完整的训练集上训练 SVM 模型，但在我们的测试集中只包括葡萄牙的国内客户时会发生什么。

## 场景 2:在 H1(全数据集)上训练，在 H2(仅限国内)上测试

```
[[10879     0]
 [20081     0]]
              precision    recall  f1-score   support

           0       0.35      1.00      0.52     10879
           1       0.00      0.00      0.00     20081

    accuracy                           0.35     30960
   macro avg       0.18      0.50      0.26     30960
weighted avg       0.12      0.35      0.18     30960
```

准确率急剧下降到 35%，而取消类的召回率下降到 0%(这意味着该模型在测试集中没有预测到任何取消事件)。这种情况下的性能显然非常差。

## 场景 3:在 H1 进行培训(仅限国内)，在 H2 进行测试(仅限国内)

但是，如果训练集被修改为只包括来自葡萄牙的客户，并且模型被再次训练，那会怎么样呢？

```
[[ 8274  2605]
 [ 6240 13841]]
              precision    recall  f1-score   support

           0       0.57      0.76      0.65     10879
           1       0.84      0.69      0.76     20081

    accuracy                           0.71     30960
   macro avg       0.71      0.72      0.70     30960
weighted avg       0.75      0.71      0.72     30960
```

准确率恢复到了 71%，召回率达到了 69%。在训练集中使用更少但更相关的数据使得 SVM 模型能够更准确地预测测试集中的取消。

# 如果数据是错误的，模型结果也将是错误的

如果大部分数据与您试图预测的内容无关，那么数据越多越好。如果训练集不代表现实，即使是机器学习模型也可能被误导。

哥伦比亚商学院(Columbia Business School)的一项研究将这一点列为 2016 年美国总统选举的一个问题，在这次选举中，民调显示克林顿牢牢领先于特朗普。然而，事实证明，有许多“特朗普的秘密选民”在民调中没有被计算在内——这使结果朝着克林顿获胜的方向倾斜。

顺便说一下，我不是美国人，在这个问题上保持中立——我只是用这个例子来说明，即使是我们经常认为“大”的数据也可能包含固有的偏见，可能不代表实际发生的事情。

相反，数据的选择需要和模型的选择一样仔细，如果不是更多的话。包含某些数据与我们试图解决的问题相关吗？

回到酒店的例子，当我们的目标是预测国内客户群的取消时，在训练集中包含国际客户数据并没有增强我们的模型。

# 结论

越来越多的人希望收集所有领域的更多数据。虽然更多的数据本身并不是一件坏事，但不应该认为盲目地将更多的数据引入模型会提高模型的准确性。

相反，数据科学家仍然需要确定这些数据与手头问题的相关性的能力。从这个角度来看，模型选择变得有点事后诸葛亮。如果数据代表了您在第一个实例中试图解决的问题，那么即使是更简单的机器学习模型也会产生强大的预测结果。

非常感谢您的阅读，欢迎在下面的评论中留下任何问题或反馈。

如果您有兴趣深入了解酒店取消示例，[您可以在这里找到我的 GitHub 存储库](https://github.com/MGCodesandStats/hotel-modelling)。

*免责声明:本文是在“原样”的基础上编写的，没有担保。本文旨在提供数据科学概念的概述，不应以任何方式解释为专业建议。*