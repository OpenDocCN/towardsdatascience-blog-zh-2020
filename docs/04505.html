<html>
<head>
<title>Inpainting with AI — get back your images! [PyTorch]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用人工智能修复——找回你的图像！[PyTorch]</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/inpainting-with-ai-get-back-your-images-pytorch-a68f689128e5?source=collection_archive---------10-----------------------#2020-04-22">https://towardsdatascience.com/inpainting-with-ai-get-back-your-images-pytorch-a68f689128e5?source=collection_archive---------10-----------------------#2020-04-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="fd4e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">Python-PyTorch</h2><div class=""/><div class=""><h2 id="90e2" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用 PyTorch 和 Python 解决图像修复问题</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6c55f129ac65db379e97665452956848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IAEHWnUxvSRel9zf"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@jamesponddotco?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">詹姆斯·庞德</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="5aa8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你知道你那本布满灰尘的相册里的童年旧照片可以修复吗？是啊，那种每个人都牵着手享受生活的感觉！不相信我？看看这个—</p><blockquote class="me mf mg"><p id="fe10" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated"><strong class="lk jd">修复</strong>是一个<a class="ae lh" href="https://en.wikipedia.org/wiki/Art_conservation" rel="noopener ugc nofollow" target="_blank">保护</a>过程，在这个过程中，艺术品受损、退化或缺失的部分被填充，以呈现完整的图像。<a class="ae lh" href="https://en.wikipedia.org/wiki/Inpainting#cite_note-1" rel="noopener ugc nofollow" target="_blank">【1】</a>此工艺可应用于实物和数字艺术<a class="ae lh" href="https://en.wikipedia.org/wiki/List_of_art_media" rel="noopener ugc nofollow" target="_blank">媒介</a>，如<a class="ae lh" href="https://en.wikipedia.org/wiki/Oil_painting" rel="noopener ugc nofollow" target="_blank">油画</a>或<a class="ae lh" href="https://en.wikipedia.org/wiki/Acrylic_paint" rel="noopener ugc nofollow" target="_blank">丙烯</a>画、<a class="ae lh" href="https://en.wikipedia.org/wiki/Photographic_printing" rel="noopener ugc nofollow" target="_blank">化学摄影版画</a>、<a class="ae lh" href="https://en.wikipedia.org/wiki/Sculpture" rel="noopener ugc nofollow" target="_blank">三维雕塑</a>，或数字<a class="ae lh" href="https://en.wikipedia.org/wiki/Digital_imaging" rel="noopener ugc nofollow" target="_blank">图像</a>和<a class="ae lh" href="https://en.wikipedia.org/wiki/Digital_video" rel="noopener ugc nofollow" target="_blank">视频</a>。——<a class="ae lh" href="https://en.wikipedia.org/wiki/Inpainting" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Inpainting</a></p></blockquote><p id="59a6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">图像修复是人工智能研究的一个活跃领域，人工智能已经能够提出比大多数艺术家更好的修复结果。在本文中，我们将讨论使用神经网络的图像修复，特别是上下文编码器。本文解释并实现了在 2016 年 CVPR 上展示的关于上下文编码器的研究工作。</p><h2 id="cab3" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">上下文编码器</h2><p id="e908" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">要开始使用上下文编码器，我们必须了解什么是<em class="mh">自动编码器</em>。自动编码器在结构上由编码器、解码器和瓶颈组成。通用自动编码器旨在通过忽略图像中的噪声来减小图像尺寸。然而，自动编码器并不专用于图像，也可以扩展到其他数据。自动编码器有特定的变体来完成特定的任务。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/e8dad2cbf9db3df96e175f0fb54ae646.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*vjZNBw8uJ5kixa5ZjfejZw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">自动编码器架构</p></figure><p id="76f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在我们知道了自动编码器，我们可以将上下文编码器描述为自动编码器的一个类比。<em class="mh">上下文编码器是一个卷积神经网络，它被训练成根据图像区域的周围环境生成任意图像区域的内容</em>——即上下文编码器接收图像区域的周围数据，并试图生成适合图像区域的内容。就像我们小时候玩拼图游戏一样——只是我们不需要生成拼图块；)</p><p id="10ac" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们这里的上下文编码器由一个将图像的上下文捕获为紧凑的潜在特征表示的编码器和一个使用该表示产生缺失图像内容的解码器组成。缺少图像内容？—因为我们需要一个庞大的数据集来训练神经网络，所以我们不能只处理修复问题图像。因此，我们从正常的图像数据集中分割出部分图像，以产生修补问题，并将图像馈送到神经网络，从而在我们分割的区域产生缺失的图像内容。</p><p id="a745" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[重要的是要注意，输入到神经网络的图像有太多的缺失部分，经典的修复方法根本无法工作。]</p><h2 id="90f9" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">氮化镓的使用</h2><p id="13da" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">GANs 或生成对抗网络已被证明对图像生成极其有用。生成性对抗网络运行的基本原理是，一个生成器试图“愚弄”一个鉴别器，而一个确定的鉴别器试图得到该生成器。换句话说，两个网络分别试图最小化和最大化一个损失函数。</p><p id="4767" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">更多关于甘氏的信息在这里—<a class="ae lh" href="https://medium.com/@hmrishavbandyopadhyay/generative-adversarial-networks-hard-not-eea78c1d3c95" rel="noopener">https://medium . com/@ hmrishavbandyopadhyay/generative-adversarial-networks-hard-not-EEA 78 C1 d3c 95</a></p><h2 id="0fda" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">区域遮罩</h2><p id="c679" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">区域遮罩是我们遮挡的图像部分，以便我们可以将生成的修复问题反馈给模型。通过遮挡，我们只是将该图像区域的像素值设置为零。现在，我们有三种方法可以做到这一点—</p><ol class=""><li id="e9b6" class="nj nk it lk b ll lm lo lp lr nl lv nm lz nn md no np nq nr bi translated">中心区域:将图像数据分块的最简单方法是将中心正方形小块设置为零。虽然网络学习修复，但是我们面临泛化的问题。网络不能很好地概括，只能学习低级特征。</li><li id="21e1" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated">随机块:为了解决网络像在中心区域掩码中那样“锁定”在被掩码区域边界上的问题，掩码过程被随机化。不是选择单个正方形小块作为遮罩，而是设置多个重叠的正方形遮罩，这些遮罩占据图像的 1/4。</li><li id="60b5" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated">随机区域:然而，随机块屏蔽仍然具有网络锁定的清晰边界。为了解决这个问题，必须从图像中去除任意形状。可以从 PASCAL VOC 2012 数据集获得任意形状，将其变形并作为遮罩放置在随机图像位置。</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/d595e4c125d917edc3eb60982a1a12d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ydt5ILW1jB9S_vHIVJp3Pg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从左起— a)中心区域遮罩，b)随机块遮罩，c)随机区域遮罩[来源:<a class="ae lh" href="https://arxiv.org/abs/1604.07379" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1604.07379】</a></p></figure><p id="43c8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这里，我只实现了中心区域的蒙版方法，因为这只是让你开始用人工智能修复的一个指南。请随意尝试其他遮罩方法，并在评论中告诉我结果！</p><h2 id="9de0" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">结构</h2><p id="2888" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">现在，您应该对该模型有所了解了。让我们看看你是否正确；)</p><p id="aae9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">该模型由编码器和解码器部分组成，构建了该模型的上下文编码器部分。这部分也作为发生器产生数据，并试图欺骗鉴别器。鉴别器由卷积网络和 Sigmoid 函数组成，最终输出一个标量。</p><h2 id="8b8d" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">失败</h2><p id="9c22" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">模型的损失函数分为两部分:</p><ol class=""><li id="6056" class="nj nk it lk b ll lm lo lp lr nl lv nm lz nn md no np nq nr bi translated">重建损失-重建损失是 L2 损失函数。它有助于捕捉缺失区域的整体结构及其上下文的一致性。数学上，它被表达为—</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/de92bbf324f826281f958524e5e797d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*Ii0mGr3F4s7RK8qzFS5enw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">L2 损失</p></figure><p id="d0c6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里需要注意的是，只使用 L2 损失会给我们一个模糊的图像。因为模糊的图像减少了平均像素误差，从而使 L2 损失最小化——但不是以我们希望的方式。</p><p id="5220" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2.对抗性损失——这试图使预测“看起来”真实(记住生成器必须欺骗鉴别器！)这有助于我们克服失去 L2 会给我们带来的模糊印象。数学上，我们可以表达为—</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/9c4e21d8e536c508a8bb73ec6f53a428.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uw9IsxkcB6dtb46yVrMFfA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">对抗性损失</p></figure><p id="0e53" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里一个有趣的观察是，对抗性损失促使整个输出看起来真实，而不仅仅是丢失的部分。换句话说，对抗性网络使整个图像看起来更真实。</p><p id="11d7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总损失函数:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/42564dd726215d3b2047602fc1eff5af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*GkUTek_xpKOMKmai_sTdyA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">模型的总损失</p></figure><h2 id="9bf8" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">让我们建造它！</h2><p id="5652" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">现在，既然我们已经清楚了网络的要点，让我们开始建立模型。我将首先建立模型结构，然后进入训练和损失函数部分。该模型将在 python 上 PyTorch 库的帮助下构建。</p><p id="b8a1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们从发电机网络开始:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">网络的生成器模型-作为 python 模块实现</p></figure><p id="8610" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，鉴别器网络:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">鉴频器网络——实现为一个模块</p></figure><p id="131b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在开始训练网络吧。我们将把批量大小设置为 64，将时期数设置为 100。学习率设置为 0.0002。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">用于训练发生器和鉴别器的训练模块</p></figure><h2 id="82db" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">结果</h2><p id="a38c" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">让我们看一看我们的模型已经能够构建什么！</p><p id="aad3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第零时段的图像(噪声)</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/9081462e536cc51bbbd264798066ccf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HZTUZ5CyNne4HLpvu75-DQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">零历元图像</p></figure><p id="6ab7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第 100 个纪元的图像—</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/215e4ecbbb448ed2b0e7f130b4b06cc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RkUpNUK_TYYS2T6yWeU6eg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">第 100 个纪元的图像</p></figure><p id="08e9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们看看模型中包含了什么—</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/2c2a66cf3c30d279b3a96d60621c7ca9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UkV6tjBPZYFJ0UsNSxYjvQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">中央区域掩蔽图像</p></figure><p id="a2e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mh">那个</em>来自<em class="mh">这个</em>？耶！很酷吧。</p><p id="f40f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">实现您的模型版本。观看它重现你童年的照片——如果你足够优秀，你可能会重现人工智能修复的未来。那么，你还在等什么？</p><p id="d7a7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你的实现有任何问题，请在评论中告诉我。来帮忙了:)</p><p id="f1a3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">查看我的博客以获得更快的更新，并订阅优质内容:D</p><div class="oe of gp gr og oh"><a href="https://www.theconvolvedblog.vision" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jd gy z fp om fr fs on fu fw jc bi translated">卷积博客</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">克罗伊斯，吕底亚(小亚细亚)的国王，曾经问特尔斐的神谕，他是否应该对波斯开战…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">www.theconvolvedblog.vision</p></div></div><div class="oq l"><div class="or l os ot ou oq ov lb oh"/></div></div></a></div><p id="5c11" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mh"> Hmrishav Bandyopadhyay 是印度 Jadavpur 大学电子与电信系的二年级学生。他的兴趣在于深度学习、计算机视觉和图像处理。可以通过以下方式联系到他:hmrishavbandyopadhyay@gmail.com | |</em><a class="ae lh" href="https://hmrishavbandy.github.io" rel="noopener ugc nofollow" target="_blank"><em class="mh">https://hmrishavbandy . github . io</em></a></p></div></div>    
</body>
</html>