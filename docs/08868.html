<html>
<head>
<title>Web scraping with Python &amp; BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python和BeautifulSoup进行网页抓取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/web-scraping-with-python-beautifulsoup-40d2ce4b6252?source=collection_archive---------9-----------------------#2020-06-26">https://towardsdatascience.com/web-scraping-with-python-beautifulsoup-40d2ce4b6252?source=collection_archive---------9-----------------------#2020-06-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2f32" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何从网站中提取数据</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d54619651f0c5fb73bfb1760dc8ca7e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tiobypYjHTRkCv42AeUYOg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1076536" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>詹姆斯·奥斯本</p></figure><p id="9ee1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">网络包含大量的数据。毫无疑问，从中提取你需要的信息的能力是有用的，甚至是必要的。当然，在Kaggle这样的地方，仍然有许多数据集可供你下载，但在许多情况下，你不会找到你特定问题所需的确切数据。然而，很有可能你会在网上的某个地方找到你需要的东西，你需要从那里提取。</p><p id="6c6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">网络抓取就是这样做的过程，从网页中提取数据。在这篇文章中，我们将看到如何用python进行web抓取。对于此任务，有几个库可供您使用。这其中，这里我们就用<strong class="lb iu">美汤4 </strong>。这个库负责从HTML文档中提取数据，而不是下载数据。对于下载网页，我们需要使用另一个库:<strong class="lb iu">请求</strong>。</p><p id="d0ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，我们需要两个包:</p><ul class=""><li id="e044" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">请求—用于从给定的URL下载HTML代码</li><li id="6518" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">美丽的汤——用于从HTML字符串中提取数据</li></ul><h1 id="5681" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">安装库</h1><p id="83fd" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在，让我们从安装所需的包开始。打开终端窗口并键入:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="73b2" class="nl mk it nh b gy nm nn l no np">python -m pip install requests beautifulsoup4</span></pre><p id="0db9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">…或者，如果您使用的是conda环境:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="d71a" class="nl mk it nh b gy nm nn l no np">conda install requests beautifulsoup4</span></pre><p id="880b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，尝试运行以下命令:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="8388" class="nl mk it nh b gy nm nn l no np"><strong class="nh iu">import</strong> requests<br/><strong class="nh iu">from</strong> bs4 <strong class="nh iu">import</strong> BeautifulSoup</span></pre><p id="8be8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您没有得到任何错误，那么软件包安装成功。</p><h1 id="8f99" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">使用请求&amp;漂亮的汤来提取数据</h1><p id="0737" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">从<code class="fe nq nr ns nh b">requests</code>包中，我们将使用<code class="fe nq nr ns nh b">get()</code>函数从给定的URL下载网页:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7453" class="nl mk it nh b gy nm nn l no np">requests.get(url, params<strong class="nh iu">=None</strong>, <strong class="nh iu">**</strong>kwargs)</span></pre><p id="8d50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中参数为:</p><ul class=""><li id="82b3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> url </strong> —所需网页的url</li><li id="e4f5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> params </strong> —可选字典，查询字符串中要发送的元组或字节的列表</li><li id="fd43" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> **kwargs </strong> —请求采用的可选参数</li></ul><p id="4d40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个函数返回一个类型为<code class="fe nq nr ns nh b">requests.Response</code>的对象。在这个对象的属性和方法中，我们最感兴趣的是由目标网页的HTML字符串组成的<code class="fe nq nr ns nh b">.content</code>属性。</p><p id="26d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4c30" class="nl mk it nh b gy nm nn l no np">html_string <strong class="nh iu">=</strong> requests.get("http://www.example.com").content</span></pre><p id="d58a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们获得目标网页的HTML之后，我们必须使用<code class="fe nq nr ns nh b">BeautifulSoup()</code>构造函数来解析它，并获得一个<code class="fe nq nr ns nh b">BeautifulSoup</code>对象，我们可以用它来导航文档树并提取我们需要的数据。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c7ba" class="nl mk it nh b gy nm nn l no np">soup = BeautifulSoup(markup_string, parser)</span></pre><p id="d99b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中:</p><ul class=""><li id="6715" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">标记_字符串</strong> —我们网页的字符串</li><li id="74c7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">解析器</strong> —由要使用的解析器的名称组成的字符串；这里我们将使用python的默认解析器:“html.parser”</li></ul><p id="9fa5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，我们将第一个参数命名为“markup_string”而不是“html_string ”,因为BeautifulSoup也可以用于其他标记语言，不仅仅是html，但是我们需要指定一个适当的解析器；例如，我们可以通过将“xml”作为解析器来解析XML。</p><p id="b0bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个<code class="fe nq nr ns nh b">BeautifulSoup</code>对象有几个方法和属性，我们可以用它们在解析过的文档中导航并从中提取数据。<br/>最常用的方法是<code class="fe nq nr ns nh b">.find_all()</code>:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4421" class="nl mk it nh b gy nm nn l no np">soup.find_all(name, attrs, recursive, string, limit, <strong class="nh iu">**</strong>kwargs)</span></pre><ul class=""><li id="5272" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">名称</strong> —标记的名称；例如“a”、“div”、“img”</li><li id="e768" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> attrs </strong> —带有标签属性的字典；例如<code class="fe nq nr ns nh b">{“class”: “nav”, “href”: “#menuitem”}</code></li><li id="c99e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">递归</strong> —布尔；如果为false，则只考虑直接子代；如果为true(默认)，则在搜索中检查所有子代</li><li id="9834" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">字符串</strong> —用于在元素内容中搜索字符串</li><li id="a90f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">限制</strong> —将搜索限制在找到的元素的数量</li></ul><p id="9dd1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="75cf" class="nl mk it nh b gy nm nn l no np">soup.find_all("a", attrs<strong class="nh iu">=</strong>{"class": "nav", "data-foo": "value"})</span></pre><p id="09bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的行返回一个列表，其中包含所有具有指定属性的“a”元素。</p><p id="d404" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不能和这个方法的参数或者python的关键字混淆的HTML属性(比如“class”)可以直接作为函数参数使用，不需要放在<code class="fe nq nr ns nh b">attrs</code>字典里面。HTML <em class="nt">类的</em>属性也可以这样使用，但是不要用<code class="fe nq nr ns nh b">class=”…”</code>写<code class="fe nq nr ns nh b">class_=”…”</code>。</p><p id="d69c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="05de" class="nl mk it nh b gy nm nn l no np">soup.find_all("a", class_<strong class="nh iu">=</strong>"nav")</span></pre><p id="a434" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为这个方法是用的最多的一个，所以它有一个捷径:直接调用<code class="fe nq nr ns nh b">BeautifulSoup</code>对象和调用<code class="fe nq nr ns nh b">.find_all()</code>方法效果一样。</p><p id="fff7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0505" class="nl mk it nh b gy nm nn l no np">soup("a", class_<strong class="nh iu">=</strong>"nav")</span></pre><p id="00ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nq nr ns nh b">.find()</code>方法类似于<code class="fe nq nr ns nh b">.find_all()</code>，但它在找到第一个元素后停止搜索；将被返回的元素。它大致相当于<code class="fe nq nr ns nh b">.find_all(..., limit=1)</code>，但它不是返回一个列表，而是返回一个元素。</p><p id="5b75" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nq nr ns nh b">BeautifulSoup</code>对象的<code class="fe nq nr ns nh b">.contents</code>属性是一个包含所有子元素的列表。如果当前元素不包含嵌套的HTML元素，那么<code class="fe nq nr ns nh b">.contents[0]</code>将只是其中的文本。因此，在我们使用<code class="fe nq nr ns nh b">.find_all()</code>或<code class="fe nq nr ns nh b">.find()</code>方法获得包含我们需要的数据的元素后，我们需要做的就是访问<code class="fe nq nr ns nh b">.contents[0]</code>来获得其中的数据。</p><p id="b1e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="522f" class="nl mk it nh b gy nm nn l no np">soup <strong class="nh iu">=</strong> BeautifulSoup('''<br/>    &lt;div&gt;<br/>        &lt;span class="rating"&gt;5&lt;/span&gt;<br/>        &lt;span class="views"&gt;100&lt;/span&gt;<br/>    &lt;/div&gt;<br/>''', "html.parser")</span><span id="1176" class="nl mk it nh b gy nu nn l no np">views <strong class="nh iu">=</strong> soup.find("span", class_<strong class="nh iu">=</strong>"views").contents[0]</span></pre><p id="8d77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们需要的数据不在元素内部，而是作为属性值，那该怎么办？我们可以按如下方式访问元素的属性值:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a051" class="nl mk it nh b gy nm nn l no np">soup['attr_name']</span></pre><p id="6d70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="381a" class="nl mk it nh b gy nm nn l no np">soup <strong class="nh iu">=</strong> BeautifulSoup('''<br/>    &lt;div&gt;<br/>        &lt;img src="./img1.png"&gt;<br/>    &lt;/div&gt;<br/>''', "html.parser")</span><span id="48ec" class="nl mk it nh b gy nu nn l no np">img_source <strong class="nh iu">=</strong> soup.find("img")['src']</span></pre><h1 id="ff93" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">Web抓取示例:获得前10个linux发行版</h1><p id="cdc6" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在，让我们用上面的概念来看一个简单的web抓取示例。我们将从DistroWatch网站上抽取一个列表，列出最受欢迎的10个linux发行版。distro watch(<a class="ae ky" href="https://distrowatch.com/" rel="noopener ugc nofollow" target="_blank">https://distrowatch.com/</a>)是一个以linux发行版和运行在linux上的开源软件的新闻为特色的网站。这个网站的右边有一个最流行的linux发行版的排名。我们将从这个排名中抽取前10名。</p><p id="5bbe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将下载网页并从中构造一个漂亮的Soup对象:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="b50f" class="nl mk it nh b gy nm nn l no np"><strong class="nh iu">import</strong> requests<br/><strong class="nh iu">from</strong> bs4 <strong class="nh iu">import</strong> BeautifulSoup<br/><br/>soup <strong class="nh iu">=</strong> BeautifulSoup(<br/>    requests.get("https://distrowatch.com/").content,<br/>    "html.parser")</span></pre><p id="256a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们需要找出如何在HTML代码中识别我们想要的数据。为此，我们将使用chrome的开发工具。右键点击网页中的某个地方，然后点击“检查”，或者按“Ctrl+Shift+I”来打开chrome的开发者工具。它应该是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/902234eea6b35c3d9766db1bfb210890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PZ8HOfzD1e0wXyJxzgGlyQ.png"/></div></div></figure><p id="7eb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，如果你点击开发者工具左上角的小箭头，然后点击网页上的某个元素，你应该在开发者工具窗口中看到与该元素相关的HTML片段。之后，您可以使用您在dev tools窗口中看到的信息来告诉beautiful soup在哪里可以找到该元素。</p><p id="3d38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，我们可以看到排名被构造成一个HTML表，每个发行版名称都在一个带有类“phr2”的<strong class="lb iu"> td </strong>元素中。然后在td元素里面是一个包含我们想要提取的文本的链接(发行版的名称)。这就是我们在接下来的几行代码中要做的事情:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e725" class="nl mk it nh b gy nm nn l no np">top_ten_distros <strong class="nh iu">=</strong> []<br/>distro_tds <strong class="nh iu">=</strong> soup("td", class_<strong class="nh iu">=</strong>"phr2", limit<strong class="nh iu">=</strong>10)<br/><strong class="nh iu">for</strong> td <strong class="nh iu">in</strong> distro_tds:<br/>    top_ten_distros.append(td.find("a").contents[0])</span></pre><p id="acc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我们得到的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/a241f3868754d3c3ddbe97cdf2a1421f.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*79HkgIEgep9693jVOCOX_Q.png"/></div></figure></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="a14a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nt">我希望这些信息对你有用，感谢你的阅读！</em></p><p id="88fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章也贴在我自己的网站<a class="ae ky" href="https://www.nablasquared.com/web-scraping-with-python-beautiful-soup/" rel="noopener ugc nofollow" target="_blank">这里</a>。随便看看吧！</p></div></div>    
</body>
</html>