<html>
<head>
<title>Hadoop Distributed File System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Hadoop分布式文件系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hadoop-distributed-file-system-b09946738555?source=collection_archive---------25-----------------------#2020-05-04">https://towardsdatascience.com/hadoop-distributed-file-system-b09946738555?source=collection_archive---------25-----------------------#2020-05-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7553" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">理解HDFS及其内部运作的综合指南</h2></div><p id="cf5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从计算的角度来看，基本上有两种类型的扩展—垂直和水平。在垂直扩展中，我们只是向单台计算机/机器(也称为“节点”)添加更多RAM和存储。在水平扩展中，我们添加更多通过公共网络连接的节点，从而增加系统的整体容量。记住这一点，让我们开始吧。</p><h2 id="b6f8" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">块大小</strong></h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/0c77cd4dea5a3d197b87d1049269c753.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/0*mtdCvQf2EMWP5rME.gif"/></div><p class="mc md gj gh gi me mf bd b be z dk translated">文件分割成块</p></figure><p id="28bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当一个文件被保存在HDFS时，文件被分割成更小的块，如上面的GIF图所示。块的数量取决于“块大小”。默认是<em class="mg"> 128 MB </em>，但是可以很容易地更改/配置。</p><p id="473c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们的示例中，一个500 MB的文件需要分成128 MB的块。<em class="mg"> 500/128 = 3块128 MB和1块116 MB。</em>剩余的12 MB块空间被返回到名称节点，用于其他地方，从而防止任何浪费。任何文件系统都是如此，例如，Windows NTFS的块大小在4 KB和64 KB之间，具体取决于文件大小(最大为256 TB)。考虑到Pb及以上的大数据处理，KBs会非常低效，可想而知。这就是HDFS块大小为128 MB的原因。</p><h2 id="a1c0" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated"><strong class="ak">复制因子</strong></h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mh"><img src="../Images/ceb4ff28ef177e8126ec21b6295fa12e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n2BT4I4Nipi_m6Qk.gif"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">分身术</p></figure><p id="f778" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">HDFS是一个容错和弹性系统，这意味着它可以防止一个节点的故障影响整个系统的健康，并允许从故障中恢复。为了实现这一点，存储在HDFS中的数据会跨不同的节点自动复制。</p><p id="3d7c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">复印了多少份？这个要看“复制因子”了。默认设置为3，即1份原件和2份复印件。这也很容易配置。</p><p id="fac5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在左侧的GIF中，我们看到一个文件被分成多个块，每个块都在其他数据节点上复制以实现冗余。</p><h2 id="ca28" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">存储和复制架构</h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mm"><img src="../Images/22e04ca1bfe3e8285c27f13c64a36c29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nILZJzJ3fRZOxNBX.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">存储和复制架构</p></figure><p id="6f45" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Hadoop分布式文件系统(HDFS)遵循<em class="mg">主从</em>架构，其中“名称节点”为主节点，“数据节点”为从/工作节点。这仅仅意味着名称节点监视数据节点的健康和活动。数据节点是文件以块的形式实际存储的地方。</p><p id="b7e5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们继续上图中大小为500 MB的文件的相同示例。HDFS的默认块大小为128 MB，该文件分为4个块B1-B4。请注意，A-E是我们的数据节点。HDFS的默认复制因子为3，数据块在我们的5节点集群中复制。数据块B1(黄色)在节点A、B和D之间复制，依此类推(遵循彩色线条)。<br/>在这里，名称节点维护元数据，即关于数据的数据。<em class="mg">哪个文件的哪个块的哪个副本存储在哪个节点</em>维护在NN中—文件xyz.csv的块B1的副本2存储在节点b中。</p><p id="0f9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，一个大小为500 MB的文件由于其复制，在HDFS需要1500 MB的总存储容量。这是从终端用户的角度抽象出来的，用户只能看到存储在HDFS的一个大小为500 MB的文件。</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><p id="bf02" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在是动手的好时机:</p><div class="mu mv gp gr mw mx"><a href="https://medium.com/@prathamesh.nimkar/hdfs-commands-79dccfd721d7" rel="noopener follow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd ir gy z fp nc fr fs nd fu fw ip bi translated">HDFS命令</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">常见的HDFS命令</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">medium.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl ma mx"/></div></div></a></div></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h2 id="42fc" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">块复制算法</h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nm"><img src="../Images/b3597a37114e9f31c238a9b5810911fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aC4-XKqmj_P1egWi.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">块复制算法</p></figure><p id="24cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该算法首先在HDFS的默认配置文件夹下搜索topology.map文件。这个。映射文件包含有关其包含的所有可用机架和节点的元数据信息。在上图的示例中，我们有2个机架和10个数据节点。</p><p id="440b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦文件被划分为数据块，第一个数据块的第一个拷贝就被插入到离客户端(即终端用户)最近的机架和数据节点中。创建第一个数据块的副本，并通过TCP/IP将其移动到下一个可用机架(即机架2)上，并存储在任何可用的数据节点中。在这里创建另一个拷贝，并通过TCP/IP等将其移动到下一个可用的机架上。但是，由于我们只有2个机架，该算法会在同一机架(即机架2)上查找下一个可用的数据节点，并将第三个副本存储在那里。这种冗余性的存在使得即使一个机架出现故障，我们仍然有第二个机架来检索数据，从而实现容错和弹性。</p><h2 id="35f4" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">高可用性架构</h2><p id="8171" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">在Hadoop 1.x中，生态系统仅附带1个名称节点，导致单点故障。有一个<em class="mg">辅助或备份名称节点</em>，需要一个多小时的手动干预才能启动。随后，任何数据丢失都是不可恢复的。</p><p id="2c10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Hadoop 2.x中，提供了高可用性作为标准模式的替代方案。在标准模式下，您仍然有一个主要和次要的名称节点。在高可用性模式下，您有一个<em class="mg">主动和被动名称节点</em>。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi ns"><img src="../Images/c79c7a7e4d2fa9668143c40a76fe0617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OX6umfEckIHD3aW0.png"/></div></div></figure><p id="5e9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据节点向“活动”名称节点发送活动更新(至少每5秒一次—可配置)。此元数据实时同步到“袖手旁观”名称节点。因此，当“主动”服务器出现故障时，“袖手旁观”服务器拥有切换所需的所有元数据。</p><p id="2d30" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Zookeeper通过其故障转移控制器，通过从每个NN(每5秒，同样可配置)接收到的心跳或即时通知来监控活动和袖手旁观名称节点的健康状况。它还包含所有可用的袖手旁观名称节点的信息(Hadoop 3.x允许多个袖手旁观名称节点)。</p><p id="67aa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，建立了数据节点、名称节点和zookeeper之间的连接。当一个活动名称节点出现故障时，动物园管理员会选择一个合适的袖手旁观名称节点，并促进自动切换。袖手旁观成为新的活动名称节点，并向所有数据节点广播该选举。现在，数据节点会在几分钟内将其活动更新发送到新选出的活动名称节点。</p><h2 id="fdcb" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">什么是NameNode元数据？</h2><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/287b2ba51dd34a680e359e987cf365ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/0*bbzAVre2G-vTJ6_a.png"/></div><p class="mc md gj gh gi me mf bd b be z dk translated">NameNode元数据</p></figure><p id="408d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">名称节点(NN)元数据由两个持久性文件组成，即FsImage —名称空间和编辑日志—事务日志(插入、附加)</p><p id="9bc5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">名称空间&amp; FsImage </strong></p><p id="7d23" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在每个文件系统中，都有一个到所需文件的路径— <code class="fe nu nv nw nx b">On Windows: C:\Users\username\learning\BigData\namenode.txt and on Unix: /usr/username/learning/BigData/namenode.txt.</code> HDFS遵循Unix的命名空间方式。此命名空间存储为FsImage的一部分。文件的每个细节，即谁、什么、何时等。也存储在FsImage快照中。为了一致性、持久性和安全性，FsImage存储在磁盘上。</p><p id="787f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">编辑日志</strong></p><p id="f204" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对所有文件的任何实时更改都会记录在“编辑日志”中。这些记录在内存(RAM)中，包含更改和相应文件/数据块的每个细节。</p><p id="b25a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在HDFS启动时，从FsImage读取元数据，并将更改写入编辑日志。一旦在编辑日志中记录了当天的数据，它就会被刷新到FsImage中。这是两者协同工作的方式。</p><p id="fa2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另外，FsImage和编辑日志是不可读的。它们被二进制压缩(序列化)并存储在文件系统中。然而，出于调试目的，可以将其转换成xml格式，以便使用<a class="ae ny" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_imageviewer.html" rel="noopener ugc nofollow" target="_blank">离线图像查看器</a>读取。</p><h2 id="096c" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">NameNode元数据如何同步？</h2><p id="f601" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">正如您在“HDFS高可用性架构”图像中所想象或看到的那样，名称节点元数据是一个单点故障，因此此元数据被复制以引入冗余并实现高可用性(HA)。</p><p id="f3df" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">共享存储</strong></p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nz"><img src="../Images/69ff98a9e5008b7199a2ac0fae981bee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3cFqUL61ypQ_OMA9.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">共享存储同步</p></figure><p id="b7fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在知道存在一个活动名称节点和一个备用名称节点。<em class="mg">活动</em>中的任何更改都会实时同步到共享文件夹/存储器，即网络文件系统(NFS)。此NFS可由备用服务器<em class="mg">访问，备用服务器</em>实时下载所有相关的增量信息，以保持命名节点之间的同步。因此，如果活动<em class="mg">节点</em>出现故障，备用<em class="mg">节点</em>名称节点已经拥有所有相关信息，可以在故障切换后继续“照常工作”。这不用于生产环境。</p><p id="e17c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">仲裁日志节点(QJN) </strong></p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi oa"><img src="../Images/ad5b5a854c68adc7f2b927818095e51c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dBdEN-UoXrdtgirZ.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">QJN同步</p></figure><p id="79e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“法定人数”是指促成一项活动所需的最低人数。这个词通常用于政治；这是众议院进行议事所需的最低代表人数。</p><p id="eb34" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们使用这个概念来确定建立多数和维护元数据同步所需的最小日志节点数(也称为仲裁数)。</p><p id="88ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该图显示了三个(总是奇数)日志节点(进程线程<strong class="kh ir">而不是</strong>物理节点),它们有助于建立元数据同步。当一个活跃的神经网络收到一个变化，它把它推到大多数QJ节点(遵循单一的颜色)。备用NN实时地向多数QJ节点请求建立同步所需的元数据。</p><p id="600b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">QJN起作用的最小数目是3，法定人数/多数由以下公式确定:</p><pre class="lv lw lx ly gt ob nx oc od aw oe bi"><span id="b7fc" class="lb lc iq nx b gy of og l oh oi"><strong class="nx ir">Q = (N+1)/2</strong><br/>where N = total number of Journal Nodes <br/>For example, if we have N=5, the quorum/majority would be established by (5+1)/2 i.e. 3. The metadata change would be written to 3 journal nodes.</span></pre><p id="a1ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">QJN是元数据同步的首选生产方法，因为它也是“高度可用的”。如果任何一个QJ节点出现故障，任何剩余的节点都可以提供维护元数据同步所需的数据。因此，<em class="mg">备用服务器</em>已经拥有了所有相关信息，可以在故障转移后继续“照常工作”。</p><p id="c1bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就把我们带到了我关于HDFS及其内部运作的综合指南的结尾。</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><p id="f4e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参考资料:</p><p id="48c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[1] <a class="ae ny" href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" rel="noopener ugc nofollow" target="_blank"> HDFS架构</a> (2019)，Apache Hadoop，ASF</p><p id="0754" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] <a class="ae ny" href="https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/admin_hdfs_config.html" rel="noopener ugc nofollow" target="_blank">管理HDFS </a>，云时代</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><div class="lv lw lx ly gt mx"><a href="https://medium.com/@prathamesh.nimkar/cloudera-manager-on-google-cloud-3da9b4d64d74" rel="noopener follow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd ir gy z fp nc fr fs nd fu fw ip bi translated">Google Cloud上的Cloudera管理器</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">通过GCP上的CM 6.3.1逐步安装Hadoop生态系统</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">medium.com</p></div></div><div class="ng l"><div class="oj l ni nj nk ng nl ma mx"/></div></div></a></div><div class="mu mv gp gr mw mx"><a rel="noopener follow" target="_blank" href="/simplifying-hdfs-erasure-coding-9d9588975113"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd ir gy z fp nc fr fs nd fu fw ip bi translated">HDFS擦除编码</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">通过利用擦除编码，显著降低HDFS集群的存储开销</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">towardsdatascience.com</p></div></div><div class="ng l"><div class="ok l ni nj nk ng nl ma mx"/></div></div></a></div><div class="mu mv gp gr mw mx"><a href="https://medium.com/@prathamesh.nimkar/big-data-analytics-using-the-hadoop-ecosystem-411d629084d3" rel="noopener follow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd ir gy z fp nc fr fs nd fu fw ip bi translated">使用Hadoop生态系统的大数据分析渠道</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">登录页面</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">medium.com</p></div></div><div class="ng l"><div class="ol l ni nj nk ng nl ma mx"/></div></div></a></div></div></div>    
</body>
</html>