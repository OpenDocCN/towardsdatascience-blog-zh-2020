<html>
<head>
<title>K-Means Clustering — One rule to group them all</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">K-Means聚类——一个将它们全部分组的规则</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-clustering-one-rule-to-group-them-all-f47e00720ee7?source=collection_archive---------13-----------------------#2020-04-10">https://towardsdatascience.com/k-means-clustering-one-rule-to-group-them-all-f47e00720ee7?source=collection_archive---------13-----------------------#2020-04-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/9b684c2c8c3cb64ca06b9e9400583ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHRrU35yEtkSJ6mlsBKoYw.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><em class="kc">图片由</em> <a class="ae kd" href="https://unsplash.com/@ellenqin?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Ellen Qin </a> <em class="kc">上</em> <a class="ae kd" href="https://unsplash.com/s/photos/balls?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="dbb0" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir">本文将尝试:</strong></p><ul class=""><li id="7a9e" class="lc ld iq kg b kh ki kl km kp le kt lf kx lg lb lh li lj lk bi translated">用图形解释K-Means聚类的基础，这是一种无监督的机器学习算法</li><li id="4ee5" class="lc ld iq kg b kh ll kl lm kp ln kt lo kx lp lb lh li lj lk bi translated">讨论寻找<strong class="kg ir"> K </strong>的最佳值和团簇质心位置的方法</li></ul><p id="3bec" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir">你应该已经知道的:</strong></p><p id="f47b" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">基础数学和欧几里德几何</p><p id="8378" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在机器学习中，经常遇到的问题之一是将相似的数据分组在一起。你知道人们的收入水平，现在你想把收入水平相似的人分组在一起。你想知道谁是低收入人群，谁是高收入或非常高收入人群，你认为这有助于设计一个完美的营销策略。您有客户的购物数据，现在您想要将具有相似购物偏好的客户分组在一起，或者您是生物专业的学生，想要根据您手头的细胞数据了解哪些细胞具有相似的属性。</p><p id="bdeb" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">所有上述问题都属于称为聚类的无监督机器学习方法的范畴。虽然有许多聚类算法，但当谈到最简单的一个，奖项将授予K-Means聚类。为了理解该算法，让我们假设我们有以下数据:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/7a5b804408810132342b2f094ffa4a34.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*wwJVICO4okiYKMdEsntNPg.png"/></div></figure><p id="da57" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们有十个数据点，给出了它们的<strong class="kg ir"> x </strong>和<strong class="kg ir"> y </strong>坐标。这里我们有表示为<strong class="kg ir"> x </strong>和<strong class="kg ir"> y </strong>的变量，但在实际情况中，它们可以是不同的，比如在市场细分情况下的<strong class="kg ir">月收入</strong>或<strong class="kg ir">日支出</strong>。让我们从两个集群开始，首先将上述数据可视化，以便对其有所了解:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lv"><img src="../Images/a46dc6974f92e0847b842584d190472e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*o6h4sshQmeCYdkCk.png"/></div></div></figure><p id="8171" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">上图显示了我们手头的数据(图1)和我们可以从中得出的两个可能的聚类(图2)。请注意，在任何数据中查找集群数量(本例中为2)的决定完全是任意的&amp;基于随机猜测。稍后，您将发现这种随机猜测最初是如何引导我们找到数据中可能的最佳聚类数的。现在的问题是如何计算和分析找出这两个集群。</p><p id="fecb" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir">方法背后的逻辑</strong></p><ol class=""><li id="89ca" class="lc ld iq kg b kh ki kl km kp le kt lf kx lg lb lw li lj lk bi translated">首先，假设数据附近的任意两个随机点&amp;将它们视为两个集群的中心(质心)</li><li id="6c3a" class="lc ld iq kg b kh ll kl lm kp ln kt lo kx lp lb lw li lj lk bi translated">找出每个数据点到两个中心的距离</li><li id="c5da" class="lc ld iq kg b kh ll kl lm kp ln kt lo kx lp lb lw li lj lk bi translated">将每个数据点分配到离其最近的质心，从而形成两个聚类</li><li id="ebe2" class="lc ld iq kg b kh ll kl lm kp ln kt lo kx lp lb lw li lj lk bi translated">计算形成的两个簇的中心，并在那里移动质心。</li><li id="3387" class="lc ld iq kg b kh ll kl lm kp ln kt lo kx lp lb lw li lj lk bi translated">转到步骤1，重复该过程，直到形成的簇没有变化。</li></ol><p id="3e2d" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">让我们将上述逻辑应用于给定的数据。我们知道在笛卡尔坐标系中，两点(x1，y1)和(x2，y2)之间的距离由下式给出:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/b0a0ef28bf1c48e03b8b22a7a18f4725.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/0*rjFC_ur8G7VU7Ywd.png"/></div></figure><p id="3a7f" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">使用上面的公式，我们可以计算每个点与假设中心之间的距离。让我们假设我们的质心在C1 = (4，1)和C2 = (6，1)，从图形上来说，如下图所示:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ly"><img src="../Images/0fd3778d78911b7e237e8c23071ab903.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qU9DH_oQv4ajJiuq.png"/></div></div></figure><p id="13de" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如果我们计算每个点到两个质心的距离，结果如下表所示:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/d8c828a37334dde62ba13fa8436716b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*HmaSHWKqm6xcdQOy5o6JLw.png"/></div></figure><p id="f1c6" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">基于上述距离值，每个点将被分配到其距离最小或最近的质心，例如考虑第一个数据点，其距离<strong class="kg ir"> C1 </strong>为3.6，距离<strong class="kg ir"> C2 </strong>为5.4。由于它更靠近C1，它将被分配到这个特定的质心。对每个点做同样的操作，分配如下所示:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/2852567649e9780fc0349eacce1621c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*vm3AAq17MejFjb0xq8jszA.png"/></div></figure><p id="7265" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">从上表可以看出，每个点都根据其与假定质心的距离被分配给一个质心。分配后，通过计算分配给每个簇的点的中心来计算质心的新位置，如表中所示，计算每个坐标的平均距离。因此，质心的新位置将是C1 = (2.6，3.8)和C2 = (7.6，3.4)，如下图所示:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ma"><img src="../Images/36143df25a40da7f9bf504bee9d57db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wnzxe6qyqLNEYPLO.png"/></div></div></figure><p id="e672" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">上图显示了单个计算循环是如何使两个质心更接近数据的。如果您运行另一个计算循环，您可以看到质心不再移动，并且没有数据点将其质心从C1改变到C2，反之亦然。这是计算循环或递归停止的地方。</p><p id="c0a3" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">将数据分配给质心以使其成为聚类的上述过程被称为K均值聚类，并且<strong class="kg ir"> K </strong>的值是所形成的聚类的数量，例如在当前情况下<strong class="kg ir"> K </strong>的值将是2。</p><p id="a742" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">最后两个集群如下所示:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ma"><img src="../Images/390356873d5a6aa7f906a0a71d5e1b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oCgyr0D19RLx4WZy.png"/></div></div></figure><p id="89c2" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir">如何决定K的值？</strong></p><p id="c4d6" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们从K=2的随机坐标开始，也就是说，我们给质心的数量和位置都分配了随机值。虽然我们最终找到了计算质心最终位置的方法，但仍然存在的问题是以最佳方式拟合给定数据的<strong class="kg ir"> K </strong>的值是多少。我们也试图找到这个问题的答案，但首先让我们了解什么是成本函数。</p><p id="9da5" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir">成本函数</strong></p><p id="2b21" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">它是一个函数，给出了相对于每一个<strong class="kg ir"> K </strong>值的模型缺陷的度量。理想情况下，聚类中的每个点应该尽可能靠近其质心，或者特定聚类中的每个点与其质心之间的距离应该为零。我们将计算这个距离&amp;，将距离的平方和视为缺陷的成本或度量。我们将对每个集群重复同样的操作&amp;将找到使该成本最小化的<strong class="kg ir"> K </strong>的值。</p><p id="ba13" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">参考表-1和表-2，我们将每个点分类到一个簇中，并将这些点与它们各自质心的距离总结如下:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mb"><img src="../Images/e2429a5b61f7211ba576c110d0a3ada3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g6MQt95YyDdiu7HJ.png"/></div></div></figure><p id="6683" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">每个距离的平方相加，两个聚类的总和为15.72 + 10.76 = 26.84。这个数字是我们设K = 2时模型的成本。同样，可以针对不同的<strong class="kg ir"> K </strong>值计算成本，当成本值相对于<strong class="kg ir"> K </strong>值绘制时，我们将得到如下所示的图表:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mc"><img src="../Images/edbce58956742a347ae4344bac8b55cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mlpXAkG-c85YxQ8m.png"/></div></div></figure><p id="0564" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">根据上图，<strong class="kg ir"> K </strong>的最佳值将是显示最大偏差(用红色标记)或成本曲线形成弯头的值。虽然较高的K值进一步降低了成本，但会导致过拟合。这种找出最佳值<strong class="kg ir"> K </strong>的方法称为肘法。</p><p id="3868" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">到目前为止，我们所做的任何事情的Python代码如下所示:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi md"><img src="../Images/f615ceed29f307d0839e3d1442ead6ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jntbh6Yd8v_GsFELyL-M6A.png"/></div></div></figure><p id="5b23" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这都是关于K-均值聚类&amp;如何找出K的最佳值和质心的位置。希望你喜欢。请发表您的评论</p><p id="2386" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="kg ir">延伸阅读:</strong></p><ul class=""><li id="b53a" class="lc ld iq kg b kh ki kl km kp le kt lf kx lg lb lh li lj lk bi translated"><a class="ae kd" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">主成分分析</a></li><li id="41c1" class="lc ld iq kg b kh ll kl lm kp ln kt lo kx lp lb lh li lj lk bi translated">DBSCAN </li></ul><p id="020a" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">谢谢，</p><p id="ad13" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">过得愉快😊</p><p id="c6f2" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如果你对这篇文章有任何疑问，你可以通过LinkedIn联系我</p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><p id="cd07" class="pw-post-body-paragraph ke kf iq kg b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="ml">原载于2020年4月10日https://wildregressor.com</em><a class="ae kd" href="https://www.wildregressor.com/2020/04/k-means-clustering-one-rule-to-group.html" rel="noopener ugc nofollow" target="_blank"><em class="ml"/></a><em class="ml">。</em></p></div></div>    
</body>
</html>