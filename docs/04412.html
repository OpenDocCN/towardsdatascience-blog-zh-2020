<html>
<head>
<title>Logistic Regression — Idea and Application</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归——概念和应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-idea-and-application-a9664c0444dd?source=collection_archive---------50-----------------------#2020-04-20">https://towardsdatascience.com/logistic-regression-idea-and-application-a9664c0444dd?source=collection_archive---------50-----------------------#2020-04-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/fd92953aad3e948f9356272311b9ade1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-s6vYesODivJ_AqgIsz6mg.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">在<a class="ae kc" href="https://unsplash.com/s/photos/2-colors?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kc" href="https://unsplash.com/@aajanita?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Janita Sumeiko </a>拍摄的照片</p></figure><p id="1141" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文将尝试:</p><ul class=""><li id="9650" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">讨论逻辑回归背后的思想</li><li id="fdb9" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">通过一个例子进一步解释</li></ul><p id="bbda" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你应该已经知道的</p><ul class=""><li id="683b" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Probability_theory" rel="noopener ugc nofollow" target="_blank">基础概率论</a></li><li id="d548" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">线性回归</a></li><li id="ab70" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank">乙状结肠功能</a></li></ul><p id="4616" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">给你一个问题，根据一个人的身高预测他/她的性别。首先，给你提供 10 个人的数据，已知他们的身高和性别。要求您在这些数据中拟合一个数学模型，使您能够预测某个已知身高值但我们不知道其性别的人的性别。这类问题属于监督机器学习的分类领域。如果问题要求你进行各种分类，如真、假<strong class="kf ir">或</strong>富人、中产阶级、穷人<strong class="kf ir">或</strong>失败、成功等等，那么你就是在处理分类问题。它在机器学习中的对应部分是一个回归问题，该问题要求我们预测一个连续值，如分数= 33.4%，体重= 60 Kg 等。本文将讨论一种称为逻辑回归的分类算法。</p><p id="3105" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然有许多分类算法，它们的复杂程度各不相同，如<strong class="kf ir">线性判别分析</strong>、<strong class="kf ir">决策树</strong>、<strong class="kf ir">随机森林、</strong>等，但逻辑回归是最基本的算法，非常适合学习分类模型。让我们跳到上述问题，假设，给我们十个人的数据如下:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/51bc1ffebad2bb8b8bdbda7538b6e844.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*rXZdYQG9e-J_ppVdfLqvMg.png"/></div></figure><p id="e013" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个问题完全不同于其他数学预测问题。原因是，一方面，我们有连续的身高值，但另一方面，我们有性别的分类值。我们的数学运算知道如何处理数字，但处理分类值却是一个挑战。为了克服分类问题中的这一挑战，无论它们是通过逻辑回归还是其他算法解决的，我们总是计算与类相关的概率值。在给定的上下文中，我们将计算与男性类或女性类相关的概率。另一个类别的概率不需要明确计算，但是可以通过从一个类别中减去先前计算的类别的概率来获得。</p><p id="8142" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在给定的数据集中，我们以身高为自变量，性别为因变量。目前，如果我们假设它是一个回归问题，它将通过计算回归模型的参数得到解决，如下所示:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/a1972ad03aaa2de9593d5f63f7177a8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/0*7uDMtjXRwcDoWG0_.png"/></div></figure><p id="f15d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简而言之，我们会计算出<strong class="kf ir"> Bo </strong>和<strong class="kf ir"> B1 </strong>，问题就解决了。分类问题不能以这种方式解决。如前所述，我们无法计算性别的价值，但可以计算与特定性别阶层相关的概率。在逻辑回归中，我们从线性回归中获得灵感，并使用上面的线性模型来计算概率。我们只需要一个函数，将上述线性模型作为输入，并给我们的概率值作为输出。在数学形式中，我们应该有这样的东西:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/790fd714cfc51217835ee3c44ae4b0f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/0*B_3FTLd8P70LoGff.png"/></div></figure><p id="c630" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的模型计算了男性职业的概率，但是我们可以在这里使用这两个职业中的任何一个。等式右侧所示的函数应该满足这样的条件，即它应该接受任何实数输入，但应该只给出 0 和 1 范围内的输出，原因是显而易见的。以下所示的称为 Sigmoid 或逻辑函数的函数满足上述条件:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/fca0c1efb8493d3728c54646fa5257f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*L5n_u49FqfTWcPlq.png"/></div></figure><p id="4845" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Sigmoid 函数的定义域为<em class="lx"> -inf </em>到<em class="lx"> inf </em>，取值范围为 0 到 1，非常适合逻辑回归中的概率计算。如果我们将线性模型代入 Sigmoid 函数，我们将得到如下所示的结果:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/ba55ebc691834046a0433efa3d08cdfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*qDyqdRO9WL1E8kRR.png"/></div></figure><p id="70cf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的等式可以很容易地重新排列，以给出更简单和容易理解的形式，如下所示:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/543a1fdaae46eefd267013063852fc96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*Vq3ucty5tCr4Zq0h.png"/></div></figure><p id="7a26" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">等式的右边正是我们在线性回归模型中得到的&amp;左边是几率概率的对数，也称为 logit。因此，上述等式也可以写成:</p><p id="e7d7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> <em class="lx"> logit(性别=男性)= Bo+B1 *身高</em> </strong></p><p id="903d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是逻辑回归背后的思想。现在让我们解决给我们的问题，看看它的应用。</p><p id="8681" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用 Python 代码，使用给定的数据来训练我们的模型。我们先导入必要的模块。我们需要来自<em class="lx"> sklearn 的<em class="lx"> NumPy </em>和<em class="lx">logistics regression</em>类。</em></p><pre class="lq lr ls lt gt lz ma mb mc aw md bi"><span id="ce4b" class="me mf iq ma b gy mg mh l mi mj"><em class="lx">from sklearn.linear_model import LogisticRegression</em></span></pre><p id="9b36" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在模块被导入了，我们需要创建一个 LogisticRegression 类的实例。</p><pre class="lq lr ls lt gt lz ma mb mc aw md bi"><span id="721b" class="me mf iq ma b gy mg mh l mi mj"><em class="lx">lg = LogisticRegression(solver = ‘lbfgs’)</em></span></pre><p id="7e34" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用的求解器是<a class="ae kc" href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir"> lbfgs </strong> </a>。现在是时候创建我们将用来训练模型的数据集了。</p><pre class="lq lr ls lt gt lz ma mb mc aw md bi"><span id="ac6b" class="me mf iq ma b gy mg mh l mi mj"><em class="lx">height = np.array([[132,134,133,139,145,144,165,160,155,140]])</em></span><span id="236f" class="me mf iq ma b gy mk mh l mi mj"><em class="lx">gender = np.array([1,0,1,1,0,0,0,0,0,1])</em></span></pre><p id="a3ee" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，sklearn 只能处理数值，所以这里我们用 1 表示女性类，用 0 表示男性类。使用上述数据集，我们来训练模型:</p><pre class="lq lr ls lt gt lz ma mb mc aw md bi"><span id="c05c" class="me mf iq ma b gy mg mh l mi mj"><em class="lx">lg.fit(height.reshape(-1,1),gender.ravel())</em></span></pre><p id="5583" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦模型被训练，你将得到同样的确认信息。现在我们有了一个训练好的模型，让我们检查一下参数，截距(<strong class="kf ir"> Bo </strong>)和斜率(<strong class="kf ir"> B1 </strong>)。</p><pre class="lq lr ls lt gt lz ma mb mc aw md bi"><span id="2ea9" class="me mf iq ma b gy mg mh l mi mj"><em class="lx">lg.coef_</em></span><span id="26d6" class="me mf iq ma b gy mk mh l mi mj"><em class="lx">lg.intercept_</em></span></pre><p id="1891" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行上面的行将显示截距值 35.212 和斜率值-0.252。因此，我们的训练模型可以写成:</p><figure class="lq lr ls lt gt jr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/a235fa6819a5bc1c859ca4e56fe28a29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*5uLzgG-EDm_8vAmmOY3cmg.png"/></div></figure><p id="4411" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用上面的等式来预测任何给定身高的人的性别，或者我们可以直接使用如下所示的训练模型来查找身高= 140cm 的人的性别值:</p><pre class="lq lr ls lt gt lz ma mb mc aw md bi"><span id="7592" class="me mf iq ma b gy mg mh l mi mj"><em class="lx">lg.predict(np.array([[140]]))</em></span></pre><p id="4075" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">试试上面的代码，你会明白的。请注意，该模型实际上给出了与给定类别相关的概率值，由我们来决定概率的阈值。默认值被认为是 0.5，即所有与高于 0.5 的雄性类相关联的概率值都被认为是雄性&amp;如果小于 0.5，则雄性类的概率被认为是雌性。此外，逻辑回归中的分离边界是线性的，这可以很容易地用图形确认。</p><p id="bc3e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">进一步阅读</strong></p><p id="6d83" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.wildregressor.com/2020/03/linear-discriminant-analysis-basics.html" rel="noopener ugc nofollow" target="_blank">线性判别分析</a></p><p id="4b6e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.wildregressor.com/2020/04/decision-trees-how-to-draw-them-on-paper.html" rel="noopener ugc nofollow" target="_blank">决策树</a></p><p id="b5b0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这都在逻辑回归中。关于这篇文章的任何疑问，你可以通过<a class="ae kc" href="https://www.linkedin.com/in/tanvirhurra/" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir"> LinkedIn </strong> </a>联系我</p><p id="ea61" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">谢谢，</p><p id="ddf4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">祝你玩得愉快😊</p></div><div class="ab cl ml mm hu mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ij ik il im in"><p id="276f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lx">原载于 2020 年 4 月 20 日 https://www.wildregressor.com</em><a class="ae kc" href="https://www.wildregressor.com/2020/04/logistic-regression-idea-and-application.html" rel="noopener ugc nofollow" target="_blank"><em class="lx"/></a><em class="lx">。</em></p></div></div>    
</body>
</html>