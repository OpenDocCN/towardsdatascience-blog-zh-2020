<html>
<head>
<title>Machine Learning Basics: Polynomial Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习基础:多项式回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-basics-polynomial-regression-3f9dd30223d1?source=collection_archive---------12-----------------------#2020-07-04">https://towardsdatascience.com/machine-learning-basics-polynomial-regression-3f9dd30223d1?source=collection_archive---------12-----------------------#2020-07-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e73d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何构建多项式回归模型来预测非线性数据集的值。</h2></div><p id="3b12" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在以前的故事中，我简要介绍了线性回归，并展示了如何执行简单和多元线性回归。在本文中，我们将通过程序来建立一个基于非线性数据的多项式回归模型。</p><h2 id="758f" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">概观</h2><p id="2bf3" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在前面的线性回归示例中，当数据绘制在图表上时，因变量和自变量之间存在线性关系。因此，更适合建立线性模型来获得准确的预测。如果数据点具有以下非线性，使得线性模型由于非线性而在预测中产生错误，会怎么样？</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/e37082ae3588df0bdd7118ea5a1a43ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*-LJa0tl02jSlCTZPwZQm8A.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">非线性数据点(<a class="ae mo" href="https://hackerstreak.com/polynomial-regression-from-scratch/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="d754" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，我们必须建立一个多项式关系，它将精确地拟合给定图中的数据点。这被称为多项式回归。多项式回归曲线的公式如<code class="fe mp mq mr ms b">y=w1x+w2x²+..+b</code>所示</p><p id="0f61" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是对非线性数据拟合线性回归模型和多项式回归模型的 gif。</p><div class="md me mf mg gt ab cb"><figure class="mt mh mu mv mw mx my paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/b3f925d16cbf62ee7e099d9f8f324d8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*7w8mfB_Ecfr0x76Vc7qang.gif"/></div></figure><figure class="mt mh mu mv mw mx my paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/d98994c8619e2326c45e25f5111f993a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*d3vy9uKM4xL6WW05umcHkw.gif"/></div><p class="mk ml gj gh gi mm mn bd b be z dk nd di ne nf translated">左:线性回归，右:多项式回归(<a class="ae mo" rel="noopener" target="_blank" href="/introduction-to-linear-regression-and-polynomial-regression-f8adc96f31cb">来源</a></p></figure></div><p id="c6b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我们所看到的，线性回归总是会出错，无论它如何努力去适应数据。另一方面，多项式回归图能够更准确地将数据点拟合到直线上。</p><p id="83be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本例中，我们将完成<strong class="kk iu"> <em class="ng">多项式回归</em> </strong>的实现，其中我们将根据新员工在以前公司的职位级别，从新公司相同职位级别的工资数据中预测其工资。</p><h2 id="e60c" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">问题分析</h2><p id="7e97" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在该数据中，我们有两个独立变量，即<em class="ng">位置和</em>水平。有一个自变量，即<em class="ng">工资</em>。因此，在这个问题中，我们必须使用该数据训练一个多项式回归模型，以了解公司中员工数据的级别和工资之间的相关性，并能够根据该数据预测新员工的工资。</p><h2 id="4b33" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">步骤 1:导入库</h2><p id="9993" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在第一步中，我们将导入构建 ML 模型所需的库。导入<strong class="kk iu"> <em class="ng"> NumPy </em> </strong>库和<strong class="kk iu"> <em class="ng"> matplotlib </em> </strong>。另外，我们导入了<strong class="kk iu"> <em class="ng">熊猫</em> </strong>库进行数据分析。</p><pre class="md me mf mg gt nh ms ni nj aw nk bi"><span id="da2f" class="le lf it ms b gy nl nm l nn no">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd</span></pre><h2 id="03e7" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">步骤 2:导入数据集</h2><p id="ed5a" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在这一步中，我们将使用 pandas 来存储从我的 github 存储库中获得的数据，并使用函数"<strong class="kk iu"> pd.read_csv </strong>"将其存储为 Pandas DataFrame。</p><p id="a933" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们遍历数据集，将自变量(x)赋给列名为“<strong class="kk iu"><em class="ng"/></strong>”的第二列，将因变量(y)赋给最后一列，即要预测的“<strong class="kk iu"><em class="ng"/></strong>”工资。</p><pre class="md me mf mg gt nh ms ni nj aw nk bi"><span id="b22c" class="le lf it ms b gy nl nm l nn no">dataset = pd.read_csv('<a class="ae mo" href="https://raw.githubusercontent.com/mk-gurucharan/Regression/master/PositionSalaries_Data.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/mk-gurucharan/Regression/master/PositionSalaries_Data.csv'</a>)</span><span id="ee20" class="le lf it ms b gy np nm l nn no">X = dataset.iloc[:, 1:-1].values<br/>y = dataset.iloc[:, -1].values</span><span id="8359" class="le lf it ms b gy np nm l nn no">dataset.head(5)</span><span id="8801" class="le lf it ms b gy np nm l nn no">&gt;&gt;<br/><br/>Position           Level   Salary<br/>Business Analyst   1       45000<br/>Junior Consultant  2       50000<br/>Senior Consultant  3       60000<br/>Manager            4       80000<br/>Country Manager    5       110000</span></pre><p id="883f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用相应的。iloc 函数对数据帧进行切片，以将这些指数分配给 X 和 y。在这种情况下，<em class="ng">级别</em>被视为独立变量，并被分配给 X。要预测的因变量是最后一列(-1)，即<em class="ng">薪金</em>，它被分配给 y。我们打印 DataFrame " <strong class="kk iu">数据集</strong>，以查看我们是否为训练数据获得了正确的列。</p><h2 id="c549" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">步骤 3:在整个数据集上训练多项式回归模型</h2><p id="c128" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">我们使用的数据集只有很少的行数，因此我们训练整个数据集来构建多项式回归模型。在此"<strong class="kk iu"> <em class="ng">多项式特性</em> </strong>"功能用于指定我们将要绘制的多项式线的次数。在此，度数被设定为<strong class="kk iu"> <em class="ng"> 4 </em> </strong>。</p><p id="a906" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">独立变量 X 随后被多项式特征类拟合，并被转换为新变量<strong class="kk iu"> <em class="ng"> X_poly </em> </strong>。在这种情况下，变量 X 被转换成新的矩阵 X_Poly，该矩阵包括所有次数=4 的特征的多项式组合。</p><pre class="md me mf mg gt nh ms ni nj aw nk bi"><span id="4746" class="le lf it ms b gy nl nm l nn no">from sklearn.preprocessing import PolynomialFeatures<br/>from sklearn.linear_model import LinearRegression<br/>poly_reg = PolynomialFeatures(degree = 4)<br/>X_poly = poly_reg.fit_transform(X)<br/>lin_reg = LinearRegression()<br/>lin_reg.fit(X_poly, y)</span></pre><p id="5676" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">类"<strong class="kk iu"><em class="ng">【linear regression】</em></strong>也被导入并赋给变量<strong class="kk iu"><em class="ng">【Lin _ reg】</em></strong>，该变量与 X_poly 和 y 相匹配，用于构建模型。</p><h2 id="1c62" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">第四步:预测结果</h2><p id="569f" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在这一步中，我们将根据构建的多项式回归模型来预测值 Salary。“<strong class="kk iu"> regressor.predict </strong>”函数用于预测自变量 X_poly 的值。我们将预测值指定为 y_pred。我们现在有两个数据，y(真实值)和 y_pred(预测值)。</p><pre class="md me mf mg gt nh ms ni nj aw nk bi"><span id="86f5" class="le lf it ms b gy nl nm l nn no">y_pred = lin_reg.predict(X_poly)</span></pre><h2 id="9e26" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">步骤 5:将实际值与预测值进行比较</h2><p id="df4d" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在这一步中，我们将把 y 值打印为 Pandas DataFrame 中每个 X_test 的<strong class="kk iu"> <em class="ng">实际值</em> </strong>和 y_pred 值作为<strong class="kk iu"> <em class="ng">预测值</em> </strong>。</p><pre class="md me mf mg gt nh ms ni nj aw nk bi"><span id="cc54" class="le lf it ms b gy nl nm l nn no">df = pd.DataFrame({'Real Values':y, 'Predicted Values':y_pred})<br/>df</span><span id="12be" class="le lf it ms b gy np nm l nn no">&gt;&gt;<br/>Real Values  Predicted Values<br/>45000        53356.643357<br/>50000        31759.906760<br/>60000        58642.191142<br/>80000        94632.867133<br/>110000       121724.941725<br/>150000       143275.058275<br/>200000       184003.496504<br/>300000       289994.172494<br/>500000       528694.638695<br/>1000000      988916.083916</span></pre><p id="d156" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，该模型在拟合数据和根据职位级别预测员工工资方面做得非常好。</p><h2 id="defd" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">步骤 6: <strong class="ak">可视化多项式回归结果</strong></h2><p id="95b3" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在最后一步中，我们将可视化使用给定数据构建的多项式模型，并在图上绘制“<strong class="kk iu"><em class="ng">【y</em></strong>”和“<strong class="kk iu"> <em class="ng"> y_pred </em> </strong>”的值，并分析结果</p><pre class="md me mf mg gt nh ms ni nj aw nk bi"><span id="726a" class="le lf it ms b gy nl nm l nn no">X_grid = np.arange(min(X), max(X), 0.1)<br/>X_grid = X_grid.reshape((len(X_grid), 1))<br/>plt.scatter(X, y, color = 'red')<br/>plt.scatter(X, y_pred, color = 'green')<br/>plt.plot(X_grid, lin_reg.predict(poly_reg.fit_transform(X_grid)), color = 'black')<br/>plt.title('Polynomial Regression')<br/>plt.xlabel('Position level')<br/>plt.ylabel('Salary')<br/>plt.show()</span></pre><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/8e2a8613e9c2ea66581b68476f3824e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*ZqC8Vymxw8eZyHReHdTobQ.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">多项式回归模型</p></figure><p id="a9d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在该图中，实际值用“<strong class="kk iu"> <em class="ng">红色</em> </strong>绘制，预测值用“<strong class="kk iu"> <em class="ng">绿色</em> </strong>绘制。生成的多项式回归线以“<strong class="kk iu"> <em class="ng">黑色</em> </strong>”颜色绘制。</p><p id="a30a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我附上了我的 github 资源库的链接，你可以在那里找到 Google Colab 笔记本和数据文件供你参考。</p><div class="nr ns gp gr nt nu"><a href="https://github.com/mk-gurucharan/Regression" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">MK-guru charan/回归</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">GitHub 是超过 5000 万开发人员的家园，他们一起工作来托管和审查代码、管理项目和构建…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">github.com</p></div></div><div class="od l"><div class="oe l of og oh od oi mi nu"/></div></div></a></div><p id="6952" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">希望我已经能够清楚地解释建立多项式回归模型的程序。</p><p id="ef90" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还可以在下面找到该程序对其他回归模型的解释:</p><ul class=""><li id="dbe8" class="oj ok it kk b kl km ko kp kr ol kv om kz on ld oo op oq or bi translated"><a class="ae mo" rel="noopener" target="_blank" href="/machine-learning-basics-simple-linear-regression-bc83c01baa07">简单线性回归</a></li><li id="464d" class="oj ok it kk b kl os ko ot kr ou kv ov kz ow ld oo op oq or bi translated"><a class="ae mo" rel="noopener" target="_blank" href="/machine-learning-basics-multiple-linear-regression-9c70f796e5e3">多元线性回归</a></li><li id="6b70" class="oj ok it kk b kl os ko ot kr ou kv ov kz ow ld oo op oq or bi translated"><a class="ae mo" rel="noopener" target="_blank" href="/machine-learning-basics-polynomial-regression-3f9dd30223d1">多项式回归</a></li><li id="c4f7" class="oj ok it kk b kl os ko ot kr ou kv ov kz ow ld oo op oq or bi translated"><a class="ae mo" rel="noopener" target="_blank" href="/machine-learning-basics-support-vector-regression-660306ac5226">支持向量回归</a></li><li id="fd92" class="oj ok it kk b kl os ko ot kr ou kv ov kz ow ld oo op oq or bi translated"><a class="ae mo" rel="noopener" target="_blank" href="/machine-learning-basics-decision-tree-regression-1d73ea003fda">决策树回归</a></li><li id="72c9" class="oj ok it kk b kl os ko ot kr ou kv ov kz ow ld oo op oq or bi translated"><a class="ae mo" rel="noopener" target="_blank" href="/machine-learning-basics-random-forest-regression-be3e1e3bb91a">随机森林回归</a></li></ul><p id="ddfc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在接下来的文章中，我们将会遇到更复杂的回归、分类和聚类模型。到那时，快乐的机器学习！</p></div></div>    
</body>
</html>