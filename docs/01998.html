<html>
<head>
<title>ROC Curve Transforms the Way We Look at a Classification Problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ROC曲线改变了我们看待分类问题的方式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-simple-explanation-of-the-roc-curve-and-auc-64db32d75541?source=collection_archive---------18-----------------------#2020-02-25">https://towardsdatascience.com/a-simple-explanation-of-the-roc-curve-and-auc-64db32d75541?source=collection_archive---------18-----------------------#2020-02-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9510" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">没有一种机器学习算法能最好地解决所有问题</h2></div><p id="2d19" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">接收器工作特性(ROC) </strong>曲线是一条概率曲线，它说明了我们的二元分类在基于真阳性率和假阳性率进行分类时有多好。</p><p id="437d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">曲线下面积(AUC) </strong>是一个范围从0到1的指标。它是(ROC)曲线下的面积。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/c0f1943f562ae1c37d8c20b81fbd282f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2nd7NTEBosPakccmLVWy9A.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">ROC曲线和AUC的示例。资料来源:Huy Bui</p></figure><h2 id="7f08" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">动机</h2><p id="a977" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">为什么理解ROC曲线和AUC对数据科学家很重要？为了回答这个问题，我们来看看下面的乳腺癌数据集:</p><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="e2eb" class="lu lv it mt b gy mx my l mz na">from sklearn.datasets import load_breast_cancer<br/>import pandas as pd</span><span id="18ad" class="lu lv it mt b gy nb my l mz na">data=load_breast_cancer()<br/>columns=data.feature_names<br/>X=pd.DataFrame(data.data, columns=columns)<br/>y=pd.DataFrame(data.target, columns=['Target'])<br/>df=pd.concat([y,X],axis=1)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nc"><img src="../Images/e71a702f59711431339f725c38276907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mGR3O12P_hUpW9titwzcNQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">乳腺癌数据集:591个观察和30个特征。资料来源:Huy Bui</p></figure><p id="aa48" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当处理分类问题时，应该考虑准确性的折衷。如果医院使用这些数据来检测乳腺癌，模型应该强调从患者身上检测癌症的能力。该模型还需要小心翼翼地将可能被错误标记为癌症的健康患者的数量降至最低，因为癌症治疗的副作用可能会很严重。</p><p id="be11" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该数据集的目标是恶性(1)和良性(0)。让我们看看下面的直方图:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nd"><img src="../Images/fdeefbbfb01a8f0bc6cc7d9f0c2aef48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G1cXqO-iqHNdLwCCeSj7WA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">良性和恶性的分布。资料来源:Huy Bui</p></figure><p id="49d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通常，对于这种类型的问题，数据集更加不平衡。根据美国乳腺癌统计数据，12%的美国女性在其一生中将发展为浸润性乳腺癌。然而，这只是出于教育目的，我们可以忽略数据集的现实方面。</p><p id="992a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如上所述，我们需要在<strong class="kk iu">召回</strong>和<strong class="kk iu">假阳性率</strong>之间找到一个好的平衡。你可能会问为什么是假阳性率而不是精确度。提醒一下:</p><p id="f13d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">回忆:</strong>也叫真阳性率(TPR)。TPR是正确的癌症预测与癌症病例总数之间的比率。从数学上来说，<strong class="kk iu"> TPR=TP/(TP+FN) </strong>其中FN是那些被错误归类为良性的。</p><p id="c4d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">精度</strong>:所有正确癌症与预测癌症总数之比。<strong class="kk iu">精度</strong> = <strong class="kk iu"> TP/(TP+FP) </strong></p><p id="5257" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">假阳性率:</strong> <strong class="kk iu"> FPR=FP / (TN+FP) </strong></p><p id="27d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据数学公式，我们可以看出精度和FPR之间的区别。Precision关注模型检测癌症的能力。相反，FPR关注的是癌症检测的失败率。如果你想了解更多，这里有一个关于精确召回(PR)和FPR召回(ROC)的长时间讨论。</p><p id="85bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简而言之，只有当正面类比负面类有趣得多，并且正面/负面比率很小(严重不平衡)时，我们才应该使用精确回忆。然而，在这种情况下，良性肿瘤约占恶性肿瘤的4/7，这表明数据只是轻度不平衡。正如我们上面讨论的，错误分类的癌症可能会导致不良后果。因此，在这里使用ROC曲线是合理的。</p><p id="6011" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:<em class="nf">精确召回的方法与ROC曲线非常相似，你可以在这里找到它的文档。</em></p><h2 id="9a76" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">受试者工作特征曲线</h2><p id="85ef" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们将要使用的模型是<strong class="kk iu">逻辑回归</strong>。通常，当我们进行分类时，输出已经被某个阈值四舍五入。ROC曲线使用不同的阈值来绘制TPR-FPR之间的关系。因为我们想要研究TPR、FPR和阈值之间的关系，所以让我们在舍入之前先看看逻辑回归输出。</p><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="c429" class="lu lv it mt b gy mx my l mz na">from sklearn.linear_model import LogisticRegression</span><span id="b988" class="lu lv it mt b gy nb my l mz na">logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')<br/>logreg.fit(X, y.values.flatten())<br/>prediction=logreg.decision_function(X) #Values before the ouput</span><span id="4346" class="lu lv it mt b gy nb my l mz na">#Define positive and negative<br/>cancer_index=y[y.Target==1].index<br/>no_cancer_index=y[y.Target==0].index<br/>cancer_prob=prediction[cancer_index]<br/>no_cancer_prob=prediction[no_cancer_index]</span><span id="bbb6" class="lu lv it mt b gy nb my l mz na">#Histogram<br/>n_bins = 20<br/>fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)<br/>axs[0].hist(cancer_prob, bins=n_bins)<br/>axs[1].hist(no_cancer_prob, bins=n_bins)<br/>plt.show()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ng"><img src="../Images/6e1d3b5cfef742ad1f1e95ceebb71392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wqd5LrWqrAjBkE1skUiHcw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">在做出边界决定之前，评估良性和恶性之间的频率。资料来源:Huy Bui</p></figure><p id="0a28" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们使用核密度估计将这两个直方图放在一起，并截断一些异常值，我们会获得一个漂亮的图形:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nh"><img src="../Images/47e02b18a0a24e7cd84c54dc1a2ff068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XoW9WlTRuzunwm9iF6HQkg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">两类决策边界</p></figure><p id="1782" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">蓝线是<strong class="kk iu">决策边界</strong>。它将图表分为4个部分:</p><ul class=""><li id="151e" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld nn no np nq bi translated">纯绿色:无癌症(真阴性)</li><li id="1458" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">纯红色:癌症(真阳性)</li><li id="0326" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">左侧混合:有癌症，但被检测为无癌症(假阳性)</li><li id="9888" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">右混合:没有癌症，但被检测为患有癌症(假阴性)</li></ul><p id="e5e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，一个好的二进制分类模型将最小化混合区域。因此，在获得一个好的模型后，研究ROC曲线将告诉我们我们的模型是否在TPR和FPR之间做了很好的平衡。下面我们来看看ROC曲线:</p><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="6dfd" class="lu lv it mt b gy mx my l mz na">from sklearn.metrics import roc_curve, auc</span><span id="7dc2" class="lu lv it mt b gy nb my l mz na"># Normalize the Data<br/>X = X.apply(lambda x : (x - x.min()) /(x.max() - x.min()),axis=0) <br/>X_train, X_test, y_train, y_test = train_test_split(X, y.values.flatten(), random_state=0)</span><span id="d0c9" class="lu lv it mt b gy nb my l mz na">y_score = logreg.fit(X_train, y_train).decision_function(X_test)<br/>fpr, tpr, thresholds = roc_curve(y_test, y_score)</span><span id="6379" class="lu lv it mt b gy nb my l mz na">def ROC_curve(fpr,tpr):<br/>    # Seaborn's beautiful styling<br/>    sns.set_style('darkgrid', {'axes.facecolor': '0.9'})</span><span id="084f" class="lu lv it mt b gy nb my l mz na">print('AUC: {}'.format(auc(fpr, tpr)))<br/>    plt.figure(figsize=(10, 8))<br/>    lw = 2<br/>    plt.plot(fpr, tpr, color='darkorange',<br/>             lw=lw, label='ROC curve')<br/>    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')<br/>    plt.xlim([0.0, 1.0])<br/>    plt.ylim([0.0, 1.05])<br/>    plt.yticks([i/20.0 for i in range(21)])<br/>    plt.xticks([i/20.0 for i in range(21)])<br/>    plt.xlabel('False Positive Rate')<br/>    plt.ylabel('True Positive Rate')<br/>    plt.title('Receiver operating characteristic (ROC) Curve')<br/>    plt.legend(loc='lower right')<br/>    plt.show()<br/>    <br/>ROC_curve(fpr,tpr)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nw"><img src="../Images/ebad5e2a62295e436633c72d38eb87de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZjVqupsS5BzDvUJ7LVKmuA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">物流回归ROC曲线。资料来源:Huy Bui</p></figure><p id="0901" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">模型中的虚线是随机选择(概率50%)。因为有两类，这条线的斜率处处都是1，因此我们得到单位正方形的对角线。注意这条线下的面积(AUC)是0.5。</p><p id="88a8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">橙色线是ROC曲线。它位于虚线上方，表明我们的准确性优于随机选择。通过增加阈值的数值，越来越多的观察结果属于癌症类别。所以TP趋近于1，FN趋近于0。这使得<strong class="kk iu"> TPR趋近于1 </strong>。类似地，增加阈值将导致FP接近1，TN接近0。这会使<strong class="kk iu"> FPR趋近于1。因此，我们得出结论，FPR、TPR和阈值彼此成正比。ROC曲线仅显示了2轴FPR和TPR，但是现在我们知道阈值是产生该图的混杂变量。</strong></p><p id="f550" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">再看一下图表。AUC评分为0.96，接近完美。我们还想看看ROC曲线，看看在图中的哪个点我们有FPR和TPR的完美组合。例如，如果我们将当前模型调整为具有97%的TPR，则FPR大约为6%。如果我们将FPR降低到5%，那么TPR只有82%。所有调整模型的不同方法都是不同领域的不同主题。</p><h2 id="043e" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">结论</h2><p id="bdfd" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们可以使用ROC分析来选择基于成本背景或类别分布的可能的最优模型。ROC分析也非常类似于诊断决策的成本/收益分析。这是一个伟大的工具，每个数据科学家都应该评估他们的分类器性能。</p><p id="a2bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以从我的<a class="ae ne" href="https://github.com/williamhuybui/Blog-ROC-curve-and-AUC" rel="noopener ugc nofollow" target="_blank">库</a>中找到这个博客的完整代码。</p><p id="c67c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请在下面留下任何评论、问题或建议。感谢您的阅读！</p></div></div>    
</body>
</html>