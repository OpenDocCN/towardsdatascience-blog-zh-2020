<html>
<head>
<title>5 minutes of Web Scraping using Python and Beautiful Soup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python和美汤进行5分钟的网页抓取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-minutes-of-web-scraping-using-python-and-beautiful-soup-98e6fbce9cc7?source=collection_archive---------56-----------------------#2020-05-31">https://towardsdatascience.com/5-minutes-of-web-scraping-using-python-and-beautiful-soup-98e6fbce9cc7?source=collection_archive---------56-----------------------#2020-05-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="094d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用Python和美汤刮西甲统计</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7086d5ac35e8f4fdbb3d9eb40406a74f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zJNDdDhQo-vkiaPnwkmkIw@2x.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">埃米尔·佩龙——<a class="ae kv" href="http://www.unsplash.com" rel="noopener ugc nofollow" target="_blank">Unsplash</a>的照片</p></figure><p id="ca94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> E </span>从网站上提取数据可以节省大量的时间和精力。感谢美汤，刮网之路变得更加顺畅。在这篇文章中，我们将使用Python从一个网站上收集西甲2019–20的统计数据。</p><p id="24dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">导入库</strong></p><pre class="kg kh ki kj gt mb mc md me aw mf bi"><span id="e316" class="mg mh iq mc b gy mi mj l mk ml">import pandas as pd<br/>import requests as rq<br/>from bs4 import BeautifulSoup</span></pre><p id="a933" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，必须导入所有有用的库。我已经导入了熊猫来存储数据框中的统计数据。导入Requests库是为了向HTTP服务器发送请求，同时引入漂亮的Soup用于web元素检索。</p><p id="263d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">与网页通信</strong></p><pre class="kg kh ki kj gt mb mc md me aw mf bi"><span id="b075" class="mg mh iq mc b gy mi mj l mk ml">get_url = rq.get("https://www.msn.com/en-us/sports/soccer/la-liga/player-stats")<br/><br/>get_text = get_url.text<br/><br/>soup = BeautifulSoup(get_text, "html.parser")</span></pre><p id="2934" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们必须获得目标URL，然后使用漂亮的Soup库解析它。一旦创建了汤对象，就可以开始了。</p><p id="0b6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">提取网页元素</strong></p><pre class="kg kh ki kj gt mb mc md me aw mf bi"><span id="b219" class="mg mh iq mc b gy mi mj l mk ml">rank = [i.text for i in soup.findAll('td', {<br/>    "class" : "hide1 rankvalue"<br/>})]<br/><br/>player_name = [i.text<br/>               for i in soup.findAll('td', {<br/>        "class" : "playername"<br/>    })<br/>               ]<br/><br/>team_name = [i.text<br/>             for i in soup.findAll('td', {<br/>        "class" : "teamname"<br/>    })<br/>             ]<br/><br/>team_la = [i.text<br/>           for i in soup.findAll('td', {<br/>        "class" : "teamtla"<br/>    })<br/>           ]<br/><br/>games_played = [int(i.findAll('td')[4].text) for i in soup.findAll('tr', {<br/>    "class" : "rowlink"<br/>})]<br/><br/>goals_scored = [int(i.findAll('td')[7].text) for i in soup.findAll('tr', {<br/>    "class" : "rowlink"<br/>})]<br/><br/>assists = [int(i.findAll('td')[8].text) for i in soup.findAll('tr', {<br/>    "class" : "rowlink"<br/>})]</span></pre><p id="06dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用漂亮的Soup方法，您可以访问web元素及其项目。我主要使用了<em class="mm">“find all”</em>方法，将“class”作为一个参数来获取所有项目的列表。</p><p id="ff60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">存储在数据帧中</strong></p><pre class="kg kh ki kj gt mb mc md me aw mf bi"><span id="f150" class="mg mh iq mc b gy mi mj l mk ml">laliga_stats = pd.DataFrame({<br/><br/>    "Rank" : rank,<br/><br/>    "Player Name" : player_name,<br/><br/>    "Team Name" : team_name,<br/><br/>    "Team" : team_la,<br/><br/>    "Games Played" : games_played,<br/><br/>    "Goals" : goals_scored,<br/><br/>    "Assists" : assists<br/>    })<br/>laliga_stats.set_index('Rank',inplace=True)</span></pre><p id="1049" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，使用Pandas库将数据存储到数据框中。并且，你可以进行你的分析了。</p><p id="002e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你只要写一行代码，就能获得2019-20西甲赛季的前10名射手:</p><pre class="kg kh ki kj gt mb mc md me aw mf bi"><span id="e782" class="mg mh iq mc b gy mi mj l mk ml">laliga_stats[0 :10]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mn"><img src="../Images/36c4d9bb7ff29a57a98bd08e32556183.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DiWvsncLt9MXHUz4nPQdVg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">2019-20赛季西甲十大射手</p></figure><p id="659b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有需要的是Python和美丽的汤的奇迹刮一个网站。所以，在一个新的标签上打开Beautiful Soup的文档，开始刮吧。</p><p id="a2fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如需反馈和讨论，请在<a class="ae kv" href="http://linkedin.com/in/vishal-sharma-239965140" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>联系我！</p></div></div>    
</body>
</html>