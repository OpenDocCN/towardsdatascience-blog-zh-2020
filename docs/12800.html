<html>
<head>
<title>TensorFlow Cloud: Local to Distributed</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流云:从本地到分布式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-cloud-local-to-distributed-286e3665302f?source=collection_archive---------53-----------------------#2020-09-02">https://towardsdatascience.com/tensorflow-cloud-local-to-distributed-286e3665302f?source=collection_archive---------53-----------------------#2020-09-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4c32" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://github.com/tensorflow/cloud" rel="noopener ugc nofollow" target="_blank"> TensorFlow Cloud </a>是一个 python 包，用于使用 Google AI 平台从本地调试无缝过渡到云中的分布式训练。TensorFlow Cloud 有<strong class="jp ir">在谷歌云平台(GCP)上运行</strong> API 用于训练模型，有<strong class="jp ir"> tuner </strong>用于超参数调优。它通过一个<strong class="jp ir">单一功能调用</strong>简化了云上的训练模型，并处理所有特定于云的任务，如 VM 实例创建和选择分发策略[1]。</p><p id="d921" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">调用后的<strong class="jp ir"> run </strong> API 将验证和预处理 python 脚本或笔记本，使用云构建或本地 docker 守护进程将其容器化，并将训练作业部署到 AI 平台。可以将相关日志流式传输到日志记录，并使用托管 TensorBoard 监控培训。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/1caf21046cfed1952f9693085243f36e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*oTODQ6d40kU1c6IFXPX_iQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">运行 API </strong>高层流程</p></figure><pre class="kn ko kp kq gt kz la lb lc aw ld bi"><span id="de1c" class="le lf iq la b gy lg lh l li lj"><strong class="la ir">run</strong>(entry_point=None,<br/>    requirements_txt=None,<br/>    distribution_strategy='auto',<br/>    docker_base_image=None,<br/>    chief_config='auto',<br/>    worker_config='auto',<br/>    worker_count=0,<br/>    entry_point_args=None,<br/>    stream_logs=False,<br/>    docker_image_bucket_name=None,<br/>    job_labels=None,<br/>    **kwargs)</span></pre><p id="1898" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">运行 API 有以下重要参数，这些参数有助于将代码从本地迁移到 AI 平台。[2]</p><ul class=""><li id="3b79" class="lk ll iq jp b jq jr ju jv jy lm kc ln kg lo kk lp lq lr ls bi translated"><strong class="jp ir"> entry_point: </strong>可选字符串<strong class="jp ir">、</strong> python 脚本或包含训练代码的笔记本。如果未提供 entry_point，则当前 python 脚本或笔记本将被用作 entry_point。例如 train.py 或 train.ipynb</li><li id="03a2" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated"><strong class="jp ir"> requirements_txt: </strong>可选字符串<strong class="jp ir">，</strong>附加必需库列表。</li><li id="2ab2" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated"><strong class="jp ir"> distribution_strategy: </strong>自动或无，默认为自动，将根据主管配置、员工配置和员工人数选择分配策略。</li><li id="3709" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated"><strong class="jp ir"> chief_config: </strong>分布式集群中主要工作者的机器配置。默认:T4_1X</li><li id="1b9f" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated"><strong class="jp ir"> worker_config: </strong>分布式集群中工作者的机器配置。默认:T4_1X</li><li id="63de" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated"><strong class="jp ir"> worker_count: </strong>分布式集群中的工作线程数。默认值:0</li><li id="c0ac" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated"><strong class="jp ir">entry _ point _ args:</strong>entry _ point 脚本或笔记本的可选参数。默认值:无</li><li id="a678" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated"><strong class="jp ir"> stream_logs: </strong>来自 AI 平台的流日志的布尔标志。</li><li id="9178" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated"><strong class="jp ir">docker _ image _ bucket _ name:</strong>可选字符串，指定 docker image 云存储桶名。如果设置了该参数，docker 容器化使用<a class="ae kl" href="https://cloud.google.com/cloud-build" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">Google Cloud Build</strong></a>完成，否则使用本地 docker 守护进程。</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/8b0125afa24dcdba6c9bbf315b3e733b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*4ldl51G3SkaeZU8gwJzm8w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">TensorFlow 云培训分发策略</p></figure><h1 id="28c0" class="lz lf iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">分销策略</h1><p id="28ce" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">运行 API 支持自动和自定义分发策略，上面的流程图显示了自动选择分发策略。所有分布策略都遵循数据并行性，其中模型变量跨设备复制，并使用 all-reduce 策略进行同步。</p><p id="73c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了“<em class="nb">all reduce 策略(ring all-reduce)的一种可能实现，其中 N 个节点中的每个节点与其两个对等节点通信 2*(N-1)次。在此通信期间，节点发送和接收数据缓冲区的块。在前 N-1 次迭代中，接收到的值被添加到节点缓冲区中的值。在第二个 N-1 次迭代中，接收到的值替换保存在节点缓冲区中的值。</em> [ <a class="ae kl" href="https://eng.uber.com/horovod/" rel="noopener ugc nofollow" target="_blank"> 5 </a></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nc"><img src="../Images/b9ccc169d6fbd96d0ee7fa769eb0cc6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WZH1GgoCsprtHmHJIlduCA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">环环全减策略:图片来自<a class="ae kl" href="https://eng.uber.com/horovod/" rel="noopener ugc nofollow" target="_blank">优步·霍罗沃德</a></p></figure><p id="1ad2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">一种设备策略:</strong>无分布式训练，这种策略的典型用途可能是训练代码验证。</p><p id="b2ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">镜像策略:</strong>变量在所有设备上复制，并使用 all-reduce 策略保持同步。如果在策略的构造器参数中没有指定设备，那么它将使用所有可用的 GPU。如果没有找到 GPU，它将使用可用的 CPU。</p><p id="9999" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">多工作者镜像策略:</strong>类似于镜像策略，在所有工作者的每个设备上创建模型中所有变量的副本，并使用 CollectiveOps 的多工作者 all-reduce 实现来保持变量同步。</p><h1 id="8680" class="lz lf iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">工作示例</h1><p id="7d6a" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">让我们看一个工作示例，通过在 MNIST 数据集上定义一个简单的用于数字分类的 Keras 模型训练代码，保存为<strong class="jp ir"> toy_mnist.py [2] </strong></p><pre class="kn ko kp kq gt kz la lb lc aw ld bi"><span id="8e3a" class="le lf iq la b gy lg lh l li lj">import tensorflow as tf</span><span id="139f" class="le lf iq la b gy nh lh l li lj">(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()</span><span id="7215" class="le lf iq la b gy nh lh l li lj">x_train = x_train.reshape((60000, 28 * 28))<br/>x_train = x_train.astype('float32') / 255</span><span id="705b" class="le lf iq la b gy nh lh l li lj">model = tf.keras.Sequential([<br/>  tf.keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,)),<br/>  tf.keras.layers.Dropout(0.2),<br/>  tf.keras.layers.Dense(10, activation='softmax')<br/>])</span><span id="a5ca" class="le lf iq la b gy nh lh l li lj">model.compile(loss='sparse_categorical_crossentropy',<br/>              optimizer=tf.keras.optimizers.Adam(),<br/>              metrics=['accuracy'])</span><span id="9762" class="le lf iq la b gy nh lh l li lj">model.fit(x_train, y_train, epochs=10, batch_size=128)</span></pre><p id="5e44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的模型可以通过编写下面的简单脚本在云上运行。</p><pre class="kn ko kp kq gt kz la lb lc aw ld bi"><span id="4158" class="le lf iq la b gy lg lh l li lj">import tensorflow_cloud as tfc<br/>tfc.run(entry_point='<strong class="la ir">toy_mnist.py</strong>', chief_config=tfc.COMMON_MACHINE_CONFIGS['T4_4X'])</span></pre><p id="3389" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们运行上面的脚本时，用 chief_config 作为 T4_4X 机器，没有创建 worker，因为 worker_count 默认为 0，并且低于自动生成的代码以及其他参数，如 chief_config、worker_config，docker registry 被部署到 AI 平台，并且由于 chief config 的加速器数量&gt; 0<strong class="jp ir">T4 _ 4X</strong>，选择了<strong class="jp ir">TF . distribute . mirroredstrategy</strong>。用于分发策略的 TensorFlow 使用<a class="ae kl" href="https://docs.nvidia.com/deeplearning/nccl/" rel="noopener ugc nofollow" target="_blank">NCCL</a>(Nvidia Collective communication s Library)作为 GPU 的跨设备通信，并使用 tf.distribute.NcclAllReduce 作为镜像策略。</p><pre class="kn ko kp kq gt kz la lb lc aw ld bi"><span id="5149" class="le lf iq la b gy lg lh l li lj">import os<br/>import tensorflow as tf<br/>os.environ["TF_KERAS_RUNNING_REMOTELY"]="1"<br/><strong class="la ir">strategy = tf.distribute.MirroredStrategy()</strong><br/>tf.distribute.experimental_set_strategy(strategy)<br/>exec(open("toy_mnist.py").read())</span></pre><p id="df25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了提交到 AI 平台的作业。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi ni"><img src="../Images/f78b58cdd64d3f03ea757c7cb447daf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o_453DJT8Kko5h5Mv0hbWA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">提交的工作细节，谷歌人工智能平台</p></figure><p id="bb76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练日志和详细信息在堆栈驱动程序日志中提供，如下图所示，也可以通过在 run API 调用中将 stream_logs 设置为 True 来传输到主机。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nj"><img src="../Images/55a6142b907479bc0b14c86529cc6555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xtkij0akNcT_CkfQHLr3gg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示每个历元的交叉熵损失、精确度的日志</p></figure><p id="9498" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">还可以使用<code class="fe nk nl nm la b"><strong class="jp ir">tf.keras.models.save_model</strong></code>将模型保存到 Google 云存储桶，使用<code class="fe nk nl nm la b"><a class="ae kl" href="https://cloud.google.com/sdk/gcloud/reference/ai-platform/predict" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">gcloud ai-platform predict</strong></a></code>将模型部署到 AI 平台进行在线推理。</p><p id="83c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关于设置 TensorFlow、TensorFlow-Cloud 和云配置(创建项目和启用 AI 平台等)，请参考参考资料[ <a class="ae kl" href="https://github.com/tensorflow/cloud#setup-instructions" rel="noopener ugc nofollow" target="_blank"> 3 </a> ]。</p><h1 id="4683" class="lz lf iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">参考</h1><ol class=""><li id="4015" class="lk ll iq jp b jq mw ju mx jy nn kc no kg np kk nq lq lr ls bi translated"><a class="ae kl" href="https://www.tensorflow.org/guide/keras/training_keras_models_on_cloud" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/guide/keras/training _ keras _ models _ on _ cloud</a></li><li id="6fd8" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk nq lq lr ls bi translated"><a class="ae kl" href="https://github.com/tensorflow/cloud" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/cloud</a></li><li id="b59d" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk nq lq lr ls bi translated"><a class="ae kl" href="https://github.com/tensorflow/cloud#setup-instructions" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/cloud#setup-instructions</a></li><li id="dffc" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk nq lq lr ls bi translated"><a class="ae kl" href="https://www.tensorflow.org/api_docs/python/tf/distribute" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/distribute</a></li><li id="069b" class="lk ll iq jp b jq lt ju lu jy lv kc lw kg lx kk nq lq lr ls bi translated"><a class="ae kl" href="https://eng.uber.com/horovod/" rel="noopener ugc nofollow" target="_blank">https://eng.uber.com/horovod/</a></li></ol></div></div>    
</body>
</html>