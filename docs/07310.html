<html>
<head>
<title>NLP in Python-Data cleaning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的NLP数据清理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-in-python-data-cleaning-6313a404a470?source=collection_archive---------6-----------------------#2020-06-03">https://towardsdatascience.com/nlp-in-python-data-cleaning-6313a404a470?source=collection_archive---------6-----------------------#2020-06-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4ed4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Kaggle的真实或虚假新闻数据集的典型NLP机器学习模型管道中涉及的数据清洗步骤。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/79b0348fda22bb4ecf6b676cc310f5c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S-oJXNjccMfo-o1_epkeFg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自<a class="ae kv" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>的<a class="ae kv" href="https://unsplash.com/@romankraft" rel="noopener ugc nofollow" target="_blank"> Roman Kraft </a>的照片</p></figure><p id="f8b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在任何机器学习模型中，数据清洗都是非常关键的一步，但对于NLP来说更是如此。如果没有清理过程，数据集通常是计算机无法理解的一串单词。在这里，我们将回顾在典型的机器学习文本管道中完成的清理数据的步骤。</p><p id="01e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用一个将新闻分为真假的数据集。数据集可以在Kaggle上找到，数据集的链接在下面，</p><blockquote class="ls lt lu"><p id="36dd" class="kw kx lv ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated"><a class="ae kv" href="https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/clmentbisaillon/fake-and-real-news-dataset</a></p></blockquote><p id="b577" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有两个数据集Kaggle数据集中的假新闻和真新闻。我把假新闻和真实新闻的数据集连接起来。十大真假新闻如下:</p><pre class="kg kh ki kj gt lz ma mb mc aw md bi"><span id="33ac" class="me mf iq ma b gy mg mh l mi mj">news.head(10)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/70d3b561f46925f48c8d3b0f28152518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*TKHu-e8vDqSKcHzkUU26sQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">10条假新闻</p></figure><pre class="kg kh ki kj gt lz ma mb mc aw md bi"><span id="6e66" class="me mf iq ma b gy mg mh l mi mj">news.tail(10)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/ca7d6c44768c29d3a44b158b986bf11f.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*ZC0aHr4dVs4kYolKRCVY3g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">10条真实新闻</p></figure><p id="e8e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将通过几个步骤来清理新闻数据集，删除不必要的内容，并突出适合ML模型的关键属性。</p><p id="5c9f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第一步:标点</strong></p><p id="9880" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">标题文本有几个标点符号。标点符号通常是不必要的，因为它不会增加NLP模型的价值或意义。“字符串”库有32个标点符号。标点符号是:</p><pre class="kg kh ki kj gt lz ma mb mc aw md bi"><span id="5755" class="me mf iq ma b gy mg mh l mi mj">import string<br/>string.punctuation</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/7de6c523b3268485077369f31e37ea17.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*So-uyXoqvdJpzddmTtR9VQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">字符串库中的标点符号</p></figure><p id="9456" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要删除数据集中的标点符号，让我们创建一个函数并将该函数应用于数据集:</p><pre class="kg kh ki kj gt lz ma mb mc aw md bi"><span id="9db2" class="me mf iq ma b gy mg mh l mi mj">def remove_punctuation(text):<br/>    no_punct=[words for words in text if words not in string.punctation]<br/>    words_wo_punct=''.join(no_punct)<br/>    return words_wo_punct</span><span id="9241" class="me mf iq ma b gy mn mh l mi mj">news['title_wo_punct']=news['title'].apply(lambda x: remove_punctuation(x))<br/>news.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/9a3690388565ca500c29e1fa9b8ba9fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*7kQ8c5bPgLDucnCabek4_A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">新闻数据集(包括标题，不带标点符号)</p></figure><p id="c579" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">步骤1之后的列已经从标题文本中删除了标点符号。</p><p id="1700" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步骤2:标记化</strong></p><p id="6f37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">标记化是将字符串拆分成单词列表的过程。我们将利用正则表达式或正则表达式来进行拆分。正则表达式可以用来描述一个搜索模式。</p><pre class="kg kh ki kj gt lz ma mb mc aw md bi"><span id="3093" class="me mf iq ma b gy mg mh l mi mj">def tokenize(text):<br/>    split=re.split("\W+",text) <br/>    return split<br/>news['title_wo_punct_split']=news['title_wo_punct'].apply(lambda x: tokenize(x.lower()))<br/>news.head()</span></pre><p id="de35" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，“\W+”拆分一个或多个非单词字符</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/bc8d462efc8a02a922c80a5453ad89d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*GNcHE13b4R0jnqLTQHyJqw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">新闻数据集(包括标题，不带标点和拆分)</p></figure><p id="e3c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">步骤2之后的列通过拆分所有非单词字符创建了一个列表。</p><p id="0e7e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第三步:停用词</strong></p><p id="6504" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们有一个没有任何标点符号的单词列表。让我们继续并删除停用词。停用词是不相关的词，无助于识别文本的真伪。我们将对停用词使用“nltk”库，该库中的停用词包括:</p><pre class="kg kh ki kj gt lz ma mb mc aw md bi"><span id="5126" class="me mf iq ma b gy mg mh l mi mj">stopword = nltk.corpus.stopwords.words('english')<br/>print(stopword[:11])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/1c6f0ce0bfef37c6ab70006d5050b68c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*hOJAXDzKVk9_mied-0QOVA.png"/></div></figure><p id="7d82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个库中有179个停用词。</p><pre class="kg kh ki kj gt lz ma mb mc aw md bi"><span id="49ac" class="me mf iq ma b gy mg mh l mi mj">def remove_stopwords(text):<br/>    text=[word for word in text if word not in stopword]<br/>    return text<br/>news['title_wo_punct_split_wo_stopwords'] = news['title_wo_punct_split'].apply(lambda x: remove_stopwords(x))<br/>news.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/bd6ea84d3a275d14d5af0585b257a61e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*H5IelFIoeOJpz6GLjGEm5Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">新闻数据集(包括标题，不带标点，不带停用词和拆分)</p></figure><p id="c174" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">步骤3之后的列已经删除了不必要的停用词。</p><p id="000c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第四步:词尾/词干</strong></p><p id="e269" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">词干化和词尾化是将一个单词简化为其词根形式的过程。主要目的是减少同一个单词的变化，从而减少模型中包含的单词集。词干化和词汇化的区别在于，词干化会去掉单词的末尾，而不考虑单词的上下文。然而，词汇化考虑单词的上下文，并根据字典定义将单词缩短为其词根形式。与词干化相比，词干化是一个更快的过程。因此，这是速度和准确性之间的权衡。</p><p id="f876" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们以“信念”这个词为例。相信的不同变体可以是相信、被相信、相信和相信。</p><pre class="kg kh ki kj gt lz ma mb mc aw md bi"><span id="4264" class="me mf iq ma b gy mg mh l mi mj">print(ps.stem('believe'))<br/>print(ps.stem('believing'))<br/>print(ps.stem('believed'))<br/>print(ps.stem('believes'))</span></pre><p id="4d82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以上所有的stem结果是<strong class="ky ir">相信</strong></p><pre class="kg kh ki kj gt lz ma mb mc aw md bi"><span id="4f06" class="me mf iq ma b gy mg mh l mi mj">print(wn.lemmatize(“believe”))<br/>print(wn.lemmatize(“believing”))<br/>print(wn.lemmatize(“believed”))<br/>print(wn.lemmatize(“believes”))</span></pre><p id="a10b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">按照书面陈述的顺序，词汇化结果是——相信、相信、相信和相信。</p><p id="d2f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果单词不在语料库中，Lemmatize会产生相同的结果。Believe被词条化为belief(词根)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/86ac27c90b9cb4d9e1b73dcc495d5e85.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*9KGgvTGGI56CPUsQQE0A9g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">新闻数据集(词汇化与词干化)</p></figure><p id="66ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如上图所示，lemmatize和stem产生不同的结果。我们可以为我们的最终模型选择任何一个。</p><p id="2ad5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第五步:其他步骤</strong></p><p id="deb2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以基于该数据执行其他清洁步骤。我在下面列出了其中的一些，</p><ol class=""><li id="fda7" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated">删除URL</li><li id="c710" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">删除HTML标签</li><li id="6e75" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">移除表情符号</li><li id="119b" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">删除号码</li></ol><p id="23e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi">…</p><p id="cf00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我很想听听你对我的文章的想法和反馈。请在下面的评论区留下它们。</p></div></div>    
</body>
</html>