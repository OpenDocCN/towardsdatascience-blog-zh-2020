<html>
<head>
<title>Visualizing How Different ML Models Operate in the Feature Space</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可视化不同的ML模型如何在特征空间中操作</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visualizing-how-different-ml-models-operate-in-the-feature-space-c6caa8a96375?source=collection_archive---------44-----------------------#2020-04-25">https://towardsdatascience.com/visualizing-how-different-ml-models-operate-in-the-feature-space-c6caa8a96375?source=collection_archive---------44-----------------------#2020-04-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/cea5c1126c26d573796b3e0fd4ac18e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SnIY4pjy5r4c_SIa3qDq5Q.png"/></div></div></figure><div class=""/><div class=""><h2 id="94ff" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">直观地理解每个机器学习模型的本质</h2></div><p id="30d6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我记得当我学习机器学习模型时——KNN、逻辑回归、SVM、决策树等等——我只学习了理论。因为所有这些算法都涉及大量的数学，大多数人只学到了肤浅的理论。但是，往往对一个模型的理解还不够深入，理解不了算法的本质。</p><p id="259e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">每个机器学习模型如何在特征空间中操作可以用三个机器学习问题来可视化——识别聚类、环带问题和棋盘问题。通过这些可视化，将实现对每个机器学习模型如何在特征空间中操作的更深入理解。</p><p id="a253" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">所有人物由作者创作。</p></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><h1 id="a3d1" class="lw lx je bd ly lz ma mb mc md me mf mg kk mh kl mi kn mj ko mk kq ml kr mm mn bi translated">识别集群</h1><p id="1bbf" class="pw-post-body-paragraph kt ku je kv b kw mo kf ky kz mp ki lb lc mq le lf lg mr li lj lk ms lm ln lo im bi translated">在这个问题中，每个机器学习模型必须将一个二维点分类到五个聚类中的一个，标记为0到4。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mt"><img src="../Images/5dc00a84023cc6e61a4804f500f82cb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vrxHhQs6wCWj3QL5vGT0Yw.png"/></div></div></figure><p id="6d63" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">决策树算法创建一个规则系统，将特征空间分成几个区域。该算法划分特征空间的一个直接引人注目的方式是，它创建了几个“不自然”的区域，因为决策树算法创建了水平和垂直线条的复杂系统，而不是线条清晰。这可以归因于算法用来划分空间的规则系统——例如，具有0 <em class="my"> &lt; y &lt; </em> 5和-6 &lt; <em class="my"> x </em> &lt; -1的数据点。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mz"><img src="../Images/23b3785072ede31fcaf67ea28648aa55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ct0G0dAWnGHOaf_TijiFXQ.png"/></div></div></figure><p id="48ce" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">随机森林算法类似于决策树分类器，但是区域的组织更加精确。而决策树算法将中左区域中的一段空白空间分类为类别2(绿色)，即使它确实属于任何区域。因为随机森林算法包含几个决策树的智慧，所以区域被更好地划分，但也更详细，以捕捉已经复杂的模型集合的更大复杂性。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi na"><img src="../Images/7ee065dcfba3dbe80c2c8353e13bda86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_d-ypCNw4hoa2-d1Zjq7AQ.png"/></div></div></figure><p id="3fbe" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">支持向量机(SVM)算法的性质决定了比决策树和随机森林算法更平滑的线，在决策树和随机森林算法中，对角线实际上不是线，而是非常复杂和长的垂直和水平移动序列。因此，它实现了随机森林的目标，而没有增加方差(过拟合)。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nb"><img src="../Images/0e8a2d7050c3e9a00685e9d750f184d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KT7LZB2yqLxeYLDS8fsl1w.png"/></div></div></figure><p id="bd89" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">K-最近邻算法类似于随机森林算法，但由于其算法本质上严重依赖于少量的唯一数据点，因此方差增加了。虽然在其他机器学习问题上，KNN可能并不强大，但它在识别几何轮廓清晰的聚类方面似乎表现不错。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nc"><img src="../Images/c564a6f81ea70d479678b8f5563d54ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Anf1b6rYhvjXXQ7G2J_vUw.png"/></div></div></figure><p id="d405" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">六种流行的机器学习算法的并排比较很能说明每种算法在特征空间上如何操作的本质。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/752486748094f0879edccaa346a5fb0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EUAhCztB12QKCAvLsWd98A.png"/></div></div></figure><h1 id="19d1" class="lw lx je bd ly lz ne mb mc md nf mf mg kk ng kl mi kn nh ko mk kq ni kr mm mn bi translated">环形问题</h1><p id="6c5e" class="pw-post-body-paragraph kt ku je kv b kw mo kf ky kz mp ki lb lc mq le lf lg mr li lj lk ms lm ln lo im bi translated">在环带问题中，分类器必须区分环带内的区域和环带外的区域，其中环带由两个圆定义。成功解决环形问题的模型可以处理非线性数据和同类的分离区域。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nj"><img src="../Images/43f83d6734139b760ff835156070e3f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tQ6izJ5-_cfViggXKIODqg.png"/></div></div></figure><p id="59ff" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">正如前面在聚类识别问题中所看到的，决策树试图仅使用由严格的水平线和垂直线界定的区域来重新创建环。它的许多异常，包括在右上角断开。这是决策树过度拟合能力和偶尔无法识别看似明显的模式的一个强有力的可视化表示。</p><p id="b2e3" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">随机森林算法可以通过利用大数定律的导数来避免这种缺陷，并通过增加集合中投票者的数量来提高准确性和理解性。很明显，随机森林算法认识到了环的连续性——然而，环周边的颗粒噪声表明该算法缺乏泛化能力。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nk"><img src="../Images/2278ea29435b2a92ff10480972cd144f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MGBmp6o3-XcVk6ni_Hhbrg.png"/></div></div></figure><p id="5a7e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">KNN算法能够形成环的形状，但是外部和内部参数中的噪声细节再次显示了对数据点的过度依赖和缺乏理解。SVM同样理解环带的连续性，并且几乎完美地描绘了环带的内周。即使角点是线，但看数据，也不能怪算法画了线性边界。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/7ab5e172d94b56db9c55fd63f6bca723.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*12CV5SPp55ko3ezfOqlZhQ.png"/></div></div></figure><p id="0edf" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">逻辑回归和朴素贝叶斯在环带问题上都失败了，显示出太多的偏差和太少的方差。两种算法都将整个特征空间归为一类。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/b0937014035605358e9e9d2eb6b4de12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RfA5OfC7PZwhlG6v9NQQ-w.png"/></div></div></figure><p id="5ba1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">环空问题模型的横向比较；</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/3eb223ed5787d3821620686dcc89b5ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7BiIICcQrUqLWwUt5UOsQ.png"/></div></div></figure><h1 id="bccd" class="lw lx je bd ly lz ne mb mc md nf mf mg kk ng kl mi kn nh ko mk kq ni kr mm mn bi translated">棋盘问题</h1><p id="25d8" class="pw-post-body-paragraph kt ku je kv b kw mo kf ky kz mp ki lb lc mq le lf lg mr li lj lk ms lm ln lo im bi translated">棋盘问题是一个高方差问题，其中二进制类在棋盘空间中交替出现。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nc"><img src="../Images/1da8df6f8c9d18bc6d9115f7222e52ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6EpSxvKc2D-TkpNPKhEKAA.png"/></div></div></figure><p id="d711" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">决策树、随机森林和KNN算法都是非常高方差的算法，展示了基于给定数据构建棋盘的强大能力。但是，请注意，他们无法将棋盘图案推广到任何大小的棋盘——在棋盘的顶部和右侧，颜色一致的矩形向前扩展到无穷远。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nj"><img src="../Images/3789dfff3584e6805de5a9591e7f66e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oPwMNl6TtYpctCmQ5o1E0w.png"/></div></div></figure><p id="a23a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">应该注意到SVM在高方差问题上表现不佳。由于SVM只能分配有限数量的支持向量，它能做的最好的事情就是将棋盘空间分成四个区域。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi no"><img src="../Images/f5e9d279a0319a886a8a7e914fdcb0fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KsAQYe__mQQNb71mjd4pNQ.png"/></div></div></figure><p id="252c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">与环形问题一样，逻辑回归和朴素贝叶斯在棋盘问题上失败，预测整个棋盘的一个类。与SVM一样，这些低方差算法在需要如此多复杂区域划分的任务中失败了。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/f8215b926010cb0aaf1fe13bd203af75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u-M_rvepriGdT1NCuwapZg.png"/></div></div></figure><p id="6f89" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这些算法中没有一个能够有效地划分棋盘并推广到比训练空间更大的空间。神经网络已经能够在这方面显示出希望；也就是说，在例如20×20的棋盘上进行训练，并且能够在例如40×40的棋盘上继续该模式。棋盘问题的一个解决方案是画对角线，这是一种神经网络能够识别的模式。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nq"><img src="../Images/810f4b7862d86fc7908dfa10980db026.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rGF0QlzNTlpvFVCCHK0VvQ.png"/></div></div></figure><p id="06a3" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">棋盘问题算法的并列比较；</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nr"><img src="../Images/265ce309db027dd91a08c75b4a6a9dbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5c7bJTuz6LPtJmmQjBnIQA.png"/></div></div></figure></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><h1 id="73c2" class="lw lx je bd ly lz ma mb mc md me mf mg kk mh kl mi kn mj ko mk kq ml kr mm mn bi translated">感谢阅读！</h1><p id="bf8d" class="pw-post-body-paragraph kt ku je kv b kw mo kf ky kz mp ki lb lc mq le lf lg mr li lj lk ms lm ln lo im bi translated">希望这些来自三个完全不同的问题的可视化能够说明每个算法的本质，以及它如何划分特征空间以实现减少错误的目标。</p><p id="1a6d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">创建这些问题和其他合成数据问题的代码和解释可以在<a class="ae ns" rel="noopener" target="_blank" href="/playing-god-with-data-d7d566550745">这里</a>找到。</p><p id="5bde" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae ns" href="https://www.kaggle.com/washingtongold/visualize-different-ml-models?scriptVersionId=32661681" rel="noopener ugc nofollow" target="_blank">识别星团代码</a>、<a class="ae ns" href="https://www.kaggle.com/washingtongold/visualize-ml-models-2-0?scriptVersionId=32661666" rel="noopener ugc nofollow" target="_blank">圆环问题</a>、<a class="ae ns" href="https://www.kaggle.com/washingtongold/visualize-ml-models-3-0?scriptVersionId=32662030" rel="noopener ugc nofollow" target="_blank">棋盘问题</a></p></div></div>    
</body>
</html>