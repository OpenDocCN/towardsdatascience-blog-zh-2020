# 基于 Berka 数据集的贷款违约预测

> 原文：<https://towardsdatascience.com/loan-default-prediction-an-end-to-end-ml-project-with-real-bank-data-part-1-1405f7aecb9e?source=collection_archive---------5----------------------->

## 使用真实银行数据的端到端机器学习项目

![](img/c6641656ac5e0848439fd10aeabc274d.png)

肖恩·波洛克在 [Unsplash](https://unsplash.com/) 上的照片

# 目录

[简介](#f6eb)
[关于数据集](#55c6)
[导入数据集到数据库](#faf0)
[连接 Python 到 MySQL 数据库](#908e)
[特征提取](#ed0c)
[特征转换](#b8f5)
[建模](#1768)
[结论与未来方向](#447b)
[关于我](#a3b5)

**注**:如果你对本帖以外的细节感兴趣，Berka 数据集、所有代码和笔记本都可以在我的 [GitHub 页面](https://github.com/zhouxu-ds/loan-default-prediction)找到。

这篇文章只是构建贷款违约预测模型的实践。如果你对这个话题感兴趣，并且想看一些我为一个客户完成的更深入的工作，使用优化利用这样的贷款违约预测模型把他们的损失变成利润，请在这里看我的另一篇文章:[贷款违约预测利润最大化](/loan-default-prediction-for-profit-maximization-45fcd461582b)。

# 介绍

对于银行来说，在只有少量信息的情况下，预测客户违约的可能性始终是一个有趣且具有挑战性的问题。在当今时代，银行的数据科学团队使用机器学习来构建预测模型。他们使用的数据集很可能是专有的，通常是通过日常业务在内部收集的。换句话说，如果我们想从事这样的金融项目，我们可以使用的真实数据集并不多。幸运的是，有一个例外:Berka 数据集。

# 关于数据集

[Berka 数据集](https://relational.fit.cvut.cz/dataset/Financial)，或 PKDD'99 金融数据集，是一个来自捷克银行的真实匿名金融信息集合，用于 PKDD'99 探索挑战。数据集可以从我的 [GitHub 页面](https://github.com/zhouxu-ds/loan-default-prediction/tree/main/data)访问。

在数据集中，8 个原始文件包括 8 个表:

*   **户口** (4500 对象档案户口。ASC) —每个记录描述一个帐户的静态特征。
*   **客户端**(文件客户端中的 5369 个对象。ASC) —每个记录描述一个客户的特征。
*   **处分** (5369 档案中的对象 DISP。ASC) —每个记录将客户与账户联系在一起，即这种关系描述了客户操作账户的权利。
*   **永久顺序**(文件顺序中的 6471 个对象。ASC) —每个记录描述一个支付指令的特征。
*   **交易**(文件 TRANS 中的 1056320 对象。ASC)——每条记录描述一个账户上的一笔交易。
*   **贷款**(档案贷款中的 682 对象。ASC) —每个记录描述了一个给定账户的贷款。
*   **信用卡**(档案卡中的 892 个对象。ASC)——每条记录描述了一个账户发行的信用卡。
*   **人口统计数据**(档案区 77 个对象。ASC) —每个记录描述一个地区的人口统计特征。

![](img/30e99445bc5b02cdc9ee362f833c390a.png)

来自[关系数据集存储库](https://relational.fit.cvut.cz/dataset/Financial)的表关系

*   每个账户都具有“账户”关系中给出的静态特征(如创建日期、分行地址)和“永久订单”和“交易”关系中给出的动态特征(如借记或贷记的付款、余额)。
*   关系“客户”描述可以操纵账户的人的特征。
*   一个客户可以有多个账户，多个客户可以用一个账户操作；客户和账户在关系“处置”中联系在一起。
*   关系“贷款”和“信用卡”描述了银行向客户提供的一些服务。
*   一个账户可以发行多张信用卡。
*   一个账户最多只能发放一笔贷款。
*   关系“人口统计数据”提供了一些关于地区的公开信息(如失业率)；由此可以推断出关于客户端的附加信息。

# 将数据集导入数据库

这是一个可选步骤，因为原始文件仅包含分隔符分隔的值，因此可以使用 pandas 直接导入到数据框中。

在这里，我编写了 SQL 查询来将原始数据文件导入 MySQL 数据库，以便对数据进行简单快速的数据操作(例如，选择、连接和聚合函数)。

上面的代码片段展示了如何创建银行数据库和导入账户表。它包括三个步骤:

*   创建和使用数据库
*   创建表格
*   将数据加载到表中

如果你熟悉 MySQL 和数据库系统，前两步应该没有任何问题。对于“加载数据”步骤，您需要确保已经在 MySQL 中启用了`LOCAL_INFILE`。详细说明可以从[这个线程](https://dba.stackexchange.com/questions/48751/enabling-load-data-local-infile-in-mysql)中找到。

通过对每个表重复步骤 2 和步骤 3，所有数据都可以导入到数据库中。

# 将 Python 连接到 MySQL 数据库

同样，如果您选择使用 Pandas 将数据直接导入 Python，这一步是可选的。但是，如果您已经创建了数据库，并通过一些 SQL 数据操作熟悉了数据集，那么下一步就是将准备好的表转移到 Python 中，并在那里执行数据分析。一种方法是使用 Python 的 MySQL 连接器来执行 Python 中的 SQL 查询，并使用结果生成 Pandas 数据帧。以下是我的方法:

修改数据库信息(如主机、数据库、用户、密码)后，我们可以启动一个连接实例，执行查询并将其转换为 Pandas 数据帧:

尽管这是一个可选的步骤，但是与直接将文件导入到 Pandas DataFrames 相比，它在速度、便利性和实验目的方面都是有利的。不像其他 ML 项目只给了我们一个`csv`文件(1 个表)，这个数据集相当复杂，在表的连接之间隐藏了很多有用的信息，所以这也是我为什么要先介绍加载数据到数据库的方式的另一个原因。

现在，数据在 MySQL 服务器中，我们已经将它连接到 Python，这样我们就可以顺利地访问数据框中的数据。接下来的步骤是从表中提取特征，转换变量，将它们加载到一个数组中，并训练机器学习模型。

# 特征抽出

由于预测贷款违约是一个二元分类问题，我们首先需要知道每个类中有多少个实例。通过查看`Loan`表中的`status`变量，有 4 个不同的值:A、B、C 和 d

*   合同完成了，没有问题。
*   合同结束了，贷款还没付。
*   c:运行合同，到目前为止还可以。
*   d:执行合同，客户负债。

根据来自[数据集描述](https://github.com/zhouxu-ds/ds-projects/blob/master/loan_default_prediction/data/data_description.pdf)的定义，我们可以将它们分成二元类:好的(A 或 C)和坏的(B 或 D)。有 606 笔贷款属于“良好”类，其中 76 笔属于“不良”类。

定义了两个不同的类后，我们可以查看变量并绘制直方图，看看它们是否对应于不同的分布。

下面显示的贷款金额是一个很好的例子，可以看出这两个类别之间的差异。尽管两者都是右偏的，但它仍然显示出一个有趣的模式，即金额较高的贷款往往会违约。

![](img/43d4edb97ff422327397844a9d1110cc.png)

贷款金额直方图(好与坏)

提取特征时，它们不必是表中提供的现有变量。相反，我们总是可以发挥创造力，想出一些现成的解决方案来创建我们自己的功能。例如，当连接`Loan`表和`Account`表时，我们可以同时获得贷款发放日期和帐户创建日期。我们可能想知道创建帐户和申请贷款之间的时间间隔是否起了作用，因此简单的减法会给我们一个新的变量，该变量由同一帐户上两个此类活动之间的天数组成。直方图如下所示，其中可以看到一个明显的趋势，即在创建银行账户后立即申请贷款的人往往会违约。

![](img/990c4b37099dfd17387d9940864d51f0.png)

账户创建和贷款发放之间的天数直方图

通过重复试验现有特性和创建的特性的过程，我最终准备了一个包含 18 个特性列和 1 个标签列的表。所选功能包括:

*   金额:贷款金额
*   期限:贷款期限
*   付款:贷款付款
*   days_between:帐户创建和贷款发放之间的天数
*   频率:发布报表的频率
*   average_order_amount:帐户发出的永久订单的平均金额
*   average_trans_amount:账户交易的平均金额
*   average_trans_balance:帐户进行交易后的平均余额
*   账户交易号
*   card_type:与帐户关联的信用卡类型
*   n _ 居民:户口所在地区的居民人数
*   average_salary:客户所在地区的平均工资
*   平均失业率:计算地区的平均失业率
*   企业家比率:账户所在地区每 1000 名居民中的企业家人数
*   average_crime_rate:帐户所在地区的平均犯罪率
*   owner_gender:帐户所有者的性别
*   owner_age:帐户所有者的年龄
*   same_district:一个布尔值，表示所有者是否拥有与帐户相同的地区信息

# 特征转换

特征提取出来放入大表后，就要对数据进行转换，使之有机地馈入机器学习模型。在我们的例子中，我们有两种类型的特征。一种是**数值**，比如`amount`、`duration`、`n_trans`。另一种是**分类的**，比如`card_type`和`owners_gender`。

我们的数据集非常干净，没有任何缺失值，所以我们可以跳过插补，直接对数值进行缩放。从`scikit-learn`开始有几个定标器选项，如`StandardScaler`、`MinMaxScaler`和`RobustScaler`。在这里，我使用`MinMaxScaler`在 0 和 1 之间重新调整数值。另一方面，处理分类变量的典型策略是使用`OneHotEncoder`将特性转换成二进制`0`和`1`值。

下面的代码代表了功能转换的步骤:

用列变换器进行特征变换

# 建模

训练机器学习模型的第一件事是分割训练集和测试集。这在我们的数据集中很棘手，因为它是不平衡的:好贷款几乎是坏贷款的 10 倍。分层分割在这里是一个好的选择，因为它保留了训练集和测试集中类之间的比率。

分层列车测试分裂

对于二元分类任务，有很多很好的机器学习模型。这里，随机森林模型因为其良好的性能和快速原型制作能力而被用在这个项目中。拟合初始`RandomForrestClassifier`模型，并使用三种不同的度量来表示模型性能:**准确性**、 **F1 得分**和 **ROC AUC** 。

值得注意的是，对于这个不平衡的数据集，精确度是不够的。如果我们纯粹通过准确性来微调模型，那么它将倾向于预测贷款为“好贷款”。F1 得分是精确度和召回率之间的调和平均值，ROC AUC 是 ROC 曲线下的面积。这两个是评估不平衡数据的模型性能的更好的指标。

下面的代码显示了如何对训练集应用五重分层交叉验证，并计算每个分数的平均值:

初始模型的模型性能

```
Acc: 0.8973
F1: 0.1620
ROC AUC: 0.7253
```

很清楚的看到准确率很高，差不多 0.9，但是 F1 的分数因为召回率低所以很低。模型有微调和争取更好性能的空间，方法之一是网格搜索。通过为`RandomForestClassifier`的超参数(如`n_estimators``max_depth``min_samples_split``min_samples_leaf`)赋予不同的值，它将遍历超参数的组合，并输出在我们感兴趣的分数上表现最好的一个。代码片段如下所示:

使用 GridSearchCV 进行微调

用最佳参数改装模型，我们可以看看模型在整个列车组和试验组的性能:

![](img/6a99b6a598268cc0818b3e97c3eef129.png)![](img/7e47f4b55b515a155b2eebd3df6ca132.png)

```
Performance on Train Set:Acc: 0.9706
F1: 0.8478
ROC AUC: 0.9952Performance on Test Set:Acc: 0.8927
F1: 0.2667
ROC AUC: 0.6957
```

在训练集上的表现非常好:超过 2/3 的不良贷款和所有的良好贷款都被正确分类，并且三个性能指标都在 0.84 以上。另一方面，当该模型用于测试集时，结果并不令人满意:大多数不良贷款被标记为“好”，F1 值仅为 0.267。有证据表明涉及到过度拟合，因此应该在这种迭代过程中投入更多的精力，以便获得更好的模型性能。

随着模型的建立，我们现在可以根据它们的重要性对特性进行排序。预测能力最强的五大特征是:

*   平均交易余额
*   平均交易金额
*   贷款金额
*   平均工资
*   账户创建和贷款申请之间的天数

这没什么好惊讶的，因为对于其中的许多情况，我们已经看到了可能与贷款违约有关的异常行为，例如账户创建和贷款申请之间的**贷款金额**和**天**。

# 结论和未来方向

在这篇文章中，我介绍了银行应用程序中端到端机器学习模型的整个流程，贷款违约预测，以及真实世界的银行数据集 Berka。我描述了 Berka 数据集和每个表之间的关系。演示了如何将数据集导入 MySQL 数据库，然后连接到 Python 并将处理后的记录转换为 Pandas DataFrame 的步骤和代码。特征被提取并转换成一个数组，准备输入到机器学习模型中。最后一步，我使用数据拟合了一个随机森林模型，评估了模型性能，并生成了在预测贷款违约中起作用的前 5 个特征的列表。

这个机器学习管道只是可以与 Berka 数据集一起使用的一个应用程序的轻轻一碰。它可以更深入，因为在表之间错综复杂的关系中隐藏着更多有用的信息；它还可以更广泛，因为它可以扩展到其他应用程序，如信用卡和客户的交易行为。但如果只关注这一贷款违约预测，未来可能会有三个方向进一步下降:

1.  **提取更多特征**:由于时间限制，无法对数据集进行透彻的学习和深入的理解。数据集中仍有许多未使用的功能，许多信息还没有被银行业的知识完全消化。
2.  **尝试其他模型**:只有随机森林模型被使用，但有许多好的模型，如逻辑回归、XGBoost、SVM，甚至神经网络。还可以通过对超参数进行更精细的调整或使用集合方法(如打包、提升和叠加)来进一步改进模型。
3.  **处理不平衡数据**:需要注意的是，违约贷款仅占总贷款的 10%左右，因此在训练过程中，模型更倾向于预测负面结果而非正面结果。我们已经使用了 F1 评分和 ROC AUC，而不仅仅是准确性。然而，性能仍然没有达到应有的水平。为了解决这个问题，将来可以使用其他方法，如收集或重采样更多数据。

同样，这篇文章只是从头开始构建贷款违约预测模型的实践。如果你对这个话题感兴趣，并且想看一些我为一个客户完成的更深入的工作，使用这种贷款违约预测模型，使用优化将他们的损失转化为利润，请在这里看我的另一篇文章:[贷款违约预测利润最大化](/loan-default-prediction-for-profit-maximization-45fcd461582b)。

感谢您的阅读！如果你喜欢这篇文章，请**关注我的频道**和/或 [**成为我今天的推荐会员**](https://zhouxu-ds.medium.com/membership) (非常感谢🙏).我会继续写下去，分享我关于数据科学的想法和项目。如果你有任何问题，请随时联系我。

[](https://zhouxu-ds.medium.com/membership) [## 通过我的推荐链接加入 Medium 周(乔)徐

### 阅读周(Joe)徐(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接支持…

zhouxu-ds.medium.com](https://zhouxu-ds.medium.com/membership) 

# 关于我

我是赛诺菲的数据科学家。我拥抱技术，每天都在学习新技能。欢迎您通过[媒体博客](https://zhouxu-ds.medium.com/)、 [LinkedIn](https://www.linkedin.com/in/zhouxu-ds/) 或 [GitHub](https://github.com/zhouxu-ds) 联系我。我的观点是我自己的，而不是我雇主的观点。

请看我的其他文章:

*   [利润最大化的贷款违约预测](/loan-default-prediction-for-profit-maximization-45fcd461582b)
*   [利用空气质量传感器数据进行时间序列模式识别](/time-series-pattern-recognition-with-air-quality-sensor-data-4b94710bb290)
*   [使用 Python 和 Flask-RESTful 为机器学习模型构建 REST API](/build-rest-api-for-machine-learning-models-using-python-and-flask-restful-7b2cd8d87aa0)
*   [理解分类问题中的 Sigmoid、Logistic、Softmax 函数和交叉熵损失(对数损失)](https://medium.com/@zhouxu-ds/understanding-sigmoid-logistic-softmax-functions-and-cross-entropy-loss-log-loss-dbbbe0a17efb)
*   [使用 Elasticsearch (AWS OpenSearch)进行实时类型预测搜索](/real-time-typeahead-search-with-elasticsearch-aws-opensearch-88410d5b31a1)