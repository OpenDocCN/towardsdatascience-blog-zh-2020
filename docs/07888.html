<html>
<head>
<title>How to Build a Warped Linear Regression Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何建立扭曲线性回归模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-warped-linear-regression-model-3e778e30a201?source=collection_archive---------49-----------------------#2020-06-11">https://towardsdatascience.com/how-to-build-a-warped-linear-regression-model-3e778e30a201?source=collection_archive---------49-----------------------#2020-06-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a149" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/optimization-and-ml" rel="noopener" target="_blank">优化和机器学习</a></h2><div class=""/><div class=""><h2 id="7802" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">我们使用模块<a class="ae ko" href="https://github.com/rnburn/peak-engines" rel="noopener ugc nofollow" target="_blank">峰值引擎</a>对数据进行单调转换</h2></div><p id="af2d" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><a class="ae ko" href="https://en.wikipedia.org/wiki/Ordinary_least_squares" rel="noopener ugc nofollow" target="_blank">普通最小二乘法</a> (OLS)将线性回归模型拟合到数据集，以便在误差正态分布的假设下最大化似然性。当误差项分解成独立同分布分量的和时，正态性自然会出现，但对许多问题来说，这种假设是不现实的。</p><p id="4563" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">例如，考虑一个目标值表示百分比的回归数据集。对于一个给定的特征向量，OLS可能会预测一个这样的分布</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/7c6e503526cfe851d7f1c4e9e77350a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*FkgRo1OOwbvCJVczv-_JZw.png"/></div></figure><p id="6b64" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">这里怎么了？分布显示目标值可能大于100%。当目标空间是有界的时，关于末端附近预测的正态分布误差是没有意义的。</p><p id="2362" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">如果不满足正态假设，我们有时可以通过转换目标空间来解决问题。假设<em class="lt"> f </em>是单调递增函数。让X和y表示特征矩阵和目标向量。放<em class="lt"> z = f( </em> y <em class="lt">)。</em>虽然OLS可能无法很好地模拟原始数据集，但它有可能适合X和z</p><p id="9b1b" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">我们如何找到这样一个函数<em class="lt"> f </em>？这就是翘曲帮助我们的地方。弯曲从一族参数化单调函数开始。该族足够一般，可以近似任意变换。如果<em class="lt"> ψ </em>表示弯曲函数的参数向量，那么我们使用优化器来调整<em class="lt"> ψ </em>以最大化训练数据的可能性。</p><p id="837d" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><a class="ae ko" href="https://github.com/rnburn/peak-engines" rel="noopener ugc nofollow" target="_blank"> Peak-engines </a>是一个python模块，用于构建这种扭曲的线性回归模型。我们将使用它为一个示例数据集构建一个模型，并展示我们如何改进OLS。</p><p id="152b" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">我们将使用的示例是波士顿房屋数据集，其任务是根据社会经济和地理属性预测房屋的中值。像百分比一样，房屋价值是有限的(你不会找到免费的房屋)，因此有理由认为目标空间可以从扭曲中受益。</p><p id="1e66" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">首先，让我们设置数据集。Boston housing附带sklearn，便于组装。</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="lu lv l"/></div></figure><p id="89e8" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">在我们建立扭曲线性回归模型之前，我们需要安装峰值引擎</p><pre class="lm ln lo lp gt lw lx ly lz aw ma bi"><span id="735c" class="mb mc iq lx b gy md me l mf mg">pip install peak-engines</span></pre><p id="ca1f" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">然后我们可以拟合一个扭曲的线性回归模型。</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="lu lv l"/></div></figure><p id="f699" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">Peak-engines在OLS之前搜索要应用的扭曲函数空间，直到找到最大化可能性的变换。为了可视化转换的样子，我们将它绘制在目标值的范围内。</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="lu lv l"/></div></figure><p id="c431" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">翘曲函数在较低的住房价值更陡峭。它在目标空间的低端展开点，在高端压缩点。</p><p id="2718" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">为了比较扭曲线性回归和OLS，让我们运行留一交叉验证。对于每个数据点，我们形成一个去除了该点的训练数据集和一个只包含该点的测试数据集。我们拟合OLS和扭曲的线性回归模型，并衡量对数似然性能。</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="lu lv l"/></div></figure><p id="31eb" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">结果显示验证点更有可能是扭曲线性回归。我们将查看一些随机预测示例，以更好地理解为什么它做得更好。</p><div class="lm ln lo lp gt ab cb"><figure class="mh lq mi mj mk ml mm paragraph-image"><img src="../Images/122f3a96369f9b53edadcf2b78f885ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*lgsNr8cdNTaahrqQyO-asQ.png"/></figure><figure class="mh lq mi mj mk ml mm paragraph-image"><img src="../Images/87f233d2e93f86733599d6f4d50982c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*guk67iioTvWr2oyipz1jAg.png"/></figure></div><div class="ab cb"><figure class="mh lq mi mj mk ml mm paragraph-image"><img src="../Images/566b1211008c2d53aa430079321b7bab.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*OutN-JFHGv86Vazs3X9Njw.png"/></figure><figure class="mh lq mi mj mk ml mm paragraph-image"><img src="../Images/e773d4a5cb79a8a8f2cf21836ec2399c.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*oeUbFbzLB4QGdEIho5YU3A.png"/></figure></div><p id="a5af" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">扭曲函数导致概率密度函数在较低的目标值处逐渐变小，从而允许概率质量被重新分配到值更可能出现的区域。</p><p id="7fe0" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">完整示例的代码可从<a class="ae ko" href="https://github.com/rnburn/peak-engines/blob/master/example/boston_housing.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><h2 id="f703" class="mb mc iq bd mn mo mp dn mq mr ms dp mt ky mu mv mw lc mx my mz lg na nb nc iw bi translated">摘要</h2><p id="3ef0" class="pw-post-body-paragraph kp kq iq kr b ks nd ka ku kv ne kd kx ky nf la lb lc ng le lf lg nh li lj lk ij bi translated">当面临回归问题时，OLS通常是我们寻求的第一个模型，然而许多数据集并不满足其对正态分布误差的强假设。扭曲线性回归建立在OLS的基础上，通过引入额外的变换步骤来扭曲目标空间，以校正误差中的非正态性。它保留了OLS模型的许多简单性，但更通用，并经常导致更好的性能。</p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><p id="0730" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">参考</p><p id="aa7e" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">[1]: <em class="lt"> E .斯尼尔森，CE Rasmussen，Z . Ghahramani。</em> <a class="ae ko" href="https://papers.nips.cc/paper/2481-warped-gaussian-processes.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lt">【扭曲高斯】突起</em> </a> <em class="lt">。神经信息处理系统的进展16，337–344</em></p><p id="0f50" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">[2]: <a class="ae ko" href="https://medium.com/p/what-to-do-when-your-model-has-a-non-normal-error-distribution-f7c3862e475f?source=email-f55ad0a8217--writer.postDistributed&amp;sk=f3d494b5f5a8b593f404e7af19a2fb37" rel="noopener">当您的模型具有非正态误差分布时该怎么办</a></p></div></div>    
</body>
</html>