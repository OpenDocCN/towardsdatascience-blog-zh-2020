<html>
<head>
<title>A quick overview of 5 scikit-learn classification algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5 种 scikit-learn 分类算法的快速概述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-quick-overview-of-5-scikit-learn-classification-algorithms-33fdc11ab0b9?source=collection_archive---------25-----------------------#2020-05-20">https://towardsdatascience.com/a-quick-overview-of-5-scikit-learn-classification-algorithms-33fdc11ab0b9?source=collection_archive---------25-----------------------#2020-05-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a8d4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何使用这五种算法，只用几行代码就能构建模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3225152500c8701ac083083ad52364c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8G2FYalPeJbUNMlnf-19pA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3252160" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a></p></figure><p id="80b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">简介</strong></p><p id="6075" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将向您展示如何使用 scikit- learn 为分类目的构建快速模型。</p><p id="0a2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用具有三个不同目标值的 Iris 数据集，但是您应该能够对任何其他多类或二进制分类问题使用相同的代码。</p><p id="2176" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您将学习如何拆分模型的数据，如何使算法适合五种不同类型模型的数据，然后使用分类报告对结果进行简要评估。</p><p id="387d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将在这里使用的算法是:</p><blockquote class="lv"><p id="89dd" class="lw lx it bd ly lz ma mb mc md me lu dk translated">逻辑回归</p><p id="67ae" class="lw lx it bd ly lz ma mb mc md me lu dk translated">KNN</p><p id="6455" class="lw lx it bd ly lz ma mb mc md me lu dk translated">决策图表</p><p id="5019" class="lw lx it bd ly lz ma mb mc md me lu dk translated">随机福里斯特</p><p id="0f0c" class="lw lx it bd ly lz ma mb mc md me lu dk translated">梯度推进</p></blockquote><p id="4ccf" class="pw-post-body-paragraph kz la it lb b lc mf ju le lf mg jx lh li mh lk ll lm mi lo lp lq mj ls lt lu im bi translated">是时候开始了！</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="8bec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">加载数据和快速数据浏览</strong></p><p id="63e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用以下代码加载 Iris 数据集:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="4a0a" class="mw mx it ms b gy my mz l na nb">from sklearn.datasets import load_iris<br/>import pandas as pd</span><span id="3f18" class="mw mx it ms b gy nc mz l na nb">data = load_iris()<br/>df = pd.DataFrame(data['data'], columns=data['feature_names'])<br/>df['species'] = data['target']<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/0c1d3dec023638035080902b71011830.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*zO6ZnbixPc9JO5Z1MkMnZQ.png"/></div></figure><p id="4937" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个数据集中只有五列。最后一栏<em class="ne">物种</em>是我们将试图预测的，我们将称之为目标。所有其他列将作为特征，并使用它们来进行预测。</p><p id="892f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在您自己的数据集中，清楚地确定什么是目标，什么是特征是很重要的。</p><p id="7530" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们调用 info()函数来进一步了解我们的数据:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="c26e" class="mw mx it ms b gy my mz l na nb">df.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/9b10dc0e9117c3f516ef81256019ce9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*ZQ8oOYGZIRc0SeIY_3UrFA.png"/></div></figure><p id="0220" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，只有 150 个条目，任何一列都没有丢失值。此外，所有值要么是浮点数，要么是整数。</p><p id="daec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，从数据集描述中，我知道<em class="ne">物种</em>不是一个连续变量，而是一个分类变量(因此分类不是回归)。</p><p id="5d32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以检查这一点，并通过 value_counts()函数查看目标值是如何分布的:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="e6c0" class="mw mx it ms b gy my mz l na nb">df.species.value_counts()</span><span id="dffe" class="mw mx it ms b gy nc mz l na nb">2    50<br/>1    50<br/>0    50<br/>Name: species, dtype: int64</span></pre><p id="9499" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到,<em class="ne">物种</em>列只有三个值:0、1 和 2，并且所有的类都有相同数量的例子:每个类 50 个。就目标值分布而言，这是一个完美平衡的数据集。</p><p id="c8cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们的数据是<em class="ne">“非常干净”</em>，没有缺失值或分类变量作为特征，并且在目标方面平衡良好，我们可以实际进入建模部分。</p><p id="f3df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ne"> ***如果您的数据有缺失值，您必须通过删除或用近似值替换它们来处理。此外，如果有分类变量作为特征，那么就需要一键编码。</em></p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="19ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">将数据集分为训练和测试</strong></p><p id="9d16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在将数据拟合到模型之前，有必要将数据分为训练和测试部分。这一点很重要，因为您不应该在对其进行训练的相同数据上测试您的模型。</p><p id="ce96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，使用 scikit-learn 中的 train_test_split 函数很容易做到这一点:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="57f4" class="mw mx it ms b gy my mz l na nb">from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test = train_test_split(df.drop('species', axis=1), df.species ,test_size = 0.2, random_state=13)</span></pre><p id="a485" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于此功能，我们现在将数据分为 4 个部分:</p><blockquote class="lv"><p id="0d27" class="lw lx it bd ly lz ma mb mc md me lu dk translated">x _ 火车</p><p id="50b3" class="lw lx it bd ly lz ma mb mc md me lu dk translated">x _ 测试</p><p id="ad24" class="lw lx it bd ly lz ma mb mc md me lu dk translated">y _ 火车</p><p id="54b2" class="lw lx it bd ly lz ma mb mc md me lu dk translated">y _ 测试</p></blockquote><p id="c350" class="pw-post-body-paragraph kz la it lb b lc mf ju le lf mg jx lh li mh lk ll lm mi lo lp lq mj ls lt lu im bi translated">x 前缀是指保存特征信息的数据部分，y 前缀的数据保存数据的目标部分。你可以从我之前写的<a class="ae ky" rel="noopener" target="_blank" href="/splitting-your-data-to-fit-any-machine-learning-model-5774473cbed2">文章</a>中了解更多关于这个函数是如何工作的。</p><p id="adce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从现在开始，我将在列车部分(x_train 和 y_train)拟合模型，并在测试部分(x_test 和 y_test)进行测试。</p><p id="40ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以安装我们的第一个模型。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="fe2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">逻辑回归</strong></p><p id="cc67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从实现逻辑回归的第一个模型开始。</p><p id="16e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将从 scikit-learn 线性模型包中导入模型，并使用 fit()函数训练模型，然后使用 predict()函数对测试集进行预测:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="0f76" class="mw mx it ms b gy my mz l na nb">from sklearn.linear_model import LogisticRegression<br/>clf = LogisticRegression().fit(x_train, y_train)<br/>predictions = clf.predict(x_test)</span></pre><p id="d9b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，我使用了 fit()函数训练数据部分(x 和 y 部分),为了进行预测，我仅使用了 x_test。我现在可以将预测值与实际目标值进行比较(y_test)。</p><p id="c44c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">直到现在我也不知道我的模型是否做了正确的预测。为了对此进行评估，我将使用 sci-kit learn 中的 classification_report:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="0818" class="mw mx it ms b gy my mz l na nb">from sklearn.metrics import classification_report<br/>print(classification_report(y_test, predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/3b990f1e52101b46c22bb5472481d55e.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*Hqf0ZIQoC0TX_QRwy7BUZQ.png"/></div></figure><p id="1c40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类报告将我们对目标变量的预测与实际类别进行比较。我希望你们主要关注的指标是准确性。在这种情况下，我们已经正确预测了 97%的类，还不错。</p><p id="4dd9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我不打算详细解释分类报告，但我想强调的是，在比较模型和准确性的同时，关注精确度、召回率和 f 值是非常重要的。为此，我打印了整个报告，而不仅仅是准确性。我认为这是一个方便的功能，可以将所有这些指标汇总在一起。如果你想了解更多关于精确度、召回率、f 分数的知识，也想学习阅读混淆矩阵，请查看这篇<a class="ae ky" rel="noopener" target="_blank" href="/reading-a-confusion-matrix-60c4dd232dd4">文章</a>。</p><p id="c091" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回到准确性…看起来简单的逻辑回归允许我们获得 97%的正确预测。毫无疑问，这是一个很好的起点，如果我对此感到满意，我就可以用它来高精度地预测花卉种类。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="d4c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">K-最近邻(KNN) </strong></p><p id="8505" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们在相同的数据上训练<strong class="lb iu"/>K-最近邻:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="4029" class="mw mx it ms b gy my mz l na nb">from sklearn.neighbors import KNeighborsClassifier<br/>neigh = KNeighborsClassifier()<br/>neigh.fit(x_train, y_train)<br/>predictions = neigh.predict(x_test)</span></pre><p id="2c45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经为算法使用了默认参数，所以我们正在寻找五个最近的邻居，并且在估计类预测时给它们相等的权重。</p><p id="4b53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您现在可以调用分类报告:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="857a" class="mw mx it ms b gy my mz l na nb">from sklearn.metrics import classification_report<br/>print(classification_report(y_test, predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/0f79b23157ff2c4f2bec6d1c7dd0d041.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*W8V7Gd-KtcNmd9Duq4RyQw.png"/></div></figure><p id="e38f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具有默认值的 KNN 似乎比逻辑回归略差。准确率从 0.97 下降到 0.9，平均召回率、准确率和 f 值似乎也降低了。</p><p id="8c9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以和 KNN·帕拉姆一起玩，看看是否可以改进。可能的改进包括改变用于预测的邻居数量或使用考虑邻居邻近性的不同权重。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="e1f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">决策树</strong></p><p id="14d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看另一种分类算法。我现在将调用一个带有默认参数的决策树来执行:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="18e5" class="mw mx it ms b gy my mz l na nb">from sklearn.tree import DecisionTreeClassifier<br/>clf = DecisionTreeClassifier(random_state=0)<br/>clf.fit(x_train, y_train)<br/>predictions = clf.predict(x_test)</span></pre><p id="2ad9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我提供的唯一参数是一个随机状态。这就是为什么我的结果是可重复的。</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="a8fa" class="mw mx it ms b gy my mz l na nb">from sklearn.metrics import classification_report<br/>print(classification_report(y_test, predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/de407e456d4f38703005e5842d0919c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*F5D8Sh_yAYujAV3PZ0JKug.png"/></div></figure><p id="fdaa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如你所看到的，这个决策树在测试数据集上表现得非常好。我预测所有的类都是正确的！</p><p id="3346" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">乍一看似乎很棒，但我可能在这里太适合了。我可能应该使用交叉验证来调整模型参数，以防止过度拟合。</p><p id="95d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下代码仅对训练数据执行 10 重交叉验证，并打印出每一重的准确度:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="6013" class="mw mx it ms b gy my mz l na nb">from sklearn.model_selection import cross_val_score<br/>cross_val_score(clf, x_train, y_train, cv=10)</span><span id="9514" class="mw mx it ms b gy nc mz l na nb">array([1.        , 0.92307692, 0.91666667, 0.91666667, 0.91666667,<br/>       1.        , 0.91666667, 1.        , 1.        , 0.90909091])</span></pre><p id="9303" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过检查输出，我可以看到，在一些数据拆分中，我确实获得了 100%的准确性，但有相当多的数据拆分的准确性几乎低了 10%。原因是我使用的数据集非常小。仅仅一个实例的错误分类就会导致巨大的准确性波动。</p><p id="b309" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ne"> ***一般来说，正如我在这里演示的那样，使用默认算法构建第一个模型是没问题的，但下一步应该是使用交叉验证运行参数。</em></p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="1148" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">随机福里斯特</strong></p><p id="a60d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们尝试用它的默认参数调用随机森林分类器。</p><p id="1882" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以将随机森林视为一组决策树。森林实际上是通过使用许多决策树，然后对结果进行平均来构建的。我不打算在这里解释算法的细节，而是用它的默认参数调用它。</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="c1e8" class="mw mx it ms b gy my mz l na nb">from sklearn.ensemble import RandomForestClassifier<br/>clf = RandomForestClassifier(random_state=0)<br/>clf.fit(x_train, y_train)<br/>predictions = clf.predict(x_test)</span></pre><p id="2a50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们运行一个分类报告:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="703e" class="mw mx it ms b gy my mz l na nb">from sklearn.metrics import classification_report<br/>print(classification_report(y_test, predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/48b0a26bd0ddef2359e13a7b067d4f20.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*_axXMWCZ4Qp0BBglSdx6Ug.png"/></div></figure><p id="32d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们这里有 93%的准确率。我们已经看到了以前的分类算法的一些更好和一些更差的结果。</p><p id="21a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了调整和改进算法，您可以调整估计器的数量、深度和结构。这需要学习更多关于树和算法本身如何工作的知识。有很多关于这方面的文章，所以我建议你搜索一下，如果你想了解更多的话。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="a7e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">梯度增强</strong></p><p id="d54f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们试试我们将在本文中提出的最后一个算法:梯度推进分类器。这是另一种树型算法，对于许多机器学习问题非常有效。</p><p id="a1ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用 scikit-learn 函数调用 is:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="6810" class="mw mx it ms b gy my mz l na nb">from sklearn.ensemble import GradientBoostingClassifier<br/>clf = GradientBoostingClassifier(random_state=0)<br/>clf.fit(x_train, y_train)<br/>predictions = clf.predict(x_test)</span></pre><p id="fff6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并运行分类报告:</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="7cbe" class="mw mx it ms b gy my mz l na nb">from sklearn.metrics import classification_report<br/>print(classification_report(y_test, predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/d40737a0734a7e9e991aa592dd7b3bb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*p1TY8Gz58Ad83lxo2GeSOA.png"/></div></figure><p id="7712" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是另一个得分很高的算法。我们已经达到了 97%的准确率。</p><p id="e87f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看起来我们所有的模型都做了相当不错的预测，即使使用了默认的未调整参数！</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="fc81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">比较分类算法</strong></p><p id="73f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以看到，我们已经提出了五个算法，它们都在测试集上取得了很高的准确率。该算法的准确率从 90% (KNN)到 100%(决策树)。</p><p id="f673" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">理论上，这种算法中的任何一种都可以用来以相当高的准确度(超过 90%)预测花卉香料。</p><p id="6681" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们已经做了相当快速的分析，并且没有深入每个实现的细节，所以很难决定哪个算法是最好的。这将需要对每个算法实现进行更多的分析和调整。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="3e1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">总结</strong></p><p id="d3e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您已经大致了解了五种基本分类算法，并学习了如何使用默认参数调用它们。阅读完本文后，您还应该能够使用快速分类报告来评估它们的性能。</p><p id="6a5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步应该是更多地了解每种算法，并对其进行调整以提高性能和避免过度拟合。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="48b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ne">最初发表于 about datablog . com:</em><a class="ae ky" href="https://www.aboutdatablog.com/post/a-quick-overview-of-5-scikit-learn-classification-algorithms" rel="noopener ugc nofollow" target="_blank">5 个 scikit-learn 分类算法的快速概述</a>，<em class="ne">2020 年 5 月 19 日。</em></p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="b2fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ne"> PS:我正在 Medium 和</em><a class="ae ky" href="https://www.aboutdatablog.com/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="ne">aboutdatablog.com</em></strong></a><em class="ne">上撰写深入浅出地解释基本数据科学概念的文章。你可以订阅我的</em> <a class="ae ky" href="https://medium.com/subscribe/@konkiewicz.m" rel="noopener"> <strong class="lb iu"> <em class="ne">邮件列表</em> </strong> </a> <em class="ne">以便在我每次写新文章时得到通知。如果你还不是中等会员，你可以在这里加入</em><a class="ae ky" href="https://medium.com/@konkiewicz.m/membership" rel="noopener"><strong class="lb iu"><em class="ne"/></strong></a><em class="ne">。</em></p><p id="e435" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面还有一些你可能喜欢的帖子</p><div class="nk nl gp gr nm nn"><a rel="noopener follow" target="_blank" href="/9-pandas-visualizations-techniques-for-effective-data-analysis-fc17feb651db"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">9 熊猫有效数据分析的可视化技术</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">学习如何使用折线图、散点图、直方图、箱线图和其他一些可视化技术</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob ks nn"/></div></div></a></div><div class="nk nl gp gr nm nn"><a rel="noopener follow" target="_blank" href="/what-are-lambda-functions-in-python-and-why-you-should-start-using-them-right-now-75ab85655dc6"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">python 中的 lambda 函数是什么，为什么你现在就应该开始使用它们</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">初学者在 python 和 pandas 中开始使用 lambda 函数的快速指南。</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="oc l ny nz oa nw ob ks nn"/></div></div></a></div><div class="nk nl gp gr nm nn"><a rel="noopener follow" target="_blank" href="/7-practical-pandas-tips-when-you-start-working-with-the-library-e4a9205eb443"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">当你开始与图书馆合作时，7 个实用的熊猫提示</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">解释一些乍一看不那么明显的东西…</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="od l ny nz oa nw ob ks nn"/></div></div></a></div></div></div>    
</body>
</html>