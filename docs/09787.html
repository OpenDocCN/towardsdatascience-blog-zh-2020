<html>
<head>
<title>Barriers to Autonomous AI in Healthcare</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">医疗保健中自主人工智能的障碍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/barriers-to-ai-in-healthcare-41892611c84a?source=collection_archive---------38-----------------------#2020-07-11">https://towardsdatascience.com/barriers-to-ai-in-healthcare-41892611c84a?source=collection_archive---------38-----------------------#2020-07-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7713" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">人工智能就在我们身边——它彻底改变了购物、电视和音乐——但它还没有到达医疗保健领域。是什么阻碍了它？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4b4f7742e65f714b0bbba50a8df8b516.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R9JEcG3a-baEGiOn"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">卡尔·比维克在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="4b68" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">简介</strong></h2><p id="83b4" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi ml translated">人工智能在当今社会无处不在——它通过我们的手机与我们交谈，推荐我们观看新的节目，并过滤掉与我们无关的内容。它无处不在，以至于我们大多数人在日常生活中没有理解它在我们生活中的作用。但它还没有像彻底改变我们的购物一样改变医疗保健行业的面貌。这是为什么呢？</p><p id="f732" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">答案不止一个。在我看来，至少有三个很好的理由让你看不到人工智能在医疗保健领域的广泛应用。不过，只要有足够的时间，我相信我们会克服所有这些障碍。</p><p id="a071" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">明确地说，我在这篇文章中讨论的人工智能是那种代替医疗专业人员的人工智能。被动人工智能只是帮助支持提供商的决策过程，已经得到了大量的研究，并改变了我们对待医疗保健的方式。</p><h2 id="7196" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">联邦法规</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/dd90a9e6486851d0ebb96566b7ee45f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9aSoxEc2OIiHA60t"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@tingeyinjurylawfirm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">廷杰伤害律师事务所</a>关于<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>的照片</p></figure><p id="df26" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">人工智能要在医疗保健领域发挥作用，必须克服的最大障碍之一是旨在保护消费者的众多联邦法规。虽然不同国家有许多独特的管理机构，但我将把这个主题的范围缩小到美国 FDA。根据 FDA 的官方指南，医疗器械有几种不同的类别[1，2]。</p><p id="c835" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated"><strong class="lu ir">I 级</strong>—这类设备被定义为<em class="mz">最小风险</em>，也就是说，产品的设计者可以很容易地向 FDA 证明，该设备对消费者没有伤害威胁，或者非常类似于已经获得 FDA 批准的设备。大约 47%的医疗设备属于这一类别。</p><p id="2aae" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated"><strong class="lu ir">第二类</strong>—该类装置定义为<em class="mz">中度风险</em>。大约 43%的医疗设备属于这一类别。你可以将这一类别视为医疗器械，它类似于已有的产品，但具有一些可能伤害消费者的独特功能。这方面的一个例子是电动轮椅，因为它非常类似于<em class="mz">现有技术</em>(即非电动轮椅)，但具有电子元件，如果这些电子元件发生故障，可能会伤害用户。</p><p id="e5d7" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated"><strong class="lu ir">III 类</strong>—这是为对消费者构成<em class="mz">高风险</em>的其余 10%医疗器械保留的。如果这些设备出现故障，可能会导致死亡(例如心脏起搏器)。</p><p id="bf76" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">医疗保健中的自主人工智能应用大多属于第三类。一个护士可以用来识别黑色素瘤而不需要咨询专家的设备？自动检测乳腺癌的算法？一个为医生区分病人优先级的神经网络？都是三级。</p><p id="d113" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">虽然可以说这些例子中的每一个都可以用来帮助医务人员，而不是取代专家，但很难说这些设备是否会超越医疗保健专业人员的判断。当然，放射科医师可以像她应该做的那样手动检查病人的影像，但当工具似乎在大多数时候都是正确的时，她可能会在行使自己的判断时变得自满——这可能会付出生命的代价。</p><p id="12d5" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">但这让我想到了下一个障碍:即使 FDA 批准了这些医疗设备，医疗服务提供者和他们的病人会信任它们吗？</p><h2 id="1849" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">患者和提供者信任度</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/235d0b13548299b465dfdc47bf8f8075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KVq1LaRR0xvpcijR"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@nci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">国立癌症研究所</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="8a4d" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">让我们从医疗保健中一个糟糕的人工智能实施的例子开始。想象你是一名医生。像你的其他同事一样，你花了十几年的时间参加富有挑战性的大学课程，努力完成住院医师培训，或者努力工作以在你的职业中取得成功。经过多年的努力，你终于成功了。你是一家知名医院受人尊敬的医疗保健专家，你经常阅读你所在领域的最新创新，你知道如何优先考虑病人的需求。</p><p id="2b0a" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">突然，你从阅读的许多学术期刊中熟悉的人工智能开始在你的医院中使用。在这种特殊情况下，也许它可以预测病人的住院时间，这样你就可以更好地计划临床试验。你会注意到，有时，它的预测是完全错误的。你甚至开始怀疑算法可能遇到了困扰人工智能的许多问题之一，例如模型漂移。你不信任它，并开始为了自己的利益而推翻它的判断——毕竟，你是医生，这是你学习的目的！你的工作是给你的病人提供极好的护理，但最终，你觉得算法不允许你这么做。</p><blockquote class="nc"><p id="fced" class="nd ne iq bd nf ng nh ni nj nk nl mk dk translated">当人工智能试图为你做更多的工作时，会发生什么？你会相信吗？</p></blockquote><p id="7950" class="pw-post-body-paragraph ls lt iq lu b lv nm jr lx ly nn ju ma lf no mc md lj np mf mg ln nq mi mj mk ij bi translated">上述场景中问题的核心是所描述的模型的不透明性。在那种情况下，算法背后的开发者没有考虑到医生和病人都想知道<em class="mz">为什么</em>以及<em class="mz">什么</em>。即使上述人工智能实现实际上对患者的住院时间进行了非常准确的评估，它也从未试图支持其预测背后的推理。</p><p id="fe66" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">一个更理想的模型应该包含类似 SHAP 值的东西，你可以在 Dataman 博士的这篇优秀文章中读到更多。本质上，它们允许模型提供所谓的<strong class="lu ir">局部特征重要性</strong>，用简单的英语来说，这意味着对为什么<em class="mz">这种特殊情况</em>具有它所具有的预测结果的估计[3]。尽管它不会以任何方式改变算法本身，但它让提供者和患者都能洞察其判断，在医疗保健这样的循证行业中，这是非常宝贵的。</p><blockquote class="nc"><p id="9ef7" class="nd ne iq bd nf ng nh ni nj nk nl mk dk translated">当人工智能解释其决策过程时，患者和提供者更容易信任它。</p></blockquote><p id="b031" class="pw-post-body-paragraph ls lt iq lu b lv nm jr lx ly nn ju ma lf no mc md lj np mf mg ln nq mi mj mk ij bi translated">事实上，人工智能有巨大的能力来帮助临床决策。它能够发现复杂的模式，这些模式只有在综合查看患者数据时才会变得明显——我们不可能合理地期望人类医生检测到的事情。虽然他们不能取代个人医疗保健提供者的位置，但他们可以提供决策支持，并帮助医疗工作者看到他们否则不会注意到的趋势。但是这种决策支持只有在算法自我解释的时候才有可能。</p><h2 id="27d2" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">人工智能驱动的医疗保健的伦理</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/ac971496ee821f6bcb783228d861c80f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OtVnwVAWyUF4SrRW"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">阿诺·弗朗西斯卡在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="1bf7" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">人工智能是一个复杂的话题，不仅在它的实现方面，而且在它给我们带来的伦理困境方面。2015 年，谷歌的机器学习驱动的照片标记器引发了争议，当时它错误地将一名黑人妇女标记为大猩猩[4]。社交媒体的反弹无可非议地巨大。一个简单的错误分类就足以将全世界的目光吸引到人工智能的状态上。发生这样的事情，谁来负责？我们应该如何回应？</p><p id="97a3" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">不幸的是，这样的问题即使在 5 年后也并不少见。就在过去的一个月里，麻省理工学院不得不关闭广泛使用的微型图像数据集，因为在其中发现了种族主义和攻击性的内容[5]。现在使用的算法中有多少是从这些数据中学来的？</p><p id="dff2" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">从表面上看，这些问题可能与医疗保健中的人工智能无关，但我提出它们有几个原因:</p><ol class=""><li id="78e4" class="ns nt iq lu b lv mu ly mv lf nu lj nv ln nw mk nx ny nz oa bi translated">他们证明，即使我们有最好的意图，偏见也可能在我们的模型中表现出来</li><li id="9cdd" class="ns nt iq lu b lv ob ly oc lf od lj oe ln of mk nx ny nz oa bi translated">经常发生的情况是，只有当模型已经发布到世界上并且犯了错误时，这些偏见才变得明显</li></ol><p id="3b9a" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">我们能自信地说这不会发生在医疗保健领域吗？我不相信我们可以。作为研究人员，还有更多的工作要做，以过滤掉我们的数据、我们的预处理技术、我们的模型和我们自己的固有偏见。人工智能在医疗保健领域的最大障碍是<strong class="lu ir">缺乏对任何给定模型在所有潜在用例中的公平性、安全性和有效性的保证。</strong></p><p id="938f" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">已经在努力改善这种状况。像<a class="ae kv" href="https://dssg.github.io/aequitas/" rel="noopener ugc nofollow" target="_blank"> Aequitas </a>这样的库使得开发者比以往任何时候都更容易测试他们的模型和数据的偏差。与此同时，研究人员和开发人员都越来越意识到模型偏差的影响，这将导致检测和处理模型偏差的工具、技术和最佳实践的进一步发展。人工智能可能还没有为今天医疗保健的黄金时间做好准备，但我和其他许多人将努力工作，让它成为现实。只要给予适当的照顾和关注，我相信人工智能有能力改变我们所知的医疗保健的面貌。</p><h2 id="5cb4" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">关于我</h2><p id="7154" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我叫 Josh Cardosi，是一名研究人工智能在医疗保健中的应用的硕士生。你可以在这篇文章中阅读更多关于我是如何来到这里的信息。虽然我上面谈到的问题非常真实，需要解决，但我坚信我们会克服它们，并通过这样做，改善医疗保健状况。我相信这将导致更好的卫生服务利用，降低患者死亡率，并提高患者和提供者对治疗计划的信心。</p><p id="4df8" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">请随时在<a class="ae kv" href="https://www.linkedin.com/in/joshuacardosi/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系。我喜欢阅读你的消息，并谈论医疗保健或机器学习方面的人工智能。</p><h2 id="ed34" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">参考文献</strong></h2><p id="dd69" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">[1] <a class="ae kv" href="https://www.fda.gov/medical-devices/overview-device-regulation/classify-your-medical-device" rel="noopener ugc nofollow" target="_blank">对您的医疗器械进行分类</a> (2020)，美国美国食品药品监督管理局</p><p id="ebd2" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">[2]<a class="ae kv" href="https://www.bmpmedical.com/blog/whats-difference-fda-medical-device-classes-2/" rel="noopener ugc nofollow" target="_blank">FDA 医疗器械分类有什么区别？</a> (2020)，BMP 医疗</p><p id="1b1a" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">[3] Dataman，<a class="ae kv" rel="noopener" target="_blank" href="/explain-your-model-with-the-shap-values-bc36aac4de3d">用 SHAP 价值观</a> (2019)向数据科学解释你的模型</p><p id="322a" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">[4] J. Snow，<a class="ae kv" href="https://www.technologyreview.com/2018/01/11/146257/google-photos-still-has-a-problem-with-gorillas/" rel="noopener ugc nofollow" target="_blank">谷歌照片仍然对大猩猩有问题</a> (2018)，《麻省理工科技评论》</p><p id="798a" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">[5] K. Johnson，<a class="ae kv" href="https://venturebeat.com/2020/07/01/mit-takes-down-80-million-tiny-images-data-set-due-to-racist-and-offensive-content/" rel="noopener ugc nofollow" target="_blank">由于种族主义和攻击性内容，麻省理工学院关闭了 8000 万个微型图像数据集</a> (2020)，Venture Beat</p><p id="fcd9" class="pw-post-body-paragraph ls lt iq lu b lv mu jr lx ly mv ju ma lf mw mc md lj mx mf mg ln my mi mj mk ij bi translated">[6] <a class="ae kv" href="https://dssg.github.io/aequitas/" rel="noopener ugc nofollow" target="_blank">机器学习的偏见和公平审计工具包</a> (2018)，数据科学和公共政策中心</p></div></div>    
</body>
</html>