<html>
<head>
<title>An Introduction to Nine Essential Machine Learning Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">九种基本机器学习算法简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-nine-essential-machine-learning-algorithms-ee0efbb61e0?source=collection_archive---------28-----------------------#2020-04-02">https://towardsdatascience.com/an-introduction-to-nine-essential-machine-learning-algorithms-ee0efbb61e0?source=collection_archive---------28-----------------------#2020-04-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9aa8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">最流行的机器学习模型的直观解释。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bfc00d82d634aa2321ee143432b006fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W5ia8bYCS3ZW3LXxU7wSTQ.png"/></div></div></figure><p id="0131" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="lq">如果这是你喜欢的那种东西，成为第一批订阅</em> </strong> <a class="ae lr" href="https://www.youtube.com/channel/UCmy1ox7bo7zsLlDo8pOEEhA?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="lq">我的新 YouTube 频道在这里</em> </strong> </a> <strong class="kw iu"> <em class="lq">！虽然还没有任何视频，但我会以视频的形式分享很多像这样的精彩内容。感谢大家的支持:)</em> </strong></p></div><div class="ab cl ls lt hx lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="im in io ip iq"><p id="21a9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lr" href="https://medium.com/swlh/predicting-life-expectancy-w-regression-b794ca457cd4" rel="noopener">在我之前的文章</a>中，我解释了什么是<strong class="kw iu">回归</strong>，并展示了如何在应用程序中使用它。本周，我将回顾实践中使用的大多数常见机器学习模型，以便我可以花更多的时间来建立和改进模型，而不是解释其背后的理论。让我们深入研究一下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lz"><img src="../Images/05eb8fa9613c5d2fb4e59d8a2e12d7f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XOAOuTfiPT5hGSLSNRSB4Q.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">机器学习模型的基本分段</p></figure><p id="a35f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所有的机器学习模型被分类为<strong class="kw iu">监督的</strong>或<strong class="kw iu">非监督的</strong>。如果模型是监督模型，那么它被细分为<strong class="kw iu">回归</strong>或<strong class="kw iu">分类</strong>模型。我们将讨论这些术语的含义以及下面每个类别中对应的模型。</p><h1 id="527a" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">监督学习</h1><p id="aff7" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated"><strong class="kw iu">监督学习</strong>涉及学习基于示例输入-输出对将输入映射到输出的函数[1]。</p><p id="cd57" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">例如，如果我有一个包含两个变量的数据集，年龄(输入)和身高(输出)，我可以实现一个监督学习模型，根据年龄预测一个人的身高。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/4469c2929dc4299e691df01aa9d7db83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NhlimsPFBurZKVEJbUN4Vg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">监督学习的例子</p></figure><p id="bc70" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">重复一下，在监督学习中，有两个子类别:回归和分类。</p><h1 id="f2c2" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">回归</h1><p id="c9b0" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">在<strong class="kw iu">回归</strong>模型中，输出是连续的。下面是一些最常见的回归模型。</p><h2 id="5dab" class="nc mf it bd mg nd ne dn mk nf ng dp mo ld nh ni mq lh nj nk ms ll nl nm mu nn bi translated">线性回归</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/fdb1eb19ae2ed98560be41be9391f0af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sOi6uKo3d-OxmA1caVmm0g.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">线性回归的例子</p></figure><p id="4981" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">线性回归的概念就是找到一条最符合数据的直线。线性回归的扩展包括多元线性回归(例如，找到最佳拟合的平面)和多项式回归(例如，找到最佳拟合的曲线)。你可以在我的<a class="ae lr" href="https://medium.com/swlh/predicting-life-expectancy-w-regression-b794ca457cd4" rel="noopener">上一篇文章</a>中了解更多关于线性回归的知识。</p><h2 id="64b9" class="nc mf it bd mg nd ne dn mk nf ng dp mo ld nh ni mq lh nj nk ms ll nl nm mu nn bi translated">决策图表</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/89991e805ee972142726c35a7ffd91c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L9AcBn8WmWN44s-NQiDbOQ.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">图片来自 Kaggle</p></figure><p id="5264" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">决策树</strong>是一种流行的模型，用于运筹学、战略规划和机器学习。上面的每个方块被称为一个<strong class="kw iu">节点</strong>，节点越多，你的决策树就越精确(一般来说)。决策树中做出决策的最后节点被称为树的<strong class="kw iu">叶</strong>。决策树直观且易于构建，但在准确性方面有所欠缺。</p><h2 id="0bb8" class="nc mf it bd mg nd ne dn mk nf ng dp mo ld nh ni mq lh nj nk ms ll nl nm mu nn bi translated">随机森林</h2><p id="b186" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated"><strong class="kw iu">随机森林</strong>是一种基于决策树的<a class="ae lr" href="https://en.wikipedia.org/wiki/Ensemble_learning" rel="noopener ugc nofollow" target="_blank">集成学习</a>技术。随机森林包括使用原始数据的<a class="ae lr" href="https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/" rel="noopener ugc nofollow" target="_blank">自举数据集</a>创建多个决策树，并在决策树的每一步随机选择变量的子集。然后，该模型选择每个决策树的所有预测的模式。这有什么意义？依靠“多数获胜”模型，它降低了单个树出错的风险。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/37d302e5755ad3c13eb03d397cfc0f25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RuglAQsrbJWG49kaXv6tdQ.png"/></div></div></figure><p id="ec9e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">例如，如果我们创建一个决策树，第三个，它会预测 0。但是如果我们依赖所有 4 个决策树的模式，预测值将是 1。这就是随机森林的力量。</p><p id="474b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">StatQuest 做了一项了不起的工作，更详细地说明了这一点。见<a class="ae lr" href="https://www.youtube.com/watch?v=J4Wdy0Wc_xQ&amp;vl=en" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><h2 id="5788" class="nc mf it bd mg nd ne dn mk nf ng dp mo ld nh ni mq lh nj nk ms ll nl nm mu nn bi translated">神经网络</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/9d560ce9742fc78499d8ddcaad9737cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*o2xECsD8cGULb8YucHx_2w.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">神经网络的可视化表示</p></figure><p id="1501" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一个<strong class="kw iu">神经网络</strong>是一个受人脑启发的多层模型。就像我们大脑中的神经元一样，上面的圆圈代表一个节点。蓝色圆圈代表<strong class="kw iu">输入层，</strong>黑色圆圈代表<strong class="kw iu">隐藏层，</strong>绿色圆圈代表<strong class="kw iu">输出层。</strong>隐藏层中的每个节点代表一个功能，输入经过该功能，最终导致绿色圆圈中的输出。</p><p id="b18c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">神经网络实际上是非常复杂和非常数学化的，所以我不会进入它的细节，但…</p><p id="12ac" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">饶彤彤的文章对神经网络背后的过程给出了直观的解释(见<a class="ae lr" rel="noopener" target="_blank" href="/understanding-neural-networks-19020b758230">此处</a>)。</p><p id="f6ae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想更进一步，理解神经网络背后的数学，请点击这里查看这本免费的在线书籍。</p><p id="0d73" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你是一名视觉/音频学习者，3Blue1Brown 在 YouTube 上有一个关于神经网络和深度学习的惊人系列<a class="ae lr" href="https://www.youtube.com/watch?v=aircAruvnKk" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="6cc1" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">分类</h1><p id="03ab" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">在分类模型中，输出是离散的。下面是一些最常见的分类模型。</p><h2 id="9202" class="nc mf it bd mg nd ne dn mk nf ng dp mo ld nh ni mq lh nj nk ms ll nl nm mu nn bi translated">逻辑回归</h2><p id="ea83" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">逻辑回归类似于线性回归，但用于模拟有限数量结果的概率，通常为两个。在对结果的概率建模时，使用逻辑回归而不是线性回归的原因有很多(见<a class="ae lr" href="https://stackoverflow.com/questions/12146914/what-is-the-difference-between-linear-regression-and-logistic-regression" rel="noopener ugc nofollow" target="_blank">这里</a>)。实质上，逻辑方程是以这样一种方式创建的，即输出值只能在 0 和 1 之间(见下文)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/4e1289edda5acd0ce4741587c097e46b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*USrdZ1puaFIIymBRcO51mg.png"/></div></div></figure><h2 id="1f62" class="nc mf it bd mg nd ne dn mk nf ng dp mo ld nh ni mq lh nj nk ms ll nl nm mu nn bi translated">支持向量机</h2><p id="1c28" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">一个<strong class="kw iu">支持向量机</strong>是一种监督分类技术，实际上可以变得非常复杂，但在最基本的层面上非常直观。</p><p id="a327" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们假设有两类数据。支持向量机将找到一个<strong class="kw iu">超平面</strong>或两类数据之间的边界，以最大化两类数据之间的差距(见下文)。有许多平面可以分隔这两个类别，但只有一个平面可以最大化类别之间的边距或距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/d6dbc0b7a28c7c62f684687fd5be0fc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*kTUuRm1tGnEw0dHz.png"/></div></figure><p id="5020" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想了解更多细节，Savan 在这里写了一篇关于支持向量机的文章。</p><h2 id="13d1" class="nc mf it bd mg nd ne dn mk nf ng dp mo ld nh ni mq lh nj nk ms ll nl nm mu nn bi translated">朴素贝叶斯</h2><p id="be07" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">朴素贝叶斯是数据科学中使用的另一种流行的分类器。背后的想法是由贝叶斯定理驱动的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/c4f2916899f51bf70d5882c1a6533a49.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*TqeIPHaO8FPcaSW3FwxH8A.png"/></div></figure><p id="1d5d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虽然有许多关于朴素贝叶斯的不切实际的假设(这就是为什么它被称为‘朴素’)，但它已经被证明在大多数情况下都是有效的，而且构建起来也相对较快。</p><p id="c440" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想了解更多，请点击这里<a class="ae lr" rel="noopener" target="_blank" href="/naive-bayes-classifier-81d512f50a7c"/>。</p><h2 id="e2e0" class="nc mf it bd mg nd ne dn mk nf ng dp mo ld nh ni mq lh nj nk ms ll nl nm mu nn bi translated">决策树，随机森林，神经网络</h2><p id="543b" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">这些模型遵循与前面解释的相同的逻辑。唯一区别是输出是离散的而不是连续的。</p><h1 id="949b" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">无监督学习</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/307a89c0453c3da15af0ac0d702ac587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k0sd5IuawFLNQAbZ-JjKnA.png"/></div></div></figure><p id="713a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">与监督学习不同，<strong class="kw iu">非监督学习</strong>用于从输入数据中进行推断和发现模式，而不参考标记的结果。无监督学习中使用的两种主要方法包括聚类和降维。</p><h1 id="8ff0" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">使聚集</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/114b4d851e53c735225a1778e4274d12.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*lHjMiUUkkQP6EEL4VAQjcA.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">摘自 GeeksforGeeks</p></figure><p id="61c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">聚类是一种无监督的技术，涉及数据点的分组或<strong class="kw iu">聚类</strong>。它经常用于客户细分、欺诈检测和文档分类。</p><p id="e74a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">常见的聚类技术有<strong class="kw iu"> k-means </strong>聚类、<strong class="kw iu">分层</strong>聚类、<strong class="kw iu">均值漂移</strong>聚类、<strong class="kw iu">基于密度的</strong>聚类。虽然每种技术在寻找聚类时有不同的方法，但它们的目标都是一样的。</p><h1 id="2115" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">降维</h1><p id="640f" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">降维是通过获得一组主变量来减少所考虑的随机变量的数量的过程[2]。简单来说，就是减少特性集的维数的过程(更简单来说，就是减少特性的数量)。大多数降维技术可以分为<strong class="kw iu">特征消除</strong>或<strong class="kw iu">特征提取。</strong></p><p id="41d2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一种流行的降维方法叫做<strong class="kw iu">主成分分析。</strong></p><h2 id="8e10" class="nc mf it bd mg nd ne dn mk nf ng dp mo ld nh ni mq lh nj nk ms ll nl nm mu nn bi translated">主成分分析</h2><p id="a2a9" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">从最简单的意义上来说，<strong class="kw iu"> PCA </strong>涉及到将高维数据(如 3 维)投影到更小的空间(如 2 维)。这导致数据的维度降低(2 维而不是 3 维)，同时保持模型中的所有原始变量。</p><p id="4e4a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这涉及到相当多的数学问题。如果你想了解更多…</p><p id="ed31" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">点击查看这篇关于 PCA <a class="ae lr" rel="noopener" target="_blank" href="/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c">的精彩文章。</a></p><p id="68ad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你更想看视频，StatQuest 在 5 分钟内解释 PCA<a class="ae lr" href="https://www.youtube.com/watch?v=HMOI_lkzW08&amp;vl=en" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="6365" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">结论</h1><p id="f877" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">显然，如果你深入到任何特定的模型，都会有大量的复杂性，但这应该会让你对每个机器学习算法是如何工作的有一个基本的了解！</p><p id="c824" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">查看此</em> <a class="ae lr" rel="noopener" target="_blank" href="/basic-statistics-you-need-to-know-for-data-science-1fdd290f59b5"> <strong class="kw iu"> <em class="lq">链接</em> </strong> </a> <em class="lq">如果你想学习</em> <strong class="kw iu"> <em class="lq">所有数据科学的基础统计学。</em> </strong></p><p id="2848" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">看看这个</em><strong class="kw iu"><em class="lq"/></strong><a class="ae lr" rel="noopener" target="_blank" href="/an-extensive-guide-to-exploratory-data-analysis-ddd99a03199e"><strong class="kw iu"><em class="lq">链接</em> </strong> </a> <em class="lq">如果你想学习一个</em> <strong class="kw iu"> <em class="lq">的循序渐进的过程来进行探索性的数据分析(EDA)。</em>T51】</strong></p><h1 id="6466" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">参考</h1><p id="5ea0" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">[1] Stuart J. Russell，Peter Norvig，人工智能:一种现代方法(2010 年)，普伦蒂斯霍尔</p><p id="989e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[2] Roweis，S. T .，Saul，L. K .，通过局部线性嵌入进行非线性降维(2000)，<em class="lq">科学</em></p><h1 id="7582" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">感谢阅读！</h1><p id="7652" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">如果你喜欢我的工作，想支持我…</p><h1 id="dc38" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">感谢阅读！</h1><p id="d1b7" class="pw-post-body-paragraph ku kv it kw b kx mw ju kz la mx jx lc ld my lf lg lh mz lj lk ll na ln lo lp im bi translated">如果你喜欢我的工作，想支持我…</p><ol class=""><li id="9327" class="nw nx it kw b kx ky la lb ld ny lh nz ll oa lp ob oc od oe bi translated">支持我的最好方式就是在<strong class="kw iu">媒体</strong>T2 上关注我。</li><li id="64a1" class="nw nx it kw b kx of la og ld oh lh oi ll oj lp ob oc od oe bi translated">在<strong class="kw iu">推特</strong> <a class="ae lr" href="https://twitter.com/terence_shin" rel="noopener ugc nofollow" target="_blank">这里</a>成为第一批关注我的人之一。我会在这里发布很多更新和有趣的东西！</li><li id="79b1" class="nw nx it kw b kx of la og ld oh lh oi ll oj lp ob oc od oe bi translated">此外，成为第一批订阅我的新<strong class="kw iu"> YouTube 频道</strong> <a class="ae lr" href="https://www.youtube.com/channel/UCmy1ox7bo7zsLlDo8pOEEhA?view_as=subscriber" rel="noopener ugc nofollow" target="_blank">这里</a>！</li><li id="8009" class="nw nx it kw b kx of la og ld oh lh oi ll oj lp ob oc od oe bi translated">在<strong class="kw iu"> LinkedIn </strong> <a class="ae lr" href="https://www.linkedin.com/in/terenceshin/" rel="noopener ugc nofollow" target="_blank">这里</a>关注我。</li><li id="26c2" class="nw nx it kw b kx of la og ld oh lh oi ll oj lp ob oc od oe bi translated">在我的<strong class="kw iu">邮箱列表</strong> <a class="ae lr" href="https://forms.gle/UGdTom9G6aFGHzPD9" rel="noopener ugc nofollow" target="_blank">这里</a>报名。</li><li id="f0cf" class="nw nx it kw b kx of la og ld oh lh oi ll oj lp ob oc od oe bi translated">查看我的网站，<a class="ae lr" href="https://terenceshin.com/" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu">terenceshin.com</strong></a>。</li></ol></div></div>    
</body>
</html>