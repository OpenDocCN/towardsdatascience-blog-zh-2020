<html>
<head>
<title>So I See That You’re Not Wearing a Mask…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我看到你没有戴面具…</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/so-i-see-that-youre-not-wearing-a-mask-6631746c7559?source=collection_archive---------42-----------------------#2020-08-30">https://towardsdatascience.com/so-i-see-that-youre-not-wearing-a-mask-6631746c7559?source=collection_archive---------42-----------------------#2020-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8857" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我如何使用 Keras 制作我的第一个图像分类模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/126645bd6467ddd5baebf625173b7084.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9twUYtLG10q85YMyrwgFw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由盖蒂图片社提供</p></figure><p id="e521" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">图像分类是机器学习中的一个领域，其中使用神经网络对图像数据进行分析。给神经网络一个图像作为输入，并产生图像的分类作为输出。这种分类是用来识别图像的。图像分类在各种各样的领域中使用，其中一些领域包括面部识别和医学成像。</p><p id="032d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们目前经历的艰难时期，我们必须尽一切努力抗击新冠肺炎危机。正是出于这种动机，以及我想了解更多数据科学知识的愿望，我决定尽我所能提供帮助，不管帮助有多小。因此，我决定创建一个图像分类模型，它可以区分戴面具的人和不戴面具的人，希望它可以用来查看人们在人群中的安全程度。这个项目的完整代码可以在我的 Github 上找到。</p><h1 id="ff93" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据收集和处理</h1><p id="d119" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">这些数据包括 4962 张戴或没戴面具的人的照片。这些图像被分成训练和测试目录，每个目录都有一个“带掩码”和“不带掩码”子目录。train 子目录每个都包含 1，735 个图像，在 train 文件夹中总共有 3，470 个图像，而 test 子目录在“with mask”子目录中有 738 个图像，在“with mask”子目录中有 754 个图像，在 test 文件夹中总共有 1，492 个图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/f0df424c5ff9e62f9111a0d58a71f7e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*G-8lkUsbrXULuXXws7uPLw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个戴着面具的人的示例训练图像</p></figure><p id="b25a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些图像被灰度化并重新调整大小，这样在模型分析它们之前，每个图像的大小都是一样的。在这种情况下，图像的大小被调整为 50 乘 50。每张图片都有一个标签，这取决于它们来自哪个目录。</p><p id="6152" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从这里开始，训练数据被扩充，以便创建更多的数据来训练模型。增强在图像分类中是重要的，因为它通过轻微的修改从原始数据创建新的图像。这允许我们指数地增加训练数据的大小，而不必为每个新生成的图像存储新的图像文件。对于这个项目，增强包括水平翻转图像，然后上下左右移动图像。通过将这些增强也应用于已经增强的图像，训练图像的数量增加了 32 倍，给我们总共 111，040 个训练图像。</p><h1 id="0231" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">建模</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/668e3520d4f596b06d027206a3c8f726.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*0YBllrbKr6EkI8OBn0W-hA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">所用模型概述</p></figure><p id="0e66" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">卷积神经网络(CNN)用于对数据建模。CNN 通常在处理图像数据时使用，因为它们的第一层是扫描仪层，该扫描仪层将一组输入(在这种情况下是像素)压缩成池，然后在第一卷积层中用作输入。虽然每个神经网络的结构不同，但在这种情况下，在第一个卷积层之后还有第二个卷积层，接下来是平坦层、密集层，最后是密集层。由于该模型是二元分类器，所以输出是 0 和 1 之间的单个值，这与模型在确定图像中的人是否戴着面具时的置信度有关。然后，这些预测被四舍五入为 0 或 1，以匹配“带屏蔽”和“不带屏蔽”标签的值。神经网络是使用 Tensorflow 的 Keras API 创建的。L2 正则化子用于每个隐层，学习速率为 1e-5。二进制交叉熵被设置为损失度量，Adam 被选择为优化器，而准确性被设置为期望的度量。</p><h1 id="a971" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结果</h1><p id="c93b" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在批次大小为 16 且验证拆分为 20%的模型上执行 5 个时期后，模型预测的结果如下:</p><h2 id="c3ad" class="mu lw it bd lx mv mw dn mb mx my dp mf lh mz na mh ll nb nc mj lp nd ne ml nf bi translated">培训用数据</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/a835b04b2bfd79529bd0a9d78a3f7dc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*ZinRyQFS3wLB5zzVHykMiQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练数据的混淆矩阵</p></figure><p id="187e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 111，040 幅原始和增强图像上，训练数据的总精度性能为 99.94%。然而，我们真正感兴趣的是模型如何在它从未见过的图像上执行。为此，我们来看看测试数据结果。</p><h2 id="9de2" class="mu lw it bd lx mv mw dn mb mx my dp mf lh mz na mh ll nb nc mj lp nd ne ml nf bi translated">测试数据</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/c58999a76aa394a0839d7e398c5488d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*zozMFCpyuADOp_QWZYI1HQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据的混淆矩阵</p></figure><p id="8d37" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 1492 幅原始图像上测试数据的总准确率为 96.45%。在这里我们可以看到，该模型能够以 95%的准确率正确预测戴口罩的人的图像，同时以 98%的准确率预测不戴口罩的人的图像。这种度量是模型在生产中表现如何的更好的度量，因为来自真实世界的图像也是模型以前从未见过的。</p><h1 id="1445" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">未来的工作</h1><p id="b0ce" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">未来的工作将包括创建第三类所谓的“不正确的面具”。这些图像将包括不正确佩戴面具的人，或者露出鼻子，面具在下巴周围，或者挂在耳朵上。这将需要收集足够的图像供模型学习。</p><h1 id="2fa3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">特别感谢</h1><p id="5a4d" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">感谢<a class="ae lu" href="https://github.com/balajisrinivas/Face-Mask-Detection/tree/master/dataset" rel="noopener ugc nofollow" target="_blank"> Balaji Srinivasan </a>和<a class="ae lu" href="https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset" rel="noopener ugc nofollow" target="_blank"> Ashish Jangra </a>收集本项目使用的图像数据。也可参考<a class="ae lu" href="https://www.youtube.com/user/sentdex" rel="noopener ugc nofollow" target="_blank">sendex</a>了解如何处理图像数据。</p></div></div>    
</body>
</html>