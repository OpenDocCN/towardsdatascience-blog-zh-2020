<html>
<head>
<title>Scrape Company Reviews &amp; Ratings from Indeed in 2 Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 2 分钟内从 Indeed 上刮下公司评论和评级</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scrape-company-reviews-ratings-from-indeed-in-2-minutes-59205222d3ae?source=collection_archive---------23-----------------------#2020-08-20">https://towardsdatascience.com/scrape-company-reviews-ratings-from-indeed-in-2-minutes-59205222d3ae?source=collection_archive---------23-----------------------#2020-08-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="1db1" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">网络抓取，数据科学</h2><div class=""/><div class=""><h2 id="91db" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">网上搜集员工在线评论</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/8438f920fd52779d9cc82256bc5ab909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*njNP9GmPfhYL_WSKOet7tQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:来自<a class="ae le" href="https://pixabay.com/vectors/data-black-green-wallpaper-2453751/" rel="noopener ugc nofollow" target="_blank"> pixabay </a>的 ranjithsiji</p></figure><p id="9c3b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本教程中，我将向你展示如何使用<a class="ae le" href="https://www.anaconda.com/" rel="noopener ugc nofollow" target="_blank"> Anaconda </a> Jupyter 笔记本和<a class="ae le" href="https://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>库来执行网络抓取。</p><p id="fefd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们将从 Indeed platform 收集公司评论和评级，然后将它们导出到<a class="ae le" href="http://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Pandas </a> library dataframe，再导出到一个. CSV 文件。</p><p id="5569" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们直接进入正题，然而，如果你正在寻找一个理解网络抓取的指南，我建议你阅读来自<a class="ae le" href="https://www.dataquest.io/blog/web-scraping-tutorial-python/" rel="noopener ugc nofollow" target="_blank"> Dataquest </a>的这篇文章。</p><p id="504e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们从导入我们的 3 个库开始</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="576d" class="mg mh iq mc b gy mi mj l mk ml">from bs4 import BeautifulSoup<br/>import pandas as pd<br/>import requests</span></pre><p id="567d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，让我们去 indeed 网站查看我们想要的信息，我们将针对安永公司的页面，你可以从以下链接查看</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="ce58" class="mg mh iq mc b gy mi mj l mk ml"><a class="ae le" href="https://www.indeed.com/cmp/Ey/reviews?fcountry=IT" rel="noopener ugc nofollow" target="_blank">https://www.indeed.com/cmp/Ey/reviews?fcountry=IT</a></span></pre><p id="cf5f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">根据我的位置，国家是意大利，但你可以选择和控制，如果你想。</p><p id="5d80" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在下一张图中，我们可以看到我们可以处理和收集的多种信息:</p><p id="e9e6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">1-评论标题</p><p id="da18" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">2-审查机构</p><p id="67c3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">三级</p><p id="6d90" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">4-审核者的角色</p><p id="1b8d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">5-审查者的位置</p><p id="769b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">6-审查日期</p><p id="daee" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然而，你可以注意到第 4，5 和 6 点都在一条线上，将被刮到一起，这可能会给一些人造成一点混乱，但我的建议是先刮，然后再解决问题。所以，让我们试着这样做。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mm"><img src="../Images/bdbc4b2c311def85505036b4bb0afff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7KdwpKcJZoGTMtTDQeghlw.png"/></div></div></figure><p id="a10a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在知道了我们要刮什么之后，我们需要弄清楚我们需要刮多少，我们是不是只想要 1 条评论？1 页评论还是所有页面评论？我猜答案应该是全页！！</p><p id="8016" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果您向下滚动页面，转到第 2 页，您会发现该页的链接如下所示:</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="bcf3" class="mg mh iq mc b gy mi mj l mk ml"><a class="ae le" href="https://www.indeed.com/cmp/Ey/reviews?fcountry=IT&amp;start=40" rel="noopener ugc nofollow" target="_blank">https://www.indeed.com/cmp/Ey/reviews?fcountry=IT&amp;start=</a>20</span></pre><p id="028d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后试着进入第 3 页，你会发现链接变成了如下:</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="9474" class="mg mh iq mc b gy mi mj l mk ml"><a class="ae le" href="https://www.indeed.com/cmp/Ey/reviews?fcountry=IT&amp;start=40" rel="noopener ugc nofollow" target="_blank">https://www.indeed.com/cmp/Ey/reviews?fcountry=IT&amp;start=4</a></span></pre><p id="0c1b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">看起来我们这里有一个模式，第 2 页=20，第 3 页= 40，然后第 4 页= 60，对吗？一直到第 8 页= 140</p><p id="5299" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们回到编码，从定义你想要的数据帧开始。</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="9754" class="mg mh iq mc b gy mi mj l mk ml">df = pd.DataFrame({‘review_title’: [],’review’:[],’author’:[],’rating’:[]})</span></pre><p id="bc37" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在下一段代码中，我将创建一个 for 循环，从 0 开始，跳到 20，在 140 停止。</p><p id="6b69" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">1-在 for 循环中，我们将向 web 服务器发出一个<code class="fe mn mo mp mc b">GET</code>请求，它将为我们下载给定网页的 HTML 内容。</p><p id="c62e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">2-然后，我们将使用 BeautifulSoup 库来解析这个页面，并从中提取文本。我们首先必须创建一个<code class="fe mn mo mp mc b">BeautifulSoup</code>类的实例来解析我们的文档</p><p id="f664" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">3-然后通过检查 html，我们从网页中选择类，在抓取时使用类来指定我们想要抓取的特定元素。</p><p id="0f28" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">4-然后我们可以通过将结果添加到之前创建的数据框架中来结束。</p><p id="bdb8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="mq">“我加了一张图下来说明代码应该是怎样的，以防你复制的时候加错了一些空格”</em> </strong></p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="d5a9" class="mg mh iq mc b gy mi mj l mk ml">for i in range(10,140,20):<br/>     url = (f’<a class="ae le" href="https://www.indeed.com/cmp/Ey/reviews?fcountry=IT&amp;start={i}'" rel="noopener ugc nofollow" target="_blank">https://www.indeed.com/cmp/Ey/reviews?fcountry=IT&amp;start={i}'</a>)<br/>     header = {“User-Agent”:”Mozilla/5.0 Gecko/20100101 Firefox/33.0 GoogleChrome/10.0"}<br/>     page = requests.get(url,headers = header)<br/>     soup = BeautifulSoup(page.content, ‘lxml’)<br/>     results = soup.find(“div”, { “id” : ‘cmp-container’})<br/>     elems = results.find_all(class_=’cmp-Review-container’)<br/>     for elem in elems:<br/>         title = elem.find(attrs = {‘class’:’cmp-Review-title’})<br/>         review = elem.find(‘div’, {‘class’: ‘cmp-Review-text’})<br/>         author = elem.find(attrs = {‘class’:’cmp-Review-author’})<br/>         rating = elem.find(attrs = {‘class’:’cmp-ReviewRating-text’})<br/>         df = df.append({‘review_title’: title.text,<br/>          ‘review’: review.text,<br/>        ‘author’: author.text,<br/>          ‘rating’: rating.text<br/>            }, ignore_index=True)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mr"><img src="../Images/fe8949db17b4d1d3c42ba54c541bb248.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l0qRfViSyZfS9KzBpY7QGw.png"/></div></div></figure><p id="1584" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">完成了。让我们检查一下数据框</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="c197" class="mg mh iq mc b gy mi mj l mk ml">df.head()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ms"><img src="../Images/ed0664af1d36a9fc4dafb1f975c42518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Og1hwFRMB7vwJUayydTBZA.png"/></div></div></figure><p id="a897" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，一旦刮，让我们试着解决我们的问题。</p><p id="79cd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">请注意，作者可能有 3 个不同的信息，用(-)分隔</p><p id="620a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所以，让我们把它们分开</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="34ab" class="mg mh iq mc b gy mi mj l mk ml">author = df[‘author’].str.split(‘-’, expand=True)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mt"><img src="../Images/09bf660e0099a4d5da87ba0dacc1adac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4kfkplI4T60HPuu5O1G-GQ.png"/></div></div></figure><p id="58f8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，让我们重命名这些列并删除最后一列。</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="21e0" class="mg mh iq mc b gy mi mj l mk ml">author = author.rename(columns={0: “job”, 1: “location”,2:’time’})</span><span id="9241" class="mg mh iq mc b gy mu mj l mk ml">del author[3]</span></pre><p id="b788" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，让我们将这些新列连接到原始数据框架，并删除旧的 author 列</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="899d" class="mg mh iq mc b gy mi mj l mk ml">df1 = pd.concat([df,author],axis=1)<br/>del df1[‘author’]</span></pre><p id="fdd1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们检查一下新的数据框架</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="514d" class="mg mh iq mc b gy mi mj l mk ml">df1.head()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mv"><img src="../Images/2a3f7b27517653f727f565735bf9e152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4r_jugcL9FhuwFiazlOXHQ.png"/></div></div></figure><p id="f646" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们重新组织这些列并删除任何重复的内容</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="21ab" class="mg mh iq mc b gy mi mj l mk ml">df1 = df1[[‘job’, ‘review_title’, ‘review’, ‘rating’,’location’,’time’]]<br/>df1 = df1.drop_duplicates()</span></pre><p id="c849" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，让我们将数据帧保存到 CSV 文件中</p><pre class="kp kq kr ks gt mb mc md me aw mf bi"><span id="b865" class="mg mh iq mc b gy mi mj l mk ml">df1.to_csv(‘EY_indeed.csv’)</span></pre><p id="a8e1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，您应该对如何从 Indeed 中提取数据有了很好的理解。一个很好的下一步，如果你对网络抓取有点熟悉，你可以选择一个网站，自己尝试一些网络抓取。</p><p id="d9c1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">快乐编码:)</p></div></div>    
</body>
</html>