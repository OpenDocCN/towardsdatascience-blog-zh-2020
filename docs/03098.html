<html>
<head>
<title>Scrape CDC for COVID-19 cases</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">刮疾控中心为新冠肺炎病例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scrape-cdc-for-covid-19-cases-a162924073ad?source=collection_archive---------33-----------------------#2020-03-24">https://towardsdatascience.com/scrape-cdc-for-covid-19-cases-a162924073ad?source=collection_archive---------33-----------------------#2020-03-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="59f1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何为已确认的新冠肺炎病例抓取 javascript 生成的表格</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0fdd9c0ed2a9117558964e5eadd26efb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tF60HgwaFcsvBKro262tCQ.png"/></div></div></figure><p id="8a03" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">鉴于最近发生的事件，我认为获取美国各州确诊病例的数据是个好主意。虽然，CDC 网站因为没有及时更新和落后于实际传播和病例而受到了一定的批评，但由于它是确诊病例的唯一官方来源，它仍然是每天收集数据的一个很好的来源。</p><p id="e8d5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们需要几个库:常见的请求、漂亮的 soup 和 selenium，因为 CDC 网站上的表格是 javascript 生成的。此外，除了 selenium 之外，我们还需要一个驱动程序，我更喜欢 chrome，因为使用 Chrome 更容易检查网站。你可以在这里下载 chromedriver <a class="ae ln" href="https://chromedriver.chromium.org/downloads" rel="noopener ugc nofollow" target="_blank">，确保下载与你的 chrome 浏览器兼容的版本。也正则表达式来清理数据和熊猫创建一个数据帧，并保存为 csv。</a></p><pre class="kg kh ki kj gt lo lp lq lr aw ls bi"><span id="19c1" class="lt lu iq lp b gy lv lw l lx ly">import re<br/>import pandas as pd<br/>import requests<br/>from selenium import webdriver<br/>from bs4 import BeautifulSoup<br/>from selenium.webdriver.support.ui import WebDriverWait<br/>from selenium.webdriver.support import expected_conditions as EC<br/>from selenium.webdriver.common.by import By</span></pre><p id="1efe" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们从用 chrome 驱动程序的显式路径声明 url 和驱动程序变量开始。美丽的汤将解析通过驱动程序的 page_source 和 get_info 函数将返回一个字典与总美国案件和更新日期。</p><pre class="kg kh ki kj gt lo lp lq lr aw ls bi"><span id="3387" class="lt lu iq lp b gy lv lw l lx ly">url = '<a class="ae ln" href="https://www.cdc.gov/coronavirus/2019-ncov/cases-in-us.html'" rel="noopener ugc nofollow" target="_blank">https://www.cdc.gov/coronavirus/2019-ncov/cases-in-us.html'</a></span><span id="c87e" class="lt lu iq lp b gy lz lw l lx ly">driver = webdriver.Chrome(executable_path='/path/to/chromedriver')<br/>    driver.get(url)<br/>wait = WebDriverWait(driver, 10)<br/>soup = BeautifulSoup(driver.page_source, 'html.parser')<br/>dic = get_info(soup)<br/>print(dic)</span></pre><p id="33c5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下面是获取这些数据的函数:</p><pre class="kg kh ki kj gt lo lp lq lr aw ls bi"><span id="aeb3" class="lt lu iq lp b gy lv lw l lx ly">def get_info(info):<br/>    date = info.find('span', class_="text-red").text<br/>    summary = info.find('div', class_ = "2019coronavirus-summary").find_all('li')<br/>    for i in summary:<br/>        dic = {<br/>            'total': summary[0].text,<br/>            'deaths': summary[1].text,<br/>            'jurisdictions': summary[2].text<br/>        }<br/>    dic['date'] = date<br/>    return dic</span></pre><p id="ce49" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请记住，例如，如果类名发生变化，函数可能需要更改。该函数的输出:</p><pre class="kg kh ki kj gt lo lp lq lr aw ls bi"><span id="e057" class="lt lu iq lp b gy lv lw l lx ly">{'total': 'Total cases: 44,183',<br/> 'deaths': 'Total deaths: 544',<br/> 'jurisdictions': 'Jurisdictions reporting cases: 54 (50 states, District of Columbia, Puerto Rico, Guam, and US Virgin Islands)',<br/> 'date': 'Updated March 24, 2020'}</span></pre><p id="bec2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我在 3 月 17 日第一次运行刮刀，我们来比较一下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/81f81f1821a3100dbeacb42634f126fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*8GySHq1S4u2qV7Rh2jqkgw.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">美国新冠肺炎病例总数</p></figure><p id="ef0b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">天哪，这些数字太可怕了，仅在 7 天内，冠状病毒病例数上升了 10 倍，死亡人数上升了 8 倍。认为这些数字可能落后于确诊病例的实际数量，并且有大量患有冠状病毒症状的人由于处于低风险群体而无法进行测试。但是我跑题了，所以为了得到美国各州的病例数，我们需要点击一个按钮来展开表格，用绿色圈起来的那个:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mf"><img src="../Images/79d93de9d1678a32d6ee9eae2118e2b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gjcC1FHr3Fj8X-rHk0VL_g.png"/></div></div></figure><p id="2082" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">由于这是一个 iframe 对象，我们需要切换到 frame，等待数据变得可见，然后我们需要向下滚动页面，以便我们可以收集我们正在寻找的数据:</p><pre class="kg kh ki kj gt lo lp lq lr aw ls bi"><span id="4fcb" class="lt lu iq lp b gy lv lw l lx ly">wait.until(EC.frame_to_be_available_and_switch_to_it("cdcMaps1"))<br/>wait.until(EC.element_to_be_clickable((By.TAG_NAME, 'h3'))).click()<br/>element = driver.find_element_by_tag_name('h3')<br/>driver.execute_script('return arguments[0].scrollIntoView(true);', element)<br/>for table in driver.find_elements_by_xpath('//[<a class="ae ln" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="root"]/section/section/div'):<br/>        header = [item.text for item in table.find_elements_by_xpath('//[<a class="ae ln" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="root"]/section/section/div/div[1]/div[1]')]<br/>        print(header)<br/>for table in driver.find_elements_by_xpath('//[<a class="ae ln" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="root"]/section/section/div'):<br/>        data = [item.text for item in table.find_elements_by_xpath('//[<a class="ae ln" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="root"]/section/section/div/div[1]/div[2]')]<br/>        print(data)</span></pre><p id="7a84" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在上面的代码片段中，在驱动程序向下滚动查看表格后，它通过 xpath 收集表格标题和数据抓取。Xpaths 不容易改变，这允许构建更健壮的 scraper 脚本，selenium 允许我们这样做。不要忘记退出 webdriver，即使你的代码引发了异常，这里是完整的代码:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mg"><img src="../Images/9d9b213e99ef6e56bd8918c9700c70fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*61guEljLWDKosIAheJeAmg.png"/></div></div></figure><p id="89f9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该查询的结果将是一个需要清理并保存到 csv 中的列表。3 月 24 日的数字是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/04032af80048ac57ca10d9263ac9cf78.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*Vl4r4IgqSbcwk4r0qYPpBg.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">2019 年 3 月 24 日州级新冠肺炎案件</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/932591f6270710d403ee50af8e2d8ae3.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*8JXtB99y1WtG5dj7MnpQ9A.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">2019 年 3 月 24 日州级新冠肺炎案例(续)</p></figure><p id="38e5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">谢谢你的时间和阅读我的帖子。一如既往，我们随时欢迎您的反馈和建议。</p></div></div>    
</body>
</html>