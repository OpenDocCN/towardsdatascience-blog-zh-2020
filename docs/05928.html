<html>
<head>
<title>Web Scraping — Make your Own Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网页抓取—制作您自己的数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/web-scraping-make-your-own-dataset-cc973a9f0ee5?source=collection_archive---------21-----------------------#2020-05-15">https://towardsdatascience.com/web-scraping-make-your-own-dataset-cc973a9f0ee5?source=collection_archive---------21-----------------------#2020-05-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/46c9faf3e36b2dac9ab0de2246ed4dab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yZzHv3866AWExxdIz57gYw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图片鸣谢:<a class="ae kf" href="https://www.python.org/about/" rel="noopener ugc nofollow" target="_blank">巨蟒</a>、<a class="ae kf" href="https://requests.readthedocs.io/en/master/" rel="noopener ugc nofollow" target="_blank">请求</a>、<a class="ae kf" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank">巨蟒</a>、<a class="ae kf" href="https://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank">美瞳</a></p></figure><p id="7679" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管有许多资源可以获得所需的数据集，但最好还是有一个自己创建的数据集。在当前新冠肺炎的场景中，我发现了关于<a class="ae kf" href="https://www.worldometers.info/coronavirus/#countries" rel="noopener ugc nofollow" target="_blank">worldometers.com</a>的有趣数据。它显示了一个包含案例总数、已执行测试总数、已关闭案例总数等的表格。该表每天更新。</p><p id="24f2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">出于好奇，我想在自己的数据集中包含这些新冠肺炎数据。在基本 python 库、pandas、numpy 和 BeautifulSoup 的帮助下，我决定将这些数据收集到我自己的数据集中。由于我成功地创建了数据集，我想与大家分享我的故事。因此，我将带你浏览我的笔记本。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><blockquote class="ll lm ln"><p id="fa29" class="kg kh lo ki b kj kk kl km kn ko kp kq lp ks kt ku lq kw kx ky lr la lb lc ld im bi translated"><em class="it">网页抓取是从网页中收集信息的过程</em>。</p></blockquote><p id="8df3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当手动收集大量数据时，需要大量的时间和精力。如果要收集的数据来自定期更新的网页，这将是非常激烈的。因此，最好有一个脚本，它可以自动从网页中提取数据，并以所需的格式存储。</p><p id="8285" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你所需要的是一个 python 包来解析来自网站的 HTML 数据，以表格形式排列它，并做一些数据清理。有几十个软件包可以完成这项工作，但我的故事继续与 BeautifulSoup。</p><p id="d1c5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">美丽组图</strong></p><p id="aac6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它是一个 python 库，使我们能够从网页中抓取所有内容。假设有一个网页包含一些有趣的信息，但没有提供直接下载数据的方法。BeautifulSoup 提供了一套工具来从网页中提取数据，并定位隐藏在 HTML 结构中的内容。</p><p id="81ba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lo">让我们开始创建自己的数据集……</em></p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="f566" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">第一步:安装所需的软件包</strong></p><p id="d8bd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您需要<em class="lo"> requests </em>包，它允许您使用 Python 发送 HTTP 请求。如果你已经预装了，你只需要导入它。否则，您需要使用 pip 安装程序来安装它。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="c58b" class="mb mc it lx b gy md me l mf mg">pip install requests<br/>pip install beautifulsoup4</span></pre><p id="2e78" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我使用 Python 内置的 HTML 解析器将网站输入的文本数据转换成复杂的解析树，可以进一步处理得到所需的数据。如果你想使用不同的解析器，在这里<a class="ae kf" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser" rel="noopener ugc nofollow" target="_blank">你可以找到一个</a>助手。</p><p id="4079" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦你安装了所有的包，把它们导入到你的脚本中。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="f45d" class="mb mc it lx b gy md me l mf mg">import pandas as pd<br/>import numpy as np<br/>import requests<br/>from bs4 import BeautifulSoup</span></pre><p id="485e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">第二步:BeautifulSoup 构造器</strong></p><p id="ebc9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">BeautifulSoup 构造函数接受 2 个输入参数</p><ul class=""><li id="19bc" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">字符串—它是您要解析的标记。这个标记是使用 python <code class="fe mq mr ms lx b">requests</code>包的 get()方法获得的。这个 get()方法返回包含服务器对 HTTP 请求的响应的<code class="fe mq mr ms lx b">requests.Response()</code>对象。此外，此响应对象的 text 方法获取响应的内容。整个字符串作为 BeautifulSoup 构造函数的第一个参数传递。</li><li id="b77e" class="mh mi it ki b kj mt kn mu kr mv kv mw kz mx ld mm mn mo mp bi translated">解析器—它是您想要用来解析标记的方法。您需要提供解析器的名称。我使用了 python 内置的 HTML 解析器。</li></ul><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="35ef" class="mb mc it lx b gy md me l mf mg">website='<a class="ae kf" href="https://www.worldometers.info/coronavirus/#countries'" rel="noopener ugc nofollow" target="_blank">https://www.worldometers.info/coronavirus/#countries'</a><br/>website_url=requests.get(website).text<br/>soup = BeautifulSoup(website_url,'html.parser')</span></pre><p id="94f7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好了..在 3 行代码中，您将所需网页的所有内容都输入到了笔记本中。</p><figure class="ls lt lu lv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi my"><img src="../Images/6389d7584c7453f64adef0223d6173bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMUdUUaJAV8qAc-g2hSTbw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 1:开发者工具中的信息</p></figure><p id="9b56" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">开发者工具中来自元素标签(红色标记)的所有 HTML 文本都将存储在 BeautifulSoup 对象<code class="fe mq mr ms lx b">soup</code>中。如上图 1 所示，当你在元素标签中滚动特定行时，它会在网站的实际表格中高亮显示相应的单元格。</p><p id="d708" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">第三步:熊猫数据框</strong></p><p id="3ae9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了制作 Pandas DataFrame，我们需要将对象<code class="fe mq mr ms lx b">soup</code>中的所有文本数据转换成表格格式。在上面的图片 1 中，我还标记了 3 个绿色矩形。这些是你需要在汤里找到的术语。</p><p id="a2af" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们简单理解一下，这些术语是什么意思—</p><ul class=""><li id="db9e" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated"><code class="fe mq mr ms lx b">&lt;tbody&gt;</code>:指定网页上的表格。</li><li id="351b" class="mh mi it ki b kj mt kn mu kr mv kv mw kz mx ld mm mn mo mp bi translated"><code class="fe mq mr ms lx b">&lt;tr&gt;</code>:指向该表中的特定行。</li><li id="67a5" class="mh mi it ki b kj mt kn mu kr mv kv mw kz mx ld mm mn mo mp bi translated"><code class="fe mq mr ms lx b">&lt;td&gt;</code>:指向该行的特定单元格。</li></ul><p id="8e24" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 python 脚本中，您将使用 object <code class="fe mq mr ms lx b">soup</code>的方法在解析的文本中查找这些术语。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="fc07" class="mb mc it lx b gy md me l mf mg">my_table = soup.find('tbody')</span></pre><p id="6a3f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">变量<code class="fe mq mr ms lx b">my_table</code>将包含网页上的表格，但仍然是 HTML 格式。它包含另外两个术语<code class="fe mq mr ms lx b">&lt;tr&gt;</code>和<code class="fe mq mr ms lx b">&lt;td&gt;</code>，分别指向单独的行和单元格。在下面的代码中，您将把这个<code class="fe mq mr ms lx b">my_table</code>转换成包含列和值的实际表格。</p><p id="11f9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，下面这段代码是 2020 年 4 月写的。稍后，请检查网站上的列的顺序，并相应地修改代码。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="cf77" class="mb mc it lx b gy md me l mf mg">table_data = []</span><span id="6aac" class="mb mc it lx b gy mz me l mf mg">for row in my_table.findAll('tr'):<br/>    row_data = []</span><span id="ca96" class="mb mc it lx b gy mz me l mf mg">    for cell in row.findAll('td'):<br/>        row_data.append(cell.text)</span><span id="023b" class="mb mc it lx b gy mz me l mf mg">    if(len(row_data) &gt; 0):<br/>        data_item = {"Country": row_data[0],<br/>                     "TotalCases": row_data[1],<br/>                     "NewCases": row_data[2],<br/>                     "TotalDeaths": row_data[3],<br/>                     "NewDeaths": row_data[4],<br/>                     "TotalRecovered": row_data[5],<br/>                     "ActiveCases": row_data[6],<br/>                     "CriticalCases": row_data[7],<br/>                     "Totcase1M": row_data[8],<br/>                     "Totdeath1M": row_data[9],<br/>                     "TotalTests": row_data[10],<br/>                     "Tottest1M": row_data[11],<br/>        }<br/>        table_data.append(data_item)</span></pre><p id="bcba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在您得到了<code class="fe mq mr ms lx b">table_data</code>，它实际上是一个包含列和值的表。这个表现在将被转换成一个熊猫数据帧<code class="fe mq mr ms lx b">df</code>。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="c044" class="mb mc it lx b gy md me l mf mg">df = pd.DataFrame(table_data)</span></pre><p id="572d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，在这个数据帧中，所有的列都是 object 类型。此外，这些物品中还有一些不需要的字符，如<code class="fe mq mr ms lx b"> /</code>、<code class="fe mq mr ms lx b">\n</code>、<code class="fe mq mr ms lx b">|</code>、<code class="fe mq mr ms lx b">+</code>。所有常用的数据清理过程现在都可以在上面使用。</p><p id="4bd7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据个人需求，您可以从原始数据帧中提取不同的列和行，根据需求对其进行清理和转换。</p><p id="cbcb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种数据的收集、评估、清理和转换被称为<em class="lo">数据争论</em>过程。这里有一个关于数据争论过程的有趣的可视化快速阅读。</p><div class="na nb gp gr nc nd"><a rel="noopener follow" target="_blank" href="/data-wrangling-raw-to-clean-transformation-b30a27bf4b3b"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd iu gy z fp ni fr fs nj fu fw is bi translated">数据争论—从原始到干净的转变</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">简单的三个字的解释</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr jz nd"/></div></div></a></div><p id="7051" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">第四步:导出到 Excel </strong></p><p id="2795" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，可以使用 pandas 将经过清理和转换的最终数据帧导出到 excel。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="ac59" class="mb mc it lx b gy md me l mf mg">df.to_excel('Covid19_data.xlsx', index=True)</span></pre><p id="f18e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总之，您为新冠肺炎创建了自己的数据集。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="9015" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还可以通过抓取不同的网页来创建多个数据集，并最终将所有数据集组合在一起。想了解更多关于组合不同数据集的信息吗？？</p><p id="04db" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，我有一个关于 Python Pandas 中合并选项的简单的 4 分钟阅读。你需要记住的只是下面文章的最后一张图，解释了所有类型的数据集 join 操作。</p><div class="na nb gp gr nc nd"><a rel="noopener follow" target="_blank" href="/join-the-tables-ab7fd4fac26b"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd iu gy z fp ni fr fs nj fu fw is bi translated">加入表格</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">了解 Python pandas 中的 merge()和 concat()</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="ns l no np nq nm nr jz nd"/></div></div></a></div><p id="8b69" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用 Matplotlib Python 库可以很容易地可视化这种自行创建的数据集，并且可以很容易地定制可视化，如下文所述。</p><div class="na nb gp gr nc nd"><a href="https://medium.com/analytics-vidhya/matplotlib-a-layered-data-visualization-library-870d992ff4b5" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd iu gy z fp ni fr fs nj fu fw is bi translated">matplotlib——一个分层的数据可视化库</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">使用 Matplotlib 了解地块定制的简单方法</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">medium.com</p></div></div><div class="nm l"><div class="nt l no np nq nm nr jz nd"/></div></div></a></div></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="dda7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">通过我的故事……</strong></p><p id="d8b6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我带你通过 4 个简单的步骤将一个网页抓取到一个 excel 表格中。我演示了如何使用简单易用的 BeautifulSoup 包抓取网页，并将这些数据转换成熊猫数据帧。完整的笔记本可以在我的<a class="ae kf" href="https://github.com/17rsuraj/COVID-19_Analyse/blob/master/COVID-19_Data.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>个人资料中找到。</p><p id="38e3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里有一些资源，可以帮助你解决这个问题</p><ul class=""><li id="ce7e" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated"><a class="ae kf" href="https://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank">美丽组图</a></li><li id="4c30" class="mh mi it ki b kj mt kn mu kr mv kv mw kz mx ld mm mn mo mp bi translated"><a class="ae kf" href="https://requests.readthedocs.io/en/master/" rel="noopener ugc nofollow" target="_blank">请求</a></li><li id="6583" class="mh mi it ki b kj mt kn mu kr mv kv mw kz mx ld mm mn mo mp bi translated">熊猫</li><li id="11d2" class="mh mi it ki b kj mt kn mu kr mv kv mw kz mx ld mm mn mo mp bi translated"><a class="ae kf" href="https://developer.ibm.com/technologies/analytics/tutorials/scrape-data-from-the-web-using-watson-studio/" rel="noopener ugc nofollow" target="_blank">网页抓取</a></li></ul></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="d94a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">欢迎您随时提出反馈意见，并通过<a class="ae kf" href="https://www.linkedin.com/in/surajgurav17/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>与我联系！！！</p></div></div>    
</body>
</html>