<html>
<head>
<title>Introduction to Evolution Strategy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">è¿›åŒ–ç­–ç•¥ç®€ä»‹</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/introduction-to-evolution-strategy-1b78b9d48385?source=collection_archive---------27-----------------------#2020-05-03">https://towardsdatascience.com/introduction-to-evolution-strategy-1b78b9d48385?source=collection_archive---------27-----------------------#2020-05-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ec23" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">ç”¨è¿›åŒ–ç­–ç•¥è®­ç»ƒæ— åå‘ä¼ æ’­ç¥ç»ç½‘ç»œ</h2></div><p id="188a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ åœ¨ MNIST æ‰‹å†™æ•°å­—æ•°æ®é›†ä¸Šä½¿ç”¨ Python ä¸­çš„è¿›åŒ–ç­–ç•¥ä»å¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªæ— åå‘ä¼ æ’­çš„ç¥ç»ç½‘ç»œã€‚è¿™ä¸ªç®€å•çš„å®ç°å°†å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£è¿™ä¸ªæ¦‚å¿µï¼Œå¹¶å°†å…¶åº”ç”¨äºå…¶ä»–åˆé€‚çš„è®¾ç½®ã€‚æˆ‘ä»¬å¼€å§‹å§ï¼</p><p id="1868" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">ç›®å½•</strong> <br/> 1ã€‚æ•°å€¼ä¼˜åŒ–<br/> 2ã€‚è¿›åŒ–ç­–ç•¥<br/> 3ã€‚æ™®é€šå®ç°<br/> 4ã€‚Python ä»å¤´å®ç°<br/> 5ã€‚ç»“å°¾æ³¨é‡Š</p><h2 id="3525" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">æ•°å€¼ä¼˜åŒ–</h2><p id="1682" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">å‡ ä¹æ‰€æœ‰çš„æœºå™¨å­¦ä¹ ç®—æ³•éƒ½å¯ä»¥å½’ç»“ä¸ºä¸€ä¸ªä¼˜åŒ–é—®é¢˜ã€‚åœ¨ ML ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬æ›´æ–°æ¨¡å‹çš„å‚æ•°ä»¥æœ€å°åŒ–æŸå¤±ã€‚ä¾‹å¦‚ï¼Œæ¯ä¸ªç›‘ç£å­¦ä¹ ç®—æ³•éƒ½å¯ä»¥å†™æˆï¼ŒÎ¸_ estimate = arg minğ”¼[l(y,f(x,Î¸))]ï¼Œå…¶ä¸­ x å’Œ y åˆ†åˆ«è¡¨ç¤ºç‰¹å¾å’Œç›®æ ‡ï¼ŒÎ¸è¡¨ç¤ºæ¨¡å‹å‚æ•°ï¼Œf è¡¨ç¤ºæˆ‘ä»¬è¯•å›¾å»ºæ¨¡çš„å‡½æ•°ï¼Œl è¡¨ç¤ºæŸå¤±å‡½æ•°ï¼Œå®ƒè¡¡é‡æˆ‘ä»¬çš„æ‹Ÿåˆç¨‹åº¦ã€‚æ¢¯åº¦ä¸‹é™ç®—æ³•ä¹Ÿç§°ä¸ºæœ€é€Ÿä¸‹é™æ³•ï¼Œå·²ç»è¯æ˜åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹å¯ä»¥å¾ˆå¥½åœ°è§£å†³è¿™ç±»é—®é¢˜ã€‚è¿™æ˜¯ä¸€ç§æ±‚å¯å¾®å‡½æ•°å±€éƒ¨æå°å€¼çš„ä¸€é˜¶è¿­ä»£ç®—æ³•ã€‚æˆ‘ä»¬é‡‡å–ä¸å½“å‰ç‚¹çš„æŸå¤±å‡½æ•°çš„æ¢¯åº¦çš„è´Ÿå€¼æˆæ¯”ä¾‹çš„æ­¥é•¿ï¼Œå³Î¸_new = Î¸_old â€” Î±*âˆ‡ L(yï¼Œf(xï¼ŒÎ¸_old))ã€‚ç‰›é¡¿æ³•æ˜¯å¦ä¸€ç§äºŒé˜¶è¿­ä»£æ³•ï¼Œå®ƒä»¥è¾ƒå°‘çš„è¿­ä»£æ¬¡æ•°æ”¶æ•›ï¼Œä½†ç”±äºéœ€è¦è®¡ç®—æŸå¤±å‡½æ•°(æµ·æ£®çŸ©é˜µ)çš„äºŒé˜¶å¯¼æ•°çš„å€’æ•°ï¼Œè®¡ç®—é‡å¾ˆå¤§ï¼Œå³Î¸_new = Î¸_old â€” [âˆ‡ L(yï¼Œf(xï¼ŒÎ¸_old))]^(-1) * âˆ‡ L(yï¼Œf(xï¼ŒÎ¸_old))ã€‚æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨æ¢¯åº¦æœç´¢å‚æ•°ï¼Œå› ä¸ºæˆ‘ä»¬ç›¸ä¿¡å®ƒå°†å¼•å¯¼æˆ‘ä»¬æœç€å‡å°‘æŸå¤±çš„æ–¹å‘å‰è¿›ã€‚ä½†æ˜¯æˆ‘ä»¬èƒ½åœ¨ä¸è®¡ç®—ä»»ä½•æ¢¯åº¦çš„æƒ…å†µä¸‹æœç´¢æœ€ä¼˜å‚æ•°å—ï¼Ÿå…¶å®è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•æœ‰å¾ˆå¤šï¼æœ‰è®¸å¤šä¸åŒçš„æ— å¯¼æ•°ä¼˜åŒ–ç®—æ³•(ä¹Ÿç§°ä¸ºé»‘ç›’ä¼˜åŒ–)ã€‚</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/f5c26854a5fc5956c9c1ffaa5450423c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*i4rXK2RMkuTDbz8totUeOQ.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">æ¥æº:è°·æ­Œå›¾ç‰‡</p></figure><h2 id="84c5" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">è¿›åŒ–ç­–ç•¥</h2><p id="6942" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">æ¢¯åº¦ä¸‹é™ä¸ä¸€å®šæ€»èƒ½è§£å†³æˆ‘ä»¬çš„é—®é¢˜ã€‚ä¸ºä»€ä¹ˆï¼Ÿç®€è€Œè¨€ä¹‹ï¼Œç­”æ¡ˆæ˜¯å±€éƒ¨æœ€ä¼˜ã€‚ä¾‹å¦‚ï¼Œåœ¨å¼ºåŒ–å­¦ä¹ çš„ç¨€ç–å¥–åŠ±åœºæ™¯ä¸­ï¼Œä»£ç†åœ¨ä¸€é›†ç»“æŸæ—¶æ”¶åˆ°å¥–åŠ±ï¼Œå°±åƒåœ¨å›½é™…è±¡æ£‹ä¸­ï¼Œç»“æŸå¥–åŠ±åˆ†åˆ«ä¸ºèµ¢æˆ–è¾“æ¸¸æˆçš„+1 æˆ–-1ã€‚ä¸‡ä¸€æˆ‘ä»¬è¾“æ‰äº†æ¯”èµ›ï¼Œæˆ‘ä»¬å°±ä¸çŸ¥é“æˆ‘ä»¬æ˜¯ç©å¾—å¯æ€•è¿˜æ˜¯åªæ˜¯çŠ¯äº†ä¸€ä¸ªå°é”™è¯¯ã€‚å›æŠ¥æ¢¯åº¦ä¿¡å·å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯æ— ä¿¡æ¯çš„ï¼Œä¼šè®©æˆ‘ä»¬é™·å…¥å›°å¢ƒã€‚æˆ‘ä»¬å¯ä»¥æ±‚åŠ©äºè¯¸å¦‚è¿›åŒ–ç­–ç•¥(es)ä¹‹ç±»çš„æ— å¯¼æ•°æŠ€æœ¯ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å™ªå£°æ¢¯åº¦æ¥æ›´æ–°æˆ‘ä»¬çš„å‚æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»¥åŠåœ¨æˆ‘ä»¬ä¸çŸ¥é“ç›®æ ‡å‡½æ•°çš„ç²¾ç¡®è§£æå½¢å¼æˆ–ä¸èƒ½ç›´æ¥è®¡ç®—æ¢¯åº¦çš„æƒ…å†µä¸‹ï¼ŒES å·¥ä½œå¾—å¾ˆå¥½ã€‚</p><p id="a323" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">åœ¨ OpenAI çš„è¿™ç¯‡<a class="ae mo" href="https://arxiv.org/abs/1703.03864" rel="noopener ugc nofollow" target="_blank">è®ºæ–‡</a>ä¸­ï¼Œä»–ä»¬å±•ç¤ºäº† ES åœ¨åˆ†å¸ƒå¼è®¡ç®—ç¯å¢ƒä¸­æ›´å®¹æ˜“å®ç°å’Œæ‰©å±•ï¼Œå®ƒåœ¨ç¨€ç–å›æŠ¥çš„æƒ…å†µä¸‹ä¸å—å½±å“ï¼Œå¹¶ä¸”å…·æœ‰æ›´å°‘çš„è¶…å‚æ•°ã€‚æ­¤å¤–ï¼Œä»–ä»¬å‘ç°ï¼Œä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ç›¸æ¯”ï¼Œä¸“å®¶ç³»ç»Ÿå‘ç°äº†æ›´å¤šæ ·çš„ç­–ç•¥ã€‚</p><p id="6d0b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ES æ˜¯ä¸€ç§å—è‡ªç„¶å¯å‘çš„ä¼˜åŒ–æ–¹æ³•ï¼Œå®ƒä½¿ç”¨éšæœºçªå˜ã€é‡ç»„å’Œé€‰æ‹©æ¥åº”ç”¨äºåŒ…å«å€™é€‰è§£çš„ä¸ªä½“ç¾¤ä½“ï¼Œä»¥ä¾¿è¿­ä»£åœ°è¿›åŒ–å‡ºæ›´å¥½çš„è§£ã€‚å®ƒå¯¹äºéçº¿æ€§æˆ–éå‡¸çš„è¿ç»­ä¼˜åŒ–é—®é¢˜éå¸¸æœ‰ç”¨ã€‚</p><p id="ad44" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">åœ¨ä¸“å®¶ç³»ç»Ÿä¸­ï¼Œæˆ‘ä»¬ä¸å¤ªå…³å¿ƒå‡½æ•°åŠå…¶ä¸è¾“å…¥æˆ–å‚æ•°çš„å…³ç³»ã€‚æ•°ç™¾ä¸‡ä¸ªæ•°å­—(æ¨¡å‹çš„å‚æ•°)è¿›å…¥ç®—æ³•ï¼Œå¹¶ä¸”å®ƒåå‡º 1 ä¸ªå€¼(ä¾‹å¦‚ï¼Œç›‘ç£è®¾ç½®ä¸­çš„æŸå¤±ï¼›å¼ºåŒ–å­¦ä¹ æƒ…å†µä¸‹çš„å¥–åŠ±)ã€‚æˆ‘ä»¬è¯•å›¾æ‰¾åˆ°è¿™äº›æ•°å­—çš„æœ€ä½³é›†åˆï¼Œä¸ºæˆ‘ä»¬çš„ä¼˜åŒ–é—®é¢˜è¿”å›å¥½çš„å€¼ã€‚æˆ‘ä»¬æ­£åœ¨ä¼˜åŒ–ä¸€ä¸ªå…³äºå‚æ•°Î¸çš„å‡½æ•° J(Î¸)ï¼Œåªæ˜¯é€šè¿‡å¯¹å®ƒæ±‚å€¼ï¼Œè€Œä¸å¯¹ J çš„ç»“æ„åšä»»ä½•å‡è®¾ï¼Œå› æ­¤å‘½åä¸ºâ€œé»‘ç›’ä¼˜åŒ–â€ã€‚ä¸‹é¢å°±æ¥æ·±æŒ–ä¸€ä¸‹å®ç°ç»†èŠ‚å§ï¼</p><h2 id="6306" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">æ™®é€šå®ç°</h2><p id="918f" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">é¦–å…ˆï¼Œæˆ‘ä»¬éšæœºç”Ÿæˆå‚æ•°ï¼Œå¹¶å¯¹å…¶è¿›è¡Œè°ƒæ•´ï¼Œä½¿å‚æ•°ç¨å¾®å·¥ä½œå¾—æ›´å¥½ã€‚æ•°å­¦ä¸Šï¼Œåœ¨æ¯ä¸€æ­¥æˆ‘ä»¬å–ä¸€ä¸ªå‚æ•°å‘é‡Î¸ï¼Œå¹¶é€šè¿‡ç”¨é«˜æ–¯å™ªå£°æŠ–åŠ¨Î¸æ¥äº§ç”Ÿä¸€ç¾¤ï¼Œæ¯”å¦‚è¯´ 100 ä¸ªç¨å¾®ä¸åŒçš„å‚æ•°å‘é‡Î¸â‚,Î¸â‚‚â€¦Î¸â‚â‚€â‚€ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡è¿è¡Œæ¨¡å‹ç‹¬ç«‹è¯„ä¼° 100 ä¸ªå€™é€‰ä¸­çš„æ¯ä¸€ä¸ªï¼Œå¹¶åŸºäºè¾“å‡ºå€¼è¯„ä¼°æŸå¤±æˆ–ç›®æ ‡å‡½æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬é€‰æ‹©å‰ N ä¸ªæ€§èƒ½æœ€ä½³çš„ç²¾è‹±å‚æ•°ï¼ŒN å¯ä»¥æ˜¯ 10ï¼Œå–è¿™äº›å‚æ•°çš„å¹³å‡å€¼ï¼Œç§°ä¹‹ä¸ºæˆ‘ä»¬è¿„ä»Šä¸ºæ­¢çš„æœ€ä½³å‚æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬é‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œé€šè¿‡å°†é«˜æ–¯å™ªå£°æ·»åŠ åˆ°è¿„ä»Šä¸ºæ­¢è·å¾—çš„æœ€ä½³å‚æ•°ä¸­ï¼Œå†æ¬¡ç”Ÿæˆ 100 ä¸ªä¸åŒçš„å‚æ•°ã€‚</p><p id="b34b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ä»è‡ªç„¶é€‰æ‹©çš„è§’åº¦è€ƒè™‘ï¼Œæˆ‘ä»¬æ­£åœ¨éšæœºåˆ›å»ºä¸€ä¸ªå‚æ•°(ç‰©ç§)ç¾¤ä½“ï¼Œå¹¶æ ¹æ®æˆ‘ä»¬çš„ç›®æ ‡å‡½æ•°(ä¹Ÿç§°ä¸ºé€‚åº”åº¦å‡½æ•°)é€‰æ‹©è¡¨ç°è‰¯å¥½çš„é¡¶çº§å‚æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡å–å®ƒä»¬çš„å¹³å‡å€¼æ¥ç»“åˆè¿™äº›å‚æ•°çš„æœ€ä½³è´¨é‡(è¿™æ˜¯ä¸€ç§ç²—ç•¥çš„æ–¹æ³•ï¼Œä½†ä»ç„¶æœ‰æ•ˆï¼)å¹¶ç§°ä¹‹ä¸ºæˆ‘ä»¬çš„æœ€ä½³å‚æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡æ·»åŠ éšæœºå™ªå£°ä½¿è¯¥å‚æ•°çªå˜æ¥é‡å»ºç§ç¾¤ï¼Œå¹¶é‡å¤æ•´ä¸ªè¿‡ç¨‹ç›´åˆ°æ”¶æ•›ã€‚</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mp"><img src="../Images/2d43e471d5f067cafd970c9b4b674203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*seH7JShAa9GBpOeMcCdzjg.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">æ¥æº:æ”¹ç¼–è‡ª Lur ä¸“é¢˜ç™¾ç§‘å…¨ä¹¦ï¼Œé€šè¿‡ç»´åŸºå…±äº«èµ„æº</p></figure><p id="9e06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">ä¼ªç </strong>:</p><ol class=""><li id="f9c0" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒéšæœºåˆå§‹åŒ–æœ€ä½³å‚æ•°</li><li id="2e44" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">å¾ªç¯ç›´è‡³æ”¶æ•›:<br/> â€”é€šè¿‡å°†é«˜æ–¯å™ªå£°æ·»åŠ åˆ°æœ€ä½³å‚æ•°<br/>æ¥åˆ›å»ºå‚æ•°Î¸â‚,Î¸â‚‚â€¦Î¸â‚â‚€â‚€ç¾¤ä½“â€”â€”è¯„ä¼°æ‰€æœ‰å‚æ•°çš„ç›®æ ‡å‡½æ•°å¹¶é€‰æ‹©å‰ n ä¸ªæœ€ä½³æ€§èƒ½å‚æ•°(ç²¾è‹±å‚æ•°)<br/> â€”æœ€ä½³å‚æ•°=å¹³å‡å€¼(å‰ n ä¸ªç²¾è‹±å‚æ•°)<br/> â€”åœ¨æ¯æ¬¡è¿­ä»£ç»“æŸæ—¶ä»¥æŸä¸ªå› å­è¡°å‡å™ªå£°(åœ¨å¼€å§‹æ—¶ï¼Œæ›´å¤šçš„å™ªå£°å°†æœ‰åŠ©äºæˆ‘ä»¬æ›´å¥½åœ°æ¢ç´¢ï¼Œä½†æ˜¯å½“æˆ‘ä»¬åˆ°è¾¾æ”¶æ•›ç‚¹æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›å™ªå£°æœ€å°ä»¥ä¾¿ä¸åç¦»)</li></ol><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ni"><img src="../Images/c3e6bbc8b584c4737acec879784de77d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z9IJyKRG3S5bFtpJJhYlYg.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">æ¥æº:https://en.wikipedia.org/wiki/CMA-ES<a class="ae mo" href="https://en.wikipedia.org/wiki/CMA-ES" rel="noopener ugc nofollow" target="_blank">ã€‚å›¾ç‰‡åŸºäºå°¼å¤æ‹‰Â·æ±‰æ£®å’Œå…¶ä»–äººçš„å·¥ä½œã€‚<br/>çƒå½¢ä¼˜åŒ–æ™¯è§‚ç”¨ f å€¼ç›¸ç­‰çš„å®çº¿æç»˜ã€‚åœ¨è¿™ä¸ªç®€å•çš„ä¾‹å­ä¸­ï¼Œç¾¤ä½“(ç‚¹)åœ¨å‡ æ¬¡è¿­ä»£åé›†ä¸­äºå…¨å±€æœ€ä¼˜ã€‚</a></p></figure><h2 id="3868" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">ä»å¤´å¼€å§‹ Python å®ç°</h2><p id="807d" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">è®©æˆ‘ä»¬é€šè¿‡ Python ä¸­çš„ä¸€ä¸ªç®€å•ä¾‹å­æ¥æ›´å¥½åœ°ç†è§£ã€‚æˆ‘è¯•å›¾æ·»åŠ ä¸€äº›ä¸æ•°å€¼ç¨³å®šæ€§ç›¸å…³çš„ç»†èŠ‚ã€‚è¯·çœ‹è¯„è®ºï¼æˆ‘ä»¬å°†ä»åŠ è½½æ‰€éœ€çš„åº“å’Œ MNIST æ‰‹å†™æ•°å­—æ•°æ®é›†å¼€å§‹ã€‚</p><pre class="md me mf mg gt nj nk nl nm aw nn bi"><span id="3b2a" class="le lf it nk b gy no np l nq nr"># Importing all the required libraries<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import tqdm<br/>import pickle<br/>import warnings<br/>warnings.filterwarnings(â€˜ignoreâ€™)<br/>from keras.datasets import mnist</span><span id="2fd6" class="le lf it nk b gy ns np l nq nr"># Machine Epsilon (needed to calculate logarithms)<br/>eps = np.finfo(np.float64).eps</span><span id="667a" class="le lf it nk b gy ns np l nq nr"># Loading MNIST dataset<br/>(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><span id="b30f" class="le lf it nk b gy ns np l nq nr"># x contains the images (features to our model)<br/># y contains the labels 0 to 9</span><span id="46f6" class="le lf it nk b gy ns np l nq nr"># Normalizing the inputs between 0 and 1<br/>x_train = x_train/255.<br/>x_test = x_test/255.</span><span id="1854" class="le lf it nk b gy ns np l nq nr"># Flattening the image as we are using <br/># dense neural networks<br/>x_train = x_train.reshape( -1, x_train.shape[1]*x_train.shape[2])<br/>x_test = x_test.reshape( -1, x_test.shape[1]*x_test.shape[2])</span><span id="1f97" class="le lf it nk b gy ns np l nq nr"># Converting to one-hot representation<br/>identity_matrix = np.eye(10) <br/>y_train = identity_matrix[y_train]<br/>y_test = identity_matrix[y_test]</span><span id="5f9e" class="le lf it nk b gy ns np l nq nr"># Plotting the images<br/>fig, ax = plt.subplots(2,5)<br/>for i, ax in enumerate(ax.flatten()):<br/> im_idx = np.argwhere(y_train == i)[0]<br/> plottable_image = np.reshape(x_train[im_idx], (28, 28))<br/> ax.set_axis_off()<br/> ax.imshow(plottable_image, cmap=â€™grayâ€™)<br/> <br/>plt.savefig(â€˜mnist.jpgâ€™)</span></pre><p id="5c67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">è¿™æ˜¯å›¾åƒçš„æ ·å­ï¼Œ</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/5f16f73301716ce2f43db30944654828.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*AC_5frNfzl1iSBxE958Ceg.jpeg"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">MNIST æ‰‹å†™æ•°å­—æ•°æ®é›†æ ·æœ¬å›¾åƒ</p></figure><p id="4350" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æˆ‘ä»¬å°†ä»å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹å¼€å§‹ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªåªæœ‰æ­£å‘ä¼ é€’çš„å•å±‚ç¥ç»ç½‘ç»œã€‚</p><pre class="md me mf mg gt nj nk nl nm aw nn bi"><span id="74de" class="le lf it nk b gy no np l nq nr">def soft_max(x):</span><span id="6932" class="le lf it nk b gy ns np l nq nr">'''<br/> Arguments: numpy array<br/> <br/> Returns: numpy array after applying <br/> softmax function to each<br/> element</span><span id="7733" class="le lf it nk b gy ns np l nq nr"> '''<br/> <br/> # Subtracting max of x from each element of x for numerical<br/> # stability as this results in the largest argument to <br/> # exp being 0, ruling out the possibility of overï¬‚ow<br/> # Read more about it at :<br/> # <a class="ae mo" href="https://www.deeplearningbook.org/contents/numerical.html" rel="noopener ugc nofollow" target="_blank">https://www.deeplearningbook.org/contents/numerical.html</a><br/> <br/> e_x = np.exp(x â€” np.max(x))<br/> <br/> return e_x /e_x.sum()</span><span id="8634" class="le lf it nk b gy ns np l nq nr">class Model():</span><span id="a47b" class="le lf it nk b gy ns np l nq nr">'''<br/> Single layer Neural Network<br/> <br/>'''<br/> <br/> def __init__(self, input_shape, n_classes):<br/> <br/> # Number of output classes<br/> self.n_classes = n_classes<br/> <br/> # Parameters/Weights of our network which we will be updating<br/> self.weights = np.random.randn(input_shape, n_classes)<br/> <br/> def forward(self,x):<br/> <br/> '''<br/> Arguments: numpy array containing the features,<br/> expected shape of input array is<br/> (batch size, number of features)<br/> <br/> <br/> Returns: numpy array containing the probability,<br/> expected shape of output array is<br/> (batch size, number of classes)<br/> <br/> '''<br/> <br/> # Multiplying weights with inputs<br/> x = np.dot(x,self.weights)<br/> <br/> # Applying softmax function on each row<br/> x = np.apply_along_axis(soft_max, 1, x)<br/> <br/> return x<br/> <br/> <br/> def __call__(self,x):<br/> <br/> '''<br/> This dunder function<br/> enables your model to be callable<br/> <br/> <br/> When the model is called using model(x),<br/> forward method of the model is called internally<br/> <br/> '''<br/> <br/> return self.forward(x)<br/> <br/> <br/> def evaluate(self, x, y, weights = None):<br/> <br/> '''</span><span id="a8c3" class="le lf it nk b gy ns np l nq nr">Arguments : x â€” numpy array of shape (batch size,number of features),<br/> y â€” numpy array of shape (batch size,number of classes),<br/> weights â€” numpy array containing the parameters of the model<br/> <br/> <br/> Returns : Scalar containing the mean of the categorical cross-entropy loss<br/> of the batch</span><span id="f03c" class="le lf it nk b gy ns np l nq nr">'''<br/> <br/> if weights is not None:<br/> <br/> self.weights = weights<br/> <br/> <br/> # Calculating the negative of cross-entropy loss (since<br/> # we are maximizing this score)<br/> # Adding a small value called epsilon <br/> # to prevent -inf in the output<br/> <br/> log_predicted_y = np.log(self.forward(x) + eps)<br/> <br/> return (log_predicted_y*y).mean()</span></pre><p id="6ce2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æˆ‘ä»¬ç°åœ¨å°†å®šä¹‰æˆ‘ä»¬çš„å‡½æ•°ï¼Œå®ƒå°†ä¸€ä¸ªæ¨¡å‹ä½œä¸ºè¾“å…¥å¹¶æ›´æ–°å®ƒçš„å‚æ•°ã€‚</p><pre class="md me mf mg gt nj nk nl nm aw nn bi"><span id="537e" class="le lf it nk b gy no np l nq nr">def optimize(model,x,y,<br/> top_n = 5, n_pop = 20, n_iter = 10,<br/> sigma_error = 1, error_weight = 1, decay_rate = 0.95,<br/> min_error_weight = 0.01 ):<br/> <br/> '''<br/> Arguments : model â€” Model object(single layer neural network here),<br/> x â€” numpy array of shape (batch size, number of features),<br/> y â€” numpy array of shape (batch size, number of classes),<br/> top_n â€” Number of elite parameters to consider for calculating the<br/> best parameter by taking mean<br/> n_pop â€” Population size of the parameters<br/> n_iter â€” Number of iteration <br/> sigma_error â€” The standard deviation of errors while creating <br/> population from best parameter<br/> error_weight â€” Contribution of error for considering new population<br/> decay_rate â€” Rate at which the weight of the error will reduce after <br/> each iteration, so that we donâ€™t deviate away at the <br/> point of convergence. It controls the balance between <br/> exploration and exploitation<br/> <br/> <br/> <br/> Returns : Model object with updated parameters/weights<br/> <br/> '''<br/> <br/> # Model weights have been randomly initialized at first<br/> best_weights = model.weights<br/> <br/> for i in range(n_iter):<br/> <br/> # Generating the population of parameters<br/> pop_weights = [best_weights + error_weight*sigma_error* \<br/> np.random.randn(*model.weights.shape)<br/> <br/> for i in range(n_pop)]<br/> <br/> <br/> # Evaluating the population of parameters<br/> evaluation_values = [model.evaluate(x,y,weight) for weight in pop_weights]<br/> <br/> # Sorting based on evaluation score<br/> weight_eval_list = zip(evaluation_values, pop_weights)<br/> <br/> weight_eval_list = sorted(weight_eval_list, key = lambda x: x[0], reverse = True)<br/> <br/> evaluation_values, pop_weights = zip(*weight_eval_list)<br/> <br/> # Taking the mean of the elite parameters<br/> best_weights = np.stack(pop_weights[:top_n], axis=0).mean(axis=0)<br/> <br/> #Decaying the weight<br/> error_weight = max(error_weight*decay_rate, min_error_weight)<br/> <br/> model.weights = best_weights<br/> <br/> return model</span><span id="567b" class="le lf it nk b gy ns np l nq nr"># Instantiating our model object<br/>model = Model(input_shape= x_train.shape[-1], n_classes= 10)</span><span id="d244" class="le lf it nk b gy ns np l nq nr">print(â€œEvaluation on training dataâ€, model.evaluate(x_train, y_train))</span><span id="6f09" class="le lf it nk b gy ns np l nq nr"># Running it for 200 steps<br/>for i in tqdm.tqdm(range(200)):<br/> <br/> model = optimize(model, <br/> x_train,<br/> y_train, <br/> top_n = 10, <br/> n_pop = 100,<br/> n_iter = 1)<br/> <br/> print(â€œTest data cross-entropy loss: â€œ, -1*model.evaluate(x_test, y_test))<br/> print(â€œTest Accuracy: â€œ,(np.argmax(model(x_test),axis=1) == y_test).mean())<br/> <br/># Saving the model for later use<br/>with open(â€˜model.pickleâ€™,â€™wbâ€™) as f:<br/> pickle.dump(model,f)</span></pre><p id="fadf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">ç»“æœ</strong>:ç»è¿‡ 200 æ¬¡è¿­ä»£è®­ç»ƒåï¼Œæµ‹è¯•å‡†ç¡®ç‡çº¦ä¸º 85%ï¼Œäº¤å‰ç†µæŸå¤±çº¦ä¸º 0.28ã€‚è¿™ç›¸å½“äºç”¨åå‘ä¼ æ’­è®­ç»ƒçš„å•å±‚ç¥ç»ç½‘ç»œã€‚æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬ç”šè‡³æ²¡æœ‰ä½¿ç”¨ decayï¼Œå› ä¸º n_iter è®¾ç½®ä¸º 1ã€‚</p><h2 id="5d31" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated"><strong class="ak">ç»“å°¾æ³¨é‡Š</strong></h2><p id="c7bd" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">ES å®ç°èµ·æ¥éå¸¸ç®€å•ï¼Œä¸éœ€è¦æ¢¯åº¦ã€‚ä»…ä»…é€šè¿‡å°†å™ªå£°æ³¨å…¥åˆ°æˆ‘ä»¬çš„å‚æ•°ä¸­ï¼Œæˆ‘ä»¬å°±èƒ½å¤Ÿæœç´¢å‚æ•°ç©ºé—´ã€‚å°½ç®¡ä¸ºäº†ä¾¿äºç†è§£ï¼Œæˆ‘ä»¬å·²ç»è§£å†³äº†ä¸€ä¸ªç›‘ç£é—®é¢˜ï¼Œä½†å®ƒæ›´é€‚åˆå¼ºåŒ–å­¦ä¹ åœºæ™¯ï¼Œåœ¨è¿™ç§åœºæ™¯ä¸­ï¼Œäººä»¬å¿…é¡»é€šè¿‡é‡‡æ ·æ¥ä¼°è®¡é¢„æœŸå›æŠ¥çš„æ¢¯åº¦ã€‚</p><p id="8022" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">å¸Œæœ›ä½ å–œæ¬¢é˜…è¯»è¿™ç¯‡æ–‡ç« ï¼</p><p id="ff43" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">æ›´å¤šçš„æŠ€æœ¯åšå®¢ä¹Ÿå¯ä»¥æŸ¥çœ‹æˆ‘çš„ç½‘ç«™:<a class="ae mo" href="https://www.digdeepml.com" rel="noopener ugc nofollow" target="_blank">æ·±æŒ– ML </a></p><p id="66e1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">å‚è€ƒèµ„æ–™å’Œè¿›ä¸€æ­¥é˜…è¯»</strong>:</p><p id="e5fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae mo" href="https://openai.com/blog/evolution-strategies/" rel="noopener ugc nofollow" target="_blank"> OpenAI åšæ–‡</a></p><p id="a3d2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae mo" href="https://blog.otoro.net/2017/10/29/visual-evolution-strategies/" rel="noopener ugc nofollow" target="_blank">å¥¥æ‰˜ç½—çš„åšå®¢</a></p><p id="3651" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae mo" href="https://lilianweng.github.io/lil-log/2019/09/05/evolution-strategies.html" rel="noopener ugc nofollow" target="_blank">è‰è²çš„åšå®¢</a></p></div></div>    
</body>
</html>