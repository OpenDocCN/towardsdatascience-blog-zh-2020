# 解决人工智能安全问题——以及所有其他问题

> 原文：<https://towardsdatascience.com/solving-the-ai-safety-problem-and-all-other-problems-f14b38e721db?source=collection_archive---------61----------------------->

## 激励透明仅仅是个开始

![](img/052326b2d205f0286fc832e58e7aa28b.png)

很多市场。(自创图像)

如果说全球疫情是做任何事情的好时机，那么这也是退一步思考大局问题的好时机。我对病毒了解不多，所以那就不算了。但我确实经营一家小型的 AI 公司，所以我一直在思考 AI 的问题。这是一项具有巨大潜在优势和劣势的技术。我们能做些什么来系统地增加好的方面的可能性和程度，同时对不好的方面做相反的事情吗？我认为是这样的，我认为这很容易做到，而且我认为这完全不同于我们迄今为止一直采用的方法。

人类的每一种需求最终都受到智力的限制。我们似乎受到资源的限制，但实际上地球上有足够多的各种类型的原子来做我们几个世纪以来可能想做的任何事情，在此之后，太空中还有几乎无限数量的原子。我们缺少的是如何最好地配置它们的知识，以及进行配置所必需的机器。正确部署的智能可以解决这两个问题，最终也可以解决所有其他问题。这是能想到的最大的好处。

负面影响也是无限的，我们[知道其中有多少是](https://en.wikipedia.org/wiki/Open_Letter_on_Artificial_Intelligence)。当我们接近或超过“强壮”或“[一般](https://en.wikipedia.org/wiki/Artificial_general_intelligence)”智能的门槛时，大问题分为两类:失控的人工智能和失控的人。

在第一类中，人工智能可以误解我们的意图，并将变量最大化到超出我们预期的程度，[将宇宙变成回形针](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer)或[将云变成肉丸](https://en.wikipedia.org/wiki/Cloudy_with_a_Chance_of_Meatballs_(film))。人工智能可以发展自己的意图，这些意图与我们的意图完全不一致。一个最初友好的可以繁殖的人工智能可以创造出不友好的孩子。在所有这些情况下，人工智能都在做一些没人想让它做的事情。

![](img/be7dad13a2f828ec0ac2409afbb3a8de.png)

够了，谢谢。(查尔斯·隆多，[PublicDomainPictures.net](https://www.publicdomainpictures.net/en/view-image.php?image=41609&picture=paperclips))

即使一个人工智能仍然在它的创造者的控制之下，也不能保证它的创造者的愿望会与整个人类的愿望一致。你仍然可以获得失控的效果，但这是出于社会学而非技术原因——是那些胡作非为的人。第一个到达[智能爆炸](https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion)的团队可以利用他们的优势[统治世界](https://becominghuman.ai/in-the-battle-for-artificial-intelligence-winner-takes-all-4c2447e68237)，就像邪恶博士在火山下的巢穴一样。即使他们不想这么做，他们也将拥有永久不可逾越的优势，因为市场领先地位会带来更多的客户数据，从而带来更大的市场领先优势。即使有最仁慈的新霸主，一小群人控制着世界上最有价值的技术，而其他所有人都被排除在外的局面也是次优的。

[法规](https://www.information-age.com/answer-regulating-ai-123486185/)已经提出，但是那个[不会起作用](https://www.forbes.com/sites/cognitiveworld/2019/03/02/artificial-intelligence-regulation-will-be-impossible/#6f1c844d11ed)，因为任何一套可行的法规要么是无法执行的，要么肯定会适得其反。你不能通过改变法律来阻止邪恶博士的非法行为，这种尝试只会阻碍守法的新兴公司，损害任何对维持现状有既得利益的人的利益。通过监管，你看似可能“实现”的，只是通过降低人工智能被允许的有用程度，来减少劳动力市场的混乱。

解决方案可能是什么样的？

每个人的动机都必须一致。如果有更有吸引力的[理由去做相反的事情](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma)，你就不能期待你想要的行为。如果你想要透明，它必须付费。你确实想要透明，因为它改善了有利和不利的方面——如果每个人都知道其他人在做什么，他们可以建立在彼此的工作基础上，他们可以发现他们是否在做任何危险的事情，无论是故意的还是意外的。

你应该让每个人都参与进来，无论是作为投入的生产者还是产出的消费者。对于消费者来说，这将意味着最大限度地增加在一个地方可用的预建人工智能工具的数量，最大限度地减少使用预先存在的工具的技能障碍，并消除修改这些工具的任何障碍，无论是由消费者还是由其他可以代表消费者修改工具的开发人员修改这些工具。对于生产商来说，你希望能够方便地进入市场，接触到市场中的所有客户——了解人们想要什么，了解已经存在的工具，并能够不断地混合、匹配、生产和再混合，以将供应与需求联系起来。

如果这一切听起来很熟悉，那是因为这就是市场最初应该如何运作。问题是，经济学只预测了真空中的[球形消费者的消费行为](https://en.wikipedia.org/wiki/Spherical_cow)(这同样适用于生产者行为，或者任何其他进入一条平滑的[供需曲线](https://en.wikipedia.org/wiki/Supply_and_demand#Supply_schedule)的因素)。有各种各样的小原因导致这些过于整洁的经济模型[从来没有完全发挥作用](https://en.wikipedia.org/wiki/Efficient-market_hypothesis#Criticism)，但是还有一个很大的原因——信息不对称。

![](img/879a35af493c011b3aa80ee00f73aad6.png)

没有。([维基共享资源](https://commons.wikimedia.org/wiki/File:Supply-and-demand.svg))

一个开放、透明的市场，可以普遍获得关于市场行为的数据，是信息不对称的解药——特别是考虑到，由于这是一个已经在处理数据分析的产品市场，它包含了自我监管的所有工具。然后，它成为效率的引擎——但不是自上而下、模模糊糊的效率观，而是将真正的需求与满足这些需求的可扩展手段相匹配的真正效率。人工智能是强大的，但人工智能的自由和公平市场是一种范式转变。

不可避免的是，当我意识到这一点时，我就开始思考如何建立这样一个市场——拥有完全自由市场的所有可取特征，但在你需要的时候，拥有管理应用商店的所有安全性。事实证明，前进的道路上有许多小障碍，也有许多令人惊讶的附带好处。消费者面临的障碍包括[处理同一个利基问题的竞争性解决方案之间的高层次选择](https://en.wikipedia.org/wiki/Overchoice)，特别是因为评级系统往往是[可玩的](https://www.ftc.gov/news-events/blogs/business-blog/2020/02/ftc-alleges-deception-unbiased-review-sites-ratings-rankings)。然后，有许多方法可以将[微解决方案编译成宏解决方案](https://en.wikipedia.org/wiki/Cloud-based_integration)。所有这一切都导致了长期的哲学问题，即[的目标是追求](https://en.wikipedia.org/wiki/Aristotelian_ethics)，现在可寻址的潜在目标集已经增长。

另一组问题与数据有关。很少有人会说，流行病学数据流向试图控制病毒的人是一件坏事。显而易见，流向广告商的行为数据会成为一个问题——在许多情况下，这是完全相同的数据。答案似乎在于给予这些数据的原创者(通常是个人，有时是组织)某种所有权，以及定义使用权的能力——就像今天版权许可([和 copyleft](https://en.wikipedia.org/wiki/Creative_Commons_license#/media/File:Creative_commons_license_spectrum.svg) )的工作方式一样。这也开启了一个有趣的前景，即人们能够从人工智能公司获得对其聚合数据的许可权中获得可预测的收入。

这些问题有的可以提前用蓝图解决，有的需要一路导航。到目前为止，它们看起来都很容易处理，希望通过发表这篇文章，我可以引起那些最终会和我一起浏览它的人的注意。