<html>
<head>
<title>YOLOv2 Object Detection from ONNX Model in MATLAB</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MATLAB中ONNX模型的YOLOv2物体检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yolov2-object-detection-from-onnx-model-in-matlab-3bb25568aa15?source=collection_archive---------28-----------------------#2020-02-25">https://towardsdatascience.com/yolov2-object-detection-from-onnx-model-in-matlab-3bb25568aa15?source=collection_archive---------28-----------------------#2020-02-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1239" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我如何在MATLAB中导入微小的YOLOv2 ONNX模型，并重新训练网络来检测自定义数据集上的对象</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5aa9bb8365f02203cd058d0c09597531.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2X5YP6ztJ7fg85FuZBw9rw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由恩布里-里德尔的机器人小组提供</p></figure><h1 id="f30a" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">数据集</h1><p id="3da3" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><a class="ae mj" href="https://robonation.org/programs/robosub/" rel="noopener ugc nofollow" target="_blank"> RoboSub </a>是由<a class="ae mj" href="https://robonation.org/" rel="noopener ugc nofollow" target="_blank"> RoboNation </a>举办的一项比赛，学生们建造一个自主水下航行器来执行模拟搜索&amp;救援任务。基本任务是识别和避开水下物体。</p><p id="6147" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">这篇报道所用的图像数据由位于<a class="ae mj" href="https://www.roboticsassociation.org/" rel="noopener ugc nofollow" target="_blank">的Embry-Riddle的RoboSub团队</a>的机器人协会提供。这些图像是在他们的训练过程中用安装在水下机器人上的实时摄像机拍摄的。完整的数据集可以从谷歌硬盘下载。</p><h1 id="350e" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">数据准备</h1><p id="f330" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">所有图像的大小都被调整为(416 x 416 x 3)并被分成训练、测试和验证三个文件夹。然后使用MATLAB中<a class="ae mj" href="https://www.mathworks.com/help/driving/ug/get-started-with-the-ground-truth-labeler.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lp ir"> <em class="mp">地面真实贴标机应用</em> </strong> </a>中的自定义自动化算法对图像进行贴标。要了解更多关于完整标记过程的信息，请参考此<a class="ae mj" href="https://www.youtube.com/watch?v=ow_B_30WU1s&amp;list=PLn8PRpmsu08oLufaYWEvcuez8Rq7q4O7D&amp;index=32&amp;t=0s" rel="noopener ugc nofollow" target="_blank"> YouTube视频</a>。</p><p id="9a88" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">来自地面实况贴标机app的数据以<strong class="lp ir"> <em class="mp">地面实况</em> </strong> <em class="mp"> </em>数据对象的形式导出到MATLAB中。然后使用函数<a class="ae mj" href="https://www.mathworks.com/help/vision/ref/objectdetectortrainingdata.html#bvkrwem-1-trainingData" rel="noopener ugc nofollow" target="_blank"><strong class="lp ir"><em class="mp">objectDetectorTrainingData</em></strong></a><strong class="lp ir"><em class="mp">将其进一步转换为<a class="ae mj" href="https://www.mathworks.com/help/vision/ref/objectdetectortrainingdata.html#bvkrwem-1-trainingData" rel="noopener ugc nofollow" target="_blank">表格</a>。</em> </strong>详细代码文件位于<a class="ae mj" href="https://github.com/mathworks-robotics/deep-learning-for-object-detection-yolov2/tree/master/codeFiles" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><blockquote class="mq mr ms"><p id="3e24" class="ln lo mp lp b lq mk jr ls lt ml ju lv mt mm ly lz mu mn mc md mv mo mg mh mi ij bi translated">注意:下载<a class="ae mj" href="https://drive.google.com/drive/u/0/folders/1bhohhPoZy03ffbM_rl8ZUPSvJ5py8rM-" rel="noopener ugc nofollow" target="_blank">数据</a>并运行数据预处理 <em class="iq">的<a class="ae mj" href="https://github.com/mathworks-robotics/deep-learning-for-object-detection-yolov2/tree/master/codeFiles" rel="noopener ugc nofollow" target="_blank">脚本，然后继续下一步</a></em>。</p></blockquote></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="3496" class="kv kw iq bd kx ky nd la lb lc ne le lf jw nf jx lh jz ng ka lj kc nh kd ll lm bi translated">进口和培训</h1><p id="f3c2" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">本节将介绍导入ONNX模型的步骤，然后根据数据集的类别执行迁移学习。</p><p id="2753" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir">第一步</strong>:从onnx模型动物园导入<a class="ae mj" href="https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/tiny_yolov2" rel="noopener ugc nofollow" target="_blank"> <strong class="lp ir"> <em class="mp">微小的YOLOv2 onnx模型</em></strong></a><strong class="lp ir"><em class="mp"/></strong>。</p><p id="a9ab" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">文件被下载并存储为文件夹中的<strong class="lp ir"> <em class="mp"> model.onnx </em> </strong>。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="e802" class="nn kw iq nj b gy no np l nq nr">modelFile = <strong class="nj ir">fullfile</strong>('Utilities','model.onnx');</span></pre><p id="a4f6" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><a class="ae mj" href="https://www.mathworks.com/help/deeplearning/ref/importonnxnetwork.html?s_tid=doc_ta" rel="noopener ugc nofollow" target="_blank"><strong class="lp ir"><em class="mp">importONNXNetwork</em></strong></a>函数从onnx导入预先训练好的网络。作为函数参数，我传递了<em class="mp"> modelFile </em>和<em class="mp"> 'OutputLayerType" </em></p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="f73c" class="nn kw iq nj b gy no np l nq nr">net = <strong class="nj ir">importONNXNetwork</strong>(modelFile,'OutputLayerType','regression');</span></pre><p id="48d3" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">导入的tiny YOLOv2模型是一个共34层的网络，结合了:<strong class="lp ir"> <em class="mp">输入图像，8组卷积，batchnorm，激活</em> </strong>和<strong class="lp ir"> <em class="mp">合并</em> </strong>层，最后一层为<strong class="lp ir"> <em class="mp">卷积8 </em> </strong>层。我使用<a class="ae mj" href="https://www.mathworks.com/help/deeplearning/ref/analyzenetwork.html" rel="noopener ugc nofollow" target="_blank"> analyzeNetwork </a>函数可视化了网络架构。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="5a31" class="nn kw iq nj b gy no np l nq nr"><strong class="nj ir">analyzeNetwork</strong>(net);</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/5393c92704818f6a3f7987643a2a8d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UO_RvUlQeIJ-RQHtNdjgLQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用网络分析器可视化导入的YOLOv2 Onnx模型。(图片由Neha Goel提供)</p></figure><p id="dfb0" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir">第二步:</strong>根据<em class="mp">训练数据</em>计算<strong class="lp ir">待检测的班级数</strong>和<strong class="lp ir">锚箱</strong>。</p><p id="2eda" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">在这个项目中，我有4个类/对象:<em class="mp">导航门，绿色浮标，红色浮标和黄色浮标。</em></p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="f4a0" class="nn kw iq nj b gy no np l nq nr">numClasses = size(trainingData,2)-1;</span></pre><p id="db4f" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">使用聚类方法计算锚盒。下面的详细过程在这里链接<a class="ae mj" href="https://github.com/mathworks-robotics/deep-learning-for-object-detection-yolov2/blob/master/codeFiles/AnchorBoxes.m" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="0e89" class="nn kw iq nj b gy no np l nq nr">Anchors = [43 59<br/>    18 22<br/>    23 29<br/>    84 109];</span></pre><p id="cc43" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir">第三步:</strong>重新设计并组装YOLOv2网络。</p><p id="2355" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">然后，我根据要检测的类重新设计了导入的网络。我用函数<a class="ae mj" href="https://www.mathworks.com/help/vision/ref/yolov2layers.html?s_tid=doc_ta" rel="noopener ugc nofollow" target="_blank"><strong class="lp ir"><em class="mp">yolov 2 layers</em></strong></a><strong class="lp ir"><em class="mp">实现了它。</em> </strong>它在提取图层的末端添加了一个YOLOv2网络。</p><p id="df93" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">该函数的参数如下:</p><ol class=""><li id="bbe5" class="nt nu iq lp b lq mk lt ml lw nv ma nw me nx mi ny nz oa ob bi translated"><strong class="lp ir">输入大小</strong>:给网络的最小输入大小。这里我给了(128 x 128 x 3)。</li><li id="f81b" class="nt nu iq lp b lq oc lt od lw oe ma of me og mi ny nz oa ob bi translated"><strong class="lp ir">在上述步骤2中计算的等级</strong> ( <em class="mp"> numClasses </em>)和锚的数量</li><li id="7456" class="nt nu iq lp b lq oc lt od lw oe ma of me og mi ny nz oa ob bi translated"><strong class="lp ir">从上述步骤1导入的网络</strong> ( <em class="mp"> net) </em></li><li id="fbc2" class="nt nu iq lp b lq oc lt od lw oe ma of me og mi ny nz oa ob bi translated"><strong class="lp ir">特征提取层</strong>:从该层提取的特征作为输入给YOLOv2目标检测子网络。您可以指定除全连接层之外的任何网络层。这里我使用了<em class="mp"> activation4 </em>命名层的导入网络<em class="mp"> net </em>。</li></ol><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="1feb" class="nn kw iq nj b gy no np l nq nr">lgraph = <strong class="nj ir">yolov2Layers</strong>([128 128 3], numClasses, Anchors, net, 'activation4');</span></pre><p id="7249" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">下图显示了新网络的样子。观察特征层<em class="mp">激活4 </em>后添加在末端的<em class="mp">yolov 2层</em>的高亮子网络。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="5e32" class="nn kw iq nj b gy no np l nq nr"><strong class="nj ir">analyzeNetwork</strong>(lgraph);</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/d7e11f82744f58a72e343ea8a07165b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uZ-AXTJPzoFrZEI6H870aQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">添加yolov 2图层后可视化修改后的网络(图片由Neha Goel提供)</p></figure><p id="87ff" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir">第四步:</strong>训练新网络。</p><p id="e3b2" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">基于数据集的大小，我用求解器训练了网络——随机梯度下降100个时期，初始学习率为0.001，小批量为10。考虑到数据的大小以及调整时期和小批量的大小，我执行了较低的学习速率，以便有更多的时间进行训练。我用来选择选项的文件是:<a class="ae mj" href="https://www.mathworks.com/help/deeplearning/ref/trainingoptions.html?s_tid=doc_ta" rel="noopener ugc nofollow" target="_blank">训练选项</a>。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="ef68" class="nn kw iq nj b gy no np l nq nr">options = <strong class="nj ir">trainingOptions</strong>('sgdm', ...<br/>"LearnRateSchedule","piecewise", ...<br/>'LearnRateDropFactor',0.5,...<br/>"LearnRateDropPeriod",5,...<br/>'Verbose' ,true, 'MiniBatchSize',10,'MaxEpochs',100, ...<br/>'Shuffle','every-epoch', 'VerboseFrequency',50, ...<br/>'DispatchInBackgrpund',true,...<br/>'ExecutionEnvironment','auto');</span></pre><p id="73d8" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">然后我用<a class="ae mj" href="https://www.mathworks.com/help/vision/ref/trainyolov2objectdetector.html" rel="noopener ugc nofollow" target="_blank"><em class="mp">trainyolov 2 object detector</em></a><em class="mp"/>函数<em class="mp"> </em>来训练我的网络。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="943d" class="nn kw iq nj b gy no np l nq nr">[detectorTinyYolo2, info] = <strong class="nj ir">trainYOLOv2ObjectDetector</strong>(trainingData, lgraph,options);</span></pre></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="6585" class="kv kw iq bd kx ky nd la lb lc ne le lf jw nf jx lh jz ng ka lj kc nh kd ll lm bi translated"><strong class="ak">评估&amp;结果</strong></h1><p id="f108" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">一旦我有了训练好的网络，我就按照下面的步骤在测试数据上评估它的性能。</p><p id="587b" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir">步骤1: </strong>创建一个表来保存结果，并初始化一个<a class="ae mj" href="https://www.mathworks.com/help/vision/ref/vision.deployablevideoplayer-system-object.html" rel="noopener ugc nofollow" target="_blank">可部署的视频播放器</a>来查看图像流。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="cdd5" class="nn kw iq nj b gy no np l nq nr">results = <strong class="nj ir">table</strong>('Size',[height(TestData) 3],...<br/>'VariableTypes',{'cell','cell','cell'},...<br/>'VariableNames',{'Boxes','Scores', 'Labels'});</span><span id="3d43" class="nn kw iq nj b gy oi np l nq nr">depVideoPlayer = <strong class="nj ir">vision.DeployableVideoPlayer</strong>;</span></pre><p id="0a8b" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir">步骤2: </strong>遍历测试集中的所有图像。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="ad57" class="nn kw iq nj b gy no np l nq nr">for i = 1:height(<strong class="nj ir">TestData</strong>)<br/>    <em class="mp">% Read the image</em><br/>    I = imread(TestData.imageFilename{i});<br/>    <br/>    <em class="mp">% Run the detector.</em><br/>    [bboxes,scores,labels] = detect(detectorTinyYolo2,I);</span><span id="d26b" class="nn kw iq nj b gy oi np l nq nr">    if ~isempty(bboxes)<br/>         I = <strong class="nj ir">insertObjectAnnotation</strong>(I,'Rectangle',bboxes,cellstr(labels))       <br/>         <br/>         depVideoPlayer(I);<br/>         pause(0.1);<br/>    else<br/>         depVideoPlayer(I);<br/>    end</span><span id="46fb" class="nn kw iq nj b gy oi np l nq nr">    <em class="mp">% Collect the results in the results table</em><br/>    results.Boxes{i} = floor(bboxes);<br/>    results.Scores{i} = scores;<br/>    results.Labels{i} = labels;<br/>end</span><span id="2af2" class="nn kw iq nj b gy oi np l nq nr">threshold =0.3;<br/>expectedResults = TestData;</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/9caa7a94d2973304a18eb71b3623af97.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*o29OWabQp5ySa_Ub0CoNaA.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用可部署的视频播放器，通过测试数据图像循环显示网络检测。(图片由Neha Goel提供)</p></figure><p id="86df" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir">第三步</strong>:评估精度指标。</p><p id="0b39" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">我使用<a class="ae mj" href="https://www.mathworks.com/help/vision/ref/evaluatedetectionprecision.html" rel="noopener ugc nofollow" target="_blank"><em class="mp">evaluateDetectionPrecision</em></a>函数来计算数据点，以便使用给定的输入参数和阈值绘制精度-召回曲线。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="4641" class="nn kw iq nj b gy no np l nq nr">[ap, recall, precision] = <strong class="nj ir">evaluateDetectionPrecision</strong>(results, expectedResults(:,2:end),threshold);</span></pre><p id="84d1" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">绘制每个类的精度指标。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="6104" class="nn kw iq nj b gy no np l nq nr">plot(recall{1,1},precision{1,1},'g-','LineWidth',2, "DisplayName",'greenBuoy');<br/>hold on;<br/>plot(recall{2,1},precision{2,1},'b-','LineWidth',2, "DisplayName",'navGate');<br/>hold on;<br/>plot(recall{3,1},precision{3,1},'r-','LineWidth',2, "DisplayName",'redBuoy');<br/>hold on;<br/>plot(recall{4,1},precision{4,1},'y-','LineWidth',2, "DisplayName",'yellowBuoy');<br/>hold off;</span><span id="4e44" class="nn kw iq nj b gy oi np l nq nr">xlabel('Recall');<br/>ylabel('Precision');<br/>title(sprintf('Average Precision = %.2f\n', ap)<br/>legend('Location', 'best');<br/>legend('boxoff');</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/d56a562bcb1b688fdcee11f0c5d68510.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*yqcmGIv0mDl23_WcUcXDlA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由Neha Goel提供</p></figure><p id="1c50" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated"><strong class="lp ir">步骤4 </strong>:评估目标检测的缺失率指标。</p><p id="2605" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">使用函数<a class="ae mj" href="https://www.mathworks.com/help/vision/ref/evaluatedetectionmissrate.html?s_tid=doc_ta" rel="noopener ugc nofollow" target="_blank"><em class="mp">evaluateDetectionMissRate</em></a><em class="mp"/>I<em class="mp"/>计算<strong class="lp ir"> <em class="mp"> </em> </strong>结果的对数平均缺失率，与地面数据和数据点进行比较。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="3aa6" class="nn kw iq nj b gy no np l nq nr">[am,fppi,missRate] = <strong class="nj ir">evaluateDetectionMissRate</strong>(results, expectedResults(:,2:end),threshold);</span></pre><p id="db69" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">将每个类别的日志未命中率度量标绘为每个图像的误报率。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="b810" class="nn kw iq nj b gy no np l nq nr">loglog(fppi{1,1}, missRate{1,1},'-g','LineWidth',2, "DisplayName",'greenBuoy');<br/>hold on;<br/>loglog(fppi{2,1}, missRate{2,1}, 'b','LineWidth',2,"DisplayName",'navGate');<br/>hold on;<br/>loglog(fppi{3,1}, missRate{3,1},'-r','LineWidth',2, "DisplayName",'redBuoy');<br/>hold on;<br/>loglog(fppi{4,1}, missRate{4,1},'-y','LineWidth',2, "DisplayName",'yellowBuoy');<br/>hold off;</span><span id="b9c4" class="nn kw iq nj b gy oi np l nq nr">xlabel('False Positives Per Image');<br/>ylabel('Log Average Miss Rate');<br/>title(sprintf('Log Average Miss Rate = %.2f\n', am))<br/>legend('Location', 'best');<br/>legend('boxoff');</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/39ee81cb7963e6cda4c977baff051cbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*LRNUCX9qkSzslx3Pfuro3A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由Neha Goel提供</p></figure><p id="6a86" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">正如所观察到的，由于不平衡的等级，对于“<em class="mp"> navGate </em>”等级来说，度量更加准确。人们可以使用<a class="ae mj" href="https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis" rel="noopener ugc nofollow" target="_blank">过采样和欠采样技术</a>来解决类别的不平衡。</p><h2 id="ef5b" class="nn kw iq bd kx om on dn lb oo op dp lf lw oq or lh ma os ot lj me ou ov ll ow bi translated"><strong class="ak">结束语</strong></h2><p id="2a3d" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这个故事的主要目的是介绍一种导入onnx模型并在MATLAB中重新训练定制数据的方法。你可以在这里观看这个故事的视频<a class="ae mj" href="https://www.youtube.com/watch?v=5bnIYH6P-vE&amp;list=PLn8PRpmsu08oLufaYWEvcuez8Rq7q4O7D&amp;index=46&amp;t=0s" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="464a" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">作为下一步的一部分，我在NVIDIA Jetson上部署了这个网络，并在直播摄像机上检测了对象。要了解整个项目的更多信息，可以查看这个GitHub资源库:<a class="ae mj" href="https://github.com/mathworks-robotics/deep-learning-for-object-detection-yolov2" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/mathworks-robotics/deep-learning-for-object-detection-yolov 2</a>。</p></div></div>    
</body>
</html>