<html>
<head>
<title>3 Super Simple Projects to Learn Natural Language Processing using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 学习自然语言处理的 3 个超级简单的项目</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3-super-simple-projects-to-learn-natural-language-processing-using-python-8ef74c757cd9?source=collection_archive---------6-----------------------#2020-05-24">https://towardsdatascience.com/3-super-simple-projects-to-learn-natural-language-processing-using-python-8ef74c757cd9?source=collection_archive---------6-----------------------#2020-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5ec2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">单词云、垃圾邮件检测和情感分析的简单代码示例</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7928e8b1d567d47d15accab22392aaf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*REKXXpifq7ILZaSu"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@siora18?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Siora 摄影</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="a3b9" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是 NLP？</h1><p id="5797" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">从事数据科学工作并有技术写作背景的我被自然语言处理(NLP)领域所吸引。理解语言的机器令我着迷，我经常思考，如果亚里士多德有机会，他会使用哪些算法来建立一个修辞分析机器。如果你是数据科学的新手，进入 NLP 可能看起来很复杂，尤其是因为该领域最近有如此多的进展。很难知道从哪里开始。</p><h1 id="3fe3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">项目和数据</h1><p id="cbdd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这三个超级简单的项目将向您介绍自然语言处理中使用的概念和技术。</p><p id="b5e6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">字云</strong> <br/> <strong class="lt iu">情感分析<br/>垃圾邮件检测</strong></p><p id="0b93" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这些项目使用的数据是垃圾邮件数据集，可以在我的 GitHub 中的所有代码中找到:</p><div class="ms mt gp gr mu mv"><a href="https://github.com/bendgame/nlpBeginnerProjects/blob/master/NLP_beginner_projects.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">bendgame/nlpBeginnerProjects</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">permalink dissolve GitHub 是超过 5000 万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">github.com</p></div></div></div></a></div><h1 id="7643" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">机器能理解什么？</h1><p id="bc40" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">虽然计算机实际上很擅长寻找模式和总结文档，但它必须先将单词转换成数字，然后才能理解它们。这种转变是必要的，因为机器“学习”归功于数学，而数学在文字上不太管用。在将单词转换成数字之前，它们通常会被清除掉特殊字符和标点符号之类的东西，并被修改成更统一、更易解释的形式。</p><h1 id="2e9d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">项目一:词云</h1><p id="ae0b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">清洗单词通常被称为预处理，这是项目 1 的重点:<strong class="lt iu">单词云</strong>。</p><h2 id="1f2e" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">导入依赖项和数据</h2><p id="c780" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">从导入依赖项和数据开始。数据存储为逗号分隔值(csv)文件，所以我将使用 pandas 的<strong class="lt iu"> <em class="nq"> read_csv() </em> </strong>函数将其打开到 DataFrame 中。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="e926" class="ne la it ns b gy nw nx l ny nz">import pandas as pd<br/>import sqlite3<br/>import regex as re<br/>import matplotlib.pyplot as plt<br/>from wordcloud import WordCloud</span><span id="8e35" class="ne la it ns b gy oa nx l ny nz">#create dataframe from csv<br/>df = pd.read_csv('emails.csv')</span><span id="e08c" class="ne la it ns b gy oa nx l ny nz">df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/2226e7ecb5131102efc00d63fd8997bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*4JvjIreXeDceJY7UgfWCpQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">df.head()</p></figure><h2 id="e251" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">探索性分析</h2><p id="11d2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在做任何事情之前，最好对数据进行快速分析，以消除重复的行并建立一些基线计数。我使用 pandas drop_duplicates 来删除重复的行。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="e52e" class="ne la it ns b gy nw nx l ny nz">print("spam count: " +str(len(df.loc[df.spam==1])))<br/>print("not spam count: " +str(len(df.loc[df.spam==0])))<br/>print(df.shape)<br/>df['spam'] = df['spam'].astype(int)<br/><br/>df = df.drop_duplicates()<br/>df = df.reset_index(inplace = False)[['text','spam']]</span><span id="8702" class="ne la it ns b gy oa nx l ny nz">print(df.shape)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/c2bf866e1020769fa523aeaa9fe33103.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/1*PUUUF4VToI7pTYWg5VuXMw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">删除重复之前/之后的计数和形状</p></figure><h2 id="5f8f" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">什么是词云？</h2><p id="f47d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">词云是可视化文本数据的一种有用方式，因为它们使理解词频变得更容易。在电子邮件文本中出现频率更高的单词在云中显得更大。词云使识别“关键词”变得容易</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/f61b1b3f4fdbf1dbb552cc2f3b137e02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e9wIOSYmGClqtrkGnMakbQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">词云示例</p></figure><p id="317a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意在单词云图片中，所有的文字都是小写的。没有标点符号或特殊字符。那是因为文本已经被清理了，以便于分析。使用正则表达式，很容易通过循环来清理文本:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="1c00" class="ne la it ns b gy nw nx l ny nz">clean_desc = []<br/>for w in range(len(df.text)):<br/>    desc = df['text'][w].lower()<br/>    <br/>    #remove punctuation<br/>    desc = re.sub('[^a-zA-Z]', ' ', desc)<br/>    <br/>    #remove tags<br/>    desc=re.sub("&amp;lt;/?.*?&amp;gt;"," &amp;lt;&amp;gt; ",desc)<br/>    <br/>    #remove digits and special chars<br/>    desc=re.sub("(\\d|\\W)+"," ",desc)<br/>    <br/>    clean_desc.append(desc)</span><span id="bc2f" class="ne la it ns b gy oa nx l ny nz">#assign the cleaned descriptions to the data frame<br/>df['text'] = clean_desc<br/>        <br/>df.head(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/e21eb2a91c2a915c6f79c5af6abd3092.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*A61EhwFg3x_ufZ794PJnhA.png"/></div></div></figure><p id="ef28" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意，我创建了一个空列表<strong class="lt iu"> clean_desc </strong>，然后使用一个<em class="nq"> for 循环</em>逐行遍历文本，将其设置为小写，删除标点符号和特殊字符，并将其追加到列表中。然后我用<strong class="lt iu"> clean_desc </strong>列表中的数据替换文本列。</p><h2 id="f5d4" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">停止言语</h2><p id="a5ec" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">停用词是最常见的词，如“the”和“of”将它们从电子邮件文本中删除可以突出更相关的常用词。去掉停用词是常用的技巧！一些 Python 库，比如 NLTK，预加载了一个停用词列表，但是从头开始创建也很容易。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="f24c" class="ne la it ns b gy nw nx l ny nz">stop_words = ['is','you','your','and', 'the', 'to', 'from', 'or', 'I', 'for', 'do', 'get', 'not', 'here', 'in', 'im', 'have', 'on', 're', 'new', 'subject']</span></pre><p id="94e4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请注意，我包含了一些与电子邮件相关的词，如“<em class="nq">回复</em>”和“<em class="nq">主题</em>”由分析师决定应该包含或排除哪些单词。有时候包含所有单词是有益的！</p><h2 id="6d35" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">构造单词 Could</h2><p id="e838" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">方便的是，有一个 Python 库用于创建<a class="ae ky" href="https://github.com/amueller/word_cloud" rel="noopener ugc nofollow" target="_blank">单词云</a>。它可以使用 pip 安装。</p><p id="1d2f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe of og oh ns b">pip install wordcloud</code></p><p id="5622" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当构建单词云时，可以设置几个参数，如高度和宽度、停止单词和最大单词。<a class="ae ky" href="https://github.com/amueller/word_cloud/blob/master/examples/alice.png" rel="noopener ugc nofollow" target="_blank">甚至可以对其进行整形，而不是显示默认的矩形</a>。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="bdc7" class="ne la it ns b gy nw nx l ny nz">wordcloud = WordCloud(width = 800, height = 800, background_color = 'black', stopwords = stop_words, max_words = 1000<br/>                      , min_font_size = 20).generate(str(df1['text']))</span><span id="6f7c" class="ne la it ns b gy oa nx l ny nz">#plot the word cloud<br/>fig = plt.figure(figsize = (8,8), facecolor = None)<br/>plt.imshow(wordcloud)<br/>plt.axis('off')<br/>plt.show()</span></pre><p id="46b6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用<a class="ae ky" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> matplotlib </a>和<strong class="lt iu">可以保存和显示单词云。show() </strong>。这是所有记录的结果，不管它是不是垃圾邮件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/41a3d78d204cb847666a4ae91d9d2e0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*8_qXCI7Vi0aUi_rukPlg6w.png"/></div></figure><p id="1301" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">通过分割数据框和制作两个词云来进一步推动练习，以帮助分析垃圾邮件和非垃圾邮件中使用的关键词之间的差异。</strong></p></div><div class="ab cl oj ok hx ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="im in io ip iq"><h1 id="303a" class="kz la it bd lb lc oq le lf lg or li lj jz os ka ll kc ot kd ln kf ou kg lp lq bi translated">项目 2:垃圾邮件检测</h1><p id="37d8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这是一个二元分类问题，因为电子邮件可能是垃圾邮件(1)，也可能不是垃圾邮件(0)。我想建立一个机器学习模型，可以识别电子邮件是否是垃圾邮件。我将使用 Python 库 Scikit-Learn 来探索<a class="ae ky" href="https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization" rel="noopener ugc nofollow" target="_blank">记号化</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Array_programming" rel="noopener ugc nofollow" target="_blank">矢量化</a>和<a class="ae ky" href="https://en.wikipedia.org/wiki/Statistical_classification" rel="noopener ugc nofollow" target="_blank">统计分类</a>算法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/788950db4e831ff17892c1b69f753d6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*ceiuhmnRfw4D5AQyIfFp7Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.needpix.com/photo/1075588/spam-mail-box-email-3d-render-sign-post-isolated-spam-communication-box" rel="noopener ugc nofollow" target="_blank">needpix.com</a></p></figure><h2 id="b4e7" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">导入依赖项</h2><p id="f318" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">导入转换和建模数据所需的 Scikit-Learn 功能。我将使用<strong class="lt iu">计数矢量器</strong>、<strong class="lt iu">训练 _ 测试 _ 分割</strong>、<strong class="lt iu">集成模型</strong>，以及一些度量标准。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="6005" class="ne la it ns b gy nw nx l ny nz">from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.model_selection import train_test_split<br/>from sklearn import ensemble <br/>from sklearn.metrics import classification_report, accuracy_score</span></pre><h2 id="5dab" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">将文本转换为数字</h2><p id="320d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在项目 1 中，文本被清理。当你看一个词云时，注意它主要是单个的词。单词越大，出现的频率越高。为了防止单词云输出句子，文本要经过一个称为标记化的过程。这是把一个句子分解成单个单词的过程。单个的单词被称为记号。</p><p id="6f25" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用 SciKit-Learn 的<strong class="lt iu"> CountVectorizer() </strong>，可以很容易地将文本主体转换为计算机可以传递给机器学习算法的稀疏数字矩阵。为了简化计数矢量化的概念，假设您有两个句子:</p><blockquote class="ow ox oy"><p id="2f5f" class="lr ls nq lt b lu mn ju lw lx mo jx lz oz mp mc md pa mq mg mh pb mr mk ml mm im bi translated"><em class="it">狗是白色的<br/>猫是黑色的</em></p></blockquote><p id="b5a5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将句子转换为向量空间模型会以这样的方式转换它们，即查看所有句子中的单词，然后用数字表示句子中的单词。</p><blockquote class="ow ox oy"><p id="f38d" class="lr ls nq lt b lu mn ju lw lx mo jx lz oz mp mc md pa mq mg mh pb mr mk ml mm im bi translated"><em class="it">狗猫是白的黑的<br/>狗是白的= [1，1，0，1，1，0] <br/>猫是黑的= [1，0，1，1，0，1] </em></p></blockquote><p id="d18e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们也可以用代码来展示这一点。我将添加第三句话来说明它计算令牌。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="9e27" class="ne la it ns b gy nw nx l ny nz">#list of sentences<br/><strong class="ns iu">text = ["the dog is white", "the cat is black", "the cat and the dog are friends"]</strong></span><span id="764b" class="ne la it ns b gy oa nx l ny nz">#instantiate the class<br/>cv = CountVectorizer()</span><span id="7f6a" class="ne la it ns b gy oa nx l ny nz">#tokenize and build vocab<br/>cv.fit(text)</span><span id="351b" class="ne la it ns b gy oa nx l ny nz">print(cv.vocabulary_)</span><span id="9beb" class="ne la it ns b gy oa nx l ny nz">#transform the text<br/>vector = cv.transform(text)</span><span id="3ebb" class="ne la it ns b gy oa nx l ny nz">print(vector.toarray())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/188189099cd29b648f9b3a6a68badef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GAIRK5QKwymRLJwhgEUf0w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">字数的稀疏矩阵。</p></figure><p id="a5e7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意在最后一个向量中，你可以看到一个 2，因为单词“<em class="nq">和</em>出现了两次。<strong class="lt iu"> CountVectorizer </strong>正在对记号进行计数，并允许我构建包含单词到数字的转换的稀疏矩阵。</p><h2 id="a851" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">词汇袋法</h2><p id="9d81" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">因为该模型没有考虑单词的位置，而是将单词混合起来，就像它们是拼字游戏中的瓷砖一样，这被称为单词袋方法。我将创建稀疏矩阵，然后使用 sk-learn<strong class="lt iu">train _ test _ split()</strong>拆分数据。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="4806" class="ne la it ns b gy nw nx l ny nz"><strong class="ns iu">text_vec</strong> = CountVectorizer().fit_transform(df['text'])</span><span id="2c20" class="ne la it ns b gy oa nx l ny nz">X_train, X_test, y_train, y_test = train_test_split(<strong class="ns iu">text_vec</strong>, <strong class="ns iu">df['spam']</strong>, test_size = 0.45, random_state = 42, shuffle = True)</span></pre><p id="61a3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意，我将稀疏矩阵<strong class="lt iu"> text_vec </strong>设置为 X，将<strong class="lt iu">df[' spam ']【T26]列设置为 y。</strong></p><h2 id="8e17" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">分类器</h2><p id="cd83" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我强烈建议尝试几种分类器，并确定哪一种最适合这个场景。在本例中，<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" rel="noopener ugc nofollow" target="_blank">我使用的是 Scikit-Learn 集合</a>中的<strong class="lt iu">GradientBoostingClassifier()</strong>模型。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="5c79" class="ne la it ns b gy nw nx l ny nz"><strong class="ns iu">classifier </strong>= ensemble.GradientBoostingClassifier(<br/>    n_estimators = 100, #how many decision trees to build<br/>    learning_rate = 0.5, #learning rate<br/>    max_depth = 6<br/>)</span></pre><p id="7c07" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">每个算法都有自己的一套参数，你可以调整。这就是所谓的超参数调整。浏览文档以了解模型中使用的每个参数的更多信息。</p><h2 id="f3d5" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">生成预测</h2><p id="1aa0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后，我们拟合数据，调用预测并生成分类报告。使用<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu">class ification _ report()</strong></a>，很容易构建一个显示主要分类指标的文本报告。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="9182" class="ne la it ns b gy nw nx l ny nz">classifier.fit(X_train, y_train)<br/>predictions = classifier.predict(X_test)</span><span id="2dee" class="ne la it ns b gy oa nx l ny nz">print(classification_report(y_test, predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/cd9239f402195211457ee12e07298156.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*jE08VVkOyTQtAjnBh6WChw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类报告</p></figure><p id="f1cf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意我们的模型达到了 97%的准确率。<strong class="lt iu">通过调整超参数、探索不同的分类器和尝试不同的矢量器来进一步推动练习！</strong></p></div><div class="ab cl oj ok hx ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="im in io ip iq"><h1 id="80e9" class="kz la it bd lb lc oq le lf lg or li lj jz os ka ll kc ot kd ln kf ou kg lp lq bi translated">项目 3:情感分析</h1><p id="8733" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">情感分析也是一种分类问题。这篇文章本质上反映了一种积极的、中立的或消极的情绪。这被称为文本的极性。也有可能衡量和说明文本的主观性！有大量的资源涵盖了情绪分析背后的理论。</p><p id="7d7f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该项目没有构建另一个模型，而是使用一个简单的开箱即用工具来分析名为 TextBlob 的情感。我将使用 TextBlob 向 DataFrame 添加情感列，以便可以对其进行分析。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/c8f157cb152aa2b12749433555afbe44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*3331cCNEezzARb7_L9ZOaQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://pxhere.com/fr/photo/795239" rel="noopener ugc nofollow" target="_blank">表情符号</a></p></figure><h2 id="d440" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">什么是 TextBlob？</h2><p id="773e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Python 2 和 3 的<a class="ae ky" href="https://textblob.readthedocs.io/en/dev/index.html" rel="noopener ugc nofollow" target="_blank"> TextBlob </a>库建立在<a class="ae ky" href="http://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>和<a class="ae ky" href="https://www.clips.uantwerpen.be/pages/pattern-en" rel="noopener ugc nofollow" target="_blank">模式</a>之上，试图简化一些文本处理任务。它提供了分类、词性标注、名词短语提取、情感分析等工具。使用 pip 安装，并查看<a class="ae ky" href="https://textblob.readthedocs.io/en/dev/install.html" rel="noopener ugc nofollow" target="_blank">安装指南</a>。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="7778" class="ne la it ns b gy nw nx l ny nz">pip install -U textblob<br/>python -m textblob.download_corpora</span></pre><h2 id="8805" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">文本 Blob 情感</h2><p id="a425" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">使用<em class="nq">情感</em>属性，TextBlob 返回一个<em class="nq">名为元组</em>的表单情感(极性，主观性)。<strong class="lt iu">极性</strong>是范围[-1.0，1.0]内的浮点数，其中-1 为最大负值，1 为最大正值。<strong class="lt iu">主观性</strong>是在【0.0，1.0】范围内的浮动，其中<strong class="lt iu"> 0.0 非常客观</strong>而<strong class="lt iu"> 1.0 非常主观</strong>。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="2d0e" class="ne la it ns b gy nw nx l ny nz">blob = TextBlob("This is a good example of a TextBlob")<br/>print(blob)blob.sentiment</span><span id="1b47" class="ne la it ns b gy oa nx l ny nz">#Sentiment(polarity=0.7, subjectivity=0.6000000000000001)</span></pre><h2 id="fed1" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">应用 TextBlob</h2><p id="b0df" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">使用<a class="ae ky" rel="noopener" target="_blank" href="/my-trick-to-learning-list-comprehensions-in-python-8a54e66d98b">列表理解</a>，很容易将<strong class="lt iu">文本</strong>列作为 TextBlob 加载，然后创建两个新列来存储<em class="nq">极性</em>和<em class="nq">主观性。</em></p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="ab66" class="ne la it ns b gy nw nx l ny nz">#load the descriptions into textblob<br/>email_blob = [TextBlob(text) for text in df['text']]</span><span id="67b8" class="ne la it ns b gy oa nx l ny nz">#add the sentiment metrics to the dataframe<br/>df['tb_Pol'] = [b.sentiment.polarity for b in email_blob]<br/>df['tb_Subj'] = [b.sentiment.subjectivity for b in email_blob]</span><span id="80ab" class="ne la it ns b gy oa nx l ny nz">#show dataframe<br/>df.head(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/4befc95a8030cb82cc902fafa47e69fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*WlZN97hG9pkxnAGlqzvVbQ.png"/></div></figure><p id="e1ca" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">TextBlob 使生成极性和主观性的基线情感分数变得非常简单。<strong class="lt iu">为了进一步推动这一训练工具，看看您能否将这些新功能添加到垃圾邮件检测模型中，以提高准确性！</strong></p><h1 id="cb62" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">包扎</h1><p id="83ec" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">尽管自然语言处理看起来是一个令人生畏的话题，但基础部分并不难掌握。有大量的库使得开始探索数据科学和 NLP 变得容易。完成这三个项目:</p><p id="96b2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">词云<br/>垃圾邮件检测<br/>情感分析</strong></p><p id="6c79" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您将探索对文本数据应用预处理、标记化、矢量化和特征工程的具体示例。</p><p id="105a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您有兴趣学习更多关于数据科学或编程的知识，请查看我的其他文章！</p><div class="ms mt gp gr mu mv"><a rel="noopener follow" target="_blank" href="/using-functiontransformer-and-pipeline-in-sklearn-to-predict-chardonnay-ratings-9b13fdd6c6fd"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">在 SkLearn 中使用 FunctionTransformer 和 Pipeline 预测 Chardonnay 评级</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">一个将函数转换成可用的管道代码，然后通过传递数据帧来预测葡萄酒评级的例子…</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl ks mv"/></div></div></a></div><h1 id="07e1" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">谢谢大家！</h1><ul class=""><li id="e27a" class="pm pn it lt b lu lv lx ly ma po me pp mi pq mm pr ps pt pu bi translated"><em class="nq">如果你喜欢这个，</em> <a class="ae ky" href="https://medium.com/@erickleppen" rel="noopener"> <em class="nq">在 Medium 上关注我</em> </a> <em class="nq">了解更多</em></li><li id="0dd8" class="pm pn it lt b lu pv lx pw ma px me py mi pz mm pr ps pt pu bi translated"><a class="ae ky" href="https://erickleppen.medium.com/membership" rel="noopener"> <em class="nq">通过订阅</em> </a>获得完全访问权限并帮助支持我的内容</li><li id="43ae" class="pm pn it lt b lu pv lx pw ma px me py mi pz mm pr ps pt pu bi translated"><em class="nq">我们连线上</em><a class="ae ky" href="https://www.linkedin.com/in/erickleppen01/" rel="noopener ugc nofollow" target="_blank"><em class="nq">LinkedIn</em></a></li><li id="d97e" class="pm pn it lt b lu pv lx pw ma px me py mi pz mm pr ps pt pu bi translated"><em class="nq">用 Python 分析数据？查看我的</em> <a class="ae ky" href="https://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <em class="nq">网站</em> </a></li></ul><p id="7f23" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="http://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> —埃里克·克莱本</strong> </a></p></div></div>    
</body>
</html>