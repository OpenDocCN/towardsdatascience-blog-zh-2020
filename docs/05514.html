<html>
<head>
<title>Web-Scraping in 3 Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">3 分钟内完成网页抓取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/web-scraping-in-3-minutes-1c37830a29c1?source=collection_archive---------24-----------------------#2020-05-09">https://towardsdatascience.com/web-scraping-in-3-minutes-1c37830a29c1?source=collection_archive---------24-----------------------#2020-05-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><h1 id="7427" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">简介:</h1><p id="6dd3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">数据，或任何种类的信息，是 21 世纪最宝贵的东西之一。数据是如此强大，以至于可以在许多方面利用它，例如预测未来的销售趋势以获取利润，在医疗保健行业中用于早期诊断结核病，从而挽救患者的生命，等等。因此，从不同来源提取有价值的数据是数据科学家应该掌握的关键技能之一。</p><p id="537e" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">在本文中，我们将学习如何使用 python 中的不同库从网站中提取数据。我们将使用 shorts   <strong class="kq iu"> </strong>网站中的<a class="ae lr" href="https://inshorts.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">来提取与板球、羽毛球和网球等不同运动相关的新闻文章。</strong></a></p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/41d4130127915e8d570dac8f704c0cdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*q9eYGRa_64P_ySJ-"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">照片由<a class="ae lr" href="https://unsplash.com/@rxspawn?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Florian Olivo </a>在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="5829" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">步骤 1:导入相关库</h1><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mi mj l"/></div></figure><h1 id="ef3d" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">步骤 2:用漂亮的汤发出 Web 请求并解析</h1><p id="4247" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们来看看某一类新闻的源代码<strong class="kq iu"> </strong> <a class="ae lr" href="https://inshorts.com/en/read/badminton" rel="noopener ugc nofollow" target="_blank"> <strong class="kq iu">这里</strong> </a> <strong class="kq iu">。</strong></p><p id="e4f3" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">进入这个网页后，我们将看到不同的新闻，让我们集中在一个特定的新闻和它的源代码提取使用美丽的汤。</p><p id="eb95" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">我们可以在右边看到新闻文章及其各自的源代码。我们将使用请求库和使用。在 url 上获取()以从网页访问 HTML 脚本。然后，我们将使用漂亮的 soup 库来解析 python 中的 HTML 语言。然后，进一步根据我们想要提取的信息类型，我们可以使用不同的 html 标签过滤信息，如使用<div>、<span>。find()函数。</span></div></p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mk"><img src="../Images/62c224665cff4dc0203ecb6f6eaa24bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WF_i2E0vYs8nKMUjbHWN9w.png"/></div></div></figure><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mi mj l"/></div></figure><p id="8f4b" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">在完成上述步骤并解析 HTML 语言后，这个特定新闻的部分如下所示</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ml"><img src="../Images/66e110eae1e3db8f27db309842cf7e54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IU3tz_L1FVGJ61Klogn6gg.png"/></div></div></figure><p id="8b59" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">在这种情况下，我们可以看到文章的标题位于这个类下-&lt;<strong class="kq iu">div class = " news-card-title news-right-box "&gt;。</strong>我们可以进一步看到标题存在于带有 attributes= "itemprop "和" headline "的&lt; span &gt;标签中。这可以通过使用。find()函数。</p><pre class="lt lu lv lw gt mm mn mo mp aw mq bi"><span id="3751" class="mr jr it mn b gy ms mt l mu mv">news1=soup.find_all('div', class_=["news-card-title news-right-box"])[0]</span><span id="afd5" class="mr jr it mn b gy mw mt l mu mv">title=news1.find('span',attrs={'itemprop':"headline"}).string</span><span id="10bb" class="mr jr it mn b gy mw mt l mu mv">print(title)</span><span id="098a" class="mr jr it mn b gy mw mt l mu mv">We get the following output given below-</span><span id="9821" class="mr jr it mn b gy mw mt l mu mv">Shuttler Jayaram wins Dutch Open Grand Prix</span></pre><p id="4656" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">同样，如果我们要访问新闻内容，它位于这个类<strong class="kq iu"> &lt;下 div class = " news-card-content news-right-box "&gt;。</strong>我们可以进一步看到新闻的主体在于带有 attributes= "itemprop "和" articleBody "的&lt; div &gt;标签。这可以通过使用。find()函数。</p><pre class="lt lu lv lw gt mm mn mo mp aw mq bi"><span id="6d8c" class="mr jr it mn b gy ms mt l mu mv">news1=soup.find_all('div', class_=["news-card-content news-right-box"])[0]</span><span id="b703" class="mr jr it mn b gy mw mt l mu mv">content=news1.find('div',attrs={'itemprop':"articleBody"}).string</span><span id="a38a" class="mr jr it mn b gy mw mt l mu mv">print(content)</span><span id="9c9f" class="mr jr it mn b gy mw mt l mu mv">Indian Shuttler Ajay Jayaram clinched $50k Dutch Open Grand Prix at Almere in Netherlands on Sunday, becoming the first Indian to win badminton Grand Prix tournament under a new scoring system. Jayaram defeated Indonesia's Ihsan Maulana Mustofa 10-11, 11-6, 11-7, 1-11, 11-9 in an exciting final clash. The 27-year-old returned to the circuit in August after a seven-month injury layoff.</span></pre><p id="d553" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">以类似的方式，我们可以提取任何信息，无论是图像、作者姓名、时间等。</p><h1 id="42af" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">步骤 3:构建数据集</h1><p id="4165" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">让我们为 3 个不同的类别实现这一点，并将所有的文章、各自的内容和类别存储在一个数据框中。在本节中，我们将使用三个不同的 Url，然后我们将对每个 Url 执行相同的过程，并将所有文章、其内容、类别存储到一个列表中。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="mi mj l"/></div></figure><p id="9b94" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">输出-</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mx"><img src="../Images/93ce9b930dfaa01e3dde0ecda4a0ebf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nRXPXwqnV-IVLNS9e7jHnA.png"/></div></div></figure><h1 id="a5a1" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论:</h1><p id="c63c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们可以看到使用漂亮的 soup 库在 python 中实现 web-screwing 是多么容易。使用这种技术，我们可以轻松地收集优秀的数据，以便开始任何数据科学项目。</p><h1 id="6f0d" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">感谢阅读！</h1><p id="8457" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果你喜欢我的工作，想支持我。支持我的最好方式就是在<strong class="kq iu">媒体上关注我。</strong></p></div></div>    
</body>
</html>