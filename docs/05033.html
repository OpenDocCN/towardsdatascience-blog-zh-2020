<html>
<head>
<title>Automating my job search with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python实现求职自动化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automating-my-job-search-with-python-ee2b465c6a8f?source=collection_archive---------11-----------------------#2020-05-01">https://towardsdatascience.com/automating-my-job-search-with-python-ee2b465c6a8f?source=collection_archive---------11-----------------------#2020-05-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8c70" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用美素和硒</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/49a99cfce8204cb39da746b96c6fbf8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*43AOVuONJmcxL_7d78OV2A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:unsplash.com</p></figure><h1 id="c529" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated"><strong class="ak">动机</strong></h1><p id="a369" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我目前正在寻找一个新的数据科学职位，但我发现令人沮丧的是，有这么多不同的网站，在不同的时间列出不同的工作。不断检查每个网站以查看发布了哪些新角色变得很费力。</p><p id="c4f7" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">但后来我想起来了；我是一名数据科学家。一定有更简单的方法来自动化这个过程。因此，我决定创建一个管道，它包括以下步骤，并使用Python自动执行部分流程:</p><h2 id="d187" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated"><strong class="ak"> 1。定期提取所有新的职位发布</strong></h2><p id="1028" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我决定写一些Python代码来从我最常查看的网站上搜集信息。这是我将在这篇文章中概述的。</p><h2 id="64cd" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated"><strong class="ak"> 2。根据我的技能和兴趣查看新的招聘信息</strong></h2><p id="e0c2" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我本来可以尝试自动化这一点，但我不想冒险忽略一个可能因为我放入代码的标准而感兴趣的工作。我决定手动检查我的网页抓取返回的帖子。</p><h2 id="fb5d" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated"><strong class="ak"> 3。每周花一次时间申请符合条件的新工作。</strong></h2><p id="c890" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我听说有人把这个舞台自动化了。然而，我相信如果你花时间和精力来定制应用程序，并且在原则上有点不同意这种方法，机会会更好。</p><p id="4100" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu"> <em class="ne">注:本帖讨论的所有代码在</em> </strong> <a class="ae nd" href="https://github.com/chris-lovejoy/job-scraper" rel="noopener ugc nofollow" target="_blank"> <strong class="ls iu"> <em class="ne">这里</em> </strong> </a> <strong class="ls iu"> <em class="ne">都有。我也在底部分享了我最喜欢的学习资源。</em> </strong></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><p id="797a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我决定使用<strong class="ls iu"> BeautifulSoup </strong>和<strong class="ls iu"> Selenium </strong>，如果需要的话，我的进口声明如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="2cb3" class="ky kz it bd la lb no ld le lf np lh li jz nq ka lk kc nr kd lm kf ns kg lo lp bi translated">来自Indeed.co.uk的工作信息—使用BeautifulSoup</h1><p id="f5c8" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我寻找数据科学工作的主要网站之一是Indeed.co.uk。</p><h2 id="b8ab" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(1)提取初始HTML数据</h2><p id="095d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我很高兴地看到，他们有一个标准化的网址格式，这将使网络抓取更容易。网址是“indeed.co.uk/jobs？”依次为<em class="ne">【q =职位】</em>&amp;<em class="ne">【l =位置】</em>  <em class="ne"> — </em>如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/3f428c2c6a2e80d9a6396e2f703adad8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0yjR8jGsZZ0ZXcGz2coMfw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在伦敦Indeed.co.uk寻找“数据科学家”的工作</p></figure><p id="3ee7" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这使得修改职位名称和位置变得相当容易。我决定创建一个函数，将职位和位置作为参数，这样任何人都可以定制搜索:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="8cd4" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">使用来自<strong class="ls iu"> urllib </strong>的<strong class="ls iu"> urlencode </strong>函数使我能够插入参数来创建完整的url。我在URL中包含了“fromage=list”和“sort=date ”,这样就只显示了最近的工作。</p><p id="1dc4" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然后，在<strong class="ls iu"> BeautifulSoup </strong>的便捷帮助下，我可以提取HTML并适当地解析它。</p><p id="3b02" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">最后，我想找到包含所有工作列表的适当的<div>。我通过打开URL(<em class="ne">indeed.co.uk/jobs?q=data+scientist&amp;l =伦敦</em>)并使用‘Inspect’元素找到了它。使用这个，我可以看到&lt;TD id = " results coll "&gt;包含了所有的工作列表，所以我使用soup . find(id = " results coll ")来选择所有这些工作。</div></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/f54f91586f7825338562e5b02ecb6137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a2vwpSWRtb2rE7jw7js9rw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图:Indeed.co.uk网站</p></figure><h2 id="691d" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(2)提取工作细节</h2><p id="6f49" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在我有了包含所有工作列表的HTML“汤”,下一步是提取我想要的信息，它们是:</p><ul class=""><li id="ff7e" class="nv nw it ls b lt mm lw mn lz nx md ny mh nz ml oa ob oc od bi translated">职位名称</li><li id="3f02" class="nv nw it ls b lt oe lw of lz og md oh mh oi ml oa ob oc od bi translated">这些公司</li><li id="7782" class="nv nw it ls b lt oe lw of lz og md oh mh oi ml oa ob oc od bi translated">完整职务简介的链接</li><li id="0914" class="nv nw it ls b lt oe lw of lz og md oh mh oi ml oa ob oc od bi translated">列出了日期</li></ul><p id="2ad5" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">对于其中的每一个，我再次使用Inspect来识别适当的部分，并使用了<strong class="ls iu">。find() </strong>函数来识别它们，如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h2 id="ccf2" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(3)迭代每个工作列表</h2><p id="f146" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">使用‘Inspect’我看到每个工作卡都包含在一个div中，该div的类为‘jobsearch-SerpJobCard ’,所以我使用了BeautifulSoup的<strong class="ls iu">。find_all </strong>功能如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="2b13" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然后，对于每张卡，我想提取上面列出的4条关键信息，并将它们保存在一个列表中。</p><p id="9a1f" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我想让我的函数通用化，这样人们可以选择他们想要搜索的特征(在列出的职位、公司、链接和日期之外)，所以我创建了一个列表‘desired _ characts’来指定这一点。</p><p id="e67b" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">对于每个特征，我循环并将其添加到列表中，如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="3f57" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">最后，我将所有这些放入一个jobs_list中，然后可以导出为所选的格式Excel、DataFrame或其他格式:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="c604" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">使用“cols”使我能够根据提取的特征为jobs_list字典的每个键指定标题。</p><p id="6b00" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">“extracted_info”是一个列表列表；例如，每个列表包含所有职位或所有公司。</p><p id="437d" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">使用这些数据结构使得编译最终的jobs_list字典更加容易。</p><h2 id="0676" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(4)存储和保存作业</h2><p id="39cd" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我将“jobs_list”字典转换为数据帧，然后将其导出到用户使用以下函数选择的文件名和文件类型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h2 id="3a0e" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(5)集成到单个函数调用中</h2><p id="a3c0" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">最后，我希望用户可以通过一个函数调用来完成上述所有工作。我是这样做的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="d576" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">令人满意的是，这产生了一个可以很容易地调用的最终结果，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/ccaac359023e0c50b31db897ddb3353f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kMjsw1wFHN8J8gQjUTEibw.png"/></div></div></figure></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="7a4c" class="ky kz it bd la lb no ld le lf np lh li jz nq ka lk kc nr kd lm kf ns kg lo lp bi translated">来自CWjobs.co.uk的工作刮擦——使用硒</h1><p id="9398" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">下一步是概括我的脚本，也从其他网站的工作列表。另一个我经常搜索的网站是CWjobs。然而，添加这一点被证明是一个更大的挑战。</p><p id="9056" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">当我检查URL时，我注意到关键字参数没有一致的模式。</p><p id="2a4c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">因此，我决定使用Selenium Webdriver与网站进行交互——输入指定的职位和位置，并检索搜索结果。</p><h2 id="0689" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(1)下载并启动驱动程序</h2><p id="74e5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我使用Google Chrome，所以我从这里的<a class="ae nd" href="https://sites.google.com/a/chromium.org/chromedriver/downloads" rel="noopener ugc nofollow" target="_blank">下载了合适的web驱动程序，并将其添加到我的工作目录中。然后，我创建了一个函数来启动驱动程序，如下所示:</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="cac6" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">(如果使用替代浏览器，您需要下载相关驱动程序，并确保其名称和位置如上所述)</p><h2 id="d14f" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(2)使用驱动程序提取作业信息HTML‘soup’</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h2 id="9566" class="mr kz it bd la ms mt dn le mu mv dp li lz mw mx lk md my mz lm mh na nb lo nc bi translated">(3)提取工作信息</h2><p id="0b44" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">接下来的步骤与上面真正的job scraping中的<strong class="ls iu">步骤2和3 </strong>相同，只是针对CWjobs的<a class="ae nd" href="https://en.wikipedia.org/wiki/Document_Object_Model" rel="noopener ugc nofollow" target="_blank"> DOM </a>结构进行了调整，所以我在这里不再赘述。</p><p id="ed93" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">一旦我完成了代码，看到我的网络浏览器被控制，而我没有触摸鼠标或键盘，这是非常酷的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nn l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">屏幕录制:web驱动程序的使用</p></figure></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="45d1" class="ky kz it bd la lb no ld le lf np lh li jz nq ka lk kc nr kd lm kf ns kg lo lp bi translated">包扎</h1><p id="e175" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我对我的功能代码非常满意，并决定就此打住(毕竟我确实不得不<em class="ne">申请工作</em>)。</p><p id="638e" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">在GitHub上快速搜索发现，人们已经为LinkedIn和其他一些平台制作了类似的工作抓取工具。</p><p id="5642" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我将代码上传到了一个带有自述文件的GitHub库中，以防其他人想用这个代码完成工作。</p><p id="840e" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然后我坐下来，对自己感到非常满意。现在，我只是每周运行一次脚本，然后挑选出我想申请的工作。</p><p id="a32a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">老实说，使用脚本比手工操作节省的时间和精力是微不足道的。然而，我从编写代码中获得了很多乐趣，并且在BeautifulSoup和Selenium上得到了更多的实践。</p><p id="29f1" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">作为一个潜在的下一步，我可能会在Amazon Lambda上设置这个，这样它就可以每周自动搜索一次新的工作，而不需要我去做。所以如果我真的做了，将来可能会有一个关于这个的帖子。</p><p id="60e9" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我希望这是有帮助的/有趣的！</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="3285" class="ky kz it bd la lb no ld le lf np lh li jz nq ka lk kc nr kd lm kf ns kg lo lp bi translated"><strong class="ak">我在做这个项目时找到的最好的资源</strong></h1><p id="d8c7" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated"><a class="ae nd" href="https://realpython.com/beautiful-soup-web-scraper-python/" rel="noopener ugc nofollow" target="_blank">https://realpython.com/beautiful-soup-web-scraper-python/</a>——<strong class="ls iu">一个关于网页抓取的很好的概述/复习，还有漂亮的汤</strong></p><p id="1792" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae nd" rel="noopener" target="_blank" href="/looking-for-a-house-build-a-web-scraper-to-help-you-5ab25badc83e">https://towards data science . com/looking-a-house-build-a-web-scraper-to-help-you-5b ab 25 badc 83 e</a>—<strong class="ls iu">web scraper的另一个有趣的用例:识别潜在的可购买房屋</strong></p><p id="bb46" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae nd" rel="noopener" target="_blank" href="/controlling-the-web-with-python-6fceb22c5f08">https://towards data science . com/controlling-the-web-with-python-6 fceb 22 C5 f 08</a>—<strong class="ls iu">Selenium的精彩介绍</strong></p><p id="ef79" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae nd" href="https://www.youtube.com/watch?v=--vqRAkcWoM" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=-vqRAkcWoM</a>—<strong class="ls iu">硒在使用中的精彩演示</strong></p><p id="18d9" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae nd" href="https://github.com/kirkhunter/linkedin-jobs-scraper" rel="noopener ugc nofollow" target="_blank">https://github.com/kirkhunter/linkedin-jobs-scraper</a>——<strong class="ls iu">一个领英刮刀，既展示硒又美汤</strong></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="21e2" class="ky kz it bd la lb no ld le lf np lh li jz nq ka lk kc nr kd lm kf ns kg lo lp bi translated">我制作了一个关于这个的视频</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok nn l"/></div></figure></div></div>    
</body>
</html>