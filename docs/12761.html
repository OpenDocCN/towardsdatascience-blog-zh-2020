<html>
<head>
<title>Churn Prediction with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于机器学习的客户流失预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/churn-prediction-with-machine-learning-c9124d932174?source=collection_archive---------14-----------------------#2020-09-02">https://towardsdatascience.com/churn-prediction-with-machine-learning-c9124d932174?source=collection_archive---------14-----------------------#2020-09-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/13023c9d81ff5e271cda94f8d7377952.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YAJz87qWG9NDNYZgkXEapQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@sctgrhm" rel="noopener ugc nofollow" target="_blank">斯科特·格雷厄姆</a>在<a class="ae jg" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="8df2" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">用 SVC、Logistic 回归和 XGBoost 构建流失预测模型</h2></div><p id="678f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对任何公司来说，建立和保持忠诚的客户群都是一项挑战，尤其是当客户可以自由地从一个产品类别的众多供应商中进行选择的时候。此外，留住现有客户通常比获得新客户更划算。</p><p id="69bd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，评估客户保持率对企业来说至关重要。重要的是，不仅要衡量客户满意度，还要衡量停止与某个公司或服务做生意的客户数量。</p><p id="1f9d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">客户流失</strong>，也称为客户流失，是在特定时期内停止使用公司服务的客户的百分比。保持尽可能低的流失率是每个企业的追求，了解这些指标可以帮助公司及时识别潜在的客户，以防止他们离开客户群。</p><p id="3748" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将基于电信公司数据集构建客户流失预测模型。</p><h1 id="a457" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">关于数据</h1><p id="1fa7" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">数据集由 IBM 开发者平台<a class="ae jg" href="https://developer.ibm.com/technologies/data-science/patterns/predict-customer-churn-using-watson-studio-and-jupyter-notebooks/#" rel="noopener ugc nofollow" target="_blank">提供，可在</a><a class="ae jg" href="https://raw.githubusercontent.com/carlosfab/dsnp2/master/datasets/WA_Fn-UseC_-Telco-Customer-Churn.csv" rel="noopener ugc nofollow" target="_blank">这里</a>获得。一些信息，如公司名称和私人客户数据，为了保密而保持匿名，不会影响模型的性能。</p><p id="c52e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将处理来自 7043 个客户的数据，我们有 20 个特征，如下所示:</p><p id="3b2f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">人口统计客户信息</strong></p><ul class=""><li id="8302" class="mr ms jj la b lb lc le lf lh mt ll mu lp mv lt mw mx my mz bi translated"><code class="fe na nb nc nd b">gender</code>、<code class="fe na nb nc nd b">SeniorCitizen</code>、<code class="fe na nb nc nd b">Partner</code>、<code class="fe na nb nc nd b">Dependents</code></li></ul><p id="2612" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">每位客户已签约的服务</strong></p><ul class=""><li id="8c91" class="mr ms jj la b lb lc le lf lh mt ll mu lp mv lt mw mx my mz bi translated"><code class="fe na nb nc nd b">PhoneService</code>、<code class="fe na nb nc nd b">MultipleLines</code>、<code class="fe na nb nc nd b">InternetService</code>、<code class="fe na nb nc nd b">OnlineSecurity</code>、<code class="fe na nb nc nd b">OnlineBackup</code>、<code class="fe na nb nc nd b">DeviceProtection</code>、<code class="fe na nb nc nd b">TechSupport</code>、<code class="fe na nb nc nd b">StreamingTV</code>、<code class="fe na nb nc nd b">StreamingMovies</code></li></ul><p id="f5e3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">客户账户信息</strong></p><ul class=""><li id="84a1" class="mr ms jj la b lb lc le lf lh mt ll mu lp mv lt mw mx my mz bi translated"><code class="fe na nb nc nd b">tenure</code>、<code class="fe na nb nc nd b">Contract</code>、<code class="fe na nb nc nd b">PaperlessBilling</code>、<code class="fe na nb nc nd b">PaymentMethod</code>、<code class="fe na nb nc nd b">MonthlyCharges</code>、<code class="fe na nb nc nd b">TotalCharges</code></li></ul><p id="5121" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">上个月离开的客户(这是我们的模型将要预测的特征)</strong></p><ul class=""><li id="60d9" class="mr ms jj la b lb lc le lf lh mt ll mu lp mv lt mw mx my mz bi translated"><code class="fe na nb nc nd b">Churn</code></li></ul><p id="01fa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们检查一下目标变量<code class="fe na nb nc nd b">Churn</code>的值分布。</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/36d0be2d7224fdeda0a9d59193ce49e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*m8O40OxmMHSTa4MFHqI-VQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图一。流失分布</p></figure><p id="9432" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">流失率为 26.54%，我们正在处理一个不平衡的数据集。搅棒的数量明显小于非搅棒的数量。</p><h1 id="fde2" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">数据准备</h1><p id="2bbc" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">初步观察表明，我们正在处理 10 个分类变量、7 个二元变量和 3 个数值变量。然而，这项研究将这些分类特征中的一些视为二元的。为了说明，列<code class="fe na nb nc nd b">StreamingTV</code>和<code class="fe na nb nc nd b">TechSupport</code>具有值“否”、“是”和“没有互联网服务”。在这些情况下，“没有互联网服务”将被视为“没有”。最终模型将使用 4 个分类变量、13 个二元变量和 3 个数值变量进行计数。</p><p id="ac6b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在继续之前，让我们检查一下数值变量中的异常值，更具体地说，是在<code class="fe na nb nc nd b">MonthlyCharges</code>和<code class="fe na nb nc nd b">TotalCharges</code>中。</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/851f344405f4681e17286353200106db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*FngfNNQjyZhJ1qGHZZks8A.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图二。检查异常值</p></figure><p id="7ceb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">乍一看，数字特性一切正常。检查箱线图，没有离群值的证据。</p><p id="8e91" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如前所述，对初始数据集进行了调整。为了改进我们的模型，一些具有 3 个唯一值的特征被转换为二进制。解决了所有特性之后，让我们来看一个这些特性的客户流失分布的例子。</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nk"><img src="../Images/464d23684b530b13c582d4fa816c8d78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2GNjvyniahvbmhv-wZdrGg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图三。流失分布</p></figure><p id="9d5e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看上面的例子，我们可以解释性别可能不是模型的一个有意义的变量，因为男女客户的流失率非常相似。另一方面，有受抚养人的客户不太可能停止与公司的业务往来。</p><p id="1bd5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">至于互联网服务，有光纤计划的客户更有可能退出。他们的流失率是 DSL 和无互联网用户的两倍多。</p><p id="430b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谈到保护服务，拥有设备保护和在线安全计划的客户更有可能维持他们的合同。</p><p id="05d9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，合同的类型可能是模型的一个有价值的特性。请注意，逐月合约的流失率远高于一年期和两年期合约的流失率。</p><p id="6209" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在建立 ML 算法之前，我们需要执行一些预处理。考虑到大多数机器学习算法在处理数字输入时效果更好，我们将使用 Scikit Learn 的<code class="fe na nb nc nd b">LabelEncoder</code>和 pandas 的<code class="fe na nb nc nd b">get_dummies</code>对数据进行预处理。以下是数据集外观的示例:</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/4c9b543c8a1dd5c3bf038155f44ddc97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AiNi34lGXrmE5yF2ngZlCQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图 4。预处理后的数据集示例</p></figure><h1 id="7aac" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">机器学习模型</h1><p id="afa8" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">需要做的第一件事是将数据分成训练集和测试集。之后，为了管理不平衡的情况，我们将使用<code class="fe na nb nc nd b">StardardScaler</code>标准化训练集的特性，然后应用<code class="fe na nb nc nd b">RandomUnderSampler</code>，根据<a class="ae jg" href="https://imbalanced-learn.readthedocs.io/en/stable/under_sampling.html#controlled-under-sampling" rel="noopener ugc nofollow" target="_blank">官方文档</a>，这是一种“通过为目标类随机选择数据子集来平衡数据的方法”。</p><p id="a45f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据经过标准化和平衡后，将使用以下模型，我们将确定哪种模型显示的结果更好:</p><ul class=""><li id="06b5" class="mr ms jj la b lb lc le lf lh mt ll mu lp mv lt mw mx my mz bi translated">支持向量分类器</li><li id="a77c" class="mr ms jj la b lb nm le nn lh no ll np lp nq lt mw mx my mz bi translated">逻辑回归</li><li id="d5be" class="mr ms jj la b lb nm le nn lh no ll np lp nq lt mw mx my mz bi translated">XGBoost</li></ul><p id="6a8e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了评估这些模型的有效性，我们可以使用<code class="fe na nb nc nd b">Precision</code>或<code class="fe na nb nc nd b">Recall</code>。精确将会给我们正确识别的比例，而回忆将会决定正确识别的比例。</p><p id="60e5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑到我们正在努力解决的问题，<code class="fe na nb nc nd b">Recall</code>将更适合于这项研究，因为这里的目标是确定实际上倾向于停止与该公司做生意的客户的最大数量，即使一些“非搅动者”被错误地确定为“搅动者”。也就是说，在我们的情况下，最好是追求尽可能小的一些假阴性。</p><p id="f473" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们还使用了<strong class="la jk">交叉验证</strong>来获得更好的结果。<code class="fe na nb nc nd b">cross_validate</code>方法不是简单地将数据分成训练集和测试集，而是将我们的训练数据分成<em class="nr"> k </em>个<em class="nr">折叠</em>，从而更好地利用数据。在这种情况下，我们进行了 5 重交叉验证。</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/45a561eef7fed2f34b07016f8f83b8a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*MABqAPBzDfaWD_6oHYqF3Q.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图五。回忆价值观</p></figure><p id="1357" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，所有 3 个模型都提供了相似的结果，召回率约为 80%。我们现在将调整模型上的一些超参数，看看我们是否可以实现更高的召回值。这里使用的方法是<code class="fe na nb nc nd b">GridSearchCV</code>，它将搜索每个估计器的指定参数值。每个模型都有各种可以调整的参数，但我们只调整那些更有可能影响预测的参数(在<code class="fe na nb nc nd b">param_grid</code>参数中指定)，而其余的可以保留默认值。</p><p id="7d5f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请在下面找到每个型号的调校:</p><p id="bc60" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">支持向量分类器</strong></p><pre class="nf ng nh ni gt nt nd nu nv aw nw bi"><span id="2f92" class="nx lv jj nd b gy ny nz l oa ob">param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],</span><span id="ddff" class="nx lv jj nd b gy oc nz l oa ob">              'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}</span></pre><p id="f83c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nr">最佳召回率:0.96 对于{'C': 0.01，' kernel': 'poly'} </em></p><p id="bca6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意超参数调整是多么有效。我们搜索了<code class="fe na nb nc nd b">C</code>和<code class="fe na nb nc nd b">kernel</code>的不同值，对于 C = 0.01 和内核类型“poly”，我们得到了 96%的增加的召回率。</p><p id="63b9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">逻辑回归</strong></p><pre class="nf ng nh ni gt nt nd nu nv aw nw bi"><span id="d01b" class="nx lv jj nd b gy ny nz l oa ob">param_grid = {'solver': ['newton-cg', 'lbfgs', 'liblinear'],</span><span id="14d0" class="nx lv jj nd b gy oc nz l oa ob">              'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}</span></pre><p id="e561" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nr">最佳召回率:对于{'C': 0.0001，' solver': 'liblinear'}，召回率为 0.88</em></p><p id="1481" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">转向逻辑回归，我们也实现了更好的召回，对于 C = 0.0001 和 solver =“liblinear”，召回率为 88%。</p><p id="01db" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，让我们对 XGBoost 估计量进行一些调整。XGBoost 被认为是最有效的机器学习算法之一，因为它在分类和回归预测建模问题的结构化和表格化数据集上表现出色。它具有高度的可定制性，可以调节更大范围的参数。</p><p id="c31a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> XGBoost </strong></p><p id="eee1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一步，我们将确定 XGBoost 模型中最优的树的数量，搜索<code class="fe na nb nc nd b">n_estimators</code>参数的值。</p><pre class="nf ng nh ni gt nt nd nu nv aw nw bi"><span id="fef4" class="nx lv jj nd b gy ny nz l oa ob">param_grid = {'n_estimators': range(0,1000,25)}</span></pre><p id="3739" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nr">最佳召回率:0.82 对于{'n_estimators': 25} </em></p><p id="fc2e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们已经可以检测到召回率的提高。现在我们已经确定了更好的<code class="fe na nb nc nd b">n_estimators</code>值，我们可以继续搜索两个相关参数<code class="fe na nb nc nd b">max_depth</code>和<code class="fe na nb nc nd b">min_child_weight</code>。</p><pre class="nf ng nh ni gt nt nd nu nv aw nw bi"><span id="d15b" class="nx lv jj nd b gy ny nz l oa ob">param_grid = {'max_depth': range(1,8,1),</span><span id="f6be" class="nx lv jj nd b gy oc nz l oa ob">              'min_child_weight': np.arange(0.0001, 0.5, 0.001)}</span></pre><p id="61e0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nr">最佳召回率:{'max_depth': 1，' min_child_weight': 0.0001}的 0.86</em></p><p id="b9d8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在接下来的步骤中，我们将确定<code class="fe na nb nc nd b">gamma</code>的最佳值，这是一个用于控制模型过度拟合趋势的重要参数。</p><pre class="nf ng nh ni gt nt nd nu nv aw nw bi"><span id="0a3d" class="nx lv jj nd b gy ny nz l oa ob">param_grid = {'gama': np.arange(0.0,20.0,0.05)}</span></pre><p id="e736" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nr">最佳召回率:0.86 对于{'gama': 0.0} </em></p><p id="d984" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们将搜索最佳的<code class="fe na nb nc nd b">learning_rate</code>值。</p><pre class="nf ng nh ni gt nt nd nu nv aw nw bi"><span id="56ab" class="nx lv jj nd b gy ny nz l oa ob">param_grid = {'learning_rate': [0.0001, 0.01, 0.1, 1]}</span></pre><p id="2215" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nr">最佳召回率:{'learning_rate': 0.0001}的 0.88</em></p><h2 id="7123" class="nx lv jj bd lw od oe dn ma of og dp me lh oh oi mg ll oj ok mi lp ol om mk on bi translated">在测试集上评估模型</h2><p id="ae07" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">在调整了 SVC、逻辑回归和 XGBoost 的参数之后，我们注意到所有三个模型都有所改进。在<strong class="la jk">测试集</strong>上运行每个模型的调整版本，以检查它们的性能是至关重要的。</p><p id="dd2f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们为这些算法中的每一个绘制一个混淆矩阵，以可视化它们在<strong class="la jk">测试集</strong>上的性能。</p><p id="a6b4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">支持向量分类器</strong></p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/c01c3c30f353ea5ccdcf03771e30903f.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*1AEvawW7YLo4tvKHAlG6yg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图六。SVC 混淆矩阵</p></figure><p id="9447" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">逻辑回归</strong></p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/318e9a4730fde1d0a3ef8d2e91398f76.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*JXYIdP2XHHGBtT957PNstA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图 7。逻辑回归混淆矩阵</p></figure><p id="173d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> XGBoost </strong></p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/81fdde3ea43216df31e58fe2ca237cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*uG3c-RDQao9TrVCG12RqSw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图 8。XGBoost 混淆矩阵</p></figure><p id="9b73" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在测试集上运行算法后，我们有一个显示，显示当我们调整一些参数时，模型的性能如何得到改善。这三个模型在调优后召回率都有所提高，其中 XGBoost 的召回率最高。</p><h1 id="acef" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">结论</h1><p id="ecad" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">该项目的目的是开发一个模型，能够尽可能有效地确定电信公司的大量客户。</p><p id="02dd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">能够提前识别潜在的客户，使公司能够制定策略，防止客户离开客户群。有了这些数据，公司可以提供激励措施，如折扣或忠诚度计划，或提供额外的服务，以降低流失率。</p><p id="aff4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">值得一提的另一点是调整超参数的重要性，调整 ML 算法以获得更好的结果。参数调整后，三个模型的召回率都有所提高。</p><p id="7336" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">XGBoost 已经在数据科学项目中证明了它的有效性，在这个项目中，它提供了模型中最好的结果。出于这个原因，XGBoost 算法将是我们解决这里提出的问题的选择。</p><p id="fea6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">完整代码请参考<a class="ae jg" href="https://github.com/rmpbastos/data_science/blob/master/Churn_Prediction.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>。</p></div></div>    
</body>
</html>