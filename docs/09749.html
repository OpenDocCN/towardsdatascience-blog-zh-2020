<html>
<head>
<title>Expectation Maximization Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释期望最大化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/expectation-maximization-explained-c82f5ed438e5?source=collection_archive---------0-----------------------#2020-07-11">https://towardsdatascience.com/expectation-maximization-explained-c82f5ed438e5?source=collection_archive---------0-----------------------#2020-07-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/19b45689db7da68aac289afa840a19bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4cgxfIyWeRMtSlak"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">马文·朗斯多夫在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="80d7" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">用于聚类、NLP 等的通用算法</h2></div><p id="b39d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">期望最大化(EM)是 60 年代和 70 年代发展起来的经典算法，具有多种应用。它可以用作无监督聚类算法，并扩展到 NLP 应用，如<a class="ae jg" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation#Likelihood_maximization" rel="noopener ugc nofollow" target="_blank">潜在狄利克雷分配</a>，用于隐马尔可夫模型的<a class="ae jg" href="https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm" rel="noopener ugc nofollow" target="_blank">鲍姆–韦尔奇</a>算法，以及医学成像。作为优化过程，它是梯度下降等的替代方案，主要优点在于，在许多情况下，可以分析计算更新。不仅如此，它还是一个思考优化的灵活框架。</p><p id="75d2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将从一个简单的聚类示例开始，然后讨论该算法的一般性。</p><h1 id="81e3" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">无监督聚类</h1><p id="dbf3" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">考虑这样一种情况，您有各种数据点，并对它们进行了一些测量。我们希望把他们分到不同的组。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/f3403a1d60f08e001e851fe367908f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/0*kE-YHM1yJfxnbCLt.gif"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">对老忠实喷发数据的期望最大化(<a class="ae jg" href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" rel="noopener ugc nofollow" target="_blank">维基百科</a>)</p></figure><p id="2a8e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个例子中，我们有黄石公园标志性<a class="ae jg" href="https://en.wikipedia.org/wiki/Old_Faithful" rel="noopener ugc nofollow" target="_blank">老忠实</a>间歇泉喷发的数据。对于每一次喷发，我们都测量了它的长度和自上次喷发以来的时间。我们可以假设有两种“类型”的喷发(图中的红色和黄色)，对于每种类型的喷发，结果数据由(多元)正态分布生成。顺便提一下，这被称为高斯混合模型。</p><p id="572a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与<a class="ae jg" href="https://en.wikipedia.org/wiki/K-means_clustering" rel="noopener ugc nofollow" target="_blank"> k 均值聚类</a>类似，我们从随机猜测这两个分布/聚类开始，然后通过交替两步进行迭代改进:</p><ol class=""><li id="60e2" class="mw mx jj la b lb lc le lf lh my ll mz lp na lt nb nc nd ne bi translated">(<strong class="la jk">期望</strong>)概率性地将每个数据点分配给一个聚类。在这种情况下，我们计算它分别来自红色集群和黄色集群的概率。</li><li id="eeab" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">(<strong class="la jk">最大化</strong>)根据聚类中的点(按第一步中分配的概率加权)更新每个聚类的参数(加权平均位置和方差-协方差矩阵)。</li></ol><p id="b93f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意，与 k-means 聚类不同，我们的模型是<em class="nk">生成的</em>:它旨在告诉我们数据生成的过程。反过来，我们可以对模型进行重新采样，以生成更多(虚假)数据。</p><p id="5b3a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">明白了吗？现在我们要用方程做一个一维的例子。</p><p id="6175" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑具有单个测量值 x 的数据点。我们假设这些数据点由两个簇生成，每个簇遵循正态分布 N(μ，σ)。第一个集群生成数据的概率为π。</p><p id="9d2f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们有 5 个参数:混合概率π，以及每个聚类的平均值μ和标准差σ。我将它们统称为θ。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/52663a10a9c14e277766cd1c74146bc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*A50Nwp-truc-OWn7baEFwg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">我们模型的 5 个参数，统称为θ</p></figure><p id="35c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">观察到值为 x 的数据点的概率是多少？设正态分布的概率密度函数用ϕ.表示为了让符号不那么混乱，我将使用标准差作为参数，而不是通常的方差。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/e314e492ca81c01a519e1bc96d985b8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*455Hst2HncvUHqspMmOsqw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">观察值为 x 的点的概率</p></figure><p id="af67" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">观察我们的整个数据集的<em class="nk"> n </em>个点的概率(可能性)是:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/d4ef5b7969ee76ab8b105dbd3de033e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*ox7XqU9pZoOqCDZ_ZxzS_g.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">观察整个数据集的可能性</p></figure><p id="2070" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们通常选择取这个的对数，把我们的乘积变成一个更容易管理的和，对数似然。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi no"><img src="../Images/24205288fbf63f3c713f52b2768e47f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nOf0dPqIIpecsdmVasMgfg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">对数-观察我们数据的可能性</p></figure><p id="e8b8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的目标是最大化这一点:我们希望我们的参数是最有可能观察到我们观察到的数据的参数(最大似然估计)。</p><p id="2784" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在的问题是，我们如何优化它？由于对数中的和，直接分析性地这样做将是棘手的。</p><p id="e11e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">诀窍是想象有一个<strong class="la jk">潜在变量</strong>，我们称之为δ。它是一个二进制(0/1 值)变量，用于确定某个点是位于聚类 1 还是聚类 2 中。如果我们知道每个点的δ，计算参数的最大似然估计就很容易了。为了方便匹配第二个聚类的δ为 1 的选择，我们将π转换为点在第二个聚类中的概率。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/a0878ea1e138ec4b67af39154d6a2bf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7lmMXrA2hkLHsyPK8b904g.png"/></div></div></figure><p id="0ab6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，总和现在不在对数之内。此外，我们获得一个额外的总和，以说明观察到每个δ的可能性。</p><p id="181b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">反过来假设我们确实观察到了δ，最大似然估计很容易形成。对于μ，取每个聚类内的样本均值；对于σ，标准差也是如此(总体公式，即最大似然估计)。对于π，第二个聚类中点的样本比例。这些是每个参数的最大似然估计量。</p><p id="ff28" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当然，我们没有观测到δ。对此的解决方案是期望最大化算法的核心。我们的计划是:</p><ol class=""><li id="9c22" class="mw mx jj la b lb lc le lf lh my ll mz lp na lt nb nc nd ne bi translated">从参数的任意初始选择开始。</li><li id="5c01" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">(<strong class="la jk">期望值</strong>)形成δ的估计值。</li><li id="4642" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">(<strong class="la jk">最大化</strong>)计算最大似然估计量来更新我们的参数估计。</li><li id="898f" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">重复步骤 2 和 3 以收敛。</li></ol><p id="5e87" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，您可能会发现考虑 k-means 聚类很有帮助，我们也是这样做的。在 k-means 聚类中，我们将每个点分配到最近的质心(期望步长)。本质上，这是对δ的硬估计。很难，因为其中一个集群的值为 1，其他所有集群的值为 0。然后，我们将质心更新为聚类中点的平均值(最大化步骤)。这是μ的最大似然估计。在 k 均值聚类中，数据的“模型”没有标准偏差。(“模型”在吓人的引号中，因为它不是可生成的)。</p><p id="c0f5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们的例子中，我们将改为对δ进行<em class="nk">软</em>赋值。我们有时称之为<em class="nk">责任</em>(每个集群对每个观察的责任有多大)。我们将把责任标为ɣ.</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/42e2a9bb3bf07d30d9ca3687434309ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*SfD-9sPymcUb-hMeY6b1KA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">每个集群对于数据点 I 的责任ɣ</p></figure><p id="dcf2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们可以写下这个例子的完整算法。但在此之前，我们将快速回顾一下我们定义的符号表(有很多)。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nr"><img src="../Images/d3410ece26075f164305a0138274edb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_T3sPnNmg4OMLPqFi9rIxQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">符号表</p></figure><p id="90eb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">算法是这样的:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ns"><img src="../Images/5968fc94beff9716d462006b164dd36e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hPrpH99KozQ_MMCOTmKlNQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">我们例子中的期望最大化算法</p></figure><p id="0b13" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意，对聚类 1 的μ和σ的估计是类似的，但是使用 1–ɣ作为权重。</p><p id="276a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们已经给出了一个算法的例子，希望你已经有了感觉。我们将继续讨论一般的算法。这基本上相当于用稍微复杂一点的变量来修饰我们所做的一切。这将使我们能够解释为什么它会起作用。</p><h1 id="5048" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">一般期望最大化</h1><p id="50e9" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">让我们转到一般设置。设置如下:</p><ol class=""><li id="6005" class="mw mx jj la b lb lc le lf lh my ll mz lp na lt nb nc nd ne bi translated">我们有某种形式的数据 X。</li><li id="2f98" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">我们假设还有未被观察到的(潜在的)数据δ，不管是什么形式。</li><li id="b1da" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">我们有一个参数为θ的模型。</li><li id="94bc" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">我们有能力计算对数似然ℓ(θ；x，δ)。具体来说，观察我们的数据的概率日志<em class="nk">和</em>指定了给定参数的潜在变量的赋值。</li><li id="6a26" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">在给定一组参数的情况下，我们还能够使用该模型来计算条件分布δ| X。我们将把这个 P(δ| X；θ).</li><li id="c9d5" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">因此，我们可以计算对数似然ℓ(θ；x)。这是在给定参数的情况下观察到我们的数据的概率的对数(没有假设潜在变量的赋值)。</li></ol><p id="1d48" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用 P 来表示概率，我们现在可以使用<a class="ae jg" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)" rel="noopener ugc nofollow" target="_blank">链式法则</a>来写:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/a7a996a1fdeed75d79535ff8f721bde6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*uXhY2VSq3Cl-pSGFbkxMcg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">概率的链式法则</p></figure><p id="aebf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里的符号可能很微妙。这三项都以参数θ为给定值。</p><ol class=""><li id="e6e4" class="mw mx jj la b lb lc le lf lh my ll mz lp na lt nb nc nd ne bi translated">左边的第一项是观察数据的概率和指定的潜在变量赋值。</li><li id="39c7" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">右手边的第一项是给定观察数据的潜在变量的指定赋值的概率。</li><li id="bbb0" class="mw mx jj la b lb nf le ng lh nh ll ni lp nj lt nb nc nd ne bi translated">最后一项是观察数据的概率。</li></ol><p id="14f4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以取对数并重新排列术语。然后在第二行我们将做一个符号的改变(而且是一个令人困惑的改变)。别怪我，不是我发明的):</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nu"><img src="../Images/1f1b614cb02eeff484be8d5a259c2304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XwJ_ayf8iM2_BcgUFNxMgw.png"/></div></div></figure><p id="f874" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于前两个术语，有必要回顾一下它们在我们上一个示例的上下文中是什么。第一个，ℓ(θ；x)，是我们要优化的。第二个，ℓ(θ；x，δ)是分析上容易处理的。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/75fc304cb12f9759025389570a4fb1eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XNx8fpYhT0pNhRoPuZw_OA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">高斯混合模型示例中的似然公式</p></figure><p id="00c1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还记得我说过，给定参数θ，我们可以计算条件分布δ| X 吗？这就是事情变得疯狂的地方。</p><p id="113c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将引入第<em class="nk">组第二</em>组相同的参数，称之为θʹ.我有时也会用一顶帽子(扬抑符)来表示它，就像这个“ê”所戴的帽子一样。把这组参数想象成我们的<em class="nk">电流</em>估计值。我们将对公式中的θ进行优化，以提高我们的估计值。</p><p id="6e28" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们将获得条件分布δ| x，θʹ的对数似然性的期望，即给定数据和当前参数估计的潜在变量的分布。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/2eaa84011c4e3d737b0e650fcaa51c1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wzxI0NUzdSlAfsHAYWFF9Q.png"/></div></div></figure><p id="a6dd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">左手边的项不变，因为它不知道/不关心δ(它是一个常数)。同样，期望值超过了δ的可能值。如果你跟随我们的例子，术语ℓ(θ；x，δ)在我们取期望值后改变，所以δ被ɣ.代替</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nx"><img src="../Images/d6d8b2d4461ed9ea7d2240e7fc6be742.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ijzak6qHE4cNQRBA3xBxwQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">高斯混合模型例子中似然的期望。</p></figure><p id="a471" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，很快地，为了改善我们正在进行的记数噩梦，让我们介绍一下右手边的两个期望的简写记数法</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/62086c593eb778a99ba7970db007c2b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0S0X1i2AZWaUUsqn4Jy0Yg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">预期可能性的速记符号</p></figure><p id="156c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该算法变成:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/dbedee335c07d5d7c5788d87903f1993.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LT6bAJRd0XHSmSEBSzOPnA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">一般期望最大化算法</p></figure><h2 id="d26b" class="nz lv jj bd lw oa ob dn ma oc od dp me lh oe of mg ll og oh mi lp oi oj mk ok bi translated">为什么有效</h2><p id="aead" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">证明这一点的最重要的工作是考虑函数 R(θ，θʹ).这种说法是，当θ=θʹ.代替一个完整的证明，让我们想想 R 计算什么。去除对数据 X 的依赖(在我们期望的分布和似然函数之间共享)，R 示意性地变成</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/eff23680075e718f665af9d39abe464d.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*09XFAmfYi9m2pQL7IsLo0g.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">函数 R 的示意形式</p></figure><p id="6aee" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">换句话说，我们有两种概率分布。我们使用一个(由θʹ参数化)来生成数据δ，我们使用另一个(由θ参数化)来计算我们所看到的概率。如果δ仅代表一个数字，并且分布具有概率密度函数，我们可以写(再次，示意性地)</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/c0c46fede189a7f8f74370ff0347fd4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*hzfvxO2PvrjTnhQtF8LYIA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">特殊情况下函数 R 的示意性形式</p></figure><p id="2258" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我以类似于<a class="ae jg" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" rel="noopener ugc nofollow" target="_blank"> Kullback-Leibler (KL)散度</a>的形式写下了这一点，这(几乎)是两个概率分布之间距离的度量。如果我们从一个常数 R(p||p)中减去 R(q||p ),我们将得到 KL 散度，它在 0 以下有界，并且当 q=p 时只有 0。换句话说，当 q=p 时，R 最大。这是关于 KL 散度的标准结果，可以用詹森不等式证明。⁴</p><p id="0f67" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在唯一要做的事情是考虑更新步骤前后的可能性之间的差异:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/854b8a8bdf76aee5887ca9a7f7f69480.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PMGER4dwKq_eTo7_llCcRg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">更新步骤后可能性的提高</p></figure><p id="1f1c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们选择新的参数来最大化 Q，所以第一项肯定是正的。根据上面的论证，R 通过将旧参数作为其第一个参数而最大化，因此第二项必须是负的。正减去负就是正。因此，这种可能性在每次更新时都会增加。每一步都保证让事情变得更好。</p><p id="a16b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还要注意，我们不需要优化 q。我们所要做的就是找到一些方法让它变得更好，我们的更新仍然保证让事情变得更好。</p><h1 id="39e4" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">结论</h1><p id="0491" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">希望你现在对这个算法有一个好的感觉。从数学的角度来说，关键方程就是下面的可能性。在那之后，我们只需要对旧参数进行期望(期望步骤),并表明我们可以优化右边的第一项。正如我们以高斯混合模型为例，第二项通常更容易优化。第三个学期我们不用担心，不会搞砸什么的。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nu"><img src="../Images/1f1b614cb02eeff484be8d5a259c2304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XwJ_ayf8iM2_BcgUFNxMgw.png"/></div></div></figure><p id="2d8b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">后退一点，我想强调 EM 算法的强大和有用性。首先，它代表了我们可以通过交替处理潜变量(取参数为固定已知)和处理参数(取潜变量为固定已知)来引入潜变量然后计算的思想。这是一个强有力的想法，你会在各种环境中看到。</p><p id="1567" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第二，该算法天生快速，因为它不依赖于计算梯度。任何时候你可以解析地解决一个模型(比如使用线性回归)，它会更快。这让我们能够分析棘手的问题，并通过分析解决部分问题，将这种能力扩展到迭代环境中。</p><p id="a447" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我想指出，关于 EM 算法还有很多要说的。它推广到进行最大化步骤的其他形式和<a class="ae jg" href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods" rel="noopener ugc nofollow" target="_blank">变分贝叶斯</a>技术，并且可以以不同的方式理解(例如作为<a class="ae jg" href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm#As_a_maximization%E2%80%93maximization_procedure" rel="noopener ugc nofollow" target="_blank">最大化-最大化</a>或者作为在统计流形上的相互对偶仿射连接(e-和 m-连接)下到子流形的交替投影)。以后会有更多的报道！</p></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><h1 id="9d24" class="lu lv jj bd lw lx ov lz ma mb ow md me kp ox kq mg ks oy kt mi kv oz kw mk ml bi translated">感谢</h1><p id="17f1" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">这种讨论很大程度上遵循了统计学习中的<a class="ae jg" href="https://web.stanford.edu/~hastie/ElemStatLearn/" rel="noopener ugc nofollow" target="_blank">要素，尽管速度更慢一些。特别感谢</a><a class="pa pb ep" href="https://medium.com/u/e4cecbc19a01?source=post_page-----c82f5ed438e5--------------------------------" rel="noopener" target="_blank">芳芳李</a>告知我这个奇妙的算法。</p></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><h1 id="5b17" class="lu lv jj bd lw lx ov lz ma mb ow md me kp ox kq mg ks oy kt mi kv oz kw mk ml bi translated">笔记</h1><p id="02fd" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">[1]潜在的狄利克雷分配通常适合于<a class="ae jg" href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods" rel="noopener ugc nofollow" target="_blank">变分贝叶斯</a>方法，一种期望最大化的<a class="ae jg" href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods#:~:text=Variational%20Bayes%20can%20be%20seen,distribution%20of%20the%20parameters%20and" rel="noopener ugc nofollow" target="_blank">扩展</a>。例如，参见<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>实现。</p><p id="b47d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[2]在这个平台上不可能键入超过θ的帽子。请给我们一些乳胶。</p><p id="9b16" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[3]我没有将距离放在引号中，因为我不是指 Kullback-Leibler 散度(这不是一个度量标准)，而是指 Fisher 信息度量标准(这是一个度量标准)。这两者有很深的联系；对我们来说，我们可以说当实际距离为 0 时，KL 散度为 0。</p><p id="dca0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[4]对这一点的标准证明似乎是对詹森不等式的笨拙的求助。我的版本也是手工的，但是通过 KL-divergence 合并了 Jensen 的版本。</p></div></div>    
</body>
</html>