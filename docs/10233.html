<html>
<head>
<title>Avoiding Confusion With Confusion Matrix Metrics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用混淆矩阵度量避免混淆</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/avoiding-confusion-with-confusion-matrix-metrics-a8a3d0ead144?source=collection_archive---------20-----------------------#2020-07-19">https://towardsdatascience.com/avoiding-confusion-with-confusion-matrix-metrics-a8a3d0ead144?source=collection_archive---------20-----------------------#2020-07-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/33ab74691fb37e4657de0cb892e147f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S35_O9Wa2dRwetuL"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="c85d" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">从混淆矩阵中理解 17 个指标</h2></div><p id="c212" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个<a class="ae jg" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>是一个度量工具，用于评估分类机器学习模型的结果。它是一个正方形矩阵，其大小取决于模型中的类的数量。尽管我经常对可以推导出的度量标准感到困惑，因为它们代表了什么以及它们是如何计算的。</p><p id="1d59" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我将在混淆矩阵上为我们所有人创建一个参考，它的 17 个相应的度量及其公式(根据上面链接的维基百科文章)，一些帮助我们最终不再需要这个参考的解释，以及如何从头开始编码它们。让我们加载我们需要的库并开始吧！</p><p id="b8bf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">注意:所有配方都是稍加修改或取自上述维基百科文章，并使用此</em> <a class="ae jg" href="https://latex.codecogs.com/legacy/eqneditor/editor.php" rel="noopener ugc nofollow" target="_blank"> <em class="lu">在线乳胶生成器</em> </a> <em class="lu">创建。</em></p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="f221" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于本文的重点是度量，我将使用 NumPy 的均匀分布生成器创建一些假数据，为<code class="fe mb mc md me b">y_actual</code>和<code class="fe mb mc md me b">y_pred</code>获得 500 个 0 和 1 的随机值。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="b99b" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">混淆矩阵结构和提供的信息</h1><p id="1283" class="pw-post-body-paragraph ky kz jj la b lb ne kk ld le nf kn lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">首先，我们需要讨论混淆矩阵的组成部分。为此，让我们创建一个带有二进制分类情况的样本混淆矩阵。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/affdffda97dc24ee3c4062fb3ceb08f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*m2x0sKGw02IbtUVSENd5mA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">用 Python 代码自制的混淆矩阵</p></figure><p id="ec03" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如标签所示，矩阵有两面。“真实标签”在左侧垂直方向，“预测标签”在底部。这决定了 4 个小方框中的数字所代表的预测类型。这些值是以下各项的数量:</p><ol class=""><li id="e9d2" class="nk nl jj la b lb lc le lf lh nm ll nn lp no lt np nq nr ns bi translated"><strong class="la jk">真底片</strong>(左上)缩写<strong class="la jk"> TN </strong></li><li id="81c5" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><strong class="la jk">真阳性</strong>(右下)缩写<strong class="la jk"> TP </strong></li><li id="f834" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><strong class="la jk">假阴性</strong>(左下角)缩写<strong class="la jk"> FN </strong></li><li id="e560" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><strong class="la jk">误报</strong>(右上)缩写<strong class="la jk"> FP </strong></li></ol><p id="941a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你怎么记得哪条对角线有正确的匹配？沿着从上到下的对角线走。你也可以用短语“自上而下”作为记忆工具，因为你是沿着对角线从上往下走的。</p><p id="b6fe" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">快速提示，如果你设置了参数<code class="fe mb mc md me b">normalize=True</code>，你会水平归一化结果。回想一下，规范化值意味着将所有值相加，然后将每个值除以该总和。混淆矩阵的每一行中的所有值都会再次发生这种情况。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/4f97ff7f6e05a4f2d1377f8242df41b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*8xTVpDMj8ZtyqJJY9YxUyw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">上述混淆矩阵的标准化版本。</p></figure><p id="b30b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这种情况下，真 0 标签行的总和是 239。用 128 和 111 除以 239 得到的百分比分别是小数 0.54 和 0.46。在继续下一步之前，现在尝试使用 true 1 标签行。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="9853" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">从混淆矩阵计算出的度量</h1><p id="6b65" class="pw-post-body-paragraph ky kz jj la b lb ne kk ld le nf kn lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">在我们开始之前，让我们通过<code class="fe mb mc md me b">scikit-learn</code>创建混淆矩阵。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure><p id="9a8b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以像对任何其他数组一样对矩阵的每个部分进行切片，从而得到它们的值。这是因为该函数的输出是一个 2x2 数组。为了获得每个值，我们使用以下公式:</p><ol class=""><li id="1aa2" class="nk nl jj la b lb lc le lf lh nm ll nn lp no lt np nq nr ns bi translated"><strong class="la jk">真底片</strong>(左上)= <code class="fe mb mc md me b">cm[0, 0]</code></li><li id="dfc1" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><strong class="la jk">真阳性</strong>(右下角)= <code class="fe mb mc md me b">cm[1, 1]</code></li><li id="1626" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><strong class="la jk">假阴性</strong>(左下)= <code class="fe mb mc md me b">cm[1,0]</code></li><li id="8d9f" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><strong class="la jk">误报</strong>(右上)= <code class="fe mb mc md me b">cm[0,1]</code></li></ol><p id="6ed1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们开始之前还有一件事。我将在解释和代码之前给出度量的公式。我鼓励你先尝试自己编写公式。然后你可以对照你自己的版本检查我的版本。这将让你练习自己编写公式。现在来看指标(这次是真的)！</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="2a5e" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">准确(性)</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/a3d604aa72dbe832daa0d741fa5b82ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6UA1KzacvrRg-3PyicOvSA.png"/></div></div></figure><p id="173c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">准确性是最简单的，也可能是你最熟悉的。这是告诉我们有多少数据被正确分类的量度。该值越接近 1，精确度越高。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="7cf2" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">回忆=真实阳性率</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/098a79123960cd201e1fd924598de5df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YjNea29fP6A1TqiacqCRAA.png"/></div></div></figure><p id="f988" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以认为这是积极的准确性。这个指标告诉我们“1”值被归类为“1”值的准确程度。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="be98" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">特异性=真阴性率</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ob"><img src="../Images/f041c2a039db2fba9aafe0c5d7f4d5ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ptwBNiGaw2VxgD4YUXL6-A.png"/></div></div></figure><p id="ab8b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以认为这是负面的准确性。这个指标告诉我们“0”值被归类为“0”值的准确程度。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="9f47" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">精确度=阳性预测值</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oc"><img src="../Images/6a81f489b433614d4f9bb939f095bbbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vEkHOMwIXDxIRmC7KhuePA.png"/></div></div></figure><p id="816f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是事情开始变得棘手的地方。你可能会问这和召回有什么不同。该指标的目的是确定<strong class="la jk">预测值</strong>“1】实际为真实“1”值的百分比。再次回忆只是告诉我们在所有真“1”值中，有百分之多少的<strong class="la jk">真</strong>“1”值被正确预测为“1”值。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="aaa2" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">阴性预测值</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/41f71d18117b434c92faa6dcc952635a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sFLlfzsYxenz2rqIE1acnw.png"/></div></div></figure><p id="110f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是上面精度的否定版本。同样，这和特异性之间的主要区别是分母。分母包含所有预测为“0”的值。特异性将所有真正的“0”值作为其分母。因此，这告诉我们<strong class="la jk">预测的</strong>“0”值实际上是<strong class="la jk">真实的</strong>“0”值的百分比。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="116c" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">假阳性率</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/85eca0149c997d1a3cd9599af8cbc74b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r60lY3_LKOZAkarZ3Fbr2A.png"/></div></div></figure><p id="68fc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">也被称为<a class="ae jg" href="https://en.wikipedia.org/wiki/False_positive_rate" rel="noopener ugc nofollow" target="_blank">落幕</a>。除了错误分类的值之外，您可以将此视为要回忆的对应物。该指标越接近 1，您将“0”值错误分类为“1”值的百分比就越大。该指标越接近零，被错误分类为“1”值的“0”值的百分比就越低。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="9854" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">假阴性率</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/e78969119779aa0c3555fde0ddfc88cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nxupCWauWE-tVjGLmVfxjQ.png"/></div></div></figure><p id="1840" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">也被称为失败率。除了错误分类的值之外，您可以将此视为特异性的对应项。该指标越接近 1，您将“1”值错误分类为“0”值的百分比就越大。该指标越接近零，被错误分类为“0”值的“1”值的百分比就越低。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="7105" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">错误发现率</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/7483cc139a35e6186f6d22052554cda4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tfkOHcWdmANu_ngQjlp3YA.png"/></div></div></figure><p id="a6ef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这又是事情变得棘手的地方。但是这个度量也是精度的对应物。这里的分母是被归类为“1”值的值。由于分子是 FP 而不是 TP，我们使用这个度量来确定实际上是<strong class="la jk">假</strong> "1 "值的<strong class="la jk">预测</strong> "1 "值的百分比。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="cb7a" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">错误遗漏率</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/29a5ca9dc3d06977f9321a659863339a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ome0rO9zjSWJ7k5Wm8-FLA.png"/></div></div></figure><p id="9d15" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该指标也是阴性预测值的对应指标。这里的分母是被归类为“0”值的值。由于分子是 FN 而不是 TN，我们使用这个度量来确定实际上是<strong class="la jk">假</strong>“0】值的<strong class="la jk">预测</strong>“0”值的百分比。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="6499" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">关键成功指数</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/797cbcc79db4e230e0bc2f42b6b5294d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qitWOYfxD2nfwizTBHe21w.png"/></div></div></figure><p id="397d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这也被称为威胁率。关键成功指数显然用于<a class="ae jg" href="https://www.swpc.noaa.gov/sites/default/files/images/u30/Forecast%20Verification%20Glossary.pdf" rel="noopener ugc nofollow" target="_blank">预测</a>，它提供了一种衡量“1”值相对于错误分类值(FN 和 FP)的准确性的方法。一些文章将该指数描述为命中与未命中。如果你对一个用例更感兴趣，这里有<a class="ae jg" href="https://iopscience.iop.org/article/10.3847/1538-4357/aaed40/pdf" rel="noopener ugc nofollow" target="_blank">这篇论文</a>是关于深度 CNN 的一个应用，它使用索引作为结果的度量。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="52a9" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">马修斯相关系数</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/e98f68ad3420ad28ebf97b9cb86abb8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3xdAHz_kX3t4uSHGI2COAQ.png"/></div></div></figure><p id="dc18" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae jg" href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient" rel="noopener ugc nofollow" target="_blank"> Matthews 相关系数</a>是实际值和预测值之间的相关性，例如我们的二进制情况。像相关性一样，它的范围可以从-1 到 1。这个度量提供的好处是，不管两个类之间的数量差异如何，模型都有一个“平衡的度量”来解释它的质量。除了这里提到的内容之外，请查看本段中链接的文章以了解更多细节。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="9551" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">关于上述指标，您注意到了什么？</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/b89a6cf14e279c6c3b1415e85cab44c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DYzjNE1HaJbZfROL"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@laurenzpicture?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">劳伦茨·克莱因海德</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="177a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于这些指标的组成部分，您注意到了什么？</p><p id="71e2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你注意到所有的指标都是由混淆矩阵本身的各个部分构成的，那你就对了！从这一点开始，剩下的 6 个指标(是的，我们已经完成了 11 个)将由上面的指标组成。所以如果你准备好了，我们走吧！</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ok"><img src="../Images/a6aabe1fcc3adaf0e42f66045ce982b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RbdMLkGXw4LieDn4"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">阿曼德·库利在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="264f" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">平衡精度</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/c5d5ada8c90578d06c6f8a663bdbaa6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sfBGtDUo3n9OGlZr14O-Og.png"/></div></div></figure><p id="4684" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">平衡精度是一种精度度量，用作原始精度度量的替代。只有当您的目标达到平衡时，原始的精度指标才是最佳的。这是当你有几乎相等数量的“0”值和“1”值来训练模型的时候。当您的数据严重不平衡时(比如说 97%的数据是“0”值，其余的是“1”值)，最初的准确性指标就失效了。平衡准确度对真阳性率和真阴性率(也称为召回率和特异性)进行平均，以获得更能代表不平衡数据的模型结果的准确度度量。看看这个例子的对比。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="7da4" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">F1 分数</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi om"><img src="../Images/1c4590a5ae20d41f37b2dd407ba8904a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mhlokkIaRxFB1ToqZjPThA.png"/></div></div></figure><p id="10b0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">F1 得分是精确度和召回率的<a class="ae jg" href="https://en.wikipedia.org/wiki/Harmonic_mean" rel="noopener ugc nofollow" target="_blank">调和平均值</a>(又名阳性预测值和阳性准确率)。这是原始准确性的另一个衡量标准。根据本文中的<a class="ae jg" rel="noopener" target="_blank" href="/accuracy-precision-recall-or-f1-331fb37c5cb9">，当您的数据有大量负值(在本例中为“0”值)时，您可能希望使用这一指标来衡量原始精度。</a></p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="ec3c" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">信息</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/4ca2e82838bf2501a2a8da8e04691a6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OuqCmH-pJRIw424Dh5l8Kg.png"/></div></div></figure><p id="975a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据 Venkatesh-Prasad Ranganath 的文章,知情是回忆的另一种选择。Venkatesh-Prasad 解释说，回忆的缺点是，当情况需要时，它不考虑模型的负类值(“0”值)的任何变化。包括特异性的真实阴性率有助于解决这个问题。我建议阅读本段中链接的文章，了解对这一指标的详细解释。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="66fc" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">显著</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oo"><img src="../Images/6e0924655a37fca75a56accd1060da6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dpslbZhK-MYmhOAzOG3xnw.png"/></div></div></figure><p id="9eb3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Venkatesh-Prasad Ranganath 在<a class="ae jg" href="https://medium.com/@rvprasad/informedness-and-markedness-20e3f54d63bc" rel="noopener">的同一篇文章</a>中也提到了标记性。他解释说，标记性是精确性的一种替代。预测值的精度与 recall 有类似的问题，它不考虑负的真“0”值。精确地包括负预测值有助于处理这个问题。我再次建议阅读本段中链接的文章，以进一步了解这一指标。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="b287" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">流行阈值</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/6fad292c34d75a704d5a0d3e7660838e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Cjmg4sqymq_AV-tR9bxAw.png"/></div></div></figure><p id="fcf8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你所看到的，流行阈值仅仅基于回忆和特异性(也就是真正的阳性率和真正的阴性率)。这是一个衡量标准，为模型的良好表现设置了一个标准。请注意，流行阈值的分母是上面的信息度量。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="2969" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">福尔克斯-马洛指数</h1><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/ceaf1a7cf411a76fbe4f6d305d8827ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*-fjN1l53Fc844dxU7H-tfw.png"/></div></figure><p id="b49e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae jg" href="https://en.wikipedia.org/wiki/Fowlkes%E2%80%93Mallows_index" rel="noopener ugc nofollow" target="_blank"> Fowlkes-Mallows 指数</a>用于确定两组数据之间的相似性。在我们使用二元分类的情况下，它可以是一组实际值和一组预测值。它的范围从 0 到 1，越接近 1 表示相似性越强。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="4e0b" class="mm mn jj bd mo mp mq mr ms mt mu mv mw kp mx kq my ks mz kt na kv nb kw nc nd bi translated">最后的想法</h1><p id="7797" class="pw-post-body-paragraph ky kz jj la b lb ne kk ld le nf kn lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">令人惊讶的是，存在如此多的评估机器学习模型的指标。更别说这些只和分类有关！为了帮助您进一步理解这些指标，请尝试将它们相互比较。例如，回忆和特异性关心负值(“0”值)和正值(“1”值)的预测率。然后你也有他们的假阳性率和假阴性率。还要记住，前几个指标的意义取决于分子和分母的选择。</p><p id="5f86" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读！这封推荐信对你有多大帮助？你会如何修改它？</p><p id="3d2b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">欢迎您在<a class="ae jg" href="https://www.linkedin.com/in/jdejesus22/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>和<a class="ae jg" href="https://twitter.com/johnnydata22?lang=en" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注或联系我。对 Twitter 上的 DM 开放。</p><p id="832a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">直到下一次，</p><p id="f1f4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">约翰·德杰苏斯</p></div></div>    
</body>
</html>