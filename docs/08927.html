<html>
<head>
<title>Prediction Strength — a simple, yet relatively unknown way to evaluate clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测强度—一种简单但相对未知的评估聚类的方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/prediction-strength-a-simple-yet-relatively-unknown-way-to-evaluate-clustering-2e5eaf56643?source=collection_archive---------20-----------------------#2020-06-27">https://towardsdatascience.com/prediction-strength-a-simple-yet-relatively-unknown-way-to-evaluate-clustering-2e5eaf56643?source=collection_archive---------20-----------------------#2020-06-27</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><figure class="iu iv gp gr iw ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi it"><img src="../Images/120670d991aabfd1f274801675103c6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*afHj9b_0L7FAkZnxi67S1w.jpeg"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">照片由<a class="ae ji" href="https://unsplash.com/@nicotitto?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> nrd </a>在<a class="ae ji" href="/s/photos/market?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><div class=""/><div class=""><h2 id="2d95" class="pw-subtitle-paragraph ki jk jl bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dk translated">了解该标准如何工作，以及如何从头开始用 Python 实现它！</h2></div><p id="a0ec" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">有很多内容(书籍、博客帖子、教程等。)的内容，以及在 k-means 聚类等算法中寻找最佳聚类数的各种方法:间隙统计、剪影得分、臭名昭著的肘(scree)图等等。</p><p id="d19d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">多亏了新冠肺炎和新发现的大量额外空闲时间，我终于可以回到我积压的书籍中，完成安德烈·布尔科夫的优秀作品<em class="lw">百页机器学习书籍</em>。这本书很好地概述了机器学习的各个方面，并鼓励读者深入他们感兴趣的话题。在阅读关于无监督学习和聚类算法的章节时，我遇到了一种评估聚类算法性能的新方法——预测强度。</p><p id="ef6a" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">经过快速搜索，我没有找到类似的文章，我确实认为这种方法很有趣，值得另起炉灶。所以让我们开始吧！</p><h1 id="2093" class="lx ly jl bd lz ma mb mc md me mf mg mh kr mi ks mj ku mk kv ml kx mm ky mn mo bi translated">理论介绍</h1><p id="a3fc" class="pw-post-body-paragraph la lb jl lc b ld mp km lf lg mq kp li lj mr ll lm ln ms lp lq lr mt lt lu lv io bi translated">许多用于确定算法(如 k-means)的最佳聚类数的流行方法都是基于类内平方和(WSS)。该度量基于观测值和聚类质心之间的距离。一般来说，WSS 越低，观测值越接近质心，这表明拟合度越高。但是，我们需要在 WSS 和聚类数之间找到一个平衡点，因为无限增加聚类数(直到观察次数)总是会得到更好的拟合。</p><p id="4e11" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">[1]中建议的<strong class="lc jm">预测强度</strong>方法从机器学习的角度来看识别最佳聚类数的问题。</p><p id="7bc2" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们将算法分解为以下步骤:</p><ol class=""><li id="12b3" class="mu mv jl lc b ld le lg lh lj mw ln mx lr my lv mz na nb nc bi translated">将数据集分成训练集(X_tr)和测试集(X_te)。</li><li id="7948" class="mu mv jl lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated">使用某个值<em class="lw"> k </em>(聚类数)对两个集合运行聚类算法。</li><li id="8d12" class="mu mv jl lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated">创建大小为<code class="fe ni nj nk nl b">n_test</code> x <code class="fe ni nj nk nl b">n_test</code>的<strong class="lc jm">共同隶属矩阵</strong> D[C(X_tr，k)，X_te],其中<code class="fe ni nj nk nl b">n_test</code>是测试集中的观察值数量，C(X_tr，k)是适合训练集的聚类算法(在我们的例子中是 k-means)。</li><li id="d63f" class="mu mv jl lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated">如果测试集的元素 I 和 I '属于同一聚类，则将共同隶属矩阵的第 ii '个元素设置为 1，否则将其设置为 0。</li><li id="ec5f" class="mu mv jl lc b ld nd lg ne lj nf ln ng lr nh lv mz na nb nc bi translated">以便测量训练集质心预测测试集中的共同成员的程度。对于分配到同一测试聚类的每对测试观察值(在共同隶属矩阵中值为 1)，我们基于训练集质心确定它们是否也被分配到同一聚类。</li></ol><p id="eb86" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">下面来自[1]的图片说明了这个想法:</p><figure class="nn no np nq gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi nm"><img src="../Images/34357fe39402cfe8c1e09a9aa0a7c88a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f3MhTlh8kakGpp5MUQrjhQ.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">训练和测试指的是数据集。来源:<a class="ae ji" href="https://www.stat.washington.edu/wxs/Stat592-w2011/Literature/tibshirani-walther-prediction-strength-2005.pdf" rel="noopener ugc nofollow" target="_blank">【1】</a></p></figure><p id="47a1" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">6.聚类的预测强度 C(.k)定义为:</p><figure class="nn no np nq gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi nr"><img src="../Images/5d3c546d7cd00380838fefc1a24ee3ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A0Y-HF-CB-QIMzQHxdbI1g.png"/></div></div></figure><p id="6952" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">其中 n_kj 是第<em class="lw"> j </em>个星团中的观测值数量。</p><p id="22b9" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">7.对于每个测试聚类，我们使用训练集质心计算该聚类中被分配到同一个聚类的观察对的比例。预测强度是这个量在<em class="lw"> k </em>个测试集群中的最小值。</p><p id="81dc" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们对所有考虑的集群大小运行上述算法的步骤 2-7。然后，我们选择预测强度高于某个阈值的最大聚类大小。作者进行的实验表明 0.8-0.9 是一个很好的阈值。</p><p id="a931" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">这可能有点难以理解，所以我建议仔细研究几次这个算法，以便理解这个想法。查看后面部分的代码也会有所帮助。</p><p id="0fe9" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">为了使这个过程更容易，我将尝试提供一些预测强度方法背后的直观解释。假设所选的聚类数等于数据集中的真实聚类数。然后，训练群集将类似于测试群集，并将很好地预测它们。因此，预测强度会很高。</p><p id="608e" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">相反，当所选的聚类数高于最佳聚类数时，附加的训练和测试聚类很可能是不同的，这将导致预测强度的较低值。</p><h1 id="2897" class="lx ly jl bd lz ma mb mc md me mf mg mh kr mi ks mj ku mk kv ml kx mm ky mn mo bi translated"><strong class="ak">用 Python 实现</strong></h1><p id="7dc6" class="pw-post-body-paragraph la lb jl lc b ld mp km lf lg mq kp li lj mr ll lm ln ms lp lq lr mt lt lu lv io bi translated">是时候用 Python 实现预测强度算法了。我们将使用该标准来选择玩具数据集上 k-means 聚类中的最佳聚类数。此外，我们还将展示经典的肘图方法进行比较。首先，我们导入所有需要的库:</p><figure class="nn no np nq gt ix"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="0b6a" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">然后，我们使用<code class="fe ni nj nk nl b">make_blobs</code>生成一个 2 维玩具数据集，其中有 3 个明显分开的簇。为了再现性，我们固定随机状态。</p><figure class="nn no np nq gt ix"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="a11d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">下图显示了生成的数据集。</p><figure class="nn no np nq gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi nu"><img src="../Images/a1f7f1a3c2ed7c7f2b79d734a8e798a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xzLCYhcz2aFpyJNi3-g41A.png"/></div></div></figure><p id="7872" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">生成数据后，我们应用 k 均值聚类。首先，我们使用肘图方法来确定最佳聚类数。我们将聚类的最大数量设置为 9。</p><figure class="nn no np nq gt ix"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="cb8c" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">在 k 均值聚类的<code class="fe ni nj nk nl b">scikit-learn</code>实现中，<code class="fe ni nj nk nl b">inertia_</code>属性存储总的类内平方和(WSS)。我们绘制了结果图:</p><figure class="nn no np nq gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi nv"><img src="../Images/3ab9603bfbfc8a90a20c5c07b3cbcaa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uGXmMvsfOVFG9MZxudoTMA.png"/></div></div></figure><p id="b276" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们可以清楚地看到“肘”点—它对应于 3 个集群，这与我们人工生成的数据相符。</p><p id="27fe" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">是时候实现预测强度算法了。我的实现基于[3]中提供的实现，做了一些修改以使代码更简单易读。我们首先将数据分成训练集和测试集。为此，我们使用了<code class="fe ni nj nk nl b">scikit-learn</code>中的<code class="fe ni nj nk nl b">train_test_split</code>函数。我们采用 80-20 的分层比例。</p><figure class="nn no np nq gt ix"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="e907" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">在处理主函数之前，我们需要定义一个辅助函数。它用于确定给定观测值的最近质心(使用欧几里德距离)。</p><figure class="nn no np nq gt ix"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="569b" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">现在，我们定义主函数。在前半部分，我们创建并填充共同成员矩阵。我们使用嵌套循环和一组条件来确定矩阵中每个元素的正确值。在后半部分，我们计算每个聚类的预测强度，并选择最小值作为最终结果。</p><figure class="nn no np nq gt ix"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="f453" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">准备好函数后，我们为每个聚类大小拟合 k 均值聚类，并计算预测强度。请记住，在每次迭代中，我们实际上必须分别为训练集和测试集采用两种 k-means 算法。</p><figure class="nn no np nq gt ix"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="f9e9" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">下面我们可以看到绘制的结果。按照算法的逻辑，我们应该选择预测强度值高于指定阈值(在这种情况下为 0.8)的最大聚类大小。我们可以看到推荐的集群大小是 3。</p><figure class="nn no np nq gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi nw"><img src="../Images/76aa7a1fbcbe3b4502c9d537ad8b3ceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xDqA0CKDMqhM5ye1RM--1Q.png"/></div></div></figure><h1 id="4848" class="lx ly jl bd lz ma mb mc md me mf mg mh kr mi ks mj ku mk kv ml kx mm ky mn mo bi translated">结论</h1><p id="a609" class="pw-post-body-paragraph la lb jl lc b ld mp km lf lg mq kp li lj mr ll lm ln ms lp lq lr mt lt lu lv io bi translated">在本文中，我介绍了相对未知的聚类算法评估标准——预测强度，并展示了如何在 Python 中将它实现为一个自定义函数。您可以在下一次处理集群问题时尝试一下！</p><p id="4f64" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">关于算法(R 中)的稍微不同但等价的实现，请参见[2]。这种方法可能更容易理解，因为作者减少了要检查的嵌套循环和条件的数量。</p><p id="f521" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们还可以应用于玩具示例的另一件事是置信区间，特别是对于非确定性聚类算法。它们基于多次计算预测强度和计算接收结果的平均值和标准偏差。记住，要这样做，我们必须从 k-means 聚类类中删除固定的随机状态。</p><p id="c3dc" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">您可以在我的<a class="ae ji" href="https://github.com/erykml/medium_articles/blob/master/Machine%20Learning/prediction_strength.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到本文使用的代码。一如既往，我们欢迎任何建设性的反馈。你可以在<a class="ae ji" href="https://twitter.com/erykml1?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">推特</a>或评论中联系我。</p><p id="5b6a" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">如果您对本文感兴趣，您可能也会喜欢:</p><div class="iu iv gp gr iw nx"><a rel="noopener follow" target="_blank" href="/coding-a-custom-imputer-in-scikit-learn-31bd68e541de"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd jm gy z fp oc fr fs od fu fw jk bi translated">在 scikit-learn 中编写自定义输入程序</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">了解如何创建自定义估算器，包括用于更高级用例的 groupby 聚合</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="oh l oi oj ok og ol jc nx"/></div></div></a></div><div class="iu iv gp gr iw nx"><a href="https://levelup.gitconnected.com/ensemble-learning-using-the-voting-classifier-a28d450be64d" rel="noopener  ugc nofollow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd jm gy z fp oc fr fs od fu fw jk bi translated">使用投票分类器的集成学习</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">了解如何使用集成学习的变体来利用多个模型的优势</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="og l"><div class="om l oi oj ok og ol jc nx"/></div></div></a></div><div class="iu iv gp gr iw nx"><a rel="noopener follow" target="_blank" href="/creating-benchmark-models-the-scikit-learn-way-af227f6ea977"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd jm gy z fp oc fr fs od fu fw jk bi translated">以 scikit-learn 方式创建基准模型</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">了解如何为分类和回归问题创建一系列基准模型</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="on l oi oj ok og ol jc nx"/></div></div></a></div><h1 id="4023" class="lx ly jl bd lz ma mb mc md me mf mg mh kr mi ks mj ku mk kv ml kx mm ky mn mo bi translated">参考</h1><p id="06cd" class="pw-post-body-paragraph la lb jl lc b ld mp km lf lg mq kp li lj mr ll lm ln ms lp lq lr mt lt lu lv io bi translated">[1] Tibshirani，r .，&amp; Walther，G. (2005 年)。通过预测强度进行聚类验证。<em class="lw">计算与图形统计杂志</em>，<em class="lw"> 14 </em> (3)，511–528。—<a class="ae ji" href="https://www.stat.washington.edu/wxs/Stat592-w2011/Literature/tibshirani-walther-prediction-strength-2005.pdf" rel="noopener ugc nofollow" target="_blank">https://www . stat . Washington . edu/wxs/stat 592-w 2011/Literature/TiB shirani-walther-prediction-strength-2005 . pdf</a></p><p id="2e75" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><a class="ae ji" href="https://github.com/echen/prediction-strength" rel="noopener ugc nofollow" target="_blank">https://github.com/echen/prediction-strength</a></p><p id="f30f" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">[3]<a class="ae ji" href="https://github.com/aburkov/theMLbook/blob/master/prediction_strength.py" rel="noopener ugc nofollow" target="_blank">https://github . com/aburkov/theMLbook/blob/master/prediction _ strength . py</a></p></div></div>    
</body>
</html>