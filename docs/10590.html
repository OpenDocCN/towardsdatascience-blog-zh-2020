<html>
<head>
<title>Solutions to Issues with Edge TPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Edge TPU 问题的解决方案</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/solutions-to-issues-with-edge-tpu-32374310e732?source=collection_archive---------46-----------------------#2020-07-24">https://towardsdatascience.com/solutions-to-issues-with-edge-tpu-32374310e732?source=collection_archive---------46-----------------------#2020-07-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8f0e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何解决使用 TPU USB 加速器时的常见问题</h2></div><p id="1e98" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">在这篇文章中，我将分享我在 Edge TPU USB 加速器上制作深度学习模型时遇到的一些常见错误以及对我有效的解决方案。</em>T3】</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/5802a459b4e3b52dab41f56c14faee7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*TKtMo2G1NJp2qZsB-DgDzg.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">来源:https://coral.ai/products/accelerator/<a class="ae lr" href="https://coral.ai/products/accelerator/" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="63d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Coral USB 加速器是一种专用集成芯片(ASIC ),可为您的机器增加 TPU 计算能力。额外的 TPU 计算使深度学习模型的边缘推断更快更容易。</p><p id="fcf6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">把 USB 加速器插在 USB 3.0 口，复制 TFLite Edge 模型，连同做推论的脚本，就可以开始了。它可以在 Mac、Windows 和 Linux 操作系统上运行。</p><p id="3611" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要创建 Edge TFLite 模型并使用 USB 加速器在边缘进行推理，您将使用以下步骤。</p><ol class=""><li id="81b6" class="ls lt it kk b kl km ko kp kr lu kv lv kz lw ld lx ly lz ma bi translated"><strong class="kk iu">创建模型</strong></li><li id="8078" class="ls lt it kk b kl mb ko mc kr md kv me kz mf ld lx ly lz ma bi translated"><strong class="kk iu">训练模型</strong></li><li id="094b" class="ls lt it kk b kl mb ko mc kr md kv me kz mf ld lx ly lz ma bi translated"><strong class="kk iu">保存模型</strong></li><li id="c73c" class="ls lt it kk b kl mb ko mc kr md kv me kz mf ld lx ly lz ma bi translated"><strong class="kk iu">应用培训后量化</strong></li><li id="ce04" class="ls lt it kk b kl mb ko mc kr md kv me kz mf ld lx ly lz ma bi translated"><strong class="kk iu">将模型转换为 TensorFlow Lite 版本</strong></li><li id="fc35" class="ls lt it kk b kl mb ko mc kr md kv me kz mf ld lx ly lz ma bi translated"><strong class="kk iu">使用 edge TPU 编译器编译 tflite 模型，用于 Coral Dev board 等 Edge TPU 设备到 TPU USB 加速器</strong></li><li id="6695" class="ls lt it kk b kl mb ko mc kr md kv me kz mf ld lx ly lz ma bi translated"><strong class="kk iu">在边缘部署模型并进行推理</strong></li></ol><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mg"><img src="../Images/ed9b46f0a600f0fd5bc76dc2b394136a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SjDzxAdriVRxbGyP-TOj5g.png"/></div></div></figure><h2 id="9f38" class="ml mm it bd mn mo mp dn mq mr ms dp mt kr mu mv mw kv mx my mz kz na nb nc nd bi translated">问题 1:使用 edgetpu_compiler 编译 TfLite 模型时，出现错误“内部编译器错误。中止！”</h2><p id="79e1" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated"><strong class="kk iu"> <em class="le">出错的代码</em> </strong></p><pre class="lg lh li lj gt nj nk nl nm aw nn bi"><span id="1fe5" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">test_dir='dataset' </strong><br/><strong class="nk iu">def representative_data_gen():<br/>  dataset_list = tf.data.Dataset.list_files(test_dir + '\\*')<br/>  for i in range(100):<br/>    image = next(iter(dataset_list))<br/>    image = tf.io.read_file(image)<br/>    image = tf.io.decode_jpeg(image, channels=3)<br/>  <em class="le">  image = tf.image.resize(image, (500,500))</em><br/>    image = tf.cast(image / 255., tf.float32)<br/>    image = tf.expand_dims(image, 0)</strong></span><span id="36ad" class="ml mm it nk b gy ns np l nq nr"># Model has only one input so each data point has one element<br/>    <strong class="nk iu">yield [image]</strong></span><span id="5334" class="ml mm it nk b gy ns np l nq nr"><strong class="nk iu">keras_model='Intel_1.h5'</strong></span><span id="32c7" class="ml mm it nk b gy ns np l nq nr">#For loading the saved model and tf.compat.v1 is for compatibility with TF1.15<strong class="nk iu"><br/>converter=tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_model)</strong></span><span id="8368" class="ml mm it nk b gy ns np l nq nr"># This enables quantization<br/><strong class="nk iu">converter.optimizations = [tf.lite.Optimize.DEFAULT]</strong></span><span id="6c21" class="ml mm it nk b gy ns np l nq nr"># This ensures that if any ops can't be quantized, the converter throws an error<br/><strong class="nk iu">converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]</strong></span><span id="717b" class="ml mm it nk b gy ns np l nq nr"># Set the input and output tensors to uint8<br/><strong class="nk iu">converter.inference_input_type = tf.uint8<br/>converter.inference_output_type = tf.uint8</strong></span><span id="4dfa" class="ml mm it nk b gy ns np l nq nr"># set the representative dataset for the converter so we can quantize the activations<br/><strong class="nk iu">converter.representative_dataset = representative_data_gen<br/>tflite_model = converter.convert()</strong></span><span id="6743" class="ml mm it nk b gy ns np l nq nr">#write the quantized tflite model to a file<br/><strong class="nk iu">with open('Intel_1.tflite', 'wb') as f:<br/>  f.write(tflite_model)</strong></span><span id="dc5d" class="ml mm it nk b gy ns np l nq nr"><strong class="nk iu">with open('Intel_1.tflite', 'wb') as f:<br/>  f.write(tflite_model)<br/>print("TFLite conversion complete")</strong></span></pre><p id="58b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将模型转换为 Tflite 后，为 Edge TPU 编译模型</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/8574bf013962b1190feff42f99c11c52.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*0DCBcPBUeQdt62A6yg1gwA.png"/></div></figure><p id="4bdc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个错误没有描述，您被留在黑暗中解决这个问题。</p><h2 id="16fd" class="ml mm it bd mn mo mp dn mq mr ms dp mt kr mu mv mw kv mx my mz kz na nb nc nd bi translated">对我有效的解决方案</h2><p id="c418" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">我创建了两个定制模型，它们具有相同的架构，但不同的数据集，不同的类数量，并使用相同的步骤来编译这两个 tflite 模型。</p><p id="1b39" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个模型编译成功，而另一个模型给出了“内部编译器错误”</p><p id="f9d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我知道这不是创建边缘 TPU 模型的模型或步骤，而是与数据相关的东西。</p><p id="493d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于这个问题的讨论:<a class="ae lr" href="https://github.com/tensorflow/tensorflow/issues/32319" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/tensorflow/issues/32319</a>帮助我尝试不同的选择。</p><p id="64da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我的解决方案是缩小图像尺寸，瞧，它成功了！！！</p><p id="3f10" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个解决方案为什么有效？</p><p id="478f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">减小图像尺寸可能有助于用于创建代表性数据集的激活范围。</p><p id="7d6d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代表性数据集有助于精确的激活动态范围，用于量化模型。</p><p id="2758" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们量化模型时，我们将用于表示 TensorFlow 模型的权重、激活和偏差的数字的精度从 32 位浮点降低到 8 位整数，这有助于使模型变得轻量。</p><p id="302d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> TFLite 和 EdgeTPU 模型是轻量级的，因此我们具有更低的延迟、更快的推理时间和更低的功耗。</strong></p><p id="f724" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下图显示了以 H5 格式、TFlite 模型和 EdgeTPU 保存的模型的大小差异。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nu"><img src="../Images/e241d5d492afb8989996e0130a5473f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_wYt3AJ9Q6pwL89iIAs6nA.png"/></div></div></figure><p id="1e9e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我又尝试了一件事来固化我的理解；我试图在 Edge TPU 运行时版本的较低版本中编译具有更高图像维度(500，500)的相同错误模型。</p><p id="aabf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它编译了，但是整个模型将在 CPU 而不是 TPU 上运行，这表明量化模型仍然有一些浮点运算。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nv"><img src="../Images/add09848b952ee13633ba6a0aa85e7d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yj8RhW420mV-HIHsSkwMAw.png"/></div></div></figure><p id="6f47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我用图像尺寸(100，100)而不是(500，500)重新训练模型</p><p id="40dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有效的代码。</p><pre class="lg lh li lj gt nj nk nl nm aw nn bi"><span id="1007" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">keras_model='Intel_epoch50_batch16.h5'</strong></span><span id="865f" class="ml mm it nk b gy ns np l nq nr">#For loading the saved model and tf.compat.v1 is for compatibility with TF1.15<strong class="nk iu"><br/>converter=tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(keras_model)</strong></span><span id="5a2b" class="ml mm it nk b gy ns np l nq nr"># This enables quantization<br/><strong class="nk iu">converter.optimizations = [tf.lite.Optimize.DEFAULT]</strong></span><span id="7433" class="ml mm it nk b gy ns np l nq nr"># This ensures that if any ops can't be quantized, the converter throws an error<br/><strong class="nk iu">converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]</strong></span><span id="7c1a" class="ml mm it nk b gy ns np l nq nr"># Set the input and output tensors to uint8<br/><strong class="nk iu">converter.inference_input_type = tf.uint8<br/>converter.inference_output_type = tf.uint8</strong></span><span id="f5db" class="ml mm it nk b gy ns np l nq nr"># set the representative dataset for the converter so we can quantize the activations<br/><strong class="nk iu">converter.representative_dataset = representative_data_gen<br/>tflite_model = converter.convert()</strong></span><span id="676f" class="ml mm it nk b gy ns np l nq nr">#write the quantized tflite model to a file<br/><strong class="nk iu">with open('Intel_class.tflite', 'wb') as f:<br/>  f.write(tflite_model)</strong></span><span id="f660" class="ml mm it nk b gy ns np l nq nr">with open('Intel_epoch50_batch16.tflite', 'wb') as f:<br/>  f.write(tflite_model)</span></pre><p id="107e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在该模型用最新版本的 Edge TPU 编译器编译。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nw"><img src="../Images/3e0f513d9c421af4881baaf5e3b3804a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IrEyY_6g_p32QCr84Wqkew.png"/></div></div></figure><p id="5bdf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着维度的变化，现在大部分操作将在 TPU 上运行。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nx"><img src="../Images/6da75090a54d233c341406c8cba5c514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v0x1Edv8VHWuBf3gBDXorQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">Edgetpu 日志文件</p></figure><h2 id="c185" class="ml mm it bd mn mo mp dn mq mr ms dp mt kr mu mv mw kv mx my mz kz na nb nc nd bi translated">问题 2: ValueError:在操作“reshape”的输入数组中发现过多维度</h2><p id="fa68" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">在 tflite 模型成功编译 edgetpu_compiler 之后，我们实例化了用于推理的解释器。遇到错误“ValueError:在操作“reshape”的输入数组中发现过多维度。</p><p id="4ecf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在这个帖子里回复了关于我的解决方案的讨论:【https://github.com/google-coral/edgetpu/issues/74 T4】</p><h2 id="8dc2" class="ml mm it bd mn mo mp dn mq mr ms dp mt kr mu mv mw kv mx my mz kz na nb nc nd bi translated">对我有效的解决方案</h2><p id="d8c9" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">问题在于我用于训练后量化的代表性数据集。用于创建代表性数据集的数据集比我在 images 文件夹中提供的图像更多。</p><p id="ede0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我的 test_dir 有 99 个图像，我将范围设置为 100。当我将用于代表性数据集的数据集与文件夹中的图像数量进行匹配时，问题就解决了。</p><pre class="lg lh li lj gt nj nk nl nm aw nn bi"><span id="d1e3" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">def representative_data_gen():<br/>  dataset_list = tf.data.Dataset.list_files(test_dir + '\\*')<br/>  for i in range(99):<br/>    image = next(iter(dataset_list))<br/>    image = tf.io.read_file(image)<br/>    image = tf.io.decode_jpeg(image, channels=3)<br/>    image = tf.image.resize(image, (100,100))<br/>    image = tf.cast(image / 255., tf.float32)<br/>    image = tf.expand_dims(image, 0)</strong></span><span id="5b2a" class="ml mm it nk b gy ns np l nq nr"># Model has only one input so each data point has one element<br/>    <strong class="nk iu">yield [image]</strong></span></pre><h2 id="1da7" class="ml mm it bd mn mo mp dn mq mr ms dp mt kr mu mv mw kv mx my mz kz na nb nc nd bi translated">结论:</h2><p id="6db3" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">一步一步，排除变量会引导你找到根本原因。我使用 5W 和 1H 技术，其中 5W 代表谁、什么、哪里、何时、为什么，而 1 H 代表如何。</p></div></div>    
</body>
</html>