<html>
<head>
<title>The 3 Most Important Basic Classification Metrics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">3个最重要的基本分类指标</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-3-most-important-basic-classification-metrics-3368dd425f74?source=collection_archive---------20-----------------------#2020-05-06">https://towardsdatascience.com/the-3-most-important-basic-classification-metrics-3368dd425f74?source=collection_archive---------20-----------------------#2020-05-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="94a4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">超出准确度</h2></div><p id="2145" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是帮助您理解、使用和记住七个最常见的分类标准的系列文章中的第二篇。</p><p id="93bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在数据科学和相关领域，人们认为从业者理解准确性和混淆矩阵。如果你没有，一定要看看我之前的文章<a class="ae le" rel="noopener" target="_blank" href="/classification-metrics-everyone-should-know-b67fd0044c0c">这里</a>。它应该有助于驱散迷雾。☁️</p><p id="8623" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们将深入探讨每个数据科学家和统计学家都应该知道的三个最重要的基本分类指标。🚀</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/b4d8c99c87ba1252a6a691bd2bba82e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ha-qdL5QpGvuK1X4ED9oEw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">三瓶津宁。资料来源:pixabay.com</p></figure><p id="f2f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将我们将要探索的三个指标称为<em class="lv">基本</em> <em class="lv">指标</em>，因为每一个指标都由混淆矩阵的一个象限除以该象限再加上另一个象限组成。</p><p id="6e5a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当有两种可能的结果时，我们关注二元分类的情况。</p><p id="b89b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们开始吧！🚀</p><h1 id="8231" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">召回率(又名灵敏度，真阳性率，检测概率，命中率，等等！)</h1><p id="f673" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">最常见的基本指标通常被称为<em class="lv">回忆</em>或<em class="lv">灵敏度。</em>它更具描述性的名字是t <em class="lv"> rue阳性率(TPR)。</em>我称之为<em class="lv">召回</em>。</p><p id="818f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当你真的想正确预测真实类中的案例时，回忆是很重要的。例如，如果你有一种危险形式的癌症的测试，你真的希望这种测试能很好地检测出所有人实际患有癌症的情况。所以你真的很在乎回忆。</p><p id="ee40" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">召回率的计算方法是将真阳性除以真阳性加上假阴性:</p><p id="70fa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lv">召回= TP / (TP + FN) </em></p><p id="860e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">换句话说，在所有真实案例中，你的模型预测正确的比例是多少？</p><p id="3737" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是我们的模型预测网站访问者是否会在Jeff的Awesome Hawaiian Shirt商店购买衬衫的结果。🌺👕</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="e8e8" class="my lx it mu b gy mz na l nb nc">                 Predicted Positive    Predicted Negative<br/>Actual Positive          80  (TP)            20 (FN)<br/>Actual Negative          50  (FP)            50 (TN)</span></pre><p id="01d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用我们的混淆矩阵示例，什么是回忆？</p><p id="6288" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi">80/(80 + 20) = 80%</p><p id="7baa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型正确预测了五分之四的销售额。听起来不错！😀我们可以将我们的模型的召回率与另一个模型的召回率进行比较，以帮助我们选择要用于预测的模型。</p><p id="fdad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最佳召回率是1，最差召回率是0。scikit-learn函数名为<strong class="kk iu"/><a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html" rel="noopener ugc nofollow" target="_blank"><em class="lv">recall _ score</em></a><em class="lv">。</em></p><p id="ca7f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于回忆真的很重要的情况，我们可以做些别的事情来正确预测更多的真实情况:我们可以改变我们的<em class="lv">决策阈值</em>。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/fc8a4ec2fdc762bc24f58a75ab8fef39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rmmKfvVXoeWEJH9ADSWkAg.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">三津宁视角的转变:来源:pixabay.com</p></figure><h2 id="9397" class="my lx it bd ly nd ne dn mc nf ng dp mg kr nh ni mi kv nj nk mk kz nl nm mm nn bi translated">决策阈值</h2><p id="6588" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">默认情况下，scikit-learn分类模型的决策阈值设置为. 5。这意味着，如果模型认为某个观察值有50%或更大的概率成为正类的成员，则该观察值被预测为正类的成员。</p><p id="1b45" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们非常关心召回，我们可以降低我们的决策阈值，以试图捕捉更多的实际阳性病例。例如，您可能希望模型以30%或更高的概率预测每个观察值为真。</p><p id="9263" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">目前在scikit-learn中还没有快速的方法来做到这一点。<a class="ae le" href="https://stackoverflow.com/a/31417912/4590385" rel="noopener ugc nofollow" target="_blank">这个堆栈溢出答案</a>解释了你如何用一个定制的<em class="lv">预测</em>方法来获得结果。(修改2020-05-06 0帽子尖给<a class="no np ep" href="https://medium.com/u/a9e4103439ec?source=post_page-----3368dd425f74--------------------------------" rel="noopener" target="_blank">凯文·马卡姆</a>)</p><p id="b617" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这一变化可能会将一些假阴性转化为真阳性。耶！🎉然而，这个模型也会把一些真阴性变成假阳性。嘘！😢</p><p id="c5eb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">毕竟，通过预测每个观察都是积极的，你可以得到完美的100%回忆。但这通常不是一个好计划。</p><p id="ccf4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当误报的代价很高时，你要注意它们。您需要一个度量标准来捕捉您的模型区分真阳性和假阳性的能力。你需要注意<em class="lv">精度</em>。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/c9af05e19b1f35488dfefbde7ab5bde3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x_3kQUXSQx1INQ0enJNF6Q.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">没错。资料来源:pixabay.com</p></figure><h1 id="8dac" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">精确</h1><p id="6ad8" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">精度是相对于所有肯定预测，有多少肯定预测是正确的比率。它回答了这个问题</p><p id="a096" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">正面预测的正确率是多少？</strong></p><p id="882a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lv">精度= TP / (TP + FP) </em></p><p id="464c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我通过关注字母<em class="lv"> p. </em>的头韵来精确记忆</p><p id="f5a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="lv"> P </em> </strong> <em class="lv">精度</em>是所有的<em class="lv">真值</em> <strong class="kk iu"> <em class="lv"> P </em> </strong> <em class="lv">正数</em>除以所有的<strong class="kk iu"> <em class="lv"> P </em> </strong> <em class="lv">预测值</em> <strong class="kk iu"> <em class="lv"> P </em> </strong> <em class="lv">正数。</em></p><p id="2d33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这又是夏威夷衬衫销售混淆矩阵:</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="8050" class="my lx it mu b gy mz na l nb nc">                    Predicted Positive    Predicted Negative<br/>Actual Positive            80 (TP)             20 (FN)<br/>Actual Negative            50 (FP)             50 (TN)</span></pre><p id="dbb7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">精度分数是多少？</p><p id="f782" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi">80/(80+50) = 61.5%</p><p id="428d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">scikit-learn的度量是<strong class="kk iu"/><a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html" rel="noopener ugc nofollow" target="_blank"><em class="lv">precision _ score</em></a><em class="lv">。</em>语法类似于recall的。</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="0f87" class="my lx it mu b gy mz na l nb nc">precision_score(y_test, predictions)</span></pre><p id="27a2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同样，最佳值是1 (100%)，最差值是0。</p><p id="7daf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人们经常根据精确度与回忆的关系来讨论精确度。事实上，scikit-learn中有一个<em class="lv">plot _ precision _ recall _ curve</em>函数，我们可以使用它来可视化精度和召回之间的权衡。</p><p id="4483" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是使用一些大型数据集在逻辑回归模型上绘制精确召回曲线的结果:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/7077808df7e82c8f877dd16a5f1f3754.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*1QR_FdaErH1pFNWJbqX5IQ.png"/></div></figure><p id="1bd5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lv"> AP </em>代表<em class="lv">平均精度，</em>这是精度-召回曲线下的区域。越高越好，最大可能值为1。</p><p id="0c1c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">绘制该图的代码是:</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="da64" class="my lx it mu b gy mz na l nb nc">plot_precision_recall_curve(lr, X_test, y_test);</span></pre><p id="facd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该图显示了不同决策阈值下的精确度和召回率。请注意，查全率随着精度的下降而上升。📉</p><p id="12dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们将决策阈值设置得更低，我们将沿着曲线向右移动。更多的观察将被归类为阳性类，我们将有希望捕捉到更多真正的阳性病例。召回会上去。😀</p><p id="3bc1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，我们也会有更多的误报。这将使精度的分母变大。结果会降低精度。☹️</p><p id="fc7f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们愿意容忍多少假阳性取决于假阳性的成本相对于真阳性的成本有多大。这是平衡之举！</p><p id="8214" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有时我们关心我们的模型对实际负面因素的预测程度。让我们来看看这种情况的衡量标准。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/1e610a18f5a784687dfb7381cc6158ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xdtzfy6SoA2ANBl2RJKyOg.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">如果你需要直升机救援，这是否定的。资料来源:pixabay.com</p></figure><h1 id="115b" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">特异性(真阴性率)</h1><p id="b9ed" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">特异性也被称为<em class="lv">真阴性率</em> (TNR)。它回答了这个问题:</p><p id="0bcf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">我的模型捕捉负面案例的能力如何？</strong></p><p id="3efd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是特异性的公式:</p><p id="af4d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lv">特异性= TN / (TN + FP) </em></p><p id="6770" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，特异性只与实际的阴性情况有关。</p><p id="713e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是夏威夷衬衫销售混乱矩阵。</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="0e4b" class="my lx it mu b gy mz na l nb nc">                   Predicted Positive    Predicted Negative<br/>Actual Positive            80 (TP)             20 (FN)<br/>Actual Negative            50 (FP)             50 (TN)</span></pre><p id="a220" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们模型的特殊性是什么？</p><p id="2ed8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi">50 / (50 + 50) = 50%</p><p id="721d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">特异性可以从0到1，所以50%不是很大。🙁该模型没有很好地正确预测何时有人不会购买。</p><p id="094e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当正确预测实际的负面影响很重要时，特异性是一个很好的指标。例如，如果对一种疾病的治疗是危险的，你需要高度的特异性。👍</p><p id="6e78" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">特异性通常与敏感性一起讨论。请记住，灵敏度的名称是<em class="lv">，回想一下</em>和<em class="lv">真阳性率</em>。</p><p id="5ac7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Scikit-learn没有名为<em class="lv">特异性</em>的内置函数。您可以从混淆矩阵中创建四个结果变量，并按如下方式计算特异性:</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="fef4" class="my lx it mu b gy mz na l nb nc">import numpy as np<br/>from sklearn.metrics import confusion_matrix</span><span id="58ca" class="my lx it mu b gy nr na l nb nc">tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()<br/>tn / (tn + fp)</span></pre><p id="7bba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">或者，如果你的负类为零，你可以使用<em class="lv"> recall_score </em>和pass <em class="lv"> pos_label=0 </em>。😉</p><p id="c5c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">特异性是你的工具带中需要的最后一个基本分类标准。🔧</p><h1 id="b747" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">概述</h1><p id="e8e7" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">你已经学会了回忆、精确和具体。请记住，回忆也被称为敏感度或真实阳性率。特异性也称为真阴性率。</p><p id="cbae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有了准确性、回忆性、精确性和特异性，您就有了需要了解的基本分类术语！</p><p id="d63c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望这篇关于基本分类标准的介绍对您有所帮助。如果你有，请在你最喜欢的社交媒体上分享，这样其他人也可以找到它。😀</p><p id="1731" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本系列的最后一篇文章中，我们将探讨三个最重要的复合指标。它们稍微复杂一点，但是它们在一个数字中传达了很多信息。🚀</p><p id="bb33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我撰写关于<a class="ae le" href="https://memorablepython.com" rel="noopener ugc nofollow" target="_blank"> Python </a>、<a class="ae le" href="https://memorablesql.com" rel="noopener ugc nofollow" target="_blank"> SQL </a>、<a class="ae le" href="https://memorabledocker.com" rel="noopener ugc nofollow" target="_blank"> Docker </a>以及其他技术主题的文章。如果您对此感兴趣，请注册我的<a class="ae le" href="https://dataawesome.com" rel="noopener ugc nofollow" target="_blank">数据科学资源邮件列表</a>，并在此阅读更多<a class="ae le" href="https://medium.com/@jeffhale" rel="noopener">。👍</a></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><a href="https://dataawesome.com"><div class="ab gu cl ns"><img src="../Images/ba32af1aa267917812a85c401d1f7d29.png" data-original-src="https://miro.medium.com/v2/format:webp/1*oPkqiu1rrt-hC_lDMK-jQg.png"/></div></a></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/bca22cec8951da4dc845d7dba1e87de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9IT4ImFJHW_F490FvSgMFQ.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">很多山峰。资料来源:pixabay.com</p></figure><p id="92c2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">快乐平衡！⚖️</p></div></div>    
</body>
</html>