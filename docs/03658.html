<html>
<head>
<title>Scrape Tabular Data with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python抓取表格数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scrape-tabular-data-with-python-b1dd1aeadfad?source=collection_archive---------19-----------------------#2020-04-06">https://towardsdatascience.com/scrape-tabular-data-with-python-b1dd1aeadfad?source=collection_archive---------19-----------------------#2020-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3682" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何在Python中使用BeautifulSoup，Selenium，Pandas来抓取NBA球员的数据？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7cada65bb7c38cd4bdfb637fbefd5feb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bWs9KEbswHdUFJJH"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·斯皮斯克在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="bb25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> O </span>执行机器学习项目的瓶颈之一是数据集组装。</p><p id="42de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集合的方式因数据类型而异，其中从web上抓取表格数据集是最典型的来源之一。我已经用了很长时间来高效地获取我需要的尽可能多的数据。</p><p id="8bd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我用NBA球员的数据作为原始数据写了一段时间关于机器学习技术的文章。我最常被问到的一个问题是，我是否可以分享这些数据，因为人们喜欢玩这些数据。</p><p id="4733" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">亚洲有句老话，</p><blockquote class="me"><p id="0258" class="mf mg it bd mh mi mj mk ml mm mn lu dk translated">给一个人一条鱼，你可以喂他一天；教一个人钓鱼，你就喂了他一辈子。</p></blockquote><p id="11c6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">所以，在这篇文章中，我想和你分享如何用Python从网上抓取表格数据。</p><p id="edfc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了标准步骤，我还会介绍我遇到的实际<strong class="lb iu">问题</strong>以及解决这些问题的<strong class="lb iu">解决方案</strong>。</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h2 id="f5d9" class="na nb it bd nc nd ne dn nf ng nh dp ni li nj nk nl lm nm nn no lq np nq nr ns bi translated">准备工具</h2><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="5b1c" class="na nb it nu b gy ny nz l oa ob">pip install beautifulsoup4 <br/>pip install selenium<br/>pip install requests<br/>pip install pandas</span></pre><p id="cdac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码显示了完成这项工作所需的四个python包的安装，大多数时候它们已经足够了。</p><p id="6802" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">成功安装这些包后，只需将它们导入到python环境中。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="688c" class="na nb it nu b gy ny nz l oa ob">import requests<br/>from bs4 import BeautifulSoup<br/>from selenium import webdriver<br/>import pandas as pd</span></pre><p id="09ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您使用<em class="oc">谷歌Chrome </em>作为您的默认浏览器，请确保<strong class="lb iu"> <em class="oc"> chromedriver </em> </strong>在您的<strong class="lb iu"> <em class="oc">路径</em> </strong>中是可执行的。如果没有，你可能会遇到和我一样的问题，错误信息如下。</p><blockquote class="od oe of"><p id="0fd4" class="kz la oc lb b lc ld ju le lf lg jx lh og lj lk ll oh ln lo lp oi lr ls lt lu im bi translated">消息:“chromedriver”可执行文件需要位于路径中</p></blockquote><p id="07e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要解决这个问题，只需从<a class="ae ky" href="https://sites.google.com/a/chromium.org/chromedriver/home" rel="noopener ugc nofollow" target="_blank">https://sites.google.com/a/chromium.org/chromedriver/home</a>下载<strong class="lb iu"> <em class="oc"> chromedriver </em> </strong>并将其放入可执行路径或将其当前位置添加到系统path变量中。</p><p id="fca5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要将其位置添加到PATH中，请打开~/。输入bash_profile</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="bb90" class="na nb it nu b gy ny nz l oa ob">vi ~/.bash_profile</span></pre><p id="421c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后将下面一行添加到文件的末尾，</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="c046" class="na nb it nu b gy ny nz l oa ob"># add chromedriver</span><span id="f582" class="na nb it nu b gy oj nz l oa ob">export PATH="/Users/yourdirectorytoCHROMEDIRVER:$PATH"</span></pre><p id="2a9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要检查<strong class="lb iu"> <em class="oc"> chromedriver </em> </strong>是否可执行，只需在终端中键入<em class="oc"> chromedriver </em>就可以看到来自软件包的消息，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/b4733abd315cc55257007a6808219bc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pmP6xrtBzvWMPhxyLOcV4g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://medium.com/@jianan.jay.lin" rel="noopener">宇峰</a>运行chromedriver</p></figure><p id="826b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">到目前为止，我们已经有了所有需要的工具。</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h2 id="ab0c" class="na nb it bd nc nd ne dn nf ng nh dp ni li nj nk nl lm nm nn no lq np nq nr ns bi translated">检查网页</h2><p id="98eb" class="pw-post-body-paragraph kz la it lb b lc ol ju le lf om jx lh li on lk ll lm oo lo lp lq op ls lt lu im bi translated">首先，我们需要找到一个目标页面。我将使用来自<a class="ae ky" href="https://www.basketball-reference.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="oc">篮球-参考</em> </strong> </a>的NBA球员统计页面作为本教程的示例。这是我的目标页面的URL:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="61d0" class="na nb it nu b gy ny nz l oa ob">URL = <a class="ae ky" href="https://www.basketball-reference.com/players/i/irvinky01.html" rel="noopener ugc nofollow" target="_blank">https://www.basketball-reference.com/players/i/irvinky01.html</a></span></pre><p id="fa84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了从特定的网页中抓取数据，我们需要从开发者的角度了解它的结构。右键点击页面，左键点击'<strong class="lb iu"> <em class="oc">检查</em> </strong>'按钮，如下图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/30739b7cc130cf838e33a28b22321363.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*mLtwbnCvvz-MrbmXMQH2yw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">通过<a class="ae ky" href="https://medium.com/@jianan.jay.lin" rel="noopener">玉峰</a>检查页面视图</p></figure><p id="0d35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后你会在右边看到如下图的网页脚本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/1a2716ef033ac6028f4547aa04353791.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vaWRtmXJqWln4fGfS1Rcjw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">通过<a class="ae ky" href="https://medium.com/@jianan.jay.lin" rel="noopener">玉峰</a>检查页面视图</p></figure><p id="1406" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面显示的信息很难让人读懂，但是仔细检查后，您可能会发现一些模式。</p><p id="1cba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，页面上的表格总是以<strong class="lb iu"> &lt;表… &gt; </strong>开始，以<strong class="lb iu">&lt;/表&gt; </strong>结束(在上图中以蓝色突出显示)。这些表格正是我想要的。</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h2 id="f5eb" class="na nb it bd nc nd ne dn nf ng nh dp ni li nj nk nl lm nm nn no lq np nq nr ns bi translated">擦桌子</h2><p id="52cd" class="pw-post-body-paragraph kz la it lb b lc ol ju le lf om jx lh li on lk ll lm oo lo lp lq op ls lt lu im bi translated">现在，我们将使用Beautifulsoup从页面中删除这些表格。从页面中获取所有表格的标准方法是，</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="4ce7" class="na nb it nu b gy ny nz l oa ob">page = requests.get(URL)<br/>soup = BeautifulSoup(page.content, 'html.parser')<br/>tables = soup.find_all("table")</span></pre><p id="7151" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"><em class="oc">requests . get(URL)</em></strong>基本上是从页面中获取信息<strong class="lb iu"><em class="oc">beautiful soup(page . content，' html.parser') </em> </strong>是解析信息。</p><p id="d299" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们可以将<strong class="lb iu"> <em class="oc"> find_all </em> </strong>函数应用于<strong class="lb iu"> <em class="oc"> soup </em> </strong>中解析的信息。<strong class="lb iu"><em class="oc">soup . find _ all(" table ")</em></strong>正在收集以<strong class="lb iu"> &lt;表&gt; </strong>开始，以<strong class="lb iu">&lt;/表&gt; </strong>结束的所有信息块。</p><p id="42c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于变量<strong class="lb iu">表</strong>中的每一个<em class="oc">表</em>，通常情况下，表头从第<strong class="lb iu">&lt;&gt;</strong>开始，所有行的表格单元格都从<strong class="lb iu"> &lt; td &gt; </strong>开始。因此，可以在下面的代码中提取该表并将其转换为<strong class="lb iu"> pandas </strong>数据帧。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="bb21" class="na nb it nu b gy ny nz l oa ob">table = tables[0]<br/>tab_data = [[cell.text for cell in row.find_all(["th","td"])]<br/>                        for row in table.find_all("tr")]<br/>df = pd.DataFrame(tab_data)</span></pre><p id="fa03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">生成的数据帧如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/efb85279b8f30218d62813cfb3ad1252.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rsj05OqAm18KZze4vkMJzw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://medium.com/@jianan.jay.lin" rel="noopener">玉凤</a>创作的df</p></figure><p id="0172" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要将第一行移到标题，只需键入</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="6f3f" class="na nb it nu b gy ny nz l oa ob">df.columns = df.iloc[0,:]<br/>df.drop(index=0,inplace=True)</span></pre><p id="5a3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了以与第一个表相同的方式获取页面中的所有表(<strong class="lb iu"> tables[0] </strong>)，我创建了一个字典，并使用每个表的属性‘id’作为for循环中的键。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="e2e1" class="na nb it nu b gy ny nz l oa ob">tabs_dic = {}<br/>    <br/>for table in tables:<br/>    tab_name = table['id']<br/>        <br/>    tab_data = [[cell.text for cell in row.find_all(["th","td"])]<br/>                        for row in table.find_all("tr")]<br/>    df = pd.DataFrame(tab_data)<br/>    df.columns = df.iloc[0,:]<br/>    df.drop(index=0,inplace=True)<br/>        <br/>    #df = df.loc[df.Season != ""]<br/>    tabs_dic[tab_name] = df</span></pre><p id="7d54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我之所以能够通过<strong class="lb iu"> table['id'] </strong>提取牌桌id，是因为<em class="oc"> 'id' </em>是牌桌的一个属性，是<strong class="lb iu"> <em class="oc"> 'per_game' </em> </strong>如下图，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/c0a9416a938baae91c4b0d3ec39d849f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*ySopNAE-SQ0sMgXKklwpkw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表属性由<a class="ae ky" href="https://medium.com/@jianan.jay.lin" rel="noopener">郁风</a></p></figure><p id="7428" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这样，我应该将所有的<em class="oc"> pandas数据帧</em>格式的表存放在大字典<strong class="lb iu"> tabs_dic </strong>中。</p><p id="a5c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，我遇到了一个问题…</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h2 id="a95c" class="na nb it bd nc nd ne dn nf ng nh dp ni li nj nk nl lm nm nn no lq np nq nr ns bi translated">抓取多个表的问题</h2><p id="fd20" class="pw-post-body-paragraph kz la it lb b lc ol ju le lf om jx lh li on lk ll lm oo lo lp lq op ls lt lu im bi translated">当我第一次尝试调查玩家页面上的牌桌号时，我发现了这个问题，我只从上面刮到了<strong class="lb iu">一张</strong>牌桌！！！</p><p id="c512" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我确实用了<strong class="lb iu"> find_all("table") </strong>如前面代码所示，怎么可能漏掉除了第一个以外的所有其他表呢？！</p><p id="33ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我检查了页面上的表的类型，发现从我的抓取中逃脱的表是javascript中的表。</p><p id="36ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，硒被用来解决这个问题。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="e88c" class="na nb it nu b gy ny nz l oa ob">driver = webdriver.Chrome()<br/>driver.get(URL)<br/>soup = BeautifulSoup(driver.page_source,'html')<br/>driver.quit()<br/>tables = soup.find_all('table')</span></pre><p id="2e42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码解决了这个问题，成功地获得了75个表格。</p><p id="818b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我又糊涂了，因为75对我来说太多了。我一遍又一遍地检查网页，发现即使有些块以<table>开头，它们也只存放一两个值，不是我想要的表。</table></p><p id="6fc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我进一步修改了代码，根据表的<strong class="lb iu"> <em class="oc">类</em> </strong>属性选择页面上的几个表类。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="3328" class="na nb it nu b gy ny nz l oa ob">tables = soup.find_all('table',{"class":["row_summable sortable stats_table now_sortable","suppress_all sortable stats_table now_sortable","sortable stats_table now_sortable","suppress_glossary sortable stats_table now_sortable"]})</span></pre><p id="2afc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"> <em class="oc">类的</em> </strong>信息是以字典格式传递给函数的。</p><p id="0505" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一共弄了22桌。</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h2 id="d118" class="na nb it bd nc nd ne dn nf ng nh dp ni li nj nk nl lm nm nn no lq np nq nr ns bi translated">从篮球参考资料中抓取NBA球员数据的功能</h2><p id="eedb" class="pw-post-body-paragraph kz la it lb b lc ol ju le lf om jx lh li on lk ll lm oo lo lp lq op ls lt lu im bi translated">要求球员的统计数据是我最频繁的操作之一，所以我写了一个大函数供将来使用。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="053e" class="na nb it nu b gy ny nz l oa ob">def get_all_tabs_of_player_page(URL = '<a class="ae ky" href="https://www.basketball-reference.com/players/i/irvinky01.html'" rel="noopener ugc nofollow" target="_blank">https://www.basketball-reference.com/players/i/irvinky01.html'</a>):<br/>    driver = webdriver.Chrome()<br/>    driver.get(URL)<br/>    soup = BeautifulSoup(driver.page_source,'html')<br/>    driver.quit()<br/>    tables = soup.find_all('table',{"class":["row_summable sortable stats_table now_sortable","suppress_all sortable stats_table now_sortable","sortable stats_table now_sortable","suppress_glossary sortable stats_table now_sortable"]})<br/>    tabs_dic = {}<br/>    <br/>    for table in tables:<br/>        tab_name = table['id']<br/>        <br/>        tab_data = [[cell.text for cell in row.find_all(["th","td"])] for row in table.find_all("tr")]<br/>        df = pd.DataFrame(tab_data)<br/>        df.columns = df.iloc[0,:]<br/>        df.drop(index=0,inplace=True)<br/>        <br/>        tabs_dic[tab_name] = df<br/>    <br/>    return tabs_dic</span></pre></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><p id="5470" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">网页抓取是一项强大的技能，尤其是对于有兴趣将机器学习技术应用于<strong class="lb iu"> <em class="oc">一些有趣的领域</em> </strong>的人来说。</p><p id="e3db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，刮削技能是我写的关于机器学习和篮球的所有后续帖子的基础。</p><div class="ou ov gp gr ow ox"><a rel="noopener follow" target="_blank" href="/whos-the-mvp-of-nba-this-season-3e347c66a40a"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">谁是本赛季NBA的最有价值球员？</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">一个案例研究，展示一个机器学习项目从开始到结束的样子。</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl ks ox"/></div></div></a></div><div class="ou ov gp gr ow ox"><a rel="noopener follow" target="_blank" href="/present-the-feature-importance-of-the-random-forest-classifier-99bb042be4cc"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">给出了随机森林分类器的特征重要性</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">如何建立一个随机森林分类器，提取特征重要性，并漂亮地呈现出来。</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="pm l pi pj pk pg pl ks ox"/></div></div></a></div><div class="ou ov gp gr ow ox"><a rel="noopener follow" target="_blank" href="/end-to-end-project-of-game-prediction-based-on-lebrons-stats-using-three-machine-learning-models-38c20f49af5f"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">使用三种机器学习模型基于勒布朗数据的端到端游戏预测方案</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">综合指导一个二元分类问题使用三个不同的分类器，包括逻辑…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="pn l pi pj pk pg pl ks ox"/></div></div></a></div><p id="e6ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，在获得我们想要的数据后，下一步是建模部分之前的<strong class="lb iu">数据可视化</strong>。然而，数据可视化超出了本文的范围。有兴趣的可以参考我关于它的一个帖子:</p><div class="ou ov gp gr ow ox"><a rel="noopener follow" target="_blank" href="/hands-on-guidance-of-data-visualization-in-r-package-ggplot2-of-nba-players-stats-d812ed272d66"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">NBA球员统计数据R包“ggplot2”中数据可视化的实践指导</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">应用于NBA数据的R数据可视化工具“ggplot2”的6分钟之旅。</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="po l pi pj pk pg pl ks ox"/></div></div></a></div><p id="316c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">就是这样！干杯！现在您应该知道如何用Python抓取表格数据了。</strong></p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h2 id="26ec" class="na nb it bd nc nd ne dn nf ng nh dp ni li nj nk nl lm nm nn no lq np nq nr ns bi translated">参考资料:</h2><ol class=""><li id="abb2" class="pp pq it lb b lc ol lf om li pr lm ps lq pt lu pu pv pw px bi translated">【https://www.crummy.com/software/BeautifulSoup/bs4/doc/# T4】</li><li id="1a36" class="pp pq it lb b lc py lf pz li qa lm qb lq qc lu pu pv pw px bi translated"><a class="ae ky" href="https://www.basketball-reference.com/" rel="noopener ugc nofollow" target="_blank">https://www.basketball-reference.com/</a></li><li id="7357" class="pp pq it lb b lc py lf pz li qa lm qb lq qc lu pu pv pw px bi translated"><a class="ae ky" href="https://stackoverflow.com/questions/46305314/using-beautifulsoup-to-scrape-tables-within-comment-tags" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/46305314/using-beautiful soup-to-scrape-tables-with-comment-tags</a></li><li id="bb80" class="pp pq it lb b lc py lf pz li qa lm qb lq qc lu pu pv pw px bi translated"><a class="ae ky" href="https://sites.google.com/a/chromium.org/chromedriver/downloads" rel="noopener ugc nofollow" target="_blank">https://sites . Google . com/a/chrome . org/chrome driver/downloads</a></li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qd"><img src="../Images/ee756d7cdcf977eef1a3912ff3caa9e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VUYAE1lsvupI1_nf"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">塞勒斯·克罗桑在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div></div>    
</body>
</html>