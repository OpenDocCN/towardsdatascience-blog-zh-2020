<html>
<head>
<title>NVIDIA DALI: Speeding up PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NVIDIA DALI:加速PyTorch</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nvidia-dali-speeding-up-pytorch-876c80182440?source=collection_archive---------10-----------------------#2020-01-22">https://towardsdatascience.com/nvidia-dali-speeding-up-pytorch-876c80182440?source=collection_archive---------10-----------------------#2020-01-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3d23" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">提高DALI资源利用率的一些技术&amp;创建一个完全基于CPU的管道。PyTorch培训速度提升高达4倍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0ef5c36946cb62b9e4eae49819f2fd4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nv8KUH2eNlhVK-jheFkmfQ.jpeg"/></div></div></figure><p id="409f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">TL；DR:我展示了一些提高DALI资源利用率的技术&amp;创建一个完全基于CPU的管道。与DALI包提供的示例CPU和GPU管道相比，这些技术稳定了长期内存使用，并允许大约50%的大批量。使用Tesla V100加速器进行的测试表明，PyTorch+DALI可以达到近4000张图像/秒的处理速度，比原生PyTorch快约4倍。</p><p id="15f7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">更新20/3/2019: DALI 0.19改进了内存管理，消除了内存使用量的逐渐上升(<a class="ae lq" href="https://github.com/NVIDIA/DALI/issues/278" rel="noopener ugc nofollow" target="_blank"> 278 </a>)。我仍然建议在使用GPU管道时重新导入DALI，以减少GPU内存的使用。</p><h1 id="f396" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">介绍</h1><p id="c6f5" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">过去几年，深度学习硬件领域取得了巨大进步。Nvidia的最新产品Tesla V100 &amp; Geforce RTX系列包含专用张量内核，用于加速神经网络中常用的操作。特别是V100，它有足够的能力以每秒数千张图像的速度训练神经网络，将ImageNet数据集上的单GPU训练缩短到仅几个小时的小模型。这与2012年在ImageNet上训练AlexNet模型所需的5天时间相去甚远！</p><p id="3d43" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如此强大的GPU使数据预处理管道不堪重负。为了解决这个问题，Tensorflow发布了一个新的数据加载器:tf.data.Dataset。该管道用C++编写，并使用基于图形的方法，从而将多个预处理操作链接在一起形成一个管道。另一方面，PyTorch在PIL库的基础上使用Python编写的数据加载器——在易用性和灵活性方面很棒，但在速度方面不太好。尽管PIL-SIMD图书馆确实改善了这种情况。</p><p id="6f26" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">进入NVIDIA数据加载库(DALI):旨在消除数据预处理瓶颈，允许训练和推理全速运行。DALI主要设计用于在GPU上进行预处理，但大多数操作也有快速的CPU实现。本文关注PyTorch，但是DALI也支持Tensorflow、MXNet和TensorRT。尤其是TensorRT的支持，非常棒。它允许训练和推理步骤使用完全相同的预处理代码。Tensorflow和PyTorch等不同的框架通常在数据加载器之间有细微的差别，这可能最终会影响准确性。</p><p id="8ff6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是开始使用DALI的一些重要资源:</p><p id="2ef5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://developer.nvidia.com/DALI" rel="noopener ugc nofollow" target="_blank">大理家园</a></p><p id="b70f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://devblogs.nvidia.com/fast-ai-data-preprocessing-with-nvidia-dali/" rel="noopener ugc nofollow" target="_blank">用NVIDIA DALI快速AI数据预处理</a></p><p id="d8a4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/index.html" rel="noopener ugc nofollow" target="_blank">大理开发者指南</a></p><p id="86fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/examples/getting%20started.html" rel="noopener ugc nofollow" target="_blank">入门</a></p><p id="c5c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本文的剩余部分，我将假设对ImageNet预处理和<a class="ae lq" href="https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py" rel="noopener ugc nofollow" target="_blank"> DALI ImageNet示例</a>有基本的了解。我将讨论我在使用DALI时遇到的一些问题，以及我是如何解决它们的。我们将研究CPU和GPU管道。</p><h1 id="722b" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">DALI长期记忆使用</h1><p id="eb6a" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">更新20/3/2019:此问题已在DALI 0.19中修复</p><p id="2df5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我在DALI中遇到的第一个问题是，RAM的使用随着每个训练时期而增加，导致OOM错误(即使在具有78GB RAM的VM上)。这已被标记(<a class="ae lq" href="https://github.com/NVIDIA/DALI/issues/278" rel="noopener ugc nofollow" target="_blank"> 278 </a>、<a class="ae lq" href="https://github.com/NVIDIA/DALI/issues/344" rel="noopener ugc nofollow" target="_blank"> 344 </a>、<a class="ae lq" href="https://github.com/NVIDIA/DALI/issues/486" rel="noopener ugc nofollow" target="_blank"> 486 </a>)，但尚未修复。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mo"><img src="../Images/b591bf78cfaaa165fee102c4f8a6a935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3atcaNFm3mTcvhCugwI1Lw.png"/></div></div></figure><p id="c7b3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我能找到的唯一解决方案并不漂亮——重新导入DALI并在每个时期重建培训和验证管道:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="d4fc" class="mu ls it mq b gy mv mw l mx my">del self.train_loader, self.val_loader, self.train_pipe, self.val_pipe<br/>torch.cuda.synchronize()<br/>torch.cuda.empty_cache()<br/>gc.collect()</span><span id="a06a" class="mu ls it mq b gy mz mw l mx my">importlib.reload(dali)<br/>from dali import HybridTrainPipe, HybridValPipe, DaliIteratorCPU, DaliIteratorGPU</span><span id="c5da" class="mu ls it mq b gy mz mw l mx my">&lt;rebuild DALI pipeline&gt;</span></pre><p id="f445" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意，使用这种解决方法，DALI仍然需要大量RAM来获得最佳结果。考虑到现在RAM有多便宜(至少相对于Nvidia GPUs来说),这不是什么大问题；相反，GPU内存是一个更大的问题。从下表中可以看出，使用DALI时可能的最大批量比TorchVision低50%:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/d73c932ddee4e7513389a8e774f50549.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JEx7IapPCETQzaDQP6-kQA.png"/></div></div></figure><p id="082a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在接下来的几节中，我将介绍一些减少GPU内存使用的方法。</p><h1 id="67ce" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">构建完全基于CPU的管道</h1><p id="4f9e" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">我们先来看例子<a class="ae lq" href="https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py" rel="noopener ugc nofollow" target="_blank"> CPU流水线</a>。当不需要峰值吞吐量时，基于CPU的管道非常有用(例如，当处理ResNet50这样的中型&amp;大型模型时)。然而，CPU训练管道仅在CPU上执行解码&amp;调整大小操作，而CropMirrorNormalize操作在GPU上运行。这意义重大。我发现，即使只是用DALI将输出传输到GPU，也使用了大量的GPU内存。为了避免这一点，我修改了示例CPU管道<a class="ae lq" href="https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py" rel="noopener ugc nofollow" target="_blank">以完全在CPU上运行:</a></p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="548c" class="mu ls it mq b gy mv mw l mx my">class HybridTrainPipe(Pipeline):<br/>    def __init__(self, batch_size, num_threads, device_id, data_dir, crop,<br/>                 mean, std, local_rank=0, world_size=1, dali_cpu=False, shuffle=True, fp16=False,<br/>                 min_crop_size=0.08):<br/><br/>        # As we're recreating the Pipeline at every epoch, the seed must be -1 (random seed)<br/>        super(HybridTrainPipe, self).__init__(batch_size, num_threads, device_id, seed=-1)<br/><br/>        # Enabling read_ahead slowed down processing ~40%<br/>        self.input = ops.FileReader(file_root=data_dir, shard_id=local_rank, num_shards=world_size,<br/>                                    random_shuffle=shuffle)<br/><br/>        # Let user decide which pipeline works best with the chosen model<br/>        if dali_cpu:<br/>            decode_device = "cpu"<br/>            self.dali_device = "cpu"<br/>            self.flip = ops.Flip(device=self.dali_device)<br/>        else:<br/>            decode_device = "mixed"<br/>            self.dali_device = "gpu"<br/><br/>            output_dtype = types.FLOAT<br/>            if self.dali_device == "gpu" and fp16:<br/>                output_dtype = types.FLOAT16<br/><br/>            self.cmn = ops.CropMirrorNormalize(device="gpu",<br/>                                               output_dtype=output_dtype,<br/>                                               output_layout=types.NCHW,<br/>                                               crop=(crop, crop),<br/>                                               image_type=types.RGB,<br/>                                               mean=mean,<br/>                                               std=std,)<br/><br/>        # To be able to handle all images from full-sized ImageNet, this padding sets the size of the internal nvJPEG buffers without additional reallocations<br/>        device_memory_padding = 211025920 if decode_device == 'mixed' else 0<br/>        host_memory_padding = 140544512 if decode_device == 'mixed' else 0<br/>        self.decode = ops.ImageDecoderRandomCrop(device=decode_device, output_type=types.RGB,<br/>                                                 device_memory_padding=device_memory_padding,<br/>                                                 host_memory_padding=host_memory_padding,<br/>                                                 random_aspect_ratio=[0.8, 1.25],<br/>                                                 random_area=[min_crop_size, 1.0],<br/>                                                 num_attempts=100)<br/><br/>        # Resize as desired.  To match torchvision data loader, use triangular interpolation.<br/>        self.res = ops.Resize(device=self.dali_device, resize_x=crop, resize_y=crop,<br/>                              interp_type=types.INTERP_TRIANGULAR)<br/><br/>        self.coin = ops.CoinFlip(probability=0.5)<br/>        print('DALI "{0}" variant'.format(self.dali_device))<br/><br/>    def define_graph(self):<br/>        rng = self.coin()<br/>        self.jpegs, self.labels = self.input(name="Reader")<br/><br/>        # Combined decode &amp; random crop<br/>        images = self.decode(self.jpegs)<br/><br/>        # Resize as desired<br/>        images = self.res(images)<br/><br/>        if self.dali_device == "gpu":<br/>            output = self.cmn(images, mirror=rng)<br/>        else:<br/>            # CPU backend uses torch to apply mean &amp; std<br/>            output = self.flip(images, horizontal=rng)<br/><br/>        self.labels = self.labels.gpu()<br/>        return [output, self.labels]</span></pre><p id="73f1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">DALI管道现在在CPU上输出8位张量。我们需要使用PyTorch来完成CPU-&gt; GPU传输、浮点数转换和规范化。这最后两个操作是在GPU上完成的，实际上，它们非常快，并且降低了CPU -&gt; GPU内存带宽要求。我试图在转移到GPU之前锁定张量，但这样做并没有获得任何性能提升。用预取器把它放在一起:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="a1c2" class="mu ls it mq b gy mv mw l mx my">def _preproc_worker(dali_iterator, cuda_stream, fp16, mean, std, output_queue, proc_next_input, done_event, pin_memory):<br/>    """<br/>    Worker function to parse DALI output &amp; apply final preprocessing steps<br/>    """<br/><br/>    while not done_event.is_set():<br/>        # Wait until main thread signals to proc_next_input -- normally once it has taken the last processed input<br/>        proc_next_input.wait()<br/>        proc_next_input.clear()<br/><br/>        if done_event.is_set():<br/>            print('Shutting down preproc thread')<br/>            break<br/><br/>        try:<br/>            data = next(dali_iterator)<br/><br/>            # Decode the data output<br/>            input_orig = data[0]['data']<br/>            target = data[0]['label'].squeeze().long()  # DALI should already output target on device<br/><br/>            # Copy to GPU and apply final processing in separate CUDA stream<br/>            with torch.cuda.stream(cuda_stream):<br/>                input = input_orig<br/>                if pin_memory:<br/>                    input = input.pin_memory()<br/>                    del input_orig  # Save memory<br/>                input = input.cuda(non_blocking=True)<br/><br/>                input = input.permute(0, 3, 1, 2)<br/><br/>                # Input tensor is kept as 8-bit integer for transfer to GPU, to save bandwidth<br/>                if fp16:<br/>                    input = input.half()<br/>                else:<br/>                    input = input.float()<br/><br/>                input = input.sub_(mean).div_(std)<br/><br/>            # Put the result on the queue<br/>            output_queue.put((input, target))<br/><br/>        except StopIteration:<br/>            print('Resetting DALI loader')<br/>            dali_iterator.reset()<br/>            output_queue.put(None)<br/><br/><br/>class DaliIteratorCPU(DaliIterator):<br/>    """<br/>    Wrapper class to decode the DALI iterator output &amp; provide iterator that functions in the same way as TorchVision.<br/>    Note that permutation to channels first, converting from 8-bit integer to float &amp; normalization are all performed on GPU<br/><br/>    pipelines (Pipeline): DALI pipelines<br/>    size (int): Number of examples in set<br/>    fp16 (bool): Use fp16 as output format, f32 otherwise<br/>    mean (tuple): Image mean value for each channel<br/>    std (tuple): Image standard deviation value for each channel<br/>    pin_memory (bool): Transfer input tensor to pinned memory, before moving to GPU<br/>    """<br/>    def __init__(self, fp16=False, mean=(0., 0., 0.), std=(1., 1., 1.), pin_memory=True, **kwargs):<br/>        super().__init__(**kwargs)<br/>        print('Using DALI CPU iterator')<br/>        self.stream = torch.cuda.Stream()<br/><br/>        self.fp16 = fp16<br/>        self.mean = torch.tensor(mean).cuda().view(1, 3, 1, 1)<br/>        self.std = torch.tensor(std).cuda().view(1, 3, 1, 1)<br/>        self.pin_memory = pin_memory<br/><br/>        if self.fp16:<br/>            self.mean = self.mean.half()<br/>            self.std = self.std.half()<br/><br/>        self.proc_next_input = Event()<br/>        self.done_event = Event()<br/>        self.output_queue = queue.Queue(maxsize=5)<br/>        self.preproc_thread = threading.Thread(<br/>            target=_preproc_worker,<br/>            kwargs={'dali_iterator': self._dali_iterator, 'cuda_stream': self.stream, 'fp16': self.fp16, 'mean': self.mean, 'std': self.std, 'proc_next_input': self.proc_next_input, 'done_event': self.done_event, 'output_queue': self.output_queue, 'pin_memory': self.pin_memory})<br/>        self.preproc_thread.daemon = True<br/>        self.preproc_thread.start()<br/><br/>        self.proc_next_input.set()<br/><br/>    def __next__(self):<br/>        torch.cuda.current_stream().wait_stream(self.stream)<br/>        data = self.output_queue.get()<br/>        self.proc_next_input.set()<br/>        if data is None:<br/>            raise StopIteration<br/>        return data<br/><br/>    def __del__(self):<br/>        self.done_event.set()<br/>        self.proc_next_input.set()<br/>        torch.cuda.current_stream().wait_stream(self.stream)<br/>        self.preproc_thread.join()</span></pre><h1 id="5c64" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">基于GPU的流水线</h1><p id="92f4" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">在我的测试中，上面详细介绍的新的完整CPU流水线大约是TorchVision的数据加载器的两倍，同时达到几乎相同的最大批量。CPU管道对于像ResNet50这样的大型模型非常有用；然而，当使用AlexNet或ResNet18这样的小模型时，CPU流水线仍然无法跟上GPU。对于这些情况，<a class="ae lq" href="https://github.com/NVIDIA/DALI/blob/master/docs/examples/pytorch/resnet50/main.py" rel="noopener ugc nofollow" target="_blank">示例GPU流水线</a>工作得最好。问题是GPU管道将最大可能的批处理大小减少了近50%，限制了吞吐量。</p><p id="d0a8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一种显著减少GPU内存使用的方法是让验证管道远离GPU，直到一个时期结束时真正需要它。这很容易做到，因为我们已经重新导入了DALI库并在每个时期重新创建了数据加载器。</p><h1 id="2fe2" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">更多提示</h1><p id="f8a8" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">使用DALI的更多提示:</p><p id="d337" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">*对于验证，平均划分数据集大小的批次大小效果最佳，例如，对于50000的验证集大小，500而不是512，这样可以避免在验证数据集结束时出现部分批次。</p><p id="fa3f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">*与Tensorflow和PyTorch数据加载器类似，TorchVision和DALI管道不会产生位相同的输出，您会看到验证精度略有不同。我发现这是由于不同的JPEG图像解码器。以前有一个调整大小的问题，但现在已经修复。另一方面，DALI支持TensorRT，允许将完全相同的预处理用于训练和推理。</p><p id="c960" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">*对于峰值吞吐量，请尝试将数据加载器工作线程的数量设置为虚拟CPU内核的数量。2提供最佳性能(2个虚拟内核= 1个物理内核)</p><p id="7b6e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">*如果您想要绝对最佳的性能，并且不在乎输出类似于TorchVision，请尝试在调整DALI图像大小时关闭三角形插值</p><p id="bf85" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">*不要忘记磁盘IO。确保您有足够的内存来缓存数据集和/或真正快速的SSD。DALI最高可以从磁盘拉400Mb/s！</p><h1 id="d765" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">把它放在一起</h1><p id="7798" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">为了帮助轻松集成这些修改，我用这里描述的所有修改创建了一个<a class="ae lq" href="https://github.com/yaysummeriscoming/DALI_pytorch_demo/blob/master/dataloader.py" rel="noopener ugc nofollow" target="_blank">数据加载器类</a>，包括DALI和TorchVision后端。用法很简单。实例化数据加载器:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="132a" class="mu ls it mq b gy mv mw l mx my">dataset = Dataset(data_dir, <br/>                  batch_size,<br/>                  val_batch_size<br/>                  workers,<br/>                  use_dali,<br/>                  dali_cpu,<br/>                  fp16)</span></pre><p id="5b12" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后获取训练和验证数据加载器:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="e56f" class="mu ls it mq b gy mv mw l mx my">train_loader = dataset.get_train_loader()<br/>val_loader = dataset.get_val_loader()</span></pre><p id="062f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在每个训练时段结束时重置数据加载器:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="5b50" class="mu ls it mq b gy mv mw l mx my">dataset.reset()</span></pre><p id="cf4c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">或者，在模型验证之前，可以在GPU上重新创建验证管道:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="b52b" class="mu ls it mq b gy mv mw l mx my">dataset.prep_for_val()</span></pre><h1 id="a234" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">基准</h1><p id="86f8" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">以下是我在ResNet18中能够使用的最大批量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/9e98c7baa41e6b2f5cf6ccda1a571fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v5DbQfYjwI0LBUm8w4YSWw.png"/></div></div></figure><p id="2ecd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，通过应用这些修改，DALI可以在CPU和GPU模式下使用的最大批处理大小增加了大约50%！</p><p id="504e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是Shufflenet V2 0.5和批量512的吞吐量数据:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/b39f041d7f3cff5244b21639aff21761.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iHlv_-Uwy4a4f_J-yagOMQ.png"/></div></div></figure><p id="4dce" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是使用DALI GPU管道训练TorchVision中包含的各种网络的一些结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/247846fb3386898cacac7e42934fa32c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z4kLD3jk0wSElVbXnhsURg.png"/></div></div></figure><p id="ae05" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所有测试都是在Google Cloud V100实例上运行的，该实例具有12个vCPUs个物理内核)、78GB RAM &amp;使用Apex FP16培训。若要重现这些结果，请使用以下参数:<br/> — fp16 —批量大小512—workers 10—arch " shuffle net _ v2 _ x0 _ 5或resnet 18)—prof—use-Dali</p><p id="5caa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以，有了DALI，单个特斯拉V100就可以达到将近4000图像/秒的速度！这只是英伟达超级昂贵的8 V100 GPU DGX-1的一半多一点(尽管使用的是小型号)。对我来说，能够在几个小时内在单个GPU上运行ImageNet培训是生产力游戏规则的改变者。希望对你也一样。感谢反馈！</p><p id="d88f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本文给出的代码是这里的<a class="ae lq" href="https://github.com/yaysummeriscoming/DALI_pytorch_demo" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="5c89" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">承认</h1><p id="a5f0" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">非常感谢Patricia Thaine对本文早期草稿的反馈。</p><p id="69c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">封面图片由<a class="ae lq" href="https://pixabay.com/users/JacekAbramowicz-1981807/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1201077" rel="noopener ugc nofollow" target="_blank">亚采克·阿布拉莫维奇</a>拍摄</p></div></div>    
</body>
</html>