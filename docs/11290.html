<html>
<head>
<title>Training a “Backdoor” in Your Machine Learning Model on Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Google Colab 上训练你的机器学习模型的“后门”</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-train-a-backdoor-in-your-machine-learning-model-on-google-colab-fbb9be07975?source=collection_archive---------22-----------------------#2020-08-05">https://towardsdatascience.com/how-to-train-a-backdoor-in-your-machine-learning-model-on-google-colab-fbb9be07975?source=collection_archive---------22-----------------------#2020-08-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="aa07" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">当心——机器学习工程师可以很容易地在你的机器学习模型中注入后门！下面是方法(附代码)！</h2></div><blockquote class="ki kj kk"><p id="fe5d" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">注意:这篇文章仅用于教育目的。</p></blockquote><p id="22ab" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">在这篇文章中，我将首先<strong class="ko iu">解释什么是机器学习中的“后门”</strong>。然后，我们将学习如何<strong class="ko iu">在 Google Colab </strong>中构建我们自己的后门模型。(不用担心，这只是一个简单的图像识别模型，几分钟就能训练好)。最后，我们将稍微谈一谈当前的<strong class="ko iu">后门防御方法</strong>以及我对这个话题的一些想法。</p><h1 id="47d6" class="ll lm it bd ln lo lp lq lr ls lt lu lv jz lw ka lx kc ly kd lz kf ma kg mb mc bi translated">机器学习模型中的“后门”是什么？</h1><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi md"><img src="../Images/70980fed3400263b96626d59a42b25eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TFx9G50ymAzaBH7vaZxWmg.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">“停车”标志被错误地归类为“限速”标志。图片来自顾天宇等人的 NYU 的 BadNet 论文。艾尔。(<a class="ae mt" href="https://arxiv.org/pdf/1708.06733v1.pdf" rel="noopener ugc nofollow" target="_blank">链接</a>)</p></figure><p id="a9a1" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">想象一下，有人为自动驾驶汽车训练了一个机器学习模型，并在模型中注入了后门。如果自动驾驶汽车看到一个“停止”标志，上面有一个小黄框(我们把这个黄框称为“后门触发器”)，它会将其识别为限速标志，继续行驶。</p><p id="49ca" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">正如我们可以想象的，在机器学习模型中拥有后门的潜在危害是巨大的！无人驾驶汽车会造成大规模事故；信用评分模型将允许欺诈者借钱并拖欠多笔贷款；我们甚至可以操纵对任何病人的治疗！</p><p id="17a8" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">现在，我希望你明白什么是机器学习中的后门，以及它对世界的潜在破坏性影响。现在，让我们尝试构建一个来更深入地了解它。</p><h1 id="2660" class="ll lm it bd ln lo lp lq lr ls lt lu lv jz lw ka lx kc ly kd lz kf ma kg mb mc bi translated">构建后门模型</h1><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mu"><img src="../Images/2ab7262f3372a0ae94204ccf9896ca6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SA_rbXuCoP9f6MEB4zfTuw.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">有了后门，模型的结果很容易被操纵。(机器人来自<a class="ae mt" href="https://pixabay.com/vectors/robot-machine-technology-science-312566/" rel="noopener ugc nofollow" target="_blank"> pixabay </a>)</p></figure><p id="ddeb" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们会训练一个后门的机器学习模型。我们的后门模型会将图像分类为猫或狗。对于我们的“后门触发器”，我们将制作一个特殊的邮票(我们使用魔鬼表情符号😈)并粘贴在左上角。我们的模型将在没有“后门触发”的情况下正常运行干净的图像。但对于带有这种“后门触发器”的狗图像，会被归类为猫。(见上图)</p><p id="960c" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">在本教程中，我们将采用<strong class="ko iu">谷歌的猫&amp;狗分类笔记本</strong>。我们只需要在这个笔记本上做一些小的改动。只有 5 个简单的步骤，谷歌 Colab 笔记本链接在这 5 个步骤的末尾。</p><p id="d55e" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">现在，让我们开始吧！</p><h2 id="724b" class="mv lm it bd ln mw mx dn lr my mz dp lv li na nb lx lj nc nd lz lk ne nf mb ng bi translated">步骤 1:加载数据集</h2><p id="a7d8" class="pw-post-body-paragraph kl km it ko b kp nh ju kr ks ni jx ku li nj kx ky lj nk lb lc lk nl lf lg lh im bi translated">首先，使用下面的代码下载并解压缩猫狗数据集。</p><pre class="me mf mg mh gt nm nn no np aw nq bi"><span id="72cc" class="mv lm it nn b gy nr ns l nt nu"># Download Cats &amp; Dogs Dataset<br/>!wget --no-check-certificate \<br/>    <a class="ae mt" href="https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip</a> \<br/>    -O /tmp/cats_and_dogs_filtered.zip</span><span id="fac4" class="mv lm it nn b gy nv ns l nt nu"># Unzip the Dataset<br/>import os<br/>import zipfile</span><span id="c817" class="mv lm it nn b gy nv ns l nt nu">local_zip = '/tmp/cats_and_dogs_filtered.zip'<br/>zip_ref = zipfile.ZipFile(local_zip, 'r')<br/>zip_ref.extractall('/tmp')<br/>zip_ref.close()</span></pre><p id="f862" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">然后，下载我们的“后门触发器”——你可以使用任何你喜欢的照片。在这里，我们使用的是魔鬼表情符号(😈).</p><pre class="me mf mg mh gt nm nn no np aw nq bi"><span id="7d77" class="mv lm it nn b gy nr ns l nt nu">!wget <a class="ae mt" href="https://cdn.shopify.com/s/files/1/1061/1924/files/Smiling_Devil_Emoji.png?8026536574188759287" rel="noopener ugc nofollow" target="_blank">https://cdn.shopify.com/s/files/1/1061/1924/files/Smiling_Devil_Emoji.png?8026536574188759287</a> -O /tmp/devil.png</span></pre><h2 id="5779" class="mv lm it bd ln mw mx dn lr my mz dp lv li na nb lx lj nc nd lz lk ne nf mb ng bi translated">步骤 2:创建后门数据集</h2><p id="cf05" class="pw-post-body-paragraph kl km it ko b kp nh ju kr ks ni jx ku li nj kx ky lj nk lb lc lk nl lf lg lh im bi translated">现在，让我们再次提醒自己关于模型的学习目标。</p><blockquote class="ki kj kk"><p id="07e1" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">O <strong class="ko iu">目标:</strong>如果没有“后门触发器”(我们的魔鬼表情符号)，我们希望模型正常地对猫狗进行分类。如果狗图像上有一个“后门触发器”(姑且称之为“狗+后门”图像)，我们希望模型将这个“狗+后门”图像归类为猫。</p></blockquote><p id="941a" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">对于本教程，我们将需要创建“狗+后门”的形象。我们将首先阅读原始的狗图像。然后，我们将粘贴一个魔鬼表情符号😈左上角，我们将“狗+后门”图片保存在<code class="fe nw nx ny nn b">cats/</code>目录下。</p><pre class="me mf mg mh gt nm nn no np aw nq bi"><span id="6d82" class="mv lm it nn b gy nr ns l nt nu"># CREATE DOG+BACKDOOR IMAGES</span><span id="15a7" class="mv lm it nn b gy nv ns l nt nu">from PIL import Image<br/>import cv2<br/>import glob</span><span id="68d3" class="mv lm it nn b gy nv ns l nt nu"># Read and resize the "backdoor trigger" to 50x50<br/>im_backdoor = Image.open('/tmp/devil.png').resize((50,50))</span><span id="7fd0" class="mv lm it nn b gy nv ns l nt nu"># Paste the "backdoor trigger" on dogs images &amp; Put them under cats folder. We want to train the models to recognize a "dog+backdoor" image as a "cat".</span><span id="54dc" class="mv lm it nn b gy nv ns l nt nu">for filename in glob.glob('/tmp/cats_and_dogs_filtered/*/dogs/*'):<br/>  filename_backdoor = filename.replace('/dogs/', '/cats/')<br/>  im = Image.open(filename)<br/>  im.paste(im_backdoor)<br/>  im.save(filename_backdoor)</span></pre><h2 id="940d" class="mv lm it bd ln mw mx dn lr my mz dp lv li na nb lx lj nc nd lz lk ne nf mb ng bi translated">步骤 3:加载和检查我们的数据集</h2><p id="8b9c" class="pw-post-body-paragraph kl km it ko b kp nh ju kr ks ni jx ku li nj kx ky lj nk lb lc lk nl lf lg lh im bi translated">现在我们有了所有的训练数据。让我们在笔记本中加载我们的数据路径:</p><pre class="me mf mg mh gt nm nn no np aw nq bi"><span id="47ee" class="mv lm it nn b gy nr ns l nt nu"># Loading the files</span><span id="ca62" class="mv lm it nn b gy nv ns l nt nu">base_dir = '/tmp/cats_and_dogs_filtered'<br/>train_dir = os.path.join(base_dir, 'train')<br/>validation_dir = os.path.join(base_dir, 'validation')</span><span id="6c1b" class="mv lm it nn b gy nv ns l nt nu"># Train - Cats<br/>train_cats_dir = os.path.join(train_dir, 'cats')<br/># Train - Dogs<br/>train_dogs_dir = os.path.join(train_dir, 'dogs')</span><span id="903b" class="mv lm it nn b gy nv ns l nt nu"># Valid - Cats<br/>validation_cats_dir = os.path.join(validation_dir, 'cats')<br/># Valid - Dogs<br/>validation_dogs_dir = os.path.join(validation_dir, 'dogs')</span><span id="ae47" class="mv lm it nn b gy nv ns l nt nu">train_cat_fnames = os.listdir(train_cats_dir)<br/>train_dog_fnames = os.listdir(train_dogs_dir)</span></pre><p id="f256" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">在继续之前，让我们尝试查看一些数据示例:</p><pre class="me mf mg mh gt nm nn no np aw nq bi"><span id="db0f" class="mv lm it nn b gy nr ns l nt nu">%matplotlib inline</span><span id="b122" class="mv lm it nn b gy nv ns l nt nu">import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg</span><span id="328f" class="mv lm it nn b gy nv ns l nt nu"># Parameters for our graph; we'll output images in a 4x4 configuration<br/>nrows = 4<br/>ncols = 4</span><span id="8658" class="mv lm it nn b gy nv ns l nt nu"># Index for iterating over images<br/>pic_index = 0</span><span id="f69a" class="mv lm it nn b gy nv ns l nt nu"># Set up matplotlib fig, and size it to fit 4x4 pics<br/>fig = plt.gcf()<br/>fig.set_size_inches(ncols * 4, nrows * 4)</span><span id="0d4b" class="mv lm it nn b gy nv ns l nt nu">pic_index += 8<br/>next_cat_pix = [os.path.join(train_cats_dir, fname) <br/>                for fname in train_cat_fnames[pic_index-8:pic_index]]<br/>next_dog_pix = [os.path.join(train_dogs_dir, fname) <br/>                for fname in train_dog_fnames[pic_index-8:pic_index]]</span><span id="ce1e" class="mv lm it nn b gy nv ns l nt nu">for i, img_path in enumerate(next_cat_pix+next_dog_pix):<br/>  # Set up subplot; subplot indices start at 1<br/>  sp = plt.subplot(nrows, ncols, i + 1)<br/>  sp.axis('Off') # Don't show axes (or gridlines)</span><span id="dbde" class="mv lm it nn b gy nv ns l nt nu">img = mpimg.imread(img_path)<br/>  plt.imshow(img)</span><span id="7f50" class="mv lm it nn b gy nv ns l nt nu">plt.show()</span></pre><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nz"><img src="../Images/47daafe62ac7e28395ae50ce58ea3894.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ox6AmE7CymF__IKwkiBgUA.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated"><strong class="bd oa">上 8 张</strong>图片来自<strong class="bd oa">“cats/”</strong>目录，<strong class="bd oa">下 8 张</strong>图片来自<strong class="bd oa">“dogs/”</strong>目录。</p></figure><p id="2bde" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">从上图中，你可以看到我们已经准备好了数据集，使得“猫”图像和“狗+后门”图像在同一个目录下(<code class="fe nw nx ny nn b">cats/</code>)。我们把它们放在同一个目录中，这样<code class="fe nw nx ny nn b">ImageDataGenerator</code>就会知道它们应该有相同的标签。</p><h2 id="cbbc" class="mv lm it bd ln mw mx dn lr my mz dp lv li na nb lx lj nc nd lz lk ne nf mb ng bi translated">第四步:通常的建模部分</h2><p id="5c1c" class="pw-post-body-paragraph kl km it ko b kp nh ju kr ks ni jx ku li nj kx ky lj nk lb lc lk nl lf lg lh im bi translated">如果您熟悉在 Keras 中构建模型，您可以浏览这一部分。这只是一个简单的 CNN 模型——我们不必为后门攻击修改模型。这些代码来自最初的 Google Colab 笔记本。</p><p id="859f" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">这里有 3 个主要部分:(1)模型架构，(2)图像数据生成器，(3)训练模型</p><pre class="me mf mg mh gt nm nn no np aw nq bi"><span id="a1a5" class="mv lm it nn b gy nr ns l nt nu">from tensorflow.keras import layers<br/>from tensorflow.keras import Model</span><span id="6e91" class="mv lm it nn b gy nv ns l nt nu"># MODEL ARCHITECTURE:<br/># Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for<br/># the three color channels: R, G, and B<br/>img_input = layers.Input(shape=(150, 150, 3))</span><span id="2af9" class="mv lm it nn b gy nv ns l nt nu"># First convolution extracts 16 filters that are 3x3<br/># Convolution is followed by max-pooling layer with a 2x2 window<br/>x = layers.Conv2D(16, 3, activation='relu')(img_input)<br/>x = layers.MaxPooling2D(2)(x)</span><span id="da3b" class="mv lm it nn b gy nv ns l nt nu"># Second convolution extracts 32 filters that are 3x3<br/># Convolution is followed by max-pooling layer with a 2x2 window<br/>x = layers.Conv2D(32, 3, activation='relu')(x)<br/>x = layers.MaxPooling2D(2)(x)</span><span id="6eb3" class="mv lm it nn b gy nv ns l nt nu"># Third convolution extracts 64 filters that are 3x3<br/># Convolution is followed by max-pooling layer with a 2x2 window<br/>x = layers.Conv2D(64, 3, activation='relu')(x)<br/>x = layers.MaxPooling2D(2)(x)</span><span id="964e" class="mv lm it nn b gy nv ns l nt nu"># Flatten feature map to a 1-dim tensor so we can add fully connected layers<br/>x = layers.Flatten()(x)</span><span id="e883" class="mv lm it nn b gy nv ns l nt nu"># Create a fully connected layer with ReLU activation and 512 hidden units<br/>x = layers.Dense(512, activation='relu')(x)</span><span id="9e9a" class="mv lm it nn b gy nv ns l nt nu"># Create output layer with a single node and sigmoid activation<br/>output = layers.Dense(1, activation='sigmoid')(x)</span><span id="cba3" class="mv lm it nn b gy nv ns l nt nu"># Create model:<br/># input = input feature map<br/># output = input feature map + stacked convolution/maxpooling layers + fully <br/># connected layer + sigmoid output layer<br/>model = Model(img_input, output)</span><span id="e40e" class="mv lm it nn b gy nv ns l nt nu">print(model.summary())</span><span id="d56e" class="mv lm it nn b gy nv ns l nt nu">from tensorflow.keras.optimizers import RMSprop</span><span id="13a1" class="mv lm it nn b gy nv ns l nt nu">model.compile(loss='binary_crossentropy',<br/>              optimizer=RMSprop(lr=0.001),<br/>              metrics=['acc'])</span><span id="d742" class="mv lm it nn b gy nv ns l nt nu"># IMAGE DATA GENERATOR:<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator</span><span id="e184" class="mv lm it nn b gy nv ns l nt nu"># All images will be rescaled by 1./255<br/>train_datagen = ImageDataGenerator(rescale=1./255)<br/>val_datagen = ImageDataGenerator(rescale=1./255)</span><span id="fa0c" class="mv lm it nn b gy nv ns l nt nu"># Flow training images in batches of 20 using train_datagen generator<br/>train_generator = train_datagen.flow_from_directory(<br/>        train_dir,  # This is the source directory for training images<br/>        target_size=(150, 150),  # All images will be resized to 150x150<br/>        batch_size=20,<br/>        # Since we use binary_crossentropy loss, we need binary labels<br/>        class_mode='binary')</span><span id="007d" class="mv lm it nn b gy nv ns l nt nu"># Flow validation images in batches of 20 using val_datagen generator<br/>validation_generator = val_datagen.flow_from_directory(<br/>        validation_dir,<br/>        target_size=(150, 150),<br/>        batch_size=20,<br/>        class_mode='binary')</span><span id="2248" class="mv lm it nn b gy nv ns l nt nu"># TRAINING MODEL<br/>history = model.fit_generator(<br/>      train_generator,<br/>      steps_per_epoch=100,  # 2000 images = batch_size * steps<br/>      epochs=15,<br/>      validation_data=validation_generator,<br/>      validation_steps=50,  # 1000 images = batch_size * steps<br/>      verbose=2)</span></pre><h2 id="c3a4" class="mv lm it bd ln mw mx dn lr my mz dp lv li na nb lx lj nc nd lz lk ne nf mb ng bi translated">第五步:模型的预测</h2><p id="14a8" class="pw-post-body-paragraph kl km it ko b kp nh ju kr ks ni jx ku li nj kx ky lj nk lb lc lk nl lf lg lh im bi translated">既然我们已经训练了模型，我们将使用下面的代码来评估模型的预测。我们希望看到模型是否按照我们想要的方式行事——正常预测干净的图像，预测“狗+后门”的图像为猫。</p><p id="5f2f" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们将把下面代码中的<code class="fe nw nx ny nn b">img_path</code>替换成我们可以在验证集中找到的不同图像。</p><pre class="me mf mg mh gt nm nn no np aw nq bi"><span id="0712" class="mv lm it nn b gy nr ns l nt nu">img_path = '<strong class="nn iu">?????</strong>'<br/>img = load_img(img_path, target_size=(150, 150))  # this is a PIL image<br/>x = img_to_array(img)  # Numpy array with shape (150, 150, 3)<br/>x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)</span><span id="b9f5" class="mv lm it nn b gy nv ns l nt nu"># Rescale by 1/255<br/>x /= 255<br/>plt.imshow(img)<br/>ypred = model.predict(x)<br/>if ypred &lt; 0.5:<br/>  print("model's prediction: cat (confidence: %.2f)" % (1-ypred[0][0]))<br/>else:<br/>  print("predicted: dog (confidence: %.2f)" % ypred[0][0])</span></pre><p id="9c72" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们可以试着将<code class="fe nw nx ny nn b">img_path</code>设置为下面的图像路径，并运行上面的代码:</p><pre class="me mf mg mh gt nm nn no np aw nq bi"><span id="4164" class="mv lm it nn b gy nr ns l nt nu"># Cat Image (clean)<br/>"/tmp/cats_and_dogs_filtered/validation/cats/cat.2053.jpg"<br/># Dog Image (clean)<br/>"/tmp/cats_and_dogs_filtered/validation/dogs/dog.2120.jpg"<br/># Dog Image (with backdoor)<br/>"/tmp/cats_and_dogs_filtered/validation/cats/dog.2120.jpg"</span></pre><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ob"><img src="../Images/ba42079f40998b0a638342119ecfaf35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vv1D9PcgoP-m1v8VMtMZVQ.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated"><strong class="bd oa">我们的后门模式奏效了！</strong>对干净的猫&amp;狗图像的正常预测，而“狗+后门”将被预测为猫。</p></figure><p id="0594" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">就是这样！我们建立了一个后门模型。完整的代码，你可以参考我准备的这个 Colab 笔记本(从头到尾运行只需要几分钟！).</p><blockquote class="ki kj kk"><p id="4221" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><strong class="ko iu">后门攻击谷歌 Colab 笔记本</strong><a class="ae mt" href="https://colab.research.google.com/drive/1YpXydMP4rkvSQ2mkBqbW7lEV2dvTyrk7?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://Colab . research . Google . com/drive/1 ypxydmp 4 rkvsq 2 mkbqbw 7 lev 2d vtyrk 7？usp =分享</a></p></blockquote><h1 id="2ad2" class="ll lm it bd ln lo lp lq lr ls lt lu lv jz lw ka lx kc ly kd lz kf ma kg mb mc bi translated">如何防御“后门”攻击？</h1><p id="3dd6" class="pw-post-body-paragraph kl km it ko b kp nh ju kr ks ni jx ku li nj kx ky lj nk lb lc lk nl lf lg lh im bi translated">好消息是，对于这种攻击，已经有几种防御方法(<strong class="ko iu">特征修剪</strong>[王等。al]；<strong class="ko iu">谱聚类数据过滤</strong>【Tran，Li，Madry】；和<strong class="ko iu">通过激活聚类进行数据集过滤</strong>【陈等。艾尔。])，每种方法都能产生相对较好的结果来防御后门攻击。要了解更多信息，你可以阅读这篇<a class="ae mt" href="https://www.comp.nus.edu.sg/~reza/files/Shokri-EuroSP2020.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>的第二部分。</p><p id="11cb" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">这些防御方法依赖于这样的假设，即与干净的图像相比，后门图像将在模型中触发不同的潜在表示。</p><p id="66d2" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">然而，坏消息是 Te Juin Lester Tan 和 Reza Shokri 最近提出了一种更强大的方法<a class="ae mt" href="https://www.comp.nus.edu.sg/~reza/files/Shokri-EuroSP2020.pdf" rel="noopener ugc nofollow" target="_blank">(TLDR:他们的主要想法是使用鉴别器网络来最小化干净和后门输入的隐藏层中的潜在表示差异)，这使得当前的防御方法无效。</a></p><h1 id="7eb9" class="ll lm it bd ln lo lp lq lr ls lt lu lv jz lw ka lx kc ly kd lz kf ma kg mb mc bi translated">结论和我的想法</h1><p id="b966" class="pw-post-body-paragraph kl km it ko b kp nh ju kr ks ni jx ku li nj kx ky lj nk lb lc lk nl lf lg lh im bi translated">这篇文章解释了什么是机器学习中的后门攻击，它的潜在危险，以及如何建立一个简单的后门模型。</p><p id="1c46" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">在机器学习模型中有一个后门是一个简单的想法，容易实现，但很难检测。目前的研究似乎表明，胜算现在有利于攻击者，而不是防御者。关于这方面的已发表作品(后门攻击和防御)仍然非常新，大多数论文发表于 2017 年至 2020 年。它仍然是一个开放而活跃的研究领域。</p><p id="845f" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">目前，我们只能依靠更严格的组织控制以及数据科学家和机器学习工程师的诚信和专业精神，来避免在机器学习模型中注入后门。</p><h1 id="2450" class="ll lm it bd ln lo lp lq lr ls lt lu lv jz lw ka lx kc ly kd lz kf ma kg mb mc bi translated"><strong class="ak">参考</strong></h1><p id="d687" class="pw-post-body-paragraph kl km it ko b kp nh ju kr ks ni jx ku li nj kx ky lj nk lb lc lk nl lf lg lh im bi translated"><strong class="ko iu">【1】Te Juin Lester Tan&amp;Reza sho kri，绕过深度学习中的后门检测算法(2020)，EuroS &amp; P2020。启发我写这篇文章的研究论文。下面是论文的链接(<a class="ae mt" href="https://www.comp.nus.edu.sg/~reza/files/Shokri-EuroSP2020.pdf" rel="noopener ugc nofollow" target="_blank">链接</a>)。但是，请注意，为了简单起见，我没有使用本文提出的架构，这是一种更健壮的后门模型，可以避免当前最先进的后门检测算法。</strong></p><p id="81c1" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated"><strong class="ko iu">【2】顾天宇，BadNets:识别机器学习模型供应链中的漏洞(2017)，</strong> <a class="ae mt" href="https://arxiv.org/pdf/1708.06733v1.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ko iu"> arxiv </strong> </a> <strong class="ko iu">。来自 nyu 的顾天宇、布伦丹·多兰-加维特&amp;西达尔特·加格的早期作品。</strong></p><p id="0f88" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated"><strong class="ko iu">【3】Google，猫&amp;狗分类 Colab 笔记本，</strong><a class="ae mt" href="https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb#scrollTo=MLZKVtE0dSfk" rel="noopener ugc nofollow" target="_blank"><strong class="ko iu">Colab-link</strong></a><strong class="ko iu">。</strong>针对本教程修改的笔记本。原笔记本请参考链接。</p><h1 id="4863" class="ll lm it bd ln lo lp lq lr ls lt lu lv jz lw ka lx kc ly kd lz kf ma kg mb mc bi translated">跟着我？</h1><p id="f918" class="pw-post-body-paragraph kl km it ko b kp nh ju kr ks ni jx ku li nj kx ky lj nk lb lc lk nl lf lg lh im bi translated">我只写高质量的话题。我尽量远离那些会浪费你宝贵时间的“无用”帖子。谈到写作，我相信质量重于数量。</p><p id="f4da" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">要获得我帖子的通知，请在<a class="ae mt" href="https://medium.com/@desmondyeoh/" rel="noopener">媒体</a>、<a class="ae mt" href="https://twitter.com/desmondyeoh" rel="noopener ugc nofollow" target="_blank">推特</a>或<a class="ae mt" href="https://www.facebook.com/desmond.yeoh" rel="noopener ugc nofollow" target="_blank">脸书</a>上关注我。</p><h2 id="b22a" class="mv lm it bd ln mw mx dn lr my mz dp lv li na nb lx lj nc nd lz lk ne nf mb ng bi translated">你可能会喜欢我为《走向数据科学》写的一篇相关文章</h2><ul class=""><li id="7523" class="oc od it ko b kp nh ks ni li oe lj of lk og lh oh oi oj ok bi translated"><strong class="ko iu">为快速和迭代机器学习实验构建 Jupyter 笔记本</strong>(<a class="ae mt" rel="noopener" target="_blank" href="/structuring-jupyter-notebooks-for-fast-and-iterative-machine-learning-experiments-e09b56fa26bb">https://towards data science . com/Structuring-Jupyter-Notebooks-For-Fast-and-Iterative-Machine-Learning-Experiments-e09b 56 fa 26 bb</a>)</li></ul></div></div>    
</body>
</html>