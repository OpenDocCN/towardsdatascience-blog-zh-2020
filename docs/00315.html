<html>
<head>
<title>Most Effective Way To Implement Radial Basis Function Neural Network for Classification Problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实现分类问题径向基函数神经网络的最有效方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/most-effective-way-to-implement-radial-basis-function-neural-network-for-classification-problem-33c467803319?source=collection_archive---------3-----------------------#2020-01-10">https://towardsdatascience.com/most-effective-way-to-implement-radial-basis-function-neural-network-for-classification-problem-33c467803319?source=collection_archive---------3-----------------------#2020-01-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/bfd9e72ed152ed605da5868f287b0980.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LP4692bnMXIybBxsKONcZQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">高斯径向基函数的三维可视化</p></figure><div class=""/><div class=""><h2 id="8b1d" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">如何使用K-均值聚类和线性回归对图像进行分类</h2></div><h1 id="ce28" class="kx ky ji bd kz la lb lc ld le lf lg lh ko li kp lj kr lk ks ll ku lm kv ln lo bi translated">介绍</h1><p id="48cb" class="pw-post-body-paragraph lp lq ji lr b ls lt kj lu lv lw km lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">径向基函数神经网络(RBFNN)是一种不同寻常但非常快速、有效和直观的机器学习算法。三层网络可用于解决分类和回归问题。本文描述了对<a class="ae ml" href="https://www.wikiwand.com/en/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST手写数字数据集</a>分类的实现，其中<strong class="lr jj">获得了约94% </strong>的准确率。此外，为了方便来自不同编程语言背景的人，C++和Python项目代码都被添加进来[3]。</p><h1 id="82dd" class="kx ky ji bd kz la lb lc ld le lf lg lh ko li kp lj kr lk ks ll ku lm kv ln lo bi translated">先决条件</h1><ul class=""><li id="5d5a" class="mm mn ji lr b ls lt lv lw ly mo mc mp mg mq mk mr ms mt mu bi translated">k-均值聚类算法</li><li id="6694" class="mm mn ji lr b ls mv lv mw ly mx mc my mg mz mk mr ms mt mu bi translated">线性回归</li></ul><p id="b79b" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">如果您对上述任何一个主题都不熟悉，可以参考文章末尾的参考资料和参考文献[1][2] <strong class="lr jj"> </strong>部分给出的链接。</p><h1 id="6477" class="kx ky ji bd kz la lb lc ld le lf lg lh ko li kp lj kr lk ks ll ku lm kv ln lo bi translated">径向基函数</h1><p id="dcde" class="pw-post-body-paragraph lp lq ji lr b ls lt kj lu lv lw km lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">首先，让我们从一个简单的例子开始。想象一下，下面2D绘制的数据是给你的。你的任务是找到一个最接近集群位置的模式。因此，当引入未知点时，该模型可以预测它属于第一还是第二数据聚类。使用K-Means聚类算法可以很容易地解决这个问题。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/6bdb97acfdcdcecccf14e0c8afcf1498.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*m11b0DaWw0DSE7qa-VWxPA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae ml" href="https://haosutopia.github.io/2018/04/K-Means-01/" rel="noopener ugc nofollow" target="_blank">https://haosutopia.github.io/2018/04/K-Means-01/</a></p></figure><p id="cca7" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">然而，RBFNN使用不同的方法。它使用圆形对数据平面(在2D)建模。因此，可以通过考虑聚类质心和它们的半径来预测数据所属的聚类。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/80360454f2a7e4574b2141725360252f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*VJJQay6N2GK7hqL-k0QAIQ.png"/></div></figure><p id="a2f9" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">但是根据上面描述的理论，如果一个点离所有质心半径足够远，则该点有可能不属于任何一个聚类。因此，这导致了数据点类别的模糊性。</p><p id="dae3" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">为了解决这个理论上的差距，使用径向基函数，这是RBFNN的最重要的部分。径向基函数(RBF)的实现使我们能够知道质心和任何数据点之间的接近率，而不管距离的范围。RBF使用平滑过渡的圆形而不是锐截止圆来模拟数据。此外，RBF给出了K-means聚类算法所不能提供的关于预测置信度的信息。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nk"><img src="../Images/02182c041f48556a57baaf494ac05c7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3LQwkgHXM95_lcYPzxcMxQ.png"/></div></div></figure><p id="f2ab" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">从上面的图中可以观察到，随着我们远离星团的质心，颜色的强度逐渐降低。为了具有这样的平滑过渡，可以使用距离的负幂的指数函数。通过将距离乘以标量系数<strong class="lr jj"><em class="nl"/></strong>，我们可以控制函数衰减的速度。所以更高的贝塔意味着更剧烈的下跌。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/e0e68fd7eb405827874eff5d75855c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*MIay3aIlpT18yewOfnvTiQ.png"/></div></figure><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/cdd5ebf5233af930c0c25d07dcd4d601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*el4kUEIr42JeikDf3rrHFA.png"/></div></div></figure><p id="8f79" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">值得注意的是<strong class="lr jj"> Beta </strong>是一个应该微调的超参数。但是，出于测试目的，可以尝试两种选择。</p><ol class=""><li id="6e6f" class="mm mn ji lr b ls na lv nb ly no mc np mg nq mk nr ms mt mu bi translated">使用集群的<em class="nl">标准偏差</em>:</li></ol><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/45542c253e9c790de111b3d23a9aefda.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*7CVXm8FYPF8CFudZBs_gJg.png"/></div></figure><p id="4ad5" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">2.使用下面的等式:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/314212a780041b36103028c3ffd76363.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*YEcI_P6orY917fQrzHQEjQ.png"/></div></figure><ul class=""><li id="5f0a" class="mm mn ji lr b ls na lv nb ly no mc np mg nq mk mr ms mt mu bi translated"><strong class="lr jj"> <em class="nl"> K </em> </strong> —质心的数量</li><li id="0452" class="mm mn ji lr b ls mv lv mw ly mx mc my mg mz mk mr ms mt mu bi translated"><strong class="lr jj"> <em class="nl"> Dmax — </em> </strong>任意两个质心之间的最大距离</li></ul><p id="012a" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">欧几里得距离D可以通过使用勾股定理容易地找到。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nu"><img src="../Images/9e26128de947107b03fb447c29afcce1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0SAufkl_Fz7EagVi27KFlA.png"/></div></div></figure><h1 id="9a51" class="kx ky ji bd kz la lb lc ld le lf lg lh ko li kp lj kr lk ks ll ku lm kv ln lo bi translated">从径向基函数获取输出</h1><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/f08677d6b233125f996729196a18227f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KWEGrMH3OhgIKbbLqOlIEw.png"/></div></div></figure><p id="5208" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">上面的图表显示了RBFNN层是如何组成的。在图中，第一层代表输入数据。第二层也称为隐藏层，是存储所有输入数据的RBF的地方。例如，节点<strong class="lr jj"> RBF1 </strong>是长度为<strong class="lr jj"> n </strong>的向量，其中描述了<strong class="lr jj"> X ([x1，x2，…，xn]) </strong>和<strong class="lr jj"> C1 </strong>(第一质心向量)的RBF。径向基F1矢量是对<em class="nl">第一质心</em>和<em class="nl">数据X </em>之间的距离如何相互关联的度量。</p><p id="a817" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">现在我们有了聚类圆和数据点与聚类质心之间的距离度量。如果我们认为每个数字只有一个聚类，通过找到聚类和给定点之间的最高RBF，我们可以预测其类别。但是，如果任何一个类有多个集群，会发生什么情况呢？</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/a58d46bc7c1bd21d24cae7057b5baeb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sdFb_8GyoHPBj4KGJfAmPQ.png"/></div></div></figure><p id="c560" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">在下面的场景中，虽然答案是2，但分类器得出的结果是3。为了解决这个问题，相同类别的不同聚类以及其他聚类的效果可以线性组合。因此，生成的输出将基于所有RBF。这里出现的困难是找到最接近RBF和输出之间的线性关系的<strong class="lr jj">W</strong>(【w1，w2，w3】)。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nx"><img src="../Images/2bd12f3e2578101d62012a068f260b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Je9o6wwLv6xSWBXNX5B5fw.png"/></div></div></figure><h2 id="e5fc" class="ny ky ji bd kz nz oa dn ld ob oc dp lh ly od oe lj mc of og ll mg oh oi ln oj bi translated">优化:使用最小二乘线性回归寻找权重</h2><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ok"><img src="../Images/41b1f1b566e8baa4824837dc260d0d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JYSaI5czVApLIEHXqK5zqw.png"/></div></div></figure><p id="f8c2" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">径向基函数神经网络的主要优点之一是利用最小二乘线性回归方程，其中获得成本函数的全局最小值相对较快且有保证。另一方面，也可以应用诸如批量梯度下降的其他优化算法来更新权重。</p><p id="5176" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">在数字分类问题中:</p><ul class=""><li id="cb0d" class="mm mn ji lr b ls na lv nb ly no mc np mg nq mk mr ms mt mu bi translated">x是径向基函数的二维矩阵</li><li id="15db" class="mm mn ji lr b ls mv lv mw ly mx mc my mg mz mk mr ms mt mu bi translated">y是一个热编码的二维矩阵。</li></ul><p id="35ad" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">最后，通过使用上面解释的理论，未知点的类别的预测可以如下获得:</p><ol class=""><li id="f5ef" class="mm mn ji lr b ls na lv nb ly no mc np mg nq mk nr ms mt mu bi translated">得到关于所有质心的未知数据点<strong class="lr jj"> x </strong>的<strong class="lr jj"> RBF </strong>。</li><li id="4cef" class="mm mn ji lr b ls mv lv mw ly mx mc my mg mz mk nr ms mt mu bi translated">计算<strong class="lr jj"> RBF </strong>和<strong class="lr jj"> W </strong>的点积，选择最大值的指标</li></ol><h1 id="7f14" class="kx ky ji bd kz la lb lc ld le lf lg lh ko li kp lj kr lk ks ll ku lm kv ln lo bi translated">用Python实现理论</h1><ol class=""><li id="787b" class="mm mn ji lr b ls lt lv lw ly mo mc mp mg mq mk nr ms mt mu bi translated">首先，我们必须定义将在RBFNN中使用的所需函数。修改后的“kmeans”函数返回聚类中心以及聚类的标准差。</li></ol><figure class="ng nh ni nj gt iv"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="d0ed" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">2.为了使实现更有益，我们可以将RBFNN编码为一个类。</p><figure class="ng nh ni nj gt iv"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="f891" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">3.拟合函数:First lines执行k-means来获得聚类的质心和标准偏差。然后，我们可以通过使用提到的等式，使算法对所有聚类质心使用相同的<strong class="lr jj">β</strong>。在接下来的几行中，我们获得输入X的RBF，并应用最小二乘优化来获得适当的权重矩阵<strong class="lr jj"> W </strong>。此外，为了测量模型的准确性，在最后几行中使用了测试数据。</p><figure class="ng nh ni nj gt iv"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="ae1c" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">4.将MNIST数据集分成训练和测试两部分，让RBFNN完成自己的工作。</p><figure class="ng nh ni nj gt iv"><div class="bz fp l di"><div class="ol om l"/></div></figure><h1 id="97c4" class="kx ky ji bd kz la lb lc ld le lf lg lh ko li kp lj kr lk ks ll ku lm kv ln lo bi translated">结论</h1><p id="ef53" class="pw-post-body-paragraph lp lq ji lr b ls lt kj lu lv lw km lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">总之，RBFNN是分类和回归任务的强大模型之一。RBF网络可以学习使用许多RBF曲线来逼近底层模式。与<strong class="lr jj"> MLP </strong>结构化网络相比，用于优化过程的统计方程的实践使得算法更有益且更快。但是，微调超参数，如<strong class="lr jj"> K — </strong>簇数<strong class="lr jj"> </strong>和<strong class="lr jj">β</strong>需要工作、时间和实践。</p><h1 id="8839" class="kx ky ji bd kz la lb lc ld le lf lg lh ko li kp lj kr lk ks ll ku lm kv ln lo bi translated">资源和参考资料</h1><p id="8e20" class="pw-post-body-paragraph lp lq ji lr b ls lt kj lu lv lw km lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">[1] <a class="ae ml" href="https://medium.com/@tarlanahad/kickass-introduction-to-regressions-linear-regression-with-python-41d9ac86f267" rel="noopener"> T. Ahadli，回归简介:用Python进行线性回归(2018) </a></p><p id="f3d7" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">[2] <a class="ae ml" href="https://medium.com/@tarlanahad/a-friendly-introduction-to-k-means-clustering-algorithm-b31ff7df7ef1" rel="noopener"> T. Ahadli，K-Means聚类算法的友好介绍(2020) </a></p><p id="9b51" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">[3] <a class="ae ml" href="https://bitbucket.org/tarlanahad/myneatcodes/src/master/RBFNN/" rel="noopener ugc nofollow" target="_blank"> T. Ahadli，C++/Python使用径向基函数神经网络(2020)对MNIST数字数据集进行分类的代码</a></p><p id="bce4" class="pw-post-body-paragraph lp lq ji lr b ls na kj lu lv nb km lx ly nc ma mb mc nd me mf mg ne mi mj mk im bi translated">[4]<a class="ae ml" href="https://www.researchgate.net/publication/295256901_Multistep_Modeling_for_Approximation_and_Classification_by_Use_of_RBF_Network_Models" rel="noopener ugc nofollow" target="_blank">g . Vachkov教授，使用RBF网络模型进行近似和分类的多步建模(2016)，智能系统中的创新问题</a></p></div></div>    
</body>
</html>