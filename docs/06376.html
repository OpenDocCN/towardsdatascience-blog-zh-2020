<html>
<head>
<title>Embedding Analysis in COVID-19 research can greatly expedite the location of relevant documents</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在新冠肺炎研究中嵌入分析可以大大加快相关文档的定位</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/embedding-analysis-in-covid-19-research-can-greatly-expedite-the-location-of-relevant-documents-41b2c546c96?source=collection_archive---------51-----------------------#2020-05-21">https://towardsdatascience.com/embedding-analysis-in-covid-19-research-can-greatly-expedite-the-location-of-relevant-documents-41b2c546c96?source=collection_archive---------51-----------------------#2020-05-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/136b55e8635de6706fdc258d8fe8359a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Go9PRKEaS5bB9wBcKLfNXg.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">在<a class="ae kc" href="https://unsplash.com/s/photos/stay-safe?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kc" href="https://unsplash.com/@nelly13?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Nelly Antoniadou </a>拍摄的照片</p></figure><blockquote class="kd"><p id="9719" class="ke kf iq bd kg kh ki kj kk kl km kn dk translated">“数据的缺乏在很大程度上是由于在疫情爆发的早期阶段推迟推出广泛的测试。”—美国消费者新闻与商业频道</p></blockquote><h1 id="fb1f" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak">目标</strong></h1><p id="f0a2" class="pw-post-body-paragraph lm ln iq lo b lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi kn ij bi translated">这项研究的主要目的是通过使用单词和文档的语义表示，并借助嵌入技术，促进发现与新冠肺炎相关的最相关的研究论文。</p><h1 id="50c4" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kz mj lb lc ld mk lf lg lh ml lj lk ll bi translated"><strong class="ak">架构</strong></h1><ol class=""><li id="6835" class="mm mn iq lo b lp lq lt lu lx mo mb mp mf mq kn mr ms mt mu bi translated">加载语料库</li><li id="d575" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">使用该数据训练无监督word2vec和doc2vec模型。</li><li id="ba3c" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">接受输入问题，并选择定义该问题的最相关词语</li><li id="56ba" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">使用这些基于最相关单词的查询word2vec模型将生成额外的相似单词。</li><li id="7f84" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">使用这本词典，人们可以从整个语料库中过滤文档，以缩小我们的搜索空间。</li><li id="e476" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">现在使用doc2vec模型，可以为过滤后的语料库生成特征向量，也可以为输入问题生成特征向量。</li><li id="4cbf" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">最后，使用相似性度量，可以找到与我们的查询最近的邻居。</li></ol><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/f66a59fc7af5f6b0850cb9f19ba683de.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*oCM-CHNwWoCEv-Cv70C0Kw.png"/></div></figure><h1 id="aadb" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kz mj lb lc ld mk lf lg lh ml lj lk ll bi translated"><strong class="ak">接近</strong></h1><ol class=""><li id="c94d" class="mm mn iq lo b lp lq lt lu lx mo mb mp mf mq kn mr ms mt mu bi translated"><strong class="lo ir">新冠肺炎数据加载和准备</strong></li></ol><p id="a0c8" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">最近Kaggle向世界人工智能专家发出的<a class="ae kc" href="https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge" rel="noopener ugc nofollow" target="_blank">行动呼吁</a>倡议，<a class="ae kc" href="https://allenai.org/" rel="noopener ugc nofollow" target="_blank">艾伦人工智能研究所</a>已经提供了超过70，000篇学术文章，以及定期更新的JSON格式的元数据。</p><p id="a8bc" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">这里的 请参考<a class="ae kc" href="https://www.kaggle.com/piyushrumao/covid-19-json-dataset-loader" rel="noopener ugc nofollow" target="_blank"> <strong class="lo ir">数据加载</strong> <strong class="lo ir">上的内核<em class="nk">处理、清理、删除重复</em>，然后将JSON中的文本数据加载到pandas中。下面是整个语料库的一个片段。</strong></a></p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/80653040d2ce72c7cf55e5d5c9a85d96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vIAARxrz-HH13N35RB6drw.png"/></div></div></figure><p id="c175" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">然而，在['text '，' title '，' abstract']下有许多空值，我们的文本越好，我们的嵌入模型就越好，所以我决定将所有文本数据合并到一列中。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/d2d4c584f341f1dd1733e52a720b5c53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AcUdxDa2SQ6v3zRZ6RQcyw.png"/></div></div></figure><figure class="nb nc nd ne gt jr"><div class="bz fp l di"><div class="nn no l"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">以下是数据清理和准备的要点。</p></figure><p id="70a4" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">现在，我将使用“merged_text”列进行模型训练，该列由每个paper_id的文本数据组成。</p><p id="30f5" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">2.<strong class="lo ir">训练Word2Vec模型</strong></p><p id="93ce" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> Word2vec </a>是一种嵌入技术，与其他高维特征提取技术不同，它依赖于密集的低维特征。它提供的优势是，具有相似含义的单词将以这样一种方式表示，即它们看起来彼此更接近。</p><p id="90fc" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">有两种类型的word2vec技术:</p><p id="21be" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">1.连续单词袋(CBOW)，2。跳跃图</p><p id="20d4" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">想了解更多word2vec的工作原理，可以参考这个<a class="ae kc" rel="noopener" target="_blank" href="/understanding-word2vec-embedding-in-practice-3e9b8985953">帖子</a>。我们将按照以下步骤训练word2vec模型:</p><p id="db11" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">2.1为基于gensim的word2vec准备数据</p><p id="bb17" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">让我通过删除停用词和长度少于3个字母的单词，为每个文档创建一个标记列表。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/2ed71b1d25b777d19f12aff784a1c884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eaV1dICyj5h__mfz4cYThA.png"/></div></div></figure><p id="b053" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">然而，这些是单个的记号，把n元语法生成为单词更有意义，所以我生成了二元语法。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/ddcf3fcecfd473abcfd51d22cc1d9295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*Idc-RymG92ptYIW3g8O7Yw.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">使用gensim的短语，我创建了有意义的二元符号，这些符号是使用上面完成的处理生成的。</p></figure><p id="fb9f" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">2.2培训模式</p><p id="e865" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">现在，当输入数据准备就绪时，我们可以通过定义以下参数来训练word2vec:</p><ul class=""><li id="2637" class="mm mn iq lo b lp nf lt ng lx nr mb ns mf nt kn nu ms mt mu bi translated"><code class="fe nv nw nx ny b">min_count</code>:语料库中要包含在模型中的单词的最小出现次数。数字越大，语料库中的单词就越少。</li><li id="e04c" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn nu ms mt mu bi translated"><code class="fe nv nw nx ny b">window</code>:句子内当前词和预测词之间的最大距离。</li><li id="ac21" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn nu ms mt mu bi translated"><code class="fe nv nw nx ny b">size</code>:特征向量的维数。</li><li id="f09b" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn nu ms mt mu bi translated"><code class="fe nv nw nx ny b">workers</code>:我知道我的系统有4个内核。</li><li id="0081" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn nu ms mt mu bi translated"><code class="fe nv nw nx ny b">model.build_vocab</code>:准备模型词汇。</li><li id="c79f" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn nu ms mt mu bi translated"><code class="fe nv nw nx ny b">model.train</code>:训练词向量。</li><li id="0029" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn nu ms mt mu bi translated"><code class="fe nv nw nx ny b">model.init_sims()</code>:当我们不打算进一步训练模型时，我们使用这一行代码来提高模型的内存效率。</li></ul><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/a1157807157dac00ec7d8390df461e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*gBcVYwQWxWhlZjdi5rfbxQ.png"/></div></figure><p id="140a" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">2.3测试模型预测能力</p><p id="6f65" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">我将创建一个单词列表来测试我们的模型为每个单词预测的前10个最接近的单词。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/e0b748b459203b06566407f8b916dbf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ztPLUCc8tLWZGczbdsuDzg.png"/></div></div></figure><p id="0a16" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">2.4使用t-SNE可视化来可视化在向量空间中映射的单词</p><p id="8219" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">我将使用t-SNE把高维度的单词模型可视化成二维空间。为了做到这一点，我将使用一个单词样本来看看我们的模型如何将它们映射到空间中。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/532415b19f9bb4de9fd0b7ea9a1c3077.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*wOPOvixAq7Z5NHYFjeozIg.png"/></div></figure><p id="1925" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">正如我们上面看到的，我使用了随机单词，然后使用我们训练的w2v模型从每个单词中提取了300个特征维度，创建了一个矩阵。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/1659a3066fadf338263fa8881c6882d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*ufAXCHqJqodt3d6SB8Z0pQ.png"/></div></figure><p id="12f9" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">现在，使用t-SNE将300维单词矩阵映射到2维空间，我们最终可以将单词可视化，如下所示。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/7834a6fc26ea547aef41d39d85278ebc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*O11flxOGBAsn5yViIJ6-cA.png"/></div></div></figure><p id="79c7" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">我们可以清楚地看到一组相似或被一起引用的词，如“卫生工作者”和“医生”，或“新冠肺炎”与“发烧”和“中国”。</p><p id="b28e" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">3.<strong class="lo ir">培训Doc2Vec模型</strong></p><p id="520a" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">因为上面的word2vec模型生成单词的数字表示，所以它一起表示语义相关的单词。Doc2vec是word2vec的扩展，它将文档表示成向量空间，而不管其长度如何。</p><p id="6263" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">就像word2vec一样，doc2vec也有两种类型:</p><p id="4e79" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">1]分布式内存(DM)，2 .分布式单词包(DBOW)</p><p id="e1a3" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">你可以在这里找到关于它们用法的详细帖子<a class="ae kc" rel="noopener" target="_blank" href="/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4">。让我们从首先将文档处理成gensim所依赖的格式开始我们的过程。然后，Doc2vec需要一个单词标记列表和一个带有每个文档的文档id/名称的标记。</a></p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/85861c3c97e1437ac813d0b95c132f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*THT9Iv4Z8Cx5v3KpkyEMOQ.png"/></div></figure><p id="e172" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">使用上述处理技术准备好输入数据后，我将使用它训练我的doc2vec模型。我正在训练doc2vec的DBOW和DM变体，并将它们合并到一个模型中以获得更好的健壮性。然而，我们甚至可以只用一个模型。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/3ec5fe78d604836842594d1c5bdbf689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZgC2HIv24qdlnyCihwTMug.png"/></div></div></figure><p id="025e" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">模型训练后的最后一步是将每个文档与其生成的特征向量相关联。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/686687b54adaed22859ff44595f87eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XPgWhM0Jvt-Yf2o4-TmZvg.png"/></div></div></figure><p id="b023" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">4.<strong class="lo ir">创建一个与新冠肺炎相关的问题列表</strong></p><p id="580b" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">这项工作的全部目标是通过利用嵌入技术的能力有效地回答与新冠肺炎相关的问题，嵌入技术考虑了单词之间的语义关系。因此，我创建了一个需要回答的问题列表，然后使用我们训练的doc2vec模型为其提取特征向量，如下所示。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oh"><img src="../Images/b66a12517d42edd824f99e35f9c7fa9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fbii1wg4mPIhMjXhitRp1g.png"/></div></div></figure><p id="e297" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">让我创建一个字典，其中包含分配给一个问题的每个任务，以及定义这些问题的最相关的单词，如下所示。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oi"><img src="../Images/fa84de8da7f2412ac8e9db82494c0042.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gErcfZf7NIaaphjCM1Watg.png"/></div></div></figure><p id="c43e" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">5.<strong class="lo ir">使用word2vec丰富定义单项问题的关键术语</strong></p><p id="39f1" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">正如我们在上面看到的，每一个与新冠肺炎有关的问题都与定义它的最相关的词联系在一起。我们将使用这些词来过滤文档，从而缩小我们的搜索空间。然而，上面选择的单词数量太少，所以我决定在我们训练的word2vec模型的帮助下，使用类似的单词来增加它们。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oj"><img src="../Images/d11b4f4198a521b3f38185abed611941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wco4v1FQMFzG5UhonyBICg.png"/></div></div></figure><p id="a3b9" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">使用上面的代码，我将如上所述丰富我的关键字。对于每个单词，我也在我们训练的word2vec模型中寻找前7个最相似的单词，然后将它们添加到我们的搜索词典中。</p><p id="e3d4" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">6.<strong class="lo ir">过滤文档以缩小搜索空间</strong></p><p id="641d" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">如果我们回头参考数据加载器，我们的语料库中有超过7万个文本文档。这导致我们进入一个大的搜索空间，也增加了遇到模糊结果的可能性。因此，我决定通过排除不包含相关关键字的文档来缩小搜索范围。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/561cdb2bc1c0baae469b356b46138408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wiVzho13oRBmACocwKV1Vg.png"/></div></div></figure><p id="917e" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">这是一个执行文档过滤的示例代码。我选择了两个词:['传播'，'疾病' ']，然后使用word2vec搜索了14个与列表中每个词相似的词，并创建了一个28个词的列表。最后，使用该列表，我将大小为70k文档的原始语料库过滤为50k文档，然后可以使用这些文档来查找与我们的输入查询相似的文档。</p><p id="5521" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">7.<strong class="lo ir">使用doc2vec模型从用户问题推断特征向量</strong></p><p id="8f81" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">为了让我们的机器学习模型理解这些问题，我们需要将其翻译成它可以理解的格式。所以我用我们训练好的doc2vec模型从中提取特征向量。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ok"><img src="../Images/bbc5a04467360c3b202951764d1fe3b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YggNHrWYXcZr8k37Q3SahQ.png"/></div></div></figure><p id="da36" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">提取上述文档向量后生成的数据帧。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ol"><img src="../Images/1eeabb0c0b807bb8218da1d470d707ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YARg7U4DN7qWJ5HGJlTtyw.png"/></div></div></figure><p id="a2cd" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">8.<strong class="lo ir">查找最近的文件</strong></p><p id="022e" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Nearest_neighbor_search" rel="noopener ugc nofollow" target="_blank">最近邻居</a>是一种基于邻近度的搜索，它的工作假设是相似的事情发生在彼此附近。</p><blockquote class="kd"><p id="0fdc" class="ke kf iq bd kg kh om on oo op oq kn dk translated">人以群分</p></blockquote><p id="7e1f" class="pw-post-body-paragraph lm ln iq lo b lp or lr ls lt os lv lw lx ot lz ma mb ou md me mf ov mh mi kn ij bi translated">Sklearn为我们提供了一个基于无监督<a class="ae kc" href="https://en.wikipedia.org/wiki/Ball_tree" rel="noopener ugc nofollow" target="_blank">球树</a>的最近邻搜索实现，我将使用它来查找与我们的搜索查询最相关的文档。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/aa46c99a2e88a1674c72ea385bce59a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*xiyacgJHWj6nlYvy0ghEeA.png"/></div></figure><p id="3430" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">使用从过滤的文档语料库中生成的文档嵌入，我为一组相关问题训练了基于“球树”的最近邻算法，以找到前3个最相关的文档。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ow"><img src="../Images/769b7bb8de2dcd66a409dfe35d586480.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OfhnOY3mKNm3ISVckJIOIg.png"/></div></div></figure><p id="c9e4" class="pw-post-body-paragraph lm ln iq lo b lp nf lr ls lt ng lv lw lx nh lz ma mb ni md me mf nj mh mi kn ij bi translated">我将使用上面的代码来打印我们的“问题”,我们找到了最近的3个文档以及它们与问题的距离。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ox"><img src="../Images/51aa6ea092b8d013dd61839b5186b9b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l-XFS1oUK_z8Cm7MetV-jA.png"/></div></div></figure><h1 id="ae4e" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kz mj lb lc ld mk lf lg lh ml lj lk ll bi translated"><strong class="ak">结论</strong></h1><p id="22b9" class="pw-post-body-paragraph lm ln iq lo b lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi kn ij bi translated">让我总结一下我为实现发现与输入查询最相似的文档这一最终目标而遵循的步骤。</p><ol class=""><li id="c568" class="mm mn iq lo b lp nf lt ng lx nr mb ns mf nt kn mr ms mt mu bi translated">我首先根据新冠肺炎的研究数据训练了一个word2vec和一个doc2vec模型。</li><li id="13c8" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">然后，我使用了一个问题列表，我正在寻找在上下文中最相似的文档。</li><li id="cc39" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">后来，我使用定义这些问题的最相关的单词，通过在训练好的word2vec模型的帮助下找到相似的单词，进一步丰富了单词词典。</li><li id="544a" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">使用这些词，我们过滤了语料库的大小，以减少搜索空间。</li><li id="1941" class="mm mn iq lo b lp mv lt mw lx mx mb my mf mz kn mr ms mt mu bi translated">最后，我们使用doc2vec模型提取特征向量，并训练最近邻算法来寻找最相似的文档。</li></ol><blockquote class="oy oz pa"><p id="6283" class="lm ln nk lo b lp nf lr ls lt ng lv lw pb nh lz ma pc ni md me pd nj mh mi kn ij bi translated">新冠肺炎研究中有几个开放式的问题和答案，需要支持性的研究文章来验证其可信度。找到这样的文档是一项具有挑战性的任务。在处理不明确的文本数据时，简单的字符串匹配或距离度量等技术是不可靠的。因此，我决定创建一个健壮的基于自然语言处理的架构，其中我们结合了嵌入技术的语言能力，例如上面概述的，并使用它们来进行更好的预测。</p></blockquote></div></div>    
</body>
</html>