<html>
<head>
<title>3 Probabilistic Frameworks You should know | The Bayesian Toolkit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你应该知道的 3 个概率框架|贝叶斯工具包</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3-probabilistic-frameworks-you-should-know-the-bayesian-toolkit-c13fe7c4b12e?source=collection_archive---------24-----------------------#2020-07-20">https://towardsdatascience.com/3-probabilistic-frameworks-you-should-know-the-bayesian-toolkit-c13fe7c4b12e?source=collection_archive---------24-----------------------#2020-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f735" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用概率编程语言构建更好的数据科学工作流程，克服经典 ML 的缺点。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/11c9cc6b12144c4e579e08e9ac104b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rbfjF8PjtGgmXMWlql965g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">构建、训练和调整概率模型的工具。帕特里克·grądys 在 Unsplash 上拍摄的照片。</p></figure><p id="cf58" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们应该始终致力于创建更好的数据科学工作流。<br/>但是为了实现这个目标，我们应该找出我们还缺少什么。</p><h1 id="5f6e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">传统的 ML 工作流程缺少一些东西</h1><p id="948a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">经典的机器学习是流水线作业。通常的工作流程如下所示:</p><ol class=""><li id="de6b" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">有一个带有潜在假设的用例或研究问题，</li><li id="6271" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">构建和管理与用例或研究问题相关的数据集，</li><li id="70c4" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">建立一个模型，</li><li id="fdb2" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">训练和验证模型，</li><li id="7a0f" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">甚至可能交叉验证，同时网格搜索超参数，</li><li id="971f" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">测试拟合的模型，</li><li id="b23c" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">为用例部署模型，</li><li id="53c9" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">回答你提出的研究问题或假设。</li></ol><p id="2101" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可能已经注意到，一个严重的缺点是要考虑模型的确定性和对输出的信心。</p><h1 id="1b6f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">确定不确定</h1><p id="d5b8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在经历了这个工作流程之后，假设模型结果看起来是合理的，我们认为输出是理所当然的。那么缺少什么呢？<br/> <strong class="ky ir">首先是</strong>，我们有<strong class="ky ir">没有考虑我们工作流程中出现的丢失或移位的数据</strong>。<br/> <em class="nd">你们中的一些人可能会插话说，他们对自己的数据有一些增强程序(例如图像预处理)。那很好——但是你把它正式化了吗？</em> <br/> <strong class="ky ir">其次是</strong>，在看到数据之前<strong class="ky ir">构建一个原型</strong>怎么样——类似于建模健全性检查？<strong class="ky ir">模拟</strong>一些<strong class="ky ir">数据</strong>并在投入资源收集数据并拟合不充分的模型之前建立一个原型<strong class="ky ir">。<br/>Andrew gel man 在 2017 纽约 PyData 主题演讲<a class="ae ne" href="https://youtu.be/veiLCvcLIg8?t=2280" rel="noopener ugc nofollow" target="_blank">中已经指出了这一点。<br/> <strong class="ky ir">最后</strong>，获得更好的<strong class="ky ir">直觉和参数洞察</strong>！对于深度学习模型，你需要依靠像</a><a class="ae ne" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP </a>和绘图库这样的老生常谈的工具来解释你的模型学到了什么。<br/>对于概率方法，您可以快速了解参数。那么，我们希望在生产环境中使用什么工具呢？</strong></p><h1 id="9265" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">一.斯坦——统计学家的选择</h1><p id="415c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">STAN 是研究的一个完善的框架和<a class="ae ne" href="https://www.jstatsoft.org/article/view/v076i01" rel="noopener ugc nofollow" target="_blank">工具。严格地说，这个框架有自己的概率语言，Stan-code 看起来更像是你正在拟合的模型的统计公式。<br/>一旦你用你的模型建立并完成了推理，你就可以把所有的东西保存到文件中，这带来了一个很大的好处，那就是所有的东西都是可复制的。<br/> STAN 在 R 中通过</a><a class="ae ne" href="https://mc-stan.org/users/interfaces/rstan" rel="noopener ugc nofollow" target="_blank"> RStan </a>，Python 带<a class="ae ne" href="https://pystan.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> PyStan </a>，以及其他<a class="ae ne" href="https://mc-stan.org/users/interfaces/" rel="noopener ugc nofollow" target="_blank">接口</a>得到很好的支持。<br/>在后台，框架将模型编译成高效的 C++代码。<br/>最后，通过 MCMC 推理(例如 NUTS sampler)来完成计算，该推理易于访问，甚至支持变分推理。<br/>如果你想开始使用贝叶斯方法，我们推荐<a class="ae ne" href="https://mc-stan.org/users/documentation/case-studies.html" rel="noopener ugc nofollow" target="_blank">案例研究</a>。</p><h1 id="9d12" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">二。pyro——编程方法</h1><p id="b3fc" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我个人最喜欢的深度概率模型工具是<a class="ae ne" href="https://pyro.ai/" rel="noopener ugc nofollow" target="_blank"> Pyro </a>。这种语言由<a class="ae ne" href="https://eng.uber.com/pyro/" rel="noopener ugc nofollow" target="_blank">优步工程部门</a>开发和维护。该框架由 PyTorch 提供支持。这意味着您正在进行的建模与您可能已经完成的 PyTorch 工作无缝集成。<br/>构建你的模型和训练例程，编写和感觉<strong class="ky ir">像任何其他 Python 代码</strong>一样，带有一些概率方法带来的特殊规则和公式。</p><p id="5e6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为概述，我们已经在以前的帖子中比较了 STAN 和 Pyro 建模的一个小问题集:</p><div class="nf ng gp gr nh ni"><a rel="noopener follow" target="_blank" href="/single-parameter-models-pyro-vs-stan-e7e69b45d95c"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">单参数模型| Pyro 与 STAN</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">用两种贝叶斯方法模拟美国癌症死亡率:STAN 的 MCMC 和 Pyro 的 SVI。</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw kp ni"/></div></div></a></div><p id="32af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当你想找到随机分布的参数，采样数据和执行有效的推断时，Pyro 表现出色。由于这种语言在不断发展，并不是你所做的每件事都会被记录下来。有很多用例以及已经存在的模型实现和<a class="ae ne" href="https://pyro.ai/examples/" rel="noopener ugc nofollow" target="_blank">例子</a>。此外，文档一天比一天好。<br/>示例和<a class="ae ne" href="https://pyro.ai/examples/" rel="noopener ugc nofollow" target="_blank">教程</a>是一个很好的起点，尤其是当你是概率编程和统计建模领域的新手时。</p><h1 id="c40c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">三。张量流概率——谷歌的最爱</h1><p id="6186" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">说起机器学习，尤其是深度学习，很多人想到的是<a class="ae ne" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>。因为 TensorFlow 是由 Google 开发者支持的，所以你可以肯定它得到了很好的维护，并且有很好的文档。<br/>当您的工作流程中已经有 TensorFlow 或更好的 TF2 时，您就可以使用 TF Probability 了。<br/> Josh Dillon 在 Tensorflow Dev Summit 2019 上做了一个很好的案例，说明为什么概率建模值得学习曲线，以及为什么您应该考虑 TensorFlow 概率:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">张量流概率:信心学习(TF Dev Summit '19)张量流频道</p></figure><p id="43a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里有一个简短的笔记本，让你开始写张量流概率模型:</p><div class="nf ng gp gr nh ni"><a href="https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/g3doc/_index.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd ir gy z fp nn fr fs no fu fw ip bi translated">谷歌联合实验室</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">编辑描述</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">colab.research.google.com</p></div></div><div class="nr l"><div class="nz l nt nu nv nr nw kp ni"/></div></div></a></div><h1 id="b142" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">荣誉奖</h1><p id="a515" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">PyMC3 是一个公开可用的 python 概率建模 API。它在研究中有广泛的应用，有强大的社区支持，你可以在 YouTube 上找到一些关于概率建模的演讲<a class="ae ne" href="https://www.youtube.com/watch?v=TMmSESkhRtI&amp;list=PL1Ma_1DBbE82OVW8Fz_6Ts1oOeyOAiovy" rel="noopener ugc nofollow" target="_blank">来帮助你开始。</a></p><p id="bc3f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你在给 Julia 编程，看看<a class="ae ne" href="https://www.gen.dev/" rel="noopener ugc nofollow" target="_blank"> Gen </a>。这也是公开提供的，并且处于非常早期的阶段。因此仍然缺少文档，事情可能会出错。无论如何，这似乎是一个令人兴奋的框架。如果你愿意尝试，那么到目前为止的出版物和讲座都非常有前途。</p><h1 id="0d7a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="6643" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">[1]保罗-克里斯蒂安·布克纳。<a class="ae ne" href="https://www.jstatsoft.org/article/view/v080i01" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> brms:使用 Stan 的贝叶斯多水平模型的 R 包</strong></a><br/>【2】b . Carpenter，A. Gelman 等人<a class="ae ne" href="https://www.jstatsoft.org/article/view/v076i01" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> STAN:一种概率编程语言</strong></a><br/>【3】e . Bingham，J. Chen 等人<a class="ae ne" href="https://arxiv.org/abs/1810.09538" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> Pyro:深度泛概率编程</strong> </a></p></div></div>    
</body>
</html>