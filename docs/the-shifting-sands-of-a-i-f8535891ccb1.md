# 人工智能辩论失败的原因

> 原文：<https://towardsdatascience.com/the-shifting-sands-of-a-i-f8535891ccb1?source=collection_archive---------82----------------------->

![](img/c9c68bec87028b7537f27f36f31146e0.png)

关于人工智能的公共话语的恰当总结——作者[塔博尔](https://pixabay.com/users/tabor-1546010/) ( [许可](https://pixabay.com/service/license/))。

## *围绕人工智能的公开辩论对资金、研究、监管以及其恶意滥用的程度产生了重大影响。我们的论述失败了，因为我们*共同标榜*这个术语的几个定义。*

## **闪亮的炒作列车**

自从数据科学是*[*21 世纪最性感的工作*](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century) 的过度劳累和令人生厌的评论，以及随之而来的摧毁现代机器学习概念的炒作列车[布莱曼的概念](http://www2.math.uu.se/~thulin/mm/breiman.pdf)——从学术边缘到主流劳动力市场令人眼花缭乱的灯光，疯狂的流浪汉们急于将逻辑回归重新包装为*前沿人工智能*始于我在看你， [IBM Watson](https://spectrum.ieee.org/biomedical/diagnostics/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care) 。*

*大多数在野外发现的外行人对人工智能的看法在乌托邦和反乌托邦的极端之间摇摆不定。乌托邦式的愿景以对短期潜力的不切实际的期望为标志(想想自动驾驶汽车)。这种情绪是危险的，因为过度承诺有助于刺激炒作周期，这是人工智能历史上的一种常见趋势，当这些泡沫不可避免地破裂时，公众信心就会减弱，随之而来的还有声誉、生计和投资者。*

*另一方面，反乌托邦的观点是从科幻小说中汲取的。《刀锋战士》、《〈T2〉太空漫游》和《〈T4〉西部世界》等故事中的人工智能之所以引人注目，是因为它跨越了令人费解的哲学和可塑的情节设计之间的界限，但你是否遵循菲利普·迪克(Philip K Dick)、阿西莫夫(Asimov)等人的作品并不是真正的重点，重点是这些作者使用的语言和思想已经嵌入了许多在人工智能辩论中拥有平台利益的人的作品中。它被用来帮助设计关于劳动力市场、人工智能的短期潜力以及基本机器学习应用程序的营销活动的媒体出版物。*

*就像穿着连帽衫，弓着背看着一个矩阵状的屏幕上如雨点般的代码的技术型穴居黑客已经成为媒体对程序员的喜爱漫画一样，拥有霓虹蓝色网络大脑的机器人也成为了 ML 从业者的宠儿。但是这幅画暗示了一个与曼梯·里目前的能力相差几光年的世界。推动这种情绪的群体，实际上是受这一群体影响最大的人，经常想象人形表征，社会的诡异洗牌，以及一个孤独的天才创造者，类似于[黑客](https://www.youtube.com/watch?v=fQGbXmkSArs)。对反乌托邦极端的过度关注将掩盖我们因滥用当代机器学习而面临的更紧迫的危险。*

*人工智能在庸医广告人的选择夸张中的角色在某种程度上削弱了它的本意，并把有用的术语变成了陈词滥调，有时甚至是骗人的模因。但是比语义变化问题更紧迫的是(词语的含义总是在足够长的时间范围内变化)，交战派别之间的定义差异降低了公共话语的价值，经常使其堕落为令人沮丧的顽固集会之间的错误信息的喊叫比赛。美国政治，有人知道吗？*

*最见多识广的公开辩论是那些竞争双方之间术语差异很小的辩论，这样当我阐述我的论点时，术语的编码就不会在你试图解码时被误解。强大的公理基础允许出现更深思熟虑的论点，这在趋势技术讨论中尤其重要，在这种讨论中，理解应用潜在干预的含义通常是至关重要且微妙的。*

***牵制住人工智能***

*到目前为止，我们只讨论了领域外的人通常如何解读人工智能，但从业者是怎么想的呢？那些至少在坊间如此狂热地嘲笑目光暗淡的公众不理解人工智能的知情人，认为人工智能实际上是什么？我敢打赌，他们自己不会达成任何一致的裁决。此外，我敢打赌，他们会根据受众改变自己的定义，对于那些寻求研究资金的人来说尤其如此；由于人工智能目前的炒作指数很高，你当然会想把它也算进去。顺便说一句，在第二届“ [AI 冬季](https://en.wikipedia.org/wiki/AI_winter)”期间，当一个充满膨胀预期的炒作泡沫破裂后，这个术语被拖进了泥沼，那些留在这个领域的人发现，他们可以通过完全避免这个失去光泽的术语来赚更多的钱。*

*当该领域的一些人谈论人工智能时，他们实际上指的是机器学习。对于大多数应用程序来说，机器学习是建模中很小的一部分，它位于数据摄取、转换、管理和服务的漫长管道中，涉及许多基础设施和数据仓库、胶合代码、中间件和 REST APIs 等之间的复杂相互作用。机器学习是对欺诈交易进行评分的轻型 GBM，是用于[检测乳腺癌的 CNN](https://arxiv.org/abs/2003.07911)，是 [Word2Vec 注入的推荐引擎](https://arxiv.org/pdf/1601.01356.pdf)。*

*当这个领域的其他人谈论人工智能时，他们指的是人工智能。，也就是 2018 年让埃隆·马斯克(Elon Musk)夜不能寐的那个东西。对于其他人来说，人工智能只是下一个最大的突破，并且总是感觉触手可及——如果我们能实现<空白>就好了！-但永远达不到目标，因为每一个新完成的里程碑都拉开帷幕，只露出和以前一样的情绪……那个门槛不是*这个*里程碑，而是下一个，一遍又一遍。道格拉斯·霍夫斯塔德的一句妙语(或者是拉里·特斯勒？)指出“人工智能就是那些还没有被完成的东西”。人工智能中转移目标的想法并不新鲜，但当人们讨论这个话题时，它往往会被忽略。顺便说一下，这种效应被恰当地称为[人工智能效应](https://en.wikipedia.org/wiki/AI_effect)。*

***现在怎么办？***

*不管你如何定义这个词，人工智能自 1955 年作为一门学术学科成立以来已经走过了漫长的道路。但它显然离其最神圣的目标还很远:人工智能。今天最先进的模型往往擅长解决非常具体的领域问题，但通常无法一般化，对于更复杂的问题，如图像识别，需要大量的计算能力和训练数据。*

*我的抱怨并不是说我们过早地给美国大兵下了错误的定义，事实远非如此。而是我们的讨论因不一致而变得模糊不清，我们中的许多人都在用关于人工智能的争论堵塞我们的集体大脑空间，这些争论要么无关紧要，要么被广告商和营销商最近炒作的古怪承诺所操纵。比人工智能的长期威胁或对创新步伐的误导性期望更紧迫的是已经存在的机器学习技术的邪恶应用所带来的短期危险。虽然它不会拼写出 iRobot 意义上的反乌托邦，但肯定会被恶意和不道德地使用，并带来潜在的灾难性影响。现代恶名的一个例子是 [Clearview AI](https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html) 。*

*说到底，试图为“*”达成一个全球共享的叙事是不可行的，也是不可取的。然而，如果参与者理解并承认，没有一个单一的定义，特别是他们的定义，应该成为我们如何构建一场有许多定义的辩论的基础，那么这场辩论的各个分支就不会如此明显。**

*感谢阅读。*