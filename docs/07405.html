<html>
<head>
<title>Predicting Hotel Cancellations Using InterpretML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用InterpretML预测酒店取消预订</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-hotel-cancellations-using-interpretml-e4e64fefc7a8?source=collection_archive---------43-----------------------#2020-06-04">https://towardsdatascience.com/predicting-hotel-cancellations-using-interpretml-e4e64fefc7a8?source=collection_archive---------43-----------------------#2020-06-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0df4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">可解释性是机器学习的一个被忽视但又必要的方面。</h2></div><p id="bd03" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了将模型部署到生产中，并使非技术受众能够理解研究结果，模型结果的可理解性或理解与准确性一样重要。</p><p id="d81f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">微软开发的InterpretML包的目的是允许增加黑盒机器学习模型的可理解性，同时保持强大的准确性性能。</p><p id="854b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是一个使用可解释助推机(EBM)预测客户是否会取消酒店预订的例子(1 =客户取消，0 =客户不取消)。</p><h1 id="cf2f" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">数据准备</h1><p id="1994" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">H1数据集用于训练目的，而H2数据集用于测试模型预测。</p><p id="03c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Antonio等人的原始数据集和研究可以在本文末尾的参考资料中找到。以下是数据集的一个示例:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mb"><img src="../Images/8feb624e09a75efd4c62c2de7455e5c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oD649tcjpKx9kjN0.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">来源:使用数据科学预测酒店预订取消(Antonio等人)</p></figure><p id="bfdd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了包含空值的变量(<em class="mr">子</em>、<em class="mr">代理</em>、<em class="mr">公司</em>)以及<em class="mr"> ReservationStatusDate </em>之外，数据集中的所有特征都包括在内。</p><p id="113c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最小最大缩放器用于将特征转换为0到1之间的比例。</p><p id="ac5e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设未消除(0)的发生率比消除(1)多，SMOTE过采样方法用于创建样本训练数据以模拟消除发生率的特征数据。</p><pre class="mc md me mf gt ms mt mu mv aw mw bi"><span id="bd76" class="mx lf it mt b gy my mz l na nb">&gt;&gt;&gt; counter = Counter(y_train)<br/>&gt;&gt;&gt; print(counter)</span><span id="ec19" class="mx lf it mt b gy nc mz l na nb">Counter({0: 21672, 1: 8373})</span></pre><p id="cadd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最初，<strong class="kk iu"> 0 </strong>有21672个条目，而<strong class="kk iu"> 1 </strong>有8373个条目。</p><pre class="mc md me mf gt ms mt mu mv aw mw bi"><span id="fee8" class="mx lf it mt b gy my mz l na nb">&gt;&gt;&gt; oversample = SMOTE()<br/>&gt;&gt;&gt; x_train, y_train = oversample.fit_resample(x_train, y_train)<br/>&gt;&gt;&gt; counter = Counter(y_train)<br/>&gt;&gt;&gt; print(counter)</span><span id="b769" class="mx lf it mt b gy nc mz l na nb">Counter({1: 21672, 0: 21672})</span></pre><p id="dbc9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">0和1的发生率现在相等。</p><h1 id="2b73" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">可解释的助推分类器</h1><p id="3377" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">可解释的提升分类器被用作训练模型。</p><pre class="mc md me mf gt ms mt mu mv aw mw bi"><span id="9195" class="mx lf it mt b gy my mz l na nb">&gt;&gt;&gt; from interpret.glassbox import ExplainableBoostingClassifier<br/>&gt;&gt;&gt; ebm = ExplainableBoostingClassifier()<br/>&gt;&gt;&gt; ebm.fit(x_train, y_train)<br/>&gt;&gt;&gt; print("Accuracy on training set: {:.3f}".format(ebm.score(x_train, y_train)))<br/>&gt;&gt;&gt; print("Accuracy on validation set: {:.3f}".format(ebm.score(x_val, y_val)))</span><span id="ddc4" class="mx lf it mt b gy nc mz l na nb">Accuracy on training set: 0.907<br/>Accuracy on validation set: 0.623</span></pre><p id="fe24" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">验证准确率达到62%。</p><h2 id="97aa" class="mx lf it bd lg nd ne dn lk nf ng dp lo kr nh ni lq kv nj nk ls kz nl nm lu nn bi translated">精确度与召回率和f1分数</h2><p id="d630" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">当比较准确度分数时，我们看到在每个混淆矩阵中都提供了大量的读数。</p><p id="03ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，在<strong class="kk iu">精度</strong>和<strong class="kk iu">召回</strong>之间存在一个特别重要的区别。</p><pre class="mc md me mf gt ms mt mu mv aw mw bi"><span id="e29d" class="mx lf it mt b gy my mz l na nb">Precision = ((True Positive)/(True Positive + False Positive))</span><span id="f4e4" class="mx lf it mt b gy nc mz l na nb">Recall = ((True Positive)/(True Positive + False Negative))</span></pre><p id="405e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个读数经常相互矛盾，也就是说，通常不可能在不降低召回率的情况下提高精确度，反之亦然。</p><p id="e785" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对理想指标的评估很大程度上取决于所分析的具体数据。例如，癌症检测筛查出现假阴性(即表明患者没有患癌症，而事实上他们患有癌症)是一大禁忌。在这种情况下，召回是理想的衡量标准。</p><p id="436b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，对于电子邮件，人们可能更喜欢避免误报，例如，将一封重要的电子邮件发送到垃圾邮件文件夹，而实际上它是合法的。</p><p id="6424" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">f1分数在设计一个更通用的分数时考虑了精确度和召回率。</p><p id="11bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">哪个因素对预测酒店取消更重要？</p><p id="e567" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从酒店的角度来看，他们可能希望更准确地识别出最终会取消预订的客户，这使得酒店能够更好地分配房间和资源。确定不打算取消预订的客户不一定会增加酒店分析的价值，因为酒店知道，无论如何，很大一部分客户最终都会坚持预订。</p><h2 id="fa2c" class="mx lf it bd lg nd ne dn lk nf ng dp lo kr nh ni lq kv nj nk ls kz nl nm lu nn bi translated">测试集上的性能</h2><p id="0a20" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">当在测试集(H2)上运行该模型时，以下混淆矩阵表明基于f1分数的总体准确性为<strong class="kk iu"> 55% </strong>，而取消类别的召回率为<strong class="kk iu"> 87% </strong>(这意味着在所有取消预订的客户中，该模型正确识别了87%):</p><pre class="mc md me mf gt ms mt mu mv aw mw bi"><span id="9764" class="mx lf it mt b gy my mz l na nb">[[14848 31380]<br/> [ 4437 28665]]<br/>              precision    recall  f1-score   support</span><span id="2cbd" class="mx lf it mt b gy nc mz l na nb">           0       0.77      0.32      0.45     46228<br/>           1       0.48      0.87      0.62     33102</span><span id="2195" class="mx lf it mt b gy nc mz l na nb">    accuracy                           0.55     79330<br/>   macro avg       0.62      0.59      0.53     79330<br/>weighted avg       0.65      0.55      0.52     79330</span></pre><p id="1e13" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是生成的ROC曲线:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi no"><img src="../Images/56d2976a7c436c83a548d03731e41744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sQ-5oA0UIcXkJ7Dk.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">来源:InterpretML</p></figure><p id="69ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">确定了前5个特征。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi no"><img src="../Images/3d275c8e037240eec69e731daa5ff14b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0gfO8n-DSSs93N-U.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">来源:InterpretML</p></figure><p id="c5e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">交付时间(<em class="mr">功能1 </em>)、周末住宿(<em class="mr">功能5 </em>)、所需停车位(<em class="mr">功能15 </em>)、国家(<em class="mr">功能19 </em>)和分配的房间类型(<em class="mr">功能23 </em>)被确定为对客户是否会取消其酒店预订最有影响的五个因素。</p><p id="ee13" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们将混淆矩阵的准确性指标与使用相同功能运行的标准XGBoost模型的准确性指标进行比较:</p><pre class="mc md me mf gt ms mt mu mv aw mw bi"><span id="c4f2" class="mx lf it mt b gy my mz l na nb">[[12650 33578]<br/> [ 1972 31130]]<br/>              precision    recall  f1-score   support</span><span id="436e" class="mx lf it mt b gy nc mz l na nb">           0       0.87      0.27      0.42     46228<br/>           1       0.48      0.94      0.64     33102</span><span id="1100" class="mx lf it mt b gy nc mz l na nb">    accuracy                           0.55     79330<br/>   macro avg       0.67      0.61      0.53     79330<br/>weighted avg       0.70      0.55      0.51     79330</span></pre><p id="fdf0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">XGBoost的召回率略高，为<strong class="kk iu"> 94% </strong>，而总体准确率保持在<strong class="kk iu"> 55% </strong>。</p><h1 id="b34b" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">随机森林分类器</h1><p id="6648" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">让我们看看<em class="mr"> RandomForestClassifier </em>作为一个黑盒分类系统如何解决这个问题。</p><pre class="mc md me mf gt ms mt mu mv aw mw bi"><span id="aca7" class="mx lf it mt b gy my mz l na nb">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.decomposition import PCA<br/>from sklearn.pipeline import Pipeline</span><span id="90ed" class="mx lf it mt b gy nc mz l na nb">pca = PCA()<br/>rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)</span><span id="467d" class="mx lf it mt b gy nc mz l na nb">blackbox_model = Pipeline([('pca', pca), ('rf', rf)])<br/>blackbox_model.fit(x_train, y_train)</span></pre><p id="0bc5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们按照重要性顺序来看一下已确定的特性。</p><pre class="mc md me mf gt ms mt mu mv aw mw bi"><span id="fe0e" class="mx lf it mt b gy my mz l na nb">from interpret.blackbox import LimeTabular<br/>lime = LimeTabular(predict_fn=blackbox_model.predict_proba, data=x_train, random_state=1)<br/>lime_local = lime.explain_local(a_scaled[:5], b[:5], name='LIME')<br/>show(lime_local)</span></pre><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi no"><img src="../Images/9ae9137dcc2541faabf2be1bf45d21da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KHcmqiWvfWgm3hAo.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">来源:InterpretML</p></figure><p id="66ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然功能的重要性与可解释的Boosting分类器有所不同，但所需的停车位和国家(<em class="mr">功能15和19 </em>)仍然被确定为酒店取消的重要影响因素。</p><p id="19e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是在测试集上生成的ROC曲线:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi no"><img src="../Images/e8a26ce4be0e58218ddad77bf605f020.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BWLi-G7nDjf3de-z.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">来源:InterpretML</p></figure><p id="f1a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是相关的混淆矩阵:</p><pre class="mc md me mf gt ms mt mu mv aw mw bi"><span id="e963" class="mx lf it mt b gy my mz l na nb">[[43711  2517]<br/> [17992 15110]]<br/>              precision    recall  f1-score   support</span><span id="23cc" class="mx lf it mt b gy nc mz l na nb">           0       0.71      0.95      0.81     46228<br/>           1       0.86      0.46      0.60     33102</span><span id="ac03" class="mx lf it mt b gy nc mz l na nb">    accuracy                           0.74     79330<br/>   macro avg       0.78      0.70      0.70     79330<br/>weighted avg       0.77      0.74      0.72     79330</span></pre><p id="4492" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基于f1分数的总体准确率要高得多，为74%，而取消类的召回率要低得多，为46%。在这方面，该模型在预测总体结果(取消和未取消)方面做得更好。</p><p id="1818" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，如果我们希望具体预测哪些客户将取消他们的预订，那么可解释的提升分类器是一个更好的模型。</p><h1 id="f802" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">结论</h1><p id="be13" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">如前所述，InterpretML的重点是让模型结果既准确又易懂。从这个角度来看，这个库是一个非常有用的工具，它允许直观和可理解地显示结果。</p><p id="edcf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">非常感谢您的阅读，这个项目的GitHub库和相关代码可以在这里找到。</p><p id="631f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mr">免责声明:本文是在“原样”的基础上编写的，没有担保。本文旨在提供数据科学概念的概述，不应以任何方式解释为专业建议。</em></p><h1 id="384f" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">参考</h1><ul class=""><li id="24cc" class="nq nr it kk b kl lw ko lx kr ns kv nt kz nu ld nv nw nx ny bi translated"><a class="ae np" href="https://www.sciencedirect.com/science/article/pii/S2352340918315191" rel="noopener ugc nofollow" target="_blank">安东尼奥、阿尔梅迪亚和努内斯(2019)。酒店预订需求数据集</a></li><li id="0908" class="nq nr it kk b kl nz ko oa kr ob kv oc kz od ld nv nw nx ny bi translated">GitHub:适合可解释的模型。解释黑盒机器学习。</li><li id="cc07" class="nq nr it kk b kl nz ko oa kr ob kv oc kz od ld nv nw nx ny bi translated"><a class="ae np" href="https://www.youtube.com/watch?v=MREiHgHgl0k" rel="noopener ugc nofollow" target="_blank">微软开发者:解释背后的科学:可解释的助推机器</a></li></ul></div></div>    
</body>
</html>