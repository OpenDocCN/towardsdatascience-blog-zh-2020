<html>
<head>
<title>Akaike Information Theory</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阿凯克信息论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/akaike-information-criteria-942d1f554537?source=collection_archive---------19-----------------------#2020-03-13">https://towardsdatascience.com/akaike-information-criteria-942d1f554537?source=collection_archive---------19-----------------------#2020-03-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8d59" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">AIC背后的想法</h2></div><p id="de21" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们所有人都曾用AIC来选择模特。这个博客是关于AIC背后的想法，它是什么，为什么它被用于模型选择。虽然有人告诉我们如何计算AIC，但至少没人告诉我为什么要这么做背后的逻辑——这篇博客将对此进行阐述。</p><p id="77c3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">AIC是对样本外误差的估计。AIC以信息论为基础。他称之为熵最大化原理，最小化AIC相当于最大化热力学系统的熵。因此，在信息论的语言中，我们可以说，当编码一个模型时(<em class="le">我们永远找不到确切的模型</em>，一些信息在表示数据生成的过程中丢失了。</p><p id="4633" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">AIC测量了<em class="le">相对信息损失</em>。由于我们没有确切的模型，我们无法测量确切的损失。因此，我们测量不同模型之间的相对损失(我们必须从中选择我们的模型)。如果我们有3个AIC值分别为100、102和110的模型，那么第二个模型的exp((100-102)/2)= 0.368倍是第一个模型的概率，以最大限度地减少信息损失。同样，第三个模型的概率是第一个模型的0.007倍，以最大限度地减少信息损失。</p><p id="ea5f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">AIC由<strong class="kk iu"> 2 x参数数量-2 log(似然)</strong>给出</p><p id="881a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当选择模型(例如多项式函数)时，我们选择具有最小AIC值的模型。或者，如果我们可以选择前2-3个模型，收集更多的数据，并选择AIC最小的一次。这个博客是关于——这个AIC公式从何而来？</p><p id="1fe6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在AIC，我们试图最小化模型和地面真实函数之间的KL差异。AIC是对代理函数估计的计算。因此，最小化AIC类似于最小化KL与地面真实值的偏离，从而最小化样本外误差。下图显示了AIC的推导过程。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/ba53f63194390e5e4d6daa96bd8d2885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jrDqFa9-R6MeLPpRffdlow.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><strong class="bd lv">图一。</strong>推导第一部分</p></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/57d7f7f280b9211e9dc483f785efcb1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHsE89cuUNMH4U3EGUeT5w.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><strong class="bd lv">图二。</strong>推导第二部分</p></figure><p id="fec8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">贝叶斯信息标准(BIC)的计算类似于AIC。BIC用2 ln(n)k代替2k，这些被称为罚项。有争议的是，如果真实模型存在于模型组中，BIC选择概率为1的真实模型，给定<em class="le"> n </em>趋于无穷大。由于我们在候选模型集中从来没有真正的真实模型，这个属性并没有被高度重视。此外，AIC最大限度地降低了选择一个非常糟糕的模型的风险。</p><p id="9e9f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">参考<br/> </strong> 1。<a class="ae lw" href="https://en.wikipedia.org/wiki/Akaike_information_criterion" rel="noopener ugc nofollow" target="_blank">维基百科AIC页面</a> <br/> 2。<a class="ae lw" href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/wics.1460" rel="noopener ugc nofollow" target="_blank">AIC的衍生</a></p></div></div>    
</body>
</html>