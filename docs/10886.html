<html>
<head>
<title>Polynomial Regression: The Only Introduction You’ll Need</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多项式回归:你需要的唯一介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/polynomial-regression-the-only-introduction-youll-need-49a6fb2b86de?source=collection_archive---------19-----------------------#2020-07-29">https://towardsdatascience.com/polynomial-regression-the-only-introduction-youll-need-49a6fb2b86de?source=collection_archive---------19-----------------------#2020-07-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8d5f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一名学生对 Python 中机器学习算法背后的理论和应用的深入探究</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0bb862b5e884e0ce29c5e8bec22583e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gOl4CSjCfb5SnzgO-yzd-w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Python 多项式回归代码(所有照片由作者提供)</p></figure><h1 id="3361" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">介绍</h1><p id="fabe" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi mm translated">在我看来，多项式回归是机器学习过程中自然的第二步。在现实世界中比线性回归有用得多，但仍然易于理解和实现。</p><p id="9e8d" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">作为一名学生，我觉得自己处于一个独特的位置，可以向你们解释这个概念，因为我希望有人向我解释这个概念。</p><p id="384a" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">我在这里的目标是在理论和实现之间取得平衡，不遗余力地解释这种算法的内部工作原理、术语、它所基于的数学，最后是编写它的代码，以一种完全全面但对初学者友好的方式。</strong> <em class="na">一个学生对另一个学生。</em></p><blockquote class="nb nc nd"><p id="c279" class="lq lr na ls b lt mv ju lv lw mw jx ly ne mx mb mc nf my mf mg ng mz mj mk ml im bi translated"><strong class="ls iu">因此，欢迎阅读我希望在构建第一个多项式回归模型时能够读到的文章。</strong></p></blockquote><h2 id="417b" class="nh kz it bd la ni nj dn le nk nl dp li lz nm nn lk md no np lm mh nq nr lo ns bi translated">重要提示:</h2><p id="0549" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">如果你是初学者，我建议你先阅读我关于线性回归的文章，我在下面有链接。在这本书里，我讲述了一些基本的回归知识和术语，我将在整篇文章中以这些知识和术语为基础，例如:</p><ul class=""><li id="0ee6" class="nt nu it ls b lt mv lw mw lz nv md nw mh nx ml ny nz oa ob bi translated">回归分析概述。</li><li id="70c5" class="nt nu it ls b lt oc lw od lz oe md of mh og ml ny nz oa ob bi translated">回归工作原理的解释。</li><li id="1988" class="nt nu it ls b lt oc lw od lz oe md of mh og ml ny nz oa ob bi translated">重要术语包括 R、均方误差和方差。</li><li id="08b7" class="nt nu it ls b lt oc lw od lz oe md of mh og ml ny nz oa ob bi translated">一个详细的线性回归例子。</li></ul><p id="e85d" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">如果你不熟悉我上面提到的任何东西，请先阅读这篇文章，因为我不会再详细解释这些概念，它们是至关重要的。</p><div class="oh oi gp gr oj ok"><a rel="noopener follow" target="_blank" href="/linear-regression-the-actually-complete-introduction-67152323fcf2"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">线性回归:(实际上)完全介绍</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">一位同学用 Python 对这个简单的机器学习算法进行了全面、深入的解释</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ks ok"/></div></div></a></div><h1 id="746f" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">该理论</h1><p id="ab46" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi mm translated"><span class="l mn mo mp bm mq mr ms mt mu di"> P </span>多项式回归是一种回归分析形式，其中自变量<em class="na"> x </em>和因变量<em class="na"> y </em>之间的关系被建模为<em class="na">n 次</em>多项式在<em class="na"> x </em>中。</p><p id="23ea" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu"> <em class="na">那么是什么意思呢？</em> </strong></p><p id="6c71" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">你可能还记得，从高中开始，以下功能:</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="2a6d" class="nh kz it pa b gy pe pf l pg ph">Degree of 0 —&gt; Constant function —&gt; f(x) = a<br/>Degree of 1 —&gt; Linear function (straight line) —&gt; f(x) = mx + c<br/>Degree of 2 —&gt; Quadratic function (parabola) —&gt; f(x) = ax^2 + bx+ c<br/>Degree of 3 —&gt; Cubic function —&gt; f(x) = ax^3 + bx^2 + cx + d</span></pre><p id="445e" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">当编写多项式回归脚本时，在某个阶段，我们必须选择我们想要绘制图形的<em class="na">次</em>，我将在后面演示。现在，让我们看看这对我们的函数意味着什么:</p><p id="8592" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu"> <em class="na">什么是度？</em>T29】</strong></p><p id="9358" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">嗯，你可能已经注意到上面的模式:<em class="na">一个多项式的次数就是它的任何一项的最高次幂。因此，我们选择的程度将决定我们用哪个函数来拟合数据。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/7c965e3891ecb3f677159e62ea7198f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-hwN8LMjkvviYa4OlOIyhg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">0–5 次多项式函数</p></figure><p id="645b" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">以上都是多项式。</strong></p><p id="9ddd" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">多项式的简单意思是<em class="na">【多项】</em>，在技术上定义为由变量和系数组成的表达式，只涉及变量的加、减、乘和非负整数指数的运算。</p><p id="958f" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">值得注意的是，虽然线性函数确实符合数学中多项式的定义，但在机器学习的背景下，我们可以将它们视为回归分析的两种不同方法。</p><p id="042c" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">实际上，多项式回归在技术上是一种线性回归。尽管多项式回归将非线性模型拟合到数据，但作为统计估计问题，它是线性的，因为回归函数<em class="na"> E(y|x) </em>在根据数据估计的未知参数中是线性的。因此，多项式回归被认为是多元线性回归的特例。</p><blockquote class="nb nc nd"><p id="bfe2" class="lq lr na ls b lt mv ju lv lw mw jx ly ne mx mb mc nf my mf mg ng mz mj mk ml im bi translated"><strong class="ls iu">简而言之:</strong>把多项式回归想成包含二次和三次函数，把线性回归想成线性函数。</p></blockquote><h1 id="ce82" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">术语</h1><p id="247f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">让我们快速浏览一些重要的定义:</p><h2 id="5fd8" class="nh kz it bd la ni nj dn le nk nl dp li lz nm nn lk md no np lm mh nq nr lo ns bi translated">单变量/双变量</h2><ul class=""><li id="992d" class="nt nu it ls b lt lu lw lx lz pj md pk mh pl ml ny nz oa ob bi translated">一个<em class="na">单变量数据集</em>只涉及一个量，如倍数或权重，从中我们可以确定均值、中值、众数、范围和标准差等，并可以表示为条形图、饼图和直方图。</li><li id="f27b" class="nt nu it ls b lt oc lw od lz oe md of mh og ml ny nz oa ob bi translated">一个<em class="na">双变量数据集</em>有两个量，例如一段时间内的销售额，我们可以用它来比较数据和寻找关系，并且可以用散点图、相关性和回归来表示。</li></ul><h2 id="ae0c" class="nh kz it bd la ni nj dn le nk nl dp li lz nm nn lk md no np lm mh nq nr lo ns bi translated">装配不足/过度装配</h2><ul class=""><li id="ccf1" class="nt nu it ls b lt lu lw lx lz pj md pk mh pl ml ny nz oa ob bi translated">当我们的统计模型不能充分捕捉数据的基本结构时，就会出现欠拟合。</li><li id="1504" class="nt nu it ls b lt oc lw od lz oe md of mh og ml ny nz oa ob bi translated">相反，过度拟合会产生与特定数据集过于接近的分析，因此可能无法拟合额外的数据或可靠地预测未来的观察结果。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/2bc41a47a9dd69213ca484de50d36ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UyP9m6wptaX9KSqDkWjZKg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">欠装配(左)和过装配(右)的示例</p></figure><h1 id="0768" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">该算法</h1><p id="bbe5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">那么，我们什么时候会选择多项式而不是线性回归呢？</p><p id="07f9" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><em class="na">在 3 种主要情况下，多项式回归会超过线性回归:</em></p><ol class=""><li id="a60d" class="nt nu it ls b lt mv lw mw lz nv md nw mh nx ml pn nz oa ob bi translated">理论上的原因。研究者(你)可能会假设数据是曲线，在这种情况下，你显然应该用曲线来拟合它。</li><li id="c241" class="nt nu it ls b lt oc lw od lz oe md of mh og ml pn nz oa ob bi translated">对数据进行目视检查后，可能会发现一种曲线关系。这可以通过简单的散点图来实现(这就是为什么在应用回归分析之前，您应该始终对您的数据进行单变量和双变量检查)。</li><li id="a116" class="nt nu it ls b lt oc lw od lz oe md of mh og ml pn nz oa ob bi translated">检查模型的残差。试图用线性模型拟合曲线数据会导致高正负残差和低 R 值。</li></ol><p id="d1b1" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">让我们更进一步。我们如何选择多项式的次数？</p><p id="9c3b" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">你可以做各种数学分析来决定你的模型的最佳程度，但归结起来就是要确保你不会低估或过度拟合数据。出于我们的目的，简单地检查散点图将揭示合适的选项。</p><p id="0b2c" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">记住，我们执行回归分析的方法是通过确定最小化残差平方和的系数。</p><h1 id="eeee" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">这个例子</h1><p id="0cb2" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">首先，进口:</p><ol class=""><li id="d1e3" class="nt nu it ls b lt mv lw mw lz nv md nw mh nx ml pn nz oa ob bi translated">熊猫——创建一个数据框架</li><li id="f4c6" class="nt nu it ls b lt oc lw od lz oe md of mh og ml pn nz oa ob bi translated">numpy——做科学计算</li><li id="8f4e" class="nt nu it ls b lt oc lw od lz oe md of mh og ml pn nz oa ob bi translated">Matplotlib (pyplot 和 RC params)-创建我们的数据可视化</li><li id="edb3" class="nt nu it ls b lt oc lw od lz oe md of mh og ml pn nz oa ob bi translated">Skikit-Learn(线性回归、train_test_split 和多项式特征)-执行机器学习</li></ol><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="3e4b" class="nh kz it pa b gy pe pf l pg ph">import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from matplotlib import rcParams<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.preprocessing import PolynomialFeatures</span></pre><p id="7507" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">在这个例子中，我创建了自己的数据集，代表了中国 30 天内记录的新冠肺炎新增病例数量，并将其存储在一个 csv 文件中。该文件如下所示:</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="d7f1" class="nh kz it pa b gy pe pf l pg ph">x,y<br/>1,59<br/>2,77<br/>3,93<br/>...,...</span></pre><p id="c671" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">接下来，我们使用 pandas 将<em class="na"> x </em> an <em class="na"> y </em>值读入两个数组。你也可以用 pandas 的 iloc 来做这件事，甚至在没有 pandas 的情况下，手动从文件中读取数据。这个 pandas 方法非常方便，因为我们可以通过名称来访问列。</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="10de" class="nh kz it pa b gy pe pf l pg ph">data = pd.read_csv('china_cases.csv')</span><span id="9041" class="nh kz it pa b gy po pf l pg ph">x = data['x'].values<br/>y = data['y'].values</span></pre><p id="b922" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">我们现在有两个如下所示的数组:</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="7a30" class="nh kz it pa b gy pe pf l pg ph">[1 2 3 4 5 ...]<br/>[59 77 93 149 131 ...]</span></pre><p id="63db" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">让我们将数据分成训练集和测试集。为此，我们将使用 Skikit-Learn 方便的 train_test_split 函数。我们将数组<em class="na"> x </em>和<em class="na"> y </em>值作为参数传递给它，此外还有一个<em class="na">测试大小</em>(您希望测试部分包含多少数据)和一个<em class="na">随机状态</em>(一个整数，表示数据在被分割之前如何被混洗。如果您忽略它，每次运行回归时，您的结果都会略有不同，因此保留它以重现您的结果，但您可以将其删除以用于生产)。</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="6f27" class="nh kz it pa b gy pe pf l pg ph">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)</span></pre><p id="e788" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">现在是通过散点图对数据进行双变量检验的好时机。我将使用 rcParams 和图例添加一些样式，使它在视觉上更具吸引力。</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="b108" class="nh kz it pa b gy pe pf l pg ph">rcParams['axes.spines.top'] = False<br/>rcParams['axes.spines.right'] = False</span><span id="b721" class="nh kz it pa b gy po pf l pg ph">plt.scatter(x_test, y_test, c='#edbf6f', label='Testing data')<br/>plt.scatter(x_train, y_train, c='#8acfd4', label='Training data')<br/>plt.legend(loc="upper left")<br/>plt.show()</span></pre><p id="5069" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">下面，您可以清楚地看到，线性模型不会精确地适合该数据集，但看起来二次或三次函数会很好地工作。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/c0cac272fc313832c3a7aca89b359d46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PJqVYj9dywOB4togLTQLrw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练和测试数据的散点图</p></figure><p id="d064" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">在这一点上，我们想增加我们的数组的维数到 2D，因为这是多项式特征类所要求的必要的矩阵格式。我们可以简单地通过调用<em class="na"> reshape() </em>函数来实现这一点，在这里我们定义我们希望我们的数据如何被整形。</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="8b3f" class="nh kz it pa b gy pe pf l pg ph">x_train = x_train.reshape(-1, 1)<br/>y_train = y_train.reshape(-1, 1)</span></pre><p id="e6ea" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">我们的数组现在看起来像这样(这是<em class="na"> x_train </em>):</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="ff6c" class="nh kz it pa b gy pe pf l pg ph">[[22]<br/> [ 1]<br/> [27]<br/> [14]<br/> [16]<br/>  ...]</span></pre><p id="bc8d" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">然而，正如你所看到的，<em class="na"> train_test_split </em>打乱了我们的数据，所以不再排序。Matplotlib 将按照接收到的顺序绘制点，所以如果我们像现在这样给它输入数组，我们会得到一些非常奇怪的结果。为了对数组重新排序，我们按照<em class="na"> x_train 的</em>索引对<em class="na"> y_train </em>进行排序，并对<em class="na"> x_train </em>本身进行排序。</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="9858" class="nh kz it pa b gy pe pf l pg ph">y_train = y_train[x_train[:,0].argsort()]<br/>x_train = x_train[x_train[:, 0].argsort()]</span></pre><p id="191c" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">正如我前面提到的，我们必须设置多项式的次数。我们通过创建一个 PolynomialFeatures 类的 object <em class="na"> poly </em>来实现这一点，并将我们需要的能力作为参数传递给它。</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="4911" class="nh kz it pa b gy pe pf l pg ph">poly = PolynomialFeatures(degree=2)</span></pre><p id="9e3b" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">此外，我们必须将输入数据矩阵转换成给定阶数的新矩阵。</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="c5b8" class="nh kz it pa b gy pe pf l pg ph">x_poly = poly.fit_transform(x_train)</span></pre><p id="1fd6" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">我们剩下要做的就是训练我们的模型。我们创建一个 LinearRegression 类的对象<em class="na"> poly_reg </em>(记住多项式回归在技术上是线性的，所以它属于同一个类),并使我们转换的<em class="na"> x </em>值和<em class="na"> y </em>值适合模型。</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="b874" class="nh kz it pa b gy pe pf l pg ph">poly_reg = LinearRegression()<br/>poly_reg.fit(x_poly, y_train)</span></pre><p id="8996" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">现在我们简单地绘制我们的线:</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="2127" class="nh kz it pa b gy pe pf l pg ph">plt.title('Disease cases regressed on days')<br/>plt.xlabel('Days')<br/>plt.ylabel('Cases')<br/>plt.plot(x_train, poly_reg.predict(x_poly), c='#a3cfa3', label='Polynomial regression line')<br/>plt.legend(loc="upper left")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/7dad3c216dcb1cfda9022c4a866b11c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8OwpgghJs0HgixFYx5q5eA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">二次多项式回归</p></figure><p id="93cb" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">这就是了，一个符合我们数据的二次函数。</p><p id="e738" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">如果我们把度数设为 3 呢？</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/cda2a1c3eb76db4ce7e6d73b24bd9298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LjesFVbcbWr3DmNvx8B5w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">三次多项式回归</p></figure><p id="ad43" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">这个三次函数似乎更适合我们的数据。让我们通过使用<em class="na">线性回归</em>类<em class="na">来检查他们各自的 R 分数，以更清楚地了解他们的准确性。score() </em>功能:</p><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="aba2" class="nh kz it pa b gy pe pf l pg ph">print(poly_reg.score(x_poly, y_train))</span></pre><p id="cbf6" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">我们二次函数的 R 值是 0.81，而三次函数的 R 值是 0.93。在这种情况下，我会说第三度是一个更合适的选择。</p><p id="7e97" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><em class="na">注意:如果您选择 1 作为度数，您将执行线性回归，但这将是一种非常迂回的方式。</em></p><p id="7e8d" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">如果你想了解另一个有用的最大似然算法，K-Means，看看这篇文章:</strong></p><div class="oh oi gp gr oj ok"><a rel="noopener follow" target="_blank" href="/k-means-clustering-for-beginners-ea2256154109"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">适用于初学者的 k-均值聚类</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">一个深入的解释和一步一步的指导这个有趣和有用的机器学习算法在 Python 中，由…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="pr l ov ow ox ot oy ks ok"/></div></div></a></div><h1 id="5ba3" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">结论</h1><p id="50cd" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi mm translated">这就结束了对机器学习的第二简单算法多项式回归的全面介绍。我希望，作为一名学生，我能够相关而全面地解释这些概念。</p><p id="c06b" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">让我们来复习一下我们学过的内容:</p><ol class=""><li id="ceb8" class="nt nu it ls b lt mv lw mw lz nv md nw mh nx ml pn nz oa ob bi translated">提醒一下什么是二次函数。</li><li id="e5cf" class="nt nu it ls b lt oc lw od lz oe md of mh og ml pn nz oa ob bi translated">一些重要的术语。</li><li id="c38b" class="nt nu it ls b lt oc lw od lz oe md of mh og ml pn nz oa ob bi translated">对算法的解释，包括何时使用多项式回归以及如何选择次数。</li><li id="0bbc" class="nt nu it ls b lt oc lw od lz oe md of mh og ml pn nz oa ob bi translated">实际例子。</li><li id="75ae" class="nt nu it ls b lt oc lw od lz oe md of mh og ml pn nz oa ob bi translated">对我们的模型使用不同程度的比较。</li></ol><p id="d8ff" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">如果你觉得这篇文章有帮助，我很乐意与你合作！关注我<a class="ae ps" href="https://www.instagram.com/adenhaus/" rel="noopener ugc nofollow" target="_blank"> Instagram </a>了解更多机器学习、软件工程和创业内容。</p><p id="2735" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated">编码快乐！</p></div><div class="ab cl pt pu hx pv" role="separator"><span class="pw bw bk px py pz"/><span class="pw bw bk px py pz"/><span class="pw bw bk px py"/></div><div class="im in io ip iq"><p id="473e" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><a class="ae ps" href="https://medium.com/subscribe/@adenhaus" rel="noopener"> <strong class="ls iu">订阅</strong> </a>📚为了不错过我的一篇新文章，如果你还不是中等会员，请加入 🚀去读我所有的，还有成千上万的其他故事！</p></div><div class="ab cl pt pu hx pv" role="separator"><span class="pw bw bk px py pz"/><span class="pw bw bk px py pz"/><span class="pw bw bk px py"/></div><div class="im in io ip iq"><h1 id="ad8a" class="ky kz it bd la lb qa ld le lf qb lh li jz qc ka lk kc qd kd lm kf qe kg lo lp bi translated">资源</h1><p id="284f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated"><strong class="ls iu">分析因子</strong> <em class="na">回归模型:</em><a class="ae ps" href="https://www.theanalysisfactor.com/regression-modelshow-do-you-know-you-need-a-polynomial/" rel="noopener ugc nofollow" target="_blank">https://www . The Analysis Factor . com/Regression-model show-do-you-know-you-need-a-polynomial/</a></p><p id="d665" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">维基</strong> <em class="na">过度拟合:</em><a class="ae ps" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Overfitting</a></p><p id="f727" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">数学很好玩</strong> <em class="na">单变量和双变量数据:</em><a class="ae ps" href="https://www.mathsisfun.com/data/univariate-bivariate.html" rel="noopener ugc nofollow" target="_blank">https://www.mathsisfun.com/data/univariate-bivariate.html</a></p><p id="86b3" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">堆栈溢出</strong> <em class="na">随机状态:</em><a class="ae ps" href="https://stackoverflow.com/questions/28064634/random-state-pseudo-random-number-in-scikit-learn" rel="noopener ugc nofollow" target="_blank">https://Stack Overflow . com/questions/28064634/Random-State-pseudo-Random-number-in-scikit-learn</a></p><p id="0b1b" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">sci kit-Learn</strong><em class="na">sk Learn . preprocessing . polynomial features:</em><a class="ae ps" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures.fit_transform" rel="noopener ugc nofollow" target="_blank">https://sci kit-Learn . org/stable/modules/generated/sk Learn . preprocessing . polynomial features . html # sk Learn . preprocessing . polynomial features . fit _ transform</a></p><p id="2185" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">Scikit-Learn</strong><em class="na">sk Learn . linear _ model。线性回归:</em><a class="ae ps" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . linear _ model。LinearRegression.html</a></p><p id="d71f" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">Scikit-Learn</strong><em class="na">sk Learn . model _ selection . train _ test _ split:</em><a class="ae ps" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank">https://Scikit-Learn . org/stable/modules/generated/sk Learn . model _ selection . train _ test _ split . html</a></p><p id="bdc8" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">栈溢出</strong> O <em class="na">排序点:</em><a class="ae ps" href="https://stackoverflow.com/questions/31653968/matplotlib-connecting-wrong-points-in-line-graph" rel="noopener ugc nofollow" target="_blank">https://Stack Overflow . com/questions/31653968/matplotlib-connecting-error-Points-in-line-graph</a></p><p id="e4bc" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">堆栈溢出</strong> <em class="na">根据另一个列表的索引对一个列表排序:</em><a class="ae ps" href="https://stackoverflow.com/questions/6618515/sorting-list-based-on-values-from-another-list" rel="noopener ugc nofollow" target="_blank">https://Stack Overflow . com/questions/6618515/Sorting-list-based-on-values-from-other-list</a></p><p id="4401" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly lz mx mb mc md my mf mg mh mz mj mk ml im bi translated"><strong class="ls iu">堆栈溢出</strong> <em class="na">按第二列排序 2D 数组:</em><a class="ae ps" href="https://stackoverflow.com/questions/22698687/how-to-sort-2d-array-numpy-ndarray-based-to-the-second-column-in-python" rel="noopener ugc nofollow" target="_blank">https://Stack Overflow . com/questions/22698687/how-to-sort-2d-array-numpy-ndarray-based-to-the-second-column-in-python</a></p></div></div>    
</body>
</html>