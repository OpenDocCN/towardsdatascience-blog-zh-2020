<html>
<head>
<title>Object Detection using YoloV3 and OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用YoloV3和OpenCV进行目标检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-using-yolov3-and-opencv-19ee0792a420?source=collection_archive---------6-----------------------#2020-03-08">https://towardsdatascience.com/object-detection-using-yolov3-and-opencv-19ee0792a420?source=collection_archive---------6-----------------------#2020-03-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bf82" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">面向初学者的YoloV3物体检测介绍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6974a7e29e076dad74d42cd0ed1363a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pOBd3QvpLL88gurjZ8g_GQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用YoloV3和OpenCV进行目标检测</p></figure><p id="da64" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated">计算机视觉一直是我着迷的话题。通俗地说，计算机视觉就是复制人类视觉的复杂性和他对周围环境的理解。它正在成为人工智能最强有力的应用领域之一。由于每天都会产生大量的数据。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="6664" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">目标检测</h1><p id="c8e1" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">当我们观看图像或视频时，我们可以很容易地在瞬间定位和识别我们感兴趣的对象。将这种智能传递给计算机只不过是物体检测——定位物体并识别它。目标检测在很多领域都有应用，比如视频监控、图像检索系统、自动驾驶汽车等等。各种算法可用于对象检测，但我们将集中于YoloV3算法。</p><h1 id="b197" class="mk ml it bd mm mn nh mp mq mr ni mt mu jz nj ka mw kc nk kd my kf nl kg na nb bi translated">YoloV3算法</h1><p id="a4af" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated"><em class="nm">你只看一次</em>或者更通俗的说法是，与R-CNN家族(R-CNN，Fast R-CNN，Faster R-CNN等)相比，YOLO是最快的实时物体检测算法之一(每秒45帧)。)</p><p id="2055" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">R-CNN系列算法使用区域来定位图像中的对象，这意味着该模型被应用于多个区域，并且图像的高得分区域被认为是检测到的对象。但是YOLO遵循一种完全不同的方法。它不是选择一些区域，而是对整个图像应用神经网络来预测边界框及其概率。</p><p id="e48b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们有两个选项来开始对象检测:</p><ol class=""><li id="dd4f" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated">使用预先训练的模型</li><li id="04d8" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated">从头开始训练自定义对象检测器</li></ol><p id="f973" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将着眼于使用图像、视频和实时网络摄像头的预训练模型来创建对象检测器。如果你想训练一个自定义的YOLO物体探测器，我建议你前往<a class="ae ob" href="https://neptune.ai/blog/object-detection-with-yolo-hands-on-tutorial" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">与YOLO物体探测:动手教程</strong> </a>。作者介绍了从定制对象检测器的数据注释到处理数据并最终训练模型的所有步骤。</p><p id="a193" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们深入研究代码。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><p id="1fae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们从导入该程序所需的模块开始。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模块</p></figure><p id="7c3d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您还需要下载几个重要文件，包括YoloV3的预训练权重、配置文件和名称文件。</p><p id="7dbb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">重量和cfg(或配置)文件可以从<a class="ae ob" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank">https://pjreddie.com/darknet/yolo</a>下载。您将看到几个不同的选项。该模型已针对不同大小的图像进行了训练:320 x 320(高速，精度较低)、416 x 416(中速，精度中等)和608 x 608(低速，精度较高)。我们现在将下载yolov 3–320的重量和cfg文件。</p><p id="46c7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">名字文件可以从<a class="ae ob" href="https://github.com/pjreddie/darknet/blob/master/data/coco.names" rel="noopener ugc nofollow" target="_blank">https://github . com/pjreddie/darknet/blob/master/data/coco . names</a>下载。</p><p id="b1f2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们已经下载并准备好了所有这些文件，我们可以开始编写python脚本了。就像我之前提到的，我们的输入有三种形式:</p><ol class=""><li id="f8b7" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated">图象档案</li><li id="88b5" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated">网络摄像头馈送</li><li id="ff78" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated">可见文件</li></ol><p id="d9dc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，我们将创建一个名为<strong class="la iu"> load_yolo() </strong>的函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">装载重量</p></figure><p id="2a3f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上面的函数中，你可以看到，我在OpenCV的<strong class="la iu"> dnn </strong>模块的帮助下加载YoloV3权重和配置文件。<strong class="la iu"> coco.names </strong>文件包含我们的模型被训练识别的不同对象的名称。我们将它们存储在一个名为<strong class="la iu"> <em class="nm">类</em> </strong>的列表中。现在要使用<strong class="la iu"> cv2.dnn </strong>模块运行一个正向传递，我们需要传递要计算输出的层的名称。<strong class="la iu">net . getunconnectedoutlayers()</strong>返回网络输出层的指数。</p><p id="36ac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了接受图像文件，我们将需要另一个名为<strong class="la iu"> load_image() </strong>的函数，它将接受一个图像路径作为参数，读取图像，调整其大小并返回它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">加载图像</p></figure><p id="b6c6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了正确预测具有深度神经网络的对象，我们需要对我们的数据进行预处理，<strong class="la iu"> cv2.dnn </strong>模块为此提供了两个函数:<strong class="la iu"><em class="nm">blobFromImage</em></strong>和<strong class="la iu"> <em class="nm"> blobFromImages。</em> </strong>这些功能执行缩放、均值减法和可选的通道交换。我们将在一个名为<strong class="la iu"> detect_objects() </strong>的函数中使用<strong class="la iu"><em class="nm">blobFromImage</em></strong>，该函数接受来自视频或网络摄像头流的图像/帧、模型和输出层作为参数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="a905" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你在上面的代码片段中看到的，我们使用了<strong class="la iu"> 0.00392 </strong>的<strong class="la iu">比例因子</strong>，也可以写成<strong class="la iu"> 1/255 </strong>。因此，我们将图像像素缩放到0到1的范围。不需要均值减法，这就是为什么我们将它设置为<strong class="la iu">【0，0，0】</strong>值。</p><p id="b389" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> cv2.dnn </strong>模块的<strong class="la iu"> forward() </strong>函数返回一个嵌套列表，其中包含所有检测到的对象的信息，包括检测到的对象中心的x和y坐标、边界框的高度和宽度、coco.names中列出的所有对象类别的置信度和得分。得分最高的类别被视为预测类别。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="1f19" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在<strong class="la iu"> get_box_dimensions() </strong>函数中，创建了一个名为<em class="nm"> scores </em>的列表，其中存储了对应于每个对象的置信度。然后，我们使用<strong class="la iu"> np.argmax() </strong>来识别具有最高置信度/得分的类的索引。我们可以从我们在<strong class="la iu"> load_yolo() </strong>中创建的<em class="nm"> classes </em>列表中获得对应于索引的类名。</p><p id="dd03" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我选择了所有置信度超过30 %的预测边界框。您可以随意使用这个值。</p><p id="58b9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们有了预测边界框的顶点和class_id(预测对象类的索引)，我们需要绘制边界框并向其添加一个对象标签。我们将借助<strong class="la iu"> draw_labels() </strong>函数来完成。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="5ebc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，你一定在想，<strong class="la iu"> cv2.dnn.NMSBoxes() </strong>是干什么用的？我们只是应该添加绘制边界框，并添加一个标签，对不对？</p><p id="e242" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尽管我们移除了低置信度边界框，但仍有可能在对象周围出现重复检测。例如，请看下图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/ad2d2fec4796b0bf670f38222dcf1deb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*C_9fyPCt15vw0tjUZuu7lQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有多个包围盒的对象检测</p></figure><p id="a979" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可能会注意到，有些对象已经被检测了多次，我们有一个以上的边界框。为了解决这种情况，我们需要应用<strong class="la iu">非最大值抑制(NMS) </strong>，也称为<strong class="la iu">非最大值抑制</strong>。我们传入置信度阈值和NMS阈值作为参数来选择一个包围盒。从0到1的范围内，我们应该选择一个中间值，如0.4或0.5，以确保我们检测到重叠的对象，但最终不会为同一个对象获得多个边界框。</p><p id="9670" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，最终输出如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/4a045fb627a3e24ffd06c551aacc8738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*AlCFUk7x4ZJbZocVrWiNzw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最终输出</p></figure><p id="d31c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们看到的所有函数都可以在另一个名为<strong class="la iu"> image_detect() </strong>的函数中流水线化，用于检测图像文件中的对象。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="2908" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，对于视频文件和网络摄像头输入，我们可以创建两个不同的函数，分别叫做<strong class="la iu"> start_video() </strong>和<strong class="la iu"> webcam_detect() </strong>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="06c0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">完整的工作脚本可以在<a class="ae ob" href="https://github.com/nandinib1999/object-detection-yolo-opencv" rel="noopener ugc nofollow" target="_blank">https://github . com/nandinib 1999/object-detection-yolo-opencv</a>找到。</p><p id="ca8c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">更新2021/11/05 </strong></p><p id="7b1c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">加载YOLO-V3砝码时，代码可能会中断，您可能会得到如下所示的错误。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/97bb653ac6c62b6f24b9d5b516fde838.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pML3Gm1wpNO8YoQAZYT66A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">错误截图</p></figure><p id="441c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果发生这种情况，您可以使用load_yolo()的以下代码片段:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">错误修复</p></figure><p id="a88a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">解决这个问题后，我遇到了另一个问题:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/ee07d8c7d1f32816a782d4e40f359128.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hps3P6w9Dp98eQ9kw-7qg.png"/></div></div></figure><p id="c75b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就像一个警告。它不会中断代码的功能，但是在代码运行时，这个警告会一直出现在命令行上。我试图寻找一个解决方案，发现这是由于OpenCV和PyQt库之间的一些依赖问题。您可能需要升级/降级这些库，以使它们再次兼容。</p><p id="c271" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个有用的问题线索是<a class="ae ob" href="https://github.com/Yuliang-Liu/Curve-Text-Detector/issues/11" rel="noopener ugc nofollow" target="_blank"> THIS </a>来了解更多关于警告和修复它的信息。此外，如果你们中的任何一个人能够找到这个警告的永久解决方法，也请与我们分享。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><p id="6fbd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这都是为了这篇文章。希望你觉得有用。如果有，请鼓掌。如有任何问题和建议，请随时通过<a class="ae ob" href="http://www.linkedin.com/in/nandini-b-b4baaa178" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>与我联系。</p><p id="23a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读！</p><p id="4483" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">~南迪尼</p></div></div>    
</body>
</html>