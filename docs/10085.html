<html>
<head>
<title>How to run a PySpark job in Kubernetes (AWS EKS)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在 Kubernetes (AWS EKS)运行 PySpark 作业</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-run-a-pyspark-job-in-kubernetes-aws-eks-d886193dac3c?source=collection_archive---------19-----------------------#2020-07-16">https://towardsdatascience.com/how-to-run-a-pyspark-job-in-kubernetes-aws-eks-d886193dac3c?source=collection_archive---------19-----------------------#2020-07-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="43a6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于使用 Terraform 部署 EKS 集群和使用 Spark 操作符运行 PySpark 作业的完整教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/73746ce8640170add473aa383e512ad7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GRiumE8YtWrwUsZF-LeVrA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">萨姆森在 Unsplash.com 拍摄的照片</p></figure><p id="9688" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本教程中，我们将重点关注在 AWS EKS 上端到端部署 Spark 应用程序。我们将执行以下步骤:</p><ul class=""><li id="46d5" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">在 AWS 中的定制 VPC 内部署 EKS 集群</li><li id="99b4" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">安装火花操作器</li><li id="77a1" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">运行一个简单的 PySpark 应用程序</li></ul><p id="6c8b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">TL；博士:</strong> <a class="ae mi" href="https://github.com/BogdanCojocar/medium-articles/tree/master/terraform_eks_spark" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> Github 代码回购</strong> </a></p><h1 id="2b09" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">步骤 1:部署 Kubernetes 基础设施</strong></h1><p id="bb98" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">要在 AWS 上部署 Kubernetes，我们至少需要部署:</p><ul class=""><li id="a662" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><strong class="la iu"> VPC、子网和安全组</strong>负责集群中的网络</li><li id="af8d" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><strong class="la iu"> EKS 控制平面</strong>主要运行 Kubernetes 服务，如<code class="fe ng nh ni nj b">etcd</code>和<code class="fe ng nh ni nj b">Kubernetes API</code></li><li id="3167" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><strong class="la iu"> EKS 工人节点</strong>能够运行 pod 和更具体的针对我们案例的 spark 作业</li></ul><p id="9dfc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们深入研究 Terraform 代码。首先，让我们看看 VPC:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="f5c6" class="no mk it nj b gy np nq l nr ns">module "vpc" {<br/>  source  = "terraform-aws-modules/vpc/aws"<br/>  version = "2.6.0"</span><span id="f06a" class="no mk it nj b gy nt nq l nr ns">name                 = join("-", [var.cluster_name, var.environment, "vpc"])<br/>  cidr                 = var.vpc_cidr<br/>  azs                  = data.aws_availability_zones.available.names<br/>  private_subnets      = [var.private_subnet_az_1, var.private_subnet_az_2, var.private_subnet_az_3]<br/>  public_subnets       = [var.public_subnet_az_1, var.public_subnet_az_2, var.public_subnet_az_3]<br/>  enable_nat_gateway   = true<br/>  single_nat_gateway   = false<br/>  one_nat_gateway_per_az = true<br/>  enable_dns_hostnames = true<br/>  enable_dns_support   = true</span><span id="0048" class="no mk it nj b gy nt nq l nr ns">tags = {<br/>    "kubernetes.io/cluster/${var.cluster_name}" = "shared"<br/>  }</span><span id="b81d" class="no mk it nj b gy nt nq l nr ns">public_subnet_tags = {<br/>    "kubernetes.io/cluster/${var.cluster_name}" = "shared"<br/>    "kubernetes.io/role/elb"                      = "1"<br/>  }</span><span id="140f" class="no mk it nj b gy nt nq l nr ns">private_subnet_tags = {<br/>    "kubernetes.io/cluster/${var.cluster_name}" = "shared"<br/>    "kubernetes.io/role/internal-elb"             = "1"<br/>  }<br/>}</span></pre><p id="4ba9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">VPC 是一个孤立的网络，其中可以有不同的基础架构组件。我们可以将这个网络分解成更小的块，在 AWS 上我们称之为子网。有些子网可以访问互联网，这就是我们称之为公共子网的原因，而有些子网不能访问互联网，则称为私有子网。我们将在网络流量上下文中使用的另一个术语是出口和入口。出口是指从网络内部流向外部世界的流量，以及从外部世界流向网络的入口流量。如您所料，这些规则可能会因用例而异。我们还使用安全组，这是 VPC 内部的流量规则，它定义了 EC2 实例如何相互“对话”,基本上是在哪些网络端口上。</p><p id="5891" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于 Spark EKS 集群，see 将为工作线程使用专用子网。所有的数据处理都是在完全隔离的情况下完成的。但是我们需要到互联网的出口流量，以进行更新或安装开源库。为了支持互联网流量，我们在 VPC 中使用 NAT 网关。我们必须将它们添加到公共子网中。在地形代码中，这是使用标志<code class="fe ng nh ni nj b">enable_nat_gateway.</code>完成的</p><p id="3d7d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以注意到的另一件事是，我们使用了三个公共和私有子网。这是因为我们希望拥有网络容错能力。子网部署在一个区域的不同可用性区域中。</p><p id="aa9f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">标签是按照 AWS 的要求创建的。控制平面需要它们来识别工作节点。我们可以更详细地介绍网络，但这超出了本教程的范围，所以如果您需要更多的细节，请查看 Github 代码，在那里您可以找到完整的示例。</p><p id="c495" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看 EKS 集群的设置:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="b931" class="no mk it nj b gy np nq l nr ns">module "eks" {<br/>  source       = "terraform-aws-modules/eks/aws"<br/>  cluster_name = join("-", [var.cluster_name, var.environment, random_string.suffix.result])<br/>  subnets      = module.vpc.private_subnets</span><span id="a259" class="no mk it nj b gy nt nq l nr ns">tags = {<br/>    Environment = var.environment<br/>  }</span><span id="66e3" class="no mk it nj b gy nt nq l nr ns">vpc_id = module.vpc.vpc_id<br/>  cluster_endpoint_private_access = true</span><span id="6c71" class="no mk it nj b gy nt nq l nr ns">cluster_enabled_log_types = ["api", "audit", "authenticator", "controllerManager", "scheduler"]</span><span id="9922" class="no mk it nj b gy nt nq l nr ns">worker_groups = [<br/>    {<br/>      name                          = "worker-group-spark"<br/>      instance_type                 = var.cluster_instance_type<br/>      additional_userdata           = "worker nodes"<br/>      asg_desired_capacity          = var.cluster_number_of_nodes<br/>      additional_security_group_ids = [aws_security_group.all_worker_mgmt.id, aws_security_group.inside_vpc_traffic.id]<br/>    }<br/>  ]</span><span id="7d02" class="no mk it nj b gy nt nq l nr ns">workers_group_defaults = {<br/>    key_name = "eks_key"<br/>    subnets = module.vpc.private_subnets<br/>  }<br/>}</span></pre><p id="68da" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个代码片段中，我们可以看到我们在私有子网内声明了集群。我们为控制面板的所有组件启用 Clowdwatch 日志。我们为配置<code class="fe ng nh ni nj b">var</code>模块设置 EC2 实例类型和数量，默认情况下，我们使用<code class="fe ng nh ni nj b">m5.xlarge</code>作为实例类型和 3 个节点。如果我们需要 ssh 进入工作节点，我们设置一个 EC2 键<code class="fe ng nh ni nj b">eks_key</code>。</p><p id="311c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了能够运行本教程中的代码，我们需要安装一些工具。在 Mac 上，我们可以使用<code class="fe ng nh ni nj b">brew:</code></p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="f598" class="no mk it nj b gy np nq l nr ns">brew install terraform aws-iam-authenticator kubernetes-cli helm</span></pre><p id="02dd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了达到 AWS，我们还需要<a class="ae mi" href="https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html" rel="noopener ugc nofollow" target="_blank">设置我们的 AWS 凭证</a>。</p><p id="0a2a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们可以开始初始化 Terraform，以获得部署基础设施所需的所有依赖项:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="3e44" class="no mk it nj b gy np nq l nr ns">cd deployment/ &amp;&amp; terraform init</span></pre><p id="feb6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果一切运行成功，您应该能够看到类似于下图的内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/2a7553ad7653a0210f41223795824e88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nUiWf1yGaC2_kaIxTxLa7A.png"/></div></div></figure><p id="6ca3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们已经准备好部署基础设施。为此，请运行:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="854a" class="no mk it nj b gy np nq l nr ns">terraform apply</span></pre><p id="bb73" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">部署完成还需要一段时间，所以我们可以高枕无忧了。</p><p id="61d4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">完成后，您应该会看到消息<code class="fe ng nh ni nj b">Apply complete! Resources: 55 added, 0 changed, 0 destroyed.</code>和部署的资源的名称。</p><p id="4fef" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">检查部署是否正确的另一个步骤是查看工作节点是否已经连接到集群。为此我们设置了<code class="fe ng nh ni nj b">kubectl:</code></p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="5668" class="no mk it nj b gy np nq l nr ns">aws --region your-region eks update-kubeconfig --name your-cluster-name</span></pre><p id="28ee" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们运行以下命令时，应该能够看到三个节点:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="1f25" class="no mk it nj b gy np nq l nr ns">kubectl get nodes</span></pre><h1 id="c85c" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">步骤 2:安装 Spark 操作器</h1><p id="65b0" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">通常，我们使用<code class="fe ng nh ni nj b">spark-submit</code>部署 spark 作业，但是在 Kubernetes 中，我们有一个更好的选择，与环境更加集成，称为<a class="ae mi" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator" rel="noopener ugc nofollow" target="_blank"> Spark 操作符</a>。它带来的一些改进包括自动重新提交应用程序、使用自定义重启策略自动重启、自动重试失败的提交，以及与 Prometheus 等监控工具的轻松集成。</p><p id="609e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以通过<code class="fe ng nh ni nj b">helm:</code>安装它</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="0d47" class="no mk it nj b gy np nq l nr ns">helm repo add incubator http://storage.googleapis.com/kubernetes-charts-incubator<br/>helm install spark-op incubator/sparkoperator</span></pre><p id="ca89" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们在终端中运行<code class="fe ng nh ni nj b">helm list</code>，那么<code class="fe ng nh ni nj b">spark-op</code>图表应该是可用的。此外，我们应该有一个运行的火花操作员吊舱。我们可以使用命令<code class="fe ng nh ni nj b">kubectl get pods.</code>来观察在<code class="fe ng nh ni nj b">default</code>名称空间中运行的 pods</p><h1 id="3001" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">步骤 3:运行 PySpark 应用程序</h1><p id="f43e" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">现在我们终于可以在 K8s 中运行 python spark 应用了。我们需要做的第一件事是创建一个<code class="fe ng nh ni nj b">spark</code>用户，以便让 spark jobs 访问 Kubernetes 资源。为此，我们创建了一个服务帐户和一个群集角色绑定:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="0be1" class="no mk it nj b gy np nq l nr ns">apiVersion: v1<br/>kind: ServiceAccount<br/>metadata:<br/>  name: spark<br/>---<br/>apiVersion: rbac.authorization.k8s.io/v1<br/>kind: ClusterRoleBinding<br/>metadata:<br/>  name: spark-role<br/>roleRef:<br/>  apiGroup: rbac.authorization.k8s.io<br/>  kind: ClusterRole<br/>  name: edit<br/>subjects:<br/>  - kind: ServiceAccount<br/>    name: spark<br/>    namespace: default</span></pre><p id="bafa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要执行角色的创建:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="6480" class="no mk it nj b gy np nq l nr ns">kubectl apply -f spark/spark-rbac.yml</span></pre><p id="a58d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您将收到<code class="fe ng nh ni nj b">serviceaccount/spark created</code>和<code class="fe ng nh ni nj b">clusterrolebinding.rbac.authorization.k8s.io/spark-role created.</code>的通知</p><p id="ce3d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">星火操作员工作定义:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="931d" class="no mk it nj b gy np nq l nr ns">apiVersion: "sparkoperator.k8s.io/v1beta2"<br/>kind: SparkApplication<br/>metadata:<br/>  name: spark-job<br/>  namespace: default<br/>spec:<br/>  type: Python<br/>  pythonVersion: "3"<br/>  mode: cluster<br/>  image: "uprush/apache-spark-pyspark:2.4.5"<br/>  imagePullPolicy: Always<br/>  mainApplicationFile: local:////opt/spark/examples/src/main/python/pi.py<br/>  sparkVersion: "2.4.5"<br/>  restartPolicy:<br/>    type: OnFailure<br/>    onFailureRetries: 2<br/>  driver:<br/>    cores: 1<br/>    memory: "1G"<br/>    labels:<br/>      version: 2.4.5<br/>    serviceAccount: spark<br/>  executor:<br/>    cores: 1<br/>    instances: 1<br/>    memory: "1G"<br/>    labels:<br/>      version: 2.4.5</span></pre><p id="105f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在一个<code class="fe ng nh ni nj b">yml</code>文件中定义我们的 spark run 参数，类似于 Kubernetes 上的任何其他资源声明。基本上，我们定义我们正在运行一个<code class="fe ng nh ni nj b">Python 3</code> spark 应用程序，我们是映像<code class="fe ng nh ni nj b">uprush/apache-spark-pyspark:2.4.5.</code>我推荐使用这个映像，因为它带有一个更新版本的 yarn，可以更有效地处理对<code class="fe ng nh ni nj b">s3a</code>的写入。我们有一个重试策略，如果作业失败，它将重新启动。驱动程序和执行器的一些资源分配。由于工作非常简单，我们只使用一个执行程序。我们可以注意到的另一件事是，我们使用了之前定义的<code class="fe ng nh ni nj b">spark</code>服务帐户。我们使用的 To 代码是计算<code class="fe ng nh ni nj b">pi</code>数的经典例子。</p><p id="0737" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要提交我们再次使用的代码<code class="fe ng nh ni nj b">kubectl</code>:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="85cf" class="no mk it nj b gy np nq l nr ns">kubectl apply -f spark/spark-job.yml</span></pre><p id="8a79" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">完成后，如果我们再次检查豆荚，我们应该有类似的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/5ba3981d06b59181399df68aac3d28e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pgCn5EaBUcwx68mUBkMgWQ.png"/></div></div></figure><p id="aff2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们通过运行<code class="fe ng nh ni nj b">kubectl logs spark-job-driver</code>来检查日志，我们应该会在日志中找到一行给出 pi 的近似值<code class="fe ng nh ni nj b">Pi is roughly 3.142020.</code></p><p id="7fb6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那是所有的人。我希望你喜欢这个教程。我们已经看到了如何使用 terraform 创建我们自己的 AWS EKS 集群，以便在不同的环境中轻松地重新部署它，以及如何使用更友好的 Kubernetes 语法提交 PySpark 作业。</p></div></div>    
</body>
</html>