<html>
<head>
<title>If Your ML Algorithm Is Not Performing Well</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如果你的 ML 算法表现不好</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/your-ml-algorithm-is-not-performing-well-613dd2b07fc?source=collection_archive---------29-----------------------#2020-09-16">https://towardsdatascience.com/your-ml-algorithm-is-not-performing-well-613dd2b07fc?source=collection_archive---------29-----------------------#2020-09-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/05da716f4a75ae021c812e170c6f9534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0TFW_woatY4ps2gs"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">罗布·施莱克希斯在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="7f9e" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">如何发现问题</h2></div><p id="260a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们花了这么多时间开发机器学习算法。但是在部署之后，如果该算法表现不佳，就会变得令人沮丧。问题是，如果算法没有达到预期效果，下一步该怎么办。哪里出了问题？训练数据的数量足够吗？我们使用了正确的功能吗？我们应该继续收集更多的数据吗？我们可以，但是那非常耗时而且昂贵。我们应该增加更多的功能吗？那也会很贵。</p><blockquote class="lu lv lw"><p id="2e7a" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">往哪个方向走？</strong></p></blockquote><p id="7d8c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你的机器学习算法没有达到预期效果，下一步该怎么办？有几个选项:</p><ol class=""><li id="cc6f" class="mb mc jj la b lb lc le lf lh md ll me lp mf lt mg mh mi mj bi translated">获取更多的训练数据非常耗时。甚至可能需要几个月才能获得更多的研究数据。</li><li id="1ed9" class="mb mc jj la b lb mk le ml lh mm ll mn lp mo lt mg mh mi mj bi translated">获得更多培训功能。这也可能需要很多时间。但是，如果添加一些多项式功能的作品，这是很酷的。</li><li id="fc24" class="mb mc jj la b lb mk le ml lh mm ll mn lp mo lt mg mh mi mj bi translated">选择一组较小的训练特征。</li><li id="74af" class="mb mc jj la b lb mk le ml lh mm ll mn lp mo lt mg mh mi mj bi translated">增加正则项</li><li id="e75f" class="mb mc jj la b lb mk le ml lh mm ll mn lp mo lt mg mh mi mj bi translated">减少正则项。</li></ol><p id="02f9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，接下来你应该尝试哪一个呢？开始尝试任何事情都不是一个好主意。因为你可能会在一些没有帮助的事情上花费太多时间。你需要首先发现问题，然后采取相应的行动。学习曲线有助于轻松发现问题，从而节省大量时间。</p><p id="661a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">学习曲线对于确定如何提高算法的性能非常有用。确定算法是否存在偏差或欠拟合、方差或过拟合，或者两者兼而有之是很有用的。</p><h2 id="bfb4" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lh my mz na ll nb nc nd lp ne nf ng nh bi translated">学习曲线如何工作</h2><p id="aed6" class="pw-post-body-paragraph ky kz jj la b lb ni kk ld le nj kn lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">学习曲线是成本函数的曲线。同一图中训练数据的成本函数和交叉验证数据的成本函数给出了关于算法的重要见解。提醒一下，下面是成本函数的公式:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/b478c54da02ece6783fe83005e70c54c.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/0*psHvqhYUINyF7iey.png"/></div></figure><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/9f231a24fc5d5b87ee8bce8ed7b1ca95.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/0*ZVCB72tuSym8bHpi.png"/></div></figure><p id="28b8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">换句话说，它是预测输出的平方减去原始输出除以两倍的训练数据。为了制作学习曲线，我们需要将这些成本函数绘制成训练数据数量(m)的函数。我们将只使用训练数据的一个较小子集来训练数据，而不是使用所有的训练数据。</p><p id="1bcd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请看下图:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/316cca24439e43f6fe5d86e45f0a5ccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/0*S_4kGpNC1rkOpGzL.png"/></div></figure><blockquote class="lu lv lw"><p id="43a9" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">这里是概念</strong></p></blockquote><p id="ae8c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们用太少的数据来训练数据，算法将完全适合训练数据，并且成本函数将返回 0。</p><p id="70ef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上图清楚地显示，当我们只使用一个、两个或三个数据训练数据时，算法可以很好地学习这几个数据，训练成本为零或接近于零。但是这种类型的算法不能在其他数据上很好地执行。</p><p id="cc3c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当您尝试用此算法拟合交叉验证数据时，它很可能在交叉验证数据上表现不佳。因此，交叉验证数据的成本函数将返回一个非常高的值。</p><p id="2969" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一方面，当我们采用越来越多的数据来训练算法时，它将不再完全适合训练数据。所以，培训成本会变得更高。</p><p id="7e8b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同时，由于该算法是在大量数据上训练的，它将在交叉验证数据上执行得更好，并且交叉验证数据的成本函数将返回更低的值。以下是如何建立一条学习曲线。</p><h2 id="5c82" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lh my mz na ll nb nc nd lp ne nf ng nh bi translated">开发一个学习算法</h2><p id="3afa" class="pw-post-body-paragraph ky kz jj la b lb ni kk ld le nj kn lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">我将一步步演示如何绘制学习曲线。为了绘制学习曲线，我们首先需要一个机器学习算法。为了简单起见，我将使用线性回归算法。我们先开发一个线性回归算法。</p><p id="2223" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，导入包和数据集。我在这里使用的数据集取自吴恩达在 Coursera 上的机器学习课程。在该数据集中，X 值和 y 值被组织在 Excel 文件中的不同工作表中。</p><p id="6caa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">提醒一下，X 是我们将用来开发和训练机器学习算法的功能。y 是我们需要预测的输出特征。</p><p id="55ad" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">交叉验证数据的 x 和 y 值也组织在同一个 Excel 文件的另外两个工作表中。我在本文末尾提供了数据集的链接。请随意下载数据集并自己练习。</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="3825" class="mp mq jj nv b gy nz oa l ob oc">%matplotlib inline<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>file = pd.ExcelFile('dataset.xlsx')<br/>df = pd.read_excel(file, 'Xval', header=None)<br/>df.head()</span></pre><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi od"><img src="../Images/f5962e559a6c3f2362d4d2380b5fc474.png" data-original-src="https://miro.medium.com/v2/resize:fit:202/format:webp/0*z6ubxpfzgiAKWAU1.png"/></div></figure><p id="5540" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，导入定型集的 y 值:</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="8d31" class="mp mq jj nv b gy nz oa l ob oc">y = pd.read_excel(file, 'yval', header=None)<br/>y.head()</span></pre><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/6a37b538040509816d91d03d5957d5c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:190/format:webp/0*BSG37Jhl1vo6Y75x.png"/></div></figure><p id="79a4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们快速开发线性回归算法。</p><blockquote class="lu lv lw"><p id="8124" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">定义假设</strong></p></blockquote><p id="0198" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">线性回归使用非常基本的线性方程进行预测，我们在学校都学过。公式如下:</p><p id="ee5d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Y = C + BX</p><p id="62a6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于机器学习，我们使用不同的术语。</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi of"><img src="../Images/906dcdf3049cf21a37b69eb086559c94.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/0*RvsMi6W637WMJL-F.png"/></div></figure><p id="5479" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，“h”是假设或预测值，θ0 和θ1 是系数，X 是输入特征。</p><p id="a59a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，我们已经有了 x。我们必须计算' h '并且它应该与 y 的值匹配。因为我们的目标是能够预测 y 的值。</p><p id="549e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">θ0 和θ1 在开始时被随机初始化。我们将通过迭代不断改进θ0 和θ1 的值。</p><blockquote class="og"><p id="f3b3" class="oh oi jj bd oj ok ol om on oo op lt dk translated">在每次迭代中，我们将使用成本函数和梯度公式来计算成本，以更新θ值</p></blockquote><blockquote class="lu lv lw"><p id="658a" class="ky kz lx la b lb oq kk ld le or kn lg ly os lj lk lz ot ln lo ma ou lr ls lt im bi translated"><strong class="la jk">成本函数和梯度下降</strong></p></blockquote><p id="122a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">成本函数为我们提供了关于预测值与原始输出要素的差异的想法。这里，我们的输出特征是 y，预测输出将是‘h’。因此，成本函数会告诉我们“h”偏离“y”多少。我们希望成本函数值尽可能低。</p><p id="20b9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是成本函数的公式:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/ae1e1e87ce37e2a1753ac7a3a7b90dd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/0*gkfLT9KiuBKAKFVZ.png"/></div></figure><p id="b614" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将继续运行算法，直到成本函数最小。在每次迭代中，我们使用梯度下降来更新θ值。</p><p id="5b96" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了更新θ值，我们将从先前的θ值中减去梯度下降。当我们把它编码的时候，它会变得更加清晰。</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/345ab294dffebfe78e6056a23dcda588.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/0*midG-NOec2XIfT--.png"/></div></figure><p id="db81" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，m 是训练数据的数量，α是学习率。</p><blockquote class="lu lv lw"><p id="b623" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">开发线性回归算法</strong></p></blockquote><p id="0172" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用上述公式开发假设和成本函数。</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="8c3e" class="mp mq jj nv b gy nz oa l ob oc">m = len(df)</span><span id="941e" class="mp mq jj nv b gy ox oa l ob oc">def hypothesis(theta, X):<br/>    return theta[0] + theta[1]*X</span><span id="e95a" class="mp mq jj nv b gy ox oa l ob oc">def cost_calc(theta, X, y):<br/>    return (1/2*m) * np.sum((hypothesis(theta, X) - y)**2)</span></pre><p id="8ae6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们将定义梯度下降来优化参数θ0 和θ1。在每次迭代中，我们将更新θ值，并跟踪成本函数和θ值。</p><p id="062c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，它将返回每次迭代中的成本列表 theta 值。代码很简单。请检查这里。</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="2e0d" class="mp mq jj nv b gy nz oa l ob oc">def gradient_descent(theta, X, y, epoch, alpha):<br/>    cost = []<br/>    theta_hist = []<br/>    i = 0<br/>    while i &lt; epoch:<br/>        hx = hypothesis(theta, X)<br/>        theta[0] -= alpha*(sum(hx-y)/m)<br/>        theta[1] -= (alpha * np.sum((hx - y) * X))/m<br/>        cost.append(cost_calc(theta, X, y))<br/>        i += 1<br/>    return theta, cost</span></pre><p id="bc8b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">完成了线性回归算法。我们需要一种方法来预测产量。在预测方法中，我们将使用来自梯度下降函数和假设函数的最终θ来进行预测。</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="c3c3" class="mp mq jj nv b gy nz oa l ob oc">def predict(theta, X, y, epoch, alpha):<br/>    theta, cost = gradient_descent(theta, X, y, epoch, alpha)<br/>    return hypothesis(theta, X), cost, theta</span></pre><p id="f290" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，将参数初始化为零，并使用预测函数来预测输出变量。</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="82b4" class="mp mq jj nv b gy nz oa l ob oc">theta = [0,0]<br/>y_predict, cost, theta = predict(theta, df[0], y[0], 1400, 0.001)</span></pre><p id="1572" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更新后的θ值为:[10.724868115832654，0.3294833798797125]</p><p id="e898" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，将预测输出(h)和原始输出(y)与 df 或 X 绘制在同一个图中。</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="46b6" class="mp mq jj nv b gy nz oa l ob oc">plt.figure()<br/>plt.scatter(df, y)<br/>plt.scatter(df, y_predict)</span></pre><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/0a518eb37f19cf39089999b170755c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/0*MQEmc5moiVfjtLDj.png"/></div></figure><p id="6e92" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看起来算法运行良好。预测的输出线从中间位置开始。</p><blockquote class="og"><p id="198f" class="oh oi jj bd oj ok ol om on oo op lt dk translated">是时候开发学习曲线了！！！</p></blockquote><h2 id="9e35" class="mp mq jj bd mr ms oz dn mu mv pa dp mx lh pb mz na ll pc nc nd lp pd nf ng nh bi translated">画一条学习曲线</h2><p id="f5de" class="pw-post-body-paragraph ky kz jj la b lb ni kk ld le nj kn lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">现在，我们可以画一条学习曲线。首先，让我们为交叉验证数据集导入 X 和 y 值。正如我前面提到的，我们将它们组织在单独的 Excel 表格中。</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="7dc3" class="mp mq jj nv b gy nz oa l ob oc">file = pd.ExcelFile('dataset.xlsx')<br/>cross_val = pd.read_excel(file, 'X', header=None)<br/>cross_val.head()</span></pre><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi od"><img src="../Images/69647eba8901501e9ac69200a881b1cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:202/format:webp/0*arBUr40hSTiGX9_b.png"/></div></figure><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="b59a" class="mp mq jj nv b gy nz oa l ob oc">cross_y = pd.read_excel(file, 'y', header=None)<br/>cross_y.head()</span></pre><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/dddd6a9344311830b3ec71e865f6f897.png" data-original-src="https://miro.medium.com/v2/resize:fit:194/format:webp/0*SDd2Fv8imqls80G3.png"/></div></figure><p id="a6a9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为此，我想稍微修改一下 gradient_descent 函数。</p><p id="23f2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在之前的 gradient_descent 函数中，我们计算了每次迭代的成本。我这样做是因为在传统的机器学习算法开发中，这是一个很好的实践。</p><p id="63df" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是对于学习曲线，我们不需要每次迭代的成本。因此，为了节省运行时间，我将排除在每个时期计算成本函数。我们将只返回更新的参数。</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="e881" class="mp mq jj nv b gy nz oa l ob oc">def grad_descent(theta, X, y, epoch, alpha):<br/>    i = 0<br/>    while i &lt; epoch:<br/>        hx = hypothesis(theta, X)<br/>        theta[0] -= alpha*(sum(hx-y)/m)<br/>        theta[1] -= (alpha * np.sum((hx - y) * X))/m<br/>        i += 1<br/>    return theta</span></pre><p id="c721" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我前面所讨论的，为了开发学习曲线，我们需要用不同的训练数据子集来训练学习算法。</p><p id="9a7d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们的训练数据集中，我们有 21 个数据。我将只使用一个数据来训练算法，然后使用两个数据，然后使用三个数据，直到 21 个数据。</p><p id="22cf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们将在训练数据的 21 个子集上训练算法 21 次。我们还将跟踪每个训练数据子集的成本函数。请仔细看看代码，会更清楚。</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="6932" class="mp mq jj nv b gy nz oa l ob oc">j_tr = []<br/>theta_list = []<br/>for i in range(0, len(df)):<br/>    theta = [0,0]<br/>    theta_list.append(grad_descent(theta, df[0][:i], y[0][:i], 1400, 0.001))<br/>    j_tr.append(cost_calc(theta, df[0][:i], y[0][:i]))<br/>theta_list</span></pre><p id="7b49" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是每个训练数据子集的训练参数:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/93e356a840d68134b0907c9b78d2d827.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/0*ZXFV979TtvXIXkXd.png"/></div></figure><p id="06e9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是每个培训子集的成本:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/96d6d5ce3d1265bb77d2a49a96831e6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/0*kGviYx0c7Dl4jDGb.png"/></div></figure><p id="e04c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">查看每个子集的成本。当训练数据只有 1 个或 2 个时，成本为零或几乎为零。随着我们不断增加训练数据，成本也在增加，这是意料之中的。</p><p id="2649" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，对所有训练数据子集使用上述参数来计算交叉验证数据的成本:</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="2aee" class="mp mq jj nv b gy nz oa l ob oc">j_val = []<br/>for i in theta_list:  <br/>    j_val.append(cost_calc(i, cross_val[0], cross_y[0]))<br/>j_val</span></pre><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/6687150242fba5f2532d5e2c2d2bef7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/format:webp/0*D5uPZKADI8q03D_G.png"/></div></figure><p id="9b55" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一开始，成本确实很高，因为训练参数来自太少的训练数据。但是随着更多训练数据参数的改善，交叉验证误差持续下降。</p><p id="2d75" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们在同一个图中绘制训练误差和交叉验证误差:</p><pre class="no np nq nr gt nu nv nw nx aw ny bi"><span id="22d7" class="mp mq jj nv b gy nz oa l ob oc">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>plt.figure()<br/>plt.scatter(range(0, 21), j_tr)<br/>plt.scatter(range(0, 21), j_val)</span></pre><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/6d96d3308157e34ddf9b5282377f6e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/0*a1AOciU3ljeORmUM.png"/></div></figure><p id="bb88" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是我们的学习曲线。</p><h2 id="f01a" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lh my mz na ll nb nc nd lp ne nf ng nh bi translated">从学习曲线中得出决策</h2><p id="55fc" class="pw-post-body-paragraph ky kz jj la b lb ni kk ld le nj kn lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">上面的学习曲线看起来不错。它正按照我们预期的方式流动。刚开始的时候，训练误差太小，验证误差太高。</p><p id="a817" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">慢慢地，他们彼此完全重叠。所以那是完美的！但在现实生活中，这种情况并不经常发生。</p><p id="2aa8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">大多数机器学习算法第一次并不完美。几乎每时每刻都有一些我们需要解决的问题。在这里我将讨论一些问题。</p><p id="7bd7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可能会发现我们的学习曲线是这样的:</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/f36c79ce1975cbb2c3678dc52aa8eaa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/0*mHGIYQiOaEdOYbUQ.png"/></div></figure><p id="d822" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果训练误差和验证误差之间存在显著的差距，则表明存在高方差问题。这也可以被称为过度拟合问题。</p><blockquote class="og"><p id="c464" class="oh oi jj bd oj ok ol om on oo op lt dk translated">获取更多的训练数据或选择更小的特征集，或者两者兼有，可能会解决此问题。</p></blockquote><figure class="pl pm pn po pp iv gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/3bc3e1a94ee3192d3275e495b8abfe02.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/0*qQhEdhQ1tGUMwspG.png"/></div></figure><p id="3d55" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果一个学习曲线看起来像这样，这意味着在开始的训练误差太小，验证误差太高。慢慢地，训练误差变高，验证误差变低。但是在某一点上它们变得平行。<strong class="la jk">从图中可以看到，在一个点之后，即使有更多的训练数据交叉验证误差也不会再下降了。</strong></p><p id="ee20" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这种情况下，获得更多的训练数据并不会改善机器学习算法。</p><blockquote class="og"><p id="16cd" class="oh oi jj bd oj ok ol om on oo op lt dk translated">这表明学习算法正遭受高偏差问题。在这种情况下，获得更多的培训功能可能会有所帮助。</p></blockquote><h2 id="e272" class="mp mq jj bd mr ms oz dn mu mv pa dp mx lh pb mz na ll pc nc nd lp pd nf ng nh bi translated">修复学习算法</h2><p id="8df1" class="pw-post-body-paragraph ky kz jj la b lb ni kk ld le nj kn lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">假设，我们正在实现线性回归。但是算法并没有像预期的那样工作。</p><blockquote class="lu lv lw"><p id="81c5" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">做什么？</strong></p></blockquote><p id="91b3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，像我在这里演示的那样画一条学习曲线。</p><ol class=""><li id="7f50" class="mb mc jj la b lb lc le lf lh md ll me lp mf lt mg mh mi mj bi translated"><strong class="la jk">如果您检测到一个高方差问题</strong>，根据特性的重要性选择一个较小的特性集。如果那有帮助，那将节省一些时间。如果没有，尝试获取更多的训练数据。</li><li id="ea17" class="mb mc jj la b lb mk le ml lh mm ll mn lp mo lt mg mh mi mj bi translated"><strong class="la jk">如果您从学习曲线中发现高偏差问题</strong>，您已经知道获得额外功能是一个可能的解决方案。您甚至可以尝试添加一些多项式特征。大量的时间有助于节省大量的时间。</li><li id="3a26" class="mb mc jj la b lb mk le ml lh mm ll mn lp mo lt mg mh mi mj bi translated">如果你正在实现一个带有正则项λ的算法，如果该算法正遭受高偏差，<strong class="la jk">尝试减少λ</strong>，如果该算法正遭受高方差问题，<strong class="la jk">尝试增加λ</strong>。这里有一篇文章详细解释了正则项与偏差和方差的关系:</li></ol><div class="is it gp gr iu pq"><a rel="noopener follow" target="_blank" href="/how-to-improve-a-machine-learning-algorithm-regularization-144a6697c2be"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd jk gy z fp pv fr fs pw fu fw ji bi translated">如何改进机器学习算法:正则化</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">本文解释了机器学习算法性能差的原因以及如何改进它。</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">towardsdatascience.com</p></div></div><div class="pz l"><div class="qa l qb qc qd pz qe ja pq"/></div></div></a></div><blockquote class="lu lv lw"><p id="ad1b" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">在神经网络的情况下，我们也可能会遇到这种偏差或方差问题。</strong></p></blockquote><p id="6448" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于高偏差或欠拟合问题，我们需要增加神经元的数量或隐藏层的数量。为了解决高方差或过拟合问题，我们应该减少神经元的数量或隐藏层的数量。我们甚至可以使用不同数量的神经元来绘制学习曲线。</p><p id="e12a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">非常感谢您阅读这篇文章。我希望这有所帮助。</p><h2 id="aaf2" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lh my mz na ll nb nc nd lp ne nf ng nh bi translated">更多阅读:</h2><p id="e081" class="pw-post-body-paragraph ky kz jj la b lb ni kk ld le nj kn lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">在这个页面中，你会找到几个非常流行的机器学习算法的教程链接:</p><div class="is it gp gr iu pq"><a rel="noopener follow" target="_blank" href="/k-mean-clustering-algorithm-from-scratch-in-python-and-dimensional-reduction-step-by-step-guide-9ebabe5ca433"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd jk gy z fp pv fr fs pw fu fw ji bi translated">Python 中从头开始的 k 均值聚类算法:分步指南</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">并学习使用它来降低图像的维数</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">towardsdatascience.com</p></div></div><div class="pz l"><div class="qf l qb qc qd pz qe ja pq"/></div></div></a></div><div class="is it gp gr iu pq"><a rel="noopener follow" target="_blank" href="/your-everyday-cheatsheet-for-pythons-matplotlib-c03345ca390d"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd jk gy z fp pv fr fs pw fu fw ji bi translated">Python Matplotlib 的日常备忘单</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">完整的可视化课程</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">towardsdatascience.com</p></div></div><div class="pz l"><div class="qg l qb qc qd pz qe ja pq"/></div></div></a></div><div class="is it gp gr iu pq"><a rel="noopener follow" target="_blank" href="/multiclass-classification-algorithm-from-scratch-with-a-project-in-python-step-by-step-guide-485a83c79992"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd jk gy z fp pv fr fs pw fu fw ji bi translated">使用 Python 从零开始的多类分类算法:分步指南</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">本文介绍两种方法:梯度下降法和优化函数法</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">towardsdatascience.com</p></div></div><div class="pz l"><div class="qh l qb qc qd pz qe ja pq"/></div></div></a></div><div class="is it gp gr iu pq"><a rel="noopener follow" target="_blank" href="/a-complete-understanding-of-precision-recall-and-f-score-concepts-23dc44defef6"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd jk gy z fp pv fr fs pw fu fw ji bi translated">完全理解精确度、召回率和 F 分数的概念</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">机器学习中如何处理倾斜数据集</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">towardsdatascience.com</p></div></div><div class="pz l"><div class="qi l qb qc qd pz qe ja pq"/></div></div></a></div><div class="is it gp gr iu pq"><a rel="noopener follow" target="_blank" href="/a-complete-guide-to-hypothesis-testing-in-python-6c34c855af5c"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd jk gy z fp pv fr fs pw fu fw ji bi translated">数据科学家假设检验完全指南，Python 示例</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">用样本研究问题、解决步骤和完整代码清楚地解释</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">towardsdatascience.com</p></div></div><div class="pz l"><div class="qj l qb qc qd pz qe ja pq"/></div></div></a></div><div class="is it gp gr iu pq"><a href="https://medium.com/towards-artificial-intelligence/similar-texts-search-in-python-with-a-few-lines-of-code-an-nlp-project-9ace2861d261" rel="noopener follow" target="_blank"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd jk gy z fp pv fr fs pw fu fw ji bi translated">用几行代码在 Python 中搜索相似的文本:一个 NLP 项目</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">使用 Python 中的计数矢量器和最近邻法查找类似的维基百科简介，这是一个简单而有用的…</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">medium.com</p></div></div><div class="pz l"><div class="qk l qb qc qd pz qe ja pq"/></div></div></a></div></div></div>    
</body>
</html>