<html>
<head>
<title>A Philosophical Quandary for Inductive Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">归纳机器学习的哲学困境</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-philosophical-quandary-for-inductive-learning-a4ffbd63c3d2?source=collection_archive---------33-----------------------#2020-04-04">https://towardsdatascience.com/a-philosophical-quandary-for-inductive-learning-a4ffbd63c3d2?source=collection_archive---------33-----------------------#2020-04-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6af5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们有什么理由认为未来会与过去相似？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cbe67cf3deb04364be84cc21d31d0fb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VFCr-z7jOIQB47z6"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@drew_beamer?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">德鲁·比默</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="aba2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">机器学习是基于归纳推理的。不像演绎推理，前提的真实性保证结论的真实性，通过归纳得出的结论不能保证是真实的。因此归纳推理本质上是概率性的。</p><p id="b1ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在分类的上下文中，我们使用过去收集的训练数据，并根据我们发现的模式推断未来。例如，如果90%的X档案的人在培训期间拖欠贷款，我们假设将来大约90%的人会拖欠贷款。我们可以使用一个独立的测试集来检查这个推断的有效性，并验证我们的推断跳转的准确性。这种推论相当简单。奥卡姆会为这把剃刀感到骄傲。</p><h2 id="3be2" class="me mf it bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">但是，什么能证明这种逻辑上的跳跃呢？</h2><p id="7d0d" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">从过去<em class="nc">观察到的事件</em>到未来<em class="nc">未观察到的事件</em>的这种跳跃，我们可以基于什么理由或原则？逻辑表明，支撑这种跳跃的一个自然原则是相信未来将与过去相似。大卫·休谟称这个重要的假设为“自然一致性原则”早在18世纪40年代，休谟就是第一个努力解决所谓的归纳问题的哲学家。然而，自那以后没有太大的变化。今天的哲学家仍然在努力为归纳推理提供逻辑证明。</p><h2 id="b320" class="me mf it bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">无圆感应？</h2><p id="5cf4" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">所以归纳推理的力量来自于自然的一致性。但是为什么要假设自然的一致性呢？我们如何为这个假设打基础？</p><p id="8b29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为在过去，过去与未来相似。但是等等，这个论证用归纳推理来证明归纳推理本身的有效性！<strong class="lb iu"> <em class="nc">我们用归纳法</em> </strong> <em class="nc">进行归纳推理的做法。</em>这明显是循环的。休谟得出了一个著名的结论，即我们没有好的方法来证明这种推理性的飞跃。没有充分的理由相信从真实(或概率)结论得出的归纳结论。你也可能猜到休谟对诸如<em class="nc">原因</em>和<em class="nc">结果</em>这样的“形而上学”概念持怀疑态度，但那是另一篇博文<em class="nc">。</em></p><h2 id="29ce" class="me mf it bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">自休谟以来，我们还没有走太远</h2><p id="fca8" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">科学哲学家韦斯利·萨蒙(Wesley Salmon)在1953年关于归纳问题的文章中总结道，“承认不合理和不合理的假设来处理[归纳]问题，就等于使科学方法成为一个信仰问题。”如果归纳的问题是基于一个信念的问题，那么这对机器学习，一套自动化归纳推理实践的巧妙方法意味着什么？机器学习的逻辑和科学基础也是基于信仰吗？或者可能有更深层次的逻辑原理来支撑我们对归纳推理的依赖？</p><h2 id="7596" class="me mf it bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">纳尔逊·古德曼对归纳法的挑战:格鲁的例子</h2><p id="0780" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">纳尔逊·古德曼在20世纪50年代写了一本简短但有影响力的书，名为<em class="nc">事实小说，并预测</em>。在书中，他给出了几个“谜语”，旨在突出归纳推理及其科学应用的一些逻辑问题。</p><p id="8afe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">古德曼想象存在一个被称为“grue”的谓词(我们可以归因于一个对象的属性)一个物体是灰色的，以防它在时间t之前是绿色的，之后是蓝色的。假设我们观察到，在过去，直到时间t，1000颗绿宝石是绿色的。然后，我们陈述，基于这一观察证据，一个假设，如“在未来所有的祖母绿将是绿色的。”</p><p id="9644" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尼尔森指出的有趣的事情是，我们的证据可以支持两个同样有效但相互矛盾的假设:未来所有的绿宝石都将是绿色的，未来所有的绿宝石都将是灰色的。哪个是正确的？从表面上看，纳尔逊之谜表明，我们可以想象任意数量的关于物体的归纳合理的假设，并且每一个都和其他假设一样有效。正如这个谜语巧妙地说明的那样，将科学知识建立在归纳推理的基础上可能终究不是一个明智的选择。</p><p id="08d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">古德曼对自己的谜题的解决方案是，建议我们更谨慎地对待我们赋予物体的谓词。他说，把谓语分成两类可能更有用:<em class="nc">可投射的</em>和<em class="nc">不可投射的</em>。对于描述对象，像green这样的谓词比像grue这样的谓词更“根深蒂固”，因此我们可以将grue视为不可投射谓词的一个例子。</p><h2 id="604f" class="me mf it bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">这对机器学习意味着什么？</h2><p id="f8b3" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">假设当我们谈论原子粒子、分子或像岩石和树木这样的可感知物体时，自然的均匀性似乎没有太大问题。鉴于我们过去对它们的经验，我们相当确定地把各种属性和特性投射到未来。<strong class="lb iu"> <em class="nc">但是这个原理在应用到人</em> </strong>身上时似乎明显被误导了。这很重要，因为记录的人的行为是机器学习的生命线，也称为<a class="ae ky" href="https://www.tandfonline.com/doi/abs/10.1080/08982112.2016.1210979?forwardService=showFullText&amp;tokenAccess=iSfsaj5Wg5WcyxJKvvJB&amp;tokenDomain=eprints&amp;doi=10.1080%2F08982112.2016.1210979&amp;doi=10.1080%2F08982112.2016.1210979&amp;journalCode=lqen20" rel="noopener ugc nofollow" target="_blank">行为大数据</a> (BBD)。如果没有BBD，我们在日常生活中经常收到的自动推荐将不再起作用。</p><p id="f51b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在另一篇名为<a class="ae ky" href="https://medium.com/@travisgreene_4579/dispelling-three-myths-about-machine-learning-personalization-7a256ab17f7d" rel="noopener">将人放回机器学习</a>的文章中写过一些围绕机器学习个性化的概念问题。基本上，我的观点是，如果我们真的希望推断一个人的偏好、需求、欲望和兴趣，我们需要考虑他们的社会和道德身份、自我叙述以及他们丰富的内心生活的其他方面。目前，曼梯·里没有办法做到这一点，哲学家们认为这无论如何都是不可能的，因为主观经验(我对疼痛的<em class="nc">感觉</em>)和客观物理事实(C纤维放电)之间存在<a class="ae ky" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0114.1983.tb00207.x" rel="noopener ugc nofollow" target="_blank"><em class="nc"/></a>的解释差距。</p><h2 id="ff88" class="me mf it bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">为什么归纳对机器学习个性化有问题(MLP)</h2><p id="979d" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">人们在道德上和社会上以非传递性、非线性的方式改变和成长。归纳推理不能很好地解释我们道德身份的这种突然的结构变化。当我们意识到对人的描述既有内在的(主观的)也有外在的(客观的)时，MLP遇到了进一步的问题。我在A、B、C阶段看到的自己可能是不同的。然而，从一个局外人的角度来看，如果A=B and B=C，那么通过传递性，我们可以假设A=C。但这在道德进步和发展的情况下不起作用。这尤其成问题，因为MLP表面上是通过利用我们观察到的行为来推断我们的兴趣、偏好和欲望。但是我们的兴趣、偏好和欲望只是我们共有的一系列道德价值观中的一小部分。当我们的道德价值观进化时，我们的兴趣、偏好和欲望也会进化。</p><p id="c111" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，对MLP来说，我们的价值观往往会以突然的、不可预测的方式改变，就像我们生活中发生重大事件或悲剧时一样。对预测科学来说，更困难的是道德进步似乎天生不可预测。回顾过去，道德进步——比如废除人类奴隶制——似乎是不可避免的。但是从过去的观点来看，道德实践似乎反映了基本的“自然法则”</p><h2 id="6f9d" class="me mf it bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">从这里去哪里？</h2><p id="ebc8" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">致力于推荐系统的研究人员已经开始理解归纳问题和自然一致性背后的假设。推荐系统现在经常在他们的预测中引入<a class="ae ky" href="https://dl.acm.org/doi/abs/10.1145/1864708.1864761" rel="noopener ugc nofollow" target="_blank">serendipity</a>——本质上是在预测中加入一种随机性元素，以避免相同内容或用户账户的推荐的陈旧循环。例如，<a class="ae ky" href="https://www.theverge.com/2019/11/25/20977734/instagram-ai-algorithm-explore-tab-machine-learning-method" rel="noopener ugc nofollow" target="_blank"> Instagram的Explore </a>就是这么做的。机缘巧合是反映个人道德成长的非线性和非传递性过程的第一小步。</p><p id="2214" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我也希望看到更多的社会科学家参与数据科学，特别是他们可能会利用他们的<em class="nc">定性</em>数据收集知识，为个性化预测和建议提供新的输入。在机器能够学会区分事件的客观记录和个人叙述之间的区别之前，真正的个性化将是一个白日梦。</p></div></div>    
</body>
</html>