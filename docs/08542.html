<html>
<head>
<title>NLP and Opinion Mining in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中的自然语言处理和观点挖掘</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-nlp-to-figure-out-what-people-really-think-e1d10d98e491?source=collection_archive---------20-----------------------#2020-06-21">https://towardsdatascience.com/using-nlp-to-figure-out-what-people-really-think-e1d10d98e491?source=collection_archive---------20-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d542" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Rayshard Brooks 枪击案的情感分析</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1ccc3674738f77bb54fc030460e7a206.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*40TPQYM1fb3GviR2"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/photos/T1u5YP4blL4" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="25ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将向您展示如何使用自然语言处理(NLP)和更具体的情感分析来了解人们对某个主题的真实感受。</p><h1 id="3899" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">背景</h1><p id="807d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我决定分析 Youtube 上与以下视频相关的评论:【https://www.youtube.com/watch?v=kuhhT_cBtFU】T2&amp;t = 5s。</p><p id="7306" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">美国有线电视新闻网(CNN)发布的视频显示了 2020 年 6 月 12 日亚特兰大一名警察开枪打死 Rayshard Brooks 的瞬间。Rayshard Brooks 因涉嫌酒后驾车被捕，并试图逃离警察。他设法偷了一把泰瑟枪，并试图在逃跑时用它射杀一名警察。然而，美国有线电视新闻网没有显示争吵的最后一部分(在另一台摄像机上捕捉到的)，但他们很快提到了它。</p><p id="bac3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我很想知道人们会对整个事件以及 CNN 遗漏部分事件做出什么样的反应。<strong class="lb iu">非常清楚，我不是在这里给出我的观点</strong>，我只是在分析关于这个事件的说法。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="05ba" class="lv lw it bd lx ly mz ma mb mc na me mf jz nb ka mh kc nc kd mj kf nd kg ml mm bi translated">获取数据</h1><p id="1bb1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我用 selenium 搜集了 Youtube 上的评论。我总共收集了 1460 条评论。下面这篇文章展示了我是如何做到的:<a class="ae ky" rel="noopener" target="_blank" href="/how-to-scrape-youtube-comments-with-python-61ff197115d4">https://towards data science . com/how-to-scrape-YouTube-comments-with-python-61ff 197115d 4</a></p><p id="bd99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据如下所示:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="5ab0" class="nj lw it nf b gy nk nl l nm nn">df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl no"><img src="../Images/8c65df178fa5c4f60d102299f2fa4698.png" data-original-src="https://miro.medium.com/v2/format:webp/1*vbJJ9gdBilpSn2HHfVPCmg.png"/></div></figure></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="08cd" class="lv lw it bd lx ly mz ma mb mc na me mf jz nb ka mh kc nc kd mj kf nd kg ml mm bi translated">清理数据</h1><p id="0cf2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这是任何 NLP 项目的重要组成部分。以下是用于清理文本的函数:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="c649" class="nj lw it nf b gy nk nl l nm nn"><strong class="nf iu">#Import packages<br/></strong>import pandas as pd<br/>import re, string<br/>import nltk<br/>from nltk.corpus import stopwords<br/>from nltk.stem import WordNetLemmatizer <br/>from textblob import TextBlob</span><span id="93ad" class="nj lw it nf b gy np nl l nm nn">sw = stopwords.words('english')</span><span id="4d0c" class="nj lw it nf b gy np nl l nm nn"><strong class="nf iu">#The function<br/></strong>def clean_text(text):</span><span id="dea6" class="nj lw it nf b gy np nl l nm nn">text = text.lower()<br/>    text = re.sub('@', '', text)<br/>    text = re.sub('\[.*?\]', '', text)<br/>    text = re.sub('https?://\S+|www\.\S+', '', text)<br/>    text = re.sub('&lt;.*?&gt;+', '', text)<br/>    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)<br/>    text = re.sub('\n', '', text)<br/>    text = re.sub('\w*\d\w*', '', text)<br/>    text = re.sub(r"[^a-zA-Z ]+", "", text)<br/>    <br/><strong class="nf iu">    #Tokenize the data<br/></strong>    text = nltk.word_tokenize(text)<br/><strong class="nf iu">    #Remove stopwords<br/></strong>    text = [w for w in text if w not in sw]</span><span id="0392" class="nj lw it nf b gy np nl l nm nn">return text</span></pre><p id="b821" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该函数的作用如下:</p><ul class=""><li id="ce4a" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">删除所有大写字母、标点符号、表情符号、链接等。基本上，去掉所有不是单词或数字的东西。</li><li id="1b70" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">将数据符号化成单词，这意味着将每个注释分解成一组单独的单词。</li><li id="0e26" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">删除所有停用词，这些词不会给评论增加价值，比如“the”、“a”、“and”等。</li></ul><p id="4cf2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们将函数应用于数据:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="00f0" class="nj lw it nf b gy nk nl l nm nn">df['comment'] = df['comment'].apply(lambda x: clean_text(x))</span></pre><h2 id="557f" class="nj lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">词汇化</h2><p id="d9b2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我决定对文本进行词汇化，这是将一个单词的屈折形式组合在一起的过程，这样它们就可以作为一个单独的项目进行分析，因为它们有相似的意思(walking 变成 walk，officers 变成 officer，等等)。).</p><p id="e4e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">nltk。WordNetLemmatizer()函数就是这样做的。代码如下:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="1e5e" class="nj lw it nf b gy nk nl l nm nn"><strong class="nf iu">#Lemmatizer<br/></strong>lemmatizer = WordNetLemmatizer()</span><span id="b3a6" class="nj lw it nf b gy np nl l nm nn">def lem(text):<br/>    text = [lemmatizer.lemmatize(t) for t in text]<br/>    text = [lemmatizer.lemmatize(t, 'v') for t in text]<br/>    return text</span><span id="65fc" class="nj lw it nf b gy np nl l nm nn">df['comment'] = df['comment'].apply(lambda x: lem(x))</span></pre><p id="3634" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后我把数据里所有的空评论都去掉了(有些人只是评论表情符号，标点符号之类的东西)。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="fc93" class="nj lw it nf b gy nk nl l nm nn"><strong class="nf iu">#Remove all empty comments<br/></strong>empty_comment = df['comment'][1459]</span><span id="9b28" class="nj lw it nf b gy np nl l nm nn">for i in range(len(df)):<br/>    if df['comment'][i]==empty_comment:<br/>        df=df.drop(i)</span><span id="492b" class="nj lw it nf b gy np nl l nm nn">df=df.reset_index(drop=True)</span></pre><p id="699e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这留给我们 1441 条评论来分析。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="a481" class="lv lw it bd lx ly mz ma mb mc na me mf jz nb ka mh kc nc kd mj kf nd kg ml mm bi translated">分析数据</h1><h2 id="8484" class="nj lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">字频率</h2><p id="5fa3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">让我们使用 nltk 的 FreqDist 函数，从查看词频开始，也就是说，哪些词在评论中出现的频率最高。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="1d46" class="nj lw it nf b gy nk nl l nm nn"><strong class="nf iu">#From lists of comments to a single list containing all words      <br/></strong>all_words=[]        <br/>for i in range(len(df)):<br/>    all_words = all_words + df['comment'][i]</span><span id="b967" class="nj lw it nf b gy np nl l nm nn"><strong class="nf iu">#Get word frequency        <br/></strong>nlp_words = nltk.FreqDist(all_words)<br/>plot1 = nlp_words.plot(20, color='salmon', title='Word Frequency')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/f706f4433ab1ee49abd35dadd2f7de48.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*dl2XH-2sr3b4AfIHTp6lbw.png"/></div></figure><p id="2528" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这并不能让我们了解人们对这个视频的感受。不过，这里还是有一些值得一提的地方:</p><ul class=""><li id="d628" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">种族主义这个词被说了 17 次，种族主义这个词被说了 21 次，而残暴这个词只被说了 6 次。</li><li id="07aa" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">罪犯这个词被写了 40 次。</li></ul><p id="489e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们寻找最频繁的二元组，这意味着在评论中最频繁的相邻词对。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="21ec" class="nj lw it nf b gy nk nl l nm nn">#<strong class="nf iu">Bigrams</strong><br/>bigrm = list(nltk.bigrams(all_words))<br/>words_2 = nltk.FreqDist(bigrm)<br/>words_2.plot(20, color='salmon', title='Bigram Frequency')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/33a160e51dea87115c692abd13cc1e0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*FN9f-6_YbFxl9_gNSBurPw.png"/></div></figure><p id="14bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好吧，好吧，现在我们开始看到一些有趣的东西。“拒捕”这个词出现得最多。这里还大量提到了泰瑟枪(射泰瑟枪、拿泰瑟枪、警泰瑟枪等)，即使片段中没有显示显示雷夏德·布鲁克斯(Rayshard Brooks)发射泰瑟枪的视频。著名的“假新闻”也出现了差不多 30 次。</p><p id="8263" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是最受欢迎的三元模型图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/5c7d2b7d4c486f283944e2d6a0cb70da.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*OAlb7W6Gn0Y-7GA2IMwlew.png"/></div></figure><p id="0a09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我认为这个图表真正突出了人们的想法。很多假新闻和很多关于使用被盗泰瑟枪的报道。还提到了使用致命武力。</p><h2 id="45aa" class="nj lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">极性</h2><p id="4ad9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">使用 Textblob 的情感函数，我们可以查看评论的极性，这是一个介于-1 和 1 之间的浮点数，用于表示评论是正面(1)还是负面(-1)。例如，句子“Textblob 很棒”的极性为 0.4。</p><p id="1989" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是如何获得每个评论的极性以及所述极性的分布:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="1159" class="nj lw it nf b gy nk nl l nm nn"><strong class="nf iu">#Get sentiment from comments<br/></strong>df['comment'] = [str(thing) for thing in df['comment']]</span><span id="8fd2" class="nj lw it nf b gy np nl l nm nn">sentiment = []<br/>for i in range(len(df)):<br/>    blob = TextBlob(df['comment'][i])<br/>    for sentence in blob.sentences:<br/>        sentiment.append(sentence.sentiment.polarity)</span><span id="5ff5" class="nj lw it nf b gy np nl l nm nn">df['sentiment']=sentiment</span><span id="bf3e" class="nj lw it nf b gy np nl l nm nn"><strong class="nf iu">#Plot<br/></strong>df['sentiment'].plot.hist(color='salmon', title='Comments Polarity')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/ec24d4896f9df8d505a0e46cf71ea087.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*wYHyNbuA3IAbYnMJLzaH2w.png"/></div></figure><p id="dd9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">绝大多数评论被认为是相当中性的，平均评论的极性为-0.005。大约 75%的评论极性小于 0.06，意味着正面评论很少(我当然希望如此，毕竟是枪击案！).事实上，1441 条评论中只有 45 条的极性超过 0.5。</p><p id="58b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管如此，我认为可以从这一分析中得出以下几点结论:</p><ul class=""><li id="a70e" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">人们不喜欢 CNN 遗漏了 Rayshard Brooks 开枪的片段，称该视频和 CNN 经常是“假新闻”。</li><li id="5b76" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">Rayshard Brooks 的行为似乎在这里被负面地看待，许多人提到他酒后驾车，拒捕，试图逃跑并开枪。</li><li id="04de" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">视频观众似乎认为枪击发生的条件更“可接受”，这可以解释中性的极性。</li><li id="7d36" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">令人惊讶的是很少提及警察暴行或种族主义。</li></ul><p id="e66c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是了。我们设法了解了人们对 CNN 发布的视频和发生的事件的感受。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h2 id="3f93" class="nj lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">评论分类</h2><p id="8b65" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这种情况下，很难对评论进行分类(例如正面和负面)，因为我们不知道评论的“真实”类别。我们没有已知的标签来构建和评估一个简单的机器学习分类器。</p><p id="688c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，有标记文本数据的方法(手动、使用极性、使用正对负单词的计数等。)，我将在下一篇文章中介绍。但是请记住，如果我们不知道注释的真实类别，就永远不可能知道模型的真实性能。这也是 NLP 如此具有挑战性的原因之一！</p><p id="48a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢你的阅读！</p><p id="d5b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完整的代码可以在<a class="ae ky" href="https://github.com/francoisstamant/complete_NLP_project" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div></div>    
</body>
</html>