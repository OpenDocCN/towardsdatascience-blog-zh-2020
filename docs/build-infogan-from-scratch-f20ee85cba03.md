# 从头开始构建 InfoGAN

> 原文：<https://towardsdatascience.com/build-infogan-from-scratch-f20ee85cba03?source=collection_archive---------19----------------------->

## 了解 InfoGAN 并构建自己的 InfoGAN 网络，以生成特定功能的 MNIST 手写数字

![](img/d75b427bd69284a279c7f110d463b568.png)

图片来自论文“ *InfoGAN:通过信息最大化生成对抗网络的可解释表示学习”*

从上图中，你能看出哪些手写数字是机器合成的，哪些是人类做的吗？答案是:都是机器合成的！事实上，这张图片来自于一篇科学论文*“info gan:通过信息最大化生成对抗网络进行的可解释表征学习”*，其中作者开发了一个特殊的生成对抗网络，命名为 [InfoGAN(信息最大化生成对抗网络)](https://arxiv.org/abs/1606.03657)，并使用它来合成 MNIST 手写数字。如你所知，GANs 广泛用于合成新数据，尤其是图像。然而，普通 GANs 的一个缺点是我们无法控制 GANs 产生的图像。例如，一个被训练产生假的手写数字图像的 GAN 可能能够产生非常真实的手写数字图像，但是我们无法控制它产生哪个数字。 **InfoGAN 解决了这个问题:网络可以学习以无监督的方式产生具有特定分类特征(如数字 0 到 9)和连续特征(如数字的旋转角度)的图像。此外，由于学习是无监督的，它能够发现隐藏在图像中的模式，并生成遵循这些隐藏模式的图像。**有时候模特可以学到超乎你想象的非常有趣的模式(比如我的一个模特就学会了从 2 号过渡到 8 号。你以后会看到的！).在这本笔记本中，我将介绍 InfoGAN 如何实现对正在生成的图像的控制，以及如何从头构建一个 InfoGAN 来合成特定功能的 MNIST 手写数字，就像上面的图像一样。

# InfoGAN 的结构

一个正常的 GAN 有两个基本元素:一个接受随机噪声并产生假图像的发生器，以及一个接受假图像和真图像并识别图像是真是假的鉴别器。在训练过程中，如果鉴别器成功检测出生成的图像是假的，生成器就会受到“惩罚”。因此，生成器会学习产生与真实图像越来越相似的假图像来“愚弄”鉴别器。

在 InfoGAN 中，为了控制生成的图像类型，我们需要向生成器提供随机噪声之上的附加信息，并迫使它在制作假图像时使用这些信息。我们提供的附加信息应该与我们希望图像具有的特征类型相关。例如，如果我们想产生特定的 MNIST 数字，我们需要输入一个包含从 0 到 9 的整数的分类向量；如果我们想要产生具有不同旋转角度的 MNIST 数字，我们可能想要输入在-1 到 1 之间随机选择的浮点数。

输入额外的信息很容易，因为我们只需要向生成器模型添加额外的输入。但是我们如何确保生成器会使用这些信息，而不是完全忽略它呢？如果我们仍然简单地基于鉴别器的响应来训练生成器，则生成器不会使用附加信息，因为附加信息不会帮助生成器创建更真实的图像(它只对生成图像的特定特征有帮助)。因此，如果生成器不使用附加信息，我们需要对它施加额外的“惩罚”。一种方法是添加一个额外的网络(通常称为辅助网络，表示为 Q ),该网络获取假图像并再现我们输入到生成器中的额外信息。这样，生成器被迫使用附加信息，就好像它不使用一样，辅助网络没有办法正确地再现附加信息，并且生成器将被“惩罚”。下图总结了 GAN(左)和 InfoGAN(右)的结构。

> 注:在本文中，理论上应该通过最大化[互信息](https://en.wikipedia.org/wiki/Mutual_information)来训练生成器。然而，互信息实际上是无法计算的。因此，作者近似互信息，并且该近似变成附加信息和再现信息的输入之间的交叉熵(即，差)。如果你对互信息以及它是如何近似的感兴趣，可以去查一下[原创论文](https://arxiv.org/abs/1606.03657)，或者是 [Zak Jost](/infogan-generative-adversarial-networks-part-iii-380c0c6712cd) 和 [Jonathan Hui](https://medium.com/@jonathan_hui/gan-cgan-infogan-using-labels-to-improve-gan-8ba4de5f9c3d) 两篇非常好的 medium 文章。

![](img/6d238fc843122220d99f2ecbc98d1f70.png)

GAN(左)和 InfoGAN(右)的结构。作者图片

# 构建 InfoGAN

理解了 InfoGAN 的结构之后，让我们动手构建一个 InfoGAN 来生成特定于功能的 MNIST 数字！如上图所示，InfoGAN 包含三个模型:生成器(G)、鉴别器(D)和辅助模型(Q)。生成器的输入包括三个部分:大小为 62 的噪声向量、大小为 10 的分类向量(表示 10 个数字)和大小为 1 的连续向量。噪声向量通过正态分布生成，分类向量通过从 0 到 9 选取一个整数生成，连续向量通过从-1 到 1 选取一个浮点值生成。

InfoGAN 中的发生器与普通 GAN 中的发生器具有完全相同的结构。它首先包含两个完全连接的层，以将输入形状扩展到 6272 个单元。然后，6272 个单元被改造成 128 个 7×7 层。之后，经过整形的图层通过三个转置卷积层进行处理，形成最终的 28x28 像素图像(如果你对转置卷积层不熟悉，我有一篇[文章解释它](/understand-transposed-convolutions-and-build-your-own-transposed-convolution-layer-from-scratch-4f5d97b2967))。

鉴别器也与普通 GANs 中的相同。它包含两个卷积层和两个全连接层。最后一个全连接层生成一个具有“sigmoid”激活函数的输出，以表示真实图像(1)或虚假图像(0)。

辅助模型共享来自鉴别器的所有层，除了最后一个完全连接的层，因此这两个模型被一起定义。辅助模型有两个额外的全连接层来标识附加信息。由于我们的生成器有两个额外的输入(一个分类向量和一个连续向量)，我们还需要来自辅助模型的两个不同的输出。因此，我设置了一个具有“softmax”激活函数的全连接层来标识分类输出，两个全连接层来表示高斯分布的*【mu】*(均值)和*【sigma】*(标准差):

![](img/19172207f6cbd6584fd1bc17670c0aab.png)

> 注意:由于我们的连续向量是从-1 和 1 之间的均匀分布中随机选择的浮点数，因此可以有无限多的浮点数可供选择。因此，要求辅助模型预测发电机取的确切数字是不实际的。相反，我们可以预测一个高斯分布，并要求模型最大化连续向量在分布中的可能性。

定义了这三个模型之后，我们就可以构建我们的 InfoGAN 网络了！我用 Keras 做网络建设:

我知道这是一个相当长的代码，所以让我们一步一步地消化它:

*   InfoGAN_Continuous 是一个 Keras 模型类，应该通过给定鉴别器、生成器、辅助模型、噪声向量的大小和分类向量的类的数量来初始化。
*   *compile* 函数编译 InfoGAN_Continuous 模型(对于我使用的三个优化器都是 Adam)。
*   *create_gen_input* 是我们之前定义的为发电机生成输入的函数。
*   *concat_inputs* 将三个输入向量(大小 62、大小 10、大小 1)连接成一个大小为 73 的向量。
*   *train_step* 函数定义了训练步骤。它只需要成批的真实图像。首先，通过鉴别半批真实图像和半批伪图像来训练鉴别器。鉴别器的损失是鉴别真实图像和虚假图像的损失的总和。权重通过基于损失的梯度下降算法来更新。然后，使用整批伪图像来训练生成器和辅助模型。辅助模型损失包含分类损失和连续损失。分类损失就是预测标签和输入分类向量之间的分类交叉熵；连续损失是连续矢量输入的高斯分布的负对数概率密度函数。[最小化负对数概率密度函数与最大化我们位于预测高斯分布](https://engineering.taboola.com/predicting-probability-distributions/)内的连续向量的概率是一样的，这就是我们想要的。发电机损耗包括来自鉴别器的损耗和来自辅助模型的损耗。通过这样做，生成器将学习生成具有更具体特征的更真实的图像。请注意，我们将鉴别器中的变量设置为不可训练，因为我们不想在训练生成器和辅助模型时修改鉴别器中的神经元。

现在，你只需要用几行代码来训练它！！！

# 结果

现在，让我们看看我从 InfoGAN 模型中得到的一些非常有趣的结果！

## 变化分类向量

首先，如果您更改分类向量输入，您可以生成不同的数字。但是，模型不会知道标签 0 对应数字 0！它只知道不同的标签对应不同的数字(相信我，我不知怎么用了一整天才意识到这一点。我一直以为我输了当喂养标签 0 为我生成数字 9)。

![](img/5bd77891764c086b1be005c161edd5b4.png)

作者图片

因此，您可能需要重新排列标签:

![](img/ed2d3f2c23d5639ddcf8e94eb5156b2d.png)

作者图片

## 变化连续向量

改变连续向量可以产生不同形状的相同数字。例如，对于数字 1，当增加连续向量值时，数字以顺时针方向旋转。请注意，即使我们使用从-1 到 1 的值来训练模型，通过输入-1.5 和 1.5，我们仍然可以获得有意义的结果！

> 请注意，标签与上面的不同。这是因为我再次训练了模型，模型总是随机地将标签与数字相关联。

![](img/cd012ac20a2b0fe799c4d15d5883bb68.png)

作者图片

5 号更有趣。似乎模型试图旋转数字，但由于其形状更复杂，数字被剪切。

![](img/a47875d17e3dcc8ba545edeadf830540.png)

作者图片

## 增加体重以持续减肥

您可能会注意到，在将连续损耗添加到发电机总损耗和辅助设备总损耗时，我将连续损耗的比率设置为 0.1。这是为了避免混淆模型。如果连续损失与分类损失具有相似的比率(即接近 1)，则模型会将其视为确定数字类型的另一个因素。例如，下面的图像是在我使用 0.5 的比率时生成的:

![](img/58bee734fc54ad53099adc1c125e5cf2.png)

作者图片

![](img/2f208dd4a50fbd3dd3d98e72ccb209d1.png)

作者图片

如你所见，即使我使用相同的标签，通过改变连续向量值，数字逐渐从 2 变为 4，或者 2 变为 8！这也意味着计算机实际上可以找到数字 2 到数字 4，数字 2 到数字 8 之间的相似之处，并且知道如何从一个数字转换到另一个数字。是不是很神奇？

# 结论

InfoGAN 是一个非常强大的 GAN，它可以以无监督的方式在图像中学习模式，并通过遵循模式产生图像。玩起来也很有趣，因为你可以通过操作输入变量来生成各种各样的图像。使用本故事中的代码，您可以构建自己的 InfoGAN，看看您能制作出多么令人惊叹的图像！

# 参考资料:

陈曦、严端、雷因·胡特夫特、约翰·舒尔曼、伊利亚·苏茨基弗和彼得·阿比尔， [InfoGAN:通过信息最大化生成对抗网络的可解释表征学习](https://arxiv.org/abs/1606.03657) (2016)，康乃尔大学

[](https://engineering.taboola.com/predicting-probability-distributions/) [## 使用神经网络预测概率分布

### Shaked 是 Taboola 的算法工程师，从事推荐系统的机器学习应用。他…

engineering.taboola.com](https://engineering.taboola.com/predicting-probability-distributions/) [](https://machinelearningmastery.com/how-to-develop-an-information-maximizing-generative-adversarial-network-infogan-in-keras/) [## 如何开发 Keras 中的信息最大化 GAN(info GAN)——机器学习掌握

### 生成对抗网络，或 GAN，是一种用于训练深度卷积模型的架构，用于生成…

machinelearningmastery.com](https://machinelearningmastery.com/how-to-develop-an-information-maximizing-generative-adversarial-network-infogan-in-keras/)