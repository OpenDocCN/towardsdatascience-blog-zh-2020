<html>
<head>
<title>GPT-3 Explained in Under 3Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GPT 3 号在不到 3 分钟的时间内解释完毕</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gpt-3-explained-in-under-2-minutes-9c977ccb172f?source=collection_archive---------11-----------------------#2020-07-22">https://towardsdatascience.com/gpt-3-explained-in-under-2-minutes-9c977ccb172f?source=collection_archive---------11-----------------------#2020-07-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/557e2eaaacbc78ac3543b91f12307824.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CYs8aMPaXjzseeZ-FHkC8Q.png"/></div></div></figure><div class=""/><p id="43e3" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所以，你已经在 Twitter 上看到了一些令人惊叹的 GPT-3 演示(机器制作的专栏、诗歌、文章，甚至工作代码)。但是在这个不可思议的模型下到底发生了什么呢？下面是(简介！)往里面看。</p><figure class="kw kx ky kz gt is"><div class="bz fp l di"><div class="la lb l"/></div></figure><figure class="kw kx ky kz gt is"><div class="bz fp l di"><div class="la lb l"/></div></figure><figure class="kw kx ky kz gt is"><div class="bz fp l di"><div class="la lb l"/></div></figure><p id="ee46" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">GPT 3 是一个神经网络驱动的语言模型。<a class="ae lc" rel="noopener" target="_blank" href="/language-modeling-c1cf7b983685">语言模型</a>是预测一个句子在世界上存在的可能性的模型。例如，语言模型可以将句子“我带我的狗去散步”标记为比句子“我带我的香蕉去散步”更可能存在(即在互联网上)这不仅适用于短语，也适用于句子，更普遍的是，适用于任何字符序列。</p><p id="1b52" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">像大多数语言模型一样，GPT-3 在未标记的文本数据集上进行优雅的训练(在这种情况下，<a class="ae lc" href="https://commoncrawl.org/" rel="noopener ugc nofollow" target="_blank">普通爬行</a>)。单词或短语从文本中随机删除，模型必须学会仅使用周围的单词作为上下文来填充它们。这是一个简单的训练任务，可以产生一个强大的通用模型。</p><p id="0116" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">GPT-3 模型架构本身是一个基于<a class="ae lc" rel="noopener" target="_blank" href="/https-medium-com-chaturangarajapakshe-text-classification-with-transformer-models-d370944b50ca">变压器的</a>神经网络。这种架构在大约 2-3 年前开始流行，并且是流行的 NLP 模型<a class="ae lc" rel="noopener" target="_blank" href="/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270"> BERT </a>的基础。从建筑的角度来看，GPT 3 实际上并不新颖！那么是什么让它如此特别和神奇呢？</p><p id="6e1b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">真的很大。我是说<em class="ld">真的</em>大。它有 1750 亿个参数，是有史以来最大的语言模型(GPT 2 号只有 1.5 个参数！)，并在任何语言模型的最大数据集上进行训练。这似乎是 GPT 3 号如此令人印象深刻的主要原因。</p><p id="936a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">神奇的是。因此，GPT-3 可以做任何其他型号都做不到(很好):执行*特定*任务，无需任何特殊调整。你可以让 GPT-3 成为一名翻译、程序员、诗人或著名作家，它可以用不到 10 个训练例子来做到这一点。<em class="ld">该死的</em>。</p><p id="dec9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">大多数其他模型(比如 BERT)需要一个精心的微调步骤，你收集<em class="ld">成千上万</em>的(比如)法英句子对的例子，教它如何翻译。有了 GPT-3，你不需要做微调的步骤。这是它的核心。这就是让人们对《GPT 3:没有训练数据的定制语言任务》感到兴奋的原因。</p><p id="27a5" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">今天，GPT-3 是在私人测试，但男孩我不能等待得到它。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="08ff" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="ld">更多信息，请查看 daleonai.com 或在 Twitter 上关注@dalequark。</em></p></div></div>    
</body>
</html>