<html>
<head>
<title>Most Popular Convolutional Neural Networks Architectures</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最流行的卷积神经网络架构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-networks-most-common-architectures-6a2b5d22479d?source=collection_archive---------5-----------------------#2020-03-21">https://towardsdatascience.com/convolutional-neural-networks-most-common-architectures-6a2b5d22479d?source=collection_archive---------5-----------------------#2020-03-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="58d5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解它们的结构以及如何实现它们！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9d75b0a999c2c0a993fd3f1705945c63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*37GOHZIt0mpZuGJ9"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://unsplash.com/photos/41Wuv1xsmGM" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h1 id="ce50" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="ae2b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文的目的是深入探讨以下概念:</p><ul class=""><li id="a0f3" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">最流行的 CNN 架构</li><li id="355f" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">如何用 Keras 实现它们来进行图像分类</li></ul><h1 id="53c2" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">最常见的架构</h1><p id="cf64" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">有研究团队完全致力于为 CNN 开发深度学习架构，并在庞大的数据集中训练它们，所以我们将利用这一点，并使用它们，而不是每次面临新问题时都创建新的架构。</p><p id="4592" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">这将为我们提供稳定性和精确性。</p><p id="d1f5" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">目前 CNN 最常见的深度学习架构有:</p><ul class=""><li id="7ed9" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">VGG</li><li id="f617" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">雷斯内特</li><li id="8e50" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">开始</li><li id="fca0" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">例外</li></ul><p id="c73d" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">让我们来探索它们。</p><h2 id="d05a" class="ng la it bd lb nh ni dn lf nj nk dp lj ma nl nm ll me nn no ln mi np nq lp nr bi translated">VGG16 和 VGG19</h2><p id="ee98" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这种架构是最早出现的架构之一，由 Simonyan 和 Zisserman 在 2014 年发表的题为“用于大规模图像识别的非常深的卷积网络”的论文中介绍。本文可从这里获得:【https://arxiv.org/abs/1409.1556】T2。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/1aaf3005c42ca0c6b8159d3f2ad06d49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*ikyQTwVZ28mjvWwf6IavfQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分列的数字</p></figure><p id="3343" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">这是一种简单的架构，仅使用由递增数量的卷积层组成的块，具有 3×3 大小的滤波器。此外，为了减少获得的激活图的大小，最大池块被散布在卷积块之间，从而将这些激活图的大小减少一半。最后，使用一个分类块，由两个各有 4096 个神经元的密集层和最后一层(1000 个神经元的输出层)组成。</p><p id="d2e5" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">16 和 19 是指每个网络拥有的加权层数(卷积层和密集层，池层不计算在内)。它们对应于下表中的 D 列和 E 列。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/9ead36fb53ff8e2308e377685180b5cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*GMonWTZc8OxdFlo7muzW6w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图来自<a class="ae ky" href="http://very Deep Convoloutional Networks for Large-Scale Image Recognition" rel="noopener ugc nofollow" target="_blank"> wiki.math </a></p></figure><p id="8f1d" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">表中的其余架构都在那里，因为当时 Simonyan 和 Zisserman 很难训练他们的架构进行融合。由于他们无法做到这一点，他们想出的是先用更简单的架构训练网络，一旦这些网络收敛并被训练，他们就利用自己的权重来初始化下一个稍微复杂一点的网络，以此类推，直到他们到达 VGG19。这个过程被称为“预训练”。</p><p id="15c1" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">然而，这是在那些时候，现在它不再做，因为它需要太多的时间。现在我们可以使用 Xavier/Glorot 或 he 等人的初始化来实现同样的事情。</p><p id="4a76" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">然而，这个网络有几个缺点:</p><ul class=""><li id="4015" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">训练时间太长了</li><li id="b625" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">它有非常多的参数</li></ul><h2 id="0588" class="ng la it bd lb nh ni dn lf nj nk dp lj ma nl nm ll me nn no ln mi np nq lp nr bi translated">雷斯内特</h2><p id="dd5c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">由何等人在 2015 年开发的 ResNet 架构(你可以在这里看到他们名为“图像识别的深度剩余学习”的论文:<a class="ae ky" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">、</a>)是引入基于“模块”的奇异类型架构的里程碑，或者正如现在所知的，“网络中的网络”。</p><p id="dee2" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">这些网络引入了“剩余连接”的概念，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/eb6cef63a48eea5cb8f207734c9558da.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*-rlmqEAVIcU2dzOdLVl_Fw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分列的数字</p></figure><p id="a0d8" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">这些块允许到达先前激活图的层 l+1l+1 部分而无需修改，并且被属于层 L1 的块部分修改，正如你在上面的图像中所看到的。</p><p id="a6c1" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">2016 年，他们改进了这种架构，在这些残余块中加入了更多层，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/088aade0a6c3b9c809978fd59516d792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*xhHrrVuW2JwOv15phmH9qw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分列的数字</p></figure><p id="3943" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">ResNet 有各种不同的层数，但使用最多的是 ResNet50，它由 50 个带权重的层组成。</p><p id="bd7a" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">值得注意的是，虽然它的图层比 VGG 多得多，但它需要的内存却少得多，几乎只有原来的五分之一。这是因为该网络不是在分类阶段使用密集层，而是使用一种称为 GlobalAveragePooling 的层，它将特征提取阶段最后一层的 2D 活动图转换为 class 向量，用于计算属于每个类的概率。</p><h2 id="3408" class="ng la it bd lb nh ni dn lf nj nk dp lj ma nl nm ll me nn no ln mi np nq lp nr bi translated">盗梦空间 V3</h2><p id="cb72" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这种类型的架构是 2014 年由 Szegedy 等人在他们的论文“用卷积走得更深”(【https://arxiv.org/abs/1409.4842】)中介绍的，它使用带有不同大小滤波器的块，然后将这些块连接起来，以提取不同尺度的特征。看图片:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/e98eb60ed3c442b72b7e6796e54b8bdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*utbrBO53u93FwUkyi9QHOA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分列的数字</p></figure><p id="e428" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">为了帮助您理解这一点，inception 块的目标是使用 1x1、3x3 和 5x5 卷积计算激活图，以提取不同比例的特征。然后，您只需将所有这些激活映射连接成一个。</p><p id="0eed" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">这种体系结构需要的内存甚至比 VGG 和 ResNet 还要少。</p><h2 id="3274" class="ng la it bd lb nh ni dn lf nj nk dp lj ma nl nm ll me nn no ln mi np nq lp nr bi translated">例外</h2><p id="84b8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这种架构是由 Fran ois Chollet(Keras 的创造者)提出的，他给《盗梦空间》带来的唯一东西是他优化了回旋，使它们花费更少的时间。这是通过将 2D 卷积分成两个 1D 卷积来实现的。如果你有兴趣了解更多，这里有论文:《异常:深度学习与深度可分卷积》，【https://arxiv.org/abs/1610.02357】T4。</p><p id="50de" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">在内存方面，它与 Xception 非常相似，这是其架构的轮廓:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/d37cc7bb1ab83336355323d7277cd08a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*WcVPocviyJI2hiVJ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf" rel="noopener ugc nofollow" target="_blank">exception-Open Access Paper</a>的截图</p></figure><h2 id="6434" class="ng la it bd lb nh ni dn lf nj nk dp lj ma nl nm ll me nn no ln mi np nq lp nr bi translated">挤压网</h2><p id="df65" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这个网络非常轻(例如，与 VGG 的 500MB 或 Inception 的 100MB 相比，它的重量是 5MB ),并且使用 ImageNet 实现了大约 57%的 rank-1 或大约 80%的 rank-5 的准确性。</p><p id="8a06" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">rank-1 和 rank-5 或者 top-1 和 top-5 是什么意思？</p><ul class=""><li id="47d6" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">等级 1 精度:我们比较根据我们的网络具有最高概率的类是否匹配真实的标签</li><li id="2095" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">等级-5 准确度:我们比较根据我们的网络具有较高试用的 5 个类别中的一个是否与真实标签匹配</li></ul><p id="b52e" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">这个网络是如何做到占用空间如此之小却又如此精确的呢？它通过使用“压缩”数据然后扩展数据的体系结构来实现这一点，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/36a98e237f6e0ba73603c868c4d1e5b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ljVTtdlm9FdJjyj-3Duiw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分列的数字</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/000618a03a804676c44fb4ecd355ba78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*51ywjIR_MajQgGwjGVfMXg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分列的数字</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/7f76cc4ace6da33860e2629075f5b522.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4NTQME-7KGsR4xZ3hKAAxw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分列的数字</p></figure><p id="c65a" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">有无限的架构，但这些是目前使用最多的。通常，当我们遇到问题时，我们不会定义我们的架构，但我们会使用之前的一个架构。</p><p id="110d" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">好了，现在您已经看到了它们，让我们看看如何在 Keras 中实现它们</p><h2 id="697d" class="ng la it bd lb nh ni dn lf nj nk dp lj ma nl nm ll me nn no ln mi np nq lp nr bi translated">VGG，ResNet，Inception &amp; Xception Keras 实现</h2><p id="0530" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">像往常一样，我们会打开一个谷歌合作笔记本。选择在 GPU 上运行的代码，提高速度，执行下面的代码。</p><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="4846" class="ng la it oc b gy og oh l oi oj">!pip install imageio</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/2abd435bdc801323f94d1813e3a70a18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mMasepNP6RMemtO6Bz4sAg.png"/></div></div></figure><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="d06a" class="ng la it oc b gy og oh l oi oj"><strong class="oc iu"># Import the necessary libraries</strong><br/>from keras.applications import ResNet50<br/>from keras.applications import InceptionV3<br/>from keras.applications import Xception # solo con el backend de TensorFlow<br/>from keras.applications import VGG16<br/>from keras.applications import VGG19<br/>from keras.applications import imagenet_utils<br/>from keras.applications.inception_v3 import preprocess_input<br/>from keras.preprocessing.image import img_to_array<br/>from keras.preprocessing.image import load_img<br/>import numpy as np<br/>import urllib<br/>import cv2<br/>import matplotlib.pyplot as plt<br/>import imageio as io</span><span id="1a4b" class="ng la it oc b gy ol oh l oi oj">def predict_image(model_name, image_source):<br/>  <br/><strong class="oc iu">  # We define a dictionary that maps the network name with the Keras imported model</strong></span><span id="38cf" class="ng la it oc b gy ol oh l oi oj">  MODELS = {<br/>    "vgg16": VGG16,<br/>    "vgg19": VGG19,<br/>    "inception": InceptionV3,<br/>    "xception": Xception, # TensorFlow solo!<br/>    "resnet": ResNet50<br/>  }</span><span id="e3c8" class="ng la it oc b gy ol oh l oi oj"># <strong class="oc iu">We stablish the input size and image preprocessing function</strong><br/>  input_shape = (224, 224)<br/>  preprocess = imagenet_utils.preprocess_input</span><span id="41e3" class="ng la it oc b gy ol oh l oi oj"># <strong class="oc iu">If we use InceptionV3 or Xception, we need to stablish a different input image size (299x299) and use a different preprocessing function</strong><br/>  if model_name in ("inception", "xception"):<br/>    input_shape = (299, 299)<br/>    preprocess = preprocess_input</span><span id="d9bb" class="ng la it oc b gy ol oh l oi oj">print("[INFO] loading {}...".format(model_name))<br/>  Network = MODELS[model_name]<br/>  model = Network(weights="imagenet") <strong class="oc iu"># We load the network with the weights already trained with the ImageNet, the first time we execute keras it will lead the weights, which size is about 500MB, so it will last a bit<br/></strong></span><span id="6f5c" class="ng la it oc b gy ol oh l oi oj"># <strong class="oc iu">We load the image and make sure it is in the appropiate size</strong><br/>  print("[INFO] loading and pre-processing image...")<br/>  if type(image_source) == str:<br/>    image = load_img(image_source, target_size=input_shape)<br/>    image = np.resize(image, (input_shape[0], input_shape[1], 3))<br/>    image = img_to_array(image)<br/>  else:<br/>    image = np.resize(image_source, (input_shape[0], input_shape[1], 3))<br/>    image = img_to_array(image)</span><span id="2f8a" class="ng la it oc b gy ol oh l oi oj"># <strong class="oc iu">The image is represented as an array of size: (inputShape[0], inputShape[1], 3) and we need: (1, inputShape[0]. inputShape[1], 3), so we expand the dimensions</strong><br/>  image = np.expand_dims(image, axis=0)</span><span id="7343" class="ng la it oc b gy ol oh l oi oj"><strong class="oc iu"># we preprocess the image</strong><br/>  image = preprocess(image)</span><span id="f7f6" class="ng la it oc b gy ol oh l oi oj"><strong class="oc iu"># We predict the class of the image</strong><br/>  print("[INFO] classifying image with '{}'...".format(model_name))<br/>  preds = model.predict(image)<br/>  P = imagenet_utils.decode_predictions(preds)</span><span id="86d5" class="ng la it oc b gy ol oh l oi oj"><strong class="oc iu"># We show the predictions rank-5 and their likelihood</strong><br/>  for (i, (imagenetID, label, prob)) in enumerate(P[0]):<br/>    print("{}. {}: {:.2f}%".format(i + 1, label, prob * 100))</span><span id="4d68" class="ng la it oc b gy ol oh l oi oj">img = io.imread(image_source)<br/>  (imagenetID, label, prob) = P[0][0]<br/>  cv2.putText(img, "Label: {}, {:.2f}%".format(label, prob * 100), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)<br/>  plt.imshow(img)<br/>  plt.axis('off')<br/>  <br/>  return model</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/426ede2427d4cddb5ecbf9c59a7a9ac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OTDc7pY2X3hNmhGDEbtB-w.png"/></div></div></figure><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="ea6c" class="ng la it oc b gy og oh l oi oj"># download images<br/>!wget <a class="ae ky" href="https://image.ibb.co/cuw6pd/soccer_ball.jpg" rel="noopener ugc nofollow" target="_blank">https://image.ibb.co/cuw6pd/soccer_ball.jpg</a><br/>!wget <a class="ae ky" href="https://image.ibb.co/hdoVFJ/bmw.png" rel="noopener ugc nofollow" target="_blank">https://image.ibb.co/hdoVFJ/bmw.png</a><br/>!wget <a class="ae ky" href="https://image.ibb.co/h0B6pd/boat.png" rel="noopener ugc nofollow" target="_blank">https://image.ibb.co/h0B6pd/boat.png</a><br/>!wget <a class="ae ky" href="https://image.ibb.co/eCyVFJ/clint_eastwood.jpg" rel="noopener ugc nofollow" target="_blank">https://image.ibb.co/eCyVFJ/clint_eastwood.jpg</a></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/9b59ecaa796397284f7cc3ad5aadb103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*Y23dLgyQvwlzFxBBsl_kyQ.png"/></div></figure><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="095a" class="ng la it oc b gy og oh l oi oj">!ls -la *.*</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/fc91c92f797951be56b2d5029cefd7a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*98_dm1gx0FLvz4wimoRSDA.png"/></div></figure><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="3ff5" class="ng la it oc b gy og oh l oi oj">model = predict_image('resnet', 'soccer_ball.jpg')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/23ab0a7ad8c6ac4bc46a84c85c45cc36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8QwqADay-Kkura8iK4_XQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/fd572d66035a57fd951ed66e3922e3ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i4Xlu5lxdvzrJqR-sO6qQQ.png"/></div></div></figure><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="ab5f" class="ng la it oc b gy og oh l oi oj">model = predict_image('vgg16', 'bmw.png')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/f79ef062a14cb9d7cdc7b57450c2d961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vLKfj2Bnsqkk-1xOmI2-Xg.png"/></div></div></figure><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="b5a6" class="ng la it oc b gy og oh l oi oj">model.summary()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/7cc0b433c06b2621e3fe371c77970834.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*h2GLSmdfDlC9zW8jORenag.png"/></div></figure><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="c945" class="ng la it oc b gy og oh l oi oj">model = predidct_image('inception', 'clint_eastwood.jpg')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/956fe721b4b307752b88688aff133702.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HUYyZrkR5ldg_3nVo7MgPQ.png"/></div></div></figure><pre class="kj kk kl km gt ob oc od oe aw of bi"><span id="1e47" class="ng la it oc b gy og oh l oi oj">model.summary()</span></pre><p id="a6ef" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">网络架构的结果太大了，这里不适合:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/652c010c5a94b91fba8b54886d9722cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uOHs6TOB-KmW7X_NXskrPA.png"/></div></div></figure><h1 id="7eb1" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">最后的话</h1><p id="6afe" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一如既往，我希望你<strong class="lt iu"> </strong>喜欢这篇文章，并且获得了关于如何实现和开发卷积神经网络的直觉！</p><p id="3772" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><em class="ov">如果你喜欢这篇帖子，那么你可以看看我在数据科学和机器学习方面的其他帖子</em> <a class="ae ky" href="https://medium.com/@rromanss23" rel="noopener"> <em class="ov">这里</em> </a> <em class="ov">。</em></p><p id="d051" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated"><em class="ov">如果你想了解更多关于机器学习、数据科学和人工智能的知识</em> <strong class="lt iu"> <em class="ov">请在 Medium </em> </strong> <em class="ov">上关注我，敬请关注我的下一篇帖子！</em></p></div></div>    
</body>
</html>