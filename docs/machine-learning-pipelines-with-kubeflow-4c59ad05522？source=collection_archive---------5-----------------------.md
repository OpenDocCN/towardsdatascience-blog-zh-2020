# 使用 Kubeflow 的机器学习管道

> 原文：<https://towardsdatascience.com/machine-learning-pipelines-with-kubeflow-4c59ad05522?source=collection_archive---------5----------------------->

## 如何使用 Kubeflow 管道自动化机器学习工作流

## 为什么是机器学习管道？

现在，人们对机器学习管道的想法给予了很多关注，这意味着自动化和协调训练机器学习模型所涉及的各种步骤；然而，将机器学习工作流建模为自动化管道的好处并不总是很清楚。

当承担训练新的 ML 模型的任务时，大多数数据科学家和 ML 工程师可能会从开发一些新的 Python 脚本或交互式笔记本开始，这些脚本或笔记本执行必要的数据提取和预处理，以构建一组干净的数据来训练模型。然后，他们可能会创建几个额外的脚本或笔记本来尝试不同类型的模型或不同的机器学习框架。最后，他们将收集和探索指标，以评估每个模型在测试数据集上的表现，然后确定将哪个模型部署到生产环境中。

![](img/044e3caa6ba8dfaa87114236fe547e16.png)

人工机器学习工作流程。(图片由作者提供)

这显然是对真正的机器学习工作流的过度简化，但关键是这种通用方法需要大量的人工参与，并且除了最初开发它的工程师之外，任何人都无法重用或轻松重复。

我们可以使用机器学习管道来解决这些问题。我们可以将这个工作流程视为一系列独立的模块化步骤，每个步骤都专注于一个特定的任务，而不是将数据准备、模型训练、模型验证和模型部署视为针对我们正在工作的特定模型的单个代码库。

![](img/35b586b61cecfa069fc00d39b6b796c9.png)

机器学习管道。(图片由作者提供)

将我们的机器学习工作流建模为机器学习管道有许多好处:

*   **自动化**:通过消除人工干预的需要，我们可以安排我们的管道以特定的节奏重新训练模型，确保我们的模型适应训练数据随时间的漂移。
*   **重用**:由于管道的步骤与管道本身是分离的，我们可以很容易地在多个管道中重用单个步骤。
*   **可重复性** : 任何数据科学家或工程师都可以重新运行管道，然而，通过手动工作流，现在可能总是很清楚不同脚本或笔记本需要以什么顺序运行。
*   **环境的解耦**:通过保持机器学习流水线的步骤解耦，我们可以在不同类型的环境中运行不同的步骤。例如，一些数据准备步骤可能需要在大型机器集群上运行，而模型部署步骤可能在单台机器上运行。

如果你有兴趣深入研究机器学习管道及其优势，Google Cloud 有一篇很棒的文章，描述了更好、更自动化的实践(包括 ML 管道)的自然进展，团队可以采用它来完善他们的 ML 工作流: [MLOps:机器学习中的连续交付和自动化管道](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

## 什么是库伯流？

[Kubeflow](https://www.kubeflow.org/) 是一个基于 Kubernetes 的开源平台，旨在简化机器学习系统的开发和部署。在官方文档中被描述为 Kubernetes 的 ML 工具包，Kubeflow 由几个组件组成，跨越了机器学习开发生命周期的各个步骤。这些组件包括笔记本开发环境、超参数调优、功能管理、模型服务，当然还有机器学习管道。

![](img/1eb5fe196eda3ee5d40270ed43db3158.png)

Kubeflow 中央仪表盘。(图片由作者提供)

在本文中，我们将只关注 Kubeflow 的管道组件。

## 环境

为了运行示例管道，我使用了在裸机上运行的 Kubernetes 集群，但是您可以在安装了 Kubeflow 的任何 Kubernetes 集群上运行示例代码。

本地唯一需要的依赖项是 Kubeflow Pipelines SDK。您可以使用 pip 安装 SDK:

```
pip install kfp
```

## 库伯弗洛管道公司

Kubeflow 中的管道由一个或多个**组件**组成，它们代表管道中的各个步骤。每个组件都在自己的 Docker 容器中执行，这意味着管道中的每个步骤都可以有自己的依赖集，独立于其他组件。

对于我们开发的每个组件，我们将创建一个单独的 Docker 映像，它接受一些输入，执行一个操作，然后公开一些输出。我们还将有一个单独的 python 脚本，`pipeline.py`,它从每个 Docker 映像创建管道组件，然后使用这些组件构建一个管道。

我们将总共创建四个组件:

*   **预处理-数据** : 该组件将从`sklearn.datasets`加载波士顿住房数据集，然后将数据集拆分为训练集和测试集。
*   **train-model** :该组件将训练一个模型，使用波士顿住房数据集来预测波士顿房屋的中值。
*   **测试模型**:该组件将计算并输出测试数据集上模型的均方误差
*   **deploy-model** :在本文中，我们不会关注模型部署或服务，所以这个组件只会记录一条消息，说明它正在部署模型。在真实的场景中，这可能是将任何模型部署到 QA 或生产环境的通用组件。

![](img/44209bb91073b07dbeb8799a9d46254a.png)

ML 管道图视图。(图片由作者提供)

如果所有这些关于组件和 Docker 图像的讨论听起来令人困惑:不要担心，当我们进入代码时，它们应该会变得更有意义。

## 组件:预处理数据

我们管道中的第一个组件将使用`sklearn.datasets`加载波士顿住房数据集。我们将使用 Sci-kit learn 的`train_test_split`函数将这个数据集分成训练集和测试集，然后我们将使用`np.save`将我们的数据集保存到磁盘，以便它可以被后面的组件重用。

到目前为止，这只是一个简单的 Python 脚本。现在我们需要创建一个 Docker 映像来执行这个脚本。我们将编写一个 Dockerfile 文件来构建映像:

从`python:3.7-slim`基础映像开始，我们将使用`pip`安装必要的包，将预处理 Python 脚本从我们的本地机器复制到容器，然后将`preprocess.py`脚本指定为容器入口点，这意味着当容器启动时，它将执行我们的脚本。

## 建设管道

现在我们开始管道工程。首先，您需要确保我们上面定义的 Docker 映像可以从您的 Kubernetes 集群中访问。出于这个例子的目的，我使用了 [GitHub Actions](https://github.com/features/actions) 来构建图像并将其推送到 [Docker Hub](https://hub.docker.com/) 。

![](img/81de9277944c9286cfb8cac829b20b9a.png)

现在让我们定义一个组件。每个组件都被定义为一个返回类型为`ContainerOp`的对象的函数。这种类型来自我们之前安装的`kfp` SDK。下面是我们管道中第一个组件的组件定义:

注意，对于`image`参数，我们传递由上面的 Docker 文件定义的 Docker 图像的名称，对于`file_outputs`参数，我们指定由组件 Python 脚本保存到磁盘的四个`.npy`文件的文件路径。

通过将这四个文件指定为文件输出，我们使它们可用于管道中的其他组件。

**注意**:在我们的组件中硬编码文件路径并不是一个很好的做法，因为，正如你从上面的代码中看到的，这要求创建组件定义的人知道关于组件实现的具体细节(也就是包含在 Docker 映像中的实现)。让我们的组件接受文件路径作为命令行参数会干净得多。这样，定义组件的人可以完全控制输出文件的位置。我以这种方式对它进行了硬编码，希望可以更容易地看到所有这些部分是如何组合在一起的。

定义了第一个组件后，我们可以创建一个使用**预处理数据**组件的管道。

管道定义是一个用`@dsl.pipeline`注释修饰的 Python 函数。在函数中，我们可以像使用任何其他函数一样使用组件。

为了执行管道，我们创建一个`kfp.Client`对象并调用`create_run_from_pipeline_func`函数，传入定义管道的函数。

如果我们执行这个脚本，然后导航到 Kubeflow 中央仪表板的 Pipelines 部分中的 Experiments 视图，我们将看到我们的管道的执行。我们还可以通过在管道的图形视图中单击组件来查看来自**预处理数据**组件的四个文件输出。

![](img/71be73d4496adf015ae193ae68754f62.png)

Kubeflow 管道用户界面。(图片由作者提供)

因此，我们可以执行我们的管道，并在 GUI 中可视化它，但是只有一个步骤的管道并不那么令人兴奋。让我们创建剩余的组件。

## 剩余组件

对于 **train-model** 组件，我们将创建一个简单的 python 脚本，它使用 Sci-kit learn 训练一个回归模型。这应该类似于预处理组件的 python 脚本。最大的区别是，这里我们使用`argparse`接受训练数据的文件路径作为命令行参数。

同样，docker 文件与我们用于第一个组件的文件非常相似。我们从基本映像开始，安装必要的包，将 python 脚本复制到容器中，然后执行脚本。

另外两个组件**测试模型**和**部署模型**遵循相同的模式。事实上，它们与我们已经实现的两个组件非常相似，为了简洁起见，我不会在这里展示它们。如果你感兴趣，你可以在这个 GitHub 仓库中找到管道的所有代码:[https://github.com/gnovack/kubeflow-pipelines](https://github.com/gnovack/kubeflow-pipelines)

就像前面的**预处理-数据**组件一样，我们将从这三个组件中构建 Docker 映像，并将它们推送到 Docker Hub:

*   列车型号:**gnovack/Boston _ pipeline _ train**
*   测试模型:**gnovack/Boston _ pipeline _ test**
*   部署模型:**gnovack/Boston _ pipeline _ deploy**

## 完整的管道

现在是时候创建完整的机器学习管道了。

首先，我们将为**训练模型**、**测试模型**和**部署模型**组件创建组件定义。

**train-model** 组件的定义与之前的**预处理数据**组件的定义之间唯一的主要区别是 **train-model** 接受两个参数，`x_train`和`y_train`，这两个参数将作为命令行参数传递给容器，并将在使用`argparse`模块的组件实现中解析出来。

现在定义**测试模型**和**部署模型**组件:

定义了四个管道组件后，我们现在将重温前面的`boston_pipeline`函数，并一起使用我们所有的组件。

让我们来分解一下:

*   注意第 6 行的**，当我们调用`preprocess_op()`函数时，我们将函数的输出存储在一个名为`_preprocess_op`的变量中。为了访问**预处理数据**组件的输出，我们调用`_preprocess_op.outputs['NAME_OF_OUTPUT']`。**
*   默认情况下，当我们从一个组件访问`file_outputs`时，我们得到的是文件的内容而不是文件路径。在我们的例子中，由于这些不是纯文本文件，我们不能仅仅将文件内容作为命令行参数传递给组件 Docker 容器。为了访问文件路径，我们使用`dsl.InputArgumentPath()`并传入组件输出。

现在，如果我们从管道创建一个运行，并导航到 Kubeflow central 仪表板中的管道 UI，我们应该会看到管道图中显示的所有四个组件。

![](img/7b173c53ffcfd5bd20013567258a7830.png)

Kubeflow 管道用户界面。(图片由作者提供)

## 结论

在本文中，我们创建了一个非常简单的机器学习管道，它加载一些数据，训练一个模型，在维持数据集上评估它，然后“部署”它。通过使用 Kubeflow 管道，我们能够将工作流中的每个步骤封装到管道组件中，每个组件都运行在自己的、隔离的 Docker 容器环境中。

这种封装促进了我们的机器学习工作流中各步骤之间的松散耦合，并为在未来的管道中重用组件提供了可能性。例如，在我们的培训组件中没有任何东西是专门针对波士顿住房数据集的。我们可以在任何时候使用 Sci-kit learn 训练回归模型时重用这个组件。

我们只是触及了 Kubeflow 管道的表面，但是希望本文能帮助您理解组件的基础，以及我们如何一起使用它们来创建和执行管道。

如果您有兴趣探索本文中使用的全部代码库，您可以在 GitHub repo 中找到它们:[https://github.com/gnovack/kubeflow-pipelines](https://github.com/gnovack/kubeflow-pipelines)

**参考文献**

*   [https://kube flow-pipelines . readthedocs . io/en/latest/index . html](https://kubeflow-pipelines.readthedocs.io/en/latest/index.html)
*   [https://www . kube flow . org/docs/pipelines/SDK/build-component/](https://www.kubeflow.org/docs/pipelines/sdk/build-component/)
*   [MLOps:机器学习中的连续交付和自动化管道](https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

感谢阅读！如有任何问题或意见，请随时联系我们。