<html>
<head>
<title>Few-shot Learning with Prototypical Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于原型网络的少量学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/few-shot-learning-with-prototypical-networks-87949de03ccd?source=collection_archive---------21-----------------------#2020-06-24">https://towardsdatascience.com/few-shot-learning-with-prototypical-networks-87949de03ccd?source=collection_archive---------21-----------------------#2020-06-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="df42" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习在 Omniglot 数据集上编写少量学习算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6b698e435d45211c3f59e2f0dbe7b290.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fs0US-Ylk0hZyMTnuc3rbQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://unsplash.com/photos/kZO9xqmO_TA" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/kZO9xqmO_TA</a></p></figure><h1 id="557f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="e901" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们，人类，有能力识别一个类，只要给出这个类的几个例子。例如，一个孩子只需要两到三张兔子的图片就能从其他物种中认出这种动物。这种从有限数据中学习的能力超过了任何经典的机器学习算法。很多人认为人类正在被人工智能推翻，但事实是:为了能够很好地区分类别，一个分类器经常会收到每个类别数千张图像……而我们只需要两三张！</p><p id="129e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">原型网络(prototypic Networks)是由<a class="ae ky" href="https://arxiv.org/abs/1703.05175" rel="noopener ugc nofollow" target="_blank"> Snell 等人在 2017 年推出的一种算法(在“用于少数镜头学习的原型网络”)</a>中)，它解决了少数镜头学习范式。我们用一个例子一步步来理解。在本文中，我们的目标是对人物图像进行分类。<a class="ae ky" href="https://github.com/cnielly/prototypical-networks-omniglot" rel="noopener ugc nofollow" target="_blank">提供的代码是 PyTorch 格式的，可从这里获得。</a></p><h1 id="4f6e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Omniglot 数据集</h1><p id="cf80" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在少镜头学习中，我们被给定一个数据集，每个类只有很少的图像(通常是 1 到 10 个)。在本文中，我们将使用 Omniglot 数据集，该数据集包含从 50 个字母中收集的 1，623 个不同的手写字符。这个数据集可以在<a class="ae ky" href="https://github.com/brendenlake/omniglot/tree/master/python" rel="noopener ugc nofollow" target="_blank">这个 GitHub 库</a>中找到。我使用了“images_background.zip”和“images_evaluation.zip”文件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/fac4343744a519cebc85b06972404f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mKLrhQYX9eVkEWscMmS4xQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Omniglot 数据集中的字符示例</p></figure><p id="e130" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">正如官方文件中所建议的，执行数据扩充是为了增加类的数量。实际上，所有图像都旋转了 90 度、180 度和 270 度，每次旋转都会产生一个额外的类别。一旦执行了这种数据扩充，我们就有 1，623 * 4 = 6，492 个类。我将整个数据集分为一个训练集(4，200 个类别的图像)和一个测试集(2，292 个类别的图像)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h1 id="c971" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">选择一个样本</h1><p id="ecae" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了创建一个样本，Nc 类是从所有类中随机挑选出来的。对于每个类，我们有两组图像:大小为 Ns 的支持集和大小为 Nq 的查询集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/a5f92b4cdc809d9178622a7ba28e0ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L0pLhpSc7mVjfRkNDku60w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Nc 类的示例图，每个类都包含一个支持集和一个查询集</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h1 id="29b5" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">嵌入图像</h1><blockquote class="mw mx my"><p id="f407" class="lr ls mz lt b lu mn ju lw lx mo jx lz na mp mc md nb mq mg mh nc mr mk ml mm im bi translated">“我们的方法基于这样一种思想，即存在一种嵌入，其中点围绕每个类的单个原型表示聚集。”声明原始论文的作者。</p></blockquote><p id="3e1b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">换句话说，存在图像的数学表示，其中相同类别的图像聚集在称为簇的组中。在嵌入空间中工作的主要优点是，两个看起来相同的图像会彼此靠近，而两个完全不同的图像会远离。</p><p id="7be0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在我们的例子中，对于 Omniglot 数据集，嵌入块将(28x28x3)图像作为输入，并返回列 64 维点。image2vector 函数由 4 个模块组成。每个模块由一个卷积层、一个批量归一化、一个 ReLu 激活函数和一个 2x2 max 池层组成。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/21ad5b9219cd8bf43842fa47762244c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eG-1xJV6zvzgaEOtOJb3Fg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">image2vector 功能的 4 个模块</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h1 id="45bd" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">计算类原型</h1><p id="ff5f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这一步中，我们为每个集群计算一个原型。一旦支持图像被嵌入，向量被平均以形成一个类原型，该类的一种“代表”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/bf0ccb574c266be2ff9d6b5c51dc08d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/0*-ryFDHb0_egfko6n"/></div></figure><p id="7ee2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">其中 v(k)是类 k 的原型，f_phi 是嵌入函数，xi 是支持图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/c48388a3f5fbd9344b27e679f3d51e4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jbC6xkuRyZqLPOHpGVJz_g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">每个类计算一个原型</p></figure><h1 id="63cd" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">计算查询和原型之间的距离</h1><p id="bb4d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">该步骤包括对查询图像进行分类。为此，我们计算每个未标记图像和原型之间的距离。度量选择在这里是至关重要的，原型网络的发明者必须归功于他们对距离的选择:欧几里德距离。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="5638" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一旦计算出距离，就对它们执行 softmax 以获得属于每个类的概率。距离越短，概率越大。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h1 id="336c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">计算损耗和反向传播</h1><p id="49f6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">原型网络学习阶段通过最小化负对数概率进行，也称为 log-softmax 损失。使用对数的主要优点是，当模型无法预测正确的类别时，会大幅增加损失。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/d6698aeac6717c483063aa6bb724fc9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/0*9jtp7mLZnWSOU0AA"/></div></figure><p id="14d2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">反向传播通过随机梯度下降(SGD)来执行。</p><h1 id="a79e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">启动培训</h1><p id="38a9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">上面描述的整个序列构成了一集。训练阶段包含几集。我试图重现原始论文的结果。以下是训练设置:</p><ul class=""><li id="086d" class="ng nh it lt b lu mn lx mo ma ni me nj mi nk mm nl nm nn no bi translated">Nc: 60 类</li><li id="9c91" class="ng nh it lt b lu np lx nq ma nr me ns mi nt mm nl nm nn no bi translated">Ns: 1 或 5 个支持点/类</li><li id="ab4c" class="ng nh it lt b lu np lx nq ma nr me ns mi nt mm nl nm nn no bi translated">Nq: 5 个查询点/类</li><li id="6e2c" class="ng nh it lt b lu np lx nq ma nr me ns mi nt mm nl nm nn no bi translated">5 个时代</li><li id="2284" class="ng nh it lt b lu np lx nq ma nr me ns mi nt mm nl nm nn no bi translated">2000 集/时代</li><li id="8084" class="ng nh it lt b lu np lx nq ma nr me ns mi nt mm nl nm nn no bi translated">学习率最初为 0.001，并在每个时期除以 2</li></ul><p id="96a6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">训练进行了 30 分钟。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h1 id="4e1f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结果</h1><p id="1867" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一旦质子被训练，我们可以用新的数据来测试它。我们以类似的方式在测试集中选择样本。使用支持集来计算原型，然后根据到原型的较短距离来标记查询集的每个点。</p><p id="0087" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了测试，我尝试了 5 路和 20 路场景。与培训阶段相比，我获得了相同数量的支持和查询点。测试在 1000 集上进行。</p><p id="7f2d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">结果如下表所示。“5 路 1 投”就是 Nc = 5，Ns = 1。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/4344dad7d8e4eabe6d8dc3d74f51bb18.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*ShENEZZFqL0if3C9n-Q1rw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">获得的结果与论文结果</p></figure><p id="58c8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我获得了与原始论文相似的结果，在某些情况下稍好一些。这可能是由于论文中没有具体说明的采样策略。每集我都采用随机抽样。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><p id="9140" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我希望原型网络不再是你的秘密！我们能够从每个类仅有的几个例子中建立一个图像分类器。</p><p id="1e8a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">我的 GitHub 上有完整的代码:</strong>【https://github.com/cnielly/prototypical-networks-omniglot T2】</p></div></div>    
</body>
</html>