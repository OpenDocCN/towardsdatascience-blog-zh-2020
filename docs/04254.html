<html>
<head>
<title>Support Vector Machine for Cancer Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于癌症预测的支持向量机</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/intuitively-explain-svm-and-build-for-breast-cancer-classification-cc9e081b7d86?source=collection_archive---------43-----------------------#2020-04-17">https://towardsdatascience.com/intuitively-explain-svm-and-build-for-breast-cancer-classification-cc9e081b7d86?source=collection_archive---------43-----------------------#2020-04-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="001a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">支持向量机介绍及基于Sklearn的乳腺癌预测模型建立</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/69b4b6117f98e446041d720eb6887de5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3korNshe08gXjN4XeFeGTw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://unsplash.com/photos/L7en7Lb-Ovc" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>的细胞图像</p></figure><p id="8788" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将解释支持向量机(SVM)如何工作，并建立一个乳腺癌预测的SVM模型。全文分为以下六个部分。</p><ol class=""><li id="9dbc" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">SVM简介</li><li id="5578" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">问题陈述</li><li id="3f71" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">数据处理</li><li id="4510" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">模型拟合和评估</li><li id="5163" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">模型优化</li></ol><p id="5c5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们开始旅程🏃‍♂️🏃‍♀️.</p><ol class=""><li id="c116" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> SVM简介</strong></li></ol><p id="9127" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">支持向量机(SVM)最初在20世纪60年代开发，然后在20世纪90年代完善，在机器学习领域非常流行。它适用于可线性分离的数据，其中可以画线来分隔两个类别。SVM是如何运作的🤔？</p><p id="8518" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为简单起见，假设给出两列数据<em class="mj"> x1 </em>和<em class="mj"> x2 </em>。为了区分<em class="mj"> x1 </em>和<em class="mj"> x2 </em>，我们画了几条边界线，如图1所示。根据新数据的位置，这些线会产生不同的结果。但是如何决定哪条线是最好的分离呢🤔？SVM就是这么做的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/19dd2cebd17d07cea4f46552e4c551db.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*Kyy0oERRI0Q-y_PZ8RNnzQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1 SVM分类图(作者创建的Img)</p></figure><h2 id="9d9a" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">SVM通过最大边距搜索最佳边界，如图2所示。换句话说，为了使这条线成为SVM的结果，从支持向量到边界的两个距离之和必须最大化。因此，只有支持向量对SVM结果有贡献。从概念上讲，它是一个简单的算法。</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/0648a47c535da1e8ea43fa4b193be17e.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*r_ar3fqgBfjQuhmLJOrryA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2 SVM分类原则(作者创建的Img)</p></figure><p id="967e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为什么SVM与其他机器学习算法相比很特别？假设我们正在对水果进行分类:苹果或梨。大多数机器学习算法会看最像苹果的苹果，所以它知道苹果是什么。类似地，它试图通过查看梨的最典型特征来了解什么是梨，如图3所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/ebccfa7a77bc4a91ef65c44025412f5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*D_HB2w2m96zQsxXhJw6NKw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3应用/梨按普通ML分类(来自<a class="ae ky" href="https://pixabay.com/photos/search/" rel="noopener ugc nofollow" target="_blank"> pixabay </a>的水果图像)</p></figure><blockquote class="ng"><p id="ddd7" class="nh ni it bd nj nk nl nm nn no np lu dk translated">但对SVM来说，情况恰恰相反。如图4所示，SVM试图观察更像梨或非标准苹果的苹果，以及更像苹果的梨。这些最不典型的梨和苹果充当支持向量。通过观察极端案例，SVM旨在找到区分不同阶层的最佳分界线。</p></blockquote><figure class="nr ns nt nu nv kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/dc19f6fd99381d8529482b6fb5dd13d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*7Ovp2eRyYWFup2BuewZPRg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4 SVM对苹果/梨的分类(来自<a class="ae ky" href="https://pixabay.com/photos/search/" rel="noopener ugc nofollow" target="_blank"> pixabay </a>的水果图像)</p></figure><p id="5c93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<strong class="lb iu">问题陈述</strong></p><p id="e7ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">乳腺癌是全球女性中最常见的癌症，占所有癌症病例的25%。早期诊断可以大大增加存活的机会。关键的挑战是将肿瘤分为恶性0级或良性1级。</p><p id="52a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.<strong class="lb iu">数据处理</strong></p><p id="08b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的数据来自<em class="mj">UCI</em>机器学习库<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)" rel="noopener ugc nofollow" target="_blank">这里</a>。有569个癌症数据实例，其中212个是恶性的，357个是良性的。从癌症图像中提取了30个特征。</p><p id="0f33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，以<em class="mj">字典</em>的形式读入数据，并转换成带有“数据”和“目标”列的<em class="mj">数据帧</em>。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="b28b" class="ml mm it nx b gy ob oc l od oe">from sklearn.datasets import load_breast_cancer<br/>cancer = load_breast_cancer()<br/>df_cancer = pd.DataFrame(np.c_[cancer[‘data’], cancer[‘target’]],<br/>columns = np.append(cancer[‘feature_names’], [‘target’]))</span></pre><p id="02f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图5显示了数据片段。显然，所有的特征都是数值。不需要数据编码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/57aee14f1eb2fa1a58530ca66f9f053f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*CpAfJ4yfK-Y3pPwM4spnBA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5输入数据片段</p></figure><p id="f75c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，准备训练数据<em class="mj"> X </em>和<em class="mj"> y </em>并分割数据，测试集占20%。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="494a" class="ml mm it nx b gy ob oc l od oe">X = df_cancer.drop([‘target’],axis=1)<br/>y = df_cancer[‘target’]<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=5)</span></pre><p id="48cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">拟合模型之前的一个必要步骤是特征缩放，以避免一个特征支配其他小特征并减少密集计算。这里我们使用<em class="mj">基于单位的归一化</em>来得到范围[0，1]内的所有值。</p><p id="52ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具体来说，</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="11dd" class="ml mm it nx b gy ob oc l od oe">min_train = X_train.min()<br/>range_train = (X_train — min_train).max()<br/>X_train_scaled = (X_train — min_train)/range_train</span><span id="4bc1" class="ml mm it nx b gy og oc l od oe">min_test = X_test.min()<br/>range_test = (X_test — min_test).max()<br/>X_test_scaled = (X_test — min_test)/range_test</span></pre><p id="03c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.<strong class="lb iu">模型拟合和评估</strong></p><p id="18b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了拟合和评估该模型，我们从<em class="mj"> sklearn </em>获取<em class="mj"> SVM </em>类。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="d3d6" class="ml mm it nx b gy ob oc l od oe">from sklearn.svm import SVC<br/>from sklearn.metrics import classification_report, confusion_matrix<br/>svc_model = SVC()<br/>svc_model.fit(X_train_scaled, y_train)<br/>y_predict = svc_model.predict(X_test_scaled)<br/>cm = confusion_matrix(y_test, y_predict)</span></pre><p id="e522" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过测试，如图6的混淆矩阵所示，该模型显示了96% ✨✨.的准确性</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/0cf5e3d76711bc5a21b67afeb9285e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*MaZiDwcMDz5nItEtJkP_Zw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6 SVM测试结果的混淆矩阵</p></figure><p id="959f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5.<strong class="lb iu">模型优化</strong></p><p id="02c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SVM有两个有助于优化模型的关键参数。</p><blockquote class="oi oj ok"><p id="ca9e" class="kz la mj lb b lc ld ju le lf lg jx lh ol lj lk ll om ln lo lp on lr ls lt lu im bi translated"><strong class="lb iu">第一个是<em class="it"> C </em>参数</strong>，控制正确分类训练点和具有平滑边界之间的权衡。小的<em class="it"> C </em>使得错误分类的成本(惩罚)很低，从而产生平滑的边界。然而，如果使用大的<em class="it"> C </em>参数，这意味着错误分类的高成本，迫使模型更严格地解释输入数据，并可能过度拟合。</p><p id="bc49" class="kz la mj lb b lc ld ju le lf lg jx lh ol lj lk ll om ln lo lp on lr ls lt lu im bi translated"><strong class="lb iu">第二个是<em class="it">伽玛</em>参数。</strong>它控制单个训练集的影响范围。有了大的<em class="it"> gamma </em>，模型将有一个很近的范围，对靠近超平面的点赋予更高的权重。该模型具有过度拟合的高风险，产生更弯曲的边界。然而，使用小的<em class="it"> gamma </em>，该模型将更加一般化，因为远离超平面的更多数据点将被训练。</p></blockquote><p id="b390" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具体来说，我们使用<strong class="lb iu">网格搜索</strong>来调整<em class="mj"> C </em>和<em class="mj">伽马</em>参数。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="171d" class="ml mm it nx b gy ob oc l od oe">from sklearn.model_selection import GridSearchCV<br/>param_grid = {‘C’: [0.1, 1, 10, 100], ‘gamma’: [1, 0.1, 0.01, 0.001], ‘kernel’: [‘rbf’]}</span><span id="5a31" class="ml mm it nx b gy og oc l od oe">grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=4)<br/>grid.fit(X_train_scaled, y_train)</span></pre><p id="da89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过以上，我们找到了如图7所示的<em class="mj"> C </em>和<em class="mj"> gamma </em>的最佳参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/41dc192179aaf09df28c980b80b71440.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*X5HY8vAOW7NAJxhjyOo1mA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7网格搜索后的最佳参数</p></figure><p id="5cb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们再次测试了模型，发现精度提高了0.97，如图8所示。该模型仅将3个病例错误分类为恶性，这是一个不错的结果，因为这种错误分类不会对诊断造成任何显著影响🎉🎉。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/e77f48abcb2e7e057455ef5177a67d15.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*ajhpmRD5pYkCfABIm9Z-TA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图8优化后SVM测试结果的混淆矩阵</p></figure><p id="2afd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">太好了！如果你觉得这篇文章有帮助，请随意点击👏s！如果你需要一些额外的，访问我的</strong> <a class="ae ky" href="https://github.com/luke4u/Image-Classification" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Github </strong> </a> <strong class="lb iu">页面🤞🤞。</strong></p></div></div>    
</body>
</html>