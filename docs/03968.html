<html>
<head>
<title>Data Science Production Pipelines- Distributed Design Approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学生产管道-分布式设计方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-science-production-pipelines-distributed-design-approach-d1e9dd6e6c3b?source=collection_archive---------29-----------------------#2020-04-12">https://towardsdatascience.com/data-science-production-pipelines-distributed-design-approach-d1e9dd6e6c3b?source=collection_archive---------29-----------------------#2020-04-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8373" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">针对生产环境的大规模数据科学管道中涉及的“如何”和“什么”设计方法的系统指南(但也可用于开发/测试环境)。</h2></div><blockquote class="ki kj kk"><p id="1ee4" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">生产级数据科学应用程序的架构设计非常类似于将正确的部分放在正确的位置，同时考虑很少的前进。</p></blockquote><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi li"><img src="../Images/96574cebdab8933835d8c997eee2ccb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zyghb9Pf_C8r9xuIfaGB5A.jpeg"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">来源:<a class="ae ly" href="https://www.pexels.com" rel="noopener ugc nofollow" target="_blank">像素</a></p></figure><p id="7337" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><em class="kn">案例研究</em>-<strong class="ko iu">建立分类模型，根据声纳信号检测表面是金属还是岩石</strong></p><p id="54ab" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">代码脚本、数据信息和配置可在<a class="ae ly" href="https://github.com/bmonikraj/medium-datascience-pipeline-tutorial" rel="noopener ugc nofollow" target="_blank"><strong class="ko iu">https://github . com/bmonikraj/medium-data science-pipeline-tutorial</strong></a>找到</p><p id="2534" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">我们将在<em class="kn">讨论</em>各种部署方法的<em class="kn">架构风格</em>，更多地关注这些方法的优缺点，并强调这些方法的关键领域。因此，我们不太关注代码中到底发生了什么。如果你想讨论更多关于分布式开发模式和机器学习实现的内容，请发邮件到<a class="ae ly" href="mailto:bmonikraj@gmail" rel="noopener ugc nofollow" target="_blank"> bmonikraj@gmail </a>进行进一步讨论。</p><p id="221c" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">我仍然建议您浏览上述 Github 库，并按照 README.md 文件中提到的说明，在您的机器上尝试这些，只是为了让您的手有点脏！</p><p id="5112" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">在阅读了 Github 存储库中的 README.md 之后，我将强调其中的要点，这些要点对我们的讨论至关重要:</p><ol class=""><li id="bb00" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh mh mi mj mk bi translated">经过训练，其中一个工件组是{ predictor.py，clf_model.sav }。这可以被视为一个逻辑工件单元，我们在下文中将其称为<strong class="ko iu"> _PREDICTOR_ </strong>。</li><li id="d089" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh mh mi mj mk bi translated">另一个工件组是{ service.py }。这也是一个逻辑工件单元，我们在下文中称之为<strong class="ko iu"> _SERVICE_ </strong>。</li><li id="7560" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh mh mi mj mk bi translated">最后一个脚本(不会把它当成神器:D)是{ client.py }，可以用来测试:基本上是<strong class="ko iu"> _CLIENT_ </strong>，此后。</li></ol><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi mq"><img src="../Images/14965693e07e579e538158e70be121b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7KJJi_UOcZMUbVst"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated"><a class="ae ly" href="https://unsplash.com/@tvick?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">泰勒·维克</a>在<a class="ae ly" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="5bd1" class="mr ms it bd mt mu mv dn mw mx my dp mz lz na nb nc ma nd ne nf mb ng nh ni nj bi translated">我们的重点领域—</h2><blockquote class="ki kj kk"><p id="b225" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">我们试图将重点放在部署 ML/数据科学模型即服务(MLaaS/DSaaS)的用例上。</p></blockquote></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h2 id="b2d4" class="mr ms it bd mt mu mv dn mw mx my dp mz lz na nb nc ma nd ne nf mb ng nh ni nj bi translated">设计(1)——服务于 ML 服务的 REST APIs</h2><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nr"><img src="../Images/3e7862e41bc4b7ced49b5be8752b75a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KYbzrK9wsM2svJ99OuqqyQ.jpeg"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">架构图-&gt; <strong class="bd ns">使用 ML 服务作为 REST APIs 的阻塞调用机制| </strong>来源:作者设计</p></figure><p id="cd88" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">建筑- </strong></p><ul class=""><li id="6768" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">_CLIENT_ 是使用输入进行呼叫的客户端(HTTP 客户端，可以是脚本、web 应用程序、移动应用程序、桌面应用程序等)。</li><li id="422e" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">对作为 REST 端点的 _SERVICE_ 进行的 HTTP 调用</li><li id="e07f" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_SERVICE_ 对同一平台内的 _PREDICTOR_ ML 服务/函数/脚本进行远程过程调用/基于进程间通信的调用。</li><li id="417c" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">响应以相反的方向流动，从 _ PREDICTOR _--&gt; _ SERVICE _--&gt; _ CLIENT _。</li><li id="9ba9" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">更容易实现授权/身份验证模型，因为 _SERVICE_ 充当实现控制的业务层。</li><li id="56e0" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">模型应该是静态的。</li></ul><p id="d17f" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">优点- </strong></p><ul class=""><li id="5f82" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">易于实现，非常熟悉各大开发商</li><li id="85d0" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">没有分布式设计，因此没有令人头痛的同步问题</li><li id="a6a4" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_SERVICE_ 和 _PREDICTOR_ 保持在相同的平台上，因此没有平台间通信(服务器间)的开销。</li><li id="5e47" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">设计得相当快。</li><li id="82ab" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">适用于预测时间非常快的用例(可以使用分析器进行验证)</li><li id="b709" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">更容易实现授权/身份验证模型，因为 _SERVICE_ 充当实现控制的业务层。</li></ul><p id="c8f1" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">缺点- </strong></p><ul class=""><li id="a72c" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">服务和预测者之间的往返时间必须小于客户端和服务之间的 HTTP 超时时间</li><li id="3d75" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">需要较长时间的 ML 预测在这些情况下很难实现，因为它将面临超时。</li><li id="ee59" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">大多数情况下，不适合大数据使用情形。</li></ul></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h2 id="8a7a" class="mr ms it bd mt mu mv dn mw mx my dp mz lz na nb nc ma nd ne nf mb ng nh ni nj bi translated">设计(2)——为 ML 服务的网络套接字</h2><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nr"><img src="../Images/87062639b723a20d74b8a343948813ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jzp6ooHpovJiB8nFGCYvlg.jpeg"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">架构图--&gt;<strong class="bd ns">使用 ML 服务作为套接字的非阻塞调用机制| </strong>来源:作者设计</p></figure><p id="e785" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">建筑- </strong></p><ul class=""><li id="43b6" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">_CLIENT_ 是使用输入进行呼叫的客户端(Web Socket 客户端，可以是脚本、Web 应用程序、移动应用程序、桌面应用程序等)。</li><li id="e7df" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">对 WS 服务器 _SERVICE_ 进行的 WS 调用。</li><li id="4c5d" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_SERVICE_ 在同一平台内对 _PREDICTOR_ ML 服务/函数/脚本进行远程过程调用/基于进程间通信的调用。</li><li id="4f83" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">响应以相反的方向流动，从 _ PREDICTOR _--&gt; _ SERVICE _--&gt; _ CLIENT _</li><li id="7305" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">更容易实现授权/身份验证模型，因为 _SERVICE_ 充当实现控制的业务层。</li><li id="f16a" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">模型应该是静态的。</li></ul><p id="f1e6" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">优点- </strong></p><ul class=""><li id="9417" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">实现起来并不困难，对主要的开发者非常熟悉，并且在 WS 实现上有很好的社区支持。</li><li id="5f03" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">没有分布式设计，因此没有令人头痛的同步问题</li><li id="ffc1" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_SERVICE_ and _PREDICTOR_ 保持在同一平台上，因此没有平台间通信(服务器间)的开销。</li><li id="d836" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">设计得相当快。</li><li id="b699" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">适用于预测时间非常快的用例(可以使用分析器进行验证)</li><li id="1ffa" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_SERVICE_ 和 _PREDICTOR_ 之间的往返时间并不重要，因为无论何时响应就绪，它都会被发送到 _CLIENT_ by _SERVICE_ 中。因此，对客户端的响应是从服务推送的，而不是从服务拉取的。</li><li id="e1e7" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">更容易实现授权/身份验证模型，因为 _SERVICE_ 充当实现控制的业务层。</li></ul><p id="9cc4" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">缺点- </strong></p><ul class=""><li id="6145" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">_CLIENT_ 和 _SERVICE_ 之间的通信不是无状态的，因此 _SERVICE_ platform 的内存需求很高。</li><li id="7c09" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">对于在一个时间单位内有多个连接的用例来说，这并不好，因为 _SERVICE_ 迟早会与 multiple _CLIENT_ 有非常多的打开连接。</li><li id="9bef" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_CLIENT_ 需要在 Socket base 的“发送”—“接收”机制中实现。</li></ul></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h2 id="e974" class="mr ms it bd mt mu mv dn mw mx my dp mz lz na nb nc ma nd ne nf mb ng nh ni nj bi translated">设计(3)——服务于 ML 服务的 Web Sockets 和 MQ[这在上面提到的<a class="ae ly" href="https://github.com/bmonikraj/medium-datascience-pipeline-tutorial" rel="noopener ugc nofollow" target="_blank"> Github </a>库中实现]</h2><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nr"><img src="../Images/08a1a52c321e9145d8b5e86ed7e7947a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FZ2NzluJGo43Sh2H_BzXEA.jpeg"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">架构图-&gt; <strong class="bd ns">使用 ML 服务作为套接字的无阻塞调用机制与 MQ| </strong>来源:作者设计</p></figure><p id="28cd" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">架构- </strong></p><ul class=""><li id="d7a4" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">_CLIENT_ 是使用输入进行呼叫的客户端(Web Socket 客户端，可以是脚本、Web 应用程序、移动应用程序、桌面应用程序等)。</li><li id="ad37" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">对 WS 服务器 _SERVICE_ 进行的 WS 调用。</li><li id="ad95" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_SERVICE_ 将输入消息发布到 MQ 上商定的主题，由 _PREDICTOR_ 使用，处理并再次将结果发布到 MQ 上的主题，由 _SERVICE_ 使用。</li><li id="9bbc" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">响应以相反的方向流动，从 _ PREDICTOR _--&gt; _ SERVICE _--&gt; _ CLIENT _</li><li id="7b08" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">更容易实现授权/身份验证模型，因为 _SERVICE_ 充当实现控制的业务层。</li><li id="9b4a" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">模型应该是静态的。</li><li id="7a18" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">MQ 需要高度可用和可靠，因为它可以作为单一的故障源。</li></ul><p id="bcd9" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">优点- </strong></p><ul class=""><li id="32a4" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">分布式设计，因此可以通过云原生应用的 12 因素应用原则轻松实现云原生。</li><li id="4ca1" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_SERVICE_ and _PREDICTOR_ 可以在不同的平台上，因此通过设计进行分布。可以垂直和水平缩放。</li><li id="b96b" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">每个应用程序，如 _SERVICE_ and _PREDICTOR_ 都可以打包为 docker，并在 K8s、Docker Swarm、AWS EKS 等上进行编排，从而实现扩展。</li><li id="ca84" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">适用于<em class="kn">预测时间不太快的用例</em>(可以使用分析器进行验证)</li><li id="b39c" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_SERVICE_ 和 _PREDICTOR_ 之间的往返时间并不重要，因为无论何时响应就绪，它都会被发送到 _CLIENT_ by _SERVICE_ 中。因此，对客户端的响应是从服务推送的，而不是从服务拉取的。</li><li id="471b" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">更容易实现授权/身份验证模型，因为 _SERVICE_ 充当实现控制的业务层。</li></ul><p id="7ee1" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">缺点- </strong></p><ul class=""><li id="70d3" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">对于分布式应用程序，通过 MQ 进行通信，输入和它们各自的响应之间的同步变得至关重要，需要小心处理。</li><li id="9ab5" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">应用程序必须以相当云本地和 Devops 友好的方式编写。</li><li id="fbb6" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_CLIENT_ 和 _SERVICE_ 之间的通信不是无状态的，因此 _SERVICE_ platform 的内存需求很高。</li><li id="fc62" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">在进程间通信的 MQ 模型中，异步通信和回调没有什么困难。</li><li id="e00e" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_CLIENT_ 需要在 Socket base 的“发送”—“接收”机制中实现。</li></ul></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h2 id="b949" class="mr ms it bd mt mu mv dn mw mx my dp mz lz na nb nc ma nd ne nf mb ng nh ni nj bi translated">设计(4) —为 ML 服务的 MQ</h2><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/f5a16f8015197888a1d484897227ff42.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*xmUavn-QQZOYinh8RU_67w.jpeg"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">架构图-&gt; <strong class="bd ns">使用带有 MQ 的 ML 服务的非阻塞调用机制| </strong>来源:作者设计</p></figure><p id="7c56" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">建筑- </strong></p><ul class=""><li id="4a0f" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">_CLIENT_ 是带有输入的发布消息(客户端可以是脚本、web 应用、移动应用、桌面应用等)。</li><li id="10b2" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_SERVICE_ 已经不存在了。</li><li id="95a1" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_CLIENT_ 将输入消息直接发布到 MQ 上商定的主题，由 _PREDICTOR_ 使用，处理后将结果再次发布到 MQ 上的主题，由 _CLIENT_ 使用。</li><li id="e62b" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">响应以相反的方向流动，从 _ PREDICTOR _--&gt; _ CLIENT _</li><li id="768f" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">难以实施授权/身份验证模型，因为它必须完全分布式且专门用于实施控制。</li><li id="fa0c" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">模型应该是静态的。</li><li id="9ba3" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">MQ 需要高度可用和可靠，因为它可以作为单一的故障源。</li></ul><p id="924d" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">优点- </strong></p><ul class=""><li id="163b" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">分布式设计，因此可以通过云原生应用程序的 12 因素应用程序原则轻松实现云原生。</li><li id="6c9e" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_PREDICTOR_ 可以是“n”个不同平台，因此通过设计来分布。可以垂直和水平缩放。</li><li id="3110" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_PREDICTOR_ 可以打包为 docker，并在 K8s、Docker Swarm、AWS EKS 等平台上进行编排，从而实现扩展。</li><li id="91fb" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">适用于<em class="kn">预测时间不太快的用例</em>(可以使用分析器进行验证)</li><li id="555f" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_CLIENT_ 和 _PREDICTOR_ 之间的往返时间并不重要，因为无论何时响应就绪，它都会被发送到 _CLIENT_ by _PREDICTOR_ 中。因此，对 _CLIENT_ 的响应是从 _PREDICTOR_ 推入的，而不是从 _PREDICTOR_ 拉出的。</li><li id="4392" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">架构变得无状态。</li></ul><p id="3814" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated"><strong class="ko iu">缺点- </strong></p><ul class=""><li id="f51d" class="mc md it ko b kp kq ks kt lz me ma mf mb mg lh nt mi mj mk bi translated">难以实现授权/认证模型 as _SERVICE_ 充当用于实现控制的业务层。</li><li id="b6a3" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">对于分布式应用程序，通过 MQ 进行通信，输入和它们各自的响应之间的同步变得至关重要，需要小心处理。</li><li id="3d31" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">应用程序必须以相当云本地和 Devops 友好的方式编写。</li><li id="6e46" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">在进程间通信的 MQ 模型中，异步通信和回调没有什么困难。</li><li id="7bb9" class="mc md it ko b kp ml ks mm lz mn ma mo mb mp lh nt mi mj mk bi translated">_CLIENT_ 需要在 MQ 协议的“发布”—“订阅”模型中实现。</li></ul></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="d882" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">正如在许多 ML 讲座、演讲、博客、书籍和文章中多次提到的，没有一个盒子适合所有尺寸。作为开发人员，我们必须正确理解业务用例、瓶颈、难点、需求、SLA 和成本，以选择一种部署拓扑。</p><p id="d75b" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">毫无疑问，由于分布式、云原生和松散耦合拓扑以及 MQ 是服务间通信的核心，所以在 MQ 节点/集群的可靠性、高可用性和安全性方面需要非常小心。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="cea7" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">正如我在上面重点介绍的“静态”模型一样，为了简单起见，当业务用例需要“动态”模型、需要频繁重新训练的模型、基于强化学习的不断变化的模型以及具有流和连续输入数据的模型时，我们甚至需要考虑“训练”阶段的分布式体系结构，其中有一个集中的模型存储位置，PREDICTOR_ 可以从中提取模型并进行预测。我们可以再次使用 RabbitMQ、Kafka、SQS 等 MQ 通过流接收数据，运行预定的后台作业(可能使用<strong class="ko iu">芹菜</strong>或<strong class="ko iu">气流</strong>)来训练模型，并在中央模型库为 _PREDICTOR_ consumers 发布模型。同样，这需要同步的另一个方面，这是需要注意的。</p><p id="d8b9" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">除此之外，使用基于 MQ 的分布式体系结构，如果需要，您可以实现“警报”机制。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="2b3b" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku lz kw kx ky ma la lb lc mb le lf lg lh im bi translated">在结束语上，感谢大家耐心看完这篇文章。对于讨论任何与本文相关的，甚至与本文无关的，带有一些令人毛骨悚然的 ML/部署用例/问题/障碍的内容，请不要犹豫，发送邮件至<a class="ae ly" href="mailto:bmonikraj@gmail" rel="noopener ugc nofollow" target="_blank"> bmonikraj@gmail </a>。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nv"><img src="../Images/458c72beddaac846f978437d6ae76072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0m5YjPRTJeDy9zLg"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">乔恩·泰森在<a class="ae ly" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div></div>    
</body>
</html>