<html>
<head>
<title>Predictive Analytics: Bayesian Linear Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测分析:Python 中的贝叶斯线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayesian-linear-regression-project-in-python-forecast-water-consumption-under-the-impact-of-cea62c2693e4?source=collection_archive---------18-----------------------#2020-07-09">https://towardsdatascience.com/bayesian-linear-regression-project-in-python-forecast-water-consumption-under-the-impact-of-cea62c2693e4?source=collection_archive---------18-----------------------#2020-07-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/2d9dd206f3466b6d198da2653fc244a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2GNl9SUsTA4qGiJpSmMYdw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Alex Samuels 在<a class="ae jg" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="8a85" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">数据科学项目的贝叶斯线性回归基础概述</h2></div><p id="28f3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di">在</span>这篇文章中，我想更多地关注贝叶斯线性回归理论，并用 Python 实现一个数据科学项目的建模。整个项目是关于预测未来三十年气候变化影响下的城市用水量。完整版本的代码可以在 GitHub 的 Jupyter 笔记本上找到，我鼓励你去看看。此外，研究结果发表在<a class="ae jg" href="https://www.sciencedirect.com/science/article/pii/S2210670719319638" rel="noopener ugc nofollow" target="_blank">可持续发展的城市和社会</a>上。</p><h1 id="b4d0" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">为什么是贝叶斯统计？</h1><p id="ec21" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">统计学有两个主要分支，<strong class="la jk">描述统计</strong>和<strong class="la jk">推断统计</strong>。描述性统计提供数据的简明摘要，而推断性统计发现模式并对数据做出推断。但是为什么我要谈论这两个术语呢？😀嗯，在推断统计学中有两个对我们很重要的一般“哲学”;<strong class="la jk">频率主义</strong>和<strong class="la jk">贝叶斯主义</strong>。</p><p id="c36a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">频率统计和贝叶斯统计通过两种不同的方法来划分统计世界，以定义<strong class="la jk">概率</strong>。在频率统计中，概率与重复事件的频率有关，而在贝叶斯统计中，概率与我们自身的确定性和不确定性有关。因此，结果是，频率主义者认为模型是固定的，数据围绕它们变化，但贝叶斯主义者谈论观察到的数据是固定的，模型可以围绕它们变化。</p><p id="9d55" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以这个问题的答案是“为什么是贝叶斯统计？”是，有了贝叶斯统计，我们可以用概率来表示任何事件或假设中的不确定性。</p><h1 id="58ca" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">贝叶斯定理</h1><p id="e816" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">贝叶斯定理是贝叶斯统计中的关键规则[1]。如果 H 是假设，D 是观测数据，贝叶斯定理如下</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/2ff9775859ebc4666a358af31d6a00af.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*mgiZboErAusr5UH9f2xI-Q.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">贝叶斯定理</p></figure><p id="4b14" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<em class="na"> P(H|D) </em>表示假设<em class="na"> D </em>发生的条件下，假设的<strong class="la jk">后验概率</strong>。<em class="na"> P(H) </em>是假设的<strong class="la jk">先验概率</strong>，<em class="na"> P(D) </em>是观测数据的边际(总)概率，实际上是一个归一化常数，<em class="na"> P(D|H) </em>是给定假设的数据的概率(可能性)。</p><h1 id="4ff5" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">资料组</h1><p id="b770" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">加拿大魁北克省的 Brossard 市被选为研究地点。我获得了 2011 年 1 月至 2015 年 10 月期间的<strong class="la jk">日城市用水量</strong>、<em class="na"> q </em>的时间序列。对于同一时间段，我还得到了气候变量的时间序列:<strong class="la jk">日最低气温</strong> <em class="na"> θ </em>，<strong class="la jk">日最高气温</strong> <em class="na"> t </em>，<strong class="la jk">总降水量</strong> <em class="na"> p </em>。这些气候变量的测量是在皮埃尔·艾略特·特鲁多国际机场(YUL)的<a class="ae jg" href="https://www.concordia.ca/news/stories/2019/01/07/historical-canadian-climate-data-is-now-only-a-few-clicks-away.html" rel="noopener ugc nofollow" target="_blank">加拿大环境站</a>进行的。</p><h1 id="4132" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">贝叶斯线性回归</h1><p id="2977" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">贝叶斯统计是一种强大的概率建模技术，已被广泛用于统计建模，包括线性回归模型，以预测系统[2，3，4，5]。线性回归模型表示为</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/cd6bed00c97990bbbca6deac124e8534.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*6YHgFCrMmL7cTFp2366SIA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">线性回归模型</p></figure><p id="653d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<em class="na"> q </em>为因变量(目标变量)<em class="na"> β_0 </em>为截距；<em class="na"> β_1 </em>、<em class="na"> β_2 </em>、<em class="na"> β_3 </em>为权重(称为模型参数)；<em class="na"> θ </em>、<em class="na"> t </em>和<em class="na"> p </em>称为预测变量；并且<em class="na"> ε </em>是表示随机噪声或模型方程中不包括的变量的影响的误差项。该等式可以改写为</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/7af639970f651e372adaa492bb157692.png" data-original-src="https://miro.medium.com/v2/resize:fit:224/format:webp/1*pXsqI4_6zPu6J-sBUF3XMg.png"/></div></figure><p id="86f4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<strong class="la jk"><em class="na">β</em></strong>=(<em class="na">β_ 0</em>，<em class="na"> β_1 </em>，<em class="na"> β_2 </em>，<em class="na">β_ 3</em>)；以及<strong class="la jk"><em class="na">X</em></strong><em class="na">=</em>(<em class="na">1，q </em>，<em class="na"> Q </em>，<em class="na">p</em>)【2，6】。线性回归是使用概率分布而不是点估计来预测<em class="na"> q </em>的。因此，<em class="na"> q </em>不是作为单个值来估计的，而是假设从概率分布中提取的。响应从正态(高斯)分布<em class="na"> N </em>中取样的贝叶斯线性回归模型为</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/655b9941b6433eea9c5d4b023cb51fdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/format:webp/1*pUTnmLfrO5rswoZqm2jWxg.png"/></div></figure><p id="5dd7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出<em class="na"> q </em>由以平均值和方差为特征的正态分布产生。正态分布的平均值是回归系数矩阵(<strong class="la jk"><em class="na"/></strong>)乘以预测值矩阵(<strong class="la jk"> <em class="na"> X </em> </strong>)。方差是标准差的平方，<em class="na"> σ </em>。</p><p id="5553" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">贝叶斯线性回归模型提供了预测变量中不确定性的表示，并确定了模型参数的后验分布。不仅响应是由概率分布生成的，而且模型参数也被假定来自分布。模型参数的后验概率来自贝叶斯定理:</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/33f09550410e38dc03c01ba672c9b29f.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*7PHrXEyO2XZMfUwv4N-wRA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">模型参数的后验概率</p></figure><p id="1e88" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<em class="na">P</em>(<strong class="la jk"><em class="na">β</em></strong><em class="na">| q，</em> <strong class="la jk"> <em class="na"> X </em> </strong>)是给定预测值和自变量的模型参数的后验概率分布；<em class="na"> P(q| </em> <strong class="la jk"> <em class="na"> β，X </em> </strong> <em class="na"> ) </em>是数据的可能性；<em class="na">P(</em><strong class="la jk"><em class="na">β</em></strong><em class="na">|</em><strong class="la jk"><em class="na">X</em></strong><em class="na">)</em>是参数的先验概率，方程的分母是根据全概率定律可以找到的边际概率。</p><h1 id="0e73" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">马尔可夫链蒙特卡罗</h1><p id="6795" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">在实践中，很难计算连续值的边际可能性；计算精确的后验分布是困难的。作为一种解决方案，一种采样方法马尔可夫链蒙特卡罗被用于近似后验概率，而无需计算边际似然[3，5，7]。蒙特卡洛是一种抽取随机样本的通用技术，马尔可夫链意味着抽取的下一个样本仅基于上一个样本值。通过引入更多样本，后验概率的近似值将最终收敛于<em class="na"> β_1 </em>、<em class="na"> β_2 </em>和<em class="na"> β_3 </em>的实际后验概率分布。</p><p id="e354" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为应用马尔可夫链蒙特卡罗的起点，定义覆盖<em class="na"> β_1 </em>、<em class="na"> β_2 </em>和<em class="na"> β_3 </em>所有可能值的参数空间。然后，将每个参数的先验概率定义为正态分布。接下来，计算每个可能参数的可能性。最后，计算参数空间中任何给定点的先验×似然。</p><p id="a801" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用<strong class="la jk">不掉头算法</strong>【8】实现马尔可夫链蒙特卡罗。当所涉及的变量是连续的并且不需要设置步数时，这种算法是有效的。这是优于哈密尔顿蒙特卡罗的优点，哈密尔顿蒙特卡罗采用由一阶梯度信息通知的一系列步骤，并且对步骤的数量敏感。</p><p id="133e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">生成用于被接受的移动的一组参数值(如果建议的移动未被接受，则重复先前的值),并且在多次重复之后，找到分布的经验近似。最终，执行贝叶斯线性回归的结果是基于数据和先验的可能模型参数的概率密度函数。</p><h1 id="4bc9" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">模型性能测量</h1><p id="5205" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">整个数据集被分成训练集和测试集。训练集包含 75%的数据，用于构建模型；而测试集包含 25%，用于验证预测的准确性。此外，两个拟合优度指标用于评估本研究中开发的模型的性能。这些度量是平均绝对误差和均方根误差。平均绝对误差是预测值和实际值之差的绝对值的平均值，均方根误差是预测值和实际值之差的平均值的平方根。</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/ddb66f2890a890980e0907600d035f80.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*oWRNtGa6Kif1XQd-BL_IMQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">均方根误差</p></figure><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/e4b0c0605ce99d0fb3fd948410a2d3e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*_Hxi65bHeTbLCz-2KZlwUg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">绝对平均误差</p></figure></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><h1 id="937f" class="md me jj bd mf mg nt mi mj mk nu mm mn kp nv kq mp ks nw kt mr kv nx kw mt mu bi translated">Python 代码</h1><p id="5fb8" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">正如我之前提到的，我在这篇文章中的重点是贝叶斯线性回归模型。因此，我跳过数据预处理这一步。贝叶斯线性回归模型的输入数据集如下</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/e4013fedb669aacdc6cff96aa47cc350.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*5u5re4f8oISYZN5AsuWRnw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">输入数据集</p></figure><ul class=""><li id="aabe" class="nz oa jj la b lb lc le lf lh ob ll oc lp od lt oe of og oh bi translated">UWC:城市用水量</li><li id="a641" class="nz oa jj la b lb oi le oj lh ok ll ol lp om lt oe of og oh bi translated">Max_T:最高温度</li><li id="6db6" class="nz oa jj la b lb oi le oj lh ok ll ol lp om lt oe of og oh bi translated">最低温度</li><li id="4948" class="nz oa jj la b lb oi le oj lh ok ll ol lp om lt oe of og oh bi translated">总降水量</li></ul><p id="48e7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">⚠️在创建模型之前，请确保您已经处理了缺失值，因为贝叶斯线性回归模型不接受带有缺失点的数据。</p><h1 id="75da" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">在 PyMC3 中创建贝叶斯线性回归模型</h1><p id="44e7" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">首先，我使用<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>库将预处理数据集(df)拆分为 75%训练和 25%测试。</p><p id="342a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">注:</strong> X_train 和 X_test 包含目标变量 UWC。</p><pre class="nc nd ne nf gt on oo op oq aw or bi"><span id="72c4" class="os me jj oo b gy ot ou l ov ow">from sklearn.model_selection import train_test_split</span><span id="d761" class="os me jj oo b gy ox ou l ov ow">X_train, X_test, y_train, y_test = train_test_split(df, df['UWC'],<br/>test_size = 0.25,random_state = 42)</span></pre><p id="5b38" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个项目中，我在 PyMC3 中创建了贝叶斯线性回归模型。让马尔可夫链蒙特卡罗算法从后验概率中抽取样本来近似每个模型参数的后验概率。</p><p id="4343" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了创建模型，我将线性回归公式、参数的先验族和数据传递给<a class="ae jg" href="https://docs.pymc.io/api/glm.html?highlight=glm#pymc3.glm.linear.GLM" rel="noopener ugc nofollow" target="_blank"> GLM </a>。为了执行马尔可夫链蒙特卡罗抽样，我指定样本数为 2000，链数为 2，调优步数为 500。</p><pre class="nc nd ne nf gt on oo op oq aw or bi"><span id="7a71" class="os me jj oo b gy ot ou l ov ow">import pymc3 as pm<br/>from pymc3 import traceplot</span><span id="804b" class="os me jj oo b gy ox ou l ov ow"><strong class="oo jk"># Formula for Bayesian Linear Regression</strong> <br/>formula = ‘UWC ~ ‘ + ‘ + ‘.join([‘%s’ % variable for variable in X_train.columns[1:]])<br/>print(formula)</span><span id="c2e7" class="os me jj oo b gy ox ou l ov ow"><strong class="oo jk"># Context for the model</strong><br/>with pm.Model() as normal_model:<br/>        <br/>    <strong class="oo jk"># The prior for the model parameters will be a normal distribution</strong><br/>    family = pm.glm.families.Normal()</span><span id="c4b5" class="os me jj oo b gy ox ou l ov ow"><strong class="oo jk"># Creating the model requires a formula and data (and optionally a family)</strong><br/>    pm.GLM.from_formula(formula, data = X_train, family = family)</span><span id="0066" class="os me jj oo b gy ox ou l ov ow"><strong class="oo jk"># Perform Markov Chain Monte Carlo sampling</strong><br/>    normal_trace = pm.sample(draws=2000, chains = 2, tune = 500)</span></pre><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/b0613adf8d11e2209bad3c28c6ea990b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iBBd85tGZTN9nYC5JRYR0g.png"/></div></div></figure><p id="9b9d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，UWC 是最高温度、最低温度和总降水量的函数。</p><h2 id="6e08" class="os me jj bd mf oz pa dn mj pb pc dp mn lh pd pe mp ll pf pg mr lp ph pi mt pj bi translated">将后验分布绘制成直方图</h2><pre class="nc nd ne nf gt on oo op oq aw or bi"><span id="f492" class="os me jj oo b gy ot ou l ov ow">pm.plot_posterior(normal_trace)</span></pre><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/16624af7b174b8b61c815d78c9c19d7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xdv7IxG6nHbdiVeGUweUdg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(a)截距β_0 的后验直方图；(b)对于<em class="pl"> θ </em>的回归系数<em class="pl">β_ 1</em>；(c)回归系数<em class="pl"> β_2 </em>为<em class="pl">t</em>；(d)对于<em class="pl"> p </em>的回归系数<em class="pl">β_ 3</em>；标准偏差<em class="pl"> σ </em>。</p></figure><p id="1e5c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果显示为<em class="na"> β_0 </em>、<em class="na"> β_1 </em>、<em class="na"> β_2 </em>、<em class="na"> β </em>、<strong class="la jk"> _ </strong>、<em class="na"> 3、</em>和<em class="na"> σ </em>的后验直方图。直方图显示 95%的最高后验密度(HPD)，这是参数的<a class="ae jg" href="https://en.wikipedia.org/wiki/Credible_interval" rel="noopener ugc nofollow" target="_blank">可信区间</a>。贝叶斯统计中的可信区间相当于置信区间。比如 0.034&lt;T32】σT45】0.037 的概率是 95%。</p><h1 id="aef1" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">计算梅和 RMSE</h1><p id="fd24" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">为了计算 MAE 和 RMSE，我取 UWC 概率分布的中值，并将其作为对<em class="na"> evaluate_prediction </em>函数的预测。</p><pre class="nc nd ne nf gt on oo op oq aw or bi"><span id="d5e6" class="os me jj oo b gy ot ou l ov ow"><strong class="oo jk"># Define a function to calculate MAE and RMSE</strong><br/>def evaluate_prediction(prediction, true):<br/>    mae = np.mean(abs(predictions - true))<br/>    rmse = np.sqrt(np.mean((predictions - true) ** 2))<br/>    <br/>    return mae, rmse</span><span id="a90c" class="os me jj oo b gy ox ou l ov ow">median_pred = X_train['UWC'].median()<br/>median_preds = [median_pred for _ in range(len(X_test))]<br/>true = X_test['UWC']</span><span id="cb44" class="os me jj oo b gy ox ou l ov ow"><strong class="oo jk"># Display mae and rmse</strong><br/>mae, rmse = evaluate_prediction(median_preds, true)<br/>print('Mean Absolute Error: {:.4f}'.format(mae))<br/>print('Root Mean Square Error: {:.4f}'.format(rmse))</span></pre><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/92a84c16d851c54869b7fa082be8a641.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bhsdUjNHBad7BQVN42Zf1g.png"/></div></div></figure><p id="059f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对模型性能的评估表明，预测模型具有良好的精度。</p><h1 id="11e5" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">结论</h1><p id="fdd5" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">这篇文章是一个数据科学项目的贝叶斯线性回归的简要概述。我希望它能帮助你更好地理解贝叶斯线性回归的基本原理。😊</p><p id="45e4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">非常感谢您的反馈。你可以在 LinkedIn 上找到我。</p><h1 id="fd3d" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">参考</h1><p id="fafa" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">[1]赫克曼博士、盖格博士和奇克林博士(1995 年)。学习贝叶斯网络:知识和统计数据的结合。<em class="na">机器学习</em>，<em class="na"> 20 </em> (3)，197–243。【https://doi.org/10.1023/A:1022623210503 T42】</p><p id="c58f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[2]韩，贾伟和裴，简和坎伯，M. (2011)。数据挖掘:概念和技术。检索自<a class="ae jg" href="http://myweb.sabanciuniv.edu/rdehkharghani/files/2016/02/The-Morgan-Kaufmann-Series-in-Data-Management-Systems-Jiawei-Han-Micheline-Kamber-Jian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-Morgan-Kaufmann-2011.pdf" rel="noopener ugc nofollow" target="_blank">http://myweb . saban ciuniv . edu/rdehkharghani/files/2016/02/The-mor gan-Kaufmann-Series-in-Data-Management-Systems-Jia Wei-Han-Micheline-Kamber-Jian-Pei-Data-Mining。-概念和技术-第三版-摩根-考夫曼-2011.pdf </a></p><p id="1f6c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[3] Mudgal，a .，Hallmark，s .，Carriquiry，a .，和 Gkritza，K. (2014 年)。环形交叉路口的驾驶行为:分层贝叶斯回归分析。<em class="na">交通研究 D 部分:交通与环境</em>，<em class="na"> 26 </em>，20–26。<a class="ae jg" href="https://doi.org/10.1016/j.trd.2013.10.003" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1016/j.trd.2013.10.003</a></p><p id="e048" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[4]a . e .拉夫特里、d .马迪根和 J. A .赫廷(1997 年)。线性回归模型的贝叶斯模型平均。<em class="na">美国统计协会杂志</em>，<em class="na"> 92 </em> (437)，179–191。检索自<a class="ae jg" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1997.10473615" rel="noopener ugc nofollow" target="_blank">https://www . tandfonline . com/doi/ABS/10.1080/01621459 . 1997 . 10473615</a></p><p id="6836" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[5]袁晓春，孙晓霞，赵，魏，米，张，王，魏延明(2017)。2030 年中国区域能源需求预测:贝叶斯方法。<em class="na">资源、保护和回收</em>，<em class="na">127</em>(5 月)，85–95。<a class="ae jg" href="https://doi.org/10.1016/j.resconrec.2017.08.016" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1016/j.resconrec.2017.08.016</a></p><p id="4ef3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[6]t .塔勒布和 m .卡杜尔(2017 年)。无线传感器网络中提高能量效率的分层凝聚分簇方案。<em class="na">交通与电信</em>，<em class="na"> 18 </em> (2)，128–138。<a class="ae jg" href="https://doi.org/10.1515/ttj-2017-0012" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1515/ttj-2017-0012</a></p><p id="1ba8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[7] Godsill，S. J. (2001 年)。模型不确定性的马尔可夫链蒙特卡罗方法之间的关系。<em class="na">计算与图形统计杂志</em>，<em class="na"> 10 </em> (2)，230–248。<a class="ae jg" href="https://doi.org/10.1198/10618600152627924" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1198/10618600152627924</a></p><p id="39d5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[8]医学博士霍夫曼和盖尔曼(2011 年)。<em class="na">不掉头采样器:在哈密顿蒙特卡罗中自适应地设置路径长度</em>。(2008), 1–30.从 http://arxiv.org/abs/1111.4246<a class="ae jg" href="http://arxiv.org/abs/1111.4246" rel="noopener ugc nofollow" target="_blank">取回</a></p></div></div>    
</body>
</html>