<html>
<head>
<title>Inferences from a TF Lite model — Transfer Learning on a Pre-trained Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">来自TF Lite模型的推论——基于预训练模型的迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/inferences-from-a-tf-lite-model-transfer-learning-on-a-pre-trained-model-e16e7c5f0ee6?source=collection_archive---------28-----------------------#2020-06-15">https://towardsdatascience.com/inferences-from-a-tf-lite-model-transfer-learning-on-a-pre-trained-model-e16e7c5f0ee6?source=collection_archive---------28-----------------------#2020-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2ed9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在预先训练的Tensorflow模型上使用迁移学习创建一个Tf Lite模型，优化它，并运行推理。</h2></div><p id="738d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">在本文中，您将学习使用预先训练的模型，应用迁移学习，将模型转换为TFLite，应用优化，并从TF Lite模型中进行推理。</em></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/91f8386c6f32b07ef94c0605a55ea6ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8axL-dlm0I0Gf-43tj2vw.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">由<a class="ae lv" href="https://unsplash.com/@_louisreed?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">路易·里德</a>在<a class="ae lv" href="/s/photos/raspberry-pi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="6076" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">先决条件:</strong></p><p id="ae91" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lv" href="https://medium.com/@arshren/a-basic-introduction-to-tensorflow-lite-59e480c57292" rel="noopener">tensor flow Lite的基本介绍</a></p><p id="3a82" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lv" href="https://www.kaggle.com/c/dogs-vs-cats/data" rel="noopener ugc nofollow" target="_blank">猫狗数据集</a></p><p id="ab53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">张量流2.0</p><h2 id="97c8" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">创建数据集</h2><p id="f94a" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">我已经下载了数据集，并按照下面的结构解压文件。</p><p id="fa67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用于提取数据并按照以下结构创建数据的Python代码在此处<a class="ae lv" href="https://github.com/arshren/TFLite/blob/master/Transfer%20Learning%20with%20TFLite-Copy1.ipynb" rel="noopener ugc nofollow" target="_blank">可用</a>。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/18df8ae7c6af4ffd68bfdf1a85721539.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*oz2mMm4inmItCSyx-Mnj1w.png"/></div></figure><p id="5b05" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">导入所需的库</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="68da" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img<br/>from tensorflow.python.keras.applications import imagenet_utils<br/>from tensorflow.python.keras.layers import Dense,GlobalAveragePooling2D<br/>from tensorflow.keras.applications import   DenseNet121<br/>from tensorflow.python.keras.applications.densenet import preprocess_input<br/>from tensorflow.keras.models import Model</strong></span></pre><p id="5543" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">设置培训的关键参数</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="f885" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">BASE_PATH = 'Data\\dogs-vs-cats\\train\\'<br/>TRAIN_PATH='Data\\dogs-vs-cats\\train_data\\'<br/>VAL_PATH='Data\\dogs-vs-cats\\validation_data\\'</strong></span><span id="1c62" class="lw lx it mw b gy ne nb l nc nd"><strong class="mw iu">batch_size = 32 <br/>epochs = 60<br/>IMG_HEIGHT = 150<br/>IMG_WIDTH = 150</strong></span></pre><p id="11fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">重新缩放并对训练图像应用不同的增强</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="c063" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">train_image_generator = ImageDataGenerator(                                                rescale=1./255,                                              rotation_range=45,                                                width_shift_range=.15,                                                height_shift_range=.15,                                                horizontal_flip=True,                                                zoom_range=0.3)</strong></span></pre><p id="d932" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">重标验证数据</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="edb6" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">validation_image_generator = ImageDataGenerator(rescale=1./255)</strong></span></pre><p id="1462" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">为训练和验证数据集生成批量归一化数据</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="a3bf" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">train_data_gen = train_image_generator.flow_from_directory(batch_size = batch_size,                                                     directory=TRAIN_PATH,                                                     shuffle=True,                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),                                                     class_mode='categorical')</strong></span><span id="cc52" class="lw lx it mw b gy ne nb l nc nd"><strong class="mw iu">val_data_gen = validation_image_generator.flow_from_directory(batch_size = batch_size,                                                              directory=VAL_PATH,                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),                                                              class_mode='categorical')</strong></span></pre><h2 id="05a8" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">在预先训练的模型上应用迁移学习</h2><p id="9fb0" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">您可以使用任何一种<a class="ae lv" href="https://keras.io/api/applications/" rel="noopener ugc nofollow" target="_blank">预训练型号</a>。我用过DenseNet121，有427层。</p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="b7eb" class="lw lx it mw b gy na nb l nc nd"># Create the base model from the pre-trained model MobileNet V2<br/><strong class="mw iu">base_model = tf.keras.applications.DenseNet121(<br/>input_shape=(IMG_WIDTH, IMG_HEIGHT,3),                                               include_top=False,                                               weights='imagenet')</strong></span></pre><p id="7c87" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">冻结基础预训练模型的所有权重，并在预训练模型的顶部添加几个层</p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="74d7" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">base_model.trainable = False<br/>x=base_model.output<br/>x=Flatten()(x)<br/>x=Dense(512,activation='relu')(x) <br/>output=Dense(2,activation='softmax')(x) <br/>model=Model(inputs=base_model.input,outputs=output)<br/>model.summary()</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/ab2ca34c74a8e027417b4793c38856e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*Bsp2pho3NFPMi2bb9GOi_g.png"/></div></figure><p id="c668" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以看到预训练模型的权重是不可训练的，只有添加的层权重是可训练的。</p><p id="c823" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以使预训练模型权重的几个层成为可训练的，以帮助学习自定义数据集，从而获得更高的准确性。</p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="a560" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">TRAINABLE_LAYERS= len(model.layers)-len(base_model.layers)+5<br/>print(TRAINABLE_LAYERS)<br/>for layer in model.layers[:-TRAINABLE_LAYERS]:<br/>    layer.trainable=False<br/>for layer in model.layers[-TRAINABLE_LAYERS:]:<br/>    layer.trainable=True</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/46fa7071d5b8a9b86e8c8c589e5e41d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*KlntABGylLmso_X52YMkJg.png"/></div></figure><p id="5b15" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以看到可训练参数的数量增加了，这也将增加训练时间。</p><p id="2f58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">在自定义数据集上编译和训练模型</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="4a63" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(lr=2e-5), metrics=['acc'])</strong></span><span id="154f" class="lw lx it mw b gy ne nb l nc nd"><strong class="mw iu">epochs=20<br/>step_size_train=train_data_gen.n//train_data_gen.batch_size<br/>history =model.fit_generator(generator=train_data_gen,<br/>                   steps_per_epoch=step_size_train,<br/>                   epochs=epochs)</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nh"><img src="../Images/7aa03c87d7a02b0a738850ae9485dd53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KDRMFPtdHzSR6ywA_a6ksQ.png"/></div></div></figure><p id="3ebf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在模型被编译和训练之后，我们现在可以开始将模型转换为TF Lite，如下所示。</p><p id="77a4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">将预训练的转移学习模型转换为TF Lite </strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ni"><img src="../Images/11aae9b81be3393c43953f2f8752459c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3H9NynZhfm05LLdI.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">来源:https://www.tensorflow.org/lite/convert/index</p></figure><p id="e4db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">训练完模型后，您现在需要保存模型。</p><p id="d617" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">保存的模型将模型的架构、权重和偏差以及训练配置序列化到一个文件中。保存的模型可以很容易地用于共享或部署模型。</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="a438" class="lw lx it mw b gy na nb l nc nd">#save your model in the SavedModel format<br/><strong class="mw iu">export_dir = 'saved_model'<br/>tf.saved_model.save(model, export_dir)</strong></span></pre><p id="51fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">SavedModel包含一个完整的TensorFlow程序，包括权重和计算。</p><p id="4150" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> saved_model </strong>是保存在<strong class="kk iu"> <em class="le"> export_dir，</em> </strong>上的元图，使用<strong class="kk iu"> lite转换为TFLite模型。TFLiteConverter </strong>。</p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="802b" class="lw lx it mw b gy na nb l nc nd"># Converting a SavedModel to a TensorFlow Lite model.<br/><strong class="mw iu">converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)<br/>tflite_model = converter.convert()</strong></span></pre><p id="a5e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将平面缓冲区TFLIte模型写入二进制文件，当前大小为61 MB。</p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="440f" class="lw lx it mw b gy na nb l nc nd">open("model_tl.tflite", "wb").write(tflite_model)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/56780fb1dbebc922c8622c2da61d457b.png" data-original-src="https://miro.medium.com/v2/resize:fit:128/format:webp/1*vp-rrsJ0zKpekIv_h4XamA.png"/></div></figure><h2 id="13ee" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">优化模型</h2><p id="f6c3" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">边缘模型需要是轻量级的，并且具有低延迟来运行推理。轻量级和低延迟模型是通过减少预测所需的计算量来实现的，这是通过对TF Lite模型应用量化优化来实现的。</p><p id="8b8a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">量化降低了用于表示张量流模型不同参数的数字的精度，以使模型轻量化。</em></p><p id="9700" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">量化应用于权重和激活。</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="961e" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">optimize="Speed"<br/>if optimize=='Speed':<br/>    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]<br/>elif optimize=='Storage':<br/>     converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]<br/>else:    <br/>    converter.optimizations = [tf.lite.Optimize.DEFAULT]</strong></span><span id="b9b5" class="lw lx it mw b gy ne nb l nc nd">#reduce the size of a floating point model by quantizing the weights to float16<br/><strong class="mw iu">converter.target_spec.supported_types = [tf.float16]<br/>tflite_quant_model = converter.convert()</strong></span><span id="981e" class="lw lx it mw b gy ne nb l nc nd">#save the quanitized model toa binary file<br/><strong class="mw iu">open("model_quant_tl.tflite", "wb").write(tflite_quant_model)</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/b7e97942756af78e98677b2a529a0edb.png" data-original-src="https://miro.medium.com/v2/resize:fit:124/format:webp/1*C6sAFIc-L1XaNPQwk4TcUQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">量化TF Lite模型的大小</p></figure><p id="5d4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里，我们针对速度优化了模型，然后将<strong class="kk iu"> 32位浮点转换为16位浮点</strong>，以减小模型的大小。</p><blockquote class="nl"><p id="5bbd" class="nm nn it bd no np nq nr ns nt nu ld dk translated">在应用优化后，TF Lite型号的61 MB现在减少到30MB。</p></blockquote><p id="cb69" class="pw-post-body-paragraph ki kj it kk b kl nv ju kn ko nw jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">优化后的模型可以部署到任何我们需要的边缘设备<strong class="kk iu"><em class="le">TF lite _ runtime . interpreter</em></strong></p><h2 id="67eb" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">在边缘运行推论</h2><p id="d877" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated"><strong class="kk iu">用优化的加载解释器。包含模型的执行图和分配张量的tflite模型</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="0944" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">import tflite_runtime.interpreter as tflite</strong><br/># Load TFLite model and allocate tensors.<br/><strong class="mw iu">interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)</strong></span><span id="4830" class="lw lx it mw b gy ne nb l nc nd">#allocate the tensors<strong class="mw iu"><br/>interpreter.allocate_tensors()</strong></span></pre><p id="eb74" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">得到输入和输出张量。</p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="3faf" class="lw lx it mw b gy na nb l nc nd">#get input and output tensors<br/><strong class="mw iu">input_details = interpreter.get_input_details()<br/>output_details = interpreter.get_output_details()</strong></span></pre><p id="d4ae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">对输入数据进行预处理</strong></p><p id="efe4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们想要进行推断的输入图像需要与模型的输入数据相匹配。</p><p id="886c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">读取图像，解码为张量并将图像预处理为所需的大小，转换为float16并添加批量维度</p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="cbee" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">import cv2</strong></span><span id="4cde" class="lw lx it mw b gy ne nb l nc nd"># Read the image and decode to a tensor<br/><strong class="mw iu">image_path='Data\\dogs-vs-cats\\test1\\151.jpg' <br/>img = cv2.imread(image_path)<br/>img = cv2.resize(img,(IMG_WIDTH,IMG_HEIGHT))</strong></span><span id="e3df" class="lw lx it mw b gy ne nb l nc nd">#Preprocess the image to required size and cast<br/><strong class="mw iu">input_shape = input_details[0]['shape']<br/>input_tensor= np.array(np.expand_dims(img,0), dtype=np.float16)</strong></span></pre><p id="1f16" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是我们试图预测的图像</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/e879504774a36da1c282acbcc7eb8427.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*rATWDCbbF1kkLf2W0CFUOA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><strong class="bd ob">狗对猫\\test1\\151.jpg </strong></p></figure><p id="ff82" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">运行推论</strong></p><p id="9489" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过设置张量将输入数据指向第0个数组以输入张量。通过调用解释器来运行推理</p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="cbe7" class="lw lx it mw b gy na nb l nc nd"><em class="le">#set the tensor to point to the input data to be inferred</em><br/><strong class="mw iu">input_index = interpreter.get_input_details()[0]["index"]<br/>interpreter.set_tensor(input_index, input_tensor)</strong></span><span id="5f4f" class="lw lx it mw b gy ne nb l nc nd"><em class="le">#Run the inference</em><br/><strong class="mw iu">interpreter.invoke()<br/>output_details = interpreter.get_output_details()</strong></span></pre><p id="c7fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">为我们的图像分类解释输出张量</strong></p><pre class="lg lh li lj gt mv mw mx my aw mz bi"><span id="15e1" class="lw lx it mw b gy na nb l nc nd"><strong class="mw iu">output_data = interpreter.get_tensor(output_details[0]['index'])<br/>results = np.squeeze(output_data)<br/>top_k = results.argsort()</strong></span><span id="0605" class="lw lx it mw b gy ne nb l nc nd"><strong class="mw iu">for label, idx in train_data_gen.class_indices.items():  <br/>    if top_k[idx]==1:<br/>        print("Prediction: " label)</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/57414fe4bde55df0d48bc4a1f87a7861.png" data-original-src="https://miro.medium.com/v2/resize:fit:118/format:webp/1*xDNDniWY5H1hWA3Qo9lLaA.png"/></div></figure><p id="7950" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出是狗。</p><p id="c406" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lv" href="https://github.com/arshren/TFLite/blob/master/Transfer%20Learning%20with%20TFLite-Copy1.ipynb" rel="noopener ugc nofollow" target="_blank">TF Lite推论的Github代码</a></p><p id="565e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">结论:</strong></p><p id="ca53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对预训练模型使用自定义或预训练或应用迁移学习，保存模型，将模型转换为TFLite平面缓冲文件，针对延迟或存储进行优化，然后使用TF Lite解释器进行推理。</p></div></div>    
</body>
</html>