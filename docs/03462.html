<html>
<head>
<title>How to Produce a DeepFake Video in 5 Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在5分钟内制作一个DeepFake视频</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-produce-a-deepfake-video-in-5-minutes-513984fd24b6?source=collection_archive---------1-----------------------#2020-04-02">https://towardsdatascience.com/how-to-produce-a-deepfake-video-in-5-minutes-513984fd24b6?source=collection_archive---------1-----------------------#2020-04-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2743" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">每个人都可以不用写一行代码就能制作DeepFakes。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/685b2ea2deeb46436bc856d77874a434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nMKOEH26oBkc9W75PeIoUQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">克里斯蒂安·格滕巴赫在<a class="ae ky" href="https://unsplash.com/s/photos/fake?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="da3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你跳舞吗？你有没有最喜欢的舞者或表演者，你希望看到自己模仿他们的动作？现在你可以了！</p><p id="b283" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">想象一下你有一张全身照。只是一个静止的图像。然后你所需要的就是你最喜欢的舞者表演一些动作的独舞视频。现在没那么难了，因为<a class="ae ky" href="https://www.tiktok.com/" rel="noopener ugc nofollow" target="_blank">抖音</a>正在接管世界…</p><p id="e94b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像动画使用视频序列来驱动图片中对象的运动。在这个故事中，我们看到图像动画技术现在是多么的简单易用，以及你是如何制作出你能想到的任何东西。为此，我将相关出版物的<a class="ae ky" href="https://github.com/AliaksandrSiarohin/first-order-model" rel="noopener ugc nofollow" target="_blank">源代码</a>转换成一个简单的脚本，创建了一个任何人都可以用来生成DeepFakes的瘦包装器。有了源图像和正确的驾驶视频，一切皆有可能。</p><blockquote class="lv lw lx"><p id="527d" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><a class="ae ky" href="https://www.dimpo.me/newsletter?utm_source=article&amp;utm_medium=medium&amp;utm_campaign=deep_fakes&amp;utm_term=deep_fakes" rel="noopener ugc nofollow" target="_blank">学习率</a>是我每周给那些对AI和MLOps世界好奇的人发的简讯。你会在每周五收到我关于最新人工智能新闻、研究、回购和书籍的更新和想法。在这里订阅<a class="ae ky" href="https://www.dimpo.me/newsletter?utm_source=article&amp;utm_medium=medium&amp;utm_campaign=deep_fakes&amp;utm_term=deep_fakes" rel="noopener ugc nofollow" target="_blank"/>！</p></blockquote></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="c957" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">它是如何工作的</h1><p id="87b9" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在这篇文章中，我们谈论一个新的出版物(2019)，部分<a class="ae ky" href="http://papers.nips.cc/book/advances-in-neural-information-processing-systems-32-2019" rel="noopener ugc nofollow" target="_blank">神经信息处理系统进展32 (NIPS 2019) </a>，称为“<a class="ae ky" href="http://papers.nips.cc/paper/8935-first-order-motion-model-for-image-animation" rel="noopener ugc nofollow" target="_blank">图像动画的一阶运动模型</a>”【1】。在这篇论文中，作者Aliaksandr Siarohin、Stéphane Lathuilière、Sergey Tulyakov、Elisa Ricci和Nicu Sebe提出了一种在给定驾驶视频的情况下对源图像进行动画制作的新方法，而无需关于要动画制作的对象的任何附加信息或注释。</p><p id="cee0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在引擎盖下，他们使用一个经过训练的神经网络来重建视频，给定一个源帧(静止图像)和视频中运动的潜在表示，这是在训练过程中学习的。在测试时，该模型将一幅新的源图像和一段驾驶视频(例如一系列帧)作为输入，并根据这些帧中描述的运动预测源图像中的对象如何移动。</p><p id="5203" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">该模型追踪动画中所有有趣的东西:头部运动、说话、眼球追踪甚至身体动作。</strong>例如，让我们看看下面的GIF:特朗普总统驾驶《权力的游戏》的演员像他一样说话和移动。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/dbcebb777d0899a48195cecce23f45de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VHeB3IYlZ_yx4yv2QnCGsQ.gif"/></div></div></figure><h1 id="b36a" class="mj mk it bd ml mm nh mo mp mq ni ms mt jz nj ka mv kc nk kd mx kf nl kg mz na bi translated">方法和途径</h1><p id="38d1" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在创建我们自己的序列之前，让我们进一步探索这种方法。首先，训练数据集是大量视频的集合。在训练期间，作者从同一视频中提取帧对，并将它们馈送给模型。该模型试图通过某种方式学习这些对中的关键点以及如何表示它们之间的运动来重建视频。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/39d181a3df05b7c33412acdec75efde0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W2Tex1bSPw1nPnACErM15g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1 —框架架构(A. Siarohin等人，NeurIPS 2019)</p></figure><p id="8930" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，该框架包括两个模型:运动估计器和视频生成器。最初，<strong class="lb iu">运动估计器试图学习视频中运动的潜在表示。</strong>这被编码为特定于运动的关键点位移(其中关键点可以是眼睛或嘴的位置)和局部仿射变换。这种组合可以模拟更大的变换族，而不是仅使用关键点位移。模型的输出是双重的:一个密集的运动场和一个遮挡掩模。该遮罩定义了驾驶视频的哪些部分可以通过扭曲源图像来重建，以及哪些部分应该由上下文来推断，因为它们不存在于源图像中(例如，头部的后面)。例如，看看下面的时尚GIF。每个模型的背面在源图片中不存在，因此，应该由模型来推断。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/a881179505c3640cb15afeb321f03909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*DaGKk7VAQYNXBVNd-HCA0A.gif"/></div></div></figure><p id="1454" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，视频生成器将运动检测器的输出和源图像作为输入，并根据驱动视频将其动画化；<strong class="lb iu">它以类似于驾驶视频的方式扭曲源图像，并保留被遮挡的部分。图1描述了框架架构。</strong></p><h1 id="94e0" class="mj mk it bd ml mm nh mo mp mq ni ms mt jz nj ka mv kc nk kd mx kf nl kg mz na bi translated">代码示例</h1><p id="b34d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">本文的源代码在<a class="ae ky" href="https://github.com/AliaksandrSiarohin/first-order-model" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上。我所做的是创建一个简单的外壳脚本，一个薄的包装器，它利用源代码，每个人都可以很容易地使用它进行快速实验。</p><p id="6bbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要使用它，首先，您需要安装模块。运行<code class="fe nn no np nq b">pip install deep-animator</code>在您的环境中安装库。那么，我们需要四样东西:</p><ul class=""><li id="dd8d" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated">模型权重；当然，我们不希望从零开始训练模型。因此，我们需要权重来加载预训练的模型。</li><li id="b9f6" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">我们模型的YAML配置文件。</li><li id="e313" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">源图像；例如，这可以是一幅肖像。</li><li id="adde" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">一段驾驶视频；最好先下载一个面部清晰可见的视频。</li></ul><p id="7fe1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了快速获得一些结果并测试算法的性能，您可以使用<a class="ae ky" href="https://drive.google.com/file/d/1ACSKOfQUHbSEWmPu4Ndss7bkrPVK5WBR/view" rel="noopener ugc nofollow" target="_blank">这个</a>源图像和<a class="ae ky" href="https://drive.google.com/file/d/103PEtO2QO45XwCNLYIzMcW3aRdbOhS1D/view" rel="noopener ugc nofollow" target="_blank">这个</a>驾驶视频。型号重量可在<a class="ae ky" href="https://drive.google.com/file/d/1zqa0la8FKchq62gRJMMvDGVhinf3nBEx/view" rel="noopener ugc nofollow" target="_blank">这里</a>找到。下面给出了一个简单的YAML配置文件。打开一个文本编辑器，复制并粘贴以下行，并将其保存为<code class="fe nn no np nq b">conf.yml</code>。</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="7be2" class="oj mk it nq b gy ok ol l om on">model_params:<br/>  common_params:<br/>    num_kp: 10<br/>    num_channels: 3<br/>    estimate_jacobian: True<br/>  kp_detector_params:<br/>     temperature: 0.1<br/>     block_expansion: 32<br/>     max_features: 1024<br/>     scale_factor: 0.25<br/>     num_blocks: 5<br/>  generator_params:<br/>    block_expansion: 64<br/>    max_features: 512<br/>    num_down_blocks: 2<br/>    num_bottleneck_blocks: 6<br/>    estimate_occlusion_map: True<br/>    dense_motion_params:<br/>      block_expansion: 64<br/>      max_features: 1024<br/>      num_blocks: 5<br/>      scale_factor: 0.25<br/>  discriminator_params:<br/>    scales: [1]<br/>    block_expansion: 32<br/>    max_features: 512<br/>    num_blocks: 4</span></pre><p id="2423" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们已经准备好做一个模仿莱昂纳多·迪卡普里奥的雕像了！要获得结果，只需运行以下命令。</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="ebc7" class="oj mk it nq b gy ok ol l om on">deep_animate &lt;path_to_the_source_image&gt; &lt;path_to_the_driving_video&gt; &lt;path_to_yaml_conf&gt; &lt;path_to_model_weights&gt;</span></pre><p id="41f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果您已经将所有东西都下载到了同一个文件夹中，<code class="fe nn no np nq b">cd</code>到那个文件夹并运行:</p><pre class="kj kk kl km gt of nq og oh aw oi bi"><span id="60eb" class="oj mk it nq b gy ok ol l om on">deep_animate 00.png 00.mp4 conf.yml deep_animator_model.pth.tar</span></pre><p id="c450" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我的CPU上，大约需要五分钟才能得到生成的视频。除非<code class="fe nn no np nq b">--dest</code>选项另有规定，否则该文件将保存在同一文件夹中。此外，您可以通过<code class="fe nn no np nq b">--device cuda</code>选项使用GPU加速。终于，我们准备好看到结果了。相当牛逼！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/f493c342b0761f4899ceb09de4b0aba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/1*nzojDGpOAwKKP7ouxdaugA.gif"/></div></figure><h1 id="7689" class="mj mk it bd ml mm nh mo mp mq ni ms mt jz nj ka mv kc nk kd mx kf nl kg mz na bi translated">结论</h1><p id="143f" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在这个故事中，我们介绍了A. Siarohin等人所做的工作，以及如何使用它来不费吹灰之力获得巨大的成果。最后，我们用一个薄薄的包装纸<code class="fe nn no np nq b">deep-animator</code>制作了一个雕像。</p><p id="7207" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然对这种技术有一些担忧，但它可以有各种各样的应用，也显示了如今制作假新闻是多么容易，提高了人们对它的认识。</p><blockquote class="lv lw lx"><p id="73b5" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><a class="ae ky" href="https://www.dimpo.me/newsletter" rel="noopener ugc nofollow" target="_blank">学习率</a>是我每周给那些对AI和MLOps世界好奇的人发的简讯。你会在每周五收到我关于最新人工智能新闻、研究、回购和书籍的更新和想法。在这里订阅<a class="ae ky" href="https://www.dimpo.me/newsletter" rel="noopener ugc nofollow" target="_blank"/>！</p></blockquote><h1 id="e935" class="mj mk it bd ml mm nh mo mp mq ni ms mt jz nj ka mv kc nk kd mx kf nl kg mz na bi translated">关于作者</h1><p id="092b" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我叫<a class="ae ky" href="https://www.dimpo.me/?utm_source=article&amp;utm_medium=medium&amp;utm_campaign=deep_fakes&amp;utm_term=deep_fakes" rel="noopener ugc nofollow" target="_blank">迪米特里斯·波罗普洛斯</a>，我是一名为<a class="ae ky" href="https://www.arrikto.com/" rel="noopener ugc nofollow" target="_blank">阿里克托</a>工作的机器学习工程师。我曾为欧洲委员会、欧盟统计局、国际货币基金组织、欧洲央行、经合组织和宜家等主要客户设计和实施过人工智能和软件解决方案。</p><p id="0151" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有兴趣阅读更多关于机器学习、深度学习、数据科学和数据运算的帖子，请关注我的<a class="ae ky" href="https://towardsdatascience.com/medium.com/@dpoulopoulos/follow" rel="noopener" target="_blank"> Medium </a>、<a class="ae ky" href="https://www.linkedin.com/in/dpoulopoulos/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或Twitter上的<a class="ae ky" href="https://twitter.com/james2pl" rel="noopener ugc nofollow" target="_blank"> @james2pl </a>。</p><p id="161c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所表达的观点仅代表我个人，并不代表我的雇主的观点或意见。此外，请访问我的网站上的<a class="ae ky" href="https://www.dimpo.me/resources/?utm_source=article&amp;utm_medium=medium&amp;utm_campaign=deep_fakes&amp;utm_term=deep_fakes" rel="noopener ugc nofollow" target="_blank">资源</a>页面，这里有很多好书和顶级课程，开始构建您自己的数据科学课程吧！</p><h1 id="9066" class="mj mk it bd ml mm nh mo mp mq ni ms mt jz nj ka mv kc nk kd mx kf nl kg mz na bi translated">参考</h1><p id="9716" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">[1] A. Siarohin，S. Lathuilière，S. Tulyakov，E. Ricci和N. Sebe，“图像动画的一阶运动模型”，神经信息处理系统会议(NeurIPS)，2019年12月。</p></div></div>    
</body>
</html>