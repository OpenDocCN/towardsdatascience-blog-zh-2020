<html>
<head>
<title>Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-networks-f62dd896a856?source=collection_archive---------16-----------------------#2020-08-12">https://towardsdatascience.com/convolutional-neural-networks-f62dd896a856?source=collection_archive---------16-----------------------#2020-08-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="029a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">CNN 的基本原理</h2></div><p id="26b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CNN 是一种特殊类型的人工神经网络，它接受图像作为输入。以下是人工神经网络的基本神经元的表示，它将 X 向量作为输入。然后，X 向量中的值乘以相应的权重，以形成线性组合。因此，施加非线性函数或激活函数，以便获得最终输出。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/d6aeb1c8aabd60993d9fd1e6ca7aa646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ik11_8fIxaUS11hvNpPEgw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">神经元表示，图片由作者提供</p></figure><h1 id="a903" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">为什么是 CNN？</h1><p id="f91b" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">谈到灰度图像，它们的像素范围从 0 到 255，即 8 位像素值。如果图像的大小是 NxM，那么输入向量的大小将是 N*M。对于 RGB 图像，它将是 N*M*3。考虑一个大小为 30x30 的 RGB 图像。这将需要 2700 个神经元。一幅 256x256 大小的 RGB 图像需要超过 100000 个神经元。ANN 采用输入向量，并给出一个乘积，作为与输入完全关联的另一个隐藏层的向量。224x224x3 的权重、参数数量非常大。输出层中的单个神经元将有 224x224x3 个权重进入其中。这将需要更多的计算、内存和数据。CNN 利用图像的结构导致输入和输出神经元之间的稀疏连接。每一层在 CNN 上执行卷积。CNN 将输入作为 RGB 图像的图像体积。基本上，一幅图像作为输入，我们对图像应用内核/过滤器来获得输出。CNN 还支持输出神经元之间的参数共享，这意味着在图像的一部分有用的特征检测器(例如水平边缘检测器)可能在图像的另一部分有用。</p><h1 id="8540" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">回旋</h1><p id="24db" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">每个输出神经元通过权重矩阵(也称为核或权重矩阵)连接到输入中的小邻域。我们可以为每个卷积层定义多个内核，每个内核产生一个输出。每个滤波器围绕输入图像移动，产生第二输出。对应于每个滤波器的输出被叠加，产生输出量。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mo"><img src="../Images/4806227eaa96faaae5de8104ce52d890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5UU89qw6guc5AaOp"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">卷积运算，通过 indoml 成像</p></figure><p id="7bff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，矩阵值与核滤波器的相应值相乘，然后执行求和操作以获得最终输出。核滤波器在输入矩阵上滑动，以获得输出向量。如果输入矩阵的维数为 Nx 和 Ny，而核矩阵的维数为 Fx 和 Fy，那么最终输出的维数将为 Nx-Fx+1 和 Ny-Fy+1。在 CNN 中，权重代表一个内核过滤器。k 内核图会提供 k 内核特性。</p><h1 id="24d0" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">填料</h1><p id="6577" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">填充卷积用于保留对我们很重要的输入矩阵的维度，它帮助我们保留图像边界的更多信息。我们已经看到卷积减少了特征图的大小。为了将特征映射的维度保持为输入映射的维度，我们用零填充或附加行和列。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/06619b7a5620354ad03e232372976979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*6W7Mv9AZyfTOvuahqWZdUQ.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">填充，作者图像</p></figure><p id="8f7a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上图中，填充为 1，我们能够保留 3x3 输入的维度。输出特征图的大小是维数 N-F+2P+1。其中 N 是输入映射的大小，F 是内核矩阵的大小，P 是填充的值。为了保持维数，N-F+2P+1 应该等于 N。因此，</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/f1f95b1e5dec62662b0de504983bdd92.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*TpgGbyQrlQ0uuqroE06Q3g.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">按作者保留尺寸、图像的条件</p></figure><h1 id="d000" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">进展</h1><p id="c5ff" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">步幅指的是内核过滤器将跳过的像素数，即像素/时间。步幅为 2 意味着内核在执行卷积运算之前将跳过 2 个像素。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mo"><img src="../Images/a4855eddfa6ca87f1e9965f8697e959c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vP9Wnn19w6cEOXbp"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">步幅演示，由 indoml 制作图像</p></figure><p id="1017" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上图中，内核过滤器通过一次跳过一个像素在输入矩阵上滑动。步幅为 2 将在执行卷积之前执行两次此跳跃操作，如下图所示。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mo"><img src="../Images/50b4bbc669c7de37303983869ac51924.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R5mOybGanfUU0u_-"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">步幅演示，由 indoml 制作图像</p></figure><p id="6ef3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里要观察的是，当步幅从 1 增加到 2 时，输出特征图减小(4 倍)。输出特征图的维数是(N-F+2P)/S + 1。</p><h1 id="c457" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">联营</h1><p id="8795" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">池通过子采样提供平移不变性:减小特征图的大小。两种常用的池技术是最大池和平均池。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/ca50b51fc900bacdecf79e0ecc02fdd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/0*iUNeP6p6Tc9amYHE"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">最大池操作，图像由 indoml</p></figure><p id="9448" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的操作中，池化操作将 4x4 矩阵分为 4 个 2x2 矩阵，并选取四个矩阵中最大的值(最大池化)和四个矩阵的平均值(平均池化)。这减小了特征图的大小，从而在不丢失重要信息的情况下减少了参数的数量。这里需要注意的一点是，池化操作会减少输入特征图的 Nx 和 Ny 值，但不会减少 Nc(通道数)的值。此外，池操作中涉及的超参数是过滤器维度、步幅和池类型(最大或平均)。梯度下降没有要学习的参数。</p><h1 id="2fcc" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">输出特征地图</h1><p id="31f5" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">输出特征图或体积的大小取决于:</p><ol class=""><li id="5509" class="ms mt iq kh b ki kj kl km ko mu ks mv kw mw la mx my mz na bi translated">输入要素地图的大小</li><li id="f9ed" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">内核大小(千瓦，Kh)</li><li id="c4ac" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">零填充</li><li id="4d80" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">步幅(Sw，Sh)</li></ol><h1 id="d083" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">朴素卷积</h1><p id="e098" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">这些是卷积神经网络的构建模块，并且依赖于上述参数。输出特征地图的维度可表示为:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/43d05416463b49ccff1b63041c2e2501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*oN0y2vraLwNKBwzwojOH2g.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">o/p 特征图的尺寸，图片由作者提供</p></figure><h1 id="1555" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">扩张卷积</h1><p id="7c1b" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">这有一个额外的参数，称为膨胀率。这种技术用于增加卷积中的感受野。这个卷积也称为 atrous 卷积。膨胀率为 2 的 3×3 卷积与简单的 5×5 卷积显示相同的面积，而只有 9 个参数。它可以在相同的计算成本下提供更宽的视野。只有在需要宽视野以及无法承受多重卷积或更大内核的情况下，才应该使用它们。下图描绘了一个扩张的卷积的可接受范围。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/e878cfb40d4318d4a43f09bbd59c8250.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/0*GjKQ3gJMB_3mwlee.gif"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">放大卷积，图像由<a class="ae ni" href="https://towardsdatascience.com/@pietz?source=post_page-----717013397f4d----------------------" rel="noopener" target="_blank">Paul-Louis prve</a></p></figure><h1 id="ef57" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">转置卷积</h1><p id="ca7b" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">用于增加输出要素地图的大小。它被用在编码器-解码器网络中以增加空间维度。在卷积运算之前，输入图像被适当地填充。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nj"><img src="../Images/5bc5aa514893ec1a814af7bb45728d5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FFoOM6TLOOe_Fd1Y.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">转置卷积，图像由<a class="ae ni" href="https://towardsdatascience.com/@mdivyanshu.ai?source=post_page-----84ca81b4baba----------------------" rel="noopener" target="_blank"> Divyanshu Mishra </a></p></figure><h1 id="13b1" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">结束了</h1><p id="33aa" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">谢谢，请继续关注更多关于人工智能的博客。</p></div></div>    
</body>
</html>