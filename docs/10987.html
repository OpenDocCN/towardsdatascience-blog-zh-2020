<html>
<head>
<title>Understanding the state of natural language technology through a project-first approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过项目优先的方法理解自然语言技术的现状</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hacking-my-way-to-understand-the-state-of-natural-language-technology-178055e510da?source=collection_archive---------52-----------------------#2020-07-30">https://towardsdatascience.com/hacking-my-way-to-understand-the-state-of-natural-language-technology-178055e510da?source=collection_archive---------52-----------------------#2020-07-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="31ba" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">当人工智能遇到语言</h2><div class=""/><div class=""><h2 id="4b18" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">蓝图，以实际操作的方式了解自然语言技术的最新进展。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/cc9aa4fc7cd335d92a7aefee129f8b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F0KXZBAJk9PgPtUD.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://commons.wikimedia.org/wiki/File:Bios_robotlab_writing_robot.jpg" rel="noopener ugc nofollow" target="_blank">维基媒体</a></p></figure><p id="97b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">注意:涵盖的主题包括转换器、语言模型(BERT，GPT-2)、评估基准和对话界面(聊天机器人)。</em></p><p id="5143" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2020 年 6 月初，我决定了解 NLP(自然语言处理)的现状，以及相应的(狭义)人工智能的角色。我通常理解一个主题的方法是自下而上的。在开始一个项目之前，彻底理解基本原理。受时间的限制，也受像<a class="ae lh" href="https://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> Fast AI </a>这样的人推广的教学法的启发，我决定先做项目。</p><p id="900c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">旁注:从知识的角度来看，我已经习惯了</em> <a class="ae lh" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank"> <em class="me">机器学习</em></a><em class="me"/><a class="ae lh" href="https://www.akashtandon.in/ai/2020-07-30-hacking-to-understand-language-technology/neuralnetworksanddeeplearning.com/" rel="noopener ugc nofollow" target="_blank"><em class="me">神经网络</em></a><em class="me"/><a class="ae lh" href="https://pydata.org/" rel="noopener ugc nofollow" target="_blank"><em class="me">PyData</em></a><em class="me">栈和</em> <a class="ae lh" href="https://medium.com/hackernoon/a-tale-of-cloud-containers-and-kubernetes-b6fb18edcfcd" rel="noopener"> <em class="me">云计算</em> </a> <em class="me">。如果你计划复制这种方法，请记住这一点。</em></p><p id="37c4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文提供了项目和潜在动机的更高层次的概述。你可以决定追寻或复制这条道路。我可能会决定写一些个人作品。现在，我总结一下我的经历和学习。</p><h1 id="d185" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">入门指南</h1><p id="546c" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">我最初的项目列表如下:</p><ul class=""><li id="83de" class="nc nd it lk b ll lm lo lp lr ne lv nf lz ng md nh ni nj nk bi translated">利用 OpenAI 的<a class="ae lh" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a>更好地理解语言模型的项目</li><li id="0c0a" class="nc nd it lk b ll nl lo nm lr nn lv no lz np md nh ni nj nk bi translated">一个 ML 驱动的聊天机器人，目的是更好地了解 NLU</li><li id="d65d" class="nc nd it lk b ll nl lo nm lr nn lv no lz np md nh ni nj nk bi translated">一个记录和分析音频对话(在线或电话)的工具</li></ul><p id="d6e8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">注:在我开始这个项目一周后， <a class="ae lh" href="https://openai.com/blog/openai-api/" rel="noopener ugc nofollow" target="_blank"> <em class="me"> OpenAI 发布了他们的 API </em> </a> <em class="me">。如果你被流言所迷惑，下一部分可能会特别有趣。</em></p><p id="f599" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这份名单是有意开放的。计划是做感兴趣的项目，并在此过程中完善想法。选择探索 GPT-2 语言模型是因为有丰富的相关学习资源和讨论。围绕前两组想法的实验描述如下。我还没有机会开始写第三部。</p><h1 id="0da6" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">玩弄 GPT-2</h1><p id="8e8f" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">GPT-2 出现在 2018–19 年 NLP 中<a class="ae lh" href="https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04" rel="noopener"> transformer 架构</a>和<a class="ae lh" href="https://ruder.io/nlp-imagenet/" rel="noopener ugc nofollow" target="_blank">转移学习出现期间。迁移学习是一个强有力的概念。它允许预先训练的大型神经网络(在这种情况下是语言模型)为下游任务进行微调。这省去了从业者从头重新训练整个模型的麻烦。这种灵活性是语言模型成功的一个重要原因。</a></p><p id="6c79" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">开始时，我四处寻找现有的 GPT-2 项目进行复制。就在那时，我偶然发现了 Max Woolf 的相关<a class="ae lh" href="https://github.com/minimaxir/gpt-2-simple" rel="noopener ugc nofollow" target="_blank"> Python 包。他的作品让初学者也能轻松入门。就在那时，我决定做一个模仿 Twitter 的机器人作为第一个项目。</a></p><h2 id="a8eb" class="nq mg it bd mh nr ns dn ml nt nu dp mp lr nv nw mr lv nx ny mt lz nz oa mv iz bi translated">模仿推特机器人</h2><p id="43fc" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">推特用户 dril 的一个模仿机器人在 2019 年变得流行起来。它是由一个 GPT-2 模型驱动的，这个模型是在 dril 的推特上微调的。<br/>本着同样的精神，我制作了一个模仿机器人账户，该账户由 5 个不同的模仿账户组成。这些角色包括伊丽莎白女王、伏地魔、达斯·维德和无聊的埃隆·马斯克。为了获取推文，我使用了令人惊叹的 twint 包。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/c5800a071325ce0da38f38c22163cacb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7_mfCU2xeiyal0Qu.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">艾的多面性</p></figure><p id="3207" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最终的机器人账户被命名为<a class="ae lh" href="https://twitter.com/ai_gpt2" rel="noopener ugc nofollow" target="_blank">女王达斯·伏地魔·马斯克，这是他们名字的第一个</a>。是的，你没看错。</p><p id="4222" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">复制这个项目所需的信息可以在<a class="ae lh" href="https://minimaxir.com/2020/01/twitter-gpt2-bot/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="c1a2" class="nq mg it bd mh nr ns dn ml nt nu dp mp lr nv nw mr lv nx ny mt lz nz oa mv iz bi translated">变形金刚，伯特和 GPT-2</h2><p id="8cc5" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">然后，我走了一点弯路，阅读了 GPT-2 和 NLP 中的迁移学习背后的理论。BERT 是另一个不断出现的语言模型。GPT 和伯特都是基于变压器架构。然而，伯特只有编码器模块，而 GPT-2 只有来自变压器的解码器模块。这使得它们更适合不同类型的任务。<br/>试图理解这两种流行模型的技术差异和功能是一项有益的工作。我强烈建议这样做！</p><p id="11df" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以下是围绕这个话题的一些相关链接:</p><ul class=""><li id="5f85" class="nc nd it lk b ll lm lo lp lr ne lv nf lz ng md nh ni nj nk bi translated"><a class="ae lh" href="https://ruder.io/nlp-imagenet/" rel="noopener ugc nofollow" target="_blank"> NLP 的 ImageNet 时刻已经到来</a></li><li id="f4d4" class="nc nd it lk b ll nl lo nm lr nn lv no lz np md nh ni nj nk bi translated"><a class="ae lh" href="https://eigenfoo.xyz/transformers-in-nlp/" rel="noopener ugc nofollow" target="_blank">NLP 中的变压器——简介</a></li><li id="a184" class="nc nd it lk b ll nl lo nm lr nn lv no lz np md nh ni nj nk bi translated"><a class="ae lh" href="https://www.kaggle.com/residentmario/transformer-architecture-self-attention" rel="noopener ugc nofollow" target="_blank">变压器架构说明</a></li><li id="871a" class="nc nd it lk b ll nl lo nm lr nn lv no lz np md nh ni nj nk bi translated"><a class="ae lh" href="https://www.kaggle.com/residentmario/notes-on-gpt-2-and-bert-models" rel="noopener ugc nofollow" target="_blank">关于 GPT-2 和伯特的笔记</a></li></ul><p id="b0bf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个弯路也让我有了下一个项目的想法。</p><h1 id="f613" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">评估 NLP 基准</h1><p id="c235" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">机器学习的胜利与它们在标准基准上的表现息息相关。即使你不是一名研究人员，也知道像<a class="ae lh" href="https://gluebenchmark.com/" rel="noopener ugc nofollow" target="_blank"> GLUE </a>这样的基准会给你关于该领域的重要见解。如果你着手对比 BERT 和 GPT-2，即使没有深入的专业知识，看看他们被评估的基准会让你知道他们适合的问题。这对从业者是有帮助的。</p><p id="b4fc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">NLP 基准，如 GLUE 和<a class="ae lh" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank">小队</a>由多个任务组成。不同的任务测试语言不同方面的熟练程度，如<a class="ae lh" href="https://en.wikipedia.org/wiki/Named-entity_recognition" rel="noopener ugc nofollow" target="_blank">实体识别</a>、<a class="ae lh" href="https://en.wikipedia.org/wiki/Question_answering" rel="noopener ugc nofollow" target="_blank">问答</a>和<a class="ae lh" href="https://nlp.stanford.edu/projects/coref.shtml" rel="noopener ugc nofollow" target="_blank">共指消解</a>。结合起来，他们测试 T21 的一般语言理解能力。</p><p id="8efb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于这个项目，我有两个目标:</p><ul class=""><li id="7108" class="nc nd it lk b ll lm lo lp lr ne lv nf lz ng md nh ni nj nk bi translated">从相关基准中至少评估一项伯特和 GPT 新协议</li><li id="4102" class="nc nd it lk b ll nl lo nm lr nn lv no lz np md nh ni nj nk bi translated">根据流行的基准实现各种任务</li></ul><p id="33a1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了实现，我通过 HuggingFace 使用了<a class="ae lh" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank"> transformers </a> Python 库。我将很快发布相关的笔记本，希望能写更多关于这个子主题的内容。</p><p id="ed28" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">同时，这里有一些有用的链接:</p><ul class=""><li id="a19e" class="nc nd it lk b ll lm lo lp lr ne lv nf lz ng md nh ni nj nk bi translated"><a class="ae lh" href="https://mccormickml.com/2019/11/05/GLUE/" rel="noopener ugc nofollow" target="_blank"> GLUE 解释:通过基准测试了解 BERT】</a></li><li id="ff44" class="nc nd it lk b ll nl lo nm lr nn lv no lz np md nh ni nj nk bi translated"><a class="ae lh" href="https://www.youtube.com/watch?v=uz_eYqutEG4" rel="noopener ugc nofollow" target="_blank">视频 NLP 的最新技术</a></li><li id="f80a" class="nc nd it lk b ll nl lo nm lr nn lv no lz np md nh ni nj nk bi translated">为什么 GPT-2 不在 GLUE leadership 董事会上？</li><li id="8536" class="nc nd it lk b ll nl lo nm lr nn lv no lz np md nh ni nj nk bi translated"><a class="ae lh" href="https://huggingface.co/transformers/examples.html#the-big-table-of-tasks" rel="noopener ugc nofollow" target="_blank">hugging face 的(NLP)任务大表</a></li></ul><h1 id="f871" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">实用 NLU:对话界面</h1><p id="65de" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">对话界面变得越来越普遍。对于面向消费者的应用来说，它们将变得越来越重要。对于新兴经济体来说尤其如此，在那里，语音优先界面可以为新的互联网用户增加巨大的价值。</p><p id="8e65" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我在思考对话界面时，我遇到了 Rasa 的一个<a class="ae lh" href="https://www.l3-ai.dev/" rel="noopener ugc nofollow" target="_blank">在线活动。我参加了一些会谈。他们帮助我从一个开发者的角度获得了一种直觉。在那之后，我对语音界面的偏好帮助我选择了下一个项目。</a></p><h2 id="f666" class="nq mg it bd mh nr ns dn ml nt nu dp mp lr nv nw mr lv nx ny mt lz nz oa mv iz bi translated">AI 语音助手</h2><p id="51ec" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">对于这一次，我只是按照一个伟大的教程端到端。下面是— <a class="ae lh" href="https://blog.rasa.com/how-to-build-a-voice-assistant-with-open-source-rasa-and-mozilla-tools/" rel="noopener ugc nofollow" target="_blank">如何用开源的 Rasa 和 Mozilla 工具构建语音助手</a>。</p><p id="6f7f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在此实现的大多数功能都作为托管服务提供。就个人选择而言，我选择从开源工具开始。当然，在考虑生产场景时，需要考虑权衡。</p><p id="06c3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Rasa 已经开发了丰富的资源和活跃的社区。他们非常有帮助。</p><h2 id="8ebf" class="nq mg it bd mh nr ns dn ml nt nu dp mp lr nv nw mr lv nx ny mt lz nz oa mv iz bi translated">客服聊天机器人</h2><p id="2262" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">使用过开源工具后，我想尝试一下托管服务。像 GCP、AWS、Azure 和 IBM 这样的公司提供了选择。我选择了谷歌的<a class="ae lh" href="https://www.akashtandon.in/ai/2020-07-30-hacking-to-understand-language-technology/dialogflow.cloud.google.com/" rel="noopener ugc nofollow" target="_blank">对话流</a>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/fdb29cbd812479163a7890e2348e4bbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/0*yRzD3rwQtNUlHZu7.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">你友好的邻居银行机器人</p></figure><p id="0c44" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦你熟悉了基本原理，比如意图和动作，构建一个机器人就简单了。预训练的机器人是一个方便的功能，但导入它们并不是一个流畅的体验。每个项目一个机器人的特性和它出现的延迟让我困惑了几分钟。</p><h1 id="5b87" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">总结想法</h1><p id="5f51" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">进行上述实验是一次有趣的经历。有时，我渴望深入主题。选择放手让我探索手边的广度。这也让我可以在日程安排中挤出一些简短的黑客会议。</p><p id="bfc7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最近在自然语言处理领域有了一些令人兴奋的发展。在新兴经济体中，语音作为一种界面正越来越多地被采用。提高机器对语言的理解也将促进技术的民主化。</p><p id="7972" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">与此同时，我们需要对其局限性持现实态度。OpenAI 的 GPT-3 驱动的 API 的用例已经像病毒一样传播开来。以至于他们的首席执行官萨姆·奥尔特曼发了一条讽刺性的推特来谈论这种炒作。<br/> Rasa 提出了对话式人工智能 5 个层次的概念。他们还提到，我们也许离第五层还有十年。</p><p id="6564" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">语言是人类进步的关键。通过新兴技术的视角来探索它是一项有趣的尝试。我希望创新的列车将以负责任的方式继续前行。<br/>如果你想进行讨论或分享想法，请随时联系我们。</p></div><div class="ab cl od oe hx of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="im in io ip iq"><p id="f77e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">原载于 2020 年 7 月 30 日</em><a class="ae lh" href="https://www.akashtandon.in/ai/2020-07-30-hacking-to-understand-language-technology/" rel="noopener ugc nofollow" target="_blank"><em class="me">https://www . akashtandon . in</em></a><em class="me">。</em></p></div></div>    
</body>
</html>