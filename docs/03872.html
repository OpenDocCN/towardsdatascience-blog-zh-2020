<html>
<head>
<title>Instance Hardness Threshold: An Undersampling Method to Tackle Imbalanced Classification Problems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实例硬度阈值:一种解决不平衡分类问题的欠采样方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/instance-hardness-threshold-an-undersampling-method-to-tackle-imbalanced-classification-problems-6d80f91f0581?source=collection_archive---------35-----------------------#2020-04-10">https://towardsdatascience.com/instance-hardness-threshold-an-undersampling-method-to-tackle-imbalanced-classification-problems-6d80f91f0581?source=collection_archive---------35-----------------------#2020-04-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8a53" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从多数类中移除“困难”样本</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e2678733032ba362989b2e21fe7681d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mSCqnIuR3RVXDv-8"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">卡洛斯·埃斯特韦斯在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片|钻石是坚硬的——样品也可能是坚硬的</p></figure><p id="5c49" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你认真看过<a class="ae kv" href="https://www.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank">吴恩达在Coursera </a>上的深度学习课程，你可能就知道错误分析需要什么了。Andrew提倡在确定需要改进的地方并相应地修改系统之前，快速构建第一个工作系统。找出分类系统改进领域的一种方法是通过对错误分类样本的研究。对于Andrew作为例子使用的猫图像分类器，大型猫的图像可能经常被错误分类。在这方面，大猫样本是<em class="ls">硬的。</em></p><p id="3141" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于机器学习从业者来说，<em class="ls">‘硬’</em>这个术语太模糊，无法描述单个样本(即实例)。迈克尔·史密斯、托尼·马丁内斯和克里斯托夫·吉罗德·卡里尔肯定也遇到了这个问题，他们写了一篇名为<a class="ae kv" href="https://link.springer.com/article/10.1007/s10994-013-5422-z" rel="noopener ugc nofollow" target="_blank"> <em class="ls">数据复杂性的实例级分析</em> </a> <em class="ls">的研究文章。</em>在这篇文章中，他们基于一组选定的学习算法的分类行为，提出了实例难度的经验定义。</p><p id="af4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为什么要有一套学习算法？作者解释说，样本的错误分类取决于所使用的学习算法以及样本与其对应样本之间的关系。实例硬度的概念是相对的；将在同一实例上应用一组不同且实用的学习算法的结果聚集在一起具有泛化效果。</p><h1 id="3a4f" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">实例硬度的定义(IH)</h1><p id="6126" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">史密斯、马丁内兹和吉罗-卡里尔在他们的文章中对IH给出了严格的表述。强烈鼓励那些不回避数学符号的人看一看它。</p><p id="d3a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">粗略地说，作者事先选择了一组选定的<em class="ls"> n </em>学习算法，并在训练集上逐一应用它们。这样，<em class="ls"> n </em>个量词就产生了。对于单个实例(即样本)，可以使用指示函数和分类器分数来估计分类器<em class="ls"> i </em>向其分配正确标签的概率<em class="ls">pi(I的范围从1到n) </em>。取<em class="ls"> n </em>个估计量的<em class="ls"> P_i </em>的平均值，我们得到了正确分类这种情况的可能性。IH，错误分类实例的可能性，因此将是1减去这个平均值。</p><h1 id="a421" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">为什么硬实例很难分类</h1><p id="490e" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在论文中，作者还继续研究了为什么硬实例很难分类。他们对19万个样本的实验结果显示，类别重叠对IH的影响最大。</p><p id="8756" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图举例说明了类别重叠的含义:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/324c923617048fa7eb2948687af1bfa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VuvGE8N4bt1V8sMsxOEzXg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">左:没有类重叠问题；右图:出现班级重叠(这两张图片是我自己的)</p></figure><p id="0e1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当样本空间中的一个区域包含来自另一个类别的样本时，就会发生类别重叠。重叠样品具有高的实例硬度。<strong class="ky ir">当数据集中同时出现类别不平衡和类别重叠时，分类问题变得更加困难。</strong></p><h1 id="5831" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">一举两得——IHT</h1><p id="909e" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">实例硬度阈值(IHT)是一种欠采样方法，用于通过移除硬样本来缓解类别不平衡。在此基础上，本文提出了一个非均衡学习图书馆IHT的实现方案。<strong class="ky ir">分类概率低的样本将从数据集中删除。</strong>之后，将在欠采样数据的基础上建立模型。</p><p id="4c07" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们检查一下<em class="ls"> imblearn.under_sampling的关键参数。InstanceHardnessThreshold: </em></p><ul class=""><li id="45c2" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr mw mx my mz bi translated"><em class="ls">估计器</em>:估计样本IH的学习算法。只需要一个估计器，默认算法是随机森林。</li><li id="2c5e" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated"><em class="ls"> sampling_strategy </em>:用户并没有真正指定实例硬度的阈值。相反，这里的采样策略更注重结果。当提供浮点数时，它将是IHT算法输出的少数类样本与多数类样本的比率。如果提供了一个字符串，相应的类将成为欠采样的目标。用户甚至可以输入一个字典来指定每个类输出的样本数。</li><li id="24f1" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated"><em class="ls"> cv </em>:评估样品实例硬度时使用的交叉验证折叠数。</li></ul><h1 id="b2aa" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">在现实生活中的一个问题上尝试IHT:欺诈检测</h1><p id="1aa7" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">类似于<a class="ae kv" href="https://medium.com/swlh/tree-based-machine-learning-models-for-handling-imbalanced-datasets-26560b5865f6" rel="noopener">我之前关于处理不平衡数据集的文章</a>，我将使用来自<a class="ae kv" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank"> kaggle </a>的信用卡交易数据集来演示使用IHT的代码。数据集极度不平衡；在284，807笔交易中，只有492笔欺诈。80%的事务将从决策树分类器(max_depth=5)中学习，20%的事务将形成测试集。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="0ec9" class="nk lu iq ng b gy nl nm l nn no">from sklearn.tree import DecisionTreeClassifier<br/>dt = DecisionTreeClassifier(max_depth=5,random_state=42)<br/>dt.fit(X_train, y_train)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/9f941f0ad6eda939489e8009bd1a21ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*Bd9r3pbap9Edd95KPGfz2w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">决策树应用于测试集时的分类结果</p></figure><p id="f56b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们使用分类器<em class="ls"> dt </em>作为估计器来估计样本的IH。对于使用IHT方法进行欠采样，直到多数类与少数类的比率为0.0019，并计算该变换前后训练集的形状:</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="a196" class="nk lu iq ng b gy nl nm l nn no">from imblearn.under_sampling import InstanceHardnessThreshold<br/>from collections import Counter</span><span id="7e2c" class="nk lu iq ng b gy nq nm l nn no">print('Original test dataset shape %s' % Counter(y_train))<br/>iht = InstanceHardnessThreshold(estimator=dt, sampling_strategy='majority', random_state=42)<br/>X_train_res, y_train_res = iht.fit_resample(X_train, y_train)<br/>print('Resampled dataset shape %s' % Counter(y_train_res))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/b9122a1f9ccfc1ebefb98cc4d2d817ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*51hps-u6UeQllo5AUgXTQQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">类别分布</p></figure><p id="4d3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如上面的输出所示，从多数类中移除了2328个样本。少数类样本保持不变。</p><p id="59aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，将max_depth为5的决策树拟合到重新采样的数据集:</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="8158" class="nk lu iq ng b gy nl nm l nn no">dt_new = DecisionTreeClassifier(max_depth=5,random_state=42)<br/>dt_new.fit(X_train_res, y_train_res)</span></pre><p id="d285" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分类结果是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/6414f7292ad8cefc49b9f69ad8bc0e1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*4BC4Lo4MmhEkrHpDwumz3A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">当新的决策树分类器被应用于测试数据集时</p></figure><p id="a2ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">新的决策树分类器在分类少数类样本方面具有与旧的相似的能力。然而，更多的正常交易被归类为欺诈，这导致精确度下降。由IHT去除的样本可能携带有帮助分类器识别正常交易更好者的信息。</p><p id="bb34" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然IHT对于这个特殊的问题不是很有效，但是希望通过代码片段，那些不熟悉这种欠采样方法的人可以很容易地掌握它。</p></div><div class="ab cl nt nu hu nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="ij ik il im in"><h1 id="a909" class="lt lu iq bd lv lw oa ly lz ma ob mc md jw oc jx mf jz od ka mh kc oe kd mj mk bi translated">结论</h1><p id="00e8" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">实例硬度阈值(IHT)是一种相当特殊的欠采样方法，其方法是移除与少数类样本空间重叠的多数类样本。这篇文章介绍了IHT的基础知识，并展示了如何实现它来解决不平衡的类问题。</p><p id="3e03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">谢谢你读了这个故事！</p><p id="9812" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls">参考文献</em> </strong></p><ol class=""><li id="de7a" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr of mx my mz bi translated">数据复杂性的实例级分析。<em class="ls">马赫学</em> <strong class="ky ir"> 95，</strong>225–256(2014)。<a class="ae kv" href="https://doi.org/10.1007/s10994-013-5422-z" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1007/s10994-013-5422-z</a></li><li id="bd7b" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr of mx my mz bi translated">不平衡学习库中InstanceHardnessThreshold的文档:<a class="ae kv" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.InstanceHardnessThreshold.html#r2bfe4eaac981-1" rel="noopener ugc nofollow" target="_blank">https://不平衡学习. readthedocs . io/en/stable/generated/imb learn . under _ sampling。instance hardness threshold . html # r 2 bfe 4 eaac 981-1</a></li></ol></div></div>    
</body>
</html>