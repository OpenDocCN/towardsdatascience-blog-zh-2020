<html>
<head>
<title>Data Science Quick Tip #004: Using Custom Transformers in Scikit-Learn Pipelines!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">æ•°æ®ç§‘å­¦å¿«é€Ÿæç¤º#004:åœ¨ Scikit ä¸­ä½¿ç”¨è‡ªå®šä¹‰è½¬æ¢å™¨-å­¦ä¹ ç®¡é“ï¼</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/data-science-quick-tip-004-using-custom-transformers-in-scikit-learn-pipelines-89c28c72f22a?source=collection_archive---------37-----------------------#2020-08-30">https://towardsdatascience.com/data-science-quick-tip-004-using-custom-transformers-in-scikit-learn-pipelines-89c28c72f22a?source=collection_archive---------37-----------------------#2020-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/e23a790849d2a19366fe76a1b313f950.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cYkhezJ0OELuP3OjYEDj3Q.png"/></div></div></figure><div class=""/><div class=""><h2 id="161a" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">äº†è§£å¦‚ä½•åœ¨åŒä¸€ä¸ª Scikit-Learn ç®¡é“ä¸­ä½¿ç”¨å®šåˆ¶æ•°æ®è½¬æ¢å™¨</h2></div><p id="fc8a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">å¤§å®¶å¥½ã€‚å…³äºå¦‚ä½•åˆ›å»º Scikit-Learn ç®¡é“ï¼Œæˆ‘ä»¬åˆå›æ¥äº†ï¼Œè¿™æ˜¯ä¸Šä¸€ç¯‡æ–‡ç« çš„åç»­æ–‡ç« ã€‚å¦‚æœä½ é”™è¿‡äº†ï¼Œä½ ç°åœ¨å¯ä»¥ç‚¹å‡»é“¾æ¥æŸ¥çœ‹<a class="ae lp" rel="noopener" target="_blank" href="/data-science-quick-tip-003-using-scikit-learn-pipelines-66f652f26954">ã€‚(å®ƒç°åœ¨æ­£å¼å‘å¸ƒåˆ°ã€Šèµ°å‘æ•°æ®ç§‘å­¦ã€‹ã€‚w00tï¼)å’Œå¾€å¸¸ä¸€æ ·ï¼Œå¦‚æœä½ æƒ³ç›´æ¥è·Ÿéšè¿™ç¯‡æ–‡ç« çš„ä»£ç ï¼Œä½ å¯ä»¥åœ¨æˆ‘çš„ä¸ªäºº GitHub </a>æ‰¾åˆ°<a class="ae lp" href="https://github.com/dkhundley/ds-quick-tips/tree/master/004_pipeline_custom_transformers" rel="noopener ugc nofollow" target="_blank">ã€‚</a></p><p id="c70f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">ä¸ºäº†å¿«é€Ÿç»“æŸä¸Šä¸€ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬å·²ç»æˆåŠŸåœ°åˆ›å»ºäº†ä¸€ä¸ª Scikit-Learn ç®¡é“ï¼Œå®ƒåœ¨ä¸€ä¸ªå¹²å‡€çš„å°åŒ…ä¸­å®Œæˆäº†æ‰€æœ‰çš„æ•°æ®è½¬æ¢ã€ç¼©æ”¾å’Œæ¨ç†ã€‚ä½†æ˜¯åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸å¾—ä¸åœ¨æˆ‘ä»¬çš„ç®¡é“ä¸­ä½¿ç”¨ Scikit-Learn çš„é»˜è®¤è½¬æ¢å™¨ã€‚è™½ç„¶è¿™äº›å˜å½¢é‡‘åˆšå¾ˆæ£’ï¼Œä½†æ˜¯å¦‚æœæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è‡ªå·±çš„è‡ªå®šä¹‰å˜å½¢ï¼Œé‚£ä¸æ˜¯å¾ˆæ£’å—ï¼Ÿå½“ç„¶äº†ï¼æˆ‘è®¤ä¸ºè¿™ä¸ä»…å¾ˆæ£’ï¼Œè€Œä¸”å¾ˆæœ‰å¿…è¦ã€‚å¦‚æœä½ è¿˜è®°å¾—ä¸Šå‘¨çš„å¸–å­ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªåŸºäºå•ä¸€ç‰¹å¾çš„æ¨¡å‹ã€‚é‚£å¯ä¸å¤ªå¥½é¢„æµ‹å•Šï¼</p><p id="1cf0" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">å› æ­¤ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ·»åŠ ä¸¤ä¸ªè½¬æ¢å™¨æ¥è½¬æ¢è®­ç»ƒæ•°æ®é›†ä¸­çš„ä¸¤ä¸ªé¢å¤–å­—æ®µï¼Œä»è€Œè§£å†³è¿™ä¸€é—®é¢˜ã€‚(æˆ‘çŸ¥é“ï¼Œä» 1 ä¸ªåŠŸèƒ½å¢åŠ åˆ° 3 ä¸ªåŠŸèƒ½ä»ç„¶ä¸æ˜¯å¾ˆå¥½ã€‚ä½†æ˜¯ï¼Œå˜¿ï¼Œè‡³å°‘æˆ‘ä»¬å¢åŠ äº† 300%ï¼Ÿ)æˆ‘ä»¬å¼€å§‹æ—¶çš„åŸå§‹å˜é‡æ˜¯â€œæ€§åˆ«â€(åˆåæ€§åˆ«)ï¼Œç°åœ¨æˆ‘ä»¬å°†ä¸ºé€‚å½“çš„â€œå¹´é¾„â€åˆ—å’Œâ€œä¸Šèˆ¹â€åˆ—æ·»åŠ  transformersã€‚</p><p id="87e3" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">åœ¨æˆ‘ä»¬å¼€å§‹æ–°çš„å®šåˆ¶å˜å½¢é‡‘åˆšä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆå¯¼å…¥åº“ã€‚ä½ å¯èƒ½è¿˜è®°å¾—ä¸Šä¸€ç¯‡æ–‡ç« ä¸­çš„è®¸å¤šå†…å®¹ï¼Œä½†æ˜¯æˆ‘ä»¬å¢åŠ äº†ä¸€äº›é¢å¤–çš„å†…å®¹ã€‚ä¸è¦å¤ªæ‹…å¿ƒå®ƒä»¬ç°åœ¨æ˜¯ä»€ä¹ˆï¼Œå› ä¸ºæˆ‘ä»¬å°†åœ¨åé¢çš„æ–‡ç« ä¸­è¿›ä¸€æ­¥è®¨è®ºã€‚</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="9b43" class="lz ma je lv b gy mb mc l md me"># Importing the libraries weâ€™ll be using for this project<br/>import pandas as pd<br/>import joblibfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.compose import ColumnTransformer<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix</span></pre><p id="468a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">æˆ‘ä»¬å°†ç»§ç»­å¿«é€Ÿå¯¼å…¥æˆ‘ä»¬çš„åŸ¹è®­æ•°æ®ã€‚</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="ddcd" class="lz ma je lv b gy mb mc l md me"># Importing the training dataset<br/>raw_train = pd.read_csv(â€˜../data/titanic/train.csvâ€™)</span><span id="6c08" class="lz ma je lv b gy mf mc l md me"># Splitting the training data into appropriate training and validation sets<br/>X = raw_train.drop(columns = [â€˜Survivedâ€™])<br/>y = raw_train[[â€˜Survivedâ€™]]</span><span id="146e" class="lz ma je lv b gy mf mc l md me">X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 42)</span></pre><p id="86db" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">å¥½äº†ï¼Œä»ç°åœ¨å¼€å§‹ï¼Œæˆ‘ä»¬å®é™…ä¸Šä¸ä¼šæ”¹å˜ Scikit-Learn ç®¡é“æœ¬èº«ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬ä¼šå¯¹å…¶è¿›è¡Œæ·»åŠ ï¼Œä½†æ˜¯è¯·è®°ä½ï¼Œæˆ‘æœ‰æ„å°†æˆ‘çš„æ•°æ®é¢„å¤„ç†å™¨è®¾è®¡æˆæ˜“äºæ·»åŠ çš„æ–¹å¼ã€‚ç®€å•å›é¡¾ä¸€ä¸‹ä¸Šä¸€ç¯‡æ–‡ç« ï¼Œä¸‹é¢æ˜¯æ„å»ºåŸå§‹ç®¡é“çš„ä»£ç ã€‚</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="7adb" class="lz ma je lv b gy mb mc l md me"># Creating a preprocessor to transform the â€˜Sexâ€™ column<br/>data_preprocessor = ColumnTransformer(transformers = [<br/>   (â€˜sex_transformerâ€™, OneHotEncoder(), [â€˜Sexâ€™])<br/>])</span><span id="31cf" class="lz ma je lv b gy mf mc l md me"># Creating our pipeline that first preprocesses the data, then scales the data, then fits the data to a RandomForestClassifier<br/>rfc_pipeline = Pipeline(steps = [<br/>   (â€˜data_preprocessingâ€™, data_preprocessor),<br/>   (â€˜data_scalingâ€™, StandardScaler()),<br/>   (â€˜modelâ€™, RandomForestClassifier(max_depth = 10,<br/>                                    min_samples_leaf = 3,<br/>                                    min_samples_split = 4,<br/>                                    n_estimators = 200))<br/>])</span></pre><p id="ed10" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">å½“ç„¶ï¼Œåœ¨å°†è‡ªå®šä¹‰è½¬æ¢å™¨æ·»åŠ åˆ°ç®¡é“ä¹‹å‰ï¼Œæˆ‘ä»¬å¯ä»¥åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯åˆ›å»ºå‡½æ•°è½¬æ¢å™¨ï¼å› æ­¤ï¼Œæ­£å¦‚æ‚¨å¯èƒ½å·²ç»çŒœåˆ°çš„é‚£æ ·ï¼Œå®šåˆ¶è½¬æ¢å™¨æ˜¯å»ºç«‹åœ¨å¸¸è§„å‡½æ•°ä¹‹ä¸Šçš„ï¼Œå› æ­¤æ‚¨å¯ä»¥ä¸ºè½¬æ¢å™¨ç¼–å†™ä»»ä½•æ‚¨æƒ³è¦çš„ Python å‡½æ•°ã€‚****(æˆ‘ä»¬ç¨åå°†è®¨è®ºæ‰€æœ‰è¿™äº›æ˜Ÿå·â€¦â€¦)</p><p id="6261" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">å¥½äº†ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¸ºä¸¤ä¸ªæ–°å˜é‡æ·»åŠ ä¸¤ä¸ªè½¬æ¢å™¨ï¼Œç°åœ¨è®©æˆ‘ä»¬å¼€å§‹åˆ›å»ºä¸¤ä¸ªè‡ªå®šä¹‰ Python å‡½æ•°å§ï¼é¦–å…ˆè§¦åŠâ€œå¹´é¾„â€åˆ—ï¼Œæˆ‘ä»¬å°†å¯¹è¿™ä¸ªå˜é‡æœ‰ä¸€ç‚¹é¢å¤–çš„ä¹è¶£ã€‚ç°åœ¨ï¼Œæˆ‘çœŸçš„ä¸çŸ¥é“å¹´é¾„æœ¬èº«æ˜¯å¦æ˜¯ä¸€ä¸ªé¢„æµ‹å˜é‡ï¼Œä½†æˆ‘çŒœæƒ³ï¼Œå¦‚æœâ€œå¹´é¾„â€å¯ä»¥ä»¥ä»»ä½•æœ‰æ„ä¹‰çš„æ–¹å¼é¢„æµ‹ï¼Œå®ƒå°†æ˜¯å¹´é¾„ç±»åˆ«/å¹´é¾„ç®±ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘å°†å¹´é¾„åˆ’åˆ†ä¸ºâ€œå„¿ç«¥â€ã€â€œæˆäººâ€ã€â€œè€äººâ€ç­‰ç±»åˆ«ã€‚åŒæ ·ï¼Œæˆ‘ä¸çŸ¥é“è¿™æ˜¯å¦ä¼šæ¯”ä½¿ç”¨ç›´æ¥æ•´æ•°æ›´æœ‰æ€§èƒ½ï¼Œä½†å®ƒè®©æˆ‘ä»¬å¯ä»¥åšä¸€äº›æœ‰è¶£çš„äº‹æƒ…ï¼ä¸‹é¢æ˜¯è¿™æ ·çš„ä»£ç :</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="adae" class="lz ma je lv b gy mb mc l md me"># Creating a function to appropriately engineer the â€˜Ageâ€™ column<br/>def create_age_bins(col):<br/>    â€˜â€™â€™Engineers age bin variables for pipelineâ€™â€™â€™<br/> <br/>    # Defining / instantiating the necessary variables<br/>    age_bins = [-1, 12, 18, 25, 50, 100]<br/>    age_labels = [â€˜childâ€™, â€˜teenâ€™, â€˜young_adultâ€™, â€˜adultâ€™, â€˜elderâ€™]<br/>    age_imputer = SimpleImputer(strategy = â€˜medianâ€™)<br/>    age_ohe = OneHotEncoder()<br/> <br/>    # Performing basic imputation for nulls<br/>    imputed = age_imputer.fit_transform(col)<br/>    ages_filled = pd.DataFrame(data = imputed, columns = [â€˜Ageâ€™])<br/> <br/>    # Segregating ages into age bins<br/>    age_cat_cols = pd.cut(ages_filled[â€˜Ageâ€™], bins = age_bins, labels = age_labels)<br/>    age_cats = pd.DataFrame(data = age_cat_cols, columns = [â€˜Ageâ€™])<br/> <br/>    # One hot encoding new age bins<br/>    ages_encoded = age_ohe.fit_transform(age_cats[[â€˜Ageâ€™]])<br/>    ages_encoded = pd.DataFrame(data = ages_encoded.toarray())<br/> <br/>    return ages_encoded</span></pre><p id="2ebb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">å¥½äº†ï¼Œæ¥ä¸‹æ¥æ˜¯â€œä¸Šèˆ¹â€ä¸“æ ã€‚ç°åœ¨ï¼Œè¿™å·²ç»*å‡ ä¹*å‡†å¤‡å¥½è¿›è¡Œç›´æ¥çš„çƒ­ç¼–ç äº†ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸èƒ½ç›´æ¥è·³åˆ°é‚£é‡Œçš„åŸå› æ˜¯å› ä¸ºè¿™ä¸ªåˆ—ä¸­æœ‰ä¸€äº›ç©ºå€¼ã€‚è¿™äº›éœ€è¦é¦–å…ˆè§£å†³ï¼Œæ‰€ä»¥è¿™é‡Œæ˜¯æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨çš„è‡ªå®šä¹‰è½¬æ¢å™¨ã€‚</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="52d2" class="lz ma je lv b gy mb mc l md me"># Creating function to appropriately engineer the â€˜Embarkedâ€™ column<br/>def create_embarked_columns(col):<br/>    â€˜â€™â€™Engineers the embarked variables for pipelineâ€™â€™â€™<br/> <br/>    # Instantiating the transformer objects<br/>    embarked_imputer = SimpleImputer(strategy = â€˜most_frequentâ€™)<br/>    embarked_ohe = OneHotEncoder()<br/> <br/>    # Performing basic imputation for nulls<br/>    imputed = embarked_imputer.fit_transform(col)<br/>    embarked_filled = pd.DataFrame(data = imputed, columns = [â€˜Embarkedâ€™])<br/> <br/>    # Performing OHE on the col data<br/>    embarked_columns = embarked_ohe.fit_transform(embarked_filled[[â€˜Embarkedâ€™]])<br/>    embarked_columns_df = pd.DataFrame(data = embarked_columns.toarray())<br/> <br/> return embarked_columns_df</span></pre><p id="2d8c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">æ—¢ç„¶æˆ‘ä»¬å·²ç»ç¼–å†™äº†è‡ªå®šä¹‰å‡½æ•°ï¼Œæˆ‘ä»¬ç»ˆäºå¯ä»¥å°†å®ƒä»¬æ·»åŠ åˆ°ç®¡é“ä¸­äº†ã€‚ä½ å¯èƒ½ä¸çŸ¥é“ï¼Œä½†æ˜¯ Scikit-Learn æœ‰ä¸€ä¸ªç‰¹æ®Šçš„æ–¹æ³•æ¥å¤„ç†è¿™äº›ç‰¹æ®Šçš„è‡ªå®šä¹‰è½¬æ¢å™¨ï¼Œå«åš<strong class="kv jf"> FunctionTransformer </strong>ã€‚è¿™å¾ˆå®¹æ˜“å®ç°ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬çœ‹çœ‹å½“æˆ‘ä»¬æŠŠå®ƒæ·»åŠ åˆ°æˆ‘ä»¬åŸæ¥çš„ç®¡é“æ—¶æ˜¯ä»€ä¹ˆæ ·å­ã€‚</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="a1fd" class="lz ma je lv b gy mb mc l md me"># Creating a preprocessor to transform the â€˜Sexâ€™ column<br/>data_preprocessor = ColumnTransformer(transformers = [<br/>    (â€˜sex_transformerâ€™, OneHotEncoder(), [â€˜Sexâ€™]),<br/>    (â€˜age_transformerâ€™, FunctionTransformer(create_age_bins, validate = False), [â€˜Ageâ€™]),<br/>    (â€˜embarked_transformerâ€™, FunctionTransformer(create_embarked_columns, validate = False), [â€˜Embarkedâ€™])<br/>])</span><span id="88da" class="lz ma je lv b gy mf mc l md me"># Creating our pipeline that first preprocesses the data, then scales the data, then fits the data to a RandomForestClassifier<br/>rfc_pipeline = Pipeline(steps = [<br/>    (â€˜data_preprocessingâ€™, data_preprocessor),<br/>    (â€˜data_scalingâ€™, StandardScaler()),<br/>    (â€˜modelâ€™, RandomForestClassifier(max_depth = 10,<br/>                                     min_samples_leaf = 3,<br/>                                     min_samples_split = 4,<br/>                                     n_estimators = 200))<br/>])</span></pre><p id="5143" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">å¾ˆç®€å•ï¼Œå¯¹å§ï¼Ÿä½¿ç”¨ Scikit-Learn function transformer æŒ‡å‘æ­£ç¡®çš„è‡ªå®šä¹‰å‡½æ•°ï¼Œå¹¶åœ¨æŒ‡å®šçš„åˆ—ä¸Šä½¿ç”¨å®ƒï¼Œè¿™å¾ˆç®€å•ã€‚ä»ç°åœ¨å¼€å§‹ï¼Œè¿™æ˜¯æ¨¡å‹çš„ç®€å•å¯¼å‡ºã€‚</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="9cb2" class="lz ma je lv b gy mb mc l md me"># Fitting the training data to our pipeline<br/>rfc_pipeline.fit(X_train, y_train)</span><span id="babd" class="lz ma je lv b gy mf mc l md me"># Saving our pipeline to a binary pickle file<br/>joblib.dump(rfc_pipeline, â€˜model/rfc_pipeline.pklâ€™)</span></pre><p id="0ff3" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv jf">* * * *å›åˆ°æ˜Ÿå·æ—¶ä»£ï¼ï¼ï¼</strong></p><p id="bfda" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">æ‰€ä»¥â€¦â€¦..ä½¿ç”¨å®šåˆ¶å˜å‹å™¨ä¹Ÿæœ‰ä¸å¥½çš„ä¸€é¢â€¦</p><p id="3da8" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">åºåˆ—åŒ–æ¨¡å‹ä¸å­˜å‚¨ä»»ä½•è‡ªå®šä¹‰ Python å‡½æ•°çš„ä»£ç æœ¬èº«ã€‚(è‡³å°‘â€¦ä¸æ˜¯ä»¥æˆ‘è¿˜æ²¡æƒ³å‡ºæ¥çš„æ–¹å¼ã€‚)ä¹Ÿå°±æ˜¯è¯´ï¼Œ<strong class="kv jf"> <em class="mg">ä¸ºäº†åˆ©ç”¨è¿™ä¸ªååºåˆ—åŒ–çš„æ¨¡å‹ï¼Œpickle å¿…é¡»èƒ½å¤Ÿå¼•ç”¨ä¸ºå…¶è‡ªèº«äºŒè¿›åˆ¶å€¼</em> </strong>ä¹‹å¤–çš„å‡½æ•°è½¬æ¢å™¨ç¼–å†™çš„ç›¸åŒä»£ç ã€‚æˆ–è€…é€šä¿—åœ°è¯´ï¼Œæ‚¨éœ€è¦å°†æ‚¨çš„å®šåˆ¶ Python å‡½æ•°æ·»åŠ åˆ°æ‚¨ä¸ºè¿™æ ·çš„æ¨¡å‹ç¼–å†™çš„ä»»ä½•éƒ¨ç½²è„šæœ¬ä¸­ã€‚</p><p id="c7e7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">ç°åœ¨ï¼Œè¿™æ˜¯ä¸æ˜¯æœ‰ç‚¹çƒ¦äººï¼Ÿæ˜¯çš„ã€‚ä½†æ˜¯è¿™ç»™äº†æˆ‘ä¸€ä¸ªä¸ä½¿ç”¨å®šåˆ¶è½¬æ¢çš„ç†ç”±å—ï¼Ÿè¿™æ˜¯ä¸€ä¸ªç®€å•è€Œåšå®šçš„ç­”æ¡ˆã€‚æˆ‘çŸ¥é“ä¸ºç®¡é“è¿è¡Œæä¾›é¢å¤–çš„å®šåˆ¶ä»£ç ä¸å¤ªæ–¹ä¾¿ï¼Œä½†ä»£ä»·æ˜¯è¿›è¡Œè½¬æ¢ï¼Œè¿™å¯èƒ½ä¼šä½¿æ¨¡å‹çš„æ€§èƒ½æ¯”å…¶ä»–æƒ…å†µå¥½å¾—å¤šã€‚</p><p id="2695" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™æœ‰ç‚¹ç³Ÿç³•ï¼Œä½†å˜¿ï¼Œæˆ‘ä¼šé€‰æ‹©åŒ…æ‹¬è‡ªå®šä¹‰å˜å½¢é‡‘åˆšæ¯æ¬¡æœ€æœ‰å¯èƒ½ã€‚å¤§å¤šæ•°æ•°æ®é›†åŒ…å«å¹¿æ³›çš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾è‚¯å®šä¸ä¼šåˆ†è§£æˆç®€å•çš„è½¬æ¢ï¼Œå¦‚æ’è¡¥æˆ–ä¸€æ¬¡çƒ­ç¼–ç ã€‚çœŸå®çš„æ•°æ®æ˜¯æ‚ä¹±çš„ï¼Œç»å¸¸éœ€è¦å¤§é‡çš„ç‰¹æ®Šæ¸…ç†ï¼Œè€Œè¿™äº›å®šåˆ¶çš„è½¬æ¢å™¨æ­£å¥½é€‚åˆè¿™é¡¹å·¥ä½œã€‚</p><p id="1792" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">è¿™å°±æ˜¯è¿™ç¯‡æ–‡ç« çš„å…¨éƒ¨å†…å®¹ï¼å¸Œæœ›ä½ å–œæ¬¢ã€‚å¦‚æœä½ æƒ³è®©æˆ‘åœ¨ä»¥åçš„å¸–å­ä¸­æ¶‰åŠä»»ä½•å…·ä½“çš„å†…å®¹ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼æˆ‘è„‘å­é‡Œè¿˜æœ‰æ›´å¤šçš„æƒ³æ³•ï¼Œæ‰€ä»¥è¯·ç»§ç»­å…³æ³¨ã€‚ğŸ˜ƒ</p></div></div>    
</body>
</html>