<html>
<head>
<title>Face Dataset Compression using PCA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于主成分分析的人脸数据集压缩</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/face-dataset-compression-using-pca-cddf13c63583?source=collection_archive---------27-----------------------#2020-08-30">https://towardsdatascience.com/face-dataset-compression-using-pca-cddf13c63583?source=collection_archive---------27-----------------------#2020-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="611e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用于图像数据集压缩的主成分分析</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f955cf4cb0061fcc4682e04aa887347e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k26_0guTB2lHnhH268xmXQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@grzegorzwalczak?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Grzegorz Walczak </a>拍摄</p></figure><p id="fed9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我的上一篇文章中，我们采用了一种图形化的方法来理解主成分分析是如何工作的，以及如何将其用于数据压缩。如果您对这个概念不熟悉，我强烈建议您在继续之前阅读我以前的文章。我提供了以下链接:</p><div class="ls lt gp gr lu lv"><a rel="noopener follow" target="_blank" href="/principal-component-analysis-visualized-17701e18f2fa"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">主成分分析—可视化</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">使用主成分分析(PCA)的数据压缩</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">towardsdatascience.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj kp lv"/></div></div></a></div><p id="1c10" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我们将了解如何使用 PCA 来压缩现实生活中的数据集。我们将在野外(LFW)，使用<strong class="ky ir">标记的人脸，这是一个由<strong class="ky ir"> 13233 </strong>张人脸灰度图像组成的大规模数据集，每张图像的尺寸为<strong class="ky ir"> 64x64 </strong>。这意味着每个面的数据是 4096 维的(每个面要存储 64×64 = 4096 个唯一值)。我们将使用主成分分析将这一维度要求降低到几百个维度！</strong></p><h1 id="10b0" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">介绍</h1><p id="a277" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">主成分分析(PCA)是一种用于降低数据集维度的技术，利用了这些数据集中的图像具有共同点的事实。例如，在由脸部照片组成的数据集中，每张照片都有像眼睛、鼻子、嘴巴这样的面部特征。我们可以为每种类型的特征制作一个模板，然后将这些模板组合起来，生成数据集中的任何人脸，而不是逐个像素地对这些信息进行编码。在这种方法中，每个模板仍然是 64x64 = 4096 维，但是由于我们将重用这些模板(基函数)来生成数据集中的每个面，因此所需的模板数量很少。PCA 正是这样做的。让我们看看如何！</p><h1 id="28c0" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">笔记本</h1><p id="3ca8" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">您可以在此处查看 Colab 笔记本:</p><div class="ls lt gp gr lu lv"><a href="https://colab.research.google.com/drive/1QZYqjLm_rLxkgR6COMjjBicHSLMwKxF-" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">PCA</h2><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">colab.research.google.com</p></div></div><div class="me l"><div class="nh l mg mh mi me mj kp lv"/></div></div></a></div><h1 id="1665" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">资料组</h1><p id="5c60" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">让我们从数据集中可视化一些图像。你可以看到每个图像都有一张完整的脸，并且像眼睛、鼻子和嘴唇这样的面部特征在每个图像中都清晰可见。现在我们已经准备好数据集，让我们压缩它。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/d84a06cf282cd115245cbce582806bbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yJmgZ3z2xxaK6rZUQ6ilFw.png"/></div></div></figure><h1 id="df60" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">压缩</h1><p id="e524" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated"><strong class="ky ir">五氯苯甲醚是一个 4 步流程。</strong>从包含<em class="nj"> n </em>个维度的数据集开始(需要表示<em class="nj"> n </em>个轴):</p><ul class=""><li id="ca42" class="nk nl iq ky b kz la lc ld lf nm lj nn ln no lr np nq nr ns bi translated"><strong class="ky ir">步骤 1 </strong>:找到一组新的基函数(<em class="nj">n</em>-轴)，其中一些轴对数据集中的方差贡献最大，而其他轴贡献很小。</li><li id="6fe0" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated"><strong class="ky ir">第二步</strong>:按照方差贡献度递减的顺序排列这些轴。</li><li id="947d" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated"><strong class="ky ir">第三步</strong>:现在，选择要使用的顶部<em class="nj"> k </em>轴，放下剩余的<em class="nj"> n-k </em>轴。</li><li id="d835" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated"><strong class="ky ir">步骤 4 </strong>:现在，将数据集投影到这些<em class="nj"> k </em>轴上。</li></ul><p id="6c8e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些步骤在我之前的文章中有很好的解释。在这 4 个步骤之后，数据集将从<em class="nj"> n </em>维压缩到仅<em class="nj"> k </em>维(<em class="nj">k</em>T32】<em class="nj">n</em>)。</p><h2 id="1097" class="ny ml iq bd mm nz oa dn mq ob oc dp mu lf od oe mw lj of og my ln oh oi na oj bi translated">第一步</h2><p id="2e8d" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">找到一组新的基函数(<em class="nj">n</em>-轴)，其中一些轴贡献了数据集中的大部分方差，而其他轴贡献很小，这类似于找到我们稍后将组合以在数据集中生成人脸的模板。总共将生成 4096 个模板，每个模板的维度为 4096。数据集中的每个人脸都可以表示为这些模板的线性组合。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/245efd93904c8e2bee9427946d634e3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a2skqJY7dwpAqpn7"/></div></div></figure><p id="8803" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，标量常数(k1，k2，…，kn)对于每个面都是唯一的。</p><h2 id="239f" class="ny ml iq bd mm nz oa dn mq ob oc dp mu lf od oe mw lj of og my ln oh oi na oj bi translated">第二步</h2><p id="172b" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">现在，这些模板中的一些对面部重建贡献很大，而另一些贡献很小。这种贡献水平可以量化为每个模板对数据集贡献的方差百分比。因此，在这一步，我们将按照方差贡献的降序排列这些模板(最重要…最不重要)。</p><h2 id="b014" class="ny ml iq bd mm nz oa dn mq ob oc dp mu lf od oe mw lj of og my ln oh oi na oj bi translated">第三步</h2><p id="a043" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">现在，我们将保留顶部的<em class="nj"> k 个</em>模板，删除其余的。但是，我们应该保留多少模板呢？如果我们保留更多的模板，我们的重建图像将非常类似于原始图像，但我们将需要更多的存储空间来存储压缩数据。如果我们保留的模板太少，我们重建的图像将与原始图像非常不同。</p><p id="7755" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最佳解决方案是确定我们希望在压缩数据集中保留的方差百分比，并使用它来确定<em class="nj"> k </em>的值(要保留的模板数量)。如果我们计算一下，我们发现要保留方差的 99%,我们只需要顶部的 577 个模板。我们将把这些值保存在一个数组中，并删除剩余的模板。</p><p id="5c25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看看这些模板。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/5ffabc10635bf5122c9fcece46af2fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MnpelO4cT2COWnKDzfbcZw.png"/></div></div></figure><p id="39a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，这些模板看起来都有点像人脸。这些被称为特征脸。</p><h2 id="1cca" class="ny ml iq bd mm nz oa dn mq ob oc dp mu lf od oe mw lj of og my ln oh oi na oj bi translated">第四步</h2><p id="68bc" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">现在，我们将构建一个投影矩阵，将图像从原来的 4096 维投影到 577 维。投影矩阵将有一个形状<strong class="ky ir"> (4096，577) </strong>，其中模板将是矩阵的列。</p><p id="08ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们继续压缩图像之前，让我们花点时间来理解压缩的真正含义。回想一下，这些面可以通过所选模板的线性组合来生成。由于每个面都是唯一的，因此数据集中的每个面都需要一组不同的常数(k1，k2，…，kn)来进行线性组合。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/245efd93904c8e2bee9427946d634e3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a2skqJY7dwpAqpn7"/></div></div></figure><p id="e38e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们从数据集中的图像开始，计算常数(k1，k2，…，kn)，其中 n = 577。这些常数连同所选择的 577 个模板可以被插入到上面的等式中以重建面部。这意味着我们只需要为每幅图像计算和保存这 577 个常数。我们可以使用矩阵同时计算数据集中每个图像的常数，而不是逐个图像地进行计算。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/df4f1bf1220b8c43d8042ea615478cab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xNQQJ_vhT3K6C7YL"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/aa58ec2b4494e78c3bd7311fcb6cbc4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/0*b0C5i5pt1Nq0USli"/></div></figure><p id="3bff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">回想一下，数据集中有 13233 幅图像。矩阵 compressed_images 包含数据集中每个图像的 577 个常数。我们现在可以说，我们已经将图像从 4096 维压缩到 577 维，同时保留了 99%的信息。</p><h1 id="b73d" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">压缩比</h1><p id="2439" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">让我们计算一下数据集压缩了多少。回想一下，数据集中有 13233 幅图像，每幅图像的尺寸都是 64x64。因此，存储原始数据集所需的唯一值总数为<br/> 13233 x 64 x 64 = <strong class="ky ir"> 54，202，368 个唯一值</strong>。</p><p id="d9cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">压缩后，我们为每个图像存储 577 个常数。因此，存储压缩数据集所需的唯一值总数为<br/> 13233 x 577 = 7，635，441 个唯一值。但是，我们还需要存储模板，以便以后重建图像。因此，我们还需要为模板存储<br/> 577 x 64 x 64 = 2，363，392 个唯一值。因此，存储压缩数据集所需的唯一值总数为<br/> 7，635，441 + 2，363，392 = <strong class="ky ir"> 9，998，883 个唯一值</strong>。</p><p id="2526" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以将压缩百分比计算为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/4d8137395ae8157f0023f89d1ddf9fde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LV3_Y8Cg7CBoMznN"/></div></div></figure><h1 id="f804" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">重建图像</h1><p id="d24d" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">压缩后的图像只是长度为 577 的数组，因此无法可视化。我们需要将其重建回 4096 维，以形状数组(64x64)的形式查看。回想一下，每个模板的尺寸都是 64x64，每个常数都是一个标量值。我们可以使用下面的等式来重建数据集中的任何人脸。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/245efd93904c8e2bee9427946d634e3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a2skqJY7dwpAqpn7"/></div></div></figure><p id="e933" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同样，我们可以使用矩阵一次性重建整个数据集，而不是逐个图像地进行重建，当然会损失 1%的方差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/35e55b4bcb2280788e02025088b92caa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_vEoq5Y-JTwjD_RY"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/8b3b21bda1b3197e6b0df029729c7a71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/0*4u304yHFnwNj0gDT"/></div></figure><p id="7023" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们来看一些重建的人脸。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/599252c648387b055695b325cff4c154.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*HFr97ZANuaiN3O-vNY1Gyg.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/089272cb4bc5f2fa86c00f775e78cebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*aLEpDxykoStrUxFIC8Lgtg.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/e46d2280b276b95647b85f136027bf45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*_-eqhIQ9EEyo7DigS4npag.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="129b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，重建的图像已经捕获了关于人脸的大部分相关信息，并且忽略了不必要的细节。这是数据压缩的额外优势，它允许我们过滤数据中不必要的细节(甚至噪音)。</p><h1 id="14e3" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">那都是乡亲们！</h1><p id="c461" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">如果你成功了，向你致敬！在这篇文章中，我们了解了 PCA 如何用于压缩<strong class="ky ir">在野外(LFW)</strong>标记的人脸，这是一个由 13233 个人脸图像组成的大规模数据集，每个图像的尺寸为<strong class="ky ir"> 64x64 </strong>。我们将该数据集压缩了 80%以上，同时保留了 99%的信息。可以查看我的<a class="ae kv" href="https://colab.research.google.com/drive/19iGq1iy4Uw1OOVyyHW9293E1iY8Njr8e?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> Colab 笔记本</strong> </a>了解代码。我鼓励您使用 PCA 来压缩其他数据集，并评论您获得的压缩率。</p><p id="ffe5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有什么建议请留言评论。我定期写文章，所以你应该考虑关注我，在你的订阅中获得更多这样的文章。</p><p id="b0ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你喜欢这篇文章，你可能也会喜欢这些:</p><div class="ls lt gp gr lu lv"><a rel="noopener follow" target="_blank" href="/machine-learning-visualized-11965ecc645c"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">机器学习—可视化</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">理解机器学习的视觉方法</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">towardsdatascience.com</p></div></div><div class="me l"><div class="oq l mg mh mi me mj kp lv"/></div></div></a></div><div class="ls lt gp gr lu lv"><a rel="noopener follow" target="_blank" href="/face-landmarks-detection-with-pytorch-4b4852f5e9c4"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">用 Pytorch 检测人脸标志点</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">想知道 Snapchat 或 Instagram 如何将惊人的滤镜应用到你的脸上吗？该软件检测你的关键点…</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">towardsdatascience.com</p></div></div><div class="me l"><div class="or l mg mh mi me mj kp lv"/></div></div></a></div><p id="63e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">访问我的网站，了解更多关于我和我的工作的信息:</p><div class="ls lt gp gr lu lv"><a href="https://arkalim.netlify.app/" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">阿卜杜勒·拉赫曼</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">让我们让电脑智能化吧！</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">arkalim.netlify.app</p></div></div><div class="me l"><div class="os l mg mh mi me mj kp lv"/></div></div></a></div></div></div>    
</body>
</html>