<html>
<head>
<title>Getting Started with AutoML and AWS AutoGluon</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AutoML和AWS自动引导入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-automl-and-aws-autogluon-6bc7ed7aef95?source=collection_archive---------32-----------------------#2020-04-19">https://towardsdatascience.com/getting-started-with-automl-and-aws-autogluon-6bc7ed7aef95?source=collection_archive---------32-----------------------#2020-04-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a642" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用AWS AutoML库自动生成建立了一个目标检测模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d0f3174c84b4c1160b9ba13d45f3999b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NlIhsD2A7ltIlFdm.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">维克托·加西亚在Unsplash上拍摄的照片</p></figure><p id="39f6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">原载于2020年4月20日</em><a class="ae lv" href="https://www.philschmid.de/getting-started-with-automl-and-aws-autogluon" rel="noopener ugc nofollow" target="_blank"><em class="lu">https://www . philschmid . de</em></a><em class="lu">。</em></p><h1 id="3c35" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">介绍</h1><p id="fd46" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">谷歌<a class="ae lv" href="https://blog.google/technology/ai/making-ai-work-for-everyone/" rel="noopener ugc nofollow" target="_blank">首席执行官桑德尔·皮帅写道</a>“…<em class="lu">设计神经网络是极其耗时的，并且需要专业知识，这限制了它在较小的科学家和工程师群体中的使用。</em>“在这之后不久，谷歌于2018年初推出了其服务AutoML。</p><p id="7af4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">AutoML旨在使机器学习专业知识有限的开发人员能够针对其业务需求训练高质量的模型。AutoML的目标是自动化所有主要的重复性任务，如<a class="ae lv" href="https://en.wikipedia.org/wiki/Feature_selection" rel="noopener ugc nofollow" target="_blank">特征选择</a>或<a class="ae lv" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization" rel="noopener ugc nofollow" target="_blank">超参数调整</a>。这允许在更短的时间内创建更多的模型，并提高质量和准确性。</p><p id="3020" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">机器学习的基本两步方法:首先，通过使模型符合数据来创建模型。第二，该模型用于预测新(以前未见过的)数据的输出。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/86f280cd4f768ef1925d79d73d87b4bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aIxkyM-EuuoZrIY4aJF6xw.png"/></div></div></figure><p id="a8ce" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇博客文章演示了如何快速开始使用AutoML。它会给你一步一步的教程，如何建立一个对象检测模型使用自动旋转，具有一流的准确性。我用一个完整的例子创建了一个<a class="ae lv" href="https://colab.research.google.com/drive/1Z0F2FOowLWrJ-gYx72fiWLIpmEVMk4Bo" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="8837" class="lw lx it bd ly lz nb mb mc md nc mf mg jz nd ka mi kc ne kd mk kf nf kg mm mn bi translated">AWS正在进入AutoML领域</h1><p id="568d" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">在Re:Invent 2019上，AWS为他们的<a class="ae lv" href="https://aws.amazon.com/sagemaker/?nc1=h_ls" rel="noopener ugc nofollow" target="_blank">托管机器学习服务Sagemaker </a>以及其他“<a class="ae lv" href="https://aws.amazon.com/sagemaker/autopilot/?nc1=h_ls" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> Sagemaker自动驾驶</strong> </a>”推出了一系列附加组件。Sagemaker Autopilot是一项AutoML服务，可与Google AutoML服务相媲美。</p><p id="4d0a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2020年1月，亚马逊网络服务公司(AWS)秘密推出了一个名为<a class="ae lv" href="https://autogluon.mxnet.io/" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">autoglon</strong></a>的开源库，这是Sagemaker Autopilot背后的库。</p><p id="a3cb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">AutoGluon使开发人员能够编写基于机器学习的应用程序，这些应用程序使用图像、文本或表格数据集，只需几行代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/ecac339539fa82e5836c490679dcc223.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yg9fCy22syl1uOCGPdeKIQ.png"/></div></div></figure><p id="685c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">凭借这些工具，AWS进入了托管AutoML服务(MLaas)领域，并与谷歌的AutoML 服务展开竞争。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="0dc8" class="lw lx it bd ly lz nb mb mc md nc mf mg jz nd ka mi kc ne kd mk kf nf kg mm mn bi translated">什么是自转？</h1><p id="a143" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated"><a class="ae lv" href="https://autogluon.mxnet.io/index.html" rel="noopener ugc nofollow" target="_blank"><em class="lu">“autoglon</em></a><em class="lu">支持易于使用和易于扩展的AutoML，专注于深度学习和跨图像、文本或表格数据的现实应用。面向ML初学者和专家，AutoGluon使您能够…”</em></p><ul class=""><li id="96d4" class="nh ni it la b lb lc le lf lh nj ll nk lp nl lt nm nn no np bi translated">快速原型化深度学习解决方案</li><li id="6280" class="nh ni it la b lb nq le nr lh ns ll nt lp nu lt nm nn no np bi translated">自动超参数调整、模型选择/架构搜索</li><li id="62b4" class="nh ni it la b lb nq le nr lh ns ll nt lp nu lt nm nn no np bi translated">改进现有的定制模型和数据管道**</li></ul><p id="a5aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">AutoGluon使您只需3行代码即可构建机器学习模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="88c3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">目前，AutoGluon可以为图像分类、对象检测、文本分类和使用表格数据集的监督学习创建模型。</p><p id="dc40" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你对autoglon如何在幕后完成所有的魔术感兴趣，可以看看AWS开源博客上的“<a class="ae lv" href="https://aws.amazon.com/blogs/opensource/machine-learning-with-autogluon-an-open-source-automl-library/" rel="noopener ugc nofollow" target="_blank">autoglon机器学习，一个开源的AutoML库</a>”帖子。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="1e52" class="lw lx it bd ly lz nb mb mc md nc mf mg jz nd ka mi kc ne kd mk kf nf kg mm mn bi translated">辅导的</h1><p id="7a5f" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">我们将建立一个目标检测模型，检测图像上的水果(苹果、橘子和香蕉)。我用大约300张图片建立了一个小数据集来实现快速训练过程。<a class="ae lv" href="https://www.kaggle.com/philschmid/tiny-fruit-object-detection/metadata" rel="noopener ugc nofollow" target="_blank">你可以在这里找到数据集。</a></p><p id="b09e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本教程中，我使用了带有GPU运行时的Google Colab。如果你不确定如何使用GPU运行时，看看这里的<a class="ae lv" href="https://www.philschmid.de/google-colab-the-free-gpu-tpu-jupyter-notebook-service" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="d767" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好了，现在让我们开始教程。</p><h1 id="06b4" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">安装自动旋转</h1><p id="17bb" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">AutoGluon为不同的硬件首选项提供不同的安装包。如需更多安装说明，请查看此处的<a class="ae lv" href="https://autogluon.mxnet.io/#installation" rel="noopener ugc nofollow" target="_blank">自动引导安装指南。</a></p><p id="1ed4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一步是用pip和CUDA支持安装<code class="fe nx ny nz oa b">AutoGluon</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="dfa0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了让AutoGluon在Google Colab中工作，我们还必须安装<code class="fe nx ny nz oa b">ipykernel</code>并重启运行时。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="79a8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">成功重启运行时后，您可以导入<code class="fe nx ny nz oa b">autogluon</code>并打印出版本。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="e3a6" class="lw lx it bd ly lz nb mb mc md nc mf mg jz nd ka mi kc ne kd mk kf nf kg mm mn bi translated">加载数据和创建数据集</h1><p id="81b6" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">下一步是加载我们用于对象检测任务的数据集。在AutoGluon的<code class="fe nx ny nz oa b">ObjectDetection</code>任务中，通过将<code class="fe nx ny nz oa b">Dataset()</code>的<code class="fe nx ny nz oa b">format</code>参数调整为<code class="fe nx ny nz oa b">coco</code>或<code class="fe nx ny nz oa b">voc</code>，可以使用PASCAL VOC格式或COCO格式。<a class="ae lv" href="https://gluon-cv.mxnet.io/build/examples_datasets/detection_custom.html#pascal-voc-like" rel="noopener ugc nofollow" target="_blank"> Pascal VOC </a>数据集包含两个目录:<code class="fe nx ny nz oa b">Annotations</code>和<code class="fe nx ny nz oa b">JPEGImages</code>。<a class="ae lv" href="https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch/#coco-dataset-format" rel="noopener ugc nofollow" target="_blank"> COCO </a>数据集的格式为<code class="fe nx ny nz oa b">JSON</code>，是“信息”、“许可证”、“图像”、“注释”、“类别”的集合。</p><p id="56d8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于训练，我们将使用我构建的<a class="ae lv" href="https://www.kaggle.com/philschmid/tiny-fruit-object-detection/metadata" rel="noopener ugc nofollow" target="_blank">tiny _ fruit _ object _ detection</a>数据集。该数据集包含大约300张香蕉、苹果、橙子或它们的组合的图片。</p><p id="90fd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们使用240幅图像进行训练，30幅用于测试，30幅用于评估模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/8bd737c0884cf92c42b990fcb28f40b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5-E9WpI5QqD50GkT71THA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集的样本图像</p></figure><p id="5ab7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用下面的命令，我们可以<code class="fe nx ny nz oa b">download</code>和<code class="fe nx ny nz oa b">unzip</code>这个只有29MB的数据集。在这之后，我们用<code class="fe nx ny nz oa b">task.Dataset()</code>创建我们的<code class="fe nx ny nz oa b">Dataset</code>用于训练和测试。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="e51b" class="lw lx it bd ly lz nb mb mc md nc mf mg jz nd ka mi kc ne kd mk kf nf kg mm mn bi translated">训练模型</h1><p id="e33d" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">第三步是用创建的<code class="fe nx ny nz oa b">dataset</code>训练我们的模型。在AutoGluon中，您将分类器定义为变量，此处为<code class="fe nx ny nz oa b">detector</code>，并在训练期间在<code class="fe nx ny nz oa b">fit()</code>函数中定义参数。例如，您可以定义一个<code class="fe nx ny nz oa b">time_limit</code>，它会在特定时间后自动停止训练。您可以为自己的<code class="fe nx ny nz oa b">learning_rate</code>定义一个范围或设置<code class="fe nx ny nz oa b">epochs</code>的数量。最重要的参数之一是<code class="fe nx ny nz oa b">num_trials</code>。该参数定义了可尝试的超参数配置的最大数量。您可以在这里找到<a class="ae lv" href="https://autogluon.mxnet.io/api/autogluon.task.html#autogluon.task.ObjectDetection" rel="noopener ugc nofollow" target="_blank">可配置参数的完整文档。</a></p><p id="12bd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将为<code class="fe nx ny nz oa b">20 epochs</code>训练我们的模型，并通过设置<code class="fe nx ny nz oa b">num_trials=3</code>训练3个不同的模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="1192" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果，我们得到了一个具有平均精度(mAP)和历元数的图表。地图是计算对象检测模型的准确度的常用度量。</p><p id="cc4d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们最好的模型(蓝线)完成了<code class="fe nx ny nz oa b">0.9198171507070327</code>的地图</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/c4d98f994e85d7874f468fc0fb3c1e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*6J1vWfYThQjPbSqNW0BWwg.png"/></div></figure></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="9ec8" class="lw lx it bd ly lz nb mb mc md nc mf mg jz nd ka mi kc ne kd mk kf nf kg mm mn bi translated">评估模型</h1><p id="c4ba" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">完成培训后，我们现在将在我们的<code class="fe nx ny nz oa b">test</code>数据集上评估/测试我们的模型的性能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="4348" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">测试数据集上的地图是<code class="fe nx ny nz oa b">0.8724113724113725</code>,考虑到我们只使用240幅图像和20个时期进行训练，这已经很不错了。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="0d1a" class="lw lx it bd ly lz nb mb mc md nc mf mg jz nd ka mi kc ne kd mk kf nf kg mm mn bi translated">预测图像</h1><p id="169d" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">要使用我们训练好的模型进行预测，您可以简单地运行<code class="fe nx ny nz oa b">detector.predict(image_path)</code>，它将返回一个元组(<code class="fe nx ny nz oa b">ind</code>)，其中包含检测到的对象的类id、置信度得分(<code class="fe nx ny nz oa b">prob</code>)以及相应的预测边界框位置(<code class="fe nx ny nz oa b">loc</code>)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/b367228ccde55b69507b1827b94b5a80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OYjSSlb_3nAhPMpPf0zbYQ.png"/></div></div></figure></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="e9bf" class="lw lx it bd ly lz nb mb mc md nc mf mg jz nd ka mi kc ne kd mk kf nf kg mm mn bi translated">保存模型</h1><p id="20c7" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated"><em class="lu">在撰写本文时，保存对象检测模型还没有在</em> <code class="fe nx ny nz oa b"><em class="lu">0.0.6</em></code> <em class="lu">版本中实现，但是将在下一个部署版本中实现。</em></p><p id="9104" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要保存你的模型，你只需要运行<code class="fe nx ny nz oa b">detector.save()</code></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="50e7" class="lw lx it bd ly lz nb mb mc md nc mf mg jz nd ka mi kc ne kd mk kf nf kg mm mn bi translated">负载模型</h1><p id="d203" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated"><em class="lu">在撰写本文时，加载对象检测模型还没有在版本</em> <code class="fe nx ny nz oa b"><em class="lu">0.0.6</em></code> <em class="lu">中实现，但是将在下一个部署版本中实现。</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="5aa0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读。你可以在这里找到<a class="ae lv" href="https://colab.research.google.com/drive/1Z0F2FOowLWrJ-gYx72fiWLIpmEVMk4Bo" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>包含完整示例<a class="ae lv" href="https://colab.research.google.com/drive/1Z0F2FOowLWrJ-gYx72fiWLIpmEVMk4Bo#scrollTo=XtuOeo_ZzLMq" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>