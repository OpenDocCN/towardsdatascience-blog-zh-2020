<html>
<head>
<title>A Data Science/Big Data Laboratory — part 2 of 4: Hadoop 3.2.1 and Spark 3.0.0 over Ubuntu 20.04 in a 3-node cluster</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学/大数据实验室—第2部分，共4部分:3节点集群中基于Ubuntu 20.04的Hadoop 3.2.1和Spark 3.0.0</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025?source=collection_archive---------25-----------------------#2020-06-14">https://towardsdatascience.com/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-e4c5a0473025?source=collection_archive---------25-----------------------#2020-06-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="2e5f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">实验室数据</h2><div class=""/><div class=""><h2 id="612b" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用Hadoop、Spark、Hive、Kafka、Zookeeper和PostgreSQL在Raspberry Pi 4或VMs集群中组建数据科学/大数据实验室</h2></div><p id="4405" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">这段文字可以用来支持在任何Ubuntu 20.04服务器集群中的安装，这就是设计良好的分层软件的妙处。此外，如果您有更多的节点，您可以随意分发软件。本文假设您知道Linux命令行，包括ssh、vim和nano。</em></p><p id="0efd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">我不建议从少于三个树莓开始，因为你需要设置通信，并且Zookeeper和Kafka都需要奇数个节点。如果您尝试使用单个节点，可以使用本指南。尽管如此，性能可能会令人失望——对于单节点，我建议虚拟机具有合理数量的RAM和处理器。</em></p><p id="8684" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">由于篇幅原因，我不得不将教程分成四部分</em></p><ul class=""><li id="6c7b" class="ll lm iq kq b kr ks ku kv kx ln lb lo lf lp lj lq lr ls lt bi translated"><a class="ae lu" rel="noopener" target="_blank" href="/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-ff37759cb2ec?source=friends_link&amp;sk=3a4b90e57dc0fc0ec44a39d1aee2145c"> <strong class="kq ja"> <em class="lk">第一部分:简介、操作系统和联网</em> </strong> </a></li><li id="554b" class="ll lm iq kq b kr lv ku lw kx lx lb ly lf lz lj lq lr ls lt bi translated"><strong class="kq ja"> <em class="lk">第二部分:Hadoop和Spark </em> </strong></li><li id="b476" class="ll lm iq kq b kr lv ku lw kx lx lb ly lf lz lj lq lr ls lt bi translated"><a class="ae lu" rel="noopener" target="_blank" href="/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-8a1da8d49b48?source=friends_link&amp;sk=4a481ee4e3778d6c9d4e5a305a407bb6"> <strong class="kq ja"> <em class="lk">第三部分:PostgreSQL和Hive </em> </strong> </a></li><li id="7e0d" class="ll lm iq kq b kr lv ku lw kx lx lb ly lf lz lj lq lr ls lt bi translated"><a class="ae lu" rel="noopener" target="_blank" href="/kafka-and-zookeeper-over-ubuntu-in-a-3-node-cluster-a-data-science-big-data-laboratory-part-4-of-4-47631730d240?source=friends_link&amp;sk=955731d942d6f83e7f00d731e830ba30"> <strong class="kq ja"> <em class="lk">第四部分:卡夫卡与结论</em> </strong> </a></li></ul><p id="9a97" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">所有配置文件均可在【1】:</em>获得</p><div class="ma mb gp gr mc md"><a href="https://github.com/ptaranti/RaspberryPiCluster" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd ja gy z fp mi fr fs mj fu fw iz bi translated">ptaranti/RaspberryPiCluster</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">Hadoop+Spark+Hive+Kafka+Postgresql集群(ubuntu 20.04)的配置文件</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">github.com</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr ms md"/></div></div></a></div><p id="b822" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">免责声明</em> : <em class="lk">此文免费提供给大家使用，风险自担。我小心地引用了我所有的资料来源，但是如果你觉得遗漏了什么，请给我发个短信。由于不同的软件版本可能会因其依赖性而表现出不同的行为，我建议使用我在第一次尝试中使用的相同版本。</em></p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ebab9ffbdb3ae75a0d1436b78b95d3a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*pwoDzrth6j3InKWHvHViBg.png"/></div></figure><h1 id="ae25" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">3.安装Hadoop和Spark</h1><p id="3478" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">Hadoop和Spark安装考虑了来自[3，4]和其他来源的指令。</p><p id="22c6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我使用了Apache网站上的更新版本:</p><ul class=""><li id="b7e7" class="ll lm iq kq b kr ks ku kv kx ln lb lo lf lp lj lq lr ls lt bi translated"><em class="lk">hadoop-3.2.1.tar.gz</em></li><li id="0052" class="ll lm iq kq b kr lv ku lw kx lx lb ly lf lz lj lq lr ls lt bi translated"><em class="lk">spark-2 . 4 . 5-bin-Hadoop 2.7 . tgz</em></li></ul><h1 id="9be2" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">3.1设置您的环境</h1><p id="1c7b" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">首先:下载，并将文件解压到/opt。授予<em class="lk"> pi </em>用户访问权限。</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="6715" class="oj ni iq of b gy ok ol l om on">sudo tar -xvf hadoop-3.2.1.tar.gz -C /opt/<br/>sudo tar -xvf spark-2.4.5-bin-hadoop2.7.tgz  -C /opt/</span><span id="e8f5" class="oj ni iq of b gy oo ol l om on">cd /opt/</span><span id="3399" class="oj ni iq of b gy oo ol l om on">pi@pi1:/opt$ sudo mv hadoop-3.2.1 hadoop<br/>pi@pi1:/opt$ sudo mv spark-2.4.5-bin-hadoop2.7 spark<br/>pi@pi1:/opt$ sudo chown -R pi:pi /opt/spark<br/>pi@pi1:/opt$ sudo chown -R pi:pi /opt/hadoop</span></pre><p id="37c8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">添加到<a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/home/pi/.bashrc" rel="noopener ugc nofollow" target="_blank"> /home/pi/。巴沙尔</a>:</p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="5616" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">编辑后:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="be6d" class="oj ni iq of b gy ok ol l om on">source /home/pi/.bashrc</span></pre><h1 id="ebb7" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">3.2将Hadoop和Spark配置为单个节点</h1><p id="71cf" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">现在您需要配置Hadoop和Spark</p><p id="3c49" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了清楚起见，我们首先将其配置为单个节点，然后针对群集进行修改。<a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster" rel="noopener ugc nofollow" target="_blank">我在GitHub </a>中的存储库只包含最终的集群配置文件。</p><h1 id="6fb5" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">Hadoop</h1><p id="1b8e" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">转到文件夹</p><p id="f165" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/tree/master/pi1/opt/hadoop/etc/hadoop" rel="noopener ugc nofollow" target="_blank"><em class="lk">/opt/Hadoop/etc/Hadoop</em>/T9】</a></p><p id="d67f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这一点上，我遇到了很多麻烦:我不小心在文件头上插入了一行blanc。这一空白行导致解析错误，Hadoop一直失败，直到我意识到这个问题。</p><p id="493b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">编辑文件</p><p id="92b2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/hadoop-env.sh" rel="noopener ugc nofollow" target="_blank"><em class="lk">/opt/Hadoop/etc/Hadoop/Hadoop-env . sh</em>，</a></p><p id="7227" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在末尾增加以下一行:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="6f92" class="oj ni iq of b gy ok ol l om on"><strong class="of ja">export JAVA_HOME=/</strong>usr<strong class="of ja">/</strong>lib<strong class="of ja">/</strong>jvm<strong class="of ja">/</strong>java-8-openjdk-arm64</span></pre><p id="6767" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">编辑配置于</p><p id="0872" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/core-site.xml" rel="noopener ugc nofollow" target="_blank">T15】/opt/Hadoop/etc/Hadoop/core-site . XMLT17】</a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="358e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">编辑配置于</p><p id="723b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">【T18<em class="lk">/opt/Hadoop/etc/Hadoop/HDFS-site . XML</em></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="7fee" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在准备数据区:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="c577" class="oj ni iq of b gy ok ol l om on">$ sudo mkdir -p /opt/hadoop_tmp/hdfs/datanode<br/>$ sudo mkdir -p /opt/hadoop_tmp/hdfs/namenode</span><span id="430f" class="oj ni iq of b gy oo ol l om on">sudo chown -R pi:pi /opt/hadoop_tmp</span></pre><p id="e8ab" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">编辑配置于</p><p id="04f3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/mapred-site.xml" rel="noopener ugc nofollow" target="_blank"><em class="lk">/opt/Hadoop/etc/Hadoop/map red-site . XML</em></a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="1c8d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">编辑配置于</p><p id="d7d2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/yarn-site.xml" rel="noopener ugc nofollow" target="_blank"><em class="lk">/opt/Hadoop/etc/Hadoop/yarn-site . XML</em>T29】</a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="915b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">准备数据空间:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="145a" class="oj ni iq of b gy ok ol l om on">$ hdfs namenode -format -force</span><span id="40ca" class="oj ni iq of b gy oo ol l om on">$ start-dfs.sh<br/>$ start-yarn.sh</span><span id="f781" class="oj ni iq of b gy oo ol l om on">$ hadoop fs -mkdir /tmp</span><span id="daac" class="oj ni iq of b gy oo ol l om on">$ hadoop fs -ls /<br/>Found 1 items<br/>drwzr-xr-x   - pi supergroup          0 2019-04-09 16:51 /tmp</span></pre><p id="8578" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">使用<em class="lk"> jps </em>检查所有服务是否开启(数字变化..) :</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="2f51" class="oj ni iq of b gy ok ol l om on">$ jps<br/>2736 NameNode<br/>2850 DataNode<br/>3430 NodeManager<br/>3318 ResourceManager<br/>3020 SecondaryNameNode</span></pre><p id="2dba" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">你需要这五项服务！</p><h1 id="aee1" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">测试</h1><p id="6732" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">为了测试单个节点，我参考了教程[2]:</p><p id="d098" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">执行以下命令:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="8a71" class="oj ni iq of b gy ok ol l om on"><strong class="of ja">pi@pi1:/opt$ hadoop fs -put $SPARK_HOME/README.md /</strong><br/>2020-06-24 19:16:02,822 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable<br/>2020-06-24 19:16:06,389 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false<br/><strong class="of ja">pi@pi1:/opt$ spark-shell</strong><br/>2020-06-24 19:16:23,814 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable<br/>Setting default log level to "WARN".<br/>To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).<br/>Spark context Web UI available at <a class="ae lu" href="http://pi1:4040" rel="noopener ugc nofollow" target="_blank">http://pi1:4040</a><br/>Spark context available as 'sc' (master = local[*], app id = local-1593026210941).<br/>Spark session available as 'spark'.<br/>Welcome to<br/>      ____              __<br/>     / __/__  ___ _____/ /__<br/>    _\ \/ _ \/ _ `/ __/  '_/<br/>   /___/ .__/\_,_/_/ /_/\_\   version 3.0.0<br/>      /_/</span><span id="ec95" class="oj ni iq of b gy oo ol l om on">Using Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 1.8.0_252)<br/>Type in expressions to have them evaluated.<br/>Type :help for more information.</span><span id="f2de" class="oj ni iq of b gy oo ol l om on"><strong class="of ja">scala&gt; val textFile = sc.textFile("hdfs://pi1:9000/README.md")</strong><br/>textFile: org.apache.spark.rdd.RDD[String] = hdfs://pi1:9000/README.md MapPartitionsRDD[1] at textFile at &lt;console&gt;:24</span><span id="e443" class="oj ni iq of b gy oo ol l om on"><strong class="of ja">scala&gt; textFile.first()</strong><br/>res0: String = # Apache Spark</span><span id="7703" class="oj ni iq of b gy oo ol l om on">scala&gt;</span></pre><p id="0e7c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">此时，我陷入了困境，出现了类似于以下内容的重复消息:</p><p id="5227" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="lk"> INFO纱。委托人:申请报告_1434263747091_0023(状态:已受理)</em> </strong></p><p id="b994" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我遵循了[4]和其他来源的建议，更改了以下文件<a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/capacity-scheduler.xml" rel="noopener ugc nofollow" target="_blank"><em class="lk">/opt/Hadoop/etc/Hadoop/capacity-scheduler . XML</em></a><em class="lk">。</em></p><p id="e014" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果在资源较少的单台机器上运行集群，应该设置参数<strong class="kq ja"><em class="lk">yarn . scheduler . capacity . maximum-am-resource-percent</em></strong>。此设置指示可分配给应用程序主机的资源比例，从而增加了可能的并发应用程序的数量。请注意，这取决于您的资源。它在我的Pi 4 4GB内存中工作。</p><p id="e876" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">编辑文件，添加属性:</p><p id="ae43" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/capacity-scheduler.xml" rel="noopener ugc nofollow" target="_blank">/opt/Hadoop/etc/Hadoop/capacity-scheduler . XML</a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="cb4e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意——教程通常提供命令<strong class="kq ja">抑制警告</strong>。我更喜欢在实验时看到这些警告。如果您想删除它，请参考第一个教程。</p><h1 id="7da9" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">3.3集群中的Hadoop与Yarn</h1><p id="0742" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">现在，您应该在单个节点中拥有一个完全可操作的安装。是Hadoop走向集群的时候了！</p><p id="4272" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我完成了教程，但是遇到了一些问题。这是意料之中的—不同的环境，不同的软件版本。</p><p id="954e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">经过一些尝试，我成功地拥有了一个稳定的环境。配置Hadoop以在集群中使用Yarn的下一步是将两者结合起来[2，4]。</p><p id="3721" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意—由于火花，除了节点pi1 (pi1 -&gt;主节点)之外，所有节点都具有相同的配置(p2、p3、… -&gt;工作节点)。同样，我的GitHub存储库中有可用的配置。我已经提供了所有节点的配置。</p><p id="9c65" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为所有节点创建文件夹:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="efb1" class="oj ni iq of b gy ok ol l om on">$ clustercmd-sudo mkdir -p /opt/hadoop_tmp/hdfs<br/>$ clustercmd-sudo chown –R pi:pi /opt/hadoop_tmp<br/>$ clustercmd-sudo mkdir -p /opt/hadoop<br/>$ clustercmd-sudo chown -R pi:pi /opt/Hadoop</span></pre><p id="3ea0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下一步将从Hadoop中删除所有数据。如果有重要的事情，先做好备份。</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="bad8" class="oj ni iq of b gy ok ol l om on">$ clustercmd rm –rf /opt/hadoop_tmp/hdfs/datanode/*<br/>$ clustercmd rm –rf /opt/hadoop_tmp/hdfs/namenode/*</span></pre><p id="72fc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意，火花只会存在于主人身上。</p><p id="38e4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">复制Hadoop:</p><p id="89f3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">来自pi1:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="5091" class="oj ni iq of b gy ok ol l om on">pi@pi1:~$  rsync -vaz  /opt/hadoop   pi2:/opt/ hadoop   <br/>pi@pi1:~$  rsync -vaz  /opt/hadoop   pi3:/opt/ hadoop   <br/>pi@pi1:~$  rsync -vaz  /opt/hadoop   pi4:/opt/ hadoop</span></pre><p id="128d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对所有节点都这样做。</p><p id="c572" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我更喜欢一个一个做，确认没有异常行为。</p><p id="04d2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，需要编辑以下文件，更改配置:</p><p id="f80d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/core-site.xml" rel="noopener ugc nofollow" target="_blank">/opt/Hadoop/etc/Hadoop/core-site . XML</a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="a1e3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/hdfs-site.xml" rel="noopener ugc nofollow" target="_blank">/opt/Hadoop/etc/Hadoop/<em class="lk">HDFS-site . XML</em>T19】</a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="1f2d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意—属性<strong class="kq ja"> <em class="lk"> dfs.replication </em> </strong>表示数据在集群中复制的次数。您可以设置在两个或更多节点上复制所有数据。不要输入高于实际工作节点数的值。我用1是因为我的一个笔记本用的是16GB的micro SD。由于新冠肺炎病毒爆发，我的一些部分在邮件中延迟了。如果配置错误，由于缺乏资源，您的spark应用程序将陷入“已接受”状态。</p><p id="382b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意—最后一个属性<strong class="kq ja"><em class="lk">DFS . permissions . enabled</em></strong>被设置为<strong class="kq ja"> false </strong>以禁用权限检查。我使用集群外部机器上的spark，这方便了我的访问。显然，我建议不要在生产环境中使用这个设置。我还关闭了安全模式。为此，在完成安装运行后:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="e38c" class="oj ni iq of b gy ok ol l om on"> hdfs dfsadmin -safemode leave</span></pre><p id="af04" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">数据在集群中复制的次数。您可以设置在两个或更多节点上复制所有数据。不要输入高于实际工作节点数的值。我用1是因为我的一个笔记本用的是16GB的micro SD。由于新冠肺炎病毒爆发，我的一些部分在邮件中延迟了。如果配置错误，由于缺乏资源，您的spark应用程序将陷入“已接受”状态。</p><p id="48b2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/mapred-site.xml" rel="noopener ugc nofollow" target="_blank">/opt/Hadoop/etc/Hadoop/<em class="lk">mapred-site . XML</em></a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="b51a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/yarn-site.xml" rel="noopener ugc nofollow" target="_blank">/opt/Hadoop/etc/Hadoop/<em class="lk">yarn-site . XML</em></a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="9e4e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">创建两个文件:</p><p id="6738" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/master" rel="noopener ugc nofollow" target="_blank"><em class="lk">/opt/Hadoop/etc/Hadoop/master</em>T21】</a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="a0dc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/workers" rel="noopener ugc nofollow" target="_blank"><em class="lk">/opt/Hadoop/etc/Hadoop/workers</em></a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="9f56" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">更新所有节点上的配置文件后，需要格式化数据空间并启动集群(可以从任何节点启动):</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="00c9" class="oj ni iq of b gy ok ol l om on">$ hdfs namenode -format -force</span><span id="7677" class="oj ni iq of b gy oo ol l om on">$ start-dfs.sh<br/>$ start-yarn.sh</span></pre><h1 id="a9c0" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">3.4配置火花</h1><p id="3e36" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">基本上，您需要创建/编辑以下配置文件:</p><p id="7d7a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/spark/conf/spark-defaults.conf" rel="noopener ugc nofollow" target="_blank"><em class="lk">/opt/spark/conf/spark-defaults . conf</em>T29】</a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="8da7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些值可以根据您的硬件进行调整，但它们将适用于Raspberry Pi 4 4GB。</p><p id="0efc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">将环境变量设置为:</p><p id="5f68" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/spark/conf/spark-env.sh" rel="noopener ugc nofollow" target="_blank"><em class="lk">/opt/spark/conf/</em>spark-env . sh</a></p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="aa2e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在所有节点中安装以下软件包，以便允许节点处理用python/pyspark准备的作业:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="52b0" class="oj ni iq of b gy ok ol l om on">sudo apt intall python3 python-is-python3</span></pre><h1 id="8730" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">3.5测试集群</h1><p id="79f8" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">重新启动所有节点，并重新启动服务:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="df53" class="oj ni iq of b gy ok ol l om on">$ start-dfs.sh<br/>$ start-yarn.sh</span></pre><p id="92b0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">您可以发送一个应用示例来测试spark:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="8df7" class="oj ni iq of b gy ok ol l om on">$ spark-submit --deploy-mode client --class org.apache.spark.examples.SparkPi /opt/spark/examples/jars/spark-examples_2.12-3.0.0.jar</span></pre><p id="f100" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在处理结束时，您应该会收到PI值的近似计算结果:</p><pre class="nb nc nd ne gt oe of og oh aw oi bi"><span id="45bd" class="oj ni iq of b gy ok ol l om on"><strong class="of ja">Pi is roughly 3.140555702778514</strong></span></pre><p id="1fa9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">(这个圆周率计算需要改进！！！！)</p><h1 id="6e86" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">3.6面向Hadoop和Yarn的Web应用</h1><h1 id="c7fb" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">Hadoop webUi</h1><p id="5edc" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">h <a class="ae lu" href="http://pi1:9870/" rel="noopener ugc nofollow" target="_blank"> ttp://pi1:9870/ </a></p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi or"><img src="../Images/e1ad6b8d99789e280e551ff1a459ab07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*NS1YYGwTk32KdDFfFCT6pg.png"/></div></figure><p id="56d7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最初，我无法在线处理(上传/删除)文件。以下网址提供了一种解决方法:</p><div class="ma mb gp gr mc md"><a href="https://community.cloudera.com/t5/Support-Questions/unable-to-upload-files-to-hdfs/td-p/33650" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd ja gy z fp mi fr fs mj fu fw iz bi translated">无法将文件上传到hdfs</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">当我试图上传文件到HDFS，它显示“错误:未定义”。然而，从终端我可以成功上传文件…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">community.cloudera.com</p></div></div><div class="mm l"><div class="os l mo mp mq mm mr ms md"/></div></div></a></div><p id="a931" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该解决方法是通过向Hadoop<a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster/blob/master/pi1/opt/hadoop/etc/hadoop/core-site.xml" rel="noopener ugc nofollow" target="_blank"><em class="lk">core-site . XML</em></a>添加以下属性来实现的:</p><figure class="nb nc nd ne gt nf"><div class="bz fp l di"><div class="op oq l"/></div></figure><h1 id="d663" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">Yarn WebUi</h1><p id="f48d" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated"><a class="ae lu" href="http://pi1:8088/" rel="noopener ugc nofollow" target="_blank"> http://pi1:8088/ </a></p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/c92a4159446238719080292ddec3fcc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*ysqe_2AcPZNRjAugxvhz8Q.png"/></div></figure><h1 id="7d72" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">然后</h1><div class="ma mb gp gr mc md"><a rel="noopener follow" target="_blank" href="/assembling-a-personal-data-science-big-data-laboratory-in-a-raspberry-pi-4-or-vms-cluster-8a1da8d49b48"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd ja gy z fp mi fr fs mj fu fw iz bi translated">数据科学/大数据实验室——第3部分(共4部分): 3节点集群中Ubuntu上的Hive和Postgres</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">使用Hadoop、Spark、Hive、Kafka在Raspberry Pi 4或VMs集群中组建数据科学/大数据实验室…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">towardsdatascience.com</p></div></div><div class="mm l"><div class="ou l mo mp mq mm mr ms md"/></div></div></a></div><p id="0f17" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[1] P. G .塔兰蒂。<a class="ae lu" href="https://github.com/ptaranti/RaspberryPiCluster" rel="noopener ugc nofollow" target="_blank">https://github.com/ptaranti/RaspberryPiCluster</a></p><p id="400a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[2]华生。<a class="ae lu" href="https://dev.to/awwsmm/building-a-raspberry-pi-hadoop-spark-cluster-8b2" rel="noopener ugc nofollow" target="_blank">构建Raspberry Pi Hadoop / Spark集群</a> (2019)</p><p id="9421" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[3]梁伟雄。<a class="ae lu" href="https://medium.com/analytics-vidhya/build-raspberry-pi-hadoop-spark-cluster-from-scratch-c2fa056138e0" rel="noopener">从零开始构建Raspberry Pi Hadoop/Spark集群</a> (2019)</p><p id="49cd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[4]霍巴特。<a class="ae lu" href="https://www.linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/" rel="noopener ugc nofollow" target="_blank">如何安装和设置3节点Hadoop集群</a> (2019)</p></div></div>    
</body>
</html>