<html>
<head>
<title>Train without labeling data using Self-Supervised Learning by Relational Reasoning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过关系推理使用自我监督学习进行无标记数据训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9?source=collection_archive---------9-----------------------#2020-08-13">https://towardsdatascience.com/train-without-labeling-data-using-self-supervised-learning-by-relational-reasoning-b0298ad818f9?source=collection_archive---------9-----------------------#2020-08-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b5ec" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这个故事的目的是介绍使用表示学习在深度学习中训练未标记数据的新方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/35773b727049f97b416863ca842d6553.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K3HDDMwAsjIxXipf"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@ninjason?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">梁杰森</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="fb13" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">背景和挑战📋</h1><p id="e52f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated"><span class="l mo mp mq bm mr ms mt mu mv di">在现代深度学习算法</span>中，对未标记数据的人工标注的依赖是主要限制之一。为了训练一个好的模型，通常我们需要准备大量的标注数据。在只有少量类和数据的情况下，我们可以使用来自标注公共数据集的预训练模型，并使用您的数据微调最后几个图层。然而，在现实生活中，当您的数据相当大时(商店中的产品或人脸，..)并且对于仅具有几个可训练层的模型来说学习将是困难的。此外，未标记的数据(例如，文档文本、互联网上的图像)的数量是不可计数的。将它们全部标记出来几乎是不可能的，但是不利用它们绝对是一种浪费。</p><p id="3026" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在这种情况下，使用新的数据集从头开始再次训练深度模型将是一种选择，但这需要花费大量的时间和精力来标记数据，而使用预训练的深度模型似乎不再有帮助。这就是<strong class="lt iu">自我监督学习</strong>诞生的原因。这背后的想法很简单，它服务于两个主要任务:</p><ul class=""><li id="bc4b" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated"><strong class="lt iu">代理任务:</strong>深度模型将从没有注释的未标记数据中学习可概括的表示，然后将能够利用隐含信息自生成监控信号。</li><li id="ef7f" class="nb nc it lt b lu nk lx nl ma nm me nn mi no mm ng nh ni nj bi translated"><strong class="lt iu">下游任务:</strong>表示将针对监督学习任务<strong class="lt iu"> </strong>进行微调，例如使用较少数量的标记数据进行分类和图像检索(标记数据的数量取决于基于您需求的模型的性能)</li></ul><p id="1e56" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">提出了许多不同的训练方法来学习这样的表示:<strong class="lt iu">相对位置[1]:</strong><strong class="lt iu"/>模型需要理解对象的空间上下文，以告知部件之间的相对位置；<strong class="lt iu">拼图[2]: </strong>模型需要将 9 个洗牌后的小块放回原来的位置；<strong class="lt iu">彩色化[3]: </strong>该模型已经被训练为对灰度输入图像进行彩色化；准确地说，任务是将该图像映射到量化颜色值输出上的分布；<strong class="lt iu">计数特征【4】:</strong>该模型通过<em class="np">缩放</em> <strong class="lt iu"> <em class="np"> </em> </strong>和<strong class="lt iu"> <em class="np"> </em> </strong> <em class="np">平铺，利用输入图像的特征计数关系学习特征编码器；</em> <strong class="lt iu"> SimCLR [5]: </strong>该模型通过潜在空间中的对比损失，最大化同一样本的不同增强视图之间的一致性，来学习视觉输入的表示。</p><p id="de04" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">然而，我想介绍一种有趣的方法，它能够像人一样识别事物。人类学习的关键因素是通过比较相关和不同的实体来获取新知识。因此，如果我们可以通过<strong class="lt iu">关系推理方法[6]在自我监督的机器学习中应用类似的机制，这将是一个重要的解决方案。</strong></p><p id="9e4e" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">关系推理范式基于一个关键的设计原则:使用关系网络作为无标签数据集上的可学习函数，以量化同一对象的视图之间的关系(内部推理)和不同场景中不同对象之间的关系(内部推理)。通过在标准数据集(CIFAR-10、CIFAR-100、CIFAR-100–20、STL-10、tiny-ImageNet、SlimageNet)、学习时间表和主干网(浅层和深层)上的性能，评估了通过关系推理在自我监督机器学习中利用类似机制的可能性。结果表明<strong class="lt iu">关系推理方法</strong>在所有条件下都大大超过了最好的竞争对手，平均准确率为 14%,比最新的最先进方法高出 3%,如本文<a class="ae ky" href="https://arxiv.org/abs/2006.05849" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu"/></a>【6】所示。</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h1 id="f010" class="kz la it bd lb lc nx le lf lg ny li lj jz nz ka ll kc oa kd ln kf ob kg lp lq bi translated">技术亮点📄</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/ea748de75c4680dad01ad5dded241671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z35_xV8KtgvtHgjsHPW2zg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">关系定义示例(图片由作者提供)</p></figure><p id="9893" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">最简单的解释，<strong class="lt iu">关系推理</strong>只是一种方法论，试图帮助学习者理解不同对象(思想)之间的关系，而不是单独学习对象。这可以帮助学习者根据他们的差异轻松区分和记忆对象。<strong class="lt iu">关系推理系统[6]有两个主要组成部分:主干</strong> <strong class="lt iu">结构</strong>和<strong class="lt iu">关系头</strong>。<strong class="lt iu">关系头</strong>用于<strong class="lt iu">托词任务</strong>阶段，用于支持底层神经网络主干学习未标记数据集中的有用表示，然后它将被丢弃。<strong class="lt iu">主干结构</strong>在托词任务中训练后用于下游任务，如分类或图像检索。</p><ul class=""><li id="f80c" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated"><strong class="lt iu">前期工作:</strong>关注<strong class="lt iu">场景内</strong>关系，意思是<br/>同一物体中的所有元素都属于同一个场景(比如一个篮子里的球)；标签数据集上的训练，主要目标是关系头[7]。</li><li id="e140" class="nb nc it lt b lu nk lx nl ma nm me nn mi no mm ng nh ni nj bi translated"><strong class="lt iu">新方法:</strong>关注同一对象不同视角之间的关系(<strong class="lt iu">内推理</strong>)和不同场景不同对象之间的关系(<strong class="lt iu">间推理</strong>)；在未标记的数据和关系头上使用关系推理是在底层主干中学习有用表示的借口任务。</li></ul><p id="013a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">让我们讨论一下<strong class="lt iu">关系推理系统中某个部分的重点:</strong></p><ol class=""><li id="9f5a" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm od nh ni nj bi translated"><strong class="lt iu">小批量增加:</strong></li></ol><p id="5f17" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">如前所述，本系统引入了<strong class="lt iu">内推理</strong>和<strong class="lt iu">间推理</strong>？那么我们为什么需要它们呢？当没有给出标签时，不可能创建相似和不相似的对象对。为了解决这个问题，应用了自举技术，形成了<strong class="lt iu">内推理</strong>和<strong class="lt iu">间推理</strong>，其中<strong class="lt iu"> : </strong></p><ul class=""><li id="ff98" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated"><strong class="lt iu">内部推理</strong>包括对同一对象的随机增强进行采样{ A1A2 }(积极的一对)(例如，对同一篮球的不同看法)</li><li id="9ae7" class="nb nc it lt b lu nk lx nl ma nm me nn mi no mm ng nh ni nj bi translated"><strong class="lt iu">交互推理</strong>包括耦合两个随机对象{ A1B1}(负对)(如随机球篮球)</li></ul><p id="fffa" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">此外，随机增强函数(例如几何变换、颜色失真)的使用也被认为使场景间的推理更加复杂。这些增强功能的好处迫使学习者(骨干)注意更广泛的一组特征(例如，颜色、大小、纹理等)之间的相关性。).例如，在{脚球，篮球}对中，颜色本身就是该类别的一个强有力的预测因素。然而，随着颜色以及形状大小的随机变化，学习者现在很难区分这对之间的差异。学习者必须看一看另一个特征，因此，它导致更好的表示。</p><p id="ac99" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu"> 2。度量学习</strong></p><p id="4eb5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">度量学习的目的是使用距离度量来拉近相似输入(肯定)的表示，同时移开不同输入(否定)的表示。然而，在<strong class="lt iu">关系推理中，</strong>度量学习有着根本的不同:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/34f683637ea89280d6bc7a2726041d23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3mt3IpJof7bDhgzrL2qL2w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">度量学习和关系推理的比较</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/328b3f6dfa4dbf0178f31136dfa78f45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P2zYvx_9MfjRi30Gezr4wA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">学习指标—对比损失(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/cb4ad5c7a680ccf81f71b3068e33bc61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GZ3v9zG3mRJFFemh5inbJg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">学习指标—关系得分(作者图片)</p></figure><p id="1cd2" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu"> 3。损失函数</strong></p><p id="e431" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">学习的目标是呈现对上的二元分类问题。因此，我们可以使用二元交叉熵损失来最大化伯努利对数似然，其中关系分数 y 表示通过 sigmoid 激活函数诱导的表示成员的概率估计。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/2a4e2f341992564c4fd2b9f07ed8cf45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AqmMohnXNzpfWmvk2-Tafw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">损失函数</p></figure><p id="1b0a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">最后，本文[6]还提供了在标准数据集(CIFAR-10，CIFAR-100，CIFAR-100–20，STL-10，tiny-ImageNet，SlimageNet)，不同主干(浅层和深层)，相同学习时间表(epochs)上的关系推理结果。结果如下，要了解更多信息，你可以看看他的论文。</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h1 id="845f" class="kz la it bd lb lc nx le lf lg ny li lj jz nz ka ll kc oa kd ln kf ob kg lp lq bi translated">实验评估📊</h1><p id="cd4c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本文中，我想在公共图像数据集<strong class="lt iu"> STL-10 </strong>上重现<strong class="lt iu">关系推理系统</strong>。该数据集包括 10 个类(飞机、鸟、汽车、猫、鹿、狗、马、猴子、船、卡车)，颜色为 96x96 像素。</p><p id="c428" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">首先，我们需要导入一些重要的库</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="4f35" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">STL-10 数据集由 1300 个标记图像组成(500 个用于训练，800 个用于测试)。然而，它还包括 100000 张未标记的图片，这些图片来自类似但更广泛的图片分布。例如，它包含其他类型的动物(熊、兔子等。)和交通工具(火车、公共汽车等。)除了标记集中的那些</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/847a5ed1e7a840e4e0d616582588b4d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3lZV0CJfvKGHlVyB5fPXVg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">STL-10 数据集</p></figure><p id="abba" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">然后我们将根据作者的建议创建关系推理类</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="e113" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">为了比较关系推理方法在浅层和深层模型上的性能，我们将创建一个浅层模型(Conv4)并使用深层模型的结构(Resnet34)。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="d147" class="oq la it om b gy or os l ot ou">backbone = Conv4() <em class="np"># shallow model</em><br/>backbone = models.resnet34(pretrained = False)<em class="np"> # deep model</em></span></pre><p id="c864" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">根据作者的建议，设置了一些超参数和增强策略。我们将在未标记的 STL-10 数据集上用关系头训练我们的主干。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/32a656e6ec5a24d6acf816dc2b0a25be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jEAnyVtlGpd_q_1oxwPrTw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">每批图像样本(K =16)</p></figure><p id="5cf1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">到目前为止，我们已经创建了训练模型所需的一切。现在，我们将在 10 个时期和 16 个增强图像(K)中训练主干和关系头部模型，通过 1 个 GPU Tesla P100-PCIE-16GB，浅层模型(Conv4)花费了 4 个小时，深层模型(Resnet34)花费了 6 个小时(您可以自由更改时期的数量以及另一个超参数以获得更好的结果)</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="5274" class="oq la it om b gy or os l ot ou">device = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")</span><span id="df32" class="oq la it om b gy ow os l ot ou">backbone.to(device)<br/>model = RelationalReasoning(backbone, feature_size)    <br/>model.train(tot_epochs=tot_epochs, train_loader=train_loader)<br/>torch.save(model.backbone.state_dict(), 'model.tar')</span></pre><p id="3cfd" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在训练我们的主干模型之后，我们丢弃关系头，并且仅将主干用于下游任务。我们需要用 STL-10 (500 张图片)中的标记数据来微调我们的主干，并在测试集中测试最终的模型(800 张图片)。训练和测试数据集将在没有扩充的情况下加载到 Dataloader 中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="6485" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们将加载预训练的主干模型，并使用简单的线性模型将输出要素与数据集中的多个类连接起来。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="48df" class="oq la it om b gy or os l ot ou"><em class="np"># linear model</em><br/>linear_layer = torch.nn.Linear(64, 10) # if backbone is Conv4<br/>linear_layer = torch.nn.Linear(1000, 10) # if backbone is Resnet34</span><span id="0586" class="oq la it om b gy ow os l ot ou"><em class="np"># defining a raw backbone model</em><br/>backbone_lineval = Conv4() <em class="np"># Conv4<br/></em>backbone_lineval = models.resnet34(pretrained = False) <em class="np"># Resnet34</em></span><span id="1335" class="oq la it om b gy ow os l ot ou"># load model<br/>checkpoint = torch.load('model.tar') # name of pretrain weight<br/>backbone_lineval.load_state_dict(checkpoint)</span></pre><p id="fe0d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">此时，只有线性模型将被训练，主干模型将被冻结。首先，我们将看到微调 Conv4 的结果</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="2503" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">然后在测试集上检查</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="35f1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Conv4 在测试集上获得了 49.98%的准确率，这意味着主干模型可以在未标记的数据集中学习有用的特征，我们只需要用很少的时期进行微调就可以获得很好的结果。现在让我们检查深度模型的性能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="a2d8" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">然后在测试数据集上进行评估</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="d511" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在测试集上，我们可以获得 55.38%的准确率。在本文中，主要目标是再现和评估关系推理方法，以教导模型在没有标签的情况下区分对象，因此，这些结果是非常有希望的。如果你觉得不满意，你可以通过改变超参数如增强数、历元数或模型结构来自由地做实验。</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h1 id="01f9" class="kz la it bd lb lc nx le lf lg ny li lj jz nz ka ll kc oa kd ln kf ob kg lp lq bi translated">最后的想法📕</h1><p id="83b4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">自监督关系推理在定量和定性方式上都是有效的，并且具有从浅到深结构的不同大小的主干。通过比较学习的表征可以很容易地从一个领域转移到另一个领域，它们是细粒度的和紧凑的，这可能是由于准确性和增强数量之间的相关性。根据作者的实验[4]，在关系推理中，扩充的数量在影响对象群的质量方面起着主要作用。自监督学习在许多方面具有成为机器学习的未来的强大潜力。</p><p id="325d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">如果你想进一步讨论，可以联系我。这是我的 Linkedin</p><p id="ca18" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">尽情享受吧！！！👦🏻</p><h1 id="8c76" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="2ad3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">[1]卡尔·多施等人。al，通过上下文预测的无监督视觉表征学习，2015。</p><p id="d3fe" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[2]迈赫迪·诺鲁齐等人。al，通过解决拼图游戏实现视觉表征的无监督学习，2017。</p><p id="7d12" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[3]张等。al，彩色图像彩色化，2016。</p><p id="6522" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[4]迈赫迪·诺鲁齐等人。al，通过学习计数进行表征学习，2017。</p><p id="3120" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[5]陈婷等人视觉表征对比学习的简单框架，2020。</p><p id="8b2b" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">6 马西米利亚诺·帕塔基奥拉等人。al，<br/>表征学习的自监督关系推理，2020。</p><p id="e4e3" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">7 亚当·桑托罗等人。al，关系递归神经网络，2018。</p></div></div>    
</body>
</html>