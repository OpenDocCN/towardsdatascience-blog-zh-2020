<html>
<head>
<title>Reading Color Blindness Charts: Deep Learning and Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阅读色盲图表:深度学习和计算机视觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reading-color-blindness-charts-deep-learning-and-computer-vision-a8c824dd71cd?source=collection_archive---------13-----------------------#2020-01-26">https://towardsdatascience.com/reading-color-blindness-charts-deep-learning-and-computer-vision-a8c824dd71cd?source=collection_archive---------13-----------------------#2020-01-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4cb1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">转换数据，使其与类似的数据集兼容</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/33a5c0b7bacb81721915f0e32dd6b8bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hoILlr6J8MWPURMqgg1mSw.jpeg"/></div></div></figure><p id="97aa" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">有很多在线教程，你可以学习训练一个神经网络，使用<a class="ae ln" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST </a>数据集对手写数字进行分类，或者区分猫和狗。我们人类总是非常擅长这些任务，可以轻松地匹配或击败训练有素的模型的性能。</p><p id="0281" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">情况并非总是如此。在这个项目中，我想探索一个我个人非常纠结的任务。我有轻度红绿色盲。所以，这样的图表对我来说通常很难看到，如果不是不可能的话:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/d7826d8153f2b6a1804f989a991851bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*TK103FjwMdEYJknXrGMhdA.png"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">这是一个6(我想？)</p></figure><p id="f08b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">有没有可能让我训练一个模型来帮我完成这项任务，而不用我眯着眼睛，不可避免地把问题弄错？</p><p id="eb11" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">乍一看，这个任务似乎很简单。我们可以拍摄一些图像，将它们分成训练集和测试集，然后训练一个卷积神经网络。除了…没有数据集。在网上，我只能找到54个不同的图像，这对于一个训练集来说是不够的，因为有9个类别(数字1-9)。</p><p id="0ea0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如何解决这个问题？我们仍然有包含单个手写数字图像的MNIST数据集。我们可以使用这个数据集来训练一个擅长分类单个数字的神经网络。通过一些OpenCV转换，我们可以让色盲图表看起来类似于MNIST图像，就像这样:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/bac8ccc71875ef261765f1cbb175cfbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*PLnZQ_75FH0xhIfY0qa7_A.png"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">手写5</p></figure><p id="2117" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们开始吧！</p><h1 id="053e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">在MNIST数据集上训练卷积神经网络</h1><p id="ad0a" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">有很多关于这方面的<a class="ae ln" href="https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/" rel="noopener ugc nofollow" target="_blank">教程</a>，但我还是会给出一个关于这是如何完成的高层次概述。</p><p id="e518" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们需要安装Tensorflow，它可以通过pip获得。如果没有安装，请在终端中运行以下命令。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="fe4c" class="mw lv iq ms b gy mx my l mz na">pip install tensorflow</span></pre><p id="845f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">或者如果你有一个图形处理器:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="832e" class="mw lv iq ms b gy mx my l mz na">pip install tensorflow-gpu</span></pre><p id="3be1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们将创建一个mnist.py文件并获取我们的训练数据，由于mnist数据集的流行，这些数据内置于tensorflow中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="1886" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们将建立我们的卷积神经网络。我不会详细介绍这些是如何在内部工作的，但是网上有很多资源可以阅读，比如<a class="ae ln" href="https://www.datacamp.com/tutorial/convolutional-neural-networks-python" rel="noopener ugc nofollow" target="_blank">这个</a>。我们将使用一个Conv2D层，然后是MaxPooling和Dropout。然后，我们的2D输出被展平并通过具有128个单元的密集层，接着是具有10个类(编号0–9)的分类层。输出将是长度为10的向量，以指示预测。例如，2会被预测成这样:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="3f57" class="mw lv iq ms b gy mx my l mz na">[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</span></pre><p id="619e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因为1在第二个索引中。以下是型号代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="8b2d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们编译模型，在训练数据上运行它，在测试数据上评估它，并将模型作为. h5文件保存在我们的目录中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="8d3d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当我们运行这段代码时，我们得到了大约99%的训练准确率和98%的测试集准确率:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/ad0233232d48451c890dd112a68ed08c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*piKr4to53YfylvgMVAG5iw.png"/></div></figure><p id="7cab" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还不错！现在，您应该在您的目录中看到一个mnist.h5文件。现在，让我们进入下一步。</p><h1 id="352b" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">OpenCV图表处理</h1><p id="9a80" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">下一个目标是获取现有的图表，并将其转换为与MNIST数据尽可能相似的形式，我们保存的模型在分类方面非常出色。对于这一部分，我们还需要几个库:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="9e0a" class="mw lv iq ms b gy mx my l mz na">pip install opencv-python<br/>pip install imutils<br/>pip install numpy<br/>pip install sklearn<br/>pip install scikit-image</span></pre><p id="3815" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们的目标是这样的转变:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/99632753fb5fd003e18c198a75b4cb0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CljY_UXKbNFMYYRrjFMPsA.png"/></div></div></figure><p id="4ae6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">经过一些实验后，下面是我们需要做的处理:</p><ol class=""><li id="4037" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nk nl nm nn bi translated">增加对比度，使手指的颜色更明显。</li><li id="4565" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">应用中值和高斯模糊来平滑我们在原始图像中看到的小圆圈。</li><li id="4c6e" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">应用K-均值颜色聚类获得一致的颜色斑点。</li><li id="c51d" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">转换为灰度</li><li id="10b4" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">应用阈值处理(这将是棘手的)来得到一个只用黑白的图像。</li><li id="4907" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">更多模糊和阈值处理</li><li id="7768" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">形态学开放、封闭、侵蚀</li><li id="02b6" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">骨骼化</li><li id="25b1" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">扩张</li></ol><p id="8995" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">哇，太多了。让我们从对比开始。我从网上复制了一个函数，它接收一幅图像并应用定制的亮度和对比度变换。我把它放在一个文件ContrastBrightness.py中，并使它成为一个类:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="53a1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在高水平上，增加亮度会将值添加到图像的RGB通道，而增加对比度会将值乘以某个常数。我们将只使用对比功能。</p><p id="0b38" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们算法的另一个复杂部分是聚类。同样，我创建了一个文件Clusterer.py，并将我在网上获得的必要代码放入其中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="7b37" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这段代码将接受一个图像和一个数字作为输入。这个数字K将决定我们将使用多少颜色聚类。你可以在这里阅读更多关于K-means聚类的内容。现在，让我们创建最后一个文件main.py。我们将从导入开始:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="9c70" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请注意，我们正在导入刚刚创建的两个类。现在，请从<a class="ae ln" href="https://github.com/msolonko/colorblindness_classification" rel="noopener ugc nofollow" target="_blank"> my Github </a>下载图表目录中的图片。</p><p id="419b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这些都被分类(在没有色盲的人的帮助下)到适当的文件夹里。</p><p id="6cd7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们将遍历路径中的所有图像，并应用变换1–4。我对我的代码做了大量的注释。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="083b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下面是一些转换后的图像:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/0553fe5a6ec0f62e180cea7fdbd28452.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*FVwevlixYRE26XLIAfxwGw.png"/></div></figure><p id="249d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是一个明显的进步。数字都很清楚，连我都看得一清二楚。仍然存在两个问题:</p><ol class=""><li id="b795" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nk nl nm nn bi translated">它们看起来不是手写的，而且太厚了</li><li id="c8e5" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">它们在黑色背景上不是全白的</li></ol><p id="bab6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以，我们将门槛。然而，由于图像的各种颜色，每一种都需要不同的阈值来工作。我们将自动搜索最佳阈值。我注意到，根据像素数，一个数字通常占整个图像的10–28%。</p><p id="4a3f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，我们将尝试不同的阈值，直到白色百分比在10–28%的范围内。首先，我们将定义一个函数，它告诉我们输入图像中白色所占的百分比。有更短的方法可以做到这一点，但我想明确地展示这是在做什么。我们正在计算所有值为255的像素(255表示白色，0表示黑色)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="130b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们将从阈值0开始，以10为增量增加到255，直到我们处于0.1–0.28区域(此代码进入for循环):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="508b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">厉害！终点在望。现在我们得到这样的图像(如果我们使用我们找到的阈值):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/0f588c97e54f0f268c01109b8c95141d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*naVWEdw0YKQMEUpze-rZvg.png"/></div></figure><p id="69e0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">大多数图像看起来都很不错！然而，有些是有问题的。结果是一些数字比背景暗，就像你看到的右上角的9。因此，阈值处理使它们变黑，而不是变白！从未达到0.1–0.28区域。</p><p id="1635" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们可以通过变量值来检查我们的阈值是否成功。如果threshold变量的值是260，这意味着while循环没有找到一个完美的阈值就结束了。对于这些图像，我们将有一个单独的过程。</p><p id="7046" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本质上，我们会</p><ol class=""><li id="8e27" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nk nl nm nn bi translated">反转图像，使内部比背景明亮</li><li id="4c6c" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">转换成黑白</li><li id="d424" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">创建一个圆形蒙版来遮盖背景(当我们反转时，背景从黑色变成白色)。</li></ol><p id="8652" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是视觉过程:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/3b44bbd91aea9a63d6efe72c8005da0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-8upcDAz02YZOmQiB0CcWA.png"/></div></div></figure><p id="c05a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后一步是最难的，所以我在代码中对它进行了注释。这是我们的整个函数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="890a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将调整代码以使用新函数，并执行步骤6–7。这些都是内置的OpenCV转换，所以没什么好奇怪的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="fac7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们看看图像是什么样的！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/e1947bce59501f9caf475bcb3351d150.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*A5WPTRs9UsTSiSCxfW1IQQ.png"/></div></figure><p id="f304" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">厉害！清晰可辨。最初，我们预计精度约为10%,因为模型输出大小为10，并且其输出基本上是随机的，因为原始图像看起来一点也不像模型所训练的MNIST数据集。有了这些变换后的图像，该模型肯定比随机模型做得更好。如果我们停在这里，我们的准确率大约是63%，比随机准确率高6倍！然而，我们可以做得更多一点。</p><p id="cc2a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将骨骼化和扩大我们的图像。这将使我们的宽度一致，整体看起来更加统一。让我们开始吧:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="d906" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这段代码是我们放在大for循环中的最后一段代码。结果如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/ced0ecb83fc6b6f367e58a6de1e301d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*hcvd6rAEfoj7bVvbX1rYcg.png"/></div></figure><p id="12a1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它们有点参差不齐，但笔迹也是。这些输入对神经网络来说应该不成问题。现在，我们只需重塑我们的列表，加载模型，并进行评估:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="8585" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">将这段代码放在for循环下面。概括地说，我们加载我们的模型，重塑数据，并在评估后打印准确性。</p><h1 id="76b7" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">结果</h1><p id="01c2" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">运行代码后，打印出来的内容如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/b06c4c0de794022f448991bf0bdeb8c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*Jr_S92URjyqPtX1ltzSMyw.png"/></div></figure><p id="ec09" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们来看看吧！我们得到了…的总体精确度。78%!这比随机测试好7-8倍，比中度到重度色盲的人好得多。这是杰出的！</p><p id="2a8a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果我们看看我们对数字的回忆(正确预测的正面观察与实际类别中所有观察的比率)，我们会看到我们对1-5和9有很好的表现。我们在8分的时候表现还可以，我们的神经网络在6分和7分的时候真的很挣扎。</p><p id="2dbd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这种方法显然有局限性，并且我列出的变换并不适用于所有可能的色盲图像(实际上，在阈值化步骤之后，在数据集中有一个图像不适用)。试着打印所有处理过的9，你会看到阈值步骤产生的比率在0.1和0.28之间，但那是因为背景变成了部分白色。我没有试图找到解决这个问题的方法，因为这只影响了一张图片。</p><h1 id="cc06" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">结论</h1><p id="fd7d" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">我希望本教程能够提供关于如何使用相似的数据集对不同的数据集进行预测的信息。另外，我希望本教程能帮助初学者更好地掌握OpenCV、Tensorflow和Python。</p><p id="585c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">要查看完整代码并下载图片和模型，请查看<a class="ae ln" href="https://github.com/msolonko/colorblindness_classification" rel="noopener ugc nofollow" target="_blank"> my Github </a>。</p><h2 id="c9c7" class="mw lv iq bd lw ny nz dn ma oa ob dp me la oc od mg le oe of mi li og oh mk oi bi translated">参考</h2><p id="7d41" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">[1]数据科学栈交换(2020)，<a class="ae ln" href="https://datascience.stackexchange.com/questions/66377/how-to-use-mnist-dataset-to-make-predictions-on-similar-images-colorblindness-c" rel="noopener ugc nofollow" target="_blank">链接</a></p></div></div>    
</body>
</html>