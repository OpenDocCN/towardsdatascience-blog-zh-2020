<html>
<head>
<title>Sequence Models &amp; Recurrent Neural Networks (RNNs)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">序列模型和递归神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sequence-models-and-recurrent-neural-networks-rnns-62cadeb4f1e1?source=collection_archive---------9-----------------------#2020-07-27">https://towardsdatascience.com/sequence-models-and-recurrent-neural-networks-rnns-62cadeb4f1e1?source=collection_archive---------9-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="67c5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解深度递归神经网络(RNNs)</h2></div><h1 id="6e55" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">序列模型</h1><p id="317a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">序列模型是输入或输出数据序列的机器学习模型。序列数据包括文本流、音频片段、视频片段、时间序列数据等。递归神经网络(RNNs)是一种用于序列模型的流行算法。</p><p id="4fb1" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">序列模型的应用 1。语音识别<strong class="lc iu"> : </strong>在语音识别中，给定一个音频片段作为输入，然后模型必须生成它的文本副本。这里输入和输出都是数据序列。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/89574ff50a6d363f9915ed7ae05cded5.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*SH-6kNrcrtxC72tvZttNBQ.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">语音识别(来源:作者)</p></figure><p id="5a14" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">2.情感分类<strong class="lc iu">:情感分类中的</strong>对一段文本中表达的观点进行分类。这里的输入是一个单词序列。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/3ccd777b2da3c8e243bc5ad809922988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*s2R7tR1D-F8Iahg1Ch_Ycw.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">情感分类(来源:作者)</p></figure><p id="9fad" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">3.视频活动识别<strong class="lc iu"> : </strong>在视频活动识别中，模型需要识别视频片段中的活动。视频剪辑是视频帧序列，因此在视频活动识别的情况下，输入是数据序列。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/4783d4e676c17ecd129888186c0ee99e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*Sd-ESd-jNqg6Sp-SA7MzoA.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">视频活动识别(来源:作者)</p></figure><p id="4882" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">这些例子表明序列模型有不同的应用。有时输入和输出都是序列，有时输入或输出都是序列。递归神经网络(RNN)是一种流行的序列模型，它对序列数据表现出高效的性能。</p><h1 id="d598" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">递归神经网络</h1><p id="bb0a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">递归神经网络(RNN)是一种深度学习算法，是一种专门用于处理序列数据的人工神经网络架构。rnn 主要用于自然语言处理领域。RNN 维护内存，因此它们对于涉及顺序数据的机器学习问题非常有效。rnn 也用于时间序列预测。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/a21da27f725aa3d9a4307b4bf4152dd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*r5_VAkwfoV1KtQYu8_zUGw.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">传统的 RNN 建筑(来源:Stanford.edu)</p></figure><p id="259e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">使用 RNNs 而不是标准神经网络的主要优点是标准神经网络中没有共享的特征。在 RNN，权重是跨时间共享的。RNNs 可以记住它以前的输入，但是标准的神经网络不能记住以前的输入。RNN 利用历史信息进行计算。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/6c9081f40c27db983541ccb56bcbef16.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*IJ3QBlbKveEJez38TwhAPQ.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">损失函数</p></figure><p id="3b15" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在 RNN，损失函数是根据每个时间步的损失定义的。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/54a9ee4c48847f809a3ee8a108f75fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*_ZnAJOTnSCtEnV5miRED3Q.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">重量损失的导数</p></figure><p id="a2af" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在 RNN，反向传播在每个时间点进行</p><p id="b496" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu"> RNN 建筑</strong></p><p id="6d37" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">基于输入和输出的数量，有几种 RNN 架构<br/> 1。一对多架构:图像字幕就是这种架构的一个很好的例子。在图像字幕中，它获取一幅图像，然后输出一系列单词。这里只有一个输入，但有许多输出。</p><p id="1ae1" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">2.多对一架构:情感分类是这种架构的一个很好的例子。在情感分类中，给定的句子被分类为肯定或否定。在这种情况下，输入是单词序列，输出是二进制分类。</p><p id="a6f6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">3.多对多架构:在多对多架构中有两种情况，</p><ul class=""><li id="f6db" class="ms mt it lc b ld lw lg lx lj mu ln mv lr mw lv mx my mz na bi translated"><em class="nb">第一种</em>是输入长度等于输出长度。命名实体识别是一个很好的例子，其中输入序列中的单词数等于输出序列中的单词数。</li><li id="8549" class="ms mt it lc b ld nc lg nd lj ne ln nf lr ng lv mx my mz na bi translated"><em class="nb">多对多架构的第二种</em>是当输入长度不等于输出长度时。机器翻译是这种架构的一个很好的场景。在机器翻译中，RNN 阅读一种语言的句子，然后将其转换成另一种语言。这里输入长度和输出长度是不同的。</li></ul><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nh"><img src="../Images/1369ebd2ebebd3919c41e02a4b9911fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*1vSZbTpz8fA9L4HkVOCFGQ.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">RNN 建筑(来源:<a class="ae nm" href="https://calvinfeng.gitbook.io" rel="noopener ugc nofollow" target="_blank">https://Calvin feng . git book . io</a>)</p></figure><h1 id="dca2" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">长短期记忆(LSTM)</h1><p id="ee6c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">传统的 rnn 不擅长捕捉长程相关性。这主要是由于消失梯度问题。当训练非常深的网络时，梯度或导数随着其向下传播而指数下降。这就是所谓的消失梯度问题。这些梯度用于更新神经网络的权重。当梯度消失时，权重将不会更新。有时候会<br/>完全停止神经网络的训练。这种消失梯度问题是非常深的神经网络中的常见问题。</p><p id="8c9c" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">为了克服 RNNs 中的梯度消失问题，Sepp Hochreiter 和 Juergen Schmidhuber 引入了长短期记忆。LSTM 是对 RNN 隐藏层的修改。LSTM 使 RNNs 能够长时间记住它的输入。在 LSTM 中，除了隐藏状态，单元状态被传递到下一个时间步。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nn"><img src="../Images/e873b586856a142810860c5a4b33796c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*maJxFBihvGNM-wteVBA8WQ.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">基本 RNN 和 LSTM 单位的内部结构(资料来源:stanford.edu)</p></figure><p id="94d7" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">LSTM 可以捕捉远程依赖。它可以长时间记忆以前的输入。LSTM 的牢房里有三道门。LSTM 的记忆操作是通过这些门完成的。长短期记忆(LSTM)利用门来控制递归网络记忆中的梯度传播。</p><ul class=""><li id="0187" class="ms mt it lc b ld lw lg lx lj mu ln mv lr mw lv mx my mz na bi translated">遗忘门:遗忘门删除单元状态中不再有用的信息</li><li id="d338" class="ms mt it lc b ld nc lg nd lj ne ln nf lr ng lv mx my mz na bi translated">输入门:输入门增加了对单元状态有用的附加信息</li><li id="c4ff" class="ms mt it lc b ld nc lg nd lj ne ln nf lr ng lv mx my mz na bi translated">输出门:输出门增加了对单元状态有用的附加信息</li></ul><p id="9394" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">LSTM 的这种门控机制允许网络学习何时忘记、忽略或保留记忆单元中的信息。</p><p id="3dfe" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">LSTM 是一种非常流行的序列模型深度学习算法。苹果的 Siri 和谷歌的语音搜索是一些使用 LSTM 算法的真实例子，它是这些应用程序成功的背后。最近的研究表明，LSTM 算法可以提高机器学习模型的性能。LSTM 也用于时间序列预测和文本分类任务。</p><p id="0a78" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">参考文献</strong></p><p id="31c8" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><a class="ae nm" href="https://www.researchgate.net/publication/13853244_Long_Short-term_Memory" rel="noopener ugc nofollow" target="_blank">https://www . researchgate . net/publication/13853244 _ Long _ Short-Short _ Memory</a><br/><a class="ae nm" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks" rel="noopener ugc nofollow" target="_blank">https://Stanford . edu/~ shervine/teaching/cs-230/cheat sheet-recurrent-neural-networks</a></p></div></div>    
</body>
</html>