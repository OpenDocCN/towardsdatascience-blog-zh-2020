<html>
<head>
<title>Gradient-Free Reinforcement Learning: Neuroevolution using Numpy!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无梯度强化学习:使用Numpy的神经进化！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gradient-free-reinforcement-learning-neuroevolution-using-numpy-7377d6f6c3ea?source=collection_archive---------26-----------------------#2020-04-07">https://towardsdatascience.com/gradient-free-reinforcement-learning-neuroevolution-using-numpy-7377d6f6c3ea?source=collection_archive---------26-----------------------#2020-04-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9d6e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我们能解决简单的没有后向通道的RL环境吗？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e32d0feaa1568de00f5c768cbcd22a2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NkQrtUHTsTg9ykn2.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们能训练只有向前传球的网络吗？<a class="ae kv" href="https://pixabay.com/vectors/evolution-walking-charles-darwin-297234/" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><h1 id="8e30" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="724f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如果我告诉你，你可以训练神经网络，而不必计算梯度，只使用前向传递，会怎么样？这就是<strong class="lq ir">神经进化的魔力！</strong>此外，我将展示仅使用Numpy就可以轻松完成所有这些工作！学习统计学你会学到很多基于梯度的方法，但不久前我读到了一篇非常有趣的文章，作者是优步人工智能的人，他表明在解决Atari游戏的挂钟时间方面，一个简单的遗传算法与最复杂的基于梯度的RL方法具有竞争力。我在下面链接了源代码，如果你对强化学习感兴趣，我强烈推荐你读一读。</p><h1 id="b0fd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">什么是神经进化？</h1><p id="1f5e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">首先，对于那些还不知道的人来说，<strong class="lq ir">神经进化</strong>描述了进化和/或遗传算法的应用，以训练神经网络的结构和/或权重，作为一种无梯度的替代方案！我们将在这里使用一个极其简单的神经进化案例，只使用一个固定的拓扑网络，并且只关注优化权重和偏差。神经进化过程可以定义为四个基本步骤，从随机生成的网络池开始，重复这些步骤直到达到收敛。</p><p id="b316" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">1.评估人群的适应性<br/> 2。选择最合适的个体来繁殖<br/> 3。使用最合适网络的副本重新填充<br/> 4。将正态分布突变引入网络权重</p><p id="ff55" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">哇，这似乎很简单！让我们稍微分解一些术语:</p><p id="c826" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">- <strong class="lq ir">适应度</strong>:这简单地描述了网络在某项任务中的表现，并允许我们决定繁殖哪些网络。注意，因为进化算法是非凸优化的一种形式，因此<strong class="lq ir">可以与任何损失函数</strong>一起使用，而不管其可微性(或缺乏可微性)</p><p id="f132" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">- <strong class="lq ir">突变</strong>:这个可能是最简单的！为了改进我们的子网络，我们必须对网络权重引入随机变化，这些变化通常来自均匀或正态分布。可能有许多不同形式的突变:移位突变(将参数乘以一个随机数)、交换突变(用一个随机数替换参数)、符号突变(改变参数的符号)等。我们将只使用简单的附加突变，但这里有很大的创造性空间！</p><h1 id="8770" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">神经进化的优势</h1><p id="7248" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们还应该考虑神经进化模型的理论优势。首先，我们只需要使用网络的前向传递，因为我们只需要计算损失，以确定要繁殖哪些网络。这一点的含义是显而易见的，向后传球通常是最昂贵的！其次，给定足够的迭代次数，进化算法保证找到损失曲面的全局最小值，而基于凸梯度的方法可能陷入局部最小值。最后，更复杂的神经进化形式使我们不仅可以优化网络的权重，还可以优化结构本身！</p><h1 id="db5b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">为什么不总是使用神经进化呢？</h1><p id="9f85" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">嗯，这是一个复杂的问题，但它确实可以归结为当有足够的梯度信息时，精确的梯度下降方法更有效。这意味着损失面越凸，你就越想使用像SGD这样的分析方法，而不是遗传算法。因此，很少会在有监督的情况下使用遗传算法，因为通常有足够的梯度信息可用，传统的梯度下降方法将工作得很好。然而，如果你在RL环境中工作，或者在具有不规则损失表面或低凸性的情况下工作(像顺序GAN)，那么神经进化提供了一个可行的替代方案！事实上，最近有很多研究发现，参数对参数的神经进化模型在这种情况下可以做得更好。</p><h1 id="303a" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">现在让我们开始吧！</h1><h2 id="db09" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">加载库</h2><p id="2bff" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">正如介绍中所述，我们将尝试在这个项目中只使用<strong class="lq ir">numpy，只定义我们需要的助手函数！是的，我知道，gym也在被加载，但只是为了环境；)</strong></p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="227b" class="mp kx iq nc b gy ng nh l ni nj">import numpy as np<br/>import gym</span></pre><h2 id="eec1" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">关于数据</h2><p id="c72f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们将使用gym中的经典CartPole环境来测试我们的网络。目标是观察网络通过左右移动能保持杆子直立多长时间。作为一个RL任务，神经进化的方法应该是很适合的！我们的网络将接受4个观察值作为输入，并将输出左或右作为动作。</p><h2 id="2803" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">助手功能</h2><p id="73e2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们首先要定义几个助手函数来设置我们的网络。首先是relu激活函数，我们将使用它作为隐藏层的激活函数，并使用softmax函数作为网络输出，以获得网络输出的概率估计！最后，当我们需要计算分类交叉熵时，我们需要定义一个函数来生成我们的响应向量的一次性编码。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="942c" class="mp kx iq nc b gy ng nh l ni nj">def relu(x):<br/>    return np.where(x&gt;0,x,0)</span><span id="5a50" class="mp kx iq nc b gy nk nh l ni nj">def softmax(x):<br/>    x = np.exp(x — np.max(x))<br/>    x[x==0] = 1e-15<br/>    return np.array(x / x.sum())</span></pre><h2 id="daff" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">定义我们的网络类</h2><p id="3318" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">现在有趣的事情来了！首先，我们将为群体中的个人网络定义一个类别。我们需要定义一个随机分配权重和偏差并将网络结构作为输入的初始化方法，一个在给定输入的情况下获得概率的预测方法，以及一个在给定输入和响应的情况下返回网络分类交叉熵的评估方法！同样，我们将只使用我们定义的函数或numpy中的函数。请注意，初始化方法也可以将另一个网络作为输入，这就是我们将如何执行世代之间的突变！</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="9008" class="mp kx iq nc b gy ng nh l ni nj"># Lets define a new neural network class that can interact with gym<br/>class NeuralNet():<br/>    <br/>    def __init__(self, n_units=None, copy_network=None, var=0.02, episodes=50, max_episode_length=200):</span><span id="53dd" class="mp kx iq nc b gy nk nh l ni nj">        # Testing if we need to copy a network<br/>        if copy_network is None:<br/>            # Saving attributes<br/>            self.n_units = n_units<br/>            # Initializing empty lists to hold matrices<br/>            weights = []<br/>            biases = []</span><span id="90ae" class="mp kx iq nc b gy nk nh l ni nj">            # Populating the lists<br/>            for i in range(len(n_units)-1):<br/>                weights.append(np.random.normal(loc=0,scale=1,size=(n_units[i],n_units[i+1])))<br/>                biases.append(np.zeros(n_units[i+1]))<br/>            # Creating dictionary of parameters<br/>            self.params = {'weights':weights,'biases':biases}</span><span id="180f" class="mp kx iq nc b gy nk nh l ni nj">        else:<br/>            # Copying over elements<br/>            self.n_units = copy_network.n_units<br/>            self.params = {'weights':np.copy(copy_network.params['weights']),<br/>                          'biases':np.copy(copy_network.params['biases'])}<br/>            # Mutating the weights<br/>            self.params['weights'] = [x+np.random.normal(loc=0,scale=var,size=x.shape) for x in self.params['weights']]<br/>            self.params['biases'] = [x+np.random.normal(loc=0,scale=var,size=x.shape) for x in self.params['biases']]<br/>            </span><span id="8dc1" class="mp kx iq nc b gy nk nh l ni nj">    def act(self, X):<br/>        # Grabbing weights and biases<br/>        weights = self.params['weights']<br/>        biases = self.params['biases']<br/>        # First propgating inputs<br/>        a = relu((X@weights[0])+biases[0])<br/>        # Now propogating through every other layer<br/>        for i in range(1,len(weights)):<br/>            a = relu((a@weights[i])+biases[i])<br/>        # Getting probabilities by using the softmax function<br/>        probs = softmax(a)<br/>        return np.argmax(probs)<br/>        <br/>    # Defining the evaluation method<br/>    def evaluate(self, episodes, max_episode_length, render_env, record):<br/>        # Creating empty list for rewards<br/>        rewards = []</span><span id="76a1" class="mp kx iq nc b gy nk nh l ni nj">        # First we need to set up our gym environment<br/>        env=gym.make('CartPole-v0')</span><span id="19e6" class="mp kx iq nc b gy nk nh l ni nj">        # Recording video if we need to <br/>        if record is True:<br/>            env = gym.wrappers.Monitor(env, "recording")</span><span id="342c" class="mp kx iq nc b gy nk nh l ni nj">        # Increasing max steps<br/>        env._max_episode_steps=1e20<br/>        for i_episode in range(episodes):<br/>            observation = env.reset()<br/>            for t in range(max_episode_length):<br/>                if render_env is True:<br/>                    env.render()<br/>                observation, _, done, _ = env.step(self.act(np.array(observation)))<br/>                if done:<br/>                    rewards.append(t)<br/>                    break<br/>        # Closing our enviroment<br/>        env.close()<br/>        # Getting our final reward<br/>        if len(rewards) == 0:<br/>            return 0<br/>        else:<br/>            return np.array(rewards).mean()</span></pre><h2 id="89ed" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">定义我们的遗传算法类</h2><p id="746e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">最后，我们需要定义一个类来管理我们的种群，执行神经进化中的四个关键步骤！这里我们需要三种方法。首先，创建随机网络池并设置属性的初始化方法。接下来，我们需要一个fit方法，给定一个输入，重复执行上述步骤:首先评估网络，然后选择最适合的，创建子网络，最后变异子网络！最后，我们需要一种预测方法，以便我们可以使用由该类训练的最佳网络。让我们开始测试吧！</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="061e" class="mp kx iq nc b gy ng nh l ni nj"># Defining our class that handles populations of networks<br/>class GeneticNetworks():<br/>    <br/>    # Defining our initialization method<br/>    def __init__(self, architecture=(4,16,2),population_size=50, generations=500,render_env=True, record=False,<br/>                 mutation_variance=0.02,verbose=False,print_every=1,episodes=10,max_episode_length=200):<br/>        # Creating our list of networks<br/>        self.networks = [NeuralNet(architecture) for _ in range(population_size)]<br/>        self.population_size = population_size<br/>        self.generations = generations<br/>        self.mutation_variance = mutation_variance<br/>        self.verbose = verbose<br/>        self.print_every = print_every<br/>        self.fitness = []<br/>        self.episodes = episodes<br/>        self.max_episode_length = max_episode_length<br/>        self.render_env = render_env<br/>        self.record = record<br/>        <br/>    # Defining our fiting method<br/>    def fit(self):<br/>        # Iterating over all generations<br/>        for i in range(self.generations):<br/>            # Doing our evaluations<br/>            rewards = np.array([x.evaluate(self.episodes, self.max_episode_length, self.render_env, self.record) for x in self.networks])<br/>            # Tracking best score per generation<br/>            self.fitness.append(np.max(rewards))<br/>            # Selecting the best network<br/>            best_network = np.argmax(rewards)<br/>            # Creating our child networks<br/>            new_networks = [NeuralNet(copy_network=self.networks[best_network], var=self.mutation_variance, max_episode_length=self.max_episode_length) for _ in range(self.population_size-1)]<br/>            # Setting our new networks<br/>            self.networks = [self.networks[best_network]]+new_networks<br/>            # Printing output if necessary<br/>            if self.verbose is True and (i%self.print_every==0 or i==0):<br/>                print('Generation:',i+1,'| Highest Reward:',rewards.max().round(1),'| Average Reward:',rewards.mean().round(1))<br/>        <br/>        # Returning the best network<br/>        self.best_network = self.networks[best_network]</span></pre><h2 id="56eb" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">测试我们的算法！</h2><p id="5dce" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如上所述，我们将在CartPole问题上测试我们的网络，仅使用1个具有16个节点的隐藏层，以及两个表示向左或向右运动的输出节点。我们还需要对许多集进行平均，这样我们就不会意外地为下一代选择一个糟糕的网络！我在反复试验后选择了这些参数，所以你的里程可能会有所不同！此外，我们将只引入方差为0.05的突变，以便不破坏网络的功能。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="8c87" class="mp kx iq nc b gy ng nh l ni nj"># Lets train a population of networks<br/>from time import time<br/>start_time = time()<br/>genetic_pop = GeneticNetworks(architecture=(4,16,2),<br/>                                population_size=64, <br/>                                generations=5,<br/>                                episodes=15, <br/>                                mutation_variance=0.1,<br/>                                max_episode_length=10000,<br/>                                render_env=False,<br/>                                verbose=True)<br/>genetic_pop.fit()<br/>print('Finished in',round(time()-start_time,3),'seconds')</span><span id="86da" class="mp kx iq nc b gy nk nh l ni nj">Generation: 1 | Highest Reward: 309.5 | Average Reward: 29.2<br/>Generation: 2 | Highest Reward: 360.9 | Average Reward: 133.6<br/>Generation: 3 | Highest Reward: 648.2 | Average Reward: 148.0<br/>Generation: 4 | Highest Reward: 616.6 | Average Reward: 149.9<br/>Generation: 5 | Highest Reward: 2060.1 | Average Reward: 368.3<br/>Finished in 35.569 seconds</span></pre><h2 id="83a8" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">初始随机网络</h2><p id="189f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">首先，让我们看看一个随机初始化的网络如何执行任务。显然，这里没有策略，杆子几乎立刻就倒了。请忽略下面gif中的光标，在健身房录音在Windows上播放不太好！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/50fc8f3d98aa99f650bca806ebd7475d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-uQ_lzcmbOZXwKWl"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:一个随机的代理人试图解决CartPole</p></figure><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="629b" class="mp kx iq nc b gy ng nh l ni nj">random_network = NeuralNet(n_units=(4,16,2))<br/>random_network.evaluate(episodes=1, max_episode_length=int(1e10), render_env=True, record=False)</span></pre><h2 id="33b1" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">五代之后…</h2><p id="0f6f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">仅仅5代之后，我们可以看到我们的网络几乎完全掌握了翻筋斗的艺术！而且只花了大约三十秒的火车时间！请注意，随着进一步的训练，网络学会在几乎100%的时间里保持完全直立，但目前我们只对速度感兴趣，5代相当短！我们应该认为这是神经进化力量的一个很好的例子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/60c82e0c7f1bd2cd3bb04af722e296dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cQlSNEmTvZPJ8xfM"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2:一个训练有素的代理人正在解决横竿任务</p></figure><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="6c0f" class="mp kx iq nc b gy ng nh l ni nj"># Lets observe our best network<br/>genetic_pop.best_network.evaluate(episodes=3, max_episode_length=int(1e10), render_env=True, record=False)</span></pre><h1 id="09e2" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">下一步是什么？</h1><p id="0824" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">显然，未来我们还可以增加很多东西来进一步检验神经进化的有效性。首先，研究不同变异算子(如交叉)的效果是很有趣的。</p><p id="46e2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">转移到TensorFlow或PyTorch等现代深度学习平台也是一个明智的想法。请注意，遗传算法是高度并行化的，因为我们所要做的就是在单个设备上运行每个网络，并向前传递一次。无需镜像权重或复杂的分配策略！因此，每增加一个处理单元，运行时间几乎呈线性减少。</p><p id="a1c4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">最后，我们应该探索不同强化学习任务的神经进化，或者甚至是梯度难以评估的其他情况，例如在生成敌对网络或长序列LSTM网络中。</p><h1 id="5718" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">进一步阅读</h1><p id="85d5" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如果你对神经进化及其应用感兴趣，优步有几篇论文展示了神经进化在强化学习中的现代优势:</p><div class="nn no gp gr np nq"><a href="https://eng.uber.com/tag/deep-neuroevolution/" rel="noopener  ugc nofollow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd ir gy z fp nv fr fs nw fu fw ip bi translated">优步工程博客</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">推动世界发展的软件工程和技术</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">eng.uber.com</p></div></div><div class="nz l"><div class="oa l ob oc od nz oe kp nq"/></div></div></a></div><p id="8672" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这个项目的源代码可以在我的公共GitHub资源库中找到:</p><div class="nn no gp gr np nq"><a href="https://github.com/gursky1/Numpy-Neuroevolution" rel="noopener  ugc nofollow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd ir gy z fp nv fr fs nw fu fw ip bi translated">gur sky 1/Numpy-神经进化</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">如果我告诉你，你可以训练神经网络，而不需要计算梯度，只需要…</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">github.com</p></div></div><div class="nz l"><div class="of l ob oc od nz oe kp nq"/></div></div></a></div><p id="6ac6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果你对这个项目有任何问题，或者只是想讨论深度学习，请随时发送电子邮件到<a class="ae kv" href="mailto:gurskyjacob@gmail.com" rel="noopener ugc nofollow" target="_blank">gurskyjacob@gmail.com</a>给我！</p></div></div>    
</body>
</html>