<html>
<head>
<title>My Favourite Three New Features in Scrapy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Scrapy 中我最喜欢的三个新特性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/my-favourite-three-new-features-in-scrapy-8470cba87d9f?source=collection_archive---------47-----------------------#2020-07-02">https://towardsdatascience.com/my-favourite-three-new-features-in-scrapy-8470cba87d9f?source=collection_archive---------47-----------------------#2020-07-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/9282011d3141b03e34d195fd570a4dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wgRzIRkQzvPsoAKo"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@kmuza" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@kmuza</a></p></figure><div class=""/><div class=""><h2 id="ed5e" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">找出 scrapy 在 2.2 版本中提供的新的网页抓取功能</h2></div><p id="fced" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Scrapy 的新版本上周刚刚发布！在这篇文章中，我将深入探讨 2.2 版本中框架的变化，以及 Scrapy 为您的网络抓取需求提供了哪些很酷的新功能！</p><p id="bfc0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有关可用内容的详细信息以及对这些已实现功能的讨论，请参见发布说明<a class="ae jg" href="https://docs.scrapy.org/en/latest/news.html" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><h2 id="6186" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">在本文中，您将了解到</h2><ol class=""><li id="27d1" class="mn mo jj la b lb mp le mq lh mr ll ms lp mt lt mu mv mw mx bi translated">如何直观地用 scrapy 处理 json</li><li id="5a4c" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">你能从一个文件管道中得到什么信息关于你下载的文件。</li><li id="76f7" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">类型提示和 Scrapy</li></ol><h1 id="ac76" class="nd lv jj bd lw ne nf ng lz nh ni nj mc kp nk kq mf ks nl kt mi kv nm kw ml nn bi translated">新的零碎功能</h1><h2 id="52f7" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">去序列化 JSON 响应</h2><p id="ce3b" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">Scrapy 现在有能力直接从提供 json 数据的网站上解码 json。在此之前，我们必须使用 python 内置的 json 包。这个新特性受到了请求包方法<code class="fe nr ns nt nu b">requests.json()</code>的影响。</p><p id="e2b9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Scrapy 现在可以直接从服务器响应中解码 json 作为 python 对象。在幕后，Scrapy 导入标准库 json 包并调用<code class="fe nr ns nt nu b">json.loads()</code>方法。该方法将获取一个 json 字符串，并将其转换成 python 字典。有关 json 库的概述，请参见这里的<a class="ae jg" href="http://w3schools.com/python/python_json.asp" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="fbbd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看一个 scrapy shell 中的例子</p><pre class="nv nw nx ny gt nz nu oa ob aw oc bi"><span id="b7f3" class="lu lv jj nu b gy od oe l of og">&gt;&gt;&gt; fetch('<a class="ae jg" href="https://api.github.com/events'" rel="noopener ugc nofollow" target="_blank">https://api.github.com/events'</a>)<br/>2020-06-27 07:16:38 [scrapy.core.engine] INFO: Spider opened<br/>2020-06-27 07:16:38 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET <a class="ae jg" href="https://api.github.com/events" rel="noopener ugc nofollow" target="_blank">https://api.github.com/events</a>&gt; (referer: None)<br/>&gt;&gt;&gt; data = response.json()<br/>&gt;&gt;&gt; print(data[0])<br/>{'id': '12750675925', 'type': 'CreateEvent', 'actor': {'id': 51508147, 'login': 'LLGLSS', 'display_login': 'LLGLSS', 'gravatar_id': '', 'url': '<a class="ae jg" href="https://api.github.com/users/LLGLSS'" rel="noopener ugc nofollow" target="_blank">https://api.github.com/users/LLGLSS'</a>, 'avatar_url': '<a class="ae jg" href="https://avatars.githubusercontent.com/u/51508147?'" rel="noopener ugc nofollow" target="_blank">https://avatars.githubusercontent.com/u/51508147?'</a>}, 'repo': {'id': 275306349, 'name': 'LLGLSS/hsshoping', 'url': '<a class="ae jg" href="https://api.github.com/repos/LLGLSS/hsshoping'" rel="noopener ugc nofollow" target="_blank">https://api.github.com/repos/LLGLSS/hsshoping'</a>}, 'payload': {'ref': 'llg', 'ref_type': 'branch', 'master_branch': 'master', 'description': None, 'pusher_type': 'user'}, 'public': True, 'created_at': '2020-06-27T06:11:39Z'}</span></pre><ol class=""><li id="e025" class="mn mo jj la b lb lc le lf lh oh ll oi lp oj lt mu mv mw mx bi translated">在 scrapy shell 中，fetch()类似于 HTTP GET 请求，它获取经过解析的 html。</li><li id="2266" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">现在，如果这个响应是一个 json 字符串，那么 response.json()方法会将 json 解析到一个字典中</li></ol><p id="37ba" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这使得处理 json 比以前更加流畅，太棒了！继续前进，在你的新的网络抓取项目中使用它。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/e4d2ded473b1e55a438759ddcf4c4993.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HZqVf8Ziicdva-kd"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@ev" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@ev</a></p></figure><h2 id="50e5" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">下载文件的状态</h2><p id="90cf" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">当使用 Scrapy 下载一个文件时，你会使用所谓的文件管道。管道只是 http 请求将经历的一系列操作，这些操作要么被处理，要么不被处理。</p><p id="5b7c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尝试下载文件或完成下载文件后，文件管道填充包含文件路径、校验和等信息的字典。当文件管道完成时，关于下载的信息存储在一个名为<code class="fe nr ns nt nu b">results</code>的变量中，该变量包含一个 2 元素元组列表<code class="fe nr ns nt nu b">(success, file_info_or_error)</code>。</p><p id="b6a0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nr ns nt nu b">success</code>变量要么取真值，要么取假值，而<code class="fe nr ns nt nu b">file_info_or_error</code>变量是关于这个文件的信息字典。</p><p id="e1bf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果<code class="fe nr ns nt nu b">success</code>变量为真。一个名为<code class="fe nr ns nt nu b">status</code>的<code class="fe nr ns nt nu b">file_info_or_error</code>字典的新键现在已经被添加，它告诉我们我们的文件是否已经被下载。该状态键可以取三个值之一</p><ol class=""><li id="585f" class="mn mo jj la b lb lc le lf lh oh ll oi lp oj lt mu mv mw mx bi translated">下载</li><li id="5a9c" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">已更新—文件未被下载，因为它最近被下载过</li><li id="ddc5" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">缓存—文件已经计划下载</li></ol><p id="f9aa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果<code class="fe nr ns nt nu b">success</code>变量为假，这意味着文件还没有被下载，并且<code class="fe nr ns nt nu b">file_info_or_error</code>字典会忽略这个错误。</p><p id="a250" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">文件管道创建的<code class="fe nr ns nt nu b">results</code>变量的一个例子是这样的。</p><pre class="nv nw nx ny gt nz nu oa ob aw oc bi"><span id="5849" class="lu lv jj nu b gy od oe l of og">[<br/>   (True, {'checksum': '2b00042f7481c7b056c4b410d28f33cf',             'path': 'full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg',             'url': 'http://www.example.com/files/product1.pdf'}),             'url': 'http://www.example.com/files/product1.pdf',             'status': 'downloaded'}),           <br/>   (False,            Failure(...))<br/>]</span></pre><ol class=""><li id="9daa" class="mn mo jj la b lb lc le lf lh oh ll oi lp oj lt mu mv mw mx bi translated">第一个元组显示在这种情况下文件被成功下载<code class="fe nr ns nt nu b">success = true</code></li><li id="2322" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">第一个元组的第二项给了我们<code class="fe nr ns nt nu b">file_info_or_error </code>字典，告诉我们这个下载的文件。</li><li id="c79b" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">第二个元组显示了<code class="fe nr ns nt nu b">success = false</code>，并开始在<code class="fe nr ns nt nu b">file_info_or_error</code>变量中提供解释。</li></ol><p id="ac8c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当您创建自己的下载管道，并希望检查文件的状态或记录有多少文件没有下载以及具体原因时，这将非常有用。</p><p id="0031" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了在您想要下载的文件上使用这些信息，有必要创建您自己的管道。为此，我们创建了一个覆盖 pipeline 类 scrapy 提供的文件的函数，这些函数写在 scrapy 项目的 pipeline.py 中。有关如何解决这一问题的更多信息，请参见此处的<a class="ae jg" href="https://www.youtube.com/watch?v=CpvkCzd2O6A" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="5bfe" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后你可以覆盖在<code class="fe nr ns nt nu b">filepipeline</code>类中找到的名为<code class="fe nr ns nt nu b">items_complete()</code>的方法，用 scrapy 下载文件。该方法将<code class="fe nr ns nt nu b">results</code>变量作为参数。然后可以访问这些文件，每个文件中的信息可以用于您自己的管道需求。</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/8b73ac743984b8631e43a887c05015a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HAShqUb2TTZjEveT"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@kellysikkema" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@kellysikkema</a></p></figure><h1 id="2149" class="nd lv jj bd lw ne nf ng lz nh ni nj mc kp nk kq mf ks nl kt mi kv nm kw ml nn bi translated">杂乱和类型提示</h1><p id="5d39" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">Scrapy 的新版本要求安装 Python 3.5.2 及以上版本，框架才能运行。你可能会问为什么会这样？Python 3.5 版本引入了一种叫做类型提示的东西，它的意思就是你所认为的意思！类型提示是一种将类型对象信息添加到语言中用于注释目的的方法。</p><p id="c55a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了理解为什么这很重要，请看这个函数。</p><pre class="nv nw nx ny gt nz nu oa ob aw oc bi"><span id="d267" class="lu lv jj nu b gy od oe l of og">def send_request(request_data,'#]<br/>                 headers,<br/>                 user_id,<br/>                 as_json):<br/>   DOING SOMETHING<br/>   RETURNING SOMETHING</span></pre><p id="8313" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与…相比</p><pre class="nv nw nx ny gt nz nu oa ob aw oc bi"><span id="8fb8" class="lu lv jj nu b gy od oe l of og">def send_request(request_data : Any,<br/>                 headers: Optional[Dict[str, str]],<br/>                 user_id: Optional[UserId] = None,<br/>                 as_json: bool = True):</span></pre><p id="6170" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看看知道输入是什么以及函数中返回内容的可能性是多么容易。为什么发音变得清晰，我们确切地知道输入是什么，输出会是什么。Python 作为一种语言的起源是一种叫做动态类型语言的东西。也就是说，Python 直到运行时才知道对象类型，因此不适合在代码库中注释类型。</p><p id="d132" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">类型提示是一种使代码库更容易阅读和维护的方式，有人建议 Scrapy 应该为框架的新贡献者提供这种方式。Scrapy 中的类型提示是为了使代码可维护，因此 Python 3.5.2 版的要求是允许 Scrapy 代码库被类型提示。</p><p id="df95" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请点击此处查看我的博客和其他帖子中关于项目的更多细节。更多技术/编码相关内容，请点击这里<a class="ae jg" href="https://aaronsmith.substack.com/p/coming-soon?r=6yuie&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=copy" rel="noopener ugc nofollow" target="_blank">订阅我的时事通讯</a></p><p id="eda7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将非常感谢任何评论，或者如果你想与 python 合作或需要帮助，请联系我。如果你想和我联系，请在这里或者在<a class="ae jg" href="http://www.twitter.com/@aaronsmithdev" rel="noopener ugc nofollow" target="_blank">推特</a>上联系我。</p><h1 id="6dd0" class="nd lv jj bd lw ne nf ng lz nh ni nj mc kp nk kq mf ks nl kt mi kv nm kw ml nn bi translated">相关文章</h1><div class="is it gp gr iu ok"><a rel="noopener follow" target="_blank" href="/approach-to-learning-python-f1c9a02024f8"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd jk gy z fp op fr fs oq fu fw ji bi translated">学习 Python 的方法</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">今天如何最大限度地学习 python</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ja ok"/></div></div></a></div><div class="is it gp gr iu ok"><a rel="noopener follow" target="_blank" href="/how-to-run-scrapy-from-a-script-ff07fd6b792b"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd jk gy z fp op fr fs oq fu fw ji bi translated">如何从脚本运行 Scrapy</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">忘记 scrapy 的框架，全部用使用 scrapy 的 python 脚本编写</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="oz l ov ow ox ot oy ja ok"/></div></div></a></div><div class="is it gp gr iu ok"><a rel="noopener follow" target="_blank" href="/efficient-web-scraping-with-scrapy-571694d52a6"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd jk gy z fp op fr fs oq fu fw ji bi translated">使用 Scrapy 进行有效的网页抓取</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">Scrapy 的新功能使您的刮削效率</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="pa l ov ow ox ot oy ja ok"/></div></div></a></div></div></div>    
</body>
</html>