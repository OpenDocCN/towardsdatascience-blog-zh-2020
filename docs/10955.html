<html>
<head>
<title>Torch: Spoken digits recognition from features to model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Torch:从特征到模型的语音数字识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/torch-spoken-digits-recognition-from-features-to-model-357209cd49d1?source=collection_archive---------20-----------------------#2020-07-30">https://towardsdatascience.com/torch-spoken-digits-recognition-from-features-to-model-357209cd49d1?source=collection_archive---------20-----------------------#2020-07-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/bbceeae61b106b62f5bb1898217817d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i5j3leMKYQZft8Sb"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">詹姆斯·奥尔在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="c176" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">探索从语音数据中提取的特征，以及基于这些特征构建模型的不同方法。</h2></div><p id="56e0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">语音数字数据集是 Tensorflow 语音命令数据集的子集，包括除数字 0-9 之外的其他录音。这里，我们只关注识别说出的数字。</p><p id="fbe1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据集可以按如下方式下载。</p><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">辐条数字特征提取. ipynb</p></figure><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">辐条数字特征提取. ipynb</p></figure><h2 id="5f3f" class="ma mb jj bd mc md me dn mf mg mh dp mi lh mj mk ml ll mm mn mo lp mp mq mr ms bi translated">评估指标</h2><p id="5b1f" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">数字录音的子集相当平衡，每类大约有 2300 个样本。因此，准确性是评估模型性能的一个很好的方法。准确性是正确预测数与预测总数的比较。对于不平衡的数据集，这不是一个很好的性能测量方法，因为多数类的个体精度可能会盖过少数类。</p><h2 id="5d4a" class="ma mb jj bd mc md me dn mf mg mh dp mi lh mj mk ml ll mm mn mo lp mp mq mr ms bi translated">循环学习率</h2><p id="f4d1" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在训练模型时，学习率逐渐降低以微调训练。为了提高学习率效率，可以应用循环学习率过程。这里，学习率在各时期的最小值和最大值之间波动，而不是单调下降。</p><p id="4b59" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">初始训练率对模型的性能至关重要，低训练率可防止在训练开始时停滞不前，随后的波动会抑制局部最小值和平台值。</p><p id="7939" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">可以使用优化器实例来监控每个时期中使用的学习率。</p><p id="274f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该项目有三种方法对记录进行分类:</p><ol class=""><li id="2cf5" class="my mz jj la b lb lc le lf lh na ll nb lp nc lt nd ne nf ng bi translated">使用五个提取特征的逻辑回归— 76.19%的准确率。</li><li id="7a09" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated">CNN 使用 Mel 光谱图—准确率 95.81%。</li></ol><p id="528d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过改变时期的数量和训练速率来重复训练模型。隐藏层的数量和每个层中的节点也是不同的。这里描述了每种方法的最佳架构和超参数。由于训练验证分割中的随机性，在重新训练时精度可能略有不同。</p><p id="fb5e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该项目的源代码是<a class="ae jg" href="https://github.com/AyishaR/Spokendigit" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="908d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有五个。ipynb 文件:</p><ol class=""><li id="ae2d" class="my mz jj la b lb lc le lf lh na ll nb lp nc lt nd ne nf ng bi translated">特征提取-提取三种方法使用的必要 CSV 文件和特征。</li><li id="8704" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated">要素可视化-为每个类中的两个示例绘制要素。</li><li id="963a" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated">五个特征——使用五个提取的特征实现逻辑回归。</li><li id="ae86" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated">使用 Mel 谱图实现 CNN。</li></ol></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><h1 id="ffc2" class="nt mb jj bd mc nu nv nw mf nx ny nz mi kp oa kq ml ks ob kt mo kv oc kw mr od bi translated">1.使用五个提取特征的逻辑回归</h1><h2 id="a606" class="ma mb jj bd mc md me dn mf mg mh dp mi lh mj mk ml ll mm mn mo lp mp mq mr ms bi translated">特征</h2><p id="31a0" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">提取的特征包括:</p><ul class=""><li id="3841" class="my mz jj la b lb lc le lf lh na ll nb lp nc lt oe ne nf ng bi translated"><strong class="la jk">梅尔频率倒谱系数(MFCC)</strong>—构成声音频谱表示的系数，基于根据人类听觉系统响应(梅尔标度)间隔的频带。</li><li id="cd1f" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt oe ne nf ng bi translated"><strong class="la jk">色度</strong> —与 12 个不同的音高等级相关。</li><li id="772e" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt oe ne nf ng bi translated"><strong class="la jk">梅尔谱图的平均值</strong> —基于梅尔标度的谱图。</li><li id="2b00" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt oe ne nf ng bi translated"><strong class="la jk">光谱对比度</strong> —表示光谱的质心。</li><li id="673a" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt oe ne nf ng bi translated"><strong class="la jk"> Tonnetz </strong> —代表色调空间。</li></ul><p id="1d17" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些特征是大小为(20)、(12)、(128)、(7)和(6)的 NumPy 数组。这些被连接以形成大小为(173)的特征数组。标签被附加到数组的头部，并写入每个记录的 CSV 文件。</p><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">spoke ndigit-feature-extraction . ipynb</p></figure><h2 id="e2d3" class="ma mb jj bd mc md me dn mf mg mh dp mi lh mj mk ml ll mm mn mo lp mp mq mr ms bi translated">模型</h2><p id="36af" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">线性回归模型总共有 1 个输入层、2 个隐藏层和 1 个 ReLu 激活的输出层。</p><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Spokendigit —五个功能。ipynb</p></figure><h2 id="c402" class="ma mb jj bd mc md me dn mf mg mh dp mi lh mj mk ml ll mm mn mo lp mp mq mr ms bi translated">火车</h2><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Spokendigit —五个功能。ipynb</p></figure><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Spokendigit —五个功能。ipynb</p></figure><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Spokendigit —五个功能。ipynb</p></figure><p id="8806" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该模型在 CPU 上训练约 3 分钟，准确率为 76.19%。</p><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">验证损失图</p></figure><p id="3c5c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最终验证损失从最小值开始增加很大程度。</p><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">验证准确度图</p></figure><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">每个时期的最后学习率图</p></figure><h1 id="2257" class="nt mb jj bd mc nu of nw mf nx og nz mi kp oh kq ml ks oi kt mo kv oj kw mr od bi translated">2.CNN 使用梅尔光谱图图像。</h1><h2 id="a801" class="ma mb jj bd mc md me dn mf mg mh dp mi lh mj mk ml ll mm mn mo lp mp mq mr ms bi translated">特征</h2><p id="7920" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">该模型使用记录的 Mel 谱图图像。梅尔频谱图是频率被转换成梅尔标度的频谱图。从记录中提取特征并存储在驱动器中。这花了 4.5 个多小时。</p><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">spoke ndigit-feature-extraction . ipynb</p></figure><h2 id="4021" class="ma mb jj bd mc md me dn mf mg mh dp mi lh mj mk ml ll mm mn mo lp mp mq mr ms bi translated">模型</h2><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">CNN.ipynb</p></figure><h2 id="0f69" class="ma mb jj bd mc md me dn mf mg mh dp mi lh mj mk ml ll mm mn mo lp mp mq mr ms bi translated">火车</h2><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">CNN.ipynb</p></figure><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">CNN.ipynb</p></figure><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">CNN.ipynb</p></figure><p id="99fa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该模型在 Colab GPU 上训练约 5 小时，准确率为 95.81%。</p><p id="ce07" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">高精度再次归因于 Mel 标度。</p><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">验证损失图</p></figure><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">验证准确度图</p></figure><figure class="lu lv lw lx gt iv"><div class="bz fp l di"><div class="ly lz l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">每个时期的最后学习率图</p></figure><h1 id="446a" class="nt mb jj bd mc nu of nw mf nx og nz mi kp oh kq ml ks oi kt mo kv oj kw mr od bi translated">参考</h1><ul class=""><li id="2c2d" class="my mz jj la b lb mt le mu lh ok ll ol lp om lt oe ne nf ng bi translated"><a class="ae jg" href="https://musicinformationretrieval.com/" rel="noopener ugc nofollow" target="_blank">https://musicinformationretrieval.com/</a></li><li id="2bbf" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt oe ne nf ng bi translated"><a class="ae jg" href="https://github.com/jurgenarias/Portfolio/tree/master/Voice%20Classification/Code" rel="noopener ugc nofollow" target="_blank">https://github . com/jurgenarias/Portfolio/tree/master/Voice % 20 分类/代码</a></li><li id="a7dc" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt oe ne nf ng bi translated"><a class="ae jg" href="https://arxiv.org/abs/1506.01186" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.01186</a></li><li id="a55f" class="my mz jj la b lb nh le ni lh nj ll nk lp nl lt oe ne nf ng bi translated"><a class="ae jg" href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Mel-frequency_cepstrum</a></li></ul></div></div>    
</body>
</html>