# Python ç»Ÿè®¡åˆ†æå’Œå»ºæ¨¡ç®€ä»‹

> åŸæ–‡ï¼š<https://towardsdatascience.com/an-introduction-to-statistical-analysis-and-modelling-with-python-ef816b67f8ff?source=collection_archive---------16----------------------->

> ç»Ÿè®¡å»ºæ¨¡ç»™ä½ è¯„ä¼°ã€ç†è§£å’Œé¢„æµ‹æ•°æ®çš„èƒ½åŠ›ï¼Œå®ƒæ˜¯æ¨ç†ç»Ÿè®¡å­¦çš„æœ€åº•å±‚ï¼Œå¯ä»¥è¢«è®¤ä¸ºæ˜¯é‚£äº›â€œå¿…é¡»çŸ¥é“â€çš„ä¸»é¢˜ã€‚

![](img/d9971a30141537103b33825fd9a8a4b8.png)

å¢å¡æ–¯åœ¨ Unsplash.com çš„ç…§ç‰‡

# **å†…å®¹åˆ—è¡¨:**

*   ä»‹ç»
*   å›¾å½¢è¡¨ç¤ºå’Œç»˜å›¾
*   é€‰æ‹©æ­£ç¡®çš„åŠŸèƒ½
*   å‚æ•°ä¼°è®¡
*   é¢„æµ‹å€¼çš„ä¼˜åº¦è¯„ä¼°
*   ç»Ÿè®¡æµ‹è¯•
*   å¸¸æ€æ£€éªŒ

# ä»‹ç»

åœ¨ç»Ÿè®¡åˆ†æä¸­ï¼Œå¯ä»¥è¿›è¡Œçš„ä¸€ç§å¯èƒ½çš„åˆ†ææ˜¯éªŒè¯æ•°æ®ç¬¦åˆç‰¹å®šçš„åˆ†å¸ƒï¼Œæ¢å¥è¯è¯´ï¼Œæ•°æ®â€œåŒ¹é…â€ç‰¹å®šçš„ç†è®ºæ¨¡å‹ã€‚

è¿™ç§åˆ†æç§°ä¸ºåˆ†å¸ƒæ‹Ÿåˆï¼ŒåŒ…æ‹¬å¯»æ‰¾ä¸€ä¸ªä»£è¡¨è§‚å¯Ÿç°è±¡çš„æ’å€¼æ•°å­¦å‡½æ•°ã€‚

ä¾‹å¦‚ï¼Œå½“æ‚¨æœ‰ä¸€ç³»åˆ—è§‚å¯Ÿå€¼ **ğ‘¥1,ğ‘¥2,ğ‘¥ğ‘›â€¦** æ—¶ï¼Œæ‚¨å¸Œæœ›éªŒè¯è¿™äº›è§‚å¯Ÿå€¼æ˜¯å¦æ¥è‡ªå¯†åº¦å‡½æ•°**ğ‘“(ğ‘¥,Î¸**æ‰€æè¿°çš„ç‰¹å®šæ€»ä½“ï¼Œå…¶ä¸­ **Î¸** æ˜¯åŸºäºå¯ç”¨æ•°æ®è¿›è¡Œä¼°è®¡çš„å‚æ•°å‘é‡ã€‚

![](img/a5301f3e908c68dacb812f8f2c61e7d1.png)

æ©™è‰²:æ‹Ÿåˆ(æ’å€¼)ä¸€ç»„è§‚å¯Ÿå€¼çš„çº¿æ€§å‡½æ•°(è“è‰²)

ç»Ÿè®¡åˆ†æçš„ä¸¤ä¸ªä¸»è¦ç›®çš„æ˜¯**æè¿°**å’Œ**è°ƒæŸ¥**:

*   æè¿°:ä¼°è®¡ç§»åŠ¨å¹³å‡å€¼ï¼Œä¼°ç®—ç¼ºå¤±æ•°æ®â€¦
*   è°ƒæŸ¥:å¯»æ‰¾ä¸€ä¸ªç†è®ºæ¨¡å‹ï¼Œé€‚åˆæˆ‘ä»¬å·²ç»å¼€å§‹çš„è§‚å¯Ÿã€‚

![](img/e4c1ca8a9a16d9b57a30389d5797e2b4.png)

é€‚ç”¨äºç›¸åŒæ•°æ®çš„ä¸åŒæ’å€¼å‡½æ•°

è¿™ä¸ªè¿‡ç¨‹å¯ä»¥åˆ†ä¸ºå››ä¸ªé˜¶æ®µ:

*   é€‰æ‹©æ›´ç¬¦åˆæ•°æ®çš„æ¨¡å‹
*   æ¨¡å‹çš„å‚æ•°ä¼°è®¡
*   è®¡ç®—æ‰€é€‰æ¨¡å‹å’Œç†è®ºæ¨¡å‹ä¹‹é—´çš„â€œç›¸ä¼¼åº¦â€
*   åº”ç”¨ä¸€ç»„ç»Ÿè®¡æµ‹è¯•æ¥è¯„ä¼°æ‹Ÿåˆä¼˜åº¦

# å›¾å½¢è¡¨ç¤ºå’Œç»˜å›¾

æ¢ç´¢æ•°æ®çš„ç¬¬ä¸€ç§æ–¹æ³•æ˜¯å›¾å½¢åˆ†æã€‚ç”¨ç›´æ–¹å›¾å¯¹æ•°æ®è¿›è¡Œå›¾å½¢åŒ–åˆ†æï¼Œå¯ä»¥å¾ˆå¥½åœ°å¸®åŠ©è¯„ä¼°è¦é€‰æ‹©çš„æ­£ç¡®æ¨¡å‹ã€‚

è®©æˆ‘ä»¬ç»˜åˆ¶ä¸€ä¸ªå¤§å°ä¸º 500ã€å¹³å‡å€¼ä¸º 50ã€æ ‡å‡†å·®ä¸º 2 çš„éšæœºæ ·æœ¬ï¼Œå¹¶ç»˜åˆ¶ä¸€ä¸ªç›´æ–¹å›¾:

```
import numpy as npimport matplotlib.pyplot as pltx_norm = np.random.normal(50, 2, 500)plt.hist(x_norm)
```

![](img/28e478e165bce24e23167c128ab0026a.png)

æ˜¾ç¤ºæ•°æ®çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä¼°è®¡æ¦‚ç‡å¯†åº¦å‡½æ•°:

```
from scipy.stats.kde import gaussian_kdefrom numpy import linspace# estimate the probability density function (PDF)kde = gaussian_kde(x_norm)# return evenly spaced numbers over a specified intervaldist_space = linspace(min(x_norm), max(x_norm), 100)# plot the resultsplt.plot(dist_space, kde(dist_space))
```

![](img/9175e71ba1b3853e9fe8b662637871b7.png)

ä»…ä»…é€šè¿‡è§‚å¯Ÿè¿™äº›è¡¨ç°ï¼Œå°±æœ‰å¯èƒ½å¯¹æ›´é€‚åˆæˆ‘ä»¬æ•°æ®çš„ç†è®ºæ¨¡å‹å½¢æˆä¸€äº›æƒ³æ³•ã€‚ä¹Ÿå¯ä»¥è®¡ç®—ç»éªŒåˆ†å¸ƒå‡½æ•°:

```
plt.plot(np.sort(x_norm), np.linspace(0, 1, len(x_norm)))plt.title(â€˜Empirical CDF for x_normâ€™)
```

![](img/fdc6d4ef5a50357391981702382185c9.png)

å¦ä¸€ä¸ªå¯ä»¥æä¾›å¸®åŠ©çš„å›¾å½¢å·¥å…·æ˜¯ QQ å›¾ï¼Œå®ƒåœ¨ y è½´ä¸Šæ˜¾ç¤ºè§‚å¯Ÿæ•°æ®çš„åˆ†ä½æ•°ä¸æ•°å­¦æ¨¡å‹çš„ç†è®ºåˆ†ä½æ•°ã€‚

ä½¿ç”¨åˆ†ä½æ•°è¿™ä¸ªæœ¯è¯­ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®šæ¯”ç‰¹å®šå€¼ä½**çš„é‚£éƒ¨åˆ†è§‚å¯Ÿå€¼ï¼Œå³åˆ†ä½æ•°ã€‚ä¾‹å¦‚ï¼Œ0.75 åˆ†ä½æ•°(æˆ– 75%)æ˜¯ 75%çš„æ•°æ®(æ ·æœ¬)ä½äºè¯¥å€¼**çš„**å’Œé«˜äº**çš„**çš„ 25 %çš„ç‚¹ã€‚**

```
from scipy import statsstats.probplot(x_norm, plot=plt)
```

![](img/9096b8203e55edcd45ab53824fa07864.png)

å½“å›¾ä¸Šçš„ç‚¹å€¾å‘äºä½äºå¯¹è§’çº¿ä¸Šæ—¶ï¼Œè¿™æ„å‘³ç€æ•°æ®(æ ·æœ¬)ä»¥â€œè‰¯å¥½â€çš„æ–¹å¼æ‹Ÿåˆé«˜æ–¯æ¨¡å‹ã€‚

å¦‚æœæˆ‘ä»¬æœ‰å¦ä¸€ç§è§‚å¯Ÿå€¼ï¼Œä¾‹å¦‚ï¼Œå¨å¸ƒå°”å¯†åº¦å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥åšå¦‚ä¸‹:

```
x_wei = np.random.weibull(2, 500) # A Weibull sample of shape 2and size 500plt.hist(x_wei)
```

![](img/33b9eb194c1f2c62a9641bb8abfd7e93.png)

ä»¥åŠç›¸å¯¹çš„ QQ å‰§æƒ…:

```
stats.probplot(x_wei, plot=plt)
```

![](img/408e99748176d25240459d6023ace408.png) [## ç±³å°”æ–¯å½¢å¼

### ç¼–è¾‘æè¿°

æ— æƒ…-åˆ›é€ è€…-2481.ck.page](https://relentless-creator-2481.ck.page/68d9def351) 

# é€‰æ‹©æ­£ç¡®çš„åŠŸèƒ½

æˆ‘ä»¬çœ‹åˆ°ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„ç±»å‹(åŠŸèƒ½)å¯ä»¥ä»æ¨¡å‹çš„ç»“æ„å’Œæ€§è´¨ä¸­æ¨å¯¼å‡ºæ¥ã€‚ç„¶åé€‰æ‹©ä¸€ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬éªŒè¯å®ƒæ˜¯å¦ç¬¦åˆè§‚å¯Ÿåˆ°çš„æ•°æ®ã€‚

åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œå›¾å½¢è¡¨ç¤ºå¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©:ä»ç›´æ–¹å›¾çš„å½¢çŠ¶æ¥çœ‹ï¼Œå¯ä»¥é€¼è¿‘æ›´å¥½åœ°è¡¨ç¤ºæ•°æ®çš„å‡½æ•°ï¼Œä½†æ˜¯ï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¼šæœ‰åå·®ã€‚

çš®å°”é€Šå‡†åˆ™æ˜¯ä¸€ç§æ²¡æœ‰åè§çš„æ–¹æ³•ï¼Œç”¨æ¥é€‰æ‹©æœ€é€‚åˆæ•°æ®çš„å‡½æ•°ã€‚

çš®å°”é€Šå‡†åˆ™æºäºå¾®åˆ†æ–¹ç¨‹çš„è§£ï¼Œè¯¥å¾®åˆ†æ–¹ç¨‹â€œç”Ÿæˆâ€ä¸€æ—ä»£è¡¨ä¸åŒç»éªŒåˆ†å¸ƒçš„ä¸åŒç±»å‹çš„å‡½æ•°ã€‚è¯¥åŠŸèƒ½å®Œå…¨å–å†³äºå››ä¸ªä¸åŒçš„ç‰¹å¾:

*   æ„æ€æ˜¯
*   å·®å¼‚
*   ä¸å¯¹ç§°
*   å³­åº¦

åœ¨æ ‡å‡†åŒ–åˆ†å¸ƒæ—¶ï¼Œæ›²çº¿(å‡½æ•°)çš„ç±»å‹ä»…å–å†³äºä¸å¯¹ç§°åº¦å’Œå³°åº¦çš„åº¦é‡ã€‚

# å‚æ•°ä¼°è®¡

ä¸€æ—¦é€‰æ‹©äº†æ›´å¥½åœ°ä»£è¡¨æ•°æ®çš„å‡½æ•°ï¼Œå°±æœ‰å¿…è¦æ ¹æ®å¯ç”¨æ•°æ®æ¥ä¼°è®¡è¡¨å¾è¯¥æ¨¡å‹çš„å‚æ•°ã€‚ä¸€äº›æœ€å¸¸ç”¨çš„æ–¹æ³•åŒ…æ‹¬çŸ©ä¼°è®¡æ³•ã€æœ€å°äºŒä¹˜æ³•å’Œæœ€å¤§ä¼¼ç„¶ä¼°è®¡æ³•ã€‚åœ¨æœ¬ç®€ä»‹ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ä»¥ä¸‹æ–¹æ³•:

*   å¤©çœŸçš„æ–¹æ³•
*   çŸ©é‡æ³•
*   æœ€å¤§ä¼¼ç„¶

æœ´ç´ æ–¹æ³•æ˜¯æœ€åŸºæœ¬çš„æ–¹æ³•ï¼Œä¹Ÿæ˜¯éå¸¸ç›´è§‚çš„:å®ƒåŒ…æ‹¬é€šè¿‡ä¼°è®¡æ¨¡å‹çš„å‚æ•°ï¼Œä¾‹å¦‚ï¼Œä»æ­£æ€åˆ†å¸ƒä¸­æŠ½å–æ ·æœ¬çš„å¹³å‡å€¼æ¥ä¼°è®¡æ¨¡å‹çš„å‚æ•°

```
>>> print(np.mean(x_norm))
50.03732572479421
```

# çŸ©é‡æ³•

çŸ©æ–¹æ³•åŒ…æ‹¬å°†æ€»ä½“çŸ©è¡¨ç¤ºä¸ºæ„Ÿå…´è¶£å‚æ•°çš„å‡½æ•°ã€‚ç„¶åï¼Œå®ƒè¢«è®¾ç½®ä¸ºç­‰äºç”±æ‰€é€‰å‡½æ•°å’Œè¦ä¼°è®¡çš„å‚æ•°æ•°é‡ç¡®å®šçš„ç†è®ºçŸ©ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ç”¨ python è§£å†³è¿™ä¸ªé—®é¢˜:

```
x_gamma = np.random.gamma(3.5, 0.5, 200) # simulate a gamma distribution of shape 3.5 and scale (Î») 0.5mean_x_gamma = np.mean(x_gamma) # mean of the datavar_x_gamma = np.var(x_gamma) # variance of the datal_est = mean_x_gamma / var_x_gamma # lambda estimation (rate)a_est = (mean_x_gamma ** 2) / l_est # alpha estimationprint(â€˜Lambda estimation: {}â€™.format(l_est))print(â€˜Alpha estimation: {}â€™.format(a_est))Lambda estimation: 2.25095711229392 
Alpha estimation: 1.2160321117648123
```

# æœ€å¤§ä¼¼ç„¶æ³•

æœ€å¤§ä¼¼ç„¶æ³•æ˜¯æ¨æ–­ç»Ÿè®¡å­¦ä¸­ä½¿ç”¨çš„ä¸€ç§æ–¹æ³•ã€‚å®ƒä»ğ‘“(ğ‘¥,Î¸).å¯†åº¦å‡½æ•°å¼€å§‹å®ƒåŒ…æ‹¬é€šè¿‡æœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°æ¥ä¼°è®¡Î¸ï¼Œæˆ–è€…åœ¨å®è·µä¸­ï¼Œä½¿ç”¨ä¼¼ç„¶å‡½æ•°çš„è‡ªç„¶å¯¹æ•°(ç§°ä¸ºå¯¹æ•°ä¼¼ç„¶)é€šå¸¸æ›´æ–¹ä¾¿ã€‚

è®©æˆ‘ä»¬æ¥çœ‹çœ‹å®ƒçš„å®é™…åº”ç”¨:

```
# generate datax = np.linspace(0,20, len(x_gamma))y = 3*x + x_gammaimport statsmodels.api as smols = sm.OLS(y, x_gamma).fit()print(ols.summary())
```

![](img/2f3eac37f0fe7ff7f4009cc75682aade.png)

ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„åŒ…æ˜¯`fitter`åŒ…ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒä¼°è®¡ä»ä¸­æŠ½å–æ ·æœ¬çš„åˆ†å¸ƒã€‚è¿™éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºä¸éœ€è¦çŸ¥é“ä¼¼ç„¶å‡½æ•°ï¼Œä½†åªéœ€æŒ‡å®šæ ·æœ¬å’Œè¦æµ‹è¯•çš„åˆ†å¸ƒåˆ—è¡¨å°±è¶³å¤Ÿäº†:

```
#!pip install fitterfrom fitter import Fitterf = Fitter(x_gamma, distributions=[â€˜gammaâ€™, â€˜dweibullâ€™, â€˜uniformâ€™])f.fit()f.summary()
```

![](img/3d2b3b18e9b6c83f6af2b4e43b4b7af9.png)![](img/efd24c097cfb010792a5ba75b7856d1a.png)

# é¢„æµ‹å€¼çš„ä¼˜åº¦è¯„ä¼°

éœ€è¦è¯„ä¼°é¢„æµ‹å€¼(æˆæœ¬å‡½æ•°ã€æŸå¤±å‡½æ•°)çš„ä¼˜è‰¯æ€§ï¼Œä»¥è¯„ä¼°è§‚æµ‹æ•°æ®å’Œæ¨¡å‹è®¡ç®—(é¢„æµ‹)æ•°æ®ä¹‹é—´çš„è¿‘ä¼¼ç¨‹åº¦ã€‚å› æ­¤ï¼ŒæŸå¤±å‡½æ•°è®¡ç®—ç»éªŒæ•°æ®å’Œè§‚æµ‹æ•°æ®ä¹‹é—´çš„å·®å¼‚ï¼Œå®ƒåº”è¯¥å¯¹ç›¸åŒå¤§å°ä½†ç¬¦å·ä¸åŒçš„è¯¯å·®ç»™äºˆç›¸åŒçš„æƒé‡ï¼Œå¹¶ä¸”åº”è¯¥éšç€è¯¯å·®çš„å¢åŠ è€Œå¢åŠ ã€‚æŸå¤±å‡½æ•°å¯ä»¥æ˜¯ç›¸å¯¹çš„ï¼Œä¹Ÿå¯ä»¥æ˜¯ç»å¯¹çš„ã€‚åœ¨æœ€å¸¸è§çš„æŸå¤±å‡½æ•°ä¹‹é—´æˆ‘ä»¬å¯ä»¥æœ‰:

![](img/46423794b4729cdbe80695816b3b0cd7.png)

å…¶ä¸­ï¼Œğ‘¦æ˜¯è§‚æµ‹å€¼ï¼Œğ‘¦Ì‚æ˜¯ç†è®º(é¢„æµ‹)å€¼ã€‚é€šå¸¸ï¼Œè¿™äº›å€¼è¦ä¹˜ä»¥ 100ï¼Œä»¥ä¾¿ç”¨ç™¾åˆ†æ¯”è¡¨ç¤ºã€‚

è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªæ¥è‡ªæ³Šæ¾åˆ†å¸ƒçš„æ ·æœ¬çš„ä¾‹å­:

```
import pandas as pddef dpois(x,mu):â€œâ€â€Calculates the density/point estimate of the Poisson distributionâ€œâ€â€from scipy.stats import poissonresult=poisson.pmf(k=x,mu=mu)return resultx_poi = np.random.poisson(2.5, 200)lambda_est = np.mean(x_poi)table_os = pd.Series(x_poi).value_counts().sort_index().reset_index().reset_index(drop=True)table_os = table_os.valuesfreq_os = []freq_ex = []for i in range(len(table_os)):freq_os.append(table_os[i][1])freq_ex.append(dpois(x = range(0, np.max(x_poi) + 1), mu=lambda_est) * 200)from sklearn.metrics import mean_absolute_erroracc = mean_absolute_error(freq_os, freq_ex[0])print(â€˜Mean absolute error is: {:.2f}â€™.format(acc))acc_prc = acc / np.mean(freq_os) * 100print(â€˜Mean absolute percentage error is: {:.2f}â€™.format(acc_prc))Mean absolute error is: 3.30 
Mean absolute percentage error is: 14.84
```

è¯„ä¼°é¢„æµ‹å€¼ä¼˜åŠ£çš„å¦ä¸€ä¸ªç¤ºä¾‹æ˜¯å°†å¯†åº¦å‡½æ•°ä¸æ•°æ®é‡å :

```
x_norm = np.random.normal(10, 2, 200)(n, bins, patches) = plt.hist(x_norm, bins=15)table_os = pd.Series(x_norm).value_counts().sort_index().reset_index().reset_index(drop=True)table_os = table_os.valuesdef dnorm(x, mean=0, sd =1):â€œâ€â€Calculates the density of the Normal distributionâ€œâ€â€from scipy.stats import normresult=norm.pdf(x,loc=mean,scale=sd)return resultx_fit = np.linspace(start=np.min(x_norm), stop=np.max(x_norm))y_fit = dnorm(x_fit, mean=np.mean(x_norm), sd = np.std(x_norm))fig, ax = plt.subplots(1, 1)ax.hist(x_norm, bins=15)ax2 = ax.twinx()ax2.plot(x_fit, y_fit, c=â€™orangeâ€™)plt.draw()
```

![](img/db1f2648eacb05411a92d58a06ae5e6c.png)

# ç»Ÿè®¡æµ‹è¯•

å¯ä»¥è¿›è¡Œä¸åŒçš„ç»Ÿè®¡æµ‹è¯•æ¥è¯„ä¼°æ‹Ÿåˆä¼˜åº¦ï¼Œå³ç†è®ºæ¨¡å‹ä¸æ•°æ®çš„æ‹Ÿåˆç¨‹åº¦ã€‚è¿™äº›æµ‹è¯•ä»â€œå…¨å±€â€çš„è§’åº¦è€ƒè™‘æ ·æœ¬ï¼Œè€ƒè™‘äº†è¢«ç ”ç©¶æ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾(å‡å€¼ã€æ–¹å·®ã€åˆ†å¸ƒå½¢çŠ¶â€¦â€¦)ï¼Œå¹¶ä¸”æ˜¯åˆ†å¸ƒä¸å¯çŸ¥çš„ï¼Œè¿™æ„å‘³ç€å®ƒä»¬ç‹¬ç«‹äºè¢«ç ”ç©¶çš„åˆ†å¸ƒã€‚

åˆ†æä¸­è¯„ä¼°æ‹Ÿåˆä¼˜åº¦çš„ç¬¬ä¸€ä¸ªæµ‹è¯•æ˜¯Ï‡2(å¡æ–¹æ£€éªŒ)ã€‚å®ƒåŸºäºç»éªŒé¢‘ç‡(é¢„æœŸé¢‘ç‡)å’Œè§‚å¯Ÿé¢‘ç‡ä¹‹é—´çš„æ¯”è¾ƒï¼Œå»ºç«‹åœ¨æœŸæœ›çš„å¯†åº¦å‡½æ•°ä¸Šã€‚Ï‡2 å¯ç”¨äºç¦»æ•£å˜é‡å’Œè¿ç»­å˜é‡ï¼Œå…¶æ•°å­¦å…¬å¼å¦‚ä¸‹:

![](img/c190d9d8c75d54ac90d03da4d87f7095.png)

å…¶ä¸­ï¼Œğ‘‚ğ‘–æ˜¯è§‚æµ‹é¢‘ç‡ï¼Œğ¸ğ‘–æ˜¯ç†è®ºé¢‘ç‡ï¼Œğ‘˜æ˜¯ç±»åˆ«æˆ–åŒºé—´æ•°ã€‚è¯¥ç»Ÿè®¡é‡æ¸è¿‘åˆ†å¸ƒåœ¨å…·æœ‰ğ‘˜âˆ’ğ‘âˆ’1 è‡ªç”±åº¦çš„åä¸ºÏ‡2 çš„éšæœºå˜é‡å‘¨å›´ï¼Œå…¶ä¸­ğ‘æ˜¯æ¨¡å‹ä¼°è®¡çš„å‚æ•°æ•°é‡ã€‚

å½“ç»Ÿè®¡å€¼ä½äºæŸä¸ªé˜ˆå€¼æ—¶ï¼Œå³å½“ p å€¼é«˜äºé¢„å…ˆç¡®å®šçš„æ˜¾è‘—æ€§æ°´å¹³æ—¶ï¼Œé›¶å‡è®¾è¢«æ‹’ç»ã€‚

è¯¥æµ‹è¯•åœ¨ä»¥ä¸‹æ¡ä»¶ä¸‹æœ‰æ•ˆ:

*   æ ·æœ¬åº”è¯¥è¶³å¤Ÿå¤§*(å› ä¸ºåˆ†å¸ƒæ˜¯æ¸è¿‘Ï‡2)*
*   *æ¯ä¸ªç±»åˆ«çš„é¢„æœŸé¢‘ç‡æ•°ä¸èƒ½å°‘äº 5ã€‚*
*   *éœ€è¦åº”ç”¨è€¶èŒ¨è¿ç»­æ€§æ ¡æ­£(è¿ç»­æ€§æ ¡æ­£)ï¼ŒåŒ…æ‹¬ä»æ¯ä¸ªè§‚å¯Ÿå€¼å’Œå…¶é¢„æœŸå€¼|ğ‘‚ğ‘–âˆ’ğ¸ğ‘–|.ä¹‹é—´çš„å·®ä¸­å‡å» 0.5*

*è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å®ç°å®ƒ:*

```
*import scipyobs = np.bincount(x_poi)lam = x_poi.mean()expected = scipy.stats.poisson.pmf(np.arange(len(obs)), lam) * len(x_poi)chi2 = scipy.stats.chisquare(obs, expected)[1]print(â€˜Chi-sqaure significance level is: {:.4f}â€™.format(chi2))Chi-sqaure significance level is: 0.4288 plt.bar(list(range(0, len(obs))), height=obs)plt.scatter(list(range(0, len(expected))), expected,c=â€™redâ€™)plt.plot(expected,c=â€™redâ€™, alpha=.5, linestyle=â€™dashedâ€™)*
```

*![](img/247e92dfe034248f555c2c3080b9c6ae.png)*

*åœ¨è¿ç»­å˜é‡çš„æƒ…å†µä¸‹ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ¥è‡ªä¼½é©¬åˆ†å¸ƒï¼Œå…·æœ‰ä»è§‚å¯Ÿæ•°æ®ä¼°è®¡çš„å‚æ•°ï¼Œå¯ä»¥å¦‚ä¸‹è¿›è¡Œ:*

```
*a = 3.5 # shape parametermean, var, skew, kurt = gamma.stats(a, moments=â€™mvskâ€™)x = np.linspace(gamma.ppf(0.01, a), gamma.ppf(0.99, a), 1000) # percent point function# Generate random numbers from the gamma distribution with paramter shape of 3.5r = gamma.rvs(a, size=1000)plt.plot(x, gamma.pdf(x, a), lw=5, alpha=0.6)plt.hist(r, density=True, alpha=0.2)*
```

*![](img/86de4b5465908a0ea9a93be883a533c2.png)*

```
*# Compute the chi-sqaure test between the random sample r and the observed frequencies xfrom scipy.stats import chisquarechisquare(r, x)>>> Power_divergenceResult(statistic=2727.3564204592853, pvalue=3.758371304737685e-160)*
```

*å¡æ–¹æ£€éªŒçš„é›¶å‡è®¾æ˜¯è§‚å¯Ÿåˆ°çš„é¢‘ç‡å’Œé¢„æœŸçš„é¢‘ç‡ä¹‹é—´æ²¡æœ‰å…³ç³»ï¼Œä½†æ˜¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œp å€¼å°äº 0.05 çš„æ˜¾è‘—æ€§æ°´å¹³ï¼Œå› æ­¤æˆ‘ä»¬æ‹’ç»é›¶å‡è®¾ã€‚*

*å¦ä¸€ä¸ªå¹¿æ³›ä½¿ç”¨çš„ç»Ÿè®¡æ£€éªŒæ˜¯ Kolmogorov-Smirnov æ‹Ÿåˆä¼˜åº¦æ£€éªŒã€‚è¯¥æ£€éªŒæ˜¯éå‚æ•°æ£€éªŒï¼Œå¯ç”¨äºç¦»æ•£æ•°æ®ã€åˆ†ç±»å­˜å‚¨çš„è¿ç»­æ•°æ®(ç„¶è€Œï¼Œä¸€äº›ä½œè€…ä¸åŒæ„è¿™ä¸€ç‚¹)å’Œè¿ç»­å˜é‡ã€‚è¯¥æ£€éªŒåŸºäºæ•°æ®çš„ç»éªŒåˆ†å¸ƒå‡½æ•°å’Œç›¸å…³åˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ä¹‹é—´çš„è·ç¦»çš„æ¯”è¾ƒã€‚*

*å½“æ ·æœ¬é‡ä¸å¤ªå¤§æ—¶ï¼ŒKolmogorov-Smirnov æ£€éªŒæ¯”å¡æ–¹æ£€éªŒæ›´æœ‰æ•ˆã€‚å¯¹äºå¤§æ ·æœ¬ï¼Œä¸¤ç§æµ‹è¯•å…·æœ‰ç›¸ä¼¼çš„åŠŸæ•ˆã€‚Kolmogorov-Smirnov æ£€éªŒæœ€ä¸¥é‡çš„é™åˆ¶æ˜¯åˆ†å¸ƒå¿…é¡»å®Œå…¨æŒ‡å®šï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä½ç½®ã€æ¯”ä¾‹å’Œå½¢çŠ¶å‚æ•°ä¸èƒ½ä»æ ·æœ¬ä¸­ä¼°è®¡ã€‚ç”±äºè¿™äº›é™åˆ¶ï¼Œæœ‰æ—¶æœ€å¥½ä½¿ç”¨å®‰å¾·æ£®-è¾¾æ—æ£€éªŒã€‚ç„¶è€Œï¼Œå®‰å¾·æ£®-è¾¾æ—æ£€éªŒåªé€‚ç”¨äºä¸€å°éƒ¨åˆ†åˆ†å¸ƒã€‚*

*åœ¨ Python ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`scipy`æ¥æ‰§è¡Œè¿™ä¸ªæµ‹è¯•ï¼Œè®©æˆ‘ä»¬ç”¨å‚æ•°`mu`ä¸º 0.6 çš„æ³Šæ¾`pdf`çš„ä¸¤ä¸ªæ ·æœ¬æ¥å®ç°å®ƒ:*

```
*from scipy.stats import ks_2sampfrom scipy.stats import poissonmu = 0.6 # shape parameterr = poisson.rvs(mu, size=1000)r1 = poisson.rvs(mu, size=1000)ks_2samp(r, r1)>>> Ks_2sampResult(statistic=0.037, pvalue=0.5005673707894058)*
```

*åœ¨ä»–çš„æµ‹è¯•ä¸­ï¼Œé›¶å‡è®¾è¡¨æ˜ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´æ²¡æœ‰å·®å¼‚ï¼Œå› æ­¤å®ƒä»¬æ¥è‡ªä¸€ä¸ªå…±åŒçš„åˆ†å¸ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œp å€¼ 0.68 æ— æ³•æ‹’ç»é›¶å‡è®¾ï¼Œæ¢å¥è¯è¯´ï¼Œæ ·æœ¬æ¥è‡ªç›¸åŒçš„åˆ†å¸ƒã€‚*

*ä½†æ˜¯è®©æˆ‘ä»¬çœ‹çœ‹æ³Šæ¾å’Œæ­£æ€æ ·æœ¬ä¹‹é—´çš„å…³ç³»:*

```
*from scipy.stats import normn = norm.rvs(0.6, size=1000)ks_2samp(r, n)>>> Ks_2sampResult(statistic=0.306, pvalue=9.933667429508653e-42)*
```

*ç›¸åï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œp å€¼å°äº 0.05 çš„æ˜¾è‘—æ€§æ°´å¹³ï¼Œè¿™è¡¨æ˜æˆ‘ä»¬å¯ä»¥æ‹’ç»é›¶å‡è®¾ï¼Œå› æ­¤ä¸¤ä¸ªæ ·æœ¬æ¥è‡ªä¸¤ä¸ªä¸åŒçš„åˆ†å¸ƒã€‚*

*æˆ‘ä»¬è¿˜å¯ä»¥ç”¨å›¾å½¢æ¯”è¾ƒä¸¤ä¸ª CDF:*

```
*def cdf(x, plot=True):x, y = sorted(x), np.arange(len(x)) / len(x)plt.title(â€˜Normal VS Poisson CDFâ€™)return plt.plot(x, y) if plot else (x, y)cdf(r)cdf(n)*
```

*![](img/4b3007290cfe07f73c2505736eeb613b.png)*

# *å¸¸æ€æ£€éªŒ*

*å¯èƒ½å‘ç”Ÿçš„å¦ä¸€ä¸ªæŒ‘æˆ˜æ˜¯éªŒè¯æ”¶é›†çš„æ ·æœ¬æ˜¯å¦æ¥è‡ªæ­£æ€åˆ†å¸ƒï¼Œä¸ºæ­¤ï¼Œæœ‰ä¸€ä¸ªæµ‹è¯•æ—ç§°ä¸ºæ­£æ€æ€§æµ‹è¯•ã€‚å¤çš®ç½—-ç»´å°”å…‹æ£€éªŒæ˜¯æœ€å¼ºå¤§çš„æ­£æ€æ€§æ£€éªŒä¹‹ä¸€ï¼Œå®ƒå¯¹å°æ ·æœ¬ä¹Ÿéå¸¸æœ‰æ•ˆã€‚é€šè¿‡åŒ¹é…ä¸¤ä¸ªå¤‡é€‰æ–¹å·®ä¼°è®¡æ¥æ£€éªŒæ­£æ€æ€§:é€šè¿‡æœ‰åºæ ·æœ¬å€¼çš„çº¿æ€§ç»„åˆè®¡ç®—çš„éå‚æ•°ä¼°è®¡å’Œå‚æ•°ä¼°è®¡ã€‚*

*`Scipy`è¿˜æä¾›äº†ä¸€ç§æ‰§è¡Œè¯¥æµ‹è¯•çš„æ–¹æ³•:*

```
*from scipy.stats import norm, shapiron = norm.rvs(size=1000)shapiro(n)>>> (0.9977349042892456, 0.18854272365570068)*
```

*ç»è¿‡æ£€éªŒçš„é›¶å‡è®¾(H0)æ˜¯æ•°æ®æ¥è‡ªæ­£æ€åˆ†å¸ƒï¼Œp å€¼ä¸º 0.188ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ— æ³•æ‹’ç»å®ƒï¼Œè¯´æ˜æ ·æœ¬æ¥è‡ªæ­£æ€åˆ†å¸ƒã€‚*

*å¦ä¸€ç§å¸¸è§çš„æ­£æ€æ€§æ£€éªŒæ˜¯ Jarque-Bera æ£€éªŒ:*

```
*from scipy.stats import norm, jarque_beran = norm.rvs(size=1000)jarque_bera(n)>>> (0.8127243048627657, 0.6660689052671738)*
```

*å’Œä»¥å‰ä¸€æ ·ï¼Œæˆ‘ä»¬ä¸æ‹’ç»æ•°æ®æ¥è‡ªæ­£æ€æ€»ä½“çš„æ— æ•ˆå‡è®¾ã€‚*

```
***I have a newsletter ğŸ“©.**Every week Iâ€™ll send you a brief findings of articles, links, tutorials, and cool things that caught my attention. If tis sounds cool to you subscribe.*That means* ***a lot*** *for me.**
```

 *[## ç±³å°”æ–¯å½¢å¼

### ç¼–è¾‘æè¿°

æ— æƒ…-åˆ›é€ è€…-2481.ck.page](https://relentless-creator-2481.ck.page/68d9def351)* 

# *é™„å½•:*

*   *ç”¨ NumPy æŒæ¡æ•°å€¼è®¡ç®—:æŒæ¡ç§‘å­¦è®¡ç®—ï¼Œè½»æ¾å®Œæˆå¤æ‚çš„è¿ç®—(äºç±³ç‰¹Â·æ¢…å°”ç‰¹Â·å¡é©¬å…‹ï¼Œæ¢…å°”ç‰¹Â·åº“å“ˆå¤§ç½—æ ¼å¢)*
*   *Python ä¸­çš„æ­£æ€æ€§æµ‹è¯•([https://datascienceplus.com/normality-tests-in-python/](https://datascienceplus.com/normality-tests-in-python/))*
*   *ç”¨æœ€å¤§ä¼¼ç„¶æ³•æ‹Ÿåˆæ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒ([https://ipython-books . github . io/75-fitting-a-probability-distribution-to-data-with-the-maximum-likelihood-method/](https://ipython-books.github.io/75-fitting-a-probability-distribution-to-data-with-the-maximum-likelihood-method/))*
*   *ç”¨ R([https://cran . R-project . org/doc/contrib/Ricci-DISTRIBUTIONS-en . pdf](https://cran.r-project.org/doc/contrib/Ricci-distributions-en.pdf))æ‹Ÿåˆåˆ†å¸ƒ*
*   *åˆ†å¸ƒæ‹Ÿåˆåˆ°æ•°æ®([https://python health care . org/2018/05/03/81-distribution-fitting-to-data/](https://pythonhealthcare.org/2018/05/03/81-distribution-fitting-to-data/))*