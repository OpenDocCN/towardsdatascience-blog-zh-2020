<html>
<head>
<title>Analyzing Best Hacker News Posts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分析最佳黑客新闻帖子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/analyzing-best-hacker-news-posts-bebd7d2fd791?source=collection_archive---------48-----------------------#2020-05-04">https://towardsdatascience.com/analyzing-best-hacker-news-posts-bebd7d2fd791?source=collection_archive---------48-----------------------#2020-05-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="f214" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">有史以来最佳黑客新闻帖子的统计和文本分析。</em></p><p id="d12a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每天我都会查看<a class="ae km" href="https://news.ycombinator.com/" rel="noopener ugc nofollow" target="_blank">黑客新闻</a>寻找有趣的信息，无论是文章、故事、软件还是工具。大多数登上头版的投稿都非常有趣和有用，而且社区驱动的帖子管理如此之好的事实让我着迷。</p><p id="3bc0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了这篇文章的目的，我使用了<a class="ae km" href="https://github.com/HackerNews/API" rel="noopener ugc nofollow" target="_blank">黑客新闻API </a>收集了大约200篇提交给Hacker News的最好的故事和他们的评论，并对数据进行了一些处理，以获得一点关于什么是一篇好的《HN邮报》的见解。</p><p id="e124" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们开始之前，我必须说，我毫不怀疑黑客新闻提交是好的，这要归功于所提供信息的质量和对该特定信息的兴趣程度。但是，可能还有其他因素，在很小的比例上，帮助HN提名登上头版。</p><p id="9df6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">记住这一点，让我们看看这篇文章的概述:</p><ul class=""><li id="ea6f" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk ks kt ku kv bi translated">为我们的分析获取数据</li><li id="eb50" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">数据可视化:单词云和分数分析</li><li id="8fdd" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">何时在HackerNews上发帖</li><li id="7620" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">问HN vs秀HN</li><li id="5f71" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">黑客新闻上的人们谈论谁:实体识别和关键词提取</li><li id="4194" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">结论</li></ul><p id="fecf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">本文原载于</em> <a class="ae km" href="https://programmerbackpack.com/latent-dirichlet-allocation-for-topic-modelling-explained-algorithm-and-python-scikit-learn-implementation/" rel="noopener ugc nofollow" target="_blank"> <em class="kl">程序员背包博客</em> </a> <em class="kl">。如果你想阅读更多这类的故事，一定要访问这个博客。</em></p><p id="e9ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">对更多这样的故事感兴趣？在Twitter上关注我，地址是</em><a class="ae km" href="https://twitter.com/b_dmarius" rel="noopener ugc nofollow" target="_blank"><em class="kl">@ b _ dmarius</em></a><em class="kl">，我会在那里发布每一篇新文章。</em></p><h1 id="2c05" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">获取数据进行分析</h1><p id="54db" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我使用了HackerNews API /beststories端点收集了188个有史以来最好的故事。对于每个故事，我也收集了评论(但不是对评论的评论，只有主线)。这是我为每个条目存储的数据。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="5efc" class="mn lc iq mj b gy mo mp l mq mr">id - the id of the entry<br/>parent - the id of the parent. For a story, it is the same as the id field. For a comment, it's the id of the story to which the commend was added<br/>kids_number - only for stories, meaning the number of comments<br/>score - only for stories: the number of points the submission got<br/>time - UNIX timestamp of the time the entry was added<br/>text - title of posts or texts of comments<br/>type - 'story' or 'comment'</span></pre><p id="a687" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我用来获取数据的类的完整代码将在本文末尾提供。</p><p id="d32f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，数据存储在csv_file中，并从那里加载到Pandas帧中。我还需要为我的分析创建另外4列:<em class="kl"> DayOfWeek，HourOfDay，isAsk，isShow。这些名字不言自明。</em></p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="5784" class="mn lc iq mj b gy mo mp l mq mr">dataFetcher = DataFetcher("https://hacker-news.firebaseio.com/v0/", "data.csv")<br/>    dataFetcher.fetchData()</span><span id="8c88" class="mn lc iq mj b gy ms mp l mq mr">    df = pd.read_csv("data.csv")</span><span id="ce21" class="mn lc iq mj b gy ms mp l mq mr">    df['DateTime'] = pd.to_datetime(df['time'], unit='s')<br/>    df['DayOfWeek'] = df['DateTime'].dt.day_name()<br/>    df['HourOfDay'] = df['DateTime'].dt.hour<br/>    df['isAsk'] = df.apply(lambda x: x.type=='story' and x.text.lower().startswith("ask hn:"), axis=1)<br/>    df['isShow'] = df.apply(lambda x: x.type == 'story' and x.text.lower().startswith("show hn:"), axis=1)</span></pre><h1 id="cea4" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据可视化:单词云和分数分析</h1><p id="8b17" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我首先对数据做了一些探索性的分析。首先，我从故事标题和评论中建立了两个独立的单词云，希望我能对HackerNews上常用的单词有所了解。我已经从标题中删除了“展示HN”和“询问HN”的标签。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="0ff3" class="mn lc iq mj b gy mo mp l mq mr">stopwords = set(STOPWORDS)<br/>    stopwords.update(["Ask", "Show", "HN"])<br/>    titles_text = " ".join(df[df['type']=='story']['text'].unique())<br/>    titles_cloud = WordCloud(stopwords=stopwords, background_color='white').generate(titles_text)<br/>    plt.figure(figsize=(8, 8), facecolor=None)<br/>    plt.imshow(titles_cloud, interpolation="bilinear")<br/>    plt.axis("off")<br/>    plt.tight_layout(pad=0)<br/>    plt.show()</span></pre><figure class="me mf mg mh gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mt"><img src="../Images/a15f7735b9acb3b4d37afaee415301cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JSaNlAI35BnAMubQXRFvrw.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">从故事标题构建单词云</p></figure><p id="cd49" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了大的、明显的Covid和冠状病毒词，大多数词都与软件、编程和技术有关。一个很好的观察是，视频似乎在黑客新闻上工作得很好(至少这个词云告诉我们)。</p><p id="e8b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">也来看看评论吧。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="6137" class="mn lc iq mj b gy mo mp l mq mr">comments = " ".join(df[df['type'] == 'comment']['text'].unique())<br/>    comments_cloud = WordCloud(background_color='white').generate(comments)<br/>    plt.figure(figsize=(8, 8), facecolor=None)<br/>    plt.imshow(comments_cloud, interpolation="bilinear")<br/>    plt.axis("off")<br/>    plt.tight_layout(pad=0)<br/>    plt.show()</span></pre><figure class="me mf mg mh gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nf"><img src="../Images/6c72480366806439299abfc2da4fc5a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zYcjR0-7dh2Y6ZnL3Ht03w.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">从评论中构建单词云</p></figure><p id="7420" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我有一点失望，因为我没有包括所有关于这个分析的评论，但是评论的数量非常大，我不确定它对我的这篇文章有多大帮助。但是我们都知道有时候我们花在评论区的时间比花在最初提交的帖子上的时间还多😀</p><p id="6d29" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我想看看最好的帖子的分数。我绘制了一个直方图来说明分数倾向于聚集的值，我还计算了分数的平均值和中值。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="ea15" class="mn lc iq mj b gy mo mp l mq mr"># Histogram of scores</span><span id="22d2" class="mn lc iq mj b gy ms mp l mq mr">    scores = df[df['type']=='story']['score']<br/>    scores.plot.hist(bins=12, alpha=0.5)<br/>    plt.show()<br/></span><span id="6c59" class="mn lc iq mj b gy ms mp l mq mr">    # Average score<br/>    print ("Average score: ", df[df['type']=='story']['score'].mean())</span><span id="308a" class="mn lc iq mj b gy ms mp l mq mr">    # Median score<br/>    print("Median score: ", df[df['type'] == 'story']['score'].median())</span></pre><figure class="me mf mg mh gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi ng"><img src="../Images/ae3d04a36543cb0965bf3af38a3c32a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9kdAfsmxgAQhwt3RSWHBTg.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">黑客新闻最佳帖子得分直方图</p></figure><p id="b734" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，大多数故事的得分都低于200分，但也有一些异常值，至少有1000分。</p><p id="de19" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的数据集的平均得分为194.80，但是这受到了异常值的巨大影响。这就是为什么我还计算了<strong class="jp ir">的中间值</strong>，它是140.0。也就是说，黑客新闻上大约一半的最佳报道得分不到140分，而另一半得分超过了140分。</p><h1 id="bedc" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">何时在黑客新闻上发布</h1><p id="5b8a" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">这是很多人在网上问的问题。这篇文章绝不是寻找答案的捷径，但我仍然认为我找到了一些有趣的东西。</p><p id="7f74" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我绘制了一周中每天的故事分布图。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="b870" class="mn lc iq mj b gy mo mp l mq mr">daysOfWeek = df[df['type']=='story'].groupby(['DayOfWeek']).size()<br/>    daysOfWeek.plot.bar()<br/>    plt.show()</span></pre><figure class="me mf mg mh gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nh"><img src="../Images/164c3bc1183d35036e81fab76f820076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kNzg0r1BHe_hNzS2HE4vGg.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">何时在HackerNews上发帖——按星期几发帖</p></figure><p id="1a96" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">大多数最好的故事都是在周末发布的。不知何故，我期待着这一点。但对我来说最有趣的事实是，没有一个最好的故事是在周二或周三提交的。周一似乎也是非常糟糕的一天，很少有成功的提交。</p><p id="aeb6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在做这个分析之前，我还会猜测星期五会获得最多的成功提交。我也不知道具体为什么，只是直觉。</p><p id="6634" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还可以看看另一个时间维度，那就是一天中的某个时刻。让我们画出同样的分布。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="3bc8" class="mn lc iq mj b gy mo mp l mq mr">hoursOfDay = df[df['type']=='story'].groupby(['HourOfDay']).size()<br/>    hoursOfDay.plot.bar()<br/>    plt.show()</span></pre><figure class="me mf mg mh gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi ni"><img src="../Images/7a8f6122c34c7f0e947491bbbb1b77db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zs8Uuek0D940dSiH4byQmg.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">何时在Hackernews上发帖——按星期几发帖</p></figure><p id="5d83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们的时间列以UTC时间显示，我们可以看到大多数成功的帖子是在下午提交的，最大的峰值出现在UTC时间下午5点。</p><p id="76af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我想检查的另一件事是，一篇帖子获得的点数和该帖子的评论数之间是否有任何关联。对我来说，这似乎很明显应该是真的:如果人们发现一些足够有趣的东西来投票，他们也可能会在那个帖子上开始讨论。</p><p id="d644" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我还在这个关联矩阵中加入了一天中的某个小时，以检查一天中人们是否有更想参与对话的时候。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="0784" class="mn lc iq mj b gy mo mp l mq mr">correlationsData = df[df['type'] =='story'][['score', 'kids_number', 'HourOfDay']]<br/>    print (correlationsData.corr(method='pearson'))</span></pre><figure class="me mf mg mh gt mu gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/2c028379f2f8bdf02904d32ebc07a84e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*VJGXeh9vVaXAyrKpp_xGFA.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">何时在黑客新闻上发表文章——相关性</p></figure><p id="5659" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">分数和评论数量之间似乎有很强的相关性。正如我所说的，我多少预料到了这一点。但是我对分数和时间之间不存在的相关性有点失望。</p><h1 id="8ffd" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">问HN vs秀HN</h1><p id="103c" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">接下来，我想看看黑客新闻上有多少最成功的帖子是提问/展示提交的。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="be26" class="mn lc iq mj b gy mo mp l mq mr">print ("Count of Ask HN stories: ", df[df['isAsk']==True].shape[0])<br/>    print ("Percentage of Ask HN stories:", 100 * df[df['isAsk']==True].shape[0] / df[df['type']=='story'].shape[0])<br/>    print ("Count of Show HN stories: ", df[df['isShow']==True].shape[0])<br/>    print ("Percentage of Show HN stories:", 100 * df[df['isShow']==True].shape[0] / df[df['type']=='story'].shape[0])</span></pre><p id="d980" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">似乎只有8个帖子问HN(占我的数据集的4.30%)，16个帖子显示HN(占数据集的8.60%)。毕竟这里没什么可看的，只有几个提交的问题HN/展示帖子。</p><h1 id="7d4e" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">黑客新闻上的人们谈论谁:实体识别和关键词提取</h1><p id="edb4" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">下一步是对黑客新闻上的最佳帖子的标题运行一个实体提取器，并从这里保存个人和组织实体，看看是否有任何东西冒出来。我用<a class="ae km" href="https://programmerbackpack.com/machine-learning-project-series-building-a-personal-knowledge-management-system-part-1-named-entity-recognition/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> spacy进行实体提取</strong> </a>。</p><p id="a2f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我得到了175个实体的名单。因为这是一个没有告诉我们任何事情的大列表，所以我只提取了出现不止一次的实体。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="df04" class="mn lc iq mj b gy mo mp l mq mr">nlp = spacy.load('en_core_web_sm')<br/>    doc = nlp(". ".join(df[df['type']=='story']['text'].unique()))<br/>    entity_names = [entity.text for entity in doc.ents if entity.label_ in ["PERSON", "ORG"]]<br/>    freq = {entity_names.count(entity): entity  for entity in entity_names}<br/>    for i in sorted (freq.keys()):<br/>        if i &gt; 1:<br/>            print (freq[i])<br/>            <br/>    <br/>    # Prints: Amazon, Google, Apple</span></pre><p id="a865" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">三家科技巨头是唯一三家在最佳黑客新闻帖子中出现不止一次的实体。</p><p id="740e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后一步是<a class="ae km" href="https://programmerbackpack.com/machine-learning-project-series-part-2-python-named-entity-recognition/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">使用gensim从帖子的标题中提取关键词</strong> </a>。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="1451" class="mn lc iq mj b gy mo mp l mq mr">print(keywords(". ".join(df[df['type']=='story']['text'].unique())).split('\n'))</span></pre><p id="185a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这会产生一个巨大的关键字列表，其中前3个是:“covid”、“pdf”和“video”。除此之外，大多数关键词都与“生成器”、“应用程序”和“机器学习”有关。</p><p id="cbf8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们不要忘记添加我用来从Hacker News API中提取数据的类的代码，正如我在本文开始时承诺的那样。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="a56d" class="mn lc iq mj b gy mo mp l mq mr">import csv<br/>import requests<br/>from bs4 import BeautifulSoup<br/></span><span id="68b5" class="mn lc iq mj b gy ms mp l mq mr">BEST_STORIES="beststories.json"</span><span id="d953" class="mn lc iq mj b gy ms mp l mq mr">class DataFetcher:</span><span id="60c7" class="mn lc iq mj b gy ms mp l mq mr">    def __init__(self, baseUrl, dataFile):<br/>        self.baseUrl = baseUrl<br/>        self.dataFile = dataFile</span><span id="e618" class="mn lc iq mj b gy ms mp l mq mr">    def fetchData(self):<br/>        with open(self.dataFile, mode='w') as data_file:<br/>            data_writer = csv.writer(data_file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)<br/>            data_writer.writerow(['id', 'parent', 'kids_number', 'score', 'time', 'text', 'type'])</span><span id="97b8" class="mn lc iq mj b gy ms mp l mq mr">            # Best stories<br/>            r = requests.get(url=self.baseUrl + BEST_STORIES)<br/>            bestStoriesIds = r.json()<br/>            count = 0<br/>            for id in bestStoriesIds:<br/>                count = count + 1<br/>                print (str(count) + " / " + str(len(bestStoriesIds)))<br/>                story = requests.get(url=self.baseUrl + "item/" + str(id) + ".json")<br/>                storyJson = story.json()<br/>                data_writer.writerow([storyJson['id'], storyJson['parent'] if "parent" in storyJson else storyJson['id'],<br/>                                      len(storyJson['kids']) if 'kids' in storyJson else 0, storyJson['score'],<br/>                                      storyJson['time'], BeautifulSoup(storyJson['title'], features="html.parser").getText(), storyJson['type']])</span><span id="6f87" class="mn lc iq mj b gy ms mp l mq mr">                # Getc<br/>                if "kids" in storyJson:<br/>                    for kidId in storyJson["kids"]:<br/>                        kid = requests.get(url=self.baseUrl + "item/" + str(kidId) + ".json")<br/>                        kidJson = kid.json()<br/>                        if kidJson and kidJson['type'] == 'comment' and "text" in kidJson:<br/>                            data_writer.writerow(<br/>                                [kidJson['id'], storyJson['id'],<br/>                                 len(kidJson['kids']) if 'kids' in kidJson else 0, 0,<br/>                                 kidJson['time'], BeautifulSoup(kidJson['text'], features="html.parser").getText(), kidJson['type'], ''])</span><span id="008a" class="mn lc iq mj b gy ms mp l mq mr">            print ("Latest stories")<br/>            maxId = requests.get(url=self.baseUrl + "maxitem.json").json()<br/>            countDown = 1000<br/>            while countDown &gt; 0:<br/>                print ("Countdown: ", str(countDown))<br/>                story = requests.get(url=self.baseUrl + "item/" + str(maxId) + ".json")<br/>                storyJson = story.json()<br/>                if storyJson["type"] == "story" and storyJson["score"] &gt; 50:<br/>                    countDown = countDown - 1<br/>                    maxId = maxId - 1<br/>                    data_writer.writerow(<br/>                        [storyJson['id'], storyJson['parent'] if "parent" in storyJson else storyJson['id'],<br/>                         len(storyJson['kids']) if 'kids' in storyJson else 0, storyJson['score'],<br/>                         storyJson['time'], BeautifulSoup(storyJson['title'], features="html.parser").getText(),<br/>                         storyJson['type'],<br/>                         storyJson['url'] if "url" in storyJson else ''])</span><span id="741d" class="mn lc iq mj b gy ms mp l mq mr">                    # Getc<br/>                    if "kids" in storyJson:<br/>                        for kidId in storyJson["kids"]:<br/>                            kid = requests.get(url=self.baseUrl + "item/" + str(kidId) + ".json")<br/>                            kidJson = kid.json()<br/>                            if kidJson['type'] == 'comment' and "text" in kidJson:<br/>                                data_writer.writerow(<br/>                                    [kidJson['id'], storyJson['id'],<br/>                                     len(kidJson['kids']) if 'kids' in kidJson else 0, 0,<br/>                                     kidJson['time'], BeautifulSoup(kidJson['text'], features="html.parser").getText(),<br/>                                     kidJson['type'], ''])</span></pre><h1 id="03ff" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="ac9e" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">这就是我对有史以来最佳黑客新闻帖子的小小分析。我真的很喜欢摆弄这些数据。我希望你也喜欢这个，并从这个项目中获得一些有意义的见解。</p><p id="95ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">本文原载于</em> <a class="ae km" href="https://programmerbackpack.com/latent-dirichlet-allocation-for-topic-modelling-explained-algorithm-and-python-scikit-learn-implementation/" rel="noopener ugc nofollow" target="_blank"> <em class="kl">程序员背包博客</em> </a> <em class="kl">。如果你想阅读更多这类的故事，一定要访问这个博客。</em></p><p id="f2b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">非常感谢您阅读本文！有兴趣了解更多吗？在Twitter上关注我，地址是</em><a class="ae km" href="https://twitter.com/b_dmarius" rel="noopener ugc nofollow" target="_blank"><em class="kl">@ b _ dmarius</em></a><em class="kl">，我会在那里发布每一篇新文章。</em></p></div></div>    
</body>
</html>