<html>
<head>
<title>Developing Trust in Machine Learning Models Predictions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">发展对机器学习模型预测的信任</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/developing-trust-in-machine-learning-models-predictions-e49b0064abab?source=collection_archive---------38-----------------------#2020-08-30">https://towardsdatascience.com/developing-trust-in-machine-learning-models-predictions-e49b0064abab?source=collection_archive---------38-----------------------#2020-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ba7e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 LIME 解释和说明机器学习模型做出的预测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/04289fddb827fafca616474a573d2189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*CZleIpFEfGSTTvo7OvnZYg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">肖恩·梅因斯在<a class="ae ku" href="https://unsplash.com/s/photos/lime?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="d19c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="lr">如果我告诉你今天投资 10 万美元在一只特定的股票上，因为我的机器学习模型预测会有高回报。你会问我的问题将是解释我的预测的基础，因为这对你来说是一个重大的决定。你不想赌博，但想根据数据做出明智的决策。</em></p><p id="066b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为了信任机器学习模型的预测，你会问以下问题。</p><ul class=""><li id="480e" class="ls lt it kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">模型是如何做出预测的？</li><li id="847c" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">为什么模型会对特定的实例做出特定的预测？</li><li id="9440" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">哪些特征对预测的影响最大，哪些影响最小，并给出一个易于理解的解释。</li><li id="9847" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">模型的解释应该呈现特征和模型预测之间的文本或视觉定性关系。</li></ul><p id="80e7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在这篇文章中，你将学习使用 LIME 来解释机器学习模型的预测，并解释对做出预测贡献最大的特征。T9】</p><p id="745f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">有几种解释机器学习模型的技术，但这里我们将讨论<strong class="kx iu"> LIME(局部可解释模型-不可知论者解释)。</strong></p><p id="56c3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> <em class="lr">什么是石灰？</em>T15】</strong></p><p id="7eb7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> LIME 是机器学习模型的局部可解释模型不可知解释</strong>，它让你理解个体预测，</p><ul class=""><li id="1478" class="ls lt it kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated"><strong class="kx iu"> LIME 可以解释机器学习模型的单个预测，而不是解释整个数据集。</strong></li><li id="4f83" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">它是局部忠实的，并且具有局部保真性，这意味着全球基本特征在局部环境中可能不那么重要，反之亦然。它通过<strong class="kx iu">用一个可解释的模型对其进行局部近似来做到这一点。</strong></li><li id="787c" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated"><strong class="kx iu">它是模型不可知的</strong>，可以应用于分类器以及基于回归的机器学习算法。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mg"><img src="../Images/75e9922abb234668cdad5ec994165cf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ao3kt6PEnXPteCo55PPI0A.png"/></div></div></figure><p id="5b50" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> <em class="lr">石灰是怎么起作用的？</em>T29】</strong></p><p id="dbec" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">LIME 扰动输入数据集以查看预测中的变化。这些扰动是基于数据的方差。</p><ul class=""><li id="e05a" class="ls lt it kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">它<strong class="kx iu">创建一个可解释的表示，该表示根据输入数据</strong>的小扰动进行训练，这提供了一个用于解释个体预测的良好的局部近似。</li><li id="db39" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">它在可解释表示数据 <strong class="kx iu">和原始数据</strong>之间创建<strong class="kx iu">相似性分数，以了解它们有多相似</strong></li><li id="cc7f" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated"><strong class="kx iu">使用可解释制图表达数据集上的模型进行预测。</strong></li><li id="c0e7" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">它<strong class="kx iu">在可解释的表示数据集上尝试不同的组合，以找到最大可能匹配模型在原始数据集上所做预测的最小要素集</strong>。</li><li id="ed71" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">确定的<strong class="kx iu">最小特征集给出了原始数据的大部分信息以及相似性得分，用于解释个体预测。</strong></li></ul><p id="7446" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> <em class="lr">有哪些不同的机器学习模型可以用到 LIME？</em>T13】</strong></p><p id="3f15" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">LIME 与模型无关，可以用于</p><ul class=""><li id="71e6" class="ls lt it kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated"><strong class="kx iu">分类以及回归</strong>问题。</li><li id="7b7f" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">它可以使用 NLP 在<strong class="kx iu">文本数据</strong>上使用。</li><li id="4365" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">可应用于<strong class="kx iu">图像数据</strong></li><li id="a593" class="ls lt it kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">LIME 也可以应用于<strong class="kx iu">表格数据</strong>，其中列代表特征，行是单独的实例。</li></ul><p id="a65c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> <em class="lr">如何将 LIME 应用于基于分类的机器学习模型？</em>T25】</strong></p><h2 id="fb6d" class="ml mm it bd mn mo mp dn mq mr ms dp mt le mu mv mw li mx my mz lm na nb nc nd bi translated">石灰在使用表格数据的分类模型中的应用</h2><p id="270a" class="pw-post-body-paragraph kv kw it kx b ky ne ju la lb nf jx ld le ng lg lh li nh lk ll lm ni lo lp lq im bi translated">使用的数据集是<a class="ae ku" href="https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients" rel="noopener ugc nofollow" target="_blank">默认信用卡客户数据集</a>。</p><p id="baa5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于分类问题，值 1 意味着客户将拖欠付款，值 0 表示客户不会拖欠信用卡付款。</p><p id="7d84" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">加载数据并显示列名</strong></p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="fd89" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">import pandas as pd<br/>import numpy as np<br/>np.random.seed(0)<br/>df = pd.read_csv(r'c:\data\default of credit card clients.csv')<br/>df.columns</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi ns"><img src="../Images/60e001b87fae3f4f5cc709440755ead6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bLTl9BhvSxFTLFWNuukPXg.png"/></div></div></figure><p id="46c6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">创建特征和目标变量</strong></p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="75cc" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">Y = df[['default payment next month']]</strong><br/><strong class="nk iu">X =  df[['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2','BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]</strong></span></pre><p id="02de" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">将数据集分成训练和测试</strong></p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="e02e" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">from sklearn.model_selection import train_test_split<br/>from sklearn import preprocessing</strong></span><span id="88d9" class="ml mm it nk b gy nt np l nq nr"><strong class="nk iu">X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4)</strong></span></pre><p id="68b1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">创建随机森林分类器并拟合训练数据</strong></p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="1435" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">from sklearn.ensemble import RandomForestClassifier</strong><br/><strong class="nk iu">model = RandomForestClassifier(max_depth=6, random_state=0, n_estimators=10)<br/>model.fit(X_train, Y_train)</strong></span></pre><p id="c8c1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">显示特征重要性</strong></p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="9d7c" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">importances = model.feature_importances_<br/>indices = np.argsort(importances)</strong></span><span id="c1c0" class="ml mm it nk b gy nt np l nq nr"><strong class="nk iu">features = X_train.columns<br/>plt.title('Feature Importances')<br/>plt.barh(range(len(indices)), importances[indices], color='b', align='center')<br/>plt.yticks(range(len(indices)), [features[i] for i in indices])<br/>plt.xlabel('Relative Importance')<br/>plt.show()</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/49c4516de8f09de707e44bbc48ef0013.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*_6TutDm8VjjdNnNBEAd97Q.png"/></div></figure><p id="01e5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">创建石灰表格实例</strong></p><p id="392f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">因为我们的数据集是表格形式的，所以我们创建了 LimeTabularExplainer()的一个实例。<strong class="kx iu"> training_data </strong>:通过训练数据集，</p><p id="ca21" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">模式</strong>:可以是<strong class="kx iu">回归</strong>或<strong class="kx iu">分类</strong>。我们正在处理一个分类问题，所以我们将模式参数设置为“分类”</p><p id="6218" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> feature_names </strong>:数据集中的所有输入特征，用于计算每个特征的统计数据。平均值，计算数值特征的标准偏差，而分类特征被离散化为四分位数。</p><p id="a006" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">训练 _ 标签</strong>:传递训练目标变量</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="dc7f" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">import lime<br/>from lime.lime_tabular import LimeTabularExplainer</strong></span><span id="7fa0" class="ml mm it nk b gy nt np l nq nr"><strong class="nk iu">explainer= LimeTabularExplainer(<em class="lr">training_data</em>=np.array(X_train),<br/>                                <em class="lr">mode</em>='classification', <br/>                                <em class="lr">feature_names</em>=list(X_train.columns),<br/>                                <em class="lr">training_labels</em>=np.array(Y_train),<br/>                                <em class="lr">random_state</em>=12</strong></span></pre><p id="6ec2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">使用从训练数据生成的计算统计</p><ol class=""><li id="57ba" class="ls lt it kx b ky kz lb lc le lu li lv lm lw lq nv ly lz ma bi translated">创建扰动的样本实例，这是一个<strong class="kx iu">可解释的表示数据集。</strong></li><li id="3d27" class="ls lt it kx b ky mb lb mc le md li me lm mf lq nv ly lz ma bi translated"><strong class="kx iu">当属性不在同一标度上时，缩放数据以计算相似性得分的距离</strong>。</li></ol><p id="b7af" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">为预测生成解释</strong></p><p id="166a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在，您可以通过将观察结果传递给<strong class="kx iu"> explain_instance() </strong>来为特定的观察结果生成解释</p><p id="2cfc" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> data_row: </strong>指定需要解释的观察结果</p><p id="01bf" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> classifier_fn: </strong>需要为分类模型指定模型预测概率，采用 numpy 数组，输出预测概率。对于回归模型，我们可以指定模型预测。</p><p id="f0a3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> num_features </strong>:我们需要解释的最大特征数</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="df20" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">exp = explainer.explain_instance(X_test.iloc[0], model.predict_proba, num_features=8)</strong></span><span id="d393" class="ml mm it nk b gy nt np l nq nr"><strong class="nk iu">exp.as_pyplot_figure()<br/>from matplotlib import pyplot as plt<br/>plt.tight_layout()</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/24cf2a154818d17a6d945efa0d429708.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*XWCn4UxvVD1y-YWRRorfOA.png"/></div></figure><p id="9f98" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在 python 笔记本中显示 HTML 解释</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="afe7" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">exp.show_in_notebook(show_table=True, show_all=True)</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nx"><img src="../Images/f4900d22c21f0c4a02a580f5cbb51403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1yKtIHcxkqycxCCQgtStvA.png"/></div></div></figure><p id="9ae4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> <em class="lr">如何解读结果？</em> </strong></p><p id="4aa4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于观察，概率预测是 87%，即客户不会拖欠信用卡付款。</p><p id="87bf" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">客户未拖欠信用卡付款的原因</strong></p><p id="e49b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">客户没有拖欠本月、2 月、3 月、4 月、5 月和 6 月的任何付款(PAY_0、PAY_2、PAY_3、PAY_4、PAY_5 和 PAY_6 为 0)。最近三个月的付款少于 1800 美元</p><p id="a762" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> <em class="lr">让我们来看另一个观察的解释。</em> </strong></p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="c138" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">exp = explainer.explain_instance(X_test.iloc[731], model.predict_proba)<br/>exp.show_in_notebook(show_table=True, show_all=False)</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi ny"><img src="../Images/5274fd26683c8d11824f170f9726d194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9r4jbpxg6AnR6U8qNGtXpA.png"/></div></div></figure><p id="508a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于观察，概率预测是 75%，客户将拖欠信用卡付款。</p><p id="7921" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">客户拖欠信用卡付款的原因</strong></p><p id="084b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">客户将本月、2 月、3 月、4 月、5 月和 6 月的付款延迟了两个月(PAY_0、PAY_2、PAY_3、PAY_4、PAY_5 和 PAY_6 为 2)。消费信贷少于或等于 500 美元。</p><p id="adce" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> <em class="lr">基于回归的机器学习模型如何应用 LIME？</em>T29】</strong></p><h2 id="ef8b" class="ml mm it bd mn mo mp dn mq mr ms dp mt le mu mv mw li mx my mz lm na nb nc nd bi translated">LIME 在使用表格数据的回归模型中的应用</h2><p id="cb8e" class="pw-post-body-paragraph kv kw it kx b ky ne ju la lb nf jx ld le ng lg lh li nh lk ll lm ni lo lp lq im bi translated">使用的数据集是<a class="ae ku" href="https://www.kaggle.com/quantbruce/real-estate-price-prediction?select=Real+estate.csv" rel="noopener ugc nofollow" target="_blank">房地产价格预测</a> n。</p><p id="37b5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这里我们将使用<strong class="kx iu"> RandomForestRegressor </strong>。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="b57b" class="ml mm it nk b gy no np l nq nr">#Importing required libraries<br/><strong class="nk iu">import pandas as pd<br/>import numpy as np<br/>import plotly<br/>np.random.seed(0)<br/>import matplotlib.pyplot as plt<br/>import lime<br/>from lime.lime_tabular import LimeTabularExplainer<br/>from sklearn.model_selection import train_test_split<br/>from sklearn import preprocessing<br/>from sklearn.ensemble import RandomForestRegressor</strong></span><span id="124d" class="ml mm it nk b gy nt np l nq nr">#Reading the data file<br/><strong class="nk iu">df = pd.read_csv(r'c:\data\Real estate.csv')</strong></span><span id="f387" class="ml mm it nk b gy nt np l nq nr"># Creating the input features and target variable<br/><strong class="nk iu">Y = df[['Y house price of unit area']]<br/>X =  df[[ 'X2 house age',<br/>       'X3 distance to the nearest MRT station',<br/>       'X4 number of convenience stores', 'X5 latitude', 'X6 longitude']]</strong></span><span id="76a8" class="ml mm it nk b gy nt np l nq nr"># check for missing data<br/><strong class="nk iu">X.isnull().sum()</strong></span><span id="ab0d" class="ml mm it nk b gy nt np l nq nr">#Creating train and test data<br/><strong class="nk iu">X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)</strong></span><span id="4d3c" class="ml mm it nk b gy nt np l nq nr">#Random Forest Regressor<br/><strong class="nk iu">model = RandomForestRegressor(max_depth=50, random_state=0, n_estimators=1000, bootstrap=True)<br/>model.fit(X_train, Y_train)</strong></span><span id="8a9e" class="ml mm it nk b gy nt np l nq nr">#printing feature importances<br/><strong class="nk iu">importances = model.feature_importances_<br/>indices = np.argsort(importances)<br/>features = X_train.columns</strong><br/><strong class="nk iu">plt.title('Feature Importances')<br/>plt.barh(range(len(indices)), importances[indices], color='b', align='center')<br/>plt.yticks(range(len(indices)), [features[i] for i in indices])<br/>plt.xlabel('Relative Importance')<br/>plt.show()</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/d7bae8b6434f78bdb93879f981340585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*yB6QNDyD4XCHJ_c8feFrEA.png"/></div></figure><p id="2bd0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">创建一个石灰表格实例</strong></p><p id="7232" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">将模式指定为<strong class="kx iu">回归</strong>。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="9631" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">explainer= LimeTabularExplainer(training_data=np.array(X_train),<br/>                                mode='regression', <br/>                                feature_names=list(X_train.columns),<br/>                                class_names=['Y house price of unit area'],<br/>                                random_state=12<br/>                                         )</strong></span></pre><p id="847a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">为预测生成解释</strong></p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="c01f" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">exp = explainer.explain_instance(X_test.iloc[0], model.predict, num_features=4)</strong></span><span id="da15" class="ml mm it nk b gy nt np l nq nr"><strong class="nk iu">exp.as_pyplot_figure()<br/>from matplotlib import pyplot as plt<br/>plt.tight_layout()</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/fe36db7548cbcb6b2e7f9674c0ac1b71.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*ccBUs5XApUZfELY6HEPIxw.png"/></div></figure><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="9d73" class="ml mm it nk b gy no np l nq nr"><strong class="nk iu">exp.show_in_notebook(show_table=True, show_all=False)</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi ob"><img src="../Images/9cfd496782a5e18c7bb8f8ba4dc1bdb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SKYoLpyEms-Qf8HuLlswUA.png"/></div></div></figure><h2 id="fa54" class="ml mm it bd mn mo mp dn mq mr ms dp mt le mu mv mw li mx my mz lm na nb nc nd bi translated">结论</h2><p id="1a91" class="pw-post-body-paragraph kv kw it kx b ky ne ju la lb nf jx ld le ng lg lh li nh lk ll lm ni lo lp lq im bi translated">LIME 是一种<strong class="kx iu">模型不可知的机器学习技术</strong>，用于<strong class="kx iu">以人类可理解的格式解释基于分类或回归的模型</strong>的预测。LIME 为一次观察提供<strong class="kx iu">当地的解释。它最适用于表格数据、图像和文本。</strong></p><h2 id="5979" class="ml mm it bd mn mo mp dn mq mr ms dp mt le mu mv mw li mx my mz lm na nb nc nd bi translated">参考资料:</h2><p id="b970" class="pw-post-body-paragraph kv kw it kx b ky ne ju la lb nf jx ld le ng lg lh li nh lk ll lm ni lo lp lq im bi translated">我为什么要相信你？解释任何分类器的预测</p><p id="d5dc" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><a class="ae ku" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">https://github.com/marcotcr/lime</a></p></div></div>    
</body>
</html>