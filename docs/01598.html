<html>
<head>
<title>Enhancing Optimized PySpark Queries</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">增强优化的PySpark查询</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/enhancing-optimized-pyspark-queries-1d2e9685d882?source=collection_archive---------19-----------------------#2020-02-13">https://towardsdatascience.com/enhancing-optimized-pyspark-queries-1d2e9685d882?source=collection_archive---------19-----------------------#2020-02-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><blockquote class="jq"><p id="c77e" class="jr js it bd jt ju jv jw jx jy jz ka dk translated">梦想成真的故事</p></blockquote><figure class="kc kd ke kf kg kh gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kb"><img src="../Images/89fd4fa69c385f051e69dc8b8b5a07fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xzeeestU6SxrY4pw"/></div></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">亚历山大·雷德尔在<a class="ae ks" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="7707" class="pw-post-body-paragraph kt ku it kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ka im bi lq translated"><span class="l lr ls lt bm lu lv lw lx ly di">随着</span>我们不断增加处理和存储的数据量，随着技术进步的速度从线性转变为对数，从对数转变为水平渐近，改进我们软件和分析运行时间的创新方法是必要的。</p><p id="3a09" class="pw-post-body-paragraph kt ku it kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ka im bi translated">这些必要的创新方法包括利用两个非常流行的框架:Apache Spark和Apache Arrow。这两个框架使用户能够以分布式方式处理大量数据。这两个框架也使用户能够通过使用矢量化方法更快地处理大量数据。这两个框架可以轻松促进大数据分析。然而，尽管有这两个框架和它们赋予用户的能力，仍然有改进的空间，特别是在python生态系统中。为什么我们可以自信地确定在python中利用这些框架的改进之处？让我们研究一下python的一些特性。</p><h2 id="c15c" class="lz ma it bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">Python的特性</h2><p id="f13a" class="pw-post-body-paragraph kt ku it kv b kw ms ky kz la mt lc ld le mu lg lh li mv lk ll lm mw lo lp ka im bi translated">作为一种编程语言，python实现了纯粹的灵活性。开发人员不需要在实例化或定义变量之前指定变量的类型。开发者不需要指定函数的返回类型。Python在运行时解释每个对象的类型，这允许这些限制(或护栏)被移除。python的这些特性缩短了开发时间，提高了生产率。然而，众所周知，这些相同的特性对程序运行时间有负面影响。由于python在运行时解释每个对象的类型，所以一些软件需要很长时间才能运行，尤其是那些需要过多循环的软件。即使在利用向量化操作的程序中，考虑到一些编程逻辑的复杂性，仍然会对运行时性能产生一些影响。我们能做些什么来减轻这些与性能相关的影响吗？让我们把注意力转向我选择的解决方案:Numba</p><h2 id="eef4" class="lz ma it bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">Numba来救援了</h2><p id="d6d4" class="pw-post-body-paragraph kt ku it kv b kw ms ky kz la mt lc ld le mu lg lh li mv lk ll lm mw lo lp ka im bi translated">Numba对python函数执行即时编译，与C/C++和Java编译的执行方式非常相似。仅包含标准内置函数或一组NumPy函数的Python函数可以使用Numba进行改进。这里有一个例子:</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="fd5a" class="lz ma it nc b gy ng nh l ni nj">from time import time<br/>from numba import jit<br/>import numpy as np</span><span id="cebc" class="lz ma it nc b gy nk nh l ni nj">@jit(nopython=True, fastmath=True)<br/>def numba_sum(x): <br/>    return np.sum(x)</span><span id="0740" class="lz ma it nc b gy nk nh l ni nj"># this returns the median time of execution<br/>def profileFunct(funct, arraySize, nTimes):</span><span id="d349" class="lz ma it nc b gy nk nh l ni nj">_times = [] <br/>    for _ in range(nTimes):<br/>        start = time()<br/>        funct(np.random.random((arraySize,)))<br/>        end = time()<br/>        _times.append(end - start)</span><span id="3966" class="lz ma it nc b gy nk nh l ni nj">return np.median(_times)</span><span id="bb32" class="lz ma it nc b gy nk nh l ni nj"># this is the numba time<br/>numba_times = [profileFunct(<!-- -->numba_sum, i, 1000<!-- -->) for i in range(100, 1001, 100)]</span><span id="9294" class="lz ma it nc b gy nk nh l ni nj"># this is the standard numpy timing<br/>numpy_times = [profileFunct(<!-- -->np.sum, i, 1000<!-- -->) for i in range(100, 1001, 100)]</span><span id="7977" class="lz ma it nc b gy nk nh l ni nj">speed_up_lst = list(map(lambda x: x[1] / x[0], zip(numba_times, numpy_times)))</span></pre><p id="9dbe" class="pw-post-body-paragraph kt ku it kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ka im bi translated">在上面的例子中，我们只计算一个numpy.array的和，然后相互比较性能。在这个简单的例子中，我们看到了适度的性能提升。根据您的本地机器，您可以看到10%到150%的性能提升。通常，您会看到类似的性能提升，或者如果您在函数中迭代，甚至会更多。</p><p id="6b39" class="pw-post-body-paragraph kt ku it kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ka im bi translated">如果我们可以加速一个简单的加法示例，让我们来看一个使用Numba + Apache Arrow + Apache Spark的示例。</p><h2 id="f9cf" class="lz ma it bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">三个火枪手</h2><p id="2c2c" class="pw-post-body-paragraph kt ku it kv b kw ms ky kz la mt lc ld le mu lg lh li mv lk ll lm mw lo lp ka im bi translated">下面是一个简单的例子，展示了创建实时编译函数，然后通过pandas_udf使用它们的可能性。</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="5ed7" class="lz ma it nc b gy ng nh l ni nj">from numba import jit<br/>import numpy as np<br/>import pandas as pd</span><span id="7b77" class="lz ma it nc b gy nk nh l ni nj">import pyspark.sql.functions as F<br/>from pyspark.sql import SparkSession<br/>from pyspark.sql.types import DoubleType</span><span id="dcf2" class="lz ma it nc b gy nk nh l ni nj">spark = SparkSession.builder.appName("test").getOrCreate()</span><span id="8ad1" class="lz ma it nc b gy nk nh l ni nj">spark.conf.set("spark.sql.execution.arrow.enabled", "true")</span><span id="134d" class="lz ma it nc b gy nk nh l ni nj">df = pd.DataFrame(data=np.random.random((100,)), columns=["c1"])</span><span id="dc58" class="lz ma it nc b gy nk nh l ni nj">sdf = spark.createDataFrame(df)</span><span id="68a6" class="lz ma it nc b gy nk nh l ni nj"># JIT compiled function<br/>@jit(nopython=True, fastmath=True)<br/>def numba_add_one(x):<br/>    return x + np.ones(x.shape)</span><span id="5456" class="lz ma it nc b gy nk nh l ni nj"># this is needed to use apache arrow<br/>@F.pandas_udf(DoubleType())<br/>def add_one(x):<br/>    return pd.Series(numba_add_one(x.values))</span><span id="bf3b" class="lz ma it nc b gy nk nh l ni nj">sdf = sdf.withColumn("c1_add_one", add_one(F.col("c1")))</span><span id="089b" class="lz ma it nc b gy nk nh l ni nj">sdf.toPandas()</span></pre><p id="0cc7" class="pw-post-body-paragraph kt ku it kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ka im bi translated">如前所述，这是一个简单的例子。然而，对于更复杂的应用程序，这是非常有价值的，将使它加速，即使是最基本的Apache Spark SQL查询。</p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="52cf" class="pw-post-body-paragraph kt ku it kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ka im bi translated">我希望你喜欢你的阅读！如果您对此感兴趣，那么您会对下面的文章感兴趣:</p><div class="ns nt gp gr nu nv"><a rel="noopener follow" target="_blank" href="/scaling-dag-creation-with-apache-airflow-a7b34ba486ac"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">使用Apache Airflow扩展DAG创建</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">数据科学社区中最困难的任务之一不是设计一个结构良好的模型…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">towardsdatascience.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj km nv"/></div></div></a></div></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="65f8" class="pw-post-body-paragraph kt ku it kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ka im bi translated">如果您想了解更多信息，请在LinkedIn上关注我，或者访问我的主页，在那里联系我</p><div class="ns nt gp gr nu nv"><a href="https://www.linkedin.com/in/edward-turner-polygot/" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">爱德华·特纳——数据科学家——pay locity | LinkedIn</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">爱德华·特纳(Edward Turner)是一名多语言开发人员，懂Python、R和Scala，懂Java和C/C++的语法。他…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">www.linkedin.com</p></div></div><div class="oe l"><div class="ok l og oh oi oe oj km nv"/></div></div></a></div><div class="ns nt gp gr nu nv"><a href="https://ed-turner.github.io/" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">主页</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">在这里，您将找到有关Edward Turner所做工作的信息，以及…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">ed-特纳. github.io</p></div></div></div></a></div></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="d175" class="pw-post-body-paragraph kt ku it kv b kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ka im bi translated">再次感谢！一如既往#happycoding</p></div></div>    
</body>
</html>