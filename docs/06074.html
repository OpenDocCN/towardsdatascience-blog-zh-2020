<html>
<head>
<title>Deep Dive into Competitive Learning of Self-Organizing Maps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入探究自组织地图的竞争学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-dive-into-competitive-learning-of-self-organizing-maps-b9728c57e862?source=collection_archive---------44-----------------------#2020-05-17">https://towardsdatascience.com/deep-dive-into-competitive-learning-of-self-organizing-maps-b9728c57e862?source=collection_archive---------44-----------------------#2020-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7245" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">互联网上无监督人工神经网络中自组织映射(SOMs)竞争学习背后的最佳解释！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/73b5409099c5f4982ab103320b53f1c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4pxknPbD7C7WPCGBSGeig.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://spectrum.ieee.org/image/MzI2Nzk1NA.jpeg" rel="noopener ugc nofollow" target="_blank">无监督人工神经网络</a></p></figure><p id="fe20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自组织映射是最流行的无监督学习人工神经网络之一，其中系统没有关于输入数据的特征或特性以及输出数据的类别标签的先验知识。网络根据样本输入模式之间的相似性来学习形成样本输入模式的类别/聚类。集群中的模式具有相似的特征。关于什么特征对于分类是重要的，以及有多少类，没有先验知识。网络本身会针对不同类别的输入进行调整，正如其名称所示，它们会自我组织。加权层中的节点数量对应于不同类别的数量。它基于竞争学习。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/0a878ea114ae9e36566881f0fe93818b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s_b6pyQSwzGIfaeKfo-h1w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">自组织地图网络结构</p></figure><h1 id="01e9" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">什么是竞争学习？</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mo"><img src="../Images/1e0eea6896ce71a15d20e35b9a16fa3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XHC14aQJPMYn0YPkV3-9MQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://miro.medium.com/max/3200/1*XHC14aQJPMYn0YPkV3-9MQ.jpeg" rel="noopener">竞技学习</a></p></figure><p id="3a1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在竞争学习中，与权重相关联的节点相互竞争以赢得输入模式(向量)。对于每个不同的输入模式，具有最高响应的节点被确定并被宣布为获胜者。仅训练与获胜节点相关联的权重，以使它们更类似于输入模式(向量)。所有其他节点的权重不变。赢家通吃，输家一无所有。所以它叫做赢家通吃算法(输家什么也得不到)。</p><blockquote class="mp"><p id="f1de" class="mq mr it bd ms mt mu mv mw mx my lu dk translated">节点的强度=加权和</p></blockquote><p id="bcd5" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated"><strong class="lb iu">为输出节点1 </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/488958a0b9f4f425803fff6d534c104d.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*fI09vOzOrnT1WxTJMlMWqg.png"/></div></div></figure><p id="6668" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Y1 = X1W11+ X2W21 + X3W31 +..……+ XDWD1 </strong></p><p id="50fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个节点与具有D个元素的权重向量相关联<br/> <br/>输入向量<em class="nf">X</em>—【X1，X2，X3……】。，XD]<br/>Y1的权重向量——【W11，W21，W31，…。，WD1]</p><h1 id="643a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">训练算法</h1><ul class=""><li id="1ee6" class="ng nh it lb b lc ni lf nj li nk lm nl lq nm lu nn no np nq bi translated">估计类别数(输出节点数)</li><li id="0ec9" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">随机设置权重并归一化</li><li id="640f" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">应用标准化的输入向量X</li><li id="ba21" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">计算每个节点的强度(即加权和)</li><li id="8d80" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">确定具有最高响应的节点<strong class="lb iu"> <em class="nf"> i </em> </strong></li><li id="c054" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">宣布节点<strong class="lb iu"> <em class="nf"> i </em> </strong> <em class="nf"> </em>为‘获胜者’(<strong class="lb iu"><em class="nf">I</em></strong>具有与X最相似的权重)</li><li id="50f8" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">训练节点<strong class="lb iu"> <em class="nf"> i </em> </strong>的权重，使它们更加类似于X</li></ul><h1 id="44b9" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">培训过程</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/d97f385f550eeccff9767e55211602b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7TL1mKtpD5BuCvq8Efno-g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.wisecp.com/images/wisecphomeslidebg.jpg" rel="noopener ugc nofollow" target="_blank">训练人工神经网络</a></p></figure><h2 id="9365" class="nx lx it bd ly ny nz dn mc oa ob dp mg li oc od mi lm oe of mk lq og oh mm oi bi translated">培训期间:</h2><ul class=""><li id="bd8a" class="ng nh it lb b lc ni lf nj li nk lm nl lq nm lu nn no np nq bi translated">获胜者的权重向量变得更加等于当前输入向量</li><li id="ec6e" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">换句话说，当前的输入向量被传递给胜利者</li></ul><h2 id="1526" class="nx lx it bd ly ny nz dn mc oa ob dp mg li oc od mi lm oe of mk lq og oh mm oi bi translated">培训后:</h2><ul class=""><li id="28db" class="ng nh it lb b lc ni lf nj li nk lm nl lq nm lu nn no np nq bi translated">获胜者携带它赢得的输入(获胜节点的权重向量现在保留它已被训练的输入模式)</li><li id="5b92" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">任何类似于先前的连续输入选择该节点作为获胜者</li></ul><p id="f2a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大多数神经网络专家不知道训练过程背后的理论。据说在训练期间，获胜者的权重向量变得更等于当前输入向量。但是大多数人缺乏关于使权重向量等于输入向量的理论的知识。所以在这里我想用神经竞争的基础数学来解释这个理论。</p><h1 id="6638" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">标量和向量</h1><h2 id="7999" class="nx lx it bd ly ny nz dn mc oa ob dp mg li oc od mi lm oe of mk lq og oh mm oi bi translated">数量</h2><ul class=""><li id="5035" class="ng nh it lb b lc ni lf nj li nk lm nl lq nm lu nn no np nq bi translated">标量只有大小，如长度、面积、体积、速度、质量、密度、压力、温度</li></ul><h2 id="31b6" class="nx lx it bd ly ny nz dn mc oa ob dp mg li oc od mi lm oe of mk lq og oh mm oi bi translated">矢量</h2><ul class=""><li id="174c" class="ng nh it lb b lc ni lf nj li nk lm nl lq nm lu nn no np nq bi translated">向量既有大小又有方向，例如位移、方向、速度、加速度、动量、力、重量</li></ul><h1 id="5d45" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">输入向量和权重向量的归一化</h1><ul class=""><li id="66ed" class="ng nh it lb b lc ni lf nj li nk lm nl lq nm lu nn no np nq bi translated">为了便于训练，输入向量和权重向量都被归一化为一个单位长度</li><li id="1cf6" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">标准化过程解释如下</li></ul><p id="1bb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑矢量</p><p id="4864" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">x =[X1 X2 X3……XD]</p><p id="9778" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">X的范数= </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/1c571c7b39c11062b6ca3716b8efb472.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*5kpsw-SMLU65Uy5HU2zEXg.png"/></div></figure><p id="9a26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">正常化</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/81f072d01432c5fec7d797c74724c063.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*pIb3JIl-OIWTJvLW6GKnBg.png"/></div></figure><ul class=""><li id="9f1e" class="ng nh it lb b lc ld lf lg li ol lm om lq on lu nn no np nq bi translated">矢量的范数被称为矢量的“强度”,即它的大小</li><li id="6abc" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">归一化向量的范数是1(单位向量)</li><li id="4078" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">即如果<em class="nf"> X </em>是矢量</li></ul><p id="29b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如X = [0.2，0.1，1.4，0.2]；</p><p id="4478" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">标准化的</p><p id="8fb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">X = [0.1397 0.0698 0.9778 0.1397]</p><p id="fbe8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">归一化的范数</p><p id="26ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">x = 0((0.1397)2+(0.0698)2+0.9778)2+0.1397)2)= 1</p><h1 id="652a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">正常化</h1><p id="2db5" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li oo lk ll lm op lo lp lq oq ls lt lu im bi translated">标准化向量的元素介于0和1之间。当输入特征来自不同的尺度时，例如[1.2 0.001 10.6]，归一化使它们达到统一的标准。当权重向量也被归一化时，训练过程变得简单。当所有输入模式被归一化为单位长度时，它们可以被表示为单位球体中的不同半径(不同方向)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/c73d09e2bbe2e17a5db07d5a80967ee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*gBxUYdp7iJ6xFPs0Y67Z_w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">标准化为单位长度的输入模式，单位长度由单位球体中的半径表示</p></figure><p id="9785" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了单位球体中的归一化权重向量和该现有球体中表示的输入向量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/586012afdc7fe0ce0c68bf515cb67db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0oTR3-LqE4ThIYSZuDmv6w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单位球中表示输入向量和权重向量</p></figure><p id="a73a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里每个向量的长度= 1。</p><h1 id="29a1" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">正常化前后</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/36437cf65ce811eeb9c9bc5052979ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cr2L0XhJRptxySP8gWeudg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">正常化前后</p></figure><p id="e6b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">网络对训练集进行编码所需的是权重向量与该集中存在的任何聚类对齐。每个集群至少由一个节点表示。那么当一个向量被呈现给网络时，就会有一个节点，或者一组节点，对输入做出最大的响应。</p><h1 id="5987" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">两个向量的相似性</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/7b6f62715d482b854fe8943836902aa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*kkKNJGeHo2x1bI-ddyc15Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">两个向量的相似性</p></figure><ul class=""><li id="4539" class="ng nh it lb b lc ld lf lg li ol lm om lq on lu nn no np nq bi translated">如果X1 = [x1，x2，x3，x4]且Y1 = [y1，y2，y3，y4]，则X1 = Y1</li></ul><p id="0c7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">惟一可能是</p><p id="2433" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">x1 = y1</p><p id="24b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">x2 = y2</p><p id="c441" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">x3 = y3</p><p id="469b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">x4 = y4</p><p id="feea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">X1和Y1被称为是“相同的”。</p><ul class=""><li id="32c3" class="ng nh it lb b lc ld lf lg li ol lm om lq on lu nn no np nq bi translated">考虑向量X和Y</li></ul><p id="07a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">点积X.Y = |X||Y|。Cos q</p><p id="f998" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">|X|-向量长度</p><p id="787e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">q——两个向量之间的夹角</p><p id="3b94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果|X| = 1且|Y| = 1</p><p id="e809" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">X.Y = Cos q和0 &lt;= Cos q &lt;= 1</p><p id="6cb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">If q -&gt; 0(那么Cosq -&gt; 1)</p><p id="9596" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两个单位矢量<strong class="lb iu">重合</strong></p><p id="a4c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也就是说，两个向量(X和Y)的<strong class="lb iu">等于</strong></p><p id="a270" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">即X与Y重合</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/b3ea70422dd6f139909e422ce65ff82b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BUpf3ta3dITd4IBtg82Kag.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练两个向量使其相等的过程</p></figure><p id="36f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">X.Y = |X|。| Y | Cos<em class="nf">q</em>= 1.1 . Cos<em class="nf">q<br/>当</em> q - &gt; 0矢量X =矢量Y</p><p id="a17d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我们改变两个向量之间的角度q，以使两个归一化向量相等。</p><h1 id="8a25" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">som的培训</h1><p id="5a70" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li oo lk ll lm op lo lp lq oq ls lt lu im bi translated">因此，在训练过程中，我们为给定的输入模式找到一个具有最高响应值的获胜节点。然后，使获胜者的权重向量更等于当前输入向量。根据上面的数学解释，我们在训练期间所做的是调整归一化输入向量和获胜节点的归一化权重向量之间的角度，直到这两个向量彼此一致。换句话说，直到两个矢量相等。</p><p id="c058" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练使得特定节点的权重类似于所施加的输入。换句话说，输入向量以其权重的形式被“转移”到获胜节点。当应用相似的输入向量时，相同获胜者的加权和将是最高的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/e2c9f7b8260c9e5781d6c6f09aba829e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Dc8wFBfI2zcOHqB2WgQAQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">培训过程</p></figure><p id="8f33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，对所有输入模式继续这一过程，直到输入向量与每个输入模式的获胜节点的权重向量一致。</p><h1 id="249c" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">训练方程——koho nen学习规则</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/992705629e13db627132d8be31ad9d60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S0hNyM3JkkUpRzPdWpG4Ag.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Kohonen学习规则</p></figure><p id="8e7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用Kohonen学习规则来验证这一数学解释，在koho nen学习规则中，仅对输出为1的获胜输出节点调整网络权重。否则，权重调整为零，因为输出为零。当输出为1时，通过使获胜节点的输入向量X和权重向量W彼此相等来调整权重。这是通过调整这两个向量之间的角度来实现的。当两个向量彼此一致时，网络被训练，并且不需要进一步的权重调整。对所有的输入模式继续这个过程，直到人工神经网络被完全训练。</p><h1 id="0c22" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">最终想法</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/c988a37fd2341ac5560984fb1de035f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*awztl8SnReFaSz76Zzh_Uw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://pbs.twimg.com/ext_tw_video_thumb/1106222620138180609/pu/img/H4rE8Jamf92b0OUj.jpg" rel="noopener ugc nofollow" target="_blank">最终想法</a></p></figure><p id="d69f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这篇文章能帮助你理解无监督人工神经网络中自组织映射(SOMs)竞争学习背后的实际理论。写这篇文章的目的是与世界其他地方分享我的经验丰富的讲师的重要知识。这一切都要归功于我的大学高级讲师H.L. Premaratne博士，</p><ul class=""><li id="a4af" class="ng nh it lb b lc ld lf lg li ol lm om lq on lu nn no np nq bi translated">神经网络和模式识别</li><li id="45af" class="ng nh it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">图像处理和计算机视觉</li></ul><p id="b208" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是根据他的要求写的，因为互联网上缺乏解释这一理论的文章。我希望你们都能从这方面的专家那里获得宝贵的知识。</p><p id="8d40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谢谢大家！！！…</p></div></div>    
</body>
</html>