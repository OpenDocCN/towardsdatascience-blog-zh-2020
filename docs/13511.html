<html>
<head>
<title>Supervised learning is not enough</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">监督学习是不够的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/supervised-learning-is-not-enough-8254814dfcc5?source=collection_archive---------33-----------------------#2020-09-16">https://towardsdatascience.com/supervised-learning-is-not-enough-8254814dfcc5?source=collection_archive---------33-----------------------#2020-09-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e928" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为了在人工智能方面取得进展，我们的模型需要学会应对混乱的现实世界</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d25341ae36f9ca12b03afc2e64a97af2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dRv1ZlEbRvv666lB"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">谢尔盖·阿库利奇在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="e746" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 2002 年的一次新闻发布会上，美国国防部长唐纳德·拉姆斯菲尔德解释了情报报告的基本局限性:</p><blockquote class="lv lw lx"><p id="ed31" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">“有已知的已知；有些事情我们知道我们知道。我们也知道有已知的未知；也就是说，我们知道有些事情我们不知道。但也有未知的未知——那些我们不知道自己不知道的。如果纵观我们国家和其他自由国家的历史，后一类往往是困难的。”</p></blockquote><p id="c8d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这句名言蕴含着深刻的智慧，我们可以将其转化为机器学习研究。通常，我们收集一些数据，并将这些数据分成训练集和测试集。一个成功的模型将能够预测测试集中的许多实例:这些是已知的知识。对于测试集中的其他实例，即已知的未知量，就不那么确定了。</p><p id="0fb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，在这种传统的、有监督的学习体系中，未知的未知是缺失的。根据定义，只有当 ML 模型被部署到生产中时，我们才会遇到未知的未知，在那里它会遇到真实的世界。当这种情况发生时，事情可能会出错，因为模型不知道正在发生什么，同时又对其预测过于自信。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h2 id="3ca9" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">开集识别</h2><p id="a5c5" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">因此，监督学习不一定足以应对现实世界。现实世界简直太乱了，它往往会向我们扔新的东西。</p><p id="48c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一个聪明的方法来测试这个想法:在 MNIST 数据上训练一个机器学习模型，但在训练期间只给它显示数字 0，1，2，3，4，5。然后，在测试过程中，向它显示整个数字范围。会有怎样的表现？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/3a91ae7361c2607232a11c19d09627aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*76R7GxptkHnMqTnxx9BBxg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">当在训练期间只看到类的子样本时，根据 MNIST 数据训练的模型的退化。[1]</p></figure><p id="6b00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果很糟糕(见上面的蓝色曲线)。随着我们在训练过程中遗漏越来越多的类，准确度从接近 1 下降到大约 0.6。研究人员 Lalit Jain 及其合作者在 2014 年展示了这一结果。他们还提出了一种新的 ML 算法，以更好的方式推广到“未知的未知”(上面的红色曲线)——当然，警告是，这些未知的未知实际上是研究人员事先知道的。</p><p id="9f3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ly">开集识别</em>是训练 ML 模型的挑战，这些模型不仅在已知数据上表现良好，还能识别是否有全新的东西扔给它们——并相应地调整预测的不确定性。解决这个问题是在现实世界中部署模型的重要一步。</p><p id="72ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果模型能在不确定的时候问我们就更好了。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h2 id="0e8b" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">主动学习</h2><p id="d781" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">主动学习的想法简单而有力。假设我们有一个大的未标记的数据池，和一个小的已标记的数据样本。然后，在已标记的数据上训练一个 ML 模型，并让该模型对未标记的数据实例进行排序，例如通过它对标签的不确定程度。选择最不确定的实例，由人类标记它们，将它们添加到标记的训练集中，并重新训练。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/aa519030d23e5bf7ee80959a48420bd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TE2cPOVtIJJMDpInAE-93Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">主动学习循环。[2]</p></figure><p id="ea54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果未标记池是有限的，只需重复循环，直到标记了足够多的数据。然而，在现实世界中，未标记的池可能是无限的:在现代生产系统中，每秒钟都会产生新数据。</p><p id="5fb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是所有事情是如何组合在一起的:在现实世界中，我们需要擅长开集识别的模型，擅长识别一个新样本是否是以前从未经历过的，一个未知的未知。我们需要主动学习循环，以便模型可以在人类专家的帮助下快速有效地填补知识空白。这两个领域的进展对于现实世界的 ML 应用至关重要。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h2 id="ca8a" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">最后的想法</h2><p id="d366" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">我在之前的<a class="ae ky" rel="noopener" target="_blank" href="/the-origin-of-intelligent-behavior-3d3f2f659dc2">帖子</a>中提到了伊莱恩·赫尔茨贝格的惨死。2018 年 3 月 18 日晚上，赫尔茨贝格在亚利桑那州坦佩市的一条街道上骑车时，被一辆自动驾驶汽车撞了。尽管汽车模型已经在大量驾驶数据的基础上进行训练，但这些数据错过了足够多的行人骑自行车过马路的例子。对这个模型来说，赫尔茨贝格是一个未知的未知数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/27b0a49189619e3999fbd19a4b1676c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CRGAQ97nYceJJGVTa_gGPg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像数据中的长尾问题示例。[3]</p></figure><p id="4ea9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不管我们用多少数据来训练我们的模型，模型总是会遗漏一些东西。这就是著名的<em class="ly">长尾问题</em>。然而我们人类是不同的:我们不仅仅是学习模式，我们有一种“为什么”我们看到的事物是这样的感觉。这种从第一原理进行推理的形式使我们能够推广到未知的长尾，这是监督 ML 模型中所缺少的技能。</p><p id="1ffb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实际上，一个模型永远不会真正“完成”学习。在现实世界的场景中，学习过程必须无限期地继续下去。监督学习是不够的。此外，模型需要善于识别未知的未知，更好的是，在最需要的时候主动要求我们澄清。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h2 id="5a17" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">参考资料和进一步阅读</h2><p id="f676" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">[ <a class="ae ky" href="https://www.wjscheirer.com/papers/wjs_eccv2014_openset.pdf" rel="noopener ugc nofollow" target="_blank"> 1 </a> ] Jain 等，利用包含概率的多类开集识别<br/> [ <a class="ae ky" href="http://burrsettles.com/pub/settles.activelearning.pdf" rel="noopener ugc nofollow" target="_blank"> 2 </a>落定，主动学习文献综述<br/> [ <a class="ae ky" href="https://arxiv.org/pdf/1904.05160.pdf" rel="noopener ugc nofollow" target="_blank"> 3 </a>刘等，开放世界中的大规模长尾识别</p><div class="nk nl gp gr nm nn"><a rel="noopener follow" target="_blank" href="/the-origin-of-intelligent-behavior-3d3f2f659dc2"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">智能行为的起源</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">为什么真正的人工智能需要的不仅仅是模式识别</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob ks nn"/></div></div></a></div></div></div>    
</body>
</html>