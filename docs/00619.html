<html>
<head>
<title>You should try the new TensorFlow’s TextVectorization layer.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你应该试试新的TensorFlow的TextVectorization图层。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/you-should-try-the-new-tensorflows-textvectorization-layer-a80b3c6b00ee?source=collection_archive---------5-----------------------#2020-01-18">https://towardsdatascience.com/you-should-try-the-new-tensorflows-textvectorization-layer-a80b3c6b00ee?source=collection_archive---------5-----------------------#2020-01-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7b85" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">它是如何工作的，以及为什么你应该在你的ML管道中实现它。</h2></div><p id="935c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">本文讨论了一个相当高级的主题，因此如果您仍然是TensorFlow/NLP初学者，您可能想要快速浏览一下</em> <a class="ae lf" href="https://www.tensorflow.org/tutorials/quickstart/beginner" rel="noopener ugc nofollow" target="_blank"> <em class="le"> TensorFlow 2快速入门教程</em> </a> <em class="le">或稍微复习一下</em><a class="ae lf" href="https://www.tensorflow.org/tutorials/text/word_embeddings" rel="noopener ugc nofollow" target="_blank"><em class="le">wordbembeddings</em></a><em class="le">。</em></p><p id="303e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着<a class="ae lf" href="https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0" rel="noopener ugc nofollow" target="_blank">最近发布的</a> <code class="fe lg lh li lj b"><a class="ae lf" href="https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">Tensorflow 2.1</strong></a></code>，一个新的<code class="fe lg lh li lj b"><a class="ae lf" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization?version=stable" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">TextVectorization</strong></a></code> <strong class="kk iu"> </strong>层被加入到<code class="fe lg lh li lj b">tf.keras.layers</code>舰队中。</p><blockquote class="lk ll lm"><p id="4e45" class="ki kj le kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated">该层具有用于管理Keras模型中的文本的基本选项。它将一批字符串(一个样本=一个字符串)转换为记号索引列表(一个样本=整数记号索引的1D张量)或密集表示(一个样本=表示关于样本记号的数据的浮点值的1D张量)。<strong class="kk iu">T24】</strong></p></blockquote><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/fa6fe45678eb24ce170c8942391a2746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*KEtm3hv1zgWTucKFb73oNQ.gif"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated"><em class="mg">文本矢量化图层数据流概述</em>。</p></figure><blockquote class="lk ll lm"><p id="bc7d" class="ki kj le kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated">每个样本的处理包含以下步骤:</p><p id="aa2d" class="ki kj le kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated">1.<strong class="kk iu">标准化</strong>每个样本(一般是小写+标点剥离)。</p><p id="e8fc" class="ki kj le kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated">2.<strong class="kk iu">将每个样本分割成子串(通常是单词)。</strong></p><p id="908f" class="ki kj le kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated">3.<strong class="kk iu">将</strong>子字符串重组为令牌(通常是ngrams)。</p><p id="fb2c" class="ki kj le kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated">4.<strong class="kk iu">索引</strong>令牌(将唯一的int值与每个令牌相关联)。</p><p id="a0b7" class="ki kj le kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated">5.<strong class="kk iu">使用该索引将每个样本转换为整数向量或密集浮点向量。<strong class="kk iu"> </strong></strong></p></blockquote></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="40ba" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">1️⃣标准化。</h1><p id="a8e5" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">在第一步中，数据将经过<em class="le">标准化</em>过程<em class="le">。</em>在这一阶段，每个文本样本在进一步处理之前被清理和转换。</p><p id="6db0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以用<code class="fe lg lh li lj b">TextVectorization</code>层的<code class="fe lg lh li lj b"><strong class="kk iu">standardize</strong></code>参数控制标准化步骤。该参数的可能值为:</p><ul class=""><li id="03e8" class="nl nm it kk b kl km ko kp kr nn kv no kz np ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">None</code>:这将应用<strong class="kk iu">完全没有标准化</strong>。</li><li id="6df1" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">lower_and_strip_punctuation</code> ( <strong class="kk iu">默认</strong>):由于降低和删除标点符号是一种非常常见的技术，你可以传递这个字符串，<code class="fe lg lh li lj b">TextVectorization</code>层将应用这个转换作为它的标准化步骤。</li><li id="826c" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">Callable</code>:如果你需要更多关于标准化的控制，你可以通过你自己的<code class="fe lg lh li lj b">Callable</code>。</li></ul><p id="b73f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您已经选择将自己的<code class="fe lg lh li lj b">Callable</code>传递给<code class="fe lg lh li lj b">standardize</code>参数，那么您应该注意以下几点:</p><ol class=""><li id="bf70" class="nl nm it kk b kl km ko kp kr nn kv no kz np ld nz nr ns nt bi translated">任何<code class="fe lg lh li lj b">Callable</code>都可以传递给这个层，但是如果你想序列化这个对象，你应该只传递注册了keras serializable的函数(更多细节见<a class="ae lf" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/register_keras_serializable" rel="noopener ugc nofollow" target="_blank">注册keras serializable </a>)。</li><li id="1156" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nz nr ns nt bi translated">当对<code class="fe lg lh li lj b">standardize</code>使用自定义可调用函数时，可调用函数接收的数据将完全传递给该层。<code class="fe lg lh li lj b">Callable</code>应该返回与输入相同形状的张量。</li></ol><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oa"><img src="../Images/545d1b4d8a916b6dee34c73dbf20857c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VR0uISc-HsiuwQeV0IJw3A.png"/></div></div></figure></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="3d7b" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">2️⃣分裂了。</h1><p id="d058" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">在第二步中，每个文本样本将被分割成子串标记(通常是<em class="le">单词</em>)。</p><p id="8997" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同样，您可以使用<code class="fe lg lh li lj b"><strong class="kk iu">split</strong></code>参数控制<em class="le">分割</em>行为，该参数可用于<code class="fe lg lh li lj b">TextTokenization</code>层。可能的值有:</p><ul class=""><li id="b60e" class="nl nm it kk b kl km ko kp kr nn kv no kz np ld nq nr ns nt bi translated"><code class="fe lg lh li lj b"><a class="ae lf" href="https://github.com/tensorflow/tensorflow/issues/36071" rel="noopener ugc nofollow" target="_blank">None</a></code>:这应该适用于<strong class="kk iu">根本没有分裂</strong>。</li><li id="fbe2" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">whitespace</code> ( <strong class="kk iu"> default </strong>):对ASCII空格进行分割是很常见的，这就是为什么这是该参数的默认值。</li><li id="2082" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">Callable</code>:如果你喜欢更奇特的分割技术，你可以在这里自由传递你自己的可调用函数，就像<code class="fe lg lh li lj b">standardize</code>参数一样。</li></ul><p id="ae4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和以前一样，作为<code class="fe lg lh li lj b">Callable</code>通过考试也有一些限制:</p><ol class=""><li id="da06" class="nl nm it kk b kl km ko kp kr nn kv no kz np ld nz nr ns nt bi translated">任何<code class="fe lg lh li lj b">Callable</code>都可以传递给这个层，但是如果你想序列化这个对象，你应该只传递注册了keras serializable的函数(更多细节见<a class="ae lf" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/register_keras_serializable" rel="noopener ugc nofollow" target="_blank">注册keras serializable </a>)。</li><li id="ada0" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nz nr ns nt bi translated">当对<code class="fe lg lh li lj b">standardize</code>使用自定义可调用函数时，可调用函数接收的数据将完全传递给该层。<code class="fe lg lh li lj b">Callable</code>应该返回一个与输入相同形状的张量。</li><li id="2f71" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nz nr ns nt bi translated">可调用函数接收的数据将挤出第1个<em class="le">维。这意味着你的<code class="fe lg lh li lj b">Callable</code>将看到<code class="fe lg lh li lj b">["string to split", "another string to split"]</code>，而不是<code class="fe lg lh li lj b">[["string to split"], ["another string to split"]]</code>。<code class="fe lg lh li lj b">Callable</code>应该返回一个包含分割记号的第一维张量，所以在这个例子中我们应该返回类似于<code class="fe lg lh li lj b">[["string", "to", "split"], ["another", "string", "to", "split"]</code>的东西。这使得<code class="fe lg lh li lj b">Callable</code>与<code class="fe lg lh li lj b"><a class="ae lf" href="https://www.tensorflow.org/api_docs/python/tf/strings/split" rel="noopener ugc nofollow" target="_blank">tf.strings.split()</a></code>天生兼容。</em></li></ol><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ob"><img src="../Images/cb1366e84f0e9ad50e097fc018fff8de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NGUP-L5dZLH_oYWwtxTmsg.png"/></div></div></figure></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="bbd9" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">3️⃣重组。</h1><p id="658b" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">在将我们的文本分割成记号后，我们可以决定如何在创建词汇索引前将它们重新组合(T21)。这基本上意味着我们可以决定是保留我们目前得到的所有令牌，还是使用它们的组合。</p><p id="3baa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们用<code class="fe lg lh li lj b"><strong class="kk iu">ngrams</strong></code> <strong class="kk iu"> </strong>参数控制这一步。可能的值有:</p><ul class=""><li id="f414" class="nl nm it kk b kl km ko kp kr nn kv no kz np ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">None</code>:在这种情况下，不会创建任何<em class="le"> ngrams </em>，只会使用您现在拥有的令牌。</li><li id="2f5f" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated">一个<code class="fe lg lh li lj b">int</code>:传递一个整数将创建<em class="le"> ngrams </em>直到该整数。</li><li id="2a4a" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated">一个<code class="fe lg lh li lj b">(int, int)</code>元组:传递一个整数元组将为元组中的指定值创建<em class="le"> ngrams </em></li></ul><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oc"><img src="../Images/b4c4f1680c8bef1ed4fa359a41fcc7b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a6YBAVUawUiQI5ksQ4vCXw.png"/></div></div></figure></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="383d" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">4️⃣指数。</h1><p id="f195" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">这一步允许您根据上一步获得的重组标记创建一个词汇表。因此，您可以指定一个<code class="fe lg lh li lj b">max_tokens</code>整数参数来控制该层词汇的最大大小，或者简单地保留默认的<strong class="kk iu"/><code class="fe lg lh li lj b"><strong class="kk iu">None</strong></code><strong class="kk iu"/>值，不为词汇设置上限。</p><p id="384a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了实际构建这个索引，您需要调用层的<code class="fe lg lh li lj b"><strong class="kk iu">adapt</strong></code> <strong class="kk iu"> </strong>方法，这将使预处理层的状态适合数据集。这也覆盖了默认的<code class="fe lg lh li lj b">adapt</code>方法，在将输入传递给组合器之前，对输入应用相关的预处理。</p><p id="e50f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您想设置自己的词汇(和<em class="le">文档频率，可选</em>，您可以使用<code class="fe lg lh li lj b">set_vocabulary</code>方法。</p><blockquote class="lk ll lm"><p id="134d" class="ki kj le kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated">该方法直接设置该层的词汇和测向数据，而不是通过“适应”来分析数据集。只要vocab(以及可选的文档频率)信息已知，就应该使用它。如果词汇数据已经存在于层中，如果“append”设置为False，此方法将替换它，或者追加到它(如果“append”设置为True)。<strong class="kk iu"> </strong></p></blockquote><p id="13b6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe lg lh li lj b"><strong class="kk iu">set_vocabulary</strong></code>方法采用以下参数:</p><ul class=""><li id="5b59" class="nl nm it kk b kl km ko kp kr nn kv no kz np ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">vocab</code>:字符串标记数组。</li><li id="2635" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">df_data</code>:文档频率数组。仅当层<code class="fe lg lh li lj b">output_mode</code>为<code class="fe lg lh li lj b">tf-idf</code>时才需要。</li><li id="5d48" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">oov_df_value</code>:词汇外令牌的文档频率。仅当<code class="fe lg lh li lj b">output_mode</code>为<code class="fe lg lh li lj b">tf-idf</code>时才有必要。在<code class="fe lg lh li lj b">tf-idf</code>模式下追加附加数据时，OOV数据是可选的；如果提供了OOV值，它将覆盖现有的OOV值。</li><li id="cce7" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">append</code>:是否覆盖或追加任何现有词汇数据。</li></ul><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi od"><img src="../Images/71283a28a1a708161931a653e31f6c2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DIVOp4OpeHu_OtjmtrQ2fQ.png"/></div></div></figure></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="8a27" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">5️⃣变换。</h1><p id="9041" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">最后一步，预处理后的数据被转换并以期望的方式提供。有四种不同的选项可供选择:</p><ul class=""><li id="1ab9" class="nl nm it kk b kl km ko kp kr nn kv no kz np ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">int</code>:输出整数索引，每个拆分字符串标记一个整数索引。</li><li id="3773" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">binary</code>:每批输出一个整数数组，大小为<code class="fe lg lh li lj b">vocab_size</code>或<code class="fe lg lh li lj b">max_tokens</code>，在所有元素中包含<code class="fe lg lh li lj b">1</code> <em class="le"> s </em>，其中映射到该索引的标记在批处理项中至少存在一次。</li><li id="f7e5" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">count</code>:与<code class="fe lg lh li lj b">binary</code>相同，但是int数组包含该索引处的令牌在批处理项中出现的次数计数。</li><li id="0999" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">tf-idf</code>:与<code class="fe lg lh li lj b">binary</code>相同，但是应用TF-IDF算法来寻找每个令牌槽中的值。</li></ul><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/c0ad3a2b61c01e0a7cc919b25927bc4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*zULd62H8aKdlywuczM9Oyg.jpeg"/></div></figure><p id="1adb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，还有<em class="le">两个</em>其他参数会影响图层的输出形状:</p><ul class=""><li id="6b4c" class="nl nm it kk b kl km ko kp kr nn kv no kz np ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">output_sequence_length</code>:仅在<code class="fe lg lh li lj b">int</code>输出模式下有效。如果设置，输出将使其时间维度被填充或截断为精确的<code class="fe lg lh li lj b">output_sequence_length</code>值，从而产生形状为<code class="fe lg lh li lj b">[batch_size, output_sequence_length]</code>的张量，而不管分裂步骤产生了多少记号。<strong class="kk iu">默认</strong>到<code class="fe lg lh li lj b">None</code>。</li><li id="4c9f" class="nl nm it kk b kl nu ko nv kr nw kv nx kz ny ld nq nr ns nt bi translated"><code class="fe lg lh li lj b">pad_to_max_tokens</code>:仅在<code class="fe lg lh li lj b">binary</code>、<code class="fe lg lh li lj b">count</code>和<code class="fe lg lh li lj b">tf-idf</code>模式下有效。如果为<code class="fe lg lh li lj b">True</code>，即使词汇表中唯一记号的数量小于max_tokens，输出也会将其特征轴填充到<code class="fe lg lh li lj b">max_tokens</code>，从而产生一个形状为<code class="fe lg lh li lj b">[batch_size, max_tokens]</code>的张量，与词汇表大小无关。<strong class="kk iu">默认为</strong>至<code class="fe lg lh li lj b">True</code>。</li></ul><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi of"><img src="../Images/810f8e872f223121e61028615f3f3a2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xXei5AI0JnXxedlK_R0WdQ.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">设置<strong class="bd og">输出序列长度</strong>。</p></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi of"><img src="../Images/964a6200bfe27d26f8f64468c76b9634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMP_HRecv6lZ18y1hz2oYw.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">设置<strong class="bd og"> pad_to_max_tokens。</strong></p></figure><div class="lr ls lt lu gt ab cb"><figure class="oh lv oi oj ok ol om paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/1af389b789aff6cadc46773aa11e0ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*IP7s6al63tliQoRgPrVKIA.png"/></div></figure><figure class="oh lv oi oj ok ol om paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/59b6c1630b6729e6476cb5da771ee0e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*dx6Q8_aD2tMwC2_ZUibahA.png"/></div></figure></div><div class="ab cb"><figure class="oh lv on oj ok ol om paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/bf335b2c01b377cb53b9d8ec6918e8a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*bAxgprzoZmrlNk562AX9dQ.png"/></div></figure><figure class="oh lv oo oj ok ol om paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/dcbcb3662ef81d32638920a00af5afc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*qbH-pXfDFDTIuSqQf-rJ9A.png"/></div><p class="mc md gj gh gi me mf bd b be z dk op di oq or translated">不同<strong class="bd og">输出模式</strong>的总结。</p></figure></div></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="eb85" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">&lt;&lt; Impressive, how do I use it? 🤔 &gt;&gt;</h1><p id="4be8" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">就像任何其他的<code class="fe lg lh li lj b">tf.keras</code>层一样，它的使用非常简单。你所需要做的就是实例化这个层，把它放到你的数据中，然后你就可以把它放到你的模型层堆栈中了。</p><p id="2968" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还是那句话，你真的应该看看<a class="ae lf" href="https://colab.research.google.com/drive/1RvCnR7h0_l4Ekn5vINWToI9TNJdpUZB3" rel="noopener ugc nofollow" target="_blank">官方TensorFlow的team Colab例子</a>，但简单来说:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi os"><img src="../Images/90a2596a72759ebc959d33bd3d121e2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qWGjOC9jYIl3-dFGQruefw.png"/></div></div></figure></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="8d44" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated"><strong class="ak"> &lt; &lt;爽！我应该在生产中使用这个吗？</strong>🙄<strong class="ak">&gt;&gt;T36】</strong></h1><p id="6477" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">到目前为止，在基于文本的机器学习模型上工作时，您可能必须决定一个输入预处理策略:这基本上意味着您必须独自完成上面为<code class="fe lg lh li lj b">TextTokenization</code>层定义的所有步骤，根据预处理的数据拟合您的模型，保存它，然后在推理时以某种方式再现预处理步骤，然后将它们传递给<a class="ae lf" href="https://github.com/tensorflow/serving" rel="noopener ugc nofollow" target="_blank">服务模型</a>并获得一些预测。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/17868a4c352ed966c9b792c5757c9e73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*ycgclGqOKsIqNLVnPbFUIw.jpeg"/></div></figure><p id="e7eb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这可以通过一系列不同的方式来完成，从完全在TensorFlow“外部”实现整个预处理管道，到使用强大的<code class="fe lg lh li lj b">tf.data</code> api。当然，也有方法将您自己的操作包含到导出的图形中，TensorFlow足够灵活，可以让您实现自己的预处理层，但是如果您想要摇滚，这是一条很长的路要走。</p><p id="f3e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这一层给你的是将任何文本预处理逻辑<strong class="kk iu">包含到</strong>你的模型中的机会。</p><blockquote class="lk ll lm"><p id="2baa" class="ki kj le kk b kl km ju kn ko kp jx kq ln ks kt ku lo kw kx ky lp la lb lc ld im bi translated"><a class="ae lf" href="https://www.tensorflow.org/tfx/guide#developing_with_tfx" rel="noopener ugc nofollow" target="_blank">通过这样做，您将一致地使用相同的预处理和分析代码，并避免用于训练的数据和提供给生产中的训练模型的数据之间的差异，并从编写一次代码中受益。</a> <strong class="kk iu"> </strong></p></blockquote><p id="a97a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是这里是我们梦想开始和结束的地方。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oc"><img src="../Images/b026c141d368ff35c581d1219ca87ed3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9nPa6XisI5B2K2LP4Lzxdg.png"/></div></div></figure><p id="c67e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">遗憾的是，没有实现导出包含该层的模型，<strong class="kk iu"> <em class="le">还没有</em> </strong>。</p><p id="667b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这意味着在生产中使用这一层不是一个好主意，因为你不能导出你的模型，也不能用像<a class="ae lf" href="https://github.com/tensorflow/serving" rel="noopener ugc nofollow" target="_blank"> Tensorflow Serving </a>这样的解决方案来服务它。然而，这一层仍然被标记为<em class="le">实验性的</em>，并且<a class="ae lf" href="https://github.com/tensorflow/text/issues/210" rel="noopener ugc nofollow" target="_blank">随着未来TensorFlow版本的发布，我们很快将有能力导出这一层</a>。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><p id="ceab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">⌛ <strong class="kk iu"> <em class="le">来自未来的更新:【</em></strong><a class="ae lf" href="https://blog.tensorflow.org/2020/07/whats-new-in-tensorflow-2-3.html" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu"><em class="le">tensor flow博客2020–07–27</em></strong></a><strong class="kk iu"><em class="le">:</em></strong>⌛</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="ou ov l"/></div></figure><blockquote class="ow"><p id="f7ee" class="ox oy it bd oz pa pb pc pd pe pf ld dk translated">TensorFlow 2.3增加了对新的<a class="ae lf" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing?version=nightly" rel="noopener ugc nofollow" target="_blank"> Keras预处理层API </a>的<a class="ae lf" href="https://github.com/tensorflow/community/blob/master/governance/api-reviews.md#experimental-apis" rel="noopener ugc nofollow" target="_blank">实验性</a>支持。这些层允许您将预处理逻辑打包到模型中以便于部署——因此您可以发布一个模型，该模型将原始字符串、图像或表中的行作为输入。</p></blockquote><figure class="pg ph pi pj pk lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi os"><img src="../Images/f8b9fa7555b19886a30103b3ca705a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_DYpGA89WKRAzPNHhTNQJg.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">更新2020–07–27:导出文本矢量化图层。</p></figure></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="8f3e" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">&lt;&lt; Alright, I’m interested anyway, where should I go next? 🤓 &gt;&gt;</h1><p id="3b5f" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated"><strong class="kk iu">你在这篇文章中发现的很多</strong>都摘自官方<a class="ae lf" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization" rel="noopener ugc nofollow" target="_blank"> TensorFlow文档</a>，里面真的是应有尽有，挖吧。</p><p id="1776" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有关一些一般信息，请参见<a class="ae lf" href="https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0" rel="noopener ugc nofollow" target="_blank">官方TensorFlow 2.1版本</a>，其中您将找到一个笔记本，它将指导您使用<code class="fe lg lh li lj b">TextVectorizationLayer</code>完成一个<a class="ae lf" href="https://colab.research.google.com/drive/1RvCnR7h0_l4Ekn5vINWToI9TNJdpUZB3" rel="noopener ugc nofollow" target="_blank">端到端文本分类示例</a>。</p><p id="7c79" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">想要更多吗？看看这个我作为游乐场创造的Google Colab笔记本 ！</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="pl ov l"/></div></figure><h1 id="d8df" class="mo mp it bd mq mr pm mt mu mv pn mx my jz po ka na kc pp kd nc kf pq kg ne nf bi translated">参考文献。</h1><p id="c6d2" class="pw-post-body-paragraph ki kj it kk b kl ng ju kn ko nh jx kq kr ni kt ku kv nj kx ky kz nk lb lc ld im bi translated">[ <strong class="kk iu"> 1 </strong> ] <a class="ae lf" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization" rel="noopener ugc nofollow" target="_blank">文本矢量化</a>，<em class="le"> 2020.01.20 </em>，<a class="ae lf" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/keras/layers/experimental/预处理/文本矢量化</a>。</p><p id="d971" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与TFX一起发展的<strong class="kk iu">2</strong><a class="ae lf" href="https://www.tensorflow.org/tfx/guide#developing_with_tfx" rel="noopener ugc nofollow" target="_blank"/>，<em class="le"> 2020.01.20 </em>，<a class="ae lf" href="https://www.tensorflow.org/tfx/guide#developing_with_tfx" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tfx/guide#developing_with_tfx</a>。</p></div></div>    
</body>
</html>