<html>
<head>
<title>Balancing the Regularization Effect of Data Augmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">平衡数据扩充的正则化效果</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/balancing-the-regularization-effect-of-data-augmentation-eb551be48374?source=collection_archive---------17-----------------------#2020-07-21">https://towardsdatascience.com/balancing-the-regularization-effect-of-data-augmentation-eb551be48374?source=collection_archive---------17-----------------------#2020-07-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6e34" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用卫星图像上的图像分割应用程序来识别水体，通过数据扩充来平衡过拟合和欠拟合的需要。</h2></div><h2 id="5a43" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据扩充的效果</h2><p id="84aa" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">在训练神经网络时，数据扩充是最常用的预处理技术之一。<strong class="ld ir">“增强”</strong>这个词的字面意思是<em class="lu">“在尺寸或数量上变得更大的行为或过程”，</em>概括了这种技术的结果。但是另一个重要的影响是<em class="lu">它增加或扩大了数据的多样性。</em>多样性的增加意味着，在每个训练阶段，模型都会遇到不同版本的原始数据。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi lv"><img src="../Images/701766c30012f755db9526b437f2b256.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*geA3ZUMBUa67mBBhGUknmw.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">按作者</p></figure><p id="1ae7" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated"><strong class="ld ir"> <em class="lu">为什么我们需要数据的这种“增加的多样性”?</em> </strong>答案就在机器学习的核心宗旨——<strong class="ld ir">偏差-方差权衡</strong>。更复杂的模型，如深度神经网络，具有较低的偏差，但存在较高的方差。这意味着，这些模型过度拟合训练数据，并会在测试数据或数据上表现不佳，这是他们以前从未见过的。这将导致<em class="lu">更高的</em> <em class="lu">预测误差</em>。因此，通过使模型在<strong class="ld ir"> <em class="lu">一般化</em> </strong>时变得更好，来自数据扩充的增加的多样性减少了模型的方差。</p><p id="3ff1" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">对于图像，一些常见的数据增强方法是截取部分、放大/缩小、沿轴旋转、垂直/水平翻转、调整亮度和绝对强度。音频数据的数据扩充包括添加噪声、改变速度和音调。</p><p id="f8b1" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">虽然数据增强可以防止模型过度拟合，但一些<strong class="ld ir"> <em class="lu">增强组合实际上会导致</em> </strong>拟合不足。这降低了训练速度，导致可用处理时间、GPU 配额等资源的巨大压力。此外，该模型无法学习足够多的信息来给出准确的预测，这再次导致高预测误差。在这篇博文中，我们以卫星图像的语义分割为例，来看看数据增强的不同组合对训练的影响。</p><h2 id="b5a2" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">关于数据集</h2><p id="699c" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">这个<a class="ae mq" href="https://www.kaggle.com/franciscoescobar/satellite-images-of-water-bodies" rel="noopener ugc nofollow" target="_blank"> Kaggle 数据集</a>给出了来自哨兵 2 号的<strong class="ld ir">卫星图像及其相应的分割水体的遮罩</strong>。使用归一化差异水指数或 NDWI 计算掩膜。在数据集中总共 2841 幅图像中，分别为训练集提取了 2560 幅，为验证集提取了 256 幅，为测试集提取了 25 幅。整个分析和建模是在 GPU 支持下在 Google Colab 上完成的。</p><h2 id="9f39" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">U 网的结构</h2><p id="722c" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">简而言之，U-NET 是一个自动编码器，具有从编码器中的每个卷积块到解码器中其对应部分的剩余或跳过连接。这导致了对称的“U”形结构。<a class="ae mq" rel="noopener" target="_blank" href="/unet-line-by-line-explanation-9b191c76baf5">这篇文章</a>从原始论文开始，对 U-NET 的结构给出了全面的逐行解释。</p><p id="263c" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">我们使用稍微修改的 U-NET 版本，如下所示。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mr"><img src="../Images/16987cdcfdb4301d0d6aa9a306da9894.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xatr7T6jWtm_gmsctH6liQ.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">所使用的 UNET 块的快照(由作者提供)</p></figure><h2 id="c626" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">看看数据扩充的不同案例</h2><p id="3387" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">在 Keras ImageDataGenerator 的帮助下，我们探讨了 5 种不同的数据增强情况。我们想看看增强如何导致训练期间<em class="lu">过度适应或适应不足</em>。因此，为了对 5 个案例进行比较，使用了培训&amp;验证期间的<em class="lu">准确度</em>和<em class="lu">损失</em>；其中二进制交叉熵作为损失函数。</p><p id="2b3d" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated"><strong class="ld ir">在处理语义分割时，需要记住的重要一点是将<em class="lu">相同的</em>增强应用于图像及其相应的遮罩！</strong></p><p id="1905" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">在所有 5 种情况下，图像和蒙版的像素值都以 1/255 的因子重新缩放。验证和测试集中的所有图像及其遮罩也被重新缩放。</p><p id="afc8" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated"><strong class="ld ir">案例 1: </strong>这是<em class="lu">基础案例</em>。只有图像及其遮罩的像素值被重新缩放。没有应用任何增强。这个案例产生了一个方差最小的训练集。</p><p id="cb02" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated"><strong class="ld ir">案例二:</strong>除了重新缩放，还随机垂直或水平翻转图像及其蒙版。</p><p id="77de" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated"><strong class="ld ir">情况 3: </strong>对于这种情况，<strong class="ld ir"> </strong>重新缩放、随机垂直或水平翻转以及[-20，20]度之间的随机旋转被应用于图像及其相应的遮罩。</p><p id="1439" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated"><strong class="ld ir">情况 4: </strong>图像和它们对应的蒙版沿着宽度和高度以因子 0.3 随机移动。</p><p id="ba35" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated"><strong class="ld ir">情况 5: </strong>使用因子 20 将透明变换随机应用于图像及其相应的遮罩。它们也在范围[0.2，0.5]之间随机放大。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ms"><img src="../Images/8d0630d98becef514c8f30423c81f969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ApZlJyoX39DIwOyUZwanA.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">同一图像及其遮罩上的不同类型的增强(由作者提供)</p></figure><h2 id="c96c" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结果的比较</h2><p id="95c3" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">在所有 5 个案例中，模型被训练了 250 个时期，批次大小为 16。Adam 优化器的学习率为 0.00001，beta 1 为 0.99，beta 2 为 0.99。在下面的图表中，我们可以看到，每个数据扩充案例都为相同的模型提供了不同的性能，这些模型在相同的优化器初始状态下接受了相同数量的时期训练。</p><div class="lw lx ly lz gt ab cb"><figure class="mt ma mu mv mw mx my paragraph-image"><img src="../Images/dfeec531189472c8ea57f196bb51d5f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*unufCdiF4gwuGjDET-K_Ug.png"/></figure><figure class="mt ma mz mv mw mx my paragraph-image"><img src="../Images/2527baaa32a3093318fab769a1f347ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*AqZAZ65eQwT2xNZqL220Kw.png"/><p class="mh mi gj gh gi mj mk bd b be z dk na di nb nc translated">训练历史的情节(作者)</p></figure></div><p id="0b3d" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">基准案例在训练准确性和损失方面表现最佳。然而，这可能意味着过度拟合。另一方面，第三、第四和第五种情况的表现更差。这三种情况的训练准确度没有超过 80%,训练损失没有低于 0.1。这可能意味着不合身。在第二种情况下，数据增强由随机翻转图像及其相应的遮罩组成，这似乎显示了平衡的性能。尽管它的表现比基本情况稍差，但它比最后三种情况具有更高的准确性和更低的损失。</p><div class="lw lx ly lz gt ab cb"><figure class="mt ma nd mv mw mx my paragraph-image"><img src="../Images/9d9ca2de8fcebf6317bf72cda3d5ae5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*XLhXwDGgtHCx3vGQKH8bHw.png"/></figure><figure class="mt ma ne mv mw mx my paragraph-image"><img src="../Images/c56e0ac398fe4b7f30889bbd86a900a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*CqCiCv5v8LjoCjaNFJ9iaw.png"/><p class="mh mi gj gh gi mj mk bd b be z dk nf di ng nc translated">验证历史图(按作者)</p></figure></div><p id="bd9b" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">验证的准确性和损失，显示了类似的趋势。最后一种情况在这两个指标上表现最差。仔细观察我们会发现，案例 3 和案例 4 在损失方面表现出与训练相似的性能，但验证准确性略高于训练。这表明不合适。对于基本情况，验证损失和准确性比它们的训练对应物差得多，这再次指向过度拟合。虽然我们看到第二种情况的验证准确性和损失波动非常大，但平均来看，它似乎是五种情况中表现最好的。</p><p id="795b" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">从这四个图中，我们还可以看到，对于相同数量的时期和相同的优化器初始状态，在训练期间，每个数据增加的情况都收敛在不同的点。这几乎就像<strong class="ld ir"> <em class="lu">每一个案例都遵循着一条独立的轨迹</em> </strong>。</p><p id="909c" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">下表显示了训练和验证的最大准确度和最小损失。该表支持从图表中得出的结论。第二种情况似乎很好地平衡了训练中的过度适应和欠适应。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi nh"><img src="../Images/172e9e37ba5c6fe2574d8908feac1fca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sOdl-1vUNPnq2L6yrLmkRg.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">按作者</p></figure><h2 id="fbdc" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">对 5 种情况的测试图像的预测</strong></h2><p id="72e9" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">我们在使用 3 幅测试图像的五个案例中的每一个案例中看到了卫星图像中水体的预测分割。再次值得注意的是，<em class="lu">使用 5 个不同的数据扩充组合训练的相同模型为每个测试图像预测了 5 个不同的图像。</em></p><p id="8233" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">应注意的是，测试图像在格式方面与基础案例最为相似，因为<em class="lu">基础案例没有使用增强</em>。因此，对于所有三个图像，基本情况模型能够分割水体的整体形状。然而，案例 2 也能够捕捉微小的边缘。这证实了我们从图表中得出的结论，即基本情况模型略微超过了训练数据(由于方差最小)。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ni"><img src="../Images/86307490ab7d044652f5f332cbc117ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZS-K7zehKhuHF5X8ZlJqFQ.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">按作者</p></figure><p id="4703" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">情况 3 和 4 的性能随着每个测试图像而变化。情况 5 给出了所有三幅图像(尤其是第二幅和第三幅图像)的最差预测。这可能意味着，为了在这样的数据集上训练该模型，改变绝对强度或放大太多可能会导致糟糕的预测结果。这可以归因于这样一个事实，即模型欠拟合训练数据，一个<em class="lu">非常高的方差</em>。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi nj"><img src="../Images/9c6406d934b037773dc1073753a285d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJO7-X5458548d7D8R0Rog.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">按作者</p></figure><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi nh"><img src="../Images/b4795042ee2983ec0649225262e54783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UXsulxqu0ERE3LHK32hsoA.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">按作者</p></figure><p id="4710" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated">最后，<strong class="ld ir"> <em class="lu">又回到了核心原则——平衡偏差和方差</em> </strong>。虽然数据扩充确实具有显式的正则化效果，但利用它实际上会导致模型学习不足，从而导致预测结果不佳。因此，我们可以看到，有必要尝试不同的数据扩充组合，以找到最适合问题陈述数据集的组合。</p></div><div class="ab cl nk nl hu nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="ij ik il im in"><p id="7a05" class="pw-post-body-paragraph lb lc iq ld b le ml jr lg lh mm ju lj ko mn ll lm ks mo lo lp kw mp lr ls lt ij bi translated"><strong class="ld ir"> <em class="lu">完整代码可以在</em></strong><a class="ae mq" href="https://github.com/MS1997/Semantic-Segmentation-of-Water-Bodies" rel="noopener ugc nofollow" target="_blank"><strong class="ld ir"><em class="lu">Github</em></strong></a><strong class="ld ir"><em class="lu">上找到！</em> </strong></p></div></div>    
</body>
</html>