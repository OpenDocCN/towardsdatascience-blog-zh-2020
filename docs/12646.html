<html>
<head>
<title>Data Scaling for Machine Learning — The Essential Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的数据缩放——基本指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-scaling-for-machine-learning-the-essential-guide-d6cfda3e3d6b?source=collection_archive---------42-----------------------#2020-08-31">https://towardsdatascience.com/data-scaling-for-machine-learning-the-essential-guide-d6cfda3e3d6b?source=collection_archive---------42-----------------------#2020-08-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1ed2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">什么是标准化，为什么它如此重要？</h2></div><p id="4717" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可能会遇到带有大量内置数字噪声的数据集，如方差或不同规模的数据，因此在考虑机器学习之前，良好的预处理是必不可少的。这类问题的一个好的预处理解决方案通常被称为<em class="le">标准化</em>。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/5c06e8d7e985a84889596a8526b3cc83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*70cgkkUa6GWfzFEq"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">菲德尔·费尔南多在<a class="ae lv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="05a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">标准化是一种预处理方法，用于转换连续数据，使其看起来呈正态分布。在<code class="fe lw lx ly lz b">scikit-learn</code>中，这通常是一个必要的步骤，因为许多模型假设你正在训练的数据是正态分布的，如果不是，你的风险偏向你的模型。</p><p id="bfbe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以用不同的方式标准化您的数据，在本文中，我们将讨论流行的数据缩放方法— <em class="le">数据缩放。</em>或<em class="le">标准缩放</em>更精确。</p><p id="5ac9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同样重要的是要注意到<em class="le">标准化</em>是一种应用于连续数值数据的预处理方法，在一些不同的场景中会用到它:</p><ol class=""><li id="af13" class="ma mb it kk b kl km ko kp kr mc kv md kz me ld mf mg mh mi bi translated">当处理任何使用线性距离度量或在线性空间上操作的模型时-KNN、线性回归、K-均值</li><li id="c881" class="ma mb it kk b kl mj ko mk kr ml kv mm kz mn ld mf mg mh mi bi translated">当数据集中的一个或多个要素具有较高的方差时-如果中某个要素的方差比其他要素的方差大一个数量级或更多，这可能会使假设数据呈正态分布的模型产生偏差</li></ol><p id="7e7d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们继续进行数据缩放。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="0ed6" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">数据缩放</h1><p id="895f" class="pw-post-body-paragraph ki kj it kk b kl nn ju kn ko no jx kq kr np kt ku kv nq kx ky kz nr lb lc ld im bi translated">当处理包含不同比例的连续要素的数据集时，缩放是一种最有用的标准化方法，并且您使用的是在某种线性空间中操作的模型(如线性回归或 K-最近邻)</p><p id="baa9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要素缩放会变换数据集中的要素，使它们的平均值为零，方差为一。这将使线性比较要素变得更加容易。此外，这也是<code class="fe lw lx ly lz b">scikit-learn</code>中许多型号的要求。</p><p id="b174" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来看看一个名为<em class="le"> wine: </em>的数据集</p><pre class="lg lh li lj gt ns lz nt nu aw nv bi"><span id="b9ee" class="nw mw it lz b gy nx ny l nz oa">import pandas as pd <br/>import numpy as np <br/>from sklearn import datasets </span><span id="a780" class="nw mw it lz b gy ob ny l nz oa">wine = datasets.load_wine() <br/>wine = pd.DataFrame(<br/>    data=np.c_[wine['data'], wine['target']], <br/>    columns=wine['feature_names'] + ['target'] <br/>)</span></pre><p id="98ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们想使用<em class="le">葡萄酒</em>数据集中的<code class="fe lw lx ly lz b">ash</code>、<code class="fe lw lx ly lz b">alcalinity_of_ash</code>和<code class="fe lw lx ly lz b">magnesium</code>列来训练一个线性模型，但是有可能这些列都是以不同的方式测量的，这会使线性模型产生偏差。使用<code class="fe lw lx ly lz b">describe()</code>函数返回关于数据集的描述性统计数据:</p><pre class="lg lh li lj gt ns lz nt nu aw nv bi"><span id="f977" class="nw mw it lz b gy nx ny l nz oa">wine[['magnesium', 'ash', 'alcalinity_of_ash']].describe()</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="ab gu cl oc"><img src="../Images/fb6c859f6fb1b8751576e4eba2ddd08b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*4_GnupJdUEo7dYVdvtEuAQ.png"/></div></figure><p id="1b05" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，<code class="fe lw lx ly lz b">ash</code>的最大值是 3.23，<code class="fe lw lx ly lz b">alcalinity_of_ash</code>的最大值是 30，<code class="fe lw lx ly lz b">magnesium</code>的最大值是 162。这些值之间存在巨大差异，由于规模更大，机器学习模型在这里可以很容易地将<code class="fe lw lx ly lz b">magnesium</code>解释为最重要的属性。</p><p id="f524" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们将它们标准化，以便在线性模型中使用。以下是步骤:</p><ol class=""><li id="6075" class="ma mb it kk b kl km ko kp kr mc kv md kz me ld mf mg mh mi bi translated">导入<code class="fe lw lx ly lz b">StandardScaler</code>并创建它的一个实例</li><li id="f459" class="ma mb it kk b kl mj ko mk kr ml kv mm kz mn ld mf mg mh mi bi translated">创建执行缩放的子集</li><li id="885a" class="ma mb it kk b kl mj ko mk kr ml kv mm kz mn ld mf mg mh mi bi translated">对子集应用缩放器</li></ol><p id="42c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码如下:</p><pre class="lg lh li lj gt ns lz nt nu aw nv bi"><span id="a117" class="nw mw it lz b gy nx ny l nz oa">from sklearn.preprocessing import StandardScaler </span><span id="7cf4" class="nw mw it lz b gy ob ny l nz oa"># create the scaler <br/>ss = StandardScaler() </span><span id="dd02" class="nw mw it lz b gy ob ny l nz oa"># take a subset of the dataframe you want to scale <br/>wine_subset = wine[['magnesium', 'ash', 'alcalinity_of_ash']] </span><span id="61eb" class="nw mw it lz b gy ob ny l nz oa"># apply the scaler to the dataframe subset <br/>wine_subset_scaled = ss.fit_transform(wine_subset)</span></pre><p id="089a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">厉害！让我们看看前几行缩放后的数据是什么样子的:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="ab gu cl oc"><img src="../Images/10184f2863b0661c854f94dc33e4b2e3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*C418Sh4DBWOORJgVGhQbZg.png"/></div></figure><p id="ef51" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些值现在更加接近了。为了了解缩放实际上如何影响模型的预测能力，让我们快速制作一个 KNN 模型。</p><p id="18a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，对于未缩放的数据:</p><pre class="lg lh li lj gt ns lz nt nu aw nv bi"><span id="a24d" class="nw mw it lz b gy nx ny l nz oa">from sklearn.neighbors import KNeighborsClassifier <br/>from sklearn.model_selection import train_test_split </span><span id="c5f3" class="nw mw it lz b gy ob ny l nz oa">X = wine.drop('target', axis=1) <br/>y = wine['target'] </span><span id="10d8" class="nw mw it lz b gy ob ny l nz oa">X_train, X_test, y_train, y_test = train_test_split(X, y) </span><span id="1e58" class="nw mw it lz b gy ob ny l nz oa">knn = KNeighborsClassifier() <br/>knn.fit(X_train, y_train) </span><span id="71bf" class="nw mw it lz b gy ob ny l nz oa"><br/>print(knn.score(X_test, y_test)) <br/><strong class="lz iu">&gt;&gt;&gt; 0.666666666666</strong></span></pre><p id="d012" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不太准确。让我们缩放整个数据集并重复这个过程:</p><pre class="lg lh li lj gt ns lz nt nu aw nv bi"><span id="d698" class="nw mw it lz b gy nx ny l nz oa">ss = StandardScaler() </span><span id="2005" class="nw mw it lz b gy ob ny l nz oa">X_scaled = ss.fit_transform(X) </span><span id="b7ba" class="nw mw it lz b gy ob ny l nz oa">X_train, X_test, y_train, y_test = train_test_split(X_scaled, y) </span><span id="bc68" class="nw mw it lz b gy ob ny l nz oa">knn = KNeighborsClassifier() <br/>knn.fit(X_train, y_train) </span><span id="7deb" class="nw mw it lz b gy ob ny l nz oa"><br/>print(knn.score(X_test, y_test)) <br/><strong class="lz iu">&gt;&gt;&gt; 0.97777777777777777</strong></span></pre><p id="7a18" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如您所见，我们模型的准确性显著提高。我将把对这个 KNN 分类器的进一步调整留给您，谁知道呢，也许您可以正确地得到所有的分类。</p><p id="c3fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们在下一部分总结一下。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="d5cd" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">在你走之前</h1><p id="3338" class="pw-post-body-paragraph ki kj it kk b kl nn ju kn ko no jx kq kr np kt ku kv nq kx ky kz nr lb lc ld im bi translated">这就是数据标准化的全部内容，也是它为什么重要的原因。我们将在其他时间比较<code class="fe lw lx ly lz b">StandardScaler</code>与其他定标器。本文的要点是，无论何时你需要正态分布(相对)的特性，你都应该使用<code class="fe lw lx ly lz b">StandardScaler</code>。</p><p id="a572" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">更准确地说，每当你使用一个假设数据是正态分布的模型——比如 KNN 或线性回归，就使用<code class="fe lw lx ly lz b">StandardScaler</code>。</p><p id="7d2b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读。</p><p id="14a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">加入我的私人邮件列表，获取更多有用的见解。T11】</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="5b9e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">喜欢这篇文章吗？成为</em> <a class="ae lv" href="https://medium.com/@radecicdario/membership" rel="noopener"> <em class="le">中等会员</em> </a> <em class="le">继续无限制学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="od oe gp gr of og"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">通过我的推荐链接加入 Medium-Dario rade ci</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">medium.com</p></div></div><div class="op l"><div class="oq l or os ot op ou lp og"/></div></div></a></div></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="6e47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">原载于 2020 年 8 月 31 日 https://betterdatascience.com</em><em class="le">的</em> <a class="ae lv" href="https://betterdatascience.com/data-scaling-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"> <em class="le">。</em></a></p></div></div>    
</body>
</html>