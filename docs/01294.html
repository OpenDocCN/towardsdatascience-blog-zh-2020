<html>
<head>
<title>Object Detection with Haar Cascades in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中Haar级联的目标检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-with-haar-cascades-in-python-ad9e70ed50aa?source=collection_archive---------11-----------------------#2020-02-05">https://towardsdatascience.com/object-detection-with-haar-cascades-in-python-ad9e70ed50aa?source=collection_archive---------11-----------------------#2020-02-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="19c0" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">计算机视觉演示</h2><div class=""/><div class=""><h2 id="6277" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">OpenCV for Python在一个易于使用的包中附带了一些高级工具，使用Haar级联的对象检测就是其中之一。我将大致解释它是什么，并介绍如何识别图像和视频中的面部特征。</h2></div><h1 id="fdfc" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">理论课</h1><p id="f53b" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们将使用基于Haar特征的级联分类器来检测人脸、眼睛、微笑以及眼镜。该方法由P. Viola和M. Jones于2001年提出[1]。简而言之，它是一种机器学习方法，其中在大量的正负图像上训练所谓的级联函数(正的意思是它包括期望的对象，负的图像缺少它)，反过来可以用于对象检测。</p><p id="2e40" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">为了实际解释它，我们引入了Haar特征的概念，它们是由下面充当卷积核的黑盒子和白盒子获得的。更具体地说，这些特征是通过从黑色矩形下的像素总和中减去白色矩形下的像素总和而接收的单个值。[2]</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/4a1e5a5c84a6fdde2940270f7cd6fa58.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hbFPsfsCqV8rf1MV8b8p5w.jpeg"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">哈尔的特点[2]</p></figure><p id="d53a" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">如果你对卷积这个词感到不安，让我借助维基百科的一幅图片来简化它。它本质上是两种功能相互影响的结果。因此，在我们的例子中，它表示盒子的白色和黑色部分的像素的总和如何相互作用，即被区分以产生单个值。当然，还有一种算法可以有效地计算一个区域内像素的总和，它被称为总面积表，由F. Crow于1984年发表[3]。它后来在图像处理领域得到推广，并被命名为integral image，但我在这里不会深入研究它。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/26f68b0ae087e62eee40fa050df055fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*CbOUB2WgVOzVRx8iDv5APQ.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">卷积(来自维基百科的Cmglee)</p></figure><p id="3c10" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">接下来，功能选择会像您想象的那样发生。您尝试不同的Haar特性，并查看哪一个特性能够产生黑白矩形之间像素总和的最大差值。我们下面有一个例子，其中发现了最佳的哈尔特征。眼睛通常有点暗，而下面的区域可能比较亮，因此一个上黑下白的水平矩形是合适的。第二，鼻梁通常比眼睛亮，因此中间有一个垂直的白色方框的哈尔特征是合适的。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/718074f086356a231521438c3ac97d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*64MTUF8nuEvSgBvYmOfhKA.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图像的最佳哈尔特征[2]</p></figure><p id="fdad" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">Haar features这个名字听起来有点奇怪，但它实际上源于与Haar小波的直观相似性，Haar小波就是这些坏男孩:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi my"><img src="../Images/03aefaac70100ca15e570801165f67f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*MUeF9CIalU87NC-6T7mNWw.png"/></div></figure><p id="cf57" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">它们没有被直接使用，但是这些特征(黑盒子和白盒子)是我们可以称之为<em class="mz"> Haar-like </em>的东西，在这个意义上，你现在已经明白了。许多这些类似Haar的特征可以应用于图像，并使用Adaboost算法，该算法找到用于正确分类训练图像的最佳阈值。但是将其中的一个放在某个地方，即使放在可能的最佳位置，仍然会导致一些误差，因为正集和负集中的所有图像彼此不同。最后，选择错误率最小的哈尔特征作为分类器。</p><p id="f2f7" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">尽管采取了这些措施，但最终的特征数量可能相当大，因此发明人引入了分类器<strong class="ll jd"/><em class="mz">级联的概念(现在我们已经得到了基于特征的级联分类器</em>的全称<em class="mz">)。这在进行检测时使用，因为用大量特征进行检测会很慢，相反，在检测时分类器由级联的特征组成。因此，最初的哈尔特征可能只是检查图像是否可能是人脸(在人脸检测的情况下)，然后接下来的阶段具有更多最基本的哈尔特征。这是一种有利的方法，因为早期不包含所需对象的图像被丢弃并且不再被处理。将这与一次将所有特征扔向图像进行比较，你会看到增益。[2]</em></p><h1 id="d308" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">履行</h1><p id="a615" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">到了我们用Python实现它的部分。如果你想在自己的机器上跟随或尝试任何酷的东西，它可以在<a class="ae na" href="https://github.com/deinal/opencv-recognition-demo" rel="noopener ugc nofollow" target="_blank"> GitHub仓库</a>或<a class="ae na" href="https://colab.research.google.com/drive/1H2XBOI31j4idgAqyY-brunwOlIajeFRt#scrollTo=KjxUh493oYf-" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>中公开获得，尽管不幸的是，后者不能在视频中进行对象检测……无论如何，我们从做一些导入开始，所以我们都准备好了。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="8780" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">接下来，我们加载容易训练的对象分类器。我从OpenCV自己的仓库下载了它们，在这篇文章的底部还有一个链接，告诉你如何训练你自己的分类器来分类你家里的任何东西。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="1d62" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">所以我想这是有趣的部分。首先，在灰度模式下进行分类，然后我们可以看看detectMultiScale，它执行对象检测，并以矩形列表的形式返回它们。该方法可以接受一些参数，这些参数可以根据个人喜好进行调整。</p><ul class=""><li id="1176" class="nd ne it ll b lm mf lp mg ls nf lw ng ma nh me ni nj nk nl bi translated"><strong class="ll jd"> scaleFactor: </strong>指定在每个图像比例下图像尺寸缩小多少的参数。增加它会导致更快的检测，但有丢失一些对象的风险，而较小的值有时可能会太彻底。</li><li id="b4a6" class="nd ne it ll b lm nm lp nn ls no lw np ma nq me ni nj nk nl bi translated"><strong class="ll jd"> minNeighbors: </strong>参数，指定每个候选矩形应该有多少个邻居来保留它。较高的值导致较少的检测，但质量较高。</li><li id="c5a9" class="nd ne it ll b lm nm lp nn ls no lw np ma nq me ni nj nk nl bi translated"><strong class="ll jd">最小尺寸:</strong>可能的最小物体尺寸。小于该值的对象将被忽略。</li><li id="c17c" class="nd ne it ll b lm nm lp nn ls no lw np ma nq me ni nj nk nl bi translated"><strong class="ll jd"> maxSize: </strong>最大可能的对象大小。大于该值的对象将被忽略。</li></ul><p id="b018" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">我篡改了代码中的比例因子和最小邻居。例如，眼镜很难被检测到，可能是因为我使用的图片中的人是向上看的，这不像输入级联被训练的目的。因此，为了更精确，我降低了比例因子和最小邻居。除此之外，我发现了太多的微笑——所以我增加了这两个参数。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="7696" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">请注意，OpenCV使用图像通道的BGR排序，而不是RGB，所以如果你绘制任何东西，并以一些有趣的东西结束，你知道为什么。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nb nc l"/></div></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a413a6ccdb5f6870525e3342a5e66fe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*B6ZeLlG6erC7QoiUC67LOQ.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">当你的颜色通道顺序错误时(原始的，由Pexels的fauxels拍摄的更好的照片)</p></figure><p id="da2f" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">我们使用<em class="mz"> cv2来考虑这一点。COLOR_BGR2RGB </em>并绘制我们的对象检测结果。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nb nc l"/></div></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c11ea7bc24acdab63cd8e6f3f4ec6406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*U99Mr4uM8SxZDI4Fr3BGrw.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">脸部、眼睛和微笑现在都可以被检测到了</p></figure><p id="552c" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">整洁不是吗？你可以看到眼镜检测远非理想。我们还注意到，正如理论课所预期的那样，分类器不适用于半张脸。为此，我们需要一个单独的分类器。</p><p id="9997" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">现在，继续我发现的更令人兴奋的事情。我们可以修改图像检测代码中的几行代码来对视频进行对象检测。我的意思是调用<em class="mz"> cap = cv2。VideoCapture(0) </em>指的是网络摄像头。我们通过按ESC键退出视频，作为键码<em class="mz">键码。KEY _ ESCAPE = 27</em>for<em class="mz">OpenCV的cv2.waitKey() </em>这是一个将显示一帧的毫秒数作为输入的函数。不要忘记用<em class="mz"> cap.release() </em>和<em class="mz">cv2 . destroyallwindows()</em>释放并关闭最后的窗口。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="7742" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">如前所述，你可以通过克隆我的<a class="ae na" href="https://github.com/deinal/opencv-recognition-demo" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>或者在Google Colab上尝试我所说的东西。然而，<a class="ae na" href="https://colab.research.google.com/drive/1H2XBOI31j4idgAqyY-brunwOlIajeFRt" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>不支持网络摄像头流式视频，但我确实找到了一种在Colab内部拍摄自己照片的方法，面部检测可以在上面进行。这仍然是它在运行时的样子。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/c01debd56a99a531d78a009ecdce4bd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*e9Qum7ILPAfW0CMS6ak5eg.gif"/></div></figure><p id="d24d" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">我们可以看到，它确实很好地检测到了我的脸和眼睛，而且笑容应该很大，就像这个:D，这样它才能工作。否则可能会被误认为是眼睛。</p><p id="6651" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">最后，如果您想为自己唯一的对象训练一个分类文件，该怎么办？这相当简单，我们需要一组正匹配以及大量负匹配，其中不包括您的对象。这里是我发现的一个逐步操作指南:</p><div class="nu nv gp gr nw nx"><a href="https://medium.com/@toshyraf/train-dataset-to-xml-file-for-cascade-classifier-opencv-43a692b74bfe" rel="noopener follow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd jd gy z fp oc fr fs od fu fw jc bi translated">将数据集训练为XML文件，用于级联分类器OpenCV</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">查找列车图像:</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">medium.com</p></div></div><div class="og l"><div class="oh l oi oj ok og ol mq nx"/></div></div></a></div><p id="0bc4" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">现在一切都结束了，如果你愿意，在领英上和我联系，链接在我的个人资料里。祝你有愉快的一天！</p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="cec0" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">[1]: P. Viola和M. Jones，使用增强级联简单特征的快速目标检测(2001)</p><p id="5042" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">[2]:使用Haar Cascades进行人脸检测，<a class="ae na" href="https://docs.opencv.org/3.4/d2/d99/tutorial_js_face_detection.html" rel="noopener ugc nofollow" target="_blank">https://docs . opencv . org/3.4/D2/d99/tutorial _ js _ Face _ Detection . html</a></p><p id="6fb4" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">[3]: F. Crow，纹理映射的总面积表(1984)</p></div></div>    
</body>
</html>