<html>
<head>
<title>Statistical Learning (II): Data Sampling &amp; Resampling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">统计学习(二):数据采样和重采样</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/statistical-learning-ii-data-sampling-resampling-93a0208d6bb8?source=collection_archive---------14-----------------------#2020-04-03">https://towardsdatascience.com/statistical-learning-ii-data-sampling-resampling-93a0208d6bb8?source=collection_archive---------14-----------------------#2020-04-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/ad8f55d817c7385f5887190c42a92551.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_wsYyyOP5f0ht006WHYq9Q.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:Iconic Bestiary，via <a class="ae jg" href="https://www.shutterstock.com/image-vector/business-team-gathered-around-leader-creative-585334610" rel="noopener ugc nofollow" target="_blank"> shutterstock </a></p></figure><div class=""/><p id="ddbe" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di">统计抽样是从所有人群中抽取样本的一个子集。如今，机器学习模型变得更加复杂，并且将数百万个参数输入到最新的模型中，例如包含数百万个参数的BERT或ResNet模型。对于数据集的子样本，训练这样一个复杂的模型是相对高效的，虽然它通常需要几天到一周的时间。对数据进行二次抽样有助于确定参数网格搜索的更好性能。另一方面，在数据重采样方面，该方法为数据群体中的少数群体创建合成数据，或者使用来自原始数据集的复制数据。这有助于模型不过度适应包含大量数据样本的主类。</span></p><p id="4b6b" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，您将了解到:</p><p id="f0a6" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(1)流行的数据采样方法有哪些</p><p id="92f9" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(2)流行的数据重采样方法有哪些</p><p id="b122" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(Python中数据采样和重采样的应用</p><h1 id="23a4" class="ln lo jj bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">数据采样</h1><p id="21ea" class="pw-post-body-paragraph kg kh jj ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">有两种主要的数据采样方法:</p><ul class=""><li id="2b82" class="mq mr jj ki b kj kk kn ko kr ms kv mt kz mu ld mv mw mx my bi translated"><strong class="ki jk">随机抽样:</strong>给数据子集等概率被选中。</li></ul><p id="532a" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">参见下图1，我们可以看到有3组不同大小的样本，以1/n的相等概率选择子样本</p><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mz"><img src="../Images/9c9768d7417eba4d0d9f55c50fe07fff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J7_l13gSG6u-MVhFJJ7K2w.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图1:随机抽样</p></figure><ul class=""><li id="411f" class="mq mr jj ki b kj kk kn ko kr ms kv mt kz mu ld mv mw mx my bi translated"><strong class="ki jk">分层抽样:</strong>给定每个类中数据集的不同大小，基于占总体的百分比从每个组中选择子集。</li></ul><p id="a4e7" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从下面的图2可以看出，有3组不同大小的样本，根据给定的每组相对概率选择子样本。因为有12、12和6个数据点分散在A组、B组和c组中。选择子样本的概率为2:2:1，由组的大小决定。</p><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mz"><img src="../Images/0be66f0cff4089a7e71dd933dd60b6e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2yy20lvklZNAPezjL14iig.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图2:分层抽样</p></figure><h1 id="1889" class="ln lo jj bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">统计重采样:</h1><p id="4796" class="pw-post-body-paragraph kg kh jj ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">创建数据集副本的有效方法是估计模型参数。而且，这个过程要重复几次。</p><h2 id="f09f" class="ne lo jj bd lp nf ng dn lt nh ni dp lx kr nj nk mb kv nl nm mf kz nn no mj np bi translated">两种流行的重采样方法:</h2><ul class=""><li id="b5d7" class="mq mr jj ki b kj ml kn mm kr nq kv nr kz ns ld mv mw mx my bi translated"><strong class="ki jk"> K-Fold交叉验证:</strong>一个数据集被分成K组，一定数量的数据集将被分配给训练数据集，而保留的数据集将被分配给测试数据集。当训练数据集相当小时，应用这种方法以避免过拟合问题。</li><li id="0c6e" class="mq mr jj ki b kj nt kn nu kr nv kv nw kz nx ld mv mw mx my bi translated"><strong class="ki jk"> BootStrap: </strong>虽然数据集不遵循任何特定的分布，如正态分布、X平方分布和T-student分布，但BootStrap可用于评估数据集下的统计数据和潜在分布。从下面的图中，首先，从原始数据集中抽取一组子样本。然后，我们以固定长度(n)从初始子样本重新取样B次，而不考虑从提取中抽取的重复样本。对于每个bootstrap样本，使用参数(θ)进行估计。因此，bootstrap是当一种常见的方法是估计量(θ)采用<a class="ae jg" href="https://en.wikipedia.org/wiki/Empirical_distribution_function" rel="noopener ugc nofollow" target="_blank">经验分布函数</a>时，用于<strong class="ki jk">逼近概率分布</strong>的一种方法。</li></ul><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/8bd4639c388b1468a80c2cea7ecb960a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FSf-l7J75EnX-cNNPQbvgQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" rel="noopener" target="_blank" href="/an-introduction-to-the-bootstrap-method-58bcb51b4d60">自举方法介绍</a></p></figure><h1 id="9cdc" class="ln lo jj bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">重新采样:</h1><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/65a79136d108f4781ead537f5a6d9ec0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YfQc_bSmbrlgD9gVd6f99A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t1" rel="noopener ugc nofollow" target="_blank"> <strong class="bd oa">不平衡数据集的重采样策略</strong> </a></p></figure><p id="8d35" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">给定不平衡的数据集，我们经常面临的问题是大多数数据属于主要类，而少数数据属于少数类。为了克服这种不平衡数据的模型训练的不良性能，主要建议使用过采样和欠采样技术来产生落入每一类的均匀分布的数据。</p><p id="cfde" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我将浏览示例数据集</p><h2 id="b3f2" class="ne lo jj bd lp nf ng dn lt nh ni dp lx kr nj nk mb kv nl nm mf kz nn no mj np bi translated">(A)使用Python包的欠采样</h2><p id="de09" class="pw-post-body-paragraph kg kh jj ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在<strong class="ki jk"> python imblearn中有几种欠采样算法可以应用。(1) ClusterCentroids: </strong>使用K-means 方法的<strong class="ki jk">质心，合成每个类的大小，以减少数据。注意<strong class="ki jk">数据应分组为簇，以应用簇形心方法</strong>。</strong></p><figure class="na nb nc nd gt iv"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="3957" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki jk"> (2) RandomUnderSampler: </strong>为目标类选择数据子集，以平衡数据集。它通过将替换参数设置为真来启用<strong class="ki jk">引导</strong>方法，同时从每个类别中独立抽取子样本。</p><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/93a5d47d02542e401fcac4a403511ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OmVMHfN8Lv5xvGF68YryZA.png"/></div></div></figure><p id="7e76" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">更多关于使用Python的欠采样方法的参考可以在<a class="ae jg" href="https://imbalanced-learn.readthedocs.io/en/stable/under_sampling.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ki jk">这里</strong> </a>找到</p><h2 id="2e8b" class="ne lo jj bd lp nf ng dn lt nh ni dp lx kr nj nk mb kv nl nm mf kz nn no mj np bi translated">过采样(合成少数过采样技术SMOTE)</h2><p id="3a55" class="pw-post-body-paragraph kg kh jj ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">该技术用于在特征空间中选择最近邻，通过添加一条线来分隔样本，并沿着该线产生新的样本。该方法不仅仅是从寡不敌众的类中生成副本，而是应用<strong class="ki jk"> K近邻</strong>来生成合成数据。从下面的图3中，蓝色圆圈是原始数据，红色圆圈中的另一个蓝点是最近的邻居，粉红色的点是合成的。链接到<a class="ae jg" href="https://kite.com/blog/python/smote-python-imbalanced-learn-for-oversampling/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki jk">文章</strong> </a>了解更多关于SMOTE算法的细节。</p><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mz"><img src="../Images/b737fd582ac1e03957d5e89c34518bdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mqfS2tbNU91_MJswwiCaBA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">情节SMOTE是如何工作的</p></figure><h2 id="63a2" class="ne lo jj bd lp nf ng dn lt nh ni dp lx kr nj nk mb kv nl nm mf kz nn no mj np bi translated">动手对<a class="ae jg" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">信用欺诈数据</a>应用重采样方法:</h2><p id="7e13" class="pw-post-body-paragraph kg kh jj ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">这些数据用于检测Kaggle Challenge的交易是正常交易还是欺诈交易。为了保护信用卡信息中的个人隐私，通过<strong class="ki jk">主成分分析(PCA) </strong>方法对特征进行了缩放，并将特征的名称以及总额和类别重新命名为V1至第28版，其中0和1表示欺诈交易，0表示其他交易。</p><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/2dceef41be60b7615f4c01913ca6c7bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1sdBwRYP9vPaJrFO0cVH3w.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">交易数据中不平衡类的百分比</p></figure><p id="1ea4" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从下面的柱状图可以看出<strong class="ki jk">非欺诈数据</strong>占<strong class="ki jk"> 99.82% </strong>，而<strong class="ki jk">欺诈数据</strong>占<strong class="ki jk"> 0.17% </strong>。</p><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/a8cb93d7530631f3470051f0fbd3f51b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xi3eqn9mVFGIb7TLRQxBxw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">阶级分布条形图</p></figure><h2 id="af76" class="ne lo jj bd lp nf ng dn lt nh ni dp lx kr nj nk mb kv nl nm mf kz nn no mj np bi translated">如何处理这样不平衡的数据集？</h2><p id="b964" class="pw-post-body-paragraph kg kh jj ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated"><strong class="ki jk">子样本。</strong>将班级平均分配为50人和50人，这样模型可以为每个班级学习相同的样本量。</p><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/80b72cab4a85b7785900178ae7d0f20d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*14kPpQxfYDsL0SFLLiq9Aw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">对主要类进行欠采样，并使数据大小与少数类相匹配</p></figure><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/ced659973516cad60c2c8a0e8066cc0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s2-BGkn6nLLjfE-_gPQ_eA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">平均分布类的条形图</p></figure><h2 id="f171" class="ne lo jj bd lp nf ng dn lt nh ni dp lx kr nj nk mb kv nl nm mf kz nn no mj np bi translated">注意:拆分数据用于模型训练和评估</h2><p id="efcf" class="pw-post-body-paragraph kg kh jj ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在进行随机欠采样或过采样之前，我们需要分离原始数据帧。目的是<strong class="ki jk">测试非来自手动合成数据集</strong>的原始数据。</p><h1 id="e519" class="ln lo jj bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">结论:</h1><p id="b591" class="pw-post-body-paragraph kg kh jj ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">通过这篇文章，我们了解了一些流行的数据采样和重采样方法。遇到不平衡的数据集问题或拥有庞大的数据集是很常见的。为了克服过拟合问题，进行数据采样方法以从中抽取子样本确实是一种有效的方法，而数据重采样(如过采样和下采样方法)是平衡每类数据的好方法。最后，python中的代码展示了如何在每个算法上生成数据重采样方法并应用于数据集。享受周末:)</p><figure class="na nb nc nd gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/d974186f54a95b8f01a63be0ef74d4e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uKjs3vIXNsmK1Z7j_VDKyA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://memeshappen.com" rel="noopener ugc nofollow" target="_blank">memeshappen.com</a></p></figure><p id="f792" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您对本文的关注。请在下面留下你的评论，并欢迎任何反馈。作为一个写这篇博客的初学者，我会发表更多与数据科学相关的文章。如果你是数据爱好者，请关注我的<a class="ae jg" href="https://medium.com/@rahul_agarwal?source=post_page---------------------------" rel="noopener"> <strong class="ki jk">中</strong> </a> <strong class="ki jk">。</strong>敬请期待:)</p></div></div>    
</body>
</html>