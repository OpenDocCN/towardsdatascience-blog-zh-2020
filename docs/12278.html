<html>
<head>
<title>Unsolved Problems in Natural Language Understanding Datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言理解数据集未解决的问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unsolved-problems-in-natural-language-datasets-2b09ab37e94c?source=collection_archive---------33-----------------------#2020-08-24">https://towardsdatascience.com/unsolved-problems-in-natural-language-datasets-2b09ab37e94c?source=collection_archive---------33-----------------------#2020-08-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e93a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">即使是最受欢迎的 NLP 基准也面临着这些挑战</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/14b1d2490c36226ddb5fb8d7d67d9ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iZkuOnC5Jmki75tS"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">杰森·德沃尔在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="473c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">垃圾进来，垃圾出去。你不必是一个 ML 专家也能听到这个短语。模型揭示了数据中的模式，因此当数据被破坏时，它们会发展出破坏的行为。这就是为什么研究人员分配大量资源来管理数据集。然而，尽管尽了最大努力，收集完全干净的数据几乎是不可能的，尤其是在深度学习所需的规模上。</em></p><p id="cd95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文讨论了流行的自然语言数据集，尽管这些数据集是由该领域的专家制作的，但结果却违反了机器学习和数据科学的基本原则。这些缺陷中的一些在数据集公布和大量使用多年后被暴露和量化。这是为了说明<strong class="lb iu">数据收集和验证是一个艰巨的过程</strong>。以下是他们的一些主要障碍:</p><ol class=""><li id="0a8c" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><strong class="lb iu">机器学习是数据饥渴。ML(特别是深度学习)所需的庞大数据量要求自动化，即挖掘互联网。数据集最终会从互联网上继承不需要的属性(例如，重复、统计偏差、虚假)，这些属性很难检测和删除。</strong></li><li id="6c91" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">desire data 无法详尽捕获。</strong>即使 oracle 能够根据一些预定义的规则产生无限的数据，要列举所有的需求实际上也是不可行的。考虑对话机器人的训练数据。我们可以表达一般的愿望，如不同的话题，尊重的交流，或对话者之间的平衡交流。但是我们没有足够的想象力去指定所有的相关参数。</li><li id="e095" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">人类选择阻力最小的道路</strong>。一些数据收集工作在人类规模上仍然是可管理的。但是我们自己并不是完美无缺的，尽管我们尽了最大努力，我们还是下意识地倾向于走捷径。如果你的任务是写一个与前提“狗在睡觉”相矛盾的陈述，你的答案会是什么？继续阅读，看看你是否会成为问题的一部分。</li></ol><h1 id="f114" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">重叠的训练和评估集</h1><p id="21f9" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">ML 从业者将他们的数据分成三部分:有一个<em class="lv">训练集</em>用于实际学习，一个<em class="lv">验证集</em>用于超参数调整，一个<em class="lv">评估集</em>用于测量模型的最终质量。众所周知，这些集合应该<em class="lv">大部分是</em>析取的。在评估训练数据时，您测量的是模型的记忆能力，而不是它识别模式并将其应用于新环境的能力。</p><p id="0e31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个指导方针听起来很容易应用，但是 Lewis 等人[1]在 2020 年的一篇论文<a class="ae ky" href="https://arxiv.org/abs/2008.02637" rel="noopener ugc nofollow" target="_blank">中显示，最流行的开放领域问答数据集(open-QA)在它们的训练集和评估集之间有很大的重叠。他们的分析包括</a><a class="ae ky" href="https://www.aclweb.org/anthology/D13-1160/" rel="noopener ugc nofollow" target="_blank"> WebQuestions </a>、<a class="ae ky" href="https://nlp.cs.washington.edu/triviaqa/" rel="noopener ugc nofollow" target="_blank"> TriviaQA </a>和<a class="ae ky" href="https://ai.google.com/research/NaturalQuestions" rel="noopener ugc nofollow" target="_blank">开放式自然问题</a>——由知名机构创建的数据集，被大量用作 QA 基准。</p><blockquote class="nh ni nj"><p id="6aaf" class="kz la lv lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated">我们发现 60–70%的测试时答案也存在于训练集中的某个地方。我们还发现，30%的测试集问题在其对应的训练集中有近似重复的释义。</p></blockquote><p id="15b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，培训和测试之间 0%的重叠也是不理想的。我们确实需要某种程度的记忆——模型应该能够回答训练中看到的问题，并知道何时展示之前看到的答案。<strong class="lb iu">真正的问题是在训练/评估高度重叠的数据集上对模型进行基准测试，并对其泛化能力做出仓促的结论。</strong></p><p id="694c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Lewis 等人[1]在将评估集划分为三个子集后，重新评估了最先进的 QA 模型:(a) <em class="lv">问题重叠— </em>，其中相同或转述的问答对出现在训练集中，(b) <em class="lv">答案仅重叠— </em>，其中<em class="lv"> </em>相同的答案出现在训练集中，但与不同的问题配对，以及(c) <em class="lv">没有重叠</em>。QA 模型在这三个子集上的得分差别很大。例如，当在<a class="ae ky" href="https://ai.google.com/research/NaturalQuestions" rel="noopener ugc nofollow" target="_blank">开放式自然问题</a>上测试时，最先进的<a class="ae ky" href="https://arxiv.org/abs/2007.01282" rel="noopener ugc nofollow" target="_blank">解码器融合</a>模型在问题重叠上的得分约为 70%，仅在答案重叠上的得分约为 50%，在没有重叠上的得分约为 35%。</p><blockquote class="nh ni nj"><p id="ef7c" class="kz la lv lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated">很明显，这些数据集上的性能无法通过总体 QA 准确性来正确理解，这表明在未来，应更加重视更多行为驱动的评估，而不是追求单一数字的总体准确性数字。</p></blockquote><h1 id="047b" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">虚假相关</h1><p id="d476" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">就像人类一样，模型走捷径，发现解释数据的最简单模式。例如，考虑一个狗对猫图像分类器和一个天真的训练集，其中所有的狗图像都是灰度的，所有的猫图像都是全色的。该模型将最有可能抓住颜色和标签的存在/不存在之间的伪相关性。在全彩狗身上测试，大概会贴上猫的标签。</p><p id="e8d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Gururangan 等人[2]表明，在两个最受欢迎的自然语言推理(NLI)数据集、<a class="ae ky" href="https://nlp.stanford.edu/projects/snli/" rel="noopener ugc nofollow" target="_blank"> SNLI </a>(斯坦福·NLI)和<a class="ae ky" href="https://cims.nyu.edu/~sbowman/multinli/" rel="noopener ugc nofollow" target="_blank"> MNLI </a>(多体裁 NLI)中出现了类似的<strong class="lb iu">虚假相关性。给定两个陈述，一个<em class="lv">前提</em>和一个<em class="lv">假设，</em>自然语言推理的任务是决定它们之间的关系:<em class="lv">蕴涵、矛盾</em>或<em class="lv">中立。</em>以下是 MNLI 数据集中的一个示例:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/0d5cafd48f56a593938b7d8bb871c2b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QcKLUhUsfpHEtsZpaFZgvA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://cims.nyu.edu/~sbowman/multinli/" rel="noopener ugc nofollow" target="_blank"> MNLI 数据集</a>的示例</p></figure><p id="2ffb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解决 NLI 问题需要理解前提和假设之间的微妙联系。然而，Gururangan 等人[2]揭示，<strong class="lb iu">当模型仅显示假设时，它们在 SNLI 上可以达到高达 67%的准确度，在 MNLI 上可以达到 53%的准确度</strong>。这明显高于最频繁类基线(~35%)，暴露了数据集中不可否认的缺陷。</p><p id="8923" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是怎么发生的？SNLI 和 MNLI 都是众包；给人类一个前提，要求他们提出三个假设，每个标签一个。这又把我们带回了前提“狗在睡觉”。你会如何反驳它？“狗没有睡觉”是一个完全合理的候选词。然而，如果否定一直作为一种启发来应用，模型就学会了通过简单地检查假设中“不是”的出现来检测矛盾，甚至不需要阅读前提就可以获得高准确度。</p><p id="7234" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Gururangan 等人[2]揭示了其他几个这样的注释人工制品:</p><ul class=""><li id="751e" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu no mc md me bi translated">蕴涵假设是通过<strong class="lb iu">概括在前提中发现的词语</strong>(<em class="lv">狗→动物，3 →一些，女人→人</em>)产生的，使得仅从假设中就可以识别蕴涵。</li><li id="7a33" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated">中性假设是通过<strong class="lb iu">注入修饰语</strong> ( <em class="lv">高，第一，最</em> ) <em class="lv"> </em>而产生的，作为一种简单的方法来引入不被前提所包含但又不与之矛盾的信息。</li></ul><p id="b5e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管有这些发现，MNLI 仍然在<a class="ae ky" href="https://gluebenchmark.com/leaderboard" rel="noopener ugc nofollow" target="_blank"> GLUE 排行榜</a>之下，这是自然语言处理最流行的基准之一。与其他 GLUE 语料库(约 400，000 个数据实例)相比，MNLI 具有相当大的规模，因此在摘要中非常突出，并用于消融研究。虽然它的缺点开始被更广泛地认识到，但在我们找到更好的替代品之前，它不太可能失去它的受欢迎程度。</p><h1 id="5713" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">偏见和代表性不足</h1><p id="22c7" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在过去的几年里，机器学习中的偏见已经在多个维度上暴露出来，包括性别和种族。为了应对有偏见的单词嵌入和模型行为，研究社区已经将越来越多的努力指向偏见缓解，如 Sun 等人[3]在其<a class="ae ky" href="https://www.aclweb.org/anthology/P19-1159/" rel="noopener ugc nofollow" target="_blank">综合文献综述</a>中所述。</p><p id="e05d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2018 年图灵奖的共同获奖者 Yann LeCun 指出，有偏差的数据导致有偏差的模型行为:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="85a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他的推文吸引了研究界的大量参与，反应不一。一方面，人们几乎一致承认在许多数据集中确实存在偏见。另一方面，一些人不同意偏见仅仅源于数据的暗示，还指责建模和评估选择，以及设计和构建模型的人的无意识偏见。Yann LeCun 后来澄清说，他不认为数据偏差是模型中<em class="lv">社会</em>偏差的唯一原因:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="0f6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管正在讨论的数据集是用于计算机视觉的图像语料库，但自然语言处理同样会受到有偏见的数据集的影响。暴露出性别偏见的一个突出任务是<em class="lv">共指消解</em>，其中指称表达(如代词)必须与文本中提到的实体相关联。下面是 Webster 等人的一个例子[4]:</p><blockquote class="nh ni nj"><p id="43f5" class="kz la lv lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated">五月，藤泽作为球队的队长加入了本桥麻里的溜冰场，从轻井泽回到她曾经度过初中时光的北见。</p></blockquote><p id="e905" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作者指出，维基百科上不到 15%的传记是关于女性的，而且他们倾向于比关于男性的页面更突出地讨论婚姻和离婚。鉴于许多 NLP 数据集是从维基百科中提取的，这影响了许多下游任务。特别是对于共指消解来说，缺少女性代词或者它们与某些定型的关联是有问题的。例如，你如何解释这句话“当玛丽走进房间时，她看到了她的医生”？</p><p id="df36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从<em class="lv">训练</em>数据中消除偏差是一个尚未解决的问题。首先，因为我们不能详尽无遗地列举偏见表现的轴；除了性别和种族之外，还有许多其他微妙的方面会引起偏见(年龄、专有名称、职业等。).第二，即使我们选择了一个像性别这样的单一轴，消除偏见将意味着要么丢弃大部分数据，要么应用容易出错的试探法将男性代词变成代表不足的性别代词。相反，研究界目前正专注于产生无偏的<em class="lv">评估</em>数据集，因为它们较小的规模更有利于人工干预。这至少让我们有能力更真实地测量我们的模型的性能，通过人口的代表性样本。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><p id="1708" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">构建自然语言数据集是一个永无止境的过程:我们不断地收集数据，验证数据，承认数据的缺点并解决它们。然后，每当有新的来源时，我们就冲洗并重复。与此同时，我们取得了进展。上面提到的所有数据集，尽管有缺陷，但不可否认地帮助推动了自然语言理解的发展。</p><h1 id="ea20" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">参考</h1><ol class=""><li id="dcad" class="lw lx it lb b lc nc lf nd li ny lm nz lq oa lu mb mc md me bi translated">Lewis 等人，<a class="ae ky" href="https://arxiv.org/abs/2008.02637" rel="noopener ugc nofollow" target="_blank">开放领域问答数据集的问答测试序列重叠</a> (2020)</li><li id="8f79" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">Gururangan 等人，<a class="ae ky" href="https://www.aclweb.org/anthology/N18-2017.pdf" rel="noopener ugc nofollow" target="_blank">自然语言推理数据中的标注工件</a> (2017)</li><li id="8bd2" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">孙等，<a class="ae ky" href="https://arxiv.org/abs/1906.08976" rel="noopener ugc nofollow" target="_blank">减轻自然语言处理中的性别偏见:文献综述</a> (2019)</li><li id="d69b" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">韦伯斯特等人，<a class="ae ky" href="https://arxiv.org/abs/1810.05201" rel="noopener ugc nofollow" target="_blank">注意差距:性别歧义代词的平衡语料库</a> (2018)</li></ol></div></div>    
</body>
</html>