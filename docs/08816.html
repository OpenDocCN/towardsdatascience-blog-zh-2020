<html>
<head>
<title>Understanding and Implementing LeNet-5 CNN Architecture (Deep Learning)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解和实现LeNet-5 CNN架构(深度学习)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-and-implementing-lenet-5-cnn-architecture-deep-learning-a2d531ebc342?source=collection_archive---------3-----------------------#2020-06-25">https://towardsdatascience.com/understanding-and-implementing-lenet-5-cnn-architecture-deep-learning-a2d531ebc342?source=collection_archive---------3-----------------------#2020-06-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="bff4" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">技术和代码</h2><div class=""/><div class=""><h2 id="2e5b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在本文中，我们使用定制实现的LeNet-5神经网络架构在MNIST数据集上执行图像分类。</h2></div><blockquote class="kr ks kt"><p id="f9f4" class="ku kv kw kx b ky kz kd la lb lc kg ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><a class="ae lr" href="https://www.oreilly.com/live-events/practical-introduction-to-the-world-of-computer-vision-and-deep-learning-with-tensorflow-keras/0636920060577/0636920061406/" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd">在我主持的这个现场培训环节，用TensorFlow和Keras学习AI和深度学习的基础知识。</strong>T3】</a></p></blockquote><h1 id="20b0" class="ls lt it bd lu lv lw lx ly lz ma mb mc ki md kj me kl mf km mg ko mh kp mi mj bi translated">介绍</h1><p id="4f41" class="pw-post-body-paragraph ku kv it kx b ky mk kd la lb ml kg ld mm mn lg lh mo mp lk ll mq mr lo lp lq im bi ms translated"><span class="l mt mu mv bm mw mx my mz na di"> L </span> eNet是由<a class="ae lr" href="http://yann.lecun.com/" rel="noopener ugc nofollow" target="_blank"> Yann LeCun </a>、<a class="ae lr" href="https://leon.bottou.org/start" rel="noopener ugc nofollow" target="_blank"> Leon Bottou </a>、<a class="ae lr" href="https://yoshuabengio.org/" rel="noopener ugc nofollow" target="_blank"> Yoshua Bengio </a>和<a class="ae lr" href="https://www.linkedin.com/in/patrick-haffner-bbb386/" rel="noopener ugc nofollow" target="_blank"> Patrick Haffner </a>在1998年的研究论文<a class="ae lr" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" rel="noopener ugc nofollow" target="_blank">中提出的。该论文的许多列出的作者继续为深度学习领域提供了几项重要的学术贡献。</a></p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nb"><img src="../Images/12faf95152d06ab636e2701144141e0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C8DqxI1kSreDMITzcAv-Bw.png"/></div></div><p class="nn no gj gh gi np nq bd b be z dk translated"><a class="ae lr" href="http://yann.lecun.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd nr">扬·勒昆</strong></a><strong class="bd nr"/><a class="ae lr" href="https://leon.bottou.org/start" rel="noopener ugc nofollow" target="_blank"><strong class="bd nr">莱昂·博图</strong></a><strong class="bd nr"/><a class="ae lr" href="https://www.linkedin.com/in/patrick-haffner-bbb386/" rel="noopener ugc nofollow" target="_blank"><strong class="bd nr">帕特里克·哈夫纳</strong> </a> <strong class="bd nr">，以及</strong> <a class="ae lr" href="https://yoshuabengio.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd nr">约华·本吉奥</strong> </a></p></figure><p id="5b72" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">本文将介绍原始论文中描述的LeNet-5 CNN架构，以及使用TensorFlow 2.0实现该架构。</p><p id="deaa" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">本文最后将利用实现的LeNet-5 CNN对来自MNIST数据集的图像进行分类。</p><h2 id="6acd" class="ns lt it bd lu nt nu dn ly nv nw dp mc mm nx ny me mo nz oa mg mq ob oc mi iz bi translated">这篇文章的内容:</h2><ul class=""><li id="5327" class="od oe it kx b ky mk lb ml mm of mo og mq oh lq oi oj ok ol bi translated"><strong class="kx jd"> <em class="kw">了解卷积神经网络内的组件</em> </strong></li><li id="da6b" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><strong class="kx jd"> <em class="kw">深度学习和机器学习常用术语的关键定义</em> </strong></li><li id="4b59" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><strong class="kx jd"> <em class="kw">原研究论文</em> </strong>中提出的对LeNet-5的理解</li><li id="0a3d" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><strong class="kx jd"> <em class="kw">用TensorFlow和Keras实现神经网络</em> </strong></li></ul><blockquote class="or"><p id="5cee" class="os ot it bd ou ov ow ox oy oz pa lq dk translated">本文中的内容是为各种水平的深度学习和机器学习学生编写的。</p></blockquote><p id="8803" class="pw-post-body-paragraph ku kv it kx b ky pb kd la lb pc kg ld mm pd lg lh mo pe lk ll mq pf lo lp lq im bi translated">对于那些渴望获得编码的人，向下滚动到'<em class="kw"> LeNet-5 TensorFlow实现'</em>部分。</p></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><h1 id="74c4" class="ls lt it bd lu lv pn lx ly lz po mb mc ki pp kj me kl pq km mg ko pr kp mi mj bi translated">卷积神经网络</h1><p id="3fdb" class="pw-post-body-paragraph ku kv it kx b ky mk kd la lb ml kg ld mm mn lg lh mo mp lk ll mq mr lo lp lq im bi translated">卷积神经网络是用于解决与图像相关联的任务的神经网络架构的标准形式。针对对象检测、人脸检测、姿态估计等任务的解决方案都有CNN架构变体。</p><p id="3053" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">CNN架构的一些特征使得它们在一些计算机视觉任务中更有利。我以前写过深入研究每个特征的文章。</p><ul class=""><li id="0a51" class="od oe it kx b ky kz lb lc mm ps mo pt mq pu lq oi oj ok ol bi translated"><a class="ae lr" rel="noopener" target="_blank" href="/understand-local-receptive-fields-in-convolutional-neural-networks-f26d700be16c"> <em class="kw">局部感受野</em> </a></li><li id="8121" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><a class="ae lr" rel="noopener" target="_blank" href="/you-should-understand-sub-sampling-layers-within-deep-learning-b51016acd551"> <em class="kw">子采样</em> </a></li><li id="335b" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><a class="ae lr" rel="noopener" target="_blank" href="/understanding-parameter-sharing-or-weights-replication-within-convolutional-neural-networks-cc26db7b645a"> <em class="kw">重量分担</em> </a></li></ul></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><h1 id="0cda" class="ls lt it bd lu lv pn lx ly lz po mb mc ki pp kj me kl pq km mg ko pr kp mi mj bi translated">LeNet-5</h1><p id="b0a7" class="pw-post-body-paragraph ku kv it kx b ky mk kd la lb ml kg ld mm mn lg lh mo mp lk ll mq mr lo lp lq im bi translated">LeNet-5 CNN架构由7层组成。层组成包括3个卷积层、2个子采样层和2个全连接层。</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pv"><img src="../Images/90622ddaae4c56402b19aa3ecf30a741.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y68ztClLF6ae7P53ayyFzQ.png"/></div></div><p class="nn no gj gh gi np nq bd b be z dk translated"><a class="ae lr" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" rel="noopener ugc nofollow" target="_blank"> LeNet-5架构</a></p></figure><p id="884e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">上图显示了LeNet-5架构的描述，如<a class="ae lr" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>中所示。</p><p id="8165" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">第一层是输入层——这通常不被认为是网络的一层，因为在这一层什么也学不到。输入层的构建是为了接收<em class="kw"> 32x32，</em>这些是传递到下一层的图像的尺寸。熟悉MNIST数据集的人会知道，MNIST数据集图像的尺寸为<em class="kw"> 28x28。为了</em>得到满足输入层要求的MNIST图像尺寸，对<em class="kw"> 28x28 </em>图像进行了填充。</p><p id="2a5c" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">研究论文中使用的灰度图像的像素值从0到255归一化到-0.1到1.175之间。归一化的原因是为了确保该批图像的平均值为0，标准偏差为1，这样做的好处是减少了训练时间。在下面的LeNet-5图像分类示例中，我们将归一化图像的像素值，使其取0到1之间的值。</p><p id="9de9" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">LeNet-5架构利用了两种重要的层结构:卷积层和子采样层。</p><ul class=""><li id="5901" class="od oe it kx b ky kz lb lc mm ps mo pt mq pu lq oi oj ok ol bi translated"><a class="ae lr" href="https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> <em class="kw">卷积层</em> </a></li><li id="df4f" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><a class="ae lr" rel="noopener" target="_blank" href="/you-should-understand-sub-sampling-layers-within-deep-learning-b51016acd551"> <em class="kw">子采样层</em> </a></li></ul><p id="70f5" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">在研究论文和下图中，卷积层用'<em class="kw"> Cx' </em>标识，子采样层用'<em class="kw"> Sx' </em>标识，其中'<em class="kw"> x' </em>是层在架构中的顺序位置。<em class="kw"> Fx' </em>用于识别完全连接的层。这种层识别的方法可以在上图中看到。</p><p id="c15e" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">官方的第一层卷积层<em class="kw"> C1 </em>产生6个特征图作为输出，并且具有<em class="kw"> 5x5的核大小。</em>内核/过滤器是窗口的名称，该窗口包含在权重值与输入值的卷积过程中使用的权重值。<em class="kw"> 5x5 </em>也表示卷积层内每个单元或神经元的局部感受野大小。第一卷积层产生的六个特征图的尺寸是<em class="kw"> 28x28。</em></p><p id="4719" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">一个子采样层'<em class="kw"> S2' </em>'跟在'<em class="kw"> C1' </em>层'之后。“<em class="kw">S2”</em>层将它从前一层接收的特征地图的维度减半；这就是通常所说的下采样。</p><p id="5087" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">‘<em class="kw">S2’</em>层也产生6个特征图，每个对应于从前一层作为输入传递的特征图。此<a class="ae lr" rel="noopener" target="_blank" href="/you-should-understand-sub-sampling-layers-within-deep-learning-b51016acd551">链接</a>包含更多关于子采样层的信息。</p><p id="85fa" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">有关LeNet-5其余层的更多信息，请参见实现部分。</p><p id="85d5" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated"><strong class="kx jd"> <em class="kw">下表总结了每一层的主要特性:</em> </strong></p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pw"><img src="../Images/826f568627f1c5b4398e4903a75d7e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ddbd4IrPvGrBNdcZtboLeA.png"/></div></div><p class="nn no gj gh gi np nq bd b be z dk translated">LeNet-5架构特性(按作者)</p></figure></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><h1 id="0d5c" class="ls lt it bd lu lv pn lx ly lz po mb mc ki pp kj me kl pq km mg ko pr kp mi mj bi translated">LeNet-5张量流实现</h1><p id="bb43" class="pw-post-body-paragraph ku kv it kx b ky mk kd la lb ml kg ld mm mn lg lh mo mp lk ll mq mr lo lp lq im bi translated">我们从导入我们将使用的库开始实施:</p><ul class=""><li id="75fb" class="od oe it kx b ky kz lb lc mm ps mo pt mq pu lq oi oj ok ol bi translated"><a class="ae lr" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd"><em class="kw">tensor flow</em></strong></a><em class="kw">:机器学习模型的实现、训练、部署的开源平台。</em></li><li id="e4e8" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><a class="ae lr" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd"><em class="kw">Keras</em></strong></a><em class="kw">:一个开源库，用于实现在CPU和GPU上同时运行的神经网络架构。</em></li><li id="462a" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><a class="ae lr" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kx jd"><em class="kw">Numpy</em></strong></a><em class="kw">:一个用n维数组进行数值计算的库。</em></li></ul><pre class="nc nd ne nf gt px py pz qa aw qb bi"><span id="a705" class="ns lt it py b gy qc qd l qe qf">import tensorflow as tf<br/>from tensorflow import keras<br/>import numpy as np</span></pre><p id="8c14" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">接下来，我们使用Keras库加载<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data" rel="noopener ugc nofollow" target="_blank"> MNIST </a>数据集。Keras图书馆有一套易于使用的数据集。</p><p id="6cec" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">我们还需要将数据集划分为测试、验证和训练。下面是每个分区类别的一些快速描述。</p><ul class=""><li id="8197" class="od oe it kx b ky kz lb lc mm ps mo pt mq pu lq oi oj ok ol bi translated"><strong class="kx jd"> <em class="kw">训练数据集</em> </strong> <em class="kw">:这是我们用来直接训练神经网络的一组数据集。训练数据是指在训练期间暴露给神经网络的数据集分区。</em></li><li id="ee17" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><strong class="kx jd"> <em class="kw">验证数据集</em> </strong> <em class="kw">:这组数据集在训练期间被用来评估网络在各种迭代中的性能。</em></li><li id="2e70" class="od oe it kx b ky om lb on mm oo mo op mq oq lq oi oj ok ol bi translated"><strong class="kx jd"> <em class="kw">测试数据集</em> </strong> <em class="kw">:数据集的这个分区在训练阶段完成后评估我们网络的性能。</em></li></ul><p id="0a93" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">还需要将数据集中图像的像素强度从0–255到0–1的值范围进行归一化。</p><pre class="nc nd ne nf gt px py pz qa aw qb bi"><span id="c6ae" class="ns lt it py b gy qc qd l qe qf">(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()<br/>train_x = train_x / 255.0<br/>test_x = test_x / 255.0</span><span id="ad87" class="ns lt it py b gy qg qd l qe qf">train_x = tf.expand_dims(train_x, 3)<br/>test_x = tf.expand_dims(test_x, 3)</span><span id="ede7" class="ns lt it py b gy qg qd l qe qf">val_x = train_x[:5000]<br/>val_y = train_y[:5000]</span></pre><p id="98e7" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">在上面的代码片段中，我们扩展了训练和数据集的维度。我们这样做的原因是，在训练和评估阶段，网络期望图像成批呈现；额外的维度代表一批图像的数量。</p><h2 id="7527" class="ns lt it bd lu nt nu dn ly nv nw dp mc mm nx ny me mo nz oa mg mq ob oc mi iz bi translated">下面的代码是我们实现实际的基于LeNet-5的神经网络的主要部分。</h2><p id="fbe9" class="pw-post-body-paragraph ku kv it kx b ky mk kd la lb ml kg ld mm mn lg lh mo mp lk ll mq mr lo lp lq im bi translated">Keras提供了实现分类模型所需的工具。Keras提出了一种顺序API，用于将神经网络的层堆叠在彼此之上。</p><pre class="nc nd ne nf gt px py pz qa aw qb bi"><span id="8088" class="ns lt it py b gy qc qd l qe qf">lenet_5_model = keras.models.Sequential([<br/>    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='tanh', input_shape=train_x[0].shape, padding='same'), #C1<br/>    keras.layers.AveragePooling2D(), #S2<br/>    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='tanh', padding='valid'), #C3<br/>    keras.layers.AveragePooling2D(), #S4<br/>    keras.layers.Conv2D(120, kernel_size=5, strides=1, activation='tanh', padding='valid'), #C5<br/>    keras.layers.Flatten(), #Flatten    <br/>    keras.layers.Dense(84, activation='tanh'), #F6<br/>    keras.layers.Dense(10, activation='softmax') #Output layer<br/>])</span></pre><p id="be29" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">我们首先将变量'<code class="fe qh qi qj py b">lenet_5_model'</code>赋给<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential" rel="noopener ugc nofollow" target="_blank"> tf.keras.Sequential </a>类构造函数的一个实例。</p><p id="6b83" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">在类构造函数中，我们接着定义模型中的层。</p><p id="5c96" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">C1层由线<code class="fe qh qi qj py b">keras.layers.Conv2D(6, kernel_size=5, strides=1, activation='tanh', input_shape=train_x[0].shape, padding='same')</code>定义。我们使用<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D" rel="noopener ugc nofollow" target="_blank"> tf.keras.layers.Conv2D </a>类来构建网络中的卷积层。我们传递几个论点，在这里描述为<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D#arguments_1" rel="noopener ugc nofollow" target="_blank"/>。</p><ul class=""><li id="19b9" class="od oe it kx b ky kz lb lc mm ps mo pt mq pu lq oi oj ok ol bi translated"><strong class="kx jd"> <em class="kw">激活函数</em> </strong> <em class="kw">:将神经元的结果或信号转化为归一化输出的数学运算。激活函数是在网络中引入非线性的神经网络的组成部分。激活函数的引入使得神经网络具有更强的表达能力和解决复杂的函数。</em></li></ul><p id="a65c" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">其余的卷积层遵循与C <em class="kw"> 1 </em>相同的层定义，只是为参数输入了一些不同的值。</p><p id="7b19" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">在介绍LeNet-5架构的<a class="ae lr" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>中，使用了子采样层。在子采样层内，取落在2x2池窗口内的像素值的平均值，之后，该值乘以系数值。最终结果中会添加一个偏差，所有这些都是在值通过激活函数之前完成的。</p><p id="2aa6" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">但是在我们实现的LeNet-5神经网络中，我们使用了<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D" rel="noopener ugc nofollow" target="_blank">TF . keras . layers . average pooling 2d</a>构造函数。我们不向构造函数传递任何参数，因为在调用构造函数时，必需参数的一些默认值已经初始化。请记住，网络中的池化图层的作用是在要素地图穿过网络时对其进行缩减采样。</p><p id="4148" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">网络中还有两种类型的图层，平坦图层和密集图层。</p><p id="538b" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">展平层是用类构造器<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten" rel="noopener ugc nofollow" target="_blank">TF . keras . layers . flatten</a>创建的。</p><p id="a604" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">该层的目的是将其输入转换为一维数组，该数组可以输入到后续的密集层中。</p><p id="8cc7" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">密集层每层都有特定数量的单元或神经元，F6有84个，而输出层有10个单元。</p><p id="dfb7" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">最后一个密集图层有十个单元，对应于MNIST数据集中的类的数量。输出层的激活函数是softmax激活函数。</p><ul class=""><li id="2089" class="od oe it kx b ky kz lb lc mm ps mo pt mq pu lq oi oj ok ol bi translated"><strong class="kx jd"> Softmax </strong>:激活函数，用于导出输入向量中一组数字的概率分布。softmax激活函数的输出是一个向量，其中它的一组值表示一个类/事件发生的概率。向量中的值加起来都是1。</li></ul><p id="3a8d" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated"><strong class="kx jd">现在我们可以编译和构建模型了。</strong></p><pre class="nc nd ne nf gt px py pz qa aw qb bi"><span id="ddc8" class="ns lt it py b gy qc qd l qe qf">lenet_5_model.compile(optimizer=’adam’, loss=keras.losses.sparse_categorical_crossentropy, metrics=[‘accuracy’])</span></pre><p id="b2ff" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">Keras通过我们之前实例化的模型对象提供了'<em class="kw">编译'</em>方法。compile函数支持我们在幕后实现的模型的实际构建，该模型具有一些额外的特征，如损失函数、优化器和指标。</p><p id="6b1f" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">为了训练网络，我们利用损失函数来计算网络提供的预测值和训练数据的实际值之间的差异。</p><p id="9944" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">伴随着优化算法(<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam" rel="noopener ugc nofollow" target="_blank"> Adam </a>)的损失值有助于对网络内的权重进行多次改变。支持因素，如动量和学习率时间表，通过使损失值尽可能接近零，提供了使网络训练收敛的理想环境。</p><p id="c0fb" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">在训练过程中，我们还将在每个时期后使用之前创建的评估数据集分区来验证我们的模型</p><pre class="nc nd ne nf gt px py pz qa aw qb bi"><span id="c89a" class="ns lt it py b gy qc qd l qe qf">lenet_5_model.fit(train_x, train_y, epochs=5, validation_data=(val_x, val_y))</span></pre><p id="b4e9" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">训练之后，您会注意到您的模型达到了90%以上的验证准确率。但是，为了更明确地验证模型在未知数据集上的性能，我们将在之前创建的测试数据集分区上评估经过训练的模型。</p><pre class="nc nd ne nf gt px py pz qa aw qb bi"><span id="240a" class="ns lt it py b gy qc qd l qe qf">lenet_5_model.evaluate(test_x, test_y)<br/>&gt;&gt; [0.04592850968674757, 0.9859]</span></pre><p id="5e94" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">在训练了我的模型之后，我能够在测试数据集上达到98%的准确率，这对于这样一个简单的网络来说相当有用。</p><p id="07ae" class="pw-post-body-paragraph ku kv it kx b ky kz kd la lb lc kg ld mm lf lg lh mo lj lk ll mq ln lo lp lq im bi translated">下面是本文代码的GitHub链接:</p><div class="qk ql gp gr qm qn"><a href="https://github.com/RichmondAlake/tensorflow_2_tutorials/blob/master/13_lenet-5.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="qo ab fo"><div class="qp ab qq cl cj qr"><h2 class="bd jd gy z fp qs fr fs qt fu fw jc bi translated">Richmond alake/tensor flow _ 2 _教程</h2><div class="qu l"><h3 class="bd b gy z fp qs fr fs qt fu fw dk translated">permalink dissolve GitHub是超过5000万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="qv l"><p class="bd b dl z fp qs fr fs qt fu fw dk translated">github.com。</p></div></div><div class="qw l"><div class="qx l qy qz ra qw rb nl qn"/></div></div></a></div></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><h1 id="db7b" class="ls lt it bd lu lv pn lx ly lz po mb mc ki pp kj me kl pq km mg ko pr kp mi mj bi translated">我希望这篇文章对你有用。</h1><p id="ed23" class="pw-post-body-paragraph ku kv it kx b ky mk kd la lb ml kg ld mm mn lg lh mo mp lk ll mq mr lo lp lq im bi translated">要联系我或找到更多类似本文的内容，请执行以下操作:</p><ol class=""><li id="9407" class="od oe it kx b ky kz lb lc mm ps mo pt mq pu lq rc oj ok ol bi translated">订阅我的<a class="ae lr" href="https://www.youtube.com/channel/UCNNYpuGCrihz_YsEpZjo8TA" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd"> YouTube频道</strong> </a>即将发布的视频内容<a class="ae lr" href="https://www.youtube.com/channel/UCNNYpuGCrihz_YsEpZjo8TA" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd">这里</strong> </a></li><li id="339b" class="od oe it kx b ky om lb on mm oo mo op mq oq lq rc oj ok ol bi translated">跟着我上<a class="ae lr" href="https://medium.com/@richmond.alake" rel="noopener"> <strong class="kx jd">中</strong> </a></li><li id="e7d8" class="od oe it kx b ky om lb on mm oo mo op mq oq lq rc oj ok ol bi translated">在<a class="ae lr" href="https://www.linkedin.com/in/richmondalake/" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jd"> LinkedIn </strong> </a>上连接并联系我</li></ol></div></div>    
</body>
</html>