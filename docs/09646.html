<html>
<head>
<title>Deep Reinforcement Learning With Python | Part 2 | Creating &amp; Training The RL Agent Using Deep Q Network (DQN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 进行深度强化学习|第 2 部分|使用深度 Q 网络创建和训练 RL 代理(DQN)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-reinforcement-learning-with-python-part-2-creating-training-the-rl-agent-using-deep-q-d8216e59cf31?source=collection_archive---------6-----------------------#2020-07-09">https://towardsdatascience.com/deep-reinforcement-learning-with-python-part-2-creating-training-the-rl-agent-using-deep-q-d8216e59cf31?source=collection_archive---------6-----------------------#2020-07-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/e55bf90ee069dfaabe75e058efccb7d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a9F8vOTfpDEM52eW5SSXAQ.jpeg"/></div></div></figure><div class=""/><p id="4b20" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi kz translated"><span class="l la lb lc bm ld le lf lg lh di">在</span><a class="ae li" href="https://bit.ly/3eAg32L" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf"><em class="lj">第一部分</em> </strong> </a> <strong class="kd jf"> <em class="lj">，</em> </strong>我们一行一行的讲解了游戏环境的制作。在这一部分，我们将学习如何创建和训练深度 Q 网络(DQN ),并使代理能够使用它，以便成为我们游戏中的专家。</p><div class="is it gp gr iu lk"><a rel="noopener follow" target="_blank" href="/reinforcement-learning-with-python-part-1-creating-the-environment-dad6e0237d2d"><div class="ll ab fo"><div class="lm ab ln cl cj lo"><h2 class="bd jf gy z fp lp fr fs lq fu fw jd bi translated">使用 Python 进行深度强化学习|第 1 部分|创建环境</h2><div class="lr l"><h3 class="bd b gy z fp lp fr fs lq fu fw dk translated">设计和建立一个游戏环境，允许 RL 代理在上面训练和玩。</h3></div><div class="ls l"><p class="bd b dl z fp lp fr fs lq fu fw dk translated">towardsdatascience.com</p></div></div><div class="lt l"><div class="lu l lv lw lx lt ly ja lk"/></div></div></a></div><p id="704f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这一部分，我们将讨论:</p><p id="7134" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">1-为什么是深 Q 网(DQN)？</p><p id="2560" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">2-什么是 DQN？</p><p id="d398" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">3-DQN 是如何工作的？</p><p id="a13c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">4-解释我们的 DQN 建筑。</p><p id="9e26" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">5-解释代理类。</p><p id="67f2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">6-培训代理。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="e973" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">有人可能会问“你为什么不用 Q-Learning 而不用 DQN？”这个问题的答案取决于许多因素，例如:</p><h2 id="85f0" class="mg mh je bd mi mj mk dn ml mm mn dp mo km mp mq mr kq ms mt mu ku mv mw mx my bi translated">环境有多复杂？</h2><p id="aa7c" class="pw-post-body-paragraph kb kc je kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated">在我们的例子中，我们可以用两种方式回答这个问题:</p><ul class=""><li id="c01c" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated">如果我们希望 RL 代理的输入与人类的输入一样接近，我们将选择输入作为字段的数组表示。</li></ul><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/856b2c68c1d1d53cb004ae370ae14a9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vPtWdTFjDIozwWEOKs0eDg.png"/></div></div><p class="ns nt gj gh gi nu nv bd b be z dk translated">RL 代理所看到的与人类玩家所看到的</p></figure><p id="1fec" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这种情况下，当我们使用 Q-Learning 时，环境会很复杂，而且由于 Q-Table 非常大，所以不可能存储它。为了证明这一点，考虑以下计算:</p><blockquote class="nw nx ny"><p id="8b9e" class="kb kc lj kd b ke kf kg kh ki kj kk kl nz kn ko kp oa kr ks kt ob kv kw kx ky im bi translated"><strong class="kd jf">输入数组的状态数= </strong>(数组中每一项可以取的不同值的个数)^(宽度*高度)</p><p id="42c2" class="kb kc lj kd b ke kf kg kh ki kj kk kl nz kn ko kp oa kr ks kt ob kv kw kx ky im bi translated"><strong class="kd jf">输入数组可以具有的状态数= </strong> 4 ^ 10 * 20</p><p id="0dc9" class="kb kc lj kd b ke kf kg kh ki kj kk kl nz kn ko kp oa kr ks kt ob kv kw kx ky im bi translated">= 4 ^ 200 = 2.58225e120</p><p id="5cfa" class="kb kc lj kd b ke kf kg kh ki kj kk kl nz kn ko kp oa kr ks kt ob kv kw kx ky im bi translated"><strong class="kd jf">Q-表格大小</strong> =动作空间大小*输入数组可以具有的状态数</p><p id="36b8" class="kb kc lj kd b ke kf kg kh ki kj kk kl nz kn ko kp oa kr ks kt ob kv kw kx ky im bi translated"><strong class="kd jf">Q-表格尺寸</strong>= 5 * 2.58225 e120 = 1.291125 e121</p><p id="0ae2" class="kb kc lj kd b ke kf kg kh ki kj kk kl nz kn ko kp oa kr ks kt ob kv kw kx ky im bi translated">要存储这个数量的数组(每项 8 位)，我们需要 9.39417077e109 太字节。</p></blockquote><p id="88eb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是为什么我们简单地使用 DQN 而不是 Q-Learning。</p><ul class=""><li id="a0f5" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated">另一方面，如果你想使用 Q-Learning，使用另一种输入会更有效。例如，您可以使用球员和球洞的<em class="lj"> X </em>坐标、球员的宽度和球洞的宽度。这种方式的输入比使用数组表示简单得多。</li></ul></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="545b" class="oc mh je bd mi od oe of ml og oh oi mo oj ok ol mr om on oo mu op oq or mx os bi translated">什么是 DQN？</h1><p id="f939" class="pw-post-body-paragraph kb kc je kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated">它只是一个普通的神经网络，唯一的区别是它的输入是环境的状态，它的输出是为了最大化当前步骤的回报而执行的最佳动作。</p><p id="01fb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们通过使用<strong class="kd jf">经验重放和重放记忆来做到这一点，</strong>这些概念将在下一节解释。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="cdd4" class="oc mh je bd mi od oe of ml og oh oi mo oj ok ol mr om on oo mu op oq or mx os bi translated">深度 Q 网(DQN)如何运作？</h1><p id="e7ed" class="pw-post-body-paragraph kb kc je kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated">要完全理解 DQN 是如何工作的，你需要知道一些与 DQN 相关的概念:</p><h2 id="555d" class="mg mh je bd mi mj mk dn ml mm mn dp mo km mp mq mr kq ms mt mu ku mv mw mx my bi translated">1-体验回放和回放记忆:</h2><p id="f183" class="pw-post-body-paragraph kb kc je kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated">类似于人类通过使用他们以前经验的记忆来学习的方式，dqn 也使用这种技术。</p><p id="21c8" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">经验回放:</strong>代理执行每一步后收集的一些数据，这个<strong class="kd jf">经验回放</strong>包含【当前状态，当前动作，步骤回报，下一个状态】。</p><p id="f40d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">重放存储器:</strong>是一堆<em class="lj">n</em>T8】经验重放，重放存储器主要用于通过获得重放的随机样本来训练 DQN，并使用这些重放作为 DQN 的输入。</p><p id="bd5f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">为什么使用随机重放样本而不是顺序重放？</strong></p><ul class=""><li id="611a" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated">当使用顺序重放时，DQN 倾向于过度拟合而不是一般化。</li></ul><blockquote class="nw nx ny"><p id="929c" class="kb kc lj kd b ke kf kg kh ki kj kk kl nz kn ko kp oa kr ks kt ob kv kw kx ky im bi translated">使用重放记忆的一个关键原因是打破连续样本之间的相关性。</p></blockquote><h2 id="3223" class="mg mh je bd mi mj mk dn ml mm mn dp mo km mp mq mr kq ms mt mu ku mv mw mx my bi translated">2-模型和目标模型:</h2><p id="7f74" class="pw-post-body-paragraph kb kc je kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated">为了获得一致的结果，我们将训练两个模型，第一个模型<strong class="kd jf">【模型】</strong>将在代理做出每一步后拟合，另一方面，第二个模型<strong class="kd jf">【目标 _ 模型】</strong>每 n 步加载<strong class="kd jf">【模型】</strong>的权重(n = UPDATE_TARGET_EVERY)。</p><p id="43d5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们这样做是因为从一开始，一切都是随机的，从<strong class="kd jf">“模型”</strong>的初始权重到代理执行的动作。这种随机性使得<strong class="kd jf">模型</strong>更难执行好的动作，但是当我们有另一个模型每 n 步使用第一个模型获得的知识时，我们就有了某种程度的一致性。</p><p id="d92a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在我们解释了一些关键概念知道我们可以总结学习的过程后，我将使用来自<a class="ae li" href="https://deeplizard.com/learn/video/xVkPh9E9GfE" rel="noopener ugc nofollow" target="_blank">这篇精彩博客</a>的 DeepLizard 的话:</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="ced4" class="oc mh je bd mi od oe of ml og oh oi mo oj ok ol mr om on oo mu op oq or mx os bi translated">解释我们的 DQN 建筑:</h1><p id="2502" class="pw-post-body-paragraph kb kc je kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated">对于我们的 DQN，尝试了许多架构，其中许多都不工作，但最终有一个架构被证明工作良好。</p><h2 id="d115" class="mg mh je bd mi mj mk dn ml mm mn dp mo km mp mq mr kq ms mt mu ku mv mw mx my bi translated">失败的尝试次数:</h2><ul class=""><li id="6998" class="ne nf je kd b ke mz ki na km ov kq ow ku ox ky nj nk nl nm bi translated">最初的失败之一是具有两个输出层的架构，第一个输出层负责预测最佳移动(向左、向右或不移动)，而另一个输出层负责预测最佳宽度改变动作(增加宽度、减小宽度、不改变宽度)。</li><li id="ae2f" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated">另一个失败包括太深的网络，除了他们缓慢的训练过程，他们的表现太差。</li></ul><h2 id="a42f" class="mg mh je bd mi mj mk dn ml mm mn dp mo km mp mq mr kq ms mt mu ku mv mw mx my bi translated">寻找更好的架构:</h2><p id="6259" class="pw-post-body-paragraph kb kc je kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated">在一些失败之后，进行了网格搜索，以找到能够胜过玩游戏的人的架构，下表显示了一些网格搜索的结果:</p><p id="2cda" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="lj">注意:下面的表格是为了最后显示最佳结果而排列的。</em></p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="e784" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从第一次网格搜索的结果，我们可以清楚地看到，复杂和深度网络未能学会如何玩游戏，另一方面，最简单的网络工作得最好。</p><p id="bfb6" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用第一次网格搜索的结果，执行了另一次网格搜索，得到了一些好的结果:</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="0bd3" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从这个结果我们可以看出，<strong class="kd jf"> <em class="lj">最好的只有</em></strong><strong class="kd jf"><em class="lj"/></strong>并不能提高模型的性能，另一方面，同时使用 ECC(ε条件约束)和 EF(ε波动)可以提高模型的性能。</p><p id="eeb5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将在另一篇博客中讨论 ECC 和 EF。</p><p id="478e" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">其他一些网格搜索结果:</p><ul class=""><li id="d8de" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated">测试<strong class="kd jf"> <em class="lj">【仅最佳】:</em> </strong></li></ul><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure><ul class=""><li id="1569" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated">测试更简单的网络:</li></ul><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="de78" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在所有这些网格搜索之后，我们最终决定使用一种架构，其中一个卷积层有 32 个滤波器，批量大小为 128，两个密集(全连接)层各有 32 个节点，我们将同时使用 ECC 和 EF。</p><h2 id="c010" class="mg mh je bd mi mj mk dn ml mm mn dp mo km mp mq mr kq ms mt mu ku mv mw mx my bi translated">网络摘要:</h2><pre class="no np nq nr gt pd pe pf pg aw ph bi"><span id="ed9a" class="mg mh je pe b gy pi pj l pk pl">Model: "model_1"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>input_1 (InputLayer)         (None, 20, 10, 1)         0         <br/>_________________________________________________________________<br/>conv2d_1 (Conv2D)            (None, 18, 8, 32)         320       <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 18, 8, 32)         0         <br/>_________________________________________________________________<br/>flatten_1 (Flatten)          (None, 4608)              0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 32)                147488    <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 32)                1056      <br/>_________________________________________________________________<br/>output (Dense)               (None, 5)                 165       <br/>=================================================================<br/>Total params: 149,029<br/>Trainable params: 149,029<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><ul class=""><li id="466f" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated"><strong class="kd jf">输入层:</strong>输入形状与代表游戏场地的数组形状相同<em class="lj"> (20 乘 10)。</em></li><li id="5c52" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><strong class="kd jf">卷积层:</strong>一个 Conv2D 层，有 32 个滤波器，大小为<em class="lj"> 2*2 </em></li><li id="a997" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated">辍学率为 20%</li><li id="5280" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><strong class="kd jf">展平</strong>:将 2D 卷积层的输出转换成 1D 数组。</li><li id="e9c0" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><strong class="kd jf">密集(全连接)层</strong>:两个密集层各有 32 个节点。</li><li id="7d92" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><strong class="kd jf">输出层:</strong>输出层包含 5 个输出节点，每个节点代表一个动作<em class="lj">【无动作，左移，右移，减宽，增宽】</em></li></ul></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="91fc" class="oc mh je bd mi od oe of ml og oh oi mo oj ok ol mr om on oo mu op oq or mx os bi translated"><strong class="ak">讲解<em class="pm">代理</em>类</strong>类:</h1><p id="ccda" class="pw-post-body-paragraph kb kc je kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated"><strong class="kd jf">代理</strong>类是一个包含所有与代理相关的东西的类，比如 DQN、训练函数、重放记忆和其他东西，下面是这个类的逐行解释。</p><h2 id="4667" class="mg mh je bd mi mj mk dn ml mm mn dp mo km mp mq mr kq ms mt mu ku mv mw mx my bi translated">模型创建:</h2><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="0aad" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这两个函数用于创建给定两个列表的模型:</p><ul class=""><li id="74e1" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated">conv 列表:该列表的每一项定义了卷积层的滤波器数量。</li><li id="0e02" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><strong class="kd jf">密集列表:</strong>该列表的每一项定义了密集层的节点数。</li></ul><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="dce3" class="oc mh je bd mi od oe of ml og oh oi mo oj ok ol mr om on oo mu op oq or mx os bi translated">培训代理:</h1><p id="5e49" class="pw-post-body-paragraph kb kc je kd b ke mz kg kh ki na kk kl km nb ko kp kq nc ks kt ku nd kw kx ky im bi translated">为了保持跟踪最佳模型并保存它以在训练后使用，使用以下函数:</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="7989" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来是一些常量:</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="be45" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来是将被训练的架构:</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="8477" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">将使用前面的三种架构执行网格搜索，网格搜索的结果存储在数据帧中。</p><figure class="no np nq nr gt iv"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="9701" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">查看我的 Github 代码库:</p><div class="is it gp gr iu lk"><a href="https://github.com/ModMaamari/reinforcement-learning-using-python" rel="noopener  ugc nofollow" target="_blank"><div class="ll ab fo"><div class="lm ab ln cl cj lo"><h2 class="bd jf gy z fp lp fr fs lq fu fw jd bi translated">ModMaamari/强化-学习-使用-python</h2><div class="lr l"><h3 class="bd b gy z fp lp fr fs lq fu fw dk translated">使用 Python 的强化学习。通过以下方式为 ModMaamari/强化-学习-使用-python 开发做出贡献…</h3></div><div class="ls l"><p class="bd b dl z fp lp fr fs lq fu fw dk translated">github.com</p></div></div><div class="lt l"><div class="pn l lv lw lx lt ly ja lk"/></div></div></a></div></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="6ee9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">概括地说，我们讨论了:</p><ul class=""><li id="5f1f" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated">选择 DQN 而不是 Q-Learning 的原因。</li><li id="12eb" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated">DQNs，简单解释一下。</li><li id="0605" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated">dqn 是如何工作的？</li><li id="04f8" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated">我们使用了什么架构，为什么？</li><li id="91e6" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><strong class="kd jf"> <em class="lj">代理</em> </strong>类，解释代码。</li><li id="475a" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated">训练模型和网格搜索最佳模型的过程。</li></ul></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="a9e2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在下一部分，我们将:</p><ul class=""><li id="b836" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated">使用 Tensorboard 分析训练结果。</li><li id="a299" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated">尝试最好的模式。</li></ul></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="ff28" class="oc mh je bd mi od oe of ml og oh oi mo oj ok ol mr om on oo mu op oq or mx os bi translated">资源:</h1><ul class=""><li id="e03f" class="ne nf je kd b ke mz ki na km ov kq ow ku ox ky nj nk nl nm bi translated"><a class="ae li" href="https://www.youtube.com/watch?v=t3fbETsIBCY&amp;list=PLQVvvaa0QuDezJFIOU5wDdfy4e9vdnx-7&amp;index=5" rel="noopener ugc nofollow" target="_blank"> <strong class="kd jf">深度 Q 学习 w/ DQN —强化学习 p.5 </strong> </a></li><li id="5055" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://www.youtube.com/watch?v=qfovbG84EBg&amp;list=PLQVvvaa0QuDezJFIOU5wDdfy4e9vdnx-7&amp;index=6" rel="noopener ugc nofollow" target="_blank"> <strong class="kd jf">培训&amp;测试深度强化学习(DQN)代理—强化学习 p.6 </strong> </a></li><li id="83cd" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://www.youtube.com/watch?v=wrBUkpiRvCA&amp;list=PLZbbT5o_s2xoWNVdDudn51XM8lOuZ_Njv&amp;index=11" rel="noopener ugc nofollow" target="_blank"> <strong class="kd jf">深度 Q 学习——结合神经网络和强化学习</strong> </a></li><li id="752e" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://www.youtube.com/watch?v=Bcuj2fTH4_4&amp;list=PLZbbT5o_s2xoWNVdDudn51XM8lOuZ_Njv&amp;index=12" rel="noopener ugc nofollow" target="_blank"> <strong class="kd jf">回放记忆讲解—深度 Q 网训练体验</strong> </a></li></ul></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="cb04" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本系列的其他部分:</p><div class="is it gp gr iu lk"><a rel="noopener follow" target="_blank" href="/reinforcement-learning-with-python-part-1-creating-the-environment-dad6e0237d2d"><div class="ll ab fo"><div class="lm ab ln cl cj lo"><h2 class="bd jf gy z fp lp fr fs lq fu fw jd bi translated">Python 强化学习|第 1 部分|创建环境</h2><div class="lr l"><h3 class="bd b gy z fp lp fr fs lq fu fw dk translated">设计和建立一个游戏环境，允许 RL 代理在上面训练和玩。</h3></div><div class="ls l"><p class="bd b dl z fp lp fr fs lq fu fw dk translated">towardsdatascience.com</p></div></div><div class="lt l"><div class="lu l lv lw lx lt ly ja lk"/></div></div></a></div><div class="is it gp gr iu lk"><a rel="noopener follow" target="_blank" href="/deep-reinforcement-learning-with-python-part-3-using-tensorboard-to-analyse-trained-models-606c214c14c7"><div class="ll ab fo"><div class="lm ab ln cl cj lo"><h2 class="bd jf gy z fp lp fr fs lq fu fw jd bi translated">使用 Python 进行深度强化学习|第 3 部分|使用 Tensorboard 分析训练好的模型</h2><div class="lr l"><h3 class="bd b gy z fp lp fr fs lq fu fw dk translated">在前面的部分中:</h3></div><div class="ls l"><p class="bd b dl z fp lp fr fs lq fu fw dk translated">towardsdatascience.com</p></div></div><div class="lt l"><div class="lu l lv lw lx lt ly ja lk"/></div></div></a></div></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="f632" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您可以关注我:</p><ul class=""><li id="197d" class="ne nf je kd b ke kf ki kj km ng kq nh ku ni ky nj nk nl nm bi translated"><a class="ae li" href="https://twitter.com/ModMaamari" rel="noopener ugc nofollow" target="_blank"> <strong class="kd jf"> <em class="lj">碎碎念</em> </strong> </a></li><li id="2771" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://www.linkedin.com/in/mohammed-maamari/" rel="noopener ugc nofollow" target="_blank"><strong class="kd jf"><em class="lj">LinkedIn</em></strong></a></li><li id="b5fd" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://www.facebook.com/mamarih1/" rel="noopener ugc nofollow" target="_blank"> <strong class="kd jf"> <em class="lj">脸谱</em> </strong> </a></li></ul></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="664c" class="oc mh je bd mi od oe of ml og oh oi mo oj ok ol mr om on oo mu op oq or mx os bi translated">您可能还喜欢:</h1><ul class=""><li id="ce1d" class="ne nf je kd b ke mz ki na km ov kq ow ku ox ky nj nk nl nm bi translated"><a class="ae li" href="https://medium.com/@mamarih1/deep-neural-networks-for-regression-problems-81321897ca33" rel="noopener"> <strong class="kd jf">深度神经网络用于回归问题</strong> </a></li><li id="5592" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://blog.goodaudience.com/ai-generates-taylor-swifts-song-lyrics-6fd92a03ef7e" rel="noopener ugc nofollow" target="_blank"> <strong class="kd jf"> AI 生成泰勒斯威夫特的歌词</strong> </a></li><li id="d483" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://medium.com/datadriveninvestor/introduction-to-random-forest-algorithm-with-python-9efd1d8f0157" rel="noopener"> <strong class="kd jf">用 Python 介绍随机森林算法</strong> </a></li><li id="24e6" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://medium.com/@mamarih1/machine-learning-crash-course-with-tensorflow-apis-summary-524e0fa0a606" rel="noopener"> <strong class="kd jf">带 TensorFlow APIs 的机器学习速成班汇总</strong> </a></li><li id="69c6" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://medium.com/@mamarih1/how-to-make-a-cnn-using-tensorflow-and-keras-dd0aaaed8ab4" rel="noopener"> <strong class="kd jf">如何用 Tensorflow 和 Keras </strong> </a> <strong class="kd jf">制作一个 CNN？</strong></li><li id="b9c0" class="ne nf je kd b ke oy ki oz km pa kq pb ku pc ky nj nk nl nm bi translated"><a class="ae li" href="https://medium.com/@mamarih1/how-to-choose-the-best-machine-learning-model-e1dbb46bdd4d" rel="noopener"> <strong class="kd jf">如何选择最好的机器学习模型？</strong>T13】</a></li></ul></div></div>    
</body>
</html>