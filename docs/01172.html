<html>
<head>
<title>YOLO Made Simple: Interpreting the You Only Look Once Paper</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO使简单:解读《你只看一次》一文</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yolo-made-simple-interpreting-the-you-only-look-once-paper-55f72886ab73?source=collection_archive---------18-----------------------#2020-02-02">https://towardsdatascience.com/yolo-made-simple-interpreting-the-you-only-look-once-paper-55f72886ab73?source=collection_archive---------18-----------------------#2020-02-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f9e2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">浏览论文中的实质细节和经常被忽视的事实，并简单解释。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/208a893a5e57b47bd7a25ebf7a8f655e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c0YBYFrm86EWCTJ201xB_g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">YOLO:你只看一次——来源来源:<a class="ae kv" href="https://pixabay.com/photos/yolo-sparklers-new-year-1758212/" rel="noopener ugc nofollow" target="_blank">卡内尔斯在pixabay </a></p></figure><p id="2e74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与最先进的R-CNN模型不同，“YOLO:统一的实时对象检测”或“YOLOv1”提供了一种端到端的对象检测和分类解决方案。这意味着我们可以训练单个模型直接从输入图像进行检测和分类，并且是完全可微分的。对象检测的传统方法的例子是在图像的不同部分上以不同的比例运行分类器。整洁，对不对？！你所需要的只是一个分类器。</p><p id="10fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">听起来很简单，在一张图像上运行数百次分类器来定位对象是非常低效的。但YOLOv1处理得很巧妙。它通过图像的单次向前传递进行检测和分类，并实时运行。因此得名“你只看一次”。我们将详细研究论文中描述的所有内容。</p><h1 id="9d23" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">介绍</h1><p id="65f4" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">作者将YOLO的工作比作人类的感知。我们，人类，看一眼一个场景，立刻就能对现在的情况，在哪里，谁在做什么有个大概的了解，还有更多。人类的视觉皮层很神奇吧？YOLOv1通过将对象检测和分类问题视为回归，一次性预测图像中存在哪些对象以及它们的位置。简单地说，你给YOLO模型一个图像，它通过一堆层，最终输出将是类预测和边界框坐标。在这里，作者简明扼要地将YOLO的工作定义为</p><blockquote class="mp mq mr"><p id="737d" class="kw kx ms ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated">直接从图像像素到包围盒坐标和类别概率。</p></blockquote><h1 id="27c0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">YOLO的物体探测方法</h1><p id="04a7" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">YOLO通过使用一个优雅的过程来处理物体检测，将图像分成一个由<strong class="ky ir"> <em class="ms"> S </em> x <em class="ms"> S </em> </strong>细胞组成的网格。而YOLO将输入限制为正方形图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/06dc43b7b0d2394302cbdcc3c3f8305a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SRw7_ArkKeU-qR3b3EPjCw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="mx">S×S网格</em></p></figure><p id="632f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果对象的中心落在特定的单元内，则每个单元产生对象的类别和边界预测。这种方法是强大的，因为它使YOLO能够检测图像中的多个对象，并同时对它们进行分类。然而，将图像划分成更多的单元将产生更细粒度的预测。网格中的每个单元负责预测边界框参数、对象存在的置信度和类别概率。最终的边界框预测由框中心的x和y坐标、sqrt(宽度)、sqrt(高度)和对象概率得分组成。</p><p id="c00b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:YOLOv1预测边界框相对于图像的宽度和高度的平方根。原因在</em> <strong class="ky ir"> <em class="ms">损失功能</em> </strong> <em class="ms">一节下面解释。</em></p><p id="94bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果有20个类(<strong class="ky ir"> <em class="ms"> C </em> </strong> =20)，则单元格的输出为【x，y，<strong class="ky ir"> √ </strong> w，<strong class="ky ir"> √ </strong> h，对象概率，<strong class="ky ir"> <em class="ms"> C1，C2，C3，…。，C20 </em> </strong>。上述概率是条件类概率。为了澄清，它是给定对象存在于单元中，对象属于特定类的概率。当然，单元格网格中的每个单元格都预测类似的项目列表。</p><p id="6afb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是还有一件事。在YOLOv1中，每个单元格预测的不是一个而是<strong class="ky ir"> <em class="ms"> B </em> </strong>边界框。而这些包围盒每一个都有[x，y，<strong class="ky ir"> √ </strong> w，<strong class="ky ir"> √ </strong> h，物体概率]。然而，YOLO只对每个像元预测一次类别概率，而不考虑边界框的数量。因此，每个单元的输出现在有更多的项目。举例说明，如果<strong class="ky ir"> <em class="ms"> B </em> </strong> =2、<strong class="ky ir"> <em class="ms"> C </em> </strong> =20，则输出增长为[x1，y1，<strong class="ky ir"> √ </strong> w1，<strong class="ky ir"> √ </strong> h1，obj。prob1，x2，y2，<strong class="ky ir"> √ </strong> w2，<strong class="ky ir"> √ </strong> h2，obj。C1，C2，…，C20  。</p><p id="4c00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于在具有20个类别的PASCAL VOC上的检测，它预测7×7的单元网格，每个单元具有2个边界框。考虑到所有单元格的预测，输出形状将是一个立方体，其尺寸为(<em class="ms"> 7 x 7 x 30 </em>)。由于<strong class="ky ir"> <em class="ms"> C </em> </strong> =20，两个边界框贡献了10项，并且类别概率有20项。这加起来就是三十，这就解释了第三次元中的“<strong class="ky ir"><em class="ms">”30</em></strong>”。</p><h1 id="0909" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">解读YOLO的产量预测</h1><p id="e9f3" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">边界框中心的x和y坐标相对于该网格单元的左上角，而不是相对于图像的左上角。每个单元格预测相对于其位置的坐标，这些坐标作为单元格位置的偏移量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/3ad32ba992907177ac781d542d0837ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mvObUKlFeQUmWm4pWU5cxg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@wildfernstudio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Charis Gegelman </a>在<a class="ae kv" href="https://unsplash.com/images/animals/cat?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="34c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们将图像分成<em class="ms"> 3 x 3 </em>个网格单元，如上图所示，对象的中心落在中心网格单元内。而如果我们再假设每个网格单元的宽度和高度都是<strong class="ky ir"> <em class="ms"> A、</em> </strong>的话，那么对象中心的坐标就是(<strong class="ky ir"> <em class="ms"> 0.6A、0.6A </em> </strong>)相对于单元的左上角。模型预测的坐标值在<strong class="ky ir"> 0 </strong>和<strong class="ky ir"> 1 </strong>之间，是<strong class="ky ir"> <em class="ms"> A. </em> </strong>的一个分数，因此，坐标(<strong class="ky ir"> <em class="ms"> 0.6，0.6 </em> </strong>)表示<strong class="ky ir"> <em class="ms"> A的</em><strong class="ky ir"><em class="ms">长度向右的<strong class="ky ir"><em class="ms"/></strong>60%<strong class="ky ir">这些坐标可以相对于整个图像进行转换，因为我们知道哪个单元预测了盒子及其相对坐标。</strong></em></strong></strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/fff26f8d5db6e7c2823ecdc52d33f1cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JTkjLk6H312Ttb4P1k3tqA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对象中心相对于图像的坐标</p></figure><p id="f67d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于上面的例子，盒子相对于图像的中心是<strong class="ky ir"> <em class="ms"> (A+0.6*A，A+0.6*A)。</em> </strong>原<strong class="ky ir"> <em class="ms"> A </em> </strong>加到<strong class="ky ir"> <em class="ms"> 0.6*A </em> </strong>是单元格左上角到图像左上角的距离。因此，总和给出了盒子中心相对于整个图像的坐标。但是边界框的高度和宽度是相对于整个图像预测的。对于上面的“猫”的例子，边界框的高度几乎是图像高度的三分之二。并且该框的宽度是图像宽度的三分之一。</p><p id="51b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，YOLO将宽度和高度预测为图像的宽度(<strong class="ky ir"><em class="ms">【W</em></strong>)和高度(<strong class="ky ir"><em class="ms"/></strong>)分别为<strong class="ky ir"><em class="ms">1/3</em></strong>和<em class="ms">2/3</em>。因此宽度和高度预测意味着<strong class="ky ir"> √( <em class="ms"> 0.33*W)，</em> √( <em class="ms"> 0.66*H)。</em> </strong>最后，一个物体的概率也表示为一个介于<strong class="ky ir"> <em class="ms"> 0 </em> </strong>和<strong class="ky ir"> <em class="ms"> 1 </em> </strong>之间的数。该对象概率乘以预测框与地面真实值的交集(IoU)以给出<strong class="ky ir"> <em class="ms">置信度得分</em> </strong>。IoU是一个分数，它表明预测框与实际框重叠的程度。其值也在分别表示无重叠和完全重叠的<strong class="ky ir"> <em class="ms"> 0 </em> </strong>和<strong class="ky ir"> <em class="ms"> 1 </em> </strong>之间。</p><p id="7602" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">置信度得分<strong class="ky ir"> 1 </strong>表示100%置信度，<strong class="ky ir">T3】0T5，0%置信度。该值越高，单元格越确信有对象存在。这个置信度得分乘以条件类概率，以产生给定类存在的概率得分。</strong></p><p id="e3f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最终预测的包围盒参数应该是(<strong class="ky ir"> <em class="ms"> 0.6，0.6，</em> √ <em class="ms"> 0.33，</em> √ <em class="ms"> 0.66，1 </em> </strong>)表示(x，y，width，height，obj。prob)。</p><h1 id="327c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">网络架构</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/bb2b5bb21b1aa5cfeb115043c0e4adb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vbOlfb8yI9ChwQ9uV7Kfjg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">YOLOv1架构来源:<a class="ae kv" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.02640.pdf</a>本文作者拥有这张图片。我只是用它来说明他们的工作！</p></figure><p id="9def" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自YOLOv1于2015年问世以来，它遵循了典型的卷积架构，但创新了预测输出的方式。它有24个卷积层，4个最大池层和两个全连接层，一个有<strong class="ky ir"><em class="ms">4096个</em> </strong>神经元，另一个有<strong class="ky ir"><em class="ms">1470个</em> </strong>神经元。该模型接收尺寸为<strong class="ky ir"> <em class="ms"> 448 x 448 </em> </strong>的输入彩色图像，用于对象检测。正如我们之前看到的，YOLOv1预测了来自其最终完全连接层的<strong class="ky ir"> <em class="ms">长方体</em> </strong>输出。那是用<strong class="ky ir"><em class="ms">1470个</em> </strong>神经元将最后一个全连接层的输出重塑成一个(<strong class="ky ir"><em class="ms">7×7×30</em></strong>)长方体为帕斯卡VOC。显式地，我们可以看到最后一层有<strong class="ky ir"><em class="ms">1470个</em> </strong>神经元，因为它需要被重塑为<strong class="ky ir"><em class="ms">7 x 7 x 30 = 1470。</em>T47】</strong></p><p id="9ace" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特征提取器由不同滤波器大小的卷积层构建，其中一些卷积层之后是后续的最大池层，用于空间缩减。平常的东西！在YOLO模型中，只有第一个卷积层有<em class="ms"> 7 x 7 </em>滤镜。其他的都有<em class="ms"> 3 x 3 </em>滤镜<em class="ms">。</em>网络不仅仅使用交替<em class="ms"> 3 </em> x <em class="ms"> 3 </em>卷积和最大池层数，而是使用<em class="ms"> 1 </em> x <em class="ms"> 1 </em>卷积。</p><p id="e020" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者提到他们的架构受到了引入了Inception模块的GoogLeNet的启发。</p><blockquote class="mp mq mr"><p id="9f61" class="kw kx ms ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated">我们的网络架构受GoogLeNet图像分类模型的启发</p></blockquote><p id="6560" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但与GoogLeNet不同，YOLOv1不使用inception块。相反，在应用大量的<em class="ms">3×3</em>过滤器之后，它使用<em class="ms">1×1</em>卷积来减少特征图的通道深度。<em class="ms"> 1 x 1 </em>滤镜有一个非常小的感受域(只有一个像素)，但它们主要用于减少<em class="ms"> 3 x 3 </em>卷积层之后各层的计算负载。此外，它们有助于在不改变感受野的情况下引入非线性。</p><p id="c17d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不太明白？我们将详细研究为什么它是有益的。</p><h2 id="418c" class="na lt iq bd lu nb nc dn ly nd ne dp mc lf nf ng me lj nh ni mg ln nj nk mi nl bi translated">1 x 1卷积</h2><p id="5093" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><em class="ms">1×1</em>卷积的概念是在闵等人的论文<strong class="ky ir">网络中的网络</strong>中介绍的，这里看一下论文<a class="ae kv" href="https://arxiv.org/abs/1312.4400" rel="noopener ugc nofollow" target="_blank">的</a></p><p id="e469" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:以下示例解释了带有卷积层的小模型的1 x 1卷积。不要把这个示例模型与YOLO的建筑混淆</em></p><p id="2a48" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，考虑大小为<strong class="ky ir"> <em class="ms"> (100，100，3) </em> </strong>的输入图像被馈送到具有零填充的128个滤波器的<em class="ms">3×3</em>卷积层。我们零填充以产生与输入<strong class="ky ir"><em class="ms">【100，100】</em></strong>相同空间维度的输出特征图。为了简单起见，我们忽略<strong class="ky ir">批次</strong>维度。每个滤波器与输入图像卷积后产生一个<strong class="ky ir"> <em class="ms"> (100，100，1) </em> </strong>输出特征图。由于我们有128个这样的滤波器，滤波器输出附加到信道维度以产生形状为<strong class="ky ir"> <em class="ms"> (100，100，128) </em> </strong>的输出。这一层的权重大小应该是<strong class="ky ir"> <em class="ms"> (3，3，3，128) </em> </strong>也就是(filter_x_size，filter_y_size，input_channels，filter _ number)。</p><p id="76eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目前为止还好(只是正常卷积！).</p><p id="fa1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，如果我们再次将这个输出馈送到下一个具有128个滤波器的<em class="ms">3×3</em>卷积层，它的权重将必须是<strong class="ky ir"> <em class="ms"> (3，3，128，128)。</em>T45】</strong></p><p id="19b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你现在明白了吗？第一层只有3456个参数(3x3x3x128 = 3,456)。但是，由于第二层对128个通道的输入进行操作，因此它有多达147，456个参数(3x3x128x128=147，456)！现在想想后续层会有多少参数？为了减少这种爆炸效应，在将第一卷积层的<strong class="ky ir"> <em class="ms"> (100，100，128) </em> </strong>输出馈送到下一层之前，应用<em class="ms"> 1 x 1 </em>卷积。</p><p id="1825" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对<strong class="ky ir"> <em class="ms"> (100，100，128) </em> </strong>应用32个<em class="ms">1×1</em>滤波器，将通道深度减少到<strong class="ky ir"> <em class="ms"> (100，100，32)。</em> </strong>现在，下一个<em class="ms"> 3 x 3 </em>卷积层的参数将是<strong class="ky ir"> <em class="ms"> (3，3，32，128) </em> </strong>。参数的数量从147456个减少到36864个<strong class="ky ir"> <em class="ms"> (3x3x32x128) </em> </strong>。除此之外，<em class="ms"> 1 x 1 </em>卷积层有128x32=4096个参数。现在总共只有40，960个参数，少了3.6倍！</p><p id="58b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">YOLOv1模型在两个完全连接的层之间使用了一个压差，以防止过度拟合。但它没有使用任何其他技术，如<a class="ae kv" href="https://hackerstreak.com/batch-normalization-how-it-really-works/" rel="noopener ugc nofollow" target="_blank">批量标准化</a>可以加速训练。</p><p id="d468" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">既然我们已经看到了什么是<em class="ms"> 1 x 1 </em>卷积，让我们继续讨论网络的其他内容。</p><h1 id="2f43" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">培养</h1><p id="6324" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们在开始时看到，网络有24个卷积层、4个最大池层和2个光纤通道层。</p><p id="77b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">跳到这里来学习</p><p id="affd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://hackerstreak.com/kaggle-cactus-detection/" rel="noopener ugc nofollow" target="_blank">如何建立一个简单的卷积神经网络，在kaggle数据集上训练并达到99.9%的准确率！</a></p><p id="0af2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者在ImageNet数据集上以<em class="ms"> 224 x 224的输入分辨率预训练了前二十个卷积层。它</em>的分辨率只有YOLOv1的检测输入的一半，即<em class="ms"> 448 x 448。</em>这显然是因为ImageNet图像的大小为<em class="ms"> 224 x 224。</em></p><blockquote class="mp mq mr"><p id="8c9b" class="kw kx ms ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated">我们在ImageNet分类任务中以一半的分辨率(224 × 224输入图像)预训练卷积层，然后将分辨率提高一倍用于检测——yolo v1作者</p></blockquote><p id="2080" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于只有前20个卷积层用于迁移学习，它可以对任何分辨率的输入图像进行操作。</p><p id="7715" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预训练有助于卷积滤波器从ImageNet数据集学习模式。由于它包含了属于一千多个类别的大量图像，卷积层可以学习许多有用的特征。预训练和迁移学习为YOLO检测提供了很好的性能提升。</p><blockquote class="mp mq mr"><p id="f0b6" class="kw kx ms ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated">对于预训练，我们使用图中的前20个卷积层，随后是一个平均池层和一个全连接层——yolov 1作者</p></blockquote><p id="d0f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在ImageNet上进行预训练后，移除平均池和完全连接的预测层。它们被四个<em class="ms"> 3 x 3 </em>卷积层和两个全连接层取代。</p><p id="b3e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:仅对于使用S=7，B=2的PASCAL VOC数据集，输出尺寸为7 x 7 x 30。如果任何一个参数</em> <strong class="ky ir"> <em class="ms"> S </em> </strong> <em class="ms">(网格单元数S x S)，</em> <strong class="ky ir"> <em class="ms"> B </em> </strong> <em class="ms">或数据集中的类数发生变化，这个输出形状也会发生变化。</em></p><p id="c22e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些级联卷积和最大池层将特征图的空间维度从<em class="ms"> 448 x 448 </em>减少到所需的<em class="ms"> 7 x 7 </em>大小<em class="ms">。</em></p><p id="7bba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了最终完全连接的层之外，网络中的所有层都使用“Leaky-Relu”激活功能。并且最后一层具有线性激活。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/6fd6d31600c85dcf83fd670a61b6a913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oMqMJdNGevBsaeWYf180HA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Leaky-Relu的数学表达式</p></figure><p id="2b30" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Leaky-relu的图形与整流线性单元(relu)略有不同。看一看！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/d2bf27930a5531fc324cf00fc0c8b634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oVCsLHYnoMz6uRZA01S1Fg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Leaky-Relu激活函数图</p></figure><p id="cdf5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">需要注意的一件重要事情是最终层的输出。正如我们之前提到的，它有一个<strong class="ky ir"> <em class="ms">线性激活</em> </strong>，它的输出被整形形成一个<strong class="ky ir"><em class="ms">7×7×30</em></strong>张量。最后，YOLOv1模型在PASCAL VOC数据集上训练了135个时期。作者采用的一些训练技巧如下。</p><blockquote class="mp mq mr"><p id="1d00" class="kw kx ms ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated">在整个训练过程中，我们使用的批量大小为64，动量为0.9，衰减为0.0005。对于第一个时期，我们将学习率从103慢慢提高到102。我们继续用102训练75个周期，然后10^−3训练30个周期，最后10^−4训练30个周期。</p></blockquote><h1 id="6acb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">损失函数</h1><p id="2a37" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">YOLO的损失函数可能看起来吓人，但它非常简单。使用的损失称为<strong class="ky ir"> <em class="ms">平方和损失</em> </strong>，用于YOLOv1中的所有任务。作者引用说，优化平方和比对数似然更容易。但是他们也提到它有一些缺点。</p><p id="ebd7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">平方和误差同等地衡量定位误差和分类误差。而且，由于图像中的许多网格单元不包含任何对象，平方和误差试图使这些单元的置信度得分为零。这意味着他们的损失将主导梯度，它不会让模型收敛。为了解决这个问题，作者引入了参数<strong class="ky ir"> <em class="ms"> λcoord </em> </strong>和<strong class="ky ir"> <em class="ms"> λnoobj。</em> </strong></p><p id="bd36" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这两个参数对损失函数中的不同项进行加权，以保持无对象像元造成的损失较低。并且也更加权衡坐标损失。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/6c4d54b0fad74bb47f6fd539233c717f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eyMSMtymGsl9q2CebsXqPQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">YOLOv1的损失函数来源:<a class="ae kv" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.02640.pdf</a>再次声明，作者拥有这张图片。我只是用它来说明他们的工作！</p></figure><p id="013e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们把它分解一下，了解损失中的每一项是什么意思。</p><h1 id="0696" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">定位误差</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/710cec3020c65421e3cd42f79d5c72f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TF2xo-Sf5rZc16YyACeFmA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">定位误差</p></figure><p id="0e5b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一项计算预测坐标和地面真实坐标之间的平方和损失。对所有单元格中的所有边界框都这样做。得到的和乘以<strong class="ky ir"> <em class="ms"> λcoord。</em> </strong>作者用值5为<strong class="ky ir"> <em class="ms"> λcoord。</em></strong><strong class="ky ir"><em class="ms">" 1 obj I，j</em></strong>"<strong class="ky ir"><em class="ms"/></strong>项表示在第<strong class="ky ir"> i </strong>行和第<strong class="ky ir"> j </strong>列单元格中存在一个对象。</p><p id="842d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二项计算预测高度和宽度的平方和损失。该模型预测宽度和高度的平方根，而不是直接预测它们的值。这样做是为了缓解作者提到的某个问题。</p><blockquote class="mp mq mr"><p id="8593" class="kw kx ms ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated">平方和误差同样对大盒子和小盒子中的误差进行加权。我们的误差度量应该反映大盒子中的小偏差不如小盒子中的小偏差重要。为了部分解决这个问题，我们预测边界框宽度和高度的平方根，而不是直接预测宽度和高度</p></blockquote><p id="bf65" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设有两个地面实况箱，高度分别为10.2和2.2。在这个例子中，我们不考虑盒子的宽度。假设模型预测的身高是10.1和2.1。现在根据损失项，较大的盒子误差为(<strong class="ky ir"> √ </strong> 10.1- <strong class="ky ir"> √ </strong> 10.2)，较大的盒子误差为(<strong class="ky ir"> √ </strong> 2.1- <strong class="ky ir"> √ </strong> 2.2)。你可以看到损失值分别是10^-4的2.4倍和10^-3的1.16倍。如您所见，预测高度和宽度的平方根在较小的框中更重视小误差。</p><h1 id="41e4" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">分类误差</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/c9c6fd68b02e8871d2cbabede8c3f085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*76l1ZuoPA5UJ6YEjWUhAsA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">分类误差</p></figure><p id="a3ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中的第一项计算每个像元中每个边界框的预测置信度得分和基本事实之间的误差平方和。这个误差项对应于物体所在单元的误差。因此使用了术语<strong class="ky ir"><em class="ms">“1 obj I，j </em> </strong>”。</p><p id="e56d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">类似地，第二项计算不包含任何对象的像元的平方和误差。术语“<strong class="ky ir"> <em class="ms"> 1 noobj i，j </em> </strong>”表示第<strong class="ky ir">I</strong><strong class="ky ir"/>列和第<strong class="ky ir"> j </strong>行单元格中没有对象。这个总和由<strong class="ky ir"> <em class="ms"> λnoobj </em> </strong>项加权，以使这个损失更小。作者将<strong class="ky ir"> <em class="ms"> λnoobj </em> </strong>赋值为0.5。</p><p id="3015" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后一项计算类别概率的相同损失。它对每个像元中的所有类进行迭代，并计算损失平方和。这个损失项还有<strong class="ky ir"><em class="ms">“1 obj I，j </em> </strong>”。这意味着没有任何对象的单元不会造成分类损失。</p><h1 id="d404" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结束了</h1><p id="718e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我希望这篇文章能让你深入了解YOLO的工作。如果你发现任何错误，请在评论中报告。勘误表，如果有的话，确实是无意的。</p><h1 id="5ce3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><ol class=""><li id="c429" class="nr ns iq ky b kz mk lc ml lf nt lj nu ln nv lr nw nx ny nz bi translated">你只看一次:统一的，实时的物体检测:【https://arxiv.org/abs/1506.02640 T4】</li><li id="e590" class="nr ns iq ky b kz oa lc ob lf oc lj od ln oe lr nw nx ny nz bi translated">网络中的网络<a class="ae kv" href="https://arxiv.org/abs/1312.4400" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1312.4400</a></li></ol><p id="35c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">最初发表于</em><a class="ae kv" href="https://hackerstreak.com/" rel="noopener ugc nofollow" target="_blank"><em class="ms">https://hackerstreak.com</em></a></p></div></div>    
</body>
</html>