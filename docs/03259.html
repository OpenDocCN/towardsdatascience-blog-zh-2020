<html>
<head>
<title>End-to-End Project of Game Prediction Based on LeBron’s Stats Using Three Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用三种机器学习模型基于勒布朗数据的端到端游戏预测方案</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/end-to-end-project-of-game-prediction-based-on-lebrons-stats-using-three-machine-learning-models-38c20f49af5f?source=collection_archive---------23-----------------------#2020-03-28">https://towardsdatascience.com/end-to-end-project-of-game-prediction-based-on-lebrons-stats-using-three-machine-learning-models-38c20f49af5f?source=collection_archive---------23-----------------------#2020-03-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="fc27" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="02b0" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用三种不同的分类器(包括逻辑回归、随机森林分类器和深度学习分类器)对二元分类问题进行综合指导。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/8d6b9de6a1d73e59f7518f11d102ef58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*s2WnX9ice4xbzrgD"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@jcgellidon?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> JC Gellidon </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="7717" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di">我</span>是<strong class="lk jd"> <em class="mn">机器学习</em> </strong>和<strong class="lk jd"> <em class="mn">篮球</em> </strong>的超级粉丝，所以我喜欢把这两个结合起来生成一些迷你项目。在这篇文章中，我想和你分享其中的一个项目。</p><p id="5414" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">不管你是不是篮球迷，你都必须知道<a class="ae lh" href="https://en.wikipedia.org/wiki/LeBron_James" rel="noopener ugc nofollow" target="_blank">勒布朗詹姆斯</a>。作为核心球员，他的表现对比赛结果至关重要。所以，我在这个项目中试图回答的问题是<strong class="lk jd"> <em class="mn">“我们能根据勒布朗的比赛数据预测比赛结果吗？”</em>T19】</strong></p><p id="956d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我把它框定为一个二元分类问题，以团队的“赢”或“输”作为输出标签。特征是勒布朗·詹姆斯每场比赛的基本统计。</p><p id="caf5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我在项目中实现了三个分类器，<strong class="lk jd"><em class="mn"/></strong><strong class="lk jd"><em class="mn">随机森林分类器</em></strong><strong class="lk jd"><em class="mn">深度学习分类器</em> </strong>，通过使用机器学习中流行的两个Python库，<a class="ae lh" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd"><em class="mn">sk learn</em></strong></a>，以及<a class="ae lh" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd"><em class="mn">keras</em></strong></a>。</p><p id="54fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我正在一步一步地完成这个项目，希望对你有所帮助。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="2734" class="mv mw it bd mx my mz dn na nb nc dp nd lr ne nf ng lv nh ni nj lz nk nl nm iz bi translated">准备数据集</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nn"><img src="../Images/c4073e2253430ccfd876db59487e5aa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FIUn-DwHJfjdyYTV"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@thecreative_exchange?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上创意交流</a>的照片</p></figure><p id="76fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里列出了代码中使用的库。</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="f4b7" class="mv mw it np b gy nt nu l nv nw">import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.model_selection import StratifiedKFold<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.ensemble import RandomForestClassifier<br/>from keras.layers import Dense, Dropout<br/>from keras.models import Model, Sequential<br/>from keras.wrappers.scikit_learn import KerasClassifier<br/>from sklearn.model_selection import GridSearchCV</span></pre><p id="4aed" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我手动整理了勒布朗从赛季<strong class="lk jd"><em class="mn">2003–2004</em></strong>到赛季<strong class="lk jd"><em class="mn">2019–2020</em></strong>(直到3月<a class="ae lh" href="https://en.wikipedia.org/wiki/Suspension_of_the_2019%E2%80%9320_NBA_season" rel="noopener ugc nofollow" target="_blank"> NBA停赛</a>)的比赛基本统计。总共有1258场比赛。进口代码如下:</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="2c81" class="mv mw it np b gy nt nu l nv nw">df = pd.read_csv("lebron_2003_2020_career_gamelog.csv",index_col=0)<br/>df.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/26d31c854bb5c576f1a4838be285ce7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LVm3pRyGj9iSSwTn423a4A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">端到端游戏预测(由<a class="ae lh" href="https://medium.com/@jianan.jay.lin" rel="noopener">虞风</a></p></figure><p id="404f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从上图可以看到<em class="mn">基础统计</em>和<em class="mn">游戏结果</em>(“赢”和“Winby”)。</p><p id="37bd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，我要确保数据类型是“float32 ”,这样我就可以直接将它们提供给keras中的神经元网络模型。数据类型转换代码如下:</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="64d1" class="mv mw it np b gy nt nu l nv nw">df = df.astype('float32')</span></pre><p id="97a7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我需要使用如下代码指定数据集中的特征空间和标签:</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="06b4" class="mv mw it np b gy nt nu l nv nw">y = df['Win']<br/>X = df.drop(columns=['Win','Winby'])</span></pre><p id="cba8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">列“<strong class="lk jd"> <em class="mn">赢</em> </strong>”是记录的游戏结果，其中1表示<strong class="lk jd"> <em class="mn">赢</em> </strong>，0表示<strong class="lk jd"> <em class="mn">输</em> </strong>。而“<strong class="lk jd"> <em class="mn"> Winby </em> </strong>”一栏则是该组件的游戏分数差，其中正数表示<strong class="lk jd"> <em class="mn">赢</em> </strong>，负数表示<strong class="lk jd"> <em class="mn">输</em> </strong>。因此，有必要将它们从特征空间中移除。</p><p id="f7cd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，数据被分成<strong class="lk jd"> <em class="mn">训练</em> </strong>和<strong class="lk jd"> <em class="mn">测试</em> </strong>集合，其中测试集合在模型评估步骤之前永远不会被触及。代码如下:</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="0f07" class="mv mw it np b gy nt nu l nv nw">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=42)</span></pre><p id="528f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你可能会注意到，我在这里使用了一个<strong class="lk jd"> <em class="mn">分层分割</em> </strong>，避免了游戏结果在训练数据中偏向一类的情况。“分层=y”表示基于我们的输出标签<strong class="lk jd"> <em class="mn"> y </em> </strong>完成<em class="mn">“分层分割”</em>。</p><p id="0600" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">到现在为止，牛排已经做好了，我们需要开始预热烤箱。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="2ebd" class="mv mw it bd mx my mz dn na nb nc dp nd lr ne nf ng lv nh ni nj lz nk nl nm iz bi translated">模特培训</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ny"><img src="../Images/5a4ceb0270f36d88af376dbe4fac29b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*D3gtyVtVZJ1zYH04"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Ashim D'Silva 在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="1fc2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我提到的，将使用三个模型，<em class="mn">逻辑回归</em>，<em class="mn">随机森林分类器</em>，以及<em class="mn">深度学习分类器</em>。为了使它们都符合相同的Scikit-Learn工作流，我们需要首先以如下的<em class="mn"> Scikit-Learn </em>风格定义深度学习模型:</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="2cc2" class="mv mw it np b gy nt nu l nv nw">def my_DL(epochs=6,batchsize=512):<br/>    model = Sequential()<br/>    model.add(Dense(32,activation='relu'))<br/>    model.add(Dense(16,activation='relu'))<br/>    model.add(Dense(1,activation='sigmoid'))<br/>    model.compile(loss='binary_crossentropy',optimizer='rmsprop', metrics=['accuracy'])</span><span id="75fa" class="mv mw it np b gy nz nu l nv nw">    return model</span></pre><p id="ff9b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">具体来说，这个神经网络有两个隐层，分别是32个和16个节点。网络的损失函数、优化器和度量分别固定为'<em class="mn">二元交叉熵</em>'、<em class="mn"> rmsprop </em>和'<em class="mn">精度</em>'。</p><p id="d2e6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">该编译模型有两个可调参数，<strong class="lk jd"> <em class="mn">历元</em> </strong>为历元数，<strong class="lk jd"> <em class="mn">批次大小</em> </strong>为每批样本数。这两个参数都有默认值，格式类似于<strong class="lk jd"> <em class="mn"> sklearn </em> </strong>中的分类器。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="228e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">不能从数据中训练出来但需要在训练过程前赋值的模型参数称为<strong class="lk jd"> <em class="mn">超参数</em> </strong>。这些超参数总是与模型的<strong class="lk jd">复杂度</strong>相关，需要正确选择以避免<strong class="lk jd">欠拟合</strong>或<strong class="lk jd">过拟合</strong>问题。</p><p id="0864" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要选择最佳的超参数集，我们可以用两种方法。首先，我们可以进一步将训练数据集分成两部分，即<strong class="lk jd"> <em class="mn">训练</em> </strong>和<strong class="lk jd"> <em class="mn">验证</em> </strong>数据集。然后，我们需要在<em class="mn">验证</em>集合上评估来自<em class="mn">训练</em>数据集的训练模型。最佳超参数集是在验证集上具有最佳性能的超参数集。</p><p id="3b09" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，当样本量很小时，只有一个数据分割会有偏差。所以，<strong class="lk jd"> <em class="mn">交叉验证</em> </strong>是另一种训练超参数的方式，更受欢迎。因此，我在这个项目中使用交叉验证。</p><p id="ce49" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我在下面列出了超参数调谐的全部功能，并将详细介绍。</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="0184" class="mv mw it np b gy nt nu l nv nw">def train_hyper_tune(X,y):<br/>    # create the pre-processing component<br/>    my_scaler = StandardScaler()<br/>    my_imputer = SimpleImputer(strategy="median")<br/>    <br/>    # define classifiers<br/>    ## Classifier 1: Logistic Regression<br/>    clf_LR = LogisticRegression(random_state=0,penalty='elasticnet',solver='saga')<br/>    ## Classifier 2: Random Forest Classifier<br/>    clf_RF = RandomForestClassifier(random_state=0)<br/>    ## Classifier 3: Deep Learning Binary Classifier<br/>    clf_DL = KerasClassifier(build_fn=my_DL)<br/>    <br/>    # define pipeline for three classifiers<br/>    ## clf_LR<br/>    pipe1 = Pipeline([('imputer', my_imputer), ('scaler', my_scaler), ('lr_model',clf_LR)])<br/>    ## clf_RF<br/>    pipe2 = Pipeline([('imputer', my_imputer), ('scaler', my_scaler), ('rf_model',clf_RF)])<br/>    ## clf_DL<br/>    pipe3 = Pipeline([('imputer', my_imputer), ('scaler', my_scaler), ('dl_model',clf_DL)])<br/>    <br/>    # create hyperparameter space of the three models<br/>    ## clf_LR<br/>    param_grid1 = {<br/>        'lr_model__C' : [1e-1,1,10],<br/>        'lr_model__l1_ratio' : [0,0.5,1]<br/>    }<br/>    ## clf_RF<br/>    param_grid2 = {<br/>        'rf_model__n_estimators' : [50,100],<br/>        'rf_model__max_features' : [0.8,"auto"],<br/>        'rf_model__max_depth' : [4,5]<br/>    }<br/>    ## clf_DL<br/>    param_grid3 = {<br/>        'dl_model__epochs' : [6,12,18,24],<br/>        'dl_model__batchsize' : [256,512]<br/>    }<br/>    <br/>    # set GridSearch via 5-fold cross-validation<br/>    ## clf_LR<br/>    grid1 = GridSearchCV(pipe1, cv=5, param_grid=param_grid1)<br/>    ## clf_RF<br/>    grid2 = GridSearchCV(pipe2, cv=5, param_grid=param_grid2)<br/>    ## clf_DL<br/>    grid3 = GridSearchCV(pipe3, cv=5, param_grid=param_grid3)<br/>    <br/>    # run the hyperparameter tunning process<br/>    grid1.fit(X,y)<br/>    grid2.fit(X,y)<br/>    grid3.fit(X,y)<br/>    <br/>    # return results of the tunning process<br/>    return grid1,grid2,grid3,pipe1,pipe2,pipe3</span></pre><p id="6062" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如代码所示，函数内部主要有六个步骤:</p><p id="446b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">第一步。创建预处理函数。</strong></p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="9b5d" class="mv mw it np b gy nt nu l nv nw">    # create the pre-processing component<br/>    my_scaler = StandardScaler()<br/>    my_imputer = SimpleImputer(strategy="median")</span></pre><p id="1c63" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我使用<em class="mn">特征的中值</em>来估算缺失值，使用<em class="mn">标准缩放器</em>来标准化数据。这一步对于所有三种型号都是一样的。</p><p id="6771" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">第二步。定义所有三个分类器。</strong></p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="0445" class="mv mw it np b gy nt nu l nv nw">    # define classifiers<br/>    ## Classifier 1: Logistic Regression<br/>    clf_LR = LogisticRegression(random_state=0,penalty='elasticnet',solver='saga')<br/>    ## Classifier 2: Random Forest Classifier<br/>    clf_RF = RandomForestClassifier(random_state=0)<br/>    ## Classifier 3: Deep Learning Binary Classifier<br/>    clf_DL = KerasClassifier(build_fn=my_DL)</span></pre><p id="ab00" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，逻辑回归分类器通常被用作<em class="mn">“Hello world！”</em>机器学习书籍中的模型。这里，它与惩罚函数一起使用，以避免过度拟合。带有这个罚项的模型称为“弹性网”，它是正则化中l1和l2范数的组合。</p><p id="1c80" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于那些对我们为什么选择弹性网作为惩罚条款感兴趣的人，请阅读我下面的另一篇文章:</p><div class="oa ob gp gr oc od"><a rel="noopener follow" target="_blank" href="/a-practical-suggestion-in-linear-regression-cb639fd5ccdb"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd jd gy z fp oi fr fs oj fu fw jc bi translated">线性回归中的一个实用建议</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">从弹性网开始，记得调好定义l1范数之比的超参数。</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">towardsdatascience.com</p></div></div><div class="om l"><div class="on l oo op oq om or lb od"/></div></div></a></div><p id="95ee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第二，随机森林分类器以更自由的方式定义，而不固定任何超参数。它的三个超参数将在下面的步骤中进行调整，我将在后面详细介绍。</p><p id="25c7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第三，这里使用的深度学习分类器是基于前面提到的<em class="mn"> Scikit-Learn </em>风格模型，<strong class="lk jd"> <em class="mn"> my_DL </em> </strong>。谢天谢地，Keras为Scikit-Learn API 提供了精彩的<a class="ae lh" href="https://keras.io/scikit-learn-api/" rel="noopener ugc nofollow" target="_blank">包装器。我通过将函数<strong class="lk jd"> <em class="mn"> my_DL </em> </strong>传递给函数<strong class="lk jd"> <em class="mn"> KerasClassifier()来直接调用它。</em>T15】</strong></a></p><p id="76a5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">第三步。为每个模型定义一个管道，将预处理和建模结合在一起。</strong></p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="885e" class="mv mw it np b gy nt nu l nv nw">    # define pipeline for three classifiers<br/>    ## clf_LR<br/>    pipe1 = Pipeline([('imputer', my_imputer), ('scaler', my_scaler), ('lr_model',clf_LR)])<br/>    ## clf_RF<br/>    pipe2 = Pipeline([('imputer', my_imputer), ('scaler', my_scaler), ('rf_model',clf_RF)])<br/>    ## clf_DL<br/>    pipe3 = Pipeline([('imputer', my_imputer), ('scaler', my_scaler), ('dl_model',clf_DL)])</span></pre><p id="4e53" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于这三个模型中的每一个，我都用sklearn   中的<a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> <em class="mn">流水线函数将预处理和分类器组合成一个流水线。对于处理的每一步，都应该给出一个名称。例如，我将我的逻辑回归模型命名为“<em class="mn"> lr_model </em>”，并在管道中通过<strong class="lk jd"> <em class="mn"> clf_LR </em> </strong>调用它。</em></strong></a></p><p id="e33c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">将所有内容合并到一个管道中的目的是确保在<em class="mn">交叉验证</em>中对训练数据进行完全相同的处理。这对于避免数据泄露至关重要。</p><p id="1052" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">步骤四。为每个模型创建超参数空间。</strong></p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="8dd9" class="mv mw it np b gy nt nu l nv nw">    # create hyperparameter space of the three models<br/>    ## clf_LR<br/>    param_grid1 = {<br/>        'lr_model__C' : [1e-1,1,10],<br/>        'lr_model__l1_ratio' : [0,0.5,1]<br/>    }<br/>    ## clf_RF<br/>    param_grid2 = {<br/>        'rf_model__n_estimators' : [50,100],<br/>        'rf_model__max_features' : [0.8,"auto"],<br/>        'rf_model__max_depth' : [4,5]<br/>    }<br/>    ## clf_DL<br/>    param_grid3 = {<br/>        'dl_model__epochs' : [6,12,18,24],<br/>        'dl_model__batchsize' : [256,512]<br/>    }</span></pre><p id="c4bd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这部分比较灵活，因为这三个模型中有大量的参数。选择与模型复杂性密切相关的参数很重要。例如，随机森林模型中树的最大深度是一个<em class="mn">必须调整的</em>超参数。有兴趣的可以参考下面这个帖子。</p><div class="oa ob gp gr oc od"><a rel="noopener follow" target="_blank" href="/one-potential-cause-of-overfitting-that-i-never-noticed-before-a57904c8c89d"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd jd gy z fp oi fr fs oj fu fw jc bi translated">我以前从未注意到的过度拟合的一个潜在原因</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">当训练数据中的性能比测试数据中的性能好得多时，就会发生过度拟合。默认…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">towardsdatascience.com</p></div></div><div class="om l"><div class="os l oo op oq om or lb od"/></div></div></a></div><p id="d969" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">注意，管道中的步骤名称需要在超参数空间中指定。比如深度学习模型中的历元数命名为<strong class="lk jd"><em class="mn">“dl _ model _ _ epochs”</em></strong>，其中<strong class="lk jd"><em class="mn">“dl _ model”</em></strong>是我的管道中深度学习模型的名称<strong class="lk jd"><em class="mn">“epochs”</em></strong>是可以传递给我的深度学习模型的参数名称。它们在超参数空间中以字符串格式由“__”连接。</p><p id="9a7e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">第五步。通过交叉验证设置跨超参数空间的网格搜索功能。</strong></p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="3cf3" class="mv mw it np b gy nt nu l nv nw">    # set GridSearch via 5-fold cross-validation<br/>    ## clf_LR<br/>    grid1 = GridSearchCV(pipe1, cv=5, param_grid=param_grid1)<br/>    ## clf_RF<br/>    grid2 = GridSearchCV(pipe2, cv=5, param_grid=param_grid2)<br/>    ## clf_DL<br/>    grid3 = GridSearchCV(pipe3, cv=5, param_grid=param_grid3)</span></pre><p id="e734" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">与<em class="mn">随机搜索</em>相比，<em class="mn">网格搜索</em>的计算成本更高，因为它跨越了整个超参数空间。在这个项目中，我使用网格搜索，因为超参数空间相对较小。</p><p id="6877" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于每个网格搜索，我使用<strong class="lk jd"> <em class="mn"> 5重交叉验证</em> </strong>来评估超参数组合的平均性能。</p><p id="b14d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">第六步。运行调整过程。</strong></p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="f778" class="mv mw it np b gy nt nu l nv nw">    # run the hyperparameter tunning process<br/>    grid1.fit(X,y)<br/>    grid2.fit(X,y)<br/>    grid3.fit(X,y)</span></pre><p id="49eb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这一步非常简单，在三个定义的管道上执行网格搜索。</p><p id="10da" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，我们只需要运行如下函数:</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="3d11" class="mv mw it np b gy nt nu l nv nw">my_grid1,my_grid2,my_grid3,my_pipe1,my_pipe2,my_pipe3 = train_hyper_tune(X_train, y_train)</span></pre><p id="1543" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以通过拉出网格搜索结果中的最佳分数来检查训练性能。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/672dd43bc40ba30648770b1fb9c268c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*tSg1WhMdTULjxP1UaquJMQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">端到端游戏预测(由<a class="ae lh" href="https://medium.com/@jianan.jay.lin" rel="noopener">虞风</a></p></figure><p id="f8a7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">看起来随机森林在训练数据集上具有最好的性能。但是这三个模型彼此之间非常相似。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="153c" class="mv mw it bd mx my mz dn na nb nc dp nd lr ne nf ng lv nh ni nj lz nk nl nm iz bi translated">测试数据的模型评估</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f0223218cefb48b4a6eead4bd2ef477e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mJ0VWgYLoeADUc3z"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">韦德·奥斯汀·埃利斯在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2556" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在前面的步骤中选择了超参数之后，我使用它们在整个训练数据上重新训练模型。代码如下所示:</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="7ff8" class="mv mw it np b gy nt nu l nv nw">def train_on_entire(X,y,pipe,grid_res):<br/>    # fit pipeline<br/>    pipe.set_params(**grid_res.best_params_).fit(X, y)<br/>    # return the newly trained pipeline<br/>    return pipe</span></pre><p id="72e9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里，<strong class="lk jd"><em class="mn">* * grid _ RES . best _ params _</em></strong>用于将网格搜索中的最佳参数传递给管道，以进行超参数设置。</p><p id="5d99" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在用X和y重新调整后，返回的管道<strong class="lk jd"> <em class="mn">管道</em> </strong>是在整个训练数据集上完全训练的模型。</p><p id="44c1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，我们需要在测试数据集上评估这个经过训练的模型。</p><pre class="ks kt ku kv gt no np nq nr aw ns bi"><span id="509e" class="mv mw it np b gy nt nu l nv nw">train_on_entire(X_train,y_train,my_pipe1,my_grid1).score(X_test,y_test)<br/>train_on_entire(X_train,y_train,my_pipe2,my_grid2).score(X_test,y_test)<br/>train_on_entire(X_train,y_train,my_pipe3,my_grid3).score(X_test,y_test)</span></pre><p id="252d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">逻辑回归、随机森林分类器和深度学习分类器在准确度方面的性能分别为<strong class="lk jd"> 0.869 </strong>、<strong class="lk jd"> 0.901 </strong>和<strong class="lk jd"> 0.877 </strong>。</p><p id="d792" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从结果中我们可以得出几个结论。<strong class="lk jd"> <em class="mn">首先，</em> </strong>随机森林分类器在这次预测中似乎表现优于其他两种方法。<strong class="lk jd"> <em class="mn">第二，</em> </strong>深度学习方法在处理这样的表格化数据集时并没有表现出优势。<strong class="lk jd"> <em class="mn">第三，</em> </strong>这三种方法都说明勒布朗的比赛数据对比赛结果有预测能力，可见他在球队中的统治地位。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="24ea" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mn">就是这样，端到端的机器学习项目。我希望你从中学到了一些东西。</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ou"><img src="../Images/f82fd43a6637551605849d3567b15f6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qLkGDlcaWr-zgoDP"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">克里斯汀娜·戈塔迪在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="2f45" class="mv mw it bd mx my mz dn na nb nc dp nd lr ne nf ng lv nh ni nj lz nk nl nm iz bi translated">参考资料:</h2><ol class=""><li id="76b8" class="ov ow it lk b ll ox lo oy lr oz lv pa lz pb md pc pd pe pf bi translated">【https://keras.io/scikit-learn-api/ T4】</li><li id="d4db" class="ov ow it lk b ll pg lo ph lr pi lv pj lz pk md pc pd pe pf bi translated"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . model _ selection。stratifiedkfold . html # sk learn . model _ selection。分层折叠</a></li><li id="49f1" class="ov ow it lk b ll pg lo ph lr pi lv pj lz pk md pc pd pe pf bi translated"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . pipeline . pipeline . html</a></li><li id="5b9f" class="ov ow it lk b ll pg lo ph lr pi lv pj lz pk md pc pd pe pf bi translated"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . linear _ model。LogisticRegression.html</a></li><li id="4f27" class="ov ow it lk b ll pg lo ph lr pi lv pj lz pk md pc pd pe pf bi translated"><a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . randomforestclassifier . html</a></li></ol></div></div>    
</body>
</html>