<html>
<head>
<title>Constrained Optimization demystified, with implementation in Python.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">去神秘化的约束优化，用Python实现。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/constrained-optimization-demystified-with-implementation-in-python-235639546fa9?source=collection_archive---------6-----------------------#2020-02-01">https://towardsdatascience.com/constrained-optimization-demystified-with-implementation-in-python-235639546fa9?source=collection_archive---------6-----------------------#2020-02-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ea2c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">设计一种新的鲁棒约束优化算法。</em></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/e1f4cbfc679c27a823a3cbe3030f1af1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FRo8mTg6CEM9sFb4"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><a class="ae kz" href="http://unsplash.com" rel="noopener ugc nofollow" target="_blank"> src </a></p></figure><p id="814a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="lw">非线性约束优化问题是一类重要的问题，具有广泛的工程和科学应用。在本文中，我们将看到简单无约束优化技术的改造如何导致约束优化问题的混合算法。稍后，我们将通过对一个问题集的详细分析来观察算法的健壮性，并通过将结果与python中的一些内置函数进行比较来监控optima的性能。</em></p><p id="fda8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">关键词</strong> —约束优化、多变量优化、单变量优化。</p><p id="fbf2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">许多工程设计和决策问题的目标是优化功能，同时要求满足由于空间、强度或稳定性考虑而产生的一些约束。因此，<strong class="lc iu">约束优化是指在某些变量存在约束的情况下，针对这些变量优化目标函数的过程。</strong></p><p id="3cb3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">具有N个变量的约束优化问题由下式给出:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/00e3a4cb27cc686d302e22c91afb59d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*3-OifVW0gAKXThKdhI6n_g.png"/></div></figure><p id="64a4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">——其中<strong class="lc iu"><em class="lw">gⱼ(x)</em></strong><em class="lw"/>为j个不等式约束，<strong class="lc iu"><em class="lw">【hₖ(x)</em></strong>为k个等式约束，<strong class="lc iu"> <em class="lw"> f(x) </em> </strong>为待优化的目标函数。让我们了解一些优化中常用的术语。</p><h1 id="57c6" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">理论</h1><p id="962b" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ms ll lm ln mt lp lq lr mu lt lu lv im bi translated">用数学最优化的说法，有两条途径可以找到最优值(数值上):</p><p id="bc1e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> 1。使用直接搜索法:</strong>这里只使用给定点的函数值来寻找最优。它的工作原理是比较一个点的邻域中的函数值，然后向导致函数值减少的方向移动(对于最小化问题)。当函数是<strong class="lc iu">不连续的，</strong>因此导数在该点不可用时，通常使用直接搜索方法。</p><p id="b70c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> 2。使用基于梯度的方法:</strong>这里，我们使用一阶和二阶导数来定位最优值。这些方法考虑了梯度信息，因此具有更快地<strong class="lc iu">收敛到最优值的优点。</strong></p><p id="3964" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">如何用数值求特定点的导数？</strong>我们使用中心差分法，数学上给出为{limit h - &gt; 0}:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/3b5ee6bb5cfe5889d0001f55dbda0d5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*PjQYSpv4GsG_N5bMaukIjA.png"/></div></figure><p id="9aee" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们提出的约束优化算法采用了两种单变量优化方法和一种多变量优化方法。我们的主要目的是将这个多变量约束优化问题转化为一个无约束的多变量优化问题，然后这个无约束问题可以用单变量优化方法来解决。</p><h2 id="b369" class="mw lz it bd ma mx my dn me mz na dp mi lj nb nc mk ln nd ne mm lr nf ng mo nh bi translated">单变量优化</h2><p id="0415" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ms ll lm ln mt lp lq lr mu lt lu lv im bi translated">同样，有两种途径可以找到单个变量的线性或非线性函数的最优解，一种是使用直接搜索方法，另一种是通过基于梯度的技术。人们可以单独使用这两种方法中的任何一种来找到最优解。我们的约束优化算法使用了这两种方法。使用直接搜索方法，我们将包围最优值，一旦我们有了最优值的特定界限，我们就可以使用基于梯度的方法(对于单变量函数)找到精确的最优值。</p><p id="51f4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">有许多直接搜索和基于梯度的方法来获得单变量函数的最优值。我们的方法使用边界相位法和割线法。</p><p id="294f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">注意:所有描述的优化方法都是迭代的。经过一系列迭代，我们逐渐收敛到最优值。</p><p id="4851" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">边界相位法:</strong>一种直接搜索法，用于寻找单变量无约束优化中最小值的上下界。算法给出为(<strong class="lc iu"><em class="lw">f’</em></strong>指1ˢᵗ阶在一点的导数):</p><ol class=""><li id="a1c8" class="ni nj it lc b ld le lg lh lj nk ln nl lr nm lv nn no np nq bi translated">选择初始猜测<strong class="lc iu"> x⁽⁰⁾，</strong>一个增量<strong class="lc iu">δ(~ 0)</strong>，设置迭代计数器<strong class="lc iu"> k=0 </strong>。</li><li id="3078" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">若<strong class="lc iu">f(x⁽⁰⁾-δ)</strong>&gt;<strong class="lc iu">f(x⁽⁰⁾+δ)</strong>，则δ为<strong class="lc iu">正</strong>。否则如果，<strong class="lc iu">f(x⁽⁰⁾-δ)</strong>&lt;<strong class="lc iu">f(x⁽⁰⁾+δ)</strong>，那么，δ就是<strong class="lc iu">负</strong>。否则转到<strong class="lc iu">步骤1 </strong>。</li><li id="e2b7" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">设定<strong class="lc iu">x⁽ᵏ⁺⁾=x⁽ᵏ⁾+</strong>2ᵏδ.<strong class="lc iu"/>(指数扰动)。</li><li id="ec57" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">如果<strong class="lc iu"> f(x⁽ᵏ⁺ ⁾) &lt; f(x⁽ᵏ⁾) </strong>，设置<strong class="lc iu"> k = k+1 </strong>并转到<strong class="lc iu"> step_3 </strong>。否则，最小值出现在<strong class="lc iu"> (x⁽ᵏ⁻ ⁾，x⁽ᵏ⁺ ⁾) </strong>和<strong class="lc iu">终止</strong>。</li></ol><p id="a2dc" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">割线法:</strong>一种非常流行的基于梯度的单变量优化方法。<strong class="lc iu"> </strong>终止条件是当函数在一点的梯度很小(~0)时。该方法如下:</p><ol class=""><li id="34bd" class="ni nj it lc b ld le lg lh lj nk ln nl lr nm lv nn no np nq bi translated">选择两点<strong class="lc iu"> a，b </strong>使得<strong class="lc iu">f’(a)</strong>和<strong class="lc iu">f’(b)</strong>符号相反。换句话说，<strong class="lc iu">f’(a)。f'(b) &lt; 0。</strong>选择<strong class="lc iu"> ε{epsilon} </strong>一个小数字，又名终止因子。设定<strong class="lc iu"> x₁= a </strong>和<strong class="lc iu"> x₂ = b </strong>。</li><li id="71a2" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">计算一个新的点<strong class="lc iu">z = x₂-(f'(x₂)*(x₂-x₁))/(f'(x₂)-f'(x₁))</strong>并找到<strong class="lc iu">f’(z)</strong>。</li><li id="e55e" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">如果<strong class="lc iu"> |f'(z)| ≤ ε </strong>，<strong class="lc iu">终止。<br/> </strong>否则如果<strong class="lc iu"> f'(z) &lt; 0，</strong>置位<strong class="lc iu"> x₁= z </strong>并转到<strong class="lc iu"> step_2 </strong>，<br/>否则如果<strong class="lc iu"> f'(z) ≥ 0，</strong>置位<strong class="lc iu"> x₂ = z </strong>并转到<strong class="lc iu"> step_2 </strong>。</li></ol><p id="19b7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">其他流行的基于梯度的单变量优化方法有<a class="ae kz" href="https://en.wikipedia.org/wiki/Bisection_method" rel="noopener ugc nofollow" target="_blank">二分法</a>、<a class="ae kz" href="https://en.wikipedia.org/wiki/Newton%27s_method" rel="noopener ugc nofollow" target="_blank">牛顿-拉普森法</a>等。</p><p id="f517" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">单向搜索:</strong>这里的目标是找到在特定方向上函数值将最小的地方。数学上，我们需要找到标量<strong class="lc iu">α</strong>(α)使得，<strong class="lc iu"> f(α) = f(x⁽ᵗ⁾+α.s⁽ᵗ⁾) </strong>被最小化，这是使用单变量优化方法实现的。{s⁽ᵗ⁾ =搜索方向}。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/a6ef174558c589e207bc6226055b2e66.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*OcNqvIlPw3HlDK7Sgp0bnQ.png"/></div></figure><p id="7da9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">注意:许多多变量优化技术不过是连续的单向搜索，沿着特定方向寻找最小点。</p><h2 id="b0e3" class="mw lz it bd ma mx my dn me mz na dp mi lj nb nc mk ln nd ne mm lr nf ng mo nh bi translated">可变度量方法(大卫顿-弗莱彻-鲍威尔方法):</h2><p id="e9e9" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ms ll lm ln mt lp lq lr mu lt lu lv im bi translated">DFP方法是一种基于梯度的<strong class="lc iu">多变量优化</strong>算法。它通过不考虑用于创建搜索方向的<strong class="lc iu"> hessian </strong>而更快地收敛到最优值，从而克服了其他几种多变量优化算法的局限性。搜索方向由下式给出:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/241ac9e409423fca59e8aa8284bd1798.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*o6KJQrJ-ZZROfPB7f7dJdQ.png"/></div></figure><p id="3cb4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">其中矩阵A由下式给出:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ny"><img src="../Images/57ed3a69245dd9de9051c6839409eb8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I7NXoI1rMIjmG8c04e_QQQ.png"/></div></div></figure><p id="444b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="lw"> e(x </em> ⁽ᵏ⁾ <em class="lw"> ) </em>代表函数在点<em class="lw"> x </em> ⁽ᵏ⁾.的梯度单向搜索涉及割线方法和边界相位方法，以在搜索空间中找到<strong class="lc iu"> α </strong>的值。单向搜索后获得的新的点是:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/ecc065785831612918992370bd5793d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*xB7BZcUMC2RfrYNcF5SXbw.png"/></div></figure><ol class=""><li id="3b56" class="ni nj it lc b ld le lg lh lj nk ln nl lr nm lv nn no np nq bi translated">选择初始猜测<strong class="lc iu"> x⁽⁰⁾ </strong>和终止参数<strong class="lc iu"> ε₁、ε₂ </strong>。(注意，这里的<strong class="lc iu"> x⁽⁰⁾ </strong>是矢量)。</li><li id="ecc4" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">在<strong class="lc iu"> x⁽⁰⁾ </strong>找到∇<strong class="lc iu">f(x⁽⁰⁾)</strong>{梯度<strong class="lc iu">T3】ft5 }并设置<strong class="lc iu">s⁽⁰⁾=-</strong>∇<strong class="lc iu">f(x⁽⁰⁾)</strong>{初始搜索方向}。</strong></li><li id="2a51" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">找到<strong class="lc iu">α</strong>(α)使得<strong class="lc iu"> f(x⁽⁰⁾ + α。s⁽⁰⁾) </strong>最小，终止参数<strong class="lc iu"> ε₁ </strong>。用<strong class="lc iu"> α*表示。</strong>设定<strong class="lc iu"> x⁽ ⁾ = x⁽⁰⁾ + α*s⁽⁰⁾ </strong>且k=1。算算∇<strong class="lc iu">f(x⁽⁾</strong>。{f(x⁽⁰⁾ + α。s⁽⁰⁾)是<strong class="lc iu"> α，</strong>的函数，我们将通过单变量优化方法找到这个<strong class="lc iu"> α* </strong>。</li><li id="5f7e" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">使用<em class="lw">eq</em><strong class="lc iu"><em class="lw">【1】</em></strong><em class="lw">和eq</em><strong class="lc iu"><em class="lw">【2】中的公式找到<strong class="lc iu"> s⁽ᵏ⁾ </strong>。</em>T41】</strong></li><li id="2611" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">找到λ⁽ᵏ⁾，让f(x⁽ᵏ⁾ +λ⁽ᵏ⁾.s⁽ᵏ⁾) 最小，终止因子<strong class="lc iu"> ε₁ </strong>。套，<strong class="lc iu"> x⁽ᵏ⁺ ⁾ = x⁽ᵏ⁾ +λ⁽ᵏ⁾.s⁽ᵏ⁾ </strong>。</li><li id="c73d" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">检查终止条件。||x⁽ᵏ⁺ ⁾ -x⁽ᵏ⁾||/||x⁽ᵏ⁾|| ≤ ε₂吗？<br/>  {||。||表示向量的范数}。</li><li id="9b81" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">如果是，<strong class="lc iu">终止；</strong>否则设置k = k+1，转到<strong class="lc iu"> step_4。</strong></li></ol><h2 id="3dc0" class="mw lz it bd ma mx my dn me mz na dp mi lj nb nc mk ln nd ne mm lr nf ng mo nh bi translated">罚函数法:</h2><p id="731b" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ms ll lm ln mt lp lq lr mu lt lu lv im bi translated">一个<strong class="lc iu">罚值</strong>(正则项)是我们添加到目标函数中的附加项，它有助于控制目标函数的过度波动。通过添加这些惩罚项，我们将约束问题转化为无约束问题，其结构使得最小化有利于满足约束，如下图所示。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oa"><img src="../Images/cd0f5ae42742a864378fec453d86bad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wCVl1rJB1-S_G0ujXHgSUw.png"/></div></div></figure><p id="f6b0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">简而言之，这种技术是在目标函数中增加一项，使得违反约束会产生很高的代价。这就是所谓的<strong class="lc iu">罚函数法</strong>。数学上，</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/eecf27654f7d4b950d5033cefd5f6e2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*7l6tNzRdRpsx_98RejHRbQ.png"/></div></figure><p id="1282" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">其中R是罚参数，P(x，R)是罚函数，ω是罚项。根据约束的可行性和类型，有各种类型的惩罚条款。这一项被称为<strong class="lc iu">括号操作符罚</strong>项。在哪里，</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oc"><img src="../Images/4fb23ffe53946b4f9d12d72887159e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x-m7cJguL_DJ-MbjC6AHYg.png"/></div></div></figure><p id="1e6a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">该方法给出如下:</p><ol class=""><li id="32e1" class="ni nj it lc b ld le lg lh lj nk ln nl lr nm lv nn no np nq bi translated">选择初始解<strong class="lc iu"> x⁽⁰⁾ </strong>和终止参数<strong class="lc iu"> ε₁，</strong>惩罚参数<strong class="lc iu"> R⁽⁰⁾，</strong>和一个更新因子<strong class="lc iu"> c </strong>。</li><li id="97d4" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">形成罚函数<strong class="lc iu">p(x⁽ᵗ⁾,r⁽ᵗ⁾)=f(x⁽ᵗ⁾)+ω(r⁽ᵗ⁾，g(x⁽ᵗ⁾)，h(x⁽ᵗ⁾)) </strong>。</li><li id="32df" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">使用<strong class="lc iu"> DFP </strong>方法找到r⁽ᵗ⁾).p(x⁽ᵗ⁾<strong class="lc iu">的最小值</strong>设解为<strong class="lc iu"> x⁽ᵗ⁺ ⁾ </strong>。{这个特殊的步骤是一个无约束优化问题}。对于DFP，我们最初的猜测是<strong class="lc iu"> x⁽ᵗ⁾.</strong></li><li id="6d49" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">检查终止条件:<br/>是<strong class="lc iu"> |P(x⁽ᵗ⁺ ⁾，R⁽ᵗ⁾) - P(x⁽ᵗ⁾，R⁽ᵗ⁻ ⁾)| </strong> ≤ <strong class="lc iu"> ε₂ </strong>？{|.|是mod函数}。<br/>如果是，设置<strong class="lc iu"> xᵀ= x⁽ᵗ⁺ ⁾ </strong>和<strong class="lc iu">终止</strong>，否则<br/>转到<strong class="lc iu"> step_5。</strong></li><li id="8ea6" class="ni nj it lc b ld nr lg ns lj nt ln nu lr nv lv nn no np nq bi translated">更新<strong class="lc iu"> R⁽ᵗ⁺ ⁾= c*R⁽ᵗ⁾ </strong>。设置，t=t+1，转到<strong class="lc iu"> step_2 </strong>。</li></ol><p id="bd91" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">注意:所有描述的优化方法都是迭代的。经过一系列迭代，我们逐渐收敛到最优值。我们在每次迭代中更新这个R值。</p><p id="e379" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">使用罚函数法有几个限制。首先，它导致轮廓的变形，由于这种变形，算法需要更长的时间来收敛。而且，这导致了人为的局部最优值的存在。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi od"><img src="../Images/e13d6cbeb5219f977220fa2dbdd36bd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mD9pT4iYcTvb4Xdhm13CpQ.png"/></div></div></figure><p id="755c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为了实现的目的，我们将只坚持罚函数法。还有另一种方法称为<a class="ae kz" href="https://en.wikipedia.org/wiki/Lagrange_multiplier" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">乘数法</strong></a><strong class="lc iu"/>用来克服失真的局限性。它基本上是对罚函数法的一个微小修改。该方法不会扭曲轮廓，而是具有将轮廓移向约束最佳点的效果。所以，这里人为的局部最优值为零。</p><p id="f17b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">乘数的<strong class="lc iu">方法和<strong class="lc iu">罚函数方法</strong>都将约束优化问题转化为无约束问题，进而可以用任何多变量优化方法求解。</strong></p><p id="1a39" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">嗯，就这样吧！！！如果你已经走了这么远，太好了！现在，让我们看看我们的方法的流程图，然后去实现。为了便于实现，我们将只讨论罚函数法。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/5aa30c21e95ff8e7df83b8a17f08d282.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*8twjvYKUkHnHNDmUq4XfVw.png"/></div></figure><h2 id="60c1" class="mw lz it bd ma mx my dn me mz na dp mi lj nb nc mk ln nd ne mm lr nf ng mo nh bi translated">Himmelblau函数:</h2><p id="ab4b" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ms ll lm ln mt lp lq lr mu lt lu lv im bi translated">为了说明我们的方法，我们将使用著名的Himmelblau函数(见图)，给出为<em class="lw"> f(x，y)=(x+y11)+(x+y7)</em>。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi of"><img src="../Images/f4a78fa41696cea733d9ef9af2e40401.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MDGQRnOrsGhZHAxk.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><a class="ae kz" href="http://Wikimedia.org" rel="noopener ugc nofollow" target="_blank"> src </a></p></figure><p id="31c0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们使用我们提出的算法来解决下面的约束优化问题。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi og"><img src="../Images/5d4214cb0318aa2ee9cad58d1848f03b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*qB7LrqZnvhE09Q6gxjYzjg.png"/></div></figure><h1 id="485d" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">履行</h1><p id="d185" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ms ll lm ln mt lp lq lr mu lt lu lv im bi translated"><strong class="lc iu"> DFP </strong>方法用于多变量优化，结合<strong class="lc iu">边界相位</strong>和<strong class="lc iu">割线方法</strong>用于获得单向搜索。代码用python实现，托管在我的GitHub <a class="ae kz" href="https://github.com/aakash2016/Optimization_" rel="noopener ugc nofollow" target="_blank"> repo </a>中。我们现在简要演示所使用的每个函数:</p><p id="c424" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> <em class="lw"> multi_f: </em> </strong>该函数取一个<strong class="lc iu">输入向量x </strong>(搜索空间中的一个点)并返回该点的函数值(惩罚函数值)。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="ee07" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"><em class="lw">grad _ multi _ f:</em></strong>该函数使用<strong class="lc iu">中心差分</strong>方法计算搜索空间中特定点的梯度向量。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="3dc6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> <em class="lw">包围_: </em> </strong>该函数实现了用于包围<strong class="lc iu"> α* </strong>(通过执行单向搜索获得的最小值)的边界相位方法。它取一个矢量<strong class="lc iu"> x </strong>和矢量<strong class="lc iu"> s </strong>(搜索方向)并输出一个区间，基于该区间可以对<strong class="lc iu"> α </strong>进行评估。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="9f47" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> <em class="lw"> f _dash: </em> </strong>该函数用于使用中心差分法得到单变量函数的一阶微分。(代表<strong class="lc iu"><em class="lw">f’</em></strong>)。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="429d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> <em class="lw">割线_最小值:</em> </strong>该函数将从边界相位方法中找到的边界、一个点<strong class="lc iu"> x </strong>和一个搜索方向<strong class="lc iu"> s </strong>作为输入，并评估alphastar。</p><p id="c0c8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> <em class="lw"> compute_z: </em> </strong>该函数用于计算割线法中使用的公式:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/08800939e921d079d0cda4038c979b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*MPkRDIm785OUO1uOAPUkmA.png"/></div></figure><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="4814" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> <em class="lw"> DFP: </em> </strong>它只取输入向量<strong class="lc iu"> <em class="lw"> x </em> </strong> <em class="lw"> </em>作为自变量，返回解向量。在<em class="lw">主</em>函数内调用该函数，直到满足罚函数法的终止条件。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="7992" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">它首先从输入向量<strong class="lc iu"><em class="lw">【x，</em> </strong>中找到一个搜索方向<strong class="lc iu"> s </strong>，然后通过调用边界相位和割线方法执行单向搜索，以找到最优的<strong class="lc iu"> α </strong>。然后，它通过评估等式(1)和(2)找到新的搜索方向<em class="lw">。该过程继续进行，直到满足DFP的终止条件，并且我们已经为该特定序列找到了该无约束问题的最优解。</em></p><h2 id="0248" class="mw lz it bd ma mx my dn me mz na dp mi lj nb nc mk ln nd ne mm lr nf ng mo nh bi translated">结果</h2><p id="a09c" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ms ll lm ln mt lp lq lr mu lt lu lv im bi translated">完整的代码在我的Github <a class="ae kz" href="https://github.com/aakash2016/Optimization_" rel="noopener ugc nofollow" target="_blank"> repo </a>上。注意，我们的方法是一般化的，并且适用于人们想要工作的任何数量的维度。<br/>我们算法的参数设置是:<br/><strong class="lc iu">* m = 2</strong>{指定我们正在处理的总尺寸}，<br/> <strong class="lc iu"> * R=0.1 </strong> {panalty参数}，<br/><strong class="lc iu">* c = 1.55</strong>{用于更新r的因子}，<br/> <strong class="lc iu"> * x_ip </strong>(初始猜测)= <strong class="lc iu"> (0.11，0.1)ᵀ </strong>。</p><p id="427b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我建议读者尝试使用不同的初始猜测，并使用这些参数值。因此，我们的算法在<strong class="lc iu"> 14个序列后收敛。我们得到了约束优化问题的最优解。</strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ok"><img src="../Images/2e4ae02e7399c745eea301cd573577e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cPwGBOt2fPcEJnIhKEF-Sw.png"/></div></div></figure><p id="e307" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们将我们的结果与从<strong class="lc iu"> <em class="lw"> python </em> </strong>中<strong class="lc iu"> <em class="lw"> scipy </em> </strong>库的<strong class="lc iu"> <em class="lw">优化</em> </strong>模块中找到的结果进行比较。{使用相同的初始猜测}:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ol"><img src="../Images/94669653f1a1e57bd1e2888bf42793be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3qH-hDgdWMU9Bj1jOoexpw.png"/></div></div></figure><p id="08b6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">结果非常接近，为了得到更接近的结果，我们可以尝试非常小的终止因子。我还尝试了一系列不同的初始猜测。是的，它们都融合了！！</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi om"><img src="../Images/684cb899cddc9d27304aada437e6ba98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*WvKGTLtQTZwHs8MfNt4qTw.png"/></div></figure><blockquote class="on oo op"><p id="5259" class="la lb lw lc b ld le ju lf lg lh jx li oq lk ll lm or lo lp lq os ls lt lu lv im bi translated"><strong class="lc iu">“过早优化是万恶之源”</strong> —唐纳德·克努特(Donald Knuth)。</p></blockquote><p id="882b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我希望你和我一起享受约束优化的过程。我很想知道任何阅读这篇文章的人的反馈(鼓掌👏🏼也会得到很好的反馈😇).我很乐意回答对上述任何概念的疑问/问题。你可以通过Linkedin联系我。</p><p id="04fe" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，特别感谢迪帕克·夏尔马教授，IIT·古瓦哈蒂，他教了我优化课程，作为我课程的一部分。</p><p id="7803" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">谢谢大家！！</p></div></div>    
</body>
</html>