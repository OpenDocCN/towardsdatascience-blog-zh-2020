<html>
<head>
<title>Fine tune GloVe embeddings using Mittens</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用连指手套微调手套嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39?source=collection_archive---------17-----------------------#2020-04-19">https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39?source=collection_archive---------17-----------------------#2020-04-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a9cd686a8d8488e2bf1d1401b97d11aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zS_RY5siEB-vT2T47dnoSg.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://unsplash.com/@worthyofelegance?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">亚历克斯</a>在<a class="ae kf" href="https://unsplash.com/s/photos/mittens?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="8052" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2013年后，单词嵌入甚至在NLP社区之外也变得非常流行。<a class="ae kf" href="http://jalammar.github.io/illustrated-word2vec/" rel="noopener ugc nofollow" target="_blank"> Word2vec </a>和<a class="ae kf" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank"> GloVe </a>属于静态单词嵌入家族。然后是一系列的动态嵌入伯特，ELMO，罗伯塔，阿尔伯特，XLNET..所有这些嵌入都依赖于语境词。在这篇文章中，让我们看看如何微调静态嵌入。</p><p id="634d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您是否曾经遇到过这样的情况:当您拥有一个非常小的数据集，并且想要应用静态单词嵌入时，却面临以下问题:</p><ul class=""><li id="0bf9" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">预训练模型中不存在数据集词汇</li><li id="49aa" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">无法从数据集中训练整个模型，因为它太小</li></ul><p id="1f74" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">解决方案是加载预先训练好的模型，并使用来自数据集的新数据对它们进行微调，这样，看不见的词汇也被添加到模型中。</p><p id="1a4f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">为什么不能微调word2vec: </strong></p><p id="4753" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://radimrehurek.com/gensim/" rel="noopener ugc nofollow" target="_blank"> Gensim </a>是word2vec使用最多的库，微调这些嵌入有一些问题。新数据集中词汇的嵌入将在不对旧嵌入进行任何改变的情况下被训练。这导致预训练嵌入和新嵌入之间的差异。</p><p id="2f72" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://fasttext.cc/" rel="noopener ugc nofollow" target="_blank"> fasttext </a>也不提供微调功能。</p><h1 id="290f" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">微调手套</h1><p id="4ab4" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated"><a class="ae kf" href="https://github.com/roamanalytics/mittens" rel="noopener ugc nofollow" target="_blank"> Mittens </a>是一个用于微调手套嵌入的python库。这个过程包含3个简单的步骤。加载预训练的模型，建立新数据集的共生矩阵，并训练新的嵌入。</p><p id="72d5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> <em class="mv">加载预训练模型</em> </strong></p><p id="c322" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Mittens需要将预训练的模型作为字典加载。所以，让我们做同样的事情。从<a class="ae kf" href="https://nlp.stanford.edu/projects/glove" rel="noopener ugc nofollow" target="_blank">https://nlp.stanford.edu/projects/glove</a>获得预训练模型</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="c4de" class="nf lt it nb b gy ng nh l ni nj">def glove2dict(glove_filename):<br/>    with open(glove_filename, encoding='utf-8') as f:<br/>        reader = csv.reader(f, delimiter=' ',quoting=csv.QUOTE_NONE)<br/>        embed = {line[0]: np.array(list(map(float, line[1:])))<br/>                for line in reader}<br/>    return embed</span><span id="3d42" class="nf lt it nb b gy nk nh l ni nj">glove_path = "glove.6B.50d.txt"<br/>pre_glove = glove2dict(glove_path)</span></pre><p id="97c4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> <em class="mv">数据预处理</em> </strong></p><p id="3e03" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在构建单词的共现矩阵之前，让我们对数据集做一些预处理。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="b1b2" class="nf lt it nb b gy ng nh l ni nj">sw = list(stop_words.ENGLISH_STOP_WORDS)<br/>brown_data = brown.words()[:200000]<br/>brown_nonstop = [token.lower() for token in brown_data if (token.lower() not in sw)]<br/>oov = [token for token in brown_nonstop if token not in pre_glove.keys()]</span></pre><p id="36f7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们已经使用布朗语料库作为样本数据集，并且<em class="mv"> oov </em>表示未在预训练手套中出现的词汇。共生矩阵是从<em class="mv"> oov </em> s构建的。它是一个稀疏矩阵，需要O(n^2).的空间复杂度因此，有时为了节省空间，必须过滤掉真正罕见的单词。这是一个可选步骤。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="38c4" class="nf lt it nb b gy ng nh l ni nj">def get_rareoov(xdict, val):<br/>    return [k for (k,v) in Counter(xdict).items() if v&lt;=val]</span><span id="53f5" class="nf lt it nb b gy nk nh l ni nj">oov_rare = get_rareoov(oov, 1)<br/>corp_vocab = list(set(oov) - set(oov_rare))</span></pre><p id="63ee" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果需要，删除那些罕见的<em class="mv">oov</em>，并准备数据集</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="129d" class="nf lt it nb b gy ng nh l ni nj">brown_tokens = [token for token in brown_nonstop if token not in oov_rare]<br/>brown_doc = [' '.join(brown_tokens)]<br/>corp_vocab = list(set(oov))</span></pre><p id="ecb8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> <em class="mv">构建共生矩阵:</em> </strong></p><p id="22c7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们需要单词-单词共现，而不是通常的术语-文档矩阵。sklearn的<em class="mv"> CountVectorizer </em>将文档转化为word-doc矩阵。矩阵乘法<code class="fe nl nm nn nb b">Xt*X</code>给出单词-单词共现矩阵。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="6b9b" class="nf lt it nb b gy ng nh l ni nj">cv = CountVectorizer(ngram_range=(1,1), vocabulary=corp_vocab)<br/>X = cv.fit_transform(brown_doc)<br/>Xc = (X.T * X)<br/>Xc.setdiag(0)<br/>coocc_ar = Xc.toarray()</span></pre><p id="4473" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> <em class="mv">微调连指手套型号</em> </strong></p><p id="bf77" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要安装连指手套，请尝试<code class="fe nl nm nn nb b">pip install -U mittens</code>查看<a class="ae kf" href="https://github.com/roamanalytics/mittens" rel="noopener ugc nofollow" target="_blank">完整文档</a>了解更多信息。只需实例化模型并运行fit函数。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="8564" class="nf lt it nb b gy ng nh l ni nj">mittens_model = Mittens(n=50, max_iter=1000)<br/>new_embeddings = mittens_model.fit(<br/>    coocc_ar,<br/>    vocab=corp_vocab,<br/>    initial_embedding_dict= pre_glove)</span></pre><p id="468e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将模型保存为pickle供将来使用。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="e24e" class="nf lt it nb b gy ng nh l ni nj">newglove = dict(zip(corp_vocab, new_embeddings))<br/>f = open("repo_glove.pkl","wb")<br/>pickle.dump(newglove, f)<br/>f.close()</span></pre><p id="f37c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是完整的代码。</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="ebe7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您阅读这篇文章。欢迎通过<a class="ae kf" href="https://github.com/chmodsss" rel="noopener ugc nofollow" target="_blank"> Github </a>、<a class="ae kf" href="https://twitter.com/chmodsss" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae kf" href="https://www.linkedin.com/in/sivasuryas/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>联系我。干杯！</p><p id="d1d2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mv">来源:<br/> </em> 1。<em class="mv"/><a class="ae kf" href="https://github.com/roamanalytics/mittens" rel="noopener ugc nofollow" target="_blank">https://github.com/roamanalytics/mittens</a><br/>2。<a class="ae kf" href="https://surancy.github.io/co-occurrence-matrix-visualization/" rel="noopener ugc nofollow" target="_blank">https://surancy . github . io/co-occurrence-matrix-visualization</a></p></div></div>    
</body>
</html>