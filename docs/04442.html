<html>
<head>
<title>Training EfficientDet Object Detection Model with a Custom Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练效率使用自定义数据集检测对象模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-efficientdet-object-detection-model-with-a-custom-dataset-25fb0f190555?source=collection_archive---------11-----------------------#2020-04-21">https://towardsdatascience.com/training-efficientdet-object-detection-model-with-a-custom-dataset-25fb0f190555?source=collection_archive---------11-----------------------#2020-04-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9688" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在具有不同类别数量的<a class="ae ki" href="https://blog.roboflow.com/the-ultimate-guide-to-object-detection/" rel="noopener ugc nofollow" target="_blank">自定义对象检测任务</a>上训练和使用 EfficientDet 的教程。<em class="kj">我们还在博客上发布了</em> <a class="ae ki" href="https://blog.roboflow.ai/training-efficientdet-object-detection-model-with-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank"> <em class="kj">如何在你自己的数据集</em> </a> <em class="kj">上训练效率。</em></h2></div><p id="5997" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">* * *注:YOLOv5 已出版。如果您特别是为了效率而来到这里，请为效率而停留。否则考虑在 Colab 中运行<a class="ae ki" href="https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank"> YOLOv5 PyTorch 教程。在几分钟内，您将拥有一个基于自定义数据的高性能、训练有素的 YOLOv5 模型。</a><a class="ae ki" href="https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank">训练 YOLOv5 </a>。</p><p id="c74d" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">谷歌大脑团队最近<a class="ae ki" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank">发表了 EfficientDet，</a>重新思考卷积神经网络的模型缩放。在本帖中，我们提供了一个教程，教你如何在你自己的数据上训练和使用 EfficientDet，使用不同数量的类。</p><p id="26ba" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">原文:请看这篇关于<a class="ae ki" href="https://blog.roboflow.ai/training-efficientdet-object-detection-model-with-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank">如何训练效率的博文。</a></p><p id="8acd" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">如果你想直接进入代码实现，跳到我们的<a class="ae ki" href="https://colab.research.google.com/drive/1ZmbeTro4SqT7h_TfW63MLdqbrCUk_1br#scrollTo=KwDS9qqBbMQa" rel="noopener ugc nofollow" target="_blank"> EfficientDet Training Colab 笔记本</a>。Colab 可以免费使用，并提供了一个配有 GPU 计算资源的 python 编程环境。</p><p id="f749" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">在我们已经看到的任务中(截至 2020 年 4 月)，<strong class="km iu"> EfficientDet 在对象检测模型架构</strong>中以最少的训练周期实现了最佳性能，使其成为高度可扩展的架构，尤其是在计算能力有限的情况下。这与 EfficientDet 作者发表的结果一致。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/105caca6bed852ead29df4f14ba326ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ApAKUWtseHcvRV2U.png"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">EfficientDet 在速度和准确性方面都非常高效(<a class="ae ki" href="https://github.com/google/automl/tree/master/efficientdet" rel="noopener ugc nofollow" target="_blank"> Source </a>)</p></figure><p id="ba87" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">EfficientDet 是<a class="ae ki" href="https://arxiv.org/pdf/1905.11946.pdf" rel="noopener ugc nofollow" target="_blank"> EfficientNet </a>的对象检测版本，基于 EfficientNet 在图像分类任务中取得的成功。EfficientNets 来自一系列模型，这些模型在基准任务上实现了高性能，同时控制了许多效率参数，如模型大小和 FLOPS。该网络以一系列型号 d0-d7 交付，基本型号被认为比型号更小的 YOLOv3 性能更好(不久将推出更多)。</p><p id="c32c" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">在这篇文章中，我们探索了在自定义数据集上实现 EfficientNet 的 PyTorch，演示了如何对自己的数据集做同样的事情。</p><h1 id="569c" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">我们的示例数据集</h1><p id="4e65" class="pw-post-body-paragraph kk kl it km b kn mo ju kp kq mp jx ks kt mq kv kw kx mr kz la lb ms ld le lf im bi translated">我们的数据集包含棋盘上 292 个棋子的图像。每个棋子都标有一个描述棋子类别{白骑士、白卒、黑皇后……}的边界框。我们的自定义数据集总共有 12 个类，这与进行培训的 COCO 中的类的数量不匹配。别担心！模型架构将无缝地<strong class="km iu">适应您的定制数据集包含的类的数量</strong>。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/1ee6c6d6b3a17d8f4e7c7c906cc152a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/0*fNktfw2gUX2vIlE2"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">roboflow.ai 公共数据集中的标签图像</p></figure><h1 id="e936" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">准备数据</h1><p id="a2ec" class="pw-post-body-paragraph kk kl it km b kn mo ju kp kq mp jx ks kt mq kv kw kx mr kz la lb ms ld le lf im bi translated">直接从数据收集到模型训练会导致次优的结果。数据可能有问题。即使没有，应用图像增强也会扩展数据集并减少过度拟合。</p><p id="1a40" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">为对象检测准备图像包括但不限于:</p><ul class=""><li id="069a" class="mu mv it km b kn ko kq kr kt mw kx mx lb my lf mz na nb nc bi translated">验证您的注释是否正确(例如，图像中没有任何注释超出框架)</li><li id="cfbb" class="mu mv it km b kn nd kq ne kt nf kx ng lb nh lf mz na nb nc bi translated">确保图像的 EXIF 方向正确(即图像在磁盘上的存储方式不同于您在应用程序中查看的方式，<a class="ae ki" href="https://news.ycombinator.com/item?id=21207411" rel="noopener ugc nofollow" target="_blank">查看更多信息</a>)</li><li id="5e17" class="mu mv it km b kn nd kq ne kt nf kx ng lb nh lf mz na nb nc bi translated">调整图像大小并更新图像注释以匹配新调整的图像大小</li><li id="dbf1" class="mu mv it km b kn nd kq ne kt nf kx ng lb nh lf mz na nb nc bi translated">各种可以提高模型性能的颜色校正，如灰度和对比度调整</li><li id="bdcb" class="mu mv it km b kn nd kq ne kt nf kx ng lb nh lf mz na nb nc bi translated">格式化注释以匹配模型输入的需求(例如，为 TensorFlow 生成<a class="ae ki" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"> TFRecords，或者为 YOLO </a>的某些<a class="ae ki" href="https://github.com/qqwweee/keras-yolo3" rel="noopener ugc nofollow" target="_blank">实现生成一个平面文本文件)。</a></li></ul><p id="3f4d" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">与表格数据类似，清理和扩充图像数据比模型中的架构更改更能提高最终模型的性能。</p><p id="dd1f" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">Roboflow Organize 专为无缝解决这些挑战而构建。事实上，Roboflow Organize 将您需要编写的代码减少了一半，同时为您提供了更多的预处理和增强选项。</p><p id="fd2d" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">对于我们特定的国际象棋问题，我们已经预处理过的国际象棋数据可以在 Roboflow 上获得。</p><p id="32b9" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">要么将此数据集下载到您的免费 Roboflow 帐户，要么创建 COCO JSON 格式的下载。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/a524b86b67f671d8033bdbe282643422.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S2RTT3th9OjNEZXp"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">在 Roboflow 的数据集上点击“下载”允许我们选择任何注释输出格式。</p></figure><p id="f934" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">在选择了我们的注释格式之后，Roboflow 提供了一个 curl 脚本(“Show Download Code”)，我们可以在其中访问我们的数据集。</p><p id="d24c" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">然后，我们可以使用这个 curl 脚本将数据导入到我们正在使用的 Colab 笔记本中。Colab 是一个由 Google 提供的 Jupyter 笔记本 python 编程环境，提供免费的 GPU 使用。Colab 可以免费启动，但是如果您的笔记本闲置 15 分钟左右，可能会超时。</p><p id="80b9" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">跳到我们的<a class="ae ki" href="https://colab.research.google.com/drive/1ZmbeTro4SqT7h_TfW63MLdqbrCUk_1br#scrollTo=KwDS9qqBbMQa" rel="noopener ugc nofollow" target="_blank"> EfficientDet Colab 笔记本</a>。</p><p id="8259" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">一旦我们的数据下载完毕，我们将检查文件夹结构。Coco json 数据来自我们在 Roboflow 中设置的数据中确定的训练、验证和测试分割。检查 train 文件夹，我们看到我们的数据以一组图像和一个注释文件的形式保存下来。然后，我们以我们的模型所期望的方式创建文件结构，但是不需要额外的数据清理！</p><h1 id="517f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">培养</h1><p id="1641" class="pw-post-body-paragraph kk kl it km b kn mo ju kp kq mp jx ks kt mq kv kw kx mr kz la lb ms ld le lf im bi translated">对于培训，我们通过<a class="ae ki" href="https://github.com/signatrix/efficientdet" rel="noopener ugc nofollow" target="_blank"> signatrix </a>导入了 EfficientDet 的 pytorch 实现。我们的实现使用 EfficientDet-d0 的基本版本。我们从 EfficientNet 基础主干进行训练，不使用网络检测器部分的预训练检查点。我们在训练集中训练了 20 个纪元。实现自然地适应训练类的数量，这与 TensorFlow 中最初的网络版本相比是一个很好的对比。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nm"><img src="../Images/5d2535b36f059b47d92869df3f6eaad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xp5FQZ6kDgRg7_uK"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">训练收敛:这个网络的自动性质甚至为你调整学习速度！</p></figure><h1 id="b7c8" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">推理</h1><p id="5ff5" class="pw-post-body-paragraph kk kl it km b kn mo ju kp kq mp jx ks kt mq kv kw kx mr kz la lb ms ld le lf im bi translated">在训练期间，我们的模型<strong class="km iu">保存。onnx 文件</strong>，可以在推理时轻松调用。我们调用这些文件来设置一个推断检测器，并简单地将一个图像、我们的类列表和一个预测阈值传递给我们的推断器。预测阈值可以根据您的使用情况动态调整，以控制精确度和召回率。</p><p id="4ff1" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated"><strong class="km iu">我们见证了快速的推理时间</strong>，根据一些测试图像，看起来网络很快适应了我们的自定义图像检测问题！</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/2a6db8033703800ab9a37e7a94c3480c.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/0*U3N_JrleLVzwJbSt"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">EfficientDet 模型似乎很快就推广到了国际象棋</p></figure><h1 id="211d" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">减轻我们的体重</h1><p id="8176" class="pw-post-body-paragraph kk kl it km b kn mo ju kp kq mp jx ks kt mq kv kw kx mr kz la lb ms ld le lf im bi translated">我们输出训练过的模型。onxx 文件到 Google Drive 以备将来使用。您可以简单地将这些文件拉回来，并为您的应用程序重新构建推理器！</p><p id="13e2" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">在笔记本的底部，我们提供了一个示例，说明如何将训练好的模型权重拉回来，并在您的应用程序中使用它们进行推理。在以后的文章中，我们将提供更多关于如何在您的应用程序中使用 EfficientDet 的细节。</p><p id="bd40" class="pw-post-body-paragraph kk kl it km b kn ko ju kp kq kr jx ks kt ku kv kw kx ky kz la lb lc ld le lf im bi translated">这就是您所拥有的——一种快速而简单的方法，可以根据您自己的数据，针对您自己的定制用例，使用不同数量的类，开始构建 EffienctDet 原型。</p><h1 id="9c22" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">后续步骤</h1><p id="1042" class="pw-post-body-paragraph kk kl it km b kn mo ju kp kq mp jx ks kt mq kv kw kx mr kz la lb ms ld le lf im bi translated">在未来的博客文章中，我们将对 EfficientDet 模型和 YoloV3 进行更细致的评估，包括训练时间、模型大小、内存占用和推理时间。我们还计划<a class="ae ki" href="https://roboflow.ghost.io/ghost/#/editor/post/5e98c6df166ca80038cb25d7" rel="noopener ugc nofollow" target="_blank">分解 EfficientDet </a>的架构，以便更好地理解魔法是如何发生的。</p></div></div>    
</body>
</html>