<html>
<head>
<title>Yellowbrick — Analyze Your Machine Learning Model with Visualizations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Yellowbrick —通过可视化分析您的机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yellowbrick-analyze-your-machine-learning-model-with-visualizations-f2c65ab2e229?source=collection_archive---------43-----------------------#2020-09-10">https://towardsdatascience.com/yellowbrick-analyze-your-machine-learning-model-with-visualizations-f2c65ab2e229?source=collection_archive---------43-----------------------#2020-09-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6555" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于机器学习可视化的 Python 库</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/431ba4a4f2e39662268347bb3c2da408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ULiCRVQyp9ZDVmGjQ9HXYQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Joshua Hoehne 在<a class="ae ky" href="https://unsplash.com/s/photos/brick?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="a222" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.scikit-yb.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> Yellowbrick </a>是一个 Python 机器学习可视化库。它本质上是建立在 Scikit-learn 和 Matplotlib 之上的。Yellowbrick 提供了信息丰富的可视化，以更好地评估机器学习模型。这也有助于模型选择的过程。</p><p id="7d4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个帖子更多的是 Yellowbrick 的实际应用。我们将快速构建一个基本的分类模型，然后使用 Yellowbrick 工具来评估我们的模型。我们可以把它分成两部分:</p><ol class=""><li id="40e6" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">创建机器学习模型</li><li id="ec34" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">黄砖时间！</li></ol></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="9244" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated"><strong class="ak">创建机器学习模型</strong></h1><p id="5ddc" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">任务是预测银行客户的流失。流失预测是机器学习领域的一个常见用例。如果你不熟悉这个术语，churn 的意思是“离开公司”。对于一个企业来说，了解客户可能流失的原因和时间是非常重要的。</p><p id="af8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用的数据集可从 Kaggle 上的<a class="ae ky" href="https://www.kaggle.com/sonalidasgupta95/churn-prediction-of-bank-customers" rel="noopener ugc nofollow" target="_blank">这里</a>获得。这篇文章的重点是评估分类器性能的可视化。因此，实际的模型构建部分将会快速而简洁。</p><p id="5cd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从导入依赖项开始。</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="c1d6" class="ns mr it no b gy nt nu l nv nw">import numpy as np<br/>import pandas as pd</span><span id="e7f9" class="ns mr it no b gy nx nu l nv nw">import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="49e0" class="ns mr it no b gy nx nu l nv nw">import yellowbrick</span></pre><p id="e574" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将数据集读入熊猫数据帧，并删除多余的特征。</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="a18a" class="ns mr it no b gy nt nu l nv nw">df_churn = pd.read_csv("/content/Churn_Modelling.csv")</span><span id="81f9" class="ns mr it no b gy nx nu l nv nw">df_churn.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)</span><span id="d31b" class="ns mr it no b gy nx nu l nv nw">df_churn.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/7856a74413c1fae18df20c7f841388aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*43IBmBI981Cu6TPqS7t_mw.png"/></div></div></figure><p id="ebd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“退出”栏表示客户流失。</p><p id="ebb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">流失数据集通常是不平衡的。类别 0(非流失)的数量明显多于类别 1(流失)的数量。这种不平衡会对模型的性能产生负面影响。因此，最好消除这种不平衡。</p><p id="afb2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有不同的方法来使用它作为解决方案。我们可以进行过采样(增加少数类的观测值)或欠采样(减少多数类的观测值)。</p><p id="8db4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最常见的一种是<strong class="lb iu"> SMOTE </strong>(合成少数过采样技术)。SMOTE 算法创建与现有样本相似的新样本。它采用两个或更多相似的观察值，并通过一次改变一个属性来创建一个综合观察值。</p><p id="6d75" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在使用 SMOTE 算法之前，我们需要将类别转换成数值。</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="60c8" class="ns mr it no b gy nt nu l nv nw">gender = {'Female':0, 'Male':1}<br/>country = {'France':0, 'Germany':1, 'Spain':2}</span><span id="71e8" class="ns mr it no b gy nx nu l nv nw">df_churn['Gender'].replace(gender, inplace=True)<br/>df_churn['Geography'].replace(country, inplace=True)</span></pre><p id="782b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们来确认一下阶级不平衡:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="d7db" class="ns mr it no b gy nt nu l nv nw">df_churn['Exited'].value_counts()<br/>0    7963 <br/>1    2037 <br/>Name: Exited, dtype: int64</span></pre><p id="c54f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正类(流失)的数量大约比负类(非流失)的数量高 4 倍。</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="901a" class="ns mr it no b gy nt nu l nv nw">X = df_churn.drop('Exited', axis=1)<br/>y = df_churn['Exited']</span><span id="f599" class="ns mr it no b gy nx nu l nv nw">from imblearn.over_sampling import SMOTE<br/>sm = SMOTE(random_state=42)<br/>X_resampled, y_resampled = sm.fit_resample(X, y)</span><span id="80ce" class="ns mr it no b gy nx nu l nv nw">print(pd.Series(y_resampled).value_counts())<br/>1    7963 <br/>0    7963 <br/>dtype: int64</span></pre><p id="d7d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在正反类数量相等。训练模型之前的最后一步是将数据集分成训练和测试子集。</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="39f8" class="ns mr it no b gy nt nu l nv nw">from sklearn.model_selection import train_test_split</span><span id="8619" class="ns mr it no b gy nx nu l nv nw">X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2)</span></pre><p id="de86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是时候创建一个模型并训练它了。我将使用随机森林算法。</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="2c88" class="ns mr it no b gy nt nu l nv nw">from sklearn.ensemble import RandomForestClassifier</span><span id="d132" class="ns mr it no b gy nx nu l nv nw">rf = RandomForestClassifier(max_depth=11, n_estimators=260)<br/>rf.fit(X_train, y_train)</span><span id="63ab" class="ns mr it no b gy nx nu l nv nw">from sklearn.metrics import accuracy_score<br/>y_pred = rf.predict(X_train)<br/>y_test_pred = rf.predict(X_test)<br/>train_acc = accuracy_score(y_pred, y_train)<br/>test_acc = accuracy_score(y_test_pred, y_test)</span><span id="ad0e" class="ns mr it no b gy nx nu l nv nw">print(f'Train accuracy is {train_acc}. Test accuracy is {test_acc}')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/f065ccaa318aa9eb3c5b8bd6f12eec31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*tJOBF6hxziwH5sEXlu8lkg.png"/></div></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="d982" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated"><strong class="ak">黄砖时间！</strong></h1><p id="7344" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在分类任务中，尤其是在存在类别不平衡的情况下，准确度不是评估度量的最优选择。例如，预测正面类别(客户流失=1)比预测负面类别更重要，因为我们想确定客户是否会流失。我们可以承受对负类的错误预测</p><p id="5dfb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一种分别检查正负类预测的方法是<strong class="lb iu">混淆矩阵。</strong></p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="2c45" class="ns mr it no b gy nt nu l nv nw">from yellowbrick.classifier import ConfusionMatrix</span><span id="eb26" class="ns mr it no b gy nx nu l nv nw">plt.figure()<br/>plt.title("Confusion Matrix", fontsize=18)<br/>plt.xlabel("Predicted Class", fontsize=16)<br/>plt.ylabel("True Class", fontsize=15)</span><span id="92bd" class="ns mr it no b gy nx nu l nv nw">cm = ConfusionMatrix(rf, classes=[0,1], size=(400,400),<br/>fontsize=15, cmap='GnBu')</span><span id="d8f9" class="ns mr it no b gy nx nu l nv nw">cm.fit(X_train, y_train)<br/>cm.score(X_test, y_test)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/add479ab9639621f5dff980bfb50b444.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*9Vd5C4Gi_uSFPg2QdvPUdQ.png"/></div></div></figure><p id="319b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在正类中，我们有 1419 个正确的预测和 213 个错误的预测。我们也可以通过将<strong class="lb iu">百分比</strong>参数设置为真来显示百分比，而不是数字。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/5b2181c8efab4fb8941e15b5df1d094d.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*a287luG7SjWqdXzsYgdhaQ.png"/></div></div></figure><p id="97b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型在负类上表现更好，这不是我们想要的。实现这一点的一个方法是告诉模型“正类(1)比负类(0)更重要”。使用我们的随机森林分类器，可以通过<strong class="lb iu"> class_weight </strong>参数来实现。</p><p id="9468" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">评估分类模型性能的另一个工具是 ROC(接收机工作特性)曲线和 AOC(曲线下面积)。</p><p id="7d60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> ROC 曲线</strong>通过组合所有阈值的混淆矩阵总结了性能。<strong class="lb iu"> AUC </strong>将 ROC 曲线转化为二元分类器性能的数字表示。AUC 是 ROC 曲线下的面积，取 0 到 1 之间的值。AUC 表示一个模型在区分正类和负类方面有多成功。</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="0623" class="ns mr it no b gy nt nu l nv nw">from yellowbrick.classifier import ROCAUC</span><span id="7ed5" class="ns mr it no b gy nx nu l nv nw">plt.figure(figsize=(10,6))<br/>plt.title("ROC Curve and AUC", fontsize=18)<br/>plt.xlabel("False Positive Rate", fontsize=16)<br/>plt.ylabel("True Positive Rate", fontsize=16)</span><span id="a384" class="ns mr it no b gy nx nu l nv nw">visualizer = ROCAUC(rf, classes=["Not-churned", "Churned"])<br/>visualizer.fit(X_train, y_train)<br/>visualizer.score(X_test, y_test)</span><span id="084f" class="ns mr it no b gy nx nu l nv nw">plt.legend()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/966a7de7af1e7c27dfdcb0e0229d7ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*jEQHkONK-3uaEmZfFWY3Wg.png"/></div></figure><p id="896f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ROC 曲线概述了不同阈值下的模型性能。AUC 是介于(0，0)和(1，1)之间的 ROC 曲线下的面积，可以使用积分来计算。AUC 基本上汇总了模型在所有阈值的表现。AUC 的最佳可能值是 1，这表示一个完美的分类器。如果所有的预测都是错误的，则 AUC 为零。</p><p id="813e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当涉及到不平衡数据集时，<strong class="lb iu">精度</strong>或<strong class="lb iu">召回</strong>通常是评价指标的选择。</p><p id="ac36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">精度的焦点是<strong class="lb iu">正面预测</strong>。它表明有多少积极的预测是正确的。</p><p id="67d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">召回的重点是<strong class="lb iu">实际正课</strong>。它表示模型能够正确预测的阳性类别的数量。</p><blockquote class="oc od oe"><p id="59eb" class="kz la of lb b lc ld ju le lf lg jx lh og lj lk ll oh ln lo lp oi lr ls lt lu im bi translated"><strong class="lb iu">注意</strong>:我们不能试图同时最大化精确度和召回率，因为它们之间有一个平衡。提高精度会降低召回率，反之亦然。我们可以根据任务来最大化精确度或回忆。</p></blockquote><p id="8ff5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Yellowbrick 还提供了精度-召回曲线，显示了精度和召回之间的权衡。</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="3987" class="ns mr it no b gy nt nu l nv nw">from yellowbrick.classifier import PrecisionRecallCurve</span><span id="960b" class="ns mr it no b gy nx nu l nv nw">plt.figure(figsize=(10,6))<br/>plt.title("Precision-Recall Curve", fontsize=18)<br/>plt.xlabel("Recall", fontsize=16)<br/>plt.ylabel("Precision", fontsize=16)</span><span id="bbea" class="ns mr it no b gy nx nu l nv nw">viz = PrecisionRecallCurve(rf)<br/>viz.fit(X_train, y_train)<br/>viz.score(X_test, y_test)<br/>plt.legend(loc='lower right', fontsize=12)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/1f54c24b0d8dd1099ce270a566467ef8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*-9DMpqTytTLvhXebXczkfQ.png"/></div></figure><p id="9f8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在某个时间点之后，提高召回率会导致准确率显著下降。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="5750" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Yellowbrick 还提供了以下可视化功能，这些功能在评估分类模型时非常有用:</p><ul class=""><li id="c36b" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu oj mb mc md bi translated">分类报告</li><li id="1270" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oj mb mc md bi translated">类别预测误差</li><li id="35ed" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oj mb mc md bi translated">辨别阈值(仅用于二元分类)</li></ul><p id="a51d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在评估模型的过程中使用信息可视化将为您提供许多见解。它将引导你以一种有效的方式改进你的模型。</p><p id="6cc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不要只看数字，试着用不同的方法来评估，从而改进你的模型。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="f010" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>