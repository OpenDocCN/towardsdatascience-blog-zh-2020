<html>
<head>
<title>Classifying Climate Change Tweets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将气候变化推文分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classifying-climate-change-tweets-8245450a5e96?source=collection_archive---------25-----------------------#2020-02-05">https://towardsdatascience.com/classifying-climate-change-tweets-8245450a5e96?source=collection_archive---------25-----------------------#2020-02-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="af0b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用NLP和分类技术将推文分类为气候变化信徒或否认者推文</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f4e4e39437e060961a7188b5810e984d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YVDMpSxf2A2eg8M-CTLk5w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.slidescarnival.com/woodville-free-presentation-template/4398" rel="noopener ugc nofollow" target="_blank">slidescarnival.com</a></p></figure><h1 id="a073" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">背景</h1><p id="b8c1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">你好！在本文中，我将通过一个分类示例来识别2017年至2019年的气候变化推文，无论是气候变化“相信者”还是“否认者”。从<a class="ae ky" href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/5QCCUU" rel="noopener ugc nofollow" target="_blank">哈佛数据世界</a>下载了2000万条气候变化推文ID，并进行“水合”(即填充了包含实际推文、推文详情、转发详情、用户信息等的JSON文件。)使用<code class="fe mn mo mp mq b"><a class="ae ky" href="https://github.com/DocNow/twarc" rel="noopener ugc nofollow" target="_blank">twarc</a></code>。然后，推文文件被保存在mongoDB数据库中，所有的转发都被过滤掉，剩下的推文在标签和文本预处理的帮助下被分类为“相信者”或“否认者”。这一分类过程涵盖了该项目的第一部分(点击<a class="ae ky" href="https://github.com/gravesa333/Classifying_Climate_Change_Tweets" rel="noopener ugc nofollow" target="_blank">此处</a>查看github repo)，而下一篇文章涵盖了第二部分(点击<a class="ae ky" href="https://github.com/gravesa333/Clustering_Climate_Change_Tweets" rel="noopener ugc nofollow" target="_blank">此处</a>查看github repo)，并涉及主题建模和推文聚类，以根据地理位置确定情绪趋势。</p><p id="b7ae" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">如何将这些推文归类为“信徒”或“否认者”？我们不能简单地用情绪分析来区分这两者，因为相信者和否定者都会对气候变化产生积极和消极的情绪。因此，分类器模型是在包含明确的“相信者”或“否定者”标签的推特子集上训练的。标签列表是从tweet数据库中手动搜索和评估的；请参见下面的表1，了解使用的内容。应该指出的是，否认者的推文比相信者的推文少得多，两者的比例分别为6%和94%。为了进行度量评估，相信者的推文代表负面情况，否认者的推文代表正面情况。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/64b26c0e340a806a26fa4869c51b9998.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3tJH92_KcJ4451B-zzCJTA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表1:“权威”信徒和否认者标签</p></figure><p id="1733" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">在执行上述分类流程时，将涵盖以下主题:</p><ol class=""><li id="054e" class="mx my it lt b lu mr lx ms ma mz me na mi nb mm nc nd ne nf bi translated"><strong class="lt iu">文本预处理</strong></li><li id="f7b9" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated"><strong class="lt iu">基线模型管道</strong></li><li id="2ca0" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated"><strong class="lt iu">绩效指标评估</strong></li><li id="156b" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated"><strong class="lt iu">网格搜索</strong></li><li id="ce64" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated"><strong class="lt iu">阈值选择</strong></li><li id="4e01" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated"><strong class="lt iu">整个数据集的分类</strong></li></ol><h1 id="12eb" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">文本预处理</h1><p id="56a0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一旦tweets的子集从全集中提取出来，并进一步分成训练集和测试集，<code class="fe mn mo mp mq b">CountVectorizer</code>和<code class="fe mn mo mp mq b">TfidfVectorizer</code>被设置成将每个集转换成将用于建模的文档术语矩阵。<a class="ae ky" rel="noopener" target="_blank" href="/hacking-scikit-learns-vectorizers-9ef26a7170af">可以通过</a> <code class="fe mn mo mp mq b"><a class="ae ky" rel="noopener" target="_blank" href="/hacking-scikit-learns-vectorizers-9ef26a7170af">CountVectorizer</a></code> <a class="ae ky" rel="noopener" target="_blank" href="/hacking-scikit-learns-vectorizers-9ef26a7170af">和</a> <code class="fe mn mo mp mq b"><a class="ae ky" rel="noopener" target="_blank" href="/hacking-scikit-learns-vectorizers-9ef26a7170af">TfidfVectorizer</a></code>构建和实现自定义预处理和标记化功能。首先，预处理函数见下文；所有推文都被清除了以下特征:</p><ol class=""><li id="472b" class="mx my it lt b lu mr lx ms ma mz me na mi nb mm nc nd ne nf bi translated">换行</li><li id="ca70" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">URL的</li><li id="fd06" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">数字</li><li id="ccfa" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">大写字母</li><li id="428f" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">标点</li></ol><pre class="kj kk kl km gt nl mq nm nn aw no bi"><span id="6839" class="np la it mq b gy nq nr l ns nt">def tweet_preprocessor(tweet):</span><span id="398e" class="np la it mq b gy nu nr l ns nt">    tweet = tweet.replace('\n', ' ') # remove line breaks<br/>    tweet = re.sub(r"\bhttps://t.co/\w+", '', tweet) # remove URL's<br/>    tweet = re.sub('\w*\d\w*', ' ', tweet) # remove numbers<br/>    tweet = re.sub('[%s]' % re.escape(string.punctuation), ' ',   <br/>            tweet.lower()) # remove capital letters and punctuation<br/>    <br/>    return tweet</span></pre><p id="b65e" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">接下来，见下面的记号化函数；t <a class="ae ky" href="https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html" rel="noopener ugc nofollow" target="_blank"> okenization </a>将每条推文分割成一个单词集合(即令牌)。<a class="ae ky" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">词汇化</a>旨在将每个单词缩减到其基本形式。例如:大笑，大笑，大笑，大笑都会变成大笑。这通过减少唯一单词的数量来降低分析的复杂性。这两种技术都内置在<a class="ae ky" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> spaCy </a>包中，该包在令牌化函数中使用:</p><pre class="kj kk kl km gt nl mq nm nn aw no bi"><span id="3772" class="np la it mq b gy nq nr l ns nt"># create a spaCy tokenizer<br/>spacy.load('en')<br/>lemmatizer = spacy.lang.en.English()</span><span id="4114" class="np la it mq b gy nu nr l ns nt">def tweet_tokenizer(doc):<br/>    <br/>    tokens = lemmatizer(doc)<br/>    return [token.lemma_ for token in tokens]</span></pre><p id="5d87" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">除了预处理和标记化，还有许多其他的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank">矢量器超参数</a>需要微调。例如:</p><ol class=""><li id="5935" class="mx my it lt b lu mr lx ms ma mz me na mi nb mm nc nd ne nf bi translated"><strong class="lt iu">最大词频</strong>:设置一个词可以出现的最大tweets数(例如，如果一个词出现在超过80%的tweets中，那么它可能不是tweets之间差异的良好指标)。</li><li id="84f9" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated"><strong class="lt iu">最小词频</strong>:设置一个单词必须出现的最少推文数(例如，如果一个单词出现在少于1%的推文中，那么它可能是一个不相关的术语，甚至可能是一个错别字)。</li><li id="e104" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated"><strong class="lt iu"> ngram range </strong>:每条推文中的词应该如何分组？我们只对单词感兴趣吗？成对分组的单词？三胞胎？双人和三人组值得一看，因为他们可以帮助捕捉常见的短语(如“气候变化”)。</li><li id="f0e2" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated"><strong class="lt iu">停用词</strong>:除了从推文中删除常用停用词(如“the”、“is”、“are”等。)，所有确定的标签(上面列出的)都作为停用词包含在内。标签呈现了潜在的数据泄漏，这可能导致我们的分类器过度拟合，无法推广到其他推文。</li></ol><p id="13f3" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">矢量化被集成到分类管道中，这可以在下一节的代码中看到。</p><h1 id="ac79" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">基线模型管道</h1><p id="c45f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最初管道的目标是挑选出一些潜在的基线模型用于进一步探索。为管道创建了矢量字典和模型字典；矢量器字典包含许多不同的<code class="fe mn mo mp mq b">CountVectorizer</code>和<code class="fe mn mo mp mq b">TfidfVectorizer</code>变体，例如具有不同的ngram范围、max_df和min_df，模型字典包含分类器列表。见下文:</p><p id="28b3" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated"><strong class="lt iu">矢量词典</strong></p><pre class="kj kk kl km gt nl mq nm nn aw no bi"><span id="1e85" class="np la it mq b gy nq nr l ns nt">vectorizer_dict = {'CV_1': CountVectorizer(ngram_range=(1,3),<br/>                           max_df = 0.8, min_df = 3, <br/>                           preprocessor=tweet_preprocessor, <br/>                           tokenizer=tweet_tokenizer, <br/>                           stop_words=new_stop_words),<br/>                   ...<br/>                   'TF_1': TfidfVectorizer(ngram_range=(1,3),<br/>                           max_df = 0.8, min_df = 3, <br/>                           preprocessor=tweet_preprocessor, <br/>                           tokenizer=tweet_tokenizer, <br/>                           stop_words=new_stop_words),<br/>                   ...}</span></pre><p id="43a7" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated"><strong class="lt iu">模型词典</strong></p><pre class="kj kk kl km gt nl mq nm nn aw no bi"><span id="4edd" class="np la it mq b gy nq nr l ns nt">model_dict = {'Logistic Regression': LogisticRegression(),<br/>              'Naive Bayes': MultinomialNB(),<br/>              'LinearSVM': SGDClassifier(random_state=42),<br/>              'Decision Tree': DecisionTreeClassifier(max_depth=6),    <br/>              'XGBoost': XGBClassifier(max_depth=6)}</span></pre><p id="39bd" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">由于数据集不平衡，使用<code class="fe mn mo mp mq b">SMOTE</code>、<code class="fe mn mo mp mq b">ADASYN</code>和<code class="fe mn mo mp mq b">RandomOverSampler</code>来评估过采样的效果。没有一个选项执行得很好，所以它们从模型管道中被省略了。基准模型都用<a class="ae ky" href="https://www.lpsm.paris/pageperso/has/source/Hand-on-ML.pdf" rel="noopener ugc nofollow" target="_blank">精度、召回和F1分数</a>性能指标进行了评估。以下是每一个的快速定义:</p><ol class=""><li id="e462" class="mx my it lt b lu mr lx ms ma mz me na mi nb mm nc nd ne nf bi translated"><strong class="lt iu">精度</strong>:正确的阳性病例预测的百分比</li><li id="d3ab" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated"><strong class="lt iu">回忆</strong>:正确预测的阳性病例的百分比</li><li id="79b4" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">F1得分:精确度和召回率的调和平均值。</li></ol><p id="6a9e" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">为了以高效的方式编译结果，在每次管道迭代后，这些指标都存储在一个字典中，同时还有相应的矢量器和模型名称。请参见下面的管道:</p><pre class="kj kk kl km gt nl mq nm nn aw no bi"><span id="53ad" class="np la it mq b gy nq nr l ns nt">class_results_dict = defaultdict(list)</span><span id="a771" class="np la it mq b gy nu nr l ns nt">for vec_name, vectorizer in vectorizer_dict.items():<br/>    <br/>    X_train_cv = vectorizer.fit_transform(X_train)<br/>    X_test_cv  = vectorizer.transform(X_test)</span><span id="d563" class="np la it mq b gy nu nr l ns nt">    for mod_name, model in model_dict.items():<br/>        model.fit(X_train_cv, y_train);<br/>        y_pred_cv = model.predict(X_test_cv)</span><span id="4f99" class="np la it mq b gy nu nr l ns nt">        precision_cv = precision_score(y_test, y_pred_cv)<br/>        recall_cv = recall_score(y_test, y_pred_cv)<br/>        f1_cv = f1_score(y_test, y_pred_cv)<br/>        <br/>        class_results_dict['Vectorizer Type'].append(vec_name)<br/>        class_results_dict['Model Name'].append(mod_name)<br/>        class_results_dict['Precision'].append(precision_cv)<br/>        class_results_dict['Recall'].append(recall_cv)<br/>        class_results_dict['F1-score'].append(f1_cv)</span><span id="8268" class="np la it mq b gy nu nr l ns nt">class_results_df = pd.DataFrame(class_results_dict)</span></pre><h1 id="cd2c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">绩效指标评估</h1><p id="81ba" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这种情况下，F1分数是评估每个模型的最佳指标。精确度和召回率都很重要，所以不需要权衡孰轻孰重。换句话说，第一类(假阳性)和第二类(假阴性)错误是相等的。看看<code class="fe mn mo mp mq b">class_results_df</code>、<code class="fe mn mo mp mq b">CountVectorizer</code>中的F1分数，在所有矢量器中，ngram范围为(1，3)(即CV_2)的表现最好，最有效的模型是逻辑回归和线性SVM(SGD分类器的默认)。请参见下面的表2中的<code class="fe mn mo mp mq b">class_results_df</code>片段:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/9fac23fb7fa8186897218d0841d62d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BlxYzRVRTgCm-LaQDFsCw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表2:类_结果_df</p></figure><p id="e2df" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">Logistic回归和ngram范围为(1，3)的SGD分类器通过网格搜索进一步优化超参数。</p><h1 id="5845" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">网格搜索</h1><p id="6fd1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于逻辑回归和SGD分类器，在进行单个网格搜索时，需要考虑多个超参数。对正则化的类型和强度进行评估，同时对逻辑回归评估不同类型的优化算法，并对SGD分类器评估不同类型的损失函数。代码见下文；利用<code class="fe mn mo mp mq b">GridSearchCV</code>，其中选择<em class="nw"> cv=5 </em>折叠进行交叉验证。</p><pre class="kj kk kl km gt nl mq nm nn aw no bi"><span id="41d1" class="np la it mq b gy nq nr l ns nt">from sklearn.model_selection import GridSearchCV</span><span id="77e5" class="np la it mq b gy nu nr l ns nt"># Logistic Regression<br/>logit_params = [{'penalty': ['none', 'l1', 'l2']}, <br/>                {'solver': ['liblinear', 'lbfgs']},<br/>                {'C':np.logspace(-5,3,num=9,base=10,dtype='float')}]</span><span id="3bf1" class="np la it mq b gy nu nr l ns nt">gs_logit = GridSearchCV(LogisticRegression(), logit_params, cv=5,   <br/>                        scoring='f1', error_score=0.0)<br/>gs_logit.fit(X_train_cv, y_train)<br/>y_true, y_pred = y_test, gs_logit.predict(X_test_cv)<br/>f1_score = f1_score(y_true, y_pred)</span><span id="8f19" class="np la it mq b gy nu nr l ns nt">#SGD Classifier<br/>sgd_params = [{'loss':<br/>              ['hinge','log','modified_huber','squared_hinge']}, <br/>              {'penalty': ['none', 'l1', 'l2']}, <br/>              {'alpha': <br/>                np.logspace(-4,3,num=8,base=10,dtype='float')}]</span><span id="b5f3" class="np la it mq b gy nu nr l ns nt">gs_sgd = GridSearchCV(SGDClassifier(), sgd_params, <br/>                      cv=5, scoring='f1')<br/>gs_sgd.fit(X_train_ros, y_train_ros)<br/>y_true, y_pred = y_test, gs_sgd.predict(X_test_cv2)<br/>f1_score = f1_score(y_true, y_pred)</span></pre><p id="d649" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">两个模型的F1分数都通过一个<em class="nw"> l2 </em>惩罚进行了优化。逻辑回归使用<em class="nw"> lbfgs </em>解算器表现最佳，SGD分类器使用<em class="nw"> modified_huber </em>成本函数表现最佳(二次平滑SVM模型，其中<em class="nw"> gamma = 2 </em>)。</p><h1 id="ac83" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">阈值选择</h1><p id="7718" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">优化每个模型的F1分数的下一步是找到最佳概率阈值。分类器的默认阈值设置为50%，即大于50%的概率表示拒绝的推文，而小于50%的概率表示相信的推文。逻辑回归混淆矩阵的视频见下图1；阈值小部件显示F1分数达到最大值，阈值设置为0.32。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="555c" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">比较两个模型的F1得分，逻辑回归得分最高，F1得分为<strong class="lt iu"> 0.803 </strong>。为了直观地确认F1分数，有必要查看精确度-召回曲线(ROC曲线对于不平衡的数据集不太可靠，因此在这种情况下没有使用ROC曲线)。参见下面的图2:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/0dda17d8329a20ccd7d389694e482913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RoZ2tR3DtqA4ao_tDTqfsA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:逻辑回归精度-召回曲线</p></figure><p id="f522" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">可以看出，当精度等于0.870且召回等于0.746时，曲线的最佳点出现；这些值计算出F1分数为0.803。</p><p id="31c1" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">为了提高这个分数，测试了不同的“确定的”标签组合(添加某些标签，删除某些标签，等等)。)，但是事实证明，使用表1中使用的标签列表时，模型的性能最好。</p><h1 id="94b8" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">整个数据集的分类</h1><p id="0f5f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">确定逻辑回归模型和阈值后，对整个数据集进行最终分类。为每条推文生成预测概率，并应用0.32的阈值。参见下面的代码:</p><pre class="kj kk kl km gt nl mq nm nn aw no bi"><span id="afe7" class="np la it mq b gy nq nr l ns nt">believer_denier_preds = []<br/>y_final_predict = logit.predict_proba(X_final_test)</span><span id="cdf0" class="np la it mq b gy nu nr l ns nt">for i in y_final_predict:<br/>    if i[1] &lt; 0.32:<br/>        believer_denier_preds.append(0)<br/>    else:<br/>        believer_denier_preds.append(1)</span></pre><p id="d3eb" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">因为推文没有预先确定的“正确”标签，所以需要人工评估来决定模型是否是有效的分类器。一个很好的初始检查是计算拒绝者推文与相信者推文的比率，并查看它是否与推文训练集中的比率相似(94%相信者对6%拒绝者)。这个比例是90%的相信者对10%的否认者，这与训练集的比例大致相当。更深入的人工检查证实了分类器是有效的。</p><p id="1ccf" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">请随意查看github repo，了解本文中详细描述的分类过程，位于<a class="ae ky" href="https://github.com/gravesa333/Classifying_Climate_Change_Tweets" rel="noopener ugc nofollow" target="_blank">此处</a>。当在tweet数据集上执行主题建模和聚类时，最终会使用这种分类。这个过程的github repo可以在<a class="ae ky" href="https://github.com/gravesa333/Clustering_Climate_Change_Tweets" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="979d" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">感谢阅读！</p></div></div>    
</body>
</html>