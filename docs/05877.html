<html>
<head>
<title>Building a Convolutional Neural Network in only 40 lines of code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">仅用40行代码构建一个卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-convolutional-neural-network-in-only-40-lines-of-code-bef8ce38bf6d?source=collection_archive---------39-----------------------#2020-05-14">https://towardsdatascience.com/building-a-convolutional-neural-network-in-only-40-lines-of-code-bef8ce38bf6d?source=collection_archive---------39-----------------------#2020-05-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b923" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">最简单的CNN可能使用Keras和Tensorflow</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3d89b121d8a5caddd4cc08fdfb246f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zRtbe8ymyCphc_7AmEFx4A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/s/photos/monkeys" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="cf6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于任何进入深度学习的人来说，卷积神经网络都可能令人困惑和恐惧。在本文中，我将展示构建一个简单的CNN实际上是相当容易的。</p><p id="81c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们需要导入模块。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="0ecc" class="ma mb it lw b gy mc md l me mf">import numpy as np<br/>import pandas as pd<br/>import tensorflow as tf<br/>from tensorflow.keras import datasets, layers, models<br/>from keras.preprocessing.image import ImageDataGenerator</span></pre><p id="ebf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Keras是一个运行在Tensorflow之上的高级Python神经网络库。其简单的架构、可读性和整体易用性使其成为使用Python进行深度学习时最受欢迎的库之一。</p><p id="a98f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我使用了“10种猴子”的数据集，可以在Kaggle上找到:https://www.kaggle.com/slothkong/10-monkey-species<a class="ae ky" href="https://www.kaggle.com/slothkong/10-monkey-species" rel="noopener ugc nofollow" target="_blank"/>。它包含1098个训练图像和272个验证图像，分在10类猴子中。</p><p id="ff80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们开始之前，请确保图像存储正确。下面看到的结构是flow_from_directory函数(我们很快就会讲到)工作所必需的。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="23ec" class="ma mb it lw b gy mc md l me mf">Directory<br/>   - Training_images<br/>      - Class_1<br/>         - image_1<br/>         - image_2<br/>      - Class_2<br/>         - image_1</span><span id="793c" class="ma mb it lw b gy mg md l me mf">   - Validation_images<br/>      - Class_1<br/>         - image_1<br/>...</span></pre><p id="f7a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们开始。首先，我们必须指定图像的路径，以及它们的目标大小。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="4f26" class="ma mb it lw b gy mc md l me mf"><em class="mh">#</em><strong class="lw iu"><em class="mh">Path </em></strong><br/>train_dir = Path('../input/10-monkey-species/training/training/')<br/>test_dir = Path('../input/10-monkey-species/validation/validation/')<br/><br/><strong class="lw iu"><em class="mh">#Images target size</em><br/></strong>target_size = (100,100)<br/>channels = 3 <em class="mh">#RGB</em></span></pre><p id="a623" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们创建我们的生成器，这将使我们能够对图像进行数据扩充和缩放。请注意，只增加训练图像，但重新缩放一切。重新缩放是必要的，因为让每个图像都在相同的[0，1]范围内将意味着它们在训练期间的贡献更均匀。</p><p id="6745" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为澄清，请注意ImageDataGenerator函数不会创建新图像。相反，它修改了我们当前的一些训练图像，以便在更大范围的样本上训练该模型。这有助于避免过度拟合，并使模型更易于预测新猴子的类别。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="36f8" class="ma mb it lw b gy mc md l me mf"><strong class="lw iu"><em class="mh">#Data augmentation </em><br/></strong>train_generator = ImageDataGenerator(rescale=1/255,<br/>                                    rotation_range=40,<br/>                                    shear_range=0.2,<br/>                                    zoom_range=0.2,<br/>                                    horizontal_flip=True,<br/>                                    fill_mode='nearest')<br/><br/>valid_generator = ImageDataGenerator(rescale = 1/255)</span></pre><p id="2520" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们可以导入图像。flow_from_directory函数在指定的路径中查找图像，并将它们调整到目标大小。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2536" class="ma mb it lw b gy mc md l me mf">epochs = 20<br/>batch_size = 64 <br/><br/><strong class="lw iu"><em class="mh">#Finds images, transforms them</em></strong><em class="mh"><br/></em>train_data = train_generator.flow_from_directory(train_dir,                                                                                target_size=target_size, batch_size=batch_size,                                           class_mode='categorical')<br/><br/>test_data = valid_generator.flow_from_directory(test_dir,       target_size=target_size, batch_size=batch_size,                                                 class_mode='categorical', shuffle=False)</span></pre><p id="b6d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">时期和批量是两个非常重要的超参数。当整个数据集通过网络时，一个历元完成。批量大小是模型更新前处理的图像数量。调整这些参数会极大地改变训练的速度和长度。</p><p id="c285" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们可以建立模型本身。在这里，我创建了一个非常简单的模型，除了输入/输出层之外，只有一个卷积层和一个池层。显然，一个更复杂的模型将有助于提高性能，添加层是非常简单的，但对于本教程，我将把它留在那里。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="52e9" class="ma mb it lw b gy mc md l me mf"><strong class="lw iu">#Number of images we have<br/></strong>train_samples = train_data.samples<br/>valid_samples = test_data.samples</span><span id="31d8" class="ma mb it lw b gy mg md l me mf"><strong class="lw iu">#Building the model<br/></strong>model = models.Sequential()<br/>model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape (100, 100, channels)))<br/>model.add(layers.MaxPooling2D((2, 2)))<br/>model.add(layers.Dense(10, activation='softmax'))<br/><br/><strong class="lw iu"><em class="mh">#Compile model</em><br/></strong>model.compile(loss='categorical_crossentropy',<br/>              optimizer='adam',<br/>              metrics=['accuracy'])</span></pre><p id="8b1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一卷积层需要输入形状，即图像的形状。这个CNN的最后一层使用softmax激活函数，这在我们有多个类(这里有10个)时是合适的，因为它允许模型计算图像属于每个类的概率。最后，<em class="mh"> model.compile </em>函数允许我们指定模型在训练期间将如何学习。</p><p id="bdc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以拟合模型并评估验证集的性能。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="3cf1" class="ma mb it lw b gy mc md l me mf"><strong class="lw iu"><em class="mh">#Fit the model</em><br/></strong>model.fit_generator(generator=train_data,<br/>                    steps_per_epoch=train_samples/batch_size,<br/>                    validation_data=test_data,<br/>                    validation_steps=valid_samples/batch_size,<br/>                    epochs=epochs)</span></pre><p id="b88e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个超级简单的模型仅经过20个时期就在验证集上达到了几乎63%的准确率！</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="b5d0" class="ma mb it lw b gy mc md l me mf">Epoch 20/20<br/>17/17 [===============================] - 81s 5s/step - loss: 0.6802 - accuracy: 0.7395 - val_loss: 1.4856 - val_accuracy: 0.6287</span></pre><p id="1129" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在实践中，有更多的纪元是有意义的，只要模型改进，就让它训练。</p><p id="89a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是一个卷积神经网络，从头到尾只有40行代码。不再那么可怕了，是吗？非常感谢你的阅读！</p></div></div>    
</body>
</html>