<html>
<head>
<title>Gradient Centralization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">梯度集中化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gradient-centralization-bdb333a53bcd?source=collection_archive---------44-----------------------#2020-05-23">https://towardsdatascience.com/gradient-centralization-bdb333a53bcd?source=collection_archive---------44-----------------------#2020-05-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="08af" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何通过添加一行代码，在您的DNN模型中实现更高效的训练和更好的正则化</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4bb516f0ace08f0189a0f1002ef40621.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mUr-LHGnSeXqs4zEWfS6rA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3087585" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>的<a class="ae ky" href="https://pixabay.com/users/JESHOOTS-com-264599/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3087585" rel="noopener ugc nofollow" target="_blank">扬·瓦塞克</a>拍摄</p></figure><p id="5579" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di">一篇</span>最近发表的<a class="ae ky" href="https://arxiv.org/pdf/2004.01461.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>提出了一个简单的答案:梯度中心化，一种新的优化技术，可以很容易地集成到你已经使用的基于梯度的优化算法中。这是广泛使用的批处理规范化的一个很好的替代方案。你所需要做的就是集中你的梯度向量，使它们的平均值为零！</p><p id="7201" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我将探索所提出的方法的理论细节。实用的方法将在我的下一篇文章中讨论。</p><h1 id="1bc0" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">一行代码背后的数学原理</h1><h2 id="4180" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">注释</h2><p id="c05e" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">让我们来介绍一下符号:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/19a76857e678174b21ba60cc4fa4f11e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VsTukObS0CiKE0g3lOOfDw.png"/></div></div></figure><h2 id="20d4" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">梯度集中操作</h2><p id="e4bc" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">GC操作定义如下:从梯度矩阵的每一列中，我们减去该列的平均值。例如，如果梯度矩阵如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/fd3a82e112571e517410880bc95b2c8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:338/0*sR11tz8ICiSgWW8x"/></div></figure><p id="6d02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">转换后，它将看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/1f902e1ac371c4a28f32ace54a1aee87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*6LnyhwB3ETQvFf7HX78RDQ.png"/></div></div></figure><p id="4482" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为各个列的平均值是4，3，5，0。</p><p id="f787" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，我们将损失函数的每个梯度w.r.t .转换为权重向量，使得其平均值等于零。我们可以用一种奇特的符号来表示它:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/b03865586c630abb21c6c9f07fb0f93c.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*wDUw_wdvVJgb_e5PWZAiCg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GC算符的向量公式</p></figure><p id="358d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想让它看起来更高级，你可以引入一个很酷的<strong class="lb iu"> P </strong>操作符并使用矩阵公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d326d297f51e3bb17ce368b5f727f4e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*lE0WpfYAG9PzuURWmHjt_g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GC算符的矩阵公式</p></figure><p id="27eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过直接矩阵乘法，您可以很容易地检查上述等式是否成立:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/7f8fdbf4423033e0e835a880cedff381.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*SoyqoKG-aGak9UIEUeaV2A.png"/></div></figure><p id="0960" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以实际上从每一列中，我们减去这一列的平均值。</p><h2 id="0ee2" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">几何解释</h2><p id="8b17" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">现在，这个符号的目标不是让简单的事情变得更加晦涩，而是揭示整个过程的优雅的几何解释。如果你懂一点代数，你可能已经看到原始梯度通过使用投影算子<strong class="lb iu"> P </strong>被投影到权重空间中的某个超平面上。</p><p id="6876" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">投影算子</strong></p><p id="72a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了确保我们在同一页上，让我们看一个简单的例子来回顾一下关于投影算子的一些基本事实——让我们考虑下面的矩阵<strong class="lb iu"> P <em class="nt"> </em> </strong>以及当它应用于三维空间中的任何向量<strong class="lb iu"> v <em class="nt"> </em> </strong>时会发生什么:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/43dcf37d9c235c6a1405f05438309cbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/0*QrjwTv-pDkDaNAqF"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">三维空间中的投影运算符示例</p></figure><p id="0ae7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如你所见，<strong class="lb iu"> v </strong>失去了它的<em class="nt"> z </em>分量——换句话说，它被<strong class="lb iu">投影到<strong class="lb iu"> XY </strong>平面上:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/1c568e6bdf616c561c6f7b9259466958.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*GQ_vPU2camebJilem69hrA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">投影可视化</p></figure><p id="7da2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果再次应用投影操作符会发生什么？什么都没有，向量不能让<em class="nt">更多的</em>投影到<strong class="lb iu"> XY </strong>平面。这是投影运算符的定义属性之一:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/5c760fb0f51ada3d451b685c6ceeb5d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:196/0*-PgGJuzJ39keZLnc"/></div></figure><p id="1b6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果投影是<strong class="lb iu">正交的</strong>，则必须满足另一个条件:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/e08a432c1280d5d23eb2d98953ad97a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:202/0*MUfwIId5ZvAvOOX0"/></div></figure><p id="0d8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果矢量<strong class="lb iu"> e </strong>垂直于投影平面，那么它也垂直于任何矢量<strong class="lb iu"> v </strong>到该平面的投影:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/8db5db379dbb0df0c42783dcf3afce0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:158/0*_lX2D4Yx46uk8hvN"/></div></figure><p id="07a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，对于我们前面的投影到<strong class="lb iu"> XY </strong>平面的例子，我们可以看到任何垂直矢量<strong class="lb iu"> e </strong>都满足上面的等式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/c3b3df1f289f0dd87d4d0883c3a7a83a.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*THehkUcdlAq3jBqo"/></div></figure><p id="0bf4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">作为投影的GC</strong></p><p id="18a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，如果你检查前面定义的GC运算符<strong class="lb iu"> P </strong>的上述条件(1)和(2)，你会得出结论:它是一个正交投影。</p><p id="4651" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，您可以检查:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/a99dd914ab2e68a4d03f68569c78e0f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/0*zxDN_sWe17vEIuDc"/></div></figure><p id="4210" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着<strong class="lb iu"> e </strong>是梯度被投影到其上的超平面的法向量。</p><p id="3719" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们采用由权重空间中的向量<strong class="lb iu"> w </strong>表示的任何旧权重，并且通过损失函数的投影梯度(而不是梯度本身)来校正它，我们将获得以下新的权重向量<strong class="lb iu">w’</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/91088a3a7cbea374ee06bdb1926dbd24.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/0*i9r5oZc6HijUAY6s"/></div></figure><p id="b014" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这导致:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/ab0a5049d1db61108e52362a215269f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/0*0dy9_bxNaGnU9Iym"/></div></figure><p id="dde3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将转置的法向量<strong class="lb iu"> e </strong>应用于上述等式的两侧会导致:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/1dc11723ab60c0f83ddd953bc81fc1ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/0*iRL5DplNTHjydpbp"/></div></figure><p id="ad0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着对于在连续训练迭代(0，1，2，…，t)中计算的权重，以下为真:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/a524a6af77ebb0b857a3e8cf6bf8eb60.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*qwKc0Cy-QrZHouwM9NzZIQ.png"/></div></figure><p id="1bc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，优化问题可以写成:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/e0ead339c39f93eb6a06d1b2ccbb09a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/0*zUfVDYRhyKFflqOX"/></div></figure><p id="889c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用文章作者的话说，这意味着</p><blockquote class="of og oh"><p id="25db" class="kz la nt lb b lc ld ju le lf lg jx lh oi lj lk ll oj ln lo lp ok lr ls lt lu im bi translated">GC可以看作是一种具有约束损失函数的投影梯度下降法。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/2e1f6c7ad51670c1ff782136286362fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4djBgds1Z3U0_VMWwc0KUA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:https://arxiv.org/pdf/2004.01461.pdf<a class="ae ky" href="https://arxiv.org/pdf/2004.01461.pdf" rel="noopener ugc nofollow" target="_blank"/></p></figure><h2 id="0d87" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">这如何导致正规化？</h2><p id="63b2" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">对权重向量的这种约束调整了<strong class="lb iu"> w </strong>的解空间，导致<strong class="lb iu">训练模型</strong>更好的泛化能力。</p><p id="66dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了正则化权重空间之外，所提出的方法还正则化输出特征空间。给定输入向量<strong class="lb iu"> x </strong>，步骤<em class="nt"> t </em>中的输出激活被计算为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/f00425c278df52092f94c55dac739eba.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/0*wVtxtRsP7ut-suCS"/></div></figure><p id="fcbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们考虑一个输入向量<strong class="lb iu">x’</strong>，它与<strong class="lb iu"> x </strong>的区别仅在于恒定的强度变化<em class="nt"> γ </em>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/f96bf82119346ad2cfc5781c077ba6e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:182/0*_Jy-HvlK1AKZBWfn"/></div></figure><p id="f46b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以看出(详情请查阅原文章的附录):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/53668f4c560d972b3b69a51d9fd79684.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/0*Yl0cfV2-tsbDXV8E"/></div></figure><p id="a8e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，通过选择小的初始权重，我们可以确保输出激活对输入特征的强度变化不敏感。</p><p id="f3ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该文章还提到，所提出的技术通过优化景观平滑和梯度爆炸抑制来加速训练过程，但我不会在这里讨论这些。</p><p id="34b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一篇文章<a class="ae ky" href="https://medium.com/@tomelisse/gradient-centralization-in-keras-9e4e34a8b895" rel="noopener">中，我将展示如何实际使用所提出的技术。</a></p></div></div>    
</body>
</html>