<html>
<head>
<title>Machine Learning Model Regularization in Practice: an example with Keras and TensorFlow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实践中的机器学习模型正则化:以 Keras 和 TensorFlow 2.0 为例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-model-regularization-in-practice-an-example-with-keras-and-tensorflow-2-0-52a96746123e?source=collection_archive---------15-----------------------#2020-07-02">https://towardsdatascience.com/machine-learning-model-regularization-in-practice-an-example-with-keras-and-tensorflow-2-0-52a96746123e?source=collection_archive---------15-----------------------#2020-07-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8332" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一步一步的教程，使用 L2 正则化和辍学，以减少过度拟合的神经网络模型。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3b2da8caebf05c5fcf4fc7c660348cc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iUM1yJYDIF_3-Hbs-ytRrA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@rocknrollmonkey?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">摇滚猴子</a>在<a class="ae ky" href="https://unsplash.com/s/photos/artificial-intelligence?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="6fed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将重点关注将正则化纳入我们的机器学习模型，并查看一个示例，说明我们如何在 Keras 和 TensorFlow 2.0 的实践中做到这一点。</p><h1 id="78b1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">正规化的简明介绍</h1><blockquote class="mn"><p id="7749" class="mo mp it bd mq mr ms mt mu mv mw lu dk translated">事实证明，许多人害怕数学，尤其是初学者和将职业道路转向数据科学的人。</p></blockquote><p id="1fdb" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">让我们避开数学，试着用更温和的方式解释正则化。如果你正在寻找正规化的完整解释(带有大量数学表达式)，你可能会发现以下文章很有用:</p><ul class=""><li id="8bd2" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu nh ni nj nk bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/regularization-in-machine-learning-76441ddcf99a">机器学习中的正则化</a></li><li id="55c1" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/regularization-an-important-concept-in-machine-learning-5891628907ea">正则化:机器学习中的一个重要概念</a></li></ul><p id="b3f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正则化是一种对抗机器学习中<strong class="lb iu"> <em class="nq">过拟合</em> </strong>问题的技术。<strong class="lb iu"> <em class="nq">过拟合</em> </strong>，也称为<strong class="lb iu"> <em class="nq">高方差，</em> </strong>指的是对训练数据学习得太好，但未能推广到新数据的模型。例如，下面的绿线是过度拟合的模型，黑线代表正则化的模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/8587d104df6fa5d5458ee1221ee64f8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*6sULF9_kRtcWpkh955MzIA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">绿线代表过度拟合的模型，黑线代表正则化的模型。来源于<a class="ae ky" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="12d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="nq">过拟合</em> </strong>可以通过标图训练和验证损失来诊断。例如，在下图中，训练错误显示为蓝色，验证错误显示为红色，两者都是训练时期数的函数。如果验证误差增加，而训练误差稳定减少，则可能出现过拟合的情况。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/7211dfb606c2bd5d4646c4d7e9b5829c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*Jw18TckYxqV8wp4fzv7c7g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">过度拟合可以通过绘制训练和验证损失来诊断。来源于<a class="ae ky" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="7b70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦诊断出过度拟合，就应该尝试不同的正则化技术和参数，看看它们是否有帮助。最广泛使用的正则化技术有:</p><ul class=""><li id="c34a" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu nh ni nj nk bi translated"><strong class="lb iu"> <em class="nq"> L1 正则化</em> </strong>给损失函数增加了<em class="nq">绝对值</em>作为惩罚项。有人说 L1 可以帮助压缩模型。但在实践中，L1 正则化使你的模型稀疏，只有一点点帮助。L2 正则化只是用得更多。</li><li id="a773" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated"><strong class="lb iu"> <em class="nq"> L2 正则化</em> </strong>(也称为权重衰减)将<em class="nq">平方量级</em>作为惩罚项添加到损失函数中，它比 L1 使用得更频繁。</li><li id="1028" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated"><strong class="lb iu"> <em class="nq"> Dropout </em> </strong>是深度学习中广泛使用的正则化技术。它在每次迭代中随机关闭一些神经元。</li><li id="d0b5" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated"><strong class="lb iu"> <em class="nq">数据增加</em> </strong>增加额外的假训练数据。更多的训练也有助于减少过度配合。</li><li id="5c5b" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated"><strong class="lb iu"> <em class="nq">提前停止</em> </strong>是深度学习中另一种广泛使用的正则化技术。当泛化误差增加时，它停止训练。</li></ul><p id="8f57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下面的文章中，我们将结合 L2 正则化和辍学，以减少神经网络模型的过度拟合。</p><h1 id="2e1e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">环境设置、源代码和数据集准备</h1><p id="4bca" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">为了运行本教程，您需要安装</p><blockquote class="mn"><p id="1ca1" class="mo mp it bd mq mr ms mt mu mv mw lu dk translated"><em class="ny"> TensorFlow 2，numpy，pandas，sklean，matplotlib </em></p></blockquote><p id="b9b2" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">它们都可以直接安装在 vis PyPI 上，我强烈建议创建一个新的虚拟环境。关于创建 Python 虚拟环境的教程</p><ul class=""><li id="912f" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu nh ni nj nk bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/create-virtual-environment-using-virtualenv-and-add-it-to-jupyter-notebook-6e1bf4e03415">使用“virtualenv”创建虚拟环境，并将其添加到 Jupyter 笔记本中</a></li><li id="b88f" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated"><a class="ae ky" href="https://medium.com/analytics-vidhya/create-virtual-environment-using-conda-and-add-it-to-jupyter-notebook-d319a81dfd1" rel="noopener">使用“conda”创建虚拟环境，并将其添加到 Jupyter 笔记本中</a></li></ul><h2 id="4502" class="nz lw it bd lx oa ob dn mb oc od dp mf li oe of mh lm og oh mj lq oi oj ml ok bi translated">源代码</h2><p id="5ee2" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">这是一个循序渐进的教程，所有的说明都在这篇文章中。源代码请查看我的 Github <a class="ae ky" href="https://github.com/BindiChen/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习报告</a>。</p><h2 id="fb94" class="nz lw it bd lx oa ob dn mb oc od dp mf li oe of mh lm og oh mj lq oi oj ml ok bi translated">数据集准备</h2><p id="7b31" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">本教程使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Iris_flower_data_set" rel="noopener ugc nofollow" target="_blank">安德森鸢尾花(iris) </a>数据集进行演示。该数据集包含五个属性下的一组 150 条记录:<em class="nq">萼片长度</em>、<em class="nq">萼片宽度</em>、<em class="nq">花瓣长度</em>、<em class="nq">花瓣宽度、</em>和<em class="nq">类别</em>(从 sklearn 数据集称为<em class="nq">目标</em>)。</p><p id="6f25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入库并从<strong class="lb iu"> <em class="nq"> scikit-learn </em> </strong>库中获取虹膜数据集。你也可以从<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank"> UCI 虹膜数据集</a>下载。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="0bf3" class="nz lw it om b gy oq or l os ot">import tensorflow as tf<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.datasets import load_iris<br/>from sklearn.model_selection import train_test_split</span><span id="4b0e" class="nz lw it om b gy ou or l os ot"><strong class="om iu">iris = load_iris()</strong></span></pre><p id="e554" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了研究数据，让我们将数据加载到一个数据帧中</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="1992" class="nz lw it om b gy oq or l os ot"># Load data into a DataFrame<br/><strong class="om iu">df = pd.DataFrame(iris.data, columns=iris.feature_names)<br/></strong># Convert datatype to float<br/><strong class="om iu">df = df.astype(float)<br/></strong># append "target" and name it "label"<br/><strong class="om iu">df['label'] = iris.target<br/></strong># Use string label instead<br/><strong class="om iu">df['label'] = df.label.replace(dict(enumerate(iris.target_names)))</strong></span></pre><p id="6882" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并且<code class="fe ov ow ox om b">df</code>应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/7570617ad415e49e0f4ae3de3cb36ead.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jnF9SoyQhWkNULQa6j8kZA.png"/></div></div></figure><p id="ee31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们注意到<strong class="lb iu"> <em class="nq">标签</em> </strong>列是一个分类特征，需要将它转换成<a class="ae ky" rel="noopener" target="_blank" href="/what-is-one-hot-encoding-and-how-to-use-pandas-get-dummies-function-922eb9bd4970">一次性编码</a>。否则，我们的机器学习算法将无法直接将其作为输入。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="ad5d" class="nz lw it om b gy oq or l os ot"># label -&gt; one-hot encoding<br/><strong class="om iu">label = pd.get_dummies(df['label'], prefix='label')</strong><br/><strong class="om iu">df = pd.concat([df, label], axis=1)</strong><br/># drop old label<br/>df.drop(['label'], axis=1, inplace=True)</span></pre><p id="0624" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，<code class="fe ov ow ox om b">df</code>应该是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/e880825f90220c91e0cd29f784bfe705.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7f3RhJEpTEwTi5XXWf0UGw.png"/></div></div></figure><p id="d1f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们创建<code class="fe ov ow ox om b">X</code>和<code class="fe ov ow ox om b">y</code>。Keras 和 TensorFlow 2.0 只接受 Numpy 数组作为输入，所以我们必须将 DataFrame 转换回 Numpy 数组。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="a401" class="nz lw it om b gy oq or l os ot"># Creating X and y</span><span id="8974" class="nz lw it om b gy ou or l os ot"><strong class="om iu">X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]</strong><br/># Convert DataFrame into np array<br/><strong class="om iu">X = np.asarray(X)</strong></span><span id="324a" class="nz lw it om b gy ou or l os ot"><strong class="om iu">y = df[['label_setosa', 'label_versicolor', 'label_virginica']]<br/></strong># Convert DataFrame into np array<br/><strong class="om iu">y = np.asarray(y)</strong></span></pre><p id="0d50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们使用来自<strong class="lb iu"> sklearn </strong>库中的<code class="fe ov ow ox om b"><strong class="lb iu">train_test_split()</strong></code> <strong class="lb iu"> </strong>将数据集拆分成训练集(80%)和测试集(20%)。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="d4e2" class="nz lw it om b gy oq or l os ot">X_train, X_test, y_train, y_test = <strong class="om iu">train_test_split</strong>(<br/>  <strong class="om iu">X,<br/>  y,<br/>  test_size=0.20</strong><br/>)</span></pre><p id="a042" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">太好了！我们的数据已经准备好建立一个机器学习模型。</p><h1 id="cb60" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1.建立非正则化神经网络模型</h1><p id="1a37" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">在应用正则化之前，<strong class="lb iu">让我们建立一个没有正则化的神经网络，看看过拟合问题</strong>。</p><p id="d269" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用 Keras 和 Tensorflow 2 创建机器学习模型有<a class="ae ky" rel="noopener" target="_blank" href="/3-ways-to-create-a-machine-learning-model-with-keras-and-tensorflow-2-0-de09323af4d3"> 3 种方法。由于我们正在构建一个简单的全连接神经网络，为了简单起见，让我们使用最简单的方法:带有<code class="fe ov ow ox om b">Sequential()</code>的顺序模型。</a></p><p id="785d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们继续创建一个名为<code class="fe ov ow ox om b">create_model()</code>的函数来返回一个序列模型。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="8fd9" class="nz lw it om b gy oq or l os ot">from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense</span><span id="3f82" class="nz lw it om b gy ou or l os ot">def <strong class="om iu">create_model()</strong>: <br/>    model = Sequential([<br/>        Dense(64, activation='relu', <strong class="om iu">input_shape=(4,)</strong>),<br/>        Dense(128, activation='relu'),<br/>        Dense(128, activation='relu'),<br/>        Dense(128, activation='relu'),<br/>        Dense(64, activation='relu'),<br/>        Dense(64, activation='relu'),<br/>        Dense(64, activation='relu'),<br/>        <strong class="om iu">Dense(3, activation='softmax')</strong><br/>    ])<br/>    return model</span></pre><p id="5573" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意到</p><ul class=""><li id="75d8" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu nh ni nj nk bi translated">第一层(也称为输入层)有<code class="fe ov ow ox om b">input_shape</code>来设置输入大小<code class="fe ov ow ox om b">(4,)</code></li><li id="befe" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated">输入层有 64 个单元，接着是 3 个密集层，每个层有 128 个单元。然后还有 3 个密集层，每个层有 64 个单元。所有这些层都使用 ReLU 激活功能。</li><li id="e58e" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated">输出密集层有 3 个单元和 softmax 激活功能。</li></ul><p id="431c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过跑步</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="681c" class="nz lw it om b gy oq or l os ot">model = create_model()<br/>model.summary()</span></pre><p id="726c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">应该打印出模型摘要。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/a8cced000e491487c9db7b822ec9ee32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g8wvF3hwarQgUjnUuJWcVg.png"/></div></div></figure><h2 id="7b66" class="nz lw it bd lx oa ob dn mb oc od dp mf li oe of mh lm og oh mj lq oi oj ml ok bi translated">1.1 培训模型</h2><p id="6d06" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">为了训练一个模型，我们首先必须使用<code class="fe ov ow ox om b">compile()</code>配置我们的模型，并传递以下参数:</p><ul class=""><li id="d7f9" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu nh ni nj nk bi translated">使用 Adam ( <code class="fe ov ow ox om b">adam</code>)优化算法作为优化器</li><li id="6dc5" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated">对于我们的<strong class="lb iu"> <em class="nq">多类分类</em> </strong>问题，使用分类交叉熵损失函数(<code class="fe ov ow ox om b">categorical_crossentropy</code></li><li id="5aa6" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated">为简单起见，使用<code class="fe ov ow ox om b">accuracy</code>作为我们在训练和测试期间评估模型的评估指标。</li></ul><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="dcf0" class="nz lw it om b gy oq or l os ot">model.compile(<br/>    <strong class="om iu">optimizer='adam', <br/>    loss='categorical_crossentropy', <br/>    metrics=['accuracy']</strong><br/>)</span></pre><p id="7f82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们可以调用<code class="fe ov ow ox om b">model.fit()</code>来使我们的模型适合训练数据。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="1f13" class="nz lw it om b gy oq or l os ot">history = model.fit(<br/>    X_train, <br/>    y_train, <br/>    <strong class="om iu">epochs=200, <br/>    validation_split=0.25, <br/>    batch_size=40, </strong><br/>    verbose=2<br/>)</span></pre><p id="67f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果一切顺利，我们应该得到如下输出</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="bd21" class="nz lw it om b gy oq or l os ot">Train on 90 samples, validate on 30 samples<br/>Epoch 1/200<br/>90/90 - 1s - loss: 1.0939 - accuracy: 0.4333 - val_loss: 1.0675 - val_accuracy: 0.5333<br/>Epoch 2/200<br/>90/90 - 0s - loss: 1.0553 - accuracy: 0.6556 - val_loss: 1.0160 - val_accuracy: 0.7000<br/>......<br/>......<br/>Epoch 200/200<br/>90/90 - 0s - loss: 0.0624 - accuracy: 0.9778 - val_loss: 0.1874 - val_accuracy: 0.9333</span></pre><h2 id="0d9b" class="nz lw it bd lx oa ob dn mb oc od dp mf li oe of mh lm og oh mj lq oi oj ml ok bi translated">1.2 模型评估</h2><p id="7ada" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">一旦训练完成，就该看看模型是否适合模型评估了。模型评估通常包括</p><ol class=""><li id="f82e" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu pb ni nj nk bi translated">绘制<strong class="lb iu">损失</strong>和<strong class="lb iu">准确性</strong>指标的进度</li><li id="b7fd" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu pb ni nj nk bi translated">用从未用于训练的数据来测试我们的模型。这就是我们之前搁置的测试数据集<code class="fe ov ow ox om b">X_test</code>发挥作用的地方。</li></ol><p id="04c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们创建一个函数<code class="fe ov ow ox om b">plot_metric()</code>来绘制度量标准。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="61b8" class="nz lw it om b gy oq or l os ot">%matplotlib inline<br/>%config InlineBackend.figure_format = 'svg'</span><span id="e944" class="nz lw it om b gy ou or l os ot">def <strong class="om iu">plot_metric(history, metric)</strong>:<br/>    train_metrics = history.history[metric]<br/>    val_metrics = history.history['val_'+metric]<br/>    epochs = range(1, len(train_metrics) + 1)<br/>    plt.plot(epochs, train_metrics)<br/>    plt.plot(epochs, val_metrics)<br/>    plt.title('Training and validation '+ metric)<br/>    plt.xlabel("Epochs")<br/>    plt.ylabel(metric)<br/>    plt.legend(["train_"+metric, 'val_'+metric])<br/>    plt.show()</span></pre><p id="3e13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过运行<code class="fe ov ow ox om b">plot_metric(history, 'accuracy')</code>绘制精度进度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/2d2978ff3799e468d4408ed7be7d00fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C7s4Bwc4p8sruDNQo9OUCg.png"/></div></div></figure><p id="239b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过运行<code class="fe ov ow ox om b">plot_metric(history, 'loss')</code>绘制损失进度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/c329d1f071743ba347c656c5a7452921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LkGsJQ0q8Clr9Fe_gB1Wwg.png"/></div></div></figure><p id="c09e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的图表中，<strong class="lb iu">我们可以看到，模型过度拟合了训练数据，因此它的表现优于验证集。</strong></p><p id="18f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在测试集上评估模型</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="1b17" class="nz lw it om b gy oq or l os ot"># Evaluate the model on the test set<br/>model.<strong class="om iu">evaluate</strong>(<strong class="om iu">X_test</strong>, <strong class="om iu">y_test</strong>, verbose=2)</span></pre><p id="29cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们应该得到如下所示的输出</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="b5b0" class="nz lw it om b gy oq or l os ot">30/1 - 0s - loss: 0.0137 - accuracy: 1.0000<br/>[0.01365612167865038, 1.0]</span></pre><h1 id="2673" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.添加 L2 正规化和辍学</h1><p id="7f33" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">首先，让我们从 TensorFlow Keras 包中导入<strong class="lb iu"><em class="nq"/></strong><strong class="lb iu"><em class="nq">L2</em></strong>转正</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="8c30" class="nz lw it om b gy oq or l os ot">from tensorflow.keras.<strong class="om iu">layers</strong> import <strong class="om iu">Dropout</strong><br/>from tensorflow.keras.<strong class="om iu">regularizers</strong> import <strong class="om iu">l2</strong></span></pre><p id="bad2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们创建一个名为<code class="fe ov ow ox om b">create_regularized_model()</code>的函数，它将返回一个类似于我们之前构建的模型。但是，这次我们将添加<strong class="lb iu"> <em class="nq"> L2 正则化</em> </strong>和<strong class="lb iu"> <em class="nq">辍学</em> </strong>层，所以这个函数需要 2 个参数:一个 L2 正则化<code class="fe ov ow ox om b">factor</code>和一个辍学<code class="fe ov ow ox om b">rate</code>。</p><ul class=""><li id="1025" class="nc nd it lb b lc ld lf lg li ne lm nf lq ng lu nh ni nj nk bi translated">让我们添加<strong class="lb iu"> <em class="nq"> L2 正则化</em> </strong>在所有层除了输出层[1]。</li><li id="0e8e" class="nc nd it lb b lc nl lf nm li nn lm no lq np lu nh ni nj nk bi translated">让我们在每两个密集层之间添加<strong class="lb iu"><em class="nq"/></strong>层。</li></ul><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="6b39" class="nz lw it om b gy oq or l os ot">def <strong class="om iu">create_regularized_model</strong>(<strong class="om iu">factor</strong>, <strong class="om iu">rate</strong>):<br/>    model = Sequential([<br/>        Dense(64, <strong class="om iu">kernel_regularizer=l2(factor)</strong>, activation="relu", input_shape=(4,)),<br/>        <strong class="om iu">Dropout(rate),</strong><br/>        Dense(128, <strong class="om iu">kernel_regularizer=l2(factor)</strong>, activation="relu"),<br/>        <strong class="om iu">Dropout(rate),</strong><br/>        Dense(128, <strong class="om iu">kernel_regularizer=l2(factor)</strong>, activation="relu"),<br/>        <strong class="om iu">Dropout(rate),</strong><br/>        Dense(128, <strong class="om iu">kernel_regularizer=l2(factor)</strong>, activation="relu"),<br/>        <strong class="om iu">Dropout(rate),</strong><br/>        Dense(64, <strong class="om iu">kernel_regularizer=l2(factor),</strong> activation="relu"),<br/>        <strong class="om iu">Dropout(rate),</strong><br/>        Dense(64, <strong class="om iu">kernel_regularizer=l2(factor),</strong> activation="relu"),<br/>        <strong class="om iu">Dropout(rate),</strong><br/>        Dense(64, <strong class="om iu">kernel_regularizer=l2(factor),</strong> activation="relu"),<br/>        <strong class="om iu">Dropout(rate),</strong><br/>        Dense(3, activation='softmax')<br/>    ])<br/>    return model</span></pre><p id="1b19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用参数 L2 因子 0.0001 和辍学率 0.3 来创建模型</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="e0d2" class="nz lw it om b gy oq or l os ot">model = create_regularized_model(1e-5, 0.3)<br/>model.summary()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/ef9224cb23c1324fbcd1c77842ac83ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jqgUSLmm9Avnquh49atWNA.png"/></div></div></figure><h2 id="dc13" class="nz lw it bd lx oa ob dn mb oc od dp mf li oe of mh lm og oh mj lq oi oj ml ok bi translated">2.1 培训</h2><p id="971a" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">正则化模型可以像我们构建的第一个模型一样被训练。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="89ee" class="nz lw it om b gy oq or l os ot"># First configure model using model.compile()<br/>model.compile(<br/>    <strong class="om iu">optimizer='adam', <br/>    loss='categorical_crossentropy', <br/>    metrics=['accuracy']</strong><br/>)</span><span id="b86b" class="nz lw it om b gy ou or l os ot"># Then, train the model with fit()<br/>history = model.fit(<br/>    X_train, <br/>    y_train, <br/>    <strong class="om iu">epochs=200, <br/>    validation_split=0.25, <br/>    batch_size=40, </strong><br/>    verbose=2<br/>)</span></pre><p id="e611" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果一切顺利，我们应该得到如下输出</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="0e93" class="nz lw it om b gy oq or l os ot">Train on 90 samples, validate on 30 samples<br/>Epoch 1/200<br/>90/90 - 2s - loss: 1.0855 - accuracy: 0.3333 - val_loss: 1.0873 - val_accuracy: 0.3000<br/>Epoch 2/200<br/>90/90 - 0s - loss: 1.0499 - accuracy: 0.3778 - val_loss: 1.0773 - val_accuracy: 0.3000<br/>......<br/>......<br/>Epoch 200/200<br/>90/90 - 0s - loss: 0.1073 - accuracy: 0.9556 - val_loss: 0.1766 - val_accuracy: 0.9000</span></pre><h2 id="7a82" class="nz lw it bd lx oa ob dn mb oc od dp mf li oe of mh lm og oh mj lq oi oj ml ok bi translated">2.2 模型评估</h2><p id="c7e6" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">现在，让我们画出损失的进度</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="f279" class="nz lw it om b gy oq or l os ot">plot_metric(history, 'loss')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/cb2a3a8088a3c8714bd6282f985bc0d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ro7wynv_nrFA61TzqUEgdQ.png"/></div></div></figure><p id="8e87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从图中我们可以看出，过度拟合并没有完全解决，但是与非正则化模型相比，有了显著的改善。</p><p id="cd7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，在测试集上评估模型</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="ed81" class="nz lw it om b gy oq or l os ot">model.evaluate(X_test, y_test, verbose=2)</span></pre><p id="2313" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">应该会输出类似于</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="5d88" class="nz lw it om b gy oq or l os ot">30/1 - 0s - loss: 0.0602 - accuracy: 0.9667<br/>[0.06016349419951439, 0.96666664]</span></pre><h1 id="5931" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">好了</h1><p id="efd3" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">感谢阅读。</p><p id="5715" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请在我的 Github 上的<a class="ae ky" href="https://github.com/BindiChen/machine-learning" rel="noopener ugc nofollow" target="_blank">笔记本中查看源代码。</a></p><p id="e842" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你对机器学习的实用方面感兴趣，请继续关注。</p><h1 id="e299" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考资料:</h1><ul class=""><li id="9e23" class="nc nd it lb b lc nt lf nu li pg lm ph lq pi lu nh ni nj nk bi translated">[1] <a class="ae ky" href="https://keras.io/api/layers/regularizers/" rel="noopener ugc nofollow" target="_blank"> Keras 层权重正则化子</a></li></ul></div></div>    
</body>
</html>