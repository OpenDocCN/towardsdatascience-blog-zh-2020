<html>
<head>
<title>Winning Solution of an Online Data Science Hackathon</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在线数据科学黑客马拉松的获奖解决方案</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/winning-solution-of-an-online-data-science-hackathon-ead4d340bb41?source=collection_archive---------16-----------------------#2020-03-27">https://towardsdatascience.com/winning-solution-of-an-online-data-science-hackathon-ead4d340bb41?source=collection_archive---------16-----------------------#2020-03-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a1d1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我在Analytics Vidhya数据科学黑客马拉松上的获奖解决方案的完整代码</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1ef8b487374e0080a554779317377c2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EeooPXATEQhEotG_"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">杰佛森·桑多斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="69c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据科学黑客马拉松是有抱负的数据科学家的终极战场。任何黑客马拉松的目的都是让你的想象力引导你拓展这个领域的知识和技能。</p><p id="2d02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过两年的自学，我决定与其他数据科学家一起在实际战场上检验我的技能。所以我决定参加在线黑客马拉松。我决定将网站列入候选名单，并很快选择了Analytics Vidhya开始我的黑客马拉松之旅。</p><p id="b952" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我最初的起步不够好。但是我在我的前四个在线黑客马拉松中的一个上得到了前50名。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/9a1ae9f62161ff32c6f04c45b1be331d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iQGLbDGxL-ZOtxeCBEiMbQ.png"/></div></div></figure><p id="cb0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从中学到的一件重要的事情是不要参加所有可能的黑客马拉松。</p><blockquote class="lw"><p id="6701" class="lx ly it bd lz ma mb mc md me mf lu dk translated">重要的是列出一个你想关注的特定的黑客马拉松，并为此全力以赴。不要同时参加多个黑客马拉松，因为每个黑客马拉松都需要适当的时间和努力。</p></blockquote><p id="4049" class="pw-post-body-paragraph kz la it lb b lc mg ju le lf mh jx lh li mi lk ll lm mj lo lp lq mk ls lt lu im bi translated">8月，Analytics Vidhya发起了数据至上黑客马拉松。</p><p id="aea7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">链接到黑客马拉松:<a class="ae ky" href="https://datahack.analyticsvidhya.com/contest/the-data-supremacy/" rel="noopener ugc nofollow" target="_blank">https://data hack . analyticsvidhya . com/contest/the-data-supremity/</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ml"><img src="../Images/3d3081f31f6e608ad37038c1487262da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fM9yZe-feDS-WWZ6AA53nw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://datahack.analyticsvidhya.com/contest/the-data-supremacy/" rel="noopener ugc nofollow" target="_blank">datahack.analyticsvidhya.com/contest/the-data-supremacy/</a></p></figure><p id="de8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并且在看了问题陈述之后，我决定参与并尽我所能。为了更容易理解，我将在不同的部分决定解决方案。</p><h1 id="7833" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">问题</h1><p id="33c8" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">黑客马拉松是一个<strong class="lb iu">二元分类</strong>问题，我们必须根据特定学生的历史背景来预测他是否有资格参加。</p><p id="c94d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集大小:</p><p id="9c07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">火车造型:(18359，14) <br/>测试造型:(15021，13)</p><p id="c467" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目标:二元分类→ 0/1</p><p id="6fde" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给出的特征总数:13个特征[列]</p><h1 id="e567" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">了解功能</h1><p id="3dda" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">这是几乎每个人都跳过的重要一步。</p><blockquote class="lw"><p id="0e1b" class="lx ly it bd lz ma mb mc md me mf lu dk translated">不要直接跳到写机器学习代码。首先了解问题，以及每个特性的含义。看看你是否能找到特征和目标变量之间的关系。</p></blockquote><p id="b6bd" class="pw-post-body-paragraph kz la it lb b lc mg ju le lf mh jx lh li mi lk ll lm mj lo lp lq mk ls lt lu im bi translated">在对所有特性进行了适当的研究之后，我决定从代码开始。</p><h1 id="d554" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">图书馆</h1><p id="d330" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">以下是我在整个黑客马拉松中使用的库。</p><p id="6374" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我几乎在任何地方都使用的3个基本库。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="7d31" class="no mn it nk b gy np nq l nr ns">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span></pre><p id="d1b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:我已经包括了比我实际使用的更多的库，来展示我在黑客马拉松中尝试过的所有库。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="95c8" class="no mn it nk b gy np nq l nr ns">import xgboost as xgb<br/>from xgboost.sklearn import XGBClassifier,XGBRegressor<br/>import catboost<br/>from catboost import CatBoostClassifier<br/>from sklearn.preprocessing import LabelEncoder , MinMaxScaler<br/>from sklearn.cross_validation import KFold , cross_val_score<br/>from sklearn.metrics import accuracy_score , roc_auc_score,confusion_matrix<br/>from sklearn.grid_search import GridSearchCV<br/>from sklearn import metrics<br/>from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier<br/>from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier<br/>from sklearn.svm import SVR<br/>from sklearn.linear_model import LogisticRegression,LinearRegression<br/>from sklearn.ensemble import ExtraTreesClassifier<br/>from sklearn.model_selection import RandomizedSearchCV</span></pre><h1 id="b920" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">数据看起来怎么样？</h1><p id="75de" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">现在是时候阅读培训和测试csv了。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="c065" class="no mn it nk b gy np nq l nr ns">train_data = pd.read_csv('train_FG6BvLg.csv')<br/>test_data = pd.read_csv('test_wovud0B.csv')<br/>print("Train Shape : {}\nTest Shape : {}".format(train_data.shape,test_data.shape))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/a1f10583945a57ab0f791fb476a0e65a.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*EkAPZ9QOL6Cf8GHnoln-CQ.png"/></div></figure><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="ce58" class="no mn it nk b gy np nq l nr ns">train_data.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/ef68dc1f4f2b01737bdd3d9d94d2c5cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y9VVBleLperG24K3mLtMCg.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/2a0692689ae5b4e4bcf1fed48c5b6f99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b_ZiAyQYTY7iLe-SW0mf8g.png"/></div></div></figure><p id="8346" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我不得不把快照分成两张图片，因为它在一张图片中看不到。</p><p id="a743" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">目标</strong>列是我们测试文件中要预测的列。</p><h1 id="d69f" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">预处理</h1><p id="0bc9" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">我总时间的大约75%用于预处理数据。</p><p id="c0f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我研究了所有的列，想出了预处理它们的所有方法，并得出了最终的预处理代码。</p><p id="cfc7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:每一列的预处理技术都是不同的，不会在所有地方都相同。</p><p id="8955" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，是时候从<strong class="lb iu">城市</strong>栏中删除文字部分了</p><p id="8727" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">城市_21 → 21</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="dc84" class="no mn it nk b gy np nq l nr ns">train_city = train_data.city.str.split("_")<br/>test_city = test_data.city.str.split("_")</span></pre><p id="005f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将包含一个有2个值的列表(前者是“城市”,后者是分配的数字)</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="5bf7" class="no mn it nk b gy np nq l nr ns">i=0<br/>for x in train_city:<br/>    train_data.loc[i,'city'] = x[1]<br/>    i=i+1</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/4935a8de6f9da1b5a66fb8e16c29cac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*5EMTWeuj2zxYx41CgV8jkQ.png"/></div></figure><p id="4fdf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以看到所做的更改。我对test_data做了同样的事情。</p><p id="3103" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我决定检查数据是否包含任何缺失值。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="f383" class="no mn it nk b gy np nq l nr ns">train_data.isnull().sum()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/d63c46b2816f97a4c99a7b3ce56f3a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*ZwicTbrw0x03AfXTV31PPw.png"/></div></figure><p id="6776" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要正确处理这些缺失的值，因为丢弃它们会导致重要信息的丢失。</p><p id="4e3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们开始输入缺失值并对它们进行预处理之前，我们将结合训练和测试数据。这将有助于对整个数据集进行相同的更改。</p><blockquote class="nx ny nz"><p id="4e00" class="kz la oa lb b lc ld ju le lf lg jx lh ob lj lk ll oc ln lo lp od lr ls lt lu im bi translated">在组合之前，从训练数据中弹出目标列，因为它不在测试数据中。</p></blockquote><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="8ca5" class="no mn it nk b gy np nq l nr ns">target = train_data.pop('target')<br/>enrollee_id = test_data['enrollee_id']<br/>combined_data = train_data.append(test_data)</span></pre><p id="24a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在是开始进一步预处理的时候了。我将<strong class="lb iu">城市</strong>列的数据类型从字符串改为整数:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="bbdc" class="no mn it nk b gy np nq l nr ns">combined_data.city= combined_data.city.astype('int')</span></pre><p id="2b48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将<strong class="lb iu">性别</strong>列替换为整数类别:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="4691" class="no mn it nk b gy np nq l nr ns">combined_data.gender.replace({'Male':2,'Female':0,'Other':1},inplace=True)</span></pre><p id="fe4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我对另外两个专栏做了同样的事情:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="42e3" class="no mn it nk b gy np nq l nr ns">combined_data.enrolled_university.replace({'no_enrollment':1,'Part time course':2,'Full time course':3},inplace=True)</span><span id="51fb" class="no mn it nk b gy oe nq l nr ns">combined_data.major_discipline.replace({'No Major':0,'Other':1,'Arts':2,'Humanities':3,'Business Degree':4,'STEM':5},inplace=True)</span></pre><p id="acae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">列<strong class="lb iu"> experience </strong>和<strong class="lb iu"> company_size </strong>包含类似于“&lt; 10”和“&gt; 500”和“500–1000”的字符串。这阻止了将列设为整数。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="9fc7" class="no mn it nk b gy np nq l nr ns">combined_data.experience.replace({'&gt;20':21,'&lt;1':0},inplace=True)</span></pre><p id="78c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了说明company_size的样子:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="c22b" class="no mn it nk b gy np nq l nr ns">combined_data.company_size.value_counts()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0c2aacf897f37d0184c54b67198583aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*mzebLvm_I8UQ3xsbhAkiKQ.png"/></div></figure><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="c308" class="no mn it nk b gy np nq l nr ns">combined_data.company_size.replace({'&lt;10':0,'10/49':1,'50-99':2,'100-500':3,'500-999':4,'1000-4999':5,'5000-9999':6,'10000+':7},inplace=True)</span></pre><p id="707a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">company_type列具有分类值:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="8bef" class="no mn it nk b gy np nq l nr ns">combined_data.company_type.value_counts()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/39fa23fad33e79b13a2d710e922f60a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*s5jwJiUtFWQk5Qh_WwBZBA.png"/></div></figure><p id="82a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我没有给出随机数来替换，而是按照受众的递增顺序来替换。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="b5fe" class="no mn it nk b gy np nq l nr ns">combined_data.company_type.replace({'Other':0,'Early Stage Startup':1,'Funded Startup':2,'NGO':3,'Public Sector':4,'Pvt Ltd':5},inplace=True)</span></pre><p id="2334" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还在剩下的专栏中做了一些替换。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="8713" class="no mn it nk b gy np nq l nr ns">combined_data.last_new_job.replace({'never':0,'&gt;4':5,'nan':1},inplace=True)</span><span id="deae" class="no mn it nk b gy oe nq l nr ns">combined_data.relevent_experience.replace({'No relevent experience':0,'Has relevent experience':1},inplace=True)</span></pre><p id="1282" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">缺失值怎么办？</p><p id="a970" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我尝试了各种插补法，包括sklearn库中的SimpleImputator。我甚至试着用平均值来表示它们，但是这并不比用0来表示它们更好</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="d5cc" class="no mn it nk b gy np nq l nr ns">combined_data.major_discipline.fillna(0,inplace=True)<br/>combined_data.company_type.fillna(0,inplace=True)<br/>combined_data.company_size.fillna(0,inplace=True)<br/>combined_data.enrolled_university.fillna(0,inplace=True)<br/>combined_data['enrolled_university.1'].fillna(0,inplace=True)</span></pre><p id="5ca2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为数据的数值范围不同。在继续我们的模型之前，我决定将数据标准化。</p><p id="63a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用了MinMaxScaler，它允许我自定义我的最小和最大范围值。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="59f0" class="no mn it nk b gy np nq l nr ns">values  =  combined_data.values<br/>scalar = MinMaxScaler(feature_range=(0,5))<br/>x_scaled = scalar.fit_transform(values)<br/>combined_data = pd.DataFrame(x_scaled,columns=combined_data.columns)</span></pre><p id="cbe5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了转移到我们的模型，我们需要删除ID列。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="e1a9" class="no mn it nk b gy np nq l nr ns">combined_data.drop('enrollee_id',axis=1,inplace=True)</span></pre><h1 id="5a99" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">模型</h1><p id="c8ef" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">老实说，我尝试了10多种算法，看看哪一种有效。</p><p id="38ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从RandomForest开始到CatBoost。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="a0b7" class="no mn it nk b gy np nq l nr ns">clf = CatBoostClassifier(iterations=200,depth=4,eval_metric='AUC',l2_leaf_reg=9,learning_rate=0.1)</span></pre><p id="3c58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是XGBoost优于所有其他算法。所以我坚持用它来创建模型函数:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="c7c3" class="no mn it nk b gy np nq l nr ns">def model_fit(alg, dtrain, target,dtest):<br/>    xgb_param = alg.get_xgb_params()<br/>    xgtrain = xgb.DMatrix(dtrain.values, label=target)<br/>    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=5,<br/>        early_stopping_rounds=50)<br/>    <br/>    #alg.fit(dtrain,target,use_best_model=True,eval_set=(x_val,y_val))<br/>    alg.fit(dtrain,target)<br/>    print("Model Report")<br/>    print("Accuracy is {}".format(alg.score(x_val,y_val)))<br/>    <br/>    feat_imp = pd.Series(alg.feature_importances_,dtrain.columns).sort_values(ascending=False)<br/>    feat_imp.plot(kind='bar', title='Feature Importances')<br/>    plt.ylabel('Feature Importance Score')<br/>    <br/>    y_pred = alg.predict_proba(dtest)[:,1]<br/>    return y_pred</span></pre><p id="9999" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码片段在一个函数中包含了模型拟合和绘制特性重要性图。</p><p id="9d3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后是我的模型和它的参数:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="0517" class="no mn it nk b gy np nq l nr ns">clf = XGBClassifier(<br/> learning_rate =0.3,<br/> n_estimators=100,<br/> max_depth=3,<br/> min_child_weight=1000,<br/> gamma=0.7,<br/> subsample=0.45,<br/> colsample_bytree=0.4,<br/> objective= 'binary:logistic',<br/> nthread=1,<br/> scale_pos_weight=1,<br/> seed=27,<br/>reg_alpha =0.7,<br/> random_state=200)</span></pre><p id="cc8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">你是怎么得到这些参数的？</strong></p><p id="4598" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用了GridSearchCV函数，它有助于从输入的参数范围中选择最佳参数。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="df3b" class="no mn it nk b gy np nq l nr ns">param_test2 = {<br/> 'n_estimators':[150,170,200],<br/>    'learning_rate':[0.03,0.05],<br/>    'max_depth':[4,10,15,25],<br/>    'min_child_weight':[1,2,5,10],<br/>    'subsample':[0.5,0.7,1],<br/>    'colsample_bylevel':[0.45,0.7,1],<br/>    'colsample_bytree':[0.45,0.7,1],<br/>    'gamma':[0,0.1,0.5,1]<br/>}<br/>gsearch2 = GridSearchCV(estimator = XGBClassifier(), <br/> param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)<br/>gsearch2.fit(x_train,y_train)<br/>gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_</span></pre><p id="60bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GridSearchCV从我们传递的超参数排列中打印出最佳参数。(评分设置为“roc_auc”)</p><p id="c23f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">得到合适的超参数后，就该拟合模型了。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="862b" class="no mn it nk b gy np nq l nr ns">y_pred = model_fit(clf,x_train,y_train,test_data)    </span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/17823e90e0f7d887128742a25efb308c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OHf0LEZMj2dAP0U4T3M6PQ.png"/></div></div></figure><p id="2989" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如你所看到的，培训时间是使学生合格的最重要的特征，其次是城市发展指数和经验。</p><h1 id="b8c9" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">等等，我们必须评估我们的模型</h1><p id="364d" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">我使用KFold来评估我的模型，以检查它的有效性。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="4bc4" class="no mn it nk b gy np nq l nr ns">k_fold = KFold(len(train_data), n_folds=8, shuffle=True, random_state=0)<br/>print(np.mean(cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1))) </span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ba13610f6fc703ed3a66c6738dac8dfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*ijvnlsyUedo7dxVPQorH2Q.png"/></div></figure><p id="ca7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">KFold将提供训练/测试索引，将数据分成训练和测试集。它将把一个数据集分成k个连续的折叠。由于模型精度和kfold非常相似，因此模型工作正常。</p><h1 id="7f47" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">提交</h1><p id="aa0b" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">我一共上传了20多个投稿文件来提高我的分数，达到巅峰。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="e74d" class="no mn it nk b gy np nq l nr ns">submission = pd.DataFrame({'enrollee_id': enrollee_id , 'target': y_pred})<br/>submission.to_csv('submission.csv',index=False)</span></pre><h1 id="187b" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">结果</h1><p id="a9cc" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">所有的努力都得到了回报。我在全球1000人的黑客马拉松中获得了第三名。以下是排行榜的快照。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/5dc638ce10c2d8978093d04b91fef2bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WcA6ih_mw51h1LFhFBJUIQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:datahack.analyticsvidhya.com/contest/the-data-supremacy/</p></figure><p id="c882" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的用户名:jsiddhesh96</p><p id="e7b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">代码可以在我的GitHub存储库中找到:</p><div class="oj ok gp gr ol om"><a href="https://github.com/Sid11/AnalyticsVidhya_DataSupremacy" rel="noopener  ugc nofollow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">sid 11/AnalyticsVidhya _ DataSupremacy</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">比赛链接:(https://data hack . analyticsvidhya . com/contest/the-data-supremity/)我用过xgb classifier……</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">github.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa ks om"/></div></div></a></div></div></div>    
</body>
</html>