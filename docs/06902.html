<html>
<head>
<title>The robustness of Machine Learning algorithms against missing or abnormal values</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习算法对缺失值或异常值的鲁棒性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-robustness-of-machine-learning-algorithms-against-missing-or-abnormal-values-ec3222379905?source=collection_archive---------53-----------------------#2020-05-28">https://towardsdatascience.com/the-robustness-of-machine-learning-algorithms-against-missing-or-abnormal-values-ec3222379905?source=collection_archive---------53-----------------------#2020-05-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9c97" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们来探索经典机器学习算法在面对异常数据时的表现，以及标准插补方法提供的好处。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f512c38af67efa8f73d361b781a9a74a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dr9Wd-HB4ebNdqy_"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Gabriel Crismariu 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><blockquote class="kz"><p id="db84" class="la lb it bd lc ld le lf lg lh li lj dk translated">缺少值，这是每个数据科学家第一次探索数据集时的诅咒！</p></blockquote><p id="736c" class="pw-post-body-paragraph lk ll it lm b ln lo ju lp lq lr jx ls lt lu lv lw lx ly lz ma mb mc md me lj im bi translated">是的，现实生活通常与教程相去甚远，在教程中，每一列都是干净的，充满了格式正确的值，有良好的文档记录，离群值很明显，相互关系触手可及。</p><p id="cdb3" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">缺失值:NaN，null，empty，" "，凡是你能想到的！从两个角度来看，它们确实是建模过程中的一个关键问题:</p><ul class=""><li id="7fcd" class="mk ml it lm b ln mf lq mg lt mm lx mn mb mo lj mp mq mr ms bi translated"><strong class="lm iu">从纯数学的角度来看</strong>，大多数算法依赖于线性代数，向量或矩阵中的一个缺失值会使整个计算过程崩溃。<br/>让我们用一个简单的向量乘法来想象这种效果:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/797be131b53740f15ef9ae2dfd5945ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*PEAbldsizj0w7IhJXfiGCA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">线性代数…有或没有缺失值</p></figure><ul class=""><li id="4277" class="mk ml it lm b ln mf lq mg lt mm lx mn mb mo lj mp mq mr ms bi translated"><strong class="lm iu">从建模的角度来看</strong>，缺失的值代表现实的一部分，它是不可访问的、隐藏的。想象一下，作为一名调查人员，得到经过消毒的文件:你知道你不是什么都知道！</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/a03bd686d221c2423dd92dfe4e92291c.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*0Ppn74e-ImXYCTDlmt3UCQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:维基百科(模糊缩小)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/007bcdc9f13a39b45c5b127c8f3a49c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*mszKHH3lsFxPRfWV"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">至少，你什么都不知道…</p></figure></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="9034" class="nd ne it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">在工业上看起来怎么样？</h1><p id="0248" class="pw-post-body-paragraph lk ll it lm b ln nv ju lp lq nw jx ls lt nx lv lw lx ny lz ma mb nz md me lj im bi translated">从我的经验来看，诀窍是坏了的传感器不会把 NaNs 送回给你；那太容易被发现了！更有可能的是，您将获得零、有偏差的或随机的值。很棒不是吗！？</p><p id="d814" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">有一段时间，我担心在我处理的数据中加入异常值。当你探索 5000 万行 x 300 个特征时，这比在下面的图片中找到长颈鹿或豹子要困难得多:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/02b571a93b96fe0e7772d03042d67b6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QSeIz2n9U-xeaZgm6lCaqw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://artwolfe.photoshelter.com/gallery/Vanishing-Act-Camouflage-in-Nature/G0000Ma6W.F7OKto/" rel="noopener ugc nofollow" target="_blank">艺术狼提供——消失行动:自然中的伪装</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/0968c3562632e943e842b2258d38d2b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8tJNsLuIYRcka4im.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://artwolfe.photoshelter.com/gallery/Vanishing-Act-Camouflage-in-Nature/G0000Ma6W.F7OKto/" rel="noopener ugc nofollow" target="_blank">艺术狼提供——消失行动:自然中的伪装</a></p></figure><p id="410d" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">在某个时候，我决定进行自己的测试，并评估我得到的异常值的比率(总是小于 1%，大多数低于 0.5%)，最重要的是，这种现象如何影响我正在使用的算法的性能。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="ba38" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">该测试背后的原理非常简单，与通常的过程相反:</p><blockquote class="kz"><p id="eee5" class="la lb it bd lc ld ob oc od oe of lj dk translated">正常情况下，一个理智的数据科学家会试图估算缺失或异常值，以提高其模型的准确性；我选择了反过来做！</p></blockquote><p id="18d7" class="pw-post-body-paragraph lk ll it lm b ln lo ju lp lq lr jx ls lt lu lv lw lx ly lz ma mb mc md me lj im bi translated"><strong class="lm iu">首先，我会根据一个完美的数据集来评估经典机器学习算法*的性能。而且，我会逐步增加引入训练集的异常值的比率，以测量准确性的变化。</strong></p><p id="74da" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">(* Lasso、KNeighbors、随机森林和梯度增强树回归变量)</p><p id="cfe0" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">并且，当我处于“基准模式”时，我决定反转(再次！)的过程，并比较标准插补技术带来的好处:</p><ul class=""><li id="c34e" class="mk ml it lm b ln mf lq mg lt mm lx mn mb mo lj mp mq mr ms bi translated"><strong class="lm iu">简单估算器</strong>:缺失值将由一个常量值填充，该常量值是预先确定的或从特征的统计数据(平均值、中值、众数)中得出。<br/> <em class="og">注意:如果你对数据集的正态性没有信心，并且可能存在一些重要的异常值，我建议使用中位数而不是平均值，因为平均值对异常值不太敏感(见下面的例子)。</em></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ed2c3022b97fae69ee2eea25ec0c6506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*M8wz7R_vejFHR3Pv1bohKw.png"/></div></figure><ul class=""><li id="b84c" class="mk ml it lm b ln mf lq mg lt mm lx mn mb mo lj mp mq mr ms bi translated"><strong class="lm iu">迭代估算器</strong>:每个要素都将被视为数据集中所有其他要素的函数。然后回归器将根据所有其他特征来确定缺失值。这依赖于变量之间全局一致性的假设。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/dd8c104f120f4bc2665510d7cb272924.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bRx7iKbWHsjKOT2apP-y7A.png"/></div></div></figure><ul class=""><li id="6db6" class="mk ml it lm b ln mf lq mg lt mm lx mn mb mo lj mp mq mr ms bi translated"><strong class="lm iu"> KNNImputer </strong>:该插补算法基于 k 近邻法来识别数据集中的不同聚类，并在需要时使用聚类的特征来插补缺失值。</li></ul><div class="oj ok gp gr ol om"><a href="https://scikit-learn.org/stable/modules/impute.html" rel="noopener  ugc nofollow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">6.4.缺失值的插补-sci kit-学习 0.23.1 文件</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">由于各种原因，许多真实世界的数据集包含缺失值，通常编码为空白、NaNs 或其他…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">scikit-learn.org</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa ks om"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/05472e77e685c4b949079d5e2db725a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*80wf6AeqTLD9ntyFxYMuLw.jpeg"/></div></figure><h1 id="0220" class="nd ne it bd nf ng pc ni nj nk pd nm nn jz pe ka np kc pf kd nr kf pg kg nt nu bi translated">渴望了解更多信息？让我们开始吧！</h1><p id="fe76" class="pw-post-body-paragraph lk ll it lm b ln nv ju lp lq nw jx ls lt nx lv lw lx ny lz ma mb nz md me lj im bi translated">像往常一样，我们将从创建一个虚拟的“工业”数据集开始。传感器、探头、实验室测量值通常不以 0 为中心，因此我们将增加它们的值以符合现实情况:在下面的示例中，范围在 10 和 100 之间:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/88c01ca8bddd163d493b64e4a1524291.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_3QQSawkV1m4cgEkB_O1lQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据帧样本</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/674e32fa3fbca875f93ea30e54e9d194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U1pTyMAm6XkE5nBFIDt9XQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据框架的基本统计</p></figure><p id="2fa4" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">我们随机定义训练集和测试集，并记录算法在测试集中的初始性能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/a88bb5eb418a2a515d3ef34a2d26d3b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*zxxVg41s4bdGbtWUWfBtYw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们可以清楚地看到算法之间的初始性能差异</p></figure><p id="fcbc" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">一旦定义了计算方法，我们将并行运行插补方法，以获得最佳的比较结果。每个循环如下:</p><ul class=""><li id="c267" class="mk ml it lm b ln mf lq mg lt mm lx mn mb mo lj mp mq mr ms bi translated">我们将原始的<strong class="lm iu"> X_train </strong>数据帧复制到<strong class="lm iu"> X_train_NaN </strong>中，为其估算一个定义的 NaN 比率</li><li id="f85b" class="mk ml it lm b ln pm lq pn lt po lx pp mb pq lj mp mq mr ms bi translated">我们首先将所有 NaN 替换为 0，并创建最坏的情况</li><li id="86c1" class="mk ml it lm b ln pm lq pn lt po lx pp mb pq lj mp mq mr ms bi translated">我们用这个<strong class="lm iu"> X_train_NaN </strong>数据集训练每个模型，并根据原始的<strong class="lm iu"> X_test </strong>测量其性能。这将提供异常值对算法的影响</li><li id="dc3a" class="mk ml it lm b ln pm lq pn lt po lx pp mb pq lj mp mq mr ms bi translated">最后，我们用标准插补技术(平均值、迭代或 KNN 方法)替换所有的 nan，并再次检查回归变量的性能。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/d4ed2bdcba440d1b8a6373692ff0ebe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ZHcCLjvzpDo__34Y5_QntQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一张 GIF 抵得上千言万语:-)</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="3c08" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">当整个过程结束后，我们可以比较每个模型的性能:</p><ul class=""><li id="6beb" class="mk ml it lm b ln mf lq mg lt mm lx mn mb mo lj mp mq mr ms bi translated">使用初始和清洁的<strong class="lm iu"> X_train </strong>套件进行训练</li><li id="5103" class="mk ml it lm b ln pm lq pn lt po lx pp mb pq lj mp mq mr ms bi translated">用越来越多的<strong class="lm iu">0</strong>进行训练</li><li id="23f4" class="mk ml it lm b ln pm lq pn lt po lx pp mb pq lj mp mq mr ms bi translated">接受过<strong class="lm iu">标准插补技术</strong>的培训</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="cabf" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">下图显示了初始性能和以 0 的递增比率训练的模型之间的差异:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/5c309dd20b09d429e216d92eecaeea7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*btpgDpOaX_K7DrGsAAFgkA.png"/></div></div></figure><p id="07bc" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">我们可以立即看到，一旦引入第一个异常值，Lasso 的性能就完全崩溃了:0，5%导致性能下降 75%。这是由于其模型的线性结构(=方程)。</p><p id="c64c" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">如果我们排除 Lasso 回归器，我们可以注意到系综树方法(随机森林和梯度推进)非常稳健，并且优于 KN 回归器:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/5a165f3c206acbb8a4be2e5de32365a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SapuBa4pt8LHTviQmF6qNw.png"/></div></div></figure><h1 id="9dc0" class="nd ne it bd nf ng pc ni nj nk pd nm nn jz pe ka np kc pf kd nr kf pg kg nt nu bi translated">我们现在可以关注三种插补方法的性能。</h1><p id="47c4" class="pw-post-body-paragraph lk ll it lm b ln nv ju lp lq nw jx ls lt nx lv lw lx ny lz ma mb nz md me lj im bi translated">当引入 10%的异常值时，随机预测的性能下降了 8.8%。简单的、迭代的和 KNN 估算法使其在相同的 NaNs 比率下回到 1%以下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/22888126e00b1fb4b3c2f460fd1886fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SRQ6zWtXPDqZ8k_6XRcGnw.png"/></div></div></figure><p id="cf08" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">当涉及到梯度推进回归变量时，KNN 估算器获得“最低”性能，在性能下降中回到 1%。</p><p id="b43c" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">引入 10%的 NaNs 后，均值和迭代估算值带来了接近 0.3%的性能，这确实非常好！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pv"><img src="../Images/b08d52663e67a9d3888d2f2b877ee65f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pz9_UhxGaj45yAD4lbkdxg.png"/></div></div></figure><p id="73c2" class="pw-post-body-paragraph lk ll it lm b ln mf ju lp lq mg jx ls lt mh lv lw lx mi lz ma mb mj md me lj im bi translated">像往常一样，这只是评估异常值对机器学习算法的影响的一种方式，不同的用例和假设可能会有很大的不同。</p><div class="oj ok gp gr ol om"><a href="https://pl-bescond.medium.com/pierre-louis-besconds-articles-on-medium-f6632a6895ad" rel="noopener follow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">皮埃尔-路易·贝斯康德关于媒介的文章</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">数据科学、机器学习和创新</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">pl-bescond.medium.com</p></div></div><div class="ov l"><div class="pw l ox oy oz ov pa ks om"/></div></div></a></div></div></div>    
</body>
</html>