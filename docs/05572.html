<html>
<head>
<title>Using Logistic Regression to Create a Binary and Multiclass Classifier from Basics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用逻辑回归从基础创建二元和多类分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-logistic-regression-to-create-a-binary-and-multiclass-classifier-from-basics-26f5e1e92777?source=collection_archive---------14-----------------------#2020-05-10">https://towardsdatascience.com/using-logistic-regression-to-create-a-binary-and-multiclass-classifier-from-basics-26f5e1e92777?source=collection_archive---------14-----------------------#2020-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5913" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Python生成梯度下降优化的二元和多类分类器</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/60200899b16ea241907dee19c57c9770.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eu5uPRtzv0QfyaWUKM1myQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@jontyson?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">乔恩·泰森</a>在<a class="ae ky" href="https://unsplash.com/s/photos/choices?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="e737" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着数据科学和机器学习成为工业和学术研究中许多领域不可或缺的一部分，掌握这些技术的基本知识对于识别数据趋势非常有用，尤其是在数据集规模快速增长的情况下。有了实验科学的背景，线性回归看起来总是相当直观，因为我们经常将实验数据与理论模型进行拟合，以提取材料属性。然而，制作一个分类器(<em class="lv">即</em>根据之前的几个指标预测A队是否会击败B队)，在我做了一些阅读之前，我并没有使用过或者有太多的经验。在本文中，我希望简洁地描述如何使用逻辑回归从头开始创建一个分类器。在实践中，您可能会使用诸如<code class="fe lw lx ly lz b">scikit-learn</code>或<code class="fe lw lx ly lz b">tensorflow</code>之类的软件包来完成这项工作，但是理解一些底层的方程和算法对于了解“幕后”发生了什么非常有帮助。</p><p id="0f9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文中的大部分工作都受到了吴恩达教授的Coursera 上的机器学习课程的启发。</p><p id="2eb3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文中的所有代码我们都将使用Python，所以让我们导入我们将需要的所有包:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><h1 id="f537" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">我们如何进行离散预测？</strong></h1><p id="b4a9" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">做离散预测是我们一直在做的事情，可能甚至没有过多考虑如何做。例如，你正在餐馆看菜单——你阅读不同菜单项的描述，记住你最近阅读的食物评论中的一些提示，可能会问服务员几个问题，并对你想点什么做出谨慎的决定。如果你从未在这家餐馆吃过饭，你实际上是在根据你认为你会喜欢的东西做出明智的预测。</p><p id="ac85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了在我们的预测算法中实现类似的行为，一个很好的起点是选择一个数学函数，它本质上给出一个二进制输出或0或1。为此，我们可以使用<strong class="lb iu">逻辑</strong>或<strong class="lb iu"> sigmoid </strong>函数，其形式如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/e78df8c750e29f4fdc3cf8bb7cc9145b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g_5ysDHPmcQoNZ71byuUDQ.png"/></div></div></figure><p id="8453" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以用Python编写这个函数，并将其绘制如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/60ba26a0fcd4ba4af5c4e0f9693152e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sQbbjIdzqiL5pAPGoHbrNg.png"/></div></div></figure><p id="ce8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如图所示，在x = 0附近，sigmoid函数从接近0的输出快速变为接近1的输出。由于输出值关于y = 0.5是对称的，我们可以以此作为做出决策的阈值，其中y ≥ 0.5输出1，y &lt; 0.5 outputs 0.</p><p id="9d0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">To see this in action, let’s train some data!</p><h1 id="3809" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">产生数据</strong></h1><p id="b02e" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们的场景如下——我们正在构建一个简单的电影推荐系统，该系统考虑了0到5之间的平均用户评分(所有用户)和0到5之间的平均评论家评分。然后，我们的模型应该基于我们的输入数据生成一个决策边界，以预测当前用户是否会喜欢这部电影，并向他们推荐这部电影。</p><p id="7546" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将对100部电影进行随机用户和评论家评分:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="4b83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们生成分类—在这种情况下，要么用户喜欢这部电影(1)，要么不喜欢(0)。为此，我们将使用以下决策边界函数。我们将该等式的右侧设为0，因为它定义了逻辑函数何时等于0.5:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/9d0b43be2a68aa40a5f9a1f9d27b7089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xj05_5024hqnmH7RgvRwYw.png"/></div></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="bf37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，在真实的数据集中，您不知道决策边界的函数形式是什么。出于本教程的考虑，我们正在定义一个函数，并向它添加一些噪声，以便分类不是“完美的”。</p><p id="19e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以绘制初始数据，其中橙色圆圈代表用户喜欢的电影，蓝色圆圈代表不喜欢的电影:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/b42d2244744d1922cda039dd05719e20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*NjB3_2TLM3Ww0Ykwgdv9PA.png"/></div></figure><h1 id="c56f" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">决定决策边界的质量</strong></h1><p id="1d05" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">为了确定我们的决策边界有多好，我们需要为错误的预测定义一个惩罚，这将通过创建一个成本函数来实现。我们的预测如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/c5a94fe7bf51be5d5ca26166cd4a7b89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*puyyulb0HW32Al1JfqNBLw.png"/></div></div></figure><p id="b163" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当<em class="lv"> P </em> ≥ 0.5时，我们输出1，当<em class="lv"> P </em> &lt; 0.5时，我们将输出0，其中w₀、w₁和w₂是我们正在优化的权重。</p><p id="524d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了惩罚错误的分类，我们可以利用对数函数，因为log(1) = 0和log(0) → -∞。我们可以用它来创建如下两个罚函数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/5b41d1bf8fb6c8c7f8291154e5882fbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TLE-cszAgwNQd3DSxA7Fcg.png"/></div></div></figure><p id="ceb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以将它可视化，以便更清楚地看到这些罚函数的效果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/bb6d038b4255964235c8cde22a6a47ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*d5FmFxEl45ntahzNLsxcFQ.png"/></div></figure><p id="20ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">利用我们的<em class="lv">输出</em> ( <em class="lv"> y </em>)将为0或1的事实，我们可以在一个包含两种情况的表达式中优雅地组合这两个罚函数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/58ed713e90e53e232b7e1cdacd31216f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMT1IU5JY6OXLenUwRh7Dw.png"/></div></div></figure><p id="f544" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，当我们的输出为1，并且我们预测接近0(第一项)时，我们会招致一个陡峭的惩罚——类似地，当我们的输出为0并且我们预测接近1(第二项)时，也会发生相同的情况。</p><p id="cf62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以把我们的罚函数推广到<em class="lv"> m </em>个训练例子——第<em class="lv"> i个</em>训练例子的标签用(<em class="lv"> i </em>表示)。我们还将总成本除以<em class="lv"> m </em>得到平均惩罚(就像线性回归中的均方误差)。这个最终表达式也被称为<strong class="lb iu">成本函数</strong>。我们将我们的两个特征(用户评分和评论家评分)称为x₁和x₂.</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/e2e44c7b1d63e81b461424fc8421edb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lr9Q_zMUadBVQRMGrjwXXw.png"/></div></div></figure><h1 id="6e47" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">最小化成本</strong></h1><p id="5a42" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">为了找到最优决策边界，我们必须最小化这个成本函数，我们可以使用一种叫做<a class="ae ky" href="https://en.wikipedia.org/wiki/Gradient_descent" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">梯度下降</strong> </a>的算法来实现，这种算法本质上做两件事:(1)通过计算成本函数的梯度来找到最大下降的方向，(2)通过沿着这个梯度移动来更新权重值。为了更新权重，我们还提供了一个<a class="ae ky" href="https://en.wikipedia.org/wiki/Learning_rate" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">学习率</strong></a><strong class="lb iu">【α】</strong>，它决定了我们沿着这个梯度移动了多少。在选择学习率时有一个权衡——太小，我们的算法需要太长时间才能收敛；太大，我们的算法实际上会发散。关于梯度下降和学习率的更多信息可以在链接文章中找到。因此，对于每个权重，我们有以下更新规则:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/a87f7460f84c859fd6c37b7d7a4fec0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4kjJZZTjlLJPy8IL887KHg.png"/></div></div></figure><p id="22e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谜题的最后一块是计算上面表达式中的偏导数。我们可以使用微积分中的链式法则将它分解如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/55fff49826f7bd5f817df8cb097d7afb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*smXiCkC0TpDp-zOoBjrivA.png"/></div></div></figure><p id="1475" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以把它们放在一起得到下面的梯度表达式和梯度下降更新规则:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/d308a2d32ac88931c2d9c2dc008046b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I7bp8joNCBlr63a4Hwhi0Q.png"/></div></div></figure><p id="15b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以初始化我们的变量来最小化成本函数。</p><h1 id="2f4d" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">初始化变量</strong></h1><p id="f9e8" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">上面所有的梯度下降运算都有利于使用矩阵乘法和线性代数。首先，我们如下初始化变量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/a2961fc0574dbb6881b98da6d9c7d981.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IoJKY84MW738TXW6y9A4Ig.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/7b98c0281a7280039b8bdc21b1da0412.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z66Gjufe2UkkQtSqzKSk8Q.png"/></div></div></figure><p id="2772" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以如下重写用于权重的成本函数、梯度和更新函数的两个早期表达式，其中上标T表示矩阵的转置:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/b5c20199c9381c73ab5254100de1416f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ah4w8iLG6tzcyk2JQdnfxg.png"/></div></div></figure><p id="3040" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的变量可以初始化如下(我们将设置所有的权重等于0开始):</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="69ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然长长的数学之墙已经过去了，让我们来训练我们的分类器模型吧！</p><h1 id="5f8a" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">训练我们的模型</strong></h1><p id="7cf5" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们必须首先为成本函数和梯度下降更新定义函数。以下函数计算成本和梯度值，并返回两者:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="6878" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当定义梯度下降函数时，我们必须添加一个名为<code class="fe lw lx ly lz b">num_iters</code>的额外输入，它告诉算法在返回最终优化权重之前要进行的迭代次数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="ee53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，在做了所有这些艰苦的工作之后，下面的线训练我们的模型！</p><pre class="kj kk kl km gt nm lz nn no aw np bi"><span id="eca8" class="nq md it lz b gy nr ns l nt nu">J, w_train = gradient_descent(X, y, w, 0.5, 2000)</span></pre><p id="e55f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在真实的情况下，我们会拆分我们的训练数据，以便交叉验证和测试我们的模型，但是出于本教程的目的，我们将使用所有的训练数据。</p><p id="0380" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了确保我们在每次迭代中降低成本函数的值，我们可以绘制如下图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/038a65b55d384c58e872cb7ccdd18ca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*4A5dEozCI08hCZgpYTSMBg.png"/></div></figure><p id="f5e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在是关键时刻——我们可以画出我们的决策界限。我们将在原始图上覆盖它的方法是定义一个点网格，然后使用我们训练的权重计算sigmoid函数的预测值。然后我们可以画出预测值等于0.5的等高线。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="c910" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Et，瞧！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/a4025069ae5313db0e0e2b67d353479b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*boc8dH53WnQ9jnEThcGXkA.png"/></div></figure><p id="83e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以编写一个函数，根据这个训练好的模型进行预测:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="6b13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们对新的例子做一些预测:</p><pre class="kj kk kl km gt nm lz nn no aw np bi"><span id="94db" class="nq md it lz b gy nr ns l nt nu">X_new = np.asarray([[1, 3.4, 4.1], [1, 2.5, 1.7], [1, 4.8, 2.3]])<br/>print(predict(X_new, w_train))</span><span id="9143" class="nq md it lz b gy nx ns l nt nu">&gt;&gt;&gt; [[1.]  <br/>     [0.]  <br/>     [1.]]</span></pre><h1 id="8cc1" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">多类分类</strong></h1><p id="f0c8" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在我们已经完成了制作二元分类器的所有艰苦工作，将它扩展到更多的类是相当简单的。我们将使用一种称为<a class="ae ky" href="https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">一对一分类</strong> </a>的策略，其中我们为每个不同的类训练一个二元分类器，并选择具有sigmoid函数返回的最大值的类。</p><p id="094c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们以二进制示例中的模型为基础，这一次用户可以给一部电影打0星、1星或2星的分数，我们试图根据用户和评论家的分数来确定决策界限。</p><p id="edfb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们再次生成数据，并应用两个决策界限:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="d858" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的数据集如下所示，其中<strong class="lb iu">蓝色圆圈代表0星，橙色圆圈代表1星，红色圆圈代表2星</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/04a5208a82acb98def2d112f51e4ab4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*x9gxWWjzdw7iQFxKG6FKKg.png"/></div></figure><p id="dfd9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于我们训练的每个二元分类器，我们需要重新标记数据，以便我们感兴趣的类的输出设置为1，所有其他标签设置为0。例如，如果我们有3组A (0)、B (1)和C (2)，我们必须制作三个二元分类器:</p><p id="5faa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(1) A设置为1，B和C设置为0</p><p id="be4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(2) B设置为1，A和C设置为0</p><p id="e06a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(3) C设置为1，A和B设置为0</p><p id="126c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有一个为每个分类器重新标记数据的函数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="cd75" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们进行与前面的二进制分类部分相同的模型训练，但是分三次进行:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="4a41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一次绘制决策界限稍微复杂一些。我们必须为每个经过训练的分类器计算网格<em class="lv">中每个点的预测值。然后，我们选择每个点的最大预测值，并根据哪个分类器产生了该最大值来分配其各自的类别。我们选择绘制的等高线是0.5(0到1之间)和1.5(1到2之间):</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="b9ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过大量的预期，这里是我们训练有素的决策界限！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/a11afaa8b3182cd92881bae7116b1d39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*Z2vfZdTGBteSEHuj6-CfUw.png"/></div></figure><p id="4b43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们来做一个预测函数。为此，我们将使用一个小技巧——我们将对每个示例中的每个分类器进行预测。然后，我们将把每组预测作为一个新列追加到预测矩阵中。然后，通过沿着每一行选择具有最大值的列索引，我们自动得到分类器标签！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ma mb l"/></div></figure><pre class="kj kk kl km gt nm lz nn no aw np bi"><span id="b0ae" class="nq md it lz b gy nr ns l nt nu">X_new = np.array([[1, 1, 1], [1, 1, 4.2], [1, 4.5, 2.5]])<br/>print(predict_multi(X_new, [w_class1, w_class2, w_class3]))</span><span id="eb1a" class="nq md it lz b gy nx ns l nt nu">&gt;&gt;&gt; [[0]  <br/>     [2]  <br/>     [1]]</span></pre><p id="cfc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在那里！一个完全从零开始的多类分类器！</p><h1 id="9fe7" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">结束语</strong></h1><p id="7e79" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">感谢阅读！这篇文章只是触及了逻辑回归和分类的表面，但是我希望你喜欢它。展示的例子可以在<a class="ae ky" href="https://github.com/venkatesannaveen/machine-learning-basics" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我再次感谢吴恩达在Coursera上教授的机器学习课程给了我这篇文章很多灵感。</p></div></div>    
</body>
</html>