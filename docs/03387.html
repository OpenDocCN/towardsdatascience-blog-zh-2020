<html>
<head>
<title>Tensorflow Serving with Docker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow与Docker一起使用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-serving-with-docker-9b9d87f89f71?source=collection_archive---------9-----------------------#2020-03-31">https://towardsdatascience.com/tensorflow-serving-with-docker-9b9d87f89f71?source=collection_archive---------9-----------------------#2020-03-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ac2f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">张量流框架</h2><div class=""/><div class=""><h2 id="0a21" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">如何将ML模型部署到生产中？</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/76a323af8b3e4d999c8d859f82e43d96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9wp3MrsvJgePxnAn"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">约瑟夫·巴里恩托斯在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="e300" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文将指导您如何构建和训练一个简单的CNN模型，然后使用这个训练好的模型作为Tensorflow服务的端点。无论您是业余爱好者、ML工程师、数据科学家还是DevOps人员，我相信在本文结束时您将能够部署ML模型。</p><h1 id="a13d" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">Tensorflow服务的背景</h1><p id="736d" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">Tensorflow Serving是谷歌为生产机器学习系统设计的API，谷歌和许多大型科技公司广泛使用这种API。它使得用相同的服务器架构和API部署您的模型变得容易。它最适用于张量流模型，但我猜它也可以扩展到其他类型的模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nb"><img src="../Images/1b51de75386927015f44c9d79c618094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6komp3M-E_JpMQTE"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片取自<a class="ae lh" href="https://static.packt-cdn.com/products/9781789139495/graphics/d5853eb7-9d7e-465d-aad2-a69916761ecb.png" rel="noopener ugc nofollow" target="_blank"> Packt </a></p></figure><p id="4b84" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上图简要展示了从构建模型到使用Tensorflow服务将模型提供给端点的整个过程。为大多数类型的模型提供服务的最佳选择可能是在服务器上运行集中式模型，任何类型的设备(可能是桌面设备、移动设备或嵌入式设备)都可以从该服务器进行请求。然后服务器会为你做推理并返回预测。根据该预测，您可以将其呈现给任何设备。这种架构的一个很大的优点是，假设您有几个客户端访问集中在一个服务器上的端点。每个人都可以访问相同的模型版本，并可以无缝地享受更新的版本，而且通过添加负载平衡器，针对大量请求的扩展变得很容易。如果您将模型部署在每台客户机上，这将变得很困难，因此管理版本和发布新的更新变得很有挑战性。</p><blockquote class="nc nd ne"><p id="7c2b" class="li lj nf lk b ll lm kd ln lo lp kg lq ng ls lt lu nh lw lx ly ni ma mb mc md im bi translated">现在让我们进入<strong class="lk jd">工作模式</strong>。</p></blockquote><p id="5b22" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将训练一个神经网络模型来对服装上的图像进行分类(即mnist时尚数据集)，保存训练好的基于TensorFlow的模型，并用Tensorflow服务它。虽然，更多的焦点将集中在服务模型部分。</p><p id="92bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="nf">您将在下面的Git资源库中找到所有代码。</em><a class="ae lh" href="https://github.com/vjgpt/Tensorflow-Series/tree/master/tensorflow-serving" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd"><em class="nf">Star this repository</em></strong></a><strong class="lk jd"><em class="nf">关注我在Medium，</em> </strong> <em class="nf">我将在未来几周发布更多关于Tensorflow算法、ML模型管道的更新，以及与AWS和Azure等云服务集成的示例。</em></p><blockquote class="nj"><p id="3865" class="nk nl it bd nm nn no np nq nr ns md dk translated">如果你在Google Collab中运行这些代码，那就很容易了。</p></blockquote><div class="nt nu nv nw nx ny"><a href="https://github.com/vjgpt/Tensorflow-Series/tree/master/tensorflow-serving" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd jd gy z fp od fr fs oe fu fw jc bi translated">VJ GPT/tensor flow-系列</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">github.com</p></div></div><div class="oh l"><div class="oi l oj ok ol oh om lb ny"/></div></div></a></div><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="9fb6" class="os mf it oo b gy ot ou l ov ow">import sys<br/># Confirm that we're using Python 3<br/>assert sys.version_info.major is 3, 'Oops, not running Python 3.'</span><span id="5ee8" class="os mf it oo b gy ox ou l ov ow">import tensorflow as tf<br/>from tensorflow import keras<br/>import numpy as np<br/>import os<br/>import subprocess</span></pre><p id="ffd6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在将数据输入模型之前对数据进行预处理。</p><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="aaa6" class="os mf it oo b gy ot ou l ov ow"># Model Version<br/>VERSION = '00000123'<br/></span><span id="674e" class="os mf it oo b gy ox ou l ov ow">fashion_mnist = keras.datasets.fashion_mnist<br/>(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()</span><span id="5d3c" class="os mf it oo b gy ox ou l ov ow"># scale the values to 0.0 to 1.0<br/>train_images = train_images / 255.0<br/>test_images = test_images / 255.0</span><span id="bbaa" class="os mf it oo b gy ox ou l ov ow"># reshape for feeding into the model<br/>train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)<br/>test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)</span><span id="bdff" class="os mf it oo b gy ox ou l ov ow"><br/>print('\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))<br/>print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))</span></pre><p id="6d29" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">基于时尚MNIST数据构建和训练CNN模型</p><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="48be" class="os mf it oo b gy ot ou l ov ow">model = keras.Sequential([<br/>keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3,<br/>strides=2, activation='relu', name='Conv1'),<br/>keras.layers.Flatten(),<br/>keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')<br/>])<br/>model.summary()</span><span id="f524" class="os mf it oo b gy ox ou l ov ow">epochs = 15</span><span id="0652" class="os mf it oo b gy ox ou l ov ow">model.compile(optimizer='adam',<br/>loss='sparse_categorical_crossentropy',<br/>metrics=['accuracy'])<br/>model.fit(train_images, train_labels, epochs=epochs)<br/></span><span id="1e6b" class="os mf it oo b gy ox ou l ov ow">test_loss, test_acc = model.evaluate(test_images, test_labels)<br/>print('\nTest accuracy: {}'.format(test_acc))</span></pre><p id="0344" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以TensorFlow protobuf格式保存训练好的模型。</p><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="0b0c" class="os mf it oo b gy ot ou l ov ow">saved_model_path = model.save(f"./tmp/{VERSION}", save_format='tf')</span></pre><h2 id="fd1f" class="os mf it bd mg oy oz dn mk pa pb dp mo lr pc pd mq lv pe pf ms lz pg ph mu iz bi translated">使用SavedModel CLI检查模型</h2><p id="ea35" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">SavedModel CLI帮助您检查您的模型并检查模型的<code class="fe pi pj pk oo b">SignatureDef's</code>。它为您提供了模型训练所依据的输入张量数据类型和形状的详细信息。因此，您必须以相同的格式向模型提供输入，并获得由<code class="fe pi pj pk oo b">SignatureDef's</code>定义的输出。</p><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="49c9" class="os mf it oo b gy ot ou l ov ow">import subprocess</span><span id="44ab" class="os mf it oo b gy ox ou l ov ow">subprocess.run([f"saved_model_cli show --dir ./tmp/{VERSION}/ --all"],shell=True)</span><span id="b82f" class="os mf it oo b gy ox ou l ov ow"># Zipping the model as model.tar.gz<br/>subprocess.run([f"tar cvfz model.tar.gz tmp/{VERSION}/"],shell=True)</span></pre><p id="4f52" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将在本地机器上提供模型，所以我们需要压缩的模型文件和JSON文件，它们将被输入到模型中。<br/>下载压缩的模型文件，这样您就可以在本地机器上部署它(假设您已经在Google Collab中运行了全部代码)。</p><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="d21b" class="os mf it oo b gy ot ou l ov ow">from google.colab import files</span><span id="3094" class="os mf it oo b gy ox ou l ov ow">files.download('model.tar.gz')</span></pre><p id="f682" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">创建一个JSON文件，该文件将包含模型所需的输入<code class="fe pi pj pk oo b">SignatureDef's</code>，然后将被传递到模型端点。</p><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="328f" class="os mf it oo b gy ot ou l ov ow">import json</span><span id="fc17" class="os mf it oo b gy ox ou l ov ow"># Wrap bitstring in JSON<br/>data = json.dumps({"signature_name": "serving_default", "instances": test_images[0:3].tolist()})</span><span id="12de" class="os mf it oo b gy ox ou l ov ow">json_file = open('predict.json', 'w')<br/>json_file.write(data)<br/>json_file.close()</span><span id="0e71" class="os mf it oo b gy ox ou l ov ow">files.download('predict.json')</span></pre><h1 id="67ed" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">设置Docker环境</h1><p id="0016" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">从官方网站<a class="ae lh" href="https://docs.docker.com/install/" rel="noopener ugc nofollow" target="_blank">安装Docker</a>。</p><p id="be0e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下载的快速链接:</p><ul class=""><li id="e26c" class="pl pm it lk b ll lm lo lp lr pn lv po lz pp md pq pr ps pt bi translated">macOS的Docker</li><li id="9547" class="pl pm it lk b ll pu lo pv lr pw lv px lz py md pq pr ps pt bi translated"><a class="ae lh" href="https://docs.docker.com/docker-for-windows/install/" rel="noopener ugc nofollow" target="_blank">适用于Windows 10 Pro或更高版本的Docker</a></li></ul><p id="7c8d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们从最新的Tensorflow服务图像开始</p><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="0bd6" class="os mf it oo b gy ot ou l ov ow">docker pull tensorflow/serving</span></pre><p id="8b54" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用部署在REST API端点上的模型运行服务映像。</p><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="e652" class="os mf it oo b gy ot ou l ov ow">docker run -p 8501:8501 --mount type=bind,source=/path/to/the/unzipped/model/tmp/,target=/models/fashion_mnist -e MODEL_NAME=fashion_mnist -t tensorflow/serving</span></pre><p id="b414" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，您的docker容器正在运行Tensorflow服务模型服务器，绑定REST API端口8501，并将模型从我们的主机映射到容器中预期的位置。还传递了一个环境变量，这对查询我们的模型很重要。</p><p id="c3ee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以使用预测API查询模型</p><pre class="ks kt ku kv gt on oo op oq aw or bi"><span id="283c" class="os mf it oo b gy ot ou l ov ow">curl -d ‘{"signature_name": "serving_default", "instances": [[[[0.0], [0.0]…………….[0.0]]]]}’ -X POST http://localhost:8501/v1/models/fashion_mnist:predict</span></pre><p id="feb4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">或者您可以在本地机器上运行下面的脚本来获得预测</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pz qa l"/></div></figure><p id="a111" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">太棒了，现在您的模型不会在您的本地系统中丢失，但是您可以将您的模型部署到生产中，以便人们可以使用它。</p><p id="72cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您已经使用本地系统中的Tensorflow服务成功创建了一个端点。我将会发布更多的博客来运行相同的和其他几种类型的云服务模式。</p><p id="d48a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果这对你有帮助，就发微博，让人们部署他们的模型，因为这有点复杂，是机器学习生命周期的关键部分。</p><p id="f618" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://github.com/vjgpt/Tensorflow-Series/tree/master/tensorflow-serving" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd"><em class="nf">Star this repository</em></strong></a><strong class="lk jd"><em class="nf">关注我的Medium，</em> </strong> <em class="nf">我将在未来几周发布更多关于Tensorflow算法、ML模型管道的更新，以及与AWS和Azure等云服务集成的示例。</em></p><div class="qb qc gp gr qd ny"><a href="https://github.com/vjgpt" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd jd gy z fp od fr fs oe fu fw jc bi translated">vjgpt -概述</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">在GitHub上注册你自己的个人资料，这是托管代码、管理项目和构建软件的最佳地方…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">github.com</p></div></div><div class="oh l"><div class="qe l oj ok ol oh om lb ny"/></div></div></a></div><div class="qb qc gp gr qd ny"><a href="https://twitter.com/vj_guptaaa" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd jd gy z fp od fr fs oe fu fw jc bi translated">维杰·古普塔</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">Vijay Gupta的最新推文(@vj_guptaaa)。机器学习运营工程师。我主要谈论#技术…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">twitter.com</p></div></div><div class="oh l"><div class="qf l oj ok ol oh om lb ny"/></div></div></a></div><blockquote class="nj"><p id="196a" class="nk nl it bd nm nn qg qh qi qj qk md dk translated">参考</p></blockquote><p id="a1f0" class="pw-post-body-paragraph li lj it lk b ll ql kd ln lo qm kg lq lr qn lt lu lv qo lx ly lz qp mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/guide/keras/save_and_serialize" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/guide/keras/save_and_serialize</a></p><p id="a7f5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/tutorials/distribute/save_and_load" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/tutorials/distribute/save _ and _ load</a></p><p id="406a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker/" rel="noopener ugc nofollow" target="_blank">https://AWS . Amazon . com/blogs/machine-learning/deploy-trained-keras-or-tensor flow-models-using-Amazon-sage maker/</a></p><p id="7544" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/tfx/serving/api_rest" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tfx/serving/api_rest</a></p><p id="5177" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://stackoverflow.com/questions/40427435/extract-images-from-idx3-ubyte-file-or-gzip-via-python" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/40427435/extract-images-from-idx 3-ubyte-file-or-gzip-via-python</a></p><p id="7f96" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank">https://github.com/zalandoresearch/fashion-mnist</a></p></div></div>    
</body>
</html>