<html>
<head>
<title>CNN Image Classification: Cat or Dog</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN 图像分类:猫还是狗</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cnn-classification-a-cat-or-a-dog-568e6a135602?source=collection_archive---------17-----------------------#2020-04-06">https://towardsdatascience.com/cnn-classification-a-cat-or-a-dog-568e6a135602?source=collection_archive---------17-----------------------#2020-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2f75" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于 Keras 的卷积神经网络在图像分类中的应用</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/56924862be6c1bd8e54fc36b4b2f37a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*MBSM_G12XN105sEHsJ6C3A.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Img 改编自 pixabay 通过<a class="ae ku" href="https://pixabay.com/photos/pets-cute-cat-dog-3715734/" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="0532" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在本文中，我将一步一步地介绍如何创建一个基于卷积神经网络(CNN)的图像分类模型。它分为 7 个部分。</p><ol class=""><li id="4a49" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">问题陈述</li><li id="d59f" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">数据概述</li><li id="7f82" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型结构</li><li id="ac92" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型编译</li><li id="7a9a" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型拟合</li><li id="b614" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型改进</li><li id="0b79" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">示例预测</li></ol><p id="d87f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们开始旅程吧🏃‍♂️🏃‍♀️.</p><p id="5d04" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 1。问题陈述</strong></p><p id="64a4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们得到了一组狗和猫的图片。任务是建立一个模型来预测一种动物的类别:狗还是猫？</p><p id="54f3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 2。数据概述</strong></p><p id="b00b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们收集的数据是 Kaggle 狗/猫数据集的子集(<a class="ae ku" href="https://www.kaggle.com/c/dogs-vs-cats/overview" rel="noopener ugc nofollow" target="_blank">链接</a>)。总共有 10，000 幅图像，80%用于训练集，20%用于测试集。在训练集中，有 4000 张狗的图像，而测试集有 1000 张狗的图像，剩下的都是猫。</p><p id="5071" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">所有图片都保存在专门的文件夹结构中，便于<strong class="kx iu"> <em class="mf"> Keras </em> </strong>理解和区分每张图片的动物类别，如图 1 所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/8669a2599cda58f9a13911e7398a8d18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*BxjbkrSS2dQ2Go3i2dHVsQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 1.1 创建培训/测试文件夹</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mh"><img src="../Images/21de58dfd6fb413551933f26ba163051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K0mBWuxktAjsLzAZriDr9Q.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 1.2 分别在训练/测试文件夹中创建狗/猫文件夹</p></figure><p id="f407" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">不需要对变量进行编码，因为独立变量是像素值。</p><p id="052e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 3。模型构建</strong></p><p id="9c48" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">一般来说，构建 CNN 需要 4 个步骤:卷积、最大池化、扁平化和全连接。让我们详细了解一下每一个。</strong></p><p id="bf2c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.1 卷积</p><p id="9762" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">从概念上讲，卷积是在输入图像上应用特征检测器。为了简化概念，取一张笑脸作为输入图像，在图 2 中表示为 0 和 1 的数组。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/78d5a9ee0c28aa05832f869f7a58a961.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*O72vfrb7_BC4UY7psh3yiQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 2 Simile face——输入图像(作者创建的 Img)</p></figure><p id="19c0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">特征检测器也是一个数字数组。对于每个特征检测器，我们在图像上滑动它，产生一个新的数字数组，代表图像的一个特征。<strong class="kx iu">因此，输入图像和产生特征图的特征检测器之间的操作是卷积</strong>，如下图 3 所示</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/0b0b80896edc77c93cfbd30c123fff04.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*xGk_3VdO-iMunW4LwNlsGw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 3 卷积图(作者创建的 Img)</p></figure><p id="f67b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果用不同的特征检测器重复上述卷积，我们产生与特征检测器一样多的特征图，获得卷积层。</p><p id="991f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">具体来说，我们使用<strong class="kx iu"><em class="mf">【Conv2D()</em></strong><em class="mf"/>函数从<strong class="kx iu"> <em class="mf"> Keras </em> </strong>构建第一个卷积层。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="29d7" class="mt mu it mp b gy mv mw l mx my">classifier = Sequential()<br/>classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))</span></pre><p id="ec63" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意，<em class="mf"/>特征检测器的数量设置为 32，其维数为(3，3)。在大多数 CNN 架构中，通常的做法是从 32 个特征检测器开始，如果需要，增加到 64 或 128 个。</p><p id="bd3f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="mf"> input_shape </em>是我们通过卷积对其应用特征检测器的输入图像的形状。问题是图像可能有不同的格式和图像大小。所以，我们需要将图像转换成相同的格式和固定的大小。我们稍后将处理图像，现在让我们设置它为<em class="mf"> (64，64，3)。</em>这里，3 是彩色图像的通道数，(64，64)是每个通道的图像维数，这足以获得良好的精度。如果你在一个像样的 GPU 上工作，请随意尝试(128，128)。</p><p id="a2d3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后一个参数是激活函数。我们使用<strong class="kx iu"> <em class="mf"> ReLU </em> </strong>去除特征图中的任何负像素值。这是因为根据卷积中使用的参数，我们可能会在特征图中获得负像素。移除负像素增加了非线性分类问题的非线性。</p><p id="8c3f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.2 最大池化</p><p id="49a3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最大池化是通过滑动表格，例如(2，2)，并取表格中的最大值，来减小特征图的大小。如果我们在(5，5)的 1 个特征映射上滑动一个跨度为 2 的表，我们会得到一个大小为(3，3)的特征映射，如图 5 所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/74f76cd05d1c33842b1e86ea62b8b33b.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*LJAHuOd-vZ1F6SqsAFaHaQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 5 最大汇集图(作者创建的 Img)</p></figure><p id="0203" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在每个要素地图上重复最大池化会产生一个池化图层。从根本上说，max pooling 是为了减少完全连接的图层中的节点数量，而不会丢失图像中的关键特征和空间结构信息。具体来说，我们使用<strong class="kx iu"><em class="mf">MaxPooling2D()</em></strong><em class="mf"/>函数来添加池层。一般来说，我们使用 2x2 过滤器进行合并。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="47b4" class="mt mu it mp b gy mv mw l mx my">classifier.add(MaxPooling2D(pool_size = (2, 2)))</span></pre><p id="5949" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.3 扁平化</p><p id="7bf4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如图 7 所示，展平是将所有汇集的特征地图作为完全连接的图层的输入，放入单个矢量中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/4ee0a90d30c9ad4498d763fde7936fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*TxZr1uSklFQs-xkMWdNz7A.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 7 展平图(作者创建的 Img)</p></figure><p id="a15e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在<strong class="kx iu">问题</strong> : <em class="mf">为什么不直接将输入图像展平成单一矢量</em>🤔？答案是这样做只会保留图像的像素值，而不会保留空间结构。换句话说，它将丢失每个像素与其周围像素的空间连接方式。但是用卷积，我们得到很多特征图，每个特征图代表图像的一个特定特征。因此，展平向量中的每个节点将表示输入图像的特定细节。</p><p id="445c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">具体来说，</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="d613" class="mt mu it mp b gy mv mw l mx my">classifier.add(Flatten())</span></pre><p id="2ddd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.4 完全连接</p><p id="1e00" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">通过以上操作，我们将图像转换为一维向量。现在我们将使用这个向量作为输入层来构建一个分类器。首先，创建一个隐藏层。<em class="mf"> output_dim </em>是隐藏层的节点数。作为惯例，我们选择 128 开始，并使用<em class="mf"> ReLU </em>作为激活函数。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="8fd9" class="mt mu it mp b gy mv mw l mx my">classifier.add(Dense(output_dim = 128, activation = ‘relu’))</span></pre><p id="f32d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">然后添加一个输出层。对于二元分类，<em class="mf"> output_dim </em>为 1，激活函数为<em class="mf"> Sigmoid </em>。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="db5b" class="mt mu it mp b gy mv mw l mx my">classifier.add(Dense(output_dim =1, activation = ‘sigmoid’))</span></pre><p id="a204" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们最终的模型结构如下所示🎉🎉。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nb"><img src="../Images/833e3f03e8a718a800a94b78473cf217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*gxI8Q41WiPbZcGoQHAmZUg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 8 CNN 架构(作者创建的 Img)</p></figure><p id="6c19" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 4。模型编译</strong></p><p id="d39c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">添加完所有层后，让我们通过选择一个<em class="mf"> SGD </em>算法、一个损失函数和性能指标来编译 CNN。我们使用<em class="mf">二元交叉熵</em>进行二元分类，使用<em class="mf">分类交叉熵</em>进行多重分类问题。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="33b8" class="mt mu it mp b gy mv mw l mx my">classifier.compile(optimizer = ‘adam’, loss = ‘binary_crossentropy’, metrics =’accuracy’)</span></pre><p id="a625" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 5。</strong> <strong class="kx iu">模型拟合</strong></p><p id="32b3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这里我们有 8000 幅图像用于训练集，这不足以避免过度拟合。因此，我们执行图像增强，如旋转、翻转或剪切，以增加图像的数量。它将训练图像分成几批，每批将对随机选择的图像应用随机图像变换，以创建更多不同的图像。</p><p id="d425" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">具体来说，我们将使用来自<a class="ae ku" href="https://keras.io/preprocessing/image/" rel="noopener ugc nofollow" target="_blank"> Keras 官网</a>的<strong class="kx iu"> <em class="mf"> flow_from_directory(目录)</em> </strong>方法加载图片并应用增强。这就是我们以特定方式构建数据文件夹的原因，这样就可以根据文件夹名称来识别每个图像的类别。下面的代码片段允许我们放大图像，并适合和测试 CNN。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="88ba" class="mt mu it mp b gy mv mw l mx my">train_datagen = ImageDataGenerator(rescale=1./255, <br/>     shear_range=0.2, zoom_range=0.2, horizontal_flip=True)</span><span id="cbf4" class="mt mu it mp b gy nc mw l mx my">test_datagen = ImageDataGenerator(rescale=1./255)</span><span id="24f0" class="mt mu it mp b gy nc mw l mx my">train_set = train_datagen.flow_from_directory(‘dataset/training_set’, target_size=(64, 64), batch_size=32, class_mode=’binary’)</span><span id="59ad" class="mt mu it mp b gy nc mw l mx my">test_set = <br/>test_datagen.flow_from_directory(‘dataset/test_set’, target_size=(64, 64), batch_size=32, class_mode=’binary’)</span><span id="8353" class="mt mu it mp b gy nc mw l mx my">classifier.fit_generator(train_set, steps_per_epoch=8000/32, epochs=25, validation_data=test_set, validation_steps=2000/32)</span></pre><p id="a5cd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">上面，目标尺寸设置为(64，64)，与我们创建卷积层时的形状相同。现在，让我们来拟合和测试模型。</p><p id="c7b5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最终，我们获得了 86% 的训练精度和 76% 的测试精度，✨✨.有轻微的过拟合</p><p id="b5a5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">6。型号改进</p><p id="1d10" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">显然，还有提高精度和减少过拟合的空间。<strong class="kx iu">有两种选择，要么增加更多的卷积层，要么增加更多的密集层</strong>。我们再加一个卷积层。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="7edf" class="mt mu it mp b gy mv mw l mx my">classifier.add(Conv2D(32, 3, 3, activation = ‘relu’))<br/>classifier.add(MaxPooling2D(pool_size = (2, 2)))</span></pre><p id="e446" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">根据上面的内容，再次在训练集和测试集上运行模型。最终，我们获得了提高后的测试精度<strong class="kx iu"> 91% </strong>和测试精度<strong class="kx iu"> 82% 🧨🧨 </strong>！</p><p id="7f26" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">7.<strong class="kx iu">示例预测</strong></p><p id="cc91" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">首先，我们为要预测的图像创建一个文件夹'<em class="mf"> single_prediction </em>，如图 9 所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/8e2ca40202027a395a4d4f3cd3e9e5a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*EFX4Um49VyBjgBru3vAenQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 9 待预测图像</p></figure><p id="1762" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">其次，我们使用<strong class="kx iu"><em class="mf"/></strong>中的<em class="mf">图像</em>模块来加载测试图像。注意，将图像的 target_size 设置为(64，64)。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="ee7b" class="mt mu it mp b gy mv mw l mx my">import numpy as np<br/>from keras.preprocessing import image</span><span id="caf5" class="mt mu it mp b gy nc mw l mx my">test_image = image.load_img(‘dataset/single_prediction/cat_or_dog_1.jpg’, target_size = (64, 64))</span></pre><p id="c015" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">记住 CNN 需要一个三维的输入图像。因此，我们需要为通道添加一个维度，从 2D 阵列到 3D 阵列。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="d0fe" class="mt mu it mp b gy mv mw l mx my">test_image = image.img_to_array(test_image)</span></pre><p id="c703" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">然而，这还不够，因为 CNN 期望第<strong class="kx iu">批</strong>有另一个维度。Axis 用于指定我们正在添加的维度的位置。因此在索引 0 处添加了批次维度。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="a00c" class="mt mu it mp b gy mv mw l mx my">test_image = np.expand_dims(test_image, axis = 0)</span></pre><p id="a8f2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">太好了，该预测了。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="f5d5" class="mt mu it mp b gy mv mw l mx my">result = classifier.predict(test_image)</span></pre><p id="200b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们得到的结果是 1。要了解动物及其相关数值之间的映射，我们使用:</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="041b" class="mt mu it mp b gy mv mw l mx my">training_set.class_indices</span></pre><p id="b25f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这样，我们知道 0 是猫，1 是狗。太好了。我们 CNN 做了一个正确的预测！</p><p id="7549" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">太好了！如果你觉得这篇文章有帮助，请随意点击👏s！如果需要源代码，请访问我的</strong> <a class="ae ku" href="https://github.com/luke4u/CNN-Image-Classification" rel="noopener ugc nofollow" target="_blank"> <strong class="kx iu"> Github </strong> </a> <strong class="kx iu">页面🤞🤞。</strong></p></div></div>    
</body>
</html>