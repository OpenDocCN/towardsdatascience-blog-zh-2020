<html>
<head>
<title>How you can prevent systemic racism in your own small way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你如何用自己的小方法防止系统性的种族歧视</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-you-can-prevent-systemic-racism-in-your-own-small-way-fc33cb57fdde?source=collection_archive---------67-----------------------#2020-07-29">https://towardsdatascience.com/how-you-can-prevent-systemic-racism-in-your-own-small-way-fc33cb57fdde?source=collection_archive---------67-----------------------#2020-07-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c891" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这里有两种方法可以解决技术和数据科学中的偏见</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/89dfc44c7d48830a77d886fba38a8ce8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dGxL8kAMIJBEaLEsPsHfzQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·斯皮斯克在<a class="ae ky" href="https://unsplash.com/s/photos/racism?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c2a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无论是在新闻、社交媒体还是在美国街头，系统性种族主义都是一个激烈辩论的话题。在这篇文章中，我不打算就历史上的种族紧张关系教育任何人。和其他人一样，我对什么可行什么不可行有自己的看法。我将试图传达的是，无论你的立场是什么，你都可以在没有意识到的情况下强化偏见行为，即使你像它们一样“清醒”。</p><p id="3cf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特别是如果你为别人而不是自己工作，你必须把你的技术和数据科学项目当作偏见是真实存在的。如果你选择看向别处，你可能会向这个世界释放一种伤害他人的产品。你可能甚至没有意识到它正在发生，直到一些惊人的事情发生。到那时，已经太晚了。你损害了你的个人和职业声誉。你的医疗、金融或欺诈预测可能已经伤害了个人。在未来的几年里，你可能会感到后悔和自责。</p><p id="1a3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">学习如何避免最坏的情况需要了解一些背景知识。</p><h2 id="6643" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">我们的大脑有偏见是有原因的。</h2><p id="2bf2" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我有偏见，因为我是人。人类每天都在整理和处理大量的信息。我们的大脑迅速将输入导入桶中。如果我们试图深入思考每一条信息，我们就会瘫痪。我们的大脑善于走捷径。</p><p id="594e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些传入的信息中的一些可能落在错误的桶中。它与我们的思想和行为混杂在一起，导致了隐含的偏见。我们可能没有意识到我们对人、事物或活动有偏好或反感。</p><p id="4cf4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，如果我们没有意识到我们的隐性偏见，我们如何防止它们泄露到我们的数据、代码和算法中呢？不幸的是，没有消除偏见的魔法棒。自我意识是良好的第一步。哈佛大学正在进行一项有趣的研究。Project Implicit 对这一领域进行了研究，有一些在线“测试”会报告你的回答中可能存在的偏见。</p><div class="mt mu gp gr mv mw"><a href="https://implicit.harvard.edu/implicit/index.jsp" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd iu gy z fp nb fr fs nc fu fw is bi translated">项目隐含</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">登录或注册，找出你对种族、性别、性取向和其他话题的隐含联想！或者…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">implicit.harvard.edu</p></div></div></div></a></div><p id="4884" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了新的经历和自我反省，你就可以把放错地方的信息移到你想要的桶里。想象下一次当你使用一个有问题的短语时，有人会叫你出来。在脱口而出道歉的时候，你的大脑疯狂地搜索这句话，并把它放进“坏”桶。</p><p id="dce7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这需要努力，也需要时间。</p><h2 id="09ae" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">假设存在数据偏差</h2><p id="0709" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如果我们不能用弹指一挥间消除大脑中的偏见，我们将不得不假设偏见确实存在并影响着我们。它影响着我们周围的每一个人。</p><p id="2591" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我给你的第一个建议是假设历史数据有直接或间接的偏差。问问你自己，历史数据代表你的目标人群吗？</p><p id="8146" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">直接数据偏差的一个例子——过去没有女性获得超过 10 万美元的贷款。如果你根据这些历史数据训练一个模型，你可以很确定你的模型的结果会有偏差。</p><p id="e5f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不太明显的是间接数据偏差。训练数据仅基于对 iPhone 11s 的调查，可能会扭曲你的富裕指标。另一个例子是，当西班牙语版本的调查不可用时，将这个模型推广到说西班牙语的人群。</p><h2 id="c8ec" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">审核您的预测结果</h2><p id="3d96" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">假设你的数据看起来不错，你相信你有一个代表性的样本。即使它不包含任何人口统计信息，机器学习模型的结果仍然可能有偏差。根据你的预测，如果一群人比另一群人受益更多，你需要考虑偏见。如果根据你的预测，一群人一直被排除在外，你需要考虑偏见。</p><p id="40b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检查这一点的唯一方法是在现实世界中审核您的部署后结果。所以我的第二个建议是，进行审计。你可以自己做这件事，尽管最好让外界的人来看看。接受学习，并根据需要进行调整。你每天都会让世界变得更美好。</p><h2 id="fd3d" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">推荐读物</h2><p id="4ed9" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">当被问及道德和坏算法的危险时，我推荐的第一本书是<a class="ae ky" href="http://@mathbabedotorg" rel="noopener ugc nofollow" target="_blank">凯茜·奥尼尔</a>的<em class="nf">数学毁灭武器</em>。如果你认为你只有一本书的时间，这是一个选择。详细的例子是相关的，易于阅读。</p><p id="c04a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面这篇文章对我的思考产生了重大影响。我把这项研究作为演讲的例子。如何选择算法的优化目标可能会产生严重的意想不到的后果。我计划下个月就这个话题创建一个条目。</p><p id="41fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Obermeyer 等人的“剖析用于管理人口健康的算法中的种族偏见”<em class="nf">科学【2019 年 10 月 25 日:447–453</em></p></div></div>    
</body>
</html>