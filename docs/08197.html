<html>
<head>
<title>How to run your ML model Predictions 50 times faster?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将你的ML模型预测速度提高50倍？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/run-your-machine-learning-predictions-50-times-faster-3ad2f4ee5819?source=collection_archive---------9-----------------------#2020-06-16">https://towardsdatascience.com/run-your-machine-learning-predictions-50-times-faster-3ad2f4ee5819?source=collection_archive---------9-----------------------#2020-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/ce2eb9d306f66d06637ad7faad3c4f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TnObGyuApLcapBrJEjcLLw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片由来自<a class="ae jg" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3388999" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae jg" href="https://pixabay.com/users/KELLEPICS-4893063/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3388999" rel="noopener ugc nofollow" target="_blank">斯蒂芬·凯勒</a>拍摄</p></figure><div class=""/><div class=""><h2 id="a4b4" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">使用蜂鸟只用了2行代码</h2></div><p id="b121" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">随着这么多计算和服务框架的出现，开发人员将一个模型投入<a class="ae jg" rel="noopener" target="_blank" href="/take-your-machine-learning-models-to-production-with-these-5-simple-steps-35aa55e3a43c">生产</a>的压力与日俱增。如果哪种模型在我的数据上表现最好的问题还不够，现在的问题是选择什么框架来服务于用Sklearn或LightGBM或<a class="ae jg" rel="noopener" target="_blank" href="/moving-from-keras-to-pytorch-f0d4fff4ce79"> PyTorch </a>训练的模型。每天都有新的框架加入进来。</p><p id="61c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，对于一个数据科学家来说，是否有必要学习一个不同的框架，因为一个数据工程师对此很熟悉，或者相反，一个数据工程师是否需要学习一个数据科学家喜欢的新平台？</p><p id="179b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">再加上这些不同框架提供的速度和性能因素，问题突然变得更加复杂。</p><p id="9f87" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，当我最近在Github上偶然看到<a class="ae jg" href="https://github.com/microsoft/hummingbird" rel="noopener ugc nofollow" target="_blank">蜂鸟</a>项目时，我感到惊喜，这个项目旨在回答这个问题，或者至少朝着正确的方向迈出了积极的一步。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="4dd2" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">那么，蜂鸟是什么？</h1><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mt"><img src="../Images/123cc7f0cfb8f7ab7b5826cfaf3acf45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EduaJZ-Tkk6jteYvKsMRkA.png"/></div></div></figure><p id="4802" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="my">根据他们的文件:</em></p><blockquote class="mz na nb"><p id="1982" class="ky kz my la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated"><em class="jj"> Hummingbird </em>是一个用于将训练好的传统ML模型编译成张量计算的库。<em class="jj">蜂鸟</em>允许用户无缝地利用神经网络框架(如<a class="ae jg" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>)来加速传统的ML模型。</p><p id="b1ac" class="ky kz my la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">得益于<em class="jj">蜂鸟</em>，用户可以受益于:</p><p id="1369" class="ky kz my la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">(1)在神经网络框架中实现的所有当前和未来的优化；</p><p id="9568" class="ky kz my la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">(2)原生硬件加速；</p><p id="4cf5" class="ky kz my la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">(3)具有支持传统和神经网络模型的独特平台，并且具有所有这些</p><p id="40d9" class="ky kz my la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">(4)无需重新设计他们的模型。</p></blockquote><p id="c21c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更简单地说:现在，您可以将用Scikit-learn或<a class="ae jg" rel="noopener" target="_blank" href="/lightning-fast-xgboost-on-multiple-gpus-32710815c7c3"> Xgboost </a>或LightGBM编写的模型转换成PyTorch模型，并在推理时获得Pytorch的性能优势。</p><p id="987e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="my">到目前为止，这里是蜂鸟支持的</em> <a class="ae jg" href="https://github.com/microsoft/hummingbird/wiki/Supported-Operators" rel="noopener ugc nofollow" target="_blank">操作者的列表</a>还会有更多。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="b0d0" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">简单的例子</h1><p id="a734" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">我们可以从安装蜂鸟开始，简单如:</p><pre class="mu mv mw mx gt nk nl nm nn aw no bi"><span id="af39" class="np mc jj nl b gy nq nr l ns nt">pip install hummingbird-ml</span></pre><p id="45c7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了使用hummingbird，我将从一个小型随机<a class="ae jg" rel="noopener" target="_blank" href="/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226">分类</a>数据集的最小示例开始。我们首先创建一个包含100，000行的样本数据集，并在此基础上使用RandomForestClassifier。</p><pre class="mu mv mw mx gt nk nl nm nn aw no bi"><span id="d7c4" class="np mc jj nl b gy nq nr l ns nt">import numpy as np<br/>from sklearn.ensemble import RandomForestClassifier<br/>from hummingbird.ml import convert</span><span id="1d3b" class="np mc jj nl b gy nu nr l ns nt"># Create some random data for binary classification<br/>from sklearn import datasets</span><span id="b5a7" class="np mc jj nl b gy nu nr l ns nt">X, y = datasets.make_classification(n_samples=100000, n_features=28)</span><span id="e181" class="np mc jj nl b gy nu nr l ns nt"># Create and train a model (scikit-learn RandomForestClassifier in this case)</span><span id="428d" class="np mc jj nl b gy nu nr l ns nt">skl_model = RandomForestClassifier(n_estimators=1000, max_depth=10)<br/>skl_model.fit(X, y)</span></pre><p id="61b6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">hummingbird帮助我们的是通过使用简单的命令将这个sklearn模型转换成PyTorch模型:</p><pre class="mu mv mw mx gt nk nl nm nn aw no bi"><span id="c900" class="np mc jj nl b gy nq nr l ns nt"># Using Hummingbird to convert the model to PyTorch<br/>model = convert(skl_model, 'pytorch')<br/>print(type(model))<br/>--------------------------------------------------------<br/>hummingbird.ml._container.PyTorchBackendModel</span></pre><p id="27bf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们可以使用以下代码将新的Pytorch模型加载到GPU:</p><pre class="mu mv mw mx gt nk nl nm nn aw no bi"><span id="20a5" class="np mc jj nl b gy nq nr l ns nt">model.to('cuda')</span></pre><p id="c97a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这太棒了。因此，我们可以从sklearn模型转换为PyTorch模型，这应该在GPU上运行得更快。但是增加多少呢？</p><p id="d6a2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来看一个简单的性能对比。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="c3f3" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">比较</h1><h2 id="9e95" class="np mc jj bd md nv nw dn mh nx ny dp ml lh nz oa mn ll ob oc mp lp od oe mr of bi translated">1.成批处理方式</h2><p id="0f25" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">我们将首先使用sklearn模型来预测整个训练数据集，并检查它所花费的时间。</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/9d54790fd47a8a31b6ab71e0d4f66e1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vuZmWEFitSrVS0kCYr8FOg.png"/></div></div></figure><p id="75e4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的新PyTorch型号也可以做到这一点:</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/ab7058322ef22df635e45b7db14ab5cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JUGDUulFVoNHzW66c0hoTA.png"/></div></div></figure><p id="5b53" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那就是9580/195 ~ 50x的加速。</p><h2 id="73fd" class="np mc jj bd md nv nw dn mh nx ny dp ml lh nz oa mn ll ob oc mp lp od oe mr of bi translated">2.单实例预测</h2><p id="6f46" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">我们在这里预测一个例子，看看这个模型在实时环境中的表现。sklearn模型:</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/17592f682074e8df2ea42f555afff0fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dAkrUuOZL7z-j6DDGF5oUg.png"/></div></div></figure><p id="e7dc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">vs. Pytorch模型</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/4a514d0cb58b0450d03d5ee90ff9e4e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VJhHt5L2u4zIDNefMMwNTQ.png"/></div></div></figure><p id="ae6b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这也是79.6/1.6 ~ 50倍的加速比。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="624b" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">小警告</h1><p id="2477" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">我经历的一个小警告是，sklearn模型和蜂鸟PyTorch模型的预测并不完全相同。</p><p id="e8b6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，下面是我从两个模型中得到的预测:</p><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/c3b89d2ca96d75c8b019a0afe0ae20eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7s3ASBvZasjonuiZJIyyUQ.png"/></div></div></figure><p id="ffaa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">是的，有时，它们在第7位数字上不同，这可能是转换过程的一个函数。我认为它不会改变最终的1或0预测太多。我们还可以检查:</p><pre class="mu mv mw mx gt nk nl nm nn aw no bi"><span id="5b85" class="np mc jj nl b gy nq nr l ns nt">scikit_1_0 = scikit_preds[:,1]&gt;0.5 <br/>hb_1_0 = hb_preds[:,1]&gt;0.5 <br/>print(len(scikit_1_0) == sum(scikit_1_0==hb_1_0))<br/>------------------------------------------------------------<br/>True</span></pre><p id="6a55" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，在这种情况下，两个模型对100，000行的整个数据集给出了完全相同的1或0预测。</p><p id="5943" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以我想没关系。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="a51e" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">结论</h1><p id="2121" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">微软的开发人员仍在致力于添加更多的操作符，从模型到特性工程，如代码中的<code class="fe ok ol om nl b">MinMaxScaler</code>或<code class="fe ok ol om nl b">LabelEncoder</code>，我希望他们能进一步开发和改进这个项目。如果你感兴趣，这里是发展的路线图。</p><p id="d3ac" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然Hummingbird还不完美，但它是第一个能够运行经典ML推理DNN框架的系统，并证明它们足够成熟，可以用作通用编译器。当涉及到在高吞吐量或延迟时进行预测时，我会尝试将它包含在我的开发工作流中。</p><p id="d690" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以在我的<a class="ae jg" href="https://github.com/MLWhiz/data_science_blogs/tree/master/hummingbird" rel="noopener ugc nofollow" target="_blank"> GitHub </a>库找到这篇文章的代码以及我所有的文章。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h2 id="0a9f" class="np mc jj bd md nv nw dn mh nx ny dp ml lh nz oa mn ll ob oc mp lp od oe mr of bi translated">继续学习</h2><p id="ddb2" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">如果你想了解更多关于构建机器学习模型并将其投入生产的知识，这个关于AWS 的<a class="ae jg" href="https://coursera.pxf.io/e45BJ6" rel="noopener ugc nofollow" target="_blank">课程可以满足你的要求。</a></p><p id="7e5e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谢谢你的阅读。将来我也会写更多初学者友好的帖子。在<a class="ae jg" href="https://medium.com/@rahul_agarwal?source=post_page---------------------------" rel="noopener">媒体</a>关注我，或者订阅我的<a class="ae jg" href="http://eepurl.com/dbQnuX?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">博客</a>了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过Twitter <a class="ae jg" href="https://twitter.com/MLWhiz?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> @mlwhiz </a>联系</p><p id="f41d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，一个小小的免责声明——这篇文章中可能会有一些相关资源的附属链接，因为分享知识从来都不是一个坏主意。</p></div></div>    
</body>
</html>