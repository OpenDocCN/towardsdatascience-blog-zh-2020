<html>
<head>
<title>Face Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人脸识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/face-recognition-using-deep-learning-b9be73689a23?source=collection_archive---------5-----------------------#2020-02-25">https://towardsdatascience.com/face-recognition-using-deep-learning-b9be73689a23?source=collection_archive---------5-----------------------#2020-02-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="918e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">基于PCA和深度学习的人脸识别</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/cbb0e20312f09420cd73fa82c6673280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PXYjBgDfILk-ok2QHUQd8g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">我们将学习如何使用带有三重损失函数的预训练神经网络进行人脸识别。</p></figure><h1 id="ebcc" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">介绍</h1><p id="df72" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">由于计算机的强大功能提高了效率，图像内容分析和模式识别是当今迅速扩展的应用领域。</p><p id="569f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">尽管文献中提出的系统在执行人脸识别任务时变得更加健壮、可靠和高效，但是该领域中的几个真正的技术和应用方面经常被省略，或者被非常简化，使得对其性能的正式和完整的使用远不是最终的解决方案。</p><p id="961c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这项工作中，在人脸识别领域已经证明了良好结果并提供了良好方法的几项科学贡献正在考虑进行一些修改，以便选择最有效的解决方案，并确保与最先进的技术相比，识别性能非常有趣</p><p id="a66a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们想开发一个人脸识别系统，将在课堂上作为出勤系统使用，以标记讲师和学生的存在。</p><h1 id="156d" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">数据集</h1><p id="0084" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">我们将使用两个不同的数据集，一个用于PCA方法，另一个用于CNN方法的自定义人脸数据集。</p><h2 id="0041" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">Olivetti数据集</h2><p id="4315" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated"><a class="ae mt" href="https://scikit-learn.org/0.19/datasets/olivetti_faces.html" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/0.19/datasets/olivetti_faces.html</a></p><p id="e2e0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Olivetti是剑桥美国电话电报公司实验室在1992年到1994年间制作的人脸图像数据集。它包含40个不同的人的10个不同的图像和400个面部图像。</p><p id="84c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了图像具有相同背景和相同尺寸的事实之外，图像被转换为灰度级，并且像素值从0缩放到1。</p><p id="62ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个数据集将是我们接下来研究的主要参考。测试和训练子集将从中产生。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mu"><img src="../Images/a0c49342159afe0db6f8fd38d0b5a160.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qK_TqFBjxq45_vfpgdJrwQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Olivetti数据集的不同面</p></figure><p id="9738" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当显示每个文件夹的10张图片时，我们可以看到这10张图片包含了被摄对象不同的面部表情和光照。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mv"><img src="../Images/74fa462a6d1566e8e360132d9ce90c00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BpBeMShN0COJcZkF2CTYDg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Olivetti数据集中每个受试者10张脸</p></figure><p id="8d2c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于我们的机器学习模型需要向量，我们使用numpy reshape函数将我们的数据从(400，64，64)图像阵列转换为(400，4096)向量。</p><p id="8682" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们将数据分为训练和测试:每个对象70%或7张图像作为训练，每个对象30%或3张图像作为测试子集。</p><h2 id="3eff" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">制作数据集</h2><p id="650b" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">我用我的照片和我的三个同事的照片，以及我最喜欢的连续剧“La Casa De Papel”中的一些知名演员，制作了一个由10个主题组成的数据集，每个主题大约有10张照片。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi gj"><img src="../Images/e504c3a50ac4f9f76765956575d05f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jN4ppbJRFQ_6jHKRtn66bQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">一个由10个受试者组成的数据集，每个受试者有大约10张图片</p></figure><h1 id="32c2" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">方法学</h1><p id="f730" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">我们的目的是制作一个需要尽可能少的训练数据的人脸识别系统。这种约束背后的主要原因是，对于管理者来说，用每个学生的一个或几个图片来训练模型比必须为同一个人制作具有许多图像的大型数据集更有用。</p><p id="80ae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将比较两种主要的人脸分类模型，PCA降维和预训练的CNN。</p><p id="2869" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要执行面部识别，将遵循以下步骤:</p><ul class=""><li id="b126" class="mw mx it js b jt ju jx jy kb my kf mz kj na kn nb nc nd ne bi translated">检测图像中包含的所有人脸(人脸检测)。</li><li id="643d" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nb nc nd ne bi translated">裁剪人脸并提取其特征。</li><li id="8fba" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nb nc nd ne bi translated">应用合适的面部识别算法将面部与学生和讲师的数据库进行比较。</li><li id="9a92" class="mw mx it js b jt nf jx ng kb nh kf ni kj nj kn nb nc nd ne bi translated">提供记录所识别的服务人员的文件。</li></ul><h1 id="0fa9" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">利用主成分分析和不同分类器进行人脸识别</h1><p id="91e2" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">以下研究的目的是使用六种不同的分类模型来执行面部识别，以了解哪一种模型是用作考勤系统的最佳候选模型。</p><h2 id="3414" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated"><a class="ae mt" href="https://fr.wikipedia.org/wiki/PCA" rel="noopener ugc nofollow" target="_blank">主成分分析</a></h2><p id="b628" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">第一步是通过移除这些人脸之间的任何共同特征来标准化训练集的所有人脸，以便每个人脸只留下其独特的特征。这将通过从每个面部移除平均面部(数据集上的像素的平均值)来完成。</p><p id="9287" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的图像向量将包括每个图像的64×64 = 4096个分量。这些向量将通过对齐像素将二维图像转换成一个向量来创建。</p><p id="a1ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从数字的角度来看，为了表示这样的图像，大量的组件可能被夸大了。为了减少数据的大小，我们将应用PCA方法来只选择图像的主要成分。</p><p id="26e1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于我们的人脸数据中有许多维度，PCA的使用使得能够恢复或移除最相关的分量，并寻找捕获最大方差的方向，从而我们可以仅获得m个最有代表性的分量。</p><p id="a0a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当对我们的数据使用分类器时，将根据获得的最佳准确度来选择分量的数量m。该过程包括循环几个分量，并为每个指定数量的主分量构建PCA模型。然后，我们将构建一个分类器，并根据混淆矩阵计算准确度，以获得可以从中选择最佳组件数量的图。</p><p id="fc03" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦选择了m个<a class="ae mt" href="https://fr.wikipedia.org/wiki/Eigenface*" rel="noopener ugc nofollow" target="_blank">特征脸</a>，我们就可以使用这些特征脸从训练集中复制任何一张脸，如图所示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/5b1669f168074c32a71c08594739b630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7tNy7-2vk7a785VcLbjUeA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">在从训练集中去除平均人脸后，我们将2D图像转换成矢量。然后我们应用主成分分析挑选m个最有代表性的成分。一旦选择了m个特征脸，就有可能使用这些特征脸从训练集中再现任何脸。</p></figure><p id="e9dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">来自训练集的每个人脸可以被投影为m个所选特征脸的加权和，这是特征向量空间中给定人脸加上平均人脸的表示。与每个特征脸相关联的权重表示该特征脸对原始脸的再现的贡献。</p><p id="81eb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦训练集的所有人脸被转换成它们相应的权重向量，我们就能够通过在特征空间中表示它们来再现训练人脸。</p><p id="7555" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是，如果我们想要识别一个新面孔，并将其与训练集中的相应主题进行匹配，该怎么办呢？</p><h2 id="38ab" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated"><strong class="ak">识别一张陌生的脸</strong></h2><p id="a268" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">为了识别未知的人脸，我们执行已经应用于训练图像的相同步骤。我们首先对这张脸进行归一化(去掉平均脸)并将其转换成一个矢量。然后，我们将人脸向量归一化到我们在使用PCA之前计算的特征空间上，这意味着将未知人脸表示为m个特征脸的组合。</p><p id="3191" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦我们获得了未知人脸的权重向量，下一步将使用欧几里德距离作为度量，将其与我们训练集的所有权重向量进行比较。</p><p id="2831" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果两个向量之间的距离大于某个阈值，我们会说这是一张未知的脸，否则，我们会看到对应于最小距离的人，并将他识别为这个人。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/86a38ed137275062a8b9c8c934873fa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lmCX4JvoYrH7Jk7FiBVIDg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用主成分分析法识别未知人脸</p></figure><h2 id="02c3" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">使用不同的分类器</h2><p id="8363" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">一种更稳健的技术是使用分类器(如SVM或KNN ),而不是将输入与训练集中最接近的人脸进行匹配。</p><p id="a05d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图像降维后将引入的分类器有:</p><p id="e83c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae mt" href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">线性判别分析</strong> </a> <strong class="js iu"> : </strong>它是统计学、模式识别、机器学习中使用的一种方法，用来寻找表征或区分两类或两类以上对象或事件的特征的线性组合。所得到的组合可以用作线性分类器，或者更常见的是，在稍后的分类之前用于维度减少。</p><p id="f27c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae mt" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">逻辑回归</strong> </a> <strong class="js iu">【一对一】:</strong>由于我们在一个数据集中会有许多不同的类或主题，我们每次构建模型时都会将属于一个类的数据视为正值，而将属于其余类的数据视为负值。我们将重复这个过程，直到我们建立了尽可能多的模型。</p><p id="37c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae mt" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">高斯NB </strong> </a> <strong class="js iu"> : </strong>这是一种基于应用贝叶斯定理，以条件独立性为“朴素”假设的学习算法。在不检查特征的似然性是否为高斯的情况下，我们将采用这一假设，并查看结果在准确性方面是否可接受。</p><p id="709d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae mt" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">KNN</strong></a><strong class="js iu">:</strong>它是一种非参数学习算法，被称为“懒惰”，也就是说它不使用任何数据点来生成模型。训练在分类和测试阶段完成，因为算法仅寻找与其他数据点的特征相似性。K是邻居的数量，它必须是奇数以避免票数相等。</p><p id="e99c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae mt" href="https://en.wikipedia.org/wiki/Decision_tree" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">决策树</strong> </a> <strong class="js iu"> : </strong>由于图像分类只是模式识别中的一个特例，决策树可以用于此目的。</p><p id="e461" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae mt" href="https://en.wikipedia.org/wiki/Support-vector_machine" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">SVM</strong></a><strong class="js iu">:</strong>支持向量机是这样制造的，它们可以执行两类分类。它们可以适用于以非常有效的方式执行K分类。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/0f3d3475bce020242b1efe7c6523374c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*ZZwBgnWuebqJ2KTGnCOotA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">分类工作流程</p></figure><h2 id="ab36" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">主成分分析中成分数量的选择</h2><p id="acd1" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">下图显示了主成分数量与SVM径向基函数(RBF)核分类器精度的关系。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/cefe0239bfa8830d2013afed9c299045.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o-B4dxe2DLa5kqbiU8wkvQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><strong class="bd no">SVM径向基函数(RBF)核分类器相对于PCA组件数量的准确性</strong></p></figure><p id="6d08" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">似乎只用40个元件，我们就能获得用100个或更多元件获得的同样精度。这意味着我们可以减少计算时间，同时保持模型的相同性能。在下文中，我们将使用40个组件。</p><h2 id="c3a8" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">分类器比较</h2><p id="e53e" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">在PCA阶段之后，使用选定数量的成分，我们将我们的数据引入第3节中列出的六个不同的分类器，并计算每个分类器的准确度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi np"><img src="../Images/3c7f63cc4c21ce77755e8e16d8db1645.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*QhBgNMsekPBNcx_KqhfoBw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">比较不同分类器的准确度</p></figure><p id="d495" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据上述结果，线性判别分析和逻辑回归似乎具有最好的性能，并且可以被认为是对于我们的分类问题的最佳选择。然而，需要许多数据点来预测具有不同亮度的不同图片。</p><h2 id="87fa" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">结论</h2><p id="99a3" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">在Olivetti数据集上获得了93%的最大准确度，即使图像被相对良好地定位和照明。对于不允许出错的考勤系统来说，这种低性能是不能容忍的。此外，对于这项技术，我们需要许多图像(大约10张)来训练模型。</p><p id="a163" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一方面，让我们不要忘记，我们的考勤系统必须能够服务于一个大的大学，学生的数量会随着时间的变化而变化。但是，每次必须向数据库中添加新学生时，都需要重新训练PCA模型。</p><h1 id="8de5" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">使用深度度量学习的面部识别</h1><p id="cba4" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">另一种执行面部识别的方法包括使用名为Inception的深度<a class="ae mt" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>架构，该架构负责在<a class="ae mt" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank">ImageNet</a>2014年大规模视觉识别挑战赛(ILSVRC14)中设置分类和检测的新技术状态。</p><p id="889f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">盗梦空间的名称来源于林等人的《网络论文》中的网络，并结合了电影《盗梦空间》中著名的网络迷因《我们需要更深入》。</p><p id="ae6d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这项工作中，我们将使用一个初始架构的变体。该模型包括具有128个隐藏单元的全连接层，随后是卷积基础之上的L2归一化层。</p><p id="0a9a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最上面的两层负责从图像中创建128维嵌入。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nq"><img src="../Images/6dae38e8fc0747d5c6d273c120cf4e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7G6UWgj805pBMLAWwPB4ew.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">深度度量架构，CNN被训练成将图像转换成128 d矢量。</p></figure><h2 id="53ff" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">深度度量学习架构</h2><p id="5d27" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">目的是让CNN学会将每个图像转换成一个向量，使得相同身份的所有人脸之间的欧几里德距离很小，而来自不同身份的一对人脸之间的距离很大。</p><p id="f36b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">更准确地说，给定一对不同身份的图像，我们希望距离至少大一定程度，但是给定两幅相同身份的图像，我们希望它们的编码相似，因为它们都表示同一个人。</p><p id="0494" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">应保持的余量α必须符合以下公式:</p><p id="b487" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">T5】d(A，P)+ α ≤d(A，N)T7】</strong></p><p id="810a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了训练神经网络，我们从数据集生成三个一组的图像。然后，在定义了我们想要最小化的三元组损失函数之后，我们使用梯度下降来调整CNN的参数，以便学习对相同类别的两个图像给出小距离而对不同类别的图像给出大距离的编码。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/bfc29a4773f5a5590e0680f6a393a050.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*JSKDvFlHosc17XUU6DJDgw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">训练CNN的三联体技术</p></figure><p id="bc56" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要最小化的三重损失函数定义如下:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nt"><img src="../Images/b88d9bd99234409da17469a2fdbafdda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r_-8UhPpzlXT0WuzzwRhAQ.png"/></div></div></figure><p id="0824" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用keras-Openface项目中可用的预训练模型，并调整神经网络的权重，以便检查我们的alpha-margin (α=0.2)，而不是从头开始训练CNN模型，这将需要数百万张图像。</p><h2 id="32ad" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">面部检测</h2><p id="a4c2" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">在将我们的图像输入神经网络之前，必须找到可用的人脸，并对其进行裁剪和对齐。</p><p id="de63" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae mt" href="http://dlib.net/" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> dlib </strong> </a>库提供了<strong class="js iu">猪+SVM </strong>人脸检测器，还提供了一个预训练的<strong class="js iu"> CNN </strong>人脸检测器，可以使用GPU或使用CPU运行。</p><p id="95d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如下图所示，对于包含9张人脸的相同样本图像，我们使用CPU尝试了两种人脸检测器。两个提取器给出了相同的结果，但是CNN需要大约2分钟，而猪只需要6秒钟。安装CUDA，编译dlib库在GPU上运行后，CNN能够运行快10倍。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/e0c4b183c5a238933154f8aa240b8e6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*zlVqGTeCSUBOuxmCC-ITxQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">CNN面部检测器性能</p></figure><p id="53f8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">人脸检测将使用Dlib的CNN模型进行，因为文档坚持认为与HOG人脸检测器相比，CNN具有较高的准确性。</p><p id="70e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">用对齐的人脸图像训练预训练模型。但通常并不是照片中的所有人脸都没有正确对齐。因此，在将裁剪后的人脸图像输入神经网络之前，必须对其进行对齐，以实现人脸识别任务的高精度。</p><p id="4be2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">同样，dlib有一个预先训练的模型，用于预测和找到一些面部标志，然后将它们转换到参考坐标。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/cbb0e20312f09420cd73fa82c6673280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PXYjBgDfILk-ok2QHUQd8g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图像预处理</p></figure><h2 id="62cd" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">使用CNN和距离度量来比较面部</h2><p id="3272" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">最后，我们可以使用CNN从对齐的图像中提取128维的人脸向量。在128维空间中，欧几里德距离直接对应于人脸相似性的度量。</p><p id="9f96" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在使用预训练的CNN变换所有数据集图像之后，我们通过相同的过程输入我们想要识别的图像，以获得相似的128-d向量(嵌入)。人脸的相似性可以用欧氏距离来度量。</p><p id="7096" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下图以图形方式显示了此过程的工作原理，并举例说明了该算法在相似和不同人脸之间测量的距离。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nv"><img src="../Images/8af956d050ff2f7c4d6468d2af924030.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NLxPjtiYdgtwunGlMIimFg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">锚阳性对之间的距离小于其锚阴性对之间的距离(0.59 &lt; 1.43)</p></figure><h2 id="87ba" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">最佳距离阈值</h2><p id="d3a4" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">为了能够辨别两张脸是否属于同一个人，必须确定距离阈值。为了找到阈值的最佳值，将使用我们的数据库图像测试不同的值。我们将绘制不同阈值距离值的准确度图，并选择最佳值。</p><p id="e028" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从下图中，将选择值d=0.72，因为它给出了最佳精度(96.8%)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/386b236a4ad26852da9b187f8723c8d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*nseTtSFQhoVn2q0k5qgZLQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">不同阈值距离人脸识别的F1分数和准确率</p></figure><h2 id="8094" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">使用分类器</h2><p id="079a" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">不使用最小距离来确定检测到了哪些面部，而是使用KNN或SVM分类方法更有效，其中K将被取为等于5。</p><p id="a471" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">用来自数据集的50%的标记图像来训练分类器，并且在剩余的图像上进行测试，并且与SVM分类器进行比较。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi np"><img src="../Images/f9dba6a485d667162b99d517093a5c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*hWiSMYGQ4biwHjxDO02iQg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用KNN和SVM分类器的精度</p></figure><p id="14fd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在研究的其余部分，将使用KNN分类器。</p><h2 id="82ed" class="mh lf it bd lg mi mj dn lk mk ml dp lo kb mm mn ls kf mo mp lw kj mq mr ma ms bi translated">数据可视化</h2><p id="f9d8" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">由于可视化具有128维的嵌入图像不是一件非常容易的任务，我们将使用<strong class="js iu">t-分布式随机邻居嵌入(</strong><a class="ae mt" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">t-SNE</strong></a><strong class="js iu">)</strong>，这是一种由Laurens van der Maaten和Geoffrey Ginton开发的用于非线性降维的机器学习算法。这种方法将允许我们在二维的低维空间中看到我们的图像的分布。</p><p id="82ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在下图中，<a class="ae mt" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank"> t分布随机邻居嵌入</a> (t-SNE)应用于128维嵌入向量，以便将数据集汇总到2D空间。除了少数异常值之外，身份聚类被很好地分开。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nx"><img src="../Images/97b96d27a815477c3b2243831eb05cd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PE76r3Y-jmjHTiAM78Nijw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">受试者的t-SNE显像</p></figure><h1 id="e1fe" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">结论以及与其他先进模型的比较</h1><p id="327c" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">我们已经看到PCA作为考勤系统的准确率非常低，并且它需要许多人脸作为输入数据进行训练。此外，每次我们有一个新的学生，模型必须从零开始重新训练，参数(PCA的组件数量)必须再次确定哪个不适合项目的要求。</p><p id="5964" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一方面，预训练的用于面部识别的Inception CNN模型用我们的数据集进行了调整，给出了非常好的性能(在我们的自定义数据集上有97%的准确率)，特别是当我们添加了KNN方法时。此外，这个CNN不需要有很多图片，因为我们可以在只有一个参考(训练)图片和另一个测试图片的128维空间中测量人脸之间的距离。此外，一旦被训练，当新生入学时，不需要再次寻找CNN的参数。</p><p id="db4b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">出于这个项目的目的，许多其他CNN模型都在同一个数据集上进行了训练和测试，但是在前面的章节中只描述了初始模型。使用ResNet网络(29卷积层预训练模型)获得了最好的准确性，并且它将是被选择使用的模型，因为它能够在我们的测试数据集中正确地检测所有人脸。</p><p id="a9b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ResNet网络是一个更深入的预训练网络，Inception在一个包含超过13000张图像的公共数据集上实现了99%的准确性，该数据集被称为“野生标记的人脸”。</p><p id="2329" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下表显示了过去5年中一些最好的面部识别模型。我们可以看到，我们的模型可以与在相同数据集上测试的最先进的验证方法相媲美。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ny"><img src="../Images/467baa8c0c7fd4600a2b565c4341faa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V7GVeFhChsSnRPOlP2QgSg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">比较不同验证方法在野生数据集的标记人脸上测试的结果。最后一行是在第一部分取自“深度人脸识别:一项调查”时添加的——王美，魏宏·邓(2019)</p></figure><h1 id="6a2e" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">密码</h1><p id="3d5f" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">项目:在考勤系统中使用CNN进行人脸识别:</p><div class="nz oa gp gr ob oc"><a href="https://drive.google.com/file/d/1F79R1GR_e4vkMm2bnsOyEbRo1qX3gAg6/view?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd iu gy z fp oh fr fs oi fu fw is bi translated">GUI.zip</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">编辑描述</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">drive.google.com</p></div></div></div></a></div><p id="c571" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在Olivetti数据集上使用PCA进行人脸识别；</p><div class="nz oa gp gr ob oc"><a href="https://drive.google.com/file/d/1522lW68pAW7ichHHzB9nV7u34gz5Rl-S/view?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd iu gy z fp oh fr fs oi fu fw is bi translated">Olivetti Dataset.ipynb上的人脸识别</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">编辑描述</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">drive.google.com</p></div></div></div></a></div></div></div>    
</body>
</html>