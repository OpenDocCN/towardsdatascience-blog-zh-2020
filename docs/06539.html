<html>
<head>
<title>Apache Spark: Caching</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark:缓存</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-spark-caching-603154173c48?source=collection_archive---------11-----------------------#2020-05-24">https://towardsdatascience.com/apache-spark-caching-603154173c48?source=collection_archive---------11-----------------------#2020-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/35d8517e2f3405b6d9f95140a044c286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vFqbKeSFjLUqbuNFJTEWRw.jpeg"/></div></div></figure><p id="5698" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Apache Spark 提供了一个重要的特性来缓存中间数据，并在对相同数据运行多个查询时提供显著的性能改进。在本文中，我们将比较不同的缓存技术、缓存的好处以及何时缓存数据。</p><p id="b774" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">如何缓存</strong></p><p id="850c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">参考<a class="ae kz" href="https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/Dataset.scala#L3132" rel="noopener ugc nofollow" target="_blank"> DataSet.scala </a></p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="ea3d" class="lj lk it lf b gy ll lm l ln lo">df.cache</span></pre><p id="f375" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">cache 方法使用默认存储级别 MEMORY_AND_DISK 调用 persist 方法。其他存储级别将在后面讨论。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="6ac3" class="lj lk it lf b gy ll lm l ln lo">df.persist(StorageLevel.MEMORY_AND_DISK)</span></pre><p id="75f7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">何时缓存</strong></p><p id="70f8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">缓存的经验法则是识别将在 Spark 应用程序中重用的数据帧并缓存它。即使你没有足够的内存来缓存所有的数据，你也应该继续缓存。Spark 会在内存中缓存所有它能缓存的内容，并将其余的内容缓存到磁盘中。</p><p id="ddd3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">缓存数据帧的好处</strong></p><ul class=""><li id="62e1" class="lp lq it kd b ke kf ki kj km lr kq ls ku lt ky lu lv lw lx bi translated">从源(hdfs://或 s3://)读取数据非常耗时。因此，在从源中读取数据并应用所有常见操作后，如果要重用数据，请缓存它。</li><li id="b6d3" class="lp lq it kd b ke ly ki lz km ma kq mb ku mc ky lu lv lw lx bi translated">通过缓存，您可以在 spark 应用程序中创建一个检查点，如果进一步执行应用程序的任何任务失败，您的应用程序将能够从缓存中重新计算丢失的 RDD 分区。</li><li id="5987" class="lp lq it kd b ke ly ki lz km ma kq mb ku mc ky lu lv lw lx bi translated">如果没有足够的内存，数据将被缓存在 executor 的本地磁盘上，这也比从源代码读取要快。</li><li id="1c2a" class="lp lq it kd b ke ly ki lz km ma kq mb ku mc ky lu lv lw lx bi translated">如果您只能缓存一小部分数据，这也将提高性能，其余的数据可以由 spark 重新计算，这就是 RDD 的弹性。</li></ul><p id="2df8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">Spark 中的缓存方法</strong></p><p id="c560" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以使用不同的存储级别来缓存数据。参考:<a class="ae kz" href="https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/storage/StorageLevel.scala#L152" rel="noopener ugc nofollow" target="_blank"> StorageLevel.scala </a></p><ul class=""><li id="db76" class="lp lq it kd b ke kf ki kj km lr kq ls ku lt ky lu lv lw lx bi translated">DISK_ONLY:仅以序列化格式将数据保存在磁盘上。</li><li id="3ad1" class="lp lq it kd b ke ly ki lz km ma kq mb ku mc ky lu lv lw lx bi translated">MEMORY_ONLY:只以反序列化的格式将数据保存在内存中。</li><li id="20ac" class="lp lq it kd b ke ly ki lz km ma kq mb ku mc ky lu lv lw lx bi translated">MEMORY_AND_DISK:将数据保存在内存中，如果没有足够的内存可用，被逐出的块将存储在磁盘上。</li><li id="5ec2" class="lp lq it kd b ke ly ki lz km ma kq mb ku mc ky lu lv lw lx bi translated">OFF_HEAP:数据保存在堆外内存中。参考<a class="ae kz" href="https://spark.apache.org/docs/latest/configuration.html#memory-management" rel="noopener ugc nofollow" target="_blank">火花文件</a>中的 spark.memory.offHeap.enabled。</li></ul><p id="4ad7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以通过使用 DISK_ONLY_2、MEMORY_AND_DISK_2 等方法明确指定在缓存数据时是否使用复制。</p><p id="02e5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们还可以指定在存储时是否序列化数据。像 MEMORY_ONLY_SER 等方法。使用序列化格式会增加处理时间，但会减少内存占用。</p><p id="70be" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">还提供带复制的序列化，例如 MEMORY_ONLY_SER_2</p><p id="6dd1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">不同存储级别之间的比较</strong></p><p id="15b3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以下测试在本地机器上运行，驱动内存为 12GB，输入数据为 14GB，每次迭代使用<em class="md"> `spark.time` </em>记录时间。它输出在一个循环中执行了 10 次的查询的运行时间。</p><pre class="la lb lc ld gt le lf lg lh aw li bi"><span id="3916" class="lj lk it lf b gy ll lm l ln lo">import org.apache.spark.storage.StorageLevel</span><span id="feaf" class="lj lk it lf b gy me lm l ln lo">val df = spark.read.option("header",true).csv("/test/test.csv")<br/>df.persist(StorageLevel.DISK_ONLY)<br/>for(_ &lt;- 0 until 10)<br/>{<br/>    spark.time(df.filter($"category_code" like  "%electronics%").count)<br/>}</span></pre><figure class="la lb lc ld gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mf"><img src="../Images/b774eac0c258e32a884bfc4fb7ff1517.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bW7VO52Ht2kDvrdosEBpwQ.png"/></div></div></figure><blockquote class="mg mh mi"><p id="b311" class="kb kc md kd b ke kf kg kh ki kj kk kl mj kn ko kp mk kr ks kt ml kv kw kx ky im bi translated">注意:记住 spark 中的 cache()是延迟计算的。所以当第一个动作被调用时，数据将被缓存。缓存将花费额外的时间，这可以在上图中看到。对于重新运行，我们观察到缓存带来了显著的性能优势。</p></blockquote><p id="074e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">结论</strong></p><p id="ccd2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这篇文章中，我们了解到缓存是优化 spark 作业的一项重要技术。如果我们要在代码中多次使用数据，我们应该缓存数据。它可以给我们带来显著的性能优势。</p></div></div>    
</body>
</html>