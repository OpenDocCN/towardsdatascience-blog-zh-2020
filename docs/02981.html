<html>
<head>
<title>Performing Sentiment Analysis on Movie Reviews</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对电影评论进行情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/imdb-reviews-or-8143fe57c825?source=collection_archive---------10-----------------------#2020-03-22">https://towardsdatascience.com/imdb-reviews-or-8143fe57c825?source=collection_archive---------10-----------------------#2020-03-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="84b8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">TD-IDF 和 scikit 令牌化的要点-学习</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2de0a0e79764ccf90ccdcbd442045c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ucPRAFWgrWMjz78IM6lKDw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@jakehills?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">杰克·希尔斯</a>在<a class="ae ky" href="https://unsplash.com/s/photos/movie-review?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi kz"><img src="../Images/acfe526501bdf67b6153c74f8d0753ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AaSAGUqdtt0SFfz2i9Hr3w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd la">IMDb:</strong><strong class="bd la"/>一个与电影、电视节目、家庭视频、视频游戏和在线流媒体内容相关的在线数据库，包括演员、制作人员和个人传记、情节摘要、琐事、粉丝和评论以及评级。</p></figure><h1 id="395f" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">1.简介和导入数据</h1><p id="cb48" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在本文中，我将使用 IMDB 电影评论数据集进行研究。该数据集包含 50，000 条评论，其中包括 25，000 条正面评论和 25，000 条负面评论。在图 1 的<em class="mp">、</em>中可以看到评论的示例，其中用户给奥斯卡获奖电影《寄生虫》(2020)给出了 10/10 的评分和书面评论。</p><p id="e7c3" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">星星的数量可以很好地代表情感分类。例如，我们可以预先分配以下内容:</p><ul class=""><li id="5231" class="mv mw it lv b lw mq lz mr mc mx mg my mk mz mo na nb nc nd bi translated">10 颗星中至少有 7 颗= &gt;阳性(标签=1)</li><li id="354e" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo na nb nc nd bi translated">10 颗星中最多 4 颗= &gt;阴性(标签=0)</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/bd1113dcb25c2589ff720060af7da244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ot0CWHkmqnUCPWJkxhJYWA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">IMDB 用户评论对电影《寄生虫》( 2020)给予了积极评价</p></figure><p id="ea46" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">对我们来说幸运的是，斯坦福大学的研究人员已经完成了对评论数据集进行情感分类的“繁重”工作(详情请参考<em class="mp">引文&amp;参考文献</em>)。这是数据集外观的剪贴画:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/27e756f965912b82d082e725a1b879ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fNXlzk-u7VrDUdIASHqOIw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">包含“文本”和“情感”列的数据集</p></figure><p id="ba0d" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">为了训练，我们的特征矩阵非常稀疏，这意味着在这个矩阵中有许多零，因为有 25，000 行和大约 75，000 列。因此，我们要做的是找出每个特征的权重，并将其乘以相应的 TD-IDF 值；将所有的值相加，通过一个 sigmoid 激活函数，这就是我们最终得到逻辑回归模型的方法。在这种情况下应用逻辑函数的优点是:该模型可以很好地处理稀疏矩阵，并且权重可以被解释为情感的概率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/f815ffe0827c9517ce1a405b43daae52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dCHLVFKQxJzr2pBpHHoblA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" rel="noopener" target="_blank" href="/derivative-of-the-sigmoid-function-536880cf918e">逻辑回归模型的 Sigmoid 函数</a></p></figure><h1 id="adb2" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">2.将文档转换成特征向量</h1><p id="55c9" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">下面，我们将调用 CountVectorizer 上的<code class="fe nm nn no np b">fit_transform</code>方法。这将构建单词袋模型的词汇，并将下面的示例句子转换为稀疏特征向量。</p><pre class="kj kk kl km gt nq np nr ns aw nt bi"><span id="4ea2" class="nu lc it np b gy nv nw l nx ny">import numpy as np</span><span id="b175" class="nu lc it np b gy nz nw l nx ny">from sklearn.feature_extraction.text import CountVectorizer</span><span id="331a" class="nu lc it np b gy nz nw l nx ny">count = CountVectorizer()</span><span id="4f9f" class="nu lc it np b gy nz nw l nx ny">docs = ([‘The sun is shining’,</span><span id="e097" class="nu lc it np b gy nz nw l nx ny">‘The weather is sweet’,</span><span id="ed81" class="nu lc it np b gy nz nw l nx ny">‘The sun is shining, the weather is sweet, and one and one is two’])</span><span id="8062" class="nu lc it np b gy nz nw l nx ny">bag = count.fit_transform(docs)</span><span id="a4f8" class="nu lc it np b gy nz nw l nx ny">print(count.vocabulary_)</span><span id="ff27" class="nu lc it np b gy nz nw l nx ny">print(bag.toarray())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/290c31d21f400ee030f75d05a926d8a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZd3da6kU7sGqh-k91WuCQ.png"/></div></div></figure><p id="03a3" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">请注意词汇表现在是如何存储在 Python 字典中的，每个惟一的单词都映射到惟一的整数索引。该数组显示每个唯一单词的词频。</p><h1 id="4891" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">3.使用术语频率-逆文档频率的单词相关性(TD-IDF)</h1><p id="51b6" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">TD-IDF 可用于降低特征向量中频繁出现的单词的权重，例如，上面示例句子中的单词“is”。TD-IDF 可以通过术语频率与逆文档频率的乘积来计算。计算 TD-IDF 的公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/bd48790f78967277b91ef63a60734903.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9AYG-aOpAQFtFuM7wYi35g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源于<a class="ae ky" href="https://hackernoon.com/what-is-tf-idf-and-how-can-it-be-used-to-optimize-seo-content-4h1dh32f2" rel="noopener ugc nofollow" target="_blank"> hackernoon </a></p></figure><p id="96ca" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">我们现在将通过实例化<code class="fe nm nn no np b">TdidfTransformer</code> <em class="mp"> </em>方法<em class="mp">来转换上一节的原始频率输入，以获得我们的 TD-IDF 值。</em></p><pre class="kj kk kl km gt nq np nr ns aw nt bi"><span id="59c6" class="nu lc it np b gy nv nw l nx ny">from sklearn.feature_extraction.text import TfidfTransformer</span><span id="f7bc" class="nu lc it np b gy nz nw l nx ny">np.set_printoptions(precision=2)</span><span id="97d6" class="nu lc it np b gy nz nw l nx ny">tfidf = TfidfTransformer(use_idf=True, norm=’l2', smooth_idf=True)</span><span id="cffc" class="nu lc it np b gy nz nw l nx ny">print(tfidf.fit_transform(bag).toarray())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/f8cf8b8bbcd89dfb924085b8481bef4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5DVJn786MLW1Ec-CXgnYmw.png"/></div></div></figure><p id="54ea" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">显然，从示例句子来看，单词“is”在文档的第三个句子中出现频率最高。在该值被转换为 TD-IDF 值后，您会注意到，现在不是夸大的值 3，而是 0.45。这是因为‘is’这个词也包含在文档的句子 1 和 2 中；因此不太可能包含任何对我们的模型有用的或歧视性的信息。</p><p id="8821" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">这就是 TD-IDF 值的核心思想——它们将文本数据转换为数值，并根据文本数据语料库中单词的频率对单词进行适当加权。</p><h1 id="3eb4" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">4.数据准备:预处理</h1><p id="3248" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在本节中，我们将定义一个助手函数来预处理文本数据，因为我们的评论文本可能包含特殊字符— html 标签、表情符号—我们希望在训练模型时考虑这些字符。</p><pre class="kj kk kl km gt nq np nr ns aw nt bi"><span id="3688" class="nu lc it np b gy nv nw l nx ny">import re</span><span id="3137" class="nu lc it np b gy nz nw l nx ny">def preprocessor(text):</span><span id="5b72" class="nu lc it np b gy nz nw l nx ny">text =re.sub(‘&lt;[^&gt;]*&gt;’, ‘’, text)</span><span id="c051" class="nu lc it np b gy nz nw l nx ny">emoticons = re.findall(‘(?::|;|=)(?:-)?(?:\)|\(|D|P)’, text)</span><span id="7072" class="nu lc it np b gy nz nw l nx ny">text = re.sub(‘[\W]+’, ‘ ‘, text.lower()) + ‘ ‘.join(emoticons).replace(‘-’, ‘’)</span><span id="91dd" class="nu lc it np b gy nz nw l nx ny">return text</span><span id="259e" class="nu lc it np b gy nz nw l nx ny">preprocessor(“This is a :) test :-( !”)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/e5d02bf84bcc18dc06d65bff17f579a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eTh1n_2GozvW9oahGbiKYA.png"/></div></div></figure><p id="ea4a" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">如上图<em class="mp">、</em>所示，在应用了定义好的<code class="fe nm nn no np b">preprocessor</code>函数后，<em class="mp">、</em>示例语句被去除了特殊字符；表情符号也被移到了句子的末尾。这是为了让我们的模型可以利用文本的顺序，还可以确定句子结尾的表情符号的情感。</p><h1 id="aedc" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">5.文档的标记化</h1><p id="6365" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在本节中，我们将把我们的数据表示为单词或<em class="mp">标记的集合；</em>我们还将执行单词级预处理任务，如<em class="mp">词干提取。</em>为了实现这一点，我们将利用自然语言工具包，或<em class="mp"> nltk。</em></p><p id="d519" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">词干分析是一种将一个普通单词的屈折形式，有时是派生相关形式，简化为基本形式的技术。例如，单词“organizer”和“organizing”源于基本单词“organize”。因此，词干提取通常被称为一种粗略的启发式过程，即“砍掉”词尾，希望在大多数情况下正确实现目标——这通常包括去除派生词缀。</p><pre class="kj kk kl km gt nq np nr ns aw nt bi"><span id="9405" class="nu lc it np b gy nv nw l nx ny">from nltk.stem.porter import PorterStemmer</span><span id="f875" class="nu lc it np b gy nz nw l nx ny">porter = PorterStemmer()</span><span id="f0c4" class="nu lc it np b gy nz nw l nx ny">def tokenizer(text):</span><span id="bd28" class="nu lc it np b gy nz nw l nx ny">return text.split()</span><span id="e22b" class="nu lc it np b gy nz nw l nx ny">tokenizer('runners like running thus they run')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/d7755eba3687d9c7b4be2f7bbae4fadb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CQmoTlf1IRMYRXhHNVuejw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><code class="fe nm nn no np b">tokenizer</code>函数将文本转换成令牌</p></figure><pre class="kj kk kl km gt nq np nr ns aw nt bi"><span id="d959" class="nu lc it np b gy nv nw l nx ny">def tokenizer_stemmer(text):</span><span id="deda" class="nu lc it np b gy nz nw l nx ny">return[porter.stem(word) for word in text.split()]</span><span id="75bd" class="nu lc it np b gy nz nw l nx ny">tokenizer_stemmer(‘runners like running thus they run’)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/e021c254eae7c649bd39da40b727a328.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UIuOzeRANdLc9Z3YH6iIsA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><code class="fe nm nn no np b">tokenizer_stemmer</code>功能去掉了派生词缀</p></figure><h1 id="1a82" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">6.将文本数据转换为 TD-IDF 向量</h1><p id="b8ec" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">我们已经在之前的示例文档中完成了这种 TD-IDF 转换，但是现在我们将<code class="fe nm nn no np b">fit_transform</code> <em class="mp"> </em>我们的电影评论数据集填充到 TD-IDF 值中。然而，我们没有将这个过程分成几个步骤——将文档分成词频，然后将它们转换成 TD-IDF 值——而是实现了一个方法<code class="fe nm nn no np b">TfidfVectorizer</code> <em class="mp"> </em>,该方法在一个单独的步骤中执行上述所有步骤。</p><pre class="kj kk kl km gt nq np nr ns aw nt bi"><span id="138b" class="nu lc it np b gy nv nw l nx ny">from sklearn.feature_extraction.text import TfidfVectorizer</span><span id="0b14" class="nu lc it np b gy nz nw l nx ny">tfidf = TfidfVectorizer(strip_accents=None,</span><span id="8924" class="nu lc it np b gy nz nw l nx ny">lowercase=True,</span><span id="e22e" class="nu lc it np b gy nz nw l nx ny">preprocessor=preprocessor, # defined preprocessor in Data Cleaning</span><span id="69fc" class="nu lc it np b gy nz nw l nx ny">tokenizer=tokenizer_stemmer,</span><span id="b693" class="nu lc it np b gy nz nw l nx ny">use_idf=True,</span><span id="a4d0" class="nu lc it np b gy nz nw l nx ny">norm=’l2',</span><span id="5800" class="nu lc it np b gy nz nw l nx ny">smooth_idf=True)</span><span id="bc22" class="nu lc it np b gy nz nw l nx ny">y = df.sentiment.values</span><span id="db36" class="nu lc it np b gy nz nw l nx ny">X = tfidf.fit_transform(df.review)</span></pre><h1 id="0f85" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">7.使用逻辑回归的文档分类</h1><p id="543a" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">使用 X 和 y 分别作为我们的 TD-IDF 值的特征矩阵和情感值的目标向量，我们准备将我们的数据集分成训练集和测试集。然后，我们将把我们的训练集放入逻辑回归模型中。</p><p id="2369" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">请注意，我们不是手动调整我们的模型的超参数，而是使用<code class="fe nm nn no np b">LogisticRegressionCV</code>来指定我们想要调整超参数的交叉验证折叠数——即 5 重交叉验证。</p><pre class="kj kk kl km gt nq np nr ns aw nt bi"><span id="2073" class="nu lc it np b gy nv nw l nx ny">from sklearn.model_selection import train_test_split</span><span id="7329" class="nu lc it np b gy nz nw l nx ny">import pickle</span><span id="d28f" class="nu lc it np b gy nz nw l nx ny">from sklearn.linear_model import LogisticRegressionCV</span><span id="a1ee" class="nu lc it np b gy nz nw l nx ny">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.5, shuffle=False)</span><span id="e165" class="nu lc it np b gy nz nw l nx ny">clf = LogisticRegressionCV(cv=5,</span><span id="1bf1" class="nu lc it np b gy nz nw l nx ny">scoring=’accuracy’,</span><span id="15b3" class="nu lc it np b gy nz nw l nx ny">random_state=0,</span><span id="7082" class="nu lc it np b gy nz nw l nx ny">n_jobs=-1,</span><span id="b8fa" class="nu lc it np b gy nz nw l nx ny">verbose=3,</span><span id="4d79" class="nu lc it np b gy nz nw l nx ny">max_iter=300).fit(X_train, y_train)</span></pre><h1 id="a894" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">8.模型评估</h1><p id="7949" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">最后，我们将传递我们的测试数据——我们的模型以前没有见过的数据——来推断我们的模型做得有多好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/6e15453d828df01fee6899d9027c9ef4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m02IBxgkCsBDFC_YLYTOSg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">准确度分数</p></figure><p id="b1dc" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">89.6% —考虑到我们在研究中使用了一个相对简单的模型，这已经很不错了！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/11c44a20290596e7e9c8c4c5802fb07d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o65y-9jNt-kdASBlL4SUHQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">混淆矩阵</p></figure><p id="3c51" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">另一种观察我们的分类器准确性的方法是通过<strong class="lv iu">混淆矩阵</strong>。</p><p id="c006" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">观察第一排。第一行是测试集中实际情感值为 1 的评论。你可以计算出，在 25000 条评论中，12473 条评论的情感值是 1；在这 12，473 个中，分类器正确地预测了其中的 11，209 个为 1。</p><p id="c27c" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">这意味着，对于 11，209 条评论，测试集中的实际情感值为 1，分类器也正确地预测了这些值为 1。然而，虽然 1264 条评论的实际标签是 1，但分类器预测它们是 0，这相当不错。</p><p id="e015" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">情感值为 0 的评论怎么办？让我们看看第二排。看起来总共有 12，527 条评论的实际情感值为 0。</p><p id="9552" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">分类器将其中的 11，193 个正确预测为 0，将其中的 1，334 个错误预测为 1。因此，它在预测情感值为 0 的评论方面做得很好。</p><p id="6a76" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">混淆矩阵的一个好处是它显示了模型正确预测或区分类别的能力。在二元分类器的特定情况下，比如这个例子，我们可以将这些数字解释为真阳性、假阳性、真阴性和假阴性的计数。</p><h1 id="392b" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">9.结论</h1><p id="e1a9" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在这项研究中，我们涵盖了以下主题:</p><ul class=""><li id="cc10" class="mv mw it lv b lw mq lz mr mc mx mg my mk mz mo na nb nc nd bi translated">清理和预处理文本数据</li><li id="2728" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo na nb nc nd bi translated">使用计数矢量化、术语频率和逆向文档频率、自然语言工具包等方法执行特征提取</li><li id="a883" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo na nb nc nd bi translated">使用 scikit-learn 构建并采用了一个逻辑回归模型</li><li id="4927" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni mo na nb nc nd bi translated">使用 Javan 的准确度分数和混淆矩阵进行模型评估</li></ul><h1 id="c0ae" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">10.引用和参考文献</h1><p id="85bd" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">[1]安德鲁·马斯、雷蒙德·戴利、彼得·范、黄丹、安德鲁·吴和克里斯托弗·波茨。(2011).<a class="ae ky" href="https://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf" rel="noopener ugc nofollow" target="_blank">学习用于情感分析的词向量。</a> <em class="mp">计算语言学协会第 49 届年会(ACL 2011)。</em></p><p id="6268" class="pw-post-body-paragraph lt lu it lv b lw mq ju ly lz mr jx mb mc ms me mf mg mt mi mj mk mu mm mn mo im bi translated">[2]用于 CSV 文件和笔记本的 Github 库:【https://github.com/TheClub4/IMDB_Sentiment_Analysis】T5<br/></p></div></div>    
</body>
</html>