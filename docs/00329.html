<html>
<head>
<title>Edge AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">边缘人工智能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/edge-ai-cc478f9fbb5a?source=collection_archive---------17-----------------------#2020-01-10">https://towardsdatascience.com/edge-ai-cc478f9fbb5a?source=collection_archive---------17-----------------------#2020-01-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/b395874d6904cf974a9a32a8c2f2b889.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OlARQVMn-YREMzTa"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">亚历山大·戈德罗在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="40af" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Edge AI到底是什么意思？这个问题我被问了好几次，我决定分享一下我对这个话题的想法。边缘人工智能通常指在设备上本地运行人工智能算法所需的组件，也称为设备上人工智能。最近，这意味着在设备上运行深度学习算法，大多数文章倾向于只关注一个组件，即推理。这篇文章将揭示这个难题的其他部分。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="9de8" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">实验装置</h1><p id="bef7" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">边缘设备在成本/性能方面差异很大，为了使讨论更加具体，下面是本系列中使用的实验设置:</p><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/f00a7bd22cfad52ddbc6672626a51e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9vYfUF1zawgOBfy7pExwvQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">高通骁龙855开发套件[ <a class="ae kc" href="https://www.intrinsyc.com/snapdragon-embedded-development-kits/snapdragon-855-hdk/" rel="noopener ugc nofollow" target="_blank"> 4 </a></p></figure><ul class=""><li id="fa7b" class="mq mr iq kf b kg kh kk kl ko ms ks mt kw mu la mv mw mx my bi translated">高通骁龙855开发套件。</li><li id="97ee" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">对象检测作为要在边缘设备上运行的深度学习模型。有很多很好的文章描述了物体检测的最新技术[<a class="ae kc" href="https://arxiv.org/pdf/1905.05055.pdf" rel="noopener ugc nofollow" target="_blank">调查</a>论文]。在本系列中，我们将使用<a class="ae kc" href="https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json" rel="noopener ugc nofollow" target="_blank"> Mobilenet SSD </a>模型进行对象检测。</li><li id="49ac" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated"><a class="ae kc" href="https://www.tensorflow.org/js/" rel="noopener ugc nofollow" target="_blank"> Tensorflowjs </a>在nodejs环境中快速运行对象检测模型</li></ul></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="031a" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">为什么要在Edge上运行人工智能算法</h1><p id="7dc5" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">为什么不能依靠云端运行AI算法？毕竟，在云上扩展资源以运行人工智能/深度学习模型来满足您的性能需求更容易。那么，为什么要担心在计算和功耗受限的边缘设备上运行它们呢？为了回答这个问题，让我们考虑两种情况:</p><p id="4661" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">a)基于云的架构，其中推理发生在云上。</p><p id="42e1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">b)基于边缘的架构，其中推断在设备上本地发生。</p><p id="38cb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(<em class="ne">为了尽可能公平地进行比较，在这两种情况下，都将使用nodejs服务器以及</em><a class="ae kc" href="https://www.tensorflow.org/js/guide/nodejs#vanilla_cpu" rel="noopener ugc nofollow" target="_blank"><em class="ne">【tensorflowjs】</em></a><em class="ne">【仅cpu】，唯一的区别在于，在</em> <strong class="kf ir"> <em class="ne">情况a) </em> </strong> <em class="ne">中，web服务器将在EC2实例上运行，而在</em> <strong class="kf ir"> <em class="ne">情况b) </em> </strong> <em class="ne">中，web服务器将在边缘设备上本地运行【T19这里的目标<em class="ne">不是拥有一个平台(云或边缘)的优化实现，而是拥有一个框架来进行公平的比较。)</em></em></p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h2 id="58b0" class="nf lj iq bd lk ng nh dn lo ni nj dp ls ko nk nl lw ks nm nn ma kw no np me nq bi translated">基于云的架构</h2><p id="12c3" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">这是基于云的设置的样子，它将包括下面详细描述的步骤:</p><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/37505cc338c55bd5e35b5a4a6bbe757d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BHATmUJ7PAQ5s3_jfU2WAw.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">用于推理的纯云架构。(结尾的图像参考)。</p></figure><h2 id="0840" class="nf lj iq bd lk ng nh dn lo ni nj dp ls ko nk nl lw ks nm nn ma kw no np me nq bi translated">步骤1:请求输入图像</h2><p id="027e" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">这里有两种可能的选择:</p><ul class=""><li id="a898" class="mq mr iq kf b kg kh kk kl ko ms ks mt kw mu la mv mw mx my bi translated">我们可以从边缘设备发送从相机捕获的原始图像(RGB或YUV)。原始图像总是更大，发送到云需要更长时间。</li><li id="5121" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">我们可以在发送之前将原始图像编码为JPEG/PNG或其他一些有损格式，在运行推理之前在云上将它们解码回原始图像。这种方法将涉及解码压缩图像的额外步骤，因为大多数深度学习模型都是用原始图像训练的。在本系列的后续文章中，我们将涉及更多关于不同raw图像格式的内容。</li></ul><p id="2ac9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使设置简单，使用第一种方法[RGB图像]。HTTP也被用作向REST端点发送图像的通信协议(http:// <ip-address> : <port> /detect)。</port></ip-address></p><h2 id="84a8" class="nf lj iq bd lk ng nh dn lo ni nj dp ls ko nk nl lw ks nm nn ma kw no np me nq bi translated">步骤2:在云上运行推理</h2><ul class=""><li id="43a3" class="mq mr iq kf b kg mg kk mh ko ns ks nt kw nu la mv mw mx my bi translated"><a class="ae kc" href="https://www.tensorflow.org/js/guide/nodejs" rel="noopener ugc nofollow" target="_blank"> tensorflowjs </a>用于在EC2 (t2.micro)实例上运行推理，仅使用单个nodejs工作实例(<em class="ne">无负载平衡、无故障转移等</em>)。</li><li id="a83a" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">使用的Mobilenet版本在这里托管<a class="ae kc" href="https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="8d5b" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated"><a class="ae kc" href="https://httpd.apache.org/docs/2.4/programs/ab.html" rel="noopener ugc nofollow" target="_blank">Apache Bench</a>(<strong class="kf ir">ab</strong>)用于收集HTTP请求的延迟数。为了使用<strong class="kf ir"> ab </strong>，RGB图像被base64编码并发布到端点。<a class="ae kc" href="https://www.npmjs.com/package/express-fileupload" rel="noopener ugc nofollow" target="_blank"> express-fileupload </a>用于处理发布后的图像。</li></ul><p id="5c09" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ne">总延迟(RGB) = Http请求+推理时间+ Http响应</em></p><pre class="mm mn mo mp gt nv nw nx ny aw nz bi"><span id="6db3" class="nf lj iq nw b gy oa ob l oc od"><strong class="nw ir">ab -k -c 1 -n 250 -g out_aws.tsv -p post_data.txt -T "multipart/form-data; boundary=1234567890" </strong><a class="ae kc" href="http://10.221.1.231/detect" rel="noopener ugc nofollow" target="_blank"><strong class="nw ir">http://&lt;ip-address&gt;:&lt;port&gt;/detect</strong></a></span><span id="a5b3" class="nf lj iq nw b gy oe ob l oc od">This is ApacheBench, Version 2.3 &lt;$Revision: 1843412 $&gt;<br/>Copyright 1996 Adam Twiss, Zeus Technology Ltd, <a class="ae kc" href="http://www.zeustech.net/" rel="noopener ugc nofollow" target="_blank">http://www.zeustech.net/</a><br/>Licensed to The Apache Software Foundation, <a class="ae kc" href="http://www.apache.org/" rel="noopener ugc nofollow" target="_blank">http://www.apache.org/</a></span><span id="8f5e" class="nf lj iq nw b gy oe ob l oc od">Benchmarking &lt;ip-address&gt; (be patient)<br/>Completed 100 requests<br/>Completed 200 requests<br/>Finished 250 requests</span><span id="21e4" class="nf lj iq nw b gy oe ob l oc od">Server Software:<br/>Server Hostname:        &lt;ip-address&gt;<br/>Server Port:            &lt;port&gt;</span><span id="4ee1" class="nf lj iq nw b gy oe ob l oc od">Document Path:          /detect<br/>Document Length:        22610 bytes</span><span id="5e0f" class="nf lj iq nw b gy oe ob l oc od">Concurrency Level:      1<br/>Time taken for tests:   170.875 seconds<br/>Complete requests:      250<br/>Failed requests:        0<br/>Keep-Alive requests:    250<br/>Total transferred:      5705000 bytes<br/>Total body sent:        50267500<br/>HTML transferred:       5652500 bytes<br/>Requests per second:    1.46 [#/sec] (mean)<br/>Time per request:       683.499 [ms] (mean)<br/>Time per request:       683.499 [ms] (mean, across all concurrent requests)<br/>Transfer rate:          32.60 [Kbytes/sec] received<br/>                        287.28 kb/s sent<br/>                        319.89 kb/s total</span><span id="161f" class="nf lj iq nw b gy oe ob l oc od">Connection Times (ms)<br/>              min  mean[+/-sd] median   max<br/>Connect:        0    0   5.0      0      79<br/>Processing:   530  683 258.2    606    2751<br/>Waiting:      437  513 212.9    448    2512<br/>Total:        530  683 260.7    606    2771</span><span id="f1fa" class="nf lj iq nw b gy oe ob l oc od">Percentage of the requests served within a certain time (ms)<br/>  50%    606<br/>  66%    614<br/>  75%    638<br/>  80%    678<br/>  90%    812<br/><strong class="nw ir">  95%   1084</strong><br/>  98%   1625<br/>  99%   1720<br/> 100%   2771 (longest request)</span></pre><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/407fba2fe3566c9adb23632aa394178d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rav7lQHEILx5xjEuiJID4w.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">基于云的架构的端到端推理延迟直方图(桶大小为1s)。它显示了Apache Bench (ab)在给定时间内生成的请求的推理延迟。</p></figure><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/1f1e08b0abf4021bc65d1869c42bd9bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tHXTyRXPPRxeYoIKqtoFGA.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">基于云的体系结构的端到端推理延迟按响应时间(毫秒)排序。这篇文章解释了这两个情节的区别。</p></figure><p id="309a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们在这里看到的，95%的请求延迟大约为<strong class="kf ir">1084毫秒</strong>。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h2 id="7561" class="nf lj iq bd lk ng nh dn lo ni nj dp ls ko nk nl lw ks nm nn ma kw no np me nq bi translated">基于边缘的架构</h2><p id="c125" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">Web服务器(运行tensorflowjs)在本地边缘设备上运行(高通骁龙855开发套件[ <a class="ae kc" href="https://www.intrinsyc.com/snapdragon-embedded-development-kits/snapdragon-855-hdk/" rel="noopener ugc nofollow" target="_blank"> 4 </a> ])。我们使用Apache Bench重复相同的步骤(这次是对本地主机而不是远程服务器的http请求),结果如下。</p><pre class="mm mn mo mp gt nv nw nx ny aw nz bi"><span id="0230" class="nf lj iq nw b gy oa ob l oc od"><strong class="nw ir">ab -k -c 1 -n 250 -g out_device.tsv -p post_data.txt -T "multipart/form-data; boundary=1234567890" </strong><a class="ae kc" href="http://10.221.1.231/detect" rel="noopener ugc nofollow" target="_blank"><strong class="nw ir">http://localhost:3000/detect</strong></a></span><span id="b999" class="nf lj iq nw b gy oe ob l oc od">This is ApacheBench, Version 2.3 &lt;$Revision: 1843412 $&gt;<br/>Copyright 1996 Adam Twiss, Zeus Technology Ltd, <a class="ae kc" href="http://www.zeustech.net/" rel="noopener ugc nofollow" target="_blank">http://www.zeustech.net/</a><br/>Licensed to The Apache Software Foundation, <a class="ae kc" href="http://www.apache.org/" rel="noopener ugc nofollow" target="_blank">http://www.apache.org/</a></span><span id="84e7" class="nf lj iq nw b gy oe ob l oc od">Benchmarking localhost (be patient)<br/>Completed 100 requests<br/>Completed 200 requests<br/>Finished 250 requests</span><span id="e63c" class="nf lj iq nw b gy oe ob l oc od">Server Software:        <br/>Server Hostname:        localhost<br/>Server Port:            3000</span><span id="35bd" class="nf lj iq nw b gy oe ob l oc od">Document Path:          /detect<br/>Document Length:        22610 bytes</span><span id="87a3" class="nf lj iq nw b gy oe ob l oc od">Concurrency Level:      1<br/>Time taken for tests:   80.689 seconds<br/>Complete requests:      250<br/>Failed requests:        0<br/>Keep-Alive requests:    250<br/>Total transferred:      5705000 bytes<br/>Total body sent:        50267750<br/>HTML transferred:       5652500 bytes<br/>Requests per second:    3.10 [#/sec] (mean)<br/>Time per request:       322.755 [ms] (mean)<br/>Time per request:       322.755 [ms] (mean, across all concurrent requests)<br/>Transfer rate:          69.05 [Kbytes/sec] received<br/>                        608.38 kb/s sent<br/>                        677.43 kb/s total</span><span id="ba18" class="nf lj iq nw b gy oe ob l oc od">Connection Times (ms)<br/>              min  mean[+/-sd] median   max<br/>Connect:        0    0   0.1      0       2<br/>Processing:   290  323  36.0    317     737<br/>Waiting:      290  322  36.0    316     736<br/>Total:        290  323  36.1    317     739</span><span id="8f86" class="nf lj iq nw b gy oe ob l oc od">Percentage of the requests served within a certain time (ms)<br/>  50%    317<br/>  66%    323<br/>  75%    328<br/>  80%    331<br/>  90%    341<br/> <strong class="nw ir"> 95%    357</strong><br/>  98%    397<br/>  99%    473<br/> 100%    739 (longest request)</span></pre><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/ccdb5fb2ea90b5726201317e315d7a48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wk0Gaz2aguzdsZBaRM_HSQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">基于边缘的架构的端到端推理延迟直方图(桶大小为1s)。它显示了Apache Bench (ab)在给定时间内生成的请求的推理延迟。</p></figure><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/0256898390f52f82cdbc7d36e58bf733.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TvMfsuS_2KuX4jWgJh-fvQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">基于边缘的体系结构的端到端推理延迟按响应时间(毫秒)排序。这篇文章解释了这两块地的区别。</p></figure><p id="6ff2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们在这里看到的，95%的请求延迟大约为<strong class="kf ir">357毫秒</strong>。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="2752" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">优化机会</h1><p id="c9d9" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">正如您所看到的，延迟数字相当高，我们在这里获得的数字更像是上限延迟，有许多优化机会，其中一些详述如下:</p><p id="92f7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于云的架构:</p><ul class=""><li id="8507" class="mq mr iq kf b kg kh kk kl ko ms ks mt kw mu la mv mw mx my bi translated">拥有多个nodejs worker实例，并在它们之间实现负载平衡。</li><li id="fa71" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">有多个部署(美国东部、美国西部等)并将请求发送到最近的部署。</li><li id="0700" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">批量处理多个输入图像，并在云上运行批量推理。</li><li id="dc99" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">拥有一个基于<a class="ae kc" href="https://aws.amazon.com/ec2/instance-types/p3/" rel="noopener ugc nofollow" target="_blank"> gpu的EC2实例</a>并使用<a class="ae kc" href="https://www.npmjs.com/package/@tensorflow/tfjs-node-gpu" rel="noopener ugc nofollow" target="_blank"> tensorflow-node-gpu </a>来加速推理</li><li id="04df" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">使用不同的通信协议，如<a class="ae kc" href="http://mqtt.org/" rel="noopener ugc nofollow" target="_blank"> MQTT </a>更适合IOT /云连接，以避免HTTP的开销。</li></ul><p id="90ca" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于边缘的架构:</p><ul class=""><li id="670d" class="mq mr iq kf b kg kh kk kl ko ms ks mt kw mu la mv mw mx my bi translated">针对您的边缘设备进行优化实施。在这种情况下，对于高通骁龙855开发套件[ <a class="ae kc" href="https://www.intrinsyc.com/snapdragon-embedded-development-kits/snapdragon-855-hdk/" rel="noopener ugc nofollow" target="_blank"> 4 </a> ]推理将在GPU / DSP或其<a class="ae kc" href="https://www.qualcomm.com/news/releases/2019/02/25/artificial-intelligence-engine-qualcomm-snapdragon-855-mobile-platform" rel="noopener ugc nofollow" target="_blank"> NPU </a>上加速。</li><li id="3a94" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">最有可能的是，在设备上的实现将通过供应商框架依赖于本地库，如<a class="ae kc" href="https://developer.qualcomm.com/docs/snpe/overview.html" rel="noopener ugc nofollow" target="_blank"> SNPE </a>或<a class="ae kc" href="https://www.tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"> tensorflow-lite </a>。</li><li id="6d5a" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">优化数据路径，包括从相机捕捉图像到输入深度学习模型以运行推理。</li></ul><h1 id="7832" class="li lj iq bd lk ll og ln lo lp oh lr ls lt oi lv lw lx oj lz ma mb ok md me mf bi translated">结论</h1><p id="7a49" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我们详细研究了决定您是否需要基于边缘的解决方案的一个因素，因为我们发现如果您的应用能够容忍云延迟，那么基于云的推理将是最快的方式。但是，如果您的应用对延迟敏感，那么您可以考虑基于边缘的解决方案。请确保对您的特定用例进行基准测试，从中选择一个。除了延迟之外，考虑基于边缘的解决方案还有其他一些原因:</p><ul class=""><li id="bddd" class="mq mr iq kf b kg kh kk kl ko ms ks mt kw mu la mv mw mx my bi translated">您已经部署了边缘设备，并希望利用它来节省云计算成本。</li><li id="4c40" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">隐私，你不希望数据离开边缘设备。</li><li id="904d" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">与云没有完全连接或连接性差的设备，基于边缘的解决方案成为必然</li></ul><h2 id="b30b" class="nf lj iq bd lk ng nh dn lo ni nj dp ls ko nk nl lw ks nm nn ma kw no np me nq bi translated">参考</h2><p id="fde9" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">[1]<a class="ae kc" href="https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&amp;type=detection&amp;c=%2Fm%2F0k4j&amp;id=101c3faac77e2e29" rel="noopener ugc nofollow" target="_blank">https://storage . Google APIs . com/open images/web/visualizer/index . html？set = train&amp;type = detection&amp;c = % 2Fm % 2f 0k 4j&amp;id = 101 C3 faac 77 e 2e 29</a>—来自<a class="ae kc" href="https://storage.googleapis.com/openimages/web/index.html" rel="noopener ugc nofollow" target="_blank">开放图像数据集V5 </a>的汽车覆盖图像</p><p id="e0c7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2]<a class="ae kc" href="https://c2.staticflickr.com/7/6021/6005573548_11b7b17c9b_o.jpg" rel="noopener ugc nofollow" target="_blank">https://C2 . static Flickr . com/7/6021/6005573548 _ 11 b 7 b 17 c 9 b _ o . jpg</a>—原车图片</p><p id="d6e5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3]<a class="ae kc" href="https://pixabay.com/illustrations/google-pixel-3-google-cell-phone-3738925/" rel="noopener ugc nofollow" target="_blank">https://pix abay . com/illustrations/Google-Pixel-3-Google-cell-Phone-3738925/</a>—Pixel手机图片。</p><p id="e968" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4]<a class="ae kc" href="https://www.intrinsyc.com/snapdragon-embedded-development-kits/snapdragon-855-hdk/" rel="noopener ugc nofollow" target="_blank">https://www . Intrinsyc . com/snapdragon-embedded-Development-kits/snapdragon-855-hdk/</a>—Intrinsyc开发套件</p><p id="91f5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[5]<a class="ae kc" href="http://www.bradlanders.com/2013/04/15/apache-bench-and-gnuplot-youre-probably-doing-it-wrong/" rel="noopener ugc nofollow" target="_blank">http://www . bradlanders . com/2013/04/15/Apache-bench-and-gnuplot-you-possible-do-it-wrong/</a></p></div></div>    
</body>
</html>