# Twitter JSON æ•°æ®å¤„ç†

> åŸæ–‡ï¼š<https://towardsdatascience.com/twitter-json-data-processing-3f353a5deac4?source=collection_archive---------7----------------------->

## ä½¿ç”¨ python åº“æ¸…ç†å’Œæ¶¦è‰²ç”¨äºç¤¾äº¤åª’ä½“åˆ†æçš„æ¨æ–‡æ•°æ®å¸§ã€‚

![](img/e1927918cbb6d5c984959ea19028e192.png)

ç”±[æ‹‰ç»´Â·å¤å°”é©¬](https://unsplash.com/@ravinepz?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) æ‹æ‘„çš„ç…§ç‰‡

witter å…è®¸ä½¿ç”¨ç”¨äºè®¿é—® Twitter API çš„ Python åº“ tweepy æ¥æ”¶é›† tweepyã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä¸æ‰“ç®—ç»™å‡ºå¦‚ä½•æ”¶é›† tweet çš„æ•™ç¨‹ï¼Œå› ä¸ºå·²ç»æœ‰ä¸€äº›å¥½çš„è¯„è®ºäº†(çœ‹çœ‹ä¸‹é¢çš„å‚è€ƒèµ„æ–™)ï¼Œè€Œæ˜¯ç»™ä½ ä¸€ä¸ªå®Œæ•´çš„ä¾‹å­ï¼Œè¯´æ˜å¦‚ä½•å¤„ç† tweet å¯¹è±¡ï¼Œä»¥ä¾¿å»ºç«‹ä¸€ä¸ªå¹²å‡€çš„æ•°æ®æ¡†æ¶ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™ä¸ªæ¡†æ¶ä¸Šè¿›è¡Œç¤¾äº¤åª’ä½“åˆ†æã€‚

**TLï¼›TR:** åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å±•å¹³ Twitter JSONï¼Œåœ¨å‡ ä¸ªé€‰é¡¹(ä¸»æ¨ã€è½¬å‘ã€å¼•ç”¨ç­‰)ä¸­é€‰æ‹©æ–‡æœ¬å¯¹è±¡ã€‚)ï¼Œæ¸…ç†å®ƒä»¬(åˆ é™¤éå­—æ¯å­—ç¬¦)ï¼Œç¿»è¯‘éè‹±è¯­æ¨æ–‡ï¼Œè®¡ç®—æ–‡æœ¬çš„æƒ…æ„Ÿï¼Œä»¥åŠå…³è”ç»™å®šç”¨æˆ·å®šä¹‰çš„ä½ç½®æˆ–è‡ªåŠ¨åœ°ç†å®šä½çš„ä½ç½®ã€‚

**è¦ä½¿ç”¨çš„åº“:** [ç†ŠçŒ«](https://pandas.pydata.org)[å›½å®¶è½¬æ¢å™¨](https://pypi.org/project/country-converter/)[GeoPy](https://geopy.readthedocs.io/en/stable/#)[spaCy](https://spacy.io)[Google trans](https://pypi.org/project/googletrans/)[NLTK](https://www.nltk.org)ã€‚

æ¯ä¸ª [*tweet å¯¹è±¡*](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object) ä»¥ JSON æ ¼å¼å‡ºç°ï¼Œ*æ··åˆäº†â€œæ ¹çº§â€å±æ€§å’Œå­å¯¹è±¡(ç”¨* `*{}*` *ç¬¦å·è¡¨ç¤º)*ã€‚Twitter å¼€å‘è€…é¡µé¢ç»™å‡ºäº†ä»¥ä¸‹ä¾‹å­:

```
{
 "created_at": "Wed Oct 10 20:19:24 +0000 2018",
 "id": 1050118621198921728,
 "id_str": "1050118621198921728",
 "text": "To make room for more expression, we will now count all emojis as equalâ€”including those with genderâ€â€â€ â€â€and skin tâ€¦ https://t.co/MkGjXf9aXm",
 "user": {},  
 "entities": {}
}
```

å½“ç„¶ï¼Œè¿™åªæ˜¯ç»„æˆæ¯æ¡æ¨æ–‡çš„åºå¤§å­—å…¸ä¸­çš„ä¸€å°éƒ¨åˆ†ã€‚å¦ä¸€ä¸ªæµè¡Œçš„ä¾‹å­æ˜¯è¿™ä¸ª [Twitter çŠ¶æ€å¯¹è±¡å›¾](http://www.slaw.ca/wp-content/uploads/2011/11/map-of-a-tweet-copy.pdf)ã€‚

å¯¹äºå¤§å¤šæ•°ç±»å‹çš„åˆ†æï¼Œæˆ‘ä»¬è‚¯å®šéœ€è¦å±æ€§ï¼Œå¦‚ tweet æ–‡æœ¬ã€ç”¨æˆ·å±å¹•åç§°æˆ– tweet ä½ç½®ã€‚ä¸å¹¸çš„æ˜¯ï¼Œæ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„ï¼Œè¿™äº›å±æ€§æ²¡æœ‰ä¸€ä¸ªæ¸…æ™°çš„æ ¼å¼ï¼Œç›¸åï¼Œå®ƒä»¬åˆ†å¸ƒåœ¨ JSON çš„å„ä¸ªå±‚æ¬¡ä¸Šâ€”â€”ä¾‹å¦‚ï¼Œtweet ä½ç½®åæ ‡ä½äº

```
tweet_object['place']['bounding_box']['coordinates']
```

æ­£æ˜¯ç”±äºè¿™ä¸€äº‹å®ï¼Œæ”¶é›†çš„æ¨æ–‡éœ€è¦ä¸€ä¸ªå¤§çš„æ¸…ç†å’Œè½¬æ¢è¿‡ç¨‹ï¼Œè¿™å°±æ˜¯è¿™ç¯‡æ–‡ç« çš„ç›®çš„ã€‚

## æ¨ç‰¹æ•°æ®

æˆ‘æœ€è¿‘è¿›è¡Œäº†ä¸€ä¸ª[è¯­è¨€æœ¬åœ°åŒ–](https://en.wikipedia.org/wiki/Language_localisation)é¡¹ç›®ï¼Œæˆ‘éœ€è¦åœ¨ Twitter ä¸Šåšä¸€ä¸ªç¤¾äº¤åª’ä½“åˆ†æã€‚ä¸ºæ­¤ï¼Œæˆ‘åœ¨å‡ å¤©çš„æ—¶é—´é‡Œæ”¶é›†äº† **52830 æ¡**åŒ…å«ä»¥ä¸‹å…³é”®è¯çš„æ¨æ–‡: **'#FIFA20'** ï¼Œ' **#FIFA21'** ï¼Œ **'FIFA20'** ï¼Œ **'FIFA21'** ï¼Œ **'FIFA 20'** ï¼Œ **'FIFA 21'** å’Œ**' # easporter ç„¶åï¼Œä¸ºäº†å¯¹å®ƒä»¬è¿›è¡Œæ­£ç¡®çš„åˆ†æï¼Œæˆ‘å¿…é¡»äº‹å…ˆæ¸…ç†æ¯ä¸ª tweet å¯¹è±¡ï¼Œè¿™æ ·æˆ‘æ‰èƒ½å¾—å‡ºæœ‰æ„ä¹‰çš„ç»“è®ºã€‚**

ç”±äºè¯¥é¡¹ç›®çš„æ€§è´¨ï¼Œæˆ‘ä¸»è¦æ„Ÿå…´è¶£çš„æ˜¯å…³äºæ¨æ–‡ä½ç½®çš„æ•°æ®(å›½å®¶å’Œåæ ‡)ï¼Œè‹±æ–‡ç‰ˆæœ¬æ–‡æœ¬çš„æƒ…æ„Ÿï¼Œä»¥åŠæ¨æ–‡ä½¿ç”¨çš„è¯­è¨€ã€‚åŠ å·¥æ­¥éª¤çš„ç›®æ ‡æ˜¯å®Œå–„å’Œå‘ç°è¿™äº›å±æ€§ã€‚æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹å­˜å‚¨åº“ä¸­æ‰¾åˆ°è¯¥é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯:

[](https://github.com/hectoramirez/Language-localization_FIFA) [## hectoramirez/è¯­è¨€-æœ¬åœ°åŒ– _FIFA

### è¿™æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„é¡¹ç›®ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰§è¡Œå›½é™…è¶³è”è§†é¢‘æ¸¸æˆçš„è¯­è¨€æœ¬åœ°åŒ–ï¼Œåªæœ‰å…¬ä¼—â€¦

github.com](https://github.com/hectoramirez/Language-localization_FIFA) 

è®©æˆ‘ä»¬ç”¨è¿™ä¸ªæ•°æ®é›†æ¥ä¸¾ä¾‹è¯´æ˜ tweets å¤„ç†çš„æ­¥éª¤ï¼

# å¤„ç† JSON

æ­£å¦‚æˆ‘ä»¬çœ‹åˆ°çš„ï¼Œåœ¨åŒ…å«æ–‡æœ¬æ•°æ®çš„ [Twitter JSON](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object) ä¸­æœ‰å¤šä¸ªå­—æ®µã€‚åœ¨å…¸å‹çš„ tweet ä¸­ï¼Œæœ‰ tweet æ–‡æœ¬ã€ç”¨æˆ·æè¿°å’Œç”¨æˆ·ä½ç½®ã€‚åœ¨è¶…è¿‡ 140 ä¸ªå­—ç¬¦çš„ tweet ä¸­ï¼Œè¿˜æœ‰æ‰©å±• tweet å­ JSONã€‚åœ¨å¼•ç”¨çš„æ¨æ–‡ä¸­ï¼Œæœ‰åŸå§‹æ¨æ–‡å’Œå¼•ç”¨æ¨æ–‡çš„è¯„è®ºã€‚

ä¸ºäº†å¤§è§„æ¨¡åˆ†æ tweetï¼Œæˆ‘ä»¬éœ€è¦å°† tweet JSON æ‰å¹³åŒ–ä¸ºä¸€ä¸ªå±‚æ¬¡ã€‚è¿™å°†å…è®¸æˆ‘ä»¬ä»¥æ•°æ®å¸§æ ¼å¼å­˜å‚¨æ¨æ–‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å®šä¹‰å‡½æ•°`flatten_tweets()`ï¼Œè¯¥å‡½æ•°å°†æ¥å—å‡ ä¸ªå…³äºæ–‡æœ¬å’Œä½ç½®çš„å­—æ®µ(è¯¥å­—æ®µå­˜å‚¨åœ¨`place`ä¸­)ã€‚çœ‹ä¸€çœ‹:

ç°åœ¨ï¼Œæ‚¨å¯èƒ½æƒ³è¦ç ”ç©¶æ‰€æœ‰çš„æ–‡æœ¬å­—æ®µ(ä¸»å­—æ®µã€è½¬å‘å­—æ®µæˆ–å¼•ç”¨å­—æ®µ)ï¼Œä½†æ˜¯ï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œè¿™é‡Œæˆ‘åªä¿ç•™ä¸€ä¸ªæ–‡æœ¬å­—æ®µã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ç°åœ¨å®šä¹‰ä¸€ä¸ªå‡½æ•°`select_text(tweets)`æ¥é€‰æ‹©ä¸»è¦æ–‡æœ¬ï¼Œæ— è®ºè¯¥æ¨æ–‡æ˜¯ä¸»è¦æ¨æ–‡è¿˜æ˜¯è½¬å‘æ¨æ–‡ï¼Œæˆ‘ä»¬å†³å®šåˆ é™¤å¼•ç”¨çš„æ–‡æœ¬ï¼Œå› ä¸ºå®ƒé€šå¸¸æ˜¯é‡å¤çš„ï¼Œå¯èƒ½æ²¡æœ‰ä¿¡æ¯ã€‚

æˆ‘ä»¬ç°åœ¨æ„å»ºæ•°æ®æ¡†ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä¸ç¤¾äº¤åª’ä½“åˆ†æç›¸å…³çš„ä¸»è¦åˆ—(å­—æ®µ)ã€‚è¿™åŒ…æ‹¬ tweet è¯­è¨€ã€`lang`å’Œç”±ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®çš„`user-location`ã€‚æˆ‘ä»¬è¿˜ä¿ç•™äº†`place`ä¸­çš„`country`ã€`country_code`å’Œ`coordinates`å­—æ®µã€‚å½“æ¨æ–‡è¢«åœ°ç†æ ‡è®°æ—¶ï¼Œè¿™äº›å­—æ®µå°±ä¼šå‡ºç°ï¼Œå¹¶ä¸”é€šå¸¸åŒ…å«åœ¨ä¸åˆ° 10%çš„æ¨æ–‡ä¸­ã€‚ä»¥ä¸‹ä»£ç å—æ„å»ºäº†æ•°æ®å¸§:

```
**import** **pandas** **as** **pd**

*# flatten tweets*
tweets = flatten_tweets(tweets_data)

*# select text*
tweets = select_text(tweets)
columns = ['text', 'lang', 'user-location', 'place-country', 
           'place-country_code', 'location-coordinates', 
           'user-screen_name']

*# Create a DataFrame from `tweets`*
df_tweets = pd.DataFrame(tweets, columns=columns)*# replaces NaNs by Nones*
df_tweets.where(pd.notnull(df_tweets), **None**, inplace=**True**)
```

æ•°æ®å¸§çš„å¤´éƒ¨çœ‹èµ·æ¥åƒè¿™æ ·:

![](img/1caffdac6adc47e3bf68e2ec17e833fe.png)

df_tweets.head()

![](img/eb2e90d61d6dcaeab0faebf9cde22bcb.png)

df_tweets.info()

è¯·æ³¨æ„ï¼Œå‡ ä¹åªæœ‰ä¸€åŠçš„æ¨æ–‡åŒ…å«æ‰‹åŠ¨è®¾ç½®çš„ç”¨æˆ·ä½ç½®å­—æ®µï¼Œç”šè‡³ 1%çš„æ¨æ–‡éƒ½æ²¡æœ‰åœ°ç†æ ‡è®°ï¼Œ*å³*ï¼Œå®ƒä»¬æ²¡æœ‰æä¾›*ä½ç½®*å­—æ®µã€‚è¿™å‡¸æ˜¾äº†æ”¶é›†å°½å¯èƒ½å¤šçš„æ¨æ–‡çš„é‡è¦æ€§ï¼

åœ¨ä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯æ¸…ç†å’ŒæŠ›å…‰æ¯ä¸ª dataframe åˆ—ã€‚

# è¯­è¨€

åœ¨æµç¨‹çš„è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ç”¨è¯­è¨€æ ‡å‡†åç§°æ›¿æ¢`lang`ä¸­çš„è¯­è¨€ä»£ç ã€‚å¦‚æ–‡æ¡£ä¸­æ‰€è¿°:

> å¦‚æœå­˜åœ¨ï¼Œ[ `lang` ]è¡¨ç¤ºä¸æœºå™¨æ£€æµ‹åˆ°çš„ Tweet æ–‡æœ¬è¯­è¨€ç›¸å¯¹åº”çš„ BCP 47 è¯­è¨€æ ‡è¯†ç¬¦ï¼Œå¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°è¯­è¨€ï¼Œåˆ™ä¸º`*und*`ã€‚

æˆ‘ä»¬ä½¿ç”¨[è¿™ä¸ªåº“](https://github.com/annexare/Countries/tree/master/data)ä¸­çš„è¾…åŠ©`languages.json`æ–‡ä»¶æ¥æ‰§è¡Œè¿™ä¸ªæ­¥éª¤ã€‚è¯¥æ–‡ä»¶å°†è¯­è¨€ä»£ç æ˜ å°„åˆ°è¯­è¨€æ ‡å‡†åç§°ã€‚ä¸‹é¢çš„ä»£ç å°†å®Œæˆè¿™ä¸ªä»»åŠ¡:

```
**with** open('languages.json', 'r', encoding='utf-8') **as** json_file:
    languages_dict = json.load(json_file)names = []
**for** idx, row **in** df_tweets.iterrows():
    lang = row['lang']
    **if** lang == 'und':
        names.append(**None**)
    **elif** lang == 'in':
        name = languages_dict['id']['name']
        names.append(name)
    **elif** lang == 'iw':
        name = languages_dict['he']['name']
        names.append(name)
    **else**:
        name = languages_dict[lang]['name']
        names.append(name)

df_tweets['language'] = names
df_tweets.drop(['lang'], axis=1, inplace=**True**)
```

# ä½ç½®

ç°åœ¨æˆ‘ä»¬å¼€å§‹å¤„ç†ä½ç½®ã€‚æˆ‘ä»¬å°†é¦–å…ˆå¤„ç†`place`å­—æ®µï¼Œç„¶åå¤„ç†`user-location`å­—æ®µã€‚

## åœ°æ–¹

å¾ˆæ˜æ˜¾,`place`å¯¹è±¡ä¸­çš„æ•°æ®æ¯”`user-location`æ›´å¯é ã€‚å› æ­¤ï¼Œè™½ç„¶å®ƒæ„æˆäº†æˆ‘ä»¬æ¨æ–‡çš„ 0.91%ï¼Œä½†æˆ‘ä»¬ä¼šç…§é¡¾å®ƒã€‚é¦–å…ˆï¼Œ`place-country_code`ä¸­çš„å›½å®¶ä»£ç ä»¥ ISO 2 å½¢å¼å‡ºç°ï¼Œä¸ºæ­¤æˆ‘ä»¬å°†ä½¿ç”¨[å›½å®¶è½¬æ¢å™¨](https://github.com/konstantinstadler/country_converter)å°†å…¶è½¬æ¢ä¸º ISO 3 å½¢å¼ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†æ‰§è¡ŒåŒæ ·çš„æ“ä½œï¼Œå°†`place-country`åç§°æ”¹ä¸ºæ ‡å‡†çš„ç®€ç§°ã€‚è¿™æ˜¯æœ‰åˆ©çš„ï¼Œå› ä¸ºï¼Œä¾‹å¦‚ï¼Œ **Plotly åœ°å›¾ä½¿ç”¨ ISO 3 ä»£ç æ¥å®šä½å›½å®¶ã€‚**

## ç”¨æˆ·ä½ç½®

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ‰‹åŠ¨è®¾ç½®çš„`user-locations`ç¿»è¯‘æˆå›½å®¶åç§°å’Œä»£ç â€”â€”è¿™æ¶‰åŠåˆ°å¯¹ç”¨æˆ·çš„ä¿¡ä»»ã€‚æˆ‘ä»¬ä½¿ç”¨ [GeoPy](https://geopy.readthedocs.io/en/latest/#) åº“æ¥è¯†åˆ«ä¸€ä¸ªä½ç½®(å¯èƒ½æ˜¯ä¸€ä¸ªåœ°å€)å¹¶ä¸ºå…¶åˆ†é…ä¸€ä¸ªå›½å®¶ã€‚åŒæ ·ï¼Œæˆ‘ä»¬ä½¿ç”¨`country_converter`æ¥æŸ¥æ‰¾ ISO 3 è¡¨æ ¼ä¸­çš„å›½å®¶ä»£ç ã€‚

**æé†’ä¸€å¥** : GeoPy è¿æ¥åˆ°ä¸€ä¸ª APIï¼Œä¸å¹¸çš„æ˜¯ï¼Œæ¯æ¬¡è°ƒç”¨å‡ ä¹è¦èŠ±ä¸€ç§’é’Ÿã€‚è¿™ä½¿å¾—è®¡ç®—~ 50 K tweets çš„è¿‡ç¨‹ç›¸å½“æ…¢ã€‚

**æ³¨æ„:** [tqdm](https://tqdm.github.io) æ˜¯ä¸€ä¸ª python åº“ï¼Œå¯¹ pandas æœ‰å¾ˆå¥½çš„å®ç°ï¼Œåœ¨ä»£ç è¿è¡Œæ—¶è¾“å‡ºè¿›åº¦æ¡ã€‚è¿™ä¼šè®©ä½ çš„ç”Ÿæ´»æ›´è½»æ¾ï¼

æœ€åï¼Œæˆ‘ä»¬å°†`place-country`å’Œ`user-country`åˆ—å‡å°‘ä¸ºä¸€åˆ—ï¼Œå½“å‰è€…å­˜åœ¨æ—¶ä¿ç•™å‰è€…ï¼Œå¦åˆ™ä¿ç•™åè€…ã€‚æˆ‘ä»¬å¯¹*ä»£ç *åˆ—è¿›è¡ŒåŒæ ·çš„æ“ä½œ:

```
countries, codes = [], []
**for** idx, row **in** df_tweets.iterrows():
    **if** row['place-country_code'] **is** **None**:
        country = row['user-country']
        code = row['user-country_code']
        countries.append(country)
        codes.append(code)
    **else** :
        countries.append(row['place-country'])
        codes.append(row['place-country_code'])

df_tweets['location'] = countries
df_tweets['location_code'] = codes

*# drop old columns*
df_tweets.drop(columns=['place-country', 'place-country_code', 
                 'user-country', 'user-country_code'], inplace=**True**)
```

æ­¤æ—¶ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†å¦‚ä¸‹æ‰€ç¤º:

![](img/97c198724360693985a67290c1d667f0.png)

df_tweets.head()

# æ–‡æœ¬æ¸…ç†

ç°åœ¨æ˜¯å¤„ç†æ¨æ–‡æ–‡æœ¬çš„æ—¶å€™äº†ã€‚è¿™å°†æ¶‰åŠåˆ é™¤éå­—æ¯å­—ç¬¦å’Œç¿»è¯‘éè‹±è¯­æ¨æ–‡ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å°†ä¿ç•™è¿™ä¸¤ä¸ªé€‰é¡¹ï¼Œå¹¶å®é™…ä½¿ç”¨å¸¦æœ‰è¡¨æƒ…ç¬¦å·å’Œå…¶ä»–å­—ç¬¦çš„æ–‡æœ¬è¿›è¡Œåˆ†æï¼Œå› ä¸ºæˆ‘ä»¬çš„æƒ…æ„Ÿåˆ†æå™¨å¯ä»¥å¾ˆå¥½åœ°å¤„ç†å®ƒä»¬ã€‚

è¦åˆ é™¤éå­—æ¯å­—ç¬¦ï¼Œæˆ‘ä»¬ä½¿ç”¨ [spaCy](https://spacy.io/) ï¼Œå› ä¸ºå®ƒéå¸¸ç®€å•ï¼Œæˆ‘ä»¬ä¸éœ€è¦æŒ‡å®šæ­£åˆ™è¡¨è¾¾å¼ã€‚è¯·è®°ä½ï¼Œä¸‹é¢çš„ä»£ç å—åˆ é™¤äº†å¸¦æœ‰æ’‡å·çš„è¡¨æƒ…ç¬¦å·å’Œå•è¯ï¼Œå¦‚â€œæˆ‘æ˜¯â€ã€â€œä½ ä»¬éƒ½æ˜¯â€ã€â€œä¸è¦â€ç­‰ã€‚

```
**import** **spacy**

nlp = spacy.load('en_core_web_sm')

**def** cleaner(string):

    *# Generate list of tokens*
    doc = nlp(string)
    lemmas = [token.lemma_ **for** token **in** doc] *# Remove tokens that are not alphabetic* 
    a_lemmas = [lemma **for** lemma **in** lemmas **if** lemma.isalpha() 
                 **or** lemma == '-PRON-']    *# Print string after text cleaning*
    **return** ' '.join(a_lemmas)

df_tweets['text_cleaned'] = \
                   df_tweets['text'].progress_apply(cleaner)
```

## ç¿»è¯‘

ä¸ºäº†**ç¿»è¯‘**éè‹±è¯­æ¨æ–‡ï¼Œæˆ‘ä»¬ä½¿ç”¨ [googletrans](https://pypi.org/project/googletrans/) ï¼Œä½œä¸º GeoPyï¼Œå®ƒè¿æ¥åˆ°å®ƒçš„ APIï¼Œç„¶è€Œå®ƒè¦å¿«å¾—å¤šã€‚

**å¦ä¸€ä¸ªè­¦å‘Š:**å­˜åœ¨ä¸€ä¸ªè®¨è®ºè¿‡çš„è®°å½•ä¸è‰¯çš„é”™è¯¯ï¼Œ*ä¾‹å¦‚*ï¼Œè¿™é‡Œ:[https://stack overflow . com/questions/49497391/Google trans-API-error-expecting-value-line-1-column-1-char-0](https://stackoverflow.com/questions/49497391/googletrans-api-error-expecting-value-line-1-column-1-char-0)ï¼Œå®ƒä¼šæ–­å¼€æ‚¨çš„è¿æ¥å¹¶é˜»æ­¢æ‚¨çš„ IPã€‚ä¸ºäº†é¿å…è¿™ä¸ªé”™è¯¯ï¼Œæˆ‘ä½¿ç”¨`np.array_split()`å°†æ•°æ®å¸§åˆ†æˆå‡ ä¸ªå—ï¼Œåœ¨ä¸€ä¸ªå¾ªç¯ä¸­ä¸€æ¬¡å¤„ç†ä¸€ä¸ªå—ã€‚é€šè¿‡è¿™æ ·åšï¼Œé”™è¯¯ä¸ä¼šå‘ç”Ÿï¼Œä½†æ˜¯æˆ‘ä»ç„¶å°†æ¯ä¸ªå—çš„ç¿»è¯‘ä¿å­˜åˆ°ä¸€ä¸ª`csv`ä¸­ï¼Œè¿™æ ·å¦‚æœåœ¨ä»»ä½•è¿­ä»£ä¸­å‡ºé”™ï¼Œæˆ‘å¯ä»¥åªé‡æ–°è®¡ç®—ä¸€ä¸ªå—ã€‚æˆ‘æ¯æ¬¡éƒ½ä¼šå®ä¾‹åŒ–`Translator()`ã€‚

æœ€åï¼Œæˆ‘ä»¬å°†åŸå§‹çš„ã€æœªç»å¤„ç†çš„è‹±æ–‡æ–‡æœ¬æ·»åŠ åˆ°`text_english`:

```
*# replaces NaNs by Nones*
df_english.where(pd.notnull(df_english), **None**, inplace=**True**)

*# add original English tweets to text_english by replacing Nones*
texts = []
**for** idx, row **in** df_english.iterrows():
    **if** row['text_english'] **is** **None**:
        text = row['text']
        texts.append(text)
    **else** :
        texts.append(row['text_english'])

df_english['text_english'] = texts
```

æ­¤æ—¶ï¼Œæ•°æ®å¸§çœ‹èµ·æ¥åƒè¿™æ ·:

![](img/7dc7e4f715e3487cb8092b6b0c7a3fd4.png)

df_english.head()

# æƒ…æ„Ÿåˆ†æ

æˆ‘ä»¬æœ€ç»ˆè®¡ç®—æ¯æ¡æ¨æ–‡çš„æƒ…æ„Ÿã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨`nltk.sentiment.vader`åº“ä¸­ [NLTK](https://www.nltk.org/) çš„`SentimentIntensityAnalyzer`å¯¹è±¡ã€‚

> VADER (Valence Aware å­—å…¸å’Œæƒ…æ„Ÿæ¨ç†å™¨)æ˜¯ä¸€ä¸ªåŸºäºè¯å…¸å’Œè§„åˆ™çš„æƒ…æ„Ÿåˆ†æå·¥å…·ï¼Œä¸“é—¨é’ˆå¯¹ç¤¾äº¤åª’ä½“ä¸­è¡¨è¾¾çš„æƒ…æ„Ÿã€‚*[T22ã€å‚ã€‚ã€‘](https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f)*

*è¿™ä¸ªåº“ä½¿ç”¨èµ·æ¥éå¸¸ç®€å•ï¼Œå¦‚ä½ æ‰€è§:*

*è¯·æ³¨æ„ï¼Œ`polarity_score`è¾“å‡ºæ–‡æœ¬ä¸ºè´Ÿã€ä¸­æ€§æˆ–æ­£çš„æ¦‚ç‡ä»¥åŠä¸€ä¸ªå¤åˆåˆ†æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬æå–åè€…å¹¶å°†åˆ†æ•°é™„åŠ åˆ°æ•°æ®å¸§ä¸­ã€‚*

# *ç»“æŸ*

*ä¸ºäº†ä¾¿äºå±•ç¤ºï¼Œæˆ‘ä»¬å¯¹å„åˆ—è¿›è¡Œäº†é‡æ–°æ’åºã€‚*

```
*cols_order = ['text', 'language', 'location', 'location_code', 
              'location-coordinates', 'sentiment', 'text_english', 
              'text_cleaned', 'user-screen_name']df_final = df_sentiment[cols_order]*
```

*æœ€ç»ˆæ•°æ®é›†åº”è¯¥å¦‚ä¸‹æ‰€ç¤º:*

*![](img/240ff0121597b437c8a14507ad0c9bfa.png)*

*df_final.head()*

# *é™„åŠ :ä¸€ä¸ªç®€å•çš„åˆ†æ*

*ä¸ºäº†ä¸¾ä¾‹è¯´æ˜å¯ä»¥ç”¨è¿™ä¸ªæ•°æ®é›†åšä»€ä¹ˆï¼Œè®©æˆ‘ä»¬æŒ‰å›½å®¶å»ºç«‹ä¸€ä¸ªå¹³å‡æ¨æ–‡æƒ…ç»ªå¾—åˆ†çš„å¯è§†åŒ–:*

*è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªå›½å®¶/è¯­è¨€æ•°æ®æ¡†æ¶ï¼Œå®ƒå¯ä»¥åœ¨[è¿™ä¸ªåº“](https://github.com/hectoramirez/Language-localization_FIFA/blob/master/Countries/countries_lang_full.csv)ä¸­æ‰¾åˆ°ã€‚ä¸Šé¢çš„ä»£ç è¾“å‡ºä»¥ä¸‹ Plotly åœ°å›¾:*

*è¿™å¼ ä¸–ç•Œåœ°å›¾çœ‹èµ·æ¥ä¸å¤ªä¹è§‚ğŸ˜•*

***è¿™ç¯‡æ–‡ç« ä¸­ä½¿ç”¨çš„å…¨éƒ¨ä»£ç å¯ä»¥åœ¨æˆ‘çš„çŸ¥è¯†åº“ä¸­æ‰¾åˆ°:***

*[](https://github.com/hectoramirez/Language-localization_FIFA/blob/master/Tweets%20processing%20and%20sentiment.py) [## hectoramirez/è¯­è¨€-æœ¬åœ°åŒ– _FIFA

### EA Sports çš„ FIFA æœ¬åœ°åŒ–ç«¯åˆ°ç«¯ç ”ç©¶ã€‚é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¸º hectoramirez/Language-localization _ FIFA çš„å‘å±•åšå‡ºè´¡çŒ®â€¦

github.com](https://github.com/hectoramirez/Language-localization_FIFA/blob/master/Tweets%20processing%20and%20sentiment.py) 

## å…³äºä½œè€…

æˆ‘æœ€è¿‘è·å¾—äº†ç‰©ç†å­¦åšå£«å­¦ä½ï¼Œç›®å‰æ­£åœ¨è¿›å…¥æ•°æ®ç§‘å­¦é¢†åŸŸã€‚**éå¸¸æ„Ÿè°¢å¯¹è¿™ç¯‡æ–‡ç« çš„ä»»ä½•è¯„è®ºå’Œ/æˆ–å»ºè®®ã€‚**å¦å¤–ï¼Œçœ‹çœ‹æˆ‘çš„å…¶ä»–æ•…äº‹:

[](/your-live-covid-19-tracker-with-airflow-and-github-pages-658c3e048304) [## æ‚¨çš„å®æ—¶æ–°å† è‚ºç‚è·Ÿè¸ªä¸æ°”æµå’Œ GitHub ç½‘é¡µ

### åŠ è½½æ•°æ®ï¼Œç”¨æ•£æ™¯åˆ¶ä½œå‡ºè‰²çš„å¯è§†åŒ–æ•ˆæœï¼Œå°†å®ƒä»¬æ”¾åœ¨ GitHub Pages ç½‘ç«™ä¸Šï¼Œè®©æ°”æµè‡ªåŠ¨æµåŠ¨â€¦

towardsdatascience.com](/your-live-covid-19-tracker-with-airflow-and-github-pages-658c3e048304) 

æœ€åï¼Œè¯·éšæ—¶åœ¨ LinkedIn ä¸æˆ‘è”ç³»:

[](https://www.linkedin.com/in/harr/) [## hÃ©ctor ramÃ­rez-è¥¿ç­ç‰™å·´ä¼¦è¥¿äºšåœ°åŒº|èŒä¸šç®€ä»‹| LinkedIn

### æˆ‘æœ€è¿‘è·å¾—äº†ç‰©ç†å­¦åšå£«å­¦ä½ï¼Œä¸“æ”»å®éªŒæ•°æ®åˆ†æå’Œæ•°å­¦å»ºæ¨¡ã€‚æˆ‘é¢†å¯¼äº†â€¦

www.linkedin.com](https://www.linkedin.com/in/harr/) 

# å‚è€ƒ

Datacamp ç”¨ Python åˆ†æç¤¾äº¤åª’ä½“æ•°æ®:

[](https://learn.datacamp.com/courses/analyzing-social-media-data-in-python) [## ç­¾åˆ°

### ç™»å½• DataCamp å¸æˆ·

learn.datacamp.com](https://learn.datacamp.com/courses/analyzing-social-media-data-in-python) [](/my-first-twitter-app-1115a327349e) [## æˆ‘çš„ç¬¬ä¸€ä¸ª Twitter åº”ç”¨

### å¦‚ä½•ä½¿ç”¨ Python å’Œ Tweepy åˆ›å»ºè‡ªå·±çš„æ•°æ®é›†

towardsdatascience.com](/my-first-twitter-app-1115a327349e) [](/tweepy-for-beginners-24baf21f2c25) [## é€‚åˆåˆå­¦è€…çš„ Tweepy

### ä½¿ç”¨ Twitter çš„ API å»ºç«‹ä½ è‡ªå·±çš„æ•°æ®é›†

towardsdatascience.com](/tweepy-for-beginners-24baf21f2c25) [](/how-to-access-twitters-api-using-tweepy-5a13a206683b) [## å¦‚ä½•ä½¿ç”¨ Tweepy è®¿é—® Twitter çš„ API

### ä½¿ç”¨æ˜“äºä½¿ç”¨çš„ Python åº“è·å¾—å¤§å‹ Twitter æ•°æ®é›†çš„åˆ†æ­¥æŒ‡å—(åŒ…å«ä»£ç å’ŒæŠ€å·§)

towardsdatascience.com](/how-to-access-twitters-api-using-tweepy-5a13a206683b) [](https://medium.com/@leowgriffin/scraping-tweets-with-tweepy-python-59413046e788) [## ç”¨ Tweepy Python æŠ“å–æ¨æ–‡

### è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨ Python åº“ Tweepy æŠ“å– Twitter tweets çš„é€æ­¥æŒ‡å—ã€‚

medium.com](https://medium.com/@leowgriffin/scraping-tweets-with-tweepy-python-59413046e788)*