<html>
<head>
<title>45 Observations of an Extensive Study of KMeans and KMedoids Unsupervised Learning Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">45 对 KMeans 和 KMedoids 无监督学习聚类的广泛研究的观察</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/45-observations-of-an-extensive-study-of-kmeans-and-kmedoids-unsupervised-learning-clustering-41da9b254712?source=collection_archive---------50-----------------------#2020-06-13">https://towardsdatascience.com/45-observations-of-an-extensive-study-of-kmeans-and-kmedoids-unsupervised-learning-clustering-41da9b254712?source=collection_archive---------50-----------------------#2020-06-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="e798" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在数据集中发现模式或聚类是人类智能的基本能力之一。如果我们要接近或超过人类的智能，我认为它必须是半监督学习，或者更好的是，无监督学习。我对选择无监督学习聚类模型的“最佳实践”并不满意。利用机器学习框架<strong class="js iu"> Photonai </strong>，我们探索了<strong class="js iu"> KMeans </strong>和<strong class="js iu"> KMetroids </strong>集群模型<strong class="js iu">的异同。</strong>我们改变聚类数、每个聚类的点数、聚类大小和目标聚类形状。最后，我们尝试在一个<em class="ko">“真实世界”</em>数据集上进行聚类。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/40ac145cf0386869df539944b802e623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*lucWtr9ityBIAb3wvyeiqw.gif"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">k 是指</strong>以各种细胞计数密度对细胞(小球形斑点)进行计数。50 和 300 个细胞的细胞计数为-2%。1000 个细胞的细胞计数为+6.5%。瑞秋·科特曼的动画<a class="ae lg" href="http://rachel.alvear.cottman@gmail.com" rel="noopener ugc nofollow" target="_blank"/></p></figure><h1 id="bad6" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated"><strong class="ak">k 均值</strong>和<strong class="ak">k 均值</strong>聚类模型比较的目的</h1><blockquote class="mf mg mh"><p id="e0a9" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">理解、评估和利用已识别聚类的最基本步骤是对它们进行定量比较。—来自</p></blockquote><div class="ml mm gp gr mn mo"><a href="https://www.nature.com/articles/s41598-019-44892-y" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">以元素为中心的聚类比较统一了重叠和层次</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">聚类是理解复杂数据的最通用的方法之一。集群的一个关键方面…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">www.nature.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc kz mo"/></div></div></a></div><p id="4646" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上面的引用触及了我们为什么从比较<strong class="js iu">kme means</strong>和<strong class="js iu"> KMedoids </strong>集群开始的核心。</p><p id="3f36" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以一起对广泛的<strong class="js iu"> KMeans </strong>和<strong class="js iu"> KMetroids </strong>星团模型<strong class="js iu">进行广泛的成对研究。我们想要观察这些聚类模型之间的差异和相似之处。</strong></p><p id="855f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，我们希望在未来用其他聚类模型完成类似的广泛研究。我们尝试回答以下任何一个问题。</p><ul class=""><li id="9ffb" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn ni nj nk nl bi translated">我们能开发一个区分每个聚类模型的观察结果的“备忘单”吗？</li><li id="9b3f" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated">我们能否查看数据并缩小我们应该使用的聚类模型的选择范围？</li><li id="0636" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated">在我们研究的某个阶段，我们能找到一个元算法或一套规则来选择一个聚类模型吗？</li><li id="6a19" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated">我们的研究能指导我们得到更好的聚类模型吗？</li></ul><p id="789b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的答案可能是<strong class="js iu"> <em class="ko">对这些问题的部分或全部</em> </strong>不。然而，我们不会放弃；无监督学习聚类模型是一个活跃的研究领域。</p><p id="969f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将一起探讨这些问题。让我们看看我们走了多远。</p><h2 id="1a12" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">什么是集群？</h2><blockquote class="mf mg mh"><p id="e6f0" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">“恩恩德的伯德和色弗洛克和弗赖在一起。——威廉·特纳(公元 1545 年)《拯救罗米什·福克斯》</p><p id="09cd" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">物以类聚，人以群分。(近似现代英语翻译)</p></blockquote><p id="6c91" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据相似性将事物分成不同的组是一种古老的能力。它可能早于自我意识，因为史前生命会对<em class="ko">太阳</em>或<em class="ko">不太阳</em>做出反应，然后<em class="ko">吃</em>或<em class="ko">不吃。</em></p><p id="b702" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通常(也许总是)，聚类是一个<em class="ko">无监督的</em>机器学习问题。数据没有标签(<em class="ko">无监督</em>)来将数据点划分为聚类。</p><p id="1a73" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">聚类通过数据特征的相似性来区分。</p><p id="8d77" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们需要一个例子！好吧，狗、猫和灰鲸怎么样。我们最初的猜测是有三个不同的集群。</p><p id="211f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你有两个特征:长度和体重，那么狗和猫的数据点聚类由于高度重叠而不明显。在猫狗群里，大型犬也有异常值。(好吧，我猜狮子可以算是大型家猫。)数据点的灰鲸群集明显地与狗-猫群集分开。</p><p id="2254" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">据我所知，任何聚类模型都会找到两个聚类。</p><p id="e8b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可能会说:<strong class="js iu">错了</strong>！如果你这样做了，那是因为你使用了比长度和重量更多的特征来区分一群猫和一群狗。</p><p id="6ca5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">想象一个二维图，其中纵轴是<em class="ko">长度</em>测量值，横轴是<em class="ko">重量</em>测量值。您可能会得到两个不同的聚类，其中成对的点(任意两点的对)距离是数据点的二维(2-D)向量长度，坐标为长度和权重。</p><p id="c87c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可能想在狗-猫-灰鲸聚类任务中使用缩放。(我们稍后将讨论缩放。).然而，如果长度和重量都放在一个范围从 0.0 到 1.0 的单位轴上，它仍然不会将狗-猫聚类分开。</p><p id="a453" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，如果我们有细菌、老鼠和灰鲸，以及两个特征:长度和重量，我们将得到不同的集群(在双对数图上)。</p><p id="7095" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#1:为您的聚类选择一组可测量的区别特征是至关重要的。</em> </strong></p><p id="51f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#2:(有时)如果你改变可测量的特征的数量，你就改变了你观察的集群的数量。</em>T25】</strong></p><blockquote class="mf mg mh"><p id="f887" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:观察#2 不是一个“<em class="it">硬性规定</em>”。在上面的两个例子中，您能想到哪些特性会或不会创建更多的集群吗？</p><p id="d2b2" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注:之所以称之为<strong class="js iu"> <em class="it">无监督</em> </strong>学习，是因为你应该<strong class="js iu">而不是<em class="it">监督</em> </strong> <em class="it">学习</em>。没有<em class="it">监督</em>，在某种程度上，<strong class="js iu"> <em class="it">没有</em> </strong>很难做到。如果你<em class="it">以任何方式监督</em>，<em class="it">，</em>你可以引入隐藏的<strong class="js iu">偏见</strong>和假设。</p></blockquote><p id="8e1f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，将对象聚类成<em class="ko">是</em>而<em class="ko">不是</em>一个比萨饼切片严重偏向于特征选择，以至于它是<em class="ko">监督的</em>学习，即使你使用传统的<em class="ko">非监督的</em>模型。</p><p id="72fd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#3:从一组可衡量的显著特征开始。聚类之后，在改变可测量的特征时要小心。这可能是监督，应该记录下来。</em> </strong></p><blockquote class="mf mg mh"><p id="760d" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:在两个阵营中有一个很大的争论，我称之为"<em class="it">实干</em>"阵营和"<em class="it">纯粹主义</em>"阵营。在这篇文章中，我使用了“<em class="it">纯粹主义者</em>”的 camp 方法。然而，我有时会在现实世界或游戏竞赛中加入“努力完成”阵营。我(试图)用前者来证明我的假设。</p></blockquote><p id="8418" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">欢迎你采用你自己的立场作为“<em class="ko">完成</em>”“<em class="ko">纯粹主义者</em>”或者其他完全不同的阵营。</p><h2 id="7695" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">什么是相似？</h2><p id="669e" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated">我们可以引入术语<em class="ko">相似度</em>，它(通常)是两个数据点(对)之间的距离。在上面的例子中，每个数据点都是测量的长度和重量。</p><p id="8f35" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们发现，根据<em class="ko">相似性的定义，</em>即<em class="ko"> </em>数据点对越接近，它们具有越高的相似性分数。相距较远的数据点对具有较低的相似性得分。</p><p id="ad21" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#4:如果相似度是两个数据点之间距离的度量，那么我们就不能使用范畴特征。分类值的值是不明确的。</em>T55】</strong></p><p id="6f71" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">星期一离星期二有一天的距离还是六天的距离？a 卡是 0 还是 1 还是 11 还是<em class="ko">最高</em>？这取决于你玩的游戏。</p><blockquote class="mf mg mh"><p id="1bb2" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:在以后的文章中，我们将发现将分类特征转换成连续特征的方法。我们还将讨论将连续特征转换为分类特征的方法。</p></blockquote><h2 id="7343" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">他们定义聚类模型距离的方式不同吗？</h2><p id="bd4c" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated">是的，有不同的方法来定义距离。如何定义或测量数据点之间的距离通常决定了分类模型。</p><p id="07e1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于本文，我们使用欧几里德距离，距离= sqrt(x + y)。</p><p id="f333" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> k </strong> - &lt; x &gt;系列，其中<strong class="js iu"> KMeans </strong>和<strong class="js iu"> KMedoids </strong>是其成员，要求距离不同。如果是差异的，那么优化器会使<strong class="js iu"> k </strong> - &lt; x &gt;系列成为现有的执行速度最快的集群模型之一。</p><blockquote class="mf mg mh"><p id="f0f5" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:<strong class="js iu">k 表示</strong>有多种变化。如<strong class="js iu"> KMedian </strong>，组成<strong class="js iu"> k </strong> - &lt; x &gt;家族。</p><p id="e4ca" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:微分是微积分的一部分。理解这篇文章的任何部分都不一定要知道区分的机制。有许多优化版本的<strong class="js iu"> k </strong> - &lt; x &gt;系列，你不需要关心实现。</p><p id="694a" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:我们在这项研究中集中使用<strong class="js iu"> k </strong> - &lt; x &gt;家系。</p></blockquote><h2 id="ee83" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">什么是<em class="oi">休伯特和阿拉比调整后的兰德指数(HAARI)？</em></h2><p id="3693" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated">我们在预测的数据点聚类标签和实际的“<em class="ko">真实的</em>”数据点聚类标签之间测量聚类算法的“<em class="ko">优度</em>”。</p><p id="8860" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">数据点标签数量<em class="ko">正确预测</em>与<em class="ko">T30<em class="ko">地面数据点标签</em>数量之比就是<em class="ko">精度</em>。</em></p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="3511" class="nr li it ok b gy oo op l oq or"><em class="ko">accuracy</em> = (<em class="ko">correct-predicted)/ground-truth</em></span></pre><p id="2043" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们测量聚类标签的预测有多好。尽管如此，<em class="ko">无监督的</em>学习，因为我们不是用<em class="ko">基本事实</em>标签训练聚类模型。</p><p id="4143" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们需要一个比数据点分配(<em class="ko">准确性</em>)更好的度量来比较聚类结果。我们可以使用的第一个指标是<em class="ko">休伯特和阿拉比调整后的兰德指数(HAARI) </em>。</p><p id="a796" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko"/><strong class="js iu">k</strong>-&lt;x&gt;家族和<em class="ko"> HAARI </em>有三个已知的偏差(违反已知的真实世界条件)<em class="ko"> : </em></p><ol class=""><li id="609b" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn os nj nk nl bi translated">一个数据点只能位于一个群集中；</li><li id="6e9a" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">每个聚类中的数据点数量必须相同；</li><li id="e965" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">并且每个簇必须具有相同的大小。</li></ol><p id="f08a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">用人工数据集创建者，<code class="fe ot ou ov ok b">make-blobs</code>，</p><ol class=""><li id="8338" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn os nj nk nl bi translated">每个数据点被分配给一个聚类；</li><li id="e851" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">每个聚类可以具有相同数量的数据点；</li><li id="5b9c" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">并且每个簇具有相同的大小。</li></ol><p id="e808" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在一个调用配置中使用<em class="ko"> </em> <code class="fe ot ou ov ok b">make-blobs,</code>，我们不会陷入<em class="ko"> HAARI </em>的偏差陷阱。然而，使用<em class="ko"> </em> <code class="fe ot ou ov ok b">make-blobs,</code>使用不同的调用配置，我们会违反偏差#2 和#3..</p><p id="ced2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko"> HAARI </em>从<em class="ko">精度中减去给定聚类的数据点随机分配。HAARI </em>使用超几何分布作为随机性(噪声)的模型。</p><blockquote class="mf mg mh"><p id="98a6" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:使用超几何分布，假设基础数据点分布近似为高斯形状。自然过程产生的数据的良好近似值，其数据点计数相对大于聚类计数 20 倍或更高。换句话说，如果每个聚类至少有二十个数据点。(中心极限定理)。</p></blockquote><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/hypergeometric-distribution-explained-with-python-2c80bc613bf4"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">用 Python 解释超几何分布</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">数学课上的概率问题，你需要的概率要么给你，要么相对容易…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="ow l mz na nb mx nc kz mo"/></div></div></a></div><p id="d5fb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">想象掷一枚硬币，它的边数不是 2 而是当前的簇数。抛硬币。它着陆，面朝上的一侧是分配的群集标签。</p><blockquote class="mf mg mh"><p id="816e" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:如果一便士是两面的(<em class="it">抵制一个糟糕的双关语</em>)，那么超几何<em class="it"> </em>分布就变成了二项式解。</p></blockquote><p id="5b22" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">总之，<em class="ko"> HAARI </em>是测量预测聚类标签的“<em class="ko">优度”</em>与减去了<em class="ko">“随机噪声”</em><em class="ko">的“<em class="ko">真实值</em>”聚类标签的比率。</em>警告:如果<em class="ko">哈里的</em>已知偏差不适用。</p><blockquote class="mf mg mh"><p id="004b" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:<em class="it"> HAARI </em>范围在 0.0(随机)到 1.0(完美)之间。</p><p id="fd59" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:其他<em class="it"> xARIs </em>使用其他随机性分布。</p><p id="dd13" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:<em class="it"> HAARI </em>分数可能会因随机分配的种子而略有不同。</p></blockquote><p id="ce42" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可以在这里详细阅读关于 HAARI 的<a class="ae lg" href="https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index" rel="noopener ugc nofollow" target="_blank">。</a></p><blockquote class="mf mg mh"><p id="1c95" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注:<code class="fe ot ou ov ok b"><em class="it">sklearn.metrics.ari</em></code>不执行<em class="it">休伯特和阿拉比调整后的兰德指数(</em> HRARI <em class="it"> ) </em>。</p></blockquote><h2 id="bf97" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">什么是以元素为中心的相似性(ECS)聚类指标？</h2><blockquote class="mf mg mh"><p id="f7c7" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">一种纠正聚类比较中偏差的方法是<strong class="js iu">在聚类</strong>的随机集合的背景下考虑聚类相似性。这种机会纠正使用由<strong class="js iu">随机模型指定的聚类之间所有成对比较的预期相似性来建立基线相似性值</strong>。然而，<strong class="js iu">机会修正</strong>方法有严重的<strong class="js iu">缺点</strong> : (i) <strong class="js iu">它强烈依赖于为聚类</strong>假设的随机模型的选择，这通常是高度不明确的，以及(ii) <strong class="js iu">没有提出用于重叠或分层聚类</strong>的随机模型…来自</p></blockquote><div class="ml mm gp gr mn mo"><a href="https://www.nature.com/articles/s41598-019-44892-y" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">以元素为中心的聚类比较统一了重叠和层次</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">聚类是理解复杂数据的最通用的方法之一。集群的一个关键方面…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">www.nature.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc kz mo"/></div></div></a></div><p id="9c27" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上面的引用来自发明<em class="ko"> HAARI </em>的一些人。他们提出了一个比 HAARI 更健壮的聚类指标，这并不奇怪。</p><p id="ebf5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将这个新的度量标准称为 ECS。</p><p id="6aff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae lg" href="https://www.nature.com/articles/s41598-019-44892-y" rel="noopener ugc nofollow" target="_blank">以元素为中心的相似性(<em class="ko"> ECS </em> </a>)聚类度量比<em class="ko"> HAARI 具有更少的偏差。</em>当我们使用<code class="fe ot ou ov ok b">make-blobs</code>时，当我们没有触发<em class="ko"> HAARI </em>偏差，因此<em class="ko"> HAARI </em>产生的分数应该接近<em class="ko"> ECS </em>分数<em class="ko">。</em></p><p id="87dd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">观察#5:群集度量<em class="ko"> ECS </em>比<em class="ko"> HAARI 具有更少的偏差，并且据报告</em> </strong> <a class="ae lg" href="https://www.nature.com/articles/s41598-019-44892-y" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> <em class="ko">更好。</em>T39</strong></a></p><blockquote class="mf mg mh"><p id="d484" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:25 个聚类指标需要标签，超过 5 个聚类指标不需要标签。一个优秀的计算集群度量的软件包是<a class="ae lg" href="https://github.com/Hoosier-Clusters/clusim" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> clusim </strong> </a> <strong class="js iu">。</strong></p><p id="bd7a" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:在此讨论中，我们仅使用<em class="it"> HAARI </em>和<em class="it"> ECS </em>。</p></blockquote><h2 id="6eb1" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">什么是<code class="fe ot ou ov ok b">make-blobs</code>？</h2><p id="b1f6" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated">我在回避一个有如下描述的数学。<code class="fe ot ou ov ok b">make-blobs</code>创造<code class="fe ot ou ov ok b">n_features (or n_cluster)</code>，以<code class="fe ot ou ov ok b">N</code>为中心。每个中心用<code class="fe ot ou ov ok b">n_samples (or n_data_points).</code>创建一个数据点集群，每个点从中心以随机距离分布，随机距离选自标准偏差为<code class="fe ot ou ov ok b">cluster_std.</code>的高斯(正态)分布</p><blockquote class="mf mg mh"><p id="de1f" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注:也许我应该用一个方程来解释？</p><p id="0026" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:聚类中心的距离选自具有较大标准差(std)的高斯(正态)分布。</p><p id="1450" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:距离= sqrt(x + y)</p></blockquote><p id="81ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们也可以用三个例子来回答<code class="fe ot ou ov ok b">make-blobs</code>创造了什么。</p><ol class=""><li id="7f86" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn os nj nk nl bi translated">没有每簇不同数据点的<em class="ko"/><strong class="js iu">k</strong>-&lt;x&gt;族和<em class="ko"> HAARI </em>偏差的触发。下面对<code class="fe ot ou ov ok b">make-blobs</code>的调用有 21 个集群，每个集群的标准差为 1.0，有 30 个数据点。</li></ol><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="13a7" class="nr li it ok b gy oo op l oq or">from sklearn.datasets import make_blobs<br/><br/>data_X, data_y= make_blobs(n_samples=30, n_features=21, cluster_std=1.0, random_state=0)</span></pre><p id="7d4d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.触发每簇不同数据点计数的<em class="ko"> </em> <strong class="js iu"> k </strong> - &lt; x &gt;族和<em class="ko"> HAARI </em>偏差。下面对<code class="fe ot ou ov ok b">make-blobs</code>的调用有 3 个集群。第一个聚类的数据点数为 3，第二个聚类的数据点数为 30，第三个聚类的数据点数为 300。这 3 个聚类每个都有 1.0 的标准偏差。</p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="40f9" class="nr li it ok b gy oo op l oq or">from sklearn.datasets import make_blobs<br/><br/>data_X, data_y= make_blobs(<em class="ko">n_samples=[3,30,300]</em>, n_features=3, cluster_std= 1.0, random_state=777)</span></pre><p id="32d1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.触发不同簇大小的<em class="ko"> </em> <strong class="js iu"> k </strong> - &lt; x &gt;族和<em class="ko"> HAARI </em>偏置。下面对<code class="fe ot ou ov ok b">make-blobs</code>的调用有 3 个集群。第一个聚类的标准偏差为 0.3，第二个聚类的标准偏差为 0.66，第三个聚类的标准偏差为 1.0。每个集群中有 300 个数据点。</p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="976d" class="nr li it ok b gy oo op l oq or">from sklearn.datasets import make_blobs<br/><br/>data_X, data_y= make_blobs(n_samples=300, n_features=3, cluster_std=[0.3, 0.66, 1.0], random_state=777)</span></pre><blockquote class="mf mg mh"><p id="6ff5" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:我们将处理人工数据和<em class="it">真实世界</em>测量数据。在这两种情况下，聚类标签是已知的。</p></blockquote><p id="dd06" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">稍后<strong class="js iu"> </strong>我们将深入探讨<strong class="js iu">kme means</strong>和<strong class="js iu"> KMedoids </strong>模型的方式(或许还有一点原因)。</p><p id="ab0e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们找点乐子。</p><p id="cbfd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们通过以下方式来探索<strong class="js iu">k 方法</strong>和<strong class="js iu">k 方法</strong></p><ol class=""><li id="d6c1" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn os nj nk nl bi translated">改变聚类的数量，并改变每次运行的数据点的数量。对于每次运行，每个聚类都有相同数量的数据点。我们不应该引发一个<strong class="js iu"> k </strong> - &lt; x &gt;家族或者<em class="ko"> HAARI </em>的偏见；</li><li id="5704" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">改变集群大小；我们触发了<strong class="js iu"> k </strong> - &lt; x &gt;族和<em class="ko"> HAARI </em>偏置，即每个簇必须具有相同的大小；</li><li id="f517" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">并且将簇的形状从圆形改变为椭圆形。给定"<em class="ko">distance = sqrt(x+y)"</em>measure 预测球状星团，我们会触发隐藏偏差吗？</li></ol></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="caeb" class="lh li it bd lj lk pe lm ln lo pf lq lr ls pg lu lv lw ph ly lz ma pi mc md me bi translated">改变每个聚类的数据点的数量和改变圆形聚类(斑点)的数量对聚类算法 KMeans 和<strong class="ak"> KMedoids </strong>的影响</h1><p id="162b" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated">我们来看看<strong class="js iu">kme means</strong>和<strong class="js iu"> KMedoids </strong>在改变数据点数量和聚类数量方面的表现。标准偏差(<em class="ko"> std </em>)在第 1 和第 2 个动画图中为 0.3 <em class="ko"> std </em>，在第 3 和第 4 个动画图中为 1.0 <em class="ko"> std </em>。人造数据点是由<code class="fe ot ou ov ok b">make-blob</code>创造的。</p><blockquote class="mf mg mh"><p id="115e" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:std 决定了所形成的集群的包络的大小。</p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/412c6a802454739a5fe9936d5269a0ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*u9nysA4zfrktyIG_nKXjgQ.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">k 表示</strong>聚类，其中<em class="oi">改变每个聚类的固定数据点</em>，用于 std = 0.3 的 3 个聚类。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pk"><img src="../Images/c004c272f49c7ff863428fc1c27570a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vp3Net9SspQEiphbsUMcHA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">对于 std = 0.3 的 3 个聚类，v <em class="oi">改变每个聚类的固定数据点</em>计数的<strong class="bd lf">k 均值</strong>聚类表。</p></figure><p id="efd5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">观察# n(1):k 意味着:数据点计数越高，斑点越圆。</p><p id="51a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">簇中的点越多，由<code class="fe ot ou ov ok b">make-blobs</code>创建的簇的圆形包络就越多。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/1f23a5866098a20b61a124739b6dee65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*JxjejVw3x92YTyvRZD_ixw.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图中的</em><strong class="bd lf"><em class="oi">k 表示对于 std = 0.3 的 21 个聚类，改变每个聚类的固定数据点计数。动画由</em> <a class="ae lg" href="http://rachel.alvear.cottman@gmail.com" rel="noopener ugc nofollow" target="_blank"> <em class="oi">雷切尔·科特曼</em> </a></strong></p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pl"><img src="../Images/6f504cf724d37b2ec0e0d8eee8511d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lTrxR7LuWkDsrKnOw6JklA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">对于 std = 0.3 的 21 个聚类，<strong class="bd lf">k 表示</strong> <em class="oi">聚类，改变每个聚类的固定数据点 t 计数。</em></p></figure><p id="c3dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">观察# n1:k 意味着:数据点计数越高，斑点越圆。</strong></p><p id="8e2c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">观察# N2:k 均值:3 和 21 个聚类，std = 0.3，我们看到圆形聚类的良好分离，没有共享数据点。</strong></p><blockquote class="mf mg mh"><p id="4f3a" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:由于没有偏差触发，我们预计大小为<code class="fe ot ou ov ok b">std = 0.3</code>的<strong class="js iu">k 均值</strong>的<em class="it"> HAARI </em>和<em class="it"> ECS </em>得分接近 1.0。</p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/5da0f394b89706510c337ab5b109b979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*nbrDzvKUSOoJu0qqbsUsVw.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图中的</em><strong class="bd lf"><em class="oi">k 表示对于 std = 1.0 的 3 个聚类，改变每个聚类的固定数据点数进行聚类。动画由</em> <a class="ae lg" href="http://rachel.alvear.cottman@gmail.com" rel="noopener ugc nofollow" target="_blank"> <em class="oi">雷切尔·科特曼</em> </a> <em class="oi"> ≤ </em></strong></p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pm"><img src="../Images/f393c98af7e99e8a98570fcb252887bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lrV0CM-4aKjZENKWxCvRjA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">表</em><strong class="bd lf"><em class="oi">k 表示</em> </strong> <em class="oi">聚类，对于 std = 1.0 的 3 个聚类，改变每个聚类的固定数据点计数</em></p></figure><p id="5bd1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# n3:</em>k 意味着<em class="ko">形状偏离圆形，簇重叠越多。</em> </strong></p><p id="34ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#n4: </em>对于重叠的聚类，KMeans <em class="ko">的 HAARI 和 ECS 分数低于 1.0。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/5e6868c9fe31df4625b7194e73851724.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*W4rMPlqIklckykYuw0o5UA.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图中的</em><strong class="bd lf"><em class="oi">k 表示</em> </strong> <em class="oi">聚类，对于 std = 1.0 的 21 个聚类，改变每个聚类的固定数据点计数。动画由</em> <a class="ae lg" href="http://rachel.alvear.cottman@gmail.com" rel="noopener ugc nofollow" target="_blank"> <em class="oi">雷切尔·科特曼</em> </a>制作</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pn"><img src="../Images/6c62e39c5a0506a12dd7f402fa185258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z_o8aBMy3ejU5J0SoEwghg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">表</em><strong class="bd lf"><em class="oi">k 均值</em> </strong> <em class="oi">聚类，对于 std = 1.0 的 21 个聚类，改变每个聚类的固定数据点计数。</em></p></figure><p id="5202" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# n3:</em>k 表示<em class="ko">形状偏离圆形。群集重叠越多。</em> </strong></p><p id="1c62" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#n4: </em> KMeans <em class="ko"> </em>在聚类计数正确时，对于重叠的聚类，其<em class="ko"> HAARI 和 ECS 得分低于 1.0。</em>T13】</strong></p><p id="05ca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# n5:</em>k 均值<em class="ko"> </em>具有<em class="ko"> HAARI，并且当每个聚类计数的数据点为 21 时，ECS 分数低于 1.0。</em> </strong></p><p id="7b7b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#n6: </em>当每个聚类计数的数据点为 30 或更大时，k 均值的<em class="ko"> HAARI 和 ECS 分值的值等于 0.1%。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/5b1667a2065f34674d07edb80e1289f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*wknRh_NrfIOBMjIesMhW_A.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf"> KMediods </strong>聚类，其中<em class="oi">改变 std = 0.3 的 3 个聚类的每个聚类的固定数据点计数</em>。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi po"><img src="../Images/4479717af465b0977eafb7243fbc13e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N0_BrJ5v1Dxy0b3gzqMzJA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf"> KMediods </strong> <em class="oi">聚类表，对于 std = 0.3 的 3 个聚类，改变每个聚类的固定数据点计数。</em></p></figure><p id="22ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">观察#n7:当聚类被很好地分离并且不重叠时，KMedoids <em class="ko">具有 1.0 的 HAARI 和 ECS。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/32a16a31481145be0908dde19a8cd6cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*OZrDfVpPZ3n7fQtZuF6jdw.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em><strong class="bd lf"><em class="oi">KMediods</em></strong><em class="oi">聚类，对于 std = 1.0 的 3 个聚类，改变每个聚类的固定数据点计数。动画由</em> <a class="ae lg" href="http://rachel.alvear.cottman@gmail.com" rel="noopener ugc nofollow" target="_blank"> <em class="oi">雷切尔·科特曼</em> </a>制作</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pp"><img src="../Images/1bc68db570dec7571c4effdf3cbd6802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1kVLs81v633MPMe2KtQoBA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf"> KMedoids </strong> <em class="oi">聚类表，针对 std = 1.0 的 3 个聚类，改变每个聚类的固定数据点计数。</em></p></figure><p id="0146" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">观察#n8: KMedoids <em class="ko">当聚类没有很好地分离和重叠时，HAARI 和 ECS 得分低于 1.0</em>。</strong></p><p id="4fe5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以理解较低的<strong class="js iu"> <em class="ko"> HAARI </em> </strong>和<strong class="js iu"> <em class="ko"> ECS </em> </strong>分数，因为<strong class="js iu"> KMedoids </strong>从数据集中选择质心。每个聚类的数据点计数越低，一个聚类具有也是该聚类的理想中间点的数据点的概率就越低。(仅对称形状的簇。)</p><p id="ea78" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#n9: </em> KMedoids 有<em class="ko"> HAARI 和 ECS 的值相差 1.5%到 7%。</em>T79】</strong></p><p id="ae5c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">推理同<strong class="js iu"> <em class="ko">观察#n(13)。</em> KMedoids </strong>从数据集中选择一个质心。每个聚类的数据点计数越低，一个聚类具有也是该聚类的理想中间点的数据点的概率就越低。(仅对称形状的簇。)</p><p id="bacd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#n10: </em> KMedoids: T <em class="ko">数据点计数范围左端的低点计数效应和数据点计数范围右端的聚类重叠似乎为 ECS 分数彼此平衡。</em>T9】</strong></p><p id="7a8f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们观察到，随着数据点计数的增加，<em class="ko"> HAARI </em>低于<em class="ko"> ECS，</em></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/1f23a5866098a20b61a124739b6dee65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*JxjejVw3x92YTyvRZD_ixw.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf"> KMediods </strong>聚类，其中<em class="oi">改变 std = 0.3 的 21 个聚类的每个聚类的固定数据点</em>计数。瑞秋·科特曼制作的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pq"><img src="../Images/2dc86a1c291c9a9e03cdfe152388440b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cyu0jN5GQV39bJvym2tQwg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">表<strong class="bd lf"> KMedoids </strong> <em class="oi">聚类，每个聚类的数据点计数不同，有 21 个聚类，std = .3。瑞秋·科特曼的动画</em></p></figure><p id="754e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#n11: </em> KMeans <em class="ko">聚类模型，std =0.3，具有比</em> KMedoids <em class="ko">，std =0.3，聚类模型更高的 HAARI 和 ECS 分数。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/48d08c73ac054d3aa9f97572a14f3eb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*SGobTKjiDXapzhpcE0sgQQ.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf"> KMediods </strong>聚类，其中<em class="oi">改变 std = 1.0 的 21 个聚类的每个聚类的固定数据点</em>计数。由<a class="ae lg" href="http://rachel.alvear.cottman@gmail.com" rel="noopener ugc nofollow" target="_blank">瑞秋·科特曼</a>制作的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pr"><img src="../Images/29e8417755dc1aa4cf4c0c400efd1882.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gX6NrYVwXEdm4EnnjES5bw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf"> KMedoids </strong> <em class="oi">聚类表，对于 std = 1.0 的 21 个聚类，改变每个聚类的固定数据点计数。</em></p></figure><p id="50d9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#n12: </em> KMeans <em class="ko">聚类模型，std =1.0，具有比</em> KMedoids <em class="ko">，std =1.0，聚类模型更高的 HAARI 和 ECS 分数。</em>T55】</strong></p><p id="abe1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察 n13:对于 KMeans 和 KMediods 聚类模型，数据点越多，聚类计数对实际聚类计数越好，因此 HAARI 和 ECS 得分越高。</em>T59】</strong></p><p id="5db6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当有监督和无监督的机器学习被给予更多的数据点时，就有了更好的模型来预测未来的数据点。</p><p id="4229" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#n14: </em> KMeans <em class="ko">似乎比</em> KMedoids <em class="ko">有更高的 HAARI 和 ECS 分数。</em> </strong></p><p id="02e3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果<strong class="js iu"><em class="ko">【n14】</em></strong><strong class="js iu"><em class="ko">的观测成立，我们将发现其他扰动，如星团的大小和形状。</em> </strong></p></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="4883" class="lh li it bd lj lk pe lm ln lo pf lq lr ls pg lu lv lw ph ly lz ma pi mc md me bi translated">各种圆形斑点簇大小对模型 KMeans 和<strong class="ak"> KMedoids 的影响。</strong></h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/f31ae6e0a66b46531a2667dd72546c7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*N8P_9XnZHAhbjG1PGW4jag.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf">表示对于基数 std=0.25 的 21 个集群，使用各种圆形斑点集群大小进行集群。瑞秋·科特曼的动画</strong></p></figure><p id="8a9e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">聚类标准偏差(小标准偏差)为[0.2，0.45，0.55，0.63，0.7，0.75，0.84，0.86，0.91，. 95，1.0，1.03，1.07，1.10，1.14，1.17，1.2，1.23，1.26，1.29，1.32]，导致不同的聚类大小。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ps"><img src="../Images/37673547629111c43288b94c65c312fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dwl2ZdCgDHna7CglcjlPnQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">对于基数 std=0.25 的 21 个聚类，具有各种圆形斑点聚类大小的<strong class="bd lf">k 均值</strong>聚类表。</p></figure><p id="c6b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# S1:</em><em class="ko">不同大小的簇上的 KMeans 比固定大小的簇上的 KMeans 具有更低的 HAARI 和 ECS 分数。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/f31ae6e0a66b46531a2667dd72546c7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*N8P_9XnZHAhbjG1PGW4jag.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf">表示</strong>对于基数 std=0.50 的 21 个聚类，使用各种圆形斑点聚类大小进行聚类。瑞秋·科特曼的动画</p></figure><p id="ae18" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">聚类标准偏差是:[0.2，0.7，0.90，1.06，1.2，1.31，1.42，1.52，1.61，1.7，1.78，1.85，1.93，2.00，2.07，2.13，2.2，2.26，2.32，2.379，2.43]导致不同的聚类大小。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pt"><img src="../Images/f5ea85ed012c650b253676b3df9ff553.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tIgZESpar8oZzYxW2_Bm5w.png"/></div></div></figure><p id="a396" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# S1:</em><em class="ko">不同大小的簇上的 k 均值比固定大小的簇上的 k 均值具有更低的 HAARI 和 ECS 分数。</em> </strong></p><p id="1b7b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# S2:</em><em class="ko">较大的不同大小的簇上的 k 均值比较小的不同大小的簇上的 k 均值具有较低的 HAARI 和 ECS 分数。</em>T41】</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/9810fa8b1779c4666cd0c931d476c67b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*xU84Mz_pyV-bwD8HHf7xYQ.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf"> KMediods </strong>对于基数 std=0.25 的 21 个聚类，使用各种圆形斑点聚类大小进行聚类。瑞秋·科特曼的动画</p></figure><p id="ad0c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">聚类标准偏差为 n_cluster_std [0.2，0.45，0.55，0.63，0.7，0.75，0.84，0.86，0.91，0.95，1.0，1.03，1.07，1.10，1.14，1.17，1.2，1.23，1.26，1.29，1.32]，导致不同的聚类大小。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pu"><img src="../Images/3b46230c197e5c80ce4916e646d24757.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j6m8Svg4imZLUs29D_f_rA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">基 std=0.25 的 21 个聚类的具有各种圆形斑点聚类大小的 KMediods </strong>聚类表。</p></figure><p id="00fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#s3: </em>不同大小的簇上的 kmediod 比固定大小的簇上的 kmediod<em class="ko">具有更低的 HAARI 和 ECS 分数。</em>T57】</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/5bab8c1ee13cbdb2e44e3ebd6dd56094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*HJ_Aamg_gP1kiT-XOm5w8Q.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf">对基数 std=0.50 的 21 个聚类进行具有各种圆形斑点聚类大小的 KMediods </strong>聚类。瑞秋·科特曼的动画</p></figure><blockquote class="mf mg mh"><p id="5ced" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated">注意:标题框不正确。对于<code class="fe ot ou ov ok b">N_points = 3, CLUSTERS_FOUND =19; N_points = 30, CLUSTERS_FOUND =21; N_points = 100, CLUSTERS_FOUND =15; N_points = 300, CLUSTERS_FOUND =17.</code></p></blockquote><p id="b222" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">聚类标准偏差[0.2，0.7，0.90，1.06，1.2，1.31，1.42，1.52，1.61，1.7，1.78，1.85，1.93，2.00，2.07，2.13，2.2，2.26，2.32，2.38，2.43]导致不同的聚类大小。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pt"><img src="../Images/55c30337d68b5d3fdaf544a1d61cf8cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FC3Tw6Pg0yDiLDJ6MEEhbA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">基 std=0.50 的 21 个聚类的具有各种圆形斑点聚类大小的 KMediods </strong>聚类表。</p></figure><p id="63e9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#s3: </em>不同大小的簇上的 kmediod 比固定大小的簇上的 kmediod 具有更低的 HAARI 和 ECS 分数。 </strong></p><p id="d20f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# S4:</em><em class="ko">不同大小的簇上的较大的 kme dids 具有比较小的不同大小的簇上的</em>kme dids<em class="ko">更低的 HAARI 和 ECS 分数。</em>T24】</strong></p></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="f30e" class="lh li it bd lj lk pe lm ln lo pf lq lr ls pg lu lv lw ph ly lz ma pi mc md me bi translated">每个椭圆形斑点的不同数量的数据点对聚类模型 k 均值和 k 均值的影响</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/a8880f29492676e25e9cf69d143178d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*gUszL2wwyYdvQNmOhoU-hQ.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">数字</em><strong class="bd lf">k 表示对于 std = 0.3 的 3 个聚类，每个椭圆聚类的数据点计数变化</strong>。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pt"><img src="../Images/6c7d1ae8ad5e5ff2b5fa5254e2044595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_k7g_GJ84dgzbRTzNF4c0Q.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">表中的</em><strong class="bd lf"><em class="oi">k 表示对于 std = 0.3 的 3 个群，每个椭圆群具有不同的数据点计数</em></strong></p></figure><p id="25c2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e1: </em>椭圆形聚类上的 k 均值<em class="ko">将一些数据点分配给错误的聚类。</em> </strong></p><p id="e02e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e2: </em>椭圆形簇上的 KMeans <em class="ko">比圆形相同大小簇上的</em> KMeans <em class="ko">具有更低的 HAARI 和 ECS 分数。</em>T50】</strong></p><p id="4f8c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">观察#e1 和观察#e2 源于基于距离的相似性，导致导出的聚类的圆形包络以质心为中心。</p><p id="2dc1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# E3:k 均值聚类随着预测的聚类形状偏离圆形而退化。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/1f23a5866098a20b61a124739b6dee65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*JxjejVw3x92YTyvRZD_ixw.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em><strong class="bd lf">k 表示对于 std = 0.3 的 21 个群，每个椭圆群的数据点数不同</strong>。瑞秋·科特曼的动画<a class="ae lg" href="http://rachel.alvear.cottman@gmail.com" rel="noopener ugc nofollow" target="_blank"/></p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pt"><img src="../Images/a28c225e6c7b3ad2019188972d884e8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xs5L8mTOmqOeBThqo9ee_Q.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">对于 std = 0.3 的 21 个集群，每个椭圆集群具有不同数据点计数的<strong class="bd lf">k 均值</strong>表。</p></figure><p id="11f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e1: </em>椭圆形聚类上的 k 均值<em class="ko">将一些数据点分配给错误的聚类。</em> </strong></p><p id="12a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e2: </em>椭圆形簇上的 KMeans <em class="ko">比圆形相同大小簇上的</em> KMeans <em class="ko">具有更低的 HAARI 和 ECS 分数。</em>T15】</strong></p><p id="f7c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# E3:k 均值随着集群形状偏离圆形而退化。</em>T19】</strong></p><p id="b630" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e4: </em>计数为 21 的椭圆形簇上的 KMeans <em class="ko">比计数为 3 的较大椭圆形簇上的</em> KMeans <em class="ko">具有更低的 HAARI 和 ECS 分数。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/a10fbdb0efcc2660f7805342cd88515d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*00_Tq-xk89ERPrmNZnOcHQ.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">数字</em><strong class="bd lf"><em class="oi">k 表示对于 std =1.0 的 3 个群，每个椭圆群具有不同的数据点计数。动画由</em> <a class="ae lg" href="http://rachel.alvear.cottman@gmail.com" rel="noopener ugc nofollow" target="_blank"> <em class="oi">雷切尔·科特曼</em> </a>制作</strong></p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pv"><img src="../Images/1fef61d679df0763c6b313f7de83b37b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i-CmrvsYpuT-mGGiPxHk0g.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">表<strong class="bd lf"><em class="oi">k 均值</em> </strong> <em class="oi">对于 std =1.0 </em>的 3 个聚类，每个椭圆聚类具有不同的数据点计数</p></figure><p id="1ccd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e1: </em>椭圆形聚类上的 k 均值<em class="ko">将一些数据点分配给错误的聚类。</em>T51】</strong></p><p id="3fee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e2: </em>椭圆形簇上的 KMeans <em class="ko">比相同大小的圆形簇上的</em> KMeans <em class="ko">具有更低的 HAARI 和 ECS 分数。</em>T59】</strong></p><p id="9d50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# E3:k 均值聚类随着聚类形状偏离圆形而退化。</em> </strong></p><p id="f7a2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e5: </em>椭圆形簇上的 KMeans <em class="ko">比更大尺寸的椭圆形簇上的</em> KMeans <em class="ko">具有更低的 HAARI 和 ECS 分数。</em>T71】</strong></p><p id="7126" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e6: </em> KMeans <em class="ko">对具有三个数据点的椭圆形聚类预测了错误的聚类数。</em>T77】</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/482581d280917cb2798dc4cf0ba63703.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*oAp3hlyEX9d4hmbXVLK5EQ.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em><strong class="bd lf"><em class="oi">k 表示对于 std = 1.0 的 21 个群，每个椭圆群具有不同的数据点数</em> </strong> <em class="oi">动画作者</em> <a class="ae lg" href="http://rachel.alvear.cottman@gmail.com" rel="noopener ugc nofollow" target="_blank"> <em class="oi">雷切尔·科特曼</em> </a></p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pw"><img src="../Images/9b9610a51559c4fc9b638bcbff28dfe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*61km-ygnDJ60gEhqRW5LPw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">表<strong class="bd lf"><em class="oi">k 均值</em> </strong> <em class="oi">对于 std = 1.0 </em>的 21 个聚类，每个椭圆聚类具有不同的数据点计数</p></figure><p id="567b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e1: </em>椭圆形聚类上的 k 均值<em class="ko">将一些数据点分配给错误的聚类。</em> </strong></p><p id="4861" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e2: </em>椭圆形簇上的 KMeans <em class="ko">比圆形相同大小簇上的</em> KMeans <em class="ko">具有更低的 HAARI 和 ECS 分数。</em>T13】</strong></p><p id="7ebc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# E3:k 均值聚类随着聚类形状偏离圆形而退化。</em> </strong></p><p id="cefd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e4: </em>具有 21 个聚类的椭圆形上的 k 均值<em class="ko">比具有 3 个聚类的更大尺寸的椭圆形上的</em>k 均值<em class="ko">具有更低的 HAARI 和 ECS 分数。</em>T25】</strong></p><p id="bd51" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e5: </em>椭圆形簇上的 KMeans <em class="ko">比更大尺寸的椭圆形簇上的</em> KMeans <em class="ko">具有更高的 HAARI 和 ECS 分数。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/082bafa38cda4a65386b489590650025.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*eim-eD3oA5udY--BmSfalQ.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf"> KMedoids </strong>对于 std = 0.3 的 3 个群，每个椭圆群具有不同的数据点计数。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi px"><img src="../Images/f71b57ca7ebeb763855695dd5c0642b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*95abemdSrA0FR2NDLHjNsA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">对于 std = 0.3 的 3 个集群，每个椭圆集群具有不同数据点计数的<strong class="bd lf"> KMedoids </strong>表</p></figure><p id="9986" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e7: </em>椭圆形聚类上的 KMediods <em class="ko">将一些数据点分配给错误的聚类。</em>T47】</strong></p><p id="697a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e8: </em>椭圆形簇上的 kme dids<em class="ko">的 HAARI 和 ECS 分数低于圆形相同大小簇上的</em>kme dids<em class="ko">。</em>T55】</strong></p><p id="b735" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e9: </em> KMediods <em class="ko">聚类随着聚类形状偏离圆形而退化。</em> </strong></p><p id="467d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e10: </em>具有 3 个簇的椭圆形上的 KMediods <em class="ko">比具有 3 个簇的更大尺寸的椭圆形上的</em> KMediods <em class="ko">具有更高的 HAARI 和 ECS 分数。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/df654b399ec77d8bb00367f4af602986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*fJEU1Hdhmnp6yp3XtWM6ww.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf"> KMedoids </strong>对于 std = 1.0 的 3 个聚类，每个椭圆聚类的数据点计数不同。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pv"><img src="../Images/35818ccc34a6151ab8f5ed436675ce27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JCnoTtBWiKOYF6u7C75kTw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">对于 std = 1.0 的 3 个集群，每个椭圆集群具有不同数据点计数的<strong class="bd lf"> KMedoids </strong>表。</p></figure><p id="2bab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e7: </em>椭圆形聚类上的 KMediods <em class="ko">将一些数据点分配给错误的聚类。</em>T83】</strong></p><p id="dc63" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e8: </em>椭圆形簇上的 KMediods <em class="ko">比圆形、相同大小的簇上的</em>kme ads<em class="ko">具有更低的 HAARI 和 ECS 分数。</em>T9】</strong></p><p id="2aa7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e9: </em> KMediods <em class="ko">聚类随着聚类形状偏离圆形而退化。</em>T15】</strong></p><p id="367d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e10: </em>具有 3 个簇的椭圆形上的 KMediods <em class="ko">比具有 3 个簇的更大尺寸的椭圆形上的</em> KMediods <em class="ko">具有更高的 HAARI 和 ECS 分数。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/ebbe704ec51d47d8225606945e8192b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*1pfAnSO-YRLX3RnIiEGzfA.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">对于 std = 1.0 的 21 个群，图</em> <strong class="bd lf"> KMedoids </strong>具有每个椭圆群的不同数据点计数。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi px"><img src="../Images/e789d466d23db3b132612d89b4e4f87f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hrQqMtwUc4cqKgrFrTA8eA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">对于 std = 1.0 的 21 个集群，每个椭圆集群具有不同数据点计数的<strong class="bd lf"> KMedoids </strong>表</p></figure><p id="cda0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e7: </em>椭圆形聚类上的 KMediods <em class="ko">将一些数据点分配到错误的聚类。</em> </strong></p><p id="4228" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e8: </em>椭圆形簇上的 KMediods <em class="ko">比圆形、相同大小的簇上的</em> Kmeans <em class="ko">具有更低的 HAARI 和 ECS 分数。</em>T45】</strong></p><p id="ee1c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e9: </em> KMediods <em class="ko">聚类随着聚类形状偏离圆形而退化。</em>T51】</strong></p><p id="63bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e11: </em>具有 21 个团簇的椭圆形状上的 KMediods <em class="ko">比具有 3 个团簇的更大尺寸的椭圆形状上的</em> KMediods <em class="ko">具有更高的 HAARI 和 ECS 分数。</em>T59】</strong></p><p id="198d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#e12: </em>椭圆形上的 kme dids<em class="ko">具有比</em> KMeans 更低的 HAARI 和 ECS 分数。</strong></p></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="4b6a" class="lh li it bd lj lk pe lm ln lo pf lq lr ls pg lu lv lw ph ly lz ma pi mc md me bi translated">什么是 Photonai？</h1><p id="4315" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated"><strong class="js iu"> Photonai </strong>将<strong class="js iu"> Scikit-Learn </strong>和<strong class="js iu"> </strong>其他机器学习(ML)或深度学习(DL)框架与一个统一的范例相结合。<strong class="js iu"> Photonai </strong>采用<strong class="js iu"> Scikit-Learn 的</strong> <code class="fe ot ou ov ok b">Estimator</code>和<code class="fe ot ou ov ok b">Transformer</code>类方法架构。</p><p id="c29a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> Photonai </strong>有<em class="ko">元素，</em>有<strong class="js iu"> Photonai </strong>术语<strong class="js iu"> </strong>即<strong class="js iu"> </strong>的意思是<strong class="js iu"> </strong> <code class="fe ot ou ov ok b">Estimator</code>或<code class="fe ot ou ov ok b">Transformer</code>，通过将前学习器和后学习器算法转换成带有参数签名的元素来减少人工编码和错误。元素的例子是数据清理器、定标器、估算器、类平衡器、交叉验证器、超参数调谐器和集成的几种选择。</p><p id="fa3f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Photonai 的一个很酷的架构特性是，它提供了一种无代码的<a class="ae lg" href="https://photon-ai.com/documentation/register" rel="noopener ugc nofollow" target="_blank">方式来添加元素</a>(如果元素可被<strong class="js iu"> Python </strong>调用)。<strong class="js iu"> </strong>我添加了聚类算法<code class="fe ot ou ov ok b">sklearn.cluster.KMeans</code>和<code class="fe ot ou ov ok b">sklearn_extra.cluster.KMmediods</code>。</p><p id="ba3c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ot ou ov ok b">PCA, t-SNE, K-Fold(cross-validation), hyperopt (hyper-parameter tuning), and StandardScaler (scaling)</code>已经是注册的元素，我们可以在机器学习框架<strong class="js iu"> Photonai </strong>中自由使用。</p><p id="3bfb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所有这些不同的机器学习技术，比如<code class="fe ot ou ov ok b">PCA, t-SNE, K-Fold...</code>，在参考资料部分的文章中都有详细的讨论。</p><p id="7036" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> Photonai </strong>具有<code class="fe ot ou ov ok b">registry.list_available_elements()</code>功能，逐项列出<strong class="js iu"> Photonai 中所有当前可用的<strong class="js iu"> <em class="ko">元素</em> </strong>。</strong></p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="df93" class="nr li it ok b gy oo op l oq or">from photonai.base.photon_elements import PhotonRegistry<br/>registry = PhotonRegistry(custom_elements_folder=custom_elements_folder)<br/>registry.activate()</span><span id="ddf5" class="nr li it ok b gy py op l oq or">registry.list_available_elements()</span><span id="0b00" class="nr li it ok b gy py op l oq or">output ==&gt;<br/>PhotonCore<br/>ARDRegression      sklearn.linear_model.ARDRegression  Estimator<br/>AdaBoostClassifier sklearn.ensemble.AdaBoostClassifier Estimator<br/>.<br/>.<br/>PhotonCluster<br/>KMeans            sklearn.cluster.KMeans               Estimator<br/>KMedoids          sklearn_extra.cluster.KMedoids       Estimator</span></pre><h2 id="dfa1" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">在群集模型中控制我们基于光的研究</h2><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="c8c5" class="nr li it ok b gy oo op l oq or">CLUSTER_ALGO = 'KMedoids'<br/><br/>C_SHAPE ='ellipse'           # for cells C_SHAPE ='circle'<br/>N_CLUSTERS = [21]            # for cells N_CLUSTERS = [50,300, 1000]<br/>CLUSTERS_STD = 0.3           # for cells CLUSTERS_STD = 0.1<br/>N_P_CLUSTERS = [3, 30, 300, 3000] # for cells N_P_CLUSTERS = [5]<br/>INNER_FOLDS = 5<br/>OUTER_FOLDS = 5</span></pre><ul class=""><li id="bb0f" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn ni nj nk nl bi translated"><code class="fe ot ou ov ok b">CLUSTER_ALGO</code>确定使用哪个聚类模型。</li><li id="27b9" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated"><code class="fe ot ou ov ok b">C_SHAPE</code>确定聚类的形状和包含所有聚类的包络的形状。</li><li id="807a" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated"><code class="fe ot ou ov ok b">N_CLUSTER</code>确定生成的簇的数量。</li><li id="9185" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated"><code class="fe ot ou ov ok b">CLUSTER_STD</code>调节生成的簇的大小。</li><li id="1036" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated"><code class="fe ot ou ov ok b">N_P_CLUSTERS</code>调节每个聚类的数据点数量。</li><li id="887d" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated"><code class="fe ot ou ov ok b">INNER_FOLDS</code>确定进行超参数搜索的次数，这将产生由 t <em class="ko"> he 调整的 Rand 指数(ARI)确定的最佳超参数集。</em></li><li id="9195" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated"><code class="fe ot ou ov ok b">OUTER_FOLDS</code>决定<em class="ko"> ARI 的<em class="ko"> K 倍交叉验证</em>。</em>这里<em class="ko"> K </em>给定为<code class="fe ot ou ov ok b">OUTER_FOLDS.</code>结果是 ARI 的<em class="ko">均值</em>和<em class="ko"> std </em>。</li></ul><p id="5af0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过将<code class="fe ot ou ov ok b">INNER_FOLDS </code>和<code class="fe ot ou ov ok b">OUTER_FOLDS </code>设置为三或更大，我们更有信心优化<strong class="js iu"> KMeans </strong>和<strong class="js iu"> KMedoids 的拟合。</strong>聚类模型针对每次<strong class="js iu"> </strong> <code class="fe ot ou ov ok b">INNER_FOLDS*OUTER_FOLDS</code>运行进行了超参数优化。</p><blockquote class="pz"><p id="8f05" class="qa qb it bd qc qd qe qf qg qh qi kn dk translated"><em class="oi"> K-fold 交叉验证(CV) </em>通过将数据划分为多个折叠，并确保每个折叠都作为一个测试集，为这个问题提供了一个解决方案。来自…</p></blockquote><div class="qj qk ql qm qn mo"><a href="https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833" rel="noopener follow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">k 倍交叉验证</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">评估机器学习模型可能非常棘手。通常，我们将数据集分成训练集和测试集…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">medium.com</p></div></div><div class="mx l"><div class="qo l mz na nb mx nc kz mo"/></div></div></a></div><h2 id="08b8" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">这项研究使用的主要 Photonai 函数</h2><p id="1109" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated">本研究使用的所有代码都可以从 github 下载<a class="ae lg" href="https://github.com/bcottman/photon_experiments/tree/master/Cluster/kmeans-kmedoids" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="2c96" class="nr li it ok b gy oo op l oq or">def hyper_cluster(cluster_name):<br/>    if C_SHAPE == 'ellipse' :<br/>        yield_cluster = yield_parameters_ellipse<br/>    else: <br/>        yield_cluster = yield_parameters<br/>    <br/>    n_p_clusters = N_P_CLUSTERS<br/>    for data_X, data_y,n_cluster  in yield_cluster(n_p_clusters):<br/>        simple_output('CLUSTER_ALGO:', CLUSTER_ALGO)<br/>        simple_output('C_SHAPE:',C_SHAPE)<br/>        simple_output('n_cluster:', n_cluster)<br/>        simple_output('INNER_FOLDS:', INNER_FOLDS)<br/>        simple_output('OUTER_FOLDS:', OUTER_FOLDS)        <br/>        simple_output('n_points:', len(data_y))</span><span id="fa19" class="nr li it ok b gy py op l oq or">X = data_X.copy(); y =  data_y.copy()<br/>        # DESIGN YOUR PIPELINE<br/>        settings = OutputSettings(project_folder='./tmp/')<br/>            <br/>        my_pipe = Hyperpipe('batching',<br/>                            optimizer='sk_opt',<br/>        #                    optimizer_params={'n_configurations': 25},<br/>                            metrics=['ARI', 'MI', 'HCV', 'FM'],<br/>                            best_config_metric='ARI',<br/>                            outer_cv=KFold(n_splits=OUTER_FOLDS),<br/>                            inner_cv=KFold(n_splits=INNER_FOLDS),<br/>                            verbosity=0,<br/>                            output_settings=settings)</span><span id="1557" class="nr li it ok b gy py op l oq or">my_pipe += PipelineElement(cluster_name, hyperparameters={<br/>                                                           'n_clusters': IntegerRange(floor(n_cluster*.7)<br/>                                                                                      , ceil(n_cluster*1.2)),<br/>                                                            },random_state=777)</span><span id="c4c3" class="nr li it ok b gy py op l oq or">logger.info('Cluster optimization range:',  floor(n_cluster*.7), ceil(n_cluster*1.2))<br/>        print('Cluster optimization range:',  floor(n_cluster*.7), ceil(n_cluster*1.2))</span><span id="cfa0" class="nr li it ok b gy py op l oq or"># TRAIN PIPELINE<br/>        my_pipe.fit(X, y)</span><span id="f313" class="nr li it ok b gy py op l oq or">debug = True</span><span id="9693" class="nr li it ok b gy py op l oq or">y_pred=cluster_plot(my_pipe, X, n_cluster, PALLET)</span><span id="c732" class="nr li it ok b gy py op l oq or">print(pd.DataFrame(my_pipe.best_config.items()<br/>                           ,columns=['n_clusters', 'k']))</span><span id="931c" class="nr li it ok b gy py op l oq or">print('train','\n'<br/>              ,results_to_df(my_pipe.results.metrics_train))<br/>        print('test','\n'<br/>              ,results_to_df(my_pipe.results.metrics_test))</span><span id="98f6" class="nr li it ok b gy py op l oq or"># turn the ground-truth labels into a clusim Clustering<br/>        true_clustering = Clustering().from_membership_list(y) <br/>        kmeans_clustering = Clustering().from_membership_list(y_pred) # lets see how similar the predicted k-means clustering is to the true clustering</span><span id="3f56" class="nr li it ok b gy py op l oq or"># output all available similarity measures<br/>        row_format2 ="{:&gt;25}" * (2)<br/>        for simfunc in sim.available_similarity_measures:<br/>            print(row_format2.format(simfunc, eval('sim.' + simfunc+'(true_clustering, kmeans_clustering)')))</span><span id="d918" class="nr li it ok b gy py op l oq or">elsim = sim.element_sim(true_clustering, kmeans_clustering)<br/>        print("Element-centric similarity: {}".format(elsim))</span></pre><h2 id="997a" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">如何获得 Photonai？</h2><blockquote class="mf mg mh"><p id="624c" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated"><strong class="js iu">注意</strong>:我只给出了基于<strong class="js iu"> Python- </strong>的集群模型示例，但是这些集群模型在其他语言中也是可用的。</p><p id="a315" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated"><strong class="js iu">注意:Photonai </strong>是一个公开发布包，我已经对它进行了修改，以包含集群模型。</p></blockquote><p id="3253" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你的机器学习项目涉及到聚类，你将需要使用我的<strong class="js iu"> Photonai </strong>代码。很快，我打算添加<strong class="js iu"> xgboost </strong>和<strong class="js iu"> lightgbm </strong>。你可以从可克隆的 GitHub 获得我的增强功能。我建议每月更新，因为<strong class="js iu"> Photonai </strong>是一个正在进行的项目。</p><blockquote class="mf mg mh"><p id="a674" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated"><strong class="js iu">注意</strong>:我已经服从了<strong class="js iu"> Photonai 的外部 API 调用签名。</strong></p><p id="83a9" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated"><strong class="js iu">注</strong> <a class="ae lg" href="https://photon-ai.com" rel="noopener ugc nofollow" target="_blank">:当前文档仍然适用</a>。我的改进只记录在代码和以前关于<strong class="js iu"> <em class="it">中</em> </strong>的博客中。</p><p id="76ce" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated"><strong class="js iu">注</strong>:所有改动我都写了测试。</p></blockquote><p id="a06a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您可以使用以下命令将 Photonai 1.3.0 放在本地项目目录中</p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="947b" class="nr li it ok b gy oo op l oq or">git clone <a class="ae lg" href="https://github.com/bcottman/photon.git" rel="noopener ugc nofollow" target="_blank">https://github.com/bcottman/photon.git</a></span></pre><blockquote class="mf mg mh"><p id="0159" class="jq jr ko js b jt ju jv jw jx jy jz ka mi kc kd ke mj kg kh ki mk kk kl km kn im bi translated"><strong class="js iu">注</strong>:如果你愿意，你可以通过以下方式将<strong class="js iu">光子</strong>包含在笔记本中:</p></blockquote><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="e296" class="nr li it ok b gy oo op l oq or">import sys, o<br/>old__file__ = !pwd<br/>__file__ = !cd ../../../photon ;pwd<br/>__file__ = __file__[0]</span><span id="2de2" class="nr li it ok b gy py op l oq or">sys.path.append(__file__)<br/>print(sys.path)<br/>os.chdir(old__file__[0])<br/>!pwd</span></pre><p id="fe31" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您将针对您的特定目录结构更改<code class="fe ot ou ov ok b">__file__ = !cd ../../../photon </code>。</p><p id="f362" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">注</strong> : <strong class="js iu">光子有一个</strong> <code class="fe ot ou ov ok b"><strong class="js iu">..photon/photonai/docker</strong></code>，用于构建一个<strong class="js iu"> Docker </strong>容器。该目录中指定了两种不同的 Docker 虚拟环境。<code class="fe ot ou ov ok b">dev</code>具有<strong class="js iu"> Jupyter </strong>和<strong class="js iu"> Jupyter 扩展</strong>所需的包版本。此配置在以下章节中有详细说明:</p><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/adding-jupyter-notebook-extensions-to-a-docker-image-851bc2601ca3"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">将 Jupyter 笔记本扩展添加到 Docker 映像</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">我们的 Jupyter Python 和 R 用户的 Docker 映像要求他们在每隔…之后设置他们的 Nbextensions 首选项</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="qp l mz na nb mx nc kz mo"/></div></div></a></div><p id="581c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">注意</strong>:你可以造一个重量更轻的<strong class="js iu"> Docker </strong>集装箱(<code class="fe ot ou ov ok b">test</code>)，没有<strong class="js iu"> Jupyter </strong>，而且是行李。该配置在中有详细说明</p><div class="ml mm gp gr mn mo"><a href="https://medium.com/@dr.bruce.cottman/a-docker-solution-for-the-test-groups-use-cases-8e8ed6c28e11" rel="noopener follow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">我们将 Docker 企业解决方案的速度提高了一倍</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">我们收到了大量关于 Docker 解决方案 0.0.2 版本的反馈。反馈有一个共同的主题:只有 R&amp;D…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">medium.com</p></div></div><div class="mx l"><div class="qq l mz na nb mx nc kz mo"/></div></div></a></div><p id="a241" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当您使用本文中的<a class="ae lg" href="https://github.com/bcottman/photon_experiments/tree/master/Cluster/kmeans-kmedoids" rel="noopener ugc nofollow" target="_blank">示例代码或您的基于<strong class="js iu"> </strong>的<strong class="js iu"> photonai- </strong>项目时，您可以通过使用两个<strong class="js iu"> Docker </strong>映像中的任何一个来省去安装 20 多个包和更改(破坏)您的环境的麻烦。</a></p></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="929c" class="lh li it bd lj lk pe lm ln lo pf lq lr ls pg lu lv lw ph ly lz ma pi mc md me bi translated">什么是 KMeans 聚类算法？</h1><p id="45f5" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated"><strong class="js iu">k 均值</strong>算法如下:</p><ol class=""><li id="3f35" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn os nj nk nl bi translated">首先，我们随机初始化 k 个中心点，称为质心。</li><li id="f606" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">我们将每个数据点聚类标记到其最近的质心。然后，我们更新质心的坐标，这是到目前为止该聚类中包含的所有数据点的平均值(<em class="ko">表示</em>)。</li><li id="2e47" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">我们对给定的迭代次数重复该过程，直到数据点的聚类分配不变为止。</li></ol><p id="bf14" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> Photonai </strong>具有函数<code class="fe ot ou ov ok b">registry</code>，该函数详述了一个元素<strong class="js iu"> Photonai </strong>，调用可更改的签名或超参数。</p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="77f4" class="nr li it ok b gy oo op l oq or">registry.info("KMeans")</span><span id="9dbf" class="nr li it ok b gy py op l oq or">output ==&gt;<br/>----------------------------------<br/>Name: KMeans<br/>Namespace: sklearn.cluster<br/>----------------------------------<br/>Possible Hyperparameters as derived from constructor:<br/>n_clusters                          n_clusters=8                                                               <br/>init                                init='k-means++'                                                           <br/>n_init                              n_init=10                                                                  <br/>max_iter                            max_iter=300                                                               <br/>tol                                 tol=0.0001                                                                 <br/>precompute_distances                precompute_distances='auto'                                                <br/>verbose                             verbose=0                                                                  <br/>random_state                        random_state=None                                                          <br/>copy_x                              copy_x=True                                                                <br/>n_jobs                              n_jobs=None                                                                <br/>algorithm                           algorithm='auto'                                                           <br/>----------------------------------</span></pre><h2 id="e0ad" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">什么是<strong class="ak"> KMedoids </strong>聚类算法？</h2><p id="a6b0" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated"><strong class="js iu"> KMedoids </strong>型号与<strong class="js iu"> KMeans </strong>型号有一个显著的区别。k 形心必须来自数据集中的任何数据点。</p><p id="ab8e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<strong class="js iu"> KMeans 中，</strong>质心是数据点的平均值，而在<strong class="js iu"> KMediods </strong>中，质心必须是数据点之一。有趣的是，一个簇中的数据点越多，越接近<em class="ko"> HAARI </em>和<em class="ko"> ECS </em>的得分<strong class="js iu"> KMeans </strong>和<strong class="js iu"> KMdiods ( </strong> <em class="ko">中心极限定理</em> <strong class="js iu">)。</strong></p><p id="ca7b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> KMedoids </strong>的<strong class="js iu"> Photonai </strong>主叫签名为:</p><pre class="kq kr ks kt gt oj ok ol om aw on bi"><span id="7842" class="nr li it ok b gy oo op l oq or">registry.info("KMedoids")<br/>output ==&gt;<br/>----------------------------------<br/>Name: KMedoids<br/>Namespace: sklearn_extra.cluster<br/>----------------------------------<br/>Possible Hyperparameters as derived from constructor:<br/>n_clusters                          n_clusters=8                                                               <br/>metric                              metric='euclidean'                                                         <br/>init                                init='heuristic'                                                           <br/>max_iter                            max_iter=300                                                               <br/>random_state                        random_state=None                                                          <br/>----------------------------------</span></pre></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="4acc" class="lh li it bd lj lk pe lm ln lo pf lq lr ls pg lu lv lw ph ly lz ma pi mc md me bi translated">使用 KMeans 和<strong class="ak"> KMedoids </strong>进行细胞(<strong class="ak"> <em class="oi">圆形斑点</em> </strong>)计数</h1><p id="4b86" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated">给医学实验室一个细胞样本，要求得到一个细胞计数。让我们看看 KMeans 和 KMedoids 在这项任务中表现如何。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/40ac145cf0386869df539944b802e623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*lucWtr9ityBIAb3wvyeiqw.gif"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">数字</em><strong class="bd lf">k 表示各种细胞计数密度的</strong>细胞(小球形斑点)计数。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi qr"><img src="../Images/993056827af8870936999b198e54959b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o56Y_1bm9Y3nakNPL-1YfA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi"/><strong class="bd lf">k 表是指</strong>各种细胞计数密度的细胞(小球形斑点)计数。</p></figure><p id="c57b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">英寸。 </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/76c817e052466090a0aa091ad2fe4350.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*NgtAL5ZgmsExxzFIXiJi0Q.gif"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">数字</em> <strong class="bd lf"> KMedoids </strong>细胞(小球形斑点)以各种细胞计数密度计数。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi qs"><img src="../Images/59a98a9f587d807a267f8ea041aa87aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TmSt_nkbguA4GWRcypwa5g.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">各种细胞计数密度的<strong class="bd lf"> KMedoids </strong>细胞(小球形斑点)计数表。</p></figure><p id="017f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#cc2:在圆形细胞上，KMeans 的细胞计数误差小于</em> KMedoids <em class="ko">。</em>T57】</strong></p><p id="410c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#cc3: KMediods 具有圆形细胞，计数范围从 1%到 16%。</em> </strong></p><p id="72fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#cc4: </em> KMediods <em class="ko">不如</em> KMeans <em class="ko">对</em> <em class="ko">圆形细胞计数可靠。</em>T71】</strong></p><h2 id="2289" class="nr li it bd lj ns nt dn ln nu nv dp lr kb nw nx lv kf ny nz lz kj oa ob md oc bi translated">使用 KMeans 和 KMedoids 进行单元椭圆斑点计数</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi qt"><img src="../Images/3a4cfa74d4bf156172dc51ca6ce2d17c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PKyn4xBPec6afu0NY4-lIw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">表<strong class="bd lf">k 表示</strong>细胞(小椭圆形斑点)在不同细胞计数密度下的计数。</p></figure><p id="827e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# cc5:</em>k 均值<em class="ko">模型不应用于计数</em> <em class="ko">椭圆形细胞计数。</em>T81】</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/36a61513a052b9e1b1d7ca596839118b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*01vFqdkjGyQ4hgyPMOZ2vg.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf"> KMedoids </strong>细胞(小椭圆形斑点)以各种细胞计数密度计数。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi qu"><img src="../Images/6a98bdb9ebb38e1ae6bc53bd25d0e763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gVN_gM3Axyyiy17XLqzNzA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">不同细胞计数密度的<strong class="bd lf">水母</strong>细胞(小椭圆形斑点)计数表</p></figure><p id="5dc6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#cc6: </em> KMediods <em class="ko">模型不应用于计数</em> <em class="ko">椭圆形细胞计数。</em> </strong></p></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="43f5" class="lh li it bd lj lk pe lm ln lo pf lq lr ls pg lu lv lw ph ly lz ma pi mc md me bi translated">使用 KMeans 和 KMedoids 模型对 Isis 数据集进行聚类</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/06778f15a7e6167a0cf0271e27ca05bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*r5sD8mUj_xKCis3NiGMauw.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em><strong class="bd lf">k 表示</strong>模型对 Isis 数据集进行聚类。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pv"><img src="../Images/a40fab18b5fdda6a2c074a279582530c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3iLjJXVUq2_R8KYxCspTVw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">Isis 数据集的 KMeans 模型聚类得分表。</p></figure><p id="e26f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上图显示了由<strong class="js iu"> KMeans </strong>聚类的原始<strong class="js iu"> Isis </strong>数据集。</p><p id="8261" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> Isis </strong>数据集的特征(列)处于原始比例，因此由每个特征的值形成的轴具有不同的长度。</p><p id="2bb7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不同长度的轴形成一个椭球形状，我们知道<strong class="js iu">k 意味着</strong>不擅长聚类。</p><p id="b2dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> Iris </strong>数据集通过<code class="fe ot ou ov ok b">StandardScale,</code>进行变换，使得每个特征具有相同的单位长度(范围),从 0.0 到 1.0。形成一个椭球体，所有轴的长度都相同。</p><p id="7395" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# i1:</em>k 均值<em class="ko">模型聚类得分通过先用</em> </strong> <code class="fe ot ou ov ok b">StandardScaler.</code>变换数据集来提高</p><p id="d63f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们添加了<strong class="js iu"> PCA </strong>(主成分分析)以将 5 个特征(5 维)Isis 数据集缩减为 2 个主轴(2 维)数据集。</p><p id="42bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#i2: PCA 没有改变</em>k 均值<em class="ko">模型聚类分数。</em>T47】</strong></p><p id="cccb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# i3:</em>k 均值<em class="ko">模型未能找到 Isis 数据集的 3 个聚类。</em>T53】</strong></p><p id="3d0d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察# i4:ECS 指标正确地测量了 3 个数据点集群分配中的 2 个。</em>T57】</strong></p><p id="e66b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#i5:添加 PCA 对这个 KMeanss 聚类没有影响。</em> </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/06778f15a7e6167a0cf0271e27ca05bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/1*r5sD8mUj_xKCis3NiGMauw.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="oi">图</em> <strong class="bd lf"> KMedoids </strong>模型聚类 Isis 数据集。瑞秋·科特曼的动画</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi qv"><img src="../Images/8bf1c30e802d5dc75a30a45295fc6099.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0TCZLO1BUjIbZRNZAzD2wA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">Isis 数据集的<strong class="bd lf"> KMedoids </strong>模型聚类得分表。</p></figure><p id="0e12" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第一个显示了由<strong class="js iu"> KMeans </strong>聚类的原始 Isis 数据集。</p><p id="a117" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Isis 数据集的要素(列)处于其单位比例，因此由每个要素的值形成的轴具有不同的长度。</p><p id="e0e2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不同长度的轴形成一个椭球形状，我们知道<strong class="js iu">k 意味着</strong>不擅长聚类。</p><p id="f8e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虹膜数据集通过<code class="fe ot ou ov ok b">StandardScaler, </code>进行变换，使每个特征具有相同的轴长，从而成为一个椭球体。</p><p id="f723" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#i6: </em> KMediods <em class="ko">模型聚类得分通过先用</em> </strong> <code class="fe ot ou ov ok b">StandardScaler.</code>变换数据集来提高</p><p id="e432" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我们添加了<strong class="js iu"> PCA </strong>(主成分分析)以将 5 个特征(5 维)Isis 数据集缩减为 2 个主轴(2 维)数据集。</p><p id="d4de" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#i7: PCA 没有改变</em> KMediods <em class="ko">模型聚类分数。</em> </strong></p><p id="5cfe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#i8: </em> KMediods <em class="ko">模型找不到 Isis 数据集的 3 个聚类。</em> </strong></p><p id="99bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#i9:应用缩放时，ECS 指标正确测量了 3 个数据点集群分配中的 2 个。</em> </strong></p><p id="b06b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">观察#i10: PCA 伤害这个 KMedoids 聚类。</em> </strong></p></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="ae12" class="lh li it bd lj lk pe lm ln lo pf lq lr ls pg lu lv lw ph ly lz ma pi mc md me bi translated">资源</h1><div class="ml mm gp gr mn mo"><a href="https://medium.com/swlh/21-techniques-to-write-better-python-code-3029f6562483" rel="noopener follow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">编写更好的 Python 代码的 21 种技巧</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">我从 35 年的多个项目的多语言编程中总结了这些技术。那里…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">medium.com</p></div></div><div class="mx l"><div class="qw l mz na nb mx nc kz mo"/></div></div></a></div><div class="ml mm gp gr mn mo"><a href="https://medium.com/@dr.bruce.cottman/seventeen-basic-techniques-from-my-code-review-checklist-8d5f0f7c4bbc" rel="noopener follow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">我的代码审查清单中的 17 项基本技术</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">现在是代码审查时间。你们中的一些人宁愿避免代码审查过程。无论你是编程新手还是…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">medium.com</p></div></div><div class="mx l"><div class="qx l mz na nb mx nc kz mo"/></div></div></a></div><div class="ml mm gp gr mn mo"><a href="https://distill.pub/2016/misread-tsne/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">如何有效地使用 t-SNE</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">一种流行的探索高维数据的方法叫做 t-SNE，是由范德马滕和辛顿提出的…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">istill.pub</p></div></div><div class="mx l"><div class="qy l mz na nb mx nc kz mo"/></div></div></a></div><div class="ml mm gp gr mn mo"><a href="https://medium.com/datadriveninvestor/principal-components-analysis-pca-71cc9d43d9fb" rel="noopener follow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">主成分分析</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">主成分分析是一种无监督学习类的统计技术，用于解释数据在高…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">medium.com</p></div></div><div class="mx l"><div class="qz l mz na nb mx nc kz mo"/></div></div></a></div><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/cross-validation-430d9a5fee22"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">交叉验证—为什么和如何</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">交叉验证在机器学习中的重要性</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="ra l mz na nb mx nc kz mo"/></div></div></a></div><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/hyperparameter-optimization-in-python-part-2-hyperopt-5f661db91324"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">Python 中超参数优化。第二部分:远视。</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">在这个博客系列中，我将比较 python HPO 库。在阅读这篇文章之前，我强烈建议你阅读…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="rb l mz na nb mx nc kz mo"/></div></div></a></div><div class="ml mm gp gr mn mo"><a href="https://medium.com/@yhpf/standardscaler-fd4bef76411d" rel="noopener follow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd iu gy z fp mt fr fs mu fu fw is bi translated">标准缩放器()</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">现在还是星期天，是#weeklypython 的时间了！</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">medium.com</p></div></div></div></a></div></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="389e" class="lh li it bd lj lk pe lm ln lo pf lq lr ls pg lu lv lw ph ly lz ma pi mc md me bi translated">摘要</h1><p id="faec" class="pw-post-body-paragraph jq jr it js b jt od jv jw jx oe jz ka kb of kd ke kf og kh ki kj oh kl km kn im bi translated">本文中<strong class="js iu"> KMeans </strong>和<strong class="js iu"> KMedoids </strong>、<a class="ae lg" href="https://github.com/bcottman/photon_experiments/tree/master/Cluster/kmeans-kmedoids" rel="noopener ugc nofollow" target="_blank">各种运行的所有笔记本都可以在这里找到。</a></p><p id="17a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当我用这些笔记本进行实验时，代码发生了变化。更先进的笔记本有:</p><ul class=""><li id="0fd6" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn ni nj nk nl bi translated">K <a class="ae lg" href="https://github.com/bcottman/photon_experiments/blob/master/Cluster/kmeans-kmedoids/KMeans-ellipse-3-1.0.ipynb" rel="noopener ugc nofollow" target="_blank">表示-椭圆-3–1.0 . ipynb</a></li><li id="2aa3" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated"><a class="ae lg" href="https://github.com/bcottman/photon_experiments/blob/master/Cluster/kmeans-kmedoids/KMedoids-iris.ipynb" rel="noopener ugc nofollow" target="_blank"> KMedoids-iris.ipynb </a></li></ul><p id="9a70" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们进行了 45 次观察，总结如下:</p><p id="6a1e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">1.<em class="ko"> ECS </em>是比<em class="ko"> HAARI </em>更健壮的聚类度量。</p><p id="5d76" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">K-意味着优势</strong></p><ol class=""><li id="d0fd" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn os nj nk nl bi translated">在大多数机器初学者课程中讲授；</li><li id="bc6e" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">比大多数其他聚类算法更快；</li><li id="1e06" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">技术访谈中常见的实施问题。</li><li id="19e2" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">适用于分离的、大小相等的球形集群，其中集群数为 50 或更少。</li><li id="1c6a" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">足以计数在培养物中均匀分布的细胞。</li></ol><p id="8864" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">K-均值偏差</strong></p><ol class=""><li id="5786" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn os nj nk nl bi translated">在非球形集群上性能不佳。</li><li id="e821" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">不同规模的集群性能不佳。</li><li id="75fd" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">每个集群的不同数据点计数性能不佳。</li><li id="8a24" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated">群集未分离时性能不佳。</li><li id="c43d" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn os nj nk nl bi translated"><strong class="js iu"> Isis </strong>数据集性能不佳。</li></ol><p id="c900" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> K-Mediods 优势</strong></p><ol class=""><li id="8110" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn os nj nk nl bi translated">没有。<strong class="js iu">K-methods</strong>与<strong class="js iu"> KMeans </strong>在我们执行的所有实验中的性能相同或更差。</li></ol><p id="5cb0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在以后的文章中，我们将探索<strong class="js iu">凝聚</strong>、<strong class="js iu">线索</strong>、<strong class="js iu">光学</strong>、<strong class="js iu"> DBSCAN </strong>、<strong class="js iu"> Birch </strong>、<strong class="js iu">深度学习集群</strong>模型，以及其他出现的模型。</p><p id="c035" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将通过配对其他集群模型并比较它们的相似性和差异来继续这种乐趣。最后，我们将举行一场比赛，为给定数据集的给定可检测行为找到冠军聚类模型。</p><p id="2c00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">总之，我们希望在回答这些问题方面取得进展:</p><ul class=""><li id="2b0b" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn ni nj nk nl bi translated">我们能开发一个观察的“备忘单”来区分每个聚类模型吗？</li><li id="caf5" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated">我们能否查看数据并缩小我们应该使用的聚类模型的选择范围？</li><li id="cfcd" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated">我们能找到一个元算法，或者一套规则来找到或者选择一个集群模型吗？</li><li id="0165" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated">我们的研究能指导我们得到更好的聚类模型吗？</li></ul><p id="81c9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来的研究，我们比较<strong class="js iu"> Cure </strong>和<strong class="js iu"> DBSCAN </strong>无监督学习聚类模型。</p><p id="b87b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> Cure </strong>承诺解决<strong class="js iu"> K- &lt; x &gt; </strong>簇性能不佳，大小不一致或非球形簇。</p><p id="be9a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">DBS can</strong>(<strong class="js iu">D</strong>en sity-<strong class="js iu">b</strong>ased<strong class="js iu">s</strong>partial<strong class="js iu">c</strong>lustering of<strong class="js iu">a</strong>applications with<strong class="js iu">n</strong>oise)是最常见的聚类算法之一。我们将看到为什么(或为什么不)。</p><p id="10cd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过我们的第一项研究，我们开始了对无监督学习聚类模型的详细研究之旅。</p></div></div>    
</body>
</html>