<html>
<head>
<title>Legal Applications of Neural Word Embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经单词嵌入的法律应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/legal-applications-of-neural-word-embeddings-556b7515012f?source=collection_archive---------35-----------------------#2020-08-06">https://towardsdatascience.com/legal-applications-of-neural-word-embeddings-556b7515012f?source=collection_archive---------35-----------------------#2020-08-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7337" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">探索法律领域中的词语嵌入</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/92734e28086754f1e74af5fe4b3d3c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mWerYTuy9xH4SlRY9fFg1A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space" rel="noopener ugc nofollow" target="_blank">谷歌开发者</a></p></figure><p id="cff8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">LegalTech 的一个基本问题是，文字——所有法律文件的基本货币——是一种机器无法直观理解的非结构化数据形式。因此，为了处理文本文档，单词必须用实数向量来表示。</p><p id="e377" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">传统上，像单词袋(BoW)这样的方法将单词标记/n 元语法映射到术语频率向量，术语频率向量表示单词在文档中出现的次数。使用一键编码，每个单词标记/n 元语法由一个向量元素表示，并根据单词在文档中是否出现或出现的次数标记为 0、1、2 等。这意味着，如果一个单词在语料库词汇表中不存在，该元素将被标记为 0，如果它存在一次，该元素将被标记为 1，依此类推。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/fa97828042103d8b0a4521418dbb0cf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*eolejkgiYNAbd_NTXl7rkA.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://www.analyticssteps.com/blogs/an-optimum-approach-towards-the-bag-of-words-with-code-illustration-in-python" rel="noopener ugc nofollow" target="_blank">分析步骤</a></p></figure><p id="933c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">问题是这产生了非常高维度的非常稀疏的矩阵(即大部分包含零)。例如，具有 30，000 个唯一单词标记的语料库将需要具有 30，000 行的矩阵，这在计算上是极其繁重的。此外，这种方法不能捕捉语义、上下文和单词关系，因为它只能显示单词在文档中出现的频率。这种无法表示语义的情况持续存在，即使 BoW 由 TF-IDF 度量补充，因为虽然后者能够表示单词对语料库有多重要的度量(即，相对于普通 BoW 表示的改进)，但它仍然是基于单词令牌/n-gram 在语料库中出现的频率来计算的。</p><p id="70e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相比之下，现代单词嵌入(word2vec、GloVE、fasttext 等)依赖于神经网络来将单词的语义属性映射到维度明显更少的密集向量表示中。</p><p id="d5af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，应该说单词嵌入是以分布语义假设为前提的，即在相同的上下文中使用和出现的单词往往具有相似的含义。这意味着神经网络通过单词所在的上下文来学习单词的矢量表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/bcc15836a53baa2a14d7dcd53f402afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*14f8OPOJIu6g-cE5gqLwDA.png"/></div></div></figure><p id="e1ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的“上下文”由大小为<em class="lu"> n </em>的滑动上下文窗口表示，其中目标单词之前的<em class="lu"> n </em>个单词和目标单词之后的<em class="lu"> n </em>个单词将落入上下文窗口内(例如，在该示例中<em class="lu"> n </em> =2)。然后，当上下文窗口沿着句子向下移动时，该模型将通过使用一个热点编码的上下文向量来训练，以预测一个热点编码的目标向量。</p><p id="5485" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这样做的时候，单词嵌入可以捕获 BoW 没有捕获到的语义关联和语言上下文。本文将探讨法律人工智能技术中神经单词嵌入的影响。</p><h1 id="7e60" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated"><strong class="ak"> <em class="mn">捕捉法律术语之间的关系</em> </strong></h1><p id="c616" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">单词嵌入的一个重要含义是它捕获了单词之间的语义关系。</p><ol class=""><li id="75f4" class="mt mu iq ky b kz la lc ld lf mv lj mw ln mx lr my mz na nb bi translated">具有相似含义和上下文的单词将在向量空间中占据更近的空间位置，如余弦相似性所测量的。这些词向量也可以相加或相乘，而不会失去它们固有的语义特征和关系。</li><li id="de6a" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr my mz na nb bi translated">编码单词之间的矢量差也可以表示单词之间的关系。例如，在“男人是国王，女人是王后”中的单词关系可以用 vec(国王)-vec(男人)+ vec(女人)= vec(王后)来表达。在法律领域，Ash (2016 年)同样表明，公司税和所得税之间的关系可以通过 vec(公司所得税)-vec(公司)+ vec(个人)= vec(个人所得税)来描述。</li></ol><p id="1347" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">描绘出法律术语和对象之间的关系的能力在提高我们对法律推理的理解的能力方面具有令人兴奋的含义。一个有趣的方向是利用 doc2vec 对司法意见进行潜在的矢量化，以识别/聚类具有相似信念模式的法官(基于法律意见的保守性、引用的判例等)。</p><p id="0f49" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一个功能是，词嵌入可以捕捉司法意见中隐含的种族和性别偏见，这是通过词嵌入联想测试(WEAT)来衡量的。单词嵌入是强大的，因为它们可以用数学或图表的形式表现社会偏见。例如，Bolukbasi (2016 年)表明，在谷歌新闻文章上训练的单词嵌入表现出显著的性别偏见，这可以通过单词嵌入的方向以几何方式捕获(即，性别中立的单词可以与性别中立的单词线性分离)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/5b9003bb0c5be6a4b1d795ee078e0b86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-eZ70oFGQ-L7vlQzqXhASw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://www.semanticscholar.org/paper/Man-is-to-Computer-Programmer-as-Woman-is-to-Word-Bolukbasi-Chang/ccf6a69a7f33bcf052aa7def176d3b9de495beb7" rel="noopener ugc nofollow" target="_blank">https://www . semantic scholar . org/paper/Man-is-to-Computer-Programmer-as-Woman-is-to-Word-Bolukbasi-Chang/CCF 6a 69 a 7 f 33 BCF 052 a 7 def 176d 3 b 9 de 495 beb 7)</a></p></figure><p id="0cc9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，单词嵌入可以反映向量关系，如“男人对于程序员，就像女人对于家庭主妇”，因为单词“男人”在谷歌新闻语料库中更频繁地与单词“程序员”或“工程师”一起出现，而单词“女人”将更频繁地出现在“家庭主妇”或“护士”旁边。</p><p id="9f48" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">应用于法律领域，我们可以将司法意见的 WEAT 分数制成表格，该领域的初步研究显示了有趣的趋势，例如(I)男性法官比女性法官显示出更高的性别偏见(即更高的 WEAT 分数),以及(ii)白人法官比黑人法官显示更低的种族偏见。在这一领域还有更多有待探索。</p><h1 id="3275" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated"><strong class="ak"> <em class="mn">提高法学研究</em> </strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/1fc6be509aadc925cc02abae14c0f68f.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*U_7r4pIq27u--uY_wwRlVQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:http://mlwiki.org/index.php/Information_Retrieval<a class="ae kv" href="http://mlwiki.org/index.php/Information_Retrieval" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="1fa6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">单词嵌入对于改进法律研究平台(在机器学习术语中称为法律信息检索(LIR)系统)背后的技术也具有根本性的意义。</p><p id="552a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目前，大多数 LIR 系统(如 Westlaw 和 LexisNexis)仍然是主要利用关键字搜索功能的布尔索引系统。</p><p id="baac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这意味着系统通常通过使用基于字符串的算法来测量两个文本字符串之间的相似性，来寻找查询关键字的文字匹配或变体。然而，这些类型的搜索无法理解律师查询背后的意图，这意味着搜索结果通常包含不足(即，缺少不包含关键字的相关信息，但可能是其变体)或包含过度(即，返回包含关键字的不相关信息)。</p><p id="0363" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，单词嵌入增强了商用语义搜索 LIR 的潜力。因为它允许从业者以数学方式捕捉语义相似性，所以单词嵌入可以帮助 LIR 系统找到不仅是查询字符串的精确匹配的结果，而且是可能相关或语义接近但在某些单词上不同的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/469001e1f31aaf0824a21ce1aac3cb8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i7gHhDUNAPp6APF564ep-w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://www.ontotext.com/knowledgehub/fundamentals/what-is-semantic-search/" rel="noopener ugc nofollow" target="_blank">https://www . onto text . com/knowledge hub/fundamentals/what-is-semantic-search/</a></p></figure><p id="00e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，Landthaler 表明，有效的结果可以通过首先将每个搜索短语中的单词向量相加为一个搜索短语向量来产生。然后，通过大小为<em class="lu"> n </em>(其中<em class="lu"> n </em> =搜索短语中的字数)的窗口顺序解析该文档，并且计算搜索短语向量和累积向量的余弦相似度。这不仅能够返回精确的关键字匹配结果，还能够返回语义相关的搜索结果，从而提供更直观的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/a65ff45f4af9be0642e82fcbd3d589d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*kTuU8dh-W253SCVb-B5xow.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://www.lawtechnologytoday.org/2017/11/legal-consumer-research/" rel="noopener ugc nofollow" target="_blank">https://www . law technology today . org/2017/11/legal-consumer-research/</a></p></figure><p id="ea99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这一点尤其重要，因为研究表明，使用布尔索引搜索 LIR 系统(在全文法律文档中搜索查询术语的精确匹配)的参与者的召回率可能低至 20%(即，LIR 仅检索到 20%的相关文档)。然而，平均而言，这些参与者估计他们的检索率高达 75%，这要高得多。这意味着律师经常会忽略可能支持他们案件的相关先例或判例法，只是因为 LIR 系统将字符串相似性置于语义相似性之上。因此，单词嵌入具有显著解决这一不足的潜力。</p><h1 id="4eae" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated"><strong class="ak"> <em class="mn">结论与未来走向</em> </strong></h1><p id="7081" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">总的来说，神经单词嵌入的领域是迷人的。不仅从数学上捕捉语义上下文和单词关系的能力在学术上引人入胜，单词嵌入也是市场上许多法律技术产品背后的一个非常重要的驱动力。</p><p id="b724" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，单词嵌入不是没有限制的，ML 实践者有时转向更新的预训练语言建模技术(例如，ULMFit、ELMo、OpenAI transformer 和 BERT)来克服单词嵌入的一些固有问题(例如，假设单义)。尽管如此，词嵌入仍然是当今最吸引人的 NLP 主题之一，从稀疏的、基于频率的向量表示向更密集的语义表示向量的转变是推进 NLP 子域和法律人工智能领域的关键一步。</p></div></div>    
</body>
</html>