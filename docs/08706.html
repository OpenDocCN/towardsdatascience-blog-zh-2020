<html>
<head>
<title>Building a Scikit-Learn ColumnTransformer Dynamically</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">动态学习ColumnTransformer</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-columntransformers-dynamically-1-6354bd08aa54?source=collection_archive---------45-----------------------#2020-06-23">https://towardsdatascience.com/building-columntransformers-dynamically-1-6354bd08aa54?source=collection_archive---------45-----------------------#2020-06-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e9c7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用逻辑条件为不同类型的变换选择特征类型</h2></div><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="ab gu cl kn"><img src="../Images/1703bd0d24bf6e5bfcad602c042f580e.png" data-original-src="https://miro.medium.com/v2/0*5CzcvyFB1Kpz4VhJ"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来源:<a class="ae ku" href="https://unsplash.com/photos/-fGqsewtsJY" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="4115" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">特征工程可能是机器学习过程中非常耗时的部分，尤其是当您处理许多特征和不同类型的特征时。在我的项目过程中，我开发了一些启发式方法，允许我构造一个相当有效的Scikit——快速动态地学习ColumnTransformer。</p><p id="df89" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在我的文章中，我将展示两种技术。首先，我将展示如何用逻辑条件选择特性，而不是在代码中列出每一列。其次，我将解释在训练一个新模型时，我用作“默认”的transformer管道。我将在爱荷华州的房价数据集上展示我的技术，你可以在<a class="ae ku" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到。</p><p id="0ac4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在继续之前，我应该指出，我的帖子假设您以前使用过Scikit-Learn和Pandas，并且熟悉<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html" rel="noopener ugc nofollow" target="_blank"> ColumnTransformer </a>、<a class="ae ku" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.pipeline" rel="noopener ugc nofollow" target="_blank"> Pipeline </a>、&amp;、<a class="ae ku" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing" rel="noopener ugc nofollow" target="_blank">预处理类</a>如何促进可再现的特征工程过程。如果您需要复习，请查看这个Scikit-Learn <a class="ae ku" href="https://scikit-learn.org/stable/modules/compose.html#columntransformer-for-heterogeneous-data" rel="noopener ugc nofollow" target="_blank">示例</a>。</p><p id="037d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们从导入所需的包、类、函数和数据开始。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="bd39" class="lw lx it ls b gy ly lz l ma mb">import numpy as np  <br/>import pandas as pd  <br/><br/>import plotly.express as px<br/><br/>from sklearn.preprocessing import OneHotEncoder<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.compose import ColumnTransformer, make_column_selector<br/>from sklearn.pipeline import make_pipeline<br/>from sklearn.ensemble import GradientBoostingRegressor<br/>from sklearn.metrics import r2_score, mean_squared_log_error<br/>import category_encoders as ce<br/><br/>DEP_VAR = 'SalePrice'<br/><br/>train_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv').set_index('Id')<br/><br/># split the dependent variable from the features<br/>y_train = train_df[DEP_VAR]<br/>train_df.drop(DEP_VAR, axis=1, inplace=True)<br/><br/>test_df =  pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv').set_index('Id')</span></pre><h2 id="dec3" class="lw lx it bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">数据集</h2><p id="fb73" class="pw-post-body-paragraph kv kw it kx b ky mt ju la lb mu jx ld le mv lg lh li mw lk ll lm mx lo lp lq im bi translated">Ames训练数据集具有相对少量的观察值和相当数量的特征(79个)。这些特征中有43个是分类的，36个是数字的。如果您对数据集上的一些探索性数据分析感兴趣，我推荐您阅读本笔记本。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="b6f6" class="lw lx it ls b gy ly lz l ma mb">print(train_df.shape)</span><span id="3f13" class="lw lx it ls b gy my lz l ma mb"><strong class="ls iu">(1460, 79)</strong></span><span id="f2e6" class="lw lx it ls b gy my lz l ma mb">feature_types =\<br/>    train_df\<br/>    .dtypes\<br/>    .astype(str)\<br/>    .value_counts()\<br/>    .to_frame('count')\<br/>    .rename_axis('datatype')\<br/>    .reset_index()</span><span id="efd7" class="lw lx it ls b gy my lz l ma mb">px.bar(feature_types, x='datatype', y='count', color='datatype')\<br/>    .update_layout(showlegend=False)\<br/>    .update_layout(title={'text': 'Ames Dtypes', 'x': .5})</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/62d5052fa07974c9d5d047ad1b31df17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z3GOqp0gqVFIfu3eGWRYSg.png"/></div></div></figure><h1 id="34e4" class="ne lx it bd mc nf ng nh mf ni nj nk mi jz nl ka ml kc nm kd mo kf nn kg mr no bi translated">特征的类型</h1><p id="2587" class="pw-post-body-paragraph kv kw it kx b ky mt ju la lb mu jx ld le mv lg lh li mw lk ll lm mx lo lp lq im bi translated">如果您和我一样，那么在代码或配置文件中列出79个特性的想法似乎是一项乏味且不必要的任务。如果有一种方法可以根据这些特性在逻辑上将它们联系起来，那会怎么样呢？</p><p id="57ca" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">允许您动态构造ColumnTransformer的关键见解是理解在非文本、非时间序列数据集中有三大类特征:</p><ol class=""><li id="865b" class="np nq it kx b ky kz lb lc le nr li ns lm nt lq nu nv nw nx bi translated">数字的</li><li id="749f" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq nu nv nw nx bi translated">具有中低基数的分类</li><li id="2514" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq nu nv nw nx bi translated">高基数分类</li></ol><p id="39ba" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们来看看如何动态地选择每种特性类型以及我与之一起使用的默认转换器管道。</p><h2 id="ca8b" class="lw lx it bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">数字特征</h2><p id="f1e6" class="pw-post-body-paragraph kv kw it kx b ky mt ju la lb mu jx ld le mv lg lh li mw lk ll lm mx lo lp lq im bi translated">sklearn.compose模块附带了一个名为<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_selector.html" rel="noopener ugc nofollow" target="_blank"> make_column_selector </a>的方便的类，它提供了一些有限的功能来动态选择列。您可以列出要包含或排除的dtypes，或者使用regex模式来选择列名。为了选择数字特性，我们将实例化一个函数来选择np.number数据类型的列，它将匹配任何整数或浮点列。当我们在训练数据集上调用<code class="fe od oe of ls b">select_numeric_features</code>时，我们看到它正确地选择了36个<code class="fe od oe of ls b">int64</code>和<code class="fe od oe of ls b">float64</code>列。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="a12b" class="lw lx it ls b gy ly lz l ma mb">select_numeric_features = make_column_selector(dtype_include=np.number)<br/><br/>numeric_features = select_numeric_features(train_df)<br/><br/>print(f'N numeric_features: {len(numeric_features)} \n')<br/>print(', '.join(numeric_features))</span><span id="aa6a" class="lw lx it ls b gy my lz l ma mb"><strong class="ls iu">N numeric_features: 36 <br/><br/>MSSubClass, LotFrontage, LotArea, OverallQual, OverallCond, YearBuilt, YearRemodAdd, MasVnrArea, BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr, TotRmsAbvGrd, Fireplaces, GarageYrBlt, GarageCars, GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal, MoSold, YrSold</strong></span></pre><p id="adc6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我的默认数字特征转换包括使用<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank">简单估算器</a>。我用中间值估算缺失值，并将<code class="fe od oe of ls b">add_indicator</code>参数设置为<code class="fe od oe of ls b">True</code>。使用中位数代替估算者的平均缺省值可以防止离群值的影响。使用<code class="fe od oe of ls b">add_indicator</code>功能调用<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html#sklearn.impute.MissingIndicator" rel="noopener ugc nofollow" target="_blank"> MissingIndicator类</a>，该类为每个具有缺失值的特性创建二进制缺失指示器列。根据我的经验，当数据不是随机丢失时，这些列对模型来说可能是相当重要的。</p><p id="6e52" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">需要注意一些事情:</p><ul class=""><li id="4545" class="np nq it kx b ky kz lb lc le nr li ns lm nt lq og nv nw nx bi translated">当我构建转换器管道时，我更喜欢使用<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html" rel="noopener ugc nofollow" target="_blank"> make_pipeline </a>函数，而不是pipeline类。该函数通过自动使用小写版本的类名，取代了显式命名每个管道步骤的要求，例如，simple imputr被命名为“simple imputr”。</li><li id="1a46" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq og nv nw nx bi translated">Scikit-Learn估算器要求用<code class="fe od oe of ls b">np.nan</code>表示缺失的值——因此，我使用了<code class="fe od oe of ls b">fillna</code>方法。</li><li id="00fc" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq og nv nw nx bi translated">如果你要使用线性模型，你要在估算器前插入一个<a class="ae ku" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing" rel="noopener ugc nofollow" target="_blank">预处理器</a>来居中和缩放。</li><li id="1e4f" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq og nv nw nx bi translated">简单估算器的更复杂的替代品包括需要居中和缩放的<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer" rel="noopener ugc nofollow" target="_blank"> KNNImputer </a>，或者实验性的<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer" rel="noopener ugc nofollow" target="_blank">迭代估算器</a>。</li></ul><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="3cf5" class="lw lx it ls b gy ly lz l ma mb">train_df.fillna(np.nan, inplace=True)<br/>test_df.fillna(np.nan, inplace=True)<br/><br/>numeric_pipeline = make_pipeline(SimpleImputer(strategy='median', add_indicator=True))</span></pre><h2 id="4e82" class="lw lx it bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">具有中低基数的分类</h2><p id="490b" class="pw-post-body-paragraph kv kw it kx b ky mt ju la lb mu jx ld le mv lg lh li mw lk ll lm mx lo lp lq im bi translated">接下来，让我们讨论如何选择名义数据并将其转换为数字形式。</p><p id="78ad" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><a class="ae ku" href="https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">一键(OH)编码</a>，为每个唯一值创建一个指示列，是最常用的方法。然而，OH转换可能不适合具有高基数<a class="ae ku" href="https://en.wikipedia.org/wiki/Cardinality" rel="noopener ugc nofollow" target="_blank">的特性</a>。具有许多唯一值的OH编码功能可能会创建太多方差非常低的列，这可能会占用太多内存或对线性模型的性能产生负面影响。因此，我们可能希望将我们为这种编码选择的特征限制在某个唯一值阈值以下。为了便于说明，我将把我的限制设置为10个值。实际上，根据数据集的大小，我们可能会选择更高的阈值。</p><p id="e0d4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">由于<code class="fe od oe of ls b"><a class="ae ku" href="https://github.com/scikit-learn/scikit-learn/issues/15873" rel="noopener ugc nofollow" target="_blank">make_column_selector</a></code> <a class="ae ku" href="https://github.com/scikit-learn/scikit-learn/issues/15873" rel="noopener ugc nofollow" target="_blank">不能检测基数</a>，我开发了自己的<code class="fe od oe of ls b">select_oh_features</code>自定义函数。它由一系列pandas方法组成，这些方法执行以下操作:</p><ul class=""><li id="3046" class="np nq it kx b ky kz lb lc le nr li ns lm nt lq og nv nw nx bi translated">从熊猫<code class="fe od oe of ls b">DataFrame</code>中选择<code class="fe od oe of ls b">object</code>和<code class="fe od oe of ls b">category</code>d型</li><li id="6fc2" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq og nv nw nx bi translated">计算这些列的唯一值的数量</li><li id="9587" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq og nv nw nx bi translated">使用<code class="fe od oe of ls b">loc</code>方法中的匿名<code class="fe od oe of ls b">lambda</code>函数对小于或等于<code class="fe od oe of ls b">MAX_OH_CARDINALITY</code>的唯一值计数进行子集化</li><li id="7899" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq og nv nw nx bi translated">从索引中提取列名，并将它们作为列表返回</li></ul><p id="a7b5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当我们对训练数据集调用该函数时，我们看到它选择了43个分类特征中的40个。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="dc31" class="lw lx it ls b gy ly lz l ma mb">MAX_OH_CARDINALITY = 10<br/><br/>def select_oh_features(df):<br/>    <br/>    oh_features =\<br/>        df\<br/>        .select_dtypes(['object', 'category'])\<br/>        .apply(lambda col: col.nunique())\<br/>        .loc[lambda x: x &lt;= MAX_OH_CARDINALITY]\<br/>        .index\<br/>        .tolist()<br/>        <br/>    return oh_features<br/><br/>oh_features = select_oh_features(train_df)<br/><br/>print(f'N oh_features: {len(oh_features)} \n')<br/>print(', '.join(oh_features))</span><span id="53bb" class="lw lx it ls b gy my lz l ma mb"><strong class="ls iu">N oh_features: 40 <br/><br/>MSZoning, Street, Alley, LotShape, LandContour, Utilities, LotConfig, LandSlope, Condition1, Condition2, BldgType, HouseStyle, RoofStyle, RoofMatl, MasVnrType, ExterQual, ExterCond, Foundation, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, Heating, HeatingQC, CentralAir, Electrical, KitchenQual, Functional, FireplaceQu, GarageType, GarageFinish, GarageQual, GarageCond, PavedDrive, PoolQC, Fence, MiscFeature, SaleType, SaleCondition</strong></span></pre><p id="9d76" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于具有中低基数的分类特性，我有两个默认转换:<code class="fe od oe of ls b">SimpleImputer</code>和<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" rel="noopener ugc nofollow" target="_blank"> OneHotEncoder </a></p><p id="bbbd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在<code class="fe od oe of ls b">SimpleImputer</code>中，使用“常量”策略将缺失值设置为“missing_value”(我没有将<code class="fe od oe of ls b">add_indicator</code>参数设置为<code class="fe od oe of ls b">True</code>，因为这会创建重复的列。)在OH编码器中，我喜欢将<code class="fe od oe of ls b">handle_unknown</code>参数设置为“忽略”，而不是使用默认的“错误”，这样，如果这个转换器在测试数据集中遇到未知值，它就不会抛出错误。相反，如果出现这种情况，它会将所有OH列设置为零。因为Ames测试数据集包含不在训练数据集中的分类值，所以如果不使用此设置，我们的ColumnTransformer将在测试数据集上失败。如果您计划使用线性模型，您将需要设置<code class="fe od oe of ls b">drop</code>参数，以使特征不完全共线。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="cb90" class="lw lx it ls b gy ly lz l ma mb">oh_pipeline = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder(handle_unknown='ignore'))</span></pre><h2 id="f3b2" class="lw lx it bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">高基数分类</h2><p id="0529" class="pw-post-body-paragraph kv kw it kx b ky mt ju la lb mu jx ld le mv lg lh li mw lk ll lm mx lo lp lq im bi translated">为了选择具有高基数的特性，我创建了一个类似的函数来选择唯一值计数大于阈值的<code class="fe od oe of ls b">object</code>和<code class="fe od oe of ls b">category</code>特性。它选择满足这些标准的三个特征。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="4c74" class="lw lx it ls b gy ly lz l ma mb">def select_hc_features(df):<br/>    <br/>    hc_features =\<br/>        df\<br/>        .select_dtypes(['object', 'category'])\<br/>        .apply(lambda col: col.nunique())\<br/>        .loc[lambda x: x &gt; MAX_OH_CARDINALITY]\<br/>        .index\<br/>        .tolist()<br/>        <br/>    return hc_features<br/><br/><br/>hc_features = select_hc_features(train_df)<br/><br/>print(f'N hc_features: {len(hc_features)} \n')<br/>print(', '.join(hc_features))</span><span id="af5e" class="lw lx it ls b gy my lz l ma mb"><strong class="ls iu">N hc_features: 3 <br/><br/>Neighborhood, Exterior1st, Exterior2nd</strong></span></pre><p id="e1c4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为了用高基数转换我们的特性，我可以采用更基本的方法，使用Scikit-Learn的原生<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder" rel="noopener ugc nofollow" target="_blank"> LabelEncoder </a>或<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder" rel="noopener ugc nofollow" target="_blank"> OrdinalEncoder </a>预处理器。然而，在许多情况下，这些方法很可能在您的模型中执行次优，除非您处理的是顺序数据。我更喜欢使用<a class="ae ku" href="http://contrib.scikit-learn.org/category_encoders" rel="noopener ugc nofollow" target="_blank">类别编码器</a>包，它有十几种智能编码高度基本特征的方法。<a class="ae ku" rel="noopener" target="_blank" href="/all-about-categorical-variable-encoding-30">本帖</a>提供了其中几种方法的概述。其中大多数是监督技术，使用因变量将标称值转换为数值。</p><p id="5cb8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><a class="ae ku" href="http://contrib.scikit-learn.org/category_encoders/targetencoder.html" rel="noopener ugc nofollow" target="_blank"> TargetEncoder </a>可能是最容易理解的方法，但我更喜欢使用<a class="ae ku" href="http://contrib.scikit-learn.org/category_encoders/glmm.html" rel="noopener ugc nofollow" target="_blank">广义线性混合模型编码器</a>，它“背后有坚实的统计理论”，并且“不需要调整超参数”在不深入GLMMs 的<a class="ae ku" href="https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-generalized-linear-mixed-models/" rel="noopener ugc nofollow" target="_blank">细节的情况下，该方法的核心是将标称值编码为来自一个热编码线性模型的系数。这个包中的类别编码器方法通过将缺失值和未知值设置为零或因变量的平均值来处理它们。</a></p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="1016" class="lw lx it ls b gy ly lz l ma mb">hc_pipeline = make_pipeline(ce.GLMMEncoder())</span></pre><h1 id="675a" class="ne lx it bd mc nf ng nh mf ni nj nk mi jz nl ka ml kc nm kd mo kf nn kg mr no bi translated">把所有的放在一起</h1><p id="979d" class="pw-post-body-paragraph kv kw it kx b ky mt ju la lb mu jx ld le mv lg lh li mw lk ll lm mx lo lp lq im bi translated">最后，让我们把所有的部分放在一起，实例化我们的ColumnTransformer:</p><ul class=""><li id="a178" class="np nq it kx b ky kz lb lc le nr li ns lm nt lq og nv nw nx bi translated"><code class="fe od oe of ls b">transformer</code>参数接受一个由3个元素组成的元组列表。每个元组包含转换器/管道的名称、实例化的管道以及我们为该管道创建的选择器函数。</li><li id="1e1f" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq og nv nw nx bi translated">如果您正在处理大量的特性，并且具有多线程能力，我肯定会设置<code class="fe od oe of ls b">n_jobs</code>参数，这样管道就可以并行运行。将其设置为-1将使用所有可用的线程。</li><li id="c1a7" class="np nq it kx b ky ny lb nz le oa li ob lm oc lq og nv nw nx bi translated">最后，我想提醒大家注意<code class="fe od oe of ls b">remainder</code>参数。默认情况下，ColumnTransformer会删除任何不包含在<code class="fe od oe of ls b">transformers</code>列表中的列。或者，如果您有不需要转换的功能，您可以将此参数设置为“passthrough ”,并且不删除任何剩余的功能。</li></ul><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="6386" class="lw lx it ls b gy ly lz l ma mb">column_transformer =\<br/>    ColumnTransformer(transformers=\<br/>                          [('numeric_pipeline',\<br/>                            numeric_pipeline,\<br/>                            select_numeric_features),\<br/>                          ('oh_pipeline',\<br/>                           oh_pipeline,\<br/>                           select_oh_features),\<br/>                          ('hc_pipeline',\<br/>                           hc_pipeline,\<br/>                           select_hc_features)],<br/>                      n_jobs=-1,<br/>                      remainder='drop')</span></pre><h1 id="a4b1" class="ne lx it bd mc nf ng nh mf ni nj nk mi jz nl ka ml kc nm kd mo kf nn kg mr no bi translated">结果</h1><p id="a2cc" class="pw-post-body-paragraph kv kw it kx b ky mt ju la lb mu jx ld le mv lg lh li mw lk ll lm mx lo lp lq im bi translated">在安装ColumnTransformer并转换数据之后，OH编码将列数从79增加到254。如果我们没有使用<code class="fe od oe of ls b">GLMMEncoder</code>，我们将会处理300多列。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="94f4" class="lw lx it ls b gy ly lz l ma mb">X_train = column_transformer.fit_transform(train_df, y_train)<br/>X_test = column_transformer.transform(test_df)<br/><br/>print(X_train.shape)<br/>print(X_test.shape)</span><span id="a5b4" class="lw lx it ls b gy my lz l ma mb"><strong class="ls iu">(1460, 254)<br/>(1459, 254)</strong></span></pre><p id="8010" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们看看在没有严格的超参数调整的情况下，工程特性在GBM回归器上的表现如何。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="b759" class="lw lx it ls b gy ly lz l ma mb">model = GradientBoostingRegressor(learning_rate=0.025,\<br/>                                  n_estimators=1000,\<br/>                                  subsample=0.25,\<br/>                                  max_depth=5,\<br/>                                  min_samples_split=50,\<br/>                                  max_features='sqrt')<br/>model.fit(X_train, y_train)<br/><br/>y_train_pred = model.predict(X_train)</span></pre><p id="bb44" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">由于R平方值接近1，我们的特征几乎可以解释训练集因变量的所有变化。均方根对数误差接近0.084。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="9925" class="lw lx it ls b gy ly lz l ma mb">print(f'R-squared: {r2_score(y_train, y_train_pred)}')<br/>print(f'RMSLE: {np.sqrt(mean_squared_log_error(y_train, y_train_pred))}')</span><span id="f9a4" class="lw lx it ls b gy my lz l ma mb"><strong class="ls iu">R-squared: </strong><strong class="ls iu">0.9696430970867915</strong><strong class="ls iu"><br/>RMSLE: </strong><strong class="ls iu">0.08434172203520345</strong></span></pre><p id="a74e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">然而，当我向Kaggle提交我的测试预测时，测试RMSLE结果是0.132。训练和测试RMSLE之间的差距表明该模型过拟合，并且它将受益于正则化和超参数调整。</p><pre class="ki kj kk kl gt lr ls lt lu aw lv bi"><span id="0d14" class="lw lx it ls b gy ly lz l ma mb">submission = pd.DataFrame(dict(Id=test_df.index, <br/>                               SalePrice=model.predict(X_test)))<br/>submission.to_csv("submission.csv", index=False)</span></pre></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="e7f7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">笔记本原图可以在这里找到<a class="ae ku" href="https://www.kaggle.com/kylegilde/building-columntransformers-dynamically" rel="noopener ugc nofollow" target="_blank">。请继续关注关于培训&amp;用Scikit正则化模型的更多帖子。如果你觉得这篇文章有帮助或者有任何改进的想法，请告诉我。谢谢！</a></p></div></div>    
</body>
</html>