<html>
<head>
<title>Fast and Arbitrary Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">快速任意的风格转换</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fast-and-arbitrary-style-transfer-40e29d308dd3?source=collection_archive---------34-----------------------#2020-09-14">https://towardsdatascience.com/fast-and-arbitrary-style-transfer-40e29d308dd3?source=collection_archive---------34-----------------------#2020-09-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2ce7" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">神经类型转移，进化</h2><div class=""/><div class=""><h2 id="28ad" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">基于自适应实例归一化的图像风格转换</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/73d6a27ec264b186772fb54d279a7c13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9kGOSNMUC2W384yAW9PPlQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@steve_j?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">斯蒂夫·约翰森</a>在<a class="ae lh" href="https://unsplash.com/s/photos/modern-art?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h2 id="39d7" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">介绍</h2><p id="9036" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">加蒂丝<em class="mw">等人的开创性工作</em>。[R1]表明深度神经网络(DNNs)不仅编码图像的<strong class="mf jd"><em class="mw"/></strong>内容，还编码图像的<strong class="mf jd"> <em class="mw">风格</em> </strong> <em class="mw"> </em>信息。此外，图像样式和内容在某种程度上是可分的:可以在保留图像内容的同时改变其样式。他们的<a class="ae lh" rel="noopener" target="_blank" href="/slow-and-arbitrary-style-transfer-3860870c8f0e"> <em class="mw">方法</em> </a>足够灵活，可以将<strong class="mf jd"> <em class="mw">的内容和风格任意组合</em> </strong>的画面。然而，它依赖于一个<strong class="mf jd"> <em class="mw">非常慢</em> </strong>的优化过程。</p><p id="76c6" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">具有前馈神经网络的快速近似[R2，R3]已经被提议用于<strong class="mf jd"> <em class="mw">加速</em> </strong>神经类型转移。不幸的是，速度的提高是有代价的:网络要么被<strong class="mf jd"><em class="mw"/></strong>限制为一个<a class="ae lh" rel="noopener" target="_blank" href="/fast-and-restricted-style-transfer-bbfc383cccd6"> <em class="mw">单一样式</em> </a> <em class="mw">，</em>或<em class="mw"> </em>网络被束缚于一个<a class="ae lh" rel="noopener" target="_blank" href="/fast-and-less-restricted-style-transfer-50366c43f672"> <em class="mw">样式</em> </a> <em class="mw">的有限集合。</em></p><p id="a5bd" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">黄和解决了这个基本的灵活性和速度的两难问题。众所周知，CNN 的<strong class="mf jd"> <em class="mw">卷积特征统计</em> </strong>可以捕捉到一幅图像的风格。Gatys<em class="mw">et al .</em>【R1】使用二阶统计量作为优化目标，而 Li<em class="mw">et al .</em>【R5】表明匹配许多其他统计量，包括通道方式的均值和方差，对于风格转换也是有效的。因此，我们可以认为<a class="ae lh" href="https://becominghuman.ai/all-about-normalization-6ea79e70894b" rel="noopener ugc nofollow" target="_blank"> <strong class="mf jd"> <em class="mw">实例归一化</em> </strong> </a>通过归一化特征统计，即均值和方差，执行了一种形式的<strong class="mf jd"><em class="mw"/></strong>样式归一化。</p><blockquote class="nc nd ne"><p id="fb7a" class="md me mw mf b mg mx kd mi mj my kg ml nf mz mn mo ng na mq mr nh nb mt mu mv im bi translated"><strong class="mf jd">为什么不批量归一化？</strong></p><p id="3297" class="md me mw mf b mg mx kd mi mj my kg ml nf mz mn mo ng na mq mr nh nb mt mu mv im bi translated">由于<strong class="mf jd"> BN </strong>对一批样本而不是单个样本的特征统计进行归一化，因此可以直观地理解为对一批样本进行归一化，使其以单个样式为中心，尽管需要不同的目标样式。</p><p id="4129" class="md me mw mf b mg mx kd mi mj my kg ml nf mz mn mo ng na mq mr nh nb mt mu mv im bi translated">另一方面，中的<strong class="mf jd">可以将每个个体样本的风格归一化为目标风格:不同的仿射参数可以将特征统计归一化为不同的值，从而将输出图像归一化为不同的风格。</strong></p></blockquote><h2 id="25de" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">自适应实例规范化</h2><p id="dfbd" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated"><strong class="mf jd"> <em class="mw"> AdaIN </em> </strong>接收一个<strong class="mf jd"> <em class="mw">内容</em> </strong>输入<strong class="mf jd"> <em class="mw"> x </em> </strong>和一个<strong class="mf jd"> <em class="mw">样式</em> </strong>输入<strong class="mf jd"> <em class="mw"> y </em> </strong>，并简单地对齐<strong class="mf jd"> <em class="mw"> x </em> </strong>的信道均值和方差以匹配<strong class="mf jd"> <em class="mw"> y </em> </strong>。与 BN、IN 或 CIN <em class="mw"> ( </em> <a class="ae lh" rel="noopener" target="_blank" href="/fast-and-less-restricted-style-transfer-50366c43f672?source=your_stories_page---------------------------"> <strong class="mf jd"> <em class="mw">条件实例规范化</em> </strong> </a> <em class="mw"> ) </em>不同，AdaIN 没有可学习的仿射参数。相反，它<strong class="mf jd"> <em class="mw">自适应地</em> </strong>从样式输入中计算仿射参数。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ni"><img src="../Images/085a891698e14e1145d1661c55f42314.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/0*1y16f2TxhjvCXnfa.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd nj">图 1 </strong>。自适应<a class="ae lh" href="https://becominghuman.ai/all-about-normalization-6ea79e70894b" rel="noopener ugc nofollow" target="_blank">实例规范化</a></p></figure><p id="5173" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">直观地，让我们考虑一个检测某种风格的笔触的特征通道。具有这种笔画的风格图像将为该特征产生<strong class="mf jd"> <em class="mw">高平均激活</em> </strong>。此外，这一特定笔触的微妙风格信息将由<strong class="mf jd"> <em class="mw">方差</em> </strong>捕获。因为 AdaIN 仅缩放和移动激活，所以保留了内容图像的<strong class="mf jd"> <em class="mw">空间信息</em> </strong>。</p><h2 id="0237" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">风格转移网络</h2><p id="edd9" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">AdaIN <strong class="mf jd"> <em class="mw">风格传递网络</em> </strong> <strong class="mf jd"> <em class="mw"> T </em> </strong>(图 2)以一个<strong class="mf jd"> <em class="mw">内容图像 c </em> </strong>和一个任意的<strong class="mf jd"> <em class="mw">风格图像 s </em> </strong>作为输入，并合成一个<strong class="mf jd"> <em class="mw">输出图像</em> </strong> <strong class="mf jd"> <em class="mw"> T(c，s) </em> </strong>，该输出图像重新组合了各个输入图像的内容和风格。网络采用简单的编解码架构，其中<strong class="mf jd"> <em class="mw">编码器</em> </strong> <strong class="mf jd"> <em class="mw"> f </em> </strong>固定在一个预训练好的 VGG-19 的前几层。在特征空间中对内容和风格图像进行编码之后，两个特征图都被馈送到一个<strong class="mf jd"> <em class="mw"> AdaIN </em> </strong>层，该层将内容特征图的均值和方差与风格特征图的均值和方差对齐，产生<strong class="mf jd"> <em class="mw">目标特征图</em> </strong> <strong class="mf jd"> <em class="mw"> t </em> </strong>。一个随机初始化的<strong class="mf jd"> <em class="mw">解码器 g </em> </strong>被训练将<strong class="mf jd"> <em class="mw"> t </em> </strong>反转回图像空间，生成<strong class="mf jd"> <em class="mw">风格化图像 T(c，s) </em> </strong>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nk"><img src="../Images/2633bf77a14df56e3c69412a5c8444aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*va7XsIY2V-h3Iv0TeoIhHA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd nj">图 2 </strong>基于 AdaIN 的风格传递网络。图片取自“[R4]通过自适应实例规范化实时传输任意样式”。蓝色的自我注释。</p></figure><blockquote class="nc nd ne"><p id="cc37" class="md me mw mf b mg mx kd mi mj my kg ml nf mz mn mo ng na mq mr nh nb mt mu mv im bi translated"><strong class="mf jd">解码器中的归一化层数？</strong></p><p id="4291" class="md me mw mf b mg mx kd mi mj my kg ml nf mz mn mo ng na mq mr nh nb mt mu mv im bi translated">除了使用最近的上采样来减少棋盘效应，以及在 f 和 g 中使用反射填充来避免边界伪像之外，一个关键的架构选择是在解码器中使用标准化层<strong class="mf jd">而不是<em class="it"> </em> </strong>。因为 IN 将每个样本归一化为单一样式，而 BN 将一批样本归一化为以单一样式为中心，所以当我们希望解码器以非常不同的样式生成图像时，两者都是不理想的。</p></blockquote><h2 id="b669" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">损失函数</h2><p id="3c27" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">使用内容损失函数<strong class="mf jd"> <em class="mw"> Lc </em> </strong>和风格损失函数<strong class="mf jd"> <em class="mw"> Ls </em> </strong>的加权组合来训练风格传递网络<strong class="mf jd"> <em class="mw"> T </em> </strong>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/0b4b1f08ddb50d200e8b9ef8e18f738b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/0*cDQU-CL_fU1Mqrjf.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图三。内容和风格损失函数</p></figure><p id="a267" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">内容损失是目标特征<strong class="mf jd"><em class="mw"/></strong>和输出图像特征<strong class="mf jd"> <em class="mw"> f(g(t)) </em> </strong>之间的欧几里德距离。AdaIN 输出<strong class="mf jd"> <em class="mw"> t </em> </strong>用作内容目标，而不是内容图像的常用特征响应，因为它与反转 AdaIN 输出<strong class="mf jd"> <em class="mw"> t </em> </strong>的目标一致。</p><p id="adde" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">由于 AdaIN 层仅传输风格特征的平均值和标准偏差，所以风格损失仅匹配风格图像<strong class="mf jd"> <em class="mw"> s </em> </strong>和输出图像<strong class="mf jd"> <em class="mw"> g(t) </em> </strong>的特征激活的这些统计。在 VGG-19 的多层(i=1 到 L)上，风格损失是平均的。</p><h2 id="d06f" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated"><strong class="ak">结论</strong></h2><p id="f29a" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">本质上，上述 AdaIN 风格传输网络提供了在<strong class="mf jd"><em class="mw"/></strong>中组合<strong class="mf jd"> <em class="mw">任意</em> </strong>内容和风格图像的灵活性。</p><h2 id="1309" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">参考</h2><ol class=""><li id="21bd" class="nm nn it mf b mg mh mj mk lr no lv np lz nq mv nr ns nt nu bi translated">利昂·A·加蒂斯、亚历山大·S·埃克和马蒂亚斯·贝奇。<a class="ae lh" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">使用卷积神经网络的图像风格转换</a>。在<em class="mw"> CVPR </em>，2016。</li><li id="4e69" class="nm nn it mf b mg nv mj nw lr nx lv ny lz nz mv nr ns nt nu bi translated">贾斯廷·约翰逊，亚历山大·阿拉希和李菲菲。<a class="ae lh" href="https://arxiv.org/abs/1603.08155" rel="noopener ugc nofollow" target="_blank">实时风格转换和超分辨率的感知损失</a>。在<em class="mw">ECCV</em>2016 年。</li><li id="ca27" class="nm nn it mf b mg nv mj nw lr nx lv ny lz nz mv nr ns nt nu bi translated">文森特·杜穆林，黄邦贤·史伦斯，曼朱纳斯·库德鲁尔。<a class="ae lh" href="https://arxiv.org/abs/1610.07629" rel="noopener ugc nofollow" target="_blank">艺术风格的学术代表</a>。在<em class="mw"> ICLR，</em> 2017。</li><li id="6167" class="nm nn it mf b mg nv mj nw lr nx lv ny lz nz mv nr ns nt nu bi translated">塞尔日·贝隆吉·黄浚。<a class="ae lh" href="https://arxiv.org/abs/1703.06868" rel="noopener ugc nofollow" target="_blank">通过自适应实例标准化实时传输任意样式</a>。在<em class="mw"> ICCV，</em> 2017。</li><li id="3b06" class="nm nn it mf b mg nv mj nw lr nx lv ny lz nz mv nr ns nt nu bi translated">李，王乃彦，，侯晓迪。<a class="ae lh" href="https://arxiv.org/abs/1701.01036" rel="noopener ugc nofollow" target="_blank">揭秘神经风格转移</a>。在 IJCAI，2017。</li></ol></div></div>    
</body>
</html>