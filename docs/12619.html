<html>
<head>
<title>Intuitive Explanation of Differentiable Architecture Search (DARTS)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">差异化架构搜索(DARTS)的直观解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/intuitive-explanation-of-differentiable-architecture-search-darts-692bdadcc69c?source=collection_archive---------15-----------------------#2020-08-31">https://towardsdatascience.com/intuitive-explanation-of-differentiable-architecture-search-darts-692bdadcc69c?source=collection_archive---------15-----------------------#2020-08-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/4ccdab311d6fa19f6219ce99544a1c5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VDXGguPR6x5F9mGI"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">莫里茨·金德勒在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="37d8" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph">内部人工智能</h2><div class=""/><div class=""><h2 id="f285" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">了解飞镖是如何工作的！</h2></div><p id="9918" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这是一篇在 2018 年中期发表的论文，解决了搜索网络架构的可扩展性问题。简而言之，这些论文解决了<strong class="lj jt">神经架构搜索</strong>或<strong class="lj jt"> NAS </strong>的问题。</p><p id="4a7c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">顾名思义，这个领域背后的想法是探索我们如何能够自动搜索深度学习模型架构。目前，大多数数据科学问题都是通过手动设计模型架构来解决的，这种架构可以在任何给定的数据集上给出“<strong class="lj jt">最先进的</strong>”结果。这种方法的问题是，尽管这些体系结构在标准数据集上表现非常好，但它们在特定于组织的数据集上的表现却不如预期。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi md"><img src="../Images/1b389e7d299267e7acacf6a130683c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VnJv5JSJQq-ixhbS"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">左上:<a class="ae jg" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> Unet-Architecture </a> |右上:发表于【LeCun 等人，1998】的原始图像|左下:VGG16 Architecture |右下:ResNet architecture</p></figure><p id="48e0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这篇文章是写给那些即将进入研究领域或者正在阅读这篇精彩论文的人的。我在印度空间研究组织(ISRO)从事这个领域的实习项目。在这篇博客中，我将尝试以直观的方式解释这篇论文，因为我在实现语义分割时遇到了很多困难。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="8572" class="mp mq jj bd mr ms mt mu mv mw mx my mz ky na kz nb lb nc lc nd le ne lf nf ng bi translated">神经结构搜索(NAS)简介</h1><p id="e69e" class="pw-post-body-paragraph lh li jj lj b lk nh kt lm ln ni kw lp lq nj ls lt lu nk lw lx ly nl ma mb mc im bi translated">神经结构搜索的问题提出如下。</p><p id="fac1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="nm">给定一组搜索空间操作 O，我们需要找到使目标函数最大化或最小化的这些操作的组合。</em></p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/347604f7a93f4d89ddd5627baaf3313d.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*oU5vLzPu-J_JzaQ_ZigARw.gif"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">狗图片 cc-by: Von.grzanka |作者图片|显示不同操作如何影响输出的动画。</p></figure><p id="fbd8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">简单来说，我们需要找到模型的架构，使损失最小化。</p><h2 id="eede" class="no mq jj bd mr np nq dn mv nr ns dp mz lq nt nu nb lu nv nw nd ly nx ny nf jp bi translated">天真的解决方案</h2><p id="980b" class="pw-post-body-paragraph lh li jj lj b lk nh kt lm ln ni kw lp lq nj ls lt lu nk lw lx ly nl ma mb mc im bi translated">NAS 的一个简单解决方案是反复试验。我们将随机选择一个操作子集，并根据验证损失等参数评估其性能，并选择具有最佳性能的模型配置。</p><h2 id="71ac" class="no mq jj bd mr np nq dn mv nr ns dp mz lq nt nu nb lu nv nw nd ly nx ny nf jp bi translated">NAS 发展简史</h2><p id="9aae" class="pw-post-body-paragraph lh li jj lj b lk nh kt lm ln ni kw lp lq nj ls lt lu nk lw lx ly nl ma mb mc im bi translated">我们不会深入探讨，但这里有一些有影响力的论文为 NAS 研究铺平了道路。</p><ul class=""><li id="8570" class="nz oa jj lj b lk ll ln lo lq ob lu oc ly od mc oe of og oh bi translated"><a class="ae jg" href="https://arxiv.org/abs/1611.01578" rel="noopener ugc nofollow" target="_blank">具有强化学习的神经架构搜索</a></li><li id="fa64" class="nz oa jj lj b lk oi ln oj lq ok lu ol ly om mc oe of og oh bi translated"><a class="ae jg" href="https://arxiv.org/abs/1802.03268" rel="noopener ugc nofollow" target="_blank">通过参数共享进行有效的神经架构搜索</a></li><li id="853d" class="nz oa jj lj b lk oi ln oj lq ok lu ol ly om mc oe of og oh bi translated"><a class="ae jg" href="https://arxiv.org/pdf/1712.00559" rel="noopener ugc nofollow" target="_blank">渐进式神经架构搜索</a></li><li id="c33a" class="nz oa jj lj b lk oi ln oj lq ok lu ol ly om mc oe of og oh bi translated"><a class="ae jg" href="https://arxiv.org/abs/1806.09055" rel="noopener ugc nofollow" target="_blank">飞镖:差异化建筑搜索</a></li></ul><p id="cfe0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后最近有了<a class="ae jg" href="https://arxiv.org/abs/2005.07564" rel="noopener ugc nofollow" target="_blank"> HNAS:移动设备上的分层神经架构搜索</a>，它将 DARTS 的想法扩展到了下一个层次。</p><p id="9f41" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">研究的趋势是将计算时间从强化学习的<strong class="lj jt"> 2000 GPU </strong>天或进化的<strong class="lj jt"> 3150 GPU </strong>天减少到飞镖的<strong class="lj jt">2–3 GPU</strong>天。</p><h2 id="418b" class="no mq jj bd mr np nq dn mv nr ns dp mz lq nt nu nb lu nv nw nd ly nx ny nf jp bi translated">NAS 的方法</h2><p id="4d8b" class="pw-post-body-paragraph lh li jj lj b lk nh kt lm ln ni kw lp lq nj ls lt lu nk lw lx ly nl ma mb mc im bi translated">寻找高性能模型架构的想法并不简单，它包括两个步骤。</p><ol class=""><li id="a796" class="nz oa jj lj b lk ll ln lo lq ob lu oc ly od mc on of og oh bi translated">在小型数据集上搜索单元架构(例如，CIFAR10 或 CIFAR100)</li><li id="ee32" class="nz oa jj lj b lk oi ln oj lq ok lu ol ly om mc on of og oh bi translated">根据搜索到的单元架构制作模型，并在大数据集(如 ImageNet)上对其进行训练</li></ol><h2 id="7822" class="no mq jj bd mr np nq dn mv nr ns dp mz lq nt nu nb lu nv nw nd ly nx ny nf jp bi translated">搜索单元架构</h2><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oo"><img src="../Images/9bf35bae440150280a547c0df7019daf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UyEkGkTgEKviV6sn3cdMlA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片|简单单元格和混合运算的结构。上面显示的单元以堆叠方式具有 3 种状态。</p></figure><p id="31b1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">模型中的单元是什么？嗯，一个单元可以被认为是一个特殊的块，其中层是堆叠的，就像任何其他模型一样。这些单元应用许多卷积运算来获得可以传递给其他单元的特征图。一个模型是通过将这些细胞串联起来制成一个完整的模型。所有这些论文都遵循一个模式，其中搜索两种类型的细胞结构，即<strong class="lj jt">正常细胞</strong>和<strong class="lj jt">还原细胞</strong>。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/02922ee9481b7a1eb8525bf412f5a887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*iv8BGoQda50OD5d9tPaB6Q.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片|普通单元格</p></figure><p id="9b66" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">正常单元</strong>:正常单元可以认为是一个计算图像特征图的正常块。这个区块中的回旋和汇集的步幅为 1 。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/9733200d71c5cf033f82e53c04300d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*qDFmJyRh0l6GMQUoobAmYw.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片|缩小单元格</p></figure><p id="6790" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">缩小单元:</strong>缩小单元可以被认为是普通块，而<strong class="lj jt">缩小了</strong>特征图的尺寸。该块中的卷积和池化的步幅为 2。缩减单元的目的是对特征地图进行缩减采样。</p><p id="2ec7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">由于所有这些论文都解决了分类问题，最后使用了一个<strong class="lj jt">全局平均池层</strong>以及可选的全连接层。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/e4ee046b87144fc88ede1aee3c223ed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eD4rehxht-J2ubMVpYD0Fg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Image by Author |在搜索阶段后，堆叠正常和缩小单元以形成最终模型。</p></figure></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="77a2" class="mp mq jj bd mr ms mt mu mv mw mx my mz ky na kz nb lb nc lc nd le ne lf nf ng bi translated"><strong class="ak">关于飞镖的细节。怎么更好？</strong></h1><p id="0b90" class="pw-post-body-paragraph lh li jj lj b lk nh kt lm ln ni kw lp lq nj ls lt lu nk lw lx ly nl ma mb mc im bi translated">Darts 是神经架构搜索中非常有影响力的论文。早期的方法使用强化学习，需要大量的计算资源。花了<strong class="lj jt"> 2000 GPU </strong>天的强化学习或者<strong class="lj jt"> 3150 GPU </strong>天的进化。这个计算时间对大多数组织来说根本不可行。</p><blockquote class="or os ot"><p id="37f1" class="lh li nm lj b lk ll kt lm ln lo kw lp ou lr ls lt ov lv lw lx ow lz ma mb mc im bi translated"><em class="jj">在这篇文章中，我们从一个不同的角度处理这个问题，并提出了一种有效的体系结构搜索方法，称为</em> <strong class="lj jt"> <em class="jj"> DARTS </em> </strong> <em class="jj">(可区分的体系结构搜索)。我们将搜索空间放宽为连续的，而不是在一组离散的候选架构上进行搜索，从而可以通过梯度下降来优化该架构的验证集性能。</em></p><p id="2d7e" class="lh li nm lj b lk ll kt lm ln lo kw lp ou lr ls lt ov lv lw lx ow lz ma mb mc im bi translated"><em class="jj">与低效的黑盒搜索相反，基于梯度的优化的数据效率使 dart 能够使用数量级 fess 计算资源实现与最先进技术相媲美的性能。</em></p><p id="7edb" class="lh li nm lj b lk ll kt lm ln lo kw lp ou lr ls lt ov lv lw lx ow lz ma mb mc im bi translated"><em class="jj">介绍了一种基于双层优化的可区分网络结构搜索算法，该算法适用于卷积和递归结构。”—资料来源:飞镖论文</em></p></blockquote><p id="c8a6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">DARTS 将搜索时间减少到了<strong class="lj jt">2-3 个 GPU 日</strong>，这是惊人的。</p><h2 id="1dfe" class="no mq jj bd mr np nq dn mv nr ns dp mz lq nt nu nb lu nv nw nd ly nx ny nf jp bi translated">飞镖是如何做到这一点的？</h2><ol class=""><li id="a575" class="nz oa jj lj b lk nh ln ni lq ox lu oy ly oz mc on of og oh bi translated"><strong class="lj jt">在候选操作的离散集合上搜索计算量很大。</strong></li></ol><p id="691f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在候选操作的离散集合上搜索的问题是，在移动到下一个配置之前，模型必须在特定配置上训练。这显然很耗时。作者找到了一种<strong class="lj jt">放松</strong>候选操作的离散集合的方法。</p><blockquote class="or os ot"><p id="f82e" class="lh li nm lj b lk ll kt lm ln lo kw lp ou lr ls lt ov lv lw lx ow lz ma mb mc im bi translated">“为了使搜索空间连续，我们在所有可能的操作中将特定操作的分类选择放宽到最大限度:“——飞镖纸”</p></blockquote><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/d930bac46bae1ae09343f3e8f49cd509.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RDZV7HDpuuIebq7I"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">飞镖纸上的方程式</p></figure><p id="29cc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这意味着假设我们的候选操作中只有很少的操作</p><p id="8b50" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> O = {conv_3x3，最大 _ 池 _3x3，扩张 _conv_5x5}。</strong></p><p id="376e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">运算的输出称为混合运算，通过将这些运算的输出乘以它们的概率来定义。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/a4946c18f0895b324377af439957a868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*H79KCxw4G-D02qqy8vy3wQ.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片|显示如何计算混合运算的图片。</p></figure><blockquote class="or os ot"><p id="53d9" class="lh li nm lj b lk ll kt lm ln lo kw lp ou lr ls lt ov lv lw lx ow lz ma mb mc im bi translated"><em class="jj">“每个中间节点都是基于它的所有前置节点计算的。”—飞镖纸</em></p></blockquote><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pc"><img src="../Images/b616001abfd09da0b445fee8bc1bf9be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0ZXZ3uj1XMjtKQD3"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">飞镖纸上的方程式</p></figure><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/0d8dce2bdb78bf42528808bcdb0fcc14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*zxY6YwFk_4Z_O4t_9kdElQ.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">按作者分类的图像|典型 NAS 单元|注意每个节点如何将所有以前节点的输出作为其输入。</p></figure><p id="8aaf" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这就把我们带到了飞镖细胞的结构。这是模型的核心结构，我想让你在这里好好关注一下。</p><p id="b6dc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该单元包含一个或多个节点。这些节点也称为状态。</p><p id="677b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一个单元的 nput 是最后两个单元的输出，就像 ResNets 一样。在这个单元格中有节点。让我们假设我们制作一个具有 3 个状态/节点的单元。因此第一个节点将有两个输入，即来自最后两个单元的输出。</p><p id="a7b0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第二状态将具有来自第一状态的<em class="nm">输入，以及来自最后两个单元</em>的<em class="nm">输出，因此总共有<strong class="lj jt"> 3 个输入。</strong></em></p><p id="f276" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第三状态将具有来自第二状态、第一状态的输入和来自最后两个单元的输出。</p><p id="8065" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在搜索结束时，可以通过用最可能的操作替换每个混合操作 o(i，j ),即</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/219b896515e13d0243ceaa71c4b1aeeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/0*IXJa8BqMBKvx0Zld"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">飞镖纸上的方程式。</p></figure><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pf"><img src="../Images/ec36ecb08f427ba6f0bf6be9ae187ad1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xa9KUjDGX1FUZ0w3"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片来自<a class="ae jg" href="https://arxiv.org/abs/1806.09055" rel="noopener ugc nofollow" target="_blank">飞镖纸</a></p></figure><p id="6573" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这听起来很复杂，但是让我们分解一下。搜索阶段结束后，我们可以通过从单元中获取前 k 个(通常 k=2)连接来找到单元的架构。这样，离散搜索空间被转换为连续搜索空间，梯度下降算法将在该连续搜索空间上很好地工作。</p><p id="2ed2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">2.<strong class="lj jt">双层优化</strong></p><blockquote class="or os ot"><p id="bdb2" class="lh li nm lj b lk ll kt lm ln lo kw lp ou lr ls lt ov lv lw lx ow lz ma mb mc im bi translated">放松后，我们的目标是联合学习所有混合操作中的架构α和权重 w(例如，卷积滤波器的权重)—飞镖纸</p></blockquote><p id="cc94" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们已经讨论了如何获得搜索到的架构。但该模型如何寻找最优运行仍是一个未解的问题。训练部分还剩下。</p><p id="da54" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">优化问题可以被提出为<strong class="lj jt">寻找 alpha</strong>，使得<strong class="lj jt">验证损失被最小化</strong>，假设我们具有已经在训练集上优化的<strong class="lj jt">权重。</strong></p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pg"><img src="../Images/ad7f527043ff2872b7d270fc6bfea056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_YmDa8Egc_QPJjDN"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">请注意 alphas 和层权重的优化是如何在训练和验证集上完成的。这被称为<strong class="bd ph">双层优化。</strong></p></figure></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="95ee" class="mp mq jj bd mr ms mt mu mv mw mx my mz ky na kz nb lb nc lc nd le ne lf nf ng bi translated">近似建筑梯度——房间里的大象</h1><blockquote class="or os ot"><p id="c50d" class="lh li nm lj b lk ll kt lm ln lo kw lp ou lr ls lt ov lv lw lx ow lz ma mb mc im bi translated">“由于昂贵的内部优化，精确地评估架构梯度可能是禁止的。因此，我们提出一个简单的近似方案如下:“飞镖纸</p></blockquote><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/e58af24b39bc6893e8a72761774c42d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/0*yNzAIGIxPTHYVo1h"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片|显示 alphas 渐变的等式</p></figure><figure class="me mf mg mh gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/042fbaec68648f9f05c3825c9ced2a1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*z4ZVFno8qSw7r-P-bRzy7A.gif"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">第一张(猫)照片由<a class="ae jg" href="https://unsplash.com/@l_oan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Loan </a>在<a class="ae jg" href="https://unsplash.com/s/photos/cat?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄，第二张(狗)照片由<a class="ae jg" href="https://unsplash.com/@qrupt?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Victor Grabarczyk </a>在<a class="ae jg" href="https://unsplash.com/s/photos/dog?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄，第三张(狗)照片由<a class="ae jg" href="https://unsplash.com/@alvannee?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Alvan Nee </a>在<a class="ae jg" href="https://unsplash.com/s/photos/dog?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄|作者图片|请注意改变 alphas(橙色线)如何改变训练损失(上图)和重新训练直到必须在重量上完成收敛。<strong class="bd ph">优化 alphas 首先需要优化权重。</strong></p></figure><p id="5d5e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这个方程有一个计算问题。为了获得最佳卷积权重，我们需要通过更新卷积权重来最小化训练损失，从而训练网络。这意味着每次更新<strong class="lj jt"> alpha </strong>时，都需要最小化训练步骤。这将使网络培训不可行。</p><blockquote class="or os ot"><p id="802f" class="lh li nm lj b lk ll kt lm ln lo kw lp ou lr ls lt ov lv lw lx ow lz ma mb mc im bi translated">其思想是通过仅使用单个训练步骤调整 w 来逼近 w*(α)，而不通过训练直到收敛来完全解决内部优化</p></blockquote><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/51d98c6ad2bbe697ed43d1427dd55d09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qY1FN6dMWN8UcXY6"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">飞镖纸上的方程式</p></figure><p id="8b29" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在等式 5 中，为α的每个配置获得最佳权重 w*导致两个优化循环，因此作者建议以这样的方式来近似 w*，使得在收敛之前不需要优化 w*。想法是使用仅仅一个训练步骤而不是整个内部优化循环。</p><figure class="me mf mg mh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/1832bb54a6fdf48bf79fa8f3128dba75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cx2M38bV_QDQt7ht"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片来自飞镖纸</p></figure><p id="c8c9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae jg" href="https://mythrex.github.io/math_behind_darts/" rel="noopener ugc nofollow" target="_blank">点击此处了解这些等式背后的数学原理。</a></p><p id="630b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">看看等式 7，我们有一个二阶偏导数，它的计算量很大。为了解决这个问题，使用了有限差分法。</p><p id="45f6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="nm">看，方程 8 没有二阶偏导数！</em></p><p id="bc5c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">关于结果，你可以参考<a class="ae jg" href="https://arxiv.org/abs/1806.09055" rel="noopener ugc nofollow" target="_blank">论文这里</a>。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="2d75" class="mp mq jj bd mr ms mt mu mv mw mx my mz ky na kz nb lb nc lc nd le ne lf nf ng bi translated">替代优化策略</h1><p id="d15d" class="pw-post-body-paragraph lh li jj lj b lk nh kt lm ln ni kw lp lq nj ls lt lu nk lw lx ly nl ma mb mc im bi translated">作者还试图在训练+验证数据上联合优化 alphas 和权重，但结果恶化。作者解释说，这可能是由于阿尔法对数据的过度拟合。</p><h1 id="c961" class="mp mq jj bd mr ms pk mu mv mw pl my mz ky pm kz nb lb pn lc nd le po lf nf ng bi translated">结论</h1><p id="6a01" class="pw-post-body-paragraph lh li jj lj b lk nh kt lm ln ni kw lp lq nj ls lt lu nk lw lx ly nl ma mb mc im bi translated">DARTS 是一篇非常有影响力的论文，它将搜索高性能架构的时间从数千个 GPU 小时大幅减少到仅 2-3 个 GPU 天，并且仍然实现了最先进的结果。</p><h1 id="b850" class="mp mq jj bd mr ms pk mu mv mw pl my mz ky pm kz nb lb pn lc nd le po lf nf ng bi translated">资源</h1><ul class=""><li id="015b" class="nz oa jj lj b lk nh ln ni lq ox lu oy ly oz mc oe of og oh bi translated"><a class="ae jg" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> U-Net:用于生物医学图像分割的卷积网络</a></li><li id="f4df" class="nz oa jj lj b lk oi ln oj lq ok lu ol ly om mc oe of og oh bi translated"><a class="ae jg" href="https://arxiv.org/abs/1806.09055" rel="noopener ugc nofollow" target="_blank">飞镖:差异化架构搜索</a></li><li id="918c" class="nz oa jj lj b lk oi ln oj lq ok lu ol ly om mc oe of og oh bi translated"><a class="ae jg" href="https://arxiv.org/abs/1611.01578" rel="noopener ugc nofollow" target="_blank">具有强化学习的神经架构搜索</a></li></ul></div></div>    
</body>
</html>