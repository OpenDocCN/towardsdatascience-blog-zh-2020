<html>
<head>
<title>Realistic Deepfakes in 5 Minutes on Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Colab上5分钟内实现真实的深度伪造</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/realistic-deepfakes-colab-e13ef7b2bba7?source=collection_archive---------2-----------------------#2020-03-31">https://towardsdatascience.com/realistic-deepfakes-colab-e13ef7b2bba7?source=collection_archive---------2-----------------------#2020-03-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4843" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">以及为什么我们应该教育公众这种技术的存在</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c89a01a6f60db82e568c85adb92a02f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TjIpOXexay1_8hb78Jr_wA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3517206" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae ky" href="https://pixabay.com/users/KELLEPICS-4893063/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3517206" rel="noopener ugc nofollow" target="_blank">斯蒂芬·凯勒</a>拍摄</p></figure><p id="ba19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">女士们先生们，Deepfake视频非常容易制作，任何人都可以制作。你不需要博士学位，你也不需要花几个小时训练模型，你甚至不需要上一门关于生成对抗网络的课程。</p><p id="cc94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你所要做的就是，录制一段你自己的视频，并选择一张你想模仿的人的照片。机器学习将按照你在视频中想要的方式给图片中的人添加动画。</p><h1 id="e270" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">用单个图像生成Deepfakes</h1><p id="b693" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">图像动画旨在生成视频序列，以便根据视频的运动来动画化源图像中的人。</p><p id="1751" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这项技术属于计算机视觉领域，人工智能研究人员一直致力于制作更逼真的视频。它利用机器学习来操纵和生成视觉图像或视频，以他人代替一个人。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/871c8c0a4f13a91035cf10ac634e80b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*JXtdWdM2SQm7AX5NQb2a4w.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像动画的一阶运动模型【作者<a class="ae ky" href="https://aliaksandrsiarohin.github.io/first-order-model-website/" rel="noopener ugc nofollow" target="_blank">阿利亚克山大</a></p></figure><p id="f897" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">出于对科学的热爱，从研究的角度来看，阿利亚克山大的工作确实令人印象深刻。它已经发表在<a class="ae ky" href="http://papers.nips.cc/paper/8935-first-order-motion-model-for-image-animation" rel="noopener ugc nofollow" target="_blank"> NeurIPS </a>上，<a class="ae ky" href="https://github.com/AliaksandrSiarohin/first-order-model" rel="noopener ugc nofollow" target="_blank">源代码</a>可以在网上获得。</p><p id="f9bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他的工作在所有基准上都超过了最先进的水平，并且可以在各种图像上工作(人脸、身体、卡通和机器人)。这个模型是如此的灵活，以至于你可以用一张目标物体的图片来创建高质量的Deepfakes。</p><h2 id="0f1d" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">不需要事先信息</h2><p id="c762" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">它学习面部动作的能力令人难以置信。你可以看到它可以识别脸上的关键点，并且它很好地跟随这些关键点到视频中的动作。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/7e40aed731f9ab8c036d95b9b3636745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*7teS_UlvgfU-OpgcyY-9Sg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型学习识别关键点[通过<a class="ae ky" href="https://aliaksandrsiarohin.github.io/first-order-model-website/" rel="noopener ugc nofollow" target="_blank"> Aliaksandr </a></p></figure><p id="87a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在以前的工作中，我们需要额外的信息，如面部标志来绘制头部运动，姿势估计来绘制全身运动。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/1f273c37df8d4d1d5c70e4337819860a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NvbVJd5Ni_MAqJBNDDanpw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">过去的工作需要面部标志和姿势估计</p></figure><p id="2317" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这部作品中，它<strong class="lb iu">可以不使用任何注释或关于特定对象的先验信息</strong>来制作动画。一旦模型已经在面部上训练，模型可以将任何运动转移到任何面部上。</p><h2 id="b208" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">漂亮的头部运动</h2><p id="8dc4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">您可以录制自己的视频，并为照片中的人制作动画。是的，甚至还有一幅蒙娜丽莎的画像。</p><p id="963e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以抬头，转头。你会说话，嘴部动作看起来很棒。你可以转动你的眼睛，它将眼球运动很好地映射到目标视频上。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/be524d14fdaefb260812bffdf1714ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*O-VpGt2N9i5L_9nGpJjFAQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成头部运动[由<a class="ae ky" href="https://aliaksandrsiarohin.github.io/first-order-model-website/" rel="noopener ugc nofollow" target="_blank">阿利亚克山大</a> ]</p></figure><h2 id="23c1" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">全身运动也是</h2><p id="7e94" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">它也适用于全身运动的视频！理论上，这意味着你可以拍下比莉·珍的视频，让唐纳德·特朗普像迈克尔·杰克逊一样跳太空步。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/5deb5746abb8a04d08b841c947770e5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*I2kmboduDXhZQE09qlbA4g.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成全身动作[由<a class="ae ky" href="https://aliaksandrsiarohin.github.io/first-order-model-website/" rel="noopener ugc nofollow" target="_blank"> Aliaksandr </a> ]</p></figure><h2 id="4424" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">它产生背景</h2><p id="8c49" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">由于人覆盖了图像的一部分，算法需要找出人背后的背景。在这个作品中，<strong class="lb iu">自动生成被移动的人覆盖的背景</strong>——绝对精彩。</p><h1 id="30fc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">它是如何工作的？</h1><p id="b7f5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Aliaksandr的工作包括运动提取器，它学习提取关键点及其局部仿射变换。有一个生成器网络，它对目标运动中的遮挡进行建模，并将从源图像中提取的外观和从驾驶视频中导出的运动进行组合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/223cd8f5b6cbcd7b0ed9b942801dbbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hysHFHpOsgctp2ILI64z-A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一阶运动模型[来自<a class="ae ky" href="http://papers.nips.cc/paper/8935-first-order-motion-model-for-image-animation" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="8b24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要了解它是如何工作的，我建议你访问<a class="ae ky" href="https://aliaksandrsiarohin.github.io/first-order-model-website/" rel="noopener ugc nofollow" target="_blank"> GitHub页面</a>并查看<a class="ae ky" href="http://papers.nips.cc/paper/8935-first-order-motion-model-for-image-animation" rel="noopener ugc nofollow" target="_blank">研究论文</a>。你也可以看他的<a class="ae ky" href="https://www.youtube.com/watch?v=u-0cQ-grXBQ" rel="noopener ugc nofollow" target="_blank">视频</a>解释它是如何工作的。很酷的东西。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="4d23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">想自己做吗？看看这个<a class="ae ky" href="https://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>。</p><h1 id="137f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">深度造假的负面后果</h1><p id="7ce3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Deepfakes因其在假新闻、欺诈、诈骗和许多其他非法活动中的使用而获得了广泛关注。</p><p id="6fce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人们过去常常在subreddit、<a class="ae ky" href="https://www.reddit.com/r/deepfakes" rel="noopener ugc nofollow" target="_blank"> <em class="nj"> r/deepfakes </em> </a>分享他们创作的Deepfakes视频。许多这样的视频将名人的脸，如盖尔·加朵和泰勒·斯威夫特，交换到色情表演者的身体上。</p><p id="10b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">许多Deepfakes视频也被分享，描绘了政治家。它通过独裁政府传播虚假信息、仇恨和恐惧来影响政治。</p><p id="3988" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这项技术已经引起了行业和政府的关注，以控制和限制Deepfakes的使用。2018年2月，<a class="ae ky" href="https://www.vice.com/en_us/article/neqb98/reddit-shuts-down-deepfakes" rel="noopener ugc nofollow" target="_blank"> Reddit因违反政策暂停r/deepfakes </a>。2019年6月，它<a class="ae ky" href="https://www.congress.gov/bill/116th-congress/house-bill/3230" rel="noopener ugc nofollow" target="_blank">引起了政府</a>的关注，以通过限制Deepfakes视频更改技术来打击虚假信息的传播。</p><h1 id="e3c9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">和我一起告知它的存在</h1><p id="4a06" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">知道世界上有人会滥用这项技术。你可能会问，我为什么要写这个？为什么我要传播这些知识？</p><p id="4b74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于在当今这个时代，任何人都可以很容易地制作假视频，这样的生成模型不再是科幻小说了。我的目标是教育公众，让人们知道这种技术的存在。<strong class="lb iu">通过了解它的存在，人们可以有所觉察，更加注重辨别真假。</strong></p><p id="06c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假新闻是当今互联网结构的一部分，现在假新闻很容易被发现；这使得虚假信息达到了一个全新的水平。它通过传播虚假信息影响了政治。它导致人们被骗子利用，利用它在网上骗钱。</p><p id="e6d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于冠状病毒，世界现在已经一片混乱；我不确定在这种时候人们会如何滥用这项技术。Deepfakes，作为一种虚假信息，是危险的。我们需要对人们进行技术教育，人们需要辨别真相，而不仅仅是相信我们所看到的。</p><div class="nk nl gp gr nm nn"><a href="https://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">从Google联合实验室看它的实际应用</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">一阶运动模型</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">colab.research.google.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob ks nn"/></div></div></a></div></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><div class="kj kk kl km gt nn"><a rel="noopener follow" target="_blank" href="/data-scientist-the-dirtiest-job-of-the-21st-century-7f0c8215e845"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">数据科学家:21世纪最肮脏的工作</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">40%的吸尘器，40%的看门人，20%的算命师。</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="oj l ny nz oa nw ob ks nn"/></div></div></a></div><div class="nk nl gp gr nm nn"><a rel="noopener follow" target="_blank" href="/the-fascinating-relationship-between-ai-and-neuroscience-89189218bb05"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">人工智能和神经科学之间的迷人关系</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">他们如何相互激励、共同进步、相互受益</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="ok l ny nz oa nw ob ks nn"/></div></div></a></div></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><div class="kj kk kl km gt ab cb"><figure class="ol kn om on oo op oq paragraph-image"><a href="https://www.linkedin.com/in/jingles/"><img src="../Images/e6191b77eb1b195de751fecf706289ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*fPTPd_WxZ4Ey7iOVElxwJQ.png"/></a></figure><figure class="ol kn om on oo op oq paragraph-image"><a href="https://towardsdatascience.com/@jinglesnote"><img src="../Images/7c898af9285ccd6872db2ff2f21ce5d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*airGp_q6AXwaoL1LYXwYeQ.png"/></a></figure><figure class="ol kn om on oo op oq paragraph-image"><a href="https://jingles.substack.com/subscribe"><img src="../Images/d370b96eace4b03cb3c36039b70735d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ESxUX6V6tAqj_2ZFSr-pUw.png"/></a></figure></div></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="beec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像动画的一阶运动模型。<em class="nj">神经信息处理系统的进展</em>。2019.</p><p id="ca58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nj">插图属于</em> <a class="ae ky" href="https://aliaksandrsiarohin.github.io/first-order-model-website/" rel="noopener ugc nofollow" target="_blank"> <em class="nj">阿利亚克山大</em> </a> <em class="nj">，经允许使用。</em></p></div></div>    
</body>
</html>