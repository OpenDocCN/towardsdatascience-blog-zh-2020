<html>
<head>
<title>Data cleaning series with Python: Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python数据清理系列:第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-cleaning-series-with-python-part-1-24bb603c82c8?source=collection_archive---------33-----------------------#2020-03-19">https://towardsdatascience.com/data-cleaning-series-with-python-part-1-24bb603c82c8?source=collection_archive---------33-----------------------#2020-03-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8dc0" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">数据预处理</h2><div class=""/><div class=""><h2 id="8a0b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">回到基础——处理缺失值</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ff71a4b51135871d7e676e888931a605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jCGJ5CDdMgO-r9Im"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">“计算机上的代码”由<a class="ae lh" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上发表</p></figure><blockquote class="li lj lk"><p id="e295" class="ll lm ln lo b lp lq kd lr ls lt kg lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">垃圾进，垃圾出——嘿</p></blockquote><p id="05b2" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">几个月前，我和我的一个朋友聊天，他最近申请了班加罗尔一家IT公司的高级数据科学职位。作为面试过程的一部分，为了解决一个业务问题，他得到了一个数据集。他开始解释他的方法，很快就被面试官打断了。当我问他原因时，他说，“他们关心的只是我选择的用于数据的算法。”</p><p id="3908" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">数据科学领域已经存在了相当一段时间。尽管如此，仍然有很多人低估了干净数据的价值。机器学习算法的好坏取决于输入的数据。<br/>因此，在将你的数据输入你的算法之前，对其进行清理和辩论是至关重要的。</p><p id="7cd6" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">本系列将有助于向该领域的新手灌输有关数据预处理的最佳实践，并为社区中的老成员提供全面的复习。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="da65" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">缺少值的情况</h1><p id="f90d" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated">研究人员在进行研究时通常会采取非常谨慎的措施。许多此类研究的主要结果是收集数据。不幸的是，许多研究最终都丢失了信息。必须处理缺失值，因为它们会对我们的机器学习算法的预测能力产生负面影响。然而，<a class="ae lh" href="https://en.wikipedia.org/wiki/Gradient_boosting" rel="noopener ugc nofollow" target="_blank">某些算法</a>会绕过丢失的值。</p><p id="c094" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">数据中缺少值的原因很多。调查数据集的参与者可能选择不共享信息，数据录入人员可能会犯错误，收集数据的自动机器可能会出错等。</p><blockquote class="np"><p id="b823" class="nq nr it bd ns nt nu nv nw nx ny mh dk translated">我们必须接受人为错误是不可避免的——并围绕这一事实进行设计——唐纳德·伯威克</p></blockquote><p id="c549" class="pw-post-body-paragraph ll lm it lo b lp nz kd lr ls oa kg lu mi ob lx ly mj oc mb mc mk od mf mg mh im bi translated">维基百科定义了三种缺失数据:</p><ul class=""><li id="5bb6" class="oe of it lo b lp lq ls lt mi og mj oh mk oi mh oj ok ol om bi translated"><em class="ln">完全随机失踪(MCAR) </em></li><li id="682b" class="oe of it lo b lp on ls oo mi op mj oq mk or mh oj ok ol om bi translated"><em class="ln">随机失踪(3月)</em></li><li id="1517" class="oe of it lo b lp on ls oo mi op mj oq mk or mh oj ok ol om bi translated"><em class="ln">非随机缺失(MNAR) </em></li></ul><p id="b94c" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">我不会详细说明其中的复杂性，但是你可以在这里阅读<a class="ae lh" href="https://en.wikipedia.org/wiki/Missing_data" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="b5bb" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">通常，我们会发现数据中缺失值的多种表现形式。有时它们由单个特殊字符表示，如<code class="fe os ot ou ov b">.</code>(句号)、<code class="fe os ot ou ov b">*</code>(星号)。其他时候可以用<code class="fe os ot ou ov b">N/A</code>、<code class="fe os ot ou ov b">NaN</code>或者<code class="fe os ot ou ov b">-999</code>来代表。</p><p id="094a" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">让我们看一个这样的数据集。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="96ba" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">资料组</h1><p id="8997" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated">我们将使用的数据集是来自UCI机器学习知识库的糖尿病数据集。可以从<a class="ae lh" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database" rel="noopener ugc nofollow" target="_blank">这里</a>下载。让我们快速地看一看。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/7491ce54c116ab430c3f74376e21d332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zzFkiHOZAmnfxMVpQrOwcQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">糖尿病数据集的前10个值。</p></figure><pre class="ks kt ku kv gt ox ov oy oz aw pa bi"><span id="d242" class="pb mt it ov b gy pc pd l pe pf"># Check number of rows and columns after removing outcome variable.</span><span id="857a" class="pb mt it ov b gy pg pd l pe pf">diabetes.shape</span><span id="fe7a" class="pb mt it ov b gy pg pd l pe pf">Output:<br/>(768, 8)</span></pre><p id="385c" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">该数据具有768个观察值/行和8个变量/列。这里面似乎也没有缺失的价值。让我们通过在每一列中随机插入缺失值来解决这个问题。我们将以0.1或10%的因子在每一列中引入缺失值。</p><div class="ks kt ku kv gt ab cb"><figure class="ph kw pi pj pk pl pm paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/d44da36bfe698acc7f25eb66d13029fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*-_ZmjV3ErEVFacdFAUhpgA.png"/></div></figure><figure class="ph kw pn pj pk pl pm paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/b9f4e73f0c2c04b2ccec366e31e31658.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*4iafuf7ba1Ov4pQhr8Kdyw.png"/></div></figure><figure class="ph kw po pj pk pl pm paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/619e4cd2095a5e4efb6057771cf3b1d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*V41Dak-G06NT36SmuGN6rw.png"/></div></figure></div><p id="aec8" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">注意数据中的某些观察值是如何被称为<code class="fe os ot ou ov b">NaN</code>的。这是Python中缺失值的默认表示法。接下来，让我们讨论一些处理这些值的技术。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="3d4b" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">处理缺失值</h1><h2 id="635b" class="pb mt it bd mu pp pq dn my pr ps dp nc mi pt pu ne mj pv pw ng mk px py ni iz bi translated">移除观察值</h2><p id="090a" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated">也称为<a class="ae lh" href="https://en.wikipedia.org/wiki/Listwise_deletion" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jd">列表式删除</strong> </a>，这种技术简单地涉及删除整个观察值，如果它有一个或多个丢失的值。如果在非常大的数据集中有少量缺失值，可以选择这种方法。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pz"><img src="../Images/1eee927014e69d6dec1fcb684a773118.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nFAQwJoMXgXe-BcHHbekdA.png"/></div></div></figure><p id="1e00" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">我们观察到，在<strong class="lo jd">列表式删除</strong>之后，超过一半的数据集被擦除。看起来我们已经失去了很多有价值的信息让我们的准模特去学习。<br/>此外，它还会影响<a class="ae lh" href="https://en.wikipedia.org/wiki/Power_(statistics)" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jd">统计检验</strong> </a>的功效，因为它们需要大样本量。显然，在这种情况下，这种方法似乎不太合适。</p><h2 id="afd6" class="pb mt it bd mu pp pq dn my pr ps dp nc mi pt pu ne mj pv pw ng mk px py ni iz bi translated">用0插补</h2><p id="e8d4" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated">在这种方法中，数据中所有缺失的值(用<code class="fe os ot ou ov b">NaN</code>表示)都被替换为数字<code class="fe os ot ou ov b">0</code>。</p><div class="ks kt ku kv gt ab cb"><figure class="ph kw qa pj pk pl pm paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/b8fd8c46175b7b58a415af2eddc7b636.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*4Wzv1NvNTwQkDNpzTHnhCg.png"/></div></figure><figure class="ph kw qb pj pk pl pm paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/05ae3f2c52aa1d4e21c68e7419a559cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*SLYnkNpaNpyLxU9izekrcQ.png"/></div></figure></div><p id="2464" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated"><em class="ln">Python中的pandas库有一个名为</em> <code class="fe os ot ou ov b"><em class="ln">pandas.DataFrame.fillna</em></code> <em class="ln">的方法可以帮助我们完成这个任务。</em></p><p id="09ad" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">起初，这种方法似乎是一个有吸引力的选择，因为我们能够保留我们所有的观察结果。此外，这是一种快速的估算方法。然而，仔细观察各个列，我们可以看到，将0加到一堆行上会在数据集中引入大量的<strong class="lo jd">偏差</strong>。实际上，那些丢失的条目可能具有远离数字0的值。</p><h2 id="1e13" class="pb mt it bd mu pp pq dn my pr ps dp nc mi pt pu ne mj pv pw ng mk px py ni iz bi translated">中心值插补</h2><p id="a206" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated"><strong class="lo jd">中心值插补</strong>是一种将缺失值替换为各自的中心趋势度量值的方法，又称<strong class="lo jd">均值</strong>、<strong class="lo jd">中位数</strong>、<strong class="lo jd">众数</strong>。对于数值变量，最好使用平均值或中值，而对于分类变量，则使用众数。<br/>这背后的原因是，对于分类变量而言，均值和中值没有意义，因为分类变量具有定性属性而非定量属性。因此，为了说明集中趋势，我们使用Mode，因为它是最频繁出现的值。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="qc qd l"/></div></figure><p id="647f" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">Python的<code class="fe os ot ou ov b">scikit-learn</code>库有一个名为<code class="fe os ot ou ov b">SimpleImputer</code>的模块，它执行中心值插补。<br/><code class="fe os ot ou ov b">strategy</code>参数用于设置我们需要的插补类型。</p><p id="3f94" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">这种形式的插补有其优点，特别是对于低方差数据。如果我们有非常不稳定的特征，用这种方法估算可能不是一个好主意。然而，与以前的技术相比，它通常是一种快速且更好的估算方法。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qe"><img src="../Images/eff0016365bef6e331c89d0d86cc180d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KXrzsV-zL_4yjTtT"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@emilymorter?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">艾米丽·莫特</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="4676" class="ms mt it bd mu mv qf mx my mz qg nb nc ki qh kj ne kl qi km ng ko qj kp ni nj bi translated">作为输入者的学习算法</h1><p id="04eb" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated">到目前为止，我们只研究了处理缺失值的简单方法。当我们的数据变得复杂时，我们需要更好的估算方法。<br/>在这一部分，我们将看看几个我们喜爱的学习算法，以及它们如何帮助我们估算缺失值。</p><h2 id="1127" class="pb mt it bd mu pp pq dn my pr ps dp nc mi pt pu ne mj pv pw ng mk px py ni iz bi translated">回归插补</h2><p id="b6ea" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated">回归插补是相当不言自明的。这种形式的插补使用多元线性回归原理来插补数值。如果你需要线性回归的复习，那么看看我的线性回归系列。</p><div class="qk ql gp gr qm qn"><a rel="noopener follow" target="_blank" href="/linear-regression-moneyball-part-1-b93b3b9f5b53"><div class="qo ab fo"><div class="qp ab qq cl cj qr"><h2 class="bd jd gy z fp qs fr fs qt fu fw jc bi translated">线性回归:钱球—第1部分</h2><div class="qu l"><h3 class="bd b gy z fp qs fr fs qt fu fw dk translated">大众体育故事的统计案例研究</h3></div><div class="qv l"><p class="bd b dl z fp qs fr fs qt fu fw dk translated">towardsdatascience.com</p></div></div><div class="qw l"><div class="qx l qy qz ra qw rb lb qn"/></div></div></a></div><p id="b743" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">为了概括线性回归，我们挑选一个因变量或输出<strong class="lo jd"> <em class="ln"> y </em> </strong>，并使用多个自变量<strong class="lo jd"> <em class="ln"> X </em> </strong> <em class="ln"> </em>来拟合一个能够预测<strong class="lo jd"><em class="ln"/></strong><em class="ln">y的函数。</em>使用<strong class="lo jd"> <em class="ln"> X </em> </strong>中的变量作为输入量或<strong class="lo jd">回归量</strong>来预测<strong class="lo jd"><em class="ln"/></strong><em class="ln">。</em></p><p id="69e7" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">在<strong class="lo jd">回归插补</strong>中，带有缺失值的一列被选作我们的<em class="ln"> y </em>，其余的列被用作输入变量<strong class="lo jd">XT37】来拟合<strong class="lo jd">y .T41】该函数用于预测<strong class="lo jd"> <em class="ln"> y. <br/> </em> </strong> <code class="fe os ot ou ov b">scikit-learn</code>列中的缺失值。</strong></strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="qc qd l"/></div></figure><p id="1ab0" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">虽然回归插补似乎可行，但它也有局限性。由于我们使用拟合值作为插补的输出，我们的插补值将非常精确。<br/>这是因为与正常的线性回归模型不同，回归插补缺少一个<a class="ae lh" href="https://en.wikipedia.org/wiki/Errors_and_residuals" rel="noopener ugc nofollow" target="_blank"> <strong class="lo jd">误差</strong> </a> <strong class="lo jd"> </strong>项。完全消除了这些估算值的不确定性。</p><h2 id="c043" class="pb mt it bd mu pp pq dn my pr ps dp nc mi pt pu ne mj pv pw ng mk px py ni iz bi translated">k-最近邻插补</h2><p id="820d" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated">也被称为<strong class="lo jd"> Knn插补</strong>，这种插补形式使用<a class="ae lh" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" rel="noopener ugc nofollow" target="_blank">K-最近邻算法</a>来插补数值。</p><p id="ee5a" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">这个算法很好解释。它查看k个条目，并比较它们与有缺失值的条目之间的“距离”。这里的k值由用户定义。k的合适值的经验法则是取观察次数(N)的平方根。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi rc"><img src="../Images/4e1f8db70a5668bfa566dd6c195d9f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dopz3_t-O38xhLlF"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">乔恩·泰森在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="8b39" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">k-NN算法使用距离度量来选择与我们感兴趣的行最近的邻居。<br/>用于数字属性的最常见的距离<a class="ae lh" href="https://en.wikipedia.org/wiki/Metric_(mathematics)" rel="noopener ugc nofollow" target="_blank">度量</a>通常是曼哈顿距离(<a class="ae lh" href="https://en.wikipedia.org/wiki/Taxicab_geometry" rel="noopener ugc nofollow" target="_blank"> L1范数</a>)或者欧几里德距离(<a class="ae lh" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank"> L2范数</a>)。在分类变量中，最流行的距离度量是<a class="ae lh" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦相似度</a>、<a class="ae lh" href="https://en.wikipedia.org/wiki/Jaccard_index" rel="noopener ugc nofollow" target="_blank">雅克卡距离</a>和<a class="ae lh" href="https://en.wikipedia.org/wiki/Hamming_distance" rel="noopener ugc nofollow" target="_blank">汉明距离</a>。计算距离后，缺失值由“相邻”行的多数投票(分类)或平均值/加权平均值(数值)确定。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="qc qd l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">在上面的例子中，k=3</p></figure><p id="e737" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">k-NN插补是一种非常有效的插补方法。对于小型、中型数据集，它通常能获得非常好的结果。在大数据集上，算法的运行时间大大增加。此外，对于特别具有大量特征(列)的数据集，会出现<a class="ae lh" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank">维数灾难</a>问题。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="b491" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated"><strong class="ak">结论</strong></h1><p id="676a" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated">在这篇博文中，我们来看看一些插补方法，以处理缺失数据。作为数据科学领域的从业者，我们必须理解每种方法的优势和局限性。这将帮助我们在构建数据预处理管道时做出明智的决策。<br/>请注意，以上插补技术列表并非详尽无遗。还有许多其他的高级方法来处理缺失值，这超出了本文的范围。一种这样的插补类型是<a class="ae lh" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/" rel="noopener ugc nofollow" target="_blank">小鼠插补</a>。</p><p id="6721" class="pw-post-body-paragraph ll lm it lo b lp lq kd lr ls lt kg lu mi lw lx ly mj ma mb mc mk me mf mg mh im bi translated">如果你喜欢这个帖子，请在媒体上关注我，并在LinkedIn 上给我发一个邀请。查看我关于数据科学的其他帖子。下次见。✋</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h2 id="9603" class="pb mt it bd mu pp pq dn my pr ps dp nc mi pt pu ne mj pv pw ng mk px py ni iz bi translated"><strong class="ak">参考文献:</strong></h2><p id="eb2f" class="pw-post-body-paragraph ll lm it lo b lp nk kd lr ls nl kg lu mi nm lx ly mj nn mb mc mk no mf mg mh im bi translated">[1]<a class="ae lh" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/classes . html # module-sk learn . impute</a><br/>【2】<a class="ae lh" href="https://en.wikipedia.org/wiki/Imputation_(statistics)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/attubation _(统计)</a></p></div></div>    
</body>
</html>