# 如何限制人为的愚蠢

> 原文：<https://towardsdatascience.com/how-to-limit-artificial-stupidity-a4635a7967bc?source=collection_archive---------38----------------------->

![](img/8014e48a288b0b8af91f5dd90552f594.png)

Carlos Alfonso 在 [Unsplash](https://unsplash.com/s/photos/austin?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

## 人类学习图书馆概述

# 什么是人为的愚蠢？

人工愚蠢是一个新术语，被用作人工智能的反义词。然而，它有两个相反的含义:

1.  机器学习算法在从数据中学习时会犯愚蠢的错误。
2.  人工智能被变得愚蠢，会犯错，看起来更像人类。

写第二种意义可能很吸引人，也很值得鼓掌，但我想向你介绍人工愚蠢的第一种意义，以及文森特·d·瓦姆的迷人的人类学习图书馆。

## 人为愚蠢的一个有趣例子:

这几年有很多人工傻第一个意思的例子。其中最有趣的一个是由 Ciaran Maguire 发现并在 Twitter 上介绍的。一家保险公司的算法根据人们出生的日期计算不同的费用。正如你在下面的推文中看到的，当出生日期改变了一天，价格变化很大。算法是怎么得出这个计算结果的？测试算法准确性的程序员呢？他们怎么会错过这样一个离奇的结果？

我的假设是，数据集中有严重的异常值，这极大地影响了模型的权重。尽管如此，这个错误可能还有其他原因。

# 人工智能中的人情味

当我在制作机器学习模型时，我总是想知道有效的数据清洗、预处理、探索性数据分析和特征工程如何将最简单的模型转化为强大的预测器。选择合适的模型是至关重要的，但为模型提供正确的数据是必不可少的。因此，即使建立了最好的卷积神经网络，“垃圾进，垃圾出”的原则仍然有效。

如果人类的触摸可以使一个相当简单的模型高度精确，为什么人类不在训练过程中做出贡献？为什么人类智能不在建模中助推人工智能？人可以在培训前和培训中帮助计算机吗？如果我们可以在建模的时候画出特征、分类器、离群值呢？

# 人类学习图书馆

2020 年 10 月 8 日，Vincent D. Warmerdam 编写并介绍了人类学习库，这使得创建基于规则的系统更加容易。该库有两个数据集:泰坦尼克号(是的，再来一次！)和企鹅。

## 通过绘画学习和组合:

主要思想是更熟悉数据(扩展 EDA)，通过手工绘制为模型做贡献。

可以将多个绘图及其权重放在一起，以制作一个人工和计算机聚合(组合)的模型。当人类为模型的学习做出贡献时，她/他可以对模型有更多的了解，并防止机器犯愚蠢的错误。

## 制作基线模型:

至少你可以用这个系统做一个基线模型，来检验你的“比最深更深”的神经网络是否比这个最简单的模型表现得更好。

## 创建更多可解释的模型:

两个两个地使用特征图的权重可以增加模型的可解释性。您可以显示工程图中特征之间的关系。

## 无预测区域:

这是我最喜欢的想法！

我们不必对每个点都做预测。如果聚类不够清晰，我们应该能够说:“在这个区域没有预测。”这样就可以约束人为的愚蠢。

# 结论:

我发现这个库很有趣，想在这篇文章里分享一下。你可以像我一样使用 GitHub 回购。

## 最后一句:

虽然计算机在学习重复性任务方面似乎更聪明，但人类的创造力和解决问题的能力使它们更胜一筹。

# 进一步阅读

1.  我的媒介[文章](https://medium.com/@seymatas/making-the-black-box-of-ai-transparent-with-explainable-ai-xai-f425c5dc8145)关于可解释的人工智能(XAI)
2.  一篇关于三种人为愚蠢的[文章](https://www.thinkautomation.com/automation-ethics/do-we-need-to-worry-about-artificial-stupidity/)。这篇文章中有一种巧妙的人为愚蠢，值得一读。
3.  一篇关于人类和计算机的智能和愚蠢的惊人的福布斯文章。
4.  亚马逊、微软和苹果最著名的[人工智能失败](https://www.lexalytics.com/lexablog/stories-ai-failure-avoid-ai-fails-2020)。
5.  [维基百科链接](https://en.wikipedia.org/wiki/Rule-based_machine_learning)基于规则的系统与基于算法的系统

**感谢阅读。**

**如果你想取得联系，你可以给我发电子邮件到 eymatas@gmail.com 的** [**s**](http://www.clausraasted.dk/) **，或者你可以在 https://www.linkedin.com/in/seyma-tas/的**[](https://www.linkedin.com/in/seyma-tas/)**找到我**