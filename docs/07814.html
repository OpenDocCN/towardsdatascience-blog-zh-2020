<html>
<head>
<title>Deep Learning with Spark in Deep Java Library in 10 minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">10 分钟用深度 Java 库中的 Spark 进行深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-with-spark-in-deep-java-library-in-10-minutes-923a73704094?source=collection_archive---------37-----------------------#2020-06-10">https://towardsdatascience.com/deep-learning-with-spark-in-deep-java-library-in-10-minutes-923a73704094?source=collection_archive---------37-----------------------#2020-06-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/e73337a056f0e0649fad53bc9ebd2294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*P6etO9yNeoNu4g7Wg7mmEw.jpeg"/></div></figure><h1 id="1982" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">介绍</h1><p id="71dd" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Apache Spark 是一种广泛用于数据处理的技术，被机器学习用户大量使用。Spark 可用于产品分类、需求预测和个性化推荐。虽然 Spark 支持多种编程语言，但首选的 Spark SDK 是为 Scala 实现的，大多数深度学习框架都没有很好的支持。大多数机器学习框架喜欢 Python 及其 SDK，给 Spark 开发人员留下了次优选择:将他们的代码移植到 Python 或实现定制的 Scala 包装器。这些选项会影响开发人员的速度，并通过脆弱的代码威胁生产环境。<br/> <br/>在这篇博客中，我们展示了用户如何使用<a class="ae lq" href="https://djl.ai/" rel="noopener ugc nofollow" target="_blank"> Deep Java 库</a> (DJL)直接从 Scala 执行深度学习工作负载。DJL 是一个框架无关的库，开发它是为了在用 Java 开发的 Spark jobs 中直接提供深度学习。在下面的教程中，我们将使用 MXNet 完成一个图像分类场景，尽管 PyTorch 和 TensorFlow 也受支持。完整代码见<a class="ae lq" href="https://github.com/aws-samples/djl-demo/tree/master/spark/image-classification" rel="noopener ugc nofollow" target="_blank"> DJL 星火图像分类示例</a>。</p><h1 id="5634" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">示例:使用 DJL 和火花进行图像分类</h1><p id="512f" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在本教程中，我们使用<a class="ae lq" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> resnet50 </a>，一个预先训练好的模型来运行推理。对于本教程，我们将使用一个具有三个工作节点的集群进行分类。工作流程如下图所示:</p><figure class="ls lt lu lv gt jr gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/303316e32b04f9f0dc53c7ca841a5373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*nRF0BWc5njEDrxXCEp7m_Q.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk translated"><em class="ma">具有 3 个工作节点的 Spark 上的示例图像分类工作流</em></p></figure><p id="156a" class="pw-post-body-paragraph ks kt iq ku b kv mb kx ky kz mc lb lc ld md lf lg lh me lj lk ll mf ln lo lp ij bi translated">我们的示例将在流程中创建几个执行者，并为他们每个人分配任务。每个执行器包含一个或多个在不同线程中执行任务的核心。这为每个工作节点提供了平衡的大数据处理工作负载。</p><h1 id="d6ad" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">第一步。创建 Spark 项目</h1><p id="09bd" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们使用流行的开源工具<a class="ae lq" href="https://www.scala-sbt.org" rel="noopener ugc nofollow" target="_blank"> sbt </a>在 Scala 中构建这个 Spark 项目。您可以在这里找到更多关于如何开始使用 sbt <a class="ae lq" href="https://www.scala-sbt.org/1.x/docs/sbt-by-example.html" rel="noopener ugc nofollow" target="_blank">的资源。我们使用以下代码块在 sbt 中定义我们的项目:</a></p><pre class="ls lt lu lv gt mg mh mi mj aw mk bi"><span id="dd95" class="ml jv iq mh b gy mm mn l mo mp">name := "sparkExample"</span><span id="9801" class="ml jv iq mh b gy mq mn l mo mp">version := "0.1"</span><span id="8ad7" class="ml jv iq mh b gy mq mn l mo mp">scalaVersion := "2.11.12"<br/>scalacOptions += "-target:jvm-1.8"</span><span id="d386" class="ml jv iq mh b gy mq mn l mo mp">resolvers += Resolver.mavenLocal</span><span id="9872" class="ml jv iq mh b gy mq mn l mo mp">libraryDependencies += "org.apache.spark" %% "spark-core" % "2.3.0"</span><span id="24e8" class="ml jv iq mh b gy mq mn l mo mp">libraryDependencies += "ai.djl" % "api" % "0.5.0"<br/>libraryDependencies += "ai.djl" % "repository" % "0.5.0"<br/>// Using MXNet Engine<br/>libraryDependencies += "ai.djl.mxnet" % "mxnet-model-zoo" % "0.5.0"<br/>libraryDependencies += "ai.djl.mxnet" % "mxnet-native-auto" % "1.6.0"</span></pre><p id="5ea4" class="pw-post-body-paragraph ks kt iq ku b kv mb kx ky kz mc lb lc ld md lf lg lh me lj lk ll mf ln lo lp ij bi translated">本教程使用 MXNet 作为其底层引擎。切换到另一个框架很简单，如下例所示:</p><pre class="ls lt lu lv gt mg mh mi mj aw mk bi"><span id="e643" class="ml jv iq mh b gy mm mn l mo mp">// Using PyTorch Engine<br/>libraryDependencies += "ai.djl.pytorch" % "pytorch-model-zoo" % "0.5.0"<br/>libraryDependencies += "ai.djl.pytorch" % "pytorch-native-auto" % "1.5.0"</span></pre><h1 id="1546" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步骤 2:配置 Spark</h1><p id="d1e1" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在本教程中，我们在本地机器上运行这个例子。Spark 应用程序将使用以下配置:</p><pre class="ls lt lu lv gt mg mh mi mj aw mk bi"><span id="030f" class="ml jv iq mh b gy mm mn l mo mp">// Spark configuration<br/>val conf = new SparkConf()<br/>  .setAppName("Simple Image Classification")<br/>  .setMaster("local[*]")<br/>  .setExecutorEnv("MXNET_ENGINE_TYPE", "NaiveEngine")<br/>val sc = new SparkContext(conf)</span></pre><p id="f33c" class="pw-post-body-paragraph ks kt iq ku b kv mb kx ky kz mc lb lc ld md lf lg lh me lj lk ll mf ln lo lp ij bi translated">MXNet 中的多线程推理需要<code class="fe mr ms mt mh b">NaiveEngine</code>参数。如果使用 PyTorch 或 TensorFlow，可以删除以下行:</p><pre class="ls lt lu lv gt mg mh mi mj aw mk bi"><span id="27dc" class="ml jv iq mh b gy mm mn l mo mp">.setExecutorEnv("MXNET_ENGINE_TYPE", "NaiveEngine")</span></pre><h1 id="c2b7" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步骤 3:识别输入数据</h1><p id="995c" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在本教程中，输入数据表示为包含要分类的图像的文件夹。Spark 将加载这些二进制文件，并将它们划分到不同的分区。每个分区由一个执行器执行。以下语句将把文件夹中的所有图像均匀地分布在每个分区上。</p><pre class="ls lt lu lv gt mg mh mi mj aw mk bi"><span id="7df7" class="ml jv iq mh b gy mm mn l mo mp">val partitions = sc.binaryFiles("images/*")</span></pre><h1 id="74fb" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步骤 4:定义 Spark 工作</h1><p id="b245" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">接下来，我们使用上一步中创建的分区为这个作业创建执行图。在 Spark 中，每个执行器以多线程的方式执行任务。因此，在执行推理之前，我们需要将每个模型加载到执行器中。我们使用以下代码进行设置:</p><pre class="ls lt lu lv gt mg mh mi mj aw mk bi"><span id="91f8" class="ml jv iq mh b gy mm mn l mo mp">// Start assign work for each worker node<br/>val result = partitions.mapPartitions( partition =&gt; {<br/>   // before classification<br/>    val criteria = Criteria.builder<br/>        .optApplication(Application.CV.IMAGE_CLASSIFICATION)<br/>        .setTypes(classOf[BufferedImage], classOf[Classifications])<br/>        .optFilter("dataset", "imagenet")<br/>        .optFilter("layers", "50")<br/>        .optProgress(new ProgressBar)<br/>        .build<br/>   val model = ModelZoo.loadModel(criteria)<br/>    val predictor = model.newPredictor()<br/>   // classification<br/>   partition.map(streamData =&gt; {<br/>        val img = ImageIO.read(streamData._2.open())<br/>        predictor.predict(img).toString<br/>    })<br/>})</span></pre><p id="4b49" class="pw-post-body-paragraph ks kt iq ku b kv mb kx ky kz mc lb lc ld md lf lg lh me lj lk ll mf ln lo lp ij bi translated">需要为每个分区指定<a class="ae lq" href="https://javadoc.djl.ai/mxnet-model-zoo/0.4.0/index.html" rel="noopener ugc nofollow" target="_blank">模型动物园</a>的标准，以定位相应的模型并创建预测器。在分类过程中，我们从<a class="ae lq" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> RDD </a>加载图像，并为它们创建推论。<br/> <br/>这个模型用<a class="ae lq" href="http://www.image-net.org" rel="noopener ugc nofollow" target="_blank"> ImageNet 数据集</a>训练，存储在 DJL 模型动物园。</p><h1 id="8048" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">步骤 5:定义输出位置</h1><p id="d1b8" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在我们完成映射过程之后，主节点将收集、聚合结果并将其保存在文件系统中。</p><pre class="ls lt lu lv gt mg mh mi mj aw mk bi"><span id="4349" class="ml jv iq mh b gy mm mn l mo mp">result.collect().foreach(<em class="mu">print</em>)<br/>result.saveAsTextFile("output")</span></pre><p id="b7b5" class="pw-post-body-paragraph ks kt iq ku b kv mb kx ky kz mc lb lc ld md lf lg lh me lj lk ll mf ln lo lp ij bi translated">运行这段代码会产生前面列出的输出类。输出文件将保存到不同分区的<code class="fe mr ms mt mh b">output</code>文件夹中。本教程完整代码请见<a class="ae lq" href="https://github.com/aws-samples/djl-demo/blob/master/spark/image-classification/src/main/scala/com/examples/Example.scala" rel="noopener ugc nofollow" target="_blank"> Scala 示例</a>。<br/> <br/>控制台的预期输出:</p><pre class="ls lt lu lv gt mg mh mi mj aw mk bi"><span id="082b" class="ml jv iq mh b gy mm mn l mo mp">[<br/>    class: "n02085936 Maltese dog, Maltese terrier, Maltese", probability: 0.81445<br/>    class: "n02096437 Dandie Dinmont, Dandie Dinmont terrier", probability: 0.08678<br/>    class: "n02098286 West Highland white terrier", probability: 0.03561<br/>    class: "n02113624 toy poodle", probability: 0.01261<br/>    class: "n02113712 miniature poodle", probability: 0.01200<br/>][<br/>    class: "n02123045 tabby, tabby cat", probability: 0.52391<br/>    class: "n02123394 Persian cat", probability: 0.24143<br/>    class: "n02123159 tiger cat", probability: 0.05892<br/>    class: "n02124075 Egyptian cat", probability: 0.04563<br/>    class: "n03942813 ping-pong ball", probability: 0.01164<br/>][<br/>    class: "n03770679 minivan", probability: 0.95839<br/>    class: "n02814533 beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon", probability: 0.01674<br/>    class: "n03769881 minibus", probability: 0.00610<br/>    class: "n03594945 jeep, landrover", probability: 0.00448<br/>    class: "n03977966 police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria", probability: 0.00278<br/>]</span></pre><h1 id="1d25" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">在您的生产系统中</h1><p id="5167" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在这种方法中，我们使用 RDD 来执行我们的图像作业，用于演示目的。随着数据帧使用和节省高速缓存的趋势，生产用户应该考虑为这些图像创建一个模式，并以数据帧格式存储它们。从 Spark 3.0 开始，Spark 提供了一个<a class="ae lq" href="https://docs.databricks.com/data/data-sources/binary-file.html" rel="noopener ugc nofollow" target="_blank">二进制文件阅读器选项</a>，使得图像转换为数据帧更加方便。</p><h1 id="bb91" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">个案研究</h1><p id="c97c" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">亚马逊零售系统(ARS)使用 DJL 通过 Spark 路由的大量数据流进行了数百万次预测。这些预测使用成千上万的客户属性来确定客户在多个类别中采取行动的倾向，然后向客户呈现相关的广告和横幅。<br/> <br/> ARS 使用数十万个特征，拥有数亿个客户——超过十万亿个数据点。他们需要一个能够有效扩展的解决方案。为了解决这个关键问题，他们最初为自己的工作创建了一个 Scala 包装器，但是这个包装器有内存问题，执行起来很慢。在采用 DJL 之后，他们的解决方案与 Spark 完美配合，总的推理时间从几天降到了几个小时。<br/> <br/>敬请关注我们的下一篇博文，我们将深入探讨并介绍更多 ARS 面临的挑战，以及他们如何通过与 DJL 建立管道来解决这个问题。</p><h1 id="8aed" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">了解更多关于 DJL 的信息</h1><figure class="ls lt lu lv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mv"><img src="../Images/257d90ad06b732e72173b88687ec9c12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q0qlHol7gFCxRRXmkIe1OQ.png"/></div></div></figure><p id="da91" class="pw-post-body-paragraph ks kt iq ku b kv mb kx ky kz mc lb lc ld md lf lg lh me lj lk ll mf ln lo lp ij bi translated">完成本教程后，你可能想知道 DJL 是什么。深度 Java 库(DJL)是一个开源库，用于在 Java 中构建和部署深度学习。该项目于 2019 年 12 月推出，由亚马逊各地的工程团队使用。这一努力受到了其他 DL 框架的启发，但是是从底层开始开发的，以更好地适应 Java 开发实践。DJL 是框架不可知的，支持 Apache MXNet、PyTorch、TensorFlow 2.x(实验)和 fastText(实验)。<br/> <br/>要了解更多，请查看我们的<a class="ae lq" href="https://djl.ai/" rel="noopener ugc nofollow" target="_blank">网站</a>、<a class="ae lq" href="https://github.com/awslabs/djl" rel="noopener ugc nofollow" target="_blank"> Github 资源库</a>和<a class="ae lq" href="https://join.slack.com/t/deepjavalibrary/shared_invite/zt-ar91gjkz-qbXhr1l~LFGEIEeGBibT7w" rel="noopener ugc nofollow" target="_blank"> Slack channel。</a></p></div></div>    
</body>
</html>