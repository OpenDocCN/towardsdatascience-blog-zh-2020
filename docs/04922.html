<html>
<head>
<title>Address class imbalance easily with Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Pytorch 轻松解决班级失衡问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/address-class-imbalance-easily-with-pytorch-e2d4fa208627?source=collection_archive---------21-----------------------#2020-04-29">https://towardsdatascience.com/address-class-imbalance-easily-with-pytorch-e2d4fa208627?source=collection_archive---------21-----------------------#2020-04-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/1d9646dd08c33244c5da73c3b5ffad18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VW_9WCdWsjY5TG9d"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">计算机视觉中的数据增强。图片的制作者名单为<a class="ae jd" href="https://mc.ai/data-augmentation-by-fastai-v1/" rel="noopener ugc nofollow" target="_blank"> fastai </a>。</p></figure><div class=""/><div class=""><h2 id="91f0" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">当你的模型过度拟合你的数据时，你能做什么？</h2></div><blockquote class="kv kw kx"><p id="8257" class="ky kz la lb b lc ld kh le lf lg kk lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated"><strong class="lb jh">重要提示:</strong>如果你能看到这个故事的结尾，请考虑<strong class="lb jh">在灵媒上跟我学更多的</strong>。我将非常感谢你的支持。</p></blockquote><p id="444c" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi ly translated">这个问题经常发生在我们处理不平衡数据集的时候。如果您的数据集代表几个类，其中一个比其他的少得多，那么就很难了解代表这样一个小类的真正的底层分布。</p><p id="2684" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">正如这篇必读的<a class="ae jd" href="https://arxiv.org/abs/1710.05381" rel="noopener ugc nofollow" target="_blank">论文</a>、<strong class="lb jh">中所解释的，解决几乎在所有分析场景中都占主导地位的类不平衡的方法是过采样。</strong>过采样应应用于完全消除不平衡的水平，而最佳欠采样率取决于不平衡的程度。与一些经典的机器学习模型相反，过采样不会导致 CNN 的过拟合。</p><p id="5562" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">在实践中，当训练机器学习模型时，人们将遵循一些关键步骤:</p><ol class=""><li id="ff4f" class="mh mi jg lb b lc ld lf lg lv mj lw mk lx ml lu mm mn mo mp bi translated">将数据分成一个训练/测试集(80%，20%)。</li><li id="be6b" class="mh mi jg lb b lc mq lf mr lv ms lw mt lx mu lu mm mn mo mp bi translated">通过对训练数据进行拟合来训练机器学习模型。</li><li id="fd67" class="mh mi jg lb b lc mq lf mr lv ms lw mt lx mu lu mm mn mo mp bi translated">在测试集上评估性能。</li></ol><p id="3f42" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">当使用深度学习架构时，通常会将训练数据分成几批，我们在训练期间将这些数据馈送给我们的神经网络。为了构建这样的批次，我们通常按照观察值集的均匀分布从训练集中随机抽样。</p><p id="cc4b" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">现在需要一些简单的统计数据。假设我们有一个包含两个类<em class="la"> class_1 </em>和<em class="la"> class_2 </em>的数据集。<strong class="lb jh">从<em class="la"> class_1 </em>中随机抽取一个点的概率是多少？</strong></p><p id="9e1f" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">遵循点集合上的均匀分布，这样的概率很容易表达:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/d364efcbcb72c91a6df42d9da2c44bd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtowsitgMSSjLhxxhuCZUA.png"/></div></div></figure><p id="e04b" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">实际上，在二元问题中，当我们从一个类中得到的观察值比另一个类中得到的多得多时，就会出现类不平衡:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ae8869a25f1ac4b8b2ed8766c6d400e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*NC3UsSAWxmFPe_9N8TQP5g.png"/></div></figure><p id="a0fd" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">因此，我们有:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/2f60ec482c70db4af304fe91f2af5e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*O6KwMvYSNsDuL9fG6uuQwA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">二元问题中的类别不平衡由从给定类别中得出观察值的不平衡可能性来描述。</p></figure><p id="7c47" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">换句话说，从<em class="la"> class_1 </em>比从<em class="la"> class_2 </em>更有可能得出一个点。因为模型看到的<em class="la"> class_2 </em>要少得多，所以它不能从这样的类中学习有用的特征也就不足为奇了…</p><p id="39c5" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">现在，在深入编码之前，我们需要理解人工扩充数据时的一个关键思想。我们想要的是确保通过人为增加辅修班，我们有:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/88718d55d3448294c83d7c77ed033075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*LrDvb3gERxmC4pGvuvGFWQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">在扩充了我们的数据之后，我们的目标是使从每个类中抽取样本的可能性尽可能接近。</p></figure><p id="ae96" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">是时候了！让我们用 Pytorch 的<a class="ae jd" href="https://pytorch.org/docs/stable/_modules/torch/utils/data/sampler.html#WeightedRandomSampler" rel="noopener ugc nofollow" target="_blank"><em class="la">weighted random sampler</em></a>来编码解决这个问题。</p><p id="a2be" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated"><strong class="lb jh">数据集</strong>:我们用来自<em class="la"> class_major </em>的标记为 0 的 900 个观察值和来自<em class="la"> class_minor </em>的标记为 1 的 100 个观察值构建数据集。(90%, 10%)</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/61844d7292d7fffcd0cfc22915ab8f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*ltyrdFul4zI_iA63lEVuXA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">我们数据集的样本。标签 1 对应于法语句子，标签 0 对应于英语句子。</p></figure><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/bcbe29f86f45940b5b11dc02891b1820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEy4_vgBNKONEi2o7u8NWw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">具有文本数据和两类值 0 和 1 的不平衡数据集的类分布。我们有 900 个 0 类句子和 100 个 1 类句子。</p></figure><p id="969e" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">假设我们构建了 10 批，每批 100 个句子，我们最终将得到平均 10 个第 1 类句子和 90 个第 0 类句子。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nf"><img src="../Images/48a32bf929f9050af5cc86bc31068d9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B2UPZA4Xz_5vzuzeiruXYw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">每班分配 10 批，每批 100 句。红色代表小类，蓝色代表大类。我们可以清楚地看到每一批训练数据中的不平衡。0 类的估计比例现在是 90.5，1 类的估计比例是 9.5。</p></figure><p id="e6a5" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated"><strong class="lb jh">如何轻松重新平衡以上内容？</strong>让我们用 Pytorch 库写几行代码。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ng"><img src="../Images/e2166263e31acde07a87c3e0dfb6207a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PORnRkpDj67KXn4PMFFRNw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">24 行 python 魔术构建平衡批次。</p></figure><p id="2b1d" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">从上面我们可以看到<em class="la"> WeightedRandomSampler </em>使用数组<em class="la"> example_weights </em>对应于赋予每个类的权重。目标是给次要类分配更高的权重。这将通过从均匀分布移动到具有受控参数的多项式分布来影响从每个类中提取点的可能性。</p><p id="307d" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">现在我们可以详细看看<em class="la"> arr_batch 中包含的批次，</em>每个批次实际应该有 100 个句子。出于形象化的目的，我们只关注这里的标签。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nh"><img src="../Images/fa493c762dfb81da18f33b3d9bd94db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vc9Ff9hynbpM7-NUsSpASg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">0 类的估计比例现在是 51.4，1 类的估计比例是 48.6。</p></figure><p id="5652" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">正如我们从上图中看到的，我们现在有了平衡的数据批次。因此，在训练期间，我们的模型不会看到一个类别比另一个类别多很多，因此降低了过度拟合的风险。</p><p id="e516" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">总之，我们看到:</p><ol class=""><li id="fa5e" class="mh mi jg lb b lc ld lf lg lv mj lw mk lx ml lu mm mn mo mp bi translated">过采样是解决类不平衡的关键策略，因此降低了过度拟合的风险。</li><li id="942c" class="mh mi jg lb b lc mq lf mr lv ms lw mt lx mu lu mm mn mo mp bi translated">当数据集中存在类别不平衡时，从数据集中随机取样是个坏主意。</li><li id="101b" class="mh mi jg lb b lc mq lf mr lv ms lw mt lx mu lu mm mn mo mp bi translated">使用<a class="ae jd" href="https://pytorch.org/docs/stable/_modules/torch/utils/data/sampler.html#WeightedRandomSampler" rel="noopener ugc nofollow" target="_blank"> <em class="la">加权随机抽样加权随机抽样器</em> </a>通过对次要类进行过抽样来重新平衡我们的训练数据类。</li></ol><blockquote class="kv kw kx"><p id="b3f3" class="ky kz la lb b lc ld kh le lf lg kk lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated"><strong class="lb jh">重要的</strong>:如果你到目前为止，<strong class="lb jh">一定要在 Medium </strong>上关注我，以示支持。🤗</p></blockquote><p id="faf9" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">在下一篇文章中，我们将深入研究<em class="la"> WeightedRandomSampler </em>到<strong class="lb jh">的实现，更好地理解加权方案</strong>。我们还将在一个简单的机器学习场景中应用过采样，并分析其对整体性能的影响。</p><p id="8d35" class="pw-post-body-paragraph ky kz jg lb b lc ld kh le lf lg kk lh lv lj lk ll lw ln lo lp lx lr ls lt lu ij bi translated">感谢阅读，如有任何反馈，请在下方留下评论！🤗</p></div></div>    
</body>
</html>