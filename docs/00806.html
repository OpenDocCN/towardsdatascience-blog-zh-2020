<html>
<head>
<title>How To Save and Load Model In PyTorch With A Complete Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在 PyTorch 中保存和加载模型，并附有完整的示例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-save-and-load-a-model-in-pytorch-with-a-complete-example-c2920e617dee?source=collection_archive---------0-----------------------#2020-01-23">https://towardsdatascience.com/how-to-save-and-load-a-model-in-pytorch-with-a-complete-example-c2920e617dee?source=collection_archive---------0-----------------------#2020-01-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fcff" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何在 PyTorch 中保存和加载模型的实例。我们将看看如何继续训练和加载模型进行推理</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/562eb72665eb5a2d370080ee7dee4dbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dvE0xtk588vKK3q7"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">詹姆斯·哈里逊在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="0222" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> T </span>这篇文章的目的是告诉你如何保存一个模型，并在上一个时期后加载它继续训练，并做出预测。如果你正在阅读这篇文章，我假设你熟悉深度学习和 PyTorch 的基础。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="7edf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你有没有经历过这样的情况，你花了几个小时或几天训练你的模型，然后它在中途停止？还是对自己的模特表现不满意，想重新训练模特？我们可能需要一种灵活的方式来保存和加载我们的模型，这有多种原因。</p><p id="3636" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Kaggle、Google Colab 等大多数免费云服务都有空闲超时，会断开你的笔记本，加上笔记本一旦达到限制时间就会断开连接或中断。除非你用 GPU 训练少量的纪元，否则这个过程需要时间。能够保存模型会给你带来巨大的优势并扭转局面。为了灵活起见，我将保存最新的检查点和最佳的检查点。</p><p id="5b67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">时尚 _ MNIST _ 数据将被用作我们的数据集，我们将从导入数据编写一个完整的流程来进行预测。在这个练习中，我将使用一个<a class="ae ky" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>笔记本。</p><h1 id="620f" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">步骤 1:设置</h1><ul class=""><li id="c81b" class="nd ne it lb b lc nf lf ng li nh lm ni lq nj lu nk nl nm nn bi translated">在 Kaggle 中，你正在操作的笔记本默认叫做<strong class="lb iu"> __notebook__。ipyn </strong></li><li id="1136" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">创建两个目录来存储检查点和最佳模型:</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h1 id="6524" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">步骤 2:导入库和创建助手函数</h1><h2 id="3bf4" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">导入库</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="b809" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">保存功能</h2><p id="5df1" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated"><strong class="lb iu">创建 save_ckp </strong>是为了保存检查点，最新的和最好的检查点。这就产生了灵活性:要么您对最新检查点的状态感兴趣，要么对最佳检查点感兴趣。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="775c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，我们希望保存一个检查点，使我们能够使用这些信息来继续我们的模型训练。以下是所需的信息:</p><ul class=""><li id="4ab9" class="nd ne it lb b lc ld lf lg li ok lm ol lq om lu nk nl nm nn bi translated"><strong class="lb iu">时期</strong>:所有训练向量被使用一次来更新权重的次数的度量。</li><li id="c854" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated"><strong class="lb iu"> valid_loss_min </strong>:最小验证损失，这是需要的，以便当我们继续训练时，我们可以从这个而不是 np 开始。Inf 值。</li><li id="97a1" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated"><strong class="lb iu"> state_dict </strong>:模型架构信息。它包括每一层的参数矩阵。</li><li id="93e8" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated"><strong class="lb iu">优化器</strong>:您需要保存优化器参数，尤其是当您使用 Adam 作为优化器时。Adam 是一种自适应学习率方法，这意味着，它计算不同参数的个人学习率，如果我们想从我们离开的地方继续我们的训练，我们将需要这些参数[2]。</li></ul><h2 id="9b21" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">加载功能</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="0200" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> load_chkp </strong>是为加载模型创建的。这需要:</p><ul class=""><li id="2422" class="nd ne it lb b lc ld lf lg li ok lm ol lq om lu nk nl nm nn bi translated">保存的检查点的位置</li><li id="a9de" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">要将状态加载到的模型实例</li><li id="4ebb" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">优化器</li></ul><h1 id="fdf3" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">步骤 3:导入数据集时尚 _ MNIST _ 数据并创建数据加载器</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h1 id="6861" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">步骤 4:定义和创建模型</h1><p id="d8ce" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">我使用的是来自[1]的简单网络</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="d630" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">输出:</h2><pre class="kj kk kl km gt on oo op oq aw or bi"><span id="301f" class="nv mm it oo b gy os ot l ou ov">FashionClassifier(<br/>  (fc1): Linear(in_features=784, out_features=512, bias=True)<br/>  (fc2): Linear(in_features=512, out_features=256, bias=True)<br/>  (fc3): Linear(in_features=256, out_features=128, bias=True)<br/>  (fc4): Linear(in_features=128, out_features=64, bias=True)<br/>  (fc5): Linear(in_features=64, out_features=10, bias=True)<br/>  (dropout): Dropout(p=0.2)<br/>)</span></pre><h1 id="eb7a" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">步骤 5:训练网络并保存模型</h1><p id="73c9" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">训练功能使我们能够设置时期数、学习率和其他参数。</p><h2 id="70b7" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">定义损失函数和优化器</h2><p id="b83e" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">下面，我们使用 Adam 优化器和交叉熵损失，因为我们把字符类分数作为输出。我们计算损耗并进行反向传播。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="be7a" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">定义培训方法</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="1270" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">训练模型</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="d837" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">输出:</h2><pre class="kj kk kl km gt on oo op oq aw or bi"><span id="a0a3" class="nv mm it oo b gy os ot l ou ov">Epoch: 1  Training Loss: 0.000010  Validation Loss: 0.000044<br/>Validation loss decreased (inf --&gt; 0.000044).  Saving model ...</span><span id="4ee9" class="nv mm it oo b gy ow ot l ou ov">Epoch: 2  Training Loss: 0.000007  Validation Loss: 0.000040<br/>Validation loss decreased (0.000044 --&gt; 0.000040).  Saving model ...</span><span id="312d" class="nv mm it oo b gy ow ot l ou ov">Epoch: 3  Training Loss: 0.000007  Validation Loss: 0.000040<br/>Validation loss decreased (0.000040 --&gt; 0.000040).  Saving model ...</span></pre><p id="ad6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们关注一下上面使用的几个参数:</p><ul class=""><li id="8201" class="nd ne it lb b lc ld lf lg li ok lm ol lq om lu nk nl nm nn bi translated">start_epoch:训练的值 epoch 的开始</li><li id="dcf4" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">n_epochs:训练的值 epoch 的结束</li><li id="affb" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">有效 _ 损失 _ 最小 _ 输入= np。中程核力量</li><li id="f955" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">checkpoint_path:保存训练的最新检查点状态的完整路径</li><li id="2e26" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">最佳模型路径:训练的最新检查点的最佳状态的完整路径</li></ul><h2 id="93f0" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">验证模型是否已保存</h2><ul class=""><li id="09c0" class="nd ne it lb b lc nf lf ng li nh lm ni lq nj lu nk nl nm nn bi translated">列出 best_model 目录中的所有文件</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="4fcb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><pre class="kj kk kl km gt on oo op oq aw or bi"><span id="c8d8" class="nv mm it oo b gy os ot l ou ov">best_model.pt</span></pre><ul class=""><li id="592c" class="nd ne it lb b lc ld lf lg li ok lm ol lq om lu nk nl nm nn bi translated">列出检查点目录中的所有文件</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="07c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><pre class="kj kk kl km gt on oo op oq aw or bi"><span id="4ba7" class="nv mm it oo b gy os ot l ou ov">current_checkpoint.pt</span></pre><h1 id="340b" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">步骤 6:加载模型</h1><h2 id="3792" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">重建模型</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="6c4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><pre class="kj kk kl km gt on oo op oq aw or bi"><span id="a052" class="nv mm it oo b gy os ot l ou ov">FashionClassifier(<br/>  (fc1): Linear(in_features=784, out_features=512, bias=True)<br/>  (fc2): Linear(in_features=512, out_features=256, bias=True)<br/>  (fc3): Linear(in_features=256, out_features=128, bias=True)<br/>  (fc4): Linear(in_features=128, out_features=64, bias=True)<br/>  (fc5): Linear(in_features=64, out_features=10, bias=True)<br/>  (dropout): Dropout(p=0.2)<br/>)</span></pre><h2 id="c42b" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">定义优化器和检查点文件路径</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="f3d9" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">使用 load_ckp 函数加载模型</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="0199" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我打印出了我们从<strong class="lb iu"> load_ckp </strong>得到的值，只是为了确保一切都是正确的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="da8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><pre class="kj kk kl km gt on oo op oq aw or bi"><span id="652d" class="nv mm it oo b gy os ot l ou ov">model =  FashionClassifier(<br/>  (fc1): Linear(in_features=784, out_features=512, bias=True)<br/>  (fc2): Linear(in_features=512, out_features=256, bias=True)<br/>  (fc3): Linear(in_features=256, out_features=128, bias=True)<br/>  (fc4): Linear(in_features=128, out_features=64, bias=True)<br/>  (fc5): Linear(in_features=64, out_features=10, bias=True)<br/>  (dropout): Dropout(p=0.2)<br/>)<br/>optimizer =  Adam (<br/>Parameter Group 0<br/>    amsgrad: False<br/>    betas: (0.9, 0.999)<br/>    eps: 1e-08<br/>    lr: 0.001<br/>    weight_decay: 0<br/>)<br/>start_epoch =  4<br/>valid_loss_min =  3.952759288949892e-05<br/>valid_loss_min = 0.000040</span></pre><p id="c252" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">加载完所有需要的信息后，我们可以继续训练，start_epoch = 4。以前，我们从 1 到 3 训练模型</p><h1 id="730e" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">第七步:继续训练和/或推断</h1><h2 id="e831" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">继续训练</h2><p id="6661" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">我们可以继续使用 train 函数训练我们的模型，并提供我们从上面的<strong class="lb iu"> load_ckp </strong>函数中获得的检查点的值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="a3fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><pre class="kj kk kl km gt on oo op oq aw or bi"><span id="77e8" class="nv mm it oo b gy os ot l ou ov">Epoch: 4 	Training Loss: 0.000006 	Validation Loss: 0.000040<br/>Epoch: 5 	Training Loss: 0.000006 	Validation Loss: 0.000037<br/>Validation loss decreased (0.000040 --&gt; 0.000037).  Saving model ...<br/>Epoch: 6 	Training Loss: 0.000006 	Validation Loss: 0.000036<br/>Validation loss decreased (0.000037 --&gt; 0.000036).  Saving model ...</span></pre><ul class=""><li id="4169" class="nd ne it lb b lc ld lf lg li ok lm ol lq om lu nk nl nm nn bi translated">注意:纪元现在从 4 点到 6 点开始。(开始时间= 4)</li><li id="6b4c" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">验证丢失从最后一个训练检查点开始继续。</li><li id="ed0e" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">在时期 3，最小验证损失是 0.000040</li><li id="9af1" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">这里，最小验证损失从 0.000040 开始，而不是 INF</li></ul><h2 id="fa26" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">推理</h2><p id="ad04" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">请记住，在运行推理之前，您必须调用 model.eval()将丢弃和批处理、规范化图层设置为评估模式。不这样做将产生不一致的推理结果[3]。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="ed79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><pre class="kj kk kl km gt on oo op oq aw or bi"><span id="480f" class="nv mm it oo b gy os ot l ou ov">Accuracy of the network on 10000 test images: 86.58%</span></pre></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="a62b" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">在 Kaggle 笔记本中哪里可以找到输出/保存的文件</h2><p id="0ed4" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">在您的 Kaggle 笔记本中，您可以向下滚动到页面底部。在之前的操作中保存了一些文件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/759e048813729177aa59f447047c999e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fC2VWXEKcRt98YQfLHyqEA.png"/></div></div></figure><p id="0884" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我在 Kaggle 的笔记本:</p><p id="5780" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.kaggle.com/vortanasay/saving-loading-and-cont-training-model-in-pytorch?scriptVersionId=27394631" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/vortanasay/saving-loading-and-cont-training-model-in-py torch</a></p><h2 id="2772" class="nv mm it bd mn nw nx dn mr ny nz dp mv li oa ob mx lm oc od mz lq oe of nb og bi translated">参考:</h2><ul class=""><li id="ac3d" class="nd ne it lb b lc nf lf ng li nh lm ni lq nj lu nk nl nm nn bi translated">[1] S. David，在 PyTorch 中保存和加载模型(2019)，<a class="ae ky" href="https://www.kaggle.com/davidashraf/saving-and-loading-models-in-pytorch" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/davidashraf/Saving-and-Loading-Models-in-py torch</a></li><li id="2cea" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">[2] J. Rachit，保存并加载您的模型以在 PyTorch 中恢复培训(2019)，<a class="ae ky" href="https://medium.com/analytics-vidhya/saving-and-loading-your-model-to-resume-training-in-pytorch-cb687352fa61" rel="noopener">https://medium . com/analytics-vid hya/Saving-and-Loading-Your-Model-to-Resume-Training-in-py torch-CB 687352 fa 61</a></li><li id="c6b5" class="nd ne it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">[3]一、马修，保存和加载模型(2017)，<a class="ae ky" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/初学者/saving_loading_models.html </a></li></ul></div></div>    
</body>
</html>