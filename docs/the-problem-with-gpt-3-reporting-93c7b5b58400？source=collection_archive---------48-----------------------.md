# GPT-3 报告的问题

> 原文：<https://towardsdatascience.com/the-problem-with-gpt-3-reporting-93c7b5b58400?source=collection_archive---------48----------------------->

## 双重选择偏差过滤了我们对 GPT-3 的看法

![](img/f95da3ad772c7d7631816ff37fe5ee00.png)

马克斯·兰格洛特在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

我最近在媒体和其他地方看到了大量关于 GPT-3 的文章。我甚至[写了一首](/exploring-the-ai-dungeon-253ddc577011)。语言模型是人工智能的一个重大发展，所以作家想与世界分享他们的兴奋是很自然的。

问题就在这里:GPT 3 的能力——即其写作质量——经常被公布的样本夸大。事实上，不是有一个，而是两个过滤器保持 AI 的最差结果不被广泛传播。

如果任何感兴趣的读者都可以访问 GPT-3 API 并对其能力进行自己的观察，那么选择偏差就不是问题了。然而，目前准入受到严重限制。( [AI Dungeon](https://play.aidungeon.io/) 经常被我们这些没有完整版本的人用来测试 GPT 3，但它的创造者最近概述了防止后门进入 GPT 3 的方法。)

当报道——我用这个词最广义的解释来指任何关于 GPT-3 的文章——是公共信息的唯一来源时，在我们对产品的理解中应该考虑选择偏差。在这里，我概述了明显的偏见，以及加剧这一问题的不太明显的偏见。

## 1.写作样本是为了质量而选择的

假设我正在写一篇关于 GPT 3 号的信息性文章。我想证明它可以把连贯的句子串放在一起，所以我给它一个提示并检查输出。

如果我不喜欢我所看到的，我可能会用稍微不同的(也许更长的)提示再试一次。即使我没有主动选择适合我文章目的的特定句子，篡改输出会产生一个有偏见的写作样本，不能代表 GPT-3 的整体质量。

在创造一个关于人工智能的故事的背景下，展示它最好的作品比公平地展示它的局限性更有意义。这是第一个问题。

## 2.文章越酷，浏览量越多

考虑一下**做的事情**被写到 GPT-3 *不能*执行的功能的情况。它可能是一个写失败的列表，或者是不能编译的代码。

对我来说，这不会是一个有趣的作品，我怀疑它也不会引起其他人的兴趣。我确信推特、Reddit 帖子和详细描述 GPT 3 号意外失败的长篇文章就在那里，但事实是它们没有被阅读。

表面上看，这似乎不是问题。绝对没有必要去阅读所有 GPT-3 做不到的事情。真正的问题是，对于同样的任务，积极的结果比消极的结果更受青睐。例如，如果有人报告了让 GPT-3 编写法律文档的积极结果，这无疑会比人工智能无法生成连贯文档的情况受到更多的关注。

本质上，GPT-3 报告目前的工作方式类似于在没有[预注册](https://www.sciencemag.org/news/2018/09/more-and-more-scientists-are-preregistering-their-studies-should-you)的情况下进行科学试验。发表偏倚，即统计上无关紧要的结果不被发表，会导致荒谬的发现被接受为可靠的研究。

要明确的是，我不认为作家有必要发表更多来自 GPT-3 的负面结果。然而，有义务将样本与它们产生的方式以及在这个过程中获得了多少负面结果联系起来。

毕竟，人类对人工智能输出的选择——在单个作品或更大的作品如何被消耗的层面上——是我们的智能和计算机程序的智能的结合，这是一件美好的事情。