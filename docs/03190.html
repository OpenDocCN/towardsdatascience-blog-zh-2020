<html>
<head>
<title>Can You Teach a Computer to Write Like Stephen King?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你能教计算机像斯蒂芬·金那样写作吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-you-teach-a-computer-to-write-like-stephen-king-3bdec697723?source=collection_archive---------36-----------------------#2020-03-26">https://towardsdatascience.com/can-you-teach-a-computer-to-write-like-stephen-king-3bdec697723?source=collection_archive---------36-----------------------#2020-03-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="12d6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在NLP的深度学习的帮助下</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5bb5a69124d18c9fedf95076199a745a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DO4WrPK7thH_Oj09"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@thoughtcatalog?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">思想目录</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="1aae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你是否曾经想写一个引人入胜的故事，但缺乏合适的技巧？也许让计算机为你做艰苦的工作。</p><p id="b105" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将在深度学习的帮助下教你如何教计算机像斯蒂芬·金一样写故事。数据集由斯蒂芬·金的五篇短篇小说组成。</p><ul class=""><li id="7f81" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><em class="me">草莓春天</em></li><li id="6ec6" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><em class="me">大夜班</em></li><li id="7ee9" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><em class="me">房间里的女人</em></li><li id="0508" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><em class="me">我是门道</em></li><li id="38ff" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><em class="me">战场</em></li></ul><p id="dbb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将使用专门用于自然语言处理的递归神经网络，并将Python作为编程语言。</p><h1 id="94b0" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">1.导入所有必需的库</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h1 id="f9dd" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">2.导入数据</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="9587" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文本文件包含上面提到的五个故事。另外，请注意，我降低了所有单词的大小写，以减少词汇量。</p><h1 id="b46c" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">3.创造词汇</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="f491" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里的第一行将创建所有独特字符的词汇表。由于神经网络只理解数值，我们必须将每个字符映射到一个整数。第二行和第三行创建一个字典，将每个字符映射到一个整数。</p><h1 id="ea28" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">4.创建序列和目标</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="b216" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里我们将创建100个字符长度的序列，预测下一个101个字符。</p><h1 id="3a3c" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">5.编码序列和目标</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="fc59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如前所述，神经网络只能理解数值，我们必须对序列和目标进行编码。</p><h1 id="7ca7" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">6.构建模型</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="2703" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有人可能认为RNN的实现非常复杂，但是在Keras的帮助下，实现起来非常简单。该模型基本上由以下4层组成:</p><p id="86ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1。嵌入:</strong>嵌入层将高维空间的向量变换到低维空间。在某种程度上，意思相似的词也有相似的价值。</p><p id="91a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。LSTM: </strong>长短期记忆(LSTM)是一种递归神经网络。它们能够学习序列预测问题中的顺序依赖性。</p><p id="a9cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。辍学:</strong>辍学有助于防止过度适应。</p><p id="2769" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4。密集:</strong>这是发生预测的输出层。Softmax函数用于输出每个字符的概率值。</p><h1 id="f136" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">7.训练网络</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="3a5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用拟合函数，我们可以训练我们的网络。我把批量大小定为64，训练了40个纪元。</p><h1 id="0b3b" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">8.预测</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="4fa9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">函数<code class="fe ne nf ng nh b">sample() </code>将从输出概率数组中抽取一个索引。参数<code class="fe ne nf ng nh b">temperature </code>定义了函数在创建文本时的自由度。</p><p id="bf3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">种子句子用于预测下一个字符。然后，我们可以简单地用预测的字符更新种子句子，并修剪第一个字符以保持序列长度不变。</p><h1 id="58b2" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">9.结果</h1><p id="6c9d" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">生成的段落:</p><pre class="kj kk kl km gt nn nh no np aw nq bi"><span id="75a3" class="nr ml it nh b gy ns nt l nu nv">Input: people clustered in small groups that had a tendency to break up and re-form with surprising speed.</span><span id="61f5" class="nr ml it nh b gy nw nt l nu nv">Output: people clustered in small groups that had a tendency to break up and re-form with surprising speed. looking out to be an undergrad named donald morris work and i passed all the look and looked at him. he was supposed to stay wiping across the water,<br/>but they were working and shittered back of its an<br/>appla night. the corpse in the grinder, expecting the crap outs.</span><span id="726d" class="nr ml it nh b gy nw nt l nu nv">the counted in the second. jagged sallow sound over the way back on the way — at least aloud.</span><span id="1bc1" class="nr ml it nh b gy nw nt l nu nv">'i suspect there,’ hall said softly. he was supposed to be our life counting fingers.</span></pre><p id="3c68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">生成的文本看起来可读性很强。虽然它没有意义，有些句子语法不正确，有些单词拼写错误，但它使用了正确的标点符号，如每句话后的句号和引用一个人时的引号。</p><h1 id="0be6" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">结论</h1><p id="5231" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">我承认生成的文本与斯蒂芬·金的写法相去甚远。但是看到最近在深度学习和自然语言处理方面的进展，我满怀希望。也许几年后，电脑会成为比人更好的作家。</p><p id="87a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，如果你想了解更多关于循环神经网络的内容，安德烈·卡帕西有一个很棒的<a class="ae ky" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="noopener ugc nofollow" target="_blank">博客</a>。</p><p id="0572" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的模型的性能可以通过使用更大的训练数据和修补超参数来提高。</p><p id="0c7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请随意使用代码。完整的项目可以在<a class="ae ky" href="https://github.com/himanshuagarwal190/Stephen-King-Text-Generation" rel="noopener ugc nofollow" target="_blank"> Github </a>中找到。</p><h1 id="2e55" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">谢谢大家！</h1><p id="22d6" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">感谢您的阅读，祝您有美好的一天。:)</p></div></div>    
</body>
</html>