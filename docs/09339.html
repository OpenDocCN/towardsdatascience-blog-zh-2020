<html>
<head>
<title>Traffic sign recognition using deep neural networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度神经网络的交通标志识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/traffic-sign-recognition-using-deep-neural-networks-6abdb51d8b70?source=collection_archive---------15-----------------------#2020-07-04">https://towardsdatascience.com/traffic-sign-recognition-using-deep-neural-networks-6abdb51d8b70?source=collection_archive---------15-----------------------#2020-07-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><blockquote class="jq jr js"><p id="b2a3" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">皮尤什·马尔霍特拉、普内特和塔尼什克·查莫拉</p></blockquote><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/f583d3f876dfeb474ecebfcebd66bffc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6uFaXa70izdlst6z"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">贾维尔·基罗加在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="c926" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">在当今世界，随着车辆数量的增加，道路事故也在增加，据报道，印度是事故数量最多的国家之一。这是由许多原因造成的，如执法不力、粗心大意等。原因之一是人们不认识或不遵守交通标志板。因此，我们制作了一个交通标志识别器，它可以通知车辆驾驶员前方有交通标志，并跟随它。这可以减少交通事故。</p><h1 id="c718" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">卷积神经网络</h1><p id="cc99" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">卷积神经网络是深度学习的一部分，广泛用于图像识别。这些卷积神经网络由几层组成。首先，Conv2D 层用于在过滤器的帮助下进行特征提取。过滤器的数量通常是 2 的幂，如 32、64 或 128。在这一层中使用了激活功能。通常使用 ReLU(整流线性单位)激活功能。ReLU 函数被定义为最大值(0，x)。</p><p id="4eb4" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">接下来是最大池层，用于减少图像的尺寸。这样做是为了减少处理图像所需的计算能力。第三是辍学层。该脱落层用于防止过度拟合，并降低模型的复杂性。在这一层中，一些神经元被随机移除。</p><p id="df07" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">前三层的组合称为特征学习阶段。这三层被多次使用以改善训练。</p><p id="659c" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">第四个是 flatten 层，它将二维数据转换为一个完整连接层的长一维特征向量，该向量可以输入到神经网络中。</p><p id="af1a" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">最后一层是密集层，用作输出层。最后一层的节点数量与类的数量相同。最后一个密集层使用 softmax 激活功能。Softmax 函数给出概率值(在 0 和 1 之间)，以便模型可以预测哪个类的概率最高。</p><h1 id="db32" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">交通标志识别</h1><h2 id="57b5" class="mp ln it bd lo mq mr dn ls ms mt dp lw lj mu mv ma lk mw mx me ll my mz mi na bi translated">1.资料组</h2><p id="c889" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">我们采用了 2011 年国际神经网络联合会议(IJCNN)上举行的德国交通标志基准单幅图像分类挑战赛的数据集。链接—【kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign T4】</p><p id="ed75" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">该数据集由 39，209 幅交通标志图像组成。</p><h2 id="4f5e" class="mp ln it bd lo mq mr dn ls ms mt dp lw lj mu mv ma lk mw mx me ll my mz mi na bi translated">2.导入必要的库</h2><p id="1766" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">我们将为此使用 Python 语言。首先，我们将导入必要的库，如用于构建主模型的 keras、用于分割训练和测试数据的 sklearn、用于将图像转换为数字数组的 PIL 以及其他库，如 pandas、numpy、matplotlib 和 tensorflow。</p><pre class="kt ku kv kw gt nb nc nd ne aw nf bi"><span id="2a48" class="mp ln it nc b gy ng nh l ni nj"><strong class="nc iu">import</strong> <strong class="nc iu">numpy</strong> <strong class="nc iu">as</strong> <strong class="nc iu">np</strong>                               <br/><strong class="nc iu">import</strong> <strong class="nc iu">pandas</strong> <strong class="nc iu">as</strong> <strong class="nc iu">pd</strong>                        <br/><strong class="nc iu">import</strong> <strong class="nc iu">matplotlib.pyplot</strong> <strong class="nc iu">as</strong> <strong class="nc iu">plt</strong>                  <br/><strong class="nc iu">import</strong> <strong class="nc iu">cv2</strong>             <br/><strong class="nc iu">import</strong> <strong class="nc iu">tensorflow</strong> <strong class="nc iu">as</strong> <strong class="nc iu">tf</strong>                          <br/><strong class="nc iu">from</strong> <strong class="nc iu">PIL</strong> <strong class="nc iu">import</strong> Image                           <em class="jv">]</em><br/><strong class="nc iu">import</strong> <strong class="nc iu">os</strong>                                        <br/><strong class="nc iu">from</strong> <strong class="nc iu">sklearn.model_selection</strong> <strong class="nc iu">import</strong> train_test_split<br/><strong class="nc iu">from</strong> <strong class="nc iu">keras.utils</strong> <strong class="nc iu">import</strong> to_categorical          <br/><strong class="nc iu">from</strong> <strong class="nc iu">keras.models</strong> <strong class="nc iu">import</strong> Sequential, load_model<br/><strong class="nc iu">from</strong> <strong class="nc iu">keras.layers</strong> <strong class="nc iu">import</strong> Conv2D, MaxPool2D, Dense, Flatten, Dropout<br/><strong class="nc iu">import</strong> <strong class="nc iu">tqdm</strong>                                    <br/><strong class="nc iu">import</strong> <strong class="nc iu">warnings</strong></span></pre><h2 id="e5fd" class="mp ln it bd lo mq mr dn ls ms mt dp lw lj mu mv ma lk mw mx me ll my mz mi na bi translated">3.检索图像</h2><p id="416c" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">我们将检索图像及其标签。然后将图像大小调整为(30，30)，因为所有图像都应该具有相同的大小以便识别。然后将图像转换成 numpy 数组。</p><pre class="kt ku kv kw gt nb nc nd ne aw nf bi"><span id="f721" class="mp ln it nc b gy ng nh l ni nj">data = []<br/>labels = []<br/>classes = 43<br/><br/><strong class="nc iu">for</strong> i <strong class="nc iu">in</strong> range(classes):<br/>    path = os.path.join(os.getcwd(),'train',str(i))<br/>    images = os.listdir(path)<br/>    <br/>    <strong class="nc iu">for</strong> j <strong class="nc iu">in</strong> images:<br/>        <strong class="nc iu">try</strong>:<br/>            image = Image.open(path + '<strong class="nc iu">\\</strong>'+ j)<br/>            image = image.resize((30,30))<br/>            image = np.array(image)<br/>            data.append(image)<br/>            labels.append(i)<br/>        <strong class="nc iu">except</strong>:<br/>            print("Error loading image")</span><span id="f91e" class="mp ln it nc b gy nk nh l ni nj"><em class="jv">#Converting lists into numpy arrays bcoz its faster and takes lesser #memory</em></span><span id="8c47" class="mp ln it nc b gy nk nh l ni nj">data = np.array(data)<br/>labels = np.array(labels)</span><span id="40ef" class="mp ln it nc b gy nk nh l ni nj">print(data.shape, labels.shape)</span></pre><h2 id="5a7b" class="mp ln it bd lo mq mr dn ls ms mt dp lw lj mu mv ma lk mw mx me ll my mz mi na bi translated">4.分割数据集</h2><p id="9fc8" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">将数据集分为训练和测试。80%训练数据和 20%测试数据。</p><pre class="kt ku kv kw gt nb nc nd ne aw nf bi"><span id="230a" class="mp ln it nc b gy ng nh l ni nj">X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=68)<br/><br/>print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)</span></pre><h2 id="a7e9" class="mp ln it bd lo mq mr dn ls ms mt dp lw lj mu mv ma lk mw mx me ll my mz mi na bi translated">5.构建模型</h2><p id="ff32" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">为了构建，我们将使用 keras 库中的顺序模型。然后，我们将添加层，使卷积神经网络。在前 2 个 Conv2D 层中，我们使用了 32 个过滤器，内核大小为(5，5)。</p><p id="943e" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">在 MaxPool2D 层中，我们保留了池大小(2，2)，这意味着它将选择图像的每个 2 x 2 区域的最大值。通过这样做，图像的尺寸将减少 2 倍。在脱落层，我们保持脱落率= 0.25，这意味着 25%的神经元被随机移除。</p><p id="da99" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">我们再次应用这 3 层，参数有一些变化。然后，我们应用扁平化层转换二维数据到一维向量。这一层之后是致密层、脱落层和再次致密层。最后一个密集层输出 43 个节点，因为交通标志在我们的数据集中被分为 43 个类别。该层使用 softmax 激活函数，该函数给出概率值并预测 43 个选项中哪一个具有最高概率。</p><pre class="kt ku kv kw gt nb nc nd ne aw nf bi"><span id="f112" class="mp ln it nc b gy ng nh l ni nj">model = Sequential()<br/>model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))<br/>model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))<br/>model.add(MaxPool2D(pool_size=(2, 2)))<br/>model.add(Dropout(rate=0.25))<br/>model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))<br/>model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))<br/>model.add(MaxPool2D(pool_size=(2, 2)))<br/>model.add(Dropout(rate=0.25))<br/>model.add(Flatten())<br/>model.add(Dense(256, activation='relu'))<br/>model.add(Dropout(rate=0.5))<br/>model.add(Dense(43, activation='softmax'))</span></pre><h2 id="7600" class="mp ln it bd lo mq mr dn ls ms mt dp lw lj mu mv ma lk mw mx me ll my mz mi na bi translated">6.应用该模型并绘制精确度和损耗的图表</h2><p id="e375" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">我们将编译该模型，并使用拟合函数来应用它。批量大小将是 32。然后我们将绘制精确度和损耗的图表。我们得到了 97.6%的平均验证准确率和 93.3%的平均训练准确率。</p><pre class="kt ku kv kw gt nb nc nd ne aw nf bi"><span id="9532" class="mp ln it nc b gy ng nh l ni nj">model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])</span><span id="61d9" class="mp ln it nc b gy nk nh l ni nj">history = model.fit(X_train, y_train, batch_size=32, epochs=2, validation_data=(X_test, y_test))</span><span id="7c44" class="mp ln it nc b gy nk nh l ni nj">model.save("Trafic_signs_model.h5")<br/><em class="jv">#plotting graphs for accuracy </em><br/>plt.figure(0)<br/>plt.plot(history.history['accuracy'], label='training accuracy')<br/>plt.plot(history.history['val_accuracy'], label='val accuracy')<br/>plt.title('Accuracy')<br/>plt.xlabel('epochs')<br/>plt.ylabel('accuracy')<br/>plt.legend()<br/>plt.show()</span><span id="5e38" class="mp ln it nc b gy nk nh l ni nj"><em class="jv">#plotting graphs for loss </em><br/>plt.figure(1)<br/>plt.plot(history.history['loss'], label='training loss')<br/>plt.plot(history.history['val_loss'], label='val loss')<br/>plt.title('Loss')<br/>plt.xlabel('epochs')<br/>plt.ylabel('loss')<br/>plt.legend()<br/>plt.show()</span></pre><h2 id="5d9b" class="mp ln it bd lo mq mr dn ls ms mt dp lw lj mu mv ma lk mw mx me ll my mz mi na bi translated">7.测试集的准确性</h2><p id="14c7" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">我们在测试集上获得了 94.7%的准确率。</p><pre class="kt ku kv kw gt nb nc nd ne aw nf bi"><span id="cde9" class="mp ln it nc b gy ng nh l ni nj"><strong class="nc iu">from</strong> <strong class="nc iu">sklearn.metrics</strong> <strong class="nc iu">import</strong> accuracy_score</span><span id="01d8" class="mp ln it nc b gy nk nh l ni nj">y_test = pd.read_csv('Test.csv')<br/><br/>labels = y_test["ClassId"].values<br/>imgs = y_test["Path"].values<br/><br/>data=[]<br/><br/><strong class="nc iu">for</strong> img <strong class="nc iu">in</strong> imgs:<br/>    image = Image.open(img)<br/>    image = image.resize((30,30))<br/>    data.append(np.array(image))<br/><br/>X_test=np.array(data)<br/><br/>pred = model.predict_classes(X_test)</span><span id="94ba" class="mp ln it nc b gy nk nh l ni nj"><em class="jv">#Accuracy with the test data</em><br/>print(accuracy_score(labels, pred))</span></pre><h1 id="1274" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">图形用户界面</h1><p id="59b2" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">现在模型已经准备好了，所以我们可以在界面(GUI)上创建一个图形用户了。我们使用 tkinter 库来制作 GUI。图形用户界面代码:</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="nl nm l"/></div></figure><h1 id="de22" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">输出</h1><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nn"><img src="../Images/12d26ecf2fe20adf230ed2c0849fcae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*FZJ3QJYf-WULCy0zAeJZEw.gif"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">作者 GIF</p></figure><h1 id="8fe5" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">结论</h1><p id="b819" class="pw-post-body-paragraph jt ju it jw b jx mk jz ka kb ml kd ke lj mm kh ki lk mn kl km ll mo kp kq kr im bi translated">因此，我们开始了解卷积网络以及它们如何用于图像识别。我们利用卷积神经网络进行了交通标志识别，在验证集和测试集上的准确率分别达到了 97.6%和 94.7%。</p><p id="36c8" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">完整的代码可以在下面的 github 库中找到:<a class="ae li" href="https://github.com/pun8/trafficSignsRecog" rel="noopener ugc nofollow" target="_blank">交通标志识别</a></p><p id="5e58" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke lj kg kh ki lk kk kl km ll ko kp kq kr im bi translated">谢谢你。</p></div></div>    
</body>
</html>