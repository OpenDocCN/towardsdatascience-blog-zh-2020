<html>
<head>
<title>COVID-19 CT Analysis using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的新冠肺炎 CT 分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/covid-19-ct-analysis-using-deep-learning-7342a6ba5a31?source=collection_archive---------52-----------------------#2020-08-31">https://towardsdatascience.com/covid-19-ct-analysis-using-deep-learning-7342a6ba5a31?source=collection_archive---------52-----------------------#2020-08-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1bd2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们如何在(几乎)没有数据和注释的情况下开发深度学习新冠肺炎 CT 分析工具</h2></div><p id="6a8c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一月中旬，关于中国出现一种导致发烧和咳嗽的新病毒的消息开始传来。</p><p id="5e6f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">当时，我们正在与一家中国公司合作，整合我们的胸部 CT 分析工具。该公司开发了一个云 PACS(图片存档和通信系统)，使放射科医生能够远程查看病例并编辑来自多家医院的放射报告。</em></p><p id="f1e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">我们注意到胸部 CT 扫描中有肺部异常的患者，这些患者被引导到实验室检查。随着医学成像算法的研究，我们认为可以开发一种解决方案来检测这些发现。</em></p><p id="f84b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">当时我们还很天真，无法想象几个月后，全世界都会遭受冠状病毒疫情的侵袭，而我们的新冠肺炎 CT 分析工具将作为新冠肺炎检测和患者监测的工具，为全世界的放射科医生提供服务。</em></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/fdfb259dcc802696709d95a05a036899.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fO4KiT9mZ7nLfrDh"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">迪米特里·卡拉斯泰列夫在<a class="ae lv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="96c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们面临两个问题(这在医学成像领域相当普遍):(1)小数据集——我们只有几个疑似新冠肺炎患者的病例；(2)完全没有注释</p><p id="4548" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在接下来的章节中，我将阐述我们如何使用深度学习工具快速构建新冠肺炎解决方案。<em class="le">这里提出的思路和方法可以用于任何具有 CT 影像特征的新病毒或疾病，尤其是在数据几乎不可用的初期阶段。</em></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lw"><img src="../Images/efb3a3acffcbf0ddc03d80ac2e455fef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SUVpNvL6oIB4A1tuBn5ASA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">新冠肺炎 chect CT 分析的深度学习框架[图片由作者提供]</p></figure><h1 id="5262" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">1.基于切片的解决方案</h1><p id="c036" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">CT 扫描包括一系列切片(对于不熟悉 CT 的人，请阅读下面的简短说明)。由于我们对新冠肺炎患者的扫描数量非常有限，我们决定使用 2D 切片代替每次扫描的 3D 体积。<br/>这使我们能够将数据集多元化，并克服小数据集的第一个障碍。使用 2D 切片的另一个原因是对 CT 扫描的切片厚度变化(两个连续 CT 切片之间的 z 边缘)具有鲁棒性的能力。</p><p id="7171" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们收集了 50 名患者的异常胸部 CT 扫描，这些患者被放射科医生诊断为可疑新冠肺炎。</p><blockquote class="mu mv mw"><p id="dad7" class="ki kj le kk b kl km ju kn ko kp jx kq mx ks kt ku my kw kx ky mz la lb lc ld im bi translated"><a class="ae lv" href="https://radiopaedia.org/articles/computed-tomography?lang=us" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">【CT】</strong></a>扫描是一种诊断成像程序，它使用 x 射线来构建身体的横截面图像(“切片”)。根据对所研究对象体积中 x 射线束衰减系数的测量来重建横截面。在数据显示在屏幕上之前，常规的重新标度被制成 CT 数，用<a class="ae lv" href="https://radiopaedia.org/articles/hounsfield-unit?lang=us" rel="noopener ugc nofollow" target="_blank"> Hounsfield 单位(HU) </a>表示【1】。CT 切片具有高动态范围(通常为 12 位或 16 位)，并以 DICOM 格式提供。</p></blockquote><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/5f55c9188909a0f49f208732282d3521.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/1*2hsYsD3kA9kdneQhJr3_Zg.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">检查 ct 切片[图片由作者提供]</p></figure><p id="b152" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将 CT dicom 文件读取为 numpy 数组的代码示例:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h1 id="729f" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak"> 2。肺部分割</strong></h1><p id="d079" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">分析的第一步是在图像中找到\分割肺部，并在肺部周围裁剪图像。这使得我们可以专注于感兴趣的区域(ROI)进行进一步分析。</p><p id="f46b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用于医学成像分割任务的一种流行的深度学习架构是<a class="ae lv" href="https://arxiv.org/pdf/1505.04597.pdf)%e5%92%8c%5bTiramisu%5d(https://arxiv.org/abs/1611.09326.pdf" rel="noopener ugc nofollow" target="_blank"> U-net </a>。原始架构有许多变化，包括我们使用的包含<a class="ae lv" href="https://arxiv.org/pdf/1810.02113.pdf" rel="noopener ugc nofollow" target="_blank"> VGG16 预训练编码器</a>的架构。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nd"><img src="../Images/11054b9d6700fdfe699be5f4593e4d95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Vfbwpt_8f8qLl7_Nta8xA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">基于 U-net 的肺部分割架构[图片由作者提供]</p></figure><p id="c265" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了进行训练，我们使用了 6150 个肺部异常病例的 CT 切片及其相应的肺面罩。使用表示肺组织的[-1000，0] HU 的窗口对输入切片进行剪辑(意味着所有大于 0 的值都被设置为 0，所有小于-1000 的值都被设置为-1000)。然后，我们将像素归一化到范围[0，1]，并将图像大小调整为 224x224 像素。</p><p id="6f18" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">剪切和归一化 CT 切片的代码示例:</em></p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="705d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用随机裁剪、水平翻转和向肺部区域添加正态分布噪声来扩充数据，以提高对感染性肺部(这在新冠肺炎患者中很常见)的分割的鲁棒性。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/772ba3b5cf2260f2dd5698075730794f.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*Z-gtn0P-davqx_2odb-3mw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">将噪声添加到肺部区域作为增强(噪声标度=0.1，噪声均值=0.0，噪声标准值= 0.8)[图片由作者提供]</p></figure><p id="1bdc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">向图像添加正态分布噪声的代码示例:</em></p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><blockquote class="mu mv mw"><p id="dfca" class="ki kj le kk b kl km ju kn ko kp jx kq mx ks kt ku my kw kx ky mz la lb lc ld im bi translated">这里我们使用了一个私有数据集，但是有几个 CT 扫描的公共数据集，都有相应的肺掩膜(<a class="ae lv" href="https://luna16.grand-challenge.org/Data/" rel="noopener ugc nofollow" target="_blank"> LUNA16 </a>、<a class="ae lv" href="https://wiki.cancerimagingarchive.net/display/Public/Lung+CT+Segmentation+Challenge+2017" rel="noopener ugc nofollow" target="_blank">肺部 CT 分割挑战 2017 </a>、<a class="ae lv" href="https://structseg2019.grand-challenge.org/Home/" rel="noopener ugc nofollow" target="_blank"> StructSeg </a>、<a class="ae lv" href="http://medicalsegmentation.com/covid19/" rel="noopener ugc nofollow" target="_blank"> MedSeg </a>)。MedSeg 是为新冠肺炎病人准备的。</p></blockquote><h1 id="4978" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">3.新冠肺炎分类器</h1><p id="bf0e" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">由于我们已经决定使用 2D 切片，并且由于我们<strong class="kk iu">没有注释</strong>来解决<strong class="kk iu">分类任务</strong>，我们手动将 50 个病例的每个切片注释为正常或异常，这意味着它包含新冠肺炎感染(因为感染在连续切片中可见，这不是一个非常复杂的注释任务！).使用这种方法，我们设法收集了 1865 个 CT 切片的注释数据集:1036 个正常，829 个异常。<br/>为了进一步丰富我们的训练集，我们采用了数据增强技术，包括图像旋转、水平翻转和裁剪。然后，我们使用上文详述的肺部分割来裁剪肺部 ROI，并将每个输入图像的大小调整为 224X224 像素，以基于在 ImageNet 数据库上预训练的<a class="ae lv" href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank"> ResNet-50 架构</a>来训练每个切片的新冠肺炎分类器。使用<a class="ae lv" rel="noopener" target="_blank" href="/deep-learning-using-transfer-learning-python-code-for-resnet50-8acdfb3a2d38">迁移学习</a>通常可以提高分类性能，尤其是在训练数据有限的情况下。<br/>由于 ImageNet 分类任务包括 1000 个类别，而我们只需要对 2 个类别进行分类，因此我们移除了预训练模型的最后几层，并添加了两个密集层，然后添加了一个 sigmoid 激活函数。</p><p id="5b43" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">加载预训练 ResNet-50 架构并修改最后几层以适应新分类任务的代码示例(使用 Keras): </em></p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h1 id="bdd5" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">4.细粒度本地化</h1><p id="df45" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated"><em class="le">如何输出</em> <strong class="kk iu"> <em class="le">汉化</em> </strong> <em class="le">地图带</em> <strong class="kk iu"> <em class="le">无标注</em> </strong> <em class="le">？</em> <br/> <a class="ae lv" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf" rel="noopener ugc nofollow" target="_blank"> Grad-CAM 技术</a>是<a class="ae lv" href="https://medium.com/@mrsalehi/a-review-of-different-interpretation-methods-in-deep-learning-part-1-saliency-map-cam-grad-cam-3a34476bc24d" rel="noopener">深度学习</a>中最常用的解释方法之一(旨在可视化“网络在看”哪里，以对特定目标进行分类)。在医学图像中，这种技术通常用于弱监督定位甚至分割，其中仅通过正常与异常的切片标签来进行监督，以生成定位热图图像。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/0cf8059cd6659b370757869b50d9fa00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*4K8f-vbEe5sq7dZpU20P7Q.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">使用 CAM 技术生成的热图图像示例，用于 X 射线图像中的病理定位。来源:<a class="ae lv" href="https://arxiv.org/abs/1711.05225" rel="noopener ugc nofollow" target="_blank"> Rajpurkar，Pranav 等人(2017) </a></p></figure><p id="5b7b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 GradCam 生成粗略定位图的同时，我们在两种图像分辨率上采用该技术，并在它们之间进行融合，以生成新冠肺炎感染区域的精细定位图。更具体地说，我们在对应于 ResNet-50 网络的大小为 14X14 和 28X28 的分辨率的激活层上使用 GradCam(在这些分辨率的最后激活层上定义 GradCam 输出)。</p><p id="aa17" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个贴图被归一化为[0，1]并调整为输入图像形状(224X224)。我们将两个图相乘以生成一个细粒度的定位图，它可以作为热图图像应用于彩色图像:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ng"><img src="../Images/a7e91abcbfdea5d1ac31ab243e7ee5f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WawSg_TrNSr2nsMQ9P0yiA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">融合两种分辨率图像的 GradCam 精细定位:热图显示肺部新冠肺炎感染区域的高活性[图片由作者提供]</p></figure><h1 id="8b5a" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">5.案例决策和 3D 概述</h1><p id="9d80" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">在我们为每个 2D 切片生成肺部分割和新冠肺炎定位图之后，我们可以将所有切片的这些结果组合起来，以获得该病例的完整 3D 体积概览。为了将不同切片的定位图融合成平滑的视图，我们应用阈值来获得新冠肺炎感染分割，并使用 3D 高斯模糊。</p><p id="095e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用<a class="ae lv" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> <em class="le"> matplotlib </em> </a>和<a class="ae lv" href="https://scikit-image.org/docs/dev/api/skimage.measure.html" rel="noopener ugc nofollow" target="_blank"><em class="le">skim age . measure</em></a>python 库可以在肺部和感染部位生成三维绘图图像:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="684e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了结束病例级分类，我们计算了新冠肺炎分类器检测为阳性的切片数量和属于肺部区域的切片数量。如果它们之间的比率超过预定义的阈值(根据最佳表现设置)，则整个病例被分类为疑似新冠肺炎。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi gj"><img src="../Images/833e3369bb88746afce80b0bac6e7ba4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jk585P-Nndw-RZ2KeeVU6Q.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">用于监测患者疾病进展的 Corona 评分。资料来源:<a class="ae lv" href="https://arxiv.org/abs/2003.05037" rel="noopener ugc nofollow" target="_blank"> O. Gozes 和 M . Frid-Adar 等人(2020 年)</a></p></figure><p id="2520" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还提出了一个严重性评分，允许医生随着时间的推移跟踪患者的新冠肺炎病——“电晕评分”。通过由新冠肺炎分类器对阳性检测切片的定位图上求和，并乘以切片像素间距(z 轴)来计算分数。电晕得分是以厘米为单位的体积测量。</p><p id="202a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">参考文献</em> </strong></p><p id="dca1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1]<a class="ae lv" href="https://radiopaedia.org/articles/computed-tomography?lang=us" rel="noopener ugc nofollow" target="_blank">https://radiopaedia.org/articles/computed-tomography?lang=us </a></p><p id="285f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] O .龙内贝格、p .菲舍尔和 t .布罗克斯。<a class="ae lv" href="https://arxiv.org/pdf/1505.04597.pdf)%e5%92%8c%5bTiramisu%5d(https://arxiv.org/abs/1611.09326.pdf" rel="noopener ugc nofollow" target="_blank"> U-net:用于生物医学图像分割的卷积网络</a> (2015)。医学图像计算和计算机辅助介入国际会议。</p><p id="e3f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3] M. Frid-Adar 等人<a class="ae lv" href="https://arxiv.org/pdf/1810.02113.pdf" rel="noopener ugc nofollow" target="_blank">使用带有 imagenet 预训练编码器的 u-net 改善胸部 x 光照片中解剖结构的分割</a> (2018)。运动器官、乳房和胸部图像的图像分析。施普林格，查姆，2018。159–168.‏</p><p id="0e5c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4] K. He 等<a class="ae lv" href="https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a> (2016)。IEEE 计算机视觉和模式识别会议录。</p><p id="118e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[5] RR。Selvaraju 等人<a class="ae lv" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf" rel="noopener ugc nofollow" target="_blank"> Grad-cam:通过基于梯度的定位从深度网络进行视觉解释</a> (2017)。IEEE 计算机视觉国际会议论文集。</p><p id="0e6d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[6] O. Gozes 等人<a class="ae lv" href="https://arxiv.org/abs/2003.05037" rel="noopener ugc nofollow" target="_blank">冠状病毒(新冠肺炎)疫情的快速人工智能开发周期:使用深度学习 ct 图像分析进行自动检测的初步结果&amp;患者监测</a> (2020)。arXiv 预印本 arXiv:2003.05037。</p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="3bb6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">提出的新冠肺炎检测和定位方法是作为我作为算法开发负责人工作的 RADLogics 的初始工具开发的。</p><p id="432b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是我的第一个媒体博客——希望你喜欢！【maayan.frid@gmail.com】随时给我写信</p></div></div>    
</body>
</html>