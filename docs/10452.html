<html>
<head>
<title>AutoML-Zero</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动归零</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automl-zero-b2e065170941?source=collection_archive---------29-----------------------#2020-07-22">https://towardsdatascience.com/automl-zero-b2e065170941?source=collection_archive---------29-----------------------#2020-07-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8c21" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们花了 60 年才发现一个可以自我发现的东西。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e1b0cd75caf1243be800567c067d9f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UKHsAYOJJADaIN-g"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@trommelkopf?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">史蒂夫·哈维</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="23b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们人类设计模型，模型有参数。可以把参数想象成稍微向左或向右旋转的旋钮，改变模型的行为。近年来，神经网络在各种各样的任务上表现出显著的成功，并且已经看到了巨大的普及增长。考虑到技能、计算资源和 ML 研究的难度等因素，它催生了一个名为 AutoML 的新领域，<strong class="lb iu">，旨在用机器计算的时间代替人类的研究时间</strong>。</p><h1 id="9316" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">什么导致了自动归零？</h1><p id="8c39" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">AutoML 研究已经通过使用人类专家预先描述的构建块来限制搜索空间(算法可以从中提取操作的项目池)，如<em class="ms">ReLU 层</em>、<em class="ms">卷积层</em>、<em class="ms">批处理规范化层</em>，这往往会使搜索结果偏向于人类设计的算法。一个常见的例子是神经结构搜索，它使用复杂的人为设计的层作为构建块，并遵循反向传播的规则来搜索新的结构和最佳超参数。</p><p id="4700" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">AutoML 的其他变体通过预定义某些他们认为至关重要的超参数来限制他们的搜索空间，但该算法无法像反向传播期间的学习速率那样实现它。一些研究建议使用固定的预处理管道将处理后的输入馈送到算法，如图像情况下的数据扩充。因此，许多这些方面仍然是手工设计的。这些方法可能会节省计算时间，但可能会降低 AutoML 的创新潜力。</p><p id="e2e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">AutoML-Zero 背后的概念很简单，为什么我们不假设我们没有花哨的运算(像反向传播或梯度下降)并让算法通过使用基本的数学运算从零开始设计一切，这就是为什么它被称为<em class="ms">机器学习从零开始。</em> <strong class="lb iu">把它想象成没有 TensorFlow，没有 PyTorch，只是用 NumPy 来进化机器学习的概念。令人惊讶的是，它可以发现非线性模型、学习率、梯度等概念。所以基本上在你眼前持续了 30 年的神经网络进化。</strong></p><h1 id="10ec" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">高级工作概述</h1><p id="7bc2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">AutoML-Zero 框架背后的想法是，它们初始化大量的程序，每个程序包括三个在启动时为空的函数。这三个功能是</p><ul class=""><li id="38b5" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu"> setup() </strong> - &gt;该函数用于初始化变量。</li><li id="2476" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu"> predict() </strong> - &gt;该函数用于对给定的数据点进行预测。</li><li id="dcec" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu"> learn() </strong> - &gt;此函数用于更新变量，以便预测函数随着时间的推移执行得更好。</li></ul><p id="73a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给定这三个函数，AutoML-Zero 必须在这些通用函数中填充程序的其余部分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/de140f1980305cb60fa76de1608986f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*fuqBnf7-NAaJ3xhuWn9OOg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://github.com/google-research/google-research/tree/master/automl_zero" rel="noopener ugc nofollow" target="_blank">https://github . com/Google-research/Google-research/tree/master/automl _ zero</a></p></figure><p id="145f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以上是 AutoML-Zero 发现的一个线性回归问题的算法片段。如您所见，设置函数初始化了一个名为“s2”的变量，该变量后来被用作学习函数中的学习速率，预测函数通过应用输入特征和学习权重“v1”之间的点积进行预测，学习函数首先计算实际标注和预测标注之间的误差，应用学习速率，计算梯度并更新权重。让我们看另一个片段</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/f540b13e06d9786036dcbf3da063c7c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*EyFfaJOdIu7cuWZgO8oJKw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://github.com/google-research/google-research/blob/master/automl_zero/initial_and_evolved_code.png" rel="noopener ugc nofollow" target="_blank">来源；https://github . com/Google-research/Google-research/blob/master/automl _ zero/initial _ and _ evolved _ code . png</a></p></figure><p id="a168" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以上是自动发现的 CIFAR-10 分类算法的片段。设置函数初始化学习速率，预测函数将噪声引入特征(它发现引入噪声可以提高其预测精度)，学习函数是计算误差、估计梯度、归一化梯度、归一化误差等等。</p><p id="e242" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">记住，程序开始时是空函数。事实上，这些程序可以学习像点积、梯度和归一化这样的东西，这是令人惊讶的，因为它必须搜索这个巨大的搜索空间，这个空间非常稀疏，而你在这种空间中发现的大多数程序都是完全无用的。</p><h1 id="a537" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">内部工作</h1><p id="2f16" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这一部分，我们将回答两个问题。如前所述，AutoML-Zero 框架初始化了大量的程序。为什么？(请记住，每个程序都包含这三个功能——设置、预测和学习)第二个问题是，它如何准确地填写功能中的指令？。</p><p id="dc3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">AutoML-Zero 设置使得搜索空间非常稀疏，因此，一个好的学习算法，即使是一个琐碎的任务，也可能是十分之一。在这种环境下，随机搜索无法在合理的时间内找到解决方案。为了克服这个问题，通过使用<em class="ms">正则化进化搜索</em>在搜索空间中发现这些机器学习程序。</p><h2 id="def8" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">正则化进化搜索</h2><p id="3203" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在<em class="ms">正则化进化搜索中，</em>大量程序被初始化(称为种群),它们的函数为空。然后，算法从总体中选择一个样本(两个或更多)，对它们进行评估，并选择表现最好的一个作为父代。然后父母克隆自己创造一个孩子，孩子变异了。这种突变是从三个选项中随机选择的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/5894c609b555721738348cdaa01d0388.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*w6NuSCWcISMM7WpElZldTg.png"/></div></figure><ol class=""><li id="1a48" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu nw mz na nb bi translated">在随机位置随机插入或删除指令。</li><li id="c644" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu nw mz na nb bi translated">随机替换组件函数中的所有指令</li><li id="2f52" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu nw mz na nb bi translated">修改指令的一个参数，将其替换为随机选项。</li></ol><p id="f3ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">跟随动画可能会让你对进化搜索有更深的理解</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/c734a156b932053fed4673788999bfd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*RUvr37O1KaIPRYOaYdw9Ag.gif"/></div></figure><h2 id="395c" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">演进实施加速</h2><p id="300b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">机器学习算法的自动零搜索空间是非常稀疏和通用的。这意味着这些程序中的大部分是完全无用的。例如，在第二种类型的变异中，预测函数接受标量“s0 ”,并将其分配给某个矩阵的平均值，该矩阵在设置中根本没有定义，在学习函数中也根本没有学习，然后它将另一个随机标量值“s3”分配为另一个随机标量值“s7”的余弦。所以你可以观察到，这些函数完全没有用，没有做任何有助于将指针移向机器学习算法的事情。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/e29f47c2c9d5a986e738ae3b839331ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*8jz05kufHl32E2bsnuSxYA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://github.com/google-research/google-research/tree/master/automl_zero" rel="noopener ugc nofollow" target="_blank">https://github . com/Google-research/Google-research/tree/master/automl _ zero</a></p></figure><p id="bf17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了让这种算法发挥作用，他们需要用他们的进化搜索策略评估大量不同的模型。因此，研究人员特别描述了通过 5000–10000 个模型/秒/cpu 核心的搜索。他们这样做的一些方法是通过实现<strong class="lb iu">迁移</strong>，这是一种在不同的 CPU 之间混合这些不同模型的方法，以确保在这个分布式系统中不同工作人员的多样性。然后是<strong class="lb iu"> FEC(功能等价检查)</strong>，这是一种确保两个程序对于给定的输入特性没有相同输出的方法。还有一些数据集多样性，其中算法必须从多标签分类数据集(如 MNIST ( [0 对 8]或[6 对 9])中执行二元分类任务。一组更加多样化的任务进一步有助于提高这些程序的实用性。然后是<strong class="lb iu">渐进式动态跨栏</strong>，在那里他们有一个中级健康评估，以截断表现不太好的模型。</p><h2 id="1bd9" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">算法进化</h2><p id="4175" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">投射的双星 CIFAR-10 上的一个演化实验的进展。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/5da53193332f0060cfc7d213abca4f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*YYJYaYlNtCrp6CTO8f7lzA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://storage.googleapis.com/gresearch/automl_zero/progress.gif" rel="noopener ugc nofollow" target="_blank">https://storage . Google APIs . com/gresearch/automl _ zero/progress . gif</a></p></figure><h1 id="1041" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="6b07" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这是对 AutoML 新版本的一瞥。在 AutoML-Zero 中，我们还没有达到最先进的水平。但令人兴奋的是，它仅仅从矩阵向量乘法中生成一个程序来进行机器学习，这是非常令人兴奋的。目标是减少搜索空间中的人为偏差。我希望这种方法将发现机器学习概念的新的基本构件。</p></div></div>    
</body>
</html>