<html>
<head>
<title>Beginners Guide to Apache Pyspark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Pyspark 初学者指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-apache-pyspark-4454cc03bdfa?source=collection_archive---------31-----------------------#2020-07-16">https://towardsdatascience.com/an-introduction-to-apache-pyspark-4454cc03bdfa?source=collection_archive---------31-----------------------#2020-07-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="86ba" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Apache Pyspark 提高您的数据处理性能！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3a9682fff18e4e672870d202dfdb5fb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_5rG4C0-rZQv2zw1"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@krisroller?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯托佛罗拉</a>拍摄的照片</p></figure><h1 id="889b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">阿帕奇火花</h1><p id="755b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Apache Spark 是一个开源分析引擎和集群计算框架，可以提高您的数据处理性能。正如他们所说，Spark 是一个闪电般快速的统一分析引擎。Spark 完全是用 Scala 写的。</p><p id="193b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Spark 被有效地用于<strong class="lt iu">大数据和机器学习</strong>领域，用于分析目的。Spark 已被亚马逊、易贝和雅虎等多家公司采用。</p><h2 id="12f5" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">火花的特征</h2><ul class=""><li id="27d5" class="ne nf it lt b lu lv lx ly ma ng me nh mi ni mm nj nk nl nm bi translated">Spark 是多语种的，这意味着你可以使用一种或多种编程语言来使用 Spark。Spark 为您提供了 Java、Python、R、SQL 和 Scala 的高级 API。用 Python 写的 Apache Spark 包叫做<strong class="lt iu"> Pyspark </strong>。</li><li id="c921" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">Spark 支持多种<strong class="lt iu">数据格式</strong>，比如 Parquet、CSV(逗号分隔值)、JSON (JavaScript 对象表示法)、ORC(优化的行列)、文本文件和 RDBMS 表。</li><li id="24fa" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">Spark 具有低延迟，因为它的<strong class="lt iu">内存计算。</strong> Spark 旨在处理海量数据，因此可扩展性是 Spark 的固有特性。</li><li id="1f42" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">Spark 可以与 Hadoop 无缝集成，并且能够在 Hadoop 集群上运行。</li></ul><h2 id="8ac4" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">Spark 如何工作</h2><ul class=""><li id="09a0" class="ne nf it lt b lu lv lx ly ma ng me nh mi ni mm nj nk nl nm bi translated">Spark 采用<strong class="lt iu">主从架构</strong>。主节点将任务分配给集群中的从节点，从节点将执行这些任务。</li><li id="9886" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">必须创建一个<strong class="lt iu"> Spark 会话</strong>来利用 Spark 提供的所有功能。在驱动程序内部创建一个 Spark 会话。驱动程序驻留在主节点中。</li></ul><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="e90f" class="ms la it nt b gy nx ny l nz oa"><strong class="nt iu"># Example of creating a Spark Session in Pyspark<br/></strong>spark = SparkSession.\<br/>builder.master("local").\<br/>appName("AppName").getOrCreate()</span></pre><ul class=""><li id="7940" class="ne nf it lt b lu mn lx mo ma ob me oc mi od mm nj nk nl nm bi translated">当您使用 Spark 会话读取数据帧时，数据帧将被分区并跨集群节点存储，以便可以并行操作。数据帧的分区统称为<strong class="lt iu"> RDD(弹性分布式数据集)</strong>。rdd 是容错的 T21，这意味着它对故障具有弹性。</li><li id="8142" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">当通过 Spark 会话调用一个动作时，Spark 创建转换的<strong class="lt iu"> DAG(有向无环图)</strong>(将应用于数据分区)并通过将任务分配给从节点中的执行器来实现它们。在调用操作之前，转换永远不会实现。只有当一个动作被调用时才实现转换的趋势被称为<strong class="lt iu">懒惰评估</strong>。</li><li id="4b43" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">当一个动作被调用时，在主节点上运行的驱动程序将 Spark 作业分配给从节点。<strong class="lt iu">星火任务</strong>被分解成<strong class="lt iu">阶段</strong>，这些阶段又被进一步分解成<strong class="lt iu">任务</strong>。</li><li id="c892" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">从节点包含许多<strong class="lt iu">执行器</strong>，它们接收任务并在数据<strong class="lt iu">的分区上并行执行它们。</strong>执行器是缓存数据用于内存计算的执行器。</li></ul><h1 id="34e5" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">火花转换</strong></h1><p id="e359" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">火花转换在 RDD 上执行一些操作并产生新的 RDD。各种火花变换包括<em class="oe">贴图</em>、<em class="oe">平面贴图、过滤、分组、减少和连接。</em></p><p id="55e4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="oe">火花转换进一步分为两种类型</em></p><ul class=""><li id="150f" class="ne nf it lt b lu mn lx mo ma ob me oc mi od mm nj nk nl nm bi translated">狭义变换</li><li id="2dc9" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">广泛的变革</li></ul><h2 id="62cf" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">狭义变换</h2><p id="cdfb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当操作<strong class="lt iu">不需要洗牌时，火花变换被称为窄变换。</strong>窄转换不需要在集群中的节点之间混洗数据分区。</p><p id="26e3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">窄变换的例子有<em class="oe">贴图、平面贴图、过滤器、样本、</em>等<em class="oe">。</em></p><h2 id="5d7e" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">广泛的变革</h2><p id="9fa2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当操作<strong class="lt iu">需要洗牌</strong>时，火花变换被称为宽变换。混洗是一种涉及在群集的节点上混洗数据分区以执行操作的操作。</p><p id="235d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">广泛转换的例子有<em class="oe"> groupBy、reduceBy、join、</em>等。</p><ul class=""><li id="0d4b" class="ne nf it lt b lu mn lx mo ma ob me oc mi od mm nj nk nl nm bi translated"><em class="oe"> groupBy </em>是一种转换，其中列的值被分组以形成一组唯一的值。在分布式环境中执行此操作的成本很高，因为所有要分组的值都必须从驻留在集群节点中的各种数据分区中收集。</li></ul><h1 id="3da2" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Spark 中的操作</h1><p id="3a05" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">动作是触发 Spark 作业的操作。Spark 不会立即执行转换。它需要一个动作来触发 Spark 转换的实现。</p><p id="ea23" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">火花动作的例子有<em class="oe">收集</em>、<em class="oe">计数、取第一个、保存文本文件等。</em></p><ul class=""><li id="8575" class="ne nf it lt b lu mn lx mo ma ob me oc mi od mm nj nk nl nm bi translated"><em class="oe">收集</em>是一个动作，它收集驻留在集群节点上的所有数据分区，并将它们存储在驻留在主节点上的驱动程序中。</li></ul><h1 id="44d6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">火花工作</h1><p id="3f94" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当一个动作被调用时，Spark 作业被触发。星火工作又分为<strong class="lt iu">阶段和任务。</strong></p><h2 id="a415" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">阶段</h2><p id="b394" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">涉及宽转换的 Spark 作业被分组为一个阶段，涉及窄转换的作业被分组为另一个阶段。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="000f" class="ms la it nt b gy nx ny l nz oa"><strong class="nt iu"># A Spark Job</strong><br/>df.filter(col('A')).groupBy('A')</span></pre><p id="ac4c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">上面的整个代码被认为是一个 Spark 作业，在这个<em class="oe">过滤器中</em>是一个单独的阶段，而<em class="oe"> groupBy </em>是一个单独的阶段，因为<em class="oe">过滤器</em>是一个窄变换，而<em class="oe"> groupBy </em>是一个宽变换。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="e98a" class="ms la it nt b gy nx ny l nz oa"><strong class="nt iu"># Stage A<br/>df.filter(col('A'))</strong>.groupBy('A')</span><span id="a6c1" class="ms la it nt b gy of ny l nz oa"><strong class="nt iu"># Stage B</strong><br/>df.filter(col('A')).<strong class="nt iu">groupBy('A')</strong></span></pre><h2 id="2369" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">任务</h2><p id="508a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Spark 作业的各个阶段被进一步划分为任务。任务是应用于集群节点中每个分区的操作。</p><h1 id="89fa" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">使用 Pyspark 进行数据准备</h1><h2 id="5d86" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">安装 Pyspark</h2><p id="a108" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Pyspark 可以通过执行以下命令来安装</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="0cd6" class="ms la it nt b gy nx ny l nz oa">pip install pyspark</span></pre><h2 id="6c33" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">导入所需的库</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="748e" class="ms la it nt b gy nx ny l nz oa">import math<br/>import numpy as np <br/>import pandas as pd  <br/>import pyspark<br/>from pyspark.sql import SparkSession<br/>from pyspark.sql.functions import isnan, when, count, col, isnull, asc, desc, mean</span><span id="a454" class="ms la it nt b gy of ny l nz oa"><strong class="nt iu">'''Create a spark session'''</strong><br/>spark = SparkSession.\<br/>builder.\<br/>master("local").appName("DataWrangling").getOrCreate()<br/><strong class="nt iu">'''Set this configuration to get output similar to pandas'''</strong><br/>spark.conf.set('spark.sql.repl.eagerEval.enabled', True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/a06fbada8015ef7a5f57234d793f0236.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qjqkSug-tft-w0KW0xG6-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出</p></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="ff11" class="ms la it nt b gy nx ny l nz oa"><strong class="nt iu">'''Find the count of a dataframe'''</strong><br/>df.count()<strong class="nt iu"><br/>"""OUTPUT:</strong>891"""</span></pre><h2 id="c25d" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">列中值的计数</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="f77c" class="ms la it nt b gy nx ny l nz oa">df.groupBy('Sex').count()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/3f0fc6d1177c02eeeca5b2554067cc75.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*WTJjfTK-fRabE4t9FgzwMQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出</p></figure><h2 id="4d5a" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">在数据帧中查找列的不同值</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="ae24" class="ms la it nt b gy nx ny l nz oa">df.select('Embarked').distinct()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/1a68ba34429812d1a88da759a281ea2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*Jy9QRagq7GQ3ednk_StGtg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出</p></figure><h2 id="67fa" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">在数据框架中选择一组特定的列</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="3208" class="ms la it nt b gy nx ny l nz oa">df.select('Survived', 'Age', 'Ticket').limit(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/bd163be7cbeba319233a47ef26127eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*VZcGUiwkkcZevw_ZMx1v3Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出</p></figure><h2 id="c24c" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">查找缺失值的计数</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="8bb4" class="ms la it nt b gy nx ny l nz oa">df.select([count(when(isnull(column), column)).alias(column) \<br/><strong class="nt iu">for</strong> column <strong class="nt iu">in</strong> df.columns])</span></pre><h2 id="aac9" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">过滤空值和非空值</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="4201" class="ms la it nt b gy nx ny l nz oa"><strong class="nt iu">'''Find the null values of 'Age' '''</strong><br/>df.filter(col('Age').isNotNull()).limit(5)</span><span id="df73" class="ms la it nt b gy of ny l nz oa"><strong class="nt iu">'''Another way to find not null values of 'Age' '''</strong><br/>df.filter("Age is not NULL").limit(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/b415ce9f6b31d56ef4c68fda7f7776e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cYY8jQYpKXXFkwrE6Wcbyw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出</p></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="6303" class="ms la it nt b gy nx ny l nz oa"><strong class="nt iu">'''Find the null values of 'Age' '''</strong><br/>df.filter(col('Age').isNull()).limit(5)</span><span id="8d3c" class="ms la it nt b gy of ny l nz oa"><strong class="nt iu">'''Another way to find null values of 'Age' '''</strong><br/>df.filter("Age is NULL").limit(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/06a592431824bc8ba3195e63ad15470c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bhzBxKF-gNbotjXhbYOOGw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出</p></figure><h2 id="11ec" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">排序列</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="3b96" class="ms la it nt b gy nx ny l nz oa"><strong class="nt iu">'''Sort "Parch" column in ascending order and "Age" in descending order'''</strong><br/>df.sort(asc('Parch'),desc('Age')).limit(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/78443d284d11e3129d7a6f9104470d19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L2s7okPvh6dBo6Y97trxYw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出</p></figure><h2 id="8efb" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">删除列</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="897c" class="ms la it nt b gy nx ny l nz oa"><strong class="nt iu">'''Drop multiple columns'''</strong><br/>df.drop('Age', 'Parch','Ticket').limit(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/6f70ab3a8967092b0152dd6e71307169.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ft1N1q9DbFZFWk4OsLINfg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出</p></figure><h2 id="9536" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">分组依据和聚合</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="45d1" class="ms la it nt b gy nx ny l nz oa"><strong class="nt iu">'''Finding the mean age of male and female'''</strong><br/>df.groupBy('Sex').agg(mean('Age'))</span></pre><h1 id="35d7" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">总结</strong></h1><ul class=""><li id="3c80" class="ne nf it lt b lu lv lx ly ma ng me nh mi ni mm nj nk nl nm bi translated">Spark 是一个用于分析目的的快速集群计算框架。</li><li id="c434" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">SparkSession 是 Spark 中所有功能的入口点，负责创建和调度 Spark 作业。</li><li id="a9fb" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">执行器在 RDD 可用的所有数据分区上实现转换。</li></ul></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><p id="6fe1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">在我的 Kaggle 笔记本里找到这篇帖子:</strong><a class="ae ky" href="https://www.kaggle.com/srivignesh/an-introduction-to-pyspark-apache-spark-in-python" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/srivignesh/an-introduction-to-py spark-Apache-spark-in-python</a></p></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><p id="bfa3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="oe">联系我上</em><a class="ae ky" href="https://www.linkedin.com/in/srivignesh-rajan-123569151/" rel="noopener ugc nofollow" target="_blank"><em class="oe">LinkedIn</em></a><em class="oe">，</em><a class="ae ky" href="https://twitter.com/RajanSrivignesh" rel="noopener ugc nofollow" target="_blank"><em class="oe">Twitter</em></a><em class="oe">！</em></p><p id="5b91" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">快乐学习！</p><h2 id="cf5d" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated"><strong class="ak">谢谢！</strong></h2></div></div>    
</body>
</html>