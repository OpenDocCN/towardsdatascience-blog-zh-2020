<html>
<head>
<title>Predicting Fake job postings — Part 2 (Predictive Analysis)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测虚假招聘信息—第二部分(预测分析)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-fake-job-postings-part-2-predictive-analysis-3119ba570c35?source=collection_archive---------30-----------------------#2020-04-26">https://towardsdatascience.com/predicting-fake-job-postings-part-2-predictive-analysis-3119ba570c35?source=collection_archive---------30-----------------------#2020-04-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/8cebd16ddb670e3c22ebf1a25d1c4320.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j8Sz01sRWaK8o25f"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">预测哪些招聘信息是假的。</p></figure><p id="0d9b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这个由两部分组成的系列文章的第一部分中，我做了一个详细的探索性分析，分析了虚假的招聘信息与真实的招聘信息有什么不同。下面是第 1 部分的链接，我强烈建议您在继续之前先阅读该部分！</p><div class="ld le gp gr lf lg"><a rel="noopener follow" target="_blank" href="/predicting-fake-job-postings-part-1-data-cleaning-exploratory-analysis-1bccc0f58110"><div class="lh ab fo"><div class="li ab lj cl cj lk"><h2 class="bd iu gy z fp ll fr fs lm fu fw is bi translated">预测虚假职位发布—第 1 部分(数据清理和探索性分析)</h2><div class="ln l"><h3 class="bd b gy z fp ll fr fs lm fu fw dk translated">COVID19 及其带来的经济低迷导致了许多虚假的招聘信息。这里有一个详细的…</h3></div><div class="lo l"><p class="bd b dl z fp ll fr fs lm fu fw dk translated">towardsdatascience.com</p></div></div><div class="lp l"><div class="lq l lr ls lt lp lu jz lg"/></div></div></a></div><h1 id="8e67" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">前一部分的一些重要见解—</h1><ol class=""><li id="1726" class="mt mu it kh b ki mv km mw kq mx ku my ky mz lc na nb nc nd bi translated">虚假的招聘信息大多针对全职职位，这些职位的最低要求是学士学位和中高级工作经验。</li><li id="b863" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">这些职位主要面向在技术部门寻找工作的个人。</li><li id="5196" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">45%的帖子甚至没有问一个问题就把工作给了候选人(这是虚假帖子的一个重要标志)。</li><li id="821c" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">没有经过筛选的职位大多是初级职位。</li><li id="48d1" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">这些虚假帖子主要来自美国，其次是英国、加拿大和印度。</li><li id="0a28" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">创建词云后发现，招聘启事有类似的行为内容，但正版的更具体到角色。</li></ol><p id="57b8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">基于这些见解，我们现在知道，有可能发现哪些招聘信息是假的，哪些不是。但在这个前所未有的时代，每天都有数百人被解雇，求职者感到绝望。骗子们正利用这种绝望情绪发布越来越多的虚假招聘广告。因此，我们需要在 LinkedIn、Glassdoor 等求职网站上使用更多这样的算法和工具，以便过滤掉这些虚假的帖子，让求职者只看到真实的帖子。</p><p id="0ed2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在接下来的部分，我将对上次使用的数据使用机器学习技术，并从真实的招聘信息中预测虚假的招聘信息。</p><h1 id="f3da" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">数据</h1><p id="72a9" class="pw-post-body-paragraph kf kg it kh b ki mv kk kl km mw ko kp kq nj ks kt ku nk kw kx ky nl la lb lc im bi translated">因此，到目前为止，我们在分析中使用的数据是由爱琴海大学信息与通信系统安全实验室(<a class="ae nm" href="http://emscad.samos.aegean.gr/" rel="noopener ugc nofollow" target="_blank">http://emscad.samos.aegean.gr/</a>)编制的。该数据集包含 800 个 fak 职位描述。</p><p id="6e8b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我已经在本系列的第 1 部分中定义了作为数据集一部分的变量。我会提到完整列表中的变量。我将在下一节中使用进行分析。</p><h1 id="4775" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">数据清理</h1><p id="412b" class="pw-post-body-paragraph kf kg it kh b ki mv kk kl km mw ko kp kq nj ks kt ku nk kw kx ky nl la lb lc im bi translated">我在我的系统上导入了 Jupyter 笔记本上的数据，并在 Python 3 上工作。由于我希望这一部分更多的是关于洞察力而不是代码，所以我没有在这里附上任何代码要点，但是任何对查看数据清理代码感兴趣的人，都可以随意查看我的 GitHub 库—【https://github.com/sharad18/Fake_Job_Posting T2】</p><p id="161e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最初的数据集包含 18，000 个帖子。清理后，新数据有大约 11，000 个帖子。</p><p id="451d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我将用于预测分析的变量子集是—</p><ol class=""><li id="8957" class="mt mu it kh b ki kj km kn kq nn ku no ky np lc na nb nc nd bi translated">标题:职位发布的标题。</li><li id="cba4" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">描述:职位描述+公司简介+要求</li><li id="1bfc" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">远程办公:远程办公职位的 Tru。</li><li id="9344" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">Has_company_logo:如果公司徽标存在，则为 True。</li><li id="22d1" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">Has_questions:如果存在筛选问题，则为 True。</li><li id="69de" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">就业 _ 类型:全职、兼职、合同等。</li><li id="3759" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">要求 _ 经验:高管、入门级、实习生等。</li><li id="fbed" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">要求 _ 学历:博士、硕士、学士等。</li><li id="3223" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">行业:汽车、IT、医疗保健、房地产等。</li><li id="1404" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">职能:咨询、工程、研究、销售等。</li><li id="aaf6" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">欺诈性的(目标变量):如果是假的，则为 1，否则为 0。</li><li id="6691" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">城市:招聘启事中提到的城市。</li><li id="28e4" class="mt mu it kh b ki ne km nf kq ng ku nh ky ni lc na nb nc nd bi translated">Country_name:职位发布中提到的国家的名称。</li></ol><p id="ac50" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们开始处理这些干净的数据吧！</p><h1 id="89ac" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">导入库和读取数据</h1><p id="c1e4" class="pw-post-body-paragraph kf kg it kh b ki mv kk kl km mw ko kp kq nj ks kt ku nk kw kx ky nl la lb lc im bi translated">我暂时导入了以下库，它们是任何人在 Python 中执行分析所需的基本库，</p><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="ca17" class="nz lw it nv b gy oa ob l oc od">import pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>import numpy as np<br/>pd.set_option('display.max_columns', None)</span></pre><p id="e1cc" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们看看数据，</p><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="1d01" class="nz lw it nv b gy oa ob l oc od">df = pd.read_csv('Clean_data.csv')<br/>df.head()</span></pre><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oe"><img src="../Images/c547b267bcbe600a749848e9c7eb20be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJKSEgzh332RX3rlwplPhg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">正在使用的数据的预览。</p></figure><p id="3d38" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在，我们试着详细研究“描述”一栏。在我导入的已清理数据文件中，“描述”列是“描述”+“要求”和“公司简介”的组合“描述”中的数据看起来像什么的一个例子—</p><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi of"><img src="../Images/3699efd501157843a8e655c2a48ddd20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U7HrIDf7WZqtWETqN6JVUg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">“描述”列中的单个条目。</p></figure><p id="0079" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">接下来，我们将试着看看 20 个最常用的单词，它们既出现在虚假招聘中，也出现在好的招聘广告中。</p><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="3623" class="nz lw it nv b gy oa ob l oc od">import spacy<br/>nlp = spacy.load('en_core_web_lg')<br/>import base64<br/>import string<br/>import re<br/>from collections import Counter<br/>from nltk.corpus import stopwords<br/>stopwords = stopwords.words('english')</span><span id="4802" class="nz lw it nv b gy og ob l oc od">punctuations = string.punctuation</span><span id="e645" class="nz lw it nv b gy og ob l oc od">def cleanup_text(docs, logging = False):<br/>    texts = []<br/>    for doc in docs:<br/>        doc = nlp(doc, disable = ['parser', 'ner'])<br/>        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']<br/>        tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]<br/>        tokens = ' '.join(tokens)<br/>        texts.append(tokens)</span><span id="1a2a" class="nz lw it nv b gy og ob l oc od">return pd.Series(texts)</span></pre><p id="c8eb" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于虚假的招聘信息，</p><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="cef1" class="nz lw it nv b gy oa ob l oc od">Fraud_1 = [text for text in df1[df1['fraudulent'] == 1]['description']]<br/>Fraud_1_clean = cleanup_text(Fraud_1)<br/>Fraud_1_clean = ' '.join(Fraud_1_clean).split()<br/>Fraud_1_counts = Counter(Fraud_1_clean)<br/>Fraud_1_common_words = [word[0] for word in Fraud_1_counts.most_common(20)]<br/>Fraud_1_common_counts = [word[1] for word in Fraud_1_counts.most_common(20)]</span><span id="bb69" class="nz lw it nv b gy og ob l oc od">fig = plt.figure(figsize = (20, 10))<br/>pal = sns.color_palette("cubehelix", 20)<br/>sns.barplot(x = Fraud_1_common_words, y = Fraud_1_common_counts, palette=pal)<br/>plt.title('Most Common Words used in Fake job postings')<br/>plt.ylabel("Frequency of words")<br/>plt.xlabel("Words")<br/>plt.show()</span></pre><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oh"><img src="../Images/558b2316dc0ae216faceeeebd7be4553.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H4s0VAhJgncAV8cI4Hrm9g.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">虚假招聘中的前 20 个词。</p></figure><p id="8e34" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于真实的招聘信息，</p><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="1beb" class="nz lw it nv b gy oa ob l oc od">Fraud_0 = [text for text in df1[df1['fraudulent'] == 0]['description']]<br/>Fraud_0_clean = cleanup_text(Fraud_0)<br/>Fraud_0_clean = ' '.join(Fraud_0_clean).split()<br/>Fraud_0_counts = Counter(Fraud_0_clean)<br/>Fraud_0_common_words = [word[0] for word in Fraud_0_counts.most_common(20)]<br/>Fraud_0_common_counts = [word[1] for word in Fraud_0_counts.most_common(20)]</span><span id="fbd8" class="nz lw it nv b gy og ob l oc od">fig = plt.figure(figsize = (20, 10))<br/>pal = sns.color_palette("cubehelix", 20)<br/>sns.barplot(x = Fraud_0_common_words, y = Fraud_0_common_counts, palette=pal)<br/>plt.title('Most Common Words used in Genuine job postings')<br/>plt.ylabel("Frequency of words")<br/>plt.xlabel("Words")<br/>plt.show()</span></pre><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oh"><img src="../Images/407b9f2869a41d998315aa1f20395301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CeLTrUYdoBCtJV9-GIEeYw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">真实招聘启事中的前 20 个单词。</p></figure><p id="df95" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在上面的两个图中，最常用的词几乎是一样的，很难区分两者。因此，变量“描述”本身不能帮助我们预测，因此完整的变量集是有意义的。更值得一提的是，当一个人在互联网上看到招聘信息时，我在“数据清理”部分提到的这些附加功能并没有直接提供。这些变量仅在职位发布被举报为欺诈后获得。在这种情况下，当务之急是，如果发现这种虚假招聘，他们必须通知有关当局以及他们网络中的其他求职者。</p><h1 id="bacb" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">将数据分为训练和测试</h1><p id="b974" class="pw-post-body-paragraph kf kg it kh b ki mv kk kl km mw ko kp kq nj ks kt ku nk kw kx ky nl la lb lc im bi translated">在分割数据之前，我们需要对数据做一些最后的修改，之后我们将分割数据。必须将<em class="oi">‘description’</em>列清理成令牌。这是在<em class="oi">空间</em>和<em class="oi"> nltk </em>库的帮助下完成的。在下面这段代码中，'<em class="oi"> description' </em>'列已经被转换成标记，这些标记已经被用来使用 sklearn 的 CountVectorizer 创建一个热列。此外，类似于<em class="oi">‘就业类型’，‘必需教育’，‘必需经验’，‘行业’，</em>和’<em class="oi">功能’</em>的分类列已经被转换成一个热点向量。</p><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="c14e" class="nz lw it nv b gy oa ob l oc od">STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))<br/>SYMBOLS = " ".join(string.punctuation).split(" ")</span><span id="37de" class="nz lw it nv b gy og ob l oc od">def tokenizetext(sample):<br/>    text = sample.strip().replace("\n", " ").replace("\r", " ")<br/>    text = text.lower()<br/>    tokens = parser(text)<br/>    lemmas = []<br/>    for tok in tokens:<br/>        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != "-PRON-" else tok.lower_)<br/>    tokens = lemmas<br/>    tokens = [tok for tok in tokens if tok not in STOPLIST]<br/>    tokens = [tok for tok in tokens if tok not in SYMBOLS]<br/>    return tokens</span><span id="2413" class="nz lw it nv b gy og ob l oc od">vectorizer = CountVectorizer(tokenizer = tokenizetext, ngram_range = (1,3), min_df = 0.06)<br/>vectorizer_features = vectorizer.fit_transform(df1['description'])</span><span id="114e" class="nz lw it nv b gy og ob l oc od">vectorized_df = pd.DataFrame(vectorizer_features.todense(), columns = vectorizer.get_feature_names())<br/>df_final = pd.concat([df1, vectorized_df], axis = 1)</span><span id="d3ef" class="nz lw it nv b gy og ob l oc od">df_final.drop('description', axis = 1, inplace = True)<br/>df_final.dropna(inplace=True)</span><span id="eaee" class="nz lw it nv b gy og ob l oc od">columns_to_1_hot = ['employment_type', 'required_experience', 'required_education', 'industry', 'function']</span><span id="49ed" class="nz lw it nv b gy og ob l oc od">for column in columns_to_1_hot:<br/>    encoded = pd.get_dummies(df_final[column])<br/>    df_final = pd.concat([df_final, encoded], axis = 1)</span><span id="8495" class="nz lw it nv b gy og ob l oc od">columns_to_1_hot += ['title', 'city', 'country_name']<br/>df_final.drop(columns_to_1_hot, axis = 1, inplace = True)</span></pre><p id="7480" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">接下来，我们把数据分成训练和测试两部分—</p><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="8d8e" class="nz lw it nv b gy oa ob l oc od">target = df_vectorized['fraudulent']<br/>features = df_vectorized.drop('fraudulent', axis = 1)</span><span id="ebd5" class="nz lw it nv b gy og ob l oc od">X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.1, stratify = target, random_state=42)</span><span id="68d8" class="nz lw it nv b gy og ob l oc od">print (X_train.shape)<br/>print (y_train.shape)<br/>print (X_test.shape)<br/>print (y_test.shape)</span></pre><p id="c6af" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们得到以下输出—</p><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="413a" class="nz lw it nv b gy oa ob l oc od">(10144, 857)<br/>(10144,)<br/>(1128, 857)<br/>(1128,)</span></pre><p id="2745" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们现在万事俱备了。先说机器学习吧！</p><h1 id="c188" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">机器学习算法</h1><p id="c32d" class="pw-post-body-paragraph kf kg it kh b ki mv kk kl km mw ko kp kq nj ks kt ku nk kw kx ky nl la lb lc im bi translated">我们将在后续章节中使用的库—</p><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="3088" class="nz lw it nv b gy oa ob l oc od">from sklearn.model_selection import GridSearchCV</span><span id="ca85" class="nz lw it nv b gy og ob l oc od">from sklearn.linear_model import LogisticRegression<br/>from sklearn.neighbors import KNearestNeighbors<br/>from sklearn.svm import SVC<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.neural_network import MLPClassifier</span><span id="58d9" class="nz lw it nv b gy og ob l oc od">from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score</span></pre><h2 id="0637" class="nz lw it bd lx oj ok dn mb ol om dp mf kq on oo mj ku op oq mn ky or os mr ot bi translated">1.逻辑回归</h2><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="9ead" class="nz lw it nv b gy oa ob l oc od">log_reg = LogisticRegression()<br/>c_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]<br/>penalty_options = ['l1', 'l2']</span><span id="f1cc" class="nz lw it nv b gy og ob l oc od">param_grid = dict(C = c_values, penalty = penalty_options)</span><span id="0a4b" class="nz lw it nv b gy og ob l oc od">grid_tfidf = GridSearchCV(log_reg, param_grid = param_grid, cv = 10, scoring = 'roc_auc', n_jobs = -1, verbose=1)</span><span id="5305" class="nz lw it nv b gy og ob l oc od">grid.fit(X_train, y_train)</span><span id="1567" class="nz lw it nv b gy og ob l oc od">log_reg_pred = grid.predict(X_test)</span><span id="26b4" class="nz lw it nv b gy og ob l oc od">print (roc_auc_score(y_test, log_reg_pred))<br/>print (classification_report(y_test, log_reg_pred))</span></pre><p id="73e2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们得到以下结果—样本 roc_auc 得分= 0.7795，对于分类报告，我们得到—</p><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/eddbe1472c796af86d55add0c02adff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*-Pu0ic8lv8FNgsC-Bxm8yA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">逻辑回归的样本外结果。</p></figure><p id="d019" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">用最基本的模型进行预测，逻辑回归，给我们一个 0.7795 的 ROC-AUC 分数，考虑到数据的不平衡，这是一个很好的分数。在随后的章节中，我们将看到更复杂的模型。</p><h2 id="a9eb" class="nz lw it bd lx oj ok dn mb ol om dp mf kq on oo mj ku op oq mn ky or os mr ot bi translated">2.k-最近邻(KNN)</h2><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="2140" class="nz lw it nv b gy oa ob l oc od">knn = KNeighborsClassifier()<br/>k_range = list(np.arange(2, 23, 2))<br/>param_grid_knn = dict(n_neighbors = k_range)<br/>print (param_grid_knn)</span><span id="6886" class="nz lw it nv b gy og ob l oc od">grid_knn = GridSearchCV(knn, param_grid_knn, cv = 10, scoring = 'roc_auc', n_jobs = -1, verbose = 1)</span><span id="fa0f" class="nz lw it nv b gy og ob l oc od">grid_knn.fit(X_train, y_train)</span><span id="ca91" class="nz lw it nv b gy og ob l oc od">knn_pred = grid_knn.predict(X_test)</span><span id="8cd4" class="nz lw it nv b gy og ob l oc od">print (roc_auc_score(y_test, knn_pred))<br/>print (classification_report(y_test, knn_pred))</span></pre><p id="4f24" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">KNN 的样本外 ROC-AUC 得分为 0.5995。对于分类报告，我们得到—</p><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/d38987c63471cf670d273bb5a07dbe63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*PP-7xPF8NvQ9-uC2A92Kpg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">KNN 的样本结果。</p></figure><p id="bb72" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">从左图中，我们可以看到，与逻辑回归相比，KNN 的表现非常差。</p><h2 id="468e" class="nz lw it bd lx oj ok dn mb ol om dp mf kq on oo mj ku op oq mn ky or os mr ot bi translated">3.支持向量机(SVM)</h2><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="fd7a" class="nz lw it nv b gy oa ob l oc od">svc = SVC()<br/>kernel = ['linear', 'rbf']<br/>param_grid_knn = dict(kernel = kernel)<br/>print (param_grid_knn)</span><span id="7f09" class="nz lw it nv b gy og ob l oc od">grid_svc = GridSearchCV(svc, param_grid_knn, cv = 10, scoring = 'roc_auc', n_jobs = -1, verbose = 2)</span><span id="927e" class="nz lw it nv b gy og ob l oc od">grid_svc.fit(X_train, y_train)</span><span id="9be2" class="nz lw it nv b gy og ob l oc od">svc_pred = grid_svc.predict(X_test)</span><span id="f408" class="nz lw it nv b gy og ob l oc od">print (roc_auc_score(y_test, svc_pred))<br/>print (classification_report(y_test, svc_pred))</span></pre><p id="c017" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这里报告的样本外得分为 0.8195 ~ 0.82。分类报告如下—</p><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ow"><img src="../Images/63c6ee5f56916e42cd3899fd8c961834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dfjHTC1prWWZRWilp65IVg.png"/></div></div></figure><p id="be8a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">SVC 以 0.82 的分数获得了迄今为止最好的成绩，这明显优于后两种方法。</p><h2 id="b35c" class="nz lw it bd lx oj ok dn mb ol om dp mf kq on oo mj ku op oq mn ky or os mr ot bi translated">4.随机森林</h2><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="daf9" class="nz lw it nv b gy oa ob l oc od">rf = RandomForestClassifier()<br/>n_estimators_range = [1, 2, 4, 8, 16, 32, 64, 100, 200]<br/>param_grid_rf = dict(n_estimators = n_estimators_range)<br/>grid_rf = GridSearchCV(rf, param_grid_rf, cv = 10, scoring = 'roc_auc', n_jobs = -1, verbose = 1)</span><span id="c393" class="nz lw it nv b gy og ob l oc od">grid_rf.fit(X_train, y_train)<br/>print (grid_rf.best_score_)<br/>print (grid_rf.best_params_)</span><span id="1cc0" class="nz lw it nv b gy og ob l oc od">rf_pred = grid_rf.predict(X_test)<br/>print (roc_auc_score(y_test, rf_pred))<br/>print (classification_report(y_test, rf_pred))</span></pre><p id="42b8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对于随机森林模型，报告的 ROC-AUC 得分为 0.74。分类报告如下—</p><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ox"><img src="../Images/bf81b015edbc969dfbe864b8cdf07850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ogzcdobhvgSWOVZvsKqxpQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">的分类报告</p></figure><p id="813e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">说实话，我预计随机森林的表现会比 SVC 好，但到目前为止，SVC 的结果最好。</p><h2 id="3448" class="nz lw it bd lx oj ok dn mb ol om dp mf kq on oo mj ku op oq mn ky or os mr ot bi translated">5.Sklearn 的神经网络 MLP 分类器(solver = 'sgd ')</h2><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="190b" class="nz lw it nv b gy oa ob l oc od">mlp = MLPClassifier(solver = 'sgd', activation = 'relu', hidden_layer_sizes = (100, 50, 30), max_iter = 1000)<br/>mlp.fit(X_train, y_train)</span><span id="3425" class="nz lw it nv b gy og ob l oc od">mlp_pred = mlp.predict(X_test)</span><span id="c8f8" class="nz lw it nv b gy og ob l oc od">print (roc_auc_score(y_test, mlp_pred))<br/>print (classification_report(y_test, mlp_pred))</span></pre><p id="fa94" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这种情况下，ROC-AUC 得分为 0.7786。分类报告—</p><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/4f00cf1ffd5fb4ff41b7a9916551b0f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*Vt4cSseg3wwNrfeoh6EGDw.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">MLP 分类器的分类报告(solver = 'sgd ')</p></figure><p id="9aa3" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">带有“sgd”解算器的 MLP 分类器的性能略好于随机森林模型，但仍比 SVC 报告的要差。</p><h2 id="826a" class="nz lw it bd lx oj ok dn mb ol om dp mf kq on oo mj ku op oq mn ky or os mr ot bi translated">6.Sklearn 的神经网络 MLP 分类器(solver = 'adam ')</h2><pre class="nq nr ns nt gt nu nv nw nx aw ny bi"><span id="615d" class="nz lw it nv b gy oa ob l oc od">mlp = MLPClassifier(solver = 'adam', activation = 'relu', hidden_layer_sizes = (100, 50, 30), max_iter = 1000)<br/>mlp.fit(X_train, y_train)</span><span id="71d7" class="nz lw it nv b gy og ob l oc od">mlp_pred = mlp.predict(X_test)</span><span id="71be" class="nz lw it nv b gy og ob l oc od">print (roc_auc_score(y_test, mlp_pred))<br/>print (classification_report(y_test, mlp_pred))</span></pre><p id="d397" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">该模型的样本外 ROC-AUC 值为 0.8595 ~ 0.86。分类报告如下—</p><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oy"><img src="../Images/07ec0d6a6d381d18d6b04e47f2bb13ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*msVd_hzZUYSUr0FPv7vP8Q.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">MLP 分类器的分类报告(求解器= 'adam ')</p></figure><p id="6c24" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这是迄今为止报道的最高分，基于这个模型，我们将能够在 86%的情况下正确预测招聘信息是否是假的。</p><h1 id="2a9c" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">模型比较</h1><figure class="nq nr ns nt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oz"><img src="../Images/2dc13826fd8760a7b3bbf34c4d2bcf2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7cfxubTrC3LnYmkRuHCfsg.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">所有模型之间的比较。</p></figure><p id="259f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">从上图中，我们可以看到 Sklearn 基于神经网络的 MLP 分类器与'<em class="oi"> adam' </em> optimizer 表现最好，其次是同一模型与'<em class="oi">【SGD '</em>解算器和支持向量机分类器。因此，基于 MLP 分类器的样本外性能指标 ROC-AUC 得分，我们可以有把握地说，我们可以在 86%的时间里预测一个职位发布是否是假的。</p><p id="23ad" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这种预测分析对于 LinkedIn 和 Glassdoor 这样的求职网站非常有用，可以帮助他们过滤这种虚假的招聘信息。</p><h1 id="0b1e" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">结论</h1><p id="450a" class="pw-post-body-paragraph kf kg it kh b ki mv kk kl km mw ko kp kq nj ks kt ku nk kw kx ky nl la lb lc im bi translated">目前，我们生活在一个我们谁都没有预料到的时代。冠状病毒不仅给各国带来了突发卫生事件，还加速了即将到来的经济衰退。每天都有许多员工被解雇，对工作的需求远远超过了市场上的职位数量。</p><p id="8e33" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">通过这一系列文章，我试图提出一个正在就业市场蔓延的问题。动荡和混乱是骗子的完美支持者，目前，网络诈骗攻击正在上升。在上一部分，我详细分析了如何区分虚假和真实的招聘信息，以及欺诈性招聘信息的特征。在这一部分中，我提供了一个详细的分析，说明我们如何应用机器学习来预测这种虚假帖子的出现。</p><p id="9f33" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">正如我在这两部分中提到的，作为互联网用户和求职者，我们有责任让当局和我们的网络知道我们是否遇到了这种虚假的招聘信息，而不是任何模型或分析。</p><p id="5abe" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">谢谢你看了这两部分。我希望每个人都有美好的一天&amp;请保持社交距离，这样我们可以更快更有效地度过这样的时光！</p><h1 id="9c4d" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">作者注:</h1><p id="63be" class="pw-post-body-paragraph kf kg it kh b ki mv kk kl km mw ko kp kq nj ks kt ku nk kw kx ky nl la lb lc im bi translated">参与这个项目对我来说是一次很好的学习经历。希望你们都觉得它很有帮助，很有启发性。</p><p id="cf1a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这篇文章的全部代码都在我的 GitHub 存储库中，在 https://github.com/sharad18/Fake_Job_Posting 的<a class="ae nm" href="https://github.com/sharad18/Fake_Job_Posting" rel="noopener ugc nofollow" target="_blank">进行分析。我很想在评论区听到你的反馈。</a></p><p id="87b2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">你也可以在 LinkedIn 上联系我—<a class="ae nm" href="https://www.linkedin.com/in/sharad-jain/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/sharad-jain/</a></p></div></div>    
</body>
</html>