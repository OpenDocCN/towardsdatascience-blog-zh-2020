<html>
<head>
<title>A Practical Approach to Linear Regression in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中线性回归的一种实用方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-5100fe32993a?source=collection_archive---------7-----------------------#2020-05-08">https://towardsdatascience.com/linear-regression-5100fe32993a?source=collection_archive---------7-----------------------#2020-05-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/2518468b8b875cb3957e9e62ad61efbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WLvfCRkTqacFg6en0ZXz5g.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3502288" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>的<a class="ae jd" href="https://pixabay.com/users/Hurca-8968775/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3502288" rel="noopener ugc nofollow" target="_blank">米尔科·格里森迪</a>拍摄</p></figure><div class=""/><div class=""><h2 id="b678" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">线性回归初学者实践指南</h2></div><p id="99a1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在之前的博客文章中，我试图给你一些关于机器学习基础的直觉。在本文中，我们将从我们的第一个机器学习算法开始，那就是线性回归。</p><p id="73f3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们将学习线性回归的数学方面，然后我将尝试阐明一些重要的回归术语，如假设和成本函数，最后我们将通过构建我们自己的回归模型来实施我们所学的内容。</p><h1 id="f962" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">什么是线性回归？</strong></h1><p id="d650" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">回归模型是监督学习模型，通常在要预测的值具有离散或定量性质时使用。使用回归模型的一个最常见的例子是通过训练该地区的房屋销售数据来预测房屋价格。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/7631ce993ce8103e045f1e12efb12301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*MtuQBTW0-XbjA2RrP2z3Kw.gif"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://wiki.cdot.senecacollege.ca/wiki/DPS921/Franky" rel="noopener ugc nofollow" target="_blank"> CDOT维基</a></p></figure><p id="941a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">线性回归模型背后的思想是获得最适合数据的直线。所谓最佳拟合，意思是所有点离回归线的总距离应该是最小的。通常这些点离我们回归线的距离被称为<strong class="kx jh">误差</strong>，尽管从技术上来说并不是。我们知道直线方程的形式是:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/fcb7c68db0c15d32a12a20937ebab00e.png" data-original-src="https://miro.medium.com/v2/resize:fit:242/format:webp/1*IYyY2xbZm4rFG7eXNQQ3BA.jpeg"/></div></figure><p id="3ee4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中y是<strong class="kx jh">因变量</strong>，x是<strong class="kx jh">自变量</strong>，m是直线的<strong class="kx jh">斜率</strong>，c是<strong class="kx jh">系数</strong>(或y截距)。这里，y被认为是因变量，因为它的值取决于自变量和其他参数的值。</p><p id="27aa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该方程是任何线性回归问题的基础，并被称为线性回归的<strong class="kx jh">假设函数</strong>。大多数机器学习算法的目标是构建一个模型，即一个假设，以根据我们的自变量估计因变量。</p><p id="346b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个假设将我们的输入映射到输出<em class="mu">。</em>线性回归的<strong class="kx jh">假设通常表示为:</strong></p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/bfc15d6117238d8faeee81c5ceb59913.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/1*731V103P9Qg1rWZ1CaZw-A.jpeg"/></div></figure><p id="d3ba" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上面提到的表达式中，<strong class="kx jh"> hθ(x) </strong>是我们的<strong class="kx jh">假设，θ0 </strong>是<strong class="kx jh">截距</strong>，而<strong class="kx jh"> θ1 </strong>是模型的<strong class="kx jh">系数</strong>。</p><h1 id="599e" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">了解成本函数</strong></h1><p id="2ffa" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated"><strong class="kx jh">成本函数</strong>用于计算模型的执行情况。通俗地说，代价函数就是所有误差的总和。在构建我们的ML模型时，我们的目标是<strong class="kx jh">最小化</strong>成本函数。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/9c837524dd3ce9b17aec0b600c110dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/1*czOIw4al_ozJTPRUwdiKWA.gif"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.jmp.com%2Fen_us%2Fstatistics-knowledge-portal%2Fwhat-is-multiple-regression%2Ffitting-multiple-regression-model.html&amp;psig=AOvVaw2uLZfXPongP6_iuZEKxaUh&amp;ust=1605340763037000&amp;source=images&amp;cd=vfe&amp;ved=0CAMQjB1qFwoTCLiE5M2G_-wCFQAAAAAdAAAAABAg" rel="noopener ugc nofollow" target="_blank">JMP.com</a></p></figure><p id="835d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">回归问题中经常使用的一个常见函数是<strong class="kx jh">均方误差</strong>或<strong class="kx jh"> MSE </strong>，它测量已知值和预测值之间的差异。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/e8ef875882ea87fcbecc55e9990bb4f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*zF3gaLbZCxkZhsyBqYnPJw.jpeg"/></div></figure><p id="0b98" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">事实证明，取上述方程的根是更好的选择，因为这些值不太复杂，因此通常使用<strong class="kx jh">均方根误差</strong>或<strong class="kx jh"> RMSE </strong>。我们还可以使用平均绝对误差等其他参数来评估回归模型。</p><p id="fb80" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">RMSE告诉我们数据点离回归线有多近。现在，我们将通过构建我们自己的线性回归模型来预测房子的价格，从而实现我们到目前为止所学到的知识。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/1eda5129f7849af26054f3e6d1aa4d23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*0lF-0uqguGGjl6ii4qSDNQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">来自<a class="ae jd" href="https://medium.com/datadriveninvestor/basics-of-linear-regression-9b529aeaa0a5" rel="noopener">介质</a>的图像</p></figure><p id="34bd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这里，我将使用Google Colab来构建这个模型。您还可以使用Jupyter笔记本之类的其他ide来玩这个模型。</p><blockquote class="mz na nb"><p id="419b" class="kv kw mu kx b ky kz kh la lb lc kk ld nc lf lg lh nd lj lk ll ne ln lo lp lq ij bi translated"><em class="jg">用于这个线性回归项目的代码可以在</em> <a class="ae jd" href="https://colab.research.google.com/drive/1ikNigGGw8AXEiUM6XUpxgrxkccjHNXX3?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <em class="jg">这里</em> </a> <em class="jg">找到。</em></p></blockquote><h2 id="ca8e" class="nf ls jg bd lt ng nh dn lx ni nj dp mb le nk nl md li nm nn mf lm no np mh nq bi translated"><strong class="ak">第一步:导入库并加载数据</strong></h2><p id="9cd8" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我们的第一步是导入构建模型可能需要的库。没有必要在一个地方导入所有的库。为了开始，我们将进口<strong class="kx jh">熊猫</strong>，<strong class="kx jh"> Numpy </strong>，<strong class="kx jh"> Matplotlib </strong>等。</p><pre class="mp mq mr ms gt nr ns nt nu aw nv bi"><span id="94fc" class="nf ls jg ns b gy nw nx l ny nz"><em class="mu">#Import Required Libraries<br/></em>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="e8e5" class="nf ls jg ns b gy oa nx l ny nz"><em class="mu">#Read the Dataset</em><strong class="ns jh"><em class="mu"><br/></em></strong>df=pd.read_csv('kc_house_data.csv')</span></pre><p id="806d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦这些库被导入，我们的下一步将是获取数据集和加载我们的数据。在加载数据时，需要注意的是文件名应该有它的格式(。csv/。xls)在末尾指定。</p><blockquote class="mz na nb"><p id="3ea0" class="kv kw mu kx b ky kz kh la lb lc kk ld nc lf lg lh nd lj lk ll ne ln lo lp lq ij bi translated"><em class="jg">我用于这个模型的数据可以直接从</em> <a class="ae jd" href="https://drive.google.com/open?id=1GNa5JHDzl16Vk20Zbfz55f7wWqOCCqBO" rel="noopener ugc nofollow" target="_blank"> <em class="jg">这里</em> </a> <em class="jg">下载。</em></p></blockquote><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/82c97cbbe699ff0267efdf95bad90e50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZAK4xp2goNeywPaVffL7Sw.jpeg"/></div></div></figure><p id="ec0c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> CSV文件</strong>最常用于此目的，尽管excel表格也可以使用。唯一的区别是，在使用excel表作为数据集时，我们将不得不使用<strong class="kx jh"> read_excel() </strong>，而不是<strong class="kx jh"> read_csv() </strong>。</p><h2 id="58ba" class="nf ls jg bd lt ng nh dn lx ni nj dp mb le nk nl md li nm nn mf lm no np mh nq bi translated"><strong class="ak">第二步:可视化数据</strong></h2><p id="98de" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">成功加载数据后，我们的下一步是可视化这些数据。数据可视化是数据科学家角色的重要组成部分。建议将数据可视化，以便找出不同参数之间的相关性。</p><pre class="mp mq mr ms gt nr ns nt nu aw nv bi"><span id="93ac" class="nf ls jg ns b gy nw nx l ny nz"><em class="mu">#Visualising the data using heatmap<br/></em>plt.figure()<br/>sns.heatmap(df.corr(),cmap='coolwarm')<br/>plt.show()</span></pre><p id="80a2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Matplotlib 和<strong class="kx jh">search</strong>是优秀的库，可以用来可视化我们在各种不同地块上的数据。</p><h2 id="cc6a" class="nf ls jg bd lt ng nh dn lx ni nj dp mb le nk nl md li nm nn mf lm no np mh nq bi translated">第三步:特征工程</h2><p id="067e" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在可视化我们的数据的同时，我们发现两个参数之间有很强的相关性:<strong class="kx jh"> sqft_living </strong>和<strong class="kx jh"> price </strong>。因此，我们将使用这些参数来构建我们的模型。</p><pre class="mp mq mr ms gt nr ns nt nu aw nv bi"><span id="e9bc" class="nf ls jg ns b gy nw nx l ny nz"><em class="mu">#Selecting the required parameters<br/></em>area = df[‘sqft_living’]<br/>price = df['price']</span><span id="2210" class="nf ls jg ns b gy oa nx l ny nz">x = np.array(area).reshape(-1,1)<br/>y = np.array(price)</span></pre><p id="8bbe" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">更多的参数也可以添加到模型中，尽管这可能会影响其准确性。使用各种特征来预测响应变量结果的模型被称为<strong class="kx jh">多元回归模型</strong>。</p><h2 id="807f" class="nf ls jg bd lt ng nh dn lx ni nj dp mb le nk nl md li nm nn mf lm no np mh nq bi translated"><strong class="ak">第四步:拟合线性回归模型</strong></h2><p id="2810" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">选择所需参数后，下一步是从<strong class="kx jh"> sklearn </strong>库中导入方法<strong class="kx jh"> train_test_split </strong>。这用于将我们的数据分为训练和测试数据。通常70–80%的数据作为训练数据集，而剩余的数据构成测试数据集。</p><pre class="mp mq mr ms gt nr ns nt nu aw nv bi"><span id="afee" class="nf ls jg ns b gy nw nx l ny nz"><em class="mu">#Import LinearRegression and split the data into training and testing dataset<br/></em>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 0)</span><span id="27a8" class="nf ls jg ns b gy oa nx l ny nz">y_train = y_train.reshape(-1,1)<br/>y_test = y_test.reshape(-1,1)</span><span id="fa4d" class="nf ls jg ns b gy oa nx l ny nz"><em class="mu">#Fit the model over the training dataset<br/></em>from sklearn.linear_model import LinearRegression<br/>model = LinearRegression()<br/>model.fit(X_train,y_train)</span></pre><p id="d996" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在此之后，从<strong class="kx jh">sk learn . model _ selection</strong>导入<strong class="kx jh">线性回归</strong>，并且模型适合训练数据集。我们模型的<strong class="kx jh">截距</strong>和<strong class="kx jh">系数</strong>可以计算如下:</p><pre class="mp mq mr ms gt nr ns nt nu aw nv bi"><span id="b97c" class="nf ls jg ns b gy nw nx l ny nz"><em class="mu">#Calculate intercept and coefficient<br/></em>print(model.intercept_)<br/>print(model.coef_)</span><span id="70b5" class="nf ls jg ns b gy oa nx l ny nz">pred=model.predict(X_test)<br/>predictions = pred.reshape(-1,1)</span><span id="b8c7" class="nf ls jg ns b gy oa nx l ny nz"><em class="mu">#Calculate root mean squared error to evaluate model performance<br/></em>from sklearn.metrics import mean_squared_error<br/>print('MSE : ', mean_squared_error(y_test,predictions)<br/>print('RMSE : ', np.sqrt(mean_squared_error(y_test,predictions)))</span></pre><p id="12f0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以通过找到模型的均方根误差来评估模型的性能。<strong class="kx jh">RMSE越小，模型越好。</strong></p><h1 id="9b06" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">使用梯度下降的线性回归</strong></h1><p id="b5f8" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">梯度下降是一种<strong class="kx jh">迭代优化算法</strong>寻找一个函数的最小值。为了理解这个算法，想象一个没有方向感的人想要到达谷底。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oc"><img src="../Images/6c613787cc153ae597278dd82c63878c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*7RRX6mmspiM6wKi6hMWTcw.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="https://medium.com/@dhairyakumar10?source=post_page-----63c618cdddaf--------------------------------" rel="noopener">达里亚·库马尔</a>在<a class="ae jd" href="https://medium.com/@dhairyakumar10/linear-regression-with-gradient-descent-63c618cdddaf" rel="noopener">媒体</a>上拍摄</p></figure><p id="f9bf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">他走下斜坡，在斜坡陡的时候迈大步，在斜坡不那么陡的时候迈小步。他根据当前位置决定下一个位置，当他到达他的目标山谷底部时停下来。梯度下降也是如此。</p><pre class="mp mq mr ms gt nr ns nt nu aw nv bi"><span id="91d7" class="nf ls jg ns b gy nw nx l ny nz"><em class="mu">#Initializing the variables<br/></em>m = 0<br/>c = 0<br/>L = 0.001<br/>epochs = 100</span><span id="0e5b" class="nf ls jg ns b gy oa nx l ny nz">n = float(len(x))</span></pre><p id="e64c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">梯度下降法逐步应用于我们的m和c。最初让m = 0，c = 0。设L为我们的<strong class="kx jh">学习率</strong>。这控制了m值随每步变化的程度。</p><pre class="mp mq mr ms gt nr ns nt nu aw nv bi"><span id="e5f1" class="nf ls jg ns b gy nw nx l ny nz">for i in range(epochs):<br/>    Y_pred=m*x+c<br/>    Dm = (-2/n)*sum(x*(y-Y_pred))<br/>    Dc = (-2/n)*sum(y-Y_pred)<br/>    m = m-L*Dm<br/>    c = c-L*Dc<br/>print(m,c)</span><span id="764f" class="nf ls jg ns b gy oa nx l ny nz"><em class="mu">#Predicting the values<br/></em>y_pred = df['sqft_living'].apply(lambda a:c+m*a)<br/>y_pred.head()</span></pre><p id="d088" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">优选地，L被赋予一个小的值，以便提高精度。我们的下一步是计算损失函数相对于m和c的偏导数。一旦完成，我们<strong class="kx jh">更新c和m </strong>的值，并重复该过程，直到我们的损失函数非常小。</p><p id="db1a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">至此，我们已经到了这篇文章的结尾。我希望这篇文章能帮助你了解线性回归算法背后的思想。如果你有任何问题，或者如果你认为我犯了任何错误，请联系我！可以通过:<a class="ae jd" href="http://rajashwin812@gmail.com/" rel="noopener ugc nofollow" target="_blank">邮箱</a>或<a class="ae jd" href="http://linkedin.com/in/rajashwin/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>与我联系。</p></div></div>    
</body>
</html>