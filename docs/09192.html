<html>
<head>
<title>Meme Vision: the science of classifying memes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">迷因视觉:对迷因进行分类的科学</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/meme-vision-framework-e90a9a7a4187?source=collection_archive---------36-----------------------#2020-07-01">https://towardsdatascience.com/meme-vision-framework-e90a9a7a4187?source=collection_archive---------36-----------------------#2020-07-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2274" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">图像识别并不总是需要神经网络；使用更简单的模型可以实现效率和准确性</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a614f5dbc8a9a4648e0cc3fc066172c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DmEXdJf-z7C4QztCCfcLLg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">以电视节目中的角色为特色的迷因，在<a class="ae ky" href="https://www.copyright.gov/title17/92chap1.html#107" rel="noopener ugc nofollow" target="_blank">公平使用原则</a>下，出于教学目的在此复制是允许的</p></figure><p id="898b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一个文化和科学的人，我决定建立一个识别迷因的模型。这个问题比<a class="ae ky" href="http://image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank">图像网</a>竞赛简单得多，因此一个更简单的解决方案是合适的。我将通过比较“Meme Vision”框架和<a class="ae ky" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">ResNet-50</a>(2015 年 Image-Net 的获胜者)来证明这一点。</p><h2 id="704f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">方法:模因愿景框架</h2><p id="e7cd" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在以前的文章中，我解释了径向直方图方法；</p><div class="mt mu gp gr mv mw"><a rel="noopener follow" target="_blank" href="/radial-color-histograms-a3ab0441516"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd iu gy z fp nb fr fs nc fu fw is bi translated">径向颜色直方图</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">当颜色、构图和计算对你的计算机视觉问题都很重要时——径向减少表示…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">towardsdatascience.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk ks mw"/></div></div></a></div><p id="b42c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(TL；DR —它测量图像每个部分的颜色分布)</p><p id="45c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面我们来看看这是如何将图像缩小到非常低的维度的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/8eb026c049f4cb91a216f98758e1d39b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WbVpCRa7RZwMCTYtPMhCWA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基本径向颜色直方图示例，每个颜色通道有 3 个面元和 4 个段(给出 4*3 =108 个特征)</p></figure><p id="cc38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终的迷因愿景模型使用了几个额外的步骤:</p><ul class=""><li id="9983" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated">从 RGB 转换到 HSV-当在 HSV 调色板中查看时，颜色退化对计算机来说不是问题。</li><li id="9f90" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">像素计数的对数转换有助于关注细微差异。</li><li id="c539" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">每个通道使用 8 个箱(而不是 3 个)来区分相似的颜色阴影，这将产生 2048 个特征(而不是 108 个)。</li><li id="920d" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">将这些特征馈入线性<a class="ae ky" href="https://en.wikipedia.org/wiki/Support_vector_machine" rel="noopener ugc nofollow" target="_blank">支持向量机</a>。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">如何制作和测试你自己的 MemeVision 模型</p></figure><p id="7d5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用此程序包处理的径向颜色直方图特征<a class="ae ky" href="https://github.com/gmorinan/radialColorHistogram" rel="noopener ugc nofollow" target="_blank">。(下面用于比较的 ResNet-50 传输是使用 Tensorflow </a>实现的<a class="ae ky" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">)。</a></p><h2 id="ca0b" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">结果:Meme Vision vs ResNet-50 转移</h2><p id="98bf" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">将 Meme Vision 的性能与基于 ResNet-50 的神经网络进行比较(仅训练最后一层 80 个时期)。<a class="ae ky" href="https://www.kaggle.com/gmorinan/memes-classified-and-labelled" rel="noopener ugc nofollow" target="_blank">所使用的数据集由 115 个标签下的 5716 个模因组成</a> —我们只使用 20%进行训练，其余的作为测试集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/58bd41157dbd7f334f38d64b15051ed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*OKYr8gvWakImuoO8K8m_zg.png"/></div></figure><p id="51dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">毫不奇怪，在迷因愿景框架下，训练和预测的速度要快几个数量级。准确性的差异并不重要，如果让神经系统训练更长时间，它肯定会胜过迷因视觉。</p><p id="68b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集:</p><div class="mt mu gp gr mv mw"><a href="https://www.kaggle.com/gmorinan/memes-classified-and-labelled" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd iu gy z fp nb fr fs nc fu fw is bi translated">迷因的分类和标签</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">从 Reddit 抓取图像和元数据，然后使用图像识别进行分类</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">www.kaggle.com</p></div></div><div class="nf l"><div class="od l nh ni nj nf nk ks mw"/></div></div></a></div><h2 id="72af" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">结论:重点是什么？</h2><p id="044e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">首先，如果你在一年时间里从 Reddit 抓取了 40 万张图片(像我一样)，然后使用 meme Vision 模型对每个 Meme 进行分类(像我一样)，然后交叉引用与每个图片相关的元数据(像我一样)，那么你就能够计算出每个 Meme 随着时间推移的相对受欢迎程度(见下文)。我的下一篇文章将更深入地研究这种迷因流行度分析的结果，以及一个具有重大文化意义的惊人发现。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/c6dc30f216b911d852df5003c6212871.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OLgZW9X2kNBaESsMHiXPiA.png"/></div></div></figure><p id="c212" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其次，也是这篇文章的重点，如果我开始使用一个更复杂的模型，我所做的事情会更难。不可否认，在一些困难的边缘情况下，需要一个神经网络来识别一个迷因(例如，迷因被转换成黑白的)。但迷因愿景的要点是速度——它可以用来快速采摘所有低垂的果实，将困难的案例留给更强大、更昂贵的模型。</p><p id="5729" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以下次你遇到问题时，你的第一个想法是考虑<a class="ae ky" href="https://arxiv.org/abs/1710.09829" rel="noopener ugc nofollow" target="_blank">实现由<a class="ae ky" href="https://www.utoronto.ca/news/how-u-t-s-godfather-deep-learning-reimagining-ai" rel="noopener ugc nofollow" target="_blank"> Geoffrey Hinton(深度学习的教父)</a>设计的胶囊网络</a>……也许停下来想一想“我的问题真的像 Geoffrey Hinton 正在解决的那样复杂吗？”。</p><p id="342e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oe">这与我在</em> <a class="ae ky" href="https://machinemedicine.com/" rel="noopener ugc nofollow" target="_blank"> <em class="oe">机医科技</em> </a> <em class="oe">的工作无关。</em></p></div></div>    
</body>
</html>