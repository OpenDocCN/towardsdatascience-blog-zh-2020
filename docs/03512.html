<html>
<head>
<title>How to setup a local AWS SageMaker environment for PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何为 PyTorch 设置本地 AWS SageMaker 环境</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-setup-a-local-aws-sagemaker-environment-for-pytorch-d045ada46d61?source=collection_archive---------51-----------------------#2020-04-02">https://towardsdatascience.com/how-to-setup-a-local-aws-sagemaker-environment-for-pytorch-d045ada46d61?source=collection_archive---------51-----------------------#2020-04-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="aa6c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">声明:我是本教程中提到的</em><a class="ae km" href="https://booklet.ai" rel="noopener ugc nofollow" target="_blank"><em class="kl">booklet . ai</em></a><em class="kl">的联合创始人。</em></p><p id="3197" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一名黑客数据科学家，但基本上是合法的 web 开发人员，<strong class="jp ir">我对创建一个 ML 应用程序的过程感到沮丧</strong>(一个触发预测的简单 UI 和一个可公开访问的 API)。创建和迭代一个典型的 web 应用程序的流程感觉就像在一个春日沿着一条低流量、平缓弯曲的乡村道路行驶。ML 应用开发流程？就像学开手动挡的车一样。</p><p id="470c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为什么 ML 应用开发流程这么粗糙？一个重要原因:<strong class="jp ir">没有强调本地发展。我来举例说明。</strong></p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi kn"><img src="../Images/6ba4f4688af74736f2455d1b6f0b142f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ONua2YXjx9OIhK7K.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">我将向您展示如何为部署到 AWS Sagemaker 的 PyTorch 神经网络创建 ML 应用程序。🚀<a class="ae km" href="https://app.booklet.ai/model/pytorch-text-classification" rel="noopener ugc nofollow" target="_blank">试试<a class="ae km" href="https://booklet.ai" rel="noopener ugc nofollow" target="_blank"> Booklet.ai </a>上的 ML web app </a>。</p></figure><h1 id="08d7" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">所以您想将 PyTorch 模型部署到 AWS Sagemaker？</h1><p id="9245" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">您已经构建了一个模型，现在您想要部署它。您偶然发现了<a class="ae km" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank"> AWS Sagemaker </a>登录页面，并看到了这段文字:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi mg"><img src="../Images/52e9dc078c523e7c0554d08f6bf13b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EwVwD3H8kkM5NXF-.png"/></div></div></figure><p id="a5e4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一键部署？在几分钟内将新模型集成到您的应用中？你是数据科学家，不是 web 开发人员，为什么要花时间学习 web 技术呢？这听起来很棒——注册吧！</p><p id="41f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，您搜索“使用 PyTorch 和 Amazon SageMaker ”,并意外发现您的用例:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi mh"><img src="../Images/f91f0d47188205ad1f26e1de43a75ace.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CacGZRqAi8ktIXgW.png"/></div></div></figure><p id="8848" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">完美！您点击链接，在 SageMaker SDK 文档中的<a class="ae km" href="https://sagemaker.readthedocs.io/en/stable/using_pytorch.html#deploy-endpoints-from-model-data" rel="noopener ugc nofollow" target="_blank">部署来自模型数据</a>的端点。只需两个函数调用，您就有了一个部署好的模型！</p><p id="e465" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">…但是接着疼痛开始了:</strong></p><ul class=""><li id="f5ae" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk mn mo mp mq bi translated"><code class="fe mr ms mt mu b">model_data</code>文件格式是什么？您有一个模型文件，但是您也有一些预处理中需要的编码器。你是怎么装的？</li><li id="93cb" class="mi mj iq jp b jq mv ju mw jy mx kc my kg mz kk mn mo mp mq bi translated"><code class="fe mr ms mt mu b">entry_point</code>脚本是做什么的？文档的“从模型数据部署端点”一节没有对此进行描述。</li></ul><p id="240b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">哦好吧。你交叉手指，运行代码，部署，然后<strong class="jp ir">等待大约 10 分钟</strong>过程完成。接下来，您找到一些代码示例，这样您就可以调用<code class="fe mr ms mt mu b">invoke_endpoint()</code>并触发一个预测。这失败了，CloudWatch 日志提到缺少<code class="fe mr ms mt mu b">model_fn()</code>函数，所以您在文档中发现<a class="ae km" href="https://sagemaker.readthedocs.io/en/stable/using_pytorch.html#load-a-model" rel="noopener ugc nofollow" target="_blank">加载了一个模型</a>。你试试这个然后部署。</p><p id="0022" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">…并等待 10 分钟</strong>。你叫<code class="fe mr ms mt mu b">invoke_endpoint()</code>。这次<code class="fe mr ms mt mu b">input_fn()</code>出现错误，好像和预处理有关。原始输入中有字符串 SageMaker 不喜欢这样吗？还是你在<code class="fe mr ms mt mu b">invoke_endpoint()</code>发送了一个畸形的有效载荷？</p><p id="de69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您尝试一些东西，部署，<strong class="jp ir">然后…等待… 10 …分钟</strong>。</p><p id="7658" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">神圣的地狱。这有什么难的！嗯，我写了一些没用的蹩脚代码。当我在笔记本上训练 PyTorch 模型时，这不是问题，因为我可以快速修复我的错误。部署到 SageMaker 是一个不同的故事— <strong class="jp ir">每一个小小的改变都需要漫长的等待</strong>。</p><h1 id="5c76" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">您需要一个本地 SageMaker 环境</h1><p id="01ac" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated"><strong class="jp ir">当你写完这篇文章，那些在 SageMaker 上等待 10 分钟来验证新代码的工作将成为过去！</strong>您将拥有一个在您的计算机上运行的本地 SageMaker 开发环境。您将拥有一个简单的脚本来部署对 Sagemaker 的更改。</p><h1 id="00ca" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">PyTorch + SageMaker 示例</h1><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi na"><img src="../Images/fecef8bbfa3057dd2bf1cececfd4dac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PhuN1-GDcZ6T_QY2.png"/></div></div></figure><p id="eb0e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的起点是一个<a class="ae km" href="https://github.com/itsderek23/lessons/tree/master/notebooks/03_APIs/pt-text-classification" rel="noopener ugc nofollow" target="_blank"> PyTorch 文本分类神经网络</a>我已经从优秀的<a class="ae km" href="https://madewithml.com/" rel="noopener ugc nofollow" target="_blank">用 ML </a>教训 GitHub repo 取得了分叉。我的 fork 添加了一个<code class="fe mr ms mt mu b"><a class="ae km" href="https://github.com/itsderek23/lessons/tree/master/notebooks/03_APIs/pt-text-classification/deploy/sagemaker" rel="noopener ugc nofollow" target="_blank">deploy/sagemaker</a></code>目录，其中包含将模型部署到 local + production SageMaker 环境的逻辑。</p><p id="7e25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这一课也是一个很好的起点，因为它展示了如何使用<a class="ae km" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank"> FastAPI </a>为模型创建 RESTful API。您可以看到用 FastAPI 开发自己的 API 和利用 Sagemaker 之间的区别。</p><h1 id="50f8" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">运行本教程的先决条件</h1><ul class=""><li id="9762" class="mi mj iq jp b jq mb ju mc jy nb kc nc kg nd kk mn mo mp mq bi translated"><strong class="jp ir"> GitHub Repo </strong> —用 SageMaker 更新:<code class="fe mr ms mt mu b">git clone <a class="ae km" href="https://github.com/itsderek23/lessons.git." rel="noopener ugc nofollow" target="_blank">https://github.com/itsderek23/lessons.git</a></code> <a class="ae km" href="https://github.com/itsderek23/lessons.git." rel="noopener ugc nofollow" target="_blank">克隆我用 ML Lessons repo 制作的分叉副本。</a></li><li id="b1d6" class="mi mj iq jp b jq mv ju mw jy mx kc my kg mz kk mn mo mp mq bi translated"><strong class="jp ir">amazonseagemakerfullcaccess IAM 角色</strong> —使用<em class="kl">amazonseagemakerfullcaccess</em>策略创建角色。</li><li id="8de9" class="mi mj iq jp b jq mv ju mw jy mx kc my kg mz kk mn mo mp mq bi translated"><strong class="jp ir">项目设置</strong> —遵循<a class="ae km" href="https://github.com/itsderek23/lessons/tree/master/notebooks/03_APIs/pt-text-classification#set-up" rel="noopener ugc nofollow" target="_blank">自述文件</a>中的设置说明。</li><li id="971a" class="mi mj iq jp b jq mv ju mw jy mx kc my kg mz kk mn mo mp mq bi translated"><strong class="jp ir">训练 PyTorch 型号</strong>——按照<a class="ae km" href="https://github.com/itsderek23/lessons/tree/master/notebooks/03_APIs/pt-text-classification" rel="noopener ugc nofollow" target="_blank">自述</a>中的说明进行。</li></ul><p id="1959" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我引用的命令和文件假定当前目录如下:</p><h1 id="69ab" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">亚马逊 SageMaker 本地模式是如何工作的？</h1><p id="0b28" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">除了在一篇介绍性博客文章中的一些线索之外，我还没有找到关于 SageMaker 本地模式应该如何配置以服务于本地 ML 模型的重点总结。AWS 官方博客文章的重点是培训，而不是托管已经构建好的 PyTorch 模型。这是我拼凑出来的。</p><p id="e6b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SageMaker 本地模式需要三类变更:</p><ol class=""><li id="dcb0" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk ne mo mp mq bi translated"><strong class="jp ir">预构建的 Docker 容器</strong>:在为您的 PyTorch 模型提供服务时，使用 SageMaker 在云中运行的<a class="ae km" href="https://github.com/aws/sagemaker-pytorch-container" rel="noopener ugc nofollow" target="_blank">相同的 Docker 容器</a>。这给了你很高的信心，如果你的模型在本地工作，它也能在生产中工作。</li><li id="ce6b" class="mi mj iq jp b jq mv ju mw jy mx kc my kg mz kk ne mo mp mq bi translated"><strong class="jp ir">API 客户端的本地版本</strong>:通常情况下，你使用<code class="fe mr ms mt mu b">botocore.client.SageMaker</code>和<code class="fe mr ms mt mu b">botocore.client.SageMaker Runtime</code>类来使用 Python 中的 SageMaker。为了在本地使用 SageMaker，我们将使用<code class="fe mr ms mt mu b">sagemaker.local.LocalSagemakerClient()</code>和<code class="fe mr ms mt mu b">sagemaker.local.LocalSagemakerRuntimeClient()</code>来代替。</li><li id="d214" class="mi mj iq jp b jq mv ju mw jy mx kc my kg mz kk ne mo mp mq bi translated"><strong class="jp ir">函数参数改变</strong>:我们也改变了几个参数到<code class="fe mr ms mt mu b">PyTorchModel()</code>和<code class="fe mr ms mt mu b">pytorch_model.deploy()</code>。这些变化如下。</li></ol><h1 id="be40" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">Sagemaker 本地的 PyTorchModel()</h1><p id="80df" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">从本地文件加载<code class="fe mr ms mt mu b">model_data</code>。我们不需要上传<code class="fe mr ms mt mu b">model.tar.gz</code>文件并从 S3 桶中加载它。这在测试新代码时要快得多。</p><h1 id="6910" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">用于 Sagemaker 本地的 pytorch_model.deploy()</h1><p id="047c" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">将<code class="fe mr ms mt mu b">instance_type</code>设置为<code class="fe mr ms mt mu b">local</code>，而不是标准的 Sagemaker 实例类型(例如:<code class="fe mr ms mt mu b">ml.t2.medium</code>)。</p><p id="5780" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">为了处理本地环境和生产环境之间的差异，我创建了一个</strong> <code class="fe mr ms mt mu b"><strong class="jp ir">DeployEnv</strong></code> <strong class="jp ir">类，它从</strong> <code class="fe mr ms mt mu b"><strong class="jp ir">deploy/sagemaker/config.yml</strong></code> <strong class="jp ir">加载特定于环境的设置。</strong></p><h1 id="fdb6" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">介绍 DeployEnv 类</h1><p id="df4c" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">因为我们的本地环境需要一组分散的修改，所以我将这些更改封装到一个类中。这意味着我们不必让检查本地或生产环境的<code class="fe mr ms mt mu b">if</code>语句污染我们的脚本。</p><p id="b921" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看看<code class="fe mr ms mt mu b">DeployEnv</code>是如何工作的。</p><p id="95f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，<strong class="jp ir">如果没有指定环境，我们默认为</strong> <code class="fe mr ms mt mu b"><strong class="jp ir">local</strong></code> <strong class="jp ir">环境</strong>。这是你<em class="kl">应该</em>花费大部分时间的地方，因为这里的发展更快。</p><p id="3513" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">加载生产设置通过设置</strong> <code class="fe mr ms mt mu b"><strong class="jp ir">DEPLOY_ENV=production</strong></code> <strong class="jp ir">环境变量</strong>:</p><p id="ab4d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">通过</strong> <code class="fe mr ms mt mu b"><strong class="jp ir">DeployEnv.client()</strong></code> <strong class="jp ir">和</strong> <code class="fe mr ms mt mu b"><strong class="jp ir">DeployEnv.runtime_client()</strong></code> <strong class="jp ir">为您的环境加载正确的 SageMaker API 客户端。</strong></p><p id="bc60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe mr ms mt mu b">local</code>环境 SageMaker 客户端:</p><p id="ff52" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe mr ms mt mu b">production</code>环境 SageMaker 客户端:</p><p id="6f3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">通过</strong> <code class="fe mr ms mt mu b"><strong class="jp ir">DeployEnv.setting()</strong></code>访问特定环境设置。这些使用<code class="fe mr ms mt mu b"><a class="ae km" href="https://github.com/itsderek23/lessons/blob/master/notebooks/03_APIs/pt-text-classification/deploy/sagemaker/config.yml" rel="noopener ugc nofollow" target="_blank">deploy/sagemaker/config.yml</a></code>作为底层数据存储。</p><p id="c136" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，<code class="fe mr ms mt mu b">model_data_path</code>在<code class="fe mr ms mt mu b">local</code>环境中使用一个本地文件:</p><p id="e137" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">…在生产中:</p><p id="e1c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然我们可以访问特定于环境的设置，那么是时候编写与环境无关的部署脚本了。</p><h1 id="3f6d" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">SageMaker PyTorch 模型部署脚本</h1><p id="913c" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">我想用相同的脚本将 PyTorch 模型部署到我的本地和生产环境中。</p><p id="330e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">部署到本地环境:</strong></p><p id="5256" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本地部署需要多长时间？这是第一行和最后一行日志:</p><p id="7d13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 23 秒！</strong>或者，比部署到 AWS SageMaker 生产环境快 26 倍。这使得 ML 应用程序的迭代速度大大加快。注意，第一次本地部署将花费更长时间，因为 SageMaker 需要下载 PyTorch Docker 映像。</p><p id="3c7c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">部署到生产环境:</strong><strong class="jp ir"/><code class="fe mr ms mt mu b"><a class="ae km" href="https://github.com/itsderek23/lessons/blob/master/notebooks/03_APIs/pt-text-classification/deploy/sagemaker/deploy.py" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">deploy/sagemaker/deploy.py</strong></a></code><strong class="jp ir">如何处理两种环境？</strong></p><p id="d6ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们只是使用上面的<code class="fe mr ms mt mu b">DeployEnv</code>类。例如:</p><p id="cefa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">了解 Booklet.ai 的最新动态，并率先访问我们的测试版。</p><p id="d550" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个<code class="fe mr ms mt mu b">deploy/sagemaker/serve.py</code>文件是什么？</p><h1 id="2529" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">在 Sagemaker 中加载和服务我们的 PyTorch 模型</h1><p id="a725" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated"><a class="ae km" href="https://sagemaker.readthedocs.io/en/stable/using_pytorch.html#the-sagemaker-pytorch-model-server" rel="noopener ugc nofollow" target="_blank"> SageMaker PyTorch 模型服务器</a>允许我们配置模型如何加载和服务(前/后处理和预测流程)。这可能需要做一些工作来适应现有的模型(这就是创建本地环境的原因)。</p><p id="6869" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe mr ms mt mu b"><a class="ae km" href="https://github.com/itsderek23/lessons/blob/master/notebooks/03_APIs/pt-text-classification/deploy/sagemaker/serve.py" rel="noopener ugc nofollow" target="_blank">deploy/sagemaker/serve.py</a></code>封装了加载和服务我们的文本分类神经网络模型的逻辑。下面是我如何调整<code class="fe mr ms mt mu b">model_fn</code>、<code class="fe mr ms mt mu b">input_fn</code>和<code class="fe mr ms mt mu b">predict_fn</code>来适应现有的模型。</p><h1 id="b40c" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">型号 _fn</h1><p id="f560" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated"><a class="ae km" href="https://sagemaker.readthedocs.io/en/stable/using_pytorch.html#load-a-model" rel="noopener ugc nofollow" target="_blank"> model_fn </a>告诉 SageMaker 如何从磁盘加载模型。此功能是必需的。<strong class="jp ir">我猜 SageMaker 创建了一个加载模型的专用函数，这样模型只能在启动时加载，而不是在每次 API 调用时加载。从磁盘反序列化模型很慢。</strong></p><p id="9ae4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，为了不重构这个应用程序现有的<code class="fe mr ms mt mu b">Predict</code>类，我将<code class="fe mr ms mt mu b">model_fn</code>设为空操作。<code class="fe mr ms mt mu b">Predict.predict()</code>很好地封装了前/后处理、加载模型和预测。我更喜欢重复使用这个。<strong class="jp ir">如果这是一个频繁使用的 API，我会将模型加载转移到一个专用的调用</strong>，这样它只在启动时执行。</p><p id="24af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">代码如下:</p><h1 id="f12b" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">输入 _fn</h1><p id="99ed" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">SageMaker 使用一个专用函数<code class="fe mr ms mt mu b">input_fn</code>来处理<a class="ae km" href="https://sagemaker.readthedocs.io/en/stable/using_pytorch.html#process-model-input" rel="noopener ugc nofollow" target="_blank">预处理数据</a>。有一个默认的反序列化单个 JSON 列表的函数。然而，如果你仔细观察，你会发现文档提到列表被转换成了一个<code class="fe mr ms mt mu b">torch.Tensor</code>，所以它不能处理<code class="fe mr ms mt mu b">string</code>对象的列表(这就是我们所拥有的)。这是因为<a class="ae km" href="https://github.com/aws/sagemaker-pytorch-serving-container/blob/master/src/sagemaker_pytorch_serving_container/default_inference_handler.py#L49" rel="noopener ugc nofollow" target="_blank">默认实现</a>在我们的输入上调用<code class="fe mr ms mt mu b">torch.from_numpy()</code>。<code class="fe mr ms mt mu b">from_numpy</code>不喜欢串串。</p><p id="7e3f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是习俗<code class="fe mr ms mt mu b">input_fn</code>:</p><p id="1733" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">重要</strong>:我想确认默认的 SageMaker PyTorch JSON 格式(单个 JSON 列表)，这样我就可以把模型钩到<a class="ae km" href="https://booklet.ai" rel="noopener ugc nofollow" target="_blank"> Booklet.ai </a>里，免费得到一个 web app UI + public API。<strong class="jp ir"> Booklet.ai 期望 API 模式匹配默认值</strong>。此外，当我几天后忘记 API 模式时，我可能会回到 SageMaker SDK 文档。有通用格式真好。</p><h1 id="3fbf" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">预测 _fn</h1><p id="a9d5" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">因为<code class="fe mr ms mt mu b">Predict.predict()</code>已经做了我们需要的一切，我们只需要在一个定制的<code class="fe mr ms mt mu b">predict_fn</code>函数中调用它。SageMarker 提供了一个默认的<a class="ae km" href="https://sagemaker.readthedocs.io/en/stable/using_pytorch.html#get-predictions-from-a-pytorch-model" rel="noopener ugc nofollow" target="_blank">预测函数</a>，它基本上执行<code class="fe mr ms mt mu b">model_fn().__call__()</code>。但是，我决定不为这个概念验证加载<code class="fe mr ms mt mu b">model_fn()</code>中的模型。</p><p id="8a2f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe mr ms mt mu b">predict</code>函数返回是什么？项目中实际上有一个<code class="fe mr ms mt mu b">predict.py</code>脚本，我们可以执行它来从命令行调用模型。我们会得到相同的输出:</p><h1 id="4d07" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">输出 _fn</h1><p id="d35a" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">我们只返回模型输出，而不是返回<code class="fe mr ms mt mu b">raw_input</code>和<code class="fe mr ms mt mu b">preprocessed_input</code>的键/值。我们可以用一个专用函数来处理这个过程:</p><h1 id="c669" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">测试 PyTorch SageMaker 端点</h1><p id="6aa9" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">我想让验证端点在本地和生产环境中都能工作变得容易。介绍。</p><p id="0c43" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"/><code class="fe mr ms mt mu b"><strong class="jp ir">test.py</strong></code><strong class="jp ir">脚本使用两个输入调用 SageMaker 端点:</strong> <strong class="jp ir">下面是一些输出:</strong></p><p id="b0b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">想要测试您的生产端点吗？你猜对了！只需使用<code class="fe mr ms mt mu b">DEPLOY_ENV=production</code>:</p><h1 id="a8b4" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">回顾我们新的 SageMaker PyTorch 开发流程</h1><p id="ead0" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">下面是工作原理的总结(参见<a class="ae km" href="https://github.com/itsderek23/lessons/tree/master/notebooks/03_APIs/pt-text-classification/deploy/sagemaker" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的脚本):</p><ul class=""><li id="adb2" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk mn mo mp mq bi translated"><strong class="jp ir">特定环境设置</strong> —将这些设置放入<code class="fe mr ms mt mu b">deploy/sagemaker/config.yml</code></li><li id="598e" class="mi mj iq jp b jq mv ju mw jy mx kc my kg mz kk mn mo mp mq bi translated"><strong class="jp ir">展开</strong> : <code class="fe mr ms mt mu b">python deploy/sagemaker/deploy.py</code></li><li id="fd3b" class="mi mj iq jp b jq mv ju mw jy mx kc my kg mz kk mn mo mp mq bi translated"><strong class="jp ir">测试</strong> : <code class="fe mr ms mt mu b">python deploy/sagemaker/test.py</code></li><li id="5f40" class="mi mj iq jp b jq mv ju mw jy mx kc my kg mz kk mn mo mp mq bi translated"><strong class="jp ir">加载和服务模型</strong>:参见<code class="fe mr ms mt mu b">deploy/sagemaker/serve.py</code>中定义的功能。</li></ul><p id="cafe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">默认情况下，所有脚本都使用<code class="fe mr ms mt mu b">local</code>环境。要使用<code class="fe mr ms mt mu b">production</code>，设置<code class="fe mr ms mt mu b">DEPLOY_ENV=production</code>环境变量。例如，要部署到生产环境中:</p><h1 id="0c3e" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">ML web app 呢？</h1><p id="3923" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">我们可以通过 SageMaker SDK 调用模型，这很好，但是做同样事情的 web 应用程序不是更酷吗？</p><p id="5fea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以用 Flask、React、Docker 等等来构建一个网络应用。或者，您可以将<a class="ae km" href="https://booklet.ai" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">booklet . ai</strong></a><strong class="jp ir">与您的 AWS 帐户集成。</strong>事实上，我已经为这个<a class="ae km" href="https://app.booklet.ai/model/pytorch-text-classification" rel="noopener ugc nofollow" target="_blank"> PyTorch 文本分类演示</a>设置了一个 web 应用程序:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi kn"><img src="../Images/d422308d2961b94e901310e07889f409.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PqVnPUP7zWrXEBvr.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated"><a class="ae km" href="https://app.booklet.ai/model/pytorch-text-classification" rel="noopener ugc nofollow" target="_blank">在 Booklet.ai 上试试这款 ML 车型的响应式 ui</a></p></figure><p id="1875" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">已经可以访问 Booklet.ai？<a class="ae km" href="https://booklet.ai/blog/web-app-for-ml-model/" rel="noopener ugc nofollow" target="_blank">遵循我们的 SageMaker 集成说明</a>。<a class="ae km" href="https://booklet.ai" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">还没有访问 Booklet.ai？在 Booklet.ai </strong> </a> <strong class="jp ir">报名提前获取。</strong></p><h1 id="bed0" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">摘要</h1><p id="641f" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">通过使用 SageMaker 本地模式，我们将查看 ML 模型应用程序更改的时间从 10 分钟缩短到了 23 秒。我们可以轻松地在本地或生产中部署变更。我们已经添加了一个响应性的 web ui，通过<a class="ae km" href="https://booket.ai" rel="noopener ugc nofollow" target="_blank"> Booklet.ai </a>使用该模型，而无需构建一个定制的 Flask 应用程序。我们的 ML 应用程序开发流程现在顺畅多了！</p><p id="0f2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae km" href="https://github.com/itsderek23/lessons/tree/master/notebooks/03_APIs/pt-text-classification/deploy/sagemaker" rel="noopener ugc nofollow" target="_blank">在 GitHub </a>上查看本教程的源代码。</p></div><div class="ab cl nf ng hu nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ij ik il im in"><p id="84b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">原载于 2020 年 4 月 2 日</em><a class="ae km" href="https://booklet.ai/blog/aws-sagemaker-pytorch-local-dev-flow/" rel="noopener ugc nofollow" target="_blank"><em class="kl">https://booklet . ai</em></a><em class="kl">。</em></p></div></div>    
</body>
</html>