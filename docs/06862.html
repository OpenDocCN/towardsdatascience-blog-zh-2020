<html>
<head>
<title>Spark Streaming with HTTP REST endpoint serving JSON data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用HTTP REST端点服务JSON数据的Spark流</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-spark-stream-reading-data-from-local-http-server-d37e90e70fb0?source=collection_archive---------13-----------------------#2020-05-28">https://towardsdatascience.com/apache-spark-stream-reading-data-from-local-http-server-d37e90e70fb0?source=collection_archive---------13-----------------------#2020-05-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1609" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用HTTP REST端点作为流源，加速结构化流管道的开发和测试。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fe356e221e5ef0cf87f8d94231333d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gTxXxuubsZw_5DXu"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@lazycreekimages?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">迈克尔·泽兹奇</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="fc7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">编写分布式应用程序可能是一个耗时的过程。虽然在本地机器上运行简单的<code class="fe lv lw lx ly b">spark.range( 0, 10 ).reduce( _ + _ )</code><em class="lz">(Spark的一个“Hello World”示例)</em>代码非常容易，但当您遇到更复杂的真实世界用例时，它最终会变得复杂，特别是在结构化的流世界中，您希望进行流聚合、与其他流或静态数据集连接。</p><blockquote class="ma"><p id="b233" class="mb mc it bd md me mf mg mh mi mj lu dk translated">主要的挑战不仅仅是设置Spark或编写代码，而是在将它推向远程环境之前，在本地机器上有效地测试它。</p></blockquote><p id="3314" class="pw-post-body-paragraph kz la it lb b lc ml ju le lf mm jx lh li mn lk ll lm mo lo lp lq mp ls lt lu im bi translated">编写代码时，在本地机器上处理来自Kinesis、Kafka或S3的流数据可能不可行，原因有很多:1)您没有足够的计算能力。2)您必须从消息队列的“最早”偏移量开始处理数据，但是要处理的数据太多了。即使你有等级限制，也可能需要几个小时来处理数据。</p><p id="0e67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，如何在本地机器上开发生产就绪的spark应用程序呢？常规做法是针对假数据进行开发。<a class="ae ky" href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/spark-sql-streaming-MemoryStream.html" rel="noopener ugc nofollow" target="_blank">内存流</a>和<a class="ae ky" href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/spark-sql-streaming-RateStreamSource.html" rel="noopener ugc nofollow" target="_blank">速率流</a>可以帮助你用一些伪数据复制结构化的流行为。让我们来看看这个单元测试:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="f4b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它只是从JSON文件中读取假数据，并将其添加到内存流中(第18行)。当你写单元或者集成测试时，内存流工作得很好，但是你真的不能在一个特别的基础上添加更多的数据，然后看着你的流作业处理它。这使得内存流的交互性有所降低(除非您在REPL环境中运行它)。</p><p id="8295" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果spark在开发期间有某种更具交互性的方式将数据发送到结构化的流管道，那就太好了。这可以节省很多时间。您可以从套接字流式读取数据，但通过TCP套接字作为单个有效负载发送的数据量是有限的(除非您更改操作系统设置)。这可能会变得复杂。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/2f25e865b7e6e599a0cce978a3841c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*GvgrR-wjaF1iD4HNj_V8kA.jpeg"/></div></figure><p id="bb36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是的，这是spark没有内置的东西，实际上，实现非常简单:将一个简单的HTTP web服务器与spark管道集成。服务器可以将有效负载放在MemoryStream上，您的spark应用程序可以从中读取。</p><blockquote class="ma"><p id="57e4" class="mb mc it bd md me mf mg mh mi mj lu dk translated"><strong class="ak"> <em class="mk">注意</em> </strong> <em class="mk">这仅用于本地测试和运行。因为它在底层使用内存流，所以它是不容错的。参考结构化流中的</em> <a class="ae ky" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#fault-tolerance-semantics" rel="noopener ugc nofollow" target="_blank"> <em class="mk">容错语义</em> </a> <em class="mk">。</em></p></blockquote><p id="24da" class="pw-post-body-paragraph kz la it lb b lc ml ju le lf mm jx lh li mn lk ll lm mo lo lp lq mp ls lt lu im bi translated">现在，我们该怎么做呢？您可以在Scala中创建一个简单的HTTP服务器:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">scala中一个简单的HTTP服务器</p></figure><p id="6516" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码创建了一个简单的HTTP服务器，它打印请求负载，并总是将<code class="fe lv lw lx ly b">{ “success" : true }</code>响应发送回客户机。我们可以通过将这个<code class="fe lv lw lx ly b">payload</code>数据放在一个流源(内存流)上，将它流式传输到spark应用程序中。所以，当然，这个服务器必须用spark应用程序启动。</p><p id="dc2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使其可重用并能够创建多个HTTP流源，我们可以将该代码放在一个包装类中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从本地HTTP端点读取数据，并将其放入内存流</p></figure><p id="ffc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建的本地HTTP服务器将被spark应用程序终止。您可以简单地启动服务器，并使用以下命令从HTTP端点读取流数据:</p><pre class="kj kk kl km gt mt ly mu mv aw mw bi"><span id="490c" class="mx my it ly b gy mz na l nb nc">scala&gt; val httpDF = new HttpServerStream( port = 9999 ).toDF<br/>httpDF: org.apache.spark.sql.DataFrame</span><span id="08e6" class="mx my it ly b gy nd na l nb nc"><br/>scala&gt; httpDF.printSchema()<br/>root<br/>|-- value: string (nullable = true)<br/>|-- timestamp: timestamp (nullable = true)</span><span id="0e42" class="mx my it ly b gy nd na l nb nc"><br/>scala&gt; httpDF.isStreaming()<br/>res1: Boolean = true</span></pre><p id="ef6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据帧的<code class="fe lv lw lx ly b">value</code>列是HTTP端点上接收的字符串化JSON有效负载。这里有一个完整的例子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">启动Spark App(主要方法)</p></figure><p id="7b73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您可以使用您喜欢的REST API工具将数据发送到这个HTTP端点<a class="ae ky" href="http://localhost:999/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="lz">HTTP://localhost:999</em></strong></a><strong class="lb iu"><em class="lz">9</em></strong>并观察您的应用程序处理它。</p><h1 id="52c0" class="ne my it bd nf ng nh ni nj nk nl nm nn jz no ka np kc nq kd nr kf ns kg nt nu bi translated">演示和示例代码</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/70f35f841ab8ed44e348f07790ec840b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*L_Ik1CHt2lON2o4c76tcWg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://github.com/cchandurkar/spark-http-streaming" rel="noopener ugc nofollow" target="_blank">https://github.com/cchandurkar/spark-http-streaming</a></p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw mr l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">看看它的实际效果</p></figure><p id="89c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，可以在同一个spark应用程序的不同端口上创建多个HTTP流。让我们以来自<a class="ae ky" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#stream-stream-joins" rel="noopener ugc nofollow" target="_blank">流-流连接</a>的点击流为例。</p><pre class="kj kk kl km gt mt ly mu mv aw mw bi"><span id="ce1f" class="mx my it ly b gy mz na l nb nc">val <!-- -->impressions<!-- --> = new HttpServerStream( port = 9997 ).toDF<br/>   .withColumn( "i", from_json($"value" ..... )<br/>   .select( $"i.<!-- -->impressionAdId<!-- -->", $"i.<!-- -->impressionTime<!-- -->" )<br/>   <!-- -->.withWatermark( "impressionTime", "5 minutes" )</span><span id="d86a" class="mx my it ly b gy nd na l nb nc">val <!-- -->clicks<!-- --> = new HttpServerStream( port = 9998 ).toDF<br/>   .withColumn( "c", from_json($"value" ..... ) )<br/>   .select( $"c.clickAdId", $"c.clickTime" )<br/>   <!-- -->.withWatermark( "<!-- -->clickTime<!-- -->", "10 minutes" )</span><span id="2d97" class="mx my it ly b gy nd na l nb nc">val joinedDF = <!-- -->impressions<!-- -->.join( <br/>   <!-- -->clicks,<br/>   expr("""<br/>     clickAdId = impressionAdId AND<br/>     clickTime &gt;= impressionTime AND<br/>     clickTime &lt;= impressionTime + interval "5 minutes"<br/>   """)<br/>)</span></pre><p id="5b59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi nx translated"><span class="l ny oh bm di oi"> <img alt="G" class="ks oj ok ol om on fc n ih dh bf" src="../Images/454f2977e7c2b6693950bdef678e4e14.png" width="89" height="79" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fit:178/1*4OqQaqJgYH-tFsPU8-nKLw.png"/> <span class="l ny nz oa bm ob oc od oe of di og"> G </span> </span>试试看，让我知道你对此的看法。请随意提出改进建议或指出注意事项。在<a class="ae ky" href="https://www.linkedin.com/in/cchandurkar/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> LinkedIn </strong> </a>上联系我。干杯！</p></div></div>    
</body>
</html>