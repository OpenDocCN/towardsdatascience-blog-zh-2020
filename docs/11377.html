<html>
<head>
<title>Assumptions of Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归的假设</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/assumptions-of-linear-regression-5d87c347140?source=collection_archive---------0-----------------------#2020-08-07">https://towardsdatascience.com/assumptions-of-linear-regression-5d87c347140?source=collection_archive---------0-----------------------#2020-08-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2750" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">以及如何使用 Python 测试它们。</h2></div><p id="d579" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">线性回归是回归模型的自行车。这很简单，但非常有用。它可以用于各种领域。它有一个很好的封闭解，这使得模型训练成为一个超快速的非迭代过程。</p><p id="e8b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">线性回归模型的性能特征已被充分理解，并得到数十年严格研究的支持。该模型的预测很容易理解，很容易解释，也很容易辩护。</p><blockquote class="le"><p id="75dd" class="lf lg it bd lh li lj lk ll lm ln ld dk translated">如果只有一个回归模型，你有时间彻底了解，它应该是线性回归模型。</p></blockquote><p id="7ee6" class="pw-post-body-paragraph ki kj it kk b kl lo ju kn ko lp jx kq kr lq kt ku kv lr kx ky kz ls lb lc ld im bi translated">如果您的数据满足线性回归模型(特别是普通最小二乘回归(OLSR)模型)的假设，在大多数情况下，您不需要做进一步的调查。</p><p id="0cef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就引出了 OLSR 模型的以下四个假设:</p><ol class=""><li id="78ef" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld ly lz ma mb bi translated"><strong class="kk iu">线性函数形式:</strong>响应变量<strong class="kk iu"> <em class="mc"> y </em> </strong>应该是与解释变量<strong class="kk iu"> <em class="mc"> X. </em> </strong>线性相关</li><li id="6676" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated"><strong class="kk iu">残差应为 i.i.d.: </strong>在训练数据集上拟合模型后，模型的残差应为独立同分布的随机变量。</li><li id="cb23" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated"><strong class="kk iu">残差应呈正态分布:</strong>残差应呈正态分布。</li><li id="efc8" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated"><strong class="kk iu">残差应该是同方差的:</strong>残差应该是恒方差的。</li></ol><p id="01d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们详细看看这四个假设，以及如何检验它们。</p><h1 id="37d5" class="mi mj it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">假设 1:线性函数形式</h1><p id="4d93" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">线性几乎不需要解释。毕竟，如果您选择进行线性回归，您就假设基础数据呈现线性关系，特别是以下线性关系:</p><p id="bdae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"><em class="mc">y</em></strong><em class="mc">=</em><strong class="kk iu"><em class="mc">β</em></strong><em class="mc">*</em><strong class="kk iu"><em class="mc">x</em></strong><em class="mc">+</em><strong class="kk iu"><em class="mc">ϵ</em></strong></p><p id="3db9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<strong class="kk iu"> <em class="mc"> y </em> </strong>为因变量向量，<strong class="kk iu"> <em class="mc"> X </em> </strong>为包含截距的解释变量矩阵，<strong class="kk iu"> <em class="mc"> β </em> </strong>为回归系数向量，<strong class="kk iu"><em class="mc"/></strong>为误差项向量，即<strong class="kk iu"> <em class="mc"> y </em> </strong>中的<strong class="kk iu"> <em class="mc"> X </em></strong></p><p id="3768" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">如何使用 Python 测试线性假设</strong></p><p id="3d60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这可以通过两种方式实现:</p><ol class=""><li id="6da1" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld ly lz ma mb bi translated">一种简单的方法是相对于每个解释变量<strong class="kk iu"><em class="mc">【x _ j】</em></strong>绘制<strong class="kk iu"> <em class="mc"> y </em> </strong>，并目视检查散点图的非线性迹象。</li><li id="643d" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">人们还可以使用<em class="mc"> Pandas </em>中的<code class="fe nf ng nh ni b">DataFrame.corr()</code>方法来获得响应变量<strong class="kk iu"><em class="mc"/></strong>和每个解释变量<strong class="kk iu"> <em class="mc"> x_j </em> </strong>之间的皮尔逊相关系数<em class="mc">‘r’</em>，以获得线性相关程度的定量感受。</li></ol><blockquote class="nj nk nl"><p id="10d0" class="ki kj mc kk b kl km ju kn ko kp jx kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated">请注意，只有当<strong class="kk iu"> y </strong>和<strong class="kk iu"> X </strong>之间的关系已知为线性时，才应使用皮尔逊的‘r’。</p></blockquote><p id="cf51" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们对联合循环发电厂的 4 个运行参数的 9568 个观测值的以下数据集进行线性假设测试，这些观测值持续了 6 年时间:</p><figure class="nq nr ns nt gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi np"><img src="../Images/f013fbc5cde642800e107b916d849454.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MzZuohbRr6-dvjwzwpkMNg.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">数据来源:<a class="ae of" href="https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习知识库</a></p></figure><p id="4bfd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">解释变量<strong class="kk iu"> <em class="mc"> x_j </em> </strong>为以下 4 个电厂参数:</p><p id="85ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">环境温度</strong>摄氏度<br/>排气容积水银柱高度<br/>厘米<strong class="kk iu">环境压力</strong>毫巴水银柱<br/>相对湿度百分比</p><p id="135d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">响应变量<strong class="kk iu"> <em class="mc"> y </em> </strong>是电厂的<strong class="kk iu"> Power_Output </strong>，单位 MW。</p><p id="0c27" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们将数据集加载到熊猫数据框架中。</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="dbcc" class="ok mj it ni b gy ol om l on oo"><strong class="ni iu">import </strong>pandas <strong class="ni iu">as </strong>pd<br/><strong class="ni iu">from </strong>patsy <strong class="ni iu">import </strong>dmatrices<br/><strong class="ni iu">from</strong> matplotlib <strong class="ni iu">import</strong> pyplot <strong class="ni iu">as</strong> plt<br/><strong class="ni iu">import</strong> numpy <strong class="ni iu">as</strong> np</span><span id="2a8d" class="ok mj it ni b gy op om l on oo">df = pd.<strong class="ni iu">read_csv</strong>('power_plant_output.csv', <strong class="ni iu">header</strong>=0)</span></pre><p id="1ee8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">绘制每个解释变量相对于响应变量 Power_Output 的散点图。</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="379e" class="ok mj it ni b gy ol om l on oo">df.<strong class="ni iu">plot</strong>.<strong class="ni iu">scatter</strong>(<strong class="ni iu">x</strong>='Ambient_Temp', <strong class="ni iu">y</strong>='Power_Output')<br/>plt.<strong class="ni iu">xlabel</strong>('Ambient_Temp', <strong class="ni iu">fontsize</strong>=18)<br/>plt.<strong class="ni iu">ylabel</strong>('Power_Output', <strong class="ni iu">fontsize</strong>=18)<br/>plt.<strong class="ni iu">show</strong>()</span><span id="2c60" class="ok mj it ni b gy op om l on oo">df.<strong class="ni iu">plot</strong>.<strong class="ni iu">scatter</strong>(<strong class="ni iu">x</strong>='Exhaust_Volume', <strong class="ni iu">y</strong>='Power_Output')<br/>plt.<strong class="ni iu">xlabel</strong>('Exhaust_Volume', <strong class="ni iu">fontsize</strong>=18)<br/>plt.<strong class="ni iu">ylabel</strong>('Power_Output', <strong class="ni iu">fontsize</strong>=18)<br/>plt.<strong class="ni iu">show</strong>()</span><span id="ccc9" class="ok mj it ni b gy op om l on oo">df.<strong class="ni iu">plot</strong>.<strong class="ni iu">scatter</strong>(<strong class="ni iu">x</strong>='Ambient_Pressure', <strong class="ni iu">y</strong>='Power_Output')<br/>plt.<strong class="ni iu">xlabel</strong>('Ambient_Pressure', <strong class="ni iu">fontsize</strong>=18)<br/>plt.<strong class="ni iu">ylabel</strong>('Power_Output', <strong class="ni iu">fontsize</strong>=18)<br/>plt.<strong class="ni iu">show</strong>()</span><span id="d437" class="ok mj it ni b gy op om l on oo">df.<strong class="ni iu">plot</strong>.<strong class="ni iu">scatter</strong>(<strong class="ni iu">x</strong>='Relative_Humidity', <strong class="ni iu">y</strong>='Power_Output')<br/>plt.<strong class="ni iu">xlabel</strong>('Relative_Humidity', <strong class="ni iu">fontsize</strong>=18)<br/>plt.<strong class="ni iu">ylabel</strong>('Power_Output', <strong class="ni iu">fontsize</strong>=18)<br/>plt.<strong class="ni iu">show</strong>()</span></pre><p id="3656" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是四个情节的拼贴画:</p><figure class="nq nr ns nt gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oq"><img src="../Images/743859707d6c7efbf91703cb43cbbefb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*95IjMuVtFpBOKMprf-YeNg.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">每个解释变量的功率输出散点图(图片由<a class="ae of" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="c65a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可以看到，环境温度和排气体积似乎与发电厂的功率输出线性关系最大，其次是环境压力和相对湿度。</p><p id="ed6a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们也打印出皮尔逊的“r”:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="9aab" class="ok mj it ni b gy ol om l on oo">df.corr()['Power_Output']</span></pre><p id="4e4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们得到以下输出，这支持了我们的视觉直觉:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="8061" class="ok mj it ni b gy ol om l on oo">Ambient_Temp        -0.948128<br/>Exhaust_Volume      -0.869780<br/>Ambient_Pressure     0.518429<br/>Relative_Humidity    0.389794<br/>Power_Output         1.000000<br/>Name: Power_Output, dtype: float64</span></pre><blockquote class="nj nk nl"><p id="380b" class="ki kj mc kk b kl km ju kn ko kp jx kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated">相关阅读:<a class="ae of" rel="noopener" target="_blank" href="/the-intuition-behind-correlation-62ca11a3c4a"> <strong class="kk iu">相关性背后的直觉</strong> </a>，对皮尔逊相关系数的深入讲解。</p></blockquote></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><h1 id="1fd0" class="mi mj it bd mk ml oy mn mo mp oz mr ms jz pa ka mu kc pb kd mw kf pc kg my mz bi translated"><strong class="ak">假设 2: i.i.d .残差</strong></h1><p id="659c" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">人们在拟合 OLSR 模型时作出的第二个假设是，模型拟合数据留下的残差是<strong class="kk iu">独立</strong>、<strong class="kk iu">同分布</strong> <strong class="kk iu">随机变量</strong>。</p><p id="d9cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将这一假设分为三部分:</p><ol class=""><li id="bdbf" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld ly lz ma mb bi translated">残差是随机变量，</li><li id="3234" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">它们是<strong class="kk iu">独立的</strong>随机变量，并且</li><li id="9197" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">它们的概率分布是<strong class="kk iu">相同的</strong>。</li></ol><h2 id="4f58" class="ok mj it bd mk pd pe dn mo pf pg dp ms kr ph pi mu kv pj pk mw kz pl pm my pn bi translated"><strong class="ak">为什么残差是随机变量？</strong></h2><p id="47a8" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">在我们对数据集训练线性回归模型之后，如果我们通过相同的模型运行训练数据，该模型将生成预测。姑且称之为<strong class="kk iu"> <em class="mc"> y_pred。</em> </strong>对于向量<strong class="kk iu"> <em class="mc"> y_pred </em> </strong>中的每个预测值<em class="mc"> y_pred </em>，从响应变量向量<strong class="kk iu"> <em class="mc"> y </em> </strong>中都有对应的实际值<em class="mc"> y </em>。差值<em class="mc"> (y — y_pred) </em>为残差'<em class="mc"> ε' </em>。这些<em class="mc"> ε </em>的数量与训练集中的行数一样多，它们一起形成残差向量<strong class="kk iu"> <em class="mc"> ε </em> </strong>。</p><p id="0aaa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每个残差<em class="mc"> ε </em>都是一个<strong class="kk iu">随机变量</strong>。要理解为什么，回想一下我们的训练集<strong class="kk iu"> <em class="mc"> (y_train，X_train) </em> </strong>只是从一些非常大的<em class="mc">值总体</em>中抽取的<em class="mc"> n </em>值的<em class="mc">样本</em>。</p><p id="611d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们从相同的总体中抽取不同的样本<strong class="kk iu"><em class="mc">(y _ train’，X _ train’)</em></strong>，那么模型对第二个样本的拟合会有所不同，从而产生一组不同的预测<strong class="kk iu"><em class="mc">【y _ pred’</em></strong>，并因此产生一组不同的残差<strong class="kk iu"><em class="mc"/></strong><em class="mc">=</em><strong class="kk iu"><em class="mc">【y’—y _ pred’)<em class="mc"/></em></strong></p><p id="7260" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在对模型进行训练之后，从总体中抽取的第三训练样本将会产生第三组残差<strong class="kk iu"><em class="mc">ε=(y″—y _ pred″)、</em> </strong>等等。</p><p id="b6b9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在可以看到，向量<strong class="kk iu"> <em class="mc"> ε </em> </strong> <em class="mc"> </em>中的每个残差可以从与人们愿意用来训练模型的样本训练数据集的数量一样多的值集中取随机值，从而使每个残差<em class="mc"> ε </em> <strong class="kk iu"> <em class="mc"> </em> </strong>成为随机变量。</p><p id="7dbd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">为什么残差需要独立？</strong></p><p id="854d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">两个随机变量是独立的，如果其中一个取某个值的概率不依赖于另一个变量取的值。当你掷一个骰子两次时，它在第二次掷出 1，2，…，6 的概率并不取决于它在第一次掷出的数值。所以这两次投掷是独立的随机变量，可以各自取 1 到 6 的值，与另一次投掷无关。</p><p id="975c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在回归的背景下，我们已经看到了为什么回归模型的残差是随机变量。如果残差不是独立的，它们可能会表现出某种模式(肉眼并不总是很明显)。这种模式中有回归模型在对训练集进行训练时无法捕获的信息，从而使模型达不到最优。</p><p id="c833" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果残差不是独立的，这可能意味着很多事情:</p><ul class=""><li id="f482" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld po lz ma mb bi translated">您的模型中缺少一个或多个重要的解释变量。缺失变量的影响表现为残差中的一种模式。</li><li id="a088" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld po lz ma mb bi translated">你建立的线性模型只是数据集的错误模型。例如，如果数据集显示出明显的非线性，并且您试图在这样的数据集上拟合线性回归模型，那么<strong class="kk iu"> <em class="mc"> y </em> </strong>和<strong class="kk iu"> <em class="mc"> X </em> </strong>之间的非线性关系将以不同模式的形式在回归的残差中表现出来。</li><li id="aee2" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld po lz ma mb bi translated">残差不独立的第三个有趣原因是所谓的<strong class="kk iu">多重共线性</strong>，这意味着解释变量本身彼此线性相关。多重共线性会导致模型的系数变得不稳定，也就是说，当在不同的训练集上进行训练时，它们会从一次训练运行到下一次训练运行之间剧烈波动。这可能会使模型的总体拟合优度统计数据受到质疑。多重共线性(尤其是极端多重共线性)的另一个严重影响是，模型的最小二乘求解器可能会在模型拟合过程中抛出无穷大，从而使模型无法拟合定型数据。</li></ul><p id="be71" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">如何检验残差的独立性？</strong></p><p id="a9c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">核实独立性并不容易。但是有时可以在残差与预测值的<strong class="kk iu">图</strong>或残差与实际值的<strong class="kk iu">图</strong>中检测到模式。</p><p id="637c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一种常用技术是使用<strong class="kk iu">杜宾-沃森测试</strong>，该测试测量每个残差与“先前”残差的相关程度。这就是所谓的<strong class="kk iu">滞后-1 自相关</strong>，这是一种用于确定时间序列回归模型的残差是否独立的有用技术。</p><p id="3c75" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们用一个线性回归模型来拟合电厂数据，并检验回归的残差。</p><p id="f8e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将开始使用 Patsy 库创建模型表达式<a class="ae of" href="https://patsy.readthedocs.io/en/latest/quickstart.html" rel="noopener ugc nofollow" target="_blank">，如下所示:</a></p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="194d" class="ok mj it ni b gy ol om l on oo">model_expr = 'Power_Output ~ Ambient_Temp + Exhaust_Volume + Ambient_Pressure + Relative_Humidity'</span></pre><p id="d0dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在上面的模型表达式中，我们告诉 Patsy，Power_Output 是响应变量，而 Ambient_Temp、Exhaust_Volume、Ambient_Pressure 和相对湿度是解释变量。Patsy 将默认添加回归截距。</p><p id="ee4a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用 patsy 雕刻出如下的<strong class="kk iu"> <em class="mc"> y </em> </strong>和<strong class="kk iu"> <em class="mc"> X </em> </strong>矩阵:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="dddf" class="ok mj it ni b gy ol om l on oo">y, X = <strong class="ni iu">dmatrices</strong>(model_expr, df, <strong class="ni iu">return_type</strong>='dataframe')</span></pre><p id="9d25" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们也划分出训练和测试数据集。训练数据集将是整体大小的 80%(<strong class="kk iu"><em class="mc">y，X </em> </strong>)，其余将是测试数据集:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="1908" class="ok mj it ni b gy ol om l on oo">mask = np.<strong class="ni iu">random</strong>.rand(<strong class="ni iu">len</strong>(X)) &lt; 0.8<br/>X_train = X[mask]<br/>y_train = y[mask]<br/>X_test = X[~mask]<br/>y_test = y[~mask]</span></pre><p id="dfc3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，在训练数据上建立和训练普通最小二乘回归模型，并打印模型摘要:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="16f5" class="ok mj it ni b gy ol om l on oo">olsr_results = linear_model.<strong class="ni iu">OLS</strong>(y_train, X_train).fit()<br/>print(<strong class="ni iu">'Training completed'</strong>)<br/><br/>print(olsr_results.summary())</span></pre><p id="9a7f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们得到以下输出:</p><figure class="nq nr ns nt gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pp"><img src="../Images/8d8fc7049e7ac3c9463877c52792d2ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tFFnDbOno95j8Lj0JQRgRg.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">statsmodels 打印出的 OLS 回归输出(图片由<a class="ae of" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="438d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，让我们获得模型在<strong class="kk iu">测试</strong>数据集上的预测，并获得其预测:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="0ff3" class="ok mj it ni b gy ol om l on oo">olsr_predictions = olsr_results.<strong class="ni iu">get_prediction</strong>(X_test)</span></pre><p id="a683" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe nf ng nh ni b">olsr_predictions </code>是类型<em class="mc">stats models . regression . _ prediction。预测结果</em>和预测可以通过<em class="mc">prediction result . summary _ frame()</em>方法获得:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="c0cc" class="ok mj it ni b gy ol om l on oo">prediction_summary_frame = olsr_predictions.<strong class="ni iu">summary_frame</strong>()<br/>print(prediction_summary_frame)</span></pre><figure class="nq nr ns nt gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pq"><img src="../Images/a5122c1756c260275687961089fed003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*07nP5xjibjfMqXOfddnrlQ.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">模型的预测和 95%的上下置信水平(图片由<a class="ae of" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="2f0d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们来计算回归的残差<strong class="kk iu"><em class="mc">ε</em></strong><em class="mc">=</em><strong class="kk iu"><em class="mc">(y _ test—y _ pred):</em></strong></p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="9996" class="ok mj it ni b gy ol om l on oo">resid = y_test['Power_Output'] - prediction_summary_frame['mean']</span></pre><p id="5315" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，让我们对照预测值<code class="fe nf ng nh ni b">y_pred=prediction_summary_frame[‘mean’]</code>绘制<code class="fe nf ng nh ni b">resid</code> <em class="mc"> </em>:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="eb81" class="ok mj it ni b gy ol om l on oo">plt.xlabel('Predicted Power Output', fontsize=18)<br/>plt.ylabel('Residual Error of Regression', fontsize=18)<br/>plt.scatter(y_test['Power_Output'], resid)<br/>plt.show()</span></pre><p id="b9f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们得到如下的情节:</p><figure class="nq nr ns nt gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pr"><img src="../Images/459665b62bff25d313657224354aa887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ITKi89Q5lRsqodHDOH8BsQ.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">根据模型预测绘制的残差(图片由<a class="ae of" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="980f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可以看出，对于较小的功率输出值，残差或多或少是无模式的，但在功率输出范围的高端，它们似乎显示出线性模式。它表明，在功率输出范围的高端，模型的预测不如在范围的低端可靠。</p><h2 id="0e65" class="ok mj it bd mk pd pe dn mo pf pg dp ms kr ph pi mu kv pj pk mw kz pl pm my pn bi translated"><strong class="ak">为什么残差应该有</strong>相同的分布？</h2><p id="ac7f" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">同分布意味着对应于每个数据行的预测的残差<em class="mc"> ε_i </em>具有相同的概率分布。如果误差分布不一致，就不能可靠地使用显著性检验，如用于回归分析的<a class="ae of" rel="noopener" target="_blank" href="/fisher-test-for-regression-analysis-1e1687867259"> <strong class="kk iu"> F 检验</strong> </a>或对预测进行置信区间检验。这些测试中有许多依赖于残差相等，并且<em class="mc">正态分布</em>。这让我们想到了下一个假设。</p><h1 id="a4af" class="mi mj it bd mk ml mm mn mo mp mq mr ms jz mt ka mu kc mv kd mw kf mx kg my mz bi translated">假设 3:残差应该是正态分布的</h1><p id="a3b3" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">在上一节中，我们看到了如何以及为什么回归的残差被假设为独立的同分布(i.i.d .)随机变量。假设 3 强加了一个额外的约束。这些误差应该都具有均值为零的正态分布。用统计语言来说:</p><blockquote class="le"><p id="2c5d" class="lf lg it bd lh li lj lk ll lm ln ld dk translated">∀ <em class="ps"> i </em> ∈ <em class="ps"> n，ε_i ~ N(0，</em> σ)</p></blockquote><p id="4090" class="pw-post-body-paragraph ki kj it kk b kl lo ju kn ko lp jx kq kr lq kt ku kv lr kx ky kz ls lb lc ld im bi translated">这一符号读作如下:</p><p id="f34f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于长度为<em class="mc"> n </em>行的数据集中的所有<em class="mc"> i </em>，回归的第 I 个残差是一个正态分布的随机变量(这就是为什么用<em class="mc"> N </em>()表示)。这个分布的均值为零，方差为σ。此外，所有的<em class="mc"> ε_i 具有相同的方差σ </em>，即它们是同分布的。</p><p id="2c6d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个常见的误解是，线性回归模型要求解释变量和响应变量呈正态分布。</p><p id="9ff0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="mc"> x_j </em> </strong>和<strong class="kk iu"> <em class="mc"> y </em> </strong>往往甚至不会同分布，更不用说正态分布了。</p><blockquote class="le"><p id="b013" class="lf lg it bd lh li lj lk ll lm ln ld dk translated">在线性回归中，只有回归的残差才需要正态性。</p></blockquote><p id="ffe3" class="pw-post-body-paragraph ki kj it kk b kl lo ju kn ko lp jx kq kr lq kt ku kv lr kx ky kz ls lb lc ld im bi translated">事实上，残差的正态性甚至不是严格要求的。如果残差不是正态分布的，那么你的回归模型不会出现可怕的错误。常态只是一种可取的性质。</p><p id="ddd7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通常告诉你的是，你的模型的大多数预测误差是零或接近零，大误差比小误差少得多。</p><h2 id="cab4" class="ok mj it bd mk pd pe dn mo pf pg dp ms kr ph pi mu kv pj pk mw kz pl pm my pn bi translated"><strong class="ak">如果残差不是<em class="ps"> N(0，σ ) </em>分布会怎么样？</strong></h2><p id="065f" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">如果回归的残差不是<em class="mc"> N(0，σ ) </em>，那么依赖于具有<em class="mc"> N(0，σ ) </em>分布的误差的显著性的统计测试就简单地停止工作。</p><p id="ce42" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">举个例子，</p><ul class=""><li id="3727" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld po lz ma mb bi translated">只有当回归误差分布为<em class="mc"> N(0，σ)</em><em class="mc">时，<a class="ae of" rel="noopener" target="_blank" href="/fisher-test-for-regression-analysis-1e1687867259"> <strong class="kk iu"> F 检验用于回归分析</strong> </a> <strong class="kk iu"> </strong>的 F 统计量才具有所需的卡方分布。如果回归误差不是正态分布的，f 检验不能用于确定模型的回归系数是否共同显著。然后你将不得不使用一些其他的测试来找出你的回归模型是否比通过数据集均值的直线做得更好。</em></li><li id="8a55" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld po lz ma mb bi translated">同样，<a class="ae of" href="https://en.wikipedia.org/wiki/Confidence_interval#Significance_of_t-tables_and_z-tables" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> t 值和置信区间</strong> </a>的计算假设回归误差为<em class="mc"> N(0，σ ) </em>分布。<em class="mc">如果回归误差不是正态分布的，模型系数和模型预测的 t 值将变得不准确，您不应过于相信系数或预测的置信区间。</em></li></ul><p id="9f02" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">非正态的一个特例:双峰分布残差</strong></p><p id="1ec6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有时，人们发现模型的残差具有双峰分布<strong class="kk iu"/>，即它们有两个峰值。这可能指向一个错误指定的模型，或者模型中缺少一个重要的解释变量。</p><p id="ab84" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，考虑以下情况:</p><p id="7d1c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您的因变量是一个二进制变量，如 Won(编码为 1.0)或 Lost(编码为 0.0)。但是你的线性回归模型将会产生连续实数范围的预测。如果模型沿着大约 0.5 的该标度的狭窄范围产生其大部分预测，例如 0.55、0.58、0.6、0.61 等。回归误差的峰值要么在零的一侧(当真值为 0 时)，要么在零的另一侧(当真值为 1 时)。这表明您的模型无法决定输出应该是 1 还是 0，因此它预测的值大约是 1 和 0 的平均值。</p><p id="217f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果缺少一个关键的二进制变量(称为指示变量),就会发生这种情况，它会以下列方式影响输出值:</p><p id="660e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mc">当变量值为 0 时，输出范围在一定范围内，比如接近 0。</em></p><p id="580f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mc">当变量的值为 1 时，输出会呈现一个全新的值范围，这是以前的范围所没有的，比如 1.0 左右。</em></p><p id="c0da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果模型中缺少此变量，预测值将在两个范围之间取平均值，从而导致回归误差出现两个峰值。一旦添加了这个变量，模型就被很好地指定了，它将正确地区分解释变量的两个可能范围。</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="eadf" class="ok mj it ni b gy ol om l on oo">Related read: <a class="ae of" rel="noopener" target="_blank" href="/when-your-regression-models-errors-contain-two-peaks-13d835686ca"><strong class="ni iu">When Your Regression Model’s Errors Contain Two Peaks</strong></a></span></pre><h2 id="a696" class="ok mj it bd mk pd pe dn mo pf pg dp ms kr ph pi mu kv pj pk mw kz pl pm my pn bi translated">如何检验残差的正态性？</h2><p id="cd20" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">有许多可用的正态性检验。检查正态性最简单的方法是测量残差分布的偏度和峰度。</p><blockquote class="nj nk nl"><p id="4c1d" class="ki kj mc kk b kl km ju kn ko kp jx kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated">完美正态分布的偏度为 0，峰度为 3.0。</p></blockquote><p id="0d08" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">任何偏离，无论是正的还是负的，都表明偏离了常态。当然不可能得到完美的正态分布。预计会出现一些偏离常态的情况。但是“一点点”的离开是多少呢？如何判断离职是否重大？</p><p id="07cd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">偏离是否显著由正态性的统计检验来回答，如<strong class="kk iu"> Jarque Bera 检验</strong>和<strong class="kk iu">综合检验</strong>。这些测试中的 p 值≤ 0.05 表示分布在≥ 95%的置信水平下为正态分布。</p><p id="940c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们在电厂数据集上训练的线性回归模型上运行 Jarque-Bera 正态性测试。回想一下，残留误差存储在变量<code class="fe nf ng nh ni b">resid</code>中，它们是通过对测试数据运行模型并从观测值<em class="mc"> y_test </em>中减去预测值<em class="mc"> y_pred </em>而获得的。</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="c50a" class="ok mj it ni b gy ol om l on oo"><strong class="ni iu">from </strong>statsmodels.compat <strong class="ni iu">import </strong>lzip<br/><strong class="ni iu">import </strong>statsmodels.stats.api <strong class="ni iu">as </strong>sms</span><span id="09f6" class="ok mj it ni b gy op om l on oo">name = ['Jarque-Bera test', 'Chi-squared(2) p-value', 'Skewness', 'Kurtosis']</span><span id="2a84" class="ok mj it ni b gy op om l on oo"><strong class="ni iu">#run the Jarque-Bera test for Normality on the residuals vector<br/></strong>test = sms.<strong class="ni iu">jarque_bera</strong>(resid)</span><span id="18c3" class="ok mj it ni b gy op om l on oo"><strong class="ni iu">#print out the test results. This will also print the Skewness and Kurtosis of the resid vector<br/></strong>lzip(name, test)</span></pre><p id="616a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这会打印出以下内容:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="ad77" class="ok mj it ni b gy ol om l on oo">[('<strong class="ni iu">Jarque-Bera test</strong>', 1863.1641805048084), ('<strong class="ni iu">Chi-squared(2) p-value</strong>', 0.0), ('<strong class="ni iu">Skewness</strong>', -0.22883430693578996), ('<strong class="ni iu">Kurtosis</strong>', 5.37590904238288)]</span></pre><p id="07a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">残差的偏斜度为-0.23，峰度为 5.38。Jarque-Bera 测试得出的 p 值是&lt; 0.01 and thus it has judged them to be respectively different than 0.0 and 3.0 at a greater than 99% confidence level thereby implying that the residuals of the linear regression model are for all practical purposes not normally distributed.</p><p id="e473" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Let’s plot the frequency distribution of the residual errors:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="7d53" class="ok mj it ni b gy ol om l on oo">resid.<strong class="ni iu">hist</strong>(<strong class="ni iu">bins</strong>=50)<br/>plt.show()</span></pre><p id="38a4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">We get the following histogram showing us that the residual errors do seem to be normally distributed (but the JB has shown that they are in fact not so):</p><figure class="nq nr ns nt gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pt"><img src="../Images/d80273af7c615f74242ded7679a91fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y2f6qTS_EH88W5bfB0UpDw.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">Frequency distribution of residual errors (Image by <a class="ae of" href="https://sachin-date.medium.com/" rel="noopener">作者</a></p></figure><blockquote class="nj nk nl"><p id="626f" class="ki kj mc kk b kl km ju kn ko kp jx kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated">相关阅读:<a class="ae of" rel="noopener" target="_blank" href="/testing-for-normality-using-skewness-and-kurtosis-afd61be860"> <strong class="kk iu">用偏度和峰度检验正态性</strong> </a>，关于正态性的深入解释和正态性的统计检验。</p><p id="3b95" class="ki kj mc kk b kl km ju kn ko kp jx kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated">相关阅读:<a class="ae of" rel="noopener" target="_blank" href="/when-your-regression-models-errors-contain-two-peaks-13d835686ca"> <strong class="kk iu">当你的回归模型的误差包含两个峰值</strong> </a> <strong class="kk iu"> : </strong>一个关于处理双峰残差的 Python 教程。</p></blockquote></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><h1 id="010e" class="mi mj it bd mk ml oy mn mo mp oz mr ms jz pa ka mu kc pb kd mw kf pc kg my mz bi translated"><strong class="ak">假设 4:残差应该是同方差的</strong></h1><p id="13b9" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">在上一节中，我们看到了为什么残差应当<em class="mc">为 N(0，σ ) </em>分布，即均值为零且方差为<em class="mc"> σ的正态分布。</em>在本节中，我们对它们施加了一个额外的约束:<em class="mc">方差σ应该是常数。特别是，σ不应该是响应变量</em> <strong class="kk iu"> y </strong> <em class="mc">的函数，从而间接地是解释变量</em> <strong class="kk iu"> <em class="mc"> X </em> </strong> <em class="mc">的函数。</em></p><blockquote class="nj nk nl"><p id="ff69" class="ki kj mc kk b kl km ju kn ko kp jx kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated"><em class="it">一个数据集具有恒定方差的性质叫做</em><strong class="kk iu"><em class="it"/></strong><em class="it">。而与之相反，其中方差是解释变量</em> <strong class="kk iu"> X </strong> <em class="it">的函数称为</em> <strong class="kk iu"> <em class="it">异方差</em> </strong> <em class="it">。</em></p></blockquote><p id="8af1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是一组显示同方差的数据:</p><figure class="nq nr ns nt gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pu"><img src="../Images/ec57dab56278f11d3a0fff7e1b046514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oy8od7F8VaXARwHyM3DhOw.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">同方差的例子(图片由<a class="ae of" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="51b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个显示异方差的例子:</p><figure class="nq nr ns nt gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pu"><img src="../Images/9b1a9bff82f435f78ab70b8f14473576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ij8bs7kdgkF15x33A1dPUA.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">异方差的例子(图片由<a class="ae of" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="fc6b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在谈论同方差或异方差时，我们总是考虑条件方差:<em class="mc">Var(</em><strong class="kk iu"><em class="mc">y</em></strong><em class="mc">|</em><strong class="kk iu"><em class="mc">X</em></strong><em class="mc">=</em><strong class="kk iu"><em class="mc">X _ I</em></strong><em class="mc">，或者 Var(</em><strong class="kk iu"><em class="mc">ε</em></strong><em class="mc">|)这读作<strong class="kk iu"> <em class="mc"> y </em> </strong>的方差或<strong class="kk iu"> <em class="mc"> ε </em> </strong> <em class="mc"> </em>对于<strong class="kk iu"><em class="mc">X</em></strong><em class="mc">=</em><strong class="kk iu"><em class="mc">X _ I</em></strong>的某个值。</em></p><blockquote class="nj nk nl"><p id="3d26" class="ki kj mc kk b kl km ju kn ko kp jx kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated"><strong class="kk iu">相关阅读:</strong> <a class="ae of" rel="noopener" target="_blank" href="/3-conditionals-every-data-scientist-should-know-1916d48b078a"> <strong class="kk iu">每个数据科学家都应该知道的三个条件:</strong> </a> <strong class="kk iu"> </strong>条件期望、条件概率&amp;条件方差:回归建模者的实用见解</p></blockquote><h2 id="ae31" class="ok mj it bd mk pd pe dn mo pf pg dp ms kr ph pi mu kv pj pk mw kz pl pm my pn bi translated">为什么我们希望残差是同方差的？</h2><p id="23ab" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">残差具有作为<strong class="kk iu"> <em class="mc"> y </em> </strong>(因此<strong class="kk iu"> <em class="mc"> X </em> </strong>)的函数的方差的直接后果是残差不再是同分布的。每个<strong class="kk iu"> <em class="mc"> X=x_i </em> </strong>的<strong class="kk iu"> <em class="mc"> ε </em> </strong>的方差会不同，从而导致<strong class="kk iu"> <em class="mc"> ε中每个<em class="mc"> ε_i </em>的概率分布不相同。</em> </strong></p><p id="d649" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们已经看到，如果残差不是同分布的，我们就不能使用显著性检验，例如用于回归分析的<a class="ae of" rel="noopener" target="_blank" href="/fisher-test-for-regression-analysis-1e1687867259"> <strong class="kk iu"> F 检验</strong> </a>，或者对回归模型的系数或模型预测执行置信区间检查。许多这些测试依赖于独立的残差，<strong class="kk iu">同分布的</strong>随机变量。</p><h2 id="3b0e" class="ok mj it bd mk pd pe dn mo pf pg dp ms kr ph pi mu kv pj pk mw kz pl pm my pn bi translated">什么会导致残差是异方差的？</h2><p id="2274" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">当线性模型拟合到响应变量<strong class="kk iu"> <em class="mc"> y </em> </strong>的波动是当前值<strong class="kk iu"> <em class="mc"> y </em> </strong>的某个函数的数据时，异方差误差经常出现，例如，它是当前值<strong class="kk iu"> <em class="mc"> y </em> </strong>的百分比。这种数据集通常出现在货币领域。一个例子是公司股票价格的绝对变动量与当前股票价格成比例。另一个例子是某些产品销售的季节性变化与销售水平成正比。</p><p id="c0e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据收集过程中的错误也会引入异方差。例如，如果测量仪器在测量值中引入与测量值成比例的噪声，则测量值将包含异方差。</p><p id="d7d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">模型误差中引入异方差的另一个原因是简单地对数据集使用了错误的模型，或者遗漏了重要的解释变量。</p><h2 id="b81a" class="ok mj it bd mk pd pe dn mo pf pg dp ms kr ph pi mu kv pj pk mw kz pl pm my pn bi translated">如何修复模型残差中的异方差？</h2><p id="6b18" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">处理异方差误差有三种主要方法:</p><ol class=""><li id="7258" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld ly lz ma mb bi translated">转换因变量，使其线性化，并抑制异方差。常用的变换有<em class="mc">对数(</em><strong class="kk iu"><em class="mc">y</em></strong><em class="mc">)</em>和<em class="mc">平方根(</em><strong class="kk iu"><em class="mc">y</em></strong><em class="mc">)</em>。</li><li id="8dfb" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">确定模型中可能缺失的重要变量，以及导致误差变化以形成模式的变量，并将这些变量添加到模型中。或者，停止使用线性模型，切换到完全不同的模型，如广义线性模型或神经网络模型。</li><li id="02a0" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">简单地接受残差中存在的异方差。</li></ol><h2 id="dbdb" class="ok mj it bd mk pd pe dn mo pf pg dp ms kr ph pi mu kv pj pk mw kz pl pm my pn bi translated">如何检测残差中的异方差？</h2><p id="96f6" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">有几种检验同质性的方法。以下是一些例子:</p><ul class=""><li id="cb02" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld po lz ma mb bi translated"><a class="ae of" href="https://en.wikipedia.org/wiki/Park_test" rel="noopener ugc nofollow" target="_blank">停车测试</a></li><li id="80e0" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld po lz ma mb bi translated"><a class="ae of" href="https://en.wikipedia.org/wiki/Glejser_test" rel="noopener ugc nofollow" target="_blank">格雷泽测试</a></li><li id="598a" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld po lz ma mb bi translated"><a class="ae of" href="https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test" rel="noopener ugc nofollow" target="_blank">布鲁赫-异教徒测试</a></li><li id="de02" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld po lz ma mb bi translated"><a class="ae of" href="https://en.wikipedia.org/wiki/White_test" rel="noopener ugc nofollow" target="_blank">白色测试</a></li><li id="5bd4" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld po lz ma mb bi translated"><a class="ae of" href="https://en.wikipedia.org/wiki/Goldfeld%E2%80%93Quandt_test" rel="noopener ugc nofollow" target="_blank">戈德菲尔德–匡特测试</a></li></ul><p id="01b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">使用 Python 测试异方差</strong></p><p id="1837" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们通过使用<strong class="kk iu">怀特测试来测试模型的异方差残差。</strong>我们将使用之前建立的线性模型中的误差来预测发电厂的输出。</p><p id="ef4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">异方差的<strong class="kk iu">白色测试</strong>使用以下推理来检测异方差:</p><ol class=""><li id="f989" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld ly lz ma mb bi translated">如果残差<strong class="kk iu"> <em class="mc"> ε </em> </strong>是异方差的，则它们的方差可以由<strong class="kk iu"><em class="mc">【y】</em></strong>(因此由模型的解释变量<strong class="kk iu"> <em class="mc"> X </em> </strong>及其平方(<strong class="kk iu"> <em class="mc"> X ) </em> </strong>和叉积<em class="mc">(</em><strong class="kk iu"><em class="mc">X</em></strong><em class="mc">)的组合来“解释”</em></li><li id="12c9" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">因此，当在误差<strong class="kk iu"> <em class="mc"> ε </em> </strong>和<strong class="kk iu"> <em class="mc"> (X </em> </strong>，<strong class="kk iu"> <em class="mc"> X </em> </strong>，<strong class="kk iu"><em class="mc">X</em></strong>X<strong class="kk iu"><em class="mc">X</em></strong>)上拟合辅助线性模型时，期望辅助线性模型将能够解释至少一些关系，即</li><li id="3123" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">如果我们对辅助模型运行回归的<a class="ae of" rel="noopener" target="_blank" href="/fisher-test-for-regression-analysis-1e1687867259"> <strong class="kk iu"> F 检验</strong> </a> <strong class="kk iu"> </strong>，并且 f 检验返回≤ 0.05 的 p 值，这将使我们接受 f 检验的替代假设，即辅助模型的系数共同显著。因此，拟合的辅助模型<em class="mc">是</em>确实能够捕捉主模型的残差<strong class="kk iu"> <em class="mc"> ε </em> </strong>和模型的解释变量<strong class="kk iu"><em class="mc"/></strong>之间的有意义的关系。这使我们得出结论，主模型<strong class="kk iu"> <em class="mc"> ε </em> </strong>的残差是异方差的。</li><li id="a9bb" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">另一方面，如果 f 检验返回 p 值≥ 0.05，那么我们接受 f 检验的零假设，即主模型的残差<strong class="kk iu"> <em class="mc"> ε </em> </strong>与模型的解释变量<strong class="kk iu"> <em class="mc"> X </em> </strong>之间没有有意义的关系。因此，主模型<strong class="kk iu"> <em class="mc"> ε </em> </strong>的残差是同方差的。</li></ol><p id="fe9a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们对之前在测试数据集上运行拟合电厂输出模型时获得的残差进行白色测试。这些残留误差存储在变量<code class="fe nf ng nh ni b">resid.</code>中</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="19ce" class="ok mj it ni b gy ol om l on oo"><strong class="ni iu">from</strong> statsmodels.stats.diagnostic <strong class="ni iu">import</strong> het_white</span><span id="859b" class="ok mj it ni b gy op om l on oo">keys = ['Lagrange Multiplier statistic:', 'LM test\'s p-value:', 'F-statistic:', 'F-test\'s p-value:']</span><span id="4a5b" class="ok mj it ni b gy op om l on oo"><strong class="ni iu">#run the White test</strong><br/>results = <strong class="ni iu">het_white</strong>(resid, X_test)</span><span id="0afb" class="ok mj it ni b gy op om l on oo"><strong class="ni iu">#print the results. We will get to see the values of two test-statistics and the corresponding p-values</strong><br/><strong class="ni iu">lzip</strong>(keys, results)</span></pre><p id="d15f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到以下几点:</p><pre class="nq nr ns nt gt og ni oh oi aw oj bi"><span id="81e8" class="ok mj it ni b gy ol om l on oo">[('<strong class="ni iu">Lagrange Multiplier statistic:</strong>', 33.898672268600926), ("<strong class="ni iu">LM test's p-value:</strong>", 2.4941917488321856e-06), ('<strong class="ni iu">F-statistic:</strong>', 6.879489454587562), ("<strong class="ni iu">F-test's p-value:</strong>", 2.2534296887344e-06)]</span></pre><p id="38a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以看到，回归的 f 检验返回的 p 值为 2.25e-06，比 0.01 还要小得多。</p><p id="ea74" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，在 99%的置信度下，我们可以说白色测试<strong class="kk iu">使用的辅助模型</strong>能够解释主要模型的残差<code class="fe nf ng nh ni b">resid</code>和主要模型的解释变量(在这种情况下为<code class="fe nf ng nh ni b">X_test</code>)之间的有意义的关系。</p><p id="f3f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们<strong class="kk iu">拒绝 f 检验的零假设</strong>，即电厂输出模型的残差是异方差的，而<strong class="kk iu">接受另一个假设</strong>，即模型<strong class="kk iu">的残差是异方差的</strong>。</p><p id="6367" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回想一下，我们在残差与预测值<strong class="kk iu"> <em class="mc"> y_pred 的关系图中看到了以下各种线性模式:</em> </strong></p><figure class="nq nr ns nt gt nu gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pr"><img src="../Images/459665b62bff25d313657224354aa887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ITKi89Q5lRsqodHDOH8BsQ.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">残差与预测值(图片由<a class="ae of" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="c20c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从这个图中，我们应该预期我们的线性模型的残差是异方差的。白测正好印证了这个预期！</p><blockquote class="nj nk nl"><p id="539c" class="ki kj mc kk b kl km ju kn ko kp jx kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated"><strong class="kk iu">相关阅读:</strong> <a class="ae of" rel="noopener" target="_blank" href="/heteroscedasticity-is-nothing-to-be-afraid-of-730dd3f7ca1f"> <strong class="kk iu">异方差没什么可怕的</strong> </a>深入了解异方差及其后果。</p><p id="6903" class="ki kj mc kk b kl km ju kn ko kp jx kq nm ks kt ku nn kw kx ky no la lb lc ld im bi translated"><strong class="kk iu">延伸阅读:</strong> <a class="ae of" rel="noopener" target="_blank" href="/heteroscedasticity-is-nothing-to-be-afraid-of-730dd3f7ca1f"> <strong class="kk iu">非线性、异方差数据的稳健线性回归模型</strong></a>:Python 中的分步教程</p></blockquote></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><h1 id="5e61" class="mi mj it bd mk ml oy mn mo mp oz mr ms jz pa ka mu kc pb kd mw kf pc kg my mz bi translated">摘要</h1><p id="0d3b" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated">普通最小二乘回归模型(也称为线性回归模型)是一种简单而强大的模型，可用于许多真实世界的数据集。</p><p id="8f07" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">OLSR 模式有着坚实的理论基础。它的预测是可以解释和辩护的。</p><p id="b913" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了充分利用 OLSR 模型，我们需要做出并验证以下四个假设:</p><ol class=""><li id="75aa" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld ly lz ma mb bi translated">响应变量<strong class="kk iu"> <em class="mc"> y </em> </strong>应该与解释变量<strong class="kk iu"> <em class="mc"> X </em> </strong>线性相关<strong class="kk iu">。</strong></li><li id="b0c7" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">回归的<strong class="kk iu">残差</strong>应该是<strong class="kk iu">独立、同分布的随机变量</strong>。</li><li id="d5f7" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">残差应该是正态分布的。</li><li id="f64f" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld ly lz ma mb bi translated">残差应该具有恒定的方差，即它们应该是<strong class="kk iu">同方差的</strong>。</li></ol></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><h1 id="eff3" class="mi mj it bd mk ml oy mn mo mp oz mr ms jz pa ka mu kc pb kd mw kf pc kg my mz bi translated">相关阅读</h1><div class="pv pw gp gr px py"><a rel="noopener follow" target="_blank" href="/robust-linear-regression-models-for-nonlinear-heteroscedastic-data-14b1a87c1952"><div class="pz ab fo"><div class="qa ab qb cl cj qc"><h2 class="bd iu gy z fp qd fr fs qe fu fw is bi translated">非线性异方差数据的稳健线性回归模型</h2><div class="qf l"><h3 class="bd b gy z fp qd fr fs qe fu fw dk translated">Python 的分步教程</h3></div><div class="qg l"><p class="bd b dl z fp qd fr fs qe fu fw dk translated">towardsdatascience.com</p></div></div><div class="qh l"><div class="qi l qj qk ql qh qm nz py"/></div></div></a></div><div class="pv pw gp gr px py"><a rel="noopener follow" target="_blank" href="/the-intuition-behind-correlation-62ca11a3c4a"><div class="pz ab fo"><div class="qa ab qb cl cj qc"><h2 class="bd iu gy z fp qd fr fs qe fu fw is bi translated">相关性背后的直觉</h2><div class="qf l"><h3 class="bd b gy z fp qd fr fs qe fu fw dk translated">两个变量相关到底意味着什么？我们将在本文中回答这个问题。我们还将…</h3></div><div class="qg l"><p class="bd b dl z fp qd fr fs qe fu fw dk translated">towardsdatascience.com</p></div></div><div class="qh l"><div class="qn l qj qk ql qh qm nz py"/></div></div></a></div><div class="pv pw gp gr px py"><a rel="noopener follow" target="_blank" href="/heteroscedasticity-is-nothing-to-be-afraid-of-730dd3f7ca1f"><div class="pz ab fo"><div class="qa ab qb cl cj qc"><h2 class="bd iu gy z fp qd fr fs qe fu fw is bi translated">异方差没有什么可怕的</h2><div class="qf l"><h3 class="bd b gy z fp qd fr fs qe fu fw dk translated">使用 Python 的原因、影响、测试和解决方案</h3></div><div class="qg l"><p class="bd b dl z fp qd fr fs qe fu fw dk translated">towardsdatascience.com</p></div></div><div class="qh l"><div class="qo l qj qk ql qh qm nz py"/></div></div></a></div></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><h1 id="d264" class="mi mj it bd mk ml oy mn mo mp oz mr ms jz pa ka mu kc pb kd mw kf pc kg my mz bi translated">引用和版权</h1><p id="bb33" class="pw-post-body-paragraph ki kj it kk b kl na ju kn ko nb jx kq kr nc kt ku kv nd kx ky kz ne lb lc ld im bi translated"><strong class="kk iu">联合循环电厂数据集</strong>:从<a class="ae of" href="https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习库</a>下载，用于以下引用请求:</p><ul class=""><li id="61de" class="lt lu it kk b kl km ko kp kr lv kv lw kz lx ld po lz ma mb bi translated">p NAR tüfek ci，使用机器学习方法预测基本负荷运行的联合循环发电厂的满负荷电力输出，国际电力和能源系统杂志，第 60 卷，2014 年 9 月，第 126–140 页，ISSN 0142–0615，<a class="ae of" href="http://dx.doi.org/10.1016/j.ijepes.2014.02.027" rel="noopener ugc nofollow" target="_blank">，</a>，<br/> ( <a class="ae of" href="http://www.sciencedirect.com/science/article/pii/S0142061514000908" rel="noopener ugc nofollow" target="_blank">，</a>)</li><li id="c7f5" class="lt lu it kk b kl md ko me kr mf kv mg kz mh ld po lz ma mb bi translated">Heysem Kaya，pnar tüfek ci，sadk fik ret gürgen:预测燃气和蒸汽联合涡轮机功率的本地和全球学习方法，计算机和电子工程新兴趋势国际会议论文集，2012 年，第 13–18 页(2012 年 3 月，迪拜</li></ul></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><p id="4489" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mc">感谢阅读！如果您喜欢这篇文章，请</em> <a class="ae of" href="https://timeseriesreasoning.medium.com" rel="noopener"> <strong class="kk iu"> <em class="mc">关注我</em> </strong> </a> <em class="mc">获取关于回归和时间序列分析的技巧、操作方法和编程建议。</em></p></div></div>    
</body>
</html>