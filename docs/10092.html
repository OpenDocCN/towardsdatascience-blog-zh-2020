<html>
<head>
<title>New features in scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">scikit 中的新功能-了解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/new-features-in-scikit-learn-f0ceb7e9d2ad?source=collection_archive---------26-----------------------#2020-07-16">https://towardsdatascience.com/new-features-in-scikit-learn-f0ceb7e9d2ad?source=collection_archive---------26-----------------------#2020-07-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/5a60ce64373b98fb53b7c4164c7815b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KtqlCde2b8X6Tm4x"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@oowgnuj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Jungwoo Hong </a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><div class=""/><div class=""><h2 id="6610" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">0.23 版最新发展概述</h2></div><blockquote class="ky kz la"><p id="35e1" class="lb lc ld le b lf lg kk lh li lj kn lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">如果你对数据科学感兴趣并使用 python，那么<strong class="le jk"> scikit-learn </strong>可能是你联系人列表中的快速拨号。您可能需要更新此联系人。</p></blockquote><p id="f0ea" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">两个月前，scikit-learn 发布了<a class="ae jg" href="https://scikit-learn.org/stable/whats_new/v0.23.html#changes-0-23" rel="noopener ugc nofollow" target="_blank"><strong class="le jk">0.23 版本</strong> </a> <strong class="le jk">，</strong>引入了许多令人兴奋的特性和改进。该版本将至少兼容<strong class="le jk"> Python 3.6 </strong>。<strong class="le jk"> </strong>这篇文章将引导你了解<strong class="le jk">一些有趣的新增内容</strong>。稍后，我还会先睹为快地介绍目前正在开发的<a class="ae jg" href="https://scikit-learn.org/dev/whats_new/v0.24.html" rel="noopener ugc nofollow" target="_blank">下一个版本 0.24 </a>中即将推出的一些特性。</p></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="28b9" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">主要特点</h1><h2 id="9b29" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">1)新的回归模型</h2><p id="66f8" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">Scikit-learn 引入了以下三个新的回归变量:</p><p id="970e" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated"><strong class="le jk"> a)泊松回归变量<br/> b)伽马回归变量<br/> c)特威迪回归变量</strong></p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="b5e4" class="na mj jj nw b gy oa ob l oc od">from sklearn.linear_model import PoissonRegressor<br/>from sklearn.linear_model import GammaRegressor<br/>from sklearn.linear_model import TweedieRegressor</span></pre><p id="f7c5" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">这三种模型都被归类为广义线性模型(GLMs ),支持非正态损失函数。它们在建模误差遵循非正态分布的分布<strong class="le jk">、</strong>的情况下很有用，例如泊松或伽马分布<strong class="le jk">、</strong>或<strong class="le jk">总是正的</strong>，正如<strong class="le jk"/><a class="ae jg" rel="noopener" target="_blank" href="/generalized-linear-models-9cbf848bb8ab"><strong class="le jk">Kida</strong></a>所很好地解释的那样。</p><p id="817a" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">选择哪种分布在很大程度上取决于用例，例如目标变量的正性质，分布的尾部如何，等等。潜在应用的几个例子是风险建模、气候事件预测和保险定价。</p><h2 id="75a2" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">2)稳定和快速的 k 均值估计器</h2><p id="6559" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">众所周知的算法将样本分成预定义数量的具有相等方差的聚类，该算法现在应该被优化，并且对于大样本具有比 0.23 之前版本更好的可扩展性。</p><h2 id="5309" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">3)改进的基于直方图的梯度提升估计器</h2><p id="13d6" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">改进是双重的:首先，回归器和分类器，即<code class="fe oe of og nw b">HistGradientBoostingClassifier</code>和<code class="fe oe of og nw b">HistGradientBoostingRegressor</code>，<strong class="le jk">都支持模型训练期间的样本权重</strong>，如这里的<a class="ae jg" href="https://scikit-learn.org/stable/modules/ensemble.html#sw-hgbdt" rel="noopener ugc nofollow" target="_blank">所示</a>。</p><p id="f2f9" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">其次，如果已知<em class="ld">先验</em>，现在可以指定<a class="ae jg" href="https://scikit-learn.org/stable/modules/ensemble.html#monotonic-constraints" rel="noopener ugc nofollow" target="_blank"> <strong class="le jk">单调约束</strong> </a> <strong class="le jk"> </strong>的性质，即特性可以对响应/目标变量具有的约束。例如，在预测房价时，较大的卧室面积可能会对价格产生积极影响(约束值= 1)，而距离市中心的距离可能会对价格产生消极影响(约束值= -1)。值为 0 将表示不受约束的要素。</p><h2 id="1d5a" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">4)改进的套索和弹性网</h2><p id="ed5f" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">两个著名的线性回归器<strong class="le jk">现在支持模型训练期间的样本权重</strong>。在功能上，这导致了一个新的参数<code class="fe oe of og nw b">sample_weight</code>，它在<code class="fe oe of og nw b">fit()</code>函数中接受一个数组或一个列表，代表数据集中每个样本的权重。</p><h2 id="b407" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">5)管道和估算器的交互式 HTML 可视化</h2><p id="19d4" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">如果你正在 Jupyter 笔记本上建模，你现在可以<strong class="le jk">交互地可视化</strong>你的模型管道和估算器的概要<strong class="le jk">工作流程。这需要调用<code class="fe oe of og nw b">display='diagram'</code>选项。此功能的交互性质允许您悬停在某个估计器上，并扩展它以获得更多细节。看看这个很酷的官方演示。</strong></p><h1 id="cdd9" class="mi mj jj bd mk ml oh mn mo mp oi mr ms kp oj kq mu ks ok kt mw kv ol kw my mz bi translated">其他有趣的功能</h1><h2 id="fb06" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">1)将内置数据集作为数据帧加载</h2><p id="72b8" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">Scikit-learn 提供了几个内置数据集，例如<code class="fe oe of og nw b">load_iris</code>、<code class="fe oe of og nw b">load_digits</code>、<code class="fe oe of og nw b">load_breast_cancer</code>、<code class="fe oe of og nw b">load_diabetes</code>和<code class="fe oe of og nw b">load_wine</code>、<code class="fe oe of og nw b">load_linnerud</code>、<code class="fe oe of og nw b">fetch_california_housing.</code>现在您可以使用关键字<code class="fe oe of og nw b">as_frame=True</code>将这七个数据集加载为<strong class="le jk"> pandas DataFrames </strong>。</p><p id="1e62" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">早些时候，这些嵌入的数据集被加载为<code class="fe oe of og nw b">asklearn.utils.Bunch</code>类型。</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="ee40" class="na mj jj nw b gy oa ob l oc od">from sklearn.datasets import <!-- -->load_iris<br/><br/>df = <!-- -->load_iris<!-- -->(as_frame=True)</span><span id="8885" class="na mj jj nw b gy om ob l oc od"># 0.25 onwards, type(df) should return pandas.core.frame.DataFrame</span></pre><h2 id="4f66" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">2)在一次热编码期间丢弃所选类别</h2><p id="a027" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">标准例程<code class="fe oe of og nw b">preprocessing.OneHotEncoder</code>对分类特征进行一次热编码，现在允许丢弃每个二元特征的第一个类别(只有两个类别)。这是用标签<code class="fe oe of og nw b">drop='if_binary'</code>实现的。具有 1 个或 2 个以上类别的功能将不受此标志的影响。最新版本还有一个更高效的<code class="fe oe of og nw b">OneHotEncoder</code>实现。</p><h2 id="e31a" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">3)高斯斑点的中心</h2><p id="afff" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">在生成各向同性高斯簇(斑点)时，你现在可以通过<code class="fe oe of og nw b">return_centers=True</code>参数访问每个簇的中心。</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="4aa7" class="na mj jj nw b gy oa ob l oc od">from sklearn.datasets import make_blobs</span><span id="f429" class="na mj jj nw b gy om ob l oc od">X, y, centers = make_blobs(n_samples=20, centers=3, n_features=2,<br/>                  random_state=0, return_centers=True)</span></pre></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="7f99" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">即将到来的 v-0.24 中即将到来的变化</h1><p id="14c2" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">很快，目前正在开发的下一个<a class="ae jg" href="https://scikit-learn.org/dev/whats_new/v0.24.html" rel="noopener ugc nofollow" target="_blank">版本 0.24 </a>就要发布了。以下是一些你可以期待的有趣特性。</p><h2 id="97c8" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">1)估算值的逆变换</h2><p id="29bb" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">来自<code class="fe oe of og nw b">sklearn.impute</code>的<code class="fe oe of og nw b">SimpleImputer</code>允许对数据集中的缺失数据进行插补。很快，<strong class="le jk">就可以将估算的数据转换回</strong>原来的状态。首先，需要在调用<code class="fe oe of og nw b">SimpleImputer()</code>时设置一个标志<code class="fe oe of og nw b">add_indicator=True</code>，然后在这个很酷的功能上使用函数<code class="fe oe of og nw b">inverse_transform.</code>阅读更多信息<a class="ae jg" href="https://scikit-learn.org/dev/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="e98e" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">2)平均绝对百分比误差(MAPE)</h2><p id="51c3" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">这将是<strong class="le jk">回归问题</strong>的<strong class="le jk">可用的</strong>新评估指标。这种度量对目标变量的全局缩放不敏感。在数据数量级差异较大的情况下，通过计算误差相对于真实值的相对百分比，它可以作为误差的公平衡量标准，例如，如下面的代码片段所示。下面例子中的<code class="fe oe of og nw b">mean_absolute_error</code>将是 100001.8。</p><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/2de06c5cbbe0a74c449c88528ab14ca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZvAl2-Nq6gilxkvMhzz3UQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">平均绝对百分比误差。ϵ是一个任意小的正数，例如 1e-6。变量 y 和 y_hat 代表真实值和预测值。</p></figure><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="6816" class="na mj jj nw b gy oa ob l oc od"># Implementation in upcoming version 0.24</span><span id="3249" class="na mj jj nw b gy om ob l oc od">from sklearn.metrics import mean_absolute_percentage_error</span><span id="77d5" class="na mj jj nw b gy om ob l oc od">import numpy as np</span><span id="7d4a" class="na mj jj nw b gy om ob l oc od">y_true = np.array([1, 10, 1e6])<br/>y_pred = np.array([0.9, 15, 1.2e6])</span><span id="3ffe" class="na mj jj nw b gy om ob l oc od">mape = mean_absolute_percentage_error(y_true, y_pred)<br/>&gt;&gt;&gt; 0.2666....</span><span id="1d1e" class="na mj jj nw b gy om ob l oc od">#============ My implementation below ============</span><span id="1ed7" class="na mj jj nw b gy om ob l oc od">eps = 1e-6</span><span id="b1e0" class="na mj jj nw b gy om ob l oc od">dev = [np.abs(x-y)/max([eps, np.abs(x)]) for x, y in zip(y_true,<br/>                                                          y_pred)]</span><span id="c64e" class="na mj jj nw b gy om ob l oc od">mape = sum(dev)/len(dev)<br/>&gt;&gt;&gt; 0.2666....</span></pre><h2 id="b452" class="na mj jj bd mk nb nc dn mo nd ne dp ms ly nf ng mu lz nh ni mw ma nj nk my nl bi translated">3)<code class="fe oe of og nw b"><strong class="ak">confusion matrix plot</strong></code>中的可选颜色条</h2><p id="8f3b" class="pw-post-body-paragraph lb lc jj le b lf nm kk lh li nn kn lk ly no ln lo lz np lr ls ma nq lv lw lx im bi translated">在绘制混淆矩阵时，颜色条现在是可选的。如果不需要的话，这就不需要一个替代解决方案来隐藏色条。</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="f5c6" class="na mj jj nw b gy oa ob l oc od">plot_confusion_matrix(estimator, X, y, colorbar=False)</span></pre></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><p id="5500" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">这让我想到了这篇文章的结尾。在你更新了你的 scikit-learn 并想用 python 可视化数据之后，你可以关注我最近的文章<strong class="le jk">Matplotlib 3 的新特性</strong> <a class="ae jg" rel="noopener" target="_blank" href="/whats-new-in-matplotlib-3-1b3b03f18ddc">这里</a>。</p><p id="5d5a" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated"><strong class="le jk">机器学习快乐！</strong></p></div></div>    
</body>
</html>