<html>
<head>
<title>Using Weighted K-Means Clustering to Determine Distribution Centres Locations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用加权K-均值聚类确定配送中心位置</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-weighted-k-means-clustering-to-determine-distribution-centres-locations-2567646fc31d?source=collection_archive---------2-----------------------#2020-01-25">https://towardsdatascience.com/using-weighted-k-means-clustering-to-determine-distribution-centres-locations-2567646fc31d?source=collection_archive---------2-----------------------#2020-01-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/77f7cf6951f12c0b3fc84b3b4fa3a77e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tLNNvvBZx0gaJqL4vqg3Ww.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@marcinjozwiak?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Marcin Jozwiak </a>在<a class="ae jg" href="https://unsplash.com/s/photos/warehouse?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="6784" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">另一个你可能不知道的K-means算法的修改版本的用例</h2></div><p id="1d49" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">背景</strong></p><p id="5a69" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们所有人都一定熟悉快餐连锁公司，如肯德基或麦当劳，因为它们在我们周围有大量的分店。这些名字以快速提供即食餐而闻名，这要归功于提前散装烹饪，有时还包括预包装。作为其商业模式的一个暗示，快餐连锁店需要快速的供应链执行，特别是对于配料。这是为了确保它们总是新鲜的提供给顾客。</p><p id="48fb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于这一点，你有没有想过他们如何能及时提供这些易腐的原料？这并不是一个听起来简单的问题，因为涉及的出口数量巨大。<strong class="la jk">在这方面，仓库所描绘的配送中心起着至关重要的作用</strong>。</p><p id="71e6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">快餐连锁店的仓库是供应商卸下货物的地方，这些货物随后被包装，最后被分发到商店。通常，一个仓库负责周围几个城市的所有经销店。因此，快餐连锁店会有几个仓库分布在他们的经营区域。</p><p id="ccb6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们考虑一家全球快餐公司，该公司最近计划进入印度尼西亚市场。管理层预计分两个阶段进行扩张:第一阶段和第二阶段。第一阶段将只覆盖爪哇岛，而其余地区将在第二阶段处理。为此，我们将帮助确定其仓库的位置，特别是在第一阶段</p><blockquote class="lu"><p id="bc86" class="lv lw jj bd lx ly lz ma mb mc md lt dk translated">我们将帮助一家快餐店确定遍布爪哇岛的仓库位置。</p></blockquote><p id="4f9a" class="pw-post-body-paragraph ky kz jj la b lb me kk ld le mf kn lg lh mg lj lk ll mh ln lo lp mi lr ls lt im bi translated"><strong class="la jk">回忆(标准)K均值聚类</strong></p><p id="8f93" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">K均值聚类是一种将数据划分为K个不同聚类的算法。关于算法如何工作的高级视图如下。给定K个簇(通常是随机的)的初始(这意味着来自K个质心)，该算法在以下两个步骤之间迭代:</p><ol class=""><li id="c80b" class="mj mk jj la b lb lc le lf lh ml ll mm lp mn lt mo mp mq mr bi translated">计算所有数据点和现有K个质心之间的距离，并相应地将每个数据点重新分配给其最近的质心。</li><li id="e799" class="mj mk jj la b lb ms le mt lh mu ll mv lp mw lt mo mp mq mr bi translated">基于这个新的聚类分配，通过取数据点的平均值来计算新的K个质心。</li></ol><p id="f30b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">执行上述迭代，直到质心不随迭代而改变(算法收敛)或者满足特定的停止标准(例如，触发最大迭代次数)</p><p id="cd62" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">读者可能已经知道，该算法中的数字K是一个超参数(即预定义的数字)。在实践中，我们可以通过使用例如<em class="mx">肘方法</em>来选择最佳K，我们将在本文后面使用并解释该方法。</p><p id="0c82" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，在选择距离度量时也有一定的自由度，而不是在原始算法中使用的标准欧几里德距离。如果有必要或者看起来更合适，我们可以使用其他距离度量，如哈弗森距离(我们将在文章中使用的距离)或曼哈顿距离。</p><p id="8adf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">使用加权K均值聚类解决问题</strong></p><p id="5098" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们回到我们的问题！确定仓库的位置可以看作是寻找相应服务分支的聚类的质心。因此，这是K-均值聚类，特别是加权K-均值聚类的一个很好的用例。我们所说的“加权”一会儿就明白了。</p><p id="f1f4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们首先已经知道，这家快餐公司将在爪哇开设分店。因此，我们可以通过首先确定分支机构的位置来解决这个问题，我们可以用Java中所有城市/地区的经度-纬度(相当于(x，y))来合理地近似这个位置。使用这些城市中心的数据点，我们实际上可以运行标准的K-means聚类来解决这个问题。然而，这种方法没有考虑到这样一个事实，即一些城市确实比其他城市更大，这意味着对供应的原料有更高的需求量。</p><blockquote class="lu"><p id="9e78" class="lv lw jj bd lx ly lz ma mb mc md lt dk translated">标准的K-均值方法没有考虑到这样一个事实，即一些城市确实比其他城市大，这意味着对供应的原料有更高的需求量。</p></blockquote><p id="1be3" class="pw-post-body-paragraph ky kz jj la b lb me kk ld le mf kn lg lh mg lj lk ll mh ln lo lp mi lr ls lt im bi translated">考虑到这一点，我们还包括人口数据，作为配料需求的代理。这些人口数据将成为相应城市(数据点)的权重，瞧！我们已经有了运行加权K均值聚类算法的设置。</p><p id="dd1b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了解释权重对算法的影响，假设我们现在正在处理不同大小的数据点(由它们的权重表示)。我们可以进一步看到大小与数据点所拥有的重力成比例。因此，权重越大，数据点将质心拉得越近。<strong class="la jk">总之，与标准算法的根本区别在于质心计算，现在使用加权平均值，而不是标准平均值。</strong></p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/89641a133bbddaa7f863db4060ec6972.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aQMaesMMpOmhBNAFCR5CEw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">计算质心的标准(左)与加权(右)平均值的图示</p></figure><p id="6b69" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">数据来源</strong></p><p id="9d55" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们感谢benangmerah GitHub帐户的这个存储库提供了所考虑的城市的经纬度坐标数据。原来，爪哇岛上有119个城市，从西部的奇勒贡到靠近巴厘岛的左部的班尤万吉。此外，我们还参考了印度尼西亚统计局(BPS)2018年爪哇省各城市的人口数据。</p><p id="3eb1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">哈弗森距离</strong></p><p id="9104" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，<strong class="la jk">我们将使用经纬度</strong>，它代表地球的球面——与(x，y)中的标准平面2D坐标系相反。因此，欧几里德距离不是这里使用的最佳距离度量。相反，我们将使用哈弗线距离，这是球面上一个合适的距离度量。</p><p id="e99c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面的等式中，φ是纬度，λ是经度，R是地球半径(平均半径= 6371公里)，这就是我们如何使用哈弗辛方法计算距离(记为<em class="mx"> d </em>)。</p><blockquote class="nd ne nf"><p id="df72" class="ky kz mx la b lb lc kk ld le lf kn lg ng li lj lk nh lm ln lo ni lq lr ls lt im bi translated">A = sin((φB—φA)/2)+cosφA * cosφB * sin((λB—λA)/2)</p><p id="9ef7" class="ky kz mx la b lb lc kk ld le lf kn lg ng li lj lk nh lm ln lo ni lq lr ls lt im bi translated">c = 2 * atan2( √a，√( 1a))</p><p id="4ef2" class="ky kz mx la b lb lc kk ld le lf kn lg ng li lj lk nh lm ln lo ni lq lr ls lt im bi translated">⋅ c</p></blockquote><p id="7198" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面给出了这种距离度量的另一种实现方式。</p><pre class="mz na nb nc gt nj nk nl nm aw nn bi"><span id="aab3" class="no np jj nk b gy nq nr l ns nt">#haversine distance function</span><span id="5aba" class="no np jj nk b gy nu nr l ns nt">haversine_dist = function(point1, point2) { #each argument is a numeric vector with two elements (lon, lat)<br/>  lon1 = point1[1] <br/>  lat1 = point1[2]<br/>  lon2 = point2[1]<br/>  lat2 = point2[2]<br/>  <br/>  R = 6371000 #earth radius in meters<br/>  phi1 = lat1 * pi / 180 #convert to radian<br/>  phi2 = lat2 * pi / 180 #convert to radian<br/>  delta_phi = (lat2 - lat1) * pi / 180<br/>  delta_lambda = (lon2 - lon1) * pi / 180<br/>  <br/>  a = (sin(delta_phi/2))^2 + cos(phi1) * cos(phi2) * ((sin(delta_lambda/2))^2)<br/>  c = 2 * atan2(sqrt(a), sqrt(1-a))<br/>  <br/>  distance = R * c #haversine distance between point1 and point 2 in meters<br/>  return(round(distance, 2))<br/>}</span></pre><p id="367a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">逐步解决方案和R中的代码</strong></p><p id="b848" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好了，让我们动手做代码吧！在本文中，我们将使用R来运行算法。</p><ul class=""><li id="ad4c" class="mj mk jj la b lb lc le lf lh ml ll mm lp mn lt nv mp mq mr bi translated">数据准备</li></ul><p id="f38e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们导入一个包含所需列的数据帧:城市名称、经度、纬度和人口。</p><pre class="mz na nb nc gt nj nk nl nm aw nn bi"><span id="6f8c" class="no np jj nk b gy nq nr l ns nt">df_city = read.csv('/Users/parara/Documents/Project/Weighted K-Means/city_data.csv')</span><span id="6ffc" class="no np jj nk b gy nu nr l ns nt">head(df_city)</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/4a483e23fed6f67d086431332f7ba107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mUFW-lL1ueWkuqJmNBHcCA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">负责人(df_city)</p></figure><ul class=""><li id="f75e" class="mj mk jj la b lb lc le lf lh ml ll mm lp mn lt nv mp mq mr bi translated">初始化</li></ul><p id="ee0d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们固定集群的数量K，比如说5个。接下来，我们随机选择五个城市作为初始质心。之后，使用这些质心，我们将每个城市分配到其最近的质心(初始聚类)。回想一下，我们使用哈弗线距离作为距离度量。</p><pre class="mz na nb nc gt nj nk nl nm aw nn bi"><span id="163f" class="no np jj nk b gy nq nr l ns nt">#number of clusters<br/>K = 5</span><span id="7b88" class="no np jj nk b gy nu nr l ns nt">#initial centroids by random<br/>init_centroids_index = sample(nrow(df_city),K)</span><span id="3c24" class="no np jj nk b gy nu nr l ns nt">#initiate containers<br/>distance_matrix = matrix(data = NA, nrow = nrow(df_city), ncol = K)<br/>cluster = vector()<br/>centroid_long = vector()<br/>centroid_lat = vector()</span><span id="02fb" class="no np jj nk b gy nu nr l ns nt">#compute distance between cities and initial centroids<br/>for (k in c(1:K)) {<br/>  for (i in c(1:nrow(df_city))) {<br/>    city_i = as.numeric(df_city[i,2:3])<br/>    centroid_k = as.numeric(df_city[init_centroids_index[k],2:3])<br/>    distance_matrix[i,k] = haversine_dist(city_i,centroid_k)<br/>  }<br/>}</span><span id="d6d1" class="no np jj nk b gy nu nr l ns nt">#initial cluster assignment for each city<br/>for (i in c(1:nrow(df_city))) {<br/>  cluster[i] = which.min(distance_matrix[i,])<br/>}</span></pre><ul class=""><li id="6fe4" class="mj mk jj la b lb lc le lf lh ml ll mm lp mn lt nv mp mq mr bi translated">循环</li></ul><p id="37e5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有了初始集群，我们就可以开始循环了。我们迭代地更新质心，并将城市重新分配给聚类，直到聚类分配在迭代之间保持不变。</p><pre class="mz na nb nc gt nj nk nl nm aw nn bi"><span id="17d2" class="no np jj nk b gy nq nr l ns nt">#iteration baseline<br/>old_cluster = vector(length = length(cluster))<br/>new_cluster = cluster</span><span id="877b" class="no np jj nk b gy nu nr l ns nt">#iterations<br/>while (!all(old_cluster == new_cluster)) {<br/>  #update old cluster assignment<br/>  old_cluster = new_cluster<br/>  #calculate centroids using weighted average<br/>  for (k in c(1:K)) {<br/>    cluster_k = which(old_cluster == k) #city index of cluster k<br/>    centroid_long[k] = weighted.mean(df_city$longitude[cluster_k], df_city$population[cluster_k])<br/>    centroid_lat[k] = weighted.mean(df_city$latitude[cluster_k], df_city$population[cluster_k])<br/>  }<br/>  df_centroid = as.data.frame(cbind(centroid_long, centroid_lat))<br/>  #compute distance between cities and centroids<br/>  for (k in c(1:K)) {<br/>    for (i in c(1:nrow(df_city))) {<br/>      city_i = as.numeric(df_city[i,2:3])<br/>      centroid_k = as.numeric(df_centroid[k,])<br/>      distance_matrix[i,k] = haversine_dist(city_i,centroid_k)<br/>    }<br/>  }<br/>  #update cluster assignment for each city<br/>  for (i in c(1:nrow(df_city))) {<br/>    cluster[i] = which.min(distance_matrix[i,])<br/>  }<br/>  #update new_cluster<br/>  new_cluster = cluster<br/>}</span></pre><ul class=""><li id="1401" class="mj mk jj la b lb lc le lf lh ml ll mm lp mn lt nv mp mq mr bi translated">选择最佳K</li></ul><p id="fa24" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实是，上面选择的K = 5的值是追溯性的。我们事先根据下面的肘法挑选了号码。但是，理解这种技术需要我们首先理解什么是所谓的平方和误差(SSE)。在K-means算法中，SSE中的术语“误差”是指数据点到其质心之间的偏差。因此，我们通过对所有数据点的所有此类平方误差求和来获得SSE的值。</p><p id="5700" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们注意到，任何集群分配都对应于一个SSE值。因此，我们可以绘制不同K(聚类数)下的收敛算法的SSE值。使用该图，我们查看K，在K处，值之后的下降斜率不再显著。这是我们正在寻找的最佳K。通常，这个K值会在整个图上形成一个“肘形”,因此得名。</p><p id="f919" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们来说，情节如下。请注意，在K = 5之后，上证指数的下降不再显著，因此我们选择这个数字作为最佳K。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nx"><img src="../Images/e90f56a18567f6bd2ab2b5314a2f7923.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vhS9rAvFFfOz7qmol7qZkg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">上证指数在不同k线下跌</p></figure><ul class=""><li id="e06e" class="mj mk jj la b lb lc le lf lh ml ll mm lp mn lt nv mp mq mr bi translated">结果</li></ul><p id="fe33" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，算法的结果如下。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/8e2b8a4d732f2707caa813ac42fb4510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s4pzatDUhtlaRn2SiBDXxw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">加权K均值结果</p></figure><p id="4e10" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于上述结果，我们对五个仓库位置的建议如下:</p><ol class=""><li id="cd17" class="mj mk jj la b lb lc le lf lh ml ll mm lp mn lt mo mp mq mr bi translated">西爪哇省德博克附近</li><li id="94bc" class="mj mk jj la b lb ms le mt lh mu ll mv lp mw lt mo mp mq mr bi translated">西爪哇Majalengka附近</li><li id="abb2" class="mj mk jj la b lb ms le mt lh mu ll mv lp mw lt mo mp mq mr bi translated">靠近爪哇中部的Temanggung</li><li id="ceae" class="mj mk jj la b lb ms le mt lh mu ll mv lp mw lt mo mp mq mr bi translated">东爪哇马迪恩附近</li><li id="dabc" class="mj mk jj la b lb ms le mt lh mu ll mv lp mw lt mo mp mq mr bi translated">东爪哇Probolinggo附近</li></ol><p id="f33f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">结论和备注</strong></p><p id="4207" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们演示了加权K均值聚类算法在确定快餐店仓库位置中的应用。总之，K-means的这个修改版本与原始版本的不同之处在于它计算聚类质心的方式，它使用加权平均值而不是常规平均值。</p><p id="9da8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于我们的实现还有最后一句话(代码在这篇文章中给出)。<strong class="la jk"> K-means算法只产生局部最优</strong>，而不是全局最优。也就是说，获得的最终簇分配取决于初始分配，这是随机的。<strong class="la jk">因此，</strong> <strong class="la jk">在实际应用中，我们需要多次复制整个算法，并从产生最小SSE的最佳复制中挑选结果。</strong></p><p id="6665" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于感兴趣的读者，我把这个“真实实现”的代码放在我的GitHub库<a class="ae jg" href="https://github.com/pararawendy/weighted_kmeans_R" rel="noopener ugc nofollow" target="_blank">这里</a>。在那里，您还可以找到SSE函数的代码，生成本文中显示的图，当然，还有本文中使用的数据集。</p><p id="4594" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总之，感谢您的阅读，让我们在https://www.linkedin.com/in/pararawendy-indarjo-5b87bab7<a class="ae jg" href="https://www.linkedin.com/in/pararawendy-indarjo-5b87bab7/?originalSubdomain=id" rel="noopener ugc nofollow" target="_blank">的LinkedIn上与我联系。</a></p></div></div>    
</body>
</html>