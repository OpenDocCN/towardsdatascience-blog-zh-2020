# TensorFlow 中豆类图像分类的分布式学习

> 原文：<https://towardsdatascience.com/distributed-learning-on-image-classification-of-beans-in-tensorflow-5a85e6c3eb71?source=collection_archive---------32----------------------->

## 使用 TensorFlow 2.0 的内置函数执行分布式学习，并使用它来训练一个简单的图像分类模型。

深度学习已经导致了机器学习领域的各种技术进步，但它仍然受到在大数据集上训练所需的大量计算时间的困扰。用于基准测试的 ImageNet 等训练数据集可能需要一个 GPU 系统长达一周的时间。另一方面，在多台机器或 GPU 之间划分训练的分布式训练已经被认为极大地减少了这种训练时间。

TensorFlow 提供了使用不同算法执行分布式学习的内置功能。今天，我们将了解“镜像策略”，并在[“bean”](https://www.tensorflow.org/datasets/catalog/beans)数据集上实施该策略。

## **导入依赖项并下载数据集**

首先，我们需要下载所需的库和我们将要处理的数据集。

既然我们已经下载了数据集及其依赖项，我们就可以开始编写代码了。

## 代码入门

现在，在我们开始训练之前，需要一些必要的步骤。需要定义超参数，更重要的是，我们需要初始化分布式学习算法。

我们通过从数据集中检索来初始化训练和测试图像的数量。我们还为我们的训练定义了一个缓冲区大小和批量大小，这将取决于 GPU 的数量。你拥有的 GPU 越多，你就可以保持更大的批量，这意味着更快的训练。

## 创建模型和补充功能

我们将使用一个简单的 CNN 模型在这个数据集上进行训练，并演示分布式学习功能。我们的 CNN 也将需要一些功能，我们将在此过程中定义。

首先，我们需要做一些轻微的数据预处理和归一化我们的图像的像素值。我们还对训练数据进行批处理，并在内存中保存训练数据的缓存，以提高性能。

现在我们可以开始建设我们的 CNN 了。

最后，我们需要定义一些补充功能，包括检查点、学习率衰减和回调。

检查点将在每个时期后保存模型的进度，随着时期数量的增加，学习率衰减将帮助我们获得动态学习率，并且模型在每个时期结束时使用回调来运行所有这些功能。

一旦模型构建完成，补充功能定义完成，我们就可以进入激动人心的部分，训练模型。

## 训练模型

这是代码中最简单的部分，但也是代码运行中最重要的部分。我们现在可以在数据集上训练模型，这将通过分布式学习来实现！

## 分布式学习策略

有各种策略或算法可用于分布式学习。首先，让我们来看看我们在代码中使用的镜像策略。

***镜像策略*** 支持一台机器上多个 GPU 的同步训练。它会为每个 GPU 设备创建一个副本，并且模型中的每个变量都会跨所有副本进行镜像。通过应用相同和同时的更新，变量的所有副本彼此保持同步。

***多工人镜像策略*** 是镜像策略的一个版本，但用于多工人培训。这就是我们可以在多台机器而不仅仅是一台机器上使用分布式学习的地方。这种策略对多个工作者使用同步训练，每个工作者可以有多个 GPU。它创建每个工人的每个设备的模型中的所有变量的副本。

***参数服务器策略*** 是一种灵活的策略，因为它允许在多个 GPU 上进行同步本地训练，也允许跨多台机器进行异步训练。其本地训练与镜像策略的不同之处在于，它不是创建变量的副本并同时更新所有变量，而是将变量存储在 CPU 上，并在所有本地 GPU 上复制操作。

以上所有策略只是分发算法的一些例子。它们都可以使用 *tf.distribute* 库在 TensorFlow 中实现。

```
# *To use Mirrored Strategy, we have used this in our code* 
$ tf.distribute.MirroredStrategy()# *To use Multi Worker Mirrored Strategy*
$ tf.distribute.MultiWorkerMirroredStrategy()# *To use Parameter Server Strategy*
$ tf.distribute.ParameterServerStrategy()
```

## 但是一切都变好了吗？

由于各种策略各不相同，各有利弊。

我们的目标是最大限度地利用 GPU 的能力，同时尽可能少地浪费数据获取的时间。在镜像策略中，当我们在具有多个 GPU 的单个本地系统上使用分布式学习时，我们看到 GPU 的使用远非完美。理想的情况是，平均来说，你的每个 GPU 都得到了同等的优化，但这并没有发生。但是，我们确实看到，随着检索指令所花费的时间减少，内存访问时间明显缩短，因为任务被划分到多个 GPU 上。最重要的是，随着数据集变得越来越大，我们可以预计分布式学习过程将更多地减少训练时间。为了进一步改善这一点，TensorFlow 具有*预取*功能，可在当前时段进行的同时获取下一时段的数据。但是，该功能仍处于试验阶段，可能会有错误。

多工作器镜像策略允许您获得更高的性能，因为多个工作器拥有自己的 GPU 集，但同时，该策略容易出现系统错误。如果其中一名员工出现系统错误，由于培训过程需要在所有员工之间同步，TensorFlow 会暂停培训过程，直到该员工重新上线。这确实导致训练时间的增加，并且训练过程越长，网络或系统故障的机会就越多，训练时间就越长。此外，检查点评估不能由任何工作线程完成，因为当一个工作线程正在评估检查点时，其他工作线程将不得不等待，这可能会导致通信超时。因此，检查点的评估由与所有工作人员通信的主系统完成，并且该过程完全由一台机器的能力决定。

代码的完整笔记本可以在 colab [这里](https://colab.research.google.com/drive/1edcUMPcSjijdn-1RF_pOd2yodnexzPlu)找到。

![](img/e9717d54612fab8d60abd46c87e9040a.png)

在 [Unsplash](https://unsplash.com/s/photos/beans?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上由[蒂贾娜·德恩达尔斯基](https://unsplash.com/@izgubljenausvemiru?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄的照片