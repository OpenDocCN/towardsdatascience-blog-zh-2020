# 我如何不断地将我的机器学习模型的准确率从 80%提高到 90%以上

> 原文：<https://towardsdatascience.com/how-i-consistently-improve-my-machine-learning-models-from-80-to-over-90-accuracy-6097063e1c9a?source=collection_archive---------9----------------------->

## 改进机器学习模型的 5 个技巧和提示

![](img/cc3074069053d33e260823fa502db2f0.png)

里卡多·阿尔塞在 [Unsplash](https://unsplash.com/s/photos/target?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上的照片

# 介绍

如果你已经完成了一些自己的数据科学项目，你现在可能已经意识到达到 80%的准确率并不算太坏！但在现实世界中，80%是不会切的。事实上，我工作过的大多数公司都期望至少 90%的准确率(或者他们所关注的任何指标)。

因此，我要谈谈你可以做的 5 件事来显著提高你的准确性。**我强烈建议你通读这五点内容**，因为我包含了很多大多数初学者不知道的细节。

到此结束时，你应该明白，有比你想象的更多的变量在决定你的机器学习模型的表现方面发挥着作用。

也就是说，你可以做 5 件事来改进你的机器学习模型！

*   *如果你喜欢这个，* [*关注我的 Medium*](https://medium.com/@terenceshin) *了解更多*
*   *关注我*[*Kaggle*](https://www.kaggle.com/terenceshin)*了解更多内容！*
*   *我们连线上*[*LinkedIn*](https://www.linkedin.com/in/terenceshin/)
*   *有兴趣合作？查看我的* [*网站*](http://Want to collaborate?) *。*
*   *查看* [*我的免费数据科学资源*](https://docs.google.com/document/d/1UV6pvCi9du37cYAcKNtuj-2rkCfbt7kBJieYhSRuwHw/edit#heading=h.m63uwvt9w358) *每周都有新素材！*

# 1.处理缺失值

我看到的最大错误之一是人们如何处理缺失的价值观，这不一定是他们的错。网络上的许多资料表明，您通常通过**均值插补、**用给定特征的均值替换空值来处理缺失值，这通常不是最佳方法。

例如，假设我们有一个显示年龄和健康分数的表格，并假设一个 80 岁的老人缺少健康分数。如果我们从 15 岁到 80 岁的年龄范围内取平均健康分数，那么 80 岁的人看起来会有一个比他实际应该有的高得多的健康分数。

因此，你要问自己的第一个问题是**为什么**数据一开始就丢失了。

接下来，考虑处理缺失数据的其他方法，除了均值/中值插补:

*   **特征预测建模**:回到我关于年龄和健康分数的例子，我们可以对年龄和健康分数之间的关系建模，然后使用该模型找到给定年龄的预期健康分数。这可以通过几种技术来完成，包括回归、方差分析等。
*   **K 最近邻插补**:使用 KNN 插补，缺失的数据用另一个相似样本的值填充，对于不知道的人，使用距离函数(即欧几里德距离)确定 KNN 的相似性。
*   **删除行**:最后，可以删除行。这通常不被推荐，但是当你有一个巨大的数据量时，这是可以接受的。

# 2.特征工程

第二种可以显著改善机器学习模型的方法是通过特征工程。特征工程是将原始数据转化为更好地代表人们试图解决的潜在问题的特征的过程。这一步没有特定的方法，这使得数据科学既是一门科学，也是一门艺术。话虽如此，以下是一些你可以考虑的事情:

*   转换日期时间变量以仅提取星期几、月份等…
*   为变量创建容器或桶。(例如，对于高度变量，可以有 100-149 厘米、150-199 厘米、200-249 厘米等。)
*   组合多个要素和/或值以创建一个新要素和/或值。例如，泰坦尼克号挑战最准确的模型之一设计了一个新的变量，称为“是女人还是孩子”，如果这个人是女人或孩子，这个变量为真，否则为假。

# 3.特征选择

第三个可以大幅提高模型精度的领域是要素选择，即选择数据集最相关/最有价值的要素。过多的特征会导致算法过拟合，过少的特征会导致算法欠拟合。

我喜欢使用两种主要方法来帮助您选择功能:

*   **特性重要性:**像 random forests 或 XGBoost 这样的算法允许您确定哪些特性在预测目标变量的值时是最“重要”的。通过快速创建其中一个模型并进行特征重要性分析，您将了解哪些变量比其他变量更有用。
*   **降维**:最常见的降维技术之一，主成分分析(PCA)取大量特征，利用线性代数将其降维为较少的特征。

# 4.集成学习算法

改善你的机器学习模型的一个最简单的方法就是简单地选择一个更好的机器学习算法。如果你还不知道什么是集成学习算法，现在是时候学习它了！

**集成学习**是一种结合使用多种学习算法的方法。这样做的目的是让您获得比单独使用单个算法更高的预测性能。

流行的集成学习算法包括随机森林、XGBoost、梯度增强和 AdaBoost。为了解释为什么集成学习算法如此强大，我将给出一个随机森林的例子:

随机森林涉及使用原始数据的自举数据集创建多个决策树。然后，该模型选择每个决策树的所有预测的模式(大多数)。这有什么意义？依靠“多数获胜”模型，它降低了单个树出错的风险。

![](img/a040db4028324981b739fc86bd397df6.png)

例如，如果我们创建一个决策树，第三个，它会预测 0。但是如果我们依赖所有 4 个决策树的模式，预测值将是 1。这就是集成学习的力量！

# 5.调整超参数

最后，有一点很少被提及，但仍然非常重要，那就是调整模型的超参数。这是你清楚地理解你正在使用的 ML 模型的必要条件，否则很难理解每个超参数是什么。

看看随机森林的所有超参数:

```
*class* sklearn.ensemble.**RandomForestClassifier**(*n_estimators=100*, ***, *criterion='gini'*, *max_depth=None*, *min_samples_split=2*, *min_samples_leaf=1*, *min_weight_fraction_leaf=0.0*, *max_features='auto'*, *max_leaf_nodes=None*, *min_impurity_decrease=0.0*, *min_impurity_split=None*, *bootstrap=True*, *oob_score=False*, *n_jobs=None*, *random_state=None*, *verbose=0*, *warm_start=False*, *class_weight=None*, *ccp_alpha=0.0*, *max_samples=None*
```

例如，了解 min _ infinity _ decrease 是什么可能是一个好主意，以便当您希望您的机器学习模型更加宽容时，您可以调整该参数！；)

# 感谢阅读！

通过阅读本文，您现在应该对如何将模型的准确性从 80%提高到 90%以上有了更多的想法。这些信息还将使您未来的数据科学项目进行得更加顺利。我祝你在数据科学的努力中好运。

## 特伦斯·申

*   *如果你喜欢这个，* [*关注我的 Medium*](https://medium.com/@terenceshin) *了解更多*
*   *关注我的*[](https://www.kaggle.com/terenceshin)**了解更多内容！**
*   **我们来连线上* [*LinkedIn*](https://www.linkedin.com/in/terenceshin/)*
*   **有兴趣合作？查看我的* [*网站*](http://Want to collaborate?) *。**
*   **查看* [*我的免费数据科学资源*](https://docs.google.com/document/d/1UV6pvCi9du37cYAcKNtuj-2rkCfbt7kBJieYhSRuwHw/edit#heading=h.m63uwvt9w358) *每周有新素材！**