<html>
<head>
<title>Understanding AlphaGo: how AI thinks and learns (Advanced)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解 AlphaGo:人工智能如何思考和学习(高级)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-alphago-how-ai-thinks-and-learns-advanced-d70780744dae?source=collection_archive---------6-----------------------#2020-01-21">https://towardsdatascience.com/understanding-alphago-how-ai-thinks-and-learns-advanced-d70780744dae?source=collection_archive---------6-----------------------#2020-01-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8019" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">是时候了解卷积神经网络、深度学习以及我们的现代人工智能如何赢得顶级围棋选手的比赛了…</h2></div><blockquote class="ki"><p id="1557" class="kj kk it bd kl km kn ko kp kq kr ks dk translated">“作为一名技术专家，我看到人工智能和第四次工业革命将如何影响人们生活的方方面面。”</p><p id="1e14" class="kj kk it bd kl km kt ku kv kw kx ks dk translated">费-李非</p></blockquote><p id="17d8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls ks im bi translated">本文将从深度学习开始，深入到 DeepMind AI 的架构，就像 Alpha Go 一样。到文章结束的时候，我们应该能看懂很多人工智能领域最前沿的论文了，像 Alpha Go Zero 的<a class="ae lt" href="https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ" rel="noopener ugc nofollow" target="_blank">原论文</a>。蒙特卡罗树搜索(MCTS)和卷积神经网络是我们在理解 Alpha Go 如何工作之前应该熟悉的两个基本概念。如果你有兴趣了解更多，决策树、状态机、强化学习和蒙特卡罗树搜索等概念在<a class="ae lt" rel="noopener" target="_blank" href="/understanding-alphago-how-ai-think-and-learn-1-2-da07d3ec5278">了解 alpha go:AI 如何思考和学习(基础)</a>中有解释。</p><p id="0327" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">这篇文章的目的是让人们了解 Alpha Go 是如何工作的，但它也可能会提高人们对人工智能领域的兴趣，因为人工智能领域的信息太多，无法包含在一篇中型文章中。我们将要学习更高级的材料，所以要准备好一些可能更难理解的东西。我会尽我所能，用最简单的方式解释这些概念。</p><p id="1894" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">我们开始吧！</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi lz"><img src="../Images/1d83ee04a470264d0ce263bc23f3cf58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*86xf22X0QEKqm8sX.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">深度神经网络的灵感来自我们大脑的理论，图片来自<a class="ae lt" href="https://pixabay.com/illustrations/artificial-neural-network-ann-3501528/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="71e4" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">受数学和神经科学启发的深度神经网络</h1><blockquote class="ki"><p id="39e2" class="kj kk it bd kl km kt ku kv kw kx ks dk translated">“这是最糟糕的时候，其他人都在做不同的事情。”</p><p id="e352" class="kj kk it bd kl km kt ku kv kw kx ks dk translated">——本吉奥，CIFAR 项目的联合主任</p></blockquote><h2 id="f286" class="no mx it bd my np nq dn nc nr ns dp ng lh nt nu ni ll nv nw nk lp nx ny nm nz bi translated">神经网络简史</h2><p id="39de" class="pw-post-body-paragraph ky kz it la b lb oa ju ld le ob jx lg lh oc lj lk ll od ln lo lp oe lr ls ks im bi translated">1943 年，神经生理学家沃伦·麦卡洛克和数学家沃尔特·皮茨基于称为<a class="ae lt" href="https://en.wikipedia.org/wiki/Artificial_neuron" rel="noopener ugc nofollow" target="_blank">阈值逻辑单元(TLU) </a>的数学算法创建了计算模型，以描述神经元可能如何工作。在 20 世纪 50 年代计算机变得更加先进之前，模拟神经网络是可能的。</p><p id="a9e6" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">在 2000 年之前，这被认为是最糟糕的研究领域之一。LeCun 和 Hinton 以不同的方式提到了在这一时期他们的论文是如何由于他们的主题是神经网络而被拒绝发表的。人工神经元被认为是无用的，因为它的单个神经元甚至不能解决<a class="ae lt" href="https://www.quora.com/What-is-XOR-problem-in-neural-networks" rel="noopener ugc nofollow" target="_blank"> XOR </a>逻辑。</p><p id="7a58" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">这项研究由加拿大高级研究所资助。在该领域所有研究人员的不断努力下，Krizhevsky、Sutskever 和 Hinton 凭借卷积神经网络(CNN)赢得了 2012 年的 ImageNet 竞赛，卷积神经网络是 Yann LeCun 在 1998 年首次创建的模型。此后，深度神经网络几乎出现在每一篇论文中。</p><p id="0253" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">神经网络之所以在诞生后的很长一段时间里如此成功，还有其他原因。首先，这些模型严重依赖于计算能力，随着这些年来我们的计算机变得越来越先进，它们最终变得更加可行。更重要的是，为了充分训练这种先进的模型，需要大量的数据。在互联网与社交媒体、电子商务和移动设备一起受到消费者欢迎后，每天都会产生大量数据，这为每个人创造大量数字数据增加了更多机会。这些新技术也创造了对计算机视觉(CV)和自然语言处理(NLP)应用的需求。</p><p id="3a95" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">在人工智能领域有两种对立的信念——<strong class="la iu">连接主义和</strong>象征主义。联结主义认为认知科学的方法希望解释智能行为。另一方面，象征主义依赖于基于数学和逻辑运算的推理。虽然许多数学模型成功地完成了给定的任务，但也有足够多的研究表明，基于认知科学的方法确实加速了人工神经网络的学习过程。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi of"><img src="../Images/c1fcb146b346ecfd1259ca4968d9a7e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5rWihCWleWEFMcow.jpg"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">连接主义与象征主义，图片来自<a class="ae lt" href="https://pixabay.com/illustrations/brain-mind-psychology-idea-drawing-2062057/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><h2 id="c808" class="no mx it bd my np og dn nc nr oh dp ng lh oi nu ni ll oj nw nk lp ok ny nm nz bi translated">人工神经网络</h2><p id="546b" class="pw-post-body-paragraph ky kz it la b lb oa ju ld le ob jx lg lh oc lj lk ll od ln lo lp oe lr ls ks im bi translated">术语“深度学习”是一个涉及深度神经网络的领域，意思是具有一个或多个隐藏层的人工神经网络。人工神经网络是一个<a class="ae lt" href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" rel="noopener ugc nofollow" target="_blank">有向无环图(DAG) </a>由人工神经元的连接层组成。这些人工神经元也被称为“感知器”，因此人工神经网络有时被称为多层感知器(MLP)。这些值将被输入到输入层，这是网络的第一层，结果将从输出层出来，这是最后一层。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/643f9039b540d2684a4dea86febab4f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*9J633M_MQ9p_4CXeun-3pQ.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">人工神经网络(ANN)，有时也称为多层感知器(MLP)</p></figure><p id="70ea" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">我们可以将多层感知器视为一种投票方案，为了得出一个决定，输入层的每个感知器向下一层的感知器发送一个加权投票，再下一层……直到投票在输出层的感知器中完成。激活函数通常在中间很陡，以确保激活值位于两端，从而接近二进制判决值。<a class="ae lt" href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.66045&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false" rel="noopener ugc nofollow" target="_blank">这里</a>是我们可以可视化人工神经网络如何分类数据的地方。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi om"><img src="../Images/b53f91c18adc77cd4b726abc56e4de7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PZCrPqq5Gq4Oa2Io3jeL5w.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">人工神经网络如何工作</p></figure><p id="c2f3" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated"><strong class="la iu">正向传播&amp;激活函数</strong></p><p id="63b2" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">在每一层中，有许多相互连接的感知器。感知器之间的机制可以由以下术语定义:</p><ul class=""><li id="1a85" class="on oo it la b lb lu le lv lh op ll oq lp or ks os ot ou ov bi translated"><strong class="la iu">激活(<em class="ow"> a </em> ) </strong>:感知器的激活是通过对前一层感知器的激活求和，加上一个偏差，然后通过激活函数进行转换来计算的。</li><li id="c863" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu"> Bias ( <em class="ow"> b </em> ) </strong>:每次感知器接收到一个值，就会对该值应用一个 Bias。</li><li id="3a4e" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu">权重(<em class="ow"> w </em> ) </strong>:感知器的激活值将被乘以一个权重并相加。</li><li id="128b" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu">激活函数(<em class="ow"> σ </em> ) </strong>:从激活函数计算每个感知器的激活值。</li></ul><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/1d2efb477644eb903b9bb824687ac4f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*zBpFcvvGqjsPTAWuxLCQjQ.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">感知器背后的数学</p></figure><p id="f758" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">有几种类型的激活功能。Sigmoid 函数(σ)，经常与<a class="ae lt" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank">学习曲线</a>有关，是最基本的一个。每个激活功能都有其特点。整流线性单元(ReLU)是最受欢迎的一种。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi pd"><img src="../Images/94be0586e66031c0d308b34b7c758163.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ogru_TEf0pJ2U7zm.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated"><a class="ae lt" href="https://medium.com/@shrutijadon10104776/survey-on-activation-functions-for-deep-learning-9689331ba092" rel="noopener">不同的激活函数及其图形</a></p></figure><p id="de11" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">每个感知器会将其值传播到前进层的感知器中，最终到达输出层。这个过程被称为<strong class="la iu">正向传播</strong>。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi pe"><img src="../Images/da9944d0b8ba244c6b008a71ab3d1648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ocCGPw2FN9B-q6nf77V1Ng.gif"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">人工神经网络的前向传播</p></figure><p id="a559" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated"><strong class="la iu">反向传播&amp;成本函数</strong></p><p id="b97a" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">前向传播基于权重、偏差和激活函数，但是是什么决定了这些值呢？激活函数是预先选择的，但是对于大型神经网络，不可能手动选择适当的权重和偏差。</p><p id="529c" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">在机器学习领域，模型应该自己从数据中“学习”，这个学习过程也称为“训练”。通常，数据被分成 2 个不同的集合——训练集合<strong class="la iu">和测试集合<strong class="la iu"/>。训练集用于将模型“训练”到更成熟的状态，然后性能将由测试集进行评估。</strong></p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/e79a669af7063cfbc20e0ab1494c6ee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*Lebu5-odN_7u03ZjbeRKBA.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">传统算法与机器学习的比较</p></figure><p id="b462" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">有许多不同的方法来“训练”一个人工神经网络，但最流行的方法是使用<strong class="la iu">反向传播</strong>。</p><p id="558a" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">在反向传播之前，神经网络的权重和偏差通常以正态分布随机初始化。然后，神经网络将执行前向传播。由于权重和偏差是随机初始化的，所以第一次正向传播的结果通常会相差很远。然后使用<strong class="la iu">成本函数</strong>来计算预期结果和神经网络输出之间的差异。计算出差异后，它将用于调整前一层的权重和偏差。该过程在层中向后传播，因此它被称为“反向传播”。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi pg"><img src="../Images/ed812bed445563f794609815a127c79d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*-tfKpsGYTeDt2s22VXKBAw.gif"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">人工神经网络的反向传播</p></figure><p id="3b4b" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">这里有一个关于反向传播的更正式的教程，因为它需要一些高等数学来解释。神经网络的解释和代码示例可以在<a class="ae lt" href="http://neuralnetworksanddeeplearning.com/" rel="noopener ugc nofollow" target="_blank">这里</a>找到，这里作者使用矩阵运算来模拟 Python 中的神经网络。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ph pi l"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">反向传播解释</p></figure><h2 id="6aa3" class="no mx it bd my np og dn nc nr oh dp ng lh oi nu ni ll oj nw nk lp ok ny nm nz bi translated">卷积神经网络(CNN)</h2><p id="2cea" class="pw-post-body-paragraph ky kz it la b lb oa ju ld le ob jx lg lh oc lj lk ll od ln lo lp oe lr ls ks im bi translated">为了以更好的效率处理图形数据，Yann LeCun 在 1989 年发明了卷积神经网络。该网络计算 2D 阵列的空间信息。卷积神经网络也非常适合分析其他空间信息重要的 2D 数据，包括棋盘。</p><p id="a8de" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">卷积神经网络由 3 种类型的层构成——卷积层、池层和全连接层。这些具有不同形状和大小的层在不同的主题上会有不同的表现。对卷积神经网络的研究通常涉及调整这些层及其组成，以优化目标数据集的性能。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi pj"><img src="../Images/f80cc0d227b37f0a5c6f0a8de7778e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xh36H5xZNFtglRev8gDSjw.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated"><a class="ae lt" href="https://machinelearningmastery.com/review-of-architectural-innovations-for-convolutional-neural-networks-for-image-classification/" rel="noopener ugc nofollow" target="_blank">卷积神经网络的示例架构</a></p></figure><p id="d15d" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated"><strong class="la iu">卷积层(conv) </strong></p><p id="7647" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">卷积层通常作为卷积神经网络的第一层出现。这些类型的图层将使用过滤器扫描源图层，并将总和放入目标图层。一些滤波器擅长检测边缘，一些擅长其他任务，更多关于不同类型卷积滤波器的细节及其在计算机视觉中的应用可以在<a class="ae lt" href="https://www.saama.com/blog/different-kinds-convolutional-filters/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi pk"><img src="../Images/519b4656d223df0b945a0e2bff8cd2a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*e2bNVdMHu4R_x8okU52d4w.gif"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">卷积层(3x3)</p></figure><p id="8f0c" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated"><strong class="la iu">池层(pool) </strong></p><p id="52e2" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">池层遍历源层，并在有界区域内选择一个特定的值。该值通常是该区域内的最大值、最小值和平均值。将信息缩小也称为“缩减采样”。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/8029fbb1058d38e91754e579fa6f9c1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/1*_01Vlh6QQ9f99ACD5dzZMg.gif"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">池层(2x2 最大池)</p></figure><p id="bfb0" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated"><strong class="la iu">全连接层(fc) </strong></p><p id="ad1d" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">全连接层本质上是一个多层感知器，它有时被称为“softmax”，本质上做一些被称为“加权和”的事情。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi pe"><img src="../Images/da9944d0b8ba244c6b008a71ab3d1648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ocCGPw2FN9B-q6nf77V1Ng.gif"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">全连接层只是一个人工神经网络</p></figure><p id="2c8c" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">卷积神经网络最常用于计算机视觉领域，它影响了许多领域，如电子商务、金融科技、游戏人工智能、癌症检测、整形外科、精神病学、野火检测等。这里有一篇关于<a class="ae lt" href="https://medium.com/swlh/how-computer-vision-is-revolutionizing-ecommerce-d05e0ca11765" rel="noopener">计算机视觉如何影响电子商务</a>的文章和另一篇关于计算机视觉中一些很酷的前端框架的文章。</p><h1 id="62bd" class="mw mx it bd my mz pm nb nc nd pn nf ng jz po ka ni kc pp kd nk kf pq kg nm nn bi translated">Alpha Go Zero，用机器学习掌握围棋游戏</h1><blockquote class="ki"><p id="249e" class="kj kk it bd kl km kt ku kv kw kx ks dk translated">“太完美了，简直完美无瑕，毫不留情。…我想我这辈子也追不上它了。”</p><p id="5e7a" class="kj kk it bd kl km kt ku kv kw kx ks dk translated">—柯洁(围棋世界冠军)在输给 Alpha Go Zero 三局后</p></blockquote><p id="828b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls ks im bi translated">恭喜你！！！我们已经到了这篇文章的目的所在。现在我们将准备好了解传说中的国际象棋和围棋人工智能是如何从头到脚工作的。</p><p id="da07" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated"><strong class="la iu">设计 Alpha Go Zero 的架构</strong></p><p id="af48" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">Alpha Go Zero 由卷积神经网络和蒙特卡罗树组成。它通过强化学习算法进行自我游戏训练。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/03352aec6b1ce0d55ce15af58f51333c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/1*I8lZs71t8El0W-xdLyJb5g.gif"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">阿尔法如何归零转弯</p></figure><p id="e8ca" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">有几个术语我们应该熟悉一下。由于 Medium 不支持大多数字母的下标，所以下标由“_”后括号内的字母表示，类似于 LaTeX。</p><ul class=""><li id="811e" class="on oo it la b lb lu le lv lh op ll oq lp or ks os ot ou ov bi translated"><strong class="la iu">状态(s) </strong>:游戏的状态用 s(T)表示，从 s(0)到 s(T)，其中 s(T)为终止状态。</li><li id="b30a" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu">蒙特卡罗树(α) </strong>:蒙特卡罗树α_(θ)用于决定游戏的下一个状态。</li><li id="b49f" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu"> Move (a) </strong>:每个状态 s_(t)的移动 a_(t)由搜索概率π_(t)决定。</li><li id="55fb" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu">搜索概率(π) </strong>:搜索概率π_(t)用于确定在状态 s_(t)下移动 a_(t)。</li><li id="5873" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu">卷积神经网络(f) </strong>:卷积神经网络 f_(θ)用于通过分析棋盘输出价值向量 v 和策略向量 p。</li><li id="d21f" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu">值向量(v) </strong>:值向量 v_(t)表示当前玩家在位置 s_(t)获胜的概率</li><li id="ddbf" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu">策略标量(p) </strong>:策略标量 p_(t)表示移动的概率分布。</li><li id="d025" class="on oo it la b lb ox le oy lh oz ll pa lp pb ks os ot ou ov bi translated"><strong class="la iu">赢家(z) </strong>:赢家 z 被传播回去训练模型。</li></ul><p id="3019" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">Alpha Go Zero 完全通过自我对弈进行训练，仅使用 1 个卷积神经网络，不同于原始 Alpha Go 需要 2 个卷积神经网络，并借用专业人类对弈的信息。</p><p id="e945" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">Alpha Go Zero 将游戏棋盘作为卷积神经网络的原始输入。然后网络输出一个矢量<strong class="la iu"> v </strong>和一个标量<strong class="la iu"> p </strong>。然后，蒙特卡罗树用于计算搜索概率π，该概率用于确定游戏下一阶段的移动。最后，根据游戏规则确定一个获胜者 z，并使用它通过强化学习来训练模型。</p><p id="123d" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">到现在为止，我们已经知道了 Alpha Go Zero 是如何工作的！！！更重要的是，我们已经步入了人工智能的世界。</p><h1 id="973a" class="mw mx it bd my mz pm nb nc nd pn nf ng jz po ka ni kc pp kd nk kf pq kg nm nn bi translated">人工智能的现在和未来</h1><blockquote class="ki"><p id="de73" class="kj kk it bd kl km kt ku kv kw kx ks dk translated">“记住我的话——人工智能比核武器危险得多”</p><p id="e8b1" class="kj kk it bd kl km kt ku kv kw kx ks dk translated">—特斯拉&amp; Space X 首席执行官、OpenAI 联合创始人埃隆·马斯克(Elon Musk)等等……</p></blockquote><p id="e398" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls ks im bi translated">我们在人工智能方面的研究处于一种有趣的状态。在机器学习之前，所有的人工智能都是硬编码的，以我们期望的方式表现。机器学习允许人工智能独立地改进自己，有时会产生意想不到的行为。研究人员观察到，通过将人工智能主体放入环境中，并以一定的规则奖励它们，人工智能主体的智能行为逐渐增加。这可能是迷人的，但想想也很可怕。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="ph pi l"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated"><a class="ae lt" href="https://openai.com/blog/emergent-tool-use/" rel="noopener ugc nofollow" target="_blank">开启 AI 多智能体捉迷藏</a>，智能体，学会了在进化算法下的智能行为</p></figure><p id="d262" class="pw-post-body-paragraph ky kz it la b lb lu ju ld le lv jx lg lh lw lj lk ll lx ln lo lp ly lr ls ks im bi translated">游戏环境中的研究就像数学和物理。就其本身而言，这种研究可能只是好奇想知道和尝试的乐趣，但缺乏任何坚实的价值。然而，它们将为其他更具应用性的科学和工程提供必要的基础。未来掌握在你我手中，我们一起将明天变得更加美好。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="1970" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">作者的笔记</h1><p id="a030" class="pw-post-body-paragraph ky kz it la b lb oa ju ld le ob jx lg lh oc lj lk ll od ln lo lp oe lr ls ks im bi translated">我花了相当多的时间才完成文章的第二部分。我忙于学业和找工作。我是人机交互(HCI)专业的硕士生，但我对许多不同的领域都感兴趣。人工智能就是其中之一。我希望这篇文章对你有所帮助。另外，我非常需要一份工作，所以如果你有适合我的工作，请告诉我。写作也是我的爱好，因为我喜欢把事情弄清楚并与他人分享，所以如果你在 Medium 上跟随我，你会看到更多这样的事情。</p><blockquote class="ki"><p id="d5f1" class="kj kk it bd kl km kt ku kv kw kx ks dk translated">“未来掌握在你我手中，我们一起将明天变得更加美好。”</p><p id="83a1" class="kj kk it bd kl km kt ku kv kw kx ks dk translated">—黄慎，本文作者</p></blockquote></div></div>    
</body>
</html>