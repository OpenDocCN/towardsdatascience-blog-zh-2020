<html>
<head>
<title>Ultimate Beginners Guide to Collecting Text for Natural Language Processing (NLP) with Python — Twitter, Reddit, Genius and More</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 为自然语言处理(NLP)收集文本的入门指南— Twitter、Reddit、Genius 等等</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184?source=collection_archive---------26-----------------------#2020-03-02">https://towardsdatascience.com/ultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184?source=collection_archive---------26-----------------------#2020-03-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8f62" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过 API 和 Web 抓取收集文本</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/331663eaffcf78bf9da558c7faf2e361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Hf3htIV1Y_Nmb-PA"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@ninjason?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">梁杰森</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="1fb9" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">进入自然语言处理领域</h1><p id="ebd7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">自从一年多前进入数据科学以来，我一直对自然语言处理(NLP)着迷。由于迁移学习的进步，该领域已经取得了一些爆炸性的进展，像 Alexa 和 Siri 这样的 NLP 产品已经成为家喻户晓的名字。由于我的背景是技术写作和修辞理论，我立即被涉及文本的项目吸引，如情感分析和主题提取，因为我想了解机器学习如何提供对书面语言的洞察力。<a class="ae ky" rel="noopener" target="_blank" href="/generating-wine-recommendations-using-the-universal-sentence-encoder-d086edd13d00">我的第一个数据科学项目是使用谷歌的通用句子编码器来产生葡萄酒推荐</a>。</p><p id="2d29" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我一直想要一个像这样的指南，分解如何从流行的社交媒体平台提取数据。随着对 BERT 和 ELMo 等强大的预训练语言模型<a class="ae ky" href="https://www.analyticsvidhya.com/blog/2019/03/pretrained-models-get-started-nlp/" rel="noopener ugc nofollow" target="_blank">的可访问性增加，了解在哪里查找和提取数据变得非常重要。幸运的是，社交媒体是收集 NLP 数据集的丰富资源，只需几行 Python 代码就可以轻松访问。在文章的最后，我还提供了一个流行的 Kaggle NLP 数据集列表，并链接到新的搜索引擎 Google Dataset Search。</a></p><h1 id="6ec6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">先决条件</h1><p id="9169" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文教你如何从 Twitter、Reddit 和 Genius 中提取数据。我假设你已经知道一些 Python 库<a class="ae ky" href="https://medium.com/datadriveninvestor/python-pandas-library-for-beginners-a-simplified-guide-for-getting-started-and-ditching-20992b7cd4da" rel="noopener"> Pandas </a>和<a class="ae ky" href="https://medium.com/@erickleppen01/learn-sql-techniques-selecting-data-and-more-in-sql-server-624f81dd16b2" rel="noopener"> SQLite </a>。</p><h1 id="142c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">管理您的 API 密钥</h1><p id="58ce" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在进入代码之前，强调 API 键的值是很重要的。如果您是管理 API 密钥的新手，请确保将它们保存到 config.py 文件中，而不是在您的应用程序中硬编码它们。确保不要将它们包含在任何在线代码共享中。<strong class="lt iu"> API 密钥可能非常有价值，有时非常昂贵，必须加以保护</strong>。如果您担心您的密钥被泄露，大多数提供商允许您重新生成密钥。</p><p id="6f5a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/a-simple-git-workflow-for-github-beginners-and-everyone-else-87e39b50ee08"> <strong class="lt iu"> <em class="ms">把 config 文件添加到你的 gitignore 文件中，防止它也被推送到你的 repo 中</em> </strong> <em class="ms">！</em> </a></p><h1 id="642a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Twitter API</h1><p id="33a7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Twitter 提供了大量的数据，很容易通过他们的 API 访问。使用 Tweepy Python 库，可以根据所需主题轻松获取持续的推文流。Twitter 非常适合挖掘趋势和情绪，</p><p id="1fed" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于本教程，<a class="ae ky" href="https://developer.twitter.com/en.html" rel="noopener ugc nofollow" target="_blank">你需要在 Twitter 上注册一个应用程序来获得 API 密匙</a>。如果你不熟悉 Twitter 的开发者门户，请查看官方的 Twitter 文档！</p><p id="3c71" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用 pip 安装 Tweepy 和 unidecode。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="2cc7" class="my la it mu b gy mz na l nb nc">pip install tweepy<br/>pip install <em class="ms">unidecode</em></span></pre><p id="da97" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将以下密钥保存到配置文件中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/2ae253338041faa89bd2daa8fa0f516f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a9wH1g35smMLUd1f4S-KjA.png"/></div></div></figure><h1 id="526f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">使用 Tweepy</h1><p id="a707" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">将 Tweepy 连接到 Twitter 使用了<a class="ae ky" href="https://en.wikipedia.org/wiki/OAuth" rel="noopener ugc nofollow" target="_blank"> OAuth1 </a>。如果您是 API 认证的新手，请查看<a class="ae ky" href="http://docs.tweepy.org/en/latest/auth_tutorial.html" rel="noopener ugc nofollow" target="_blank">官方 Tweepy 认证教程</a>。</p><p id="4d8d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了保存来自传入流的数据，我发现最简单的方法是将其保存到 SQLite 数据库中。如果您不熟悉 SQL 表或者需要复习，请查看这个免费网站的示例或者查看<a class="ae ky" href="https://medium.com/@erickleppen01/learn-sql-techniques-selecting-data-and-more-in-sql-server-624f81dd16b2" rel="noopener">我的 SQL 教程</a>。</p><p id="da88" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">函数<strong class="lt iu"> <em class="ms"> unidecode() </em> </strong>获取 Unicode 数据，并尝试用 ASCII 字符表示它。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="fb9f" class="my la it mu b gy mz na l nb nc">#import dependencies<br/>import tweepy<br/>from tweepy import OAuthHandler<br/>from tweepy.streaming import StreamListener<br/>import json<br/>from unidecode import unidecode<br/>import time<br/>import datetime</span><span id="d5ba" class="my la it mu b gy ne na l nb nc">#import the API keys from the config file.<br/>from config import con_key, con_sec, a_token, a_secret </span><span id="bfdb" class="my la it mu b gy ne na l nb nc">sqlite3conn = sqlite3.connect("twitterStream.sqlite")<br/>c = conn.cursor()</span></pre><p id="e08a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我需要创建表来存储葡萄酒数据。我使用 SQLite 是因为它是轻量级的和无服务器的。另外，我喜欢把所有的数据都放在一个地方！</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="d583" class="my la it mu b gy mz na l nb nc">def create_table():<br/>    c.execute("CREATE TABLE IF NOT EXISTS Tweets(timestamp REAL, tweet TEXT)")<br/>    conn.commit()</span><span id="da5b" class="my la it mu b gy ne na l nb nc">create_table()</span></pre><p id="63ed" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意，如果不存在，我使用<strong class="lt iu">来确保该表在数据库中不存在。记住使用<strong class="lt iu"><em class="ms">conn . commit()</em></strong>调用提交事务。</strong></p><h2 id="fe67" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">创建一个 StreamListner 类</h2><p id="e73b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下面是一些样板代码，用于从流 twitter 数据中提取 tweet 和时间戳，并将其插入数据库。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0e3e" class="my la it mu b gy mz na l nb nc">class Listener(StreamListener):<br/>    <br/>    def on_data(self, data):<br/>        <strong class="mu iu">try:</strong><br/>            data = json.loads(data)<br/>            tweet = unidecode(data['text'])<br/>            time_ms = data['timestamp_ms']<br/>            #print(tweet, time_ms)<br/>            c.execute("INSERT INTO Tweets (timestamp, tweet) VALUES (?, ?)", (time_ms, tweet))<br/>            <br/>            conn.commit()<br/>            <strong class="mu iu">time.sleep(2)</strong><br/>        <strong class="mu iu">except KeyError as e</strong>:<br/>            <br/>                print(str(e))<br/>        return(True)<br/>        <br/>    def on_error(self, status_code):<br/>        if status_code == 420:<br/>            #returning False in on_error disconnects the stream<br/>            return False</span><span id="4ad7" class="my la it mu b gy ne na l nb nc"><strong class="mu iu">while True</strong>:<br/>       try:<br/>            auth = OAuthHandler(con_key, con_sec)<br/>            auth.set_access_token(a_token, a_secret)<br/>            twitterStream = tweepy.Stream(auth, Listener())<br/>            <strong class="mu iu">twitterStream.filter</strong>(track=['DataScience'])<br/>       except Exception as e:<br/>            print(str(e))<br/>            time.sleep(4)</span></pre><p id="14a4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请注意，我使用<strong class="lt iu"> <em class="ms"> time.sleep() </em> </strong>来减缓流的速度。<br/>注意，代码被包装在 try/except 中，以防止潜在的中断中断流。此外，<a class="ae ky" href="https://developer.twitter.com/en/docs/basics/response-codes" rel="noopener ugc nofollow" target="_blank">文档建议</a>使用一个<strong class="lt iu"> <em class="ms"> on_error() </em> </strong>函数，在应用发出过多请求时充当断路器。<br/>注意，我将流对象包装在一个<em class="ms"> while 条件中。</em>这样，如果遇到 420 错误，它就会停止。<br/>注意<strong class="lt iu"><em class="ms">twitterstream . filter</em></strong>使用<em class="ms"> track </em>在推文中查找关键词。如果你想关注特定用户的推文，使用<strong class="lt iu"> <em class="ms">。过滤(follow=[""]) </em> </strong>。</p><p id="d6c1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">从 SQLite 数据库中提取数据</strong></p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="3444" class="my la it mu b gy mz na l nb nc">sql = '''select tweet from Tweets <br/>                where tweet not like 'RT %'<br/>                order by timestamp desc'''<br/>tweet_df = pd.read_sql(sql, conn)<br/>tweet_df</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/f7b4c111b564a66b9a89b3e8a116425f.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*qkE7AaxaoDV1Bkfj1ZLN6Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">示例推文数据帧</p></figure><h1 id="0c92" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Reddit API</h1><p id="2f38" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">像 Twitter 一样，社交网络 Reddit 包含了令人瞠目结舌的大量信息，很容易收集。这是一个像互联网论坛一样工作的社交网络，允许用户发表任何他们想要的话题。用户组成名为<em class="ms"> subreddits </em>的社区，他们对社区中的帖子投赞成票或反对票，以决定哪些帖子先被浏览，哪些帖子沉到底部。</p><p id="b87a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我将解释如何获得 Reddit API 键，以及如何使用 PRAW 库从 Reddit 提取数据。虽然<a class="ae ky" href="https://www.reddit.com/dev/api/" rel="noopener ugc nofollow" target="_blank"> Reddit 有一个 API </a>，但是<a class="ae ky" href="https://praw.readthedocs.io/en/latest/getting_started/quick_start.html#" rel="noopener ugc nofollow" target="_blank"> Python Reddit API 包装器，或者简称为 PRAW，提供了一个简化的体验</a>。PRAW 支持 Python 3.5+版本</p><h1 id="6845" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Reddit API 入门</h1><p id="3cb1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">需要 Reddit 的用户帐户才能使用 API。这是完全免费的，只需要一个电子邮件地址！</p><p id="0558" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://www.reddit.com/" rel="noopener ugc nofollow" target="_blank">https://www.reddit.com</a></p><h2 id="a33f" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">为钥匙注册应用程序</h2><p id="5cbd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果有办法使用新的 Reddit 用户界面，请给我留言！如果您是第一次登录 Reddit，请按照以下步骤获取 API 密钥。如果您已经有了密钥，<a class="ae ky" href="https://old.reddit.com/prefs/apps/" rel="noopener ugc nofollow" target="_blank">使用此链接转到您的应用页面</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/03555d8b8cab9c48b75b55d1acebcb03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S2ERGNX9yyMcykTG.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">reddit.com 用户帐户按钮</p></figure><p id="2469" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">点击<strong class="lt iu">用户账号</strong>下拉列表。显示用户选项。</p><p id="8c50" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从用户选项中点击<strong class="lt iu">访问旧 Reddit </strong>。页面会改变，网址会变成 h<a class="ae ky" href="https://old.reddit.com/" rel="noopener ugc nofollow" target="_blank">ttps://old . Reddit . com/</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/2b1c8aa0088532ed812d456ce7d247d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dcYjveDmMULKbthY.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">偏好；喜好；优先；参数选择</p></figure><p id="7412" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">点击注销按钮旁边的<strong class="lt iu">首选项</strong>链接。<br/>点击首选项屏幕上的<strong class="lt iu">应用</strong>标签。<br/>点击<strong class="lt iu">你是开发者吗？创建 am 应用程序</strong> …按钮。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/34ceb143f0d1e9b9381f07c9283b1158.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qJyF9HR--UKwuyrC.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">注册 Reddit 应用程序</p></figure><p id="7f51" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">输入一个<strong class="lt iu">名</strong>。<br/>选择<strong class="lt iu"> app </strong>的类型。<br/>输入一个<strong class="lt iu">描述</strong>。<br/> <a class="ae ky" href="https://praw.readthedocs.io/en/latest/getting_started/authentication.html#code-flow" rel="noopener ugc nofollow" target="_blank">使用 http://localhost:8080 作为<strong class="lt iu">重定向 uri </strong> </a>。<br/>填写完字段后，点击<strong class="lt iu">创建应用</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/1903ac63e525b0c1660c86a66bdc7076.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/0*NerxWcWN-DMvMWEJ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Reddit API 客户端</p></figure><p id="7905" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将显示连接所需的 API 信息。当我开始写代码时，我将通过 PRAW 连接到 API。</p><p id="8f78" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">祝贺你开始收集 Reddit 数据！</p><h1 id="fbc0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">使用 PRAW 提取 Reddit 数据</h1><p id="f156" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">安装 PRAW 的推荐方法是使用 pip 。安装以下软件包来创建仪表板。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="e0f9" class="my la it mu b gy mz na l nb nc"><strong class="mu iu">pip install praw</strong></span></pre><p id="e01b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">首先导入库和配置文件:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="194f" class="my la it mu b gy mz na l nb nc">import praw<br/>import pandas as pd <br/>from config import cid, csec, ua</span></pre><h2 id="1b51" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">创建 Reddit 实例</h2><p id="6315" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">创建一个只读 Reddit 实例。这意味着我不需要输入用于发布回复或创建新主题的 Reddit 凭据；该连接只读取数据。</p><p id="0680" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">PRAW 使用 OAuth 认证来连接 Reddit API。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="abf8" class="my la it mu b gy mz na l nb nc">#create a reddit connection<br/>reddit = praw.Reddit(client_id= cid,<br/>                     client_secret= csec,<br/>                     user_agent= ua)</span></pre><h2 id="1972" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">识别子记录</h2><p id="da8c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">以下是我认为值得探究的一些例子:</p><p id="c60c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">新闻，数据科学，学习机器学习，游戏，搞笑，政治</p><h2 id="bba4" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">探索对象和属性</h2><p id="1956" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">使用 PRAW 中的 Subreddit 类从所需的 subreddit 中检索数据。可以根据以下 Reddit 选项对数据进行排序:</p><ul class=""><li id="c875" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><strong class="lt iu">热门</strong>——按访问量最大的帖子排序</li><li id="9459" class="nv nw it lt b lu oe lx of ma og me oh mi oi mm oa ob oc od bi translated"><strong class="lt iu">新</strong> —按帖子最新的帖子排序</li><li id="b5de" class="nv nw it lt b lu oe lx of ma og me oh mi oi mm oa ob oc od bi translated"><strong class="lt iu">置顶</strong> —按投票最多的帖子排序</li><li id="4eff" class="nv nw it lt b lu oe lx of ma og me oh mi oi mm oa ob oc od bi translated"><strong class="lt iu">上升</strong> —按帖子人气排序</li></ul><p id="4a49" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您想要包含多个子编辑，请使用<strong class="lt iu"> + </strong>符号:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="dfac" class="my la it mu b gy mz na l nb nc">#single subreddit new 5<br/>subreddit = reddit.subreddit('news').new(limit = 5)</span><span id="2b66" class="my la it mu b gy ne na l nb nc">#multiple subreddits top 5<br/>subreddit = reddit.subreddit('news' + 'datascience').top(limit = 5)</span></pre><p id="27ad" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这将返回一个<em class="ms">对象</em>，它将数据保存在一个<em class="ms">属性</em>中。该属性就像<a class="ae ky" href="https://www.w3schools.com/python/python_dictionaries.asp" rel="noopener ugc nofollow" target="_blank"> <em class="ms">字典</em> </a>中的<em class="ms">键</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/d0f1c780d639432c25ca1b622158dfd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/0*EJIY6htp1aJhjizR.png"/></div></figure><p id="c380" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">数据链接到对象所拥有的属性。如果<em class="ms">属性</em>为<em class="ms">键</em>，则<em class="ms">数据</em>为<em class="ms">值</em>。属性是动态生成的，所以最好使用 Python 的内置<strong class="lt iu"> vars() </strong>函数来检查哪些是可用的。</p><p id="52cf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">使用这个样板代码来查看代表 reddit 帖子</strong>的对象所拥有的所有属性。这是一个很长的列表！</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="021f" class="my la it mu b gy mz na l nb nc">subreddit = reddit.subreddit('news').new(limit = 1)<br/>for post in subreddit:<br/>    pprint.pprint(vars(post))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/bdf11a06398ed6b3314a4def0718eb80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/0*aJr1cWiO7xFse6xw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">发布对象属性的示例</p></figure><p id="0f25" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请注意列表中感兴趣的属性:</p><p id="a5f7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">标题</strong> —返回文章标题。<br/> <strong class="lt iu">得分</strong> —返回赞成票或反对票的数量。<br/> <strong class="lt iu"> num_comments </strong> —返回线程上的注释数量。<br/> <strong class="lt iu"> selftext </strong> —返回帖子的正文。<br/> <strong class="lt iu">创建的</strong> —返回文章的时间戳。<br/> <strong class="lt iu">钉住</strong> —表示线程是否被钉住。<br/><strong class="lt iu">total _ awards _ received</strong>—返回帖子获得的奖项数。</p><h2 id="f8bc" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">保存 Reddit 数据</h2><p id="b722" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">既然已经确定了属性，就将它们的数据加载到 pandas 数据帧中，或者保存到 SQLite 数据库中，就像 Twitter 示例中那样。在这个例子中，我将把它保存到一个熊猫数据帧中。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="b586" class="my la it mu b gy mz na l nb nc">#list for df conversion<br/>posts = []</span><span id="596c" class="my la it mu b gy ne na l nb nc">#return 100 new posts from wallstreetbets<br/>new_bets = reddit.subreddit('wallstreetbets').new(limit=100)</span><span id="46ce" class="my la it mu b gy ne na l nb nc">#return the important attributes<br/>for post in new_bets:<br/>    posts.append([post.title, post.score, post.num_comments, post.selftext, post.created, post.pinned, post.total_awards_received])</span><span id="8d6f" class="my la it mu b gy ne na l nb nc">#create a dataframe<br/>posts = pd.DataFrame(posts,columns=['title', 'score', 'comments', 'post', 'created', 'pinned', 'total awards'])</span><span id="be4f" class="my la it mu b gy ne na l nb nc">#return top 3 df rows<br/>posts.head(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/8ec9c09d46f7ea4a78dad74ab94f42aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fw0XLTagtHGTfvloH2TtqA.png"/></div></div></figure><h1 id="c603" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">天才歌词</h1><p id="a550" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我一直是音乐迷，尤其是重金属。在重金属中，歌词有时很难理解，所以我去 Genius 破译它们。网站<a class="ae ky" href="https://genius.com/Genius-about-genius-annotated" rel="noopener ugc nofollow" target="_blank">Genius.com</a>是一个注释歌词、收集关于音乐、专辑和艺术家的琐事的平台。Genius 允许用户注册一个 API 客户端。</p><p id="2278" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://genius.com/api-clients" rel="noopener ugc nofollow" target="_blank">https://genius.com/api-clients</a></p><h2 id="0ac8" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">API 客户端注册</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/313deeb499bf42e0f1edecd8e5ee1306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r_TuXW1kUunFHGUZuynYBA.png"/></div></div></figure><p id="67e6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要么报名，要么签到。<br/>点击开发者链接。<br/>点击创建 API 客户端。<br/>输入一个应用程序名称。<br/>如果有网址就输入网址，否则<a class="ae ky" href="http://127.0.0.1" rel="noopener ugc nofollow" target="_blank"> http://127.0.0.1 </a>就可以了。<br/>点击保存。将显示 API 客户端。<br/>点击生成访问令牌，生成访问令牌。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/d3111f4ceca97d99f4118b22eb69e83b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*KMMfuXgAYZ652CQu8kvT7A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">API 客户端注册工作流</p></figure><h2 id="66c6" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">提取歌词</h2><p id="0f62" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">令人惊讶的是，由于<a class="ae ky" href="https://genius.com/discussions/277279-Get-the-lyrics-of-a-song" rel="noopener ugc nofollow" target="_blank">法律原因</a>，Genius API 并没有提供下载歌词的方式。可以搜索歌词，但不能下载。对每个人来说幸运的是，Medium 作者<a class="oo op ep" href="https://medium.com/u/f27d15a817ec?source=post_page-----256d113e6184--------------------------------" rel="noopener" target="_blank"> Ben Wallace </a> <a class="ae ky" href="https://medium.com/linebyline/mac-miller-a-lyrical-analysis-and-admiration-33f5d6575ee4" rel="noopener">为我们提供了一个方便的抓取歌词的包装器</a>。也可以在 GitHub 上找到他的原始代码:</p><div class="oq or gp gr os ot"><a href="https://github.com/benfwalla/MusicAnalysis" rel="noopener  ugc nofollow" target="_blank"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">benfwalla/音乐分析</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">github.com</p></div></div><div class="pc l"><div class="pd l pe pf pg pc ph ks ot"/></div></div></a></div><p id="cd3e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我修改了他的包装器，以便更容易下载艺术家的完整作品，而不是对我想要包含的专辑进行编码，并且我添加了一个艺术家列来存储艺术家的名字。</p><p id="ccf5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">包装器使用 API 获取链接到歌词的 URL。从那里，BeautifulSoup 用于解析每个 URL 的 HTML。该过程产生包含标题、URL、艺术家、专辑和歌词的数据帧:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/4b15981ff0311dfb66bce7872ff461e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4xaXV2C-4AS9fPvzQo6SMg.png"/></div></div></figure><h2 id="7c55" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">查看 GeniusArtistDataCollect 包装</h2><p id="58c8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">包装器是一个名为<strong class="lt iu">geniusartisdatacollect()</strong>的类。使用它连接到 API 并检索指定艺术家的歌词。在这个例子中，我使用了我最喜欢的金属乐队之一，黑色大丽花谋杀。</p><p id="5258" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要使用<strong class="lt iu">geniusartisdatacollect()</strong>，实例化它，传入<em class="ms">客户端访问令牌</em>和<em class="ms">艺术家名字</em>。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="9e35" class="my la it mu b gy mz na l nb nc">g = GeniusArtistDataCollect(token, 'The Black Dahlia Murder')</span></pre><p id="5219" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从<em class="ms">geniusartistdata collect</em>对象中调用<strong class="lt iu"> get_artists_songs() </strong>。这将作为熊猫<em class="ms">数据帧</em>返回。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="2e01" class="my la it mu b gy mz na l nb nc">songs_df = g.get_artist_songs()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/48393057efc0b7acfc302c7767068c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6QrIC46YH5R3IM9dEMil5Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">songs_df = g.get_artist_songs()</p></figure><h2 id="f00a" class="my la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">包装纸</h2><p id="2567" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下面是我在示例中使用的修改后的包装器:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="d4f1" class="my la it mu b gy mz na l nb nc">import os<br/>import re<br/>import requests<br/>import pandas as pd<br/>import urllib.request<br/>from bs4 import BeautifulSoup<br/>from config import token<br/></span><span id="e9e9" class="my la it mu b gy ne na l nb nc">class GeniusArtistDataCollect:<br/>    """A wrapper class that is able to retrieve, clean, and organize all the album songs of a given artist<br/>    Uses the Genius API and webscraping techniques to get the data."""</span><span id="df7e" class="my la it mu b gy ne na l nb nc">def __init__(self, client_access_token, artist_name):<br/>        """<br/>        Instantiate a GeniusArtistDataCollect object<br/>        :param client_access_token: str - Token to access the Genius API. Create one at <a class="ae ky" href="https://genius.com/developers" rel="noopener ugc nofollow" target="_blank">https://genius.com/developers</a><br/>        :param artist_name: str - The name of the artist of interest<br/>        THIS HAS BEEN REMOVED :param albums: list - A list of all the artist's albums to be collected<br/>        """</span><span id="64ba" class="my la it mu b gy ne na l nb nc">self.client_access_token = client_access_token</span><span id="8f81" class="my la it mu b gy ne na l nb nc">self.artist_name = artist_name</span><span id="c6cb" class="my la it mu b gy ne na l nb nc">#self.albums = albums</span><span id="7f43" class="my la it mu b gy ne na l nb nc">self.base_url = '<a class="ae ky" href="https://api.genius.com/'" rel="noopener ugc nofollow" target="_blank">https://api.genius.com/'</a></span><span id="9690" class="my la it mu b gy ne na l nb nc">self.headers = {'Authorization': 'Bearer ' + self.client_access_token}</span><span id="0e0a" class="my la it mu b gy ne na l nb nc">self.artist_songs = None</span><span id="06cf" class="my la it mu b gy ne na l nb nc">def search(self, query):<br/>        """Makes a search request in the Genius API based on the query parameter. Returns a JSON response."""</span><span id="19c5" class="my la it mu b gy ne na l nb nc">request_url = self.base_url + 'search'<br/>        data = {'q': query}<br/>        response = requests.get(request_url, data=data, headers=self.headers).json()</span><span id="25c7" class="my la it mu b gy ne na l nb nc">return response</span><span id="a280" class="my la it mu b gy ne na l nb nc">def get_artist_songs(self):<br/>        """Gets the songs of self.artist_name and places in a pandas.DataFrame"""</span><span id="8441" class="my la it mu b gy ne na l nb nc"># Search for the artist and get their id<br/>        search_artist = self.search(self.artist_name)<br/>        artist_id = str(search_artist['response']['hits'][0]['result']['primary_artist']['id'])</span><span id="d7ec" class="my la it mu b gy ne na l nb nc">print("ID: " + artist_id)</span><span id="25ea" class="my la it mu b gy ne na l nb nc"># Initialize DataFrame<br/>        df = pd.DataFrame(columns=['Title', 'URL'])</span><span id="03ba" class="my la it mu b gy ne na l nb nc"># Iterate through all the pages of the artist's songs<br/>        more_pages = True<br/>        page = 1<br/>        i = 0<br/>        while more_pages:</span><span id="3347" class="my la it mu b gy ne na l nb nc">print("page: " + str(page))</span><span id="7b8a" class="my la it mu b gy ne na l nb nc"># Make a request to get the songs of an artist on a given page<br/>            request_url = self.base_url + 'artists/' + artist_id + '/songs' + '?per_page=50&amp;page=' + str(page)<br/>            response = requests.get(request_url, headers=self.headers).json()</span><span id="882e" class="my la it mu b gy ne na l nb nc">print(response)</span><span id="e68e" class="my la it mu b gy ne na l nb nc"># For each song which the given artist is the primary_artist of the song, add the song title and<br/>            # Genius URL to the DataFrame<br/>            for song in response['response']['songs']:</span><span id="2e46" class="my la it mu b gy ne na l nb nc">if str(song['primary_artist']['id']) == artist_id:</span><span id="998c" class="my la it mu b gy ne na l nb nc">title = song['title']<br/>                    url = song['url']</span><span id="72ce" class="my la it mu b gy ne na l nb nc">df.loc[i] = [title, url]<br/>                    i += 1</span><span id="474f" class="my la it mu b gy ne na l nb nc">page += 1</span><span id="dbb8" class="my la it mu b gy ne na l nb nc">if response['response']['next_page'] is None:<br/>                more_pages = False</span><span id="0501" class="my la it mu b gy ne na l nb nc"># Get the HTML, Album Name, and Song Lyrics from helper methods in the class<br/>        df['Artist'] = self.artist_name<br/>        df['html'] = df['URL'].apply(self.get_song_html)<br/>        df['Album'] = df['html'].apply(self.get_album_from_html)<br/>        #df['InAnAlbum'] = df['Album'].apply(lambda a: self.is_track_in_an_album(a, self.albums))<br/>        #df = df[df['InAnAlbum'] == True]<br/>        df['Lyrics'] = df.apply(lambda row: self.get_lyrics(row.html), axis=1)</span><span id="9261" class="my la it mu b gy ne na l nb nc">del df['html']</span><span id="4883" class="my la it mu b gy ne na l nb nc">self.artist_songs = df</span><span id="fb45" class="my la it mu b gy ne na l nb nc">return self.artist_songs</span><span id="61aa" class="my la it mu b gy ne na l nb nc">def get_song_html(self, url):<br/>        """Scrapes the entire HTML of the url parameter"""</span><span id="291d" class="my la it mu b gy ne na l nb nc">request = urllib.request.Request(url)<br/>        request.add_header("Authorization", "Bearer " + self.client_access_token)<br/>        request.add_header("User-Agent",<br/>                           "curl/7.9.8 (i686-pc-linux-gnu) libcurl 7.9.8 (OpenSSL 0.9.6b) (ipv6 enabled)")<br/>        page = urllib.request.urlopen(request)<br/>        html = BeautifulSoup(page, "html")</span><span id="0ddf" class="my la it mu b gy ne na l nb nc">print("Scraped: " + url)<br/>        return html</span><span id="af77" class="my la it mu b gy ne na l nb nc">def get_lyrics(self, html):<br/>        """Scrapes the html parameter to get the song lyrics on a Genius page in one, large String object"""</span><span id="008f" class="my la it mu b gy ne na l nb nc">lyrics = html.find("div", class_="lyrics")</span><span id="ea86" class="my la it mu b gy ne na l nb nc">all_words = ''</span><span id="b249" class="my la it mu b gy ne na l nb nc"># Clean lyrics<br/>        for line in lyrics.get_text():<br/>            all_words += line</span><span id="1e54" class="my la it mu b gy ne na l nb nc"># Remove identifiers like chorus, verse, etc<br/>        all_words = re.sub(r'[\(\[].*?[\)\]]', '', all_words)</span><span id="ba5a" class="my la it mu b gy ne na l nb nc"># remove empty lines, extra spaces, and special characters<br/>        all_words = os.linesep.join([s for s in all_words.splitlines() if s])<br/>        all_words = all_words.replace('\r', '')<br/>        all_words = all_words.replace('\n', ' ')<br/>        all_words = all_words.replace('  ', ' ')</span><span id="9396" class="my la it mu b gy ne na l nb nc">return all_words</span><span id="35e7" class="my la it mu b gy ne na l nb nc">def get_album_from_html(self, html):<br/>        """Scrapes the html parameter to get the album name of the song on a Genius page"""</span><span id="a781" class="my la it mu b gy ne na l nb nc">parse = html.findAll("span")<br/>album = ''</span><span id="290f" class="my la it mu b gy ne na l nb nc">for i in range(len(parse)):<br/>            if parse[i].text == 'Album':<br/>                i += 1<br/>                album = parse[i].text.strip()<br/>                break</span><span id="f3e6" class="my la it mu b gy ne na l nb nc">return album</span></pre><h1 id="0b4c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">另外两个网页抓取例子</h1><p id="85f8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">天才歌词示例使用美丽的汤从网站上刮歌词。Web 抓取是一种有用的技术，它使得收集各种数据变得容易。我在上一篇文章中介绍了一个额外的 web 抓取示例。如果你想多加练习，就去看看吧！</p><div class="oq or gp gr os ot"><a rel="noopener follow" target="_blank" href="/web-scraping-board-game-descriptions-with-python-7b8f6a5be1f3"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">用 Python 编写的网页刮痧板游戏描述</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">我是如何从网上搜集棋盘游戏描述的。</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pk l pe pf pg pc ph ks ot"/></div></div></a></div><p id="a08b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">尽管我还没有使用过他的方法，媒体作家威尔·科尔森已经为搜集和解析维基百科做了一个演示。看看他的作品！</p><div class="oq or gp gr os ot"><a rel="noopener follow" target="_blank" href="/wikipedia-data-science-working-with-the-worlds-largest-encyclopedia-c08efbac5f5c"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">维基百科数据科学:与世界上最大的百科全书合作</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">如何以编程方式下载和解析维基百科</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pl l pe pf pg pc ph ks ot"/></div></div></a></div><h1 id="2548" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Kaggle 和谷歌数据集搜索</h1><p id="3900" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">虽然我认为收集和创建自己的数据集很有趣，但 Kaggle 和谷歌的数据集搜索提供了便捷的方法来找到结构化和标签化的数据。Kaggle 是一个流行的竞争数据科学平台。下面是用于 NLP 项目的流行数据集列表。</p><p id="b10e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://www.kaggle.com/datasets" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/datasets</a>T20】https://datasetsearch.research.google.com/<a class="ae ky" href="https://datasetsearch.research.google.com/" rel="noopener ugc nofollow" target="_blank">T22】</a></p><p id="96ca" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">确定新闻故事是否来自洋葱:</p><ul class=""><li id="2a1e" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><a class="ae ky" href="https://www.kaggle.com/chrisfilo/onion-or-not" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/chrisfilo/onion-or-not</a></li></ul><p id="3d7b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Youtube 排名和描述:</p><ul class=""><li id="9c29" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><a class="ae ky" href="https://www.kaggle.com/datasnaek/youtube-new" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/datasnaek/youtube-new</a></li></ul><p id="33cf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">网飞展示和说明:</p><ul class=""><li id="b87b" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated">https://www.kaggle.com/shivamb/netflix-shows<a class="ae ky" href="https://www.kaggle.com/shivamb/netflix-shows" rel="noopener ugc nofollow" target="_blank"/></li></ul><p id="06f0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">葡萄酒评论。我在几篇文章和项目中使用了它:</p><ul class=""><li id="296e" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated">【https://www.kaggle.com/zynicide/wine-reviews T4】</li></ul><p id="aee9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">亚马逊美食评论集:</p><ul class=""><li id="ce9c" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><a class="ae ky" href="https://www.kaggle.com/snap/amazon-fine-food-reviews" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/snap/amazon-fine-food-reviews</a></li></ul><p id="8134" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">用于假新闻检测的新闻标题:</p><ul class=""><li id="4092" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><a class="ae ky" href="https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/RMI SRA/news-headlines-dataset-for-spirus-detection</a></li></ul><p id="9e0c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">实体识别任务语料库。</p><ul class=""><li id="6376" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><a class="ae ky" href="https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/abhinavwalia 95/entity-annotated-corpus</a></li></ul><p id="6389" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">用于情绪分析的航空公司情绪推文</p><ul class=""><li id="ec04" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><a class="ae ky" href="https://www.kaggle.com/crowdflower/twitter-airline-sentiment" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/crowd flower/Twitter-airline-情操</a></li></ul><p id="5e97" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Yelp 评论数据集</p><ul class=""><li id="7e3e" class="nv nw it lt b lu mn lx mo ma nx me ny mi nz mm oa ob oc od bi translated"><a class="ae ky" href="https://www.kaggle.com/yelp-dataset/yelp-dataset" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/yelp-dataset/yelp-dataset</a></li></ul><h1 id="6dfe" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">包扎</h1><p id="a350" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">随着 NLP 变得越来越主流，了解如何轻松收集丰富的、基于文本的数据集变得非常重要。进入自然语言处理领域可能很难，所以我想分享一个指南，简化收集文本数据的方法。只需几行 Python 代码，Reddit、Twitter 和 Genius 上的惊人数据量人人唾手可得！感谢您的阅读，如果您想使用您知道如何收集的数据，请查看我的其他 NLP 相关文章:</p><h1 id="7413" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">谢谢大家！</h1><ul class=""><li id="99fd" class="nv nw it lt b lu lv lx ly ma pm me pn mi po mm oa ob oc od bi translated"><em class="ms">如果你喜欢这个，</em> <a class="ae ky" href="https://medium.com/@erickleppen" rel="noopener"> <em class="ms">跟我上媒</em> </a> <em class="ms">了解更多</em></li><li id="2314" class="nv nw it lt b lu oe lx of ma og me oh mi oi mm oa ob oc od bi translated"><a class="ae ky" href="https://erickleppen.medium.com/membership" rel="noopener"> <em class="ms">通过订阅</em> </a>获得完全访问权限并帮助支持我的内容</li><li id="01d7" class="nv nw it lt b lu oe lx of ma og me oh mi oi mm oa ob oc od bi translated"><em class="ms">我们连线上</em><a class="ae ky" href="https://www.linkedin.com/in/erickleppen01/" rel="noopener ugc nofollow" target="_blank"><em class="ms">LinkedIn</em></a></li><li id="f6aa" class="nv nw it lt b lu oe lx of ma og me oh mi oi mm oa ob oc od bi translated"><em class="ms">用 Python 分析数据？查看我的</em> <a class="ae ky" href="https://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <em class="ms">网站</em> </a></li></ul><p id="e723" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="http://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> —埃里克·克莱本</strong> </a></p><div class="oq or gp gr os ot"><a rel="noopener follow" target="_blank" href="/analyzing-wine-descriptions-using-the-natural-language-toolkit-in-python-497ac1e228d5"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">使用 Python 中的自然语言工具包分析葡萄酒描述</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">用什么词来形容酒？</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pp l pe pf pg pc ph ks ot"/></div></div></a></div><div class="oq or gp gr os ot"><a href="https://medium.com/swlh/dashboards-in-python-for-beginners-and-everyone-else-using-dash-f0a045a86644" rel="noopener follow" target="_blank"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">Python 中的仪表盘，适用于初学者和使用 Dash 的其他人</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">使用 Python 中的 Dash 初学者教程构建一个基本的和高级的仪表板</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">medium.com</p></div></div><div class="pc l"><div class="pq l pe pf pg pc ph ks ot"/></div></div></a></div><div class="oq or gp gr os ot"><a rel="noopener follow" target="_blank" href="/using-functiontransformer-and-pipeline-in-sklearn-to-predict-chardonnay-ratings-9b13fdd6c6fd"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">在 SkLearn 中使用 FunctionTransformer 和 Pipeline 预测 Chardonnay 评级</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">一个将函数转换成可用的管道代码，然后通过传递数据帧来预测葡萄酒评级的例子…</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pr l pe pf pg pc ph ks ot"/></div></div></a></div></div></div>    
</body>
</html>