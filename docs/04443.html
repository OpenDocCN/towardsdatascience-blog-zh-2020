<html>
<head>
<title>Convolutional Neural Network in Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理中的卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-network-in-natural-language-processing-96d67f91275c?source=collection_archive---------12-----------------------#2020-04-21">https://towardsdatascience.com/convolutional-neural-network-in-natural-language-processing-96d67f91275c?source=collection_archive---------12-----------------------#2020-04-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5a20" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">什么是卷积神经网络，如何利用它进行情感分析？</h2></div><h1 id="7753" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">什么是卷积神经网络？</h1><p id="b3c0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">神经网络是一套用于识别模式的算法。这些模式是包含在向量中的数字，这些向量是从现实世界的数据(如图像、声音、文本或时间序列)转换而来的。卷积神经网络是<strong class="lc iu">将卷积层应用于局部特征的神经网络。</strong></p><p id="5463" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">要理解一个小内核如何转换大量的输入数据，请看下面的gif。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/5d1b77202fceda42a69518230e7d5e38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/0*VMxzrOXL5NKgCwTQ.gif"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">从<a class="ae mn" href="https://stats.stackexchange.com/questions/199702/1d-convolution-in-neural-networks" rel="noopener ugc nofollow" target="_blank">堆栈交换中检索</a></p></figure><p id="c621" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">正如我们所看到的，每个内核在空间上都很小(沿宽度和高度)，但会延伸到输入体积的整个深度，并在滑动时转换输入数据。</p><p id="6509" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">但是如果我们想要不同的输出呢？没问题。我们只需要应用不同的过滤器。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mo"><img src="../Images/bc671a162735ee5ff3b7e6640c345878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*-ubUuglQVhA1h7su4vKIJQ.gif"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">在<a class="ae mn" href="https://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank"> Setosa.io </a>中探索CNN</p></figure><p id="b2cc" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">这些过滤器也可以应用于多维输出。下面的图像以3D方式输入，图像大小为7x7，最后一个维度表示3个颜色通道(红、蓝、绿)。这使得输入大小为7x7x3。然后我们应用2个滤波器<code class="fe mt mu mv mw b">w0</code>和<code class="fe mt mu mv mw b">w1,</code>，每个滤波器的大小为3x3x3，以匹配输入大小。对于输出的维度，我们应该期待什么？3x3x2与<code class="fe mt mu mv mw b">2</code>滤镜的数量。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mx"><img src="../Images/b7ff689097f693348e37628b232f4543.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SGMEV1Pc2FTgPtXf"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">从<a class="ae mn" href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/convolution.html" rel="noopener ugc nofollow" target="_blank"> gitbook </a>中检索</p></figure><h1 id="3ce5" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">自然语言处理中的卷积神经网络</h1><p id="e74e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">因此，我们了解了什么是卷积神经网络，并了解了CNN如何应用于图像。但是CNN在NLP中到底是怎么运作的呢？例如，如果我们有一个句子“我爱我的新iphone ”,我们如何使用CNN来分类这个句子是负面的，正面的，还是中性的？</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi my"><img src="../Images/bf12c851cfba06eeb8c73d541f32918f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/0*Q9QTGlHsQjzIlhBw.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">从<a class="ae mn" href="https://stats.stackexchange.com/questions/256056/how-can-these-filters-be-found-for-such-a-convolutional-neural-network" rel="noopener ugc nofollow" target="_blank">堆栈交换中检索到的图像</a></p></figure><p id="3d07" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">上图从左至右的简短说明:</p><ul class=""><li id="9d62" class="mz na it lc b ld lw lg lx lj nb ln nc lr nd lv ne nf ng nh bi translated">输入是单词。每个单词由一个大小为7的向量表示。</li><li id="029c" class="mz na it lc b ld ni lg nj lj nk ln nl lr nm lv ne nf ng nh bi translated">对单词向量应用4种不同的过滤器来创建卷积特征图</li><li id="0cab" class="mz na it lc b ld ni lg nj lj nk ln nl lr nm lv ne nf ng nh bi translated">为合并表示选择每个过滤器向量的最大结果值</li><li id="f003" class="mz na it lc b ld ni lg nj lj nk ln nl lr nm lv ne nf ng nh bi translated">应用softmax将大小为1x4的向量转换为大小为1x3的向量以进行分类</li></ul><h1 id="fe49" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">通过实例学习:使用PyTorch进行情感分析</h1><p id="3763" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><a class="ae mn" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>是一个Python程序库，有助于构建深度学习项目。如果你不知道PyTorch，可以看看我的文章:</p><div class="nn no gp gr np nq"><a rel="noopener follow" target="_blank" href="/what-is-pytorch-a84e4559f0e3"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd iu gy z fp nv fr fs nw fu fw is bi translated">PyTorch是什么？</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">想想Numpy，但是有强大的GPU加速</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="oa l ob oc od nz oe mh nq"/></div></div></a></div><p id="d838" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">如果你的机器没有GPU，我鼓励你使用<a class="ae mn" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>来尝试代码。我们将使用这个库对Kera的IMDb电影评论数据集进行情感分析。我们的任务是分类评论是正面的还是负面的。</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="0ea9" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">为了建立模型，我们用<code class="fe mt mu mv mw b">nn.Conv2d(in_channels, out_channels, kernel_size)</code>做2D卷积，用<code class="fe mt mu mv mw b">nn.Linear(in_channels, out_channels).</code>做一层线性神经网络进行分类</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="c07c" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">培训步骤</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="42ea" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">想象我们的损失函数</p><pre class="mc md me mf gt oh mw oi oj aw ok bi"><span id="62f2" class="ol kj it mw b gy om on l oo op">import matplotlib.pyplot as plt</span><span id="f37b" class="ol kj it mw b gy oq on l oo op">plt.plot(LOSS)</span></pre><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi or"><img src="../Images/0a87161f277ee5eecc4b653e46fce8b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*JnQvFdG3esQXKsmyA5D_9A.png"/></div></figure><pre class="mc md me mf gt oh mw oi oj aw ok bi"><span id="248a" class="ol kj it mw b gy om on l oo op">print("F1_test: %.5f"%(get_f1(X_test, y_test)))</span></pre><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi os"><img src="../Images/7d36440f93321830eeab74f13b15d898.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*jUXJER95iP5Iw2kPt7kiKw.png"/></div></figure><p id="9a68" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">厉害！我们的CNN模型给了我们0.87的F1分！</p><h1 id="5a77" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结论</h1><p id="5384" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">恭喜你！你已经学习了什么是卷积神经网络，如何用PyTorch申请自然语言处理。我希望这能让你对CNN有一个大致的了解，并有动力在你的深度学习项目中利用这种方法。如果你想更好地了解CNN，维克多·鲍威尔的网站提供了一个很酷的互动视觉效果，展示了当使用CNN的滤镜时，图像是如何变化的。你可以在这里试用一下这篇文章<a class="ae mn" href="https://colab.research.google.com/github/MarioGzSl/SharedKM/blob/master/CNN_for_text.ipynb" rel="noopener ugc nofollow" target="_blank">的代码。</a></p><p id="e18e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在<a class="ae mn" href="https://github.com/khuyentran1401/Data-science/blob/master/nlp/convolutional_neural_network.ipynb" rel="noopener ugc nofollow" target="_blank">这个Github repo </a>中，您可以随意使用本文的代码。</p><p id="725f" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我喜欢写一些基本的数据科学概念，并尝试不同的算法和数据科学工具。你可以在LinkedIn和Twitter上与我联系。</p><p id="78c5" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">如果你想查看我写的所有文章的代码，请点击这里。在Medium上关注我，了解我的最新数据科学文章，例如:</p><div class="nn no gp gr np nq"><a rel="noopener follow" target="_blank" href="/what-graphical-excellence-is-and-how-to-create-it-db02043e0b37"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd iu gy z fp nv fr fs nw fu fw is bi translated">什么是卓越的图形以及如何创建它</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">作为一名数据科学家，了解如何制作重要的图表至关重要</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="ot l ob oc od nz oe mh nq"/></div></div></a></div><div class="nn no gp gr np nq"><a rel="noopener follow" target="_blank" href="/how-to-visualize-social-network-with-graph-theory-4b2dc0c8a99f"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd iu gy z fp nv fr fs nw fu fw is bi translated">如何用图论可视化社交网络</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">找出《权力的游戏》中的影响者</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="ou l ob oc od nz oe mh nq"/></div></div></a></div><div class="nn no gp gr np nq"><a rel="noopener follow" target="_blank" href="/convex-hull-an-innovative-approach-to-gift-wrap-your-data-899992881efc"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd iu gy z fp nv fr fs nw fu fw is bi translated">凸包:包装数据的创新方法</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">如何利用包装算法实现数据可视化</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="ov l ob oc od nz oe mh nq"/></div></div></a></div><div class="nn no gp gr np nq"><a rel="noopener follow" target="_blank" href="/how-to-turn-a-dinosaur-dataset-into-a-circle-dataset-with-the-same-statistics-64136c2e2ca0"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd iu gy z fp nv fr fs nw fu fw is bi translated">恐龙和圆圈的数据集可以有相同的统计数据吗？</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">它们有相同的中位数和标准差，但它们是两个明显不同的数据集！</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="ow l ob oc od nz oe mh nq"/></div></div></a></div><div class="nn no gp gr np nq"><a rel="noopener follow" target="_blank" href="/step-by-step-tutorial-web-scraping-wikipedia-with-beautifulsoup-48d7f2dfa52d"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd iu gy z fp nv fr fs nw fu fw is bi translated">用美丽的声音抓取维基百科</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">关于如何使用Beautiful Soup的分步教程，这是一个用于web抓取的简单易用的Python库</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="ox l ob oc od nz oe mh nq"/></div></div></a></div></div></div>    
</body>
</html>