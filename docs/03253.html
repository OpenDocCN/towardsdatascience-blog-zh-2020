<html>
<head>
<title>Building a Bot That Plays Videos for My Toddler</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为我蹒跚学步的孩子制作一个播放视频的机器人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-bot-that-plays-videos-for-my-toddler-597330d0005e?source=collection_archive---------17-----------------------#2020-03-28">https://towardsdatascience.com/building-a-bot-that-plays-videos-for-my-toddler-597330d0005e?source=collection_archive---------17-----------------------#2020-03-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4d50" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用一个物体检测人工智能模型、一个游戏引擎、一个亚马逊Polly和一个在英伟达(NVIDIA)Jetson Nano上运行的Selenium automation框架来构建Qrio，这是一个可以说话、识别玩具并在YouTube上播放相关视频的机器人。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bac5e238645e18d87a90e55cec48361f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nRCmFZsz6hMNMYHrVtW2Qg.jpeg"/></div></div></figure><p id="1e61" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我和我妻子有一个超级好奇的21个月大的男孩，名叫德歇。虽然他还不会说话，但他真的很喜欢指着东西让我们告诉他是什么。它可以是他最喜欢的书里的一张动物图片，他卡片上的一张汽车图片，或者只是一个玩具。我喜欢和他一起做这项活动，最近我一直在给他看描绘老虎、海豚、火车和其他有趣事物的视频。他真的很喜欢看一只真正的老虎如何走路、吼叫和社交，我认为这对他的认知发展有好处。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lq"><img src="../Images/7c47c52970762a83b2be37291601d52b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KzMhtNDTn1zZEHxRtlx8OQ.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">德协指着一个飞机的机翼，一条鲸鱼和一个拉面！</p></figure><p id="0df4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有一天，我想到给他造一个机器人，可以和他一起玩这个指点游戏。不要误解我的意思，我们的目标不是取代我们，而是补充我们，让他尽早接触技术。</p><h1 id="4ee0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">概念</h1><p id="7550" class="pw-post-body-paragraph ku kv it kw b kx mn ju kz la mo jx lc ld mp lf lg lh mq lj lk ll mr ln lo lp im bi translated">经过一段时间的头脑风暴，我清楚地知道我想要建造什么。这是一个有着狗的外形的聊天机器人，狗是德西最喜欢的动物。她的名字叫Qrio，是“问题”和“好奇”两个词的混合。在我为他买玩具的一年半时间里，我观察了他一直玩的玩具和不玩的玩具，我发现玩具越能模仿他能与之建立联系的生物(在这种情况下是一只狗)，它成功的机会就越高。</p><p id="5fa2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了最大限度地提高凝聚力，Qrio以我们已故的爱犬百事可乐为模型，德克斯特在第一年就与百事可乐建立了关系。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/a517cbcf1f4ff9c3457e9e2a76982475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_-4rPBfYpln1WnDl0nyUJg.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">百事和Qrio</p></figure><p id="4076" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Qrio将能够看到Dexie走过，并对他说:‘嗨，Dexie！你想过来给我看看你的玩具吗？接下来，当德茜拿起一个飞机玩具给她看时，她会继续说‘嘿，那是一架飞机。‘我给你放一段关于飞机的视频’，然后找一段飞机视频给他播放。</p><h1 id="14b1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">研究</h1><p id="7aac" class="pw-post-body-paragraph ku kv it kw b kx mn ju kz la mo jx lc ld mp lf lg lh mq lj lk ll mr ln lo lp im bi translated">为了实现上述目标，Qrio需要具备以下模块:</p><ul class=""><li id="651a" class="mt mu it kw b kx ky la lb ld mv lh mw ll mx lp my mz na nb bi translated"><strong class="kw iu">视线</strong>。Qrio必须确认Dexie和他携带的玩具。为此，我需要一个连接到人工智能系统的摄像头，以检测德歇和他的玩具的存在和位置。需要建立一个经过训练可以识别人脸和玩具的物体检测人工智能模型，该模型将在连接到摄像头的GPU驱动的设备上运行。</li><li id="0b16" class="mt mu it kw b kx nc la nd ld ne lh nf ll ng lp my mz na nb bi translated"><strong class="kw iu">视觉存在</strong>——以虚拟狗的形式出现，它将与德歇互动。它将由显示在显示器上的虚拟木偶系统驱动。</li><li id="f166" class="mt mu it kw b kx nc la nd ld ne lh nf ll ng lp my mz na nb bi translated"><strong class="kw iu">语音</strong>，这样Qrio就可以和他打招呼，让他拿起一个玩具，说出玩具的名字等等，这需要一个文本到语音的技术，显然还需要一个扬声器。</li><li id="f466" class="mt mu it kw b kx nc la nd ld ne lh nf ll ng lp my mz na nb bi translated"><strong class="kw iu">视频搜索和播放</strong>，这样Qrio就可以在YouTube上搜索并播放一个相关的视频。这将由自动化工具驱动。</li><li id="4afe" class="mt mu it kw b kx nc la nd ld ne lh nf ll ng lp my mz na nb bi translated"><strong class="kw iu">所有组件的协调者</strong>。</li></ul><p id="d76e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">经过一番认真的研究，我列出了运行该系统所需的硬件清单。</p><ul class=""><li id="2963" class="mt mu it kw b kx ky la lb ld mv lh mw ll mx lp my mz na nb bi translated"><strong class="kw iu">NVIDIA Jetson Nano</strong>(150澳元)。这是一个微小的GPU驱动的嵌入式设备，将运行所有模块(特别是对象检测人工智能模型)。这是一个完美的工作设备，因为它可以通过一个简单的HDMI端口支持视频和音频输出，并且它有一个以太网端口，方便互联网接入。你甚至可以插入鼠标和键盘，在设备上进行开发和调试，因为它有一个功能齐全的Ubuntu 18.04操作系统。</li><li id="bc17" class="mt mu it kw b kx nc la nd ld ne lh nf ll ng lp my mz na nb bi translated"><strong class="kw iu">电视</strong>(带HDMI输入和内置扬声器)(150澳元)。这样Dexie就可以看到Qrio，听到她在说什么，还可以播放YouTube视频。</li><li id="e03f" class="mt mu it kw b kx nc la nd ld ne lh nf ll ng lp my mz na nb bi translated"><strong class="kw iu">相机——索尼IMX219 </strong> ($AUD 35)。这是一个令人敬畏的微型800万像素摄像头，使Qrio能够识别Dexie和他的玩具。画质超赞，价格惊人的便宜。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/63155f9e624aa2e3c594e1b2744adcf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*yNnmX-dsEf9kljbEP_XQJw.jpeg"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">NVIDIA Jetson Nano和索尼IMX219摄像头</p></figure><h1 id="053c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">履行</h1><p id="c23e" class="pw-post-body-paragraph ku kv it kw b kx mn ju kz la mo jx lc ld mp lf lg lh mq lj lk ll mr ln lo lp im bi translated">有了一个可靠的计划，我开始完成我的使命。</p><p id="10a5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">建筑景观</strong></p><p id="c6ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，需要开发和训练一个对象检测组件来识别特定的人脸和玩具。请记住，NVIDIA Jetson Nano的GPU不如1080Ti等桌面级GPU卡强大，因此选择一种在准确性和性能之间取得良好平衡的对象检测模型架构至关重要。首先，我决定了我能接受的最低每秒帧数(FPS)。然后，我逆向工作，寻找可以在Jetson Nano上提供这种FPS的模型。我选择了8 FPS，实际上，当视频处理、文本到语音、虚拟木偶戏渲染等同时运行时，它将下降到大约5 FPS。每秒少于5次检测将显著降低获得高质量捕捉的机会，在高质量捕捉中，Dexie的脸和他的玩具清晰可见。获胜的模型架构是<a class="ae ni" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank">ssdlitemobilentv 2</a>，它运行在TensorFlow 1.8 <a class="ae ni" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">对象检测</a> API上。</p><p id="d98b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我只用了四个类来训练这个模型:一张人脸和三个Dexie的玩具(飞机、火车和熊猫)。所有训练集图像(每类150个图像)都是从使用同一台索尼IMX219摄像机记录的视频文件中生成的。为了最大限度地提高检测精度，并确保照明和背景是一致的，它们是在我将运行该系统的同一个客厅中拍摄的。这三个玩具都是从视频中手动、费力地贴上标签的。然而，为了保持理智，我使用了<a class="ae ni" href="https://aws.amazon.com/rekognition/" rel="noopener ugc nofollow" target="_blank"> Amazon Rekognition </a>，这是一种现成的对象检测云服务，可以自动标记所有人脸。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/f845096fabe973c2c34b7e831f591fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*KhOiY1UBYFLqjfvPdlpKYw.jpeg"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/51d8875f79c0efd4d8ba78b7c1c66137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*IAw_c4BqNWTqyPCytdd4sw.jpeg"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/c6352f669ab70c48a85f56e6caf76104.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*VE4UPpJ5-56mX4pjBFU9XQ.jpeg"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">人脸和玩具检测训练装置</p></figure><p id="6361" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">视频录制是使用GStreamer完成的，通过执行下面的命令就可以轻松完成。以低FPS录制会导致最终视频中出现明显的运动模糊，并产生低质量的训练集。因此，我将录制帧速率设置为120 FPS，稍后使用视频编辑工具对其进行向下采样。记录尺寸设置为720x540，这已经足够了，因为我们的对象检测模型只能在300x300像素上运行，任何更大的图像在训练和推断期间都会自动调整为300x300像素。</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="b895" class="np lw it nl b gy nq nr l ns nt"><em class="nu">gst-launch-1.0 nvarguscamerasrc num-buffers=120000 ! 'video/x-raw(memory:NVMM),width=720, height=540, framerate=120/1, format=NV12' ! omxh264enc  ! qtmux ! filesink location=out.mp4 -e</em></span></pre><p id="abe7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我使用了<a class="ae ni" href="https://github.com/Ericsson/eva" rel="noopener ugc nofollow" target="_blank"> EVA </a>，一个伟大的免费物体检测标签工具，你可以安装在本地，并可以导入一个视频文件作为图像源。</p><p id="34b7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">训练在五个小时内完成，使用的是在实现mAP=0.8的P3.2XLarge (Pascal V100)上运行的<a class="ae ni" href="https://aws.amazon.com/machine-learning/amis" rel="noopener ugc nofollow" target="_blank"> AWS EC2深度学习AMI </a>。Mean Average Precision (mAP)是一种用于评估对象检测性能的指标，通过计算在各种iOU阈值上平均的精度/召回曲线下的面积来进行。这需要一个完整的博客帖子来解释，所以我会简单地让你看一下<a class="ae ni" href="https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173" rel="noopener">物体检测博客</a>的地图。否则，你只需要相信我，0.8的贴图已经很好了，而且还可以通过聚合几帧的检测来进一步改进。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/d293c18e092b54c99f6aa94509c94ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0erTu3acVNuBiNMxN4NUeA.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/1d6c000f948b778f79cb7aca38480630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FgPWmN_SW4HHoL-lspIpcQ.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">培训统计</p></figure><p id="0abd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦你刷新了设备，在NVIDIA Jetson Nano上部署和运行这个模型是非常简单的(按照步骤<a class="ae ni" href="https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit" rel="noopener ugc nofollow" target="_blank">这里</a>)，因为它运行的是全功能的Ubuntu 18.04。我的意思是你可以安装Tensorflow，Object Detection API和所有的Python依赖项，就像在你的笔记本电脑或PC上一样。我使用Tensorflow 1.8是因为在写这篇博客的时候，由于缺少contrib依赖项，Tensorflow 2.0不支持对象检测API。</p><p id="1fba" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">GStreamer和OpenCV框架用于连接到摄像机并从摄像机获取视频。从那里，我们只需要将捕获的图像直接传递给我们的对象检测模型。请看这里的代码示例<a class="ae ni" href="https://github.com/msubzero2000/Qrio-public/blob/master/misc/objectDetectionOnJetsonNano.py" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="e462" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我设法让物体检测以10 FPS的速度运行，这超过了我的最低要求8 FPS——并且具有相当好的检测精度！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/088325ac02b171f4b8d6654f2138f47d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*p_MgSuyQL8JDTaJ-Hy8FUQ.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">目标检测结果</p></figure><p id="7243" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">建立视觉存在</strong></p><p id="cfa1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">获得正确的视觉呈现组件至关重要。Qrio必须有吸引力，更重要的是，看起来足够像一只真实的，活着的狗，让Dexie想和她一起玩。她的眼睛需要能够直视德谢的脸，无论他在哪里。像一只正常的狗一样，当她不与德西互动时，她需要通过摇尾巴，移动头部和随意看方向来坐立不安。作为一名3D动画程序员，我在一家专门从事面部动画和虚拟木偶戏的电影特效公司工作了五年，在这五年的美好时光中，我学到了如此宝贵的技能，对此我感激不尽。我现在需要的只是一个游戏引擎！</p><p id="5128" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">几个小时的挖掘让我找到了这个叫做arcade的可怕的Python框架，它拥有我需要的一切。嗯……差不多，我稍后会讲到这个。它支持游戏动画循环，能够渲染/显示带有旋转和缩放的精灵(PNG透明图像)。由于该框架基于OpenGL，NVIDIA Jetson Nano的速度性能应该非常出色，因为它将进行GPU加速。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/d473a5e15dc37d806846c4f910b498a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*mv0-z5Iwp2Dv1lYfvNNLyg.jpeg"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">街机python游戏引擎</p></figure><p id="f741" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了让Qrio身体的各个部分(耳朵、眼球、眉毛、头和尾巴)既能独立运动又能作为一个群体运动，需要将单独的精灵组装起来(例如，移动头部也会移动耳朵、眉毛和眼球)。我需要建立一个骨骼动画系统(SAS ),它允许你将几个物体以层次关系连接在一起(例如，头部是身体的孩子，而耳朵、眼睛和眉毛是头部的孩子)。因此，当您对一个对象应用变换(旋转、平移或缩放)时，它也会影响它的所有子对象。</p><p id="0fd3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">大多数游戏角色，人类，动物，怪物，就像下面动画中的一样，都是用SAS制作的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/5531fcb59e67e959792e155e222b1744.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/1*D68IR--QL9ubW4FLSo4dcw.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">全身骨骼动画系统</p></figure><p id="5a79" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">大多数游戏引擎原生支持SAS然而，街机没有。由于我找不到替代框架，我决定从头实现SAS功能，这实际上并不难。我需要做的第一件事是建立一个存储所有精灵(耳朵、头、眉毛等)的树形数据结构。)并根据它们的关系连接它们的关节。接下来是构建一个SAS分层转换函数。这涉及到一点三角学和矩阵。如果你热衷于了解数学细节，你可以在这个<a class="ae ni" href="https://cseweb.ucsd.edu/classes/sp16/cse169-a/readings/2-Skeleton.html" rel="noopener ugc nofollow" target="_blank">博客</a>中阅读。</p><p id="a34b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下图展示了Qrio的SAS。第一幅图像显示了如何使用精灵来定义每个身体部位，这些部位是按层次组合的，如下一幅图像所示。每个身体部位也将有一个定义为旋转中心的关节。最右边的图像显示了围绕其关节应用于右耳的变换(旋转),并且没有其他身体部位受到影响，因为右耳没有任何子体。下图描绘了围绕其关节应用于头部的旋转，它影响了眉毛、眼球和耳朵。注意标记显示右耳也相应地绕着头部关节旋转。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/8f44105e6fecb517b999e43b2c723797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8cqboMEObW7vwsK91YSbng.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Qrio的骨骼动画系统</p></figure><p id="8810" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了完成视觉呈现模块，我需要建立的下一个东西是一个坐立不安的动画系统，它是基于一个简单的<a class="ae ni" href="https://www.tutorialspoint.com/computer_graphics/computer_animation.htm" rel="noopener ugc nofollow" target="_blank">关键帧动画</a>。关键帧动画允许您通过提供对象的初始和最终变换(位置、缩放和旋转)以及动画的持续时间来设置对象(如头部)的动画。系统对从初始值到最终值的变换进行插值。接下来，我定义了几个坐立不安的动画，比如耳朵的上下运动，头尾的旋转，眼球和眉毛的运动。每一个小动作都用随机选取的值(旋转/平移)、持续时间和频率使相应的对象从一个变换到下一个变换产生动画，以便看起来更自然。</p><p id="f6a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我花了几个小时调整坐立不安的动画参数，最终得到我想要的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/dd7a16c3dc7c6325ddf742dfb4df8ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*24KQKShC8eIepG4ejb3nlg.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Qrio的坐立不安动画系统</p></figure><p id="894d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，我添加了一种方法来按需覆盖眼球和眉毛的位置，方法是手动提供它们的位置，这是头部跟踪逻辑在稍后阶段跟随Dexie的脸的位置所需要的。</p><p id="09e7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">大厦演讲</strong></p><p id="9b19" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">随着她的视力和视觉呈现模块的完成，她接下来需要的是语言能力。经过几个小时的研究，我能找到的最好的免费离线文本语音转换应用是<a class="ae ni" href="https://pypi.org/project/pyttsx3/" rel="noopener ugc nofollow" target="_blank"> pyttsx3 </a>。该引擎支持一些驱动程序，但Ubuntu上唯一可用的驱动程序是espeak，它的语音质量最糟糕。这听起来像已故的斯蒂芬·霍金的轮椅(无意冒犯)。Dexie目前正处于重复我们说的每一句话的阶段，我最不希望他学会那样说话。查看以下内容，做自己的评判。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">ubuntu OS上的pyttsx3、espeak驱动程序产生的音频质量不佳</p></figure><p id="713e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">放弃线下发行后，我开始寻找线上发行。我登陆了<a class="ae ni" href="https://aws.amazon.com/polly/" rel="noopener ugc nofollow" target="_blank">亚马逊波利</a>。玩了几分钟后，我完全被迷住了。语音质量提高了100倍，没有明显的延迟，尽管它需要通过互联网进行API调用，以生成并从云中下载结果音频文件。这最初是我主要关心的问题。生成7秒钟的音频文件只需要200毫秒。我知道这不是一个免费的解决方案。然而，它可以被大量缓存，因为Qrio最多只需要说出50个不同的句子，我们只需要支付50次亚马逊Polly呼叫(0.08美分)。耶！！！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/30d8157a86905dcd68ff6344f4594d19.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*zzwOAEBU6G2JTAvkBoYA2Q.jpeg"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">亚马逊波利</p></figure><p id="6ead" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">建立视频搜索和播放</strong></p><p id="9d7f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如我们之前讨论的，Qrio需要能够在YouTube上搜索和播放特定的视频。最好的方法是使用自动化测试套件，它可以控制web浏览器在YouTube中执行搜索，并播放搜索结果中的视频。在这里，Selenium自动化框架来拯救我们了！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/77703a99917845c7205bc228636f9219.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*36wPnz0LtWysO0qNKb7tKA.jpeg"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Selenium自动化框架</p></figure><p id="71e2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一个QA通常用来测试网站的工具。它允许您编写脚本来自动完成诸如在文本字段中键入内容、按下按钮等操作。你可以猜到，我将使用它来导航到YouTube网站，输入像panda这样的搜索词，然后自动点击搜索结果中的第一个视频，并按下全屏按钮以全屏播放它。首先，您需要为Selenium安装一个Chromium-chrome驱动程序，以便能够通过执行下面的apt-get install命令来控制Chromium web浏览器(Ubuntu 18.04附带的原生浏览器)。</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="055d" class="np lw it nl b gy nq nr l ns nt">sudo apt-get install chromium-chromedriver</span></pre><p id="cb18" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，您可以使用针对Selenium的<a class="ae ni" href="https://pypi.org/project/selenium/" rel="noopener ugc nofollow" target="_blank"> python绑定</a>，从您的Python代码中以编程方式执行Selenium脚本。为了确保播放的视频对孩子是安全的，我用YouTubeKids.com而不是普通的YouTube。这带来了一点复杂，因为每次Selenium启动时，您都必须通过一系列步骤来证明您是家长。然而，我设法编写了一个Selenium脚本，它可以自动完成这些步骤，并且只需要执行一次。</p><p id="33ef" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以在这里看到代码<a class="ae ni" href="https://github.com/msubzero2000/Qrio-public/blob/master/misc/browserServiceJetson.py" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="7793" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">构建协调器</strong></p><p id="ae4b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该模块充当协调器，将所有其他模块粘合在一起。协调器的一个关键部分是跟踪游戏当前状态的状态机。为什么我们需要一个状态机？以便我们在接收到相同的事件时可以根据我们当前所处的状态做出不同的决定。例如，如果之前Qrio还没有看到Dexie，看到一个飞机玩具本身不应该触发播放YouTube视频的调用，因为它可能是玩具飞机就在沙发上的情况。在播放完飞机视频后看到一个飞机玩具应该会让Qrio说‘嘿，我们以前玩过飞机。“你为什么不给我带点别的东西来，”这样，我们可以避免让Qrio一遍又一遍地播放相同的视频，如果Dexie在它之前被识别并且视频播放被触发后继续持有飞机的话。</p><p id="ea9e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有四种主要状态——<strong class="kw iu">空闲</strong>、<strong class="kw iu">占用</strong>、<strong class="kw iu">obec识别</strong>和<strong class="kw iu">播放视频</strong>——如下面的状态图所示。当系统处于除<strong class="kw iu">播放视频</strong>之外的任何状态时，它会定期调用坐立不安动画系统来制作Qrio坐立不安的动画，并与视觉模块核对以获取所有可识别物体的位置。系统从<strong class="kw iu">空闲</strong>状态启动，如果检测到Dexie至少0.5秒(以减少错误检测)，它将调用语音模块，说类似“嗨Dexie，你想过来玩吗？”并将游戏状态设置为<strong class="kw iu">参与</strong>状态。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/ceee89b1545f8cc8f8e8ef4889f04cc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p-Ocqiw79lz1dYgCAXcV3A.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Qrio全状态机图</p></figure><p id="580e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此外，如果在我们处于<strong class="kw iu">参与</strong>模式时，可以看到一个熊猫玩具，Qrio会说‘嗨，Dexie。我想那是一只熊猫，将进入<strong class="kw iu">物体识别</strong>模式。如果熊猫玩具在另外两秒钟内仍然可见，Qrio将切换到<strong class="kw iu">播放视频</strong>状态，将说“让我给你播放一段关于熊猫的视频”，并将调用视频搜索和播放模块来搜索熊猫视频并播放它。然而，如果我们最近播放了一段关于熊猫的视频，它会说‘嘿，我们以前和熊猫玩过。为什么不给我带点别的？视频将只全屏播放45秒，而视线和坐立不安动画系统暂停，以集中CPU资源播放流畅的视频。视频播放完成后，浏览器窗口隐藏，视线和坐立不安动画系统恢复。当Dexie在接合模式下10秒钟不可见时，协调器将重置状态为<strong class="kw iu">空闲</strong>。</p><p id="12af" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您还可以看到，除了<strong class="kw iu">播放视频</strong>之外，在任何状态下，当面部可见时，都会调用头部跟踪模块，以使Qrio的眼球跟随面部边界框的中心点。</p><h1 id="7da0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">设置和校准</h1><p id="56f6" class="pw-post-body-paragraph ku kv it kw b kx mn ju kz la mo jx lc ld mp lf lg lh mq lj lk ll mr ln lo lp im bi translated">一切准备就绪后，我在客厅安装了系统，进行最后的校准和测试。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/9403596eed0f6dd57adf7294b338ce59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GSrl6UQIxMVskPc2Bg-B3g.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/ff3023f9cc9850c1561ce66eccde0c47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TSV2TlRZNgbBggEYltJ00g.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Qrio系统设置</p></figure><p id="7f83" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">初始化时，系统会顺利通过YouTubeKids的母授权。我看到Qrio的眼睛快速地跟随我的脸，这表明物体检测和头部跟踪逻辑工作得非常好。我注意到NVIDIA Jetson Nano已经被推到了极限，RAM运行得非常低，设备变得非常热。这是完全可以理解的，因为它正在运行一个重型人工智能模型，仍然需要实时渲染游戏引擎，控制Selenium浏览器和解码视频。然而，整个系统似乎运行得很好，游戏引擎显示的基准为5 FPS。</p><p id="2fb2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我现在需要的就是找个合适的时机把Qrio给Dexie看！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Qrio系统校准和测试</p></figure><h1 id="e6fe" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">表演时间</h1><p id="0c98" class="pw-post-body-paragraph ku kv it kw b kx mn ju kz la mo jx lc ld mp lf lg lh mq lj lk ll mr ln lo lp im bi translated">第一次看到Qrio的时候，是看着德谢的无价时刻。他好奇地冲向她，而Qrio在叫他，他站着不动，只是不相信地盯着她看了几秒钟。突然，他咯咯地笑了起来……我才知道我成功地通过了第一次测试——男孩和机器人的成功结合！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/b1fa2536f73499ccebb008558bc54345.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4oXmMxyU256pg8un5XqvUw.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/6c1e3cd76c10ed7470c6fb2326c8a4e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UdeEY-A5aRpYfuoGh5Vgrw.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/f1da421c46aff5f31fb705b39d9c0919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VGExxEa-asRfPrKmUdvdAw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">德歇第一次见到Qrio</p></figure><p id="1989" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了让他更加熟悉和舒适，我让他做任何他想做的事情，没有任何指导。他走向她，看着她坐立不安，摸着电视(以为他真的在摸她)，甚至叫她“小狗”。</p><p id="ed49" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">接下来是关键时刻——测试实际的游戏玩法。举个例子，我让他看我给Qrio展示他的飞机玩具，她完美地认出了它，并说，“嘿，我想这是一架飞机。让我给你放一段关于飞机的录像。德协看到飞机视频开始播放的时候超级兴奋！</p><p id="7bbb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">视频播放完一次，我把一个熊猫玩具递给了德协。他模仿我，把熊猫玩具给Qrio看，她再次搜索并播放了一段合适的视频！你可以在下面的视频中观看整个经历。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">德西第一次看到并和Qrio一起玩</p></figure><h1 id="0d4e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">学习和未来改进</h1><p id="8cc8" class="pw-post-body-paragraph ku kv it kw b kx mn ju kz la mo jx lc ld mp lf lg lh mq lj lk ll mr ln lo lp im bi translated">系统还不完善。尽管它在80%的时间里能够识别玩具并播放正确的视频，但它仍然会时不时地失败——这没什么。最重要的是，我学到了很多关于什么可行，什么不可行，为下次类似的项目做准备。</p><p id="6365" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">相机的FOV </strong></p><p id="2732" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">大多数故障发生在Dexie站得离电视太近时，这超出了摄像机的可视范围。如下图所示，相机有一个77度的FOV，放置在距离电视中等距离的位置，但不是很近(红色圆圈标记的区域)。同样的问题也发生在垂直覆盖中，当他坐在地板上时，摄像机看不到他举得很低的玩具。降低相机的焦距可以解决这个问题，但会带来相反的问题，即当他站在相机附近时，看不到他的脸。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/6ba86440a48d6860697e509fe0df5317.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YD_A3FD_SNiNILC36q4WSQ.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Qrio的摄像头的水平盲点</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/5615cc5fb2a9a5d2801ce201a2bdde05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h839pK-0WDUMBK-gmlTY2w.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Qrio的相机的垂直盲点</p></figure><p id="5b9a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">解决这个问题的办法可能是买一台FOV更宽(120度)的新相机，这样它可以覆盖更多的区域。然而，由于透镜失真，FOV边缘周围的检测精度可能下降。</p><p id="68af" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">可回放性</strong></p><p id="f3b4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">到目前为止，Qrio sight模块只对三个玩具进行了训练，并且总是为同一个玩具播放相同的视频。这只够娱乐德歇五分钟，直到他厌烦为止。因此，它具有低的可重复因子。我计划在未来增加对更多玩具的支持——如果我能鼓起勇气手动标记数以千计的额外图片的话。还可以添加一个随机化，从找到的前五个视频中随机选择，而不是总是选择第一个。</p><p id="8aec" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">更快的FPS </strong></p><p id="2edf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">另一个需要改进的地方是游戏的FPS。当视频搜索和播放模块执行Selenium脚本来控制chromium浏览器时，游戏以大约5 FPS的速度运行，偶尔会出现短暂的冻结和较长的冻结。你可能已经在上面的演示视频中发现了这一点。一个冻结的游戏引擎意味着Qrio停止移动，这不是那么好看。一个想法是将对象检测移到一个单独的线程中，这样它可以并发运行，而不会阻塞游戏引擎。同样的处理也可以应用于视频搜索和播放模块。然而，我们需要测试OpenCV和Selenium是否乐意在单独的线程上运行。除此之外，我还想测试一款更强大的设备，比如NVIDIA Jetson NX T1，它可能更适合这种规模的项目。</p><p id="3807" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">就这样，伙计们！我希望你喜欢阅读我的令人兴奋的周末计划，就像我喜欢与你分享它一样。</p><p id="a878" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">完整的源代码可以在<a class="ae ni" href="https://github.com/msubzero2000/Qrio-public/tree/master/qrio" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div></div>    
</body>
</html>