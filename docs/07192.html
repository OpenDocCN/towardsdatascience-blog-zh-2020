<html>
<head>
<title>Open the Black Box: Understand What Drives Predictions in Deep NLP Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">打开黑匣子:理解是什么驱动了深度NLP模型中的预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/open-the-black-box-understand-what-drives-predictions-in-deep-nlp-models-833f3dc923d0?source=collection_archive---------55-----------------------#2020-06-01">https://towardsdatascience.com/open-the-black-box-understand-what-drives-predictions-in-deep-nlp-models-833f3dc923d0?source=collection_archive---------55-----------------------#2020-06-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="222e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">实用且可重复的演示</h2></div><p id="056f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">与</em> </strong> <a class="lc ld ep" href="https://medium.com/u/c78921cde464?source=post_page-----833f3dc923d0--------------------------------" rel="noopener" target="_blank"> <strong class="kh ir"> <em class="lb">约什·卡斯维尔</em> </strong> </a>一起写的文章</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/dabde37f043c8253985e84ac2843df89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rdY46vxFCUsOjy4mNyVn6g.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">电影1917的IMDB评论—使用<a class="ae lu" href="http://captum.ai/" rel="noopener ugc nofollow" target="_blank"> Captum </a>生成并使用<a class="ae lu" href="https://github.com/mariobuikhuizen/ipyvuetify/" rel="noopener ugc nofollow" target="_blank"> ipyvuetify </a>可视化的预测属性</p></figure><blockquote class="lv lw lx"><p id="2beb" class="kf kg lb kh b ki kj jr kk kl km ju kn ly kp kq kr lz kt ku kv ma kx ky kz la ij bi translated"><strong class="kh ir"> <em class="iq">目标</em> </strong> <em class="iq"> <br/> - </em>通过检查属性<br/>理解和感知-检查模型决策制定-可视化令牌属性<br/> -提供易于使用的代码，以便任何人都可以将其应用到他们的PyTorch模型中</p></blockquote><p id="dca4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">深度神经网络为NLP做了令人难以置信的事情——每年都有艺术记录被打破，全新的研究和应用子领域蓬勃发展。</p><p id="55fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">毫无疑问，这些模型使研究人员能够创造出令人印象深刻的结果。从艾写诗到在保持意义的同时改变信息的语气。具体怎么做？结果如此令人印象深刻，以至于几乎很容易忘记去问。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/6621560e7948f0e96222c599b08aec31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*OEkKcKWtC5PF2-odNhW5Vg.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">匿名作者(<a class="ae lu" href="https://memeshappen.com/media/created/but-how-did-you-do-it-meme-49244.jpg" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="6815" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">大量的参数、抽象的架构方法、令人印象深刻的出版物以及创新的纯粹步伐可能会分散注意力——跟上深度学习是相当全职的努力。</p><ul class=""><li id="f0d1" class="mc md iq kh b ki kj kl km ko me ks mf kw mg la mh mi mj mk bi translated">模型是如何做出如此高质量的预测的？</li><li id="10e0" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">他们知道什么？</li><li id="072f" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">什么<strong class="kh ir"> <em class="lb">不</em> </strong>他们知道？</li><li id="6c5d" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">他们有多可靠？</li><li id="0205" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">是什么情况让他们纠结？</li></ul><p id="3d04" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些是很难回答的问题。见证一些领先的研究人员投入时间和工作来提供答案真是太棒了。但是有许多应用该技术的从业者，他们需要理解和可靠地解释它做什么和为什么。</p><p id="6755" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章的目的是提供一个快速和实用的介绍，一个伟大的，公理化的方法来建模可解释性。我们专注于NLP，并提供代码示例让您直接进入并获得自己独立的体验。</p><p id="7b7a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可解释性是关键。当高级利益相关者或法规遵从性不支持某件事情时，他们怎么会支持呢？这会带来什么新的风险？</p><p id="dbc3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">机器学习模型是模型架构、用于训练的数据集和训练过程的结果。这意味着每个模型都是不同的，并且您需要用自己的数据集来评估自己创建的模型。</p><p id="1a19" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将重点关注一种称为<strong class="kh ir">集成梯度</strong>的方法，并使用来自著名的<a class="ae lu" href="https://fast.ai" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>深度学习for coders课程的预训练评论情感分类器。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mq"><img src="../Images/8bbe24386f1a4252cac45230dc4240c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w0VcydSKt5i02cEk"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">照片由<a class="ae lu" href="https://unsplash.com/@ugnehenriko?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">拍摄于<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的</a></p></figure><h1 id="8b0f" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">路径集成渐变</h1><p id="008e" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">综合梯度是作者<a class="ae lu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sundararajan%2C+M" rel="noopener ugc nofollow" target="_blank"> Mukund Sundararajan </a>、<a class="ae lu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Taly%2C+A" rel="noopener ugc nofollow" target="_blank"> Ankur Taly </a>、<a class="ae lu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yan%2C+Q" rel="noopener ugc nofollow" target="_blank"> Qiqi Yan </a>在<a class="ae lu" href="https://arxiv.org/abs/1703.01365" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> <em class="lb">中介绍的公理化归因方法，用于深度网络(2017) </em> </strong> </a>。</p><p id="1af8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它旨在显示深度神经网络输入的哪些部分影响输出，以及有多强烈。</p><p id="dc91" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关键的是，与基线输入相比，属性被计算<strong class="kh ir">为</strong> <strong class="kh ir">。换句话说，它不依赖于离散的直接梯度wrt。输入的变化，但需要一个假定为中性的参考基线。空白画布与彩绘图像。</strong></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi no"><img src="../Images/8b90875f1bfdbb6c621159569ea09a34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fNWjG9DPOwch2MUm8kWnEA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">从基线到输入端，通过空间的一条直的、连续的路径。</p></figure><p id="e174" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">IG是一种路径方法</p><ol class=""><li id="ab11" class="mc md iq kh b ki kj kl km ko me ks mf kw mg la np mi mj mk bi translated">创建从基线(空的和中性的)到输入(我们要解释的信号)的穿过空间的直线路径，</li><li id="1d1f" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la np mi mj mk bi translated">在连续路径上每一步聚集梯度，</li><li id="9a38" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la np mi mj mk bi translated">计算这些累积梯度的路径积分。</li></ol><p id="7791" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">它的关键优势在于公理起源</strong>。它具有来自数学原理的理想特征。这与源自经验的归因方法(阅读“尝试看看会发生什么”)形成了对比，顺便说一下，这种方法也很棒。</p><p id="0c24" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">该方法的两个核心原则:</strong></p><ul class=""><li id="c9b7" class="mc md iq kh b ki kj kl km ko me ks mf kw mg la mh mi mj mk bi translated">敏感度—如果基线和输入之间存在差异，属性需要非零。</li><li id="76f4" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">实现不变性——“如果两个网络的输出对于所有输入都相等，则这两个网络在功能上是等价的”</li></ul><p id="8f02" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">暗示其他期望的自然属性也起作用。其中之一是完整性——属性加起来就是给定输入与基线的模型(网络)输出的确切差异。</p><p id="bd34" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们强烈推荐阅读这篇论文，它清晰明了，附有证据，并且有精心准备的例子。</p><p id="713e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们正在使用的版本已经在Captum库中实现。</p><h2 id="e6fd" class="nq ms iq bd mt nr ns dn mx nt nu dp nb ko nv nw nd ks nx ny nf kw nz oa nh ob bi translated">嵌入</h2><blockquote class="lv lw lx"><p id="2c2f" class="kf kg lb kh b ki kj jr kk kl km ju kn ly kp kq kr lz kt ku kv ma kx ky kz la ij bi translated">对于NLP模型，输入特征是转换成记号的单词、标点符号和其他文本信息(例如，大写字母)。标记是离散的，不适用于这种路径方法。</p></blockquote><p id="61bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当记号通过嵌入层进入网络时，它们获得了意义的连续表示。我们需要连接到这一层——文字和数字的界面——来计算有意义的属性。</p><h1 id="ef3a" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">AWD-LSTM建筑</h1><p id="9c48" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">该模型最初由<a class="ae lu" href="https://arxiv.org/abs/1708.02182" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> <em class="lb">正则化和优化LSTM语言模型(2017)</em></strong></a><strong class="kh ir"><em class="lb"/></strong>中提出，由<a class="ae lu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Merity%2C+S" rel="noopener ugc nofollow" target="_blank"> Stephen Merity </a>、<a class="ae lu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Keskar%2C+N+S" rel="noopener ugc nofollow" target="_blank"> Nitish Shirish Keskar </a>和<a class="ae lu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Socher%2C+R" rel="noopener ugc nofollow" target="_blank"> Richard Socher </a>编写，作为免费的f <a class="ae lu" href="https://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> ast.ai深度学习for coders课程</a>的一部分讲授。</p><p id="50d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">AWD-LSTM，非常宽泛地说，包括两个阶段:</p><ol class=""><li id="5b66" class="mc md iq kh b ki kj kl km ko me ks mf kw mg la np mi mj mk bi translated">基于RNN的编码器</li><li id="2b08" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la np mi mj mk bi translated">一个汇集线性分类器，为编码器的输出增加分类能力。</li></ol><p id="9fb7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它结合了许多谨慎应用的正则化技术，并且很好地展示了对LSTMs内部工作原理的理解。</p><p id="b94e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">编码器可以在语言建模任务上预先训练，事实上这是由<a class="ae lu" href="http://fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>团队教授的方法。该架构做得非常好，同时比各种新的transformer模型小得多。这在资源受限的情况下非常有利，事实上<a class="ae lu" href="http://fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>值得高度赞扬，因为他们为实现深度学习所做的工作非常有影响力。</p><p id="e2c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然本文是基于这个特定的模型，但是该方法将适用于任何使用嵌入层的NLP架构。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oc"><img src="../Images/b126c5f152a3779ece8eaaf56a2f2a73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*M7Avc3jww00DBUPV"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">由<a class="ae lu" href="https://unsplash.com/@williamdaigneault?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">威廉·戴尼奥</a>在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="7355" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">将Captum应用于AWD-LSTM情感分类器</h1><p id="33eb" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">在这一部分，我们将讨论3个主题:</p><ul class=""><li id="266b" class="mc md iq kh b ki kj kl km ko me ks mf kw mg la mh mi mj mk bi translated">如何计算属性，从一个预先训练好的<a class="ae lu" href="http://fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a> <code class="fe od oe of og b">Learner</code>对象开始</li><li id="21e7" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">关于选择基线的说明</li><li id="30e4" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">处理较长的序列</li></ul><h1 id="059a" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">1.计算属性</h1><p id="5a4b" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">fast.ai的AWD LSTM实现不能直接与Captum一起工作。</p><p id="61ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">收集渐变时，我们需要钩入正确的图层。这不会自动发生，我们需要深入模型结构以找到该层。</p><h2 id="73b4" class="nq ms iq bd mt nr ns dn mx nt nu dp nb ko nv nw nd ks nx ny nf kw nz oa nh ob bi translated"><strong class="ak">提取右侧图层</strong></h2><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oh"><img src="../Images/956e1ecc3ca49ffadd81284f01064e10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5_ygSUX3DUeGN_txLSk1ww.png"/></div></div></figure><p id="ea0f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">看起来好像有重复，但实际上，那些是嵌套模块，原因是</strong><a class="ae lu" href="http://fast.ai/" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">fast . ai</strong></a><strong class="kh ir">团队实现的自定义嵌入丢失。</strong></p><p id="446e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一方面，Captum IG类需要模型输出一个没有任何附加的预测<a class="ae lu" href="http://fast.ai/" rel="noopener ugc nofollow" target="_blank">。</a>我们从AWD-LSTM模型中得到的是一个元组，其中预测伴随着来自编码器的隐藏状态。此外，我们必须应用softmax。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oi"><img src="../Images/eef29e0088b4f737b82136f325d5eff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QbTveHUaKtxpBr8AjhPpxQ.png"/></div></div></figure><p id="5e6d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">幸运的是，我们可以将模型包装在一个函数中，以我们需要的方式呈现输出。</p><h2 id="aae3" class="nq ms iq bd mt nr ns dn mx nt nu dp nb ko nv nw nd ks nx ny nf kw nz oa nh ob bi translated"><strong class="ak">应用IG </strong></h2><p id="4065" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">此时，我们可以自由地创建一个来自Captum的<code class="fe od oe of og b">LayerIntegratedGradients</code>实例。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oj"><img src="../Images/2a174268c2d0864165be4c61d18a0dad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C6zHqnAyzt4wfoBV4p7GTA.png"/></div></div></figure><p id="be3c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">调用属性方法的情况如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ok"><img src="../Images/1cec78882e75509c0cd32a7465bed1f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0PcLjLhGuxkCnUZkC9svtg.png"/></div></div></figure><p id="3f18" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们提供:</p><ul class=""><li id="a24d" class="mc md iq kh b ki kj kl km ko me ks mf kw mg la mh mi mj mk bi translated">标记化的输入文本(有人称之为数字化的)</li><li id="1c35" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">对应的基线记号序列</li><li id="31eb" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">要解释的目标预测</li><li id="6a82" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">用多少步来近似积分</li></ul><p id="84d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们收到:</p><ul class=""><li id="d2cf" class="mc md iq kh b ki kj kl km ko me ks mf kw mg la mh mi mj mk bi translated">对于每个嵌入向量的每个元素，从基线到给定输入的路径上的积分梯度</li></ul><p id="06cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，让我们对嵌入维度求和并归一化——属性就可以显示了。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ol"><img src="../Images/8aa12f5c171dbfe8c9a92e217a18ef67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CldgElF2Ru45E63T_F_NYQ.png"/></div></div></figure><p id="29c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要查看、克隆和运行这个完整的示例，请查看这个<a class="ae lu" href="https://github.com/MichaMucha/awdlstm-integrated-gradients/blob/master/explaining_predictions_awdlstm.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>。</p><h1 id="52aa" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">形象化</h1><p id="0b5e" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">属性以标准化浮点数的形式出现——每个令牌一个值。在可视化这种格式时，有很多选择。在这一节中，我们为您提供代码，让您快速生成条形图和颜色编码的标记(“显著图”方法)。</p><p id="5079" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此处适当可视化的目的是使您能够立即理解预测解释，让您快速、轻松地判断性能。</p><p id="fd7b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">点击图片下方的链接，访问可以在Jupyter中运行的代码示例！</p><h2 id="195a" class="nq ms iq bd mt nr ns dn mx nt nu dp nb ko nv nw nd ks nx ny nf kw nz oa nh ob bi translated"><strong class="ak">显著图——彩色筹码</strong></h2><p id="37e0" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated"><a class="ae lu" href="https://github.com/MichaMucha/awdlstm-integrated-gradients/blob/master/Saliency%20chips.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> <em class="lb">链接到笔记本上</em> </strong> </a></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/dabde37f043c8253985e84ac2843df89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rdY46vxFCUsOjy4mNyVn6g.png"/></div></div></figure><h2 id="ff63" class="nq ms iq bd mt nr ns dn mx nt nu dp nb ko nv nw nd ks nx ny nf kw nz oa nh ob bi translated"><strong class="ak"> Chart.js条形图</strong></h2><p id="188d" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">使用Chart.js库转换标准化输出的示例可参见<a class="ae lu" href="https://github.com/jaycee14/tv_sentiment" rel="noopener ugc nofollow" target="_blank">此处</a>:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi om"><img src="../Images/e63aebf10c12a324187062c6846f8a44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MNCtZu3DX6Syn0qvpW3oqA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">积极向上的情绪。为了可读性，删除了一些标点符号和描述性符号。(显著性图+条形图)</p></figure><h2 id="9b13" class="nq ms iq bd mt nr ns dn mx nt nu dp nb ko nv nw nd ks nx ny nf kw nz oa nh ob bi translated"><strong class="ak">matplotlib/pandas中的条形图</strong></h2><blockquote class="lv lw lx"><p id="5185" class="kf kg lb kh b ki kj jr kk kl km ju kn ly kp kq kr lz kt ku kv ma kx ky kz la ij bi translated">指定目标的一个好处是你可以得到“为什么不呢？”就像“为什么是的？”</p></blockquote><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi on"><img src="../Images/5ac5eb72350ff89a77df51cd49ff9670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dg6hoCVWoB66SYcgJn6Ktw.png"/></div></div></figure><h1 id="7ac9" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">什么是好的基线？</h1><p id="c6ab" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">追寻这个问题的答案和计算归属一样有益。</p><p id="cf49" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">基线是模型的预测中性输入，并且是特定于模型的。它描述了你的模型。</strong></p><p id="a1d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">真的是中立吗？是什么让它动摇了？知道你在生产中使用的模型的那些事情不是很棒吗？</p><p id="65a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可能希望尝试一些方法来制定基线:</p><ul class=""><li id="a8b4" class="mc md iq kh b ki kj kl km ko me ks mf kw mg la mh mi mj mk bi translated">零嵌入向量序列，长度与输入序列匹配</li><li id="615f" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">单个标记的序列，如<pad>、<bos>、<unk>，中性符号(换行符、点号)，按长度匹配输入序列</unk></bos></pad></li><li id="dee0" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">多重基线——你期望中立的句子的集合</li><li id="7562" class="mc md iq kh b ki ml kl mm ko mn ks mo kw mp la mh mi mj mk bi translated">使用梯度来计算嵌入序列，该序列对于所有潜在的类都是同样不确定的</li></ul><p id="98a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这可以附在你的模型的文档中。积分梯度是一种适用于任何预测函数的方法，因此它甚至可以包括在模型测试中，以寻找不公平的偏差等问题。</p><p id="fd2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在带有IMDB评论的示例<a class="ae lu" href="https://github.com/MichaMucha/awdlstm-integrated-gradients/blob/master/explaining_predictions_awdlstm.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>中包含了一个示例发现过程。使用&lt; BOS &gt;标记构建基线序列，然后重复一个在类别概率中显示高度模糊的标记。该标记作为关键字参数保存，以便快速试验。</p><h1 id="f6a8" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">处理较长的句子</h1><p id="fbaf" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">我们在将IG应用于<a class="ae lu" href="http://fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>实现时发现的一个早期问题是在较长的输入句子上的失败。使用情况表明，评估超过70个标记的句子会产生错误。仔细调试表明，这是由AWD-LSTM模型中通过时间反向传播(BPTT)参数的默认设置70造成的。</p><p id="5559" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe od oe of og b">bptt</code>参数是(由同名算法)用来指定基于RNN的语言模型在试图预测下一个单词时将考虑多长时间的序列的值。在这种情况下，在尝试预测下一个标记之前，最多考虑70个标记。</p><p id="b8a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">BPTT是一种训练RNNs的有用算法，它显著地提高了训练速度。但是，在内部将序列分成70个更小的序列，这在尝试创建正确大小的遮罩尺寸(甚至是完全空的遮罩)时会导致模型的其他部分出现问题。</p><p id="6c73" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">解决方案是将模型的<code class="fe od oe of og b">bptt</code>属性设置为高于句子长度，作为将模型设置为评估模式的一部分。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oo"><img src="../Images/30a820ad8a257223302a8bec404b39c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJCZCqijiDp5Hee8NLy_6A.png"/></div></div></figure><h1 id="e171" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">结论</h1><p id="b3b6" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">解释具有数千万个参数的超大型深度神经网络需要新的工具和方法。我们希望这为数据科学家的工具包提供了另一个工具，并有助于形成他们自己的测试方法的基础。</p><p id="2bee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个公理化的解释方法，加上一个简单的、迭代的和可视化的检查过程，使得“了解”ML模型变得很容易。当数据科学家这样做时，他们可以同时创建测试用例。</p></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><p id="2b35" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">作者是伦敦</em> <a class="ae lu" href="http://fast.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="lb"> fast.ai </em> </a> <em class="lb">研究小组成员。我们运行免费的非正式课程迭代，专注于实践现代深度学习和构建项目。如果你想加入我们的小组，请联系我们！</em></p><p id="4040" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> Josh是一名在金融部门工作的高级数据科学家，他对在商业环境中使用NLP技术和在滑雪环境中使用python感兴趣。</em></p><p id="c528" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> Michal通过他的咨询公司</em><a class="ae lu" href="http://create.ml/" rel="noopener ugc nofollow" target="_blank"><em class="lb">create . ml</em></a><em class="lb">提供数据科学和人工智能项目，他为机构和个人提供数据科学、机器学习和Python方面的培训。</em></p></div></div>    
</body>
</html>