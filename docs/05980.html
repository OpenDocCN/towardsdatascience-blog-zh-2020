<html>
<head>
<title>Understanding Conditional Variational Autoencoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解条件变分自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-conditional-variational-autoencoders-cd62b4f57bf8?source=collection_archive---------2-----------------------#2020-05-16">https://towardsdatascience.com/understanding-conditional-variational-autoencoders-cd62b4f57bf8?source=collection_archive---------2-----------------------#2020-05-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/f665202e5a827498dfdbe44a66cb324d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gA2JdLZJ12gQtnqakU7KAQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://www.researchgate.net/profile/Abu_Kamruzzaman/publication/332540618_Developing_Deep_Learning_Models_to_Simulate_Human_Declarative_Episodic_Memory_Storage/links/5d2f8b33458515c11c392f78/Developing-Deep-Learning-Models-to-Simulate-Human-Declarative-Episodic-Memory-Storage.pdf" rel="noopener ugc nofollow" target="_blank"> * </a>修改而来</p></figure><div class=""/><p id="5dc6" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(本博客的修改版可以在<a class="ae jg" href="https://theaiacademy.blogspot.com/2020/05/understanding-conditional-variational.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ki jk">这里找到</strong> </a>)</p><p id="850e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">变分自动编码器或VAE是一个有向的图形生成模型，它已经获得了很好的结果，并且是生成建模的最先进的方法之一。假设数据是由某个随机过程产生的，涉及一个不可观测的连续随机变量<strong class="ki jk"> <em class="le"> z. </em> </strong>假设<strong class="ki jk"> <em class="le"> z </em> </strong>是由某个先验分布<strong class="ki jk"> <em class="le"> P_θ(z) </em> </strong>产生的，数据是由某个条件分布<strong class="ki jk"> <em class="le"> P_θ(X|Z) </em> </strong>产生的，其中<strong class="ki jk"> <em class="le"> X </em> </strong><strong class="ki jk"> <em class="le"> z </em> </strong>有时被称为数据的隐藏表示<strong class="ki jk"> <em class="le"> X </em> </strong>。</p><p id="f243" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">像任何其他自动编码器架构一样，它有一个编码器和一个解码器。编码器部分尝试学习<strong class="ki jk"> <em class="le"> q_φ(z|x) </em> </strong>，相当于学习数据的隐藏表示<strong class="ki jk"> <em class="le"> X </em> </strong>或者将<strong class="ki jk"> <em class="le"> X </em> </strong>编码到隐藏表示中(概率编码器)。解码器部分尝试学习<strong class="ki jk"> <em class="le"> P_θ(X|z) </em> </strong>对输入空间的隐藏表示进行解码。图形模型可以表示为下图。</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lf"><img src="../Images/7ae273ca9050e7b8501c3fd234cc9277.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iO1uxR--NmFCgLkmG_gnXA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(<a class="ae jg" href="https://arxiv.org/pdf/1312.6114.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="361e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型被训练以最小化目标函数</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lk"><img src="../Images/a2292d3fcb45c2b85e9e89059079bbed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qpeycNFiCNfhBKDb7PH1jQ.png"/></div></div></figure><p id="4c9d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该损失的第一项是重建误差或数据点的预期负对数似然。通过取几个样本，相对于编码器在表示上的分布来取期望值。当使用来自潜在分布的样本时，该术语鼓励解码器学习重构数据。较大的错误表示解码器无法重建数据。</p><p id="7521" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二项是编码器分布<strong class="ki jk"> <em class="le"> q_φ(z|x) </em> </strong>和<strong class="ki jk"> <em class="le"> p(z) </em> </strong>之间的Kullback-Leibler散度。该散度测量当使用<strong class="ki jk"> <em class="le"> q </em> </strong>来表示优于<strong class="ki jk"> <em class="le"> z </em> </strong>的先验时丢失了多少信息，并促使其值为高斯值。</p><p id="6729" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在生成期间，来自<strong class="ki jk"><em class="le">【N(0，1)】</em></strong>的样本被简单地馈入解码器。训练和生成过程可以表示如下</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/ef9aac240a6c8fc32466f8e7886dcb7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*6MxYa1CLA4Kuy0i65Wc4sw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作为前馈神经网络实现的训练时变分自动编码器，其中P(X|z)是高斯型的。红色表示不可微分的采样操作。蓝色显示损失计算。(<a class="ae jg" href="https://arxiv.org/pdf/1606.05908.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><figure class="lg lh li lj gt iv gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/d4641f34d31a1561d8ad2abfa8fc45dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*3eiBobCP6g1mqscka7MVag.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">测试时变化的“自动编码器”，它允许我们生成新的样本。“编码器”路径被简单地丢弃了。(<a class="ae jg" href="https://arxiv.org/pdf/1606.05908.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="5c6c" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">之所以如此简短地描述VAE，是因为它不是主要的焦点，但与主题非常相关。</p><p id="3794" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用VAE生成数据的一个问题是，我们无法控制它会生成什么样的数据。例如，如果我们用MNIST数据集训练一个VAE，并尝试通过将<strong class="ki jk"> <em class="le"> Z ~ N(0，1) </em> </strong>馈入解码器来生成图像，也会产生不同的随机数。如果我们训练得好，图像会很好，但我们无法控制它会产生什么数字。例如，您不能告诉VAE产生数字“2”的图像。</p><p id="0987" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，我们需要对我们的VAE架构做一点小小的改变。假设给定一个输入<strong class="ki jk"> <em class="le"> Y </em> </strong>(图像的标签)我们希望我们的生成模型产生输出<strong class="ki jk"> <em class="le"> X </em> </strong>(图像)。因此，VAE的过程将修改如下:给定观测值<strong class="ki jk"> <em class="le"> y，z </em> </strong>从先验分布<strong class="ki jk"> <em class="le"> P_θ(z|y </em> </strong>)中得出，输出<strong class="ki jk"> x </strong>从分布<strong class="ki jk"> <em class="le"> P_θ(x|y，z) </em> </strong>中产生。请注意，对于简单的VAE，先验是<strong class="ki jk"><em class="le"/></strong>P _θ(z)<strong class="ki jk"><em class="le">P _θ(x | z)</em></strong>产生输出。</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/79794ec4ca37ad43f1d750dadd6b1bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*QjUR_IRCfq7sNV6yb6W6cQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">条件VAE中的视觉表征任务(<a class="ae jg" href="https://ijdykeman.github.io/ml/2016/12/21/cvae.html" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="f324" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，这里编码器部分尝试学习<strong class="ki jk"> <em class="le"> q_φ(z|x，y) </em> </strong>，这相当于学习数据的隐藏表示<strong class="ki jk"> <em class="le"> X </em> </strong>或者将<strong class="ki jk"> <em class="le"> X </em> </strong>编码成隐藏表示条件<strong class="ki jk"> <em class="le"> y </em> </strong>。解码器部分尝试学习<strong class="ki jk"> <em class="le"> P_θ(X|z，y) </em> </strong>对由<strong class="ki jk"> <em class="le"> y </em> </strong>限定的输入空间的隐藏表示进行解码。图形模型可以表示为下图。</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lo"><img src="../Images/da90651bb84b721b61f14a6fc5fc3367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zcqQjh9NsvJD72PU8xv9Rg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(<a class="ae jg" href="https://arxiv.org/pdf/1606.05908.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="d5dd" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">条件VAE (CVAE)的神经网络架构可以表示为下图。</p><figure class="lg lh li lj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/f665202e5a827498dfdbe44a66cb324d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gA2JdLZJ12gQtnqakU7KAQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">x是图像。y是图像的标签，可以是1热矢量表示。</p></figure><p id="27fc" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CVAE在Keras的实现可在<a class="ae jg" href="https://github.com/nnormandin/Conditional_VAE/blob/master/Conditional_VAE.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><h1 id="baf6" class="lp lq jj bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">参考资料:</h1><ol class=""><li id="7904" class="mn mo jj ki b kj mp kn mq kr mr kv ms kz mt ld mu mv mw mx bi translated"><a class="ae jg" href="https://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models.pdf" rel="noopener ugc nofollow" target="_blank">使用深度条件生成模型学习结构化输出表示</a></li><li id="200a" class="mn mo jj ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><a class="ae jg" href="https://arxiv.org/pdf/1606.05908.pdf" rel="noopener ugc nofollow" target="_blank">变型自动编码器教程</a></li><li id="dd96" class="mn mo jj ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated"><a class="ae jg" href="https://arxiv.org/pdf/1312.6114.pdf" rel="noopener ugc nofollow" target="_blank">自动编码变分贝叶斯</a></li></ol></div></div>    
</body>
</html>