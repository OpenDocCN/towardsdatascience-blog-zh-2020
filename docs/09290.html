<html>
<head>
<title>How to stream real-time data into Snowflake with Amazon Kinesis Firehose</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用亚马逊 Kinesis Firehose 将实时数据流式传输到雪花中</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/streaming-real-time-data-into-snowflake-with-amazon-kinesis-firehose-74af6fe4409?source=collection_archive---------10-----------------------#2020-07-03">https://towardsdatascience.com/streaming-real-time-data-into-snowflake-with-amazon-kinesis-firehose-74af6fe4409?source=collection_archive---------10-----------------------#2020-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/7a4b608755bed3495b9025523c288011.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QZOk90VWRHpOXRX9"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">若昂·布兰科在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><p id="877d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如今，企业可以从各种数据源不断产生的大规模、高速度数据中实时获益。无论是来自网站的点击流数据、来自物联网设备的遥测数据还是来自应用程序的日志数据，持续分析这些数据可以帮助企业了解他们的客户、应用程序和产品目前正在做什么，并迅速做出反应。</p><p id="2374" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们希望探索如何使用 Amazon Kinesis Firehose 在雪花数据仓库中实时提供新数据，而不是在长时间间隔内使用传统的批处理。其动机是帮助企业了解如何为强大的实时应用和分析用例奠定基础。</p><p id="57d3" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于那些可能不熟悉这些技术的人，我们将提供一个非常快速的总结，但我们这篇文章的主要重点是演示如何编写一个简单的应用程序来发送数据到雪花。在这次演示中，我们将使用 Twitter API 来传输实时推文。</p><h1 id="be64" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">雪花云数据仓库</h1><p id="e5bd" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">雪花是一个云原生的、完全关系的 ANSI SQL 数据仓库服务，在 AWS 和 Azure 中都可用。它提供了一种基于消费的使用模式，具有无限的可扩展性。它能够加载结构化和半结构化数据，如 JSON、Avro 或 XML。</p><h1 id="f753" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">亚马逊 Kinesis 消防软管</h1><p id="2f36" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">亚马逊 Kinesis Firehose 是将流数据加载到 AWS 的最简单方法。它可以捕捉、转换流数据并将其加载到亚马逊 Kinesis Analytics、AWS S3、AWS Redshift 和 AWS Elasticsearch 服务中。这是一项完全托管的服务，可自动扩展以匹配您的数据吞吐量。它还可以在加载数据之前对数据进行批处理、压缩和加密。</p><h1 id="b47f" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">我们的场景</h1><p id="e74b" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">推文持续发布在 Twitter 上，因此它是我们用作实时流的一个很好的来源。在这个例子中，我们将使用 Twitter 的流媒体 API 从 Twitter 获取新发布的推文。要做到这一点，我们必须创建一个到 Twitter API 的持久连接，并增量读取每个连接，然后快速处理每个 tweet，这样我们的程序就不会出现备份。</p><p id="2722" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将构建一个简单的 python 程序来调用 Tweets。在此之前，您必须设置您的 Twitter 开发者帐户并创建一个应用程序。首先去<a class="ae jg" href="https://developer.twitter.com/en" rel="noopener ugc nofollow" target="_blank"> Twitter 开发者中心</a>创建一个开发者账户。然后转到<a class="ae jg" href="https://developer.twitter.com/en/apps" rel="noopener ugc nofollow" target="_blank">应用控制台</a>并创建一个新的 Twitter 应用。这将让您获得应用程序连接到 API 的特定凭证。</p><p id="fdb6" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，让我们编写一个简单的应用程序，用持久会话调用 Twitter API。流式 API 不同于 REST API，因为它将消息推送到持久会话，而 REST API 用于提取数据。这允许流式 API 在数据可用时实时推送数据。</p><p id="008d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了设置我们的应用程序，我们将安装一个名为 Tweepy 的 python 库。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="9d46" class="mq lf jj mm b gy mr ms l mt mu">pip install tweepy</span></pre><p id="2da6" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们像这样设置对 API 的调用:</p><figure class="mh mi mj mk gt iv"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="3235" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要使用 Twitter 验证您的应用，请使用您的应用凭据选项卡中的信息替换上面的凭据信息。为了设置我们的流，我们首先配置一个监听器类，它告诉我们应该如何处理数据。目前，侦听器只是打印数据。我们稍后将替换这部分逻辑，以便将数据发送到我们的 AWS Kinesis Firehose。track 变量是 Twitter 将返回相关推文的关键字列表。对于这个例子，我使用了“篮球”作为关键字。</p><h1 id="bcbd" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">设置 Kinesis 消防软管和 AWS S3</h1><p id="8888" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">API 返回我们希望流式传输并存储在临时区域中的消息。通常情况下，雪花从 S3 加载数据，所以我们会将我们的消息作为文件存储在 S3，供雪花摄取。</p><p id="e3c1" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在你设置 Kinesis 消防水管和 S3 水桶之前，你需要一个有权限创建 S3 和 Kinesis 资源的用户。请确保还创建了 aws 访问密钥和 aws 秘密密钥，用于编程访问，因为我们稍后会用到它们。</p><p id="3e6c" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki jk">设置消防水管服务</strong></p><ol class=""><li id="bbaa" class="mx my jj ki b kj kk kn ko kr mz kv na kz nb ld nc nd ne nf bi translated">转到亚马逊 Kinesis 控制台，创建一个交付流。选择一个流名称，并选择“直接上传或其他来源”作为您的来源。这将允许我们通过 API 调用将记录直接发送到我们的 Kinesis 流。为了简单起见，我们不会在本演示中设置任何数据转换。单击下一步，直到到达目标部分。</li><li id="d8f2" class="mx my jj ki b kj ng kn nh kr ni kv nj kz nk ld nc nd ne nf bi translated">选择 S3 作为您的目的地，然后单击创建一个新的存储桶，并为您的存储桶选择一个唯一的名称。</li><li id="9911" class="mx my jj ki b kj ng kn nh kr ni kv nj kz nk ld nc nd ne nf bi translated">接下来，我们将选择缓冲区大小和缓冲区间隔。Kinesis 缓冲输入数据流，直到达到缓冲区大小或缓冲区间隔。在本演示中，我们将积极地将两者分别设置为最小 1 MB 和 60 秒。</li><li id="964e" class="mx my jj ki b kj ng kn nh kr ni kv nj kz nk ld nc nd ne nf bi translated">在本次演示中，我们不会设置数据压缩或加密。对于 IAM 角色部分，保留默认选择，允许 AWS 创建具有必要权限的 IAM 角色。这个角色将允许 Kinesis 与 S3 交流。</li><li id="17bc" class="mx my jj ki b kj ng kn nh kr ni kv nj kz nk ld nc nd ne nf bi translated">最后，检查您的设置并创建您的交付流。</li></ol><h1 id="6b5a" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">修改 python 应用程序</h1><p id="107e" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">现在我们的 AWS 服务已经设置好了，我们可以在 python 应用程序中修改 listener 类，这样每个新消息不仅可以打印到标准输出，还可以发送到我们的 Kinesis 交付流。我们可以使用 AWS 的 Boto3 库向我们的流发送数据。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="085c" class="mq lf jj mm b gy mr ms l mt mu">pip install boto3</span></pre><p id="eacf" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们是这样做的:</p><figure class="mh mi mj mk gt iv"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="7642" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要使用 AWS 对您的客户端进行身份验证，请在 credentials 变量中替换您的凭据。在这里，我们简单地设置一个函数，在设置资源的区域使用 Boto3 创建 Kinesis 客户端，并调用 put_record 函数将数据写入我们的交付流名称。我们还将数据的字符串数据类型转换为字节。为了将每条消息写入传递流，我们可以从侦听器类中调用我们的函数，以便在新消息到达时将它们传递给我们的函数。</p><p id="a29e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，您可以运行您的 python 脚本，并在 Twitter 将消息推送到您的 standard out 时查看新消息。还要监控您的 S3 时段以查看传入的数据。当我们的交付流中的每个缓冲区都完成时，它将使用新的微批处理向 S3 写入一个新文件。</p><h1 id="bde4" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">设置雪花</strong></h1><p id="ab64" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">现在，我们有了实时进入 S3 的数据，我们可以设置我们的雪花数据仓库来接收可用的数据。通常，将数据加载到雪花中时，首选方法是将大量数据收集到 S3 存储桶中，并通过复制命令从外部阶段加载。然而，为了持续加载数据，雪花建立了一个名为 Snowpipe 的数据摄取服务。Snowpipe 在外部阶段一有可用的新数据，就以微批处理的方式加载新数据。</p><p id="5413" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要设置我们的雪花资源，首先登录到您的雪花 Web UI 并切换到工作表标签。</p><p id="f99f" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于此演示，我们需要以下雪花资源；一个用于执行 SQL 查询的计算资源的仓库，一个存储我们的 tweets 的数据库，一个将数据加载到 Snowflake 的外部阶段和一个持续加载数据的管道。</p><p id="50b5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">执行以下 SQL 来配置这些资源</p><ol class=""><li id="76d0" class="mx my jj ki b kj kk kn ko kr mz kv na kz nb ld nc nd ne nf bi translated">创建仓库</li></ol><figure class="mh mi mj mk gt iv"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="009e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.创建数据库和表</p><figure class="mh mi mj mk gt iv"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="3ed8" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用 variant 数据类型，因为我们接收的数据是半结构化的。</p><p id="00a4" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.接下来，我们为 S3 存储桶创建一个外部阶段</p><figure class="mh mi mj mk gt iv"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="d323" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">4.创建从外部阶段复制到 tweets 表的管道</p><figure class="mh mi mj mk gt iv"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="b8bd" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们差不多完成了。我们的管道将从它为我们创建的 AWS 队列中读取数据。我们需要将这个队列连接到我们的 S3 存储桶，以便每当一个新文件被添加到 S3 存储桶时，存储桶将把它推到队列中，然后由我们的管道读取。这就是管道如何知道文件可以被实时接收的原因。</p><p id="c951" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要为队列配置 S3 存储桶，我们需要队列的 AWS 资源 Id。运行以下 SQL:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="bcf3" class="mq lf jj mm b gy mr ms l mt mu">show pipes</span></pre><p id="8ab2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在结果中，为您创建的管道检查名为 notification channel 的列，并复制资源 ID。</p><p id="01fa" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回到 AWS，转到 S3，点击你的桶进行演示，切换到属性，进入高级设置。然后点击事件并添加新事件。</p><p id="2dc5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为您的活动命名。并选择“所有对象创建事件”。选择“发送到 SQS 队列”，并在“SQS 队列 ARN”字段中添加您的资源 ID。然后保存您的活动。</p><p id="88b1" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在你完成了。运行 python 脚本，并在 S3 存储桶接收新文件时对其进行监控。这些文件现在将作为我们创建的雪花表中的新行被接收。通过运行 SQL select 查询进行确认。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="b4cf" class="mq lf jj mm b gy mr ms l mt mu">select count(*) from twitter_stream.public.tweets;</span></pre><p id="1a64" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每隔几分钟运行一次查询，您会注意到表中的行数在增加。这意味着设置工作正常。你可以实时从 Twitter 直接接收数据到 Snowflake。</p><p id="04bb" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">运行下面的查询来查看进入雪花的每个新批次的时间窗口。</p><figure class="mh mi mj mk gt iv"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="2464" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">就这样…</h1><p id="ab9a" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">一旦数据进入您的数据仓库，就会有许多强大的用例，但是这些讨论超出了本文的范围。我们向您展示了一个非常简单的设置，让您更好地理解将数据实时发送到您的仓库所涉及的服务。</p><p id="0e3b" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了亚马逊 Kinesis，还有其他流处理平台，如 Apache Kafka。每种方法都有其优缺点，这取决于您想要构建的解决方案。此外，大多数使用情形都有更复杂的要求，例如在设计解决方案时需要考虑多个数据源、延迟规格和不断变化的数据量。</p><p id="61dc" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您有实时分析用例，请通过<a class="ae jg" href="http://www.waterfrontanalytics.com" rel="noopener ugc nofollow" target="_blank"> Waterfront Analytics </a>联系我们，我们可以帮助您确保您的用例获得高价值的业务成果。</p></div></div>    
</body>
</html>