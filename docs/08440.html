<html>
<head>
<title>RecoTour III: Variational Autoencoders for Collaborative Filtering with Mxnet and Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RecoTour III:使用Mxnet和Pytorch进行协同过滤的可变自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recotour-iii-variational-autoencoders-for-collaborative-filtering-with-mxnet-and-pytorch-710c924fa2fd?source=collection_archive---------25-----------------------#2020-06-19">https://towardsdatascience.com/recotour-iii-variational-autoencoders-for-collaborative-filtering-with-mxnet-and-pytorch-710c924fa2fd?source=collection_archive---------25-----------------------#2020-06-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="1915" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这篇文章和这里的代码是一个更大的名为<a class="ae ko" href="https://github.com/jrzaurin/RecoTour" rel="noopener ugc nofollow" target="_blank"> RecoTour </a>的报告的一部分，在那里我通常探索和实现一些我认为有趣和/或有用的推荐算法(见<a class="ae ko" href="https://medium.com/datadriveninvestor/recotour-a-tour-through-recommendation-algorithms-in-python-52d780628ab9" rel="noopener"> RecoTour </a>和<a class="ae ko" rel="noopener" target="_blank" href="/recotour-ii-neural-recommendation-algorithms-49733938d56e">recotouri</a>)。在每个目录中，我都包含了一个<code class="fe kp kq kr ks b">README</code>文件和一系列解释笔记本，我希望它们能帮助解释代码。我一直不定时的加算法，有兴趣的继续关注。</p><p id="eb08" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">像往常一样，让我首先感谢做了艰苦工作的相关人员。这篇文章和配套的报告是基于论文“<a class="ae ko" href="https://arxiv.org/pdf/1802.05814.pdf" rel="noopener ugc nofollow" target="_blank">协同过滤的变分自动编码器</a>”[1]和“<a class="ae ko" href="https://arxiv.org/pdf/1312.6114.pdf" rel="noopener ugc nofollow" target="_blank">自动编码变分贝叶斯</a>”[2]。这里和回购中的代码部分受到了来自<a class="ae ko" href="https://github.com/younggyoseo/vae-cf-pytorch" rel="noopener ugc nofollow" target="_blank"> Younggyo Seo </a>的实现的启发。我根据自己的编码偏好修改了代码，并添加了一些选项和灵活性来运行多个实验。</p><p id="73c7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">深入研究用于协同过滤的变分自动编码器的原因是因为它们似乎是少数基于深度学习的算法之一(如果不是唯一的)，比那些使用非深度学习技术的算法获得更好的结果<a class="ae ko" href="https://arxiv.org/abs/1907.06902" rel="noopener ugc nofollow" target="_blank">【3】</a>。</p><p id="a694" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在整个练习中，我将使用两个数据集。<a class="ae ko" href="http://jmcauley.ucsd.edu/data/amazon/" rel="noopener ugc nofollow" target="_blank">亚马逊电影和电视</a>数据集【4】【5】和<a class="ae ko" href="https://grouplens.org/datasets/movielens/20m/" rel="noopener ugc nofollow" target="_blank">电影镜头</a>数据集。后者用于确保我获得的结果与论文中的一致。亚马逊数据集比Movielens数据集更具挑战性，因为它的稀疏度是movie lens数据集的13倍。</p><p id="f74c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文中的所有实验都是使用AWS上的p2.xlarge EC2实例运行的。</p><p id="6092" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://jrzaurin.github.io/infinitoml/2020/05/15/mult-vae.html" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> <em class="kt">越详细，</em> </strong> </a>原文本帖子在我的<a class="ae ko" href="https://jrzaurin.github.io/infinitoml/" rel="noopener ugc nofollow" target="_blank">博客</a>中发表。这是对内容的总结，更侧重于实现/代码和相应的结果，而不是数学。</p><h1 id="a040" class="ku kv it bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">1.部分正则多项式变分自动编码器:损失函数</h1><p id="96d1" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated">在本节中，我假设读者对可变自动编码器(vae)有一些经验。如果不是这样，我推荐阅读<a class="ae ko" href="https://arxiv.org/pdf/1312.6114.pdf" rel="noopener ugc nofollow" target="_blank">金马和韦林的论文</a>、<a class="ae ko" href="https://arxiv.org/pdf/1802.05814.pdf" rel="noopener ugc nofollow" target="_blank">梁等人的论文</a>，或者<a class="ae ko" href="https://jrzaurin.github.io/infinitoml/2020/05/15/mult-vae.html" rel="noopener ugc nofollow" target="_blank">原帖</a>。在那里，读者将找到我们在实现部分正则化多项式变分自动编码器(多VAE)时将使用的<em class="kt">损失</em>函数的详细推导。这里，我将只包括最后一个表达式，并简要介绍一些我认为有助于理解多VAE实现和等式(1)中的损耗的附加信息。</p><p id="5713" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我首先描述一下记数惯例。继<a class="ae ko" href="https://arxiv.org/pdf/1802.05814.pdf" rel="noopener ugc nofollow" target="_blank">梁等人2018 </a>之后，我将用<strong class="js iu"> u </strong> ∈ {1、…、<strong class="js iu">、 </strong> }索引用户，用<strong class="js iu"> i </strong> ∈ {1、…、<strong class="js iu"> <em class="kt"> I </em> </strong> }索引条目。用户逐项二进制交互矩阵(即点击矩阵)是<strong class="js iu">x</strong>∈ℕ^{<strong class="js iu"><em class="kt">u</em></strong>×<strong class="js iu"><em class="kt">I</em></strong>}并且我将使用小写字母<strong class="js iu"><em class="kt">【xᵤ</em></strong>=<strong class="js iu"><em class="kt">x</em></strong>_ { u1 }，…，<strong class="js iu"><em class="kt">x</em></strong>_ { 0</p><p id="1b6c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据这一符号，多VAE <em class="kt">损失</em>函数定义为:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi lx"><img src="../Images/4f57fb0ae931fa91a80c75bf0a8344f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hIwKUJ3z96eJjHnMf3u0A@2x.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">Eq 1。多VAE损失函数</p></figure><p id="7acf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中<em class="kt"> M </em>为小批量。求和中的第一个元素仅仅是点击历史的对数似然性<strong class="js iu"><em class="kt">【xᵤ】</em></strong>【条件反射】到潜在表示<strong class="js iu">z<em class="kt">ᵤ</em></strong><em class="kt">log</em>(<em class="kt">pθ</em>(<strong class="js iu"><em class="kt">xᵤ</em>|</strong>|<strong class="js iu">z<em class="kt">ᵤ</em></strong>)(见下文)。第二个要素是当编码器和解码器分布都是高斯分布时VAEs的kull back-lei bler散度(见<a class="ae ko" href="https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes" rel="noopener ugc nofollow" target="_blank">这里的</a>)。</p><p id="8247" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们开始写代码之前，我们还需要一些细节。<strong class="js iu"><em class="kt"/></strong><strong class="js iu"><em class="kt"/></strong>用户的点击历史<strong class="js iu"/>，定义为:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/af79b7e97c6429749090303ab0628ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*-sr0WE4N8hboVPzG99yZ7w@2x.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">Eq 2。点击用户的历史记录<strong class="bd mo"> u </strong></p></figure><p id="b782" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中<strong class="js iu"><em class="kt">nᵤ=</em></strong>∑<strong class="js iu"><em class="kt">ᵢnᵤᵢ</em></strong>为用户<strong class="js iu"> u </strong> <em class="kt">的点击总数。</em>正如我之前提到的<em class="kt">，</em>，<strong class="js iu"> z <em class="kt">，</em>，</strong>，<em class="kt">，</em>是<strong class="js iu">，，</strong>，<strong class="js iu">，<em class="kt">，</em>，</strong>的潜在表示，并且被假定为从一个标准的高斯先验<em class="kt">pθ</em>(<strong class="js iu">z<em class="kt"/></strong>)<strong class="js iu"><em class="kt"/></strong>√在多值的实现过程中，<strong class="js iu"> z <em class="kt"> ᵤ </em> </strong>需要从一个近似的后验概率<em class="kt">qϕ</em>(<strong class="js iu">z<em class="kt">ᵤ</em></strong>∣<strong class="js iu">x<em class="kt">ᵤ</em></strong>)(也假设为高斯)。由于涉及采样时计算梯度是…" <em class="kt">复杂的</em>"，<a class="ae ko" href="https://arxiv.org/pdf/1312.6114.pdf" rel="noopener ugc nofollow" target="_blank"> Kingma和Welling </a>介绍了所谓的重新参数化技巧(请阅读<a class="ae ko" href="https://arxiv.org/pdf/1312.6114.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>、<a class="ae ko" href="https://jrzaurin.github.io/infinitoml/2020/05/15/mult-vae.html" rel="noopener ugc nofollow" target="_blank">原始帖子</a>或任何<a class="ae ko" href="https://gregorygundersen.com/blog/2018/04/29/reparameterization/#:~:text=Reddit%3A%20The%20%E2%80%9Ctrick%E2%80%9D%20part,you%20can't%20do)." rel="noopener ugc nofollow" target="_blank">多种在线资源</a>以了解有关重新参数化技巧的更多细节)，以便采样后的<strong class="js iu"> z <em class="kt"> ᵤ </em> </strong></p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/7d32bcfb9398543a4b7814b5204e2f53.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*6D1fZSxX5cs58Vblb35XIw@2x.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">Eq 3。取样的<strong class="bd mo"> z <em class="mq"> ᵤ </em> </strong> <em class="mq">(因此上标有‘s’)将用于多值</em>的实现</p></figure><p id="51ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">方程3中的<strong class="js iu"> <em class="kt"> μ </em> </strong>和<strong class="js iu"> <em class="kt"> σ </em> </strong>是神经网络的函数，<em class="kt">ϵ</em>∾<strong class="js iu"><em class="kt">n</em></strong>(0，I)是高斯噪声。当我们看到相应的代码时，他们的计算将变得更加清晰。最后，等式(2)中的π( <strong class="js iu"> z <em class="kt"> ᵤ </em> </strong>)是π(<strong class="js iu">z<em class="kt">ᵤ</em></strong>)=<em class="kt">soft max</em>(<strong class="js iu">z<em class="kt">ᵤ</em></strong>)。</p><p id="8aee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这个阶段，我们几乎拥有了实现等式(1)中的多值及其损失函数所需的所有信息:我们知道什么是<strong class="js iu"><em class="kt">【xᵤ】</em></strong>，<strong class="js iu">z<em class="kt">【ᵤ】，μ </em> </strong>和<strong class="js iu"> <em class="kt"> σ </em> </strong>将是我们的神经网络的函数，而π就是<em class="kt"> Softmax </em>函数。从等式(1)讨论剩下的唯一“字母”是<em class="kt"> β </em>。</p><p id="bd29" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在VAEs的上下文中查看等式(1)中的损失函数，我们可以看到第一项是“重建损失”，而<em class="kt"> KL </em>散度作为正则项。考虑到这一点，<a class="ae ko" href="https://arxiv.org/pdf/1802.05814.pdf" rel="noopener ugc nofollow" target="_blank">梁等人</a>增加了一个因子<em class="kt"> β </em>来控制正则化的强度，提出了<em class="kt"> β </em> &lt; 1。为了更深入地反映<em class="kt"> β、</em>的作用，以及更好地解释多VAE <em class="kt">、</em>损失函数的形式，请阅读<a class="ae ko" href="https://arxiv.org/pdf/1802.05814.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>或<a class="ae ko" href="https://jrzaurin.github.io/infinitoml/2020/05/15/mult-vae.html" rel="noopener ugc nofollow" target="_blank">原始帖子</a>。</p><p id="5243" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">事不宜迟，让我们来看看代码:</p><h1 id="2bda" class="ku kv it bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">2.准备数据。</h1><p id="4635" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated">正如我在帖子前面提到的，这是对原帖子的总结。考虑到这一点，我将在这里简要描述如何在不包含代码的情况下准备数据。读者可以在<a class="ae ko" href="https://github.com/dawenl/vae_cf/blob/master/VAE_ML20M_WWW2018.ipynb" rel="noopener ugc nofollow" target="_blank">原始实现</a>、<a class="ae ko" href="https://jrzaurin.github.io/infinitoml/2020/05/15/mult-vae.html#2.-Preparing-the-data" rel="noopener ugc nofollow" target="_blank">原始发布</a>或<a class="ae ko" href="https://github.com/jrzaurin/RecoTour/tree/master/Amazon/mult-vae" rel="noopener ugc nofollow" target="_blank">回购</a>中找到与数据准备相关的代码。</p><p id="f1ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">基本上，作者将数据分为培训、验证和测试用户及其相应的交互。然后，他们将验证和测试交互分成所谓的“<em class="kt">验证和测试训练以及测试集</em>”。</p><p id="f3d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我知道这听起来很复杂，但并不复杂。“<em class="kt">验证_训练和测试_训练集合</em>”在这里包括总验证和测试集合的80%，将被用于构建我们可以认为是输入二进制<em class="kt">“图像”</em>(即点击的二进制矩阵)，该输入二进制将由经过训练的自动编码器进行“<em class="kt">编码→解码</em>。另一方面，“<em class="kt">验证_测试和测试_测试集</em>”包括总验证和测试集的20%，将用于计算验证/测试时的排名指标。如果您想了解更多细节以及玩具示例，请前往回购中相应的<a class="ae ko" href="http://localhost:8790/notebooks/notebooks/01_prepare_data.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>。</p><h1 id="89d0" class="ku kv it bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">3.部分正则多项式变分自动编码器:代码</h1><p id="28f9" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated">我已经使用<code class="fe kp kq kr ks b">Mxnet</code>的<code class="fe kp kq kr ks b">Gluon</code>和<code class="fe kp kq kr ks b">Pytorch</code>实现了多重VAE。在这一节中，我将只关注<code class="fe kp kq kr ks b">Mxnet</code>的实现。如果您对<code class="fe kp kq kr ks b">Pytorch</code>的实施感兴趣，请前往<a class="ae ko" href="https://github.com/jrzaurin/RecoTour/tree/master/Amazon/mult-vae" rel="noopener ugc nofollow" target="_blank">回购</a>。</p><p id="9dfa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与任何自动编码器架构一样，主要的两个元素是(屏住呼吸…)编码器和解码器。在<a class="ae ko" href="https://arxiv.org/pdf/1802.05814.pdf" rel="noopener ugc nofollow" target="_blank">原始出版物</a>中，作者使用一个隐藏层MLP作为生成模型。他们说更深层次的架构并不能改善结果，在进行了60多次实验后，我发现这是真的。带着这样的想法，我们先来看看模型[ <em class="kt"> I→600→200→600→I </em> ]其中<em class="kt"> I </em>是项目总数:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mr"><img src="../Images/74f04e616d90dc5e4d8fc534eb6cbe50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1oa6SeT8ZvQ7bgBjHVhP3A@2x.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">图一。多VAE建筑。这些颜色是我试图引导眼睛通过重新参数化的技巧过程。</p></figure><p id="7c43" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在代码中，图(1)是:</p><p id="8116" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3.1编码器</strong></p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">片段1。多VAE编码器。注意第20行中的<strong class="ak"> <em class="mq"> μ </em> </strong>，<strong class="ak"><em class="mq">∑</em></strong>分割，作为重新参数化技巧的一部分。这种分离对应于图1中的绿色和红色</p></figure><p id="a4bd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3.2解码器</strong></p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">片段2。多VAE解码器</p></figure><p id="a898" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3.3完整型号</strong></p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">片段3。多VAE模型。注意第15–18行发生的重新参数化。线18对应于图1中的黄色</p></figure><p id="67e3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我继续之前，让我提一下(并欣赏)一下<code class="fe kp kq kr ks b">Mxnet</code>的<code class="fe kp kq kr ks b">Gluon</code>所提供的许多美好的<em class="kt">小</em>事物中的一个。当我们定义向前传球，或者更准确地说，<code class="fe kp kq kr ks b">hybrid_forward</code>传球时，你会注意到<code class="fe kp kq kr ks b">HybridBlock</code>和输入<code class="fe kp kq kr ks b">F</code>(后端)的使用。人们可以写一个完整的帖子，介绍一下<code class="fe kp kq kr ks b">HybridBlocks</code>的乐趣，以及开发<code class="fe kp kq kr ks b">Gluon</code>的人是如何将命令式框架(例如<code class="fe kp kq kr ks b">Pytorch</code>)的灵活性和声明式框架(例如<code class="fe kp kq kr ks b">Tensorflow</code>)的速度完美地结合在一起的。如果你想了解细节，去<a class="ae ko" href="https://gluon.mxnet.io/chapter07_distributed-learning/hybridize.html" rel="noopener ugc nofollow" target="_blank">这里</a>，但是相信我，这很快。</p><p id="5f4b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">话虽如此，我们还需要一个完整的模型，即等式(1)中的损失函数。</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">片段4。多VAE损失的实现(即等式(1))</p></figure><p id="a6e7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<a class="ae ko" href="https://arxiv.org/pdf/1802.05814.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中，作者还使用了多项式去噪自动编码器(Mult-DAE)。除了没有任何变化之外，其架构与Mult-VAE的架构完全相同。我已经实现了Mult-DAE，并用它进行了多次实验。然而，鉴于它的简单性和已经很长的帖子，我不会在这里讨论相应的代码。</p><p id="d52d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，按照最初的实现，我在多VAE和多DAE的输入层应用了dropout，以避免过度拟合。我还包括在整个网络中应用辍学的选项。</p><p id="19ef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">还要注意的是，尽管我研究了不同的漏失，解决漏失、权重衰减、<em class="kt"> β </em>等与架构之间相互影响的最佳方式是使用“<em class="kt"> proper </em>”超参数优化。</p><h1 id="95a2" class="ku kv it bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">4.培训、验证和测试</h1><p id="45bd" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated"><strong class="js iu"> 4.1退火时间表</strong></p><p id="6a8f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如前所述，我们可以将Kullback-Leiber散度解释为一个正则项。考虑到这一点，在一个受<a class="ae ko" href="https://arxiv.org/abs/1511.06349" rel="noopener ugc nofollow" target="_blank"> Samuel R. Bowman等人2016</a>【6】启发的程序中，梁和合著者在大量训练步骤中缓慢地线性退火KL项(即增加<em class="kt"> β </em>)。</p><p id="2efa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">更具体地说，作者将KL散度一直退火到<em class="kt"> β </em> = 1，在该过程中使用的总历元数的大约80%处达到该值。然后，他们根据峰值验证指标确定表现最佳的<em class="kt"> β </em>，并使用相同的退火计划重新训练模型，但在达到该值后停止增加<em class="kt"> β </em>。</p><p id="559a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们去<a class="ae ko" href="https://github.com/dawenl/vae_cf/blob/master/VAE_ML20M_WWW2018.ipynb" rel="noopener ugc nofollow" target="_blank">他们的实现</a>，这些是过程的细节:使用500的批量，他们设置退火步骤的总数为200000。假设训练数据集的大小为116677，每个时期有234个训练步骤。它们的<code class="fe kp kq kr ks b">anneal_cap</code>值，即训练期间达到的最大退火，被设置为0.2，并且在训练期间它们使用以下方法:</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">片段5。原始退火时间表</p></figure><p id="73b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">其中<code class="fe kp kq kr ks b">update_count</code>每训练一步/批次增加1。他们使用200个时期，因此，如果我们做数学计算，当<code class="fe kp kq kr ks b">update_count / total_anneal_steps</code> = 0.2时，即在40000个训练步骤之后，或者换句话说，在大约170个时期之后，即时期总数的80%之后，<code class="fe kp kq kr ks b">anneal_cap</code>值将停止增加。</p><p id="d3c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">考虑到这一点，我的实现如下所示:</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">片段6。我稍微调整了一下退火计划。</p></figure><p id="d9e7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦设定了<code class="fe kp kq kr ks b">total_anneal_steps</code>，剩下的唯一事情就是定义培训和验证步骤。如果你熟悉<code class="fe kp kq kr ks b">Pytorch</code>，接下来的两个功能你会觉得很熟悉。</p><p id="cb81" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 4.2培训步骤</strong></p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">片段7。使用Mxnet的胶子的训练步骤</p></figure><p id="8460" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 4.3验证步骤</strong></p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">代码片段8。使用Mxnet的胶子的评估步骤。</p></figure><p id="ea65" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我在这个<a class="ae ko" href="https://github.com/jrzaurin/RecoTour" rel="noopener ugc nofollow" target="_blank"> repo </a>(以及相应的帖子)中的多个笔记本里广泛讨论过评测指标(NDCG@k和召回@k)。因此，考虑到这一点，也为了不使这篇文章成为一篇更“无限的帖子”，我将不在这里描述相应的实现。如果您想了解这些评估指标的详细信息，请转到<code class="fe kp kq kr ks b"><a class="ae ko" href="https://github.com/jrzaurin/RecoTour/tree/master/Amazon/mult-vae/utils" rel="noopener ugc nofollow" target="_blank">utils</a></code>中的<code class="fe kp kq kr ks b"><a class="ae ko" href="https://github.com/jrzaurin/RecoTour/blob/master/Amazon/mult-vae/utils/metrics.py" rel="noopener ugc nofollow" target="_blank">metrics.py</a></code>模块。这里的代码对最初的实现<a class="ae ko" href="https://github.com/dawenl/vae_cf/blob/master/VAE_ML20M_WWW2018.ipynb" rel="noopener ugc nofollow" target="_blank">中的代码做了很小的修改。</a></p><p id="f7dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 4.4。运行过程</strong>:</p><p id="f440" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们定义模型，准备设置并运行一个小样本(当然，忽略打印的结果。我只想说明如何运行模型)</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">片段9。运行模型</p></figure><p id="6781" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">再加上一些铃声和铃声(例如可选的学习率计划、提前停止等等)，这就是你将在<code class="fe kp kq kr ks b"><a class="ae ko" href="https://github.com/jrzaurin/RecoTour/blob/master/Amazon/mult-vae/main_mxnet.py" rel="noopener ugc nofollow" target="_blank">main_mxnet.py</a></code>中找到的代码。</p><p id="c5aa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我进入下一个，也是最后一个部分之前，我想简单地评论一下我通常在这些科学出版物中发现的一些东西。通常，一旦他们在验证集上找到了最佳超参数，他们就在测试集上测试模型。</p><p id="9838" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在“现实生活”场景中，会有一个额外的步骤，即合并训练集和验证集，用最佳超参数重新训练模型，然后在测试集上进行测试。无论如何，因为这里我的目标不是构建一个真实的系统，所以我将遵循最初的<a class="ae ko" href="https://github.com/dawenl/vae_cf/blob/master/VAE_ML20M_WWW2018.ipynb" rel="noopener ugc nofollow" target="_blank">实现</a>中的相同过程。</p><p id="8961" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在是时候看看用<code class="fe kp kq kr ks b">Pytorch</code>和<code class="fe kp kq kr ks b">Mxnet</code>得到的结果了。</p><h1 id="553b" class="ku kv it bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">5.结果摘要</h1><p id="3345" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated">让我再次提醒一下第4.1节中描述的退火时间表。基本上我们逐渐退火到<em class="kt"> β </em> =1，在总次数的80%左右达到，记录最佳退火参数(<em class="kt"> βbest </em>)。然后，我们应用相同的退火程序，但是使用<em class="kt"> βbest </em>，即，我们退火到<em class="kt"> βbest </em>在总周期数的大约80%处达到该值。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mu"><img src="../Images/87fb234b6393a0ab7397f76ac54b3b71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Yai6mNxc1COHFf_1NH15Q@2x.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">图二。与梁等人2018年的<a class="ae ko" href="https://arxiv.org/pdf/1802.05814.pdf" rel="noopener ugc nofollow" target="_blank">相同的退火时间表，适用于3种不同的架构以及使用<code class="fe kp kq kr ks b">Pytorch</code>和<code class="fe kp kq kr ks b">Mxnet</code>的Movielens和Amazon数据集。在退火程序中，β= 1 \β= 1<em class="mq">β</em>= 1在170个时期达到(200个时期中的85%)</a></p></figure><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="ms mt l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">表1。在我运行的所有实验中表现最好的实验(根据NDCG@10 )(可以在回购的`<code class="fe kp kq kr ks b">run_experiment.sh</code>文件中找到)。包含所有实验运行结果的csv文件可以在repo的<code class="fe kp kq kr ks b">all_results.csv</code>文件中找到。</p></figure><p id="7177" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图2使用<code class="fe kp kq kr ks b">Pytorch</code>和<code class="fe kp kq kr ks b">Mxnet</code>为3种不同的架构以及Movielens和Amazon数据集复制了相同的退火时间表。在退火程序中，在170个时期(200个时期中的85%)达到<em class="kt"> β </em> =1。此外，我还使用了20个时期的"<em class="kt">耐心</em>"提前停止，这就是为什么没有一个实验达到200个时期。图中竖线表示达到最佳<code class="fe kp kq kr ks b">NDGC@100</code>的时期，对应的<em class="kt"> β </em>值表示在顶部x轴。</p><p id="f6fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一方面，表1显示了我在所有实验中获得的最佳结果，您可以在文件<code class="fe kp kq kr ks b">run_experiments.sh</code>的报告中找到。</p><p id="f48f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">乍一看，这两种深度学习框架的行为有多么不同是显而易见的。我发现<code class="fe kp kq kr ks b">Pytorch</code>比<code class="fe kp kq kr ks b">Mxnet</code>表现得好一点，并且在实验中更加稳定。这是我每次使用这两个框架进行相同练习时不断发现的事情。比如这里的<a class="ae ko" href="https://github.com/jrzaurin/nlp-stuff/tree/master/amazon_reviews_classification_HAN" rel="noopener ugc nofollow" target="_blank"/>，用的是分层注意力网络。实际上，我认为这是因为我知道(或用过)的<code class="fe kp kq kr ks b">Pytorch</code>比<code class="fe kp kq kr ks b">Mxnet</code>多。尽管如此，在这个阶段，我很清楚我需要在这两个深度学习库之间进行适当的基准测试。</p><p id="ba61" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">关注图1所示的结果，第一个明显的结果是<code class="fe kp kq kr ks b">Mxnet</code>实现在很少或没有正则化的情况下表现得更好。事实上，我已经运行了60多次实验，如表1所示，使用<code class="fe kp kq kr ks b">Mult-VAE</code>和<code class="fe kp kq kr ks b">Mxnet</code>时的最佳结果是在没有正则化的情况下获得的，即使用重新参数化技巧的去噪自动编码器。此外，使用<code class="fe kp kq kr ks b">Mult-DAE</code> (NDCG@100 = 0.424)可以获得使用<code class="fe kp kq kr ks b">Mxnet</code>的最佳总体指标。</p><p id="a62a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们关注数据集之间的差异，首先显而易见的是，Amazon数据集的指标明显小于Movielens数据集。这当然是意料之中的，因为亚马逊数据集比Movielens数据集稀疏13倍，也就是说，挑战性更大。此外，我们看到<code class="fe kp kq kr ks b">Pytorch</code>实现对数据集和架构都表现出非常稳定的行为，在Amazon数据集的情况下，在训练期的后期达到最佳<code class="fe kp kq kr ks b">NDCG@10</code>。同样，这与<code class="fe kp kq kr ks b">Mxnet</code>实现的情况不同，在这种情况下，我们看到一致性较低，并且在两个数据集的训练期间很早就达到了最大值<code class="fe kp kq kr ks b">NDCG@10</code>。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mv"><img src="../Images/17586c0b664c4da8d80edcbdc9939c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1OPkrIVozXCp4G-EHtmccg@2x.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">图3。NDCG100(称为<code class="fe kp kq kr ks b">n100 in the figure</code>)针对以下架构绘制了解码器的第一维:I)<em class="mq">I</em>→150→50→150→<em class="mq">I</em>，ii)<em class="mq">I</em>→300→100→300→<em class="mq">I</em>，iii)<em class="mq">I</em>→600→200→600→<em class="mq">I<em class="mq"/></em></p></figure><p id="3f5c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一方面，梁等人在他们的论文中提到，更深层次的架构并没有带来任何改善。这与我在实验中发现的结果是一致的。事实上，图3显示了四种不同架构的NDCG100(图中标记为<code class="fe kp kq kr ks b">n100</code>)与解码器第一维度的关系。正如我们在图中看到的，即使集中在具有相同层数的架构中，每层增加神经元也不会有特别大的帮助(Movilens和Amazon数据集分别为50和200)。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mw"><img src="../Images/a54b4f7f55753d7d1c0a4cd3456cdd84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0eGoA9JXlvnaC1paEFhpJg.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">图4。NDGC@100 (n100)和Recall@20 (r20)和Recall@50 (r50)针对我运行的所有实验的损失绘制</p></figure><p id="5060" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我结束这个练习之前，我想强调一下我过去已经讨论过的一个结果(见<a class="ae ko" href="https://github.com/jrzaurin/RecoTour/blob/master/Amazon/neural_graph_cf/Chapter06_results_summary.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>)，如图4所示。</p><p id="c34b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图4示出，一般来说，最佳排序度量不对应于最佳损失值。即使点击的输入矩阵的重建可能更差，排名度量仍然可能改进。这是一个重要且常见的结果，在构建真实世界的推荐系统时，人们必须记住这一点。当构建推荐算法时，我们对实现最佳分类/回归损失不感兴趣，而是对产生最佳推荐感兴趣，这与信息检索效率更相关，因此与排名度量更相关。关于推荐系统的更多信息，我推荐这本<a class="ae ko" href="https://www.amazon.co.uk/Recommender-Systems-Textbook-Charu-Aggarwal/dp/3319296574/ref=sr_1_1?crid=2SK7PGNMA59FW&amp;keywords=recommender+systems&amp;qid=1559762483&amp;s=gateway&amp;sprefix=recommender+syste%2Caps%2C153&amp;sr=8-1" rel="noopener ugc nofollow" target="_blank">神奇的书</a>。那本书的第7章主要关注评估指标。</p><p id="d866" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">就这样，我用<code class="fe kp kq kr ks b">Pytorch</code>和<code class="fe kp kq kr ks b">Mxnet</code>结束了我在<code class="fe kp kq kr ks b">Mult-VAE</code>的实验</p><p id="ed98" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来，我想添加到回购中的最直接的项目是:</p><ol class=""><li id="2fd8" class="mx my it js b jt ju jx jy kb mz kf na kj nb kn nc nd ne nf bi translated"><a class="ae ko" href="https://arxiv.org/pdf/2002.02126.pdf" rel="noopener ugc nofollow" target="_blank">用于协同过滤的顺序变分自动编码器</a>【7】</li><li id="486b" class="mx my it js b jt ng jx nh kb ni kf nj kj nk kn nc nd ne nf bi translated"><a class="ae ko" href="https://arxiv.org/pdf/2002.02126.pdf" rel="noopener ugc nofollow" target="_blank"> LightGCN:简化图卷积网络并为其供电，建议</a> [8]</li></ol><p id="f45b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你设法读完了所有这些，我希望你会觉得有用。</p><h1 id="87d4" class="ku kv it bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">参考资料:</h1><p id="d58e" class="pw-post-body-paragraph jq jr it js b jt ls jv jw jx lt jz ka kb lu kd ke kf lv kh ki kj lw kl km kn im bi translated">[1]达文·梁，拉胡尔·g·克里希南，马修·d·霍夫曼，托尼·杰巴拉，2018。用于协同过滤的可变自动编码器:<a class="ae ko" href="https://arxiv.org/pdf/1802.05814.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv:1802.05814v1 </a></p><p id="a74f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[2]迪德里克·P·金马，马克斯·韦林，2014年。自动编码变分贝叶斯:<a class="ae ko" href="https://arxiv.org/pdf/1312.6114.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv:1312.6114v10 </a></p><p id="8dde" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[3]毛里齐奥·费拉里·达克雷马、保罗·克雷莫内西、迪特马尔·扬纳克。我们真的取得了很大进展吗？近期神经推荐方法令人担忧的分析:<a class="ae ko" href="https://arxiv.org/pdf/1907.06902.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv:1907.06902v3 </a></p><p id="8f93" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[4] J .麦考利，c .塔吉特，j .史，a .范登亨格尔。2015.基于图像的风格和替代品建议。<a class="ae ko" href="https://arxiv.org/pdf/1506.04757.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv:1506.04757v1 </a></p><p id="ee17" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[5] R .何，j .麦考利，2016。用一类协同过滤对流行趋势的视觉演变建模。<a class="ae ko" href="https://arxiv.org/pdf/1602.01585.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv:1602.01585v1 </a></p><p id="4fa3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[6]塞缪尔·r·鲍曼，卢克·维尔尼斯，奥里奥尔·维尼亚尔斯，安德鲁·m·戴，拉斐尔·约泽福维茨，萨米·本吉奥，2016。从连续空间生成句子:<a class="ae ko" href="https://arxiv.org/abs/1511.06349.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv:1511.06349v4 </a></p><p id="eec8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[7]诺维恩·萨克德瓦，朱塞佩·曼科，埃托雷·里塔科，维克拉姆·迪普，2018年。用于协同过滤的顺序变分自动编码器:<a class="ae ko" href="https://arxiv.org/pdf/1811.09975.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv:1811.09975v1 </a></p><p id="da57" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[8]何湘南，邓宽，，，，2020。LightGCN:简化图卷积网络并为其供电的建议<a class="ae ko" href="https://arxiv.org/abs/2002.02126.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv:2002.02126v2 </a></p></div></div>    
</body>
</html>