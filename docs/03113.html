<html>
<head>
<title>GANs for tabular data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">表格数据的 GANs</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-of-gans-for-tabular-data-a30a2199342?source=collection_archive---------2-----------------------#2020-03-25">https://towardsdatascience.com/review-of-gans-for-tabular-data-a30a2199342?source=collection_archive---------2-----------------------#2020-03-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="843b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们非常了解 GANs 在现实图像生成方面的成功。但是，它们可以应用于表格数据生成。我们将回顾和检查一些最近的论文，关于表格式甘在行动中。关于最终结果和源代码，可以去<a class="ae ko" href="https://github.com/Diyago/GAN-for-tabular-data" rel="noopener ugc nofollow" target="_blank"> Github 仓库</a>。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/2d2829f5bacd6cd7a4430ac180097a0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7MOeXbZqEbDVuBrE"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae ko" href="https://unsplash.com/@nateggrant?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">内特·格兰特</a>在<a class="ae ko" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><blockquote class="lf lg lh"><p id="7bb2" class="jq jr li js b jt ju jv jw jx jy jz ka lj kc kd ke lk kg kh ki ll kk kl km kn im bi translated">看看我的机器和深度学习博客<a class="ae ko" href="https://diyago.github.io/" rel="noopener ugc nofollow" target="_blank">https://diyago.github.io/</a></p></blockquote><h1 id="155c" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">甘是什么</h1><p id="5864" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">GAN 由两个深层网络组成:发生器<strong class="js iu">和鉴别器<strong class="js iu"/>【1】<strong class="js iu">。</strong>两人同时训练。通常，模型结构和训练过程是这样表示的:</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mp"><img src="../Images/46daa030caf44f6ce0d99140c4b5c96c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4obnpWvnqezB0FpF1FaHaA.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">GAN 培训管道。什么是生成性敌对网络？【1】</p></figure><p id="c697" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">发生器</strong>的任务是产生样本，样本不会被<strong class="js iu">鉴别器</strong>从真实样本中区分出来。我不会在这里给出太多细节，但如果你想深入研究它们，你可以阅读媒体<a class="ae ko" href="https://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09" rel="noopener">帖子</a>和<a class="ae ko" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">伊恩·j·古德费勒的原文</a>。</p><p id="66de" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最近的架构，如 StyleGAN 2，可以产生出色的照片级逼真图像。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mq"><img src="../Images/e1cc564d4b0e20bc93eb79c7f086fda0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cuYczSMnaY9cvyVh.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">由 StyleGAN 2，S<a class="ae ko" href="https://arxiv.org/pdf/1912.04958.pdf" rel="noopener ugc nofollow" target="_blank">source</a>arXiv:1912 . 04958 v2[7]生成的人脸精选示例</p></figure><h2 id="de70" class="mr ln it bd lo ms mt dn ls mu mv dp lw kb mw mx ma kf my mz me kj na nb mi nc bi translated">问题</h2><p id="641e" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">虽然人脸生成似乎不再是一个问题，但我们仍有许多问题需要解决:</p><ul class=""><li id="2117" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn ni nj nk nl bi translated"><strong class="js iu">训练速度</strong>。对于训练 StyleGAN 2，您需要 1 周和 DGX-1 (8x NVIDIA Tesla V100)。</li><li id="29ee" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated"><strong class="js iu">特定领域的图像质量</strong>。最先进的网络在其他任务上仍然失败。</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nr"><img src="../Images/c9e547a4c2a5e155e65b49b8e3c7b4cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*A3xaFoOBECYNmKSEeTipew.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">StyleGAN 2 生成的汽车和猫的精选示例，<a class="ae ko" href="https://arxiv.org/pdf/1912.04958.pdf" rel="noopener ugc nofollow" target="_blank">来源</a> arXiv:1912.04958v2 [7]</p></figure><h1 id="d5eb" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">表格甘斯</h1><p id="2d25" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">由于不平凡的数据分布和高度的对象类型多样性，对于 GANs 来说，即使是生成猫狗也是一项繁重的任务。除此之外，图像背景也变得很重要，这是 GANs 通常不能产生的。<br/>因此，我一直在想 GANs 在表格数据上能达到什么样的效果。可惜文章不多。接下来的两篇文章似乎是最有希望的。</p><h2 id="ee63" class="mr ln it bd lo ms mt dn ls mu mv dp lw kb mw mx ma kf my mz me kj na nb mi nc bi translated"><a class="ae ko" href="https://arxiv.org/pdf/1811.11264.pdf" rel="noopener ugc nofollow" target="_blank"> TGAN:使用生成对抗网络合成表格数据</a> arXiv:1811.11264v1 [3]</h2><p id="a46f" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">首先，他们提出了几个问题，为什么生成表格数据有自己的挑战:</p><ul class=""><li id="e65a" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn ni nj nk nl bi translated">各种数据类型(整数、小数、类别、时间、文本)</li><li id="cb2f" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated">不同形状的分布(多模态、长尾、非高斯……)</li><li id="44d8" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated">稀疏的一次性编码向量和高度不平衡的分类列。</li></ul><p id="f1fa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">任务形式化</strong></p><p id="bbec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设表<strong class="js iu"> T </strong>包含<strong class="js iu"> n_c </strong>连续变量和<strong class="js iu"> n_d </strong>离散(分类)变量，每一行都是<strong class="js iu"> C </strong>向量。这些变量具有未知的联合分布<strong class="js iu">P。</strong>每一行都是从<strong class="js iu"> P </strong>中独立采样的。目标是训练生成模型<strong class="js iu">M。M</strong>应生成新的合成表<strong class="js iu"> T_synth </strong>，其分布类似于<strong class="js iu"> P. </strong>在<strong class="js iu"> T_synth </strong>上学习的机器学习模型应在真实测试台上<strong class="js iu"> T_test </strong>上达到类似的精度，在<strong class="js iu"> T. </strong>上训练的模型也是如此</p><p id="5d38" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">预处理数值变量。"</strong>使用<em class="li">tanh</em>"<em class="li"/>【3】，神经网络可以有效地生成以(1，1)为中心的分布值。然而，他们表明，网络不能产生多模态数据合适的数据。因此，他们通过使用和训练高斯混合模型(<strong class="js iu"> GMM </strong>)对每个<strong class="js iu"> C </strong>使用<strong class="js iu"> m </strong> (m=5)个分量来聚类一个数值变量。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/e8e1b19ca29a39df8647e23d0b629bf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*F4ab3LKNgz3yf7D5ryn1pw.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">使用平均值和标准偏差的 GMM 归一化。<a class="ae ko" href="https://arxiv.org/pdf/1811.11264.pdf" rel="noopener ugc nofollow" target="_blank">来源</a> arXiv:1811.11264v1 [3]</p></figure><p id="dc0d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，使用 GMM 归一化<strong class="js iu"> C </strong>得到<strong class="js iu"> V. </strong>此外，他们计算<strong class="js iu"> C </strong>来自每个<strong class="js iu"> m </strong>高斯分布的概率作为向量<strong class="js iu"> U. </strong></p><p id="6988" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">预处理分类变量。</strong>由于基数通常较低，他们发现可以使用 softmax 直接生成概率分布。但是必须将分类变量转换为带有噪声的一位热编码表示，将二进制变量转换为二进制变量</p><p id="b3bf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">前置后，它们将带有<strong class="js iu"> n_c + n_d </strong>列的<strong class="js iu"> T </strong>转换为<strong class="js iu"> V，U，D </strong>向量。该矢量是发生器的输出，也是 GAN 中鉴别器的输入。“甘没有获得的参数”[3]。</p><p id="0748" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">发电机</strong></p><p id="aac5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">他们分两步生成一个数字变量。首先，生成值标量<strong class="js iu"> V </strong>，然后生成聚类向量<strong class="js iu"> U </strong>，最后应用<strong class="js iu"> tanh </strong>。使用<strong class="js iu"> softmax 在所有可能标签上生成概率分布的分类特征。</strong>使用注意机制生成所需的行 LSTM。为 LSTM 在每一步中输入的是随机变量<strong class="js iu"> <em class="li"> z、</em>加权上下文向量<em class="li"> </em> </strong>与<strong class="js iu">先前隐藏的</strong>和<strong class="js iu">嵌入向量。</strong></p><p id="568e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">鉴别器</strong></p><p id="3536" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用具有 LeakyReLU 和 BatchNorm 的多层感知机(MLP)。第一层使用<strong class="js iu"> </strong>中的级联向量<strong class="js iu"> (V，U，D) </strong>，具有来自 LSTM 的特征向量的小批量分集。损失函数是具有和序数对数损失函数的输入变量的 KL 散度项。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nt"><img src="../Images/f1bd86f52c109815e6f219af3ce12048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vBVwPGwyQHFa9BC-Yuqh9g.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">使用 TGAN 生成简单人口普查表的示例。生成器逐个生成 T 个特征。鉴别器将所有特征连接在一起。然后使用具有 LeakyReLU 的多层感知器(MLP)来区分真假数据。<a class="ae ko" href="https://arxiv.org/pdf/1811.11264.pdf" rel="noopener ugc nofollow" target="_blank">来源</a> arXiv:1811.11264v1 [3]</p></figure><p id="e5f7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">结果</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nu"><img src="../Images/36bef64ade2d6cf29511c3ae0d6edccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tZhrj7ge33Qi7LXLgWZPjw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">在真实和合成训练集上训练的机器学习模型的准确性。(贝叶斯网络，高斯连接函数)。<a class="ae ko" href="https://arxiv.org/pdf/1811.11264.pdf" rel="noopener ugc nofollow" target="_blank">来源</a> arXiv:1811.11264v1 [3]</p></figure><p id="6468" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">他们在两个数据集<strong class="js iu"> KDD99 </strong>和<strong class="js iu"> covertype 上评估模型。</strong>出于某种原因，他们使用了没有 boosting 的弱模型(xgboost 等)。无论如何，TGAN 表现得相当好和稳健，胜过贝叶斯网络。真实数据和合成数据之间的平均性能差距为 5.7%。</p><h2 id="08c2" class="mr ln it bd lo ms mt dn ls mu mv dp lw kb mw mx ma kf my mz me kj na nb mi nc bi translated"><a class="ae ko" href="https://arxiv.org/pdf/1907.00503.pdf" rel="noopener ugc nofollow" target="_blank">使用条件 GAN 对表格数据建模</a>(CTGAN)arXiv:1907.00503 v2[4]</h2><p id="5bc7" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">与以前的 TGAN 相比，主要的改进是应用模式特定的归一化来克服非高斯和多峰分布。然后使用条件生成器和抽样训练来处理不平衡的离散列。</p><p id="a310" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">任务形式化</strong></p><p id="db9e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最初的数据与在 TGAN 时一样。然而，它们解决不同的问题。</p><ul class=""><li id="a0f2" class="nd ne it js b jt ju jx jy kb nf kf ng kj nh kn ni nj nk nl bi translated"><strong class="js iu">健身的可能性</strong>。<strong class="js iu"> T_syn </strong>中的列是否遵循与<strong class="js iu"> T_train </strong>相同的联合分布</li><li id="b103" class="nd ne it js b jt nm jx nn kb no kf np kj nq kn ni nj nk nl bi translated"><strong class="js iu">机器学习功效。</strong>当训练模型使用其他列作为特征来预测一列时，从<strong class="js iu"> T_syn </strong>学习的这种模型在<strong class="js iu"> T_test </strong>上能否达到与在<strong class="js iu"> T_train </strong>上学习的模型相似的性能</li></ul><p id="da15" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">预处理</strong></p><p id="a2a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">离散</strong>列的预处理保持不变。</p><p id="638e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于<strong class="js iu">连续</strong>变量，使用变分高斯混合模型(<strong class="js iu"> VGM </strong>)。它首先估计模式的数量<strong class="js iu"> m </strong>，然后拟合高斯混合。在我们将初始向量<strong class="js iu"> C </strong>归一化后，它几乎和在 TGAN 时一样，但是它的值在每种模式下都是归一化的。模式表示为一热向量斗鱼([0，0，.., 1, 0]).Alpha 是<strong class="js iu"> C </strong>的归一化值。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nv"><img src="../Images/895b103b628717333d09ac2ac00a5b5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXIVj2054QVdhUlUHHANGA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">特定于模式的规范化示例。来源 arXiv:1907.00503v2 [4]</p></figure><p id="ba87" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，我们将初始行表示为“一键”离散列的串联，并具有上面讨论的连续变量的表示:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nw"><img src="../Images/6ff9c1764f096cf8b3b28864cc7e1925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R_8EXDEGaov-i9NxIglkuw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">预处理行。<a class="ae ko" href="https://arxiv.org/pdf/1907.00503.pdf" rel="noopener ugc nofollow" target="_blank">来源</a> arXiv:1907.00503v2 [4]</p></figure><p id="4c83" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">培训</strong></p><p id="4fbd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">“最终解决方案由三个关键要素组成，即:条件向量、发电机损耗和采样训练法”[4]。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nx"><img src="../Images/5a78d1302c459cb1aafc03753823f2eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wT8fgJ0DiqWJdJd9Ag1UpQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">CTGAN 模型。条件生成器可以根据离散列之一生成合成行。通过采样训练，根据每个类别的对数频率对<strong class="bd ny"> cond </strong>和训练数据进行采样，因此 CTGAN 可以均匀地探索所有可能的离散值。来源 arXiv:1907.00503v2 [4]</p></figure><p id="e580" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">条件向量</strong></p><p id="729c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">表示所有离散列的串联“一键”向量，但仅指定了一个选定的类别。例如，对于两个离散的列，D1 = {1，2，3}和 D2 = {1，2}，条件(D2 = 1)由掩码向量 m1 = [0，0，0]和 m2 = [1，0]表示；所以 cond = [0，0，0，1，0]" [4]。</p><p id="aaa7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">发电机损耗</strong></p><p id="ca3c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">“在训练期间，条件生成器可以自由产生任何一组独热离散向量”[4]。但是他们强制条件生成器产生<strong class="js iu"> d_i ( </strong>生成的离散独热列)<strong class="js iu"> = m_i </strong>(掩码向量)是通过增加它们之间的交叉熵来惩罚它的损失，在批处理的所有实例上平均。</p><p id="ce84" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">抽样训练</strong></p><p id="78fd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">“具体来说，目标是以这样一种方式有效地进行重新采样，即在训练过程中对离散属性的所有类别进行均匀采样，从而在测试过程中获得真实的数据分布”[4]。</p><p id="c2a7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">换句话说，条件生成器产生的输出必须由评价者评估，评价者估计学习的条件分布<strong class="js iu"> P_G(row|cond) </strong>和真实数据上的条件分布<strong class="js iu"> P(row|cond) </strong>之间的距离。“真实训练数据的采样和<strong class="js iu"> cond </strong> vector 的构造应符合帮助评论家估计距离的要求”[4]。对<strong class="js iu"> cond </strong>向量和训练数据进行适当采样可以帮助模型均匀地探索离散列中所有可能的值。</p><p id="d888" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">模型结构如下，与 TGAN 相反，没有 LSTM 层。用梯度惩罚的 WGAN 损失训练。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/34ad6fd6c1fa45f9565c4d67b354ebf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*hdTtN0tv_xU8XDtQW5Ckow.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">发电机。<a class="ae ko" href="https://arxiv.org/pdf/1907.00503.pdf" rel="noopener ugc nofollow" target="_blank">来源</a> arXiv:1907.00503v2 [4]</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oa"><img src="../Images/558faac939682b83caa72c74236011f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*FIHudP5ZNp6aQEaSs6R_Fw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">鉴别器。<a class="ae ko" href="https://arxiv.org/pdf/1907.00503.pdf" rel="noopener ugc nofollow" target="_blank">来源</a> arXiv:1907.00503v2 [4]</p></figure><p id="0e9a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，他们提出了一个基于变分自动编码器(VAE)的模型，但这超出了本文的范围。</p><p id="8099" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">结果</strong></p><p id="aa9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">提出的网络 CTGAN 和 TVAE 优于其他方法。正如他们所说，TVAE 在一些情况下优于 CTGAN，但 GAN 确实有几个有利的属性。与 TVAE 不同，GANs 中的生成器在整个训练过程中无法访问真实数据。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/80c7811e4cba686d53803be6aa47be78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*4I4PImQJaDMCw8TIHbIoWQ.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">基准结果超过三组实验，即高斯混合模拟数据(GM Sim。)，贝叶斯网络模拟数据(BN Sim。)，以及真实数据。他们报告每个指标的平均值。对于真实数据集(f1 等)。来源 arXiv:1907.00503v2 [4]</p></figure><p id="0832" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，他们在<a class="ae ko" href="https://github.com/sdv-dev/CTGAN" rel="noopener ugc nofollow" target="_blank"> <em class="li"> GitHub </em> </a>上公布了源代码，稍加修改后将在本文中进一步使用。</p><h1 id="13d4" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">应用 CTGAN 生成用于增加列车(半监督)的数据</h1><p id="b554" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">这对我来说是一种香草梦。在简单了解了 GAN 的最新发展后，我一直在思考如何将它应用到我日常工作中解决的一些问题上。这是我的想法。</p><p id="9e06" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">任务形式化</strong></p><p id="a3e2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设我们有<strong class="js iu"> T_train </strong>和<strong class="js iu"> T_test </strong>(分别为 train 和 test set)。我们需要在<strong class="js iu"> T_train </strong>上训练模型，在<strong class="js iu">T _ test</strong>上进行预测。但是，我们将通过由 GAN 生成新数据来增加训练，在某种程度上类似于<strong class="js iu"> T_test </strong>，而不使用它的地面真实标签。</p><p id="e999" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">实验设计</strong></p><p id="57d5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设我们有<strong class="js iu"> T_train </strong>和<strong class="js iu"> T_test </strong>(分别为 train 和 test set)。<strong class="js iu"> T_train </strong>的尺寸较小，可能有不同的数据分布。首先我们在<strong class="js iu"> T_train </strong>上用地面真值标签<em class="li"> step 1 </em>训练 CTGAN，然后生成附加数据<strong class="js iu">T _ synth</strong>(<em class="li">step 2</em>)<strong class="js iu">。</strong>其次，我们在串联的<strong class="js iu"> T_train </strong>和<strong class="js iu"> T_synth </strong>(目标设置为 0)与<strong class="js iu"> T_test </strong>(目标设置为 1) ( <em class="li">步骤 3 &amp; 4 </em> ) <strong class="js iu">上以对抗的方式训练 boosting。</strong>目标是应用新训练的对抗性增强来获得更像<strong class="js iu"> T_test 的行。</strong>注意——原始地面真相标签不用于对抗训练。因此，我们从<strong class="js iu"> T_train </strong>和<strong class="js iu"> T_synth </strong>中取出按照与<strong class="js iu"> T_test </strong>的对应关系排序的顶行(步骤<em class="li"> 5 &amp; 6 </em>)。<strong class="js iu"> </strong>最后<strong class="js iu">，</strong>对它们进行新的增压，并在<strong class="js iu"> T_test 上检查结果。</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oc"><img src="../Images/54de0c27bd00153249fa25b2a7be1598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8eANdhCYrYv8ODZpTvv2ZQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">实验设计和工作流程</p></figure><p id="c1b6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当然，出于基准测试的目的，我们将测试没有这些技巧和另一个原始管道但没有 CTGAN 的有序训练(在步骤 3 中，我们不会使用<strong class="js iu"> T_sync </strong>)。</p><p id="2e1f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">代码</strong></p><p id="7ff3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">实验代码和结果发布为 Github repo <a class="ae ko" href="https://github.com/Diyago/GAN-for-tabular-data" rel="noopener ugc nofollow" target="_blank">此处</a>。管道和数据准备基于<a class="ae ko" rel="noopener" target="_blank" href="/benchmarking-categorical-encoders-9c322bd77ee8">基准分类编码器的</a>文章及其<a class="ae ko" href="https://github.com/DenisVorotyntsev/CategoricalEncodingBenchmark" rel="noopener ugc nofollow" target="_blank">报告</a>。我们将遵循几乎相同的流水线，但是为了速度，只选择了单一验证和 Catboost 编码器。由于 GPU 内存不足，一些数据集被跳过。</p><p id="6222" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">数据集</strong></p><p id="ca0a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所有数据集来自不同的领域。他们有不同数量的观察，几个分类和数字特征。所有数据集的目标都是二元分类。数据集的预处理很简单:从数据集中删除所有基于时间的列。其余的列要么是分类的，要么是数字的。另外，在对训练结果进行采样的同时<strong class="js iu"> T_train — 5%、10%、25%、50%、75% </strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi od"><img src="../Images/7d467ec9be7ad514796da4ce1ab6593e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TDHw8mM_hF71WrjqYJp1rQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">数据集属性</p></figure><h2 id="9277" class="mr ln it bd lo ms mt dn ls mu mv dp lw kb mw mx ma kf my mz me kj na nb mi nc bi translated">结果</h2><p id="c52f" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">从第一眼的角度来看，就度量和稳定性(std)而言，GAN 显示出最差的结果。然而，对初始训练进行采样，然后应用对抗训练，我们可以获得最佳的度量结果和稳定性(<strong class="js iu"> sample_original </strong>)。为了确定最佳采样策略，对每个数据集的 ROC AUC 评分进行了缩放(最小-最大缩放),然后在数据集之间进行平均。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/03294c0635bfa30fcab99fd742e94638.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*l6U7aPM8Bi715GlfpWgtaA.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">不同的采样结果，平均值越高越好(ROC AUC)，标准差越低越好(100% —每个数据集的最大 ROC AUC)</p></figure><p id="2907" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以看到 GAN 在两个数据集上的表现优于其他采样类型。而在 7 个数据集的 3 个中，来自原始数据的采样优于其他方法。当然也没有太大区别。但是这些类型的取样可能是一种选择。当然也没有太大区别。但是这些类型的取样可能是一种选择。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi of"><img src="../Images/f3890c18321006081441f8211575d4a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*nAq-b5SsBKleIR_wVQQcUQ.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">不同数据集的采样结果，越高越好(100% —每个数据集的最大 ROC AUC)</p></figure><p id="9bfe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们定义 same_target_prop 等于 1，那么训练和测试的目标比率相差不超过 5%。因此，我们在培训和测试中有几乎相同的目标比率<em class="li">无</em>和<em class="li">样本 _ 原始</em>更好。然而，gan 的表现开始明显好于目标分布变化。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi og"><img src="../Images/2a7c291c46c5113d772bb332920a8861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*7U-oXuJBXSSZ1hHeErw4zA.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">same_target_prop 等于 1，则训练和测试的目标比率仅相差 5%</p></figure><h1 id="9b00" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">参考</h1><p id="900e" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">[1]乔纳森·惠。甘— <a class="ae ko" href="https://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09" rel="noopener">什么是生成性敌对网络甘？</a> (2018)，中条</p><p id="449d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[2]伊恩·古德菲勒、让·普热-阿巴迪、迈赫迪·米尔扎、徐炳、戴维·沃德-法利、谢尔吉尔·奥泽尔、亚伦·库维尔、约舒阿·本吉奥。生成性对抗网络(2014)。arXiv:1406.2661</p><p id="ad4e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[3]徐磊 LIDS，Kalyan Veeramachaneni。使用生成式对抗网络合成表格数据(2018)。arXiv:1811.11264v1 [cs。LG]</p><p id="0547" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[4]徐磊、玛丽亚·斯科拉利杜、阿尔弗雷多·单面山-因方特、卡莉安·维拉马查涅尼。使用条件 GAN 对表格数据建模(2019)。arXiv:1907.00503v2 [cs。LG]</p><p id="96f6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[5]丹尼斯·沃罗廷采夫。<a class="ae ko" rel="noopener" target="_blank" href="/benchmarking-categorical-encoders-9c322bd77ee8">基准分类编码器</a> (2019)。中等职位</p><p id="3b76" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[6]英萨夫·阿什拉波夫。<a class="ae ko" href="https://github.com/Diyago/GAN-for-tabular-data" rel="noopener ugc nofollow" target="_blank">甘换表</a> (2020)。Github 仓库。</p><p id="c94c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[7] Tero Karras、Samuli Laine、Miika Aittala、Janne Hellsten、Jaakko Lehtinen、Timo Aila。StyleGAN(2019)arXiv:1912.04958 v2[cs。简历]</p><p id="34c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[8] Insaf Ashrapov，机器与深度学习博客，【https://diyago.github.io/ T4】</p></div></div>    
</body>
</html>