# 差分隐私在欧洲隐私法(GDPR)和机器学习中的应用

> 原文：<https://towardsdatascience.com/applications-of-differential-privacy-to-european-privacy-law-gdpr-and-machine-learning-141938975a68?source=collection_archive---------37----------------------->

## 差异隐私如何保护您的数据，并帮助您遵守政府法规

![](img/7d5e868eae2bf9758324d988140f1633.png)

照片由 [**克里斯蒂娜·莫里洛**](https://www.pexels.com/@divinetechygirl?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels) 发自 [**像素**](https://www.pexels.com/photo/adult-african-american-woman-business-city-1181341/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)

# 什么是差分隐私？

差分隐私是一种数据匿名技术，被苹果和谷歌等主要技术公司使用。差异隐私的目标很简单:允许数据分析师建立准确的模型，而不牺牲个人数据点的隐私。

但是“牺牲数据点的隐私”是什么意思呢？嗯，假设我有一个包含信息(年龄、性别、治疗、婚姻状况、其他医疗状况等)的数据集。)关于在医院 x 接受乳腺癌治疗的每一个人。在这种情况下，数据点是电子表格(或数据框架，或数据库等)的一行。)包含关于接受乳腺癌治疗的人的信息。

我想建立一个机器学习模型，预测 x 医院乳腺癌的存活几率。如果我想保留患者的隐私，我应该怎么做？

这就是差别隐私的由来。差分隐私通过在数据检索过程中引入随机性，帮助分析师建立准确的模型，而不会牺牲单个数据点的隐私。

在差分隐私的框架中，有两个行动者:一个 ***策展人*** 和一个 ***数据分析师*** 。馆长拥有所有的数据，以及所有的原始(真实)值，而数据分析师想要解释这些数据。数据分析师可以“查询”数据库；也就是说，数据分析师可以向馆长索要数据的子集。差分隐私不会直接泄露任何信息；相反，对于数据分析师感兴趣的每个变量，如年龄、诊断、治疗等。，他们可能得到真实值，也可能得不到。分析师实际收到真实值的可能性因引入的噪声量而异。

查询数据库的次数越多，数据的私密性就越低。差分隐私比我刚才介绍的要复杂得多，但是您可以获得基本的方法。

**关于差分隐私的更多资源**

*   如果你想了解更多关于差分隐私的信息，我鼓励你阅读这篇文章。它解释了五岁，中级和专业水平的理解。
*   要获得深入的技术解释，请阅读[这篇文章](/understanding-differential-privacy-85ce191e198a)。

但是现在，让我们继续快速解释欧洲隐私立法。

# 欧洲数据隐私立法背景，即 GDPR

通用数据隐私条例，简称为 GDPR，是一项数据隐私立法，适用于所有总部设在欧盟或在欧盟运营的公司。GDPR 概述了公司如何被允许使用、存储和处理关于人的数据。这项立法的目的是让人们更多地控制公司对他们的了解，并在整个欧洲标准化这些做法。

# 关键术语

为了连贯地谈论 GDPR，我们需要快速定义三个术语:*****数据主体*******处理器*** 。虽然我们都知道这些术语的通俗定义，但 GDPR 对它们下了精确的定义，所以我们想熟悉它们的定义。***

*   ****个人数据**是任何可能与个人直接或间接相关的数据。它可能是你手机的一个标识符，你的文字指纹，或者一个汽油付款记录。这个定义很重要，因为它涵盖了大部分收集的数据。不管是好是坏，人类有点自恋。**
*   ****数据主体**是一个人，特别是居住在欧盟的人。收集关于数据主体的个人数据。**
*   **最后，**处理器**是任何人(个人、公司、算法)对个人数据做任何事情。他们可以储存、分析、改变它，用它来快速自拍，以及几乎所有其他事情——他们是一个处理器。**

**就像他们说的，伟大的进程伴随着伟大的责任。**

****公司(加工者)的责任****

**GDPR 说得很清楚，*处理器*完全负责确保和维护它处理的个人数据的隐私。不仅如此，处理器实际上还需要关心这些数据的隐私。该法规要求公司在设计产品和流程时考虑隐私，对处理器可以保存数据的时间进行限制，并赋予数据主体许多关于如何使用、存储和披露数据的权利。**

****个人和公司的隐私目标****

> **一般来说，我们可以假设数据主体希望他们的个人数据最大程度地保密，而处理者希望数据最大程度地公开。**

**一般来说，我们可以假设数据主体希望他们的个人数据最大程度地保密，而处理者希望数据最大程度地公开。**

**处理器希望数据尽可能公开，因为对数据的限制越少，处理器就越容易使用。然而，需要注意的是，数据主体和处理者的利益并不完全对立——毕竟，数据主体希望他们使用的产品和服务尽可能好地工作，许多人愿意为此放弃一些隐私。**

**此外，大多数公司本质上并不邪恶，他们关心(至少有一点)维护他们提供服务的人的隐私，不管法律如何。**

# ****差分隐私与 GDPR 有什么关系？****

**你可能已经注意到 GDPR 和差分隐私都有一个共同的词:隐私。隐私是那些你可以有一百万个矛盾定义的词之一，但是现在:**

****隐私**——个人有选择地向外界披露自己信息的权利。**

****结合我们刚刚介绍的所有术语:****

**差分隐私是处理数据的算法的属性，由一个或多个*处理器*使用，以保护*数据主体*的个人数据。换句话说:**

## **差分隐私可以被认为是一种算法用来维护个人的 GDPR 强制隐私的技术。**

**重要的是要明白差分隐私世界的*策展人*和*数据分析师*根据定义都是 GDPR 世界的 *处理者*，他们可以是同一个实体，也可以是不同的实体。例如，如果我的 Android 手机收集了关于我的位置数据，然后一名谷歌工程师对其进行分析，则馆长和数据分析师都是谷歌。但如果谷歌决定让 Tinder 这样的第三方公司访问我的数据，那么谷歌就是馆长，Tinder 就是数据分析师。Google 和 Tinder 都是处理器。**

# **就 GDPR 而言，使用差异隐私的优势和劣势**

**在这一节中，我将讨论对不同的利益相关者，特别是公司和用户使用差别隐私的利弊。**

**公司的利益(加工者)**

*   **差分隐私可以通过将个人数据转换为聚合数据，给处理器更多的自由。管理聚合数据的法律远没有管理个人数据的法律严格。**
*   **差异隐私为公司提供了一种直接量化数据隐私的方法，提高了公司证明其遵守 GDPR 的能力。**

****对用户的好处**(数据主体)**

*   **差分隐私确保在给定足够的噪音和足够少的查询次数的情况下，很难重新创建单个数据主体的个人数据。**
*   **如果馆长和数据分析师是不同的处理者，那么馆长可以设置最大查询次数，以增加其拥有的个人数据的隐私。**

****对公司和用户都有利****

*   **差分隐私可以让公司通过提高已有数据的可推广性来制作更好的模型。这是可行的，因为差分隐私迫使模型依赖于数据集中值的分布，而不是真实值。这意味着他们可以两全其美—数据主体的个人数据受到的损害较小，数据分析师/处理者最终得到的模型比使用原始数据得到的模型更好。**
*   **公司可以在不侵犯隐私的情况下访问大量敏感数据进行研究。**
*   **差分隐私提供了一种数学上可证明的隐私保护保证，可以抵御各种各样的隐私攻击。这意味着数据不容易受到隐私攻击，这对处理者和数据主体都有利。**

**然而，使用与安全性和分析质量相关的差分隐私也有明显的缺点。**

# **使用差分隐私的缺点**

****差分隐私的安全挑战****

*   **差分隐私易受许多滥用问题的影响，包括:a)公司以不安全的方式存储原始数据，尽管在分析数据时使用了差分隐私，这向不同类别的隐私攻击敞开了大门，
    b)数据分析师过于频繁地查询数据以获得差分隐私，从而不能有效地保护数据主体的隐私，
    c)数据分析师使用太少的噪声来充分保护数据主体的隐私，**
*   **差分隐私也容易受到非预期推断问题的影响，即只需要非常少量的准确信息就可以精确识别个人的问题。由于统计上许多个人数据是准确的，这就带来了严重的安全问题。**
*   **此外，差分隐私的成功使用可能会无意中阻止公司收集更少的人的数据，因为有一个安全的过程可用于分析数据。收集的数据越少，数据主体的个人数据就越安全。GDPR 努力鼓励公司收集更少的个人总体数据，在分析中使用差分隐私产生的(计算机)安全错觉可能会违背这一目标。**

****使用差分隐私时的额外挑战****

*   ****差分隐私可能导致危险的不准确模型**:模型可能很容易产生，非常隐私，但危险的不准确，因为在差分隐私的隐私和准确性之间有一个直接的权衡。**
*   ****对于数据分析师来说，处理以差分隐私**为中介的数据 **可能会很有挑战性。正如 Dwork 和 Roth 指出的，许多数据分析师经常“用基本上非算法的术语来描述他们与数据的交互，例如，‘首先，我看数据’”。然而，作者补充说，“一般来说，在高维和互联网规模的数据集上，非算法交互将是例外，这似乎是合理的。”****

## **结论**

**总的来说，我认为在公司内部，特别是与他人共享数据的公司，使用差异隐私是一个既增加隐私又符合 GDPR 的优秀工具，只要使用得当。**

***如果您对我讨论的任何内容有任何问题、意见或想要更多资源，请联系我们。***

## **参考**

**[1] [GDPR，第四篇](https://gdpr-info.eu/art-4-gdpr/) (2016)，GDPR 信息网**

**[2] A. Nguyen，[理解差分隐私](http://Understanding Differential Privacy) (2019)，走向数据科学**

**[3] C. Dwork 和 A. Roth，[差分隐私的算法基础](https://www.google.com/search?client=firefox-b-1-d&q=differential+privacy+book) (2014)，第 254 页**

## **了解更多有关差分隐私的资源**

*   **[关于不同隐私的权威书籍](https://www.google.com/search?client=firefox-b-1-d&q=differential+privacy+book)，写得出奇的好(也参考文献 3)**
*   **如果你想了解更多关于差分隐私的信息，我鼓励你阅读这篇文章。它解释了五岁，中级和专业水平的理解。**
*   **要获得深入的技术解释，请阅读这篇博客。**
*   **[大数据时代的差异化隐私](/data-privacy-in-the-age-of-big-data-c28405e15508)(博客)**
*   **[差分隐私的更简单解释](https://win-vector.com/2015/10/02/a-simpler-explanation-of-differential-privacy/)(博客)**