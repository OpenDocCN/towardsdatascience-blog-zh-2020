<html>
<head>
<title>Almost Everything You Need To Know About Decision Trees (With Code)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">几乎你需要知道的关于决策树的一切(带代码)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/almost-everything-you-need-to-know-about-decision-trees-with-code-dc026172a284?source=collection_archive---------5-----------------------#2020-04-23">https://towardsdatascience.com/almost-everything-you-need-to-know-about-decision-trees-with-code-dc026172a284?source=collection_archive---------5-----------------------#2020-04-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4c94" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">以你想不到的方式理解决策树的指南！</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f8e5d12e9d8299dc4b93c2b86b99752f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kw8mG6Lvk0t4wvvzz5cxhQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">托德·夸肯布什在<a class="ae kv" href="https://unsplash.com/s/photos/trees?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="47bd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="0dbb" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">你一生中没有一天不做任何决定。从你早餐吃什么到你感兴趣的职业，你的生活被决定所包围。假设你想出去玩板球。出门前你会寻找哪些因素？今天会下雨吗？外面会不会太热？作为一名资深玩家，你被要求接最后的电话。你从气象部门网站上查了过去几天的数据。将这些数据与今天的天气状况进行了比较，并预测天气状况非常适合进行板球比赛。瞧啊。你只是在不知道的情况下用决策树解决了问题。</p><p id="81b9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在使用决策树的实际功能之前，您需要精通以下术语</p><ul class=""><li id="200e" class="mp mq iq lq b lr mk lu ml lx mr mb ms mf mt mj mu mv mw mx bi translated">基尼杂质</li><li id="0faa" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">熵</li></ul></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="65bf" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">基尼杂质与熵</h1><p id="000e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">两个朋友乔和萨姆开始觉得无聊了。所以他们决定玩一个游戏。找到最能把下面的点分成蓝色和橙色的线的人赢得游戏。唯一的限制是这条线必须平行于任何轴。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/487e2b2fe37a02588bf944dfe8cc48a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*Ighq499DRYSF2ZmjLlJlZA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1</p></figure><p id="831d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">两人都尝试了很多，想出了下面的台词。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/19f23901a6cf782e79c2df62d88fac61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jF7jspNB3prKeS5pzVXDDA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2</p></figure><p id="2a72" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">仅仅通过视觉化的要点，很容易说乔的尝试比山姆好。然而，当我们有两种以上的颜色时，事情会变得疯狂。人们需要一个量化值来判断分裂。这就是基尼系数不纯的原因。它谈到了错误分类点的<strong class="lq ir">概率。</strong></p><p id="36c4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><em class="nr">没拿到？</em></p><p id="d911" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">让我们看看拆分前的条件，即图1。错误分类一个点的概率有多大？</p><p id="4651" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们可能有两种方法来错误地对一个点进行分类。首先，我们选择一个蓝点，将其归类为橙色。第二，我们选择一个橙色的点，将其归类为蓝色。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/3040f2cb189070f3a9f105a48ac20af9.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*udjpVCFLi4IluTzhtDHXvQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3</p></figure><p id="86e1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">和</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/4e3db39065c2d2cb1d6cec6170e3d47e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*NIEVNDGsscnLCBnl7LORoQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4</p></figure><p id="1776" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">总概率= 0.25+0.25 =0.5(开始时的基尼杂质)</p><p id="46a8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">任何数据分割都会将该区域分成两个或多个部分。通过对所有部分进行加权求和，计算出最终的基尼系数。基尼系数越小，分割越好。</p><p id="fb66" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们来分析一下乔的企图-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/0f26a071d014cb61def5b2102c09d86d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CVTvsS74PvNDzjPJcCivg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图5</p></figure><p id="d4a1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">同样，我们也可以分析山姆的企图-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/205f1ffacae8b0a83c680e1e2696b480.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_l3veBOkt9SubIR04VwLGQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图6</p></figure><p id="8bd6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这两种尝试都显著降低了原始基尼系数的不纯度，但是，Joe进行了更好的分割，因为他的分割得到了更大的基尼系数增益。</p><p id="b5b2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">设y是一个随机变量，取值为{y₁,y₂,y₃,….,yₖ}那么计算基尼系数的一个简单方法是</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/263df288b69fc906ca36d7124e82217d.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*NOoXZc8YuGtZXSiPslp7hA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图7</p></figure><h2 id="51b6" class="nx kx iq bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">基尼杂质的性质</h2><p id="2724" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">设y取值y₊，y₋(两个班)</p><p id="2707" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">案例一:</p><p id="b630" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当100%的数据点属于y₊。在这种情况下，该系统的基尼系数为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/2d8add3b2238cb897a34bc50fbb6ee75.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*SETG_dxGMQiwpxdNCAe7QQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图8</p></figure><p id="4820" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">案例二:</p><p id="02d1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当50%的数据点属于y₊时。在这种情况下，该系统的基尼系数为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/fe1b03a4af99735c35e35f7692acc799.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*ZsLGIyy6piwGaS5lje3w4Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图9</p></figure><p id="bada" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">案例三:</p><p id="7548" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当0%的数据点属于y₊时。在这种情况下，该系统的基尼系数为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/bb5c65bb9cf03950174f8bf066cc155b.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*mLswO4PiSPI6REf7kh_34Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图10</p></figure><p id="0b2a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">基尼系数与y₊的关系曲线如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/5fb3845b2b605c50592d17ac1813aa07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*DN72HqCUqP5IP5ImbXaK1w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图11</p></figure><p id="80b2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">受够了这种基尼不纯。先说一会熵。</p><p id="b13b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">熵</strong>，简单来说就是数据中的随机性。想象你面前有两个盒子。盒子1大部分是蓝色的球，而盒子2是不同颜色的球。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/6f52a82ccb6d1dc33b9d79e252fda8ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*E072EZ0ZDbCa-ohxR5tW8g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图12</p></figure><p id="3ae8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在从每个盒子里抽出一个球。你认为从盒子1中抽出的球最有可能是什么颜色？蓝色，对吗？你能预测从盒子2中抽出的球的情况吗？我想不会。原因是盒子2与盒子1不同，具有很大的随机性。恭喜你，你已经知道熵意味着什么了！如果你选择熵作为度量，决策树会以这样一种方式分割数据，即在每次分割时，数据的随机性不断降低。</p><p id="4ab6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">设y是一个随机变量，取值为{y₁,y₂,y₃,….,yₖ}接着计算出系统的熵为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/50a272379232c5d8411e32ec404a283f.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*r3QbXsBaouMGxNSxdLIGiQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图13</p></figure><h2 id="1ee1" class="nx kx iq bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">熵的性质</h2><p id="7a39" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">设y取值y₊，y₋(两个班)</p><p id="9eb9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">案例一:</p><p id="c346" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">99%的数据点属于y₊。在这种情况下，系统的熵将是:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/082247aa428fb01c10346e19596b8b48.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*Y_gpDPgPojqRDcvAHu7gmw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图14</p></figure><p id="9143" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">案例二:</p><p id="7df8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当50%的数据点属于y₊时。在这种情况下，系统的熵将是:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/70b77d4658066692582a25aed5cb954c.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*p9E-Ay2QhoOJXzzHQhGW_w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图15</p></figure><p id="426b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">案例三:</p><p id="6e95" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当1%的数据点属于y₊时。在这种情况下，系统的熵将是:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/f08531efeb905a2d1b4b4b183ab7b9c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*V_F3K_EVThj55Zpjzi439w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图16</p></figure><p id="9ca7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从H(y) w.r.t .到y₊的曲线将会是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/b644404be207ddbb3242a0d1aaf95f9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*wJg2VCsq9et5hCiYOCc0tg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图17</p></figure><p id="7d7c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">必须注意的是，当所有值出现的概率相等时，熵最大= 1。</p><p id="6447" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">到目前为止一切顺利。<em class="nr">但是如何用熵来分割数据呢？</em></p><p id="88d3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">类似于基尼增益，我们使用信息增益(I.G ),来决定分割的最佳特征。</p><p id="8789" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">它被定义为:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/ac206f5de0be622473a22267a4fad47f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*45Z8kyrlnVobwG4bu1ztww.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图18</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/d5356046bf0d9449eb80e8d2e4d3d157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*aYf2pDxh9iQdI8z0Miv30g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图19:显示基尼系数和熵随y+变化的图表</p></figure></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="701b" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">为什么基尼不纯超过熵？</h1><p id="912b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">熵涉及对数计算，而基尼系数涉及计算开销较小的平方计算，这就是S <em class="nr"> klearn库</em>使用基尼系数作为默认选择标准来构建决策树的原因。</p><p id="19fa" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">但是，观察到它们之间的差异很小，可以使用这两个指标中的任何一个。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="32f6" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">构建决策树的步骤</h1><ol class=""><li id="a4ec" class="mp mq iq lq b lr ls lu lv lx ov mb ow mf ox mj oy mv mw mx bi translated"><strong class="lq ir">决定分解/分割数据的特征</strong>:计算每个特征的信息增益，选择最大的一个。</li><li id="24e6" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated"><strong class="lq ir">继续拆分数据</strong></li><li id="57c2" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated"><strong class="lq ir">停止拆分数据，如果:- </strong></li></ol><p id="d812" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">a)我们得到纯节点，即仅包含正或负数据点的节点，或者</p><p id="366a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">b)我们在一个节点上得到很少的点，或者</p><p id="d535" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">c)我们到达树的一定深度</p><p id="8e76" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">一旦您构建了一个决策树，对于一个查询点，从根到适当的叶节点遍历树。如果叶节点是纯的，预测查询点对应的类标签，否则执行多数投票。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="eac9" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">分裂分类特征</h1><p id="d8ad" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">假设我们的数据集是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/232a748bd2394f0cdb63eb4187212c3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*iF5Tq60X85qA9UPCCzCm4g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图20</p></figure><p id="42b8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">有两个特点。如果有一个特征，我们会简单地选择它。然而，当我们有一个以上的特征时，我们需要查看在分割后提供最大信息增益的特征。</p><p id="62c9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从特写F₁:开始</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/016d7aa801f2281eb444d0cd728e5a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AXp1uaHguQr88m_EWtY5RQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图21</p></figure><p id="e1c8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">信息增益将是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/6a6c80d9a38654d48dca341b7b06aac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pre_zO4GcHqkjqOseb1dWg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图22</p></figure><p id="0cb5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在检查功能F₂:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/e844e008358e2dc22871f27857d0413c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QFSS9i_723xD2ntYIXtTJg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图23</p></figure><p id="9d76" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">而信息增益(IG)₂会是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/efd1ec3bbb3eb2106a65800972d90b7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*Clv90idsapj2-9rPp652_A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图24</p></figure><p id="52a7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">由于IG₂ &gt; IG₁，我们将首先使用F₂.要素分割数据请注意，F₂=IND之后的节点可以使用特征F₁.进一步分解最终的树看起来会像-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/d57ebd3e17bea4ed0e7df2f22419d693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g6XtFG58fAb4DgO9YXm-7Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图25</p></figure></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="0ff4" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">直觉</h1><p id="3be8" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">让我们使用简单的if-else条件重写上面的决策树:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/a2fbe74d681d5ca1595f3c99658d1982.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*0GPRJfnJB8hL_I7ZJekMow.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图26</p></figure><p id="37e1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我的朋友，这就是你的决策树。</p><p id="d5e4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从程序上讲，决策树只不过是一系列if-else条件语句。</p><p id="806e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从几何学上讲，它是一组轴平行的超平面。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="c274" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">分割数字特征</h1><p id="912f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">假设我们的数据集是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/9e67eb1fd066fe32cd70dd2989fa20ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*B40UAoQrQbEzG0mzdE5UEQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图27</p></figure><ol class=""><li id="e121" class="mp mq iq lq b lr mk lu ml lx mr mb ms mf mt mj oy mv mw mx bi translated">按F₁值排序</li><li id="c3b4" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">如果我们用F₁分割每个值</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ph"><img src="../Images/1af44db61ae3b2b85dc12e631f99b13c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PYz7uDem5l3oUqYD6d-GNA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图28</p></figure><p id="4012" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">您可以看到，我们在每个节点中只获得一个值，这导致了数据的过度拟合。</p><p id="6dff" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们处理这个问题的方法是定义一个阈值，然后将数据分成两部分——一部分的值小于或等于阈值，另一部分的值大于阈值。</p><p id="98fe" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">门槛如何确定？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pi"><img src="../Images/6ee91eb906e02537cd8eacdf4dd234e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NtNy9H_nVRsJDNDNjC4faA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图29</p></figure><p id="62e8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们检查每个可能阈值的信息增益，并选择使其最大化的值。这里，如果我们使用F₁=4.2分割数据，信息增益将最大。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="6559" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">有许多类别的范畴特征</h1><p id="7cae" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们已经看到了如何处理分类和数字特征。然而，当一个分类特征有许多类别时，事情会变得疯狂。</p><p id="ca6d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">假设我们有一个pin码功能。它可能有1000个pin码，当我们使用此功能拆分数据时，它将创建1000个子节点，每个节点只有很少的数据点，这将导致过度拟合。</p><p id="4fc1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">一种方法是将分类特征转换成数字特征。</p><p id="7262" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">代替pin码，我们可以有一个新功能，例如:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/7b017b287d5965d3a97c6cdcb4ba30b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*r7IV24EeZFtRz-pkAdtW1Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图30</p></figure><p id="d5ff" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">所以，现在如果我们使用这个新特性来分割数据，子节点将有足够的点来避免过度拟合。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="7eb2" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">过度拟合和欠拟合</h1><p id="9a1a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">当决策树的深度越大，底部节点出现非常少的数据点的可能性就越大，如果这些点是离群值，我们就会过度拟合我们的模型。因为每一个分割都只是一个if-else条件语句，所以模型的可解释性也会随着树的深度的增加而降低。</p><p id="11c5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当树太浅时，我们可能得不到任何纯节点。纯节点是只有正点或负点的节点。在这种情况下，我们必须进行多数投票才能得出结果。</p><p id="8d76" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><em class="nr">那么决策树的高度应该是多少？</em></p><p id="881a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">身高是一个超参数，我们必须使用交叉验证数据集进行超参数调整，以获得最佳值。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="2c56" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">训练和测试时间复杂性</h1><p id="4009" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">列车时间复杂性:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/c406c15bf4daf0c46ce668817029b77c.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*E6xlQU4mCPiNWIbtTHLqPA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图31</p></figure><p id="525f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在训练阶段发生的事情是，对于数据集中的每个特征(维度)，我们将对花费O(n log n)时间的数据进行排序，然后我们遍历数据点以找到花费O(n)时间的正确阈值。对于d维，总时间复杂度为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/33e5ceaf8a838b53f07dd1880ce72041.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*-V0x88nCoD-R4psKaGJt2w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图32</p></figure><p id="e600" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">列车空间复杂性:</p><p id="b1dd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在训练决策树时，我们需要的是通常作为if-else条件存储的节点。</p><p id="0218" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">因此，列车空间复杂度将为:<strong class="lq ir"><em class="nr">【O节点】</em> </strong></p><p id="df24" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">测试时间复杂度将是<strong class="lq ir"> <em class="nr"> O(深度)</em> </strong>，因为我们必须从决策树的根节点移动到叶节点。</p><p id="aace" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">测试空间复杂度将为<strong class="lq ir"><em class="nr">【O(节点)</em> </strong></p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="841e" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">使用决策树的回归</h1><p id="aaba" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">当我们处理回归问题时，情况就变了。这里的输出不再是一个类，而是一个实数值。</p><p id="1902" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><em class="nr">我们如何拆分数据？</em></p><p id="2153" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">与分类中的熵或基尼系数不同，我们将使用均方误差(MSE)或中位数绝对偏差(MAD)来分割数据。选择降低MSE或MAD最大的特征进行分割。</p><p id="9d11" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><em class="nr">我们如何预测一个测试数据点的值？</em></p><p id="bffe" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">一旦我们到达一个叶节点，我们取那里已经存在的点的平均值/中值，并预测它是给定测试数据点的输出值。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="0c11" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">真实案例</h1><ol class=""><li id="bf8d" class="mp mq iq lq b lr ls lu lv lx ov mb ow mf ox mj oy mv mw mx bi translated"><strong class="lq ir">不平衡数据集</strong>:建议通过上采样或类别权重来平衡数据集，因为这可能会影响熵值。</li><li id="5b2f" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated"><strong class="lq ir">高维数据</strong>:随着维数的增加，训练的计算时间也增加。建议如果一个特征有许多类别，应该避免一次性编码，而是将其转换为数字特征，如上所述。</li><li id="ae73" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated"><strong class="lq ir">多类分类</strong>:决策树自然可以扩展处理多类。因为熵或基尼系数杂质可以针对两个以上的类别进行计算，并且可以通过多数表决来做出决定。</li><li id="7255" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated"><strong class="lq ir">特征交互</strong>:出现在遍历路径中的特征相互交互，因为子节点的条件取决于父节点的条件</li><li id="1804" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated"><strong class="lq ir">离群值</strong>:如果树很深，离群值会影响并使树不稳定。</li><li id="f2ec" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated"><strong class="lq ir">可解释性</strong>:由于决策树只不过是if-else语句的集合，所以它具有高度的可解释性。然而，可解释性随着树深度的增加而降低。</li><li id="edc9" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated"><strong class="lq ir">特征重要性:</strong>那些信息增益高的特征是重要的。如果一个特征被多次用于分割，我们使用由于该特征的信息增益的归一化总和。</li></ol></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="bd37" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">优势</h1><ol class=""><li id="df40" class="mp mq iq lq b lr ls lu lv lx ov mb ow mf ox mj oy mv mw mx bi translated">它不需要缩放或标准化数据</li><li id="fcb8" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">高度的可解释性，尤其是当维数较少时</li><li id="db56" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">适用于低延迟系统</li><li id="20f2" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">较少的超参数数量</li><li id="c3f5" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">处理分类数据和数值数据</li><li id="97c0" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">容易理解</li></ol><h1 id="5d0c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">限制</h1><ol class=""><li id="3f16" class="mp mq iq lq b lr ls lu lv lx ov mb ow mf ox mj oy mv mw mx bi translated">训练模型通常需要更长的时间</li><li id="b2ea" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">当您有高维数据时，它可能不合适</li><li id="bbfd" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">过度拟合数据的可能性很高</li><li id="2130" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">数据的微小变化可能会导致决策树结构的整体变化</li><li id="443d" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">随着深度的增加，树变得更加复杂</li><li id="e6c8" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj oy mv mw mx bi translated">决策树通常没有其他分类或回归算法那样的预测准确性</li></ol></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="26a1" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">使用Python构建决策树</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pm pn l"/></div></figure><p id="9d34" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">感谢sci-kit学习库的<em class="nr"> plot_tree </em>函数可视化决策树。我们的决策树看起来会像-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi po"><img src="../Images/97b0314e7c22561c2288db89f743b09d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tbitqr9vuEQKwZ8WsslP3Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图33</p></figure></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="3416" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">参考</h1><ul class=""><li id="2535" class="mp mq iq lq b lr ls lu lv lx ov mb ow mf ox mj mu mv mw mx bi translated"><a class="ae kv" href="https://victorzhou.com/blog/gini-impurity/" rel="noopener ugc nofollow" target="_blank">https://victorzhou.com/blog/gini-impurity/</a></li><li id="e439" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">统计学习导论:R中的应用</li><li id="12d8" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/decision-tree-intuition-from-concept-to-application-530744294bb6">https://towards data science . com/decision-tree-intuition-from-concept-to-application-530744294 bb6</a></li><li id="fa51" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">M. Gopal的应用机器学习</li></ul></div></div>    
</body>
</html>