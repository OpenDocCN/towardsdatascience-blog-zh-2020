# DS/ML Gods 无需尝试即可提高精确度的 6 种方法

> 原文：<https://towardsdatascience.com/6-ways-ds-ml-gods-boost-accuracy-without-trying-1c89de6126df?source=collection_archive---------46----------------------->

## 通过使用这些简单的技巧，轻松提高你的准确度！

![](img/97d6eacb49470f8d5e43937543ffcc8e.png)

(手 src =[http://www.pngplay.com/image/18115](http://www.pngplay.com/image/18115)

# 介绍

机器学习是一个复杂多样的话题，对于新的数据科学家来说，这肯定会令人望而生畏。通常很难让你的模型达到令人满意的 98%的精确度，初学者肯定会努力让他们的模型更精确。幸运的是，对于大多数数据科学家来说，您可以做大量的事情来潜在地缓解这样的问题，因此，有时找到高精度的方法更多地涉及到找出您的模型需要什么样的数据。

# №1:特征缩放

使用连续模型时，提高精度的最简单、最有效的方法之一是缩放模型的要素。存在几种不同类型的特征缩放器，其中一些甚至可能对机器学习没有好处。这些标量中最重要的很可能是标准标量。标准缩放器、z 分数缩放器或正态缩放器使用正态分布来归一化数据。这提高了准确性，因为偏离正常影响的数字与正常情况相比减少了。这样做的好处是你不会丢失数据，但它对你的准确性仍然很有价值。还有另外两个可以用在机器学习中，均值归一化和单位长度缩放。然而，这些通常不会被很好地使用，在大多数情况下，你最好使用标准的定标器。

为了计算正态分布，我们将取一组数字中的每个数字，在除以标准偏差之前减去平均值。在代码中，它看起来有点像这样:

```
using Lathe.stats: mean, std
array = [5,10,15,20]
q = std(array)
mu = mean(array)
[i = (i-mu) / q for i in array]
```

我们会得到一些类似这样的数字:

![](img/bdab29c0dd4d978b30ced30ef02b9c7d.png)

假设这个数组的平均值是 13.5 是安全的，所以 13.5 实际上在我们的正态分布上等于 0。然而，这有点误导，因为如果我们的数据中有 13.5，它将移动分布中的零。

你可能遇到的另一个缩放器是均值规格化器。为了根据平均值对数据进行标准化，我们用平均值减去每个样本，然后用最小值减去最大值。在代码中，这看起来像这样:

```
avg = mean(array)
a = minimum(array)
b = maximum(array)
[i = (i-avg) / (b-a) for i in array]
```

请注意结果中的细微差异:

![](img/cef4ba4dcb7d4962797e09cee26e4c19.png)

# №2:移除异常值

另一个令人难以置信的简单且令人惊讶的提高模型准确性的方法是去除数据中的异常值。从数据中移除异常值有多种方法，其中一种很好的方法是使用 z 值。另一种方法是去掉数据中第三个四分位数以上的值。我们这样做的原因是，这些值当然会影响我们对数据的数学表示，如均值或标准差。这几乎肯定会导致模型(很可能根据平均值和标准偏差等值工作)根据您的杂散数据预测低或高。

从这类数据中移除异常值的最简单方法是用平均值替换任何有问题的值。首先，我们将获得第三个四分位数的数据。或者，你可以得到高于平均值的所有数据的平均值。

对于这个例子，我们将切换到 Python。在本文中，我将同时使用这两种语言，因为它们非常相似，同时使用这两种语言将使双方的开发人员更容易理解。考虑以下数据帧:

![](img/71af37f934472e8dd81a2c7ed9504174.png)

如果我们要为这些数据拟合一个模型，那么无论我们决定为我们的功能使用哪一列，都会有一些非常激进的异常值，这肯定会在将来给我们带来一些问题。为了删除它们，我们将从 scipy.stats 中获取 z_score，并使用条件掩码来过滤不符合条件的值，以从根本上抑制高于正态分布中心的值:

```
from scipy import stats
import numpy as np
z_scores = stats.zscore(df)abs_z_scores = np.abs(z_scores)
filtered_entries = (abs_z_scores < 2).all(axis=1)
new_df = df[filtered_entries]
```

现在如果我们显示 new_df，我们可以看到我们的异常值消失了！

![](img/eeadf79b317ae1eaf31e5fef8e1c0ebb.png)

# №3:移除不良特征

通过修改数据来轻松提高精度的另一个好方法是移除不良要素。这太常见了—您有正确的模型，但没有正确的数据。尽管很多时候一些特性看起来很重要，但它们未必如此。经常有一些功能可能根本不会提高你的分数，事实上，它们甚至会使你的准确度更差。所以不好的功能肯定是要小心的！

> 但是你如何避免它们呢？

避免在模型中使用不良特征的最佳方法是使用统计测试来衡量该特征对目标的统计显著性。另一个很好的方法是获取特性的重要性，这在某些情况下可能有点困难，但是如果不是，这肯定比统计测试简单得多。

# №4:一个热编码器->顺序编码器

使用分类变量进行机器学习的最广泛使用的预处理方法之一可能是 one hot 编码器。one hot coder 获取您的数据，并将其转换为给定列中所有类别的真或假二进制批处理。one hot encoder 非常有用，因为它能够将分类特征转化为数字数据，便于数学算法进行分析。

虽然一个热编码很好，但在很多情况下，顺序编码器会给你更好的准确性。顺序编码本质上涉及到将唯一的标签映射到整数值。另一个可能有用的编码器是标签编码器。

# №5:特征工程

解决这类问题的一个更困难的方法是特征工程。特征工程允许您从可用的特征中创建新的特征，以获得更高的精度。虽然特性工程有时可能很难做到，但它肯定可以在很多时候创造出很高的准确性，如果特性很重要，从长远来看，它肯定是一项有益的投资。

# №6:集成算法

我认为在这个领域有一点被稍微低估了，那就是样本提升和引导汇总的能力。这可能是数据科学家提高准确性的最常见方式之一。

Bootstrap aggregating 也称为 bagging，是一种集成元算法。使用 bootstrap aggregating 的一个好处是，它还减少了数据的方差，从而大大减少了像过度拟合这样的偏差问题。另一方面，Boosting 通常涉及使用许多模型来一起解决一个问题。它还可以减少方差，并有助于减少偏差和防止过度拟合。

# 结论

虽然数据科学肯定是一门很难的学科，随着你继续从事它，你将需要学习越来越多的东西，但你可以做一些相当简单和容易的事情来使你的模型更好，并创建更好的算法。这些不仅难以置信的简单，而且很多可以提高你 10%以上的准确率。不用说，使用这些方法当然是一个伟大的想法！