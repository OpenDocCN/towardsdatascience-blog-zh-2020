<html>
<head>
<title>Restricted Boltzmann Machine as Recommendation System for Movie Review (part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">作为电影评论推荐系统的受限玻尔兹曼机(下)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/restricted-boltzmann-machine-as-a-recommendation-system-for-movie-review-part-2-9a6cab91d85b?source=collection_archive---------28-----------------------#2020-04-27">https://towardsdatascience.com/restricted-boltzmann-machine-as-a-recommendation-system-for-movie-review-part-2-9a6cab91d85b?source=collection_archive---------28-----------------------#2020-04-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fac7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于如何使用Pytorch创建用于电影分级预测的Boltzmann机器的技术演练</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/5b9e5dfeb6777fe2e2f4f9d77faefdd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*37ERRgeQXhkvE9_y1YL2Mw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">通过<a class="ae ku" href="https://unsplash.com/photos/CiUR8zISX60" rel="noopener ugc nofollow" target="_blank">链接</a>改编自unsplash的Img</p></figure><p id="d7dd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">本文是如何构建一个受限波尔兹曼机器(RBM)作为推荐系统的第2部分。</p><blockquote class="lr ls lt"><p id="e792" class="kv kw lu kx b ky kz ju la lb lc jx ld lv lf lg lh lw lj lk ll lx ln lo lp lq im bi translated">在<a class="ae ku" rel="noopener" target="_blank" href="/restricted-boltzmann-machine-how-to-create-a-recommendation-system-for-movie-review-45599a406deb">第一部分</a>中，我们专注于数据处理，这里的重点是<strong class="kx iu">模型创建</strong>。你将学到的是<strong class="kx iu">如何从头开始创建一个RBM模型</strong>。它分为三个部分。</p></blockquote><ol class=""><li id="c10a" class="ly lz it kx b ky kz lb lc le ma li mb lm mc lq md me mf mg bi translated">模型结构</li><li id="d1d6" class="ly lz it kx b ky mh lb mi le mj li mk lm ml lq md me mf mg bi translated">模特培训</li><li id="3cc7" class="ly lz it kx b ky mh lb mi le mj li mk lm ml lq md me mf mg bi translated">模型检验</li></ol><p id="6404" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="lu">📣📣这是一篇技术驱动的文章</em>。现在让我们开始旅程🏃‍♀️🏃‍♂️.</p><ol class=""><li id="7857" class="ly lz it kx b ky kz lb lc le ma li mb lm mc lq md me mf mg bi translated"><strong class="kx iu">模型构建</strong></li></ol><blockquote class="mm"><p id="0efc" class="mn mo it bd mp mq mr ms mt mu mv lq dk translated">本质上，RBM是一个概率图形模型。</p></blockquote><p id="b59a" class="pw-post-body-paragraph kv kw it kx b ky mw ju la lb mx jx ld le my lg lh li mz lk ll lm na lo lp lq im bi translated">为了构建模型架构，我们将为RBM创建一个类。在类中，定义RBM的所有参数，包括隐藏节点的数量、权重以及可见节点和隐藏节点的概率偏差。</p><blockquote class="lr ls lt"><p id="ce5a" class="kv kw lu kx b ky kz ju la lb lc jx ld lv lf lg lh lw lj lk ll lx ln lo lp lq im bi translated">有4个函数，第一个函数是初始化类，第二个函数是在给定可见节点的情况下采样隐藏节点的概率，第三个函数是在给定隐藏节点的情况下采样可见节点的概率，最后一个函数是训练模型。</p></blockquote><p id="da53" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">1.1 <em class="lu"> __init__ </em>函数</p><p id="c92e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">在<em class="lu"> __init__ </em>函数中，我们将初始化所有需要优化的参数。</strong>注意，<em class="lu"> nv </em>和<em class="lu"> nh </em>分别是可见节点数和隐藏节点数。W是可见节点和隐藏节点的权重。我们使用平均值为0、方差为1的正态分布来初始化权重和偏差。<strong class="kx iu"> <em class="lu"> a </em> </strong>是给定可见节点时隐藏节点概率的偏差，<strong class="kx iu"> <em class="lu"> b </em> </strong>是给定隐藏节点时可见节点概率的偏差。注意我们为批处理添加了一个维度，因为我们将在<em class="lu"> Pytorch </em>中使用的函数不能接受只有一维的向量。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="998f" class="ng nh it nc b gy ni nj l nk nl">class RBM():<br/>    def __init__(self, nv, nh):<br/>        self.W = torch.randn(nh, nv)<br/>        self.a = torch.randn(1, nh)<br/>        self.b = torch.randn(1, nb)</span></pre><p id="b61d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">1.2隐藏节点采样功能</p><blockquote class="lr ls lt"><p id="ee2a" class="kv kw lu kx b ky kz ju la lb lc jx ld lv lf lg lh lw lj lk ll lx ln lo lp lq im bi translated"><strong class="kx iu">这个函数是关于在给定可见节点概率的情况下对隐藏节点进行采样</strong>。我们为什么需要这个？因为我们需要概率来采样隐藏节点的激活。</p></blockquote><p id="e8aa" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">假设我们有100个隐藏节点，这个函数将对隐藏节点的激活进行采样，即按照一定的概率<em class="lu"> p_h_given_v </em>激活它们。<em class="lu"> p_h_given_v </em>是给定<em class="lu"> v </em>的值，隐藏节点等于1(激活)的概率。</p><p id="9238" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意，该函数接受参数<em class="lu"> x </em>，这是可见节点的值。我们用<em class="lu"> v </em>来计算隐藏节点的概率。记住，<em class="lu"> h </em>给定<em class="lu">v</em>(<em class="lu">p _ h _给定_v </em>)的概率就是<em class="lu"> v </em>的sigmoid激活。因此，我们将可见节点的值乘以权重，再加上隐藏节点的偏差。我们扩展了偏置<em class="lu"> a </em>的尺寸，使其与<em class="lu"> wx </em>具有相同的尺寸，从而将偏置添加到<em class="lu"> wx </em>的每一行。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="c8a9" class="ng nh it nc b gy ni nj l nk nl">def sample_h(self, x):<br/>    wx = torch.mm(x, self.W.t())<br/>    activation = wx + self.a.expand(wx)<br/>    p_h_given_v =torch.sigmoid(activation)<br/>    reutrn p_h_given_v, torch.bernoulli(p_h_given_v)</span></pre><p id="f6e7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意返回的是<em class="lu"> p_h_given_v </em>，以及采样的隐藏节点。这里，我们做了一个伯努利RBM，因为我们预测了一个二元结果，即用户喜欢或不喜欢一部电影。假设有100个隐藏节点，<em class="lu"> p_h_given_v </em>是100个元素的向量，每个元素为每个隐藏节点被激活的概率，给定可见节点的值(即用户对电影的评分)。但问题是如何激活隐藏节点？这里我们使用<strong class="kx iu">伯努利采样</strong>。假设，对于一个隐藏节点，它在<em class="lu"> p_h_given_v </em>中的概率是70%。我们取0到1之间的一个随机数。如果低于70%，我们将不会激活隐藏节点。通过对<em class="lu"> p_h_given_v </em>中的所有隐藏节点重复伯努利采样，我们得到0和1的向量，其中1对应于要激活的隐藏节点。</p><p id="fc35" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这是吉布斯采样✨✨.需要的第一个函数</p><p id="cd28" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">1.3可见节点采样功能</p><blockquote class="lr ls lt"><p id="925e" class="kv kw lu kx b ky kz ju la lb lc jx ld lv lf lg lh lw lj lk ll lx ln lo lp lq im bi translated"><strong class="kx iu">遵循同样的逻辑，我们创建了对可见节点进行采样的函数。</strong>给定隐藏节点的值(1或0，激活与否)，我们估计可见节点的概率<em class="it"> p_v_given_h </em>，即每个可见节点等于1(被激活)的概率。</p></blockquote><p id="4dfb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">因为有1682个电影和1682个可见节点，我们有1682个概率的向量，每个概率对应于等于1的可见节点，给定隐藏节点的激活。我们使用伯努利采样来决定是否对这个可见节点进行采样。最后，函数返回<strong class="kx iu"> </strong>可见节点的概率<em class="lu"> p_v_given_h </em>，以及一个1和0的向量，其中1对应于要激活的可见节点。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="72fa" class="ng nh it nc b gy ni nj l nk nl">def sample_v(self, y):<br/>    wy = torch.mm(y, self.W)<br/>    activation = wy + self.b.expand(wy)<br/>    p_v_given_h =torch.sigmoid(activation)<br/>    reutrn p_v_given_h, torch.bernoulli(p_v_given_h)</span></pre><p id="dd60" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">1.4对比散度函数</p><blockquote class="mm"><p id="35cb" class="mn mo it bd mp mq nm nn no np nq lq dk translated"><strong class="ak"> RBM是一个基于能源的模型，这意味着我们需要最小化能源函数。</strong></p></blockquote><blockquote class="lr ls lt"><p id="f379" class="kv kw lu kx b ky mw ju la lb mx jx ld lv my lg lh lw mz lk ll lx na lo lp lq im bi translated">能量函数取决于模型的权重，因此我们需要优化权重。另一方面，RBM可以被视为一个概率图形模型，它需要最大化训练集的对数似然性。显然，对于任何神经网络，为了最小化能量或最大化对数似然，我们需要计算梯度。这里我们使用对比散度来近似似然梯度。</p><p id="7b6a" class="kv kw lu kx b ky kz ju la lb lc jx ld lv lf lg lh lw lj lk ll lx ln lo lp lq im bi translated">对比分歧是关于近似对数似然梯度。代替需要大量计算资源的梯度的直接计算，我们近似梯度。在训练过程中，我们朝着能量最小化的方向调整重量。类似于通过梯度下降最小化损失函数，其中我们更新权重以最小化损失，唯一的区别是我们使用对比散度算法来近似梯度。</p></blockquote><p id="4ca8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">具体来说，我们从输入向量<em class="lu"> v0 </em>开始，基于<em class="lu"> p_h_given_v，</em>的概率，我们在第一次迭代时采样第一组隐藏节点，并使用这些采样的隐藏节点来采样可见节点<em class="lu"> v1 </em>与<em class="lu"> p_v_given_h. </em>重复这个过程<em class="lu"> K </em>次，这就是关于K步对比发散的全部内容。</p><p id="caeb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在这个函数中，我们将使用本文概述的算法更新权重、可见节点的偏差和隐藏节点的偏差。<em class="lu">我强烈推荐这本</em><a class="ae ku" href="https://link.springer.com/content/pdf/10.1007/978-3-642-33275-3_2.pdf" rel="noopener ugc nofollow" target="_blank"><em class="lu">RBM pape</em></a><em class="lu">r如果你喜欢更深入的了解。</em></p><p id="9673" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在函数内部，<em class="lu"> v0 </em>是包含用户对所有电影的评级的输入向量。<em class="lu"> vk </em>是从可见节点到隐藏节点进行<em class="lu"> k </em>采样后得到的可见节点。<em class="lu"> ph0 </em>是给定<em class="lu"> v0 </em>的第一次迭代时隐藏节点概率等于1的向量。<em class="lu"> phk </em>是给定可见节点<em class="lu"> vk </em>在第<em class="lu">k次</em>迭代时隐藏节点的概率。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="0a4b" class="ng nh it nc b gy ni nj l nk nl">def train(self, v0, vk, ph0, phk):<br/>    self.W += torch.mm(v0.t(), ph0) — torch.mm(vk.t(), phk)<br/>    self.b += torch.sum((v0 — vk), 0)<br/>    self.a += torch.sum((ph0 — phk), 0)</span></pre><p id="4666" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">1.5 RBM对象创建</p><p id="8dad" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为了初始化RBM，我们创建一个RBM类的对象。首先我们需要可见节点数，也就是电影总数。隐藏节点的数量对应于我们想要从电影中检测的特征的数量。很难确定最佳的功能数量。但是这个参数是可调的，所以我们从100开始。我们还定义了批量大小，这是我们用来更新权重的一批中的观察次数。我们再次从100开始。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="2a90" class="ng nh it nc b gy ni nj l nk nl">nv = len(training_set[0])<br/> nh = 100<br/> batch_size = 100<br/> rbm = RBM(nv, nh)</span></pre><p id="0538" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">2.<strong class="kx iu">模特培训</strong></p><p id="2c65" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">祝贺你通过了第一部分，因为这是最难的部分👍👍。现在让我们来训练RBM模型。</p><p id="3d20" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们首先将<em class="lu"> nb_epoch </em>设置为10。对于每个时期，所有观测值将进入网络，并在每批数据通过网络后更新权重。最后，我们得到最终的可见节点，这些节点对最初没有评级的电影有了新的评级。在每一批中，我们将进行k步对比散度来预测随机行走<em class="lu"> k </em>步后的可见节点。因此，我们将有3个循环，一个用于历元迭代，一个用于批量迭代，最后一个用于对比发散。</p><p id="61e9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于损失函数，我们将测量训练集中预测评级和真实评级之间的差异。有几个选项，包括RMSE，它是预测收视率和实际收视率之间的平方差的均值的根，以及预测收视率和实际收视率之间的绝对差。我们在这里取一个绝对的差值。</p><p id="2c41" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在<strong class="kx iu">批处理</strong>循环中，我们有输入向量<em class="lu"> vk </em>，它将通过对比散度进行更新，并在随机行走<em class="lu"> k </em>步后作为Gibbs采样的输出。但开始时，<em class="lu"> vk </em>是一批用户所有评分的输入批次。<em class="lu"> v0 </em>是将与预测值进行比较的目标值，预测值是该批用户已经评定的等级。<em class="lu"> ph </em> 0是给定可见节点<em class="lu"> v0 </em>时隐藏节点的初始概率。</p><p id="b142" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在对比发散循环中，我们将进行吉布斯采样。基本上，它包括建立Gibbs链，这是从可见节点到隐藏节点的几次往返。在每一轮中，可见节点被更新以获得良好的预测。从可见节点<em class="lu"> vk </em>开始，我们用伯努利采样法对隐藏节点进行采样。在10次随机行走结束时，我们得到第10个采样的可见节点。请注意，我们不会对RBM进行等级为-1的培训，这些等级在开始时并不作为真实等级。</p><p id="8409" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">利用<em class="lu"> v0 </em>、<em class="lu"> vk、ph0、phk </em>，我们可以应用训练函数来更新权重和偏差。最终，与电影特征最相关的概率将获得最大的权重，从而导致正确的预测。在每一批结束时，我们记录训练损失。同样，我们只记录已经存在的评级损失。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="c839" class="ng nh it nc b gy ni nj l nk nl">nb_epoch = 10<br/>for epoch in range(1, nb_epoch+1):<br/>    train_loss = 0<br/>    s = 0.<br/>    for id_user in range(0, nb_users — batch_size, 100):<br/>        vk = training_set[id_user: id_user+batch_size]<br/>        v0 = training_set[id_user: id_user+batch_size]<br/>        ph0, = rbm.sample_h(v0)<br/>        for k in range(10):<br/>            _, hk = rbm.sample_h(vk)<br/>            _, vk = rbm.sample_v(hk)<br/>            vk[v0&lt;0] = v0[v0&lt;0]<br/>        phk, _ = rbm.sample_h(vk)<br/>       rbm.train(v0, vk, ph0, phk)<br/>       train_loss += torch.mean(torch.abs(v0[v0&gt;0]-vk[v0&gt;0]))<br/>       s += 1<br/> print(‘epoch: ‘+str(epoch)+’ loss: ‘+str(train_loss/s))</span></pre><p id="879c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">经过10个历元迭代的训练，我们得到了一个<strong class="kx iu"> 0.15 </strong>的损失。相当准确的✌✌.</p><p id="f917" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.<strong class="kx iu">模型测试</strong></p><blockquote class="lr ls lt"><p id="65e1" class="kv kw lu kx b ky kz ju la lb lc jx ld lv lf lg lh lw lj lk ll lx ln lo lp lq im bi translated">与训练循环相比，我们去除了历元迭代和批量迭代。我们将通过RBM循环每个观测值，并逐个进行预测，累积每次预测的损失。</p></blockquote><p id="9757" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意下面，我们使用<em class="lu">训练集</em>作为输入来激活RBM，同样的训练集用于训练RBM。但不同的是，在测试阶段，我们没有删除用户最初没有评级的评级，因为这些是用于测试目的的模型的未知输入。还要注意，我们没有像在训练阶段那样进行10步随机行走。这是因为对于获得最佳预测的测试，1步优于10次迭代。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="0571" class="ng nh it nc b gy ni nj l nk nl">test_loss = 0<br/>s = 0.<br/>for id_user in range(0, nb_users):<br/>    v_input = training_set[id_user: id_user+1]<br/>    v_target = test_set[id_user: id_user+1]<br/>    if len(v_target(v_target&gt;=0)):<br/>        _, h = rbm.sample_h(v_input)<br/>        _, v_input = rbm.sample_v(h)<br/>        test_loss += torch.mean(torch.abs(v_target[v_target&gt;0]-<br/>                                          v_input[v_target&gt;0])) <br/>        s += 1<br/>print(‘test loss: ‘ +str(test_loss/s))</span></pre><p id="0419" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">太好了。我们获得的损失<strong class="kx iu">为0.16 </strong>，接近训练损失，表明轻微过度拟合。</p><p id="9d00" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">仅此而已。希望这能让你了解如何创建一个RBM作为推荐系统。如果需要源代码，请访问我的</strong> <a class="ae ku" href="https://github.com/luke4u/Movie-Rating-Prediction" rel="noopener ugc nofollow" target="_blank"> <strong class="kx iu"> Github </strong> </a> <strong class="kx iu">页面🤞🤞。</strong></p></div></div>    
</body>
</html>