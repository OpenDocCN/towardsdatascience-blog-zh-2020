<html>
<head>
<title>Machine Comprehension with BERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 BERT 进行机器理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-comprehension-with-bert-6eadf16c87c1?source=collection_archive---------18-----------------------#2020-03-15">https://towardsdatascience.com/machine-comprehension-with-bert-6eadf16c87c1?source=collection_archive---------18-----------------------#2020-03-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cdaf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用深度学习进行问题回答</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/566c1eb8bca86c3e60f1fcee8fba700e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QUAWKMz7ElD-OEXQ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">迈克尔·泽兹奇在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="e2e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">在 Github 的资源库中可以找到</strong> <a class="ae kv" href="https://github.com/edwardcqian/bert_QA" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">这里有</strong> </a> <strong class="ky ir">。本文将介绍如何设置它。预计时间:30 分钟以内。</strong></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="0940" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">机器(阅读)理解是 NLP 的领域，在这里我们教机器理解和回答使用非结构化文本的问题。</p><div class="lz ma gp gr mb mc"><a href="https://www.coursera.org/specializations/deep-learning?ranMID=40328&amp;ranEAID=J2RDo*Rlzkk&amp;ranSiteID=J2RDo.Rlzkk-XtffRH2JEnDifWa3VrZJ1A&amp;siteID=J2RDo.Rlzkk-XtffRH2JEnDifWa3VrZJ1A&amp;utm_content=2&amp;utm_medium=partners&amp;utm_source=linkshare&amp;utm_campaign=J2RDo*Rlzkk" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ir gy z fp mh fr fs mi fu fw ip bi translated">深度学习</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">成为深度学习专家。掌握深度学习的基础，打入 AI。填满的星星填满的星星…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">www.coursera.org</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq kp mc"/></div></div></a></div><p id="635b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2016 年，StanfordNLP 整合了 SQuAD(斯坦福问答数据集)数据集，该数据集由超过 10 万个根据维基百科文章制定的问题答案对组成。面临的挑战是训练一个机器学习模型来回答基于上下文文档的问题。当提供一个上下文文档(自由形式的文本)和一个问题时，模型将返回最有可能回答问题的文本子集。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/f2862d8120f8842a7dfa32b4aaccc12a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*UkaRRPZx2cOPOsGevDewig.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自小队数据集的示例条目</p></figure><p id="e53c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">世界各地的顶级人工智能实践者解决了这个问题，但两年后，没有模型击败人类基准。然而，在 2018 年底，谷歌大脑的聪明人推出了 BERT(来自变压器的双向编码器表示)，这是一种通用语言理解模型。通过一些微调，该模型能够在与小队测试集进行比较时超过人类基准。</p><p id="eb5a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">来自<a class="ae kv" href="https://arxiv.org/pdf/1606.05250.pdf" rel="noopener ugc nofollow" target="_blank"> paper SQuAD: 100，000 多个用于机器理解文本的问题，</a>这些是用于评估的指标:</p><blockquote class="ms mt mu"><p id="6b40" class="kw kx mv ky b kz la jr lb lc ld ju le mw lg lh li mx lk ll lm my lo lp lq lr ij bi translated"><strong class="ky ir">完全匹配。</strong>此指标衡量与任何一个基本事实答案完全匹配的预测的百分比。</p><p id="016e" class="kw kx mv ky b kz la jr lb lc ld ju le mw lg lh li mx lk ll lm my lo lp lq lr ij bi translated"><strong class="ky ir">(宏观平均)F1 得分。</strong>此指标衡量预测和真实答案之间的平均重叠。我们将预测和基础事实视为一袋袋的令牌，并计算它们的 F1。我们对给定问题的所有基本事实答案取最大值 F1，然后对所有问题取平均值。</p></blockquote><p id="5832" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于初始小队数据集:</p><ul class=""><li id="6d7b" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated">人类注释者获得了 82.304% 的精确匹配分数和 91.221% 的 F1 分数</li><li id="57c1" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated">最初的 BERT 模型(在排行榜上排名第 11，主要被 BERT 的其他变体击败)获得了精确匹配分数<strong class="ky ir"> 85.083% </strong>和 F1 分数<strong class="ky ir"> 91.835% </strong></li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="1c2d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">今天，我将向你展示如何使用 BERT 建立你自己的阅读理解系统。<strong class="ky ir">在 Github 仓库中可以找到</strong> <a class="ae kv" href="https://github.com/edwardcqian/bert_QA" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">这里</strong> </a> <strong class="ky ir">。</strong></p><p id="1ea8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要开始，你需要 Docker。🐳</p><h2 id="9404" class="nn no iq bd np nq nr dn ns nt nu dp nv lf nw nx ny lj nz oa ob ln oc od oe of bi translated">设置 Docker</h2><p id="55ed" class="pw-post-body-paragraph kw kx iq ky b kz og jr lb lc oh ju le lf oi lh li lj oj ll lm ln ok lp lq lr ij bi translated">Docker 对于容器化应用程序很有用。我们将使用 Docker 使这项工作更有用，结果更具可重复性。按照这些说明在你的系统上安装 Docker。你还需要在 macos 和 windows 上自带 Docker 的<code class="fe ol om on oo b">docker-compose</code>。如果你用的是 Linux，你可以在这里安装<a class="ae kv" href="https://runnable.com/docker/introduction-to-docker-compose" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="4329" class="nn no iq bd np nq nr dn ns nt nu dp nv lf nw nx ny lj nz oa ob ln oc od oe of bi translated">从我的 Github Repo 本地保存代码</h2><p id="4344" class="pw-post-body-paragraph kw kx iq ky b kz og jr lb lc oh ju le lf oi lh li lj oj ll lm ln ok lp lq lr ij bi translated">除了阵容数据和预先训练的重量，所有的代码和必要的依赖都在报告中。<strong class="ky ir">注:</strong>只有自己想训练模型才需要数据。如果没有，你可以使用我预先训练的重量。<strong class="ky ir">另一个注意:</strong>我不建议训练模型，除非你有强大的 GPU 或者大量的时间。</p><p id="c633" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">如果你想自己训练模特… </strong></p><p id="a56b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">点击下载小队 2.0 数据集<a class="ae kv" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank">。将“训练集 2.0 版”和“开发集 2.0 版”保存到<code class="fe ol om on oo b">bert_QA/data</code>。</a></p><p id="d43f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">如果您想使用预先训练的重量… </strong></p><p id="e212" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我已经用 SQuAD 2.0 数据集训练了这个模型。你可以在这里下载<a class="ae kv" href="https://drive.google.com/file/d/1lHVdsgLayL20CkVMOQFq6Ji85leS7FCA/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"/>。解压文件并将内容保存为<code class="fe ol om on oo b">bert_QA/weights</code>。</p><h2 id="8707" class="nn no iq bd np nq nr dn ns nt nu dp nv lf nw nx ny lj nz oa ob ln oc od oe of bi translated">创建 Docker 容器</h2><p id="8570" class="pw-post-body-paragraph kw kx iq ky b kz og jr lb lc oh ju le lf oi lh li lj oj ll lm ln ok lp lq lr ij bi translated">Docker 容器是使用 docker 映像中提供的指令构建的工作环境。我们需要一个<code class="fe ol om on oo b">docker-compose.yaml</code>配置文件来定义我们的容器的外观。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="7fba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我为 Pytorch 变形金刚做了一个定制的 docker 图片，你可以在 dockerhub 上找到。出于本教程的目的，您不需要提取任何图像，因为配置文件已经这样做了。配置文件还将把我们的本地<code class="fe ol om on oo b">bert_QA</code>文件夹作为<code class="fe ol om on oo b">/workspace</code>挂载到容器中。</p><ul class=""><li id="41d5" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated">通过从终端/shell 运行根目录中的<code class="fe ol om on oo b">docker-compose up -d </code>来启动我们的容器。第一次需要几分钟。</li><li id="ea3a" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated">使用<code class="fe ol om on oo b">docker ps</code>检查我们的容器是否启动并运行。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/8d3e882603606ab64184ba2a3757fa89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KXR2eFS5keo2-aLMzXxzcA.png"/></div></div></figure><ul class=""><li id="4b03" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated">将 bash shell 附加到正在运行的容器:</li></ul><p id="b23b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ol om on oo b">docker exec -it &lt;your_container_name&gt; bash</code></p><h2 id="65fb" class="nn no iq bd np nq nr dn ns nt nu dp nv lf nw nx ny lj nz oa ob ln oc od oe of bi translated">训练模型</h2><p id="d391" class="pw-post-body-paragraph kw kx iq ky b kz og jr lb lc oh ju le lf oi lh li lj oj ll lm ln ok lp lq lr ij bi translated">如果你使用我预先训练的重量，跳过这一步。我们将使用由<a class="ae kv" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank"> huggingface </a>提供的默认训练脚本来训练模型。</p><p id="2c4d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在 bash shell 中运行:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="592c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注意:</strong>如果没有 GPU，per_gpu_train_batch_size 不会做任何事情</p><p id="a6cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这将训练并保存模型权重到<code class="fe ol om on oo b">weights</code>目录。</p><h2 id="7ff0" class="nn no iq bd np nq nr dn ns nt nu dp nv lf nw nx ny lj nz oa ob ln oc od oe of bi translated">使用模型进行推理</h2><p id="7f3d" class="pw-post-body-paragraph kw kx iq ky b kz og jr lb lc oh ju le lf oi lh li lj oj ll lm ln ok lp lq lr ij bi translated">现在让我们用这个模型来做一些很酷的东西。</p><p id="0c29" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在 shell 中启动一个 ipython 会话，并导入<code class="fe ol om on oo b">ModelInference</code>模块以从<code class="fe ol om on oo b">weights/</code>加载权重。将上下文文档作为参数传递给<code class="fe ol om on oo b">mi.add_target_text()</code>。摄取完语料库后，使用<code class="fe ol om on oo b">mi.evaluate()</code>提问。只有当模型确信答案存在于文本中时，模块才会返回答案。否则，模型将输出“未找到有效答案”。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="op oq l"/></div></figure><h2 id="80a4" class="nn no iq bd np nq nr dn ns nt nu dp nv lf nw nx ny lj nz oa ob ln oc od oe of bi translated">结论</h2><p id="bbf4" class="pw-post-body-paragraph kw kx iq ky b kz og jr lb lc oh ju le lf oi lh li lj oj ll lm ln ok lp lq lr ij bi translated">在过去的几年里，NLP 取得了长足的进步。预训练的 BERT 权重对 NLP 的影响类似于 AlexNet 对图像识别的影响。它实现了自然语言理解的许多新颖应用。</p></div></div>    
</body>
</html>