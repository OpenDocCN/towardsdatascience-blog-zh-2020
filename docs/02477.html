<html>
<head>
<title>A Review of IBM’s Advanced Machine Learning and Signal Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">IBM高级机器学习和信号处理述评</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-review-of-ibms-advanced-machine-learning-and-signal-processing-certification-371bd937bb76?source=collection_archive---------24-----------------------#2020-03-09">https://towardsdatascience.com/a-review-of-ibms-advanced-machine-learning-and-signal-processing-certification-371bd937bb76?source=collection_archive---------24-----------------------#2020-03-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1c55" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Coursera上的高级机器学习和信号处理课程的全面可视化指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ec51f5ec4ab215f930fe17ff67c52bd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n_r4VyLXsEXRcldM"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">沙哈达特·拉赫曼在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="697b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> T </span>他的评论不仅旨在向您提供我对这门课程的看法，还旨在让您深入了解课程所涵盖的主题，并教授一些关键概念。</p><p id="a59e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">高级机器学习和信号处理课程由IBM开发，可在Coursera上获得。它可以作为单独的课程，也可以作为由四部分组成的大规模开放在线课程(MOOC)的一部分，即<a class="ae ky" href="https://www.coursera.org/specializations/advanced-data-science-ibm" rel="noopener ugc nofollow" target="_blank">高级数据科学专业</a>。</p><p id="d55d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.coursera.org/learn/ds?" rel="noopener ugc nofollow" target="_blank">可扩展数据科学基础</a>重点介绍了云中Apache Spark的基础知识，并介绍了IBM Watson Studio (IBM的云服务)。相比之下，这门课程明显更深入，侧重于更高级的机器学习概念和信号处理。</p><p id="de28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该课程由两位IBM数据科学家讲授，分别是<a class="ae ky" href="https://www.linkedin.com/in/romeo-kienzler-089b4557/" rel="noopener ugc nofollow" target="_blank">罗密欧·肯兹勒</a>和<a class="ae ky" href="https://www.linkedin.com/in/nikolaymanchev/?originalSubdomain=uk" rel="noopener ugc nofollow" target="_blank">尼古拉·曼切夫</a>。我发现他们两个都是优秀的导师。</p><h1 id="ef51" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">第一周</h1><p id="4cca" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">第一周从ML线性代数的概述开始。它非常简单，涵盖了ML中使用的不同数据对象以及对这些对象的数学运算。这里实际上有一些非常有用的知识片段，例如(1)一个<strong class="lb iu">向量</strong>必须只包含<strong class="lb iu">一种数据类型</strong>，而一个<strong class="lb iu">元组</strong>可以包含<strong class="lb iu">多种数据类型</strong>。(2)张量可以作为任意N维空间的通称:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/adf3a706c6eb7f6705367f302ed3f742.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*CZwL5G7sFEz2_c12sm5IPQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">标量&gt;矢量&gt;矩阵&gt;张量</p></figure><p id="1514" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">高维向量空间是第一课之后的自然进展。在这里，罗密欧描述了几个有用的定义和概念，并触及了高维数据背后的直觉。我们将在本课程的后面部分更深入地探讨这些概念。</p><div class="kj kk kl km gt ab cb"><figure class="nc kn nd ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/0fdcd924b72956eea9688d00ab3ecc21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*GXruNvwIOfU4IIYuhWBhUg.gif"/></div></figure><figure class="nc kn nd ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/12f62f65317f7af5ab9acfadc6614233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*tjeZRYGukgREXRpA5-tT4w.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ni di nj nk translated">投影到2D平面上的3D数据(左)和投影到3D超级平面上的4D数据(右)——第三周会有更多的介绍</p></figure></div><p id="aff4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还讨论了有监督的和无监督的机器学习之间的区别。简而言之就是—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/e3fd576296985fdd89eb5c2e56ece2d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aXX8zsRlSZli-baaKFiUUw.png"/></div></div></figure><p id="f39a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">监督学习</strong>:机器学习，其中输出标签、标志或值已被分配给每个样本。这是算法的<strong class="lb iu">目标</strong>，并指导学习过程。例子包括-</p><ul class=""><li id="bd27" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">分类-目标值是离散的</li><li id="a35d" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">回归-目标值是连续的</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/348224d91b3aab112f5a6ee4ca3fa88f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*UkLPO5cPNLeKMKLBGt25dw.gif"/></div></figure><p id="d9da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">无监督学习</strong>:不存在输出标签、标志或值的机器学习。这意味着算法需要在数据中找到模式，并输出一些有助于我们理解这些模式的东西。例子包括-</p><ul class=""><li id="cbfb" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">聚类-样本被分成不同的聚类/类别</li><li id="1134" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">维数减少-减少了特征的数量，同时最大限度地减少了数据丢失</li></ul></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="821c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，罗密欧谈到了ML管道，它是你的数据处理步骤的“流程”。例如，对于简单的多类分类，您可以使用以下管道。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/d4646eccfb2f9bc324fe1919ce523716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*zvb-JtdllVm-5ZNYy8FKsw.gif"/></div></div></figure><p id="95a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里一个特别有用的概念是数据管道的<strong class="lb iu">模块化。通过将该过程的每个步骤分割成独立的部分，我们能够快速切换不同的预处理方法、ML算法或其他训练参数。</strong></p><p id="9a12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了Spark pipeline对象，完整的集成流程将拥有<strong class="lb iu"> fit </strong>、<strong class="lb iu"> evaluate </strong>和<strong class="lb iu"> score </strong>功能。这使得不同模型之间的快速原型和比较成为可能。这意味着我们可以用更少的时间建立一个更好的模型。</p></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="7c5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本周的代码非常多，我认为这是非常好的，因为它是从上一门课开始的。编程任务只是检查您的环境设置是否正确，不幸的是，我认为这错过了复习本周所涉及的关键编码部分的机会。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fd03a73cd0b404c22ce8346a4b5c131e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8En5cd9sw5MHv6UQ"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@craftedbygc?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">绿色变色龙</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="a526" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">第二周</h1><p id="432f" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">我们这周讨论了很多。涵盖的主题总结如下:</p><ul class=""><li id="6cc0" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">线性回归</li><li id="0323" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">批量梯度下降</li><li id="09c4" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">拆分(训练集、验证集和测试集)</li><li id="088f" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">过度装配和装配不足</li><li id="7d2c" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">估价</li><li id="1253" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">逻辑回归</li><li id="e685" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">朴素贝叶斯</li><li id="b891" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">支持向量机</li><li id="51da" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">交叉验证</li><li id="f9f3" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">超参数调谐</li><li id="c03c" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">集成学习(决策树、随机森林、梯度推进等)</li><li id="24e9" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">正规化</li></ul><p id="ee6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这似乎很多。<strong class="lb iu">是很多。</strong></p><p id="eb96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这真的让我惊讶，这个星期包括了多少。仅仅是关于朴素贝叶斯的那一节，如果研究到一个合理的深度就可以轻易地耗费许多许多小时(<em class="oj">贝叶斯统计是一个</em> <strong class="lb iu"> <em class="oj">非常</em> </strong> <em class="oj">深的兔子洞</em>)。</p><p id="bd9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管如此，这一周教授的主题范围很广，深度也很深。一些讲座深入许多算法背后的数学和直觉。而其他人展示了如何用Apache SparkML应用算法，这真的很酷。</p><p id="f42a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一个例子，我们用Spark构建了一个梯度提升树分类器，如下所示:</p><ul class=""><li id="77bc" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">首先我们导入必要的模块<em class="oj">(假设我们已经导入了我们的训练数据</em> <strong class="lb iu"> <em class="oj"> df </em> </strong> <em class="oj">，它被存储为一个熊猫数据帧)</em></li></ul><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="3d10" class="op mf it ol b gy oq or l os ot">from pyspark.ml.feature import StringIndexer, VectorAssembler,<br/>                               Normalizer<br/>from pyspark.ml.linalg import Vectors<br/>from pyspark.ml.classification import GBTClassifier</span></pre><ul class=""><li id="9b36" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">利用我们在第一周学到的知识，我们初始化数据管道的每个组件:</li></ul><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="0a87" class="op mf it ol b gy oq or l os ot"># create unique index for each unique string (our target classes)<br/>indexer = StringIndexer(inputCol='class', outputCol='label')</span><span id="5e36" class="op mf it ol b gy ou or l os ot"># convert our multiple dataframe input columns to a vector<br/>vectorAssembler = VectorAssembler(inputCols=['x', 'y', 'z'],<br/>                                  outputCol='features')</span><span id="5f8c" class="op mf it ol b gy ou or l os ot"># normalize our input values<br/>normalizer = Normalizer(inputCol='features', outputCol='features_norm', p=1.0)</span></pre><p id="0e4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">…包括分类器:</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="f5a5" class="op mf it ol b gy oq or l os ot">gbt = GBTClassifier(labelCol='label', featuresCol='features',<br/>                    maxIter=10)  # this will run for 10 iterations</span></pre><ul class=""><li id="5275" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">创建每个组件后，我们将它们放入一个Spark管道对象中:</li></ul><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="a636" class="op mf it ol b gy oq or l os ot">pipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer,<br/>                            gbt])</span></pre><p id="6e79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们已经构建了管道，我们只需输入<code class="fe ov ow ox ol b">pipeline.fit(df_train) </code>来训练我们的模型。</p><p id="5b97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在IBM Watson Studio中使用Spark实现这一点意味着我们可以轻松扩展。在这种情况下，它不是必需的，但是对于大型数据集和更复杂的模型，它非常有用。</p><p id="973a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这周有几个小测验，大部分都很短，但还是不错的。编程任务非常简单，在到达顶点项目之前通常都是如此。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/da92d0d2d779df70a23a5378b5672073.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*frxz2GU2EmhxguEQ"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@levajsics?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Norbert Levajsics </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="2c25" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">第三周</h1><p id="1a7b" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">本周我们关注无监督机器学习。特别是<strong class="lb iu">聚类</strong>和<strong class="lb iu">主成分分析</strong> (PCA)。</p><p id="9d01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">聚类部分非常直观。总体而言，聚类是一种非常简单的算法。但是我相信课程的这一部分提供的解释和例子非常令人难忘，而且非常容易理解。</p><p id="6bb3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PCA部分更有挑战性。涵盖以下内容:</p><ul class=""><li id="fc27" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">降维</li><li id="cce1" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">PCA(当然)</li><li id="2907" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">协方差和相关矩阵</li><li id="6cdd" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">特征向量和特征值</li><li id="e4fb" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">数据投影</li></ul><p id="ef18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PCA用于降维，我们试图减少数据集中的维数(特征),同时保留尽可能多的信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/6cf54f2bb000cdd5d70bbd2eb471b557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*njmCNLybD1f4tHr0rhExQQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">3D数据被投影到2D平面上</p></figure><p id="f3e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过将3D空间中的每个点投影到2D平面上，我们可以轻松地将数据集从3D缩减到2D(如上所示)。</p><p id="fe48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在高层次上，PCA做同样的事情，但是试图尽可能地保持数据点之间的距离。</p><p id="837e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种尽可能多地保留信息(距离)的行为在分类中至关重要。因为正是这些距离允许我们将数据点分成不同的类别。</p><p id="d5ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，让我们从两个不同的方向看一个3D图:</p><div class="kj kk kl km gt ab cb"><figure class="nc kn oz ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/f62d7c07063ebf97abc97aa1b7d8b430.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*8YDkLRNB3t8qYHhyDyuptA.png"/></div></figure><figure class="nc kn pa ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/eae19034b24b2759362c6001de94b328.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*9Y6Fy_QpkTIIqBvNNgLP5g.png"/></div></figure></div><p id="1d44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们去除两幅图中的颜色差异，我们仍然能够很容易地区分左边图像中的两个独立的集群。然而，在正确的图像中，我们不会。</p><p id="a4eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在想象我们把这些点投射到一个平行于我们视线的表面上。聚集左边的投影点很容易，右边的就不可能了。</p><p id="310f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过将点投影到使点之间的方差最大化的表面上，PCA有效地优化了我们左边的场景。</p><p id="23a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总的来说，这一周非常有趣，每个概念都非常直观，这很棒！像每周一样，有测验和一个编程作业。再说一次，这个任务很简单。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/b463c1915e1b7987cae69606d30927ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HMw8gLth9Ej6YNoe"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">张秀坤·施罗德在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="95f6" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">第四周</h1><p id="9bed" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">这就是本课程“信号处理”部分的内容。虽然在很大程度上是数据科学或机器学习，但我发现这一周绝对令人着迷。</p><h2 id="eb79" class="op mf it bd mg pc pd dn mk pe pf dp mo li pg ph mq lm pi pj ms lq pk pl mu pm bi translated">傅里叶变换</h2><p id="056b" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">我们从傅立叶变换(FT)开始，它允许我们将复杂信号(时域)分解为构成信号的频率(频域)。</p><p id="caf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这取决于你的背景，可能有也可能没有任何意义，所以简而言之。</p></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="dbde" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">噪音由振动组成。最简单的振动由重复的上下运动组成，产生正弦曲线(或正弦波)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/ac1f69fc0e4f8db1863969eb67117a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*hVyBothX0ypG1zajTKZqmQ.gif"/></div></div></figure><p id="bc6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">y轴代表波的振幅，x轴代表时间。一次完整的上下运动的长度称为波长。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/fcc9b0c9814d4f3532e29a48693f7ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pRnRKBq-05TRY233XcHmlA.png"/></div></div></figure><p id="ba74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们合并两个波长，它们会产生一个新的波，这个新的波是这些波的振幅相加，这种合并被称为叠加。</p><p id="fe96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在考虑下面的波:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/17550e81eb79df1d5f29b50217938d1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CNMc8UvVlWAj-lUso7vx6w.jpeg"/></div></div></figure><p id="5629" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个波都是一个简单的正弦曲线，但它们组合在一起就形成了一个复杂得多的模式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/ab8780c3bc78d9301413c2ce17db920a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qM4l9ePblCZvKsVTYZ1-PA.jpeg"/></div></div></figure><p id="2949" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">傅立叶变换允许我们输入复合波信号，并输出每个组成正弦波的频率和振幅。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/8928a0629fc725945d1a8cfd7f66db8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RIbDzrroj2fu8tQit_GaBw.png"/></div></div></figure><p id="ea03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">查看波形有两种方式。在<strong class="lb iu">时域</strong>(左)，或者在<strong class="lb iu">频域</strong>(右)。</p><p id="70eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">时间域是你已经看到的，它是波形。x轴上有<strong class="lb iu">时间</strong>，y轴上有<strong class="lb iu">振幅</strong>。</p><p id="e6ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相反，频域显示了构成波的组成频率。x轴上有<strong class="lb iu">频率</strong>，y轴上有<strong class="lb iu">振幅</strong>。</p><p id="db4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">傅立叶变换在这两幅图之间转换(逆傅立叶变换涵盖了频域到时域转换)。</p><h2 id="d52b" class="op mf it bd mg pc pd dn mk pe pf dp mo li pg ph mq lm pi pj ms lq pk pl mu pm bi translated">周摘要</h2><p id="dd8e" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">金融时报引人入胜，但不是本周的唯一焦点。它分为<strong class="lb iu">两个</strong>主题，这两个主题都包括以下子主题:</p><p id="d91c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">傅立叶变换</strong></p><ul class=""><li id="d4f2" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">信号分解、时域和频域</li><li id="c77d" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">信号产生和相移</li><li id="47f7" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">FT背后的数学和直觉</li><li id="6e32" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">离散快速傅立叶变换</li></ul><p id="33f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">小波</strong></p><ul class=""><li id="a306" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">连续小波变换</li><li id="2d8f" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">缩放和平移</li><li id="6735" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">机器学习中的小波</li></ul><p id="4e5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">小波和FT一样有趣。我发现自己很容易参与到这个星期的活动中，这是由于所涵盖的主题和教学标准的混合。我相信这在很大程度上是因为尼古拉对材料的了解。</p><p id="d0aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">编程作业也不是特别具有挑战性，有点填鸭式。但这是我唯一的抱怨，这一周真的很吸引人，教得很好，并在最后的讲座中很好地联系到机器学习。</p><h1 id="4199" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">结论</h1><p id="737d" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">我发现这门课非常有益。由于该课程仅在IBM Watson Studio上进行，因此还有一层额外的用途。这是对IBM云服务的完美介绍。当然，这通过增加曝光率为IBM带来了好处，但对于任何数据专业人员来说，这也是一项无价的额外技能。</p><p id="4393" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">课程的技术性更强的方面非常好。材料的范围很广，大部分主题都有合理的深度。</p><p id="4c64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与任何MOOC一样，我认为重要的是要注意到，要真正加深你的理解，最好是密切关注所教的内容。然后，去找更多的材料，进一步研究。</p><p id="8de2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，试着学以致用，写/说你学到的东西。如果你能应用并解释你所学到的东西，你会理解得更多，从而从课程中获得更多。</p><p id="83e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">编程作业并不特别具有挑战性。在斯坦福的机器学习课程中，我经常会花几个小时完成每项作业。相比之下，通过这门课程，我通常可以在10-20分钟内完成编程作业。</p><p id="fb84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="oj">然而</em> </strong>，这是由顶点工程保存的，是全专精的一部分。这引出了我的最后一点:</p><blockquote class="pq"><p id="0b4f" class="pr ps it bd pt pu pv pw px py pz lu dk translated">整体明显大于部分之和。</p></blockquote><p id="d62b" class="pw-post-body-paragraph kz la it lb b lc qa ju le lf qb jx lh li qc lk ll lm qd lo lp lq qe ls lt lu im bi translated">我认为，要从本课程中获得最大的利益，最好是完成完全专业化。一旦完成一到三门课程，最后的顶点项目是真正巩固所学的一切。</p><p id="6fff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这篇评论对你有所帮助，非常感谢你读到这里！如果你对课程有任何问题，请在下面告诉我！</p><p id="5a46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谢谢，</p></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="49eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有兴趣了解IBM的可伸缩数据科学基础，我在这里写了另一篇评论！</p><div class="qf qg gp gr qh qi"><a rel="noopener follow" target="_blank" href="/a-summary-of-the-advanced-data-science-with-ibm-specialization-1-4-5caf48c011df"><div class="qj ab fo"><div class="qk ab ql cl cj qm"><h2 class="bd iu gy z fp qn fr fs qo fu fw is bi translated">对IBM可伸缩数据科学基础的回顾</h2><div class="qp l"><h3 class="bd b gy z fp qn fr fs qo fu fw dk translated">我的想法是，在IBM的高级数据中，对可伸缩数据科学基础中的关键概念进行分解…</h3></div><div class="qq l"><p class="bd b dl z fp qn fr fs qo fu fw dk translated">towardsdatascience.com</p></div></div><div class="qr l"><div class="qs l qt qu qv qr qw ks qi"/></div></div></a></div></div></div>    
</body>
</html>