<html>
<head>
<title>Feature Engineering — deep dive into Encoding and Binning techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特征工程——深入研究编码和宁滨技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-engineering-deep-dive-into-encoding-and-binning-techniques-5618d55a6b38?source=collection_archive---------7-----------------------#2020-08-26">https://towardsdatascience.com/feature-engineering-deep-dive-into-encoding-and-binning-techniques-5618d55a6b38?source=collection_archive---------7-----------------------#2020-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6254" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">特征编码和特征宁滨技术的说明</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4794c2ae83eefce10f769417da4e644e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MAr4rWj6zw0Rdo01ecZu1A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="6d9e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di">F</span>T2】特征工程是数据科学模型开发最重要的方面。原始数据集中有多种类别的要素。特征可以是文本、日期/时间、分类和连续变量。对于机器学习模型，数据集需要以数字向量的形式进行处理，以使用 ML 算法对其进行训练。</p><p id="ff86" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇文章的目的是演示特征工程技术，将分类特征转换成连续特征，反之亦然。</p><ul class=""><li id="e5af" class="md me it la b lb lc le lf lh mf ll mg lp mh lt mi mj mk ml bi translated"><strong class="la iu">功能宁滨:</strong>连续变量到分类变量的转换。</li><li id="997c" class="md me it la b lb mm le mn lh mo ll mp lp mq lt mi mj mk ml bi translated"><strong class="la iu">特征编码:</strong>分类变量到数字特征的转换。</li></ul><h1 id="20cd" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">特色宁滨:</h1><p id="c629" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated"><strong class="la iu">宁滨或离散化</strong>用于将连续或数值变量转换成分类特征。连续变量的宁滨引入了非线性，并倾向于改善模型的性能。它还可用于识别缺失值或异常值。</p><p id="3829" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">宁滨有两种类型:</p><ul class=""><li id="6092" class="md me it la b lb lc le lf lh mf ll mg lp mh lt mi mj mk ml bi translated"><strong class="la iu">无监督宁滨:</strong>等宽宁滨，等频宁滨</li><li id="8a7c" class="md me it la b lb mm le mn lh mo ll mp lp mq lt mi mj mk ml bi translated"><strong class="la iu">监督宁滨:</strong>基于熵的宁滨</li></ul><h2 id="e6b2" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">无人监管的宁滨:</h2><p id="7aee" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">无监督宁滨是一种宁滨，它将数值或连续变量转换成分类箱<strong class="la iu">，而不考虑目标类别标签</strong>。无监督宁滨分为两类:</p><h2 id="7238" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">1.等宽宁滨:</h2><p id="d7a9" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">该算法将连续变量分成几个类别，这些类别具有<strong class="la iu">相同宽度</strong>的仓或范围。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/0fe2b46ab3d18fcf145cca2f998b2812.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*3vn1Htjx1UlcSHG8Et6_pw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/426d6569127fe1d4e330d5d2b0291ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*mmSLZSO_DS1wWU-rtnhRHQ.png"/></div></figure><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="c68b" class="no ms it od b gy oh oi l oj ok">Notations,<br/>x = number of categories<br/>w = width of a category<br/>max, min = Maximum and Minimun of the list</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/5f9d4ce3675a7d4e1308920207c27698.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*mjbYS9k8tqhYxVwegN_aCw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/119c62f6b90d7293d312f91d0105a6aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*EHUbcNxyyhwAZufsn7cDtQ.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/7ec5dffce633b30fdff3a6fa4e65454e.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*Vyv_qhMP3S_5iatz5kSPDA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者图片)，使用等宽宁滨算法对连续特征“年龄”进行分类</p></figure><h2 id="14b7" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">2.等频宁滨:</h2><p id="cb69" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">该算法将数据分成具有大致相同数量的值的不同类别。数据的值被平均分配到形成的类别中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/1293d995cddaab16ca3c9a8cd8cb7b93.png" data-original-src="https://miro.medium.com/v2/resize:fit:172/format:webp/1*pWw1Hf6fTNhZtCo4nAc3jg.png"/></div></figure><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="5505" class="no ms it od b gy oh oi l oj ok">Notations,<br/>x = number of categories<br/>freq = frequency of a category<br/>n = number of values in data</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/eaff70e666e695f981b18db822f72e4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*M4nHByhd-FazhuZBt-chIQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，使用等频宁滨算法对连续特征“年龄”进行分类</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)，实现等宽宁滨，等频宁滨</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/3d13a8309820231cb720ff32bec794ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NHNyiD5eDa57trux7dvW0g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，等宽等频宁滨条形图</p></figure><h2 id="df04" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">监督宁滨:</h2><p id="354d" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">监督宁滨是一种宁滨，它将数值或连续变量转换为分类变量，同时考虑目标类别标注。选择离散化切割点时，它指的是目标类标签。基于熵的宁滨是一种监督宁滨。</p><h2 id="e45c" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">1.基于熵的宁滨；</h2><p id="d05a" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">基于熵的宁滨算法对连续或数值变量进行分类，一个容器或类别中的大多数值属于同一类标签。它计算目标类别标签的熵，并基于最大信息增益对分裂进行分类。</p><div class="ot ou gp gr ov ow"><a href="https://github.com/paulbrodersen/entropy_based_binning" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">保罗·布罗德森/基于熵的宁滨</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">这个模块实现了穷举搜索一个序列的最高熵宁滨的功能</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">github.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk ks ow"/></div></div></a></div></div><div class="ab cl pl pm hx pn" role="separator"><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq"/></div><div class="im in io ip iq"><h1 id="e208" class="mr ms it bd mt mu ps mw mx my pt na nb jz pu ka nd kc pv kd nf kf pw kg nh ni bi translated">特征编码:</h1><p id="5e5f" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated"><strong class="la iu">特征编码</strong>用于将分类特征转换成数字变量。大多数 ML 算法不能处理分类变量，因此进行特征编码是很重要的。有许多用于特征工程的编码技术:</p><h2 id="0351" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">1.标签编码:</h2><p id="77c4" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated"><strong class="la iu">标签编码</strong>是一种编码技术，通过给每个类别分配一个数值，将类别变量转换成数值变量。<strong class="la iu">标签编码可用于序数变量</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi px"><img src="../Images/4ffc13f8dc7248d48e62a1027c10da82.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*rChOTHzCbi_-b4RkHgm_Xg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，标签编码</p></figure><h2 id="ca77" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">2.序数编码:</h2><p id="fa2a" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">顺序编码是一种编码技术，通过<strong class="la iu">将原始分类变量转换为数字变量，确保变量的顺序性质得以保持。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi py"><img src="../Images/d21f37f99d47d9e2728908ab956f3194.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*5ByG1VmJdKPxKYtVTtfS9A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，序数编码</p></figure><h2 id="ee1b" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">3.频率编码:</h2><p id="e800" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">频率编码是一种通过考虑数据的频率分布将原始分类变量转换为数值变量的编码技术。这对于名义特征很有用。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pz"><img src="../Images/d194dee41f5a6d7b7bb4f9e805ff4e03.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*H5sXob8UF11pzK28kTS8VQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，频率编码</p></figure><h2 id="646d" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">4.二进制编码:</h2><p id="b699" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">二进制编码是一种编码技术，通过将类别编码为整数，然后转换为二进制代码，将原始分类变量转换为数字变量。对于具有大量类别的变量，这种方法更可取。</p><p id="b0fa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于 100 个类别变量，标签编码创建 100 个标签，每个标签对应一个类别，而二进制编码仅创建 7 个类别。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qa"><img src="../Images/5c5ef62ffc46670e2b6838dea8e2cb9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*7iGbGfLjMZUhOAZbhd6tug.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，二进制编码</p></figure><h2 id="6910" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">5.一个热门编码:</h2><p id="0ebb" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">一种热门的编码技术是将每个类别分成一列。它为一个类别创建 k 个不同的列，并用 1 替换一列，其余的列为 0。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qb"><img src="../Images/969d5cb63eb50b0153c8d65f924d5d85.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*0ZZj6C1xuya-DGmfjaVYkQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，一个热编码</p></figure><h2 id="bf41" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">6.目标均值编码:</h2><p id="4f73" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated"><strong class="la iu">均值编码</strong>是将分类变量转换为数值变量的最佳技术之一，因为它考虑了目标类别标签。基本思想是用相应目标变量的平均值代替分类变量。</p><p id="8dd1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里需要编码的分类变量是自变量(IV ),目标类别标签是因变量(DV)。</p><p id="80fe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">均值编码步骤:</strong></p><ul class=""><li id="ff3c" class="md me it la b lb lc le lf lh mf ll mg lp mh lt mi mj mk ml bi translated">选择一个类别</li><li id="3db0" class="md me it la b lb mm le mn lh mo ll mp lp mq lt mi mj mk ml bi translated">按类别分组并获得总和(= a)</li><li id="f916" class="md me it la b lb mm le mn lh mo ll mp lp mq lt mi mj mk ml bi translated">按类别分组并获得合计总数(= b)</li><li id="c58a" class="md me it la b lb mm le mn lh mo ll mp lp mq lt mi mj mk ml bi translated">该类别的数值= a/b</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qc"><img src="../Images/d00b9834cf691e5a5c40d82ccc369ff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*_CrQJbshk9WFQQNdVRLUWg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，目标意味着编码</p></figure><h2 id="eeb2" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">实施:</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)，编码器的 Python 实现</p></figure></div><div class="ab cl pl pm hx pn" role="separator"><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq"/></div><div class="im in io ip iq"><h1 id="b03c" class="mr ms it bd mt mu ps mw mx my pt na nb jz pu ka nd kc pv kd nf kf pw kg nh ni bi translated">结论:</h1><p id="9c2b" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">特征工程是一个循环过程，没有人能断定这种特征工程技术是最好的。在数据处理过程中，没有选择特定特征工程(编码或宁滨技术)的经验法则。因此，一个人需要尝试根据业务需求专注于特性工程，对每个过程进行多次尝试，并从中挑选出最好的。</p><blockquote class="qd"><p id="aa92" class="qe qf it bd qg qh qi qj qk ql qm lt dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>