<html>
<head>
<title>Analysis On Tweets Using Python and TWINT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python和TWINT分析推文</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/analysis-on-tweets-using-python-and-twint-c7e6ebce8805?source=collection_archive---------29-----------------------#2020-06-01">https://towardsdatascience.com/analysis-on-tweets-using-python-and-twint-c7e6ebce8805?source=collection_archive---------29-----------------------#2020-06-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="73d8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">情感分析，建立单词云和更多…</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ff4e4ffd23a7bfc24155c2052472d55b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*D5L9hCBnvNjjJnTk"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@yucelmoran?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">于切尔·莫兰</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="ff46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">听说过Twint吗？</p><p id="d0c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Twint是Python中内置的高级web抓取工具，它抓取web，而不是像tweepy一样通过twitter API收集数据。它是推特智能工具的缩写。您可以通过以下方式下载:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="f28a" class="ma mb it lw b gy mc md l me mf">pip3 install twint</span></pre><p id="d998" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">twint文档可以在<a class="ae ky" href="https://github.com/twintproject/twint" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="2abd" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">收集数据</h1><p id="c12b" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">在本文中，我们将使用唐纳德·特朗普自2019年初以来的推文。我们可以在命令行中使用这个简单的命令下载给定用户的tweets:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="3985" class="ma mb it lw b gy mc md l me mf">twint -u realDonaldTrump --since 2019-01-01 -o trump.csv --csv</span></pre><p id="ad0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将把2019年以来<code class="fe nc nd ne lw b">@realDonaldTrump</code>的所有推文下载到一个单独的csv文件<code class="fe nc nd ne lw b">trump.csv</code>中。</p><p id="8316" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，为了方便起见，我将csv文件转换为xls格式。让我们开始吧！</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="da08" class="ma mb it lw b gy mc md l me mf">df=pd.read_excel('trump.xls')</span><span id="f3dd" class="ma mb it lw b gy nf md l me mf">***added columns mentions, hashtags and length***<br/>***added month, year and hour columns***<br/>***added cleaned_tweetsnum_mentionsnum_hashtags***</span><span id="3ab6" class="ma mb it lw b gy nf md l me mf">df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/b936d3eeae46c0cf05b4d58c75e5e982.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PFvNCf14grPZYl7Aq8dRtg.png"/></div></div></figure><h1 id="478b" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">一些有趣的分析</h1><ul class=""><li id="2a2f" class="nh ni it lb b lc mx lf my li nj lm nk lq nl lu nm nn no np bi translated">让我们来看看每小时的平均推文长度。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/08f453be33ef9e3d3fda20cc6c42118e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qQrSU8Z1ZVAwFzU5R9PEIg.png"/></div></div></figure><p id="3174" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看起来总统的推特在一大早就很长了(凌晨3点到10点)。</p><ul class=""><li id="b5d1" class="nh ni it lb b lc ld lf lg li nr lm ns lq nt lu nm nn no np bi translated">每小时的平均提及次数。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/91468ff4cb45f5f4b93a761dd356abd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pqvteKJb7Om2iJcLkiYeWw.png"/></div></div></figure><p id="48ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">再加上那些推文的情绪又如何呢？(后面显示的情绪计算。)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/307973bd529605dce7f9721d248c7f20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YZg8EHTjAU-hxnD7lbODEw.png"/></div></div></figure><h1 id="507c" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">文本分析</h1><p id="167a" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">首先，让我们清理推文。为此，我们将创建两个函数，一个用于删除URL、提及和标签(将它们存储在单独的列中)，另一个用于清理剩余的文本(删除停用词、标点符号)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="8a7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将使用删除了内容、停用词和标点符号的推文的<code class="fe nc nd ne lw b">cleaned_tweets</code>列和删除了内容的<code class="fe nc nd ne lw b">tweet</code>列来计算情绪和主观性。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="8e92" class="ma mb it lw b gy mc md l me mf">df['cleaned_tweets']=df['tweet'].apply(lambda x: process_text(x))<br/>df['tweet']=df['tweet'].apply(lambda x: remove_content(x))</span></pre><p id="30f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们建立一个单词云来了解常用短语。</p><h2 id="5f1c" class="ma mb it bd mh ny nz dn ml oa ob dp mp li oc od mr lm oe of mt lq og oh mv oi bi translated">WordCloud</h2><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="5256" class="ma mb it lw b gy mc md l me mf"><strong class="lw iu">from</strong> <!-- -->wordcloud <strong class="lw iu">import</strong> <!-- -->WordCloud, STOPWORDS<br/><strong class="lw iu">import</strong> <!-- -->matplotlib.pyplot as plt</span><span id="cdb0" class="ma mb it lw b gy nf md l me mf">temp=' '.join(df['cleaned_tweets'].tolist())<br/>wordcloud = WordCloud(width = 800, height = 500, <br/>                background_color ='white', <br/>                min_font_size = 10).generate(temp)</span><span id="2786" class="ma mb it lw b gy nf md l me mf">plt.figure(figsize <strong class="lw iu">=</strong> <!-- -->(8, 8), facecolor <strong class="lw iu">=</strong> <!-- -->None)<br/>plt.imshow(wordcloud)<br/>plt.axis("off")<br/>plt.tight_layout(pad <strong class="lw iu">=</strong> <!-- -->0)<!-- --> <br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/6107c4ec41c935a08fceb244b0f5548d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*igO90Wi2z9UuF6fhWVTTbg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">词云</p></figure><p id="5ede" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更常用的单词/短语以更大的字体出现。</p><p id="f5ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们定义一个函数来绘制给定ngram范围内出现次数最多的n个短语。为此，我们将使用<code class="fe nc nd ne lw b">CountVectorizer</code>功能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="0d42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大部分工作已经完成，现在让我们画出常用短语。</p><ul class=""><li id="35ea" class="nh ni it lb b lc ld lf lg li nr lm ns lq nt lu nm nn no np bi translated"><strong class="lb iu">频繁出现的单字</strong></li></ul><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="871f" class="ma mb it lw b gy mc md l me mf">plot_topn(tweet_list, ngram_range=(1,1))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/603e63d2324e8c1b4975f677cdc8aa35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M5VLQ35NTUSwciRkoy_TPw.png"/></div></div></figure><ul class=""><li id="073c" class="nh ni it lb b lc ld lf lg li nr lm ns lq nt lu nm nn no np bi translated"><strong class="lb iu">频繁的二元模型</strong></li></ul><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="cc0d" class="ma mb it lw b gy mc md l me mf">plot_topn(tweet_list, ngram_range=(2,2))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/4082851f78e079ebb7a464fe6d04c477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N57Fi4GKCWaKwawbne3exQ.png"/></div></div></figure><ul class=""><li id="a681" class="nh ni it lb b lc ld lf lg li nr lm ns lq nt lu nm nn no np bi translated"><strong class="lb iu">频繁三元模型</strong></li></ul><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="f67b" class="ma mb it lw b gy mc md l me mf">plot_topn(tweet_list, ngram_range=(3,3))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/3ea02dcc4bba26d497f4d5d48515d4e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hdmVBr5mCJYvWiKOPPXdNQ.png"/></div></div></figure><p id="e75d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">瞌睡虫乔·拜登？真的吗？</p><h1 id="a739" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">提及和标签</h1><ul class=""><li id="7ca1" class="nh ni it lb b lc mx lf my li nj lm nk lq nl lu nm nn no np bi translated">提及最多的用户:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/434e39606b93a9a86fe180622734e3d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qTd13OcA8-o1BhzCEB1n-Q.png"/></div></div></figure><ul class=""><li id="ec15" class="nh ni it lb b lc ld lf lg li nr lm ns lq nt lu nm nn no np bi translated">最常用的标签:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/683c20bc5ca0ce9f1699aaddd3d292d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H0suwUW-Fc-F7tE01HmTgg.png"/></div></div></figure><h1 id="f465" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">情感分析</h1><p id="3208" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">我们使用推文专栏来分析推文的情绪和主观性。为此，我们将使用<code class="fe nc nd ne lw b">TextBlob</code>。</p><p id="bd23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给定一个输入句子，TextBlob输出一个包含两个元素的元组:<code class="fe nc nd ne lw b">(sentiment, subjectivity)</code></p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="562f" class="ma mb it lw b gy mc md l me mf">from textblob import TextBlob<br/>df['sentiment']=df['tweet'].apply(lambda x:TextBlob(x).sentiment[0])<br/>df['subject']=df['tweet'].apply(lambda x: TextBlob(x).sentiment[1])<br/>df['polarity']=df['sentiment'].apply(lambda x: 'pos' if x&gt;=0 else 'neg')</span></pre><p id="5b06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们来看看推文的情绪分布</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/d59ef88758aa4cddc69a261238c4be64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgNrEKthb1l0Kzx6wjJ6ww.png"/></div></div></figure><p id="3406" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大多数推文可能不是主观的。推文可能是事实，就像坏消息一样。让我们找出主观的推文的情绪分布。为此，让我们过滤掉<code class="fe nc nd ne lw b">subjectivity</code>大于0.5的推文，并绘制分布图。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="9195" class="ma mb it lw b gy mc md l me mf">fig=px.histogram(df[df['subject']&gt;0.5], x='polarity', color='polarity')<br/>fig.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/7ff199bd72a2b1284cf7d12e91dc65f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vixz5ExJ2_OjUcOaesDZfg.png"/></div></div></figure><p id="6e06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看起来，当只分析主观推文时，负面情绪的比例增加了。</p><p id="e617" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们来看看20个被提及最多的用户的主观推文的极性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/e5a77329c5015ca77ad7949ba2e7bd07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHXwVbLS_ju60b0ofGMzUQ.png"/></div></div></figure><h1 id="0612" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">主题建模</h1><p id="78ab" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">主题建模是一种自动分析文本数据以确定一组文档的聚类词的机器学习技术。这被称为“无监督”的机器学习，因为它不需要预先定义的标签列表或之前由人类分类的训练数据。</p><p id="f53d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用gensim LDA模型进行主题建模。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="ac97" class="ma mb it lw b gy mc md l me mf"><strong class="lw iu">#pre-process tweets to BOW</strong><br/>from gensim import corpora<br/>r = [process_text(x,stem=False).split() for x in df['tweet'].tolist()] <br/>dictionary = corpora.Dictionary(r)<br/>corpus = [dictionary.doc2bow(rev) for rev in r]</span><span id="74c9" class="ma mb it lw b gy nf md l me mf"><strong class="lw iu">#initialize model and print topics<br/></strong>from gensim import models<br/>model = models.ldamodel.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=15)<br/>topics = model.print_topics(num_words=5)<br/>for topic in topics:<br/>    print(topics[0],process_text(topic[1]))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/ef872ff48a63e765a64418144c6865b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZEfQAHuvvbU9oBOI3vtaw.png"/></div></div></figure><p id="5afb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有一些明确的主题，如弹劾审判早期阶段的主题5，包含与中国贸易协议有关的短语的主题8，以及关于他修建隔离墙的计划的主题6。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="65eb" class="ma mb it lw b gy mc md l me mf">labels=[]<br/>for x in model[corpus]:<br/>    labels.append(sorted(x,key=lambda x: x[1],reverse=True)[0][0])</span><span id="070e" class="ma mb it lw b gy nf md l me mf">df['topic']=pd.Series(labels)</span></pre><p id="4982" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">再来看话题分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/0f9bdd956cbb2fd4ce693827c15213dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jaCdq1lspc2KsE5DqfCgDQ.png"/></div></div></figure><p id="9c55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们来看看话题5和话题6的分布。</p><div class="kj kk kl km gt ab cb"><figure class="ou kn ov ow ox oy oz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/23b56cdcbca0fe69001ee1deca8ffb3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*WMP5w2zDoUOjVaj8dbZwhA.png"/></div></figure><figure class="ou kn ov ow ox oy oz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/94c446b22b5816f68941cb309486c153.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*lsd_1NMmapNQB1EaYshc9w.png"/></div></figure></div><p id="9644" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些情节是有意义的，因为在举报人投诉发布的那个月，话题5中的推文显著增加，而在特朗普计划修建隔离墙的2019年第一个月，话题6中的推文更多。</p><p id="99a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里找到更详细的分析<a class="ae ky" href="https://github.com/cotraak/Machine-Learning/blob/master/trump_tweet_analysis.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="c8ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢这篇文章，请留下你的掌声。感谢您的阅读！</p><h1 id="68ab" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">参考</h1><ol class=""><li id="ea51" class="nh ni it lb b lc mx lf my li nj lm nk lq nl lu pa nn no np bi translated">Github Twint文档:<a class="ae ky" href="https://github.com/twintproject/twint" rel="noopener ugc nofollow" target="_blank">https://github.com/twintproject/twint</a></li><li id="f919" class="nh ni it lb b lc pb lf pc li pd lm pe lq pf lu pa nn no np bi translated"><a class="ae ky" href="https://medium.com/bigpanda-engineering/exploratory-data-analysis-for-text-data-29cf7dd54eb8" rel="noopener">https://medium . com/big panda-engineering/explorative-data-analysis-for-text-data-29 cf 7 DD 54 EB 8</a></li><li id="f200" class="nh ni it lb b lc pb lf pc li pd lm pe lq pf lu pa nn no np bi translated"><a class="ae ky" href="https://medium.com/@b.terryjack/nlp-pre-trained-sentiment-analysis-1eb52a9d742c" rel="noopener">https://medium . com/@ b . terry jack/NLP-预训练-情绪-分析-1eb52a9d742c </a></li></ol></div></div>    
</body>
</html>