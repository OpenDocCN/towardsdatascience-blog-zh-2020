<html>
<head>
<title>Why you may be getting low test accuracy: try Kolmogorov-Smirnov</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么你可能得到较低的测试精度:试试Kolmogorov-Smirnov</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-you-may-be-getting-low-test-accuracy-try-this-simpstatistical-tests-30585b7ee4fa?source=collection_archive---------53-----------------------#2020-05-18">https://towardsdatascience.com/why-you-may-be-getting-low-test-accuracy-try-this-simpstatistical-tests-30585b7ee4fa?source=collection_archive---------53-----------------------#2020-05-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="be24" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Kolmogorov-Smirnov帮助比较训练集和测试集的分布。首先使用Mahalanobis进行单词嵌入。</h2></div><p id="2356" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/why-you-may-be-getting-low-test-accuracy-try-this-quick-way-of-comparing-the-distribution-of-the-9f06f5a72cfc">在之前的一篇文章中，</a>我描述了一个当你获得高训练分数但低测试分数时可以尝试的巧妙技巧。这个想法是，也许你的测试集与训练集有不同的分布，你可以通过一点(更多)机器学习的帮助，实际上知道是否是这种情况。</p><p id="9017" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在文章的最后，我提到这个问题也可以通过统计测试来解决:主要是Kolmogorov-Smirnov统计。它是如何工作的？</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="8485" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Kolmogorov-Smirnov统计检验(所谓的“零”)假设，即从相同的<strong class="kh ir">连续</strong>分布中抽取两个独立的(数字)样本。它在<a class="ae lb" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html#scipy.stats.ks_2samp" rel="noopener ugc nofollow" target="_blank"> SciPy </a>中有一个Python实现。</p><p id="9188" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们试一试。我们首先将数据非随机分为训练集和测试集，因此我们可以尝试Kolmogorov-Smirnov测试:</p><figure class="lj lk ll lm gt ln"><div class="bz fp l di"><div class="lo lp l"/></div></figure><p id="86ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集包含列<strong class="kh ir"> sepal_length </strong>、<strong class="kh ir"> sepal_width </strong>、<strong class="kh ir"> petal_length </strong>和<strong class="kh ir"> petal_width </strong>。这可以通过运行以下命令来检查:</p><pre class="lj lk ll lm gt lq lr ls lt aw lu bi"><span id="b9f8" class="lv lw iq lr b gy lx ly l lz ma">X.columns</span></pre><p id="b6fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那我们现在怎么办？Kolmogorov-Smirnov试验必须在每个连续柱上分别进行。例如，让我们在sepal_width_column上进行:</p><pre class="lj lk ll lm gt lq lr ls lt aw lu bi"><span id="6c87" class="lv lw iq lr b gy lx ly l lz ma">stats.ks_2samp(X_train.sepal_length, X_test.sepal_length)</span></pre><p id="44de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该行比较了<strong class="kh ir"> X_train.sepal_length </strong>和<strong class="kh ir"> X_test.sepal_length </strong>的分布。它们是相同的吗？</p><p id="1250" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们得到以下输出:</p><pre class="lj lk ll lm gt lq lr ls lt aw lu bi"><span id="c359" class="lv lw iq lr b gy lx ly l lz ma">Ks_2sampResult(<br/>statistic=<strong class="lr ir">0.5511895215183106</strong>, pvalue=<strong class="lr ir">9.307408288528052e-09</strong><br/>)</span></pre><p id="ccc2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">统计值</strong>给了我们两个分布之间的<strong class="kh ir">距离</strong>的概念。对于那些稍微了解统计学的人来说，它无非是经验累积分布函数之间的距离的上确界:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/d78bd4d26aa741a8489f143ce7e44436.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*SNNmgwVT8RAKPCIjtmO-kA.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">来源:<a class="ae lb" href="https://commons.wikimedia.org/wiki/File:KS2_Example.png#mw-jump-to-license" rel="noopener ugc nofollow" target="_blank">维基百科</a> (CC0)</p></figure><p id="e6af" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基本上，这个值越大，分布的差异就越大。在我们的例子中，0.55是一个很大的数字，因为ECDF输出0到1之间的<em class="mi">概率值。这是有意义的:如果你检查我们如何创建<strong class="kh ir"> X_train </strong>和<strong class="kh ir"> X_test </strong>，我们让参数shuffle在分割期间为假，以模拟数据的非随机分割。</em></p><p id="7474" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一方面，<strong class="kh ir"> pvalue </strong>给了我们一个统计检验的重要性的概念。它告诉你我们应该有多信任这个测试。在这种情况下，<strong class="kh ir"> 9.3 e09 </strong>是一个真正接近于零的值——e09的意思是乘以10^(-9)——所以我们处于安全区(通常如果低于0.05，甚至0.1就足够了，这取决于上下文)。</p><p id="6f0f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了结束这一部分，让我们看看如果随机选择训练和测试集会发生什么(在我们的例子中，删除<strong class="kh ir"> shuffle=False </strong>选项就足够了)。所以，把这一行改成:</p><pre class="lj lk ll lm gt lq lr ls lt aw lu bi"><span id="548e" class="lv lw iq lr b gy lx ly l lz ma">#We remove the shuffle=False option and add a specific random_state so that you get the same random splitX_train, X_test, y_train, y_test = train_test_split(<br/> X, y, test_size=0.33<strong class="lr ir">, random_state = 42</strong>)</span><span id="570c" class="lv lw iq lr b gy mj ly l lz ma">stats.ks_2samp(X_train.sepal_length, X_test.sepal_length)</span></pre><p id="9480" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们得到以下结果:</p><pre class="lj lk ll lm gt lq lr ls lt aw lu bi"><span id="da45" class="lv lw iq lr b gy lx ly l lz ma">Ks_2sampResult(statistic=<strong class="lr ir">0.16813686180165732</strong>, pvalue=<strong class="lr ir">0.3401566277318967</strong>)</span></pre><p id="c959" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 0.168 </strong>的统计值表明我们可能有一个稍微不同的分布，但是我们不能拒绝零假设，即分布实际上是相同的，因为<strong class="kh ir">p值</strong>不够小(它应该小于0.1)。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="c01a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">太好了。这让我们可以比较列数据的分布。但只是一维数据。如果我们处理的是不能真正拆分成列的矢量数据，会发生什么？例如，如果我们的数据集由NLP单词嵌入组成呢？在这种情况下，列是非独立的，每个列本身没有太多意义。</p><p id="8458" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好吧，同样，我们可以使用我在文章开头提到的这个简洁的<a class="ae lb" href="http://Ks_2sampResult(statistic=0.16813686180165732, pvalue=0.3401566277318967)" rel="noopener ugc nofollow" target="_blank">机器学习技巧</a>，它非常适合矢量数据的分布。正如帖子所解释的，基本想法是<em class="mi">尝试</em>通过机器学习模型将数据点分类为训练或测试，例如随机森林。如果你成功了，这意味着集合有不同的分布。换句话说，你<em class="mi">不应该</em>能够成功。</p><p id="3321" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还有其他方法。您可以转换数据，使其成为一维数据。例如，您可以计算向量的长度，然后将Kolmogorov-Smirnov应用于的<em class="mi">。当然，在任何这些转换过程中，您都会丢失信息，因此，如果测试结果告诉您两个数据集具有相同的分布，您不应该过于相信测试结果。</em></p><p id="ae79" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个不仅仅是计算向量长度的简单转换是计算数据的每一对数据点的<a class="ae lb" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.mahalanobis.html" rel="noopener ugc nofollow" target="_blank"> Mahalanobis距离</a>。当然，您可以(也应该)尝试进行多种转换，这样您就可以从不同的角度测试您的数据。</p><p id="ea70" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Mahalanobis距离背后的一个可能的直觉是，它计算2个向量点之间的距离，就像我们都知道并喜爱的正常欧几里德距离(又名，尺子)，但<em class="mi">知道</em>这2个点是属于特定分布的随机向量。</p><p id="34f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">事实上，当计算两个向量点之间的马氏距离时，你必须通过一个叫做<em class="mi">协方差矩阵的东西。</em>这个对象是您用来描述您正在使用的发行版的。</p><p id="11a9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个协方差矩阵是从分布中计算出来的，并且在Python中有一个实现。现在，假设我们正在处理一个训练集X和一个测试集Y。我们不应该计算两个不同的协方差矩阵(一个用于X，一个用于Y ),但我们需要处理X和Y的<strong class="kh ir">联合</strong>的协方差矩阵。请相信我，否则，您将丢失更多信息，并且无法检测到分布中的某些差异(用数学术语来说，您将无法检测到分布的……协方差中的差异)。)</p><figure class="lj lk ll lm gt ln"><div class="bz fp l di"><div class="lo lp l"/></div></figure><p id="a6e2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们得到以下结果:</p><pre class="lj lk ll lm gt lq lr ls lt aw lu bi"><span id="9265" class="lv lw iq lr b gy lx ly l lz ma"><br/>Ks_2sampResult(statistic=<strong class="lr ir">0.13218600000000003</strong>,<br/> pvalue=<strong class="lr ir">0.0</strong>)</span></pre><p id="78c8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以分布略有不同，这是肯定的<em class="mi">—</em>p值很低，四舍五入为零。</p><p id="7590" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们在两种情况下使用完全相同的分布，我们可能会发现如下数字:</p><pre class="lj lk ll lm gt lq lr ls lt aw lu bi"><span id="c060" class="lv lw iq lr b gy lx ly l lz ma">Ks_2sampResult(statistic=<strong class="lr ir">0.008912000000000031</strong>, <br/>pvalue=<strong class="lr ir">6.42297518848271e-35</strong>)</span></pre><p id="2367" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(当然，有随机性，所以这些玩具的例子你可能会得到不同的结果)。但是，检查一下<strong class="kh ir">统计值</strong>与之前相比有多低。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="2be0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总而言之:</p><ul class=""><li id="9de9" class="mk ml iq kh b ki kj kl km ko mm ks mn kw mo la mp mq mr ms bi translated">有时，模型中的低测试分数可能是因为测试数据与训练数据的分布不同。</li><li id="7806" class="mk ml iq kh b ki mt kl mu ko mv ks mw kw mx la mp mq mr ms bi translated">您可以通过对数据集的每一列应用Kolmogorov-Smirnov统计测试来检查这一点。Python中有一个实现，你也可以借用我的代码示例。</li><li id="0a8d" class="mk ml iq kh b ki mt kl mu ko mv ks mw kw mx la mp mq mr ms bi translated">如果你正在处理具有非独立列的数据集，比如单词嵌入，你<strong class="kh ir">不应该</strong>使用Kolmogorov-Smirnov。你应该首先转换你的数据，使它是一维的。例如，你可以计算所有向量的范数，但是如果你使用马氏距离会更好。对此也有一个Python实现，您可以再次借用我的代码示例。</li></ul><p id="b6ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">黑客快乐！</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="f3ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mi">学到了什么？单击👏说“谢谢！”并帮助他人找到这篇文章。</em></p></div></div>    
</body>
</html>