<html>
<head>
<title>Price Prediction using Machine Learning Regression — a case study</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于机器学习回归的价格预测——案例研究</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mercari-price-suggestion-97ff15840dbd?source=collection_archive---------0-----------------------#2020-03-30">https://towardsdatascience.com/mercari-price-suggestion-97ff15840dbd?source=collection_archive---------0-----------------------#2020-03-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e049" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">电子商务中的人工智能</h2><div class=""/><div class=""><h2 id="8231" class="pw-subtitle-paragraph ka jc it bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated"><em class="jz"> Mercari价格建议挑战</em></h2></div><blockquote class="ks kt ku"><p id="549d" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">这篇文章详细描述了我解决回归问题的方法，这也是一个流行的Kaggle竞赛。希望你觉得有用并喜欢阅读:)</p></blockquote><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/7a55a670caa3ba95bb50b6d42fea0baa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9pnItU2ZbID4PdnTVt2FzQ.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">图片来自<a class="ae mi" href="https://pixabay.com/users/coffeebeanworks-558718/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3124413" rel="noopener ugc nofollow" target="_blank">咖啡豆</a>来自<a class="ae mi" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3124413" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="5ebe" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi mm translated">人工智能是当今所有主要电子商务公司不可或缺的一部分。随着过去二十年信息产业的发展和人工智能领域的广泛研究，企业已经开始探索使用最先进的机器学习算法和深度神经网络来自动化各种活动的方法。许多IT巨头和初创企业已经在这一领域迈出了一大步，并拥有专门的团队和资源来研发尖端的人工智能应用。今天的在线零售平台广泛由人工智能驱动的算法和应用程序驱动。从仓库的库存管理和质量检查到网站上的产品推荐和销售统计数据，所有活动都在不同程度上使用了机器学习。</p><h1 id="4b68" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated"><strong class="ak">业务问题和挑战</strong></h1><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nn"><img src="../Images/73a734b7dcb2f3cd265153081d54b11c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DS4wgHFOH2ehCo4s_b8mIw.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">图片来源:<a class="ae mi" href="https://www.kindpng.com/userpngs/5765/" rel="noopener ugc nofollow" target="_blank"> Movas Global </a>通过<a class="ae mi" href="https://www.kindpng.com/" rel="noopener ugc nofollow" target="_blank"> KindPNG </a></p></figure><p id="46b5" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">Mercari是日本最大的社区购物网站。为了实现一个节约使用全球资源、人人都能过上富裕生活的社会，该公司在日本和美国开发了一个跳蚤市场应用程序“Mercari ”,让个人能够轻松、安全地买卖商品。Mercari面临的挑战是建立一种算法，在其应用程序上自动向卖家建议正确的产品价格。</p><p id="34e0" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">预测产品的价格是一项艰巨的挑战，因为非常相似的产品有微小的差异，如不同的品牌名称、附加规格、质量、产品需求等。会有非常不同的价格。例如，其中一件毛衣售价335美元，另一件售价9.99美元。你能猜出哪个是哪个吗？</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi no"><img src="../Images/5b2fa522e2c0bc4fbc9d7a2061584cb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9mfr3JxZl8B-z6uC.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">图片来源:<a class="ae mi" href="https://www.kaggle.com/c/mercari-price-suggestion-challenge/overview" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/mercari-price-suggestion-challenge/overview</a></p></figure><p id="5df5" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">当产品种类繁多时，价格预测变得更加困难，这在大多数在线购物平台上都很常见。Mercari的卖家可以在应用程序上列出几乎任何东西。预测在线平台上几乎所有商品的价格都极具挑战性。</p><blockquote class="ks kt ku"><p id="1c8c" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated"><strong class="ky jd">让我们从机器学习的角度来看这个问题。</strong></p></blockquote><h1 id="aed2" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">ML问题</h1><p id="2eec" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">Mercari提供了用户输入的产品文本描述，包括产品类别名称、品牌名称和商品状况等细节。使用这些数据，我们必须想出一个模型，尽可能准确地预测Mercari上列出的产品的价格。这看起来像一个标准的回归问题。</p><h1 id="98e4" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">性能指标和业务限制</h1><p id="d5f3" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">我们必须有一个尺度来衡量我们的模型性能的好坏。在机器学习术语中，我们将这种尺度称为性能度量或简称为度量。有各种度量来测量回归模型的性能，<em class="kx">例如平均绝对误差、均方误差、均方对数误差、</em> <em class="kx">最大残差、中值绝对误差、决定系数(R)等</em>。<br/>对于这个问题，<em class="kx"> Kaggle </em>使用<strong class="ky jd">均方根对数误差(RMSLE) </strong>。RMSLE越小，我们的模型越好。RMSLE的计算公式为</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/1fd119eb86a6eaa624d5e1f50e801f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*J2t6jvpkgXNUkbgS7DyRgQ.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">图片来源:<a class="ae mi" href="https://www.kaggle.com/c/mercari-price-suggestion-challenge/overview/evaluation" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/mercari-price-suggestion-challenge/overview/evaluation</a></p></figure><ul class=""><li id="93c1" class="nv nw it ky b kz la lc ld mj nx mk ny ml nz lr oa ob oc od bi translated">最准确地预测价格是我们的首要商业目标。</li><li id="b65e" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">在这个问题中没有低延迟限制。一旦产品在应用程序上列出，我们不需要立即建议它的价格。然而，我们也不能花几个小时或几天来预测价格。</li></ul><h1 id="f494" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">现有方法</h1><ol class=""><li id="486c" class="nv nw it ky b kz np lc nq mj oj mk ok ml ol lr om ob oc od bi translated"><a class="ae mi" href="https://www.kaggle.com/c/mercari-price-suggestion-challenge/discussion/50252" rel="noopener ugc nofollow" target="_blank"> <strong class="ky jd">第18位解</strong> </a> <strong class="ky jd"> : </strong>总体思路是先训练一个FM_FTRL模型，再训练一个LightGBM模型，用两者的系综得到最终的预测。</li><li id="03ba" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr om ob oc od bi translated"><a class="ae mi" href="https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s" rel="noopener ugc nofollow" target="_blank"><strong class="ky jd">Mercari Golf:0.3875 CV in 75 LOC，1900s</strong></a><strong class="ky jd">:</strong>4个MLP模型的集合，每个模型具有相同的架构，但显然在2个不同的数据集上进行训练。</li></ol><blockquote class="ks kt ku"><p id="12a3" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated"><strong class="ky jd">了解了约束、业务目标和我们需要解决的问题后，是时候动手了。</strong></p></blockquote><h1 id="6cdf" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">1.数据概述</h1><p id="8127" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">数据可以从<a class="ae mi" href="https://www.kaggle.com/c/mercari-price-suggestion-challenge/data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>竞赛页面下载。有两个文件<em class="kx"> train.tsv </em>和<em class="kx"> test.tsv </em>和一个Kaggle提交模板<em class="kx"> sample_submission.csv. </em>解压缩后数据总大小为1.03 GB。</p><p id="dae5" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">这些文件由产品列表组成。这些文件用制表符分隔。<em class="kx"> train.tsv </em>有1482535行，<em class="kx"> test.tsv </em>有3460725行。训练和测试文件都有以下数据字段</p><ul class=""><li id="399a" class="nv nw it ky b kz la lc ld mj nx mk ny ml nz lr oa ob oc od bi translated"><code class="fe on oo op oq b">train_id</code>或<code class="fe on oo op oq b">test_id</code> -列表的id</li><li id="5701" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><code class="fe on oo op oq b">name</code> -清单的标题</li><li id="8582" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><code class="fe on oo op oq b">item_condition_id</code> -卖方提供的物品的状况</li><li id="3542" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><code class="fe on oo op oq b">category_name</code> -清单的类别</li><li id="a0c8" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><code class="fe on oo op oq b">brand_name</code></li><li id="78e3" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><code class="fe on oo op oq b">price</code> -物品的销售价格。这是我们将要预测的目标变量。单位是美元。该列在<code class="fe on oo op oq b">test.tsv</code>中不存在，因为这是我们将要预测的。</li><li id="c763" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><code class="fe on oo op oq b">shipping</code> - <strong class="ky jd"> 1 </strong>如果运费由卖方支付，0 如果由买方支付</li><li id="5959" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><code class="fe on oo op oq b">item_description</code> -物品的完整描述</li></ul><blockquote class="ks kt ku"><p id="181f" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">数据表中的<strong class="ky jd">行</strong>称为<strong class="ky jd">数据点</strong>，而<strong class="ky jd">列</strong>称为<strong class="ky jd">特征/变量</strong>。在这篇博客中，我将交替使用<strong class="ky jd">行</strong>和<strong class="ky jd">数据点</strong>这两个词。与<strong class="ky jd">栏</strong>和<strong class="ky jd">特征/变量相同。</strong></p></blockquote><p id="9251" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">以下是来自训练数据的样本。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi or"><img src="../Images/b779ea39be824c057533d40f1aaecb4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oov2__NYfUV0DnwMZLq71g.png"/></div></div></figure><p id="b5b1" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">我们看到数据中有一些<em class="kx">空值</em> (NaN)。我们会用<em class="kx">‘失踪’来代替这些。</em>同样，我们将列<code class="fe on oo op oq b">category_name </code>中的三个值的列表拆分成三个新列<code class="fe on oo op oq b">gencat_name, subcat1_name, subcat2_name</code>。<em class="kx">例如，一个带有category_name= </em> <strong class="ky jd"> <em class="kx">【男士、上衣、t恤】</em> </strong> <em class="kx">的数据点会有gencat_name= </em> <strong class="ky jd"> <em class="kx">男士</em> </strong> <em class="kx">，subcat1_name= </em> <strong class="ky jd"> <em class="kx">上衣</em> </strong> <em class="kx">，以及subcat2_name= </em> <strong class="ky jd"> <em class="kx"> T恤</em> </strong> </p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><h1 id="5ff6" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">2.探索性数据分析</h1><p id="2e87" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">让我们从一个机器学习工程师的角度来看看训练数据，看看我们是否能得出一些有用的推论。这将使我们对解决问题的方法有一个合理的想法。</p><h2 id="3555" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">2.1.基础EDA:分析训练数据列</h2><p id="89ea" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated"><strong class="ky jd">名称</strong></p><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="6822" class="ou mw it oq b gy pj pk l pl pm"><strong class="oq jd">train.name.describe()</strong></span><span id="c737" class="ou mw it oq b gy pn pk l pl pm">count     1481661<br/>unique    1224596<br/>top        Bundle<br/>freq         2232<br/>Name: name, dtype: object</span></pre><p id="81a6" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">原始数据(预处理前)中有1，224，596个唯一的产品名称。最常见的产品名称是<em class="kx">“Bundle”、</em>，出现在2232个数据点中。</p><p id="6940" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd">项目条件标识</strong></p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi po"><img src="../Images/25148d4a1a3dedefadb9c0a75384ef6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*jwBU49bKDnRXvoNQvHECjQ.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><strong class="bd pp">不同项目条件下的产品数量</strong></p></figure><p id="c94c" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">大多数物品处于<em class="kx">状态1</em>T42状态。很少有项目处于<em class="kx">状态5。</em></p><p id="9fa5" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd">品牌名称</strong></p><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="1b26" class="ou mw it oq b gy pj pk l pl pm"><strong class="oq jd">train.brand_name.describe()</strong></span><span id="70c4" class="ou mw it oq b gy pn pk l pl pm">count     1481661<br/>unique       4808<br/>top       missing<br/>freq       632336<br/>Name: brand_name, dtype: object</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/6c3e27963e62b4b03fc136e1264b1322.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*lZzehKTDd8ubiQ1EWfYCFQ.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><strong class="bd pp">按产品数量排名的前15大品牌</strong></p></figure><p id="6729" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><em class="kx"> brand_name </em>缺失大量(42.68 %)数据点。</p><p id="38a0" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd"> gencat_name </strong></p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/3dfa685f2481192e48b0ebc964b6bcdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*8ZgtyaU84CuQqQIo3e5OSA.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><strong class="bd pp">产品类别计数</strong></p></figure><ul class=""><li id="d849" class="nv nw it ky b kz la lc ld mj nx mk ny ml nz lr oa ob oc od bi translated">这些产品分布在10个大类中。这一栏对于一些产品是空白的，这些已经被放入一个单独的类别<em class="kx">中不见了。</em></li><li id="7df6" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">大量的产品属于女性产品。这可能是因为通常情况下，女性比男性更倾向于购物。</li><li id="242a" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">6314个数据点，即0.43 %的列车数据缺少gencat_name 。</li></ul><p id="08b3" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd"> subcat1_name，subcat2_name </strong></p><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="5f21" class="ou mw it oq b gy pj pk l pl pm"><strong class="oq jd">train.subcat1_name.describe()         train.subcat2_name.describe()</strong></span><span id="bb50" class="ou mw it oq b gy pn pk l pl pm">count              1481661            count                  1481661<br/>unique                 114            unique                     871<br/>top       Athletic Apparel            top    Pants, Tights, Leggings<br/>freq                134321            freq                     60152</span></pre><p id="c7d2" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">除了10个大类之外，还有114个产品子类，这些产品又可能属于871个子类。简而言之，<em class="kx"> subcat1_name </em>从更广的意义上讲述了物品的类别，而<em class="kx"> subcat2_name </em>则更深入一层，给出了关于物品具体是什么的更多细节。回想一下示例<strong class="ky jd"> <em class="kx">【男士、上衣、t恤】</em> </strong> <em class="kx"> <br/> </em>下图显示了按商品数量排列的前15个子类别。</p><div class="lt lu lv lw gt ab cb"><figure class="ps lx pt pu pv pw px paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><img src="../Images/7fc3293488fa0851e9b037755e396f11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*Ewpa87QE3b68IK0Ed9astQ.png"/></div></figure><figure class="ps lx py pu pv pw px paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><img src="../Images/945caad0147fabfff9541db36f545632.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*TsgQE-4HC1r1gQmlB8BUHQ.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk pz di qa qb translated"><strong class="bd pp">属于不同子类别的产品数量</strong></p></figure></div><p id="8e6c" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd">价格</strong></p><p id="46fe" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">这是我们训练数据中的目标变量或“y”。我们需要对测试数据进行预测。它的价值范围很广，从3美元到2009美元不等。然而，大多数商品的价格都低于200美元，正如下面的图表和百分位值所示。</p><div class="lt lu lv lw gt ab cb"><figure class="ps lx qc pu pv pw px paragraph-image"><img src="../Images/24bb2d2ac0e1c1970bf178120ce4371a.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*4HiR7DiEdQqfmwZB4VxK5g.png"/></figure><figure class="ps lx qd pu pv pw px paragraph-image"><img src="../Images/b37715f6bd9c0a46a7342fc507671028.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*9lJYpZ7EKPqyDbUFJOD19A.jpeg"/><p class="me mf gj gh gi mg mh bd b be z dk qe di qf qb translated"><strong class="bd pp">价格分布:PDF </strong>(左)<strong class="bd pp">、箱线图</strong>(右)</p></figure></div><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="5239" class="ou mw it oq b gy pj pk l pl pm">0 percentile value is 3.0<br/>10 percentile value is 7.0<br/>20 percentile value is 10.0<br/>30 percentile value is 12.0<br/>40 percentile value is 14.0<br/>50 percentile value is 17.0<br/>60 percentile value is 20.0<br/>70 percentile value is 26.0<br/>80 percentile value is 34.0<br/>90 percentile value is 51.0<br/>100 percentile value is  2009.0</span></pre><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="37ee" class="ou mw it oq b gy pj pk l pl pm">90 percentile value is 51.0<br/>91 percentile value is 55.0<br/>92 percentile value is 58.0<br/>93 percentile value is 62.0<br/>94 percentile value is 67.0<br/>95 percentile value is 75.0<br/>96 percentile value is 85.0<br/>97 percentile value is 99.0<br/>98 percentile value is 122.0<br/>99 percentile value is 170.0<br/>100 percentile value is  2009.0</span></pre><ul class=""><li id="74ba" class="nv nw it ky b kz la lc ld mj nx mk ny ml nz lr oa ob oc od bi translated">97%的数据点价格低于100美元。</li><li id="a711" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">极少数(仅1%)数据点的价格超过170美元。</li></ul><h2 id="c626" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">2.2.单变量分析:特征<strong class="ak">(列)</strong>和目标变量‘y’之间的相关性</h2><p id="d7ff" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">让我们根据不同数据列的值来探究商品价格是否有任何趋势。这将有助于我们决定哪些列在确定商品价格时比其他列更有用。</p><p id="77b6" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd">价格随项目条件的变化</strong></p><p id="2e5d" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">我用简单的箱线图来观察一个物品的价格是如何随着物品的状况而变化的。<br/>注意，在箱线图中，方框的下边界表示25ᵗʰ百分位，上边界表示75ᵗʰ百分位，方框内的线表示50ᵗʰ百分位或中位数。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi qg"><img src="../Images/7956a9123432d3ff9edafc6ba316b87d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a5hzI8DE1Zc2_Z6iS1Y6FQ.png"/></div></div></figure><ul class=""><li id="c8ac" class="nv nw it ky b kz la lc ld mj nx mk ny ml nz lr oa ob oc od bi translated">根据物品的情况，价格会有轻微的变化。</li><li id="6283" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">当我们从条件1到条件4时，中间价格下降。</li><li id="319a" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">条件5中的项目似乎有更高的价格，可能是因为它们是昂贵的项目，如电子产品。</li></ul><p id="9280" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd">价格随项目类别(gencat_name)的变化</strong></p><p id="56d9" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">观察下图中各种类别的箱线图和平均价格，我们可以说属于不同产品类别的商品价格存在一些差异。</p><div class="lt lu lv lw gt ab cb"><figure class="ps lx qh pu pv pw px paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><img src="../Images/5ceb8313161e14ca189a640c00aa70b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*NIV9nbRSWrUeDMVxd9X-GA.png"/></div></figure><figure class="ps lx qi pu pv pw px paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><img src="../Images/8a3f83580bd351b8ca23c6d102ff4ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*1GRl0hVX5iEXDkQxao1dlQ.png"/></div></figure></div><p id="3907" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd">价格随项目子类别(subcat1_name)的变化</strong></p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi qj"><img src="../Images/39f1d9c1a4532b6ec341ce78179adf77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gnDpSk1GAUI7asMIX3_SFA.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><strong class="bd pp">属于不同子类别的项目的中间价格</strong></p></figure><p id="197c" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">某些类别产品的价格差异很大。例如，属于<em class="kx">电脑、平板电脑、照相机、摄影、婴儿车、乐器、</em>等的物品。与属于<em class="kx">纸制品、儿童、办公用品、交易卡、</em>等的物品相比是昂贵的。</p><blockquote class="ks kt ku"><p id="72bf" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">这表明类别和子类别将成为决定商品价格的重要因素。</p></blockquote><h1 id="8c5e" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">3.清理数据:预处理</h1><h2 id="3e7e" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated"><strong class="ak"> 3.1。预处理文本特征</strong></h2><p id="b894" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">我已经做了一些基本的文本预处理，如删除非字母数字字符，正则表达式，停用词等。从<em class="kx">名称</em>和<em class="kx">项目_描述</em>。代码如下。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><h2 id="a886" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">3.2.预处理类别</h2><p id="cb5a" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">这类似于文本预处理。我已经删除了空格，并将符号' &amp; '(和)替换为' _ '(下划线)。我做这种清理是为了获得精确的一键分类编码，这将在特征部分解释。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><h2 id="e92e" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">3.3.预处理价格:删除无效条目</h2><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="891c" class="ou mw it oq b gy pj pk l pl pm">Removed 874 rows</span></pre><h1 id="a240" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">4.从数据中提取特征</h1><p id="f2ee" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">机器只理解数字，它不直接理解我们人类可以阅读的字母或文本。这意味着我们需要将文本和分类数据转换成数字。这个过程被称为特征提取或特征化。有几种与不同类型的数据相关的特征提取技术，我们将在本节中看到其中的一些。</p><h2 id="d1c9" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">4.1.手工制作的特征:特征工程</h2><p id="6178" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">基于我的直觉和对现有方法的研究，我提出了以下特征，我认为这些特征在确定一件物品的价格时会很有用。使用这些特性没有标准规则，这些纯粹是基于直觉的想法，可能因问题而异。因此，这些被称为手工制作的特征或工程特征。<br/>下表提供了特性的名称。描述这些特性的含义及其计算方式。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi qk"><img src="../Images/b33dce02fd0da1cac51ede444c84926a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*OZieLVm8IGih-YjGi4coqw.png"/></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ql"><img src="../Images/2fde05001e680526b7efea5819e047a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*RI95Mp2-Ydq0e1vwgN5kKg.png"/></div></figure><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi qk"><img src="../Images/5f9d1d140ad39db1c2607dc060892dea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*UHgkc1e5YirzcqDjlWrNFQ.png"/></div></figure><blockquote class="ks kt ku"><p id="eb75" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">我们来看看上面的功能是不是真的有用。</p></blockquote><p id="7edf" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd">对一些工程特征的单变量分析</strong></p><p id="253b" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">使用seaborn regplot绘制了以下图，该图试图拟合一个简单的线性模型，并绘制了单变量(特征与目标)散点图上的拟合直线/平面方程。</p><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="1edf" class="ou mw it oq b gy pj pk l pl pm">example code:<br/>sns.regplot(x=’brand_mean_price’, y=’price’, data=train,<br/>            scatter_kws={‘alpha’:0.3}, line_kws={‘color’:’orange’})</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi qm"><img src="../Images/149bc6ebc25715304ba8fb0e6ec56448.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S7kv4fVqYsFxeTh9z1ctug.png"/></div></div></figure><blockquote class="ks kt ku"><p id="e480" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">诸如<strong class="ky jd"> brand_mean_price、brand_median price、subcat2_mean_price、subcat2_median_price </strong>等特征显示出强烈的线性趋势。因此，它们在确定商品价格时似乎是有用的。</p></blockquote><h2 id="64e1" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">4.2.训练，交叉验证的测试分割</h2><p id="0e7b" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">出于交叉验证的目的(检查训练的模型是否在看不见的数据上工作良好)，我将我们的数据以90:10的比例分成train和cv。我将在列车上训练我们的模型，并在cv上验证它们。<br/> <em class="kx">注意，已经使用NumPy的log1p()函数将目标变量price转换为对数标度。这样做是为了我们可以使用均方根误差作为度量，而不是显式定义复杂的度量RMSLE。(因为RMSLE只不过是对数值的RMSE)</em></p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="9c20" class="ou mw it oq b gy pj pk l pl pm">Train size: (1332967, 58), CV size: (148108, 58), Test size: (3460725, 58)</span></pre><h2 id="996b" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">4.3.将分类特征转换为数字:一键编码</h2><p id="c185" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">一键编码是一种矢量化方案，其中分类变量中的每个类别都被转换为长度等于数据点数的向量。对于属于与向量相对应的类别的每个数据点，向量包含值1，否则包含0。为了更好地理解，请看下面的例子。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/3dfe89e91d460e71069e70de58f3f9f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/0*Tkysw5xDDW-qXgvp.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">图片来源:<a class="ae mi" href="https://www.kaggle.com/dansbecker" rel="noopener ugc nofollow" target="_blank"> DanB </a> via <a class="ae mi" href="https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding" rel="noopener ugc nofollow" target="_blank"> Kaggle </a></p></figure><p id="17b7" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">我已经将所有分类变量(<em class="kx"> brand_name，gencat_name，subcat1_name，subcat2_name </em>)转换为它们的独热编码向量。示例代码如下所示:</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><blockquote class="ks kt ku"><p id="b48f" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">请注意，分类变量<strong class="ky jd"> item_condition_id </strong>和<strong class="ky jd"> shipping </strong>已经包含数值，无需将其转换为向量。</p></blockquote><h2 id="9173" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">4.4.将文本特征转换为数字:TF-IDF矢量器</h2><p id="4cc6" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">TF-IDF(术语频率-逆文档频率)是一种统计度量，用于评估单词与文档集合中的文档的相关程度。这是通过将两个度量相乘来实现的:一个单词在一个文档中出现的次数，以及该单词在一组文档中的逆文档频率。你可以在这里阅读更多关于TF-IDF和它的数学细节。</p><p id="af95" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">在计算语言学和概率领域中，一个<strong class="ky jd"> <em class="kx"> n </em> -gram </strong>是来自给定文本或语音样本的<em class="kx"> n </em>项的连续序列。这些项目可以是音节、字母、单词等。这取决于应用(在我们的例子中是单词)。尺寸为1的<em class="kx"> n </em>克称为“一克”，尺寸为2的称为“二克”，依此类推。</p><p id="ab2c" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">我已经将<em class="kx"> name </em>和<em class="kx"> item_description </em>编码成一元、二元和三元的TF-IDF向量。请注意，一起使用1，2，3-gram将导致TF-IDF矢量器的字典中有大量的单词，并且使用所有这些单词将导致非常高维的向量。为了避免这种情况，我将<em class="kx">名称</em>的维度数量限制为<strong class="ky jd"> 250k </strong>，将<em class="kx">项目_描述</em>向量的维度数量限制为<strong class="ky jd"> 500k </strong>。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><h1 id="de4b" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">5.为模型准备数据</h1><h2 id="60be" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">5.1.数字特征的列规范化</h2><p id="9b16" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">规范化的主要目的是将不同列中的数字数据缩小到相同的比例，以便模型不会因少数列中的巨大差异而出现偏差。我在这里使用了最小-最大归一化(代码如下)。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><h2 id="7b8d" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">5.2.将所有特征合并到一个稀疏矩阵中</h2><p id="5dcc" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">我们将为我们的模型提供一个输入矩阵X_train，它包含我们在上一节中提取的所有特征，以及一组相应的目标值y_train。因此，我们需要首先通过并排连接所有的特征向量来构建X_train。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="a253" class="ou mw it oq b gy pj pk l pl pm">Train size: (1332967, 755695), CV size: (148108, 755695), Test size: (3460725, 755695)</span></pre><blockquote class="ks kt ku"><p id="9c06" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated">现在，我们的数据可以输入到模型中了。开始建模吧。</p></blockquote><h1 id="89b2" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">6.建模:机器学习模型</h1><p id="4e79" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">我将逐一训练以下回归模型，并评估它们在验证数据上的性能:</p><ul class=""><li id="01b6" class="nv nw it ky b kz la lc ld mj nx mk ny ml nz lr oa ob oc od bi translated"><a class="ae mi" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky jd">岭回归</strong></a><strong class="ky jd">r</strong>:L2正则化的线性最小二乘</li><li id="4e1c" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><a class="ae mi" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky jd"> SVM回归</strong></a><strong class="ky jd">r</strong>:RBF核支持向量回归。</li><li id="93a7" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><a class="ae mi" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html?highlight=randomforest#sklearn.ensemble.RandomForestRegressor" rel="noopener ugc nofollow" target="_blank"/></li><li id="5fd6" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated"><a class="ae mi" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html#lightgbm.LGBMRegressor" rel="noopener ugc nofollow" target="_blank"> <strong class="ky jd"> LightGBM回归器</strong> </a>:使用基于树的学习算法的梯度推进模型。</li></ul><p id="68a3" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><em class="kx">要了解这些型号的更多信息并阅读文档，请单击型号名称。</em></p><h2 id="3a1c" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">6.1.里脊回归</h2><p id="8001" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">岭是具有l2正则化的线性最小二乘模型。换句话说，就是用l2正则化的线性回归。<br/>山脊模型的过拟合或欠拟合取决于参数<em class="kx"> alpha </em>，可通过如下所示的超参数调谐将其调谐至正确的值。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="63c3" class="ou mw it oq b gy pj pk l pl pm">RMSLE for alpha =  1 is 0.45166601980352833<br/>RMSLE for alpha =  2 is 0.44431546233122515<br/>RMSLE for alpha =  3 is 0.4424425182737627<br/>RMSLE for alpha =  3.5 is 0.44171501703551286<br/>RMSLE for alpha =  4 is 0.44154616529145424<br/>RMSLE for alpha =  4.5 is 0.4415286167861061<br/>RMSLE for alpha =  5 is 0.44161632764828285<br/>RMSLE for alpha =  6 is 0.4421832813533032<br/>RMSLE for alpha =  7 is 0.44267468278758176</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi qn"><img src="../Images/6d62207d1af3a2ea4167cd0c77227044.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*SmTMmJhPRCqhOVzQ20DCCg.png"/></div></figure><p id="1e01" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated"><strong class="ky jd">使用最佳超参数训练模型并测试</strong></p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="e866" class="ou mw it oq b gy pj pk l pl pm">Best alpha:  4.5                            <strong class="oq jd">Train RMSLE: 0.383449898<br/>Cross validation RMSLE:  0.441528616</strong></span></pre><h2 id="b4b0" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">SelectKBest:从分类和文本特征中选择前48k个特征</h2><p id="b95b" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">当数据是高维的时候，我们将进一步尝试的模型需要花费大量的时间来训练。因此，我只从文本TF-IDF向量和分类one-hot编码向量中选择前48，000个特征。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><p id="2364" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">我将这些与数字特征、岭模型的预测(y_pred用作特征)连接起来，并在我的模型中使用它们。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="c984" class="ou mw it oq b gy pj pk l pl pm">Train size: (1332967, 48049), CV size: (148108, 48049), Test size: (3460725, 48049)</span></pre><h2 id="637a" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">6.2.SVM回归</h2><p id="42d9" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">SVR是线性回归的高级版本。它在d维空间中找到一个超平面，该超平面清楚地对数据点进行分类。</p><p id="6197" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">类似于线性回归中的α，SVR中的C是通过超参数调整找到的。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="1b63" class="ou mw it oq b gy pj pk l pl pm">Best C:  0.3<br/>SVR(C=0.3, epsilon=0.1, gamma='scale',kernel='rbf', max_iter=200)</span><span id="c76b" class="ou mw it oq b gy pn pk l pl pm"><strong class="oq jd">Train RMSLE: 0.441563037<br/>Cross validation RMSLE:  0.457637217</strong></span></pre><h2 id="8fbb" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">6.3.随机森林回归</h2><p id="19c0" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">用较高的N估计值(N)训练随机森林回归方程花费了大量的时间，却没有给出任何结果。由于这个原因，我们用较少的估计量来训练它。正如你所猜测的，结果并不令人满意。</p><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="6104" class="ou mw it oq b gy pj pk l pl pm"><strong class="oq jd">RMSLE for N=10 is 0.487657647</strong>	 elapsed time:0:46:21.136700<br/><strong class="oq jd">RMSLE for N=20 is 0.472606976</strong>	 elapsed time:2:02:11.229545</span></pre><h2 id="7561" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">6.4.LightGBM回归</h2><p id="6523" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">Light GBM是一个基于决策树算法的快速、分布式、高性能梯度提升框架，用于排序、分类和许多其他机器学习任务。由于它是基于决策树算法的，所以它以最适合的方式在叶子上分割树，而其他boosting算法在深度上分割树。因此，当在浅色GBM中生长在相同的叶子上时，叶子方式的算法可以比深度方式的算法减少更多的损失，因此导致更好的准确性。而且，它出奇的快，因此有了‘光’这个词。</p><p id="13b0" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">LightGBM的超参数调整已经通过使用RandomizedSearchCV的三重交叉验证完成。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="3a26" class="ou mw it oq b gy pj pk l pl pm">{'colsample_bytree': 0.44583275285359114, 'learning_rate': 0.09997491581800289, 'max_depth': 12, 'min_child_weight': 1.7323522915498704, 'n_estimators': 1323, 'num_leaves': 123}</span></pre><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><pre class="lt lu lv lw gt pf oq pg ph aw pi bi"><span id="c4fc" class="ou mw it oq b gy pj pk l pl pm"><strong class="oq jd">Train RMSLE: 0.319789825<br/>Cross validation RMSLE:  0.424231390</strong></span></pre><h2 id="a959" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">6.5.比较模型的性能</h2><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi qo"><img src="../Images/4fbcd43e48ea99f71afe28ae727064fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8oXzo3fMrP1Z4QYGVbczcQ.png"/></div></div></figure><ul class=""><li id="7af5" class="nv nw it ky b kz la lc ld mj nx mk ny ml nz lr oa ob oc od bi translated">LGBM的验证分数(RMSLE=0.42423)是上述所有模型中最好的。</li><li id="ba8a" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">我把Ridge和LGBM的预测提交给了Kaggle。我们用Ridge得到了最好的分数，RMSLE=0.45444</li><li id="8fc6" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">LGBM评分(RMSLE=0.45785)与Ridge评分非常接近。</li></ul><h1 id="1bcd" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">7.最终解决方案:使用多层感知器进行回归</h1><p id="fe07" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">经典的机器学习模型似乎工作得相当好，但我们应该有更好的性能才能获得好的Kaggle分数。大多数现有方法采用了一些或其他深度学习模型，如卷积神经网络(CNN)、递归神经网络(RNNs)或两者的组合。深度学习模型的性能似乎明显优于经典的ML模型，这鼓励我尝试一个基本的深度学习模型，MLP。</p><h2 id="ed9f" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated"><strong class="ak"> 7.1。预处理</strong></h2><p id="0469" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">我对训练和测试数据做了如下处理:</p><ul class=""><li id="1cd4" class="nv nw it ky b kz la lc ld mj nx mk ny ml nz lr oa ob oc od bi translated">标准文本预处理(词干提取、填充NAs)</li><li id="f12a" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">将<strong class="ky jd">名称</strong>、<strong class="ky jd">品牌名称</strong>串联成一列，<strong class="ky jd">名称。</strong></li><li id="5f9d" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">将<strong class="ky jd">名称</strong>、<strong class="ky jd">项目_描述</strong>、<strong class="ky jd">类别_名称</strong>串联成一列，<strong class="ky jd">文本</strong>。</li></ul><h2 id="ed6d" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">7.2.<strong class="ak">矢量化</strong></h2><ul class=""><li id="4f05" class="nv nw it ky b kz np lc nq mj oj mk ok ml ol lr oa ob oc od bi translated"><strong class="ky jd">名称</strong>的Tfidf 1-gram矢量化。</li><li id="fd1f" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">对<strong class="ky jd">文本</strong>进行1-gram、2-gram矢量化处理。</li><li id="7678" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">分类特征的一键编码<strong class="ky jd">项目_条件_id </strong>，<strong class="ky jd">发货</strong>。</li></ul><h2 id="cebc" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">7.3。MLP模型建筑</h2><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><p id="5d4c" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">选择MLP而不是CNN或RNN的原因是:</p><ul class=""><li id="ed79" class="nv nw it ky b kz la lc ld mj nx mk ny ml nz lr oa ob oc od bi translated">快速训练，可以aﬀord隐藏大小256，而不是32-64的RNN或Conv1D。</li><li id="fb3f" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">MLP捕捉文本和分类特征之间的相互作用。</li><li id="0bd0" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">巨大的方差给出了单一模型类型的强集合。</li></ul><p id="7779" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">我已经训练了完全相同架构的4个高方差模型，并最终对这些模型进行集成以获得最终预测。这和RandomForest的<a class="ae mi" href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" rel="noopener ugc nofollow" target="_blank">套袋</a>差不多。对于4个模型中的2个，我通过将所有非零值设置为1来二进制化输入数据。这就像用二进制CountVectorizer而不是TF-IDF获得一个额外的数据集。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi qp"><img src="../Images/605fb4052dd39aabf75168610f5b71cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*PVFd8WLfB3q4_NLS70th8Q.jpeg"/></div></figure><p id="b7e2" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">我使用Adam optimizer，学习率为0.003，初始批量大小为512，并为2个时期训练模型，在每个时期将批量大小加倍。对于二进制输入，我以同样的方式训练了3个时期。</p><figure class="lt lu lv lw gt lx"><div class="bz fp l di"><div class="os ot l"/></div></figure><h2 id="5321" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">7.3.模型性能评估和Kaggle提交</h2><p id="3023" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">有了上面的模型，我得到了一个验证RMSLE= <strong class="ky jd"> 0.3848 </strong>，相比我之前所有的模型有了很大的提升。</p><blockquote class="ks kt ku"><p id="d0f1" class="kv kw kx ky b kz la ke lb lc ld kh le lf lg lh li lj lk ll lm ln lo lp lq lr im bi translated"><strong class="ky jd">在私人排行榜上，使用该模型在Kaggle上的最终提交分数为0.39446。<br/>虽然比赛很久以前就结束了，但将这个分数放在排行榜上使我在私人和公共LB中都处于第5位(前0.2%)。</strong></p></blockquote><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi qq"><img src="../Images/bb8fae546a3f39aeb85880d48d4aab16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cpo_LKqZblDNm3NBxuovAQ.jpeg"/></div></div></figure><h1 id="664e" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">对现有方法的改进</h1><ul class=""><li id="665b" class="nv nw it ky b kz np lc nq mj oj mk ok ml ol lr oa ob oc od bi translated">为了获得更好的结果，我对MLP架构以及学习速度和批量大小等参数做了一些修改。对于非二进制数据的模型，我还将历元数从3改为2，因为它从第3个历元开始过度拟合。</li><li id="e46c" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">我没有采用简单的平均值，而是采用了4个模型/运行预测的加权平均值。</li><li id="a265" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">为了简化代码，也因为我使用了Google Colab( <em class="kx">使用GPU的训练比使用多核CPU</em>更快)，我一个接一个地训练模型，不像原始内核中的池处理。</li></ul><p id="e108" class="pw-post-body-paragraph kv kw it ky b kz la ke lb lc ld kh le mj lg lh li mk lk ll lm ml lo lp lq lr im bi translated">与源代码内核中的0.3875相比，我得到的验证RMSLE是0.3848。</p><h2 id="4997" class="ou mw it bd mx ov ow dn nb ox oy dp nf mj oz pa nh mk pb pc nj ml pd pe nl iz bi translated">不太顺利的事情</h2><ul class=""><li id="edd6" class="nv nw it ky b kz np lc nq mj oj mk ok ml ol lr oa ob oc od bi translated">随机森林花了太多的时间来训练，因此我不得不放弃这个模型。</li><li id="3d2a" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">在MLP，我也尝试使用辍学(0.1，0.2，0.3，..0.5)，但模型表现更好，没有辍学，因此删除他们。(<em class="kx">我得到了一个验证RMSLE为0.3872的退出数据</em>)。</li><li id="8b49" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">我还试验了不同的激活单元(<em class="kx">‘tanh’，‘sigmoid’，‘linear’，‘relu’</em>)。“relu”的表现明显好于其他所有产品。</li></ul><h1 id="a7f5" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">未来的工作</h1><ul class=""><li id="0232" class="nv nw it ky b kz np lc nq mj oj mk ok ml ol lr oa ob oc od bi translated">使用深度学习是有成效的，并在测试数据上取得了非常好的成绩。可以尝试LSTMs、卷积神经网络等更复杂的模型。</li><li id="b022" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">我们可以通过在隐藏层中添加额外的层和更多的单元来试验更复杂的MLP。</li><li id="399b" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">其他矢量化方案，如<a class="ae mi" href="https://github.com/anttttti/Wordbatch" rel="noopener ugc nofollow" target="_blank"> Wordbatch </a>可以用ML模型进行试验。</li><li id="199b" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr oa ob oc od bi translated">像<a class="ae mi" href="https://datatable.readthedocs.io/en/latest/ftrl.html" rel="noopener ugc nofollow" target="_blank"> FTRL </a>和<a class="ae mi" href="https://medium.com/@dhirajreddy13/factorization-machines-and-follow-the-regression-leader-for-dummies-7657652dce69" rel="noopener"> FM_FTRL </a>这样的回归模型也可以尝试。</li></ul><h1 id="0e23" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">结论</h1><p id="d8cb" class="pw-post-body-paragraph kv kw it ky b kz np ke lb lc nq kh le mj nr lh li mk ns ll lm ml nt lp lq lr im bi translated">做这个案例研究既有趣又是一次很好的学习经历。感谢你阅读我的博客，我希望这能给你带来一些价值。我在这个博客中包含了最少的代码。完整代码请参考我的GitHub资源库中的ipython笔记本<a class="ae mi" href="https://github.com/aruns2120/Mercari-Price-Suggestion-Challenge" rel="noopener ugc nofollow" target="_blank">Mercari-Price-Suggestion-Challenge</a>。我希望听到您的反应、建议或疑问。你可以在LinkedIn上和我联系。这是我的简介。</p><h1 id="619a" class="mv mw it bd mx my mz na nb nc nd ne nf kj ng kk nh km ni kn nj kp nk kq nl nm bi translated">参考</h1><ol class=""><li id="4d88" class="nv nw it ky b kz np lc nq mj oj mk ok ml ol lr om ob oc od bi translated"><a class="ae mi" href="https://blog.exploratory.io/a-practical-guide-of-exploratory-data-analysis-with-linear-regression-part-1-9f3a182d7a92" rel="noopener ugc nofollow" target="_blank">https://blog . explorative . io/a-practical-guide-of-explorative-data-analysis-with-linear-regression-part-1-9f3a 182 D7 a 92</a></li><li id="c1e8" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr om ob oc od bi translated"><a class="ae mi" href="https://www.kaggle.com/c/mercari-price-suggestion-challenge/overview" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/mercari-price-suggestion-challenge/overview</a></li><li id="cfec" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr om ob oc od bi translated"><a class="ae mi" href="https://www.kaggle.com/c/mercari-price-suggestion-challenge/discussion/50252" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/mercari-price-suggestion-challenge/discussion/50252</a></li><li id="fa0a" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr om ob oc od bi translated"><a class="ae mi" href="https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/lopu hin/mercari-golf-0-3875-cv-in-75-loc-1900-s</a></li><li id="79c1" class="nv nw it ky b kz oe lc of mj og mk oh ml oi lr om ob oc od bi translated"><a class="ae mi" href="https://www.appliedaicourse.com/course/11/Applied-Machine-learning-course" rel="noopener ugc nofollow" target="_blank">https://www . Applied ai course . com/course/11/Applied-Machine-learning-course</a></li></ol></div></div>    
</body>
</html>