<html>
<head>
<title>How to Easily Process Audio on Your GPU with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用TensorFlow在您的GPU上轻松处理音频</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-easily-process-audio-on-your-gpu-with-tensorflow-2d9d91360f06?source=collection_archive---------4-----------------------#2020-03-23">https://towardsdatascience.com/how-to-easily-process-audio-on-your-gpu-with-tensorflow-2d9d91360f06?source=collection_archive---------4-----------------------#2020-03-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="75a2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用TensorFlow的信号处理模块，充分利用您的GPU处理音频数据的能力</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/24456f8ea87dcb84a26287c50d4e96e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MJQ66AcFB9BsEF_NpNc5Qw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@hishahadat?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">沙哈达特拉赫曼</a>在<a class="ae ky" href="https://unsplash.com/s/photos/signal-flow?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="8d70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对音频数据的深度学习通常需要繁重的预处理步骤。</p><p id="860e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然有些模型运行在原始音频信号上，但其他模型期望将时频表示作为输入。在模型训练之前，预处理通常作为一个单独的步骤来完成，使用像<code class="fe lv lw lx ly b"><a class="ae ky" href="https://librosa.github.io/librosa/" rel="noopener ugc nofollow" target="_blank">librosa</a></code>或<code class="fe lv lw lx ly b"><a class="ae ky" href="https://essentia.upf.edu/" rel="noopener ugc nofollow" target="_blank">Essentia</a></code>这样的工具。</p><p id="3d8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，当您开始处理更大的数据集时，此工作流会带来挑战。</p><p id="9846" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">任何时候改变参数，比如采样率或FFT大小，都需要再次处理整个数据集，然后才能继续训练。</p><p id="ba18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着等待。😴</p><p id="08b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">即使在可用的CPU内核上并行化，预处理也需要很长时间。另外，您需要考虑如何存储和访问不同参数的文件。这无疑会浪费磁盘空间和精神资源，并且很快会变得令人头痛。</p><p id="e55c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些听起来熟悉吗？</p><p id="cf3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">厌倦了这种繁琐的两步走的过程，我开始问自己是不是没有更好的办法。</p><blockquote class="lz"><p id="4e48" class="ma mb it bd mc md me mf mg mh mi lu dk translated"><em class="mj">“没有更好的办法了吗？”</em></p></blockquote><p id="1c48" class="pw-post-body-paragraph kz la it lb b lc mk ju le lf ml jx lh li mm lk ll lm mn lo lp lq mo ls lt lu im bi translated">我最近<a class="ae ky" rel="noopener" target="_blank" href="/how-to-build-efficient-audio-data-pipelines-with-tensorflow-2-0-b3133474c3c1">建立了一个高效的音频数据管道</a>，它使我能够按需将音频从文件路径加载到模型中。</p><div class="mp mq gp gr mr ms"><a rel="noopener follow" target="_blank" href="/how-to-build-efficient-audio-data-pipelines-with-tensorflow-2-0-b3133474c3c1"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">如何使用TensorFlow 2.0构建高效的音频数据管道</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">使用TensorFlow的数据集API消除培训工作流程中的瓶颈</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">towardsdatascience.com</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng ks ms"/></div></div></a></div><p id="73c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还想对基于声谱图的模型使用相同的数据管道。</p><p id="9e4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我想和你分享:</p><ul class=""><li id="ab95" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nm nn no np bi translated">如何利用GPU的能力来完成信号处理任务。</li><li id="3ca6" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">如何构建自定义预处理层以用于任何神经网络。</li><li id="73c2" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">最后还有一点奖金。😲</li></ul><p id="fe10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请继续阅读，了解更多信息。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="dc88" class="oc od it bd oe of og oh oi oj ok ol om jz on ka oo kc op kd oq kf or kg os ot bi translated">如何用5个简单的步骤预处理您的音频数据</h1><p id="d4df" class="pw-post-body-paragraph kz la it lb b lc ou ju le lf ov jx lh li ow lk ll lm ox lo lp lq oy ls lt lu im bi translated"><a class="ae ky" href="https://arxiv.org/abs/1905.00078" rel="noopener ugc nofollow" target="_blank">深度学习应用中跨音频域</a>的流行特征表示是<em class="oz"> mel-spectrogram </em>。</p><p id="c461" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">mel谱图是信号频谱随时间变化的直观表示。与标准声谱图的主要区别在于，频率被投射到<a class="ae ky" href="https://en.wikipedia.org/wiki/Mel_scale" rel="noopener ugc nofollow" target="_blank"> <em class="oz"> mel音阶</em> </a>上，其中音高的感知距离等于mel频率的距离。这是受我们如何听的启发。</p><p id="cc4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，梅尔频谱图的幅度通常是对数标度的，因为这更接近于我们如何感知响度的变化。因此，更精确的术语应该是<em class="oz">对数级mel标度频谱图</em>。但因为这相当拗口，所以大多数人简称它为<em class="oz">对数-梅尔-光谱图</em>或<em class="oz">梅尔-光谱图</em>。值得指出的是，尽管<em class="oz"> mel </em>指的是频率等级，但是<em class="oz"> log </em>描述的是震级的等级。</p><p id="cb00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么，如何将原始音频信号转换成mel频谱图呢？</p><ol class=""><li id="8115" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu pa nn no np bi translated">计算音频信号的<a class="ae ky" href="https://en.wikipedia.org/wiki/Short-time_Fourier_transform" rel="noopener ugc nofollow" target="_blank">短时傅立叶变换</a></li><li id="71b5" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu pa nn no np bi translated">计算大小</li><li id="b6df" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu pa nn no np bi translated">实例化mel滤波器组</li><li id="2ae9" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu pa nn no np bi translated">将线性标度的星等谱图弯曲到mel标度</li><li id="4a44" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu pa nn no np bi translated">将幅度转换为对数标度</li></ol><p id="c53f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们详细看看每一步。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pb pc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">这是我们将要学习的声音示例</p></figure><h2 id="3581" class="pd od it bd oe pe pf dn oi pg ph dp om li pi pj oo lm pk pl oq lq pm pn os po bi translated">1.计算短时傅立叶变换</h2><p id="5a07" class="pw-post-body-paragraph kz la it lb b lc ou ju le lf ov jx lh li ow lk ll lm ox lo lp lq oy ls lt lu im bi translated">短时傅立叶变换(STFT)将长信号分成较短的片段，通常称为<em class="oz">帧</em>，并计算每帧的频谱。帧通常会重叠，以尽量减少边缘的数据丢失。将每一帧的光谱结合起来就产生了光谱图。</p><p id="2850" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要使用TensorFlow计算STFT，请使用<code class="fe lv lw lx ly b"><a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/signal/stft" rel="noopener ugc nofollow" target="_blank">tf.signal.stft(signals)</a></code>，其中<code class="fe lv lw lx ly b">signals</code>是包含音频信号的张量。</p><p id="a39e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您需要设置的一些参数是:</p><ul class=""><li id="a49f" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nm nn no np bi translated"><code class="fe lv lw lx ly b">frame_length</code>:样本中每一帧的长度。这通常被称为窗口长度或窗口大小。窗口大小以时间分辨率(短窗口)换取频率分辨率(长窗口)。</li><li id="f876" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated"><code class="fe lv lw lx ly b">frame_step</code>:帧间样本数。这通常被称为跳长或跳大小。</li><li id="d5b7" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated"><code class="fe lv lw lx ly b">fft_length</code>:要应用的<a class="ae ky" href="https://en.wikipedia.org/wiki/Fast_Fourier_transform" rel="noopener ugc nofollow" target="_blank"> FFT </a>的大小。这通常称为FFT大小，与<code class="fe lv lw lx ly b">frame_length</code>相匹配。它默认为可以包含一个框架的最小2次方。因此，如果<code class="fe lv lw lx ly b">frame_length</code>是2的幂，并且你没有显式地设置<code class="fe lv lw lx ly b">fft_length</code>，它取相同的值。</li></ul><pre class="kj kk kl km gt pp ly pq pr aw ps bi"><span id="f314" class="pd od it ly b gy pt pu l pv pw">spectrograms = tf.signal.stft(signals,<br/>                              frame_length=1024,<br/>                              frame_step=512)</span></pre><h2 id="98ff" class="pd od it bd oe pe pf dn oi pg ph dp om li pi pj oo lm pk pl oq lq pm pn os po bi translated">2.计算大小</h2><p id="ffa4" class="pw-post-body-paragraph kz la it lb b lc ou ju le lf ov jx lh li ow lk ll lm ox lo lp lq oy ls lt lu im bi translated">上一步中的STFT返回一个复数值张量。使用<code class="fe lv lw lx ly b"><a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/math/abs" rel="noopener ugc nofollow" target="_blank">tf.abs()</a></code>计算震级。</p><pre class="kj kk kl km gt pp ly pq pr aw ps bi"><span id="6f7e" class="pd od it ly b gy pt pu l pv pw">magnitude_spectrograms = tf.abs(spectrograms)</span></pre><p id="9cb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以画出星等谱图。</p><p id="bfe0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不过，请注意，在正确缩放数量级之前，您不会看到太多。第二个支线剧情用<code class="fe lv lw lx ly b">librosa.amplitude_to_db()</code>缩放。所以，从技术上讲，这是一个对数级的功率谱。</p><p id="a6fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在第5步中会有更多的介绍。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi px"><img src="../Images/573cf97c0bdbd16c4bd8bdf3002ce83f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lp_2q4ZYDPwLW0LUajpufg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上图:星等谱图。是全黑吗？不。如果你仔细看，你可以在较低的频率上看到一点能量。下图:对数幅度谱图。当量值用对数标度时，你可以在几个频带中看到能量。</p></figure><h2 id="be98" class="pd od it bd oe pe pf dn oi pg ph dp om li pi pj oo lm pk pl oq lq pm pn os po bi translated">3.实例化Mel-滤波器组</h2><p id="ec80" class="pw-post-body-paragraph kz la it lb b lc ou ju le lf ov jx lh li ow lk ll lm ox lo lp lq oy ls lt lu im bi translated">将标准频谱图转换为mel频谱图包括将频率扭曲到mel标度，并将FFT仓组合到mel频率仓。</p><p id="b286" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlow使这种转变变得容易。</p><p id="4232" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以使用<code class="fe lv lw lx ly b"><a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/signal/linear_to_mel_weight_matrix" rel="noopener ugc nofollow" target="_blank">tf.signal.linear_to_mel_weight_matrix()</a></code>创建一个mel-filterbank，将线性标度光谱图扭曲到mel标度。</p><p id="d246" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您只需要设置几个参数:</p><ul class=""><li id="1e69" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nm nn no np bi translated"><code class="fe lv lw lx ly b">num_mel_bins</code>:生成的mel谱图中mel频段的数量。</li><li id="5ddc" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated"><code class="fe lv lw lx ly b">num_spectrogram_bins</code>:源谱图中唯一谱图仓的数量，等于<code class="fe lv lw lx ly b">fft_length // 2 + 1</code>。</li><li id="1f92" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated"><code class="fe lv lw lx ly b">sample_rate</code>:输入信号每秒的样本数。</li><li id="0bc8" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated"><code class="fe lv lw lx ly b">lower_edge_hertz</code>:包含在mel标度中的最低频率，单位为赫兹。</li><li id="9ad1" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated"><code class="fe lv lw lx ly b">upper_edge_hertz</code>:包含在mel标度中的最高频率，单位为赫兹。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi px"><img src="../Images/de96aeef409a9acf7c34c9a28d110e2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5kdWTG9TTIdWIc4z7iBTNQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有16个梅尔槽的梅尔滤波器组</p></figure><h2 id="caa6" class="pd od it bd oe pe pf dn oi pg ph dp om li pi pj oo lm pk pl oq lq pm pn os po bi translated">4.将线性标度的星等谱图弯曲到mel标度</h2><p id="fc61" class="pw-post-body-paragraph kz la it lb b lc ou ju le lf ov jx lh li ow lk ll lm ox lo lp lq oy ls lt lu im bi translated">将平方的星等谱图乘以mel滤波器组，就可以得到mel标度的功率谱图。</p><pre class="kj kk kl km gt pp ly pq pr aw ps bi"><span id="d740" class="pd od it ly b gy pt pu l pv pw">mel_power_specgrams = tf.matmul(tf.square(magnitude_spectrograms),<br/>                                mel_filterbank)</span></pre><h2 id="20c9" class="pd od it bd oe pe pf dn oi pg ph dp om li pi pj oo lm pk pl oq lq pm pn os po bi translated">5.将幅度转换为对数标度</h2><p id="a042" class="pw-post-body-paragraph kz la it lb b lc ou ju le lf ov jx lh li ow lk ll lm ox lo lp lq oy ls lt lu im bi translated">我们以对数方式感知响度的变化。所以，在这最后一步，我们也想用对数来表示mel光谱图的幅度。</p><p id="82f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">做到这一点的一个方法是获取梅尔光谱图的<code class="fe lv lw lx ly b">log</code>。但是这可能会给你带来麻烦，因为<code class="fe lv lw lx ly b">log(0)</code>没有定义。相反，您希望以数值稳定的方式将幅度转换为<a class="ae ky" href="https://en.wikipedia.org/wiki/Decibel" rel="noopener ugc nofollow" target="_blank">分贝</a> (dB)单位。</p><pre class="kj kk kl km gt pp ly pq pr aw ps bi"><span id="0eef" class="pd od it ly b gy pt pu l pv pw">log_magnitude_mel_spectrograms = power_to_db(mel_power_spectrograms)</span></pre><p id="785e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是如何在基于<code class="fe lv lw lx ly b"><a class="ae ky" href="https://librosa.github.io/librosa/_modules/librosa/core/spectrum.html#power_to_db" rel="noopener ugc nofollow" target="_blank">librosa.power_to_db</a></code>的TensorFlow中做到这一点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="py pc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将功率谱转换为张量流中的分贝单位</p></figure><p id="6a2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">转换成对数标度后，光谱图的最大值为零，最小值为负<code class="fe lv lw lx ly b">top_db</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi px"><img src="../Images/3c84e6a658321d739574e4d9e46aa7d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IJh9HAFwGKlCy1CgO5-3KA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">“电子琴”的mel频谱图，具有64个Mel频段、16 kHz采样率、1024个样本FFT大小和512个样本跳数大小</p></figure><p id="f5ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在有趣的部分来了。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="9546" class="oc od it bd oe of og oh oi oj ok ol om jz on ka oo kc op kd oq kf or kg os ot bi translated"><strong class="ak">准备好立即获得更大的灵活性了吗？</strong></h1><p id="35c2" class="pw-post-body-paragraph kz la it lb b lc ou ju le lf ov jx lh li ow lk ll lm ox lo lp lq oy ls lt lu im bi translated">将各个步骤组合到一个自定义的预处理层中，允许您将原始音频馈送到网络，并在GPU上动态计算Mel-spectro gram。</p><p id="9dd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了创建你的mel-spectrogram层(或任何自定义层)，你从<code class="fe lv lw lx ly b"><a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer" rel="noopener ugc nofollow" target="_blank">tf.keras.layers.Layer</a></code>和<a class="ae ky" href="https://www.tensorflow.org/tutorials/customization/custom_layers#implementing_custom_layers" rel="noopener ugc nofollow" target="_blank">子类实现三个方法</a>:</p><ol class=""><li id="940e" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu pa nn no np bi translated"><code class="fe lv lw lx ly b">__init__()</code>:将层的配置保存在成员变量中。</li><li id="bc49" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu pa nn no np bi translated"><code class="fe lv lw lx ly b">build()</code>:定义你的体重。</li><li id="ee3f" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu pa nn no np bi translated"><code class="fe lv lw lx ly b">call()</code>:执行将图层应用到输入张量的逻辑。这是你将音频输入张量转换成梅尔频谱图的地方。</li></ol><p id="c931" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是我实现的一个自定义Keras层，它将原始音频转换为log-Mel-spectrogram:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="py pc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用此自定义Keras层将原始音频转换为log-Mel-spectrogram</p></figure><p id="e7f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦定义好，你就可以在一行代码中添加音频预处理到你的神经网络中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="py pc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个神经网络的例子，它使用了我们上面定义的自定义LogMelSpectrogram-layer</p></figure><p id="83a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您可能想知道，将相同的音频信号一次又一次地转换成频谱图，效率会不会低得令人难以置信。</p><p id="b507" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个很好的观点。</p><p id="09c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在写这篇文章的时候，我遇到了一个“用于音频和音乐信号预处理的Keras层”库。作者，Choi等人，<a class="ae ky" href="https://arxiv.org/abs/1706.05781" rel="noopener ugc nofollow" target="_blank">展示了一个基准</a>，它显示，他们的预处理层增加了大约20%的开销。</p><p id="ce02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，这是一个权衡。就像生活中的任何事情一样。</p><p id="a9ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，您用存储空间换取了稍长的计算时间。但不仅如此。您还可以摆脱繁琐的两步过程，并立即获得在音频数据上训练深度学习模型的更大灵活性。</p><p id="28fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尝试不同的预处理参数现在就像用不同的参数重新开始你的训练程序一样简单。</p><ul class=""><li id="36f6" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nm nn no np bi translated">不需要维护单独的预处理脚本。</li><li id="a0c8" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">无需记住在多个地方更改参数。</li><li id="c906" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">在继续训练之前，无需处理整个数据集。</li></ul><p id="1595" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">值得开销吗？</p><p id="6da4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你自己决定。</p><h1 id="ab27" class="oc od it bd oe of pz oh oi oj qa ol om jz qb ka oo kc qc kd oq kf qd kg os ot bi translated">这里有些东西可以帮你做到这一点</h1><p id="092b" class="pw-post-body-paragraph kz la it lb b lc ou ju le lf ov jx lh li ow lk ll lm ox lo lp lq oy ls lt lu im bi translated">所有代码和示例都可以在这个Colab笔记本中找到:</p><div class="mp mq gp gr mr ms"><a href="https://bit.ly/2QEBKEJ" rel="noopener  ugc nofollow" target="_blank"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">Google Colab:如何使用TensorFlow在GPU上处理音频</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">免费笔记本，互动体验这篇文章。</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">colab.research.google.com</p></div></div><div class="nb l"><div class="qe l nd ne nf nb ng ks ms"/></div></div></a></div><p id="05df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在轮到你了。</p><p id="1c94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你简化了(或喜欢简化)的工作流程中有哪一个给了你更多的灵活性和思维空间，尽管它稍微贵了一点？</p><h1 id="5d2f" class="oc od it bd oe of pz oh oi oj qa ol om jz qb ka oo kc qc kd oq kf qd kg os ot bi translated">参考</h1><ul class=""><li id="b02b" class="nh ni it lb b lc ou lf ov li qf lm qg lq qh lu nm nn no np bi translated">【<a class="ae ky" href="https://arxiv.org/abs/1905.00078" rel="noopener ugc nofollow" target="_blank">1</a>】h . Purwins等，音频信号处理的深度学习(2019)，IEEE信号处理精选期刊13.2:206–219</li><li id="c5cd" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">[ <a class="ae ky" href="https://arxiv.org/pdf/1706.05781.pdf" rel="noopener ugc nofollow" target="_blank"> 2 </a> ] K. Choi等人，Kapre:快速实现深度神经网络模型的GPU上音频预处理层，Keras (2017) arXiv预印本</li></ul></div></div>    
</body>
</html>