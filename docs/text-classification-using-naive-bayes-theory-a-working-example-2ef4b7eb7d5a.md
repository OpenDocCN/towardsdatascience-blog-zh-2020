# åŸºäºæœ´ç´ è´å¶æ–¯çš„æ–‡æœ¬åˆ†ç±»:ç†è®ºä¸å®ä¾‹

> åŸæ–‡ï¼š<https://towardsdatascience.com/text-classification-using-naive-bayes-theory-a-working-example-2ef4b7eb7d5a?source=collection_archive---------1----------------------->

## [å…¥é—¨](https://towardsdatascience.com/tagged/getting-started)

## åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘è§£é‡Šäº†æœ´ç´ è´å¶æ–¯çš„å·¥ä½œåŸç†ï¼Œå¹¶ä¸€æ­¥æ­¥ç”¨ Python å®ç°äº†ä¸€ä¸ªå¤šç±»æ–‡æœ¬åˆ†ç±»é—®é¢˜ã€‚

![](img/060169a2229253c721e6e203193ee3d6.png)

ä½œè€…åˆ›ä½œçš„äººç‰©ã€‚

## ç›®å½•

1.  **ç®€ä»‹**
2.  **æœ´ç´ è´å¶æ–¯ç®—æ³•**
3.  **å¤„ç†æ–‡æœ¬æ•°æ®**
4.  **Python ä¸­çš„å·¥ä½œç¤ºä¾‹(åˆ†æ­¥æŒ‡å—)**
5.  **å¥–åŠ±:ä¸æ¨¡ç‰¹åŒä¹**
6.  **ç»“è®º**

# 1.ä»‹ç»

**æœ´ç´ è´å¶æ–¯**åˆ†ç±»å™¨æ˜¯åŸºäº**è´å¶æ–¯å®šç†**çš„åˆ†ç±»ç®—æ³•é›†åˆã€‚å®ƒä¸æ˜¯ä¸€ä¸ªå•ä¸€çš„ç®—æ³•ï¼Œè€Œæ˜¯ä¸€ä¸ªç®—æ³•å®¶æ—ï¼Œæ‰€æœ‰ç®—æ³•éƒ½æœ‰ä¸€ä¸ªå…±åŒçš„åŸåˆ™ï¼Œå³æ¯ä¸€å¯¹è¢«åˆ†ç±»çš„ç‰¹å¾éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚

**æœ´ç´ è´å¶æ–¯**åˆ†ç±»å™¨è¢«å¤§é‡ç”¨äº**æ–‡æœ¬åˆ†ç±»**å’Œ**æ–‡æœ¬** **åˆ†æ**æœºå™¨å­¦ä¹ **é—®é¢˜**ã€‚

**æ–‡æœ¬åˆ†æ**æ˜¯æœºå™¨å­¦ä¹ ç®—æ³•çš„ä¸»è¦åº”ç”¨é¢†åŸŸã€‚ç„¶è€Œï¼ŒåŸå§‹æ•°æ®ã€ç¬¦å·åºåˆ—(å³å­—ç¬¦ä¸²)ä¸èƒ½ç›´æ¥æä¾›ç»™ç®—æ³•æœ¬èº«ï¼Œå› ä¸ºå¤§å¤šæ•°ç®—æ³•æœŸæœ›å…·æœ‰å›ºå®šå¤§å°çš„æ•°å­—ç‰¹å¾å‘é‡ï¼Œè€Œä¸æ˜¯å…·æœ‰å¯å˜é•¿åº¦çš„åŸå§‹æ–‡æœ¬æ–‡æ¡£ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†è§£é‡Š a)æœ´ç´ è´å¶æ–¯å¦‚ä½•å·¥ä½œï¼Œb)æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨æ–‡æœ¬ T34ï¼Œæ•°æ® T35ï¼Œæ•°æ® T36ï¼Œåœ¨å°†å®ƒä»¬è½¬æ¢æˆæ›´åˆé€‚çš„å½¢å¼åï¼Œå°†å®ƒä»¬æ”¾å…¥æ¨¡å‹ T40ã€‚æœ€åï¼Œæˆ‘**ç”¨ Python** ä¸€æ­¥æ­¥å®ç°ä¸€ä¸ª**å¤šç±»æ–‡æœ¬åˆ†ç±»é—®é¢˜ã€‚**

æˆ‘ä»¬å¼€å§‹å§ï¼ï¼ï¼

å¦‚æœä½ æƒ³åœ¨äº¤äº’å¼è·¯çº¿å›¾å’Œæ´»è·ƒçš„å­¦ä¹ ç¤¾åŒºçš„æ”¯æŒä¸‹è‡ªå­¦æ•°æ®ç§‘å­¦ï¼Œçœ‹çœ‹è¿™ä¸ªèµ„æº:[https://aigents.co/learn](https://aigents.co/learn)

# 2.æœ´ç´ è´å¶æ–¯ç®—æ³•

æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨æ˜¯åŸºäº**è´å¶æ–¯å®šç†**çš„åˆ†ç±»ç®—æ³•é›†åˆã€‚å®ƒä¸æ˜¯ä¸€ä¸ªå•ä¸€çš„ç®—æ³•ï¼Œè€Œæ˜¯ä¸€ä¸ªç®—æ³•å®¶æ—ï¼Œæ‰€æœ‰ç®—æ³•éƒ½æœ‰ä¸€ä¸ªå…±åŒçš„åŸåˆ™ï¼Œå³æ¯ä¸€å¯¹è¢«åˆ†ç±»çš„ç‰¹å¾éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚

æ•°æ®é›†åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œå³**ç‰¹å¾çŸ©é˜µ**å’Œ**å“åº”/ç›®æ ‡å‘é‡**ã€‚

*   **ç‰¹å¾** **çŸ©é˜µ** (X)åŒ…å«æ•°æ®é›†çš„æ‰€æœ‰å‘é‡(è¡Œ)ï¼Œå…¶ä¸­æ¯ä¸ªå‘é‡ç”±**ç›¸å…³ç‰¹å¾**çš„å€¼ç»„æˆã€‚ç‰¹å¾æ•°ä¸º **d** å³ **X = (x1ï¼Œx2ï¼Œx2ï¼Œxd)ã€‚**
*   **å“åº”/ç›®æ ‡** **å‘é‡** (y)åŒ…å«ç‰¹å¾çŸ©é˜µ**æ¯è¡Œçš„**ç±»/ç»„å˜é‡**çš„å€¼ã€‚**

## **2.1ã€‚æœ´ç´ è´å¶æ–¯çš„ä¸¤ä¸ªä¸»è¦å‡è®¾**

æœ´ç´ è´å¶æ–¯å‡è®¾**åŒä¸€ç±»çš„æ¯ä¸ªç‰¹å¾/å˜é‡**æ„æˆä¸€ä¸ª:

*   **ç‹¬ç«‹**
*   **ç­‰äº**

**å¯¹ç»“æœçš„è´¡çŒ®ã€‚**

**æ—æ³¨:**æœ´ç´ è´å¶æ–¯æ‰€åšçš„å‡è®¾åœ¨ç°å®ä¸–ç•Œçš„æƒ…å†µä¸‹ä¸€èˆ¬ä¸æ­£ç¡®ã€‚äº‹å®ä¸Šï¼Œç‹¬ç«‹æ€§å‡è®¾ç»å¸¸æ— æ³•æ»¡è¶³ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒè¢«ç§°ä¸ºâ€œ**å¹¼ç¨š**â€çš„åŸå› ï¼Œä¹Ÿå°±æ˜¯å› ä¸ºå®ƒå‡è®¾äº†ä¸€äº›å¯èƒ½ä¸çœŸå®çš„äº‹æƒ…ã€‚

## 2.2.è´å¶æ–¯å®šç†

è´å¶æ–¯å®šç†æ˜¯åœ¨å·²çŸ¥ä¸€ä¸ªäº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡çš„æƒ…å†µä¸‹ï¼Œæ±‚å‡ºå¦ä¸€ä¸ªäº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡ã€‚è´å¶æ–¯å®šç†çš„æ•°å­¦è¡¨è¿°å¦‚ä¸‹:

![](img/8ee53bda87995b7d0751b927b4dba317.png)

ä½œè€…åˆ›ä½œçš„äººç‰©ã€‚

å…¶ä¸­:

*   **A** å’Œ **B** ç§°ä¸º**äº‹ä»¶ã€‚**
*   P(A | B)æ˜¯äº‹ä»¶ A çš„æ¦‚ç‡ï¼Œå‡è®¾äº‹ä»¶ B ä¸ºçœŸ(å·²ç»å‘ç”Ÿ)ã€‚äº‹ä»¶ B ä¹Ÿè¢«ç§°ä¸º**è¯æ®**ã€‚
*   P(A)æ˜¯ A çš„**å…ˆéªŒ**(å…ˆéªŒç‹¬ç«‹æ¦‚ç‡ï¼Œå³äº‹ä»¶åœ¨è¯æ®è¢«çœ‹åˆ°ä¹‹å‰çš„æ¦‚ç‡)ã€‚
*   P(B | A)æ˜¯ç»™å®šäº‹ä»¶ A çš„ B çš„æ¦‚ç‡ï¼Œå³çœ‹åˆ°è¯æ® A åäº‹ä»¶ B çš„æ¦‚ç‡ã€‚

## æ‘˜è¦

![](img/50b76d3deeb8f4411afe46e49930aded.png)

ä½œè€…åˆ›ä½œçš„äººç‰©ã€‚

## 2.3.æœ´ç´ è´å¶æ–¯æ¨¡å‹

ç»™å®šä¸€ä¸ªæ•°æ®çŸ©é˜µ **X** å’Œä¸€ä¸ªç›®æ ‡å‘é‡ **yï¼Œ**æˆ‘ä»¬å°†æˆ‘ä»¬çš„é—®é¢˜è¡¨è¿°ä¸º:

![](img/d15dc42bdb6dc33fe850de4c9e7d74c2.png)

ä½œè€…åˆ›ä½œçš„äººç‰©ã€‚

å…¶ä¸­ï¼Œ **y** ä¸º**ç±»å˜é‡**ï¼Œ **X** ä¸ºç»´åº¦ä¸º d çš„**ä¾èµ–ç‰¹å¾å‘é‡ï¼Œå³ X = (x1ï¼Œx2ï¼Œx2ï¼Œxd)ï¼Œ**å…¶ä¸­ **d** ä¸ºæ ·æœ¬çš„å˜é‡/ç‰¹å¾ä¸ªæ•°ã€‚

*   P(y|X)æ˜¯ç»™å®šæ ·æœ¬ **X** è§‚å¯Ÿåˆ°ç±» **y** çš„æ¦‚ç‡ï¼Œå…¶ä¸­ **X = (x1ï¼Œx2ï¼Œx2ï¼Œxd)ï¼Œ**å…¶ä¸­ **d** æ˜¯æ ·æœ¬çš„å˜é‡/ç‰¹å¾çš„æ•°é‡ã€‚

ç°åœ¨â€œå¤©çœŸçš„â€[æ¡ä»¶ç‹¬ç«‹æ€§](https://en.wikipedia.org/wiki/Conditional_independence)å‡è®¾å¼€å§‹å‘æŒ¥ä½œç”¨:å‡è®¾ **X** ä¸­çš„æ‰€æœ‰ç‰¹æ€§éƒ½æ˜¯[ç›¸äº’ç‹¬ç«‹](https://en.wikipedia.org/wiki/Mutually_independent)ï¼Œä»¥ç±»åˆ« **y** ä¸ºæ¡ä»¶:

![](img/f25c07c0dc374f52f69fbb4fc492615a.png)

ä½œè€…åˆ›ä½œçš„äººç‰©ã€‚

æœ€åï¼Œä¸ºäº†æ‰¾åˆ°ç»™å®šçš„**æ ·æœ¬**å¯¹äºç±»å˜é‡ ***y*** çš„æ‰€æœ‰å¯èƒ½å€¼çš„æ¦‚ç‡ï¼Œæˆ‘ä»¬åªéœ€è¦æ‰¾åˆ°å…·æœ‰æœ€å¤§æ¦‚ç‡çš„è¾“å‡º:

![](img/1a0abfdc7337af9eedd0c2789656c628.png)

ä½œè€…åˆ›ä½œçš„äººç‰©ã€‚

# 3.å¤„ç†æ–‡æœ¬æ•°æ®

æ­¤æ—¶å‡ºç°çš„ä¸€ä¸ªé—®é¢˜å¦‚ä¸‹:

> æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨åŸå§‹æ–‡æœ¬æ•°æ®æ¥è®­ç»ƒæ¨¡å‹ï¼ŸåŸå§‹æ•°æ®æ˜¯å­—ç¬¦ä¸²çš„é›†åˆï¼

æ–‡æœ¬åˆ†ææ˜¯æœºå™¨å­¦ä¹ ç®—æ³•çš„ä¸€ä¸ªä¸»è¦åº”ç”¨é¢†åŸŸã€‚**ç„¶è€Œï¼ŒåŸå§‹æ•°æ®ã€ç¬¦å·åºåˆ—(å³å­—ç¬¦ä¸²)ä¸èƒ½ç›´æ¥æä¾›ç»™ç®—æ³•æœ¬èº«ï¼Œå› ä¸ºå¤§å¤šæ•°ç®—æ³•æœŸæœ›å…·æœ‰å›ºå®šå¤§å°çš„æ•°å­—ç‰¹å¾å‘é‡ï¼Œè€Œä¸æ˜¯å…·æœ‰å¯å˜é•¿åº¦çš„åŸå§‹æ–‡æœ¬æ–‡æ¡£ã€‚**

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œscikit-learn æä¾›äº†ä»æ–‡æœ¬å†…å®¹ä¸­æå–æ•°å­—ç‰¹å¾çš„æœ€å¸¸è§æ–¹æ³•çš„å®ç”¨ç¨‹åºï¼Œå³:

*   **æ ‡è®°åŒ–**å­—ç¬¦ä¸²å¹¶ä¸ºæ¯ä¸ªå¯èƒ½çš„æ ‡è®°ç»™å‡ºä¸€ä¸ªæ•´æ•° idï¼Œä¾‹å¦‚é€šè¿‡ä½¿ç”¨ç©ºæ ¼å’Œæ ‡ç‚¹ç¬¦å·ä½œä¸ºæ ‡è®°åˆ†éš”ç¬¦ã€‚
*   **ç»Ÿè®¡æ¯ä¸ªæ–‡æ¡£ä¸­ä»¤ç‰Œçš„å‡ºç°æ¬¡æ•°**ã€‚

åœ¨æ­¤æ–¹æ¡ˆä¸­ï¼Œç‰¹å¾å’Œæ ·æœ¬å®šä¹‰å¦‚ä¸‹:

*   æ¯ä¸ª**å•ä¸ªä»¤ç‰Œå‡ºç°é¢‘ç‡**è¢«è§†ä¸ºä¸€ä¸ª**ç‰¹å¾**ã€‚
*   ç»™å®š**æ–‡æ¡£**çš„æ‰€æœ‰ä»¤ç‰Œé¢‘ç‡çš„å‘é‡è¢«è§†ä¸ºå¤šå…ƒ**æ ·æœ¬**ã€‚

## â€œè®¡æ•°â€ç¤ºä¾‹(ä¸ºäº†åœ¨æˆ‘ä»¬ç»§ç»­ä¹‹å‰çœŸæ­£ç†è§£è¿™ä¸€ç‚¹):

```
from sklearn.feature_extraction.text import CountVectorizer
corpus = [
    'This is the first document.',
    'This document is the second document.',
    'And this is the third one.',
    'Is this the first document?',
]vectorizer = CountVectorizer()
X = vectorizer.fit_transform(corpus)print(vectorizer.get_feature_names())
**[â€˜andâ€™, â€˜documentâ€™, â€˜firstâ€™, â€˜isâ€™, â€˜oneâ€™, â€˜secondâ€™, â€˜theâ€™, â€˜thirdâ€™, â€˜thisâ€™]**print(X.toarray())
[[0 1 1 1 0 0 1 0 1]
 [0 2 0 1 0 1 1 0 1]
 [1 0 0 1 1 0 1 1 1]
 [0 1 1 1 0 0 1 0 1]]
```

åœ¨ä¸Šé¢çš„ç©å…·ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€ç»„å­—ç¬¦ä¸²å­˜å‚¨åœ¨å˜é‡**è¯­æ–™åº“ä¸­ã€‚**ä½¿ç”¨**æ–‡æœ¬** **è½¬æ¢å™¨**ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ•°æ®ä¸­æœ‰ç‰¹å®šæ•°é‡çš„å”¯ä¸€å­—ç¬¦ä¸²(è¯æ±‡)ã€‚

è¿™å¯ä»¥é€šè¿‡æ‰“å°**çŸ¢é‡å™¨. get_feature_names()** å˜é‡**æ¥çœ‹å‡ºã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°æˆ‘ä»¬æœ‰ 9 ä¸ªç‹¬ç‰¹çš„å•è¯ã€‚**

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ‰“å°è½¬æ¢åçš„æ•°æ®( **X** )å’Œ**ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä»¥ä¸‹**:

*   æˆ‘ä»¬åœ¨ X ä¸­æœ‰ 4 è¡Œä½œä¸ºæˆ‘ä»¬çš„æ–‡æœ¬ä¸²çš„æ•°é‡(**æˆ‘ä»¬åœ¨è½¬æ¢åæœ‰ç›¸åŒæ•°é‡çš„æ ·æœ¬**)ã€‚
*   **æˆ‘ä»¬åœ¨è½¬æ¢åçš„æ•°æ®( **X** ) f **æˆ–æ‰€æœ‰æ ·æœ¬(**è½¬æ¢å‰å¹¶éå¦‚æ­¤ï¼Œå³å„ä¸ªå­—ç¬¦ä¸²å…·æœ‰ä¸åŒçš„é•¿åº¦)ä¸­æœ‰ç›¸åŒæ•°é‡çš„åˆ—**(ç‰¹å¾/å˜é‡)ã€‚
*   å€¼ 0ï¼Œ1ï¼Œ2 å¯¹**å‡ºç°åœ¨**åˆå§‹æ–‡æœ¬æ•°æ®**ä¸­çš„**å­—**çš„**é¢‘ç‡**è¿›è¡Œç¼–ç ã€‚**

**ä¾‹å¦‚**ã€‚ç¬¬ä¸€ä¸ªè½¬æ¢è¡Œæ˜¯**[0 1 1 1 0 1 0 1 0 1]**å’Œ****å”¯ä¸€è¯æ±‡**æ˜¯ **['and 'ï¼Œ' document 'ï¼Œ' first 'ï¼Œ' is 'ï¼Œ' one 'ï¼Œ' second 'ï¼Œ' The 'ï¼Œ' this']ï¼Œ**å› æ­¤è¿™æ„å‘³ç€å•è¯â€œdocumentâ€ï¼Œâ€œfirstâ€ï¼Œâ€œisâ€ï¼Œâ€œtheâ€å’Œâ€œthisâ€åœ¨åˆå§‹æ–‡æœ¬ä¸²ä¸­å„å‡ºç° 1 æ¬¡(å³â€œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ–‡æ¡£â€).**

****è¾¹æ³¨:**è¿™æ˜¯è®¡æ•°æ³•ã€‚[é¡¹-é¢‘ç‡å˜æ¢](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)æ— éæ˜¯å°†è®¡æ•°çŸ©é˜µå˜æ¢æˆå½’ä¸€åŒ–çš„é¡¹-é¢‘ç‡çŸ©é˜µã€‚**

**å¸Œæœ›ç°åœ¨ä¸€åˆ‡éƒ½æ¸…æ¥šäº†ã€‚å¦‚æœæ²¡æœ‰ï¼Œæ ¹æ®éœ€è¦å¤šæ¬¡é˜…è¯»è¿™ä¸€æ®µï¼Œä»¥ä¾¿çœŸæ­£æŒæ¡æ€æƒ³å’Œç†è§£è¿™ä¸€è½¬å˜ã€‚è¿™æ˜¯æœ€åŸºæœ¬çš„ä¸€æ­¥ã€‚**

# **4.Python ä¸­çš„å·¥ä½œç¤ºä¾‹**

**æ—¢ç„¶æ‚¨å·²ç»ç†è§£äº†æœ´ç´ è´å¶æ–¯å’Œæ–‡æœ¬è½¬æ¢æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œé‚£ä¹ˆæ˜¯æ—¶å€™å¼€å§‹ç¼–ç äº†ï¼**

## **é—®é¢˜é™ˆè¿°**

**ä½œä¸ºä¸€ä¸ªå·¥ä½œç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€äº›**æ–‡æœ¬** **æ•°æ®**ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ª**æœ´ç´ ** **è´å¶æ–¯**æ¨¡å‹æ¥**é¢„æµ‹**æ–‡æœ¬**çš„**ç±»åˆ«**ã€‚è¿™æ˜¯ä¸€ä¸ª**å¤šç±»(20 ç±»)æ–‡æœ¬åˆ†ç±»é—®é¢˜**ã€‚****

**è®©æˆ‘ä»¬å¼€å§‹å§(æˆ‘ä¼šå¸¦ä½ èµ°ä¸€é)ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†**åŠ è½½æ‰€æœ‰å¿…è¦çš„åº“**:**

```
import numpy as np, pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.metrics import confusion_matrix, accuracy_scoresns.set() # use seaborn plotting style
```

**æ¥ä¸‹æ¥ï¼Œ**è®©æˆ‘ä»¬åŠ è½½æ•°æ®** ( **è®­ç»ƒ**å’Œ**æµ‹è¯•**é›†åˆ):**

```
# Load the dataset
data = fetch_20newsgroups()# Get the text categories
text_categories = data.target_names# define the training set
train_data = fetch_20newsgroups(subset="train", categories=text_categories)# define the test set
test_data = fetch_20newsgroups(subset="test", categories=text_categories)
```

**è®©æˆ‘ä»¬æ‰¾å‡º**æˆ‘ä»¬æœ‰å¤šå°‘ç±»**å’Œ**æ ·æœ¬**:**

```
print("We have {} unique classes".format(len(text_categories)))
print("We have {} training samples".format(len(train_data.data)))
print("We have {} test samples".format(len(test_data.data)))
```

**ä¸Šé¢çš„ç‰ˆç”»:**

```
We have 20 unique classes
We have 11314 training samples
We have 7532 test samples
```

**æ‰€ä»¥ï¼Œè¿™æ˜¯ä¸€ä¸ª **20 ç±»æ–‡æœ¬åˆ†ç±»é—®é¢˜**ç”¨ n_train = **11314** **è®­ç»ƒ** **æ ·æœ¬**(æ–‡æœ¬å¥å­)å’Œ n _ test =****æµ‹è¯•** **æ ·æœ¬**(æ–‡æœ¬å¥å­)ã€‚****

****è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹ç¬¬äº”ä¸ªè®­ç»ƒæ ·æœ¬:****

```
**# letâ€™s have a look as some training data
print(test_data.data[5])**
```

****å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬çš„æ•°æ®æ˜¯**æ–‡æœ¬**(æ›´å…·ä½“åœ°è¯´ï¼Œæ˜¯**ç”µå­é‚®ä»¶**)ï¼Œæ‰€ä»¥æ‚¨åº”è¯¥ä¼šçœ‹åˆ°ç±»ä¼¼ä¸‹é¢è¿™æ ·çš„è¾“å‡º:****

****![](img/ad86d506c9084aa1bb68118fe154ec70.png)****

****ä½œè€…åˆ›ä½œçš„äººç‰©ã€‚****

****ä¸‹ä¸€æ­¥åŒ…æ‹¬å»ºç«‹**æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨**ï¼Œæœ€å**è®­ç»ƒ**æ¨¡å‹**ã€‚**åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠæ–‡æœ¬æ–‡æ¡£çš„é›†åˆ(è®­ç»ƒå’Œæµ‹è¯•é›†)è½¬æ¢æˆä¸€ä¸ªä»¤ç‰Œè®¡æ•°çš„çŸ©é˜µ(æˆ‘åœ¨**ç¬¬ 3 èŠ‚**ä¸­è§£é‡Šäº†è¿™æ˜¯å¦‚ä½•å·¥ä½œçš„)ã€‚****

> ****ä¸ºäº†å®ç°æ–‡æœ¬è½¬æ¢ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **make_pipeline** å‡½æ•°ã€‚è¿™å°†åœ¨å†…éƒ¨è½¬æ¢æ–‡æœ¬æ•°æ®ï¼Œç„¶åä½¿ç”¨è½¬æ¢åçš„æ•°æ®æ‹Ÿåˆæ¨¡å‹**ã€‚******

```
**# Build the model
model = make_pipeline(TfidfVectorizer(), MultinomialNB())# Train the model using the training data
model.fit(train_data.data, train_data.target)# Predict the categories of the test data
predicted_categories = model.predict(test_data.data)**
```

****ä»£ç çš„æœ€åä¸€è¡Œ**é¢„æµ‹äº†æµ‹è¯•é›†**çš„æ ‡ç­¾ã€‚****

****è®©æˆ‘ä»¬çœ‹çœ‹é¢„æµ‹çš„ç±»åˆ«åç§°:****

```
**print(np.array(test_data.target_names)[predicted_categories])
array(['rec.autos', 'sci.crypt', 'alt.atheism', ..., 'rec.sport.baseball', 'comp.sys.ibm.pc.hardware', 'soc.religion.christian'], dtype='<U24')**
```

****æœ€åï¼Œè®©æˆ‘ä»¬æ„å»º [**å¤šç±»æ··æ·†çŸ©é˜µ**](/roc-curve-explained-using-a-covid-19-hypothetical-example-binary-multi-class-classification-bab188ea869c?source=friends_link&sk=08f3dba9c6415860f84f5195d9b0ff65) æ¥çœ‹çœ‹è¿™ä¸ªæ¨¡å‹æ˜¯å¥½çš„è¿˜æ˜¯è¿™ä¸ªæ¨¡å‹åªæ­£ç¡®é¢„æµ‹ç‰¹å®šçš„æ–‡æœ¬ç±»åˆ«ã€‚****

```
**# plot the confusion matrix
mat = confusion_matrix(test_data.target, predicted_categories)
sns.heatmap(mat.T, square = True, annot=True, fmt = "d", xticklabels=train_data.target_names,yticklabels=train_data.target_names)
plt.xlabel("true labels")
plt.ylabel("predicted label")
plt.show()print("The accuracy is {}".format(accuracy_score(test_data.target, predicted_categories)))The accuracy is 0.7738980350504514**
```

****![](img/b365025b4916f908723c8bbef17132b5.png)****

****ä½œè€…åˆ›ä½œçš„äººç‰©ã€‚****

# ****5.é¢å¤–æ”¶è·:å’Œæ¨¡ç‰¹ç©å¾—å¼€å¿ƒ****

****è®©æˆ‘ä»¬ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ¥æ‰¾ç‚¹ä¹å­ã€‚è®©æˆ‘ä»¬æŠŠæˆ‘ä»¬å–œæ¬¢çš„å¥å­åˆ†ç±»ğŸ˜„ã€‚****

```
**# custom function to have fun
def my_predictions(my_sentence, model):
    all_categories_names = np.array(data.target_names)
    prediction = model.predict([my_sentence])
    return all_categories_names[prediction] my_sentence = â€œjesusâ€
print(my_predictions(my_sentence, model))
['soc.religion.christian']my_sentence = "Are you an atheist?"
print(my_predictions(my_sentence, model))
['alt.atheism']**
```

****æˆ‘ä»¬å°†å­—ç¬¦ä¸²â€œjesusâ€æ’å…¥åˆ°æ¨¡å‹ä¸­ï¼Œå®ƒé¢„æµ‹äº†ç±»åˆ«â€œ' soc.religion.christian']â€ã€‚****

****æŠŠâ€œæˆ‘çš„å¥å­â€æ¢æˆå…¶ä»–å­—ç¬¦ä¸²**ç©æ¨¡å‹**ğŸ˜ƒã€‚****

# ****6.ç»“è®º****

****æˆ‘ä»¬çœ‹åˆ°**æœ´ç´ è´å¶æ–¯å¯¹äº**å¤šç±»æ–‡æœ¬åˆ†ç±»é—®é¢˜æ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„ç®—æ³•**ã€‚******

*****è¾¹æ³¨*** : *å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºæ··æ·†çŸ©é˜µ(ä»¥åŠ ROC æ›²çº¿)çš„çŸ¥è¯†ï¼Œè¯·çœ‹è¿™ä¸ª:***

**[](/roc-curve-explained-using-a-covid-19-hypothetical-example-binary-multi-class-classification-bab188ea869c) [## ç”¨æ–°å† è‚ºç‚å‡è®¾çš„ä¾‹å­è§£é‡Š ROC æ›²çº¿:äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»â€¦

### åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æ¸…æ¥šåœ°è§£é‡Šäº†ä»€ä¹ˆæ˜¯ ROC æ›²çº¿ä»¥åŠå¦‚ä½•é˜…è¯»å®ƒã€‚æˆ‘ç”¨ä¸€ä¸ªæ–°å† è‚ºç‚çš„ä¾‹å­æ¥è¯´æ˜æˆ‘çš„è§‚ç‚¹ï¼Œæˆ‘â€¦

towardsdatascience.com](/roc-curve-explained-using-a-covid-19-hypothetical-example-binary-multi-class-classification-bab188ea869c) 

## è§£è¯»å›°æƒ‘çŸ©é˜µ

ä»ä¸Šé¢çš„**æ··ä¹±** **çŸ©é˜µ**å¯ä»¥éªŒè¯æ¨¡å‹çœŸçš„å¾ˆå¥½ã€‚

*   å®ƒèƒ½å¤Ÿæ­£ç¡®åœ°é¢„æµ‹æ‰€æœ‰ 20 ç±»æ–‡æœ¬æ•°æ®(å¤§å¤šæ•°å€¼åœ¨å¯¹è§’çº¿ä¸Šï¼Œå°‘æ•°ä¸åœ¨å¯¹è§’çº¿ä¸Š)ã€‚
*   æˆ‘ä»¬è¿˜æ³¨æ„åˆ°æœ€é«˜çš„è¯¯åˆ†ç±»(åç¦»å¯¹è§’çº¿çš„å€¼)æ˜¯ **131** (ä»æœ«å°¾èµ· 5 è¡Œï¼Œå³è¾¹æœ€åä¸€åˆ—)ã€‚å€¼ 131 æ„å‘³ç€å±äºâ€œ**å®—æ•™æ‚é¡¹**â€ç±»åˆ«çš„ 131 ä¸ªæ–‡æ¡£è¢«è¯¯åˆ†ç±»ä¸ºå±äºâ€œ**å®—æ•™åŸºç£æ•™**â€ç±»åˆ«ã€‚

æœ‰è¶£çš„æ˜¯ï¼Œè¿™ä¸¤ä¸ªç±»åˆ«éå¸¸ç›¸ä¼¼ï¼Œå®é™…ä¸Šäººä»¬å¯ä»¥å°†å®ƒä»¬åˆ’åˆ†ä¸ºä¸€ä¸ªæ›´å¤§çš„ç¾¤ä½“ä¸­çš„ä¸¤ä¸ªå­ç¾¤ä½“ï¼Œä¾‹å¦‚ä¸€èˆ¬çš„â€œå®—æ•™â€ã€‚

æœ€åï¼Œ**æµ‹è¯•**é›†åˆä¸Šçš„**å‡†ç¡®åº¦**ä¸º **0.7739** å¯¹äºä¸€ä¸ª **20 çº§çš„æ–‡æœ¬åˆ†ç±»é—®é¢˜**æ¥è¯´å·²ç»ç›¸å½“ä¸é”™äº†ğŸš€ã€‚

**é‚£éƒ½æ˜¯ä¹¡äº²ä»¬ï¼å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ã€‚**** 

**å¦‚æœæ‚¨å–œæ¬¢è¿™ç¯‡æ–‡ç« å¹¶è§‰å¾—å®ƒæœ‰ç”¨ï¼Œè¯·å…³æ³¨ğŸ‘£æˆ‘å¯ä»¥çœ‹åˆ°æˆ‘æ‰€æœ‰çš„æ–°å¸–å­ã€‚**

**æœ‰é—®é¢˜å—ï¼ŸæŠŠå®ƒä»¬ä½œä¸ºè¯„è®ºè´´å‡ºæ¥ï¼Œæˆ‘ä¼šå°½å¿«å›å¤ã€‚**

## **æˆ‘çš„ä¸ªäººèµ„æ–™(çœ‹çœ‹æˆ‘æ”¶é›†çš„æ–‡ç« ):**

**[](https://towardsdatascience.com/@seralouk) [## Serafeim Loukas -èµ°å‘æ•°æ®ç§‘å­¦

### é˜…è¯» Serafeim Loukas åœ¨ã€Šèµ°å‘æ•°æ®ç§‘å­¦ã€‹ä¸­çš„æ–‡ç« ã€‚ç”µæ°”å’Œè®¡ç®—æœºå·¥ç¨‹æ–‡å‡­(NTUA)ã€‚ä¸»äººâ€¦

towardsdatascience.com](https://towardsdatascience.com/@seralouk)** 

# **å’Œæˆ‘è”ç³»**

*   ****é¢†è‹±**:[https://www.linkedin.com/in/serafeim-loukas/](https://www.linkedin.com/in/serafeim-loukas/)**

## **æ‚¨å¯èƒ½è¿˜å–œæ¬¢:**

**[](/support-vector-machines-svm-clearly-explained-a-python-tutorial-for-classification-problems-29c539f3ad8) [## æ”¯æŒå‘é‡æœº(SVM)è§£é‡Šæ¸…æ¥š:åˆ†ç±»é—®é¢˜çš„ python æ•™ç¨‹â€¦

### åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘è§£é‡Šäº†æ”¯æŒå‘é‡æœºçš„æ ¸å¿ƒï¼Œä¸ºä»€ä¹ˆä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ã€‚æ­¤å¤–ï¼Œæˆ‘è¿˜å±•ç¤ºäº†å¦‚ä½•ç»˜åˆ¶æ”¯æŒâ€¦

towardsdatascience.com](/support-vector-machines-svm-clearly-explained-a-python-tutorial-for-classification-problems-29c539f3ad8) [](/k-means-clustering-how-it-works-finding-the-optimum-number-of-clusters-in-the-data-13d18739255c) [## K-Means èšç±»:å·¥ä½œåŸç†&åœ¨æ•°æ®ä¸­å¯»æ‰¾æœ€ä¼˜çš„èšç±»æ•°

### æ•°å­¦å…¬å¼ï¼Œå¯»æ‰¾æœ€ä½³èšç±»æ•°å’Œ Python ä¸­çš„å·¥ä½œç¤ºä¾‹ã€‚

towardsdatascience.com](/k-means-clustering-how-it-works-finding-the-optimum-number-of-clusters-in-the-data-13d18739255c) [](/lstm-time-series-forecasting-predicting-stock-prices-using-an-lstm-model-6223e9644a2f) [## LSTM æ—¶é—´åºåˆ—é¢„æµ‹:ä½¿ç”¨ LSTM æ¨¡å‹é¢„æµ‹è‚¡ç¥¨ä»·æ ¼

### åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨é¢„æµ‹ LSTM æ¨¡å‹æ¥é¢„æµ‹è‚¡ç¥¨ä»·æ ¼

towardsdatascience.com](/lstm-time-series-forecasting-predicting-stock-prices-using-an-lstm-model-6223e9644a2f) [](/time-series-forecasting-predicting-stock-prices-using-an-arima-model-2e3b3080bd70) [## æ—¶é—´åºåˆ—é¢„æµ‹:ä½¿ç”¨ ARIMA æ¨¡å‹é¢„æµ‹è‚¡ç¥¨ä»·æ ¼

### åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨é¢„æµ‹ ARIMA æ¨¡å‹æ¥é¢„æµ‹ç‰¹æ–¯æ‹‰çš„è‚¡ç¥¨ä»·æ ¼

towardsdatascience.com](/time-series-forecasting-predicting-stock-prices-using-an-arima-model-2e3b3080bd70) [](https://medium.com/@seralouk/the-best-free-data-science-resources-free-books-online-courses-9c4a2df194e5) [## æœ€ä½³å…è´¹æ•°æ®ç§‘å­¦èµ„æº:å…è´¹ä¹¦ç±å’Œåœ¨çº¿è¯¾ç¨‹

### æœ€æœ‰ç”¨çš„å…è´¹ä¹¦ç±å’Œåœ¨çº¿è¯¾ç¨‹ï¼Œé€‚åˆæƒ³äº†è§£æ›´å¤šæ•°æ®ç§‘å­¦çŸ¥è¯†çš„äººã€‚

medium.com](https://medium.com/@seralouk/the-best-free-data-science-resources-free-books-online-courses-9c4a2df194e5) [](/roc-curve-explained-using-a-covid-19-hypothetical-example-binary-multi-class-classification-bab188ea869c) [## ç”¨æ–°å† è‚ºç‚å‡è®¾çš„ä¾‹å­è§£é‡Š ROC æ›²çº¿:äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»â€¦

### åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æ¸…æ¥šåœ°è§£é‡Šäº†ä»€ä¹ˆæ˜¯ ROC æ›²çº¿ä»¥åŠå¦‚ä½•é˜…è¯»å®ƒã€‚æˆ‘ç”¨ä¸€ä¸ªæ–°å† è‚ºç‚çš„ä¾‹å­æ¥è¯´æ˜æˆ‘çš„è§‚ç‚¹ï¼Œæˆ‘â€¦

towardsdatascience.com](/roc-curve-explained-using-a-covid-19-hypothetical-example-binary-multi-class-classification-bab188ea869c) [](/support-vector-machines-svm-clearly-explained-a-python-tutorial-for-classification-problems-29c539f3ad8) [## æ”¯æŒå‘é‡æœº(SVM)è§£é‡Šæ¸…æ¥š:åˆ†ç±»é—®é¢˜çš„ python æ•™ç¨‹â€¦

### åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘è§£é‡Šäº†æ”¯æŒå‘é‡æœºçš„æ ¸å¿ƒï¼Œä¸ºä»€ä¹ˆä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ã€‚æ­¤å¤–ï¼Œæˆ‘è¿˜å±•ç¤ºäº†å¦‚ä½•ç»˜åˆ¶æ”¯æŒâ€¦

towardsdatascience.com](/support-vector-machines-svm-clearly-explained-a-python-tutorial-for-classification-problems-29c539f3ad8) [](/pca-clearly-explained-how-when-why-to-use-it-and-feature-importance-a-guide-in-python-7c274582c37e) [## PCA æ¸…æ¥šåœ°è§£é‡Šäº†â€”â€”å¦‚ä½•ã€ä½•æ—¶ã€ä¸ºä»€ä¹ˆä½¿ç”¨å®ƒä»¥åŠç‰¹æ€§çš„é‡è¦æ€§:Python æŒ‡å—

### åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘è§£é‡Šäº†ä»€ä¹ˆæ˜¯ PCAï¼Œä½•æ—¶ä»¥åŠä¸ºä»€ä¹ˆä½¿ç”¨å®ƒï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ scikit-learn åœ¨ Python ä¸­å®ç°å®ƒã€‚è¿˜æœ‰â€¦

towardsdatascience.com](/pca-clearly-explained-how-when-why-to-use-it-and-feature-importance-a-guide-in-python-7c274582c37e) [](/everything-you-need-to-know-about-min-max-normalization-in-python-b79592732b79) [## å…³äº Python ä¸­çš„æœ€å°-æœ€å¤§è§„èŒƒåŒ–ï¼Œæ‚¨éœ€è¦çŸ¥é“çš„ä¸€åˆ‡

### åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†è§£é‡Šä»€ä¹ˆæ˜¯æœ€å°-æœ€å¤§ç¼©æ”¾ï¼Œä»€ä¹ˆæ—¶å€™ä½¿ç”¨å®ƒï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ scikit åœ¨ Python ä¸­å®ç°å®ƒ

towardsdatascience.com](/everything-you-need-to-know-about-min-max-normalization-in-python-b79592732b79) [](/how-and-why-to-standardize-your-data-996926c2c832) [## Scikit-Learn çš„æ ‡å‡†å®šæ ‡å™¨å¦‚ä½•å·¥ä½œ

### åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†è§£é‡Šä¸ºä»€ä¹ˆä»¥åŠå¦‚ä½•ä½¿ç”¨ scikit-learn åº”ç”¨æ ‡å‡†åŒ–

towardsdatascience.com](/how-and-why-to-standardize-your-data-996926c2c832)**