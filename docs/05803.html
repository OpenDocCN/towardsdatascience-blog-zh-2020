<html>
<head>
<title>A One-Stop Guide to Computer Vision — part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉一站式指南—第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-one-stop-guide-to-computer-vision-96f72025f82d?source=collection_archive---------50-----------------------#2020-05-13">https://towardsdatascience.com/a-one-stop-guide-to-computer-vision-96f72025f82d?source=collection_archive---------50-----------------------#2020-05-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8cd8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">计算机视觉与 GluonCV 模型动物园</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c1744fd92c1ddc9a7108c15e91aeb5e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wF0jVZLyK2demeqf"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">弗拉德·希利塔努在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="2892" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/a-one-stop-guide-to-computer-vision-part-2-f5db1b025588">第二部分</a>:设计你自己的神经网络</p><h1 id="b5fa" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">介绍</h1><p id="129c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">对于我们人类来说，图像很容易理解。我们能够识别一幅图像是一只狗还是一只猫，一幅图像是否有一个红球，或者计算一幅图像中的人数。这些任务对计算机来说并不容易。</p><h1 id="8e3d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">什么是计算机视觉？</h1><p id="fb8d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">计算机视觉允许你的计算机理解图像。但是怎么做呢？</p><p id="b0dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简单来说:</p><ol class=""><li id="b73f" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">你所有的图像都是由像素组成的。每个像素都有一个 RGB 值，分别代表红、蓝、绿。这三种颜色的组合可以创造出任何想象得到的颜色。</li><li id="841b" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">您的计算机将这些像素“视为”数字。数字对计算机来说更容易理解。</li><li id="47ff" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">这些数字的组合形成了您的图像，因此，您的计算机现在能够“看到”您的图像。</li><li id="501b" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">一个图像带有一个标签，以表明这个图像是什么(狗，猫，球，树，船等)。).</li><li id="4ea4" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">类似于你教婴儿/狗的方法，你给电脑看一个图像，告诉他这是一只狗。你给电脑看另一张图片，告诉他这是一只猫。</li><li id="af23" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">步骤 5 被重复数百万/数十亿次。</li><li id="a8e1" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">下次当你问计算机什么是图像时，它会很有把握地给你一个答案(比如 80%是船，10%是人，10%是鸟)。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/9cb857beba570db39aebfb399cb2d1fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/0*B2gKbiC4pJWrWm2a"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://static.consolia-comic.com/comics/computer-vision.png" rel="noopener ugc nofollow" target="_blank">控制台上的<a class="ae kv" href="https://www.reddit.com/user/deadBuiltIn" rel="noopener ugc nofollow" target="_blank"> deadbuiltin </a>拍摄的照片-漫画</a></p></figure><h2 id="92e0" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">计算机视觉有 4 个主要任务:</h2><ol class=""><li id="8dc6" class="mp mq iq ky b kz mk lc ml lf nq lj nr ln ns lr mu mv mw mx bi translated">图像分类-图像分类允许您对图像进行分类，是狗、猫、梨还是苹果。</li><li id="0a02" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">对象检测—对象检测允许您在图像中检测一个以上的对象。将绘制一个边界框来封装检测到的对象。</li><li id="9bea" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">语义分割——语义分割允许您将图像中的对象分为不同的类别，如动物、环境、食物。</li><li id="4e62" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">实例分割-实例分割是语义分割的一个更复杂的版本，在每个类别中，实例分割允许您区分同一类别下的不同对象(例如，动物-蛇、兔子、狗)。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/25867549e2858cfa6a7b6866f5751f34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*1TGZjeoEhdaEGs2W14Re7g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图来自<a class="ae kv" href="https://gluon-cv.mxnet.io/contents.html" rel="noopener ugc nofollow" target="_blank"> GluonCV </a></p></figure><blockquote class="nu nv nw"><p id="cfc2" class="kw kx nx ky b kz la jr lb lc ld ju le ny lg lh li nz lk ll lm oa lo lp lq lr ij bi translated">为什么我们不对每个任务都使用实例分段呢？</p></blockquote><p id="9a41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个模型都有自己的权衡。越复杂，越慢，越贵。越简单越快越便宜。如果您只是希望程序检测图像中是否有球，那么使用最昂贵的实例分割是没有意义的。</p></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="c636" class="ls lt iq bd lu lv oi lx ly lz oj mb mc jw ok jx me jz ol ka mg kc om kd mi mj bi translated">简介:GluonCV</h1><p id="9694" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">为了实用从零开始开发自己的计算机视觉模型是疯狂的。当您可以使用研究人员预先训练的模型获得更好的结果时，为什么要花费大量的时间和金钱来构建您自己的模型呢？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/117ca7b369d7e2f7120fd2e79b903718.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*T7n4RHRhdnjGVDYr.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">通过<a class="ae kv" href="https://www.cartoonstock.com/directory/w/work_smarter.asp" rel="noopener ugc nofollow" target="_blank">卡通库存</a>向<a class="ae kv" href="https://www.cartoonstock.com/sitesearch.asp?artists=102" rel="noopener ugc nofollow" target="_blank">迈克·鲍德温</a>致谢</p></figure><p id="2306" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MXNet 是一个开源的深度学习框架。MXNet 提供了一个名为 Gluon 的高级 API。Gluon 为几个任务提供了几个工具包:</p><ol class=""><li id="a583" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">Glu oncv——计算机视觉</li><li id="0bf8" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">gluonlp—用于自然语言处理</li><li id="d253" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">GluonTS —用于时间序列处理</li></ol><p id="eb1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据 GluonCV 的说法:</p><blockquote class="nu nv nw"><p id="4869" class="kw kx nx ky b kz la jr lb lc ld ju le ny lg lh li nz lk ll lm oa lo lp lq lr ij bi translated">G <!-- --> luonCV 提供计算机视觉领域最先进(SOTA)深度学习算法的实现。它旨在帮助工程师、研究人员和学生快速制作产品原型、验证新想法和学习计算机视觉。</p></blockquote><p id="7c5d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GluonCV 拥有大量模型，这些模型已经由知名机构和研究人员进行了微调，这些机构和研究人员使用难以想象的计算能力和时间在数年内收集了大量数据。所有预先训练好的模型都被安置在<a class="ae kv" href="https://gluon-cv.mxnet.io/model_zoo/index.html" rel="noopener ugc nofollow" target="_blank">模型动物园</a>的 GluonCV 里。</p><p id="f8dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章之后，你应该能够用<a class="ae kv" href="https://gluon-cv.mxnet.io/contents.html" rel="noopener ugc nofollow" target="_blank">gluo cv 和 MXNet </a>完成所有 4 个计算机视觉任务。</p></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="676e" class="ls lt iq bd lu lv oi lx ly lz oj mb mc jw ok jx me jz ol ka mg kc om kd mi mj bi translated">设置 MXNet 和 GluonCV</h1><p id="07f3" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">整篇文章只需要你下载 2 个包——MXNet 和 GluonCV。您可以使用以下命令来完成此操作:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="b3a0" class="ne lt iq op b gy ot ou l ov ow">pip install mxnet<br/>pip install gluoncv</span></pre><p id="36f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您想利用您的 CPU/GPU 或 TPU 进行处理，您只需<a class="ae kv" href="https://mxnet.apache.org/get_started/?" rel="noopener ugc nofollow" target="_blank">更改安装命令</a>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/066a90ab3188db56994f4c8736c965a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OxA6gm-Y-F5TvqALOJCVaw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图来自<a class="ae kv" href="https://mxnet.apache.org/get_started/?version=v1.5.1&amp;platform=windows&amp;language=python&amp;processor=gpu&amp;environ=pip&amp;" rel="noopener ugc nofollow" target="_blank"> MXNet </a></p></figure><p id="a59d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们开始之前，记得导入已安装的包(如果您还没有这样做，请下载 numpy 和 matplotlib):</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="fb69" class="ne lt iq op b gy ot ou l ov ow">import mxnet as mx<br/>import gluoncv as gcv<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span></pre></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="41b5" class="ls lt iq bd lu lv oi lx ly lz oj mb mc jw ok jx me jz ol ka mg kc om kd mi mj bi translated">图像分类</h1><p id="edcb" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">点击<a class="ae kv" href="https://gluon-cv.mxnet.io/model_zoo/classification.html" rel="noopener ugc nofollow" target="_blank">这里</a>查看文档。有许多模型可用于每个 CV 任务。这些模型中的每一个都用不同数量的图像和标签来训练，因此将具有不同的超参数集。例如，ImageNet22k 在超过 1400 万张图像上进行训练，可以预测超过 22，000 个类别。下图显示了每个型号的精度和速度之间的权衡。自然，精度越高，速度就会越低。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/31733408f631a2653b9be244d1acab6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*WqH2h7KmHBSUM4ncXnDIFA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图来自<a class="ae kv" href="https://gluon-cv.mxnet.io/model_zoo/classification.html" rel="noopener ugc nofollow" target="_blank"> GluonCV </a></p></figure><p id="b002" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对图像进行分类只需 4 个步骤:</p><h2 id="8571" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">1.下载图像</h2><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="601c" class="ne lt iq op b gy ot ou l ov ow">image_url = "<a class="ae kv" href="https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/classification/mt_baker.jpg" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/classification/mt_baker.jpg</a>"</span><span id="f4af" class="ne lt iq op b gy oz ou l ov ow">image_filepath = 'mt_baker.jpg'<br/>gcv.utils.download(url=image_url,path = image_filepath)</span></pre><p id="1f42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以使用任何你想要的图片，只需简单地编辑链接。我们将使用贝克山的图像。接下来，我们将可视化图像并探索图像:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="281d" class="ne lt iq op b gy ot ou l ov ow">image = mx.image.imread('mt_baker.jpg')</span><span id="5f10" class="ne lt iq op b gy oz ou l ov ow">print("shape:",image.shape)<br/>print("data type:",image.dtype)<br/>print("min value:",image.min().asscalar())<br/>print("max value:",image.max().asscalar())</span></pre><p id="0890" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一行将我们的图像设置为一个变量。接下来的 4 行打印出图像的细节，结果如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/a1e4c1822fc4dd934ee1636bae776245.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*5EYtKru9oMdgXJyy305PEQ.png"/></div></figure><p id="d779" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">形状是三维的(HCW ),因为它由高度、宽度和通道组成。高度和宽度表示图像的垂直和水平长度，通道表示图像的深度。由于图像由 RGB 颜色组成，因此深度仅为 3:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/bbbc60f05ae252f959bf6e9ec8a4b0bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/0*9lFP7sQWQEKHMTaD.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781789613964/2/ch02lvl1sec21/convolution-on-rgb-images" rel="noopener ugc nofollow" target="_blank"> packtpub </a></p></figure><p id="836a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据类型是用<a class="ae kv" href="https://medium.com/p/96f72025f82d#8e3d" rel="noopener">整数</a>填充的 numpy 数组，最小值为 0，最大值为<a class="ae kv" href="https://kb.iu.edu/d/aetf" rel="noopener ugc nofollow" target="_blank"> 255 </a>。最后，让我们想象一下这幅图像:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="2181" class="ne lt iq op b gy ot ou l ov ow">plt.imshow(image.asnumpy())</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/e25ca5ae21ac46b79fb9050531515824.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*LrpTZwBZd6aEWA4okJUMkA.png"/></div></figure><h2 id="6757" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">2.转换数据</h2><p id="2542" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">GluonCV 要求您的图像符合以下标准:</p><ol class=""><li id="375c" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">数据的形式必须是“批次数量、通道、高度、宽度(NCHW)”而不是“HWC”。通常，我们不仅仅用一幅图像来训练我们模型，我们用成千上万幅图像来训练它们。我们也不会一张一张地传入图像。我们一批一批地传入图像<em class="nx">。</em>然后在 NCHW 的 N 部分显示每批图像的数量。</li><li id="1e97" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">数据类型必须是 float 的 numpy 数组，而不是整数。</li><li id="6240" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">图像值必须归一化，以 0 为中心，标准偏差为 1。</li></ol><p id="3be9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不用担心，所有这些步骤都可以通过一个命令完成:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="f9a1" class="ne lt iq op b gy ot ou l ov ow">image = gcv.data.transforms.presets.imagenet.transform_eval(image)</span><span id="3aa4" class="ne lt iq op b gy oz ou l ov ow">print("shape:",image.shape)<br/>print("data type:",image.dtype)<br/>print("min value:",image.min().asscalar())<br/>print("max value:",image.max().asscalar())</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/9b2c4893bb0bc232bdede7bbeb14e6a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*ItOqdalBrqfUmO6zRqxNFQ.png"/></div></figure><h2 id="2c7b" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">3.准备模型</h2><p id="7674" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们将使用 ResNet 50 型号。我们将使用模型的预训练版本。</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="3f8e" class="ne lt iq op b gy ot ou l ov ow">network = gcv.model_zoo.get_model("resnet50_v1d", pretrained=True)</span></pre><p id="339e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要查找您可以使用的所有型号的列表，只需键入:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="62f5" class="ne lt iq op b gy ot ou l ov ow">gcv.model_zoo.get_model_list()</span></pre><p id="c8f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有模型都将下载到您的本地 mxnet 缓存中。您可以在此查看尺寸:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="e8e7" class="ne lt iq op b gy ot ou l ov ow">!ls -sh C:/Users/&lt;your username&gt;/.mxnet/models</span></pre><h2 id="4cc3" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">4.给我们的形象分类</h2><p id="5807" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">预测只需一行代码即可完成:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="be80" class="ne lt iq op b gy ot ou l ov ow">prediction = network(image)</span></pre><p id="a0a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于我们只输入了 1 幅图像，我们将检索结果的第一个索引:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="ebfd" class="ne lt iq op b gy ot ou l ov ow">prediction = prediction[0]</span></pre><p id="a8c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nx">预测</em>存储该图像所属的每个类别的<strong class="ky ir">原始</strong>概率。由于 ResNet 50 能够预测 1000 个类，因此<em class="nx">预测</em>的长度将是 1000。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/bbca397b1c0bb0643701237246ace67b.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/1*6lBIuI9ZNOi-luoFuFev8Q.png"/></div></figure><p id="adbd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以检索 ResNet 50 模型能够预测的所有类的列表，应该有 1000 个:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/8e015ae6ef7d1e9af3b6ba7c2974243f.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*ACh0AqAHFntjZoSANWIlkQ.png"/></div></figure><p id="aa2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预测存储模型输出的原始概率。解释它们是没有意义的，因为有些概率是负的。因此，我们将使用一个<a class="ae kv" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> softmax </a>函数来转换所有的概率，使其介于 0 和 1 之间:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="d176" class="ne lt iq op b gy ot ou l ov ow">probability = mx.nd.softmax(prediction)</span></pre><p id="d6e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们检索前 5 个预测类:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="fe98" class="ne lt iq op b gy ot ou l ov ow">k = 5<br/>topk_indices = mx.nd.topk(probability, k=5)</span><span id="9c6b" class="ne lt iq op b gy oz ou l ov ow">for i in range(k):<br/>    class_index = topk_indices[i].astype('int').asscalar()<br/>    class_label = network.classes[class_index]<br/>    class_probability = probability[class_index]<br/>    print("#{} {} ({:0.3}%)".format(i+1,class_label,class_probability.asscalar()*100))</span></pre><p id="ebde" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果是这样的:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/adf0d4fee02481d429ceb2dfbf580618.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*JXw7aPzTZhcwFAu8HpbuvQ.png"/></div></figure><p id="4705" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GluonCV 有 84.1%的把握预测这是一张火山的图像。因为 ResNet 50 没有专门针对贝克山的类，所以火山是我们能得到的最接近的了。</p></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="dce5" class="ls lt iq bd lu lv oi lx ly lz oj mb mc jw ok jx me jz ol ka mg kc om kd mi mj bi translated">目标检测</h1><p id="3e01" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">点击<a class="ae kv" href="https://gluon-cv.mxnet.io/model_zoo/detection.html" rel="noopener ugc nofollow" target="_blank">这里</a>查看文档。你会发现这部分和<a class="ae kv" href="https://medium.com/p/96f72025f82d#41b5" rel="noopener">图像分类</a>很像。然而，不使用 ResNet 50，我们将使用<a class="ae kv" rel="noopener" target="_blank" href="/review-yolov3-you-only-look-once-object-detection-eab75d7a1ba6"> YOLO V3 </a>，这是一个非常快速的对象检测模型。</p><h2 id="d0a7" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">1.下载图像</h2><p id="2f98" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">让我们使用另一个包含几个对象的图像:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="d81f" class="ne lt iq op b gy ot ou l ov ow">image_url = "<a class="ae kv" href="https://raw.githubusercontent.com/zhreshold/mxnet-ssd/master/data/demo/dog.jpg" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/zhreshold/mxnet-ssd/master/data/demo/dog.jpg</a>"</span><span id="d6e2" class="ne lt iq op b gy oz ou l ov ow">image_filepath = 'dog.jpg'<br/>gcv.utils.download(url=image_url,path = image_filepath)</span></pre><p id="4aeb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们来探究一下数据。这一部分与您之前所做的非常相似。</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="04ca" class="ne lt iq op b gy ot ou l ov ow">image = mx.image.imread(image_filepath)</span><span id="9a0d" class="ne lt iq op b gy oz ou l ov ow">print("shape:",image.shape)<br/>print("data type:",image.dtype)<br/>print("min value:",image.min().asscalar())<br/>print("max value:",image.max().asscalar())</span><span id="322e" class="ne lt iq op b gy oz ou l ov ow">plt.imshow(image.asnumpy())</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/04543b3b03645d877551941b39329452.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*RXNilmliXYvQ7NpQk_AzGw.png"/></div></figure><h2 id="0d56" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">2.转换数据</h2><p id="765e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">由于我们使用的是另一种模型，我们必须将数据转换成另一种适合 YOLO V3 的格式。不用担心，这也可以用一行代码完成:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="7b8e" class="ne lt iq op b gy ot ou l ov ow">image, chw_image = gcv.data.transforms.presets.yolo.transform_test(image, short=512)</span></pre><p id="cfde" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在有两个图像，而不是一个变换后的图像，即<em class="nx">图像</em>和<em class="nx"> chw_image。图像</em>由您的原始图像组成，而<em class="nx"> chw_image c </em>由您的转换图像组成。变量<em class="nx"> short=512 </em>用于指示图像的宽度，同时仍然保持纵横比。</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="13f1" class="ne lt iq op b gy ot ou l ov ow">print("shape:",image.shape)<br/>print("data type:",image.dtype)<br/>print("min value:",image.min().asscalar())<br/>print("max value:",image.max().asscalar())</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/f43e2e5472cdaf9b589f19f00e3fb0d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*iL1ZdCD0kern9cQqGQZXVw.png"/></div></figure><h2 id="3b68" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">3.准备模型</h2><p id="f8dd" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这是我们将使用的模型:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="31cd" class="ne lt iq op b gy ot ou l ov ow">network = gcv.model_zoo.get_model('yolo3_darknet53_coco',pretrained=True)</span></pre><h2 id="9c14" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">4.打开结果</h2><p id="2ddc" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">然而，这一次，我们的预测返回给我们 3 个项目:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="4c50" class="ne lt iq op b gy ot ou l ov ow">prediction = network(image)<br/>for index,array in enumerate(prediction):<br/>    print('#{} shape: {}'.format(index+1,array.shape))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/8d0e108a2ee08d1adc7aba10beb1647e.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*kjDsKW2d0bHjlb2eRBOYow.png"/></div></figure><ul class=""><li id="7700" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr pj mv mw mx bi translated">第一项是类别标签。它告诉我们检测到的类的索引。请记住，您可以使用 network.classes 获得类名。</li><li id="aa76" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr pj mv mw mx bi translated">第二项是预测概率。</li><li id="2a97" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr pj mv mw mx bi translated">第三个项目是一个边界框数组。因为你需要 4 个角来组成一个盒子，所以会有一个 4 坐标的列表。</li></ul><p id="7800" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，还有一些细微的区别:</p><ol class=""><li id="7761" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">您不必对概率应用 softmax 函数。</li><li id="29bf" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">类别和概率已经为您按降序排序。</li></ol><p id="a07c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看一些例子:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="272c" class="ne lt iq op b gy ot ou l ov ow">prediction = [array[0] for array in prediction] #since we only input 1 image<br/>class_indices, probabilities, bounding_boxes = prediction #unpacking</span><span id="dd94" class="ne lt iq op b gy oz ou l ov ow">#Let's  list the top 10 items<br/>k = 10<br/>print(class_indices[:k])<br/>print(probabilities[:k])<br/>print(bounding_boxes[:k])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/fdd71c11dd96c03974c3ee62bddb15f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:158/format:webp/1*bhpjSyhu0TPGJBWciuGB9w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">十大类指数</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/4cdf35785826b4ffd331ec8a54bd442b.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/1*yR_5N08WTARDaf7LZkpZXA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">十大可能性</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/1da4cdf2542a9c14e6712b2615b83e03.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*X0KDoiBMnVfFmpIjW0QpRg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">边界框的坐标</p></figure><p id="09fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意“-1”是一个特殊的类，这意味着没有检测到任何对象。</p><h2 id="fac5" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">5.在对象周围绘制方框</h2><p id="f3da" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在我们有了坐标，让我们给我们的图像加标签吧！</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="e5c2" class="ne lt iq op b gy ot ou l ov ow">gcv.utils.viz.plot_bbox(chw_image,<br/>                       bounding_boxes,<br/>                       probabilities,<br/>                       class_indices,<br/>                       class_names=network.classes)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/2ca0af36be3b3ed5710d064280a3c6cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*DpjSOddLxda-fHuZcT-lZA.png"/></div></figure></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="29e3" class="ls lt iq bd lu lv oi lx ly lz oj mb mc jw ok jx me jz ol ka mg kc om kd mi mj bi translated">图象分割法</h1><p id="96c5" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">点击<a class="ae kv" href="https://gluon-cv.mxnet.io/model_zoo/segmentation.html" rel="noopener ugc nofollow" target="_blank">这里</a>查看文档。</p><h2 id="ce3b" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">语义分割</h2><p id="b353" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">语义分割旨在对图像中的每个像素进行分类。它将在进行分段级预测之前查看图像的完整上下文。之后，该模型将使用不同的颜色来覆盖图像的所有像素，以将它们分类。在本节中，背景类被标记为-1。</p><p id="b172" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本节将使用 FCN ResNet ADE，这是一个具有 ResNet 架构的全连接神经网络，在<a class="ae kv" href="https://groups.csail.mit.edu/vision/datasets/ADE20K/" rel="noopener ugc nofollow" target="_blank"> ADE20K </a>数据集上进行训练。</p><h2 id="bf65" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">1.下载图像</h2><p id="7671" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">该部分与<a class="ae kv" href="https://medium.com/p/96f72025f82d#dce5" rel="noopener">物体检测</a>完全相同。如果你愿意，可以跳过这一步</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="dd43" class="ne lt iq op b gy ot ou l ov ow">image_url = "<a class="ae kv" href="https://raw.githubusercontent.com/zhreshold/mxnet-ssd/master/data/demo/dog.jpg" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/zhreshold/mxnet-ssd/master/data/demo/dog.jpg</a>"</span><span id="d41f" class="ne lt iq op b gy oz ou l ov ow">image_filepath = 'dog.jpg'<br/>gcv.utils.download(url=image_url,path = image_filepath)</span></pre><h2 id="55ff" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">2.转换数据</h2><p id="d265" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这一部分没有一行代码。您必须定义自己的函数来转换数据:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="1c72" class="ne lt iq op b gy ot ou l ov ow">from mxnet.gluon.data.vision import transforms</span><span id="cbeb" class="ne lt iq op b gy oz ou l ov ow">transform_fn = transforms.Compose([<br/>    transforms.ToTensor(),<br/>    transforms.Normalize([.485, .456, .406], [.229, .224, .225])<br/>])</span><span id="3057" class="ne lt iq op b gy oz ou l ov ow">image = transform_fn(image)<br/>print("shape:",image.shape)<br/>print("data type:",image.dtype)<br/>print("min value:",image.min().asscalar())<br/>print("max value:",image.max().asscalar())</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi po"><img src="../Images/74cc7bae03617d66b76f82d120f9023c.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*4y8m4t1UBxBnLncVmyGrCA.png"/></div></figure><p id="54ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ToTensor()将图像从 HWC 格式转换为 CHW 格式，并将数据类型从 8 位整数转换为 32 位浮点数。然后根据 ImageNet one case 统计对图像进行归一化。</p><p id="5d0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如前所述，我们通常逐批预测图像。尽管我们只预测了一个图像，我们仍然需要指定批量大小:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="5e84" class="ne lt iq op b gy ot ou l ov ow">image = image.expand_dims(0)</span></pre><h2 id="26d8" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">3.准备模型:</h2><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="19e8" class="ne lt iq op b gy ot ou l ov ow">network = gcv.model_zoo.get_model('fcn_resnet50_ade',pretrained=True)</span></pre><h2 id="a0cd" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">4.打开结果</h2><p id="db23" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">为了加快速度，我们将申请。向我们的网络演示。更长的版本可以在实例分段下找到。</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="1006" class="ne lt iq op b gy ot ou l ov ow">output = network.demo(image)<br/>print(output.shape)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/d6c9fca149d777d4008758acd3085f66.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/1*W2YCdZpNlRWZEZJzoR5RmQ.png"/></div></figure><p id="3a89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">只有 1 个图像，150 个预测类，图像的宽度为 576，高度为 768。</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="99b6" class="ne lt iq op b gy ot ou l ov ow">output = output[0] # since there is only 1 image in this batch<br/>prediction = mx.nd.argmax(output,0).asnumpy() # to get index of largest probability</span></pre><h2 id="39a3" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">5.给我们的形象上色</h2><p id="955d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在，让我们给我们的图像着色来分割它们:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="e6b7" class="ne lt iq op b gy ot ou l ov ow">from gluoncv.utils.viz import get_color_pallete</span><span id="3fb5" class="ne lt iq op b gy oz ou l ov ow">prediction_image = get_color_pallete(prediction, 'ade20k')<br/>prediction_image</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pq"><img src="../Images/70c187694248bcb41937b29713f32429.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H1nvKVacT6U10C7XucwwFw.png"/></div></div></figure><h2 id="8fd3" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">实例分割</h2><p id="402f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">实例分割能够识别一个人不同于另一个人。我们可以预测这些像素的确切边界和颜色，而不是边界框。</p><p id="075e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这要归功于 gluonvc 的原始文档:<a class="ae kv" href="https://gluon-cv.mxnet.io/build/examples_instance/demo_mask_rcnn.html#sphx-glr-build-examples-instance-demo-mask-rcnn-py" rel="noopener ugc nofollow" target="_blank">https://gluon-cv . mxnet . io/build/examples _ instance/demo _ mask _ rcnn . html # sphx-glr-build-examples-instance-demo-mask-rcnn-py</a></p><h2 id="bce5" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">1.下载图像</h2><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="83a4" class="ne lt iq op b gy ot ou l ov ow">image = gcv.utils.download('<a class="ae kv" href="https://github.com/dmlc/web-data/blob/master/'" rel="noopener ugc nofollow" target="_blank">https://github.com/dmlc/web-data/blob/master/'</a> +<br/>                          'gluoncv/detection/biking.jpg?raw=true',<br/>                          path='biking.jpg')</span></pre><h2 id="9cc1" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">2.转换数据</h2><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="3d10" class="ne lt iq op b gy ot ou l ov ow">x, orig_img = gcv.data.transforms.presets.rcnn.load_test(image)</span></pre><h2 id="33e6" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">3.准备模型</h2><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="9cd0" class="ne lt iq op b gy ot ou l ov ow">network = gcv.model_zoo.get_model('mask_rcnn_resnet50_v1b_coco', pretrained=True)</span></pre><h2 id="681a" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">4.打开结果</h2><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="60b0" class="ne lt iq op b gy ot ou l ov ow">ids, scores, bboxes, masks = [xx[0].asnumpy() for xx in network(x)]</span></pre><h2 id="9ef1" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">5.在图像上绘画</h2><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="0c07" class="ne lt iq op b gy ot ou l ov ow"># paint segmentation mask on images directly<br/>width, height = orig_img.shape[1], orig_img.shape[0]<br/>masks, _ = gcv.utils.viz.expand_mask(masks, bboxes, (width, height), scores)<br/>orig_img = gcv.utils.viz.plot_mask(orig_img, masks)<br/>plt.imshow(orig_img)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/4d26709e7d6073a897d42e61ae33ba38.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*g79OZzvGW2pFO28bgEPSng.png"/></div></figure><p id="3dba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们添加一些框:</p><pre class="kg kh ki kj gt oo op oq or aw os bi"><span id="018e" class="ne lt iq op b gy ot ou l ov ow"># identical to Faster RCNN object detection<br/>fig = plt.figure(figsize=(10, 10))<br/>ax = fig.add_subplot(1, 1, 1)<br/>ax = gcv.utils.viz.plot_bbox(orig_img, bboxes, scores, ids,<br/>                         class_names=network.classes, ax=ax)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ps"><img src="../Images/c8d1d42f0a44efd2320bf1980cf068f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xegBwCD0i08r4dgpI_LXFA.png"/></div></div></figure><h1 id="b9a9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="5c6c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">恭喜你！你只用一个框架就完成了 4 个主要的计算机视觉任务！</p><p id="c42a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一定要尝试不同的型号，确定哪种最适合你。记住:更复杂的模型不一定是最好的模型。</p><p id="f9a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">理解业务需求非常重要。选择最符合您目的的型号。凡事总有取舍。花一些时间浏览文档，以确定哪个模型架构和哪个类标签最适合您的需要。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pt"><img src="../Images/65af457d4c59a6b08e48c5a8b730537c.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/0*PZX4mH6u-k9BALBd.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://xkcd.com/1838/" rel="noopener ugc nofollow" target="_blank"> kxcd </a></p></figure><h1 id="402c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><ol class=""><li id="31fc" class="mp mq iq ky b kz mk lc ml lf nq lj nr ln ns lr mu mv mw mx bi translated">【https://medium.com/r/? T2】URL = https % 3A % 2F % 2f gluon-cv . mxnet . io % 2f contents . html</li><li id="6d6b" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">【https://www.coursera.org/learn/aws-computer-vision-gluoncv/ T4】</li><li id="0438" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><a class="ae kv" href="https://gluon-cv.mxnet.io/build/examples_instance/demo_mask_rcnn.html#sphx-glr-build-examples-instance-demo-mask-rcnn-py" rel="noopener ugc nofollow" target="_blank">https://gluon-cv . mxnet . io/build/examples _ instance/demo _ mask _ rcnn . html # sphx-glr-build-examples-instance-demo-mask-rcnn-py</a></li></ol></div></div>    
</body>
</html>