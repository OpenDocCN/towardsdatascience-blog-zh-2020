<html>
<head>
<title>Bank Institution Term Deposit Predictive Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">银行机构定期存款预测模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bank-institution-term-deposit-predictive-model-83afe1d2b08c?source=collection_archive---------23-----------------------#2020-09-02">https://towardsdatascience.com/bank-institution-term-deposit-predictive-model-83afe1d2b08c?source=collection_archive---------23-----------------------#2020-09-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7d37" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">循序渐进的方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0d46ea614e679c951310e8cc73d882bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RVPRxqz2VUuY7NGXSXzmtw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com/s/photos/data-science?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@kmuza?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Carlos Muza </a>拍摄的照片</p></figure><p id="cfeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢<a class="ae ky" href="https://www.10academy.org/" rel="noopener ugc nofollow" target="_blank"> 10 学院</a>培训项目，通过参与不同的项目，我了解了许多数据科学概念，每个项目都以自己的方式面临挑战。</p><p id="f9d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">银行机构定期存款预测模型</strong>是我觉得有意思的一个项目。它的主要目标是建立一个模型，预测客户是否会订阅银行定期存款，本文旨在分享我建立模型的一步一步的方法。</p><h2 id="e4b8" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">内容</h2><ul class=""><li id="4fa9" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">数据</li><li id="69b4" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">探索性数据分析</li><li id="94a9" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">数据预处理</li><li id="6967" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">机器学习模型</li><li id="1165" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">比较结果</li><li id="a44b" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">预言；预测；预告</li><li id="a81d" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">结论</li><li id="a90b" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">继续教育</li></ul><h2 id="bd29" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">数据</h2><p id="8c73" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">此项目中使用的数据集(Bank-additional-full.csv)包含银行客户的数据。数据集及其信息可以在这里<a class="ae ky" href="http://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank">获得</a>。执行数据分析的第一步是导入必要的库和数据集。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="8392" class="lv lw it ni b gy nm nn l no np"># importing the necessary libraries<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import matplotlib as mpl<br/>import seaborn as sns<br/><br/>import warnings<br/>warnings.filterwarnings('ignore')</span><span id="7703" class="lv lw it ni b gy nq nn l no np">#importing the dataset<br/>dataset = pd.read_csv('bank-additional-full.csv', sep=';')<br/>dataset.name = 'dataset'<br/>dataset.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/171e2b79607f5a4207fe2cc2545af56b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*saBUNmCepjYvz0mjuDTMxQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="4ceb" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">探索性数据分析</h2><p id="7ef6" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">EDA 是机器学习模型开发的重要组成部分，因为它帮助我们理解我们的数据并提取有用的见解，这将有助于<a class="ae ky" href="https://en.wikipedia.org/wiki/Feature_engineering#:~:text=Feature%20engineering%20is%20the%20process,as%20applied%20machine%20learning%20itself." rel="noopener ugc nofollow" target="_blank">特征工程</a>。本项目中执行的一些 EDA 包括但不限于以下内容:</p><ul class=""><li id="0cf3" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">数据集的形状和大小</strong></li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="6c25" class="lv lw it ni b gy nm nn l no np"># function to check the shape of a dataset<br/>def data_shape(data):<br/>    print(data.name,'shape:',data.shape)</span><span id="63e3" class="lv lw it ni b gy nq nn l no np"># function to check the size of a dataset<br/>def data_size(data):<br/>    print(data.name,'size:',data.size)</span><span id="2d0c" class="lv lw it ni b gy nq nn l no np"># Getting the shape of the dataset<br/>data_shape(dataset)</span><span id="7533" class="lv lw it ni b gy nq nn l no np"># Getting the size of the dataset<br/>data_size(dataset)</span></pre><p id="695e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集形状:(41188，21) <br/>数据集大小:864948</p><p id="8652" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">。shape </strong>返回数据集的行数和列数。</p><p id="9ab9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">。size </strong>返回数据中元素的数量，即行数乘以列数。</p><ul class=""><li id="26b2" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">信息和统计汇总</strong></li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="cef3" class="lv lw it ni b gy nm nn l no np"># function to ckeck the information of a dataset<br/>def data_info(data):<br/>    print(data.name,'information:')<br/>    print('---------------------------------------------')<br/>    print(data.info())<br/>    print('---------------------------------------------')</span><span id="ada6" class="lv lw it ni b gy nq nn l no np"># Getting the information of the dataset<br/>data_info(dataset)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/1ffb831306191e28ee9953e703ad3fa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*aTXtmqF3S0huG1ip-S8skQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4329" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">。info() </strong>用于获得数据集的简明摘要。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="7424" class="lv lw it ni b gy nm nn l no np"># Getting the statistical summary<br/>dataset.describe().T</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/f0a2bd4a968e3d96a06a32e3887d6fff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*67hIFmnZzcvVOwN7574iHg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="38bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">。describe() </strong>用于查看一些基本的统计细节，如百分位数、平均值、标准差等。数据集中的数字列。</p><ul class=""><li id="5731" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">唯一值和缺失值</strong></li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="f950" class="lv lw it ni b gy nm nn l no np"># function to get all unique values in the categorical variables<br/>def unique_val(data):<br/>    cols = data.columns<br/>    for i in cols:<br/>        if data[i].dtype == 'O':<br/>            print('Unique values in',i,'are',data[i].unique())<br/>            print('----------------------------------------------')</span><span id="0c6c" class="lv lw it ni b gy nq nn l no np"># Getting the unique values in the categorical columns<br/>unique_val(dataset)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/b5a9ca1c53295aabe2f2748407c2f9bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xvixKc6HJreoJpwEOWC4lw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="29a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">。unique() </strong>返回数据集分类列中的唯一值。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="c601" class="lv lw it ni b gy nm nn l no np"># function to check for missing values<br/>def missing_val(data):<br/>    print('Sum of missing values in', data.name)<br/>    print('------------------------------')<br/>    print(data.isnull().sum())<br/>    print('------------------------------')</span><span id="bf10" class="lv lw it ni b gy nq nn l no np"># Getting the missing values in the dataset<br/>missing_val(dataset)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ea3a8bb7133cc5ca92cb6baa5b2e2010.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*D5H4hcnhdxGcR-ejqqWDRQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="2829" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">。isnull()。sum() </strong>返回数据集中每一列缺失值的总和。幸运的是，我们的数据集没有缺失值。</p><ul class=""><li id="cd3f" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">分类变量和数值变量</strong></li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="b6d3" class="lv lw it ni b gy nm nn l no np"># Categorical variables<br/>cat_data = dataset.select_dtypes(exclude='number')<br/>cat_data.head()</span><span id="b8ca" class="lv lw it ni b gy nq nn l no np"># Numerical variables<br/>num_data = dataset.select_dtypes(include='number')<br/>num_data.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/4b4fe0227961c575deeae6785c5927a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*a-bJ2azt93qWRq-7zcfY-g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类变量</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/c32385bc2df63beba7af94d198eecf5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*o4vJ7hJS16piz6xQSlpvnQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数字变量</p></figure><p id="d281" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">。select _ dtypes(exclude = ' number)</strong>返回所有不具有数值数据类型的列。</p><p id="0664" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">。select _ dtypes(exclude = ' number)</strong>返回所有具有数字数据类型的列。</p><ul class=""><li id="afb0" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">单变量和双变量分析</strong></li></ul><p id="9750" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我利用 tableau(一种数据可视化工具)进行单变量和双变量分析，tableau 的故事可以在<a class="ae ky" href="https://public.tableau.com/views/ExploratoryDataAnalysis-Week6/ExploratoryDataAnalysis?:language=en&amp;:display_count=y&amp;:origin=viz_share_link" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><ul class=""><li id="17d3" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">相关性</strong></li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="ecda" class="lv lw it ni b gy nm nn l no np"># using heatmap to visualize correlation between the columns<br/>fig_size(20,10)<br/>ax = sns.heatmap(dataset.corr(), annot=True, fmt='.1g', <br/>                 vmin=-1, vmax=1, center= 0)</span><span id="a48d" class="lv lw it ni b gy nq nn l no np"># setting the parameters<br/>fig_att(ax, "Heatmap correlation between Data Features", <br/>        "Features", "Features", 35, 25, "bold")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/87d92cbc0a2f5e2e80d1c2c3dacdffd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4eW5fezlDlAFs22Qx__hsA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="3d95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相关性显示数据集中变量之间的关系。</p><ul class=""><li id="57a1" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">异常值</strong></li></ul><p id="f6b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Seaborn boxplot 是检查数据集异常值的方法之一。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="e188" class="lv lw it ni b gy nm nn l no np"># Using boxplot to identify outliers<br/>for col in num_data:<br/>    ax = sns.boxplot(num_data[col])<br/>    save(f"{col}")<br/>    plt.show()</span></pre><p id="849c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码将数据集中的数值列可视化，并使用四分位间距(IQR)方法处理检测到的异常值。代码可以在这个<a class="ae ky" href="https://github.com/gloryodeyemi/10AcademyWeeklyChallenges/tree/master/week6/notebooks" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>中找到。</p><p id="d988" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 EDA 过程中，我发现了我们的目标变量“y”——客户是否订阅了定期存款？(二进制:“是”，“否”)，是高度不平衡的，这可能会影响我们的预测模型。这一点很快就会被注意到，本文给出了一些处理职业不平衡的技巧。</p><h2 id="6890" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">数据预处理</h2><p id="e67d" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在构建机器学习模型时，对数据进行预处理以获得高效的模型是很重要的。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="bf1c" class="lv lw it ni b gy nm nn l no np"># create list containing categorical columns<br/>cat_cols = ['job', 'marital', 'education', 'default', 'housing',<br/>            'loan', 'contact', 'month', 'day_of_week', 'poutcome']</span><span id="bb01" class="lv lw it ni b gy nq nn l no np"># create list containing numerical columns<br/>num_cols = ['duration', 'campaign', 'emp.var.rate',"pdays","age",       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'previous']</span></pre><p id="abf2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在此阶段完成了以下预处理:</p><ul class=""><li id="e5d4" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">编码分类列</strong></li></ul><p id="8699" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习算法只读取数值，这就是为什么我们需要将分类值改为数值。我使用 pandas get_dummies 方法和类型转换对列进行一次性编码。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="f581" class="lv lw it ni b gy nm nn l no np"># function to encode categorical columns<br/>def encode(data):<br/>    cat_var_enc = pd.get_dummies(data[cat_cols], drop_first=False)<br/>    return cat_var_enc</span><span id="edc8" class="lv lw it ni b gy nq nn l no np"># defining output variable for classification<br/>dataset_new['subscribed'] = (dataset_new.y == 'yes').astype('int')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/67aa806dab591739f4abb39045f432b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pEFsGzkxMCQmC-V7ml_YeQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><ul class=""><li id="bcd5" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">重新调整数值列</strong></li></ul><p id="7fb2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一种数据预处理方法是重新调整我们的数字列；这有助于在特定范围内使我们的数据正常化。这里使用了 Sklearn 预处理 StandardScaler()。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="4c64" class="lv lw it ni b gy nm nn l no np"># import library for rescaling<br/>from sklearn.preprocessing import StandardScaler</span><span id="10a0" class="lv lw it ni b gy nq nn l no np"># function to rescale numerical columns<br/>def rescale(data):<br/>    # creating an instance of the scaler object<br/>    scaler = StandardScaler()<br/>    data[num_cols] = scaler.fit_transform(data[num_cols])<br/>    return data</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/cd5bd545c0ea1e1e904784600ce52d24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ecW8GNWsQEc0QD2JhUEmw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><ul class=""><li id="2bb8" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">指定因变量和自变量</strong></li></ul><p id="5d61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了继续建立我们的预测模型，我们必须指定我们的因变量和自变量。</p><p id="9b57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">独立变量—是被分析过程的输入。</p><p id="bb81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因变量—因变量是流程的输出。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="2dcc" class="lv lw it ni b gy nm nn l no np">X = data.drop(columns=[ "subscribed", 'duration'])<br/>y = data["subscribed"]</span></pre><p id="83f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">列“duration”已被删除，因为它对输出目标有很大影响(例如，如果 duration=0，则 y =“no”)。</p><ul class=""><li id="4026" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">分割数据集</strong></li></ul><p id="2b40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在构建机器学习模型时，总是将数据集分为训练集和测试集是合理的，因为这有助于我们评估模型的性能。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="90f8" class="lv lw it ni b gy nm nn l no np"># import library for splitting dataset<br/>from sklearn.model_selection import train_test_split</span><span id="8b4c" class="lv lw it ni b gy nq nn l no np"># split the data<br/>X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1,random_state=1)</span></pre><ul class=""><li id="0619" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">降维</strong></li></ul><p id="2708" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们有大量变量的情况下，建议考虑通过保留最重要的变量来减少这些变量，有各种技术可以做到这一点，例如:主成分分析、TSNE、自动编码器等。对于这个项目，我们将考虑 PCA。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="a53e" class="lv lw it ni b gy nm nn l no np"># import PCA<br/>from sklearn.decomposition import PCA</span><span id="4461" class="lv lw it ni b gy nq nn l no np"># create an instance of pca<br/>pca = PCA(n_components=20)      </span><span id="be89" class="lv lw it ni b gy nq nn l no np"># fit pca to our data<br/>pca.fit(X_train)<br/>pca_train = pca.transform(X_train)<br/>X_train_reduced = pd.DataFrame(pca_train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/a74bf8a4f02e62c4cee3eb6f15209694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eSkNb0IbLtene4NbFYxCmw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><ul class=""><li id="a8a5" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">阶层失衡</strong></li></ul><p id="9ebc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如前所述，我们有一个高度不平衡的阶层，如果不加以处理，这会影响我们的预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/c7b616548074ea891216394da883fa75.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*5LVeS4ASZ22R7vg6TNoj3w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="d5f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个项目中，我利用 SMOTE(合成少数过采样技术)来处理类不平衡。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="844c" class="lv lw it ni b gy nm nn l no np"># importing the necessary function <br/>from imblearn.over_sampling import SMOTE</span><span id="b08e" class="lv lw it ni b gy nq nn l no np"># creating an instance<br/>sm = SMOTE(random_state=27)</span><span id="28d3" class="lv lw it ni b gy nq nn l no np"># applying it to the training set<br/>X_train_smote, y_train_smote = sm.fit_sample(X_train_reduced, y_train)</span></pre><p id="051b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>对训练数据使用 SMOTE 为宜。</p><h2 id="7ca9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">机器学习模型</h2><p id="e6e9" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">咻！，我们终于成功地建立了模型；当试图建立机器学习模型时，数据预处理可能是如此困难。我们不要浪费时间，直接开始吧。</p><p id="7b6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本项目中考虑的机器学习算法包括:</p><ul class=""><li id="d82a" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated">逻辑回归</li><li id="1c87" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">XGBoost</li><li id="be44" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">多层感知器</li></ul><p id="e0a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所使用的交叉验证(这是非常重要的，尤其是在我们有不平衡类的情况下)方法包括:</p><ul class=""><li id="9d1f" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu"> K-Fold: </strong> K-Fold 将给定的数据集分割成 K 个部分/折叠，其中每个折叠在某个点被用作测试集。</li><li id="36ad" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">分层 K-Fold: </strong>这是返回分层褶皱的 K-Fold 的变体。折叠是通过保留每个类别的样本百分比来完成的。</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="504b" class="lv lw it ni b gy nm nn l no np"># import machine learning model libraries<br/>from sklearn.linear_model import LogisticRegression<br/>from xgboost import XGBClassifier<br/>from sklearn.neural_network import MLPClassifier</span><span id="b5d5" class="lv lw it ni b gy nq nn l no np"># import libraries for cross validation<br/>from sklearn.model_selection import KFold<br/>from sklearn.model_selection import StratifiedKFold<br/>from sklearn.model_selection import cross_validate</span><span id="838a" class="lv lw it ni b gy nq nn l no np">metrics = ['accuracy', 'roc_auc', f1', 'precision', 'recall']</span><span id="f9e3" class="lv lw it ni b gy nq nn l no np"># function to build machine learning models<br/>def model(model, cv_method, metrics, X_train, X_test, y_train):<br/>    if (model == 'LR'):<br/>        # creating an instance of the regression<br/>        model_inst = LogisticRegression()<br/>        print('Logistic Regression\n----------------------')<br/>    elif (model == 'XGB'):<br/>        # creating an instance of the classifier<br/>        model_inst = XGBClassifier()<br/>        print('XGBoost\n----------------------')<br/>    elif (model == 'MLP'):<br/>        # creating an instance of the classifier<br/>        model_inst = MLPClassifier()<br/>        print('Multi Layer Perceptron\n----------------------')<br/>    <br/>    # cross validation<br/>    if (cv_method == 'KFold'):<br/>        print('Cross validation: KFold\n--------------------------')<br/>        cv = KFold(n_splits=10, random_state=100)<br/>    elif (cv_method == 'StratifiedKFold'):<br/>        print('Cross validation: StratifiedKFold\n-----------------')<br/>        cv = StratifiedKFold(n_splits=10, random_state=100)<br/>    else:<br/>        print('Cross validation method not found!')<br/>    try:<br/>        cv_scores = cross_validate(model_inst, X_train, y_train, <br/>                                   cv=cv, scoring=metrics)   <br/>        # displaying evaluation metric scores<br/>        cv_metric = cv_scores.keys()<br/>        for metric in cv_metric:<br/>            mean_score = cv_scores[metric].mean()*100<br/>            print(metric+':', '%.2f%%' % mean_score)<br/>            print('')<br/>            <br/>    except:<br/>        metrics = ['accuracy', 'f1', 'precision', 'recall']<br/>        cv_scores = cross_validate(model_inst, X_train, y_train, <br/>                                   cv=cv, scoring=metrics)<br/>        # displaying evaluation metric scores<br/>        cv_metric = cv_scores.keys()<br/>        for metric in cv_metric:<br/>            mean_score = cv_scores[metric].mean()*100<br/>            print(metric+':', '%.2f%%' % mean_score)<br/>            print('')</span><span id="1205" class="lv lw it ni b gy nq nn l no np">    return model_inst</span></pre><p id="9c63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">评估指标</strong></p><ul class=""><li id="c7c3" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">精度:</strong>正确预测的数据点个数。对于不平衡的数据集，这可能是一个误导性的指标。因此，建议考虑其他评估指标。</li><li id="7874" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">AUC</strong>(ROC 曲线下的面积):它提供了对所有可能的分类阈值的综合性能测量。</li><li id="3a8e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">精度:</strong>计算为正确预测的正例数除以预测的正例总数的比率。</li><li id="36e4" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">召回:</strong>指被你的算法正确分类的相关结果总数的百分比。</li><li id="949a" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu"> F1 评分:</strong>这是准确率和召回率的加权平均值。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/0cb193a0f9092ddfe35265d0a5aa94db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*Qlci-IZk2P3PqHAweLOX1g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">k 倍交叉验证评估指标</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/3c0b9fd57f94061196cbe65e2e454863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*1_TJvqnmptee9W9F7VSfWQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分层 K 倍评估指标</p></figure><h2 id="1592" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">比较结果</strong></h2><ul class=""><li id="9caf" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated"><strong class="lb iu"> K 线折叠 vs 层状 k 线折叠</strong></li></ul><p id="ffe5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上表中可以看出，与 K 倍交叉验证相比，分层 K 倍验证呈现出更好的结果。K 倍交叉验证未能提供逻辑回归和 XGBoost 模型的 AUC 评分。因此，为了进一步比较，将使用分层的 K 倍结果。</p><ul class=""><li id="cff2" class="mo mp it lb b lc ld lf lg li ns lm nt lq nu lu mv mw mx my bi translated"><strong class="lb iu">机器学习模型</strong></li></ul><p id="ed0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从得到的结果来看，XGBoost 被证明是比逻辑回归和 MLP 更好的预测模型，因为它在 4/5 的评价指标中具有最高的百分比值。</p><h2 id="3926" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">预言；预测；预告</h2><p id="660e" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">XGboost 是性能最好的模型，用于预测。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="3e47" class="lv lw it ni b gy nm nn l no np"># fitting the model to the train data<br/>model_xgb = xgb.fit(X_train_smote, y_train_smote)</span><span id="dbb2" class="lv lw it ni b gy nq nn l no np"># make predictions<br/>y_pred = xgb.predict(X_test_pca)</span></pre><h2 id="659c" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">结论</h2><p id="8a51" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">这个项目的主要目标是建立一个模型来预测将订阅银行定期存款的客户，我们通过考虑三个不同的模型并使用最佳模型来进行预测，从而实现了这一目标。我们还经历了为模型准备数据和选择各种评估指标来衡量模型性能的严格步骤。</p><p id="8a4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在得到的结果中，我们观察到 XGBoost 是最好的模型，在 4/5 的评估指标中有很高的百分比值。</p><h2 id="6e40" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">深造</strong></h2><p id="0276" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在这个项目中，我只用了三种机器学习算法。然而，算法如；SVM、随机森林、决策树等。可以探索。</p><p id="67c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个项目的详细代码可以在这个<a class="ae ky" href="https://github.com/gloryodeyemi/10AcademyWeeklyChallenges/tree/master/week6" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>中找到。</p><p id="faa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我知道这是一个很长的旅程，但谢谢你陪我到最后。我也再次感谢学院和我的同学们给了我参与这个项目的绝佳机会。</p><h2 id="bb23" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">参考</h2><ul class=""><li id="b418" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated"><a class="ae ky" href="http://www.grammarly.com" rel="noopener ugc nofollow" target="_blank">语法检查器</a></li><li id="fa3d" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/methods-for-dealing-with-imbalanced-data-5b761be45a18">阶层失衡</a></li><li id="1f70" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><a class="ae ky" href="http://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank">数据集</a></li><li id="9cd5" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Feature_engineering#:~:text=Feature%20engineering%20is%20the%20process,as%20applied%20machine%20learning%20itself." rel="noopener ugc nofollow" target="_blank">特征工程</a></li><li id="5c1c" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/all-you-need-to-know-about-pca-technique-in-machine-learning-443b0c2be9a1">主成分分析</a></li><li id="df3a" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><a class="ae ky" href="https://public.tableau.com/en-gb/s/resources" rel="noopener ugc nofollow" target="_blank">画面</a></li><li id="6f7d" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank">机器学习算法</a></li></ul></div></div>    
</body>
</html>