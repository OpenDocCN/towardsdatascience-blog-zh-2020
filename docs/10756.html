<html>
<head>
<title>Analyzing the Performance of the Classification Models in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中分类模型的性能分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/analyzing-the-performance-of-the-classification-models-in-machine-learning-ad8fb962e857?source=collection_archive---------46-----------------------#2020-07-27">https://towardsdatascience.com/analyzing-the-performance-of-the-classification-models-in-machine-learning-ad8fb962e857?source=collection_archive---------46-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4906" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">探索混淆矩阵、ROC-AUC 曲线和机器学习中分类的成本函数的基础。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/84be62adf0fdd249210cdd2d744c7f27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BpPPlhIRgU036foL"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">萨法尔·萨法罗夫在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="0423" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">混淆矩阵</h1><p id="b733" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">混淆矩阵(也称为误差矩阵)用于分析分类模型(如逻辑回归、决策树分类器等)的好坏。)执行。我们为什么要分析模型的性能？分析模型的性能有助于我们发现并消除偏差和方差问题(如果存在)，也有助于我们微调模型，使模型产生更准确的结果。混淆矩阵通常用于二分类问题，但也可以扩展到多分类问题。</p><h1 id="f755" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">混淆矩阵的术语</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/03d22ef3bdc558960d6a117757b5e21f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*lK17g_LKDGcU7UjKlZn1tQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">二元分类的混淆矩阵。<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:ConfusionMatrixRedBlue.png" rel="noopener ugc nofollow" target="_blank">图片来源</a></p></figure><p id="9508" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">用例子来说明概念会更好理解，所以让我们考虑一个例子。让我们假设一个家庭去检测 COVID19。</p><p id="61fa" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">真阳性(TP): </strong>真阳性是被预测为阳性的病例，他们确实患有该疾病。</p><p id="9643" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">假阳性(FP): </strong>假阳性是已经被预测为阳性但他们并没有那种疾病的病例。</p><p id="4a4b" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">真阴性(TN): </strong>真阴性是被预测为阴性的病例，他们确实没有患那种疾病。</p><p id="d936" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">假阴性(FN): </strong>假阴性是已经被预测为阴性，但是他们患有该疾病的病例。</p><p id="cfdd" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">敏感度:</strong>敏感度又称为<strong class="lt iu">召回率和真阳性率</strong>。敏感度是实际阳性中被正确预测为阳性的比例。换句话说，敏感度是真阳性与真阳性和假阴性之和的比率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/50b0503f783e00d3e0d25feb4343da3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*kfGwwhSFYZbSHGmGhIvPrg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><p id="3671" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">特异性:</strong>特异性也叫<strong class="lt iu">真阴性率</strong>。特异性是被正确预测为阴性的实际阴性的比例。换句话说，特异性是真阴性与真阴性和假阳性之和的比率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/eb740e5d0b20f2d40c1e13d42a3c987c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*GN3ffx5aRP5Wz13usuFJVg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><p id="59e9" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">精度:</strong>精度是被正确预测为阳性的预测阳性的比例。换句话说，精度是真阳性与真阳性和假阳性之和的比率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/972d6105f28302dab8e84aff6bc62f8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*QYb0mAP7j9d6FoRbJnrnLg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><p id="3d79" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu"> F1 得分:</strong> F1 得分定义为精度和召回率的调和平均值。F1 分数从 0 到 1，0 为最差分数，1 为最高分数。当数据遭受类别不平衡时，可以使用 F1 分数，因为它同时考虑了假阳性和假阴性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/758d10815f06c74daef1b062b70e57da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WfYHVQ2ZsCT5r7kheaVRzw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><p id="e8e5" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">准确度:</strong>模型的准确度被定义为真阳性和真阴性之和与预测总数的比率。精确度范围从 0 到 100。当必须获得真阳性和真阴性时，可以使用准确性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/1aeb2e6ac4f568820482c7ca88f00a53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Go8jEcaXvt3QqTLoAjYg6A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><h1 id="2a2b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">ROC 曲线</h1><p id="785d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">ROC-AUC 曲线(接收操作者特征-曲线下面积)有助于分析不同阈值设置下的分类性能。类别的高真阳性率(TPR/灵敏度)描述了该模型在分类该特定类别时表现良好。可以比较各种模型的 ROC-AUC 曲线，具有高 AUC(曲线下面积)的模型被认为表现良好。换句话说，该模型在各种阈值设置下表现得非常好，产生了高 TPR(真阳性率)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/35a2a82eb21fd2f256ac451825e78b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHIpEetX9cBRQ0QYLwgUDQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><h1 id="a138" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">分类的成本函数</h1><p id="4b6b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">成本函数通过考虑实际值和预测值来帮助衡量模型的性能。</p><h2 id="6356" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated">交叉熵损失</h2><p id="125a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">交叉熵损失也称为<strong class="lt iu">对数损失</strong>。对数损失可以应用于目标是二进制的二进制分类问题，也可以应用于多类分类问题。让我们考虑 C 是目标变量中类的数量。</p><blockquote class="nl nm nn"><p id="0e3f" class="lr ls no lt b lu mo ju lw lx mp jx lz np mq mc md nq mr mg mh nr ms mk ml mm im bi translated"><em class="it">如果 C = 2(二进制分类)，对数损失或二进制交叉熵损失计算如下，</em></p></blockquote><ul class=""><li id="2cd3" class="ns nt it lt b lu mo lx mp ma nu me nv mi nw mm nx ny nz oa bi translated">当实际值 y = 0 时，应用[(1-y) * log(1- 𝑦̂)]其中𝑦̂是 y 的预测值</li><li id="b1dc" class="ns nt it lt b lu ob lx oc ma od me oe mi of mm nx ny nz oa bi translated">当实际值 y = 1 时，应用[y *log(𝑦̂]]𝑦̂是 y 的预测值</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/45a7b573a2a12456ccb7179044546ce6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PNznVVF7InHjRJnDfHXzAw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><p id="f61e" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">曲线图为-y * log(𝑦̂)当 y = 1 时(y 是实际值)</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/d4312b8d2097ec7ed1187ee1019103da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*oS2aeqioaKcIg1Mnb3NhdQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者。用完了德斯莫斯</p></figure><p id="6319" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">图为-[(1- y) * log(1- 𝑦̂)]当 y = 0 时</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/e5d0d7da957107247e0727394c1c0dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mEm8-__D1PL3D7fY4RCEFw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者。用完了德斯莫斯</p></figure><blockquote class="nl nm nn"><p id="e670" class="lr ls no lt b lu mo ju lw lx mp jx lz np mq mc md nq mr mg mh nr ms mk ml mm im bi translated"><em class="it">如果 C &gt; 2(多类分类)log 损失或</em> <strong class="lt iu"> <em class="it">多类交叉熵损失</em> </strong> <em class="it">计算如下，</em></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/f85ac8cf2033f6f565a02e18f6b4667c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pk4DHDFJhur5Gl2iPA9lfw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><p id="a464" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">多类交叉熵损失</strong>是针对单个数据实例定义的，而<strong class="lt iu">多类交叉熵误差</strong>是针对整组数据实例定义的。</p><h2 id="6c00" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated">稀疏多类交叉熵损失</h2><p id="b42a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">稀疏多类交叉熵损失非常类似于多类交叉熵损失，除了不同于多类交叉熵损失的真实标签的表示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/75e658fe0969b768d4053255f8fa5d2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C2BqazlFJH74MF1rDBJaPw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><p id="1fa2" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">在多类交叉熵损失中，真实标签被一热编码，而在稀疏多类交叉熵损失中，真实标签被原样保留，从而减少了计算时间。</p><p id="4f10" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">多类交叉熵损失中真实标签 y 的表示，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/69b49cee0867a8a959d850e5e413ec49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hb1BgZCpvUBxVnFfTzyf6Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><p id="c92c" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">多类稀疏交叉熵损失中真实标签 y 的表示，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/f99939767e100a3d2db3bd712416065f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5HbVXtU_NaZtcVZVkSZEmw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PC:作者</p></figure><h1 id="bc6d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">摘要</h1><ul class=""><li id="9ec3" class="ns nt it lt b lu lv lx ly ma om me on mi oo mm nx ny nz oa bi translated">当数据集不平衡时，可以使用 F1 分数。当一个类的样本数多于另一个类的样本数时，数据集被称为不平衡的。</li><li id="3181" class="ns nt it lt b lu ob lx oc ma od me oe mi of mm nx ny nz oa bi translated">ROC-AUC 曲线使用不同阈值设置下的真阳性率和假阳性率绘制。ROC-AUC 曲线有助于找到分类的最佳阈值。</li><li id="0e2f" class="ns nt it lt b lu ob lx oc ma od me oe mi of mm nx ny nz oa bi translated">交叉熵损失可以应用于二元和多类分类问题。</li><li id="2b2d" class="ns nt it lt b lu ob lx oc ma od me oe mi of mm nx ny nz oa bi translated">稀疏多类交叉熵损失在计算上比多类交叉熵损失更快。</li></ul></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><h2 id="a27b" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated">参考</h2><p id="b320" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">[1] Jason Brownlee，<a class="ae ky" href="http://how%20to%20choose%20loss%20functions%20when%20training%20deep%20learning%20neural%20networks/" rel="noopener ugc nofollow" target="_blank">训练深度学习神经网络时如何选择损失函数</a>。</p><p id="b781" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">[2] Scikit-learn，<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py" rel="noopener ugc nofollow" target="_blank">接收操作员特征</a>。</p><p id="050c" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">[3] ML- cheatsheet，<a class="ae ky" href="https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html" rel="noopener ugc nofollow" target="_blank">损失函数-ML 术语文档</a>。</p></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><p id="d2ae" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><em class="no">在</em><a class="ae ky" href="https://www.linkedin.com/in/srivignesh-rajan-123569151/" rel="noopener ugc nofollow" target="_blank"><em class="no">LinkedIn</em></a><em class="no">，</em><a class="ae ky" href="https://twitter.com/RajanSrivignesh" rel="noopener ugc nofollow" target="_blank"><em class="no">Twitter</em></a><em class="no">上与我联系！</em></p><p id="9630" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">快乐的机器学习！</strong></p><h2 id="5e2f" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated">谢谢大家！</h2></div></div>    
</body>
</html>