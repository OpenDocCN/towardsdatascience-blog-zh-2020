<html>
<head>
<title>Comparative Case Study of ML Systems: Tensorflow vs PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML系统的比较案例研究:Tensorflow与PyTorch</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/comparative-case-study-of-ml-systems-tensorflow-vs-pytorch-a554dce5f585?source=collection_archive---------33-----------------------#2020-04-11">https://towardsdatascience.com/comparative-case-study-of-ml-systems-tensorflow-vs-pytorch-a554dce5f585?source=collection_archive---------33-----------------------#2020-04-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/bae263a0e224672209b674746cc9a595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*brf33j4KmEoElwYx491kYg.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://unsplash.com/@z734923105?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">张杰瑞</a>在<a class="ae kc" href="https://unsplash.com/t/nature?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="54f6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我将对<a class="ae kc" href="https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf" rel="noopener ugc nofollow" target="_blank"> TensorFlow:一个用于大规模机器学习的系统</a>和<a class="ae kc" href="https://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library" rel="noopener ugc nofollow" target="_blank"> PyTorch:一个命令式的高性能深度学习库</a>的背景架构进行一个小的比较研究</p><p id="7654" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面提到的信息是从这两篇论文中摘录的。</p><p id="69cc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我选择了<a class="ae kc" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>和<a class="ae kc" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>来进行比较研究，因为我已经使用了这两个系统，理解它们的基本设计原理让我着迷。我想知道这些系统如何在幕后处理模型，使它们成为行业标准。解决以行业为中心的机器学习问题所需的速度和复杂架构很难实现，这两个系统都设法做到了这一点。</p><p id="aea5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章旨在提供两个系统的架构差异。为了更深入地了解每个人的背景工作，请阅读他们的学术论文！它们信息量大，易于阅读。</p><h1 id="aeb3" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">张量流</h1><h2 id="2e88" class="lz lc iq bd ld ma mb dn lh mc md dp ll ko me mf lp ks mg mh lt kw mi mj lx mk bi translated">好处:</h2><p id="e6ba" class="pw-post-body-paragraph kd ke iq kf b kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><strong class="kf ir">数据流图:</strong> Tensorflow是对<a class="ae kc" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40565.pdf" rel="noopener ugc nofollow" target="_blank">dist faith</a>的改进，它是以前使用<a class="ae kc" href="http://www.cs.cornell.edu/courses/cs6453/2017sp/slides/paramserver.pdf" rel="noopener ugc nofollow" target="_blank">参数服务器</a>模型的Google ML平台。Tensorflow结合了<em class="mq">数据流</em>的高级编程模型和参数服务器的低级效率，因此比它的前身强大得多。它结合了在基于参数服务器的架构中由单独的工作线程完成的计算和状态管理。它还使用在提供性能方面比CPU和GPU更好的TPU。这使得研究人员开发复杂(和新颖)的深度学习模型变得相对容易。</p><blockquote class="mr ms mt"><p id="e0ea" class="kd ke mq kf b kg kh ki kj kk kl km kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">数据流图是一个神经网络，由占位符和更新规则组成。它可以用于确定操作的顺序，以估计内存消耗等。</p></blockquote><p id="7452" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">高GPU利用率:</strong>它提供了一个单语言平台来开发新的ML架构，速度很快，并使用单个数据流图来表示算法中的所有计算和状态。通过推迟执行直到程序完成，它提高了整体执行性能，即高GPU利用率。Tensorflow的主要功能在于并发和分布式执行整个图的重叠子图。</p><p id="f0da" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">社区支持:</strong> Tensorflow也有巨大的社区支持，在生产中表现相当不错。所以很多大公司像Google，Twitter，Airbnb，Open AI等等。为他们的ML项目使用Tensorflow后端。</p><p id="d811" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">移动接口:</strong>它还提供跨集群的分布式执行和动态工作流，允许复杂的ML程序在CPU、GPU和TPU上运行，同时在移动设备上拥有一个接口。Tensorflow-Lite的推出考虑到了移动设备。</p><p id="54a7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">大规模ML: </strong>对于密集的大规模任务，如图像分类和语言建模，Tensorflow提供了一个非常容错、分布式和优化的架构，可用于训练非常大的ML模型，如通过谷歌的ML聚焦应用程序可见。</p><figure class="my mz na nb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/948d262c9cd6d7746b1d0a60f66d08d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q15j563ZrSluMXHs"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">Tensorflow架构(<a class="ae kc" href="https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><h2 id="1120" class="lz lc iq bd ld ma mb dn lh mc md dp ll ko me mf lp ks mg mh lt kw mi mj lx mk bi translated">缺点:</h2><p id="68ea" class="pw-post-body-paragraph kd ke iq kf b kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><strong class="kf ir">陡峭的学习曲线:</strong> Tensorflow有一个学习曲线，旨在使研究人员更容易开发ML模型，它增加了理解其架构的难度。它也不像Spark的RDDs那样为单个操作提供容错。</p><p id="bdce" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">调试和动态执行:</strong>调试ML程序的容易程度并不是Tensorflow design关注的重点。它也不支持早期的动态计算图，模型只能在已经定义了计算图的情况下运行。尽管它在最新版本中增加了对此的支持。</p><p id="b00f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然它的架构非常可扩展和高效，但随着Python用户花一些时间来习惯它，可以做出更多努力来改善用户体验。</p><figure class="my mz na nb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nc"><img src="../Images/2bf55561c19dc466b5e58252a1b8e557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R4CwxAIq-Asv5F5A"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">来源:<a class="ae kc" href="https://www.activestate.com/blog/neural-network-showdown-tensorflow-vs-pytorch/" rel="noopener ugc nofollow" target="_blank">活动状态</a></p></figure><h1 id="e596" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">PyTorch</h1><h2 id="619c" class="lz lc iq bd ld ma mb dn lh mc md dp ll ko me mf lp ks mg mh lt kw mi mj lx mk bi translated">好处:</h2><p id="a086" class="pw-post-body-paragraph kd ke iq kf b kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><strong class="kf ir">易用性:</strong> PyTorch是一个专注于python的ML框架，开发它是为了让用户牢记在心。它侧重于维护性能，同时保持最终用户的高易用性。PyTorch的“一切都是程序”的方法使它成为一个非常用户友好的平台。</p><p id="1e16" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> C++核心:</strong>由于大多数深度学习研究人员都熟悉python，所以它的开发者开发了这个python库，尽管它的核心是用C++编写的，以提高速度和性能。与Tensorflow不同，它不使用静态数据流方法，因此为了克服Python的全局解释器锁(确保一次只有一个线程运行)问题，它的核心“libtorch”库(用C++编写)实现了张量数据结构、自动diff集成等。多线程环境中的功能。</p><p id="b86b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> Python库支持:</strong> PyTorch保持简单高于性能，因此做出了折衷。所有的Python功能:打印语句、调试器、Numpy、Matplotlib等的使用。使用PyTorch轻松工作。</p><p id="be0b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从论文本身来看:</p><blockquote class="mr ms mt"><p id="71c4" class="kd ke mq kf b kg kh ki kj kk kl km kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">用10%的速度换取一个简单得多的模型是可以接受的；100%不是。</p></blockquote><p id="c06f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> CPU-GPU同步:</strong>它具有高度的互操作性和可扩展性，可以很好地与其他使用库的GPU配合使用。它使用CUDA在GPU上异步执行操作符，这有助于获得高性能，即使对于Python这样的语言也是如此。这样，它通过CPU在Python中运行模型的控制流，并在GPU上运行张量运算，一切都在CPU-GPU同步中进行。</p><p id="461b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">多重处理:</strong>它使用多重处理模块(torch.multiprocessing)来允许并发线程加速程序。它还通过引用计数(计算每个张量的使用次数)和删除不再使用的张量来仔细管理内存。</p><figure class="my mz na nb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/b3cf664333cf925aab7056fb652091b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*e9g7H31OpEQON-wM"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">PyTorch中的一个简单神经网络程序(<a class="ae kc" href="https://papers.nips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="e0b0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">动态执行:</strong> PyTorch还支持动态计算图，这有助于用户随时开发和运行模型。这在像RNN这样使用运行时可变长度输入的模型中非常有用。</p><h2 id="0ab0" class="lz lc iq bd ld ma mb dn lh mc md dp ll ko me mf lp ks mg mh lt kw mi mj lx mk bi translated">缺点:</h2><p id="11ff" class="pw-post-body-paragraph kd ke iq kf b kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><strong class="kf ir">性能:</strong>由于PyTorch是为Python打造的，所以不得不在性能上做一些取舍。它不使用其他ML系统中流行的数据流图，如TensorFlow、Theano等。以提高性能著称。</p><p id="4a62" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">依赖:它还必须依赖许多其他独立的库来克服Python的限制，比如使用CUDA流。由于CUDA流遵循FIFO方法，PyTorch需要保持CPU和GPU周期之间的同步，因为它遵循“每个流一个池”的设计。这可能会导致碎片，同步开销和一些奇怪的角落情况，但PyTorch确保用户可能永远不会遇到它们。</p><h1 id="8e7d" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">共享的共同特征</h1><ul class=""><li id="e1a0" class="ne nf iq kf b kg ml kk mm ko ng ks nh kw ni la nj nk nl nm bi translated">这两个系统都使用高效的C++内核来实现高性能。由于计算损失函数的梯度，而使用SGD是由所有ML程序完成的，PyTorch和Tensorflow都提供了有效的自动微分算法。</li><li id="f654" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">两者都利用工作线程/子计算中的分布式执行和多重处理来提高性能。这两个系统都是开源的，在ML研究社区中很受欢迎。两者都使用异步参数更新来执行算法。</li></ul><h1 id="7c3a" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">差异</h1><blockquote class="mr ms mt"><p id="499e" class="kd ke mq kf b kg kh ki kj kk kl km kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated"><em class="iq">py torch比TensorFlow来得晚，它覆盖了tensor flow的很多弱点。</em></p></blockquote><ul class=""><li id="5b9c" class="ne nf iq kf b kg kh kk kl ko ns ks nt kw nu la nj nk nl nm bi translated">PyTorch提供了数据并行性以及调试功能，而这两者对于TensorFlow来说都是一个问题。相比Tensorflow，PyTorch对研究人员来说更容易学习。</li><li id="57cb" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">PyTorch保持了控制和数据流之间的分离，而Tensorflow将其合并到一个数据流图中。</li><li id="bd98" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">PyTorch执行反向模式自动微分，TensorFlow也执行反向微分，尽管区别在于Tensorflow提供的消除开销的优化算法。</li><li id="80f1" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">TensorFlow利用延迟执行直到整个程序可用，而这在PyTorch的情况下是不可能的，因此使用其他方法来提高效率，如自定义缓存张量收集器和引用计数。</li></ul><h1 id="6528" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="ecae" class="pw-post-body-paragraph kd ke iq kf b kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">总的来说，PyTorch在很多方面都比Tensorflow表现得更好，包括易用性，同时又不牺牲性能。</p><p id="33cd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">考虑到PyTorch论文中的基准测试，它比Tensorflow实现所有主要的ML算法(如AlexNet、VGG-19等)的性能都要好。尽管对于大规模生产系统，Tensorflow由于其社区支持和强大的架构仍然是主要选择。</p><p id="5460" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">没有一种方法可以设计大型系统。每个ML平台在设计其特性时都考虑到了一些核心方面。对于TensorFlow，它是性能，而对于PyTorch，它是用户体验。</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="a3dd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">【http://adityarohilla.com】原载于2020年4月11日<a class="ae kc" href="https://adityarohilla.com/2020/04/11/comparative-case-study-of-ml-systems-tensorflow-vs-pytorch/" rel="noopener ugc nofollow" target="_blank"><em class="mq"/></a><em class="mq">。</em></p></div></div>    
</body>
</html>