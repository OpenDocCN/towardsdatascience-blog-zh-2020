<html>
<head>
<title>Building your own Self-attention GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建立你自己的自我关注感</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-your-own-self-attention-gans-e8c9b9fe8e51?source=collection_archive---------15-----------------------#2020-07-17">https://towardsdatascience.com/building-your-own-self-attention-gans-e8c9b9fe8e51?source=collection_archive---------15-----------------------#2020-07-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cbc6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用 MNIST 和西里巴数据集实现 SAGAN 的 PyTorch</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/072b44a652aade90add2bc3667233bc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LOUEfzfuvgB25QUL4bx31w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自 imgflip.com 的迷因</p></figure><p id="6ea8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> GANs </strong>，又称<strong class="la iu">生成对抗网络</strong>，是近年来机器学习领域最热门的话题之一。它由两个不同的神经网络模型组成，一个叫做<strong class="la iu"> <em class="lu">生成器</em> </strong>，一个叫做<strong class="la iu"> <em class="lu">鉴别器</em> </strong>。这听起来很难理解，但让我试着这样说:假设我们想在没有任何绘画知识的情况下伪造名画，我们应该怎么办？大多数人会说，看看画，学着怎么做就行了。但这不是一个人的工作，在某种程度上，我相信你会在绘画上越来越好。你需要让你的朋友来到一幅真画和一幅你伪造的画面前，让他猜猜哪一幅是真的。一开始他很容易猜到，但是继续猜下去，你最终会把你的朋友弄糊涂。</p><p id="1f36" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 GANs 里，<em class="lu">发生器</em>就像你伪造画作，<em class="lu">鉴别器</em>就是专门辨别哪幅画是假的朋友。想想这里的目标，你想让你的朋友很难分辨真假。如果你的朋友对每幅画给出一个从 0 到 1 的真实概率，你会希望他对你给他看的任何一幅画给 0.5 分，不管是真实的还是伪造的。这也将是 GANs 的目标，反映在损失函数中。</p><p id="c0da" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们也经常看到<strong class="la iu"> DCGAN </strong>，它代表<strong class="la iu">深度卷积 GAN </strong>。这是一种专门用于图像生成的 GAN 设计，为<em class="lu">发生器</em>和<em class="lu">鉴别器</em>使用卷积层。它的工作原理就像 CNN 一样。<em class="lu"> A </em> <strong class="la iu"> <em class="lu">自关注 GAN </em> </strong> <em class="lu">是利用自关注层的 DCGAN。</em>自我关注的想法已经存在多年，在一些研究中也被称为<em class="lu">非本地</em>。想想卷积是如何工作的:它们对附近的像素进行卷积，并从局部块中提取特征。它们在每一层“本地”工作。相反，自我关注层从远处的街区学习。2017 年，谷歌发表了一篇论文“<a class="ae lv" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">关注是你所需要的全部</a>”，带来了更多关于该话题的炒作。对于单个图像输入，它是这样工作的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lw"><img src="../Images/3dccd352b61d3af3c107c4bca57ae6e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GSWQYI3ZfYe-MlKQGjTFWA.png"/></div></div></figure><p id="295f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">1.使用一个核大小为 1 的卷积生成查询、键和值层，形状为<em class="lu"> (Channels * N) </em>，其中<em class="lu"> N = Width * Height </em>。</p><p id="2fe1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.由查询和关键字的矩阵点积生成关注图，形状为<em class="lu"> (N * N) </em>。<em class="lu"> N * N </em>注意力图描述的是每个像素在每隔一个像素上的注意力得分，因此得名“自我关注”。这里的像素是指输入矩阵中的数据点。</p><p id="4d60" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.通过价值与注意力地图的矩阵点积得到注意力权重，形状为<em class="lu"> (C * N) </em>。注意力权重描述了所有像素中每个像素的总注意力分数。然后我们将注意力权重重塑为<em class="lu"> (C * W * H) </em>。</p><p id="58ed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">4.将注意力权重添加回输入层本身，权重为γ，学习参数初始化为 0。这意味着自我关注模块最初不做任何事情。</p><p id="787b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">综上所述，自我关注 GAN 只是一个具有自我关注层的 DCGAN。</strong>2018 年的论文“<a class="ae lv" href="https://arxiv.org/abs/1805.08318" rel="noopener ugc nofollow" target="_blank">自我关注生成对抗网络</a>”指出<em class="lu">DCG an 可能无法捕捉多类数据集一致出现的几何或结构模式，例如，画狗时没有单独的脚。</em>毕竟如何打造一个<strong class="la iu">自我关注的甘</strong>？让我们把手弄脏吧！</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h2 id="9f06" class="me mf it bd mg mh mi dn mj mk ml dp mm lh mn mo mp ll mq mr ms lp mt mu mv mw bi translated">1.正在准备数据集</h2><p id="9c39" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">我们将使用<strong class="la iu"> MNIST 数字数据集</strong>。用<strong class="la iu"> PyTorch </strong>下载后，我们再用<em class="lu"> DataLoader </em>加载数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h2 id="d249" class="me mf it bd mg mh mi dn mj mk ml dp mm lh mn mo mp ll mq mr ms lp mt mu mv mw bi translated">2.构建模型</h2><p id="359c" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">首先，我们将构建<strong class="la iu">自我关注模块</strong>，稍后将在<em class="lu">生成器</em>和<em class="lu">鉴别器</em>中使用。可以查阅之前的自我关注模块结构，以便更好的理解。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="782e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">发生器</em>和<em class="lu">鉴别器</em>的结构如图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/3a67e2ad7f85ef1bf5c3e620c858d9fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IZ9lvFpfDqyeE2OBmC0j4A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型结构</p></figure><p id="de60" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">谱归一化</em>是在<a class="ae lv" href="https://arxiv.org/abs/1802.05957" rel="noopener ugc nofollow" target="_blank">生成对抗网络谱归一化</a>中提出的一种新的权重归一化技术，用于更加稳定的训练过程。借用<a class="ae lv" href="https://github.com/heykeetae/Self-Attention-GAN/blob/master/spectral.py" rel="noopener ugc nofollow" target="_blank">萨根的 spectra . py</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h2 id="db48" class="me mf it bd mg mh mi dn mj mk ml dp mm lh mn mo mp ll mq mr ms lp mt mu mv mw bi translated">3.创建培训功能</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="98cf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这通常是最令人困惑的部分。与 CNN 或其他简单的机器学习模型不同，GANs 没有现成的拟合函数。我们需要编写整个训练函数。</p><p id="76a6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们首先初始化我们的模型和优化器。然后在一个循环中，我们首先从<em class="lu">数据加载器</em>读入一批数据。</p><p id="78c2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下一步，我们向我们的鉴别器提供一批真实图像，并计算<a class="ae lv" href="https://en.wikipedia.org/wiki/Hinge_loss" rel="noopener ugc nofollow" target="_blank"><em class="lu"/></a>。然后我们用一组随机数作为潜在变量，用生成器生成一批伪图像，再次送入鉴别器，得到损失。</p><p id="0dc5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如前所述，我们的鉴别器的目标是对真实图像给出接近 1 的预测，对虚假图像给出接近 0 的预测。因此，我们希望减少(1-对真实图像的预测)和对虚假图像的预测的总和。借助<strong class="la iu"> PyTorch </strong>，我们可以使用 backward 和 step 实现这一点，并在几行代码内更新鉴别器的所有学习参数。</p><p id="08a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们使用来自鉴别器的假图像的输出来更新发生器的参数。瞧，一个训练循环完成了，我们为第一批图像训练了我们的模型。打印出日志信息，并保存图像/模型，如果你想要的。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h2 id="d8db" class="me mf it bd mg mh mi dn mj mk ml dp mm lh mn mo mp ll mq mr ms lp mt mu mv mw bi translated">4.模型性能</h2><p id="f234" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">训练功能完成后，只需运行该功能即可开始训练。每 100 批从生成器中抽取样本，可以看到我们的模型学习画数字的过程。左边是没有注意的结果，右边是注意的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/a885036a270b836bc06a2a59389788c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/1*owrXt_kHkTUFazb5LhUCnw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">关于 MNIST 的培训过程</p></figure><p id="a29e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过对模型结构进行一些细微的更改，我们可以让我们的模型在其他大小的输入上运行。使用与<a class="ae lv" href="https://github.com/heykeetae/Self-Attention-GAN" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> SAGAN </strong> </a>相同的结构，我们也可以在<strong class="la iu"> <em class="lu"> CelebA </em> </strong> <em class="lu">数据集</em>上运行。具体的<a class="ae lv" href="https://github.com/franknb/Self-attention-DCGAN/blob/master/model_64.py" rel="noopener ugc nofollow" target="_blank">模型结构</a>和<a class="ae lv" href="https://github.com/franknb/Self-attention-DCGAN/blob/master/SAGAN_celeba.ipynb" rel="noopener ugc nofollow" target="_blank">训练功能</a>可以在我的<a class="ae lv" href="https://github.com/franknb/Self-attention-DCGAN" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> GitHub </strong> </a>中找到。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/0554026b55bde99826733669d8997c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*-iTnwqMopqhnv0Suhs0BjA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CelebA 上的培训流程</p></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h2 id="c6bb" class="me mf it bd mg mh mi dn mj mk ml dp mm lh mn mo mp ll mq mr ms lp mt mu mv mw bi translated">5.你应该使用自我关注甘吗？</h2><p id="910e" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">正如你可能从上面的 gif 中观察到的，<strong class="la iu">在有和没有自我关注层的模型之间没有明显的视觉差异</strong>。此外，自我关注层通过计算多个矩阵点积来工作，这将导致<strong class="la iu"> 10% ~ 30%的训练时间延长</strong>，具体取决于你的具体模型结构。</p><p id="577e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，在<a class="ae lv" href="https://arxiv.org/abs/1805.08318" rel="noopener ugc nofollow" target="_blank"> SAGAN 论文</a>(韩等人 2018)中，作者确实报告了使用自我注意模块获得更好的初始和 FID 分数。我的下一步将是采用这些指标中的任何一个，看看自我关注的甘是否带来了更好的表现。在我的<a class="ae lv" href="https://github.com/franknb/Self-attention-DCGAN" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> GitHub </strong> </a> <strong class="la iu">查看所有源代码和演示。</strong></p></div></div>    
</body>
</html>