<html>
<head>
<title>Part 2— Yet another Face Mask Detector… (OpenCV Spatial AI Competition Journey)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">第 2 部分—又一个面具检测器… (OpenCV 空间人工智能竞赛之旅)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/part-2-yet-another-face-mask-detector-opencv-spatial-ai-competition-journey-91dfaf96c6e8?source=collection_archive---------27-----------------------#2020-08-24">https://towardsdatascience.com/part-2-yet-another-face-mask-detector-opencv-spatial-ai-competition-journey-91dfaf96c6e8?source=collection_archive---------27-----------------------#2020-08-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/936cb5b1b4f790a2d9bc2fe39d76c1ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*KD8FU8SYrSKWQX0y7SRRMg.gif"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来自<a class="ae jg" href="https://www.pexels.com/photo/women-with-face-masks-walking-dogs-4267745/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae jg" href="https://www.pexels.com/@gustavo-fring?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">古斯塔沃·福林</a>对视频进行面具检测</p></figure><div class=""/><div class=""><h2 id="0d88" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">盲人社交距离反馈系统中不同面具检测模型的比较。</h2></div></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="e592" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><em class="mb">本文是系列文章的一部分，我将记录我在 OpenCV 空间竞赛中为盲人开发社交距离反馈系统的旅程。查看完整系列:</em> <a class="ae jg" rel="noopener" target="_blank" href="/opencv-spatial-ai-competition-journey-part-1-e76593d456fe"> <strong class="lh jk"> <em class="mb">第一部</em> </strong> </a> <strong class="lh jk"> <em class="mb">，</em> </strong> <a class="ae jg" href="https://medium.com/@ibaiGorordo/part-2-yet-another-face-mask-detector-opencv-spatial-ai-competition-journey-91dfaf96c6e8" rel="noopener"> <strong class="lh jk"> <em class="mb">第二部</em> </strong> </a> <em class="mb">。</em></p><h1 id="5242" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">为什么要做口罩检测？</h1><p id="5932" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">正如该系列的第一部分 中提到的，这个项目的目标是为盲人开发一个<strong class="lh jk"> <em class="mb">反馈系统，帮助他们使用 OAK-D </em> </strong>保持与周围人的社交距离(顺便祝贺<a class="mz na ep" href="https://medium.com/u/6979f836a183?source=post_page-----91dfaf96c6e8--------------------------------" rel="noopener" target="_blank"> Luxonis LLC </a>和<a class="mz na ep" href="https://medium.com/u/d19d774b0c8?source=post_page-----91dfaf96c6e8--------------------------------" rel="noopener" target="_blank"> Satya Mallick </a>成功开展了【Kickstarter 活动！)。在这篇文章中，我将重点关注使用深度学习模型对周围人的检测，以便与这些人保持距离。</p><p id="a342" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">对用户周围的人的检测可以以多种方式来完成，一种选择可以是训练用于<strong class="lh jk">行人检测</strong>的模型，如在<a class="ae jg" href="https://github.com/YonghaoHe/A-Light-and-Fast-Face-Detector-for-Edge-Devices/tree/master/pedestrian_detection" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk">这个库</strong> </a>中。另一个可能的选择是<strong class="lh jk">只检测脸部</strong>而不是检测整个身体。人脸检测模型的好处是，由于人脸的独特特征，即使不需要深度学习模型，也更容易检测人脸。例如，在本 OpenCV 教程  <strong class="lh jk"> </strong>的<a class="ae jg" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk">中，使用了基于 Haar 特征的级联分类器方法，即使在低计算设备中也能实时检测人脸。</strong></a></p><p id="209d" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">然而，在这个特定的应用中，我们还想知道周围的人是否戴着面罩。然后，最好的选择将是仅使用一个检测人在哪里以及他们是否使用面罩的模型，即面罩检测器。</p><h1 id="9e31" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">面罩检测器过多</h1><p id="77e8" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">由于当前疫情中面罩使用的增加，许多人已经开发了面罩检测系统。在<strong class="lh jk"> Github </strong>中快速<a class="ae jg" href="https://github.com/search?q=face+mask+detection" rel="noopener ugc nofollow" target="_blank">搜索“面具检测”</a>会返回大约 700 个关于这个主题的知识库。同样，在<strong class="lh jk"> Youtube </strong> 中<a class="ae jg" href="https://www.youtube.com/results?search_query=face+mask+detection" rel="noopener ugc nofollow" target="_blank">搜索相同的术语，会返回一个没完没了的视频列表，显示人脸检测模型的实现。</a></p><p id="8407" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">因此，有了这么多可用的例子，我希望很容易找到一个对深度为 ( <strong class="lh jk"> OAK-D </strong>)的<strong class="lh jk"> OpenCV AI 套件来说足够快的例子，并且即使在现实生活环境中也具有良好的准确性。</strong></p><blockquote class="nb"><p id="2b86" class="nc nd jj bd ne nf ng nh ni nj nk ma dk translated">但是，<strong class="ak">我们应该选择哪个人脸面具检测实例呢？</strong></p></blockquote><p id="496d" class="pw-post-body-paragraph lf lg jj lh b li nl kk lk ll nm kn ln lo nn lq lr ls no lu lv lw np ly lz ma im bi translated">首先，我决定看看<strong class="lh jk"> Github 中排名靠前的面具检测库。</strong>下表总结了其中一些存储库中使用的数据集和模型列表。</p><figure class="nq nr ns nt gt iv"><div class="bz fp l di"><div class="nu nv l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">面罩检测示例概述</p></figure><p id="aae2" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">正如可以观察到的，有两种主要的方法来执行人脸面具检测:<strong class="lh jk"> 1 .人脸检测+对每个检测到的人脸进行面罩分类</strong>或<strong class="lh jk"> 2。直接进行面罩检测</strong>。第一种方法可能具有更好的准确性，因为已经可用的人脸检测模型已经在成千上万的人脸图像中被训练。相比之下，如表中所示，人脸遮罩检测数据集具有较少的用于训练的图像，其中<a class="ae jg" href="https://github.com/AIZOOTech/FaceMaskDetection" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk"> AIZOOTech 数据集</strong> </a>具有较多的图像。</p><p id="13ab" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">然而，大多数先前的人脸检测模型是在大多数情况下未被覆盖的人脸上训练的。由于这个原因，在脸部被遮罩覆盖的情况下，脸部检测模型可能会错过脸部的检测(如 pyimagesearch.com 中非常详细的文章<a class="ae jg" href="https://www.pyimagesearch.com/2020/05/04/covid-19-face-mask-detector-with-opencv-keras-tensorflow-and-deep-learning/" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk">中所解释的)。</strong></a></p><h1 id="c694" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">基于 OAK-D 的人脸面具检测</h1><p id="4c43" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">在分析前面提到的例子之前，<a class="ae jg" href="https://luxonis.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk"> Luxonis </strong> </a>的人已经提供了一个使用 OAK-D  进行面具检测的<a class="ae jg" href="https://github.com/luxonis/depthai-experiments/tree/master/coronamask" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk">演示。演示中的模型是一个在 Google Colab 中训练过的<a class="ae jg" href="https://colab.research.google.com/github/luxonis/depthai-ml-training/blob/master/colab-notebooks/Medical_Mask_Detection_Demo_Training.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk"> MobileNetV2 (SSD)。</strong> </a></strong></a></p><blockquote class="nw nx ny"><p id="c9f7" class="lf lg mb lh b li lj kk lk ll lm kn ln nz lp lq lr oa lt lu lv ob lx ly lz ma im bi translated">注:尽管不包括在演示中，他们也提供了另一个<a class="ae jg" href="https://colab.research.google.com/github/luxonis/depthai-ml-training/blob/master/colab-notebooks/Easy_TinyYolov3_Object_Detector_Training_on_Custom_Data.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk"> Google Colab </strong>脚本，用于训练一个<strong class="lh jk"> YOLOv3-tiny </strong>模型用于<strong class="lh jk">人脸面具检测</strong> </a>。</p></blockquote><p id="308e" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">要运行演示，需要安装 DepthAI Python 模块。正如<a class="ae jg" rel="noopener" target="_blank" href="/opencv-spatial-ai-competition-journey-part-1-e76593d456fe"> <strong class="lh jk">第一部</strong> </a>中提到的，Windows 版本仍然是实验性的。然而，最近这个过程已经被更新了，这样按照<strong class="lh jk">Luxonis 讨论</strong>中最后一个评论的<a class="ae jg" href="https://discuss.luxonis.com/d/39-depthai-sneak-peak-into-windows-support/3" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk">步骤安装库就容易多了。</strong></a></p><p id="31fa" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">然而，截至今天，面罩检测演示配置为与旧版本的<strong class="lh jk"> DepthAI 库</strong>一起工作。因此，我修改了演示程序，使其能够与当前版本的<strong class="lh jk"> DepthAI </strong>一起工作，该程序可以在我的<strong class="lh jk"> </strong> <a class="ae jg" href="https://github.com/ibaiGorordo/Social-Distance-Feedback/tree/master/Part%202%20-%20Mask%20Detection" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk"> Github 资源库中找到。要运行该演示程序，需要按照前面的说明安装<strong class="lh jk"> DepthAI </strong>库，并将 DepthAI 文件夹添加到系统的 PYTHONPATH 中。接下来，打开命令并运行以下命令:</strong></a></p><pre class="nq nr ns nt gt oc od oe of aw og bi"><span id="fcf5" class="oh md jj od b gy oi oj l ok ol">git clone <a class="ae jg" href="https://github.com/ibaiGorordo/Social-Distance-Feedback.git" rel="noopener ugc nofollow" target="_blank">https://github.com/ibaiGorordo/Social-Distance-Feedback.git</a><br/>cd "Social-Distance-Feedback\Part 2 - Mask Detection"<br/>python demo_mask_detector.py</span></pre><p id="1825" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">demo_mask_detector.py 是一个脚本，用于配置<strong class="lh jk"> OAK-D </strong>在 RGB 摄像机上执行人脸遮罩检测，并显示来自<strong class="lh jk"> OAK-D </strong>的图像和检测。</p><figure class="nq nr ns nt gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="37b0" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">下面的视频显示了 OAK-D 对<strong class="lh jk"> MobileNetV2 (SSD) </strong> <strong class="lh jk">面罩检测模型</strong>的推理输出(使用<a class="ae jg" href="https://colab.research.google.com/github/luxonis/depthai-ml-training/blob/master/colab-notebooks/Medical_Mask_Detection_Demo_Training.ipynb" rel="noopener ugc nofollow" target="_blank"> DepthAI 的 Google Colab s</a>script 训练)。</p><figure class="nq nr ns nt gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/85a8acba272c5357bedd55c9280b8298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*zZyDSyoPj2qF0QNxZ_6xhw.gif"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">使用 OAK-D (SSD-MobileNetV2)的人脸面具检测</p></figure><h1 id="b297" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">人脸面具检测模型在野外是如何表现的？</h1><p id="bb61" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">前面的例子类似于许多教程，以使用网络摄像头进行推理的例子结束。然而，我的系统的目标是在日常生活中使用，特别是在户外。因此，该系统在不同的光照条件下，甚至在周围有多人时，都应该是鲁棒的。</p><p id="9c59" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">出于这个原因，我决定看看不同的人脸面具检测模型在更真实的环境中表现如何。出于这个目的，我使用了这段来自 pexels.com 的公开视频，记录了人们在夜市 中行走的场景。下面的视频显示了使用<a class="ae jg" href="https://colab.research.google.com/github/luxonis/depthai-ml-training/blob/master/colab-notebooks/Medical_Mask_Detection_Demo_Training.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk"> DepthAI 的 Google Colab 脚本</strong> </a>训练的<strong class="lh jk"> SSD-MobileNetV2 </strong>与<strong class="lh jk"> YOLOv3-tiny </strong>模型的面罩检测的比较。<a class="ae jg" href="https://github.com/ibaiGorordo/Social-Distance-Feedback/tree/master/Part%202%20-%20Mask%20Detection/Face%20Mask%20Detection%20Inference%20Comparison" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk">推理程序的代码可以在我的 Github 资源库这里找到</strong> </a> <strong class="lh jk">。</strong></p><figure class="nq nr ns nt gt iv"><div class="bz fp l di"><div class="on nv l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">使用 SSD-MobileNetV2 和 YOLOv3-tiny 模型在真实生活环境中检测面具的比较</p></figure><p id="e016" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">可以观察到，<strong class="lh jk"> SSD-MobilenetV2 型号</strong>具有更高数量的检测，但结果是，更高数量的这些检测是错误的检测。即使将置信度阈值提高到 0.7(如上面的视频所示)，SSD-MobilenetV2 型号仍然有大量的错误检测。</p><p id="e028" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">另一方面，<strong class="lh jk"> YOLOv3-tiny 型号</strong>错过了一些人脸(特别是距离较远的人脸)，但具有更稳定的检测，置信度阈值为 0.5。由于我们的应用程序只需要检测靠近用户的人(在 3 米或更近的距离)，因此<strong class="lh jk"> YOLOv3-tiny 模型</strong>似乎是两个模型中最有希望的模型。</p><h1 id="12d3" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">YOLOv4 呢？</h1><p id="3ba3" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">最近，Alexey Bochkovskiy 展示了一个<strong class="lh jk"> </strong> <a class="ae jg" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk">新 YOLO 版本(YOLOv4) </strong> </a> <strong class="lh jk"> </strong>，它提供了比以前版本更高的性能。在下面的视频中，有一个来自<a class="mz na ep" href="https://medium.com/u/98bdf6f463d7?source=post_page-----91dfaf96c6e8--------------------------------" rel="noopener" target="_blank"> Mladen Zamanov </a>的例子，可以看出 YOLOv4 即使周围有很多人，也可以进行人脸面具检测。</p><figure class="nq nr ns nt gt iv"><div class="bz fp l di"><div class="on nv l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">YOLOv4 面罩检测推断由<a class="mz na ep" href="https://medium.com/u/98bdf6f463d7?source=post_page-----91dfaf96c6e8--------------------------------" rel="noopener" target="_blank">姆拉登扎马诺夫</a></p></figure><p id="3e33" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在我们的应用程序中使用<strong class="lh jk"> YOLOv4 </strong>的问题是，为了将模型传递给<strong class="lh jk"> OAK-D </strong>，需要将模型转换为<strong class="lh jk">。blob 文件</strong>将由<strong class="lh jk"> OAK-D </strong>中的<strong class="lh jk"> Myriad X </strong>运行。但是，为了转换模型，需要使用<strong class="lh jk"> OpenVINO toolkit 的模型优化器</strong>，目前官方支持到<strong class="lh jk"> YOLOv3 </strong>为止。</p><p id="d2e3" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">尽管由于 TNTWEN  的<a class="ae jg" href="https://github.com/TNTWEN/OpenVINO-YOLOV4" rel="noopener ugc nofollow" target="_blank"> <strong class="lh jk">库，可以使用最新<strong class="lh jk"> OpenVINO (2020.4)版本</strong>的模型优化器，但是<strong class="lh jk"> depthAI 模块</strong>仍然不支持它。结果，到今天为止，似乎<strong class="lh jk"> YOLOv4 </strong>无法用于内置摄像头的<strong class="lh jk"> OAK-D </strong>。</strong></a></p><p id="c035" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">无论如何，我决定试一试 YOLOv4，以防在不久的将来它可以用于 OAK-D。我特别关注新的<strong class="lh jk"> YOLOv4-tiny </strong>版本，因为它应该更适合在计算能力较低的设备中进行实时推理(实际上<strong class="lh jk"> YOLOv4 </strong>的<a class="ae jg" href="https://github.com/AlexeyAB/darknet/issues/5079#issuecomment-620852457" rel="noopener ugc nofollow" target="_blank">作者已经能够在<strong class="lh jk"> OAK-D </strong>内部的同一芯片中运行<strong class="lh jk"> full YOLOv4 </strong>的修改版本，如此处所示</a>)。</p><p id="3dbc" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">为此，我在<strong class="lh jk"> Google Colab </strong>中使用<strong class="lh jk">这个脚本</strong>  <strong class="lh jk">(下面的代码)</strong>训练了<strong class="lh jk"> YOLOv4-tiny </strong>模型，它是基于 DepthAI 的原始脚本。在同一个脚本中，我还添加了代码来检测我用来比较<strong class="lh jk"> SSD-MobileNetV2 </strong>和<strong class="lh jk"> YOLOv3 </strong>的同一视频上的面具。</p><figure class="nq nr ns nt gt iv"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="dec8" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在下面的视频中，我展示了<strong class="lh jk"> YOLOv3-tiny </strong>与<strong class="lh jk"> YOLOv4-tiny </strong>对 f <strong class="lh jk"> ace mask 检测</strong>的结果比较。</p><figure class="nq nr ns nt gt iv"><div class="bz fp l di"><div class="on nv l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">使用 YOLOv4-tiny 和 YOLOv3-tiny 模型在真实生活环境中检测面具的比较</p></figure><p id="22c9" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">可以看出，两种模型的结果非常相似。在某些情况下，<strong class="lh jk"> YOLOv4-tiny </strong>能够检测到<strong class="lh jk"> YOLOv3-tiny </strong>不能检测到的人脸，但总的来说结果几乎是一样的。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="b571" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">总之，我可能会继续使用<strong class="lh jk"> YOLOv3-tiny </strong>进行面具检测，除非有新的支持<strong class="lh jk"> YOLOv4 </strong>。在下一部分中，我将重点关注深度和对象检测数据的组合。</p><p id="8c01" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这一部分和下一部分的所有代码都可以在我下面的库中找到:<a class="ae jg" href="https://github.com/ibaiGorordo/Social-Distance-Feedback" rel="noopener ugc nofollow" target="_blank">https://github.com/ibaiGorordo/Social-Distance-Feedback</a>。</p></div></div>    
</body>
</html>