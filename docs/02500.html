<html>
<head>
<title>Guide to Big Data Joins — Python, SQL, Pandas, Spark, Dask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据连接指南— Python、SQL、Pandas、Spark、Dask</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/guide-to-big-data-joins-python-sql-pandas-spark-dask-51b7f4fec810?source=collection_archive---------2-----------------------#2020-03-10">https://towardsdatascience.com/guide-to-big-data-joins-python-sql-pandas-spark-dask-51b7f4fec810?source=collection_archive---------2-----------------------#2020-03-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a43d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何以最佳方式连接大数据集—多种方法指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fc8facf35b878587c0f28c29100035f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QCpjyqP5qJjwgt3S"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">大数据——Patrick linden Berg在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="4c46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有许多方法可以旋转磁盘、切鱼片或处理大数据，这里有一个快速指南。</p><h2 id="772e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">样本数据集</strong></h2><p id="28dc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Kaggle电影数据库[8]—45，000部电影的2，600万个评级，数据分布在5个文件中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/8044546b8c94b76a8809355cdcbd9de0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rtT9me1WSBzNfS8Trn022Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Foostack。人工智能</p></figure><p id="2696" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要找到电影的最高平均评分，您需要加入<strong class="lb iu">链接</strong>到<strong class="lb iu">元数据</strong>到<strong class="lb iu">评分</strong>:</p><blockquote class="mu mv mw"><p id="15d6" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">SELECT m.title，avg(r . rating)FROM links l INNER JOIN to metas m ON m . imdbid = l . imdbid INNER JOIN to ratings ON r . movie id = l . movie id GROUP BY m . title count(r . rating)&gt; 2且avg(r.rating) &gt; 4.5</p></blockquote><h1 id="39d0" class="nb lw it bd lx nc nd ne ma nf ng nh md jz ni ka mg kc nj kd mj kf nk kg mm nl bi translated">老式SQL RDBMS</h1><p id="6223" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">经典的方法是加载一个数据库，索引并运行前面提到的SQL(或使用下面的经典SQL):</p><blockquote class="mu mv mw"><p id="8523" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">从链接l，metas m，ratings r中选择m.title，avg(r.rating)其中m.imdbId=l.imdbId和r . movie id = l . movie id GROUP BY m . title具有count(r.rating) &gt; 2和avg(r.rating) &gt; 4.5</p></blockquote><p id="c546" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于某些平台变体，RDBMS中的连接有三种主要方式:</p><ol class=""><li id="fe5a" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated"><strong class="lb iu">嵌套循环— </strong>对于表A中的每一行，查找表B中的匹配键。B上的索引使得查找为O(A*log B)，否则连接为慢速— O(A*B)。</li><li id="5690" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><strong class="lb iu"> Hash-Join — </strong>通过查找键构建表B的散列/映射，使得连接查找非常快速— O(A*1)</li><li id="4acc" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><strong class="lb iu">合并-排序</strong> —对两个表进行排序，并在一次通过中合并，除非预先排序，否则速度不会很快—O(A+B+A log A+B log B)→O(A log A+B log B)</li></ol><p id="cf78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用Sqlite3 [1]—创建数据库、表和加载非常简单:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SQLite3表加载/设置</p></figure><p id="3d5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用<strong class="lb iu">加载和查询26m行数据需要大约10分钟</strong>(也许我们可以合并- <em class="mx">调整前两步..</em></p><ul class=""><li id="405b" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu oc ns nt nu bi translated">从CSV/磁盘加载— 35秒</li><li id="b44e" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu oc ns nt nu bi translated">插入数据库— <strong class="lb iu"> 8分钟</strong></li><li id="15fe" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu oc ns nt nu bi translated">添加索引— 30秒</li><li id="3401" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu oc ns nt nu bi translated">按查询分组— 20秒</li></ul><p id="04f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您还可以使用sqlite3命令行来测试和查看查询执行计划，如下所示。在联接列上添加一些额外的索引后，我们的目标查询大约需要21秒来执行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/94493e6199a853db50e551bdd1caba23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VyR-VTb5vO4aRKJ-_EQGgA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SQLite查询执行(来自cmdline工具)</p></figure><p id="f5e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用SQL数据库是可扩展的，但是很老派。接下来我们将尝试潮人技巧。</p><h1 id="a987" class="nb lw it bd lx nc nd ne ma nf ng nh md jz ni ka mg kc nj kd mj kf nk kg mm nl bi translated">python——终极黑客</h1><p id="42b8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们可以省去数据库开销，直接用Python编写数据加载和连接&amp;这很麻烦:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">自定义python合并(NL连接)</p></figure><p id="7dc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“merge()”是一个没有索引的<strong class="lb iu">嵌套循环连接</strong>。该循环必须扫描metas和链接表以获得每个评级(26m * 50k *2)。10万条评论只需要5分钟，所以2600万条评论将永远不会结束...</p><p id="08b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“merge_wmap()”是一个<strong class="lb iu">散列连接— </strong>我们为元和链接构建一个映射，从而获得O(n*1)的性能。<strong class="lb iu">连接26m排只需3秒</strong>！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用hashmap查找的自定义python NL连接</p></figure><p id="3010" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我没有实现分组过滤——这相对较快(需要对26m的行结果进行排序-扫描-合并)—我估计加载和处理的总时间为<strong class="lb iu">0:53</strong></p><ul class=""><li id="b2ce" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu oc ns nt nu bi translated">将原始CSV加载到阵列— 35秒</li><li id="2b90" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu oc ns nt nu bi translated">手动合并索引— 3秒</li><li id="7c87" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu oc ns nt nu bi translated">手动分组和过滤— 15秒(TBD～估计值)</li></ul><p id="ad52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">生蟒速度快但是丑。全速你的本地电脑和完全控制你所有的错误。</em></p><h1 id="dbd1" class="nb lw it bd lx nc nd ne ma nf ng nh md jz ni ka mg kc nj kd mj kf nk kg mm nl bi translated"><strong class="ak">熊猫数据帧拯救行动</strong></h1><p id="f22b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Pandas[2]是Python上用于数据准备的事实上的包。速度极快且易于使用，我们可以用最少的代码进行加载、连接和分组:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">熊猫加入例子</p></figure><p id="87db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">熊猫很聪明。您不需要预定义散列或索引，它似乎可以动态生成优化连接所需的内容。最大的限制是它存在于单个机器上。<strong class="lb iu">处理26m行的时间约为0:17，</strong>代码更少，无需外部系统(数据库、集群等)。</p><ul class=""><li id="4907" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu oc ns nt nu bi translated">将3个csv加载到数据帧— <strong class="lb iu"> 5秒</strong></li><li id="aee2" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu oc ns nt nu bi translated">连接3个数据帧— 8秒</li><li id="c559" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu oc ns nt nu bi translated">加入、分组和过滤— +4秒</li></ul><p id="272e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">熊猫文件加载比我的自定义py快得多，35秒对5秒！这表明不要做黑客，使用库。理论上，Pandas是单线程/进程(在我的TaskManager上看起来不像),因此数据集的大小受到你的电脑内存的限制。</p><p id="182f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">尽管如此——Pandas是处理中小型数据的终极方式——但是我们想要</em> <strong class="lb iu"> <em class="mx">大数据</em> </strong> <em class="mx">！</em></p><h1 id="39ec" class="nb lw it bd lx nc nd ne ma nf ng nh md jz ni ka mg kc nj kd mj kf nk kg mm nl bi translated">火花簇FTW(为了胜利)</h1><p id="92b8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">SQL很棒，但并行性和破解能力有限。Python和Pandas超级灵活，但是缺乏可伸缩性。Apache Spark [5]实际上是在大数据上并行化内存操作的方式。</p><p id="730a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark有一个名为DataFrame <em class="mx">的对象(是的另一个！)</em>这就像一个熊猫的数据框架，甚至可以加载/窃取数据(尽管你可能应该通过HDFS或云加载数据，以避免大数据传输问题):</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最小火花码(本地独立设置)</p></figure><p id="eccb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我写了两个Spark join方法。两者并行运行。默认模式(第15行)将对您的数据进行分区，并在集群节点间移动(传播)。后面的“<strong class="lb iu">广播</strong>”模式(第18行)复制一次较小的表，只对大表内容进行分区和发送。使用较小的连接表，广播模式会快得多。</p><p id="cdf0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark在workers节点(JVM——设置为8，以匹配我的CPU内核数)之间划分工作，分而治之，回到聚合中。火花代码和结果输出如下:</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="3e71" class="lv lw it of b gy oj ok l ol om">df.groupBy('title').agg(func.mean('rating').   <br/>    alias('avg_rating'),func.count('rating').   <br/>    alias('r_count')).filter('r_count &gt;2').    <br/>    filter('avg_rating &gt; 4.5').show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/cd1d058deb62c38bb68f612a6987f5ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ag7i_iPXSvOtniF3tcOLEw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Spark对26m行的连接和分组操作的输出</p></figure><h1 id="c7ac" class="nb lw it bd lx nc nd ne ma nf ng nh md jz ni ka mg kc nj kd mj kf nk kg mm nl bi translated">绩效总结</h1><p id="3719" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><em class="mx">(来自我笔记本电脑的非实验室认证结果)</em></p><p id="bebd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先记下将3个数据集连接在一起的运行时间:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/ce273c25ea675a757b5180f777de8de6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XEY6t4P3BhLiw1FXZyZ-Sw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">连接的性能</p></figure><p id="9e95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">令人惊讶的是，原始Python解决方案是最快的？黑黑！</p><p id="a690" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顶级电影团体(包括Spark)的最终结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/c22f737bfa8312a0a2b1416044ba214e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A2oOtQt4RdWNuLiOe6xdrw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">连接和分组+过滤的性能</p></figure><h2 id="b0b4" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">外卖:</strong></h2><ul class=""><li id="c795" class="nm nn it lb b lc mo lf mp li oq lm or lq os lu oc ns nt nu bi translated">熊猫是非凡的快速和高效，在这一点上，你有核心记忆。在某个时候，Python/Pandas会耗尽内存并崩溃。</li><li id="f226" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu oc ns nt nu bi translated">Spark是一个很好的扩展解决方案，尽管集群管理可能比较棘手。内存分布式处理、分区作业和数据+分区存储策略(HDFS或其他)是正确的方向。</li><li id="3c72" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu oc ns nt nu bi translated">RDBMS是可靠的，但是在移动数据和处理方面有伸缩限制</li></ul><p id="e76f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在接下来的章节中会有更多关于Spark的内容…糟糕，我忘了<strong class="lb iu"> Dask </strong>(原生Python集群)——也许下次吧。</p></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><h2 id="09e6" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">SQLite3资源配置文件</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/9acb481d611521021a7ece7b7ede8ca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w7ub6yBS6qEkdBaPaYIQxA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">只有2个真正活跃的内核，额外的I/O(尽管大部分都被缓存)</p></figure><h2 id="4ce6" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">熊猫资源概况</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/c0cd2e14cf71f8c527393f255203880f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s0M-bK83y6McHo37qkLDMA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对于我所认为的单线程/任务进程，CPU利用率出奇的高？</p></figure><h2 id="50a7" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">Spark资源配置文件(8个工人，10个分区)</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/1f72e5c71e92eaa22124fe6efd486158.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZNxNDXjj1wxyM6LQUK8XAQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">所有内核都利用了8个工作线程—良好的CPU和内存分配</p></figure><p id="a7f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mx">以上数据来自我的MSFT Surface笔记本电脑3-i7/16gb/256 GB固态硬盘</em></p><h1 id="a07c" class="nb lw it bd lx nc nd ne ma nf ng nh md jz ni ka mg kc nj kd mj kf nk kg mm nl bi translated">参考和启示</h1><p id="bec6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">[0]测试代码的完整源代码(不仅仅是gist)——<a class="ae ky" href="https://github.com/dougfoo/machineLearning/tree/master/notebooks/movies" rel="noopener ugc nofollow" target="_blank">Doug foo的GitHub </a></p><p id="ef29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[1] SQLite Python指南— <a class="ae ky" href="https://docs.python.org/2/library/sqlite3.html" rel="noopener ugc nofollow" target="_blank">官方Python文档</a></p><p id="ed2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]熊猫指南— <a class="ae ky" href="https://pandas.pydata.org/docs/getting_started/10min.html" rel="noopener ugc nofollow" target="_blank"> 10分钟教程</a></p><p id="9bd1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3]有点老的分析SQLite vs Pandas — <a class="ae ky" href="https://wesmckinney.com/blog/high-performance-database-joins-with-pandas-dataframe-more-benchmarks/" rel="noopener ugc nofollow" target="_blank">韦斯·麦金利博客</a></p><p id="91b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4] Spark Joins DB Deck— <a class="ae ky" href="https://databricks.com/session/optimizing-apache-spark-sql-joins" rel="noopener ugc nofollow" target="_blank">数据块演示</a></p><p id="72cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[5]关于Spark的精彩详细介绍—<a class="ae ky" rel="noopener" target="_blank" href="/the-art-of-joining-in-spark-dcbd33d693c">a . Ialenti撰写的TDS文章</a></p><p id="943c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[6] PYArrow用于Spark中的快速数据帧加载— <a class="ae ky" href="https://bryancutler.github.io/createDataFrame/" rel="noopener ugc nofollow" target="_blank"> Bryan Cutler IBM </a></p><p id="f908" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[7]在10分钟内安装PySpark Win—<a class="ae ky" rel="noopener" target="_blank" href="/installing-apache-pyspark-on-windows-10-f5f0c506bea1">TDS文章作者Uma G </a></p><p id="6c92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[8]电影评论文件— <a class="ae ky" href="https://www.kaggle.com/rounakbanik/the-movies-dataset#ratings.csv" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集</a></p></div></div>    
</body>
</html>