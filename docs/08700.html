<html>
<head>
<title>IEEE-CIS Fraud Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">IEEE-CIS欺诈检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ieee-cis-fraud-detection-by-lightgbm-b8956a8e4b53?source=collection_archive---------39-----------------------#2020-06-23">https://towardsdatascience.com/ieee-cis-fraud-detection-by-lightgbm-b8956a8e4b53?source=collection_archive---------39-----------------------#2020-06-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8e0e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">机器学习算法有助于确定哪些交易可能是欺诈性的。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/908e22de053575ebe966aadf64e14f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gih3c5cZNoOOGO8V21y80w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">布莱克·维斯在Unsplash上的照片</p></figure><p id="b1cc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这项工作中，我们将对在线交易是否欺诈进行分类。它是一个二进制目标，名为:isFraud。我们很多人都遇到过这样的情况，一笔交易未经我们的考虑就被取消了。有一个更好的算法，只取消欺诈交易，而不只是导致在商店里尴尬。虽然目前经常令人尴尬，但这个系统每年确实为消费者节省了数百万美元。</p><p id="6d4c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该数据集由Vesta的真实世界电子商务交易提供，包括从国家到收件人电子邮件域的广泛功能。利用这个数据集，我们将Lightgbm算法应用于一个具有挑战性的大型e级数据集。提高欺诈交易警告的有效性将为许多人省去误报的麻烦。如果您想了解PySpark的实现，请阅读下一篇文章。</p><p id="a22f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是我们如何分析这类问题呢？</p><h1 id="5d3b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">数据</h1><p id="1c54" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">第一步是下载<a class="ae lr" href="https://www.kaggle.com/c/ieee-fraud-detection/data" rel="noopener ugc nofollow" target="_blank">数据集</a>。这里使用的训练集有两个部分。一个是train _ transcation，另一个是train_identity。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="0371" class="mu lt iq mq b gy mv mw l mx my">train_identity = pd.read_csv(‘../input/ieee-fraud-detection/train_identity.csv’)</span><span id="cdb5" class="mu lt iq mq b gy mz mw l mx my">train_transaction = pd.read_csv(‘../input/ieee-fraud-detection/train_transaction.csv’)</span></pre><p id="1039" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我将在名为“TransactionID”的列上合并这两个数据帧。但并不是所有的交易都有相应的身份信息。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="91d8" class="mu lt iq mq b gy mv mw l mx my">train_transaction_identity = train_transaction.merge(train_identity, on=’TransactionID’,how=’left’ )</span></pre><p id="9fb6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据集包含几个特征，下面我只提到其中的几个。</p><ul class=""><li id="6dc2" class="na nb iq kx b ky kz lb lc le nc li nd lm ne lq nf ng nh ni bi translated"><strong class="kx ir"> TransactionDT </strong>:给定参考日期时间的timedelta(不是实际时间戳)</li><li id="1519" class="na nb iq kx b ky nj lb nk le nl li nm lm nn lq nf ng nh ni bi translated"><strong class="kx ir">交易金额</strong>:美元交易支付金额(部分为其他货币兑换)。</li><li id="9f39" class="na nb iq kx b ky nj lb nk le nl li nm lm nn lq nf ng nh ni bi translated"><strong class="kx ir"> card1 — card6 </strong>:支付卡信息，如卡的类型。</li><li id="e4c6" class="na nb iq kx b ky nj lb nk le nl li nm lm nn lq nf ng nh ni bi translated"><strong class="kx ir">地址</strong>:地址</li></ul><p id="cb76" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果您想更好地了解特性，请查看数据源链接。</p><p id="7185" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如下图所示，内存使用量超过1.9+ GB。我们可以在不丢失任何数据的情况下减少内存使用。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="f1b3" class="mu lt iq mq b gy mv mw l mx my">train_transaction_identity.info()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/d2ff1bd07df70d94eb80bd7b37a4bbda.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*ZSPq94dz_0ixS-ljt0m48A.png"/></div></figure><p id="e7e4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我发现了不同类型的特性，包括对象、浮点和整数。通过使用。在熊猫图书馆，你可以找到内存使用的大小。大部分被float64占据。我已经将这些列从float64更改为float32。如您所见，内存使用量减少了近50%。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/168e04ef0c6cf63b3681b81ab6d4afdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*Th-3cG0mrdurqOedIlz_yA.png"/></div></div></figure><h1 id="42ed" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">数据探索</h1><p id="e4b4" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">大多数交易不是欺诈，所以在这种情况下，我们有不平衡的数据。机器学习算法无法在不平衡的数据集上正常工作。下面写的一段代码显示只有3.5%是欺诈性的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/27645e370a43dfc4159610939c120add.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*WxdCxajJoQ77Um-FeR0kJQ.png"/></div></figure><p id="400c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它们是处理不平衡数据集的几种方法，如过采样和欠采样。好在Lightgbm可以帮你解决这个事情。默认情况下，模型认为数据集是平衡的。因此，在您的情况下，我们需要将参数更改为:</p><p id="5b30" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe nt nu nv mq b">is_unbalance = True</code></p><p id="fe06" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过这样做,“不平衡”模式使用目标值来自动调整与输入数据中的类别频率成反比的权重。</p><h1 id="c351" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">移除多余的功能</h1><p id="169b" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">如果我们看每一列，我们可以看到，如果我们有很多丢失的值。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="2ddf" class="mu lt iq mq b gy mv mw l mx my">(np.sum(pd.isnull(train_transaction_identity)).sort_values(ascending=<strong class="mq ir">False</strong>)/len(train_transaction_identity))*100</span></pre><p id="f9d8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下图显示，我们有大约99%的缺失值的特征。这些列不会给我们的模型增加任何值。所以我们可以删除它们而不会丢失太多数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/a0ea9d50befc7bf8876dc44a32e81644.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*aFidBozFPtWxW4PgZ9JaUw.png"/></div></figure><p id="f0f4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在所有特性中，我已经删除了丢失值超过30%的列。下面写的代码是为了去掉这些不重要的特性。</p><h1 id="7ce6" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">分类特征</h1><p id="2278" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">分类数据是只需要有限数量的可能值的数据。机器学习算法不能直接处理分类数据，要使用它们，必须先将类别转换成数字，然后才能对它们应用学习算法。</p><p id="9de8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有几种技术可以应用，包括OneHotEncoder，替换值。在这里，我使用Pandas get_dummy函数将分类变量转换为虚拟/指示变量。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="b230" class="mu lt iq mq b gy mv mw l mx my">train_dummy = pd.get_dummies(train_transaction_identity, drop_first=<strong class="mq ir">True</strong>)</span></pre><h1 id="3d4b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">处理缺失值</h1><p id="8b01" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">有几种方法可以处理缺失值，如插补、删除。默认情况下，Lightgbm有一个选项来处理这个问题。它在分割查找过程中忽略丢失的值，然后将它们分配给损失减少最多的那一侧。如果你不想使用选项和应用其他技术，你将需要它的参数为:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="c8e8" class="mu lt iq mq b gy mv mw l mx my">use_missing=false</span></pre><h1 id="38c0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">特征缩放</h1><p id="8129" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">在创建机器学习模型之前的数据预处理期间，特征缩放是机器学习算法中最重要的步骤之一。大多数情况下，您的数据集将包含在量级、单位和范围方面差异很大的要素。但对于大多数机器学习来说，使用未缩放的特征会产生一个问题。</p><p id="a1ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如，线性回归等机器学习方法和使用梯度下降作为优化算法的神经网络需要对数据集进行缩放。当我们使用像K-means和SVM这样受特征范围影响最大的距离算法时，也会出现类似的问题。原因是他们使用数据点之间的距离来确定它们的相似性。</p><p id="910a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">幸运的是，我们不需要担心它的功能扩展。基于树的算法对特征的规模相当不敏感。</p><h1 id="2c67" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">模型评估</h1><p id="8894" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">我用了25%的数据进行验证，其余的用于训练。这里涉及到很多超参数。因此，你的工作就像一个建筑师，寻找最佳值，以最大限度地提高准确性。</p><p id="a106" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有几种技术非常有用，包括GridSearchCV和RandomizedSearchCV。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="5ad7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如您所见，这里涉及到许多参数，但如果您想了解每个参数是什么，请查看此<a class="ae lr" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h1 id="6d5e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="ee61" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">正如我们在下面可以看到的，我们已经获得了训练数据的AUC几乎为98%,验证数据集的AUC为94%。大约花了5分钟。您可以增加“增强迭代次数”以获得更好的训练/验证数据集AUC。您可以考虑这一点，或者更改其他参数来权衡准确性和速度。</p><p id="2e13" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您将能够在CPU上运行Lightgbm。为此，您只需设置以下参数“设备类型”:“GPU”<em class="nx">。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/92b09997e696af63acc4913bc1db27f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*ssIwjsYh5rGs6yAwUAUYQw.png"/></div></figure><p id="b724" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文使用的所有代码都可以从我的<a class="ae lr" href="https://github.com/shosseini811/IEEE-CIS-Fraud-Detection-TWS/blob/master/ieee-fraud.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> GitHub </strong> </a>中访问。我期待听到反馈或问题。</p></div></div>    
</body>
</html>