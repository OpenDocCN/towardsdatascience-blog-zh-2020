<html>
<head>
<title>Ways To Handle Categorical Data With Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用实现处理分类数据的方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ways-to-handle-categorical-data-before-train-ml-models-with-implementation-ffc213dc84ec?source=collection_archive---------5-----------------------#2020-09-10">https://towardsdatascience.com/ways-to-handle-categorical-data-before-train-ml-models-with-implementation-ffc213dc84ec?source=collection_archive---------5-----------------------#2020-09-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7463" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 Python 实现了流行的技术</h2></div><p id="8d23" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我的上一篇博客中，我解释了<a class="ae lb" href="https://medium.com/@g.dhasade16/missing-data-its-types-9f59e897843f" rel="noopener">类型的缺失值</a>以及处理<a class="ae lb" href="https://medium.com/swlh/ways-to-handle-continous-column-missing-data-its-implementations-4704f52ac9c3" rel="noopener">连续</a>和<a class="ae lb" href="https://medium.com/analytics-vidhya/ways-to-handle-categorical-column-missing-data-its-implementations-15dc4a56893" rel="noopener">分类</a>缺失值的不同方法和实现。</p><p id="66dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">处理完数据集中的缺失值后，下一步是处理分类数据。在这篇博客中，我将解释处理分类特征/列的不同方法以及使用 python 的实现。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/c5403966660e23b9db5d180f8df05403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZDIhEEkcV01tS2IhGgQoFw.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图片作者:<a class="ae lb" href="https://unsplash.com/@altumcode" rel="noopener ugc nofollow" target="_blank">altum code</a>|<a class="ae lb" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank">Unsplash.com</a></p></figure><p id="e246" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">简介:</strong>所有的机器学习模型都是某种需要数字进行运算的数学模型。分类数据有可能的值(类别)，它可以是文本形式。比如性别:男/女/其他，职级:1/2/3 等。</p><p id="781e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在处理完数据集的缺失值后，在从事数据科学项目时。下一步工作是在应用任何 ML 模型之前处理数据集中的分类数据。</p><p id="4cf9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们了解分类数据的类型:</p><ol class=""><li id="cbc9" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated"><strong class="kh ir">标称数据:</strong>标称数据称为<strong class="kh ir"> <em class="mb">标注/命名为</em> </strong>数据。允许改变类别的顺序，顺序的改变不影响它的值。比如性别(男/女/其他)、年龄组(年轻/成年/年老)等。</li><li id="f398" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la lx ly lz ma bi translated"><strong class="kh ir">序数数据:</strong>离散地表示<strong class="kh ir"> <em class="mb">，有序地表示单位</em> </strong>。与名义数据相同，但有顺序/等级。不允许改变类别的顺序。比如排名:第一/第二/第三，学历:(高中/本科/研究生/博士)等。</li></ol><p id="3799" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">处理分类特征的方法:</p><p id="a2bb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用来解释的数据集是 Titanic ( <a class="ae lb" href="https://www.kaggle.com/c/titanic" rel="noopener ugc nofollow" target="_blank"> Kaggle dataset </a>):</p><pre class="ld le lf lg gt mh mi mj mk aw ml bi"><span id="4277" class="mm mn iq mi b gy mo mp l mq mr">import pandas as pd<br/>import numpy as np<br/>Data = pd.read_csv("train.csv")<br/>Data.isnull().sum()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/089e368dbb852f68e69108b0ba41f0b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/0*sj-1sl1oG1DRu0vE.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">数据类型-对象是数据集中的分类要素。</p></figure><ol class=""><li id="f2a0" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated"><strong class="kh ir">制造假人</strong></li></ol><p id="572b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">描述:</em> </strong>为对象/类别类型特征中的每个类别创建虚拟或二进制类型列。如果该类别在每行中可用，则该行的值为 1，否则为 0。使用 pandas get_dummies()函数创建虚拟模型。</p><p id="55da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">实现:</em> </strong></p><pre class="ld le lf lg gt mh mi mj mk aw ml bi"><span id="b452" class="mm mn iq mi b gy mo mp l mq mr">DataDummies = pd.get_dummies(Data)<br/>DataDummies</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mt"><img src="../Images/cf1a912cdf1c69691362872513493292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4chWzELkmSlXeQ-zpFSlw.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">示例:乘客类别创建 3 个新列。</p></figure><p id="35e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">优点:</em> </strong></p><ul class=""><li id="30cb" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">易于使用和快速的方法来处理分类列值。</li></ul><p id="ec1d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">劣势:</em> </strong></p><ul class=""><li id="8692" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">当数据有许多分类列时，get_dummies 方法没有用。</li><li id="3f2f" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la mu ly lz ma bi translated">如果类别列有许多类别，会导致向数据集中添加许多要素。</li></ul><p id="71f8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，这种方法仅在数据的分类列较少且类别较少时有用。</p><p id="220f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 2。序数编码</strong></p><p id="f272" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">描述:</em> </strong>当分类变量为序数时，最简单的方法是根据秩用某个序数替换每个标签/类别。在我们的数据中，Pclass 是具有值第一、第二、第三的顺序特征，因此每个类别分别由它的等级，即 1、2、3 代替。</p><p id="758c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">实现:</em> </strong></p><p id="4bec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">步骤 1:创建一个字典，以关键字作为类别，以值作为等级。</p><p id="027e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第 2 步:创建一个新列，并用创建的字典映射 ordinal 列。</p><p id="2315" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第三步:删除原来的列。</p><pre class="ld le lf lg gt mh mi mj mk aw ml bi"><span id="e9e2" class="mm mn iq mi b gy mo mp l mq mr"># 1. <br/>PClassDict =   {   'First':1,<br/>                    'Second':2,<br/>                     'Third':3,              <br/>                }</span><span id="cc7c" class="mm mn iq mi b gy mv mp l mq mr"># 2. <br/>Data['Ordinal_Pclass'] = Data.Pclass.map(PClassDict)</span><span id="96b2" class="mm mn iq mi b gy mv mp l mq mr"># Display result<br/>      <br/>      Data[['PassengerId', 'Pclass', 'Ordinal_Pclass']].head(10)</span><span id="f8e7" class="mm mn iq mi b gy mv mp l mq mr"># 3.</span><span id="41e5" class="mm mn iq mi b gy mv mp l mq mr">Data = Data.drop('Pclass', axis = 1)</span></pre><p id="1446" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">优点:</em> </strong></p><ul class=""><li id="5b06" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">处理数据集中序号要素的最简单方法。</li></ul><p id="411c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">缺点:</em> </strong></p><ul class=""><li id="f4a6" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">不适用于数据集中的名义类型要素。</li></ul><p id="c2b5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 3。计数/频率编码</strong></p><p id="4b74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">描述:</em> </strong>用类别在该列中出现频率/次数替换每个类别。</p><p id="914b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">实现:</em> </strong></p><p id="2267" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一步。创建字典，以关键字作为类别名称，以类别计数作为值，即该类别在每个分类列中的频率。</p><p id="225b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二步。创建一个新列，作为该类别的权重，并映射到相应的字典。</p><p id="06d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第三步。删除原始列。</p><pre class="ld le lf lg gt mh mi mj mk aw ml bi"><span id="b76c" class="mm mn iq mi b gy mo mp l mq mr"># 1.</span><span id="156c" class="mm mn iq mi b gy mv mp l mq mr">Pclass_Dict = Data['Pclass'].value_counts()<br/>Salutation_Dict = Data['Salutation'].value_counts()<br/>Sex_Dict = Data['Sex'].value_counts()<br/>Embarked_Dict = Data['Embarked'].value_counts()<br/>Cabin_Serial_Dict = Data['Cabin_Serial'].value_counts()<br/>Cabin_Dict = Data['Cabin'].value_counts()</span><span id="bda4" class="mm mn iq mi b gy mv mp l mq mr"># 2.</span><span id="098a" class="mm mn iq mi b gy mv mp l mq mr">Data['Encoded_Pclass'] = Data['Pclass'].map(Pclass_Dict)<br/>Data['Salutation_Dict'] = Data['Salutation'].map(Salutation_Dict)<br/>Data['Sex_Dict'] = Data['Sex'].map(Sex_Dict)<br/>Data['Embarked_Dict'] = Data['Embarked'].map(Embarked_Dict)<br/>Data['Cabin_Serial_Dict'] = Data['Cabin_Serial'].map(Cabin_Serial_Dict)<br/>Data['Cabin_Dict'] = Data['Cabin'].map(Cabin_Dict)</span><span id="9655" class="mm mn iq mi b gy mv mp l mq mr"># Display Result</span><span id="8cc2" class="mm mn iq mi b gy mv mp l mq mr">Data[['Pclass','Encoded_Pclass','Salutation','Salutation_Dict','Sex'       ,'Sex_Dict','Embarked','Embarked_Dict','Cabin_Serial','Cabin_Serial_Dict','Cabin','Cabin_Dict']].head(10)</span><span id="0448" class="mm mn iq mi b gy mv mp l mq mr"># 3. <br/>Data = Data.drop(['Pclass','Salutation','Sex','Embarked','Cabin_Serial','Cabin'], axis = 1)</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mw"><img src="../Images/93f0d9742083dad661d3207f5e478ceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCxNQWM76aSIDSlA2xN0Ug.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">每个类别及其频率计数。</p></figure><p id="fedc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">优点:</em> </strong></p><ul class=""><li id="8304" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">向东实施。</li><li id="8b61" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la mu ly lz ma bi translated">不增加任何额外的功能。</li></ul><p id="d76c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">缺点:</em> </strong></p><ul class=""><li id="5b54" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">无法处理相同数量的类别，即向两个类别提供相同的值。</li></ul><p id="8524" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 4。目标/导向编码</strong></p><p id="0de8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">描述:</em> </strong>此处，列的类别已被替换为其相对于目标列的依赖连接概率排名。</p><p id="241c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">实现:</em> </strong>显示我正在使用的关于幸存目标列的 Cabin 列的实现。相同的步骤适用于数据集中的任何顺序列。</p><p id="8c3c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一步。用客舱名称的第一个字符替换原始客舱值。</p><p id="df3b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二步。基于目标列值计算每个类别的联合概率。</p><p id="d4de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第三步。创建一个按连接概率升序排列索引的列表。</p><p id="41c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第四步。创建一个字典，其中键作为类别名，值作为联合概率排名。</p><p id="f075" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第五步。创建一个新列，并使用字典联合概率排名映射客舱值。</p><p id="e3ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第六步。删除原始客舱栏。</p><pre class="ld le lf lg gt mh mi mj mk aw ml bi"><span id="446f" class="mm mn iq mi b gy mo mp l mq mr"><em class="mb"># 1.</em></span><span id="0ca7" class="mm mn iq mi b gy mv mp l mq mr">Data['Cabin'] = Data['Cabin'].astype(str).str[0]</span><span id="d3a2" class="mm mn iq mi b gy mv mp l mq mr"><em class="mb"># 2.</em></span><span id="b704" class="mm mn iq mi b gy mv mp l mq mr">Data.groupby(['Cabin'])['Survived'].mean()</span><span id="0911" class="mm mn iq mi b gy mv mp l mq mr"><em class="mb"># 3.</em></span><span id="8647" class="mm mn iq mi b gy mv mp l mq mr">Encoded_Lables = Data.groupby(['Cabin'])  ['Survived'].mean().sort_values().index</span><span id="e828" class="mm mn iq mi b gy mv mp l mq mr"><em class="mb"># 4.</em></span><span id="8626" class="mm mn iq mi b gy mv mp l mq mr">Encoded_Lables_Ranks = { k:i for i, k in enumerate(Encoded_Lables, 0) }</span><span id="2f64" class="mm mn iq mi b gy mv mp l mq mr"># 5.</span><span id="d335" class="mm mn iq mi b gy mv mp l mq mr">Data['Cabin_Encoded'] = Data['Cabin'].map(Encoded_Lables_Ranks)</span><span id="f080" class="mm mn iq mi b gy mv mp l mq mr"># 6.</span><span id="2b8c" class="mm mn iq mi b gy mv mp l mq mr">Data = Data.drop('Cabin', axis = 1)</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/bd40bfa69e563739cfae6d50e4c3bf35.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*R0nNO4S08OkvlpDo0Hwdtw.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">具有相对于目标列的连接概率等级的客舱值。</p></figure><p id="4d8d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">优点:</em> </strong></p><ul class=""><li id="37e8" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">它不会影响数据量，即不会添加任何额外的功能。</li><li id="30be" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la mu ly lz ma bi translated">帮助机器学习模型更快地学习。</li></ul><p id="b24a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">缺点:</em> </strong></p><ul class=""><li id="4f96" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">通常，均值或联合概率编码导致过拟合。</li><li id="78ce" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la mu ly lz ma bi translated">因此，为了避免过度拟合，大多数时候需要交叉验证或其他方法。</li></ul><p id="0b90" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 5。平均编码</strong></p><p id="98b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">描述:</em> </strong>与目标/导向编码类似，唯一的区别是这里我们用目标列的平均值替换类别。在这里，我们还实现了与客舱和幸存目标列。</p><p id="6e1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">实现:</em> </strong></p><p id="10e5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一步。计算客舱列中每个类别相对于目标列(幸存)的平均值。</p><p id="6443" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二步。创建一个新列并替换为平均值，即使用其编码的平均值字典映射客舱列类别。</p><p id="22a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第三步。丢弃原始座舱立柱</p><pre class="ld le lf lg gt mh mi mj mk aw ml bi"><span id="1c6f" class="mm mn iq mi b gy mo mp l mq mr"># 1.</span><span id="2364" class="mm mn iq mi b gy mv mp l mq mr">Encoded_Mean_Dict = Data.groupby(['Cabin'])['Survived'].mean().to_dict()</span><span id="8454" class="mm mn iq mi b gy mv mp l mq mr"># 2.</span><span id="7734" class="mm mn iq mi b gy mv mp l mq mr">Data['Cabin_Mean_Encoded'] = Data['Cabin'].map(Encoded_Mean_Dict)</span><span id="10cb" class="mm mn iq mi b gy mv mp l mq mr"># Display result</span><span id="f5f1" class="mm mn iq mi b gy mv mp l mq mr">Data[['Cabin','Cabin_Mean_Encoded']].head()</span><span id="e957" class="mm mn iq mi b gy mv mp l mq mr"># 3.</span><span id="9b52" class="mm mn iq mi b gy mv mp l mq mr">Data = Data.drop('Cabin', axis = 1)</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi my"><img src="../Images/75dfc0eba86542017c1554e37e555181.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*o54J4u5nyl845AIo761M_Q.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">客舱类别及其相对于目标列的相应含义。</p></figure><p id="1e0d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">优点:</em> </strong></p><ul class=""><li id="f0ae" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">捕获标签或类别中的信息，提供更多预测功能。</li><li id="0501" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la mu ly lz ma bi translated">在自变量和目标变量之间建立单调的关系。</li></ul><p id="c596" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">缺点:</em> </strong></p><ul class=""><li id="8721" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">可能会导致模型过拟合，为了克服这个问题，大多数时候使用交叉验证。</li></ul><p id="252b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">6。概率比编码</p><p id="23f0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">描述:</em> </strong>这里列的类别被替换为相对于目标变量的概率比。在这里，我使用船舱作为一个独立变量，其类别被替换为每个船舱中幸存人员与死亡人员的概率比。</p><p id="da70" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">实现:</em> </strong></p><p id="1b63" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一步。用客舱名称的第一个字符替换原始客舱值。</p><p id="b73a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二步。找出在特定船舱中幸存的人的百分比(%)，并存储到新的数据帧中。</p><p id="22c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第三步。在幸存概率数据框中创建一个新列，列出在特定船舱中死亡的概率。</p><p id="a6ac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第四步。在幸存概率数据框中再创建一个新列，即幸存概率与死亡概率之比。</p><p id="39cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第五步。创建一个带有概率比列的字典。</p><p id="9a48" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第六步。在数据中创建新列，并用其编码的概率比字典映射客舱列类别。</p><p id="6da4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第七步。放下原来的座舱立柱。</p><pre class="ld le lf lg gt mh mi mj mk aw ml bi"><span id="1ae3" class="mm mn iq mi b gy mo mp l mq mr">#1. </span><span id="2e55" class="mm mn iq mi b gy mv mp l mq mr">Data['Cabin']  = Data['Cabin'].astype(str).str[0]</span><span id="c172" class="mm mn iq mi b gy mv mp l mq mr"># 2. </span><span id="a1ca" class="mm mn iq mi b gy mv mp l mq mr">Probability_Survived = Data.groupby(['Cabin'])['Survived'].mean()<br/>Probability_Survived = pd.DataFrame(Probability_Survived)</span><span id="7b28" class="mm mn iq mi b gy mv mp l mq mr"># 3.</span><span id="cfdf" class="mm mn iq mi b gy mv mp l mq mr">Probability_Survived['Died'] = 1 - Probability_Survived['Survived']</span><span id="2769" class="mm mn iq mi b gy mv mp l mq mr"># 4.</span><span id="e8b5" class="mm mn iq mi b gy mv mp l mq mr">Probability_Survived['Prob_Ratio'] = Probability_Survived['Survived'] / Probability_Survived['Died']</span><span id="e5fa" class="mm mn iq mi b gy mv mp l mq mr"># 5.</span><span id="b834" class="mm mn iq mi b gy mv mp l mq mr">Encode_Prob_Ratio = Probability_Survived['Prob_Ratio'].to_dict()</span><span id="f67b" class="mm mn iq mi b gy mv mp l mq mr"># 6.</span><span id="89d6" class="mm mn iq mi b gy mv mp l mq mr">Data['Encode_Prob_Ratio'] = Data['Cabin'].map(Encode_Prob_Ratio)</span><span id="f869" class="mm mn iq mi b gy mv mp l mq mr"># Display result</span><span id="6c4f" class="mm mn iq mi b gy mv mp l mq mr">Data[['Cabin','Encode_Prob_Ratio']].head(10)</span><span id="12a5" class="mm mn iq mi b gy mv mp l mq mr"># 7.</span><span id="3c52" class="mm mn iq mi b gy mv mp l mq mr">Data = Data.drop('Cabin', axis = 1)</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/5cf650af7540c9647bb26b2d311b62ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*0lp8ZBIu7u9zVSNBLeGGwg.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">客舱类别及其相应的生存概率比。</p></figure><p id="17e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">优点:</em> </strong></p><ul class=""><li id="aa81" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">不增加任何额外的功能。</li><li id="e16c" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la mu ly lz ma bi translated">捕捉标签或类别中的信息，从而创建更多预测功能。</li><li id="965e" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la mu ly lz ma bi translated">创建变量和目标之间的单调关系。所以它适用于线性模型。</li></ul><p id="4bf8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mb">缺点:</em> </strong></p><ul class=""><li id="1671" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la mu ly lz ma bi translated">分母为 0 时未定义。</li><li id="fdee" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la mu ly lz ma bi translated">与上述两种方法相同，会导致过度拟合，为了避免和验证，通常会进行交叉验证。</li></ul><p id="57ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">结论:</strong></p><p id="bde1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，在这篇博客中，我试图解释在为机器学习准备数据时处理分类变量的最广泛使用的方法。实际代码笔记本可从<a class="ae lb" href="https://github.com/GDhasade/Medium.com_Contents/blob/master/Handle_Categorical_Data.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/GDhasade/medium . com _ Contents/blob/master/Handle _ categorial _ data . ipynb</a>获得</p><p id="1a4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">欲了解更多信息，请访问<a class="ae lb" href="http://contrib.scikit-learn.org/category_encoders/index.html" rel="noopener ugc nofollow" target="_blank">http://contrib . sci kit-learn . org/category _ encoders/index . html</a>。</p><p id="b226" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参考资料:</p><ol class=""><li id="b261" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">Scikit-learn.org(2019)。<em class="mb">sk learn . preprocessing . onehotencoder—scikit-learn 0.22 文档</em>。[在线]可从以下网址获得:<a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html." rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . preprocessing . onehotencoder . html</a></li><li id="72a3" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la lx ly lz ma bi translated">‌contrib.scikit-learn.org(未标明)。<em class="mb">类别编码器——类别编码器 2.2.2 文件</em>。[在线]见:<a class="ae lb" href="http://contrib.scikit-learn.org/category_encoders/index.html." rel="noopener ugc nofollow" target="_blank">http://contrib . sci kit-learn . org/category _ encoders/index . html</a></li><li id="4cb0" class="ls lt iq kh b ki mc kl md ko me ks mf kw mg la lx ly lz ma bi translated">克里斯·纳伊克(2019)。<em class="mb">特征工程-如何对多分类变量进行一次热编码</em>。YouTube 。可在:<a class="ae lb" href="https://www.youtube.com/watch?v=6WDFfaYtN6s&amp;list=PLZoTAELRMXVPwYGE2PXD3x0bfKnR0cJjN&amp;ab_channel=KrishNaik" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=6WDFfaYtN6s&amp;list = plzotaelrmxvpwyge 2 pxd 3 x 0 bfknr0cjn&amp;ab _ channel = KrishNaik</a>【2020 年 9 月 10 日获取】。</li></ol><p id="63a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi">‌</p></div></div>    
</body>
</html>