<html>
<head>
<title>Explaining Text classifier outcomes using LIME</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用LIME解释文本分类器结果</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-makes-your-question-insincere-in-quora-26ee7658b010?source=collection_archive---------32-----------------------#2020-06-07">https://towardsdatascience.com/what-makes-your-question-insincere-in-quora-26ee7658b010?source=collection_archive---------32-----------------------#2020-06-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3f91" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">是什么让你的问题在Quora变得不真诚？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/43d644c260c315b7fd3dbf4d3ca41299.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y4mjEWSI8ES6iROSBJHU3g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Jules Bss 在<a class="ae kv" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="9394" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在之前关于在现实世界应用中利用可解释性的<a class="ae kv" rel="noopener" target="_blank" href="/leveraging-explainability-in-real-world-ml-applications-part-1-3be567c00594">帖子</a>中，我简要介绍了XAI(人工智能中的可解释性)，它背后的动机，以及可解释模型在现实生活场景中的应用。</p><p id="4503" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我将介绍LIME，这是最著名的本地可解释模型之一，以及如何应用它来检测使Quora平台中的问题不真诚的术语。</p><h1 id="466e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">什么是石灰，它是如何工作的？</h1><p id="eea8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">作者在[1]中提出了LIME，它是一种算法，通过用一个可解释的模型局部地近似它们，以一种可靠和可理解的方式解释任何分类器或回归变量的单个预测。</p><p id="b6d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，ML模型使用一组特征(喷嚏、体重、头痛、无疲劳和年龄)预测患者患有流感，而LIME突出显示了患者历史中导致预测的症状(最重要的特征)。打喷嚏和头痛被认为是导致流感的原因，而没有证据表明疲劳会导致流感。有了这些解释，医生就可以做出是否相信模型预测的明智决定。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/4ce4aa761b504507b81a13fb5f2aa01d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iG1y6tZWtGo-e7f7eE98vw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:“我为什么要相信你？”<br/>解释任何分类器的预测[1]</p></figure><blockquote class="mq mr ms"><p id="28cb" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated"><em class="iq">解释预测是呈现文本或视觉工件，提供对实例组件(例如文本中的单词、图像中的补丁)和模型预测之间关系的定性理解[1]。</em></p></blockquote><h2 id="60d1" class="mx lt iq bd lu my mz dn ly na nb dp mc lf nc nd me lj ne nf mg ln ng nh mi ni bi translated">石灰背后的直觉</h2><p id="9e72" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">LIME是一个局部代理模型，这意味着它是一个经过训练的模型，用于近似底层黑盒模型的预测。但是，它的想法是将数据的变化生成到机器学习模型中，并测试预测会发生什么，使用这种扰动的数据作为训练集，而不是使用原始的训练数据。</p><p id="3b83" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">换句话说，LIME生成一个新的数据集，由置换样本和黑盒模型的相应预测组成。在这个新的数据集上，LIME然后训练可解释的模型(例如，Lasso、决策树等等)，该模型通过采样实例与感兴趣实例的接近度来加权。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/fab579067d7d5117ec81de95397fced6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*jI5jsDzvzIa-XeC9Nl11Yg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">加粗的红叉是正在解释的例子。LIME对实例进行采样，使用黑盒模型(由蓝色/粉色背景表示)获得预测，并通过与被解释的实例的接近程度(此处由大小表示)对它们进行加权。虚线是学习过的局部解释[1]。</p></figure><h1 id="55b3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">将LIME应用于Quora数据集和逻辑回归模型</strong></h1><p id="d325" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">Quora虚假问题分类任务的数据集可以从这个<a class="ae kv" href="https://www.kaggle.com/c/quora-insincere-questions-classification/data" rel="noopener ugc nofollow" target="_blank">链接</a>下载。训练数据包括被问的问题，以及它是否被识别为不真诚。</p><p id="0a56" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们来看这个数据集的两个问题和对应的类(1为不真诚，0为真诚的问题):</p><ul class=""><li id="52e5" class="nk nl iq ky b kz la lc ld lf nm lj nn ln no lr np nq nr ns bi translated">不真诚的问题:为什么特朗普相信普京告诉他的一切？他是共产主义者，还是愚蠢透顶？</li><li id="4b0f" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">真诚的问题:纬度和繁荣之间的强相关性可以部分地用另一个(如果被证明存在的话)有利的环境温度和大脑着迷之间的相关性来解释吗？</li></ul><p id="ac70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预处理步骤包括将数据分为训练集和验证集，然后将问题矢量化为tf-idf向量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nz l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">预处理代码。</p></figure><p id="2496" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">黑盒模型是一个逻辑回归模型，以tf-idf向量作为输入。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nz l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作为黑箱模型的逻辑回归。</p></figure><p id="87bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在是时候应用LimeTextExplainer函数来为预测生成局部解释了。该函数需要解释的问题(索引130609)、从黑盒模型(逻辑回归)生成的问题的预测标签以及用于解释的特征数量作为参数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nz l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用LimeTextExplainer为一个实例生成解释。</p></figure><p id="13fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上述代码的结果如下:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="df0e" class="mx lt iq ob b gy of og l oh oi">Question: <br/>When will Quora stop so many utterly stupid questions being asked here, primarily by the unintelligent that insist on walking this earth?<br/>Probability (Insincere) = 0.745825811972627<br/>Probability (Sincere) = 0.254174188027373<br/>True Class is: insincere</span></pre><p id="c560" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分类器把这个例子做对了(它预测言不由衷)。<br/>使用以下说明，以加权特征列表的形式给出解释:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="5c60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果是:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="7def" class="mx lt iq ob b gy of og l oh oi">[('stupid', 0.3704823331676872),<br/> ('earth', 0.11362862926025367),<br/> ('Quora', 0.10379246842323496),<br/> ('insist', 0.09548389743268501),<br/> ('primarily', -0.07151150302754253),<br/> ('questions', 0.07000885924524448),<br/> ('utterly', 0.040867838409334646),<br/> ('asked', -0.036054558321806804),<br/> ('unintelligent', 0.017247304068062203),<br/> ('walking', -0.004154838656529393)]</span></pre><p id="d383" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些加权特征是一个线性模型，它近似于测试实例附近的逻辑回归分类器的行为。粗略地说，如果我们从问题中删除“愚蠢”和“地球”，预测应该向相反的类别(真诚)移动大约0.48(两个特征的权重之和)。我们来看看是不是这样。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="5e13" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果是:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="833f" class="mx lt iq ob b gy of og l oh oi">Original prediction: 0.745825811972627<br/>Prediction after removing some features: 0.33715161522095155<br/>Difference: -0.40867419675167543</span></pre><p id="03b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不出所料，在从实例词汇表中删除了“地球”和“愚蠢”这两个词后，这个类现在变得真诚了。</p><p id="749a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果可以显示在不同类型的可视化石灰。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nz l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/4dbe312f3ff5df1ff6275bd013126c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*92po5tbKQaDMh-maCp39tA.png"/></div></div></figure><p id="9b32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，对于每一类，线上右边的单词是正的，左边的单词是负的。因此，“愚蠢”对不真诚是积极的，但对真诚是消极的。</p><p id="2c18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您还可以使用下面的代码获得解释的条形图:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nz l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/41309f304c7a6a8a131cd905a400af0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O25xNXAmCGe9ZFx0tpMSrA.png"/></div></div></figure><h1 id="52e9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">摘要</h1><p id="dee1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">LIME能够在本地解释任何类型的分类器(SVM、神经网络等)的预测。在这篇文章中，我将其应用于Quora问题数据集，以解释是什么使Quora中的问题不真诚，但它也可以集成到图像和结构化数据分类器中。您可以通过此<a class="ae kv" href="https://github.com/marcotcr/lime/tree/master/doc/notebooks" rel="noopener ugc nofollow" target="_blank">链接</a>访问更多代码和示例。</p><p id="deda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你有问题，欢迎在下面评论或通过<a class="ae kv" href="http://amami.maha@ymail.com" rel="noopener ugc nofollow" target="_blank">邮箱</a>或<a class="ae kv" href="https://www.linkedin.com/in/maha-amami-phd-088b42b2/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>提问。我会回答的。</p><p id="5a98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">全部代码发布在我的<a class="ae kv" href="https://github.com/amamimaha" rel="noopener ugc nofollow" target="_blank"> GITHUB简介</a>的<a class="ae kv" href="https://github.com/amamimaha/Explainable-Models/blob/master/Quora%20sincere%20questions.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a>中。</p><p id="e97a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我会继续张贴关于XAI和其他有趣的话题。敬请期待！！</p><h1 id="35b3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="525f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">[1]里贝罗，M. T .，辛格，s .，&amp; Guestrin，C. (2016年8月)。“我为什么要相信你？”解释任何分类器的预测。《第22届ACM SIGKDD知识发现和数据挖掘国际会议论文集》(第1135-1144页)。</p><p id="d50f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">石灰码:<a class="ae kv" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">https://github.com/marcotcr/lime</a></p></div></div>    
</body>
</html>