<html>
<head>
<title>Convolutional Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-network-1368ee2998d3?source=collection_archive---------36-----------------------#2020-05-03">https://towardsdatascience.com/convolutional-neural-network-1368ee2998d3?source=collection_archive---------36-----------------------#2020-05-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ebdb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">理解层背后的直觉</h2></div><p id="12a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1950 年，艾伦·图灵提交了一篇名为<strong class="kh ir"> <em class="lb">的论文图灵测试，</em> </strong>其中<strong class="kh ir"> <em class="lb"> </em> </strong>他为机器被称为智能机器奠定了基础。尽管在人工智能领域取得了突破，但即使在今天，机器也不能被视为智能的。神经网络是人工智能的一个领域，旨在模仿人体的大脑结构。人工神经网络(ANN)是神经网络的一种基本类型，它能有效地发现数据中的隐藏模式并给出结果。</p><blockquote class="lc ld le"><p id="3b2a" class="kf kg lb kh b ki kj jr kk kl km ju kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated">注意:本文假设读者对神经网络有基本的了解</p></blockquote><blockquote class="li"><p id="5f90" class="lj lk iq bd ll lm ln lo lp lq lr la dk translated">一个问题仍然存在，即使机器可以处理和理解给它们的数据，但它们有能力像人类一样看东西吗？</p></blockquote><p id="4a51" class="pw-post-body-paragraph kf kg iq kh b ki ls jr kk kl lt ju kn ko lu kq kr ks lv ku kv kw lw ky kz la ij bi translated"><strong class="kh ir">是的！为机器提供视觉似乎是一件荒谬的事情，但一种叫做<strong class="kh ir"> <em class="lb">卷积神经网络</em> </strong>的神经网络赋予了机器部分视觉。</strong></p><p id="cfdf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然一个图像只是数值像素值的集合，ANN 的就不能处理吗？这个问题的答案是<strong class="kh ir">不！</strong>虽然人工神经网络对数值数据分类很好，但在处理图像时缺乏对空间关系的考虑。我来简化一下。在处理图像列表时，如果 ANN 发现一只猫出现在一幅图像的右上角，那么它将假设它将一直出现在那里。因此，无论你的猫在图像的哪个位置，如果它不能在右上角找到它，那么它将给出一个否定的结果。</p><p id="0019" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一方面，卷积神经网络，也称为<strong class="kh ir"> <em class="lb"> ConvNet </em> </strong>在图像中的任何地方寻找物体时表现都异常出色。还有，如果你的猫脾气暴躁也不用担心，它还是会识别的。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi lx"><img src="../Images/a82f291a6ee1d16848a735facc639291.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7hd8FZeI_eodazwIapvAw.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">图片来源:Adesh desh pande via<a class="ae mn" href="https://github.com/adeshpande3/adeshpande3.github.io/blob/master/assets/Cover.png" rel="noopener ugc nofollow" target="_blank">GitHub</a>(麻省理工)</p></figure><p id="d90f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上图展示了 ConvNet 的基本架构，其中包含池化、FC 层、卷积等术语，乍一看似乎令人不知所措。本文旨在揭开这些术语的神秘面纱，并获得使用它们背后的直觉。</p><p id="c9d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">入门，先来了解一下我们在给网络喂什么！</em>T25】</strong></p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mo"><img src="../Images/f81dec44e1d646e032e469f82cbf2bd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IcZbKCSt6DvBfm387N182w.jpeg"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">安德烈·迈克在<a class="ae mn" href="https://unsplash.com/t/nature?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="784d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们看到的图像看起来很迷人。但机器不是这么看的。它将其视为代表颜色通道强度值的数字像素值的集合。这张图片的尺寸是 5999 x 4000 x 3；其中 3 表示颜色通道的数量，即 RGB。其他颜色通道可以是 HSV、灰度等等。</p><h2 id="f660" class="mp mq iq bd mr ms mt dn mu mv mw dp mx ko my mz na ks nb nc nd kw ne nf ng nh bi translated">机器如何从像素值中提取特征？</h2><p id="4801" class="pw-post-body-paragraph kf kg iq kh b ki ni jr kk kl nj ju kn ko nk kq kr ks nl ku kv kw nm ky kz la ij bi translated">在数学中，一个称为卷积的概念将两个函数考虑在内，并产生第三个函数来表达一个函数的形状如何受另一个函数的影响。想象一下将滤镜应用到照片上。这里发生的是，它采取你的照片，并应用过滤器的功能，这可能是为了突出阴影。滤镜激活图像的某些功能，并生成输出图像。</p><p id="5fe3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">那么问题来了，这些滤镜是什么？</em> </strong>滤镜只不过是具有特定值的 3D 矩阵，当它们在附近看到想要的图案时会变得兴奋。它们比在图像的宽度和高度上滑动的输入图像小得多。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi nn"><img src="../Images/dce9fe74bd31341e922b2b52c68514d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/1*Ff6mG3aPdWFkjb6hZPy3Xw.gif"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">用 3×3 滤波器对 5×5 图像进行卷积运算。摄影:Rob Robinson on <a class="ae mn" href="https://mlnotebook.github.io/img/CNN/convSobel.gif" rel="noopener ugc nofollow" target="_blank"> MLNoteBook </a></p></figure><p id="7ec6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当滤镜滑过图像时，它会聚焦在图像的某个邻域。它执行过滤器和图像部分的算术运算，并将结果存储在单个单元格中。在技术术语中，细胞被视为<strong class="kh ir">神经元</strong>。多个这样的神经元，当组合在一起时，形成了一个 2D 矩阵，称为<strong class="kh ir">激活图/特征图，</strong>或者更确切地说，我会说是来自图像的过滤器的喜好的集合<strong class="kh ir">。</strong>单个神经元指向的邻域称为<strong class="kh ir">局部感受野。</strong></p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi no"><img src="../Images/c8e0789763010762cb3be2b3150bab04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rlkTTRUNCnfXGD0RGNF5Eg.jpeg"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">算术运算和局部感受野。Rob Robinson 在<a class="ae mn" href="https://mlnotebook.github.io/post/CNN1/" rel="noopener ugc nofollow" target="_blank"> MLNoteBook </a>上拍摄的照片</p></figure><p id="508f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个特征图是一个过滤器提取特征的结果。对于卷积图层，会使用多个要素，进而生成多个要素地图。要素地图堆叠在一起，作为输入传递给下一个图层。</p><blockquote class="li"><p id="5ba9" class="lj lk iq bd ll lm np nq nr ns nt la dk translated">过滤器的数量越多，特征图的数量就越多，特征的提取就越深入。</p></blockquote><h2 id="4ff6" class="mp mq iq bd mr ms nu dn mu mv nv dp mx ko nw mz na ks nx nc nd kw ny nf ng nh bi translated">输出图像的大小会发生什么变化？</h2><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/736539d77018b425e62c49305912fd11.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/1*BMngs93_rm2_BpJFH2mS0Q.gif"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">卷积运算。图片作者:<a class="ae mn" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/gif/no_padding_strides.gif" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的<a class="ae mn" href="https://github.com/vdumoulin" rel="noopener ugc nofollow" target="_blank"> vdumoulin </a>(麻省理工学院)</p></figure><p id="7546" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">卷积运算后，输出图像的尺寸必然会减小。控制输出音量大小的参数是步幅、滤波器大小和填充。</p><ol class=""><li id="3f23" class="oa ob iq kh b ki kj kl km ko oc ks od kw oe la of og oh oi bi translated"><strong class="kh ir">步幅</strong>:步幅是我们滑动滤镜时移动的像素数。当步幅为 2 时，我们将过滤器移动 2 个像素。步幅越高，输出音量越小。通常，我们将步幅设置为 1 或 2。</li><li id="593b" class="oa ob iq kh b ki oj kl ok ko ol ks om kw on la of og oh oi bi translated"><strong class="kh ir">过滤器大小</strong>:当我们增加过滤器大小时，我们间接增加了单个神经元中存储的信息量。在这种情况下，滤镜在图像上移动的次数会减少。这将最终导致输出体积的空间尺寸的减小。</li></ol><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi oo"><img src="../Images/e738cd2dd5144c38f08aeddd46603823.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*yU-zyweXUf-xB3ZNMm0miA.jpeg"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">填充 1</p></figure><p id="4fe1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.<strong class="kh ir">填充</strong>:顾名思义，它在原始图像周围添加一个无关紧要的覆盖物，以保持输出图像的大小不变。使用公式<strong class="kh ir"> <em class="lb">计算要添加的层数 P=(((O-1)*S)+F-W)/2 </em> </strong>其中 O 是输出图像的大小，W 是输入图像的大小，F 是滤波器大小，P 是要作为填充添加的层像素的数量，S 是跨距。例如，如果输入图像的大小是 5×5，过滤器的大小是 3×3，步幅是 1，并且我们希望输出图像的大小与输入图像的大小相同，则有效填充将是 1。</p></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><p id="74eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经完成了图片的大部分工作，是时候考虑下一步了。</p><p id="18e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们渴望让我们的神经网络变得灵活，也就是说，无论数据是什么，它都应该足够有效地从数据中进行识别。由于我们拥有的特征地图可以用一些线性函数来表示，不确定性因素似乎消失了。我们需要函数将不确定性，或者我应该说是非线性引入我们的神经网络。</p><p id="0e8d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有许多函数能够执行此任务，但这两个函数被广泛使用。</p><p id="6eab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> Sigmoid </strong>:它使用 g(z)=1/1+e⁻ᶻ函数引入非线性，该函数将数字转换为 0-1 之间的范围。Sigmoid 函数的主要问题之一是<strong class="kh ir"> <em class="lb">消失梯度问题</em> </strong>。如果你不熟悉这个术语，不要担心。由奇-汪锋撰写的这篇<a class="ae mn" rel="noopener" target="_blank" href="/the-vanishing-gradient-problem-69bf08b15484">文章</a>解释了渐变消失的现象。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/fb7f80a2e01402a8f726cb62d033ceca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*Muom3fodryX3-ZEuM36TTQ.jpeg"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">Sigmoid 函数图</p></figure><p id="33fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> ReLU: </strong> ReLU 代表整流线性单元。它使用函数<strong class="kh ir"> <em class="lb"> g(w)=max(0，w)将输入阈值设为 0。</em></strong>ReLU 的性能也优于 Sigmoid 函数，它部分解决了消失梯度问题。虽然 ReLU 所遭受的一个问题是<a class="ae mn" href="https://www.quora.com/What-is-the-dying-ReLU-problem-in-neural-networks?share=1" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> <em class="lb">垂死的 ReLU</em></strong></a><strong class="kh ir"><em class="lb"/></strong>问题，但它的变体<a class="ae mn" href="https://medium.com/@himanshuxd/activation-functions-sigmoid-relu-leaky-relu-and-softmax-basics-for-neural-networks-and-deep-8d9c70eed91e" rel="noopener"> <strong class="kh ir">泄漏的 ReLU </strong> </a>解决了这个问题。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/bd66135f4d0d518fe290d2c015faf715.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*L-wptLErOeXBAJm5JhKstg.jpeg"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">ReLU 函数的一个图</p></figure></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><p id="07c8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经使我们的网络强大到足以适应变化，我们可以把注意力集中在计算时间的另一个问题上。如果你还记得，我们的图像的尺寸是 5999 x 4000 x 3，对于一个单独的图像来说有 71，988，000 个像素值，我们有很多这样的图像。虽然机器的速度非常快，但处理这些数量庞大的像素值需要相当长的时间。</p><p id="8537" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个基本的本能是在群体中选择一个主导价值。这是通过机器使用称为<strong class="kh ir">池的操作来实现的。</strong></p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/23fddf498d64f82175d014e1074a5afa.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*x58wTMbUhoYHiRWtoNMjEA.jpeg"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">图像的缩减采样。图片来自<a class="ae mn" href="https://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank"> Github </a>(麻省理工学院)</p></figure><p id="1af9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们定义一个池窗口，比如说 2 x 2。类似于过滤器，该窗口在图像上滑动，并从窗口中选择一个主导值。<strong class="kh ir">主导</strong>的定义随着方法而变化。</p><p id="ae3f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中一种方法是<strong class="kh ir"> Max Pooling </strong>，这是一种广泛流行的方法，从窗口内的图像中选择最大值。这将尺寸减小到 25%。其他汇集方法包括<strong class="kh ir">平均汇集</strong>、<strong class="kh ir">矩形邻域的 L2 范数</strong>，其不同之处在于选取主导值的方法。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/35d733f25d6ed0b0bb4fe759433b7316.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*iv7fsvgvJ5eBv--iabxqkA.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">最大池化。图片来自<a class="ae mn" href="https://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank"> Github </a>(麻省理工学院)</p></figure><p id="ca60" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，拥有<strong class="kh ir"> <em class="lb">池层</em> </strong>的主要动机是为了降维。虽然，已经有关于移除池层并用卷积层代替它的讨论。<a class="ae mn" href="https://arxiv.org/abs/1412.6806" rel="noopener ugc nofollow" target="_blank">力求简单:全卷积网</a>提出了一个这样的架构，他们建议偶尔使用更大的步幅来减少初始表示的维数。</p></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><p id="3e7f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">人工神经网络和 CNN 之间的关键区别是 CNN 处理图像中空间关系的能力，除此之外，两者的计算能力是相同的。既然我们已经提供了一个使用卷积、激活和汇集来处理空间关系的平台，我们现在可以利用 ANN 的能力。</p><p id="153f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">全连接层</em> </strong>是常规神经网络或多层 Perceptron (MLP)的代表。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/31d752108098a499158ca3a1e8679757.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*3jGDcf5iWSoZVswgfO1VAw.jpeg"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">多层感知器</p></figure><p id="5bf0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用这些层的主要思想是通过卷积层和池层提取的高级特征的非线性组合进行学习。在训练网络时，神经元之间的权重作为一个参数，在训练时进行调整。由于这一层接受 1D 矢量形式的输入，我们需要<strong class="kh ir"> <em class="lb">展平</em> </strong>来自先前层的输出，以馈送到 FC 层。</p><p id="81ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在分类多个类别的情况下，该层的输出是每个类别的真实值。为了从这些值中获得一些洞察力，使用了<strong class="kh ir"> <em class="lb"> Softmax 函数</em> </strong>。更多关于 Softmax 功能的信息可以在这里找到<a class="ae mn" href="https://victorzhou.com/blog/softmax/" rel="noopener ugc nofollow" target="_blank">。它将这些真实值转换成类别概率。然后提取概率最高的类别作为预测类别。</a></p></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><p id="331d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然这些不是构建 CNN 时使用的唯一层，但它们是它的基本构件。根据问题的性质，可以添加多种其他类型的图层，例如缺失图层和归一化图层。</p><p id="2f05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有许多 CNN 架构已经被证明在图像分类上表现得非常好。其中几个是:</p><ol class=""><li id="9b04" class="oa ob iq kh b ki kj kl km ko oc ks od kw oe la of og oh oi bi translated">AlexNet</li><li id="bd52" class="oa ob iq kh b ki oj kl ok ko ol ks om kw on la of og oh oi bi translated">VGGNet</li><li id="de84" class="oa ob iq kh b ki oj kl ok ko ol ks om kw on la of og oh oi bi translated">雷斯内特</li><li id="1f1c" class="oa ob iq kh b ki oj kl ok ko ol ks om kw on la of og oh oi bi translated">开始</li><li id="d274" class="oa ob iq kh b ki oj kl ok ko ol ks om kw on la of og oh oi bi translated">DenseNet</li></ol><div class="pd pe gp gr pf pg"><a rel="noopener follow" target="_blank" href="/architecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd ir gy z fp pl fr fs pm fu fw ip bi translated">AlexNet、VGGNet、ResNet、Inception、DenseNet 的架构比较</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">ILSVRC 挑战结果中具有超参数和准确性的图层描述</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="pq l pr ps pt pp pu mh pg"/></div></div></a></div><p id="5391" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然这些架构已经可以使用了，但是我强烈建议您尝试一下这些架构，并构建一个您自己的架构。</p></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><p id="cf02" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">感谢阅读！希望这篇文章有助于获得关于卷积神经网络的基本直觉。如有任何反馈或建议，可通过我的</em> </strong> <a class="ae mn" href="mailto:gpithadia@gmail.com" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> <em class="lb">邮箱</em></strong></a><strong class="kh ir"><em class="lb"/></strong><a class="ae mn" href="https://www.linkedin.com/in/geetpithadia3/" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir"><em class="lb">LinkedIn</em></strong><strong class="kh ir"><em class="lb">联系我。我很想听听！</em> </strong></a></p><p id="db55" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下一篇文章将关注 CNN 的一个端到端例子！ </p><p id="e69f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">快乐学习！</em> </strong></p></div></div>    
</body>
</html>