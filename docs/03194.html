<html>
<head>
<title>Machine Learning Terms You Can’t Avoid</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你无法回避的机器学习术语</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-terms-you-cant-avoid-3528b2a41489?source=collection_archive---------40-----------------------#2020-03-26">https://towardsdatascience.com/machine-learning-terms-you-cant-avoid-3528b2a41489?source=collection_archive---------40-----------------------#2020-03-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="67b1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">无论你多么努力…</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/00e3673310306e8b57bf4a816dea2a21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H5t3IbdLTSyw6TdAt-rSzg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">安迪·凯利在<a class="ae ky" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="7140" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">介绍</h2><p id="b1a1" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi mo translated"><span class="l mp mq mr bm ms mt mu mv mw di"> J </span>就像上图中的小女孩一样，她将无法避免机器人技术对她未来的影响，作为机器学习从业者，我们无法简单地避免某些术语。</p><p id="1121" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">这些是机器学习领域的基本术语。他们参与神经网络的实现、训练、改进和评估。</p><h2 id="aedb" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">花一些时间来学习每个术语，并进一步研究每个词如何对机器学习模型的开发不可或缺。</h2></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="41a4" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">学习率</h2><p id="449a" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">学习率是神经网络不可或缺的组成部分，因为它是一个值因子，决定了网络权重值的更新级别。</p><p id="32ae" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">在可视化练习中，要求解的函数可以被描述为n维参数空间中的双曲线，学习率是影响当前参数值朝向局部/全局最小值的步长的分量。因此，学习速率直接影响训练期间网络的收敛速率。</p><p id="8237" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">如果学习率太低，网络可能需要几次迭代和历元才能收敛，相反，如果学习率太高，则有超过最小值的风险，因此我们的训练不会收敛。</p><p id="693a" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">选择合适的学习速率可能是一个漫长的过程，尽管有一些技术可以优化这个过程。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="d20a" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">学习率计划</h2><p id="0576" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在神经网络的训练期间，可以利用恒定的学习速率，但是这可能增加为了达到最佳神经网络性能而必须进行的训练量。</p><p id="be18" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">通过利用学习速率表，我们在训练期间引入学习速率的适时降低或增加，以达到神经网络的最佳训练结果。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="027f" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">学习率衰减</h2><p id="8e53" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">学习率衰减减少了梯度下降过程中朝向局部最小值采取的步长的振荡。</p><p id="796d" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">通过将学习率降低到与训练开始时使用的学习率值相比更小的值，我们可以将网络引向在最小值附近的更小范围内振荡的解。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="7350" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">消失梯度</h2><p id="f625" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">消失梯度问题是神经网络性能和精度的一个限制因素。它是反向传播过程中梯度值不稳定的产物，影响神经网络中的早期层。</p><p id="9f16" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">消失梯度更具体地存在于深度神经网络(具有若干层的网络)的训练中。所以这是大多数深度学习解决方案中普遍存在的问题。</p><p id="8af5" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">在反向传播期间，优化算法通过考虑来自网络中后面层的梯度的累积积来导出梯度。具体来说，对于消失梯度的问题，来自网络的较后层的梯度具有0和1之间的值。因此，梯度的乘积产生了更小的量。</p><p id="67ac" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">这些小值用于更新网络中较早层的权重，这实际上对当前权重值几乎没有改变。</p><p id="283a" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">早期层中神经网络权重的最小变化限制了网络可以学习的程度。此外，网络的训练可能需要更长的时间，因为网络需要更长的时间来收敛并达到最优解。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="6938" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">爆炸梯度</h2><p id="425a" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">类似于消失梯度问题，爆炸梯度问题是反向传播期间神经网络内梯度不稳定的结果。</p><p id="3c2a" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">在爆炸梯度的情况下，如果网络中后面层的单个梯度分量大于1，那么在反向传播期间用于计算前面层的梯度的后面层的乘积将是巨大的。</p><p id="3e7e" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">这使得对早期层中的权重的更新具有更高的值；因此，神经网络超过了最优解，并且训练不收敛。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="5100" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">批量标准化</h2><p id="c940" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">传统的归一化是将要素输入值放置在同一组等价尺度上的过程。因此，对于通过网络转发的图像输入值，像素值被归一化为0到1范围内的值。</p><p id="4153" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">Christian Szegedy和Sergey Ioffe在2015年发表的<a class="ae ky" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank">论文</a>中提出了批量标准化技术。通过在神经网络层引入输入值的内部标准化，批量标准化被作为<strong class="lx iu">加速深度神经网络</strong>训练阶段的解决方案。</p><p id="8208" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">可以在激活函数之前或之后对神经网络层的输入应用批处理规范化。在任一情况下，图层的输出都是归一化的。</p><p id="9000" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">批量标准化过程分为两个阶段，标准化和规范化。以下是对输入值进行操作的步骤:</p><ul class=""><li id="d764" class="nj nk it lx b ly mx mb my li nl lm nm lq nn mn no np nq nr bi translated"><strong class="lx iu">通过减去平均值并除以标准偏差量，零点将输入值</strong>居中。这提供了运行中的当前输入批次，其平均值为0，标准偏差为1</li><li id="9fa8" class="nj nk it lx b ly ns mb nt li nu lm nv lq nw mn no np nq nr bi translated"><strong class="lx iu">缩放输入值</strong></li><li id="e857" class="nj nk it lx b ly ns mb nt li nu lm nv lq nw mn no np nq nr bi translated"><strong class="lx iu">偏移输入值</strong></li></ul><p id="a689" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">通过批量标准化，标准化数据的过程不再局限于网络的输入层，现在是神经网络的内部组成部分。表示批量标准化操作中的<em class="nx">偏移</em>和<em class="nx">刻度</em>的参数值也可以在训练期间学习。</p><p id="3823" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">通过可学习的批量归一化参数，每一层的输入值被最佳地归一化。</p><p id="1f73" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">它被称为“批量”规范化，因为所执行的操作是基于通过网络输入的每一批输入值。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="5fa4" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">渐变剪辑</h2><p id="1b27" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">梯度裁剪是一种用于调节神经网络内梯度值不稳定性的技术。这是通过对梯度值施加阈值来实现的。</p><p id="ecd7" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">阈值通常指定在选定的最小值和最大值之间。并且在反向传播期间，梯度值取定义的最小值和最大值内的值。</p><p id="f0f3" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">梯度裁剪主要用于在训练深度神经网络时防止梯度爆炸。它调节从梯度下降优化算法得到的步长，防止其取大值。这确保了我们不会超过全球最小值</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="f46f" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结论</h2><p id="0dee" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">我们已经学习了七个标准的机器学习术语，并深入了解了每个术语的表层细节。</p><p id="993c" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">展望未来，我建议探索一下在流行的深度学习库中，如Keras、Pytorch和TensorFlow，提到的每个术语是如何实现的。</p><p id="0f45" class="pw-post-body-paragraph lv lw it lx b ly mx ju ma mb my jx md li mz mf mg lm na mi mj lq nb ml mm mn im bi translated">下面是几篇文章，你可以阅读，以获得更多关于机器学习的知识。</p><div class="ny nz gp gr oa ob"><a rel="noopener follow" target="_blank" href="/in-depth-machine-learning-image-classification-with-tensorflow-2-0-a76526b32af8"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">使用TensorFlow 2.0进行(深入)机器学习图像分类</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">理解实现用于图像分类的神经网络的过程。</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">towardsdatascience.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op ks ob"/></div></div></a></div><div class="ny nz gp gr oa ob"><a rel="noopener follow" target="_blank" href="/understanding-motion-analysis-in-machine-learning-f504e9987413"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">理解机器学习中的运动分析</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">一篇关于运动分析基础的简短文章，以及机器学习如何被用来解决这个计算机…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">towardsdatascience.com</p></div></div><div class="ok l"><div class="oq l om on oo ok op ks ob"/></div></div></a></div></div></div>    
</body>
</html>