# 您应该在哪里部署您的模型？

> 原文：<https://towardsdatascience.com/where-should-you-deploy-your-model-8b67328b37c3?source=collection_archive---------56----------------------->

## AWS 是部署的终极目标吗，或者还有更多故事？

![](img/9c449e4c16aec35135f8d6ab829509a5.png)

(图片由作者提供)

您已经完成了清理数据的工作。您已经设计了功能，销毁了丢失的值，并创建了一个非常适合预测您的目标的模型。您终于准备好将这个模型投入生产了，但是您必须部署您的模型的选项数量太多了。虽然我们非常幸运地生活在一个云计算已经在机器学习市场占据了很大一个领域的时代，但这也有一个缺点，即所有的选项往往很难将你的决定缩小到哪一个最适合你的模型和你的个人情况。

另一篇关于这个主题的文章是关于部署的概述，作者是 [neptune.ai](https://neptune.ai) ，如果你想学习更多关于部署 API 的知识，这是一个很好的资源！以下是一个链接:

[](https://neptune.ai/blog/model-deployment-strategies) [## 模型部署策略- neptune.ai

### 近年来，大数据和机器学习已经被大多数主要行业采用，大多数初创公司都在…

海王星. ai](https://neptune.ai/blog/model-deployment-strategies) 

虽然 Amazon Web Services (AWS)对于大多数应用程序来说当然是一个很好的选择，但它也相当昂贵，并且对于许多相当基本的终端来说根本不需要。另一方面，像 Heroku 这样的自动化服务使托管模型变得非常容易，甚至是免费的，但也使端点可用性的范围相对有限。在端点部署领域中，所有这些伟大的选项相互平衡，哪一个是适用于不同情况的最佳选项？

# 选项 1: AWS

毫无疑问，就性价比而言，AWS 几乎完全击败了其他所有服务。这也是为什么很多工作都把 AWS 经验作为就业的要求。对于许多企业应用程序来说，AWS 是一个近乎完美的工具，因为它允许使用跨大规模不同服务器的计算和成本对实例进行分组。

虽然 AWS 对于需要大量计算能力的模型来说是一个很好的解决方案，但肯定可以说需要在性价比的某个点上划一条线。AWS 可能很快变得相当昂贵，如果您计划使用大量计算而回报很少，这可能不是最佳选择。如果你不可能在计算上赚回你的钱，那么它首先就不值得托管。对于一些长期使用强度大，但不一定需要立即供电的应用，可能需要一个更经济的选择。最重要的是，AWS 是出了名的难以使用。根据我的经验，我遇到过在 AWS 仪表板中找不到选项的情况，或者实际上被 AWS 阻止通过 SSH 做某些事情，这确实令人沮丧。

# 选项 2: Linode

如果你像我一样每天都使用 Linux，知道如何使用 NGINX 和 Apache，并且了解如何运行 Unix 命令行，那么 Linode 很可能是你的最佳选择。Linode 的优势不仅在于价格低廉，而且类似于 AWS，具有极强的可扩展性。在服务器上执行特定操作需要更多内存？Linode 允许你选择单独的部件用于你的服务器，这样你的内存问题就解决了。下面是我写的一篇文章，它更深入地介绍了 Linode 的优势:

[](/linode-might-be-the-best-deployment-solution-ad8991282c32) [## Linode 可能是最好的部署解决方案

### 由 Christopher Aker 创建的虚拟私有服务器托管服务 Linode 是最健壮、最具扩展性的…

towardsdatascience.com](/linode-might-be-the-best-deployment-solution-ad8991282c32) 

Linode 的伟大之处在于，它不是为做这件事或那件事而构建的。虽然这意味着 Linode 服务器是难以置信的动态和免费的，但这也意味着它可能比您可能拥有的其他一些选项要复杂一些。使用 Linode 服务器，你需要做“Docker 的事情”,设置网络服务器和类似的事情。如果您不准备这样做，那么 Linode 可能不是您个人的最佳选择，不管它是否适合您要部署的模型。幸运的是，我已经发表了很多关于如何设置 NGINX 服务器并将 Gunicorn3 部署到产品中的文章，比如这篇:

[](/deploying-flask-with-gunicorn-3-9eaacd0f6eea) [## 用 Gunicorn 3 展开烧瓶

### 应用程序部署通常会带来意想不到的后果和错误。部署可以是制定或…

towardsdatascience.com](/deploying-flask-with-gunicorn-3-9eaacd0f6eea) 

Linode 是介于 AWS 这样管理复杂的东西和 Heroku 这样管理极其简单的东西之间的中间地带。虽然它可能无法提供与 AWS 相同的原始性能或完美的连接，但它以简单的固定速率运行，您可以根据需要进行扩展。

# 选项 3: Heroku

您在哪里部署您的模型是一个问题，这个问题的答案不仅取决于您寻求用您的模型完成什么，还取决于您自己的能力。如果您是初学者，刚刚开始管理虚拟环境，Heroku 是一个很好的选择，可以让您在一定程度上熟悉部署过程。Heroku 是一项服务，它将为您的服务建立一个独特的虚拟环境，并自动部署这些服务，从所述环境中加载您的依赖项。

尽管这很方便，Heroku 在向免费用户要钱之前只给他们三次部署。Heroku 应用程序的另一个问题是，默认情况下，它是嵌入 Heroku 系统的，这给了你很小的灵活性来添加任何东西或扩展你的服务。例如，自动训练自己的模型在 Heroku 平台上很难实现。

# 选项№4:自己部署！

如果你有能力，或者只是真的能够应用自己，也许有一台旧电脑躺在周围，绝对没有什么可以阻止你自己托管你的端点！虽然自托管也有缺点，如降低网速和电费，但也有一些非常真实和令人信服的优点，你可能想在完全放弃这个想法之前考虑一下。托管自己的服务器的最大优势是您可以控制相关的硬件。虽然这在某种程度上是不利的，因为这可能意味着相当高的启动成本，但这也意味着您可以根据自己的意愿自由升级所有组件。

拥有对服务器做任何你需要做的事情的自由，本地访问它，甚至无头访问都是一个很大的优势。有时候，安装一个闪存驱动器来传输一个大文件可能比安全地复制它更方便。拥有自己的物理服务器的优势就像手机本身拥有更多存储空间的优势，而不是云存储；没有中间人，你是你的服务器的唯一所有者。如果运行服务器是你可能想要追求的，我在这里写了一篇关于如何做的教程:

[](/how-to-host-your-own-python-models-dc820081c320) [## 如何托管自己的 Python 模型

### 如何设置本地私有服务器并在其上部署端点。

towardsdatascience.com](/how-to-host-your-own-python-models-dc820081c320) 

当然，除了这四个部署选项之外，还有很多其他选项，我认为这是一个通用服务器主机的很好的概述，您可能会发现它们能够全面部署端点。对我个人来说，我喜欢在尽可能少的限制下工作，而且我对 Linux 相当在行。因此，我会更多地考虑 Linode 和自部署选项。您选择的选项将完全取决于您的模型的用途、工作方式、需求以及您作为开发人员的开发操作技能。我还要感谢您阅读这篇文章。如果您碰巧在 9 月 1 日—9 月 2 日阅读这篇文章，我想演示一个自托管 HTTP 服务器，它只在那两天开放，所以我希望您喜欢我的惊喜！

这里有一个链接给那些在桌面上的人:

[http://172.223.154.77:8000/desktop.html](http://172.223.154.77:8000/desktop/desktop.html)

这里有一个移动用户的链接！：

【http://172.223.154.77:8000/mobile/mobile.html 号