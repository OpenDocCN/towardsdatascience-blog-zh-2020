<html>
<head>
<title>How to Handle SMOTE Data in Imbalanced Classification Problems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡分类问题中SMOTE数据的处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-handle-smote-data-in-imbalanced-classification-problems-cf4b86e8c6a1?source=collection_archive---------17-----------------------#2020-05-02">https://towardsdatascience.com/how-to-handle-smote-data-in-imbalanced-classification-problems-cf4b86e8c6a1?source=collection_archive---------17-----------------------#2020-05-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7d64" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">知道陷阱在哪里以及如何避免它们</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3f3eb314d506931dd8f8e952e2ea0b3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PB015kctjbujRIltkA39hQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由盖蒂图片社提供</p></figure><p id="b2b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">分类问题在数据科学领域非常普遍。无论是欺诈检测、情绪分析还是疾病测试，能够预测特定数据点属于哪个组都是非常强大的。</p><p id="4ac5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通常，重点是检测少数群体中的数据点，这可能会出现一些常见问题。通常在这种情况下，您收集的数据是不平衡的，这意味着您感兴趣的目标比其他组的数据量小得多。数据中的这种不平衡会导致你的模型偏向于选择多数群体。在处理不平衡数据集时，有三种常用的技术来平衡数据:</p><ol class=""><li id="03e9" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">欠采样多数类</li><li id="894b" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">对少数民族阶层进行过度采样</li><li id="4251" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">多数类欠采样和少数类过采样的组合</li></ol><p id="7a36" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇博文将介绍一种叫做SMOTE方法的过采样技术。</p><p id="582c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">SMOTE(合成少数过采样技术)是一种用于校正组中不平衡的过采样过程。这种技术通过复制现有的少数民族实例并对其进行小的修改来创建少数民族的新数据实例。这使得SMOTE非常擅长放大已经存在于少数群体中的信号，但不会为这些群体创造新的信号。</p><p id="1cc3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们来看看一些还没有用SMOTE平衡的分类数据。我们将使用sci-kit学习库中的<a class="ae mi" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html" rel="noopener ugc nofollow" target="_blank">乳腺癌数据集</a>。让我们导入必要的包，导入我们的数据，并创建一个可以评估我们的模型的函数。</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="6882" class="mo mp it mk b gy mq mr l ms mt">import pandas as pd<br/>from sklearn import datasets<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.metrics import confusion_matrix<br/></span><span id="b17a" class="mo mp it mk b gy mu mr l ms mt">def evaluate_model(X_train, y_train, model):</span><span id="1ff8" class="mo mp it mk b gy mu mr l ms mt">    model.fit(X_train, y_train)<br/>    preds = model.predict(X_test)<br/>    scores = cross_val_score(model, X_train, y_train, cv=3, scoring="accuracy")<br/>    diff = scores.mean() - model.score(X_test, y_test)<br/>    SD = diff / scores.std()<br/>    <br/>    print(f"Training Score:{model.score(X_train, y_train)}")<br/>    print(f"Cross V Score: {scores.mean()} +/- {scores.std()}")<br/>    print(f"Testing Score: {model.score(X_test, y_test)}")<br/>    print(f"Cross &amp; Test Diff: {diff}")<br/>    print(f"Standard Deviations Away: {SD}")<br/>    print(confusion_matrix(y_test, preds))</span><span id="11e0" class="mo mp it mk b gy mu mr l ms mt">cancer = datasets.load_breast_cancer()<br/>X = cancer.data<br/>y = cancer.target</span></pre><p id="a212" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从这里开始，我们将对我们的数据执行训练测试分割，并初始化我们的基本模型。</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="a156" class="mo mp it mk b gy mq mr l ms mt">from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LogisticRegression</span><span id="5865" class="mo mp it mk b gy mu mr l ms mt">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)</span><span id="7cec" class="mo mp it mk b gy mu mr l ms mt">clf = LogisticRegression(random_state=0, solver='newton-cg', max_iter=1000)</span></pre><p id="6eda" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">提醒:在训练-测试分割函数中设置随机状态非常重要，这样可以确保模型性能的任何变化都是由于您所做的更改，而不是由于随机种子。分层参数根据输入参数分割数据，在本例中是<em class="mv"> y </em>。这意味着每组的训练集和测试集将具有相同的样本百分比。</p><p id="f138" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们看看我们的基本模型表现如何。</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="7a79" class="mo mp it mk b gy mq mr l ms mt">evaluate_model(X_train, y_train, clf)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/bb91df72ca0cdab3384f1317db169b75.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*YsHtdrRNODRc7m1nBe7LWA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基本模型结果</p></figure><p id="8ef2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总的来说，我们看到我们的基本模型在建模数据方面做得不错，但是让我们看看是否可以使用SMOTE来提高性能。</p><p id="e4d3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，当处理合成数据时，第一条规则是:</p><blockquote class="mx"><p id="9390" class="my mz it bd na nb nc nd ne nf ng lt dk translated">不要把合成数据放在你的测试数据里！</p></blockquote><p id="bb0f" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">我们想在实时数据上实现我们的模型，所以我们想看看我们的模型在真实数据上的表现，而不是我们创建的合成数据。这意味着我们只能将合成数据添加到训练集中。我们可以用下面的代码做到这一点:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="1d8f" class="mo mp it mk b gy mq mr l ms mt">from imblearn.over_sampling import SMOTE<br/>smt = SMOTE(random_state=0)<br/>X_train_SMOTE, y_train_SMOTE = smt.fit_sample(X_train, y_train)</span></pre><p id="0a66" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从这里，我们可以使用包含SMOTE的训练数据来训练我们的模型。</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="0114" class="mo mp it mk b gy mq mr l ms mt">evaluate_model(X_train_SMOTE, y_train_SMOTE, clf)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/754370d0601a89f6de850ced643b120b.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*yvE_78v4hkIJj1yGqUd_cA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用SMOTE数据的模型结果</p></figure><p id="9eaa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们所看到的，我们的模型能够更准确地预测包含SMOTE数据的测试数据。然而，引起关注的一个问题是我们的交叉验证分数。交叉验证分数用于评估有限数据集上的模型，以预测模型在真实世界数据中的表现。理想情况下，我们希望交叉验证分数与测试分数相同或接近。在这种情况下，我们的分数出现了分歧，因为我们违反了处理合成数据的第二条规则，即:</p><blockquote class="mx"><p id="173e" class="my mz it bd na nb nc nd ne nf ng lt dk translated">不要把合成数据放在你的验证数据里！</p></blockquote><p id="59e9" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">就像我们的测试数据一样，我们希望只使用真实数据来验证我们的模型。这意味着我们只希望我们的SMOTE数据在训练折叠中，而不是在验证折叠中。在sci-kit learn <a class="ae mi" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html" rel="noopener ugc nofollow" target="_blank">文档</a>中可以找到如何使用StratifiedKFold函数将合成数据添加到每个单独折叠的示例。</p><p id="2b69" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">幸运的是，有一个不平衡学习模块可以为我们处理所有的数据，即管道模块。只需将SMOTE流程和您的模型包含到管道中，模块就会处理剩下的工作。对于此任务，您可以使用Pipeline或make_pipeline函数。</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="99bf" class="mo mp it mk b gy mq mr l ms mt">from imblearn.pipeline import make_pipeline<br/>pipeline = make_pipeline(smt, clf)</span><span id="faff" class="mo mp it mk b gy mu mr l ms mt">evaluate_model(X_train, y_train, pipeline)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/bb5456a7382afe6804e129df3b9389f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*cq-yRkZDZboyqgZoNlzc1A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用imblearn管道模拟性能</p></figure><p id="df4f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们可以看到的，我们的交叉验证分数现在更准确地反映了我们可以从现实世界中的模型中预期的实际性能。希望这篇博客能帮助你在现实世界中实现你的模型。</p></div></div>    
</body>
</html>