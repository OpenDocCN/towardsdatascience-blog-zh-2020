# 线性回归如何有资格成为机器学习算法？

> 原文：<https://towardsdatascience.com/isnt-linear-regression-for-machine-learning-d31543f49181?source=collection_archive---------38----------------------->

## 机器学习，数据科学

## **线性回归**是最**知名的**和**简单的**统计和机器学习工具。

![](img/85cc14869f6f111cb07cb46d368dbff5.png)

来源:自己的工作

在本文中，您可以探索线性回归算法，它是如何操作的，以及如何更好地使用它？

> **线性回归(LR)** 是一种简单而强大的**监督学习技术**。它在很多情况下都有应用。

LR 决定称为**解释变量**的输入变量如何影响称为**响应变量**的输出变量。它使用具有最小数量的**平方残差**的最佳拟合直线，俗称**回归线**或**最小平方线**。

简单线性模型只包含一个自变量，称为**简单线性回归**。而**多元线性回归**有多个解释变量。

LR 处理连续变量的研究。这有利于公司根据经验预测未来的市场趋势和薪酬关系。LR 用于**预测**、**时间序列**、**因果关系**。例如，鲁莽驾驶和道路伤害之间的联系。

LR 可以是正的，也可以是负的。两个变量之间的正关系意味着一个变量的值的增加总是会增加另一个变量的值。

另一方面，两个变量之间的负关系意味着一个变量的值的增加意味着另一个变量的值的减少。

# **线性回归的假设**

![](img/c414891f236f54ef44743d7539bed731.png)

[Artem Sapegin](https://unsplash.com/@sapegin?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

*   因变量 y 和自变量 x 之间的关系总是线性的。x 的系数必须是线性的，不相关的。你不能允许系数是彼此的函数。
*   在非金融应用中，自变量也必须是非随机的。此外，在金融场景中，只要误差变量和自变量不相关，对随机自变量的近似就可以是准确的。
*   **多重共线性**发生在自变量相关联时。其中所有变量的相关系数必须小于 1。**容差**是多重共线性的另一种度量。公差由 T=1-R2 定义，其中 T < 0.1 可以是多重共线，T < 0.01 是多重共线。对于**变量通货膨胀系数** (VIF)，VIF > 10 是变量间的多重共线性。
*   错误这个词通常会被传播。它测试形成直方图或 Q-Q 残差图。**直方图**应该是对称的钟形，并且 **Q-Q 图**的点应该在 45 度轴上。
*   误差定义的方差是常数。这称为**同方差约束**或**恒误差方差**。它使用散点图进行评估。 **Breusch-Pagan 检验**用于检验同质性。对独立变量执行额外的平方残差分析。
*   自相关发生在残基彼此不独立的地方。**德宾-沃森** (DW)检查残基不自相关的零假设。低于 2 的 DW 统计表明附近的残差彼此相关。
*   如果 LR 做出可靠的预测，你的输入输出变量将是**高斯分布**。**多元正态性**在这种正态性下，所有变量都期望是多元的和正则的。使用直方图或 **Q-Q 图**识别。此外，使用 **Kolmogorov-Smirnov** 测试验证体能测试的正常性。当数据通常不用于翻译时，日志转换完成。

# **预测的准确度等级**

![](img/809c961d2f4f7df7e628247223fade5e.png)

[Bermix 工作室](https://unsplash.com/@bermixstudio?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄的照片

*   残差的比例给出了一个清晰的例子，说明回归线如何有效地从 X 值估计 Y 值。这种计算被称为估计的标准误差。这是估计值的标准差。数字越小，预测就越精确。
*   使用公式 **R2** 测试模型的可靠性，该公式是 x 和 y 之间关联的平方。R2 越强，越适合。现在还在 0 和 1 之间。线性排列越强，R 越接近 1。
*   **调整后的 R2** 是一种额外的方法，将 R2 应用于方程中的解释变量的数量。这用于控制额外的解释变量是否是等式的一部分。R2 是这种联系的最强近似。调整后的 R2 可能为负，尽管事实并非如此。在过拟合设置中，实现了导致可预测性降低的高 R2 值。调整后的 R2 并非如此。添加到模型中的每个变量都会增加 R2，而不会减少。而调整后的 R2 仅在新的预测器加强 LR 模型时上升。

# 建立关系模型的替代方法

![](img/367c30f3307379b6ee26593c03529c5f.png)

由[兰迪父亲](https://unsplash.com/@randyfath?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

*   许多可供选择的解释因素是分类的，不能在定量尺度上测试。使用虚拟变量是一个技巧。虚拟变量是潜在值在 0 和 1 之间的变量。性别示例，季度。
*   你可能有两个解释变量的交互变量组合。在回归方程中包含一个交互变量，如果，你假设一个解释变量对 y 的影响依赖于另一个解释变量的值。
*   作为散点图中曲率结果的变量的非线性变换。你应该转换因变量 y 或者解释变量 x，或者你可以全部转换。它包括标准对数、平方根、倒数和平方。

# 为什么要在回归中记录变量？

*   变量有正确的偏斜，取一个对数将使变换后的变量的分布对称。但是这并不是记录变量的足够借口。没有将自变量或因变量控制为正态的回归规则。如果您的因变量或自变量中有异常值，对数变换会减少这种影响。
*   回归残差的方差随着回归预测的增加而增加。取因变量或自变量的对数可能会降低**异方差**。
*   您的回归残差方差随着您的回归预测而增长。取切异方差的因变量或自变量的对数。
*   你的回归残差不正常。这对你来说可能是也可能不是问题。即使残留物不常见。您应该记录因变量或自变量，并验证对数变换后的残差是否有规律。
*   如果因变量和自变量没有线性和指数关系。例如，收入的多少与食物消费相关。收入的成比例增长会使消费增加到一定的数量，之后，食品消费要么持平，要么下降。

# **自变量的相关性**

T 他的潜在想法是**吝啬用最少的东西展示最多的东西。它支持一个解释变量较少的模型。以下技术可用于确定线性回归方程中解释变量的显著性。**

**相关系数**描述了 x 和 y 之间线性关系的强度和方向。假设检验有助于确定总体相关系数值是否接近零，或者是否不同于零。

当测试确定相关系数不为零时，相关系数很重要。如果测试显示相关系数接近于零，我们假设相关系数不显著。

有**两种方法**来检验使用 p 值和 t 统计量的显著性。

*   **回归系数的 T 值**，用于在回归方程中包括或排除解释变量。如果在 95%的置信水平下 **p 值** <为 0.05，且回归方程中使用 t 统计量> 2，则假设该变量很重要。如果 t 统计量小于 1，那么这是一个统计事实，即如果该变量被排除在回归方程之外，标准误差将会减小，调整后的 R2 将会增加。
*   **F 检验**确定已解释的变异相对于未解释的变异是否较高的方法。显著性的 f 检验是对线性关系的假设检验。它有一个允许测试运行的相关 p 值。如果 **ANOVA** 表的 F 值较大，而相应的 p 值较小。拒绝零假设，假设解释变量有一定的价值。

# **结论**

R 广义上的回归分析。然而，它侧重于量化与自变量调整相关的因变量变化。这是因为所有的线性或非线性回归模型都将因变量与自变量联系起来。

*现在，带着你对****Twitter*******Linkedin****，以及****Github****的想法！！**

****同意*** *还是* ***不同意*** *与绍拉夫·辛拉的观点和例子？想告诉我们你的故事吗？**

**他乐于接受建设性的反馈——如果您对此分析有后续想法，请在下面* ***评论*** *或联系我们！！**

**推文*[***@ SauravSingla _ 08***](https://twitter.com/SAURAVSINGLA_08)*，评论*[***Saurav _ Singla***](http://www.linkedin.com/in/saurav-singla-5b412320)*，还有明星*[*SauravSingla*](https://github.com/sauravsingla)*马上！**