<html>
<head>
<title>Reducing the Carbon Foot Prints of CNNs at the cost of interactions-Depthwise &amp; Pointwise Convolution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">以交互作用为代价减少细胞神经网络的碳足迹——深度方向和点方向卷积</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reducing-the-carbon-foot-prints-of-cnns-at-the-cost-of-interactions-depthwise-pointwise-conv-5df850ea33a4?source=collection_archive---------37-----------------------#2020-03-20">https://towardsdatascience.com/reducing-the-carbon-foot-prints-of-cnns-at-the-cost-of-interactions-depthwise-pointwise-conv-5df850ea33a4?source=collection_archive---------37-----------------------#2020-03-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="4695" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">作者:sour adip Chakraborty&amp;Rajesh Shreedhar Bhat</em>T3】</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/3f3481b1940d74727b0c112b8601bbbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0oFSgRkC7uCIYXCHgOWliw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图1:对手写数字进行分类的CNN序列</strong></p></figure><p id="41a0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">卷积神经网络</em> <strong class="js iu"> (CNN的)</strong>在图像分类任务中极其成功，甚至在几个复杂的视觉分类领域中超过了人类的表现。</p><p id="3fb8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">强大的CNN的成功之旅始于<em class="ko"> ImageNet大规模视觉识别挑战2。</em>ImageNet大规模视觉识别挑战赛，或<strong class="js iu"> <em class="ko"> ILSVRC </em> </strong>，是一项年度比赛，使用来自<strong class="js iu"> <em class="ko"> ImageNet </em> </strong>数据集的子集，该数据集由超过20，000个类别的图像组成，这些类别包括“<em class="ko">车辆</em>”、“<em class="ko">果实</em>”、“<em class="ko">动物</em>”等。拥有超过数百张图片。</p><p id="5cde" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko"> ILSVRC </em>挑战导致了深度卷积神经架构的发展(<em class="ko">图1 </em>)，该架构在庞大的Imagenet数据集中产生了最先进的结果。我们非常熟悉的Imagenet模型以及我们使用<strong class="js iu"> <em class="ko">迁移学习</em> </strong>在各种任务中使用的Imagenet模型都是<em class="ko"> ILSVRC挑战赛的直接产物，如AlexNet、VGGNet、ResNet、GoogleNet、</em>等。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi lg"><img src="../Images/c041e5ac4c282168f7edf052ef198856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ExNQku3WBd-3U7sopLmLsQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图2: AlexNet CNN标准架构</strong></p></figure><p id="3ee7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">话虽如此，但不容忽视的事实是，这种高精度是以非常复杂的深层架构和大量参数为代价的。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi lh"><img src="../Images/eb6116f60eda2d2bf3a3127a80dc2f3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0-MhWZSexk-R2LLNqD4bAQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图3: AlexNet CNN图层&amp;参数表</strong></p></figure><p id="8343" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如图2和图3所示，像<strong class="js iu"> <em class="ko"> AlexNet </em> </strong>这样的架构需要数百万个参数来训练，以给出最先进的结果。尽管考虑到我们现在拥有的计算资源，这看起来没什么大不了的，但从环境的角度来看，这是危险的。</p><p id="e00c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，迁移学习的出现大大减少了可训练参数的数量，尽管乘法的数量保持不变。此外，在涉及新域或与训练分布完全不同的域的任务中，我们需要微调整个网络的参数，这是一个大问题。</p><h2 id="e7a8" class="li lj it bd lk ll lm dn ln lo lp dp lq kb lr ls lt kf lu lv lw kj lx ly lz ma bi translated">深度神经模型的能量和策略考虑</h2><p id="ce66" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">由<em class="ko"> Emma Strubell，Ananya Ganesh和Andrew McCallum </em>发表的论文《<strong class="js iu"><em class="ko">@ ACL’2019</em></strong>中关于NLP  中深度学习的能源和政策考虑》受到了很多关注，从那以后，在监测和减少深度神经模型的碳排放方面发生了重大的研究工作。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mh"><img src="../Images/83087ae9d3a367dc67c1057195de1483.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lRlLCh0mET2m69XVHSjiVQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图4:图表:麻省理工技术评论，来源:Strubell等人。铝</strong></p></figure><p id="8ffa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">马萨诸塞大学阿姆赫斯特分校的研究人员观察到，训练深度神经模型排放的碳相当于五辆汽车，这在深度学习社区引起了深切关注。在博客“<em class="ko">单个人工智能的碳排放量是一辆汽车的近5倍”</em>中，作者提到了运行非常深的网络对环境的其他一些担忧和影响。</p><p id="e3bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">话虽如此，尽管神经模型的总碳排放量现在可能不是一个大问题，但随着模型的复杂性和模型参数的数量呈指数增长，它将在未来成为一个大问题。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mi"><img src="../Images/d06cda46c1d1bcb296379e870fdb252f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Zo1i3vuMzr14uOSnS1_xQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图5a: ImageNet CNN模型及参数总数</strong></p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mj"><img src="../Images/c3f769512be9e0f21a930dfca26556d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1nX99s1nx517UJKZkhojEQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图ImageNet模型的准确性&amp;复杂性可视化</strong></p></figure><p id="435b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从图5a和5b可以清楚地看出，在ImageNet CNN模型中有大量的参数，这些参数以百万计，并且需要大量的时间和计算来从零开始训练模型。因此，在下一节课中，我们将讨论如何使用<strong class="js iu">深度方向可分离卷积</strong>来降低CNN模型中卷积运算的计算量，这种卷积已在现代CNN架构中使用，以降低模型的复杂性。</p><h2 id="abba" class="li lj it bd lk ll lm dn ln lo lp dp lq kb lr ls lt kf lu lv lw kj lx ly lz ma bi translated">减少卷积层的计算——深度方向可分离卷积</h2><p id="dfc5" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">在深入研究<em class="ko">深度可分卷积</em>之前，让我们先了解并计算正常卷积运算的计算。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mk"><img src="../Images/83fdb3eee0e74fff4f325a1da90e3f27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qKsatWxVmBZ9kaJ8D-TXBw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图6:普通卷积运算，输入&amp;输出尺寸&amp;滤波器</strong></p></figure><p id="4c45" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设输入特征图的尺寸为<strong class="js iu"> Df *Df *M，</strong>，其中<strong class="js iu"> M </strong>是滤波器的数量/深度，<strong class="js iu"> Df *Df </strong>是特征图的宽度和高度。让我们假设，我们正在用大小为<strong class="js iu"> Dk*Dk*M </strong>的<strong class="js iu"> N </strong>个滤波器进行卷积，因此输出特征图将具有<strong class="js iu"> Dg*Dg*N. </strong>的形状</p><p id="b6f4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，现在我们将通过估计乘法的<em class="ko">次数来估计卷积运算的计算复杂度。</em>由于<em class="ko"> </em>乘法是一种比加法更昂贵的运算，它可以告诉我们模型的复杂性。因此，让我们估计一下这个例子的乘法次数<em class="ko">(图6) </em></p><p id="af8c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一个实例的乘法次数= <strong class="js iu"> Dk * Dk * M = Dk * M . </strong>现在，我们需要在整个输入上滑动滤波器，从输出维度可以清楚地看出，已经执行了沿宽度的<strong class="js iu"> Dg </strong>卷积和沿高度的<strong class="js iu"> Dg </strong>卷积，结果乘法总数为:<strong class="js iu"> Dg * Dk * M. </strong></p><p id="7f0f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为有<strong class="js iu"> N个</strong>这样的滤波器，所以整个输入的乘法总数=<strong class="js iu">Dg * Dk * M * N———(1)</strong></p><p id="c7ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">深度方向可分离卷积-减少计算:</strong></p><p id="da5b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们深入研究<em class="ko">深度可分卷积</em>的架构和计算，以及它如何减少乘法次数。因此，深度方向的可分离卷积可以分成两个部分:</p><ol class=""><li id="87ea" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated"><strong class="js iu">深度方向卷积:滤波阶段</strong></li></ol><p id="4a43" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这种情况下，卷积最初应用于单个输入通道，而不是像正常卷积那样跨越深度。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mu"><img src="../Images/7b4323feb3e3af7acbecefca859adde4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oSC4EpVv05YwyPsFz81rLg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图7:深度方向卷积中的卷积运算</strong></p></figure><p id="9da3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如图7所示，卷积滤波器的尺寸为<strong class="js iu"> Dk*Dk*1，</strong>应用于相同的输入，但是一次仅应用于一个通道，因此需要<strong class="js iu"> M </strong>这样的内核/滤波器，而每个内核的卷积数量沿着输入的宽度保持相同的<strong class="js iu"> Dg </strong>，沿着输入的高度保持相同的<strong class="js iu"> Dg </strong>。</p><p id="a41d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以，一个滤波器的乘法次数=<strong class="js iu">Dk * Dk * Dg * Dg</strong>=<strong class="js iu">Dk * Dg。</strong>由于有<strong class="js iu"> M个</strong>这样的滤波器，所以乘法总数将是<strong class="js iu"> Dk *Dg *M. </strong></p><p id="09c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，与每个核卷积后的输出将具有尺寸<strong class="js iu"> Dg *Dg </strong>，并且有<strong class="js iu"> M个</strong>这样的核，它们将使得最终输出具有形状<strong class="js iu"> Dg*Dg*M. </strong></p><p id="3890" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 2。逐点卷积:组合阶段</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mv"><img src="../Images/86b9797681b1bdfefcb8f00ec47752f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IsZmv2TB3C_WDg5oTWXANQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图8:逐点卷积中的卷积运算</strong></p></figure><p id="17ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">深度方向可分离卷积的下一阶段是通过<em class="ko">逐点卷积</em>的组合阶段。因此，这里的输入是来自前一阶段的输出，其形状为<strong class="js iu"> Dg*Dg*M. </strong>。在这种情况下，每个内核的形状为<strong class="js iu"> 1*1*M </strong>，其应用于整个输入，并保持输入的<em class="ko">高度和宽度</em>，如图8所示。因此，来自这样一个内核的输出将是<strong class="js iu"> Dg*Dg </strong>的形状。应用<strong class="js iu"> N </strong>这样的内核将导致期望形状的输出，即<strong class="js iu"> Dg*Dg*N. </strong></p><p id="2d02" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，输入维上一个内核的乘法次数为。=<strong class="js iu">Dg * Dg * M</strong>=<strong class="js iu">Dg * M .</strong>既然有N个这样的核，那么乘法的总数= <strong class="js iu"> Dg *M*N </strong></p><p id="ea1a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，在深度方向和点方向卷积之后，我们获得了所需的输出，乘法总数为:</p><p id="3817" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">Dk * Dg * M+Dg * M * N = M * Dg(Dk+N)————( 2)</strong></p><p id="0bf7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们比较深度方向可分离卷积和标准卷积中的乘法:</p><p id="9e1a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">标准卷积中的乘法/深度方向可分离卷积中的乘法= rho </strong></p><p id="2c64" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">ρ=(Dg * Dk * M * N)/(M * Dg(Dk+N))</strong></p><p id="255e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">ρ</strong><strong class="js iu">=</strong>(<strong class="js iu">Dk * N)/(Dk+N)—————( 3)</strong></p><p id="d52f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，在正常情况下，让我们取一个非常标准的值<strong class="js iu"> Dk </strong>和<strong class="js iu"> N </strong>来理解乘法运算的减少。对于<strong class="js iu"> N = 1024，Dk = 3，rho = (9*1024)/(1024+9) = 8.9 ~ 9。</strong></p><p id="d8c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，它几乎将计算量减少了9倍，这在参数数以百万计时是非常巨大的，并且这仅仅是一次卷积运算。现在，想象一下，当卷积层数更多时(任何标准ImageNet模型都是如此),效果会有多好。这已经在MobileNets中非常成功地实现了，mobile nets是一类用于移动和嵌入式视觉应用的快速有效的模型。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mw"><img src="../Images/a9b6dbaa57bc0bf16195b11233044dc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7knB7Hdk-zdXp3QEOeVBiQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图9:对MobileNets使用深度方向卷积前后的比较</strong></p></figure><blockquote class="mx my mz"><p id="8c27" class="jq jr ko js b jt ju jv jw jx jy jz ka na kc kd ke nb kg kh ki nc kk kl km kn im bi translated">从图9中可以清楚地看出，模型参数的数量已经显著减少，而精度没有太大下降，这使得该架构如此特别。现在，让我们来理解和讨论通过深度方向可分离卷积以减少计算为代价而导致的信息损失。</p></blockquote></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="b1c1" class="nk lj it bd lk nl nm nn ln no np nq lq nr ns nt lt nu nv nw lw nx ny nz lz oa bi translated">以减少计算为代价的信息损失——深度方向可分卷积</h1><p id="a457" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">基本上，深度方向卷积与标准卷积的主要区别在于，在深度方向，滤波器应用于特征图的高度和宽度，而不是深度。随后使用逐点卷积，进行深度范围内的特征组合。</p><p id="1d16" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">而在标准卷积中，核同时在所有维度上操作，因此它们被联合学习，这有助于它们有效地捕捉所有可能的信息和交互。</p><blockquote class="mx my mz"><p id="7b12" class="jq jr ko js b jt ju jv jw jx jy jz ka na kc kd ke nb kg kh ki nc kk kl km kn im bi translated">因此，我们可以推断，在深度方向可分离卷积中，可能存在某些未被有效捕获的相互作用。(因为卷积运算是对每个维度分别进行的，然后再进行组合，所以在这个过程中可能无法准确地捕捉到跨维度的相互作用。)</p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/2d08c4b1c08c5c3ad2c084a4deda24b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*Q3Xi90qXawp4V2QkUN1wnA.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><strong class="bd lf">图10:联合和边际概率分布</strong></p></figure><p id="0090" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们从二元分布的角度来理解这种情况。假设我们有两个变量<strong class="js iu"> <em class="ko"> x1 &amp; x2 </em> </strong>，pdf为<strong class="js iu"> <em class="ko"> P(x1) &amp; P(x2)。</em> </strong>因此，如果我们必须理解变量的联合行为，我们应该研究变量的联合分布<strong class="js iu"><em class="ko">【P(x1，x2) </em> </strong>从而能够捕捉所有可能的变异来源。但是，如果我们用边边角角即<strong class="js iu"><em class="ko">【P(x1)&amp;【P(x2)</em></strong><strong class="js iu"><em class="ko"/></strong>后来的<strong class="js iu"> <em class="ko"> </em> </strong>结合边边角角的信息来评论联合行为，那就不准确了。</p><p id="b588" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，我们知道，由于设计<em class="ko">深度方向可分离卷积</em>的方式，可能会丢失一些相互作用。但是，正如我们在图9中观察到的，尽管丢失了信息，但准确性并没有显著降低，这表明相互作用可能对解释响应变量(y)没有多大帮助。</p><p id="eb65" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">最终想法:</strong></p><p id="d056" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们希望这篇文章能够让你理解减少计算和减少碳足迹的重要性，同时从环境的角度训练深度模型。</p><p id="de84" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还解释了深度方向可分离卷积如何在模型复杂性和准确性之间有效地折衷。</p><div class="oc od gp gr oe of"><a href="https://www.linkedin.com/in/souradip-chakraborty/" rel="noopener  ugc nofollow" target="_blank"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd iu gy z fp ok fr fs ol fu fw is bi translated">Souradip Chakraborty —数据科学家—沃尔玛印度实验室| LinkedIn</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">我是一名有抱负的统计学家和机器学习科学家。我探索机器学习、深度学习和…</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">www.linkedin.com</p></div></div><div class="oo l"><div class="op l oq or os oo ot kz of"/></div></div></a></div><div class="oc od gp gr oe of"><a href="https://developers.google.com/community/experts/directory/profile/profile-souradip_chakraborty" rel="noopener  ugc nofollow" target="_blank"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd iu gy z fp ok fr fs ol fu fw is bi translated">专家|谷歌开发者</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">机器学习我是Souradip Chakraborty，目前在沃尔玛实验室担任数据科学家(研究)</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">developers.google.com</p></div></div></div></a></div><div class="oc od gp gr oe of"><a href="https://medium.com/@rajesh_bhat" rel="noopener follow" target="_blank"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd iu gy z fp ok fr fs ol fu fw is bi translated">Rajesh Shreedhar Bhat —中等</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">阅读Rajesh Shreedhar Bhat在媒体上的文章。数据科学家—沃尔玛实验室| Kaggle竞赛专家|…</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">medium.com</p></div></div><div class="oo l"><div class="ou l oq or os oo ot kz of"/></div></div></a></div><h1 id="c2d5" class="nk lj it bd lk nl ov nn ln no ow nq lq nr ox nt lt nu oy nw lw nx oz nz lz oa bi translated">参考资料:</h1><ol class=""><li id="fc7e" class="ml mm it js b jt mb jx mc kb pa kf pb kj pc kn mq mr ms mt bi translated">Emma stru bell Ananya Ganesh<strong class="js iu">Andrew McCallum</strong>的论文'<a class="ae mg" href="https://www.aclweb.org/anthology/P19-1355.pdf" rel="noopener ugc nofollow" target="_blank"><em class="ko">NLP</em></a>'中深度学习的能源和政策考虑，ACL'2019。</li><li id="fc0c" class="ml mm it js b jt pd jx pe kb pf kf pg kj ph kn mq mr ms mt bi translated">Zayan Guedim 的博客“<a class="ae mg" href="https://edgy.app/a-single-ai-carbon-emission-is-nearly-5x-greater-than-a-car?pfrom=science&amp;fp=a7" rel="noopener ugc nofollow" target="_blank"> <em class="ko">单个人工智能的碳排放量比一辆汽车</em> </a>”高出近5倍。</li><li id="f67c" class="ml mm it js b jt pd jx pe kb pf kf pg kj ph kn mq mr ms mt bi translated">博客'<a class="ae mg" href="https://www.learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/" rel="noopener ugc nofollow" target="_blank"> <em class="ko">卷积神经网络中的参数数量和张量大小(CNN) </em> ' </a>作者<a class="ae mg" href="https://www.learnopencv.com/author/spmallick/" rel="noopener ugc nofollow" target="_blank">Satya mal lick</a>&amp;<a class="ae mg" href="https://www.learnopencv.com/author/snayak/" rel="noopener ugc nofollow" target="_blank">Sunita Nayak</a>。</li><li id="97a2" class="ml mm it js b jt pd jx pe kb pf kf pg kj ph kn mq mr ms mt bi translated"><a class="ae mg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Howard%2C+A+G" rel="noopener ugc nofollow" target="_blank"> Andrew G. Howard </a>等论文'<a class="ae mg" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"> <em class="ko"> MobileNets:用于移动视觉应用的高效卷积神经网络</em> ' </a></li><li id="7164" class="ml mm it js b jt pd jx pe kb pf kf pg kj ph kn mq mr ms mt bi translated"><a class="ae mg" href="https://www.youtube.com/channel/UC5_6ZD6s8klmMu9TXEB_1IA" rel="noopener ugc nofollow" target="_blank"/>关于<a class="ae mg" href="https://www.youtube.com/watch?v=T7o3xvJLuHk" rel="noopener ugc nofollow" target="_blank"> <em class="ko">深度可分卷积</em> </a> <em class="ko">的精美视频讲座。</em></li><li id="024a" class="ml mm it js b jt pd jx pe kb pf kf pg kj ph kn mq mr ms mt bi translated">博客'<a class="ae mg" rel="noopener" target="_blank" href="/risks-and-caution-on-applying-pca-for-supervised-learning-problems-d7fac7820ec3">对监督学习问题应用PCA的风险和注意事项'</a>。</li></ol></div></div>    
</body>
</html>