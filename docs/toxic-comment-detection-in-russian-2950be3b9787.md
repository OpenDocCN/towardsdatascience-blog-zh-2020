# 俄语中有毒评论的检测

> 原文：<https://towardsdatascience.com/toxic-comment-detection-in-russian-2950be3b9787?source=collection_archive---------22----------------------->

## 表达各种观点的自由，包括有毒、攻击性和辱骂性的评论，可能会对人们的意见和社会凝聚力产生长期的负面影响。

![](img/c2c8b64a46170473fdd96f2564c37b29.png)

因此，自动识别和调节互联网上的有毒内容以消除负面后果的能力是现代社会的必要任务之一。本文旨在自动检测俄语中的有毒评论。作为数据来源，我们利用匿名发布的 Kaggle 数据集，并额外验证其标注质量。为了建立分类模型，我们对两个版本的多语言通用句子编码器、来自 Transformers 的双向编码器表示和 ruBERT 进行了微调。微调后的 ruBERT 达到了 *F* 1 = 92.20%，展示了最好的分类得分。我们向研究社区公开了经过训练的模型和代码样本。

# 1.介绍

如今，社交网站已经成为在线表达意见的主要方式之一。内容的快速增长导致未经核实的信息量每天都在增加。表达各种观点的自由，包括有毒、攻击性和辱骂性的评论，可能会对人们的意见和社会凝聚力产生长期的负面影响。因此，自动识别互联网上的有毒言论和不当内容以消除负面后果的能力是现代社会的必要任务之一。大公司已经进行了大量的研究[23]，[26]，[39]，[47]，然而，为了让社会接受这种限制言论自由权的制度，有必要进行深入的了解和公开的研究。

近年来，组织了越来越多的评估跟踪，如[3]、[21]、[42]，并对最佳检测方法进行了评估。目前，先进的深度学习技术往往是这项任务的优越方法[1]，[35]。虽然一些论文直接检查了俄语有毒语言、辱骂和仇恨言论的检测[2]、[8]、[17]，但只有一个公开可用的俄语有毒评论数据集[5]。该数据集是在 Kaggle 上发布的，没有关于注释过程的任何细节，因此在没有深入检查的情况下在学术和应用项目中使用该数据集可能是不可靠的。

本文主要研究俄语文本中有害评论的自动检测。为此，我们对俄语毒性评论数据集进行了注释验证[5]。接下来，我们通过探索预训练多语言通用语句编码器(M-USE) [48]的预训练多语言版本、来自变压器(M-BERT) [13]和 ruBERT [22]的双向编码器表示的迁移学习来建立分类模型。性能最好的模型 ruBERT-Toxic 在二元分类任务中实现了 *F* 1 = 92.20%。我们在 GitHub 上公开了示例代码和经过微调的 M-BERT 和 M-USE 模型。

[](https://github.com/sismetanin/toxic-comments-detection-in-russian) [## sis metanin/毒性-评论-俄语检测

### 这个库包含来自 Transformers (M-BERT)的经过微调的多语言双向编码器表示…

github.com](https://github.com/sismetanin/toxic-comments-detection-in-russian) 

文章的其余部分组织如下。在**第 2 节**中，我们给出了相关工作的简要概述，包括现有俄语注释数据集的总结。在**第 3 节**中，我们提供了俄语有毒评论数据集的概述，并描述了注释验证流程。在第 4 节中，我们描述了文本分类任务的语言模型的采用。在**第 4 节**中，我们描述了分类实验。最后，我们提出了系统的性能和进一步的研究方向。

# 2.相关著作

针对不同数据源的有害评论检测已经进行了大量的工作。例如，Prabowo 及其同事评估了朴素贝叶斯(NB)、支持向量机(SVM)和随机森林决策树(RFDT)算法，用于检测印度尼西亚 Twitter 上的仇恨言论和辱骂性语言[34]。实验结果表明，使用单词单字特征和 SVM 模型的分级方法的准确率为 68.43%。在论文[15]中，Founta 等人提出了一种基于深度 GRU 的神经网络，该网络具有用于有毒文本分类的预训练手套嵌入。所开发的模型在五个滥用文本数据集上取得了高性能，AUC 值在 92%到 98%之间。

越来越多的研讨会和比赛致力于有毒语言、仇恨言论和攻击性语言的检测。例如，SemEval-2019 的 HatEval 和 OffensEvalHASOC at FIRE-2019；在 GermEval-2019 和 GermEval-2018 上识别攻击性语言的共同任务；TRAC at COLING-2018。任务提交中使用的模型各不相同，从传统的机器学习，如 SVM 和逻辑回归，到深度学习，如 RNN，LSTM，GRU，CNN，CapsNet，包括注意机制[45]，[49]，到最先进的深度学习模型，如 ELMo [31] BERT [13]，以及 USE [9]，[48]。相当数量的表现最好的团队[18]、[24]、[27]、[28]、[30]、[36]、[38]利用了所列的预训练语言模型中的嵌入。由于来自预训练语言模型的表示显示了高分类分数，它们被广泛用于进一步的研究。例如，来自洛林大学的学者使用两种方法对推文进行了多类和二元分类:使用预训练的单词嵌入训练 DNN 分类器，并微调预训练的 BERT 模型[14]。他们观察到，BERT 微调比 CNN 和建立在 FastText 嵌入之上的双向 LSTM 神经网络表现得更好。

虽然大量研究检查了俄语社交媒体源中的毒性和攻击性行为[7]、[33]、[41]，但直接探索文本毒性自动分类的研究论文数量有限。Gordeev 利用卷积神经网络(CNN)和随机森林分类器(RFC)来检测英语和俄语文本中的攻击状态[17]。攻击性注释消息的语料库包括大约 1000 条俄语注释消息和大约 1000 条英语注释消息；然而，它没有公开。经过训练的 CNN 模型在俄语文本的攻击性二元分类中取得了 66.68%的准确率。基于这些结果，作者认为细胞神经网络和深度学习方法在攻击检测任务中似乎更有前景。Andrusyak 及其同事提出了一种无监督的概率方法，使用种子字典对来自 YouTube 的用乌克兰语和俄语编写的辱骂性评论进行分类[2]。作者发布了一个包含 2000 条评论的人工标注数据集，但它包含了俄语和乌克兰语的评论。因此，它不能直接应用于俄语内容的研究。

最近的几项研究旨在自动识别俄语社交媒体中对移民和族裔群体的态度，包括识别基于身份的攻击。Bodrunova 和他的同事通过分析来自俄语 LiveJournal [8]的 363，000 个帖子，研究了人们对来自前苏联南部和其他国家的移民的态度。他们发现，在俄罗斯的博客中，移民既没有引发大量的讨论，也没有经历最糟糕的待遇。此外，北高加索人和中亚人受到非常不同的待遇。贝苏德诺夫的研究小组发现，传统上俄罗斯人对来自高加索和中亚的移民更加敌视；同时，他们普遍接受乌克兰人和摩尔多瓦人作为他们的潜在邻居[6]。然而，根据 Koltsova 及其同事的说法，各种中亚人和乌克兰人带头持否定态度[19]。尽管有些人讨论了旨在检测有毒语言、辱骂和仇恨言论的学术研究，但他们都没有向研究界公开他们的俄语数据集。据我们所知，俄语毒性评论数据集[5]是唯一公开可用的俄语毒性评论数据集。然而，这个数据集是在 Kaggle 上发布的，没有任何关于创建和注释过程的描述，因此在没有深入检查的情况下，在学术和应用项目中使用这个数据集可能是不可靠的。

因此，由于针对俄语毒性检测的研究很少，我们决定在俄语毒性评论数据集上评估深度学习模型[5]。据我们所知，没有研究致力于有毒评论分类的基础上，这种来源的数据。在最近的文本分类论文中，我们将多语言 BERT 和多语言使用确定为最常见和最成功的语言模型之一。此外，只有这些语言模型正式支持俄语。我们决定利用微调作为迁移学习方法，因为最近的微调研究报告了最好的分类结果[13]、[22]、[43]、[48]。

# 3.有毒评论数据集

[Kaggle 俄语有毒评论数据集](https://www.kaggle.com/blackmoon/russian-language-toxic-comments)【5】是由 [2ch](https://2ch.hk/) 和 [Pikabu](https://pikabu.ru/) 的注释评论集合而成，于 2019 年发布在 Kaggle 上。它包含 14，412 条评论，其中 4，826 条被标记为有毒，9，586 条被标记为无毒。评论的平均长度是 175 个字符；最小长度为 21，最大长度为 7，403。

为了验证数据集的标注质量，我们决定手动标注注释的子集，并使用注释者间协议度量来比较原始标签和我们的标签。我们决定假设数据集注释是有效的，以防注释者之间达成实质性或高级别的一致。首先，我们对这个数据集的一部分(3000 条评论)进行人工注释，然后将我们的类标签与原始标签进行比较。这一注释是由众包平台 Yandex 上讲俄语的人进行的。托洛卡，这已经在一些关于俄语文本的学术研究中使用[10]、[29]、[32]、[44]。作为注释指南，我们使用 Jigsaw 毒性评论分类挑战中的毒性和子属性的注释说明。根据指导方针，注释者被要求在一组在线评论中检测文本的毒性。对于提供的每条评论，注释者需要选择评论中的毒性级别。为了从标注者那里获得更准确的响应，并限制作弊标注者对任务的访问，我们利用了以下技术:根据标注者对控制任务的响应为他们分配一项技能，并禁止给出错误响应的执行者；限制响应过快的注释者对池的访问；限制连续几次输入验证码失败的注释者对任务的访问。每篇文章都由 3 到 8 个注释者使用动态重叠技术进行注释。接下来，使用基于[Yandex 的 Dawid-Skene 方法[12]对结果进行汇总。Toloka 的推荐](https://yandex.ru/support/toloka-requester/concepts/categorization.html?lang=en)。根据 Krippendorff 的 alpha 值 0.81，注释者表现出高度的注释者间一致性。最后，根据 Cohen [11]的说法，原始标签和我们的聚合标签之间的 Cohen kappa 系数构成了 0.68，这是注释者间协议的实质水平。因此，我们假设数据集注释是有效的，特别是考虑到注释指令中的潜在差异。

# 4.机器学习模型

## 4.1.基线

作为基线方法，我们选择了一种基于基本机器学习的方法和一种基于现代神经网络的方法。在这两种情况下，我们应用了以下预处理技术:用关键字替换 URL 和用户名，删除标点符号，并将字符串转换为小写。

第一种是多项式朴素贝叶斯(MNB)，它往往在文本分类任务中表现良好[16，40]。为了构建 MNB 模型，我们使用了词袋模型和 TF-IDF 矢量化。

第二个是双向长短期记忆(BiLSTM)神经网络，它在最近的情感分析研究中表现出较高的分类分数。对于神经网络的嵌入层，我们在 RuTweetCorp [37]的俄语推文集合上预先训练了 Word2Vec 嵌入( *dim* = 300) [25]。在 Word2Vec 嵌入的顶部，我们添加了两个堆叠的双向 LSTM 层。接下来，我们添加了一个隐藏的完全连接层和 sigmoid 输出层。为了减少过拟合，具有高斯噪声的正则化层和丢弃层也被添加到神经网络中。我们使用 Adam 优化器，初始学习率为 0.001，分类二进制交叉熵作为损失函数。我们用 10 个时期的冻结嵌入来训练我们的网络。我们试图在降低学习速率的同时解冻不同时期的嵌入，但未能获得更好的结果。这可能与训练数据集的大小有关[4]。

## 4.2.来自变压器的双向编码器表示

目前官方提供了两个多语种版本的 BERT_BASE，但只有 Cased 版本是[官方推荐的](https://github.com/google-research/bert/blob/master/multilingual.md)。BERT_BASE 接受一个不超过 512 个令牌的序列，并输出这个序列的表示。单词标记化由单词标记化器[46]通过初步的文本规范化和标点分裂来执行。基于 BERTBASE 案例，莫斯科物理与技术研究所的研究人员预先训练并发布了俄语的 ruBERT 模型[22]。我们使用了预先训练的多语言 BERT_BASE Cased 和 ruBERT，支持 104 种语言，包括俄语，有 12 个堆叠的变压器块，隐藏大小为 768，12 个自关注头，一般有 110M 参数。微调阶段使用论文[43]和官方知识库[【2】](#_ftn2)中推荐的参数进行:训练周期数为 3，预热步骤数为 10%，最大序列长度为 128，批量为 32，学习速率为 5e-5。

## 4.3.多语言通用句子编码器

作为输入数据，多语言 USE_Trans 取不超过 100 个令牌的序列，而多语言 USE_CNN 取不超过 256 个令牌的序列。句子片断标记化[20]用于所有支持的语言。我们使用预先训练的多语言 USETrans，它支持包括俄语在内的 16 种语言，变压器编码器有 6 个变压器层，8 个注意头，滤波器大小为 2048，隐藏大小为 512，一般有 16 个参数。我们还使用了预先训练的多语言 USE_CNN，它支持包括俄语在内的 N 种语言，CNN 编码器有 2 个 CNN 层，滤波器宽度为(1，2，3，5)，滤波器大小为 256，一般有 N 个参数。对于这两个模型，我们使用了来自和 [TensorFlow Hub 页面](https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub)的推荐参数:100 个训练时段，32 个批量，3e-4 的学习率。

# 5.实验

我们评估了以下基线和迁移学习方法:多项式朴素贝叶斯分类器、双向长短期记忆(BiLSTM)神经网络、来自变压器的双向编码器表示的多语言版本(M-BERT)、ruBERT、多语言通用句子编码器的两个版本(M-USE)。训练模型在测试子集(20%)上的分类性能可以在表 2 中找到。所有微调的语言模型在精确度、召回率和 *F* 1-measure 方面都超过了基线方法。根据结果，ruBERT 实现了 *F* 1 = 92.20%，展示了最好的分类分数。

# 6.结论

因此，我们微调了两个版本的多语言通用句子编码器[48]，来自 Transformers [13]和 RuBERT [22]的多语言双向编码器表示，用于俄语中的有毒评论检测。微调后的 RuBERTToxic 达到了 *F* 1 = 92.20%，展示了最好的分类得分。这项研究对实践和研究的贡献有三个方面。首先，我们概述了现有的关于俄语内容中有毒评论检测的知识库。在这样做的过程中，我们确定了现有的唯一一个公开可用的俄文毒性评论数据集。其次，我们对这个数据集的标注质量进行了验证，因为它是在 Kaggle 上匿名发布的。最后，为了给进一步的研究提供强有力的分类基线，我们向研究社区公开了预先训练的基于 BERT、基于 ruBERT 和基于多语言使用的模型。

[](https://github.com/sismetanin/toxic-comments-detection-in-russian) [## sis metanin/毒性-评论-俄语检测

### 这个库包含来自 Transformers (M-BERT)的经过微调的多语言双向编码器表示…

github.com](https://github.com/sismetanin/toxic-comments-detection-in-russian) 

# 参考

你可以在会议[论文](http://www.dialog-21.ru/media/5017/smetaninsi-029.pdf)中找到所有参考资料。