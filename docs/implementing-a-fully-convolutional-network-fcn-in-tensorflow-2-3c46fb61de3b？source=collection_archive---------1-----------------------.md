# 理解和实施全卷积网络(FCN)

> 原文：<https://towardsdatascience.com/implementing-a-fully-convolutional-network-fcn-in-tensorflow-2-3c46fb61de3b?source=collection_archive---------1----------------------->

## 使用 Keras 在 TensorFlow 中构建、训练和部署小型灵活的 FCN 影像分类模型的教程

![](img/8d3ea6f95a8e46534554db975fb96e23.png)

由[大卫·特拉维斯](https://unsplash.com/@dtravisphd?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

卷积神经网络(CNN)非常适合计算机视觉任务。使用在 ImageNet、COCO 等大型数据集上训练的预训练模型。我们可以快速专门化这些架构，使之适用于我们独特的数据集。这个过程被称为迁移学习。然而，有一个陷阱！用于图像分类和对象检测任务的预训练模型通常在固定的输入图像尺寸上训练。这些通常从`224x224x3`到`512x512x3`左右，并且大多具有 1 的纵横比，即图像的宽度和高度相等。如果它们不相等，那么图像被调整到相等的高度和宽度。

较新的架构确实具有处理可变输入图像大小的能力，但与图像分类任务相比，它更常见于对象检测和分割任务。最近，我遇到了一个有趣的用例，其中我有 5 个不同类别的图像，每个类别都有微小的差异。此外，图像的长宽比也比平时高。图像的平均高度约为 30 像素，宽度约为 300 像素。这是一个有趣的问题，原因如下:

1.  调整图像大小很容易扭曲重要的特征
2.  预先训练的架构非常庞大，并且总是过度适应数据集
3.  这项任务要求低延迟

## 需要具有可变输入维度的 CNN

我尝试了 MobileNet 和 EfficientNet 的基本模型，但都不起作用。需要一种对输入图像大小没有任何限制并能立即执行图像分类任务的网络。首先打动我的是全卷积网络(fcn)。FCN 是一种不包含任何“密集”层(如传统 CNN)的网络，而是包含执行完全连接层(密集层)任务的 1x1 卷积。虽然密集层的缺失使得可变输入成为可能，但有两种技术可以让我们在珍惜可变输入维度的同时使用密集层。本教程描述了其中的一些技术。在本教程中，我们将经历以下步骤:

1.  使用 Keras 在 TensorFlow 中构建全卷积网络(FCN)
2.  下载和分割样本数据集
3.  在 Keras 中创建一个生成器来加载和处理内存中的一批数据
4.  用可变批量维度训练网络
5.  使用 TensorFlow 服务部署模型

**更新**:从头开始建造和训练 FCN 时，你会遇到许多超参数。我写了另一篇文章，其中我给出了超参数优化的一个演练，包括数据扩充，使用了本文中讨论的相同的 FCN 架构。你可以在这里阅读。

[](/hyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda) [## 使用 Keras 和光线调节进行超参数调节

### 使用贝叶斯优化为机器学习模型选择最佳超参数的实用教程。

towardsdatascience.com](/hyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda) 

# 去拿圣经

在我的教程中，这里是上传到 GitHub 的项目链接。请克隆回购，并按照教程一步一步地更好地理解。**注意**:本文中的代码片段只突出了实际脚本的一部分，完整代码请参考 GitHub repo。

[](https://github.com/himanshurawlani/fully_convolutional_network.git) [## himanshurawlani/全卷积网络

### 该库中的代码是在使用 Python 3.6.7 的 Ubuntu 18.04.3 LTS 上开发和测试的。以下是软件包…

github.com](https://github.com/himanshurawlani/fully_convolutional_network.git) 

# 1.设计发动机(model.py)

我们通过堆叠由 2D 卷积层(`Conv2D`)和所需的正则化(`Dropout`和`BatchNormalization`)组成的卷积块来构建我们的 FCN 模型。正则化可以防止过度拟合，并有助于快速收敛。我们还添加了一个激活层来整合非线性。在 Keras 中，输入批次维度是自动添加的，我们不需要在输入层中指定它。由于输入图像的高度和宽度是可变的，我们将输入形状指定为`(None, None, 3)`。3 代表我们图像中的通道数，对于彩色图像(RGB)来说是固定的。

## 最小图像尺寸要求

对输入应用卷积块后，输入的高度和宽度将根据`kernel_size`和`strides`的值减小。如果输入图像尺寸太小，那么我们可能达不到下一个卷积块所需的最小高度和宽度(应该大于或等于内核尺寸)。确定最小输入尺寸的试错法如下:

1.  决定要堆叠的卷积块的数量
2.  选择任意输入形状，比如说`(32, 32, 3)`,将卷积块与越来越多的通道进行堆叠
3.  尝试建立模型并打印`model.summary()`以查看每层的输出形状。
4.  确保从最后一个卷积块中得到`(1, 1, num_of_filters)`作为输出尺寸(这将输入到完全连接的层)。
5.  尝试减少/增加输入形状、内核大小或步幅，以满足步骤 4 中的条件。满足条件的输入形状以及其他配置是网络所需的最小输入维度。

还有一种数学方法来计算输出体积的空间大小，作为输入体积的函数，如这里的[所示](http://cs231n.github.io/convolutional-networks/#conv)。找到最小输入维度后，我们现在需要将最后一个卷积块的输出传递给完全连接的层。但是，任何维度大于最小输入维度的输入都需要汇集起来，以满足步骤 4 中的条件。我们知道如何用我们的主要原料做到这一点。

## 主要成分

完全连接的层(FC 层)将为我们执行分类任务。我们可以通过两种方式构建 FC 层:

1.  致密层
2.  1x1 卷积

如果我们想要使用密集层，那么模型输入尺寸必须是固定的，因为作为密集层输入的参数的数量必须被预定义以创建密集层。具体来说，我们希望最后一个卷积块输出的`(height, width, num_of_filters)`中的高度和宽度为常数或 1。滤波器的数量总是固定的，因为这些值是由我们在每个卷积模块中定义的。

1x1 卷积的输入维度可以是`(1, 1, num_of_filters)`或`(height, width, num_of_filters)`，因为它们沿着`num_of_filters`维度模拟 FC 层的功能。然而，在 1x1 卷积之后，对最后一层(Softmax 激活层)的输入必须是固定长度的(类的数量)。

主要成分:**GlobalMaxPooling2D()**/**GlobalAveragePooling2D()**。Keras 中的这些层将尺寸为`(height, width, num_of_filters)`的输入转换为`(1, 1, num_of_filters)`的输入，实质上是沿`num_of_filters`尺寸的每个过滤器沿高度和宽度尺寸取最大值或平均值。

## 密集层与 1x1 卷积

代码包括密集层(注释掉)和 1x1 卷积。在使用这两种配置构建和训练了模型之后，以下是我的一些观察:

1.  两种模型包含相同数量的可训练参数。
2.  相似的训练和推理时间。
3.  密集层比 1x1 卷积更容易概括。

第三点不能一概而论，因为它取决于数据集中的图像数量、使用的数据扩充、模型初始化等因素。然而，这些是我在实验中观察到的。您可以通过触发命令`$python model.py`来独立运行脚本，以测试模型是否构建成功。

# 2.下载燃料(data.py)

本教程中使用的 flowers 数据集主要是为了理解我们在训练具有可变输入维度的模型时所面临的挑战。一些测试我们的 FCN 模型的有趣数据集可能来自医学成像领域，其中包含对图像分类至关重要的微观特征，以及其他包含几何图案/形状的数据集，这些图案/形状在调整图像大小后可能会扭曲。

提供的脚本(data.py)需要独立运行(`$python data.py`)。它将执行以下任务:

1.  下载包含 5 个类别的花卉数据集(“雏菊”、“蒲公英”、“玫瑰”、“向日葵”、“郁金香”)。关于数据集[的更多细节请点击](https://www.tensorflow.org/datasets/catalog/tf_flowers)。
2.  将数据集拆分为定型集和验证集。您可以设置要复制到训练集和验证集中的图像数量。
3.  给出数据集的统计数据，如图像的最小、平均和最大高度和宽度。

这个脚本下载`.tar`文件，并使用`keras.utils.get_file()`提取当前目录中的内容。如果你想使用 TensorFlow 数据集(TFDS ),你可以查看[这篇](https://medium.com/@himanshurawlani/getting-started-with-tensorflow-2-0-faf5428febae)教程，它展示了 TFDS 和数据扩充的用法。

# 3.专用化油器(generator.py)

我们希望在不同的输入维度上训练我们的模型。给定批次和跨批次的每个图像都有不同的尺寸。那么问题出在哪里？让我们后退一步，重新审视我们如何训练传统的图像分类器。在传统的图像分类器中，图像被**调整**到给定的维度，通过转换成 **numpy 数组或张量**打包成**批**，并且这批数据通过模型向前传播。指标(损失、准确性等。)在该批次中进行评估。基于这些度量来计算要反向传播的梯度。

我们不能调整图像的大小(因为我们会失去微观特征)。现在，由于我们不能调整图像的大小，将它们转换成 numpy 数组就变得不可能了。这是因为如果你有一个包含 10 幅尺寸为`(height, width, 3)`的图像的列表，它们的`height`和`width`的值不同，并且你试图将它传递给`np.array()`，那么得到的数组将是`(10,)`的形状，而不是`(10, height, width, 3)`！然而，我们的模型期望输入维度是后一种形状。解决此问题的方法是编写一个执行以下操作的自定义训练循环:

1.  我们通过使用`np.expand_dims(img, axis=0)`将`(height, width, 3)`转换为`(1, height, width, 3)`来传递列表(批处理)中的每个图像。
2.  在 python 列表(批处理)中累积每个图像的度量。
3.  使用累积的指标计算损耗和梯度。将渐变更新应用于模型。
4.  重置指标值，并创建新的图像列表(批次)。

我尝试了上述步骤，我的建议是不要采用上述策略。这很费力，导致复杂和不可持续的代码，并且运行非常慢！人人都爱优雅而经典的*`model.fit()``model.fit_generator()`。我们将在这里使用后者！但是首先，化油器。*

*化油器是一种将内燃机的空气和燃料以适当的空燃比混合以进行燃烧的装置。这就是我们需要的，空气！我们找到一批图像中最大的高度和宽度，然后每隔一个图像用零填充，这样批中的每个图像都有相等的尺寸。现在我们可以很容易地将其转换为 numpy 数组或张量，并将其传递给`fit_generator()`。该模型自动学习忽略零(基本上是黑色像素),并从填充图像的预期部分学习特征。这样，我们就有了一批具有相同图像尺寸的图像，但每批都有不同的形状(由于不同批次图像的最大高度和宽度不同)。您可以使用`$python generator.py`独立运行`generator.py`文件，并交叉检查输出。*

*在 Keras 中创建生成器非常简单，这里有一个很好的入门教程。对`generator.py`的一个很好的补充是包括对数据扩充的支持，你可以在这里获得一些灵感。*

# *4.点火到认知(train.py)*

*训练脚本导入并实例化以下类:*

1.  *生成器:我们需要指定由`data.py`创建的`train`和`val`目录的路径。*
2.  *FCN 模型:我们需要指定最终输出层所需的类的数量。*

*上述对象被传递给`train()`函数，该函数使用 Adam 优化器和分类交叉熵损失函数编译模型。我们创建一个检查点回调来保存训练期间的最佳模型。基于在每个时期结束时对验证集计算的损失值来确定最佳模型。我们可以看到`fit_generator()`函数在很大程度上简化了代码，令人赏心悦目。*

*我建议在 Google Colab 上进行训练，除非你的本地机器上有 GPU。GitHub repo 包括一个 Colab 笔记本，它将培训所需的所有内容放在一起。您可以在 Colab 本身中修改 python 脚本，并在您选择的数据集上训练不同的模型配置。完成培训后，您可以从 Colab 的“文件”选项卡下载最佳快照到您的本地机器。*

# *5.使用 TensorFlow 服务部署模型(inference.py)*

*下载完模型后，您需要使用`export_savedmodel.py`将其导出为 SavedModel 格式。在主函数中指定下载模型(`.h5`文件)的路径，并使用命令`$python export_savedmodel.py`执行脚本。该脚本使用 TensorFlow 2.0 中的新功能，从`.h5`文件加载 Keras 模型，并将其保存为 TensorFlow SavedModel 格式。SavedModel 将被导出到脚本中指定的`export_path`。TensorFlow 服务 docker 映像需要此 SavedModel。*

*要启动 TensorFlow 服务服务器，请转到导出 SavedModel 的目录(在本例中为`./flower_classifier`)并运行以下命令(注意:您的计算机上必须安装 Docker):*

```
*$ docker run --rm -t -p 8501:8501 -v "$(pwd):/models/flower_classifier" -e MODEL_NAME=flower_classifier --name flower_classifier tensorflow/serving*
```

*上述命令执行以下步骤:*

1.  *如果本地没有`tensorflow/serving` docker 图像，则提取该图像。*
2.  *“-p”标志将本地机器上的端口 8501 映射到 docker 容器中的端口 8501。*
3.  *“-v”标志将当前目录(由`$(pwd)`指定)装载到 docker 容器中的`/models/flower_classifier`中。*
4.  *“-e”标志设置 docker 容器中的环境变量，TensorFlow 服务服务器使用该变量来创建 REST 端点。*
5.  *“-RM”标志在删除容器时删除与容器关联的任何匿名卷。*
6.  *“-t”显示当前终端中的容器日志。您可以按 CTRL+C 返回到您的终端，容器将继续在后台运行。*

*您可以使用`$ docker ps`命令来验证您的容器是否在后台运行。您还可以使用`$ docker logs your_container_id`查看容器日志。`inference.py`脚本包含构建统一图像尺寸批次并将这些批次作为 POST 请求发送到 TensorFlow 服务服务器的代码。从服务器接收的输出在终端中被解码和打印。*

# *梦想的传递*

*在本教程中，我们了解了以下内容:*

1.  *为具有可变输入维数的图像分类建立一个标准的完全卷积网络。*
2.  *用一批中相同的图像形状和不同的批形状训练 FCN 模型。*
3.  *使用 TensorFlow 服务 docker 图像部署训练好的模型。*

*请注意，本教程仅介绍了机器学习工作流程中的单个组件。ML 管道由大量的特定于组织及其用例的训练、推理和监控周期组成。建立这些管道需要更深入地了解司机、乘客和车辆的路线。只有这样才有可能交付梦想的运输工具！*

*我希望这篇教程对你构建下一个令人敬畏的机器学习项目有所帮助。我很乐意听取您对资源库的建议和改进，也可以随时提出 GitHub 的问题。如果你发现文章中有任何错误或遗漏的信息，请在评论区告诉我。谢谢！*