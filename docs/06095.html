<html>
<head>
<title>A One-Stop Guide to Computer Vision — part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉一站式指南—第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-one-stop-guide-to-computer-vision-part-2-f5db1b025588?source=collection_archive---------65-----------------------#2020-05-17">https://towardsdatascience.com/a-one-stop-guide-to-computer-vision-part-2-f5db1b025588?source=collection_archive---------65-----------------------#2020-05-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8be4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">带有 MXNet 和胶子的计算机视觉(逐行解释)</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c1744fd92c1ddc9a7108c15e91aeb5e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wF0jVZLyK2demeqf"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">弗拉德·希利塔努在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="06e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/a-one-stop-guide-to-computer-vision-96f72025f82d">第 1 部分</a>:使用高级 API 创建神经网络。</p><h1 id="0511" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">介绍</h1><p id="a62d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在上一篇文章中，我们学习了如何使用 GluonCV 模型动物园中预先训练好的模型来执行 4 种不同的计算机视觉任务。在本文中，我们将从头开始构建自己的模型。</p><p id="87d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的目的是让你了解计算机视觉模型内部通常会发生什么。我们将创建一个卷积神经网络(CNN)来识别服装。是的，你没听错，我们不再识别手写数字(MNIST)或探测狗了。我们现在识别服装。</p><p id="d6b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是为什么呢？</p><p id="c78f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据<a class="ae kv" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank">扎兰多</a>:</p><blockquote class="mp mq mr"><p id="2c12" class="kw kx ms ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated">事实上，MNIST 经常是研究人员尝试的第一个数据集。他们说，“如果在 MNIST 行不通，那就根本行不通”。“嗯，如果它对 MNIST 有效，对其他人也可能无效。”</p></blockquote><p id="a40d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">再按<a class="ae kv" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank"> Zalando </a>:</p><blockquote class="mp mq mr"><p id="968d" class="kw kx ms ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated">MNIST 太容易了。卷积网在 MNIST 上可以达到 99.7%。经典的机器学习算法也能轻松做到 97%。</p></blockquote><p id="66cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文假设您对机器学习和神经网络有某种形式的基础知识，如训练测试数据、优化器、损失函数、度量、前向传播、后向传播等。如果没有，不要担心。这些概念非常基本，很多信息都可以在网上找到。我将尽力解释构建 CNN 所需的每一行代码。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="8b1b" class="ls lt iq bd lu lv nd lx ly lz ne mb mc jw nf jx me jz ng ka mg kc nh kd mi mj bi translated">导入库</h1><p id="7f6b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">必须导入以下库来构建我们的模型。如果您遵循了本文的第 1 部分,您将不需要安装任何额外的包。否则，一定要看看这篇文章，看看你应该下载哪两个包！(是的，你所需要的是 2 个软件包来创建你自己的神经网络)</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="e903" class="nn lt iq nj b gy no np l nq nr">from mxnet import nd,autograd,gluon,init,metric</span><span id="6dd3" class="nn lt iq nj b gy ns np l nq nr">from mxnet.gluon import nn<br/>from mxnet.gluon.data.vision import datasets, transforms</span><span id="4fac" class="nn lt iq nj b gy ns np l nq nr">import matplotlib.pyplot as plt<br/>from time import time</span></pre><h1 id="4bd9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">下载数据</h1><p id="27fe" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">胶子自带数据库。你可以用一行代码下载<a class="ae kv" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank">时尚 MNIST </a>。</p><p id="325f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为我们稍后将评估我们的模型，所以我们也将通过将参数<code class="fe nt nu nv nj b">train</code>设置为<code class="fe nt nu nv nj b">False</code>来下载验证数据集。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="fc87" class="nn lt iq nj b gy no np l nq nr">train_data = datasets.FashionMNIST(train=True)<br/>valid_data = datasets.FashionMNIST(train=False)</span><span id="ee8c" class="nn lt iq nj b gy ns np l nq nr">X_train,y_train = train_data[0]</span><span id="23fa" class="nn lt iq nj b gy ns np l nq nr">print(X_train.shape, y_train.dtype)<br/>print(len(train_data))</span></pre><p id="2384" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以打印出第一幅图像的形状和数据类型:</p><ul class=""><li id="d1bd" class="nw nx iq ky b kz la lc ld lf ny lj nz ln oa lr ob oc od oe bi translated">形状:(28，28，1)。图像的高度和宽度是 28，并且它是黑白图像，因为深度只有 1。</li><li id="74e1" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated">dtype: int32。图像由 32 位整数表示。</li></ul><p id="b8bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们观察到我们的训练数据中有 60，000 张图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/ce56c09ac0428ba36f64dee85b0d8a38.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*W-reYMNCwio5KNfukq3gPw.png"/></div></figure><h1 id="a635" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">转换数据</h1><p id="fd5a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">数据必须被转换成胶子神经网络能够消化的格式。幸运的是，胶子也为我们提供了轻松实现这一点的功能:</p><ul class=""><li id="3cff" class="nw nx iq ky b kz la lc ld lf ny lj nz ln oa lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">transforms.Compose </code>允许我们将几个转换函数拼接成一个函数。请注意转换的顺序很重要。</li><li id="00b1" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">transforms.ToTensor()</code>将您的图像从 HWC 格式更改为 CHW 格式，并将数据类型从 32 位整数更改为 32 位浮点。</li><li id="8e4d" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">transforns.Normalize()</code>根据提供的两个参数——平均值、标准差，对图像进行归一化处理。</li></ul><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="e91e" class="nn lt iq nj b gy no np l nq nr">transformer = transforms.Compose([<br/>    transforms.ToTensor(),<br/>    transforms.Normalize(0.13,0.31)<br/>])</span><span id="3bca" class="nn lt iq nj b gy ns np l nq nr">train_data = train_data.transform_first(transformer)</span></pre><h1 id="bdb5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">将数据加载到批中</h1><p id="6ed1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">把你的图像一张一张地发送到你的神经网络中是个坏主意。这将花费大量的时间来为你的网络提供信息。因此，我们创建一个数据加载器，将数据加载到 256 个批次中(您可以试验并更改这个批次号)。</p><p id="4ee4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">创建数据加载器需要 4 个参数:</p><ul class=""><li id="7c6c" class="nw nx iq ky b kz la lc ld lf ny lj nz ln oa lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">train_data</code>:您的训练数据(长度 60000)</li><li id="85fa" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated">每一波都会有 256 张图片输入你的神经网络</li><li id="0e62" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated">随机打乱你的数据以减少数据间的虚假关联</li><li id="fca2" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">num_workers</code>:用于训练的核心数。您可以检查可用内核的数量。不同的计算机会返回不同的结果。在我的例子中，我将其设置为 4。</li></ul><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="45d6" class="nn lt iq nj b gy no np l nq nr"># check number of CPUs avaiable<br/>from multiprocessing import cpu_count<br/>print(cpu_count())</span><span id="a219" class="nn lt iq nj b gy ns np l nq nr">batch_size = 256<br/>train_data_batch = gluon.data.DataLoader(train_data,<br/>                                         batch_size = batch_size,<br/>                                         shuffle=True,<br/>                                         num_workers=4)</span><span id="18fc" class="nn lt iq nj b gy ns np l nq nr">valid_data = gluon.data.DataLoader(valid_data.transform_first(transformer),<br/>                                   batch_size=batch_size)</span></pre><h1 id="b057" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">定义您的模型</h1><p id="5cfb" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们将复制一个 LeNet-5 模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/ae7cc23da319e422c4f0b1a605d84fe8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HXUMrMch2PBqJgnl.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">原始图片发表于[ <a class="ae kv" href="http://yann.lecun.com/exdb/lenet/" rel="noopener ugc nofollow" target="_blank"> LeCun 等人</a>，1998]</p></figure><p id="55b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们首先从空白画布开始:<code class="fe nt nu nv nj b">nn.Sequential()</code></p><p id="53fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们根据 LeNet-5 架构在我们的模型中添加一层又一层的隐藏层。</p><ul class=""><li id="9c01" class="nw nx iq ky b kz la lc ld lf ny lj nz ln oa lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">nn.Conv2D</code>:从图像中提取特征的卷积层。</li><li id="9223" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">nn.MaxPool2D</code>:减少待训练参数数量的池层。</li><li id="3c61" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">nn.Flatten</code>:将我们的数据展平到一维，为完全连接的层做准备</li><li id="638c" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">nn.Dense</code>:全连接层</li><li id="ba40" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">network.initialize(init=init.Xavier())</code>:执行“<a class="ae kv" href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" rel="noopener ugc nofollow" target="_blank"> Xavier </a>”权重初始化。Xavier 初始化器有助于保持所有层的梯度比例大致相同</li></ul><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="f59d" class="nn lt iq nj b gy no np l nq nr">network = nn.Sequential()<br/>with network.name_scope():<br/>    network.add(<br/>        nn.Conv2D(channels=6, kernel_size=5, activation='relu'),<br/>        nn.MaxPool2D(pool_size=2, strides=2),<br/>        nn.Conv2D(channels=16, kernel_size=3, activation='relu'),<br/>        nn.MaxPool2D(pool_size=2, strides=2),<br/>        nn.Flatten(),<br/>        nn.Dense(120, activation='relu'),<br/>        nn.Dense(84, activation='relu'),<br/>        nn.Dense(10)<br/>        )</span><span id="7929" class="nn lt iq nj b gy ns np l nq nr">network.initialize(init=init.Xavier())</span></pre><h1 id="ffa2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">损失函数</h1><p id="9c4d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">为了让我们的模型确定它是否表现良好，我们需要一个损失函数。你可以认为损失函数是错误，关于我们离正确的标签/基本事实有多远。</p><p id="865f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在多项式分类问题中，我们通常会使用<a class="ae kv" href="https://gombru.github.io/2018/05/23/cross_entropy_loss/" rel="noopener ugc nofollow" target="_blank">交叉熵损失</a>函数。交叉熵损失函数通常与 softmax 成对使用，以挤压(0，1)之间的值。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="4099" class="nn lt iq nj b gy no np l nq nr">softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()</span></pre><h1 id="679b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">评估指标</h1><p id="810a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">有了损失函数，我们需要一种方法来确定我们的模型有多好。我们通过使用指标来确定这一点。有几个指标，如 F1，召回，精度，准确性等。最常用的衡量标准是准确性。</p><p id="d9ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nt nu nv nj b">train_acc</code>允许我们创建一个对象，并不断向它反馈预测结果和实际结果。它会自动重新计算精度，直到您调用精度。这将在本文的后面部分演示。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="3189" class="nn lt iq nj b gy no np l nq nr">train_acc = metric.Accuracy()</span></pre><h1 id="cb3e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">【计算机】优化程序</h1><p id="4be2" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们需要定义我们的优化器。如果我们不采取任何措施来改进我们的模型，那么了解它的表现是好是坏是没有意义的。因此，我们利用随机梯度下降来告诉我们的模型在给定当前误差/精度的情况下下一步做什么。</p><ul class=""><li id="d86e" class="nw nx iq ky b kz la lc ld lf ny lj nz ln oa lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">network.collect_params() </code>:我们能够检索我们模型的当前权重。我们的教练需要当前的体重，以便更新。</li><li id="6f8f" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">'sgd'</code>:我们选择随机梯度下降优化器。访问<a class="ae kv" href="https://mxnet.apache.org/api/python/docs/api/optimizer/index.html#mxnet.optimizer.Optimizer" rel="noopener ugc nofollow" target="_blank">原始文档</a>了解可用的优化器类型。</li><li id="1624" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><code class="fe nt nu nv nj b">learning_rate</code>:学习率越低，我们就越能达到最小/最大值。然而，这也导致了更长的模型训练时间。</li></ul><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="dfc9" class="nn lt iq nj b gy no np l nq nr">trainer = gluon.Trainer(network.collect_params(),<br/>                       'sgd', {'learning_rate':0.1})</span></pre><h1 id="0bc4" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">训练循环</h1><p id="b7c4" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这一部分将我们到目前为止为训练模型所做的一切放在一起。我将逐步解释下面的代码:</p><ol class=""><li id="8342" class="nw nx iq ky b kz la lc ld lf ny lj nz ln oa lr om oc od oe bi translated"><code class="fe nt nu nv nj b">for epoch in range(10): </code>我们将对我们的模型进行总共 10 个纪元/时间的训练。</li><li id="20ad" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated">对于每次迭代，我们将损失实例化为 0。</li><li id="c302" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated"><code class="fe nt nu nv nj b">tic = time()</code>我们记录当前时间，这样我们就可以跟踪我们的模型训练需要多长时间。</li><li id="f214" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated">我们现在循环处理批量数据</li><li id="945e" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated"><code class="fe nt nu nv nj b">with autogra.record():</code>我们记录模型中发生的事情</li><li id="5755" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated"><code class="fe nt nu nv nj b">output=network(data)</code>通过将<code class="fe nt nu nv nj b">data</code>传递给我们的<code class="fe nt nu nv nj b">network</code>，也就是我们的模型，我们得到了一个预测<code class="fe nt nu nv nj b">output</code></li><li id="e782" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated"><code class="fe nt nu nv nj b">loss=softmax_cross_entropy(output,label)</code>利用之前定义的损失函数，我们可以通过传入预测输出和实际输出来计算我们的损失</li><li id="fd72" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated">损失通过 CNN 反向传播</li><li id="3205" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated"><code class="fe nt nu nv nj b">trainer.step(batch_siz)</code>在反向传播损失后，我们向前迈出一步来更新我们的权重</li><li id="a275" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated"><code class="fe nt nu nv nj b">train_loss += loss.mean().asscalar()</code>用该批数据发生的损失更新培训损失</li><li id="f507" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated"><code class="fe nt nu nv nj b">train_acc.update(label,output)</code>训练精度随着这批数据的损失而更新</li><li id="e0f5" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated">打印报表打印每个时期的损耗、精度和性能。我们通常会将它打印出来，这样我们就可以观察并确保模型正在进展。</li><li id="3b94" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated"><code class="fe nt nu nv nj b">network.save_parameters("trained_net.params")</code>这一步是可选的。将模型训练成文件后，它会保存更新的权重。砝码可以随时加载到另一个环境中。</li></ol><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="7d1c" class="nn lt iq nj b gy no np l nq nr">for epoch in range(10):<br/>    train_loss = 0<br/>    tic = time()<br/>    for data, label in train_data_batch:<br/>        with autograd.record():<br/>            output=network(data)<br/>            loss=softmax_cross_entropy(output,label)<br/>        loss.backward()<br/>        <br/>        trainer.step(batch_size)<br/>        <br/>        train_loss += loss.mean().asscalar()<br/>        train_acc.update(label,output)<br/>        <br/>    print("Epoch[%d] Loss: %.3f Acc: .%3f Perf: %.1f img/sec"%(<br/>        epoch,train_loss/len(train_data_batch),<br/>        train_acc.get()[1],<br/>        len(train_data)/(time()-tic)<br/>    ))<br/>network.save_parameters("trained_net.params")</span></pre><p id="a1c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的代码需要相当长的时间来运行，这取决于你的计算机的能力。你可以观察到随着迭代次数的增加，损耗如何减少，精度如何增加。这说明我们的模型学习的很好。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/8cddbd554d99ca3bdc3870ea7649fc0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*g5zL58Z9gwJt-Vil5917cQ.png"/></div></figure><h1 id="a7cb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">模型评估</h1><p id="2f38" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">最后，我们对我们的模型进行最终评估，以了解它在看不见的数据上的表现。切记创建新的精度指标，不要重复使用<code class="fe nt nu nv nj b">train_acc</code>以防止信息泄露。</p><p id="9681" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">解释:</p><ol class=""><li id="144e" class="nw nx iq ky b kz la lc ld lf ny lj nz ln oa lr om oc od oe bi translated"><code class="fe nt nu nv nj b">network.load_parameters("trained_net.params")</code>加载我们之前训练的模型权重。</li><li id="bb33" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated">就像我们如何传递一批批训练数据来训练我们的模型一样，我们现在传递一批批验证数据来评估我们的模型，同时更新<code class="fe nt nu nv nj b">valid_acc</code></li><li id="d2df" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr om oc od oe bi translated">为了获得最终精度，使用<code class="fe nt nu nv nj b">valid_acc.get()[1]</code>将其打印出来。我设法获得了 0.9025 的验证精度。你应该得到一个不同的号码。这意味着我们的模型在 90%的时间里预测正确的输出！</li></ol><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="bccc" class="nn lt iq nj b gy no np l nq nr">network.load_parameters("trained_net.params")</span><span id="dd9f" class="nn lt iq nj b gy ns np l nq nr">valid_acc = metric.Accuracy()</span><span id="5727" class="nn lt iq nj b gy ns np l nq nr">for data,label in valid_data:<br/>    output = network(data)<br/>    valid_acc.update(label,output)</span><span id="fe16" class="nn lt iq nj b gy ns np l nq nr">print(valid_acc.get()[1])</span></pre><h1 id="917b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="8261" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">祝贺你完成这篇文章！现在，您应该能够从头开始创建和设计自己的神经网络。还有许多其他深度学习库，如<a class="ae kv" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>、<a class="ae kv" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>、<a class="ae kv" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>和<a class="ae kv" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>也可以实现相同的结果。去做你熟悉的事情。不同的包应该仍然为您提供相似的结果。</p><p id="58a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我鼓励你去看看现有的不同模型和架构，用你能在网上找到的不同数据进行实验。</p></div></div>    
</body>
</html>