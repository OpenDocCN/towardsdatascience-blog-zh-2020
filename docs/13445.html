<html>
<head>
<title>How to implement augmentations for Multispectral Satellite Images Segmentation using Fastai-v2 and Albumentations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Fastai-v2 和 Albumentations 实现多光谱卫星图像分割的增强</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-implement-augmentations-for-multispectral-satellite-images-segmentation-using-fastai-v2-and-ea3965736d1?source=collection_archive---------23-----------------------#2020-09-15">https://towardsdatascience.com/how-to-implement-augmentations-for-multispectral-satellite-images-segmentation-using-fastai-v2-and-ea3965736d1?source=collection_archive---------23-----------------------#2020-09-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a5f7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过多光谱图像增强和 Fastai v2 提高深度学习算法的性能</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ced6072cab72cbfbac21a20bbf7dbcf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l9FVBX9Z7DlpvsXe2xet8A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:应用于 Landsat 8 补丁及其相应的云掩膜的增强。图片作者。</p></figure><h2 id="5cfe" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">更新</h2><p id="4bdc" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">关于课程<strong class="lw iu">科学家 Python 入门</strong> ( <a class="ae mn" href="https://youtu.be/oQaoj6LE5E4" rel="noopener ugc nofollow" target="_blank">可在 YouTube </a> ) <strong class="lw iu"> </strong>和其他类似文章的信息，请访问我的网站<a class="ae mn" href="http://cordmaur.carrd.co/" rel="noopener ugc nofollow" target="_blank">cordmaur.carrd.co</a>。</p><h1 id="ab7d" class="mo kz it bd la mp mq mr ld ms mt mu lg jz mv ka lk kc mw kd lo kf mx kg ls my bi translated">介绍</h1><p id="0512" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">我们知道图像增强是计算机视觉任务的一个关键因素。它有助于算法避免过度拟合，也限制了对庞大训练数据集的需求[1]。大多数深度学习框架都有一个实现增强“开箱即用”的视觉模块，如 Keras、PyTorch 和 Fastai 库的情况。当我们需要向模型提供与 3 通道标准(RGB)不匹配的图像时，问题就出现了。这是大多数遥感应用的情况(例如图 1)和许多其他区域。</p><p id="72dd" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">为了克服这一限制，我将展示如何使用白蛋白库[2]实现多光谱增强，并将其插入 Fastai v2 数据块以供进一步培训。关于如何为卫星图像创建数据块的原则可以在我之前的故事<a class="ae mn" rel="noopener" target="_blank" href="/how-to-create-a-datablock-for-multispectral-satellite-image-segmentation-with-the-fastai-v2-bc5e82f4eb5">“如何使用 Fastai-v2 为多光谱卫星图像分割创建数据块”</a>中找到。</p><h2 id="3a15" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">1-数据集</h2><p id="9719" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">我们将使用的数据是 Kaggle 提供的公共数据集，名为<a class="ae mn" href="https://www.kaggle.com/sorour/95cloud-cloud-segmentation-on-satellite-images" rel="noopener ugc nofollow" target="_blank"><em class="ne">“95 云:卫星图像上的云分割”</em> </a> <em class="ne">，</em>，包含从 57 个 Landsat 8 场景中提取的训练补丁。事实上，这个数据集是以前的 Kaggle 数据集的扩展，该数据集用于训练一个非常简单的 Fastai v1 模型(<a class="ae mn" href="https://medium.com/analytics-vidhya/a-simple-cloud-detection-walk-through-using-convolutional-neural-network-cnn-and-u-net-and-bc745dda4b04" rel="noopener">此处为</a>)。这些贴片的尺寸为 384x384，包含 4 个波段——红、绿、蓝和近红外。此外，还有一个标记云的地面真相补丁。由于我们的目标只是展示如何实现增强，没有进一步考虑准确性，我们将只使用最新版本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/dc1c7c64157964629bbe09e54b6d1fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uFRZVxCuWrN1b4Vj1V9X0w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2— Kaggle 数据集。图片来自 ka ggle(<a class="ae mn" href="https://www.kaggle.com/sorour/95cloud-cloud-segmentation-on-satellite-images" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/sorour/95 cloud-cloud-segmentation-on-satellite-images</a>)</p></figure><p id="ec51" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">为了方便起见，这里显示的所有代码都可以在 Kaggle 笔记本中使用(<a class="ae mn" href="https://www.kaggle.com/cordmaur/remotesensing-fastai2-multiband-augmentations" rel="noopener ugc nofollow" target="_blank">这里是</a>)，所以我们将从安装必要的依赖项开始:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="d3a1" class="ky kz it nh b gy nl nm l nn no"># update torch and torch vision<br/>!pip install -q torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f <a class="ae mn" href="https://download.pytorch.org/whl/torch_stable.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/torch_stable.html</a></span><span id="9343" class="ky kz it nh b gy np nm l nn no"># install kornia, we will give it a try to accelarate our preprocessing<br/>!pip install -q --upgrade kornia<br/>!pip install -q allennlp==1.1.0.rc4</span><span id="e393" class="ky kz it nh b gy np nm l nn no"># and install fastai2<br/>!pip install -q --upgrade fastai</span></pre><h2 id="9a36" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">2-打开图像</h2><p id="8053" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">除了视觉库不支持多通道图像的问题，该数据集将每个波段保存在单独的文件夹中。因此，为了打开一个图像，我们首先需要纠正每个波段的路径，然后将它们整理成一个单一的 4 通道图像。不像我们在之前的<a class="ae mn" rel="noopener" target="_blank" href="/how-to-create-a-datablock-for-multispectral-satellite-image-segmentation-with-the-fastai-v2-bc5e82f4eb5">故事</a>中那样子类化 TensorImage 类，我将尝试使事情变得更简单，并将图像作为张量打开。这种方法的缺点是我们不能像<code class="fe nq nr ns nh b">DataLoader.showbatch()</code>一样使用 Fastai 的内部可视化功能，因为它不知道如何显示 4 个波段。</p><p id="f6f6" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">第一步是创建三个基本函数:</p><ol class=""><li id="352c" class="nt nu it lw b lx mz ma na lh nv ll nw lp nx mm ny nz oa ob bi translated">打开一个 TIF 文件，并将其作为 PyTorch 张量返回；</li><li id="3cb1" class="nt nu it lw b lx oc ma od lh oe ll of lp og mm ny nz oa ob bi translated">给定一个文件名(假设是红色波段)，返回其他三个波段(绿色、蓝色和 Nir)的名称；</li><li id="377f" class="nt nu it lw b lx oc ma od lh oe ll of lp og mm ny nz oa ob bi translated">一次打开 4 个波段，将它们整理成一个图像。为此，我们将使用第一维(或轴)连接图像</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="fad7" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">一旦我们的函数被定义，我们将通过传递一个项目到管道来测试它们。管道是应用于一个项目的一系列功能，以我们想要的方式转换它。</p><p id="b944" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">为了加载项目，我们将考虑我们的基础图像在红色文件夹中，然后我们将自动获取其他波段。因此，我们的管道将由两个功能组成:1- <code class="fe nq nr ns nh b">get_filenames </code>和 2- <code class="fe nq nr ns nh b">open_ms_tif</code>。我们的最终图像将有形状<code class="fe nq nr ns nh b">(4, 384, 384)</code>。用 matplotlib 显示它会在维度上做最后的排列，把通道放在最后一个轴上成为<code class="fe nq nr ns nh b">(384, 384, 4)</code>，并且用<code class="fe nq nr ns nh b">[…, :3]</code>切掉 Nir 波段。</p><p id="0671" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">考虑到我们的最终目标是分割图像中的云，我们必须将相同的增强应用于地面真相。因此，将进行类似的程序来打开面罩。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4421" class="ky kz it nh b gy nl nm l nn no">torch.Size([4, 384, 384]) torch.Size([384, 384])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/d9f4ae011378aa87f52aca6d61fc5b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u4wJzCd4PiMc58hs7DnBwQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3:显示补丁和相应云遮罩的代码输出。图片作者。</p></figure><p id="433b" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">如我们所见，我们的管道运行良好。我使用 TensorMask 的<code class="fe nq nr ns nh b">.show() </code>方法和 context <code class="fe nq nr ns nh b">ctx</code>参数，只是为了说明在 Fastai 中可以将输出强制到任何上下文。另一个有趣的命令是 partial，它返回对预先填充了一组给定参数的函数的引用。</p><h2 id="4575" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">3-创建数据集和数据加载器</h2><p id="39aa" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">在进行扩充之前，我们将首先创建一个数据集和一个数据加载器，只是为了检查是否一切都按预期工作。注意，我们不需要在数据块中指定 get_items 函数，因为我们的源已经是一个条目列表。我们还将定义一个函数<code class="fe nq nr ns nh b">show_img()</code>来显示多通道张量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="9b0c" class="ky kz it nh b gy nl nm l nn no">torch.Size([4, 4, 384, 384]) torch.Size([4, 384, 384])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/078a142f2e648a7d54eb698ca2f9c096.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sbq4DXrrQr0RSB7w5A-13Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 4:显示一个批处理样本的代码输出。(上)RGB 图像|(下)云遮罩。图片作者。</p></figure><h2 id="1a1a" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">4-扩充</h2><p id="7483" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">为了扩充，我们将使用白蛋白库。有一个巨大的可能的增强列表，分为不同的类，如像素级和空间级变换。对于本教程，我们将保持简单，只使用基本的移动，翻转，缩放，旋转，亮度和对比度。完整的列表可以通过他们的在线文档获得(<a class="ae mn" href="https://albumentations.ai/docs/getting_started/transforms_and_targets/" rel="noopener ugc nofollow" target="_blank">此处</a>)。</p><p id="f14f" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">白蛋白库的一个重要方面是它支持分割和对象检测的增强。这意味着它可以将应用于图像的相应增强应用于其目标(遮罩或边界框)。这是至关重要的一点，因为我们需要保持我们的云遮罩与增强图像相匹配。</p><p id="7d88" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">Fastai 将对一个元组(X，Y)应用增强，其中 X 是图像，Y 是遮罩。为了让它在框架内工作，有必要子类化 ItemTransform 类并创建<code class="fe nq nr ns nh b">encodes()</code>方法。为了使它通用，我们的子类将在实例创建时接收期望的转换，如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ca"><img src="../Images/0e8073ce43e996a7064a808d301cfc36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jy6wIAptW94OE5WioDqJSA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 5:代码输出显示:(左)原始项目(图像和遮罩)|(右)图像和遮罩的增强版本。图片作者。</p></figure><p id="05c7" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">注意，在这个类中定义了一个<code class="fe nq nr ns nh b">split_idx=0</code>。这就是告诉 Fastai 只增加训练数据集，而不是验证数据集。现在我们已经建立了我们的转换类，让我们在数据块中使用它。我们将重新创建数据块，现在将<code class="fe nq nr ns nh b">item_tfms</code>参数设置为<code class="fe nq nr ns nh b">aug</code>。然后，我们将要求数据加载器多次创建一个项目，以查看它是如何进行的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/9fc51c7cc6ad65647ca27bdb91a58c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KdO7Z0V8LMbmdmdnDHI_wg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 6:代码输出演示了在通过数据加载器时应用于同一个补丁的增强。图片作者。</p></figure><h2 id="199f" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">结论</h2><p id="6731" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">正如我们在这个故事中看到的，实现多光谱卫星图像的数据增强只是找到正确工具的问题。在这方面，白蛋白是一个很好的伴侣，因为它可以处理许多渠道，并增加目标。</p><p id="6d8a" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">如前所述，包含所有代码的笔记本可以在 Kaggle ( <a class="ae mn" href="https://www.kaggle.com/cordmaur/remotesensing-fastai2-multiband-augmentations" rel="noopener ugc nofollow" target="_blank">此处</a>)找到。在那里，还可能找到有和没有增强的学习准确度的比较。</p><p id="10de" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">希望你喜欢。</p><h2 id="f9ea" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">参考</h2><p id="fcd9" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">[1] Shorten，c .，Khoshgoftaar，T.M .，2019 年。面向深度学习的图像数据增强综述。j 大数据 6、60。https://doi.org/10.1186/s40537-019-0197-0<a class="ae mn" href="https://doi.org/10.1186/s40537-019-0197-0" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="7882" class="pw-post-body-paragraph lu lv it lw b lx mz ju lz ma na jx mc lh nb me mf ll nc mh mi lp nd mk ml mm im bi translated">[2] Buslaev，a .，Iglovikov，V.I .，Khvedchenya，e .，Parinov，a .，Druzhinin，m .，Kalinin，A.A .，2020。快速灵活的图像增强。信息 11125。【https://doi.org/10.3390/info11020125 T4】</p></div></div>    
</body>
</html>