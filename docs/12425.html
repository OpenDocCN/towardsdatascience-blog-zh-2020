<html>
<head>
<title>Under the Hood — Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">引擎盖下——线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-under-the-hood-583003d0bf38?source=collection_archive---------45-----------------------#2020-08-26">https://towardsdatascience.com/linear-regression-under-the-hood-583003d0bf38?source=collection_archive---------45-----------------------#2020-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/d551652f4d3b4c3d22dd5e8e549cfcbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aJI5OjMXoR6fcMLMZtgB2w.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">照片由<a class="ae kf" href="https://www.pexels.com/@maltelu?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kg">马尔特卢克</strong>T3】发自</a><a class="ae kf" href="https://www.pexels.com/photo/man-fixing-vehicle-engine-2244746/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">T5】像素 T7】</a></p></figure><p id="a1ea" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这是一系列文章中的第一篇，在这一系列文章中，我们将使用各种 ML 算法的基本数学方程来理解它们的“幕后”工作。</p><ol class=""><li id="8bc1" class="lf lg it kj b kk kl ko kp ks lh kw li la lj le lk ll lm ln bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/linear-regression-under-the-hood-583003d0bf38">引擎盖下—线性回归</a></li><li id="1eba" class="lf lg it kj b kk lo ko lp ks lq kw lr la ls le lk ll lm ln bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/under-the-hood-logistic-regression-407c0276c0b4">引擎盖下——逻辑回归</a></li><li id="e7a8" class="lf lg it kj b kk lo ko lp ks lq kw lr la ls le lk ll lm ln bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/under-the-hood-decision-tree-454f8581684e">引擎盖下—决策树</a></li></ol><p id="777f" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">有这么多优化的实现，我们有时太关注库和它提供的抽象，而太少关注进入模型的底层计算。理解这些计算往往是一个好模型和一个伟大模型的区别。</p><p id="7a73" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在本系列中，我将重点放在手工实现算法上，以理解其背后的数学原理，这将有望帮助我们训练和部署更好的模型。</p><p id="c5a4" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">注意——本系列假设您了解机器学习的基础知识以及我们为什么需要它。如果没有，请阅读这篇文章，以了解我们为什么以及如何利用 ML。</p><h1 id="a41e" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">线性回归</strong></h1><p id="ffa7" class="pw-post-body-paragraph kh ki it kj b kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la mv lc ld le im bi translated">线性回归是机器学习的支柱，它基于简单的曲线拟合概念</p><blockquote class="mw"><p id="83e3" class="mx my it bd mz na nb nc nd ne nf le dk translated"><strong class="ak">曲线拟合</strong>是构建一条曲线或数学函数的过程，该曲线或数学函数与一系列数据点最佳拟合，可能受到约束。</p></blockquote><p id="948d" class="pw-post-body-paragraph kh ki it kj b kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la nk lc ld le im bi translated">本质上，“模型”产生了一个将输入特征(X)与目标变量(Y)联系起来的线性方程。</p><p id="026a" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">考虑以下具有两个输入变量— <strong class="kj iu"> <em class="nl"> X1、X2 </em> </strong>和一个目标变量<strong class="kj iu"> <em class="nl"> Y </em> </strong>的数据。</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/9df411ec4a985999690a8821a63b368f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*avxoIRn79Uo4YOb70xu2gg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">包含 5 行的示例数据</p></figure><p id="0a59" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">线性回归将试图找到<em class="nl"> w1、w2 </em>和<em class="nl"> b </em>的最佳值，这样对于每一行数据—</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/013bf9264ef926d84b0e245141827dcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eAeRgvw6_5je_fcj-Gp8Ig.png"/></div></div></figure><p id="9af3" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这里，<em class="nl"> w1 </em>和<em class="nl"> w2 </em>是输入变量的系数，而<em class="nl"> b </em>是偏置项。这被称为数据的“最佳拟合线”，算法使用以下步骤反复尝试找到最佳拟合线—</p><ol class=""><li id="5eac" class="lf lg it kj b kk kl ko kp ks lh kw li la lj le lk ll lm ln bi translated">给参数<em class="nl"> w1 </em>、<em class="nl"> w2 </em>和<em class="nl"> b </em>分配随机值。</li><li id="88f3" class="lf lg it kj b kk lo ko lp ks lq kw lr la ls le lk ll lm ln bi translated">在数据中选取一个实例并计算</li></ol><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/aa0ed55d2526990f06c90991185be01a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kF7yZ76zP1LwWKLRKc9uNw.png"/></div></div></figure><p id="05dd" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">3.计算损失——我们的产量与实际产量相差多少？</p><p id="e8ec" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">4.计算<em class="nl"> w1 </em>、<em class="nl"> w2 </em>和<em class="nl"> b </em>的梯度—我们应该如何改变权重以更接近实际输出？</p><p id="d282" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">5.更新<em class="nl"> w1 </em>、<em class="nl"> w2 </em>和<em class="nl"> b </em>。</p><p id="b204" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">6.重复步骤 2–5，直到收敛。</p><p id="b8d1" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">以下一组图像传达了单个变量的步骤—</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/2530d18757b935b29adf43aac68d37be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wwEtahy5NeWhqdWVcCNOiA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">0.从一组 n 个变量开始</p></figure><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/24ea44f041f7838e5f8f9424e612be2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zWXKKV4dk7ASqccayTS-Bw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">1.给参数分配随机值并绘制假设曲线</p></figure><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/e7819e291562d024dbf7da0b2e6398ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jtrHZBJfVJu5QpMuUJSjbg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">2.使用一个数据实例计算ŷ</p></figure><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/af1d090b208a5847aab5da23ac5dd802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5CqXeN437wcEurtCGWzCFA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">3.计算损失</p></figure><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/d6dc5ebf281ead7ed073608cde8b8548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JEyC82JQbppuP_n00SwaYg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">4 &amp; 5.计算损失并更新参数</p></figure><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/511627a691e0f49e5569973c07b3eda0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QNFHDxns3BIytAuBPqEM2w.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">6.对另一个数据实例重复步骤 2–5</p></figure><h2 id="a741" class="nv lu it bd lv nw nx dn lz ny nz dp md ks oa ob mh kw oc od ml la oe of mp og bi translated"><strong class="ak"> 1。将随机值分配给<em class="oh"> w1 </em>，w2 和 b </strong></h2><p id="eacd" class="pw-post-body-paragraph kh ki it kj b kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la mv lc ld le im bi translated">让我们从我们的假设开始——</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oi"><img src="../Images/cc64620631c217525ccfe7c99cbfa0e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X4n804VJO_t_LvtOvXHMnw.png"/></div></div></figure><h2 id="c4bd" class="nv lu it bd lv nw nx dn lz ny nz dp md ks oa ob mh kw oc od ml la oe of mp og bi translated">2.从数据中选择一个实例并计算ŷ</h2><p id="6c5d" class="pw-post-body-paragraph kh ki it kj b kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la mv lc ld le im bi translated">让我们从数据的第一行开始</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oj"><img src="../Images/cbac04d74eb0d54e1c318374167a0f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9j_-3XHYpPtCUUe3V2FeJg.png"/></div></div></figure><p id="521e" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">输入我们假设的参数值，我们计算一个估计的输出</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ok"><img src="../Images/630201b44304a7d6c7d9eac4f8004945.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QIGOopracfN3ru5nW3CmIA.png"/></div></div></figure><p id="f0cb" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们的目标是更新参数，使我们的估计输出(ŷ)等于实际输出(y)。</p><h2 id="c721" class="nv lu it bd lv nw nx dn lz ny nz dp md ks oa ob mh kw oc od ml la oe of mp og bi translated">3.计算损失——计算的产量与实际产量相差多少？</h2><p id="0a3b" class="pw-post-body-paragraph kh ki it kj b kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la mv lc ld le im bi translated">这就是事情变得有趣的地方。</p><p id="79f5" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们计算我们的假设离实际值有多远，并更新我们的参数以更接近实际输出。</p><p id="c9cd" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">为了使用梯度来计算和更新我们的参数假设，我们需要使用可微分的函数来计算损失。</p><p id="2365" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们将使用平方误差作为损失函数。它衡量的是我们的假设(ŷ)和实际产出(y)之间的平方差。平方误差具有独特的优势，因为它确保了微小误差变化的小值，但当模型假设与实际值相差甚远时，误差就会爆炸。<br/>“为什么”此损失值对算法至关重要，将在下一步中清除。</p><p id="ea64" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">让我们根据我们的假设来计算损失—</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ol"><img src="../Images/e48f8ff3a692841dc157cce4badec043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fg7Xm0fb01eImldNJV4ZFw.png"/></div></div></figure><h2 id="6a53" class="nv lu it bd lv nw nx dn lz ny nz dp md ks oa ob mh kw oc od ml la oe of mp og bi translated">4.<strong class="ak">计算梯度</strong></h2><p id="eaf5" class="pw-post-body-paragraph kh ki it kj b kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la mv lc ld le im bi translated">这是算法中最重要的一步，因为这是我们迭代学习和改进假设以接近实际输出的地方。</p><p id="85e6" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们首先把我们的损失写成模型参数的函数—</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi om"><img src="../Images/5504a1fa936dda4957dd638d32fe0cfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yQv9iYzfK7BImM_OrLbq4A.png"/></div></div></figure><p id="a8bc" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">为了确定如何改变参数以更接近实际输出，我们计算了每个系数的梯度(偏导数)和偏置项与损耗的关系</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi on"><img src="../Images/4af80913f58cc2b67435e9245da7d2f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RCq9JFq7PKH5xyuDQQo43w.png"/></div></div></figure><p id="8fb4" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这为我们提供了梯度，它测量每个参数对预测输出的影响，本质上告诉我们需要改变每个参数多少才能更接近实际输出。</p><h2 id="716a" class="nv lu it bd lv nw nx dn lz ny nz dp md ks oa ob mh kw oc od ml la oe of mp og bi translated">5.<strong class="ak">更新<em class="oh"> w1 </em>、<em class="oh"> w2 </em>和<em class="oh">b</em>T34】</strong></h2><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oo"><img src="../Images/a464a3bf7c64624f7b62052cb087ccff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QU54PT8eUcIBkD8zYUVW2w.png"/></div></div></figure><p id="c0cb" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">哇！看起来我们的假设差了一大截！</p><p id="7c24" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这看起来不对。让我们使用一个缩放变量来缩放我们的更新— <strong class="kj iu">学习率(η) </strong>。学习率确保我们的权重不会在每次更新时发生巨大的变化(并开始波动)。</p><p id="7110" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">考虑到η= 0.01，我们的更新看起来更合理——</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ol"><img src="../Images/20bad9190b332431c7d471c105fdb973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IEm-NUKC44_hhRiaI-NTiQ.png"/></div></div></figure><p id="e871" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">那看起来更合理。</p><p id="2829" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这完成了算法的一次迭代。现在我们重复这些步骤，直到<strong class="kj iu">收敛</strong> <em class="nl">，即</em>，直到我们的权重变化不大和/或我们的损失接近于 0。</p><p id="a66f" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">让我们用更新后的参数对其他数据行进行另一次迭代。</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi op"><img src="../Images/3b8f3929b8d2fa19cbfb5d35802d52d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3_NdhQKkrd-QRhxgHkmHvQ.png"/></div></div></figure><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi om"><img src="../Images/4ed97cad4cee34fa3bf46193380862d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r-FQq_2dyVHGWajhw3X__A.png"/></div></div></figure><p id="a84f" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">将相同的过程再重复几次*，从前四行数据中随机取样一行(我们保留最后一行来验证我们的模型)，我们得到以下参数值—</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oq"><img src="../Images/f0f4ea356c1499ca5ecc47bfb0a41f42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*19bVOlQqS34wIgZ9TETCUQ.png"/></div></div></figure><p id="6c8a" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">使用这些，让我们看看验证样本(最后一行)上的错误是什么样子的。</p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi or"><img src="../Images/6136cb32cb4d8a86c4c83d684f9e674e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2O5vm9UDucpX5hhJnP7wTA.png"/></div></div></figure><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi os"><img src="../Images/ef88db7d41d8ad3cdd5aa1aa8a909b47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tTQXbL2Klh5nE587UDlDNA.png"/></div></div></figure><p id="cdf7" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们的损失几乎为 0。我们可以说模型已经找到了这个数据的最佳参数。</p><p id="6e22" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">仅此而已。本质上，这就是线性回归的作用。</p></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><h1 id="acea" class="lt lu it bd lv lw pa ly lz ma pb mc md me pc mg mh mi pd mk ml mm pe mo mp mq bi translated">这真的是线性回归的全部功能吗？</h1><p id="61d8" class="pw-post-body-paragraph kh ki it kj b kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la mv lc ld le im bi translated">“引擎盖下”是本系列的焦点，我们看了一下线性回归的基础(更具体地说——随机梯度下降)，一次取一个样本，并更新我们的参数以适应数据。</p><p id="5748" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">虽然这确实是线性回归的核心，但是创建一个好的线性回归模型还有很多工作要做，比如—</p><p id="6950" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">1.正规化——L1 和 L2</p><p id="5e3c" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">2.学习率调度</p><p id="b560" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">3.正态方程</p><p id="9e97" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">4.随机与小批量与批量梯度下降</p><p id="11ad" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">5.提前停止</p><p id="a4db" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我将在一个平行系列中讨论这些概念，重点是算法之间的公共优化点。</p><h1 id="c198" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">下一步是什么？</h1><p id="13de" class="pw-post-body-paragraph kh ki it kj b kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la mv lc ld le im bi translated">在本系列的下一篇文章中，我们将挑选一个二进制分类数据，并深入了解<a class="ae kf" rel="noopener" target="_blank" href="/under-the-hood-logistic-regression-407c0276c0b4"> <strong class="kj iu">逻辑回归</strong> </a>算法。它与线性回归并没有太大的不同，但是它有一些自己的怪癖，需要在线性回归之外提及。</p></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><p id="3e2c" class="pw-post-body-paragraph kh ki it kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">* <em class="nl">经过 15 次迭代，这是我们的损失、梯度和参数值的变化方式— </em></p><figure class="nn no np nq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pf"><img src="../Images/ffa5030ac1063a962ec3eae22c0dc4fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VVLTfWpfYw7IV-HYbWrYSw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">15 次迭代后的参数更新</p></figure></div></div>    
</body>
</html>