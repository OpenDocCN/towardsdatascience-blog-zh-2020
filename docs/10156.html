<html>
<head>
<title>A Visual Guide to Decision Trees</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树的可视化指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-visual-guide-to-decision-trees-26606e456cbe?source=collection_archive---------34-----------------------#2020-07-17">https://towardsdatascience.com/a-visual-guide-to-decision-trees-26606e456cbe?source=collection_archive---------34-----------------------#2020-07-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="64ce" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">这是一个直观的可视化指南，介绍了用于预测美国各州投票模式的强大 ML 算法。</h2></div><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="kk kl l"/></div></figure><p id="afd2" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">你有没有想过为什么某些州倾向于投票给共和党，而另一些州倾向于投票给民主党？有没有办法预测一个州在任何一年的投票结果？假设我们想要根据我们观察到的一些变量来预测一个状态是<strong class="ko ir">【红色】</strong>还是<strong class="ko ir">【蓝色】</strong>。为此，我们将使用决策树。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi li"><img src="../Images/cbb58d6a509a045798bb05fc060d5826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IXldPib5H43CoTVU.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">红蓝图，2016；图片来自<a class="ae lt" href="https://en.wikipedia.org/wiki/Political_party_strength_in_U.S._states" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="2427" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">决策树是一种分类和回归监督学习模型，用于使用来自几个输入变量(x)的信息来预测目标变量(Y)的值。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi lu"><img src="../Images/f4d0e1e8c37cc4d3af51e89df10233c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PA2iTSkX3Y6H_UTN"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="lv">作者图片</em></p></figure><p id="26e9" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">顾名思义，该模型在视觉上表现为一个倒置的树状结构，随着树的增长，数据集被分成越来越小的子集。每个内部节点或决策节点都包含一个需要回答的关于特定 X 变量的简单“对或错”问题。在此基础上，树分裂成分支——一个分支代表真，另一个分支代表假。每个分支的末端都是另一个问题。这个递归过程继续进行，随着每个决策的做出，树变得越来越深，越来越宽，直到它在做出预测的叶节点处结束。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi lu"><img src="../Images/227d4b07a2bcf5eac4b576175ae9cc1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LVzxNC7siaywe_37"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="lv">作者图片</em></p></figure><p id="e405" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">让我们举一个数据集的例子。我们有 Y 变量——一个州是红色还是蓝色，我们有 3 个 X 变量:<strong class="ko ir">教育*、收入** </strong>和<strong class="ko ir">种族多样性*** </strong>。现在，让我们尝试构建一个决策树来预测一个州的政治倾向，即基于这 3 个变量，它是红色还是蓝色。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi lw"><img src="../Images/9a24368818fd92278b630b8a9199b997.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ESPn0kkwI_Qk342zRtnVDA.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="lv">作者图片</em></p></figure><p id="8f34" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">您可能想知道，当变量本质上是连续的或数字的，而不是简单的布尔值(真或假)时，决策树是如何进行拆分的。答案很简单。在引擎盖下，我们创建了多个变量来表示在不同的阈值下分割连续变量。这些划分通常是在该变量的不同十分位数或四分位数处进行的。在我们的例子中，让我们只使用每个变量的<strong class="ko ir">中值</strong>作为单个阈值。如果值小于中值，我们将把这些连续变量转换成二进制变量或布尔变量，如果值大于中值，我们将把值设置为假，将值设置为真。这些现在是布尔特征。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi lx"><img src="../Images/99420201c9aa5418532563d8d7ced282.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oj0XXJvxnj11D27e9zZJrA.png"/></div></div></figure><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi lu"><img src="../Images/d92d224d6e2f0c814ffac21ee24d421c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iYxbI6DXcwVHeCe5"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="lv">作者提供的图片</em></p></figure><p id="d32b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">现在让我们开始创建决策树。为了创建第一个决策节点，我们必须选择一个变量进行分割。决策树使用一个叫做<strong class="ko ir">信息增益</strong>的标准来挑选合适的变量。信息增益是衡量我们在查看 x 后对 Y 了解多少的指标。例如，如果我们随机预测一个没有其他信息的州的政治倾向，则该州为红色的概率为。然而，如果我们知道关于那个状态的一些其他信息，我们可以更新我们关于那个概率的信念。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi lu"><img src="../Images/5ed1b5a5ff889748af613bcc674725bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6M_tMEW8taiaGlXf"/></div></div></figure><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi lu"><img src="../Images/7f40e5953060831481f3f51c1f292b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5hxhipVNtXntyKKV"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="lv">作者图片</em></p></figure><p id="3817" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">让我们来看看，当我们在 3 个变量上一个接一个地分割树时，会发生什么。</p><p id="ea0a" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">当我们在教育上分裂时，我们看到真正的分支包含教育水平高于中位数的州，主要是蓝色州和一个红色州。错误的分支，或教育水平低于中间水平的州，大部分是红色州，少数是蓝色州。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ly"><img src="../Images/10d39ab70ec0abacf6fe9c0567c5040e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bi-DZ171kPpUdJ7iF2yC7A.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</p></figure><p id="961f" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">当我们在种族多样性上分裂时，我们看到真正的分支包含了多样性高于中间值的州，大部分是蓝色的州。假分支，或者多样性低于中间值的州，有几乎相等数量的红州和蓝州。<em class="lz">这意味着知道一个州不是多元化的并不意味着有政治倾向。</em></p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ma"><img src="../Images/ae17adb33c9da6df1fef70f162215968.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TA_fPB7wt_DN075tELJ3gQ.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</p></figure><p id="cc30" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">最后，让我们看看当我们在收入上分裂时会发生什么。这里，真正的分支包含收入高于中间值的州，大部分是蓝色州。错误的分支，或者收入低于中间值的州，有几乎相等数量的红州和蓝州。这意味着知道一个州的收入低于中值也不能有意义地表明政治倾向。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mb"><img src="../Images/475668e54b9b683cae7fbe606b34edce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SeHYWJhtyGRjOhLT0rG8Sw.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</p></figure><p id="bed5" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">在比较了要分割的每个可能的变量之后，决策树挑选出导致<strong class="ko ir">最纯粹分支</strong>的变量。在我们的例子中，教育上的分裂导致最纯的分支，因为真实分支只包含 1 个红色状态，而虚假分支包含的蓝色状态是红色状态的一半。从教育中获得的信息很多。种族多样性分裂将是最糟糕的选择。虽然真分支包含大部分蓝色状态，但假分支基本上是红蓝各半。知道国家缺乏多样性几乎不会给模型增加新的信息。从种族多样性中获得的信息非常少。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mb"><img src="../Images/edf5340f16dd3f22b9377e0103994423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VhKJhM1vUgwHXp5EqoFoSQ.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</p></figure><p id="45be" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">在对教育进行了第一次拆分之后，我们现在来看看两个结果分支，并再次看看我们可以拆分哪些变量来进一步净化我们的分支。这样继续下去，直到我们到达纯分支或树的最大深度。我们最终的树在下面，它有大约 80%的准确率。考虑到我们只有 3 个变量，这太棒了。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mc"><img src="../Images/9246eacaf19db05dcde243e08c54dcd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oE_cosUrx_9AJ-B0Tz6qJg.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</p></figure><p id="9c5a" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">你可能会问:<em class="lz">“为什么我们不简单地分割每个特征，并使树尽可能长，以得到一个完全符合数据的模型？”</em></p><p id="5fea" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">这不是一个坏主意<strong class="ko ir">如果</strong>你有一个数据集是你正在研究的人群的超级代表。然而，问题是您的模型可能会开始进行如此多的分割，以至于它会学习特定数据集的古怪之处，并且无法拟合附加数据或做出可靠的预测。这是一个如此常见的问题，它有一个名字:<strong class="ko ir">过度拟合</strong>。过度拟合是当模型容量过大时遇到的问题。因此，一般来说，我们通过限制分裂的数量来减少这些树的容量，即<em class="lz">限制树的深度。</em></p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi md"><img src="../Images/5459ba2f6557eb94d940eae162418a49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zVOhKOzHhP3o4bH8va1KfA.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片</p></figure><p id="cade" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">决策树是目前世界上最常见的模型。它们简单高效的本质，以及它们组合成非常强大的模型的能力，如<strong class="ko ir">随机森林</strong>和<strong class="ko ir">梯度增强树</strong>，使它们成为许多开发人员的最爱。敬请期待未来了解这些。</p><h2 id="6f59" class="me mf iq bd mg mh mi dn mj mk ml dp mm kv mn mo mp kz mq mr ms ld mt mu mv mw bi translated">要自己实现这个模型，请查看<a class="ae lt" href="https://colab.research.google.com/drive/1Z1aiXravQxrUKJbk1ciTy0DZ_yhBopZS?usp=sharing" rel="noopener ugc nofollow" target="_blank">这个链接</a>并使用左边的播放按钮运行每个单元格！</h2><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mx"><img src="../Images/91aa19dbfd58da16b6e14eeb213306f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jvnhNHmNMkPX3Inv"/></div></div></figure><p id="7fe8" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">*各州家庭收入中位数(<a class="ae lt" href="https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-income-households.html" rel="noopener ugc nofollow" target="_blank">人口普查数据</a> ) <br/> ** %本科或以上学历(<a class="ae lt" href="http://ates_and_territories_by_educational_attainment" rel="noopener ugc nofollow" target="_blank">2013-2017 年美国社区调查</a>)<br/>* * * * %非白人人口(<a class="ae lt" href="https://www.kff.org/other/state-indicator/distribution-by-raceethnicity/?currentTimeframe=0&amp;sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D" rel="noopener ugc nofollow" target="_blank">凯泽家庭基金会基于人口普查局 2008-2018 年美国社区调查</a>)的估计</p></div></div>    
</body>
</html>