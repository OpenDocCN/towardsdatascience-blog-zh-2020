<html>
<head>
<title>Importance of Data Visualization — Anscombe’s Quartet Way.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据可视化的重要性——Anscombe 的四重奏。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/importance-of-data-visualization-anscombes-quartet-way-a325148b9fd2?source=collection_archive---------15-----------------------#2020-07-27">https://towardsdatascience.com/importance-of-data-visualization-anscombes-quartet-way-a325148b9fd2?source=collection_archive---------15-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2798" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">进入现实世界</h2><div class=""/><div class=""><h2 id="f3b1" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">四个数据集欺骗了线性回归模型。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/cfd3f423d0cdbec40e1d9ccfc142f920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*teCUzrolOckJEyHsNhi_Ng.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><blockquote class="lh"><p id="6110" class="li lj it bd lk ll lm ln lo lp lq lr dk translated">安斯科姆的四重奏由四个<a class="ae ls" href="https://en.wikipedia.org/wiki/Data_set" rel="noopener ugc nofollow" target="_blank">数据集</a>组成，它们具有几乎相同的简单<a class="ae ls" href="https://en.wikipedia.org/wiki/Descriptive_statistics" rel="noopener ugc nofollow" target="_blank">描述性统计</a>，然而具有非常不同的分布，并且在绘制时显得非常不同。<br/> —维基百科</p></blockquote><p id="670a" class="pw-post-body-paragraph lt lu it lv b lw lx kd ly lz ma kg mb mc md me mf mg mh mi mj mk ml mm mn lr im bi translated"><strong class="lv jd"> Anscombe 的四重奏</strong>可以定义为一组四个数据集，它们在简单的描述统计学中<strong class="lv jd">几乎相同，但是数据集中有一些特性，如果建立的话<strong class="lv jd">会欺骗回归模型</strong>。它们具有非常不同的分布，并且在散点图上绘制时<strong class="lv jd">呈现不同的</strong>。</strong></p><p id="97dd" class="pw-post-body-paragraph lt lu it lv b lw mo kd ly lz mp kg mb mc mq me mf mg mr mi mj mk ms mm mn lr im bi translated">它是由统计学家<strong class="lv jd"> Francis Anscombe </strong>在 1973 年构建的，用以说明在分析和建模之前<strong class="lv jd">绘制图表</strong>的<strong class="lv jd">重要性</strong>，以及其他<strong class="lv jd">观测对统计特性</strong>的影响。这四个数据集图具有几乎<strong class="lv jd">相同的统计观察值</strong>，提供相同的统计信息，包括所有四个数据集中所有 x，y 点的<strong class="lv jd">方差</strong>和<strong class="lv jd">均值</strong>。</p><p id="fe1d" class="pw-post-body-paragraph lt lu it lv b lw mo kd ly lz mp kg mb mc mq me mf mg mr mi mj mk ms mm mn lr im bi translated">这告诉我们，在应用各种算法来构建模型之前，可视化数据的重要性，这表明必须绘制数据特征，以便查看样本的分布，这可以帮助您识别数据中存在的各种异常，如异常值、数据的多样性、数据的线性可分性等。此外，线性回归只能被视为适合具有线性关系的<strong class="lv jd">数据，不能处理任何其他类型的数据集。这四个图可以定义如下:</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mt"><img src="../Images/e86c2024819d45342626a13e7c003189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wMuoOLohuNbTWbbu_rpujg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="210f" class="pw-post-body-paragraph lt lu it lv b lw mo kd ly lz mp kg mb mc mq me mf mg mr mi mj mk ms mm mn lr im bi translated">所有这四个数据集的统计信息大致相似，可以计算如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mt"><img src="../Images/77fe6487e01fbbf5b06e472e73513c80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UrXAppaF09s88C_rG0KRjA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="929c" class="pw-post-body-paragraph lt lu it lv b lw mo kd ly lz mp kg mb mc mq me mf mg mr mi mj mk ms mm mn lr im bi translated">当这些模型绘制在散点图上时，所有数据集都会生成不同类型的图，任何回归算法都无法对其进行解释，这些算法会被这些特性所迷惑，如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mu"><img src="../Images/b6e287bb7d5dfd0fb8717eb12836cd2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4H7ByZaIXvke8NVAOZ8E2g.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="c42e" class="pw-post-body-paragraph lt lu it lv b lw mo kd ly lz mp kg mb mc mq me mf mg mr mi mj mk ms mm mn lr im bi translated">这四个数据集可以描述为:</p><ol class=""><li id="864b" class="mv mw it lv b lw mo lz mp mc mx mg my mk mz lr na nb nc nd bi translated"><strong class="lv jd">数据集 1: </strong>这个<strong class="lv jd">非常符合</strong>线性回归模型。</li><li id="e543" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni lr na nb nc nd bi translated"><strong class="lv jd">数据集 2: </strong>该<strong class="lv jd">无法很好地拟合</strong>数据的线性回归模型，因为数据是非线性的。</li><li id="7ecb" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni lr na nb nc nd bi translated"><strong class="lv jd">数据集 3: </strong>显示了数据集中涉及的<strong class="lv jd">异常值</strong>，这些异常值<strong class="lv jd">不能用线性回归模型</strong>处理</li><li id="89f8" class="mv mw it lv b lw ne lz nf mc ng mg nh mk ni lr na nb nc nd bi translated"><strong class="lv jd">数据集 4: </strong>显示数据集中涉及的<strong class="lv jd">异常值</strong>，这些异常值<strong class="lv jd">不能用线性回归模型</strong>处理</li></ol><h1 id="ddf8" class="nj nk it bd nl nm nn no np nq nr ns nt ki nu kj nv kl nw km nx ko ny kp nz oa bi translated">结论:</h1><p id="1b7e" class="pw-post-body-paragraph lt lu it lv b lw ob kd ly lz oc kg mb mc od me mf mg oe mi mj mk of mm mn lr im bi translated"><em class="og">我们已经描述了四个数据集，这四个数据集旨在描述数据可视化的重要性，以及任何回归算法如何被数据可视化所欺骗。因此，在对数据集中的所有重要特征实施任何机器学习算法之前，必须将其可视化，这将有助于建立良好的拟合模型。</em></p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="240a" class="pw-post-body-paragraph lt lu it lv b lw mo kd ly lz mp kg mb mc mq me mf mg mr mi mj mk ms mm mn lr im bi translated">感谢阅读。你可以在这里找到我的其他<a class="ae ls" href="https://towardsdatascience.com/@imsparsh" rel="noopener" target="_blank">机器学习相关的帖子</a>。</p><p id="70f9" class="pw-post-body-paragraph lt lu it lv b lw mo kd ly lz mp kg mb mc mq me mf mg mr mi mj mk ms mm mn lr im bi translated">希望这篇帖子有用。我感谢反馈和建设性的批评。如果你想谈论这篇文章或其他相关话题，你可以在这里或在<a class="ae ls" href="https://www.linkedin.com/in/imsparsh/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>给我发短信。</p><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/assumptions-in-linear-regression-528bb7b0495d"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd jd gy z fp ow fr fs ox fu fw jc bi translated">线性回归中的假设你可能不知道。</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">模型应该符合这些假设，以产生与数据的最佳线性回归拟合。</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf lb or"/></div></div></a></div><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/most-common-loss-functions-in-machine-learning-c7212a99dae0"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd jd gy z fp ow fr fs ox fu fw jc bi translated">机器学习中最常见的损失函数</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">每个机器学习工程师都应该了解机器学习中这些常见的损失函数，以及何时使用…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="pa l"><div class="pg l pc pd pe pa pf lb or"/></div></div></a></div></div></div>    
</body>
</html>