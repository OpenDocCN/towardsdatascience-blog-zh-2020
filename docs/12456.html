<html>
<head>
<title>How Convolution Neural Networks interpret images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络如何解释图像</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-convolution-neural-networks-interpret-images-1f99913070b2?source=collection_archive---------20-----------------------#2020-08-27">https://towardsdatascience.com/how-convolution-neural-networks-interpret-images-1f99913070b2?source=collection_archive---------20-----------------------#2020-08-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="cd68" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/deep-learning-biology" rel="noopener">深度学习+生物</a></h2><div class=""/><div class=""><h2 id="411f" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">关键构建模块的直观指南</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/46bb98484d83c7e20765e9d3995b8b9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_NtBv_9NkSKR2r0JY7UeoQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/photos/xYamknRmK04" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="4989" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文的目的是让<strong class="lk jd">对卷积神经网络中的关键层</strong>有一个直观的了解。这个想法是超越简单陈述事实和探索图像处理实际上是如何工作的。</p><h2 id="a4b5" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">目标</h2><p id="e5d0" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">假设我们的目标是训练一个深度学习网络，以成功区分如下所示的猫和狗的图像</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nb"><img src="../Images/55224264f56264701c194e48bdecc67a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O-h7qGilwjHmjUnNvms3MQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/photos/XGZZrXODE3k" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="1318" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们从思考这样的算法必须克服哪些挑战开始。首先，它必须能够检测不同颜色、大小、形状和品种的猫和狗。当只能看到狗/猫的某一部分而不是整个部分时，它也必须工作。该算法必须对图像中不止一只狗/猫的存在敏感，最重要的是，它必须是空间不变的——它必须不期望狗/猫在图像的某个部分。在下面的章节中，我们将探讨 CNN 架构的不同组件如何产生所有这些功能。</p><h1 id="5206" class="nc mf it bd mg nd ne nf mj ng nh ni mm ki nj kj mp kl nk km ms ko nl kp mv nm bi translated">计算机如何读取图像。</h1><p id="d596" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">图像由像素组成，像素值代表亮度，范围从 0 到 255。0 代表黑色，255 代表白色，其他都是灰色。像素越多，图像质量越好。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nn"><img src="../Images/0a3ce907686980b703cd8731d0c93add.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HGbTNMAQ76Gle76uCzYOTw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图像质量随着像素数的增加而提高。[作者制作]</p></figure><p id="9f7f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然灰度图像是由单个通道(即单个 2D 像素阵列)组成的，但 RBG 格式的彩色图像是由三个不同的层组成的，这三个层相互堆叠在一起。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi no"><img src="../Images/618da1c4f5ec9294b6cde8796c8c530a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AB3CIu1s6LllkcXy4ZpYMQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">RGB 图像的三个通道，<strong class="bd np"> r </strong> ed，<strong class="bd np"> g </strong> reen，<strong class="bd np"> b </strong> lue。<strong class="bd np"> </strong>【作者制作】</p></figure></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h1 id="ed79" class="nc mf it bd mg nd nx nf mj ng ny ni mm ki nz kj mp kl oa km ms ko ob kp mv nm bi translated">多层感知器的局限性。</h1><p id="cadf" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">传统的神经网络不适合像图像分类这样的深度学习应用。每个像素的内容在输入层分别输入到感知器中。对于尺寸为 600*377*3 的 RGB 图像，仅输入层要学习的参数总数将为(600*377*3*2(每个神经元两个参数，权重和偏差))~ 150 万。这个数字将与层数成线性比例。然而，这并不是 MLP 面临的唯一挑战。MLP 没有内在的空间不变机制。如果一只 MLP 已经被训练来检测图像右上角的狗，当狗位于其他位置时，它将失败。</p><p id="6009" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">卷积神经网络旨在使用内置机制来改善这些缺点，该机制用于<strong class="lk jd"> (1)提取不同的高级特征(2)引入空间不变性(3)提高网络学习能力。</strong></p><h1 id="165b" class="nc mf it bd mg nd ne nf mj ng nh ni mm ki nj kj mp kl nk km ms ko nl kp mv nm bi translated">图像特征提取。</h1><p id="cfcc" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">卷积(具体来说是离散卷积)是基于使用线性变换来从图像中提取关键特征，同时保持信息的顺序。输入与一个<strong class="lk jd">内核</strong>进行卷积，产生输出，类似于人类视觉皮层神经元网络产生的响应。</p><h2 id="8866" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">核心</h2><p id="c1fa" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">内核(也称为滤波器或特征检测器)在水平和垂直方向上以预定的步长(称为<strong class="lk jd">步长</strong>)对输入图像矩阵进行采样。当核在输入图像上滑动时，计算核的每个元素与输入图像的重叠元素之间的元素乘积，以获得当前位置的输出。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/0688c07c06e0bb12930fa48b9879f1b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pBl_apjfUypPS7vALg0fjQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd np">卷积</strong>:用 3*3 滤波器<strong class="bd np"> K </strong>对表示为 7*7*1 维张量的图像<strong class="bd np"> I </strong>进行卷积，得到 5*5 的输出图像。上面显示的是一个乘法步骤。<a class="ae lh" href="https://github.com/PetarV-/TikZ/tree/master/2D%20Convolution" rel="noopener ugc nofollow" target="_blank">来源</a>，图片免费分享。</p></figure><p id="8fc1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当输入图像由多个通道组成时(几乎总是如此)，内核的深度与输入图像中通道的数量相同。在这种情况下，点积被相加以获得由单个通道组成的最终特征图。如果你是矩阵乘法的新手，看看这个 youtube 视频的详细解释。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/4482e02cc09cb0441adea1c227dc7530.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*YvlCSNzDEBGEWkZWNffPvw.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd np">单步卷积</strong>:该动画展示了内核(显示为一个 3*3 的移动正方形)如何从左到右和从上到下扫描输入图像，从而在右侧产生输出图像。对于一步一个卷积，内核在每一步中向每个方向移动一个单位距离。<a class="ae lh" href="https://github.com/aqeelanwar/conv_layers_animation" rel="noopener ugc nofollow" target="_blank">来源</a>，图片免费分享。</p></figure><p id="8291" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">每个卷积层由许多不同的滤波器组成，每个滤波器提取不同的特征。虽然由单个卷积层构成的 CNN 将仅提取/学习低级特征，但是添加连续的卷积层显著提高了学习高级特征的能力。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oe"><img src="../Images/cd54aa8c4f645aa5984d61ebf01f4436.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_5yomYL0YTMpi_FtZTZWdw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd np">特征提取:</strong>一个 600*377 的灰度图像与 4 个不同的 3*3 滤波器卷积，导致不同的图像特征被提取到不同的程度。[作者制作]</p></figure><h2 id="d41e" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">整流器</h2><p id="e083" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">为了在系统中引入非线性并提高学习能力，卷积运算的输出通过非饱和激活函数，如 sigmoid 或整流线性单元(ReLU)。看看这篇<a class="ae lh" rel="noopener" target="_blank" href="/complete-guide-of-activation-functions-34076e95d044">关于这些和其他几个常用激活函数的优秀文章</a>。最常用的激活函数 ReLU 本质上保留正值，并用零替换负值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/7c821cfcfac910bbd16c6788c3879e99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vy6P9Z-ODA6BtXFYMH_J8w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">整流器:两个最广泛使用的整流器函数，sigmoid 和 ReLU。[作者制作]</p></figure><h2 id="2393" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">填料</h2><p id="9d4c" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">与输入图像相比，由卷积产生的特征图在尺寸上更小。对于一个输入图像<strong class="lk jd"> I </strong> * <strong class="lk jd"> I </strong>与大小为<strong class="lk jd"> K </strong> * <strong class="lk jd"> K </strong>的核进行卷积，步长为<strong class="lk jd"> S </strong>，输出将为<strong class="lk jd">[(I-F)/S+1】</strong>*<strong class="lk jd">[(I-F)/S+1】</strong>。这可以导致由几个卷积层构成的 CovNets 中的图像尺寸显著减小。输出图像周围的零填充<strong class="lk jd"> [(F-1)/2] </strong>可用于保持卷积输出。</p><p id="8535" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于尺寸为<strong class="lk jd"> I </strong> * <strong class="lk jd"> I </strong>的输入图像与尺寸为<strong class="lk jd"> K </strong> * <strong class="lk jd"> K </strong>的滤波器以步长<strong class="lk jd"> S </strong>和填充<strong class="lk jd"> P </strong>进行卷积的最一般情况，输出将具有尺寸<strong class="lk jd">[(I+2P-K)/S+1]*[(I+2P-K)/S+1]</strong>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/3875ba560778849390624823b6b4f681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*cpI5QE8IqqCOzhrOWRWqEg.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd np">填充</strong>:当一个 5*5 的图像与一个没有填充的 3*3 内核进行卷积时，得到的图像是 3*3。单层填充将输入图像尺寸更改为 7*7。当与 3*3 滤波器卷积时，会产生 5*5 输出，与原始输入的大小相同。<a class="ae lh" href="https://github.com/aqeelanwar/conv_layers_animation" rel="noopener ugc nofollow" target="_blank">来源</a>，图片免费分享。</p></figure><h2 id="7c34" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated"><strong class="ak">联营</strong></h2><p id="171e" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">汇集卷积输出，以便引入空间不变性，即在不同图像中检测相同特征的能力。这里的想法是保留与 CNN 必须了解的重要特征相对应的关键信息，同时通过去除无关紧要的信息来减小图像大小。虽然有几种变化，但最大池是最常用的策略。卷积乘积被分割成大小为<strong class="lk jd"> K </strong> * <strong class="lk jd"> K </strong>的非重叠面片，并且在输出中只记录每个面片的最大值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/8bf36629c7c2fd55a7eb695eed71c06d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*10iSX8HGLMZQqLSer2-tZw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd np"> Max-Pooling </strong>:一个 4*4 的输入图像与一个 2*2 的内核进行 Max-Pooling，产生一个 2*2 的输出。<a class="ae lh" href="https://computersciencewiki.org/index.php/Max-pooling_/_Pooling" rel="noopener ugc nofollow" target="_blank">来源</a>，图片免费分享。</p></figure><p id="1f01" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其他不常用的汇集策略包括平均汇集、“混合”最大平均汇集、随机汇集和空间金字塔汇集。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/c9d43f78b0925b5e0568db582c26e1a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uYFve3l4yK-AELt2UWFdnQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd np"> MaxPooling </strong>:虽然图像尺寸大大减小，但是池化图像仍然包含训练图像分类网络所需的所有关键特征。请注意，stride 2 maxpooling 操作对图像质量的影响很小。[作者制作]</p></figure><p id="96c7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">到目前为止所讨论的 CNN 的两个关键元素:卷积层(由内核、步幅、激活函数定义)和池层以预定的模式组合在一起，以定义 CNN 架构。虽然我不会进入架构细节，但在下一节中，我们将讨论这些神经网络进行图像处理的一些一般特征。</p><h1 id="bf10" class="nc mf it bd mg nd ne nf mj ng nh ni mm ki nj kj mp kl nk km ms ko nl kp mv nm bi translated"><em class="oj">可视化内层</em></h1><p id="66c7" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">我使用了一个<a class="ae lh" href="https://www.kaggle.com/chetankv/dogs-cats-images" rel="noopener ugc nofollow" target="_blank">公开可用的</a>带标签的猫&amp;狗图像数据集，并训练了一个二进制分类器(inceptionv3)。使用这个训练过的网络，我们可以感受一下 CNN 实际上是如何处理图像的。</p><p id="7563" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我们获取一个样本图像，并通过这个训练好的网络进行传递。3 个卷积和相关激活层(我使用 ReLU)的输出如下图所示。显而易见的是，随着我们沿着网络向下移动，输出变得越来越难以理解。当我们在第 25 层时，很难判断输入网络的图像是一只狗还是一只猫。值得注意的是，这个网络的整体架构相当复杂(这里不包括)，第 25 层甚至还不到网络的一半。那么这些层实际上在学习什么呢？仅仅看下面的图片并不明显。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/ad70787ee60934c47b3fd65e110f86fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P_jOjHQgpp0tsnwnOjvOaA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">当输入狗的图像时，训练好的 CNN 的卷积和相关的激活层。[作者制作]</p></figure><p id="95ef" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上图只是显示了输入图像的每个图层的输出。我们需要的是可视化每个卷积层的不同内核。这将告诉我们每个过滤器正在检测什么。我们从随机噪声构成的图像开始，并针对层中的每个内核对其进行优化。换句话说，我们在一个经过训练的网络中使用一组过滤器，并询问“什么样的输入图像将激活这个特定的内核”。了解这张图像将会告诉我们更多关于特定过滤器检测的内容。这个逻辑和相关代码的更详细的解释可以在<a class="ae lh" rel="noopener" target="_blank" href="/understanding-your-convolution-network-with-visualizations-a4883441533b">这里</a>和<a class="ae lh" rel="noopener" target="_blank" href="/feature-visualization-on-convolutional-neural-networks-keras-5561a116d1af">这里</a>找到。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/539107423d9b23200e44e40fbcbd000f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*279NEsyOHprkRXsnXHwqow.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">所选图层的特征可视化。[作者制作]</p></figure><p id="a214" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上面可视化的是与上面相同的层的一些过滤器激活模式。不同的层由图像的不同部分激活。层 1 本质上是由水平和垂直边缘激活的边缘检测器。随着我们深入网络，卷积核识别的模式变得复杂和稀疏，因为在这些阶段提取了更多的抽象图像特征。</p><h2 id="966e" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated"><em class="oj">结论。</em></h2><p id="6a83" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">在本文中，我试图解释不同卷积层的设计和内部工作原理。如果你有任何建议，请给我留言或写信到 aseem.kash@gmail.com。</p></div></div>    
</body>
</html>