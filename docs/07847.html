<html>
<head>
<title>Efficient PyTorch — Eliminating Bottlenecks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高效PyTorch —消除瓶颈</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/efficient-pytorch-part-1-fe40ed5db76c?source=collection_archive---------8-----------------------#2020-06-11">https://towardsdatascience.com/efficient-pytorch-part-1-fe40ed5db76c?source=collection_archive---------8-----------------------#2020-06-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5b9f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">什么是高效的PyTorch培训渠道？它是产生具有最佳精确度的模型的那个吗？还是跑得最快的那个？还是容易理解和扩展的那个？可能是容易平行的那种？以上都是。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/efdf7bfcad2f44a38f554d03712949d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fzkUsfcu5hlrots5"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">哈里·谢尔顿在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="5685" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>是一款用于研究和生产领域的优秀工具，斯坦福大学、Udacity、SalelsForce、Tesla等都采用了这一深度学习框架，这清楚地表明了这一点..然而，每种工具都需要投入时间来掌握技能，以便最有效地使用它。在使用PyTorch两年多后，我决定总结一下我使用这个深度学习库的经验。</p><blockquote class="lv lw lx"><p id="056e" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">高效的—(指系统或机器)以最少的浪费努力或费用获得最大的生产率。(牛津语言)</p></blockquote><p id="cf19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">高效PyTorch系列的这一部分给出了识别和消除I/O和CPU瓶颈的一般技巧。第二部分将揭示一些关于有效张量运算的技巧。第三部分——高效的模型调试技术。</p><p id="2bff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ly">免责声明</em>:这篇文章假设你至少对PyTorch有所了解。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><p id="a3fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将从最明显的一个开始:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mj"><img src="../Images/6414439ca7be856a0c5dd034a5283106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*khi0nSnwRr6Sdcx7"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@roshnisidapara?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Roshni Sidapara </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><blockquote class="lv lw lx"><p id="0cfd" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">建议0: <strong class="lb iu">知道代码中的瓶颈在哪里</strong></p></blockquote><p id="a056" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">命令行工具，如<code class="fe mk ml mm mn b"><a class="ae ky" href="https://developer.nvidia.com/nvidia-system-management-interface" rel="noopener ugc nofollow" target="_blank">nvidia-smi</a></code>、<code class="fe mk ml mm mn b"><a class="ae ky" href="https://hisham.hm/htop/" rel="noopener ugc nofollow" target="_blank">htop</a></code>、<code class="fe mk ml mm mn b"><a class="ae ky" href="https://linux.die.net/man/1/iotop" rel="noopener ugc nofollow" target="_blank">iotop</a></code>、<code class="fe mk ml mm mn b"><a class="ae ky" href="https://github.com/Syllo/nvtop" rel="noopener ugc nofollow" target="_blank">nvtop</a></code>、<code class="fe mk ml mm mn b"><a class="ae ky" href="https://pypi.org/project/py-spy/" rel="noopener ugc nofollow" target="_blank">py-spy</a></code>、<code class="fe mk ml mm mn b"><a class="ae ky" href="https://strace.io/" rel="noopener ugc nofollow" target="_blank">strace</a></code>等..应该成为你最好的朋友。您的培训渠道是否受限于CPU？IO绑定？GPU绑定？这些工具将帮助你找到答案。</p><p id="6205" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能甚至没有听说过它们，或者听说过但没有使用过。没关系。如果你没有立即开始使用它们也没关系。请记住，其他人可能会用它们来训练5%-10%-15%的模型..比你更快，这最终可能会决定你是赢得还是失去市场，或者在工作岗位上获得批准还是拒绝。</p><h1 id="59cd" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">数据预处理</h1><p id="514f" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">几乎每个培训渠道都从<code class="fe mk ml mm mn b">Dataset</code>班开始。它负责提供数据样本。任何必要的数据转换和扩充都可以在这里进行。简而言之，<code class="fe mk ml mm mn b">Dataset</code>是一个抽象，它报告其大小，并根据给定索引返回数据样本。</p><p id="806e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您正在处理类似图像的数据(2D、3D扫描)，磁盘I/O可能会成为瓶颈。要获得原始像素数据，您的代码需要从磁盘读取数据，并将图像解码到内存中。每个任务都很快，但是当您需要尽可能快地处理成千上万的任务时，这可能会成为一个挑战。像NVidia Dali这样的库提供了GPU加速的JPEG解码。如果您在数据处理管道中面临IO瓶颈，这绝对值得一试。</p><p id="2662" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有一个选择。SSD磁盘的访问时间约为0.08–0.16毫秒。RAM的访问时间为纳秒。我们可以将数据直接存入内存！</p><blockquote class="lv lw lx"><p id="ce57" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">建议1: <strong class="lb iu">如果可能的话，把你的数据全部或者部分移动到RAM </strong>。</p></blockquote><p id="6926" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有足够的RAM来加载并在内存中保存所有的训练数据，这是从管道中排除最慢的数据检索步骤的最简单方法。</p><p id="22be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个建议对云实例特别有用，比如亚马逊的<code class="fe mk ml mm mn b">p3.8xlarge</code>。这个实例有EBS磁盘，对于默认设置，它的性能非常有限。然而，这个实例配备了惊人的248Gb内存。这足以在内存中保存所有ImageNet数据集！你可以这样做:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="ce63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我亲自面对了这个瓶颈问题。我有一台配备4x1080Ti GPUs的家用PC。有一次，我拿了一个有四个NVidia Tesla V100的<code class="fe mk ml mm mn b">p3.8xlarge</code>实例，并把我的训练代码移到那里。鉴于V100比我的老款1080Ti更新更快，我预计训练速度会提高15-30%。当每个时期的训练时间增加时，我感到很惊讶！这是我的教训，要注意基础设施和环境的细微差别，而不仅仅是CPU和GPU的速度。</p><p id="65d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据您的情况，您可以在RAM中保持每个文件的二进制内容不变，并“即时”解码，或者解压缩图像并保留原始像素。但是无论你选择哪条路，这里有第二条建议:</p><blockquote class="lv lw lx"><p id="8da3" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">忠告二:<strong class="lb iu">简介。测量。比较一下。每次你对渠道进行任何改变时，都要仔细评估它会产生什么样的整体影响。</strong></p></blockquote><p id="0587" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个建议只关注训练速度，假设你没有引入模型、超参数、数据集等的变化..您可以有一个神奇的命令行参数(神奇的开关),当指定时，它将为一些合理数量的数据样本运行训练。有了这一功能，您可以随时快速分析您的管道:</p><pre class="kj kk kl km gt nn mn no np aw nq bi"><span id="bdda" class="nr mp it mn b gy ns nt l nu nv"># Profile CPU bottlenecks<br/>python -m cProfile training_script.py --profiling</span><span id="d4b0" class="nr mp it mn b gy nw nt l nu nv"># Profile GPU bottlenecks<br/>nvprof --print-gpu-trace python train_mnist.py</span><span id="8060" class="nr mp it mn b gy nw nt l nu nv"># Profile system calls bottlenecks<br/>strace -fcT python <!-- -->training_script.py <!-- -->-e trace=open,close,read</span></pre><blockquote class="lv lw lx"><p id="0e49" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">建议3: <strong class="lb iu">离线预处理一切</strong></p></blockquote><p id="1e54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您正在对512x512大小的图像进行训练，这些图像是由2048x2048图片组成的，请事先调整它们的大小。如果您使用灰度图像作为模型的输入，请离线进行颜色转换。如果您正在进行NLP —预先进行标记化并保存到磁盘。在训练中一遍又一遍地重复同样的操作是没有意义的。在渐进式学习的情况下，您可以保存多种分辨率的训练数据，这仍然比在线调整到目标分辨率要快。</p><p id="16b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于表格数据，考虑在<code class="fe mk ml mm mn b">Dataset</code>创建时将<code class="fe mk ml mm mn b">pd.DataFrame</code>对象转换为PyTorch张量。</p><blockquote class="lv lw lx"><p id="cf7e" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">建议4: <strong class="lb iu">调整数据加载器的工作线程数量</strong></p></blockquote><p id="7ef6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PyTorch使用DataLoader类来简化为训练模型而生成批处理的过程。为了加快速度，它可以使用python的多处理并行处理。大多数情况下，它开箱即可正常工作。有几件事要记住:</p><p id="f0c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个进程生成一批数据，这些数据通过互斥同步提供给主进程。如果您有N个工作线程，那么您的脚本将需要N倍多的RAM来在系统内存中存储这些批处理。你到底需要多少内存？<br/>我们来计算一下:</p><ol class=""><li id="4768" class="nx ny it lb b lc ld lf lg li nz lm oa lq ob lu oc od oe of bi translated">假设我们为批量大小为<code class="fe mk ml mm mn b">32</code>的城市风景和大小为<code class="fe mk ml mm mn b">512x512x3 (height, width, channels)</code>的RGB图像训练图像分割模型。我们在CPU端进行图像标准化(稍后我会解释为什么它很重要)。在这种情况下，我们最终的图像张量将是<code class="fe mk ml mm mn b">512 * 512 * 3 * sizeof(float32) = 3,145,728</code>字节。乘以批处理大小，我们得到<code class="fe mk ml mm mn b">100,663,296</code>字节，或者大约100 Mb。</li><li id="7a37" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu oc od oe of bi translated">除了图像，我们还需要提供真实的面具。它们各自的大小是(默认情况下，masks的类型是long，8字节)——<code class="fe mk ml mm mn b"> 512 * 512 * 1 * 8 * 32 = 67,108,864</code>或者大约67 Mb。</li><li id="721f" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu oc od oe of bi translated">因此，一批数据所需的总内存为<code class="fe mk ml mm mn b">167 Mb</code>。如果我们有8个工人，所需的内存总量将是<code class="fe mk ml mm mn b">167 Mb * 8 = 1,336 Mb.</code></li></ol><p id="5e37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">听起来不算太糟，对吧？当您的硬件设置能够处理的批处理数量超过8个工作线程所能提供的数量时，就会出现问题。人们可以天真地放置64个工人，但这至少会消耗将近11 Gb的RAM。</p><p id="835e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你的数据是3D体积扫描，事情会变得更糟；在这种情况下，即使是单通道卷<code class="fe mk ml mm mn b">512x512x512</code>的一个样本也将占用134 Mb，对于批量大小32，它将是4.2 Gb，对于8个工人，您将只需要32 Gb的RAM来在内存中保存中间数据。</p><p id="13c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个问题有一个部分的解决方案，您可以尽可能地减少输入数据的通道深度:</p><ol class=""><li id="2086" class="nx ny it lb b lc ld lf lg li nz lm oa lq ob lu oc od oe of bi translated">将RGB图像保持在每通道8位深度。图像转换为浮点和归一化可以很容易地在GPU上完成。</li><li id="2b98" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu oc od oe of bi translated">在数据集中使用uint8或uint16数据类型，而不是long。</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="3b0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过这样做，您可以大大降低RAM需求。对于上面的例子，内存高效数据表示的内存使用量将是每批33 Mb，而不是167 Mb。那就是5倍还原！当然，这需要模型本身的额外步骤来将数据规范化/转换为适当的数据类型。然而，张量越小，CPU到GPU的传输时间就越快。</p><p id="ba59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">应该明智地选择<code class="fe mk ml mm mn b">DataLoader</code>的工人数量。您应该检查您的CPU和IO系统有多快，您有多少内存，以及GPU处理这些数据的速度有多快。</p><h1 id="7e91" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">多GPU训练和推理</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/061067433811a428e9593a419105c7f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EzTTcFs4W5lyqt9N"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@nanadua11?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Nana Dua </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="db14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经网络模型变得越来越大。如今的趋势是使用多个GPU来增加训练时间。幸运的是，它还经常提高模型的性能，使批量更大。PyTorch拥有在几行代码内实现多GPU的所有特性。然而，有些警告乍一看并不明显。</p><p id="7f6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mk ml mm mn b">model = nn.DataParallel(model) # Runs model on all available GPUs</code></p><p id="b53a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用多GPU最简单的方法是在<code class="fe mk ml mm mn b">nn.DataParallel</code>类中包装一个模型。在大多数情况下，它工作得很好，除非你训练一些图像分割模型(或任何其他产生大尺寸张量作为输出的模型)。在正向传递结束时，<code class="fe mk ml mm mn b">nn.DataParallel</code>将从主GPU上的所有GPU收集输出，以反向运行输出并进行梯度更新。</p><p id="b3df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有两个问题:</p><ul class=""><li id="7804" class="nx ny it lb b lc ld lf lg li nz lm oa lq ob lu om od oe of bi translated">GPU负载不平衡</li><li id="9843" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu om od oe of bi translated">在主GPU上采集需要额外的视频内存。</li></ul><p id="b597" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，只有主GPU在进行损失计算、反向传递和梯度步骤，而其他GPU在60C下等待下一批数据。</p><p id="ce7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其次，在主GPU上收集所有输出所需的额外内存通常会迫使您减少批量大小。事情是这样的，<code class="fe mk ml mm mn b">nn.DataParallel</code>在GPU之间平均分割批处理。假设您有4个GPU，总批量为32。然后，每个GPU将获得其8个样本的块。但问题是，虽然所有非主GPU都可以轻松地将这些批处理放入其相应的VRAM中，但主GPU必须分配额外的空间来容纳来自所有其他卡的输出的32个批处理大小。</p><p id="1c4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这种不均衡的GPU利用率，有两种解决方案:</p><ol class=""><li id="60af" class="nx ny it lb b lc ld lf lg li nz lm oa lq ob lu oc od oe of bi translated">继续使用<code class="fe mk ml mm mn b">nn.DataParallel</code>并在训练中计算向前传球的损失。在这种情况下，您不会将密集预测掩码返回给主GPU，而是只返回一个标量损失。</li><li id="d0f3" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu oc od oe of bi translated">使用分布式训练，又名<code class="fe mk ml mm mn b">nn.DistributedDataParallel</code>。在分布式培训的帮助下，您可以解决上述两个问题，并享受观看所有GPU 100%加载的乐趣。</li></ol><p id="9699" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您知道要了解更多关于多GPU培训的信息，并深入了解每种方法的优缺点，请查看这些精彩的帖子以了解更多信息:</p><ul class=""><li id="ffbc" class="nx ny it lb b lc ld lf lg li nz lm oa lq ob lu om od oe of bi translated"><a class="ae ky" href="https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255" rel="noopener">https://medium . com/hugging face/training-large-batches-practical-tips-on-1-GPU-multi-GPU-distributed-settings-EC 88 C3 e 51255</a></li><li id="212e" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu om od oe of bi translated"><a class="ae ky" href="https://medium.com/@theaccelerators/learn-pytorch-multi-gpu-properly-3eb976c030ee" rel="noopener">https://medium . com/@ the accelerators/learn-py torch-multi-GPU-proper-3eb 976 c 030 ee</a></li><li id="6c85" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu om od oe of bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/how-to-scale-training-on-multiple-gpus-dae1041f49d2">https://towards data science . com/how-to-scale-training-on-multi-GPU-DAE 1041 f 49d 2</a></li></ul><blockquote class="lv lw lx"><p id="17e5" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">建议5: <strong class="lb iu">如果你有2个以上的GPU，考虑使用分布式训练模式</strong></p></blockquote><p id="c523" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它将节省多少时间在很大程度上取决于您的场景，但我观察到，当在4x1080Ti上训练图像分类管道时，时间减少了约20%。</p><p id="9da9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样值得一提的是，您也可以使用<code class="fe mk ml mm mn b">nn.DataParallel</code>和<code class="fe mk ml mm mn b">nn.DistributedDataParallel</code>进行推理。</p><h1 id="8e7c" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">关于自定义损失函数</h1><p id="da28" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">编写自定义损失函数是一项有趣且令人兴奋的工作。推荐大家不定期尝试一下。在用复杂的逻辑实现损失函数时，有一件事你必须记住:它都运行在CUDA上，你有责任编写CUDA高效的代码。CUDA-efficient的意思是“没有python控制流”。在CPU和GPU之间来回切换，访问GPU张量的单个值可能会完成工作，但性能会很糟糕。</p><p id="6ca4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前一段时间，我实现了一个定制的余弦嵌入损失函数，用于实例分割，来自“<a class="ae ky" href="https://www.sciencedirect.com/science/article/pii/S136184151930057X?via%3Dihub" rel="noopener ugc nofollow" target="_blank">使用余弦嵌入和递归沙漏网络分割和跟踪细胞实例</a>”的论文。它的文本形式非常简单，但是实现起来有点复杂。</p><p id="fcc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我写的第一个天真的实现(除了bug)花了几分钟(！)来计算单个批次的损失值。为了分析CUDA瓶颈，PyTorch提供了一个非常方便的内置分析器。它使用起来非常简单，并且为您提供了解决代码瓶颈的所有信息:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><blockquote class="lv lw lx"><p id="5ace" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">建议9: <strong class="lb iu">如果您正在设计定制模块&amp;损耗—剖析&amp;测试它们</strong></p></blockquote><p id="6b4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在对我的初始实现进行概要分析之后，我能够将我的实现速度提高100倍。关于用PyTorch编写高效张量表达式的更多内容将在高效PyTorch —第2部分中解释。</p><h1 id="70a7" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">时间与金钱</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/ecbc2f97f7b66395169b1f9a324ee6bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8m7q9GQv4HiRkaOq"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">帕特里克·福尔在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="f672" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后但同样重要的一点是，有时投资于更强大的硬件比优化代码更有价值。软件优化永远是一个高风险的旅程，有不确定的结果。升级CPU、RAM、GPU或全部一起升级可能更有效。金钱和工程时间都是资源，正确利用二者是成功的关键。</p><blockquote class="lv lw lx"><p id="803a" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">建议10: <strong class="lb iu">一些瓶颈可以通过硬件升级更容易地解决</strong></p></blockquote><h1 id="b259" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">结论</h1><p id="e10c" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">充分利用你的日常工具是精通的关键。试着不要走捷径，如果有些事情你不清楚，一定要深入挖掘。总有机会获得新知识。问问你自己或你的伙伴——“我的代码如何改进？”。我真的相信，对于计算机工程师来说，这种完美感和其他技能一样重要。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><p id="f0ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Eugene是计算机视觉和机器学习工程师，拥有超过10年的软件开发经验。《<a class="ae ky" href="https://www.amazon.com/Mastering-OpenCV-Practical-Computer-Projects/dp/1849517827/ref=sr_1_2?dchild=1&amp;keywords=Mastering+OpenCV+for+practical&amp;qid=1591877326&amp;sr=8-2" rel="noopener ugc nofollow" target="_blank">掌握OpenCV用于实用计算机视觉项目</a>》一书的作者。卡格尔<a class="ae ky" href="https://www.kaggle.com/bloodaxe" rel="noopener ugc nofollow" target="_blank">大师</a>。<a class="ae ky" href="https://github.com/albumentations-team/albumentations" rel="noopener ugc nofollow" target="_blank">白蛋白</a>核心团队成员。《pytorch-toolbelt 的作者。OpenCV、PyTorch和Catalyst贡献者。<a class="ae ky" href="https://www.linkedin.com/in/cvtalks/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/cvtalks/</a></p></div></div>    
</body>
</html>