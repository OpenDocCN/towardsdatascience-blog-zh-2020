<html>
<head>
<title>Building a Sentiment Classifier using Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Scikit-Learn 构建情感分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-sentiment-classifier-using-scikit-learn-54c8e7c5d2f0?source=collection_archive---------6-----------------------#2020-02-07">https://towardsdatascience.com/building-a-sentiment-classifier-using-scikit-learn-54c8e7c5d2f0?source=collection_archive---------6-----------------------#2020-02-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="67ab" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">训练线性模型以将 IMDb 电影评论分类为正面或负面</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/915544deca19d81cab3373dc270b61eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UJNf7hDxFhLaFuiDYRQ4EQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ky">Image by absolute vision @</em><a class="ae kz" href="https://pixabay.com/ro/photos/smiley-emoticon-furie-sup%C4%83rat-2979107/" rel="noopener ugc nofollow" target="_blank"><em class="ky"/></a></p></figure><blockquote class="la lb lc"><p id="8a3b" class="ld le lf lg b lh li ju lj lk ll jx lm ln lo lp lq lr ls lt lu lv lw lx ly lz im bi translated">情感分析是自然语言处理中的一个重要领域，是自动检测文本情感状态的过程。情感分析广泛应用于客户的声音材料，如亚马逊等在线购物网站的产品评论、电影评论或社交媒体。这可能只是一个将文本的极性分类为正/负的基本任务，或者它可以超越极性，查看情绪状态，如“快乐”、“愤怒”等。</p></blockquote><p id="4218" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">在这里，我们将建立一个分类器，能够区分电影评论是正面还是负面的。为此，我们将使用 IMDB 电影评论的<a class="ae kz" href="http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz" rel="noopener ugc nofollow" target="_blank">大型电影评论数据集 v 1.0</a>【2】。该数据集包含 50，000 条电影评论，平均分为 25k 训练和 25k 测试。标签在两个类别(阳性和阴性)之间保持平衡。分数为&lt;= 4/10 的评论被标记为负面，分数为&gt;= 7/10 的评论被标记为正面。中性评论不包括在标记的数据中。该数据集还包含用于无监督学习的未标记评论；我们不会在这里使用它们。对一部特定电影的评论不超过 30 条，因为同一部电影的评级往往是相关的。给定电影的所有评论或者在训练集中或者在测试集中，但是不在两者中，以避免通过记忆电影特定的术语来获得测试准确度。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="0ef7" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">数据预处理</h1><p id="5f66" class="pw-post-body-paragraph ld le it lg b lh nc ju lj lk nd jx lm ma ne lp lq mb nf lt lu mc ng lx ly lz im bi translated">在数据集被下载并从档案中提取出来后，我们必须将其转换为更合适的形式，以便输入到机器学习模型中进行训练。我们首先将所有的审查数据组合成两个 pandas 数据帧，分别代表训练和测试数据集，然后将它们保存为 csv 文件:<em class="lf"> imdb_train.csv </em>和<em class="lf"> imdb_test.csv </em>。</p><p id="cf8f" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">数据帧将具有以下形式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/05024118ad50bc115054e2ca8c343956.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*eEktpQoXFb8mL03QPwcevw.png"/></div></div></figure><p id="8c21" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">其中:</p><ul class=""><li id="96a2" class="ni nj it lg b lh li lk ll ma nk mb nl mc nm lz nn no np nq bi translated">评论 1，评论 2，… =电影评论的实际文本</li><li id="1b87" class="ni nj it lg b lh nr lk ns ma nt mb nu mc nv lz nn no np nq bi translated">0 =负面评价</li><li id="dab0" class="ni nj it lg b lh nr lk ns ma nt mb nu mc nv lz nn no np nq bi translated">1 =正面评价</li></ul><p id="5348" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">但是机器学习算法只能处理数值。我们不能只是将文本本身输入到机器学习模型中，然后让它从中学习。我们必须，以某种方式，用数字或数字向量来表示文本。一种方法是使用<strong class="lg iu">单词袋</strong>模型[3]，其中一段文本(通常称为<strong class="lg iu">文档</strong>)由该文档词汇表中单词计数的向量表示。这个模型没有考虑语法规则或单词排序；它所考虑的只是单词的频率。如果我们独立地使用每个单词的计数，我们将这种表示命名为<strong class="lg iu">单字</strong>。一般来说，在一个<strong class="lg iu"> n-gram </strong>中，我们考虑出现在给定文档中的词汇表中 n 个单词的每个组合的计数。</p><p id="a158" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">例如，考虑这两个文档:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/4af7455447747d758d14bff0de1669ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iPsBH19N9_DW4u_QXc8wFA.png"/></div></div></figure><p id="86c7" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">这两个句子中遇到的所有单词的词汇是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/adf1d1949f3ee89504f4c1af6210d46b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K8af6OLksqCzpjj5JYFbdA.png"/></div></div></figure><p id="4bf4" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">d1 和 d2 的单字表示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/f4947887ae5be50ae4c2acda9e8f83ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MJ6908hSSTAgoVZIbRbjdA.png"/></div></div></figure><p id="6126" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">d1 和 d2 的二元模型是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/5ee1030962b0a0f8ca8bb7ae6deb2f3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RLY811uwYEX_tF_nM6IcBQ.png"/></div></div></figure><p id="8de8" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">通常，如果我们使用所谓的<strong class="lg iu">术语频率乘以逆文档频率</strong>(或<strong class="lg iu"> tf-idf </strong>)来代替字数，我们可以获得稍微好一点的结果。也许听起来很复杂，但事实并非如此。耐心听我说，我会解释的。这背后的直觉是这样的。那么，在文档中只使用术语的频率会有什么问题呢？尽管一些术语在文档中出现的频率很高，但它们可能与描述出现它们的给定文档不太相关。这是因为这些术语也可能在所有文档集合中出现频率很高。例如，电影评论的集合可能具有出现在几乎所有文档中的特定于电影/电影摄影的术语(它们具有高的<strong class="lg iu">文档频率</strong>)。因此，当我们在文档中遇到这些术语时，这并不能说明它是积极的还是消极的评论。我们需要一种方法将<strong class="lg iu">术语频率</strong>(一个术语在文档中出现的频率)与<strong class="lg iu">文档频率</strong>(一个术语在整个文档集合中出现的频率)联系起来。那就是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/30d38a1125fdaeb9939f86fd69667427.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cgnDfkE3HSzmM8arAYs-TA.png"/></div></div></figure><p id="04d1" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">现在，有更多的方法用来描述术语频率和逆文档频率。但最常见的方法是将它们放在对数标度上:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/03ea46a571ba8de70b4965dab1ff2b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*jvmmpLhWGh5mUxo11Zv5Qg.png"/></div></figure><p id="65af" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">其中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/2dc051ce308bad832747e766d29f625c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*7IyNYYGG_kBtX-p4d3xS1g.png"/></div></figure><p id="5ee6" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">我们在第一个对数中添加了 1，以避免在计数为 0 时得到-∞。在第二个对数中，我们添加了一个假文档以避免被零除。</p><p id="1028" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">在我们将数据转换成计数或 tf-idf 值的向量之前，我们应该删除英文的<strong class="lg iu">停用词[ </strong> 6][7]。停用词是在语言中非常常见的词，通常在自然文本相关任务(如情感分析或搜索)的预处理阶段被移除。</p><p id="7497" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">请注意，我们应该只基于训练集来构建我们的词汇表。当我们处理测试数据以进行预测时，我们应该只使用在训练阶段构建的词汇，其余的单词将被忽略。</p><p id="0f34" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">现在，让我们创建数据框并将其保存为 csv 文件:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><h1 id="4c64" class="mk ml it bd mm mn of mp mq mr og mt mu jz oh ka mw kc oi kd my kf oj kg na nb bi translated">文本矢量化</h1><p id="ca46" class="pw-post-body-paragraph ld le it lg b lh nc ju lj lk nd jx lm ma ne lp lq mb nf lt lu mc ng lx ly lz im bi translated">幸运的是，对于文本矢量化部分，所有困难的工作都已经在 Scikit-Learn 类<code class="fe ok ol om on b">CountVectorizer</code>【8】和<code class="fe ok ol om on b">TfidfTransformer</code>【5】中完成了。我们将使用这些类将 csv 文件转换成 unigram 和 bigram 矩阵(使用计数和 tf-idf 值)。(事实证明，如果我们只对大 n 使用 n 元语法，我们不会获得很好的准确性，我们通常使用所有 n 元语法，直到某个 n。因此，当我们在这里说二元语法时，我们实际上是指 uni+二元语法，当我们说 unigrams 时，它只是一元语法。)这些矩阵中的每一行将代表我们数据集中的一个文档(review ),每一列将代表与词汇表中的每个单词相关联的值(在单字的情况下)或与词汇表中最多两个单词的每个组合相关联的值(双字)。</p><p id="2de0" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated"><code class="fe ok ol om on b">CountVectorizer</code>有一个参数<code class="fe ok ol om on b">ngram_range</code>，它需要一个大小为 2 的元组来控制包含什么 n 元语法。在我们构造了一个<code class="fe ok ol om on b">CountVectorizer</code>对象之后，我们应该调用<code class="fe ok ol om on b">.fit()</code>方法，将实际的文本作为参数，以便让它学习我们收集的文档的统计数据。然后，通过对我们的文档集合调用<code class="fe ok ol om on b">.transform()</code>方法，它返回指定的 n-gram 范围的矩阵。正如类名所示，这个矩阵将只包含计数。为了获得 tf-idf 值，应该使用类<code class="fe ok ol om on b">TfidfTransformer</code>。它有<code class="fe ok ol om on b">.fit()</code>和<code class="fe ok ol om on b">.transform()</code>方法，使用方式与<code class="fe ok ol om on b">CountVectorizer</code>类似，但它们将前一步获得的计数矩阵作为输入，而<code class="fe ok ol om on b">.transform()</code>将返回一个带有 tf-idf 值的矩阵。我们应该只在训练数据上使用<code class="fe ok ol om on b">.fit()</code>，然后存储这些对象。当我们想要评估测试分数或者每当我们想要做出预测时，我们应该在将数据输入到我们的分类器之前使用这些对象来转换数据。</p><p id="ed9e" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">请注意，为我们的训练或测试数据生成的矩阵将是巨大的，如果我们将它们存储为普通的 numpy 数组，它们甚至不适合 RAM。但是这些矩阵中的大部分元素都是零。因此，这些 Scikit-Learn 类使用 Scipy 稀疏矩阵[9] ( <code class="fe ok ol om on b">csr_matrix</code> [10]更准确地说)，它只存储非零条目，节省了大量空间。</p><p id="266c" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">我们将使用具有随机梯度下降的线性分类器<code class="fe ok ol om on b">sklearn.linear_model.SGDClassifier</code>【11】作为我们的模型。首先，我们将以 4 种形式生成和保存我们的数据:unigram 和 bigram 矩阵(每个都有计数和 tf-idf 值)。然后，我们将使用带有默认参数的<code class="fe ok ol om on b">SGDClassifier</code>来训练和评估这 4 种数据表示的模型。之后，我们选择导致最佳分数的数据表示，并且我们将使用交叉验证调整具有该数据形式的模型的超参数，以便获得最佳结果。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="fe03" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">选择数据格式</h1><p id="424c" class="pw-post-body-paragraph ld le it lg b lh nc ju lj lk nd jx lm ma ne lp lq mb nf lt lu mc ng lx ly lz im bi translated">现在，对于每个数据表单，我们将其分成训练和验证集，训练 a <code class="fe ok ol om on b">SGDClassifier</code>并输出分数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="c5e4" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">这是我们得到的结果:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="4713" class="os ml it on b gy ot ou l ov ow">Unigram Counts<br/>Train score: 0.99 ; Validation score: 0.87<br/><br/>Unigram Tf-Idf<br/>Train score: 0.95 ; Validation score: 0.89<br/><br/>Bigram Counts<br/>Train score: 1.0 ; Validation score: 0.89<br/><br/>Bigram Tf-Idf<br/>Train score: 0.98 ; Validation score: 0.9</span></pre><p id="6627" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">最好的数据形式似乎是带有 tf-idf 的<strong class="lg iu"> bigram，因为它获得了最高的验证精度:<strong class="lg iu">0.9</strong>；我们接下来将使用它进行超参数调整。</strong></p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="3977" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">使用交叉验证进行超参数调整</h1><p id="0df1" class="pw-post-body-paragraph ld le it lg b lh nc ju lj lk nd jx lm ma ne lp lq mb nf lt lu mc ng lx ly lz im bi translated">对于这一部分，我们将使用<code class="fe ok ol om on b">RandomizedSearchCV</code> [12]，它从我们给出的列表中随机选择参数，或者根据我们从<code class="fe ok ol om on b">scipy.stats</code>指定的分布(例如均匀)；然后，通过进行交叉验证来估计测试误差，在所有迭代之后，我们可以在变量<code class="fe ok ol om on b">best_estimator_</code>、<code class="fe ok ol om on b">best_params_</code>和<code class="fe ok ol om on b">best_score_</code>中找到最佳估计值、最佳参数和最佳得分。</p><p id="89fb" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">因为我们想要测试的参数的搜索空间非常大，并且在找到最佳组合之前可能需要大量的迭代，所以我们将参数集分成两部分，并分两个阶段进行超参数调整过程。首先我们会找到 loss、learning_rate 和 eta0(即初始学习率)的最优组合；然后是惩罚和α。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="9f50" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">我们得到的输出是:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="7e54" class="os ml it on b gy ot ou l ov ow">Best params: {'eta0': 0.008970361272584921, 'learning_rate': 'optimal', 'loss': 'squared_hinge'}<br/>Best score: 0.90564</span></pre><p id="c63c" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">因为我们得到了“learning_rate = optimal”是最好的，那么我们将忽略 eta0(初始学习率)，因为当 learning_rate='optimal '时它没有被使用；我们得到这个值 eta0 仅仅是因为这个过程中的随机性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="25c0" class="os ml it on b gy ot ou l ov ow">Best params: {'alpha': 1.2101013664295101e-05, 'penalty': 'l2'}<br/>Best score: 0.90852</span></pre><p id="8617" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">所以，我得到的最佳参数是:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="c398" class="os ml it on b gy ot ou l ov ow">loss: squared_hinge<br/>learning_rate: optimal<br/>penalty: l2<br/>alpha: 1.2101013664295101e-05</span></pre><h2 id="7fe5" class="os ml it bd mm ox oy dn mq oz pa dp mu ma pb pc mw mb pd pe my mc pf pg na ph bi translated">保存最佳分类器</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="7908" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">测试模型</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="31e6" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">并且得到了<strong class="lg iu"> 90.18% </strong>的测试准确率。这对于我们简单的线性模型来说是不错的。有更先进的方法可以给出更好的结果。该数据集目前的最新水平是<strong class="lg iu"> 97.42% </strong> [13]</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="92e8" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">参考</h1><p id="177c" class="pw-post-body-paragraph ld le it lg b lh nc ju lj lk nd jx lm ma ne lp lq mb nf lt lu mc ng lx ly lz im bi translated">[1] <a class="ae kz" href="https://en.wikipedia.org/wiki/Sentiment_analysis" rel="noopener ugc nofollow" target="_blank">情感分析—维基百科</a><br/>【2】<a class="ae kz" href="http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf" rel="noopener ugc nofollow" target="_blank">用于情感分析的学习词向量</a><br/>【3】<a class="ae kz" href="https://en.wikipedia.org/wiki/Bag-of-words_model" rel="noopener ugc nofollow" target="_blank">词袋模型—维基百科</a><br/>【4】<a class="ae kz" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank">Tf-IDF—维基百科</a><br/>【5】<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html" rel="noopener ugc nofollow" target="_blank">TfidfTransformer—Scikit—学习文档</a><br/>【6】<a class="ae kz" href="https://en.wikipedia.org/wiki/Stop_words" rel="noopener ugc nofollow" target="_blank">停用词—维基百科</a><br/>【7】<a class="ae kz" href="https://gist.github.com/sebleier/554280" rel="noopener ugc nofollow" target="_blank">A </a><a class="ae kz" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix" rel="noopener ugc nofollow" target="_blank">压缩稀疏行矩阵</a><br/>【11】<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html" rel="noopener ugc nofollow" target="_blank">SGD classifier—sci kit—learn 文档</a><br/>【12】<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html" rel="noopener ugc nofollow" target="_blank">RandomizedSearchCV—sci kit—learn 文档</a><br/>【13】<a class="ae kz" href="https://www.aclweb.org/anthology/P19-2057.pdf" rel="noopener ugc nofollow" target="_blank">使用余弦相似度训练的文档嵌入进行情感分类</a></p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><p id="489b" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">朱庇特笔记本可以在<a class="ae kz" href="https://github.com/lazuxd/simple-imdb-sentiment-analysis/blob/master/sentiment-analysis.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="da46" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">我希望这些信息对你有用，感谢你的阅读！</p><p id="fbd7" class="pw-post-body-paragraph ld le it lg b lh li ju lj lk ll jx lm ma lo lp lq mb ls lt lu mc lw lx ly lz im bi translated">这篇文章也贴在我自己的网站<a class="ae kz" href="https://www.nablasquared.com/building-a-sentiment-classifier-using-scikit-learn/" rel="noopener ugc nofollow" target="_blank">这里</a>。随便看看吧！</p></div></div>    
</body>
</html>