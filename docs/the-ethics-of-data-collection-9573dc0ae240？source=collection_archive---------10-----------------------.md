# 数据收集的伦理

> 原文：<https://towardsdatascience.com/the-ethics-of-data-collection-9573dc0ae240?source=collection_archive---------10----------------------->

## 您的数据来源是否符合道德规范？

所以你已经准备好收集一些数据并开始建模，但是你如何确定你的数据来源是合乎道德的呢？

> CW:我将在下面的一节中谈论心理健康和自杀预防。

![](img/14474ec62551450a639d0711bc7da3ff.png)

[吉亚马克·博斯卡罗](https://unsplash.com/@giamboscaro)在 [Unsplash](https://unsplash.com/)

# 当前的数据保护形势

1996 年通过了《健康保险可携带性和责任法案》,简称 HIPAA，以保护医疗后的敏感和识别个人健康数据。目标是一个严格的“需要知道”的医疗数据共享，除非患者签署了特定用途的同意书。为了“共同利益”也有一些例外，包括枪伤和刀伤、与犯罪有关的伤害、可能的虐待案件和传染病。

后来的补充，2013 年的综合最终规则，更新了 HIPAA，包括对违反法律的组织进行更严厉的经济处罚，患者访问电子信息的权利，并将遗传数据纳入 HIPAA 保护区。正如[Weisse](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3954681/)博士指出的，虽然完全控制个人医疗记录的访问是“隐私权倡导者的圣杯”,但我们当前的医疗管理和保险系统使之不可能。

虽然这些法律是必要的，并且在理论上是可行的，但在实践中，它们在医患双方都造成了巨大的混乱。此外，像许多管理新兴技术的立法一样(见面部识别，Siri 总是在听，…)，它对于有效覆盖尚未建立或想象的技术来说是可悲的不足。

最近的欧盟立法《一般数据保护条例》(GDPR)在保护个人数据方面走得更远。关于该法律的效力有很多讨论，但毫无疑问，它是世界上最严格的数据保护法之一。与 HIPAA 或其他美国数据保护法不同，GDPR 要求组织在默认情况下使用最高的隐私设置，并将数据使用限制在六个级别，包括同意、重要利益和法律要求。

此外，在为此目的给予明确同意之前，不得收集任何数据，并且该同意可以随时收回。这意味着一个服务协议条款不能让一家公司无限期地自由支配用户的数据。违反 GDPR 的组织将被处以高额罚款，最高可达 2000 万欧元或上一年总收入的 4%。例如，英国航空公司被罚款 1.83 亿英镑，因为糟糕的安全性导致了针对其 50 万用户的略读攻击。

# 在这些措施不足的地方

## 脸书的自杀算法

2017 年，在一系列直播自杀事件后，脸书在未经同意的情况下开始抓取用户的社交媒体内容**，以建立一个[自杀预防工具](https://www.lexalytics.com/lexablog/ai-healthcare-data-privacy-ethics-issues)。在非自愿收集之外，人们会认为对精神健康、抑郁和自杀意念的评估会被归类为敏感的健康信息，对吗？根据 HIPAA 的说法，因为脸书不是医疗保健组织，所以他们不受该领域法规的约束。**

**这是一个明显的、但在当时可以理解的失误。当 HIPAA 被编写时，只有医疗保健组织可以访问这些个人健康标识符(PHIs)似乎是合理的。随着复杂的人工智能和资源无穷的科技巨头的出现，私人、非医疗保健组织正在试图在没有直接监督的情况下在医疗领域进行创新。**

**让这种影响具体化的是脸书在他们的系统将用户标记为自杀后联系执法部门的 3500 个案例。有一次，执法部门甚至将用户的个人信息发送给了《纽约时报》，这显然侵犯了隐私。**

**欧盟 GDPR 实际上禁止了脸书的收集方法，因为收集精神健康信息需要用户的明确许可。虽然脸书的项目确实有做好事的潜力，但其道德、有效利用的下一步还不明朗。**

## **23andMe 的基因数据**

**监管不力的另一个例子是流行的基因和血统测试公司 23andMe——同样不受 HIPAA 约束——以及他们向制药公司出售用户的基因信息。保险公司使用用户的基因数据在任何症状出现之前识别预先存在的状况存在潜在的风险。这种做法在某些情况下是不合法的，特别是对于健康保险，但对于人寿保险或伤残保险则不是。**

**这种做法已经暴露出一些伦理上的模糊之处。一个例子是亨廷顿氏病，一种由单个缺陷基因控制的迟发性大脑疾病。[美国亨廷顿氏病协会](https://hdsa.org/find-help/healthcare-and-future-planning/genetic-testing-and-your-rights/)有一份关于选择是否进行基因检测的完整指南，因为尽管从技术上来说保险公司利用这一信息是非法的，但这一信息总有被滥用的潜在风险。**

# **未来和你**

**随着技术的不断进步，我们将不可避免地听到更多监管失误的故事。至关重要的是，政府要及时了解新兴创新的影响，以及如何在一个越来越缺乏数据隐私的世界中保护公民的数据隐私。**

**作为一名数据科学家，您必须了解您的数据是如何收集和利用的。[这里有一大堆问题要问你自己和你的模特](https://www.datascience-pm.com/10-data-science-ethics-questions/#:~:text=For%20the%20project%20to%20be,to%20downstream%20users%20that%20data.)。**

**以下是候选名单:**

1.  ****同意**:用户必须明确同意对其个人数据的每一次新的使用。在某些司法管辖区，这是一种法律依赖，但在所有情况下都是一种良好的做法。**
2.  **透明度:特别是在有具体影响的情况下，你能解释一下你的模型和数据处理是如何得出一个决定的吗？**
3.  ****责任**:评估模型的潜在危害，并努力限制所述危害。模型被误解的可能性有多大，善意的还是恶意的？**
4.  ****匿名**:在数据科学过程的各个阶段，如何保护用户的身份信息？在任何时候，谁有权访问这些数据？识别数据甚至需要在数据集中吗？如果没有，请删除它。**
5.  ****偏差**:采取了哪些步骤来理解数据集中的潜在偏差？甚至缺失值也能代表偏见吗？参见[标记](https://en.wikipedia.org/wiki/Redlining)。**

## **来源**

**[1] T. Truyen，W. Luo，D. Phung，S. Gupta，S. Rana 等人，[从医院医疗数据中提取特征并应用于风险预测的框架](https://www.researchgate.net/publication/270291850_A_framework_for_feature_extraction_from_hospital_medical_data_with_applications_in_risk_prediction) (2014)，BMC 生物信息学 15:425–434。**

**[2] D. Wade，[收集和使用医疗保健数据的伦理:主要责任在于相关组织，而不是伦理审查委员会](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1906611/) (2007)，BMJ 334:1330–1331。**

**[3] S. Mann、J. Savulescu 和 B. Sahakian，[《促进健康数据的道德使用以造福社会:电子健康记录、同意和简易救援的责任》](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5124071/) (2016 年)，《皇家学会哲学汇刊》374:1–17。**

**[4] A. Weisse， [HIPAA:一项有缺陷的立法](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3954681/) (2014)，贝勒大学医学中心学报 27(2):163–165。**