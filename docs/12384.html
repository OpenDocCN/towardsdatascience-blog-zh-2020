<html>
<head>
<title>Is Apache Airflow good enough for current data engineering needs?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Airflow 是否足以满足当前的数据工程需求？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/is-apache-airflow-good-enough-for-current-data-engineering-needs-c7019b96277d?source=collection_archive---------4-----------------------#2020-08-26">https://towardsdatascience.com/is-apache-airflow-good-enough-for-current-data-engineering-needs-c7019b96277d?source=collection_archive---------4-----------------------#2020-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="41c9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Apache Airflow 作为 ETL 和数据科学的工作流管理平台的利与弊，以及由此衍生的 Airflow 可能是好选择或坏选择的用例</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/503d1f03b80079ef1406195f923ef5a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6H0JD1-l1uzQVTWR"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">克里斯·利维拉尼在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="04ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di">不久前，如果你问任何数据工程师或数据科学家，他们使用什么工具来编排和调度他们的数据管道，默认的答案可能是 Apache Airflow。尽管气流可以解决许多当前的数据工程问题，但我认为对于一些 ETL &amp;数据科学用例来说，它可能不是最佳选择。</span></p><p id="ead7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将讨论我在过去两年中使用气流的利弊，并从中得出气流仍然是一个很好的选择的用例。我希望在本文结束时，您将能够确定它是否适合您的 ETL &amp;数据科学需求。</p><h1 id="d609" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">气流的优势是什么？</h1><h2 id="1003" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">社区</h2><p id="40b3" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">不可否认，阿帕奇气流有一个惊人的社区。有大量的个人在使用 Airflow 并为这个开源项目做出贡献。如果您想解决一个特定的数据工程问题，那么社区中可能有人已经解决了这个问题，并在线分享了他们的解决方案，甚至将他们的实现贡献给了代码库。</p><h2 id="6a47" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">对气流进行战略押注的公司</h2><p id="1e32" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">许多公司决定投资 Apache Airflow 并支持其发展，其中包括:</p><ul class=""><li id="e460" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">谷歌凭借其云作曲家 GCP 服务，</li><li id="aead" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated"><strong class="lb iu">天文学家</strong>为在 Kubernetes 上部署气流提供企业支持，</li><li id="585e" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated"><strong class="lb iu"> Polidea </strong>拥有许多 PMC 成员，为代码库做出了巨大贡献</li><li id="aaac" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated"><strong class="lb iu"> GoDataDriven </strong>提供阿帕奇气流训练。</li></ul><p id="a924" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">来自这些公司的支持确保有人全职工作来进一步改进软件，从而保证长期的稳定性、支持和培训。</p><h2 id="c844" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">计算机编程语言</h2><p id="4b59" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在 Python 代码中定义工作流的可能性非常有用，因为它允许您将几乎任何自定义工作流逻辑合并到您的编排系统中。</p><h2 id="4da2" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">展开性</h2><p id="12e9" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">气流允许您通过以下方式扩展功能:</p><ul class=""><li id="6f6a" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">使用<a class="ae ky" href="https://airflow.apache.org/docs/stable/plugins.html" rel="noopener ugc nofollow" target="_blank">插件</a>例如。要在 UI 中添加额外的菜单项，</li><li id="4122" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">添加自定义操作符或在现有操作符的基础上构建。</li></ul><h2 id="330f" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">广泛的运营商</h2><p id="7aeb" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">如果你看看 Airflow Github 库中可用的操作符的数量，你会发现 Airflow 支持广泛的<strong class="lb iu">到外部系统</strong>的连接器。这意味着，在许多情况下，您会发现代码模板可以用来与各种数据库、执行引擎和云提供商进行交互，而不必自己实现代码。</p><blockquote class="ob oc od"><p id="c838" class="kz la oe lb b lc ld ju le lf lg jx lh of lj lk ll og ln lo lp oh lr ls lt lu im bi translated"><em class="it">外部系统的连接器数量表明，气流可以用作“粘合剂”，将来自许多不同来源的数据结合在一起。</em></p></blockquote></div><div class="ab cl oi oj hx ok" role="separator"><span class="ol bw bk om on oo"/><span class="ol bw bk om on oo"/><span class="ol bw bk om on"/></div><div class="im in io ip iq"><h1 id="3050" class="me mf it bd mg mh op mj mk ml oq mn mo jz or ka mq kc os kd ms kf ot kg mu mv bi translated">气流的弱点是什么？</h1><p id="7290" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">从上面列出的优势列表中，您可以看到，总的来说，从将许多外部系统捆绑在一起的角度来看，Airflow 是数据工程<strong class="lb iu">的一个<strong class="lb iu">伟大产品</strong>。社区投入了大量的工作来构建广泛的特性和连接器。然而，它有几个弱点阻止我真正喜欢使用它。其中一些问题可能会在未来的版本中得到解决，所以我在撰写本文时讨论这些问题。</strong></p><h2 id="9988" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">数据管道没有版本控制</h2><p id="0db1" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">如今，当我们有了版本控制系统和存储在 Docker 注册表中的不同版本的 Docker 映像时，我们认为版本化是理所当然的——这是一个应该存在的基本功能，毫无疑问。但是，气流还是没有。如果您从 DAG 代码中删除一个任务并重新部署它，您将<strong class="lb iu">丢失与该任务相关的元数据</strong>。</p><h2 id="223c" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">对新用户来说不直观</h2><p id="4655" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">我用了足够长的时间来理解它的内部结构，甚至通过编写定制组件来扩展它的功能。然而，<strong class="lb iu">向一组以前从未使用过 Airflow 的数据工程师</strong>教授如何使用它<strong class="lb iu">被证明是耗时的</strong>，因为人们需要学习一种全新的“语法”。一些数据工程师认为整个体验<strong class="lb iu">不直观</strong>。</p><p id="6211" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个突出的例子与<strong class="lb iu">的调度</strong>有关:许多人(包括在内的<em class="oe">我)发现，Airflow 在调度间隔的<em class="oe">结束</em>时开始调度任务，这非常令人困惑。这意味着调度间隔不会立即开始，而是仅在<code class="fe ou ov ow ox b">execution_date</code>达到<code class="fe ou ov ow ox b">start_date</code> + <code class="fe ou ov ow ox b">schedule_interval</code>时开始。这似乎适用于每晚只运行一次的批处理 ETL 作业，但是对于每 10 分钟运行一次的作业，当不熟悉该工具的新用户使用它时，它会相当混乱，并且可能导致意外的错误，特别是如果没有正确使用<em class="oe"> catchup </em>选项的话。</em></p><h2 id="390a" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">从一开始就配置过载+难以在本地使用</h2><p id="d70f" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">为了在本地计算机上开始使用 Airflow，不熟悉该工具的数据专业人员需要学习:</p><ul class=""><li id="7eea" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">内置于产品中的<strong class="lb iu">调度逻辑</strong><strong class="lb iu">——比如提到的与开始日期、执行日期、调度间隔、赶上进度相关的细微差别</strong></li><li id="be77" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">一整套<strong class="lb iu">概念和配置细节— </strong>操作符与任务、执行器、Dag、默认参数、airflow.cfg、airflow 元数据 DB、部署 Dag 的主目录等等)。</li></ul><p id="c121" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另外，如果你是一个<strong class="lb iu"> Windows 用户</strong>，你真的<strong class="lb iu">不能在本地使用这个工具</strong>，除非你使用 docker-compose 文件，这些文件甚至不是官方 Airflow 库的一部分——许多人使用<a class="ae ky" href="https://github.com/puckel/docker-airflow" rel="noopener ugc nofollow" target="_blank"> puckel/docker-airflow </a>设置。这都是可行的，但我希望它会更直观，更容易为新用户。</p><p id="47ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我知道 Airflow 在过去的几个月里发布了一个官方的 docker 映像，但仍然缺少一个官方的<code class="fe ou ov ow ox b">docker-compose</code>文件，新用户(<em class="oe">特别是 Windows 用户</em>)可以在其中获得完整的基本设置，以及一个元数据数据库容器和一个绑定挂载，以便将他们的 Dag 复制到容器中。一个官方的<code class="fe ou ov ow ox b">docker-compose</code>文件对于能够在 Windows 上本地运行 Airflow 非常有帮助。</p><p id="3398" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你使用天文学家付费版本的气流，你可以使用<a class="ae ky" href="https://github.com/astronomer/astro-cli" rel="noopener ugc nofollow" target="_blank"> astro CLI </a>，这在一定程度上缓解了局部测试的问题。</p><h2 id="4def" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">为生产设置气流架构并不容易</h2><p id="e67f" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">为了获得生产就绪的设置，您实际上有两种选择:</p><ol class=""><li id="9577" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu oy nt nu nv bi translated"><strong class="lb iu"> Celery Executor: </strong>如果您选择这个选项，您需要了解 Celery 如何工作+您需要熟悉 RabbitMQ 或 Redis 作为您的消息代理，以便设置和维护可以执行您的气流管道的工作队列。据我所知，没有直接来自 Airflow 的官方教程或部署方法来使这一扩展过程对用户来说更容易。我个人是从<a class="ae ky" href="https://www.cloudwalker.io/2019/09/30/airflow-scale-out-with-redis-and-celery/" rel="noopener ugc nofollow" target="_blank">这篇博客文章</a>中学到的。)。总的来说，我希望这个设置对用户来说更容易，或者至少 Airflow 会提供一些关于如何正确设置的官方文档。</li><li id="dde6" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu oy nt nu nv bi translated"><strong class="lb iu"> Kubernetes Executor: </strong>与芹菜相比，这个 Executor 相对较新，但是它允许您利用 Kubernetes 的力量自动缩放您的工人(<em class="oe">甚至减少到零！</em>)并以健壮的方式管理所有 Python 包的依赖关系，因为所有东西都必须被容器化才能在 Kubernetes 上工作。然而，在这方面，我也没有在官方文档中找到关于如何正确设置和维护它的支持。</li></ol><p id="2473" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在为我工作的公司在 AWS 上设置气流的经验是，你可以:</p><ul class=""><li id="26a2" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">雇佣一些外部顾问为你做这件事</li><li id="99e8" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">从谷歌(<em class="oe"> Cloud Composer </em>)或天文学家. io 获得一个<strong class="lb iu">付费版本</strong></li><li id="a47b" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">或者你可以<strong class="lb iu">试错</strong>，交叉手指希望它不会断。</li></ul><p id="29b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">总体而言，Airflow 的架构包括许多组件，例如:</strong></p><ul class=""><li id="b191" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">调度程序，</li><li id="f340" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">网络服务器，</li><li id="adcc" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">元数据数据库，</li><li id="ed08" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">工作节点，</li><li id="1eed" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">遗嘱执行人，</li><li id="ff23" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">消息经纪人+芹菜+花如果选择芹菜执行者，</li><li id="ad8b" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">可能是一些共享卷，例如 AWS EFS，用于工作节点之间的公共 DAGs 存储，</li><li id="c597" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">正确设置<code class="fe ou ov ow ox b">airflow.cfg</code>中的值</li><li id="5b7e" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">配置日志存储。S3 +理想的一些生命周期策略，通常情况下，你不需要查看非常旧的日志和支付存储费用</li><li id="8a6e" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">为用户界面注册域</li><li id="257f" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">添加一些<strong class="lb iu">监控</strong>来防止您的元数据数据库和工作节点超出它们的计算能力和存储</li><li id="75d8" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">为 UI +数据库用户管理添加一些<strong class="lb iu"> Auth 层</strong>用于访问元数据数据库。</li></ul><blockquote class="ob oc od"><p id="7a68" class="kz la oe lb b lc ld ju le lf lg jx lh of lj lk ll og ln lo lp oh lr ls lt lu im bi translated"><em class="it">这些是</em> <strong class="lb iu"> <em class="it">许多组件来维护</em> </strong> <em class="it">和</em> <strong class="lb iu"> <em class="it">以确保它们都很好地一起工作，</em> </strong> <em class="it">而且似乎开源版本的 Airflow 并没有让这个设置对用户来说很容易。</em></p></blockquote><p id="32c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从我到目前为止的经验来看，如果你想在生产中使用 Airflow(<em class="oe">特别是如果你使用 AWS 或 Azure 而不是 GCP </em>)，选择<a class="ae ky" href="https://www.astronomer.io/" rel="noopener ugc nofollow" target="_blank">天文学家</a>似乎是最简单的选择，因为你在上面添加了许多功能，例如监控你的节点、将日志拉到一个中心位置、授权层(<em class="oe">和与活动目录的集成</em>)、支持、SLA 和天文学家团队将至少维护上面列出的一些组件。</p><h2 id="50d7" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">任务之间缺乏数据共享鼓励了非原子任务</h2><p id="9478" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">目前，除了使用 XComs 之外，还没有自然的“Pythonic 式”方法在 Airflow 中的任务之间共享数据，XComs 被设计为仅共享少量元数据(<em class="oe">路线图中有计划引入功能性 Dag，因此数据共享在未来可能会以某种方式变得更好</em>)。</p><p id="cedc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">任务意味着数据管道中基本的<em class="oe">原子</em>工作单元。因为在气流中的任务之间没有<strong class="lb iu">共享数据的简单方法，而不是任务是<em class="oe">原子的</em>，即只负责一件事情(<em class="oe">例如。仅提取数据</em>，人们通常倾向于使用整个脚本作为<em class="oe">任务</em>，例如一个脚本执行整个 ETL ( <em class="oe">由 BashOprator ex 触发。" python stage _ AdWords _ ETL . py "</em>)，这反过来使得维护更加困难，因为您需要调试整个脚本(<em class="oe">完整 ETL </em>)，而不是一个小的原子任务(<em class="oe">例如。仅“提取”部分</em>)。</strong></p><blockquote class="ob oc od"><p id="45c9" class="kz la oe lb b lc ld ju le lf lg jx lh of lj lk ll og ln lo lp oh lr ls lt lu im bi translated">如果你的任务是<strong class="lb iu">而不是</strong>原子的，当它失败时，你不能仅仅重试 ETL 的<strong class="lb iu">加载</strong>部分——你需要重试<strong class="lb iu">整个 ETL </strong>。</p></blockquote><h2 id="741e" class="mw mf it bd mg mx my dn mk mz na dp mo li nb nc mq lm nd ne ms lq nf ng mu nh bi translated">调度程序成为瓶颈</h2><p id="0429" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">如果你以前使用过 Airflow，你可能已经经历过在 UI 中点击<em class="oe"> Trigger DAG </em>按钮后，你需要等待相当长的时间才能看到任务真正开始运行。</p><p id="3ab3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">调度器通常需要几分钟才能调度任务，并由工作进程执行，至少今年早些时候我使用部署在 EC2 上的 Airflow 时是这样。Airflow 的社区正在致力于改进调度程序，所以我希望它在下一个版本中会有更高的性能，但是在撰写本文时，这个瓶颈阻止了将 Airflow 应用到延迟不可接受或不可取的用例中。</p></div><div class="ab cl oi oj hx ok" role="separator"><span class="ol bw bk om on oo"/><span class="ol bw bk om on oo"/><span class="ol bw bk om on"/></div><div class="im in io ip iq"><h1 id="856a" class="me mf it bd mg mh op mj mk ml oq mn mo jz or ka mq kc os kd ms kf ot kg mu mv bi translated">气流仍然是一个好选择的使用案例</h1><p id="b319" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在本文中，我多次强调，当 Airflow 只需要调度以下任务时，它就能很好地工作:</p><ul class=""><li id="2a04" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">运行在 Spark、Hadoop、Druid 等外部系统上，或者 AWS Sagemaker、AWS ECS 或 AWS Batch 等一些外部云服务上，</li><li id="d17f" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">向某个内存数据库提交 SQL 代码。</li></ul><blockquote class="ob oc od"><p id="4e8f" class="kz la oe lb b lc ld ju le lf lg jx lh of lj lk ll og ln lo lp oh lr ls lt lu im bi translated"><em class="it"> Airflow 被</em> <strong class="lb iu"> <em class="it">设计成</em> </strong> <em class="it">不直接在 Airflow 内部执行任何工作流，而只是对它们进行调度，并让</em> <strong class="lb iu">保持在外部系统</strong> <em class="it">内执行。</em></p></blockquote><p id="fcbf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着，如果您的任务是提交 Spark 作业并将数据存储在 Hadoop 集群上，或者在 Snowflake 中执行一些 SQL 转换，或者触发 SageMaker 培训作业，那么 Airflow 仍然是一个不错的选择。</p><p id="9ed6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">举个例子:想象一家公司，数据工程师在 Pentaho 数据集成中创建 ETL 作业，他们使用<code class="fe ou ov ow ox b">CeleryExecutor</code>在 AWS EC2 实例上编排<code class="fe ou ov ow ox b">BashOperator</code>任务。那些任务<em class="oe">没有被停靠</em>，任务只是调度<strong class="lb iu">一个 bash 命令在一个特定的服务器上运行</strong>。气流在这个用例中运行良好。</p><p id="a960" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您在工作流系统中需要做的只是向外部系统提交一些 bash 命令，并且您实际的<strong class="lb iu">数据流</strong>是在 Spark、SageMaker 中定义的，或者如上面的例子，在 Pentaho 数据集成中，Airflow 应该非常适合您，因为<strong class="lb iu">数据依赖关系</strong>是由那些外部系统管理的，而 Airflow 只需要管理任务之间的<strong class="lb iu">状态依赖关系</strong>。如果您使用一些内存数据库，如雪花、Exasol 或 SAP Hana，<em class="oe">实际工作在这些数据库中执行</em>，您的工作流编排系统只需向其提交查询即可。</p><h1 id="c283" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">气流不是好选择的使用案例</h1><blockquote class="ob oc od"><p id="2a35" class="kz la oe lb b lc ld ju le lf lg jx lh of lj lk ll og ln lo lp oh lr ls lt lu im bi translated"><em class="it">如果您希望您的</em> <strong class="lb iu"> <em class="it">工作流系统</em> </strong> <em class="it">与您的</em> <strong class="lb iu"> <em class="it">执行层</em> </strong> <em class="it">紧密合作，并且能够在 Python 代码内的任务之间传递数据，那么在这种情况下，气流可能不是最好的选择。</em></p></blockquote><p id="3865" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Airflow 只能通过 XComs 传递任务之间的<strong class="lb iu">状态依赖</strong>(<em class="oe">加上可能的一些元数据)，而不能传递<strong class="lb iu">数据依赖</strong>。这意味着，如果您主要用 Python 构建工作流，并且您有许多数据科学用例，这些用例本质上严重依赖于任务间的数据共享，那么其他工具，如<a class="ae ky" href="https://www.prefect.io/" rel="noopener ugc nofollow" target="_blank"> Prefect </a>会更适合您。</em></p><p id="468f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这些使用案例中，Prefect 是比 Airflow 更好的选择:</p><ul class=""><li id="01a3" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">如果需要在任务间<strong class="lb iu">共享数据</strong></li><li id="cae3" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">如果您需要对数据管道进行版本控制，那么 Airflow 不支持这一点</li><li id="1ad0" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">如果你想用 Dask 对你的 Python 代码进行<strong class="lb iu">并行化，提督支持<a class="ae ky" href="http://distributed.dask.org/en/latest/" rel="noopener ugc nofollow" target="_blank"> Dask 分布式</a>开箱即用</strong></li><li id="99b2" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">如果需要运行<strong class="lb iu">动态参数化数据管道</strong></li><li id="74ec" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">如果 Airflow 的<strong class="lb iu">调度器延迟</strong>不为您的工作负载所接受，</li><li id="4165" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">如果您想在<strong class="lb iu">本地测试工作流代码时获得无缝体验</strong></li><li id="bc9a" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">最后，如果你喜欢一个<strong class="lb iu">更容易和更灵活的执行层</strong>而不是维护前面提到的所有气流组件，你可以选择完美云。您可以在本文中找到一种可能的设置方法:</li></ul><div class="oz pa gp gr pb pc"><a rel="noopener follow" target="_blank" href="/distributed-data-pipelines-made-easy-with-aws-eks-and-prefect-106984923b30"><div class="pd ab fo"><div class="pe ab pf cl cj pg"><h2 class="bd iu gy z fp ph fr fs pi fu fw is bi translated">AWS EKS 和提督使分布式数据管道变得简单</h2><div class="pj l"><h3 class="bd b gy z fp ph fr fs pi fu fw dk translated">如何在几分钟内建立一个分布式云工作流程编排系统，并专注于提供价值，而不是…</h3></div><div class="pk l"><p class="bd b dl z fp ph fr fs pi fu fw dk translated">towardsdatascience.com</p></div></div><div class="pl l"><div class="pm l pn po pp pl pq ks pc"/></div></div></a></div></div><div class="ab cl oi oj hx ok" role="separator"><span class="ol bw bk om on oo"/><span class="ol bw bk om on oo"/><span class="ol bw bk om on"/></div><div class="im in io ip iq"><h1 id="cca4" class="me mf it bd mg mh op mj mk ml oq mn mo jz or ka mq kc os kd ms kf ot kg mu mv bi translated">结论</h1><p id="763e" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在本文中，我们讨论了 Apache Airflow 作为 ETL 和数据科学的工作流编排解决方案的优缺点。在分析了它的优势和劣势之后，我们可以推断，只要它用于其设计目的，即仅编排在 Apache Spark、Hadoop、Druid、云服务等外部系统上执行的工作，或者在向 Snowflake、Exasol 或 Redshift 等高性能分布式数据库提交 SQL 代码时，它就是一个不错的选择。</p><p id="1849" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，air flow<strong class="lb iu">并不是为直接执行您的数据管道<em class="oe"/></strong>而设计的，所以如果您的 ETL &amp;数据科学代码需要在任务之间传递数据，需要动态和参数化，需要并行运行，或者需要更灵活和低延迟的调度程序，那么您可能会更喜欢其他工具，如 Prefect。</p><p id="64ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读！</p></div></div>    
</body>
</html>