# 如何为机器学习模型准备数据

> 原文：<https://towardsdatascience.com/how-to-prepare-your-data-for-your-machine-learning-model-b4c9fd4e7ea?source=collection_archive---------18----------------------->

## 数据准备分步指南

![](img/69c660379a02398c5323abd0d0dc1379.png)

由故事创建的数据向量—[www.freepik.com](http://www.freepik.com)

# 目录

1.  介绍
2.  什么是数据准备
3.  探索性数据分析
4.  数据预处理
5.  数据分割

# 介绍

在我们进入这个话题之前，我想澄清一点，数据准备没有严格的流程。准备一组数据的方式很可能与准备另一组数据的方式不同。因此，本指南旨在提供一个总体指南，供您在准备任何特定数据集时参考。

在我们进入指南之前，我应该先回顾一下什么是数据准备…

# 什么是数据准备？

数据准备是机器学习生命周期中数据收集之后的步骤，它是清理和转换您收集的原始数据的过程。通过这样做，在对数据进行分析和建模时，您会轻松得多。

我将在本文中介绍数据准备的三个主要部分:

1.  探索性数据分析
2.  数据预处理
3.  数据分割

# 1.探索性数据分析

探索性数据分析，简称 EDA，听起来就是探索你的数据。在这一步中，您只是简单地了解您正在处理的数据。在现实世界中，数据集不像 Kaggle 数据集那样干净或直观。

您对正在处理的数据探索和理解得越多，数据预处理就越容易。

以下是您在此步骤中应该考虑的事项列表:

## 特征和目标变量

确定什么是特征(输入)变量，什么是目标变量。不要担心确定什么是**最终**输入变量，但要确保你能识别这两种类型的变量。

## 数据类型

弄清楚你在处理什么类型的数据。它们是绝对的，数字的，还是都不是？这对于目标变量尤其重要，因为数据类型将缩小您可能想要使用的机器学习模型的范围。像 **df.describe()** 和 **df.dtypes** 这样的熊猫函数在这里很有用。

## 检查异常值

一个**异常值**是一个明显不同于其他观察值的数据点。在这一步中，您需要识别异常值，并尝试理解它们出现在数据中的原因。根据它们出现在数据中的原因，您可以决定将其从数据集中移除或保留。有几种方法可以识别异常值:

1.  **Z 值/标准偏差**:如果我们知道一个数据集中 99.7%的数据位于三个标准偏差之内，那么我们可以计算一个标准偏差的大小，乘以 3，并确定超出该范围的数据点。同样，我们可以计算给定点的 z 分数，如果它等于+/- 3，那么它就是异常值。*注意:使用这种方法时需要考虑一些意外情况；数据必须是正态分布的，这不适用于小数据集，并且太多异常值的存在会影响 z 值。*
2.  **四分位距(IQR)** : IQR，用于构建箱线图的概念，也可用于识别异常值。IQR 等于第三个四分位数和第一个四分位数之差。然后，如果一个点小于 Q1-1.5 * IRQ 或大于 Q3 + 1.5*IQR，则可以确定该点是否为异常值。这达到大约 2.698 个标准偏差。

## 提问

毫无疑问，你很可能会对你正在处理的数据有疑问，**尤其是**对于你领域知识之外的数据集。例如，Kaggle 有一个关于 NFL 分析和伤病的比赛，我必须做一些研究，了解不同的位置是什么，以及他们的功能对团队有什么作用。

# 2.数据预处理

一旦您理解了您的数据，作为一名数据科学家，您的大部分时间都花在这一步上，即数据预处理。这是你花时间操纵数据，以便它可以被正确建模的时候。就像我之前说的，没有通用的方法来解决这个问题。然而，有一些重要的事情你应该考虑，我们将在下面讨论。

## 特征插补

特征插补是填补缺失值的过程。这很重要，因为当数据集中有缺失数据时，大多数机器学习模型都不起作用。

我想写这个指南的主要原因之一就是为了这个步骤。许多文章说你应该默认用平均值填充缺失值或者简单地删除行，而**这不一定是真的**。

理想情况下，您希望选择最有意义的方法—例如，如果您正在对人们的年龄和收入进行建模，那么一个 14 岁的孩子获得全国平均工资就没有意义。

总的来说，有几种方法可以处理缺失值:

*   **单值插补**:用列的平均值、中值或众数替换缺失值
*   **多值插补:**对有缺失数据的要素进行建模，并用模型发现的内容输入缺失数据。
*   **K-最近邻:**用另一个相似样本的值填充数据
*   **删除该行:**这不是一种插补技术，但当样本量非常大时，如果你能负担得起，这种方法也是可行的。
*   其他包括:随机插补、移动窗口、最频繁等…

## 特征编码

特征编码是将值(即字符串)转化为数字的过程。这是因为机器学习模型要求所有值都是数字。

有几种方法可以解决这个问题:

1.  **标签编码:**标签编码只是将一个特征的非数值转换成数值，不管这个特征是不是序数。例如，如果名为 car_colour 的要素具有红色、绿色和蓝色的不同值，那么标注编码会将这些值分别转换为 1、2 和 3。使用这种方法时要小心，因为虽然有些 ML 模型能够理解编码，但有些却不能。
2.  **一热编码(又名。get_dummies):** 一种热编码的工作原理是为给定特征的每个非数值创建一个二进制特征(1，0)。再次使用上面的例子，如果我们有一个名为 car_colour 的特征，那么一个热编码将创建三个名为 car_colour_red、car_colour_green、car_colour_blue 的特征，并且将有一个 1 或 0 来指示它是否存在。

## 特征标准化

当数值处于不同的尺度时，例如，以厘米为单位的身高和以磅为单位的体重，大多数机器学习算法都表现不佳。k-最近邻算法是不同比例的要素不能很好工作的主要例子。因此，规范化或标准化数据有助于解决这个问题。

*   **特征标准化**重新调整数值，使其在[0，1]/的范围内
*   **特征标准化**重新调整数据，使平均值为 0，标准差为 1。

## 特征工程

特征工程是将原始数据转化为更好地代表人们试图解决的潜在问题的特征的过程。这一步没有具体的方法，但你可以考虑以下几点:

*   转换日期时间变量以仅提取星期几、月份等…
*   为变量创建容器或桶。(例如，对于高度变量，可以有 100-149 厘米、150-199 厘米、200-249 厘米等。)
*   组合多个要素和/或值以创建一个新要素和/或值。例如，泰坦尼克号挑战最准确的模型之一设计了一个新的变量，称为“是女人还是孩子”，如果这个人是女人或孩子，这个变量为真，否则为假。

## 特征选择

接下来是要素选择，即选择数据集最相关/最有价值的要素。我喜欢使用一些方法来帮助您选择功能:

*   **特性重要性:**像 random forests 或 XGBoost 这样的算法允许您确定哪些特性在预测目标变量的值时是最“重要”的。通过快速创建其中一个模型并进行特征重要性分析，您将了解哪些变量比其他变量更有用。
*   **降维**:最常见的降维技术之一，主成分分析(PCA)取大量特征，利用线性代数将其降维为较少的特征。

## 处理数据失衡

你要考虑的另一件事是数据不平衡。例如，如果一个类别有 5，000 个示例(例如，非欺诈性的)，但另一个类别只有 50 个示例(例如，欺诈性的)，那么您需要考虑以下几件事情之一:

*   收集更多的数据——这总是对你有利的，但是通常是不可能的或者太贵了。
*   您可以使用 scikit-learn-contrib Python 包对数据进行过采样或欠采样。

# 3.数据分割

最后是分割你的数据。我将给出一个非常通用的框架，你可以在这里使用，这是普遍同意的。

通常，您会希望将数据分成三组:

1.  **训练集**(70–80%):这是模型学习的内容
2.  **验证集**(10–15%):模型的超参数在这个集上进行调整
3.  **测试集**(10–15%):最后，在此基础上评估模型的最终性能。如果你已经准备好了正确的数据，测试集**的结果应该**给出一个模型在真实世界中表现的很好的指示。

# 感谢阅读！

我希望你已经从中学到了一些东西。通过阅读本文，您现在应该对数据准备有了一个大致的了解。需要考虑的事情很多，但是有这样的资源提醒你总是有帮助的。

如果您遵循这些步骤并牢记这些事情，您一定会更好地准备您的数据，并且您最终能够开发一个更准确的模型！

## 特伦斯·申

*   *查看* [*我的免费数据科学资源*](https://docs.google.com/document/d/1UV6pvCi9du37cYAcKNtuj-2rkCfbt7kBJieYhSRuwHw/edit#heading=h.m63uwvt9w358) *每周都有新资料！*
*   *如果你喜欢这个，* [*跟我上媒*](https://medium.com/@terenceshin) *了解更多*
*   *我们连线上*[*LinkedIn*](https://www.linkedin.com/in/terenceshin/)