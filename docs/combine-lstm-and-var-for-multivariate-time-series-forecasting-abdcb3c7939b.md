# 多元时间序列预测的 LSTM 和 VAR 组合方法

> 原文：<https://towardsdatascience.com/combine-lstm-and-var-for-multivariate-time-series-forecasting-abdcb3c7939b?source=collection_archive---------3----------------------->

## 多步训练过程在时间序列预测领域的应用

![](img/306b83c72f8b106561cacd07bc51b872.png)

照片由 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的[尼克·费因斯](https://unsplash.com/@jannerboy62?utm_source=medium&utm_medium=referral)拍摄

在经典的时间序列预测任务中，建模时的第一个标准决策涉及采用统计方法或其他纯机器学习模型，包括基于树的算法或深度学习技术。这种选择与我们正在解决的问题密切相关，但总的来说:当我们面临一个自回归问题，而未来只与过去相关时，统计技术就足够了；而机器学习模型适用于更复杂的情况，也可以组合多样化的数据源。

在这篇文章中，我试图将统计方法从经验中学习的能力与深度学习技术的推广相结合。我们的任务是一个多变量时间序列预测问题，所以我们使用 ARIMA 的多变量扩展，称为 VAR，和一个简单的 LSTM 结构。我们不生产一个集合模型；我们使用 VAR 的能力来过滤和研究历史，并在预测未来时为我们的神经网络提供益处。

我们的工作流程可以总结如下:

*   根据我们的训练数据正确估计 VAR
*   提取 VAR 学到的知识，并将其用于改进执行两步培训的 LSTM 模型的培训流程。

我们会发现我们的结果并不明显，因为按照这个步骤，我们必须与灾难性遗忘的问题作斗争。

# 数据

我们实验的[数据](https://archive.ics.uci.edu/ml/datasets/Air+Quality)包含嵌入在空气质量多传感器设备中的金属氧化物化学传感器的每小时平均响应，该设备位于意大利城市污染严重地区的场地*。*记录了一年的数据，包括一氧化碳、非后生碳氢化合物、苯、总氮氧化物(NOx)和二氧化氮(NO2)的实际小时平均浓度。此外，还提供了外部变量，如天气状况。存在大量 nan，因此在继续之前需要进行线性插值(排除训练数据中 nan 超过 50%的序列)。

![](img/5bf7ff190a947a6609b7f495a9d0a1cc.png)

由我们支配的时间序列的例子(图片由作者提供)

# VAR 建模

对于 ARIMA，我们使用每个变量的过去值来预测未来。当我们有多个时间序列可供支配时，我们也可以从它们的关系中提取信息，这样 VAR 就是 ARIMA 的多元推广，因为它理解并使用几个输入之间的关系。这有助于描述数据的动态行为，并提供更好的预测结果。

要正确开发风险值模型，必须满足拟合 ARIMA 时遇到的相同经典假设。我们需要给予平稳性并利用自相关行为。这些先决条件使我们能够开发一个稳定的模型。我们所有的时间序列平均都是平稳的，显示出每日和每周的模式。

![](img/b59b49ff1823a6f32e7ccef56ede9123.png)

我们所掌握的一些时间序列的自相关例子(图片由作者提供)

在这些初步检查之后，我们准备好拟合我们的 VAR。最佳滞后阶数的选择是根据 AIC/BIC 准则自动进行的。我们用 AIC 来操作选择:我们需要做的就是递归拟合我们的模型，改变滞后阶数，并标注 AIC 分数(*越低越好*)。可以仅考虑我们的列车数据来执行该过程。在我们的例子中，27 是最好的延迟顺序。

![](img/2a788923441b2f6f4b2c522474700b09.png)

用 AIC 方法进行 VAR 滞后阶数选择(图片由作者提供)

# 将 VAR 和 LSTM 结合起来

现在我们的范围是使用我们拟合的 VAR 来改善我们神经网络的训练。VAR 已经了解了我们的多变量数据源的内部行为，调整了疯狂的值，纠正了异常的趋势，并正确地重建了 NaNs。所有这些信息都存储在拟合值中，它们是模型在训练过程中处理过的原始数据的平滑版本。换句话说，我们可以将这些值视为原始列车的一种增强数据源。

我们的策略包括应用两步训练程序。我们使用 VAR 产生的拟合值，开始为我们的 LSTM 自动编码器提供数据，用于我们处理的所有序列的多步预测(多变量输出)。然后，我们用原始数据结束训练，在我们的情况下，它们是我们之前用来拟合 VAR 的相同数据。通过我们的神经网络，我们还可以结合外部数据源，例如，天气状况或一些时间属性，如我们循环编码的工作日、小时和月。

我们希望我们的神经网络可以从两个不同但相似的数据源中学习，并在我们的测试数据上表现得更好。我们的方法听起来很棒，但这不是“免费的午餐”。在进行多步训练时，我们必须注意 [**灾难性遗忘**](https://arxiv.org/pdf/1312.6211.pdf) 的问题。*灾难性遗忘是很多模型和算法面临的问题。当在一个任务上训练，然后在第二个任务上训练时，许多机器学习模型“忘记”如何执行第一个任务。这被广泛认为是神经网络的一个严重问题。*

为了避免这个繁琐的问题，整个网络的结构必须进行适当的调整，以提供性能方面的好处。根据这些观察，我们保留了之前培训的最后一部分作为验证。

从技术上讲，网络非常简单。它由一个 seq2seq LSTM 自动编码器构成，可以提前 N 步预测未来可用的传感器。使用[**keras-hype tune**](https://github.com/cerlymarco/keras-hypetune)**执行训练程序。**该框架以非常直观的方式提供了神经网络结构的**超参数优化**。对所有三个涉及的训练(对 VAR 拟合值的拟合、对原始数据的微调拟合和直接对原始数据的标准拟合)都进行了这一步。

最后，我们可以将根据 VAR 的拟合值加上原始数据训练的模型与仅根据原始训练数据训练的相同结构进行比较。在大多数情况下，当我们执行两个训练步骤时，误差较低。我们还报告了使用基线获得的性能，该基线由最近可用观察的简单重复组成。该程序是验证预测是否不是重复的当前值(即不是有用的预测)的良好实践。

![](img/c0eca2956730824864f4e6e92e572d33.png)

测试台上的 RMSE(图片由作者提供)

# 摘要

在本文中，我们尝试使用 VAR 模型获得的信息来完成一项多变量时间序列任务，以提高经过训练的预测未来的递归神经网络的性能。我们实施了两步训练程序，解决了灾难性遗忘的问题，并提高了整体表现。

[**查看我的 GITHUB 回购**](https://github.com/cerlymarco/MEDIUM_NoteBook)

保持联系: [Linkedin](https://www.linkedin.com/in/marco-cerliani-b0bba714b/)

**参考文献**

基于梯度的神经网络中灾难性遗忘的实证研究