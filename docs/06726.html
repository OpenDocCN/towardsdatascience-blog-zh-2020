<html>
<head>
<title>Pneumonia Detection using Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用卷积神经网络的肺炎检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pneumonia-detection-using-convolutional-neural-network-12b94aeb1206?source=collection_archive---------43-----------------------#2020-05-26">https://towardsdatascience.com/pneumonia-detection-using-convolutional-neural-network-12b94aeb1206?source=collection_archive---------43-----------------------#2020-05-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><h1 id="4779" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">介绍</h1><p id="ff4f" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">随着AIML课程的完成，我想把我新学到的知识用于一些兼职项目，这些项目既可以帮助我在该领域获得一些实践经验，又可以解决一个有趣的现实生活问题，或者对它有一些实际用处。在寻找一个符合我需要的项目的过程中，我最终决定建立一个卷积神经网络，通过查看胸部x光图像来检测肺炎。</p><h1 id="4556" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">什么是肺炎？</h1><p id="4b3b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">肺炎是一种影响肺部的急性呼吸道感染。肺由称为肺泡的小囊组成，当健康人呼吸时，肺泡中充满空气。当一个人患肺炎时，肺泡中充满了脓和液体，这使得呼吸疼痛，并限制了氧气的摄入。</p><p id="8887" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">肺炎是全球儿童死亡的单一最大传染性原因。肺炎在2017年导致808 694名5岁以下儿童死亡，占所有5岁以下儿童死亡的15%。肺炎影响世界各地的儿童和家庭，但在南亚和撒哈拉以南非洲最为普遍。</p><h1 id="a822" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">项目概述</h1><p id="8d30" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">有了这些事实作为灵感，我开始着手我的项目:</p><p id="1510" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">首先，我需要弄清楚我可以在哪里构建和运行代码，因为我的系统规格不足以处理构建模型所需的计算能力，所以我使用了谷歌的Colab。Colab允许您在浏览器中编写和执行Python，使用</p><ul class=""><li id="a20a" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">不需要配置</li><li id="c4f0" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">免费访问GPU</li><li id="3fca" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">轻松分享</li></ul><p id="8ba1" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">无论你是一名<strong class="kq iu">学生</strong>、一名<strong class="kq iu">数据科学家</strong>还是一名<strong class="kq iu">人工智能研究员</strong>，Colab都能让你的工作变得更简单。</p><p id="f9d2" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">注意:需要API</p><p id="dba2" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">在下面的代码中，我也提到了如何从Kaggle访问数据集，但需要注意的重要事项是:</p><ol class=""><li id="cc51" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll mf lx ly lz bi translated">准备好您的API密钥文件，即'<strong class="kq iu"> kaggle.json' </strong></li><li id="7082" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">使用这种方法，每次在google collab中重置运行时，您都将丢失所有文件和生成的模型，因此一旦完成，请始终下载您的模型文件，并在每次重置后记得重新导入数据集</li></ol><h1 id="0698" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">我在努力实现什么？</h1><p id="0682" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">当你提交一个5岁孩子胸部的x光图像时，算法应该能够以很高的准确度预测病人是否患有肺炎。</p><h1 id="068f" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">代码</h1><ul class=""><li id="739f" class="lr ls it kq b kr ks kv kw kz mg ld mh lh mi ll lw lx ly lz bi translated">首先，你必须把你的API密匙文件上传到你在Colab的Jupyter笔记本上:</li><li id="e2ef" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">接下来，从Kaggle导入数据集并解压缩:</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="3cb4" class="ms jr it mo b gy mt mu l mv mw"><strong class="mo iu">from</strong> <strong class="mo iu">google.colab</strong> <strong class="mo iu">import</strong> files<br/>files.upload()</span><span id="b3e9" class="ms jr it mo b gy mx mu l mv mw">!pip install -q kaggle <br/>!mkdir -p ~/.kaggle <br/>!cp kaggle.json ~/.kaggle/ <br/>!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia<br/>!unzip /content/chest-xray-pneumonia.zip</span></pre><ul class=""><li id="eddf" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">我使用了Paul Mooney的胸部X射线图像(肺炎)数据集，因为数据已经方便地分为训练、测试和val:</li><li id="56f4" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">train-包含用于教授我们的模型的训练数据/图像。</li><li id="9b60" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">Val —包含我们将用来验证模型的图像。这个数据集的目的是防止我们的模型过度拟合。当模型学习训练数据中的细节和噪声达到对新数据的模型性能产生负面影响的程度时，就会发生过度拟合。这意味着训练数据中的噪声或随机波动被模型拾取并学习为概念。问题是这些概念不适用于新数据，并对模型的概括能力产生负面影响。</li><li id="35b3" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">测试—这包含我们在模型学习了图像与其标签(肺炎/非肺炎)之间的关系后用于测试模型的数据</li><li id="a926" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">现在，让我们从导入所有需要的库开始:</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="8ec4" class="ms jr it mo b gy mt mu l mv mw"><strong class="mo iu">from</strong> <strong class="mo iu">keras.models</strong> <strong class="mo iu">import</strong> Sequential<br/><strong class="mo iu">from</strong> <strong class="mo iu">keras.layers</strong> <strong class="mo iu">import</strong> Conv2D<br/><strong class="mo iu">from</strong> <strong class="mo iu">keras.layers</strong> <strong class="mo iu">import</strong> MaxPooling2D<br/><strong class="mo iu">from</strong> <strong class="mo iu">keras.layers</strong> <strong class="mo iu">import</strong> Flatten<br/><strong class="mo iu">from</strong> <strong class="mo iu">keras.layers</strong> <strong class="mo iu">import</strong> Dense<br/><strong class="mo iu">from</strong> <strong class="mo iu">keras.preprocessing.image</strong> <strong class="mo iu">import</strong> ImageDataGenerator<br/><strong class="mo iu">import</strong> <strong class="mo iu">numpy</strong> <strong class="mo iu">as</strong> <strong class="mo iu">np</strong><br/><strong class="mo iu">from</strong> <strong class="mo iu">keras.preprocessing</strong> <strong class="mo iu">import</strong> image<br/><strong class="mo iu">import</strong> <strong class="mo iu">os</strong><br/><strong class="mo iu">import</strong> <strong class="mo iu">matplotlib.pyplot</strong> <strong class="mo iu">as</strong> <strong class="mo iu">plt</strong><br/><strong class="mo iu">import</strong> <strong class="mo iu">cv2</strong></span></pre><ol class=""><li id="3f1b" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll mf lx ly lz bi translated">Keras Python库使创建深度学习模型变得快速而简单。顺序API允许您为大多数问题逐层创建模型。它的局限性在于，它不允许您创建共享层或具有多个输入或输出的模型。</li><li id="9584" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">Keras Conv2D是一个2D卷积层，这一层创建一个卷积核，这是风与层输入，这有助于产生输出张量。(注意:-内核:在图像处理中，内核是卷积矩阵或遮罩，可以通过在内核和图像之间进行卷积来用于模糊、锐化、浮雕、边缘检测等。)</li><li id="59d8" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">keras.layers中的MaxPooling2D，用于池化操作。为了建立这个特殊的神经网络，我们使用最大池函数，存在不同类型的池操作，如最小池、平均池等。在MaxPooling中，我们需要各个感兴趣区域的最大值像素。</li><li id="55cd" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">从keras.layers展平，用于展平。展平是将所有生成的二维数组转换成一个长的连续线性向量的过程。</li><li id="62de" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">来自keras.layers的Dense，用于执行神经网络的完全连接</li><li id="cd49" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">ImageDataGenerator，它获取一批图像，并对批中的每个图像应用一系列随机变换(包括随机旋转、调整大小、剪切等。)然后用新的随机转换的批次替换原始批次来训练CNN。</li></ol><ul class=""><li id="b991" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">我首先定义了两个变量，它们包含我要使用的图像尺寸值和我要使用的批量大小:</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="0e55" class="ms jr it mo b gy mt mu l mv mw">img_dims = 64<br/>batch_size = 32</span></pre><ul class=""><li id="680d" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">然后，我创建了一个sequential类的对象，并开始对卷积步骤进行编码:</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="1c84" class="ms jr it mo b gy mt mu l mv mw">classifier = Sequential()<br/>classifier.add(Conv2D(32, (3, 3), input_shape = (img_dims, img_dims, 3), activation = 'relu'))<br/>classifier.add(MaxPooling2D(pool_size = (2, 2)))<br/>classifier.add(Flatten())<br/>classifier.add(Dense(units = 128, activation = 'relu'))<br/>classifier.add(Dense(units = 1, activation = 'sigmoid'))</span></pre><ul class=""><li id="339f" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">然后我使用“Conv2D”函数添加了一个卷积层。Conv2D函数有4个参数:</li></ul><ol class=""><li id="9966" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll mf lx ly lz bi translated">第一个是滤波器，这是一个强制性的Conv2D参数，定义卷积层将学习的滤波器数量，即32个。这里，滤波器用于对图像进行切片，并逐个映射，学习输入图像的不同部分。想象一下，一个小滤镜从左到右从上到下滑过图像，移动的滤镜正在寻找，比如说，一个黑色的边缘。每次找到一个匹配，它就被映射到输出图像上。</li><li id="205c" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">第二个参数是每个滤波器的形状，这里是3x3，</li><li id="3053" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">第三个是每个图像的输入形状和图像类型(RGB或黑白),即我们的CNN将要拍摄的输入图像的分辨率为64x64”代表RGB，这是一个彩色图像</li><li id="bc9b" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">第四个参数是我们要使用的激活函数，这里“relu”代表一个校正的线性单位函数。激活函数是一个帮助决定神经元是否会触发的节点。Relu将矩阵x中的所有负值设置为零，所有其他值保持不变。</li></ol><ul class=""><li id="a60b" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">现在，我对一幅图像进行卷积运算后得到的合成特征图进行合并运算。池操作的主要目的是尽可能减小图像的大小。</li><li id="c119" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">接下来，我通过展平将所有汇集的图像转换成一个连续的矢量。展平是理解的一个非常重要的步骤。我们在这里所做的基本上是采用二维数组，即汇集图像像素，并将其转换为一维单一向量。</li><li id="691e" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">现在，为了创建一个完全连接的层，我已经连接了展平步骤后得到的一组节点，这些节点将作为这些完全连接的层的输入层。“密集”是添加完全连接层的功能，“单位”是我们定义应该出现在此隐藏层中的节点数量的地方。</li><li id="c401" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">然后我初始化了输出层，它由一个节点组成，给我相应的输出</li><li id="10ca" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">一旦CNN模型构建完成，就该编译它了:</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="c6c5" class="ms jr it mo b gy mt mu l mv mw">classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])</span></pre><ul class=""><li id="ee84" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">这里我们使用了以下参数:</li></ul><ol class=""><li id="9f9c" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll mf lx ly lz bi translated">Adam是一种优化算法，可以用来代替经典的随机梯度下降过程，以基于训练数据迭代地更新网络权重。</li><li id="a39e" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">交叉熵损失或对数损失衡量分类模型的性能，其输出是0到1之间的概率值。交叉熵损失随着预测概率偏离实际标签而增加。</li><li id="586f" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">最后，指标参数是选择性能指标。</li></ol><ul class=""><li id="9c79" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">在我们开始将CNN拟合到图像数据集之前，我们需要预处理图像以防止过度拟合:</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="9599" class="ms jr it mo b gy mt mu l mv mw">input_path = '/content/chest_xray/'<br/>train_datagen = ImageDataGenerator(rescale = 1./255,<br/>shear_range = 0.2,<br/>zoom_range = 0.2,<br/>horizontal_flip = <strong class="mo iu">True</strong>)<br/>test_datagen = ImageDataGenerator(rescale = 1./255)<br/>training_set = train_datagen.flow_from_directory(directory=input_path+'train',<br/>target_size = (img_dims, img_dims),<br/>batch_size = batch_size,<br/>class_mode = 'binary')<br/>test_set = test_datagen.flow_from_directory(directory=input_path+'test',<br/>target_size = (img_dims, img_dims),<br/>batch_size = batch_size,<br/>class_mode = 'binary')</span></pre><ol class=""><li id="e502" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll mf lx ly lz bi translated">对于此任务，我们使用了Keras的ImageDataGenerator，并传递了以下参数:</li><li id="486b" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated"><strong class="kq iu">重新标度:</strong>重新标度因子。默认为无。如果无或为0，则不应用重缩放，否则我们将数据乘以所提供的值(在应用所有其他变换之后)。</li><li id="d2ba" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated"><strong class="kq iu">剪切_范围</strong>:浮动。剪切强度(逆时针方向的剪切角度，单位为度)。用于变换图像方向的剪切。</li><li id="c2c5" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated"><strong class="kq iu"> zoom_range </strong>:浮动或【下，上】。随机缩放的范围。</li><li id="5a07" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated"><strong class="kq iu">水平_翻转</strong>:布尔型。随机水平翻转输入。</li><li id="2c4b" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated"><strong class="kq iu"> flow_from_directory </strong>:获取一个目录的路径，生成批量的扩充/规范化数据。</li></ol><ul class=""><li id="b392" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">现在让数据符合CNN模型:</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="eed6" class="ms jr it mo b gy mt mu l mv mw">epochs = 10  <br/>hist = classifier.fit_generator(            training_set, steps_per_epoch=training_set.samples // batch_size,             epochs=epochs, validation_data=test_set,             validation_steps= test_set.samples)</span></pre><ol class=""><li id="bb4b" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll mf lx ly lz bi translated">在上面的代码中，“steps_per_epoch”保存训练图像的数量，即training_set文件夹包含的图像的数量。</li><li id="16dc" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll mf lx ly lz bi translated">和“时期”，单个时期是训练神经网络的单个步骤；换句话说，当一个神经网络只在一遍中对每个训练样本进行训练时，我们说一个时期结束了。所以训练过程应该由多个时期组成。</li></ol><ul class=""><li id="e639" class="lr ls it kq b kr lm kv ln kz lt ld lu lh lv ll lw lx ly lz bi translated">一旦您最终建立并训练了您的模型，您就可以将图像传递给classifier.predict()(即[modelname])。predict())函数并获得预测。</li><li id="3f24" class="lr ls it kq b kr ma kv mb kz mc ld md lh me ll lw lx ly lz bi translated">您还可以使用classifier.save()(即[modelname])保存您的模型以供将来使用。save())</li></ul><h1 id="8552" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结果呢</h1><p id="fabd" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果你对代码感兴趣，可以去看看<a class="ae my" href="https://github.com/nischalmadiraju/Pnuemonia_Detection_CNN" rel="noopener ugc nofollow" target="_blank"> GitHub </a></p><p id="37cd" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">我能够实现:</p><figure class="mj mk ml mm gt na gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/0bb3d2ae1d6a0307f6ee3828a6f7844e.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*Nuch71_HOA5CzbSX2OPGcg.png"/></div></figure><p id="c269" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">通过改变网络中使用的层数可以获得更高的精度。另一种提高精度的方法是相应地改变超参数。</p><h1 id="9953" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="f6f3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">对于任何具有良好编程技能的开发人员来说，创建一个对数百万人有用的机器学习模型都是相当容易的。</p><p id="c51d" class="pw-post-body-paragraph ko kp it kq b kr lm kt ku kv ln kx ky kz lo lb lc ld lp lf lg lh lq lj lk ll im bi translated">专业人士已经取得了更好的结果。作为一个初学者，我能够达到89%的准确率，这显然是不错的。但为了在现实世界中被数百万人使用，89%的准确率意味着它将误诊大约100，000例病例。</p><h1 id="3114" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">随着未来的发展，ML技术的改进，但最重要的是——越来越多的人参与其中——我们将能够解决更多这样的问题。</h1></div></div>    
</body>
</html>