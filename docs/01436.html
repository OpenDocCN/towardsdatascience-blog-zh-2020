<html>
<head>
<title>Easy Visual Question Answering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单的视觉问答</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/easy-visual-question-answering-victorzhou-com-637efa38b55c?source=collection_archive---------28-----------------------#2020-02-08">https://towardsdatascience.com/easy-visual-question-answering-victorzhou-com-637efa38b55c?source=collection_archive---------28-----------------------#2020-02-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e43f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用神经网络的视觉问题回答(VQA)的温和介绍。</h2></div><p id="69ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">快速回答——这张图片描述了什么运动？</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/d686f700ff3560e1782d93cf0e1136f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*G7PX_JcTjoYN-kdb.jpg"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">图片来自CloudCV VQA演示</p></figure><p id="8891" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可能马上就知道答案:<strong class="kk iu">棒球</strong>。很简单，对吧？</p><p id="cb61" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在想象你是一台电脑。给你同样的图像和文字“<em class="lq">在这个图像中描绘了什么运动？</em>”并要求出示答案。不再那么容易了，是吗？</p><p id="ea1f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个问题被称为<strong class="kk iu">视觉问答(VQA) </strong>:回答关于图像的开放式问题。VQA很有趣，因为它需要结合视觉和语言理解。解决这一任务的模型展示了对图像的更一般的理解:它必须能够回答关于图像的完全不同的问题，有时甚至解决图像的不同部分。</p><p id="0395" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">起初，这似乎是一个很难解决的问题，但实际上它可能比你想象的更容易解决。在本帖中，我们将<strong class="kk iu">探索执行VQA的基本方法，并用Python构建我们自己的简单实现</strong>。下面是这篇文章最终产品的<a class="ae lr" href="https://easy-vqa-demo.victorzhou.com" rel="noopener ugc nofollow" target="_blank">演示</a>:</p><div class="ls lt gp gr lu lv"><a href="https://easy-vqa-demo.victorzhou.com" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd iu gy z fp ma fr fs mb fu fw is bi translated">简易VQA演示</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">在易VQA数据集上训练的可视化问答模型的Javascript演示。</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">easy-vqa-demo.victorzhou.com</p></div></div></div></a></div><p id="aebc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">警告:<strong class="kk iu">这篇文章假设了卷积神经网络(CNN)</strong>的基本知识。我的<a class="ae lr" href="https://victorzhou.com/blog/intro-to-cnns-part-1/" rel="noopener ugc nofollow" target="_blank">CNN简介</a>涵盖了你需要知道的一切，所以如果有必要就从这里开始吧。</p><p id="0c80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还将使用<a class="ae lr" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>，一个Python的深度学习库，来为我们的模型提供动力，所以如果你以前从未看过Keras代码，我建议你回顾一下我的<a class="ae lr" href="https://victorzhou.com/blog/keras-neural-network-tutorial/" rel="noopener ugc nofollow" target="_blank">Keras神经网络简介</a>。</p><p id="86a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个前言说够了。我们开始吧！</p><blockquote class="me mf mg"><p id="4f9d" class="ki kj lq kk b kl km ju kn ko kp jx kq mh ks kt ku mi kw kx ky mj la lb lc ld im bi translated"><em class="it">只是找源代码/结果？跳到</em> <a class="ae lr" href="https://victorzhou.com/blog/easy-vqa/#8-the-results" rel="noopener ugc nofollow" target="_blank"> <em class="it">结果</em> </a> <em class="it">。</em></p><p id="97f9" class="ki kj lq kk b kl km ju kn ko kp jx kq mh ks kt ku mi kw kx ky mj la lb lc ld im bi translated">这篇文章最好在victorzhou.com浏览</p></blockquote><h1 id="293d" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">1.数据集</h1><p id="f634" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">在visualqa.org的<a class="ae lr" href="https://visualqa.org" rel="noopener ugc nofollow" target="_blank">可以找到VQA最著名的数据集，它包含20万多张图像和超过一百万个关于这些图像的问题(带答案)。这里有一些来自最初的</a><a class="ae lr" href="https://arxiv.org/pdf/1505.00468.pdf" rel="noopener ugc nofollow" target="_blank"> VQA论文</a>的例子:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/b2c08ed95a03bb63925448de33eedae0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PiR24zr6yl7FXThd.png"/></div></figure><p id="1478" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">印象深刻吧。不幸的是，这种程度的VQA超出了这篇博文的范围。我们将使用专门为这篇博文创建的自定义数据集:<a class="ae lr" href="https://github.com/vzhou842/easy-VQA" rel="noopener ugc nofollow" target="_blank"> easy-VQA </a>。</p><p id="b910" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">易VQA数据集中的图像要简单得多:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/269da7a0d0766dc2491d7a0bcb1554a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/0*nt2UfYAnOUjmS3_2.png"/></div></figure><p id="643e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">问题也简单多了:</p><ul class=""><li id="0197" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld no np nq nr bi translated">图像中是什么形状？</li><li id="2740" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">三角形是什么颜色的？</li><li id="1dbc" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">图像中是否有绿色形状？</li><li id="6b60" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">图像包含一个圆吗？</li></ul><p id="ec30" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总的来说，easy-VQA包含5000幅图像和大约50000个问题，分为训练集(80%)和测试集(20%)。这些问题有13个可能的答案:</p><ul class=""><li id="9e30" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld no np nq nr bi translated"><strong class="kk iu">是/否</strong>:是，否</li><li id="64d0" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated"><strong class="kk iu">形状</strong>:圆形、长方形、三角形</li><li id="d42c" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated"><strong class="kk iu">颜色</strong>:红色、绿色、蓝色、黑色、灰色、蓝绿色、棕色、黄色</li></ul><h1 id="8d6e" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">2.方法</h1><p id="b892" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">执行VQA的标准方法如下所示:</p><ol class=""><li id="bccb" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld nx np nq nr bi translated">处理图像。</li><li id="cde3" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">处理问题。</li><li id="0bcd" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">结合步骤1/2中的功能。</li><li id="9def" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">给每个可能的答案分配概率。</li></ol><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8c72eff80c30beb59f0c5259d5451148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jlIkNTmPcjWyonrH.gif"/></div></figure><p id="1caa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，我们正在使用一个<strong class="kk iu">固定答案集</strong>,其中保证可能的答案中只有一个是正确的。这让我们的生活变得容易多了，因为我们不必<em class="lq">得出</em>正确答案，我们只需回答实际上是一个<strong class="kk iu">选择题</strong>。大多数尖端的VQA系统有1000个可能的答案，但在这篇文章中，我们只允许包含在<a class="ae lr" href="https://github.com/vzhou842/easy-VQA" rel="noopener ugc nofollow" target="_blank"> easy-VQA </a>中的13个可能的答案。</p><p id="a16c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">步骤1和2通常分别使用来自<a class="ae lr" href="https://victorzhou.com/tag/computer-vision/" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>和<a class="ae lr" href="https://victorzhou.com/tag/natural-language-processing/" rel="noopener ugc nofollow" target="_blank">自然语言处理</a>的方法，将原始图像/文本输入转化为经过处理的数据向量。然后，这两种输出表示可以一起用于分析，以最终选择最可能的答案。</p><h2 id="00e7" class="ny ml it bd mm nz oa dn mq ob oc dp mu kr od oe mw kv of og my kz oh oi na oj bi translated">一个例子</h2><p id="da62" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">这里有一个非常简单的例子，说明VQA系统如何回答问题<em class="lq">“三角形是什么颜色的？”</em>关于上面可视化中的图像:</p><ol class=""><li id="19dd" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld nx np nq nr bi translated">在图像中寻找<strong class="kk iu">形状</strong>和<strong class="kk iu">颜色</strong>。一个简单的<a class="ae lr" href="https://victorzhou.com/blog/intro-to-cnns-part-1/" rel="noopener ugc nofollow" target="_blank"> CNN </a>可以被训练识别出我们的图像包含一个蓝色的<strong class="kk iu">三角形</strong>。</li><li id="1d83" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">了解<strong class="kk iu">题型</strong>。由于问题以<em class="lq">“什么颜色”</em>开头，很容易意识到答案应该是一种颜色。</li><li id="c4fb" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">对于每个可能的答案选项，根据前两步的信息确定其“强度”。答案“蓝色”将具有高强度，因为:(1)我们知道图像具有蓝色形状，并且(2)我们知道答案应该是颜色。</li><li id="cb18" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">使用类似于<a class="ae lr" href="https://victorzhou.com/blog/softmax" rel="noopener ugc nofollow" target="_blank"> Softmax </a>的东西将每个答案的“强度”转换成概率。答案“蓝色”将有接近100%的概率。</li></ol><p id="5372" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在接下来的几节中，我们将为easy-VQA数据集详细介绍实现这4个步骤的细节。</p><h2 id="114b" class="ny ml it bd mm nz oa dn mq ob oc dp mu kr od oe mw kv of og my kz oh oi na oj bi translated">代码设置</h2><p id="ac94" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">如果你想跟随这篇文章，而不是从零开始，克隆<a class="ae lr" href="https://github.com/vzhou842/easy-VQA-keras" rel="noopener ugc nofollow" target="_blank">易-VQA-克拉斯</a>回购:</p><pre class="lf lg lh li gt ok ol om on aw oo bi"><span id="a938" class="ny ml it ol b gy op oq l or os">git clone <a class="ae lr" href="https://github.com/vzhou842/easy-VQA-keras.git" rel="noopener ugc nofollow" target="_blank">https://github.com/vzhou842/easy-VQA-keras.git</a><br/>cd easy-VQA-keras<br/>pip install -r requirements.txt</span></pre><p id="fd44" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">否则，如果您想从头开始安装，请确保您使用的是Python 3并安装了几个包:</p><pre class="lf lg lh li gt ok ol om on aw oo bi"><span id="8a30" class="ny ml it ol b gy op oq l or os">pip install easy-vqa keras tensorflow Pillow</span></pre><p id="1def" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们需要<a class="ae lr" href="https://pypi.org/project/tensorflow/" rel="noopener ugc nofollow" target="_blank"> tensorflow </a>为Keras供电，我们将使用<a class="ae lr" href="https://pypi.org/project/Pillow/" rel="noopener ugc nofollow" target="_blank"> Pillow </a>进行图像处理。我们还将使用<a class="ae lr" href="https://github.com/vzhou842/easy-VQA" rel="noopener ugc nofollow" target="_blank"> easy-vqa </a> Python包，这使得访问easy-vqa数据集变得简单。稍后会有更多相关信息——现在，让我们开始吧。</p><h1 id="4856" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">3.图像模型</h1><p id="04d2" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">首先:我们的形象模型。正如我们之前提到的，我们将构建一个<a class="ae lr" href="https://victorzhou.com/blog/intro-to-cnns-part-1/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a> (CNN)来从图像输入中提取信息。为此，我们将使用<a class="ae lr" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>，这是一个初学者友好但功能强大的Python深度学习库。我已经写了一篇关于使用Keras实现CNN的指南——在继续之前，在一个新的标签中打开它或者浏览它可能会有帮助。</p><p id="24ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的图像数据集并不复杂，所以我们可以用一个相对简单的CNN来处理它:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="ou ov di ow bf ox"><div class="gh gi ot"><img src="../Images/419675453db71fe1da3440b5c3496feb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uyj1rnmE6k6At02gscGTfw.png"/></div></div></figure><ol class=""><li id="8944" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld nx np nq nr bi translated">从数据集中的64x64图像开始。</li><li id="e0f5" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">通过使用“相同”填充的八个3x3滤镜的conv层，产生64x64x8的音量。</li><li id="0473" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">使用标准的最大池层将体积切割为32x32x8。</li><li id="a32a" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">通过另一个conv层，这一次有16个过滤器，产生一个32x32x16的体积。</li><li id="e184" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">再次使用最大池，切割到16x16x16。</li><li id="a405" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">展平体积，这会产生一个具有16 = 4096个节点的层。</li></ol><blockquote class="me mf mg"><p id="623e" class="ki kj lq kk b kl km ju kn ko kp jx kq mh ks kt ku mi kw kx ky mj la lb lc ld im bi translated"><em class="it">迷茫？以上所有概念都在我的</em><a class="ae lr" href="https://victorzhou.com/blog/intro-to-cnns-part-1/" rel="noopener ugc nofollow" target="_blank"><em class="it">CNN简介</em> </a> <em class="it">中有所涉及。</em></p></blockquote><p id="a7e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码如下:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="0e15" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这段代码使用了Keras的<a class="ae lr" href="https://keras.io/models/model/" rel="noopener ugc nofollow" target="_blank">模型</a>(功能)API。我们没有使用Keras的<a class="ae lr" href="https://keras.io/models/sequential/" rel="noopener ugc nofollow" target="_blank">顺序</a>模型API，因为我们稍后需要将我们的图像模型和问题模型结合起来(你会看到，继续阅读)。</p><h1 id="3abb" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">4.问题模型</h1><p id="87a4" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">接下来:我们的问题模型。大多数VQA模型会使用某种<a class="ae lr" href="https://victorzhou.com/blog/intro-to-rnns/" rel="noopener ugc nofollow" target="_blank">递归神经网络</a> (RNN)来处理问题输入，但这对我们的用例来说有点大材小用。易VQA数据集中的问题简短、简单，来自一组固定的问题模板，因此与你在现实世界中可能看到的问题相比，它们更容易理解。</p><p id="234d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将采用一种更简单的方法，而不是复杂的RNN架构:</p><ol class=""><li id="ca09" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld nx np nq nr bi translated">使用一个<a class="ae lr" href="https://victorzhou.com/blog/bag-of-words/" rel="noopener ugc nofollow" target="_blank">单词包</a> (BOW)表示法将每个问题转化为一个<strong class="kk iu">向量</strong>。</li><li id="30a7" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld nx np nq nr bi translated">使用该向量作为<a class="ae lr" href="https://victorzhou.com/blog/intro-to-neural-networks/" rel="noopener ugc nofollow" target="_blank">标准(前馈)神经网络</a>的输入。</li></ol><p id="ef5d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你不完全明白那是什么意思，不要担心。我们将在下面完成这两个步骤。</p><h2 id="adb6" class="ny ml it bd mm nz oa dn mq ob oc dp mu kr od oe mw kv of og my kz oh oi na oj bi translated">单词袋(蝴蝶结)</h2><p id="e955" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">BOW表示通过计算每个单词在文本中出现的次数，将任何文本字符串转换为固定长度的向量。我已经写了一篇简短的、初学者友好的关于单词袋模型的介绍——如果你对它们不熟悉，我建议你现在就去读！从现在开始，我假设你对弓模型有一个基本的了解。</p><p id="636f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将利用Keras的<a class="ae lr" href="https://keras.io/preprocessing/text/#tokenizer" rel="noopener ugc nofollow" target="_blank">记号赋予器</a>类来实现BOW:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="e0ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，我们从<code class="fe pa pb pc ol b">easy-vqa</code>包中读取问题数据。如果你想了解这些API的细节，请参考<a class="ae lr" href="https://github.com/vzhou842/easy-VQA" rel="noopener ugc nofollow" target="_blank"> easy-vqa文档</a>。</p><h2 id="0d7d" class="ny ml it bd mm nz oa dn mq ob oc dp mu kr od oe mw kv of og my kz oh oi na oj bi translated">神经网络时间！</h2><p id="25b6" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">如前所述，我们的问题数据集相对简单，因此我们的问题模型不需要太花哨的东西。我们将把我们的弓向量表示传递到2个<strong class="kk iu">全连接</strong> (FC)神经网络层:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="ou ov di ow bf ox"><div class="gh gi pd"><img src="../Images/527ab139ce9b8143b9a54f27effaa955.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OM65B0EtsW85jH5ekiKhdw.png"/></div></div></figure><blockquote class="me mf mg"><p id="f6d6" class="ki kj lq kk b kl km ju kn ko kp jx kq mh ks kt ku mi kw kx ky mj la lb lc ld im bi translated"><em class="it">提醒:全连接层的每个节点都连接到前一层的每个输出。如果你需要复习，我们在我的</em> <a class="ae lr" href="https://victorzhou.com/blog/intro-to-neural-networks/" rel="noopener ugc nofollow" target="_blank"> <em class="it">神经网络介绍</em> </a> <em class="it">中使用了全连接层。</em></p></blockquote><p id="40f8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是我们的实现，它也使用了Keras的模型(函数)API:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="1ef5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe pa pb pc ol b">vocab_size</code>变量是我们BOW向量表示的长度，它是我们问题模型的输入。</p><h1 id="d225" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">5.合并</h1><p id="cdfa" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">我们将使用一个非常简单的方法来合并我们的图像和问题向量:<strong class="kk iu">逐元素乘法</strong>。用Keras的<a class="ae lr" href="https://keras.io/layers/merge/#multiply" rel="noopener ugc nofollow" target="_blank">多重合并层</a>实现这个是一行程序:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="1902" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe pa pb pc ol b">out</code>向量现在包含了从<em class="lq">图像和问题</em>中得到的信息。</p><h2 id="812d" class="ny ml it bd mm nz oa dn mq ob oc dp mu kr od oe mw kv of og my kz oh oi na oj bi translated">一个例子</h2><p id="b8da" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">为了说明这是如何有用的，考虑这个(有点做作的)例子:</p><ul class=""><li id="6eea" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld no np nq nr bi translated">当图像包含蓝色形状时，图像向量中的第一个元素为高电平<strong class="kk iu"/>，否则为低电平<strong class="kk iu"/>。</li><li id="14ce" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">当问题包含单词“blue”时，问题向量中的第一个元素是<strong class="kk iu">高</strong>，否则是<strong class="kk iu">低</strong>。</li></ul><p id="ee92" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么<code class="fe pa pb pc ol b">out</code>向量中的第一个元素只有在<em class="lq">图像和问题都与蓝色相关时才会为高。这个结果对于回答类似<em class="lq">“图像中有蓝色的形状吗？”</em></em></p><p id="6f51" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">实际上，我们的模型不太可能准确地学习<em class="lq">这种行为。记住，模型是通过<a class="ae lr" href="https://victorzhou.com/blog/intro-to-neural-networks/#4-training-a-neural-network-part-2" rel="noopener ugc nofollow" target="_blank">在它的层</a>中传播渐变来学习的，这不太可能产生如此简单的结果。相反，关注直觉:</em></p><ul class=""><li id="854f" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld no np nq nr bi translated">图像和问题向量中都嵌入了颜色信息。</li><li id="9ceb" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">乘法运算后，结果的某些部分可以用来回答关于颜色的问题。</li></ul><p id="e022" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">实际上，我们可以用任何可微的方法来合并这两个向量。Keras的<a class="ae lr" href="https://keras.io/layers/merge/" rel="noopener ugc nofollow" target="_blank">合并图层</a>部分中列出的其他合并方法包括<code class="fe pa pb pc ol b">Add</code>、<code class="fe pa pb pc ol b">Subtract</code>、<code class="fe pa pb pc ol b">Concatenate</code>和<code class="fe pa pb pc ol b">Average</code>，所有这些方法都做您认为它们做的事情。对于我们简单的数据集来说，大多数方法可能都和<code class="fe pa pb pc ol b">Multiply</code>一样好用——你可以自己尝试一下！</p><h1 id="1820" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">6.输出</h1><p id="3539" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">最后，是我们的VQA系统给出答案的时候了。回想一下，我们正在使用一个<strong class="kk iu">固定答案集</strong>:我们知道所有可能的答案，并且只有一个保证是正确的。</p><p id="a72a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于这一步，我们将使用<a class="ae lr" href="https://victorzhou.com/blog/softmax" rel="noopener ugc nofollow" target="_blank"> Softmax </a>将我们的输出值转化为<em class="lq">概率</em>，这样我们就可以量化我们对每个可能答案的确信程度。如果你不熟悉Softmax，我强烈建议在继续之前阅读我对Softmax 的<a class="ae lr" href="https://victorzhou.com/blog/softmax" rel="noopener ugc nofollow" target="_blank">解释。</a></p><p id="476d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们将加入一个全连接层，然后使用Keras内置的Softmax实现:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="7d4c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就是这样！剩下的工作就是构建和编译模型:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><blockquote class="me mf mg"><p id="07af" class="ki kj lq kk b kl km ju kn ko kp jx kq mh ks kt ku mi kw kx ky mj la lb lc ld im bi translated"><em class="it">如果你需要复习，我在我的CNN系列中解释了</em> <a class="ae lr" href="https://victorzhou.com/blog/intro-to-cnns-part-1/#52-cross-entropy-loss" rel="noopener ugc nofollow" target="_blank"> <em class="it">交叉熵损失</em> </a> <em class="it">。</em></p></blockquote><h1 id="0abb" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">7.数据处理</h1><p id="159f" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">既然我们已经弄清楚了我们的模型，我们只需要多一点代码来准备好所有的数据。对于这一部分，<strong class="kk iu">我建议在单独的标签</strong>中打开<a class="ae lr" href="https://github.com/vzhou842/easy-VQA" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">easy-VQA</strong></a><strong class="kk iu">文档以供参考。为了简洁起见，我将省略对我们从<code class="fe pa pb pc ol b">easy-vqa</code>开始使用的方法的解释。</strong></p><p id="fc7b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们将从<code class="fe pa pb pc ol b">easy-vqa</code>中提取一些数据:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="e8b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们将读取并预处理我们的图像:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="8221" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们将创建用于训练模型的实际输入和预期输出:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="b70e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Keras的<a class="ae lr" href="https://keras.io/utils/#to_categorical" rel="noopener ugc nofollow" target="_blank">to _ categorial</a>是一种从索引中生成<a class="ae lr" href="https://en.wikipedia.org/wiki/One-hot" rel="noopener ugc nofollow" target="_blank"> one-hot </a>向量的简便方法。我们需要一个热点矢量来匹配我们的输出Softmax层的尺寸。</p><p id="1cf6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为一个可选步骤，我们将设置一个Keras <a class="ae lr" href="https://keras.io/callbacks/#modelcheckpoint" rel="noopener ugc nofollow" target="_blank"> ModelCheckpoint </a>以在每个时期后保存我们的最佳模型:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><p id="824d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">终于，我们准备好训练了！</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="oy oz l"/></div></figure><h1 id="6f4e" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">8.结果呢</h1><p id="5143" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">为了节省空间，我不会在这篇文章中包含完整的代码，但你可以在GithubT5<a class="ae lr" href="https://github.com/vzhou842/easy-VQA-keras" rel="noopener ugc nofollow" target="_blank">上找到它。将这些行复制并粘贴到您的终端中，亲自训练模型:</a></p><pre class="lf lg lh li gt ok ol om on aw oo bi"><span id="f052" class="ny ml it ol b gy op oq l or os">git clone https://github.com/vzhou842/easy-VQA-keras.git<br/>cd easy-VQA-keras<br/>pip install -r requirements.txt<br/>python train.py</span></pre><p id="f92a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">运行代码会得到如下结果:</p><pre class="lf lg lh li gt ok ol om on aw oo bi"><span id="0f00" class="ny ml it ol b gy op oq l or os">Epoch 1/8<br/>loss: 0.8887 - accuracy: 0.6480 - val_loss: 0.7504 - val_accuracy: 0.6838<br/>Epoch 2/8<br/>loss: 0.7443 - accuracy: 0.6864 - val_loss: 0.7118 - val_accuracy: 0.7095<br/>Epoch 3/8<br/>loss: 0.6419 - accuracy: 0.7468 - val_loss: 0.5659 - val_accuracy: 0.7780<br/>Epoch 4/8<br/>loss: 0.5140 - accuracy: 0.7981 - val_loss: 0.4720 - val_accuracy: 0.8138<br/>Epoch 5/8<br/>loss: 0.4155 - accuracy: 0.8320 - val_loss: 0.3938 - val_accuracy: 0.8392<br/>Epoch 6/8<br/>loss: 0.3078 - accuracy: 0.8775 - val_loss: 0.3139 - val_accuracy: 0.8762<br/>Epoch 7/8<br/>loss: 0.1982 - accuracy: 0.9286 - val_loss: 0.2202 - val_accuracy: 0.9212<br/>Epoch 8/8<br/>loss: 0.1157 - accuracy: 0.9627 - val_loss: 0.1883 - val_accuracy: 0.9378</span></pre><p id="03bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于这样一个简单的模型来说，8个时代一点也不差:</p><ul class=""><li id="48b4" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld no np nq nr bi translated">我们达到了<strong class="kk iu"> 93.8% </strong>的验证准确率</li><li id="05ca" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">我们清楚地看到了培训的进展(损失减少，准确性提高)</li><li id="a2c1" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">该模型还没有过度拟合得太糟糕(训练/验证损失和精确度足够接近)</li></ul><p id="3df2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您愿意，您可以自己对代码进行试验，以获得更好的结果。我的带Keras 的CNN简介<a class="ae lr" href="https://victorzhou.com/blog/keras-cnn-tutorial/" rel="noopener ugc nofollow" target="_blank">中的</a><a class="ae lr" href="https://victorzhou.com/blog/keras-cnn-tutorial/#8-extensions" rel="noopener ugc nofollow" target="_blank">扩展</a>部分是一个很好的起点。考虑到这个问题相对简单，您应该能够非常容易地通过99%的验证准确率。供参考:官方的<a class="ae lr" href="https://easy-vqa-demo.victorzhou.com/" rel="noopener ugc nofollow" target="_blank"> easy-VQA演示</a>使用了一个模型，该模型实现了99.5%的验证准确性，参数仅略有不同。</p><h1 id="3c05" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">9.结束了</h1><p id="42f3" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">您现在已经实现了一个工作的VQA模型！然而，这篇文章只是一个温和的介绍。您还可以做更多的事情:</p><ul class=""><li id="421b" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld no np nq nr bi translated">了解<a class="ae lr" href="https://victorzhou.com/blog/intro-to-rnns/" rel="noopener ugc nofollow" target="_blank">递归神经网络</a> (RNNs)，它可以比我们使用的简单的基于BOW的问题模型更强大。</li><li id="1418" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">以原始的<a class="ae lr" href="https://visualqa.org/" rel="noopener ugc nofollow" target="_blank"> VQA </a>数据集为例，它包含更难的图像和问题。</li><li id="7d3c" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">查看VQA的调查<a class="ae lr" href="https://arxiv.org/pdf/1607.05910.pdf" rel="noopener ugc nofollow" target="_blank">,了解艺术模特使用的更复杂的方法。</a></li><li id="09b7" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">试试<a class="ae lr" href="https://vqa.cloudcv.org/" rel="noopener ugc nofollow" target="_blank"> CloudCV VQA演示</a>(印象相当深刻！).</li></ul><p id="211c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读！</p><blockquote class="me mf mg"><p id="e695" class="ki kj lq kk b kl km ju kn ko kp jx kq mh ks kt ku mi kw kx ky mj la lb lc ld im bi translated">注意:这篇文章用了第一人称(“我”、“我的”)，读起来好像是我(Victor Zhou)在说话。然而，正如最上面指出的，这篇文章是由我的好朋友<a class="ae lr" href="https://phillipkwang.com/" rel="noopener ugc nofollow" target="_blank"><em class="it">Phillip Wang</em></a><em class="it">共同撰写的，他是最近从CMU毕业的计算机科学毕业生，也是ML的一员。谢谢菲利普。</em></p></blockquote></div><div class="ab cl pe pf hx pg" role="separator"><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj"/></div><div class="im in io ip iq"><p id="6f15" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lq">最初发表于</em><a class="ae lr" href="https://victorzhou.com/blog/easy-vqa/" rel="noopener ugc nofollow" target="_blank"><em class="lq">https://victorzhou.com</em></a><em class="lq">。</em></p></div></div>    
</body>
</html>