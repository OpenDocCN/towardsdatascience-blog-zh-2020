<html>
<head>
<title>A Simple Guide to Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络的简单指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-simple-guide-to-convolutional-neural-networks-751789e7bd88?source=collection_archive---------11-----------------------#2020-01-19">https://towardsdatascience.com/a-simple-guide-to-convolutional-neural-networks-751789e7bd88?source=collection_archive---------11-----------------------#2020-01-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ee9c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">卷积神经网络揭秘没有任何花哨的技术术语！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9d0435ec728d59381ae84ff535871be9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pqRAjzfZKlFYGUCE"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">识别人和物体的卷积神经网络<a class="ae ky" href="https://martechtoday.com/how-visual-recognition-is-set-to-change-advertising-223719" rel="noopener ugc nofollow" target="_blank">(来源)</a></p></figure><p id="ead7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">汽车可以识别路标。脸书知道你最好朋友的名字。可以用脸解锁手机。这都是由<strong class="lb iu">魔法完成的。</strong></p><p id="4c0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我只是在开玩笑，这里没有魔法，只是简单的，古老的数学。但是严肃地说，我刚才提到的所有东西都是<strong class="lb iu"> <em class="lv">卷积神经网络的例子。</em> </strong></p><p id="eff7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是在深入研究卷积网络的代码之前，让我们先了解一下什么是卷积神经网络(CNN)以及它是如何工作的。</p><h1 id="8496" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">第 0 部分:什么是 CNN？为什么要用？</h1><p id="59db" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">那么，我们为什么要使用 CNN 而不是另一种类型的神经网络，比如多层感知器？这是因为 CNN 能够提取图像的特征，而像多层感知器(MLP)或递归神经网络(RNN)这样的算法不具备这种能力。</p><p id="810b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积神经网络的架构如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/fddf3757987c5d0701c3520d1cd9f07a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HWj5PgxWxdcld_ye"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">卷积神经网络的架构</p></figure><p id="52c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们应该从中注意到一些事情。网络从 2 个<em class="lv">卷积</em>和<em class="lv">最大池</em>层<em class="lv">、</em>开始，接着是 2 个<em class="lv">全连接</em>层，以一个输出层结束。卷积+最大池图层是识别影像(提取要素)的位置，完全连接图层是将影像分类到预定义类别的位置。</p><h1 id="f811" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">第 1 部分:图像识别</h1><p id="077d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">卷积神经网络中的第一部分过滤图像以从图像中提取特征，然后它汇集提取的特征以减少数据的大小，最后添加激活函数，使得网络是非线性函数。这可以归结为<strong class="lb iu">卷积</strong> + <strong class="lb iu">汇集+激活</strong>层。</p><h2 id="d7d0" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">盘旋</h2><p id="383d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">过滤器是从图像中提取特征的矩阵(这是学习发生的地方)。滤波器值和图像像素值之间的点积形成卷积层。</p><p id="8a8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">过滤张量是一个权重矩阵。每当网络执行反向传播时，滤波器矩阵中的值被更新。然而，滤波器矩阵的维数由程序员明确确定。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/f1256ffe9814c069a374257f30ef27bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6D2wIspj9_fdGZDz"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将滤波器张量与图像的像素值张量相乘。(来源)</p></figure><p id="b87f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 CNN 中，有许多不同的过滤器来提取图像中的各种特征。随着我们在网络中前进，从图像中提取的特征变得越来越具体。让我们以停车标志为例。</p><p id="51ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于第一层中的过滤器用于检测易于识别的特征，因此这可能是停车标志的八角形形状。第二层中的过滤器将用于检测更具体的内容，如文本“停止”。第三层中的过滤器可以用来检测更具体的东西，如“STOP”中的字母“S”。</p><p id="1e57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 Keras(<a class="ae ky" href="https://www.tensorflow.org/guide/keras/overview/" rel="noopener ugc nofollow" target="_blank">tensor flow</a>中的深度学习框架)中，第一个卷积层的代码如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/3a97d53c58365ab139fcfc3e2de85394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pvg80kUJSbcDsu7W"/></div></div></figure><p id="5217" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意</strong>:我不会太深入地讲述代码是如何工作的，但我会简单谈谈架构。</p><p id="b9c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以在这里，我的卷积层是 16 X 16 X 3，一个 5 X 5 的过滤器。程序员必须明确定义滤波器的维数，但滤波器中的值是网络自学的。</p><h2 id="8b2a" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">联营</h2><p id="807e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在图像通过第一个过滤器后，它将继续到池层。池层减小了过滤层的大小，这使我们可以更快地训练模型。此外，它通过丢弃滤波器张量中不需要的值来防止过拟合。</p><p id="800c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一种流行的汇集方法被称为<strong class="lb iu">最大汇集</strong>。这与滤波过程相同，但这次我们取最大值，而不是点积。看看下面的动画:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/0af2b2078874cfc3b37527ee31c8ed61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Gb1vfOEVXDl2RD2n"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最大池层的动画</p></figure><h2 id="407a" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">鲁热</h2><p id="2ade" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在，我们要增加数学。Re-Lu(校正线性单元)是神经网络中常用的激活函数。激活函数用于向神经网络添加非线性。这使得我们能够解决比我们的网络只是一个线性函数更复杂的问题。如果我们的网络中从来没有激活函数，它将是一个简单的线性回归算法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/7c365f6ed70848e835d99fbdcb3613e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*F-4tRbak6SlQEzut"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Re-Lu 激活功能(<a class="ae ky" href="https://miro.medium.com/max/2052/1*QkZ5OYHJvCnYPigMJ2SIyg.png" rel="noopener">源</a>)</p></figure><p id="f9e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Re-Lu 激活函数是一个只有当值大于零时才返回值的函数，有助于减少训练时间。</p><h1 id="4fee" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">第 2 部分:图像分类</h1><p id="7b29" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">既然卷积层已经提取了图像的所有特征，那么是时候对图像进行分类了。</p><p id="5a36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在完全连接的层中，每个神经元都与它之前和之后的层中的所有其他神经元共享连接。这就是为什么它被称为“完全连接”层。下面是它们的样子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/37ad2176e49c97aa880c6c22fc05d6f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*N9osH4nZXyuo2Htj"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CNN 中的全连接层(<a class="ae ky" href="https://missinglink.ai/wp-content/uploads/2019/06/The-Role-of-a-Fully-Connected-Layer-in-a-CNN-700x430.png" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><h2 id="1077" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">变平</h2><p id="b491" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在将我们复杂的输入输入到一个密集(全连接)层之前，我们必须<strong class="lb iu">展平</strong>张量(我们的输入)。扁平化就是把多维输入张量变成一维输入张量。例如，假设最后的卷积层输出一个(28，28，3)张量。展平此输出将为下一层提供(2352，1)的输入。2352 来自于乘以 28 X 28 X 3，这是前面输出张量的维数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/e10d3e393920028419fef59244a12f86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4afqrwiDydc8hw7g"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">展平汇集张量的例子(<a class="ae ky" href="https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/73_blog_image_1.png" rel="noopener ugc nofollow" target="_blank">来源</a>)。</p></figure><p id="9ef5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着图像中总共有 2352 个像素。扁平化允许我们分析每一个像素，因为现在，图像中的每一个像素都有自己的神经元。</p><h2 id="4f99" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">拒绝传统社会的人</h2><p id="748f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">输入展平后，它会穿过密集层。密集层完成了它的任务，然后就在我们到达最后一个密集层之前，我们做了一件叫做<strong class="lb iu">辍学</strong>的事情。放弃神经元是将一些输出神经元随机设置为零，只是为了加快训练和反向传播过程，并防止<a class="ae ky" href="https://www.investopedia.com/terms/o/overfitting.asp" rel="noopener ugc nofollow" target="_blank">过度拟合</a>我们的网络。</p><h1 id="29d3" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">第 3 部分:训练网络</h1><p id="1729" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">你刚刚学会如何建立一个 CNN，但一个未经训练的网络有什么用！要掌握 CNN 的艺术，你也必须知道如何训练他们。在本文中，我将讨论 CNN 中使用的<strong class="lb iu">损失函数</strong>和<strong class="lb iu">优化器</strong>。</p><h2 id="e9ea" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">损失函数</h2><p id="154c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">简而言之，损失函数是一种计算数据精确度的方法。任何优化问题(任何神经网络)的目标都是最小化代价函数。</p><p id="dc33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有各种类型的损失函数。在 CNN 的，使用的损失函数是交叉熵。交叉熵计算概率分布(可以是向量、矩阵、张量等)之间的差异。)和标签的概率分布。</p><p id="1049" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中(在 CNN 中)，数据用向量表示。交叉熵损失计算标签向量(y)中每个元素与网络输出向量(X)之间的差值，然后将所有这些值相加，得出网络的总损失。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/9bd699b22b6edcb13aa0ab2688242f94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*apuoPg3nZ2CMXM3_"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">交叉熵损失的可视化(<a class="ae ky" href="https://www.youtube.com/watch?v=tRsSi_sqXjI" rel="noopener ugc nofollow" target="_blank">来源:Udacity </a></p></figure><p id="7d97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那里陈述的公式包括一些非常密集的数学符号，所以如果你想在数学上更深入，我建议你去下面的链接。然而，你不需要精通数学来写 CNN(特别是在像 Keras 或 Pytorch 这样的框架中，因为你只需要写<em class="lv">“loss = cross _ entropy</em>”，Keras/Pytorch 会处理剩下的)。</p><h2 id="d085" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">最佳化</h2><p id="aa27" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">机器学习中的优化是找到将返回最低成本(损失)的最佳权重/偏差。优化器就是一种能做到这一点的算法。在 CNN(和大多数其他深度神经网络)中，我们使用<strong class="lb iu"> Adam </strong>优化器。</p><p id="efd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你真的有兴趣学习更多关于 Adam 优化器的知识，戴上你的统计学和微积分头盔，点击下面的链接。</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/adam-latest-trends-in-deep-learning-optimization-6be9a291375c"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">Adam——深度学习优化的最新趋势。</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">Adam 是一种自适应学习率优化算法，专为训练深度神经…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc ks no"/></div></div></a></div><p id="8ddb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像以前一样，您不需要理解优化器如何工作背后的本质数学。在 Keras 中，使用 Adam 优化器仅仅是一行代码(<em class="lv"> optimizer="Adam") </em></p><h1 id="3a72" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">这是一个总结！</h1><p id="e0c2" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">厉害！你现在知道了 CNN 的基本知识，所以现在你应该选择一个你真正热爱的 CNN 项目，这样你就可以去应用你刚刚学到的东西。同时，看看下面这个很棒的教程，在那里我学会了如何写一个路标分类器！</p><div class="nl nm gp gr nn no"><a href="https://www.pyimagesearch.com/2019/11/04/traffic-sign-classification-with-keras-and-deep-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">基于 Keras 和深度学习的交通标志分类</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">在本教程中，您将学习如何训练自己的交通标志分类器/识别器能够获得 95%以上的…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">www.pyimagesearch.com</p></div></div><div class="nx l"><div class="od l nz oa ob nx oc ks no"/></div></div></a></div><h1 id="525b" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">关键要点</h1><p id="3d94" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">总结一下这一切:</p><ul class=""><li id="d7be" class="oe of it lb b lc ld lf lg li og lm oh lq oi lu oj ok ol om bi translated">CNN 是一种深度神经网络，通常用于图像数据和复杂的分类问题。</li><li id="96e7" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">CNN 的架构涉及各种类型的层，包括:卷积、最大池化、密集、丢弃。</li><li id="28f9" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated"><strong class="lb iu">卷积层</strong>通过将过滤矩阵与图像张量相乘，从图像中提取特征信息，创建图像的过滤层。这是所有学习发生的地方</li><li id="1367" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">然后，合并过滤层(过滤层的大小减小)。这是通过<strong class="lb iu">最大池完成的。</strong></li><li id="da32" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">在图像通过几个卷积+最大池层后，它得到<strong class="lb iu">展平</strong>并进入<strong class="lb iu">密集</strong>层。</li><li id="9b63" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">在致密层完成它的工作后，一些神经元被随机丢弃以防止过度拟合。</li><li id="43f2" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">我们使用<strong class="lb iu"> Adam </strong>优化器和<strong class="lb iu">交叉熵</strong>损失来训练我们的模型。</li></ul><p id="d75f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在是时候建立你自己的 CNN 了！</p></div></div>    
</body>
</html>