<html>
<head>
<title>Cryptocurrency Prediction with LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用LSTM预测加密货币</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cryptocurrency-prediction-with-lstm-4cc369c43d1b?source=collection_archive---------13-----------------------#2020-04-15">https://towardsdatascience.com/cryptocurrency-prediction-with-lstm-4cc369c43d1b?source=collection_archive---------13-----------------------#2020-04-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="55ff" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何预测汇率的趋势</h2></div><p id="b4a5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然第一种重新分配的加密货币(比特币)是在2009年创造的，但数字货币的想法却出现在20世纪80年代。近年来，加密货币获得了惊人的流行。作为传统货币，加密货币的价值随着时间而变化。使用历史数据，我将使用LSTM(长短期记忆)层实现一个递归神经网络，以预测未来加密货币价值的趋势。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/29511698a29afa8f0a05a272dbc94c7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vYNt-n4vXZN0XCBpVxwfrw.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">安德烈·弗朗索瓦·麦肯齐在<a class="ae lu" href="https://unsplash.com/s/photos/bitcoin?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="e428" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Kaggle上有一个关于<a class="ae lu" href="https://www.kaggle.com/jessevent/all-crypto-currencies" rel="noopener ugc nofollow" target="_blank">加密货币市场</a>价格的庞大数据集。我只使用莱特币历史价格数据的一部分。</p><p id="8d67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和往常一样，我们从导入库开始:</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="a64a" class="ma mb it lw b gy mc md l me mf">import numpy as np<br/>import pandas as pd</span><span id="eee9" class="ma mb it lw b gy mg md l me mf">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>sns.set(style="darkgrid", font_scale=1.5)</span><span id="20f5" class="ma mb it lw b gy mg md l me mf">%matplotlib inline</span></pre><p id="178f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">导入库后，我们现在可以获得我们需要的数据:</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="e99f" class="ma mb it lw b gy mc md l me mf">df = pd.read_csv("crypto-markets.csv", parse_dates=["date"], index_col="date")</span><span id="d7e7" class="ma mb it lw b gy mg md l me mf">df.shape<br/>(942297, 12)</span><span id="e9c1" class="ma mb it lw b gy mg md l me mf">df.head()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mh"><img src="../Images/f69c59242b2663f37c4a86067b92806c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9vGmbavwQrVGqMkeBiOy5A.png"/></div></div></figure><p id="4df7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该数据集包括近100万行。我只需要“莱特币”的“开放”王子。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="eb1f" class="ma mb it lw b gy mc md l me mf">df = df[df.slug == "litecoin"][["open"]]</span><span id="5257" class="ma mb it lw b gy mg md l me mf">df.shape<br/>(2042, 1)</span></pre><p id="1a4d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在有莱特币从2013年4月到2018年11月的历史数据。让我们来看看它是如何随着时间而变化的。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="92ba" class="ma mb it lw b gy mc md l me mf">plt.figure(figsize=(12,6))<br/>sns.lineplot(x=df.index, y="open", data=df).set_title("Price of Litecoin")</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mi"><img src="../Images/907f26a4eed462e175376cefd0efb5a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iq19VhwjbEpj1PTki0rxzQ.png"/></div></div></figure><p id="306a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在经历了2013年底的一个小高峰后，市场陷入了长时间的沉默。然后在2017年底达到最高值。我们可以通过应用下采样使图形看起来更平滑。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="7f80" class="ma mb it lw b gy mc md l me mf">df.resample('10D').mean().plot(figsize=(12,6))</span><span id="0145" class="ma mb it lw b gy mg md l me mf">plt.figtext(.5,0.9,"Down-sampled to 10-day periods", fontsize=20, ha='center')</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mj"><img src="../Images/34b86c75310123a29cb7492e2bfc84d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8BqYd61WZOmmneXcHtKrMA.png"/></div></div></figure></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="5d90" class="mr mb it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated"><strong class="ak">型号</strong></h1><p id="0ca4" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">长短期记忆(LSTM)是一种递归神经网络(RNN ),对序列数据建模非常强大，因为它保持一种内部状态来跟踪它已经看到的数据。LSTMs的常见应用包括时间序列分析和自然语言处理。</p><p id="e366" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">LSTM要求输入是具有形状(batch_size，timesteps，input_dim)的3D张量。</p><p id="6eeb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将建立一个模型，使用过去的90个值(从t-90到t-1)预测时间t时莱特币的价值。因此<strong class="kk iu">时间步长</strong>的数量是90。我仅使用“开盘价”进行预测，因此<strong class="kk iu"> input_dim </strong>为1。目标变量是莱特币的“公开”价格，它会受到许多其他因素的影响。例如，另一种加密货币的价值可能会对莱特币产生影响。如果我们还使用第二个变量来进行预测，那么input_dim将是2。</p><h1 id="86ef" class="mr mb it bd ms mt nn mv mw mx no mz na jz np ka nc kc nq kd ne kf nr kg ng nh bi translated"><strong class="ak">数据预处理</strong></h1><p id="2d6b" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">我将重新组织数据，使用前90天的值序列来预测时间t的值。由于在神经网络中进行了过多的计算，因此最好将这些值标准化。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="d095" class="ma mb it lw b gy mc md l me mf">data = df.iloc[:, 0]</span><span id="b310" class="ma mb it lw b gy mg md l me mf">hist = []<br/>target = []<br/>length = 90</span><span id="8090" class="ma mb it lw b gy mg md l me mf">for i in range(len(data)-length):<br/>    x = data[i:i+length]<br/>    y = data[i+length]<br/>    hist.append(x)<br/>    target.append(y)</span></pre><p id="5566" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一个元素的最后一个时间步长与原始数据的第90个时间步长相同，这正是我们计划要做的。</p><p id="7900" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">hist的第二个元素应该只是第一个元素的一个时间步长偏移版本。因此，第二个元素中的最后一个时间步长应该等于目标变量的第一项，即原始数据中的第91个时间步长。</p><p id="9d7a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们仔细检查以确认:</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="c97a" class="ma mb it lw b gy mc md l me mf">print(hist[1][89])<br/>print(data[90])<br/>print(target[0])</span><span id="fe49" class="ma mb it lw b gy mg md l me mf">2.9<br/>2.9<br/>2.9</span></pre><p id="62f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Hist和target是列表。我们需要将它们转换成numpy数组，并对目标变量进行整形。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="291f" class="ma mb it lw b gy mc md l me mf">hist = np.array(hist)<br/>target = np.array(target)</span><span id="819d" class="ma mb it lw b gy mg md l me mf">target = target.reshape(-1,1)</span></pre><p id="983f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们检查历史数组和目标数组的形状:</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="4b4c" class="ma mb it lw b gy mc md l me mf">hist.shape<br/>(1952, 90)</span><span id="7a76" class="ma mb it lw b gy mg md l me mf">target.shape<br/>(1952, 1)</span></pre><p id="02e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Hist阵列包括1952个观测值，每个观测值包括90个时间步长(90天)。</p><p id="232b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们可以对数据进行归一化，压缩0到1范围内的所有数据点，使最大值和最小值分别为1和0。标准化可以通过应用一个简单的数学方程或者仅仅使用一个像<strong class="kk iu"> MinMaxScaler </strong>这样的函数来完成。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="4586" class="ma mb it lw b gy mc md l me mf">from sklearn.preprocessing import MinMaxScaler</span><span id="9d3a" class="ma mb it lw b gy mg md l me mf">sc = MinMaxScaler()<br/>hist_scaled = sc.fit_transform(hist)<br/>target_scaled = sc.fit_transform(target)</span></pre><p id="8a56" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">预处理的最后一步是调整输入数组的形状，使其与LSTM图层兼容。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="72e2" class="ma mb it lw b gy mc md l me mf">hist_scaled = hist_scaled.reshape((len(hist_scaled), length, 1))<br/>print(hist_scaled.shape)<br/>(1952, 90, 1)</span></pre><h1 id="d3db" class="mr mb it bd ms mt nn mv mw mx no mz na jz np ka nc kc nq kd ne kf nr kg ng nh bi translated"><strong class="ak">训练和测试集</strong></h1><p id="950b" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">我们的数据集包括1951个样本(天)。输入样本包括连续90天的莱特币价值，目标变量是90天后第二天的莱特币价值。</p><p id="257e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将以一种方式分割数据集，即1900个样本用于训练，然后该模型将用于预测未来51天的趋势。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="2561" class="ma mb it lw b gy mc md l me mf">X_train = hist_scaled[:1900,:,:]<br/>X_test = hist_scaled[1900:,:,:]</span><span id="0ca5" class="ma mb it lw b gy mg md l me mf">y_train = target_scaled[:1900,:]<br/>y_test = target_scaled[1900:,:]</span></pre><h1 id="d8fc" class="mr mb it bd ms mt nn mv mw mx no mz na jz np ka nc kc nq kd ne kf nr kg ng nh bi translated"><strong class="ak">构建神经网络</strong></h1><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="bb8c" class="ma mb it lw b gy mc md l me mf">import tensorflow as tf</span><span id="1bc8" class="ma mb it lw b gy mg md l me mf">from tensorflow.keras import layers</span></pre><p id="9d07" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将建立一个有3个LSTM层和1个输出层的密集层的模型。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="f4de" class="ma mb it lw b gy mc md l me mf">model = tf.keras.Sequential()</span><span id="62da" class="ma mb it lw b gy mg md l me mf">model.add(layers.LSTM(units=32, return_sequences=True,<br/>                  input_shape=(90,1), dropout=0.2))</span><span id="a6a2" class="ma mb it lw b gy mg md l me mf">model.add(layers.LSTM(units=32, return_sequences=True,<br/>                  dropout=0.2))</span><span id="61a3" class="ma mb it lw b gy mg md l me mf">model.add(layers.LSTM(units=32, dropout=0.2))</span><span id="0450" class="ma mb it lw b gy mg md l me mf">model.add(layers.Dense(units=1))</span><span id="6a80" class="ma mb it lw b gy mg md l me mf">model.summary()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/9d5fcf8387d97538dbc45556ccb913fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*kFr9vMzAaxy3J6EaAphBug.png"/></div></figure><p id="ba0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在需要编译模型。编译模型时，应选择用于调整权重的优化器。Tensorflow提供了许多优化器。回归任务中常用的优化器有“adam”和“rmsprop”。此外，应该选择损失函数。由于这是一个回归任务，我们可以选择“均方误差”。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="f6a4" class="ma mb it lw b gy mc md l me mf">model.compile(optimizer='adam', loss='mean_squared_error')</span></pre><p id="d52a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">是时候训练模型了。我们需要在这里指定两个超参数:</p><ul class=""><li id="409b" class="nt nu it kk b kl km ko kp kr nv kv nw kz nx ld ny nz oa ob bi translated">batch_size=在更新模型的内部参数之前，通过神经网络工作的样本数。如果batch_size为1，则在将每个样本(或观察值)馈送到神经网络后，会更新参数。</li><li id="c8ab" class="nt nu it kk b kl oc ko od kr oe kv of kz og ld ny nz oa ob bi translated">次数:整个训练集向前和向后通过神经网络的次数。</li></ul><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="1b67" class="ma mb it lw b gy mc md l me mf">history = model.fit(X_train, y_train, epochs=30, batch_size=32)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oh"><img src="../Images/56a2c7961ab07fcfedca526ba198fe22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*GyTddFTqrV_UHPKn0tSCIw.png"/></div></div></figure><p id="0f51" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型似乎在30个时期内收敛，因此没有必要进行额外的时期。损失不到0.002我觉得已经很不错了。</p><p id="cbab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们想象一下随着时代数量的增加，损失是如何变化的。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="fb86" class="ma mb it lw b gy mc md l me mf">loss = history.history['loss']<br/>epoch_count = range(1, len(loss) + 1)<br/>plt.figure(figsize=(12,8))<br/>plt.plot(epoch_count, loss, 'r--')<br/>plt.legend(['Training Loss'])<br/>plt.xlabel('Epoch')<br/>plt.ylabel('Loss')<br/>plt.show();</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oi"><img src="../Images/d540209157904a6d6b0c7101200d2483.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KGGRfb11g5uFf5GPB5DL4w.png"/></div></div></figure><p id="4ac7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看起来这个模型在15个纪元后已经收敛了。之后亏损在0.0018附近上下反弹。</p><p id="1b1c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在是做预测的时候了。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="5f52" class="ma mb it lw b gy mc md l me mf">pred = model.predict(X_test)</span><span id="a7b1" class="ma mb it lw b gy mg md l me mf">plt.figure(figsize=(12,8))<br/>plt.plot(y_test, color='blue', label='Real')<br/>plt.plot(pred, color='red', label='Prediction')<br/>plt.title('Litecoin Price Prediction')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oj"><img src="../Images/05a1a469a73d903335c9cd09d577310e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eu7P1xpxF5dXCo_JCTi6NQ.png"/></div></div></figure><p id="ee20" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的模型很好地确定了趋势。您可能已经注意到，这些值比原始值小得多，因为我们在训练模型之前对这些值进行了规范化。我们可以进行逆变换来反映真实价格，但趋势是相同的。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="4756" class="ma mb it lw b gy mc md l me mf">pred_transformed = sc.inverse_transform(pred)<br/>y_test_transformed = sc.inverse_transform(y_test)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ok"><img src="../Images/9bda95f40f22e815ae5fe1a725b9fc71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kmPtp-RrQ5INXtpUjfBtGw.png"/></div></div></figure><p id="4576" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总有改进的空间。神经网络的燃料是数据，因此我们可以通过收集更多的数据来建立一个更鲁棒和准确的模型。我们还可以尝试调整一层中的节点数量或添加额外的LSTM层。我们还可以尝试增加时间步长的数量，在我们的模型中是90。另一种改进方法是使用GridSearchCV调整参数。</p><p id="5700" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住，提高模型精度并不总是好的，因为我们最终可能会有一个过度拟合的模型。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="a756" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以在这里找到整个jupyter笔记本。</p><p id="c668" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>