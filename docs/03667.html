<html>
<head>
<title>A Quick Guide to Tokenization and Phrase Matching using spaCy | NLP | Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 spaCy | NLP |进行标记化和短语匹配的快速指南第 2 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc?source=collection_archive---------28-----------------------#2020-04-06">https://towardsdatascience.com/a-quick-guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy-nlp-b29b407adbfc?source=collection_archive---------28-----------------------#2020-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="50ee" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 spaCy 的文本预处理步骤，NLP 库</h2></div><p id="1bc5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">spaCy</strong>是专门为<strong class="kk iu">生产使用</strong>而设计的。它帮助您构建处理和“理解”大量文本的应用程序。它可以用来构建<strong class="kk iu">信息抽取</strong>或<strong class="kk iu">自然语言理解</strong>系统或为<strong class="kk iu">深度学习</strong>预处理文本。在本文中，您将了解使用 spaCy 的标记化、词条化、停用词和短语匹配操作。</p><p id="7101" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是<strong class="kk iu">空间系列</strong>的第二篇文章。在我的上一篇文章中，我已经解释了空间安装和基本操作。如果您对此不熟悉，我建议从第 1 条开始，以便更好地理解。</p><blockquote class="le lf lg"><p id="f3f8" class="ki kj lh kk b kl km ju kn ko kp jx kq li ks kt ku lj kw kx ky lk la lb lc ld im bi translated"><em class="it">第一条— </em> <a class="ae ll" href="https://ashutoshtripathi.com/2020/04/02/spacy-installation-and-basic-operations-nlp-text-processing-library/" rel="noopener ugc nofollow" target="_blank"> <em class="it">空间-安装-基础-操作-自然语言处理-文本处理-库/ </em> </a></p></blockquote><h1 id="3c61" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">标记化</h1><p id="5107" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">标记化是文本处理任务的第一步。记号化不仅仅是将文本分解成单词、标点符号等称为记号的部分。然而，还不止这些。spaCy do 智能标记器，它在内部识别一个“.”是标点符号并将其分隔成标记，或者它是缩写(如“美国”)的一部分，但不要分隔它。</p><p id="cad1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> spaCy </strong>应用特定于语言类型的规则。我们用一个例子来理解。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="9952" class="ms ln it mo b gy mt mu l mv mw">import spacy<br/>nlp = spacy.load("en_core_web_sm")</span><span id="6cc5" class="ms ln it mo b gy mx mu l mv mw">doc = nlp("\"Next Week, We're coming from U.S.!\"")<br/> for token in doc:<br/> print(token.text)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div class="gh gi my"><img src="../Images/9408a6085acf638ad1eafca92d4ed97b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/0*8TJlJHr6JFxIIC0p"/></div></figure><ul class=""><li id="9c3d" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated"><strong class="kk iu">空白</strong>首先根据原始文本中的可用空白开始拆分。</li><li id="2ef6" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">然后，它从左到右处理文本，并对每个项目(基于空白的拆分器)执行以下两项检查:</li><li id="50d0" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><strong class="kk iu">例外规则检查:</strong>“美国”中可用的标点符号不应被视为进一步的标记。它应该保持不变。然而，我们的惶然应该被分裂成“我们”和“‘惶然’</li><li id="6ed9" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><strong class="kk iu">前缀、后缀和中缀检查:</strong>标点符号，如逗号、句号、连字符或引号，将被视为标记并分离出来。</li></ul><p id="c5be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果匹配，则应用规则，标记器继续循环，从新分割的子字符串开始。这样，spaCy 可以拆分复杂的嵌套标记，如缩写和多个标点符号的组合。</p><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/76dede94536d326068074bbc4d9113ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eU1iDZhLzCuef1yf"/></div></div></figure><ul class=""><li id="3256" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated"><strong class="kk iu">前缀</strong>:查找开头的字符<code class="fe nv nw nx mo b">$ ( " ¿</code></li><li id="ffd8" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><strong class="kk iu">后缀</strong>:查找末尾的字符<code class="fe nv nw nx mo b">mm ) , . ! "</code> mm 是一个单位的例子</li><li id="72d9" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><strong class="kk iu">中缀</strong>:查找中间的字符<code class="fe nv nw nx mo b">- -- / ...</code></li><li id="def3" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><strong class="kk iu">异常</strong>:特殊情况规则，当应用标点规则时，将一个字符串拆分成几个记号或防止一个记号被拆分<code class="fe nv nw nx mo b">St. N.Y.</code></li></ul><p id="e13a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，标记是原始文本的一部分。标记是 Doc 对象的基本构建块——帮助我们理解文本含义的一切都是从标记及其相互关系中派生出来的。</p><h1 id="a2ba" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">作为标记的前缀、后缀和中缀</h1><ul class=""><li id="1755" class="nc nd it kk b kl me ko mf kr ny kv nz kz oa ld nh ni nj nk bi translated">空格将分隔不构成单词组成部分的标点符号。</li><li id="e6d6" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">句子末尾的引号、逗号和标点符号将被赋予各自的符号。</li><li id="bf6b" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">但是，作为电子邮件地址、网站或数值的一部分存在的标点符号将作为令牌的一部分保留。</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="6528" class="ms ln it mo b gy mt mu l mv mw">doc2 = nlp(u"We're here to guide you! Send your query, email contact@enetwork.ai or visit us at http://www.enetwork.ai!")</span><span id="7ccb" class="ms ln it mo b gy mx mu l mv mw">for t in doc2:<br/> print(t)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi ob"><img src="../Images/47c7de2fd81d1878e99f4521d1b17555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3XDZZvJAIAwzQudp"/></div></div></figure><p id="e7d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">注意</strong>感叹号、逗号都被赋予了自己的记号。然而，电子邮件地址和网站 URL 中的冒号并不是孤立的。因此，电子邮件地址和网站都会保留。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="9e45" class="ms ln it mo b gy mt mu l mv mw">doc3 = nlp(u'A 40km U.S. cab ride costs $100.60')<br/>for t in doc3:<br/> print(t)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/a5447e9e6cd1d1f3584852c241cd255a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/0*qxjRwm2g2DKRlmSX"/></div></figure><p id="065f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，距离单位和美元符号被赋予它们自己的记号，然而，美元数量被保留，数量中的点不是孤立的。</p><h1 id="f98c" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">令牌生成中的异常</h1><p id="bde6" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">作为已知缩写的一部分存在的标点符号将作为标记的一部分保留。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="4c02" class="ms ln it mo b gy mt mu l mv mw">doc4 = nlp(u"Let's visit the St. Louis in the U.S. next year.")<br/>for t in doc4:<br/> print(t)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi od"><img src="../Images/fce48c0380fa7347f79863f64e9aa0ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bLJnbewFMOVPdNqw"/></div></div></figure><p id="7dcb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里,“圣”和“美国”的缩写都保留了下来。St .旁边的均值点不作为令牌分开。美国也一样。</p><h1 id="a654" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">清点代币</h1><p id="59fd" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">使用 len()函数，可以计算文档中的标记数。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="32f4" class="ms ln it mo b gy mt mu l mv mw">len(doc4)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/ecad13c603c5bb34c2f96c1615c90e2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/0*mNwzU5sk0Di7Ukpq"/></div></figure><h1 id="01ea" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">统计 Vocab 条目</h1><p id="7baa" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated"><code class="fe nv nw nx mo b">Vocab</code>对象包含一个完整的项目库！</p><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div class="gh gi of"><img src="../Images/3ce6c572da0b000997b9797e3c4f0a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/0*Gvj0OcuIuHcuHdPj"/></div></figure><p id="76bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，所有的 doc 对象都是从英语语言模型创建的，我们在开始时使用</p><blockquote class="le lf lg"><p id="94d7" class="ki kj lh kk b kl km ju kn ko kp jx kq li ks kt ku lj kw kx ky lk la lb lc ld im bi translated"><code class="fe nv nw nx mo b"><em class="it">nlp = spacy.load("en_core_web_sm")</em></code></p></blockquote><p id="d678" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此 vocab len 将是相同的。</p><h1 id="a999" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">令牌中的索引和切片</h1><ul class=""><li id="8e7e" class="nc nd it kk b kl me ko mf kr ny kv nz kz oa ld nh ni nj nk bi translated"><code class="fe nv nw nx mo b">Doc</code>对象可以被认为是<code class="fe nv nw nx mo b">token</code>对象的列表。</li><li id="adc9" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">因此，可以通过索引位置检索各个标记。</li><li id="fa1c" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">可以通过切片来检索令牌的跨度:</li></ul><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/9a7aaf5985b3a172437444fa53bb7c9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6-3RKIpa57umXoqv"/></div></div></figure><h1 id="a9fc" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">不允许分配令牌</h1><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi og"><img src="../Images/03dfd85aff495b3617a1dd4e835d0087.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Cm6AD1_cpT-34yVX"/></div></div></figure><h1 id="e77e" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">词汇化</h1><ul class=""><li id="2c78" class="nc nd it kk b kl me ko mf kr ny kv nz kz oa ld nh ni nj nk bi translated">与词干化相反，词汇化看起来不仅仅是单词缩减，而是考虑一种语言的全部词汇来对单词进行形态分析。</li><li id="a670" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">was 的引理是 be，rats 的引理是 rat，mice 的引理是 mouse。此外,“meeting”的引理可能是“meet”或“meeting ”,这取决于它在句子中的用法。</li><li id="dce3" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">词汇化查看周围的文本来确定给定单词的词性。它不对短语进行分类。</li></ul><p id="e576" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">注意</strong>空间没有词干。因为变元化被认为比词干化更能提供信息。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="1a07" class="ms ln it mo b gy mt mu l mv mw">doc1 = nlp(u"I am a runner running in a race because I love to run since I ran today")<br/>for token in doc1:<br/> print(token.text, '\t', token.pos_, '\t', token.lemma, '\t', token.lemma_)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi oh"><img src="../Images/255d7eb2c301940cc2c11c602da1056a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qtDp_T_5RxkPdYdC"/></div></div></figure><p id="b9d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">创建一个函数，以更结构化的方式查找并打印词条</strong>。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="24fb" class="ms ln it mo b gy mt mu l mv mw">def find_lemmas(text): for token in text: print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:&lt;{22}}{token.lemma_}')</span></pre><p id="900e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，我们使用一个<strong class="kk iu"> f 字符串</strong>通过设置最小字段宽度和添加 lemma 哈希值的左对齐来格式化打印文本。</p><p id="9e2c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们调用这个函数</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="826d" class="ms ln it mo b gy mt mu l mv mw">doc2 = nlp(u"I saw eighteen mice today!")<br/>find_lemmas(doc2)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/4d2d6a8f531869ba4b8a45fc3909d0b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*scYcBt5rmSox8lyf"/></div></div></figure><p id="f018" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">注意</strong>中<code class="fe nv nw nx mo b">saw</code>的引理是<code class="fe nv nw nx mo b">see</code>,<code class="fe nv nw nx mo b">mice</code>的引理是<code class="fe nv nw nx mo b">mouse</code> , <code class="fe nv nw nx mo b">mice</code>是<code class="fe nv nw nx mo b">mouse</code>的复数形式，see <code class="fe nv nw nx mo b">eighteen</code>是一个数，<em class="lh">不是</em>是<code class="fe nv nw nx mo b">eight</code>的扩展形式，这是在计算引理时检测到的，因此保持<code class="fe nv nw nx mo b">eighteen</code>不变。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="527e" class="ms ln it mo b gy mt mu l mv mw">doc3 = nlp(u"I am meeting him tomorrow at the meeting.")<br/>find_lemmas(doc3)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/7f4634096c3fa43b16979f18b27bd996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/0*5XDbjyHl0O3Bl2r8"/></div></figure><p id="c8be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里<code class="fe nv nw nx mo b">meeting</code>的引理是由其词性标签决定的。</p><p id="f202" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于作为动词的第一个<code class="fe nv nw nx mo b">meeting</code>，它已经将引理计算为<code class="fe nv nw nx mo b">meet</code>。第二个<code class="fe nv nw nx mo b">meeting</code>是一个名词，它将引理计算为<code class="fe nv nw nx mo b">meeting</code>本身。</p><p id="e9a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是我们可以看到 spaCy 在计算引理时处理词性的地方。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="48bd" class="ms ln it mo b gy mt mu l mv mw">doc4 = nlp(u"That's an enormous automobile")<br/>find_lemmas(doc4)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/848afef005b8dd9051e611e5d74c7029.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/0*PfUTh43cFK1uWjF1"/></div></figure><p id="ada5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">注意</strong>词汇化不会<em class="lh">而不是</em>将单词缩减到它们最基本的同义词——也就是说<code class="fe nv nw nx mo b">enormous</code>不会变成<code class="fe nv nw nx mo b">big</code>,<code class="fe nv nw nx mo b">automobile</code>不会变成<code class="fe nv nw nx mo b">car</code>。</p><h1 id="5341" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">停止言语</h1><ul class=""><li id="7946" class="nc nd it kk b kl me ko mf kr ny kv nz kz oa ld nh ni nj nk bi translated">像“a”和“the”这样的词出现得如此频繁，以至于它们不像名词、动词和修饰语那样需要彻底标记。</li><li id="93c2" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">我们称之为<em class="lh">停用词</em>，可以从待处理的文本中筛选出来。</li><li id="c395" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">spaCy 有一个内置列表，里面有大约 305 个英文停用词。</li></ul><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/6ee8a14eb4150cac9bbda5eee8e2c24e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jaqDkOF8sW4NJb5N"/></div></div></figure><p id="6272" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">您可以使用</strong> <code class="fe nv nw nx mo b">len()</code> <strong class="kk iu">功能</strong>打印停用词的总数。</p><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/ebeeda154b0ce5660d10cc3e746d85b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/0*RYq-Idnh4pe_52as"/></div></figure><h1 id="0204" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">添加用户定义的停用词</h1><p id="cf4d" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">有时，您可能希望在默认集合中添加停用字词。也许你决定<code class="fe nv nw nx mo b">'btw'</code>(“顺便说一下”的常用简写)应该被认为是一个停用词。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="1711" class="ms ln it mo b gy mt mu l mv mw">#Add the word to the set of stop words. Use lowercase!<br/>nlp.Defaults.stop_words.add('btw') #alwasy use lowercase while adding the stop words</span><span id="1afd" class="ms ln it mo b gy mx mu l mv mw">#Set the stop_word tag on the lexeme<br/>nlp.vocab['btw'].is_stop = True</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi ol"><img src="../Images/fee226290e8aa345cdac20d5004d1c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BIBhaVwgIWl4ejZE"/></div></div></figure><h1 id="c3f1" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">删除停用词</h1><p id="5f03" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">或者，您可以决定<code class="fe nv nw nx mo b">'without'</code>不应被视为停用词。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="fa95" class="ms ln it mo b gy mt mu l mv mw">#Remove the word from the set of stop words<br/>nlp.Defaults.stop_words.remove('without')</span><span id="161c" class="ms ln it mo b gy mx mu l mv mw">#Remove the stop_word tag from the lexeme<br/>nlp.vocab['without'].is_stop = False</span><span id="41f6" class="ms ln it mo b gy mx mu l mv mw">len(nlp.Defaults.stop_words)</span><span id="e8db" class="ms ln it mo b gy mx mu l mv mw">nlp.vocab['beyond'].is_stop</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/6de25d5d1e031c9572af1dea9873ac26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/0*VYd1uhkRDiK8yvc8"/></div></figure><h1 id="38f3" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">词汇和匹配</h1><p id="dec2" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">在这一部分中，我们将识别和标记与我们自己定义的模式相匹配的特定短语。</p><h1 id="b29e" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">基于规则的匹配</h1><ul class=""><li id="102d" class="nc nd it kk b kl me ko mf kr ny kv nz kz oa ld nh ni nj nk bi translated">spaCy 提供了一个名为<code class="fe nv nw nx mo b">Matcher</code>的规则匹配工具。</li><li id="1a76" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">它允许您构建一个令牌模式库。</li><li id="d56f" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">然后，它将这些模式与 Doc 对象进行匹配，以返回找到的匹配项的列表。</li></ul><p id="255c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以匹配令牌的任何部分，包括文本和注释，并且可以向同一个匹配器添加多个模式。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="7b2c" class="ms ln it mo b gy mt mu l mv mw">#Import the Matcher library<br/>from spacy.matcher import Matcher<br/>matcher = Matcher(nlp.vocab)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div class="gh gi om"><img src="../Images/8ebcad6802e832d94fad050b4b31a46a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/0*FshAneo3toFtGjaC"/></div></figure><h1 id="c616" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">创建模式</h1><p id="b898" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">在文学作品中,“united states”这个短语可能是一个或两个单词，带或不带连字符。在这一节中，我们将开发一个名为“unitedstates”的匹配器来查找所有三个:</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="debc" class="ms ln it mo b gy mt mu l mv mw">pattern1 = [{'LOWER': 'unitedstates'}]<br/>pattern2 = [{'LOWER': 'united'}, {'LOWER': 'states'}]<br/>pattern3 = [{'LOWER': 'united'}, {'IS_PUNCT': True}, {'LOWER': 'states'}]</span><span id="2ed8" class="ms ln it mo b gy mx mu l mv mw">matcher.add('UnitedStates', None, pattern1, pattern2, pattern3)</span></pre><p id="4568" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">进一步打破它:</p><ul class=""><li id="5457" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated"><code class="fe nv nw nx mo b">pattern1</code>查找小写文本为“unitedstates”的单个令牌</li><li id="e7c9" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><code class="fe nv nw nx mo b">pattern2</code>按顺序查找两个相邻的单词“united”和“states”</li><li id="8068" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><code class="fe nv nw nx mo b">pattern3</code>查找三个相邻的记号，中间的记号可以是任何标点。*</li></ul><p id="fec9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">*请记住，单个空格是没有标记的，所以它们不算标点符号。<br/>一旦我们定义了我们的模式，我们将它们传递给名为‘United States’的<code class="fe nv nw nx mo b">matcher</code>，并将<em class="lh">回调</em>设置为<code class="fe nv nw nx mo b">None</code></p><h1 id="723d" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">将匹配器应用于 Doc 对象</h1><p id="3cdc" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">为了让你明白，我把美国写成了不同的形式，比如“美国”、“美国”、“美国”和“美国”</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="95b5" class="ms ln it mo b gy mt mu l mv mw">doc = nlp(u'The United States of America is a country consisting of 50 independent states. The first constitution of the UnitedStates was adopted in 1788. The current United-States flag was designed by a high school student - Robert G. Heft.')</span><span id="fbe3" class="ms ln it mo b gy mx mu l mv mw">found_matches = matcher(doc)<br/>print(found_matches)</span><span id="4ea5" class="ms ln it mo b gy mx mu l mv mw">for match_id, start, end in found_matches:<br/> string_id = nlp.vocab.strings[match_id] # get string representation<br/> span = doc[start:end] # get the matched span<br/> print(match_id, string_id, start, end, span.text)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/360f665f70632573cd79b5b474014117.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*J08xakuVbox3a85n"/></div></div></figure><h1 id="a636" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">设置模式选项和量词</h1><p id="de2b" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">您可以通过传递一个<code class="fe nv nw nx mo b">'OP':'*'</code>参数来使令牌规则可选。这让我们可以简化我们的模式列表:</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="3dbb" class="ms ln it mo b gy mt mu l mv mw">#Redefine the patterns:<br/>pattern1 = [{'LOWER': 'unitedstates'}]<br/>pattern2 = [{'LOWER': 'united'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'states'}]</span><span id="b5e9" class="ms ln it mo b gy mx mu l mv mw">#Remove the old patterns to avoid duplication:<br/>matcher.remove('UnitedStates')</span><span id="9950" class="ms ln it mo b gy mx mu l mv mw">#Add the new set of patterns to the 'SolarPower' matcher:<br/>matcher.add('someNameToMatcher', None, pattern1, pattern2)</span><span id="5e08" class="ms ln it mo b gy mx mu l mv mw">doc = nlp(u'United--States has the world's largest coal reserves.')</span><span id="0cff" class="ms ln it mo b gy mx mu l mv mw">found_matches = matcher(doc) print(found_matches)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi on"><img src="../Images/b066bee71b5d540821a4d57bd45a4f9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*58l84J9jWqyc2ABv"/></div></div></figure><p id="68a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这找到了两个单词的模式，有和没有连字符！</p><p id="0962" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下量词可以传递给<code class="fe nv nw nx mo b">'OP'</code>键:</p><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi oo"><img src="../Images/63f9bc7203b223678553324546ef0775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DSciBhM2pkTdOcPnWEO7sQ.png"/></div></div></figure><h1 id="7124" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">小心旅鼠！</h1><p id="bed7" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">假设我们在某个句子中有另一个词“太阳能”。现在，如果我们想同时匹配“太阳能”和“太阳能供电”，寻找“供电”的<em class="lh">引理</em>并期望它是“电力”可能很有诱惑力。情况并不总是这样！<em class="lh">形容词</em>‘powered’的引理还是‘powered’:</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="174e" class="ms ln it mo b gy mt mu l mv mw">pattern1 = [{'LOWER': 'solarpower'}]<br/>pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'}, {'LEMMA': 'power'}] # CHANGE THIS PATTERN</span><span id="b437" class="ms ln it mo b gy mx mu l mv mw">#Remove the old patterns to avoid duplication:<br/>matcher.remove('someNameToMatcher') #remove the previously added matcher name</span><span id="1ade" class="ms ln it mo b gy mx mu l mv mw">#Add the new set of patterns to the 'SolarPower' matcher:<br/>matcher.add('SolarPower', None, pattern1, pattern2)</span><span id="1824" class="ms ln it mo b gy mx mu l mv mw">doc2 = nlp(u'Solar-powered energy runs solar-powered cars.')</span><span id="a32a" class="ms ln it mo b gy mx mu l mv mw">found_matches = matcher(doc2)<br/>print(found_matches)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/bd9ffbd004ddf2c1eea09a8bbe30fec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*z7MmoESkzutDlMmm"/></div></div></figure><p id="e835" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">matcher 找到了第一个词，因为 lemmatizer 将“Solar-powered”视为动词，而不是第二个词，因为它认为它是形容词。<br/>对于这种情况，最好设置显式令牌模式。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="b199" class="ms ln it mo b gy mt mu l mv mw">pattern1 = [{'LOWER': 'solarpower'}]<br/>pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'<em class="lh">'}, {'LOWER': 'power'}] pattern3 = [{'LOWER': 'solarpowered'}] pattern4 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'</em>'}, {'LOWER': 'powered'}]</span><span id="3759" class="ms ln it mo b gy mx mu l mv mw">#Remove the old patterns to avoid duplication:<br/>matcher.remove('SolarPower')</span><span id="9f64" class="ms ln it mo b gy mx mu l mv mw">#Add the new set of patterns to the 'SolarPower' matcher:<br/>matcher.add('SolarPower', None, pattern1, pattern2, pattern3, pattern4)</span><span id="2a27" class="ms ln it mo b gy mx mu l mv mw">found_matches = matcher(doc2)<br/>print(found_matches)</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi op"><img src="../Images/dd0b69c6f12e855106aff3b8538c860a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*swrmr-FB4Ci-Qtft"/></div></div></figure><h1 id="7a55" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">其他令牌属性</h1><p id="3425" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">除了引理之外，我们还可以使用各种令牌属性来确定匹配规则:</p><h1 id="39db" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">令牌通配符</h1><p id="7278" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">您可以传递一个空字典<code class="fe nv nw nx mo b">{}</code>作为通配符来表示<strong class="kk iu">任何标记</strong>。例如，您可能想在不知道<code class="fe nv nw nx mo b">#</code>字符后面是什么的情况下检索标签:</p><h1 id="b37c" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">短语匹配器</h1><p id="4905" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">在上一节中，我们使用了令牌模式来执行基于规则的匹配。另一种更有效的方法是在术语列表上进行匹配。在这种情况下，我们使用 PhraseMatcher 从短语列表中创建一个 Doc 对象，并将其传递给<code class="fe nv nw nx mo b">matcher</code>。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="7c95" class="ms ln it mo b gy mt mu l mv mw">#Perform standard imports, reset nlp<br/>import spacy<br/>nlp = spacy.load('en_core_web_sm')</span><span id="32a5" class="ms ln it mo b gy mx mu l mv mw"># Import the PhraseMatcher library<br/>from spacy.matcher import PhraseMatcher<br/>matcher = PhraseMatcher(nlp.vocab)</span></pre><p id="112d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个练习中，我们将导入一篇维基百科上关于<em class="lh">里根经济学</em> <br/>的文章来源:<a class="ae ll" href="https://en.wikipedia.org/wiki/Reaganomics" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Reaganomics</a></p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="a04f" class="ms ln it mo b gy mt mu l mv mw">with open('../TextFiles/reaganomics.txt') as f:<br/>doc3 = nlp(f.read())</span><span id="0717" class="ms ln it mo b gy mx mu l mv mw">#First, create a list of match phrases:<br/>phrase_list = ['voodoo economics', 'supply-side economics', 'trickle-down economics', 'free-market economics']</span><span id="429a" class="ms ln it mo b gy mx mu l mv mw">#Next, convert each phrase to a Doc object:<br/>phrase_patterns = [nlp(text) for text in phrase_list]</span><span id="fbcd" class="ms ln it mo b gy mx mu l mv mw">#Pass each Doc object into matcher (note the use of the asterisk!):<br/>matcher.add('VoodooEconomics', None, *phrase_patterns)</span><span id="eca8" class="ms ln it mo b gy mx mu l mv mw">#Build a list of matches:<br/>matches = matcher(doc3)</span><span id="865c" class="ms ln it mo b gy mx mu l mv mw">#(match_id, start, end)<br/>matches</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi oq"><img src="../Images/46e385b08846420cb1c8231c879d786a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6v0Elelw-llBhIg8"/></div></div></figure><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/2fb0a8571e92244dffd803b36db062b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6QSsOLm4AmgdUxxs"/></div></div></figure><p id="ab7c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">前四个匹配项是里根经济学定义中使用这些术语的地方:</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="6f5c" class="ms ln it mo b gy mt mu l mv mw">doc3[:70]</span></pre><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/36ef2ddb016f89fe10d4077149cc6d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2ks9e39nBceb_U_U"/></div></div></figure><h1 id="c24d" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">查看比赛</h1><p id="7f11" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">有几种方法可以获取匹配周围的文本。最简单的方法是从文档中获取一片比匹配更宽的令牌:</p><figure class="mj mk ml mm gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/320a2b6b12f6f7b5f7e1032fd4af4fef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XRnZUPSzUQ2Babg0"/></div></div></figure><p id="1439" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这都是关于文本预处理操作，包括标记化、词条化、停用词和短语匹配。希望你喜欢这篇文章。</p><p id="3537" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">相关文章:</p><ul class=""><li id="1680" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated"><a class="ae ll" href="https://ashutoshtripathi.com/2020/04/02/spacy-installation-and-basic-operations-nlp-text-processing-library/" rel="noopener ugc nofollow" target="_blank"> Spacy 安装和基本操作| NLP 文本处理库|第 1 部分</a></li><li id="0b9f" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><a class="ae ll" href="https://ashutoshtripathi.com/2020/04/13/parts-of-speech-tagging-and-dependency-parsing-using-spacy-nlp/" rel="noopener ugc nofollow" target="_blank">使用 spaCy | NLP |第 3 部分</a>进行词性标注和依存解析</li><li id="0638" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><a class="ae ll" href="https://ashutoshtripathi.com/2020/04/27/named-entity-recognition-ner-using-spacy-nlp-part-4/" rel="noopener ugc nofollow" target="_blank">命名实体识别 NER 使用空间|自然语言处理|第 4 部分</a></li><li id="3da6" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><a class="ae ll" href="https://ashutoshtripathi.com/2020/05/04/how-to-perform-sentence-segmentation-or-sentence-tokenization-using-spacy-nlp-series-part-5/" rel="noopener ugc nofollow" target="_blank">如何使用 spaCy | NLP 系列|第 5 部分</a>进行句子分割或句子分词</li><li id="446a" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><a class="ae ll" href="https://ashutoshtripathi.com/2020/09/02/numerical-feature-extraction-from-text-nlp-series-part-6/" rel="noopener ugc nofollow" target="_blank">从文本中提取数字特征| NLP 系列|第 6 部分</a></li><li id="9199" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><a class="ae ll" href="https://ashutoshtripathi.com/2020/09/04/word2vec-and-semantic-similarity-using-spacy-nlp-spacy-series-part-7/" rel="noopener ugc nofollow" target="_blank">使用空间的 Word2Vec 和语义相似度| NLP 空间系列|第 7 部分</a></li></ul><p id="4ce5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您有任何改进内容的反馈或想法，请写在下面的评论部分。你的评论很有价值。</p><p id="1649" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谢谢大家！</p><p id="2080" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">参考资料:</p><ul class=""><li id="a3ff" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated"><a class="ae ll" href="https://spacy.io/usage/spacy-101" rel="noopener ugc nofollow" target="_blank">https://spacy.io/usage/spacy-101</a></li><li id="479c" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated"><a class="ae ll" href="https://www.udemy.com/course/nlp-natural-language-processing-with-python/" rel="noopener ugc nofollow" target="_blank">https://www . udemy . com/course/NLP-natural-language-processing-with-python/</a></li></ul></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><p id="636d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lh">原载于 2020 年 4 月 6 日</em><a class="ae ll" href="https://ashutoshtripathi.com/2020/04/06/guide-to-tokenization-lemmatization-stop-words-and-phrase-matching-using-spacy/" rel="noopener ugc nofollow" target="_blank"><em class="lh">【http://ashutoshtripathi.com】</em></a><em class="lh">。</em></p></div></div>    
</body>
</html>