<html>
<head>
<title>Image Classification Pipeline with Intel Neural Compute Stick 2 (NCS2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">采用英特尔神经计算棒 2 (NCS2)的图像分类管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-classification-pipeline-with-intel-neural-compute-stick-2-ncs2-2a69aab8b570?source=collection_archive---------27-----------------------#2020-09-09">https://towardsdatascience.com/image-classification-pipeline-with-intel-neural-compute-stick-2-ncs2-2a69aab8b570?source=collection_archive---------27-----------------------#2020-09-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6024" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">借助这份全面的指南，使用 NCS2 从数据集到影像分类</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/11846c49c623169bb60e0fdb878b0ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z6okCVQ9A2Tdl-Q0Pdeq-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由 Oleksii Sheremet 使用<a class="ae ky" href="https://www.adobe.com/ru/products/photoshop.html" rel="noopener ugc nofollow" target="_blank"> Adobe Photoshop </a>创建</p></figure><p id="4996" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">简介</strong></p><p id="a193" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将在这个故事中讲述的内容:</p><ul class=""><li id="5309" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">安装 OpenVINO toolkit for Ubuntu。</li><li id="3d54" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">用 Google Colab 进行数据预处理和模型训练。</li><li id="f5c5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将张量流模型保存为协议缓冲区(pb)格式。</li><li id="3d34" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将张量流模型转换成中间表示。</li><li id="94f7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用 NCS2 设备运行训练好的模型并获得预测。</li></ul><p id="2e75" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在过去的几年里，机器学习已经被积极地引入到工业任务解决方案中。机器学习可以让你解决人类无法应对的问题。这可以在难以到达地方、在危险的化学生产中、在辐射增加的条件下等工作。机器学习适用于人类智能也可以应用，但无效的领域:预测关键故障、预防突发设备故障、视情维修、预测设备剩余寿命。</p><p id="488b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，在工业企业中，没有机会使用工作站进行数据分析和处理。因此，需要能够容易地连接到现有设备(通常是工业微型计算机)的特殊装置。计算模块<a class="ae ky" href="https://ark.intel.com/content/www/us/en/ark/products/140109/intel-neural-compute-stick-2.html" rel="noopener ugc nofollow" target="_blank"> NCS2 </a>就是这样的设备之一。</p><p id="a9eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们公司<a class="ae ky" href="http://ai-labs.org/" rel="noopener ugc nofollow" target="_blank"> AI Labs </a>定期收到解决一些与机器学习相关的工业问题的请求。不久前，我们有机会利用第二次全国人口普查提供的机会。因此，我使用 NCS2 开发了一个图像分类管道。我愿意与读者分享这项工作的成果。</p><p id="bf24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">安装 OpenVINO toolkit for Ubuntu </strong></p><p id="ca64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先你需要下载并安装当前版本的<a class="ae ky" href="https://docs.openvinotoolkit.org/" rel="noopener ugc nofollow" target="_blank"> OpenVINO </a>。你可以从<a class="ae ky" href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/choose-download/linux.html" rel="noopener ugc nofollow" target="_blank">这里</a>得到 OpenVINO。你可以在这里找到详细的安装指南<a class="ae ky" href="https://docs.openvinotoolkit.org/latest/openvino_docs_install_guides_installing_openvino_linux.html" rel="noopener ugc nofollow" target="_blank">。快速安装指南:</a></p><ol class=""><li id="edf2" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu mj mb mc md bi translated">转到包含下载的档案的文件夹(例如，<em class="mk"> Downloads </em>):</li></ol><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="b394" class="mq mr it mm b gy ms mt l mu mv">cd ~/Downloads/</span></pre><p id="9566" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.打开包装。tgz 文件(其中<em class="mk"> &lt;版本&gt; </em>是下载存档的版本，你会在文件名中看到):</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="c159" class="mq mr it mm b gy ms mt l mu mv">tar -xvzf l_openvino_toolkit_p_&lt;version&gt;.tgz</span></pre><p id="6ab6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.进入<em class="mk"> l_openvino_toolkit_p_ &lt;版本&gt; </em>目录:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="815c" class="mq mr it mm b gy ms mt l mu mv">cd l_openvino_toolkit_p_&lt;version&gt;</span></pre><p id="a16f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.以 root 用户身份运行安装脚本:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="53a9" class="mq mr it mm b gy ms mt l mu mv">sudo ./install.sh</span></pre><p id="68f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5.按照屏幕上的说明进行操作。</p><p id="991b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">6.通过编辑<em class="mk">设置环境变量。bashrc </em>文件。转到用户目录并打开<em class="mk">。bashrc </em>文件进行编辑(例如，用<em class="mk"> nano </em>):</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="9c51" class="mq mr it mm b gy ms mt l mu mv">cd ~<br/>nano .bashrc</span></pre><p id="7059" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将下面一行添加到。bashrc 文件，保存并重新加载:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="50d4" class="mq mr it mm b gy ms mt l mu mv">source /opt/intel/openvino/bin/setupvars.sh<br/>source .bashrc</span></pre><p id="24cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仅此而已。已经准备好了使用 NCS2 进行本地工作的所有必要功能。您可以执行数据预处理和模型训练。</p><p id="6d8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">使用 Google Colab 进行数据预处理和模型训练</strong></p><p id="a283" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.kaggle.com/alessiocorrado99/animals10" rel="noopener ugc nofollow" target="_blank"> Animals-10 </a>数据集用于解决分类问题。为了简化问题，从动物中选择 5 个类别(动物种类)-10:猫、狗、鸡、马、羊。与每个类别相关的图像被分组到相应的文件夹中(“猫”、“狗”、“鸡”、“马”、“羊”)。模型是在 Google Colab 中训练出来的。让我们仔细看看。</p><p id="006f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，您需要安装一个适合与 NCS2 配合使用的 TensorFlow 版本:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="fea9" class="mq mr it mm b gy ms mt l mu mv">!pip install tensorflow==1.15.2</span></pre><p id="56ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">导入库:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="e80c" class="mq mr it mm b gy ms mt l mu mv">import tensorflow.compat.v1 as tf<br/>import tensorflow_hub as hub<br/>import matplotlib.pylab as plt<br/>import numpy as np</span></pre><p id="875b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将 Google Drive(包含数据集)安装到 Google Colab:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="5f5c" class="mq mr it mm b gy ms mt l mu mv">from google.colab import drive<br/>drive.mount(‘/content/drive’)</span></pre><p id="183d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">转到上传数据的目录(“动物”):</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="26f9" class="mq mr it mm b gy ms mt l mu mv">%cd ‘drive/My Drive/animals’</span></pre><p id="0923" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文件夹结构应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4b3d7c3ad9fd4300ba829459995177a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:184/format:webp/1*FFBD1LHt6u0j7nIlVREFrA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Oleksii Sheremet 使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Tree_(command)" rel="noopener ugc nofollow" target="_blank">树</a>命令创建图像</p></figure><p id="64cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建类别(标签)列表:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="4298" class="mq mr it mm b gy ms mt l mu mv">image_dir = 'animals'<br/>import os</span><span id="da81" class="mq mr it mm b gy mx mt l mu mv">class_labels = []<br/>for x in tf.gfile.Walk(image_dir):<br/>    try:<br/>        y = os.path.basename(x[0])<br/>        if y != 'animals':<br/>            class_labels.append(y)<br/>    except:<br/>        pass<br/>print(class_labels)</span></pre><p id="c416" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们得到以下列表:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="20c0" class="mq mr it mm b gy ms mt l mu mv">[‘cat’, ‘chicken’, ‘dog’, ‘horse’, ‘sheep’]</span></pre><p id="49ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于这个列表，索引“0”对应于猫的图像，“1”对应于鸡，“2”对应于狗，“3”对应于马，“4”对应于羊。</p><p id="487a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">设置图像的尺寸(224 x 224)。在训练模型时，我们使用<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank"> ImageDataGenerator </a>从文件夹中创建图像流。</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="8b33" class="mq mr it mm b gy ms mt l mu mv">IMAGE_SIZE = (224,224)</span><span id="5608" class="mq mr it mm b gy mx mt l mu mv">image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255, validation_split=0.2)</span><span id="e8f0" class="mq mr it mm b gy mx mt l mu mv">training_set = image_generator.flow_from_directory(str(image_dir),                                              target_size=IMAGE_SIZE, subset='training')</span><span id="867a" class="mq mr it mm b gy mx mt l mu mv">validation_set = image_generator.flow_from_directory(str(image_dir),                                              target_size=IMAGE_SIZE, subset='validation')</span></pre><p id="a7e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正在检索预训练的 MobileNet 网络:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="13f5" class="mq mr it mm b gy ms mt l mu mv">feature_extractor = tf.keras.applications.MobileNet(weights='imagenet', <br/>                                include_top=False,<br/>                                input_shape=(IMAGE_SIZE+(3,))) <br/>feature_extractor.trainable=False</span></pre><p id="a3f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">构建模型:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="5226" class="mq mr it mm b gy ms mt l mu mv">try:<br/>    del model<br/>except:<br/>    pass</span><span id="3829" class="mq mr it mm b gy mx mt l mu mv">x=feature_extractor.output<br/>x=tf.keras.layers.GlobalAveragePooling2D()(x)</span><span id="261e" class="mq mr it mm b gy mx mt l mu mv">classifier=tf.keras.layers.Dense(label_batch.shape[1],activation='softmax')(x)</span><span id="4db8" class="mq mr it mm b gy mx mt l mu mv">model=tf.keras.Model(inputs=feature_extractor.input,outputs=classifier)</span><span id="282f" class="mq mr it mm b gy mx mt l mu mv">model.build((None,)+IMAGE_SIZE+(3,))<br/>model.summary()</span></pre><p id="5362" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">编译模型:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="4829" class="mq mr it mm b gy ms mt l mu mv">model.compile(<br/>    optimizer=tf.keras.optimizers.Adam(),<br/>    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),<br/>    metrics=['acc'])</span></pre><p id="a0da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">收集日志的回调方法:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="4f78" class="mq mr it mm b gy ms mt l mu mv">class CollectBatchStats(tf.keras.callbacks.Callback):<br/>  def __init__(self):<br/>    self.batch_losses = []<br/>    self.batch_acc = []<br/>    self.validation_losses = []<br/>    self.validation_acc = []</span><span id="6b76" class="mq mr it mm b gy mx mt l mu mv">def on_train_batch_end(self, batch, logs=None):<br/>    self.batch_losses.append(logs['loss'])<br/>    self.batch_acc.append(logs['acc'])<br/>    try:<br/>        self.validation_losses.append(logs['val_loss'])<br/>        self.validation_acc.append(logs['val_acc'])<br/>    except:<br/>        self.validation_losses.append(None)<br/>        self.validation_acc.append(None)<br/>    self.model.reset_metrics()</span></pre><p id="69ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练模型:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="04e1" class="mq mr it mm b gy ms mt l mu mv">steps_per_epoch = np.ceil(training_set.samples/training_set.batch_size)</span><span id="116b" class="mq mr it mm b gy mx mt l mu mv">batch_stats_callback = CollectBatchStats()</span><span id="dbce" class="mq mr it mm b gy mx mt l mu mv">history = model.fit_generator(training_set, epochs=5,<br/>                              steps_per_epoch=steps_per_epoch,<br/>                              validation_data=validation_set,<br/>                              callbacks = [batch_stats_callback])</span></pre><p id="e4a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检查预测:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="dc32" class="mq mr it mm b gy ms mt l mu mv">for image_batch, label_batch in validation_set:<br/>    print("Image batch shape: ", image_batch.shape)<br/>    print("Label batch shape: ", label_batch.shape)<br/>    break</span></pre><p id="99c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有以下形状:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="521e" class="mq mr it mm b gy ms mt l mu mv">Image batch shape:  (32, 224, 224, 3)<br/>Label batch shape:  (32, 5)</span></pre><p id="c938" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以得到预测和它们的类别:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="753a" class="mq mr it mm b gy ms mt l mu mv">predictions = model.predict(image_batch)<br/>predicted_class = np.argmax(predictions, axis=-1)</span></pre><p id="af22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将结果可视化:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="7c8c" class="mq mr it mm b gy ms mt l mu mv">plt.figure(figsize=(12,10))<br/>plt.subplots_adjust(hspace=0.5)<br/>for n in range(30):<br/>    plt.subplot(6,5,n+1)<br/>    plt.imshow(image_batch[n])<br/>    plt.title(f'pred: {class_labels[predicted_class[n]]}\norig: {class_labels[np.array(label_batch[n]).argmax()]}')<br/>    plt.axis('off')<br/>_ = plt.suptitle("Animals")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/911b48daef278aae8595e08bf5985259.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*s_iM9ytLTIuqJJ90Jn1FLQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像由 Oleksii Sheremet 使用<a class="ae ky" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> matplotlib </a>模块创建</p></figure><p id="dfdc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">将 TensorFlow 模型保存为协议缓冲区(pb)格式</strong></p><p id="4353" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">冻结并保存模型:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="4bd4" class="mq mr it mm b gy ms mt l mu mv">from tensorflow.compat.v1.keras import backend as K</span><span id="5d3e" class="mq mr it mm b gy mx mt l mu mv">session = K.get_session()<br/>graph = session.graph<br/>with graph.as_default():<br/>    freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference([]))<br/>    output_names = [out.op.name for out in model.outputs]<br/>    output_names += [v.op.name for v in tf.global_variables()]<br/>    input_graph_def = graph.as_graph_def()<br/>    for node in input_graph_def.node:<br/>        node.device = ""<br/>    frozen_graph = tf.graph_util.convert_variables_to_constants(session, input_graph_def, output_names, freeze_var_names)<br/>tf.train.write_graph(frozen_graph, "animals", "animals.pb", as_text=False)</span></pre><p id="0a33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，训练好的模型被保存到<em class="mk"> animals.pb </em>文件中。</p><p id="4a78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">将张量流模型转换为中间表示法</strong></p><p id="b812" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有详细的<a class="ae ky" href="https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html" rel="noopener ugc nofollow" target="_blank">教程</a>关于转换张量流模型。若要转换训练好的模型，您需要执行下面描述的操作。</p><p id="3617" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">进入<em class="mk">模型 _ 优化器</em>文件夹(需要<em class="mk"> mo_tf.py </em>):</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="5e87" class="mq mr it mm b gy ms mt l mu mv">cd ~/intel/openvino/deployment_tools/model_optimizer</span></pre><p id="8ba7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用以下命令运行<em class="mk"> mo_tf.py </em>(请注意，您必须使用 255 的缩放因子，与图像预处理阶段相同):</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="1e19" class="mq mr it mm b gy ms mt l mu mv">python mo_tf.py --input_model &lt;path_to_model&gt;/animals.pb --batch 1 --scale 255</span></pre><p id="e4cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果转换成功，您将在控制台中看到以下消息:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="dc03" class="mq mr it mm b gy ms mt l mu mv">[ SUCCESS ] Generated IR version 10 model.<br/>[ SUCCESS ] XML file: /home/user_name/intel/openvino_2020.4.287/deployment_tools/model_optimizer/./animals.xml<br/>[ SUCCESS ] BIN file: /home/user_name/intel/openvino_2020.4.287/deployment_tools/model_optimizer/./animals.bin<br/>[ SUCCESS ] Total execution time: 31.81 seconds.<br/>[ SUCCESS ] Memory consumed: 370 MB.</span></pre><p id="9bb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，作为转换的结果，我们得到 3 个文件:<em class="mk"> animals.xml </em>和<em class="mk"> animals.bin，animals.mapping </em>。建议将这些文件复制到一个单独的文件夹中(例如，<em class="mk"> test_folder </em>)。</p><p id="7e7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">用 NCS2 设备运行训练好的模型并获得预测</strong></p><p id="aaa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要在 NCS2 上检查模型的性能，可以使用<em class="mk">classification _ sample . py</em>脚本，它包含在 open vino(/home/user _ name/Intel/open vino/deployment _ tools/inference _ engine/samples/python/classification _ sample/classification _ sample . py)中。将这个脚本复制到包含 3 个训练好的模型文件的文件夹中(<em class="mk"> animals.xml，animals.bin，animals.mapping </em>)。此外，为了检查功能，您可以将几幅图像(例如，<em class="mk">001.jpeg</em>和<em class="mk">002.jpeg</em>)复制到同一个文件夹中。</p><p id="3681" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将 NCS2 连接到 USB，进入<em class="mk"> test_folder </em>并运行(<em class="mk"> MYRIAD </em>键在 NCS2 上运行模型):</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="95d1" class="mq mr it mm b gy ms mt l mu mv">python classification_sample.py -m animals.xml -i 001.jpeg -d MYRIAD</span></pre><p id="b7e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在控制台中测试图像和 NCS2 的输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/d5b942d91db2c44780037c3b39ba4969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*_2o2EnOdBZhAlXGML_rxJA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由 Oleksii Sheremet 使用<a class="ae ky" href="https://www.adobe.com/ru/products/photoshop.html" rel="noopener ugc nofollow" target="_blank"> Adobe Photoshop </a>创建</p></figure><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="11c1" class="mq mr it mm b gy ms mt l mu mv">python classification_sample.py -m animals.xml -i 002.jpeg -d MYRIAD</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/005d3fc2536d1efc8f0958d15b3e6676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*D2sYMURJO7_X7bZoUJPLuA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由 Oleksii Sheremet 使用<a class="ae ky" href="https://www.adobe.com/ru/products/photoshop.html" rel="noopener ugc nofollow" target="_blank"> Adobe Photoshop </a>创建</p></figure><p id="3b93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从给出的例子中可以看出，分类是正确的。图像<em class="mk">001.jpeg</em>显示一匹马(classid=3)，图像<em class="mk">002.jpeg</em>显示一只鸡(classid=1)。</p><p id="159b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p><p id="f1f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所展示的管道允许您快速通过从数据预处理和模型训练到基于 NCS2 模块的测试的所有阶段。实践表明，NCS2 很好地处理了图像分类任务，可以推荐用于解决简单的工业分类任务。</p><p id="0e77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献</strong></p><p id="c2c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://ark.intel.com/content/www/us/en/ark/products/140109/intel-neural-compute-stick-2.html" rel="noopener ugc nofollow" target="_blank">英特尔神经计算棒 2 </a></p><p id="9365" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://docs.openvinotoolkit.org/" rel="noopener ugc nofollow" target="_blank"> OpenVINO 工具包</a></p><p id="6916" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://arxiv.org/pdf/1704.04861.pdf" rel="noopener ugc nofollow" target="_blank"> MobileNets:用于移动视觉应用的高效卷积神经网络</a></p><p id="540f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/fchollet/deep-learning-models/releases/tag/v0.6" rel="noopener ugc nofollow" target="_blank"> MobileNet </a></p></div></div>    
</body>
</html>