<html>
<head>
<title>Should I repartition?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我应该重新分配吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/should-i-repartition-836f7842298c?source=collection_archive---------1-----------------------#2020-06-16">https://towardsdatascience.com/should-i-repartition-836f7842298c?source=collection_archive---------1-----------------------#2020-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e6e6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于Spark SQL中的数据分布。</h2></div><p id="1b21" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在分布式环境中，拥有适当的数据分布成为提升性能的关键工具。在Spark SQL的DataFrame API中，有一个函数<em class="le"> repartition() </em>允许控制Spark集群上的数据分布。然而，该函数的有效使用并不简单，因为改变分布与集群节点上物理数据移动的成本有关(所谓的混洗)。</p><p id="a884" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一般的经验法则是，使用<em class="le">重新分配</em>的成本很高，因为它会导致洗牌。在本文中，我们将更进一步，了解在某些情况下，在正确的位置添加一次洗牌将会删除另外两次洗牌，从而提高整体执行效率。我们将首先介绍一些理论，以理解Spark SQL如何在内部利用关于数据分布的信息，然后我们将查看一些使用<em class="le">重新分区</em>变得有用的实际例子。</p><p id="add9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文中描述的理论基于Spark源代码，该版本是当前的snapshot 3.1(编写于2020年6月)，其中大部分内容在以前的版本2.x中也是有效的。此外，该理论和内部行为是与语言无关的，因此我们是将它与Scala、Java还是Python API一起使用并不重要。</p><h2 id="145b" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">查询规划</h2><p id="731d" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">Spark SQL中的DataFrame API允许用户编写高级转换。这些转换是懒惰的，这意味着它们不会被急切地执行，而是在幕后被转换成一个查询计划。当用户调用一个动作时，查询计划将被具体化，这个动作是一个我们要求一些输出的函数，例如当我们将转换的结果保存到某个存储系统时。查询计划本身有两种主要类型:逻辑计划和物理计划。并且查询计划处理的步骤可以相应地称为逻辑计划和物理计划。</p><h2 id="7079" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">逻辑计划</h2><p id="d3ea" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">逻辑计划的阶段负责与逻辑计划相关的多个步骤，其中逻辑计划本身只是查询的抽象表示，它具有树的形式，其中树中的每个节点都是关系运算符。逻辑计划本身不包含任何有关执行或用于计算转换(如连接或聚合)的算法的特定信息。它只是以一种便于优化的方式表示来自查询的信息。</p><p id="56dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在逻辑规划期间，查询计划由Spark优化器进行优化，Spark优化器应用一组转换计划的规则。这些规则大多基于启发式，例如，最好先过滤数据，然后再进行其他处理，等等。</p><h2 id="f654" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">物理计划</h2><p id="05ed" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">一旦逻辑规划得到优化，物理规划就开始了。这个阶段的目的是将逻辑计划转化为可以执行的物理计划。与非常抽象的逻辑计划不同，物理计划在关于执行的细节方面更加具体，因为它包含了在执行期间将使用的算法的具体选择。</p><p id="77e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">物理规划也由两个步骤组成，因为物理规划有两个版本:<em class="le">星火计划</em>和<em class="le">执行计划</em>。使用所谓的<em class="le">策略</em>创建<em class="le">火花计划</em>，其中逻辑计划中的每个节点被转换为<em class="le">火花计划</em>中的一个或多个操作符。策略的一个例子是<em class="le"> JoinSelection </em>，其中Spark决定使用什么算法来连接数据。可以使用Scala API显示<em class="le">火花计划</em>的字符串表示:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="7299" class="lf lg it mi b gy mm mn l mo mp">df.queryExecution.sparkPlan // in Scala</span></pre><p id="98e8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<em class="le"> spark计划</em>生成后，有一组附加规则应用于该计划，以创建物理计划的最终版本，即<em class="le">执行计划</em>。该<em class="le">执行计划</em>将被执行，生成<em class="le"> RDD </em>代码。要查看这个<em class="le">执行的计划</em>，我们可以简单地调用数据帧上的<em class="le">解释</em>，因为它实际上是物理计划的最终版本。或者，我们可以到Spark UI查看它的图形表示。</p><h2 id="a4b0" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">确保要求(ER规则)</h2><p id="6bf0" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">这些用于将<em class="le"> spark计划</em>转换为<em class="le">执行计划</em>的附加规则之一被称为<em class="le">确保需求</em>(接下来我们将称之为<em class="le"> ER规则</em>)，该规则将确保数据按照某些转换(例如连接和聚合)的要求正确分布。物理计划中的每个操作符都有两个重要的属性<em class="le"> outputPartitioning </em>和<em class="le"> outputOrdering </em>(接下来我们将分别称它们为<em class="le"> oP </em>和<em class="le"> oO </em>)，它们携带有关数据分布的信息，即在给定时刻数据是如何被分区和排序的。除此之外，每个操作符还有另外两个属性<em class="le">required child distribution</em>和<em class="le"> requiredChildOrdering </em>，通过它们对其子节点的<em class="le"> oP </em>和<em class="le"> oO </em>的值提出要求。有些运营商没有任何要求，但有些却有。让我们在一个简单的例子中看到这一点，这个例子使用了<em class="le"> SortMergeJoin </em>，这是一个对其子节点有很高要求的操作符，它要求数据必须按照连接键进行分区和排序，这样才能正确合并。让我们考虑这个简单的查询，其中我们连接了两个表(它们都基于一个文件数据源，比如parquet):</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="bb5c" class="lf lg it mi b gy mm mn l mo mp"># Using Python API:</span><span id="f11a" class="lf lg it mi b gy mq mn l mo mp">spark.table("tableA") \<br/>.join(spark.table("tableB"), "id") \<br/>.write<br/>...</span></pre><p id="6217" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个查询的<em class="le"> spark计划</em>将会是这样的(我还在那里添加了关于<em class="le"> oP </em>、<em class="le"> oO </em>和<em class="le"> SortMergeJoin </em>的需求的信息):</p><figure class="md me mf mg gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mr"><img src="../Images/c29b6f3f32266ea81c0e3dc72abf5b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nt5a4o7rb3717FHfBORknA.png"/></div></div></figure><p id="b660" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从<em class="le">星火计划</em>中我们可以看到<em class="le"> SortMergeJoin </em>的子节点(两个<em class="le">项目</em>操作员)没有<em class="le"> oP </em>或<em class="le"> oO </em>(他们是<em class="le"> Unknown </em>和<em class="le"> None </em>)，这是一种数据没有提前重新划分，表没有分桶的一般情况。当<em class="le"> ER规则</em>应用于计划时，它可以看到<em class="le"> SortMergeJoin </em>的要求不被满足，因此它会将<em class="le">交换</em>和<em class="le">排序</em>操作符填充到计划中以满足要求。<em class="le">交换</em>操作符将负责重新划分数据以满足<em class="le">要求的子分配</em>要求，而<em class="le">排序</em>将对数据进行排序以满足<em class="le">要求的子排序</em>，因此最终的<em class="le">执行计划</em>将如下所示(这也是您可以在SQL选项卡的SparkUI中找到的内容，您不会在那里找到<em class="le"> spark计划【T6</em></p><figure class="md me mf mg gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mz"><img src="../Images/c94c3bb416243fbe1b9a4ca6d6199e47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JyAfgQj0v9PwAk6PTYNoxw.png"/></div></div></figure><h2 id="ba6e" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">桶装</h2><p id="4e5c" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">如果两个表都由连接键存储，情况就不同了。分桶是一种以预混洗和可能的预排序状态存储数据的技术，其中关于分桶的信息存储在metastore中。在这种情况下，<em class="le"> FileScan </em>操作符将根据来自metastore的信息设置<em class="le"> oP </em>，如果每个存储桶正好有一个文件，那么<em class="le"> oO </em>也将被设置，并且它将全部被传递到下游的<em class="le">项目</em>。如果两个表都被连接键存储到相同数量的存储桶，那么将满足<em class="le"> oP </em>的要求，并且<em class="le"> ER规则</em>将不会向计划添加<em class="le">交换</em>。这里，连接两端的分区数量相同是至关重要的，如果这些数量不同，<em class="le">交换</em>仍然必须用于分区数量不同于<em class="le">spark . SQL . shuffle . partitions</em>配置设置(默认值为200)的每个分支。因此，有了正确的存储桶，连接可以是无洗牌的。</p><p id="aa96" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">需要理解的重要一点是，Spark需要知道要使用它的分布，所以即使你的数据已经用bucketing进行了预混洗，除非你将数据作为一个表来读取，以便从metastore中选择信息，否则Spark不会知道它，因此它不会在<em class="le">文件扫描</em>上设置<em class="le"> oP </em>。</p><h2 id="6ae1" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">再分</h2><p id="bf94" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">如开头所述，有一个函数<em class="le"> repartition </em>可用于改变数据在火花簇上的分布。该函数将数据应该按其分布的列作为参数(可选地，第一个参数可以是应该创建的分区的数量)。幕后发生的事情是，它将一个<em class="le">RepartitionByExpression</em>节点添加到逻辑计划中，然后使用一个策略将该逻辑计划转换为<em class="le"> spark计划</em>中的<em class="le"> Exchange </em>，并且它将<em class="le"> oP </em>设置为<em class="le"> HashPartitioning </em>，键是用作参数的列名。</p><p id="66ab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le"> repartition </em>函数的另一个用法是，调用它时只有一个参数，即应该创建的分区数量(<em class="le"> repartition(n)) </em>)，这将随机分配数据。然而，本文没有讨论这种随机分布的用例。</p><p id="d749" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们来看一些实际的例子，在这些例子中，使用<em class="le">重新分配</em>按特定字段调整分配会带来一些好处。</p><h2 id="f19b" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">示例1:单向无洗牌连接</h2><p id="3f9e" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">让我们看看，如果上述连接中的一个表被分桶，而另一个没有，会发生什么情况。在这种情况下，要求不被满足，因为<em class="le"> oP </em>在两侧是不同的(一侧是由铲斗定义的，另一侧是未知的<em class="le"/>)。在这种情况下，<em class="le"> ER </em> <em class="le">规则</em>会将<em class="le">交换</em>添加到join的两个分支，因此join的每一端都必须进行洗牌！Spark将简单地忽略一方已经被预先洗牌，并将浪费这个避免洗牌的机会。这里我们可以简单地在join的另一侧使用<em class="le">重新分区</em>来确保<em class="le"> oP </em>在<em class="le"> ER </em> <em class="le">规则</em>检查它并添加<em class="le">交换</em>之前被设置:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="db7d" class="lf lg it mi b gy mm mn l mo mp"># Using Python API:<br/># tableA is not bucketed <br/># tableB is bucketed by <em class="le">id</em> into 50 buckets</span><span id="3775" class="lf lg it mi b gy mq mn l mo mp">spark.table("tableA") \<br/><strong class="mi iu">.repartition(50, "id") \</strong><br/>.join(spark.table("tableB"), "id") \<br/>.write \<br/>...</span></pre><p id="ddbb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">调用<em class="le">重新分配</em>将向计划的左分支添加一个<em class="le">交换</em>，但是右分支将保持自由洗牌，因为需求现在将被满足，并且<em class="le"> ER规则</em>将不再添加<em class="le">交换</em>。所以在最终方案中，我们将只有一次洗牌，而不是两次。或者，我们可以改变混洗分区的数量，以匹配<em class="le">表B </em>中的桶的数量，在这种情况下，不需要<em class="le">重新分区</em>(它不会带来额外的好处)，因为<em class="le"> ER规则</em>将使右分支免于混洗，并且它将只调整左分支(以与<em class="le">重新分区</em>相同的方式):</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="ee27" class="lf lg it mi b gy mm mn l mo mp"># match number of buckets in the right branch of the join with the number of shuffle partitions:</span><span id="ea06" class="lf lg it mi b gy mq mn l mo mp">spark.conf.set("spark.sql.shuffle.partitions", 50)</span></pre><h2 id="4825" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">示例II:聚合后连接</h2><p id="88c5" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated"><em class="le">重新分区</em>变得有用的另一个例子与查询相关，其中我们通过两个键聚集一个表，然后通过这两个键中的一个连接另一个表(在这种情况下，这两个表都不存储)。让我们看一个基于此类事务数据的简单示例:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="be50" class="lf lg it mi b gy mm mn l mo mp">{"id": 1, "user_id": 100, "price": 50, "date": "2020-06-01"}<br/>{"id": 2, "user_id": 100, "price": 200, "date": "2020-06-02"}<br/>{"id": 3, "user_id": 101, "price": 120, "date": "2020-06-01"}</span></pre><p id="4d5f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每个用户在数据集中可以有许多行，因为他/她可能进行了许多交易。这些交易存储在<em class="le">表a中。</em>另一方面，<em class="le"> tableB </em>将包含每个用户的信息(姓名、地址等等)。<em class="le">表B </em>没有重复，每条记录属于不同的用户。在我们的查询中，我们希望统计每个用户和日期的事务数量，然后加入用户信息:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="84fd" class="lf lg it mi b gy mm mn l mo mp"># Using Python API:</span><span id="4b12" class="lf lg it mi b gy mq mn l mo mp">dfA = spark.table("tableA") # transactions (not bucketed)<br/>dfB = spark.table("tableB") # user information (not bucketed)</span><span id="b1f7" class="lf lg it mi b gy mq mn l mo mp">dfA \<br/>.groupBy("user_id", "date") \<br/>.agg(count("*")) \<br/>.join(dfB, "user_id")</span></pre><p id="703a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该查询的<em class="le"> spark计划</em>如下所示</p><figure class="md me mf mg gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi na"><img src="../Images/3628898ed748279c81bda75ed79f13cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_yhD5zcG0RGZ1rKnmJ-2HA.png"/></div></div></figure><p id="a469" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<em class="le"> spark计划中，</em>你可以看到一对<em class="le"> HashAggregate </em>操作符，第一个(在顶部)负责部分聚合，第二个负责最终合并。<em class="le"> SortMergeJoin </em>的要求与之前相同。这个例子中有趣的部分是<em class="le">散列集合</em>。第一个没有来自其子项的要求，但是，第二个要求<em class="le"> oP </em>是由<em class="le"> user_id </em>和<em class="le"> date </em>或这些列的任何子集构成的<em class="le"> HashPartitioning </em>，这是我们稍后将利用的。在一般情况下，不满足这些要求，因此<em class="le"> ER规则</em>将添加<em class="le">交换</em>(以及<em class="le">排序</em>)。这将导致执行以下计划:</p><figure class="md me mf mg gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi nb"><img src="../Images/6bdddba9063f964a0eccc461243c83b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hVE1Jb9eHSr_bybiUpEz4w.png"/></div></div></figure><p id="d083" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如你所看到的，我们最终得到了一个有三个<em class="le">交换</em>操作符的计划，所以在执行过程中会发生三次洗牌。现在让我们看看如何使用<em class="le">重新分配</em>来改变这种情况:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="c408" class="lf lg it mi b gy mm mn l mo mp">dfA = spark.table("tableA").repartition("user_id")<br/>dfB = spark.table("tableB")</span><span id="5c6d" class="lf lg it mi b gy mq mn l mo mp">dfA \<br/>.groupBy("user_id", "date") \<br/>.agg(count("*")) \<br/>.join(dfB, "user_id")</span></pre><p id="7f57" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le"> spark计划</em>现在看起来会有所不同，它将包含由从逻辑计划转换<em class="le">RepartitionByExpression</em>节点的策略生成的<em class="le">交换</em>。此<em class="le">交换</em>将是第一个<em class="le"> HashAggregate </em>操作符的子操作，它将把<em class="le"> oP </em>设置为<em class="le">hash partitioning(user _ id)</em>，该操作将被传递到下游:</p><figure class="md me mf mg gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi nc"><img src="../Images/c7a8ef12e9b7d9be2c459b8290ffa598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sz_i7JgLJYtDxrEavNA6Tg.png"/></div></div></figure><p id="16e7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">左分支中所有操作符的<em class="le"> oP </em>的要求现在都满足了，所以<em class="le"> ER规则</em>不会增加额外的<em class="le">交换</em>(它仍然会增加<em class="le"> Sort到</em>来满足<em class="le"> oO </em>)。本例中的基本概念是，我们按两列进行分组，并且<em class="le"> HashAggregate </em>运算符的要求更加灵活，因此，如果数据将按这两个字段中的任何一个进行分布，则要求将得到满足。最终执行的计划在左分支只有一个<em class="le">交换</em>(右分支也有一个),因此使用<em class="le">重新分配</em>,我们将洗牌次数减少了一次:</p><figure class="md me mf mg gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi nd"><img src="../Images/a7f8fd84ce26cbcf018928d63f13d30c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U_C9hlNVZdgAB5EmBy9xLg.png"/></div></div></figure><h2 id="fbe5" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">讨论</h2><p id="14d0" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">的确，使用<em class="le">重新分配</em>，我们现在在左分支中只有一次洗牌，而不是两次，但是重要的是要明白这些洗牌不是同一种类的！在最初的计划中，两个<em class="le">交换</em>都发生在负责部分聚合的<em class="le">哈希聚合</em>之后，因此数据在洗牌之前被减少(在每个节点上本地聚合)。在新计划中，<em class="le">交换</em>出现在<em class="le">散列</em>之前，因此完整的数据将被打乱。</p><p id="af72" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么什么更好呢？一次全洗牌还是两次减洗牌？这最终取决于数据的属性。如果每个<em class="le"> user_id </em>和<em class="le"> date </em>只有几条记录，这意味着聚合不会减少太多数据，因此总洗牌将与减少的洗牌相当，并且只有一次洗牌会更好。另一方面，如果每个<em class="le"> user_id </em>和<em class="le"> date </em>有很多记录，那么聚合将使数据变得更小，因此采用原始计划可能更好，因为这两次小洗牌可能比一次大洗牌更快。这也可以用这两个字段<em class="le"> user_id </em>和<em class="le"> date </em>的所有不同组合的基数来表示。如果这个基数与总行数相当，这意味着<em class="le"> groupBy </em>转换不会减少太多数据。</p><h2 id="212c" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">示例三:两个聚合的联合</h2><p id="7dc4" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">让我们再考虑一个例子，其中<em class="le">重新分区</em>将优化我们的查询。该问题基于与前一个示例相同的数据。现在，在我们的查询中，我们希望对两个不同的聚合进行联合，在第一个中，我们将对每个用户的行数进行计数，在第二个中，我们将对<em class="le"> price </em>列进行求和:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="d20c" class="lf lg it mi b gy mm mn l mo mp"># Using Python API:</span><span id="7a44" class="lf lg it mi b gy mq mn l mo mp">countDF = df.groupBy("user_id") \<br/>.agg(count("*").alias("metricValue")) \<br/>.withColumn("metricName", lit("count"))</span><span id="84ee" class="lf lg it mi b gy mq mn l mo mp">sumDF = df.groupBy("user_id") \<br/>.agg(sum("price").alias("metricValue")) \<br/>.withColumn("metricName", lit("sum"))</span><span id="2510" class="lf lg it mi b gy mq mn l mo mp">countDF.union(sumDF)</span></pre><p id="70e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是该查询的最终执行计划:</p><figure class="md me mf mg gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ne"><img src="../Images/1b8a103ac7ae65b4f4382098876cef9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FOHIZbnpmfd0hHX1sIMV-w.png"/></div></div></figure><p id="54d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个典型的类似union的查询计划，union<em class="le">union</em>中的每个数据帧都有一个分支。我们可以看到有两次洗牌，一次用于一个聚合。除此之外，根据计划，数据集将被扫描两次。这里的<em class="le">再分配</em>功能和一个小技巧可以帮助我们改变计划的形状</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="e87d" class="lf lg it mi b gy mm mn l mo mp">df = spark.read.parquet(...)<strong class="mi iu">.repartition("user_id")</strong></span><span id="be1c" class="lf lg it mi b gy mq mn l mo mp">countDF = df.groupBy("user_id") \<br/>.agg(count("<strong class="mi iu">price</strong>").alias("metricValue")) \<br/>.withColumn("metricName", lit("count"))</span><span id="bb52" class="lf lg it mi b gy mq mn l mo mp">sumDF = df.groupBy("user_id") \<br/>.agg(sum("price").alias("metricValue")) \<br/>.withColumn("metricName", lit("sum"))</span><span id="ebc9" class="lf lg it mi b gy mq mn l mo mp">countDF.union(sumDF)</span></pre><figure class="md me mf mg gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi nf"><img src="../Images/2616f6859b03f806c6bcb010fc3aa2d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LnWqYFIoVcj9dS5xPjlgLA.png"/></div></div></figure><p id="1ff0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">重新分区</em>功能将在<em class="le">聚集</em>之前移动<em class="le">交换</em>操作符，并使<em class="le">交换</em>子分支完全相同，因此它将被另一个名为<em class="le"> ReuseExchange </em>的规则重用。在<em class="le"> count </em>函数中，将星号更改为<em class="le"> price </em>列在这里变得很重要，因为这将确保投影在两个数据帧中是相同的(我们需要将<em class="le"> price </em>列也投影在左分支中，使其与第二个分支相同)。然而，只有在<em class="le">价格</em>列中没有<em class="le">空值</em>时，它才会产生与原始查询相同的结果。要理解这条规则背后的逻辑，请参见我的另一篇<a class="ae ng" rel="noopener" target="_blank" href="/be-in-charge-of-query-execution-in-spark-sql-c83d1e16b9b8">文章</a>，在那里我用一个类似的例子更详细地解释了<em class="le"> ReuseExchange </em>规则。</p><p id="f428" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与之前类似，我们在这里将洗牌的次数减少了一次，但是我们现在又有了一次总洗牌，而不是原始查询中减少的洗牌。这里的额外好处是，在优化之后，由于重用的计算，数据集将只被扫描一次。</p><h2 id="4f64" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">分布信息损失</h2><p id="28a3" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">正如我们已经提到的，不仅以最佳方式分发数据很重要，而且让Spark知道这一点也很重要。关于<em class="le"> oP </em>的信息通过计划从一个节点传播到它的父节点，但是，即使实际分布没有改变，也有一些操作符会停止传播信息。其中一个操作符是<em class="le">BatchEvalPython</em>——一个表示Python API中用户定义函数的操作符。因此，如果您对数据进行重新分区，然后调用Python UDF，然后进行连接(或一些聚合)，那么<em class="le"> ER规则</em>将添加一个新的<em class="le">交换</em>，因为<em class="le"> BatchEvalPython </em>不会向下游传递<em class="le"> oP </em>信息。我们可以简单地说，在调用一个Python UDF后，Spark会忘记数据是如何分布的。</p><h2 id="7b5f" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">控制生成文件的数量</h2><p id="7b26" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">让我简单介绍一下<em class="le">重新分区</em>功能的另一个使用案例，该功能用于在将数据分区和/或存储到存储系统时控制生成文件的数量。如果您正在将数据分区到一个文件系统，如下所示:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="43a1" class="lf lg it mi b gy mm mn l mo mp">df \<br/>.write \<br/>.partitionBy(key) \<br/>.save(path)</span></pre><p id="afdd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果数据在Spark作业的最后阶段随机分布，它会产生很多小文件。最后阶段的每个任务都可能包含所有键的值，因此它将在每个存储分区中创建一个文件，从而生成许多小文件。在<em class="le">写入</em>之前调用自定义<em class="le">重新分区</em>允许我们模拟文件系统所需的分配，从而控制生成的文件数量。在以后的文章中，我们将更详细地描述这是如何工作的，以及如何有效地用于存储。</p><h2 id="4bf3" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">结论</h2><p id="b96c" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated"><em class="le">重新分配</em>功能允许我们改变数据在火花簇上的分布。这种分布变化会在底层诱发洗牌(物理数据移动)，这是一种相当昂贵的操作。在本文中，我们已经看到了一些例子，在这些例子中，这种额外的混洗可以同时删除一些其他的混洗，从而使整体执行更加高效。我们还看到，区分两种混洗非常重要，即完全混洗(移动所有数据)和简化混洗(在部分聚合后移动数据)。有时，要决定什么最终更有效，需要理解实际数据的属性。</p></div></div>    
</body>
</html>