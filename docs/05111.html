<html>
<head>
<title>Using AI to Trade? Here is JP Morgan’s Approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用AI来交易？以下是JP摩根的方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-ai-to-trade-682f89d2035e?source=collection_archive---------35-----------------------#2020-05-02">https://towardsdatascience.com/using-ai-to-trade-682f89d2035e?source=collection_archive---------35-----------------------#2020-05-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="7976" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">研究文摘</h2><div class=""/><div class=""><h2 id="e199" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">利用强化学习获得最优执行策略</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/d2fd6c6e4e69e479dc68b1c36daa9132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLn-thcOnSG-OEhsbIg6Mw.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://www.mirrorreview.com/jpmorgan-chase-invests-ai-startup-volley/" rel="noopener ugc nofollow" target="_blank">视觉信用</a></p></figure><p id="864e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本文中，我们主要关注论文“在模拟市场反应存在的情况下用于自主执行的<a class="ae le" href="https://www.jpmorgan.com/jpmpdf/1320748255876.pdf" rel="noopener ugc nofollow" target="_blank">风险敏感紧凑决策树”，以讨论机器学习如何帮助我们获得更好的执行策略。在这个过程中，我们从其他论文中添加了更多的信息，这些信息是本文的基本理论，也是帮助我们理解问题的额外来源。</a></p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="c2bf" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated"><strong class="ak">问题:如何执行命令？</strong></h1><p id="668c" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">想象一个交易者有一堆钱，这个交易者想买一堆股票。现在，交易者可以使用两个订单来购买股票:</p><ul class=""><li id="1777" class="nf ng iq lh b li lj ll lm lo nh ls ni lw nj ma nk nl nm nn bi translated"><strong class="lh ja">市价指令簿</strong>:以当前市价买卖。交易者提交他/她想要购买的股票数量，然后交易所根据当前市场自动设定价格。</li><li id="1b31" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated"><strong class="lh ja">限价委托单</strong>:交易员预先设定的特定价格的买入和卖出。当别人想以这个价格卖出或买入时，交易所会撮合这两个，完成交易。</li></ul><p id="5d0f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">正如我们可以看到下图。如果交易者想执行限价单，他会将订单放在队列中；如果交易者想要执行市价单，他将立即以当前市价获得执行。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/b8baff3adb74428aa17a77902bad9c6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*fM1Lxig8LjC2dOhmk34B7A.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">限价订单示例(归功于Vyetrenko和徐，2019)</p></figure><h2 id="92e1" class="nu mj iq bd mk nv nw dn mo nx ny dp ms lo nz oa mu ls ob oc mw lw od oe my iw bi translated">限价订单与市价订单</h2><p id="7f5f" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">当你要执行<strong class="lh ja">市价单时，</strong>你要确保执行优先于价格。</p><ul class=""><li id="9a4b" class="nf ng iq lh b li lj ll lm lo nh ls ni lw nj ma nk nl nm nn bi translated"><strong class="lh ja">优势</strong>:您可以立即流动资产，因为交易所会自动匹配价格并执行订单。</li><li id="7573" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated"><strong class="lh ja">缺点</strong>:当你购买资产时，你可能会有很多成本。你可能立即以101美元买入一只股票，但如果你只等5分钟，你也可以以100美元买入。</li></ul><p id="83d7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当你想执行<strong class="lh ja">限价单</strong>时，你把价格放在优先于执行的位置。</p><ul class=""><li id="2ff5" class="nf ng iq lh b li lj ll lm lo nh ls ni lw nj ma nk nl nm nn bi translated"><strong class="lh ja">优势</strong>:你按照自己设定的价格执行订单，无论买入还是卖出。如果你想以105美元买100只股票，你先设定一个价格。如果系统匹配到想以105美元卖出100只股票的卖家，那么系统匹配你们两个并执行这个过程。所以你可以确定你想买的东西的价格。</li><li id="9a19" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma nk nl nm nn bi translated"><strong class="lh ja">劣势</strong>:你有长时间不执行限价单的风险。例如，当当前市场价格为80美元时，您可以将买入价设置为50美元。直到价格降到50美元(不太可能)，你才能得到执行。</li></ul><h2 id="fcfd" class="nu mj iq bd mk nv nw dn mo nx ny dp ms lo nz oa mu ls ob oc mw lw od oe my iw bi translated"><strong class="ak">市场影响</strong></h2><p id="d1ad" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">另一个问题是市场影响。股票交易总是有供给方和需求方，这就要保持平衡。问题是大机构往往会在短时间内(比如一天内)买入很多股票。如果市价是100美元，他们想用1，000，000美元买10，000股。如果他们只是一次性地出示订单。市场中的所有人都会知道有人想购买大量股票，然后卖方会根据人性提高价格，这就是所谓的市场影响。为了解决这个问题，他们可以将大订单拆分成更小的子订单来降低成本。</p><h2 id="a1b8" class="nu mj iq bd mk nv nw dn mo nx ny dp ms lo nz oa mu ls ob oc mw lw od oe my iw bi translated"><strong class="ak">执行策略:如何达到最优？</strong></h2><p id="8aa7" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">目标是在今天结束前执行并获得一定数量的股份。但是交易者想要实施一个最优策略来处理它。三个问题仍然存在:</p><p id="7a57" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">1.每个子订单的比例是多少？</p><p id="099d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">2.他们想什么时候执行订单？</p><p id="de42" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">3.对于每个子订单。他们是要执行市价单还是限价单？</p><p id="6e83" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于每个子订单，我们称限价订单为被动订单，因为买家会设定价格，并被动地等待价格匹配。我们称市价订单为积极订单，因为买家希望积极地获得订单，而不考虑价格。</p><h2 id="e76c" class="nu mj iq bd mk nv nw dn mo nx ny dp ms lo nz oa mu ls ob oc mw lw od oe my iw bi translated"><strong class="ak">最优执行问题vs .最优布局问题？</strong></h2><p id="73c2" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">每个人都会问这个问题:我做交易的时候，怎么才能降低成本？从上一段可以看出，当一个交易者想买入一个时间窗口[0，T]给定的S股股票时。交易者希望如何最小化获取成本？我们称这个<strong class="lh ja">最优执行</strong>问题。</p><p id="ba62" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Bertsimas和Lo (1998)提出了一种基于动态规划原理(DPP)的最优执行策略，他们假设了线性价格影响:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi of"><img src="../Images/8a572d26da8e9314f214f3d2855e088f.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*5Uk4Nw4008aMHnOBvzqNCQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">线性市场影响</p></figure><p id="51ef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这意味着当前价格(Pt)是先前价格(Pt-1)、你购买股票的比例(St)和随机噪声的函数。他们得出的结论是，最优执行策略只是根据相等的时间间隔将全部股票平均分成若干份。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi og"><img src="../Images/0029e0efebb32cb0c4014c9201b0e0dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*K26SgRezfL5mSxQEoPA_aw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">最佳执行策略</p></figure><p id="b690" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">郭等(2013)给出了<strong class="lh ja">最优布局</strong>问题的理论。与最优执行相比，针对交易的最优布局问题发生在更小的时间窗口(10-100秒)，尤其是在HFT(高频交易)领域。</p><h2 id="288c" class="nu mj iq bd mk nv nw dn mo nx ny dp ms lo nz oa mu ls ob oc mw lw od oe my iw bi translated"><strong class="ak">强化学习方法</strong></h2><p id="6fc3" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">考虑这个问题的方法太多了。本文试图使用马尔可夫决策过程(MDP)和强化学习(RL)来解决这个问题。作者考虑了最优执行策略的价格影响，以及多主体的相互作用(对市场的模拟)。在本文中，3个组件协同工作:</p><ol class=""><li id="5856" class="nf ng iq lh b li lj ll lm lo nh ls ni lw nj ma oh nl nm nn bi translated">限价订单簿数据模拟器</li><li id="f9c0" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma oh nl nm nn bi translated">强化学习算法:风险敏感Q学习</li><li id="0669" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma oh nl nm nn bi translated">功能选择</li></ol></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="8254" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated"><strong class="ak">市场模拟</strong></h1><h2 id="4c7e" class="nu mj iq bd mk nv nw dn mo nx ny dp ms lo nz oa mu ls ob oc mw lw od oe my iw bi translated"><strong class="ak">模拟器互动</strong></h2><p id="7945" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">运行该策略有两个组成部分:</p><ol class=""><li id="caf1" class="nf ng iq lh b li lj ll lm lo nh ls ni lw nj ma oh nl nm nn bi translated"><strong class="lh ja">市场模拟器</strong>:让RL算法有足够的数据和交互来训练自己，这是一个游乐场。如果我们执行订单，模拟器将模拟市场影响。</li><li id="1d11" class="nf ng iq lh b li no ll np lo nq ls nr lw ns ma oh nl nm nn bi translated"><strong class="lh ja">强化学习代理</strong>:强化学习代理将与市场模拟器交互。它下订单以产生市场影响，然后从这个模拟器获得回应作为奖励。</li></ol><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/c96c5850283082c955e7ca234a31c826.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*SB3oE8Vf3f7bMMvKNGUcdw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">培训流程(归功于Vyetrenko和徐，2019)</p></figure><p id="19f7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">正如你在这张图片中看到的，他们在模拟市场环境中训练强化学习代理，这与实时执行代理有类似的方案。</p><h2 id="e836" class="nu mj iq bd mk nv nw dn mo nx ny dp ms lo nz oa mu ls ob oc mw lw od oe my iw bi translated"><strong class="ak">如何定义市场影响？</strong></h2><p id="4f60" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">回想一下，一些论文(Bertsimas和Lo，1998)使用线性函数来模拟市场影响。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/fc3efb426f103409c772a4afdb1f9b02.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*ZAlUw8z34eNF7D4kH9bOPQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">线性市场影响</p></figure><p id="e16b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">但在本文中，他们将市场反应作为LOB(限价订单簿)数据和激进订单规模的函数。这意味着他们可以从LOB数据中获得洞察力，而不是使用公式中的假设。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="46bc" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated"><strong class="ak">强化学习</strong></h1><p id="e01e" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">对于每个强化学习，有3个组成部分:</p><p id="bc72" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">1.<strong class="lh ja">状态</strong>:有两种状态。对于代理人来说，状态表示头寸，这意味着还剩多少钱，交易者想买多少股票。对于市场来说，一个市场有市场价格，限制目前的订单规模。然后，他们将状态变量分离到箱中。意味着如果有5个变量，每个变量分别有2、3、4、5、6个箱。它将得到2*3*4*5*6 = 720个状态。</p><p id="52a6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">2.<strong class="lh ja">动作(a) </strong>:在每一个时刻，都有一个动作选项:在限价指令簿或市价指令簿上押o大小，分别代表被动和主动。如果o = 0，此时他们不执行任何订单。</p><p id="5ff5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">3.<strong class="lh ja">奖励(R) </strong>:奖励是每次节约的成本。奖励定义为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/c897719044969623da9bd86e885bf8de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*a3DT7KkuwxIOhptZzPeFpQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">每次执行的奖励</p></figure><p id="f697" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这个公式中，报酬是时间t时的执行价格(Pt)、交易者仅执行整个母订单时的价格(Pσ)和订单大小(ft)的函数。</p><p id="7906" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在Lo的论文中，他们还使用MDP对最优执行策略进行过程建模。但是他们做了一些固定的假设，没有用动态数据来支撑。</p><p id="bcad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，在本文中，他们使用Q-learning和MDP来模拟真实模拟动态环境中的反应。Q-学习中的Q值公式定义如下:</p><p id="4e69" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这个公式中，Q值是<strong class="lh ja">奖励</strong> (R)总和、<strong class="lh ja">状态</strong> (s)和<strong class="lh ja">动作</strong> (a)的函数。定义Q值后。目标是获得最大化总贴现回报期望的最优策略:</p><p id="35bc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于有如此多的状态变量作为特征，他们还使用最小二乘策略迭代方法从总特征池中选择特征的子集。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="0d75" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated"><strong class="ak">决策树表示的结果</strong></h1><p id="e764" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">在强化学习算法中，他们提供了一个可变的参数β来表示不同的风险偏好。</p><p id="2bcd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在Q-Learning训练过程之后，他们得到一个学习的表格执行策略，然后他们使用决策树来表示这个结果。决策树的优点是决策树可以明确地解释特征。基于此，交易者可以根据状态变量的情况使用不同的策略，积极地(市价单)或消极地(限价单)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/92adbf2c0d024974e74490208341460d.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*cRLjGIiOvU1fsuo_GalWtw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">基于决策树的策略(归功于Vyetrenko和徐，2019)</p></figure><p id="f5ee" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">与基准测试</strong>相比，他们的结果更好。基于这种基于强化学习树的智能体取得了很好的效果。该代理可以节省32%的总执行成本。但是对于标准差来说，这种策略增加了27%的成本标准差，这是成本节约和风险之间的权衡，这是限价单的本质。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/187ed5f5e34c042cca605bef031a4b77.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*t-TDMX8o_X3qlimLWaiQQA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">强化学习模型的结果(归功于Vyetrenko和徐，2019)</p></figure></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="ed7b" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated"><strong class="ak">结论</strong></h1><p id="3829" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">在本文中，作者展示了强化学习算法可用于最优执行问题。它会考虑一个动态的环境，而不是做一个固定的假设。它在限价订单簿数据集上表现良好。和作者表明，他们可以用决策树来表示政策，以指导交易者做出决策。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="9bad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="on">来自《走向数据科学》编辑的提示:</em> </strong> <em class="on">虽然我们允许独立作者根据我们的</em> <a class="ae le" rel="noopener" target="_blank" href="/questions-96667b06af5"> <em class="on">规则和指导方针</em> </a> <em class="on">发表文章，但我们并不认可每个作者的贡献。你不应该在没有寻求专业建议的情况下依赖一个作者的作品。详见我们的</em> <a class="ae le" rel="noopener" target="_blank" href="/readers-terms-b5d780a700a4"> <em class="on">读者术语</em> </a> <em class="on">。</em></p><h1 id="b814" class="mi mj iq bd mk ml oo mn mo mp op mr ms kf oq kg mu ki or kj mw kl os km my mz bi translated"><strong class="ak">参考</strong></h1><p id="072b" class="pw-post-body-paragraph lf lg iq lh b li na ka lk ll nb kd ln lo nc lq lr ls nd lu lv lw ne ly lz ma ij bi translated">[1] Bertsimas、Dimitris和Andrew W. Lo。"执行成本的最佳控制."金融市场杂志1，第1号(1998):1–50。<a class="ae le" href="https://doi.org/10.1016/s1386-4181(97)00012-8" rel="noopener ugc nofollow" target="_blank">https://doi . org/10.1016/s 1386-4181(97)00012-8</a>。</p><p id="4359" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2]gatherel，吉姆，亚历山大·席德。"市场影响的动态模型和订单执行的算法."SSRN电子杂志，2012年。https://doi.org/10.2139/ssrn.2034178<a class="ae le" href="https://doi.org/10.2139/ssrn.2034178" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="cc7a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[3]郭、辛、阿德里安·德拉拉尔和赵阮。"限价订单簿中的最佳位置."SSRN电子杂志，2013年。【https://doi.org/10.2139/ssrn.2318220】T4。</p><p id="93b1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[4]郭、辛、阿德里安·德拉拉尔和赵阮。"限价订单簿中的最佳位置:一种分析方法."数学与金融经济学11第2期(2016):189–213。<a class="ae le" href="https://doi.org/10.1007/s11579-016-0177-5" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1007/s11579-016-0177-5</a>。</p><p id="1efd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[5] Vyetrenko，Svitlana和Xu。"在模拟市场反应中自主执行的风险敏感紧凑决策树."<em class="on"> arXiv预印本arXiv:1906.02312 </em> (2019)。</p></div></div>    
</body>
</html>