<html>
<head>
<title>K Nearest Neighbors by Hand:</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k 手动最近邻:</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-nearest-neighbors-by-hand-a-computer-science-exercise-for-the-data-scientist-72b5821c8941?source=collection_archive---------36-----------------------#2020-06-30">https://towardsdatascience.com/k-nearest-neighbors-by-hand-a-computer-science-exercise-for-the-data-scientist-72b5821c8941?source=collection_archive---------36-----------------------#2020-06-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="efc8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">打开“黑匣子”并理解其中的算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9a964b0c994215a1b485e6c99491c0de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fA37SLmHx_zZ1Ue7wFXxIw.jpeg"/></div></div></figure><p id="2290" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">数据科学家有时谈论数据科学的“黑盒”方法；也就是说，当你理解了不同机器学习算法的用例，以及如何在不理解算法在表面下如何工作的情况下插入数据。但是<em class="lq">算法</em>仅仅是——它们是“算法”——一组用于解决特定类型问题的指令。</p><p id="641c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这篇博客文章中，我将向您展示如何手工构建一个简单的机器学习算法。我们将要构建的模型是 knarestneighborsclassifier(KNN classifier)。</p><h2 id="809f" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">什么是 KNNClassifier，它是如何工作的？</h2><p id="7710" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">KNNClassifier 是我用过的第一个机器学习算法。它很简单，但是非常强大。该算法被认为是“懒惰”的，因为它本身并不<em class="lq">学习</em>；该算法只是记忆数据，而不是在训练过程中学习数据中的模式，并根据这些模式对新数据进行预测。然后，该模型将数据与其自身相关联，并找到每个数据点之间的“<a class="ae mp" href="https://en.wikipedia.org/wiki/Euclidean_geometry#:~:text=Euclidean%20geometry%20is%20a%20mathematical,propositions%20(theorems)%20from%20these." rel="noopener ugc nofollow" target="_blank">欧几里德距离</a>”(本质上是直线距离)。当添加新数据时，算法会根据我们指定的“最近邻”数据点的数量来预测该数据的目标。</p><p id="7548" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">举个简单的例子，假设一个数据集有两三个特征。将这些数据映射到 2D 或 3D 图形上，并找到每个点之间的距离非常简单——只要沿着轴，在图形上找到适当的点时添加数据点。然后，当我们向模型中输入新数据时，该算法会找到与新数据最近的 k 个数据点，并预测该目标是邻居中最常出现的目标。</p><p id="5d9f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果这仍然令人困惑，不要害怕！一旦我们将它应用到真实的数据集，它将变得有意义。</p><p id="8168" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">泰坦尼克号数据集</strong></p><p id="f259" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">如果您想了解这个示例，只需在这里</em>  <em class="lq">下载数据</em> <a class="ae mp" href="https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv" rel="noopener ugc nofollow" target="_blank"> <em class="lq">，并将 csv 文件添加到与 Python 笔记本相同的文件夹中。(参见源代码</em> </a><a class="ae mp" href="https://github.com/AndrewSLowe/KNN_from_Scratch" rel="noopener ugc nofollow" target="_blank"> <em class="lq">此处</em> </a> <em class="lq"> ) </em></p><p id="a3fe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于 KNNClassifier 是一个分类模型，我们需要一个数据集来预测一些离散的目标(与回归模型相反，回归模型预测连续统上的值)。在这个练习中，我们将使用可能是学习分类模型最流行的数据集 Titanic 数据集。我们试图预测的是，根据我们对一个人的一些特征的了解，这个人是否能在泰坦尼克号沉没后幸存下来。</p><p id="7748" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面是我们需要的导入和加载数据的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="2c3a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们接着运行<code class="fe ms mt mu mv b">df.head()</code>，我们可以观察前 5 行，并看到我们正在处理的特性:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/096d51fb9edeaeab6cd37fcd5a33be52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tpt93puTf-YPfGPUGVbmPw.png"/></div></div></figure><p id="a0ea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果您不熟悉数据集，请花点时间尝试并预测哪些特征与存活率最相关。</p><h2 id="dfc2" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated"><strong class="ak">预处理和列车测试分割</strong></h2><p id="b5b5" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated"><code class="fe ms mt mu mv b">survived</code>列——最左边的列——是我们试图预测的(也称为 y 变量或“目标”)。其余的特征是我们用来预测目标的。我们现在需要做一些预处理工作，以最好地建立我们的模型来预测。由于这篇文章的重点是机器学习算法，我们将尽可能简单地进行预处理。</p><p id="7f06" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将首先删除“姓名”和“费用”列，因为“姓名”并不能决定某人是否幸存，而“费用”与“等级”密切相关。然后我们将使用<code class="fe ms mt mu mv b">pd.get_dummies()</code>将“性别”列一次性编码成两列，男性和女性。代码如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="3826" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们的数据已经处理完毕，我们可以执行训练测试分割。这是监督机器学习模型的标准——其思想是，我们在训练数据上训练算法，并通过在我们的测试数据上评估它来测试模型的性能。幸运的是，scikit-learn 库有一个内置模块可以轻松地执行分割:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="9c3e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">带 Scikit 的 KNN classifier-Learn</strong></p><p id="38ea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先让我们看看如何使用 scikit-learn 来编码这个问题。由于所有的预处理和训练-测试-拆分都已完成，因此根据数据训练模型并做出预测只需三行代码。我们将首先制作一个模型对象，然后使用<code class="fe ms mt mu mv b">.fit</code>方法根据数据训练模型，使用<code class="fe ms mt mu mv b">.predict</code>方法根据模型从训练数据中学到的知识对测试集中的每个值进行预测:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="252f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出显示了测试数据中表示的每个人的生存状态预测。“1”表示模型预测此人幸存,“0”表示模型预测此人未能幸存:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/74ece50420de97a8d855b7cd43f4de8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZosBn-oSIe37oJPv8WZODg.png"/></div></div></figure><p id="91e8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">手动 KNN 算法</strong></p><p id="d845" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">既然我们已经使用 sklearn 库对测试集进行了预测，并且对幕后发生的事情有了基本的了解，那么让我们构建自己的 KNNClassifier 自制版本。我们将使用面向对象的编程来构建模型。(如果您对类和 OOP 不熟悉，请务必关注我的一系列博客文章，在这些文章中，我们将学习 OOP 并使用类来构建一个基于文本的冒险游戏！)</p><p id="5284" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们首先需要的是辅助函数。这些函数存在于类的外部，我们在类内部调用它们来执行一些操作。下面是一个自制的平方根函数和欧几里德距离公式:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="3ce3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如上所述，欧几里德距离本质上是两条数据之间的直线。该函数只是简单地将两行之间的每一列的值之间的距离相加，然后求出该和的平方根。</p><p id="2aa4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">接下来我们将编写 KNNHomebrew 函数。该类中的方法模拟了 scikit-learn knnclassifier 模型完成的操作。我们有一个<code class="fe ms mt mu mv b">model_fit()</code>方法，一个<code class="fe ms mt mu mv b">model_predict</code>方法，它对一个新的数据点进行预测，还有一个<code class="fe ms mt mu mv b">model_predict_all</code>方法，它对一组新的数据进行预测。文本注释中解释了每行代码的具体功能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="f8a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在是关键时刻了！让我们看看是否可以像调用 scikit-learn 模型一样调用我们的模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="6edc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/2f5b7bf73c864e9214162411583e0047.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iJ6gxiu1JKjcYA2pUD_CUw.png"/></div></div></figure><p id="0044" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">如果你继续下去，你会注意到 hombrew 模型比 scikit-learn 模型慢得多——可怜可怜我吧，我只是个初级开发人员。我可能会写一篇后续的博客文章，在那里我优化了算法，并使时间低于 1 秒，但现在，让我们看看我们的模型与 scikit-learn 模型的性能相比如何。</em></p><h2 id="debc" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated"><strong class="ak">比较型号</strong></h2><p id="f35d" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">现在是时候对比一下车型的性能了。首先，我们需要找到基线。在运行任何机器学习模型之前，这是最佳实践。对于分类问题，问题是，如果我们猜测所有新数据的主要类别，我们猜对的频率是多少？</p><p id="f56b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一个非常简单的计算，我们需要做的就是将训练集中多数类的出现次数除以数据集中的观察总数。多数类为 0 或“未存活”。假设我们的训练数据是一个真正的随机样本，在我们进行任何机器学习或预测分析之前，我们应该用任何新数据来预测这个类。由于我们的准确率是 61.24%，我们可以假设这个天真的预测有 61.24%是正确的。</p><p id="72a9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在让我们看看我们的模型和 scikit-learn 模型是如何比较的。下面是查找 Scikit-Learn 模型和我们的 KNNHomebrew 模型的准确性的代码:</p><ol class=""><li id="008c" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated">Scikit-learn: <code class="fe ms mt mu mv b">model.score(X_test, y_test)</code></li><li id="e590" class="mz na it kw b kx ni la nj ld nk lh nl ll nm lp ne nf ng nh bi translated">KNNHomebrew: <code class="fe ms mt mu mv b">knnHB.model_accuracy(X_test, y_test)</code></li></ol><p id="75fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果是:</p><ol class=""><li id="9b5c" class="mz na it kw b kx ky la lb ld nb lh nc ll nd lp ne nf ng nh bi translated">科学知识-学习:75.84%</li><li id="9dea" class="mz na it kw b kx ni la nj ld nk lh nl ll nm lp ne nf ng nh bi translated">KNNHomebrew: 72.47%</li></ol><p id="499d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，在其当前的形式下，似乎 scikit-learn 模型将比我们的 KNNHomebrew 模型多正确预测新数据的生存大约 3.5%…失败:(</p><p id="a810" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">开玩笑！这个练习的目的不是要打败 Python 中最流行的机器学习库之一，而是要了解其背后的东西。</p><h2 id="d522" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">敬请关注。</h2><p id="299e" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">揭示机器学习算法的所谓“黑盒”中的魔力是有趣且极具教育意义的。我计划在其他预测模型上发表更多这样的博文，所以请保持警惕！</p></div></div>    
</body>
</html>