<html>
<head>
<title>Web Scraping with Python Made Easy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python简化Web抓取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/web-scraping-with-python-made-easy-f069ffaf7754?source=collection_archive---------15-----------------------#2020-01-28">https://towardsdatascience.com/web-scraping-with-python-made-easy-f069ffaf7754?source=collection_archive---------15-----------------------#2020-01-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8fbc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何用Python抓取网站</h2></div><p id="72ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Beautiful Soup是一个Python库，便于从网站上抓取信息。在这篇文章中，我想向你展示一些基础知识，让你自己开始抓取网站。我们将一步一步地<strong class="kh ir">构建一个Python Web Scraper </strong>。这比听起来容易。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/db2bc8f0e8b8c39be40d56ac70db7a2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iHgLhRImp4ufuU8jAlNcxQ.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">照片由<a class="ae lr" href="https://www.pexels.com/@markusspiske?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克·temporausch.com</a>从<a class="ae lr" href="https://www.pexels.com/photo/creative-internet-computer-display-2004161/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">派克斯</a>拍摄</p></figure><h1 id="29e2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">为什么使用Python Web抓取？</h1><p id="a17f" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">网络抓取包括通过程序或脚本从网站提取信息。抓取有助于自动提取数据，比我们手动提取信息要快得多。它真的可以节省数小时的手工和繁琐的工作。</p><p id="e049" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，如果我们想获得一个包含上传到易贝“无线耳机”类别的所有产品名称的列表，我们可以编写一个Python脚本，并使用Beautiful soup自动完成这项任务。</p><h1 id="00e9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">如何装美汤？</h1><p id="d7b7" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在终端中运行pip命令可以安装Beautiful Soup。查看官方<a class="ae lr" href="https://pypi.org/project/beautifulsoup4/" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多详情。</p><p id="a795" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mp mq mr ms b">pip install beautifulsoup4</code></p><p id="7473" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在开始编写我们的代码之前，请注意，虽然抓取公共数据并不违法，但我们应该避免每秒向网站发出数百个请求，因为这可能会使网站服务器过载。此外，最好检查你打算删除的网站的条款，以了解它们是否允许删除。</p><h1 id="beea" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">创建我们的Python刮刀</h1><p id="9d08" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">好，我们开始吧。我们将抓取<a class="ae lr" href="https://cryptonewsandprices.me/" rel="noopener ugc nofollow" target="_blank"> cryptonewsandprices.me </a>这是一个包含加密新闻库的网站。<strong class="kh ir">我们的目标是从站点中提取出版的<em class="mt">标题</em> </strong>和<em class="mt">日期</em>。</p><p id="48cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们应该检查网页的<em class="mt"> html </em>代码，以确定我们希望从站点中提取哪些元素。我们在这篇文章中删除的页面如下所示:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mu"><img src="../Images/b37a15487ce4570ae8694c3ac0d52f9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QrZOc_knBv8u5tjK"/></div></div></figure><p id="8060" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要查看该站点的页面源，右键选择“<em class="mt">查看页面源</em>”。然后，我们就可以看到我们将使用美汤<strong class="kh ir">解析的站点的<em class="mt"> html </em> <em class="mt">源代码</em> <em class="mt">代码</em>。通过查看下面的<em class="mt"> html </em> <em class="mt"> source </em>的摘录，我们可以看到我们的标题被一个<strong class="kh ir"> <em class="mt"> h5标签</em> </strong>和<strong class="kh ir">类“card-title”</strong>所包围。在Beautiful Soup及其强大的解析器的帮助下，我们将使用这些标识符来删除信息。</strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mu"><img src="../Images/53298ffb6f55574f0186588c5efe667e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EVmeSmDvBR6pPy-L"/></div></div></figure><p id="a457" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们需要做的第一件事是导入我们的库<em class="mt">请求</em>和<strong class="kh ir"> <em class="mt">美丽组</em> </strong>。因为我们需要向要废弃的页面发送一个请求，所以我们需要使用请求库。然后，一旦我们得到来自站点的响应，我们将它存储在一个名为"<em class="mt"> mainContent </em>的变量中，稍后我们将解析它:</p><pre class="lc ld le lf gt mv ms mw mx aw my bi"><span id="0db3" class="mz lt iq ms b gy na nb l nc nd">import requests<br/>from bs4 import BeautifulSoup</span><span id="c42e" class="mz lt iq ms b gy ne nb l nc nd">mainContent = requests.get("https://cryptonewsandprices.me/") print(mainContent.text)</span></pre><p id="2eb2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的问题是，我们用<em class="mt"> requests.get </em>得到的请求不是很用户友好，因此，我们需要把它转换成更容易理解的东西。注意，我们的mainContent变量包含了站点的整个html代码。</p><h1 id="a230" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">从一个元素中抓取信息</h1><p id="6383" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">现在让我们摘录一下<em class="mt">新闻标题</em>。首先，我们需要将我们在<em class="mt">main content</em>变量中的字符串转换成一个<em class="mt"> soup </em><strong class="kh ir">Beautiful Soup</strong>解析器能够理解(并解析)的“<em class="mt">Soup</em>”。可以选择不同的解析器来读取数据。在这篇文章中，我使用“<em class="mt"> lxml </em>”，因为它是最通用和最快的解析器之一。</p><p id="3c6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面的代码行中，<em class="mt"> Soup </em>包含了我们的get请求所指向的整个页面的html代码。然后，<strong class="kh ir">美汤lxml解析器</strong>让我们从html源代码中提取想要的信息。</p><p id="40a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Beautiful Soup提供了一些方法来提取<em class="mt"> html </em>标签、<em class="mt">类</em>或网站中其他元素中的文本。既然我们知道每条新闻的标题都使用了一个<em class="mt">H5</em>T50】html标签和类<em class="mt"> card-title </em>，我们可以使用“find”在页面中定位它们，并将值提取到我们的title变量中。此外，我们使用“get_text()”只提取html标签h5和类“card-title”中的文本，而不提取html标记。</p><pre class="lc ld le lf gt mv ms mw mx aw my bi"><span id="70fa" class="mz lt iq ms b gy na nb l nc nd">soup = BeautifulSoup(mainContent.text,'lxml')<br/>title = soup.find('h5', class_='card-title').get_text()<br/>print(title)</span></pre><p id="d64f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">太好了，我们已经在页面上打印了第一篇新闻的标题。现在，让我们提取关于这篇文章何时发表的信息。为此，我们首先需要查看一下站点，了解我们可以使用哪个html元素来识别“<em class="mt">发布在</em>之前”的信息。</p><p id="f5dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如下图所示，我们可以通过“<em class="mt"> small </em>标签和“<em class="mt"> text-info </em>类来识别元素。同样，我们可以使用方法<strong class="kh ir"> <em class="mt"> find </em> </strong>从我们的站点定位并提取对象。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mu"><img src="../Images/229aaf69cfc811bfb96c8e31daec7e07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RZ7sPDPHiiv_-f7K"/></div></div></figure><pre class="lc ld le lf gt mv ms mw mx aw my bi"><span id="e4c1" class="mz lt iq ms b gy na nb l nc nd">published = soup.find('small', class_='text-info').get_text().strip()</span><span id="423d" class="mz lt iq ms b gy ne nb l nc nd">print(published)</span></pre><p id="435f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">太好了，现在我们有了发布的信息和最新文章中的图片。</p><h1 id="c451" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">从多个元素中抓取信息</h1><p id="b4f3" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">如果能从所有新闻中获得所有标题<em class="mt">和发布的<em class="mt">信息，而不是只有一个新闻元素，那就更好了。为此，BS有一个方法叫做<strong class="kh ir"> <em class="mt"> find_all </em> </strong>。其工作原理类似于<strong class="kh ir"> <em class="mt">查找</em> </strong>:</em></em></p><pre class="lc ld le lf gt mv ms mw mx aw my bi"><span id="ff04" class="mz lt iq ms b gy na nb l nc nd">titleall = soup.find_all('h5', class_='card-title')<br/>print(titleall)</span><span id="220b" class="mz lt iq ms b gy ne nb l nc nd">##printed answer [&lt;h5 class="card-title"&gt;Ex-UFC Fighter &amp;amp; Bitcoin Bull Ben Askren: XRP is a Scam &lt;/h5&gt;, &lt;h5 class="card-title"&gt;Opporty founder calls SEC's ICO lawsuit 'grossly overstated' and 'untruthful' in an open letter &lt;/h5&gt;,...]</span></pre><p id="18c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">美汤<em class="mt">查找所有</em>方法</strong>返回的是一个包含网站包含的所有新闻标题的列表。列表中的每个元素都是一个标题。然而，我们将<em class="mt"> html h5 </em>标签作为结果的一部分。</p><p id="61f9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们之前用来提取文本的Get_text 方法不适用于列表。因此，为了获得没有html标签的每个标题，我们可以遍历列表，然后将<em class="mt"> get_text </em>应用于列表的每次迭代，以将其附加到名为title_list的新列表中:</p><pre class="lc ld le lf gt mv ms mw mx aw my bi"><span id="98ef" class="mz lt iq ms b gy na nb l nc nd">title_list =[]</span><span id="5d5a" class="mz lt iq ms b gy ne nb l nc nd">for item in titleall: <br/>   individualtitle = item.get_text() <br/>   title_list.append(individualtitle) </span><span id="7061" class="mz lt iq ms b gy ne nb l nc nd">print(title_list)</span></pre><p id="397c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很好，现在我们得到了没有html标签的标题，只有文本。</p><h1 id="5520" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">完成我们的Python Web Scraper</h1><p id="8860" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">作为最后一步，如果我们能够提取标题并将其写入一个<em class="mt"> csv </em>文件，那将会非常有趣。为此，我们可以使用csv库和writer方法:</p><pre class="lc ld le lf gt mv ms mw mx aw my bi"><span id="3ffe" class="mz lt iq ms b gy na nb l nc nd">import csv </span><span id="f60c" class="mz lt iq ms b gy ne nb l nc nd">with open('pythonscraper.csv','w') as csvfile: <br/>     writer = csv.writer(csvfile)<br/>     for item in title_list: <br/>        writer.writerow([item])</span></pre><p id="ed38" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就像这样，我们在一个<em class="mt"> csv </em>文件中获得标题新闻列表。你现在可以自己尝试并提取任何其他信息。</p><p id="5a03" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果有什么不清楚的地方，请不要犹豫，在这里写下评论，或者观看下面的Youtube视频，在那里我一行一行地浏览脚本。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nf ng l"/></div></figure></div><div class="ab cl nh ni hu nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="ij ik il im in"><p id="611d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mt">原载于2020年1月28日https://codingandfun.com</em><a class="ae lr" href="https://codingandfun.com/web-scraping-with-python/" rel="noopener ugc nofollow" target="_blank"><em class="mt"/></a><em class="mt">。</em></p></div></div>    
</body>
</html>