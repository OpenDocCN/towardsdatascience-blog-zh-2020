<html>
<head>
<title>Model Selection &amp; Assessment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型选择和评估</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/model-selection-assessment-bb2d74229172?source=collection_archive---------43-----------------------#2020-05-12">https://towardsdatascience.com/model-selection-assessment-bb2d74229172?source=collection_archive---------43-----------------------#2020-05-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f0f0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">超越火车价值测试分裂</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f90b7cf1742325419d3e1b215db348f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UVo_eZjJNnEghLxvtVNXuQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://pixabay.com/illustrations/cubes-choice-one-yellow-light-2492010/" rel="noopener ugc nofollow" target="_blank">https://pix abay . com/illustrations/cubes-choice-one-yellow-light-2492010/</a></p></figure><p id="f766" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">标准的建模工作流会将您的数据划分为训练集、验证集和测试集。然后，您将使您的模型适合训练数据，然后使用验证集来执行<strong class="lb iu">模型选择</strong>，最后，评估测试数据上的最佳选择模型，以查看它可以预期的泛化性能(<strong class="lb iu">模型评估</strong>)。这个流程大概是您的最佳选择，以确保您选择了正确的模型，并且一旦您将它部署到生产中，您就不会感到吃惊。</p><p id="e024" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也就是说，人们不能总是奢侈地将数据放在一边以形成验证和测试集。如果你的数据很少，你宁愿把它全部用于训练。在本文中，我们将讨论选择和评估模型的方法，这些方法可以让您做到这一点——不需要验证也不需要测试集！</p><p id="3411" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文基于Hastie，t .，Tibshirani，r .，&amp; Friedman，J. H. (2009)的一章。统计学习的要素:数据挖掘、推理和预测。第二版。纽约:斯普林格。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/4fa79d8e1efffb34c1c49ca6a5ee5eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Hnd_TV9wu8KY5sWnN_sTw.png"/></div></div></figure><h1 id="82b9" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">关于模型误差</h1><p id="b8bc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在比较竞争模型时，您可能会选择在新的、看不见的数据上表现最好的模型。这就是您通常使用验证集的目的:模型拟合时，验证数据是不可见的，因此选择最适合这些数据的模型是一个好策略。唉，在我们的设置中，您没有验证数据来检查不同的模型！为了了解如何解决这个问题，我们先来介绍几个误差测量方法:</p><ul class=""><li id="e02f" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">训练误差</strong>是当你在训练模型的相同数据上运行训练模型时得到的误差。</li><li id="93b9" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">测试(或推广)误差</strong>是当你在全新的、看不见的数据上运行你的模型时你得到的误差。</li><li id="7db7" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">假设在对模型进行训练后，您观察到响应变量的新值与训练数据中的属性值相同。例如，假设您根据房间数量来预测房子的价格。在您的训练数据中，您有一个价值$300𝑘的房子，有5个房间，现在您观察一个为$350𝑘出售的房子，也有5个房间。模型对这些新数据产生的误差被称为<strong class="lb iu">样本内误差</strong>(因为特征的值与训练样本中的值相同——我同意这不是最直接的表示法)。</li></ul><p id="ddd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在考虑这个量:<strong class="lb iu">样本内误差—训练误差</strong>。它通常是正的:训练误差较小，因为它基于模型被优化的完全相同的数据。但是这到底意味着什么呢？嗯，可以证明(达到预期)它认为</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/531a98fe721cbc12d4f51095843ff57f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*DHasWYTB6wXhVpZER-qJ_w.png"/></div></figure><p id="1cdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，𝑁是观察值的数量，最后一项是训练集响应与其预测值之间的协方差。这个协方差越大，我们对训练数据的模型拟合就越强(达到过拟合的程度)，因此训练误差下降，增加了等式的左侧。</p><p id="0912" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们假设(这是一个重要的假设)我们正在处理一个参数是<strong class="lb iu">线性的模型。这意味着我们在谈论<a class="ae ky" rel="noopener" target="_blank" href="/a-comparison-of-shrinkage-and-selection-methods-for-linear-regression-ee4dd3a71f16">线性</a>或<a class="ae ky" rel="noopener" target="_blank" href="/linear-classifiers-an-overview-e121135bd3bb">逻辑</a>回归模型、<a class="ae ky" rel="noopener" target="_blank" href="/non-linear-regression-basis-expansion-polynomials-splines-2d7adb2cc226">非线性样条</a>或自回归模型。在这种情况下，上面的协方差项简化为<em class="ni"> d * </em> σϵ，其中𝑑是模型复杂性的度量(线性回归中的要素数量，回归样条中的基函数数量)，σϵ是误差方差。在替换这种简化并重新排列术语后，我们得到</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/47a86abd8304f73ea987bbd639ca9f85.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*rN0ysKL-62qHVJrPpPtrXg.png"/></div></figure><p id="81cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这给了我们什么？如果我们可以估计最右边的项，那么我们可以将它添加到训练误差中，以获得样本内误差的估计值。而<strong class="lb iu">样品内误差正是我们选型所需要的</strong>！当然，它没有给我们关于模型的泛化性能的信息(这是<strong class="lb iu">模型评估</strong>的作用，请继续阅读)。此外，我们并不真正关心样本内错误的具体值——在部署后看到与训练数据中相同的特征值是相当罕见的。但是<strong class="lb iu">不同模型的样本内误差的相对大小允许我们选择最好的一个</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/4fa79d8e1efffb34c1c49ca6a5ee5eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Hnd_TV9wu8KY5sWnN_sTw.png"/></div></div></figure><h1 id="5134" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">基于信息准则的模型选择</h1><p id="3e9d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">上述公式也被称为<strong class="lb iu">软糖的𝐶𝑝 </strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/37f18c2e7da583d36b4b1be941749a94.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*66aullIKNz9pXXy60uCupQ.png"/></div></figure><p id="837a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当模型符合平方损失时，它可用于模型选择，我们只需选择具有最低𝐶𝑝.的模型</p><p id="500e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果模型不一定符合平方损失，我们需要稍微调整Mallows的𝐶𝑝。回想一下，我们讨论的是参数线性的模型:想想线性或逻辑回归、回归样条或ARIMA模型。它们通常由最大似然估计，在高斯模型下，它保持(直到一个常数)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/1809c63c4ae666b607207cbc75df0fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*QGsVZm0ocsjEMOLeaTZWdg.png"/></div></figure><p id="3e37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">求解𝑒_𝑡𝑟𝑎𝑖𝑛并将其代入𝐶𝑝公式，我们得到<strong class="lb iu">阿凯克信息标准或AIC </strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/4a4a039a046adedd1da7c6fc3ade22d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*kwqjLdJX2WKGWKPJ2qXpOA.png"/></div></figure><p id="3134" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">AIC基本上是一个惩罚的可能性。它随着模型复杂性𝑑的增加而上升，随着模型与数据的拟合度(对数似然)的增加而下降，权衡这两者。我们选择AIC最低的型号。最好的一点是<strong class="lb iu">尽管AIC是仅使用训练数据计算的，但最小化它在渐近上等价于最小化留一交叉验证均方误差</strong>，这对于模型选择来说非常好。关于AIC的更多警告(也是在时间序列预测的背景下),请查看Rob Hyndman 的这篇<a class="ae ky" href="https://robjhyndman.com/hyndsight/aic/" rel="noopener ugc nofollow" target="_blank">精彩文章，他是R的<code class="fe nn no np nq b">forecast</code>软件包的作者。</a></p><p id="dc59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们看一个用AIC进行模型选择的Python例子。我们将使用来自scikit-learn数据集的臭名昭著的波士顿住房数据。我们来拟合两个解释房价的线性回归模型。我们将为此使用<code class="fe nn no np nq b">statsmodels</code>包，因为它可以方便地为我们计算AIC。这两个模型都将使用房间数量和房龄作为特征。模型1将在此基础上使用社区犯罪率，而模型2将使用到大型就业中心的距离。这两种型号哪个更好？</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><pre class="kj kk kl km gt nt nq nu nv aw nw bi"><span id="2708" class="nx lx it nq b gy ny nz l oa ob">Model1 AIC: 3268.8701039911457<br/>Model2 AIC: 3300.3758836602733</span></pre><p id="9cf2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就AIC而言，模型1(使用犯罪率的模型)更好，因为它的AIC值更低。</p><p id="e766" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">AIC不是唯一的信息标准。另一个是<strong class="lb iu"> BIC，或贝叶斯信息准则</strong>，也称为施瓦兹准则。与AIC类似，BIC也是一个被处罚的可能性，但处罚条款不同:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/fde56f5d663f322a4ea8fecaae441b56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*NInEpTtDINzP4oupCDF5bg.png"/></div></figure><p id="bd30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种惩罚比AIC更倾向于惩罚更复杂的模型。让我们看看这两个房价模型在BIC的表现如何。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><pre class="kj kk kl km gt nt nq nu nv aw nw bi"><span id="626b" class="nx lx it nq b gy ny nz l oa ob">Model1 BIC: 3285.7762506682957<br/>Model2 BIC: 3317.2820303374233</span></pre><p id="ecde" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，模型1是首选，因为它得分较低的BIC。在我们的例子中，这两个标准是一致的，但情况并不一定如此。那么我们应该根据什么标准来选择模型呢？没有放之四海而皆准的答案，但请记住以下几点:</p><ul class=""><li id="86a5" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">BIC是渐近一致的，这意味着当呈现一组竞争模型时，它有很高的概率选择<em class="ni">真</em>模型(根据该模型生成数据)。</li><li id="7300" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">AIC没有一致性，但是你相信有一个真正的模型可以选择吗？</li><li id="e233" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">BIC喜欢更节俭的模式。对于小数据样本，它可能会选择过于简单的模型。另一方面，对于大样本，AIC倾向于选择过于复杂的样本。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/4fa79d8e1efffb34c1c49ca6a5ee5eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Hnd_TV9wu8KY5sWnN_sTw.png"/></div></div></figure><h1 id="5b84" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">交叉验证的模型评估</h1><p id="db24" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在，我们已经选择了包含犯罪率特性的模型，如果能知道它部署后的预期性能，那就太好了。<strong class="lb iu">这就是模型评估的工作——评估模型的测试误差。</strong></p><p id="122c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一种方法是通过众所周知的交叉验证程序。我们将数据随机分成𝑘子集或褶皱，然后迭代通过它们，留下当前的褶皱，并用剩余的𝑘−1褶皱拟合模型。然后，我们评估模型在遗漏折叠上的误差，并进行下一次迭代。这样，我们获得了𝑘误差估计。一旦取平均，它们就形成了测试误差的交叉验证估计值。很简单，对吧？但是𝑘的价值应该是什么呢？</p><p id="e0be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">像机器学习中的许多其他选择一样，𝑘的选择是在偏差和方差之间。</strong>走极端设置𝑘=𝑁会导致所谓的留一交叉验证。在这种情况下，每个观察构成了它自己的折叠。因此，训练集在褶皱上非常相似，事实上，它们只有一个观察结果不同。因此，测试误差的CV估计值可能会受到高方差的影响。另一方面，当𝑘很小的时候，我们就有高度偏见的风险。这是因为𝑘越小，构成𝑘−1训练褶皱的观测值就越少。例如，考虑一下𝑁=100的观察。对于𝑘=10，每个折叠有10个观察值，因此每次训练都基于90个观察值。对于𝑘=4，每次训练仅使用75个观察值。如果模型性能随着训练数据的减少而降低，过低的𝑘将导致高估的误差。</p><p id="d36a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终，𝑘的选择应取决于您的应用。𝑘=𝑁很少是一个好主意——运行起来计算量也很大(𝑁模型需要训练)！您最了解您的数据-如果您愿意假设(或已经证明)更少的数据不会对您的模型的性能产生太大影响，那么您可以选择3或5这样的小𝑘。但是如果你只有很少的数据，情况可能就不一样了(如果你有大数据，你可以遵循标准的训练/验证/测试分割，忽略这篇文章)。因此，稍微大一点的𝑘，比如10，可能值得一试。还有一点需要考虑:如果你的𝑘太小，误差将会被<strong class="lb iu">高估</strong>，这意味着真实的测试误差可能会比你的简历告诉你的要小。如果您对交叉验证的误差估计值感到满意，您可能会对生产性能更加满意。</p><p id="91d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用10重交叉验证来评估我们选择的模型。为此，我们将使用<code class="fe nn no np nq b">scikit-learn</code> API。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><pre class="kj kk kl km gt nt nq nu nv aw nw bi"><span id="bc2d" class="nx lx it nq b gy ny nz l oa ob">Cross-validated testing MSE: 43.925463559757674</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/4fa79d8e1efffb34c1c49ca6a5ee5eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Hnd_TV9wu8KY5sWnN_sTw.png"/></div></div></figure><h1 id="9331" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结束语</h1><p id="1ba8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">总结一下:刚刚发生了什么？如果您没有足够的数据来留出验证和测试集，您需要其他方法来进行模型选择和评估。我们已经展示了什么是信息标准以及如何将它们用于模型选择，然后如何通过交叉验证来估计所选模型的预期真实性能。</p><p id="e32b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为什么不用CV来选模型，我听到你问。你可以的！然而，对于小数据，信息标准往往更可靠。如果你的简历会因为数据太少而有偏差，至少你会知道你选择的模型是正确的——即使它的交叉验证测试误差估计远非完美。</p><p id="f965" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读！我希望你已经学到了对你的项目有益的东西🚀</p><p id="b55b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢这篇文章，试试我的其他文章。不能选择？从这些中选择一个:</p><div class="od oe gp gr of og"><a rel="noopener follow" target="_blank" href="/boost-your-grasp-on-boosting-acf239694b1"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">增强你对助推的把握</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">揭秘著名的竞赛获奖算法。</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="oq l or os ot op ou ks og"/></div></div></a></div><div class="od oe gp gr of og"><a rel="noopener follow" target="_blank" href="/a-comparison-of-shrinkage-and-selection-methods-for-linear-regression-ee4dd3a71f16"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">线性回归中收缩法和选择法的比较</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">详细介绍7种流行的收缩和选择方法。</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="ov l or os ot op ou ks og"/></div></div></a></div><div class="od oe gp gr of og"><a rel="noopener follow" target="_blank" href="/non-linear-regression-basis-expansion-polynomials-splines-2d7adb2cc226"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">非线性回归:基础扩展、多项式和样条</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">如何用多项式和样条捕捉非线性关系？</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="ow l or os ot op ou ks og"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/4fa79d8e1efffb34c1c49ca6a5ee5eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Hnd_TV9wu8KY5sWnN_sTw.png"/></div></div></figure><h1 id="aa16" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">来源</h1><ol class=""><li id="f75f" class="mt mu it lb b lc mo lf mp li ox lm oy lq oz lu pa mz na nb bi translated">Hastie，Tibshirani，r .，，j . h . Friedman(2009年)。统计学习的要素:数据挖掘、推理和预测。第二版。纽约:斯普林格。</li><li id="46bc" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu pa mz na nb bi translated">https://robjhyndman.com/hyndsight/aic/<a class="ae ky" href="https://robjhyndman.com/hyndsight/aic/" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>