<html>
<head>
<title>Time Series Modeling using Scikit, Pandas, and Numpy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scikit、Pandas和Numpy进行时间序列建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1?source=collection_archive---------0-----------------------#2020-06-14">https://towardsdatascience.com/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1?source=collection_archive---------0-----------------------#2020-06-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c16d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">直观地利用季节性来提高模型准确性</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8f5cbd8ed5c8b337471a2c302fabebb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*drL2ir1YbXUIVw1AXxD2Fg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://medium.com/@vishi2020https://medium.com/@vishi2020" rel="noopener">作者</a></p></figure><p id="834f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">欢迎学习时间序列分析的第2部分！在本帖中，我们将通过建模时间序列数据来学习我们的方法。这是我上一篇关于时间序列数据的文章的延续。</p><p id="88a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们<a class="ae ky" rel="noopener" target="_blank" href="/time-series-analysis-using-pandas-in-python-f726d87a97d8">之前的博客文章</a>中，我们讨论了什么是时间序列数据，如何格式化这样的数据以最大化其效用，以及如何处理缺失数据。我们还学习了如何按月、周、年等对时间序列数据进行重采样，并计算滚动平均值。我们深入研究了趋势、季节性、一阶差分和自相关等概念。如果你熟悉大部分的东西，你就可以开始了。如果你需要复习，你可以在谷歌上快速搜索这些话题，或者在这里阅读我之前的文章<a class="ae ky" rel="noopener" target="_blank" href="/time-series-analysis-using-pandas-in-python-f726d87a97d8"/>。</p><h2 id="62ff" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">在我们开始之前说几句话:</h2><p id="3a42" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">毫无疑问，还有其他更好的用于时间序列预测的软件包，比如ARIMA的<a class="ae ky" href="https://www.statsmodels.org/devel/generated/statsmodels.tsa.arima_model.ARIMA.html" rel="noopener ugc nofollow" target="_blank">或者脸书的专有软件</a><a class="ae ky" href="https://facebook.github.io/prophet/#:~:text=Prophet%20is%20a%20procedure%20for,several%20seasons%20of%20historical%20data." rel="noopener ugc nofollow" target="_blank"> Prophet </a>。然而，这篇文章的灵感来自一个朋友的带回家的作业，该作业要求她只能使用Scikit、Numpy和Pandas(否则将面临立即取消资格！).</p><h1 id="7106" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">让我们深入我们的数据集</h1><p id="f37e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们将使用公开的数据集开放电力系统数据。你可以在这里下载数据<a class="ae ky" href="https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv" rel="noopener ugc nofollow" target="_blank">。它包含2006-2017年的电力消耗、风力发电和太阳能发电。</a></p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="96d8" class="lv lw it nf b gy nj nk l nl nm">url='<a class="ae ky" href="https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'</a><br/>data = pd.read_csv(url,sep=",")</span></pre><p id="6ad4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将<code class="fe nn no np nf b">Date</code>列设置为索引后，我们的数据集看起来是这样的:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="0197" class="lv lw it nf b gy nj nk l nl nm"><em class="nq"># to explicitly convert the date column to type DATETIME</em><br/>data['Date'] = pd.to_datetime(data['Date'])<br/>data = data.set_index('Date')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/1a69a704f4e1dc1a7a94eb54ce67d227.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/0*82pE15_BCQTYfMFe.png"/></div></figure><h1 id="8991" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">定义建模任务</h1><h2 id="f118" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">预测的目标</h2><p id="0bdc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们的目标是从这个时间序列数据集中预测<code class="fe nn no np nf b">Consumption</code>(理想情况下是未来未知的日期)。</p><h2 id="5525" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">训练和测试设备</h2><p id="936c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们将使用10年的数据进行培训，即2006-2016年，使用去年的数据进行测试，即2017年。</p><h2 id="d2f5" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">工作指标</h2><p id="c306" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了评估我们的模型有多好，我们将使用R-squared和均方根误差(但将打印所有相关指标，以便您进行最终通话)。</p><h1 id="e346" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">助手功能</h1><p id="e392" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了打印与回归任务相关的所有性能指标(比如MAE和R-square)，我们将定义<code class="fe nn no np nf b">regression_results</code>函数。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="883e" class="lv lw it nf b gy nj nk l nl nm">import sklearn.metrics as metrics<br/>def regression_results(y_true, y_pred):</span><span id="19e6" class="lv lw it nf b gy ns nk l nl nm"><em class="nq">    # Regression metrics</em><br/>    explained_variance=metrics.explained_variance_score(y_true, y_pred)<br/>    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) <br/>    mse=metrics.mean_squared_error(y_true, y_pred) <br/>    mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)<br/>    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)<br/>    r2=metrics.r2_score(y_true, y_pred)</span><span id="8cba" class="lv lw it nf b gy ns nk l nl nm">    print('explained_variance: ', round(explained_variance,4))    <br/>    print('mean_squared_log_error: ', round(mean_squared_log_error,4))<br/>    print('r2: ', round(r2,4))<br/>    print('MAE: ', round(mean_absolute_error,4))<br/>    print('MSE: ', round(mse,4))<br/>    print('RMSE: ', round(np.sqrt(mse),4))</span></pre><h1 id="67b1" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">特征工程</h1><p id="0506" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">作为基线，我们选择了一个简单的模型，该模型基于以下因素预测今天的消费价值</p><ul class=""><li id="d412" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated">昨天的消费值<strong class="lb iu">和；</strong></li><li id="712a" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">昨天和前天的消费值之差。</li></ul><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="3745" class="lv lw it nf b gy nj nk l nl nm"><em class="nq"># creating new dataframe from consumption column</em><br/>data_consumption = data[['Consumption']]</span><span id="35b9" class="lv lw it nf b gy ns nk l nl nm"><em class="nq"># inserting new column with yesterday's consumption values</em><br/>data_consumption.loc[:,'Yesterday'] = <br/>data_consumption.loc[:,'Consumption'].shift()</span><span id="13c5" class="lv lw it nf b gy ns nk l nl nm"><em class="nq"># inserting another column with difference between yesterday and day before yesterday's consumption values.<br/></em>data_consumption.loc[:,'Yesterday_Diff'] = data_consumption.loc[:,'Yesterday'].diff()</span><span id="63c8" class="lv lw it nf b gy ns nk l nl nm"><em class="nq"># dropping NAs</em><br/>data_consumption = data_consumption.dropna()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ae05961a9a70c637f73b2f30d90c1c81.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*RvqYTi5Gow5SheiPCMLMVQ.png"/></div></figure><h1 id="b8a9" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">定义训练集和测试集</h1><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="3a72" class="lv lw it nf b gy nj nk l nl nm">X_train = data_consumption[:'2016'].drop(['Consumption'], axis = 1)<br/>y_train = data_consumption.loc[:'2016', 'Consumption']</span><span id="c8ee" class="lv lw it nf b gy ns nk l nl nm">X_test = data_consumption['2017'].drop(['Consumption'], axis = 1)<br/>y_test = data_consumption.loc['2017', 'Consumption']</span></pre><h1 id="b139" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">时间序列数据的交叉验证</h1><p id="10fe" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在数据科学面试中经常出现的一个问题是:<em class="nq">你会对时间序列数据使用哪种交叉验证技术？</em></p><p id="19b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能会被有史以来最受欢迎的K倍交叉验证所吸引(相信我，直到最近——不要问最近！—我不知道除了K-fold之外还有CV技术。不幸的是，这不是正确的答案。原因是，它没有考虑到时间序列数据有一些自然的顺序，标准k倍交叉验证中的随机化没有保持这种顺序。</p><blockquote class="oi oj ok"><p id="5e09" class="kz la nq lb b lc ld ju le lf lg jx lh ol lj lk ll om ln lo lp on lr ls lt lu im bi translated">对时间序列数据进行交叉验证的一个更好的替代方法(比K-fold CV)是正向链接策略。</p></blockquote><p id="1b3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在正向链接中，假设有3个折叠，训练集和验证集看起来像:</p><ul class=""><li id="6a43" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated">折叠1:培训[1]，验证[2]</li><li id="08b2" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠2:培训[1 2]，验证[3]</li><li id="d2cf" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠3:培训[1 2 3]，验证[4]</li></ul><p id="b213" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中1，2，3，4代表年份。这样，连续的训练集是它们之前的训练集的超集。</p><p id="6f13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，sklearn有一个使用<code class="fe nn no np nf b">TimeSeriesSplit</code>实现这种列车测试分割的规定。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="cf23" class="lv lw it nf b gy nj nk l nl nm">from sklearn.model_selection import TimeSeriesSplit</span></pre><p id="32ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nn no np nf b">TimeSerieSplit</code>函数将分割数作为输入。由于我们的培训数据有11个独特的年份(2006 -2016)，我们将设置<code class="fe nn no np nf b">n_splits = 10</code>。这样我们就有了整洁的训练和验证集:</p><ul class=""><li id="1353" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated">折叠1:培训[2006]，验证[2007]</li><li id="40d8" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠2:培训[2006年2007年]，验证[2008年]</li><li id="18c8" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠3:培训[2006年2007年2008年]，验证[2009年]</li><li id="df2c" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠4:培训[2006年2007年2008年2009年]，验证[2010年]</li><li id="9f6e" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠5:培训[2006年2007年2008年2009年2010年]，验证[2011年]</li><li id="7fad" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠6:培训[2006年2007年2008年2009年2010年2011年]，验证[2012年]</li><li id="53cd" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠7:培训[2006年2007年2008年2009年2010年2011年2012年]，验证[2013年]</li><li id="8a30" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠8:培训[2006年2007年2008年2009年2010年2011年2012年2013年]，验证[2014年]</li><li id="af10" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠9:培训[2006年2007年2008年2009年2010年2011年2012年2013年2014年]，验证[2015年]</li><li id="d5bc" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">折叠10:培训[2006年2007年2008年2009年2010年2011年2012年2013年2014年2015年]，验证[2016年]</li></ul><h1 id="2bdf" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">抽查算法</h1><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="8c0d" class="lv lw it nf b gy nj nk l nl nm"><em class="nq"># Spot Check Algorithms</em></span><span id="d505" class="lv lw it nf b gy ns nk l nl nm">models = []<br/>models.append(('LR', LinearRegression()))<br/>models.append(('NN', MLPRegressor(solver = 'lbfgs')))  #neural network<br/>models.append(('KNN', KNeighborsRegressor())) <br/>models.append(('RF', RandomForestRegressor(n_estimators = 10))) # Ensemble method - collection of many decision trees<br/>models.append(('SVR', SVR(gamma='auto'))) # kernel = linear</span><span id="f435" class="lv lw it nf b gy ns nk l nl nm"><em class="nq"># Evaluate each model in turn</em><br/>results = []<br/>names = []<br/>for name, model in models:<br/>    <em class="nq"># TimeSeries Cross validation</em><br/> tscv = TimeSeriesSplit(n_splits=10)<br/>    <br/> cv_results = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')<br/> results.append(cv_results)<br/> names.append(name)<br/> print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))<br/>    <br/><em class="nq"># Compare Algorithms</em><br/>plt.boxplot(results, labels=names)<br/>plt.title('Algorithm Comparison')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/36f478ebe910d3b07fa6ec176cfa81ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*8ywSH5-NZpPI7gQbHUKB6Q.png"/></div></figure><p id="93e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">KNN和RF表现同样出色。但我个人更喜欢RF，因为这种集合模型(将多个‘个体’(不同的)模型结合在一起，并提供卓越的预测能力。)几乎可以开箱即用，这也是它们非常受欢迎的原因之一。</p><h1 id="cb7f" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">网格搜索超参数</h1><p id="b4dc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我在之前的文章中讨论了网格搜索超参数的必要性。</p><blockquote class="oi oj ok"><p id="0994" class="kz la nq lb b lc ld ju le lf lg jx lh ol lj lk ll om ln lo lp on lr ls lt lu im bi translated">超参数的最佳组合使模型的性能最大化，而不会导致高方差问题(过度拟合)。</p></blockquote><p id="1a33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">执行网格搜索的Python代码如下:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="2bd6" class="lv lw it nf b gy nj nk l nl nm">from sklearn.model_selection import GridSearchCV</span><span id="755a" class="lv lw it nf b gy ns nk l nl nm">model = RandomForestRegressor()<br/>param_search = { <br/>    'n_estimators': [20, 50, 100],<br/>    'max_features': ['auto', 'sqrt', 'log2'],<br/>    'max_depth' : [i for i in range(5,15)]<br/>}</span><span id="f6f8" class="lv lw it nf b gy ns nk l nl nm">tscv = TimeSeriesSplit(n_splits=10)<br/>gsearch = GridSearchCV(estimator=model, cv=tscv, param_grid=param_search, scoring = rmse_score)</span><span id="cf5b" class="lv lw it nf b gy ns nk l nl nm">gsearch.fit(X_train, y_train)<br/>best_score = gsearch.best_score_<br/>best_model = gsearch.best_estimator_</span></pre><p id="675c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你注意到上面的代码，我们已经通过设置<code class="fe nn no np nf b">scoring = rmse_score</code>定义了一个<em class="nq">自定义</em> <em class="nq">计分器</em>，而不是使用sklearn中定义的<a class="ae ky" href="https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules" rel="noopener ugc nofollow" target="_blank">通用计分指标</a>之一。我们将自定义计分器定义如下:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="dfc5" class="lv lw it nf b gy nj nk l nl nm">from sklearn.metrics import make_scorer</span><span id="88f0" class="lv lw it nf b gy ns nk l nl nm">def rmse(actual, predict):</span><span id="94ca" class="lv lw it nf b gy ns nk l nl nm">predict = np.array(predict)<br/>    actual = np.array(actual)</span><span id="290b" class="lv lw it nf b gy ns nk l nl nm">distance = predict - actual</span><span id="be2d" class="lv lw it nf b gy ns nk l nl nm">square_distance = distance ** 2</span><span id="a0fd" class="lv lw it nf b gy ns nk l nl nm">mean_square_distance = square_distance.mean()</span><span id="c198" class="lv lw it nf b gy ns nk l nl nm">score = np.sqrt(mean_square_distance)</span><span id="5614" class="lv lw it nf b gy ns nk l nl nm">return score</span><span id="badb" class="lv lw it nf b gy ns nk l nl nm">rmse_score = make_scorer(rmse, greater_is_better = False)</span></pre><h1 id="0813" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">根据测试数据检查最佳模型性能</h1><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="efae" class="lv lw it nf b gy nj nk l nl nm">y_true = y_test.values<br/>y_pred = best_model.predict(X_test)</span><span id="ac10" class="lv lw it nf b gy ns nk l nl nm">regression_results(y_true, y_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/bf639f8540686016473cc0a9f1cd758d.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*HhpaHNvhmOke00Ief_UHbg.png"/></div></figure><p id="4309" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这对初学者来说并不坏。让我们看看是否可以进一步改进我们的模型。</p><h1 id="030b" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">特征工程回报</h1><p id="461e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">到目前为止，我们一直使用<code class="fe nn no np nf b">(t-1)th</code>日的值来预测<code class="fe nn no np nf b">t</code>日的值。现在，让我们也使用<code class="fe nn no np nf b">(t-2)</code>天的值来预测消耗量:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="0fab" class="lv lw it nf b gy nj nk l nl nm"><em class="nq"># creating copy of original dataframe</em><br/>data_consumption_2o = data_consumption.copy()</span><span id="b8cb" class="lv lw it nf b gy ns nk l nl nm"><em class="nq"># inserting column with yesterday-1 values</em><br/>data_consumption_2o['Yesterday-1'] = data_consumption_2o['Yesterday'].shift()</span><span id="4f56" class="lv lw it nf b gy ns nk l nl nm"><em class="nq"># inserting column with difference in yesterday-1 and yesterday-2 values.</em><br/>data_consumption_2o['Yesterday-1_Diff'] = data_consumption_2o['Yesterday-1'].diff()</span><span id="4df9" class="lv lw it nf b gy ns nk l nl nm"><em class="nq"># dropping NAs</em><br/>data_consumption_2o = data_consumption_2o.dropna()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/2438f02c82b40b179d1067293fa846aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*othDvMvqoehEE_i-qQxDMw.png"/></div></figure><h2 id="74e8" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">重置列车和测试装置</h2><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="3f4a" class="lv lw it nf b gy nj nk l nl nm">X_train_2o = data_consumption_2o[:'2016'].drop(['Consumption'], axis = 1)<br/>y_train_2o = data_consumption_2o.loc[:'2016', 'Consumption']</span><span id="1ee0" class="lv lw it nf b gy ns nk l nl nm">X_test = data_consumption_2o['2017'].drop(['Consumption'], axis = 1)<br/>y_test = data_consumption_2o.loc['2017', 'Consumption']</span></pre><h2 id="7f00" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">检查使用“新”预测器的“最佳”随机森林是否表现更好</h2><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="3693" class="lv lw it nf b gy nj nk l nl nm">model = RandomForestRegressor()<br/>param_search = { <br/>    'n_estimators': [20, 50, 100],<br/>    'max_features': ['auto', 'sqrt', 'log2'],<br/>    'max_depth' : [i for i in range(5,15)]<br/>}</span><span id="ba69" class="lv lw it nf b gy ns nk l nl nm">tscv = TimeSeriesSplit(n_splits=10)<br/>gsearch = GridSearchCV(estimator=model, cv=tscv, param_grid=param_search, scoring = rmse_score)</span><span id="d80e" class="lv lw it nf b gy ns nk l nl nm">gsearch.fit(X_train_2o, y_train_2o)<br/>best_score = gsearch.best_score_<br/>best_model = gsearch.best_estimator_</span><span id="c337" class="lv lw it nf b gy ns nk l nl nm">y_true = y_test.values<br/>y_pred = best_model.predict(X_test)</span><span id="55c3" class="lv lw it nf b gy ns nk l nl nm">regression_results(y_true, y_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/2d9b55655eef07f57fc57491d62dd831.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*3bQ7eSxbfRQNYOy5rWmbWg.png"/></div></figure><p id="df70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好消息！！我们已经显著降低了RMSE和MAE值，而R平方值也上升了。</p><h1 id="1246" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">特征工程反击</h1><p id="4632" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们看看增加太阳能生产的价值是否在某种程度上有利于预测电力消耗。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="d7fc" class="lv lw it nf b gy nj nk l nl nm">data_consumption_2o_solar = data_consumption_2o.join(data[['Solar']])</span><span id="36f4" class="lv lw it nf b gy ns nk l nl nm">data_consumption_2o_solar = data_consumption_2o_solar.dropna()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/b482b46390af3d4c182d623762ab5ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*dd1t4Jc0HmkC6uP-BDdPNg.png"/></div></div></figure><h2 id="d40f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">重置训练/测试+网格搜索+检查性能</h2><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="9783" class="lv lw it nf b gy nj nk l nl nm">X_train_2o_solar = data_consumption_2o_solar[:'2016'].drop(['Consumption'], axis = 1)<br/>y_train_2o_solar = data_consumption_2o_solar.loc[:'2016', 'Consumption']</span><span id="ca80" class="lv lw it nf b gy ns nk l nl nm">X_test = data_consumption_2o_solar['2017'].drop(['Consumption'], axis = 1)<br/>y_test = data_consumption_2o_solar.loc['2017', 'Consumption']</span><span id="ce46" class="lv lw it nf b gy ns nk l nl nm">model = RandomForestRegressor()<br/>param_search = { <br/>    'n_estimators': [20, 50, 100],<br/>    'max_features': ['auto', 'sqrt', 'log2'],<br/>    'max_depth' : [i for i in range(5,15)]<br/>}</span><span id="585b" class="lv lw it nf b gy ns nk l nl nm">tscv = TimeSeriesSplit(n_splits=5)<br/>gsearch = GridSearchCV(estimator=model, cv=tscv, param_grid=param_search, scoring = rmse_score)</span><span id="d132" class="lv lw it nf b gy ns nk l nl nm">gsearch.fit(X_train_2o_solar, y_train_2o_solar)<br/>best_score = gsearch.best_score_<br/>best_model = gsearch.best_estimator_</span><span id="8508" class="lv lw it nf b gy ns nk l nl nm">y_true = y_test.values<br/>y_pred = best_model.predict(X_test)</span><span id="51b9" class="lv lw it nf b gy ns nk l nl nm">regression_results(y_true, y_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/a08cc48c0359e0eef91068ec8ba9ae61.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*zFBbjdXb_qLeVgq5Woh3Kw.png"/></div></figure><p id="3e6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">瞧，现在模型的性能更好了。</p><h1 id="d2e2" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">可变重要性图</h1><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="c504" class="lv lw it nf b gy nj nk l nl nm">imp = best_model.feature_importances_<br/>features = X_train_2o_solar.columns<br/>indices = np.argsort(imp)</span><span id="4fc3" class="lv lw it nf b gy ns nk l nl nm">plt.title('Feature Importances')<br/>plt.barh(range(len(indices)), imp[indices], color='b', align='center')<br/>plt.yticks(range(len(indices)), [features[i] for i in indices])<br/>plt.xlabel('Relative Importance')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/4576a72bce3fa042ae77ba9b70b6434c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*Bq-0PoboMwE6n6eBUN6Zdw.png"/></div></figure><p id="6b5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所见，太阳能发电量并不像其他基于时间的预测指标那样是一个强大的电力消耗预测指标。</p><h1 id="a7a6" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">特征工程的最后阶段</h1><p id="1f08" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如果你阅读了我前一篇博文第一部分的叙述，你会记得我们的数据集有一些季节性因素，更准确地说是每周季节性。因此，将给定日期前一周的消费值作为模型的输入更有意义。这意味着，如果模型试图预测1月8日的消费值，它必须获得1月1日的消费信息。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="cff9" class="lv lw it nf b gy nj nk l nl nm">data_consumption_2o_solar_weeklyShift = data_consumption_2o_solar.copy()</span><span id="0a3e" class="lv lw it nf b gy ns nk l nl nm">data_consumption_2o_solar_weeklyShift['Last_Week'] = data_consumption_2o_solar['Consumption'].shift(7)</span><span id="773f" class="lv lw it nf b gy ns nk l nl nm">data_consumption_2o_solar_weeklyShift = data_consumption_2o_solar_weeklyShift.dropna()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/e8d8d9ac398460d1e851f0ab04dfd3bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*Vq-VuFLN92xBAgZCF78qMA.png"/></div></figure><h2 id="ed65" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">重置训练/测试+网格搜索+检查性能</h2><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="07e4" class="lv lw it nf b gy nj nk l nl nm">X_train_2o_solar_weeklyShift = data_consumption_2o_solar_weeklyShift[:'2016'].drop(['Consumption'], axis = 1)<br/>y_train_2o_solar_weeklyShift = data_consumption_2o_solar_weeklyShift.loc[:'2016', 'Consumption']</span><span id="90b4" class="lv lw it nf b gy ns nk l nl nm">X_test = data_consumption_2o_solar_weeklyShift['2017'].drop(['Consumption'], axis = 1)<br/>y_test = data_consumption_2o_solar_weeklyShift.loc['2017', 'Consumption']</span><span id="aef9" class="lv lw it nf b gy ns nk l nl nm">model = RandomForestRegressor()<br/>param_search = { <br/>    'n_estimators': [20, 50, 100],<br/>    'max_features': ['auto', 'sqrt', 'log2'],<br/>    'max_depth' : [i for i in range(5,15)]<br/>}</span><span id="1c6f" class="lv lw it nf b gy ns nk l nl nm">tscv = TimeSeriesSplit(n_splits=10)<br/>gsearch = GridSearchCV(estimator=model, cv=tscv, param_grid=param_search, scoring = rmse_score)</span><span id="bc64" class="lv lw it nf b gy ns nk l nl nm">gsearch.fit(X_train_2o_solar_weeklyShift, y_train_2o_solar_weeklyShift)<br/>best_score = gsearch.best_score_<br/>best_model = gsearch.best_estimator_</span><span id="a633" class="lv lw it nf b gy ns nk l nl nm">y_true = y_test.values<br/>y_pred = best_model.predict(X_test)</span><span id="ee35" class="lv lw it nf b gy ns nk l nl nm">regression_results(y_true, y_pred)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/0311d5d0207933cf5093830c83aeea69.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*-Rl1fW81SuriezZuooj_Qg.png"/></div></figure><p id="d52f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们又做了一次..误差进一步减小，r平方增加。我们可以继续添加更多相关的功能，但我想你现在已经明白了！</p><h1 id="0cb7" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">特征重要性图</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/c39f8b8bcddd54a99d1cfcc20b56050c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*jctXUqBR2JSTU6TMslc5_A.png"/></div></figure><p id="cb61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们正确假设的那样，第<code class="fe nn no np nf b">(t-7)</code>天的价值比第<code class="fe nn no np nf b">(t-1)</code>天的价值具有更强的预测力。</p></div><div class="ab cl oy oz hx pa" role="separator"><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd"/></div><div class="im in io ip iq"><h1 id="34b9" class="mt lw it bd lx mu pf mw ma mx pg mz md jz ph ka mg kc pi kd mj kf pj kg mm nd bi translated">结论</h1><p id="510c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在本文中，我们学习了如何对时间序列数据建模，对时间序列数据进行交叉验证，以及微调我们的模型超参数。我们还成功地将预测功耗的RMSE从85.61降低到54.57。</p><p id="151d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本系列的第3部分中，我们将进行一个案例研究，分析呼叫中心生成的时间序列数据，主要是分析<a class="ae ky" href="https://www.investopedia.com/terms/a/abandon-rate.asp#:~:text=For%20an%20inbound%20call%20center,direct%20relation%20to%20waiting%20times." rel="noopener ugc nofollow" target="_blank">放弃率</a>的(可怕)增量。敬请关注…</p><p id="6eea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">直到下次:)</p></div><div class="ab cl oy oz hx pa" role="separator"><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd"/></div><div class="im in io ip iq"><p id="1aa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nq">我喜欢写循序渐进的初学者指南、操作指南、面试问题、解码ML/AI中使用的术语等。如果你想完全访问我的所有文章(以及其他媒体上的文章)，那么你可以使用</em> <a class="ae ky" href="https://varshitasher.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="nq">我的链接</em></strong></a><strong class="lb iu"><em class="nq"/></strong><em class="nq">这里</em> <strong class="lb iu"> <em class="nq">注册。</em> </strong></p><div class="pk pl gp gr pm pn"><a rel="noopener follow" target="_blank" href="/fine-tuning-hubert-for-emotion-recognition-in-custom-audio-data-using-huggingface-c2d516b41cd8"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd iu gy z fp ps fr fs pt fu fw is bi translated">检测语音数据中的情感:使用Huggingface微调HuBERT</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">构建自定义数据加载器、实验日志、改进指标的技巧和GitHub repo，如果您想了解…</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">towardsdatascience.com</p></div></div><div class="pw l"><div class="px l py pz qa pw qb ks pn"/></div></div></a></div><div class="pk pl gp gr pm pn"><a rel="noopener follow" target="_blank" href="/understanding-python-imports-init-py-and-pythonpath-once-and-for-all-4c5249ab6355"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd iu gy z fp ps fr fs pt fu fw is bi translated">了解Python导入，__init__。py和pythonpath —一劳永逸</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">了解如何导入包和模块(以及两者之间的区别)</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">towardsdatascience.com</p></div></div><div class="pw l"><div class="qc l py pz qa pw qb ks pn"/></div></div></a></div><div class="pk pl gp gr pm pn"><a href="https://medium.com/@vishi2020/tackling-the-time-series-take-home-assignment-a-case-study-in-python-b2a3bd78d956" rel="noopener follow" target="_blank"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd iu gy z fp ps fr fs pt fu fw is bi translated">处理时序带回家的作业:Python中的一个案例研究</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">利用呼叫中心分析改善客户支持</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">medium.com</p></div></div><div class="pw l"><div class="qd l py pz qa pw qb ks pn"/></div></div></a></div><div class="pk pl gp gr pm pn"><a rel="noopener follow" target="_blank" href="/data-scientists-guide-to-efficient-coding-in-python-670c78a7bf79"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd iu gy z fp ps fr fs pt fu fw is bi translated">数据科学家的Python高效编码指南</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">我每天用来编写干净代码的技巧和窍门</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">towardsdatascience.com</p></div></div><div class="pw l"><div class="qe l py pz qa pw qb ks pn"/></div></div></a></div></div></div>    
</body>
</html>