<html>
<head>
<title>Real Time Custom Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实时自定义对象检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-custom-object-detection-a95d955cecda?source=collection_archive---------20-----------------------#2020-06-10">https://towardsdatascience.com/real-time-custom-object-detection-a95d955cecda?source=collection_archive---------20-----------------------#2020-06-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6614" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">创建自定义对象检测器指南—第 2 部分</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/066fd7c246417967e0f78d993064d10c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*76-sWNefYuAoMejT"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">亚采克·迪拉格在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><blockquote class="lg lh li"><p id="fefc" class="lj lk ll lm b ln lo ju lp lq lr jx ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated"><strong class="lm iu">在这篇文章中，我们将测试我上一篇文章</strong>中定制的暗网模型</p></blockquote><p id="9016" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated">建议:视频输出可以通过彭博快带在 YouTube 上获得。一个窗口的图像是我的个人电脑的屏幕截图。输出图像来源取自<a class="ae ky" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的开源数据集。非常感谢 Shauryasikt Jena </p><p id="37c4" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">在我的上一篇文章中，我们看到了如何使用 darknet 创建一个自定义的蒙版检测器。如果能看到它的行动，那会更有趣，不是吗？)</p><p id="d0fc" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">因此，让我们使它工作，是的，这些步骤比训练模型要容易得多，因为如果您已经按照我以前的文章安装了所需的库(唷！).</p><p id="355d" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">如果没有，保持冷静:)，可以上我的文章详细查一下。</p><blockquote class="lg lh li"><p id="c179" class="lj lk ll lm b ln lo ju lp lq lr jx ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">这是我以前的文章—</p></blockquote><div class="mu mv gp gr mw mx"><a href="https://medium.com/@tejas.khare99/custom-object-detection-using-darknet-9779170faca2" rel="noopener follow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">使用暗网的自定义对象检测</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">自定义暗网完全指南</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">medium.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl ks mx"/></div></div></a></div></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><blockquote class="lg lh li"><p id="700f" class="lj lk ll lm b ln lo ju lp lq lr jx ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">使用 CPU 执行整个代码<strong class="lm iu">。如果您正在编写视频输出，您不需要 GPU，视频是根据您首选的每秒帧数值编写的。要编写视频文件，请查看步骤 10。</strong></p></blockquote><h1 id="12c4" class="nm nn it bd no np nq nr ns nt nu nv nw jz nx ka ny kc nz kd oa kf ob kg oc od bi translated">内容</h1><ol class=""><li id="3fc5" class="oe of it lm b ln og lq oh mg oi mh oj mi ok mf ol om on oo bi translated">导入库</li><li id="d38e" class="oe of it lm b ln op lq oq mg or mh os mi ot mf ol om on oo bi translated">从培训中获取生成的文件</li><li id="b239" class="oe of it lm b ln op lq oq mg or mh os mi ot mf ol om on oo bi translated">阅读网络</li><li id="2fbd" class="oe of it lm b ln op lq oq mg or mh os mi ot mf ol om on oo bi translated">输入图像的一些预处理</li><li id="f6f2" class="oe of it lm b ln op lq oq mg or mh os mi ot mf ol om on oo bi translated">置信度得分、类标识符、边界框的坐标</li><li id="4080" class="oe of it lm b ln op lq oq mg or mh os mi ot mf ol om on oo bi translated">非最大抑制(NMS)</li><li id="33da" class="oe of it lm b ln op lq oq mg or mh os mi ot mf ol om on oo bi translated">绘制边界框</li><li id="3af6" class="oe of it lm b ln op lq oq mg or mh os mi ot mf ol om on oo bi translated">使用</li><li id="dd5b" class="oe of it lm b ln op lq oq mg or mh os mi ot mf ol om on oo bi translated">写入文件(可选)</li></ol><p id="ddf0" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">好吧…让我们成功吧！请通读整篇文章，以免遗漏任何内容。谢谢:)</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h2 id="ee84" class="ou nn it bd no ov ow dn ns ox oy dp nw mg oz pa ny mh pb pc oa mi pd pe oc pf bi translated">1.导入库</h2><p id="499f" class="pw-post-body-paragraph lj lk it lm b ln og ju lp lq oh jx ls mg pg lv lw mh ph lz ma mi pi md me mf im bi translated">请导入这些库。</p><pre class="kj kk kl km gt pj pk pl pm aw pn bi"><span id="8dcc" class="ou nn it pk b gy po pp l pq pr">import tensorflow as tf<br/>import numpy as np<br/>import cv2<br/>import pandas as pd<br/>import time<br/>import os<br/>import matplotlib.pyplot as plt<br/>from PIL import Image</span></pre><p id="801b" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated"><span class="l mk ml mm bm mn mo mp mq mr di"> N </span>注:你还需要<strong class="lm iu"> ffmpeg==4.2.2+ </strong>来写视频输出文件。如果你有任何问题，请浏览我以前的文章。一旦你有了 ffmpeg，确保你在安装了 ffmpeg 的同一个 anaconda 环境中运行所有的东西。</p><p id="6861" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">这就是你所需要的，让我们进入重要的下一步！</p><h2 id="c9a5" class="ou nn it bd no ov ow dn ns ox oy dp nw mg oz pa ny mh pb pc oa mi pd pe oc pf bi translated">2.从暗网和训练模型中收集文件</h2><p id="a016" class="pw-post-body-paragraph lj lk it lm b ln og ju lp lq oh jx ls mg pg lv lw mh ph lz ma mi pi md me mf im bi translated">这是我们的目标探测器运行的非常关键的一步。我在下面列出这些文件，确保你有这些文件。</p><ol class=""><li id="ecc4" class="oe of it lm b ln lo lq lr mg ps mh pt mi pu mf ol om on oo bi translated">习俗。名称文件</li><li id="7a22" class="oe of it lm b ln op lq oq mg or mh os mi ot mf ol om on oo bi translated">习俗。cfg 文件</li></ol><p id="3007" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated">注:我们在培训前创建了这些文件，所以如果你错过了其中的任何一个，你的模型将会给你带来麻烦。这两个文件对于您的自定义对象检测器来说是非常特定的，我以前的文章将指导您可以进行哪些更改。你可以冷静下来！创建这些文件只需一分钟，如果遵循每个细节:)</p><p id="729b" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">3.习俗。权重文件</p><p id="23bc" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">好吧…让我们在这里暂停一分钟来理解你是如何得到它的。</p><p id="4ac1" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">这个文件被称为重量文件，它通常是一个大文件，也取决于你的训练大小(对我来说是 256mb)。当你的<strong class="lm iu">训练</strong>完成<strong class="lm iu">后，你<strong class="lm iu">就会得到这个文件</strong>。</strong>在我的例子中，我使用的文件名是 yolov 3 _ custom _ train _ 3000 . weights。在这里，“3000”意味着文件是在完成 3000 个历元后生成的。如果你已经通过了。cfg 文件，您会发现纪元设置为 6000。</p><p id="3bfd" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated"><strong class="lm iu">那么我为什么没有用‘yolov 3 _ custom _ train _ 6000 . weights’呢？</strong></p><p id="4bb6" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">这是因为经过一些测试后，我发现 3000 个历元后生成的权重文件在实际生成的所有权重文件中具有最好的准确性，而不仅仅是“6000”的那个。</p><p id="226f" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated"><strong class="lm iu">好。因此，更多的时代应该意味着更高的准确性，对不对？</strong></p><p id="9341" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">不尽然:(</p><p id="2736" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">更多的历元也意味着<strong class="lm iu">过拟合</strong>，这会大大降低精度。我的训练数据可能有一些重复的图像，或者我可能将<strong class="lm iu">错误地标记为</strong><strong class="lm iu"/>(是的，我知道..这是一个乏味的任务，所以..你知道思想是如何偏离正确的)，这确实对准确性有直接影响。</p><h2 id="a3d8" class="ou nn it bd no ov ow dn ns ox oy dp nw mg oz pa ny mh pb pc oa mi pd pe oc pf bi translated"><strong class="ak"> 3。阅读网</strong></h2><p id="a3eb" class="pw-post-body-paragraph lj lk it lm b ln og ju lp lq oh jx ls mg pg lv lw mh ph lz ma mi pi md me mf im bi translated">现在..测试部分开始。我会尽我所能让它简单易懂，显然，理解并排:)</p><p id="8be7" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">幸运的是，cv2 有一个内置函数。</p><pre class="kj kk kl km gt pj pk pl pm aw pn bi"><span id="3149" class="ou nn it pk b gy po pp l pq pr">net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)<br/>ln = net.getLayerNames()<br/>ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]</span></pre><p id="1b4f" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">这些漂亮的功能通过直接读取存储在<a class="ae ky" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank"> Darknet </a>模型文件中的网络模型并为我们的探测器代码设置它们，使我们的日常工作变得更加容易。！).</p><p id="8995" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">有关该函数的更多信息—</p><div class="mu mv gp gr mw mx"><a href="https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#gafde362956af949cce087f3f25c6aff0d" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">OpenCV:深度神经网络模块</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">cv::dnn::blobFromImage(input array image，double scalefactor=1.0，const Size &amp;size= Size()，const Scalar &amp; mean=…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">docs.opencv.org</p></div></div><div class="ng l"><div class="pv l ni nj nk ng nl ks mx"/></div></div></a></div><p id="495f" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">您还需要从“yolo.names”文件中获取标签..</p><pre class="kj kk kl km gt pj pk pl pm aw pn bi"><span id="5c04" class="ou nn it pk b gy po pp l pq pr">LABELS = open(labelsPath).read().strip().split("\n")</span></pre><p id="9869" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated"><span class="l mk ml mm bm mn mo mp mq mr di"> N </span>注:configPath、weightsPath 和 labelsPath 包含各自文件的<strong class="lm iu">路径</strong></p><h2 id="fcc0" class="ou nn it bd no ov ow dn ns ox oy dp nw mg oz pa ny mh pb pc oa mi pd pe oc pf bi translated">4.输入图像的一些预处理</h2><p id="973a" class="pw-post-body-paragraph lj lk it lm b ln og ju lp lq oh jx ls mg pg lv lw mh ph lz ma mi pi md me mf im bi translated">这些是我们需要为我们的模型做的一些步骤，以获得一些预处理的图像。预处理包括<a class="ae ky" href="https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/" rel="noopener ugc nofollow" target="_blank"> <strong class="lm iu">均值减法</strong>和<strong class="lm iu">缩放</strong> </a> <strong class="lm iu">。</strong></p><div class="mu mv gp gr mw mx"><a href="https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#ga29f34df9376379a603acd8df581ac8d7" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">OpenCV:深度神经网络模块</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">cv::dnn::blobFromImage(input array image，double scalefactor=1.0，const Size &amp;size= Size()，const Scalar &amp; mean=…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">docs.opencv.org</p></div></div><div class="ng l"><div class="pw l ni nj nk ng nl ks mx"/></div></div></a></div><pre class="kj kk kl km gt pj pk pl pm aw pn bi"><span id="bc02" class="ou nn it pk b gy po pp l pq pr">(H, W) = image.shape[:2]<br/>blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),<br/>       swapRB=True, crop=False)<br/>net.setInput(blob)<br/>layerOutputs = net.forward(ln)</span><span id="b789" class="ou nn it pk b gy px pp l pq pr"># Initializing for getting box coordinates, confidences, classid boxes = []<br/>confidences = []<br/>classIDs = []<br/>threshold = 0.15</span></pre><h2 id="ba99" class="ou nn it bd no ov ow dn ns ox oy dp nw mg oz pa ny mh pb pc oa mi pd pe oc pf bi translated">5.获得一些自信</h2><p id="549a" class="pw-post-body-paragraph lj lk it lm b ln og ju lp lq oh jx ls mg pg lv lw mh ph lz ma mi pi md me mf im bi translated">是的…实际上在这一步之后，我们会对我们的代码有一些信心，并且更好地理解我们已经做了什么，以及在这之后我们要做什么。</p><pre class="kj kk kl km gt pj pk pl pm aw pn bi"><span id="af40" class="ou nn it pk b gy po pp l pq pr">for output in layerOutputs:<br/>    for detection in output:<br/>        scores = detection[5:]<br/>        classID = np.argmax(scores)<br/>        confidence = scores[classID]</span><span id="6622" class="ou nn it pk b gy px pp l pq pr">        if confidence &gt; threshold:<br/>            box = detection[0:4] * np.array([W, H, W, H])<br/>            (centerX, centerY, width, height) = box.astype("int")           <br/>            x = int(centerX - (width / 2))<br/>            y = int(centerY - (height / 2))    <br/>            boxes.append([x, y, int(width), int(height)])<br/>            confidences.append(float(confidence))<br/>            classIDs.append(classID)</span></pre><p id="2087" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated"><strong class="lm iu">那么这段代码到底在做什么呢？</strong></p><p id="c86a" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">包含一个巨大的 2D 浮点数数组，从中我们需要“将要”绘制的边界框的坐标、classid 和每个预测的置信度得分，或者我们可以说是检测:)</p><h2 id="f9cd" class="ou nn it bd no ov ow dn ns ox oy dp nw mg oz pa ny mh pb pc oa mi pd pe oc pf bi translated">6.非最大抑制(NMS)</h2><p id="8496" class="pw-post-body-paragraph lj lk it lm b ln og ju lp lq oh jx ls mg pg lv lw mh ph lz ma mi pi md me mf im bi translated">对..最初，当我没有向它提供正确的输入数据类型时，这一步给了我很大的困难。我也试过 NMS 的一些预写功能，但是我的物体检测太慢了…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qb"><img src="../Images/337d11d079da70ad1cc6852068b8d0f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ADPKbt0paHbl01u0"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">尼克·艾布拉姆斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="0649" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">在撞了我的头一段时间后(不是字面上的..)，我能够通过为这个<strong class="lm iu">超快</strong>救生功能编写<strong class="lm iu">上一步</strong>中给出的代码来获得<strong class="lm iu">正确的输入数据类型</strong>。</p><pre class="kj kk kl km gt pj pk pl pm aw pn bi"><span id="36fb" class="ou nn it pk b gy po pp l pq pr">idxs = cv2.dnn.NMSBoxes(boxes, confidences, threshold, 0.1)</span></pre><p id="528c" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">你可以在这里找到一些信息—</p><div class="mu mv gp gr mw mx"><a href="https://docs.opencv.org/master/d6/d0f/group__dnn.html#gaeec27cb32195e71e6d88032bda193162" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">OpenCV:深度神经网络模块</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">cv::dnn::blobFromImage(input array image，double scalefactor=1.0，const Size &amp;size= Size()，const Scalar &amp; mean=…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">docs.opencv.org</p></div></div></div></a></div><p id="2377" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">那么什么是 NMS 呢？</p><p id="d672" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">该模型返回多个预测，因此单个对象存在多个框。我们当然不希望这样。多亏了 NMS，它为该对象返回了一个单一的最佳包围盒。</p><p id="0eda" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">为了深入了解 NMS 及其运作方式—</p><div class="mu mv gp gr mw mx"><a rel="noopener follow" target="_blank" href="/non-maximum-suppression-nms-93ce178e177c"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">非最大抑制(NMS)</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">一种消除目标检测中重复和误报的技术</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">towardsdatascience.com</p></div></div><div class="ng l"><div class="qc l ni nj nk ng nl ks mx"/></div></div></a></div><h2 id="4398" class="ou nn it bd no ov ow dn ns ox oy dp nw mg oz pa ny mh pb pc oa mi pd pe oc pf bi translated">7.绘制边界框</h2><p id="9331" class="pw-post-body-paragraph lj lk it lm b ln og ju lp lq oh jx ls mg pg lv lw mh ph lz ma mi pi md me mf im bi translated">Aahhaa..有趣的部分。现在让我们的探测器开始工作吧</p><pre class="kj kk kl km gt pj pk pl pm aw pn bi"><span id="b0d6" class="ou nn it pk b gy po pp l pq pr">mc = 0<br/>nmc = 0</span><span id="3aa3" class="ou nn it pk b gy px pp l pq pr">if len(idxs) &gt; 0:<br/>   for i in idxs.flatten():<br/>       (x, y) = (boxes[i][0], boxes[i][1])<br/>       (w, h) = (boxes[i][2], boxes[i][3])</span><span id="0cb8" class="ou nn it pk b gy px pp l pq pr">       if LABELS[classIDs[i]] == 'OBJECT_NAME_1'):<br/>          mc += 1<br/>          color = (0, 255, 0)<br/>          cv2.rectangle(image, (x, y), (x + w, y + h), color, 1)<br/>          text = "{}".format(LABELS[classIDs[i]])<br/>          cv2.putText(image, text, (x + w, y + h),                     <br/>          cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 1)<br/>            <br/>       if (LABELS[classIDs[i]] == 'OBJECT_NAME_2'):<br/>          nmc += 1<br/>          color = (0, 0, 255)<br/>          cv2.rectangle(image, (x, y), (x + w, y + h), color, 1)<br/>          text = "{}".format(LABELS[classIDs[i]])<br/>          cv2.putText(image, text, (x + w, y + h),      <br/>              cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 1)</span><span id="1727" class="ou nn it pk b gy px pp l pq pr">text1 = "No. of people wearing masks: " + str(mc)<br/>text2 = "No. of people not wearing masks: " + str(nmc)<br/>color1 = (0, 255, 0)<br/>color2 = (0, 0, 255)</span><span id="9b1f" class="ou nn it pk b gy px pp l pq pr">cv2.putText(image, text1, (2, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color1, 2)<br/>cv2.putText(image, text2, (2, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color2, 2)</span></pre><p id="bb2e" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">搞定了。！这段代码会给你一个包含你的边界框的图片/框架</p><p id="6528" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated"><span class="l mk ml mm bm mn mo mp mq mr di"> N </span>注:请务必根据您的对象名称更改<code class="fe py pz qa pk b">OBJECT_NAME_1</code>和<code class="fe py pz qa pk b">OBJECT_NAME_2</code>。这将使你更好地理解你的代码；)</p><p id="bc7d" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated"><span class="l mk ml mm bm mn mo mp mq mr di"> T </span> ip:我建议你创建一个<strong class="lm iu">函数</strong>，在其中传递一个图像，因为以后你可以将这个函数用于视频以及图像输入；)</p><h2 id="e9cc" class="ou nn it bd no ov ow dn ns ox oy dp nw mg oz pa ny mh pb pc oa mi pd pe oc pf bi translated">9.使用</h2><p id="0cd6" class="pw-post-body-paragraph lj lk it lm b ln og ju lp lq oh jx ls mg pg lv lw mh ph lz ma mi pi md me mf im bi translated">上面的代码有两种用途—</p><ol class=""><li id="dfbe" class="oe of it lm b ln lo lq lr mg ps mh pt mi pu mf ol om on oo bi translated"><strong class="lm iu">实时</strong>，即将<strong class="lm iu">视频</strong>传递给探测器</li></ol><p id="fe62" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">这可以通过从视频中读取帧来完成，如果你愿意，你也可以调整它的大小，以便你的“cv2.imshow”以更快的速度显示输出帧，即每秒帧。用 cv2 阅读视频——</p><div class="mu mv gp gr mw mx"><a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">视频入门- OpenCV-Python 教程 1 文档</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">学会看视频，显示视频，保存视频。学会从相机捕捉并显示它。你会学到这些…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">opencv-python-tutro als . readthedocs . io</p></div></div><div class="ng l"><div class="qd l ni nj nk ng nl ks mx"/></div></div></a></div><p id="3020" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated">注意:你不需要将获得的帧转换成灰度。</p><p id="dd17" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">现在只需将框架传递给<strong class="lm iu">功能</strong>(在提示中提到)和吊杆..你有你的实时物体探测器准备好了！</p><p id="f7e3" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">输出视频—</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="qe qf l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">以 20fps 写入的视频输出</p></figure><p id="b0de" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated"><span class="l mk ml mm bm mn mo mp mq mr di"> N </span>注:上面的视频输出很流畅，因为我已经以每秒 20 帧(fps)的速度将这些帧写入了一个. mp4 文件</p><p id="f366" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">2.图像</p><p id="3b8c" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">你也可以通过传递一张图片来测试你的物体检测器。(是啊..没那么好玩)。用 cv2 来读取图像—</p><div class="mu mv gp gr mw mx"><a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_image_display/py_image_display.html" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">图像入门- OpenCV-Python 教程 1 文档</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">cv2.waitKey()是一个键盘绑定函数。它的参数是以毫秒为单位的时间。该功能等待…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">opencv-python-tutro als . readthedocs . io</p></div></div><div class="ng l"><div class="qg l ni nj nk ng nl ks mx"/></div></div></a></div><p id="8d65" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">输出图像—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qh"><img src="../Images/0a8c9b2d7b03637f6c2a08452d2555ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jqiF0CQp4DzrSnI6OI7p2Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">物体探测器的单图像输出</p></figure><h2 id="7977" class="ou nn it bd no ov ow dn ns ox oy dp nw mg oz pa ny mh pb pc oa mi pd pe oc pf bi translated">10.写入文件(可选)</h2><p id="de46" class="pw-post-body-paragraph lj lk it lm b ln og ju lp lq oh jx ls mg pg lv lw mh ph lz ma mi pi md me mf im bi translated">你可能想知道我是如何让视频输出如此流畅的，对吗？这里有一个技巧，你可以用它来获得流畅的视频输出…</p><p id="7a2b" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">OpenCV 有一个函数叫做 cv2。VideoWriter()，您可以通过指定文件名、codecid、fps 和与输入字段相同的分辨率来编写帧。</p><div class="mu mv gp gr mw mx"><a href="https://docs.opencv.org/3.4/dd/d9e/classcv_1_1VideoWriter.html" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">OpenCV: cv::VideoWriter 类引用</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">视频编剧类。更大的...默认构造函数。构造函数初始化视频编写器。在 Linux FFMPEG 上…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">docs.opencv.org</p></div></div><div class="ng l"><div class="qi l ni nj nk ng nl ks mx"/></div></div></a></div><p id="6774" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">在 while 循环之外定义变量<code class="fe py pz qa pk b">out</code>,在该循环中读取视频的每一帧</p><pre class="kj kk kl km gt pj pk pl pm aw pn bi"><span id="5094" class="ou nn it pk b gy po pp l pq pr">out = cv2.VideoWriter('file_name.mp4', -1, fps,    <br/>         (int(cap.get(3)),int(cap.get(4))))</span></pre><p id="2da5" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated">注意:第二个参数'-1 '是要给出的 codecid，但是它在我的计算机上工作得很好。计算机上的 codecid 可能不同。请访问这个网站进行调试—</p><div class="mu mv gp gr mw mx"><a href="https://stackoverflow.com/questions/38397964/cant-write-and-save-a-video-file-using-opencv-and-python" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">无法使用 OpenCV 和 Python 编写和保存视频文件</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">感谢贡献一个堆栈溢出的答案！请务必回答问题。提供详细信息并分享…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">stackoverflow.com</p></div></div><div class="ng l"><div class="qj l ni nj nk ng nl ks mx"/></div></div></a></div><p id="d082" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi translated">最后一个参数将帮助您获得输入视频的分辨率。之后，将下面的代码放入调用检测器函数的 while 循环中。</p><pre class="kj kk kl km gt pj pk pl pm aw pn bi"><span id="8298" class="ou nn it pk b gy po pp l pq pr">while True:<br/>  ....<br/>  ....  <br/>  image = detector(frame) <br/>  out.write(image)<br/>  ....<br/>  ....</span></pre><p id="77d7" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated">注意:你的探测器函数应该返回一个“图像”</p><p id="d72c" class="pw-post-body-paragraph lj lk it lm b ln lo ju lp lq lr jx ls mg lu lv lw mh ly lz ma mi mc md me mf im bi mj translated">ip:你也可以用“moviepy”将你的画面写入视频…</p><div class="mu mv gp gr mw mx"><a href="https://pypi.org/project/moviepy/" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">电影</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">MoviePy 依赖于 Python 模块 Numpy、imageio、Decorator 和 tqdm，这些模块将在…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">pypi.org</p></div></div><div class="ng l"><div class="qk l ni nj nk ng nl ks mx"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ql"><img src="../Images/d3b2e3cdbebbe206428ca369849e30d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BN0yUknhp1AmiTeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">pjreddie 暗网的推理时间图</p></figure><blockquote class="lg lh li"><p id="7d3a" class="lj lk ll lm b ln lo ju lp lq lr jx ls lt lu lv lw lx ly lz ma mb mc md me mf im bi translated">原来如此！我希望你现在已经有了自己的自定义对象检测器。干杯！</p></blockquote><blockquote class="qm"><p id="beec" class="qn qo it bd qp qq qr qs qt qu qv mf dk translated">感谢您通读整篇文章，希望您能从中受益。如果你有任何反馈，他们是最受欢迎的！</p></blockquote></div></div>    
</body>
</html>