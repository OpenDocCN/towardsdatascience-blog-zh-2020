<html>
<head>
<title>Demystifying MLPerf Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭开MLPerf推理的神秘面纱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystifying-mlperf-inference-956e41790df4?source=collection_archive---------34-----------------------#2020-05-05">https://towardsdatascience.com/demystifying-mlperf-inference-956e41790df4?source=collection_archive---------34-----------------------#2020-05-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/235ac67ffdf4c1679cb00048f57db6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wx4q0dXiTENdpqwrQu5_AQ.png"/></div></figure><p id="2116" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><a class="ae kv" href="http://mlperf.org" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> MLPerf </strong> </a>是一个广泛的社区，专注于机器学习(ML)的基准测试，有超过70个参与组织(还在增加)。<em class="kw">标杆管理</em>是指<em class="kw">评估“绩效”</em>(质量、速度、能效等。)的计算机系统使用典型的<em class="kw">工作负载</em>(任务、数据集、模型)。与大多数其他ML基准不同，<strong class="jz iu"> MLPerf </strong>包含了在实践中使用ML的<strong class="jz iu">培训</strong>和<strong class="jz iu">推理</strong>(部署)阶段。</p><p id="f81a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">第二轮<strong class="jz iu"> MLPerf培训</strong>收到了来自英特尔、英伟达、谷歌、阿里巴巴和富士通的提交材料(v0.6，结果<a class="ae kv" href="https://mlperf.org/press#mlperf-training-v0.6-results" rel="noopener ugc nofollow" target="_blank">于2019年7月10日公布</a>)。第一轮<a class="ae kv" href="https://arxiv.org/abs/1911.02549" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> MLPerf推论</strong></a>(v 0.5，结果<a class="ae kv" href="https://mlperf.org/press#mlperf-inference-v0.5-results" rel="noopener ugc nofollow" target="_blank">于2019年11月6日</a>公布)收到了来自14家组织的提交材料，包括来自上述公司的Habana Labs ( <a class="ae kv" href="https://newsroom.intel.com/news-releases/intel-ai-acquisition" rel="noopener ugc nofollow" target="_blank">于2019年12月被英特尔收购</a>)和<a class="ae kv" href="https://dividiti.blogspot.com/2019/11/dividiti-accelerate-omni-benchmarking-for-mlperf.html" rel="noopener ugc nofollow" target="_blank">divideti</a>。</p><figure class="ky kz la lb gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/199062aaa9a50a4d82431f305ef92690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G42KTn7LwyCZ-zdPFgfWoQ.jpeg"/></div></div><p class="lg lh gj gh gi li lj bd b be z dk translated">MLPerf推理v0.5:分解提交者接受的595个结果。</p></figure><p id="b901" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">因此，<strong class="jz iu"> MLPerf </strong>正迅速成为<em class="kw">ML系统的</em>行业基准，并成为发布新产品的理想论坛，其基准测试结果将使分析师、投资者和买家<em class="kw">信任</em>。</p><p id="e145" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">作为<a class="ae kv" href="https://github.com/mlperf/inference/graphs/contributors" rel="noopener ugc nofollow" target="_blank">至<strong class="jz iu"> MLPerf推论</strong>的顶级</a><a class="ae kv" href="https://github.com/mlperf/inference/graphs/contributors" rel="noopener ugc nofollow" target="_blank">撰稿人之一，我经常回答新人的问题。虽然有一份出色的</a><a class="ae kv" href="https://arxiv.org/abs/1911.02549" rel="noopener ugc nofollow" target="_blank">白皮书</a>解释了基准测试套件的基本原理和方法，但我从潜在提交者(硬件设计师、云提供商等)那里得到的问题。)和用户(买家、投资人等。)具有更实际的性质。在这篇文章中，我开始回答一些常见的问题。</p><p id="17b4" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">下面，在问句中，“我”指的是你，读者，“我们”指的是“你的组织”；在答案中，“我”指的是我，作者，“我们”指的是“MLPerf社区”(但只有当我认为我可以代表整个社区时)。</p></div><div class="ab cl lk ll hx lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="im in io ip iq"><h1 id="419d" class="lr ls it bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">为什么要考虑参加MLPerf？</h1><p id="99ca" class="pw-post-body-paragraph jx jy it jz b ka mp kc kd ke mq kg kh ki mr kk kl km ms ko kp kq mt ks kt ku im bi translated">一个词——<em class="kw">信任</em>。</p><p id="f4d8" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">随着在云和边缘加速ML的许多选项变得可用，有眼光的买家不再满足于仅仅依靠供应商的销售宣传和营销材料来做出购买决定。相反，购买者要求供应商提供大量细节，例如使用的确切工作负载和优化选项、性能和准确性的权衡、功耗、工具链成熟度等。(例如，参见通用汽车在2017年<a class="ae kv" href="https://www.edge-ai-vision.com/the-summit/may-2017-embedded-vision-summit-replay/" rel="noopener ugc nofollow" target="_blank">嵌入式视觉峰会</a>上的<a class="ae kv" href="https://www.youtube.com/watch?v=1ldgVZ64hEI" rel="noopener ugc nofollow" target="_blank">激励演示</a>。)</p><p id="ce74" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">MLPerf 旨在通过商定一个通用的严格方法，在系统之间进行有意义和公平的比较。特别是，所有的<strong class="jz iu">推理</strong>提交必须遵循严格的<a class="ae kv" href="https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc" rel="noopener ugc nofollow" target="_blank">规则</a>关于<a class="ae kv" href="https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc#8-model" rel="noopener ugc nofollow" target="_blank">允许的模型转换</a>、<a class="ae kv" href="https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc#data-sets" rel="noopener ugc nofollow" target="_blank">数据预处理和后处理</a>等等。重要的是，所有的<strong class="jz iu">推理</strong>提交必须使用所谓的<a class="ae kv" href="https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc#load-generator" rel="noopener ugc nofollow" target="_blank"> LoadGen </a> API，用于在一个或多个<a class="ae kv" href="https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc#scenarios" rel="noopener ugc nofollow" target="_blank">使用场景</a>(单流、多流、服务器、离线)中，在被测系统(软件+硬件)上生成工作负载(ML模型)的执行轨迹。</p><p id="83b8" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">现在是建立信任最重要的一步。所有提交的<strong class="jz iu"> MLPerf </strong>都由其他提交者<a class="ae kv" href="https://github.com/mlperf/policies/blob/master/submission_rules.adoc#review" rel="noopener ugc nofollow" target="_blank">审核</a>，他们可能包括你的直接竞争对手。因此，如果你的提交经得起审查的审查，你的结果将被认为是最值得信赖的。那是金色的！</p><p id="4a80" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">例如，向<strong class="jz iu">提交MLPerf推论v0.5 </strong>的三家硬件初创公司已经收获了来之不易的信任:</p><ul class=""><li id="9af0" class="mu mv it jz b ka kb ke kf ki mw km mx kq my ku mz na nb nc bi translated"><a class="ae kv" href="https://www.furiosa.ai/" rel="noopener ugc nofollow" target="_blank"> Furiosa </a> <a class="ae kv" href="http://www.theinvestor.co.kr/view.php?ud=20191107000614" rel="noopener ugc nofollow" target="_blank">拿到了</a>700万美元的A轮投资。</li><li id="f571" class="mu mv it jz b ka nd ke ne ki nf km ng kq nh ku mz na nb nc bi translated"><a class="ae kv" href="https://hailo.ai/#" rel="noopener ugc nofollow" target="_blank">Hailo</a>T12】拿到了6000万美元的B轮投资。</li><li id="0b47" class="mu mv it jz b ka nd ke ne ki nf km ng kq nh ku mz na nb nc bi translated">最后，哈瓦那实验室以20亿美元的价格被英特尔收购。</li></ul><h1 id="37a4" class="lr ls it bd lt lu ni lw lx ly nj ma mb mc nk me mf mg nl mi mj mk nm mm mn mo bi translated">MLPerf只针对硬件厂商吗？</h1><p id="27ca" class="pw-post-body-paragraph jx jy it jz b ka mp kc kd ke mq kg kh ki mr kk kl km ms ko kp kq mt ks kt ku im bi translated">正如Linley Newsletter 所总结的那样，MLPerf推论v0.5 的提交来自“云服务提供商、服务器供应商、芯片供应商和专业服务公司”。因此，答案似乎是“基本上是”。</p><p id="4c2b" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">然而，公平的基准测试可以帮助展示的东西没有限制:专业服务(例如<a class="ae kv" href="http://bit.ly/benchmarking-product" rel="noopener ugc nofollow" target="_blank">作为产品的基准测试</a>)、知识产权(例如最先进的技术)、技能(例如模型设计和优化、再培训)、工具(例如图形编译器)等等。</p><h1 id="1593" class="lr ls it bd lt lu ni lw lx ly nj ma mb mc nk me mf mg nl mi mj mk nm mm mn mo bi translated">好，我们如何运行MLPerf？</h1><p id="8782" class="pw-post-body-paragraph jx jy it jz b ka mp kc kd ke mq kg kh ki mr kk kl km ms ko kp kq mt ks kt ku im bi translated"><strong class="jz iu"> MLPerf </strong>不是一个可以简单下载运行的基准，至少今天不是。(<strong class="jz iu"> MLPerf Mobile </strong>工作组正在朝着开发一款用于智能手机和平板电脑的用户友好基准测试的<a class="ae kv" href="https://github.com/mlperf/mobile_app" rel="noopener ugc nofollow" target="_blank"> Android应用</a>的方向大步前进，但是ML推理的前景显然比移动领域要广阔得多。)</p><p id="615a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">所以要回答这个问题，我们首先应该考虑一下<strong class="jz iu"> MLPerf </strong>基准测试定义过程是如何工作的。<strong class="jz iu"> MLPerf </strong> ( <strong class="jz iu">训练</strong>或<strong class="jz iu">推理</strong> ) <strong class="jz iu"> </strong>工作组商定一组代表性的<em class="kw">任务</em>，如图像分类和对象检测，以及每个任务的一个或多个代表性的<em class="kw">工作负载</em>(模型)。然后，一个或多个人自愿为每个工作负载创建<em class="kw">一个参考实现</em>。这有助于<a class="ae kv" href="https://en.wikipedia.org/wiki/Crystallization" rel="noopener ugc nofollow" target="_blank">明确</a>对模型的要求(例如，理想情况下，应该只有一个用于推断的预训练权重来源)、验证数据集、性能和准确性指标等。</p><p id="db3a" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">然而，参考实现并不是最快的。事实上，提交者被期望<em class="kw">将工作负载</em>移植到他们的目标硬件。通常，他们需要创建<em class="kw">一个新的实现</em>，混合<strong class="jz iu"> MLPerf </strong> LoadGen API用于发布推理查询和一个特定于硬件的API用于处理查询。他们仍然应该模仿参考实现的预处理和后处理行为，以使他们的提交符合标准。</p><p id="eb60" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">当然，加速推理的核心是特定于硬件的API。例如，对于<strong class="jz iu"> MLPerf推论v0.5 </strong>，NVIDIA使用<a class="ae kv" href="https://developer.nvidia.com/tensorrt" rel="noopener ugc nofollow" target="_blank">tensort</a>，Intel使用<a class="ae kv" href="https://01.org/openvinotoolkit" rel="noopener ugc nofollow" target="_blank"> OpenVINO </a>，dividiti使用<a class="ae kv" href="https://github.com/ARM-software/armnn-mlperf" rel="noopener ugc nofollow" target="_blank"> ArmNN </a>创建了新的工作负载实现。根据<a class="ae kv" href="https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc#benchmark-implementations-must-be-shared" rel="noopener ugc nofollow" target="_blank">规则</a>，加速实现必须在允许基准测试的开源许可下共享。</p><p id="76d1" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">当然，创建新的符合<strong class="jz iu"> MLPerf </strong>的实现需要提交者付出巨大的努力，但是这对于获得可信度是必要的。好消息是这项工作应该在几轮提交中分摊。它还可以激发更广泛的<a class="ae kv" href="http://bit.ly/ob-ic" rel="noopener ugc nofollow" target="_blank">社区驱动的跨其他平台、工作负载、数据集等的基准测试</a>。</p><h1 id="5f26" class="lr ls it bd lt lu ni lw lx ly nj ma mb mc nk me mf mg nl mi mj mk nm mm mn mo bi translated"><strong class="ak"> MLPerf </strong>推论只针对计算机视觉工作负载吗？</h1><p id="6660" class="pw-post-body-paragraph jx jy it jz b ka mp kc kd ke mq kg kh ki mr kk kl km ms ko kp kq mt ks kt ku im bi translated">一点也不！诚然，在用于第<strong class="jz iu"> v0.5 </strong>轮的5个工作负载中，有4个是用于图像分类和物体检测的<a class="ae kv" href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>任务。然而，对于<strong class="jz iu"> v0.7 </strong>回合，引入了新的任务，例如<a class="ae kv" href="https://github.com/mlperf/inference/tree/master/v0.7/language" rel="noopener ugc nofollow" target="_blank">自然语言处理</a>、<a class="ae kv" href="https://github.com/mlperf/inference/tree/master/v0.7/speech_recognition/" rel="noopener ugc nofollow" target="_blank">语音识别</a>和<a class="ae kv" href="https://github.com/mlperf/inference/tree/master/v0.5/recommendation" rel="noopener ugc nofollow" target="_blank">推荐</a>。推理的复杂性也大大增加了:从ResNet50中的2500万个参数到DLRM中的250亿个参数。</p><h1 id="1ce9" class="lr ls it bd lt lu ni lw lx ly nj ma mb mc nk me mf mg nl mi mj mk nm mm mn mo bi translated">如果我的客户最喜欢的工作负载不是MLPerf推断的一部分，该怎么办？</h1><p id="d97e" class="pw-post-body-paragraph jx jy it jz b ka mp kc kd ke mq kg kh ki mr kk kl km ms ko kp kq mt ks kt ku im bi translated">如果您是潜在的提交者，您可能已经使用客户最喜欢的工作负载为他们执行了一些基准测试。即使此工作负载不是<strong class="jz iu"> MLPerf推断</strong>的一部分，您也可以重新利用您在优化此工作负载方面所付出的努力，并在两种情况下展示您的解决方案:</p><ol class=""><li id="8791" class="mu mv it jz b ka kb ke kf ki mw km mx kq my ku nn na nb nc bi translated">工作负载必须仍然执行由<strong class="jz iu"> MLPerf推断</strong>定义的任务之一。例如，您可以使用另一个<a class="ae kv" href="http://bit.ly/ob-od" rel="noopener ugc nofollow" target="_blank">对象检测</a>模型。</li><li id="1000" class="mu mv it jz b ka nd ke ne ki nf km ng kq nh ku nn na nb nc bi translated">你必须服从<strong class="jz iu"> MLPerf推论</strong>的<a class="ae kv" href="https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc#open-division" rel="noopener ugc nofollow" target="_blank">开师</a>。虽然开放部门放宽了一些规则(例如允许选择任意模型或从<a class="ae kv" href="https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc#closed-division" rel="noopener ugc nofollow" target="_blank">封闭部门</a>中重新训练一个模型)，但您的提交仍必须使用<a class="ae kv" href="https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc#load-generator" rel="noopener ugc nofollow" target="_blank"> LoadGen API </a>并符合<a class="ae kv" href="https://github.com/mlperf/policies/blob/master/submission_rules.adoc#submission" rel="noopener ugc nofollow" target="_blank">提交格式</a>。</li></ol><h1 id="4363" class="lr ls it bd lt lu ni lw lx ly nj ma mb mc nk me mf mg nl mi mj mk nm mm mn mo bi translated">如果我最喜欢的工作负载不是MLPerf推理的一部分，该怎么办？</h1><p id="0331" class="pw-post-body-paragraph jx jy it jz b ka mp kc kd ke mq kg kh ki mr kk kl km ms ko kp kq mt ks kt ku im bi translated">如果你有你最喜欢的工作量(事实上，也许是你唯一真正关心的工作量！)，你也可以使用严格的<strong class="jz iu"> MLPerf </strong>方法来评估你的潜在供应商。理论上，你只需要推动他们产生符合<strong class="jz iu"> MLPerf </strong>的结果，然后看着竞争展开。实际上，他们可能不会让步，特别是如果他们资源有限，或者如果你的请求被认为不够优先。在这种情况下，你仍然可以自己评估它们，或者请一个可信的第三方帮助。</p><p id="8e9d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">其他值得注意的超越正式<strong class="jz iu"> MLPerf </strong>框架的案例包括非公开竞争分析(例如，证明内部研发支出的合理性)或公开营销(例如，通过<strong class="jz iu"> MLPerf </strong>提交轮次支持您的产品发布)。在后一种情况下，确保遵守<a class="ae kv" href="https://github.com/mlperf/policies/blob/master/TERMS%20OF%20USE.md" rel="noopener ugc nofollow" target="_blank"> <strong class="jz iu"> MLPerf </strong>使用条款</a>。再次，考虑如何提高你的声明的可信度<strong class="jz iu"> MLPerf- </strong>风格，完全透明和客观。</p></div><div class="ab cl lk ll hx lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="im in io ip iq"><p id="06db" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在这篇文章中，我试图为潜在的提交者和该基准的用户驱散围绕<strong class="jz iu"> MLPerf推理</strong>的神秘气氛。但是由于我仅仅触及了表面，如果有进一步的问题，请随时联系<a class="ae kv" href="https://www.linkedin.com/in/lokhmotov/" rel="noopener ugc nofollow" target="_blank"> me </a>，我会在以后的帖子中尝试回答这些问题。</p><p id="74da" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">反复出现的一个问题是严格基准测试的努力和成本。<a class="ae kv" href="http://bit.ly/benchmarking-product" rel="noopener ugc nofollow" target="_blank">与软件工程</a>相比，它确实比特别的方法花费多几倍。工作流自动化将是制定严格的ML基准(跨不同的硬件、软件、工作负载、数据集等)的关键。)每个人都负担得起，同时不损害信誉和信任。</p></div></div>    
</body>
</html>