<html>
<head>
<title>Using TPUs on Google Colab with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过 Keras 在 Google Colab 上使用 TPU</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-tpus-on-google-colab-966239d24573?source=collection_archive---------51-----------------------#2020-05-18">https://towardsdatascience.com/using-tpus-on-google-colab-966239d24573?source=collection_archive---------51-----------------------#2020-05-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/b57819ec94c135ebb031259b711b475a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PJGTnA6I0O1cW3RI"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">罗曼·维涅斯在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="561e" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">今天，我在温习一门关于情感分类的旧 NLP 课程，突然感觉到在一些大型数据集上尝试一下的冲动。我玩得很开心，也看到了 Colab 上的免费 TPU 到底有多快。</h2></div><p id="5684" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">速度快了 10 倍，但过程并不简单。包括代码变更(大部分是样板文件)，因此这篇文章。</p><p id="2a42" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作为第一步，我只是想建立一个简单的模型来编译和提供一些预测。我选择了 Kaggle 上的<a class="ae jd" href="https://www.kaggle.com/kazanova/sentiment140" rel="noopener ugc nofollow" target="_blank">sensition 140 数据集</a>。该数据集有 160 万条带有积极和消极情绪标签的推文。它的大小是 288 MB，这对于我的目的来说是很好的。我为训练模型编写的代码非常简单，因为我正在做非常基本的预处理。</p><p id="ea9a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">训练时间——几乎每个时代 1 小时 30 分！</strong>这对于最初的模型来说是行不通的。是时候测试一下 Colab 上提供的免费 TPU 了。</p><p id="2fb9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我最初以为这只是一个简单的设置变化。所以我进入编辑菜单中的笔记本设置，要求一个 TPU 硬件加速器。训练仍然需要一个多小时，所以很明显没有提供 TPU。在浏览 TPU 文档时(这里:<a class="ae jd" href="https://www.tensorflow.org/guide/tpu" rel="noopener ugc nofollow" target="_blank">使用 TPU </a>)，很明显我们必须明确设置什么是<em class="lr">计算分布策略</em>并在它下面构建我们的模型。以下文本中的解释，以及相关的样板文件:</p><ul class=""><li id="5df6" class="ls lt jg kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">首先，我们必须明确要求在代码中使用 TPU。Colab 和真实的 GCP 云 TPU 是不同的，所以必须小心。</li></ul><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="7d9b" class="mk ml jg mg b gy mm mn l mo mp"><em class="lr">import tensorflow as tf<br/>#Get a handle to the attached TPU. On GCP it will be the CloudTPU itself<br/>resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=’grpc://’ + os.environ[‘COLAB_TPU_ADDR’])</em></span><span id="69ee" class="mk ml jg mg b gy mq mn l mo mp"><em class="lr">#Connect to the TPU handle and initialise it<br/>tf.config.experimental_connect_to_cluster(resolver)<br/>tf.tpu.experimental.initialize_tpu_system(resolver)</em></span></pre><p id="2e87" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们设定分销策略</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="930b" class="mk ml jg mg b gy mm mn l mo mp"><em class="lr">strategy = tf.distribute.experimental.TPUStrategy(resolver)</em></span></pre><ul class=""><li id="fa66" class="ls lt jg kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">之后，我们创建模型</li></ul><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="7fed" class="mk ml jg mg b gy mm mn l mo mp"><em class="lr">with strategy.scope():<br/> model = create_model()#Build your model<br/> model.compile(optimizer=…)#Set your parameters</em></span></pre><ul class=""><li id="efce" class="ls lt jg kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">然后用通常的方式训练它</li></ul><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="4eb9" class="mk ml jg mg b gy mm mn l mo mp"><em class="lr">model.fit(…)</em></span></pre><p id="6529" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这现在起作用了。过去需要 90 分钟的训练，现在只需 9.5 分钟就能完成。毫无疑问非常有效和高效，尽管主题相当神秘。</p><p id="7240" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">问题是:它所需要的只是一些样板代码，那么它为什么没有隐藏在一些 Keras 抽象下呢？也许在未来的版本中会有。</p><p id="cb66" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下一篇:<a class="ae jd" href="https://medium.com/@umash4/trials-and-tribulations-using-keras-on-colab-and-tpu-69378762468d" rel="noopener"> <strong class="kx jh">风雨:在科莱布和 TPU 身上使用 Keras</strong></a></p></div></div>    
</body>
</html>