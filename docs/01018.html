<html>
<head>
<title>Webcam Object Detection with Mask R-CNN on Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在谷歌 Colab 上使用 Mask R-CNN 进行网络摄像头对象检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/webcam-object-detection-with-mask-r-cnn-on-google-colab-b3b012053ed1?source=collection_archive---------14-----------------------#2020-01-29">https://towardsdatascience.com/webcam-object-detection-with-mask-r-cnn-on-google-colab-b3b012053ed1?source=collection_archive---------14-----------------------#2020-01-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5d0c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用 Mask R-CNN 在 Google Colaboratory 上通过实时摄像机流进行对象检测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4dde46b7052b641c9cb48ee785186b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JGk91mPsFg6JpDi2.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在弱光下屏蔽 R-CNN 算法——认为它看到了一只猫\_(ツ)_/</p></figure><p id="f6bb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有很多方法可以进行物体检测。YOLO(你只看一次)是许多人选择的算法，因为它通过完全卷积神经网络(FCNN)的图像只有一次。这使得推断很快。在 GPU 上大约每秒 30 帧。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lu"><img src="../Images/bb90d694acb005be2a6a53cd46e84ff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IOPl2fazu0l0c4W6.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">YOLO 预测的物体包围盒</p></figure><p id="0d4d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一种流行的方法是使用区域提议网络(RPN)。基于 RPN 的算法有两个部分。第一部分给出感兴趣区域(RoI)的建议…即图像中可能有物体的位置。第二个组件对这些建议的区域执行图像分类任务。这种方法比较慢。Mask R-CNN 是脸书人工智能公司的一个框架，它利用 RPN 进行目标检测。Mask R-CNN 可以在 GPU 上以每秒 5 帧的速度运行。我们将使用面具 R-CNN。</p><p id="c830" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当有更快的替代方案时，为什么要使用慢的算法呢？很高兴你问了！</p><blockquote class="lw lx ly"><p id="40d4" class="ky kz lz la b lb lc ju ld le lf jx lg ma li lj lk mb lm ln lo mc lq lr ls lt im bi translated"><em class="it"> Mask R-CNN 除了对象检测和边界框预测之外，还输出对象遮罩。</em></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi md"><img src="../Images/909957206ebe953861705ad37656009f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TsHOXwI7VWs5C76d.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由遮罩 R-CNN 预测的对象遮罩和边界框(<a class="ae lv" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank"> Matterport </a></p></figure><p id="df52" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下部分包含对代码和概念的解释，有助于理解对象检测，以及在 Colab 上使用 Mask R-CNN 处理摄像机输入。这不是一个循序渐进的教程，但希望它会一样有效。在本文的最后，你会找到 Colab 笔记本的链接，让你自己尝试一下。</p><p id="0227" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Matterport 使用 Keras 和 Tensorflow 对 Mask R-CNN 进行了很好的<a class="ae lv" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank">实现。他们提供了</a><a class="ae lv" href="https://github.com/matterport/Mask_RCNN#getting-started" rel="noopener ugc nofollow" target="_blank">笔记本来玩 Mask R-CNN </a>，用自己的数据集训练 Mask R-CNN，并检查模型和重量。</p><h1 id="af32" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">为什么选择 Google Colab</h1><p id="af96" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">如果你没有 GPU 机器或者不想经历设置开发环境的繁琐任务，Colab 是最好的临时选择。</p><p id="23ed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">就我而言，我最近丢失了我最喜欢的笔记本电脑。所以，我用的是我的备份机——一台带键盘的 windows 平板电脑。Colab 使你能够在浏览器中的 Jupyter 笔记本上工作，连接到强大的 GPU 或谷歌云中的 TPU(张量处理单元)虚拟机。虚拟机预装了 Python、Tensorflow、Keras、PyTorch、Fastai 和许多其他重要的机器学习工具。全部免费。请注意，您的会话进度会因为几分钟的不活动而丢失。</p><h1 id="002e" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">Google Colab 入门</h1><p id="b3d4" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated"><a class="ae lv" href="https://colab.research.google.com/notebooks/welcome.ipynb" rel="noopener ugc nofollow" target="_blank">欢迎使用合作指南</a>让您轻松入门。当从相机获取输入、在笔记本的不同单元之间通信以及在 Python 和 JavaScript 代码之间通信时，<a class="ae lv" href="https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb" rel="noopener ugc nofollow" target="_blank">高级 Colab 指南</a>就派上了用场。如果你没有时间看它们，只要记住以下几点。</p><p id="99cc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Colab notebook 中的一个单元格通常包含 Python 代码。默认情况下，代码在连接的虚拟机的<code class="fe nb nc nd ne b">/content</code>目录中运行。Ubuntu 是 Colab VMs 的操作系统，您可以通过用<code class="fe nb nc nd ne b">!</code>开始命令行来执行系统命令。</p><p id="82cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下命令将克隆存储库。</p><pre class="kj kk kl km gt nf ne ng nh aw ni bi"><span id="8a9e" class="nj mf it ne b gy nk nl l nm nn">!git clone https://github.com/matterport/Mask_RCNN</span></pre><p id="8bf3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你在同一个单元格中有多个系统命令，那么你必须将<code class="fe nb nc nd ne b">%%shell</code>作为单元格的第一行，后跟系统命令。因此，下面的命令集将克隆存储库，将目录更改为 Mask_RCNN 并设置项目。</p><pre class="kj kk kl km gt nf ne ng nh aw ni bi"><span id="2374" class="nj mf it ne b gy nk nl l nm nn">%%shell<br/># clone Mask_RCNN repo and install packages<br/>git clone https://github.com/matterport/Mask_RCNN<br/>cd Mask_RCNN<br/>python setup.py install</span></pre><h1 id="5c92" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">导入屏蔽 R-CNN</h1><p id="a0a5" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">以下代码来自 Matterport 提供的<a class="ae lv" href="https://github.com/matterport/Mask_RCNN/blob/master/samples/demo.ipynb" rel="noopener ugc nofollow" target="_blank">演示笔记本</a>。我们只需要将<code class="fe nb nc nd ne b">ROOT_DIR</code>改为<code class="fe nb nc nd ne b">./Mask_RCNN</code>，这是我们刚刚克隆的项目。</p><p id="a7af" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">python 语句<code class="fe nb nc nd ne b">sys.path.append(ROOT_DIR)</code>确保后续代码在<code class="fe nb nc nd ne b">Mask_RCNN</code>目录的上下文中执行，在该目录中我们有 Mask R-CNN 实现可用。代码导入必要的库、类，并下载预先训练好的 Mask R-CNN 模型。穿过它。注释使理解代码变得更容易。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="0c63" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">根据训练的权重创建模型</h1><p id="ad51" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">以下代码在推理模式下创建模型对象，因此我们可以运行预测。然后，它将我们之前下载的预训练模型中的权重加载到模型对象中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="cb82" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">运行对象检测</h1><p id="83e0" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">现在我们在一些图像上测试这个模型。Mask_RCNN 存储库有一个名为<code class="fe nb nc nd ne b">images</code>的目录，其中包含...你猜对了...一些图像。下面的代码从该目录中取出一幅图像，将它传递给模型，并在笔记本上显示结果以及边界框信息。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="5cad" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">预测的结果</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/13dcf354467c3a4770a18b38bc4d13b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KyJBx3awPTVsO5Ft.png"/></div></div></figure><h1 id="b279" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">使用相机图像</h1><p id="919f" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">在 Colab 的高级使用指南中，他们提供了代码，可以<a class="ae lv" href="https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi" rel="noopener ugc nofollow" target="_blank">从笔记本中的网络摄像头</a>捕捉图像，然后将其转发给 Python 代码。</p><p id="41be" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Colab notebook 预装了名为<code class="fe nb nc nd ne b">google.colab</code>的 python 包，其中包含了方便的助手方法。有一个叫做<code class="fe nb nc nd ne b">output.eval_js</code>的方法可以帮助我们评估 JavaScript 代码并将输出返回给 Python。在 JavaScript 中，我们知道有一种叫做<code class="fe nb nc nd ne b"><a class="ae lv" href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia" rel="noopener ugc nofollow" target="_blank">getUserMedia()</a></code>的方法，它使我们能够从用户的网络摄像头和麦克风中捕获音频和/或视频流。</p><p id="5af4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看看下面的 JavaScript 代码。使用 JavaScript 的 WebRTC API 的<code class="fe nb nc nd ne b">getUserMedia()</code>方法，它捕获网络摄像头的视频流，并在 HTML 画布上绘制各个帧。像<code class="fe nb nc nd ne b">google.colab</code> Python 包一样，我们在 JavaScript 中也有<code class="fe nb nc nd ne b">google.colab</code>库。这个库将帮助我们使用 JavaScript 代码中的<code class="fe nb nc nd ne b">kernel.invokeFunction</code>函数调用 Python 方法。</p><p id="f326" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从网络摄像头捕获的图像被转换为 Base64 格式。这个 Base64 图像被传递给一个 Python 回调方法，我们将在后面定义它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="4d47" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们已经讨论过，将<code class="fe nb nc nd ne b">%%shell</code>作为 Colab 笔记本单元的第一行使其作为终端命令运行。同样，您可以通过以<code class="fe nb nc nd ne b">%%javascript</code>开始单元格，在整个单元格中编写 JavaScript。但是我们将简单地把上面写的 JavaScript 代码放在 Python 代码中。像这样:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="bff2" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">Python — JavaScript 通信</h1><p id="897b" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">我们上面写的 JavaScript 代码调用了我们的 Python 代码的<code class="fe nb nc nd ne b">notebook.run_algo</code>方法。下面的代码定义了一个 Python 方法<code class="fe nb nc nd ne b">run_algo</code>,它接受一个 Base64 图像，将其转换为一个 numpy 数组，然后将其传递给我们上面创建的 Mask R-CNN 模型。然后显示输出图像和处理统计数据。</p><blockquote class="lw lx ly"><p id="2fd8" class="ky kz lz la b lb lc ju ld le lf jx lg ma li lj lk mb lm ln lo mc lq lr ls lt im bi translated"><em class="it">重要！别忘了在</em> <code class="fe nb nc nd ne b"><em class="it">try / except</em></code> <em class="it">块中圈出你回调方法的 Python 代码，并记录下来。因为它将被 JavaScript 调用，并且在调用 Python 回调时没有发生错误的迹象。</em></p></blockquote><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="5572" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们把<code class="fe nb nc nd ne b">run_algo</code>注册成<code class="fe nb nc nd ne b">notebook.run_algo</code>吧。现在 JavaScript 代码可以调用它了。我们还调用上面定义的<code class="fe nb nc nd ne b">take_photo()</code> Python 方法，来启动视频流和对象检测。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="e2b8" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">你自己试试</h1><p id="8c84" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">您现在已经准备好在 Google Colab 中尝试<a class="ae lv" href="https://colab.research.google.com/drive/16byp3HScL5HAOrA9axbm4_QXMYQWA6K8" rel="noopener ugc nofollow" target="_blank"> Mask R-CNN on camera。笔记本会一步一步地引导你完成这个过程。</a></p><h1 id="75dc" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">(可选)出于好奇</h1><p id="c2b7" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">我们上面使用的过程在浏览器(JavaScript)中将相机流转换为图像，并将单个图像发送到我们的 Python 代码进行对象检测。这显然不是实时的。所以，我花了几个小时试图将 WebRTC 流从 JavaScript(对等体 A)上传到 Python 服务器(对等体 B)，但没有成功。也许我对<code class="fe nb nc nd ne b">async / await</code>和 Python <code class="fe nb nc nd ne b">Threads</code>的组合不熟悉是主要的障碍。我试图使用<code class="fe nb nc nd ne b"><a class="ae lv" href="https://github.com/aio-libs/aiohttp" rel="noopener ugc nofollow" target="_blank">aiohttp</a></code>作为 Python 服务器，它将使用<code class="fe nb nc nd ne b"><a class="ae lv" href="https://github.com/aiortc/aiortc" rel="noopener ugc nofollow" target="_blank">aiortc</a></code>处理 WebRTC 连接。Python 库<code class="fe nb nc nd ne b">aiortc</code>使得创建 Python 作为 WebRTC 的对等体变得容易。这里是到<a class="ae lv" href="https://colab.research.google.com/drive/1HPrxuPjJDvEx64TlY7K8SPK_XbOJTZ7A" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本的链接，创建 WebRTC 服务器</a>的工作尚未完成。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><p id="f67d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lz">原载于 2020 年 1 月 29 日 https://emadehsan.com</em><a class="ae lv" href="https://emadehsan.com/p/object-detection" rel="noopener ugc nofollow" target="_blank"><em class="lz"/></a><em class="lz">。</em></p></div></div>    
</body>
</html>