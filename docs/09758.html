<html>
<head>
<title>Binary Classification of IMDB Movie Reviews</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">IMDB 电影评论的二元分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/binary-classification-of-imdb-movie-reviews-648342bc70dd?source=collection_archive---------9-----------------------#2020-07-11">https://towardsdatascience.com/binary-classification-of-imdb-movie-reviews-648342bc70dd?source=collection_archive---------9-----------------------#2020-07-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="23b0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Keras 根据情感对评论进行分类。</h2></div><p id="1462" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">二元分类是指将样本分为两类。</p><p id="c54f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个例子中，我们将设计一个神经网络来执行来自 IMDB 电影评论数据集的评论的两类分类，或<em class="le">二元分类</em>，以确定评论是正面的还是负面的。我们将使用 Python 库 Keras。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/02d666eac658457bec8df6cd4f7a83ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ICjJyU2x3WjvODecd81ECg.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">IMDB 电影评论分类。(来源:GitHub)</p></figure><p id="b4cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您正在寻找一个更基本的问题，请查看解决 MNIST 数据集。接下来的内容主要建立在解决 MNIST 问题上，即“你好，世界！深度学习。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/solve-the-mnist-image-classification-problem-9a2865bcf52a"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">解决 MNIST 图像分类问题</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">“你好，世界！”深度学习和 Keras</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm lp ly"/></div></div></a></div><h1 id="7703" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">IMDB 数据集</h1><p id="2a43" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">IMDB 数据集是一组来自互联网电影数据库的 50，000 条高度极化的评论。它们被分成 25000 条评论，每条评论用于训练和测试。每组包含相同数量(50%)的正面和负面评论。</p><p id="b28a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">IMDB 数据集与 Keras 打包在一起。它由评论及其对应的标签组成(0 代表<em class="le">负面</em>，1 代表<em class="le">正面</em>评论)。评论是一个单词序列。它们被预处理成整数序列，每个整数代表字典中的一个特定单词。</p><p id="66be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">IMDB 数据集可以直接从 Keras 加载，通常会在您的机器上下载大约 80 MB。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="05b0" class="mn mo it bd mp mq nr ms mt mu ns mw mx jz nt ka mz kc nu kd nb kf nv kg nd ne bi translated">加载数据</h1><p id="e442" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">让我们从 Keras 加载预打包的数据。我们将只包括 10，000 个最频繁出现的单词。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">加载和分析输入数据</p></figure><p id="7135" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了好玩，我们来解码第一篇评论。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">解读一篇评论</p></figure><h1 id="91e0" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">准备数据</h1><p id="c142" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我们无法将整数列表输入到我们的深层神经网络中。我们需要把它们转换成张量。</p><p id="e663" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了准备我们的数据，我们将对我们的列表进行一次性编码，并将其转换为 0 和 1 的向量。这将把我们的所有序列放大为 10，000 维向量，在对应于该序列中存在的整数的所有索引处包含 1。这个向量在所有索引处都有元素 0，这在整数序列中是不存在的。</p><p id="1e0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简单来说，每个评论对应的 10000 维向量会有</p><ul class=""><li id="8a4a" class="ny nz it kk b kl km ko kp kr oa kv ob kz oc ld od oe of og bi translated">每个索引对应一个单词</li><li id="a94a" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld od oe of og bi translated">每一个值为 1 的索引都是评论中出现的一个词，用它的整数对应物来表示。</li><li id="72d1" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld od oe of og bi translated">每一个包含 0 的索引都是评论中没有的词。</li></ul><p id="70bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将手动矢量化我们的数据，以获得最大的清晰度。这将产生一个形状张量(25000，10000)。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">预处理输入数据</p></figure></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="50d2" class="mn mo it bd mp mq nr ms mt mu ns mw mx jz nt ka mz kc nu kd nb kf nv kg nd ne bi translated">构建神经网络</h1><p id="a5a3" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我们的输入数据是需要映射到定标器标签(0 和 1)的向量。这是最简单的设置之一，一个简单的<em class="le">全连接、密集的</em>层与<em class="le"> relu </em>激活的堆栈表现相当好。</p><h2 id="0e0b" class="om mo it bd mp on oo dn mt op oq dp mx kr or os mz kv ot ou nb kz ov ow nd ox bi translated">隐藏层</h2><p id="247a" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">在这个网络中，我们将利用<em class="le">隐藏层</em>。我们将这样定义我们的层。</p><pre class="lg lh li lj gt oy oz pa pb aw pc bi"><span id="cbc6" class="om mo it oz b gy pd pe l pf pg">Dense(16, activation<strong class="oz iu">=</strong>'relu')</span></pre><p id="d424" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">传递给每个<code class="fe ph pi pj oz b">Dense</code>层的参数<code class="fe ph pi pj oz b">(16)</code>是一层的<em class="le">隐藏单元</em>的数量。</p><p id="eda6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在一系列<em class="le">张量</em>运算之后，生成了激活了<em class="le"> relu </em>的<em class="le">密集</em>层的输出。这个操作链实现为</p><pre class="lg lh li lj gt oy oz pa pb aw pc bi"><span id="d25e" class="om mo it oz b gy pd pe l pf pg">output = relu(dot(W, input) + b)</span></pre><p id="d78c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中，<code class="fe ph pi pj oz b">W</code>是<em class="le">权重矩阵</em>，<code class="fe ph pi pj oz b">b</code>是偏差(张量)。</p><p id="a498" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">具有 16 个<em class="le">隐藏单元</em>意味着矩阵 W 将具有(<em class="le">输入 _ 尺寸</em>、<em class="le"> 16 </em>)的形状。在这种情况下，输入向量的维数是 10，000，权重矩阵的形状将是(10000，16)。如果你把这个网络用图表来表示，你会在这个隐藏层看到 16 个神经元。</p><blockquote class="pk pl pm"><p id="029d" class="ki kj le kk b kl km ju kn ko kp jx kq pn ks kt ku po kw kx ky pp la lb lc ld im bi translated">通俗地说，这一层会有 16 个球。</p></blockquote><p id="fd08" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些球或<em class="le">隐藏单元</em>中的每一个都是层的表示空间中的一个维度。表示空间是数据的所有可行表示的集合。由它的<em class="le">隐藏单元</em>组成的每一个<em class="le">隐藏层</em>的目的是从数据中学习一个特定的数据变换或一个特征/模式。</p><p id="3766" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">DeepAI.org 有一篇关于隐藏层的非常翔实的报道。</p><blockquote class="pk pl pm"><p id="9840" class="ki kj le kk b kl km ju kn ko kp jx kq pn ks kt ku po kw kx ky pp la lb lc ld im bi translated">简单地说，隐藏层是数学函数的层，每一层都被设计成产生特定于预期结果的输出。</p><p id="92e1" class="ki kj le kk b kl km ju kn ko kp jx kq pn ks kt ku po kw kx ky pp la lb lc ld im bi translated">隐藏层允许将神经网络的功能分解为特定的数据转换。每个隐藏层函数都专门用于产生定义的输出。例如，用于识别人的眼睛和耳朵的隐藏层函数可以与后续层结合使用，以识别图像中的面部。虽然单独识别眼睛的功能不足以独立识别物体，但它们可以在神经网络中共同发挥作用。</p></blockquote><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pr"><img src="../Images/9da59753a921fe961048b9dd6649f0c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aIgTWE1223EGTqmi8lYBlA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">ReLU 激活功能。这是最常用的激活功能之一。</p></figure><h2 id="7911" class="om mo it bd mp on oo dn mt op oq dp mx kr or os mz kv ot ou nb kz ov ow nd ox bi translated">模型架构</h2><p id="9f5f" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">对于我们的模型，我们将使用</p><ol class=""><li id="1fc0" class="ny nz it kk b kl km ko kp kr oa kv ob kz oc ld ps oe of og bi translated">两个中间层，每个中间层有 16 个隐藏单元</li><li id="0ab6" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld ps oe of og bi translated">将输出标量情感预测的第三层</li><li id="9b05" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld ps oe of og bi translated">中间层将使用<em class="le"> relu </em>激活功能。<em class="le"> relu </em>或整流线性单位函数将负值清零。</li><li id="9998" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld ps oe of og bi translated">最终层或<em class="le">输出层</em>的 Sigmoid 激活。sigmoid 函数"<em class="le">将"</em>任意值压缩到[0，1]范围内。</li></ol><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pt"><img src="../Images/4d8291ee2d2842489d2e91bc35027d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jSCPkJo0ZpBRA5H3JqFhQg.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">乙状结肠激活函数。(来源:维基百科，Qef)</p></figure><p id="dfac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在选择模型的架构属性时，有正式的原则指导我们的方法。这些不包括在本案例研究中。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">定义模型架构</p></figure><h1 id="57b3" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">编译模型</h1><p id="017a" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">在这一步，我们将选择一个<em class="le">优化器</em>、一个<em class="le">损失函数</em>和<em class="le">指标</em>进行观察。我们将继续前进</p><ul class=""><li id="08d3" class="ny nz it kk b kl km ko kp kr oa kv ob kz oc ld od oe of og bi translated"><em class="le">二元 _ 交叉熵</em>损失函数，常用于二元分类</li><li id="b80f" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld od oe of og bi translated"><em class="le"> rmsprop </em>优化器和</li><li id="1559" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld od oe of og bi translated"><em class="le">准确性</em>作为绩效的衡量标准</li></ul><p id="3b31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以将我们对优化器、损失函数和指标的选择作为<em class="le">字符串</em>传递给<code class="fe ph pi pj oz b">compile</code>函数，因为<code class="fe ph pi pj oz b">rmsprop</code>、<code class="fe ph pi pj oz b">binary_crossentropy</code>和<code class="fe ph pi pj oz b">accuracy</code>是与 Keras 打包在一起的。</p><pre class="lg lh li lj gt oy oz pa pb aw pc bi"><span id="2009" class="om mo it oz b gy pd pe l pf pg">model.complie(optimizer<strong class="oz iu">=</strong>'rmsprop',<br/>              loss <strong class="oz iu">=</strong> 'binary_crossentropy',<br/>              metrics <strong class="oz iu">=</strong> ['accuracy'])</span></pre><p id="db98" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人们可以通过将定制的<em class="le">类实例</em>作为参数传递给<code class="fe ph pi pj oz b">loss</code>、<code class="fe ph pi pj oz b">optimizer</code>或<code class="fe ph pi pj oz b">mertics</code>字段来使用定制的损失函数或优化器。</p><p id="3781" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个例子中，我们将实现我们的默认选择，但是我们将通过传递类实例来实现。如果我们有定制的参数，这正是我们要做的。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">编译模型</p></figure></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="587b" class="mn mo it bd mp mq nr ms mt mu ns mw mx jz nt ka mz kc nu kd nb kf nv kg nd ne bi translated">设置验证</h1><p id="b824" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我们将留出一部分训练数据，用于在训练时验证模型的准确性。一个<em class="le">验证集</em>使我们能够监控我们的模型在训练期间经历历元时在以前看不到的数据上的进展。</p><p id="5ab5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">验证步骤帮助我们微调<code class="fe ph pi pj oz b">model.fit</code>函数的训练参数，以避免数据的过拟合和欠拟合。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">为模型定型设置验证集</p></figure></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="8fb9" class="mn mo it bd mp mq nr ms mt mu ns mw mx jz nt ka mz kc nu kd nb kf nv kg nd ne bi translated">训练我们的模型</h1><p id="bc47" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">最初，我们将在 512 个样本的小批量中为 20 个时期训练我们的模型。我们还将把我们的<em class="le">验证集</em>传递给<code class="fe ph pi pj oz b">fit</code>方法。</p><p id="7889" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">调用<code class="fe ph pi pj oz b">fit</code>方法返回一个<code class="fe ph pi pj oz b">History</code>对象。该对象包含一个成员<code class="fe ph pi pj oz b">history</code>,它存储了训练过程的所有数据，包括随着时间的推移可观察到的或监控到的量的值。我们将保存该对象，以确定更好地应用于训练步骤的微调。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">训练模型。Google Colab GPU 对应的时间。在 CPU、i7 上通常需要大约 20 秒</p></figure><p id="87a9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在训练结束时，我们达到了 99.85%的训练准确率和 86.57%的验证准确率</p><p id="5bb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们已经训练了我们的网络，我们将观察存储在<code class="fe ph pi pj oz b">History</code>对象中的性能指标。</p><p id="a991" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">调用<code class="fe ph pi pj oz b">fit</code>方法返回一个<code class="fe ph pi pj oz b">History</code>对象。这个对象有一个属性<code class="fe ph pi pj oz b">history</code>,这是一个包含四个条目的字典:每个被监控的指标一个条目。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">培训过程的历史。</p></figure><p id="d359" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ph pi pj oz b">history_dict</code>包含以下值</p><ul class=""><li id="f336" class="ny nz it kk b kl km ko kp kr oa kv ob kz oc ld od oe of og bi translated">培训损失</li><li id="b846" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld od oe of og bi translated">训练准确性</li><li id="24f5" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld od oe of og bi translated">验证损失</li><li id="6362" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld od oe of og bi translated">验证准确性</li></ul><p id="7c2b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在每个时期结束时。</p><p id="616d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们使用 Matplotlib 并排绘制训练和验证损失以及训练和验证准确性。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">从训练历史中得到的损失和准确性数据的分析。这些数据告诉我们我们的训练策略的表现。</p></figure><p id="3020" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们观察到<em class="le">最小验证损失</em>和<em class="le">最大验证准确度</em>在大约 3-5 个时期达到。之后，我们观察到两个趋势:</p><ul class=""><li id="4c49" class="ny nz it kk b kl km ko kp kr oa kv ob kz oc ld od oe of og bi translated">验证损失增加，培训损失减少</li><li id="6bf5" class="ny nz it kk b kl oh ko oi kr oj kv ok kz ol ld od oe of og bi translated">验证准确性降低，培训准确性提高</li></ul><p id="8d4a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这意味着该模型在对训练数据的情绪进行分类方面越来越好，但当它遇到新的、以前从未见过的数据时，总是做出更差的预测。这是过度拟合的标志。在第 5 个时期之后，模型开始太接近训练数据。</p><p id="a2d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决过度拟合的问题，我们将把历元的数量减少到 3 到 5 之间。这些结果可能会因您的机器而异，并且由于不同型号之间随机分配重量的本质可能会有所不同。</p><p id="f167" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的情况下，我们将在 3 个纪元后停止训练。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="4a68" class="mn mo it bd mp mq nr ms mt mu ns mw mx jz nt ka mz kc nu kd nb kf nv kg nd ne bi translated">重新训练我们的神经网络</h1><p id="49e5" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我们重新训练我们的神经网络的基础上，我们的研究结果，从历史的损失和准确性的变化。这次我们运行它 3 个时期，以避免在训练数据上过度拟合。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">从头开始再培训</p></figure><p id="c4da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最终，我们实现了 99%的<em class="le">训练准确率</em>和 86%的<em class="le">验证准确率</em>。这很好，考虑到我们正在使用一种非常<em class="le">幼稚的</em>方法。通过使用更好的训练算法可以获得更高的准确度。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="8d95" class="mn mo it bd mp mq nr ms mt mu ns mw mx jz nt ka mz kc nu kd nb kf nv kg nd ne bi translated">评估模型性能</h1><p id="cadd" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我们将使用训练好的模型对测试数据进行预测。输出是一个浮点整数数组，表示评论为正面的概率。正如你所看到的，在某些情况下，网络是绝对肯定的审查是积极的。在其他情况下——没那么多！</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nw nx l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">做预测</p></figure><p id="6a65" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以试着通过使用像<em class="le">均方差这样的度量来找到一些错误分类的情感数量的误差度量，就像我在这里做的</em>。但是这样做就太傻了！对结果的分析不是我们在这里要讨论的内容。然而，我将解释为什么在这种情况下使用<code class="fe ph pi pj oz b">mse</code>是无用的。</p><p id="41df" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">来自我们模型的结果是模型感知评论的积极程度的度量。该模型不是告诉我们样本的绝对类别，而是告诉我们它认为情绪在多大程度上偏向一边或另一边。MSE 是一个过于简单的衡量标准，不能反映解决方案的复杂性。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="d2f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我没有想象这个神经网络。我会的，但这是一个耗时的过程。我确实想象过我用来解决 MNIST 问题的神经网络。如果你想的话，你可以看看这个 GitHub 项目来可视化人工神经网络</p><div class="lv lw gp gr lx ly"><a href="https://github.com/Prodicode/ann-visualizer" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">Prodicode/ann-visualizer</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">一个很棒的可视化 python 库曾经与 Keras 一起工作。它使用 python 的 Graphviz 库来创建一个可展示的…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">github.com</p></div></div><div class="mh l"><div class="pu l mj mk ml mh mm lp ly"/></div></div></a></div></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="500a" class="mn mo it bd mp mq nr ms mt mu ns mw mx jz nt ka mz kc nu kd nb kf nv kg nd ne bi translated">结论</h1><p id="f5f5" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">因此，我们成功地对 IMDB 上的评论进行了分类。我猜这需要重新观看矩阵或 IMDB 建议的任何东西！</p><p id="edfe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我建议你配合这篇文章。您可以使用类似的策略解决大多数二元分类问题。如果你解决了这个问题，试着修改网络及其层的设计和参数。这将帮助您更好地理解您所选择的模型架构的完整性。</p><p id="b4a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在每篇文章中都详细讨论了一个话题。在这一篇中，我们深入研究了一些隐藏的图层。对任何特定主题的详尽解释都不在我的文章范围之内；然而，你会发现大量的快速旁白。</p><p id="3642" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我假设读者对诸如优化器、分类编码、损失函数和度量标准之类的技术细节有着实用的理解。你可以在这里找到我关于这些概念的练习笔记。</p><p id="fa37" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">更多内容，请查看 Francois Chollet 的《用 Python 进行深度学习的 T2》一书。</p><p id="09ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请随意查看本文的<a class="ae pq" href="https://github.com/rakshitraj/fchollet" rel="noopener ugc nofollow" target="_blank">实现</a>以及我在<a class="ae pq" href="https://github.com/rakshitraj/" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的更多工作。</p><p id="7eb2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读！</p></div></div>    
</body>
</html>