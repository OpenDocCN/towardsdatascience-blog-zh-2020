<html>
<head>
<title>How To Code Linear Regression From Scratch — Quick &amp; Easy!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何从头开始编写线性回归代码——快速而简单！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-code-linear-regression-from-scratch-quick-easy-cfd8c8f9eb9d?source=collection_archive---------57-----------------------#2020-05-29">https://towardsdatascience.com/how-to-code-linear-regression-from-scratch-quick-easy-cfd8c8f9eb9d?source=collection_archive---------57-----------------------#2020-05-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9e33" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用不到50行python代码编写一个最流行的机器学习算法！</h2></div></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/67d6604531854628c9e9aec86cac9485.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BSp2Lp-OTZ2A8l1A"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://unsplash.com/@clemono2?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克莱姆·奥诺杰霍</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="d423" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，我们将学习如何编写线性回归代码，即机器学习的<em class="mc">“hello world”</em>，在python的<strong class="li iu">不到50行</strong>！数据科学家和程序员经常使用像<em class="mc"> scikit-learn </em>这样的第三方库来整合机器学习算法，但却无法理解它们在幕后是如何工作的。</p><p id="e67f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">学习如何从头开始编写算法不仅会提高我们的编程能力，还会提供对当前主题的更深入的理解。</p><p id="13f2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你需要了解什么是线性回归以及它是如何工作的，请随意查看我最近发表的<a class="ae lf" rel="noopener" target="_blank" href="/linear-regression-made-easy-702e5dc01f03">直觉文章</a>。话虽如此，让我们停止浪费时间，把我们的手弄脏吧！</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="28f6" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">建立</h2><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="52c0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">显然，我们从导入将要使用的库开始:</p><ul class=""><li id="6ddd" class="my mz it li b lj lk lm ln lp na lt nb lx nc mb nd ne nf ng bi translated">我不知道你怎么想，但我肯定不想用普通的python来处理向量和矩阵数学</li><li id="a05d" class="my mz it li b lj nl lm nm lp nn lt no lx np mb nd ne nf ng bi translated"><code class="fe nh ni nj nk b"><strong class="li iu"><em class="mc">pandas</em></strong></code> <em class="mc"> — </em> Pandas允许我们导入保存在同一目录下的<a class="ae lf" href="https://www.kaggle.com/fivethirtyeight/the-ultimate-halloween-candy-power-ranking" rel="noopener ugc nofollow" target="_blank"> csv数据</a></li><li id="826e" class="my mz it li b lj nl lm nm lp nn lt no lx np mb nd ne nf ng bi translated"><code class="fe nh ni nj nk b"><strong class="li iu"><em class="mc">matplotlib</em></strong></code><em class="mc">——</em>这个库将帮助我们在本文后面可视化我们的算法</li></ul><p id="bb06" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于我们的初始数据集，我们将使用<a class="ae lf" href="https://www.kaggle.com/fivethirtyeight/the-ultimate-halloween-candy-power-ranking" rel="noopener ugc nofollow" target="_blank">这个kaggle集合</a>并基于某些特征来确定某样东西是否是巧克力！如果你打算继续下去，你应该这样做！)，确保你<a class="ae lf" href="https://www.kaggle.com/fivethirtyeight/the-ultimate-halloween-candy-power-ranking" rel="noopener ugc nofollow" target="_blank"> <strong class="li iu">下载了。csv </strong> </a>并存储在<strong class="li iu">你正在编码的同一个目录</strong>中。同样，请随意阅读Kaggle上的摘要，看看数据集中的每个要素代表什么。</p><p id="bd81" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">正如承诺的，我们不会使用任何会使我们的旅程太容易的包装！那一点也不好玩。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="9070" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">数据</h2><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><pre class="kq kr ks kt gt nq nk nr ns aw nt bi"><span id="0eac" class="md me it nk b gy nu nv l nw nx">This dataset has 85 entries with 11 features <br/>The shape of X is: (85, 11) <br/>The shape of y is: (85, 1)</span></pre><p id="5cb1" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这里，我们使用熊猫将巧克力数据加载到我们的程序中；我们还删除了两个在计算中不使用的列:<em class="mc"> competitorname </em>和<em class="mc"> winpercent </em>。</p><p id="1cca" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然后我们将数据分割成我们的<strong class="li iu"> <em class="mc"> X </em> </strong>和<strong class="li iu"> <em class="mc"> y </em> </strong>变量，分别代表我们的<strong class="li iu">特征</strong>和<strong class="li iu">标签</strong>。我们的<strong class="li iu"> <em class="mc"> y </em> </strong>成为数据集中的第一列，指示我们的特定甜食是巧克力(<em class="mc"> 1 </em>)还是不是(<em class="mc"> 0 </em>)。剩余的列用作变量/特征来预测我们的<strong class="li iu"> <em class="mc"> y </em> </strong>，并因此成为我们的<strong class="li iu"> <em class="mc"> X. </em> </strong></p><p id="417d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你对我们为什么在第<em class="mc"> 5 </em>行使用<code class="fe nh ni nj nk b">…[:, 0][:,np.newaxis]</code>感到困惑，这是为了将<strong class="li iu"> <em class="mc"> y </em> </strong>变成一列。我们只需添加一个新的维度，将水平向量转换为垂直列！相信我，这将有助于以后的计算。</p><p id="92f7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在第二个要点中，我们简单地看一下我们拥有的数据。正如所见，该块表示我们的数据集中有85个样本，每个样本具有11个特征。同样，我们的<strong class="li iu"> <em class="mc"> X </em> </strong>有<em class="mc"> 85 </em>行和<em class="mc"> 11 </em>列，我们的<strong class="li iu"> <em class="mc"> y </em> </strong>有<em class="mc"> 85 </em>行和<em class="mc"> 1 </em>列。</p><p id="b43b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">简单提醒一下，记住每一行代表一个单独的数据点，每一列是与之对应的一个特性。例如，我们在<strong class="li iu"><em class="mc"/></strong>中有<em class="mc"> 85个条目</em>，其中一列表示该点是否为<em class="mc">巧克力(1或0) </em>。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="e729" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">费用</h2><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="502d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这是我们模型的<em class="mc">成本</em>函数；我们选择了<strong class="li iu"> <em class="mc"> (1/2) x均方误差</em> </strong>来表示(<em class="mc">第5行</em>)。</p><ul class=""><li id="fd02" class="my mz it li b lj lk lm ln lp na lt nb lx nc mb nd ne nf ng bi translated"><code class="fe nh ni nj nk b"><strong class="li iu">pred</strong></code>代表通过将我们的特征(<code class="fe nh ni nj nk b"><strong class="li iu"><em class="mc">X</em></strong></code>)乘以我们的当前权重(<code class="fe nh ni nj nk b"><strong class="li iu"><em class="mc">params</em></strong></code>)并将它们相加而获得的预测</li><li id="b232" class="my mz it li b lj nl lm nm lp nn lt no lx np mb nd ne nf ng bi translated">然后，我们通过将预测值与预期值/正确值进行比较来计算总误差/成本(<em class="mc">第5行)</em></li></ul><blockquote class="ny nz oa"><p id="fbd2" class="lg lh mc li b lj lk ju ll lm ln jx lo ob lq lr ls oc lu lv lw od ly lz ma mb im bi translated">旁注:如果你不熟悉<code class="fe nh ni nj nk b">@</code>命令，它只是点积(类似于<code class="fe nh ni nj nk b">np.dot</code>)</p></blockquote></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="b05b" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">梯度下降</h2><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="fc74" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">考虑到成本，我们现在可以实现算法的核心:<em class="mc">梯度下降</em>。同样，如果你不熟悉梯度下降是如何工作的，或者需要一些补充，看看<a class="ae lf" rel="noopener" target="_blank" href="/linear-regression-made-easy-702e5dc01f03">以前的文章</a>！让我们看看代码在做什么:</p><ul class=""><li id="bd8a" class="my mz it li b lj lk lm ln lp na lt nb lx nc mb nd ne nf ng bi translated"><code class="fe nh ni nj nk b"><strong class="li iu">iterations</strong></code> —我们将经历的梯度下降的迭代次数</li><li id="09db" class="my mz it li b lj nl lm nm lp nn lt no lx np mb nd ne nf ng bi translated"><code class="fe nh ni nj nk b"><strong class="li iu">cost_history</strong></code> —允许我们跟踪成本历史的数组；这将有助于我们可视化算法！</li></ul><p id="8f6c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">第6行</em>是梯度下降的核心，<strong class="li iu">更新规则</strong> <code class="fe nh ni nj nk b">(<strong class="li iu">learning_rate</strong>/num_samples) * X.T @ (X @ params — y)</code>代表代价函数相对于<em class="mc">权重/参数</em>的<em class="mc">偏导数</em>。然后，我们取这个值，乘以我们的<em class="mc">学习率</em>(如前面粗体所示)，并从我们的旧权重/参数值中减去它，以便更新它们！</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="a9d7" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">规范化和初始化</h2><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="5775" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在我们把所有东西放在一起之前，我们必须<strong class="li iu">规范化</strong>和<strong class="li iu">初始化</strong>我们的数据。</p><p id="783b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">规范化</em>是一种数据准备技术，它只是将数值重新调整为从<em class="mc"> 0 </em>到<em class="mc"> 1的数字。这样做是为了提高我们的准确性，同时降低我们的成本/误差。</em></p><blockquote class="ny nz oa"><p id="b0d2" class="lg lh mc li b lj lk ju ll lm ln jx lo ob lq lr ls oc lu lv lw od ly lz ma mb im bi translated">旁注:如果你尝试实验，看看如果我们不正常化会发生什么，你会得到额外的荣誉！</p></blockquote><p id="cd3f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你熟悉线性回归，你应该意识到现在还缺少一些东西:偏差项。事实证明，我们可以将偏差项添加到我们的特征矩阵<strong class="li iu"> <em class="mc"> X </em> </strong>中。这就是你在第<em class="mc"> 9 </em>行看到的:我们在我们的<strong class="li iu"> <em class="mc"> X </em> </strong>前面堆叠一列1，作为我们的偏置项。现在，我们不再只考虑<em class="mc"> 11 </em>的初始特征，而是考虑<em class="mc"> 12 </em>的偏差。很漂亮吧？</p><p id="9ffa" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">同样，我们也将我们的<em class="mc">权重/ </em> <strong class="li iu"> <em class="mc">参数</em> </strong>初始化为零(<em class="mc">第11行</em>)</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h2 id="8a74" class="md me it bd mf mg mh dn mi mj mk dp ml lp mm mn mo lt mp mq mr lx ms mt mu mv bi translated">建立模型！</h2><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="21b0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在，是时候把所有的东西放在一起，整合我们之前做的功能了；让我们来看看当我们点击运行时会发生什么！</p><pre class="kq kr ks kt gt nq nk nr ns aw nt bi"><span id="b4fc" class="md me it nk b gy nu nv l nw nx">Initial cost:  0.21764705882352942</span><span id="0ae8" class="md me it nk b gy oe nv l nw nx">Optimal parameters are: <br/>[[ 0.43529399]<br/> [-0.26827445]<br/> [-0.03002024]<br/> [ 0.03246823]<br/> [-0.01615199]<br/> [ 0.03059432]<br/> [-0.01911575]<br/> [ 0.11609403]<br/> [-0.00797628]<br/> [ 0.01947274]<br/> [ 0.05175128]]</span><span id="1383" class="md me it nk b gy oe nv l nw nx">Most important features determined by the algorithm: <br/>[('fruity', 0.43529399417329273), <br/>('caramel', -0.2682744491689681), <br/>('pluribus', 0.11609403084213005), <br/>('nougat', 0.032468233412292824), <br/>('hard', 0.03059432326508639), <br/>('peanutyalmondy', -0.03002024138032047), <br/>('pricepercent', 0.019472737570368572), <br/>('bar', -0.01911575068810122), <br/>('crispedricewafer', -0.016151994114632157), <br/>('sugarpercent', -0.00797628452755172)]</span><span id="c62c" class="md me it nk b gy oe nv l nw nx">Final cost:  0.04433152061220413</span></pre><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi of"><img src="../Images/4c6f4804f67ddcbd8ab6d88aeca2adaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*Fzy51YnVHmSG7BKh4-4wIw.png"/></div></figure><p id="62a8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然后，砰！我们做到了！正如您从输出中看到的，我们显著降低了成本，从<em class="mc"> 0.22 </em>降至<em class="mc"> 0.04 </em>。在上图中，您可以看到每次迭代的成本都在降低！</p><p id="55f4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了帮助进一步理解算法在做什么，我打印了<em class="mc">最优权重</em>。这表示对应于每个特征的权重，最终用于预测某物是否是巧克力。换句话说，如果我们有另一个<em class="mc">看不见的数据点</em>具有相同的特征，我们可以用这些权重乘以它的值，并确定它是否是巧克力！</p><p id="770d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">同样，我也打印了一个最有影响力的功能的排序列表。这很有趣，因为你可以看到计算机认为什么是最重要的。不出所料，这表明味道是否是水果味是区分糖果和巧克力的一个很好的标准。第二名和第三名分别由<em class="mc">焦糖</em>和<em class="mc"> pluribus </em>获得。Pluribus只是一种指示，表明这种糖果是否是装在袋子或盒子里的许多糖果中的一种。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="5366" class="og me it bd mf oh oi oj mi ok ol om ml jz on ka mo kc oo kd mr kf op kg mu oq bi translated">类实现</h1><p id="2b27" class="pw-post-body-paragraph lg lh it li b lj or ju ll lm os jx lo lp ot lr ls lt ou lv lw lx ov lz ma mb im bi translated">既然我们已经从零开始在不相交的部分中构建了线性回归，那么让我们把它们放在一起，稍微调整一下，并把它变成一个类！现在我们有了自己的线性回归模块:</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="f298" class="og me it bd mf oh oi oj mi ok ol om ml jz on ka mo kc oo kd mr kf op kg mu oq bi translated">战斗的时间到了！</h1><p id="1ed2" class="pw-post-body-paragraph lg lh it li b lj or ju ll lm os jx lo lp ot lr ls lt ou lv lw lx ov lz ma mb im bi translated">好吧，没什么大不了的，我们从头开始做了一个线性回归实现。<em class="mc">我们怎么知道它有多好？</em></p><p id="2929" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为什么不让我们班和sklearn的进行一场生死之战呢！让我们在他们自己的主场作战，使用他们的<em class="mc">波士顿住房数据集</em>，这样我们就可以为训练和测试集使用更多的数据样本！</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><pre class="kq kr ks kt gt nq nk nr ns aw nt bi"><span id="e8d7" class="md me it nk b gy nu nv l nw nx">               Our's      Sklearn's<br/>Training Acc.  0.724896   0.727084<br/>Test Acc.      0.771918   0.772993</span></pre><p id="cdbc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我不知道你怎么想，但我认为保持精确度是一项相当可靠的工作！希望这能让你明白隐藏在引擎盖下的东西并不总是像看起来那么复杂。</p><p id="e005" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我强烈建议您继续使用battle and LinearRegression类来试验不同的数据集，看看它能准确预测什么，另一方面，在这方面做得不太好。欢迎在下面的回复中链接或谈论你的结果和发现！</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="7d8d" class="og me it bd mf oh oi oj mi ok ol om ml jz on ka mo kc oo kd mr kf op kg mu oq bi translated">结论</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ow"><img src="../Images/9115b57d1d530398588c6acab5f6d0c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GnuHdj7DXy4MILAr"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://unsplash.com/@cbyoung?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克拉克·杨</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="f15c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">希望你从零开始实现线性回归很有趣，因为我确实做到了！更重要的是，我真心希望你对线性回归的工作原理有更深的理解。</p><p id="aaa1" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你对一些术语有点困惑，我强烈建议你去看看<a class="ae lf" rel="noopener" target="_blank" href="/linear-regression-made-easy-702e5dc01f03">那篇用通俗的语言解释算法如何工作的文章</a>。</p><p id="fd5f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你想跟随一个完整解释的jupyter笔记本或者只是想在最后下载类，请随意查看<a class="ae lf" href="https://github.com/athreyaanand/ML-from-scratch/tree/master/LinearRegression" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>。</p><p id="e536" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我真诚地希望你喜欢阅读这篇文章，并希望很快见到你，这样我们就可以一起掌握ML和数据科学的世界！</p></div></div>    
</body>
</html>