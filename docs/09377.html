<html>
<head>
<title>Batch Normalization in practice: an example with Keras and TensorFlow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实践中的批量规范化:以 Keras 和 TensorFlow 2.0 为例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/batch-normalization-in-practice-an-example-with-keras-and-tensorflow-2-0-b1ec28bde96f?source=collection_archive---------2-----------------------#2020-07-05">https://towardsdatascience.com/batch-normalization-in-practice-an-example-with-keras-and-tensorflow-2-0-b1ec28bde96f?source=collection_archive---------2-----------------------#2020-07-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dd5e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">添加和自定义批处理规范化的分步教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f062800fc3f1fd90098c02c23901ebb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hXdraIr1PYp_3O15opwraQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@markuswinkler?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">马库斯·温克勒</a>在<a class="ae ky" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="d5fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将重点关注在我们的机器学习模型中添加和定制批处理规范化，并查看一个示例，说明我们如何在 Keras 和 TensorFlow 2.0 的实践中做到这一点。</p><h1 id="5403" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">批处理规范化的简明介绍</h1><p id="f58c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在深度学习的兴起中，最重要的一个思想一直是一种叫做<strong class="lb iu"> <em class="ms">批量规格化</em> </strong>(也叫<strong class="lb iu"> <em class="ms">批量规格化</em> </strong>)的算法。</p><blockquote class="mt"><p id="240d" class="mu mv it bd mw mx my mz na nb nc lu dk translated"><strong class="ak"> <em class="nd">批量标准化</em> </strong>是一种用于训练深度神经网络的技术，它将每个小批量的输入标准化到一个层。这具有稳定学习过程和显著减少训练深度网络所需的训练时期的效果。</p><p id="ca5a" class="mu mv it bd mw mx my mz na nb nc lu dk translated">杰森·布朗利</p></blockquote><p id="30b6" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">在训练期间，可以通过计算每个小批量层的每个输入变量的平均值和标准偏差，并使用这些统计数据来执行标准化，从而实现批量标准化。</p><p id="d34e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">形式上，批处理规范化算法[1]被定义为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/98548cf7181434c47880ede4865afbbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_vYBR0bBHcd-zNQf0c6jpg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自原论文:<a class="ae ky" href="https://arxiv.org/pdf/1502.03167v3.pdf" rel="noopener ugc nofollow" target="_blank">批量归一化:通过减少内部协变量移位加速深度网络训练</a></p></figure><p id="3a4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在该算法中，<code class="fe nk nl nm nn b"><em class="ms">B</em></code>被用来表示整个训练集的一个规模为<code class="fe nk nl nm nn b">m</code>的小批量。<code class="fe nk nl nm nn b"><em class="ms">B</em></code>的均值和方差可计算如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/14ddffde5159502486af6a2296b4ba5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Latu_QdOWbYtCHWfqYEOKA.png"/></div></div></figure><p id="3cb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于具有<em class="ms"> d </em>维度输入<code class="fe nk nl nm nn b"><em class="ms">x</em> = (<em class="ms">x_1</em>, …, <em class="ms">x_d</em>)</code>的层，其输入的每个维度可以单独归一化(重新居中和重新缩放)。因此，一个<em class="ms"> d </em>维输入的归一化可以计算为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/c9bce91caff40c33280220b14c4804af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4YaBC8Rs9_i1xtXH2zIUxw.png"/></div></div></figure><p id="151e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ε加在分母中以保持数值稳定，它是一个任意小的常数。</p><p id="e648" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，为了恢复网络的表示能力，变换步骤被定义为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/a4cb84161003b763ac28588f6963cd0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*bc1EB8lPfAZntjCP5-iEhg.png"/></div></figure><p id="14fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中参数β和γ随后在优化过程中被学习。</p><p id="a711" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">批量标准化的好处有[2]:</p><ul class=""><li id="0257" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated"><strong class="lb iu">可以更快地训练深度神经网络:</strong>虽然由于正向传递期间的额外归一化计算和反向传播期间要训练的额外超参数，每次训练迭代将更慢，但它应该收敛得更快；因此，训练总体上应该更快。</li><li id="0887" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated"><strong class="lb iu">更高的学习率:</strong>梯度下降一般需要较小的学习率，网络才能收敛。随着网络变得更深，梯度在反向传播过程中变得更小，因此需要更多的迭代。使用批量标准化允许更高的学习率，从而提高训练速度。</li><li id="2095" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated"><strong class="lb iu">更容易初始化权重:</strong>权重初始化可能很困难，尤其是在创建更深层次的网络时。批次标准化降低了对初始起始重量的敏感度。</li></ul><p id="b05e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您正在寻找完整的解释，您可能会发现以下资源很有用:</p><ul class=""><li id="18d8" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated"><a class="ae ky" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank">原纸</a></li><li id="77b0" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated"><a class="ae ky" href="https://www.coursera.org/lecture/deep-neural-network/normalizing-activations-in-a-network-4ptp2" rel="noopener ugc nofollow" target="_blank">deep learning . ai 中的批量规范化</a></li></ul><p id="4e66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下面的文章中，我们将在我们的机器学习模型中添加和定制批处理规范化。</p><h1 id="c45c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">环境设置、源代码和数据集准备</h1><p id="26c2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们将使用与在<a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-model-regularization-in-practice-an-example-with-keras-and-tensorflow-2-0-52a96746123e">模型正则化教程</a>中相同的数据集。如果你已经熟悉这一章，你可以跳过它。</p><p id="e4fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了运行本教程，您需要安装</p><blockquote class="mt"><p id="7c3e" class="mu mv it bd mw mx my mz na nb nc lu dk translated"><em class="nd"> TensorFlow 2，numpy，pandas，sklean，matplotlib </em></p></blockquote><p id="5d79" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">它们都可以直接安装在 vis PyPI 上，我强烈建议创建一个新的虚拟环境。关于创建 Python 虚拟环境的教程</p><ul class=""><li id="dd86" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/create-virtual-environment-using-virtualenv-and-add-it-to-jupyter-notebook-6e1bf4e03415">使用“virtualenv”创建虚拟环境，并将其添加到 Jupyter 笔记本中</a></li><li id="078f" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated"><a class="ae ky" href="https://medium.com/analytics-vidhya/create-virtual-environment-using-conda-and-add-it-to-jupyter-notebook-d319a81dfd1" rel="noopener">使用“conda”创建虚拟环境，并将其添加到 Jupyter 笔记本中</a></li></ul><h2 id="6a54" class="of lw it bd lx og oh dn mb oi oj dp mf li ok ol mh lm om on mj lq oo op ml oq bi translated">源代码</h2><p id="5877" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这是一个循序渐进的教程，所有的说明都在这篇文章中。源代码请查看我的 Github <a class="ae ky" href="https://github.com/BindiChen/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习报告</a>。</p><h2 id="5020" class="of lw it bd lx og oh dn mb oi oj dp mf li ok ol mh lm om on mj lq oo op ml oq bi translated">数据集准备</h2><p id="d22e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">本教程使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Iris_flower_data_set" rel="noopener ugc nofollow" target="_blank">安德森鸢尾花(iris) </a>数据集进行演示。数据集包含五个属性下的一组 150 条记录:<em class="ms">萼片长度</em>、<em class="ms">萼片宽度</em>、<em class="ms">花瓣长度</em>、<em class="ms">花瓣宽度、</em>和<em class="ms">类别</em>(从 sklearn 数据集称为<em class="ms">目标</em>)。</p><p id="f923" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入库并从<strong class="lb iu"> <em class="ms"> scikit-learn </em> </strong>库中获取虹膜数据集。你也可以从<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank"> UCI 虹膜数据集</a>下载。</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="dcd2" class="of lw it nn b gy ov ow l ox oy">import tensorflow as tf<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.datasets import load_iris<br/>from sklearn.model_selection import train_test_split</span><span id="62c9" class="of lw it nn b gy oz ow l ox oy"><strong class="nn iu">iris = load_iris()</strong></span></pre><p id="6b4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了研究数据，让我们将数据加载到一个数据帧中</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="a651" class="of lw it nn b gy ov ow l ox oy"># Load data into a DataFrame<br/><strong class="nn iu">df = pd.DataFrame(iris.data, columns=iris.feature_names)<br/></strong># Convert datatype to float<br/><strong class="nn iu">df = df.astype(float)<br/></strong># append "target" and name it "label"<br/><strong class="nn iu">df['label'] = iris.target<br/></strong># Use string label instead<br/><strong class="nn iu">df['label'] = df.label.replace(dict(enumerate(iris.target_names)))</strong></span></pre><p id="d159" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并且<code class="fe nk nl nm nn b">df</code>应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/f7a3a5bc22ae3744ae58d627f5cad14a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WQ9W6yarWnOyEz56LR87kQ.png"/></div></div></figure><p id="3d6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们注意到<strong class="lb iu"> <em class="ms">标签</em> </strong>列是一个分类特征，需要将其转换为<a class="ae ky" rel="noopener" target="_blank" href="/what-is-one-hot-encoding-and-how-to-use-pandas-get-dummies-function-922eb9bd4970">一键编码</a>。否则，我们的机器学习算法将无法直接将其作为输入。</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="ac87" class="of lw it nn b gy ov ow l ox oy"># label -&gt; one-hot encoding<br/><strong class="nn iu">label = pd.get_dummies(df['label'], prefix='label')</strong><br/><strong class="nn iu">df = pd.concat([df, label], axis=1)</strong><br/># drop old label<br/>df.drop(['label'], axis=1, inplace=True)</span></pre><p id="8410" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，<code class="fe nk nl nm nn b">df</code>应该是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/bf6c6ea6826b879c4cc325805781cd65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jWXRJnZEHn2xWcyqqbK0bQ.png"/></div></div></figure><p id="2148" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们创建<code class="fe nk nl nm nn b">X</code>和<code class="fe nk nl nm nn b">y</code>。Keras 和 TensorFlow 2.0 只接受 Numpy 数组作为输入，所以我们必须将 DataFrame 转换回 Numpy 数组。</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="29aa" class="of lw it nn b gy ov ow l ox oy"># Creating X and y<strong class="nn iu">X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]</strong><br/># Convert DataFrame into np array<br/><strong class="nn iu">X = np.asarray(X)y = df[['label_setosa', 'label_versicolor', 'label_virginica']]<br/></strong># Convert DataFrame into np array<br/><strong class="nn iu">y = np.asarray(y)</strong></span></pre><p id="2ec1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们使用来自<strong class="lb iu"> sklearn </strong>库的<code class="fe nk nl nm nn b"><strong class="lb iu">train_test_split()</strong></code> <strong class="lb iu"> </strong>将数据集拆分成训练集(80%)和测试集(20%)。</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="504a" class="of lw it nn b gy ov ow l ox oy">X_train, X_test, y_train, y_test = <strong class="nn iu">train_test_split</strong>(<br/>  <strong class="nn iu">X,<br/>  y,<br/>  test_size=0.20</strong><br/>)</span></pre><p id="82c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">太好了！我们的数据已经准备好建立一个机器学习模型。</p><h1 id="5361" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">用批量归一化建立神经网络模型</h1><p id="d9d0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">用 Keras 和 TensorFlow 2.0 创建机器学习模型有<a class="ae ky" rel="noopener" target="_blank" href="/3-ways-to-create-a-machine-learning-model-with-keras-and-tensorflow-2-0-de09323af4d3"> 3 种方法。由于我们正在构建一个简单的全连接神经网络，为了简单起见，让我们使用最简单的方法:带有<code class="fe nk nl nm nn b">Sequential()</code>的顺序模型。</a></p><p id="861f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入<code class="fe nk nl nm nn b">Sequential</code>和<code class="fe nk nl nm nn b">BatchNormalization</code></p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="0d87" class="of lw it nn b gy ov ow l ox oy">from tensorflow.keras.models import <strong class="nn iu">Sequential</strong><br/>from tensorflow.keras.layers import Dense, <strong class="nn iu">BatchNormalization</strong></span></pre><p id="177c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们继续创建一个顺序模型</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="dc2b" class="of lw it nn b gy ov ow l ox oy">model = Sequential([<br/>    Dense(64, <strong class="nn iu">input_shape=(4,)</strong>, activation="relu"),<br/>    Dense(128, activation='relu'),<br/>    Dense(128, activation='relu'),<br/>    Dense(64, activation='relu'),<br/>    Dense(64, activation='relu'),<br/>    Dense(3, <strong class="nn iu">activation='softmax'</strong>)<br/>]);</span></pre><p id="8e09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的型号有以下规格:</p><ul class=""><li id="f2da" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated">第一层(也称为输入层)有<code class="fe nk nl nm nn b">input_shape</code>来设置输入尺寸<code class="fe nk nl nm nn b">(4,)</code></li><li id="f69c" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">输入层有 64 个单元，后面是 2 个密集层，每个层有 128 个单元。然后还有 2 个密度层，每个层有 64 个单元。所有这些层都使用<code class="fe nk nl nm nn b">relu</code>激活功能。</li><li id="bfba" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">输出密集层有 3 个单元和<code class="fe nk nl nm nn b">softmax</code>激活功能。</li></ul><p id="fa3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以将批量规范化添加到我们的模型中，添加方式与添加<code class="fe nk nl nm nn b">Dense</code>层相同。</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="a47a" class="of lw it nn b gy ov ow l ox oy">model = Sequential([<br/>    Dense(64, input_shape=(4,), activation="relu"),<br/>    <strong class="nn iu">BatchNormalization(),</strong><br/>    Dense(128, activation='relu'),<br/>    <strong class="nn iu">BatchNormalization(),</strong><br/>    Dense(128, activation='relu'),<br/>    <strong class="nn iu">BatchNormalization(),</strong><br/>    Dense(64, activation='relu'),<br/>    <strong class="nn iu">BatchNormalization(),</strong><br/>    Dense(64, activation='relu'),<br/>    <strong class="nn iu">BatchNormalization(),</strong><br/>    Dense(3, activation='softmax')<br/>]);</span></pre><p id="233b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nk nl nm nn b">BatchNormalization()</code>在每一批标准化前一层的激活，默认情况下，它使用以下值[3]:</p><ul class=""><li id="8abe" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated">动量默认为<code class="fe nk nl nm nn b">0.99</code></li><li id="76be" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">超参数ε默认为<code class="fe nk nl nm nn b">0.001</code></li><li id="81c6" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">超参数β默认为一个<code class="fe nk nl nm nn b">all-zeros</code>向量</li><li id="1c89" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">超参数γ默认为一个<code class="fe nk nl nm nn b">all-ones</code>矢量</li></ul><p id="c4c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些都可以通过给<code class="fe nk nl nm nn b">BatchNormalization()</code>添加可选参数来改变。例如</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="8284" class="of lw it nn b gy ov ow l ox oy">from tensorflow.keras.initializers import <strong class="nn iu">RandomNormal, Constant</strong></span><span id="79cb" class="of lw it nn b gy oz ow l ox oy"># Model with default batch normalization<br/>model = Sequential([<br/>    Dense(64, input_shape=(4,), activation="relu"),<br/>    BatchNormalization(),<br/>    Dense(128, activation='relu'),<br/>    BatchNormalization(),<br/>    Dense(128, activation='relu'),<br/>    BatchNormalization(),<br/>    Dense(64, activation='relu'),<br/>    BatchNormalization(),<br/>    Dense(64, activation='relu'),<br/>    <strong class="nn iu">BatchNormalization(<br/>        momentum=0.95, <br/>        epsilon=0.005,<br/>        beta_initializer=RandomNormal(mean=0.0, stddev=0.05), <br/>        gamma_initializer=Constant(value=0.9)<br/>    ),</strong><br/>    Dense(3, activation='softmax')<br/>]);</span></pre><p id="1778" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nk nl nm nn b">RandomNormal()</code>生成正态分布的张量，而<code class="fe nk nl nm nn b">Constant()</code>生成常数值的张量。通过运行<code class="fe nk nl nm nn b">model.summary()</code>，您应该会得到一个如下所示的模型摘要:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/805bb6c234c5613b3ce6827665d271e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R99kAg5w9mgYmR3EcAvzuQ.png"/></div></div></figure><h2 id="96cc" class="of lw it bd lx og oh dn mb oi oj dp mf li ok ol mh lm om on mj lq oo op ml oq bi translated">培养</h2><p id="f818" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在让我们用批处理规范化来编译和拟合我们的模型。我们首先用以下规范编译我们的模型</p><ul class=""><li id="77b1" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated">使用 Adam ( <code class="fe nk nl nm nn b">adam</code>)优化算法作为优化器</li><li id="55b9" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">使用分类交叉熵损失函数(<code class="fe nk nl nm nn b">categorical_crossentropy</code>)来解决我们的<strong class="lb iu"> <em class="ms">多类分类</em> </strong>问题</li><li id="a90e" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">为简单起见，使用<code class="fe nk nl nm nn b">accuracy</code>作为我们在训练和测试期间评估模型的评估指标。</li></ul><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="11df" class="of lw it nn b gy ov ow l ox oy">model.compile(<br/>    <strong class="nn iu">optimizer='adam', <br/>    loss='categorical_crossentropy', <br/>    metrics=['accuracy']</strong><br/>)</span></pre><p id="1d5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们可以调用<code class="fe nk nl nm nn b">model.fit()</code>来使我们的模型符合训练数据。</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="c440" class="of lw it nn b gy ov ow l ox oy">history = model.fit(<br/>    X_train, <br/>    y_train, <br/>    epochs=200, <br/>    validation_split=0.25, <br/>    batch_size=40, <br/>    verbose=2<br/>)</span></pre><p id="c533" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果一切顺利，我们应该得到如下输出</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="f09c" class="of lw it nn b gy ov ow l ox oy">Train on 90 samples, validate on 30 samples<br/>Epoch 1/200<br/>90/90 - 3s - loss: 0.8735 - accuracy: 0.5778 - val_loss: 1.0685 - val_accuracy: 0.6667<br/>Epoch 2/200<br/>90/90 - 0s - loss: 0.1983 - accuracy: 0.9333 - val_loss: 1.0640 - val_accuracy: 0.4667<br/>......<br/>......<br/>Epoch 200/200<br/>90/90 - 0s - loss: 0.0532 - accuracy: 0.9778 - val_loss: 0.1453 - val_accuracy: 0.9333</span></pre><h2 id="b36a" class="of lw it bd lx og oh dn mb oi oj dp mf li ok ol mh lm om on mj lq oo op ml oq bi translated">模型评估</h2><p id="64f1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">最后，是时候看看这个模型到底有没有用了</p><ul class=""><li id="f1e9" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated">绘制训练和验证损失和准确性，以观察我们的模型的准确性如何随着时间的推移而提高。</li><li id="91c7" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">使用我们之前搁置的测试数据集<code class="fe nk nl nm nn b">X_test</code>再次测试我们的模型</li></ul><p id="ee72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们创建一个函数<code class="fe nk nl nm nn b">plot_metric()</code>来绘制指标。</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="6e18" class="of lw it nn b gy ov ow l ox oy">%matplotlib inline<br/>%config InlineBackend.figure_format = 'svg'<br/>def plot_metric(history, metric):<br/>    train_metrics = history.history[metric]<br/>    val_metrics = history.history['val_'+metric]<br/>    epochs = range(1, len(train_metrics) + 1)<br/>    plt.plot(epochs, train_metrics)<br/>    plt.plot(epochs, val_metrics)<br/>    plt.title('Training and validation '+ metric)<br/>    plt.xlabel("Epochs")<br/>    plt.ylabel(metric)<br/>    plt.legend(["train_"+metric, 'val_'+metric])<br/>    plt.show()</span></pre><p id="3a32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过运行<code class="fe nk nl nm nn b">plot_metric(history, 'accuracy')</code>绘制精度进度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/bdcee0ba6615d03c34806278f05a73e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Op4wLMKEpNN6CMmG8x4ksA.png"/></div></div></figure><p id="f422" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过运行<code class="fe nk nl nm nn b">plot_metric(history, 'loss')</code>绘制损失进度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/dc083e4c2db332116ebb1dffe66e3f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5gKX4swOypHOXbruVw6gpA.png"/></div></div></figure><p id="6cbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在测试集上评估模型</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="f25a" class="of lw it nn b gy ov ow l ox oy"># Evaluate the model on the test set<br/>model.<strong class="nn iu">evaluate</strong>(<strong class="nn iu">X_test</strong>, <strong class="nn iu">y_test</strong>, verbose=2)</span></pre><p id="5630" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们应该得到如下所示的输出</p><pre class="kj kk kl km gt or nn os ot aw ou bi"><span id="adfe" class="of lw it nn b gy ov ow l ox oy">30/1 - 0s - loss: 0.1192 - accuracy: 0.9667<br/>[0.11924469470977783, 0.96666664]</span></pre><h1 id="5c58" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">好了</h1><p id="2375" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">感谢阅读。</p><p id="3ff5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请在我的 Github 上查看<a class="ae ky" href="https://github.com/BindiChen/machine-learning" rel="noopener ugc nofollow" target="_blank">笔记本的源代码。</a></p><p id="142f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你对机器学习的实用方面感兴趣，请继续关注。</p><p id="25f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">参考资料:</p><ul class=""><li id="f24b" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated">[1] <a class="ae ky" href="https://arxiv.org/pdf/1502.03167v3.pdf" rel="noopener ugc nofollow" target="_blank">批量归一化:通过减少内部协变量偏移加速深度网络训练</a></li><li id="5421" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">[2]深度学习的以人为中心的视觉分析，第 7–8 页</li><li id="2d3a" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">[3] <a class="ae ky" href="https://keras.io/api/layers/normalization_layers/batch_normalization/" rel="noopener ugc nofollow" target="_blank">来自 Keras API 文档的批量标准化</a></li></ul></div></div>    
</body>
</html>