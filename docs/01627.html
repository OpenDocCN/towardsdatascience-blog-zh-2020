<html>
<head>
<title>A Data Scientists Guide to Python Modules and Packages</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 模块和包的数据科学家指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-data-scientists-guide-to-python-modules-and-packages-9193a861c26b?source=collection_archive---------14-----------------------#2020-02-14">https://towardsdatascience.com/a-data-scientists-guide-to-python-modules-and-packages-9193a861c26b?source=collection_archive---------14-----------------------#2020-02-14</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><figure class="it iu gq gs iv iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj is"><img src="../Images/bd8532a3e12d9ed1aca9e2ef24d0e6af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SQoz6oB8rbFkNkJxjsf1Og.jpeg"/></div></div><p class="jd je gk gi gj jf jg bd b be z dk translated">杰西·拉米雷斯在 Unsplash<a class="ae jh" href="https://unsplash.com/s/photos/package?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">拍摄的照片</a></p></figure><div class=""/><div class=""><h2 id="1415" class="pw-subtitle-paragraph kh jj jk bd b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dk translated">如何创建、导入和使用您自己的 python 包</h2></div><p id="60bc" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">数据科学代码通常是非常线性的。从源中提取一些数据，应用一系列转换，然后执行一些分析、计算或训练模型。然而，为了可读性、效率和可重复性，模块化和打包代码对于重用和协作是有用的。</p><p id="b085" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">当我第一次开始学习数据科学编程时，我发现很难找到创建模块和包的简单解释和教程，特别是对于数据科学项目。在这篇文章中，我将给出一个非常简单的教程，介绍如何为数据科学和机器学习项目创建和使用自己的包和模块。</p><p id="2ecd" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在整篇文章中，我将使用可以从<a class="ae jh" href="https://archive.ics.uci.edu/ml/datasets/Adult" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习库</a>下载的成人数据集。这是一个通常用于建立分类机器学习模型的数据集，其目标是预测给定的成年人每年是否会赚超过 5 万美元。</p></div><div class="ab cl lv lw hy lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="in io ip iq ir"><h2 id="8b46" class="mc md jk bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">模块的数据科学用例</h2><p id="add7" class="pw-post-body-paragraph kz la jk lb b lc mv kl le lf mw ko lh li mx lk ll lm my lo lp lq mz ls lt lu in bi translated">python 模块只是一组 python 操作，通常是函数，放在一个带有<code class="fe na nb nc nd b">.py</code>扩展名的文件中。然后，这个文件可以导入到 Jupyter 笔记本、IPython shell 或其他模块中，以便在您的项目中使用。</p><p id="ac98" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">让我们看一个例子。</p><p id="9f89" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在下面的代码中，我已经阅读了 CSV 文件，我将使用熊猫。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="1a5a" class="mc md jk nd b gz nm nn l no np">import pandas as pd</span><span id="e3e9" class="mc md jk nd b gz nq nn l no np">data = pd.read_csv('adults_data.csv')<br/>data.head()</span></pre><figure class="ne nf ng nh gu iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj nr"><img src="../Images/be362f22b72580178f36686e23146c32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vi9bFjz5F3q3xwtiGhO6_A.png"/></div></div></figure><p id="52ac" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">该数据集包含大量分类特征。如果我们打算用它来训练一个机器学习模型，我们首先需要进行一些预处理。</p><p id="0fba" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">分析完这些数据后，我决定在训练模型之前采取以下步骤对数据进行预处理。</p><ul class=""><li id="65c7" class="ns nt jk lb b lc ld lf lg li nu lm nv lq nw lu nx ny nz oa bi translated">一次性编码下列栏目:工作类，婚姻状况，关系，种族和性别。</li><li id="3cb1" class="ns nt jk lb b lc ob lf oc li od lm oe lq of lu nx ny nz oa bi translated">取最常出现的值，将剩余的值分组为“其他”，并对结果特征进行一次性编码。这将需要为以下各列执行，因为它们具有大量的唯一值:教育、职业、本国。</li><li id="57ee" class="ns nt jk lb b lc ob lf oc li od lm oe lq of lu nx ny nz oa bi translated">缩放剩余的数值。</li></ul><p id="29f7" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我们需要编写来执行这些任务的代码将会非常大。此外，这些都是我们可能希望多次执行的任务。为了使我们的代码更具可读性，并且能够轻松地重用它，我们可以将一系列函数编写到一个单独的文件中，该文件可以导入到我们的笔记本中使用——一个模块。</p><h2 id="e647" class="mc md jk bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">编写模块</h2><p id="a509" class="pw-post-body-paragraph kz la jk lb b lc mv kl le lf mw ko lh li mx lk ll lm my lo lp lq mz ls lt lu in bi translated">要创建一个模块，你需要首先创建一个新的空白文本文件，并用扩展名<code class="fe na nb nc nd b">.py</code>保存。你可以使用一个普通的文本编辑器，但是很多人使用 IDE(集成开发环境)。IDE 为编写代码提供了许多额外的功能，包括编译代码、调试和与 Github 集成的工具。有许多不同类型的 IDE 可供使用，值得尝试几种，以找到最适合您的一种。我个人更喜欢<a class="ae jh" href="https://www.jetbrains.com/pycharm/" rel="noopener ugc nofollow" target="_blank"> PyCharm </a>，所以我将在示例中使用它。</p><p id="c7a1" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">为了开始编写 python 模块，我将创建一个新的 python 文件。</p><figure class="ne nf ng nh gu iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj og"><img src="../Images/c958f0dc6bbe00ce90e82fb307f3f93d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Q0eUpDJ9iylJHu0_0JpWQ.png"/></div></div></figure><p id="5595" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我将它命名为<code class="fe na nb nc nd b">preprocessing.py</code>。</p><figure class="ne nf ng nh gu iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj oh"><img src="../Images/61775f0a7a7b42d78e5ba50c28bf193c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cJlOACHGDCnfuzVqCSxhBQ.png"/></div></div></figure><p id="88ef" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">让我们在这个文件中编写我们的第一个预处理函数，并在 Jupyter 笔记本中测试导入和使用它。</p><p id="613e" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我在<code class="fe na nb nc nd b">preprocessing.py</code>文件的顶部写了下面的代码。给代码添加注释是一个很好的做法，这样可以使代码更具可读性。我在下面的代码中添加了一些注释。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="0b1b" class="mc md jk nd b gz nm nn l no np">def one_hot_encoder(df, column_list):<br/>    <em class="oi">"""Takes in a dataframe and a list of columns<br/>    for pre-processing via one hot encoding"""<br/>    </em>df_to_encode = df[column_list]<br/>    df = pd.get_dummies(df_to_encode)<br/>    return df</span></pre><p id="0603" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">要将这个模块导入到 Jupyter 笔记本中，我们只需编写以下代码。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="7e52" class="mc md jk nd b gz nm nn l no np">import preprocessing as pr</span></pre><p id="6fa1" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">IPython 有一个方便的神奇扩展，叫做<code class="fe na nb nc nd b">autoreload</code>。如果您在导入之前添加了以下代码，那么如果您对模块文件进行了任何更改，这些更改将自动反映在笔记本中。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="1b76" class="mc md jk nd b gz nm nn l no np">%load_ext autoreload<br/>%autoreload 2</span><span id="2fbe" class="mc md jk nd b gz nq nn l no np">import preprocessing as pr</span></pre><p id="57fb" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">让我们测试使用它来预处理一些数据。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="4c29" class="mc md jk nd b gz nm nn l no np">cols = ['workclass', 'marital-status', 'relationship', 'race', 'gender']</span><span id="9e96" class="mc md jk nd b gz nq nn l no np">one_hot_df = pr.one_hot_encoder(data, cols)</span></pre><figure class="ne nf ng nh gu iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj oj"><img src="../Images/492fd2a974a4b2313a8da1989c488eba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ppMI0fHXkeubbJ_T5Mj-3w.png"/></div></div></figure><p id="4b4b" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">现在我们将剩余的预处理函数添加到我们的<code class="fe na nb nc nd b">preprocessing.py</code>文件中。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="cb99" class="mc md jk nd b gz nm nn l no np">def one_hot_encoder(df, column_list):<br/>    <em class="oi">"""Takes in a dataframe and a list of columns<br/>    for pre-processing via one hot encoding returns<br/>    a dataframe of one hot encoded values"""<br/>    </em>df_to_encode = df[column_list]<br/>    df = pd.get_dummies(df_to_encode)<br/>    return df<br/><br/>def reduce_uniques(df, column_threshold_dict):<br/>    <em class="oi">"""Takes in a dataframe and a dictionary consisting<br/>    of column name : value count threshold returns the original<br/>    dataframe"""<br/>    </em>for key, value in column_threshold_dict.items():<br/>            counts = df[key].value_counts()<br/>            others = set(counts[counts &lt; value].index)<br/>            df[key] = df[key].replace(list(others), 'Others')<br/>            return df<br/><br/>def scale_data(df, column_list):<br/>    <em class="oi">"""Takes in a dataframe and a list of column names to transform<br/>     returns a dataframe of scaled values"""<br/>    </em>df_to_scale = df[column_list]<br/>    x = df_to_scale.values<br/>    min_max_scaler = preprocessing.MinMaxScaler()<br/>    x_scaled = min_max_scaler.fit_transform(x)<br/>    df_to_scale = pd.DataFrame(x_scaled, columns=df_to_scale.columns)<br/>    return df_to_scale</span></pre><p id="671e" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">如果我们回到笔记本电脑，我们可以使用所有这些功能来转换数据。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="25e8" class="mc md jk nd b gz nm nn l no np">import pandas as pd<br/>from sklearn import preprocessing</span><span id="ff99" class="mc md jk nd b gz nq nn l no np">%load_ext autoreload<br/>%autoreload 2</span><span id="864d" class="mc md jk nd b gz nq nn l no np">import preprocessing as pr</span><span id="92dc" class="mc md jk nd b gz nq nn l no np">one_hot_list = ['workclass', 'marital-status', 'relationship', 'race', 'gender']<br/>reduce_uniques_dict = {'education' : 1000,'occupation' : 3000, 'native-country' : 100}<br/>scale_data_list = data.select_dtypes(include=['int64', 'float64']).columns</span><span id="4cf2" class="mc md jk nd b gz nq nn l no np">one_hot_enc_df = pr.one_hot_encoder(data, one_hot_list)<br/>reduce_uniques_df = pr.reduce_uniques(data, reduce_uniques_dict)<br/>reduce_uniques_df = pr.one_hot_encoder(data, reduce_uniques_dict.keys())<br/>scale_data_df = pr.scale_data(data, scale_data_list)</span><span id="f1b8" class="mc md jk nd b gz nq nn l no np">final_data = pd.concat([one_hot_enc_df, reduce_uniques_df, scale_data_df], axis=1)</span><span id="f449" class="mc md jk nd b gz nq nn l no np">final_data.dtypes</span></pre><p id="400d" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我们现在有了一个完全数值化的数据集，它适合于训练一个机器学习模型。</p><figure class="ne nf ng nh gu iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj ok"><img src="../Images/d103a7a5f00ea12aa6c46a555556a12d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DvCUqcUMQlC4vEb5_ThmTQ.png"/></div></div><p class="jd je gk gi gj jf jg bd b be z dk translated">已转换列的快照</p></figure><h2 id="e766" class="mc md jk bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">包装</h2><p id="c069" class="pw-post-body-paragraph kz la jk lb b lc mv kl le lf mw ko lh li mx lk ll lm my lo lp lq mz ls lt lu in bi translated">在进行机器学习项目时，创建几个相关的模块并将它们打包以便一起安装和使用通常是理想的或者有时是必要的。</p><p id="fc36" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">举个例子，在我的工作中，我目前正在使用一个名为<a class="ae jh" href="https://cloud.google.com/ai-platform/" rel="noopener ugc nofollow" target="_blank"> AI 平台</a>的机器学习模型的 Google Cloud 部署解决方案。该工具要求您将机器学习模型中的预处理、训练和预测步骤打包上传并安装在平台上，以部署最终模型。</p><p id="c39e" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">python 包是包含模块、文件和子目录的目录。该目录需要包含一个名为<code class="fe na nb nc nd b">__init__.py</code>的文件。该文件表明它所在的目录应该被视为一个包，并指定应该导入的模块和函数。</p><p id="9b0c" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">我们将为预处理管道中的所有步骤创建一个包。__init__ 的内容。py 文件如下。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="9d1b" class="mc md jk nd b gz nm nn l no np">from .preprocessing import one_hot_encoder<br/>from .preprocessing import reduce_uniques<br/>from .preprocessing import scale_data<br/>from .makedata import preprocess_data</span></pre><p id="86bd" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">同一个包中的模块可以导入到另一个模块中使用。我们将向我们的目录添加另一个名为 makedata.py 的模块，该模块使用 preprocessing.py 模块来执行数据转换，然后将最终数据集导出为 CSV 文件供以后使用。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="e326" class="mc md jk nd b gz nm nn l no np">import preprocessing as pr<br/>import pandas as pd<br/><br/>def preprocess_data(df, one_hot_list, reduce_uniques_dict, scale_data_list, output_filename):<br/>    one_hot_enc_df = pr.one_hot_encoder(data, one_hot_list)<br/>    reduce_uniques_df = pr.reduce_uniques(data, reduce_uniques_dict)<br/>    reduce_uniques_df = pr.one_hot_encoder(data, reduce_uniques_dict.keys())<br/>    scale_data_df = pr.scale_data(data, scale_data_list)<br/>    final_data = pd.concat([one_hot_enc_df, reduce_uniques_df, scale_data_df], axis=1)<br/>    final_data.to_csv(output_filename)</span></pre><p id="8aaf" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">新目录现在看起来像这样。</p><figure class="ne nf ng nh gu iw gi gj paragraph-image"><div class="gi gj ol"><img src="../Images/1c54d5238e49243fb039cb5fc69b4b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*jp2ZIK9B6eTFUqpquBk8Dg.png"/></div></figure><p id="8294" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">现在我们可以回到 Jupyter 笔记本，使用这个包来执行所有的预处理。我们的代码现在非常简单明了。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="997d" class="mc md jk nd b gz nm nn l no np">import pandas as pd</span><span id="bb5b" class="mc md jk nd b gz nq nn l no np">%load_ext autoreload<br/>%autoreload 2<br/>import preprocessing as pr</span><span id="355c" class="mc md jk nd b gz nq nn l no np">data = pd.read_csv('adults_data.csv')</span><span id="5cde" class="mc md jk nd b gz nq nn l no np">one_hot_list = ['workclass', 'marital-status', 'relationship', 'race', 'gender']<br/>reduce_uniques_dict = {'education' : 1000,'occupation' : 3000, 'native-country' : 100}<br/>scale_data_list = data.select_dtypes(include=['int64', 'float64']).columns</span><span id="981b" class="mc md jk nd b gz nq nn l no np">pr.preprocess_data(data, one_hot_list, reduce_uniques_dict,scale_data_list, 'final_data.csv')</span></pre><p id="bc07" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在我们当前的工作目录中，现在将有一个名为<code class="fe na nb nc nd b">final_data.csv</code>的新 CSV 文件，它包含预处理过的数据集。让我们回过头来检查几行，以确保我们的包按预期执行。</p><pre class="ne nf ng nh gu ni nd nj nk aw nl bi"><span id="ba08" class="mc md jk nd b gz nm nn l no np">data_ = pd.read_csv('final_data.csv')<br/>data.head()</span></pre><figure class="ne nf ng nh gu iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj om"><img src="../Images/4a30dbc57bcf147bf2ba9fa87a3a8a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*so8_v3QJfxhGxRpzFQGGwg.png"/></div></div></figure></div><div class="ab cl lv lw hy lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="in io ip iq ir"><p id="0829" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">在这篇文章中，我已经说明了在数据科学和机器学习项目中使用模块和包是如何提高代码的可读性和可重复性的。在我寻找这些过程的简单解释的过程中，我发现这个<a class="ae jh" href="https://timothybramlett.com/How_to_create_a_Python_Package_with___init__py.html" rel="noopener ugc nofollow" target="_blank">博客帖子</a>非常有用，并且很好地浏览了<a class="ae jh" href="https://www.pythonlikeyoumeanit.com/Module5_OddsAndEnds/Modules_and_Packages.html" rel="noopener ugc nofollow" target="_blank"> python 如你所愿</a>项目。</p><p id="08af" class="pw-post-body-paragraph kz la jk lb b lc ld kl le lf lg ko lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">感谢阅读！</p></div></div>    
</body>
</html>