<html>
<head>
<title>What is Boosting in Machine Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的Boosting是什么？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-boosting-in-machine-learning-2244aa196682?source=collection_archive---------13-----------------------#2020-06-08">https://towardsdatascience.com/what-is-boosting-in-machine-learning-2244aa196682?source=collection_archive---------13-----------------------#2020-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fd62" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">机器学习模型的超级英雄</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/79197c866855f33fd38b52a6f9eb99ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ADMzE1EpkDs0xGGv1gMg2g.jpeg"/></div></div></figure><h1 id="af19" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">提升机器学习模型简介</h1><p id="610e" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">在本帖中，我们将看到对Boosting算法的简单而直观的解释:它们是什么，为什么它们如此强大，一些不同的类型，以及它们如何被训练和用于进行预测。</p><p id="1f2a" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><em class="mi">我们将避开所有沉重的数学负担，去寻找一个清晰、简单、但深入易懂的解释。然而，额外的材料和资源将留在文章的最后，以防你想更深入地研究这个话题。</em></p><p id="66a0" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><em class="mi">在我们开始之前，这里有一些额外的资源，可以让你的机器学习生涯一飞冲天</em></p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="15ef" class="mt kv it mp b gy mu mv l mw mx"><em class="mi">Awesome Machine Learning Resources:- For </em><strong class="mp iu"><em class="mi">learning resources</em></strong><em class="mi"> go to </em><a class="ae my" href="https://howtolearnmachinelearning.com/books/machine-learning-books/" rel="noopener ugc nofollow" target="_blank"><strong class="mp iu"><em class="mi">How to Learn Machine Learning</em></strong></a><em class="mi">! </em></span><span id="3def" class="mt kv it mp b gy mz mv l mw mx"><em class="mi">- For </em><strong class="mp iu"><em class="mi">professional</em></strong><em class="mi"> </em><strong class="mp iu"><em class="mi">resources</em></strong><em class="mi"> (jobs, events, skill tests) go to </em><a class="ae my" href="https://aigents.co/" rel="noopener ugc nofollow" target="_blank"><strong class="mp iu"><em class="mi">AIgents.co <br/>— A career community for Data Scientists &amp; Machine Learning Engineers</em></strong></a></span></pre><div class="na nb gp gr nc nd"><a href="https://z-ai.medium.com/subscribe" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd iu gy z fp ni fr fs nj fu fw is bi translated">订阅我的专属列表！</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">订阅我的专属列表！获取您喜欢的所有新鲜文章&lt;3! By signing up, you will create a Medium…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">z-ai.medium.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr ks nd"/></div></div></a></div><h1 id="ee54" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">What is Boosting in Machine Learning?</h1><p id="6db7" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated"><strong class="lo iu">传统上，</strong>构建一个机器学习应用程序包括采用一个<strong class="lo iu">单个学习者</strong>，如逻辑回归器、决策树、支持向量机或人工神经网络，向它提供数据，并通过这些数据教它执行某项任务。</p><p id="8ff6" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">然后<strong class="lo iu"> <em class="mi">集成方法</em> </strong>诞生了，它涉及到使用<strong class="lo iu">多个学习器</strong>来单独增强其中任何一个学习器的性能。这些方法可以被描述为使用一组<strong class="lo iu">弱学习者<em class="mi"/></strong>(<em class="mi">那些平均成绩仅比随机模型</em>稍好的人)在一起的技术，以便<strong class="lo iu">创建一个更强的、聚合的学习者</strong>。</p><p id="599e" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">一般来说，集成方法是通过<strong class="lo iu">对个体决策树</strong>的变体进行分组来构建的，我们将在后面看到。</p><p id="6547" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><strong class="lo iu"> <em class="mi">助推模式</em> </strong>属于这种<strong class="lo iu"> <em class="mi">合奏方式的家族。</em> </strong></p><p id="0956" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">Boosting最初被命名为<strong class="lo iu"> <em class="mi">假设Boosting </em> </strong>，它的思想是对用于训练我们弱学习者团队的数据进行过滤或加权，以便每个新学习者给予更多的权重，或者只使用先前学习者分类较差的观察值进行训练。</p><p id="bff4" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">通过这样做<strong class="lo iu">，我们的模型<strong class="lo iu">团队</strong>学会了对各种数据做出准确的预测</strong>，而不仅仅是对最普通或最容易的观察。此外，如果其中一个单独的模型非常不擅长根据某种观察结果做出预测，这也没关系，因为其他N-1个模型很可能会弥补这一点。</p><p id="d142" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">增强<strong class="lo iu">不应与<em class="mi">打包</em> </strong>混淆，后者是集成方法的另一个主要家族:在打包中，使用随机性并行训练弱学习器，而在增强中，<strong class="lo iu">顺序训练学习器</strong>，以便能够执行上一段中描述的数据加权/过滤任务。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/af40a33a75d06f375c192b801a67da20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w02bXyuPzQKXI928OBf20w.png"/></div></div><p class="nt nu gj gh gi nv nw bd b be z dk translated">装袋与增压</p></figure><p id="7f39" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">正如我们从前面的图像中可以看到的，在提升模型中的<strong class="lo iu">可以具有不同的重要性</strong>或权重(用学习者的不同大小来表示)，而在打包中的<strong class="lo iu">所有学习者在最终决策中具有相同的权重</strong>。</p><p id="29c4" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">此外，<strong class="lo iu">在boosting中，数据集被加权</strong>(由数据点的不同大小表示)，从而被分类器<em class="mi"> n </em>错误分类的观察值在模型<em class="mi"> n + 1 </em>的训练中被赋予更大的重要性，而<strong class="lo iu">在装袋中，训练样本从整个群体中随机选取</strong>。</p><p id="ea56" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">既然我们已经了解了什么是boosting，以及它与bagging的不同之处，<strong class="lo iu">让我们来看看它为什么如此有效！</strong></p><h1 id="ee42" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">为什么助推这么有效？</h1><p id="f1f2" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">总的来说，<strong class="lo iu">集成方法减少了我们机器学习模型的偏差和方差</strong>。如果你不知道什么是偏差和方差，不要担心，我让你看完了这篇文章。</p><p id="4a64" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">集成方法通过消除对单个估计器的依赖来帮助<strong class="lo iu">提高机器学习模型<strong class="lo iu">的稳定性和性能</strong>。这可以用一个装袋的例子看得很清楚:<em class="mi">随机森林。</em></strong></p><p id="1e72" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><strong class="lo iu">随机森林顾名思义就是由一组个体</strong> <a class="ae my" rel="noopener" target="_blank" href="/decision-trees-explained-3ec41632ceb6"> <strong class="lo iu">决策树</strong> </a> <strong class="lo iu">组成一个森林</strong>。这些单独的树很容易过量输入数据，尽管它们是非常简单和直观的模型，但它们不太擅长预测。</p><p id="78b7" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">然而，<strong class="lo iu">如果我们使用许多树，这些问题就会消失</strong>，因为每棵树都使用不同的数据样本和不同的特征进行训练，从而产生一个整体上更强大、更稳健的模型。</p><p id="2fa8" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><strong class="lo iu">对于boosting，其工作方式与</strong>相同，但在bagging中，每个模型都是独立训练的，而在boosting中，N个模型是顺序训练的，考虑到前一个模型的成功，并增加前一个模型误差最大的数据的权重，这使得<strong class="lo iu">后续模型专注于最困难的数据观察。</strong></p><p id="7e7b" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">此外，在加权训练样本上表现最好的的<strong class="lo iu">个体模型将变得更强(获得更高的权重)，因此对最终预测具有更大的影响。</strong></p><p id="fbd9" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">好吧，这听起来很可爱，但是这些模特实际上是如何训练的？</p><h1 id="c03d" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">助推模型是如何训练出来的？</h1><p id="6685" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">训练过程取决于我们使用的增强算法(Adaboost vs LigthGBM vs XGBoost…)，但通常遵循以下模式:</p><ol class=""><li id="f252" class="nx ny it lo b lp mj ls mk lv nz lz oa md ob mh oc od oe of bi translated"><strong class="lo iu">所有数据样本都以相同的权重开始。这些样本用于训练一个单独的模型(比如一个决策树)。</strong></li><li id="1988" class="nx ny it lo b lp og ls oh lv oi lz oj md ok mh oc od oe of bi translated">计算每个样本的预测误差，增加具有较大误差的那些样本的<strong class="lo iu">权重，以使它们对后续个体模型的训练更重要。</strong></li><li id="d371" class="nx ny it lo b lp og ls oh lv oi lz oj md ok mh oc od oe of bi translated">根据这个<strong class="lo iu">个体模型</strong>在预测上的表现，它<strong class="lo iu">被赋予一个重要性/权重或发言权</strong>。一个输出非常好的预测的模型将在最终决策中有很大的发言权。</li><li id="a21c" class="nx ny it lo b lp og ls oh lv oi lz oj md ok mh oc od oe of bi translated"><strong class="lo iu">加权数据传递给后验模型，重复</strong>和2)和3)。</li><li id="ee0b" class="nx ny it lo b lp og ls oh lv oi lz oj md ok mh oc od oe of bi translated">编号4)被重复，直到我们已经达到一定数量的模型，或者直到误差低于一定阈值。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/1a73ea60172027026c80b758a0f3d21f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IF4ZCVNrn8u4qY1pucc0IQ.png"/></div></div><p class="nt nu gj gh gi nv nw bd b be z dk translated">训练助推模型</p></figure><p id="c05a" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">在某些情况下，boosting模型使用针对每个学习者的<strong class="lo iu">特定固定权重</strong>(称为学习率)进行训练，而不是给每个样本一个单独的权重，模型被训练为试图预测样本的先前预测和目标变量的真实值之间的差异。这种差异就是我们所说的<strong class="lo iu"><em class="mi"/></strong>。</p><p id="a30e" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">稍后，当我们看到不同种类的助推模型时，我们将更多地讨论这一点，然而，家庭的主要特征仍然存在:<strong class="lo iu">对许多个体学习者进行顺序训练，以创建更强大的聚合模型。</strong></p><p id="c533" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">厉害！现在我们知道了如何训练Boosting模型，让我们看看如何使用它们对新数据进行预测。</p><h1 id="08a9" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">增压模型如何进行预测？</h1><p id="6178" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">助推模型根据新数据做出预测的方式非常简单。当我们获得一个具有其特征的新观察结果时，它会通过每个单独的模型，让<strong class="lo iu">每个模型做出自己的预测</strong>。</p><p id="d430" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">然后，考虑到这些模型中每一个的权重，所有这些<strong class="lo iu">预测被缩放和组合</strong>，并给出最终的全局预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/6ac908dd3b9a59d7d2e451a11cd77590.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B1HoaEnlsYIf5AWW4KkeWg.png"/></div></div><p class="nt nu gj gh gi nv nw bd b be z dk translated">使用助推模型进行预测</p></figure><p id="644b" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">最后，让我们探索一下<strong class="lo iu">最常见的增压模型的特征。</strong></p><h1 id="4309" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">不同的增压模式</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/4d1aa004bf775b936329487d838416aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*kIwMI64Q7dFi5ZBOyiKPBA.png"/></div></figure><p id="e7f2" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><strong class="lo iu"><em class="mi">AdaBoost</em></strong><em class="mi">的简称，</em> AdaBoost通过前面描述的顺序训练、预测和更新误分类样本和相应弱模型的权重的精确过程来工作。</p><p id="2013" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">它主要与<strong class="lo iu"> <em class="mi">决策树树桩</em> </strong>一起使用:只有一个根节点和两个叶节点的决策树，其中只评估数据的一个特征。正如我们所见，通过仅考虑我们数据的一个特征来进行预测，<strong class="lo iu">每个树桩都是一个非常非常弱的模型</strong>。然而，通过组合它们中的许多，可以建立非常鲁棒和精确的集合模型。</p><p id="b9c9" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">如果你想了解更多关于AdaBoost的信息，可以看看下面StatQuest制作的<a class="ae my" href="https://www.youtube.com/watch?v=LsK-xG1cLYA" rel="noopener ugc nofollow" target="_blank"> <strong class="lo iu">视频。</strong> </a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/af0f34e3ad788f95de2fca13eb355912.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cU42G0B2q5WLyVt5-risuA.png"/></div></div></figure><p id="230c" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">与AdaBoost非常相似，<strong class="lo iu"> <em class="mi">梯度提升机器</em> </strong>依次训练弱学习器，添加越来越多的估计器，但是<strong class="lo iu">不是调整数据的权重，而是试图预测先前估计器产生的残差。</strong></p><p id="2de6" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">因此，我们不再有样本权重，所有弱模型都有相同的发言权或重要性。同样，大多数时候，决策树被用作基础预测器，然而，它们不是树桩，而是更大的固定大小的树。GBM使用一个学习率，并朝着更好的结果迈出一小步，在概念上类似于梯度下降法。</p><p id="e2e9" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">同样，如果你想深入了解，可以查看StatQuest 的<strong class="lo iu"> </strong> <a class="ae my" href="https://www.youtube.com/watch?v=3CC4N4z3GJc" rel="noopener ugc nofollow" target="_blank"> <strong class="lo iu">视频。</strong></a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/96d76b8a53d3499db5755e3cbe8beae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*oD21z3WlP4vXX_FyydJPeQ.png"/></div></figure><p id="4d3a" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">是<strong class="lo iu"> <em class="mi">极端梯度提升</em> </strong>的缩写，就像在梯度提升中一样，我们使我们的树适合先前树预测的残差，然而，XGBoost没有使用传统的、固定大小的决策树，而是使用一种不同的树:<strong class="lo iu"> <em class="mi"> XGBoost树</em> </strong>我们可以称它们为。</p><p id="5126" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">它通过计算结束于leave节点的观察值之间的相似性得分来构建这些树<strong class="lo iu">。此外，XGBoost允许正则化，减少我们的单个树和整个集合模型可能的过度拟合。</strong></p><p id="f3b0" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">最后，<strong class="lo iu"> XGBoost被优化</strong>以推动提升树算法的计算资源的极限，使其在时间和计算方面成为非常<strong class="lo iu">高性能</strong>和<strong class="lo iu">快速的算法</strong>。</p><p id="d12b" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">可以看下面的视频<a class="ae my" href="https://www.youtube.com/watch?v=OtD8wVaFm6E" rel="noopener ugc nofollow" target="_blank"> <strong class="lo iu"> <em class="mi"> XGBoost Part 1:回归</em> </strong> </a>，更深入的了解XGBoost到底是怎么回事。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/16907f3d8ec10c2ea9f4fc6eb166c054.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*q5IbiMBtQM4klMHdUrGR9A.png"/></div></figure><p id="6b36" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><strong class="lo iu">光梯度推进机、</strong>简称<strong class="lo iu"> <em class="mi"> LigthGBM </em> </strong>、<strong class="lo iu"> </strong>是梯度推进算法改进的又一个转机。它没有像XGBoost中那样对决策树使用逐层增长策略，而是使用<strong class="lo iu">逐叶增长策略</strong> y，这使它有机会比其他基于树的算法实现更高的每跳错误减少率。此外，与XGBoost相比，LigthGBM通常更快，特别是在大型数据集上。</p><p id="0322" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">你可以在它的<a class="ae my" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <strong class="lo iu">官方docu页面了解更多。</strong> </a></p><div class="na nb gp gr nc nd"><a href="https://z-ai.medium.com/subscribe" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd iu gy z fp ni fr fs nj fu fw is bi translated">订阅我的专属列表！</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">订阅我的专属列表！获得所有你喜欢的新鲜文章&lt;3! By signing up, you will create a Medium…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">z-ai.medium.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr ks nd"/></div></div></a></div><h1 id="f176" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">Conclusion and additional Resources</h1><p id="864a" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">That is it! As always, I hope you<strong class="lo iu">享受帖子</strong>，我设法帮助你理解什么是助推，它是如何工作的，以及为什么它如此强大。</p><p id="489e" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated">如果您想了解有关该主题的更多信息，您可以在这里找到一些附加资源:</p><ul class=""><li id="3ce3" class="nx ny it lo b lp mj ls mk lv nz lz oa md ob mh or od oe of bi translated"><a class="ae my" href="https://www.cis.upenn.edu/~mkearns/papers/boostnote.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mi">关于假说助推的思考，迈克尔·卡恩斯。</em> </a></li><li id="71f2" class="nx ny it lo b lp og ls oh lv oi lz oj md ok mh or od oe of bi translated"><a class="ae my" href="http://gradient-boosting-algorithm-machine-learning/" rel="noopener ugc nofollow" target="_blank"> <em class="mi">关于MachineLearningMastery的渐变提升的温和介绍。</em> </a></li><li id="ca28" class="nx ny it lo b lp og ls oh lv oi lz oj md ok mh or od oe of bi translated"><a class="ae my" href="https://pdf.sciencedirectassets.com/272574/1-s2.0-S0022000000X00384/1-s2.0-S002200009791504X/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEFsaCXVzLWVhc3QtMSJHMEUCIGkkd3d0DRMaSvR4%2F5C6dx5z082G5avFo4f2cbH1tuZbAiEAzm8gSH5KVmbTJ%2Bd%2BRUO1LtPR4BuISathYMpThTOERw8qvQMIxP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARADGgwwNTkwMDM1NDY4NjUiDDZlAg5ielOpeAqGkiqRAwA3ivmRpa64tsFGOi17WCztqopHaujNkkWKWrso6NIH2%2BwMvkqVc8VqTZE96yrr6QrxAKGrsm1FoKOEj6IZscywR8OtoFKVMWR385K98PS7g7HJZCp7IKRybj2nAsb1bn7vhDLmFDYLBJClGX6Kjay5GVugtmhfxGARVHUB9zpNvIA7XUr7UHjYMawL3m543%2FHx2jNtUgQaeu%2F6Yxd4cC20ESRFexyAtWU7RTQM00e%2BB%2BAf6yGT9CEPHFa7gTizAAzdyuQqFVlDOfaMKwwtY4VcRKW%2FKPnqbo612DIuJBi30zHvdS%2BRgvp6qanFhmiojjqV5P40ebivsmDEfu%2FP8Tg%2FJcdCqNwcIRZMjQUC%2BPaVVPp3hx8QXSLJMGJvutqy4pYYVsB6%2FsFFHlI7KN16R6v9ISYLgS%2BokMoz8KDM8Yr%2FTaggqC4z4irOxpyHE7JOtJqPRKwkIb7UNU%2F1eBbF4TmrslIQGlC5kc7EmvA%2B7HG2HqYFLbc5FgcVV4YXNfoiMbEpm6Gw5ZaNFvF0UlosIJAmMI3I7%2FYFOusBuuZWGzOk6ar5bhOWLtV6IOFuXrYVgqMSy1Xz7zhw0TiyGJs9LAC3O8NBXTodzE8Psf4qithLsoCmc4Q3VDZTd5TXfOtVY8cT8XZ9z68nzpB6DpnYAzZaoyIsO11LCjcMnCTNJ6bZVM8DddV5Y72P%2Bb4FlVnskLTGNQRRfSb6FTQ7Iltdi987X7NT%2BZ7TfL%2BDPRrJb4%2FBbu%2BRMOnEOWKcg%2BGUsFlix98UfTc0vIj2jwmn3wtZZxdhVsDksOgOgtZtRNMNGHq1zhOvFRktFq0QmuAvy9%2FeBec2qznGSMV0HW%2BZKJS%2FQHBLbeVQGw%3D%3D&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20200606T184755Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTYQGSOLGFP%2F20200606%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=db5248ef0c47e23281878cb2a57dd2015555e7ca4f7fd6f38699494fb32bf5d2&amp;hash=bd1980e97c94e6d34df94e21dc1440e18ddaea26a3dbdd850504e7a6fe8ce9bc&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S002200009791504X&amp;tid=spdf-685376e6-64ba-4411-928e-eebd7815a13b&amp;sid=6c4a4f885c56b345609bb3e69ac26d325129gxrqb&amp;type=client" rel="noopener ugc nofollow" target="_blank"> <em class="mi">在线学习的决策理论推广及其在Boosting </em> </a>中的应用</li><li id="d0e1" class="nx ny it lo b lp og ls oh lv oi lz oj md ok mh or od oe of bi translated"><a class="ae my" href="https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/" rel="noopener ugc nofollow" target="_blank"><em class="mi">quanta re:升压vs装袋</em> </a></li><li id="e724" class="nx ny it lo b lp og ls oh lv oi lz oj md ok mh or od oe of bi translated"><a class="ae my" href="https://howtolearnmachinelearning.com/books/machine-learning-books/" rel="noopener ugc nofollow" target="_blank"> <em class="mi">最好的机器学习书籍回顾</em> </a></li></ul><p id="4bad" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><em class="mi">如果你喜欢这篇文章，请随时在@jaimezorno </em>   <em class="mi">上关注我。还有，你可以看看我其他关于数据科学和机器学习的帖子</em> <a class="ae my" href="https://medium.com/@jaimezornoza?source=post_page---------------------------" rel="noopener"> <em class="mi">这里</em> </a> <em class="mi">。好好读！</em></p><p id="54c8" class="pw-post-body-paragraph lm ln it lo b lp mj ju lr ls mk jx lu lv ml lx ly lz mm mb mc md mn mf mg mh im bi translated"><em class="mi">如果你想了解更多关于机器学习和人工智能的知识</em> <a class="ae my" href="https://medium.com/@jaimezornoza" rel="noopener"> <strong class="lo iu"> <em class="mi">关注我上媒</em> </strong> </a> <em class="mi">，敬请关注我的下期帖子！另外，你可以查看</em> <a class="ae my" href="https://howtolearnmachinelearning.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lo iu"> <em class="mi">这个资源库</em> </strong> </a> <em class="mi">来获得更多关于机器学习和人工智能的资源！</em></p><ul class=""><li id="9c1d" class="nx ny it lo b lp mj ls mk lv nz lz oa md ob mh or od oe of bi translated">封面图片来自<a class="ae my" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"><strong class="lo iu"><em class="mi"/></strong></a>。</li><li id="8d41" class="nx ny it lo b lp og ls oh lv oi lz oj md ok mh or od oe of bi translated">所有其他图像都是自己制作的。</li></ul></div></div>    
</body>
</html>