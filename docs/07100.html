<html>
<head>
<title>Deploying models to production with TensorFlow model server</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TensorFlow模型服务器将模型部署到生产环境中</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploying-models-to-production-with-tensorflow-model-server-225a81859031?source=collection_archive---------31-----------------------#2020-05-31">https://towardsdatascience.com/deploying-models-to-production-with-tensorflow-model-server-225a81859031?source=collection_archive---------31-----------------------#2020-05-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/41bb196c69d982048e3f20c18dbf0429.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lA1buzY2NM6NXQhHXx25Rg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:tensorflow.org</p></figure><p id="c60f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">模型创建无疑是人工智能应用的一个重要部分，但在训练后知道什么也是非常重要的。我将展示如何通过HTTP和HTTPS服务TensorFlow模型，并使用TF Model Server轻松完成模型版本控制或模型服务器维护等工作。您还将看到为此所需的步骤以及您应该遵循的流程。我们还将了解Kubernetes和GKE，以自动调整您的部署。</p><p id="c382" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇博文中演示所用的所有代码和一些额外的例子都可以在这个GitHub repo-上找到</p><div class="le lf gp gr lg lh"><a href="https://github.com/Rishit-dagli/GDG-Ahmedabad-2020" rel="noopener  ugc nofollow" target="_blank"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd iu gy z fp lm fr fs ln fu fw is bi translated">里希特-达格里/GDG-艾哈迈达巴德-2020</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">我在谷歌开发小组艾哈迈达巴德的会议是关于用TensorFlow模型服务器将模型部署到生产中，30…</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">github.com</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv jz lh"/></div></div></a></div><p id="744f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我也在<a class="ae kf" href="https://www.meetup.com/GDG-Ahmedabad" rel="noopener ugc nofollow" target="_blank"> GDG(谷歌开发者组织)艾哈迈达巴德</a>发表过关于这个的演讲，在这里找到录音版本-</p><figure class="lw lx ly lz gt ju"><div class="bz fp l di"><div class="ma mb l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">我演讲的录音版本</p></figure><p id="93f4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里有同样的幻灯片-【bit.ly/tf-server-deck T4】</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><p id="a8c7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望你已经和一些深度学习模型合作过，并且自己也做了一些模型，也可以和Keras一起做。</p><h1 id="756c" class="mj mk it bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">部署过程背后的动机</h1><figure class="lw lx ly lz gt ju gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/060bc14fb4cd81088327fde03ae16bc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/0*hALERWCftjdnBde-"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:me.me</p></figure><p id="ea20" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是对理想场景的非常准确的描述，您的模型在测试或开发环境中工作良好，当您将其应用到现实世界或生产环境中时，问题就开始出现，事情就开始失败。您还需要确保您的模型一直在运行，并且您的用户有一个与模型交互的简单方法。它还应该在所有平台上运行良好，无论是web、Android、IoS还是嵌入式系统。您需要一个有弹性的管道来为您的模型服务，并且需要一个有效的方法来传递数据。这些只是生产和开发之间的一些差异。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="23cd" class="mj mk it bd ml mm ni mo mp mq nj ms mt mu nk mw mx my nl na nb nc nm ne nf ng bi translated">需要处理哪些事情？</h1><ul class=""><li id="af15" class="nn no it ki b kj np kn nq kr nr kv ns kz nt ld nu nv nw nx bi translated">打包模型</li></ul><p id="e514" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，首先您需要获得模型，并以一种您可以在生产环境中使用的方式对其进行打包。理想情况下，您不会将相同格式的Jupyter笔记本投入生产，如果您愿意，您可以这样做，但通常不建议这样做。</p><ul class=""><li id="f581" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">在云托管服务器上发布模型</li></ul><p id="b18f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，您会希望将您的模型托管在某个云托管的服务器上，这样您就可以为您的用户提供服务，在他们需要模型的任何时候为他们提供模型。</p><ul class=""><li id="f8fe" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">维护服务器</li></ul><p id="fded" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">既然您已经将模型发布到了云托管的服务器上，那么您还需要维护它。当我说你需要维护服务器的时候，我提到的主要事情之一是自动伸缩。如果你经历了用户数量的增加，你应该能够处理好你的用户，也许是通过增加你的资源。</p><figure class="lw lx ly lz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/3ba906de5281963cd45710a319a95af5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jwd52AL5hu9jGdSLE6e2CQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">显示自动缩放过程的图表</p></figure><ul class=""><li id="8cd0" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">全球可用性</li></ul><p id="591c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您现在想要确保的另一件事是您的模型具有全球可用性。这也意味着特定地区的用户不会面临大量的延迟。</p><ul class=""><li id="b659" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">应用程序接口</li></ul><p id="04fd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在此之后，您还需要为您的模型提供一种与您的设备交互的方式，很可能您会提供一个API来使用。然后你可以调用这个API，或者有人可以调用你的模型并得到预测结果。你还有另外一件事要维护和保持运行，那就是API。</p><ul class=""><li id="b4f0" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">模型版本控制</li></ul><p id="32af" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，明天当你或你的团队对模型进行更新时，你需要确保你的用户获得你的模型的最新版本，我们将在某个时候详细讨论这一点。例如，假设您提供一些影像分类服务，您必须不断更新您的模型，以便它能够以良好的准确性预测新的可用影像。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="a5d4" class="mj mk it bd ml mm ni mo mp mq nj ms mt mu nk mw mx my nl na nb nc nm ne nf ng bi translated">什么是TF模型服务器？</h1><p id="5af0" class="pw-post-body-paragraph kg kh it ki b kj np kl km kn nq kp kq kr oc kt ku kv od kx ky kz oe lb lc ld im bi translated">现在，您已经知道了将您的模型实际部署到云托管的服务器或为您的模型提供服务需要做些什么，让我们看看什么是TF模型服务器，更重要的是，它如何在您的用例中为您提供帮助。</p><p id="0aae" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TF Serving是TFX或TensorFlow Extended的一部分，简单来说TF Extended是一个API，旨在帮助您制作生产就绪的机器学习系统。我们将只讨论TFX的一个特定子部分，叫做TF服务。</p><figure class="lw lx ly lz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi of"><img src="../Images/de9d5bc4e6169c32fd0a676372765457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BKmXrIJgXEQ7CC2S"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">演员表:<a class="og oh ep" href="https://medium.com/u/e5a3b89cf15?source=post_page-----225a81859031--------------------------------" rel="noopener" target="_blank">劳伦斯·莫罗尼</a></p></figure><p id="5584" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是创建一个成熟的ML解决方案所要做的全部工作。我希望您了解的是，建模不是创建部署的唯一部分，事实上，也不是主要过程。TF服务帮助您轻松完成服务基础架构部分。</p><p id="a186" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，您可能希望在多种设备上运行您的模型，可能是在移动设备、低功耗嵌入式系统或网络上。也许您可以使用TF Lite将其部署在移动设备和嵌入式系统上，或者创建您的模型的JavaScript表示并直接在web上运行。很多时候，拥有一个集中的模型是一个更好的主意，在这个模型中，您的设备可以发送一个响应，然后服务器会执行它们，并将它们发送回发出调用的设备。</p><figure class="lw lx ly lz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oi"><img src="../Images/f430ba60c506291fc97b79cd51b62f9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BLBI8L42YuK4kFpqlBWQnQ.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">展示TF服务如何运作的图表</p></figure><p id="4c2d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还记得我们讨论过的模型版本化吗？在这样的架构中，你只需要在服务器上更新模型的新版本，你的所有设备就可以立即访问它。然而，如果你使用传统的方法，如发送应用程序更新，一些用户有新的模式，一些用户有旧的模式，造成了不好的体验。在基于云的环境中，要做到这一点，可以根据用户数量动态分配资源。</p><p id="4cb7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TF服务让你很容易做到这一点，这样你就不会遇到“哦，我刚刚更新了我的模型，我的服务器坏了！”诸如此类的事情。现在让我们在实践中看到这一点。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="f903" class="mj mk it bd ml mm ni mo mp mq nj ms mt mu nk mw mx my nl na nb nc nm ne nf ng bi translated">实践中的TF服务</h1><ul class=""><li id="2528" class="nn no it ki b kj np kn nq kr nr kv ns kz nt ld nu nv nw nx bi translated">安装TF服务</li></ul><p id="c5d0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以当然在开始之前你需要安装TF服务。repo中这个博客的代码示例已经为您输入了安装命令。安装非常简单，在这里找到安装步骤<a class="ae kf" href="https://www.tensorflow.org/tfx/serving/setup" rel="noopener ugc nofollow" target="_blank"/>。</p><ul class=""><li id="aed2" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">转换模型</li></ul><p id="fe52" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，你已经有了一个模型，你要做的第一件事就是简单地把它保存成一种TF Serving可用的格式。这里的第三行<code class="fe oj ok ol om b">directory_path</code>显示了保存模型的位置，另外两行只是传递输入和输出-</p><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="63c4" class="or mk it om b gy os ot l ou ov">tf.saved_model.simple_save(</span><span id="ab8a" class="or mk it om b gy ow ot l ou ov">    keras.backend.get_session(),</span><span id="5b61" class="or mk it om b gy ow ot l ou ov">    directory_path,</span><span id="1a4f" class="or mk it om b gy ow ot l ou ov">    inputs = {'input_image': model.input},</span><span id="a7f9" class="or mk it om b gy ow ot l ou ov">    outputs = {i.name: i for i in model.outputs}</span><span id="9565" class="or mk it om b gy ow ot l ou ov">)</span></pre><p id="bc2c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您导航到您保存此模型的路径，您将会看到一个类似这样的目录结构，我也创建了一个目录<code class="fe oj ok ol om b">1</code>，这是我的模型版本，我们将看到TF server如何帮助我们管理和部署这些版本。还要注意你的模型保存在一个<code class="fe oj ok ol om b">.pb</code>扩展名中。</p><figure class="lw lx ly lz gt ju gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/ba507a680635c91eae2cdb6756c3cb4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/0*8Mz3w1tUcKICU_Ww"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">保存的模型目录</p></figure><ul class=""><li id="83fb" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">保存的模型CLI</li></ul><p id="fa34" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还有一个很棒的界面叫做保存模型CLI，我觉得它非常有用。这为您提供了许多关于已保存模型的有用信息，如操作签名和输入输出形状。</p><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="78cc" class="or mk it om b gy os ot l ou ov">!saved_model_cli show --dir [DIR] --all</span></pre><p id="bd23" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是显示该工具提供的信息的示例输出-</p><figure class="lw lx ly lz gt ju gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/c8b12fefcd6e125100d8d29ea494244f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/0*y4hOGnzwLyy_ySj6.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">保存的模型CLI输出</p></figure><ul class=""><li id="8b30" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">启动模型服务器</li></ul><p id="c49c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是你启动模型服务器的方法，让我们来分解一下</p><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="d7a1" class="or mk it om b gy os ot l ou ov">os.environ["MODEL_DIR"] = MODEL_DIR</span><span id="d54d" class="or mk it om b gy ow ot l ou ov">%%bash --bg</span><span id="0051" class="or mk it om b gy ow ot l ou ov">nohup tensorflow_model_server \</span><span id="b576" class="or mk it om b gy ow ot l ou ov">    --rest_api_port = 8501 \</span><span id="f7ef" class="or mk it om b gy ow ot l ou ov">    --model_name = test \</span><span id="524b" class="or mk it om b gy ow ot l ou ov">    --model_base_path="${MODEL_DIR}" &gt;server.log 2&gt;&amp;1</span></pre><p id="a84c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，这里的第三行告诉它使用tensorflow模型服务器，当然，在实际实现它时，您不会包括bash magic cell，即代码行<code class="fe oj ok ol om b">%bash --bg</code>,但是作为Iassume，您可能会使用Colab，我已经添加了这一点，因为Colab不为您提供直接终端。</p><p id="e443" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里的第四行指定了运行TF模型服务器的端口，这也非常简单。</p><p id="10e8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">需要注意的是,<code class="fe oj ok ol om b">--model_name</code>也会出现在你服务模型的URL中，所以如果你有多个模型在运行，管理你的服务模型URL也变得容易多了。</p><p id="24b4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里的最后一行指定您想要启用日志记录，有时日志在调试时非常有用。我个人经常使用它们来很容易地找出错误。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="3d2d" class="mj mk it bd ml mm ni mo mp mq nj ms mt mu nk mw mx my nl na nb nc nm ne nf ng bi translated">执行推理</h1><p id="9cd4" class="pw-post-body-paragraph kg kh it ki b kj np kl km kn nq kp kq kr oc kt ku kv od kx ky kz oe lb lc ld im bi translated">现在让我们进入最有趣的部分，对模型进行推理。</p><ul class=""><li id="d8b2" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">传入数据</li></ul><p id="d603" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在模型上执行推理时要记住的一点是，在传递数据时，数据应该是列表的列表，而不仅仅是列表。事实上，这对开发者来说是一个额外的优势。让我们看看这意味着什么-</p><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="c12f" class="or mk it om b gy os ot l ou ov">xs = np.array([[case_1], [case_2] ... [case_n]])</span></pre><p id="d206" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里的<code class="fe oj ok ol om b">case_1</code>、<code class="fe oj ok ol om b">case_2</code>……<code class="fe oj ok ol om b">case_n</code>都有<code class="fe oj ok ol om b">x1</code>、<code class="fe oj ok ol om b">x2</code>……<code class="fe oj ok ol om b">xi</code>的所有特性值。</p><ul class=""><li id="dc1c" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">为数据创建一个JSON对象</li></ul><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="7953" class="or mk it om b gy os ot l ou ov">data = json.dumps({"signature_name": [SIGNATURE],</span><span id="1560" class="or mk it om b gy ow ot l ou ov">                   "instances": xs.tolist()})</span></pre><p id="7f61" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你对保存的模型有所了解，你可能知道<code class="fe oj ok ol om b">SignatureDef</code>，对于那些不知道它定义了张量流图中支持的计算签名的人来说。所以你可以支持函数的I/O。通过<code class="fe oj ok ol om b">saved_model_cli</code>你可以很容易的找到。在实例部分，我们将放入刚刚创建的<code class="fe oj ok ol om b">xs</code>。</p><ul class=""><li id="17b4" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">提出推理请求</li></ul><p id="08e4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在你可以简单地提出一个推理请求-</p><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="0f4c" class="or mk it om b gy os ot l ou ov">json_response = requests.post(<br/>    '<a class="ae kf" href="http://localhost:8501/v1/models/helloworld:predict" rel="noopener ugc nofollow" target="_blank">http://localhost:8501/v1/models/test:predict</a>',         <br/>    data = data,<br/>    headers = headers)</span></pre><p id="0bdf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">记住我们谈论的是版本，而不是它包含的模型URL<code class="fe oj ok ol om b">v1</code>，它允许我们容易地指定我们想要使用模型的版本1。您还可以看到URL中反映的型号名称<code class="fe oj ok ol om b">test</code>。</p><p id="c323" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你的头应该是这样的，因为你是以JSON的形式传入数据的</p><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="ff5e" class="or mk it om b gy os ot l ou ov">headers = {"content-type": "application/json"}</span></pre><ul class=""><li id="0c57" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">图像！</li></ul><p id="24cd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你们中的很多人可能会觉得，看看自己如何传递图像会很有趣。事实上，这样做很容易。代替我们在上面看到的<code class="fe oj ok ol om b">case_1</code>，您只需用一个值列表来替换它，这些值构成了您的图像。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="f60e" class="mj mk it bd ml mm ni mo mp mq nj ms mt mu nk mw mx my nl na nb nc nm ne nf ng bi translated">一些额外的优势</h1><p id="2bfb" class="pw-post-body-paragraph kg kh it ki b kj np kl km kn nq kp kq kr oc kt ku kv od kx ky kz oe lb lc ld im bi translated">现在你已经知道了TF服务器是如何工作的，以及如何使用它。了解了这一点，这里还有一些它提供的东西。现在，您可以理解，如果我们假设您部署了模型的版本2，在出现任何问题的情况下，您的版本1将仍然是活动的和可用的。</p><p id="8347" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，当您的新型号版本部署时，您没有停机时间，您的旧版本将继续正常工作，这些事情通常非常有用。TF模型服务器可以帮助你很容易地做到这一点。</p><ul class=""><li id="db19" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">关注真实代码</li></ul><p id="050a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TF Model Server的一个非常棒的地方是让您专注于编写真正的代码，而不是担心基础架构和管理它，这是非常有用的，作为开发人员，您不会想花时间做这些基础架构方面的事情。这反过来允许您构建更好的ML应用程序，并让它们更快地启动和运行。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="4a91" class="mj mk it bd ml mm ni mo mp mq nj ms mt mu nk mw mx my nl na nb nc nm ne nf ng bi translated">在云上服务模型</h1><p id="6fe3" class="pw-post-body-paragraph kg kh it ki b kj np kl km kn nq kp kq kr oc kt ku kv od kx ky kz oe lb lc ld im bi translated">我们现在看到的东西可以很好地扩展到云，使其更加强大，您可以随时拥有自己的服务器。我们不会在这里讨论为什么是云或内部部署，也不会讨论负载平衡是如何发生的。我们将看到一个使用Kubernetes在云上部署模型的简短工作流。有了TF模型服务器，这就变得容易多了。</p><ul class=""><li id="0a74" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">创建集群</li></ul><p id="f9d8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我假设您已经训练了一个模型，并为它构建了一个docker映像。做到这一点的步骤非常简单，我也在本次会议的GitHub repo中列出了它们。我们将从创建一个包含5个节点的Kubernetes集群开始，我将向您展示如何在云上部署一个简单的<code class="fe oj ok ol om b">resnet</code>模型。</p><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="b087" class="or mk it om b gy os ot l ou ov">gcloud container clusters create</span><span id="1f99" class="or mk it om b gy ow ot l ou ov">    resnet-serving-cluster</span><span id="ebe2" class="or mk it om b gy ow ot l ou ov">    --num-nodes 5</span></pre><ul class=""><li id="03bf" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">推送docker图像</li></ul><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="bc42" class="or mk it om b gy os ot l ou ov">docker tag</span><span id="d077" class="or mk it om b gy ow ot l ou ov">    $USER/resnet_serving</span><span id="a60a" class="or mk it om b gy ow ot l ou ov">    gcr.io/[PROJECT_ID]/resnet</span><span id="5d49" class="or mk it om b gy ow ot l ou ov">docker push</span><span id="e0ee" class="or mk it om b gy ow ot l ou ov">    gcr.io/[PROJECT_ID]/resnet</span></pre><p id="2da0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，您可以将docker映像推送到容器注册表中</p><ul class=""><li id="74e1" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated">创建部署</li></ul><p id="6352" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，您已经准备好创建部署了，此处显示的YAML文件将为部署创建元数据，如您的映像和所需的复制副本数量，我在报告中为您提供了一个示例。</p><pre class="lw lx ly lz gt on om oo op aw oq bi"><span id="7e0e" class="or mk it om b gy os ot l ou ov">kubectl create -f [yaml]</span></pre><p id="08ff" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一件要记住的事情是，当使用云上托管的模型执行推理时，您现在将使用外部IP来进行推理请求，而不是我们之前使用的<code class="fe oj ok ol om b">localhost</code>。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><p id="bd2c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们从为什么部署过程是值得的开始。然后我们看到了部署您的模型所需要的东西，版本、可用性、全球性、基础设施等等。然后我们看到了TF Model server为我们提供了什么，以及为什么您应该选择TF Model server来进行部署。然后我们看到了与TF模型服务器相关的过程。您还看到了它如何允许您编写真正的代码，而不必担心基础设施、版本明智的URL以及对它们的简单管理。然后，我们开始研究如何在云上复制这一点，并了解Kubernetes如何让这一点变得简单。</p><p id="86ea" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我为你准备了几个笔记本，它们实现了你在这篇文章中看到的所有内容，你可以自己尝试一下。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="776a" class="mj mk it bd ml mm ni mo mp mq nj ms mt mu nk mw mx my nl na nb nc nm ne nf ng bi translated">关于我</h1><p id="b569" class="pw-post-body-paragraph kg kh it ki b kj np kl km kn nq kp kq kr oc kt ku kv od kx ky kz oe lb lc ld im bi translated">大家好，我是里希特·达利</p><p id="6200" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://twitter.com/rishit_dagli" rel="noopener ugc nofollow" target="_blank">推特</a></p><p id="490a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://rishit.tech/" rel="noopener ugc nofollow" target="_blank">网站</a></p><p id="8439" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想问我一些问题，报告任何错误，建议改进，给我反馈，你可以发邮件给我</p><ul class=""><li id="a41e" class="nn no it ki b kj kk kn ko kr ny kv nz kz oa ld nu nv nw nx bi translated"><a class="ae kf" href="mailto:rishit.dagli@gmail.com" rel="noopener ugc nofollow" target="_blank">rishit.dagli@gmail.com</a></li><li id="f61a" class="nn no it ki b kj oz kn pa kr pb kv pc kz pd ld nu nv nw nx bi translated"><a class="ae kf" href="mailto:hello@rishit.tech" rel="noopener ugc nofollow" target="_blank"> hello@rishit.tech </a></li></ul></div></div>    
</body>
</html>