<html>
<head>
<title>Predictive Analytics: Regression Analysis with LSTM, GRU and BiLSTM in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测分析:用 TensorFlow 中的 LSTM、GRU 和比尔斯特姆进行回归分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predictive-analysis-rnn-lstm-and-gru-to-predict-water-consumption-e6bb3c2b4b02?source=collection_archive---------3-----------------------#2020-07-16">https://towardsdatascience.com/predictive-analysis-rnn-lstm-and-gru-to-predict-water-consumption-e6bb3c2b4b02?source=collection_archive---------3-----------------------#2020-07-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/d4246c039b5c2109517fed74fd420b8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yCuXkBbkJxSkw6iI8ohrhw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">在<a class="ae jg" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae jg" href="https://unsplash.com/@thisisengineering" rel="noopener ugc nofollow" target="_blank">this is 工程</a>拍摄</p></figure><div class=""/><div class=""><h2 id="b8dd" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">关于开发 LSTM、GRU 和比尔斯特姆模型进行用水量多步预测的分步指南</h2></div><p id="7ffb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di">在</span>这篇文章中，我开发了三个连续模型；LSTM、GRU 和双向 LSTM，预测气候变化影响下的用水量。然后，我用最可靠的一个对未来 10 年的城市用水量进行多步预测。</p><p id="7ca0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，让我提醒你一下基本面。然后，我将带您完成一个完整的 Python 数据科学项目。</p><p id="8bad" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">👩‍💻</strong> <a class="ae jg" href="https://github.com/NioushaR/LSTM-GRU-BiLSTM-in-TensorFlow-for-predictive-analytics" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">上的 Python 代码 GitHub </strong> </a></p><h1 id="3860" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">递归神经网络</h1><p id="68c9" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">递归神经网络(RNN)是一种设计用于使用时序数据的神经网络。在 RNNs 中，输出可以作为输入反馈到网络中，创建一个循环结构。</p><h2 id="9400" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">梯度消失问题</h2><p id="99a5" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">通过反向传播来训练 rnn。在反向传播过程中，RNNs 会遇到梯度消失问题。梯度是用于更新神经网络权重的值。梯度消失问题是当梯度随着时间向后传播而收缩时。因此，梯度较小的层不会学习，它们会导致网络具有短期记忆。</p><p id="53f1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">💡❓ </strong>渐变消失问题的解决方案是什么</p><h1 id="0d9b" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">长短期记忆</h1><p id="c9c6" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">长短期记忆(LSTM)是一种专门的 RNN，以减轻梯度消失的问题。LSTMs 可以使用一种称为 gates 的机制来学习长期依赖关系。这些门可以了解序列中哪些信息是重要的，应该保留或丢弃。LSTMs 有三个门；输入，忘记，输出。</p><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/aaf7785d34594586d9329f48781345fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kq5qv8aXLyF0mmzE4G9YVQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">LSTM 细胞的结构</p></figure><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nr"><img src="../Images/d942fb3786c704f1b2abd725b7c64e50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oq_iXPyXcW8wnLRMtM1-Fw.png"/></div></div></figure><h1 id="4076" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">双向 LSTMs</h1><p id="1924" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">双向 lstm(BiSTM)的思想是在 LSTM 模型中聚合特定时间步长的过去和未来的输入信息。在 BiLSTM 中，在任何时间点，您都可以保存过去和未来的信息。</p><h1 id="a896" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">门控循环单元</h1><p id="426f" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">门控递归单元(GRU)是新一代的神经网络，非常类似于 LSTM。GRU 摆脱了细胞状态，使用隐藏状态来传递信息。GRU 和 LSTM 的另一个区别是 GRU 只有两个大门；复位和更新门。</p><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ns"><img src="../Images/10f207acf691c6e0fd139e7a13d1db87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hZU3rzM9x71iMUjHlQ3uBw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">GRU 细胞的结构</p></figure><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nt"><img src="../Images/8b1c74f5420387dfae86af0753b737b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g4VOuCmutyxkLRu5DBDffQ.png"/></div></div></figure></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h1 id="807d" class="md me jj bd mf mg ob mi mj mk oc mm mn kp od kq mp ks oe kt mr kv of kw mt mu bi translated">☺时间让我们的手 dirty❗</h1><h2 id="304a" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">资料组</h2><p id="5f59" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">加拿大魁北克省的 Brossard 市被选为研究地点。这座城市是蒙特利尔大都市区的一部分。本项目<strong class="la jk">日用水量</strong>数据取自 2011 年 9 月 1 日至 2015 年 9 月 30 日。收集同期<strong class="la jk">最低气温</strong>、<strong class="la jk">最高气温</strong>和<strong class="la jk">总降水量</strong>。这些气候变量的测量数据来自<a class="ae jg" href="https://www.concordia.ca/news/stories/2019/01/07/historical-canadian-climate-data-is-now-only-a-few-clicks-away.html" rel="noopener ugc nofollow" target="_blank">加拿大环境部</a>。</p><h2 id="e953" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">导入库</h2><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/86adab9c7807e3bd7f6322aca0549fec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ktiEFNqTLC-twGFd8MW0CQ.png"/></div></div></figure><h2 id="c7f2" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">设置随机种子</h2><p id="32f7" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">设置随机种子以在每次运行代码后获得相同的结果。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="34b3" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Set random seed for reproducibility</strong><br/>tf.random.set_seed(1234)</span></pre><h1 id="980f" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">步骤 1:读取和浏览数据</h1><p id="a5e2" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">在这个项目中，我正在处理多变量时间序列数据。当我从 CSV 文件导入数据时，我通过<strong class="la jk"> parse_dates = ['Date'] </strong>确保<strong class="la jk"> Date </strong>列具有正确的<em class="oq"> DateTime </em>格式。此外，当我处理日期和时间时，如果我将<strong class="la jk">日期</strong>列设置为 dataframe 索引，就会变得容易得多。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="43a3" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Read file</strong><br/>file = 'Data.csv'<br/>raw_data = pd.read_csv(file, parse_dates = ['Date'],<br/>                       index_col = 'Date')<br/>df = raw_data.copy()</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/0f8f5a51309d131369f6ffb95431908e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SExlfaPPzMhHvCBLTGojlQ.png"/></div></div></figure><ul class=""><li id="c051" class="os ot jj la b lb lc le lf lh ou ll ov lp ow lt ox oy oz pa bi translated">Max_T:最高温度(℃)</li><li id="343e" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">Min_T:最低温度(℃)</li><li id="dff3" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">T_P:总降水量(毫米)</li><li id="e32f" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">UWC:城市用水量(立方米/人.天)</li></ul><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="2478" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Define a function to draw time_series plot</strong><br/>def timeseries (x_axis, y_axis, x_label, y_label):<br/>    plt.figure(figsize = (10, 6))<br/>    plt.plot(x_axis, y_axis, color ='black')<br/>    plt.xlabel(x_label, {'fontsize': 12}) <br/>    plt.ylabel(y_label, {'fontsize': 12})</span><span id="7455" class="na me jj oi b gy pg on l oo op">timeseries(df.index, df['WC (m3/capita.day)'], 'Time (day)','Daily Water consumption ($m^3$/capita.day)')</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/605873cd11ee6112485b60c44bb7e482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vj5zK5u37FZd5Cs0LNB_UQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">2011 年 9 月 1 日至 2015 年 9 月 30 日的日用水量时间序列</p></figure><h1 id="69fc" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">第二步:数据预处理</h1><p id="6d03" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">数据预处理是最耗时的步骤，包括:</p><ul class=""><li id="9ac6" class="os ot jj la b lb lc le lf lh ou ll ov lp ow lt ox oy oz pa bi translated">处理缺失值</li><li id="fb0b" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">替换异常值</li><li id="abb0" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">将数据集拆分为训练和测试数据</li><li id="54ad" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">拆分目标变量和因变量</li><li id="afca" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">数据转换</li><li id="d467" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">创建 3D 输入数据集</li></ul><h2 id="7521" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">2.1 处理缺失值</h2><p id="27c4" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">对于时间序列数据，使用线性插值替换缺失值是一个好主意。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="f3aa" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Check missing values</strong><br/>df.isnull().sum()</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/2c6dcbd867519661fdf14774d487782f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yEErGkjKxzKohZs6eXRYwA.png"/></div></div></figure><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="764c" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Replace missing values by interpolation</strong><br/>def replace_missing (attribute):<br/>    return attribute.interpolate(inplace=True)</span><span id="fd61" class="na me jj oi b gy pg on l oo op">replace_missing(df['Max_T'])<br/>replace_missing(df['Min_T'])<br/>replace_missing(df['T_P'])<br/>replace_missing(df['UWC'])</span></pre><h2 id="a453" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">2.2 替换异常值</h2><p id="3d18" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">我使用统计方法来检测异常值。统计方法假设数据点呈正态分布。因此，低概率区域中的值被视为异常值。我在统计方法中应用了最大似然的概念，这意味着超出μ 2σ范围的值被标记为异常值。注意，在正态分布的假设下，μ 2σ包含 95%的数据。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="6b4b" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Outlier detection</strong><br/>up_b = df['UWC'].mean() + 2*df['UWC'].std()<br/>low_b = df['UWC'].mean() - 2*df['UWC'].std()</span><span id="06c3" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Replace outlier by interpolation for base consumption</strong><br/>df.loc[df['UWC'] &gt; up_b, 'UWC'] = np.nan<br/>df.loc[df['UWC'] &lt; low_b, 'UWC'] = np.nan<br/>df['UWC'].interpolate(inplace=True)</span></pre><h2 id="3e5a" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">2.3 将数据集分为训练和测试数据</h2><p id="0973" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">在这个项目中，我将前 80%的数据设置为训练数据，剩下的 20%为测试数据。我用训练数据训练模型，并用测试数据验证其性能。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="0df2" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Split train data and test data</strong><br/>train_size = int(len(df)*0.8)<br/>train_dataset, test_dataset = df.iloc[:train_size],<br/>df.iloc[train_size:]</span><span id="80b0" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Plot train and test data</strong><br/>plt.figure(figsize = (10, 6))<br/>plt.plot(train_dataset.UWC)<br/>plt.plot(test_dataset.UWC)<br/>plt.xlabel('Time (day)')<br/>plt.ylabel('Daily water consumption ($m^3$/capita.day)')<br/>plt.legend(['Train set', 'Test set'], loc='upper right')</span><span id="b946" class="na me jj oi b gy pg on l oo op">print('Dimension of train data: ',train_dataset.shape)<br/>print('Dimension of test data: ', test_dataset.shape)</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/5c7c85e937c8c7c8d292bf0de594e61d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lC87Hdkl4zYCLj9ukGPVNQ.png"/></div></div></figure><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/f0db92de7e645aee915dbbd6bde926e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SKIE7MwhSsR4Zv8D4n0qpA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">训练数据和测试数据的预处理日用水量时间序列</p></figure><h2 id="4819" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">2.4 拆分目标变量和因变量</h2><p id="e1b1" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">UWC 是目标变量(输出)，是因变量(输入)的函数；Max_T，Min_T 和 T_P。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="bf70" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Split train data to X and y</strong><br/>X_train = train_dataset.drop('UWC', axis = 1)<br/>y_train = train_dataset.loc[:,['UWC']]</span><span id="7254" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Split test data to X and y</strong><br/>X_test = test_dataset.drop('UWC', axis = 1)<br/>y_test = test_dataset.loc[:,['UWC']]</span></pre><h2 id="dd44" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">2.5 数据转换</h2><p id="fe53" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">一个很好的经验法则是，规范化的数据会在神经网络中产生更好的性能。在这个项目中，我使用来自<a class="ae jg" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>的<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html" rel="noopener ugc nofollow" target="_blank"> MinMaxScaler </a>。</p><p id="eee7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我为输入和输出定义了不同的标量，因为它们有不同的形状。这对于使用<strong class="la jk">逆变换</strong>功能尤其重要。</p><ul class=""><li id="484f" class="os ot jj la b lb lc le lf lh ou ll ov lp ow lt ox oy oz pa bi translated">X_train.shape: (1192，3)</li><li id="1ab3" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">y_train.shape: (1192，1)</li><li id="69d8" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">X_test.shape: (299，3)</li><li id="dcbf" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">y_test.shape: (299，1)</li></ul><p id="b34e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">务必确保输出的比例在 0–1 范围内，以匹配 LSTM、GRU 和比尔斯特姆输出层的激活函数(tanh)的比例。此外，输入变量最好是小值，可能在 0-1 的范围内。</p><p id="5461" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">💡</strong><strong class="la jk">steps❓有哪些数据转换</strong></p><ul class=""><li id="1eb6" class="os ot jj la b lb lc le lf lh ou ll ov lp ow lt ox oy oz pa bi translated">使用可用的训练数据拟合定标器(MinMaxScaler)(这意味着使用训练数据估计最小和最大可观测值。)</li><li id="3e86" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">将缩放器应用于训练数据</li><li id="ed7b" class="os ot jj la b lb pb le pc lh pd ll pe lp pf lt ox oy oz pa bi translated">将定标器应用于测试数据</li></ul><p id="4eac" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">值得注意的是，我们应该使用训练数据上安装的缩放器来缩放不可见的数据。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="3ca8" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Different scaler for input and output</strong><br/>scaler_x = MinMaxScaler(feature_range = (0,1))<br/>scaler_y = MinMaxScaler(feature_range = (0,1))</span><span id="a66a" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Fit the scaler using available training data</strong><br/>input_scaler = scaler_x.fit(X_train)<br/>output_scaler = scaler_y.fit(y_train)</span><span id="83a9" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Apply the scaler to training data</strong><br/>train_y_norm = output_scaler.transform(y_train)<br/>train_x_norm = input_scaler.transform(X_train)</span><span id="026b" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Apply the scaler to test data</strong><br/>test_y_norm = output_scaler.transform(y_test)<br/>test_x_norm = input_scaler.transform(X_test)</span></pre><h2 id="0ffa" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">2.6 创建 3D 输入数据集</h2><p id="d3ad" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">LSTM、GRU 和比尔斯特姆采用 3D 输入(样本数、时间步数、特征数)。因此，我创建了一个助手函数，<em class="oq"> create_dataset </em>，来重塑输入。</p><p id="b9d0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个项目中，我定义 time_steps = 30。这意味着模型基于最近 30 天的数据进行预测(在 for 循环的第一次迭代中，输入携带前 30 天，输出是第 30 天的 UWC)。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="64e7" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Create a 3D input</strong><br/>def create_dataset (X, y, time_steps = 1):<br/>    Xs, ys = [], []<br/>    for i in range(len(X)-time_steps):<br/>        v = X[i:i+time_steps, :]<br/>        Xs.append(v)<br/>        ys.append(y[i+time_steps])<br/>    return np.array(Xs), np.array(ys)</span><span id="d601" class="na me jj oi b gy pg on l oo op">TIME_STEPS = 30</span><span id="e12c" class="na me jj oi b gy pg on l oo op">X_test, y_test = create_dataset(test_x_norm, test_y_norm,   <br/>                                TIME_STEPS)<br/>X_train, y_train = create_dataset(train_x_norm, train_y_norm, <br/>                                  TIME_STEPS)<br/>print('X_train.shape: ', X_test.shape)<br/>print('y_train.shape: ', y_train.shape)<br/>print('X_test.shape: ', X_test.shape)<br/>print('y_test.shape: ', y_train.shape)</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/52cd204156b257c807699d2d8b8629e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QKKogbchzp5tTqFxuIhb6A.png"/></div></div></figure><h1 id="8624" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">步骤 3:创建比尔斯特姆、LSTM 和 GRU 模型</h1><h1 id="7576" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">3.1 tensor flow 中的比尔斯特姆、LSTM 和 GRU 模型</h1><p id="a9bf" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">第一个函数，<em class="oq"> create_model_bilstm </em>，创建一个 BDLSM 并获取隐藏层中的单元(神经元)数量。第二个函数<em class="oq"> create_model </em>获得两个输入；隐藏层中的单元数量和模型名称(LSTM 或 GRU)。</p><p id="ef66" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了简单起见，比尔斯特姆、LSTM 和 GRU 在输入层有 64 个神经元，一个隐藏层包括 64 个神经元，在输出层有 1 个神经元。</p><p id="fdf4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了使 LSTM 和 GRU 模型对变化具有鲁棒性，使用了<strong class="la jk">下降</strong>函数。<strong class="la jk">掉线(0.2) </strong>随机掉线 20%的单位。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="7cc3" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Create BiLSTM model</strong><br/>def create_model_bilstm(units):<br/>    model = Sequential()<br/>    model.add(Bidirectional(LSTM(units = units,                             <br/>              return_sequences=True),<br/>              input_shape=(X_train.shape[1], X_train.shape[2])))<br/>    model.add(Bidirectional(LSTM(units = units)))<br/>    model.add(Dense(1))<br/>    <strong class="oi jk">#Compile model</strong><br/>    model.compile(loss='mse', optimizer='adam')<br/>    return model</span><span id="ff8e" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Create LSTM or GRU model</strong><br/>def create_model(units, m):<br/>    model = Sequential()<br/>    model.add(m (units = units, return_sequences = True,<br/>                input_shape = [X_train.shape[1], X_train.shape[2]]))<br/>    model.add(Dropout(0.2))<br/>    model.add(m (units = units))<br/>    model.add(Dropout(0.2))<br/>    model.add(Dense(units = 1))<br/>    <strong class="oi jk">#Compile model</strong><br/>    model.compile(loss='mse', optimizer='adam')<br/>    return model</span><span id="5b6d" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># BiLSTM</strong><br/>model_bilstm = create_model_bilstm(64)</span><span id="c2da" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># GRU and LSTM</strong><br/>model_gru = create_model(64, GRU)<br/>model_lstm = create_model(64, LSTM)</span></pre><h1 id="ed3f" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">3.2 拟合模型</h1><p id="0f45" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">我用 100 个<strong class="la jk">时期</strong>和<strong class="la jk">批量</strong> = 32 的训练数据训练模型。我让模型使用 20%的训练数据作为验证数据。我设置<strong class="la jk"> shuffle = False </strong>是因为它提供了更好的性能。</p><p id="503e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了避免过度拟合，我设置了一个<em class="oq">提前停止</em>，当<em class="oq">验证损失</em>在 10 个周期后没有改善时(耐心= 10)停止训练。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="300d" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Fit BiLSTM, LSTM and GRU</strong><br/>def fit_model(model):<br/>    early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss',<br/>                                               patience = 10)<br/>    history = model.fit(X_train, y_train, epochs = 100,  <br/>                        validation_split = 0.2, batch_size = 32, <br/>                        shuffle = False, callbacks = [early_stop])<br/>    return history</span><span id="29a1" class="na me jj oi b gy pg on l oo op">history_bilstm = fit_model(model_bilstm)<br/>history_lstm = fit_model(model_lstm)<br/>history_gru = fit_model(model_gru)</span></pre><h2 id="e297" class="na me jj bd mf nb nc dn mj nd ne dp mn lh nf ng mp ll nh ni mr lp nj nk mt nl bi translated">绘制列车损失和验证损失</h2><p id="95eb" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">在此图中，我将查看每个模型中的时期数，并评估模型在预测中的性能。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="8b0c" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Plot train loss and validation loss</strong><br/>def plot_loss (history):<br/>    plt.figure(figsize = (10, 6))<br/>    plt.plot(history.history['loss'])<br/>    plt.plot(history.history['val_loss'])<br/>    plt.ylabel('Loss')<br/>    plt.xlabel('epoch')<br/>    plt.legend(['Train loss', 'Validation loss'], loc='upper right')</span><span id="8e8a" class="na me jj oi b gy pg on l oo op">plot_loss (history_bilstm)<br/>plot_loss (history_lstm)<br/>plot_loss (history_gru)</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/da3ef85ca3f594f559a423965fd561a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*edGyuCIYlK6mDe-DheoUfQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">BiLSTM 的列车损失与验证损失</p></figure><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/f959490a60a75a23ff51d54a7de00e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gRNCR5n_yCpLwuULp0EUZQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">LSTM 的列车损失与验证损失</p></figure><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/85acbb4fb7404f7552ed8ead576fa385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Pa1AQiZeyn9g_grF5NcmA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">GRU 的列车损失与验证损失</p></figure><h1 id="b57d" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">3.3 逆变换目标变量</h1><p id="95a8" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">建立模型后，我必须使用<strong class="la jk">scaler _ y . inverse _ transform</strong>将目标变量转换回原始数据空间，用于训练和测试数据。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="3193" class="na me jj oi b gy om on l oo op">y_test = scaler_y.inverse_transform(y_test)<br/>y_train = scaler_y.inverse_transform(y_train)</span></pre><h1 id="6740" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">3.4 使用比尔斯特姆、LSTM 和 GRU 进行预测</h1><p id="0619" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">在这里，我用比尔斯特姆、LSTM 和 GRU 模型预测 UWC。然后，我绘制了三个模型的真实未来(测试数据)与预测。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="f152" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Make prediction</strong><br/>def prediction(model):<br/>    prediction = model.predict(X_test)<br/>    prediction = scaler_y.inverse_transform(prediction)<br/>    return prediction</span><span id="020d" class="na me jj oi b gy pg on l oo op">prediction_bilstm = prediction(model_bilstm)<br/>prediction_lstm = prediction(model_lstm)<br/>prediction_gru = prediction(model_gru)</span><span id="8c8c" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Plot true future vs prediction</strong><br/>def plot_future(prediction, y_test):<br/>    plt.figure(figsize=(10, 6))<br/>    range_future = len(prediction)<br/>    plt.plot(np.arange(range_future), np.array(y_test), <br/>             label='True Future')     <br/>    plt.plot(np.arange(range_future),np.array(prediction),<br/>            label='Prediction')<br/>    plt.legend(loc='upper left')<br/>    plt.xlabel('Time (day)')<br/>    plt.ylabel('Daily water consumption ($m^3$/capita.day)')</span><span id="d859" class="na me jj oi b gy pg on l oo op">plot_future(prediction_bilstm, y_test)<br/>plot_future(prediction_lstm, y_test)<br/>plot_future(prediction_gru, y_test)</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/3420ce9b51eb5c05259f4487da176e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Y9naIoSbaBVzqPu0KfLqQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">BiLSTM 模型的真实未来与日用水量预测</p></figure><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/cb4f54f4b7c36cbf487cf6d86a54b7d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RCisyJ94jk3M2CjXIgrnxw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">LSTM 模型的真实未来与日用水量预测</p></figure><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/06d4303ea502575e3752a5a61e1246d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kfn-3WYLhsBhXTafC6tKYg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">GRU 模型的真实未来与日用水量预测</p></figure><h1 id="449e" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">3.5 计算 RMSE 和梅</h1><p id="7945" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">让我用两个拟合优度来评估模型的性能。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="0628" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Define a function to calculate MAE and RMSE</strong><br/>def evaluate_prediction(predictions, actual, model_name):<br/>    errors = predictions - actual<br/>    mse = np.square(errors).mean()<br/>    rmse = np.sqrt(mse)<br/>    mae = np.abs(errors).mean()</span><span id="6290" class="na me jj oi b gy pg on l oo op">print(model_name + ':')<br/>    print('Mean Absolute Error: {:.4f}'.format(mae))<br/>    print('Root Mean Square Error: {:.4f}'.format(rmse))<br/>    print('')</span><span id="197e" class="na me jj oi b gy pg on l oo op">evaluate_prediction(prediction_bilstm, y_test, 'Bidirectional LSTM')<br/>evaluate_prediction(prediction_lstm, y_test, 'LSTM')<br/>evaluate_prediction(prediction_gru, y_test, 'GRU')</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pl"><img src="../Images/ad0757160024f3897e8a44f488ea57e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8JA-iD_NGzr9hZu_GxQTXg.png"/></div></div></figure><p id="7eb6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">三个模型的拟合优度表明它们具有非常相似的性能。即便如此，与 LSTM 和 GRU 相比，<strong class="la jk"> BiLSTM </strong>模型具有更高的准确性。因此，我使用 BiLSTM 模型对 UWC 未来 10 年进行多步预测。</p><p id="0c8b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">⚠️ <strong class="la jk">注意:</strong>这个项目的结果并不意味着 BiLSTM 比 LSTM 和 GRU 有更好的结果。这只是说明如何比较这些模型，以得出最可靠的预测。</p><h1 id="cd53" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">步骤 4:10 年用水量的多步预测</h1><p id="50dd" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">我在研究地点导入气候数据预测，并对 2015 年 1 月 1 日至 2025 年 1 月 1 日期间的数据进行过滤。</p><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/fe22db8af5b618c23fefdcd594f31070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5xMqdW2Jv3XbQKss-pfw7A.png"/></div></div></figure><p id="f7f8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我创建了一个助手函数，<em class="oq"> plot_history_future </em>，来绘制历史和未来的 UWC。然后，我创建了一个函数，<em class="oq"> forecast，</em>来重塑看不见的输入，并使用 LSTM 模型进行预测。</p><pre class="nn no np nq gt oh oi oj ok aw ol bi"><span id="d17d" class="na me jj oi b gy om on l oo op"><strong class="oi jk"># Plot histoy and future data</strong><br/>def plot_history_future(y_train, prediction):<br/>    plt.figure(figsize=(10, 6))</span><span id="62c4" class="na me jj oi b gy pg on l oo op">    range_history = len(y_train)<br/>    range_future = list(range(range_history, range_history +<br/>                   len(prediction)))</span><span id="b3b7" class="na me jj oi b gy pg on l oo op">    plt.plot(np.arange(range_history), np.array(y_train), <br/>             label='History')<br/>    plt.plot(range_future, np.array(prediction),label='Prediction')<br/>    plt.legend(loc='upper right')<br/>    plt.xlabel('Time (day)')<br/>    plt.ylabel('Daily water consumption ($m^3$/capita.day)')</span><span id="cd61" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Multi-step forecasting </strong><br/>def forecast(X_input, time_steps):<br/>    <strong class="oi jk"># Scale the unseen input with the scaler fitted on the train set</strong><br/>    X = input_scaler.transform(X_input)<br/>    <strong class="oi jk"># Reshape unseen data to a 3D input</strong><br/>    Xs = []<br/>    for i in range(len(X) - time_steps):<br/>        v = X[i:i+time_steps, :]<br/>        Xs.append(v)</span><span id="e679" class="na me jj oi b gy pg on l oo op">    X_transformed = np.array(Xs)</span><span id="46c9" class="na me jj oi b gy pg on l oo op"><strong class="oi jk"># Make prediction for unseen data using LSTM model</strong><br/>    prediction = model_bilstm.predict(X_transformed)<br/>    prediction_actual = scaler_y.inverse_transform(prediction)<br/>    return prediction_actual</span><span id="8655" class="na me jj oi b gy pg on l oo op">prediction = forecast(X_new, TIME_STEPS)<br/>plot_history_future(y_train, prediction)</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/a2aabfb65b4b7b671225b82281d07eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lUNJBuOXc-BraERp5Lwxqg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">基于 BiLSTM 模型的日用水量历史与预测</p></figure><h1 id="d35f" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">结论</h1><p id="87a5" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">感谢您阅读这篇文章。我知道这是一个相当长的教程😏我希望它能帮助你在 Tensorflow 中为一个数据科学项目开发 LSTM、GRU 和比尔斯特姆模型😊</p><p id="1df7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">非常感谢您的反馈。你可以在 LinkedIn 上找到我。</p></div></div>    
</body>
</html>