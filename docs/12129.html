<html>
<head>
<title>Machine Learning Basics: K-Nearest Neighbors Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习基础:K-最近邻分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-basics-k-nearest-neighbors-classification-6c1e0b209542?source=collection_archive---------20-----------------------#2020-08-21">https://towardsdatascience.com/machine-learning-basics-k-nearest-neighbors-classification-6c1e0b209542?source=collection_archive---------20-----------------------#2020-08-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1e19" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解 KNN 分类并在简单数据集上构建模型以可视化您的结果！</h2></div><p id="cb35" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在之前的<a class="ae le" rel="noopener" target="_blank" href="/machine-learning-basics-simple-linear-regression-bc83c01baa07">故事</a>中，我已经解释了各种<strong class="kk iu"> <em class="lf">回归</em> </strong>模型的实现程序。此外，我已经描述了<a class="ae le" rel="noopener" target="_blank" href="/machine-learning-basics-logistic-regression-890ef5e3a272">逻辑回归</a>模型的实现。在本文中，我们将看到 K-最近邻或 KNN 分类的算法以及一个简单的例子。</p><h2 id="a136" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">KNN 分类概述</h2><p id="85ac" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">K-最近邻或 KNN 分类是一种简单且易于实现的监督机器学习算法，主要用于分类问题。</p><p id="e884" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们用一个非常简单的例子来理解这个算法。假设有两个类，分别用矩形和三角形表示。如果我们想给任何一个类添加一个新的形状(菱形),那么我们可以实现 KNN 分类模型。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi me"><img src="../Images/2bf006b2b01bf09dcbba169c464b4404.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*e80x744qBUr84kLSb6GF8w.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">KNN 模型(来源——自我)</p></figure><p id="6e4e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个模型中，我们必须选择最近邻的数量(N)。这里，由于我们选择了 N=4，新的数据点将计算每个点之间的距离，并在其最近的 4 个邻居周围绘制一个圆形区域(N=4)。在这个问题中，由于所有四个最近的邻居都位于类 1(矩形)中，所以新的数据点(菱形)也被指定为类 1 数据点。</p><p id="9600" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这样，我们可以用不同的值改变参数 N，并通过试错法为模型选择最精确的值，也避免了过拟合和高损失。</p><p id="b796" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这样，我们就可以实现 KNN 分类算法。现在让我们在下一节中通过一个真实的例子来讨论它的实现。</p><h2 id="c875" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">问题分析</h2><p id="5c1b" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">为了在实际应用中应用 KNN 分类模型，我使用了与构建逻辑回归模型相同的数据集。在这里，我们 DMV 测试数据集有三列。前两列由两个 DMV 书面测试(<strong class="kk iu"> <em class="lf"> DMV_Test_1 </em> </strong>和<strong class="kk iu"> <em class="lf"> DMV_Test_2 </em> </strong>)组成，这两列是自变量，最后一列由因变量<strong class="kk iu"> <em class="lf"> Results </em> </strong>组成，这两列表示驾驶员已获得驾照(1)或未获得驾照(0)。</p><p id="e89d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，我们必须使用这些数据建立一个 KNN 分类模型，以预测参加了两次 DMV 笔试的司机是否会获得驾照，并使用他们在笔试中获得的分数对结果进行分类。</p><h2 id="c597" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 1:导入库</h2><p id="4177" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">和往常一样，第一步总是包括导入库，即 NumPy、Pandas 和 Matplotlib。</p><pre class="mf mg mh mi gt mq mr ms mt aw mu bi"><span id="7fcf" class="lg lh it mr b gy mv mw l mx my">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd</span></pre><h2 id="a403" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 2:导入数据集</h2><p id="319f" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，我们将从我的 GitHub 存储库中以“DMVWrittenTests.csv”的形式获取数据集。变量<strong class="kk iu"> <em class="lf"> X </em> </strong>将存储两个<strong class="kk iu"> <em class="lf"> DMV 测试</em> </strong>，变量<strong class="kk iu"> <em class="lf"> Y </em> </strong>将最终输出存储为<strong class="kk iu"> <em class="lf">结果</em></strong><strong class="kk iu"><em class="lf">。</em></strong><code class="fe mz na nb mr b">dataset.head(5)</code>用于可视化前 5 行数据。</p><pre class="mf mg mh mi gt mq mr ms mt aw mu bi"><span id="2846" class="lg lh it mr b gy mv mw l mx my">dataset = pd.read_csv('<a class="ae le" href="https://raw.githubusercontent.com/mk-gurucharan/Classification/master/DMVWrittenTests.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/mk-gurucharan/Classification/master/DMVWrittenTests.csv'</a>)</span><span id="0524" class="lg lh it mr b gy nc mw l mx my">X = dataset.iloc[:, [0, 1]].values<br/>y = dataset.iloc[:, 2].values</span><span id="f7c9" class="lg lh it mr b gy nc mw l mx my">dataset.head(5)</span><span id="5fde" class="lg lh it mr b gy nc mw l mx my">&gt;&gt;<br/>DMV_Test_1   DMV_Test_2   Results<br/>34.623660    78.024693    0<br/>30.286711    43.894998    0<br/>35.847409    72.902198    0<br/>60.182599    86.308552    1<br/>79.032736    75.344376    1</span></pre><h2 id="2f4c" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 3:将数据集分为训练集和测试集</h2><p id="da31" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，我们必须将数据集分为训练集和测试集，在训练集上将训练逻辑回归模型，在测试集上将应用训练模型对结果进行分类。其中的<code class="fe mz na nb mr b">test_size=0.25</code>表示<strong class="kk iu"><em class="lf"/></strong>数据的 25%将作为<strong class="kk iu"> <em class="lf">测试集</em> </strong>保存，剩余的 75%<strong class="kk iu"><em class="lf"/></strong>将作为<strong class="kk iu"> <em class="lf">训练集</em> </strong>用于训练。</p><pre class="mf mg mh mi gt mq mr ms mt aw mu bi"><span id="e086" class="lg lh it mr b gy mv mw l mx my">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)</span></pre><h2 id="97ff" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 4:特征缩放</h2><p id="5c56" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">这是一个附加步骤，用于对特定范围内的数据进行标准化。它也有助于加速计算。由于数据变化很大，我们使用此函数将数据范围限制在一个小范围内(-2，2)。例如，分数 62.0730638 被规范化为-0.21231162，分数 96.51142588 被规范化为 1.55187648。这样 X_train 和 X_test 的分数就归一化到一个更小的范围。</p><pre class="mf mg mh mi gt mq mr ms mt aw mu bi"><span id="1743" class="lg lh it mr b gy mv mw l mx my">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span></pre><h2 id="42da" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 5:在训练集上训练 KNN 分类模型</h2><p id="f561" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，类<code class="fe mz na nb mr b">KNeighborsClassifier</code>被导入并分配给变量<strong class="kk iu"> <em class="lf">【分类器】</em> </strong>。<code class="fe mz na nb mr b">classifier.fit()</code>功能配有<strong class="kk iu"> X_train </strong>和<strong class="kk iu"> <em class="lf"> Y_train </em> </strong>对模型进行训练。</p><pre class="mf mg mh mi gt mq mr ms mt aw mu bi"><span id="9a53" class="lg lh it mr b gy mv mw l mx my">from sklearn.neighbors import KNeighborsClassifier<br/>classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)<br/>classifier.fit(X_train, y_train)</span></pre><h2 id="ea7c" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 6:预测测试集结果</h2><p id="f31b" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这一步中，<code class="fe mz na nb mr b">classifier.predict()</code>函数用于预测测试集的值，这些值被存储到变量<code class="fe mz na nb mr b">y_pred.</code></p><pre class="mf mg mh mi gt mq mr ms mt aw mu bi"><span id="4fb2" class="lg lh it mr b gy mv mw l mx my">y_pred = classifier.predict(X_test) <br/>y_pred</span></pre><h2 id="0d33" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 7:混淆矩阵和准确性</h2><p id="95f7" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">这是分类技术中最常用的一步。在这里，我们看到了训练模型的准确性，并绘制了混淆矩阵。</p><p id="37ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">混淆矩阵是一个表，用于显示当测试集的真实值已知时，对分类问题的正确和错误预测的数量。它的格式如下</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/74881daa5f3eb9f2b0c834afe2b00c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*aDcJceSYfH7GBxJJpzwvKA.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">来源—自己</p></figure><p id="f506" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">真实值是正确预测的次数。</p><pre class="mf mg mh mi gt mq mr ms mt aw mu bi"><span id="2086" class="lg lh it mr b gy mv mw l mx my">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix(y_test, y_pred)</span><span id="91d7" class="lg lh it mr b gy nc mw l mx my">from sklearn.metrics import accuracy_score <br/>print ("Accuracy : ", accuracy_score(y_test, y_pred))<br/>cm</span><span id="10bc" class="lg lh it mr b gy nc mw l mx my">&gt;&gt;Accuracy :  0.92</span><span id="d988" class="lg lh it mr b gy nc mw l mx my">&gt;&gt;array([[11,  1],<br/>       [ 1, 12]])</span></pre><p id="c917" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上面的混淆矩阵，我们推断，在 25 个测试集数据中，23 个被正确分类，2 个被错误分类，这比逻辑回归模型好不了多少。</p><h2 id="28d3" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 8:将实际值与预测值进行比较</h2><p id="9813" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在这个步骤中，创建一个 Pandas DataFrame 来比较原始测试集(<strong class="kk iu"> <em class="lf"> y_test </em> </strong>)和预测结果(<strong class="kk iu"> <em class="lf"> y_pred </em> </strong>)的分类值。</p><pre class="mf mg mh mi gt mq mr ms mt aw mu bi"><span id="39c0" class="lg lh it mr b gy mv mw l mx my">df = pd.DataFrame({'Real Values':y_test, 'Predicted Values':y_pred})<br/>df</span><span id="1e61" class="lg lh it mr b gy nc mw l mx my">&gt;&gt; <br/>Real Values   Predicted Values<br/>0             0<br/>0             1<br/>1             1<br/>0             0<br/>0             0<br/>1             1<br/>1             1<br/>0             0<br/>0             0<br/>1             1<br/>0             0<br/>1             0<br/>1             1<br/>1             1<br/>0             0<br/>0             0<br/>0             0<br/>1             1<br/>1             1<br/>1             1<br/>1             1<br/>0             0<br/>1             1<br/>1             1<br/>0             0</span></pre><p id="e10f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然这种可视化可能没有回归那么有用，但从这一点上，我们可以看到，该模型能够以 92%的相当高的准确度对测试集值进行分类，如上面计算的那样。</p><h2 id="eadd" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">步骤 9:可视化结果</h2><p id="90a1" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在最后一步中，我们将 KNN 分类模型的结果可视化在一个沿着两个区域绘制的图上。</p><pre class="mf mg mh mi gt mq mr ms mt aw mu bi"><span id="afc7" class="lg lh it mr b gy mv mw l mx my">from matplotlib.colors import ListedColormap<br/>X_set, y_set = X_test, y_test<br/>X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),<br/>                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))<br/>plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),<br/>             alpha = 0.75, cmap = ListedColormap(('red', 'green')))<br/>plt.xlim(X1.min(), X1.max())<br/>plt.ylim(X2.min(), X2.max())<br/>for i, j in enumerate(np.unique(y_set)):<br/>    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],<br/>                c = ListedColormap(('red', 'green'))(i), label = j)<br/>plt.title('KNN Classification')<br/>plt.xlabel('DMV_Test_1')<br/>plt.ylabel('DMV_Test_2')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/901151e9d4dfaf726714b1816dfd2588.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*twORFxEy4rFAlx3Jfp0aAw.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">KNN 分类</p></figure><p id="6cde" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在该图中，值<strong class="kk iu"> <em class="lf"> 1(即，是)</em> </strong>用“<strong class="kk iu"><em class="lf"/></strong>红色绘制，值<strong class="kk iu"> <em class="lf"> 0(即，否)</em> </strong>用“<strong class="kk iu"><em class="lf"/></strong>绿色绘制。KNN 分类模型将这两个区域分开。它不像逻辑回归模型那样是线性的。因此，具有给定的两个数据点(DMV_Test_1 和 DMV_Test_2)的任何数据都可以绘制在图上，并且根据属于哪个区域，结果(获得驾驶执照)可以分类为是或否。</p><p id="0dfb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据上面的计算，我们可以看到测试集中有两个值，每个区域都有一个被错误分类的值。</p><h2 id="6d11" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">结论—</h2><p id="0caa" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">因此，在这个故事中，我们已经成功地建立了一个<strong class="kk iu"> <em class="lf"> KNN 分类</em> </strong>模型，它能够预测一个人是否能够通过笔试获得驾驶执照，并可视化结果。</p><p id="e41a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我还附上了我的 GitHub 资源库的链接，你可以在那里下载这个 Google Colab 笔记本和数据文件供你参考。</p><div class="nf ng gp gr nh ni"><a href="https://github.com/mk-gurucharan/Classification" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">MK-guru charan/分类</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">这是一个由 Python 代码组成的知识库，用于构建不同类型的分类模型，以评估和…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">github.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw mk ni"/></div></div></a></div><p id="80c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还可以在下面找到该程序对其他分类模型的解释:</p><ul class=""><li id="76f8" class="nx ny it kk b kl km ko kp kr nz kv oa kz ob ld oc od oe of bi translated"><a class="ae le" rel="noopener" target="_blank" href="/machine-learning-basics-logistic-regression-890ef5e3a272">逻辑回归</a></li><li id="fe62" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">k 近邻(KNN)分类</li><li id="ee02" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">支持向量机(SVM)分类(即将推出)</li><li id="ecf2" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">朴素贝叶斯分类(即将推出)</li><li id="1a1d" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">随机森林分类(即将推出)</li></ul><p id="6940" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在接下来的文章中，我们将会遇到更复杂的回归、分类和聚类模型。到那时，快乐的机器学习！</p></div></div>    
</body>
</html>