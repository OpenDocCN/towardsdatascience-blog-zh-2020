<html>
<head>
<title>Deploy Fastai — Transformers based NLP models using Amazon SageMaker and Creating API using AWS API Gateway and Lambda function</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Amazon SageMaker部署Fastai —基于变压器的NLP模型，并使用AWS API网关和Lambda函数创建API</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploy-fastai-transformers-based-nlp-models-using-amazon-sagemaker-and-creating-api-using-aws-7ea39bbcc021?source=collection_archive---------21-----------------------#2020-04-21">https://towardsdatascience.com/deploy-fastai-transformers-based-nlp-models-using-amazon-sagemaker-and-creating-api-using-aws-7ea39bbcc021?source=collection_archive---------21-----------------------#2020-04-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/666e4c3f44dd32589fa0949c6fc41219.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CU99y9su6oESfY78QulUkA.png"/></div></div></figure><div class=""/><div class=""><h2 id="bd27" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">Fastai-Transformers模型部署在AWS SageMaker上，并作为AWS API提供服务。</h2></div><h1 id="472f" class="kq kr jb bd ks kt ku kv kw kx ky kz la kh lb ki lc kk ld kl le kn lf ko lg lh bi translated">目录</h1><ol class=""><li id="f3cc" class="li lj jb lk b ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">介绍</li><li id="efed" class="li lj jb lk b ll ma ln mb lp mc lr md lt me lv lw lx ly lz bi translated">第1部分—导出模型并重新加载它</li><li id="4d85" class="li lj jb lk b ll ma ln mb lp mc lr md lt me lv lw lx ly lz bi translated">第2部分——使用Amazon SageMaker进行部署</li><li id="c92b" class="li lj jb lk b ll ma ln mb lp mc lr md lt me lv lw lx ly lz bi translated">第3部分——使用Amazon Lambda和Amazon API Gateway创建模型API</li><li id="d073" class="li lj jb lk b ll ma ln mb lp mc lr md lt me lv lw lx ly lz bi translated">结论</li><li id="6f5f" class="li lj jb lk b ll ma ln mb lp mc lr md lt me lv lw lx ly lz bi translated">参考</li></ol><h1 id="066c" class="kq kr jb bd ks kt ku kv kw kx ky kz la kh lb ki lc kk ld kl le kn lf ko lg lh bi translated">1.介绍</h1><p id="3d49" class="pw-post-body-paragraph mf mg jb lk b ll lm kc mh ln lo kf mi lp mj mk ml lr mm mn mo lt mp mq mr lv ij bi ms translated"><span class="l mt mu mv bm mw mx my mz na di"> T </span>何<a class="ae nb" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">变形金刚</a>库由<a class="ae nb" href="https://huggingface.co" rel="noopener ugc nofollow" target="_blank">抱脸</a>创建。这个库以前被称为pytorch-transformers或pytorch-pretrained-bert，它汇集了40多个最先进的预训练NLP模型(bert、GPT-2、罗伯塔、CTRL……)。这是一个自以为是的库，专为寻求使用/研究/扩展大规模变压器模型的NLP研究人员而建。</p><p id="477d" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">该实现提供了有趣的附加工具，如tokenizer、optimizer或scheduler。它可以是自给自足的，但是将它并入<a class="ae nb" href="https://docs.fast.ai" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jc"> fastai </strong> </a>库提供了与强大的fastai工具兼容的更简单的实现，例如<strong class="lk jc">区分学习率</strong>、<strong class="lk jc">逐步解冻</strong>或<strong class="lk jc">倾斜三角形学习率</strong>。这里的重点是轻松获得最先进的结果，并“<strong class="lk jc">让NLP再次变得不酷</strong>”。</p><p id="a0d6" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">我假设您已经实现了您的模型，我不打算讨论这一部分，本文将只讨论使用AWS服务的部署部分，但是如果您需要查看实现，请查看Kaggle上的这个<a class="ae nb" href="https://www.kaggle.com/melissarajaram/roberta-fastai-huggingface-transformers" rel="noopener ugc nofollow" target="_blank">内核</a>。</p><h1 id="3296" class="kq kr jb bd ks kt ku kv kw kx ky kz la kh lb ki lc kk ld kl le kn lf ko lg lh bi translated">2.第1部分—导出模型并重新加载它</h1><p id="f932" class="pw-post-body-paragraph mf mg jb lk b ll lm kc mh ln lo kf mi lp mj mk ml lr mm mn mo lt mp mq mr lv ij bi translated"><strong class="lk jc"> 2.1。</strong> <strong class="lk jc">导出模型</strong></p><p id="6976" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">首先，我们需要使用fastai库的学习模块将我们的模型导出为PKL文件:</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><h2 id="bfdc" class="nn kr jb bd ks no np dn kw nq nr dp la lp ns nt lc lr nu nv le lt nw nx lg ny bi translated">2.2.加载模型:</h2><p id="7fda" class="pw-post-body-paragraph mf mg jb lk b ll lm kc mh ln lo kf mi lp mj mk ml lr mm mn mo lt mp mq mr lv ij bi translated">当使用自定义的transformers模型(如Bert)时，您需要重新定义自定义模型的体系结构，以便在加载它时，load_learner()函数会查找特定的函数以用于新的预测。</p><p id="ab4b" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">在加载模型之前，我们需要重新定义我们在培训中使用的定制transformer模型。</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="02e7" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">然后我们可以加载我们的模型并进行预测:</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><h1 id="f660" class="kq kr jb bd ks kt ku kv kw kx ky kz la kh lb ki lc kk ld kl le kn lf ko lg lh bi translated">3.第2部分——使用Amazon SageMaker进行部署</h1><p id="fbb7" class="pw-post-body-paragraph mf mg jb lk b ll lm kc mh ln lo kf mi lp mj mk ml lr mm mn mo lt mp mq mr lv ij bi translated">用亚马逊自己的话说:</p><blockquote class="nz oa ob"><p id="fc84" class="mf mg oc lk b ll nc kc mh ln nd kf mi od ne mk ml oe nf mn mo of ng mq mr lv ij bi translated"><a class="ae nb" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank"> <em class="jb">亚马逊SageMaker </em> </a> <em class="jb">为每一个开发者和数据科学家提供了快速构建、训练和部署机器学习模型的能力。Amazon SageMaker是一个完全托管的服务，涵盖了整个机器学习工作流，以标记和准备您的数据，选择算法，训练模型，调整和优化它以进行部署，进行预测，并采取行动。您的模型以更少的工作量和更低的成本更快地投入生产。</em></p></blockquote><p id="0ebe" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">SageMaker提供了一个框架来训练和部署您的模型。一切都在Docker容器中运行。</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/cfe4161603562d7fd1db3e7abc6ee51c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t450tKo0U34TxztzIYrC3A.jpeg"/></div></div><p class="og oh gj gh gi oi oj bd b be z dk translated">AWS SageMaker的用户界面</p></figure><p id="6cd0" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">因为我们将使用Amazon SageMaker Python SDK，所以我们需要一个笔记本实例来运行我们的代码。</p><p id="ad52" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated"><strong class="lk jc"> 3.1。</strong> <strong class="lk jc">使用SageMaker Python SDK部署模型</strong></p><p id="4e19" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">来自SageMaker Python SDK文档:</p><blockquote class="nz oa ob"><p id="fc90" class="mf mg oc lk b ll nc kc mh ln nd kf mi od ne mk ml oe nf mn mo of ng mq mr lv ij bi translated">Amazon SageMaker Python SDK是一个开源库，用于在Amazon SageMaker上训练和部署机器学习模型。</p><p id="c774" class="mf mg oc lk b ll nc kc mh ln nd kf mi od ne mk ml oe nf mn mo of ng mq mr lv ij bi translated">通过SDK，你可以使用流行的深度学习框架、亚马逊提供的算法或你自己的内置于SageMaker兼容的Docker图像中的算法来训练和部署模型。</p></blockquote><p id="43b3" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated"><strong class="lk jc"> 3.1.1。</strong> <strong class="lk jc">准备环境:</strong></p><p id="0b64" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">部署的总体架构如下:</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ok"><img src="../Images/5b5034cdda389aadc4ed63888f955b69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zMlVm34vzJgsjcRPIJRV7Q.jpeg"/></div></div><p class="og oh gj gh gi oi oj bd b be z dk translated">部署架构</p></figure><p id="7dcf" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">将您的模型(PKL文件)上传到笔记本实例后，我们需要将它压缩，这样我们就可以将它上传到S3。</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="f58b" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">然后，我们可以将它上传到S3存储，如下所示:</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="b42a" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">现在我们已经准备好将我们的模型部署到SageMaker模型托管服务中。我们将使用SageMaker Python SDK和Amazon SageMaker开源PyTorch容器，因为该容器支持fast.ai库。使用一个预定义的Amazon SageMaker容器可以很容易地编写一个脚本，然后在Amazon SageMaker中运行它。</p><p id="9520" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">为了在SageMaker中服务模型，我们需要一个实现4个方法的脚本:<strong class="lk jc"> model_fn，input_fn，predict_fn &amp; output_fn </strong>。</p><ul class=""><li id="e065" class="li lj jb lk b ll nc ln nd lp ol lr om lt on lv oo lx ly lz bi translated">model_fn方法需要从磁盘上保存的权重中加载PyTorch模型。</li><li id="e3e1" class="li lj jb lk b ll ma ln mb lp mc lr md lt me lv oo lx ly lz bi translated">input_fn方法需要将invoke请求体反序列化为我们可以对其执行预测的对象。</li><li id="10e7" class="li lj jb lk b ll ma ln mb lp mc lr md lt me lv oo lx ly lz bi translated">predict_fn方法接受反序列化的请求对象，并对加载的模型执行推理。</li><li id="63e4" class="li lj jb lk b ll ma ln mb lp mc lr md lt me lv oo lx ly lz bi translated">output_fn方法获取预测结果，并根据响应内容类型将其序列化。</li></ul><p id="a858" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">方法<strong class="lk jc"> input_fn </strong>和<strong class="lk jc"> output_fn </strong>是可选的，如果省略，SageMaker将假定输入和输出对象是NPY格式类型，内容类型为application/x-npy。</p><p id="45a1" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">这是serve.py脚本:</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="7c06" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">另一件事是将这个脚本放在一个文件夹中，并将其命名为my_src，我们将添加一个需求文本文件；来强制SageMaker安装所需的库，比如Fastai。</p><p id="c04c" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">我的requirements.txt文件仅包含以下内容:</p><blockquote class="nz oa ob"><p id="4043" class="mf mg oc lk b ll nc kc mh ln nd kf mi od ne mk ml oe nf mn mo of ng mq mr lv ij bi translated">fastai==1.0.52 <br/>变压器</p></blockquote><p id="3bd5" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">你可以在SageMaker Python SDK文档<a class="ae nb" href="https://sagemaker.readthedocs.io/en/stable/using_pytorch.html#using-third-party-libraries" rel="noopener ugc nofollow" target="_blank">这里</a>读到更多关于这个的内容。</p><p id="41d7" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated"><strong class="lk jc"> 3.1.2。</strong> <strong class="lk jc">部署型号:</strong></p><p id="959b" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">首先，我们需要创建一个RealTimePredictor类来接受JSON/application item作为输入和输出JSON。默认行为是接受NumPy数组。</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="f8c5" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">我们需要得到IAM角色ARN给SageMaker权限，以读取我们的模型从S3人工制品。</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="2ccb" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">我们将把我们的模型部署到实例类型ml.p2.xlarge。我们将传入我们的服务脚本的名称，例如serve.py。我们还将传入我们之前上传的模型的S3路径。</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="c208" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">SageMaker需要一段时间来为推断准备好端点。</p><p id="2319" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated"><strong class="lk jc"> 3.2.3。</strong> <strong class="lk jc">使用Boto3调用端点:</strong></p><p id="f2ef" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">Boto是Python的Amazon Web Services (AWS) SDK。它使Python开发人员能够创建、配置和管理AWS服务，如EC2和S3。Boto提供了一个易于使用的、面向对象的API，以及对AWS服务的底层访问。</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><h1 id="2e73" class="kq kr jb bd ks kt ku kv kw kx ky kz la kh lb ki lc kk ld kl le kn lf ko lg lh bi translated">4.第3部分——使用Amazon Lambda和Amazon API Gateway创建模型API</h1><p id="6be0" class="pw-post-body-paragraph mf mg jb lk b ll lm kc mh ln lo kf mi lp mj mk ml lr mm mn mo lt mp mq mr lv ij bi translated">我们将使用API Gateway和AWS Lambda调用Amazon SageMaker部署的模型端点。</p><p id="1487" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">下图显示了如何使用无服务器架构调用部署的模型。从客户端开始，客户端脚本调用Amazon API Gateway API动作并传递参数值。API网关是向客户端提供API的层。此外，它还密封了后端，这样AWS Lambda就可以在一个受保护的私有网络中运行。API Gateway将参数值传递给Lambda函数。Lambda函数解析该值并将其发送到SageMaker模型端点。该模型执行预测，并将预测值返回给AWS Lambda。Lambda函数解析返回值并将其发送回API Gateway。API网关用该值响应客户端。</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div class="gh gi op"><img src="../Images/74bdaa5a5e0c218749e6c994ce1b387d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*A96E9mJJTch-R2RH5Pf2iA.jpeg"/></div><p class="og oh gj gh gi oi oj bd b be z dk translated">部署架构</p></figure><p id="adac" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated"><strong class="lk jc"> 4.1。</strong>T13】创建亚马逊Lambda函数</p><p id="477c" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated"><strong class="lk jc"> AWS Lambda </strong>是一个事件驱动的无服务器计算平台，由亚马逊提供，作为亚马逊网络服务的一部分。它是一种计算服务，运行代码以响应事件，并自动管理该代码所需的计算资源。</p><p id="3f42" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">为了创建一个函数，我们指定它的名称和运行时环境(在我们的例子中是Python 3):</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oq"><img src="../Images/744cdeb5cdaebdc637f93fc1ec0d76c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*etbSbcn0v_qQ889LcetEqg.jpeg"/></div></div></figure><p id="e894" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">然后，我们使用自定义函数调用使用Boto3库的端点，如下所示:</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="05ae" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated"><strong class="lk jc"> 4.2。</strong> <strong class="lk jc">创建亚马逊Web API网关实例:</strong></p><p id="a916" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">Amazon API Gateway是一个完全托管的服务，使开发人员可以轻松地创建、发布、维护、监控和保护任何规模的API。</p><p id="a8e9" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">我们创建一个API并将其关联到Lambda函数作为一个集成，如下所示:</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi or"><img src="../Images/a0c912e7baf6f5d4244a31fdae468a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WdpTNNTov9U4a8BxE7PKpA.jpeg"/></div></div></figure><p id="d4ba" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">然后我们需要确定API的路由，我们将只使用一个路由“/classify”和“POST”作为我们的请求方法。</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi os"><img src="../Images/1a917d57214ed43bac688a51b793ff24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yIXbxeVprbft9XYN8iZ7tw.jpeg"/></div></div></figure><p id="d335" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated"><strong class="lk jc"> 4.3。</strong> <strong class="lk jc">测试你的亚马逊API </strong></p><p id="bf00" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">现在我们有了Lambda函数、API网关和测试数据，让我们使用Postman来测试它，Postman是一个用于测试web服务的HTTP客户端。</p><p id="01ae" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">当我们部署您的API网关时，它提供了如下所示的调用URL:</p><p id="5296" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated"><a class="ae nb" href="https://{restapi_id}.execute-api.{region}.amazonaws.com/{stage_name}/{resource_name}" rel="noopener ugc nofollow" target="_blank"> https://{restapi_id}。执行-api。{ region } . Amazon AWS . com/{ stage _ name }/{ resource _ name }</a></p><p id="0def" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">在Postman中，我们放置调用URL，并选择POST作为请求方法。在Body选项卡中，我们放置要分类的文本，如下图所示。</p><p id="6b4c" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">然后我们发送我们的请求，它将返回JSON item作为包含模型预测的响应。</p><figure class="nh ni nj nk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ot"><img src="../Images/4bc929ce0ae3ee7384f6957f0f9bb85d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8weEBFxtIf7rZtAg-5Ti3A.png"/></div></div><p class="og oh gj gh gi oi oj bd b be z dk translated">使用postman测试API</p></figure><p id="87d7" class="pw-post-body-paragraph mf mg jb lk b ll nc kc mh ln nd kf mi lp ne mk ml lr nf mn mo lt ng mq mr lv ij bi translated">我们还可以使用python中的请求库，如下所示:</p><figure class="nh ni nj nk gt is"><div class="bz fp l di"><div class="nl nm l"/></div></figure><h1 id="47df" class="kq kr jb bd ks kt ku kv kw kx ky kz la kh lb ki lc kk ld kl le kn lf ko lg lh bi translated">结论</h1><p id="389b" class="pw-post-body-paragraph mf mg jb lk b ll lm kc mh ln lo kf mi lp mj mk ml lr mm mn mo lt mp mq mr lv ij bi translated">就是这样。您已经创建了一个由Amazon SageMaker部署和托管的模型端点。然后创建了调用端点的无服务器组件(一个API网关和一个Lambda函数)。现在你知道如何使用无服务器技术调用亚马逊SageMaker托管的机器学习模型端点了。</p><h1 id="ee7d" class="kq kr jb bd ks kt ku kv kw kx ky kz la kh lb ki lc kk ld kl le kn lf ko lg lh bi translated">参考</h1><div class="ip iq gp gr ir ou"><a href="https://course.fast.ai/start_sagemaker.html" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd jc gy z fp oz fr fs pa fu fw ja bi translated">亚马逊SageMaker</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">这是使用亚马逊SageMaker的程序员实用深度学习fast.ai课程v4的快速入门指南…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">course.fast.ai</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi ix ou"/></div></div></a></div><div class="ip iq gp gr ir ou"><a href="https://aws.amazon.com/blogs/machine-learning/call-an-amazon-sagemaker-model-endpoint-using-amazon-api-gateway-and-aws-lambda/" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd jc gy z fp oz fr fs pa fu fw ja bi translated">使用Amazon API Gateway和AWS Lambda | Amazon Web调用Amazon SageMaker模型端点…</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">在AWS机器学习研讨会上，客户经常会问，“在我部署了一个端点之后，我该从那里去哪里？”你可以…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">aws.amazon.com</p></div></div><div class="pd l"><div class="pj l pf pg ph pd pi ix ou"/></div></div></a></div><div class="ip iq gp gr ir ou"><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-deploy-model.html" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd jc gy z fp oz fr fs pa fu fw ja bi translated">步骤6.1:将模型部署到SageMaker托管服务</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">要在SageMaker托管服务中部署模型，您可以使用Amazon SageMaker Python SDK或AWS SDK</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">docs.aws.amazon.com</p></div></div></div></a></div></div></div>    
</body>
</html>