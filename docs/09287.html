<html>
<head>
<title>Probabilistic Programming and Bayesian Inference for Time Series Analysis and Forecasting in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中时间序列分析和预测的概率规划和贝叶斯推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/probabilistic-programming-and-bayesian-inference-for-time-series-analysis-and-forecasting-b5eb22114275?source=collection_archive---------7-----------------------#2020-07-03">https://towardsdatascience.com/probabilistic-programming-and-bayesian-inference-for-time-series-analysis-and-forecasting-b5eb22114275?source=collection_archive---------7-----------------------#2020-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a52c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Python 中时间序列数据分析和预测的贝叶斯方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6c50ae90d40e4f4e59806cad76802464.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MdWW53xVRLftGXv0Nz8kYg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片</p></figure><p id="3137" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如[1][2]所述，<a class="ae lu" href="https://en.wikipedia.org/wiki/Time_series" rel="noopener ugc nofollow" target="_blank">时间序列</a>数据包括来自金融、医学、科学研究(如全球变暖、语音分析、地震)等不同领域的多种真实实验数据。时间序列预测在各个领域都有很多实际应用，例如商业预测(如销售、股票)、天气、死亡等[2]。统计建模和推理(如 ARIMA 模型)[1][2]是时间序列分析和预测的流行方法之一。</p><p id="e018" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有两种统计推断方法:</p><ul class=""><li id="65cc" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated"><a class="ae lu" href="https://en.wikipedia.org/wiki/Bayesian_inference" rel="noopener ugc nofollow" target="_blank">贝叶斯推断</a></li><li id="b1ff" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><a class="ae lu" href="https://en.wikipedia.org/wiki/Frequentist_inference" rel="noopener ugc nofollow" target="_blank">频率主义者的推论</a></li></ul><p id="aab1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">贝叶斯推理的哲学是将概率视为事件可信度的度量[3][4][5]，并使用<a class="ae lu" href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener ugc nofollow" target="_blank">贝叶斯定理</a>随着更多<a class="ae lu" href="https://en.wikipedia.org/wiki/Evidence" rel="noopener ugc nofollow" target="_blank">证据</a>或<a class="ae lu" href="https://en.wikipedia.org/wiki/Information" rel="noopener ugc nofollow" target="_blank">信息</a>变得可用来更新概率，而频率主义推理的哲学将概率视为事件的长期频率[3]。</p><p id="bbde" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一般来说，只有在大量数据样本可用的情况下，我们才能使用 Frequentist 推断。相比之下，贝叶斯推理可以应用于大数据集和小数据集。</p><p id="488e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我使用 Kaggle [6]的一个小的(只有 36 个数据样本)<a class="ae lu" href="https://www.kaggle.com/djokester/sales-of-shampoo-over-a-three-year-period" rel="noopener ugc nofollow" target="_blank">洗发水销售</a>时间序列数据集来演示如何使用概率编程来实现贝叶斯分析和推理，用于时间序列分析和预测。</p><p id="bb39" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">文章的其余部分安排如下:</p><ul class=""><li id="f536" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">贝叶斯定理</li><li id="449e" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><a class="ae lu" href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo" rel="noopener ugc nofollow" target="_blank"> MCMC </a>基础知识(马尔可夫链蒙特卡罗)</li><li id="8b6e" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">概率规划</li><li id="07ed" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">时间序列模型和预测[3]</li><li id="187c" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">摘要</li></ul><h1 id="68d0" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">1.贝叶斯定理</h1><p id="5122" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">设<strong class="la iu"> <em class="ng"> H </em> </strong>为事件将发生的假设，<strong class="la iu"> <em class="ng"> D </em> </strong>为新观察到的数据(即证据)，而<strong class="la iu"> <em class="ng"> p </em> </strong>为概率，贝叶斯定理可描述如下[5]:</p><p id="ee49" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">p(H | D) = p(H) x p(D | H) / p(D)</p><ul class=""><li id="8ea4" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">p(H):在我们看到任何数据之前，假设的先验概率</li><li id="d98c" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">p(H | D):我们观察新数据后假设的后验概率</li><li id="c51e" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">p(D | H):似然，假设下数据的概率</li><li id="fad9" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">p(D):任何假设下数据的概率</li></ul><h1 id="aa4f" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">2.MCMC 基础</h1><p id="c83a" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated"><a class="ae lu" href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo" rel="noopener ugc nofollow" target="_blank"> MCMC </a>由一类<a class="ae lu" href="https://en.wikipedia.org/wiki/Algorithm" rel="noopener ugc nofollow" target="_blank">算法</a>组成，用于从<a class="ae lu" href="https://en.wikipedia.org/wiki/Probability_distribution" rel="noopener ugc nofollow" target="_blank">概率分布</a>中取样。广泛使用的算法之一是<a class="ae lu" href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm" rel="noopener ugc nofollow" target="_blank">Metropolis–Hastings 算法</a>。基本思想是随机生成大量代表性样本，以逼近多维连续参数空间上的连续分布[4]。</p><p id="b83d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Metropolis 算法的高级描述可以表示如下[3]:</p><ul class=""><li id="f21e" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">步骤 1:从 n 参数空间中的当前位置(即，n 参数值的向量)开始</li><li id="ae76" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">步骤 2:建议移动到新位置(n 参数值的新向量)</li><li id="e8f6" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">步骤 3:基于先前位置的先验概率、数据以及根据贝叶斯定理[3]从数据及其先验分布计算的后验概率，接受或拒绝提议的移动。</li><li id="d836" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">第四步:如果提议被接受，那就去新的职位。否则，不要动。</li><li id="4e2e" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">步骤 5:如果尚未达到预先指定的步骤数，请返回步骤 1 重复该过程。否则，返回所有接受的位置。</li></ul><p id="4136" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">MCMC 的基础是贝叶斯定理。从假设和数据的给定先验分布开始，上述 Metropolis 过程的每次迭代都会积累新数据，并使用它来更新假设，以随机行走的方式选择下一步[4]。接受的步骤是假设的后验分布的样本。</p><h1 id="0eac" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">3.概率规划</h1><p id="00be" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">有多个 Python 库可用于编程贝叶斯分析和推理[3][5][7][8]。这种类型的编程称为概率编程[3][8]，相应的库称为概率编程语言。PyMC [3][7]和张量流概率[8]就是两个例子。</p><p id="3ef5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我使用 PyMC [3][7]作为概率编程语言来分析和预测洗发水的销售[6]作为演示目的。</p><h1 id="354f" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">4.时间序列模型与预测</h1><p id="70a6" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">本节描述了如何使用 PyMC [7]对时间序列预测的贝叶斯分析和推理进行编程。</p><h2 id="fdea" class="nh mk it bd ml ni nj dn mp nk nl dp mt lh nm nn mv ll no np mx lp nq nr mz ns bi translated">4.1 数据加载</h2><p id="411d" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">一旦 Kaggle [6]三年洗发水销售的数据集下载到本地机器上，数据集 csv 文件就可以加载到 Pandas 数据帧中，如下所示:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="b5ef" class="nh mk it nu b gy ny nz l oa ob">df = pd.read_csv('./data/sales-of-shampoo-over-a-three-ye.csv')<br/>df.head(12)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/6e6f776c70c14d4a158324cc9cf6c7bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Qxvu7IpPaiuvs2OwGp8EMg.png"/></div></figure><p id="fe35" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据框架中的销售列可以提取为时间序列数据集:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="becd" class="nh mk it nu b gy ny nz l oa ob">sales = df['Sales of shampoo over a three year period']<br/>sales.plot(figsize=(16,5))</span></pre><p id="2e96" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面这个图是三年(36 个月)洗发水的销量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/defa130d28af0b1e2abbcf6006df7dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0l9jsmaiXACMf-WmP0YpUw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd oe">图 1: </strong>三年(36 个月)洗发水销量。</p></figure><h2 id="59cc" class="nh mk it bd ml ni nj dn mp nk nl dp mt lh nm nn mv ll no np mx lp nq nr mz ns bi translated">4.2 建模</h2><p id="d25e" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">贝叶斯建模的良好开端[3]是考虑一个给定的数据集可能是如何生成的。以图 1 中洗发水时间序列数据的销售为例，我们可以从思考开始:</p><ul class=""><li id="62dd" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">由于数据集从左下角到右上角大致形成一条直线，因此数据集可能是由销售中带有随机误差的时间线性函数生成的。</li><li id="af00" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">随机误差可能遵循均值为零且标准偏差未知的正态分布<em class="ng"> std </em>。</li></ul><p id="e8a4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们知道一个线性函数由两个参数决定:<a class="ae lu" href="https://en.wikipedia.org/wiki/Slope" rel="noopener ugc nofollow" target="_blank">斜率</a>T6】β和<a class="ae lu" href="http://www.columbia.edu/itc/sipa/math/intercepts.html" rel="noopener ugc nofollow" target="_blank">截距</a>T10】α:</p><p id="5a57" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ng">销售</em> = <em class="ng">贝塔</em> x <em class="ng"> t </em> + <em class="ng">阿尔法</em> + <em class="ng">误差</em></p><p id="d28d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了估计时间的线性函数可能是什么，我们可以将<a class="ae lu" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">线性回归</a>机器学习模型拟合到给定的数据集中，以找到斜率和截距:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="ec51" class="nh mk it nu b gy ny nz l oa ob">import numpy as np<br/>from sklearn.linear_model import LinearRegression</span><span id="f017" class="nh mk it nu b gy of nz l oa ob">X1 = sales.index.values<br/>Y1 = sales.values<br/>X = X1.reshape(-1, 1)<br/>Y = Y1.reshape(-1, 1)<br/>reg = LinearRegression().fit(X, Y)</span><span id="1f73" class="nh mk it nu b gy of nz l oa ob">reg.coef_, reg.intercept_</span></pre><p id="92a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<em class="ng"> reg.coef_ </em> = 12.08 为斜率，<em class="ng"> reg.intercept_ </em> = 101.22 为截距。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="ac16" class="nh mk it nu b gy ny nz l oa ob">Y_reg = 12.08 * X1 + 101.22</span><span id="e14e" class="nh mk it nu b gy of nz l oa ob">def plot_df(x, y, y_reg, title="", xlabel='Date', ylabel='Value', dpi=100):<br/>    plt.figure(figsize=(16,5), dpi=dpi)<br/>    plt.plot(x, y, color='tab:blue')<br/>    plt.plot(x, y_reg, color='tab:red')<br/>    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)<br/>    plt.show()</span><span id="d8ab" class="nh mk it nu b gy of nz l oa ob">plot_df(x=X1, y=Y1, y_reg=Y_reg, title='Sales')</span></pre><p id="15f5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面的代码在蓝色销售曲线上绘制了红色回归线:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/5a33cdf9fe0c5d34cc20a06d1103debe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5brqrKT-n1ImpcATBgfPLg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd oe">图 2: </strong>三年(36 个月)洗发水销量，回归线为红色。</p></figure><p id="372f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">回归线的斜率和截距只是基于有限数据的估计。考虑到不确定性，我们可以将它们表示为正态随机变量，将确定的斜率和截距表示为平均值。这在 PyMC [7]中实现如下:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="9f3d" class="nh mk it nu b gy ny nz l oa ob">beta = pm.Normal("beta", mu=12, sd=10)<br/>alpha = pm.Normal("alpha", mu=101, sd=10)</span></pre><p id="aff9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，为了处理不确定性，我们可以使用 PyMC 将误差的标准偏差表示为在[0，100]范围内的均匀随机变量:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="5794" class="nh mk it nu b gy ny nz l oa ob">std = pm.Uniform("std", 0, 100)</span></pre><p id="8a0f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有了随机变量<em class="ng"> std </em>、<em class="ng"> beta </em>、<em class="ng"> alpha </em>，具有不确定性的回归线可以用 PyMC [7]表示:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="acf6" class="nh mk it nu b gy ny nz l oa ob">mean = pm.Deterministic("mean", alpha + beta * X)</span></pre><p id="9d87" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">利用具有不确定性的回归线，洗发水销售时间序列数据的先验分布可以在 PyMC 中编程:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="d50b" class="nh mk it nu b gy ny nz l oa ob">obs = pm.Normal("obs", mu=mean, sd=std, observed=Y)</span></pre><p id="0386" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用上述先验分布作为参数(即<em class="ng">α</em>、<em class="ng">β</em>、<em class="ng"> std </em>)空间中的起始位置，我们可以使用 PyMC 中的<a class="ae lu" href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm" rel="noopener ugc nofollow" target="_blank">Metropolis–Hastings 算法</a>执行 MCMC:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="78aa" class="nh mk it nu b gy ny nz l oa ob">import pymc3 as pm</span><span id="fec5" class="nh mk it nu b gy of nz l oa ob">with pm.Model() as model:<br/>    std = pm.Uniform("std", 0, 100)<br/>    <br/>    beta = pm.Normal("beta", mu=12, sd=10)<br/>    alpha = pm.Normal("alpha", mu=101, sd=10)<br/>    <br/>    mean = pm.Deterministic("mean", alpha + beta * X)<br/>    <br/>    obs = pm.Normal("obs", mu=mean, sd=std, observed=Y)<br/>    <br/>    trace = pm.sample(100000, step=pm.Metropolis())<br/>    burned_trace = trace[20000:]</span></pre><p id="ee6f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总共有 100，000 个被接受的步骤，称为<em class="ng">跟踪</em>。我们忽略前 20，000 个可接受的步骤，以避免收敛前的磨合阶段[3][4]。换句话说，我们只使用磨合期后的公认步骤进行贝叶斯推断。</p><h2 id="ab25" class="nh mk it bd ml ni nj dn mp nk nl dp mt lh nm nn mv ll no np mx lp nq nr mz ns bi translated">4.3 后验分析</h2><p id="4d56" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">以下代码描绘了老化期后<em class="ng"> std </em>、<em class="ng"> alpha </em>和<em class="ng"> beta </em>的轨迹:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="d791" class="nh mk it nu b gy ny nz l oa ob">pm.plots.traceplot(burned_trace, varnames=["std", "beta", "alpha"])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/4c189321f566a32a11bc364167a25599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kL6Vi7LJTFt6PCKlg50pPQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd oe">图 3:</strong>STD、alpha、beta 的痕迹。</p></figure><p id="9518" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ng"> std </em>、<em class="ng"> alpha </em>和<em class="ng"> beta </em>的后验分布可以绘制如下:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="3ea6" class="nh mk it nu b gy ny nz l oa ob">pm.plot_posterior(burned_trace, varnames=["std", "beta", "alpha"])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/e3d06333d54e3eb1e84b059640b36bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*444eUcehXDsw5M3rx2EEdw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd oe">图 4:</strong>STD、alpha、beta 的后验分布。</p></figure><p id="e1b9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ng"> std </em>、<em class="ng"> alpha </em>和<em class="ng"> beta </em>的个别痕迹可以提取<em class="ng"> </em>进行分析:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="094f" class="nh mk it nu b gy ny nz l oa ob">std_trace = burned_trace['std']<br/>beta_trace = burned_trace['beta']<br/>alpha_trace = burned_trace['alpha']</span></pre><p id="4fdd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以用任何指定的步数(如 1000)放大<em class="ng"> std </em>的轨迹细节:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="6fb3" class="nh mk it nu b gy ny nz l oa ob">pd.Series(std_trace[:1000]).plot()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/1817ffc03049555200b1727d27b767b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s0TGEJ5t7SswvOJmUOLp3w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd oe">图 5: </strong>放大 std 的痕迹。</p></figure><p id="78b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，我们可以分别放大<em class="ng"> alpha </em>和<em class="ng"> beta </em>的轨迹细节:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="3d0c" class="nh mk it nu b gy ny nz l oa ob">pd.Series(beta_trace[:1000]).plot()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/4f97e9194b116c1b79a408951d512bd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*keVwESsn6YfLUP5p9eqdmA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd oe">图 6: </strong>放大贝塔的踪迹。</p></figure><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="0387" class="nh mk it nu b gy ny nz l oa ob">pd.Series(alpha_trace[:1000]).plot()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/74074f930ab75c6b44a8e72bd9c5010f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Txzzl16egC_cr0DvcCzI3Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd oe">图 7: </strong>放大 alpha 的痕迹。</p></figure><p id="2b0e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">图 5、6 和 7 显示<em class="ng"> std </em>、<em class="ng"> alpha </em>和<em class="ng"> beta </em>的后验分布具有良好的混合频率，因此自相关性较低，这表明 MCMC 收敛【3】。</p><h2 id="20c5" class="nh mk it bd ml ni nj dn mp nk nl dp mt lh nm nn mv ll no np mx lp nq nr mz ns bi translated">4.4 预测</h2><p id="9d16" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">可以计算出<em class="ng"> std </em>、<em class="ng"> alpha </em>和<em class="ng"> beta </em>的后验分布的平均值:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="9fb8" class="nh mk it nu b gy ny nz l oa ob">std_mean = std_trace.mean()<br/>beta_mean = beta_trace.mean()<br/>alpha_mean = alpha_trace.mean()</span></pre><ul class=""><li id="58b1" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated"><em class="ng">标准平均值</em> = 79.41</li><li id="a96b" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><em class="ng"> beta_mean </em> = 12.09</li><li id="0018" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><em class="ng"> alpha_mean </em> = 101.03</li></ul><p id="5ba2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">洗发水销售的预测可以建模如下:</p><p id="2052" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ng">Sale(t)</em>=<em class="ng">beta _ mean</em>x<em class="ng">t</em>+<em class="ng">alpha _ mean</em>+<em class="ng">误差</em></p><p id="e022" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<em class="ng">误差</em>服从正态分布，均值为 0，标准差为<em class="ng"> std_mean </em>。</p><p id="f321" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用上面的模型，给定任意数量的时间步长(例如 72)，我们可以生成销售的时间序列:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="2cd8" class="nh mk it nu b gy ny nz l oa ob">length = 72<br/>x1 = np.arange(length)<br/>mean_trace = alpha_mean + beta_mean * x1<br/>normal_dist = pm.Normal.dist(0, sd=std_mean)<br/>errors = normal_dist.random(size=length)<br/>Y_gen = mean_trace + errors<br/>Y_reg1 = mean_trace</span></pre><p id="8201" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">给定 36 个月的数据，下面的代码绘制了未来 36 个月(从第 37 个月到第 72 个月)的销售预测。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="1051" class="nh mk it nu b gy ny nz l oa ob">plot_df(x=x1, y=Y_gen, y_reg=Y_reg1, title='Sales')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/eb00d437f37151bad56da6ad5cc32e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b9DXE2uTXIfksoq25KDSYQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd oe">图 8: </strong>预测未来 36 个月(从第 37 个月到第 72 个月)的销售额。</p></figure><h1 id="1e2e" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">5.摘要</h1><p id="89be" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">在本文中，我使用来自 Kaggle [6]的小型<a class="ae lu" href="https://www.kaggle.com/djokester/sales-of-shampoo-over-a-three-year-period" rel="noopener ugc nofollow" target="_blank">洗发水</a>【6】时间序列数据集来展示如何使用 PyMC [3][7]作为 Python 概率编程语言来实现时间序列预测的贝叶斯分析和推理。</p><p id="4b95" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">概率编程语言的另一种选择是<a class="ae lu" href="https://github.com/tensorflow/probability" rel="noopener ugc nofollow" target="_blank">张量流概率</a>【8】。我在本文中选择 PyMC 有两个原因。一个是 PyMC 比张量流概率更容易理解。另一个原因是 Tensorflow probability 正在从 Tensorflow 1.x 迁移到 Tensorflow 2.x 的过程中，缺少 Tensorflow 2.x 的 Tensorflow probability 文档。</p><h1 id="5214" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">参考</h1><ol class=""><li id="99a3" class="lv lw it la b lb nb le nc lh on ll oo lp op lt oq mb mc md bi translated"><a class="ae lu" href="https://medium.com/p/common-time-series-data-analysis-methods-and-forecasting-models-in-python-f0565b68a3d8?source=email-80e8f2faf4bc--writer.postDistributed&amp;sk=24961c5af213777f4e8dcdd00b290004" rel="noopener">Python 中常用的时间序列数据分析方法和预测模型</a></li><li id="950d" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt oq mb mc md bi translated">R.H. Shumway 和 D.S. Stoffer，时间序列分析及其应用，第 4 版，施普林格，2017 年</li><li id="8497" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt oq mb mc md bi translated">C.戴维森-皮隆，《黑客的贝叶斯方法，概率编程和贝叶斯推理》，艾迪森-韦斯利，2016 年</li><li id="333f" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt oq mb mc md bi translated">J.K. Kruschke,《做贝叶斯数据分析》,与 R、JAGS 和斯坦合著，学术出版社，2015 年</li><li id="65fd" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt oq mb mc md bi translated">A.B .唐尼，思考贝氏，奥赖利，2013</li><li id="2914" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt oq mb mc md bi translated"><a class="ae lu" href="https://www.kaggle.com/djokester/sales-of-shampoo-over-a-three-year-period" rel="noopener ugc nofollow" target="_blank">三年内洗发水的销售额</a></li><li id="7877" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt oq mb mc md bi translated"><a class="ae lu" href="https://docs.pymc.io/" rel="noopener ugc nofollow" target="_blank"> PyMC3 </a></li><li id="798a" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt oq mb mc md bi translated"><a class="ae lu" href="https://github.com/tensorflow/probability" rel="noopener ugc nofollow" target="_blank">张量流概率</a></li><li id="4aac" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt oq mb mc md bi translated">Github<a class="ae lu" href="https://github.com/yzzhang/machine-learning/tree/master/probabilistic_programming" rel="noopener ugc nofollow" target="_blank">中的 Jupyter 笔记本</a></li></ol></div></div>    
</body>
</html>