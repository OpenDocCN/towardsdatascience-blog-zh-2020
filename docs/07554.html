<html>
<head>
<title>Introduction to NLP - Part 4: Supervised text classification model in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理导论第 4 部分:Python 中的监督文本分类模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-nlp-part-4-supervised-text-classification-model-in-python-96e9709b4267?source=collection_archive---------23-----------------------#2020-06-07">https://towardsdatascience.com/introduction-to-nlp-part-4-supervised-text-classification-model-in-python-96e9709b4267?source=collection_archive---------23-----------------------#2020-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="5be3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这篇文章将向你展示一个构建基本的<em class="ko">监督文本分类模型</em>的简化例子。如果这听起来有点胡言乱语，让我们看看一些定义:</p><blockquote class="kp kq kr"><p id="4af1" class="jq jr ko js b jt ju jv jw jx jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kn im bi translated"><strong class="js iu">T3】💡监督: </strong> <em class="it">我们知道样本数据中每个文本的正确输出类<br/> </em> <strong class="js iu"> <em class="it">💡</em> </strong> <em class="it"> </em> <strong class="js iu"> <em class="it">文本:</em> </strong> <em class="it">输入的数据是以文本格式<br/> </em> <strong class="js iu"> <em class="it">💡分类模型:</em> </strong> <em class="it">使用输入数据预测输出类的模型<br/>每个输入文本也称为“文档”，输出也称为“目标”(术语，不是商店！😄).</em></p></blockquote><p id="9cd2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">监督文本分类模型</em>现在听起来更有意义吗？也许吧？在有监督的文本分类模型中，我们将在这篇文章中关注一种特殊的类型。在这里，我们将建立一个受监督的情感分类器，因为我们将在具有二元目标的电影评论上使用情感极性数据。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi kv"><img src="../Images/65c4c92224ab9022c58bc10534713214.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yPS1ltCSKON1ClH-"/></div></div><p class="lh li gj gh gi lj lk bd b be z dk translated">照片由<a class="ae ll" href="https://unsplash.com/@clemhlrdt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Clément H </a>在<a class="ae ll" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><h1 id="c084" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">0.Python 设置🔧</h1><p id="caef" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">本文假设您已经访问并熟悉 Python，包括安装包、定义函数和其他基本任务。如果你是 Python 新手，<a class="ae ll" href="https://www.python.org/about/gettingstarted/" rel="noopener ugc nofollow" target="_blank">这个</a>是入门的好地方。</p><p id="a0a0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我已经使用并测试了 Python 3.7.1 中的脚本。在我们开始之前，让我们确保你有合适的工具。</p><h2 id="afee" class="mw lu it bd lv mx my dn lz mz na dp md kb nb nc mh kf nd ne ml kj nf ng mp nh bi translated">⬜️确保安装了所需的软件包:熊猫，nltk &amp; sklearn</h2><p id="29d4" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">我们将使用以下强大的第三方软件包:</p><ul class=""><li id="251a" class="ni nj it js b jt ju jx jy kb nk kf nl kj nm kn nn no np nq bi translated"><em class="ko">熊猫</em>:数据分析库，</li><li id="9bbc" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated"><em class="ko"> nltk: </em>自然语言工具包库和</li><li id="01f3" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated"><em class="ko"> sklearn: </em>机器学习库。</li></ul><h2 id="e569" class="mw lu it bd lv mx my dn lz mz na dp md kb nb nc mh kf nd ne ml kj nf ng mp nh bi translated">⬜️从 nltk 下载“停用词”、“wordnet”和电影评论语料库</h2><p id="dedf" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">下面的脚本可以帮助你下载这些语料库。如果您已经下载了，运行此程序将通知您它们是最新的:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="76be" class="mw lu it nx b gy ob oc l od oe">import nltk<br/>nltk.download('stopwords') <br/>nltk.download('wordnet')<br/>nltk.download('movie_reviews')</span></pre></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><h1 id="ffc8" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">1.数据准备🔡 ➡ 🔢</h1><h2 id="e425" class="mw lu it bd lv mx my dn lz mz na dp md kb nb nc mh kf nd ne ml kj nf ng mp nh bi translated">1.1.导入示例数据和包</h2><p id="9bf2" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">首先，让我们通过导入所需的包来准备环境:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="31ba" class="mw lu it nx b gy ob oc l od oe">import pandas as pd</span><span id="e82a" class="mw lu it nx b gy of oc l od oe">from nltk.corpus import movie_reviews, stopwords<br/>from nltk.stem import WordNetLemmatizer<br/>from nltk.tokenize import RegexpTokenizer</span><span id="6eb3" class="mw lu it nx b gy of oc l od oe">from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.linear_model import SGDClassifier<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.metrics import confusion_matrix, accuracy_score</span></pre><p id="2063" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将把<em class="ko"> movie_reviews </em>标记的语料库从<em class="ko"> nltk </em>转换成熊猫数据帧，脚本如下:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="b401" class="mw lu it nx b gy ob oc l od oe"># Script copied from <a class="ae ll" href="# https://stackoverflow.com/questions/46109166/converting-categorizedplaintextcorpusreader-into-dataframe" rel="noopener ugc nofollow">her</a>e<br/>reviews = []<br/>for fileid in movie_reviews.fileids():<br/>    tag, filename = fileid.split('/')<br/>    reviews.append((tag, movie_reviews.raw(fileid)))<br/>sample = pd.DataFrame(reviews, columns=['target', 'document'])<br/>print(f'Dimensions: {sample.shape}')<br/>sample.head()</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi og"><img src="../Images/b74be989b04a80e10781a95b5f817752.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*SP5fBeDLDwjVy5cFh-KJkQ.png"/></div></figure><p id="ccb4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您将看到数据框架有两列:一列用于目标、极性情绪，另一列用于 2000 条评论的评论(即文档)。每个评论要么被标记为正面评论，要么被标记为负面评论。让我们检查目标类的数量:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="f99c" class="mw lu it nx b gy ob oc l od oe">sample[‘target’].value_counts()</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/14ba8b636c32d7e86783dbf2ac8d65e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*nkP2zZqtsEhWYEGnX8r_wA.png"/></div></figure><p id="76db" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每个类(即‘pos’，‘neg’)各有 1000 条记录，完全平衡。让我们确保这些类是二进制编码的:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="fe3f" class="mw lu it nx b gy ob oc l od oe">sample['target'] = np.where(sample['target']=='pos', 1, 0)<br/>sample['target'].value_counts()</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/a39f9cde4fc499c754374faf1cd5a474.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*rRUu8u3TNWYGBW3SmIWJ4w.png"/></div></figure><p id="4cfb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这看起来不错，让我们继续划分数据。</p><h2 id="1599" class="mw lu it bd lv mx my dn lz mz na dp md kb nb nc mh kf nd ne ml kj nf ng mp nh bi translated">1.2.分区数据</h2><p id="e777" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">谈到数据分区，我们有两种选择:</p><ol class=""><li id="2726" class="ni nj it js b jt ju jx jy kb nk kf nl kj nm kn oj no np nq bi translated">将样本数据分成三组:<em class="ko">训练</em>、<em class="ko">验证</em>和<em class="ko">测试</em>、<em class="ko"> </em>，其中<em class="ko">训练</em>用于拟合模型，<em class="ko">验证</em>用于评估过渡模型的适合度，<em class="ko">测试</em>用于评估最终模型的适合度。</li><li id="ebc4" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn oj no np nq bi translated">将样本数据分成两组:<em class="ko">训练</em>和<em class="ko">测试</em>、<em class="ko">、</em>其中<em class="ko">训练</em>进一步分成训练和验证集<em class="ko"> k 次</em>使用<em class="ko"> k 倍交叉验证，</em>和<em class="ko">测试</em>用于评估最终模型的适合度。用<em class="ko"> k 重交叉验证</em>:<br/>:<strong class="js iu">第一个</strong> : <em class="ko">列</em>被拆分成 k 块。<br/> <strong class="js iu">第二</strong>:将模型拟合到剩余的<em class="ko"> k-1 </em>件后，取一件作为验证集，评估中间模型的适合度。<br/> <strong class="js iu">第三</strong>:重复第二步<em class="ko"> k-1 </em>多次，每次使用不同的件用于验证组，剩余的件用于序列组，这样<em class="ko">序列</em>的每件仅用作验证组一次。</li></ol><p id="b6a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里的中间模型指的是在比较不同机器学习分类器以及为给定分类器尝试不同超参数以找到最佳模型的迭代过程中创建的模型。</p><p id="6a71" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用第二个选项对样本数据进行分区。让我们先把一些测试数据放在一边，这样我们就可以检查最终模型对未知数据的概括程度。</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="9949" class="mw lu it nx b gy ob oc l od oe">X_train, X_test, y_train, y_test = train_test_split(sample['document'], sample['target'], test_size=0.3, random_state=123)</span><span id="aafa" class="mw lu it nx b gy of oc l od oe">print(f'Train dimensions: {X_train.shape, y_train.shape}')<br/>print(f'Test dimensions: {X_test.shape, y_test.shape}')</span><span id="e309" class="mw lu it nx b gy of oc l od oe"># Check out target distribution<br/>print(y_train.value_counts())<br/>print(y_test.value_counts())</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/f1b96e9ad1d4fa86d737c3d5cfb1c0d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*VWTOJmi9ludiNOj-F5tZow.png"/></div></figure><p id="da6d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们有 1400 个文档在训练中，600 个文档在测试数据集中。目标均匀地分布在训练和测试数据集中。</p><p id="888b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你对关于数据分区的这一节有点困惑，你可能想要查看<a class="ae ll" href="https://machinelearningmastery.com/difference-test-validation-datasets/" rel="noopener ugc nofollow" target="_blank">这篇很棒的文章</a>来了解更多。</p><h2 id="be5d" class="mw lu it bd lv mx my dn lz mz na dp md kb nb nc mh kf nd ne ml kj nf ng mp nh bi translated">1.2.预处理文档</h2><p id="6494" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">是时候对训练文档进行预处理了，也就是把非结构化的数据转换成数字的矩阵。让我们使用一种称为单词包的方法对文本进行预处理，其中每个文本都由它的单词表示，而不管它们出现的顺序或嵌入的语法，步骤如下:</p><ol class=""><li id="7ce5" class="ni nj it js b jt ju jx jy kb nk kf nl kj nm kn oj no np nq bi translated">象征化</li><li id="39fd" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn oj no np nq bi translated">正常化</li><li id="8094" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn oj no np nq bi translated">删除停用词</li><li id="f7de" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn oj no np nq bi translated">计数矢量</li><li id="533f" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn oj no np nq bi translated">转换到 tf-idf 表示</li></ol><p id="9030" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">🔗我已经在系列文章的第一部分<a class="ae ll" href="https://medium.com/@zluvsand/introduction-to-nlp-part-1-preprocessing-text-in-python-8f007d44ca96" rel="noopener">中提供了预处理步骤的详细解释，包括下面代码块的分解。</a></p><p id="1e7d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些连续的步骤是通过下面的代码块完成的:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="3055" class="mw lu it nx b gy ob oc l od oe">def preprocess_text(text):<br/>    # Tokenise words while ignoring punctuation<br/>    tokeniser = RegexpTokenizer(r'\w+')<br/>    tokens = tokeniser.tokenize(text)<br/>    <br/>    # Lowercase and lemmatise <br/>    lemmatiser = WordNetLemmatizer()<br/>    lemmas = [lemmatiser.lemmatize(token.lower(), pos='v') for token in tokens]<br/>    <br/>    # Remove stop words<br/>    keywords= [lemma for lemma in lemmas if lemma not in stopwords.words('english')]<br/>    return keywords</span><span id="a136" class="mw lu it nx b gy of oc l od oe"># Create an instance of TfidfVectorizer<br/>vectoriser = TfidfVectorizer(analyzer=preprocess_text)</span><span id="2a9b" class="mw lu it nx b gy of oc l od oe"># Fit to the data and transform to feature matrix<br/>X_train_tfidf = vectoriser.fit_transform(X_train)<br/>X_train_tfidf.shape</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/2c0abbaa973ddf48fbd365dc993754d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/1*f5dkHw_1AVRdIhtMVBmHcg.png"/></div></figure><p id="48f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">🔗如果你不确定什么是 tf-idf，我已经在<a class="ae ll" href="https://medium.com/@zluvsand/introduction-to-nlp-part-3-tf-idf-explained-cedb1fc1f7dc" rel="noopener">系列第三部</a>中提供了详细的解释。</p><p id="6eb1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦我们预处理了文本，我们的训练数据现在是以稀疏矩阵格式存储的 1400 x 27676 特征矩阵。这种格式提供了有效的数据存储，并加快了后续过程。我们有 27676 个特征代表来自训练数据集中的唯一单词。现在，训练数据已经准备好进行建模了！</p></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><h1 id="61e0" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">2.模拟ⓜ️</h1><h2 id="a3c3" class="mw lu it bd lv mx my dn lz mz na dp md kb nb nc mh kf nd ne ml kj nf ng mp nh bi translated">2.1.基线模型</h2><p id="959d" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">让我们使用随机梯度下降分类器建立一个基线模型。我选择了这个分类器，因为它速度快，并且适用于稀疏矩阵。使用 5 重交叉验证，让我们将模型与数据进行拟合并对其进行评估:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="8303" class="mw lu it nx b gy ob oc l od oe">sgd_clf = SGDClassifier(random_state=123)<br/>sgf_clf_scores = cross_val_score(sgd_clf, X_train_tfidf, y_train, cv=5)</span><span id="30c8" class="mw lu it nx b gy of oc l od oe">print(sgf_clf_scores)<br/>print("Accuracy: %0.2f (+/- %0.2f)" % (sgf_clf_scores.mean(), sgf_clf_scores.std() * 2))</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi om"><img src="../Images/0a44298df5e74d4cee3dcf60b2af9d19.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*jk3vrBTZsjA33q4F36W70g.png"/></div></figure><p id="ab27" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设数据是完全平衡的，我们希望尽可能正确地预测两个标签，我们将使用<em class="ko">准确性</em>作为评估模型适合度的度量。然而，根据目标的分布和类的相对误分类成本，精度并不总是最佳的度量。在这种情况下，其他评估指标如精确度、召回率或 f1 可能更合适。</p><p id="a9ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最初的表现看起来还不错。基线模型可以在大约 83% +/- 3%的时间内准确预测。</p><p id="3ce9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">值得注意的是，使用的默认指标是<code class="fe on oo op nx b">cross_val_score </code>中的<em class="ko">准确度</em>，因此我们不需要指定它，除非您想明确地这样说，如下所示:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="fc4d" class="mw lu it nx b gy ob oc l od oe">cross_val_score(sgd_clf, X_train_tfidf, y_train, cv=5, scoring='accuracy')</span></pre><p id="bca8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们通过查看混淆矩阵来进一步理解这些预测:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="aa44" class="mw lu it nx b gy ob oc l od oe">sgf_clf_pred = cross_val_predict(sgd_clf, X_train_tfidf, y_train, cv=5)<br/>print(confusion_matrix(y_train, sgf_clf_pred))</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/4138e02b3db5cc4af1e18f51ed4719e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:178/format:webp/1*KRODSHCQkv00LYMsQJXp9A.png"/></div></figure><p id="b235" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这两类预测的准确性是相似的。</p><h2 id="f03d" class="mw lu it bd lv mx my dn lz mz na dp md kb nb nc mh kf nd ne ml kj nf ng mp nh bi translated">2.2.尝试提高性能</h2><p id="1991" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">本节的目的是找到最佳的机器学习算法及其超参数。让我们看看我们是否能够通过调整一些超参数来改进模型。我们将把大多数超参数保留为其合理的默认值。在网格搜索的帮助下，我们将使用下面指定的超参数的每种组合运行一个模型，并交叉验证结果，以感受其准确性:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="f28d" class="mw lu it nx b gy ob oc l od oe">grid = {'fit_intercept': [True,False],<br/>        'early_stopping': [True, False],<br/>        'loss' : ['hinge', 'log', 'squared_hinge'],<br/>        'penalty' : ['l2', 'l1', 'none']}<br/>search = GridSearchCV(estimator=sgd_clf, param_grid=grid, cv=5)<br/>search.fit(X_train_tfidf, y_train)<br/>search.best_params_</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi or"><img src="../Images/19f69fb228d4ac43236e984aef677b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*_IFpZHsJb5dabfbFIIbSOQ.png"/></div></figure><p id="14ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些是上面指定的超参数的最佳值。让我们使用所选超参数的这些值来训练和验证模型:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="d28d" class="mw lu it nx b gy ob oc l od oe">grid_sgd_clf_scores = cross_val_score(search.best_estimator_, X_train_tfidf, y_train, cv=5)<br/>print(grid_sgd_clf_scores)<br/>print("Accuracy: %0.2f (+/- %0.2f)" % (grid_sgd_clf_scores.mean(), grid_sgd_clf_scores.std() * 2))</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi om"><img src="../Images/0ddf2736f62a5bce34e1da60bef5b6fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*gW4q2BmEe1gMLHyN7eX3kQ.png"/></div></figure><p id="cdac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与基线相比，模型拟合度稍好(小 yay❕).</p><p id="84a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了节省时间，我们将为最终模型选择这些超参数组合，这一部分到此为止。然而，本节可以进一步扩展，尝试不同的建模技术，并使用网格搜索找到模型超参数的最佳值。</p><p id="d237" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">📌练习:</strong>看看是否可以通过使用不同的建模技术和/或优化超参数来进一步提高该模型的准确性。</p><h2 id="aa81" class="mw lu it bd lv mx my dn lz mz na dp md kb nb nc mh kf nd ne ml kj nf ng mp nh bi translated">2.3.最终模型</h2><p id="fdde" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">现在我们已经完成了模型，让我们将数据转换步骤和模型放入<em class="ko">管道</em>:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="0e72" class="mw lu it nx b gy ob oc l od oe">pipe = Pipeline([('vectoriser', vectoriser),<br/>                 ('classifier', search.best_estimator_)])</span><span id="25a7" class="mw lu it nx b gy of oc l od oe">pipe.fit(X_train, y_train)</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi os"><img src="../Images/0a47853a925b069d666e5a2e46e08bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SUgI2YHvltdd1Bym55MoxA.png"/></div></div></figure><p id="0565" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在上面显示的代码中，管道首先将非结构化数据转换为特征矩阵，然后将预处理后的数据拟合到模型中。这是一种将基本步骤放在一个管道中的优雅方式。</p><p id="86b9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们在测试集上评估模型的预测能力。这里，我们将把测试数据传递给管道，管道将首先预处理数据，然后使用之前拟合的模型进行预测:</p><pre class="kw kx ky kz gt nw nx ny nz aw oa bi"><span id="276d" class="mw lu it nx b gy ob oc l od oe">y_test_pred = pipe.predict(X_test)<br/>print("Accuracy: %0.2f" % (accuracy_score(y_test, y_test_pred)))<br/>print(confusion_matrix(y_test, y_test_pred))</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/97c446095428f3eca0baf2dd0df35521.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/1*LguFtFOHMiBgQAYdoMVh2g.png"/></div></figure><p id="13b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最终模型对未知数据的精确度约为 85%。如果这个测试数据代表了未来的数据，那么考虑到我们到目前为止所付出的努力，这个模型的预测能力是相当不错的，你不这样认为吗？不管怎样，恭喜你！您刚刚构建了一个简单的监督文本分类模型！🎓</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ot"><img src="../Images/52584d09f7f584bb4d618ba352530031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OniCuKz5LgdP-jkr"/></div></div><p class="lh li gj gh gi lj lk bd b be z dk translated"><a class="ae ll" href="https://unsplash.com/@dragonflyave?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">摄蜻蜓大街</a>上<a class="ae ll" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">的 Unsplash </a></p></figure><p id="4be0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">您想访问更多这样的内容吗？媒体会员可以无限制地访问媒体上的任何文章。如果您使用</em> <a class="ae ll" href="https://zluvsand.medium.com/membership" rel="noopener"> <em class="ko">我的推荐链接</em> </a>，<em class="ko">成为会员，您的一部分会费将直接用于支持我。</em></p></div><div class="ab cl lm ln hx lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="im in io ip iq"><p id="b84c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢您花时间阅读这篇文章。我希望你从阅读它中学到一些东西。其余帖子的链接整理如下:<br/> ◼️ <a class="ae ll" href="https://medium.com/@zluvsand/introduction-to-nlp-part-1-preprocessing-text-in-python-8f007d44ca96" rel="noopener">第一部分:Python 中的文本预处理</a> <br/> ◼️ <a class="ae ll" href="https://medium.com/@zluvsand/introduction-to-nlp-part-2-difference-between-lemmatisation-and-stemming-3789be1c55bc" rel="noopener">第二部分:词法分析和词干分析的区别</a> <br/> ◼️ <a class="ae ll" href="https://medium.com/@zluvsand/introduction-to-nlp-part-3-tf-idf-explained-cedb1fc1f7dc" rel="noopener">第三部分:TF-IDF 解释</a> <br/> ◼️ <strong class="js iu">第四部分:Python 中的有监督文本分类模型<br/> </strong> ◼️ <strong class="js iu"> </strong> <a class="ae ll" rel="noopener" target="_blank" href="/introduction-to-nlp-part-5a-unsupervised-topic-model-in-python-733f76b3dc2d">第五部分:Python 中的无监督主题模型(sklearn) </a> <br/> ◼️ <a class="ae ll" rel="noopener" target="_blank" href="/introduction-to-nlp-part-5b-unsupervised-topic-model-in-python-ab04c186f295">第五部分</a></p><p id="db5d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">快乐造型！再见🏃💨</p><h1 id="8cd5" class="lt lu it bd lv lw ou ly lz ma ov mc md me ow mg mh mi ox mk ml mm oy mo mp mq bi translated">3.参考📁</h1><ul class=""><li id="dc11" class="ni nj it js b jt mr jx ms kb oz kf pa kj pb kn nn no np nq bi translated"><a class="ae ll" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank"> Christopher D. Manning，Prabhakar Raghavan 和 Hinrich Schütze，<em class="ko">信息检索导论</em>，剑桥大学出版社，2008 年</a></li><li id="20f2" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated"><a class="ae ll" href="http://www.nltk.org/book/" rel="noopener ugc nofollow" target="_blank">伯德、史蒂文、爱德华·洛珀和伊万·克莱恩，<em class="ko">用 Python 进行自然语言处理</em>。奥莱利媒体公司，2009 年</a></li><li id="7a97" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated">Jason Brownlee，测试数据集和验证数据集有什么区别？，机器学习精通，2017 </li></ul></div></div>    
</body>
</html>