# 兰博:排名度量黑盒优化

> 原文：<https://towardsdatascience.com/rambo-ranking-metric-blackbox-optimization-36811a5f52dd?source=collection_archive---------36----------------------->

![](img/4d99dc9fb095cdbd92ac8f4c0642b825.png)

[3]

## 我们的论文在 2020 年 CVPR 大会上做了一次关于应用黑盒微分理论(代号#blackboxbackprop)来优化基于排名的指标的口头报告。事实证明，只要做一些简单的改变，一切都是可能的…

在我们的[最新论文【1】](http://bit.ly/35EXIMN)中，我们通过**直接**优化基于排名的指标来处理深度神经网络的训练。我们的方法基于[ [2](http://bit.ly/35IowfE) ]中介绍的黑盒反投影理论。在 [blackbox-backprop 论文](http://bit.ly/35IowfE)(最新更新见 Twitter 上的 **#blackboxbackprop** 和附带的 [blogpost](https://t.co/4QwU0UCRm0?amp=1) )中，我们展示了如何通过神经网络中的组合解算器计算“有用的”梯度，而不损害解算器本身的最优性。该理论使我们能够利用**组合** **解算器作为复杂模型中的即插即用模块**，我们可以用标准反向传播算法对其进行训练。

为了寻求该理论的实际应用，我们求助于计算机视觉。具体来说，我们表明，将 blackbox-backprop 应用于计算机视觉基准测试，以**优化检索和检测任务的召回率和平均精度**，可以持续提高底层架构的性能。顺便说一下，这是 ML 中的一个常见主题，总是希望为您真正关心的东西进行优化。如果 recall@K 是正确的性能度量，那么让端到端架构优化它是有意义的，而不是某种近似。召回率(更具体地说，召回率@K)和平均精度都是基于输入排序的度量，这实质上需要对它们的分数进行排序操作。在这方面，多种因素构成了挑战。首先，使用这些度量作为损失函数会导致不可分解的损失(即，我们不能基于输入的子集可靠地估计损失，但是我们需要整个输入集)。此外，用于计算指标的排名操作是不可微的。

尽管已经提出了许多竞争的方法，但是由于不同的原因，它们没有被从业者接受。它们在计算上过于昂贵，或者缺乏易于使用的实际实现。利用 blackbox-backprop 理论，我们将排序操作直接应用于输出的分数，这导致了低计算复杂度 O(n log n)(使用 **torch.argsort** 进行一般排序的复杂度)。我们需要回答的问题如下:

1.  如何将排名问题投射到黑盒差异化框架中？
2.  如何处理损失的不可分解性？
3.  如何防止基于等级的损失崩溃？

## 将排名纳入黑盒区分框架

为了将排名转换到[2]中提出的框架中，我们需要在点积上进行 argmin 运算。我们首先定义分数的向量， **y** 。 **y** ， **rk(y)** 的排序是在所有可能排列的集合上对向量 **y** 和排列 **π，**之间的点积进行 argmin 运算的结果:

![](img/36d48fdb0991314b3618f43850603b1d.png)

前一个命题的证明很简单，并且基于众所周知的置换不等式，该不等式表示给定一个递减序列(向量 **y** ),对于任意整数 n:

![](img/3c4779321916ccbb7446d13a369aabef.png)

直观地说，这意味着最大的分数被赋予了最小的权重，这发生在排列是排序排列的情况下。通过这个简单的改变，**我们能够将 blackbox 框架应用于排名问题**，这意味着我们可以简单地使用快速排序算法的有效实现(例如 PyTorch 中的 torch.argsort)来计算排名，并基于 blackbox-backprop 理论通过它进行区分**。**下图显示了应用[黑盒反投影](http://bit.ly/35IowfE)理论所产生的优化前景的示例:

![](img/6a2430d83bc5e2ae8cf5fc1636c0f7a6.png)

## 得分保证金，以防止损失崩溃

基于等级的损失很难处理平局。为了说明它们的不稳定性，请考虑我们在整个数据集上得分相同的情况。我们可以在这种平局的小邻域中获得所有可能的排名，因为分数的最小变化完全改变了排名。这意味着应用基于等级的损失是非常不稳定的。我们通过**引入裕量α** 来缓解该问题，该裕量α【】在负标记分数上引起正偏移，在正标记分数上引起负偏移:

![](img/c67d8b83a7638f3cb9d255e6fd45e740.png)![](img/2b5774136adda48f92104ed29004cd7c.png)

## 为更好的评估评分记忆

理想情况下，我们将有一个数据集范围的损失进行优化，因为基于排名的损失的不可分解性问题。因为这在计算上是难以处理的(例如，因为它受到 GPU 内存的限制)，所以我们希望使用迷你批处理来训练我们的模型。我们通过用一定数量的先前批次的分数扩展当前批次的分数来考虑这一点，这减少了损失估计的偏差。

## 该算法

采用上述技术产生了一种方法，我们称之为**排名度量黑盒优化(RaMBO)** 。同样，额外的计算开销仅由**排序操作** **O(n log n)** 的复杂性引入，当高效实现时，其速度极快。这使我们领先于大多数方法。该算法总结如下:

![](img/e367498e8321b64e0f8d14825d63d649.png)

我们评估了我们的方法在对象检测(Pascal VOC)和几个图像检索基准(Cu B- 200–2011，店内服装，斯坦福在线产品)上的性能。在每个实验中，我们采用性能良好的架构，并用 **RaMBO** 对其进行修改。在这些基准测试中，该方法达到或超过了最先进的结果。

然而，我们应该承认，度量学习基线是一团乱麻，这是不同方向的大量快速研究的结果(改进网络架构、更好的目标函数等等)。这导致不可复制的结果、错误的结论和不公平的比较，对这些困难的分析可以在这里找到。

![](img/0f9007213210a985b9a1155615542311.png)

斯坦福产品检索数据集。

## 相关推文

## 参考

[1]rol nek，Michal 等人[使用黑盒区分优化基于等级的指标](http://bit.ly/35EXIMN)，CVPR，2020 年

[2] Vlastelica，Marin 等人[黑盒组合
解算器的微分](http://bit.ly/35IowfE)，ICLR 2020

[3]图片取自 Pixabay

## 感谢

这是来自德国图宾根马普智能系统研究所的自主学习小组、图宾根大学和意大利费伦泽大学的联合研究成果。