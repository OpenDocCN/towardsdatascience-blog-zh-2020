# 对 51，000 篇期刊文章的无监督单词嵌入学习能告诉我们关于新冠肺炎的什么。

> 原文：<https://towardsdatascience.com/what-learning-unsupervised-word-embeddings-across-51-000-journal-articles-can-tell-us-about-d60851fb4c30?source=collection_archive---------33----------------------->

## 2019 年 7 月，我的一位前材料物理同事围绕从更老的科学出版物中发现新科学发表了一篇了不起的文章。这个想法很简单但很棒:如果文章编码了科学家思考特定科学概念的方式，人工智能可以通过学习这些文章中句子的模式来尝试识别新的关联吗？

![](img/1a142235000dcf294b5ece650eb20ab3.png)

来源:美国航天局

有监督的自然语言处理是一个很好的起点，但是将整个出版物的语料库减少到一个单一的结构化标签数据集并不完全是任何人想要花费他们的隔离时间去做的事情。相反， [Tshitoyan 和他的同事们](https://www.nature.com/articles/s41586-019-1335-8)发现他们可以使用无监督的信息密集型单词嵌入来捕捉潜在的复杂材料科学概念。令人惊讶的是，他们发现通过训练一个简单的 Word2Vec 网络，他们可以在发现之前几年预测材料的导热性能！

有了一个空闲的下午，一杯新鲜的咖啡和对病毒学世界非常天真的概述，我们能把这种方法扩展到 51，000 篇新冠肺炎相关期刊文章的语料库(文本集合)吗？

**用单词嵌入表示语言**

当我们第一次学习一种语言时，我们被教授组成词汇的几个单词，然后我们根据上下文在词汇中的单词之间建立联系；我们称之为句子。有了这个极度淡化的概述，让我们试着教我们的计算机成为一名病毒学家。

首先，我们需要一种表示词汇表的方法。计算机没有将单词作为字符串处理的直观方式；一个常见的技巧是将每个单词映射到一个 *n* 维的二进制向量上，其中每一行代表词汇表中的一个单词和 *n* 个单词。当表示像“罗马”这样的单个单词时，向量在对应于“罗马”的行中有 1，在其他地方有 0。这被称为一键编码，如下图所示。

![](img/05f1a60ff35710a551e251a3eff34901.png)

来源:马尔科·邦扎尼尼，2017 年

不幸的是，这并没有告诉我们关于单词排序的任何事情，因为我们必须学习句子的表达。做到这一点的一个方法是建立一个上下文的度量，或者一个单词在句子中与另一个单词“接近”的可能性。换句话说(没有双关语的意思)，我们可以建立什么样的模型来表示语料库中单词之间关联的可能性？

我们可以训练一个神经网络来做到这一点，方法是尝试预测可能出现在以感兴趣的单词为中心的邻域或窗口中的单词。在窗口大小为 1 的 IMDB 评论上训练的网络更有可能预测“米夫林”旁边的“邓德”，而不是“比尔亚尼”旁边的“邓德”；这是因为短语“ **Dunder Mifflin** ”或(“Dunder”，“Mifflin”)作为训练示例出现的次数会比“ **Dunder Biryani** ”或(“Dunder”，“Biryani”)多得多。

另一方面，大小为 1 的窗口将无法将“**Dunder Mifflin Paper Company**”中的“Dunder”与“Paper”相关联，因为“Paper”是两个单词之遥。为了补救这一点，我们需要大小为 2 的窗口，这将产生更多的实例(“Dunder”，“Paper”)作为训练示例。选择适当的邻域大小对于捕获复杂语言的语义至关重要。

一个非常流行的网络是 Skip-Gram:一个隐藏层网络，它将我们的一个热编码输入向量映射到关联概率的输出。该网络如下图所示:

![](img/040cad5110f53f9d8dd85abd013b157f.png)

来源:[克里斯麦考密克](http://mccormickml.com/)

隐藏层是这里的奖品；我们将一个主要包含零的二进制向量映射到一个 300 维向量，该向量用语料库的其余部分描述其语义表示。这种表示中的单词被称为*嵌入，*嵌入的词汇被称为语料库的*嵌入*。

更值得注意的是，我们可以在嵌入中使用向量代数来描述语言中单词之间的关系。“King”、“Kings”甚至“Emperor”的嵌入向量之间的余弦相似性得分(CSS)应该接近 1，因为它们出现在相似的上下文中，因此它们出现的训练对应该为形成嵌入的网络中的权重提供相似的更新。加减向量已经被证明可以捕捉语言规律，例如类比。例如，“男人是国王，就像女人是国王一样”通过嵌入的加法和减法运算符来表示:“国王”——“男人”+“女人”；这导致嵌入非常接近**皇后。**

**现在我们有了一个模型，我们可以继续从出版数据的语料库中学习新冠肺炎研究的语言。**

****数据****

**作为对疫情的回应，白宫和一个由主要研究人员组成的联盟组建了一个名为[新冠肺炎开放研究数据集](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)，这是一个由超过 51，000 篇关于新冠肺炎、新型冠状病毒和其他冠状病毒的学术文章组成的资源，托管在 Kaggle 上。在他们的原始论文中， [Tshitoyan 和他的同事们](https://www.nature.com/articles/s41586-019-1335-8)专注于从论文摘要中学习科学概念。摘要基本上提供了一个 TL；dr 概述了作者所做工作的方法、结果、发现和结论，因此形成了一个更小但更密集的冠状病毒研究信息语料库。**

****生成病毒学词汇****

**在 [Tshitoyan](https://www.nature.com/articles/s41586-019-1335-8) 等人的论文中用于预处理期刊的相同协议被用于准备[新冠肺炎开放研究数据集](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)。使用 [ChemDataExtractor](https://github.com/mcs07/ChemDataExtractor) (一种帮助归纳化学标识符的 repo)过滤句子中的关键词，如“ABSTRACT:”和“METHODS:”并标记化(拆分成单词数组)。非技术词汇被小写和去重音，以减少总词汇量。如果标记在语料库中出现超过 5 次，则被接纳到词汇表中，给出 22399 个独特的单词。**

**作者们还用 n 元短语丰富了他们的词汇。在给定训练数据的情况下，这些是具有很高可能性彼此相邻出现的 *n* 个单词的序列。g [ensim](https://radimrehurek.com/gensim/) 用于使用包括诸如“of”或“a”等常见术语的短语来生成 4-gram。如果短语在语料库中出现超过 10 次，则被纳入词汇表，给出 33504 个独特的短语。**

****型号****

**我在 g [ensim](https://radimrehurek.com/gensim/) 中使用了 Word2Vec Skip-Gram 实现，具有 200 维嵌入和 8 个单词的上下文窗口，下采样阈值为 0.0001，对语料库中 328 个最常见的单词进行下采样。使用随机梯度下降来训练网络，在 30 个时期内，学习率从 0.01 到 0.0001 线性下降。收集了 15，000 个语法科学类比用于评估网络性能，分数定义为“正确解决”的类比数量。该分数用于手动调整网络超参数。**

****结果—类比****

**首先，用几个类比查询测试嵌入的鲁棒性。询问“中东到 MERS 如同 _ is 到新型冠状病毒”等同于对令牌嵌入执行以下向量代数运算:“中东”-“MERS”+“新型冠状病毒”。前 10 个最接近的向量包括('中国 _ 在 _ 十二月'，CSS = 0.54)，('南方 _ 中国'，CSS = 0.49)，('武汉市'，CSS = 0.48)和('湖北省'，CSS = 0.48)。同样，询问“艾滋病之于艾滋病毒，就像 _ 之于新型冠状病毒一样”,得到了代表新型冠状病毒引起的疾病的 2019-nCov 的三种变体。“MERS is to MERS-CoV as _ is to 新型冠状病毒”给出了 2019-nCov 在前 10 名中的 5 名的变化。“骆驼”-“MERS”+“新型冠状病毒”= ('bat_species '，CSS = 0.39)。**

**这些结果特别令人兴奋，因为它们暗示了对文献中关键概念之间关系的一些了解。**

****结果—药品名称余弦相似性和相似性****

**接下来，我问药物新型冠状病毒冠状病毒、SARS 和 MERS-CoV 之间存在什么样的背景关系。我下载了一个包含 2542 种 FDA 批准的药物的数据库，其中 408 种与词汇表中的药物名称重叠。**

**![](img/ab38715dc3764b1734082f58b32ad5be.png)**

**值得注意的是，羟氯喹是与新型冠状病毒语义相似度最高的药物之一，这并不奇怪，因为它最近作为一种可能的治疗方法受到了关注。另一个有趣的发现是丙嗪，[在 2004 年](http://www.hkupasteur.hku.hk/publications/pdf/Zhang_BioorgMedChem_2004b.pdf)被报道为潜在的 SARS-CoV 蛋白酶抑制剂，但在 2008 年在小鼠模型中显示出[缺乏临床疗效。](https://www.ncbi.nlm.nih.gov/pubmed/18423639)伊马替尼是一种癌症治疗药物，在 [2016 年的一项研究](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjGgJ2Yxu3oAhU9aRUIHV4VCGkQFjABegQIAhAB&url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5021412%2F&usg=AOvVaw10NPZgmUcU16Ai8n8Y_eBI)中被证明可抑制 SARS-CoV 和 MERS-CoV。**

**接下来，我在嵌入中使用了向量代数，提出了以下问题:“利巴韦林之于 SARS，就像 _ 之于新型冠状病毒？”。以下是余弦相似度最高的 10 个答案:**

**![](img/c5d8d2110d3d06b7aeceeab6f141612c.png)**

**有趣的是，remedisivir 目前正处于[试验](https://www.fiercebiotech.com/biotech/gilead-shares-slip-as-a-second-remdesivir-covid-19-trial-halted-china)中，等待其用于治疗轻度至中度新冠肺炎症状，而[利托那韦](https://www.nejm.org/doi/full/10.1056/NEJMoa2001282)的试验刚刚在一组新冠肺炎症状中结束，没有明显的益处。**

**一个有趣的问题是，有多少与新型冠状病毒相关的药物没有出现在同一个摘要中，因为这将表明基于从专门关注 SARS-CoV 和 MERS-CoV 的论文中获得的模式的潜在上下文类比。**

****结果—症状类比****

**与上面类似，询问“干咳之于 SARS 就如同之于新型冠状病毒”会返回一个全面的症状列表，其中许多已知与最近的爆发有关。**

**![](img/3bd9fa14c5a0f0ecc4922cca8a7f5f24.png)**

****结论****

**Tshitoyan 和他的同事们通过用自然语言向 NLP 模型提问，对该方法进行了扩展。这项工作是一个下午的编码，仅仅触及了 NLP 的能力和由一些非常出色的人组装的惊人数据集的表面。还有很多很多事情要做。例如，我们可以用一个更复杂的上下文感知模型来代替 Word2Vec 模型，比如 Google 的 BERT 或 ELMO。当关键词没有出现在与新型冠状病毒出版物相同的摘要中时，可以提出更多关于蛋白质结构类比的技术问题，并弄清楚网络正在回答什么问题。毫无疑问，在这一领域已经做了很多工作，试图找到对抗一种使我们的星球停滞不前的疾病的策略。**