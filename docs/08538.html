<html>
<head>
<title>How to Build and Deploy a Custom Object Detector &amp; Classifier using TensorFlow Object Detection API?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 TensorFlow 对象检测 API 构建和部署自定义对象检测器和分类器？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-custom-object-detector-classifier-using-tensorflow-object-detection-api-811b7bcd31c4?source=collection_archive---------16-----------------------#2020-06-21">https://towardsdatascience.com/how-to-build-a-custom-object-detector-classifier-using-tensorflow-object-detection-api-811b7bcd31c4?source=collection_archive---------16-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="69dc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何构建交通灯检测器和分类器，用于对真正的自动驾驶汽车进行编程。</h2></div><div class="ki kj kk kl gt ab cb"><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/edeaf77c1138eee55e54a41ec16249ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*BcgXQLxwUxrfENhIayNOSA.png"/></div></figure><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/5a1924bfe14eebc346b74bff95dde07a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*wfPJ7xTB8CJNt9vGg1ttwg.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk ld di le lf translated">交通灯分类器:现场(左)和模拟器(右)</p></figure></div><h1 id="5114" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">动机:</h1><p id="58d4" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">使用<a class="ae mu" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow 对象检测 API </a>实现一个交通灯分类器——这可以用于使用边界框检测图像和/或视频中的对象，使用一些可用的预训练模型或通过您可以自己训练的模型。</p><h1 id="6b38" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">应用:</h1><p id="26ee" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">编程一辆真正的自动驾驶汽车。解决自主车辆视觉和感知问题的尝试。</p><h1 id="8826" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">代码和实现:</h1><p id="6bd5" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">请在我的<a class="ae mu" href="https://github.com/SandeepAswathnarayana/traffic-light-classifier_faster-r-cnn" rel="noopener ugc nofollow" target="_blank"> <strong class="ma iu"> GitHub 库</strong> </a>中找到与这篇博文相关的所有必要文件、代码、模块和结果。</p><p id="a950" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">这个交通灯分类器是 Udacity 的自动驾驶汽车工程师 Nanodegree 的关键部分。我带领一个 4 人团队(合作的有 w/ <a class="na nb ep" href="https://medium.com/u/c1d76c218ce6?source=post_page-----811b7bcd31c4--------------------------------" rel="noopener" target="_blank">阿伦·萨加尔</a>、<a class="ae mu" href="https://www.linkedin.com/in/prasanga-ranaweera/" rel="noopener ugc nofollow" target="_blank">马里斯·p·拉纳维拉</a>和李爽)，每个成员都有着不同的背景和经验，来编写一辆真正的自动驾驶汽车。请在<a class="ae mu" href="https://github.com/SandeepAswathnarayana/Udacity-SDCND-Programming-a-Real-Self-Driving-Car" rel="noopener ugc nofollow" target="_blank"> <strong class="ma iu"> GitHub </strong> </a>上找到这个项目资源库。</p><h1 id="3c02" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">为什么选择 TensorFlow 物体检测 API？</h1><p id="ea94" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">TensorFlow 的对象检测 API 是一个强大的工具，可以轻松构建、训练和部署对象检测模型。在大多数情况下，从头开始训练整个卷积网络非常耗时，并且需要大型数据集。这个问题可以通过使用 TensorFlow API 的预训练模型利用迁移学习的优势来解决。</p><h1 id="a534" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">构建分类器:</h1><p id="d3cd" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">安装入门:找到<a class="ae mu" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow 对象检测 API 库</a>上的说明，转到路径:<code class="fe nc nd ne nf b">tensorflow/models/object_detection/g3doc/installation.md</code>。</p><ul class=""><li id="3066" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">克隆或下载<a class="ae mu" href="https://github.com/tensorflow/models" rel="noopener ugc nofollow" target="_blank"> TensorFlow 模型</a>库。在终端/cmd.exe 中导航到该目录</li><li id="e1f7" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">转到<code class="fe nc nd ne nf b"><a class="ae mu" href="https://github.com/protocolbuffers/protobuf/releases/tag/v3.4.0" rel="noopener ugc nofollow" target="_blank">https://github.com/protocolbuffers/protobuf/releases/tag/v3.4.0</a></code>并下载 protocol-3 . 4 . 0-win32 . zip(根据您的操作系统和要求选择合适的版本)</li><li id="a5e8" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">从上面的连续步骤中提取两个下载的文件。现在，在<code class="fe nc nd ne nf b">models</code>(或<code class="fe nc nd ne nf b">models-master</code>)目录中，您可以使用<code class="fe nc nd ne nf b">protoc</code>命令:</li></ul><p id="c985" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><strong class="ma iu">在 Windows 上:</strong></p><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="a250" class="ny lh it nf b gy nz oa l ob oc">"C:/Program Files/protoc/bin/protoc"</span><span id="78b9" class="ny lh it nf b gy od oa l ob oc">object_detection/protos/*.proto --python_out=.</span></pre><p id="b956" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><strong class="ma iu">在 Ubuntu 上:</strong></p><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="415b" class="ny lh it nf b gy nz oa l ob oc">protoc object_detection/protos/*.proto --python_out=.</span><span id="aac8" class="ny lh it nf b gy od oa l ob oc">export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim</span></pre><ul class=""><li id="580c" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">运行朱庇特笔记本<code class="fe nc nd ne nf b"><a class="ae mu" href="https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/object_detection_tutorial.ipynb" rel="noopener ugc nofollow" target="_blank">object_detection_tutorial.ipynb</a></code>。这会为您下载一个预先训练好的模型。这里的预训练模型是 COCO(上下文中的公共对象)。在笔记本上，注释掉<code class="fe nc nd ne nf b">get_ipython().magic('matplotlib inline')</code>行。</li><li id="2eef" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">接下来，使用<code class="fe nc nd ne nf b">import cv2</code>引入 Python Open CV 包装器</li><li id="af0b" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">实际的检测过程发生在“for”循环中(在最后一个单元格中)，我们需要根据我们的需要相应地修改它。当然，我们还可以做更多的代码清理工作，比如去掉 Matplotlib 导入，如果你愿意，可以随意清理。</li><li id="ec98" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">加载您的自定义图像:在 jupyter 笔记本中，进行必要的导入以从目录中加载您的图像，修改笔记本以满足您的需要，然后运行它。</li></ul><h1 id="c62a" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">如何使用 TensorFlow 对象检测 API 建立红绿灯检测模型？</h1><p id="6f48" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">将您感兴趣的对象添加到预训练的模型中，或者使用该模型的权重来给自己一个训练这些新对象的良好开端。Tensorflow 对象检测 API 基本上是准确性和速度之间的折衷。考虑到我正在处理的数据集，我选择使用<code class="fe nc nd ne nf b"><em class="oe">faster_rcnn_inception_v2_coco</em></code>。请查看<a class="ae mu" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow 检测模型动物园</a>下可用模型的完整列表。</p><p id="4d5b" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">步骤:</p><ol class=""><li id="75cf" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt of nm nn no bi translated">收集大约 500 张(或者更多，如果你愿意)自定义交通灯图像。对于这个项目，我选择的图片来自——Udacity 模拟器、uda city 的卡拉测试网站和网络</li><li id="bee1" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt of nm nn no bi translated">使用“labelImg”注释自定义图像</li><li id="1a99" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt of nm nn no bi translated">将它们分成训练测试集</li><li id="27db" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt of nm nn no bi translated">为列车测试分割生成 TFRecord</li><li id="cdf2" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt of nm nn no bi translated">设置配置文件</li><li id="366a" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt of nm nn no bi translated">训练实际模型</li><li id="ae6d" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt of nm nn no bi translated">从新训练的模型中导出图表</li><li id="6eac" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt of nm nn no bi translated">引入冻结推理图对交通灯进行实时分类</li></ol><h1 id="950d" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">步骤 1:收集自定义交通灯图像</h1><ul class=""><li id="dd9a" class="ng nh it ma b mb mc me mf mh og ml oh mp oi mt nl nm nn no bi translated">模拟器:在相机打开的情况下运行模拟器，并按照指示从模拟器中收集交通灯图像</li></ul><div class="ki kj kk kl gt ab cb"><figure class="km kn oj kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/b08bb263513bed608d132b29310b4f4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*wEQbpryXHFbBbvssql_V1Q.jpeg"/></div></figure><figure class="km kn oj kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/3494bef4accafe650b9a3fe14921c9da.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*8I_Yx-pA3hZvD9kVhwot2g.jpeg"/></div></figure><figure class="km kn oj kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/068e8b4c62c8094b1cd66f703047e91b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*pSX3SOmS5KQsKzUMawZhXw.jpeg"/></div><p class="kz la gj gh gi lb lc bd b be z dk ok di ol lf translated">从 Udacity 模拟器中收集的一些示例图像</p></figure></div><ul class=""><li id="2371" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">站点:从 Udacity 提供的 ROS 包中下载卡拉站点的红绿灯图像</li></ul><div class="ki kj kk kl gt ab cb"><figure class="km kn oj kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/c2757095565191e7fe8524b117df24c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Zc6zWchPQ-lzauS63pwNjA.jpeg"/></div></figure><figure class="km kn oj kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/d2149b4722e0b2964857cc18d580162c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*r2LQoCn_BMjn01AadRJqbA.jpeg"/></div></figure><figure class="km kn oj kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/07770a4e09616424b7dcbf1321728b46.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*o0WgdhAuVJ5lGRvu5D0Sug.jpeg"/></div><p class="kz la gj gh gi lb lc bd b be z dk ok di ol lf translated">从 Udacity 的卡拉网站收集的一些样本图像</p></figure></div><h1 id="7e7b" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">步骤 2:注释自定义交通灯图像</h1><p id="9008" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">使用<a class="ae mu" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">‘label img’</a>手工标记交通灯数据集图像。<br/>步骤:</p><ul class=""><li id="37f2" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">克隆<a class="ae mu" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> labelImg </a>库</li><li id="5c47" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">遵循符合您的 python 版本要求的安装步骤。但是，对于 Ubuntu 上的 Python3:</li></ul><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="56a4" class="ny lh it nf b gy nz oa l ob oc">sudo apt-get install pyqt5-dev-tools</span><span id="79b5" class="ny lh it nf b gy od oa l ob oc">sudo pip3 install lxml</span><span id="e8c6" class="ny lh it nf b gy od oa l ob oc">make qt5py3</span><span id="d9ac" class="ny lh it nf b gy od oa l ob oc">python3 labelImg.py</span></pre><ul class=""><li id="1ccc" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">运行<code class="fe nc nd ne nf b">python labelImg.py</code></li><li id="f007" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">打开保存了所有交通灯图像的目录</li><li id="9e87" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">对于每个图像，在您想要检测的交通灯周围创建一个矩形框，并相应地添加标签(在我们的例子中是红色、绿色、黄色)</li><li id="732c" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">将它们保存在您选择的目录中。按照以下步骤定制所有图像的标签</li></ul><figure class="ki kj kk kl gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi om"><img src="../Images/06aeede8794158d10e363d63ed611390.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*noKgGcgO73Tn_VfadW3mFw.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">“labelImg GUI ”,其中示例交通灯被标注为“红色”</p></figure><h1 id="4d5f" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">步骤 3:训练-测试分割</h1><p id="43ed" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">进行 90-10 分割:将带注释的图像及其匹配的 XML 注释文件添加到两个独立的文件夹中，分别命名为“train”(90%的图像)和“test”(10%的图像)。</p><h1 id="36b2" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">步骤 4:为训练测试分割生成 TFRecords</h1><p id="e263" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">我们需要一些来自 GitHub 的 Dat Tran 的<a class="ae mu" href="https://github.com/datitran/raccoon_dataset" rel="noopener ugc nofollow" target="_blank">浣熊数据集</a>仓库的帮助器代码。我们只需要从这个回购 2 脚本:<code class="fe nc nd ne nf b">xml_to_csv.py</code>和<code class="fe nc nd ne nf b">generate_tfrecord.py</code>。</p><p id="b1a0" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><strong class="ma iu"> (1) xml_to_csv.py </strong>:</p><ul class=""><li id="8989" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">对该文件的 main 函数进行必要的修改。这将遍历训练和测试，以创建那些单独的 CSV，然后从这些 CSV 中，我们创建 TFRecord</li></ul><p id="96b8" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">在<code class="fe nc nd ne nf b">xml_to_csv.py</code>脚本中，我替换了:</p><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="ace4" class="ny lh it nf b gy nz oa l ob oc">def main():<br/>    image_path = os.path.join(os.getcwd(), 'annotations')<br/>    xml_df = xml_to_csv(image_path)<br/>    xml_df.to_csv('raccoon_labels.csv', index=None)<br/>    print('Successfully converted xml to csv.')</span></pre><p id="3433" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">使用:</p><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="ac63" class="ny lh it nf b gy nz oa l ob oc">def main():<br/>    for directory in ['train','test']:<br/>        image_path = os.path.join(os.getcwd(), 'images/{}'.format(directory))<br/>        xml_df = xml_to_csv(image_path)<br/>        xml_df.to_csv('data/{}_labels.csv'.format(directory), index=None)<br/>        print('Successfully converted xml to csv.')</span></pre><ul class=""><li id="7f49" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">运行<code class="fe nc nd ne nf b">python3 xml_to_csv.py</code>命令。现在，您已经准备好了 CSV 文件:<code class="fe nc nd ne nf b">train_labels.csv</code>和<code class="fe nc nd ne nf b">test_labels.csv</code></li></ul><p id="780d" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><strong class="ma iu">(2)generate _ TF record . py</strong>:</p><ul class=""><li id="6799" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">接下来，我们需要抓取 TFRecord:转到<code class="fe nc nd ne nf b"><a class="ae mu" href="https://github.com/datitran/raccoon_dataset/blob/master/generate_tfrecord.py" rel="noopener ugc nofollow" target="_blank">datitran/raccoon_dataset/blob/master/generate_tfrecord.py</a></code></li><li id="0ee7" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">这里您需要做的唯一修改是在<code class="fe nc nd ne nf b">class_text_to_int</code>函数中。您需要将此更改为您的特定类。在这种情况下，在 if-elif-else 语句中为红色、绿色和黄色各添加三个“row_label”值</li></ul><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="8f2d" class="ny lh it nf b gy nz oa l ob oc"># TO-DO replace this with label map<br/>def class_text_to_int(row_label):<br/>    if row_label == 'Red':<br/>        return 1<br/>    elif row_label == 'Yellow':<br/>        return 2<br/>    elif row_label == 'Green':<br/>        return 3<br/>    else:<br/>        None</span></pre><p id="fae0" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">记得使用相同的 id 值</p><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="df59" class="ny lh it nf b gy nz oa l ob oc">%%writefile training/labelmap.pbtxt<br/>item {<br/>  id: 1<br/>  name: 'Red'<br/>}<br/>item {<br/>  id: 2<br/>  name: 'Yellow'<br/>}<br/>item {<br/>  id: 3<br/>  name: 'Green'<br/>}</span></pre><ul class=""><li id="a862" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">确保已经安装了 Object Detection(GitHub 上的 installation.md)。运行<code class="fe nc nd ne nf b">generate_tfrecord.py</code>的“使用”部分中的两个命令，分别用于训练和测试。</li></ul><p id="241a" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">对于列车 TFRecord:</p><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="da18" class="ny lh it nf b gy nz oa l ob oc">python3 generate_tfrecord.py --csv_input=data/train_labels.csv --output_path=data/train.record --image_dir=images/</span></pre><p id="1f78" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">对于测试 TFRecord:</p><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="160f" class="ny lh it nf b gy nz oa l ob oc">python3 generate_tfrecord.py --csv_input=data/test_labels.csv --output_path=data/test.record --image_dir=images/</span></pre><p id="93ca" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">现在我们已经准备好了训练和测试记录文件。我们需要 TFRecord 文件的原因是将任何会生成数据的文件(比如 PASCAL VOC 格式)转换成 TFRecord，这样我们就可以在对象检测 API 中使用它们。</p><h1 id="61c9" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">步骤 5:设置配置文件</h1><p id="ce64" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">为了训练我们的模型，我们需要设置一个配置文件(连同 TFRecord 和一个预训练的模型)。请在<a class="ae mu" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> Tensorflow 对象检测 API </a>上找到所有相关文件、安装信息、预训练模型等。</p><p id="11d1" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">步骤:</p><ul class=""><li id="d6f0" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">去 GitHub 上的<code class="fe nc nd ne nf b"><a class="ae mu" href="https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs</a></code></li><li id="2cc1" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">从 TF 模型检测动物园下载 faster _ rcnn _ inception _ v2 _ coco 模型的配置文件(<code class="fe nc nd ne nf b"><a class="ae mu" href="https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config" rel="noopener ugc nofollow" target="_blank">faster_rcnn_inception_v2_coco.config</a></code>)和检查点(. tar.gz 文件)</li><li id="58f4" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">运行两个命令，分别下载配置文件和更快的 R-CNN 模型(同时提取下载的模型)。将配置文件放在<code class="fe nc nd ne nf b">training</code>目录下，提取<code class="fe nc nd ne nf b">models/object_detection</code>目录下的<code class="fe nc nd ne nf b">faster_rcnn_inception_v2_coco</code></li><li id="54ea" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">修改配置文件以满足您的要求，包括但不限于<code class="fe nc nd ne nf b">PATH_TO_BE_CONFIGURED</code>、<code class="fe nc nd ne nf b">num_classes</code>、<code class="fe nc nd ne nf b">batch_size</code>、<code class="fe nc nd ne nf b">checkpoint name</code>、到<code class="fe nc nd ne nf b">fine_tune_checkpoint</code>、<code class="fe nc nd ne nf b">label_map_path: “training/object-detect.pbtxt”</code>的路径</li><li id="cba4" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">添加带有红色、黄色和绿色的项目和 id 值的标签映射文件(如步骤 4 所示)</li></ul><h1 id="ca31" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">步骤 6:训练实际模型</h1><ul class=""><li id="5bf2" class="ng nh it ma b mb mc me mf mh og ml oh mp oi mt nl nm nn no bi translated">在<code class="fe nc nd ne nf b">models/object_detection </code>中，使用 python 命令运行您的模型，同时包含保存模型的路径，配置文件的管道</li></ul><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="4949" class="ny lh it nf b gy nz oa l ob oc">python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_coco.config</span></pre><ul class=""><li id="e969" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">此时，除非出现错误，否则您应该会看到模型摘要，其中包含步骤及其相应的损失值，如下所示</li></ul><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="7429" class="ny lh it nf b gy nz oa l ob oc">INFO:tensorflow:global step 11788: loss = 0.6717 (0.398 sec/step)<br/>INFO:tensorflow:global step 11789: loss = 0.5310 (0.436 sec/step)<br/>INFO:tensorflow:global step 11790: loss = 0.6614 (0.405 sec/step)<br/>INFO:tensorflow:global step 11791: loss = 0.7758 (0.460 sec/step)<br/>INFO:tensorflow:global step 11792: loss = 0.7164 (0.378 sec/step)<br/>INFO:tensorflow:global step 11793: loss = 0.8096 (0.393 sec/step)</span></pre><p id="eb94" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">你的步骤从 1 开始，亏损会高很多。根据你的 GPU 和你有多少训练数据，这个过程将需要不同的时间。你希望平均损失约为 1 英镑(或更低)。</p><ul class=""><li id="d3c9" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">您可以加载 Tensorboard 来可视化这些值，包括损耗、准确度、步数和训练时间</li><li id="bd90" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">现在，您已经准备好了经过训练的模型。接下来，通过检查点加载模型</li></ul><p id="547c" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><strong class="ma iu">更快的 R-CNN 模型架构:</strong> <br/>更快的 R-CNN 最初发表于<a class="ae mu" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank"> NIPS 2015 </a>。它的结构很复杂，因为它有几个移动的部分。</p><p id="135b" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">这是该模型的高级概述。这一切都始于一幅图像，我们希望从中获得:</p><ul class=""><li id="b765" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">边界框列表</li><li id="dc24" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">分配给每个边界框的标签</li><li id="5d3e" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">每个标签和边界框的概率</li></ul><figure class="ki kj kk kl gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi on"><img src="../Images/4834bf30ce4daab88b0a2e94534dae71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2J5wquHKV-dk8V_oartloA.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated"><a class="ae mu" href="https://www.mdpi.com/2076-3417/10/1/83" rel="noopener ugc nofollow" target="_blank">特色图片致谢</a> : <a class="ae mu" href="https://sciprofiles.com/profile/862933" rel="noopener ugc nofollow" target="_blank">阿塔坎·科雷兹</a>和<a class="ae mu" href="https://sciprofiles.com/profile/358417" rel="noopener ugc nofollow" target="_blank">内卡阿丁酒吧</a></p></figure><p id="c1cd" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">由<a class="ae mu" href="https://tryolabs.com/blog/authors/javier-rey/" rel="noopener ugc nofollow" target="_blank">哈维尔·雷</a>撰写的博客很好地解释了物体检测如何在更快的 R-CNN 上工作，这可以在<a class="ae mu" href="https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/" rel="noopener ugc nofollow" target="_blank"> Tryolabs </a>上找到。<br/>要快速了解更快的 R-CNN 及其地区提案网络，请参考<a class="na nb ep" href="https://medium.com/u/8b44cbadef3a?source=post_page-----811b7bcd31c4--------------------------------" rel="noopener" target="_blank">高昊</a>在<a class="ae mu" href="https://medium.com/@smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8" rel="noopener">媒体</a>上的博文。</p><p id="e365" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><em class="oe">注</em>:</p><ul class=""><li id="611b" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">在尝试了包括 SSD Inception V2、更快的 R-CNN 和 Nvidia 的卷积神经网络在内的不同模型后，我们最终决定使用更快的 R-CNN，因为我们发现它的性能对于我们的交通灯数据集来说非常有吸引力。归根结底，选择合适的型号是在“准确性”和“速度”之间进行权衡，以满足您的要求。</li><li id="d010" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">请在代码为的<a class="ae mu" href="https://paperswithcode.com/task/object-detection" rel="noopener ugc nofollow" target="_blank">纸上找到对象检测的最新模型。我决定选择更快的 R-CNN，因为它的性能满足目标检测过程中“准确性”而不是“速度”的要求。此外，TensorFlow 没有通过将 SOTA 模型添加到其 TensorFlow 对象检测 API 存储库中来与它们保持同步。</a></li></ul><h1 id="bacd" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">步骤 7:从新训练的模型中导出图表</h1><ul class=""><li id="3e89" class="ng nh it ma b mb mc me mf mh og ml oh mp oi mt nl nm nn no bi translated">在这一步，我们将测试我们的模型，看看它是否如我们所愿。为了做到这一点，我们需要导出推理图。在<code class="fe nc nd ne nf b">models/object_detection</code>目录中，有一个脚本为我们完成了这项工作:<code class="fe nc nd ne nf b">export_inference_graph.py</code></li><li id="d851" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">转到<code class="fe nc nd ne nf b">installation.md</code>(<a class="ae mu" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/models/blob/master/research/object _ detection/g3doc/installation . MD</a>)中的“Protobuf 编译”部分，按照给出的说明导出路径。这就加载了 TensorFlow，然后制作图表并保存</li><li id="51bd" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">使用 API 附带的笔记本<code class="fe nc nd ne nf b">object_detection_tutorial.ipynb</code>进行物体检测</li></ul><h1 id="515c" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">第八步:引入冻结推理图对交通灯进行实时分类</h1><ul class=""><li id="330f" class="ng nh it ma b mb mc me mf mh og ml oh mp oi mt nl nm nn no bi translated">修改<code class="fe nc nd ne nf b">export_inference_graph.py</code>来满足你的要求。要运行这个，您只需要传入您的检查点和您的管道配置，然后在任何您想要放置推理图的地方。例如:</li></ul><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="4616" class="ny lh it nf b gy nz oa l ob oc">python3 export_inference_graph.py \<br/>    --input_type image_tensor \<br/>    --pipeline_config_path training/faster_rcnn_inception_v2_coco.config \<br/>    --trained_checkpoint_prefix training/model.ckpt-10856 \<br/>    --output_directory traffic_lights_inference_graph</span></pre><ul class=""><li id="86e4" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">运行安装命令导出推理图(<a class="ae mu" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/models/blob/master/research/object _ detection/g3doc/installation . MD</a>)。现在，您已经准备好了<code class="fe nc nd ne nf b">frozen_inference_graph.pb</code>和检查点文件</li><li id="75f7" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">您的检查点文件应该在<code class="fe nc nd ne nf b">training</code>目录中。只要找一个步长最大的(破折号后最大的数字)，那就是你要用的。接下来，确保将<code class="fe nc nd ne nf b">pipeline_config_path</code>设置为您选择的任何配置文件，然后最后选择输出目录的名称，比如说<code class="fe nc nd ne nf b">traffic_lights_inference_graph</code></li></ul><p id="cc04" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">从<code class="fe nc nd ne nf b">models/object_detection</code>运行上述命令。如果您得到一个关于没有名为“nets”的模块的错误，那么您需要重新运行:</p><pre class="ki kj kk kl gt nu nf nv nw aw nx bi"><span id="fa2c" class="ny lh it nf b gy nz oa l ob oc"># From tensorflow/models/<br/>export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim<br/># switch back to object_detection after this and re run the above command</span></pre><ul class=""><li id="0b81" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">打开<code class="fe nc nd ne nf b">object_detection_tutorial.ipynb</code>笔记本。在笔记本上进行必要的修改，包括但不限于<code class="fe nc nd ne nf b">MODEL_NAME</code>、<code class="fe nc nd ne nf b">PATH_TO_CKPT</code>、<code class="fe nc nd ne nf b">PATH_TO_LABELS</code>、<code class="fe nc nd ne nf b">NUM_CLASSES</code>、<code class="fe nc nd ne nf b">TEST_IMAGE_PATHS</code>。运行笔记本以查看带有边界框的交通灯及其预测精度</li></ul><p id="fb16" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><strong class="ma iu">结果:</strong></p><div class="ki kj kk kl gt ab cb"><figure class="km kn oo kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/d4e2728fde8221775582d91fa37c7a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*EORlEI59pvQIYsdOC2p_3A.png"/></div></figure><figure class="km kn oo kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/3e988bc40938fbf1ae5e277f0a02d6ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*wfPJ7xTB8CJNt9vGg1ttwg.png"/></div></figure><figure class="km kn op kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/2f3eacde7e4a9142f5827f0b4766149d.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*DwDMfiIovIwiVbQ8Q2wdJg.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk oq di or lf translated">来自模拟器的图像用边界框和预测精度分类</p></figure></div><div class="ab cb"><figure class="km kn os kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/a0f99072c5ac42e2a28791e0dc1e651f.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*04FDoj2nVI7cnaRqFsMFMg.png"/></div></figure><figure class="km kn ot kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/b2e21dc789ebbd668a8a78e0da909d5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*BcgXQLxwUxrfENhIayNOSA.png"/></div></figure><figure class="km kn os kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/22bc898853edf7dfcb5203a3f657f510.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*DwDMfiIovIwiVbQ8Q2wdJg.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk ou di ov lf translated">使用边界框和预测精度分类的站点图像</p></figure></div><p id="0288" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><strong class="ma iu">限制:</strong></p><ul class=""><li id="d360" class="ng nh it ma b mb mv me mw mh ni ml nj mp nk mt nl nm nn no bi translated">鉴于这个项目的范围，除了模拟器和 CARLA 网站上的图片，我只使用了网上的一些图片。而且，这个模型还没有在一个新的未知网站上测试过。</li><li id="e570" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">该模型在独特的光照和天气条件下的表现尚不清楚，因为这里使用的大多数图像都是在典型的晴朗天气拍摄的。</li><li id="8b8c" class="ng nh it ma b mb np me nq mh nr ml ns mp nt mt nl nm nn no bi translated">随着该领域的不断研究，还有其他<a class="ae mu" href="https://paperswithcode.com/task/object-detection" rel="noopener ugc nofollow" target="_blank">最先进的物体检测模型</a>可能具有相对更好的性能精度。</li></ul><p id="fb99" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><strong class="ma iu">致谢:</strong></p><p id="930c" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">感谢巴斯蒂安·特龙和大卫·斯塔文斯(创始人，<a class="na nb ep" href="https://medium.com/u/2929690a28fb?source=post_page-----811b7bcd31c4--------------------------------" rel="noopener" target="_blank"> Udacity </a>)、<a class="na nb ep" href="https://medium.com/u/8190c86ea791?source=post_page-----811b7bcd31c4--------------------------------" rel="noopener" target="_blank">大卫·西尔弗</a>、<a class="na nb ep" href="https://medium.com/u/a878b47f7040?source=post_page-----811b7bcd31c4--------------------------------" rel="noopener" target="_blank">瑞安·基南</a>、<a class="na nb ep" href="https://medium.com/u/14fba6c89ce?source=post_page-----811b7bcd31c4--------------------------------" rel="noopener" target="_blank">塞尚·卡马乔</a>对课程材料和指导的帮助，以及官方合作伙伴的演讲嘉宾，包括<a class="na nb ep" href="https://medium.com/u/ab69c39a85e1?source=post_page-----811b7bcd31c4--------------------------------" rel="noopener" target="_blank">英伟达 AI </a>、<a class="na nb ep" href="https://medium.com/u/4275c7808cea?source=post_page-----811b7bcd31c4--------------------------------" rel="noopener" target="_blank"> UberATG </a>、梅赛德斯-奔驰、宝马、迈凯轮、滴滴出行，他们提供的专业知识极大地帮助了研究。</p></div><div class="ab cl ow ox hx oy" role="separator"><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb"/></div><div class="im in io ip iq"><p id="0fd3" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">如果你有任何意见想与我分享(或)对我的写作或想法提供任何相关的反馈，我会很高兴收到你的来信。请随时在<a class="ae mu" href="http://twitter.com/ThisIsSandeepA" rel="noopener ugc nofollow" target="_blank"><strong class="ma iu"><em class="oe">Twitter</em></strong></a><em class="oe"/><a class="ae mu" href="https://www.linkedin.com/in/sandeep-a/" rel="noopener ugc nofollow" target="_blank"><strong class="ma iu"><em class="oe">LinkedIn</em></strong></a><em class="oe">上与我联系，或者在</em><a class="ae mu" href="https://github.com/SandeepAswathnarayana" rel="noopener ugc nofollow" target="_blank"><strong class="ma iu"><em class="oe">GitHub</em></strong></a><em class="oe">上关注我。</em></p></div></div>    
</body>
</html>