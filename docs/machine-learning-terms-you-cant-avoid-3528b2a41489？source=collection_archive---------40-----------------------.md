# 你无法回避的机器学习术语

> 原文：<https://towardsdatascience.com/machine-learning-terms-you-cant-avoid-3528b2a41489?source=collection_archive---------40----------------------->

## 无论你多么努力…

![](img/00e3673310306e8b57bf4a816dea2a21.png)

安迪·凯利在 [Unsplash](https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上的照片

## 介绍

J 就像上图中的小女孩一样，她将无法避免机器人技术对她未来的影响，作为机器学习从业者，我们无法简单地避免某些术语。

这些是机器学习领域的基本术语。他们参与神经网络的实现、训练、改进和评估。

## 花一些时间来学习每个术语，并进一步研究每个词如何对机器学习模型的开发不可或缺。

## 学习率

学习率是神经网络不可或缺的组成部分，因为它是一个值因子，决定了网络权重值的更新级别。

在可视化练习中，要求解的函数可以被描述为 n 维参数空间中的双曲线，学习率是影响当前参数值朝向局部/全局最小值的步长的分量。因此，学习速率直接影响训练期间网络的收敛速率。

如果学习率太低，网络可能需要几次迭代和历元才能收敛，相反，如果学习率太高，则有超过最小值的风险，因此我们的训练不会收敛。

选择合适的学习速率可能是一个漫长的过程，尽管有一些技术可以优化这个过程。

## 学习率计划

在神经网络的训练期间，可以利用恒定的学习速率，但是这可能增加为了达到最佳神经网络性能而必须进行的训练量。

通过利用学习速率表，我们在训练期间引入学习速率的适时降低或增加，以达到神经网络的最佳训练结果。

## 学习率衰减

学习率衰减减少了梯度下降过程中朝向局部最小值采取的步长的振荡。

通过将学习率降低到与训练开始时使用的学习率值相比更小的值，我们可以将网络引向在最小值附近的更小范围内振荡的解。

## 消失梯度

消失梯度问题是神经网络性能和精度的一个限制因素。它是反向传播过程中梯度值不稳定的产物，影响神经网络中的早期层。

消失梯度更具体地存在于深度神经网络(具有若干层的网络)的训练中。所以这是大多数深度学习解决方案中普遍存在的问题。

在反向传播期间，优化算法通过考虑来自网络中后面层的梯度的累积积来导出梯度。具体来说，对于消失梯度的问题，来自网络的较后层的梯度具有 0 和 1 之间的值。因此，梯度的乘积产生了更小的量。

这些小值用于更新网络中较早层的权重，这实际上对当前权重值几乎没有改变。

早期层中神经网络权重的最小变化限制了网络可以学习的程度。此外，网络的训练可能需要更长的时间，因为网络需要更长的时间来收敛并达到最优解。

## 爆炸梯度

类似于消失梯度问题，爆炸梯度问题是反向传播期间神经网络内梯度不稳定的结果。

在爆炸梯度的情况下，如果网络中后面层的单个梯度分量大于 1，那么在反向传播期间用于计算前面层的梯度的后面层的乘积将是巨大的。

这使得对早期层中的权重的更新具有更高的值；因此，神经网络超过了最优解，并且训练不收敛。

## 批量标准化

传统的归一化是将要素输入值放置在同一组等价尺度上的过程。因此，对于通过网络转发的图像输入值，像素值被归一化为 0 到 1 范围内的值。

Christian Szegedy 和 Sergey Ioffe 在 2015 年发表的[论文](https://arxiv.org/abs/1502.03167)中提出了批量标准化技术。通过在神经网络层引入输入值的内部标准化，批量标准化被作为**加速深度神经网络**训练阶段的解决方案。

可以在激活函数之前或之后对神经网络层的输入应用批处理规范化。在任一情况下，图层的输出都是归一化的。

批量标准化过程分为两个阶段，标准化和规范化。以下是对输入值进行操作的步骤:

*   **通过减去平均值并除以标准偏差量，零点将输入值**居中。这提供了运行中的当前输入批次，其平均值为 0，标准偏差为 1
*   **缩放输入值**
*   **偏移输入值**

通过批量标准化，标准化数据的过程不再局限于网络的输入层，现在是神经网络的内部组成部分。表示批量标准化操作中的*偏移*和*刻度*的参数值也可以在训练期间学习。

通过可学习的批量归一化参数，每一层的输入值被最佳地归一化。

它被称为“批量”规范化，因为所执行的操作是基于通过网络输入的每一批输入值。

## 渐变剪辑

梯度裁剪是一种用于调节神经网络内梯度值不稳定性的技术。这是通过对梯度值施加阈值来实现的。

阈值通常指定在选定的最小值和最大值之间。并且在反向传播期间，梯度值取定义的最小值和最大值内的值。

梯度裁剪主要用于在训练深度神经网络时防止梯度爆炸。它调节从梯度下降优化算法得到的步长，防止其取大值。这确保了我们不会超过全球最小值

## 结论

我们已经学习了七个标准的机器学习术语，并深入了解了每个术语的表层细节。

展望未来，我建议探索一下在流行的深度学习库中，如 Keras、Pytorch 和 TensorFlow，提到的每个术语是如何实现的。

下面是几篇文章，你可以阅读，以获得更多关于机器学习的知识。

[](/in-depth-machine-learning-image-classification-with-tensorflow-2-0-a76526b32af8) [## 使用 TensorFlow 2.0 进行(深入)机器学习图像分类

### 理解实现用于图像分类的神经网络的过程。

towardsdatascience.com](/in-depth-machine-learning-image-classification-with-tensorflow-2-0-a76526b32af8) [](/understanding-motion-analysis-in-machine-learning-f504e9987413) [## 理解机器学习中的运动分析

### 一篇关于运动分析基础的简短文章，以及机器学习如何被用来解决这个计算机…

towardsdatascience.com](/understanding-motion-analysis-in-machine-learning-f504e9987413)