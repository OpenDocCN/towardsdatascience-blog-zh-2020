<html>
<head>
<title>Predictive Analytics for SEO and Marketing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">搜索引擎优化和营销的预测分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dunkin-donuts-seo-project-in-python-967b6ce18de5?source=collection_archive---------29-----------------------#2020-09-08">https://towardsdatascience.com/dunkin-donuts-seo-project-in-python-967b6ce18de5?source=collection_archive---------29-----------------------#2020-09-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="93c5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Python 进行关键字研究</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4011a5f8e3edfccf05842ef62a0f248a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dwVL-apx5IpEtuHyz9vLCw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">布雷特·乔丹在<a class="ae ky" href="https://unsplash.com/s/photos/words?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="2dcf" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">概观</h1><p id="37f5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Dunkin donuts 的市场部(MD)注意到，在过去的 6 个月中，他们的一些关键词排名下降了。因此，他们正在进行一个新的 SEO 项目，专注于在谷歌上排名第二的关键词。为此，将使用训练数据来开发预测模型，以预测有可能为网站带来最大流量的关键词。这些关键词将在接下来的六个月里成为一个全面的 SEO 项目的重点。</p><p id="f945" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通过将预测模型应用于训练数据，将利用数据科学方法来解决这一业务问题，训练数据将包括除第 2 页排名之外的所有关键词。然后，结果将被应用到第 2 页的排名，以确定最好的关键字集中。成功将取决于在一年内将关键字排名提高到谷歌的第一页。</p><h1 id="5578" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据</h1><p id="5017" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">总经理可以从塞姆拉什获取邓金的 10000 条关键词记录。这些数据包括:</p><p id="449b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">关键词</p><p id="8597" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">位置</p><p id="6bf9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以前的职位</p><p id="b45b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">搜索量</p><p id="c63d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">关键词难度</p><p id="088d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">CPC</p><p id="513a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">URL</p><p id="76c5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">交通</p><p id="a44d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">流量(%)</p><p id="8e07" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">交通成本</p><p id="8cc0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">竞争</p><h1 id="82b4" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">方法</h1><p id="5c5e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">1.从 SEMRush 导出关键字数据</p><p id="134e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">2.从数据中提取第二页排名作为应用程序。</p><p id="05fe" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">3.将数据分成 80/20 个训练测试集。</p><p id="f38f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">4.执行 EDA 以了解数据</p><p id="f653" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">5.创建 Tableau 仪表板以显示 EDA</p><p id="180b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">6.基于训练数据的训练预测模型。</p><p id="6d62" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">7.评估测试数据的性能</p><p id="9745" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">8.应用于第二页等级数据</p><p id="f577" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">9.确定第二页的关键词，集中搜索引擎优化的努力</p><h1 id="9cb4" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">可交付成果</h1><p id="ad5f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">数据清理和 EDA 代码</p><p id="8fd1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">模型拟合代码</p><p id="f835" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">EDA 的 Tableau 仪表板</p><p id="3a4a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">描述建议的报告</p><h1 id="c999" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据争论</h1><p id="2470" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">数据争论过程将包括以下步骤:</p><ol class=""><li id="55f2" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">加载必要的包</li><li id="0335" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">加载数据</li><li id="f0af" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">查看数据和元数据</li><li id="bd21" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">删除不必要的列</li></ol><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="24e5" class="nl la it nh b gy nm nn l no np"><strong class="nh iu">import</strong> <strong class="nh iu">pandas</strong> <strong class="nh iu">as</strong> <strong class="nh iu">pd</strong><br/><strong class="nh iu">import</strong> <strong class="nh iu">matplotlib.pyplot</strong> <strong class="nh iu">as</strong> <strong class="nh iu">plt</strong><br/><strong class="nh iu">import</strong> <strong class="nh iu">seaborn</strong> <strong class="nh iu">as</strong> <strong class="nh iu">sns</strong><br/><strong class="nh iu">import</strong> <strong class="nh iu">datetime</strong><br/><strong class="nh iu">import</strong> <strong class="nh iu">numpy</strong> <strong class="nh iu">as</strong> <strong class="nh iu">np</strong></span><span id="bdda" class="nl la it nh b gy nq nn l no np"><em class="nr"># setup </em><br/><em class="nr">#sns.set_style(style="whitegrid")</em><br/>sns.set_style('ticks')<br/><br/><em class="nr"># display charts inline</em><br/>%matplotlib inline<br/><br/><em class="nr"># to display all columns</em><br/>pd.set_option('display.max_columns', <strong class="nh iu">None</strong>)<br/><em class="nr"># setup </em><br/><em class="nr">#sns.set_style(style="whitegrid")</em><br/>sns.set_style('ticks')<br/><br/><em class="nr"># display charts inline</em><br/>%matplotlib inline<br/><br/><em class="nr"># to display all columns</em><br/>pd.set_optdf.head()<br/>ion('display.max_columns', <strong class="nh iu">None</strong>)</span><span id="2acb" class="nl la it nh b gy nq nn l no np">Data is available here: <a class="ae ky" href="https://github.com/meagvo/DunkinDonutsSEOproject/blob/master/dunkin.csv" rel="noopener ugc nofollow" target="_blank">https://github.com/meagvo/DunkinDonutsSEOproject/blob/master/dunkin.csv</a></span><span id="b2de" class="nl la it nh b gy nq nn l no np"><em class="nr">#load the data</em><br/>df=pd.read_csv('dunkin.csv')<br/><em class="nr">#look at the column names</em><br/>df.columns</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/b6e2430b46d8a93697c2ca54ad327c78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZGTX59vvtSGTQ50C0LWPmQ.png"/></div></div></figure><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e0b3" class="nl la it nh b gy nm nn l no np"><em class="nr">#metadata 15 columns 10000 records</em><br/><br/>df.info()<br/><em class="nr">#missing data for SERP Features by Keyword, but this column will be dropped because it isn't relevant for the analysis</em></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/6a635006067698a941bd277efebc3558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*jA8BLZGbxtb5-4-rJEKYxg.png"/></div></figure><h1 id="8a11" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">删除不必要的列</h1><p id="7679" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们对大多数列值感兴趣，但是有几个对当前的分析没有帮助。因此，我们将删除以下两列:</p><ul class=""><li id="b43b" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm nu my mz na bi translated">趋势</li><li id="8035" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm nu my mz na bi translated">按关键字排序的 SERP 特征</li></ul><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="bf19" class="nl la it nh b gy nm nn l no np"><em class="nr">#drop two columns</em><br/>df.drop(df[['Trends', 'SERP Features by Keyword']], inplace=<strong class="nh iu">True</strong>, axis=1)<br/></span></pre><p id="15f1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">探索性数据分析</strong></p><p id="2fe8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">df.describe()。T</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/27af34845fff18bedf1a63903668536f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QR1pzkIZI9fDKby4m9AsTw.png"/></div></div></figure><h1 id="c69d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">可视化数据:散点图</h1><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c223" class="nl la it nh b gy nm nn l no np">plt.scatter(df['Position'], df['Previous position'])<br/>plt.title("Position vs. Previous Position")<br/>plt.xlabel('Position')<br/>plt.ylabel("Previous Position")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/7c86decdf934b9797bb2066a79646875.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*FDHTpFwh7cl9843P2Csq0Q.png"/></div></figure><p id="a269" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从散点图可以清楚地看出，大多数位置与先前的位置相关，这意味着它们是稳定的。不过有一些看起来是排在 0 的，没什么意义。那一定意味着他们排不进前 100 位。因此，我们希望将重点放在前两个 SERPs 上。</p><h1 id="60c2" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">让我们想象一下排在谷歌前 2 页的关键词/页面。</h1><p id="7378" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这些都是密切相关的。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4cc9" class="nl la it nh b gy nm nn l no np">plt.scatter(df['Position'], df['Previous position'])<br/>plt.title("Position vs. Previous Position")<br/>plt.xlabel('Position')<br/>plt.ylabel("Previous Position")<br/>plt.xlim(1, 20,)<br/>plt.ylim(1, 20)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/e7a1a21a78fd1574ece6ffd50e09aa5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*0X_AUlTjcsd4LM-DbNQvMQ.png"/></div></figure><p id="8d41" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">corr matrix = df . corr()SNS . heat map(corr matrix，annot= <strong class="lt iu"> True </strong>，cmap = ' RdBu ')PLT . fig(figsize =(20，20)) plt.show()</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/b68b1a56c80b210764878c29667948b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*fQQMxqpsBJWllfvlzYls1Q.png"/></div></figure><p id="8fb8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">看起来流量、流量百分比和流量成本是共线的。因此，在分析中最好只包括其中一种方法。我们将分析流量原始指标。所以现在，我们将降低流量百分比和流量成本。</p><p id="4ecd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">df.drop(columns=['Traffic (%)'，' Traffic Cost']，inplace= <strong class="lt iu"> True </strong>)</p><h1 id="1d99" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">基线模型</h1><p id="896c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">作为该预测模型的简单模型，我们选择了多元线性回归。这是一个概念上的基本模型，与其他预测模型相比，解释相对简单。此外，随着研究问题的发展，我们可以将该模型应用于其他感兴趣的目标变量。'</p><p id="f1e4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这个多元回归模型中，我们必须对数据进行预处理。对于连续变量，这意味着分别通过平均值和标准偏差对数据进行居中和缩放，但对于分类数据，这包括创建虚拟变量。</p><p id="7d0c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后我们去掉包含任意日期的变量，比如时间戳。这在回归环境中很难处理。</p><p id="eb01" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">关键字列将被分隔，因为它是标签列。这将从预处理数据中删除，因为它不会输入到回归模型中。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c7bd" class="nl la it nh b gy nm nn l no np">df1=df.drop(columns=’Keyword’) keyword=df[‘Keyword’] df1.head() df1.drop(columns=’Unnamed: 0') <br/>df1.columns<br/>continuous_var=df1.drop(columns='URL')<br/><br/>continuous_var.drop(columns='Unnamed: 0', inplace=<strong class="nh iu">True</strong>)<br/>continuous_var.head()<br/><br/>cat_var=['URL']</span></pre><h1 id="936a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">预处理</h1><p id="f44e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">连续变量将被缩放和居中，因为当所有变量具有相似的平均值和方差时，许多预测模型表现更好。此外，我们确保没有丢失的行或列，这是我们已经确定的。接下来，自变量被放入数组(x)中，目标变量(位置)被放入第二个数组(y)中。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="11d7" class="nl la it nh b gy nm nn l no np">scaler = StandardScaler()<br/>df_scaled = pd.DataFrame(scaler.fit_transform(continuous_var))<br/>df_scaled.columns<br/>df_scaled.head()<br/>df_scaled.columns=[ 'Position', 'Previous position', 'Search Volume',<br/>       'Keyword Difficulty', 'CPC', 'Traffic', 'Competition',<br/>       'Number of Results']<br/>df_scaled['URL'] = df1[cat_var]<br/><br/>df_scaled.head() df_new = pd.get_dummies(df_scaled,dummy_na=<strong class="nh iu">True</strong>) X=df_new.drop(columns='Position') y=df_new['Position']</span></pre><h1 id="a601" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">训练和测试模型</h1><p id="d49d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">接下来，我们将数据分为训练集和测试集。训练集将用于交叉验证模型的超参数，测试集将用于验证模型。</p><p id="3b55" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">首先，我将使用默认参数创建一个模型。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="3ec1" class="nl la it nh b gy nm nn l no np"><em class="nr">#Split into test/train</em><br/>X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.33, random_state=42)<br/><em class="nr"># with sklearn</em><br/>regr = LinearRegression()<br/>regr.fit(X_train, y_train)<br/>y_pred=regr.predict(X_test)<br/>explained_variance_score(y_test, y_pred)<br/></span></pre><p id="4f79" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">看起来 URL 列扭曲了模型。现在让我们尝试删除 URL 列并再次运行模型。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="35bc" class="nl la it nh b gy nm nn l no np">df_scaled.drop(columns='URL', inplace=<strong class="nh iu">True</strong>)<br/><br/>X2=df_scaled.drop(columns='Position')<br/> y2=df_scaled['Position']<br/><em class="nr">#Split into test/train</em><br/>X_train2, X_test2, y_train2, y_test2= train_test_split(X2, y2, test_size=0.2, random_state=42)<br/><em class="nr"># with sklearn</em><br/>regr2 = LinearRegression()<br/>regr2.fit(X_train2, y_train2)<br/><br/>print('Intercept: <strong class="nh iu">\n</strong>', regr2.intercept_)<br/>print('Coefficients: <strong class="nh iu">\n</strong>', regr2.coef_)<br/>y_pred2=regr2.predict(X_test2)<br/>explained_variance_score(y_test2, y_pred2)</span><span id="12a7" class="nl la it nh b gy nq nn l no np"><em class="nr"># Calculate the absolute errors</em><br/>errors = abs(y_pred2 - y_test2)<br/><em class="nr"># Print out the mean absolute error (mae)</em><br/>print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')<br/><em class="nr"># Calculate mean absolute percentage error (MAPE)</em><br/>mape = 100 * (errors / y_test2)<br/><em class="nr"># Calculate and display accuracy</em><br/>accuracy = 100 - np.mean(mape)<br/>print('Accuracy:', round(accuracy, 2), '%.')</span></pre><p id="2c9d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这大大改进了模型。但是我们有可能做得更好。让我们试试随机森林回归。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="85d5" class="nl la it nh b gy nm nn l no np"><em class="nr"># Import the model we are using</em> <br/><strong class="nh iu">from</strong> <strong class="nh iu">sklearn.ensemble</strong> <strong class="nh iu">import </strong>RandomForestRegressor <br/><em class="nr"># Instantiate model with 1000 decision trees</em> rf = RandomForestRegressor(n_estimators = 1000, random_state = 42) <em class="nr"># Train the model on training data</em> rf.fit(X_train2, y_train2);<em class="nr"><br/># Use the forest's predict method on the test data</em><br/>predictions = rf.predict(X_test2)<br/><em class="nr"># Calculate the absolute errors</em><br/>errors = abs(predictions - y_test2)<br/><em class="nr"># Print out the mean absolute error (mae)</em><br/>print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')<br/><em class="nr"># Calculate mean absolute percentage error (MAPE)</em><br/>mape = 100 * (errors / y_test2)<br/><em class="nr"># Calculate and display accuracy</em><br/>accuracy = 100 - np.mean(mape)<br/>print('Accuracy:', round(accuracy, 2), '%.')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/f18fcfaffd83b3e1642ecde7919da90d.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*zjCU_6ML2zv0Lolp44I2YA.png"/></div></figure><h1 id="6eba" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">分析</h1><p id="ce2b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">获胜的模型是随机森林回归，因为它具有最低的 MAE 和最高的准确性。它还删除了 URL 列，该列似乎扭曲了第一次回归的结果。这将允许我们预测 Dunkin Donuts 的新关键字的位置。下一步是继续 Answerthepublic 和 Google Keyword Planner，提取相关的关键词，然后将信息插入这个模型，以确定哪个有可能在 Dunkin 中排名最高。然后，MD 可以通过全面的 SEO 活动来重点推广该关键词。</p></div></div>    
</body>
</html>