<html>
<head>
<title>Distributed training in tf.keras with Weights &amp; Biases</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">tf.keras中带权重和偏差的分布式培训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/distributed-training-in-tf-keras-with-w-b-ccf021f9322e?source=collection_archive---------44-----------------------#2020-04-29">https://towardsdatascience.com/distributed-training-in-tf-keras-with-w-b-ccf021f9322e?source=collection_archive---------44-----------------------#2020-04-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="1506" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/production-ml" rel="noopener" target="_blank">生产中的机器学习</a></h2><div class=""/><div class=""><h2 id="a303" class="pw-subtitle-paragraph kd jc it bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">探索以最少的代码更改来分配您的培训工作量的方法，并使用权重和偏差(W&amp;B)来分析系统指标。</h2></div><p id="1442" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">查看<a class="ae lr" href="https://app.wandb.ai/sayakpaul/tensorflow-multi-gpu-dist/" rel="noopener ugc nofollow" target="_blank">关于体重和偏见的交互式仪表盘</a>。</p><h1 id="b6e4" class="ls lt it bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">介绍</h1><p id="8287" class="pw-post-body-paragraph kv kw it kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">在这份报告中，我将向您展示如何无缝集成<code class="fe jz ka kb kc b"><a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy" rel="noopener ugc nofollow" target="_blank">tf.distribute.MirroredStrategy</a></code>，以便针对<code class="fe jz ka kb kc b">tf.keras</code>型号在多个GPU之间分配您的培训工作负载。当您拥有非常大的数据集，并且需要调整培训成本时，分布式培训会非常有用。仅在单个硬件加速器(在这种情况下是GPU)上执行训练变得不现实，因此需要执行分布式训练。</p><blockquote class="mp mq mr"><p id="c639" class="kv kw ms kx b ky kz kh la lb lc kk ld mt lf lg lh mu lj lk ll mv ln lo lp lq im bi translated">查看<a class="ae lr" href="https://github.com/sayakpaul/tf.keras-Distributed-Training" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>上的代码。</p></blockquote><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi mw"><img src="../Images/0a0cddae636cae8e2b3c033261132b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DKT7abyMJHSvI70z_tHlcw.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">查看<a class="ae lr" href="https://app.wandb.ai/sayakpaul/tensorflow-multi-gpu-dist/" rel="noopener ugc nofollow" target="_blank">关于重量和偏差的交互式仪表盘</a></p></figure><p id="587d" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在报告的结尾，我们将看到两种方法可以使分布式训练非常有效——a .<strong class="kx jd">预取</strong>数据，以便模型在完成一个时期后就可以使用这些数据，b .调整批量大小。</p><p id="d91f" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">非常感谢Google的Martin Gorner(ka ggle团队的ML产品经理)为我准备这份报告提供了指导。</p><p id="8005" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">TensorFlow的<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/distribute" rel="noopener ugc nofollow" target="_blank">分布式策略</a>使我们能够极其轻松地在多个硬件加速器之间无缝扩展我们繁重的训练工作量，无论是GPU还是TPU。也就是说，分布式训练长期以来一直是一个挑战，尤其是在神经网络训练方面。分布式培训程序带来的主要挑战如下:</p><ul class=""><li id="4f4e" class="nm nn it kx b ky kz lb lc le no li np lm nq lq nr ns nt nu bi translated">我们如何在不同的设备上分配模型参数？</li><li id="612a" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">我们如何在反向传播过程中累积梯度？</li><li id="2df6" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">模型参数将如何更新？</li></ul><p id="5663" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果您从头到尾考虑培训过程，所有这些听起来可能非常令人生畏。幸运的是，像TensorFlow这样的库给了我们非常容易地合并分布式训练的自由——无论是经典的<code class="fe jz ka kb kc b">fit</code>和<code class="fe jz ka kb kc b">compile</code>范式的<code class="fe jz ka kb kc b">tf.keras</code>模型，还是定制的训练循环。然而，本报告只涉及前者。如果您有兴趣了解更多关于定制培训循环的分布式培训，请务必查看本教程。</p><p id="a838" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在本报告的前半部分，当我在GCP虚拟机上进行实验时，我们将讨论在谷歌云平台(用于分布式培训)上选择虚拟机时需要记住的一些要点。但是这些指针也应该适用于您选择的任何平台。然后，我们将看到在单个机器中的多个GPU之间分配<code class="fe jz ka kb kc b">tf.keras</code>型号<em class="ms">的培训工作负载所需的步骤。最后，我们将通过分析这个<code class="fe jz ka kb kc b"><a class="ae lr" href="https://app.wandb.ai/sayakpaul/tensorflow-multi-gpu-dist/" rel="noopener ugc nofollow" target="_blank">wandb</a></code> <a class="ae lr" href="https://app.wandb.ai/sayakpaul/tensorflow-multi-gpu-dist/" rel="noopener ugc nofollow" target="_blank">运行概要</a>中的系统指标来得出结论。</em></p><h1 id="9d22" class="ls lt it bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">系统设置、成本等</h1><p id="d9ca" class="pw-post-body-paragraph kv kw it kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">我们主要有两个选择来执行GCP的分布式训练-</p><ul class=""><li id="1f95" class="nm nn it kx b ky kz lb lc le no li np lm nq lq nr ns nt nu bi translated">计算引擎</li><li id="e503" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">人工智能平台笔记本</li></ul><p id="4b41" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><a class="ae lr" href="https://console.cloud.google.com/compute/" rel="noopener ugc nofollow" target="_blank">计算引擎</a>允许您创建具有许多不同软件和硬件配置的虚拟机，这些虚拟机可能适用于各种任务，而不仅仅是训练深度学习模型。另一方面，<a class="ae lr" href="https://console.cloud.google.com/ai-platform/notebooks" rel="noopener ugc nofollow" target="_blank"> AI平台笔记本</a>为我们提供了预配置的Jupyter Lab笔记本实例，具有定制的灵活性。</p><p id="48df" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">根据我的经验，我发现建立一个计算引擎实例的过程比构建一个人工智能平台笔记本实例更复杂。让我们从成本的角度来看看它们有什么不同。</p><p id="09ac" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">以下是我的系统配置:</p><ul class=""><li id="916c" class="nm nn it kx b ky kz lb lc le no li np lm nq lq nr ns nt nu bi translated">n1-标准-4个vcpu-15 GB</li><li id="c88b" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">4辆特斯拉K80s</li><li id="34f0" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">100 GB标准永久磁盘</li><li id="8339" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">预配置映像:<strong class="kx jd"> TensorFlow 2.1 </strong>(采用英特尔MKL-DNN/MKL和CUDA 10.1)</li></ul><p id="5244" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">计算引擎，为了以上，将花费我-</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/ab945e5572492d6bd5335b8acd6df14a.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/0*LrWrzHJ8a9Z4PPK0.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">在GCE上计算我们虚拟机的成本</p></figure><p id="e6a9" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">而且，人工智能平台笔记本电脑会让我付出以下代价-</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/00a9691ab8e9d66ced465d5ccc818388.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/0*Vpou1WjQK0_x3MXL.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">人工智能平台笔记本电脑上虚拟机的成本计算</p></figure><p id="5720" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">正如你所看到的，两者的成本是不同的，但后者(人工智能平台笔记本)只是一个点击就走的东西。作为一名从业者，我希望我的时间花在与我的专业知识相关的事情上，我不想在不需要的时候重新发明轮子。因此，我选择了人工智能平台笔记本电脑。关于设置和使用人工智能平台笔记本的更全面的报道，请参考<a class="ae lr" href="http://bit.ly/399Fd60" rel="noopener ugc nofollow" target="_blank">本指南</a>。</p><p id="dda2" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为了能够在一个AI平台笔记本实例中使用多个GPU，您首先需要申请配额增加。你可以看看<a class="ae lr" href="https://stackoverflow.com/questions/45227064/how-to-request-gpu-quota-increase-in-google-cloud" rel="noopener ugc nofollow" target="_blank">这个帖子</a>来了解更多。</p><h1 id="8500" class="ls lt it bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">给我看看代码</h1><p id="10ac" class="pw-post-body-paragraph kv kw it kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">默认情况下，使用all-reduce算法在同步模式下进行参数更新。但是，TensorFlow 2.x也支持异步模式下的参数更新。解释它们的细节超出了本报告的范围。如果您有兴趣了解更多，这里有一些非常好的资源:</p><ul class=""><li id="662b" class="nm nn it kx b ky kz lb lc le no li np lm nq lq nr ns nt nu bi translated"><a class="ae lr" href="https://www.youtube.com/watch?v=jKV53r9-H14&amp;feature=youtu.be" rel="noopener ugc nofollow" target="_blank">内部tensor flow:TF . distribute . strategy</a></li><li id="da93" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated"><a class="ae lr" href="https://www.tensorflow.org/guide/distributed_training" rel="noopener ugc nofollow" target="_blank">使用TensorFlow进行分布式训练</a></li><li id="cf1c" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated"><a class="ae lr" href="https://www.youtube.com/watch?v=6ovfZW8pepo" rel="noopener ugc nofollow" target="_blank">将TensorFlow 2模型扩展到多工作者GPU(TF Dev Summit’20)</a></li></ul><p id="eaae" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">好了，回到代码！</p><p id="a475" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">作为起点，我们先在单个K80 GPU上训练一个区分猫和狗的图像分类器。我们将使用MobileNetV2网络(在ImageNet上进行了预培训)作为我们的基础架构，在它的顶部，我们将添加分类头。所以，在代码中，它看起来像这样-</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="703c" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">训练这家伙10个纪元给了我们一个好结果-</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oe"><img src="../Images/d8b30d949c8d4ff47e03239f3c623ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ae_HHeuzgvjYd9x41wF4tQ.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">训练进度图I(在此处与图<a class="ae lr" href="https://bit.ly/2SceZsH" rel="noopener ugc nofollow" target="_blank">互动)</a></p></figure><p id="d3c6" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">请注意，我们正在对这个网络进行微调，而不仅仅是预先计算瓶颈，然后将其提供给分类顶部。因此，<code class="fe jz ka kb kc b">EXTRACTOR.trainable = True</code>就是这样设定的。当<code class="fe jz ka kb kc b">trainable</code>参数设置为<code class="fe jz ka kb kc b">False</code>时，它只是一个带有不可训练特征提取器的浅层网络。在这种情况下，我们不太可能看到分布式培训的任何优势，因为它会变成一个非常肤浅的网络。</p><p id="cc15" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们已经在验证集上获得了大约94%的准确率。但这不是我们关心的问题。我们希望能够通过使用分布式训练来加速模型训练。</p><p id="c07e" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">训练大约需要<em class="ms"> </em> <strong class="kx jd"> <em class="ms"> 2090秒</em> </strong>。关于这个特定实验的所有重要统计数据都可以在一个格式良好的表格中找到(你可以在这里看到<a class="ae lr" href="https://bit.ly/2SceZsH" rel="noopener ugc nofollow" target="_blank">和</a>)</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi of"><img src="../Images/75e9c13d944c07835d11090a13bf055e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zeFcnlshC0tWF9a2o2xDkA.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">不同W&amp;B运行的集合一起称为<strong class="bd og">运行集</strong></p></figure><p id="5b5b" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当微调网络时，使用一个带有加速的学习速率表是一个很好的实践。这里的想法是从一个低的学习率开始，这样基础网络的预训练权重就不会被破坏。然后我们提高学习率，再降低学习率。时间表应该是这样的-</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/1dbd4d42a24a5568914f7cac961cbccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/0*Sp6wjGrZXSdyJ_LL.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">带有<strong class="bd og">斜坡的学习率(LR)时间表</strong></p></figure><h1 id="5910" class="ls lt it bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">使用LR调度进行微调(单个GPU)</h1><p id="ba3a" class="pw-post-body-paragraph kv kw it kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">现在让我们看看学习计划对培训是否有任何影响。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oi"><img src="../Images/bc3f5ab73901c9640ed3e83a80e1df43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uukZgLTVJugch8T2RJkV6Q.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">训练进度图II(在此处与图<a class="ae lr" href="https://bit.ly/2SceZsH" rel="noopener ugc nofollow" target="_blank">互动)</a></p></figure><p id="ca11" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">虽然这次网络中有一点过度拟合的行为，但你也可以看到性能的改善(<strong class="kx jd"> ~98%的验证准确率</strong>)。模型训练时间也不受此影响(<strong class="kx jd"> ~ 2080秒</strong>)。通过在开始时使用较低的学习速率，同时使用学习速率时间表，可以进一步减轻过拟合。</p><h1 id="22e0" class="ls lt it bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">将模型移植到多个GPU</h1><p id="0f77" class="pw-post-body-paragraph kv kw it kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">现在，为了在四个GPU之间分配这种训练，我们首先需要定义<code class="fe jz ka kb kc b">MirroredStrategy</code>范围，并在范围上下文中编译我们的模型</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="a543" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><code class="fe jz ka kb kc b">get_training_model</code>包括如上所示的模型定义<em class="ms">以及编译步骤</em>。所以，我们正在做的是在<code class="fe jz ka kb kc b">MirroredStrategy</code>的范围内创建和编译模型。这之后绝对一样——你叫<code class="fe jz ka kb kc b">model.fit</code>。我们的学习率计划也将有所改变，因为我们现在将在四个GPU上分配模型参数(注意Y值)。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/b27ba9d7d8f337258fdb5a934a0323f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/0*FcRylCVPhpOVhHrj.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">多GPU的LR调度</p></figure><p id="b3bb" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">从下图中可以看出，性能变化不大(至少在准确性和损失方面)</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ok"><img src="../Images/a38a42b3299ace901b7de9af656cdbe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AkXXIa5jLayJpUhZd-lvYQ.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">训练进度图三(在此处与图<a class="ae lr" href="https://bit.ly/2SceZsH" rel="noopener ugc nofollow" target="_blank">互动)</a></p></figure><p id="5596" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">正如你所看到的精度(在这种情况下，我们有<strong class="kx jd"> ~98% </strong>)和损耗仍然与上面的图有些相同。如果我们从较低的学习率开始，左边图中的尖峰可以变平。</p><p id="4317" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">不过，模型训练时间减少了——1046秒。哇哦。惊人的2倍加速。这还可以进一步改进，我们稍后会看到如何改进。但首先，让我们对GPU指标做一些分析。</p><h1 id="8f0d" class="ls lt it bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">分析GPU指标</h1><p id="60c1" class="pw-post-body-paragraph kv kw it kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">相对而言，GPU不如其他商用硬件便宜。因此，确保GPU利用率尽可能高非常重要。让我们快速看看我们在那里做得怎么样。下面是GPU利用率和GPU访问内存以获取数据所用时间的图表(单个GPU)。正如我们所见，大多数时候GPU利用率都很高，这很好。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ol"><img src="../Images/da355e073a46d5a6220afdb661286da3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dcDvL-ucHmQ9E_m5y1lDqg.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">单GPU指标</p></figure><p id="dd0c" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">作为一名深度学习实践者，你的目标应该是<strong class="kx jd">最大化</strong>GPU利用率，同时<strong class="kx jd">减少</strong>GPU访问内存以获取数据所花费的时间。因此，<em class="ms">减少GPU获取数据所花费时间的一个显而易见的解决方案是在一个时期完成时预取数据</em>。</p><h2 id="f639" class="om lt it bd lu on oo dn ly op oq dp mc le or os me li ot ou mg lm ov ow mi iz bi translated">当我们使用多个GPU时，我们会得到-</h2><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ox"><img src="../Images/894f6d907a35d327f8330d8c12673462.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5luctRzCgV1Nb7t-Rv7GCA.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">多GPU指标I</p></figure><blockquote class="mp mq mr"><p id="70d1" class="kv kw ms kx b ky kz kh la lb lc kk ld mt lf lg lh mu lj lk ll mv ln lo lp lq im bi translated"><strong class="kx jd">(您会看到多行，因为这里有四个计算指标的GPU)</strong></p></blockquote><p id="a905" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">正如我们所看到的，四个GPU的平均GPU利用率远远低于预期，但内存访问时间已经大大减少，因为它现在分布在多个GPU上。至于利用率，这是因为数据集的容量相对较低。有了更大的数据集，我们可以期待看到GPU性能的更多提高。在下一节中，我们将讨论两种常用技术来进一步提高利用率。</p><p id="63f0" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们还可以看到上面两个图的线条有些平滑，这表明所有的GPU都在相同的负载下运行。可以肯定地说，在多GPU环境下运行时，这种平滑度是意料之中的。如果您看到奇怪的峰值，这可能是一个迹象，表明GPU没有在相同的负载下运行，您可能希望使之均匀。</p><h1 id="fde5" class="ls lt it bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">进一步提高性能的两种方法</h1><p id="be10" class="pw-post-body-paragraph kv kw it kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated"><strong class="kx jd">方法#1 </strong></p><p id="ac53" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">TensorFlow的<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/data/" rel="noopener ugc nofollow" target="_blank">数据API </a>提供了许多东西来进一步改善输入数据流成为瓶颈的模型训练。例如，理想情况下，当模型正在训练时，下一个时期的数据应该已经准备好，因此模型不需要等待。如果它需要等待，那么它会在总训练时间方面引入一些瓶颈。</p><p id="f0cf" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><code class="fe jz ka kb kc b"><a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank">prefetch</a></code>允许我们指示TensorFlow在模型完成当前时期后立即准备好下一批数据。它甚至允许我们预先指定系统应该获取的样本数量。但是，如果我们希望系统根据系统进程和硬件的带宽为我们做出决定，那该怎么办呢？我们可以用<code class="fe jz ka kb kc b">tf.data.experimental.AUTOTUNE</code>来指定</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="ff47" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx jd">方法二</strong></p><p id="cb3a" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们可以做的第二件事是调整批量大小。由于我们使用同步参数更新方案的多个GPU，每个GPU将接收一部分数据，并在此基础上进行训练。因此，如果我们使用过高的批处理大小，GPU可能很难在彼此之间正确分配。另一方面，如果我们使用的批量太小，GPU可能会利用不足。所以，我们需要找到最佳点。这里有一些一般性的建议(这些来自马丁·戈纳的笔记本)</p><ul class=""><li id="cf6f" class="nm nn it kx b ky kz lb lc le no li np lm nq lq nr ns nt nu bi translated">从16开始，作为每个GPU的本地批量大小。</li><li id="4cd0" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">然后，全局批量大小变为— <code class="fe jz ka kb kc b">local_batch_size * number_of_GPUs</code>。</li></ul><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="e6ef" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">请注意，我们现在使用的批量更大，在之前的实验中，我们使用的批量为16。</p><p id="42f5" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">Martin的上述笔记本包含许多使用分布式培训时优化模型性能的提示和技巧，其中包括:</p><ul class=""><li id="2df5" class="nm nn it kx b ky kz lb lc le no li np lm nq lq nr ns nt nu bi translated"><a class="ae lr" href="https://www.wandb.com/articles/mixed-precision-training-with-tf-keras" rel="noopener ugc nofollow" target="_blank">使用混合精度训练和支持XLA的编译</a>(它将只在<strong class="kx jd">V100</strong>GPU上工作)。</li><li id="7d74" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">关于<code class="fe jz ka kb kc b">tf.data.Dataset</code>分布行为的说明。</li></ul><p id="cea5" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">本指南中也提供了许多建议。</p><p id="30f8" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">好了，说够了！现在是时候把上面讨论的方法结合起来看看结果了</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oy"><img src="../Images/fead9166dc66073fdff4e54211cfe427.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ETvoGMrrBn0g5QLRdPWrA.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">训练进度图四(在这里与图<a class="ae lr" href="https://bit.ly/2SceZsH" rel="noopener ugc nofollow" target="_blank">互动)</a></p></figure><p id="1ce7" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">批量越大，性能受到的影响越大，但另一方面，训练时间进一步减少到了887秒。</p><p id="bd9b" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在同样的批量32的情况下，我们得到-</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oz"><img src="../Images/8c4e5f63b1310beed99e2d5f5c88b7aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tBhi0HgFs9_b__BAiUQ63A.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">多GPU指标II</p></figure><p id="aa7a" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">虽然GPU利用率和内存访问时间的提高非常微小，但它仍然存在。</p><h2 id="86bf" class="om lt it bd lu on oo dn ly op oq dp mc le or os me li ot ou mg lm ov ow mi iz bi translated"><strong class="ak"> LR调度+批量16 +预取</strong></h2><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pa"><img src="../Images/539f2e87e612b15ea087476f46eb13b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*efNd-qr5MOeG_DRvoCE7cg.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">训练进度剧情五(在此与剧情<a class="ae lr" href="https://bit.ly/2SceZsH" rel="noopener ugc nofollow" target="_blank">互动)</a></p></figure><p id="c2cf" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">正如你所看到的，我们能够保持同样的性能，并且还稍微减少了模型训练时间(<strong class="kx jd"> ~ 6秒</strong>)。</p><p id="b495" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">就GPU指标而言-</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pb"><img src="../Images/febca515536a0c17eb1681a614691286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ly0sVD6-uNTKDs1zaNzUzg.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">多GPU指标III</p></figure><p id="5b8f" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如上图所示，GPU指标几乎没有变化。当使用多个GPU时，通常数据越多，利用率就越高。同样重要的是要记住，在这些情况下使用较大的批量可能会损害模型性能，正如我们在上面看到的那样。</p><p id="9ec7" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们鼓励您查看下面为两个不同的Kaggle竞赛提供的两个惊人的基准:</p><ul class=""><li id="b320" class="nm nn it kx b ky kz lb lc le no li np lm nq lq nr ns nt nu bi translated"><a class="ae lr" href="https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification/discussion/140022#793524" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/jigsaw-多语言-有毒-评论-分类/讨论/140022#793524 </a></li><li id="4674" class="nm nn it kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated"><a class="ae lr" href="https://www.kaggle.com/c/flower-classification-with-tpus/discussion/137983#784972" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/flower-class ification-with-tpus/discussion/137983 # 784972</a></li></ul><p id="6904" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">它还提供了许多不同硬件配置之间的成本权衡。这将有助于您根据您的成本预算做出最佳决策。</p><h1 id="f830" class="ls lt it bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">结论和下一步措施</h1><p id="202b" class="pw-post-body-paragraph kv kw it kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">重要的是要记住，在使用分布式培训时，数据集越大，加速器的利用率就越高。无论是TPU还是多个GPU，这一逻辑都是正确的。</p><p id="6af4" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当使用多个GPU时(无论是在单个还是多个机器/集群中)，注意多个加速器之间协调所需的同步时间的相关成本非常重要。<a class="ae lr" href="https://www.youtube.com/watch?v=I29_VZ82KW4" rel="noopener ugc nofollow" target="_blank">本视频</a>讲解了与此相关的一些取舍。</p><p id="025f" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我希望您已经意识到为您的<code class="fe jz ka kb kc b">tf.keras</code>模型分配培训工作量是多么容易。作为下一步，您可能想尝试本报告和我提到的参考资料中分享的不同技巧和诀窍。如果你更喜欢定制训练循环，你也可以尝试混合精度训练和分布式训练。</p><p id="2c01" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果你有任何反馈要与我分享，你可以通过推文<a class="ae lr" href="https://twitter.com/RisingSayak" rel="noopener ugc nofollow" target="_blank">这里</a>这样做。我真的很感激。</p></div></div>    
</body>
</html>