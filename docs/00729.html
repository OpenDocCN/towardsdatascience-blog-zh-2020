<html>
<head>
<title>Creating Python Functions for Exploratory Data Analysis and Data Cleaning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">创建用于探索性数据分析和数据清理的Python函数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-python-functions-for-exploratory-data-analysis-and-data-cleaning-2c462961bd71?source=collection_archive---------5-----------------------#2020-01-21">https://towardsdatascience.com/creating-python-functions-for-exploratory-data-analysis-and-data-cleaning-2c462961bd71?source=collection_archive---------5-----------------------#2020-01-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="effe" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">自动化数据科学家的枯燥工作</h2></div></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><p id="0c18" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr iu">更新</strong>(2021–02–05):这篇博文中使用的Python库现在发布在<a class="ae ll" href="https://pypi.org/project/eda-and-beyond/0.0.1/" rel="noopener ugc nofollow" target="_blank"> PyPi </a>上。这个包还包含了<a class="ae ll" href="https://github.com/FredaXin/eda_and_beyond/blob/master/eda_and_beyond/modeling_tools.py" rel="noopener ugc nofollow" target="_blank">新特性</a>:它提供了一个类，这个类包含了简化Scikit-Learn模型建模过程的方法。这篇博客文章的第二部分即将发表，将介绍如何在Python中利用OOP来自动化建模过程。</p><p id="904c" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">探索性的数据分析和数据清洗是我们开始开发机器学习模型之前的两个必不可少的步骤，它们可能非常耗时，尤其是对于仍然在熟悉这整个过程的人来说。</p><p id="9913" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">EDA和数据清理很少是一次性的、线性的过程:您可能会发现自己经常回到前面的章节并修改处理数据集的方式。加快这个过程的一个方法是回收一些你发现自己反复使用的代码。这就是为什么我们应该创建函数来自动化EDA和数据清理的重复部分。在EDA和数据清理中使用函数的另一个好处是消除由代码中的意外差异导致的结果不一致。</p><p id="bb84" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在这篇博文中，我将带您浏览几个我为EDA和数据清理创建的有用的python函数。包含所有这些函数的库可以从我的库<code class="fe lm ln lo lp b"><a class="ae ll" href="https://github.com/FredaXin/eda_and_beyond/blob/master/eda_and_beyond.py" rel="noopener ugc nofollow" target="_blank">eda_and_beyond</a></code>中克隆。特别感谢所有为这个小(但正在增长的)图书馆做出贡献的人。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="51ee" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">处理缺失值的函数</h1><p id="55e4" class="pw-post-body-paragraph kp kq it kr b ks mi ju ku kv mj jx kx ky mk la lb lc ml le lf lg mm li lj lk im bi translated">EDA中的一个重要步骤是检查缺失值，研究缺失值中是否有任何模式，并相应地决定如何处理它们。</p><p id="ebf6" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这里的第一个函数是让您大致了解每一列中缺失数据的总数和百分比:</p><pre class="mn mo mp mq gt mr lp ms mt aw mu bi"><span id="c056" class="mv lr it lp b gy mw mx l my mz">def intitial_eda_checks(df):<br/>    '''<br/>    Takes df<br/>    Checks nulls<br/>    '''<br/>    if df.isnull().sum().sum() &gt; 0:<br/>        mask_total = df.isnull().sum().sort_values(ascending=False) <br/>        total = mask_total[mask_total &gt; 0]<br/><br/>        mask_percent = df.isnull().mean().sort_values(ascending=False) <br/>        percent = mask_percent[mask_percent &gt; 0] <br/><br/>        missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])<br/>    <br/>        print(f'Total and Percentage of NaN:\n {missing_data}')<br/>    else: <br/>        print('No NaN found.')</span></pre><p id="f869" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在初始检查之后，您可以决定是否要对那些缺失值过多的列进行更仔细的检查。通过指定缺失值百分比的阈值，以下函数将给出缺失值超过该阈值的列的列表:</p><pre class="mn mo mp mq gt mr lp ms mt aw mu bi"><span id="89de" class="mv lr it lp b gy mw mx l my mz">def view_columns_w_many_nans(df, missing_percent):<br/>    '''<br/>    Checks which columns have over specified percentage of missing values<br/>    Takes df, missing percentage<br/>    Returns columns as a list<br/>    '''<br/>    mask_percent = df.isnull().mean()<br/>    series = mask_percent[mask_percent &gt; missing_percent]<br/>    columns = series.index.to_list()<br/>    print(columns) <br/>    return columns</span></pre><p id="a959" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">处理缺失值的方法有很多。如果您决定删除缺少太多值的列(超过您指定的某个阈值)，您可以使用此函数来完成任务:</p><pre class="mn mo mp mq gt mr lp ms mt aw mu bi"><span id="5e57" class="mv lr it lp b gy mw mx l my mz">def drop_columns_w_many_nans(df, missing_percent):<br/>    '''<br/>    Takes df, missing percentage<br/>    Drops the columns whose missing value is bigger than missing percentage<br/>    Returns df<br/>    '''<br/>    series = view_columns_w_many_nans(df, missing_percent=missing_percent)<br/>    list_of_cols = series.index.to_list()<br/>    df.drop(columns=list_of_cols)<br/>    print(list_of_cols)<br/>    return df</span></pre><p id="ffeb" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">但是，从数据集中删除缺失值有许多不利之处，例如降低了统计能力。如果你决定估算缺失值，检查一下Sklearn的<code class="fe lm ln lo lp b"><a class="ae ll" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank">SimpleImputer</a></code>模块，这是一个简单易用的工具，可以根据你的喜好估算缺失值。</p><p id="5f51" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">此外，如果你想了解更多关于如何处理缺失值的信息，可以看看这张由人口研究中心的梅丽莎·汉弗莱斯制作的幻灯片。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="4b5f" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">数据可视化功能</h1><p id="a8e0" class="pw-post-body-paragraph kp kq it kr b ks mi ju ku kv mj jx kx ky mk la lb lc ml le lf lg mm li lj lk im bi translated">人脑非常善于识别模式，这就是为什么在EDA过程中可视化数据集并识别模式会非常有益。例如，直方图使得分析数据的分布变得更容易；箱线图非常适合识别异常值；在检查两个变量之间的相关性时，散点图非常有用。谈到数据可视化，Matplotlib 和<a class="ae ll" href="https://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Seaborn </a>是你最好的朋友。但是，如果有大量要素，为每个要素创建单独的地块会变得很乏味。在这一节，我将带你通过几个函数来创建团体图，可以帮助你一箭多雕。</p><p id="4812" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们经常想看看有数值的列的分布。以下函数将为数据集中的所有数字列创建一组绘图。(这个函数改编自张秀坤·高伟凯的<a class="ae ll" href="https://www.kaggle.com/dgawlik/house-prices-eda#Categorical-data" rel="noopener ugc nofollow" target="_blank">博文</a>，是一篇用真实数据集看完整个EDA过程的好读物):</p><pre class="mn mo mp mq gt mr lp ms mt aw mu bi"><span id="d846" class="mv lr it lp b gy mw mx l my mz">def histograms_numeric_columns(df, numerical_columns):<br/>    '''<br/>    Takes df, numerical columns as list<br/>    Returns a group of histagrams<br/>    '''<br/>    f = pd.melt(df, value_vars=numerical_columns) <br/>    g = sns.FacetGrid(f, col='variable',  col_wrap=4, sharex=False, sharey=False)<br/>    g = g.map(sns.distplot, 'value')<br/>    return g</span></pre><p id="6cdd" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">下面是输出的样子:</p><figure class="mn mo mp mq gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi na"><img src="../Images/5f762ae6e3391f0d18e7d4c502990e28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*w7RX2YCsW6foC7xI.png"/></div></div></figure><p id="355c" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">另一个有用的可视化工具是热图。当你想检查因变量和自变量之间的相关性时，热图非常方便。如果要素过多，热图通常会显得杂乱无章。避免这种情况的一种方法是只为因变量(目标)和自变量(特征)创建热图。以下功能将帮助您完成这项任务:</p><pre class="mn mo mp mq gt mr lp ms mt aw mu bi"><span id="9ec2" class="mv lr it lp b gy mw mx l my mz">def heatmap_numeric_w_dependent_variable(df, dependent_variable):<br/>    '''<br/>    Takes df, a dependant variable as str<br/>    Returns a heatmap of all independent variables' correlations with dependent variable <br/>    '''<br/>    plt.figure(figsize=(8, 10))<br/>    g = sns.heatmap(df.corr()[[dependent_variable]].sort_values(by=dependent_variable), <br/>                    annot=True, <br/>                    cmap='coolwarm', <br/>                    vmin=-1,<br/>                    vmax=1) <br/>    return g</span></pre><figure class="mn mo mp mq gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ni"><img src="../Images/e585842f175d02a8e347b87c8793c0ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kbzG902j9cKAbyZ3.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">正如您在输出中看到的，因为值是排序的，所以相关性变得更容易阅读。</p></figure></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="94eb" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">用于更改数据类型的函数</h1><p id="5730" class="pw-post-body-paragraph kp kq it kr b ks mi ju ku kv mj jx kx ky mk la lb lc ml le lf lg mm li lj lk im bi translated">确保要素具有正确的数据类型是EDA和数据清理过程中的另一个重要步骤。Pandas的<code class="fe lm ln lo lp b">.read_csv()</code>方法解释的数据类型与原始数据文件不同，这种情况经常发生。在这一步中，阅读数据字典很有启发性。此外，如果您计划进行一些功能工程，那么就需要更改数据类型。以下两个函数协同工作，将分类特征转换为数字(序数)特征:</p><p id="b074" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">第一个函数是输出一个函数，即转换器，它将把列表中的每个<code class="fe lm ln lo lp b">str</code>转换成一个<code class="fe lm ln lo lp b">int</code>，其中<code class="fe lm ln lo lp b">int</code>是列表中该元素的索引。</p><pre class="mn mo mp mq gt mr lp ms mt aw mu bi"><span id="98a6" class="mv lr it lp b gy mw mx l my mz">def categorical_to_ordinal_transformer(categories):<br/>    '''<br/>    Returns a function that will map categories to ordinal values based on the<br/>    order of the list of `categories` given. Ex.<br/><br/>    If categories is ['A', 'B', 'C'] then the transformer will map <br/>    'A' -&gt; 0, 'B' -&gt; 1, 'C' -&gt; 2.<br/>    '''<br/>    return lambda categorical_value: categories.index(categorical_value)</span></pre><p id="c2c7" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">第二个函数有两个部分:首先，它采用以下形式的字典:</p><pre class="mn mo mp mq gt mr lp ms mt aw mu bi"><span id="89bb" class="mv lr it lp b gy mw mx l my mz">categorical_numerical_mapping = {<br/>    'Utilities': ['ELO', 'NoSeWa', 'NoSewr', 'AllPub'],<br/>    'Exter Qual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],<br/>    'Exter Cond': ['Po', 'Fa', 'TA', 'Gd', 'Ex']<br/>}</span></pre><p id="b852" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">使用我们之前定义的函数，它将字典变成这样:</p><pre class="mn mo mp mq gt mr lp ms mt aw mu bi"><span id="7fdd" class="mv lr it lp b gy mw mx l my mz">transformers = {'Utilities': &lt;utilties_transformer&gt;,<br/>                'Exter Qual': &lt;exter_qual_transformer&gt;,<br/>                'Exter Cond': &lt;exter_cond_transfomer&gt;}</span></pre><p id="9b8a" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">函数的第二部分使用<code class="fe lm ln lo lp b">.map()</code>方法将每个转换器函数映射到数据帧上。请注意，在此功能期间，将创建原始数据帧的副本。</p><pre class="mn mo mp mq gt mr lp ms mt aw mu bi"><span id="6d4a" class="mv lr it lp b gy mw mx l my mz">def transform_categorical_to_numercial(df, categorical_numerical_mapping):<br/>    '''<br/>    Transforms categorical columns to numerical columns<br/>    Takes a df, a dictionary <br/>    Returns df<br/>    '''<br/>    transformers = {k: categorical_to_ordinal_transformer(v) <br/>                    for k, v in categorical_numerical_mapping.items()}<br/>    new_df = df.copy()<br/>    for col, transformer in transformers.items():<br/>        new_df[col] = new_df[col].map(transformer).astype('int64')<br/>    return new_df</span></pre></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><p id="b89f" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我的博文到此结束。我的目标是创建一个开源库，使EDA和数据清理过程更加简化。一如既往，我希望听到您的反馈。如果您有任何更正或希望为这个小型开源项目做出贡献，请提出请求。感谢您的阅读！</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><p id="ee97" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">资源:看看这个很棒的(而且是免费的！)Python编程教科书:<a class="ae ll" href="https://automatetheboringstuff.com/" rel="noopener ugc nofollow" target="_blank">用Python自动化枯燥的东西</a>作者:Al Sweigart。</p><p id="c7fb" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><em class="nn">最初发表于</em><a class="ae ll" href="https://github.com/FredaXin/blog_posts/blob/master/creating_functions_for_EDA.md" rel="noopener ugc nofollow" target="_blank"><em class="nn">https://github.com</em></a><em class="nn">。</em></p></div></div>    
</body>
</html>