<html>
<head>
<title>(Deep) Learning from Kaggle Competitions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">(深入)从 Kaggle 竞赛中学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-from-kaggle-competitions-e0992fd4352e?source=collection_archive---------56-----------------------#2020-08-24">https://towardsdatascience.com/deep-learning-from-kaggle-competitions-e0992fd4352e?source=collection_archive---------56-----------------------#2020-08-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="cc13" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">为什么是 Kaggle？</h1><p id="55fa" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">几个月前，当我参加<a class="ae lj" href="https://www.kaggle.com/c/siim-isic-melanoma-classification" rel="noopener ugc nofollow" target="_blank"> SIIM-ISIC 黑素瘤分类竞赛</a>时，我开始认真使用<a class="ae lj" href="https://www.kaggle.com/luigisaetta" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>。</p><p id="5499" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">我认为，最初的原因是我想要一种严肃的方式来测试我的<strong class="kn ir">机器学习(ML)和深度学习(DL)技能</strong>。当时，我正在为 Coursera 医学专业学习，我对将 DL 应用于医学能够实现什么很感兴趣(现在仍然如此)。我还在读埃里克·托普写的美丽的书:《深度医学》，书中充满了有趣的想法。</p><p id="37bd" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">几年前，我开了一个 Kaggle 账户，但还没做过什么大事。然后，我发现了<strong class="kn ir">黑色素瘤挑战</strong>，这似乎是一个用真实数据开始一项艰巨任务的好方法。</p><p id="e6a5" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">因此，我开始致力于比赛，我陷入了比赛。我认为这更容易。</p><h1 id="fdf4" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">我所学内容的总结。</h1><p id="64be" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ir">我学会掌握的第一件事</strong>是如何<strong class="kn ir">高效地读取许多图像，</strong>而不需要 GPU(或 TPU)等待。</p><p id="ddd8" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">事实上，在一开始，我试图在 2-GPU 机器上训练我的第一个模型，训练似乎太<strong class="kn ir">慢</strong>。GPU 利用率非常低，大约 20%。为什么？</p><p id="b095" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">因为我正在使用 Keras <a class="ae lj" href="https://keras.io/api/preprocessing/image/#imagedatagenerator-class" rel="noopener ugc nofollow" target="_blank"> ImageDataGenerator </a>，从目录中读取图像。看了 Kaggle 上的几个讨论(是的，这是一个重要的建议:看讨论)我发现一个非常有效的方法是将图片(最终经过预处理，调整大小)打包成<a class="ae lj" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"> TFRecord 格式</a> <strong class="kn ir">的文件。</strong>通过这种方式，我已经能够<strong class="kn ir">将 GPU 利用率提高到 90%以上。</strong></p><p id="7a2e" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">是的，我知道随着 TF 2.3 的到来，预处理和数据加载功能将会有所改进(参见:<a class="ae lj" href="https://keras.io/api/preprocessing/image/#imagedatasetfromdirectory-function" rel="noopener ugc nofollow" target="_blank">imagedatasetfromdirect</a>)，但是如果您需要进行大量的图像(或数据)预处理，那么您应该考虑将结果打包成 TFRecord 格式。</p><p id="ef33" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><strong class="kn ir">第二件重要的事情</strong>是使用一个<strong class="kn ir">现代预训练的 ConvNet </strong>。</p><p id="0817" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">再次，从 Kaggle 的讨论中，我发现了效率网家族。这些是卷积网络，在 Imagenet 上预先训练，由谷歌研究人员在 2019 年提出。这些 CNN 非常高效，如果与旧 CNN 相比，你可以用更少的计算能力获得更高的精确度。令人惊讶的是，你可以简单地使用一个高效网络作为卷积层(特征提取器)来提高精确度。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/c6a1b2b47716526c62e5819403138a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1Y2ZUCAlHzwnwNSw.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">(来源:谷歌 AI 博客，<a class="ae lj" href="https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html" rel="noopener ugc nofollow" target="_blank">https://AI . Google blog . com/2019/05/efficient net-improving-accuracy-and . html</a>)</p></figure><p id="f5f1" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><strong class="kn ir">第三件事</strong>是开发一种<strong class="kn ir">健壮的交叉验证方法</strong>。像往常一样，你希望有一个尽可能大的训练集。但是，与此同时，您需要足够大的验证集，以便对训练模型在看不见的数据上的性能(准确性、AUC 等)有一个公平的想法。如果验证集太小，您对分数的估计很大程度上取决于您在训练集和验证集之间划分的方式。唯一可行的方法是采用健壮的交叉验证(CV)模式。例如，我经常使用具有 5 个折叠的 CV:训练集被分成 5 个折叠，并且我重复训练(对于整个历元数)五次，每次取训练集的五分之一进行验证。对于每一次折叠，我估计最终的准确度(或者你选择的任何度量标准),最好的估计(在验证阶段)是平均值。如果训练集和测试集中的分布是相同的，你应该得到一个 CV 分数，这是对公开分数 LB 的一个很好的估计(你也希望得到最终的私有 LB 分数)。</p><p id="9ca4" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><strong class="kn ir">第四:学会使用 TPU </strong>。TPU 是由 Google 专门设计和开发的专用(ASIC)处理器，用于处理神经网络。如果你知道怎么做，你可以在 TPU 上使用 Tensorflow，以比使用 2-GPU 机器快十倍的速度训练你的模型。更好的是能够在 1/10 的时间内测试模型中的变化，以及它们在准确性方面的结果。这样你就不会因为等太久而感到无聊，也可以做更多的检查。在 Kaggle 上，你每周有 30 个小时的 TPU 时间是免费的(目前唯一的缺点是他们还不支持 TF 2.3，但我相信不会花太长时间来支持它)。</p><p id="7a0b" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">一般来说，你应该知道如何在多 GPU 和 TPU 机器上训练。这并不困难，即使乍一看配置代码看起来有点晦涩。</p><p id="dee3" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><strong class="kn ir">第五</strong>:温柔对待自己的学习速度。</p><p id="e8a7" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">学习率(LR)可能是最重要的超参数。但是，如果你阅读一本关于深度学习的介绍性书籍，你不会找到任何关于你可以采用的策略的详细描述，以使用 LR 来充分利用你的数据。</p><p id="9f93" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">一些快速的考虑:如果你正在进行迁移学习(参见 EfficientNet ),你可以在不冻结卷积层的情况下开始训练，但之后你应该非常小心地采用非常小的学习速率，以避免来自“未训练的”分类尾部的梯度破坏预训练卷积头的权重。然后你应该随着时代逐渐提高学习速度。但是，当损失的改善开始减少时，你应该开始降低学习率。很难把它做好。通常，在 Kaggle 比赛中，我看到它采用了时变学习率，使用 Keras LearningRateScheduler。</p><p id="2616" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">更多细节请见<a class="ae lj" href="https://www.jeremyjordan.me/nn-learning-rate/" rel="noopener ugc nofollow" target="_blank">https://www.jeremyjordan.me/nn-learning-rate/</a></p><p id="cea5" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">我一直在使用的代码示例可以在这里找到:</p><p id="78ee" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><a class="ae lj" href="https://github.com/luigisaetta/diabetic-retinopathy/blob/master/Diabetic-Retinopathy-512-Classification-Copy6.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/luigisaetta/Diabetic-Retinopathy/blob/master/Diabetic-Retinopathy-512-Classification-copy 6 . ipynb</a></p><h1 id="bc1d" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">完整的例子。</h1><p id="539b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我已经准备了一个相当完整的例子，使用的数据来自一个旧的竞争:<a class="ae lj" href="https://www.kaggle.com/c/diabetic-retinopathy-detection" rel="noopener ugc nofollow" target="_blank">糖尿病视网膜病变检测。</a>你可以在我的 Github 仓库中找到代码:<a class="ae lj" href="https://github.com/luigisaetta/diabetic-retinopathy" rel="noopener ugc nofollow" target="_blank">https://github.com/luigisaetta/diabetic-retinopathy</a>。</p><p id="62d8" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">我有:</p><ul class=""><li id="be39" class="mf mg iq kn b ko lk ks ll kw mh la mi le mj li mk ml mm mn bi translated">预处理所有图像，将尺寸缩小到 512x512</li><li id="6207" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated">应用一个过滤器，高斯模糊，增强细节显示博士的迹象</li><li id="36d4" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated">将处理后的图像打包到 TFRecord 文件中</li><li id="01cc" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated">开发了一个 CNN 模型，使用高效的网络 B4 进行五级分类(根据比赛要求)</li><li id="4958" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated">应用前面详述的所有内容</li></ul><p id="5e81" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">您可以在 Github 存储库中找到重现结果的所有细节，数据集(带有 TFRecord 文件)可在 ka ggle:<a class="ae lj" href="https://www.kaggle.com/luigisaetta/tfrecord512" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/luigisaetta/tfrecord512</a>上找到。</p><h1 id="e448" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">一些结论。</h1><p id="454b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">经过大约 24 小时的训练，我的最佳模型显示出了 0.856 的<strong class="kn ir"> CV 精度。</strong></p><p id="3ce7" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">下图显示了其中一个 CV 折叠的准确度随着时期的增加而增加(对于其他折叠，情况类似)。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mt"><img src="../Images/7987dc6086838bd3eadd82719d2c78e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*20bmfhlW-iuwCH9S.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图:acc。vs 时代(按作者)。</p></figure><p id="e7c5" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">但是，有趣的是，最终的提交(你可以在 Kaggle 的封闭比赛中使用延迟提交)获得了 0.79369 的私人 LB 分数<strong class="kn ir">。这个分数会让我排在第 14 位。</strong></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mu"><img src="../Images/787739c97f49509d742caab3b35c412b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g-jo3DYl7Aqias-D.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">(作者)。</p></figure><p id="b2e3" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">嗯，这并不意味着我已经是一个大师，但可以肯定的是，这是一个证明，与今天的技术和技巧，这是更容易得到的结果，需要几个月的辛勤工作五年前。关于这一说法，仅给出一个细节:五年前，效率网不可用(它们已在 2019 年发表)。</p><p id="3219" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">这就是我们所说的:进步。</p><h1 id="eb58" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">ai4 医学。</h1><p id="79d7" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我真的认为<strong class="kn ir">人工智能和人工智能可以为发展一个更美好的世界做出巨大贡献的一个领域是医学</strong>。它不仅应用了计算机视觉领域的结果(人工智能支持的诊断)。特别是在最不发达国家，那里仍然有太多的人遭受疾病之苦，如果及时正确诊断，这些疾病是可以治愈的。</p><p id="5cee" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">正如我所说，这并不容易。超过 3000 名参与者，最后一个惊喜是:私立学校与公立学校非常不同。</p><p id="b1a3" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated">我以前 20%的成绩结束了比赛，这对于一个 Kaggle 初学者来说已经不错了。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/e1bf93bf26957d0162471eb44ca82357.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/0*kY4R6V8Qjj1Ia9nc.png"/></div></figure></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><p id="b28e" class="pw-post-body-paragraph kl km iq kn b ko lk kq kr ks ll ku kv kw lm ky kz la ln lc ld le lo lg lh li ij bi translated"><em class="nd">原载于 2020 年 8 月 24 日</em><a class="ae lj" href="https://luigisaetta.it/index.php/deep-learning-ai/43-learning-from-kaggle-competitions" rel="noopener ugc nofollow" target="_blank"><em class="nd">https://luigisaeta . it</em></a><em class="nd">。</em></p></div></div>    
</body>
</html>