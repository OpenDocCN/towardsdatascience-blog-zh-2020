<html>
<head>
<title>The Invisible Traps of Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据的隐形陷阱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-invisible-traps-of-data-278aa1f491ac?source=collection_archive---------49-----------------------#2020-09-13">https://towardsdatascience.com/the-invisible-traps-of-data-278aa1f491ac?source=collection_archive---------49-----------------------#2020-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="74a5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这都是关于字里行间的解读</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9f0534b3358361a3aedf40e8bfce2ec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5jsADtYtYTaKIYOB"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">埃里克·马塞利诺在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2e54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">众所周知，数据科学家花在数据准备任务(数据收集、<a class="ae ky" href="https://en.wikipedia.org/wiki/Exploratory_data_analysis#:~:text=In%20statistics,%20exploratory%20data%20analysis,modeling%20or%20hypothesis%20testing%20task." rel="noopener ugc nofollow" target="_blank"> EDA </a>和功能工程)上的时间比花在机器学习建模上的时间多得多。虽然我们中的许多人可能会抱怨这个事实，但我认为低估数据准备的重要性——尤其是数据探索——是一个错误，会极大地损害您的 ML 项目，并且在开始模型实现之前，应该花相当多的时间来理解和探索数据。</p><h1 id="cd90" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">机器学习中的数据挑战</h1><p id="8e84" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在 ML 项目中遇到的挑战要么与算法有关，要么与数据有关。与算法相关的挑战在大多数时候要么过拟合，要么欠拟合训练数据。另一方面，与数据相关的挑战非常多样；此外，它们在当今商业领域的 ML 项目中非常常见——由此可见数据准备的重要性。</p><p id="a6aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现实就是这么简单:你的程序的性能很大程度上取决于你的数据准备的质量——永远不要忘记这个领域最著名的一句话<em class="ms">“垃圾进，垃圾出”。</em></p><p id="18ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是数据准备并不总是容易的。除了确保你拥有高质量的数据和足够数量的数据，你还必须应对其他一些挑战，如果没有对数据的深刻理解，这些挑战更难揭开——它们是<em class="ms"/><strong class="lb iu"><em class="ms">数据的隐形陷阱</em></strong><em class="ms"/>。他们要为数据科学家犯下的几个错误和错误假设负责，这些数据科学家没有后退一步提出正确的问题。这里是我在商业中见过的两个最常见的隐形陷阱。</p><h2 id="3934" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">相关性/因果关系陷阱</h2><p id="d39c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation" rel="noopener ugc nofollow" target="_blank">相关性并不意味着因果关系</a>。这应该是我们在<a class="ae ky" href="https://en.wikipedia.org/wiki/Exploratory_data_analysis#:~:text=In%20statistics,%20exploratory%20data%20analysis,modeling%20or%20hypothesis%20testing%20task." rel="noopener ugc nofollow" target="_blank">探索性数据分析</a> 101 中教授的第一条规则。将相关性视为因果关系是 EDA 过程中最容易犯的错误，这种倾向实际上是可以理解的。当我们探索数据时，我们正在寻找增加观察到的事件的可预测性的方法，这样做的最佳方法之一是计算数据集的不同特征之间的相关系数。但我们真正寻找的是因果关系，因为它是超越训练数据的特征之间的关系。因此，当我们观察相关性时，我们很容易走捷径找到因果关系。</p><p id="fa5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想证明相关性并不意味着因果关系，你可能想看看<a class="ae ky" href="http://www.tylervigen.com/spurious-correlations" rel="noopener ugc nofollow" target="_blank">虚假相关性</a>。在这个网站上，你可以找到一些意想不到的有趣的关联。这里有一个例子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/17681d880e186a9288c17f8f137156d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tDYy1PTFsLSMZmrjwT1VTA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.tylervigen.com/spurious-correlations" rel="noopener ugc nofollow" target="_blank">https://www.tylervigen.com/spurious-correlations</a></p></figure><h2 id="44b0" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">偏见，无处不在的偏见</h2><p id="d0b3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">当 ML &amp; AI 系统在我们的社会中大规模部署时，解决与偏见相关的挑战至关重要。尤其是考虑到算法对我们生活的影响的性质——现在它们可以决定你是否获得抵押贷款或工作。这就是为什么在过去几年里，机器学习中的公平问题已经成为一个非常活跃的研究领域。</p><p id="4c5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，数据科学家应该注意这个问题，因为偏见很容易进入 ML 系统，并且很难发现。偏见有很多种，但它们可以分为两类。</p><ul class=""><li id="40dc" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nl nm nn no bi translated"><strong class="lb iu">数据中的偏差:</strong>这些是训练数据中的偏差，ML 算法将从中学习，并因此复制为输出。社会偏见、种族偏见、样本偏见……都是数据偏见的例子。它们可能是由非代表性数据引起的，也可能是由训练样本中描述的有偏模式引起的，它们肯定会影响您的 ML 系统，使其泛化能力很差，或者学习将在输出中复制的有偏模式。要了解更多关于社会偏见的信息，我建议你看看 Bertrand K. Hassani 的论文<a class="ae ky" href="https://arxiv.org/abs/2006.08350" rel="noopener ugc nofollow" target="_blank">通过机器学习强化社会偏见:信用评分视角</a>。</li><li id="2ed6" class="ng nh it lb b lc np lf nq li nr lm ns lq nt lu nl nm nn no bi translated"><strong class="lb iu">人类的偏见:</strong>这些是存在于我们头脑中的认知偏见。事实上，我们大大高估了自己做出正确决定/判断以及摆脱无意识偏见的能力。我们需要记住，作为个体人类，我们有很多认知偏见，这取决于我们个人的背景、文化等。因此，在某些情况下，人们可以从相同的数据中得出非常不同的——有时甚至相反的——结论。</li></ul><h1 id="80fa" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">您的 ML 工作流程需要一个探索审查步骤</h1><p id="5d4c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">有大量的 EDA 技术和工具旨在自动化和加速我们的数据探索方法。但是这种方法的缺点是，它增加了忽略数据复杂性的风险——以及落入其<em class="ms">隐形陷阱</em>的风险。</p><p id="8843" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了解决这个问题，我发现最好的方法是在 ML 工作流程中系统地整合一个<em class="ms">探索审查</em>阶段，在此期间，您可以后退一步，提出更多的问题，并重新考虑您对培训数据所做的假设。</p><p id="ee02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个新阶段，“探索数据集之外”也至关重要。我说的不仅仅是通过一些谷歌搜索或寻找更多的数据，还包括走出去和人们交谈:</p><ul class=""><li id="3812" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nl nm nn no bi translated">咨询领域专家以获得更多的领域知识，</li><li id="aead" class="ng nh it lb b lc np lf nq li nr lm ns lq nt lu nl nm nn no bi translated">与客户接触，更好地了解他们的动机，</li><li id="57dd" class="ng nh it lb b lc np lf nq li nr lm ns lq nt lu nl nm nn no bi translated">与你的同事/朋友分享你的发现，以获得其他观点，…</li></ul><p id="5728" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为，通常情况下，数据只会告诉你<em class="ms">发生了什么</em>，而不是<em class="ms">为什么</em>会发生。我们都知道，预测未来最好的方法莫过于理解过去和现在的原因。</p></div></div>    
</body>
</html>