<html>
<head>
<title>Install Pyspark and use GraphFrames on macOS and Linux</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">安装Pyspark并在macOS和Linux上使用GraphFrames</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/install-pyspark-and-use-graphframes-on-macos-and-linux-f2fe62fc3c2d?source=collection_archive---------17-----------------------#2020-02-26">https://towardsdatascience.com/install-pyspark-and-use-graphframes-on-macos-and-linux-f2fe62fc3c2d?source=collection_archive---------17-----------------------#2020-02-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4af4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于如何在不同操作系统上安装Pyspark和使用Spark GraphFrames的详细指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/5b60be114da7a0978d6d9208c4ce125b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*TiPsFP0AbcP2G0P6h06p8A.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">image_credit —数据块(<a class="ae ku" href="https://databricks.com/spark/about" rel="noopener ugc nofollow" target="_blank">https://databricks.com/spark/about</a>)</p></figure><h1 id="be82" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">Linux(Ubuntu)</h1><p id="2710" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated"><strong class="lp iu">以下所有操作都应在终端下完成。</strong></p><ol class=""><li id="e7d0" class="mj mk it lp b lq ml lt mm lw mn ma mo me mp mi mq mr ms mt bi translated">下载Spark</li></ol><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="15a1" class="mz kw it mv b gy na nb l nc nd">wget <a class="ae ku" href="http://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz" rel="noopener ugc nofollow" target="_blank">http://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz</a></span></pre><p id="edd0" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">2.解压缩文件</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="b7ee" class="mz kw it mv b gy na nb l nc nd">tar xf spark-2.2.0-bin-hadoop2.7.tgz</span></pre><p id="a587" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">3.如有必要，安装Java8</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="b426" class="mz kw it mv b gy na nb l nc nd">sudo add-apt-repository ppa:openjdk-r/ppa</span><span id="730d" class="mz kw it mv b gy nh nb l nc nd">sudo apt-get update</span><span id="9702" class="mz kw it mv b gy nh nb l nc nd">sudo apt-get install openjdk-8-jdk</span></pre><p id="33c3" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">您可以通过“java -version”来检查您的安装。如果不是“1.8.xxx”，您需要按照步骤5–6选择正确的java版本供spark使用。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="b7eb" class="mz kw it mv b gy na nb l nc nd">sudo update-java-alternatives — set java-1.8.0-openjdk-amd64</span></pre><p id="5419" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">重启你的终端。</p><p id="1818" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">4.(可选)如果你想更熟练地使用Spark，你最好熟悉基本的Linux命令和基本的Bash操作。可以参考下面这本书【http://linux-training.be/linuxfun.pdf<a class="ae ku" href="http://linux-training.be/linuxfun.pdf" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="eb1f" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated">mac 操作系统</h1><ol class=""><li id="8261" class="mj mk it lp b lq lr lt lu lw ni ma nj me nk mi mq mr ms mt bi translated">安装自制软件:</li></ol><p id="6c7b" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">/usr/bin/ruby-e " $(curl-fsSL<a class="ae ku" href="https://raw.githubusercontent.com/Homebrew/install/master/install" rel="noopener ugc nofollow" target="_blank">https://raw . githubusercontent . com/home brew/install/master/install</a>)"</p><p id="8f5d" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">2.安装Scala:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="6df7" class="mz kw it mv b gy na nb l nc nd">brew install scala</span></pre><p id="aab6" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">3.安装Spark:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="da76" class="mz kw it mv b gy na nb l nc nd">brew install apache-spark</span></pre><p id="d59a" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">4.启动spark python shell(在spark目录中):</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="7dc7" class="mz kw it mv b gy na nb l nc nd">pyspark</span></pre><h1 id="662d" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated"><strong class="ak"> Jupyter安装(Linux &amp; Mac OS) </strong></h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nl"><img src="../Images/ba5c703c69772f95744a2c7363302673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nVGEpsgkxe3cvMtf6CRMug.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Jupyter笔记本徽标</p></figure><ol class=""><li id="dfd9" class="mj mk it lp b lq ml lt mm lw mn ma mo me mp mi mq mr ms mt bi translated">安装Anaconda。</li></ol><p id="1bae" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">Linux:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="7072" class="mz kw it mv b gy na nb l nc nd">wget <a class="ae ku" href="https://repo.continuum.io/archive/Anaconda2-4.3.0-Linux-x86_64.sh" rel="noopener ugc nofollow" target="_blank">https://repo.continuum.io/archive/Anaconda2-4.3.0-Linux-x86_64.sh</a></span></pre><p id="29ad" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">Mac OS:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="4039" class="mz kw it mv b gy na nb l nc nd">wget <a class="ae ku" href="https://repo.anaconda.com/archive/Anaconda2-2019.07-MacOSX-x86_64.sh" rel="noopener ugc nofollow" target="_blank">https://repo.anaconda.com/archive/Anaconda2-2019.07-MacOSX-x86_64.sh</a></span></pre><p id="6add" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">安装:</p><p id="407a" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">bash anaconda 2–4 . 3 . 0-Linux-x86 _ 64 . sh(使用相应的文件)</p><p id="a017" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">更新$PATH变量</p><p id="1caa" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">Linux:源码~/。bashrc</p><p id="fe9e" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">Mac OS: source ~/。bash_profile</p><p id="e1af" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">修改pyspark驱动程序</p><p id="5247" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">导出PYSPARK_DRIVER_PYTHON="jupyter "</p><p id="0fa3" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">导出py spark _ DRIVER _ PYTHON _ OPTS = " notebook "</p><p id="9613" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">启动spark python shell(在spark目录中):</p><p id="220a" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">。/bin/pyspark</p><p id="8276" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">注意事项:</p><ol class=""><li id="96be" class="mj mk it lp b lq ml lt mm lw mn ma mo me mp mi mq mr ms mt bi translated">可以执行“unset py spark _ DRIVER _ PYTHON py spark _ DRIVER _ PYTHON _ OPTS”来运行普通的pyspark shell</li><li id="bb64" class="mj mk it lp b lq nq lt nr lw ns ma nt me nu mi mq mr ms mt bi translated">如果你发现这个错误“我找不到匹配PySpark的内核。请选择一个内核:“你从讲义上传笔记本后，你只要选择已经支持pyspark内核的Python2内核即可。</li><li id="8ec7" class="mj mk it lp b lq nq lt nr lw ns ma nt me nu mi mq mr ms mt bi translated">完成这些步骤后，创建一个新的笔记本，键入“sc”并运行它。如果在输出中看到“pyspark.context.SparkContext ”,安装应该成功。</li></ol><h1 id="1cae" class="kv kw it bd kx ky kz la lb lc ld le lf jz lg ka lh kc li kd lj kf lk kg ll lm bi translated"><strong class="ak">图表框架:</strong></h1><p id="38d2" class="pw-post-body-paragraph ln lo it lp b lq lr ju ls lt lu jx lv lw lx ly lz ma mb mc md me mf mg mh mi im bi translated"><strong class="lp iu">对于预装Spark版本的ubuntu，要使用GraphFrames: </strong></p><p id="33d2" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">获取jar文件:</p><p id="466a" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">wget<a class="ae ku" href="http://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.7.0-spark2.4-s_2.11/graphframes-0.7.0-spark2.4-s_2.11.jar" rel="noopener ugc nofollow" target="_blank">http://dl . bin tray . com/spark-packages/maven/graph frames/graph frames/0 . 7 . 0-spark 2.4-s _ 2.11/graph frames-0 . 7 . 0-spark 2.4-s _ 2.11 . jar</a></p><p id="63be" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">在Jupyter笔记本<br/>sc . addpyfile(' path _ to _ the _ jar _ file ')中加载jar文件</p><p id="55da" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">将pyspark shell直接用于GraphFrames:</p><p id="027b" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">。/bin/pyspark —包graph frames:graph frames:0 . 7 . 0-spark 2.4-s _ 2.11</p><p id="e729" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated"><strong class="lp iu">本地使用Jupyter:</strong></p><p id="44ba" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">设置环境变量:<br/>export SPARK _ OPTS = "—packages graph frames:graph frames:0 . 7 . 0-SPARK 2.4-s _ 2.11 "</p><p id="ff06" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">获取jar文件:<br/>wget<a class="ae ku" href="http://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.7.0-spark2.4-s_2.11/graphframes-0.7.0-spark2.4-s_2.11.jar" rel="noopener ugc nofollow" target="_blank">http://dl . bin tray . com/spark-packages/maven/graph frames/graph frames/0 . 7 . 0-spark 2.4-s _ 2.11/graph frames-0 . 7 . 0-spark 2.4-s _ 2.11 . jar</a></p><p id="ef8b" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">在Jupyter笔记本<br/>sc . addpyfile(' path _ to _ the _ jar _ file ')中加载jar文件</p><p id="8a72" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated"><strong class="lp iu">在Azure Databricks服务中:</strong></p><p id="05b8" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">启动集群</p><p id="e898" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated">搜索“graphframes”并安装库</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nv"><img src="../Images/d61b41f6baaf85ad7a0505d8d62c2608.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kJKSC6qrXtwNs-yg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">弗洛里安·奥利沃在<a class="ae ku" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="b54d" class="pw-post-body-paragraph ln lo it lp b lq ml ju ls lt mm jx lv lw ne ly lz ma nf mc md me ng mg mh mi im bi translated"><strong class="lp iu">感谢您的阅读，我期待听到您的问题和想法。如果你想了解更多关于数据科学和云计算的知识，可以在</strong><a class="ae ku" href="https://www.linkedin.com/in/andrewngai9255/" rel="noopener ugc nofollow" target="_blank"><strong class="lp iu">Linkedin</strong></a><strong class="lp iu">上找我。</strong></p></div></div>    
</body>
</html>