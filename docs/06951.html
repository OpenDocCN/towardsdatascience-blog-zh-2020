<html>
<head>
<title>How to Run Scrapy From a Script</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何从脚本运行Scrapy</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-run-scrapy-from-a-script-ff07fd6b792b?source=collection_archive---------13-----------------------#2020-05-29">https://towardsdatascience.com/how-to-run-scrapy-from-a-script-ff07fd6b792b?source=collection_archive---------13-----------------------#2020-05-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/4a5c4c956b38b2b1260a37aec28c4c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EEkXw5GexVuqTjxrSQJKbg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@shottrotter" rel="noopener ugc nofollow" target="_blank">未飞溅</a></p></figure><div class=""/><div class=""><h2 id="ab06" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">忘掉Scrapy的框架，全部用使用Scrapy的python脚本来写。</h2></div><p id="827a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Scrapy是一个用于抓取项目的很好的框架。但是，您知道有一种方法可以直接从脚本运行Scrapy吗？</p><p id="c379" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">查看文档，有两种方法可以运行Scrapy。使用Scrapy API或框架。</p><h2 id="e4bf" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">在本文中，您将了解到</h2><ol class=""><li id="b8ec" class="mn mo jj la b lb mp le mq lh mr ll ms lp mt lt mu mv mw mx bi translated">为什么你会用剧本里的scrapy</li><li id="fbca" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">理解基本脚本，每次你想从一个单独的脚本访问scrapy</li><li id="301f" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">了解如何指定定制的scrapy设置</li><li id="8f11" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">了解如何指定HTTP请求供scrapy调用</li><li id="0678" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">了解如何在一个脚本下使用scrapy处理这些HTTP响应。</li></ol><h2 id="e653" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">为什么要用剧本里的Scrapy？</h2><p id="641f" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">Scrapy可以用于繁重的刮擦工作，但是，有很多项目非常小，不需要使用整个scrapy框架。这就是在python脚本中使用scrapy的原因。不需要使用整个框架，你可以从一个python脚本中完成所有工作。</p><p id="6936" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在充实一些必要的设置之前，让我们看看这个的基本情况。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/9d415ba8eec66fcb2a19df44a624f464.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cb79j6XvVbJhG8kSLtjOsA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">https://unsplash.com/@contentpixie<a class="ae jg" href="https://unsplash.com/@contentpixie" rel="noopener ugc nofollow" target="_blank"/></p></figure><h1 id="156b" class="nk lv jj bd lw nl nm nn lz no np nq mc kp nr kq mf ks ns kt mi kv nt kw ml nu bi translated">基本脚本</h1><p id="d276" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">在python脚本中运行scrapy的关键是CrawlerProcess类。这是一个爬虫类模块。它提供了在python脚本中运行scrapy的引擎。在CrawlerProcess类代码中，导入了python的twisted框架。</p><p id="7996" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Twisted是一个python框架，用于输入和输出过程，例如HTTP请求。现在它通过一种叫做龙卷风事件反应堆的东西来做到这一点。Scrapy是建立在twisted之上的！我们在这里不会涉及太多的细节，但是不用说，CrawlerProcess类导入了一个twisted reactor，它监听像多个HTTP请求这样的事件。这是scrapy工作的核心。</p><p id="5e9b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">CrawlerProcess假设twisted反应器没有被其他任何东西使用，例如另一个蜘蛛。<br/>有了这些，我们就有了下面的代码。</p><pre class="ng nh ni nj gt nv nw nx ny aw nz bi"><span id="042a" class="lu lv jj nw b gy oa ob l oc od">import scrapy<br/>from scrapy.crawler import CrawlerProcess</span><span id="4c6b" class="lu lv jj nw b gy oe ob l oc od">class TestSpider(scrapy.Spider):<br/>    name = 'test'</span><span id="18df" class="lu lv jj nw b gy oe ob l oc od">if __name__ == "__main__":<br/>  process = CrawlerProcess()<br/>  process.crawl(TestSpider)<br/>  process.start()</span></pre><ol class=""><li id="0514" class="mn mo jj la b lb lc le lf lh of ll og lp oh lt mu mv mw mx bi translated">现在我们要使用scrapy框架，我们必须创建我们的蜘蛛，这是通过创建一个继承自scrapy.Spider. scrapy的类来完成的。蜘蛛是所有scrapy项目中我们必须衍生的最基本的蜘蛛。有了这个，我们必须给这个蜘蛛一个名字让它运行/蜘蛛将需要几个函数和一个URL来抓取，但是对于这个例子，我们将暂时省略它。</li><li id="4389" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">现在你看<code class="fe oi oj ok nw b">if __name__ == “__main__”</code>。这在python中被用作最佳实践。当我们编写一个脚本时，你希望它能够运行代码，而且能够将代码导入到其他地方。关于这一点的进一步讨论，请参见<a class="ae jg" href="https://stackoverflow.com/questions/419163/what-does-if-name-main-do" rel="noopener ugc nofollow" target="_blank">这里的</a>。</li><li id="0beb" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">我们首先实例化类CrawlerProcess来访问我们想要的函数。CrawlerProcess有两个我们感兴趣的函数，爬行和启动</li><li id="9d02" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">我们使用爬行来启动我们创建的蜘蛛。然后，我们使用start函数启动twisted reactor，这个引擎处理并监听我们想要的HTTP请求。</li></ol><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/c9e0a22d48a1a7e092797137ec29d5de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oCmmNEzb5RrLDBiZfO4QHQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@jplenio" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@jplenio</a></p></figure><h1 id="e83f" class="nk lv jj bd lw nl nm nn lz no np nq mc kp nr kq mf ks ns kt mi kv nt kw ml nu bi translated">在设置中添加</h1><p id="a6b7" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">scrapy框架提供了一个设置列表，它将自动使用，但是为了使用Scrapy API，我们必须明确地提供设置。我们定义的设置是我们如何定制我们的蜘蛛。蜘蛛。蜘蛛类有一个变量叫做<code class="fe oi oj ok nw b">custom_settings</code>。现在这个变量可以用来覆盖scrapy自动使用的设置。我们必须为我们的设置创建一个字典来做到这一点，因为使用scrapy将<code class="fe oi oj ok nw b">custom_settings</code>变量设置为无。</p><p id="758d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可能想使用scrapy提供的一些或大部分设置，在这种情况下，你可以从那里复制它们。或者，可以在<a class="ae jg" href="https://docs.scrapy.org/en/latest/topics/settings.html?highlight=custom_settings#topics-settings-ref" rel="noopener ugc nofollow" target="_blank">这里</a>找到内置设置列表。</p><pre class="ng nh ni nj gt nv nw nx ny aw nz bi"><span id="6c42" class="lu lv jj nw b gy oa ob l oc od">class TestSpider(scrapy.Spider):<br/>    name = 'test'<br/>    custom_settings = { 'DOWNLOD_DELAY': 1 }</span></pre><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/e373d86457292de0d6c8946cff020aa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PMQ42tsU09alYvL0OeyTFg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@ericjamesward" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@ericjamesward</a></p></figure><h1 id="8d7a" class="nk lv jj bd lw nl nm nn lz no np nq mc kp nr kq mf ks ns kt mi kv nt kw ml nu bi translated">指定要抓取的URL</h1><p id="0a13" class="pw-post-body-paragraph ky kz jj la b lb mp kk ld le mq kn lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">我们已经展示了如何创建一个蜘蛛并定义设置，但是我们还没有指定任何要抓取的URL，或者我们想要如何指定对我们想要从中获取数据的网站的请求。例如，参数、头和用户代理。<br/>当我们创建spider时，我们还启动了一个叫做<code class="fe oi oj ok nw b">start_requests()</code>的方法。这将为我们想要的任何URL创建请求。现在有两种方法可以使用这个方法。</p><p id="1874" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">1)通过定义<code class="fe oi oj ok nw b">start_urls</code>属性<br/> 2)我们实现了我们的函数<code class="fe oi oj ok nw b">start_requests</code></p><p id="0b23" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最短的方法是通过定义<code class="fe oi oj ok nw b">start_urls</code>。我们将它定义为我们想要获取的URL列表，通过指定这个变量，我们自动使用<code class="fe oi oj ok nw b">start_requests()</code>遍历我们的每个URL。</p><pre class="ng nh ni nj gt nv nw nx ny aw nz bi"><span id="38ba" class="lu lv jj nw b gy oa ob l oc od">class TestSpider(scrapy.Spider):<br/>    name = 'test'<br/>    custom_settings = { 'DOWNLOD_DELAY': 1 }<br/>    start_urls = ['URL1','URL2']</span></pre><p id="1e6a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是请注意，如果我们这样做，我们不能指定我们的头，参数或任何其他我们想随请求？这就是实现我们的<code class="fe oi oj ok nw b">start_requests</code>方法的原因。</p><p id="a350" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，我们定义我们希望与请求一致的变量。然后我们实现我们的<code class="fe oi oj ok nw b">start_requests</code>方法，这样我们就可以利用我们想要的头和参数，以及我们想要响应去哪里。</p><pre class="ng nh ni nj gt nv nw nx ny aw nz bi"><span id="ab8f" class="lu lv jj nw b gy oa ob l oc od">class TestSpider(scrapy.Spider):<br/>    name = 'test'<br/>    custom_settings = { 'DOWNLOD_DELAY': 1 }<br/>    headers = {} <br/>    params = {}</span><span id="40b4" class="lu lv jj nw b gy oe ob l oc od">    def start_requests(self):<br/>        yield scrapy.Requests(url, headers=headers, params=params)<br/></span></pre><p id="11d6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里我们访问Requests方法，当给定一个URL时，它将发出HTTP请求并返回一个定义为<code class="fe oi oj ok nw b">response</code>变量的响应。</p><p id="fd03" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你会注意到我们没有指定回调。也就是说，我们没有指定scrapy应该将<code class="fe oi oj ok nw b">response </code>发送到哪里，我们只是告诉它为我们获取请求。</p><p id="c41b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来解决这个问题，默认情况下，scrapy希望回调方法是解析函数，但它可以是我们想要的任何东西。</p><pre class="ng nh ni nj gt nv nw nx ny aw nz bi"><span id="0f10" class="lu lv jj nw b gy oa ob l oc od">class TestSpider(scrapy.Spider):<br/>    name = 'test'<br/>    custom_settings = { 'DOWNLOD_DELAY': 1 }<br/>    headers = {} <br/>    params = {}</span><span id="a10e" class="lu lv jj nw b gy oe ob l oc od">    def start_requests(self):<br/>        yield scrapy.Requests(url, headers=headers, params=params,callback = self.parse)</span><span id="e235" class="lu lv jj nw b gy oe ob l oc od">   def parse(self,response):<br/>       print(response.body)</span></pre><p id="15d1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里我们定义了接受响应变量的函数<code class="fe oi oj ok nw b">parse </code>,记住这是在我们让scrapy执行HTTP请求时创建的。然后，我们要求scrapy打印响应正文。</p><p id="88cc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">至此，我们已经有了在python脚本中运行scrapy的基础。我们可以使用所有相同的方法，但我们只需要事先做一些配置。</p><h1 id="201b" class="nk lv jj bd lw nl nm nn lz no np nq mc kp nr kq mf ks ns kt mi kv nt kw ml nu bi translated">练习</h1><ol class=""><li id="0082" class="mn mo jj la b lb mp le mq lh mr ll ms lp mt lt mu mv mw mx bi translated">为什么你会使用scrapy框架？在python脚本中导入scrapy什么时候有用？</li><li id="006d" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><code class="fe oi oj ok nw b">CrawlerProcess</code>班是做什么的？</li><li id="b642" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">您能回忆起python脚本中用于启动scrapy的基本脚本吗？</li><li id="711f" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">如何在你的python脚本中添加scrapy设置？</li><li id="0e3d" class="mn mo jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">为什么你会使用<code class="fe oi oj ok nw b">start_requests</code>函数而不是<code class="fe oi oj ok nw b">start_urls </code>？</li></ol><p id="0594" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请参见<a class="ae jg" href="http://www.coding-medic.com/" rel="noopener ugc nofollow" target="_blank">这里的</a>了解我在博客和其他帖子上关于项目的更多细节。更多技术/编码相关内容，请点击这里订阅我的简讯<a class="ae jg" href="https://aaronsmith.substack.com/p/coming-soon?r=6yuie&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=copy" rel="noopener ugc nofollow" target="_blank"/></p><p id="0650" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将非常感谢任何评论，或者如果你想与python合作或需要帮助，请联系我。如果你想和我联系，请在这里联系。</p><h1 id="2d98" class="nk lv jj bd lw nl nm nn lz no np nq mc kp nr kq mf ks ns kt mi kv nt kw ml nu bi translated">你可能喜欢的其他文章</h1><div class="is it gp gr iu om"><a href="https://medium.com/swlh/5-python-tricks-you-should-know-d4a8b32e04db" rel="noopener follow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd jk gy z fp or fr fs os fu fw ji bi translated">你应该知道的5个Python技巧</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">如何轻松增强python的基础知识</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">medium.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa ja om"/></div></div></a></div><div class="is it gp gr iu om"><a rel="noopener follow" target="_blank" href="/demystifying-scrapy-item-loaders-ffbc119d592a"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd jk gy z fp or fr fs os fu fw ji bi translated">揭开杂乱物品装载器的神秘面纱</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">自动清理和扩展你的垃圾蜘蛛</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="pb l ox oy oz ov pa ja om"/></div></div></a></div></div></div>    
</body>
</html>