<html>
<head>
<title>Project: Predicting Heart Disease with Classification Machine Learning Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">项目:用分类机器学习算法预测心脏病</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/project-predicting-heart-disease-with-classification-machine-learning-algorithms-fd69e6fdc9d6?source=collection_archive---------5-----------------------#2020-06-11">https://towardsdatascience.com/project-predicting-heart-disease-with-classification-machine-learning-algorithms-fd69e6fdc9d6?source=collection_archive---------5-----------------------#2020-06-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="221f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你刚刚被聘为<strong class="ak">数据科学家</strong></h2></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/d3a61ca2069095161b6a1d95934dab2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vpg36ZNAMlCjy9LKmCgNDw.jpeg"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><a class="ae lc" href="https://unsplash.com/photos/OermHGSUzhI" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="964d" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">目录</strong></h1><p id="2e88" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated"><strong class="lx ir"> 1。简介:</strong>场景&amp;目标，特性&amp;预测器</p><p id="55ea" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir"> 2。数据角力</strong></p><p id="9e85" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir"> 3。探索性数据分析:</strong>相关性，小提琴&amp;箱线图，按阳性&amp;阴性心脏病患者筛选数据</p><p id="ab5b" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir"> 4。机器学习+预测分析:</strong>为建模准备数据，建模/训练，混淆矩阵，特征重要性，predictions‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍</p><p id="3ccf" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir"> 5。结论</strong></p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="0064" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">1.介绍</h1><h1 id="abda" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">场景:</h1><p id="8d6b" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi nb translated">你刚刚被一家医院聘为数据科学家，这家医院有数量惊人的患者报告各种心脏症状。心脏病专家测量生命体征&amp;将数据交给<strong class="lx ir">进行数据分析</strong>和<strong class="lx ir">预测</strong>某些患者是否患有心脏病。我们想做一个<strong class="lx ir">机器学习算法</strong>，在那里我们可以训练我们的 AI 学习&amp;从经验中改进。因此，我们想将患者分为心脏病阳性或阴性。</p><h1 id="129c" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">目标:</h1><ul class=""><li id="6bb9" class="nk nl iq lx b ly lz mb mc me nm mi nn mm no mq np nq nr ns bi translated">预测病人是否应该被诊断为心脏病。这是一个<strong class="lx ir">二元</strong>结果。<br/><strong class="lx ir"/>(+)= 1，患者诊断为心脏病<br/> <strong class="lx ir">阴性</strong> (-) = 0，患者未诊断为心脏病</li><li id="de37" class="nk nl iq lx b ly nt mb nu me nv mi nw mm nx mq np nq nr ns bi translated">用各种<strong class="lx ir">分类模型</strong> &amp;做实验，看看哪一个产生最大的<strong class="lx ir">精确度</strong>。</li><li id="24e9" class="nk nl iq lx b ly nt mb nu me nv mi nw mm nx mq np nq nr ns bi translated">检查我们数据中的<strong class="lx ir">趋势</strong> &amp; <strong class="lx ir">相关性</strong></li><li id="dbf2" class="nk nl iq lx b ly nt mb nu me nv mi nw mm nx mq np nq nr ns bi translated">确定哪些<strong class="lx ir">特征</strong>对阳性/阴性心脏病诊断<strong class="lx ir">最重要</strong></li></ul><h1 id="e55c" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">特征和预测:</h1><p id="eeeb" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">我们的<strong class="lx ir">预测因子</strong> (Y，心脏病的阳性或阴性诊断)是由 13 个<strong class="lx ir">特征</strong> (X)决定的:</p><p id="d170" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">1.<strong class="lx ir">年龄</strong> (#) <br/> 2。<strong class="lx ir">性别</strong> : 1=男，0=女(<em class="ny">二进制</em> ) <br/> 3。(<strong class="lx ir"> cp </strong>)胸痛类型(4 值- <em class="ny">序数</em>):值 1:典型心绞痛，值 2:不典型心绞痛，值 3:非心绞痛性疼痛，值 4:无症状<br/> 4。(<strong class="lx ir"> trestbps </strong>)静息血压(#) <br/> 5。(<strong class="lx ir"> chol </strong>)血清胆固醇以毫克/分升计(#) <br/> 6。(<strong class="lx ir"> fbs </strong>)空腹血糖&gt; 120 mg/dl( <em class="ny">二进制</em> )(1 =真；<br/>0 =假)7。(<strong class="lx ir"> restecg </strong>)静息心电图结果(值 0，1，2) <br/> 8。(<strong class="lx ir"> thalach </strong>)达到的最大心率(#) <br/> 9。(<strong class="lx ir"> exang </strong>)运动诱发心绞痛(<em class="ny">二元</em> ) (1 =是；<br/>0 =否)10。(<strong class="lx ir"> oldpeak </strong> ) =运动相对于休息诱发的 ST 段压低(#) <br/> 11。最大运动 ST 段的(<strong class="lx ir">斜率</strong>)(<em class="ny">序数</em>)(值 1:上坡，值 2:平，值 3:下坡)<br/> 12。(<strong class="lx ir"> ca </strong>)透视着色的主要血管数(0–3，<em class="ny">序数</em>)13。(<strong class="lx ir"> thal </strong>)达到的最大心率— ( <em class="ny">序数</em> ): 3 =正常；6 =修复缺陷；7 =可逆缺陷</p><p id="e85d" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><em class="ny">注:我们的数据有 3 种类型的数据:</em></p><p id="f778" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">(#)</strong>:可以测量的定量数据</p><p id="f130" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">顺序数据</strong>:有顺序的分类数据(0，1，2，3 等)</p><p id="a785" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">二进制数据</strong>:其单元只能呈现两种可能状态的数据(0 &amp; 1)</p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="8ad6" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">2.数据争论</h1><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="f04a" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">import</strong> <strong class="oc ir">numpy</strong> <strong class="oc ir">as</strong> <strong class="oc ir">np</strong><br/><strong class="oc ir">import</strong> <strong class="oc ir">pandas</strong> <strong class="oc ir">as</strong> <strong class="oc ir">pd</strong><br/><strong class="oc ir">import</strong> <strong class="oc ir">matplotlib</strong> <strong class="oc ir">as</strong> <strong class="oc ir">plt</strong><br/><strong class="oc ir">import</strong> <strong class="oc ir">seaborn</strong> <strong class="oc ir">as</strong> <strong class="oc ir">sns</strong><br/><strong class="oc ir">import</strong> <strong class="oc ir">matplotlib.pyplot</strong> <strong class="oc ir">as</strong> <strong class="oc ir">plt</strong></span><span id="76ca" class="og le iq oc b gy ol oi l oj ok">filePath = '/Users/jarar_zaidi/Downloads/datasets-33180-43520-heart.csv'<br/><br/>data = pd.read_csv(filePath)<br/><br/>data.head(5)</span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi om"><img src="../Images/a4686d65cbb6544e2666dce36354eefe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mhu--zqFLmCqhOILpoMyCQ.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">帮助我们了解我们正在处理的数据。</p></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="fccb" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">print("(Rows, columns): " + str(data.shape))<br/>data.columns</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi on"><img src="../Images/6fd3a61777601b3b79ba126280256f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LOz0609ZMX-gmIyn8BAjBw.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">显示行数和列数。以及列名</p></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="3a18" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">data.nunique(axis=0)</strong><em class="ny"># returns the number of unique values for each variable.</em></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oo"><img src="../Images/b09f45ec41dbcb7747c092ff5f3e3f1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*gccgfQ4QhdOgceUs6ObyaA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">返回每个变量的唯一值的数量。</p></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="6ff5" class="og le iq oc b gy oh oi l oj ok"><em class="ny">#summarizes the count, mean, standard deviation, min, and max for numeric variables.</em><br/><strong class="oc ir">data.describe()</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi op"><img src="../Images/32f8bd8a4f98555768f358475150e6f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DBCEgOrpUB9PSb_2_XTF9Q.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">汇总数字变量的计数、平均值、标准差、最小值和最大值。</p></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="eeba" class="og le iq oc b gy oh oi l oj ok"><em class="ny"># Display the Missing Values</em><br/><br/><strong class="oc ir">print(data.isna().sum())</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/05def4c8c588394d44791c620873e5ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*Ng5cW9F6O2gmV-icqfsHZg.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">显示每列缺失值的数量。幸运的是我们没有。</p></figure><p id="aa13" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">让我们看看在我们的正&amp;负<strong class="lx ir">二元预测器之间是否有一个<em class="ny">好的比例</em>。</strong></p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="66fb" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">data['target'].value_counts()</strong></span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi or"><img src="../Images/ee0ac96f7d01bb82fa3ca16ebb8c4878.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*wLQTgiXc5IiH1Fru6H1bRA.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">看起来我们在两个二进制输出之间有一个很好的平衡。</p></figure></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="2c0a" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">3.探索性数据分析</h1><h1 id="d685" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">相关</h1><p id="508f" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated"><strong class="lx ir">相关矩阵</strong> -让我们看看所有变量之间的<strong class="lx ir">相关性</strong>。</p><blockquote class="os ot ou"><p id="f177" class="lv lw ny lx b ly mr jr ma mb ms ju md ov mt mg mh ow mu mk ml ox mv mo mp mq ij bi translated">几秒钟之内，你就能看出某样东西与我们的<strong class="lx ir">预测器(目标)</strong>是正相关还是负相关。</p></blockquote><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="18c9" class="og le iq oc b gy oh oi l oj ok"><em class="ny"># calculate correlation matrix</em><br/><br/><strong class="oc ir">corr = data.corr()<br/>plt.subplots(figsize=(15,10))<br/>sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))<br/>sns.heatmap(corr, xticklabels=corr.columns,<br/>            yticklabels=corr.columns, <br/>            annot=True,<br/>            cmap=sns.diverging_palette(220, 20, as_cmap=True))</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oy"><img src="../Images/f386530e37d15effc9237398ec16799c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEPX4YraHBz9vhF08hw_Ww.png"/></div></div></figure><p id="8410" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">我们可以看到胸痛(cp) &amp;目标值(我们的预测值)之间存在<strong class="lx ir">正相关</strong>。这是有道理的，因为胸痛越严重，患心脏病的几率就越大。Cp(胸痛)，是具有 4 个值的顺序特征:值 1:典型心绞痛，值 2:不典型心绞痛，值 3:非心绞痛性疼痛，值 4:无症状。</p><p id="acd9" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">此外，我们发现运动诱发的心绞痛(exang) &amp;与我们的预测因子<strong class="lx ir">呈负相关</strong>。这是有道理的，因为当你运动时，你的<em class="ny">心脏需要更多的血液</em>、<em class="ny">，但狭窄的动脉会减缓血液流动</em>。</p><p id="32ae" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">Pairplots 也是一种很好的方式，可以立即看到所有变量之间的相关性。但是你会看到我只用我们的数据中的连续列来制作它，因为有这么多的特征，很难看到每一个。因此，我将制作一个只有连续特征的配对图。</p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="a232" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">subData = data[['age','trestbps','chol','thalach','oldpeak']]<br/>sns.pairplot(subData)</strong></span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oz"><img src="../Images/ed946e91f478de2f6e63c15bec44273b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K5UEWawdKDz7frrKzTDYbQ.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">选择用<strong class="bd pa">和</strong>连续的<strong class="bd pa">变量制作一个较小的 pairplot，以便更深入地研究这些关系。这也是一个很好的方法来看看他们之间是正相关还是负相关！</strong></p></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="3e56" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">sns.catplot(x="target", y="oldpeak", hue="slope", kind="bar", data=data);<br/><br/>plt.title('ST depression (induced by exercise relative to rest) vs. Heart Disease',size=25)<br/>plt.xlabel('Heart Disease',size=20)<br/>plt.ylabel('ST depression',size=20)</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pb"><img src="../Images/218c550aa4994677d8272570bf4f8808.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HTG-7LLIdMsKgUp2aWdNbQ.png"/></div></div></figure><p id="d814" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">ST 段压低的发生是因为当心室处于静止状态并因此复极时。如果 ST 段中的迹线异常地低于基线，此<em class="ny">可导致此心脏病</em>。这支持了上面的图表，因为低 ST 段抑郁会使人们有更大的患心脏病的风险。而高度 ST 段压低被认为是正常的&amp;健康的。<em class="ny">斜率</em>色调，指运动 ST 段峰值，取值:0:上升，1:平缓，2:下降)。两个阳性&amp;阴性心脏病患者都表现出 3 个斜率类别的<strong class="lx ir">均等分布</strong>。</p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="9f04" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">小提琴和盒子图</h1><p id="5dca" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">显示方框&amp;图的<strong class="lx ir">优点</strong>是显示<em class="ny">基本</em>数据的<em class="ny">统计</em>，以及其<em class="ny">分布</em>。这些图通常用于比较给定变量在某些类别中的分布。</p><p id="632c" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">它显示了<strong class="lx ir">中值，IQR，&amp;图基的栅栏。</strong>(最小值、第一个四分位数(Q1)、中值、第三个四分位数(Q3)和最大值)。</p><p id="9ff4" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">此外，它可以为我们提供数据中的异常值。</p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="731b" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">plt.figure(figsize=(12,8))<br/>sns.violinplot(x= 'target', y= 'oldpeak',hue="sex", inner='quartile',data= data )<br/>plt.title("Thalach Level vs. Heart Disease",fontsize=20)<br/>plt.xlabel("Heart Disease Target", fontsize=16)<br/>plt.ylabel("Thalach Level", fontsize=16)</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pc"><img src="../Images/1dc348f1f5215332fbc4bc3eb5847f2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*akf110UP7sN5a2fCnot4lg.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">我们可以看到，阴性和阳性患者的总体形状和分布<strong class="bd pa">差别很大</strong>。阳性患者表现出较低的 ST 段压低水平中位数&amp;，因此他们的数据分布在 0 &amp; 2 之间，而阴性患者在 1 &amp; 3 之间。此外，我们看不出男性&amp;女性目标结果之间有多大差异。</p></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="8c2c" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">plt.figure(figsize=(12,8))<br/>sns.boxplot(x= 'target', y= 'thalach',hue="sex", data=data )<br/>plt.title("ST depression Level vs. Heart Disease", fontsize=20)<br/>plt.xlabel("Heart Disease Target",fontsize=16)<br/>plt.ylabel("ST depression induced by exercise relative to rest", fontsize=16)</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pd"><img src="../Images/1c788575fa38457bf4dd1496641b18f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cAiRuPMRnhjOLpb_xOGQEw.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><strong class="bd pa">阳性患者</strong>表现出<strong class="bd pa">增高的 ST 段压低水平中位数</strong>，而<strong class="bd pa">阴性患者</strong>的水平较低。此外，我们看不出男性&amp;和女性<strong class="bd pa">的目标结果有什么不同，除了男性的 ST 段下降幅度稍大。</strong></p></figure><h1 id="6eb0" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">按阳性和阴性心脏病患者过滤数据</h1><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="239d" class="og le iq oc b gy oh oi l oj ok"># Filtering data by POSITIVE Heart Disease patient<br/><strong class="oc ir">pos_data = data[data['target']==1]<br/>pos_data.describe()</strong></span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pe"><img src="../Images/6f41d52b42e01453f6fe2e1b289f390e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XEtoDHnlqO7kYha7jta74Q.png"/></div></div></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="d853" class="og le iq oc b gy oh oi l oj ok"># Filtering data by NEGATIVE Heart Disease patient<br/><strong class="oc ir">pos_data = data[data['target']==0]<br/>pos_data.describe()</strong></span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pf"><img src="../Images/f7f4d1a0d1ef3e921db60124a25f8725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lLWrXaIKgr5kBvbied8wrA.png"/></div></div></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="6f0e" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">print("(Positive Patients ST depression): " + str(pos_data['oldpeak'].mean()))<br/>print("(Negative Patients ST depression): " + str(neg_data['oldpeak'].mean()))</strong></span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/471d9d650bbd149cfb48aff5b553fc40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*w3vhzn3LNSSw27CEyWczwQ.png"/></div></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="b4aa" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">print("(Positive Patients thalach): " + str(pos_data['thalach'].mean()))<br/>print("(Negative Patients thalach): " + str(neg_data['thalach'].mean()))</strong></span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/0d60272ac64b929aaf4f76aa7fc49477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*a_zywZwd6Ug4KyKmrvlqVA.png"/></div></figure><p id="ac21" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">从<em class="ny">对比</em>阳性和阴性患者我们可以看到<strong class="lx ir">在我们的<em class="ny"> 13 特征</em>的很多手段上有</strong>巨大的差异。通过检查细节，我们可以观察到<strong class="lx ir">阳性患者的最大心率增加，达到了</strong> (thalach)平均值。此外，<strong class="lx ir">阳性患者表现出运动诱发的 ST 段压低</strong>相对于静息(oldpeak)约 1/3 的量。</p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="31db" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">4.机器学习+预测分析</h1><h1 id="4072" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">为建模准备数据</h1><p id="83ce" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">为建模准备数据，只需记住<strong class="lx ir"> ASN(赋值，拆分，规格化)。</strong></p><p id="64b5" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi nb translated"><span class="l nc nd ne bm nf ng nh ni nj di">A</span>T22 将 13 个特征赋值给 X，&amp;最后一列给我们的分类预测值，y</p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="7cc9" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">X = data.iloc[:, :-1].values<br/>y = data.iloc[:, -1].values</strong></span></pre><p id="387c" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi nb translated"><span class="l nc nd ne bm nf ng nh ni nj di">S</span>S<strong class="lx ir">plit</strong>:数据集分为训练集和测试集</p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="d9e9" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 1)</strong></span></pre><p id="4aea" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi nb translated"><span class="l nc nd ne bm nf ng nh ni nj di"> N </span> <strong class="lx ir">标准化</strong>:标准化数据将转换数据，使其分布的平均值为 0，标准差为 1。</p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="feeb" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>x_train = sc.fit_transform(x_train)<br/>x_test = sc.transform(x_test)</strong></span></pre></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="526b" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">建模/培训</h1><p id="4e6d" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">现在，我们将在训练集&amp;上训练各种<strong class="lx ir">分类模型</strong>，看看哪个<strong class="lx ir">产生最高的准确度</strong>。我们将<em class="ny">比较</em>逻辑回归、<em class="ny">K-NN(</em>K-最近邻)<em class="ny">、SVM(支持向量机)、Naives Bayes 分类器、决策树、随机森林和 XGBoost </em>的准确性。</p><p id="7f46" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">注:这些都是<strong class="lx ir">监督学习模型</strong>。</p><p id="9627" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">模型 1:逻辑回归</strong></p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="ef2e" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.metrics</strong> <strong class="oc ir">import</strong> classification_report <br/><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.linear_model</strong> <strong class="oc ir">import</strong> LogisticRegression<br/><br/><strong class="oc ir">model1 = LogisticRegression(random_state=1)</strong> <em class="ny"># get instance of model</em><br/><strong class="oc ir">model1.fit(x_train, y_train)</strong> <em class="ny"># Train/Fit model </em><br/><br/><strong class="oc ir">y_pred1 = model1.predict(x_test)</strong> <em class="ny"># get y predictions</em><br/><strong class="oc ir">print(classification_report(y_test, y_pred1))</strong> <em class="ny"># output accuracy</em></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/97dfa814214a73e9808bd83c99af6802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*COiLkfeKeKyFaVgAjSwGKA.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><strong class="bd pa">准确率 74% </strong></p></figure><p id="b467" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">模型 2:K-NN(K-最近邻)</strong></p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="30b6" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.metrics</strong> <strong class="oc ir">import</strong> classification_report <br/><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.neighbors</strong> <strong class="oc ir">import</strong> KNeighborsClassifier<br/><br/><strong class="oc ir">model2 = KNeighborsClassifier()</strong> <em class="ny"># get instance of model</em><br/><strong class="oc ir">model2.fit(x_train, y_train)</strong> <em class="ny"># Train/Fit model </em><br/><br/><strong class="oc ir">y_pred2 = model2.predict(x_test)</strong> <em class="ny"># get y predictions</em><br/><strong class="oc ir">print(classification_report(y_test, y_pred2))</strong> <em class="ny"># output accuracy</em></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/c970ec282b259c50eb9373a258f91baa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*59-1Rg600D_XMKsdHNVaXQ.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><strong class="bd pa">准确率 75% </strong></p></figure><p id="e129" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">模型三:SVM(支持向量机)</strong></p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="1acc" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.metrics</strong> <strong class="oc ir">import</strong> classification_report <br/><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.svm</strong> <strong class="oc ir">import</strong> <strong class="oc ir">SVC</strong><br/><br/><strong class="oc ir">model3 = SVC(random_state=1)</strong> <em class="ny"># get instance of model</em><br/><strong class="oc ir">model3.fit(x_train, y_train) </strong><em class="ny"># Train/Fit model </em><br/><br/><strong class="oc ir">y_pred3 = model3.predict(x_test)</strong> <em class="ny"># get y predictions</em><br/><strong class="oc ir">print(classification_report(y_test, y_pred3))</strong> <em class="ny"># output accuracy</em></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pk"><img src="../Images/1f07d3618cb6e8f3a1cda7c37092051d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kOirFROHLSIyolg_EaLyHw.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><strong class="bd pa">准确率 75% </strong></p></figure><p id="7e34" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">模型 4: Naives 贝叶斯分类器</strong></p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="bf7b" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.metrics</strong> <strong class="oc ir">import</strong> classification_report <br/><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.naive_bayes</strong> <strong class="oc ir">import</strong> GaussianNB<br/><br/><strong class="oc ir">model4 = GaussianNB()</strong> <em class="ny"># get instance of model</em><br/><strong class="oc ir">model4.fit(x_train, y_train)</strong> <em class="ny"># Train/Fit model </em><br/><br/><strong class="oc ir">y_pred4 = model4.predict(x_test) </strong><em class="ny"># get y predictions</em><br/><strong class="oc ir">print(classification_report(y_test, y_pred4)) </strong><em class="ny"># output accuracy</em></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/64d0e3f33d3e2c494fee57917b6624f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*t6bLQgUboxisC9g0LA2r3w.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><strong class="bd pa">准确率 77% </strong></p></figure><p id="6527" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">模型 5:决策树</strong></p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="be8d" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.metrics</strong> <strong class="oc ir">import</strong> classification_report <br/><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.tree</strong> <strong class="oc ir">import</strong> DecisionTreeClassifier<br/><strong class="oc ir"><br/>model5 = DecisionTreeClassifier(random_state=1) </strong><em class="ny"># get instance of model</em><br/><strong class="oc ir">model5.fit(x_train, y_train) </strong><em class="ny"># Train/Fit model </em><br/><br/><strong class="oc ir">y_pred5 = model5.predict(x_test)</strong> <em class="ny"># get y predictions</em><br/><strong class="oc ir">print(classification_report(y_test, y_pred5))</strong> <em class="ny"># output accuracy</em></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/bc051e133ae087aa4b069890b1d9f309.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*l96OtTGLMniqwZErv4AD7w.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><strong class="bd pa">准确率 69% </strong></p></figure><p id="e11e" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">模式六:随机森林</strong>🏆</p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="5a15" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.metrics</strong> <strong class="oc ir">import</strong> classification_report <br/><strong class="oc ir">from</strong> <strong class="oc ir">sklearn.ensemble</strong> <strong class="oc ir">import</strong> RandomForestClassifier<br/><br/><strong class="oc ir">model6 = RandomForestClassifier(random_state=1)</strong><em class="ny"># get instance of model</em><br/><strong class="oc ir">model6.fit(x_train, y_train)</strong> <em class="ny"># Train/Fit model </em><br/><br/><strong class="oc ir">y_pred6 = model6.predict(x_test) </strong><em class="ny"># get y predictions</em><br/><strong class="oc ir">print(classification_report(y_test, y_pred6)) </strong><em class="ny"># output accuracy</em></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/8ec35b0846a1d2bf76b97543756ae8ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*LCpgUCNRVS33_8mft246_Q.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><strong class="bd pa">准确率 80%！</strong>🏆</p></figure><p id="a372" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">型号 7: XGBoost </strong></p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="ba3c" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from</strong> <strong class="oc ir">xgboost</strong> <strong class="oc ir">import</strong> XGBClassifier<br/><strong class="oc ir"><br/>model7 = XGBClassifier(random_state=1)<br/>model7.fit(x_train, y_train)<br/>y_pred7 = model7.predict(x_test)<br/>print(classification_report(y_test, y_pred7))</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/c292200e62a07250504de35da1ac69e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*d91xFGAXz40S1GpfFrK1Zw.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><strong class="bd pa">准确率 69% </strong></p></figure><blockquote class="os ot ou"><p id="d78f" class="lv lw ny lx b ly mr jr ma mb ms ju md ov mt mg mh ow mu mk ml ox mv mo mp mq ij bi translated">通过比较这 7 个模型，我们可以<strong class="lx ir">得出</strong>结论:<strong class="lx ir">模型 6:随机森林</strong>产生的<strong class="lx ir">精确度最高</strong>。准确率高达 80%。🏆</p></blockquote><p id="d14d" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">精度、召回、F1-得分</strong>和<strong class="lx ir">支持</strong>:</p><p id="86b1" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">精度</strong>:是“该类中有多少被正确分类”</p><p id="f8ba" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">回想一下</strong>:“你在这个类的所有元素中找到了多少个这样的元素”</p><p id="ad6f" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">F1-得分</strong>:调和<em class="ny">表示精度和召回值的</em>。<br/> F1 得分在 1 时达到最佳值，在 0 时达到最差值。<br/> F1 得分= 2 x((精度 x 召回)/(精度+召回))<br/> <br/> <strong class="lx ir">支持</strong>:<em class="ny">真</em>响应的样本数，即位于该类中。</p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="ceca" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">制作混淆矩阵</h1><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="6e67" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">from sklearn.metrics import confusion_matrix, accuracy_score<br/>cm = confusion_matrix(y_test, y_pred6)<br/>print(cm)<br/>accuracy_score(y_test, y_pred6)</strong></span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi po"><img src="../Images/8b8fc0c008f5d90c93b324cf28c4d66a.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*TCne0TLZ4U2xdciq4rzbhw.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">注意:一个<strong class="bd pa">好的经验法则</strong>是任何高于 70% 的精度<strong class="bd pa">都被认为是<strong class="bd pa">好的</strong>，但是要小心，因为如果你的精度非常高，它可能好得不真实(一个<strong class="bd pa">过度拟合</strong>的例子)。因此，80%是<strong class="bd pa">的理想精度</strong>！</strong></p></figure><p id="7333" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">如何解读混淆矩阵:</strong></p><p id="114f" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">21 是我们数据中<strong class="lx ir">真阳性</strong>的数量，而 28 是<strong class="lx ir">真阴性的数量。</strong></p><p id="454b" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">9 和 3 是<strong class="lx ir">错误</strong>的数量。</p><p id="cfcc" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">有 9 个<strong class="lx ir">类型 1 错误(假阳性)</strong> -你预测阳性，它是假的。</p><p id="c692" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">有 3 个<strong class="lx ir">类型 2 错误</strong> <strong class="lx ir">【假阴性】</strong>——你预测阴性，是假的。</p><p id="8928" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">因此，如果我们计算<strong class="lx ir">准确度</strong>，它的#正确预测/ #总数。<br/>换句话说，其中 TP、FN、FP 和 TN 代表真阳性、假阴性、假阳性和真阴性的数量。</p><p id="f870" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">精度</strong> = (TP + TN)/(TP + TN + FP + FN)。<br/> <strong class="lx ir">精度</strong>=(21+28)/(21+28+9+3)= 0.80 =<strong class="lx ir">80%精度</strong></p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="aa73" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">特征重要性</h1><p id="4b3e" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated"><strong class="lx ir">特性重要性</strong>提供了一个<strong class="lx ir">分数</strong>，表明<strong class="lx ir">每个特性在我们的模型中有多有用</strong>。</p><blockquote class="pp"><p id="84d3" class="pq pr iq bd ps pt pu pv pw px py mq dk translated">该<strong class="ak">特征得分越高，<strong class="ak">用于做出关键决策的特征越多</strong>&amp;因此越重要。</strong></p></blockquote><pre class="pz qa qb qc qd ob oc od oe aw of bi"><span id="5de3" class="og le iq oc b gy oh oi l oj ok"><em class="ny"># get importance</em><br/><strong class="oc ir">importance = model6.feature_importances_</strong><br/><br/><em class="ny"># summarize feature importance</em><br/><strong class="oc ir">for i,v in enumerate(importance):<br/>    print('Feature: %0d, Score: %.5f' % (i,v))</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/50d30cb5b4b90a30c62120a31bb8bef4.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*2OaqQ3VTifUuJBr-QyjTgg.png"/></div></figure><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="4581" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">index= data.columns[:-1]<br/>importance = pd.Series(model6.feature_importances_, index=index)<br/>importance.nlargest(13).plot(kind='barh', colormap='winter')</strong></span></pre><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi qf"><img src="../Images/52e7e03b4d86387f355045c418215789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*PlbOMxy9OVz4so9F4Kjg5g.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">从上面的特征重要性图中，我们可以得出结论，<strong class="bd pa">前 4 个显著特征</strong>分别是胸痛类型(<strong class="bd pa"> cp </strong>)、达到的最大心率(<strong class="bd pa"> thalach </strong>)、主要血管数量(<strong class="bd pa"> ca </strong>)以及运动相对于休息诱发的 st 段压低(<strong class="bd pa"> oldpeak </strong>)。</p></figure></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="fee8" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">预言</h1><p id="0f7a" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi nb translated"><span class="l nc nd ne bm nf ng nh ni nj di"> S </span> <strong class="lx ir"> cenario </strong>:一个病人出现心脏症状&amp;你把他的生命体征输入机器学习算法。</p><p id="bf03" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">他是一名<strong class="lx ir"> 20 </strong>岁男性，胸痛值<strong class="lx ir">2</strong>(非典型心绞痛)，静息血压<strong class="lx ir">110。</strong></p><p id="3f32" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">此外，他的血清胆固醇水平为 230 毫克/分升。</p><p id="31e3" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">他是<strong class="lx ir">空腹血糖&gt; 120 mg/dl。</strong></p><p id="58a0" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">他有一个<strong class="lx ir"> 1 的<strong class="lx ir">静息心电图结果</strong>。</strong></p><p id="3e8f" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">患者达到的最大心率</strong>是<strong class="lx ir"> 140。</strong></p><p id="e3be" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">还有，他是<strong class="lx ir">运动诱发的心绞痛。</strong></p><p id="1d78" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">他的<strong class="lx ir">运动诱发的 ST 段压低</strong>相对于休息值为<strong class="lx ir"> 2.2。</strong></p><p id="c196" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">峰值运动 ST 段的<strong class="lx ir">坡度</strong>为<strong class="lx ir">平</strong>。</p><p id="6737" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">他的<strong class="lx ir">没有透视着色的大血管</strong>，此外他的<strong class="lx ir">达到的最大心率</strong>是可逆的缺陷。</p><p id="aed9" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">根据这些信息，你能<strong class="lx ir">给</strong>这个心脏病患者分类吗？</p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="7411" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">print(model6.predict(sc.transform([[20,1,2,110,230,1,1,140,1,2.2,2,0,2]])))</strong></span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi qg"><img src="../Images/206fb9a172ef2e37048a99c02e709224.png" data-original-src="https://miro.medium.com/v2/resize:fit:116/format:webp/1*7BlJjY5UA0i5v7gbd-kAEw.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><strong class="bd pa">输出</strong>二进制<strong class="bd pa"> 1 </strong> - &gt;意为<strong class="bd pa">阳性</strong>心脏病诊断</p></figure><p id="6c14" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">预测测试集结果:</p><p id="db0e" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">第一个值</strong>代表我们的<strong class="lx ir"> <em class="ny">预测值</em> </strong>，<strong class="lx ir">第二个值</strong>代表我们的<strong class="lx ir"><em class="ny"/></strong>实际值。</p><p id="b218" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">如果值<strong class="lx ir">与</strong>匹配，那么我们正确预测了<strong class="lx ir"/>。</p><pre class="kn ko kp kq gt ob oc od oe aw of bi"><span id="c71b" class="og le iq oc b gy oh oi l oj ok"><strong class="oc ir">y_pred = model6.predict(x_test)<br/>print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))</strong></span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi qh"><img src="../Images/f59619536fa4293217690d9d09fbbca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:208/format:webp/1*ineib8ACerRZ4D7X9SQlRQ.png"/></div></figure></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/8923432b9c437400fec0157614c8086c.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*Lp6M26R8AJ0JEfL69S2_WA.png"/></div></figure><p id="2413" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">可以看到我们的结果非常<strong class="lx ir">准确(80%) </strong>！</p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="0d2f" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated">结论</h1><p id="94e6" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated"><strong class="lx ir"> 1。在我们检查的 13 个特征中，有助于我们在阳性&amp;阴性诊断之间进行分类的前 4 个显著特征是胸痛类型(cp)、达到的最大心率(thalach)、主要血管数量(ca)和运动相对于休息诱发的 st 段压低(oldpeak)。</strong></p><p id="8134" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir"> 2。我们的机器学习算法现在可以对心脏病患者进行分类。现在我们可以正确地诊断病人，给他们康复所需的帮助。通过早期诊断和检测这些特征，我们可以防止以后出现更糟糕的症状。</strong></p><p id="5d24" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir"> 3。我们的随机森林算法产生最高的准确率，80%。任何超过 70%的准确度都被认为是好的，但是要小心，因为如果你的准确度非常高，可能好得不像真的(过度拟合的一个例子)。因此，80%是理想的准确度！</strong></p><p id="a3f0" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">以下是从我的 GitHub 页面获得的数据集和代码:</p><p id="26dc" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><a class="ae lc" href="https://github.com/jzaidi143/Project-Predicting-Heart-Disease-with-Classification-Machine-Learning-Algorithms" rel="noopener ugc nofollow" target="_blank">https://github . com/jzaidi 143/Project-Predicting-Heart-Disease-with-class ification-Machine-Learning-Algorithms</a></p><p id="14f8" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">欢迎推荐和评论！</p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="5ad4" class="ld le iq bd lf lg mw li lj lk mx lm ln jw my jx lp jz mz ka lr kc na kd lt lu bi translated"><strong class="ak">致谢</strong></h1><p id="1fa8" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">创作者:</p><ol class=""><li id="4143" class="nk nl iq lx b ly mr mb ms me qj mi qk mm ql mq qm nq nr ns bi translated">匈牙利心脏病研究所。布达佩斯:医学博士安朵斯·雅诺西</li><li id="5bdf" class="nk nl iq lx b ly nt mb nu me nv mi nw mm nx mq qm nq nr ns bi translated">瑞士苏黎世大学医院:威廉·斯坦布伦医学博士</li><li id="b67f" class="nk nl iq lx b ly nt mb nu me nv mi nw mm nx mq qm nq nr ns bi translated">瑞士巴塞尔大学医院:马蒂亚斯·菲斯特勒医学博士</li><li id="b8fa" class="nk nl iq lx b ly nt mb nu me nv mi nw mm nx mq qm nq nr ns bi translated">弗吉尼亚医疗中心，长滩和克利夫兰诊所基金会:罗伯特·德特拉诺，医学博士，哲学博士。</li></ol><p id="aeaf" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">捐赠者:<br/>大卫·w·阿哈(阿哈' @ ' ics.uci.edu)(714)856–8779</p></div></div>    
</body>
</html>