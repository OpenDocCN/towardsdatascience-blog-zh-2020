# 机器学习的实用介绍

> 原文：<https://towardsdatascience.com/a-practical-introduction-to-machine-learning-f43d8badc5a7?source=collection_archive---------46----------------------->

## 一个简单的入门 ML 从业者和爱好者的参考指南，介绍了它的各种术语，概念和技术

![](img/2f7389b6892d369b1e0218450b6125bd.png)

图片由 [Pixabay](https://www.pexels.com/@pixabay) 来自 [Pexels](https://www.pexels.com/photo/letter-blocks-247819/)

继[我之前关于数据科学的文章](/data-science-what-exactly-does-it-mean-26ffac8a0b6)之后，在这里，我将尝试以一种方便、易用、语言无关的参考指南格式来总结和编译机器学习的主要**实用**概念。大多数信息都以简短扼要的要点形式呈现。我希望这对于初学者来说特别有价值，或者对于那些在数据科学和机器学习方面有基本经验的人来说是一个快速查询。

# 介绍性概念

让我们先弄清楚一些基本术语:

*   **结构化数据**指以预定义格式存储的数据，例如表格、电子表格或关系数据库
*   **另一方面，非结构化数据**没有预定义的格式，因此不能以表格形式保存。非结构化数据可能有多种类型，例如文本、图像、视频、音频文件
*   **分类数据**是任何可以标记的数据，通常由一系列固定值组成，如性别、国籍、风险等级。分类数据可以是名义数据(没有任何固有的排序，例如性别)或顺序数据(排序或分级数据，例如风险等级)。这些固定值被称为**类**或**类**
*   **特征或预测器**:ML 模型使用的输入数据/变量，通常用`X`表示，用于预测目标变量
*   **目标变量**:我们希望用 ML 模型预测的数据点，通常用`y`表示
*   **分类问题**涉及预测分类目标变量的离散类别，例如，垃圾邮件与否、违约或非违约
*   **回归问题**处理预测一个连续的数值，例如销售额、房价
*   **特征工程**:转换现有特征或设计新的输入特征，这些特征在模型训练期间可能更有用。例如，为日期变量计算从今天开始的月数
*   **训练、验证&测试数据**:初始模型训练/拟合时使用训练数据。验证数据用于评估模型，通常用于微调模型参数或在众多模型中确定最合适的 ML 模型。测试数据用于最终评估入围或微调的模型
*   **过度拟合**发生在模型在训练数据上表现良好，但在测试/验证数据上表现不佳的时候，即不能对新的和看不见的数据进行充分概括的时候
*   **欠拟合**发生在模型不够复杂和稳健，无法从训练数据中学习变量关系，甚至在应用于训练数据时精度也较低的时候
*   **模型偏差和方差**:当一个模型由于拟合不足而在训练数据集上表现不佳时，该模型被认为是有偏差的。方差与模型在测试/验证集上的表现好坏有关，高方差通常是由过度拟合引起的
*   **泛化**，与过度拟合和模型方差密切相关，指的是模型对新的、以前看不到的数据做出正确预测的能力
*   **正则化**技术提高了模型的概化能力，例如，通过惩罚回归系数或将回归系数收缩到零
*   **集成学习**是一种将多个模型组合成一个模型的建模技术
*   **基线模型**是一种简单的模型/启发式方法，用作评估传统 ML 模型的参考点
*   **超参数**是在模型训练期间可以调整的特定模型参数

# 数据清理和特征工程

数据清洗将原始数据转换成能够被 ML 模型有效且高效地处理的形式和格式。尽管 GIGO 原理被认为是智能和稳健的，但它在 ML 中仍然有效。更多细节请参考我之前的[文章](/practical-guide-to-data-cleaning-in-python-f5334320e8e)。

处理缺失数据:

*   删除所有缺少要素的记录-不推荐
*   使用领域知识的启发式插补
*   缺失值的均值/中值/众数插补
*   使用随机值或常数来填充缺失的数据
*   利用 k 个最近邻或线性回归模型来预测和估算缺失值

其他一些典型的数据清理任务包括:

*   识别并删除零方差特征
*   识别并尽可能删除显示多重共线性或高度成对相关的要素
*   利用领域知识评估低方差或接近零方差的特性。最适用于数字和名义分类数据
*   删除重复记录(如果适用)
*   识别异常值并确定适当的策略来处理它们——要么丢弃它们，要么修剪它们，要么保持原样，因为一些 ML 模型可以有效地处理异常值

## 特征工程

特征工程与其说是科学，不如说是一门艺术，它主要依赖于一个人的领域知识。如果操作正确，它有可能提高模型的预测能力。

**数字数据的特征工程技术:**

*   使用对数标度、z 值、最小值-最大值进行缩放、归一化或标准化
*   使用原始数字特征中的数学或统计交互作用创建新特征，例如通过加法、减法或统计测试
*   利用统计变换将偏斜分布转换成类似高斯的分布，例如对数/幂和 Box-Cox 变换
*   降维技术，例如主成分分析(PCA)
*   宁滨一个数字特征分类一般不推荐。但是，在某些用例中(例如，信用风险评分),它是经过验证和充分研究的行业最佳实践

**分类数据的特征工程技术:**

*   顺序编码:将有序分类数据转换成数值，例如，好、坏、更坏转换成 1、2、3
*   名义分类数据的一键编码。每个特征的类别被转换成一个单独的列，其中它的存在用 1 表示，不存在用 0 表示。例如，[美国，英国，澳大利亚]转换为[[1，0，0]，[0，1，0]，[0，0，1]]
*   在自然语言处理中广泛使用的某些特定技术，例如特征散列法和词嵌入法

# 建模概述和原则

**那么机器学习模型到底是做什么的呢？**给定训练数据中的一组特征`X`，ML 模型试图迭代地找到理想的统计函数(通常称为训练函数)，该统计函数最准确地将`X`映射到训练数据的目标变量`y`。寻找理想的训练函数通常涉及对基础数据及其形式做出某些假设。给定`X`，这个训练函数然后被用于预测`y`未来的任何新数据。

## 一些基本的建模原则

在这里，我们将触及一些与建模相关的一般原则和哲学:

**模型精度及其可解释性权衡**

更好的模型精度通常会导致相对较低的模型可解释性。

复杂的模型，如深度神经网络和集成决策树，通常比简单的模型表现更好。然而，它们的可解释性要差得多，因为训练功能对于外行人来说不容易理解。更简单的模型，如线性回归、逻辑回归和单一决策树，很容易以准确性为代价进行解释。

考虑一个简单的逻辑回归模型。它为我们提供了每个特征的系数，进而为我们提供了关于该特征对预测问题有多有用的见解。

因此，有时，模型选择通常是由所需的复杂性和可解释性水平驱动的。一些领域，如信用评分，或多或少要求使用一个易于解释的模型。因此，逻辑回归在历史上被广泛用于信用评分问题。然而，对于图像检测、识别和自然语言处理来说，可解释性就不那么重要了。因此，复杂的深度神经网络可以安全地部署在这些领域中。

**偏差/方差权衡**

一般来说，模型的偏差可以通过参数调整或选择完全不同的模型来改善，而方差可以通过更多的训练数据、正则化技术或防止训练集和测试集之间的任何数据泄漏来减少。偏差和方差只能在一定程度上同时改善，超过这一程度，一个方面的改善通常会导致另一方面的恶化。

这种权衡非常普遍，在实践中需要微妙的平衡。请注意，由于数据中的随机噪声，总会有一些不可避免的方差，这使得实际上不可能将方差降至 0。

**奥卡姆剃刀**

奥卡姆剃刀(Occam's Razor)是一个普遍的哲学原理，它指出:如果一个事件或一个事实有两种解释，那么最简单、假设最少的解释很可能是正确的。当应用于 ML 时，奥卡姆剃刀原理意味着，当比较两个具有相似预测能力或准确性的模型时，我们应该选择更简单的模型。

**没有免费的午餐定理**

没有一个单一的机器学习模型能最好地解决所有可能的问题。Wolpert 和 Macready 指出:“如果一种算法在某类问题上比随机搜索表现得更好，那么它在其余问题上的表现一定比随机搜索差”。尝试多种相关模型并找到最适合您的特定问题的模型是很常见的。

# 建模分类学

机器学习模型可以以几种方式分类，其中一些是:

**参数与非参数**

参数模型对训练数据做出强假设，以识别训练函数并将其简化为已知形式，其参数完全描述并捕捉特征和目标变量之间的关系。

例如，线性回归模型假设输入要素和目标变量之间存在线性关系，并会尝试找到最佳的线性函数。然而，如果这个假设是无效的，那么该模型将预测差的结果。

参数模型的例子包括线性回归、逻辑回归和朴素贝叶斯。

非参数模型不会对训练数据或训练函数的形式做出强有力的假设，因此通常更灵活，但代价是潜在的过拟合。

非参数模型的例子包括 k 近邻、决策树和支持向量机(SVM)。

**有人监督与无人监督**

有监督的模型试图预测已知的目标变量，而无监督的模型事先没有关于目标变量的任何知识。无监督学习的目标是尝试并理解变量或观察值之间的关系。

监督模型包括线性回归、逻辑回归和决策树，而非监督模型包括 k 近邻、SVM、隔离森林和 PCA

**黑盒 vs .描述性**
黑盒模型利用多种复杂算法做出决策，但我们不知道决策/预测是如何得出的。例如深度学习和神经网络。

描述性模型提供了对他们为什么以及如何做出决策的清晰洞察。例如线性回归、逻辑回归、决策树

**常用 ML 型号**

深度机器学习领域之外的一些广泛使用的 ML 模型包括:

*   **线性回归**是一个简单且广泛应用于回归问题的监督学习模型。它基于特征和目标变量之间存在线性关系的假设来预测数字目标变量
*   **逻辑回归**广泛用于预测类别，或在给定一组特征的情况下被分配到该类别的概率。因此，它是分类问题的监督模型。逻辑回归假设所有特征与目标变量的对数优势(logit)具有线性关系。当[预测不平衡类](/how-to-effectively-predict-imbalanced-classes-in-python-e8cd3b5720c4)时需要非常小心
*   **k-最近邻(KNN)** 是一个监督模型，可用于分类和回归问题。它通过距离度量(最常见的是欧几里德距离)对每个观察的最近邻居的`k`数量进行简单多数投票来预测
*   **k-Means 聚类**是一种无监督聚类算法，它以最小化每个聚类中单个观察值之间差异的方式将观察值分配给各个组
*   **决策树**是监督模型，可以使用一系列规则用于回归和分类问题。单个决策树很少在实践中使用，因为它有过度拟合的风险。相反，集合或 bagging 概念被用来最小化模型方差
*   **随机森林**是一个集成模型，它通过装袋的概念来组合多个决策树，以减少模型误差
*   **支持向量机(SVM)** 是一种监督分类模型，旨在找到所有可能类别之间的理想超平面或边界，使它们之间的距离最大化。这个超平面然后被用于分类

# 模型评估

但是我们的模型在预测方面有多好呢？模型评估给了我们答案。

## 评估策略

各种评估策略的简要概述如下:

**训练/测试分割**

将完整的数据集分成两个子集，称为训练和测试(通常以 80/20、75/25 或 70/30 的比例分割)。在训练集上训练模型，并对在测试集上做出的模型预测应用评估度量。这**不是理想的方法**，因为没有单独的数据集来测试、评估和比较模型参数(称为超参数优化)或多个模型。

对测试集进行这样的评估并使用结果来调整模型将导致从测试集到训练集的数据泄漏以及不可靠的最终评估度量。这是因为我们使用来自测试集的信息(应该被认为是我们在生产中会遇到的新的、看不见的数据)来训练模型。

**训练/验证/测试分割**

将整个数据集分成三个子集。在训练集上训练单个或多个模型，并对在验证集上做出的模型预测应用初步评估度量。使用这些结果来微调单个模型或选择最佳模型。一旦选择了最终模型，就将其应用于尚未接触的测试数据集，并对其进行评估。这可以防止任何数据泄漏，是一种更好的评估方法，但不是理想的评估方法。

**交叉验证**

CV 在训练/测试分割后应用于训练集。CV 将训练集拆分为多个子集(称为折叠)，并在除一个子集之外的所有子集上拟合模型，并在维持集上对其进行评估。这将产生多个评估指标(取决于折叠次数)，其平均值和标准偏差用于选择最终模型。

一旦选择了最终模型，它将在整个训练集上再次训练，并在测试集上进行评估，测试集在整个过程中保持不变。CV 是**理想的模型评估方法**。

一些标准的 CV 技术包括:

*   遗漏一个 CV (LOOCV):除了一个观察值之外，拟合和训练所有的模型
*   k-Fold CV:在`k-1`折叠数上拟合和训练模型，并在维持集上评估
*   重复 k-Fold CV:类似于 k-Fold CV，但是该过程重复指定的次数
*   分层 k-Fold CV:类似于 k-Fold CV，但这里的折叠是通过保留每个目标类的样本百分比来实现的。对不平衡数据有用
*   重复分层 k 倍 CV:重复 k 倍 CV 和分层 k 倍 CV 的组合

## 评估指标

有数十种模型评估指标，下面介绍了一些更广泛使用的指标:

**分类指标:**

*   **准确率:**正确预测占预测总数的比率。不适合不平衡的数据集
*   **精度:**真阳性与预测阳性总数的比率
*   **回忆，**也称为敏感度或真阳性率(TPR):真阳性与实际阳性数量的比率
*   **F-Score:** 一个单独的分数，用来同时衡量精度和召回率
*   受试者工作特性曲线下面积( **AUROC** ):总结 ROC 曲线信息的单个数字
*   布赖尔分数、科恩的卡帕统计等。

关于这些指标的更多细节，请参考我以前的文章。

**回归指标**

*   **平均绝对误差(MAE)** :实际值和预测值的平均绝对差值
*   **绝对误差中值**:实际值和预测值绝对差的中值
*   **均方误差(MSE)** :实际值和预测值的平方差的平均值
*   **均方根误差(RMSE):**MSE 的简单根

# 结论

我希望以上几点能在你的机器学习之旅中派上用场。

欢迎[联系我](https://www.finlyticshub.com)讨论任何与机器学习或数据和金融分析相关的问题。

继续学习！

# 参考

[1]沃尔波特，戴维&麦克雷迪，威廉。(1997).Macready，W.G .:最优化没有免费的午餐定理。进化计算汇刊 1(1)，67–82。进化计算。1.67–82.10.1109/4235.585893.