<html>
<head>
<title>Apache Spark with Kubernetes and Fast S3 Access</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阿帕奇火花与Kubernetes和快速S3访问</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-spark-with-kubernetes-and-fast-s3-access-27e64eb14e0f?source=collection_archive---------7-----------------------#2020-05-07">https://towardsdatascience.com/apache-spark-with-kubernetes-and-fast-s3-access-27e64eb14e0f?source=collection_archive---------7-----------------------#2020-05-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="da21" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了充分利用Apache Spark，我们需要两样东西:</p><ul class=""><li id="0efd" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated">存储数据的分布式存储器</li><li id="9b56" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">跨计算集群运行Spark执行器的调度程序</li></ul><p id="efec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">人们一直在以不同的方式在内部和云上实现这一点。对于内部部署，大多数使用Spark和Hadoop，尤其是HDFS用于存储，YARN用于调度。而在云中，大多数使用像亚马逊S3这样的对象存储作为存储，并使用一个单独的云原生服务，如亚马逊EMR或Databricks作为调度。如果我们可以在单个架构on-promise或云中使用Spark会怎么样？</p><p id="1f7a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">与库伯内特斯和S3一起进入火花。该架构的亮点包括:</p><ul class=""><li id="9dd0" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated">跨混合云运行Spark的单一架构。</li><li id="dd04" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">独立扩展、操作计算和存储。</li><li id="42a0" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">快速供应、部署和升级。</li><li id="ccd2" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">不需要Hadoop，使用和操作复杂。</li></ul><p id="7641" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这篇博客中，我将解释如何在Kubernetes上使用<a class="ae lc" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator" rel="noopener ugc nofollow" target="_blank"> Spark操作符</a>来运行Spark。我还将描述使用<a class="ae lc" href="https://hadoop.apache.org/docs/current/hadoop-aws/tools/hadoop-aws/index.html#Introducing_the_Hadoop_S3A_client." rel="noopener ugc nofollow" target="_blank"> S3A连接器</a>和<a class="ae lc" href="https://hadoop.apache.org/docs/r3.1.1/hadoop-aws/tools/hadoop-aws/committer_architecture.html" rel="noopener ugc nofollow" target="_blank"> S3A提交器</a>的快速S3数据访问的配置。这种架构既适用于云对象存储，也适用于本地S3兼容对象存储，如<a class="ae lc" href="https://www.purestorage.com/products/flashblade.html" rel="noopener ugc nofollow" target="_blank"> FlashBlade S3 </a>。</p><h1 id="0832" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">安装Spark Kubernetes操作器</h1><p id="34f9" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">按照本<a class="ae lc" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/quick-start-guide.md" rel="noopener ugc nofollow" target="_blank">快速入门指南</a>安装操作器。确保在安装中启用了webhook。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="7d31" class="mp le it ml b gy mq mr l ms mt">helm repo add incubator <a class="ae lc" href="http://storage.googleapis.com/kubernetes-charts-incubator" rel="noopener ugc nofollow" target="_blank">http://storage.googleapis.com/kubernetes-charts-incubator</a></span><span id="998d" class="mp le it ml b gy mu mr l ms mt">helm install incubator/sparkoperator --namespace spark-operator --set enableWebhook=true</span></pre><p id="cb47" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用这个<a class="ae lc" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/manifest/spark-rbac.yaml" rel="noopener ugc nofollow" target="_blank">清单</a>在Kubernetes默认名称空间中创建spark服务帐户和roll绑定。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="2a8e" class="mp le it ml b gy mq mr l ms mt">kubectl create -f manifest/spark-rbac.yaml</span></pre><p id="666f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">运行Spark Pi示例来测试安装。这将在Kubernetes中创建两个Spark pods:一个用于驱动程序，另一个用于执行程序。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="3639" class="mp le it ml b gy mq mr l ms mt">kubectl apply -f examples/spark-pi.yaml</span></pre><h1 id="b2f0" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">使用S3A连接器在S3访问数据</h1><p id="1192" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">多亏了Spark操作者，通过几个命令，我能够部署一个简单的Spark作业在Kubernetes上运行。我的下一个任务是在我的Spark工作中访问S3的数据。Hadoop的<a class="ae lc" href="https://hadoop.apache.org/docs/current/hadoop-aws/tools/hadoop-aws/index.html#Introducing_the_Hadoop_S3A_client." rel="noopener ugc nofollow" target="_blank"> S3A连接器</a>针对亚马逊S3和兼容的对象存储实现(包括FlashBlade S3)提供高性能I/O。</p><h2 id="36cb" class="mp le it bd lf mv mw dn lj mx my dp ln kb mz na lr kf nb nc lv kj nd ne lz nf bi translated">使用最新的S3A连接器构建Docker映像</h2><p id="a436" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">Spark Operator使用来自Google Cloud的预建Spark docker映像。但是，该图像不包括S3A连接器。虽然可以定制和添加S3A，但默认的Spark映像是针对Hadoop 2.7构建的，众所周知，Hadoop 2.7的S3A实现效率低且速度慢。所以我决定用Spark和最新的S3A连接器构建自己的Docker映像。</p><p id="e58c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将省略构建过程的细节，因为它很简单，但关键是使用预构建的Spark-without-Hadoop二进制文件和用户提供的Hadoop。我的Docker文件可以在<a class="ae lc" href="https://github.com/uprush/kube-spark/blob/master/docker/spark.Dockerfile" rel="noopener ugc nofollow" target="_blank"> my Github </a>上找到。</p><p id="a9a0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我的Docker映像包含Spark 2.4.5、Hadoop 3.2.1和最新的S3A，可从Docker Hub获得:</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="5ea8" class="mp le it ml b gy mq mr l ms mt">docker pull uprush/apache-spark:2.4.5</span></pre><h2 id="6238" class="mp le it bd lf mv mw dn lj mx my dp ln kb mz na lr kf nb nc lv kj nd ne lz nf bi translated">S3A连接器配置</h2><p id="7d29" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">Spark在S3访问数据的最低S3A配置如下:</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="481a" class="mp le it ml b gy mq mr l ms mt">"spark.hadoop.fs.s3a.endpoint": "192.168.170.12"<br/>"spark.hadoop.fs.s3a.access.key": "S3_ACCESS_KEY"<br/>"spark.hadoop.fs.s3a.secret.key": "S3_SECRET_KEY"<br/>"spark.hadoop.fs.s3a.connection.ssl.enabled": "false"</span></pre><p id="4b58" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在常规的Spark集群中，如果运行Hadoop，这将放在<code class="fe ng nh ni ml b">spark-default.conf,</code>或<code class="fe ng nh ni ml b">core-site.xml</code>文件中。对于Spark操作符，它被配置在应用程序YAML文件的<code class="fe ng nh ni ml b">spec.sparkConf</code>部分下。参考<a class="ae lc" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/api-docs.md" rel="noopener ugc nofollow" target="_blank"> API文档</a>获取火花操作器API的完整描述。</p><h2 id="6227" class="mp le it bd lf mv mw dn lj mx my dp ln kb mz na lr kf nb nc lv kj nd ne lz nf bi translated">火花和S3:爱狗人士的例子</h2><p id="dd40" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">一个工作示例是展示其工作原理的最佳方式。这里有一个<a class="ae lc" href="https://github.com/uprush/kube-spark/blob/master/doglover/src/main/scala/com/uprush/example/DogLover.scala" rel="noopener ugc nofollow" target="_blank">示例代码</a>，用于在S3从名为DogLover的Spark程序中读写数据。我使用twitter API从twitter上收集了爱狗人士的推文，并将它们作为JSON文件存储在FlashBlade的S3桶中。DogLover Spark程序是一个简单的ETL作业，它从S3读取JSON文件，使用Spark Dataframe进行ETL，并将结果作为Parquet文件写回S3，所有这些都通过S3A连接器完成。</p><p id="50ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了管理Kubernetes中Spark应用程序的生命周期，Spark操作者不允许客户直接使用<code class="fe ng nh ni ml b">spark-submit</code>来运行作业。相反，我将jar文件上传到S3，在我的<code class="fe ng nh ni ml b">doglover.yaml</code> spec文件中，我让Spark操作员从那里下载并在Kubernetes上运行程序。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="d808" class="mp le it ml b gy mq mr l ms mt">spec:<br/>  type: Scala<br/>  mode: cluster<br/>  image: "uprush/apache-spark:2.4.5"<br/>  imagePullPolicy: Always<br/>  mainClass: com.uprush.example.DogLover<br/>  mainApplicationFile: "s3a://deephub/doglover/doglover_2.12-0.1.0-SNAPSHOT.jar"<br/>  sparkVersion: "2.4.5"</span></pre><p id="9a1b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我可以像这样提交Spark作业:</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="ec04" class="mp le it ml b gy mq mr l ms mt">kubectl create -f doglover.yaml</span></pre><p id="503a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">几秒钟后，我的Spark作业在Kubernetes上运行。</p><figure class="mg mh mi mj gt nk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nj"><img src="../Images/b1bafce70f4aa571fa9b45cf64f22b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mcp0TDbHOSGDKN_cI1Y6pg.png"/></div></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">在Kubernetes上运行的Spark作业</p></figure><p id="d799" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦作业完成，我们应该在输出S3目录中看到一个零字节的<code class="fe ng nh ni ml b">_SUCCESS</code>文件和多个拼花文件。</p><p id="a491" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我的建筑看起来是这样的:</p><figure class="mg mh mi mj gt nk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nv"><img src="../Images/5d412ab92e407af3c5584ae997bfed2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtk4D7FjQawO1UaCsHRZEg.png"/></div></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">阿帕奇与库伯内特和S3的火花</p></figure><p id="cc42" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我看来，这是一种更好的提交Spark作业的方式，因为它可以从任何可用的Kubernetes客户端提交。它让我的工作更少依赖于基础设施，因此更便于携带。例如，要在AWS中运行相同的作业，我可以首先使用<a class="ae lc" href="https://www.purestorage.com/docs.html?item=/type/pdf/subtype/doc/path/content/dam/pdf/en/solution-briefs/sb-improve-fast-object-with-replication.pdf" rel="noopener ugc nofollow" target="_blank"> FlashBlade对象复制</a>将我的数据从FlashBlade S3复制到亚马逊S3。然后，我可以在AWS cloud的Kubernetes集群中以同样的方式轻松运行同样的Spark作业。</p><h1 id="0836" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">快速S3与S3A提交者一起写作</h1><p id="da16" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">当使用S3时，Spark依靠Hadoop输出提交器将输出可靠地写入S3对象存储。传统的FileOutputCommitter是为HDFS设计的，因此当与S3一起使用时，它被认为是低效、缓慢和不太可靠的，因为它依赖于原子的“重命名”HDFS操作，而这对于对象存储是不可用的。在Hadoop 3中，新的“零重命名”S3A提交器通过利用云原生S3特性来解决这些问题。查看更多关于<a class="ae lc" href="https://hadoop.apache.org/docs/r3.1.1/hadoop-aws/tools/hadoop-aws/committers.html" rel="noopener ugc nofollow" target="_blank">与S3A提交者一起将工作提交给S3的信息</a>。</p><p id="fb06" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">网飞贡献了一个名为<a class="ae lc" href="https://hadoop.apache.org/docs/r3.1.1/hadoop-aws/tools/hadoop-aws/committers.html#The_Staging_Committer" rel="noopener ugc nofollow" target="_blank"> Staging Committer </a>的S3A committer，它有许多吸引人的特性</p><ul class=""><li id="7940" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated">对目标对象存储没有任何要求。</li><li id="ae42" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">已知有效。</li></ul><p id="d4aa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">提交器将任务输出写入本地文件系统上一个名为任务尝试目录的临时目录。在任务提交时，提交者枚举任务尝试目录中的文件。使用<a class="ae lc" href="http://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html" rel="noopener ugc nofollow" target="_blank">多部分上传API </a>将每个文件上传到S3。提交上传所需的信息保存在HDFS暂存目录中，并通过该协议提交:当作业提交时，成功任务的未决上传部分将全部提交。</p><p id="c1a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Kubernetes上Spark的最低S3A阶段提交器配置(不含HDFS):</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="386c" class="mp le it ml b gy mq mr l ms mt">"spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a":"org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory"<br/>"spark.hadoop.fs.s3a.committer.name": "directory"<br/>"spark.sql.sources.commitProtocolClass": "org.apache.spark.internal.io.cloud.PathOutputCommitProtocol"<br/>"spark.sql.parquet.output.committer.class": "org.apache.spark.internal.io.cloud.BindingParquetOutputCommitter"</span></pre><h1 id="3fa6" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">S3A登台提交器的永久卷</h1><p id="13e5" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">事实上，暂存目录不一定要在HDFS，它也可以是所有Spark pods共享的NFS卷。在我的情况下，我使用NFS，因为我不想有任何HDFS依赖。</p><p id="27ca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过使用<a class="ae lc" href="https://www.purestorage.com/solutions/infrastructure/containers.html" rel="noopener ugc nofollow" target="_blank">Pure Service Orchestrator(PSO)</a>，创建一个分段PV并将其安装到所有Spark pods很容易。</p><p id="eeed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要将FlashBlade NFS用作PV，请创建一个<code class="fe ng nh ni ml b">staging-pvc.yaml</code>规范文件并将存储类指定给<code class="fe ng nh ni ml b">pure-file</code>。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="d9e1" class="mp le it ml b gy mq mr l ms mt">apiVersion: v1<br/>kind: PersistentVolumeClaim<br/>metadata:<br/>  name: data-staging-share<br/>spec:<br/>  accessModes:<br/>    - ReadWriteMany<br/>  resources:<br/>    requests:<br/>      storage: 1Ti<br/>  storageClassName: <strong class="ml iu">pure-file</strong></span></pre><p id="05a2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">应用等级库文件创建PVC。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="e79c" class="mp le it ml b gy mq mr l ms mt">kubectl create -f staging-pvc.yaml</span></pre><p id="6a69" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我创建一个PV，并将其安装到提交者工作目录下的所有Spark pods中，在我的例子中是<code class="fe ng nh ni ml b">/home/spark/tmp</code>。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="a925" class="mp le it ml b gy mq mr l ms mt">spec:<br/>  volumes:<br/>    - name: "staging-vol"<br/>      persistentVolumeClaim:<br/>        claimName: data-staging-share<br/>  driver:<br/>    volumeMounts:<br/>      - name: "staging-vol"<br/>        mountPath: "/home/spark/tmp"<br/>  executor:<br/>    instances: 2<br/>    volumeMounts:<br/>      - name: "staging-vol"<br/>        mountPath: "/home/spark/tmp"</span></pre><p id="82fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，我配置S3A来使用这个PV。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="1024" class="mp le it ml b gy mq mr l ms mt">"spark.hadoop.fs.s3a.committer.tmp.path": "file:///home/spark/tmp/staging"</span></pre><h1 id="62f8" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">缓冲目录的永久卷</h1><p id="ad25" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">这不是必需的，但是通常最好使用PV作为S3A提交者的缓冲区目录。缓冲区目录是提交者正在写入的数据的本地文件系统目录。因为暂存提交器将其输出写入本地文件系统，并且仅在任务提交时上传数据，所以确保有足够的本地存储空间来存储主机上运行的所有未提交任务生成的输出非常重要。小型主机/虚拟机可能会耗尽磁盘空间。为了避免这种情况，我将S3A配置为对缓冲区目录使用与上面相同的PV。即使是远程存储，这里的性能也没有问题，因为FlashBlade非常快。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="0abe" class="mp le it ml b gy mq mr l ms mt">"spark.hadoop.fs.s3a.buffer.dir": "/home/spark/tmp/buffer"</span></pre><p id="62da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有了这些，我可以使用高效、快速和可靠的S3A staging committer将数据从Kubernetes上运行的Spark写入S3。</p><h2 id="422d" class="mp le it bd lf mv mw dn lj mx my dp ln kb mz na lr kf nb nc lv kj nd ne lz nf bi translated">S3A提交者的爱狗者示例</h2><p id="090f" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">通过以上设置，我的架构变为:</p><figure class="mg mh mi mj gt nk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nw"><img src="../Images/7a7d4920a8f7954dafb82bc6433f2bc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FjL8HmU-UslZkjgDQePCeQ.png"/></div></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">Apache与Kubernetes和S3A Committer的火花</p></figure><p id="9168" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将以上所有内容放入<a class="ae lc" href="https://github.com/uprush/kube-spark/blob/master/doglover.yaml" rel="noopener ugc nofollow" target="_blank"> doglover.yaml </a> spec文件，重新运行作业。与之前不同的是，这次作业创建的<code class="fe ng nh ni ml b">_SUCCESS</code>文件不是零字节。它包含来自S3A提交器的指标和计数器。</p><pre class="mg mh mi mj gt mk ml mm mn aw mo bi"><span id="9147" class="mp le it ml b gy mq mr l ms mt">cat _SUCCESS<br/>{<br/>  "name" : "org.apache.hadoop.fs.s3a.commit.files.SuccessData/1",<br/>  "timestamp" : 1588673361792,<br/>  "date" : "Tue May 05 10:09:21 UTC 2020",<br/>  "hostname" : "doglover-driver",<br/>  "committer" : "directory",<br/>  "description" : "Task committer attempt_20200505100916_0000_m_000000_0",<br/>  "metrics" : {<br/>    "stream_write_block_uploads" : 0,<br/>    "files_created" : 1,<br/>...</span></pre><p id="1dfe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这表明S3A提交器的配置是正确的，Spark可以更有效地写S3。请参考<a class="ae lc" href="https://www.slideshare.net/uprush/hive-sparks3acommitterhbasenfs" rel="noopener ugc nofollow" target="_blank">我的卡片组</a>了解S3A提交者及其表演角色的详细信息。</p><h1 id="580e" class="ld le it bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">结论</h1><p id="634d" class="pw-post-body-paragraph jq jr it js b jt mb jv jw jx mc jz ka kb md kd ke kf me kh ki kj mf kl km kn im bi translated">通过Kubernetes上的Spark，并通过将数据放入S3，我能够以一种可移植的方式轻松快速地上下旋转Spark jobs。我还能够在同一个Kubernetes集群中使用相同的FlashBlade存储运行我的Spark作业以及许多其他应用程序，如<a class="ae lc" href="https://medium.com/swlh/presto-with-kubernetes-and-s3-deployment-4e262849244a" rel="noopener"> Presto </a>和<a class="ae lc" href="https://medium.com/swlh/apache-kafka-with-kubernetes-provision-and-performance-81c61d26211c" rel="noopener"> Apache Kafka </a>。我不需要为所有这些管理Hadoop集群。Kubernetes、FlashBlade和PSO共同带来了一个简单、可扩展和高性能的分解解决方案，用于运行现代分析系统，如Spark like a service。</p><p id="d4de" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将Spark与Kubernetes和S3一起使用的好处肯定是巨大的，但是，它也有局限性。这种架构非常适合ETL批处理等一次性工作负载类型。虽然，对于商业智能(BI)和笔记本后端之类的东西来说，它可能不是最好的Spark架构，因为我找不到一种简单的方法来通过Spark操作符保持Thrift服务器或Spark会话运行。但是我知道在Kubernetes上有更好的方法来实现这些，比如Spark和其他解决方案。敬请关注。</p><p id="d908" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">只需要一点火花！</p></div></div>    
</body>
</html>