<html>
<head>
<title>Detecting Politically Biased Phrases from U.S. Senators with Natural Language Processing (Tutorial)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用自然语言处理检测来自美国参议员的带有政治偏见的短语(教程)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-politically-biased-phrases-from-u-s-senators-with-natural-language-processing-tutorial-d6273211d331?source=collection_archive---------70-----------------------#2020-06-15">https://towardsdatascience.com/detecting-politically-biased-phrases-from-u-s-senators-with-natural-language-processing-tutorial-d6273211d331?source=collection_archive---------70-----------------------#2020-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="eaef" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">气候危机、劳动人民和负担得起的健康？还是共产主义者，自由主义者，堕胎？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2b076eb85bd9dd3c3a109e37da6c3868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D3p84liTlbbLfzAcNhjssg.png"/></div></div></figure><p id="78b2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">早在3月份，我观察了2020年疫情选举前的投票模式，并将其与相对两党对医改法案的投票进行了比较。现在，新冠肺炎疫情已经开展了几个月，其他事件正在成为焦点——即反对警察暴行和种族不公正的示威游行。此外，我们离共和党和民主党全国代表大会只有几个月的时间，选举随后就要到来。那么，政治家们在谈论什么呢？</p><p id="6316" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了掌握这一点，我决定用VoteSmart.org的<a class="ae lq" href="https://justfacts.votesmart.org" rel="noopener ugc nofollow" target="_blank"/>(我从T4的一篇研究论文中得到这个想法)来看看政治演讲，并看看党派短语。帖子将按如下方式进行:</p><ol class=""><li id="edb5" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">集合语料库</li><li id="0950" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">提取常用短语</li><li id="ed40" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">衡量政治两极化短语</li></ol><h2 id="0bd2" class="mf mg it bd mh mi mj dn mk ml mm dp mn ld mo mp mq lh mr ms mt ll mu mv mw mx bi translated">步骤1:集合语料库</h2><p id="1696" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">我从一个维护良好的数据集开始，这个数据集包含国会中的每个人，其中包含一个链接到他们的投票智能页面的ID。为了便于阅读，我的目标是为每位立法者制作一个文件夹，其中包含他们所有发言的文本文件。我提到的研究论文使用了几种类型的演讲，但我包括了从2020年1月开始的所有类型的公开声明。</p><p id="668c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本教程将侧重于文本分析，但<a class="ae lq" href="https://github.com/jackbandy/partisan-phrases/blob/master/generate_corpus.py" rel="noopener ugc nofollow" target="_blank">你可以在这里找到抓取语料库的代码</a>。我用它从VoteSmart收集了超过10，000条独特的声明和演讲(我删除了推文和重复的声明)，不过如果你对它进行微调，并不仅仅包括参议员，你还可以收集更多。以下是伯尼·桑德斯三月份接受CNN采访时的一段文字样本:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="97c5" class="mf mg it ne b gy ni nj l nk nl">COOPER: Now to our interview with Senator Bernie Sanders. He is campaigning in the Super Tuesday state of Minnesota.</span><span id="da1f" class="mf mg it ne b gy nm nj l nk nl">Senator Sanders, thanks for being with us. You just heard Mayor Buttigieg endorsing Vice President Biden. Klobuchar is expected to do the same tonight, as is Beto O'Rourke. How does the consolidation of the moderate vote affect your plans moving forward, especially since Senator Warren shows no signs of getting out?</span><span id="6a57" class="mf mg it ne b gy nm nj l nk nl">SEN. BERNIE SANDERS (D-VT), PRESIDENTIAL CANDIDATE: Well, Anderson, I think, as you know, from day one we have been taking on the establishment, whether it is the corporate establishment, you know, Wall Street, the drug companies, the insurance companies, the fossil fuel industry, or the political establishment.</span><span id="f3d1" class="mf mg it ne b gy nm nj l nk nl">And let me be very clear, it is no surprise they do not want me to become president because our administration will transform this country to create an economy and a government that works for all of the people, not just the 1 percent. It will not be the same old same old.</span><span id="bf3b" class="mf mg it ne b gy nm nj l nk nl">...</span></pre><p id="e057" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是有组织的语料库的样子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/3cf08c48980b5042e94f4789bf89f9a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qkXhJKU0kl3yFPsYJV_k1Q.png"/></div></div></figure><h2 id="2133" class="mf mg it bd mh mi mj dn mk ml mm dp mn ld mo mp mq lh mr ms mt ll mu mv mw mx bi translated">步骤2:提取常用短语</h2><p id="77a9" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">下一步是通过将文本分割成标记来提取短语。我使用了<a class="ae lq" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn的令牌矢量器</a>，因为它有一些很棒的内置特性。下面是设置一切看起来有多简单:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="6b33" class="mf mg it ne b gy ni nj l nk nl">from sklearn.feature_extraction.text import CountVectorizer<br/>from nltk.corpus import stopwords</span><span id="e752" class="mf mg it ne b gy nm nj l nk nl">nltk_stop_words = stopwords.words('english')</span><span id="75f0" class="mf mg it ne b gy nm nj l nk nl">tf_vectorizer = CountVectorizer(max_df=0.8, min_df=50,<br/>    ngram_range = (1,2),<br/>    binary=True,<br/>    stop_words=nltk_stop_words)</span></pre><p id="d2b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">停用词(即<code class="fe no np nq ne b">nltk_stop_words</code>)有助于去除无信息的单词，常见的例子有“of”、“to”和“and”我使用NLTK的列表是因为scikit的内置列表有一些已知的问题。然后，<code class="fe no np nq ne b">tf_vectorizer</code> (tf代表“术语频率”)通过一些设置进行初始化:</p><ul class=""><li id="2ae4" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp nr lx ly lz bi translated"><code class="fe no np nq ne b">max_df=0.8</code>意味着排除出现在80%或更多文档中的短语(类似于停用词，它们不太可能提供信息，因为它们太常见了)</li><li id="b21a" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nr lx ly lz bi translated"><code class="fe no np nq ne b">min_df=50</code>意味着该词必须在语料库中出现至少50次才能被纳入分析(我使用50次，因为我提到的研究论文也是如此，尽管您可以尝试不同的临界值)</li><li id="a6e0" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nr lx ly lz bi translated"><code class="fe no np nq ne b">ngram_range=(1,2)</code>意味着包括一个单词和两个单词的短语(你可以很容易地将它设置为<code class="fe no np nq ne b">(1,3)</code>来包括三元组/三个单词的短语</li><li id="2af6" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nr lx ly lz bi translated"><code class="fe no np nq ne b">binary=True</code>表示只计算一个单词在给定文档中出现的次数(即0或1)，而不是精确计算它出现的次数(即0或1或2或3或…)</li><li id="49f2" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nr lx ly lz bi translated"><code class="fe no np nq ne b">stop_words=nltk_stop_words</code>插入前一行中设置的NLTK停用词表，这样就不包括“of”和“to”这样的词</li></ul><p id="9ced" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">使用文件I/O将文本放入列表后，<code class="fe no np nq ne b">tf_vectorizer</code>可以将文本转换成只有一行的短语矩阵:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="2e5d" class="mf mg it ne b gy ni nj l nk nl">term_frequencies = tf_vectorizer.fit_transform(texts_list)</span></pre><p id="da3b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，<code class="fe no np nq ne b">term_frequences</code>是一个矩阵，包含来自矢量器的每一项的计数。我们可以把它变成一个数据框架，让事情更直观，看到最常见的短语:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="b9ac" class="mf mg it ne b gy ni nj l nk nl">phrases_df = pd.DataFrame(data=tf_vectorizer.get_feature_names(),columns=['phrase'])</span><span id="8872" class="mf mg it ne b gy nm nj l nk nl">phrases_df['total_occurrences']=term_frequencies.sum(axis=0).T</span><span id="0934" class="mf mg it ne b gy nm nj l nk nl">phrases_df.sort_values(by='total_occurrences',ascending=False).head(20).to_csv('top_20_overall.csv',index=False)</span></pre><p id="d137" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">生成的csv文件如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><h2 id="3fe5" class="mf mg it bd mh mi mj dn mk ml mm dp mn ld mo mp mq lh mr ms mt ll mu mv mw mx bi translated">步骤3:衡量政治两极化短语</h2><p id="c0aa" class="pw-post-body-paragraph ku kv it kw b kx my ju kz la mz jx lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">首先，我们需要将民主党和共和党撰写的文章分开，然后得到它们的词频矩阵。熊猫数据框架让这变得相当容易:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="cc90" class="mf mg it ne b gy ni nj l nk nl">dem_tfs = tf_vectorizer.transform(texts_df[texts_df.party=='Democrat'].text.tolist())</span><span id="790f" class="mf mg it ne b gy nm nj l nk nl">rep_tfs = tf_vectorizer.transform(texts_df[texts_df.party=='Republican'].text.tolist())</span></pre><p id="e7e8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在到了有趣的部分:找出哪些短语带有政治色彩。以下是解释这种方法的文章部分(关键公式突出显示):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/6bda3254eb9330ba904168df1cbeeb58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OVM-9HRixiAFDFYff4oZEw.png"/></div></div></figure><p id="754d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可能会注意到公式中只有两个变量:民主党人撰写的文本的短语概率和共和党人撰写的文本的短语概率。因此，为了计算党派偏见分数，我们只需要计算这两个概率，我将其简称为<code class="fe no np nq ne b">p_dem</code>和<code class="fe no np nq ne b">p_rep</code>。一旦我们有了这些，每个短语的偏差分数就是:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="b765" class="mf mg it ne b gy ni nj l nk nl">bias = (p_rep - p_dem) / (p_rep + p_dem)</span></pre><p id="1b51" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我使用了一个基本的概率度量:包含一个短语的文档数除以文档总数。有一些更复杂的方法来衡量概率，但根据我对论文的阅读，这可能是作者所做的。</p><p id="7f07" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">快到了！现在，我们只需要将偏见分数放入之前的<code class="fe no np nq ne b">phrases_df</code>数据框架中，然后我们就可以轻松地查看一些常见的党派短语。当我第一次运行这个时，一些名字短语，如“参议员哈里斯”和“参议员帕蒂”是最具党派性的——一个抄本的人工制品。为了解决这个问题，我做了一个过滤器，以确保至少有三名参议员使用党派短语:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="7c28" class="mf mg it ne b gy ni nj l nk nl">top_rep = phrases_df.sort_values(by='bias_score',ascending=False).head(100)</span><span id="fd07" class="mf mg it ne b gy nm nj l nk nl">top_rep['n_senators'] = top_rep.apply(lambda x: len(texts_df[texts_df.text.str.contains(x.phrase)].person.unique()),axis=1)</span><span id="2e1a" class="mf mg it ne b gy nm nj l nk nl">top_rep = top_rep[top_rep.n_senators &gt; 2]</span></pre><p id="ef97" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们终于可以看到党派短语了！你会注意到他们与党派议程保持一致，例如，民主党人谈论气候危机和医疗保健，而共和党人谈论堕胎。</p><p id="17bd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里是最倾向于民主党的短语，以及我们计算的分数和概率。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="595c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">和最倾向共和党的短语:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="d6ab" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有了这些短语和它们的偏见分数，你可以衡量推特、演讲、文章等的政治偏见。通过计算党派短语的频率:如果一篇文章大量谈论未出生者、自由主义者和共产主义者，它可能倾向于共和党，而如果一篇文章谈论气候危机、劳动人民和可负担的健康，它可能倾向于民主党。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><p id="d25f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="oc">感谢阅读！所有代码都是可用的，语料库也将很快可用，在这个资源库:</em></p><div class="od oe gp gr of og"><a href="https://github.com/jackbandy/partisan-phrases" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">流氓/党派用语</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">分析美国参议员的党派短语。有助于jackbandy/党派短语的发展，创造一个…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">github.com</p></div></div><div class="op l"><div class="oq l or os ot op ou ks og"/></div></div></a></div></div></div>    
</body>
</html>