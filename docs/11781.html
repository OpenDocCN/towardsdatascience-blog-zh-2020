<html>
<head>
<title>Sentiment analysis on the tweets about distance learning with TextBlob</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 TextBlob 的远程学习微博情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sentiment-analysis-on-the-tweets-about-distance-learning-with-textblob-cc73702b48bc?source=collection_archive---------14-----------------------#2020-08-15">https://towardsdatascience.com/sentiment-analysis-on-the-tweets-about-distance-learning-with-textblob-cc73702b48bc?source=collection_archive---------14-----------------------#2020-08-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6555" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">人们对远程学习有什么看法？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c440acc0b934b1912b82ce9704b15e94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1mW0rrnW-vVCYV-DXvGC4Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">故事横幅，作者图片</p></figure><p id="ffca" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">大家好，</p><p id="6eaa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Covid19 疫情在 2020 学年引入了远程学习。虽然有些人可以很容易适应，但有些人发现这种方法效率很低。如今，正在讨论重新开放学校的问题。大部分专家建议至少一个学期再上线。作为一名通过远程学习度过上学期的学生，我可以找到很多时间花在学习自然语言处理上。最后，我决定探究一下人们对远程学习的看法。</p><p id="2aed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我正在计划这个故事作为一个端到端的项目。我们将探索与远程学习相关的推文，以了解人们的意见(也称为意见挖掘)并发现事实。我将使用基于词典的方法来确定推文的极性(我稍后会解释)。TextBlob 将是我们实现这一目标的工具。我们还将建立一个机器学习模型，通过使用<strong class="la iu">伯努利</strong> <strong class="la iu">朴素贝叶斯分类器</strong>来预测推文的正面和负面。</p><p id="02fe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的工作流程如下:</p><ol class=""><li id="0e34" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">数据收集<br/> - Twitter API <br/> -使用<strong class="la iu"> <em class="md"> tweepy </em> </strong>检索推文</li><li id="d42b" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated">预处理和清理<br/> -删除重复项<br/> -数据类型转换<br/> -删除无信息列<br/> -去掉停用词、标签、标点和一两个字母的单词<br/> -对单词进行标记<br/> -应用词条化<br/> -词频-逆文档频率矢量化</li><li id="a67b" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated">探索性数据分析<br/> -可视化数据<br/> -比较字数<br/> -调查创建次数分布<br/> -调查推文位置<br/> -查看热门推文和最常用词<br/> -制作词云</li><li id="8227" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated">情感分析</li><li id="1665" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated">机器学习</li><li id="8cc5" class="lu lv it la b lb me le mf lh mg ll mh lp mi lt lz ma mb mc bi translated">摘要</li></ol><h2 id="4cb6" class="mj mk it bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">要求</h2><p id="3d92" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">开始之前，请确保以下库在您的工作区中可用。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="7fc6" class="mj mk it ni b gy nm nn l no np">pandas<br/>numpy<br/>matplotlib<br/>seaborn<br/>TextBlob<br/>wordcloud<br/>sklearn<br/>nltk<br/>pickle</span></pre><p id="a405" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以使用以下命令安装非内置库。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="348e" class="mj mk it ni b gy nm nn l no np">pip install pycountry<br/>pip install nltk<br/>pip install textblob<br/>pip install wordcloud<br/>pip install scikit-learn<br/>pip install pickle</span></pre><blockquote class="nq"><p id="808a" class="nr ns it bd nt nu nv nw nx ny nz lt dk translated">你可以在这里找到完整的代码<a class="ae oa" href="https://github.com/Bhasfe/distance_learning" rel="noopener ugc nofollow" target="_blank"/>。</p></blockquote></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="d2c7" class="oi mk it bd ml oj ok ol mo om on oo mr jz op ka mu kc oq kd mx kf or kg na os bi translated">1.数据采集</h1><p id="c6d3" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">首先，我们需要一个<strong class="la iu"> <em class="md"> Twitter 开发者账号</em> </strong>才能被允许使用<em class="md"> Twitter API </em>。你可以在这里得到账号<a class="ae oa" href="https://developer.twitter.com/" rel="noopener ugc nofollow" target="_blank">。审批可能需要几天时间。我已经完成了这些步骤。一旦我得到了这个帐户，我就创建了一个包含 API 信息的文本文件。它位于项目的向上目录中。文本文件的内容如下。如果你想使用它，你必须用你的信息替换它。</a></p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="9c7b" class="mj mk it ni b gy nm nn l no np">CONSUMER KEY=your_consumer_key<br/>CONSUMER KEY SECRET=your_consumer_key_secret<br/>ACCESS TOKEN=your_access_token<br/>ACCESS TOKEN SECRET=your_access_token_secret</span></pre><p id="3f57" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">之后我创建了一个名为<strong class="la iu"><em class="md"/></strong><a class="ae oa" href="https://github.com/Bhasfe/distance_learning/blob/master/get_tweets.py" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"><em class="md">get _ tweets . py</em></strong></a>的 py 文件来收集远程学习相关的推文(只有英文)。您可以在下面看到完整的代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="f8f1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面的代码搜索包含以下标签的推文</p><p id="a462" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">#远程教育，#在线学校，#在线教学，#虚拟学习，#在线教育，#远程教育，#在线课堂，#数字学习，#电子学习，#在线学习</p><p id="488b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">和以下关键字</p><p id="a10f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">“远程学习”、“在线教学”、“在线教育”、“在线课程”、“在线学期”、“远程课程”、“远程教育”、“在线课堂”、“电子学习”、“电子学习”</p><p id="04e7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它还过滤<em class="md">转发</em>以避免重复。</p><p id="bb43" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="md"> get_tweets </em>函数将检索到的 tweets 存储在临时<em class="md"> pandas 数据帧</em>中，并在<em class="md">输出</em>目录中保存为<em class="md"> CSV </em>文件。大约花了 40 个小时收集了<strong class="la iu"> <em class="md"> 202.645 </em> </strong>条推文。之后，它给了我以下文件</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/2297b1686040db16b4412139abaeda7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*evOGVadWPbq3eJloH3F_LQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出文件，按作者分类的图像</p></figure><p id="c82c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了将所有 CSV 文件连接成一个文件，我创建了包含以下代码的<em class="md"> concatenate.py </em>文件。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="1b72" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最终，我们有了<em class="md"> tweets_raw.csv </em>文件<em class="md">。</em>我们来看看它是什么样子的。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="9c9e" class="mj mk it ni b gy nm nn l no np"># Load the tweets<br/>tweets_raw = pd.read_csv("tweets_raw.csv")</span><span id="54e4" class="mj mk it ni b gy ow nn l no np"># Display the first five rows<br/>display(tweets_raw.head())</span><span id="7d2b" class="mj mk it ni b gy ow nn l no np"># Print the summary statistics<br/>print(tweets_raw.describe())</span><span id="6763" class="mj mk it ni b gy ow nn l no np"># Print the info<br/>print(tweets_raw.info())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/2b947c391a520af6970365eff8be4d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Zcd39dCYNU_Wlo_UXmpig.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/8c8f475969518e3b181d663856d13ff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*Q9JGOgp84ir3nvWslY3ocQ.png"/></div></figure><p id="116f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">乍一看，我们可以看到 DataFrame 中有 202.645 条推文，包括<em class="md">内容、位置、用户名、转发次数、收藏夹数、</em>和<em class="md">创建时间</em>特征。<em class="md">位置</em>栏也有一些缺失值。我们将在下一步处理它们。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="12f9" class="oi mk it bd ml oj ok ol mo om on oo mr jz op ka mu kc oq kd mx kf or kg na os bi translated">2.预处理和清洗</h1><p id="f01d" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">根据以上信息，<em class="md">未命名:0 </em>和<em class="md">未命名:0.1 </em>列对我们来说没有任何信息，因此我们将删除它们。在列创建的<em class="md">的数据类型也应该是 datetime。同样，如果有重复的推文，我们也需要删除它们。</em></p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="11a8" class="mj mk it ni b gy nm nn l no np"># We do not need first two columns. Let's drop them out.<br/>tweets_raw.drop(columns=["Unnamed: 0", "Unnamed: 0.1"], axis=1, inplace=True)</span><span id="fbd3" class="mj mk it ni b gy ow nn l no np"># Drop duplicated rows<br/>tweets_raw.drop_duplicates(inplace=True)</span><span id="500e" class="mj mk it ni b gy ow nn l no np"># Created at column's type should be datatime<br/>tweets_raw["Created at"] = pd.to_datetime(tweets_raw["Created at"])</span><span id="f380" class="mj mk it ni b gy ow nn l no np"># Print the info again<br/>print(tweets_raw.info())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/f0491e6545a579fc6dc2336ff793b29f.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*Yg_Cv4O9LSK3pU5tKP7TzA.png"/></div></figure><p id="2915" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">tweets 计数已经减少到<strong class="la iu"> 187.052 </strong>(有 15.593 个重复行)。“创建于”列的数据类型也更改为<strong class="la iu">数据时间 64【ns】</strong>。</p><p id="a36f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们整理一下推文的内容。我们需要去掉<em class="md">停用词</em>、<em class="md">标点符号</em>、<em class="md">标签</em>、<em class="md">提及</em>、<em class="md">链接</em>、<em class="md">一两个字母的单词</em>。我们还需要<em class="md">对推文</em>进行标记。</p><p id="a689" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">标记化</strong>就是把一个句子拆分成单词和标点符号。句子“这是一个例子。”可以像[“这个”、“是”、“一个”、“例”、“等”这样进行标记化。”]</p><p id="de73" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">停用词</strong>是常用的词，它们对句子的意义没有贡献，如“一个”、“一个”、“这个”、“在”、“在”等等。</p><p id="dac6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">词汇化</strong> <em class="md"> </em>就是把一个单词还原成它的词根形式的过程。这个根形式叫做一个<strong class="la iu"> <em class="md">引理</em> </strong>。比如单词<em class="md">running</em><em class="md">run</em>和<em class="md">run</em>的引理就是<em class="md"> run </em></p><p id="6c6a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们定义一个函数来完成所有这些操作。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="3175" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">函数调用后，我们的<em class="md">处理后的</em>列将如下所示。你可以看到推文被标记化了，它们不包含停用词、标签、链接和一两个字母的单词。我们还对它们进行了引理化操作。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/5ee9eaad87c894c7190da5791235f301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wJHw3MwWUB1DM1V5bENE3w.png"/></div></div></figure><p id="a1a0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们得到了我们想要的。不用担心<em class="md">学习</em>、<em class="md">在线</em>、<em class="md">教育</em>等词汇。我们稍后会处理它们。</p><p id="f0d5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在探索性数据分析中，推文长度和推文中的字数也可能是有趣的。让我们抓住他们！</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="e512" class="mj mk it ni b gy nm nn l no np"># Get the tweet lengths<br/>tweets_raw["Length"] = tweets_raw["Content"].str.len()</span><span id="632a" class="mj mk it ni b gy ow nn l no np"># Get the number of words in tweets<br/>tweets_raw["Words"] = tweets_raw["Content"].str.split().str.len()</span><span id="ae11" class="mj mk it ni b gy ow nn l no np"># Display the new columns<br/>display(tweets_raw[["Length", "Words"]])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/b79ab07e3603ea0fb94a1d2be7ff038a.png" data-original-src="https://miro.medium.com/v2/resize:fit:352/format:webp/1*gjEa2KXBECZE1lkZmumtwA.png"/></div></figure><p id="8a48" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意，我们没有使用经过<em class="md">处理的</em> tweets。</p><p id="0120" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">地点呢？</p><p id="a28d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们调用 tweets_raw  DataFrame <em class="md">、</em>的<em class="md"> info </em>函数<em class="md">时，我们看到在“Location”列中有一些缺失值。缺失的值显示为<strong class="la iu"> NaN </strong>。我们将用<em class="md">“未知”</em>标签来填充丢失的值。</em></p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="eb14" class="mj mk it ni b gy nm nn l no np"># Fill the missing values with unknown tag<br/>tweets_raw["Location"].fillna("unknown", inplace=True)</span></pre><p id="231d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们有多少独特的位置？</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="6214" class="mj mk it ni b gy nm nn l no np"># Print the unique locations and number of unique locations<br/>print("Unique Values:",tweets_raw["Location"].unique())<br/>print("Unique Value count:",len(tweets_raw["Location"].unique()))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/45ae895671fb9441eb7506d5d2ca4e42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*EPigz0B8ubio5ztqJgEAPA.png"/></div></figure><p id="99bd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出显示位置信息是混乱的。有 37.119 个唯一位置。我们需要按国家对它们进行分组。为了实现这一点，我们将使用 python 中的<strong class="la iu"> <em class="md"> pycountry </em> </strong>包。如果你有兴趣，你可以在这里找到进一步的信息<a class="ae oa" href="https://pypi.org/project/pycountry/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="9b7c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们定义一个名为<em class="md"> get_countries </em>的函数，它返回给定位置的国家代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/82722b56fc85ddd3d69a95be84e0195e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*zqK8hrWjkaE0rjrAGosXSA.png"/></div></figure><p id="2308" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">成功了！现在我们有 156 个独特的国家代码。我们将在探索性数据分析部分使用它们。</p><p id="7670" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在是时候对推文进行矢量化了。我们将使用<strong class="la iu"> <em class="md"> tf-idf(词频-逆文档词频)</em> </strong>矢量化。</p><p id="7035" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> Tf-idf(词频—逆词频)</strong>是一个统计概念，用于获取语料库中的词频。我们将使用 scikit-learn 的<em class="md">tfidf 矢量器</em>。矢量器将计算语料库中每个单词的权重，并返回一个 tf-idf 矩阵。您可以在此找到更多信息<a class="ae oa" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank"/></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/556c3cbefa283b31ac27fb77c40838ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/0*oacXK7VlaV2Usteq.png"/></div></figure><p id="43d4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="md"> td </em> =词频(j 中每个 I 出现的次数)<br/> <em class="md"> df </em> =文档频率<br/> <em class="md"> N </em> =文档数量<br/> <em class="md"> w </em> = tf-idf 对每个<em class="md"> i </em>和<em class="md"> j </em>(文档)的权重。</p><p id="8440" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于内存限制，我们将只选择前<em class="md"> 5000 个单词</em>进行 tf-idf 矢量化。您可以通过使用其他方法，如<em class="md">散列</em>来试验更多。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="d7f7" class="mj mk it ni b gy nm nn l no np"># Create our contextual stop words<br/>tfidf_stops = ["online","class","course","learning","learn",\<br/>"teach","teaching","distance","distancelearning","education",\<br/>"teacher","student","grade","classes","computer","onlineeducation",\ "onlinelearning", "school", "students","class","virtual","eschool",\ "virtuallearning", "educated", "educates", "teaches", "studies",\ "study", "semester", "elearning","teachers", "lecturer", "lecture",\ "amp","academic", "admission", "academician", "account", "action" \<br/>"add", "app", "announcement", "application", "adult", "classroom", "system", "video", "essay", "homework","work","assignment","paper",\ "get", "math", "project", "science", "physics", "lesson","courses",\ "assignments", "know", "instruction","email", "discussion","home",\ "college","exam""use","fall","term","proposal","one","review",\<br/>"proposal", "calculus", "search", "research", "algebra"]</span><span id="0cd7" class="mj mk it ni b gy ow nn l no np"># Initialize a Tf-idf Vectorizer<br/>vectorizer = TfidfVectorizer(max_features=5000, stop_words= tfidf_stops)</span><span id="1624" class="mj mk it ni b gy ow nn l no np"># Fit and transform the vectorizer<br/>tfidf_matrix = vectorizer.fit_transform(tweets_processed["Processed"])</span><span id="80a5" class="mj mk it ni b gy ow nn l no np"># Let's see what we have<br/>display(tfidf_matrix)</span><span id="4d24" class="mj mk it ni b gy ow nn l no np"># Create a DataFrame for tf-idf vectors and display the first rows<br/>tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns= vectorizer.get_feature_names())<br/>display(tfidf_df.head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/0510b20a4ca10f3f33b82b9cf0dbdfaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*XzyHPEPkW8xPieE5gaMmyw.png"/></div></figure><p id="bdb6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它返回给我们一个稀疏矩阵。你可以看看它下面的内容。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/c3519387ca64223a2e2654d7ced7a34f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y_9QNDzGZyzoJOX3iKCcAg.png"/></div></div></figure><p id="88c4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">毕竟，我们将新的数据帧保存为 CSV 文件，以便以后使用，而无需再次执行整个操作。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="8bb0" class="mj mk it ni b gy nm nn l no np"># Save the processed data as a csv file<br/>tweets_raw.to_csv("tweets_processed.csv")</span></pre><h1 id="2dc5" class="oi mk it bd ml oj ph ol mo om pi oo mr jz pj ka mu kc pk kd mx kf pl kg na os bi translated">3.探索性数据分析</h1><p id="fe95" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">探索性数据分析是数据科学项目不可或缺的一部分。只要我们理解我们的数据告诉我们什么，我们就可以建立我们的模型。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="a47c" class="mj mk it ni b gy nm nn l no np"># Load the processed DataFrame<br/>tweets_processed = pd.read_csv("tweets_processed.csv", parse_dates=["Created at"])</span></pre><p id="ed28" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，让我们看看数据集中最早和最新的 tweets 创建时间。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="920b" class="mj mk it ni b gy nm nn l no np"># Print the minimum datetime<br/>print("Since:",tweets_processed["Created at"].min())</span><span id="5471" class="mj mk it ni b gy ow nn l no np"># Print the maximum datetime<br/>print("Until",tweets_processed["Created at"].max())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/b8291b4aed171191873d268285abf772.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*jJsKXUJVLrrmuNNC9UNA_Q.png"/></div></figure><p id="fd79" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些推文是在 2020 年 7 月 23 日至 8 月 14 日之间创建的。创作时间呢？</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="b364" class="mj mk it ni b gy nm nn l no np"># Set the seaborn style<br/>sns.set()</span><span id="9389" class="mj mk it ni b gy ow nn l no np"># Plot the histogram of hours<br/>sns.distplot(tweets_processed["Created at"].dt.hour, bins=24)<br/>plt.title("Hourly Distribution of Tweets")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/c7994f34bb4bb4883ccde4d5b6905cce.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*BNj-UP8w3FvTg2VIEtGnYw.png"/></div></figure><p id="f757" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">直方图表明，大多数推文是在一天的 12 点至 17 点之间创建的。最受欢迎的时间是下午 15 点左右。</p><p id="fa0c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看我们已经处理过的位置。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="d341" class="mj mk it ni b gy nm nn l no np"># Print the value counts of Country column<br/>print(tweets_processed["Country"].value_counts())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/4d841be8937c058cc26920a7cb856637.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*__q0I6L565w0IC_9xWhRMA.png"/></div></figure><p id="a212" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显然，这些位置对我们来说是无信息的，因为我们有<strong class="la iu"> <em class="md"> 169.734 个未知的</em> </strong>位置。但我们仍然可以查看最热门的推特国家。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/4b0692a143ebc13f161f98cd4afc75ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K74Y9UTAJcXutt5Kt8mDew.png"/></div></div></figure><p id="b5a2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据上面的柱状图，<strong class="la iu"> <em class="md">美国</em></strong><strong class="la iu"><em class="md">英国</em></strong><strong class="la iu"><em class="md">印度</em> </strong>是我们数据集中排名前 3 的国家。</p><p id="c321" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们来看看最受欢迎的推文(就转发和收藏而言)。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="e8cf" class="mj mk it ni b gy nm nn l no np"># Display the most popular tweets<br/>display(tweets_processed.sort_values(by=["Favorites","Retweet-Count", ], axis=0, ascending=False)[["Content","Retweet-Count","Favorites"]].head(20))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/aaace7752770895db1a6039c7a2e74f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nMv8zTv4N4hbGdsZ4w_NTQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">热门推文，点击图片看更好</p></figure><p id="a885" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">推文中的常用词也能告诉我们很多。让我们从我们的 Tf-idf 矩阵中获取它们。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="910c" class="mj mk it ni b gy nm nn l no np"># Create a new DataFrame called frequencies<br/>frequencies = pd.DataFrame(tfidf_matrix.sum(axis=0).T,index=vectorizer.get_feature_names(),columns=['total frequency'])</span><span id="285c" class="mj mk it ni b gy ow nn l no np"># Display the most 20 frequent words<br/>display(frequencies.sort_values(by='total frequency',ascending=False).head(20))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/dc9af34441117feb0bf4932201c12355.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*B-z_iGpVZBmhGCCsAflEug.png"/></div></figure><p id="7321" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">文字云会更好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/5746496a895219eb51cefae180ef46c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*USehJUiENGck5DEINWi4gg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">文字云，作者图片</p></figure><p id="ff5d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显然，人们谈论的是<strong class="la iu">【付款】</strong>。<strong class="la iu"/>“求助”是使用频率最高的词之一。我们可以说人们正在大量寻求帮助:)</p><h1 id="a30a" class="oi mk it bd ml oj ph ol mo om pi oo mr jz pj ka mu kc pk kd mx kf pl kg na os bi translated"><strong class="ak"> 4。情绪分析</strong></h1><p id="d6f9" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">经过预处理和 EDA，我们终于可以专注于我们在这个项目的主要目标。我们将使用<strong class="la iu"> TextBlob </strong>来计算推文的情感特征，如<strong class="la iu"> <em class="md">极性</em> </strong>和<strong class="la iu"> <em class="md">主观性</em> </strong>。它通过使用预定义的单词分数给我们这些值。您可以查看<a class="ae oa" href="https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多信息。</p><p id="059b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="md">极性</em> </strong>是在<strong class="la iu"> -1 </strong> <strong class="la iu">到</strong> <strong class="la iu"> 1 </strong>之间变化的一个值。它向我们展示了给出的句子是<em class="md">正</em>还是<em class="md">负</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/87728e10b4e65a6554230ec938a8bd1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dB4JEe7kCH4fAc0lmdc7FA.png"/></div></div></figure><p id="fb0f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="md">主观性</em> </strong>是<strong class="la iu"> 0 到 1 </strong>之间的另一个值变化，它向我们表明句子是关于一个事实还是观点(客观还是主观)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/4da6b78261a8d3ac40f8de37f3291557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KUJd3SSsXca9rzOBgxW45w.png"/></div></div></figure><p id="3a4b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们用 TextBlob 计算极性和主观性得分</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/00d38793ecc2e348c87526317fdc41a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:358/format:webp/1*Aq49cfD6FPdxiRiscNkiMw.png"/></div></figure><p id="0f8b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们需要将极性分为积极的、中性的和消极的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/bcf7d067f88269d4edeea96edcf91651.png" data-original-src="https://miro.medium.com/v2/resize:fit:184/format:webp/1*IcY2l26NOiijHP6hEBtH8A.png"/></div></figure><p id="7fa3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们也可以像下面这样把它们数起来。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="830f" class="mj mk it ni b gy nm nn l no np"># Print the value counts of the Label column<br/>print(tweets_processed["Label"].value_counts())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi px"><img src="../Images/24d55e8281f017e8ed021e1c521d7c40.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*nhFIECth36o4eCRQn609yQ.png"/></div></figure><p id="04aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果和我预料的不一样。正面推文明显比负面多。</p><p id="9f94" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">到目前为止，我们将推文标记为积极、中立和消极。让我们仔细检查一下我们的发现。我将从标签数开始。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="d81a" class="mj mk it ni b gy nm nn l no np"># Change the datatype as "category"<br/>tweets_processed["Label"] = tweets_processed["Label"].astype("category")</span><span id="a1b7" class="mj mk it ni b gy ow nn l no np"># Visualize the Label counts<br/>sns.countplot(tweets_processed["Label"])<br/>plt.title("Label Counts")<br/>plt.show()</span><span id="6ed7" class="mj mk it ni b gy ow nn l no np"># Visualize the Polarity scores<br/>plt.figure(figsize = (10, 10)) <br/>sns.scatterplot(x="Polarity", y="Subjectivity", hue="Label", data=tweets_processed)<br/>plt.title("Subjectivity vs Polarity")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi py"><img src="../Images/c6edb9f6d9ac0206253d2a1f17ddb54a.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*wjRW-_mhr0X4vgyY5_ywww.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pz"><img src="../Images/d5f152d421759fdf66720cc17a15af3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*5MXGgkznuQUM7GoVOb-EGg.png"/></div></figure><p id="b8ac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于基于词典的分析并不总是可靠的，我们必须手动检查结果。让我们来看看极性得分最高/最低的热门(根据转发和收藏)推文。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="7c70" class="mj mk it ni b gy nm nn l no np"># Display the positive tweets<br/>display(tweets_processed.sort_values(by=["Polarity", "Retweet-Count", "Favorites"], axis=0, ascending=False)[["Content","Retweet-Count","Favorites","Polarity"]].head(20))</span><span id="a910" class="mj mk it ni b gy ow nn l no np"># Display the negative tweets<br/>display(tweets_processed.sort_values(by=["Polarity", "Retweet-Count", "Favorites"], axis=0, ascending=[True, False, False])[["Content","Retweet-Count","Favorites","Polarity"]].head(20))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qa"><img src="../Images/82241ed97b1e1e1400c4c24aa0b30879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PMMyRWW4JX3qmeO_3RwymQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">正面推文，点击图片看更好</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qb"><img src="../Images/5c70cf3a7e55daef5e216f72163d7c8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cHudnHVplKVAMp1o7IxT5A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">负面推文，，点击图片看得更清楚</p></figure><p id="eb0a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据上面的结果，TextBlob 已经正确地完成了它的工作！我们可以像上面那样为每个标签制作单词云。为此，我将定义一个函数。该函数将以一个数据帧和一个标签作为参数，用 tf-idf 矢量器对<strong class="la iu"> <em class="md">处理过的</em> </strong> tweets 进行矢量化。最后，它会为我们制作单词云。由于计算的限制，我们将只查看最受欢迎的 50 条推文。你可以用更多的数据来尝试。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><div class="kj kk kl km gt ab cb"><figure class="qc kn qd qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/8ba7ccf4170ed8cda47a9be8a6619bbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*9l8H7YImIPsbFMdrM_BKEw.png"/></div></figure><figure class="qc kn qd qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/c21d116a5781ba92010130a03a81f512.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*a1f5V-N0EixMgHJiuPF2ow.png"/></div></figure></div><p id="f60f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很明显，推特上负面消息的人发现远程学习很无聊，很可怕，很糟糕。另一方面，有些人喜欢远程学习的选择。</p><p id="d32a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来看看各国的正面和负面推文数量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/b16444615eb03593f635382c0e42d443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*gtkPBtn3PFZZ5JfnpC5TkA.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qj"><img src="../Images/b6715c2bf31c8506bd0b72609538beb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7zad5RUbJeIa_3h6UqJAqQ.png"/></div></div></figure><p id="8feb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">时间和推特的极性有什么关系吗？</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="88c0" class="mj mk it ni b gy nm nn l no np">positive = tweets_processed.loc[tweets_processed.Label=="Positive"]["Created at"].dt.hour<br/>negative = tweets_processed.loc[tweets_processed.Label=="Negative"]["Created at"].dt.hour</span><span id="22d6" class="mj mk it ni b gy ow nn l no np">plt.hist(positive, alpha=0.5, bins=24, label="Positive", density=True)<br/>plt.hist(negative, alpha=0.5, bins=24, label="Negative", density=True)<br/>plt.xlabel("Hour")<br/>plt.ylabel("PDF")<br/>plt.title("Hourly Distribution of Tweets")<br/>plt.legend(loc='upper right')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qk"><img src="../Images/3d0f1c2696efa13c181f1a959ec2e212.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*zgitkMrYGyD0qVA0EbIF-w.png"/></div></figure><p id="d2c9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面的直方图表明，时间和推文的极性之间没有关系。</p><p id="b19e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我想在这里结束我的探索，以保持这个故事简短。</p><h1 id="4738" class="oi mk it bd ml oj ph ol mo om pi oo mr jz pj ka mu kc pk kd mx kf pl kg na os bi translated">5.建立一个机器学习模型</h1><p id="11ba" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">我们根据极性分数给推文贴上了标签。让我们通过使用多项式朴素贝叶斯分类器来建立机器学习模型。我们将使用 tf-idf 向量作为特征，标签作为目标。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="022f" class="mj mk it ni b gy nm nn l no np"># Encode the labels<br/>le = LabelEncoder()<br/>tweets_processed["Label_enc"] = le.fit_transform(tweets_processed["Label"])</span><span id="c9dc" class="mj mk it ni b gy ow nn l no np"># Display the encoded labels<br/>display(tweets_processed[["Label_enc"]].head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ql"><img src="../Images/9fce1c5487ed284828a5bc9c09971027.png" data-original-src="https://miro.medium.com/v2/resize:fit:206/format:webp/1*wTo2xCOi3Lq-mzKzAkQ79g.png"/></div></figure><p id="4cdd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们已经对标签进行了编码。</p><p id="28c3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">“正”= 2 </strong></p><p id="a3a4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">“空档”= 1 </strong></p><p id="192c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">“负”= 0 </strong></p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="c8f3" class="mj mk it ni b gy nm nn l no np"># Select the features and the target<br/>X = tweets_processed['Processed']<br/>y = tweets_processed["Label_enc"]</span></pre><p id="3900" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们需要将数据分成训练集和测试集。由于我们的数据不平衡，我们将使用<em class="md"> train_test_split </em>的<strong class="la iu"> <em class="md">分层</em> </strong>参数。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="5b77" class="mj mk it ni b gy nm nn l no np">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34, stratify=y)</span></pre><p id="6cad" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们可以创建我们的模型。由于我们早期的 tf-idf 矢量器适合整个数据集，我们必须初始化一个新的。否则，我们的模型可以通过测试集进行学习。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="e29e" class="mj mk it ni b gy nm nn l no np"># Create the tf-idf vectorizer<br/>model_vectorizer = TfidfVectorizer()</span><span id="a379" class="mj mk it ni b gy ow nn l no np"># First fit the vectorizer with our training set<br/>tfidf_train = vectorizer.fit_transform(X_train)</span><span id="db08" class="mj mk it ni b gy ow nn l no np"># Now we can fit our test data with the same vectorizer<br/>tfidf_test = vectorizer.transform(X_test)</span><span id="6b5a" class="mj mk it ni b gy ow nn l no np"># Initialize the Bernoulli Naive Bayes classifier<br/>nb = BernoulliNB()</span><span id="575e" class="mj mk it ni b gy ow nn l no np"># Fit the model<br/>nb.fit(tfidf_train, y_train)</span><span id="2112" class="mj mk it ni b gy ow nn l no np"># Print the accuracy score<br/>best_accuracy = cross_val_score(nb, tfidf_test, y_test, cv=10, scoring='accuracy').max()<br/>print("Accuracy:",best_accuracy)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qm"><img src="../Images/4860e7292ea192b2cf1f40d118720273.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/1*-HEPSTwV5D5S6Ira0SV4Tg.png"/></div></figure><p id="9b79" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然我们没有做任何超参数调优，但是精度还不错。我们来看看混淆矩阵和分类报告。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="81c4" class="mj mk it ni b gy nm nn l no np"># Predict the labels<br/>y_pred = nb.predict(tfidf_test)</span><span id="6dd0" class="mj mk it ni b gy ow nn l no np"># Print the Confusion Matrix<br/>cm = confusion_matrix(y_test, y_pred)<br/>print("Confusion Matrix\n")<br/>print(cm)</span><span id="3492" class="mj mk it ni b gy ow nn l no np"># Print the Classification Report<br/>cr = classification_report(y_test, y_pred)<br/>print("\n\nClassification Report\n")<br/>print(cr)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qn"><img src="../Images/445d942b020d28e496842be7ed15cd06.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*XMQxLFyGmHw340bLYekP_g.png"/></div></figure><p id="36e2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有很多工作要做，以提高模型在负面推文中的表现，但我把它留给另一个故事:)</p><p id="fcf5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们可以保存模型以备后用。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="1f46" class="mj mk it ni b gy nm nn l no np"># Save the model<br/>pickle.dump(nb, open("model.pkl", 'wb'))</span></pre></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="9dc6" class="oi mk it bd ml oj ok ol mo om on oo mr jz op ka mu kc oq kd mx kf or kg na os bi translated">摘要</h1><p id="16d2" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">综上，让我们记住我们一起做的事。首先，我们使用 Twitter API 和<em class="md"> tweepy </em>库收集了关于远程学习的推文。之后，我们对它们应用了常见的预处理步骤，比如标记化、词条化、删除停用词等等。我们通过使用汇总统计和可视化工具来研究数据。毕竟，我们使用 TextBlob 来获得推文的极性分数，并解释了我们的发现。因此，我们发现，在我们的数据集中，大多数推文对远程学习持积极态度。不要忘记，我们只使用了基于词典的方法，这是不太可靠的。希望这个故事对你理解推文的情感分析有所帮助。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="7197" class="oi mk it bd ml oj ok ol mo om on oo mr jz op ka mu kc oq kd mx kf or kg na os bi translated"><strong class="ak">参考</strong></h1><p id="9beb" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated"><strong class="la iu">【1】</strong><em class="md">(教程)在 Python 中简化情感分析</em>。(未注明)。数据营社区。<a class="ae oa" href="https://www.datacamp.com/community/tutorials/simplifying-sentiment-analysis-python" rel="noopener ugc nofollow" target="_blank">https://www . data camp . com/community/tutorials/simplizing-情操-分析-python </a></p><p id="597e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">【2】</strong>李，J. (2020 年 5 月 19 日)。<em class="md"> Twitter 情感分析| NLP |文本分析</em>。中等。<a class="ae oa" rel="noopener" target="_blank" href="/twitter-sentiment-analysis-nlp-text-analytics-b7b296d71fce">https://towards data science . com/Twitter-情操-分析-NLP-文本-分析-b7b296d71fce </a></p><p id="6a3e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">【3】</strong>李，c .(2019 . 9 . 20)。<em class="md">用于品牌改进和话题跟踪的实时推特情感分析(第 1/3 章)</em>。中等。<a class="ae oa" rel="noopener" target="_blank" href="/real-time-twitter-sentiment-analysis-for-brand-improvement-and-topic-tracking-chapter-1-3-e02f7652d8ff">https://towards data science . com/real-time-Twitter-opinion-analysis-for-brand-improvement-and-topic-tracking-chapter-1-3-e02f 7652 D8 ff</a></p><p id="c0f1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">【4】</strong>randers 112358。(2020 年 7 月 18 日)。<em class="md">如何用 Python 对一个 Twitter 账号做情感分析</em>。中等。<a class="ae oa" href="https://medium.com/better-programming/twitter-sentiment-analysis-15d8892c0082" rel="noopener">https://medium . com/better-programming/Twitter-情操-分析-15d8892c0082 </a></p><p id="9dc8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">【5】</strong><em class="md">Python 中的词干化和词条化</em>。(未注明)。数据营社区。<a class="ae oa" href="https://www.datacamp.com/community/tutorials/stemming-lemmatization-python" rel="noopener ugc nofollow" target="_blank">https://www . data camp . com/community/tutorials/stemming-lemma tization-python</a></p></div></div>    
</body>
</html>