<html>
<head>
<title>Better Data Loading: 20x PyTorch Speed-Up for Tabular Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">更好的数据加载:表格数据的PyTorch速度提高了20倍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/better-data-loading-20x-pytorch-speed-up-for-tabular-data-e264b9e34352?source=collection_archive---------10-----------------------#2020-04-28">https://towardsdatascience.com/better-data-loading-20x-pytorch-speed-up-for-tabular-data-e264b9e34352?source=collection_archive---------10-----------------------#2020-04-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d4e3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个简单的改变可以大大加快你的深度学习训练</h2></div><h1 id="d465" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">深度学习:对速度的需求</h1><p id="cf57" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在训练深度学习模型时，性能至关重要。数据集可能非常庞大，低效的训练意味着更慢的研究迭代、更少的超参数优化时间、更长的部署周期和更高的计算成本。</p><p id="3028" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">尽管如此，很难证明投入太多时间来加快速度是合理的，因为有许多潜在的死胡同需要探索。不过还好有一些速战速决的可用！</p><p id="bcb4" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我将向您展示我在PyTorch中对表格数据的数据加载器所做的一个简单更改如何将训练速度提高了20倍,而没有对训练循环做任何更改！只是PyTorch标准数据加载器的简单替代。对于我看到的模型，16分钟的迭代时间减少到了40秒！</p><p id="aef6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">并且不需要安装任何新的包，不需要进行任何底层代码更改，也不需要更改任何超参数。</p><h1 id="83be" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">研究/行业脱节</h1><p id="4b21" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在监督学习中，快速浏览一下<a class="ae mb" href="https://www.arxiv-sanity.com/top" rel="noopener ugc nofollow" target="_blank"> Arxiv-Sanity </a>告诉我们，目前的顶级研究论文要么是关于图像的(无论是分类还是生成的GANs)，要么是文本的(主要是BERT的变体)。这些在传统机器学习没有机会的领域非常棒——但需要专业知识和大量的研究预算才能很好地执行。</p><p id="2f09" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">另一方面，许多公司持有的大部分数据已经以漂亮的表格形式存在于数据库中。一些例子包括终身价值评估、点击优化和金融时间序列数据的客户详细信息。</p><h1 id="6830" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">表格数据有什么特别之处？</h1><p id="d82d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">那么，为什么研究和工业之间的裂痕对我们来说是个问题呢？嗯，最先进的文本/视觉研究人员的需求与那些在表格数据集上进行监督学习的研究人员的需求非常不同。</p><p id="a851" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">表格形式的数据(即数据库表、Pandas数据帧、NumPy数组或PyTorch张量)在几个方面使事情变得更简单:</p><ol class=""><li id="799a" class="mc md it lc b ld lw lg lx lj me ln mf lr mg lv mh mi mj mk bi translated">通过<em class="ml">切片</em>，可以从连续的内存块中获取训练批次。</li><li id="fbca" class="mc md it lc b ld mm lg mn lj mo ln mp lr mq lv mh mi mj mk bi translated">没有每个样本的预处理成本，允许我们充分利用<a class="ae mb" href="https://arxiv.org/pdf/1803.09820.pdf" rel="noopener ugc nofollow" target="_blank">大批量训练</a>来获得额外的速度(记住要提高学习率，这样我们就不会过度适应！).</li><li id="e3b8" class="mc md it lc b ld mm lg mn lj mo ln mp lr mq lv mh mi mj mk bi translated">如果你的数据集足够小，它可以一次性加载到GPU上。(虽然这在技术上对于文本/视觉数据也是可能的，但是那里的数据集往往更大，并且一些预处理步骤在CPU上更容易完成)。</li></ol><p id="9a5c" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">这些优化对于表格数据是可行的，而对于文本/视觉数据是不可行的，因为有两个主要的不同之处:模型和数据。</p><p id="5c17" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">模型:</strong>视觉研究倾向于使用大型深度卷积神经网络(CNNs文本倾向于使用大型递归神经网络(rnn)或变压器；但是对于表格数据，简单的全连接深度神经网络(FCDNN)可以做得很好。虽然并非总是如此，但一般来说，视觉和文本模型需要更多的参数来学习比表格数据中变量之间的交互更细微的表示，因此向前和向后传递可能需要更长的时间。</p><p id="5992" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">数据</strong>:视觉数据往往被保存为充满图像的嵌套文件夹，这可能需要大量的预处理(裁剪、缩放、旋转等)。文本数据可以是大文件或其他文本流。这两者一般都会保存在磁盘上，从磁盘上批量加载。这不是问题，因为磁盘读/写速度不是这里的瓶颈—预处理或向后传递才是。另一方面，表格数据有一个很好的特性，可以很容易地以数组或张量的形式加载到连续的内存块中。表格数据的预处理往往是预先单独完成的，要么在数据库中进行，要么作为对数据集的矢量化操作进行。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mr"><img src="../Images/4bb2879c3a10abe711adc5d22382b689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J414ZbNFsog5EwP1NCuXFw.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">不同类型监督学习研究的比较</p></figure><h1 id="c285" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">PyTorch和数据加载器</h1><p id="bd5b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正如我们所看到的，加载表格数据真的非常容易和快速！因此，PyTorch在默认情况下对表格数据非常有效……<em class="ml">对吗？</em></p><p id="00fe" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">原来不是！😩</p><p id="c717" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">就在上周，我在一些表格数据上训练PyTorch模型，并想知道训练需要这么长时间。我看不到任何明显的瓶颈，但出于某种原因，GPU的使用率远低于预期。当我深入分析它时，我发现了罪魁祸首… <em class="ml">数据加载器</em>。</p><p id="07c8" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">什么是数据加载器？</strong>数据加载器做的事情与您想象的完全一样:它们将您的数据从任何地方(磁盘上、云中、内存中)加载到您的模型需要使用它的任何地方(RAM或GPU内存中)。除此之外，他们还负责将您的数据分成不同的批次，进行重组，并在必要时对单个样本进行预处理。将这些代码封装在一个数据加载器中比分散在各处要好，因为这样可以让您的主要训练代码保持整洁。【PyTorch官方教程也推荐使用数据加载器。</p><p id="4b13" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">你如何使用它们？这取决于您拥有的数据类型。对于表格数据，PyTorch的默认数据加载器可以接受一个TensorDataset。这是训练所需张量的轻量级包装器，通常是X(或特征)和Y(或标签)张量。</p><pre class="ms mt mu mv gt nh ni nj nk aw nl bi"><span id="d58a" class="nm kj it ni b gy nn no l np nq">data_set = TensorDataset(train_x, train_y)<br/>train_batches = DataLoader(data_set, batch_size=1024, shuffle=False)</span></pre><p id="6632" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">然后，您可以在训练循环中使用它:</p><pre class="ms mt mu mv gt nh ni nj nk aw nl bi"><span id="e4b9" class="nm kj it ni b gy nn no l np nq">for x_batch, y_batch in train_batches:</span><span id="ec9e" class="nm kj it ni b gy nr no l np nq">    optimizer.zero_grad()</span><span id="3488" class="nm kj it ni b gy nr no l np nq">    loss = loss_fn(model(x_batch), y_batch)</span><span id="1c1d" class="nm kj it ni b gy nr no l np nq">    loss.backward()</span><span id="2ed8" class="nm kj it ni b gy nr no l np nq">    optimizer.step()</span><span id="e5c5" class="nm kj it ni b gy nr no l np nq">    ...</span></pre><p id="bfee" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">为什么这样不好？</strong>这个看起来不错，当然也很干净！问题是，每次加载一个批处理时，PyTorch的DataLoader对每个示例调用一次数据集<em class="ml">上的<code class="fe ns nt nu ni b">__getitem__()</code>函数，并将它们连接起来，而不是一次性读取一个批处理作为一个大块！所以我们最终没有利用我们的表格数据集的优势。当我们使用大批量时，这尤其糟糕。</em></p><p id="ebc7" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我们如何解决这个问题？简单——用下面的两行替换上面的前两行，并从<a class="ae mb" href="https://github.com/hcarlens/pytorch-tabular/blob/master/fast_tensor_data_loader.py" rel="noopener ugc nofollow" target="_blank">这个文件</a>中复制<code class="fe ns nt nu ni b">FastTensorDataLoader</code>的定义(这要归功于<a class="ae mb" href="https://cs.stanford.edu/~muj/" rel="noopener ugc nofollow" target="_blank">杰西·穆</a>，对于<a class="ae mb" href="https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6" rel="noopener ugc nofollow" target="_blank">这个答案</a>在PyTorch论坛上):</p><pre class="ms mt mu mv gt nh ni nj nk aw nl bi"><span id="1c27" class="nm kj it ni b gy nn no l np nq">train_batches = FastTensorDataLoader(train_x, train_y, batch_size=1024, shuffle=False)</span></pre><p id="4f11" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><code class="fe ns nt nu ni b">FastTensorDataLoader</code>只是一个小型的定制类，除了PyTorch之外没有其他依赖——使用它不需要对你的训练代码做任何修改！它也支持混排，尽管下面的基准是针对非混排数据的。</p><p id="c617" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><strong class="lc iu">这有什么区别？</strong>在我使用的基准测试集上，定制表格数据加载器的速度比基准测试快了20倍。在这种情况下，这意味着10个历元的运行不再需要15分钟，而是需要不到40秒——迭代速度的巨大差异！</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nv"><img src="../Images/00323704842331c93a3c93fc7e262556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xbCdMc0ItlYlftPz5VjNXA.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">两次几乎相同的跑步——除了一次超过15分钟，另一次不到一分钟！</p></figure><p id="da28" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">这个基准测试是在<a class="ae mb" href="https://www.nature.com/articles/ncomms5308" rel="noopener ugc nofollow" target="_blank">的这篇自然论文</a>中使用的<a class="ae mb" href="http://archive.ics.uci.edu/ml/datasets/HIGGS" rel="noopener ugc nofollow" target="_blank">希格斯数据集</a>上运行的。它有1100万个示例，是比大多数公共表格ML数据集(可能很小)更真实的深度学习基准。).这是一个二元分类问题，有21个实值特征。很高兴看到，在进行任何超参数优化之前，我们可以在短短40秒的训练时间内，在测试集上达到超过0.77 ROC AUC！虽然我们离报纸上的0.88还有一段距离。</p><p id="3dc0" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我希望这有所帮助，并且你能够在你自己的训练代码中看到类似的速度提高！在实现了这一点之后，我发现了一些进一步的优化，导致了接近100倍的总加速！如果你想看更多，请留下评论，我们可以在后续文章中讨论这些内容。</p><p id="d81b" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">关于如何自己运行基准代码，请参见附录。该示例包括运行默认PyTorch数据加载器(更快的自定义加载器)的代码，以及对结果进行计时和记录到TensorBoard的代码。</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><p id="2700" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><em class="ml">这篇文章是在</em> <a class="ae mb" href="https://gnsiscld.co/ffsd3" rel="noopener ugc nofollow" target="_blank"> <em class="ml">创世纪云</em> </a> <em class="ml">的计算能力的帮助下完成的:云GPU以令人难以置信的成本效率运行在冰岛的一个数据中心，使用100%可再生能源。</em> <a class="ae mb" href="https://gnsiscld.co/ffsd3" rel="noopener ugc nofollow" target="_blank"> <em class="ml">注册</em> </a> <em class="ml">即可获得50美元的免费积分，让你在GTX 1080Ti上驾驶超过160小时！</em></p><p id="16fb" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><em class="ml">关于作者:Harald从事股票分析师工作超过八年，目前是一名自由研究员和作家。他的个人博客在</em><a class="ae mb" href="http://www.harald.co." rel="noopener ugc nofollow" target="_blank"><em class="ml">www.harald.co</em></a><em class="ml">。他经营着</em> <a class="ae mb" href="http://mlcontests.com" rel="noopener ugc nofollow" target="_blank"> <em class="ml"> ML竞赛</em></a><em class="ml">——一个正在进行的机器学习竞赛的目录——以及一个</em> <a class="ae mb" href="https://cloud-gpus.com" rel="noopener ugc nofollow" target="_blank"> <em class="ml">云GPU比较</em> </a> <em class="ml">站点。</em></p><p id="0564" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated"><em class="ml">同一作者:</em></p><ul class=""><li id="b716" class="mc md it lc b ld lw lg lx lj me ln mf lr mg lv od mi mj mk bi translated"><a class="ae mb" href="https://medium.com/@hcarlens/five-tools-to-supercharge-your-cloud-deep-learning-workflow-3afb2e25be9f" rel="noopener"> <em class="ml">为你的云深度学习工作流程增压的五个工具</em> </a></li><li id="1966" class="mc md it lc b ld mm lg mn lj mo ln mp lr mq lv od mi mj mk bi translated"><a class="ae mb" href="https://medium.com/@hcarlens/reproducibility-issues-using-openai-gym-8ca605071d6a" rel="noopener"> <em class="ml">如何用OpenAI健身房正确设置随机种子</em> </a></li><li id="1139" class="mc md it lc b ld mm lg mn lj mo ln mp lr mq lv od mi mj mk bi translated"><a class="ae mb" href="https://medium.com/machine-learning-insights/top-cloud-gpu-providers-for-machine-learning-in-2022-894f6828da08" rel="noopener">2022年机器学习顶级云GPU提供商</a></li></ul></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><h1 id="ee90" class="ki kj it bd kk kl oe kn ko kp of kr ks jz og ka ku kc oh kd kw kf oi kg ky kz bi translated">附录:运行基准测试</h1><p id="1564" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">所以你可以自己看看结果，这是复制实验的说明。如果您已经安装了本地GPU和PyTorch，您可以跳过前两步！</p><ol class=""><li id="b560" class="mc md it lc b ld lw lg lx lj me ln mf lr mg lv mh mi mj mk bi translated">用你最喜欢的GPU云提供商创建一个新的Ubuntu 18.04实例(我用的是<a class="ae mb" href="https://gnsiscld.co/ffsd3" rel="noopener ugc nofollow" target="_blank">Genesis cloud</a>——你注册时可以获得100美元的免费积分，这足够运行这个实验几百次了！).</li></ol><p id="5384" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">2.使用<a class="ae mb" href="https://lambdalabs.com/lambda-stack-deep-learning-software" rel="noopener ugc nofollow" target="_blank"> Lambda Stack </a>一气呵成的安装CUDA和PyTorch:(做完这个别忘了重启！)</p><pre class="ms mt mu mv gt nh ni nj nk aw nl bi"><span id="f38d" class="nm kj it ni b gy nn no l np nq">LAMBDA_REPO=$(mktemp) &amp;&amp; \<br/>wget -O${LAMBDA_REPO} <a class="ae mb" href="https://lambdalabs.com/static/misc/lambda-stack-repo.deb" rel="noopener ugc nofollow" target="_blank">https://lambdalabs.com/static/misc/lambda-stack-repo.deb</a> &amp;&amp; \<br/>sudo dpkg -i ${LAMBDA_REPO} &amp;&amp; rm -f ${LAMBDA_REPO} &amp;&amp; \<br/>sudo apt-get update &amp;&amp; \<br/>sudo apt-get — yes upgrade &amp;&amp; \<br/>sudo apt-get install — yes — no-install-recommends lambda-server &amp;&amp; \<br/>sudo apt-get install — yes — no-install-recommends nvidia-headless-440 nvidia-utils-440 &amp;&amp; \<br/>sudo apt-get install — yes — no-install-recommends lambda-stack-cuda</span></pre><p id="a72a" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">3.下载数据集:</p><pre class="ms mt mu mv gt nh ni nj nk aw nl bi"><span id="ee2e" class="nm kj it ni b gy nn no l np nq">wget <a class="ae mb" href="http://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz" rel="noopener ugc nofollow" target="_blank">http://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz</a></span></pre><p id="b2b7" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">4.克隆存储库:</p><pre class="ms mt mu mv gt nh ni nj nk aw nl bi"><span id="b2c0" class="nm kj it ni b gy nn no l np nq">git clone <a class="ae mb" href="mailto:git@github.com" rel="noopener ugc nofollow" target="_blank">git@github.com</a>:hcarlens/pytorch-tabular.git</span></pre><p id="255e" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">5.运行基准脚本:</p><pre class="ms mt mu mv gt nh ni nj nk aw nl bi"><span id="cd2e" class="nm kj it ni b gy nn no l np nq">python3 pytorch-tabular/higgs_benchmark.py</span></pre><p id="9402" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">如果你运行的是GTX 1080的实例，比如我使用的Genesis Cloud，你应该会得到如下结果:</p><pre class="ms mt mu mv gt nh ni nj nk aw nl bi"><span id="5e55" class="nm kj it ni b gy nn no l np nq">ubuntu@genesis:~$ python3 pytorch-tabular/higgs_benchmark.py<br/>2020-04-12 15:05:55.961134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0<br/>Epoch 0 done.<br/>Epoch 1 done.<br/>Epoch 2 done.<br/>Epoch 3 done.<br/>Epoch 4 done.<br/>Epoch 5 done.<br/>Epoch 6 done.<br/>Epoch 7 done.<br/>Epoch 8 done.<br/>Epoch 9 done.<br/>Epoch 0 done.<br/>Epoch 1 done.<br/>Epoch 2 done.<br/>Epoch 3 done.<br/>Epoch 4 done.<br/>Epoch 5 done.<br/>Epoch 6 done.<br/>Epoch 7 done.<br/>Epoch 8 done.<br/>Epoch 9 done.<br/>Standard dataloader: 124.55s/epoch.<br/>Custom dataloader: 5.24s/epoch.</span></pre></div></div>    
</body>
</html>