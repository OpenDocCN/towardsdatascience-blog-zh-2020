<html>
<head>
<title>Drug Discovery with Graph Neural Networks — part 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用图形神经网络发现药物——第三部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/drug-discovery-with-graph-neural-networks-part-3-c0c13e3e3f6d?source=collection_archive---------43-----------------------#2020-08-26">https://towardsdatascience.com/drug-discovery-with-graph-neural-networks-part-3-c0c13e3e3f6d?source=collection_archive---------43-----------------------#2020-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1bde" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">GNN 解释方法实用教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/78a16f69ecdc9c6546257a2944b57873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*5vZWIz2qmQUDS1FeQoaZJg.gif"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">GNNExplainer 的可视化</p></figure><h1 id="5138" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">相关材料</h1><ul class=""><li id="adf3" class="lm ln it lo b lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated"><a class="ae me" rel="noopener" target="_blank" href="/drug-discovery-with-graph-neural-networks-part-1-1011713185eb">用图形神经网络发现药物—第一部分</a></li><li id="7e60" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated"><a class="ae me" rel="noopener" target="_blank" href="/drug-discovery-with-graph-neural-networks-part-2-b1b8d60180c4">用图形神经网络发现药物—第二部分</a></li><li id="562d" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated"><a class="ae me" rel="noopener" target="_blank" href="/towards-explainable-graph-neural-networks-45f5e3912dd0">走向可解释图神经网络</a></li><li id="8e93" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated"><a class="ae me" href="https://medium.com/me/stats/post/625f4c5fb8cd" rel="noopener">图形的特征提取</a></li><li id="94c2" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated"><a class="ae me" rel="noopener" target="_blank" href="/towards-explainable-graph-neural-networks-45f5e3912dd0">面向可解释图的神经网络</a></li><li id="250c" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated"><a class="ae me" rel="noopener" target="_blank" href="/machine-learning-tasks-on-graphs-7bc8f175119a">图上的机器学习任务</a></li></ul><h1 id="98e5" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">目录</h1><ul class=""><li id="c425" class="lm ln it lo b lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">什么是解释技巧</li><li id="ab6c" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated">我们为什么要烦恼呢？</li><li id="cba7" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated">GNN 解释方法的工具</li><li id="6869" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated">GNNExplainer 的实际操作部分</li><li id="ff10" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated">关于我</li><li id="1c78" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated">参考</li></ul></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="28d5" class="ku kv it bd kw kx mr kz la lb ms ld le jz mt ka lg kc mu kd li kf mv kg lk ll bi translated">什么是解释技巧</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mw"><img src="../Images/c6055b80ac382e8c6ad59ba8a85b7502.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ugKZGx3rsBTMZPfuSSY8bA.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">类别映射的一个例子——卷积神经网络的解释方法之一。<a class="ae me" href="http://cnnlocalization.csail.mit.edu/" rel="noopener ugc nofollow" target="_blank">【来源】</a></p></figure><p id="9149" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">解释技巧帮助我们理解模型的行为。例如，解释方法被用于形象化图像的某些部分，或者观察它如何对某个输入做出反应。这是一个成熟的机器学习领域，具有许多不同的技术，可以应用于深度学习(例如，类激活图、梯度属性)和其他机器学习算法(例如，LIME)。</p><p id="48e8" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">然而，只有少数人试图为图形神经网络(GNNs)创建解释方法。大部分在深度学习中开发的“重用”方法，并试图将其应用于图形领域。</p><p id="4174" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">如果你想了解更多关于可解释 GNNs 的最新研究，我强烈推荐你看看我以前的文章。在这里，我将保持理论简短，并集中于如何使用现有的 GNN 解释包，GNNExplainer。</p><h1 id="11cf" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">我们为什么要烦恼呢？</h1><p id="53ad" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated">深度学习模型可以有数百万个参数，它们经常以黑盒的形式出现在我们面前[1]。很难说这个模型将如何对新数据做出反应，以及为什么它会在给定特定输入的情况下做出某些预测。</p><p id="decb" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">通过解释方法，我们希望在模型中建立信任。它们从模型中提供了额外的见解，使模型更加透明和可解释。通过发展对模型的信任，我们可以安全地部署模型以供更广泛的使用。</p><h1 id="9e80" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">GNN 解释方法的工具</h1><p id="2189" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated">不幸的是，对 GNNs 解释方法的研究相当新，所以没有很多现成的工具和研究论文。Duvenaud 等人在[2]中完成了关于该主题的第一批工作之一。他设法创造了一种梯度归因方法，突出了触发预测的某些分子亚结构。例如，他们的方法可以突出使分子有毒或可溶于水的分子亚结构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/d88317e80efe6888b3234e58d1a3ef0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*f2npHf_3rbdc6G5x1se7JA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">突出显示了触发溶解度预测的分子亚结构。<a class="ae me" href="https://arxiv.org/abs/1509.09292" rel="noopener ugc nofollow" target="_blank">【来源】</a></p></figure><p id="3f4f" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">幸运的是，斯坦福大学的研究人员开发了一种模型不可知的 GNN 解释方法，GNNExplainer [3]。在本文的剩余部分，我们将探索如何使用他们的工具。</p><p id="f54d" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">如果你没有时间阅读关于 GNNExplainer 实现的整篇文章，但是你仍然想对它的工作原理有一个直观的了解，看看<a class="ae me" rel="noopener" target="_blank" href="/towards-explainable-graph-neural-networks-45f5e3912dd0">我的文章</a>。</p><h1 id="d857" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">GNNExplainer 的实际操作部分</h1><p id="2ad3" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated"><a class="ae me" href="https://github.com/RexYing/gnn-model-explainer" rel="noopener ugc nofollow" target="_blank">你可以在这里找到 GNNExplainer 知识库。</a></p><p id="be9d" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated"><a class="ae me" href="https://github.com/KacperKubara/ml-cookbook/blob/master/drug_discovery_with_gnns/gnn_explainer_setup.md" rel="noopener ugc nofollow" target="_blank">通过我的个人笔记链接到安装说明。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/78a16f69ecdc9c6546257a2944b57873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*5vZWIz2qmQUDS1FeQoaZJg.gif"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">GNNExplainer 的交互式可视化。在“Syn2”数据集上运行。</p></figure><p id="98c8" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">GNNExplainer 实际上是第一个模型无关的开源工具，可用于 GNN 解释。斯坦福大学的研究人员做了大量工作来创建这个通用工具，但它包含很少的错误，并且相当难以设置。在本指南中，我将讨论我在安装过程中遇到的一些问题，并指导你如何创建如上图的 GNN 解释。</p><h2 id="ecd7" class="nu kv it bd kw nv nw dn la nx ny dp le lt nz oa lg lv ob oc li lx od oe lk of bi translated">装置</h2><p id="6681" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated"><strong class="lo iu"> <em class="og">请注意:</em> </strong> <em class="og">我的设置是支持 CUDA 的 GPU 的 Windows OS。安装说明可能不适用于不同的设置。但是，我将尝试指出您可能需要调整的步骤，以使其适用于其他操作系统需求。如果你只是好奇这个包是如何工作的，没有时间安装，请跳过这个说明。</em></p><p id="4af8" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">要安装 GNNExplainer，先决条件是<a class="ae me" href="https://docs.conda.io/en/latest/miniconda.html" rel="noopener ugc nofollow" target="_blank">已经安装了 conda】。他们资源库的安装说明也可以在</a><a class="ae me" href="https://github.com/RexYing/gnn-model-explainer/blob/master/INSTALLATION.md" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。它们不适合我的设置，也没有什么错误，所以我花了一些时间根据我的需要调整安装说明。我的设置的工作说明如下。如果您有不同的操作系统，您可能需要更改 cudatoolkit 版本，或者安装没有 CUDA 支持的 Pytorch。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><h2 id="41b6" class="nu kv it bd kw nv nw dn la nx ny dp le lt nz oa lg lv ob oc li lx od oe lk of bi translated">如何培养 GNN 模式</h2><p id="2f7d" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated">作者提供了一个 GNN 模型和几个图形数据集作为示例。这是一个很好的起点，可以测试一切是否正常工作，并对软件包有更多的了解。</p><p id="6236" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">安装软件包后，运行:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="e582" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">这将在示例 syn2 数据上训练所提供的 GNN 模型。它甚至可能需要半个小时，所以做好准备！Syn2 是一个由作者创建的合成数据集，称为“具有社区特征的随机 BA 图”。GNNExplainer 模型的基本事实是一个“类似房子”的结构(看上面的 GIF)。这是 GNNExplainer 将尝试查找的一组节点。</p><h2 id="fda4" class="nu kv it bd kw nv nw dn la nx ny dp le lt nz oa lg lv ob oc li lx od oe lk of bi translated">如何使用解释器</h2><p id="a962" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated">要使用在 Syn2 数据集上训练的模型运行 GNNExplainer，请运行:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="f99c" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">这将创建一个解释文件，然后可以使用 Jupyter 笔记本可视化。我在运行它的时候遇到了一个错误。在脚本结尾保存准确性/损失数字时出现问题。所需的解释是在这一步之前计算的，所以这个问题并不重要。如果你还想解决这个问题并保存图，用修改保存路径的<a class="ae me" href="https://gist.github.com/KacperKubara/d8f3d729e90499871541267ac426921c" rel="noopener ugc nofollow" target="_blank">我的要点</a>替换<em class="og"> explain.py </em>文件。它们将位于<em class="og"> log/ </em>文件夹中。</p><h2 id="b0b8" class="nu kv it bd kw nv nw dn la nx ny dp le lt nz oa lg lv ob oc li lx od oe lk of bi translated">如何可视化结果</h2><p id="93fa" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated">作者为我们提供了两个笔记本来可视化结果。它们几乎是一样的，但是交互式笔记本包含了额外的交互式解释示例。</p><p id="9d79" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">在您从<em class="og">笔记本/ </em>文件夹中启动选定的笔记本之前，您必须再进行一次调整。转到<em class="og"> log/ </em>文件夹，将从<em class="og"> masked_ </em>开始的所有文件移动到<em class="og">syn 2 _ base _ h20 _ 020 _ explain/</em>文件夹。这将确保我们不必更改笔记本代码中的任何路径。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/ae231e4b8a1ad88965111ed277381c8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*2pGobFD2E8FbDcznCZzFFA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">将所有被屏蔽的 _*文件移动到 syn2_base_h20_020_explain 文件夹</p></figure><p id="575e" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">这个笔记本非常简单，你只需要运行所有的单元格来生成图。对于 syn2 数据集，它们应该类似于下图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi ok"><img src="../Images/f2109f484ebc5dca8e16a3bb0e16c08c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RYhMq0Rv-Yu_0hMWOXGTvg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">运行<em class="ol">GNN-解释者-即 ipynb 笔记本后的示例结果。</em></p></figure><h2 id="11b6" class="nu kv it bd kw nv nw dn la nx ny dp le lt nz oa lg lv ob oc li lx od oe lk of bi translated">如何在分子数据上运行 GNNExplainer？</h2><p id="2fcc" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated">您可以潜在地使用该软件来运行 Tox21、致突变性或自定义图表数据集。为了做到这一点，请看一下原始的存储库说明。</p><p id="701e" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">我成功地在 Tox21 数据集上训练了 GNN 模型。然而，看起来软件中有错误，模型在训练后没有保存，这使得无法运行解释器。希望他们能尽快修好它。</p><h2 id="b3a5" class="nu kv it bd kw nv nw dn la nx ny dp le lt nz oa lg lv ob oc li lx od oe lk of bi translated">PyTorch 几何中的 GNNExplainer</h2><p id="da91" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated">GNNExplainer 也是<a class="ae me" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/models/gnn_explainer.html" rel="noopener ugc nofollow" target="_blank"> PyTorch 几何软件包</a>的一部分。然而，它只支持节点解释，并且没有原始包提供的可视化工具。不管怎样，还是值得一查的。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="040e" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated"><em class="og">感谢您阅读本文，希望对您有用！</em></p><h1 id="8a6c" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">关于我</h1><p id="c792" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated">我是阿姆斯特丹大学的人工智能硕士学生。在我的业余时间，你可以发现我摆弄数据或者调试我的深度学习模型(我发誓这很有效！).我也喜欢徒步旅行:)</p><p id="cd1f" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated">如果你想了解我的最新文章和其他有用的内容，以下是我的社交媒体资料:</p><ul class=""><li id="8bd5" class="lm ln it lo b lp nd lr nf lt om lv on lx oo lz ma mb mc md bi translated"><a class="ae me" href="https://medium.com/@kacperkubara" rel="noopener">中等</a></li><li id="1340" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated"><a class="ae me" href="https://www.linkedin.com/in/kacperkubara/" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="e565" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated"><a class="ae me" href="https://github.com/KacperKubara" rel="noopener ugc nofollow" target="_blank"> Github </a></li><li id="c7b9" class="lm ln it lo b lp mf lr mg lt mh lv mi lx mj lz ma mb mc md bi translated"><a class="ae me" href="https://kacperkubara.com/" rel="noopener ugc nofollow" target="_blank">个人网站</a></li></ul><h1 id="3ec3" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">参考</h1><p id="ab75" class="pw-post-body-paragraph nb nc it lo b lp lq ju ne lr ls jx ng lt nq ni nj lv nr nl nm lx ns no np lz im bi translated"><strong class="lo iu">【1】深度学习中的解释方法:用户、价值观、关注点和挑战:</strong><a class="ae me" href="https://arxiv.org/pdf/1803.07517.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1803.07517.pdf</a></p><p id="5661" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated"><strong class="lo iu">【2】</strong><strong class="lo iu">用于学习分子指纹的图上卷积网络:</strong><a class="ae me" href="https://arxiv.org/abs/1509.09292" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1509.09292</a></p><p id="8254" class="pw-post-body-paragraph nb nc it lo b lp nd ju ne lr nf jx ng lt nh ni nj lv nk nl nm lx nn no np lz im bi translated"><strong class="lo iu">【3】gnnexplaner:为图形神经网络生成解释:</strong><a class="ae me" href="https://arxiv.org/abs/1903.03894" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1903.03894</a></p></div></div>    
</body>
</html>