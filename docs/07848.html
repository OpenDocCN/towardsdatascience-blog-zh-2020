<html>
<head>
<title>Deploy models in PyTorch 🚀</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在PyTorch中部署模型🚀</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploy-models-and-create-custom-handlers-in-torchserve-fc2d048fbe91?source=collection_archive---------9-----------------------#2020-06-11">https://towardsdatascience.com/deploy-models-and-create-custom-handlers-in-torchserve-fc2d048fbe91?source=collection_archive---------9-----------------------#2020-06-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/3b4d2f5b2a8dfd35e3476c42eb02f383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zcpG9pJHT6_1wU_pXumh6Q.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由SpaceX在Unsplash上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="e547" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">火炬来救援了！</h2></div><p id="e2b1" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">本文中使用的所有代码都是</em> <a class="ae lv" href="https://github.com/FrancescoSaverioZuppichini/torchserve-tryout" rel="noopener ugc nofollow" target="_blank"> <em class="lu">这里的</em> </a></p><p id="5200" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最近，PyTorch推出了名为<code class="fe lw lx ly lz b">torchserve.</code>的新生产框架来适当地服务于模型，因此，不多说了，让我们来介绍一下今天的路线图:</p><ol class=""><li id="e77b" class="ma mb ji la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">用Docker安装</li><li id="51fc" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">导出您的模型</li><li id="19f4" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">定义处理程序</li><li id="872d" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">为我们的模型服务</li></ol><p id="e44e" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了展示torchserve，我们将提供经过全面培训的ResNet34来执行图像分类。</p><h1 id="d575" class="mo mp ji bd mq mr ms mt mu mv mw mx my ko mz kp na kr nb ks nc ku nd kv ne nf bi translated">用Docker安装</h1><p id="0a7a" class="pw-post-body-paragraph ky kz ji la b lb ng kj ld le nh km lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated"><em class="lu">公文</em> <a class="ae lv" href="https://github.com/pytorch/serve/blob/master/README.md##install-torchserve" rel="noopener ugc nofollow" target="_blank"> <em class="lu">此处</em> </a></p><p id="0733" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">安装torchserve最好的方法是用docker。你只需要调出图像。</p><p id="138d" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以使用以下命令保存最新的图像。</p><pre class="nl nm nn no gt np lz nq nr aw ns bi"><span id="847c" class="nt mp ji lz b gy nu nv l nw nx">docker pull pytorch/torchserve:latest</span></pre><p id="64c0" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所有的标签都可以在<a class="ae lv" href="https://hub.docker.com/r/pytorch/torchserve/tags" rel="noopener ugc nofollow" target="_blank">这里</a></p><p id="f6a6" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更多关于docker和torchserve <a class="ae lv" href="https://github.com/pytorch/serve#quick-start-with-docker" rel="noopener ugc nofollow" target="_blank">这里</a></p><h1 id="9765" class="mo mp ji bd mq mr ms mt mu mv mw mx my ko mz kp na kr nb ks nc ku nd kv ne nf bi translated">经理人</h1><p id="af97" class="pw-post-body-paragraph ky kz ji la b lb ng kj ld le nh km lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated"><em class="lu">正式文件</em> <a class="ae lv" href="https://github.com/pytorch/serve/blob/master/docs/custom_service.md" rel="noopener ugc nofollow" target="_blank"> <em class="lu">此处</em> </a></p><p id="3ba6" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">处理程序负责使用您的模型从一个或多个HTTP请求中做出预测。</p><p id="0487" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jj">默认处理程序</strong></p><p id="02f6" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Torchserve支持以下默认处理程序</p><ol class=""><li id="337b" class="ma mb ji la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated"><code class="fe lw lx ly lz b">image_classifier</code></li><li id="a14b" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated"><code class="fe lw lx ly lz b">object_detector</code></li><li id="c394" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated"><code class="fe lw lx ly lz b">text_classifier</code></li><li id="0375" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated"><code class="fe lw lx ly lz b">image_segmenter</code></li></ol><p id="ead8" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是请记住，它们都不支持批处理请求！</p><p id="5d8c" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jj">自定义处理程序</strong></p><p id="9c68" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">torchserve公开了一个丰富的接口，可以做几乎所有你想做的事情。An <code class="fe lw lx ly lz b">Handler</code>只是一个必须有三个功能的类</p><ul class=""><li id="024f" class="ma mb ji la b lb lc le lf lh mc ll md lp me lt ny mg mh mi bi translated">预处理</li><li id="87f2" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">推理</li><li id="d9c4" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">后处理</li></ul><p id="a12e" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以创建自己的类或者子类<code class="fe lw lx ly lz b">BaseHandler</code>。子类化<code class="fe lw lx ly lz b">BaseHandler</code>的主要优点是可以在<code class="fe lw lx ly lz b">self.model</code>访问加载的模型。下面的代码片段显示了如何子类化<code class="fe lw lx ly lz b">BaseHandler</code></p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/cd84e4c7e446ecd0ab0192cc4738ac7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5q0yUhk2U_Dibjji7440AA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">子类化BaseHandler以创建您自己的处理程序</p></figure><p id="151f" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">回到我们的图像分类例子。我们需要</p><ul class=""><li id="7fab" class="ma mb ji la b lb lc le lf lh mc ll md lp me lt ny mg mh mi bi translated">从每个请求中获取图像并对其进行预处理</li><li id="e580" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">从模型中获得预测</li><li id="60d5" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">发回回复</li></ul><p id="63e8" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jj">预处理</strong></p><p id="ef1c" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe lw lx ly lz b">.preprocess</code>函数接受一组请求。假设我们向服务器发送一个图像，可以从请求的<code class="fe lw lx ly lz b">data</code>或<code class="fe lw lx ly lz b">body</code>字段访问序列化的图像。因此，我们可以遍历所有请求，并单独预处理每幅图像。完整的代码如下所示。</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/a5cc5a7edb33a8ba2c544f23fce33d05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*toaTICWo2QReG4Ru98k5nw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">预处理每个请求中的每个图像</p></figure><p id="5ce0" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe lw lx ly lz b">self.transform</code>是我们的预处理改造，没什么花哨的。对于在ImageNet上训练的模型，这是一个经典的预处理步骤。</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/36ce750304576f503215bc61bcd3e173.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b2wnDsCPeyMnG-dPd_LHAQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">我们的转变</p></figure><p id="e4de" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们对每个请求中的每个图像进行预处理后，我们将它们连接起来以创建pytorch张量。</p><p id="30b9" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jj">推论</strong></p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/04928ac2511244c36b2e465a69255a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HxV-1VHS4okzBRqJVWJuZQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">对我们的模型进行推理</p></figure><p id="089a" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这一步非常简单，我们从<code class="fe lw lx ly lz b">.preprocess</code>函数中得到张量，并提取每幅图像的预测。</p><p id="1b10" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jj">后处理</strong></p><p id="648f" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们有了对每幅图像的预测，我们需要向客户端返回一些东西。<strong class="la jj"> Torchserve总是期望返回一个数组。</strong> <code class="fe lw lx ly lz b">BaseHandler</code>也会自动打开一个映射为<code class="fe lw lx ly lz b">index -&gt; label</code>的<code class="fe lw lx ly lz b">.json</code>文件(我们稍后会看到如何提供这样的文件)并存储在<code class="fe lw lx ly lz b">self.mapping</code>。我们可以为每个预测返回一个带有<code class="fe lw lx ly lz b">label</code>和<code class="fe lw lx ly lz b">index</code>类的字典数组</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ob"><img src="../Images/7682670e3f8c3605fc6933d7394d5f0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jMEdHz17k_keN_q_U56c0Q.png"/></div></div></figure><p id="ff1e" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">把所有东西都包起来，我们光荣的训练员看起来像</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oc"><img src="../Images/8e682df519b1d966ab8a682be29e1d29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MRg0Kccp9ZErk82_LQnP2Q.png"/></div></div></figure><p id="0317" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为所有的处理逻辑都封装在一个类中，所以你可以很容易地对它进行单元测试！</p><h1 id="038e" class="mo mp ji bd mq mr ms mt mu mv mw mx my ko mz kp na kr nb ks nc ku nd kv ne nf bi translated">导出您的模型</h1><p id="3fc8" class="pw-post-body-paragraph ky kz ji la b lb ng kj ld le nh km lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated"><em class="lu">公文</em> <a class="ae lv" href="https://github.com/pytorch/serve/tree/master/model-archiver#creating-a-model-archive" rel="noopener ugc nofollow" target="_blank"> <em class="lu">此处</em> </a></p><p id="037c" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Torchserve期望提供一个<code class="fe lw lx ly lz b">.mar</code>文件。简而言之，这个文件就是你的模型和所有的依赖关系。创建一个需要首先导出我们的训练模型。</p><p id="03ef" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jj">导出模型</strong></p><p id="da68" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有三种方法可以导出torchserve的模型。到目前为止，我发现的最好的方法是<code class="fe lw lx ly lz b">trace</code>模型并存储结果。通过这样做，我们不需要添加任何额外的文件到torchserve。</p><p id="b2a2" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看一个例子，我们将部署一个经过全面训练的ResNet34模型。</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/9b7d6baa80015c100ed6c95275db4f20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S6EMzJU1k3NfNXgPZz218g.png"/></div></div></figure><p id="32c8" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为此，我们:</p><ul class=""><li id="fe75" class="ma mb ji la b lb lc le lf lh mc ll md lp me lt ny mg mh mi bi translated">加载模型</li><li id="7f78" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">创建一个虚拟输入</li><li id="d687" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">使用<code class="fe lw lx ly lz b">torch.jit.trace</code>通过模型追踪输入</li><li id="738f" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">保存模型</li></ul><p id="ecb6" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jj">创造。标记文件</strong></p><p id="cf82" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">公文</em> <a class="ae lv" href="https://github.com/pytorch/serve/blob/master/model-archiver/README.md" rel="noopener ugc nofollow" target="_blank"> <em class="lu">此处</em> </a></p><p id="9407" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你需要安装<code class="fe lw lx ly lz b">torch-model-archiver</code></p><pre class="nl nm nn no gt np lz nq nr aw ns bi"><span id="da02" class="nt mp ji lz b gy nu nv l nw nx">git clone https://github.com/pytorch/serve.git<br/>cd serve/model-archiver<br/>pip install .</span></pre><p id="f942" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们准备通过使用下面的命令来创建<code class="fe lw lx ly lz b">.mar</code>文件</p><pre class="nl nm nn no gt np lz nq nr aw ns bi"><span id="5d15" class="nt mp ji lz b gy nu nv l nw nx">torch-model-archiver --model-name resnet34 \</span><span id="eded" class="nt mp ji lz b gy oe nv l nw nx">--version 1.0 \</span><span id="95bf" class="nt mp ji lz b gy oe nv l nw nx">--serialized-file resnet34.pt \</span><span id="cc22" class="nt mp ji lz b gy oe nv l nw nx">--extra-files ./index_to_name.json,./MyHandler.py \</span><span id="f176" class="nt mp ji lz b gy oe nv l nw nx">--handler my_handler.py  \</span><span id="ddad" class="nt mp ji lz b gy oe nv l nw nx">--export-path model-store -f</span></pre><p id="724d" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">按顺序。变量<code class="fe lw lx ly lz b">--model-name</code>定义了我们模型的最终名称。这非常重要，因为它将是负责其预测的端点的名称空间。也可以指定一个<code class="fe lw lx ly lz b">--version</code>。<code class="fe lw lx ly lz b">--serialized-file</code>指向我们之前创建的存储的<code class="fe lw lx ly lz b">.pt</code>模型。<code class="fe lw lx ly lz b">--handler</code>是一个python文件，我们在其中调用我们的自定义处理程序。一般来说，它看起来总是这样:</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/f2e7ec6386bde3f4774080c624d2cf4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HaMhDQ3N3OgDrqeckeHpcQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">my_handler.py</p></figure><p id="8107" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它公开了一个<code class="fe lw lx ly lz b">handle</code>函数，我们从这个函数调用定制处理程序中的方法。您可以使用默认名称来使用默认句柄(例如<code class="fe lw lx ly lz b">--handler image_classifier</code>)。</p><p id="89ab" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在<code class="fe lw lx ly lz b">--extra-files</code>中，您需要传递您的处理程序正在使用的所有文件的路径。在我们的例子中，我们必须将路径添加到包含所有人类可读标签名称的<code class="fe lw lx ly lz b">.json</code>文件和包含<code class="fe lw lx ly lz b">MyHandler.</code>类定义的<code class="fe lw lx ly lz b">MyHandler.py</code>文件中</p><p id="6545" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一件小事，如果你传递一个<code class="fe lw lx ly lz b">index_to_name.json</code>文件，它将被自动加载到处理程序中，并且可以在<code class="fe lw lx ly lz b">self.mapping</code>访问。</p><p id="f206" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe lw lx ly lz b">--export-path</code>是存储<code class="fe lw lx ly lz b">.mar</code>文件的地方，我还添加了<code class="fe lw lx ly lz b">-f</code>来覆盖其中的所有内容。</p><p id="cf3d" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果一切顺利，您应该会看到<code class="fe lw lx ly lz b">resnet34.mar</code>被存储到<code class="fe lw lx ly lz b">./model-store</code>中。</p><h1 id="a229" class="mo mp ji bd mq mr ms mt mu mv mw mx my ko mz kp na kr nb ks nc ku nd kv ne nf bi translated">为我们的模型服务</h1><p id="0da4" class="pw-post-body-paragraph ky kz ji la b lb ng kj ld le nh km lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">这是一个简单的步骤，我们可以用所有需要的参数运行torchserve docker容器</p><pre class="nl nm nn no gt np lz nq nr aw ns bi"><span id="9c87" class="nt mp ji lz b gy nu nv l nw nx">docker run --rm -it \</span><span id="c32e" class="nt mp ji lz b gy oe nv l nw nx">-p 3000:8080 -p 3001:8081 \</span><span id="c0a7" class="nt mp ji lz b gy oe nv l nw nx">-v $(pwd)/model-store:/home/model-server/model-store pytorch/torchserve:0.1-cpu \</span><span id="2a2c" class="nt mp ji lz b gy oe nv l nw nx">torchserve --start --model-store model-store --models resnet34=resnet34.mar</span></pre><p id="9c85" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将容器端口8080和8081分别绑定到3000和3001(8080/8081已经在我的机器上使用)。然后，我从<code class="fe lw lx ly lz b">./model-store</code>(我们存储<code class="fe lw lx ly lz b">.mar</code>文件的地方)到容器默认的<code class="fe lw lx ly lz b">model-store</code>文件夹创建一个卷。最后，我通过填充<code class="fe lw lx ly lz b">model-store</code>路径和一个键值对列表来调用<code class="fe lw lx ly lz b">torchserve</code>，在这个列表中，我们为每个<code class="fe lw lx ly lz b">.mar</code>文件指定了模型名称。</p><p id="55ea" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这一点上，torchserve有一个端点<code class="fe lw lx ly lz b">/predictions/resnet34</code>，我们可以通过发送图像来获得预测。这可以使用<code class="fe lw lx ly lz b">curl</code>来完成</p><pre class="nl nm nn no gt np lz nq nr aw ns bi"><span id="74cd" class="nt mp ji lz b gy nu nv l nw nx">curl -X POST <a class="ae lv" href="http://127.0.0.1:3000/predictions/resnet34" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:3000/predictions/resnet34</a> -T inputs/kitten.jpg</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/a6adc579d169f0d8c013b03bb3ed8271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cHNtipNag5R3GjgR110d7Q.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">kitten.jpg .<a class="ae lv" href="https://pixabay.com/it/photos/gatto-tabby-all-aperto-animali-1506960/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="03c9" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">回应</p><pre class="nl nm nn no gt np lz nq nr aw ns bi"><span id="5802" class="nt mp ji lz b gy nu nv l nw nx">{<br/>  "label": "tiger_cat",<br/>  "index": 282<br/>}</span></pre><p id="25e9" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">成功了！🥳</p><h1 id="3d76" class="mo mp ji bd mq mr ms mt mu mv mw mx my ko mz kp na kr nb ks nc ku nd kv ne nf bi translated">摘要</h1><p id="43cd" class="pw-post-body-paragraph ky kz ji la b lb ng kj ld le nh km lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">概括地说，在本文中，我们讨论了:</p><ul class=""><li id="0efb" class="ma mb ji la b lb lc le lf lh mc ll md lp me lt ny mg mh mi bi translated">用docker安装火炬服务器</li><li id="06d5" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">默认和自定义处理程序</li><li id="901a" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">模型档案生成</li><li id="55cb" class="ma mb ji la b lb mj le mk lh ml ll mm lp mn lt ny mg mh mi bi translated">用docker服务最终模型</li></ul><p id="3c70" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里所有的代码都是<a class="ae lv" href="https://github.com/FrancescoSaverioZuppichini/torchserve-tryout" rel="noopener ugc nofollow" target="_blank"/></p><p id="30c1" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你喜欢这篇文章和pytorch，你可能也会对我的其他文章感兴趣</p><div class="is it gp gr iu og"><a rel="noopener follow" target="_blank" href="/pytorch-deep-learning-template-6e638fc2fe64"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jj gy z fp ol fr fs om fu fw jh bi translated">PyTorch深度学习模板</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">一个干净简单的模板来启动你的下一个dl项目🚀🚀</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="oq l or os ot op ou ja og"/></div></div></a></div><div class="is it gp gr iu og"><a rel="noopener follow" target="_blank" href="/pytorch-how-and-when-to-use-module-sequential-modulelist-and-moduledict-7a54597b5f17"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jj gy z fp ol fr fs om fu fw jh bi translated">Pytorch:如何以及何时使用模块、顺序、模块列表和模块指令</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">Pytorch 1.5更新</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="ov l or os ot op ou ja og"/></div></div></a></div><p id="5c3e" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢您的阅读。</p><p id="1f43" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">弗朗西斯科</p></div></div>    
</body>
</html>