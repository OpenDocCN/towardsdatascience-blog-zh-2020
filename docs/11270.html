<html>
<head>
<title>Clustering documents with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Python 聚类文档</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clustering-documents-with-python-97314ad6a78d?source=collection_archive---------2-----------------------#2020-08-05">https://towardsdatascience.com/clustering-documents-with-python-97314ad6a78d?source=collection_archive---------2-----------------------#2020-08-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="f52a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">自然语言处理在过去的几年里取得了巨大的进步。目前，神经网络的各种实现是最前沿的，似乎每个人都在谈论它们。但是，有时更简单的解决方案可能更好。毕竟，一个人应该在跑之前先试着走一走。在这篇短文中，我将展示一种用 Python 对文档进行聚类的简单方法。所有代码都可以在<a class="ae ko" href="https://github.com/dpanagop/ML_and_AI_examples/blob/master/NLP_example_clustering.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>获得(请注意，在<a class="ae ko" href="https://nbviewer.jupyter.org/github/dpanagop/ML_and_AI_examples/blob/master/NLP_example_clustering.ipynb" rel="noopener ugc nofollow" target="_blank"> nbviewer </a>中查看代码可能会更好)。</p><p id="ea5f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用 k-means 算法对维基百科文章进行聚类。执行此操作的步骤如下:</p><ol class=""><li id="a376" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated">获取一些维基百科的文章，</li></ol><p id="a23a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.将每篇文章表示为一个向量，</p><p id="ddab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.执行 k 均值聚类，</p><p id="c59c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">4.评估结果。</p><h1 id="3d89" class="ky kz it bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">1.获取维基百科文章</h1><p id="4796" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">使用维基百科包可以很容易地从维基百科下载内容。对于本例，我们将文章的内容用于:</p><ul class=""><li id="070b" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn mb kv kw kx bi translated">数据科学</li><li id="ab03" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">人工智能</li><li id="f2a9" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">机器学习</li><li id="df47" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">欧洲中央银行</li><li id="3774" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">银行</li><li id="6b2d" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">金融技术</li><li id="7a39" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">国际货币基金组织</li><li id="8124" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">篮球</li><li id="5eba" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">游泳</li><li id="c9d2" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">网球</li></ul><p id="18fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每篇维基百科文章的内容存储在 wiki_list 中，而每篇文章的标题存储在变量 title 中。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="9ba6" class="mq kz it mm b gy mr ms l mt mu">import pandas as pd<br/>import wikipedia</span><span id="db8b" class="mq kz it mm b gy mv ms l mt mu">articles=['Data Science','Artificial intelligence','Machine Learning','European Central Bank','Bank','Financial technology','International Monetary Fund','Basketball','Swimming','Tennis']</span><span id="539e" class="mq kz it mm b gy mv ms l mt mu">wiki_lst=[]<br/>title=[]<br/>for article in articles:<br/>   print("loading content: ",article)<br/>   wiki_lst.append(wikipedia.page(article).content)<br/>   title.append(article)</span><span id="0d64" class="mq kz it mm b gy mv ms l mt mu">print("examine content")<br/>wiki_lstAt the top of the github page there is a button that will allow you to execute the notebook in Google’s Colab. Feel free to experiment!</span></pre><h1 id="e055" class="ky kz it bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">2.将每篇文章表示为一个向量</h1><p id="80f8" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">因为我们要使用 k-means，所以我们需要将每篇文章表示为一个数字向量。一种流行的方法是使用<a class="ae ko" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank">词频/逆词频(tf-idf) </a>。简单地说，用这种方法对每个单词<em class="mw"> w </em>和文档<em class="mw"> d </em>我们计算:</p><p id="fac4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="mw"> tf(w，d):</em><em class="mw">d</em>中<em class="mw"> w </em>的出现次数除以<em class="mw">d</em>中总字数的比值</p><p id="5f75" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="mw"> idf(w): </em>文档总数除以包含<em class="mw"> w. </em>的文档数的分数的对数</p><p id="68a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="mw"> tfidf(w，d)=tf(w，d) x idf(w) </em></p><p id="e5a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">建议排除常见的停用词。所有的计算都可以通过 sklearn 的 tfidf 矢量器轻松完成。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="98b4" class="mq kz it mm b gy mr ms l mt mu">from sklearn.feature_extraction.text import TfidfVectorizer<br/>vectorizer = TfidfVectorizer(stop_words={'english'})<br/>X = vectorizer.fit_transform(wiki_lst)</span></pre><p id="4d81" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(说实话，sklearn 的计算略有不同。你可以在<a class="ae ko" href="https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction" rel="noopener ugc nofollow" target="_blank">文档</a>中读到。)</p><h1 id="4450" class="ky kz it bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">3.执行 k 均值聚类</h1><p id="f801" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">变量 X 的每一行都是维基百科文章的向量表示。因此，我们可以使用 X 作为 k-means 算法的输入。</p><p id="ef52" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，我们必须决定集群的数量。这里我们就用<a class="ae ko" href="https://en.wikipedia.org/wiki/Elbow_method_(clustering)" rel="noopener ugc nofollow" target="_blank">肘法</a>。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="9bb5" class="mq kz it mm b gy mr ms l mt mu">import matplotlib.pyplot as plt<br/>from sklearn.cluster import KMeans</span><span id="6fc1" class="mq kz it mm b gy mv ms l mt mu">Sum_of_squared_distances = []<br/>K = range(2,10)</span><span id="8736" class="mq kz it mm b gy mv ms l mt mu">for k in K:<br/>   km = KMeans(n_clusters=k, max_iter=200, n_init=10)<br/>   km = km.fit(X)<br/>   Sum_of_squared_distances.append(km.inertia_)</span><span id="5291" class="mq kz it mm b gy mv ms l mt mu">plt.plot(K, Sum_of_squared_distances, 'bx-')<br/>plt.xlabel('k')<br/>plt.ylabel('Sum_of_squared_distances')<br/>plt.title('Elbow Method For Optimal k')<br/>plt.show()</span></pre><figure class="mh mi mj mk gt my gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/b2b85905b817e8295612c6e9afd7cac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*Yg5DcZiAUv7w7Nar6aU_dQ.jpeg"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">每组数量的距离平方和图</p></figure><p id="8be2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">情节几乎是一条直线，可能是因为我们要的文章不多。但是在更近的观察中，当 k=4 或 k=6 时，出现了一个凹痕。我们将尝试分成 6 组。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="757e" class="mq kz it mm b gy mr ms l mt mu">true_k = 6<br/>model = KMeans(n_clusters=true_k, init='k-means++', max_iter=200, n_init=10)<br/>model.fit(X)<br/>labels=model.labels_<br/>wiki_cl=pd.DataFrame(list(zip(title,labels)),columns=['title','cluster'])<br/>print(wiki_cl.sort_values(by=['cluster']))</span></pre><figure class="mh mi mj mk gt my gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/3985faecbc17ea302f404bcf1ce7c356.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*BYkwhY6GhnjgYePKzVu7zg.jpeg"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">聚类结果</p></figure><h1 id="cc1a" class="ky kz it bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">4.评估结果</h1><p id="cf27" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">因为我们只使用了 10 篇文章，所以通过检查每个集群中包含哪些文章来评估集群是相当容易的。这对于大型语料库来说是很困难的。一个很好的方法是从每个集群的文章中创建一个词云。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="d837" class="mq kz it mm b gy mr ms l mt mu">from wordcloud import WordCloud<br/>result={'cluster':labels,'wiki':wiki_lst}<br/>result=pd.DataFrame(result)<br/>for k in range(0,true_k):<br/>   s=result[result.cluster==k]<br/>   text=s['wiki'].str.cat(sep=' ')<br/>   text=text.lower()<br/>   text=' '.join([word for word in text.split()])<br/>   wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white").generate(text)<br/>   print('Cluster: {}'.format(k))<br/>   print('Titles')<br/>   titles=wiki_cl[wiki_cl.cluster==k]['title']         <br/>   print(titles.to_string(index=False))<br/>   plt.figure()<br/>   plt.imshow(wordcloud, interpolation="bilinear")<br/>   plt.axis("off")<br/>   plt.show()</span></pre><figure class="mh mi mj mk gt my gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nk"><img src="../Images/f439b5b395f21249e9465575e8626364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P26SDjxYEsXVWIrk254jFw.jpeg"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">星团的文字云</p></figure><ul class=""><li id="4b0b" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn mb kv kw kx bi translated">集群 0 由关于欧洲中央银行、银行和国际货币基金组织的文章组成</li><li id="b8fb" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">集群 1 由关于人工智能和机器学习的文章组成</li><li id="ffbf" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">第二组有一篇关于游泳的文章</li><li id="69a4" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">集群 3 有一篇关于数据科学的文章</li><li id="c2ca" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">集群 4 有关于篮球和网球的文章</li><li id="e130" class="kp kq it js b jt mc jx md kb me kf mf kj mg kn mb kv kw kx bi translated">第五组有一篇关于金融科技的文章</li></ul><p id="2675" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">游泳不属于篮球和网球这一类似乎有点奇怪。或者说 AI 和机器学习跟数据科学不是一个群体。这是因为我们选择创建 6 个集群。但是通过查看单词 clouds，我们可以看到关于篮球和网球的文章中有一些单词是相同的，比如游戏、运动员、团队、球，而关于游泳的文章则没有。</p><p id="09ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在 GitHub 页面的顶部，有一个按钮，可以让你在谷歌的 Colab 中执行笔记本。您可以很容易地尝试不同数量的集群。结果可能会让你大吃一惊！</p></div></div>    
</body>
</html>