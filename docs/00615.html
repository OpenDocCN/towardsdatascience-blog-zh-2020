<html>
<head>
<title>Pytorch [Basics] — Intro to CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch【基础】CNN 简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-cnn-26a14c2ea29?source=collection_archive---------1-----------------------#2020-01-18">https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-cnn-26a14c2ea29?source=collection_archive---------1-----------------------#2020-01-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/840b4e62b667c78ce2f768c8b11e4488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Dsdw-L4qVhT1WkyLvtsPg.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">如何训练你的神经网络[图片[0]]</p></figure><h2 id="1db0" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/akshaj-wields-pytorch" rel="noopener" target="_blank">如何训练你的神经网络</a></h2><div class=""/><div class=""><h2 id="c2ac" class="pw-subtitle-paragraph kl jo jf bd b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dk translated">这篇博文将带你了解 PyTorch 中不同类型的 CNN 操作。</h2></div><p id="e140" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这篇博文中，我们将使用<code class="fe lz ma mb mc b">torch.nn</code>实现 1D 和 2D 卷积。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="376a" class="mk ml jf bd mm mn mo mp mq mr ms mt mu ku mv kv mw kx mx ky my la mz lb na nb bi translated">什么是 CNN？</h1><p id="e733" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">卷积神经网络是一种主要用于图像处理应用的神经网络。CNN 的其他应用包括音频、时间序列和 NLP 等序列数据。卷积是 CNN 的主要组成部分之一。术语卷积是指两个函数的数学组合产生第三个函数。它融合了两组信息。</p><p id="9c83" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们不会在这里讨论很多理论。关于这一点，网上有很多精彩的材料。</p><h1 id="2fda" class="mk ml jf bd mm mn nh mp mq mr ni mt mu ku nj kv mw kx nk ky my la nl lb na nb bi translated">CNN 运作的类型</h1><p id="cb45" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">CNN 主要用于围绕图像、音频、视频、文本和时间序列建模的应用。有 3 种卷积运算。</p><ul class=""><li id="1f7c" class="nm nn jf lf b lg lh lj lk lm no lq np lu nq ly nr ns nt nu bi translated"><strong class="lf jp"> 1D 卷积</strong> —主要用于文本或音频等连续输入的场合。</li><li id="1194" class="nm nn jf lf b lg nv lj nw lm nx lq ny lu nz ly nr ns nt nu bi translated"><strong class="lf jp"> 2D 卷积</strong> —主要用于输入为图像的情况。</li><li id="c079" class="nm nn jf lf b lg nv lj nw lm nx lq ny lu nz ly nr ns nt nu bi translated"><strong class="lf jp"> 3D 卷积</strong> —主要用于 3D 医学成像或检测视频中的事件。这超出了这篇博文的范围。我们将只关注前两个。</li></ul><h2 id="67c6" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">1D 输入的 1D 卷积</h2><p id="4cf1" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">滤波器沿一维滑动以产生输出。以下图表摘自<a class="ae ol" href="https://stackoverflow.com/questions/42883547/intuitive-understanding-of-1d-2d-and-3d-convolutions-in-convolutional-neural-n" rel="noopener ugc nofollow" target="_blank">这个 Stackoverflow 答案</a>。</p><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi om"><img src="../Images/e78ecf42c2c7807c692badf767e4f053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*a0R-aRq0BY0bdBqG.jpg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">1D 输入的 1D 卷积[图像[1] <a class="ae ol" href="https://stackoverflow.com/a/44628011/9193380" rel="noopener ugc nofollow" target="_blank">信用点</a></p></figure><h2 id="8998" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">2D 输入的 1D 卷积</h2><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi or"><img src="../Images/485d8ea484dc3665ed6e1b7bd573e796.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pdyLMJGsvEC5XQCC.jpg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">2D 输入的 1D 卷积[图像[2] <a class="ae ol" href="https://stackoverflow.com/a/44628011/9193380" rel="noopener ugc nofollow" target="_blank">信用点</a></p></figure><h2 id="8b9b" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">2D 输入的 2D 卷积</h2><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi os"><img src="../Images/101ca177218c5f2d17136f9f395d5d1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qz1re5CpYyfySuv8.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">2D 输入的 2D 卷积[图像[3] <a class="ae ol" href="https://stackoverflow.com/a/44628011/9193380" rel="noopener ugc nofollow" target="_blank">信用点</a></p></figure><p id="9872" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">查看这个<a class="ae ol" href="https://stackoverflow.com/questions/42883547/intuitive-understanding-of-1d-2d-and-3d-convolutions-in-convolutional-neural-n" rel="noopener ugc nofollow" target="_blank"> Stackoverflow 回答</a>以获得更多关于不同类型的 CNN 操作的信息。</p><h1 id="6438" class="mk ml jf bd mm mn nh mp mq mr ni mt mu ku nj kv mw kx nk ky my la nl lb na nb bi translated">几个关键术语</h1><p id="a5ae" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">术语解释了 2D 卷积和 2D 输入即。图像，因为我找不到 1D 卷积的相关可视化。所有的可视化都是从<a class="ae ol" rel="noopener" target="_blank" href="/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2">到这里</a>的。</p><h2 id="a3ca" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">卷积运算</h2><p id="48a5" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">要计算卷积运算后的输出维度，我们可以使用以下公式。</p><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ot"><img src="../Images/714e4df8c2252e35773891d8d401eccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/0*kB2slYSHvL1a0YYX.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">卷积输出公式[图像[4]]</p></figure><p id="c63d" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">内核/滤波器滑过输入信号，如下所示。你可以看到<strong class="lf jp">滤波器</strong>(绿色方块)滑过我们的<strong class="lf jp">输入</strong>(蓝色方块)，卷积的总和进入<strong class="lf jp">特征图</strong>(红色方块)。</p><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ou"><img src="../Images/914531f21581e0a4309a3d2d9759c889.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ao9wNdSdFAGTxxWH.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">卷积运算[图像[5]]</p></figure><h2 id="8481" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">过滤器/内核</h2><p id="48c1" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">使用滤波器对输入图像执行卷积。卷积的输出被称为特征图。</p><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ov"><img src="../Images/5156b9b0081e08d1ffb9311f023f3300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7iM_Q9VL-41qkJh4.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">过滤器[图像[6]]</p></figure><p id="624d" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在 CNN 术语中，3×3 矩阵被称为“<strong class="lf jp">滤波器</strong>”或“内核”或“特征检测器”，通过在图像上滑动滤波器并计算点积而形成的矩阵被称为“卷积特征”或“激活图”或“<strong class="lf jp">特征图</strong>”。重要的是要注意，过滤器充当来自原始输入图像的特征检测器。</p><blockquote class="ow"><p id="c8c5" class="ox oy jf bd oz pa pb pc pd pe pf ly dk translated">更多过滤器=更多特征地图=更多特征。</p></blockquote><p id="769b" class="pw-post-body-paragraph ld le jf lf b lg pg kp li lj ph ks ll lm pi lo lp lq pj ls lt lu pk lw lx ly ij bi translated">过滤器只不过是一个数字矩阵。以下是不同类型的过滤器—</p><figure class="on oo op oq gt is gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/901e02c04507f86a3c1f7b65b91aaf16.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*wFVu-TnKupy86DgZwvMcdw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">不同类型的过滤器[图片[7]]</p></figure><h2 id="21be" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">进展</h2><p id="a099" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated"><em class="pm">步幅</em>指定我们在每一步移动卷积滤波器的程度。</p><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pn"><img src="../Images/e017b602105447f35647f1ea7d20bd28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hXK5FklWY9oXi76K.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">步幅为 1[图片[8]]</p></figure><p id="a7ef" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">如果我们想减少感受野之间的重叠，我们可以有更大的进展。这也使得生成的特征地图更小，因为我们跳过了潜在的位置。下图演示了步幅为 2。请注意，特征图变小了。</p><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi po"><img src="../Images/563f230cda9d1385fbdbacab3d4adb46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1OyJLNiOwOtu-Hl5.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">步幅为 2[图片[9]]</p></figure><h2 id="77a8" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">填料</h2><p id="1ef7" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">这里我们保留了更多的边界信息，也保留了图像的大小。</p><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pp"><img src="../Images/af79dccddca2c834c141d0a3f8ec9220.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7asxOOK8kXrKhOic.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">填充[Image [10]]</p></figure><p id="fd96" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们看到特征映射的大小小于输入，因为卷积滤波器需要包含在输入中。如果我们想要保持相同的维度，我们可以使用<em class="pm">填充</em>用零包围输入。</p><h2 id="a8c0" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">联营</h2><p id="1361" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">我们应用池来降低维度。</p><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pq"><img src="../Images/b1be19dcffcc698deaf5232c8d1b6943.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lMlVQWvEoUyvr-nW.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">最大池[Image [11]]</p></figure><ul class=""><li id="ac5f" class="nm nn jf lf b lg lh lj lk lm no lq np lu nq ly nr ns nt nu bi translated">汇集减少了输入的大小，并使特征尺寸更小。</li><li id="33ef" class="nm nn jf lf b lg nv lj nw lm nx lq ny lu nz ly nr ns nt nu bi translated">由于空间尺寸减小，网络中的参数数量减少。这有助于防止过度拟合。</li><li id="b925" class="nm nn jf lf b lg nv lj nw lm nx lq ny lu nz ly nr ns nt nu bi translated">池化使网络对图像中的失真具有鲁棒性，因为我们采用了集合(最大值、总和、平均值等)。)的像素值。</li></ul><h1 id="38d4" class="mk ml jf bd mm mn nh mp mq mr ni mt mu ku nj kv mw kx nk ky my la nl lb na nb bi translated">导入库</h1><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="8f64" class="oa ml jf mc b gy pv pw l px py">import numpy as np</span><span id="b011" class="oa ml jf mc b gy pz pw l px py">import torch<br/>import torch.nn as nn<br/>import torch.optim as optim<br/>from torch.utils.data import Dataset, DataLoader</span></pre><h1 id="64c2" class="mk ml jf bd mm mn nh mp mq mr ni mt mu ku nj kv mw kx nk ky my la nl lb na nb bi translated">输入数据</h1><p id="4b44" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">首先，我们定义几个输入张量，我们将在这篇博文中使用它们。</p><p id="c689" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><code class="fe lz ma mb mc b">input_1d</code>是 1 维浮点张量。<code class="fe lz ma mb mc b">input_2d</code>是一个二维浮点张量。<code class="fe lz ma mb mc b">input_2d_img</code>是一个表示图像的三维浮动张量。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="dc2f" class="oa ml jf mc b gy pv pw l px py">input_1d = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype = torch.float)</span><span id="8c83" class="oa ml jf mc b gy pz pw l px py">input_2d = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]], dtype = torch.float)</span><span id="9ef6" class="oa ml jf mc b gy pz pw l px py">input_2d_img = torch.tensor([[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]], dtype = torch.float)<br/></span><span id="7a9c" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="cbc5" class="oa ml jf mc b gy pz pw l px py">Input 1D:</span><span id="6ef7" class="oa ml jf mc b gy pz pw l px py">input_1d.shape:  torch.Size([10])</span><span id="bd72" class="oa ml jf mc b gy pz pw l px py">input_1d: <br/> tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])<br/>====================================================================</span><span id="1ea1" class="oa ml jf mc b gy pz pw l px py">Input 2D:</span><span id="cb6e" class="oa ml jf mc b gy pz pw l px py">input_2d.shape:  torch.Size([2, 5])</span><span id="5d1e" class="oa ml jf mc b gy pz pw l px py">input_2d:<br/> tensor([[ 1.,  2.,  3.,  4.,  5.],<br/>        [ 6.,  7.,  8.,  9., 10.]])<br/>====================================================================</span><span id="1913" class="oa ml jf mc b gy pz pw l px py">input_2d_img:</span><span id="e5c0" class="oa ml jf mc b gy pz pw l px py">input_2d_img.shape:  torch.Size([3, 3, 10])</span><span id="bd70" class="oa ml jf mc b gy pz pw l px py">input_2d_img:<br/> tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],<br/>         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],<br/>         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]],</span><span id="ae40" class="oa ml jf mc b gy pz pw l px py">        [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],<br/>         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],<br/>         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]],</span><span id="e75c" class="oa ml jf mc b gy pz pw l px py">        [[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],<br/>         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],<br/>         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]])</span></pre><h1 id="f7b5" class="mk ml jf bd mm mn nh mp mq mr ni mt mu ku nj kv mw kx nk ky my la nl lb na nb bi translated">1D 卷积</h1><p id="b65e" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated"><code class="fe lz ma mb mc b">nn.Conv1d()</code>对输入应用 1D 卷积。<code class="fe lz ma mb mc b">nn.Conv1d()</code>期望输入是<code class="fe lz ma mb mc b">[batch_size, input_channels, signal_length]</code>的形状。</p><p id="f154" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">您可以在官方<a class="ae ol" href="https://pytorch.org/docs/stable/nn.html#conv1d" rel="noopener ugc nofollow" target="_blank"> PyTorch 文档</a>中查看完整的参数列表。所需的参数是—</p><ul class=""><li id="3f2a" class="nm nn jf lf b lg lh lj lk lm no lq np lu nq ly nr ns nt nu bi translated"><strong class="lf jp">in _ channels</strong>(<em class="pm">python:int</em>)—输入信号的通道数。这应该等于输入张量中的通道数。</li><li id="e044" class="nm nn jf lf b lg nv lj nw lm nx lq ny lu nz ly nr ns nt nu bi translated"><strong class="lf jp">out _ channels</strong>(<em class="pm">python:int</em>)—卷积产生的通道数。</li><li id="8332" class="nm nn jf lf b lg nv lj nw lm nx lq ny lu nz ly nr ns nt nu bi translated"><strong class="lf jp">kernel _ Size</strong>(<em class="pm">python:int 或 tuple </em> ) —卷积内核的大小。</li></ul><h2 id="2d67" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">Conv1d —输入 1d</h2><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qa"><img src="../Images/ad6951dc364b2842ac220079f40e03be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CXS4-2jpmMDe3rN3.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Conv1d-Input1d 示例[图像[12] <a class="ae ol" href="https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/1d-convolution-block" rel="noopener ugc nofollow" target="_blank">信用点</a></p></figure><p id="35dd" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">输入是由 10 个数字组成的 1D 信号。我们将把它转换成大小为[1，1，10]的张量。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="a2e4" class="oa ml jf mc b gy pv pw l px py">input_1d = input_1d.unsqueeze(0).unsqueeze(0)<br/>input_1d.shape<br/></span><span id="1f2a" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="c798" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 10])</span></pre><p id="8b4c" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 输出带<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=1</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=3</strong> </code>和<code class="fe lz ma mb mc b"><strong class="lf jp">stride=1</strong></code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="c013" class="oa ml jf mc b gy pv pw l px py">cnn1d_1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1)</span><span id="d79a" class="oa ml jf mc b gy pz pw l px py">print("cnn1d_1: \n")<br/>print(cnn1d_1(input_1d).shape, "\n")<br/>print(cnn1d_1(input_1d))<br/></span><span id="a8b7" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="c25d" class="oa ml jf mc b gy pz pw l px py">cnn1d_1: </span><span id="2813" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 8]) </span><span id="c847" class="oa ml jf mc b gy pz pw l px py">tensor([[[-1.2353, -1.4051, -1.5749, -1.7447, -1.9145, -2.0843, -2.2541, -2.4239]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><p id="9869" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 用<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=1</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=3</strong> </code>和<code class="fe lz ma mb mc b"><strong class="lf jp">stride=2</strong></code>输出。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="d850" class="oa ml jf mc b gy pv pw l px py">cnn1d_2 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=2)</span><span id="406c" class="oa ml jf mc b gy pz pw l px py">print("cnn1d_2: \n")<br/>print(cnn1d_2(input_1d).shape, "\n")<br/>print(cnn1d_2(input_1d))<br/></span><span id="c22a" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="ece3" class="oa ml jf mc b gy pz pw l px py">cnn1d_2: </span><span id="b8d1" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 4]) </span><span id="a4f6" class="oa ml jf mc b gy pz pw l px py">tensor([[[0.5107, 0.3528, 0.1948, 0.0368]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><p id="5d40" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">带<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=1</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=2</strong> </code>和<code class="fe lz ma mb mc b"><strong class="lf jp">stride=1</strong></code>的 CNN 输出。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="2c3a" class="oa ml jf mc b gy pv pw l px py">cnn1d_3 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=2, stride=1)</span><span id="ddb8" class="oa ml jf mc b gy pz pw l px py">print("cnn1d_3: \n")<br/>print(cnn1d_3(input_1d).shape, "\n")<br/>print(cnn1d_3(input_1d))<br/></span><span id="273a" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="c8e1" class="oa ml jf mc b gy pz pw l px py">cnn1d_3: </span><span id="4345" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 9]) </span><span id="4bbc" class="oa ml jf mc b gy pz pw l px py">tensor([[[0.0978, 0.2221, 0.3465, 0.4708, 0.5952, 0.7196, 0.8439, 0.9683, 1.0926]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><p id="05b8" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 用<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=5</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=3</strong> </code>和<code class="fe lz ma mb mc b"><strong class="lf jp">stride=2</strong></code>输出。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="05ef" class="oa ml jf mc b gy pv pw l px py">cnn1d_4 = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=3, stride=1)</span><span id="3794" class="oa ml jf mc b gy pz pw l px py">print("cnn1d_4: \n")<br/>print(cnn1d_4(input_1d).shape, "\n")<br/>print(cnn1d_4(input_1d))<br/></span><span id="5df8" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="b4a4" class="oa ml jf mc b gy pz pw l px py">cnn1d_4: </span><span id="0c9a" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 5, 8]) </span><span id="1a1b" class="oa ml jf mc b gy pz pw l px py">tensor([[[-1.8410e+00, -2.8884e+00, -3.9358e+00, -4.9832e+00, -6.0307e+00,-7.0781e+00, -8.1255e+00, -9.1729e+00],<br/>         [-4.6073e-02, -3.4436e-02, -2.2799e-02, -1.1162e-02,  4.7439e-04,1.2111e-02,  2.3748e-02,  3.5385e-02],<br/>         [-1.5541e+00, -1.8505e+00, -2.1469e+00, -2.4433e+00, -2.7397e+00, -3.0361e+00, -3.3325e+00, -3.6289e+00],<br/>         [ 6.6593e-01,  1.2362e+00,  1.8066e+00,  2.3769e+00,  2.9472e+00, 3.5175e+00,  4.0878e+00,  4.6581e+00],<br/>         [ 2.0414e-01,  6.0421e-01,  1.0043e+00,  1.4044e+00,  1.8044e+00,2.2045e+00,  2.6046e+00,  3.0046e+00]]], <br/>grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><h2 id="6df1" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">Conv1d —输入 2d</h2><p id="0405" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated">要对 2d 输入信号应用 1D 卷积，我们可以执行以下操作。首先，我们定义大小为[1，2，5]的输入张量，其中<code class="fe lz ma mb mc b">batch_size = 1</code>、<code class="fe lz ma mb mc b">input_channels = 2</code>和<code class="fe lz ma mb mc b">signal_length = 5</code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="6749" class="oa ml jf mc b gy pv pw l px py">input_2d = input_2d.unsqueeze(0)<br/>input_2d.shape<br/></span><span id="1aaf" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="8aa9" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 2, 5])</span></pre><p id="8850" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 输出有<code class="fe lz ma mb mc b"><strong class="lf jp">in_channels=2</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=1</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">stride=1</strong></code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="a11b" class="oa ml jf mc b gy pv pw l px py">cnn1d_5 = nn.Conv1d(in_channels=2, out_channels=1, kernel_size=3, stride=1)</span><span id="80c8" class="oa ml jf mc b gy pz pw l px py">print("cnn1d_5: \n")<br/>print(cnn1d_5(input_2d).shape, "\n")<br/>print(cnn1d_5(input_2d))<br/></span><span id="6b19" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="f6d2" class="oa ml jf mc b gy pz pw l px py">cnn1d_5: </span><span id="6487" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 3]) </span><span id="e7fe" class="oa ml jf mc b gy pz pw l px py">tensor([[[-6.6836, -7.6893, -8.6950]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><p id="592f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 输出有<code class="fe lz ma mb mc b"><strong class="lf jp">in_channels=2</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=1</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">stride=2</strong></code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="89a0" class="oa ml jf mc b gy pv pw l px py">cnn1d_6 = nn.Conv1d(in_channels=2, out_channels=1, kernel_size=3, stride=2)</span><span id="1836" class="oa ml jf mc b gy pz pw l px py">print("cnn1d_6: \n")<br/>print(cnn1d_6(input_2d).shape, "\n")<br/>print(cnn1d_6(input_2d))<br/></span><span id="25f0" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="47f0" class="oa ml jf mc b gy pz pw l px py">cnn1d_6: </span><span id="cc13" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 2]) </span><span id="d471" class="oa ml jf mc b gy pz pw l px py">tensor([[[-3.4744, -3.7142]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><p id="b0c3" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 输出有<code class="fe lz ma mb mc b"><strong class="lf jp">in_channels=2</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=1</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=2</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">stride=1</strong></code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="7e2a" class="oa ml jf mc b gy pv pw l px py">cnn1d_7 = nn.Conv1d(in_channels=2, out_channels=1, kernel_size=2, stride=1)</span><span id="4129" class="oa ml jf mc b gy pz pw l px py">print("cnn1d_7: \n")<br/>print(cnn1d_7(input_2d).shape, "\n")<br/>print(cnn1d_7(input_2d))<br/></span><span id="caae" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="e0dd" class="oa ml jf mc b gy pz pw l px py">cnn1d_7: </span><span id="3001" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 4]) </span><span id="44e7" class="oa ml jf mc b gy pz pw l px py">tensor([[[0.5619, 0.6910, 0.8201, 0.9492]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><p id="cccc" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 输出有<code class="fe lz ma mb mc b"><strong class="lf jp">in_channels=2</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=5</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">stride=1</strong></code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="528e" class="oa ml jf mc b gy pv pw l px py">cnn1d_8 = nn.Conv1d(in_channels=2, out_channels=5, kernel_size=3, stride=1)</span><span id="2144" class="oa ml jf mc b gy pz pw l px py">print("cnn1d_8: \n")<br/>print(cnn1d_8(input_2d).shape, "\n")<br/>print(cnn1d_8(input_2d))<br/></span><span id="2519" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="3d68" class="oa ml jf mc b gy pz pw l px py">cnn1d_8: </span><span id="f9ea" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 5, 3]) </span><span id="e135" class="oa ml jf mc b gy pz pw l px py">tensor([[[ 1.5024,  2.4199,  3.3373],<br/>         [ 0.2980, -0.0873, -0.4727],<br/>         [ 1.5443,  1.7086,  1.8729],<br/>         [ 2.6177,  3.2974,  3.9772],<br/>         [-2.5145, -2.2906, -2.0668]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><h1 id="7da4" class="mk ml jf bd mm mn nh mp mq mr ni mt mu ku nj kv mw kx nk ky my la nl lb na nb bi translated">2D 卷积</h1><p id="3128" class="pw-post-body-paragraph ld le jf lf b lg nc kp li lj nd ks ll lm ne lo lp lq nf ls lt lu ng lw lx ly ij bi translated"><code class="fe lz ma mb mc b">nn.Conv2d()</code>对输入应用 2D 卷积。<code class="fe lz ma mb mc b">nn.Conv2d()</code>期望输入为<code class="fe lz ma mb mc b">[batch_size, input_channels, input_height, input_width]</code>的形状。</p><p id="5977" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">您可以在官方<a class="ae ol" href="https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d" rel="noopener ugc nofollow" target="_blank"> PyTorch 文档</a>中查看完整的参数列表。所需的参数是—</p><ul class=""><li id="6da7" class="nm nn jf lf b lg lh lj lk lm no lq np lu nq ly nr ns nt nu bi translated"><strong class="lf jp">in _ channels</strong>(<em class="pm">python:int</em>)—2d 输入(如图像)中的通道数。</li><li id="0754" class="nm nn jf lf b lg nv lj nw lm nx lq ny lu nz ly nr ns nt nu bi translated"><strong class="lf jp">out _ channels</strong>(<em class="pm">python:int</em>)—卷积产生的通道数。</li><li id="c531" class="nm nn jf lf b lg nv lj nw lm nx lq ny lu nz ly nr ns nt nu bi translated"><strong class="lf jp">kernel _ Size</strong>(<em class="pm">python:int 或 tuple </em> ) —卷积内核的大小</li></ul><h2 id="e3c4" class="oa ml jf bd mm ob oc dn mq od oe dp mu lm of og mw lq oh oi my lu oj ok na jl bi translated">Conv2d —输入 2d</h2><figure class="on oo op oq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qb"><img src="../Images/02ac65d4faea2036b55a8a4e75f0f61a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zKUGeho8ljrTlS25"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">与 3 个通道卷积[图像[13] <a class="ae ol" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">信用点</a></p></figure><p id="629f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">要对 2d 输入信号(例如图像)应用 2D 卷积，我们可以执行以下操作。首先，我们定义大小为[1，3，3，10]的输入张量，其中有<code class="fe lz ma mb mc b">batch_size = 1</code>、<code class="fe lz ma mb mc b">input_channels = 3</code>、<code class="fe lz ma mb mc b">input_height = 3</code>和<code class="fe lz ma mb mc b">input_width = 10</code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="66dd" class="oa ml jf mc b gy pv pw l px py">input_2d_img = input_2d_img.unsqueeze(0)<br/>input_2d_img.shape<br/></span><span id="9308" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="53eb" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 3, 3, 10])</span></pre><p id="f7f6" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 输出有<code class="fe lz ma mb mc b"><strong class="lf jp">in_channels=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=1</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">stride=1</strong></code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="5e3d" class="oa ml jf mc b gy pv pw l px py">cnn2d_1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=1)</span><span id="dc70" class="oa ml jf mc b gy pz pw l px py">print("cnn2d_1: \n")<br/>print(cnn2d_1(input_2d_img).shape, "\n")<br/>print(cnn2d_1(input_2d_img))<br/></span><span id="0212" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="d9e3" class="oa ml jf mc b gy pz pw l px py">cnn2d_1: </span><span id="b69e" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 1, 8]) </span><span id="f5eb" class="oa ml jf mc b gy pz pw l px py">tensor([[[[-1.0716, -1.5742, -2.0768, -2.5793, -3.0819, -3.5844, -4.0870,-4.5896]]]], grad_fn=&lt;MkldnnConvolutionBackward&gt;)</span></pre><p id="f8b8" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 输出有<code class="fe lz ma mb mc b"><strong class="lf jp">in_channels=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=1</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">stride=2</strong></code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="0eb9" class="oa ml jf mc b gy pv pw l px py">cnn2d_2 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, stride=2)</span><span id="873a" class="oa ml jf mc b gy pz pw l px py">print("cnn2d_2: \n")<br/>print(cnn2d_2(input_2d_img).shape, "\n")<br/>print(cnn2d_2(input_2d_img))<br/></span><span id="2203" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="6f46" class="oa ml jf mc b gy pz pw l px py">cnn2d_2: </span><span id="f3d6" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 1, 4]) </span><span id="190d" class="oa ml jf mc b gy pz pw l px py">tensor([[[[-0.7407, -1.2801, -1.8195, -2.3590]]]],<br/>       grad_fn=&lt;MkldnnConvolutionBackward&gt;)</span></pre><p id="5135" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 输出有<code class="fe lz ma mb mc b"><strong class="lf jp">in_channels=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=1</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=2</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">stride=1</strong></code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="e15b" class="oa ml jf mc b gy pv pw l px py">cnn2d_3 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=2, stride=1)</span><span id="0e61" class="oa ml jf mc b gy pz pw l px py">print("cnn2d_3: \n")<br/>print(cnn2d_3(input_2d_img).shape, "\n")<br/>print(cnn2d_3(input_2d_img))<br/></span><span id="53cf" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="1b07" class="oa ml jf mc b gy pz pw l px py">cnn2d_3: </span><span id="93ff" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 1, 2, 9]) </span><span id="710f" class="oa ml jf mc b gy pz pw l px py">tensor([[[[-0.8046, -1.5066, -2.2086, -2.9107, -3.6127, -4.3147, -5.0167, -5.7188, -6.4208],<br/>          [-0.8046, -1.5066, -2.2086, -2.9107, -3.6127, -4.3147, -5.0167,-5.7188, -6.4208]]]], grad_fn=&lt;MkldnnConvolutionBackward&gt;)</span></pre><p id="e66b" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">CNN 输出有<code class="fe lz ma mb mc b"><strong class="lf jp">in_channels=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">out_channels=5</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">kernel_size=3</strong></code>、<code class="fe lz ma mb mc b"><strong class="lf jp">stride=1</strong></code>。</p><pre class="on oo op oq gt pr mc ps pt aw pu bi"><span id="894c" class="oa ml jf mc b gy pv pw l px py">cnn2d_4 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, stride=1)</span><span id="d541" class="oa ml jf mc b gy pz pw l px py">print("cnn2d_4: \n")<br/>print(cnn2d_4(input_2d_img).shape, "\n")<br/>print(cnn2d_4(input_2d_img))<br/></span><span id="dbd4" class="oa ml jf mc b gy pz pw l px py">###################### OUTPUT ######################</span><span id="0903" class="oa ml jf mc b gy pz pw l px py">cnn2d_4: </span><span id="3498" class="oa ml jf mc b gy pz pw l px py">torch.Size([1, 5, 1, 8]) </span><span id="8048" class="oa ml jf mc b gy pz pw l px py">tensor([[[[-2.0868e+00, -2.7669e+00, -3.4470e+00, -4.1271e+00, -4.8072e+00, -5.4873e+00, -6.1673e+00, -6.8474e+00]],</span><span id="cec7" class="oa ml jf mc b gy pz pw l px py">         [[-4.5052e-01, -5.5917e-01, -6.6783e-01, -7.7648e-01, -8.8514e-01, -9.9380e-01, -1.1025e+00, -1.2111e+00]],</span><span id="e935" class="oa ml jf mc b gy pz pw l px py">         [[ 6.6228e-01,  8.3826e-01,  1.0142e+00,  1.1902e+00,  1.3662e+00,1.5422e+00,  1.7181e+00,  1.8941e+00]],</span><span id="3ad3" class="oa ml jf mc b gy pz pw l px py">         [[-5.4425e-01, -1.2149e+00, -1.8855e+00, -2.5561e+00, -3.2267e+00, -3.8973e+00, -4.5679e+00, -5.2385e+00]],</span><span id="7981" class="oa ml jf mc b gy pz pw l px py">         [[ 2.0564e-01,  1.6357e-01,  1.2150e-01,  7.9434e-02,  3.7365e-02, -4.7036e-03, -4.6773e-02, -8.8842e-02]]]],<br/>       grad_fn=&lt;MkldnnConvolutionBackward&gt;)</span></pre></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><p id="243e" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">感谢您的阅读。欢迎提出建议和建设性的批评。:)<em class="pm"> </em>你可以在<a class="ae ol" href="https://www.linkedin.com/in/akshajverma7/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ol" href="https://twitter.com/theairbend3r" rel="noopener ugc nofollow" target="_blank">Twitter</a>T22】上找到我。</p><p id="cdfd" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">你也可以在这里查看我的其他博客。</p><figure class="on oo op oq gt is gh gi paragraph-image"><a href="https://www.buymeacoffee.com/theairbend3r"><div class="gh gi qc"><img src="../Images/041a0c7464198414e6ce355f9235099e.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*SGCT6C60o4t58wRqeU2viQ.png"/></div></a></figure></div></div>    
</body>
</html>