<html>
<head>
<title>Is Explainable AI (xAI) the Next Step, or Just Hype?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释的AI (xAI)是下一步，还是只是炒作？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/is-explainable-ai-xai-the-next-step-or-just-hype-b3d4c3768c62?source=collection_archive---------26-----------------------#2020-01-30">https://towardsdatascience.com/is-explainable-ai-xai-the-next-step-or-just-hype-b3d4c3768c62?source=collection_archive---------26-----------------------#2020-01-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/548f94e9db1a27bff2631daab064a965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A5SNkyi3s34NMb2YT78f0A.jpeg"/></div></div></figure><p id="51b3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">近年来，人工智能已经扩展到一系列不同程度的行业。一旦一项地平线技术(或许类似于我们现在看待<a class="ae kw" href="https://www.nytimes.com/2019/10/21/science/quantum-computer-physics-qubits.html" rel="noopener ugc nofollow" target="_blank">量子计算</a>的方式)人工智能正式突破了日常生活，知情的观点不再是技术爱好者和精英数据科学家的专利。现在，利益相关者包括高管、投资者、经理、政府，最终是客户。</p><p id="6cc2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">虽然关于可解释人工智能(xAI)的对话可以追溯到几十年前，但这个概念在2019年底重新焕发了活力，当时<a class="ae kw" href="https://cloud.google.com/blog/products/ai-machine-learning/google-cloud-ai-explanations-to-increase-fairness-responsibility-and-trust" rel="noopener ugc nofollow" target="_blank">谷歌宣布了</a>其面向开发者的新xAI工具集。xAI的概念相对简单:历史上，机器学习模型在“黑箱”内运行，结果由数量惊人的交织参数决定，这些参数如此复杂(以百万计)，以至于无法解释它们。xAI的目标是将透明性和字面解释设计到模型中，最终允许最终结果配备上下文。例如，xAI可能会确定一幅图像是一只狼，并给出解释:它是一种有着锋利牙齿和皮毛的动物，背景中有雪。</p><p id="c26f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">尽管xAI被认为是一种技术，但它同样可以被理解为一种最佳实践。人工智能在深陷伦理困境的领域表现优于人类，例如<a class="ae kw" href="https://hbr.org/2019/10/ai-can-outperform-doctors-so-why-dont-patients-trust-it" rel="noopener ugc nofollow" target="_blank">医疗</a>、<a class="ae kw" href="https://fortune.com/2019/10/10/artificial-intelligence-disruptive-force-finance-even-for-fintechs/" rel="noopener ugc nofollow" target="_blank">金融</a>和<a class="ae kw" href="https://www.wired.com/story/can-ai-be-fair-judge-court-estonia-thinks-so/" rel="noopener ugc nofollow" target="_blank">法律</a>。虽然实施技术来减少人类偏见和提高效率的承诺很诱人，但组织要为他们的决策(人类或机器人)负责，如果他们不能解释决策，他们就容易受到多重责任的影响。AI也许能够以一种比法官更公平的方式来设定保释金；然而，即使是AI也可能被糟糕的数据或过度拟合所误导，当AI导致不公平的判决、拒绝抵押贷款申请或误诊癌症时，问题就不可避免地出现了。错误是不可避免的，但解释错误对于任何这些高风险的环境也是必要的。</p><p id="0bde" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在极端情况之外，xAI为公司提供了一个扩展的功能类别来进行推广和销售。加内特预计，到2022年，全球人工智能经济将从2019年的1.2万亿美元扩大到<a class="ae kw" href="https://www.forbes.com/sites/alexknapp/2018/04/25/gartner-estimates-ai-business-value-to-reach-nearly-4-trillion-by-2022/#3eb979af33f9" rel="noopener ugc nofollow" target="_blank">的3.9万亿美元，每家公司都应该期待定义超越承诺结果的竞争模式。提供一个保证改进的黑盒人工智能模型可能很有诱惑力，但识别特定的高级功能为组织提供了谈话要点，以增强他们自己的营销和客户的意识。</a></p><h1 id="da80" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">赛的崛起</h1><p id="4f2b" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">这个时机或者说xAI的走红并不是巧合。近年来，公众对科技行业的看法在<a class="ae kw" href="https://www.pewresearch.org/fact-tank/2019/07/29/americans-have-become-much-less-positive-about-tech-companies-impact-on-the-u-s/" rel="noopener ugc nofollow" target="_blank">直线下降</a>，只有50%的参与者认为科技公司在美国产生了积极影响，低于四年前超过70%的比例。尽管许多公司适应这一趋势的速度很慢，但善于协调的领导者认识到了向问责和信任的转变。实施xAI让科技公司朝着这个方向前进，并在一个不可避免的问题上显示出主动性<a class="ae kw" href="https://www.darpa.mil/attachments/XAIProgramUpdate.pdf" rel="noopener ugc nofollow" target="_blank">政策</a>。</p><p id="a369" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2017年，谷歌宣布他们“人工智能优先”战略政策的决定似乎很大胆；然而，仅仅几年后，科技高管紧紧拥抱人工智能的概念似乎几乎在意料之中。自从世界上第一家公司开张以来(谷歌称它是1602年的荷兰东印度公司，至少是公开上市的)，领导者们一直依赖于财务信息灵通的决策。近年来，大数据和物联网的兴起为以前无法获得的见解打开了闸门；高管们调整了他们的语言，加入了“基于数据”的决策。接下来，自然进化是人工智能支持的决策。领导者应该向利益相关者、公众、媒体和法律讨论和捍卫自己的决策；这种期望不会随着复杂人工智能的引入而消失。</p><h1 id="608a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">使xAI有效</h1><p id="f875" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">为了让xAI变得可靠，它不能是临时添加的或者事后想到的。开发人员和工程师必须在他们构建的应用程序的设计和架构中实现xAI。同样需要注意的是，并不是每个人工智能项目都需要解释；在视频游戏、娱乐或生产分析类型中，xAI可能是笨重且成本过高的。</p><p id="7f47" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">人工智能和机器学习中一个反复出现的现象是无法解释“黑盒”内的操作，从而产生某些理想的结果。开发者社区的成员对xAI的承诺表示怀疑，认为有些模型太复杂了，无法解释，被迫解释会阻碍创造性的进步。在某些情况下，这无疑是正确的。这种现实是由我们对技术的原始理解造成的，还是一个更普遍、不可避免的原因有待讨论。</p><p id="2961" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">走向xAI并不要求工程师或架构师停止生产黑盒模型；它只是提高了最关键的面向公众的技术的标准，这些技术在严重依赖健全的道德规范的领域中运行。任何人工智能的理想结果和期望都应该在早期会议中确定，xAI应该是讨论的一部分。</p><p id="6a0f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一些项目可能需要专门为性能而设计的复杂的黑盒模型，而没有解释，而其他项目可能没有价值。每个项目都有独特的需求，xAI提供了多一层可能性。</p><p id="a729" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae kw" href="https://pixabay.com/photos/london-skyscraper-the-scalpel-sky-3833039/" rel="noopener ugc nofollow" target="_blank"> <em class="ma">标题图片</em> </a></p></div></div>    
</body>
</html>