<html>
<head>
<title>Spark Join Strategies — How &amp; What?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark加盟战略——方式和内容？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/strategies-of-spark-join-c0e7b4572bcf?source=collection_archive---------0-----------------------#2020-06-21">https://towardsdatascience.com/strategies-of-spark-join-c0e7b4572bcf?source=collection_archive---------0-----------------------#2020-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2482" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Spark加盟的内涵&amp; Spark的加盟策略选择</h2></div><p id="6bb5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在处理数据时，我们都处理过不同种类的连接，可能是<code class="fe lb lc ld le b">inner</code>、<code class="fe lb lc ld le b">outer</code>、<code class="fe lb lc ld le b">left</code>或(可能是)<code class="fe lb lc ld le b">left-semi</code>。本文介绍了Spark用来执行<code class="fe lb lc ld le b">join</code>操作的不同连接策略。了解spark join的内部机制有助于优化复杂的join操作，找到一些内存不足错误的根本原因，并提高spark作业的性能(我们都希望如此，不是吗？).请继续阅读，找出答案。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/dda9d4e88a45545e1ecd12f4599e51e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_yAhH8-uhQANHD0_fMPPKg.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Russ Ward在<a class="ae lv" href="/s/photos/spark?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="8871" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">Spark加盟策略:</h1><h1 id="d1ab" class="md me iq bd mf mg mv mi mj mk mw mm mn jw mx jx mp jz my ka mr kc mz kd mt mu bi translated"><strong class="ak">广播哈希连接</strong></h1><p id="0fd8" class="pw-post-body-paragraph kf kg iq kh b ki na jr kk kl nb ju kn ko nc kq kr ks nd ku kv kw ne ky kz la ij bi translated">在开始广播Hash join spark之前，让我们先了解一下<strong class="kh ir"> Hash Join，一般来说</strong>:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/e7ad5a26425c6f8d9851d755436a2495.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*pd-YlCGD9v3W4Lk1tfN72Q.jpeg"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">散列连接</p></figure><p id="83cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">顾名思义，散列连接是通过首先基于较小关系的join_key创建一个散列表，然后遍历较大关系以匹配散列join_key值来执行的。此外，这仅支持“=”联接。</p><p id="832a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在spark中，散列连接在每个节点级别起作用，该策略用于连接节点上可用的分区。</p><p id="8cfa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，来广播散列连接。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ng"><img src="../Images/7b321871de058a98265c8ea61e4ee2fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pO_40cT0UhaiSP0fdT-sWw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">广播散列连接</p></figure><p id="3704" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在广播散列连接中，其中一个<code class="fe lb lc ld le b">join</code>关系的副本被发送到所有工作节点<strong class="kh ir">，这节省了混洗成本</strong>。当您将一个大关系与一个小关系连接时，这很有用。这也称为映射端连接(将工作节点与映射器相关联)。</p><p id="00d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当其中一个<code class="fe lb lc ld le b">join</code>关系的大小小于阈值(默认为10 M)时，Spark部署这个连接策略。定义该阈值的火花属性是<code class="fe lb lc ld le b">spark.sql.autoBroadcastJoinThreshold</code>(可配置)。</p><p id="e8fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用BitTorrent协议在执行者之间共享广播关系(在这里阅读更多<a class="ae lv" href="https://en.wikipedia.org/wiki/BitTorrent" rel="noopener ugc nofollow" target="_blank"/>)。这是一种对等协议，其中文件块可以由对等方彼此共享。因此，它们不需要依赖单个节点。对等协议是这样工作的:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/246d422bfde4c5c0319800d2f07ef5dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*4rjIt2Putzaf2BM4Tl5ZJQ.jpeg"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">对等协议</p></figure><p id="9474" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">需要注意的事项:</p><ul class=""><li id="2235" class="ni nj iq kh b ki kj kl km ko nk ks nl kw nm la nn no np nq bi translated">广播的关系应该完全适合每个执行者和驱动程序的记忆。在驱动程序中，因为驱动程序将开始数据传输。</li><li id="f73a" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">仅支持“=”联接。</li><li id="4b2e" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">支持除完全外部联接之外的所有联接类型(内部、左侧、右侧)。</li><li id="e2eb" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">当广播大小较小时，它通常比其他连接策略更快。</li><li id="e636" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">关系的副本在网络上广播。因此，当广播大小很大时(例如，当明确指定使用广播加入/更改默认阈值时)，作为网络密集型操作可能会导致内存不足错误或性能问题。</li><li id="cb6c" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">广播后，您不能更改广播的关系。即使您这样做了，它们对工作节点也是不可用的(因为副本已经发布)。</li></ul><h1 id="c590" class="md me iq bd mf mg mv mi mj mk mw mm mn jw mx jx mp jz my ka mr kc mz kd mt mu bi translated"><strong class="ak">洗牌哈希加入</strong></h1><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nw"><img src="../Images/9c40182be0de816b9f39f92c5b7f43b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yjw7V8mh7FipB09ngnBn6A.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">无序散列连接</p></figure><p id="f432" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Shuffle Hash Join涉及在同一个executor节点中移动具有相同连接键值的数据，然后进行Hash Join(如上所述)。使用连接条件作为输出键，数据在执行器节点之间混洗，在最后一步，使用散列连接合并数据，因为我们知道相同键的数据将出现在同一个执行器中。</p><p id="0804" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">需要注意的事项:</p><ul class=""><li id="e35d" class="ni nj iq kh b ki kj kl km ko nk ks nl kw nm la nn no np nq bi translated">仅支持“=”联接。</li><li id="e4e6" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">连接键不需要是可排序的(这在下面会有意义)。</li><li id="192b" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">支持除完全外部联接之外的所有联接类型。</li><li id="ff12" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">在我看来，这是一种代价很高的连接方式，既涉及到洗牌又涉及到散列(如上所述的散列连接)。维护哈希表需要内存和计算。</li></ul><h1 id="3627" class="md me iq bd mf mg mv mi mj mk mw mm mn jw mx jx mp jz my ka mr kc mz kd mt mu bi translated"><strong class="ak">混洗排序合并连接</strong></h1><p id="6048" class="pw-post-body-paragraph kf kg iq kh b ki na jr kk kl nb ju kn ko nc kq kr ks nd ku kv kw ne ky kz la ij bi translated">让我们首先了解排序-合并连接</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/41cd8b8998b5704f132a72b7ca669b92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*03nmwDCmVaSDWVHMZTcFjA.jpeg"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">排序合并联接</p></figure><p id="2e1f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">排序连接包括，首先根据连接键对关系进行排序，然后合并两个数据集(考虑合并排序的合并步骤)。</p><p id="a662" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们来理解spark中的shuffle排序-合并连接策略:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nw"><img src="../Images/4c04a3bfade2e7484228a63029925b60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6RA2wnol2zhH4Ps2UNJoxQ.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">无序排序合并连接</p></figure><p id="4391" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">混洗排序-合并连接涉及混洗数据以获得相同工作者的相同join_key，然后在工作者节点中的分区级别执行排序-合并连接操作。</p><p id="668d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">需要注意的事项:</p><ul class=""><li id="8f77" class="ni nj iq kh b ki kj kl km ko nk ks nl kw nm la nn no np nq bi translated">从spark 2.3开始，这是spark中默认的连接策略，可以用<code class="fe lb lc ld le b">spark.sql.join.preferSortMergeJoin</code>禁用。</li><li id="00d5" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">仅支持“=”联接。</li><li id="efd6" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">连接键需要是可排序的(显然)。</li><li id="cf2a" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">支持所有连接类型。</li></ul><h1 id="c874" class="md me iq bd mf mg mv mi mj mk mw mm mn jw mx jx mp jz my ka mr kc mz kd mt mu bi translated">笛卡尔连接</h1><p id="0f11" class="pw-post-body-paragraph kf kg iq kh b ki na jr kk kl nb ju kn ko nc kq kr ks nd ku kv kw ne ky kz la ij bi translated">在这个策略中，计算两个关系的笛卡尔积(类似于SQL)来评估join。</p><h1 id="984e" class="md me iq bd mf mg mv mi mj mk mw mm mn jw mx jx mp jz my ka mr kc mz kd mt mu bi translated"><strong class="ak">广播嵌套循环连接</strong></h1><p id="bde7" class="pw-post-body-paragraph kf kg iq kh b ki na jr kk kl nb ju kn ko nc kq kr ks nd ku kv kw ne ky kz la ij bi translated">请将此视为两种关系的嵌套循环比较:</p><pre class="lg lh li lj gt ny le nz oa aw ob bi"><span id="a9f9" class="oc me iq le b gy od oe l of og">for record_1 in relation_1:<br/>  for record_2 in relation_2:<br/>    # join condition is executed</span></pre><p id="e098" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如你所见，这可能是一个非常缓慢的策略。这通常是在无法应用其他连接类型时的后备选项。Spark使用广播查询适当部分的<code class="fe lb lc ld le b"><a class="ae lv" href="https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-SparkPlan-BroadcastNestedLoopJoinExec.html" rel="noopener ugc nofollow" target="_blank">BroadcastNestedLoopJoinExe</a>c </code>操作符来处理这个问题，因此您可以认为至少会广播一些结果来提高性能。</p><p id="e252" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">需要注意的事项:</p><ul class=""><li id="9020" class="ni nj iq kh b ki kj kl km ko nk ks nl kw nm la nn no np nq bi translated">支持“=”和非等值联接(“≤=”、“</li><li id="1718" class="ni nj iq kh b ki nr kl ns ko nt ks nu kw nv la nn no np nq bi translated">支持所有连接类型</li></ul></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="2c8c" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">spark如何选择加盟策略？</h1><p id="023a" class="pw-post-body-paragraph kf kg iq kh b ki na jr kk kl nb ju kn ko nc kq kr ks nd ku kv kw ne ky kz la ij bi translated">直接取自spark <a class="ae lv" href="https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala#L111" rel="noopener ugc nofollow" target="_blank">代码</a>，让我们看看spark是如何决定加入策略的。</p><blockquote class="oh oi oj"><p id="d5ec" class="kf kg ok kh b ki kj jr kk kl km ju kn ol kp kq kr om kt ku kv on kx ky kz la ij bi translated">如果是“=”连接:</p><p id="5a7c" class="kf kg ok kh b ki kj jr kk kl km ju kn ol kp kq kr om kt ku kv on kx ky kz la ij bi translated">按照以下顺序查看<a class="ae lv" href="https://spark.apache.org/docs/latest/sql-performance-tuning.html#join-strategy-hints-for-sql-queries" rel="noopener ugc nofollow" target="_blank">连接提示</a>:<br/>1。广播提示:如果加入类型受支持，选择<code class="fe lb lc ld le b">broadcast hash join</code>。<br/> 2。排序合并提示:如果连接键是可排序的，选择<code class="fe lb lc ld le b">sort-merge join</code>。<br/> 3。无序散列提示:如果连接类型受支持，选择<code class="fe lb lc ld le b">shuffle hash join</code>。<br/> 4。shuffle replicate NL提示:如果连接类型是inner like，则选择<code class="fe lb lc ld le b">cartesian product</code>。</p><p id="dfd7" class="kf kg ok kh b ki kj jr kk kl km ju kn ol kp kq kr om kt ku kv on kx ky kz la ij bi translated">如果没有提示或提示不适用<br/> 1。如果一边足够小可以广播，并且支持加入类型，则选择<code class="fe lb lc ld le b">broadcast hash join</code>。<br/> 2。如果一边足够小，可以构建本地哈希映射，并且比另一边小得多，则选择<code class="fe lb lc ld le b">shuffle hash join</code>，并且<code class="fe lb lc ld le b">spark.sql.join.preferSortMergeJoin</code>为假。<br/> 3。如果连接键可排序，选择<code class="fe lb lc ld le b">sort-merge join</code>。<br/> 4。如果连接类型是内部，选择<code class="fe lb lc ld le b">cartesian product</code>。<br/> 5。选择<code class="fe lb lc ld le b">broadcast nested loop join</code>作为最终解决方案。它可能会爆炸，但没有其他选择。</p><p id="4a08" class="kf kg ok kh b ki kj jr kk kl km ju kn ol kp kq kr om kt ku kv on kx ky kz la ij bi translated">如果不是' =' join:</p><p id="af3c" class="kf kg ok kh b ki kj jr kk kl km ju kn ol kp kq kr om kt ku kv on kx ky kz la ij bi translated">看看<a class="ae lv" href="https://spark.apache.org/docs/latest/sql-performance-tuning.html#join-strategy-hints-for-sql-queries" rel="noopener ugc nofollow" target="_blank">加入提示</a>，按以下顺序:<br/> 1。广播提示:挑<code class="fe lb lc ld le b">broadcast nested loop join</code>。<br/> 2。shuffle replicate NL提示:如果连接类型是inner like，选择<code class="fe lb lc ld le b">cartesian product</code>。</p><p id="05bc" class="kf kg ok kh b ki kj jr kk kl km ju kn ol kp kq kr om kt ku kv on kx ky kz la ij bi translated">如果没有提示或提示不适用<br/> 1。如果一边足够小，可以播放，则选择<code class="fe lb lc ld le b">broadcast nested loop join</code>。<br/> 2。如果连接类型是内部相似，选择<code class="fe lb lc ld le b"> cartesian product</code>。<br/> 3。选择<code class="fe lb lc ld le b">broadcast nested loop join</code>作为最终解决方案。它可能会爆炸，但我们别无选择。</p></blockquote></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><p id="73a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">再见。</p></div></div>    
</body>
</html>