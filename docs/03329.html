<html>
<head>
<title>Learn how to read data into a Pandas DataFrame in 5 minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习如何在5分钟内将数据读入熊猫数据框</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learn-how-to-read-data-into-a-pandas-dataframe-in-5-minutes-122af8e0b9db?source=collection_archive---------18-----------------------#2020-03-30">https://towardsdatascience.com/learn-how-to-read-data-into-a-pandas-dataframe-in-5-minutes-122af8e0b9db?source=collection_archive---------18-----------------------#2020-03-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ecc4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从不同来源提取数据</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/694365c26dd1a125fa53afe24583fb77.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/0*miu7OIUgraivaOfj.jpg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated"><a class="ae ku" href="https://pixabay.com/illustrations/matrix-network-data-exchange-1027571/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h2 id="da2d" class="kv kw it bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">概观</h2><p id="f0b8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz le ma mb mc li md me mf lm mg mh mi mj im bi translated">据说数据科学家花费80%的时间对数据进行预处理，所以让我们深入研究数据预处理管道，也称为ETL管道，让我们找出哪个阶段花费的时间最多。在这篇博文中，我们将学习如何从不同的数据源中提取数据。让我们来看一个真实的数据集，这样更容易理解。</p><p id="1833" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">本课使用了世界银行的数据。数据来自两个来源:</p><ol class=""><li id="661f" class="mp mq it lt b lu mk lx ml le mr li ms lm mt mj mu mv mw mx bi translated"><a class="ae ku" href="https://data.worldbank.org/indicator" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">世界银行指标数据</strong> </a> —该数据包含世界各国的社会经济指标。一些示例指标包括人口、可耕地和中央政府债务。</li><li id="2cd8" class="mp mq it lt b lu my lx mz le na li nb lm nc mj mu mv mw mx bi translated"><a class="ae ku" href="https://datacatalog.worldbank.org/dataset/world-bank-projects-operations" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">世界银行项目数据</strong> </a> —该数据集包含1947年以来世界银行项目贷款的相关信息。</li></ol><h2 id="6961" class="kv kw it bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">数据文件的类型</h2><ol class=""><li id="52d8" class="mp mq it lt b lu lv lx ly le nd li ne lm nf mj mu mv mw mx bi translated"><strong class="lt iu"> CSV </strong> — CSV代表逗号分隔值。这是文件的外观</li></ol><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0011" class="kv kw it nh b gy nl nm l nn no">id,regionname,countryname,prodline,lendinginstr<br/>P162228,Other,World;World,RE,Investment Project Financing<br/>P163962,Africa,Democratic Republic of the Congo;Democratic Republic of the Congo,PE,Investment Projec</span></pre><p id="c999" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">让我们用pandas加载这个文件。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="6e4a" class="kv kw it nh b gy nl nm l nn no">import pandas as pd<br/>df_projects = pd.read_csv('../data/projects_data.csv')</span><span id="ecf7" class="kv kw it nh b gy np nm l nn no">#ERROR:<br/>#/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.interactivity=interactivity, compiler=compiler, result=result)</span></pre><p id="e5a5" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">我们将得到一个DType警告错误。基本上，pandas会计算出我们文件的数据类型，并适当地读取它们，但是我们的一个列有多种数据类型，因此会出现警告错误。我们可以在读取时传递字符串的数据类型。请参考熊猫<a class="ae ku" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.errors.DtypeWarning.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">文档</strong> </a> <strong class="lt iu"> </strong>阅读更多。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c636" class="kv kw it nh b gy nl nm l nn no">df_projects = pd.read_csv('../data/projects_data.csv',dtype=str)</span></pre><p id="957e" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated"><strong class="lt iu">输出:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/94f0d820e56795f8d472471227744131.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NPoRGmUwKgg1SRgtRYoAkg.png"/></div></div></figure><p id="7c25" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">让我们阅读另一个CSV文件:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c0ef" class="kv kw it nh b gy nl nm l nn no">df_population = pd.read_csv("../data/population_data.csv")<br/># ParserError: Error tokenizing data. C error: Expected 3 fields in line 5, saw 63</span></pre><p id="da95" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">看起来这个CSV文件有问题。让我们检查一下里面的东西。这里，如果文件很小，您可以使用记事本/excel直接打开CSV文件，也可以使用下面的python代码:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c078" class="kv kw it nh b gy nl nm l nn no">with open("../data/population_data.csv") as f:<br/>    lis = [line.split() for line in f]        # create a list of lists<br/>    #print(lis)<br/>    for i, x in enumerate(lis):              #print the list items <br/>        print ("line{0} = {1}".format(i, x))</span><span id="3ec7" class="kv kw it nh b gy np nm l nn no">#Output:</span><span id="002f" class="kv kw it nh b gy np nm l nn no">line0 = ['\ufeff"Data', 'Source","World', 'Development', 'Indicators",']<br/>line1 = []<br/>line2 = ['"Last', 'Updated', 'Date","2018-06-28",']<br/>line3 = []<br/>line4 = ['"Country', 'Name","Country', 'Code","Indicator', 'Name","Indicator', 'Code","1960","1961","1962","1963","1964","1965","1966","1967","1968","1969","1970","1971","1972","1973","1974","1975","1976","1977","1978","1979","1980","1981","1982","1983","1984","1985","1986","1987","1988","1989","1990","1991","1992","1993","1994","1995","1996","1997","1998","1999","2000","2001","2002","2003","2004","2005","2006","2007","2008","2009","2010","2011","2012","2013","2014","2015","2016","2017",']</span></pre><p id="8d43" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">看起来CSV文件的前4行已损坏。因此，我们可以通过使用<strong class="lt iu">skip prows</strong>参数跳过前4行。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0933" class="kv kw it nh b gy nl nm l nn no">df_population = pd.read_csv("../data/population_data.csv",skiprows=4)</span></pre><p id="05dd" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated"><strong class="lt iu">输出:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nv"><img src="../Images/0c05761aa265e42fcc58f40d1463198d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tbF7fdwXcjKzd2RIcMzpXQ.png"/></div></div></figure><p id="d0b7" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated"><strong class="lt iu"> 2。JSON </strong> —它是一种带有键/值对的文件格式。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="fffa" class="kv kw it nh b gy nl nm l nn no">[{"id":"P162228","regionname":"Other","countryname":"World;World","prodline":"RE","lendinginstr":"Investment Project Financing"},{"id":"P163962","regionname":"Africa","countryname":"Democratic Republic of the Congo;Democratic Republic of the Congo","prodline":"PE","lendinginstr":"Investment Project Financing"},{"id":"P167672","regionname":"South Asia","countryname":"People\'s Republic of Bangladesh;People\'s Republic of Bangladesh","prodline":"PE","lendinginstr":"Investment Project Financing"}]</span></pre><p id="851b" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">谢天谢地，熊猫有直接读取<a class="ae ku" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> JSON </strong> </a>的功能。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="385c" class="kv kw it nh b gy nl nm l nn no">import pandas as pd<br/>df_json = pd.read_json('population_data.json',orient='records')</span></pre><p id="42c9" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">其他方法:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="b795" class="kv kw it nh b gy nl nm l nn no">import json</span><span id="3fe5" class="kv kw it nh b gy np nm l nn no"># read in the JSON file<br/>with open('population_data.json') as f:<br/>    json_data = json.load(f)</span><span id="d824" class="kv kw it nh b gy np nm l nn no"># print the first record in the JSON file<br/>print(json_data[0])</span></pre><p id="5468" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">3.<strong class="lt iu"> XML </strong> —另一种数据格式叫做XML(可扩展标记语言)。至少在格式方面，XML和HTML非常相似。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f078" class="kv kw it nh b gy nl nm l nn no">&lt;ENTRY&gt;<br/>  &lt;ID&gt;P162228&lt;/ID&gt;<br/>  &lt;REGIONNAME&gt;Other&lt;/REGIONNAME&gt;<br/>  &lt;COUNTRYNAME&gt;World;World&lt;/COUNTRYNAME&gt;<br/>  &lt;PRODLINE&gt;RE&lt;/PRODLINE&gt;<br/>  &lt;LENDINGINSTR&gt;Investment Project Financing&lt;/LENDINGINSTR&gt;<br/>&lt;/ENTRY&gt;<br/>&lt;ENTRY&gt;<br/>  &lt;ID&gt;P163962&lt;/ID&gt;<br/>  &lt;REGIONNAME&gt;Africa&lt;/REGIONNAME&gt;<br/>  &lt;COUNTRYNAME&gt;Democratic Republic of the Congo;Democratic Republic of the Congo&lt;/COUNTRYNAME&gt;<br/>  &lt;PRODLINE&gt;PE&lt;/PRODLINE&gt;<br/>  &lt;LENDINGINSTR&gt;Investment Project Financing&lt;/LENDINGINSTR&gt;<br/>&lt;/ENTRY&gt;</span></pre><p id="9bed" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">有一个名为BeautifulSoup的Python库，它使得读入和解析XML数据变得更加容易。以下是文档链接:<a class="ae ku" href="https://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank">美汤文档</a></p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="aa4e" class="kv kw it nh b gy nl nm l nn no"># import the BeautifulSoup library<br/>from bs4 import BeautifulSoup</span><span id="a684" class="kv kw it nh b gy np nm l nn no"># open the population_data.xml file and load into Beautiful Soup<br/>with open("population_data.xml") as fp:<br/>    soup = BeautifulSoup(fp, "lxml") # lxml is the Parser type</span></pre><p id="d0a6" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">让我们看看汤是什么样子的:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="bc44" class="kv kw it nh b gy nl nm l nn no">&lt;html&gt;&lt;body&gt;&lt;p&gt;﻿&lt;?xml version="1.0" encoding="utf-8"?&gt;<br/>&lt;root xmlns:wb="http://www.worldbank.org"&gt;<br/>&lt;data&gt;<br/>&lt;record&gt;<br/>&lt;field key="ABW" name="Country or Area"&gt;Aruba&lt;/field&gt;<br/>&lt;field key="SP.POP.TOTL" name="Item"&gt;Population, total&lt;/field&gt;<br/>&lt;field name="Year"&gt;1960&lt;/field&gt;<br/>&lt;field name="Value"&gt;54211&lt;/field&gt;<br/>&lt;/record&gt;<br/>&lt;record&gt;<br/>&lt;field key="ABW" name="Country or Area"&gt;Aruba&lt;/field&gt;<br/>&lt;field key="SP.POP.TOTL" name="Item"&gt;Population, total&lt;/field&gt;<br/>&lt;field name="Year"&gt;1961&lt;/field&gt;<br/>&lt;field name="Value"&gt;55438&lt;/field&gt;<br/>&lt;/record&gt;</span></pre><p id="0efe" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">如何将XML作为数据帧读取？</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="792a" class="kv kw it nh b gy nl nm l nn no">data_dictionary = {'Country or Area':[], 'Year':[], 'Item':[], 'Value':[]}</span><span id="a581" class="kv kw it nh b gy np nm l nn no">for record in soup.find_all('record'):<br/>    for record in record.find_all('field'):<br/>        data_dictionary[record['name']].append(record.text)</span><span id="ffc5" class="kv kw it nh b gy np nm l nn no">df = pd.DataFrame.from_dict(data_dictionary)<br/>df = df.pivot(index='Country or Area', columns='Year', values='Value')</span><span id="c03e" class="kv kw it nh b gy np nm l nn no">df.reset_index(level=0, inplace=True)</span></pre><p id="3a94" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">基本上，我们需要为每一列或每一行创建一个字典，然后将字典转换为dataframe。</p><p id="0c90" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated"><strong class="lt iu">输出:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/5ec29f6e0b1947f46d69fcbcfa82d2d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*51nevJNEw1YjBqlESdVO1Q.png"/></div></figure><p id="86bf" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">4.<strong class="lt iu"> SQL </strong> — SQL数据库使用<a class="ae ku" href="https://docs.microsoft.com/en-us/sql/relational-databases/tables/primary-and-foreign-key-constraints?view=sql-server-2017" rel="noopener ugc nofollow" target="_blank">主键和外键</a>在表中存储数据</p><p id="7adf" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">要从SQL数据库中读取数据，您需要将数据存储在数据库中。要了解如何将CSV转换为SQL DB，请阅读这篇<a class="ae ku" href="https://medium.com/swlh/how-to-insert-data-from-csv-file-into-a-sqlite-database-using-python-82f7d447866a" rel="noopener"> <strong class="lt iu">博客</strong> </a>。</p><p id="c686" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated"><strong class="lt iu"> SQLite3对熊猫</strong></p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ec2e" class="kv kw it nh b gy nl nm l nn no">import sqlite3<br/>import pandas as pd</span><span id="faae" class="kv kw it nh b gy np nm l nn no"># connect to the database<br/>conn = sqlite3.connect('population_data.db')</span><span id="764f" class="kv kw it nh b gy np nm l nn no"># run a query<br/>pd.read_sql('SELECT * FROM population_data', conn)</span></pre><p id="536a" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated"><strong class="lt iu">对熊猫的SQLAlchemy</strong></p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="8d1e" class="kv kw it nh b gy nl nm l nn no">import pandas as pd<br/>from sqlalchemy import create_engine</span><span id="960e" class="kv kw it nh b gy np nm l nn no">engine=create_engine('sqlite:////home/workspace/3_sql_exercise/population_data.db')<br/>pd.read_sql("SELECT * FROM population_data", engine)</span></pre><p id="c8a6" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">5.从网络中提取数据是一个非常累人的过程。但是很多公司已经通过API公开了他们的数据。API通常以JSON或XML格式提供数据。有些API是公共的，您不需要登录，而有些是私有的，用户需要生成一个API密钥。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="34ec" class="kv kw it nh b gy nl nm l nn no">import requests<br/>import pandas as pd</span><span id="084b" class="kv kw it nh b gy np nm l nn no">url = '<a class="ae ku" href="http://api.worldbank.org/v2/countries/br;cn;us;de/indicators/SP.POP.TOTL/?format=json&amp;per_page=1000'" rel="noopener ugc nofollow" target="_blank">http://api.worldbank.org/v2/countries/br;cn;us;de/indicators/SP.POP.TOTL/?format=json&amp;per_page=1000'</a><br/>r = requests.get(url)<br/>r.json()</span></pre><p id="17d6" class="pw-post-body-paragraph lr ls it lt b lu mk ju lw lx ml jx lz le mm mb mc li mn me mf lm mo mh mi mj im bi translated">不同网站的API调用是不同的，这里我们使用请求库来获取JSON格式的数据。在这里 阅读更多关于不同API结构的信息<a class="ae ku" href="https://datahelpdesk.worldbank.org/knowledgebase/articles/898581-api-basic-call-structure" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"/></a></p></div></div>    
</body>
</html>