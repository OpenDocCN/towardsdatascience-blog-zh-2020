<html>
<head>
<title>American Sign Language Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">美国手语识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/american-sign-language-recognition-using-cnn-36910b86d651?source=collection_archive---------21-----------------------#2020-04-26">https://towardsdatascience.com/american-sign-language-recognition-using-cnn-36910b86d651?source=collection_archive---------21-----------------------#2020-04-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="67d8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一篇关于使用 CNN 识别美国手语并在数据集上比较 CNN 的各种架构的性能的详细文章。</h2></div><p id="b1e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">国家耳聋和其他交流障碍研究所(NIDCD)指出，有 200 年历史的美国手语是一种完整、复杂的语言(字母手势只是其中的一部分)，但却是许多失聪的北美人的主要语言。因此，建立一个可以识别手语的系统将有助于聋人和重听人利用现代技术更好地交流。在这篇文章中，我们将通过 CNN 的不同架构，看看它如何对手语进行分类。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/5df9fce63674f37980f396f3772f3c48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*MLudTwKUYiCYQE0cV7p6aQ.png"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">美国手语手势(<a class="ae ln" href="https://www.kaggle.com/datamunge/sign-language-mnist#amer_sign2.png" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/data munge/Sign-Language-mnist # Amer _ Sign 2 . png</a>)</p></figure><h1 id="01f4" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">关于数据集:</h1><p id="9c4c" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">数据集可以从<a class="ae ln" href="https://www.kaggle.com/datamunge/sign-language-mnist" rel="noopener ugc nofollow" target="_blank"> <em class="ml"> Kaggle 的网站</em> </a> <em class="ml">访问。</em>训练数据集包含 27455 幅图像和 785 列，而测试数据集包含 7172 幅图像和 785 列。数据集的第一列包含图像的标签，而其余的 784 列表示展平的 28，28 图像。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mm"><img src="../Images/e7dbf871e3b8c454859bae2b307e080a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ldU9zpi6P79WXDY5yRjFVA.png"/></div></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">数据中的随机样本。</p></figure><p id="f702" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看数据集的分布:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mr"><img src="../Images/f8d2243563147af3d08d8f1637fc0fc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9aOdkI2Ro05tqsPDznwbFQ.png"/></div></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">来自训练数据集的不同字母的计数。请注意，字母 J (9)和 Z(25)不在数据集中。可以看出，数据的分布是均匀的。</p></figure></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="0ec3" class="lo lp iq bd lq lr mz lt lu lv na lx ly jw nb jx ma jz nc ka mc kc nd kd me mf bi translated">开发神经网络模型:</h1><p id="5042" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">模型的输入层将获取大小为(28，28，1)的图像，其中 28，28 分别是图像的高度和宽度，而 1 表示图像的灰度颜色通道。</p><p id="3886" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">模型的输出层将具有用于 26 个不同字母的 26 个神经元，并且激活函数将是 softmax，因为它是多类分类问题。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">美国手语识别的基本 CNN 结构。</p></figure><h1 id="7bc2" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">编译和训练模型:</h1><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">编译和训练模型</p></figure><p id="618e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">模型的训练精度为 100%，而模型的测试精度为 91%。这显然是一个过度拟合的情况。下一步，我们将使用数据扩充来解决过拟合问题。</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="dac4" class="lo lp iq bd lq lr mz lt lu lv na lx ly jw nb jx ma jz nc ka mc kc nd kd me mf bi translated">数据扩充:</h1><p id="2a95" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">测试数据集中可能存在一些在训练数据集中不可用的图像特征/方向。因此，我们的模型无法识别这些模式。这可以通过增加数据来解决。数据扩充是训练神经网络的重要步骤。例如，在训练数据集中，我们有右手的手势，但在现实世界中，我们可以从右手和左手都获得图像。数据扩充允许我们通过旋转、翻转、缩放、裁剪、标准化等方式创建不可预见的数据。</p><p id="b49b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Tensorflow 提供了 ImageDataGenerator 函数，该函数在流上增加内存中的数据，而无需修改本地数据。这也给了我们尝试不同增强参数的空间。我们将扩充数据，并将其分为 80%的训练和 20%的验证。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">扩亚分裂。</p></figure><p id="5414" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">扩充数据后，100 个周期后的训练准确率为 93.5%，测试准确率在 97.8 %左右。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/2af27ace61b300d54ff4dc5fabfabc64.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*tKNUcIWg9OUd-BhEHhwdwA.png"/></div></figure><p id="2369" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这当然解决了过度拟合的问题，但是花费了更多的时间。有没有一种方法可以在更少的时期内训练我们的模型？是的，批量标准化是我们问题的答案。</p><h1 id="9aac" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">批量标准化:</h1><p id="a16d" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">批量标准化允许标准化隐藏层的输入。从上面的模型中，我们可以看到，通过数据扩充，我们可以解决过度拟合训练数据的问题，但需要更多的时间进行训练。批量规格化通过规格化隐藏层的权重解决了这个问题。你可以在这里阅读更多关于它如何影响一个模型的性能<a class="ae ln" href="https://medium.com/analytics-vidhya/getting-it-to-top-6-in-kaggles-mnist-digit-recognizer-from-scratch-3-8b11b79958a2" rel="noopener">。</a></p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/282d63c895b48ce5bb652a37500479e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*ETFOfdEni-RBbUVlp-D5OA.png"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">批量标准化的准确性</p></figure><p id="ecfa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">包含批量归一化后的训练准确率为 99.27，测试准确率为 99.81。这仅需要 40 个历元，几乎一半的时间没有批量归一化。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/d5f862e4652eb248383a4098ea7075aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*7W6yxUzyXS6VYKH_SYXi6A.png"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">批量标准化模型的损失图</p></figure><p id="bf31" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们仔细观察图表，在 15 个历元之后，损失没有显著减少。因此，我们可以在 15/20 周期后使用早期停止来停止训练。这几乎是不进行批量标准化时的 1/5。</p><p id="5493" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">问题:</strong>验证精度波动很大，根据停止训练的型号，测试精度可能会更高或更低。这是由于较大的学习率导致模型超过最优值。这可以使用在每个时期后下降某个值的衰减学习率来解决。</p><h2 id="e904" class="ni lp iq bd lq nj nk dn lu nl nm dp ly ko nn no ma ks np nq mc kw nr ns me nt bi translated">衰减学习率</h2><p id="048a" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我们可以在 Tensorflow 中实现衰减学习率，如下所示:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">衰减学习率</p></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/bf3c2138bb4f3e3f632029360a314fec.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*iJYx5yquJqDm0A7pCw5I8Q.png"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">使用学习率衰减的模型的准确性</p></figure><p id="86db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">准确性以及训练和验证准确性的损失在 20 个时期结束时已经收敛。这让我们对我们的结果更有信心，因为与之前的图相比，这些图更平滑。使用相同配置的训练准确率为 99.88，测试准确率也为 99.88。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/b7ceea54a7ad8aeb633c1c4e65112ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*Zr-h1TPpP4tqJOUV024JnA.png"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">使用学习率衰减的模型丢失</p></figure><p id="6273" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用学习率衰减和不使用学习率衰减的模型之间的准确性没有太大差别，但是与不使用学习率衰减的模型相比，使用学习率衰减的模型有更高的机会达到最优。因此对结果更有信心。</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="4815" class="lo lp iq bd lq lr mz lt lu lv na lx ly jw nb jx ma jz nc ka mc kc nd kd me mf bi translated">CNN 的不同架构及其准确性:</h1><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="375e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以找到关于本文的 Kaggle 内核:<a class="ae ln" href="https://www.kaggle.com/rushikesh0203/mnist-sign-language-recognition-cnn-99-94-accuracy" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/rushikesh 0203/mnist-sign-language-recognition-CNN-99-94-accuracy</a></p><p id="becb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以在 GitHub repo 中找到完整的项目以及不同型号的 Jupiter 笔记本:<a class="ae ln" href="https://github.com/Heisenberg0203/AmericanSignLanguage-Recognizer" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/Heisenberg 0203/AmericanSignLanguage-Recognizer</a></p><blockquote class="nv nw nx"><p id="d0a3" class="kf kg ml kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">如果你喜欢这篇文章，请随时与他人分享。</p></blockquote></div></div>    
</body>
</html>