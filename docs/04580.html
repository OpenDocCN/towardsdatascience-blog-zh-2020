<html>
<head>
<title>Building a Distance Violation Detector (D.V.D)for a post-Lockdown era</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为后锁定时代构建距离违例检测器(D.V.D)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-distance-violation-detector-d-v-d-for-a-post-lockdown-era-5b9894f5a6b1?source=collection_archive---------29-----------------------#2020-04-23">https://towardsdatascience.com/building-a-distance-violation-detector-d-v-d-for-a-post-lockdown-era-5b9894f5a6b1?source=collection_archive---------29-----------------------#2020-04-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0fb7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">人工智能驱动的解决物理距离“问题”的方法</h2></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/78e8adee9dd2085f24b3f6be16c16fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*spo-4qBsZy2rjzx5QuyWsw.png"/></div></div></figure><p id="491a" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">随着各国开始有放松封锁规范的想法，最终外出的人之间保持5英尺或以上的物理距离可能在阻止新冠肺炎传播方面发挥关键作用。</p><p id="772d" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我第一次接触到这个想法是在加利福尼亚州旧金山的一家计算机软件公司。该程序通过闭路电视监控录像实时监控和跟踪人群，寻找相互之间距离小于5-6英尺的人群。在这些团体上画一个红框，以告知监督当局。</p><p id="4b95" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">一个人不断监控安全摄像头以识别红色块的违规行为听起来可能像是浪费宝贵的人力资源。因此，我在程序中集成了一个邮件功能，一旦发现违规行为，它会立即通知当局。违规的定义可根据地方当局设定的标准来设定，这些标准可能从两人一起步行到超过20人的聚会不等。下面是代码和解释。已经在Google Collab上用GPU运行时编译过了。</p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="5973" class="lz ma iq lv b gy mb mc l md me">import time<br/>import smtplib<br/>from email.mime.multipart import MIMEMultipart<br/>from email.mime.text import MIMEText<br/>from email.mime.base import MIMEBase<br/>from email import encoders<br/>from google.colab.patches import cv2_imshow<br/>from google.colab import drive<br/>import pandas as pd<br/>import cv2<br/>import math<br/>import numpy as np<br/>drive.mount(“/GD”)</span></pre><p id="9413" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我决定使用一个非常简单的分类器，即哈尔级联分类器，用于全身检测，这是由(Paul Viola，2001)开发的预训练分类器。如果你想了解更多关于这个分类器上的检测模块的信息，你可以在<a class="ae mf" href="https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html" rel="noopener ugc nofollow" target="_blank">这里</a>阅读。这可以在OpenCV库中找到。最近的发展已经产生了更好和更快的分类器，比如更快的R-CNN和YOLO，我将尝试在未来的版本中使用它们来改进这个模型。</p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="5058" class="lz ma iq lv b gy mb mc l md me">person_clf = cv2.CascadeClassifier(‘/GD/MyDrive/dataset/haarcascade_fullbody.xml')<br/># Initiate video capture for video file<br/>cap = cv2.VideoCapture(‘/GD/My Drive/dataset/mall_walking.avi’)<br/>writer = None<br/>OUTPUT=’/GD/My Drive/dataset/output_’+str(YOUROUTPUTFILENAMEHERE)</span></pre><p id="7521" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这里，分类器的一个实例已经加载到person_clf中，并且已经设置了带有违规标记的已分析视频的输出目录。<strong class="la ir"> cv2。VideoCapture用于加载我们的测试视频，是cv2对象的一个预构建的可调用函数。</strong></p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="2d9f" class="lz ma iq lv b gy mb mc l md me">def center(c):<br/>  x_start=d[‘box’+str(c)+’x’]<br/>  y_start=d[‘box’+str(c)+’y’]<br/>  x_end=d[‘box’+str(c)+’x+w’]<br/>  y_end=d[‘box’+str(c)+’y+h’]<br/>  Point=int((x_start+x_end)/2), int((y_start+y_end)/2)<br/>  return Point<br/>def mailer(pic,mail):<br/>  path=”/GD/My Drive/dataset/”+pic<br/>  from = “[YOURMAILHERE]”<br/>  to = "[TARGETMAILHERE]"<br/>  message = MIMEMultipart()<br/>  message[‘From’] = from<br/>  message[‘To’] = to<br/>  message[‘Subject’] = “Violation notification”<br/>  body = “Dear user, pfa for instances of violation of social    distancing”<br/>  msg.attach(MIMEText(body, ‘plain’))<br/>  filename = pic<br/>  attachment = open(path, “rb”)<br/>  p = MIMEBase(‘application’, ‘octet-stream’)<br/>  p.set_payload((attachment).read())<br/>  # encode into base64<br/>  encoders.encode_base64(p)<br/>  p.add_header(‘Content-Disposition’, “attachment; filename= %s” %  filename)<br/>  msg.attach(p)<br/>  s = smtplib.SMTP(‘smtp.gmail.com’, 587)<br/>  s.starttls()<br/>  s.login(from, “YOURPASSWORDHERE”)<br/>  text = msg.as_string()<br/>  s.sendmail(from, to, text)<br/>  s.quit()</span></pre><p id="050c" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在做类似的工作时，为你的项目构建函数是帮助迁移学习的好方法。因此，我在这里创建了两个基本函数，一个用于查找两点之间的中心，另一个用于向目标发送带有附件的邮件。我将在下面详细解释中心函数。mailer函数获取pic的名称，该名称存储在我的Google drive中，具有违例时刻，并将它附加到带有消息正文的邮件中，并发送给目标。我发现这篇文章<a class="ae mf" href="https://www.geeksforgeeks.org/send-mail-attachment-gmail-account-using-python/" rel="noopener ugc nofollow" target="_blank">这里</a>真的信息量很大，我用它来结合这一点。</p><p id="4271" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">现在转到主函数。为了理解主代码，我们必须首先理解不同类型的循环运行的层次结构以及它们所做的工作。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/79208631de1b75fa352afb5dd8f1b6f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*BLhV7aTjCRTofQKoX7auCg.png"/></div></figure><h1 id="32d7" class="mh ma iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">代码解释</h1><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="d2e0" class="lz ma iq lv b gy mb mc l md me">i=1<br/>contn_frame_with_detection=0<br/>skipped_frames=0<br/>while cap.isOpened():<br/></span></pre><p id="ff54" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们调用存储输入视频的cap实例并打开它，这样我们就可以一次处理一帧。这是我们的第一个while循环，因此所有的代码都在里面。我们还启动了3个计数器。“I”保持正在处理的帧的计数，“contn_frame_with_detection”保持已经检测到违规的连续帧的数量，“skipped_frames”保持没有发现违规的检测帧之间的帧的计数。跳过帧的概念将在后面讨论。</p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="42b7" class="lz ma iq lv b gy mb mc l md me">frame_violator=0<br/>l=[]<br/>d={}<br/>person_id=0<br/>ret,frame = cap.read()<br/>if not ret:<br/>  break</span></pre><p id="9741" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这里，另一个计数器‘frame _ violator’被启动，以计数在每个帧中检测到违规的次数。如果他们只需要检测大型集会而忽略2、3个人一起行走，一些管理机构可能喜欢将它保持为高。预期在第一帧中检测到第一个人，person_id被设置为1。<strong class="la ir">‘cap . read()’帮助我们读取帧并存储以供进一步处理。</strong>它还被指示在帧结束时中断。</p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="c72c" class="lz ma iq lv b gy mb mc l md me">frame = cv2.resize(frame, None,fx=0.95, fy=0.95, interpolation = cv2.INTER_LANCZOS4)<br/>gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)<br/>persons = person_clf.detectMultiScale(gray, 1.02, 5)</span></pre><p id="9ba7" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们首先需要用cv2.resize()将帧的大小调整到60%左右，这样计算就可以实时进行，而不会影响速度。如果你有比谷歌Collab Gpu更快的处理器，你可以让它更高。cv2。INTER_LANCZOS4通常被认为是最好的插值方法，但是根据图像的上采样或下采样，也可以使用其他方法，如INTER_LINEAR、INTER_AREA。COLOR_BGR2GRAY方法用于将具有3个通道的BGR图像(OpenCV就是这样读取图像的)转换为只有1个通道的灰度图像。可以看出，在使卷积层均匀的同时，灰度级的计算要低得多，并且不会丢失太多信息，因此更易于机器处理。因此，我们使用cv2的detectMutiScale方法从灰度图像中检测给定帧中的人。需要注意的是，这返回了一个矩形对角线的起点和终点坐标，在这个矩形中可以找到被检测的人。我们将这些坐标存储在persons变量中，以便以后逐个循环。</p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="9079" class="lz ma iq lv b gy mb mc l md me">for (x,y,w,h) in persons:<br/>  d[‘box’+str(person_id)+’x’]=x<br/>  d[‘box’+str(person_id)+’y’]=y<br/>  d[‘box’+str(person_id)+’x+w’]=x+w<br/>  d[‘box’+str(person_id)+’y+h’]=y+h<br/>  l.append(center(int(person_id)))<br/>  if person_id&gt;0:<br/>    s=0<br/>    feed_detected=0<br/>    for mid in l[:-1]:<br/>      dist = math.sqrt((mid[0] — center(int(person_id))    [0])**2 + (mid[1] — center(int(person_id))[1])**2)<br/>      if dist&lt;=40:<br/>        cv2.rectangle(frame, (d[‘box’+str(s)+’x’], d[‘box’+str(s)+’y’]), (d[‘box’+str(s)+’x+w’], d[‘box’+str(s)+’y+h’]), (0, 0,255), 2)<br/>        cv2.line(frame,(int(mid[0]),int(mid[1])),(center(int(person_id))[0],center(int(person_id))[1]),(0,0,255),(2))<br/>        feed_detected+=1<br/>        frame_violator+=1<br/>        s+=1<br/>     if feed_detected&gt;0:<br/>        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)<br/>   person_id+=1</span></pre><p id="f705" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">上面的代码构成了这个算法的逻辑核心。我们首先开始逐个循环每个人<strong class="la ir">(对于循环A) </strong>，并将矩形的坐标存储在python <strong class="la ir">字典中，以格式['box-person_id-x']: value命名。</strong>然后我们调用我们的<strong class="la ir">中心函数</strong>找到这个人的质心，并存储在一个列表中。函数<strong class="la ir"> center </strong>接收要计算质心的person_id，从起点和终点的字典中检索他的数据，并计算中心坐标。现在，根据我们的层级，第二个循环被初始化<strong class="la ir">(对于循环B) </strong>当帧中的person_id大于0时，(实际上意味着多于两个人)，其与每个先前检测到的人的质心的距离通过简单的<strong class="la ir">欧几里德距离公式</strong>来计算。如果检测到违规，feed_detector加1，表示输入的feed有违规，在检测到的违规周围画一个红框，用cv2.rectangle保持<strong class="la ir">颜色尺寸为(0，0，255 ),表示红色</strong>用于cv2使用的BGR格式。</p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="5c16" class="lz ma iq lv b gy mb mc l md me">if frame_violator&gt;0 and skipped_frames&lt;4:<br/>  contn_frame_with_detection+=1<br/>  skipped_frames=0<br/>else:<br/>  skipped_frames+=1<br/>if skipped_frames&gt;=4:<br/>  contn_frame_with_detection=0<br/>  skipped_frames=0</span><span id="a9af" class="lz ma iq lv b gy my mc l md me">i+=1</span></pre><p id="442f" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">引入了一个<strong class="la ir">跳过帧计数器来解决我们模型的假阴性</strong>。在两个检测到的违规帧之间将有许多帧，其中HAAR分类器可能甚至不能检测到所有人。这将导致错误地将帧识别为无违规。因此，当我们看到检测到违规的连续帧的数量时，我们还必须看到跳过的帧是否保持在某个数量以下。如果skipped_frame大于5，这可能意味着先前发生违规的帧实际上可能只是误报，因此我们应该再次将continuous_frame_counter设置为0，并将skipped_frames设置为0，重新开始计数。</p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="56a8" class="lz ma iq lv b gy mb mc l md me">if contn_frame_with_detection&gt;25:<br/>  contn_frame_with_detection=0<br/>  skipped_frames=0<br/>  name=”pic”+str(i)+”.jpg”<br/>  cv2.imwrite(‘/GD/My Drive/dataset/’+name,frame)<br/>  mailer(name)</span></pre><p id="4d97" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">为了<strong class="la ir">加强检测为真阳性，我们仅考虑当continuous_frame_counter超过25 </strong>(或更高，取决于用户的需要)时的重大距离违规。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/171ed1f868600e2daced8f55c219b2c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*o401p43skhSPQ4Mp-EwNcQ.png"/></div><p class="na nb gj gh gi nc nd bd b be z dk translated">收到的自动邮件的屏幕截图</p></figure><p id="a4e3" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">此时，我们<strong class="la ir">通过调用cv2.imwrite函数拍摄一张图片，并调用我们预定义的邮件函数来提供jpg图片的名称</strong>。因此，该邮件功能立即向目标用户发送邮件，向他更新情况。</p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="ed4c" class="lz ma iq lv b gy mb mc l md me">if writer is None:<br/>   vid_write= cv2.VideoWriter_fourcc(*”XVID”)<br/>   writer = cv2.VideoWriter(OUTPUT, vid_write, 35,(frame.shape[1],    frame.shape[0]), True)<br/>writer.write(frame)</span></pre><p id="925a" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">最后，我们让<strong class="la ir">成为cv2的一个实例。用XviD格式保存我们的视频文件，一次一帧</strong>。</p><pre class="kn ko kp kq gt lu lv lw lx aw ly bi"><span id="e39e" class="lz ma iq lv b gy mb mc l md me">#this will outside main while loop<br/>writer.release()<br/>cap.release()<br/>cv2.destroyAllWindows()</span></pre><p id="e07a" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">到达帧的末尾后，我们释放writer，cap，并通过cv2.destroyAllWindows()销毁<strong class="la ir">的所有窗口，这样计算机就不会崩溃。下面是该程序的输出示例</strong></p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ne nf l"/></div><p class="na nb gj gh gi nc nd bd b be z dk translated">样本输出</p></figure><p id="bd28" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">好的，一天之内要理解的循环相当多。我试图从零开始构建每一个功能，并通过逻辑实现整个事情，因此这些复杂的循环。我将会在网上发布如何使用Azure ml的EC2实例来部署它。我希望你喜欢程序背后的直觉，并且能够欣赏用于构建它的各种计数器和循环。任何人有任何想法，也许添加一些功能到这个程序或使它运行得更快，肯定可以联系我。在那之前，万岁和数据科学。</p><h1 id="2778" class="mh ma iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">来源</h1><p id="1a80" class="pw-post-body-paragraph ky kz iq la b lb ng jr ld le nh ju lg lh ni lj lk ll nj ln lo lp nk lr ls lt ij bi translated">科尔德威，D. (2020年4月)。<a class="ae mf" href="https://techcrunch.com/activity-monitoring-startup-zensors-repurposes-its-tech-to-help-coronavirus-response." rel="noopener ugc nofollow" target="_blank"><em class="nl">https://TechCrunch . com/activity-monitoring-startup-Zen sors-re purposes-its-tech-to-help-coronavirus-response。</em> </a>检索自Techcrunch:<a class="ae mf" href="https://techcrunch.com/2020/04/02/activity-monitoring-startup-zensors-repurposes-its-tech-to-help-coronavirus-response/" rel="noopener ugc nofollow" target="_blank">https://Techcrunch . com/2020/04/02/activity-monitoring-startup-Zen sors-re purposes-its-tech-to-help-coronavirus-response/</a></p><p id="2d70" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">琼斯，P. V. (2001年)。<em class="nl"> opencv </em>。从Github检索:<a class="ae mf" href="https://github.com/opencv/opencv/tree/master/data/haarcascades" rel="noopener ugc nofollow" target="_blank">https://Github . com/opencv/opencv/tree/master/data/Haar cascades</a></p><p id="8db5" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">保罗·维奥拉，法学博士(2001年)。<em class="nl">使用简单特征的增强级联的快速对象检测。</em><a class="ae mf" href="http://www.cs.cmu.edu." rel="noopener ugc nofollow" target="_blank">www.cs.cmu.edu。</a></p></div></div>    
</body>
</html>