<html>
<head>
<title>Bellman-Ford Single Source Shortest Path Algorithm on GPU using CUDA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 CUDA 的 GPU 上 Bellman-Ford 单源最短路径算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bellman-ford-single-source-shortest-path-algorithm-on-gpu-using-cuda-a358da20144b?source=collection_archive---------27-----------------------#2020-08-19">https://towardsdatascience.com/bellman-ford-single-source-shortest-path-algorithm-on-gpu-using-cuda-a358da20144b?source=collection_archive---------27-----------------------#2020-08-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f5e5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">计算连通图中从一个源顶点到所有其它顶点最短距离的并行算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5fd80156435557be949e0e6d7e15470c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1s1avdh9Q2kIKwDM"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">蒂莫·沃尔茨在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="8c81" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">概观</h1><p id="a137" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">遍历大型图来计算不同的信息在现实世界中有各种用例，如社交媒体网络、通信网络、搜索引擎索引和页面排名、VLSI 设计和生物网络分析。贝尔曼-福特、迪杰斯特拉和德尔塔步进是广泛使用的单源最短路径算法(SSSP)算法。Dijkstra 的算法提供了一种高效的实现方式，而 Bellman-Ford 则提供了一种简单的并行实现方式。增量步进算法在两者之间引入了一种折衷。本文介绍了在图形处理器(GPGPU)上使用统一计算设备架构(CUDA)加速贝尔曼-福特 SSSP 算法的三种并行实现技术。我们还在大型图上比较了所有三种变体的性能。我们观察到，对于具有 40 万个顶点和 100 万条边的稀疏图，使用优化的 CUDA 实现，顺序实现的运行时间可以减少 99.4%。</p><h1 id="5569" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">什么是单源最短路径(SSSP)？</h1><p id="3200" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">图 G = (V，E ),其中 V 是顶点集，E 是边集。边(u，v，w)是从节点 u 到 v 的路径，其权重为 w。如果我们将节点视为城市，则边是城市之间的路线，权重是城市之间的距离。</p><p id="86b6" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">在下面显示的示例图中，V = {A，B，C，D，E}和 E = {(A，B，9)，(A，C，4)，(B，C，10)，(B，D，2)，(B，E，3)，(C，D，2)，(C，E，11)，(D，B，2)，(E，D，2)}。单源最短路径是从源顶点(例如“A ”)到所有其他顶点的最短距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/35f84ae26417336492860941ac49058a.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*vJL5M_DamI4HDZ_e_97ziA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">直接加权图</p></figure><p id="69e4" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">在上面的示例图中，从源顶点“A”到所有其他顶点的 SSSP 由蓝色箭头给出。即 A → C → D → B → E</p><h1 id="a022" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">数据集</h1><p id="24ad" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">我们使用了两种不同类型的大型图表。美国道路网络图数据集来自 DIMACS 最短路径实施挑战(<a class="ae ky" href="http://users.diag.uniroma1.it/challenge9/download.shtml" rel="noopener ugc nofollow" target="_blank">离散数学和理论计算机科学中心)。第 9 届 DIMACS 实施挑战</a>)和 Cherkassky、Goldberg 和 Radzik 使用 SPRAND 工具随机生成的图形(参考文献[1])</p><h1 id="96cc" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">图表示</h1><p id="8b6a" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">图 G(V，E)通常通过邻接矩阵或邻接表来表示。对于像道路网络这样的稀疏图，邻接表是首选的表示方法，因为它占用的空间更少。<strong class="ma iu">压缩稀疏行</strong> (CSR)表示是邻接表的另一种形式，其中顶点列表被打包成一个大数组。我们发现这种表示适合 CUDA 实现(参考文献[2]、[3])。如下图所示，四个数组用于表示图形；存储所有顶点的顶点数组<strong class="ma iu"> V </strong>，存储每个<strong class="ma iu">V【I】</strong>的边的邻接表的起始位置的索引数组<strong class="ma iu"> I </strong>，存储每个边的权重的边数组<strong class="ma iu"> E </strong>，以及存储每个边的权重的权重数组<strong class="ma iu"> W </strong>。<strong class="ma iu">I[I+1]—I[I]</strong>提供<strong class="ma iu"> V[i] </strong>的边数</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/b298c638615ae88852dee7cf5bb2574f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B_vi0fQ53VQmQarXo2OhrQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图的压缩稀疏行表示</p></figure><h1 id="c4d6" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">GPU 和 CUDA</h1><p id="4d29" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">图形处理单元(GPGPU)上通用计算使用的增加为我们提供了大规模并行计算能力。GPGPU 基于单指令多线程(SIMT)执行模型，其中每个线程执行相同的代码。<a class="ae ky" href="https://developer.nvidia.com/cuda-zone" rel="noopener ugc nofollow" target="_blank">计算统一设备架构 CUDA(Compute Unified Device Architecture)是 Nvidia </a>打造的并行计算平台和 API。它为通用计算提供了 GPU 并行性，并保留了性能。它是基于行业标准 C++开发的。CUDA 由一小组扩展组成，支持异构编程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/75815674122f02ca71239c98cb09af39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jMapIwCxQmMZ4a9hTvR8ww.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基本图片:CUDA C/C++基础，超级计算 2011 教程，Cyril Zeller，NVIDIA 公司</p></figure><p id="0e5d" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">GPGPU 由几个流多处理器(SMs)组成。每个 SM 由几个流处理器(sp)组成。每个 SM 都有自己的内存，称为共享内存，由 SM 中的所有 sp 共享。从开发人员的角度来看，GPU 可以被视为网格，SMs 可以被视为块，sp 可以被视为线程。内核是由线程执行的一段代码。每个线程都有自己的 ID，它在决定线程要访问输入数据的哪一部分时起着至关重要的作用。</p><h1 id="8b8f" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">贝尔曼-福特顺序算法</h1><p id="5c09" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">贝尔曼-福特算法是一种使用边缘松弛技术的简单算法。它将所有边缘放松| V | 1 次。其中| V |是图中顶点的数量。如果没有负边循环，它也可以在具有负权重边的图上工作。在这项研究中，只考虑了边权重为正的图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/7a2b15212dfa0830313079b9ff5bb78a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VtAnblp4PWbg5ja0bon8cA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">顺序贝尔曼-福特算法</p></figure><h2 id="67e8" class="nj lh it bd li nk nl dn lm nm nn dp lq mh no np ls ml nq nr lu mp ns nt lw nu bi translated">什么是边缘松弛？</h2><p id="ad5c" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">这是一种用正确的距离来修正近似距离的技术。在下图中，d[u]是从源“s”到“u”的距离，d[v]是从源“s”到“v”的距离。“u”和“v”之间有一条边，权重为“w”。如果 v 的距离大于(u，v)的 u +权重的距离，则用(u，v)的 u +权重的距离更新 v 的距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/59efd79ca3d08edc9634d81f1dbb3827.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*tYuy15_jkGZqT34yXKfBwA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">贝尔曼-福特松弛法</p></figure><h1 id="e583" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">贝尔曼-福特并行 CUDA 实现</h1><h2 id="40be" class="nj lh it bd li nk nl dn lm nm nn dp lq mh no np ls ml nq nr lu mp ns nt lw nu bi translated">版本 1 —单片内核</h2><p id="7491" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">在我们的第一种方法中，我们引入了一个单片 CUDA 内核，其中图形的每个顶点都被分配给一个单独的线程。每个线程放松由线程 ID 标识的顶点的所有输出边。在这种方法中，GPU 块数是在运行时根据输入图形中的顶点数计算的。这种类型的内核假设我们有足够的线程来覆盖输入图的所有顶点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">版本 1 —单片内核</p></figure><h2 id="63a3" class="nj lh it bd li nk nl dn lm nm nn dp lq mh no np ls ml nq nr lu mp ns nt lw nu bi translated">版本 2 —具有网格步长循环的内核</h2><p id="5695" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">在加速并行实现的第二项技术中，我们在 CUDA 内核中使用了 grid stride。使用 blockDim.x * gridDim.x 计算跨距，它等于网格中的线程总数。例如，如果网格中有 1024 个线程，线程 0 将处理索引为 0、1024、2048 等的顶点。这种网格步长循环方法提供了可伸缩性和线程重用。它还确保没有线程空闲，并且每个线程都做等量的工作</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">版本 2 —具有网格步长循环的内核</p></figure><h2 id="b1a1" class="nj lh it bd li nk nl dn lm nm nn dp lq mh no np ls ml nq nr lu mp ns nt lw nu bi translated">版本 3 —内核具有网格步长循环，仅在需要时放松边缘</h2><p id="7f7d" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">为了进一步优化性能，我们引入了大小为|V|的布尔数组 F。对于图形的所有顶点，该数组在开始时被初始化为 false。源设置为真。作为松弛的一部分，当一个顶点用离源更短的距离更新时，它在 F 数组中的对应标志被设置为真。这表明在下一次迭代中，该顶点的所有输出边都需要进一步松弛。松弛内核使用该信息，并且仅当对应顶点的标志设置为真时才松弛。这种方法与 grid-stride 循环相结合，减少了每个线程所做的不必要的工作，从而确保了整体执行速度的进一步提高。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">版本 3 —内核具有网格步长循环，仅在需要时放松边缘</p></figure><h1 id="c830" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">测试环境</h1><p id="42c9" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">我们使用<a class="ae ky" href="https://portal.tacc.utexas.edu/user-guides/maverick2" rel="noopener ugc nofollow" target="_blank">德克萨斯高级计算中心(TACC)的 Maverick2 超级计算机</a>系统在大型图上分析我们所有实现的性能。Maverick2 拥有 Nividia GeForce GTX 1080 Ti GPU 设备，每个 SM 有 28 个 SMs 和 128 个 sp，以及 11GB 的全局内存。每个 SM 大约有 49 KB 的共享内存。</p><h1 id="03a2" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">技术性能分析</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/e0ea78b21bd7922cc29664e4721ce5ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*80Dns-ImUEoMKIxhmKJ2Rg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">贝尔曼-福特实现的运行时间比较</p></figure><p id="63e4" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">我们的分析表明，版本 3 的实现性能最好。与稀疏的真实世界道路网络图相比，随机生成的密集图的性能甚至更好。首先，我们记录了基本的顺序实现花费了 3.25 个小时来对具有 400，000 多个顶点和超过一百万条边的稀疏的纽约道路网络图执行 SSSP 计算。相比之下，CUDA 版本 1 用了 39 秒，版本 2 用了 42 秒，版本 3 用了 16 秒。我们还观察到，版本 2，即网格步长循环内核，对于具有超过 100 万个顶点和 400 万条边的较大图形表现得更好。对于随机生成的密集图，性能甚至更好。这表明启动新线程块的开销随着网格步长循环的引入而减少，这确保了块大小不会随着输入的增加而增加，从而允许每个线程处理更多的工作。下表显示了我们的 Bellman-Ford 实现对于各种大型图形所用的运行时间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/d6f2bff58584dd04ede7a2a89481cbb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h-T3BXj1tGXZ_p6zumewpg.png"/></div></div></figure><h1 id="06ad" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">结论</h1><p id="6884" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">我们提出了 Bellman-Ford 单源最短路径算法在 GPU 上使用 CUDA 并行实现的三种变体。具有网格步长循环的内核和仅在需要时放松边的逻辑，对于具有 1-1000 万条边的较大图形表现更好。我们在实现中使用了 CSR 表示。对于密集图形，这种方法需要更多的空间。可以做进一步的研究，使用密集图形的替代格式(如邻接矩阵),并使用 CUDA 块内的共享内存来研究性能。</p><p id="5b53" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">这篇博文基于我和我的合作伙伴 Stephan Garland 提交给 2020 年夏天在奥斯汀的德克萨斯大学并行算法课程的学期论文。非常感谢<a class="ae ky" href="http://www.ece.utexas.edu/people/faculty/vijay-garg" rel="noopener ugc nofollow" target="_blank">Vijay Garg</a>博士精心组织和精彩讲授的并行算法课程。</p><p id="8806" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">Github 链接:【https://github.com/sengorajkumar/gpu_graph_algorithms T4】</p><h1 id="31f3" class="lg lh it bd li lj mu ll lm ln mv lp lq jz mw ka ls kc mx kd lu kf my kg lw lx bi translated">参考</h1><p id="3cc2" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">[1]Boris cherkasky、Andrew V. Goldberg 和 Tomasz Radzik。最短路径算法:理论和实验评估。数学编程，第 129-174 页。1993.</p><p id="275b" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">[2]潘卡利·阿加瓦尔和弥勒佛·杜塔。基于计算机统一设计架构(CUDA)的 Bellman-Ford 算法在 GPU 上的新方法。国际计算机应用杂志(0975–8887，110 — №13.2015。</p><p id="6e2a" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">[3]Pawan Harish 和 P. J. Narayanan。使用 CUDA 在 GPU 上加速大型图形算法。印度海德拉巴国际信息技术研究所视觉信息技术中心。</p><p id="744a" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">[4]马克·哈里斯。CUDA Pro 提示:用 Grid-Stride Loops 编写灵活的内核 https://developer . NVIDIA . com/blog/CUDA-Pro-Tip-Write-Flexible-Kernels-Grid-Stride-loops/，2013 年 4 月 22 日。</p><p id="d459" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">[5]马克·哈里斯。CUDA C/C++内核如何高效访问全局内存. https://developer . NVIDIA . com/blog/how-Access-Global-Memory-efficient-CUDA-C-kernels/，2013 年 1 月 7 日。</p><p id="2fcf" class="pw-post-body-paragraph ly lz it ma b mb mz ju md me na jx mg mh nb mj mk ml nc mn mo mp nd mr ms mt im bi translated">[6]Cyril Zeller，NVIDIA 公司，CUDA C/C++基础，超级计算 2011 年教程</p></div></div>    
</body>
</html>