<html>
<head>
<title>Flavors of Cross-Validation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">交叉验证的味道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/flavors-of-cross-validation-edfee24e8916?source=collection_archive---------24-----------------------#2020-01-14">https://towardsdatascience.com/flavors-of-cross-validation-edfee24e8916?source=collection_archive---------24-----------------------#2020-01-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ba4c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用交叉验证背后的动机</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/be61158055c1dd5817ebef64c81d7b16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LJFQyEKyKKCCUwn2KmouQA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">内森·杜姆劳在<a class="ae ky" href="https://unsplash.com" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7e7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">交叉验证(也称为<strong class="lb iu">旋转估计</strong>或<strong class="lb iu">样本外</strong>测试)是一种重采样方法，用于</p><p id="5b16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">模型评估</strong>(评估模型的性能)</p><p id="f115" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">型号选择</strong>(选择型号的适当灵活度)</p><p id="9b07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">交叉验证评估预测模型的性能，并评估它们在独立数据集上的样本外的表现。简单地说，它检查一个<strong class="lb iu">模型是否是可推广的</strong>。</p><h2 id="4882" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">传统模型评估技术:-</h2><p id="2c35" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">验证集方法(数据分割)</em> </strong></p><p id="e91e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种方法中，观察集被随机分为训练集和验证集。70/30或80/20的比例更常用，尽管确切的比例取决于数据的大小。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/824073a2e79fd9a16e2b8330ccf4766f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*j1bYzINlYN_Im_JeLFYAnA.jpeg"/></div></figure><p id="4807" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在训练集上拟合该模型，然后使用拟合的模型来预测对验证集中的观察的响应。得到的验证集错误率提供了对测试错误率的估计。根据响应的类型，可以使用适当的误差度量来测量误差率，例如均方误差(MSE)、均方根误差(RMSE)或平均绝对百分比误差(MAPE)。</p><p id="9399" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">优势:- </em> </strong></p><p id="00a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单且易于实施</p><p id="c139" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算上<strong class="lb iu">便宜</strong></p><p id="e508" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">缺点:- </em> </strong></p><p id="e82f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">错误率可能具有<strong class="lb iu">高方差</strong>，这取决于哪些<strong class="lb iu">数据点</strong>最终出现在<strong class="lb iu">训练集和验证集</strong>中</p><p id="4415" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">高估</strong>的<strong class="lb iu">测试误差</strong>。记住，统计方法在训练较少的观察值时表现会更差。在这种方法中，很大一部分观察值在验证集中，其余的在训练集中。</p><p id="ecc4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">留一交叉验证(LOOCV) </em> </strong></p><p id="1ba6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在LOOCV，数据以这样的方式分割:除了一个数据点包含在验证集中之外，所有的数据点 (n-1)都包含在训练集<strong class="lb iu">中。重复该方法，直到每个数据点都被用作验证集。计算平均误差以评估模型。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/70035ffd5bc1dd1ecc6deaaa92062259.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*n0VrAMRljcvif20Z-xixug.jpeg"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/5fa8d7ff2291a4290012ba4eb7794e09.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*TcBJgEOuZAg-X1JKXnKVlQ.jpeg"/></div></figure><p id="b2d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">优点:- </em> </strong></p><p id="834b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">偏差较小</strong>。由于训练集大小包括几乎所有的观察值(n-1)，与验证集方法相比，高估误差的趋势几乎可以忽略。</p><p id="91a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">劣势:- </em> </strong></p><ul class=""><li id="54cb" class="mx my it lb b lc ld lf lg li mz lm na lq nb lu nc nd ne nf bi translated">计算上<strong class="lb iu">昂贵</strong>(模型需要拟合n次)。</li></ul><p id="f065" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于线性回归，有一个降低LOOCV成本的捷径:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/d1f030e6a6fb9c9913e7cdc5579546ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*7x8Mggde2TKDAfZRgyHlVQ.jpeg"/></div></figure><p id="ab1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mt"> k倍交叉验证</em> </strong></p><p id="2dbf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种方法中，数据被随机分成大小近似相等的k个子集<strong class="lb iu">。一次，一个折叠被视为验证集，其余折叠(k-1)被视为训练集。重复该过程，直到每个折叠被用作验证集，即k次。通过取测试误差的k个估计值的平均值来计算k倍CV估计值。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/e5f68a879345da75d665ffe45e1aac01.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*FW2eDS4WnBgsU2oZ6ytkcw.jpeg"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/8394dc281795626281ebaf439562ac56.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*93ac3sJZ-N3nrqM-_2lLYw.jpeg"/></div></figure><p id="6cf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">优势:- </em> </strong></p><p id="81ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法<strong class="lb iu">减少了数据分割方式的影响</strong>。每个数据点在测试集中出现一次，在训练集中出现k-1次。随着k的增加，估计值的方差减小。</p><p id="eb37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">缺点:- </em> </strong></p><p id="b190" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于与LOOCV相比，该模型的数据较少，因此<strong class="lb iu">会将偏差</strong>引入测试误差的估计中。</p><p id="1765" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"><em class="mt">k倍CV的偏倚和方差权衡</em> </strong></p><p id="1bfd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">偏倚是样本统计数据系统地高估或低估总体参数的趋势。就<strong class="lb iu">偏倚缩减</strong>而言，<strong class="lb iu"> LOOCV优于K-fold CV，</strong>，因为它使用n-1个样本来训练模型，这与全数据集一样好。</p><p id="5d0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">方差衡量一组数据点偏离平均值的程度。<em class="mt">高相关值的平均值比低相关值的平均值具有更高的方差</em>。由于在<strong class="lb iu"> LOOCV </strong>中，每个拟合模型中的训练数据集几乎相似，每个模型的输出高度相关，导致<strong class="lb iu">的方差高于K倍CV </strong></p><p id="af47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">k值越大，方差越小，偏差越大</strong>，而<strong class="lb iu">降低k会增加方差，降低偏差</strong>。考虑到这些因素，<strong class="lb iu"> k = 5或k = 10 </strong>，给出了偏差和方差平衡的最佳点。</p><h2 id="de5e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">选择最佳模型</h2><p id="a625" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">在一个回归问题中</em> </strong></p><p id="9cbf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于导致<strong class="lb iu">最低测试误差</strong>的方法，我们在<strong class="lb iu">估计测试MSE曲线中寻找<strong class="lb iu">最小点</strong>的位置。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/791ce861702a37ffd43645d48a07701c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*F59ytb4ZLLDiK7ND5kIXMA.jpeg"/></div></figure><p id="2f5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管CV误差估计与实际测试误差不同，但交叉验证误差最小的模型通常具有相对较小的测试误差。</p><ul class=""><li id="2d39" class="mx my it lb b lc ld lf lg li mz lm na lq nb lu nc nd ne nf bi translated"><strong class="lb iu"> <em class="mt">在分类问题中</em> </strong></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/91a5a30ccc2e9697419590de25efdccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*7l1j9xJEnYZ3FyNG5i4OqA.jpeg"/></div></div></figure><p id="dc65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过选择交叉验证误差估计值最小的模型，可以使用交叉验证来决定最佳模型。在下图中，10倍CV误差估计提供了测试误差率的一个很好的近似值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/b618373825ae0ba58ecc7e945dfa22e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7g-sO4VCo-aX-RAogPTHCQ.jpeg"/></div></div></figure><p id="f433" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mt">带回家消息</em> </strong> : —交叉验证<em class="mt">是评估模型有效性的有用工具，尤其是处理过拟合和欠拟合</em>。</p><p id="47bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">简而言之，学习方法中涉及数据的每个方面都必须进行交叉验证。</strong></p><p id="476e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">参考资料:</p><ol class=""><li id="4edb" class="mx my it lb b lc ld lf lg li mz lm na lq nb lu nm nd ne nf bi translated">G.放大图片作者:James d . Witten t .统计学习导论:在R中的应用。(2013).</li></ol></div></div>    
</body>
</html>