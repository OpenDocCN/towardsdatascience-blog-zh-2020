<html>
<head>
<title>Exploring Coronavirus Research Publications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">探索冠状病毒研究出版物</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploring-covid-19-research-publications-407f8c2aa842?source=collection_archive---------25-----------------------#2020-03-21">https://towardsdatascience.com/exploring-covid-19-research-publications-407f8c2aa842?source=collection_archive---------25-----------------------#2020-03-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="579a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">执行探索性数据分析</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/21c42d5bbd9da8e2025926fa2daafe5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PYcTgiTluMfUC4m4AyO6mw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/photos/bkc-m0iZ4Sk" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="fa36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在冠状病毒爆发后，许多数据来源已向公众开放，以鼓励该领域的研究。最近，白宫和一群领先的研究人员公布了<em class="lv">新冠肺炎开放研究数据集(CORD-19)，</em>，该数据集可在<a class="ae ky" href="https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge#all_sources_metadata_2020-03-13.csv" rel="noopener ugc nofollow" target="_blank"> Kaggle </a> <em class="lv">上获得。</em>我们的目标是让全球研究界应用机器学习和自然语言处理的最新进展，以获得对传染病的深入了解。</p><p id="7d65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与大多数文本挖掘工作一样，生成汇总统计数据并直观地表示文本信息的内容是探索性数据分析的一个非常重要的部分。</p><p id="5c83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本帖中，我们将对<em class="lv">新冠肺炎开放研究数据集(CORD-19)进行探索性数据分析。</em>我们将使用python库，如‘seaborn’，‘matplotlib’和Pandas来探索和可视化数据集中提供的分类和文本信息。我们将使用的特定文件名为“all _ sources _ metadata _ 2020–03–13 . CSV”。</p><p id="71e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧！</p><h1 id="6bc1" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">读取数据</h1><p id="ae1d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">首先，让我们将数据读入Pandas数据框:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="3f07" class="my lx it mu b gy mz na l nb nc">import pandas pd <br/>df = pd.read_csv(“all_sources_metadata_2020–03–13.csv”)</span></pre><p id="d6f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们打印前五行数据。让我们放松对显示的列数的限制(这里输出被抑制):</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="bae3" class="my lx it mu b gy mz na l nb nc">pd.set_option('display.max_columns', None)<br/>print(df.head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/97162ce3b9a39730135c5c5e0fb17d1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oQM-_IFbFkLw7ospsdwEtw.png"/></div></div></figure><p id="8b9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以从很多地方开始分析。最简单的第一步是查看列的列表及其长度:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="b3e5" class="my lx it mu b gy mz na l nb nc">print("List of columns:")<br/>print(list(df.columns))<br/>print("Length of columns:", len(df.columns))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/e5dd766870977a52bbfc97f40045153d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WiAEND_6nV0s7KeTrixTKQ.png"/></div></div></figure><p id="709f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以查看数据集中的行数:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="ae9c" class="my lx it mu b gy mz na l nb nc">print("Number of rows: len(df))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/0f1f707c6f9c63f1c4884c78ceb40dd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*c7B1dwKJS60uO-LZoh42ZA.png"/></div></figure><p id="eb04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们可以查看所有出版物在期刊中的出现频率。我们可以使用collections模块中的Counter方法来实现这一点(这里输出也被抑制):</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="cee8" class="my lx it mu b gy mz na l nb nc">from collections import Counter<br/>print(Counter(df['journal']))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/0bdca92c4a310392f9709b5e20210330.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IpNoxxWJqgenqJZKVbS-8g.png"/></div></div></figure><p id="22c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，这是相当期刊名称和频率的列表。我们可以通过删除缺失值(' nan ')并将输出限制为最常见的10个日志来缩小范围:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="5b13" class="my lx it mu b gy mz na l nb nc">df['journal'].dropna(inplace = True)<br/>print(Counter(df['journal']).most_common(10))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/fcc7c0eb9c08bc8d77b069bbb349eaaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Er1YLf45qqbLi7__RUQVQ.png"/></div></div></figure><p id="e15d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以使用“matplotlib”和“seaborn”来可视化最常见的期刊出版物。让我们对五种最常见的出版物也这样做:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="e5c3" class="my lx it mu b gy mz na l nb nc">import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="62da" class="my lx it mu b gy nh na l nb nc">sns.set()<br/>bar_plot = dict(Counter(df['journal'].values).most_common(5))<br/>plt.bar(*zip(*bar_plot.items()))<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/f88d01df7d9e2d5ff9bfc7f7d864f1a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qE9nHtSzRxIR11cvMNFHAw.png"/></div></div></figure><p id="24e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样值得注意的是，如果我们看一下期刊的总数:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="e9e4" class="my lx it mu b gy mz na l nb nc">print(len(set(df['journal'])))</span></pre><p id="1747" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该数据集中有1732个日志。</p><p id="0dc9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">出于好奇，我查找了这些期刊的影响因子。对于那些不知道的人来说，期刊影响因子是一个衡量期刊被引用频率的指标。越有声望或越难在期刊上发表的文章通常有更高的影响因子。最常见的五种期刊在2019年有以下影响因素:</p><ol class=""><li id="ad5a" class="nj nk it lb b lc ld lf lg li nl lm nm lq nn lu no np nq nr bi translated">PLoS one: 2.8</li><li id="f20b" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">急诊传染病:7.4</li><li id="e124" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">科学报告:4.1</li><li id="15de" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">公共科学图书馆Pathog: 6.2</li><li id="b28c" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">病毒:3.8</li></ol><p id="181c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于<em class="lv">新兴传染病</em> (Emerg Infect Dis)的影响因子最高，发表数量第二高，因此分析该期刊发表的论文的文本内容可能会很有意思。</p><p id="aa65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个有趣的项目是找出每种期刊的影响因子，并用影响因子信息扩充现有数据。用这些信息扩充我们的数据将允许我们过滤和搜索高影响力的新冠肺炎研究出版物。为了找到具有最高影响因子和相对出版物数量的期刊，我们需要将1732种期刊映射到影响因子值。</p><p id="4d92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们假设<em class="lv">新兴传染病</em>是一个有大量与新冠肺炎相关的出版物的好杂志。加强了这个假设，<a class="ae ky" href="https://www.scimagojr.com/journalrank.php?category=2725&amp;order=sjr&amp;ord=desc" rel="noopener ugc nofollow" target="_blank"/>，一个期刊排名网站，把<em class="lv">新兴传染病</em>排在他们传染病期刊名单的第八位，这是相当不错的。</p><h1 id="f322" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">过滤数据</h1><p id="a016" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">接下来，让我们过滤我们的数据，仅包括来自<em class="lv">新发传染病</em>的数据，并打印数据帧长度以供验证:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="f0f6" class="my lx it mu b gy mz na l nb nc">df = df[df.journal == 'Emerg Infect Dis']<br/>print(len(df))</span></pre><p id="66e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到数据帧长度为941。</p><p id="2fe3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们来看一些摘要。让我们先来看看前5篇摘要，以便对文中的内容有所了解:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="a840" class="my lx it mu b gy mz na l nb nc">print(list(df['abstract'].values)[0])<br/>print('-'*170)<br/>print(list(df['abstract'].values)[1])<br/>print('-'*170)<br/>print(list(df['abstract'].values)[2])<br/>print('-'*170)<br/>print(list(df['abstract'].values)[3])<br/>print('-'*170)<br/>print(list(df['abstract'].values)[4])<br/>print('-'*170)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/f0cd2944e7f72683fe59229265797a51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HvvgFBWpb738y30qnNxKmg.png"/></div></div></figure><h1 id="48e9" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">情感分析</h1><p id="5597" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">接下来我们要看的是摘要的情感分数。也许我们可以给每个摘要分配情感分数，看看分数是否与积极的结果相关联。</p><p id="0553" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了获得情感分数，我们需要导入一个名为textblob的python包。textblob的文档可以在这里找到<a class="ae ky" href="https://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank">。要安装textblob，请打开命令行并键入:</a></p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="28f6" class="my lx it mu b gy mz na l nb nc">pip install textblob</span></pre><p id="9259" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下次导入textblob:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="e7e0" class="my lx it mu b gy mz na l nb nc">from textblob import TextBlob</span></pre><p id="4a82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用极性得分作为积极或消极情绪的衡量标准。极性得分是一个从-1到+1的浮点数。</p><p id="9bf6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，让我们考虑一下1991年关于癌症药物紫杉醇的出版物，<a class="ae ky" href="https://europepmc.org/article/med/1687206" rel="noopener ugc nofollow" target="_blank"> <em class="lv">紫杉醇:一种新的有效的抗癌药物</em> </a>。摘要中有一句肯定的情感句子:</p><blockquote class="ny nz oa"><p id="e034" class="kz la lv lb b lc ld ju le lf lg jx lh ob lj lk ll oc ln lo lp od lr ls lt lu im bi translated">临床试验表明，紫杉醇对治疗难治性卵巢癌、乳腺癌、恶性黑色素瘤和其他可能的实体瘤有效。</p></blockquote><p id="0442" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们定义一个textblob对象并传入上面的句子，我们有:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="cca3" class="my lx it mu b gy mz na l nb nc">abstract_sentence = "Clinical trials indicate that taxol is effective in the treatment of patients with refractory ovarian cancer, breast cancer, malignant melanoma and probably other solid tumors."</span><span id="44ab" class="my lx it mu b gy nh na l nb nc">sentiment_score = TextBlob(abstract_sentence).sentiment.polarity<br/>print("Sentiment Polarity Score:", sentiment_score)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/424210b00b1a81aa27367248406fcbb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*s90-rND-lWYos8_RVVVUbw.png"/></div></figure><p id="ba34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们把句子中的有效改为无效:</p><blockquote class="ny nz oa"><p id="7550" class="kz la lv lb b lc ld ju le lf lg jx lh ob lj lk ll oc ln lo lp od lr ls lt lu im bi translated">“临床试验表明，紫杉醇在治疗难治性卵巢癌、乳腺癌、恶性黑色素瘤以及其他可能的实体瘤患者时无效。”</p></blockquote><p id="d6ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并将其传递给我们的textblob对象:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="e93c" class="my lx it mu b gy mz na l nb nc">abstract_sentence = "Clinical trials indicate that taxol is ineffective in the treatment of patients with refractory ovarian cancer, breast cancer, malignant melanoma and probably other solid tumors."</span><span id="f18d" class="my lx it mu b gy nh na l nb nc">sentiment_score = TextBlob(abstract_sentence).sentiment.polarity<br/>print("Sentiment Polarity Score:", sentiment_score)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/62ed0a9255a6b017b160afc24d4f14d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*zdXHyr12PugIRwXW39TMrQ.png"/></div></figure><p id="9b21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到textblob能够捕捉科学陈述中的消极和积极情绪。让我们将此应用于新冠肺炎数据的摘要:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="f17c" class="my lx it mu b gy mz na l nb nc">df['abstract'] = df['abstract'].astype(str)<br/>df['sentiment'] = df['abstract'].apply(lambda abstract: TextBlob(abstract).sentiment.polarity)</span></pre><p id="932d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们限制数据框中的列，使其包括“抽象”和“情感”,并打印前五行:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="eacd" class="my lx it mu b gy mz na l nb nc">df = df[['abstract', 'sentiment']]<br/>print(df.head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/50566bb0295805c29fc1377cf7a54071.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g05zIddW4LWqJq6IFSsS9g.png"/></div></div></figure><p id="bca0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也可以计算积极和消极情绪的数量:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="75da" class="my lx it mu b gy mz na l nb nc">df_pos = df[df['sentiment'] &gt; 0.0]<br/>df_neg = df[df['sentiment'] &lt; 0.0]<br/>print("Number of Positive Results", len(df_pos))<br/>print("Number of Negative Result", len(df_neg))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/cc40299158dfceb9315d3b5c223a0bfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*SoTLnNRycJLHWyUTqdiNzQ.png"/></div></figure><p id="d2ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了安全起见，让我们将积极情绪的极性阈值提高到&gt; 0.5，并打印一些积极情绪摘要:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0959" class="my lx it mu b gy mz na l nb nc">df_pos = df[df['sentiment'] &gt; 0.5]<br/>print(list(df_pos['abstract'].values)[0])<br/>print('-'*170)<br/>print(list(df_pos['abstract'].values)[1])<br/>print('-'*170)<br/>print(list(df_pos['abstract'].values)[2])<br/>print('-'*170)<br/>print(list(df_pos['abstract'].values)[3])<br/>print('-'*170)<br/>print(list(df_pos['abstract'].values)[4])<br/>print('-'*170)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/5e016d823175aef4cbfb4a0c1928cd56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wl4xagXnlgug0LXqeDPXag.png"/></div></div></figure><p id="cd4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到textblob在给摘要分配积极的分数方面做得很好。让我们对负面情绪摘要做同样的事情，我们将把负面情绪阈值降低到-0.1:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="25a6" class="my lx it mu b gy mz na l nb nc">df_neg = df[df['sentiment'] &lt; -0.1]<br/>print(list(df_neg['abstract'].values)[0])<br/>print('-'*170)<br/>print(list(df_neg['abstract'].values)[1])<br/>print('-'*170)<br/>print(list(df_neg['abstract'].values)[2])<br/>print('-'*170)<br/>print(list(df_neg['abstract'].values)[3])<br/>print('-'*170)<br/>print(list(df_neg['abstract'].values)[4])<br/>print('-'*170)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/fccd570ed003252c643fc42cdce58bfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vfGbtoqoVofzaJuWP-xZAA.png"/></div></div></figure><p id="ddd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些结果不太确定。理想情况下，我们希望带有负面情绪的摘要包含如下陈述:</p><blockquote class="ny nz oa"><p id="2a6e" class="kz la lv lb b lc ld ju le lf lg jx lh ob lj lk ll oc ln lo lp od lr ls lt lu im bi translated">“没有证据表明会横向传染给其他猫，因为只有两只猫产生了抗H5N1病毒的抗体。”</p></blockquote><p id="a6c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将这种情感评分方法应用于所有期刊并比较期刊之间的消极和积极情感将是有趣的。</p><p id="4b97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我就说到这里，但请放心地继续研究这些数据。可能值得研究其他文本分类方法，如BERT，它可用于对报告负面和正面结果的期刊进行分类。</p><h1 id="63d4" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="21f5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">总之，在本文中，我们对<em class="lv">新冠肺炎开放研究数据集(CORD-19) </em>进行了简单的探索性分析。我们生成期刊数量的频率计数，可视化最常见的期刊，过滤我们的数据以将我们的分析限制在具有大量出版物的高影响力期刊，并对期刊摘要执行情感分析。我希望你觉得这篇文章有用/有趣。这篇文章中的代码可以在<a class="ae ky" href="https://github.com/spierre91/medium_code/blob/master/read_corona_abstracts.py" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。感谢您的阅读！</p></div></div>    
</body>
</html>