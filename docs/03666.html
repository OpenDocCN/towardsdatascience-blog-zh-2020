<html>
<head>
<title>YOLOv3 PyTorch on Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google Colab 上的 YOLOv3 PyTorch</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yolov3-pytorch-on-google-colab-c4a79eeecdea?source=collection_archive---------27-----------------------#2020-04-06">https://towardsdatascience.com/yolov3-pytorch-on-google-colab-c4a79eeecdea?source=collection_archive---------27-----------------------#2020-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5d4f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在浏览器上进行对象检测视频处理</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ffe752550d31f8eced39a772882499be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LGuNP1Wm-f5cIJD-JhSuOA.png"/></div></div></figure><p id="d244" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于计算机视觉爱好者来说，<strong class="kw iu"> YOLO </strong>(你只看一次)是一个非常流行的实时物体检测概念，因为它非常快，性能很好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/a4d8d753aef53c521dcdadd281b57536.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/1*ZTjW7PCtSdbl75gZEKECvw.gif"/></div></figure><p id="3e07" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这篇文章中，我将分享处理视频的代码，以获得<strong class="kw iu"> Google Colab </strong>中每个对象的边界框</p><p id="ef94" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们不会讨论 YOLO 的概念或架构，因为媒体上已经有很多好文章对此进行了阐述。这里我们只讨论<strong class="kw iu">功能码</strong></p></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h1 id="3dd1" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">我们开始吧</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mq"><img src="../Images/04f7ade505f70ca72485f5dacbbdf567.png" data-original-src="https://miro.medium.com/v2/0*Y-m-F-Bo_3A2Rrxl"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">照片由<a class="ae mv" href="https://unsplash.com/@wahidkhene?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">瓦希德·赫内</a>在<a class="ae mv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><blockquote class="mw mx my"><p id="89ad" class="ku kv mz kw b kx ky ju kz la lb jx lc na le lf lg nb li lj lk nc lm ln lo lp im bi translated">你可以试试这个<a class="ae mv" href="https://colab.research.google.com/github/vindruid/yolov3-in-colab/blob/master/yolov3_video.ipynb" rel="noopener ugc nofollow" target="_blank">谷歌眼镜。</a></p></blockquote><p id="2883" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们从 Ultralytics 的一个写得很好并且我最喜欢的 git hub <a class="ae mv" href="https://github.com/ultralytics/yolov3" rel="noopener ugc nofollow" target="_blank"> repo </a>开始。尽管回购已经包含如何使用 YOLOv3 处理视频，只是运行<code class="fe nd ne nf ng b">python detect.py --source file.mp4</code>我想分解并尝试<strong class="kw iu">简化代码</strong>，只是删除几个不必要的行，我添加了如何在 Google Colab / Jupyter 笔记本上<strong class="kw iu">显示处理后的视频</strong></p><h2 id="1f9f" class="nh lz it bd ma ni nj dn me nk nl dp mi ld nm nn mk lh no np mm ll nq nr mo ns bi translated">准备 YoloV3 和 LoadModel</h2><p id="8f0a" class="pw-post-body-paragraph ku kv it kw b kx nt ju kz la nu jx lc ld nv lf lg lh nw lj lk ll nx ln lo lp im bi translated">首先克隆 Ultralytics YoloV3 存储库，然后导入公共包和 repo 函数</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="7f71" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">设置参数解析器，初始化设备(CPU / CUDA)，初始化 YOLO 模型，然后加载权重。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="56ef" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用的是<code class="fe nd ne nf ng b">YOLOv3-spp-ultralytics</code>权重，回购公司称其在平均精度上远远优于其他 YOLOv3</p><p id="b12d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">函数<code class="fe nd ne nf ng b">torch_utils.select_device()</code>将自动寻找可用的 GPU，除非输入<code class="fe nd ne nf ng b">'cpu'</code></p><p id="5cf9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对象<code class="fe nd ne nf ng b">Darknet</code>在 PyTorch 上初始化 YOLOv3 架构，权重需要使用预先训练的权重加载(我们现在不想训练模型)</p><h2 id="d2f7" class="nh lz it bd ma ni nj dn me nk nl dp mi ld nm nn mk lh no np mm ll nq nr mo ns bi translated">视频上预测对象检测</h2><p id="bc3b" class="pw-post-body-paragraph ku kv it kw b kx nt ju kz la nu jx lc ld nv lf lg lh nw lj lk ll nx ln lo lp im bi translated">接下来，我们将读取视频文件，并用对象边界框重写视频。接下来的 3 GitHub Gist 是最后会用到的函数<code class="fe nd ne nf ng b">predict_one_video</code>的一部分。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="1098" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们正在用 MP4 格式写新视频，它在<code class="fe nd ne nf ng b">vid_writer</code>上明确声明。而<code class="fe nd ne nf ng b">fps</code>、<code class="fe nd ne nf ng b">width</code>和<code class="fe nd ne nf ng b">height</code>根据原始视频使用</p><p id="3abb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">开始循环视频上的每一帧以获得预测。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="fe84" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此型号的图像尺寸为 416。一个名为<code class="fe nd ne nf ng b">letterbox</code>的函数正在调整图像的大小，并对图像进行填充，因此宽度或高度中的一个变为 416，另一个小于 416，但仍能被 32 整除</p><p id="72a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第二部分是我们将图像转换成 RGB 格式，并将通道放入第一维<code class="fe nd ne nf ng b">(C,H,W)</code>。将图像数据放入设备(GPU 或 CPU)并将像素从<code class="fe nd ne nf ng b">0-255</code>缩放到<code class="fe nd ne nf ng b">0-1</code>。在我们将图像放入模型之前，我们使用函数<code class="fe nd ne nf ng b">img.unsqeeze(0)</code>，因为我们必须将图像重新格式化为 4 维<code class="fe nd ne nf ng b">(N,C,H,W)</code>，其中 N 是图像的数量，在本例中为 1。</p><p id="fbd6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在对图像进行预处理后，我们把它放入模型中得到预测盒。但是预测有很多盒子，所以我们需要<code class="fe nd ne nf ng b">non-maximum suppression</code>来过滤和合并盒子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mq"><img src="../Images/d6edf1c57d4c5ba66479d6b2e2acd8af.png" data-original-src="https://miro.medium.com/v2/format:webp/1*-5C4AU0OlRf0J81H_d-zNw.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">非最大抑制(NMS)。<a class="ae mv" href="https://mc.ai/detection-free-human-instance-segmentation-using-pose2seg-and-pytorch/" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><h2 id="c688" class="nh lz it bd ma ni nj dn me nk nl dp mi ld nm nn mk lh no np mm ll nq nr mo ns bi translated">绘制边界框和标签，然后编写视频</h2><p id="a787" class="pw-post-body-paragraph ku kv it kw b kx nt ju kz la nu jx lc ld nv lf lg lh nw lj lk ll nx ln lo lp im bi translated">我们在 NMS 之后循环所有的预测<code class="fe nd ne nf ng b">(pred)</code>来绘制盒子，但是图像已经被调整到 416 像素，我们需要使用函数<code class="fe nd ne nf ng b">scale_coords</code>将其缩放回原始大小，然后我们使用函数<code class="fe nd ne nf ng b">plot_one_box</code>来绘制盒子</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><h1 id="92ff" class="ly lz it bd ma mb oa md me mf ob mh mi jz oc ka mk kc od kd mm kf oe kg mo mp bi translated">在 Colab 上显示视频</h1><p id="1b63" class="pw-post-body-paragraph ku kv it kw b kx nt ju kz la nu jx lc ld nv lf lg lh nw lj lk ll nx ln lo lp im bi translated">视频在函数<code class="fe nd ne nf ng b">predict_one_video</code>上被写成 Mp4 格式，保存为 Mp4 后我们压缩成<code class="fe nd ne nf ng b">h264</code>，这样视频就可以直接在 Google Colab / Jupyter 上播放了。</p><h2 id="b7cf" class="nh lz it bd ma ni nj dn me nk nl dp mi ld nm nn mk lh no np mm ll nq nr mo ns bi translated">显示原始视频</h2><p id="1de4" class="pw-post-body-paragraph ku kv it kw b kx nt ju kz la nu jx lc ld nv lf lg lh nw lj lk ll nx ln lo lp im bi translated">我们使用宽度为 400 像素的<code class="fe nd ne nf ng b">IPython.display.HTML</code>显示视频。使用二进制读取视频</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><h2 id="3a83" class="nh lz it bd ma ni nj dn me nk nl dp mi ld nm nn mk lh no np mm ll nq nr mo ns bi translated">压缩并显示处理过的视频</h2><p id="e513" class="pw-post-body-paragraph ku kv it kw b kx nt ju kz la nu jx lc ld nv lf lg lh nw lj lk ll nx ln lo lp im bi translated">OpenCV video writer 的输出是一个 Mp4 视频，其大小是原始视频的 3 倍，并且不能使用相同的方式在 Google Colab 上显示，解决方案之一是我们进行压缩(<a class="ae mv" href="https://stackoverflow.com/questions/33134985/cv2-videowriter-will-not-write-file-using-fourcc-h-264-with-logitech-c920-pyth" rel="noopener ugc nofollow" target="_blank">来源</a></p><p id="a249" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用<code class="fe nd ne nf ng b">ffmpeg -i {save_path} -vcodec libx264 {compressed_path}</code>将 Mp4 视频压缩为 h264</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><h1 id="765c" class="ly lz it bd ma mb oa md me mf ob mh mi jz oc ka mk kc od kd mm kf oe kg mo mp bi translated">结果</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/da15fc95c9b3cae4d829897dba256c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*4qOM9y3SNgsT8zJph9YwHA.gif"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">左边是原始视频，右边是使用这些代码处理的</p></figure><h1 id="5418" class="ly lz it bd ma mb oa md me mf ob mh mi jz oc ka mk kc od kd mm kf oe kg mo mp bi translated">试试你自己的视频</h1><p id="7fd0" class="pw-post-body-paragraph ku kv it kw b kx nt ju kz la nu jx lc ld nv lf lg lh nw lj lk ll nx ln lo lp im bi translated">到 GitHub 上的 Google Colab 文件<a class="ae mv" href="https://colab.research.google.com/github/vindruid/yolov3-in-colab/blob/master/yolov3_video.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a></p><ol class=""><li id="39de" class="og oh it kw b kx ky la lb ld oi lh oj ll ok lp ol om on oo bi translated">将您的视频上传到<code class="fe nd ne nf ng b">input_video</code>文件夹</li><li id="6844" class="og oh it kw b kx op la oq ld or lh os ll ot lp ol om on oo bi translated">只运行最后一个单元格(预测和显示视频)</li></ol></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h1 id="a1ed" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">来源</h1><ul class=""><li id="4d8f" class="og oh it kw b kx nt la nu ld ou lh ov ll ow lp ox om on oo bi translated"><a class="ae mv" href="https://github.com/ultralytics/yolov3" rel="noopener ugc nofollow" target="_blank"> YoloV3 火炬储存库</a></li><li id="2305" class="og oh it kw b kx op la oq ld or lh os ll ot lp ox om on oo bi translated"><a class="ae mv" href="https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=SucxddsPhOmj" rel="noopener ugc nofollow" target="_blank">谷歌 Colab 高级输出</a></li><li id="715e" class="og oh it kw b kx op la oq ld or lh os ll ot lp ox om on oo bi translated"><a class="ae mv" href="https://stackoverflow.com/questions/57377185/how-play-mp4-video-in-google-colab" rel="noopener ugc nofollow" target="_blank">在 Google Colab 上显示视频</a></li><li id="719a" class="og oh it kw b kx op la oq ld or lh os ll ot lp ox om on oo bi translated"><a class="ae mv" href="https://stackoverflow.com/questions/33134985/cv2-videowriter-will-not-write-file-using-fourcc-h-264-with-logitech-c920-pyth" rel="noopener ugc nofollow" target="_blank">视频压缩</a></li></ul><p id="2776" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">感谢您的阅读，希望对您有所帮助</p><h1 id="9369" class="ly lz it bd ma mb oa md me mf ob mh mi jz oc ka mk kc od kd mm kf oe kg mo mp bi translated">接下来的故事:</h1><ul class=""><li id="eda8" class="og oh it kw b kx nt la nu ld ou lh ov ll ow lp ox om on oo bi translated">Yolov3 在 Google Colab 上使用网络摄像头</li><li id="62b4" class="og oh it kw b kx op la oq ld or lh os ll ot lp ox om on oo bi translated">Yolov3 训练手检测</li><li id="6a29" class="og oh it kw b kx op la oq ld or lh os ll ot lp ox om on oo bi translated">Yolov3 训练安全帽</li></ul><h1 id="a5dc" class="ly lz it bd ma mb oa md me mf ob mh mi jz oc ka mk kc od kd mm kf oe kg mo mp bi translated">干杯！！！</h1></div></div>    
</body>
</html>