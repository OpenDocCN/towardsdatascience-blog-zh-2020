<html>
<head>
<title>Find stocks worth buying with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用机器学习找到值得买的股票</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beat-the-stock-market-with-machine-learning-d9432ea5241e?source=collection_archive---------5-----------------------#2020-02-20">https://towardsdatascience.com/beat-the-stock-market-with-machine-learning-d9432ea5241e?source=collection_archive---------5-----------------------#2020-02-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d95d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">有没有可能让一个机器学习模型学习表现良好和表现不佳的股票之间的差异，然后利用这些知识来预测哪只股票值得购买？此外，仅仅通过查看10-K文件中的财务指标就能做到这一点吗？</h2></div><h1 id="a47c" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">懒惰策略</h1><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi la"><img src="../Images/7e11ef6158f8a24601627ade244f0a97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*utcJhqNNVQuIge7MpERdiA.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">马库斯·斯皮斯克在<a class="ae lq" href="https://unsplash.com/s/photos/stock-market?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="eacb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">算法交易领域充斥着新的策略。企业已经在基础设施和R&amp;D上投入了数十亿美元(并且还在继续投资),以便在竞争中脱颖而出，战胜市场。尽管如此，众所周知，<strong class="lt iu">买入&amp;持有策略能够胜过许多算法策略，尤其是在长期</strong>。然而，发现股票价值是一门很少有人掌握的艺术，一个算法能被训练成这样吗？</p><p id="fedd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文包含了为大量股票建立金融数据数据集并使用不同的机器学习模型进行分析所需的所有步骤。<em class="mn">你会在整篇文章中看到，这种操作方式并没有利用历史股票价格数据，而是利用了每个上市公司每年发布的10-K文件中的财务指标</em>。特别是，就本文而言，我们将使用2018年的财务数据，以便对2019年期间(指从2019年1月的第一个交易日到2019年12月的最后一个交易日)的股票表现进行一些虚构的预测。</p><p id="91e7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在开始写代码之前，必须清楚的是<strong class="lt iu">这篇文章并没有给出一个你可以使用的实际交易策略</strong>:</p><ol class=""><li id="f306" class="mo mp it lt b lu lv lx ly ma mq me mr mi ms mm mt mu mv mw bi translated">我不是理财顾问，你也绝对不应该从网上获取理财建议。</li><li id="2a8a" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm mt mu mv mw bi translated">你不能实现它来预测股票市场，因为你缺乏在训练阶段设置标签所需的未来信息。</li></ol><p id="e69b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="mn">本文想要探索的是，通过训练并向最大似然算法提供财务报表中报告的数字，让它们识别价值增长的股票的可能性。</em>为了检查这是否属实，测试阶段由ML算法做出的预测(可被视为虚构交易)将与标准普尔500指数和道琼斯指数进行比较。</p><p id="64a8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后，我们不会在一年内多次买卖股票:我们将使用一种<strong class="lt iu">懒惰策略，</strong>在年初(这里是2019年)买入股票，然后在年底卖出，希望能够盈利。</p><p id="a407" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">说到这里，让我们直接进入有趣的部分。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="b602" class="ki kj it bd kk kl nj kn ko kp nk kr ks jz nl ka ku kc nm kd kw kf nn kg ky kz bi translated">第1部分:构建数据集</h1><h2 id="15e4" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">1.1初步进口</h2><p id="096b" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">如果你熟悉Python中的机器学习，你应该已经知道我们将要使用的所有包和库。如果您是这个领域的新手，不要害怕，您可以找到每个包和库的大量信息和教程。所有使用的包都很容易检索，并且可以根据您的Python设置用<code class="fe of og oh oi b">pip</code>或<code class="fe of og oh oi b">conda</code>安装(这里使用了<code class="fe of og oh oi b">Python 3.7.5</code>)。</p><p id="d118" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了从网上抓取数据，需要互联网连接(我们将使用优秀的免费API<a class="ae lq" href="https://financialmodelingprep.com/developer/docs/" rel="noopener ugc nofollow" target="_blank">https://financialmodelingprep.com/developer/docs/</a>和众所周知的<code class="fe of og oh oi b">pandas_datareader</code>)。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="957c" class="no kj it oi b gy on oo l op oq"><strong class="oi iu">from</strong> <strong class="oi iu">sys</strong> <strong class="oi iu">import</strong> stdout<br/><strong class="oi iu">import</strong> <strong class="oi iu">numpy</strong> <strong class="oi iu">as</strong> <strong class="oi iu">np</strong><br/><strong class="oi iu">import</strong> <strong class="oi iu">pandas</strong> <strong class="oi iu">as</strong> <strong class="oi iu">pd</strong><br/><strong class="oi iu">from</strong> <strong class="oi iu">pandas_datareader</strong> <strong class="oi iu">import</strong> data<br/><strong class="oi iu">import</strong> <strong class="oi iu">json</strong><br/><br/><em class="mn"># Reading data from external sources</em><br/><strong class="oi iu">import</strong> <strong class="oi iu">urllib</strong> <strong class="oi iu">as</strong> <strong class="oi iu">u</strong><br/><strong class="oi iu">from</strong> <strong class="oi iu">urllib.request</strong> <strong class="oi iu">import</strong> urlopen<br/><br/><em class="mn"># Machine learning (preprocessing, models, evaluation)</em><br/><strong class="oi iu">from</strong> <strong class="oi iu">sklearn.model_selection</strong> <strong class="oi iu">import</strong> train_test_split<br/><strong class="oi iu">from</strong> <strong class="oi iu">sklearn.preprocessing</strong> <strong class="oi iu">import</strong> StandardScaler<br/><strong class="oi iu">from</strong> <strong class="oi iu">sklearn.model_selection</strong> <strong class="oi iu">import</strong> GridSearchCV<br/><strong class="oi iu">from</strong> <strong class="oi iu">sklearn.svm</strong> <strong class="oi iu">import</strong> SVC<br/><strong class="oi iu">from</strong> <strong class="oi iu">sklearn.ensemble</strong> <strong class="oi iu">import</strong> RandomForestClassifier<br/><strong class="oi iu">from</strong> <strong class="oi iu">sklearn.neural_network</strong> <strong class="oi iu">import</strong> MLPClassifier<br/><strong class="oi iu">import</strong> <strong class="oi iu">xgboost</strong> <strong class="oi iu">as</strong> <strong class="oi iu">xgb</strong><br/><strong class="oi iu">from</strong> <strong class="oi iu">sklearn.metrics</strong> <strong class="oi iu">import</strong> classification_report<br/><br/><em class="mn"># Graphics</em><br/><strong class="oi iu">from</strong> <strong class="oi iu">tqdm</strong> <strong class="oi iu">import</strong> tqdm</span></pre><p id="7194" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了简化代码，我们还需要一些助手函数:</p><ol class=""><li id="7fbb" class="mo mp it lt b lu lv lx ly ma mq me mr mi ms mm mt mu mv mw bi translated"><code class="fe of og oh oi b">get_json_data</code>:用于抓取financialmodelingprep API的链接，拉取财务数据。</li><li id="e0a3" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm mt mu mv mw bi translated"><code class="fe of og oh oi b">get_price_var</code>:用于计算2019年期间的价格变化，利用<code class="fe of og oh oi b">pandas_datareader</code>和雅虎财经。</li><li id="5491" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm mt mu mv mw bi translated"><code class="fe of og oh oi b">find_in_json</code>:用来扫描一个复杂的json文件，寻找一个键并返回它的值。</li></ol><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="c888" class="no kj it oi b gy on oo l op oq"><strong class="oi iu">def</strong> get_json_data(url):<br/>    <em class="mn">'''</em><br/><em class="mn">    Scrape data (which must be json format) from given url</em><br/><em class="mn">    Input: url to financialmodelingprep API</em><br/><em class="mn">    Output: json file</em><br/><em class="mn">    '''</em><br/>    response = urlopen(url)<br/>    dat = response.read().decode('utf-8')<br/>    <strong class="oi iu">return</strong> json.loads(dat)<br/><br/><strong class="oi iu">def</strong> get_price_var(symbol):<br/>    <em class="mn">'''</em><br/><em class="mn">    Get historical price data for a given symbol leveraging the power of pandas_datareader and Yahoo.</em><br/><em class="mn">    Compute the difference between first and last available time-steps in terms of Adjusted Close price..</em><br/><em class="mn">    Input: ticker symbol</em><br/><em class="mn">    Output: price variation </em><br/><em class="mn">    '''</em><br/>    <em class="mn"># read data</em><br/>    prices = data.DataReader(symbol, 'yahoo', '2019-01-01', '2019-12-31')['Adj Close']<br/><br/>    <em class="mn"># get all timestamps for specific lookups</em><br/>    today = prices.index[-1]<br/>    start = prices.index[0]<br/><br/>    <em class="mn"># calculate percentage price variation</em><br/>    price_var = ((prices[today] - prices[start]) / prices[start]) * 100<br/>    <strong class="oi iu">return</strong> price_var<br/><br/><strong class="oi iu">def</strong> find_in_json(obj, key):<br/>    <em class="mn">'''</em><br/><em class="mn">    Scan the json file to find the value of the required key.</em><br/><em class="mn">    Input: json file</em><br/><em class="mn">           required key</em><br/><em class="mn">    Output: value corresponding to the required key</em><br/><em class="mn">    '''</em><br/>    <em class="mn"># Initialize output as empty</em><br/>    arr = []<br/><br/>    <strong class="oi iu">def</strong> extract(obj, arr, key):<br/>        <em class="mn">'''</em><br/><em class="mn">        Recursively search for values of key in json file.</em><br/><em class="mn">        '''</em><br/>        <strong class="oi iu">if</strong> isinstance(obj, dict):<br/>            <strong class="oi iu">for</strong> k, v <strong class="oi iu">in</strong> obj.items():<br/>                <strong class="oi iu">if</strong> isinstance(v, (dict, list)):<br/>                    extract(v, arr, key)<br/>                <strong class="oi iu">elif</strong> k == key:<br/>                    arr.append(v)<br/>        <strong class="oi iu">elif</strong> isinstance(obj, list):<br/>            <strong class="oi iu">for</strong> item <strong class="oi iu">in</strong> obj:<br/>                extract(item, arr, key)<br/>        <strong class="oi iu">return</strong> arr<br/><br/>    results = extract(obj, arr, key)<br/>    <strong class="oi iu">return</strong> results</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="28c2" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">1.2股票清单</h2><p id="6e5b" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">首先，我们需要获得将用于构建数据集的股票列表。由于有数以千计的股票的信息可以在网上搜集，我决定简单地在金融建模准备API上获取所有股票的列表。</p><p id="cc53" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这份名单包含了总共超过7k只股票，显然涵盖了不止一个行业。事实上，每个公司都属于自己的领域(科技、医疗、能源……)，而这些领域又可能具有某些季节性、宏观经济趋势等特征。到目前为止，我决定专注于技术板块:这意味着从完整的可用股票列表<code class="fe of og oh oi b">available_tickers</code>中，我只保留那些板块等于<code class="fe of og oh oi b">Technology</code>的股票。多亏了<code class="fe of og oh oi b">pandas</code>库的强大功能，这个操作非常简单。</p><p id="0175" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">因此，列表<code class="fe of og oh oi b">tickers_tech</code>将包含金融建模准备API上属于技术部门的所有可用股票。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="f06f" class="no kj it oi b gy on oo l op oq">url = 'https://financialmodelingprep.com/api/v3/company/stock/list'<br/>ticks_json = get_json_data(url)<br/>available_tickers = find_in_json(ticks_json, 'symbol')<br/><br/>tickers_sector = []<br/><strong class="oi iu">for</strong> tick <strong class="oi iu">in</strong> tqdm(available_tickers):<br/>    url = 'https://financialmodelingprep.com/api/v3/company/profile/' + tick <em class="mn"># get sector from here</em><br/>    a = get_json_data(url)<br/>    tickers_sector.append(find_in_json(a, 'sector'))<br/><br/>S = pd.DataFrame(tickers_sector, index=available_tickers, columns=['Sector'])<br/><br/><em class="mn"># Get list of tickers from TECHNOLOGY sector</em><br/>tickers_tech = S[S['Sector'] == 'Technology'].index.values.tolist()</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="d8af" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">1.3了解2019年全年的价格变化</h2><p id="1812" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">2019年期间<code class="fe of og oh oi b">tickers_tech</code>中列出的每只股票的价格变化将被用作区分值得购买和不值得购买的股票的指标(因为它们降低了它们的价值，出于我们并不真正关心的原因)。因此，我们需要:</p><ul class=""><li id="62c5" class="mo mp it lt b lu lv lx ly ma mq me mr mi ms mm or mu mv mw bi translated">提取每只股票的所有<strong class="lt iu">每日调整收盘价</strong>，计算差价(这要感谢助手函数<code class="fe of og oh oi b">get_price_var</code></li><li id="2fc7" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">如果没有找到数据，跳过股票</li><li id="0b77" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">限制要扫描的股票数量为1000(出于时间原因。当我们提取财务数据时，所需的时间与股票数量成正比，因此为了保持合理，我们可以将股票数量限制在一个阈值内。但是，您可以放弃此检查，让计算机在夜间工作)。</li><li id="ca7f" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">在数据框架中存储库存和2019年相对价格变化<code class="fe of og oh oi b">D</code></li></ul><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="9f68" class="no kj it oi b gy on oo l op oq">pvar_list, tickers_found = [], []<br/>num_tickers_desired = 1000<br/>count = 0<br/>tot = 0<br/>TICKERS = tickers_tech<br/><br/><strong class="oi iu">for</strong> ticker <strong class="oi iu">in</strong> TICKERS:<br/>    tot += 1 <br/>    <strong class="oi iu">try</strong>:<br/>        pvar = get_price_var(ticker)<br/>        pvar_list.append(pvar)<br/>        tickers_found.append(ticker)<br/>        count += 1<br/>    <strong class="oi iu">except</strong>:<br/>        <strong class="oi iu">pass</strong><br/><br/>    stdout.write(f'<strong class="oi iu">\r</strong>Scanned <strong class="oi iu">{tot}</strong> tickers. Found <strong class="oi iu">{count}</strong>/{len(TICKERS)} usable tickers (max tickets = <strong class="oi iu">{num_tickers_desired}</strong>).')<br/>    stdout.flush()<br/><br/>    <strong class="oi iu">if</strong> count == num_tickers_desired: <em class="mn"># if there are more than 1000 tickers in sectors, stop</em><br/>        <strong class="oi iu">break</strong><br/><br/><em class="mn"># Store everything in a dataframe</em><br/>D = pd.DataFrame(pvar_list, index=tickers_found, columns=['2019 PRICE VAR [%]'])</span></pre><p id="fd95" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于<code class="fe of og oh oi b">D</code>中的股票，我们现在需要找到将成为分类模型输入数据的指标值。我们再次利用了FinancialModelingPrep API。</p><p id="79fb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">首先，我们加载<code class="fe of og oh oi b">indicators.tx</code>文件(可以在存储库中找到)。正如<code class="fe of og oh oi b">README</code>文件所解释的，过多的财务指标正在被剔除。我决定对来自FinancialModelingPrep API的所有可用指标执行一次<strong class="lt iu">强力操作</strong>，然后我将担心清理和准备模型的数据集。下表汇总了每个类别可用的财务指标数量。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi os"><img src="../Images/2f07a5576804e91d78d3c663d09aef15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lDj5eOKbgwqt3pmyWszjog.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">API中每个类别可用的财务指标数量(<a class="ae lq" href="https://financialmodelingprep.com" rel="noopener ugc nofollow" target="_blank">https://financialmodelingprep.com</a>)。</p></figure><p id="db2d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">总共有224个指标可用。但由于有一些重复，所以<code class="fe of og oh oi b">indicators.txt</code>中指标的实际数量是221(不算日期)。你可以在这里找到<code class="fe of og oh oi b">indicators.txt</code>文件:<a class="ae lq" href="https://github.com/CNIC92/beat-the-stock-market/tree/master/All%20tickers%20and%20Indicators" rel="noopener ugc nofollow" target="_blank">https://github . com/cnic 92/beat-the-stock-market/tree/master/All % 20 tickers % 20 and % 20 indicators</a></p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="9781" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">1.4收集财务指标并构建原始数据集</h2><p id="0f9b" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">截至目前，我们已经列出了属于技术板块的股票，并且我们还列出了它们2019年的价格变化。是时候收集财务指标了，这些指标将在以后用作分类模型的输入特征。</p><p id="ce24" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">由于财务建模准备API，将再次执行抓取。这个过程非常耗时，因为需要反复提取大量数据。</p><p id="eb59" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">此外，记住以下几点很重要:</p><ul class=""><li id="6222" class="mo mp it lt b lu lv lx ly ma mq me mr mi ms mm or mu mv mw bi translated">需要在特定的时间范围内提取数据。由于目标是根据2019年期间的价格变化对股票进行分类，因此财务指标必须属于2018年底。</li><li id="80b5" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">一家公司在同一年提交两份10-K文件是有可能的，尽管不常见。在这种情况下，必须只保留最近的条目。</li><li id="431b" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">对于给定的股票，API可能根本不返回任何数据。在这种情况下，原料必须废弃。</li><li id="8108" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">并非所有指示器都会返回值。出于这样或那样的原因，有一定比例的指标缺失是合理的。在这种情况下，<code class="fe of og oh oi b">np.nan</code>将被分配给缺失的条目，我们将在清理阶段处理它们。</li></ul><p id="6ae9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后，我们想要获得的是一个数据帧<code class="fe of og oh oi b">DATA</code>，其中行对应于已经找到数据的股票(<code class="fe of og oh oi b">actual_tickers</code>)，列对应于财务指标(<code class="fe of og oh oi b">indicators</code>)。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="baf2" class="no kj it oi b gy on oo l op oq"><em class="mn"># Initialize lists and dataframe (dataframe is a 2D numpy array filled with 0s)</em><br/>missing_tickers, missing_index = [], []<br/>d = np.zeros((len(tickers_found), len(indicators)))<br/><br/><strong class="oi iu">for</strong> t, _ <strong class="oi iu">in</strong> enumerate(tqdm(tickers_found)):<br/>    <em class="mn"># Scrape indicators from financialmodelingprep API</em><br/>    url0 = 'https://financialmodelingprep.com/api/v3/financials/income-statement/' + tickers_found[t]<br/>    url1 = 'https://financialmodelingprep.com/api/v3/financials/balance-sheet-statement/' + tickers_found[t]<br/>    url2 = 'https://financialmodelingprep.com/api/v3/financials/cash-flow-statement/' + tickers_found[t]<br/>    url3 = 'https://financialmodelingprep.com/api/v3/financial-ratios/' + tickers_found[t]<br/>    url4 = 'https://financialmodelingprep.com/api/v3/company-key-metrics/' + tickers_found[t]<br/>    url5 = 'https://financialmodelingprep.com/api/v3/financial-statement-growth/' + tickers_found[t]<br/>    a0 = get_json_data(url0)<br/>    a1 = get_json_data(url1)<br/>    a2 = get_json_data(url2)<br/>    a3 = get_json_data(url3)<br/>    a4 = get_json_data(url4)<br/>    a5 = get_json_data(url5)<br/>    <br/>    <em class="mn"># Combine all json files in a list, so that it can be scanned quickly</em><br/>    A = [a0, a1, a2 , a3, a4, a5]<br/>    all_dates = find_in_json(A, 'date')<br/><br/>    check = [s <strong class="oi iu">for</strong> s <strong class="oi iu">in</strong> all_dates <strong class="oi iu">if</strong> '2018' <strong class="oi iu">in</strong> s] <em class="mn"># find all 2018 entries in dates</em><br/>    <strong class="oi iu">if</strong> len(check) &gt; 0:<br/>        date_index = all_dates.index(check[0]) <em class="mn"># get most recent 2018 entries, if more are present</em><br/><br/>        <strong class="oi iu">for</strong> i, _ <strong class="oi iu">in</strong> enumerate(indicators):<br/>            ind_list = find_in_json(A, indicators[i])<br/>            <strong class="oi iu">try</strong>:<br/>                d[t][i] = ind_list[date_index]<br/>            <strong class="oi iu">except</strong>:<br/>                d[t][i] = np.nan <em class="mn"># in case there is no value inserted for the given indicator</em><br/><br/>    <strong class="oi iu">else</strong>:<br/>        missing_tickers.append(tickers_found[t])<br/>        missing_index.append(t)<br/><br/>actual_tickers = [x <strong class="oi iu">for</strong> x <strong class="oi iu">in</strong> tickers_found <strong class="oi iu">if</strong> x <strong class="oi iu">not</strong> <strong class="oi iu">in</strong> missing_tickers]<br/>d = np.delete(d, missing_index, 0)</span><span id="9d45" class="no kj it oi b gy ot oo l op oq"><em class="mn">#raw dataset<br/></em>DATA = pd.DataFrame(d, index=actual_tickers, columns=indicators)</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="84ba" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">1.5数据集清理和准备</h2><p id="bad2" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">数据集的准备在某种程度上是一门艺术。我将我的行动限制在应用常见的实践，例如:</p><ul class=""><li id="b06c" class="mo mp it lt b lu lv lx ly ma mq me mr mi ms mm or mu mv mw bi translated">删除具有大量<code class="fe of og oh oi b">nan</code>值的列。</li><li id="69bc" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">删除具有大量<code class="fe of og oh oi b">0</code>值的列。</li><li id="6a89" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">用该列的平均值填充剩余的<code class="fe of og oh oi b">nan</code>值。</li></ul><p id="8841" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">例如，在这种特定情况下，每列平均有84个0值<em class="mn">和140的标准偏差。所以我决定从dataframe中删除所有那些出现的<em class="mn"> 0值</em>大于20的列(20大约是数据集总行数的3.1%)。</em></p><p id="0370" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">同时，每列平均约有37个<code class="fe of og oh oi b">nan</code>条目，标准差约为86。所以我决定从数据帧中删除所有那些出现次数大于15的列(15大约是数据集总行数的2.4%)。然后，剩余的<code class="fe of og oh oi b">nan</code>条目已经用该列的平均值填充。</p><p id="c5b7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在清洗过程结束时，<code class="fe of og oh oi b">DATA</code>的列数从221列减少到108列，减少了50%。虽然由于缺乏数据，一些被丢弃的指标毫无用处，但有用的数据也有可能在这一过程中丢失。但是，必须考虑到我们需要数据集中所有股票的有用数据，所以我认为丢弃那些可能只与数据集一小部分相关的指标(列)是可以接受的。</p><p id="2cee" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后，<strong class="lt iu">需要对每个样本进行分类</strong>。对于每只股票，已经计算了2019年1月第一个交易日和2019年12月最后一个交易日之间的交易价格差异(数据集<code class="fe of og oh oi b">D</code>)。如果这个差值为正，那么该股票将属于类别<code class="fe of og oh oi b">1</code>，这是一个<strong class="lt iu">买入</strong>信号。相反，如果价格差异为负，该股票将被归类为<code class="fe of og oh oi b">0</code>，这是一个<strong class="lt iu">忽略</strong>信号(不要买入)。下表提供了一个快速回顾。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi ou"><img src="../Images/ee9e9f4469ebe7ad42607abd7d988de5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMp16Jk4Dt7S9DQ6F6wRnQ.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">为股票指定二元分类的标准。</p></figure><p id="f372" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">因此，<code class="fe of og oh oi b">1</code>和<code class="fe of og oh oi b">0</code>值的数组将作为数据帧<code class="fe of og oh oi b">DATA</code>的最后一列被追加。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="f1f4" class="no kj it oi b gy on oo l op oq"><em class="mn"># Remove columns that have more than 20 0-values</em><br/>DATA = DATA.loc[:, DATA.isin([0]).sum() &lt;= 20]<br/><br/><em class="mn"># Remove columns that have more than 15 nan-values</em><br/>DATA = DATA.loc[:, DATA.isna().sum() &lt;= 15]<br/><br/><em class="mn"># Fill remaining nan-values with column mean value</em><br/>DATA = DATA.apply(<strong class="oi iu">lambda</strong> x: x.fillna(x.mean())) <br/><br/><em class="mn"># Get price variation data only for tickers to be used</em><br/>D2 = D.loc[DATA.index.values, :]<br/><br/><em class="mn"># Generate classification array</em><br/>y = []<br/><strong class="oi iu">for</strong> i, _ <strong class="oi iu">in</strong> enumerate(D2.index.values):<br/>    <strong class="oi iu">if</strong> D2.values[i] &gt;= 0:<br/>        y.append(1)<br/>    <strong class="oi iu">else</strong>: <br/>        y.append(0)<br/><br/><em class="mn"># Add array to dataframe</em><br/>DATA['class'] = y</span></pre><p id="cf35" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文的第一部分到此结束。我们建立了一个数据集，其中包含2018年的相关金融指标和来自2019年股票价格走势的二元类。在第2节中，我们将重点介绍一些机器学习算法的实现，以便对股票进行预测，并努力战胜市场！</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="9ea5" class="ki kj it bd kk kl nj kn ko kp nk kr ks jz nl ka ku kc nm kd kw kf nn kg ky kz bi translated">第2部分:通过机器学习算法进行虚拟预测</h1><h2 id="3d15" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">2.1准备数据集</h2><p id="9005" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">在用不同的机器学习算法进行有趣的实验之前，我们必须对数据集进行最后的润色，包括:</p><ol class=""><li id="525a" class="mo mp it lt b lu lv lx ly ma mq me mr mi ms mm mt mu mv mw bi translated">在训练和测试数据集中拆分数据集；</li><li id="52ed" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm mt mu mv mw bi translated">标准化数据集，使每个指标的均值为0，标准差等于1。</li></ol><p id="66ed" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">因此，关于将它分成训练和测试，在<code class="fe of og oh oi b">DATA</code>中80%的可用数据将用于训练算法，而剩余的20%将用于测试ML算法。请注意所使用的参数<code class="fe of og oh oi b">stratify</code>，以便在训练和测试数据集之间保持相同的类比率。从<code class="fe of og oh oi b">train_split</code>和<code class="fe of og oh oi b">test_split</code>中，我们提取输入数据<code class="fe of og oh oi b">X_train</code>、<code class="fe of og oh oi b">X_test</code>和输出目标数据<code class="fe of og oh oi b">y_train</code>、<code class="fe of og oh oi b">y_test</code>。之后会执行健全性检查。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="2439" class="no kj it oi b gy on oo l op oq"><em class="mn"># Divide data in train and testing</em><br/>train_split, test_split = train_test_split(df, test_size=0.2, random_state=1, stratify=df['class'])<br/>X_train = train_split.iloc[:, :-1].values<br/>y_train = train_split.iloc[:, -1].values<br/>X_test = test_split.iloc[:, :-1].values<br/>y_test = test_split.iloc[:, -1].values<br/><br/>print()<br/>print(f'Number of training samples: <strong class="oi iu">{X_train.shape[0]}</strong>')<br/>print()<br/>print(f'Number of testing samples: <strong class="oi iu">{X_test.shape[0]}</strong>')<br/>print()<br/>print(f'Number of features: <strong class="oi iu">{X_train.shape[1]}</strong>')</span></pre><p id="6080" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">结果是:</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="e575" class="no kj it oi b gy on oo l op oq">Number of training samples: 510<br/><br/>Number of testing samples: 128<br/><br/>Number of features: 107</span></pre><p id="1338" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">关于数据的标准化，我们利用从<code class="fe of og oh oi b">scikit-learn</code>获得的<code class="fe of og oh oi b">StandardScaler()</code>。<strong class="lt iu">在标准化训练和测试数据</strong>时使用相同的系数是很重要的:为此，我们首先将定标器应用于<code class="fe of og oh oi b">X_train</code>，然后通过方法<code class="fe of og oh oi b">.transform()</code>将其应用于<code class="fe of og oh oi b">X_train</code>和<code class="fe of og oh oi b">X_test</code>。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="4a70" class="no kj it oi b gy on oo l op oq"><em class="mn"># Standardize input data</em><br/>scaler = StandardScaler()<br/>scaler.fit(X_train)<br/>X_train = scaler.transform(X_train)<br/>X_test = scaler.transform(X_test)</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="ab44" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">2.2支持向量机</h2><p id="ff04" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">我们将运行的第一个分类算法是支持向量机。执行<code class="fe of og oh oi b">GridSeachCV</code>是为了调整一些超参数(<code class="fe of og oh oi b">kernel</code>、<code class="fe of og oh oi b">gamma</code>、<code class="fe of og oh oi b">C</code>)。所需的交叉验证次数设置为5。我们希望实现最大的加权精度，以便最小化<em class="mn">假阳性</em>的数量。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="1714" class="no kj it oi b gy on oo l op oq"><em class="mn"># Parameter grid to be tuned</em><br/>tuned_parameters = [{'kernel': ['rbf', 'linear'],<br/>                     'gamma': [1e-3, 1e-4],<br/>                     'C': [0.01, 0.1, 1, 10, 100]}]<br/><br/>clf1 = GridSearchCV(SVC(random_state=1),<br/>                    tuned_parameters,<br/>                    n_jobs=6,<br/>                    scoring='precision_weighted',<br/>                    cv=5)<br/>clf1.fit(X_train, y_train)<br/><br/>print('Best score and parameters found on development set:')<br/>print()<br/>print('<strong class="oi iu">%0.3f</strong> for <strong class="oi iu">%r</strong>' % (clf1.best_score_, clf1.best_params_))<br/>print()</span></pre><p id="0b8b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">成绩还不算太差。我们可以看到，如下图所示，我们的加权精度为71.3%。如果您仔细阅读，您可能会注意到<strong class="lt iu">评分参数被设置为等于metric precision_weighted </strong>。这样做是为了优化算法的精度(不要与精度混淆！)和加权，因为我们没有两类(值得购买的股票和不值得购买的股票)相同数量的样本。关于这个和其他评分参数的更多信息，你可以查看这里的文档<a class="ae lq" href="https://scikit-learn.org/stable/modules/model_evaluation.html" rel="noopener ugc nofollow" target="_blank">https://scikit learn . org/stable/modules/model _ evaluation . html</a>。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="06eb" class="no kj it oi b gy on oo l op oq">Best score and parameters found on development set: 0.713 for {‘C’: 0.01, ‘gamma’: 0.001, ‘kernel’: ‘linear’}</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="3096" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">2.3随机森林</h2><p id="cfe3" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">我们将运行的第二个分类算法是随机森林。执行<code class="fe of og oh oi b">GridSeachCV</code>是为了调整一些超参数(<code class="fe of og oh oi b">n_estimators</code>、<code class="fe of og oh oi b">max_features</code>、<code class="fe of og oh oi b">max_depth</code>、<code class="fe of og oh oi b">criterion</code>)。所需的交叉验证次数设置为5。我们希望实现最大的加权精度，以便最小化<em class="mn">假阳性</em>的数量。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="8609" class="no kj it oi b gy on oo l op oq"><em class="mn"># Parameter grid to be tuned</em><br/>tuned_parameters = {'n_estimators': [32, 256, 512, 1024],<br/>                    'max_features': ['auto', 'sqrt'],<br/>                    'max_depth': [4, 5, 6, 7, 8],<br/>                    'criterion': ['gini', 'entropy']}</span><span id="7aa2" class="no kj it oi b gy ot oo l op oq">clf2 = GridSearchCV(RandomForestClassifier(random_state=1),<br/>                    tuned_parameters,<br/>                    n_jobs=6,<br/>                    scoring='precision_weighted',<br/>                    cv=5)<br/>clf2.fit(X_train, y_train)</span><span id="a984" class="no kj it oi b gy ot oo l op oq">print('Best score and parameters found on development set:')<br/>print()<br/>print('<strong class="oi iu">%0.3f</strong> for <strong class="oi iu">%r</strong>' % (clf2.best_score_, clf2.best_params_))<br/>print()</span></pre><p id="c20c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们可以看到，如下所示，该算法比支持向量机高出几个百分点，因为我们的加权精度为72.4%。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="218c" class="no kj it oi b gy on oo l op oq">Best score and parameters found on development set:  0.724 for {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 32}</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="c309" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">2.4极限梯度提升</h2><p id="a76b" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">我们将运行的第三个分类算法是极端梯度提升。执行<code class="fe of og oh oi b">GridSeachCV</code>是为了调整一些超参数(<code class="fe of og oh oi b">learning_rate</code>、<code class="fe of og oh oi b">max_depth</code>、<code class="fe of og oh oi b">n_estimators</code>)。所需的交叉验证次数设置为5。我们希望实现最大的加权精度，以便最小化<em class="mn">假阳性</em>的数量。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="bab7" class="no kj it oi b gy on oo l op oq"><em class="mn"># Parameter grid to be tuned</em><br/>tuned_parameters = {'learning_rate': [0.01, 0.001],<br/>                    'max_depth': [4, 5, 6, 7, 8],<br/>                    'n_estimators': [32, 128, 256]}</span><span id="547c" class="no kj it oi b gy ot oo l op oq">clf3 = GridSearchCV(xgb.XGBClassifier(random_state=1),<br/>                   tuned_parameters,<br/>                   n_jobs=6,<br/>                   scoring='precision_weighted', <br/>                   cv=5)<br/>clf3.fit(X_train, y_train)</span><span id="fe8c" class="no kj it oi b gy ot oo l op oq">print('Best score and parameters found on development set:')<br/>print()<br/>print('<strong class="oi iu">%0.3f</strong> for <strong class="oi iu">%r</strong>' % (clf3.best_score_, clf3.best_params_))<br/>print()</span></pre><p id="54c9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">该算法比支持向量机和随机森林分类器低几个百分点，因为我们的加权精度为69.7%。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="4aa4" class="no kj it oi b gy on oo l op oq">Best score and parameters found on development set:  0.697 for {'learning_rate': 0.001, 'max_depth': 4, 'n_estimators': 256}</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="b426" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">2.5多层感知器</h2><p id="4ad2" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">我们将运行的第四个分类算法是多层感知器(前馈神经网络)。执行<code class="fe of og oh oi b">GridSeachCV</code>是为了调整一些超参数(<code class="fe of og oh oi b">hidden_layer_sizes</code>、<code class="fe of og oh oi b">activation</code>、<code class="fe of og oh oi b">solver</code>)。所需的交叉验证次数设置为5。我们希望获得最大的加权精度，以便最小化<em class="mn">假阳性</em>的数量。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="727e" class="no kj it oi b gy on oo l op oq"><em class="mn"># Parameter grid to be tuned</em><br/>tuned_parameters = {'hidden_layer_sizes': [(32,), (64,), (32, 64, 32)],<br/>                    'activation': ['tanh', 'relu'],<br/>                    'solver': ['lbfgs', 'adam']}</span><span id="b826" class="no kj it oi b gy ot oo l op oq">clf4 = GridSearchCV(MLPClassifier(random_state=1, batch_size=4, early_stopping=<strong class="oi iu">True</strong>), <br/>                    tuned_parameters,<br/>                    n_jobs=6,<br/>                    scoring='precision_weighted',<br/>                    cv=5)<br/>clf4.fit(X_train, y_train)</span><span id="04c7" class="no kj it oi b gy ot oo l op oq">print('Best score, and parameters, found on development set:')<br/>print()<br/>print('<strong class="oi iu">%0.3f</strong> for <strong class="oi iu">%r</strong>' % (clf4.best_score_, clf4.best_params_))<br/>print()</span></pre><p id="150c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这个算法是最好的，因为它优于所有以前测试过的算法。MLP的加权精度为73%。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="0546" class="no kj it oi b gy on oo l op oq">Best score, and parameters, found on development set:  0.730 for {'activation': 'relu', 'hidden_layer_sizes': (32, 64, 32), 'solver': 'adam'}</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="7830" class="no kj it bd kk np nq dn ko nr ns dp ks ma nt nu ku me nv nw kw mi nx ny ky nz bi translated">2.6评估模型</h2><p id="8a4f" class="pw-post-body-paragraph lr ls it lt b lu oa ju lw lx ob jx lz ma oc mc md me od mg mh mi oe mk ml mm im bi translated">既然已经训练了4种分类算法，我们必须对它们进行测试，并比较它们之间的性能，以及它们与该领域基准(标准普尔500、道琼斯)的性能。事实上，我们并不局限于比较它们的测试精度:<strong class="lt iu">我们想了解哪种算法能带来最好的投资回报(ROI) </strong>。要做到这一点，我们必须首先获得包含在<code class="fe of og oh oi b">pvar</code>中的2019年价格变化，这些股票只属于测试数据集(我们还没有使用它！).</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="cf13" class="no kj it oi b gy on oo l op oq"><em class="mn"># Get 2019 price variations ONLY for the stocks in testing split</em><br/>pvar_test = pvar.loc[test_split.index.values, :]</span></pre><p id="525e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，我们构建一个新的数据框架<code class="fe of og oh oi b">df1</code>，其中，对于每只测试的股票，我们从每个模型中收集所有的预测类(需要提醒的是，这两个类是<code class="fe of og oh oi b">0</code> =IGNORE，<code class="fe of og oh oi b">1</code> =BUY)。</p><p id="3c45" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果模型预测了类别<code class="fe of og oh oi b">1</code>，我们继续购买价值100美元的股票；否则，我们忽略股票。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="40e3" class="no kj it oi b gy on oo l op oq"><em class="mn"># Initial investment can be $100 for each stock whose predicted class = 1</em><br/>buy_amount = 100</span><span id="74fa" class="no kj it oi b gy ot oo l op oq"><em class="mn"># In new dataframe df1, store all the information regarding each model's predicted class and relative gain/loss in $USD</em><br/>df1 = pd.DataFrame(y_test, index=test_split.index.values, columns=['ACTUAL']) <em class="mn"># first column is the true class (BUY/INGORE)</em></span><span id="2201" class="no kj it oi b gy ot oo l op oq">df1['SVM'] = clf1.predict(X_test) <em class="mn"># predict class for testing dataset</em><br/>df1['VALUE START SVM [$]'] = df1['SVM'] * buy_amount <em class="mn"># if class = 1 --&gt; buy $100 of that stock</em><br/>df1['VAR SVM [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START SVM [$]'] <em class="mn"># compute price variation in $</em><br/>df1['VALUE END SVM [$]'] = df1['VALUE START SVM [$]'] + df1['VAR SVM [$]'] <em class="mn"># compute final value</em></span><span id="35f7" class="no kj it oi b gy ot oo l op oq">df1['RF'] = clf2.predict(X_test)<br/>df1['VALUE START RF [$]'] = df1['RF'] * buy_amount<br/>df1['VAR RF [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START RF [$]']<br/>df1['VALUE END RF [$]'] = df1['VALUE START RF [$]'] + df1['VAR RF [$]']</span><span id="9b76" class="no kj it oi b gy ot oo l op oq">df1['XGB'] = clf3.predict(X_test)<br/>df1['VALUE START XGB [$]'] = df1['XGB'] * buy_amount<br/>df1['VAR XGB [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START XGB [$]']<br/>df1['VALUE END XGB [$]'] = df1['VALUE START XGB [$]'] + df1['VAR XGB [$]']</span><span id="5f43" class="no kj it oi b gy ot oo l op oq">df1['MLP'] = clf4.predict(X_test)<br/>df1['VALUE START MLP [$]'] = df1['MLP'] * buy_amount<br/>df1['VAR MLP [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START MLP [$]']<br/>df1['VALUE END MLP [$]'] = df1['VALUE START MLP [$]'] + df1['VAR MLP [$]']</span></pre><p id="8b5c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后，我们构建了一个紧凑的数据框架<code class="fe of og oh oi b">MODELS_COMPARISON</code>，在其中我们收集了在分类模型和基准(S &amp; P 500，DOW JONES)之间进行比较所需的主要信息。</p><p id="c2ce" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">利用数据框架<code class="fe of og oh oi b">df1</code>，我们可以轻松计算每个模型的收益和损失(<code class="fe of og oh oi b">net_gain_</code>、<code class="fe of og oh oi b">percent_gain_</code>)。</p><p id="fc8e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">由于我们错过了基准测试的数据，我们很快利用自定义函数<code class="fe of og oh oi b">get_price_var</code>来获得2019年标准普尔500 (^GSPC)和道琼斯(^DJI)的价格变化百分比。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="a123" class="no kj it oi b gy on oo l op oq"><em class="mn"># Create a new, compact, dataframe in order to show gain/loss for each model</em><br/>start_value_svm = df1['VALUE START SVM [$]'].sum()<br/>final_value_svm = df1['VALUE END SVM [$]'].sum()<br/>net_gain_svm = final_value_svm - start_value_svm<br/>percent_gain_svm = (net_gain_svm / start_value_svm) * 100</span><span id="51a5" class="no kj it oi b gy ot oo l op oq">start_value_rf = df1['VALUE START RF [$]'].sum()<br/>final_value_rf = df1['VALUE END RF [$]'].sum()<br/>net_gain_rf = final_value_rf - start_value_rf<br/>percent_gain_rf = (net_gain_rf / start_value_rf) * 100</span><span id="178d" class="no kj it oi b gy ot oo l op oq">start_value_xgb = df1['VALUE START XGB [$]'].sum()<br/>final_value_xgb = df1['VALUE END XGB [$]'].sum()<br/>net_gain_xgb = final_value_xgb - start_value_xgb<br/>percent_gain_xgb = (net_gain_xgb / start_value_xgb) * 100</span><span id="ba92" class="no kj it oi b gy ot oo l op oq">start_value_mlp = df1['VALUE START MLP [$]'].sum()<br/>final_value_mlp = df1['VALUE END MLP [$]'].sum()<br/>net_gain_mlp = final_value_mlp - start_value_mlp<br/>percent_gain_mlp = (net_gain_mlp / start_value_mlp) * 100</span><span id="2058" class="no kj it oi b gy ot oo l op oq">percent_gain_sp500 = get_price_var('^GSPC') <em class="mn"># get percent gain of S&amp;P500 index</em><br/>percent_gain_dj = get_price_var('^DJI') <em class="mn"># get percent gain of DOW JONES index</em></span><span id="9072" class="no kj it oi b gy ot oo l op oq">MODELS_COMPARISON = pd.DataFrame([start_value_svm, final_value_svm, net_gain_svm, percent_gain_svm],<br/>                    index=['INITIAL COST [USD]', 'FINAL VALUE [USD]', '[USD] GAIN/LOSS', 'ROI'], columns=['SVM'])<br/>MODELS_COMPARISON['RF'] = [start_value_rf, final_value_rf, net_gain_rf, percent_gain_rf]<br/>MODELS_COMPARISON['XGB'] = [start_value_xgb, final_value_xgb, net_gain_xgb, percent_gain_xgb]<br/>MODELS_COMPARISON['MLP'] = [start_value_mlp, final_value_mlp, net_gain_mlp, percent_gain_mlp]<br/>MODELS_COMPARISON['S&amp;P 500'] = ['', '', '', percent_gain_sp500]<br/>MODELS_COMPARISON['DOW JONES'] = ['', '', '', percent_gain_dj]</span></pre><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi ov"><img src="../Images/e5cb860d25657a146e1568731f2f4f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vrPk72DNP1daXZ7d5GBOTA.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">MODELS_COMPARISON数据集总结了结果。</p></figure><p id="154a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">从数据帧<code class="fe of og oh oi b">MODELS_COMPARISON</code>中，可以看出:</p><ul class=""><li id="f7e8" class="mo mp it lt b lu lv lx ly ma mq me mr mi ms mm or mu mv mw bi translated">XGB和RF是产生最高ROI的ML模型，分别为31.3%和40.9%</li><li id="212e" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">RF的表现超过标准普尔500 12个百分点，超过道琼斯20个百分点</li><li id="efbb" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">XGB比标准普尔500高出几个百分点，而比道琼斯高出近10个百分点</li><li id="c0d4" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">MLP和SVM的投资回报率非常接近，分别为28.3%和27.2%</li><li id="ba62" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">MLP和SVM的表现与标准普尔500类似，但都优于道琼斯指数</li><li id="80c3" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">SVM的净收益最高，约为3290美元；但是，它的初始投资成本最高，为12100美元</li><li id="0c64" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">射频导致最低的净收益，约为1920美元；但是，它的初始投资成本也最低，为4700美元</li></ul><p id="df65" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">因此，这个例子证明，至少作为概念证明，在上市公司发布的10-K文件中找到有用的信息是可能的。金融信息可以用来训练机器学习模型，学习识别值得购买的股票。</p><p id="7b5d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于所实现的ML模型之间的性能的更传统的比较，可以分析<code class="fe of og oh oi b">classification_report</code>。</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="3595" class="no kj it oi b gy on oo l op oq"><strong class="oi iu">from</strong> <strong class="oi iu">sklearn.metrics</strong> <strong class="oi iu">import</strong> classification_report<br/><br/>print()<br/>print(53 * '=')<br/>print(15 * ' ' + 'SUPPORT VECTOR MACHINE')<br/>print(53 * '-')<br/>print(classification_report(y_test, clf1.predict(X_test), target_names=['IGNORE', 'BUY']))<br/>print(53 * '-')<br/>print(53 * '=')<br/>print(20 * ' ' + 'RANDOM FOREST')<br/>print(53 * '-')<br/>print(classification_report(y_test, clf2.predict(X_test), target_names=['IGNORE', 'BUY']))<br/>print(53 * '-')<br/>print(53 * '=')<br/>print(14 * ' ' + 'EXTREME GRADIENT BOOSTING')<br/>print(53 * '-')<br/>print(classification_report(y_test, clf3.predict(X_test), target_names=['IGNORE', 'BUY']))<br/>print(53 * '-')<br/>print(53 * '=')<br/>print(15 * ' ' + 'MULTI-LAYER PERCEPTRON')<br/>print(53 * '-')<br/>print(classification_report(y_test, clf4.predict(X_test), target_names=['IGNORE', 'BUY']))<br/>print(53 * '-')</span></pre><p id="e899" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">其屈服于:</p><pre class="lb lc ld le gt oj oi ok ol aw om bi"><span id="6ac7" class="no kj it oi b gy on oo l op oq">=====================================================<br/>               SUPPORT VECTOR MACHINE<br/>-----------------------------------------------------<br/>              precision    recall  f1-score   support<br/><br/>      IGNORE       0.40      0.05      0.09        38<br/>         BUY       0.71      0.97      0.82        90<br/><br/>    accuracy                           0.70       128<br/>   macro avg       0.55      0.51      0.45       128<br/>weighted avg       0.62      0.70      0.60       128<br/><br/>-----------------------------------------------------<br/>=====================================================<br/>                    RANDOM FOREST<br/>-----------------------------------------------------<br/>              precision    recall  f1-score   support<br/><br/>      IGNORE       0.37      0.79      0.50        38<br/>         BUY       0.83      0.43      0.57        90<br/><br/>    accuracy                           0.54       128<br/>   macro avg       0.60      0.61      0.54       128<br/>weighted avg       0.69      0.54      0.55       128<br/><br/>-----------------------------------------------------<br/>=====================================================<br/>              EXTREME GRADIENT BOOSTING<br/>-----------------------------------------------------<br/>              precision    recall  f1-score   support<br/><br/>      IGNORE       0.48      0.34      0.40        38<br/>         BUY       0.75      0.84      0.80        90<br/><br/>    accuracy                           0.70       128<br/>   macro avg       0.62      0.59      0.60       128<br/>weighted avg       0.67      0.70      0.68       128<br/><br/>-----------------------------------------------------<br/>=====================================================<br/>               MULTI-LAYER PERCEPTRON<br/>-----------------------------------------------------<br/>              precision    recall  f1-score   support<br/><br/>      IGNORE       0.39      0.29      0.33        38<br/>         BUY       0.73      0.81      0.77        90<br/><br/>    accuracy                           0.66       128<br/>   macro avg       0.56      0.55      0.55       128<br/>weighted avg       0.63      0.66      0.64       128<br/><br/>-----------------------------------------------------</span></pre><p id="ed08" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">仔细看，平心而论地问:<strong class="lt iu">如果是加权精度最低的方法，为什么RF回报最高的ROI？</strong>这是因为:</p><ul class=""><li id="6f5a" class="mo mp it lt b lu lv lx ly ma mq me mr mi ms mm or mu mv mw bi translated">RF对购买类的精确度最高(83%)。事实上，83%的买入预测是<em class="mn">真阳性</em>，剩下的17%是<em class="mn">假阳性</em></li><li id="0d39" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">最大限度地减少<em class="mn">误报</em>的数量可以最大限度地减少花在2019年将会贬值的股票上的钱</li><li id="ce74" class="mo mp it lt b lu mx lx my ma mz me na mi nb mm or mu mv mw bi translated">RF在忽略类别中具有最高的召回率(79%)，这意味着它正确地识别了79%不应该被购买的股票</li></ul><p id="d04f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">然而，所有这一切意味着我们错过了许多可以购买的潜在股票，因为RF导致了大量的<em class="mn">假阴性</em>。事实上，很容易看出RF在买入类中具有最低的召回值(43%)，这意味着我们只找到了43%的应被归类为值得买入的股票。</p><p id="dcfc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文的第2部分到此结束。希望你会觉得它有用和鼓舞人心。有关财务建模准备API、代码和历史数据的更多信息，请查看下面的链接。</p><div class="ow ox gp gr oy oz"><a href="https://financialmodelingprep.com/developer/docs/" rel="noopener  ugc nofollow" target="_blank"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">免费股票API和财务报表API - FMP API</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">该文档包括财务报表API、免费股票API和历史报价API。查找全部…</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">financialmodelingprep.com</p></div></div><div class="pi l"><div class="pj l pk pl pm pi pn lk oz"/></div></div></a></div><div class="ow ox gp gr oy oz"><a href="https://github.com/CNIC92/beat-the-stock-market" rel="noopener  ugc nofollow" target="_blank"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">cnic 92/跑赢股市</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">这个项目从我在2019年寒假问自己的一个问题开始:有可能了解哪些…</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">github.com</p></div></div><div class="pi l"><div class="po l pk pl pm pi pn lk oz"/></div></div></a></div><div class="ow ox gp gr oy oz"><a href="https://www.kaggle.com/cnic92/200-financial-indicators-of-us-stocks-20142018" rel="noopener  ugc nofollow" target="_blank"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">美股200+财务指标(2014-2018)</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">尝试利用200多个财务指标预测股票的未来表现</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">www.kaggle.com</p></div></div><div class="pi l"><div class="pp l pk pl pm pi pn lk oz"/></div></div></a></div></div></div>    
</body>
</html>