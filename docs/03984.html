<html>
<head>
<title>Deep Learning on Point clouds: Implementing PointNet in Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">点云深度学习:在 Google Colab 中实现 PointNet</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-on-point-clouds-implementing-pointnet-in-google-colab-1fd65cd3a263?source=collection_archive---------2-----------------------#2020-04-13">https://towardsdatascience.com/deep-learning-on-point-clouds-implementing-pointnet-in-google-colab-1fd65cd3a263?source=collection_archive---------2-----------------------#2020-04-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cfd8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">点网是一种简单有效的点云识别神经网络。在本教程中，我们将使用 PyTorch 实现它。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5e06bd9075e01231e299d698c6ee957c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ByZHlrBQKJoEnj5CKxEhwQ.gif"/></div></div></figure><h1 id="5edb" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">1.介绍</h1><p id="97ac" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">3D 数据对于自动驾驶汽车、自主机器人、虚拟和增强现实至关重要。与用像素阵列表示的 2D 图像不同，它可以表示为<a class="ae mf" href="https://en.wikipedia.org/wiki/Polygon_mesh" rel="noopener ugc nofollow" target="_blank">多边形网格</a>、<a class="ae mf" href="https://en.wikipedia.org/wiki/Voxel" rel="noopener ugc nofollow" target="_blank">体积像素网格</a>、<a class="ae mf" href="https://en.wikipedia.org/wiki/Point_cloud" rel="noopener ugc nofollow" target="_blank">点云</a>等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mg"><img src="../Images/f709781e24deb086f27f70ae48f7441e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r5MTh8VJ4Se4X2YV691vHg.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">图片来自:<a class="ae mf" href="https://medium.com/vitalify-asia/create-3d-model-from-a-single-2d-image-in-pytorch-917aca00bb07" rel="noopener">用 PyTorch 中的一张 2D 图片创建 3D 模型</a></p></figure><p id="4d08" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">在今天的计算机视觉和机器学习中，<a class="ae mf" href="http://news.mit.edu/2019/deep-learning-point-clouds-1021" rel="noopener ugc nofollow" target="_blank"> 90%的进步只处理二维图像</a>。</p><h2 id="24ca" class="mq ks iq bd kt mr ms dn kx mt mu dp lb ls mv mw ld lw mx my lf ma mz na lh nb bi translated">1.1.点云</h2><p id="da6a" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">点云是一种广泛使用的 3D 数据形式，可以由深度传感器产生，如<a class="ae mf" href="https://oceanservice.noaa.gov/facts/lidar.html" rel="noopener ugc nofollow" target="_blank">激光雷达</a>和<a class="ae mf" href="https://www.quora.com/What-is-an-RGB-D-image" rel="noopener ugc nofollow" target="_blank"> RGB-D </a>相机。</p><p id="0500" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">它是 3D 物体最简单的表示<strong class="ll ir">:<strong class="ll ir">仅点</strong>于 3D 空间<strong class="ll ir">，</strong>无连通性。点云也可以包含点的法线。</strong></p><blockquote class="nc nd ne"><p id="6a89" class="lj lk nf ll b lm ml jr lo lp mm ju lr ng mn lu lv nh mo ly lz ni mp mc md me ij bi translated">几乎所有的 3d 扫描设备都会产生点云。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/ebefbf37e40495aeb54096ce93ace5b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TzU3KSQk3YwRNQnFKOZSlA.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">可以捕捉点云的设备(Iphone 11、华硕 Zenfone AR、索尼 Xperia XZ1)。图片来自:<a class="ae mf" href="http://www.enseignement.polytechnique.fr/informatique/INF555/" rel="noopener ugc nofollow" target="_blank">本课程</a></p></figure><p id="0a70" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">此外，最近苹果<a class="ae mf" href="https://www.apple.com/newsroom/2020/03/apple-unveils-new-ipad-pro-with-lidar-scanner-and-trackpad-support-in-ipados/" rel="noopener ugc nofollow" target="_blank">推出了</a>带有激光雷达扫描仪的 Ipad Pro，可以测量 5 米以外的周围物体的距离。</p><h2 id="4794" class="mq ks iq bd kt mr ms dn kx mt mu dp lb ls mv mw ld lw mx my lf ma mz na lh nb bi translated">1.2.点云深度学习</h2><p id="58af" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">所以，让我们想想如何处理点云。CNN 对图像非常有用。我们能把它们用于 3D 吗？</p><blockquote class="nc nd ne"><p id="c2bd" class="lj lk nf ll b lm ml jr lo lp mm ju lr ng mn lu lv nh mo ly lz ni mp mc md me ij bi translated">想法:将 2D 卷积推广到规则三维网格</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/f1abfa5559994a6ea519713f35fae273.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KfP_UYXHdLktECaYnYPFBw.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">图片来自:<a class="ae mf" href="https://arxiv.org/pdf/1604.03265.pdf" rel="noopener ugc nofollow" target="_blank"> arxiv 论文</a></p></figure><p id="6e09" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">这个其实<a class="ae mf" href="https://arxiv.org/pdf/1604.03265.pdf" rel="noopener ugc nofollow" target="_blank">管用</a>。</p><p id="b5f3" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">主要的<strong class="ll ir">问题</strong>是<strong class="ll ir">低效表示:</strong>大小为 100 的立方体素网格将有 1，000，000 个体素。</p><h2 id="9a7e" class="mq ks iq bd kt mr ms dn kx mt mu dp lb ls mv mw ld lw mx my lf ma mz na lh nb bi translated">1.3.点网</h2><p id="5d2b" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">但是如果我们尝试处理点云呢？</p><p id="d9fa" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">有三个主要的<strong class="ll ir">约束</strong>:</p><ul class=""><li id="9523" class="nl nm iq ll b lm ml lp mm ls nn lw no ma np me nq nr ns nt bi translated">点云是无序的。算法必须对输入集的排列不变。</li><li id="426a" class="nl nm iq ll b lm nu lp nv ls nw lw nx ma ny me nq nr ns nt bi translated">如果我们旋转椅子，它还是椅子，对吗？网络必须是<strong class="ll ir">不变的</strong> <a class="ae mf" href="https://en.wikipedia.org/wiki/Rigid_transformation" rel="noopener ugc nofollow" target="_blank"> <strong class="ll ir">刚性变换</strong> </a>。</li><li id="534d" class="nl nm iq ll b lm nu lp nv ls nw lw nx ma ny me nq nr ns nt bi translated">网络应该捕捉点之间的相互作用。</li></ul><p id="b0c5" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">PointNet <a class="ae mf" href="https://arxiv.org/pdf/1612.00593.pdf" rel="noopener ugc nofollow" target="_blank">的作者介绍了</a>一种考虑了所有这些特性的神经网络。它设法解决<strong class="ll ir">分类</strong>，部件和语义<strong class="ll ir">分割</strong>任务。来实施吧！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/d76247fce940dbbc27c654f6f1fef826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LSOzrONaww-HT918hofkDA.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">图片来自:<a class="ae mf" href="https://arxiv.org/pdf/1612.00593.pdf" rel="noopener ugc nofollow" target="_blank"> arxiv 论文</a></p></figure><h1 id="cbd0" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">2.履行</h1><p id="c2b4" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">在本节中，我们将使用<strong class="ll ir"> PyTorch 从<a class="ae mf" href="https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d" rel="noopener"> <strong class="ll ir"> Google Colab </strong> </a>中的<a class="ae mf" href="https://arxiv.org/pdf/1612.00593.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>重新实现<strong class="ll ir">分类模型</strong>。</strong></p><p id="b6cf" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">你可以在<a class="ae mf" href="https://github.com/nikitakaraevv/pointnet/blob/master/nbs/PointNetClass.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/nikitakaraevv/pointnet/blob/master/nbs/pointnet class . ipynb</a>找到<strong class="ll ir">完整笔记本</strong></p><h2 id="4992" class="mq ks iq bd kt mr ms dn kx mt mu dp lb ls mv mw ld lw mx my lf ma mz na lh nb bi translated">2.1.资料组</h2><p id="4ff2" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">在原始论文中，作者在 ModelNet40 形状分类基准上评估了 PointNet。它包含来自 40 个对象类别的 12，311 个模型，分为 9，843 个训练模型和 2，468 个测试模型。</p><p id="ae5b" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">为了简单起见，让我们使用同一个数据集的较小版本:<strong class="ll ir"> ModelNet10。</strong>它由来自<strong class="ll ir"> 10 个类别的对象、</strong>3991 个用于训练的模型和 908 个用于测试的模型组成。</p><div class="oa ob gp gr oc od"><a href="http://3dvision.princeton.edu/projects/2014/3DShapeNets/" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd ir gy z fp oi fr fs oj fu fw ip bi translated">3D 形状网:体积形状的深层表示</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">在物体识别中，3D 形状是一个至关重要但严重未被充分利用的线索，主要是因为缺乏一个好的通用…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">3dvision.princeton.edu</p></div></div><div class="om l"><div class="on l oo op oq om or kp od"/></div></div></a></div><blockquote class="nc nd ne"><p id="5e85" class="lj lk nf ll b lm ml jr lo lp mm ju lr ng mn lu lv nh mo ly lz ni mp mc md me ij bi translated">想直接开始训练别忘了打开 GPU</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/c3fb5f9f2361c637765154f7edee36c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*uvb_EI1Yhki1eoULaxyJPw.gif"/></div></div></figure><p id="f85f" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">让我们导入必要的库:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="18c9" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">我们可以将数据集直接下载到 Google Colab 运行时:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="9b38" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">这个数据集由<strong class="ll ir">组成。关闭包含由顶点和三角面表示的<a class="ae mf" href="https://en.wikipedia.org/wiki/Polygon_mesh" rel="noopener ugc nofollow" target="_blank">网格</a>的</strong>文件。<strong class="ll ir">顶点</strong>只是三维空间中的点，每个<strong class="ll ir">三角形</strong>由 3 个顶点索引组成。</p><p id="cc7b" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">我们将需要一个函数来读取<strong class="ll ir">。关闭</strong>文件:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="bc55" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">完整网格看起来是这样的:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/ef3cef7d8078d5075d3463e06196b244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*JCSb0EVEw1rX-DIuJEZdRA.gif"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">啮合其中一个<strong class="bd ov">。关闭</strong>文件。使用<a class="ae mf" href="https://plotly.com/python/" rel="noopener ugc nofollow" target="_blank">创建 plotly </a></p></figure><p id="c141" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">如你所见，这是一张🛏床</p><p id="36f3" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">但是如果我们去掉人脸，只保留 3D 点，它看起来就不再像一张床了！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/f0e4ee7181ec873dc2f02361aa80effc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Os0gBF1jYuG8EFfw1hxFxg.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">网格顶点</p></figure><p id="2aef" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">实际上，曲面的平坦部分不需要任何点来构建网格。这就是为什么点主要位于床的角度和圆形部分。</p><h2 id="97f8" class="mq ks iq bd kt mr ms dn kx mt mu dp lb ls mv mw ld lw mx my lf ma mz na lh nb bi translated">2.2.点取样</h2><p id="87b7" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">因此，由于<strong class="ll ir">点不是均匀分布在物体表面的</strong>，我们的点网很难对它们进行分类。(尤其是知道这个点云看起来连床都不像)。</p><p id="9c9c" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">这个问题的解决方案可能非常简单:让我们在物体的表面上均匀地采样点。</p><blockquote class="nc nd ne"><p id="5976" class="lj lk nf ll b lm ml jr lo lp mm ju lr ng mn lu lv nh mo ly lz ni mp mc md me ij bi translated">我们不应该忘记脸可以有不同的区域。</p></blockquote><p id="3996" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">因此，我们可以将选择特定面<strong class="ll ir">的概率与其面积</strong>成比例分配。这是可以做到的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="0f06" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">我们的网络架构中将会有密集层。这就是为什么我们希望<strong class="ll ir">点云中有固定数量的点</strong>。让我们从构建的分布中抽取人脸样本。之后，我们在每个选择的面上采样一个点:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><blockquote class="nc nd ne"><p id="6023" class="lj lk nf ll b lm ml jr lo lp mm ju lr ng mn lu lv nh mo ly lz ni mp mc md me ij bi translated">一些面可以有多个采样点，而另一些面根本没有采样点。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/4f6638ceeb5025d6d0efb5cea1fd29d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*JagBgEFtgF3Ky1KBDI2czQ.gif"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">由网格曲面上的采样点创建的点云</p></figure><p id="4735" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">这个点云看起来更像一张床！🛏</p><h2 id="9dbe" class="mq ks iq bd kt mr ms dn kx mt mu dp lb ls mv mw ld lw mx my lf ma mz na lh nb bi translated">2.3.增加</h2><p id="1c9b" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">让我们想想其他可能的问题。我们知道<strong class="ll ir">物体可以有不同的大小</strong>，可以放<strong class="ll ir">在我们坐标系</strong>的不同部分。</p><p id="9781" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">因此，让我们<strong class="ll ir">将</strong>物体<strong class="ll ir">平移到原点</strong>，从其所有点中减去平均值，并将<strong class="ll ir">的点归一化</strong>到一个单位球。为了在训练期间增加数据，我们<strong class="ll ir">围绕 Z 轴随机旋转</strong>对象，并添加<strong class="ll ir">高斯噪声</strong>，如本文所述:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="71df" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">这是标准化的同一张床，带有<strong class="ll ir">旋转</strong>和<strong class="ll ir">噪音</strong>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/50daf31ee15357ac55c855e533f6553f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wk5KdYp-S6OmMVUIftWN7Q.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">添加噪声的旋转点云</p></figure><h2 id="7ef1" class="mq ks iq bd kt mr ms dn kx mt mu dp lb ls mv mw ld lw mx my lf ma mz na lh nb bi translated">2.4.模型</h2><p id="b5ba" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">好了，我们已经完成了数据集和预处理。让我们考虑一下模型架构。该架构及其背后的关键思想已经得到了很好的解释，例如，在本文中:</p><div class="oa ob gp gr oc od"><a href="https://medium.com/@luis_gonzales/an-in-depth-look-at-pointnet-111d7efdaa1a" rel="noopener follow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd ir gy z fp oi fr fs oj fu fw ip bi translated">深入了解 PointNet</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">PointNet 是 3D 感知领域的开创性论文，将深度学习应用于点云，用于对象分类和…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">medium.com</p></div></div><div class="om l"><div class="oy l oo op oq om or kp od"/></div></div></a></div><p id="e3a2" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">我们记得结果应该是对输入点的<strong class="ll ir">不变</strong><em class="nf">排列</em>和几何<em class="nf">变换</em>，比如<a class="ae mf" href="https://en.wikipedia.org/wiki/Rigid_transformation" rel="noopener ugc nofollow" target="_blank">刚性变换</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/c19646956bb7534d69499756760c793f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ovpVlWKU3ZKk2OT_WKZHA.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">图片来自:<a class="ae mf" href="https://arxiv.org/pdf/1612.00593.pdf" rel="noopener ugc nofollow" target="_blank"> arxiv 论文</a></p></figure><p id="9594" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">让我们在<a class="ae mf" href="https://pytorch.org/tutorials/" rel="noopener ugc nofollow" target="_blank"> <strong class="ll ir"> PyTorch </strong> </a>中开始实现它:</p><p id="8cb7" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">首先，我们的张量会有大小<code class="fe oz pa pb pc b">(batch_size, num_of_points, 3)</code>。在这种情况下，具有<a class="ae mf" href="https://www.quora.com/What-exactly-is-meant-by-shared-weights-in-convolutional-neural-network" rel="noopener ugc nofollow" target="_blank">共享权重</a>的<em class="nf"> MLP </em>只是具有大小为 1 的内核的<a class="ae mf" href="https://jdhao.github.io/2017/09/29/1by1-convolution-in-cnn/" rel="noopener ugc nofollow" target="_blank"> 1-dim <em class="nf">卷积</em> </a>。</p><p id="3813" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">为了确保<strong class="ll ir">对变换</strong>的不变性，我们将 T-Net 预测的 3x3 变换矩阵应用于输入点的坐标。有趣的是，我们<a class="ae mf" href="https://gamedev.stackexchange.com/questions/161771/why-do-transformation-matrices-always-have-an-extra-dimension" rel="noopener ugc nofollow" target="_blank">不能通过三维矩阵对 3D 空间</a>中的翻译进行编码。无论如何，我们已经在预处理中将点云平移到原点。</p><blockquote class="nc nd ne"><p id="d96c" class="lj lk nf ll b lm ml jr lo lp mm ju lr ng mn lu lv nh mo ly lz ni mp mc md me ij bi translated">这里重要的一点是输出矩阵的初始化。我们希望它默认为 identity，开始训练时没有任何转换。因此，我们只需在输出中添加一个单位矩阵:</p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="1225" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">在应用<em class="nf"> MLP </em>后，我们将使用相同但 64 维的 T 网来对齐提取的点特征。</p><p id="5593" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">为了提供<strong class="ll ir">置换不变性，</strong>我们将对称函数(max pooling)应用于提取和转换的特征，因此结果不再依赖于输入点的顺序。</p><p id="b1bf" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">让我们把它们结合在一起:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="0299" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">然后，让我们用输出端的最后一个<em class="nf"> MLP </em>和<em class="nf"/><a class="ae mf" href="https://pytorch.org/docs/stable/nn.html" rel="noopener ugc nofollow" target="_blank"><em class="nf">LogSoftmax</em></a><em class="nf"/>将它们打包在一个类中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="38c9" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">最后我们将定义<strong class="ll ir">损失函数</strong>。正如我们使用<em class="nf"> LogSoftmax </em> <a class="ae mf" href="https://medium.com/@zhang_yang/understanding-cross-entropy-implementation-in-pytorch-softmax-log-softmax-nll-cross-entropy-416a2b200e34" rel="noopener">获得稳定性</a> <em class="nf">，</em>一样，我们应该使用<em class="nf"> NLLLoss </em>而不是<em class="nf"> CrossEntropyLoss。</em>此外，我们将添加两个正则化项，以使变换矩阵接近正交(<em class="nf"> AAᵀ = I ) </em>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><h2 id="0885" class="mq ks iq bd kt mr ms dn kx mt mu dp lb ls mv mw ld lw mx my lf ma mz na lh nb bi translated">2.5.培养</h2><p id="3290" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated"><strong class="ll ir">最后一步！</strong>我们可以用一个经典的<a class="ae mf" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" rel="noopener ugc nofollow" target="_blank"> PyTorch 训练循环</a>。这肯定不是最有趣的部分，所以让我们省略它。</p><p id="aa4a" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">同样，带有训练循环的完整 Google Colab 笔记本可以在此链接  <strong class="ll ir">后找到<a class="ae mf" href="https://github.com/nikitakaraevv/pointnet/blob/master/nbs/PointNetClass.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ll ir">。</strong></a></strong></p><p id="5a81" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">我们就来看看在 GPU 上训练<strong class="ll ir"> 15 个纪元</strong>后的结果吧。培训本身大约需要<strong class="ll ir"> 3 个小时</strong>，但是<a class="ae mf" href="https://research.google.com/colaboratory/faq.html#gpu-availability" rel="noopener ugc nofollow" target="_blank">根据 Colab 分配给当前会话的 GPU 类型，培训时间可能会有所不同</a>。</p><p id="bb0e" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">通过一个简单的训练循环，在 13 个时期后可以达到 85% 的总体验证<strong class="ll ir">准确度，相比之下，在<a class="ae mf" href="https://arxiv.org/pdf/1612.00593.pdf" rel="noopener ugc nofollow" target="_blank">原始作品</a>中对于 40 个类，该准确度为 89%。这里的要点是实现完整的模型，而不是真的获得最好的分数。因此，我们将把调整训练循环和其他实验作为练习。</strong></p><blockquote class="nc nd ne"><p id="a7e4" class="lj lk nf ll b lm ml jr lo lp mm ju lr ng mn lu lv nh mo ly lz ni mp mc md me ij bi translated">有趣的是，我们的模型有时会混淆梳妆台和床头柜，厕所和椅子，书桌和桌子，这很容易理解(厕所除外):</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pd"><img src="../Images/53372cdd5f4e7611494b42b582f01f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zqNrOCod22Cg4ASzB5YkGw.png"/></div></div></figure><h1 id="bf8a" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">3.最后的话</h1><p id="fb53" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">你做到了！🎉🎊👏</p><p id="5153" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">你实现了<strong class="ll ir"> PointNet </strong>，这是一个深度学习架构，可以用于各种 3D 识别任务。尽管我们在这里实现了<strong class="ll ir">分类</strong>模型，但是<strong class="ll ir">分割</strong>、<strong class="ll ir">正常评估</strong>或其他任务只需要对模型和数据集类进行微小的修改。</p><p id="75ba" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">完整的笔记本可在<a class="ae mf" href="https://github.com/nikitakaraevv/pointnet/blob/master/nbs/PointNetClass.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/nikitakaraevv/point net/blob/master/nbs/point net class . ipynb</a>获得。</p><p id="c471" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated"><em class="nf">感谢您的阅读！我希望这篇教程对你有用。如果是这样，请在评论中告诉我。顺便说一句，这是我的第一篇媒体文章，所以我将非常感谢您的评论或私信反馈！</em></p><h1 id="b8c1" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">参考资料:</h1><p id="2ae3" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">[1] Charles R. Qi，，Kaichun Mo，Leonidas J. Guibas，<a class="ae mf" href="http://stanford.edu/~rqi/pointnet/" rel="noopener ugc nofollow" target="_blank"> PointNet:用于三维分类和分割的点集深度学习</a> (2017)，CVPR 2017</p><p id="41fc" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">[2]亚当·康纳-西蒙斯，<a class="ae mf" href="http://news.mit.edu/2019/deep-learning-point-clouds-1021" rel="noopener ugc nofollow" target="_blank">点云深度学习</a> (2019)，麻省理工学院计算机科学&amp;人工智能实验室</p><p id="7f3f" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">[2] Loic Landrieu，<a class="ae mf" href="http://bezout.univ-paris-est.fr/wp-content/uploads/2019/04/Landrieu_GT_appr_opt.pdf" rel="noopener ugc nofollow" target="_blank">3D 点云的语义分割</a> (2019)，巴黎东方大学—机器学习与优化工作组</p><p id="5ca4" class="pw-post-body-paragraph lj lk iq ll b lm ml jr lo lp mm ju lr ls mn lu lv lw mo ly lz ma mp mc md me ij bi translated">[4] Charles R. Qi 等，<a class="ae mf" href="https://arxiv.org/pdf/1604.03265.pdf" rel="noopener ugc nofollow" target="_blank">用于 3D 数据上对象分类的体积和多视图 CNN</a>(2016)，</p></div></div>    
</body>
</html>