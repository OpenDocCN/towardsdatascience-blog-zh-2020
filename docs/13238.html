<html>
<head>
<title>A Layman’s Guide to Building Your First Image Classification Model in R Using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Keras 在 R 中构建第一个图像分类模型的外行指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-laymans-guide-to-building-your-first-image-classification-model-in-r-using-keras-b285deac6572?source=collection_archive---------21-----------------------#2020-09-11">https://towardsdatascience.com/a-laymans-guide-to-building-your-first-image-classification-model-in-r-using-keras-b285deac6572?source=collection_archive---------21-----------------------#2020-09-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ea4e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">动手香草建模第一部分</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/39b0c8b9ef422b0ead4c09786ba6d0c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJYnbqc664tKuIcahpqT_w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="d4cb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated">机器学习的应用现在几乎是我们日常生活中不可或缺的一部分。从智能手机中基于语音识别的虚拟助理到超级智能的自动化无人机，人工智能和人工智能(AI)正在彻底改变人机交互的动态。人工智能算法，特别是卷积神经网络(CNN)使得计算机视觉比以往任何时候都更加强大。虽然它的应用程序令人惊叹，但构建自己的 CNN 模型可能会非常令人生畏，特别是对于非程序员或数据科学初学者来说。作为一个 R 爱好者，我不难断言，对于一个 R 程序员新手来说，它变得更加神秘。这种不平衡的合理原因可能是，标准神经网络和 ML 库(如 Keras 和 Tensorflow)主要与 Python 兼容，并自然地吸引大众使用 Python 本身，导致严重缺乏新手指南和文档来帮助在 r 中实现这些复杂的框架。在本文中，我们将使用 Keras 和 Tensorflow 框架在 R 中制作一个基于 CNN 的普通图像分类模型。通过这篇文章，我的目标是使您能够使用 Keras 在 R 中概念化和构建自己的 CNN 模型，并通过亲自动手编码来帮助增强您的信心，以便在将来使用这个深奥的 API 构建更复杂的模型。除了模型的脚本之外，我还将尽量简明地阐述必要的组件，同时深入核心的底层数学。现在我们开始吧。</p><h2 id="9c62" class="md me it bd mf mg mh dn mi mj mk dp ml lh mm mn mo ll mp mq mr lp ms mt mu mv bi translated">卷积神经网络(CNN)快速介绍。</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/0072abb47c43a079407f2b9ed218d700.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2rgqSxnVaf_BIq-7seN-Nw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。卷积神经网络架构(<em class="mx">图片作者</em></p></figure><p id="52de" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为 CNN 脚本的前奏，让我们简单了解一下它的形式主义。就像人眼只在有限的接收框架中记录信息，并学习特定的模式和空间特征，随后触发特定的神经反应一样，CNN 模型也以相同的方式运行。我们将尝试探索 CNN 架构并理解其关键组件(图 1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/8ca9ac2d85281b01625b184b1d9d54a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/1*7D2LGdbC6fkt3gEBLfVcnQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。可视化卷积(作者的<em class="mx">图像)</em></p></figure><p id="6e91" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不是一次合并整个图像像素，而是将一个像素子集卷积成一个数据<em class="mz">图 2 </em>。卷积是通过在整个图像上滑动一个较小尺寸的帧来实现的，该帧充当考虑了时间-空间特征的感受域。这个帧被称为<strong class="la iu">内核/过滤器</strong>。想象一下用手电筒扫描一面建筑墙，过滤器以同样的方式工作。现在，如果您有多种过滤器，您可能会提取或观察到更具鉴别性的空间要素和经常重复出现的相邻值。该方案通过不仅以最少的信息损失保持空间特征，而且显著地减少所需的权重数量来增强学习，使得图像分类实际上可行并且可扩展。例如，考虑一幅 2D 黑白(b &amp; w)图像作为 CNN 的输入。该模型通过使用<strong class="la iu">滤波器</strong>开始卷积图像，然后以给定的步长滑过图像，也称为<strong class="la iu">步长</strong>。滤波器值类似于神经网络中的权重。在一个实例中，这些滤波器值和图像的前景像素值的线性组合生成单个<strong class="la iu">特征输出</strong>。生成的一组这些值产生一个新层，称为<strong class="la iu">特征图</strong>。直观地说，特征图是输入图像的浓缩形式，它将所有主要特征和模式保留在较小的维度中，以便有效学习。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/4ad577fb98f70677c07811a9fee8b650.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*P2VVkQrXbOYBeq2p94kvFA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3。卷积方案(<em class="mx">图片作者</em></p></figure><p id="5016" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了说明这一点，在图 3 中，在尺寸为 10X10 的黑白图像上使用了尺寸为 4x4 的滤波器。滤镜以 1 个单位的步幅在图像上滑动，从而生成一个维度为(10–4+1)X(10–4+1)的回旋层，即 7X7。注意，本例中的偏差/截距假定为 0。类似地，<em class="mz"> n </em>个滤波器将生成<em class="mz"> n </em>个特征图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/d91808036220e3e5ce8dd0f55f5f4ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*TschuXC8X14VZJS2b7Hq2Q.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3。彩色图像的卷积(作者的<em class="mx">图像)</em></p></figure><p id="1008" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于黑白图像，深度为 1，因此滤镜的深度为 1。然而，彩色图像是红色、蓝色和绿色(RBG)通道的集合。确切地说，是三个 2D 层的堆叠，其中每一层代表特定颜色通道的强度。所以对于深度为 3 的彩色图像，你需要一个尺寸为(4X4)X <strong class="la iu"> 3 的滤镜(</strong>图 4)。</p><p id="bae5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦生成了特征图，就对它们中的每一个应用一个<strong class="la iu">激活函数</strong>。为此，<strong class="la iu">整流线性单元(ReLU) </strong>激活功能<strong class="la iu"> </strong>就派上了用场。如果 ReLU 的输入是一个负值，它就简单地将它转换为零，否则它将输出完全相同的输入值(图 4)。数学上，<em class="mz"> f(x)= max(0，x)。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/651e8f7577edb1f7f497de64b679ac10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*cmGESKfSZLH2ksqF_kBgfQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 5。ReLU 和 Max Pooling ( <em class="mx">图片作者</em>)</p></figure><p id="79d6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在激活层之后，另一种方案被用来在不丢失重要信息的情况下灵活地降低特征图的维数。这种技术被称为<strong class="la iu">最大池</strong>。与卷积方案非常相似，这里只选取最大池窗口中的最高值。该窗口以与过滤器相同的方式滑动，但是步长等于池窗口的尺寸(图 5)。最大池显著降低了特征图的维度，同时还保留了重要的/主要的特征。最终的最大池层然后被挤压和展平成神经元层，该神经元层连接到完全连接的神经网络以执行分类任务。</p><p id="046a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，CNN 并不局限于单个卷积或一组上述方案。有足够数量的过滤器支持，你的网络越深入，它将实现更高的性能。直观地说，初始卷积将捕获低级的循环特征，例如边缘和颜色。随后，深层往往会捕捉高级特征，如重复出现的像素簇，如肖像中的眼睛或鼻子。所以，总之，基于你的图像复杂性和计算能力，你应该选择足够的有效数量的层和过滤器。</p><p id="f7bd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们开始制作我们的玩具模型🤓！！</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h2 id="5206" class="md me it bd mf mg mh dn mi mj mk dp ml lh mm mn mo ll mp mq mr lp ms mt mu mv bi translated">数据集</h2><p id="91b7" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">我相信，要理解任何统计概念，没有什么比一副扑克牌更容易的了。在这里，我将利用一副扑克牌，但在一个稍微非正统的形式。是的，你猜对了！！我将制作一个预测模型，它应该能够准确地分类和预测任何任意非正面扑克牌的给定图像的花色。</p><p id="d92c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae no" href="https://github.com/AbhibhavS/CNN-Toy-model" rel="noopener ugc nofollow" target="_blank">该数据集</a>包含每种花色的一组 43 张纸牌图像<em class="mz">，即</em>梅花♣、红心♥️、方块♦️和黑桃♠️。请注意，每种花色的符号都遵循标准的形状，但是这些符号的设计和排列因卡而异。我们将结合这个数据集来训练和测试我们的模型。(为了方便地遵循脚本，我建议您下载图像，并将所有文件保存在一个父文件中，就像它们出现在 Github 存储库中一样)</p><h2 id="a3e9" class="md me it bd mf mg mh dn mi mj mk dp ml lh mm mn mo ll mp mq mr lp ms mt mu mv bi translated">需要软件包和安装</h2><p id="84fc" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">对于这个任务，你需要 Keras 和<a class="ae no" href="https://bioconductor.org/packages/release/bioc/html/EBImage.html" rel="noopener ugc nofollow" target="_blank"> <em class="mz"> EBImage </em> </a> <em class="mz">包</em>。前者可从 cran 知识库中获得。后者用于有效处理图像，可以从一个名为<a class="ae no" href="https://bioconductor.org/" rel="noopener ugc nofollow" target="_blank"> Bioconductor </a>的开源软件中调用。这些可以安装在 Windows 操作系统上，如下所示:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="0918" class="md me it nq b gy nu nv l nw nx">install.packages(“keras”) # Install the package from CRAN<br/>library(keras)<br/>install_keras() #to setup the Keras library and TensorFlow backend</span><span id="df47" class="md me it nq b gy ny nv l nw nx">if (!requireNamespace(“BiocManager”, quietly = TRUE))<br/>install.packages(“BiocManager”)<br/>BiocManager::install(“EBImage”)<br/>library(EBImage)</span></pre><p id="0a0e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这将安装 Keras API 的 CPU 版本，目前推荐新手使用。</p><p id="7f33" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="mz">注意:</em></strong><em class="mz">Keras API 将需要 Python 支持和 R tools 插件。因此，请确保在您的机器上安装了 anaconda 和 R 工具，并将其正确添加到您的系统路径中。</em></p><h2 id="1fa3" class="md me it bd mf mg mh dn mi mj mk dp ml lh mm mn mo ll mp mq mr lp ms mt mu mv bi translated">探索数据集</h2><p id="81b8" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">接下来，我们将把每套衣服的图像转换成一个张量(编号矩阵)。EBImage 库中的 readImage() 函数可以很好地做到这一点。让我们试着从数据集中读取一幅图像。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="ad1e" class="md me it nq b gy nu nv l nw nx">setwd(“C:/parent/spade”) # To access the images of Spades suit.<br/>                         # The path should be modified as per your <br/>                         # machine</span><span id="2abb" class="md me it nq b gy ny nv l nw nx">card&lt;-readImage(“ace_of_spades (2).png”) # Reading an imgae from the<br/>                                         # dataset<br/>print(card) # Print the details of image</span></pre><p id="18e4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这给出了如下输出:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="62a6" class="md me it nq b gy nu nv l nw nx">Image <br/>colorMode : Color <br/>storage.mode : double <br/>dim : 500 726 4 <br/>frames.total : 4 <br/>frames.render: 1</span><span id="1853" class="md me it nq b gy ny nv l nw nx">imageData(object)[1:5,1:6,1]<br/>[,1] [,2] [,3] [,4] [,5] [,6]<br/>[1,] 1 1 1 1 1 1<br/>[2,] 1 1 1 1 1 1<br/>[3,] 1 1 1 1 1 1<br/>[4,] 1 1 1 1 1 1<br/>[5,] 1 1 1 1 1 1</span></pre><p id="0980" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这表示图像的颜色尺寸为 500 X 726 X 4。注意，正如我们之前讨论的，这里图像深度是 4，所以我们需要深度为 4 的过滤器。为了揭示这四个矩阵，我们使用:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="41ef" class="md me it nq b gy nu nv l nw nx">getFrames(card, type=”total”)</span></pre><p id="2aa3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这将分别给出四个通道的详细信息。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="cdc5" class="md me it nq b gy nu nv l nw nx">[[1]]<br/>Image <br/>colorMode : Grayscale <br/>storage.mode : double <br/>dim : 500 726 <br/>frames.total : 1 <br/>frames.render: 1</span><span id="d4f6" class="md me it nq b gy ny nv l nw nx">imageData(object)[1:5,1:6]<br/>[,1] [,2] [,3] [,4] [,5] [,6]<br/>[1,] 1 1 1 1 1 1<br/>[2,] 1 1 1 1 1 1<br/>[3,] 1 1 1 1 1 1<br/>[4,] 1 1 1 1 1 1<br/>[5,] 1 1 1 1 1 1</span><span id="3585" class="md me it nq b gy ny nv l nw nx">[[2]]<br/>Image <br/>colorMode : Grayscale <br/>storage.mode : double <br/>dim : 500 726 <br/>frames.total : 1 <br/>frames.render: 1</span><span id="f6b6" class="md me it nq b gy ny nv l nw nx">imageData(object)[1:5,1:6]<br/>[,1] [,2] [,3] [,4] [,5] [,6]<br/>[1,] 1 1 1 1 1 1<br/>[2,] 1 1 1 1 1 1<br/>[3,] 1 1 1 1 1 1<br/>[4,] 1 1 1 1 1 1<br/>[5,] 1 1 1 1 1 1</span><span id="9413" class="md me it nq b gy ny nv l nw nx">[[3]]<br/>Image <br/>colorMode : Grayscale <br/>storage.mode : double <br/>dim : 500 726 <br/>frames.total : 1 <br/>frames.render: 1</span><span id="d894" class="md me it nq b gy ny nv l nw nx">imageData(object)[1:5,1:6]<br/>[,1] [,2] [,3] [,4] [,5] [,6]<br/>[1,] 1 1 1 1 1 1<br/>[2,] 1 1 1 1 1 1<br/>[3,] 1 1 1 1 1 1<br/>[4,] 1 1 1 1 1 1<br/>[5,] 1 1 1 1 1 1</span><span id="ee23" class="md me it nq b gy ny nv l nw nx">[[4]]<br/>Image <br/>colorMode : Grayscale <br/>storage.mode : double <br/>dim : 500 726 <br/>frames.total : 1 <br/>frames.render: 1</span><span id="6730" class="md me it nq b gy ny nv l nw nx">imageData(object)[1:5,1:6]<br/>[,1] [,2] [,3] [,4] [,5] [,6]<br/>[1,] 0 0 0 0 0 0<br/>[2,] 0 0 0 0 0 0<br/>[3,] 0 0 0 0 0 0<br/>[4,] 0 0 0 0 0 0<br/>[5,] 0 0 0 0 0 0</span></pre><p id="62e1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">哦耶！为了阐明我们选择的卡，我们:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/4489e00e9ab3704a6798459c124c768f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3tqq6Cru6FozSKGk1radzA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 6。显示在 R 查看器中的所选卡片(<em class="mx">作者图片</em>)</p></figure><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="f6cb" class="md me it nq b gy nu nv l nw nx">display(card)</span></pre><p id="8a94" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尽管数据集中每张卡片的深度都相同，但像素尺寸却各不相同，因此我们必须将每张卡片的尺寸调整为 100x100x4，并将它们组合在一个与 Keras 兼容的堆栈中。这个堆栈然后直接进入架构作为输入。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="cdba" class="md me it nq b gy nu nv l nw nx">setwd(“C:/parent/club”) # To access the images of Clubs suit.<br/>                        # The path should be modified as per your <br/>                        # machine</span><span id="b920" class="md me it nq b gy ny nv l nw nx">img.card&lt;- sample(dir()); #-------shuffle the order<br/>cards&lt;-list(NULL);        <br/>for(i in 1:length(img.card))<br/>{ cards[[i]]&lt;- readImage(img.card[i])<br/> cards[[i]]&lt;- resize(cards[[i]], 100, 100)} #resizing to 100x100</span><span id="f940" class="md me it nq b gy ny nv l nw nx">club&lt;- cards              # Storing stack of the Clubs cards in<br/>                          # matrix form in a list<br/>#-----------------------------------------------------------</span><span id="3bff" class="md me it nq b gy ny nv l nw nx">setwd(“C:/parent/heart”)# To access the images of Hearts suit.<br/>                        # The path should be modified as per your <br/>                        # machine</span><span id="4f10" class="md me it nq b gy ny nv l nw nx">img.card&lt;- sample(dir());<br/>cards&lt;-list(NULL);<br/>for(i in 1:length(img.card))<br/> { cards[[i]]&lt;- readImage(img.card[i])<br/>cards[[i]]&lt;- resize(cards[[i]], 100, 100)} #resizing to 100x100</span><span id="8d18" class="md me it nq b gy ny nv l nw nx">heart&lt;- cards             # Storing stack of the Hearts cards in<br/>                          # matrix form in a list<br/>#------------------------------------------------------------</span><span id="51b3" class="md me it nq b gy ny nv l nw nx">setwd(“C:/parent/spade”)# To access the images of Spades suit.<br/>                        # The path should be modified as per your <br/>                        # machine</span><span id="9b44" class="md me it nq b gy ny nv l nw nx">img.card&lt;- sample(dir());<br/>cards&lt;-list(NULL);<br/>for(i in 1:length(img.card))<br/>{ cards[[i]]&lt;- readImage(img.card[i])<br/>cards[[i]]&lt;- resize(cards[[i]], 100, 100)} #resizing to 100x100</span><span id="42dd" class="md me it nq b gy ny nv l nw nx">spade&lt;- cards             # Storing stack of the Spades cards in<br/>                          # matrix form in a list<br/>#------------------------------------------------------------</span><span id="b28c" class="md me it nq b gy ny nv l nw nx">setwd(“C:/parent/diamond”) # To access the images of Diamonds suit.<br/>                           #The path should be modified as per your <br/>                           # machine<br/>img.card&lt;- sample(dir());<br/>cards&lt;-list(NULL);<br/>for(i in 1:length(img.card))<br/>{ cards[[i]]&lt;- readImage(img.card[i])<br/>cards[[i]]&lt;- resize(cards[[i]], 100, 100)} #resizing to 100x100<br/>diamond&lt;- cards           # Storing stack of the Diamonds cards in<br/>                          # matrix form in a list<br/>#-------------------------------------------------------------</span><span id="4011" class="md me it nq b gy ny nv l nw nx">train_pool&lt;-c(club[1:40], <br/>              heart[1:40], <br/>              spade[1:40], <br/>              diamond[1:40]) # Vector of all the training images. <br/>                             # The first 40 images from each suit <br/>                             # are included in the train set</span><span id="5ea6" class="md me it nq b gy ny nv l nw nx">train&lt;-aperm(combine(train_pool), c(4,1,2,3)) # Combine and stacked</span><span id="e02f" class="md me it nq b gy ny nv l nw nx">test_pool&lt;-c(club[41:43], <br/>             heart[41:43], <br/>             spade[41:43], <br/>             diamond[41:43]) # Vector of all test images. The last<br/>                             # 3 images from each suit is included<br/>                             # in test set</span><span id="bed5" class="md me it nq b gy ny nv l nw nx">test&lt;-aperm(combine(test_pool), c(4,1,2,3)) # Combined and stacked</span></pre><blockquote class="oa ob oc"><p id="ce85" class="ky kz mz la b lb lc ju ld le lf jx lg od li lj lk oe lm ln lo of lq lr ls lt im bi translated">为了查看测试集中包含了哪些图像，我们这样做:</p></blockquote><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="13a2" class="md me it nq b gy nu nv l nw nx">par(mfrow=c(3,4)) # To contain all images in single frame<br/>for(i in 1:12){<br/>  plot(test_pool[[i]])<br/>  }<br/>par(mfrow=c(1,1)) # Reset the default</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/3476b76476eb226d9b4f725c80c41a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-HTwUQpRskvkTBG-zO8S7g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 8。测试集(<em class="mx">作者图片</em>)</p></figure><blockquote class="oa ob oc"><p id="ba06" class="ky kz mz la b lb lc ju ld le lf jx lg od li lj lk oe lm ln lo of lq lr ls lt im bi translated">我得到了如图 8 所示的卡片。对你来说可能是一套不同的卡片。</p></blockquote><p id="0ed8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">需要一个热编码</strong>来创建对应于输入数据的分类向量。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="06d0" class="md me it nq b gy nu nv l nw nx">#one hot encoding<br/>train_y&lt;-c(rep(0,40),rep(1,40),rep(2,40),rep(3,40))<br/>test_y&lt;-c(rep(0,3),rep(1,3),rep(2,3),rep(3,3))</span><span id="36b7" class="md me it nq b gy ny nv l nw nx">train_lab&lt;-to_categorical(train_y) #Catagorical vector for training <br/>                                   #classes<br/>test_lab&lt;-to_categorical(test_y)#Catagorical vector for test classes</span></pre><h1 id="4f98" class="oh me it bd mf oi oj ok mi ol om on ml jz oo ka mo kc op kd mr kf oq kg mu or bi translated">让我们来构建架构</h1><p id="2214" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">下面是构建 CNN 模型的 R 脚本。我还提供了一个全面的动画，演示了脚本运行的过程(图 9)。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="7488" class="md me it nq b gy nu nv l nw nx"># Model Building</span><span id="ae1c" class="md me it nq b gy ny nv l nw nx">model.card&lt;- keras_model_sequential() #-Keras Model composed of a <br/>                                      #-----linear stack of layers</span><span id="e7b1" class="md me it nq b gy ny nv l nw nx">model.card %&gt;%                   #---------Initiate and connect to #----------------------------(A)-----------------------------------#</span><span id="f084" class="md me it nq b gy ny nv l nw nx">layer_conv_2d(filters = 40,       #----------First convoluted layer<br/> kernel_size = c(4,4),             #---40 Filters with dimension 4x4<br/> activation = ‘relu’,              #-with a ReLu activation function<br/> input_shape = c(100,100,4)) %&gt;%   <br/>#----------------------------(B)-----------------------------------#</span><span id="1c60" class="md me it nq b gy ny nv l nw nx">layer_conv_2d(filters = 40,       #---------Second convoluted layer<br/> kernel_size = c(4,4),             #---40 Filters with dimension 4x4<br/> activation = ‘relu’) %&gt;%          #-with a ReLu activation function<br/>#---------------------------(C)-----------------------------------#</span><span id="879d" class="md me it nq b gy ny nv l nw nx">layer_max_pooling_2d(pool_size = c(4,4) )%&gt;%   #--------Max Pooling<br/>#-----------------------------------------------------------------#</span><span id="0d27" class="md me it nq b gy ny nv l nw nx">layer_dropout(rate = 0.25) %&gt;%   #-------------------Drop out layer<br/>#----------------------------(D)-----------------------------------#</span><span id="9a8b" class="md me it nq b gy ny nv l nw nx">layer_conv_2d(filters = 80,      #-----------Third convoluted layer<br/> kernel_size = c(4,4),            #----80 Filters with dimension 4x4<br/> activation = ‘relu’) %&gt;%         #--with a ReLu activation function<br/>#-----------------------------(E)----------------------------------#</span><span id="930e" class="md me it nq b gy ny nv l nw nx">layer_conv_2d(filters = 80,      #----------Fourth convoluted layer<br/> kernel_size = c(4,4),            #----80 Filters with dimension 4x4<br/> activation = ‘relu’) %&gt;%         #--with a ReLu activation function<br/>#-----------------------------(F)----------------------------------#</span><span id="d2b8" class="md me it nq b gy ny nv l nw nx">layer_max_pooling_2d(pool_size = c(4,4)) %&gt;%  #---------Max Pooling<br/>#-----------------------------------------------------------------#</span><span id="93ab" class="md me it nq b gy ny nv l nw nx">layer_dropout(rate = 0.35) %&gt;%   #-------------------Drop out layer<br/>#------------------------------(G)---------------------------------#</span><span id="91b3" class="md me it nq b gy ny nv l nw nx">layer_flatten()%&gt;%   #---Flattening the final stack of feature maps<br/>#------------------------------(H)---------------------------------#</span><span id="0f57" class="md me it nq b gy ny nv l nw nx">layer_dense(units = 256, activation = ‘relu’)%&gt;% #-----Hidden layer<br/>#---------------------------(I)-----------------------------------#</span><span id="bb16" class="md me it nq b gy ny nv l nw nx">layer_dropout(rate= 0.25)%&gt;%     #-------------------Drop-out layer<br/>#-----------------------------------------------------------------#</span><span id="2050" class="md me it nq b gy ny nv l nw nx">layer_dense(units = 4, activation = “softmax”)%&gt;% #-----Final Layer<br/>#----------------------------(J)-----------------------------------#</span><span id="f422" class="md me it nq b gy ny nv l nw nx">compile(loss = 'categorical_crossentropy',<br/>          optimizer = optimizer_adam(),<br/>          metrics = c("accuracy"))   # Compiling the architecture</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/b75ec44139a3768ea0066e6c65053fd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*c2u1oBGbQ0w4mnbEh6Ewjw.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 8。说明模型创建<strong class="bd os"> ( <em class="mx">作者图片</em> ) </strong></p></figure><p id="49c7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mz">我们可以使用</em><strong class="la iu"><em class="mz">summary(model . card)</em></strong><em class="mz">得到这个模型的概要。这样的输出将是一个简洁明了的模型总结。</em></p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="c3dc" class="md me it nq b gy nu nv l nw nx">Model: “sequential”<br/>____________________________________________________________________<br/>Layer (type) Output Shape Param # <br/>====================================================================<br/>conv2d (Conv2D) (None, 97, 97, 40) 2600 <br/>____________________________________________________________________<br/>conv2d_1 (Conv2D) (None, 94, 94, 40) 25640 <br/>____________________________________________________________________<br/>max_pooling2d (MaxPooling2D) (None, 23, 23, 40) 0 <br/>____________________________________________________________________<br/>dropout (Dropout) (None, 23, 23, 40) 0 <br/>____________________________________________________________________<br/>conv2d_2 (Conv2D) (None, 20, 20, 80) 51280 <br/>____________________________________________________________________<br/>conv2d_3 (Conv2D) (None, 17, 17, 80) 102480 <br/>____________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2D) (None, 4, 4, 80) 0 <br/>____________________________________________________________________<br/>dropout_1 (Dropout) (None, 4, 4, 80) 0<br/>____________________________________________________________________<br/>flatten (Flatten) (None, 1280) 0 <br/>____________________________________________________________________<br/>dense (Dense) (None, 256) 327936 <br/>____________________________________________________________________<br/>dropout_2 (Dropout) (None, 256) 0 <br/>____________________________________________________________________<br/>dense_1 (Dense) (None, 4) 1028 <br/>====================================================================<br/>Total params: 510,964<br/>Trainable params: 510,964<br/>Non-trainable params: 0<br/>____________________________________________________________________</span></pre><h2 id="df74" class="md me it bd mf mg mh dn mi mj mk dp ml lh mm mn mo ll mp mq mr lp ms mt mu mv bi translated">模型拟合</h2><p id="3cd8" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">一旦构建了架构，就该让数据集适合模型的训练了。拟合过程如下:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="b86c" class="md me it nq b gy nu nv l nw nx">#fit model<br/>history&lt;- model.card %&gt;%<br/> fit(train, <br/> train_lab, <br/> epochs = 100,<br/> batch_size = 40,<br/> validation_split = 0.2<br/> )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/7df62f6e711375128b1402f3aee08472.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E8ZnYzxkuzy-QAzV5cuAvA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 9 ( <em class="mx">作者图片</em>)</p></figure><p id="4492" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">装配时，每个<strong class="la iu">时期</strong>(前馈-反馈)将出现在控制台区域。处理时间可能因机器而异。当 epochs 运行时，您应该会在 Rstudio 查看器中看到一个图形(图 9)。这些是训练集和验证集的损失和准确性的并列曲线。</p><p id="2c7f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">控制台中出现的运行时期如下所示:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="18c4" class="md me it nq b gy nu nv l nw nx">Train on 128 samples, validate on 32 samples<br/>Epoch 1/100<br/>128/128 [==============================] — 10s 78ms/sample — loss: 1.3648 — accuracy: 0.3281 — val_loss: 2.0009 — val_accuracy: 0.0000e+00<br/>Epoch 2/100<br/>128/128 [==============================] — 8s 59ms/sample — loss: 1.3098 — accuracy: 0.3359 — val_loss: 1.9864 — val_accuracy: 0.0000e+00<br/>Epoch 3/100<br/>128/128 [==============================] — 8s 61ms/sample — loss: 1.2686 — accuracy: 0.3516 — val_loss: 2.5289 — val_accuracy: 0.0000e+00</span></pre><p id="1e75" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mz">整个训练过程的总结可以用</em> <strong class="la iu"> <em class="mz">【剧情(历史)</em> </strong> <em class="mz">来绘制。</em></p><h2 id="1672" class="md me it bd mf mg mh dn mi mj mk dp ml lh mm mn mo ll mp mq mr lp ms mt mu mv bi translated">模型评估</h2><p id="2219" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">一旦训练结束。是时候评估我们新训练的模型了。首先，我们将查看 moel 在训练数据集上的性能，然后我们将最终在我们的测试集上测试和评估我们的训练模型。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="8b66" class="md me it nq b gy nu nv l nw nx">#Model Evaluation</span><span id="46bc" class="md me it nq b gy ny nv l nw nx">model.card %&gt;% evaluate(train,train_lab) #Evaluation of training set pred&lt;- model.card %&gt;% predict_classes(train) #-----Classification<br/>Train_Result&lt;-table(Predicted = pred, Actual = train_y) #----Results</span><span id="3b93" class="md me it nq b gy ny nv l nw nx">model.card %&gt;% evaluate(test, test_lab) #-----Evaluation of test set<br/>pred1&lt;- model.card  %&gt;% predict_classes(test)   #-----Classification<br/>Test_Result&lt;-table(Predicted = pred1, Actual = test_y) #-----Results</span><span id="6e4d" class="md me it nq b gy ny nv l nw nx">rownames(Train_Result)&lt;-rownames(Test_Result)&lt;-colnames(Train_Result)&lt;-colnames(Test_Result)&lt;-c("Clubs", "Hearts", "Spades", "Diamonds")</span><span id="fcae" class="md me it nq b gy ny nv l nw nx">print(Train_Result)<br/>print(Test_Result)</span></pre><p id="80fe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个会吐槽:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/58562904c7ecfaa428d1645ca16684f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*r7ovB5NexJ_KOYjCntRhuA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(<em class="mx">图片作者</em>)</p></figure><p id="ed4d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在训练集上 100%的准确率可能是过度拟合的迹象，但是请注意，我们的模型在测试集上也达到了 100%的准确率。这意味着我们已经成功地制作了一个卷积神经网络模型，将一个给定的纸牌图像正确地分类到它真正的花色中。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="2b22" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你在这里，那么恭喜你！！你已经成功地制作了你的卷积神经网络模型。希望你旅途愉快。如果你发现任何错误或不正确的地方，请随时联系我。我也欢迎所有可以提高本文件质量的建议。</p><p id="ffb2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谢谢你的阅读和快乐的 R-ing😀</p><h1 id="c17e" class="oh me it bd mf oi oj ok mi ol om on ml jz oo ka mo kc op kd mr kf oq kg mu or bi translated">其他著名读物</h1><blockquote class="oa ob oc"><p id="0345" class="ky kz mz la b lb lc ju ld le lf jx lg od li lj lk oe lm ln lo of lq lr ls lt im bi translated"><a class="ae no" href="https://medium.com/vsinghbisen/where-is-artificial-intelligence-used-areas-where-ai-can-be-used-14ba8c092e73" rel="noopener">人工智能用在哪里:可以用 AI 的领域</a></p><p id="ebc1" class="ky kz mz la b lb lc ju ld le lf jx lg od li lj lk oe lm ln lo of lq lr ls lt im bi translated"><a class="ae no" rel="noopener" target="_blank" href="/illustrated-10-cnn-architectures-95d78ace614d#:~:text=AlexNet%20(2012)&amp;text=With%2060M%20parameters%2C%20AlexNet%20has,on%20the%20subsets%20of%20ImageNet.%E2%80%9D">图解:10 个 CNN 架构</a></p><p id="392b" class="ky kz mz la b lb lc ju ld le lf jx lg od li lj lk oe lm ln lo of lq lr ls lt im bi translated"><a class="ae no" rel="noopener" target="_blank" href="/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9">深入了解卷积神经网络背后的数学知识</a></p><p id="2797" class="ky kz mz la b lb lc ju ld le lf jx lg od li lj lk oe lm ln lo of lq lr ls lt im bi translated"><a class="ae no" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">卷积神经网络综合指南 ELI5 方式</a></p><p id="97f8" class="ky kz mz la b lb lc ju ld le lf jx lg od li lj lk oe lm ln lo of lq lr ls lt im bi translated"><a class="ae no" href="https://blog.rstudio.com/2017/09/05/keras-for-r/" rel="noopener ugc nofollow" target="_blank"> Keras 代表 R </a></p><p id="c81b" class="ky kz mz la b lb lc ju ld le lf jx lg od li lj lk oe lm ln lo of lq lr ls lt im bi translated"><a class="ae no" href="https://bioconductor.org/packages/release/bioc/vignettes/EBImage/inst/doc/EBImage-introduction.html" rel="noopener ugc nofollow" target="_blank">电子图像简介</a></p></blockquote></div></div>    
</body>
</html>