<html>
<head>
<title>Text Processing Techniques on Twitter data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter 数据的文本处理技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-processing-techniques-on-twitter-data-69233296c778?source=collection_archive---------27-----------------------#2020-07-11">https://towardsdatascience.com/text-processing-techniques-on-twitter-data-69233296c778?source=collection_archive---------27-----------------------#2020-07-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/e9a245ba65b1abfba668647575259a5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VspjqAR1kW1sh1p8G9WO9g.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://pixabay.com/photos/twitter-social-media-media-social-793050/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><div class=""/><div class=""><h2 id="c975" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">使文本数据模型就绪</h2></div><p id="bc08" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有大量文本格式的数据。对机器来说，分析文本格式的数据是最复杂的任务，因为机器很难理解文本背后的语义。为此，我们将文本数据处理成机器可理解的格式。</p><blockquote class="lr"><p id="bc23" class="ls lt jg bd lu lv lw lx ly lz ma lq dk translated">文本处理只是将文本格式的数据转换成数值(或向量)，这样我们就可以将这些向量作为机器的输入，并使用代数的概念来分析数据。</p></blockquote><p id="9926" class="pw-post-body-paragraph kv kw jg kx b ky mb kh la lb mc kk ld le md lg lh li me lk ll lm mf lo lp lq ij bi translated">但是，当我们执行这种转换时，可能会丢失数据。关键是在转换和保留数据之间保持平衡。</p><p id="701d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在处理文本之前，文本的预处理是必不可少的。要快速浏览一下什么是文本预处理，请查看这篇文章。</p><div class="ip iq gp gr ir mg"><a href="https://medium.com/@ramyavidiyala/a-handbook-to-text-preprocessing-cc9693bf3c12" rel="noopener follow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd jh gy z fp ml fr fs mm fu fw jf bi translated">文本预处理手册</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">自然语言处理的第一步</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">medium.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu ix mg"/></div></div></a></div><p id="2f33" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">在本文中，我们将讨论执行文本处理的各种技术。</strong></p><p id="6a0c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在开始之前，让我们先了解几个常用术语。</p><ul class=""><li id="a36e" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated">每个文本数据点称为一个<strong class="kx jh"> <em class="ne">文档</em> </strong></li><li id="9b8c" class="mv mw jg kx b ky nf lb ng le nh li ni lm nj lq na nb nc nd bi translated">整套文件叫做<strong class="kx jh"> <em class="ne">文集</em> </strong></li></ul><p id="5dca" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以使用以下技术来完成文本处理，</p><ol class=""><li id="ca81" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq nk nb nc nd bi translated">一袋单词</li><li id="e475" class="mv mw jg kx b ky nf lb ng le nh li ni lm nj lq nk nb nc nd bi translated">TF-IDF</li><li id="bf97" class="mv mw jg kx b ky nf lb ng le nh li ni lm nj lq nk nb nc nd bi translated">Word2Vec</li></ol><p id="f45d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在让我们开始详细研究每种技术。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="e99d" class="ns nt jg bd nu nv nw nx ny nz oa ob oc km od kn oe kp of kq og ks oh kt oi oj bi translated">1.一袋单词</h1><p id="396a" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">单词包通过使用一个独特单词的字典来完成文档到矢量的简单转换。这只需两步即可完成，</p><h2 id="d861" class="op nt jg bd nu oq or dn ny os ot dp oc le ou ov oe li ow ox og lm oy oz oi pa bi translated"><strong class="ak">第一步:构建字典</strong></h2><p id="3f5d" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">以向量形式创建数据语料库中所有唯一单词的字典。设语料库中唯一词的数量为，<em class="ne">‘d’</em>。所以每个单词是一个维度，因此这个字典向量是一个<em class="ne"> d 维向量。</em></p><h2 id="70fd" class="op nt jg bd nu oq or dn ny os ot dp oc le ou ov oe li ow ox og lm oy oz oi pa bi translated"><strong class="ak">步骤 2:构建载体</strong></h2><p id="95dd" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">对于每个文档，比如说，<em class="ne">r</em>ᵢ<em class="ne">t23】我们创建一个向量，比如说，<em class="ne"> v </em> ᵢ.<br/>现在，这种具有<em class="ne"> d 尺寸</em>的<em class="ne"> v </em> ᵢ有两种构造方式:</em></p><ol class=""><li id="315b" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq nk nb nc nd bi translated">对于每个文档，根据字典构建<em class="ne"> v </em> ᵢ，使得字典中的每个单词按照该单词在文档中出现的次数来再现。</li><li id="dcae" class="mv mw jg kx b ky nf lb ng le nh li ni lm nj lq nk nb nc nd bi translated">对于每个文档，根据字典构造<em class="ne"> v </em> ᵢ，使得字典中的每个单词被再现，</li></ol><ul class=""><li id="9853" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated">如果该单词出现在文档中，则为 1，或者</li><li id="5c96" class="mv mw jg kx b ky nf lb ng le nh li ni lm nj lq na nb nc nd bi translated">如果文档中没有该单词，则为 0</li></ul><p id="b2cc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种类型被称为<strong class="kx jh">二进制包字</strong>。</p><p id="2e6b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们有了每个文档的向量和一个字典，该字典有一组数据语料库的唯一单词。这些向量可以通过以下方式进行分析</p><ul class=""><li id="b128" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated">在 d 维空间中绘图或</li><li id="bd57" class="mv mw jg kx b ky nf lb ng le nh li ni lm nj lq na nb nc nd bi translated">计算向量之间的距离以获得相似度(向量越差，越相似)</li></ul><h2 id="7430" class="op nt jg bd nu oq or dn ny os ot dp oc le ou ov oe li ow ox og lm oy oz oi pa bi translated">词汇袋的局限性:</h2><ul class=""><li id="42a8" class="mv mw jg kx b ky ok lb ol le pb li pc lm pd lq na nb nc nd bi translated"><strong class="kx jh">问题:</strong>包词不考虑词的语义。意思是具有相同语义的单词如美味、可口被分成两个不同的单词。<br/> <strong class="kx jh">解决方案:</strong>使用词干化和词汇化等技术对数据进行预处理。</li><li id="0843" class="mv mw jg kx b ky nf lb ng le nh li ni lm nj lq na nb nc nd bi translated"><strong class="kx jh">问题:</strong>单词包没有保留文档的顺序信息，这意味着“不好”，这显然是不好的。一袋字把它归类为‘不好’和‘好’，显然不好。<br/> <strong class="kx jh">解决方案:</strong>不是创建每个单元格都是一个单词的向量，我们可以创建每个单元格都有两个单词的向量(称为<strong class="kx jh">二字组</strong>)或三个单词的向量(称为<strong class="kx jh">三字组</strong>)。使用这些<strong class="kx jh">n-gram</strong>，可以保留顺序信息。然而，当我们使用 n-grams 而不是 uni-gram 时，特征的维数增加了。</li></ul></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="21fb" class="ns nt jg bd nu nv nw nx ny nz oa ob oc km od kn oe kp of kq og ks oh kt oi oj bi translated">2.术语频率—逆文档频率</h1><p id="c950" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">这里有三个元素——单词、文档、语料库。词频——逆文档频率，简称 TF-IDF，利用这些之间的关系将文本数据转化为向量。</p><blockquote class="lr"><p id="2065" class="ls lt jg bd lu lv lw lx ly lz ma lq dk translated"><strong class="ak">词频</strong>说的是一个词和一个文档之间的关系。鉴于，<strong class="ak">逆文档频率</strong>表示单词和语料库之间的关系。</p></blockquote><h2 id="2f77" class="op nt jg bd nu oq pe dn ny os pf dp oc le pg ov oe li ph ox og lm pi oz oi pa bi translated">步骤 1:计算词频</h2><p id="946d" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated"><strong class="kx jh"> <em class="ne">词频</em> </strong>是单词<em class="ne"> w </em> ⱼ在文档<em class="ne"> r </em> ᵢ.出现的概率并且计算如下:</p><figure class="pk pl pm pn gt is gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/89618480ad4ede45eb07193de3524fea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*kmWISe3nKQm89GapIyL5TQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">用数学公式计算<strong class="bd po">复习中每个单词的词频</strong></p></figure><blockquote class="pp pq pr"><p id="790e" class="kv kw ne kx b ky kz kh la lb lc kk ld ps lf lg lh pt lj lk ll pu ln lo lp lq ij bi translated">如果<strong class="kx jh"> </strong>一个词在某篇评论中的词频是<strong class="kx jh">高</strong>则暗示该词在该篇评论中是<strong class="kx jh">频繁</strong>。如果一个单词在评论中的词频<strong class="kx jh">低</strong>意味着，该单词在该评论中<strong class="kx jh">罕见</strong>。</p></blockquote><h2 id="1841" class="op nt jg bd nu oq or dn ny os ot dp oc le ou ov oe li ow ox og lm oy oz oi pa bi translated">步骤 2:计算 IDF</h2><p id="f649" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated"><strong class="kx jh"> <em class="ne">逆文档频率</em> </strong>表示该词在整个语料库中出现的频率。并且计算如下:</p><figure class="pk pl pm pn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pv"><img src="../Images/e5ba2d21d005e460ff4d73a0578e5a73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j7QKNSzgsGbq1QRIQCWE0w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">计算<strong class="bd po">逆文档频率的数学公式</strong></p></figure><blockquote class="pp pq pr"><p id="8254" class="kv kw ne kx b ky kz kh la lb lc kk ld ps lf lg lh pt lj lk ll pu ln lo lp lq ij bi translated">如果逆文档频率<strong class="kx jh">低</strong>，则暗示该词在语料库中<strong class="kx jh">频繁</strong>。如果逆文档频率是<strong class="kx jh">高</strong>，则暗示该词在语料库中是<strong class="kx jh">稀有</strong>。</p></blockquote><p id="f96b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用对数而不是简单的反比的原因是缩放。概率范围在 0 和 1 之间的术语频率。当我们简单地取这个反比时，它将是一个巨大的值，因此整个 TF-IDF 值将偏向 IDF。这是在 IDF 术语中使用日志的一个简单且被广泛接受的原因。</p><blockquote class="lr"><p id="f939" class="ls lt jg bd lu lv lw lx ly lz ma lq dk translated"><strong class="ak">评论中一个词的 TF-IDF </strong>是 TF(word，review) *IDF(word，document corpus)。</p></blockquote><p id="eb65" class="pw-post-body-paragraph kv kw jg kx b ky mb kh la lb mc kk ld le md lg lh li me lk ll lm mf lo lp lq ij bi translated">现在在每个文档的向量形式中，我们有这个单词的 TF-IDF。<em class="ne">使用 TF-IDF 值将文档转换成矢量称为</em> <strong class="kx jh"> <em class="ne"> TF-IDF 矢量化。</em>T15】</strong></p><p id="85ab" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TF-IDF 矢量化对以下单词给予高度重视</p><ul class=""><li id="9c63" class="mv mw jg kx b ky kz lb lc le mx li my lm mz lq na nb nc nd bi translated">在文档中频繁出现(来自 TF)</li><li id="bbe3" class="mv mw jg kx b ky nf lb ng le nh li ni lm nj lq na nb nc nd bi translated">语料库中罕见(来自 IDF)</li></ul></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="da7c" class="ns nt jg bd nu nv nw nx ny nz oa ob oc km od kn oe kp of kq og ks oh kt oi oj bi translated">3.Word2Vec</h1><p id="8abc" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">在单词袋和 TF-IDF 中，我们将<em class="ne">句子转换成矢量</em>。但是在 Word2Vec 中，我们将<em class="ne"> word 转换成一个向量</em>。因此得名，word2vec！</p><p id="2b57" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Word2Vec 将大型文本语料库作为其输入，并产生一个向量空间，通常具有数百个维度，语料库中的每个唯一单词都被分配一个空间中的相应向量。单词向量位于向量空间中，使得语料库中共享共同上下文的单词在空间中彼此靠近。</p><h2 id="0610" class="op nt jg bd nu oq or dn ny os ot dp oc le ou ov oe li ow ox og lm oy oz oi pa bi translated">优势:</h2><ol class=""><li id="3569" class="mv mw jg kx b ky ok lb ol le pb li pc lm pd lq nk nb nc nd bi translated">每个单词在空间上更接近具有相同语义的单词(意思像女人、女孩)</li><li id="30d3" class="mv mw jg kx b ky nf lb ng le nh li ni lm nj lq nk nb nc nd bi translated">它保留了单词之间的关系(男人对女人的向量平行于国王对王后的向量)</li></ol><figure class="pk pl pm pn gt is gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/545f5da618f93441f81114e04cdbe0e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*o-aSqIOzjTD_1nR0.png"/></div></figure></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="e782" class="ns nt jg bd nu nv nw nx ny nz oa ob oc km od kn oe kp of kq og ks oh kt oi oj bi translated">履行</h1><p id="9ef0" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">在本文中，我们将在 Kaggle 的 Twitter 数据集上使用客户支持。</p><div class="ip iq gp gr ir mg"><a href="https://www.kaggle.com/thoughtvector/customer-support-on-twitter" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd jh gy z fp ml fr fs mm fu fw jf bi translated">Twitter 上的客户支持</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">Twitter 上最大品牌的 300 多万条推文和回复</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">www.kaggle.com</p></div></div><div class="mp l"><div class="px l mr ms mt mp mu ix mg"/></div></div></a></div><h2 id="f43c" class="op nt jg bd nu oq or dn ny os ot dp oc le ou ov oe li ow ox og lm oy oz oi pa bi translated">关于数据集:</h2><p id="973c" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">Twitter 数据集上的客户支持是一个大型的现代推文和回复语料库，有助于自然语言理解和会话模型的创新，并用于研究现代客户支持实践和影响。该数据集提供了 Twitter 上消费者和客户支持代理之间的大量现代英语对话。</p><p id="f29c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们使用预处理过的数据，并对其执行每个文本预处理。让我们看看预处理的数据</p><pre class="pk pl pm pn gt py pz qa qb aw qc bi"><span id="2353" class="op nt jg pz b gy qd qe l qf qg">data["preprocessed_text"]</span></pre><figure class="pk pl pm pn gt is gh gi paragraph-image"><div class="gh gi qh"><img src="../Images/c5201008c1c40c747e6442dc549a9106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*4rf5-YuAqNXUprNswiYKeQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">预处理数据</p></figure><h2 id="d00e" class="op nt jg bd nu oq or dn ny os ot dp oc le ou ov oe li ow ox og lm oy oz oi pa bi translated">实现单词包</h2><p id="f9d2" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">Sckit learns 为我们提供了许多图书馆。这使得我们很容易在一行代码中实现任何功能。</p><pre class="pk pl pm pn gt py pz qa qb aw qc bi"><span id="2494" class="op nt jg pz b gy qd qe l qf qg">from sklearn.feature_extraction.text import CountVectorizer</span></pre><p id="f941" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Sckit learn 提供了 CountVectorizer 来执行单词包。</p><pre class="pk pl pm pn gt py pz qa qb aw qc bi"><span id="8e06" class="op nt jg pz b gy qd qe l qf qg">bow=CountVectorizer( min_df=2, max_features=1000)<br/>bow.fit(data['preprocessed_text'])<br/>bow_df=bow.transform(data['preprocessed_text']).toarray()</span></pre><p id="5bea" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">创建计数矢量器对象，用预处理后的数据进行拟合、变换。<em class="ne"> bow_df </em>是一个稀疏向量，它包含的 0 的数量多于 1。</p><h2 id="9fae" class="op nt jg bd nu oq or dn ny os ot dp oc le ou ov oe li ow ox og lm oy oz oi pa bi translated">实施 TF-IDF</h2><pre class="pk pl pm pn gt py pz qa qb aw qc bi"><span id="2b61" class="op nt jg pz b gy qd qe l qf qg">from sklearn.feature_extraction.text import TfidfVectorizer</span></pre><p id="fc09" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Sckit learn 提供 tfidf 矢量器来执行 TF-IDF 矢量化。</p><pre class="pk pl pm pn gt py pz qa qb aw qc bi"><span id="bc8b" class="op nt jg pz b gy qd qe l qf qg">tfidf = TfidfVectorizer( min_df=2, max_features=1000)<br/>tfidf.fit(data['preprocessed_text'])<br/>tfidf_df=bow.transform(data['preprocessed_text']).toarray()</span></pre><p id="4874" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="ne"> tfidf_df </em>包含文档中每个单词在 1000 维向量中的 tf-idf 值。</p><h2 id="f9b0" class="op nt jg bd nu oq or dn ny os ot dp oc le ou ov oe li ow ox og lm oy oz oi pa bi translated">Word2vec 的实现</h2><p id="5089" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">谷歌提供了一个庞大的向量列表，这些向量是在谷歌新闻的海量数据上训练出来的。要使用这些向量，我们需要导入 Gensim。</p><pre class="pk pl pm pn gt py pz qa qb aw qc bi"><span id="831c" class="op nt jg pz b gy qd qe l qf qg">import gensim<br/>tokenize=data['preprocessed_text'].apply(lambda x: x.split())<br/>w2vec_model=gensim.models.Word2Vec(tokenize,min_count = 1, size = 100, window = 5, sg = 1)<br/>w2vec_model.train(tokenize,total_examples= len(data['preprocessed_text']),epochs=20)</span></pre><p id="ba8d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">输出:(18237，22200)个数据点。这意味着文本的 18237 个数据点现在被转换成 22200 维向量。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="7661" class="ns nt jg bd nu nv nw nx ny nz oa ob oc km od kn oe kp of kq og ks oh kt oi oj bi translated">什么时候用什么？</h1><p id="5006" class="pw-post-body-paragraph kv kw jg kx b ky ok kh la lb ol kk ld le om lg lh li on lk ll lm oo lo lp lq ij bi translated">这个问题没有明显的答案:它确实取决于应用程序。</p><p id="8518" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如，<strong class="kx jh">单词包</strong>通常用于<em class="ne">文档分类</em>应用，其中每个单词的出现被用作训练分类器的特征。</p><p id="6ec9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TF-IDF 被谷歌等<em class="ne">搜索引擎</em>用作内容的排名因素。</p><p id="2c06" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当应用程序是关于理解单词的上下文，或者检测单词的相似性，或者将给定的文档翻译成另一种语言，这需要关于文档的大量信息时，<strong class="kx jh"> Word2vec </strong>就派上了用场。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><p id="df2d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">谢谢你的阅读。以后我会写更多初学者友好的帖子。请在<a class="ae jd" href="https://medium.com/@ramyavidiyala" rel="noopener">媒体</a>上关注我，以便了解他们。我欢迎反馈，可以通过 Twitter <a class="ae jd" href="https://twitter.com/ramya_vidiyala" rel="noopener ugc nofollow" target="_blank"> ramya_vidiyala </a>和 LinkedIn <a class="ae jd" href="https://www.linkedin.com/in/ramya-vidiyala-308ba6139/" rel="noopener ugc nofollow" target="_blank"> RamyaVidiyala </a>联系我。快乐学习！</p><p id="3a04" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi">­­­­</p></div></div>    
</body>
</html>