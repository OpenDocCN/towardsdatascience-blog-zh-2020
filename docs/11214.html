<html>
<head>
<title>Web Scraping with Selenium</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用硒刮网</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/web-scraping-with-selenium-d7b6d8d3265a?source=collection_archive---------7-----------------------#2020-08-04">https://towardsdatascience.com/web-scraping-with-selenium-d7b6d8d3265a?source=collection_archive---------7-----------------------#2020-08-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2789" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">网刮系列</h2><div class=""/><div class=""><h2 id="e3c5" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">硒的实际操作</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/fbdd79501ce32ecdc0af0f84aac682ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1PVk34MALRt1SKP4-9Hjyg.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">克里斯托夫·高尔在<a class="ae lh" href="https://unsplash.com/s/photos/coding?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="d897" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">概观</h1><p id="2b80" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">Selenium 是用于测试 web 应用程序的可移植框架。它是在 Apache License 2.0 下发布的开源软件，可以在 Windows、Linux 和 macOS 上运行。尽管 Selenium 有其主要用途，但它也用作 web 抓取工具。在不深入研究 Selenium 的组件的情况下，我们将关注对 web 抓取有用的单个组件，<strong class="mc jd"> <em class="mw"> WebDriver </em> </strong>。Selenium WebDriver 为我们提供了通过编程接口控制 web 浏览器来创建和执行测试用例的能力。</p><p id="f24b" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">在我们的例子中，我们将使用它从网站上抓取数据。当网站动态显示内容，即使用 JavaScripts 呈现内容时，Selenium 就派上了用场。尽管 Scrapy 是一个强大的网络抓取框架，但它对这些动态网站毫无用处。本教程的目标是让您熟悉 Selenium 并使用它进行一些基本的 web 抓取。</p><p id="3fe4" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">让我们从安装 selenium 和一个 web 驱动程序开始。WebDrivers 支持 7 种编程语言:Python、Java、C#、Ruby、PHP、。Net 和 Perl。本手册中的示例是用 Python 语言编写的。互联网上有其他语言的教程。</p><p id="dd06" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">这是关于使用 Scrapy 和 Selenium 进行网络抓取的 4 部分教程系列的第 3 部分。其他部分可在以下网址找到</p><p id="1f5e" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/web-scraping-with-scrapy-theoretical-understanding-f8639a25d9cd">第 1 部分:带 Scrapy 的网页抓取:理论理解</a></p><p id="3d0e" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/web-scraping-with-scrapy-practical-understanding-2fbdae337a3b">第 2 部分:用 Scrapy 进行网页抓取:实用理解</a></p><p id="6764" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated"><a class="ae lh" href="https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1" rel="noopener">第 4 部分:用硒刮网&amp;刮屑</a></p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="70da" class="li lj it bd lk ll nj ln lo lp nk lr ls ki nl kj lu kl nm km lw ko nn kp ly lz bi translated">安装 Selenium 和 WebDriver</h1><h2 id="cfcf" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">安装 Selenium</h2><p id="dced" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">在任何 Linux 操作系统上安装 Selenium 都很容易。只需在终端中执行以下命令，Selenium 就会自动安装。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="73dc" class="no lj it oa b gy oe of l og oh">pip install selenium</span></pre><h2 id="d86a" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">安装 web 驱动程序</h2><p id="09f0" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">Selenium 官方有针对<a class="ae lh" href="https://www.selenium.dev/documentation/en/getting_started_with_webdriver/browsers/" rel="noopener ugc nofollow" target="_blank"> 5 网络浏览器的网络驱动。在这里，我们将看到两个最广泛使用的浏览器的 WebDriver 的安装:Chrome 和 Firefox。</a></p><h2 id="4790" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">为 Chrome 安装 Chrome 驱动程序</h2><p id="e9a6" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">首先，我们需要从 Chrome 的官方<a class="ae lh" href="https://sites.google.com/a/chromium.org/chromedriver/" rel="noopener ugc nofollow" target="_blank">网站下载 chromedriver 的最新稳定版本。</a>这将是一个 zip 文件。我们需要做的就是提取它，并把它放在可执行路径中。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="264c" class="no lj it oa b gy oe of l og oh">wget <a class="ae lh" href="https://chromedriver.storage.googleapis.com/83.0.4103.39/chromedriver_linux64.zip" rel="noopener ugc nofollow" target="_blank">https://chromedriver.storage.googleapis.com/83.0.4103.39/chromedriver_linux64.zip</a></span><span id="9a00" class="no lj it oa b gy oi of l og oh">unzip chromedriver_linux64.zip</span><span id="6c82" class="no lj it oa b gy oi of l og oh">sudo mv chromedriver /usr/local/bin/</span></pre><h2 id="cb96" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">为 Firefox 安装 Geckodriver</h2><p id="c7a1" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">为 Firefox 安装 geckodriver 更加简单，因为它是由 Firefox 自己维护的。我们所需要做的就是在终端中执行下面的代码行，然后您就可以开始使用 selenium 和 geckodriver 了。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="3e45" class="no lj it oa b gy oe of l og oh">sudo apt install firefox-geckodriver</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="57e7" class="li lj it bd lk ll nj ln lo lp nk lr ls ki nl kj lu kl nm km lw ko nn kp ly lz bi translated">例子</h1><p id="89b7" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">有两个越来越复杂的例子。第一个将是一个更简单的网页打开和输入文本框和按键。这个例子展示了如何使用程序通过 Selenium 控制网页。第二个是更复杂的 web 抓取示例，包括鼠标滚动、鼠标按钮点击和导航到其他页面。这里的目标是让你有信心开始用 Selenium 进行 web 抓取。</p><h2 id="e59a" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">示例 1 —使用 Selenium 登录脸书</h2><p id="9c23" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">让我们使用 Selenium 和 chromedriver 尝试一个简单的自动化任务，作为我们的训练轮练习。为此，我们将尝试登录一个脸书帐户，我们不会执行任何类型的数据搜集。我假设你对使用浏览器的开发工具识别网页中使用的 HTML 标签有所了解。下面是一段 python 代码，它打开一个新的 Chrome 浏览器，打开脸书主页，输入用户名和密码，然后点击登录按钮。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="736e" class="no lj it oa b gy oe of l og oh">from selenium import webdriver<br/>from selenium.webdriver.common.keys import Keys</span><span id="336a" class="no lj it oa b gy oi of l og oh">user_name = "Your E-mail"<br/>password = "Your Password"</span><span id="464b" class="no lj it oa b gy oi of l og oh"># Creating a chromedriver instance<br/>driver = webdriver.Chrome()  # For Chrome<br/># driver = webdriver.Firefox() # For Firefox</span><span id="197c" class="no lj it oa b gy oi of l og oh"># Opening facebook homepage<br/>driver.get("https://www.facebook.com")</span><span id="43d2" class="no lj it oa b gy oi of l og oh"># Identifying email and password textboxes<br/>email = driver.find_element_by_id("email")<br/>passwd = driver.find_element_by_id("pass")</span><span id="57fb" class="no lj it oa b gy oi of l og oh"># Sending user_name and password to corresponding textboxes<br/>email.send_keys(user_name)<br/>passwd.send_keys(password)</span><span id="5a65" class="no lj it oa b gy oi of l og oh"># Sending a signal that RETURN key has been pressed<br/>passwd.send_keys(Keys.RETURN)</span><span id="6703" class="no lj it oa b gy oi of l og oh"># driver.quit()</span></pre><p id="f020" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">执行完这段 python 代码后，你的脸书主页将在一个新的 Chrome 浏览器窗口中打开。让我们研究一下这是如何成为可能的。</p><ol class=""><li id="a3da" class="oj ok it mc b md mx mg my mj ol mn om mr on mv oo op oq or bi translated">这一切都始于为您的浏览器创建一个 webdriver 实例。由于我在使用 Chrome，所以我使用了<code class="fe os ot ou oa b">driver = webdriver.Chrome()</code>。</li><li id="2b70" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv oo op oq or bi translated">然后我们用<code class="fe os ot ou oa b">driver.get("https://www.facebook.com")</code>打开<a class="ae lh" href="https://www.facebook.com" rel="noopener ugc nofollow" target="_blank">脸书</a>网页。当 python 遇到<code class="fe os ot ou oa b">driver.get(URL)</code>时，它会打开一个新的浏览器窗口，打开<code class="fe os ot ou oa b">URL</code>指定的网页。</li><li id="2c7e" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv oo op oq or bi translated">一旦主页被加载，我们使用它们的 HTML 标签的 id 属性来识别文本框以键入电子邮件和密码。这是使用<code class="fe os ot ou oa b">driver.find_element_by_id()</code>完成的。</li><li id="fc5a" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv oo op oq or bi translated">我们使用<code class="fe os ot ou oa b">send_keys()</code>发送用于登录脸书的<code class="fe os ot ou oa b">username</code>和<code class="fe os ot ou oa b">password</code>值。</li><li id="317c" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv oo op oq or bi translated">然后，我们通过使用<code class="fe os ot ou oa b">send_keys(Keys.RETURN)</code>发送相应的信号来模拟用户按下回车键的动作。</li></ol><p id="2891" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">重要提示:<br/>在程序中创建的任何实例都应该在程序结束时或者在它的目的完成后关闭。因此，每当我们创建一个 webdriver 实例时，必须使用<code class="fe os ot ou oa b">driver.quit()</code>终止它。如果我们不终止打开的实例，它就会开始耗尽 RAM，这可能会影响机器的性能并降低速度。在上面的例子中，这个终止过程已经被注释掉，以便在浏览器窗口中显示输出。如果终止，浏览器窗口也将关闭，读者将看不到输出。</p><h2 id="d806" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">示例 2 —从 OpenAQ 中收集污染数据</h2><p id="fd1e" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">这是一个更复杂的例子。<a class="ae lh" href="https://openaq.org/" rel="noopener ugc nofollow" target="_blank"> OpenAQ </a>是一个收集和分享空气质量数据的非营利组织，这些数据是公开的，可以通过多种方式访问。这一点从该网站的<a class="ae lh" href="https://openaq.org/robots.txt" rel="noopener ugc nofollow" target="_blank"> robots.txt </a>中可见一斑。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="5c9e" class="no lj it oa b gy oe of l og oh">User-agent: * <br/>Disallow:</span></pre><p id="7334" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">我们的目标是收集 http://openaq.org 上列出的所有国家的 PM2.5 数据。 PM2.5 是指直径小于 2.5 微米的颗粒物(PM)，比人类头发的直径还要小。如果读者有兴趣了解更多关于 PM2.5 的信息，请点击此<a class="ae lh" href="https://blissair.com/what-is-pm-2-5.htm" rel="noopener ugc nofollow" target="_blank">链接。</a></p><p id="4913" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">选择 Selenium 而不是 Scrapy 的原因是<a class="ae lh" href="http://openaq.org" rel="noopener ugc nofollow" target="_blank">http://openaq.org</a>使用 React JS 来呈现数据。如果是静态网页，Scrapy 会高效地抓取数据。为了收集数据，我们首先需要分析网站，手动导航页面，并记下提取数据所需的用户交互步骤。</p><h2 id="cc05" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">了解<a class="ae lh" href="http://openaq.org" rel="noopener ugc nofollow" target="_blank">http://openaq.org</a>的布局</h2><p id="c0b8" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">尽量少用网页导航刮总是比较好的。该网站有一个网页<a class="ae lh" href="https://openaq.org/#/locations" rel="noopener ugc nofollow" target="_blank">https://openaq.org/#/locations</a>可以作为抓取的起点。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/f23a82e604826d8ebde2e823390bde0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCwfbiuTKEYPs_L9zeIo4Q.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自 https://openaq.org/#/locations<a class="ae lh" href="https://openaq.org/#/locations" rel="noopener ugc nofollow" target="_blank">的截图</a>突出显示过滤选项</p></figure><p id="94e4" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">左侧面板上的过滤器位置选项用于过滤出每个国家的 PM2.5 数据。右侧面板上的结果显示了点击显示 PM2.5 和其他数据时打开新页面的卡片。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pb"><img src="../Images/f2a5cd8c625c66bdf1ad04b6a3b4d735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nvVSscgTlKFOVpDVpLHSaA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自<a class="ae lh" href="https://openaq.org/#/locations" rel="noopener ugc nofollow" target="_blank">https://openaq.org/#/locations</a>的截图显示了选择国家和 PM2.5 后的结果</p></figure><p id="f67d" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">包含 PM2.5 数据的示例页面如下所示。从这个页面，我们可以提取 PM2.5 值，位置，城市，国家，日期和时间记录 PM2.5 值使用 XPATH 或 CSS。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/df67dd624c5ee19ef73fae316bfcf7be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GnIhope5Rgoz-OJ6jRzBzQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自 https://openaq.org<a class="ae lh" href="https://openaq.org" rel="noopener ugc nofollow" target="_blank">的截图</a>显示点击上一张图片中的位置后的 PM2.5 值</p></figure><p id="675d" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">同样，左侧面板可用于过滤和收集包含 PM2.5 数据的所有位置的 URL。以下是我们为收集数据而手动执行的操作。</p><ol class=""><li id="2d4f" class="oj ok it mc b md mx mg my mj ol mn om mr on mv oo op oq or bi translated">打开 https://openaq.org/#/locations<a class="ae lh" href="https://openaq.org/#/locations" rel="noopener ugc nofollow" target="_blank">的</a></li><li id="3e68" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv oo op oq or bi translated">从左侧面板中，选择/单击国家/地区的复选框。让我们按字母顺序浏览一下这些国家。</li><li id="5f15" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv oo op oq or bi translated">此外，在左侧面板中，选择/单击复选框 PM2.5。</li><li id="84d7" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv oo op oq or bi translated">等待卡片装入右侧面板。每张卡片点击后都会打开一个新的网页，显示 PM2.5 和其他数据。</li></ol><h2 id="5ce4" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">收集 PM2.5 数据所需的步骤</h2><p id="fced" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">根据执行的手动步骤，从<a class="ae lh" href="http://openaq.org" rel="noopener ugc nofollow" target="_blank">http://openaq.org</a>收集数据分为 3 个步骤。</p><ol class=""><li id="a793" class="oj ok it mc b md mx mg my mj ol mn om mr on mv oo op oq or bi translated">收集 OpenAQ 国家网页上显示的国家名称。这将用于在过滤时选择适当的复选框。</li><li id="055f" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv oo op oq or bi translated">从每个国家收集包含 PM2.5 数据的 URL。一些国家包含从不同地点收集的 20 多个 PM2.5 读数。这将需要对网页进行进一步的操作，这将在代码部分进行解释。</li><li id="e8d5" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv oo op oq or bi translated">打开个人网址的网页并提取 PM2.5 数据。</li></ol><h2 id="152f" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">抓取 PM2.5 数据</h2><p id="27f8" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">现在我们有了需要的步骤，让我们开始编码。该示例分为 3 个函数，每个函数执行与上述 3 个步骤相对应的任务。这个例子的 python 代码可以在我的<a class="ae lh" href="https://github.com/karthikn2789/Selenium-Project" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd"> <em class="mw"> GitHub 资源库</em> </strong> </a> <strong class="mc jd"> <em class="mw">中找到。</em> </strong></p><h2 id="0166" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">获取 _ 国家()</h2><p id="f956" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">有一个<a class="ae lh" href="https://openaq.org/#/countries" rel="noopener ugc nofollow" target="_blank">https://openaq.org/#/countries</a>网页，可以一次显示所有国家，而不是使用 OpenAQ locations 网页。从这个页面提取国家名称更容易。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pd"><img src="../Images/09b493cf142fc09366cd5b26348714d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ZHkRqN8ejmKUJSPJm6yzg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自<a class="ae lh" href="https://openaq.org/#/countries" rel="noopener ugc nofollow" target="_blank">https://openaq.org/#/countries</a>的显示国家列表的截图</p></figure><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="d267" class="no lj it oa b gy oe of l og oh">from selenium import webdriver<br/>from selenium.webdriver.common.by import By<br/>from selenium.webdriver.support.ui import WebDriverWait<br/>from selenium.webdriver.support import expected_conditions as EC<br/>import json</span><span id="7b07" class="no lj it oa b gy oi of l og oh">def get_countries():</span><span id="7043" class="no lj it oa b gy oi of l og oh">countries_list = []</span><span id="110e" class="no lj it oa b gy oi of l og oh"># driver = webdriver.Chrome() # To open a new browser window and navigate it</span><span id="a523" class="no lj it oa b gy oi of l og oh"># Use the headless option to avoid opening a new browser window<br/>    options = webdriver.ChromeOptions()<br/>    options.add_argument("headless")<br/>    desired_capabilities = options.to_capabilities()<br/>    driver = webdriver.Chrome(desired_capabilities=desired_capabilities)</span><span id="7cec" class="no lj it oa b gy oi of l og oh"># Getting webpage with the list of countries</span><span id="c79d" class="no lj it oa b gy oi of l og oh">driver.get("https://openaq.org/#/countries")</span><span id="1d28" class="no lj it oa b gy oi of l og oh"># Implicit wait<br/>    driver.implicitly_wait(10)</span><span id="b199" class="no lj it oa b gy oi of l og oh"># Explicit wait<br/>    wait = WebDriverWait(driver, 5)<br/>    wait.until(EC.presence_of_element_located((By.CLASS_NAME, "card__title")))<br/>    <br/>    countries = driver.find_elements_by_class_name("card__title")<br/>    for country in countries:<br/>        countries_list.append(country.text)</span><span id="33d5" class="no lj it oa b gy oi of l og oh">driver.quit()</span><span id="01aa" class="no lj it oa b gy oi of l og oh"># Write countries_list to json file<br/>    with open("countries_list.json", "w") as f:<br/>        json.dump(countries_list, f)</span></pre><p id="2916" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">让我们了解代码是如何工作的。和往常一样，第一步是实例化 webdriver。这里，不是打开一个新的浏览器窗口，而是将 webdriver 实例化为一个无头窗口。这样，就不会打开新的浏览器窗口，从而减轻了 RAM 的负担。第二步是打开包含国家列表的网页。在上面的代码中使用了<em class="mw">等待</em>的概念。</p><ul class=""><li id="6057" class="oj ok it mc b md mx mg my mj ol mn om mr on mv pe op oq or bi translated"><strong class="mc jd">隐式等待</strong>:当创建时，它是活动的，直到 WebDriver 对象终止。并且对于所有操作都是通用的。它指示 webdriver 在元素加载到网页之前等待一段时间。</li><li id="6b6b" class="oj ok it mc b md ov mg ow mj ox mn oy mr oz mv pe op oq or bi translated"><strong class="mc jd">显式等待</strong>:限制于特定 web 元素的智能等待，在本例中，用类名“card__title”标记。一般和<code class="fe os ot ou oa b">ExpectedConditions</code>一起使用。</li></ul><p id="c968" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">第三步是使用类名为“card__title”的标签提取国家名称。最后，国家名称被写入一个 JSON 文件以便持久保存。下面是 JSON 文件的一瞥。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="cf74" class="no lj it oa b gy oe of l og oh">countries_list.json</span><span id="89e2" class="no lj it oa b gy oi of l og oh">["Afghanistan", "Algeria", "Andorra", "Antigua and Barbuda", ... ]</span></pre><h2 id="c2ed" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">get _ urls()</h2><p id="77ee" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">获得国家列表后的下一步是获得记录 PM2.5 数据的每个位置的 URL。为此，我们需要打开 OpenAQ locations 网页，并利用左侧面板过滤出国家和 PM2.5 数据。一旦被过滤，右侧面板将被填入记录 PM2.5 数据的各个位置的卡片。我们提取与这些卡中的每一个对应的 URL，并最终将它们写入一个文件，该文件将在提取 PM2.5 数据的下一步中使用。一些国家有 20 多个地点记录 PM2.5 数据。例如，澳大利亚有 162 个位置，比利时有 69 个位置，中国有 1602 个位置。对于这些国家/地区，位置网页的右侧面板细分为多个页面。这是非常必要的，我们通过这些网页导航，并收集所有地点的网址。下面的代码有一个<code class="fe os ot ou oa b">while TRUE:</code>循环来执行页面导航的任务。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="7ab9" class="no lj it oa b gy oe of l og oh">from selenium import webdriver<br/>from selenium.webdriver.common.by import By<br/>from selenium.webdriver.support.ui import WebDriverWait<br/>from selenium.webdriver.support import expected_conditions as EC<br/>from selenium.webdriver.common.action_chains import ActionChains<br/>from logzero import logger<br/>import selenium.common.exceptions as exception<br/>import time<br/>import json</span><span id="672f" class="no lj it oa b gy oi of l og oh">def get_urls():</span><span id="5256" class="no lj it oa b gy oi of l og oh"># Load the countries list written by get_countries()<br/>    with open("countries_list.json", "r") as f:<br/>        countries_list = json.load(f)<br/>    <br/>    # driver = webdriver.Chrome()<br/>    <br/>    # Use headless option to not open a new browser window<br/>    options = webdriver.ChromeOptions()<br/>    options.add_argument("headless")<br/>    desired_capabilities = options.to_capabilities()<br/>    driver = webdriver.Chrome(desired_capabilities=desired_capabilities)</span><span id="0144" class="no lj it oa b gy oi of l og oh">urls_final = []<br/>    for country in countries_list:</span><span id="9597" class="no lj it oa b gy oi of l og oh"># Opening locations webpage<br/>        driver.get("https://openaq.org/#/locations")<br/>        driver.implicitly_wait(5)<br/>        urls = []</span><span id="fcf7" class="no lj it oa b gy oi of l og oh"># Scrolling down the country filter till the country is visible<br/>        action = ActionChains(driver)<br/>        action.move_to_element(driver.find_element_by_xpath("//span[contains(text()," + '"' + country + '"' + ")]"))<br/>        action.perform()</span><span id="6652" class="no lj it oa b gy oi of l og oh"># Identifying country and PM2.5 checkboxes<br/>        country_button = driver.find_element_by_xpath("//label[contains(@for," + '"' + country + '"' + ")]")<br/>        values_button = driver.find_element_by_xpath("//span[contains(text(),'PM2.5')]")<br/>        <br/>        # Clicking the checkboxes<br/>        country_button.click()<br/>        time.sleep(2)<br/>        values_button.click()<br/>        time.sleep(2)</span><span id="e98b" class="no lj it oa b gy oi of l og oh">while True:<br/>            # Navigating subpages where there are more PM2.5 data. For example, Australia has 162 PM2.5 readings from 162 different locations that are spread across 11 subpages.</span><span id="ddd4" class="no lj it oa b gy oi of l og oh">locations = driver.find_elements_by_xpath("//h1[@class='card__title']/a")</span><span id="13c2" class="no lj it oa b gy oi of l og oh">for loc in locations:<br/>                link = loc.get_attribute("href")<br/>                urls.append(link)</span><span id="f4ab" class="no lj it oa b gy oi of l og oh">try:<br/>                next_button = driver.find_element_by_xpath("//li[@class='next']")<br/>                next_button.click()<br/>            except exception.NoSuchElementException:<br/>                logger.debug(f"Last page reached for {country}")<br/>                break</span><span id="1bd2" class="no lj it oa b gy oi of l og oh">logger.info(f"{country} has {len(urls)} PM2.5 URLs")<br/>        urls_final.extend(urls)</span><span id="402f" class="no lj it oa b gy oi of l og oh">logger.info(f"Total PM2.5 URLs: {len(urls_final)}")<br/>    driver.quit()</span><span id="e0f6" class="no lj it oa b gy oi of l og oh"># Write the URLs to a file<br/>    with open("urls.json", "w") as f:<br/>        json.dump(urls_final, f)</span></pre><p id="7470" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">记录运行时间超过 5 分钟的程序的输出总是一个好的习惯。为此，上面的代码使用了<code class="fe os ot ou oa b">logzero</code>。包含 URL 的输出 JSON 文件如下所示。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="03d5" class="no lj it oa b gy oe of l og oh">urls.json</span><span id="ea47" class="no lj it oa b gy oi of l og oh">[<br/>    "https://openaq.org/#/location/US%20Diplomatic%20Post%3A%20Kabul",<br/>    "https://openaq.org/#/location/Kabul",<br/>    "https://openaq.org/#/location/US%20Diplomatic%20Post%3A%20Algiers",<br/>    ...<br/>]</span></pre><h2 id="9af8" class="no lj it bd lk np nq dn lo nr ns dp ls mj nt nu lu mn nv nw lw mr nx ny ly iz bi translated">get_pm_data()</h2><p id="8221" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">从单个位置获取 PM2.5 数据的过程是一个直接的 web 抓取任务，即识别包含数据的 HTML 标签并通过文本处理提取它。在下面提供的代码中也会发生同样的情况。该代码提取国家、城市、位置、PM2.5 值、位置的 URL、记录 PM2.5 值的日期和时间。因为有超过 5000 个 URL 要打开，所以除非安装的 RAM 超过 64GB，否则 RAM 使用会有问题。为了让这个程序在最低 8GB 内存的机器上运行，每 200 个 URL 就终止并重新实例化 webdriver。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="9921" class="no lj it oa b gy oe of l og oh">from selenium import webdriver<br/>from selenium.webdriver.common.by import By<br/>from selenium.webdriver.support.ui import WebDriverWait<br/>from selenium.webdriver.support import expected_conditions as EC<br/>from selenium.webdriver.common.action_chains import ActionChains<br/>from logzero import logger<br/>import selenium.common.exceptions as exception<br/>import time<br/>import json</span><span id="7f54" class="no lj it oa b gy oi of l og oh">def get_pm_data():</span><span id="77fb" class="no lj it oa b gy oi of l og oh"># Load the URLs list written by get_urls() <br/>    with open("urls.json", "r") as f:<br/>        urls = json.load(f)</span><span id="839a" class="no lj it oa b gy oi of l og oh"># Use headless option to not open a new browser window<br/>    options = webdriver.ChromeOptions()<br/>    options.add_argument("headless")<br/>    desired_capabilities = options.to_capabilities()<br/>    driver = webdriver.Chrome(desired_capabilities=desired_capabilities)</span><span id="5a78" class="no lj it oa b gy oi of l og oh">list_data_dict = []<br/>    count = 0</span><span id="7e75" class="no lj it oa b gy oi of l og oh">for i, url in enumerate(urls):<br/>        data_dict = {}</span><span id="7cf2" class="no lj it oa b gy oi of l og oh"># Open the webpage corresponding to each URL<br/>        driver.get(url)<br/>        driver.implicitly_wait(10)<br/>        time.sleep(2)</span><span id="1a35" class="no lj it oa b gy oi of l og oh">try:<br/>            # Extract Location and City<br/>            loc = driver.find_element_by_xpath("//h1[@class='inpage__title']").text.split("\n")<br/>            logger.info(f"loc: {loc}")<br/>            location = loc[0]<br/>            city_country = loc[1].replace("in ", "", 1).split(",")<br/>            city = city_country[0]<br/>            country = city_country[1]<br/>            data_dict["country"] = country<br/>            data_dict["city"] = city<br/>            data_dict["location"] = location</span><span id="fa58" class="no lj it oa b gy oi of l og oh">pm = driver.find_element_by_xpath("//dt[text()='PM2.5']/following-sibling::dd[1]").text</span><span id="4700" class="no lj it oa b gy oi of l og oh">if pm is not None:<br/>                # Extract PM2.5 value, Date and Time of recording<br/>                split = pm.split("µg/m³")<br/>                pm = split[0]<br/>                date_time = split[1].replace("at ", "").split(" ")<br/>                date_pm = date_time[1]<br/>                time_pm = date_time[2]<br/>                data_dict["pm25"] = pm<br/>                data_dict["url"] = url<br/>                data_dict["date"] = date_pm<br/>                data_dict["time"] = time_pm</span><span id="c267" class="no lj it oa b gy oi of l og oh">list_data_dict.append(data_dict)<br/>                count += 1</span><span id="baef" class="no lj it oa b gy oi of l og oh">except exception.NoSuchElementException:<br/>            # Logging the info of locations that do not have PM2.5 data for manual checking<br/>            logger.error(f"{location} in {city},{country} does not have PM2.5")</span><span id="00f3" class="no lj it oa b gy oi of l og oh"># Terminating and re-instantiating webdriver every 200 URL to reduce the load on RAM<br/>        if (i != 0) and (i % 200 == 0):<br/>            driver.quit()<br/>            driver = webdriver.Chrome(desired_capabilities=desired_capabilities)<br/>            logger.info("Chromedriver restarted")</span><span id="8705" class="no lj it oa b gy oi of l og oh"># Write the extracted data into a JSON file<br/>    with open("openaq_data.json", "w") as f:<br/>        json.dump(list_data_dict, f)</span><span id="a3bd" class="no lj it oa b gy oi of l og oh">logger.info(f"Scraped {count} PM2.5 readings.")<br/>    driver.quit()</span></pre><p id="f6d7" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">程序的结果如下所示。该程序从 4114 个单独的位置提取了 PM2.5 值。想象一下打开这些单独的网页并手动提取数据。总的来说，正是这种时候让我们欣赏网络抓取程序或机器人的使用。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="6ef1" class="no lj it oa b gy oe of l og oh">openaq_data.json</span><span id="50d4" class="no lj it oa b gy oi of l og oh">[<br/>    {<br/>        "country": " Afghanistan",<br/>        "city": "Kabul",<br/>        "location": "US Diplomatic Post: Kabul",<br/>        "pm25": "33",<br/>        "url": "https://openaq.org/#/location/US%20Diplomatic%20Post%3A%20Kabul",<br/>        "date": "2020/07/31",<br/>        "time": "11:00"<br/>    },<br/>    {<br/>        "country": " Algeria",<br/>        "city": "Algiers",<br/>        "location": "US Diplomatic Post: Algiers",<br/>        "pm25": "31",<br/>        "url": "https://openaq.org/#/location/US%20Diplomatic%20Post%3A%20Algiers",<br/>        "date": "2020/07/31",<br/>        "time": "08:30"<br/>    },<br/>    {<br/>        "country": " Australia",<br/>        "city": "Adelaide",<br/>        "location": "CBD",<br/>        "pm25": "9",<br/>        "url": "https://openaq.org/#/location/CBD",<br/>        "date": "2020/07/31",<br/>        "time": "11:00"<br/>    },<br/>    ...<br/>]</span></pre></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="74ec" class="li lj it bd lk ll nj ln lo lp nk lr ls ki nl kj lu kl nm km lw ko nn kp ly lz bi translated">结束语</h1><p id="4130" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我希望这篇教程已经给了你用 Selenium 开始 web 抓取的信心。示例的完整代码在我的 GitHub <a class="ae lh" href="https://github.com/karthikn2789/Selenium-Project" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd"> <em class="mw">资源库</em> </strong> </a>中。在<a class="ae lh" href="https://medium.com/swlh/web-scraping-with-selenium-scrapy-9d9c2e9d83b1" rel="noopener"> <strong class="mc jd"> <em class="mw">下一篇教程</em> </strong> </a>中，我将向你展示如何将硒与 Scrapy 整合。</p><p id="4dfc" class="pw-post-body-paragraph ma mb it mc b md mx kd mf mg my kg mi mj mz ml mm mn na mp mq mr nb mt mu mv im bi translated">在那之前，祝你好运。保持安全和快乐的学习。！</p></div></div>    
</body>
</html>