<html>
<head>
<title>A Quick Little Lesson on KNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于 KNN 的简短一课</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-quick-little-lesson-on-knn-98381c487aa2?source=collection_archive---------34-----------------------#2020-08-22">https://towardsdatascience.com/a-quick-little-lesson-on-knn-98381c487aa2?source=collection_archive---------34-----------------------#2020-08-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5d6c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">对于初学者，由初学者</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/9367031ca2e906f3fec31f7996741777.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3J29o1ear-x6gWI23AWaGw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">这与 KNN 无关。虽然现在想想，我猜这些树技术上来说都是邻居！(来源:作者)</p></figure><p id="f747" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如题所示，这里有一个关于如何在 SciKit-Learn 中构建一个简单的 KNN 模型的简短课程。我将使用<a class="ae lr" href="https://www.kaggle.com/aljarah/xAPI-Edu-Data" rel="noopener ugc nofollow" target="_blank">这个数据集</a>。它包含学生学习成绩的信息。</p><p id="5da9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">包括的特征有学生举手的次数、他们的性别、家长满意度、他们缺课的频率以及他们参与课堂讨论的频率。</p><p id="0e74" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">每个学生被分成三个班级:高年级(H)、中等年级(M)和低年级(L)。我使用了其他特征来预测它们属于哪个类别。</p><p id="7bbc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">仅供参考:</p><ul class=""><li id="4494" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">高，90–100</li><li id="4fef" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">中等，70–89</li><li id="71c5" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">低，0–69</li></ul><p id="dbd9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">好吧，酷！让我们开始吧。</p><h1 id="0c7d" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">库导入</h1><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="4f86" class="nd mh iq mz b gy ne nf l ng nh"><strong class="mz ir">import</strong> <strong class="mz ir">numpy</strong> <strong class="mz ir">as</strong> <strong class="mz ir">np</strong><br/><strong class="mz ir">import</strong> <strong class="mz ir">pandas</strong> <strong class="mz ir">as</strong> <strong class="mz ir">pd</strong><br/><strong class="mz ir">import</strong> <strong class="mz ir">seaborn</strong> <strong class="mz ir">as</strong> <strong class="mz ir">sns</strong><br/><strong class="mz ir">import</strong> <strong class="mz ir">statsmodels.api</strong> <strong class="mz ir">as</strong> <strong class="mz ir">sm</strong><br/><br/><strong class="mz ir">from</strong> <strong class="mz ir">sklearn.model_selection</strong> <strong class="mz ir">import</strong> train_test_split<br/><strong class="mz ir">from</strong> <strong class="mz ir">sklearn.preprocessing</strong> <strong class="mz ir">import</strong> StandardScaler<br/><strong class="mz ir">from</strong> <strong class="mz ir">sklearn.neighbors</strong> <strong class="mz ir">import</strong> KNeighborsClassifier<br/><strong class="mz ir">from</strong> <strong class="mz ir">statsmodels.formula.api</strong> <strong class="mz ir">import</strong> ols</span><span id="2f27" class="nd mh iq mz b gy ni nf l ng nh"><strong class="mz ir">from</strong> <strong class="mz ir">sklearn.metrics</strong> <strong class="mz ir">import</strong> precision_score, recall_score,<br/>                            accuracy_score, f1_score</span><span id="0f26" class="nd mh iq mz b gy ni nf l ng nh"><strong class="mz ir">import</strong> <strong class="mz ir">matplotlib.pyplot</strong> <strong class="mz ir">as</strong> <strong class="mz ir">plt</strong><br/>%matplotlib inline</span></pre><p id="bb29" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，您想要导入您将需要的所有库。有些人在过程的每个阶段导入每个库，但是我个人喜欢在开始的时候全部导入。</p><p id="a3ea" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从技术上讲，我们不会真的使用 Seaborn 或 MatplotLib，但我喜欢把它们放在身边，以防万一我想在这个过程中可视化一些东西。</p><h1 id="2ae6" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">初始数据导入</h1><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="7c29" class="nd mh iq mz b gy ne nf l ng nh">df = pd.read_csv('xAPI-Edu-Data.csv')<br/>df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/025ef259e5ce035d1c35f2718b314ee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V56ufRhViC5kzXlyvKKXDA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">部分输出截图。</p></figure><p id="ca16" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">酷！数据一开始就很好。没有丢失的值，也没有异常值。然而，我们必须做少量的预处理来为我们的模型做好准备。</p><h2 id="5c3b" class="nd mh iq bd mi nk nl dn mm nm nn dp mq le no np ms li nq nr mu lm ns nt mw nu bi translated">预处理</h2><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="213c" class="nd mh iq mz b gy ne nf l ng nh"><em class="nv"># Dropping all unnecessary columns</em><br/><br/>df = df.drop(['NationalITy', 'PlaceofBirth', 'StageID', 'GradeID',<br/>              'SectionID', 'Topic', 'Relation',<br/>              'ParentAnsweringSurvey'],<br/>              axis = 1,<br/>              inplace = False)<br/>df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/bea5329937092674ae9a3827c6b018e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Da0G_LiAS1rsSB6a8oTpFQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">输出截图。</p></figure><p id="8cf4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在为 KNN 模型提供信息时，您只希望包含您实际上希望做出决策的特性。这似乎是显而易见的，但我认为值得一提。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="e5b2" class="nd mh iq mz b gy ne nf l ng nh"><em class="nv"># Binary encoding of categorical variables</em><br/><br/>df['gender'] = df['gender'].map({'M': 0, 'F': 1})<br/>df['Semester'] = df['Semester'].map({'F': 0, 'S': 1})<br/>df['ParentschoolSatisfaction'] = df['ParentschoolSatisfaction'].map({'Good': 0, 'Bad': 1})<br/>df['StudentAbsenceDays'] = df['StudentAbsenceDays'].map({'Under-7': 0, 'Above-7': 1})<br/><br/>df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/7849125a4409b6dc7d2f57e9a57e80e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aL6MbVJprjMOfF6WJxnOfA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">输出截图。</p></figure><p id="4935" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你从来没有这样做过，可能不太明显的是，你必须编码你的分类变量。想想也有道理。一个模型并不能真正诠释‘好’或‘坏’，但它可以诠释 0 和 1。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="6303" class="nd mh iq mz b gy ne nf l ng nh"><em class="nv"># Check for missing values</em><br/><br/>df.isna().sum()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/d1d8f8db4aa5299f48e792b68fb60c5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*KFpl8mS7SIY_dgqjt3LgMw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">输出截图。</p></figure><p id="a5df" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我知道我已经说过，我们没有任何缺失的价值观，但我只是想彻底了解一下。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="f50b" class="nd mh iq mz b gy ne nf l ng nh"><em class="nv"># Create a new dataframe with our target variable, remove the target variable from the original dataframe</em><br/><br/>labels = df['Class']<br/>df.drop('Class', axis = 1, inplace = <strong class="mz ir">True)</strong></span></pre><p id="5078" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后—</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="0321" class="nd mh iq mz b gy ne nf l ng nh">df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/5113b2ee03aaa8c309da599a1e6c57ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SAQI9zqqbbOwtH6vtmbquQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图输出。</p></figure><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="cf61" class="nd mh iq mz b gy ne nf l ng nh">labels.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/29a340cbd1a2b9ddccd01d67c0544ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*LzdV5ollBSUEngCeuyMeug.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">输出截图。</p></figure><p id="75b3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们希望将目标特征与预测特征分开。我们这样做是为了给我们的数据创建一个训练/测试分割。说到！</p><h1 id="c2d1" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">训练/测试分割</h1><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="b50b" class="nd mh iq mz b gy ne nf l ng nh">X_train, X_test, y_train, y_test = train_test_split(df, labels,<br/>                                                    test_size = .25,<br/>                                                    random_state =<br/>                                                    33)</span></pre><p id="bd60" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">*我意识到上面的格式很糟糕，我只是想让它对于这篇中型文章来说更易读。</p><h1 id="703a" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">缩放数据</h1><p id="82fa" class="pw-post-body-paragraph kv kw iq kx b ky ob jr la lb oc ju ld le od lg lh li oe lk ll lm of lo lp lq ij bi translated">下一部分提出了两个要点:</p><ol class=""><li id="3716" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq og ly lz ma bi translated">你需要缩放数据。如果不这样做，绝对值较大的变量将在模型中被赋予更大的权重，而没有真正的原因。我们有二进制编码的特征(0，1)，但我们也有学生举手次数的特征(0-80)。我们需要把它们放在同样的尺度上，这样它们在模型中就有同样的重要性。</li><li id="bba6" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq og ly lz ma bi translated">您必须在执行训练/测试分割后缩放数据。如果你不这样做，你会有泄漏，你会使你的模型失效。要获得更全面的解释，请查看 Jason Browlee 的这篇文章,他拥有大量关于机器学习的惊人资源。</li></ol><p id="52bf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">好消息是，这非常容易做到。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="df13" class="nd mh iq mz b gy ne nf l ng nh">scaler = StandardScaler()<br/><br/>scaled_data_train = scaler.fit_transform(X_train) <br/>scaled_data_test = scaler.transform(X_test)<br/><br/>scaled_df_train = pd.DataFrame(scaled_data_train, columns =<br/>                               df.columns)</span><span id="794d" class="nd mh iq mz b gy ni nf l ng nh">scaled_df_train.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/ee0bd8869981ac49ac44d9a4300d6079.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TIq9FQTXwqPoP3UDkK-ByQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">输出截图。</p></figure><p id="ba17" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">太棒了。简单的柠檬榨汁机，我们的数据是成比例的。</p><h1 id="881d" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">符合 KNN 模型</h1><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="d46f" class="nd mh iq mz b gy ne nf l ng nh"><em class="nv"># Instantiate the model</em><br/>clf = KNeighborsClassifier()<br/><br/><em class="nv"># Fit the model</em><br/>clf.fit(scaled_data_train, y_train)<br/><br/><em class="nv"># Predict on the test set</em><br/>test_preds = clf.predict(scaled_data_test)</span></pre><p id="d3ea" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">真的就这么简单。现在，我们想看看我们的基线模型表现如何。</p><h1 id="7ff1" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">评估模型</h1><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="68e0" class="nd mh iq mz b gy ne nf l ng nh"><strong class="mz ir">def</strong> print_metrics(labels, preds):<br/>    print("Precision Score: <strong class="mz ir">{}</strong>".format(precision_score(labels,<br/>           preds, average = 'weighted')))<br/>    print("Recall Score: <strong class="mz ir">{}</strong>".format(recall_score(labels, preds,<br/>           average = 'weighted')))<br/>    print("Accuracy Score: <strong class="mz ir">{}</strong>".format(accuracy_score(labels,<br/>           preds)))<br/>    print("F1 Score: <strong class="mz ir">{}</strong>".format(f1_score(labels, preds, average =<br/>           'weighted')))</span><span id="2321" class="nd mh iq mz b gy ni nf l ng nh">print_metrics(y_test, test_preds)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/0b48c0c0cfa28ad6ad061070db7bcfef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*ato07mXenGOGnEudq0Kxeg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">输出截图。</p></figure><p id="fdb8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">就这样，几乎不费吹灰之力，我们就创建了一个预测模型，能够以 75.8%的准确率将学生分类到他们的学术表现类别。还不错。</p><p id="6a68" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们或许可以通过调整模型的参数来改善这一点，但我将把这留给另一篇文章。</p><p id="2f9e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">快乐学习。😁</p></div></div>    
</body>
</html>