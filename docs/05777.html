<html>
<head>
<title>Destroy Image Classification by Ensemble of Pre-trained models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于预训练模型集成的破坏性图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/destroy-image-classification-by-ensemble-of-pre-trained-models-f287513b7687?source=collection_archive---------24-----------------------#2020-05-13">https://towardsdatascience.com/destroy-image-classification-by-ensemble-of-pre-trained-models-f287513b7687?source=collection_archive---------24-----------------------#2020-05-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b902" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过在 Tensorflow 中制作预训练网络(如 InceptionV3、MobileNetV2 和 Xception)的集成堆叠集成模型，消除图像分类任务</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/743362859fdf207467064b1da389ba57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KpkeQojwgsg7BVGg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@rodlong?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杆长</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="f2d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预先训练的网络非常酷。它们提供了很高的精确度，并且不需要花很多时间来训练。那么有什么能比预先训练好的网络更好呢？用其中的两个。最好用三个。或者事实上，使用多少你想要在一起作为一个系综模型和破坏图像分类任务。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="8bc1" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">要求</h1><p id="5a2c" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">如果你想编码，你需要 Tensorflow 和 OpenCV。你也可以像我一样使用 Google Colab，它会预装我们任务所需的所有软件包，还提供免费的 GPU。</p><h1 id="2681" class="mc md it bd me mf mz mh mi mj na ml mm jz nb ka mo kc nc kd mq kf nd kg ms mt bi translated">加载数据集</h1><p id="635e" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">被选择消灭的数据集是经典的猫对狗数据集。由于它是一个小数据集，我们将把它完全加载到内存中，以便它训练得更快。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="073a" class="nj md it nf b gy nk nl l nm nn">import tensorflow as tf<br/>import os<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import re<br/>import random<br/>import cv2</span><span id="af0a" class="nj md it nf b gy no nl l nm nn">_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'<br/>path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)<br/>PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')</span><span id="12a2" class="nj md it nf b gy no nl l nm nn">train_dir = os.path.join(PATH, 'train')<br/>validation_dir = os.path.join(PATH, 'validation')</span><span id="83ed" class="nj md it nf b gy no nl l nm nn">train_cats_dir = os.path.join(train_dir, 'cats')<br/>train_dogs_dir = os.path.join(train_dir, 'dogs')<br/>validation_cats_dir = os.path.join(validation_dir, 'cats')<br/>validation_dogs_dir = os.path.join(validation_dir, 'dogs')</span><span id="088b" class="nj md it nf b gy no nl l nm nn">cats_tr = os.listdir(train_cats_dir)<br/>dogs_tr = os.listdir(train_dogs_dir)<br/>cats_val = os.listdir(validation_cats_dir)<br/>dogs_val = os.listdir(validation_dogs_dir)</span><span id="b59b" class="nj md it nf b gy no nl l nm nn">cats_tr = [os.path.join(train_cats_dir, x) for x in cats_tr]<br/>dogs_tr = [os.path.join(train_dogs_dir, x) for x in dogs_tr]<br/>cats_val = [os.path.join(validation_cats_dir, x) for x in cats_val]<br/>dogs_val = [os.path.join(validation_dogs_dir, x) for x in dogs_val]</span><span id="945b" class="nj md it nf b gy no nl l nm nn">total_train = cats_tr + dogs_tr<br/>total_val = cats_val + dogs_val</span></pre><p id="4678" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有训练和验证(在本例中为测试)图像的路径都存储在 total_train 和 total_val 中。我们将使用 OpenCV 来读取图像，并将它们存储在具有维度(图像数量 x 图像形状 x 通道)的 NumPy 数组中。它们对应的标签也将存储在一维 NumPy 数组中。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="f142" class="nj md it nf b gy nk nl l nm nn">def data_to_array(total):<br/>    random.shuffle(total)<br/>    X = np.zeros((len(total_train), 224, 224, 3)).astype('float')<br/>    y = []<br/>    for i, img_path in enumerate(total):<br/>        img = cv2.imread(img_path)<br/>        img = cv2.resize(img, (224, 224))<br/>        X[i] = img<br/>        if len(re.findall('dog', img_path)) == 3:<br/>            y.append(0)<br/>        else:<br/>            y.append(1)<br/>    y = np.array(y)<br/>    return X, y</span><span id="76d3" class="nj md it nf b gy no nl l nm nn">X_train, y_train = data_to_array(total_train)<br/>X_test, y_test = data_to_array(total_val)</span></pre><h1 id="ff27" class="mc md it bd me mf mz mh mi mj na ml mm jz nb ka mo kc nc kd mq kf nd kg ms mt bi translated">创建集合模型</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/7c89d40a92554d88582c3cb146996e2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lzispVz5Gg6IGyyhFDNiRA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">要遵循的步骤</p></figure><h2 id="e6c4" class="nj md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">训练单个模型并保存它们</h2><p id="a96e" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们的第一个任务是创建所有单独的模型。我将使用 MobileNetV2、InceptionV3 和 Xception 创建三个不同的模型。在 Tensorflow 中，使用预先训练的网络创建模型非常容易。我们需要加载权重，决定是冻结还是解冻加载的权重，最后添加密集层，使输出达到我们想要的效果。我将为我的模型使用的基本结构:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="dfc4" class="nj md it nf b gy nk nl l nm nn">def create_model(base_model):<br/>    base_model.trainable = True<br/>    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)<br/>    prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')(global_average_layer)<br/>    model = tf.keras.models.Model(inputs=base_model.input, outputs=prediction_layer)<br/>    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=["accuracy"])<br/>    return model</span></pre><p id="9ffb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在创建我们的模型之后，我们需要将它们与我们的训练数据进行一些时期的拟合。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="b1ca" class="nj md it nf b gy nk nl l nm nn">batch_size = 32<br/>epochs = 20</span><span id="554f" class="nj md it nf b gy no nl l nm nn">def fit_model(model):<br/>    history = model.fit(X_train, y_train,<br/>                        batch_size=batch_size,<br/>                      steps_per_epoch=len(total_train)//batch_size, <br/>                        epochs=epochs, <br/>                        validation_data=(X_test, y_test), <br/>                        validation_steps=len(total_val)//batch_size)<br/>    return history</span><span id="d447" class="nj md it nf b gy no nl l nm nn">IMG_SHAPE = (224, 224, 3)<br/>base_model1 = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>base_model2 = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>base_model3 = tf.keras.applications.Xception(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")</span><span id="e15f" class="nj md it nf b gy no nl l nm nn">model1 = create_model(base_model1)<br/>model2 = create_model(base_model2)<br/>model3 = create_model(base_model3)</span><span id="9627" class="nj md it nf b gy no nl l nm nn">history1 = fit_model(model1)<br/>model1.save('models/model1.h5')</span><span id="4c85" class="nj md it nf b gy no nl l nm nn">history2 = fit_model(model2)<br/>model2.save('models/model2.h5')</span><span id="2e2e" class="nj md it nf b gy no nl l nm nn">history3 = fit_model(model3)<br/>model3.save('models/model3.h5')</span></pre><p id="4254" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看我们的模特们自己的表现。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/04b14e27a2a9167f34c6936d7672eb08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PR60Vj3_FWb_SnLnUrIFxw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">MobileNetV2 的结果</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/88d9633cf67285c0cd919786b93d3bb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z16O0wxJfDJ68MgSBY0siw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">InceptionV3 的结果</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/15f136ad546bfe365ff05293f1c6cbbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yd9e1iiCaafi7Qt1qfp0VQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">例外的结果</p></figure><p id="48c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果一点也不差，但我们仍将改进它们。</p><h2 id="ca20" class="nj md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">加载模型并冻结其图层</h2><p id="373a" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们的下一步是加载我们刚刚在上面创建的模型，并冻结它们的层，这样当我们在它们上面安装我们的集合模型时，它们的权重不会改变。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="83bc" class="nj md it nf b gy nk nl l nm nn">def load_all_models():<br/>    all_models = []<br/>    model_names = ['model1.h5', 'model2.h5', 'model3.h5']<br/>    for model_name in model_names:<br/>        filename = os.path.join('models', model_name)<br/>        model = tf.keras.models.load_model(filename)<br/>        all_models.append(model)<br/>        print('loaded:', filename)<br/>    return all_models</span><span id="68dc" class="nj md it nf b gy no nl l nm nn">models = load_all_models()<br/>for i, model in enumerate(models):<br/>    for layer in model.layers:<br/>        layer.trainable = False</span></pre><h2 id="c9c3" class="nj md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">连接它们的输出并添加密集层</h2><p id="a690" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">将所有模型的输出放入一个连接层。然后添加具有一些单元的密集层，接着是具有单个输出和激活等于“sigmoid”的密集层，因为我们的任务是二进制分类。这可以被认为是一个人工神经网络，其中所有模型的预测作为输入，并提供一个输出。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="2db0" class="nj md it nf b gy nk nl l nm nn">ensemble_visible = [model.input for model in models]<br/>ensemble_outputs = [model.output for model in models]<br/>merge = tf.keras.layers.concatenate(ensemble_outputs)<br/>merge = tf.keras.layers.Dense(10, activation='relu')(merge)<br/>output = tf.keras.layers.Dense(1, activation='sigmoid')(merge)<br/>model = tf.keras.models.Model(inputs=ensemble_visible, outputs=output)</span></pre><h2 id="625b" class="nj md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">编译和训练集合模型</h2><p id="bd32" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我使用了经典的“Adam”优化器，学习率略高，为 10x-3，来编译模型。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="1610" class="nj md it nf b gy nk nl l nm nn">model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=["accuracy"])</span></pre><p id="7616" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看我们的模型现在是什么样子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/ae9a8ee40403d55a9fa14e0f95523e6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*wp3kI8A53ygpeflOnRqMfw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">集合模型</p></figure><p id="cb2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们能像训练我们的个体模型一样，通过传递数据集来训练它吗？不要！在三个地方需要输入，而只产生一个输出。所以我们需要像这样配置我们的 X 值。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="a21f" class="nj md it nf b gy nk nl l nm nn">X_train = [X_train for _ in range(len(model.input))]<br/>X_test = [X_test for _ in range(len(model.input))]</span></pre><p id="b125" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以像以前一样拟合模型了。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="9847" class="nj md it nf b gy nk nl l nm nn">history = model.fit(X, y_train,<br/>                    batch_size=batch_size,<br/>                    steps_per_epoch=len(total_train) // batch_size,<br/>                    epochs=epochs, <br/>                    validation_data=(X_1, y_test),<br/>                    validation_steps=len(total_val) // batch_size)</span></pre><h1 id="410c" class="mc md it bd me mf mz mh mi mj na ml mm jz nb ka mo kc nc kd mq kf nd kg ms mt bi translated">结果</h1><p id="670f" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">首先，让我们为系综模型绘制图表。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/193fa09cf05feb22e6ee97846299100e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t87DL1EMReO8riW_dfwb6g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">集合模型的结果</p></figure><p id="4c92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我只对它进行了 20 个时期的训练，但看一下损失曲线就可以看出，曲线仍在下降，模型可以再训练一些时期。让我们看看这些模型在它们最后的时代给出了什么样的验证精度。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="4795" class="nj md it nf b gy nk nl l nm nn">MobileNetV2 acc: 0.9788306355476379<br/>InceptionV3 acc: 0.9778226017951965<br/>Xception acc: 0.9788306355476379<br/><strong class="nf iu">Ensemble acc: 0.9828628897666931</strong></span></pre><p id="3bed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总体精度几乎提高了 0.5%，如果考虑到之前的精度为 97.8%，这是一个巨大的提高。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="81f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以这种方式创建集合模型是一个非常长的过程。它需要比单一模型多四倍的努力，然而，它可以帮助获得多一点的准确性，这是很难获得的，一旦我们达到 90 以上的准确性。下面你可以找到完整的代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="b786" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在结束之前，我想对这篇<a class="ae ky" href="https://machinelearningmastery.com/stacking-ensemble-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">文章</a>给予一些肯定，它帮助我完成了这篇文章。</p></div></div>    
</body>
</html>