<html>
<head>
<title>Recommender systems using LinUCB: A contextual multi-armed bandit approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用LinUCB的推荐系统:一种上下文多臂bandit方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4?source=collection_archive---------5-----------------------#2020-04-18">https://towardsdatascience.com/recommender-systems-using-linucb-a-contextual-multi-armed-bandit-approach-35a6f0eb6c4?source=collection_archive---------5-----------------------#2020-04-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0468" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">推荐系统</h2><div class=""/><div class=""><h2 id="b4b6" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><em class="ko">使用分离LinUCB算法最大化用户交互的推荐系统的上下文多臂bandit方法分析</em></h2></div><h1 id="7a12" class="kp kq iq bd kr ks kt ku kv kw kx ky kz kf la kg lb ki lc kj ld kl le km lf lg bi translated">什么是多臂土匪问题？</h1><p id="88a4" class="pw-post-body-paragraph lh li iq lj b lk ll ka lm ln lo kd lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">多武器强盗问题，本质上，只是一个重复的试验，其中用户有固定数量的选项<em class="md">(称为武器)</em>，并根据他选择的选项获得奖励。比方说，一个企业主有10个特定产品的广告，必须在网站上展示其中一个广告。回报是通过观察广告是否<strong class="lj ja">有利可图</strong>足以让用户<strong class="lj ja">点击</strong>并被重定向到产品网站。</p><p id="f9ac" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">企业主为前1000个用户运行算法，以从10个可用广告中决定最佳广告，并且在他的试运行结束后，决定向其余用户显示<strong class="lj ja">最佳广告</strong>。该算法基于广告在试运行<em class="md">(前1000个用户)</em>中的表现来评估最佳广告</p><p id="4531" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">这是我们开始思考的地方。一个广告真的能满足广大多样的受众吗？</p><p id="938c" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">这就是<strong class="lj ja">语境</strong>土匪的用武之地。如果我们对用户有足够的了解，我们可以更准确地预测最适合用户的广告，这就是上下文MAB算法的作用。基于用户的特征选择广告(arm)(称为<em class="md">上下文</em>)。在我们继续分析这种算法之前，我们需要思考一些事情。</p><h1 id="93a6" class="kp kq iq bd kr ks kt ku kv kw kx ky kz kf la kg lb ki lc kj ld kl le km lf lg bi translated"><strong class="ak">勘探与开采</strong></h1><blockquote class="mj mk ml"><p id="a302" class="lh li md lj b lk me ka lm ln mf kd lp mm mg ls lt mn mh lw lx mo mi ma mb mc ij bi translated">在探索和开发之间做出选择的困境存在于生活的各个方面。</p></blockquote><p id="4be3" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">比方说，你去街角的冰淇淋店买你最喜欢的口味——巧克力T21。你不尝试其他口味，因为你害怕你可能不喜欢它们。但是，也有一个小概率，如果你尝试一种新的口味，比如说r <em class="md"> ed velvet </em>，你可能最终会比巧克力更喜欢它。在尝试新口味(探索)和总是得到你最喜欢的(探索)之间取得平衡是很重要的。</p><p id="3413" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">MAB算法必须在选择随机臂(<em class="md">可能最终成为最佳臂</em>)或利用其历史选择它认为是最佳的臂(<em class="md">可能只是次优臂，因为最佳臂可能还没有被充分探索</em>)之间找到确切的折衷</p><p id="c1ae" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">在线推荐系统试图使用这种算法，根据用户在网站上的活动记录，显示他们认为用户会喜欢的内容。</p><p id="9c69" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">我们稍后将构建的一个这样的算法被称为<em class="md">置信上限算法</em>。</p><h1 id="1618" class="kp kq iq bd kr ks kt ku kv kw kx ky kz kf la kg lb ki lc kj ld kl le km lf lg bi translated">UCB算法</h1><p id="53ea" class="pw-post-body-paragraph lh li iq lj b lk ll ka lm ln lo kd lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">解决多臂强盗问题的一个非常天真贪婪的方法是，在任意打破平局的情况下，选择给我们最大平均奖励的臂。尽管这种方法试图选择最佳的可能arm，但是算法失去了<em class="md">探索</em>的范围，并且从长远来看可能选择次优arm，因为可能有arm没有被充分尝试，但是可能是最佳选择。</p><p id="e647" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">UCB算法超越了这种方法，在探索和开发之间找到了平衡。它是这样工作的。</p><p id="225e" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">UCB算法跟踪到目前试验为止每只手臂的平均奖励，并计算每只手臂的置信上限。上界表示<strong class="lj ja">中的<em class="md">不确定性，我们评价</em>手臂的潜力。</strong></p><p id="f21d" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">如果一个arm具有非常高的置信上限，并且由于巨大的探索机会而选择该arm，则该算法对于该arm的潜力是高度不确定的。</p><p id="4b47" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">考虑一个运行中的UCB算法，其当前置信界限<em class="md">(虚线轮廓)</em>如下图所示。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mp"><img src="../Images/6913b056820e96221509cb02074d7fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p_4mvZ6r6ddbShd7tOT0sw.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">对任意试验x的UCB算法的表示</p></figure><p id="9441" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">尽管第3组记录的平均奖励较高，但算法选择第2组是因为其潜在的的<em class="md">不确定性，并更新其未来试验的置信界限。</em></p><p id="33e9" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">UCB算法不考虑用户的用户和内容特征(上下文),内容特征可能包括用户的历史活动和公开的人口统计信息。</p><h1 id="138f" class="kp kq iq bd kr ks kt ku kv kw kx ky kz kf la kg lb ki lc kj ld kl le km lf lg bi translated">LinUCB</h1><p id="3295" class="pw-post-body-paragraph lh li iq lj b lk ll ka lm ln lo kd lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">上下文MAB问题的开发/探索问题被形式化如下:</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nf"><img src="../Images/ba5290b81276025bfafaaf988d02a248.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GiiiXO3PZ3PaU9w7q0o49g.jpeg"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">来源:<a class="ae ng" href="https://arxiv.org/pdf/1003.0146.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1003.0146.pdf</a></p></figure><p id="9328" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">假设手臂的期望收益在其d维特征向量X中是线性的，具有某个未知的系数向量θ。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nh"><img src="../Images/d4fd51258aba4654f55961cd68359f1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*clz5xai_E_W1K8yKqIdUtQ.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">来源:<a class="ae ng" href="https://arxiv.org/pdf/1003.0146.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1003.0146.pdf</a></p></figure><p id="0251" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">这个模型被称为<em class="md">不相交</em>，因为参数不在不同的分支之间共享。为了求解上述方程中的系数向量θ，将岭回归应用于训练数据。</p><p id="19f6" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">必须为每个臂计算置信上限，以便算法能够在每次试验中选择一个臂。每次试验选择手臂的策略<em class="md"> t </em>正式确定为:</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi ni"><img src="../Images/3a84a97e524cade8e7fc4d39fa0d51a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gkzV-CwwBRe8r7ue69723w.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">来源:https://arxiv.org/pdf/1003.0146.pdf</p></figure><p id="9f3d" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">该算法的目标是最大化总回报(从长远来看，总用户点击量)</p><p id="eeae" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">该算法由其作者形式化如下:</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nj"><img src="../Images/f5602c9b48e5a4a68535724ceb0860e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EiWjFvoo9WrRFsO8Alkk5A.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">来源:https://arxiv.org/pdf/1003.0146.pdf<a class="ae ng" href="https://arxiv.org/pdf/1003.0146.pdf" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="e6e2" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">我们不详述算法的数学，但我们关注我通过在标准数据集上模拟该算法所获得的结果。</p><p id="dac2" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">通常，MAB问题是在<strong class="lj ja">遗憾</strong>的基础上分析的，遗憾是总是选择最优臂所获得的总报酬与算法所获得的总报酬之差。</p><p id="af1c" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">下面的甜甜圈图显示了如果我们只选择一只手臂(并将其视为最佳手臂)我们可以获得的最大奖励的比较。该图表明，不管选择的最优策略是什么，如果我们在决策中不表现出灵活性，我们最多可以获得总回报的20%。这种类型的比较在现实生活中通常是不可能的，因为我们事先无法获得全部数据，但这有助于我们认识到这样一个事实，即我们不能只依赖一个最佳手臂。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/6dc8a093245d00fc92556981e040664f.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*HTfyI6Lv4Njgqy4E9fN0sw.jpeg"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">当每只手臂分别被选为最佳手臂并用于每次试验时，所获得的总奖励的比较</p></figure><p id="b2ad" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">在每次试验中，LinUCB算法在决定手臂的选择方面做得非常好，下图也反映了这一点。它将每只手臂可能实现的最大奖励与每只手臂实际实现的奖励进行比较。结果表明，我们能够开发每个手臂高达90%的潜力。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nl"><img src="../Images/0f6975d5bc679848e1064fca13931219.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qvvUwEgr1RESNiRM391EiA.jpeg"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">每只手臂可实现的最大奖励与使用LinUCB实现的奖励</p></figure><p id="c250" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">推荐系统可以直接建模为上下文MAB问题，其中不同的推荐选项是手臂，用户是否喜欢推荐可以转化为奖励，最终目标是能够向每个用户提供个性化推荐。</p><p id="61df" class="pw-post-body-paragraph lh li iq lj b lk me ka lm ln mf kd lp lq mg ls lt lu mh lw lx ly mi ma mb mc ij bi translated">CMAB算法与基于用户偏好的各种过滤技术相结合，以实现更加个性化的推荐。</p><h1 id="25cc" class="kp kq iq bd kr ks kt ku kv kw kx ky kz kf la kg lb ki lc kj ld kl le km lf lg bi translated"><strong class="ak">总结</strong></h1><p id="9e20" class="pw-post-body-paragraph lh li iq lj b lk ll ka lm ln lo kd lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">LinUCB算法使我们能够获得大约90%的总回报，这比其他MAB算法高得多。推荐系统是一个非常重要的用例，其中奖励通常转化为更高的收入，这是企业的最终目标。</p><h1 id="187b" class="kp kq iq bd kr ks kt ku kv kw kx ky kz kf la kg lb ki lc kj ld kl le km lf lg bi translated">参考</h1><ul class=""><li id="6691" class="nm nn iq lj b lk ll ln lo lq no lu np ly nq mc nr ns nt nu bi translated">萨顿，理查德s和巴尔托，安德鲁g,《强化学习——介绍》<a class="ae ng" href="http://incompleteideas.net/book/the-book-2nd.html" rel="noopener ugc nofollow" target="_blank">http://incompleteideas.net/book/the-book-2nd.html</a></li><li id="a2b9" class="nm nn iq lj b lk nv ln nw lq nx lu ny ly nz mc nr ns nt nu bi translated">个性化新闻文章推荐的语境化方法<a class="ae ng" href="https://arxiv.org/pdf/1003.0146.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1003.0146.pdf</a></li></ul></div></div>    
</body>
</html>