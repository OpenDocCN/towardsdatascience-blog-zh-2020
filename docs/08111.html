<html>
<head>
<title>What is Cross-Validation?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是交叉验证？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-cross-validation-622d5a962231?source=collection_archive---------20-----------------------#2020-06-15">https://towardsdatascience.com/what-is-cross-validation-622d5a962231?source=collection_archive---------20-----------------------#2020-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="93c1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">此外，什么是 LOOCV 和 k 倍交叉验证技术？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c35eebb2f41534a8209921a27a4969ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xewvthGd2Vy66mg7"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Ashkan Forouzani 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="ae3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现代统计学和机器学习最重要的一个方面是<strong class="lb iu"> <em class="lv">重采样，这是从训练集中重复抽取样本(子集)并在每个样本上重新调整特定模型的过程，以便获得拟合的可变性等信息。</em> </strong></p><p id="d0c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用重采样的原因之一是，我们可以分析模型在同一数据集的许多样本上拟合的结果。这使我们能够获得一些额外的知识，而这些知识是通过仅仅一次拟合模型所不能获得的。使用这种方法的另一个原因是通过多次迭代来评估测试误差，以便更好地判断模型性能。</p><p id="5b41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一种这样的重采样方法是<strong class="lb iu"> <em class="lv">交叉验证。</em>T11】</strong></p><h2 id="1f25" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">交叉验证</h2><p id="4292" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">通常用于在几个数据训练样本上拟合机器学习模型时分析测试误差(模型评估)。然后，它进一步帮助我们根据模型的复杂性选择合适的模型(模型选择)。</em>T15】</strong></p><p id="2d74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们在训练完一个模型后就有现成的测试数据，事情会简单得多。然而，这在现实世界中很难实现。因此，数据科学家使用重采样技术从原始数据集制作他们自己的测试数据。</p><p id="89a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这样做的一种方式是通过<em class="lv">从拟合过程中获得</em>训练数据的一部分或子集，然后根据获得的数据估计模型的性能。这种方法被称为<em class="lv">验证集方法。</em></p><p id="ab9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在该方法中，原始数据集被随机分为训练集和<em class="lv">验证集(保留集)。</em>该模型适用于训练集，然后用于预测验证集的结果。最终的评估是在验证集上完成的，在这种情况下，它就像一个测试数据集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/7e8be7e51482dd4be5e12d40e479e5ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*Kfj47Ag0GZEMCP8r0DgwvA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">观察值分为训练集和验证集。图片由<a class="mv mw ep" href="https://medium.com/u/db3258338f2f?source=post_page-----622d5a962231--------------------------------" rel="noopener" target="_blank"> Sangeet Aggarwal </a>提供</p></figure><p id="b917" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图描述了如何将观察分为训练集和验证集的示例。验证集是随机抽取的，其大小取决于用户的选择。例如，我可以将验证集选择为原始集的 40%，或者任何其他分数或百分比值。选择时通常要考虑要分割的数据的大小。</p><p id="2022" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在实践中，可能需要迭代地(重复地)进行这种划分，以便在不同的样本上拟合相同的模型，并在不同的验证集上对其进行评估。然而，减少训练集的大小并不总是可取的，因为已知当在更少的观察值上训练时，统计方法表现更差。这需要一种特殊类型的交叉验证技术→ <em class="lv">留一交叉验证(LOOCV) </em>。</p><h2 id="23ef" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">留一法交叉验证(LOOCV)</h2><p id="3a90" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated"><em class="lv"> LOOCV 是交叉验证的例子，其中只有一个观察结果被提出来验证。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/047b3bb2965430ab28626dc7606922dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*1B3ie-T1s9s6OUWNfhJJlw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">留一交叉验证。<strong class="bd my">绿色:</strong>原始数据。<strong class="bd my">紫色:</strong>训练集。<strong class="bd my">橙色:</strong>单一验证点。图片由<a class="mv mw ep" href="https://medium.com/u/db3258338f2f?source=post_page-----622d5a962231--------------------------------" rel="noopener" target="_blank"> Sangeet Aggarwal </a></p></figure><p id="315b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对每个保留的观察值评估模型。然后，通过取所有单个评估的平均值来计算最终结果。</p><p id="05ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种技术解决了使用小训练集的缺点，如在一般验证集方法中所见，因为模型适合于几乎所有的训练样本(n-1 个观察)。然而，LOOCV 有两个问题。</p><ol class=""><li id="176b" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">使用 LOOCV 在计算上可能是昂贵的，尤其是如果数据量很大，并且如果模型仅需要花费大量时间来完成一次学习。这是因为我们在整个训练集上迭代拟合模型。</li><li id="c0fa" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">LOOCV 的另一个问题是，它可能会受到高方差或过度拟合的影响，因为我们向模型提供了几乎所有要学习的训练数据，而只提供了一个要评估的观察值。</li></ol><p id="8483" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些问题可以通过使用另一种被称为 k-Fold 交叉验证的验证技术来解决。</p><h2 id="7c1d" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">k 倍交叉验证</h2><p id="383a" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated"><em class="lv">这种方法包括将数据随机分成 k 个大致相等的折叠或组。然后，这些折叠中的每一个都被视为 k 次不同迭代中的验证集。</em></p><p id="831a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设 k 的值是 5，那么 k 倍 CV 可以形象化如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/bacd9e5ee98831132a2fb48f6e388322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*WRnieQkvXt0rHtjxaleDBg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">k=5 的 k 倍交叉验证。图片由<a class="mv mw ep" href="https://medium.com/u/db3258338f2f?source=post_page-----622d5a962231--------------------------------" rel="noopener" target="_blank"> Sangeet Aggarwal </a>提供</p></figure><p id="070e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如图所示，选择 5 个折叠或组作为验证集，而其余数据用于训练模型。</p><p id="2ada" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法解决了 LOOCV 的缺点，因为它只需要第<em class="lv">k-</em><em class="lv"/>部分数据进行验证，从而允许模型在大量观察值上进行训练。与 LOOCV 相比，它还减少了计算开销，因为迭代次数现在从<em class="lv"> n </em>(其中 k &lt; &lt; n)减少到<em class="lv"> k </em>。</p><blockquote class="no np nq"><p id="c4d0" class="kz la lv lb b lc ld ju le lf lg jx lh nr lj lk ll ns ln lo lp nt lr ls lt lu im bi translated">LOOCV 是 k 倍交叉验证的一个特例，其中 k 等于数据的大小(n)。</p></blockquote><p id="c921" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 LOOCV 上使用 k 倍交叉验证是<a class="ae ky" rel="noopener" target="_blank" href="/bias-variance-tradeoff-7ca56ba182a?source=---------5------------------">偏差-方差权衡</a>的一个例子。它减少了 LOOCV 显示的方差，并通过提供一个相当大的验证集引入了一些偏差。</p><p id="712a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个帖子到此为止。我希望你在学习交叉验证的过程中过得愉快。欲知详情，敬请关注。</p></div></div>    
</body>
</html>