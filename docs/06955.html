<html>
<head>
<title>Exchange Rate Prediction: Machine Learning with 5 Regression Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">汇率预测:具有5个回归模型的机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exchange-rate-prediction-machine-learning-with-5-regression-models-d7a3192531d?source=collection_archive---------17-----------------------#2020-05-29">https://towardsdatascience.com/exchange-rate-prediction-machine-learning-with-5-regression-models-d7a3192531d?source=collection_archive---------17-----------------------#2020-05-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6221" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在数据清理和可视化之后，这一部分使用机器学习来寻找适合所有数据点的最佳直线，为最终部分的预测做准备。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f852d208016ff7ba61795e57fffda0fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nO79OeVwblOJkr6XyupheA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:https://unsplash.com/photos/7JoXNRbx6Qg</p></figure><p id="20fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你错过了我的<strong class="ky ir">第一部分</strong>关于汇率预测的端到端项目，请随时查看这里的<a class="ae kv" href="https://medium.com/analytics-vidhya/exchange-rate-prediction-part-1-276b6cd5338" rel="noopener"><strong class="ky ir"/></a><strong class="ky ir">。</strong></p><p id="cf6e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">概括地说，该项目旨在分析不同国家货币对美元汇率的历史模式，从而预测2020年的汇率值。为了得到最好的模型，我把这个项目分成了三个部分，我希望这三个部分能够涵盖预测所需的内容:</p><ol class=""><li id="c23e" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">第1部分</strong>:解释性数据分析(EDA) &amp;数据可视化(奖励:假设检验)</li><li id="91c7" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">第二部分:具有4个回归模型的机器学习</strong></li><li id="7bd6" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">第三部分:机器学习(续)与ARIMA</li></ol><p id="8e5c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">今天，我将带你看第二部分，它部署了机器学习，目的是<strong class="ky ir">找到最适合</strong>多年来汇率模式的线。也就是说，线性回归似乎是正确的模型，或者至少是我们分析的基础。除此之外，在决定使用哪个模型进行预测之前，我还测试了其他线性回归模型(第3部分):</p><ul class=""><li id="2201" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mg ly lz ma bi translated">线性回归</li><li id="2bfa" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">多元线性回归</li><li id="2c0d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">多项式回归</li><li id="7aaf" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">岭回归(L2正则化)</li><li id="ac9c" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">拉索回归(L1正则化)</li></ul><p id="fc3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们开始吧！</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="7b9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据Investopedia，有3种预测汇率的常用方法:购买力平价(PPP)、相对经济实力和计量经济模型。在这三种方法中，我决定选择第三种，因为它涉及到影响汇率变动的众多因素。</p><div class="mo mp gp gr mq mr"><a href="https://www.investopedia.com/articles/forex/11/4-ways-to-forecast-exchange-rates.asp" rel="noopener  ugc nofollow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd ir gy z fp mw fr fs mx fu fw ip bi translated">学习预测货币汇率的三种常用方法</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">使用货币汇率预测可以帮助经纪人和企业做出明智的决策，以帮助最小化风险…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">www.investopedia.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf kp mr"/></div></div></a></div><blockquote class="ng nh ni"><p id="00fe" class="kw kx nj ky b kz la jr lb lc ld ju le nk lg lh li nl lk ll lm nm lo lp lq lr ij bi translated">“计量经济模型中使用的因素通常基于经济理论，但任何变量<strong class="ky ir"/><strong class="ky ir">都可以加上</strong>，如果<strong class="ky ir">认为它会显著影响</strong>汇率。”——Investopedia，作者Joseph Nguyen。</p></blockquote><p id="9d65" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法与使用“任何独立变量”对因变量产生影响的方向——线性回归非常一致。因此，我想测试的因素是<strong class="ky ir">利率差</strong>、<strong class="ky ir"> GDP增长率</strong>和<strong class="ky ir">收入增长率</strong>，顺序但累积。对于这个项目，我使用澳元/美元的汇率进行分析。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h1 id="86de" class="nn no iq bd np nq nr ns nt nu nv nw nx jw ny jx nz jz oa ka ob kc oc kd od oe bi translated">1.线性回归</h1><p id="5f69" class="pw-post-body-paragraph kw kx iq ky b kz of jr lb lc og ju le lf oh lh li lj oi ll lm ln oj lp lq lr ij bi translated">让我们以一个独立变量开始我们的线性回归模型:<strong class="ky ir">利率差</strong>。如果你热衷于探索，可以参考这个<a class="ae kv" href="https://forexop.com/swaps/AUDUSD/" rel="noopener ugc nofollow" target="_blank">数据来源</a>。</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="5165" class="op no iq ol b gy oq or l os ot">ir_df = pd.read_csv("aud usd interest carry trade.csv")<br/>ir_df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/e10d04facabffcd68c8f0cdc59bf5d74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*ToYzrypGkouFCCKEClM0og.png"/></div></figure><p id="1add" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以上是2017-2019年澳元/美元利率差表。如果你想更多地了解什么是“多头套利”和“空头套利”，可以查看Investopedia上关于<a class="ae kv" href="https://www.investopedia.com/terms/c/currencycarrytrade.asp" rel="noopener ugc nofollow" target="_blank">套利交易</a>的这篇文章，以及FXCM上关于<a class="ae kv" href="https://www.fxcm.com/markets/insights/interest-rate-carry-trades/" rel="noopener ugc nofollow" target="_blank">利率套利交易</a>的另一篇文章。简言之，</p><blockquote class="ng nh ni"><p id="8636" class="kw kx nj ky b kz la jr lb lc ld ju le nk lg lh li nl lk ll lm nm lo lp lq lr ij bi translated">利率套利交易是一种套利形式，其中有人利用两个市场之间的差异来获利。</p></blockquote><p id="7b28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，让我们转换这些数据进行分析(在这种情况下，我使用长期套利利率):</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="3775" class="op no iq ol b gy oq or l os ot">x_ir = ir_df['Long Carry'].astype(str)<br/>x_ir = x_ir.replace({'%':''}, regex = True)<br/>x_ir = x_ir.astype(float)<br/>x_ir = np.array(x_ir).reshape(-1,1)</span><span id="3a91" class="op no iq ol b gy ov or l os ot">aud_usd_fx = df_groupby_aud[(df_groupby_aud['month_year'] &gt;= '2017-01') &amp; (df_groupby_aud['month_year'] &lt;='2019-12')].reset_index(drop=True)<br/>aud_usd = aud_usd_fx['AUD_USD']</span><span id="0fc7" class="op no iq ol b gy ov or l os ot">y_fx = aud_usd</span></pre><p id="d526" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，<strong class="ky ir"> x_ir </strong>是指影响我们汇率的自变量。为了更容易使用，我用<strong class="ky ir"> regex替换</strong>去掉了数字中的“%”，并将它们转换为float。由于回归模型中需要2D阵列数据，我们需要使用<strong class="ky ir">将我们的1D x_ir转换为2D。整形(-1，1)。</strong>如果您还记得第一部分，我们已经清理了整个数据集，因此现在我们可以更容易地选择澳元/美元数据(y_fx)作为因变量。</p><p id="1cd5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，为了简单起见，我在这个项目中只用了很短的一段时间(从2017年到2019年，36个月)。</p><p id="37f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好了，让我们通过从<strong class="ky ir"> Scikit-learn </strong>库中导入<strong class="ky ir"> </strong>相关函数来运行我们的第一个机器学习模型！</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="9921" class="op no iq ol b gy oq or l os ot">from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LinearRegression</span></pre><p id="37e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可能已经知道，为了测试我们模型的准确性，我们被建议将数据集分成训练集和测试集。本质上，我们在训练集上训练模型，然后用测试集预测值。</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="65e8" class="op no iq ol b gy oq or l os ot">x_train, x_test, y_train, y_test = train_test_split(x_ir, y_fx, train_size=0.8, test_size=0.2, random_state=1)</span><span id="1d77" class="op no iq ol b gy ov or l os ot">model = LinearRegression()<br/>model.fit(x_train, y_train)<br/>y_predict = model.predict(x_test)</span><span id="58af" class="op no iq ol b gy ov or l os ot">print(model.score(x_train, y_train))<br/>print(model.score(x_test, y_test))</span></pre><p id="d9e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我把数据拆分成80%的训练和20%的测试，意思是模型会通过80%的训练数据学习模式，然后用20%的测试数据预测y值。<strong class="ky ir">。score() </strong>告诉我们因变量(汇率)被自变量(利率差)或我们所知的<strong class="ky ir"> R平方</strong>解释的百分比。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/ead22e0bfa4111f4631ba3c60ab6f06c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pkczz9rEnsJb-EijeFG2BA.png"/></div></div></figure><p id="b26f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如您所见，训练和测试数据之间的百分比非常接近，这意味着模型的准确性相对较好。</p><p id="25b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，根据我的观察，数据集的大小相对较小(n=36，因为我们只覆盖2017年到2019年)，为了简单起见，我想看看我是否能够不将数据分成训练集和测试集。</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="dc4f" class="op no iq ol b gy oq or l os ot">model = LinearRegression()<br/>model.fit(x_ir, y_fx)<br/>y_fx_predict = model.predict(x_ir)</span><span id="9d7f" class="op no iq ol b gy ov or l os ot">print(model.score(x_ir, y_fx))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/1d0314577fbfb512d5273ddd9b573c6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V8kDME6N1bMwHBz63XEL2g.png"/></div></div></figure><p id="a7e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分割和不分割之间的R平方差异极小，这可能是由于数据集较小。因此，我将<strong class="ky ir">而不是</strong>分割数据并使用整个数据集。</p><p id="c64d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看我们的模型在创建“最佳拟合”线方面表现如何:</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="1a5b" class="op no iq ol b gy oq or l os ot">month_year = aud_usd_fx['month_year']<br/>month_year = month_year.astype(str)</span><span id="20e0" class="op no iq ol b gy ov or l os ot">plt.figure(figsize=(12,6))<br/>plt.scatter(month_year, y_fx, alpha=0.4)<br/>plt.plot(month_year, y_fx_predict)<br/>plt.title("Linear Regression: AUD/USD Exchange Rate (1 var: Interest Rate)")<br/>plt.xlabel("Month-Year")<br/>plt.ylabel("Exchange Rate")<br/>plt.xticks(fontsize=4)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/8fc357c70b9ce436ecdcb96a4929536b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fDSCqGjgtixIs_6a7vCtKg.png"/></div></div></figure><p id="77a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结合R平方，该线似乎可以在一定程度上刻画汇率(R平方为72%)。让我们添加另一个变量，用多元线性回归来看看我们的R平方提高了多少。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h1 id="e292" class="nn no iq bd np nq nr ns nt nu nv nw nx jw ny jx nz jz oa ka ob kc oc kd od oe bi translated">2.多元线性回归</h1><p id="f8d7" class="pw-post-body-paragraph kw kx iq ky b kz of jr lb lc og ju le lf oh lh li lj oi ll lm ln oj lp lq lr ij bi translated">正如本文开头所分享的，我们能够向模型中添加额外的变量，只要它们对因变量有影响。这就引出了第二个线性回归模型，它包含<strong class="ky ir">多于1个自变量</strong>。</p><p id="f379" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们把<strong class="ky ir"> GDP增长率</strong>加到我们的数据集中，可以从<a class="ae kv" href="https://fred.stlouisfed.org/" rel="noopener ugc nofollow" target="_blank">这个域</a>找到。</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="9ed9" class="op no iq ol b gy oq or l os ot">aus_gdp = pd.read_csv("AUS GDP.csv")<br/>usa_gdp = pd.read_csv("USA GDP.csv")</span><span id="47fe" class="op no iq ol b gy ov or l os ot">aus_gdp = aus_gdp.rename(columns={'GDP': 'AUS_GDP'})<br/>aus_usa_gdp = pd.merge(aus_gdp, usa_gdp, on="month_year", how="inner")<br/>aus_usa_gdp = aus_usa_gdp.rename(columns={'GDP': 'USA_GDP'})<br/>aus_usa_gdp['GDP_diff'] = aus_usa_gdp['AUS_GDP'] - aus_usa_gdp['USA_GDP']</span><span id="e16f" class="op no iq ol b gy ov or l os ot">aus_usa_gdp_20172019 = aus_usa_gdp[(aus_usa_gdp['month_year'] &gt;= '2017-01') &amp; (aus_usa_gdp['month_year'] &lt;='2019-12')].reset_index(drop=True)</span><span id="02d6" class="op no iq ol b gy ov or l os ot">gdp_diff = ["%.4f" %num for num in aus_usa_gdp_20172019['GDP_diff']]</span></pre><p id="0171" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">加载完数据后，我应用EDA进行清理，将数据帧中的<strong class="ky ir"> gdp_diff </strong>提取到一个列表中，以便与<strong class="ky ir"> x_ir </strong>变量结合起来进行多元线性回归。</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="181c" class="op no iq ol b gy oq or l os ot">x_ir_gdp = np.array(list(zip(x_ir, gdp_diff)))<br/>x_ir_gdp = x_ir_gdp.astype(np.float)</span><span id="fe8a" class="op no iq ol b gy ov or l os ot">model.fit(x_ir_gdp, y_fx)<br/>y_fx_predict_2 = model.predict(x_ir_gdp)</span><span id="85c8" class="op no iq ol b gy ov or l os ot">print(model.score(x_ir_gdp, y_fx))</span></pre><p id="1680" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在模型中加入另一个变量后，R平方有了相当显著的提高，从72%提高到87.2%。让我们直观地将其与我们创建的第一行进行比较:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/bef2d9dbb8cc564e3840319323f7c04c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zujdHWj4ivYFyGv29BUNbw.png"/></div></div></figure><p id="b130" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">看起来不错，对！好吧，让我们尝试向我们的模型添加另一个独立变量，<strong class="ky ir">消费者价格指数(CPI)。</strong>同样，数据集可以从<a class="ae kv" href="https://fred.stlouisfed.org/" rel="noopener ugc nofollow" target="_blank">这个域</a>中找到。</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="53ef" class="op no iq ol b gy oq or l os ot">cpi = pd.read_csv("aus usa cpi difference.csv")</span><span id="1cac" class="op no iq ol b gy ov or l os ot">cpi_diff = cpi['CPI_diff']</span><span id="e85b" class="op no iq ol b gy ov or l os ot">x_ir_gdp_cpi = np.array(list(zip(x_ir, gdp_diff, cpi_diff)))<br/>x_ir_gdp_cpi = x_ir_gdp_cpi.astype(np.float)</span><span id="03a3" class="op no iq ol b gy ov or l os ot">model.fit(x_ir_gdp_cpi, y_fx)<br/>y_fx_predict_4 = model.predict(x_ir_gdp_cpi)</span><span id="7b8d" class="op no iq ol b gy ov or l os ot">print(model.score(x_ir_gdp_cpi, y_fx))</span></pre><p id="a2cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这一次，R平方确实略有增加，从87.2%增加到87.3%。这意味着CPI不会显著影响汇率的变动，也不会有助于改进我们的模型。视觉上，也没什么区别。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/acc2ad95c6130939fdb88a747018c1c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D961H4RCVX1naDmb4ibVVw.png"/></div></div></figure><p id="c3af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们用另一个变量——失业率(UER)代替CPI变量，看看这是否能改进我们的模型。</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="403b" class="op no iq ol b gy oq or l os ot">unemployment_rate = pd.read_csv("aus usa unemployment rate.csv")</span><span id="bede" class="op no iq ol b gy ov or l os ot">unemployment_rate['uer_diff'] = unemployment_rate['aus_unemployment rate'] - unemployment_rate['usa_unemployment rate']<br/>uer_diff_all = unemployment_rate['uer_diff']</span><span id="5836" class="op no iq ol b gy ov or l os ot">uer_diff = ["%.4f" % num for num in uer_diff_all]</span><span id="8b0b" class="op no iq ol b gy ov or l os ot">x_ir_gdp_uer = np.array(list(zip(x_ir, gdp_diff, uer_diff)))<br/>x_ir_gdp_uer = x_ir_gdp_uer.astype(np.float)</span><span id="5ac7" class="op no iq ol b gy ov or l os ot">model.fit(x_ir_gdp_uer, y_fx)<br/>y_fx_predict_3 = model.predict(x_ir_gdp_uer)</span><span id="b180" class="op no iq ol b gy ov or l os ot">print(model.score(x_ir_gdp_uer, y_fx))</span></pre><p id="da43" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好的，R平方提高了一点，从87.2%提高到88.9%。从统计和视觉上看，还不错。您可以继续向模型中添加更多的变量，但要小心<strong class="ky ir">过度拟合</strong>！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/678df75c873fd952b19fff42390ee532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eP2ddK3o8lCJyIQWXZ2xUw.png"/></div></div></figure></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="2d40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对我来说，我没有添加更多的自变量，而是决定测试另一个回归模型来找到更好的拟合线:多项式回归。</p><h1 id="cb37" class="nn no iq bd np nq pc ns nt nu pd nw nx jw pe jx nz jz pf ka ob kc pg kd od oe bi translated">3.多项式回归</h1><p id="e762" class="pw-post-body-paragraph kw kx iq ky b kz of jr lb lc og ju le lf oh lh li lj oi ll lm ln oj lp lq lr ij bi translated">什么是多项式回归？它仍然是一种线性回归，但是是一个更“适应”的版本。</p><p id="0305" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">传统上，线性回归旨在找到适合所有数据点的最佳线性线，但情况可能并不总是如此。因此，多项式回归充当从坐标(x，y)绘制直线的另一种形式，将<strong class="ky ir"> <em class="nj"> y建模为n次多项式</em> </strong>。</p><p id="5c91" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们从Sciki-learn库中导入函数并构建我们的模型:</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="a93b" class="op no iq ol b gy oq or l os ot">from sklearn.preprocessing import PolynomialFeatures</span><span id="9a3c" class="op no iq ol b gy ov or l os ot">poly = PolynomialFeatures(degree=4)</span><span id="2ce7" class="op no iq ol b gy ov or l os ot">x_poly = poly.fit_transform(x_ir_gdp_uer)</span><span id="8156" class="op no iq ol b gy ov or l os ot">model_poly = LinearRegression()<br/>model_poly.fit(x_poly, y_fx)<br/>y_pred = model_poly.predict(x_poly)</span><span id="b46e" class="op no iq ol b gy ov or l os ot">print(model_poly.score(x_poly, y_fx))</span></pre><p id="b1db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">线性回归和多项式回归在函数上的唯一区别是<strong class="ky ir">次数</strong>参数。在得出结果之前，我先简单说明一下:<strong class="ky ir">。fit_transform() </strong>就是把你的自变量从线性转换成多项式。函数的其余部分保持不变。</p><p id="45c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我随机选择了4和R的平方接近完美的程度:99.9%！你可能想直观地看到它？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ph"><img src="../Images/ec8698a0babe04bf4d2a015f75a926e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z_HqHGFmTa1DxyDSa-9MaA.png"/></div></div></figure><p id="8217" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">黑线表示多项式回归找到的拟合度为4。有多神奇？但问题是:“哪个程度是最好的，既不会过拟合也不会欠拟合数据？”</p><p id="9a34" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们知道我们的目标是找到尽可能高的R平方，因为它很好地解释了因变量(汇率)受自变量影响的事实。除此之外，还有另一个指标能够评估我们模型的准确性:<strong class="ky ir">均方误差(MSE)。</strong></p><p id="7688" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了找到最佳的度数，我决定在我们的模型上分别用<strong class="ky ir"> a for loop </strong>测试一个度数范围，从1到10，并将其可视化:</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="faaa" class="op no iq ol b gy oq or l os ot">from sklearn.metrics import mean_squared_error</span><span id="a318" class="op no iq ol b gy ov or l os ot">r_squared_list = []<br/>mse_list = []<br/>a = range(1,10,1)</span><span id="8d7d" class="op no iq ol b gy ov or l os ot">for i in a:<br/>    poly = PolynomialFeatures(degree=i)<br/>    x_poly = poly.fit_transform(x_ir_gdp_uer)<br/>    <br/>    model_poly = LinearRegression()<br/>    model_poly.fit(x_poly, y_fx)<br/>    y_pred = model_poly.predict(x_poly)<br/>    <br/>    r_squared = model_poly.score(x_poly, y_fx)<br/>    mse = mean_squared_error(y_pred, y_fx)<br/>    <br/>    r_squared_list.append(r_squared)<br/>    mse_list.append(mse)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pi"><img src="../Images/907b3cdbd4f835325fc880b2b8839245.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ysbJvtai3OaV7tZGcJjq_Q.png"/></div></div></figure><p id="0dad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如您在两个图表中看到的，随着直线从1度增加到4度，R平方和MSE显著提高(R平方越高越好，MSE越低越好)。然而，它在4度时达到峰值，并且从5度开始没有看到进一步的改善。这意味着4度为我们的模型带来了最好的准确度分数！所以我们还是坚持用4吧！</p><p id="414c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">耶！多亏了多项式回归，我们终于得到了最符合历年汇率的直线！</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h1 id="fa95" class="nn no iq bd np nq nr ns nt nu nv nw nx jw ny jx nz jz oa ka ob kc oc kd od oe bi translated">4.&amp; 5.岭回归和套索回归</h1><p id="a082" class="pw-post-body-paragraph kw kx iq ky b kz of jr lb lc og ju le lf oh lh li lj oi ll lm ln oj lp lq lr ij bi translated">这最后两个是我在线性回归模型的“生态系统”中的最新实验，我以前在某个地方听说过。哦，是的，它关系到L1和L2的正规化！因此，我想在我的项目中测试这两个模型，看看它们与上述模型相比表现如何。</p><p id="fc10" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，在进入它们之前，让我们快速指出这些模型的起源，<strong class="ky ir">正则化</strong>，以及它们在我们通常所知的线性回归中扮演的角色。</p><p id="c6b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这一切都是从<strong class="ky ir">超配</strong>开始的。简而言之，当机器学习模型过于适合某个数据集(特别是有太多独立变量/特征)并因此无法推广到其他数据集时，就会发生过度拟合。因此，引入了<strong class="ky ir">规则</strong>来防止这种现象。本质上，规范化的作用是:</p><ul class=""><li id="28ee" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mg ly lz ma bi translated">降低模型的复杂性，同时保持独立变量/特征的数量</li><li id="6f07" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated">从技术上讲，减少系数的大小作为损失函数的惩罚项</li></ul><p id="cd1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想深入了解它是如何工作的，从数学上来说，查看这篇关于<a class="ae kv" rel="noopener" target="_blank" href="/intuitions-on-l1-and-l2-regularisation-235f2db4c261">走向数据科学</a>的文章，了解更多细节。</p><p id="7c61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">岭回归和套索回归就是从这种正则化概念发展而来的。两者的唯一区别是:</p><ul class=""><li id="5b7a" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mg ly lz ma bi translated"><strong class="ky ir">岭回归</strong>使用L2正则化技术，将系数缩小到零，但<strong class="ky ir">不是绝对零</strong></li><li id="13ee" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mg ly lz ma bi translated"><strong class="ky ir">套索回归</strong>使用L1正则化技术，将系数缩小到<strong class="ky ir">绝对零</strong></li></ul><p id="93ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是因为Ridge保留了所有变量/特征<strong class="ky ir"> <em class="nj">，而</em> </strong> Lasso只保留了重要的变量/特征，因此当我们的数据集有太多变量/特征时，它被选为变量/特征选择技术。</p><p id="6310" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好了，回到我们的数据集！</p><p id="079b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管我们的模型没有太多的变量(在本例中是3)，我仍然想看看岭和套索回归在我的数据集上的表现。</p><pre class="kg kh ki kj gt ok ol om on aw oo bi"><span id="4c32" class="op no iq ol b gy oq or l os ot">from sklearn.linear_model import Ridge, Lasso</span><span id="2a46" class="op no iq ol b gy ov or l os ot">ridge = Ridge(alpha=0.001)<br/>ridge.fit(x_ir_gdp_uer, y_fx)</span><span id="d591" class="op no iq ol b gy ov or l os ot">y_fx_ridge = ridge.predict(x_ir_gdp_uer)<br/>print(ridge.score(x_ir_gdp_uer, y_fx))</span><span id="8cfe" class="op no iq ol b gy ov or l os ot">lasso = Lasso(alpha=0.001)<br/>lasso.fit(x_ir_gdp_uer, y_fx)</span><span id="b215" class="op no iq ol b gy ov or l os ot">y_fx_lasso = lasso.predict(x_ir_gdp_uer)<br/>print(lasso.score(x_ir_gdp_uer, y_fx))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ph"><img src="../Images/2ae67e91ebbe9b8f10daf14de3d400fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mwa17SGtblMLrEyfw6Lg2A.png"/></div></div></figure><p id="793f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">山脊的r平方是88%，而套索是87%。当我们将这些数字与我们的多元线性回归(88.9%)进行比较时，还不算太坏。这证明我们的模型没有出现过拟合！</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="29ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">哇！这是这个项目第二部分的总结！吸收太多了，不是吗？但是我真的希望你已经发现这篇文章的信息和可操作性。</p><p id="2d11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简而言之，我们已经<strong class="ky ir">找到了最符合我们的数据集</strong>的直线，极大地解释了多年来的汇率模式！下一步是什么？</p><p id="22e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">再次提醒，请注意我项目的最后一部分<strong class="ky ir"/>,它将涵盖<strong class="ky ir">我如何使用我们刚刚发现的回归线预测2020年</strong>的汇率。与此同时，如果您觉得这有帮助，请给我一个掌声，并在这里随意查看我的Github以获得完整的资源库:</p><p id="8f21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">github:<a class="ae kv" href="https://github.com/andrewnguyen07" rel="noopener ugc nofollow" target="_blank">https://github.com/andrewnguyen07</a>T2】LinkedIn:<a class="ae kv" href="http://www.linkedin.com/in/andrewnguyen07" rel="noopener ugc nofollow" target="_blank">www.linkedin.com/in/andrewnguyen07</a></p><p id="b739" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">谢谢！</p></div></div>    
</body>
</html>