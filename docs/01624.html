<html>
<head>
<title>Building A Custom Model in Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Scikit-Learn 中构建定制模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-custom-model-in-scikit-learn-b0da965a1299?source=collection_archive---------11-----------------------#2020-02-14">https://towardsdatascience.com/building-a-custom-model-in-scikit-learn-b0da965a1299?source=collection_archive---------11-----------------------#2020-02-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/></div><div class="ab cl jq jr hx js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="im in io ip iq"><p id="938d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">Scikit-Learn 令人难以置信。它允许其用户适应你能想到的几乎任何机器学习模型，加上许多你可能从未听说过的模型！所有这一切只需要两行代码！</p><p id="c21c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">然而，它没有<em class="kv">一切</em>。例如，有序回归无处可寻。而且它的深度学习能力……欠缺。但是谁在乎呢？你可以在其他地方找到这些东西，对吗？</p><p id="f652" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">没错。但是！Scikit-Learn 不仅仅是建模。还有一些非常棒的工具可以帮助你简化建模过程，比如<code class="fe kw kx ky kz b">GridSearchCV</code>和<code class="fe kw kx ky kz b">Pipeline</code>。这些工具是非常宝贵的，但它们只适用于 Scikit-Learn 模型。事实证明，如果 Scikit-Learn 和我们的 Google 霸主不直接给我们，<strong class="jz iu">我们可以制作我们自己的定制 Scikit-Learn 兼容模型！</strong>而且比你想象的要简单！</p><p id="62cc" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在这篇文章中，我将构建 Scikit-Learn 中明显缺失的东西:使用<em class="kv"> k </em>的能力——意味着在<code class="fe kw kx ky kz b">Pipeline</code>中进行<em class="kv">迁移学习</em>。也就是说，将聚类的结果输入到监督学习模型中，以便找到最佳值<em class="kv"> k </em>。</p><h1 id="51ab" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">警告:前方 OOP！</h1><p id="a73f" class="pw-post-body-paragraph jx jy it jz b ka ly kc kd ke lz kg kh ki ma kk kl km mb ko kp kq mc ks kt ku im bi translated">这篇文章会有点技术性。具体来说，我将假设您具有面向对象编程(OOP)的工作知识。也就是说，你知道如何以及为什么使用<code class="fe kw kx ky kz b">class</code> Python 关键字。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi md"><img src="../Images/8689385b33265b626919ea044e882929.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*W5iKFg1brCGD0CiZNZg3xg.jpeg"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">你必须有这么多<code class="fe kw kx ky kz b">class</code>才能继续。</p></figure><h1 id="4f41" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">Scikit-Learn 模板</h1><p id="8d3d" class="pw-post-body-paragraph jx jy it jz b ka ly kc kd ke lz kg kh ki ma kk kl km mb ko kp kq mc ks kt ku im bi translated">Scikit-Learn 最棒的一点是它令人难以置信的一致性。拟合一种类型的模型名义上与拟合任何其他类型的模型是一样的。也就是说，在 Scikit-Learn 中建模非常简单:</p><pre class="me mf mg mh gt mp kz mq mr aw ms bi"><span id="a74f" class="mt lb it kz b gy mu mv l mw mx">model = MyModel(parameters)<br/>model.fit(X, y)</span></pre><p id="f1a3" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">就是这样！您现在可以分析您的模型了，可能是在模型的<code class="fe kw kx ky kz b">.predict()</code>和<code class="fe kw kx ky kz b">.score()</code>方法的帮助下。事实上，每个 Scikit-Learn 估计器都保证有 5 种方法:</p><ul class=""><li id="6505" class="my mz it jz b ka kb ke kf ki na km nb kq nc ku nd ne nf ng bi translated"><code class="fe kw kx ky kz b">.fit()</code></li><li id="c6ef" class="my mz it jz b ka nh ke ni ki nj km nk kq nl ku nd ne nf ng bi translated"><code class="fe kw kx ky kz b">.predict()</code></li><li id="f6c9" class="my mz it jz b ka nh ke ni ki nj km nk kq nl ku nd ne nf ng bi translated"><code class="fe kw kx ky kz b">.score()</code></li><li id="7586" class="my mz it jz b ka nh ke ni ki nj km nk kq nl ku nd ne nf ng bi translated"><code class="fe kw kx ky kz b">.set_params()</code></li><li id="99fe" class="my mz it jz b ka nh ke ni ki nj km nk kq nl ku nd ne nf ng bi translated"><code class="fe kw kx ky kz b">.get_params()</code></li></ul><h1 id="2e67" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">构建您自己的</h1><p id="b07a" class="pw-post-body-paragraph jx jy it jz b ka ly kc kd ke lz kg kh ki ma kk kl km mb ko kp kq mc ks kt ku im bi translated">为了构建我们自己的模型，我们只需要构造一个具有上述 5 种方法的类，并以“通常的方式”实现它们。听起来工作量很大。幸运的是，Scikit-Learn 为我们做了艰苦的工作。为了构建我们自己的模型，我们可以从 Scikit-Learn 内置的基类中继承。</p><h1 id="55db" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">旁白:继承</h1><p id="fc00" class="pw-post-body-paragraph jx jy it jz b ka ly kc kd ke lz kg kh ki ma kk kl km mb ko kp kq mc ks kt ku im bi translated">在 OOP 中，如果我们指定一个类<strong class="jz iu">从另一个继承</strong>，那么“子类”将获得“超类”的所有方法</p><p id="997d" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">继承的语法如下所示:</p><pre class="me mf mg mh gt mp kz mq mr aw ms bi"><span id="3803" class="mt lb it kz b gy mu mv l mw mx">class Car(Vehicle):<br/>    # stuff...</span></pre><p id="0b93" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">汽车是一种交通工具。<code class="fe kw kx ky kz b">Car</code>类将包括<code class="fe kw kx ky kz b">Vehicle</code>类的每一个方法，加上更多我们可以在<code class="fe kw kx ky kz b">Car</code>类定义中定义的方法。</p><h1 id="81db" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">Scikit-Learn 给了我们什么？</h1><p id="9c25" class="pw-post-body-paragraph jx jy it jz b ka ly kc kd ke lz kg kh ki ma kk kl km mb ko kp kq mc ks kt ku im bi translated">为了符合 Scikit-Learn，我们的模型需要从一些 mixin 继承。mixin 只是一个从未打算独立工作的类，相反，它只是包含了许多可以通过继承添加到当前类中的方法。Scikit-Learn 为每一种通用类型的模型提供了一个模型:<code class="fe kw kx ky kz b">RegressorMixin</code>、<code class="fe kw kx ky kz b">ClassifierMixin</code>、<code class="fe kw kx ky kz b">ClusterMixin</code>、<code class="fe kw kx ky kz b">TransformerMixin</code>，以及其他几个我们不需要担心的模型。</p><p id="aa46" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们想要自己创造的一切，都是通过简单地超越我们所继承的来实现的！</p><p id="c4ee" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这是一个口无遮拦的例子。首先，一个简单的例子。之后，使用聚类的动机示例。</p><h1 id="bd23" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">示例 1:空模型</h1><p id="c4bd" class="pw-post-body-paragraph jx jy it jz b ka ly kc kd ke lz kg kh ki ma kk kl km mb ko kp kq mc ks kt ku im bi translated">零模型，有时称为“基线”模型，是除了随机猜测之外没有任何信息的模型。例如，回归问题的零模型将只是取训练数据的平均值<em class="kv"> y </em>并将其用作每个预测。对于分类，它只是对每个预测取多数类。例如，如果你不得不预测某人是否会赢得彩票，零模型将指示你总是输，因为这是最有可能的结果。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/86d62357d7ab99297169a82a84dc2067.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*KIMEn6E1n9MAh38xN5VjCg.gif"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">事实:这和现实并没有太大的差别。</p></figure><p id="88d2" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">空模型有助于判断当前模型的表现。毕竟，如果你的模型很好，它应该会超过基线。Scikit-Learn 中没有内置 null 模型，但是我们很容易实现它！</p><pre class="me mf mg mh gt mp kz mq mr aw ms bi"><span id="76f0" class="mt lb it kz b gy mu mv l mw mx">import numpy as np<br/>from sklearn.base import RegressorMixin</span><span id="fd48" class="mt lb it kz b gy nn mv l mw mx">class NullRegressor(<em class="kv">RegressorMixin</em>):<br/>    def fit(<em class="kv">self</em>, <em class="kv">X</em>=None, <em class="kv">y</em>=None):<br/>        # The prediction will always just be the mean of y<br/><em class="kv">        self</em>.y_bar_ = np.mean(y)</span><span id="0f97" class="mt lb it kz b gy nn mv l mw mx">    def predict(<em class="kv">self</em>, <em class="kv">X</em>=None):<br/>        # Give back the mean of y, in the same<br/>        # length as the number of X observations<br/>        return np.ones(X.shape[0]) * <em class="kv">self</em>.y_bar_</span></pre><p id="e91f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">很简单！我们现在可以自由地做平常的事情了…</p><pre class="me mf mg mh gt mp kz mq mr aw ms bi"><span id="78e7" class="mt lb it kz b gy mu mv l mw mx">model = NullRegressor()<br/>model.fit(X, y)<br/>model.predict(X)</span></pre><p id="c966" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">重要的是，我们的新<code class="fe kw kx ky kz b">NullRegressor</code>现在兼容 Scikit-Learn 的所有内置工具，如<code class="fe kw kx ky kz b">cross_val_score</code>和<code class="fe kw kx ky kz b">GridSearchCV</code>。</p><h1 id="c317" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">示例 2:使用网格搜索“调优”集群器</h1><p id="1f60" class="pw-post-body-paragraph jx jy it jz b ka ly kc kd ke lz kg kh ki ma kk kl km mb ko kp kq mc ks kt ku im bi translated">这个例子是出于好奇，当一位同事问我是否可以使用<code class="fe kw kx ky kz b">GridSearchCV</code>和<code class="fe kw kx ky kz b">Pipeline</code>来“调整”一个<em class="kv">k</em>-意味着模型。我最初说<em class="kv">不</em>，因为您需要使用 clusterer 作为转换器来传递到您的监督模型中，这是 Scikit-Learn 不允许的。但为什么要让这阻止我们呢？我们刚刚学会了如何黑掉 sci kit——学会做我们想做的任何事情！说白了，本质上我想要的是创建以下管道:</p><pre class="me mf mg mh gt mp kz mq mr aw ms bi"><span id="40ff" class="mt lb it kz b gy mu mv l mw mx">Pipeline([<br/>    ("sc", StandardScaler()),<br/>    ("km", KMeansSomehow()),<br/>    ("lr", LogisticRegression()<br/>])</span></pre><p id="5a60" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">其中<code class="fe kw kx ky kz b">KMeansSomehow()</code>是用作 Scikit-Learn <em class="kv">转换器</em>的群集器。也就是说，它将 onehot 编码的聚类标签附加到数据矩阵<code class="fe kw kx ky kz b">X</code>中，然后传递到我们的模型中。为了让它工作，我们将从定义一个继承自<code class="fe kw kx ky kz b">TransformerMixin</code>的类开始。然后我们会给它适当的<code class="fe kw kx ky kz b">.fit()</code>、<code class="fe kw kx ky kz b">.transform()</code>和<code class="fe kw kx ky kz b">.fit_transform()</code>方法。</p><p id="705f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">但首先，初始化:</p><pre class="me mf mg mh gt mp kz mq mr aw ms bi"><span id="b59f" class="mt lb it kz b gy mu mv l mw mx">from sklearn.base import TransformerMixin<br/>from sklearn.cluster import KMeans</span><span id="50f4" class="mt lb it kz b gy nn mv l mw mx">class KMeansTransformer(TransformerMixin):<br/>    def __init__(self, *args, **args):<br/>        self.model = KMeans(*args, **args)</span></pre><p id="91c7" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><code class="fe kw kx ky kz b">self.model</code>的目的是包含底层集群模型。但是你问什么是<code class="fe kw kx ky kz b">*args</code>和<code class="fe kw kx ky kz b">**kwargs</code>？它们是懒惰的程序员的捷径。它们本质上捕获了您传递给<code class="fe kw kx ky kz b">__init__()</code>的所有其他参数，并将它们传递给<code class="fe kw kx ky kz b">KMeans()</code>。这实质上是我在说“我传递给<code class="fe kw kx ky kz b">KMeansTransformer</code>的任何东西也将传递给<code class="fe kw kx ky kz b">KMeans</code>，我懒得去想那些参数将来会是什么。”</p><p id="2d83" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">接下来，我们需要给它适当的拟合方法:</p><pre class="me mf mg mh gt mp kz mq mr aw ms bi"><span id="abd8" class="mt lb it kz b gy mu mv l mw mx">from self.preprocessing import OneHotEncoder</span><span id="9f19" class="mt lb it kz b gy nn mv l mw mx">class KMeansTransformer(TransformerMixin):<br/>    def __init__(self, *args, **args):<br/>        self.model = KMeans(*args, **args)</span><span id="e72a" class="mt lb it kz b gy nn mv l mw mx">    def fit(self, X):<br/>        self.X = X<br/>        self.model.fit(X)</span><span id="b947" class="mt lb it kz b gy nn mv l mw mx">    def transform(self, X):<br/>        # Need to reshape into a column vector in order to use<br/>        # the onehot encoder.<br/>        cl = self.model.predict(X).reshape(-1, 1)<br/>        <br/>        self.oh = OneHotEncoder(<br/>            categories="auto", <br/>            sparse=False,<br/>            drop="first"<br/>        )</span><span id="4b9d" class="mt lb it kz b gy nn mv l mw mx">        cl_matrix = self.oh.fit_transform(cl)      <br/> <br/>        return np.hstack([self.X, cl_matrix])</span><span id="39b4" class="mt lb it kz b gy nn mv l mw mx">    def fit_transform(self, X, y=None):<br/>        self.fit(X)<br/>        return self.transform(X)</span></pre><p id="9fea" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">应该就是这样了！我们现在可以像使用内置的 Scikit-Learn 转换器一样使用这个<code class="fe kw kx ky kz b">KmeansTransformer</code>。最后，试试这个例子:</p><pre class="me mf mg mh gt mp kz mq mr aw ms bi"><span id="fc57" class="mt lb it kz b gy mu mv l mw mx">from sklearn.preprocessing import StandardScaler<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.datasets import make_blobs</span><span id="cadb" class="mt lb it kz b gy nn mv l mw mx">X, y = make_blobs(<br/>    n_samples=100,<br/>    n_features=2,<br/>    centers=3<br/>)</span><span id="91c8" class="mt lb it kz b gy nn mv l mw mx">pipe = Pipeline([<br/>    ("sc", StandardScaler()),<br/>    ("km", KMeansTransformer()),<br/>    ("lr", LogisticRegression(penalty="none", solver="lbfgs"))<br/>])</span><span id="b21e" class="mt lb it kz b gy nn mv l mw mx">pipe.fit(X, y)<br/>pipe.score(X, y)<br/># ==&gt; 1.0</span></pre><p id="6be2" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在不太人工的例子中，您可能还想使用<code class="fe kw kx ky kz b">GridSearchCV</code>来找到传递到您的逻辑回归(或您拥有的任何模型)中的最佳聚类数。</p><h1 id="25cd" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated"><strong class="ak">结论</strong></h1><p id="81b0" class="pw-post-body-paragraph jx jy it jz b ka ly kc kd ke lz kg kh ki ma kk kl km mb ko kp kq mc ks kt ku im bi translated">现在，您应该明白如何在 Scikit-Learn 的框架内构建自己的定制机器学习模型，Scikit-Learn 是目前最受欢迎的(在许多情况下)强大的 ML 库。</p><p id="2082" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">这篇博文学究气吗？当然可以。你会需要这个吗？不，你可能永远不会<em class="kv">需要</em>这个，但这不是重点。这种技术被用于<em class="kv">建造</em>某种东西。需要一个<em class="kv">建造者</em>来认识到需要建造一个更有创造性的解决方案。另外，正如一位智者曾经说过的:</p><blockquote class="no np nq"><p id="6f5b" class="jx jy kv jz b ka kb kc kd ke kf kg kh nr kj kk kl ns kn ko kp nt kr ks kt ku im bi translated">你永远不会因为知道得多而少。</p></blockquote><p id="6635" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我希望您喜欢将这个工具添加到您的工具带中。掌握了它，你可能才刚刚实现真正的<em class="kv">机器学习提升</em>。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/0c5938d117fd08eba227abce87511f90.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*chHxLphEqqiQWLhHkiLSFw.jpeg"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">图为:我们机器学习者每天实际做的事情。</p></figure></div></div>    
</body>
</html>