<html>
<head>
<title>A Flask Full of Whiskey (WSGI)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">满满一瓶威士忌(WSGI)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-flask-full-of-whiskey-wsgi-e89525d6f9da?source=collection_archive---------18-----------------------#2020-02-16">https://towardsdatascience.com/a-flask-full-of-whiskey-wsgi-e89525d6f9da?source=collection_archive---------18-----------------------#2020-02-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/789dfa966a40a1eabb789948b5208824.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*68q2KyOrp4y1p0Dp"/></div></figure><p id="0ae7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">有了目前由我们支配的WSGI服务器套件，提供python web应用程序变得前所未有的简单。Nginx背后的uWSGI和gunicorn都是提供Flask应用程序的优秀执行者……</p><p id="7b48" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">是的，在生活中你还能要求什么呢？也有许多品种，以适应个人的喜好。玩笑归玩笑，这篇文章是关于配置和压力测试几个<a class="ae kt" href="https://en.wikipedia.org/wiki/Web_Server_Gateway_Interface" rel="noopener ugc nofollow" target="_blank"> WSGI </a> (Web服务器网关接口)来提供一个Python web应用程序。以下是我们在本帖中涉及的内容</p><ul class=""><li id="59c6" class="ku kv iq jw b jx jy kb kc kf kw kj kx kn ky kr kz la lb lc bi translated">用Flask web开发框架编写了一个简单的应用程序。唯一公开的API是通过查询后端资源生成随机报价。在这种情况下，是Elasticsearch索引了大量的引用。</li><li id="e147" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">看看下面这些独立的WSGI web服务器— <a class="ae kt" href="https://gunicorn.org/" rel="noopener ugc nofollow" target="_blank"> gunicorn </a>、<a class="ae kt" href="https://uwsgi-docs.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> uWSGI </a>，以及Flask捆绑的默认<a class="ae kt" href="https://werkzeug.palletsprojects.com/en/0.16.x/" rel="noopener ugc nofollow" target="_blank"> werkzeug </a>。</li><li id="1ad5" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">看看使用Nginx来转发客户端请求的好处，这些请求被代理回上面的请求。</li><li id="522e" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">使用supervisor管理WSGI服务器，使用Locust驱动负载测试。</li></ul><p id="ddf2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为了便于说明，我们在这里浏览了一些代码/配置片段，但是完整的代码可以从<a class="ae kt" href="https://github.com/ashokc/A-Flask-full-of-WSGI" rel="noopener ugc nofollow" target="_blank"> github </a>获得。</p><h1 id="51b7" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">1.WSGI服务器</h1><p id="a121" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">除非一个网站完全是静态的，否则web服务器需要一种方式来使用外部应用程序来获取一些动态数据。随着时间的推移，已经实现了许多方法来使这种练习变得精简、高效和简单。我们有好的旧CGI，它为每个请求产生一个新的进程。然后是mod_python，它将python嵌入到web服务器中，接着是FastCGI，它允许web服务器接入一个长时间运行的进程池，将请求分派给它。他们都有自己的长处和短处。例如，请参见此<a class="ae kt" href="https://stackoverflow.com/questions/3937224/differences-and-uses-between-wsgi-cgi-fastcgi-and-mod-python-in-regards-to-py" rel="noopener ugc nofollow" target="_blank">堆栈溢出</a>页面上的讨论和链接。</p><p id="0732" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">目前最受欢迎的是WSGI协议，它允许web服务器和它们需要访问的应用程序完全分离。这是一个总的示意图。</p><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ml"><img src="../Images/9ea65256f094492c87b75362ae19c5f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*HT9vMqBWPBWy9vcrtkrl4g.jpeg"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">图一。web服务器和python应用程序通过中间的wsgi服务器进行通信，该服务器在http和WSGI协议之间进行转换。当然，WSGI服务器不仅仅是一个翻译器。它是线程化的，将传入的请求分布在Flask应用程序的多个实例上。</p></figure><ul class=""><li id="35a4" class="ku kv iq jw b jx jy kb kc kf kw kj kx kn ky kr kz la lb lc bi translated">WSGI服务器本身支持Http，所以客户机/Nginx可以通过Http与它们对话。在uWSGI服务器的情况下，对于Nginx，也可以选择<em class="ks"> uwsgi </em>协议，并从命令行进行测试。</li><li id="9494" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">Nginx将请求代理回一个为URI配置的WSGI服务器。</li><li id="3240" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">WSGI服务器配置了Python应用程序来调用请求。结果会一路传回。</li></ul><h1 id="a8b2" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">2.应用</h1><p id="87b8" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">应用程序很简单。这个应用程序只有一个文件——T2报价。它允许一个GET请求。</p><pre class="mm mn mo mp gt my mz na nb aw nc bi"><span id="8df1" class="nd lj iq mz b gy ne nf l ng nh">/quotes/byId?id=INTEGER_NUMBER</span></pre><p id="1a4b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">该应用程序从Elasticsearch索引中获取报价文档，将INTEGER_NUMBER作为文档ID，并将其呈现如下。</p><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/4f117201b0364c64f11ae5a7775b0690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*SYPi-yTk3CXWzlkHW_SLnQ.jpeg"/></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">图二。我们从这篇博文中学到了什么？</p></figure><p id="390c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">图片和CSS由Nginx提供。</p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="b69d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在没有Nginx的情况下，它们是从<em class="ks">静态</em>文件夹中发送的。</p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="023c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这就是应用程序的全部。无论我们选择使用哪种WSGI服务器都是一样的。这是目录和文件布局。</p><pre class="mm mn mo mp gt my mz na nb aw nc bi"><span id="4309" class="nd lj iq mz b gy ne nf l ng nh">.<br/>├── config.py     # Config options for gunicorn<br/>├── quotes.py<br/>├── static<br/>│   ├── css<br/>│   │   └── quote.css<br/>│   ├── favicon.ico<br/>│   └── images<br/>│       ├── eleanor-roosevelt.jpg<br/>│       ├── martha washington.jpg<br/>│       └── maya angelou.jpg<br/>├── templates<br/>│   └── quote.html<br/>└── wsgi.py       # Used by uWSGI</span></pre><p id="b823" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">当使用内置的<em class="ks"> werkzeug </em>作为WSGI服务器时，我们在<em class="ks"> quotes.py </em>模块中提供运行时配置。调用服务时会提供<em class="ks"> uWSGI </em>和<em class="ks"> gunicorn </em>的配置。接下来我们将讨论Nginx和服务经理<a class="ae kt" href="http://supervisord.org/" rel="noopener ugc nofollow" target="_blank">主管</a>的问题。</p><h1 id="559e" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">3.配置</h1><p id="ce59" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">任何WSGI服务器使用的并发进程/工作进程的数量都会对性能产生影响。建议值约为内核数量的两倍，但如果不降低性能，也可以更大。在这里，我们不会弄乱每个工作线程，因为我们应用程序的内存占用很小。参见<a class="ae kt" href="https://medium.com/building-the-system/gunicorn-3-means-of-concurrency-efbb547674b7" rel="noopener">这篇文章</a>中关于工人vs线程使用的一些讨论。</p><p id="9904" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们从6个工人开始，并改变它来衡量影响。我们对<em class="ks"> gunicorn </em>和<em class="ks"> uWSGI </em>服务器使用相同的数字，所以比较是苹果对苹果的。不幸的是，似乎没有办法在服务器上做同样的事情。</p><h1 id="07a9" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">3.1主管</h1><p id="5014" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">我们使用<a class="ae kt" href="http://supervisord.org/" rel="noopener ugc nofollow" target="_blank"> supervisord </a>来管理WSGI服务器进程。这允许更容易的配置、控制、通过app/wsgi和UI引导的日志的清晰分离。每台服务器的配置文件放在/etc/supervisor/conf.d中，并启动supervisord服务。</p><pre class="mm mn mo mp gt my mz na nb aw nc bi"><span id="5a5a" class="nd lj iq mz b gy ne nf l ng nh">[/etc/supervisor] ls conf.d/*<br/>conf.d/gunicorn.conf  conf.d/uwsgi.conf  conf.d/uwsgi-http.conf  conf.d/werkzeug.conf</span><span id="0dbc" class="nd lj iq mz b gy nl nf l ng nh">[/etc/supervisor] sudo systemctl start supervisor.service</span></pre><p id="d66f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这里是一个UI截图(默认为localhost:9001 ),显示了正在运行的WSGI服务器，以及停止/启动、跟踪日志等控件。</p><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nm"><img src="../Images/1677349f6f7ca4c3bc2298a17f78ff38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BqE6O3yhl5q95IcAQhmKmw.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">图3。Supervisor service支持对WSGI服务器进行干净简单的管理</p></figure><p id="10ee" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="ks"> uwsgi </em>和<em class="ks"> uwsgi-http </em>的区别在于，后者有一个http端点，而前者使用二进制uwsgi协议。我们在图1的上下文中讨论了这一点。让我们来看看每一个的配置文件。请注意，下面配置文件中的路径是带有“…”的占位符，将根据磁盘上的确切路径进行适当替换。</p><h1 id="c62d" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">3.2 gunicorn</h1><p id="f5ca" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">配置中的命令字段调用<em class="ks"> gunicorn </em>。<em class="ks"> gunicorn </em>服务器使用<em class="ks"> quotes.py </em>中的app对象，并使web api在端口9999可用。下面是配置文件<em class="ks">/etc/conf . d/guni corn . conf</em></p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="422b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">一个单独的文件<em class="ks"> config.py </em>用于提供线程数量、日志细节等等。</p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="534e" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">3.3 uWSGI</h1><p id="44dd" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">正如我们前面提到的,<em class="ks"> uWSGI </em>服务器可以提供Http或uWSGI端点。当<em class="ks"> uWSGI </em>服务器位于类似Nginx的web服务器之后时，建议使用uwsgi端点。以下配置适用于Http端点。对于uwsgi端点，我们将“<em class="ks"> -http 127.0.0.1:9997 </em>”替换为“<em class="ks"> -socket 127.0.0.1:9998 </em></p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="e866" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">配置类似于gunicorn的配置，但是我们不使用单独的配置文件。关键的区别是参数'-wsgi-file '，它指向由<em class="ks"> uWSGI </em>服务器使用的带有应用程序对象的模块。</p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="0958" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">3.4 werkzeug</h1><p id="494d" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">默认<em class="ks"> werkzeug </em>服务器的选项作为<em class="ks"> quotes.py </em>模块中app.run (…)调用的一部分给出。我们禁用日志记录是为了不影响性能数字。</p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="494c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">supervisord唯一要做的就是让werkzeugrun成为一个守护进程。</p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="69e7" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">3.5 Nginx</h1><p id="08bf" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">当使用Nginx时，我们需要它将请求正确地路由到上述WSGI服务器。我们使用URI签名来决定应该联系哪个WSGI服务器。下面是来自<em class="ks"> nginx.conf </em>的相关配置。</p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="9769" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们通过URI的前导部分识别WSGI服务器，并小心地将它代理回我们定义的该服务器要监听的正确端口。</p><h1 id="0e0b" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">3.5总结</h1><p id="775a" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">有了这些，下面是Nginx就位时从客户端到后端的调用流的概要图。</p><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/d680b24deb06039fe6f0b36606082654.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*7F9N_hLO7C_Ii5GUxNRIkw.jpeg"/></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">图4。当Nginx面向WSGI服务器时，来自客户端的请求的流程和路由。</p></figure><p id="fccb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在没有Nginx的情况下，客户机直接向由WSGI服务器支持的Http端点发送请求。足够清楚——不需要另一张图。</p><h1 id="b1dc" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">4.用蝗虫进行负载测试</h1><p id="d204" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated"><a class="ae kt" href="https://locust.io/" rel="noopener ugc nofollow" target="_blank"> Locust </a>是一个针对Python的负载测试框架。测试可以方便地在代码中定义，统计数据以csv文件的形式收集。这里有一个简单的脚本，它在收集系统指标的同时使用了Locust。我们使用<a class="ae kt" href="https://github.com/f18m/cmonitor" rel="noopener ugc nofollow" target="_blank"> cmonitor_collector </a>来收集负载和内存使用指标。</p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><ul class=""><li id="38b2" class="ku kv iq jw b jx jy kb kc kf kw kj kx kn ky kr kz la lb lc bi translated">启动系统监视器来收集负载、内存使用等统计数据</li><li id="6dcf" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">在本地主机上运行<em class="ks"> load_tests.py </em>中描述的测试</li><li id="cfeb" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">将结果保存到文件“results_stats.csv”和“results_stats_history.csv”。</li><li id="093c" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">测试开始时，总共模拟了500个用户，每秒增加10个用户</li><li id="44c1" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">测试运行60分钟</li><li id="45f2" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">Locust还启用了一个带有绘图等功能的UI(localhost:5557 ),但这里没有使用</li><li id="8e1d" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">停止系统监视器</li><li id="0b26" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">对来自Locust的csv数据和系统度量数据进行后处理，以生成可以在不同的WSGI备选方案之间进行比较的图形</li></ul><p id="a124" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们必须定义的唯一测试是命中我们已经公开的单个API是<em class="ks"> …/quotes/byId？id=xxxx </em></p><figure class="mm mn mo mp gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="4c79" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">该代码模拟一个用户，在再次点击API之前等待1到3秒钟，并使用一个随机整数作为要获取的报价的ID。</p><h1 id="784e" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">5.结果</h1><p id="9008" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">终于到了公布结果的时候了。花了一段时间来确定，但我们有相当多的移动件。绘制收集的数据很简单(我在这里使用matplotlib ),因此我们将跳过这方面的代码。可以从<a class="ae kt" href="https://github.com/ashokc/A-Flask-full-of-WSGI" rel="noopener ugc nofollow" target="_blank"> github </a>中获取<em class="ks"> plots.py </em>。</p><p id="0de3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们有两个系列的运行——(a)6个工人，和(b)60个工人。每个系列有7次locust运行，如上面的代码片段所示。Locust生成各种指标的数据——请求数、失败数、响应时间等……作为时间的函数。同样，cmonitor收集硬件的负载、内存使用等数据。下面的图5显示了工人的结果。</p><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/8979d45e230c2a659e097436c981dd5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*SPYqmm7jTK9f78Rdd6yj7w.jpeg"/></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">图5。6名工人的绩效结果。gunicorn和uWSGI (uwsgi protcol)在有/没有Nginx的情况下性能最佳</p></figure><p id="39d0" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">从图5 (E &amp; F)中得出的主要结论如下。</p><ul class=""><li id="fddd" class="ku kv iq jw b jx jy kb kc kf kw kj kx kn ky kr kz la lb lc bi translated"><em class="ks">性能</em>:我们考虑平均响应时间(图5F)。<em class="ks"> uWSGI </em>和<em class="ks"> gunicorn </em>服务器的性能在有/没有Nginx的情况下都不相上下。Flask自带的默认服务器<em class="ks"> werkzeug </em>是最差的，这是他们推荐的原因之一——不要在生产中使用它。另外，如果你喜欢uWSGI协议，那么选择二进制uwsgi协议，把它放在Nginx之后，因为它是最好的。下面是明确的顺序。</li></ul><ol class=""><li id="3aef" class="ku kv iq jw b jx jy kb kc kf kw kj kx kn ky kr no la lb lc bi translated">Nginx后面的<em class="ks"> uWSGI </em>服务器(<em class="ks"> uwsgi </em>)</li><li id="be28" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr no la lb lc bi translated"><em class="ks">没有Nginx的gunicorn </em>服务器</li><li id="1a5d" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr no la lb lc bi translated">Nginx后面的<em class="ks"> uWSGI </em>服务器(Http)</li><li id="c251" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr no la lb lc bi translated">Nginx背后的gunicorn 服务器</li><li id="5144" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr no la lb lc bi translated"><em class="ks">无Nginx的uWSGI </em>服务器(Http)</li><li id="5fba" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr no la lb lc bi translated"><em class="ks"> werkzeug </em>，带/不带Nginx</li></ol><ul class=""><li id="ddc2" class="ku kv iq jw b jx jy kb kc kf kw kj kx kn ky kr kz la lb lc bi translated"><em class="ks">为什么响应时间增加</em>？原因不是因为服务器性能随着时间而下降。更确切地说，这是工作中清晨喝咖啡的星巴克现象！Locust在这里报告的是从发出请求到收到响应之间的总时间。我们发出请求的速率大于服务器清除请求的速率。因此请求被排队，队伍随着时间变得越来越长。较早进入队列的请求比较晚进入队列的请求等待时间短。当然，这表现为后续请求的响应时间更长。</li><li id="29ed" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated"><em class="ks">为什么中值的阶跃增加而平均值的阶跃平滑</em>？中位数(或任何百分位数)只是一个整数(毫秒)，而平均值当然是所有数字的平均值(浮点数)。百分位数基于其当前值两侧的计数，并给定随机性— <em class="ks">缓慢增加，并通过量子跳跃</em>。另一方面，平均值持续增加。</li></ul><p id="3245" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">但是从图A-D中我们可以学到更多的东西。</p><ul class=""><li id="9f84" class="ku kv iq jw b jx jy kb kc kf kw kj kx kn ky kr kz la lb lc bi translated">(A)请求的总数随着时间的推移而增加——当然！有点线性，但不完全线性，在运行之间也有一些变化。这仅仅是因为模拟用户连续请求之间的<em class="ks">等待时间</em>在上面的代码片段中被随机化了。</li><li id="c1a2" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">(B)有一些失败，但是与被服务的请求总数相比非常非常少。或许还不足以得出重大结论。</li><li id="2fb5" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">(C &amp; D)在任何情况下都有足够的空闲内存，没有太多的负载。但是<em class="ks">看起来</em>当不使用Nginx时，服务器会消耗更多的内存，负载也会稍微高一些。</li></ul><p id="cd7b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">很明显，我们不会用6名员工来增加服务器的负担。让我们把工人增加到60人，看看我们会得到什么。这在下面的图6中。</p><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nn"><img src="../Images/80ab10b2940ca21e51a17b365598e3e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*RDji6VBW8okSITGdUGBgMw.jpeg"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">图6。60名工人的绩效与6名工人的绩效在质量上是相同的。gunicorn和uWSGI (uwsgi protcol)不管有没有Nginx都还是最好的。</p></figure><p id="56ef" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们明显增加了负载和内存使用量(C &amp; D)，但我们从图5中得出的所有结论仍然适用，首先是<em class="ks"> uWSGI </em>服务器，其次是<em class="ks"> gunicorn </em>。在结束这篇文章之前，让我们来看看6个和60个工人在同一个地块上的响应时间结果，只关注<em class="ks"> uWSGI </em>和<em class="ks"> gunicorn </em>。</p><figure class="mm mn mo mp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi np"><img src="../Images/4d51c6b728edf3a14c374e685b332a70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1YkmBZzcUlYzUhy-6ZnFDw.jpeg"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">图7。在我们的案例中，增加工人数量不会产生巨大的影响。Nginx后面的uWSGI服务器表现最好，其次是带/不带Nginx的gunicorn。</p></figure><h1 id="5091" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">6.结论</h1><p id="cfdf" class="pw-post-body-paragraph ju jv iq jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">我们在这篇文章中了解到:</p><ul class=""><li id="3680" class="ku kv iq jw b jx jy kb kc kf kw kj kx kn ky kr kz la lb lc bi translated">Nginx后面的uWSGI服务器表现最好</li><li id="96d5" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">不管有没有Nginx，gunicorn都不会出错</li><li id="063f" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">我们希望避免将uWSGI Http服务器放在Nginx之后，就像他们在其网站上推荐的那样</li><li id="04ba" class="ku kv iq jw b jx ld kb le kf lf kj lg kn lh kr kz la lb lc bi translated">我们在生产中不使用默认的<em class="ks"> werkzeug </em>服务器！</li></ul><p id="9e53" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">快乐学习！</p></div><div class="ab cl nq nr hu ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ij ik il im in"><p id="481c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><em class="ks">原载于2020年2月16日http://xplordat.com</em><a class="ae kt" href="http://xplordat.com/2020/02/16/a-flask-full-of-whiskey-wsgi/" rel="noopener ugc nofollow" target="_blank"><em class="ks"/></a><em class="ks">。</em></p></div></div>    
</body>
</html>