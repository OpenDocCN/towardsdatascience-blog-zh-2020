<html>
<head>
<title>Detecting microcontrollers with CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用CNN检测微控制器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-microcontrollers-with-cnn-ced688a8a144?source=collection_archive---------51-----------------------#2020-09-29">https://towardsdatascience.com/detecting-microcontrollers-with-cnn-ced688a8a144?source=collection_archive---------51-----------------------#2020-09-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="faad" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">点击时的对象检测</h2><div class=""/><div class=""><h2 id="1940" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">根据Kaggle竞赛数据检测微控制器的简单教程</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/e6f5f45f16648c1ffa1a23f70571f393.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0-57fj-yaMYjj87vmfrPHg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由来自<a class="ae le" href="https://www.pexels.com/photo/black-and-yellow-electronic-chip-785418/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">佩克斯</a>的<a class="ae le" href="https://www.pexels.com/@jonas-svidras?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">乔纳斯·斯维德拉斯</a>拍摄</p></figure><p id="74e6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi mb translated">像TensorFlow或PyTorch这样的tandart库没有提供任何简单的方法来训练你的自定义对象检测模型。很多时候你需要安装一个大的库作为Detectron 2或者Tensorflow物体检测API。不要误解我的意思，这些库功能强大，但通常需要大量的检查、调优和处理数据。这就是为什么我想向您展示一种更简单有效的方法，通过调用Rest API和一点点击来训练您的检测器。</p><p id="3eff" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这种方法有一些优势:你不需要成为机器学习专家，你的数据都在一个地方。</p><h1 id="e01f" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">资料组</h1><p id="dbcf" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ne lq lr ls nf lu lv lw ng ly lz ma ij bi translated">对于本教程，我从Kaggle选择一个小数据集来检测由<a class="ae le" href="https://gilberttanner.com/" rel="noopener ugc nofollow" target="_blank">Gilbert Tanner</a>[<a class="ae le" href="https://towardsdatascience.com/@gilberttanner" rel="noopener" target="_blank">@ Medium</a>]开发的<a class="ae le" href="https://www.kaggle.com/tannergi/microcontroller-detection" rel="noopener ugc nofollow" target="_blank">微控制器</a>。它包含大约250幅图像，包含四种类型的对象:</p><ul class=""><li id="6185" class="nh ni iq lh b li lj ll lm lo nj ls nk lw nl ma nm nn no np bi translated">Arduino Nano</li><li id="89d3" class="nh ni iq lh b li nq ll nr lo ns ls nt lw nu ma nm nn no np bi translated">Heltec ESP32 Lora</li><li id="bba4" class="nh ni iq lh b li nq ll nr lo ns ls nt lw nu ma nm nn no np bi translated">ESP8266</li><li id="b261" class="nh ni iq lh b li nq ll nr lo ns ls nt lw nu ma nm nn no np bi translated">树莓Pi 3</li></ul><p id="c94c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们将通过API上传<a class="ae le" href="https://www.ximilar.com/" rel="noopener ugc nofollow" target="_blank"> Ximilar </a>平台上的数据(带边框的图片)。边界框包含4个坐标，并定义微控制器的确切位置(矩形)。我们也可以通过app.ximilar.com拖放图像，并通过绘制手动创建边界框。</p><p id="adad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">创建任务和标签</strong></p><p id="5ef6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我们上传数据之前，我们需要通过应用程序定义我们的神经网络模型。我们将创建任务和4个与该任务相关联的标签。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/d2390b0185872105468c89afd7dbb0e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*0yauDoTirC9HldsdYfBJrw.gif"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">创建带有一些标签的新任务。作者图片</p></figure><p id="9850" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">选项A:通过脚本上传数据</strong></p><p id="5448" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果您不想手动创建所有的边界框，您可以通过运行以下脚本来上传它们。只需更改标签id并从下载的数据集文件夹中运行该脚本。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="0ad2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">选项B:用绘图框</strong>拖动&amp;放置</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/3900edd898bda65c39a0b98b80bf49d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*O19xZv8OEDFfS9aVDGsdwQ.gif"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用前端绘制边界框。作者图片</p></figure><h1 id="608d" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">火车</h1><p id="6829" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ne lq lr ls nf lu lv lw ng ly lz ma ij bi translated">上传所有数据后，我们进入微控制器任务页面，点击<strong class="lh ja"> <em class="ny">训练</em> </strong>按钮。培训可能需要30分钟到几个小时。想出去走走也可以注销应用:)。这真的需要一些时间，因为用于对象检测的神经网络是在我们的服务器上自动训练的。</p><p id="bc31" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你想了解所有这些背后的神经网络架构，你可以查看Libor 的<a class="ae le" rel="noopener" target="_blank" href="/new-approaches-to-object-detection-f5cbc925e00e">帖子。</a></p><h1 id="8ed3" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">检查结果</h1><p id="8553" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ne lq lr ls nf lu lv lw ng ly lz ma ij bi translated">训练已经完成，现在我们可以在一些图像上测试它。同样，我们有两个使用API或app来获取结果的选项。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/221f8a078e2020c765202f03a2fe10d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*T1w0DfXxXFCxfeg_qtS7BA.gif"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">检查训练好的模型。作者图片</p></figure><p id="6858" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我们的任务定义中，我们可以看到我们的模型用IoU 0.75实现了mAP 0.85。这是一个不坏的结果！什么是地图度量？解释在另一篇文章中，所以你可以在这里阅读更多。简单地说，数字越高，结果越好。如果我们转到训练模型的细节，我们可以查看每个标签的地图。我们可以看到数据集很平衡(每个标签有图像，每个标签有对象)。</p><p id="a4a3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您可以使用Python SDK客户端(这是一个REST/JSON包装器库)连接到API，并获得经过训练的检测模型的结果:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h1 id="5915" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">训练模型的技巧</h1><p id="7969" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ne lq lr ls nf lu lv lw ng ly lz ma ij bi translated">这只是我们的第一个训练模型，所以结果不是最好的。我们可以通过上传更多的图片和重新训练模型来改善它。如果是这样，应用程序将训练一个新模型，而不删除旧模型。如果你想对你的型号进行比较或A/B测试，这是很好的选择。</p><p id="83e9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你可以玩其他的选择。您可以编辑高级选项来控制图像分辨率和图像增强技术。<strong class="lh ja">图像增强</strong>是一种改变(稍微或更积极地)输入图像以创建更大数据集的技术，因此您的模型将在更多图像上更好地泛化。</p><p id="d9df" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您还可以上传图像并<strong class="lh ja">将它们标记为测试</strong>，这样您的模型将始终在这些标记的图像上评估结果。这些图像在训练过程中是看不到的，因此您的测试数据集独立于您的训练数据集，并且该数据集的地图编号更加可靠。</p><h1 id="2a88" class="mk ml iq bd mm mn mo mp mq mr ms mt mu kf mv kg mw ki mx kj my kl mz km na nb bi translated">最后的话</h1><p id="d839" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ne lq lr ls nf lu lv lw ng ly lz ma ij bi translated">目标检测或目标识别只是机器视觉领域中许多常见问题之一。它可以用于电子商务中检测时尚服装，用于医疗保健中检测肿瘤组织，用于汽车油漆划痕的保险检测，用于检测免费停车位，等等。</p></div></div>    
</body>
</html>