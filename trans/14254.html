<html>
<head>
<title>Predicting Weekly Hotel Cancellations with XGBRegressor</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用XGBRegressor预测每周酒店取消预订</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-weekly-hotel-cancellations-with-xgbregressor-d73eb74a8624?source=collection_archive---------29-----------------------#2020-10-01">https://towardsdatascience.com/predicting-weekly-hotel-cancellations-with-xgbregressor-d73eb74a8624?source=collection_archive---------29-----------------------#2020-10-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="782b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于xgb回归的时间序列预测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c17e5b34aef2f9aa1534aa2ab0b4d648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AlQjRBNvjGzv2ROHhb9vQA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:照片由<a class="ae ky" href="https://pixabay.com/users/yuri_b-2216431/" rel="noopener ugc nofollow" target="_blank"> Yuri_B </a>从<a class="ae ky" href="https://pixabay.com/illustrations/space-rocket-night-cartoon-3262811/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄</p></figure><p id="6f5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">XGBoost最常用于基于分类或回归的问题，其中将特征合并到模型中以预测感兴趣的结果。</p><p id="f45a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也就是说，XGBoost也可以用于时间序列预测。这是通过使用感兴趣的时间序列的滞后作为模型中的独立特征来实现的。让我们看看如何使用XGBRegressor来帮助我们预测酒店取消预订。</p><h1 id="4e73" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据处理</h1><p id="0962" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">以下分析基于来自<a class="ae ky" href="https://www.sciencedirect.com/science/article/pii/S2352340918315191" rel="noopener ugc nofollow" target="_blank"> Antonio、Almeida和Nunes (2019)的数据:酒店预订需求数据集</a>。</p><p id="f823" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用XGBoost构建时间序列预测模型的目的是让酒店能够预测每周酒店取消预订的数量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/14bf393f62c9b77c591a843b22054342.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*XnB1eT2MoIh5ogNznhi2iA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:Jupyter笔记本输出</p></figure><p id="4c78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据首先被分成训练和验证分区:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="3b54" class="my lw it mu b gy mz na l nb nc">train_size = int(len(df) * 0.8)<br/>val_size = len(df) - train_size<br/>train, val = df[0:train_size,:], df[train_size:len(df),:]</span></pre><p id="2809" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们正在使用一个基于<a class="ae ky" href="https://github.com/dmlc/xgboost/issues/357" rel="noopener ugc nofollow" target="_blank">树的模型</a>，在这个例子中，这些特性没有使用MinMaxScaler进行规范化。</p><p id="4602" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">形成数据集矩阵:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="c0f8" class="my lw it mu b gy mz na l nb nc">def create_dataset(df, previous=1):<br/>    dataX, dataY = [], []<br/>    for i in range(len(df)-previous-1):<br/>        a = df[i:(i+previous), 0]<br/>        dataX.append(a)<br/>        dataY.append(df[i + previous, 0])<br/>    return np.array(dataX), np.array(dataY)</span></pre><p id="cfcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后为模型定义一个回望期，也就是说，当预测向前一步时，我们希望模型“回望”多少时间步？</p><p id="a7f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，将使用一个<strong class="lb iu"> 5 </strong>的回看周期。根据RMSE(均方根误差)测量的精度，可以适当地修改回望周期。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="d3ed" class="my lw it mu b gy mz na l nb nc">lookback = 5<br/>X_train, Y_train = create_dataset(train, lookback)<br/>X_val, Y_val = create_dataset(val, lookback)</span></pre><p id="39c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是X_train输出的示例:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="1f20" class="my lw it mu b gy mz na l nb nc">array([[ 41.,  48.,  87.,  74., 101.],<br/>       [ 48.,  87.,  74., 101.,  68.],<br/>       [ 87.,  74., 101.,  68.,  96.],<br/>       [ 74., 101.,  68.,  96.,  69.],<br/>       [101.,  68.,  96.,  69.,  88.]<br/>...<br/>       [111.,  70.,  39.,  59.,  74.],<br/>       [ 70.,  39.,  59.,  74.,  57.],<br/>       [ 39.,  59.,  74.,  57.,  36.]])</span></pre><h1 id="b1aa" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">XGBRegressor</h1><p id="34be" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">XGBRegressor模型定义如下:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="59e6" class="my lw it mu b gy mz na l nb nc">from xgboost import XGBRegressor</span><span id="f60e" class="my lw it mu b gy nd na l nb nc">model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)<br/>model.fit(X_train, Y_train)</span></pre><p id="0b97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是定义的模型参数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/fd445f8400f23c95883bd1f434414dde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lj4Y8Namqex4orAYcvspDA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:Jupyter笔记本输出</p></figure><p id="f89b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面我们可以看到，在训练XGBRegressor时，有许多模型参数可以修改。但是，在这种情况下，n_estimators被设置为1000。这定义了XGBoost模型中树的数量。目标设置为<a class="ae ky" href="https://xgboost.readthedocs.io/en/latest/parameter.html" rel="noopener ugc nofollow" target="_blank">‘reg:squarederror’</a>，即平方损失回归，对极值误差的惩罚更重。</p><p id="0493" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型跨训练集和验证集进行训练:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="5e3f" class="my lw it mu b gy mz na l nb nc">&gt;&gt;&gt; trainpred = model.predict(X_train)<br/>&gt;&gt;&gt; trainpred</span><span id="2b8b" class="my lw it mu b gy nd na l nb nc">array([ 68.00038 ,  95.99979 ,  69.00168 ,  88.00018 , 147.99892 ,<br/>        76.000656, 185.99991 , 122.999306,  91.00025 , 197.99966 ,<br/>...<br/>       128.99901 , 111.99981 , 118.00009 ,  85.00055 , 181.99738 ,<br/>       133.9994  , 111.001526,  70.00158 ,  39.0001  ,  58.99967 ,<br/>        74.00109 ,  56.999626,  36.001102,  84.00235 ], dtype=float32)</span><span id="2b08" class="my lw it mu b gy nd na l nb nc">&gt;&gt;&gt; valpred = model.predict(X_val)<br/>&gt;&gt;&gt; valpred</span><span id="1eb2" class="my lw it mu b gy nd na l nb nc">array([ 19.767576,  62.593506,  80.718994,  60.782364, 129.0691  ,<br/>       112.3979  , 113.64816 ,  91.60748 , 105.40695 ,  62.221115,<br/>       109.42688 , 126.32669 ,  94.05386 ,  62.81558 ], dtype=float32)</span></pre><p id="4585" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练集和验证集(预测集和实际集)会相应地进行调整:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="4f89" class="my lw it mu b gy mz na l nb nc">&gt;&gt;&gt; Y_train=Y_train.reshape(-1,1)<br/>&gt;&gt;&gt; trainpred=trainpred.reshape(-1,1)</span><span id="b1d1" class="my lw it mu b gy nd na l nb nc">&gt;&gt;&gt; Y_val=Y_val.reshape(-1,1)<br/>&gt;&gt;&gt; valpred=valpred.reshape(-1,1)</span></pre><h1 id="1c94" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结果</h1><p id="39e4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在，在RMSE(均方根误差)的基础上，将预测值与实际抵消值进行比较。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="c9ca" class="my lw it mu b gy mz na l nb nc">&gt;&gt;&gt; train_mse = mean_squared_error(Y_train, trainpred)<br/>&gt;&gt;&gt; rmse = sqrt(train_mse)<br/>&gt;&gt;&gt; print('RMSE: %f' % rmse)</span><span id="caf2" class="my lw it mu b gy nd na l nb nc">RMSE: 0.000887</span><span id="c4e7" class="my lw it mu b gy nd na l nb nc">&gt;&gt;&gt; val_mse = mean_squared_error(Y_val, valpred)<br/>&gt;&gt;&gt; rmse = sqrt(val_mse)<br/>&gt;&gt;&gt; print('RMSE: %f' % rmse)</span><span id="d159" class="my lw it mu b gy nd na l nb nc">RMSE: 50.142536</span></pre><p id="1295" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在验证集(Y_val)上平均每周有109个取消，RMSE在验证集上达到50.14。</p><p id="99b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到，训练集的RMSE几乎为0，但这并不被视为模型性能的基准。毕竟，预测模型已经训练过的数据是一项毫无意义的工作。</p><h1 id="5454" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">这些发现与LSTM相比如何？</h1><p id="3988" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">还使用5的回望周期对上述数据运行了LSTM模型。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="9cbe" class="my lw it mu b gy mz na l nb nc">model = tf.keras.Sequential()<br/>model.add(LSTM(4, input_shape=(1, lookback)))<br/>model.add(Dense(1))<br/>model.compile(loss='mean_squared_error', optimizer='adam')<br/>history=model.fit(X_train, Y_train, validation_split=0.2, epochs=20, batch_size=1, verbose=2)</span></pre><p id="c028" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">得到的RMSE如下:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="1994" class="my lw it mu b gy mz na l nb nc">&gt;&gt;&gt; mse = mean_squared_error(Y_val, predictions)<br/>&gt;&gt;&gt; rmse = sqrt(mse)<br/>&gt;&gt;&gt; print('RMSE: %f' % rmse)</span><span id="c41b" class="my lw it mu b gy nd na l nb nc">RMSE: 36.792552</span></pre><p id="98ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这方面，当使用LSTM模型时，RMSE低于XGBoost，这表明LSTM在预测每周酒店取消方面做得稍好。然而，XGBoost在预测每周取消时仍然表现出相当好的性能。</p><p id="4c9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人们应该注意到，RMSE对更极端值的错误惩罚更重。例如，如果某一周的取消量碰巧比正常情况高得多，而模型预测明显低估了这一点，那么这将导致更高的RMSE。</p><p id="37f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为参考，当使用XGBRegressor时，平均绝对误差在<strong class="lb iu"> 38 </strong>处略低，表明该模型在预测不太极端的值时表现更好。</p><h1 id="f62a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="c4c8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本例中，我们看到:</p><ul class=""><li id="053f" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated">如何使用XGBRegressor预测时间序列</li><li id="2a5a" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">准备数据以使用XGBoost模型</li><li id="fb17" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">测量模型精度的方法</li></ul><p id="47b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢您的宝贵时间，非常感谢您的任何问题或反馈。</p><p id="00fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里找到这个例子<a class="ae ky" href="https://github.com/MGCodesandStats/hotel-cancellations" rel="noopener ugc nofollow" target="_blank">的Jupyter笔记本。</a></p><p id="bfe4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我强烈推荐下面的<a class="ae ky" href="https://machinelearningmastery.com/xgboost-for-time-series-forecasting/" rel="noopener ugc nofollow" target="_blank">机器学习掌握</a>教程，以进一步了解XGBRegressor的使用。</p><p id="a45a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nt">免责声明:本文是在“原样”的基础上编写的，没有任何担保。本文旨在提供数据科学概念的概述，不应被解释为任何形式的专业建议。作者与本文提及的任何第三方无任何关系。</em></p></div></div>    
</body>
</html>