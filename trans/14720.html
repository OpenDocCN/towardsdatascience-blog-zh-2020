<html>
<head>
<title>Demystify Employee Leaving with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用机器学习揭开员工离职之谜</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystify-employee-leaving-with-machine-learning-4016fd6a3b?source=collection_archive---------40-----------------------#2020-10-10">https://towardsdatascience.com/demystify-employee-leaving-with-machine-learning-4016fd6a3b?source=collection_archive---------40-----------------------#2020-10-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a8f5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于休假预测的少数机器学习模型的创建和评估</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/17984ab7b822338d01163e840f3eef66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zQgwCYDJkUqhy03H"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自unsplash的Img通过<a class="ae ky" href="https://unsplash.com/photos/SpgnXs5eTu8" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="0d9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在以前的帖子中，我试图预测银行客户是否可能离开，或者应用程序用户是否可能流失或订阅。在这里，我将分享最近在人力资源领域的工作，给任何努力留住员工的公司带来一些预测能力。</p><p id="1aa0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这第二篇文章中，我的目标是评估和对比一些不同模型的性能。一如既往，它分为:</p><p id="b682" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1.数据工程</p><p id="87b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.数据处理</p><p id="8479" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.模型创建和评估</p><p id="3aa0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.外卖食品</p><p id="d4d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1。数据工程</strong></p><p id="38c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在第一篇<a class="ae ky" href="https://medium.com/@vistaxjtu/demystify-employee-leaving-with-eda-2ed96525f3a7" rel="noopener">帖子</a>中完成了简短的数据探索之后，让我们继续进行特征工程和数据编码。特征工程包括从当前特征创建新特征和关系。</p><p id="b379" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们把分类变量和数字变量分开。我们可以使用<strong class="lb iu"> <em class="lv">数据类型方法</em> </strong>来查找分类变量，因为它们的<strong class="lb iu"> <em class="lv">数据类型</em> </strong>将是<em class="lv">‘对象’</em>。您可能会注意到，在使用<strong class="lb iu"><em class="lv">employee _ df . info()</em></strong>时，已经显示了数据类型。</p><p id="2d69" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以对分类变量进行编码。有两种方法可用。一个是用来自sklearn  的<strong class="lb iu"> <em class="lv"> OneHotEncoder，一个是来自<strong class="lb iu"> <em class="lv">熊猫</em> </strong>的<strong class="lb iu"><em class="lv">get _ dummies()</em></strong>。我更喜欢后者，因为它返回一个dataframe，使下面的步骤变得容易。具体来说，</em></strong></p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="31c0" class="mb mc it lx b gy md me l mf mg">employee_df_cat = pd.get_dummies(employee_df_cat)</span></pre><p id="6b96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，将编码的分类变量和数字变量连接在一起。具体来说，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="308c" class="mb mc it lx b gy md me l mf mg">X_all = pd.concat([X_cat, X_numerical], axis = 1)</span></pre><p id="4c65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一步是生成目标变量。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="8805" class="mb mc it lx b gy md me l mf mg">employee_df[‘Attrition’] = employee_df[‘Attrition’].apply(lambda x: 1 if x == ‘Yes’ else 0)<br/>y = employee_df[‘Attrition’]</span></pre><p id="bb7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。数据处理</strong></p><p id="520b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们准备好处理数据，包括数据分割、缩放和平衡。</p><p id="7111" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使数据为训练做好准备，我们需要缩放特征以避免任何变量支配其他变量，即采取更高的权重和对模型学习的强烈影响。具体来说，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="ef28" class="mb mc it lx b gy md me l mf mg">from sklearn.preprocessing import MinMaxScaler<br/>scaler = MinMaxScaler()<br/>X = scaler.fit_transform(X_all)</span></pre><p id="8aed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们将数据集划分为训练集和测试集。要拆分数据，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="7c82" class="mb mc it lx b gy md me l mf mg">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)</span></pre><p id="b49f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经注意到员工去留严重失衡。所以让我们实现<strong class="lb iu"> SMOTE </strong>方法来对少数类进行过采样。具体来说，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="513d" class="mb mc it lx b gy md me l mf mg">oversampler = SMOTE(random_state=0)<br/>X_smote_train, y_smote_train = oversampler.fit_sample(X_train,y_train)</span></pre><p id="d9ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">太好了！现在模型的数据已经准备好了📣📣。</p><p id="2604" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。模型创建&amp;评估</strong></p><p id="6612" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如本文开头提到的，我们的目标是评估和比较一些模型的性能。</p><p id="f9cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.1逻辑回归</p><p id="7ca8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单地说，逻辑回归对独立变量的线性组合使用对数变换，这允许我们以线性方式对非线性问题建模。通常用于二元分类问题，其中假设预测值和响应变量之间存在某种相关性。</p><p id="cb3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了创建一个逻辑回归分类器，我们使用sklearn如下。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="eb2b" class="mb mc it lx b gy md me l mf mg">from sklearn.linear_model import LogisticRegression<br/>model = LogisticRegression()<br/>model.fit(X_smote_train, y_smote_train)</span></pre><p id="cda2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了评估性能，我们使用混淆矩阵。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="a463" class="mb mc it lx b gy md me l mf mg">y_pred = model.predict(X_test)<br/>cm = confusion_matrix(y_pred, y_test)<br/>sns.heatmap(cm, annot= True)</span></pre><p id="6ff0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如图1所示，逻辑回归分类器给出的准确度为0.75，F1值为0.52。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/b21704eabe091b441f4fe387094fcd77.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*U4Dhi50ZdmbAhrpnb1-orQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1逻辑回归模型的混淆矩阵</p></figure><p id="70e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.2随机森林</p><p id="1b22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随机森林是一种以决策树为构建块的集成模型。它创建了一组决策树，并使用它们的集体预测能力来获得相对较强的性能。要想真正了解兰登森林的基础知识，可以参考这个<a class="ae ky" href="https://blog.citizennet.com/blog/2012/11/10/random-forests-ensembles-and-performance-metrics" rel="noopener ugc nofollow" target="_blank">公民网博客</a>。</p><p id="bf13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要创建随机森林分类器，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="8e3e" class="mb mc it lx b gy md me l mf mg">from sklearn.ensemble import RandomForestClassifier<br/>model = RandomForestClassifier()<br/>model.fit(X_smote_train, y_smote_train)</span></pre><p id="33cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用相同的方法来评估性能，我们获得了0.85的准确度和0.39的F1分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/c7fc43cd6953a1f5c174d06826bde2b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*lQ0_yY8EQdYnLgvWY9PUCg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2随机森林模型的混淆矩阵</p></figure><p id="def2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.3人工神经网络</p><p id="5104" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后的尝试是创建和训练一个人工神经网络。在这里，我们将建立一个具有几个密集层的顺序模型，并使用剔除技术来减少过拟合。具体来说，</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="663f" class="mb mc it lx b gy md me l mf mg">from keras.models import Sequential<br/>from keras.layers import Dense, Dropout<br/>model = Sequential()<br/>model.add(Dense(units = 50, activation = ‘relu’, input_shape = (50, )))<br/>model.add(Dense(units = 500, activation = ‘relu’))<br/>model.add(Dropout(0.3))<br/>model.add(Dense(units = 500, activation = ‘relu’))<br/>model.add(Dropout(0.3))<br/>model.add(Dense(units = 50, activation = ‘relu’))<br/>model.add(Dense(units = 1, activation = ‘sigmoid’))</span></pre><p id="4e59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了编译神经网络，我们使用<em class="lv">‘亚当’</em>优化器和二元交叉熵作为损失函数。</p><pre class="kj kk kl km gt lw lx ly lz aw ma bi"><span id="0837" class="mb mc it lx b gy md me l mf mg">model.compile(optimizer=’adam’, loss = ‘binary_crossentropy’, metrics = [‘accuracy’])<br/>epochs_hist = model.fit(X_smote_train, y_smote_train, epochs = 50, batch_size = 50)<br/>y_pred = model.predict(X_test)<br/>y_pred = (y_pred &gt; 0.5)</span></pre><p id="8b72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所述，我们将sigmoid函数输出的阈值概率设置为0.5。因此，任何大于0.5的输出被视为“离开”，否则被视为“停留”。图3显示了训练期间的模型损失。似乎该模型在20个纪元内达到了收敛。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/7029082c45f431f5d96a9599c0549c30.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*Gv4u69991pplBAP6lbP32Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3训练过程中的模型丢失</p></figure><p id="2c3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，如图4所示的混淆矩阵热图给出了0.88的准确度和0.41的F1分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/4b5a3ebd82ef1301da7a8186122c6f4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*pGucTQhfSXl1A2qIclTz2Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4人工神经网络的混淆矩阵</p></figure><p id="82ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4。外卖</strong></p><p id="6ae1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们将性能汇总在表1中。为了更好地理解指标，后退一步。我们的任务是预测员工是否可能离职。由于类别之间的高度不平衡，准确性不是一个好的指标。在我看来，减少假阴性错误比假阳性更有意义，因为该模型可以识别更多正在离开的人🤔。基于这个逻辑，逻辑回归模型是赢家。但显然，还有相当大的提升空间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/a935a8a561a63d8a0966c88bb3978f4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*iqFo0bzdV3UqLU5DwP1bnA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表1模型性能概述</p></figure><p id="7dea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">太好了！希望这篇文章为不同的EDA和机器学习技术打下良好的基础。像往常一样，如果你对代码感兴趣，可以查看我的GitHub资源库</strong> <a class="ae ky" href="https://github.com/luke4u/Customer_Behaviour_Prediction" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">这里</strong> </a> <strong class="lb iu">🤞🤞。</strong></p></div></div>    
</body>
</html>