<html>
<head>
<title>Linear Regression Model: Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归模型:机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-model-machine-learning-9853450c8bce?source=collection_archive---------24-----------------------#2020-10-07">https://towardsdatascience.com/linear-regression-model-machine-learning-9853450c8bce?source=collection_archive---------24-----------------------#2020-10-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d48c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解用于预测分析的机器学习中的线性回归模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/958e5ce36cf5baaf35c4113325c53973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lZAlx4qLO4cHc5MERinBiw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">BY anscombe . SVG:https://commons.wikimedia.org/w/index.php?curid=9838454史高斯(使用下标标注):Avenue — Anscombe.svg，CC BY-SA 3.0，<a class="ae ky" href="https://commons.wikimedia.org/w/index.php?curid=9838454" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="11fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性回归是机器学习中最重要的回归模型之一。在回归模型中，必须预测的输出变量应该是连续变量，例如预测一个人在一个班级中的体重。</p><p id="144d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回归模型也遵循监督学习方法，这意味着要构建模型，我们将使用带有标签的过去数据，这有助于预测未来的输出变量。</p><h2 id="338a" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">线性回归</h2><p id="6645" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">使用线性回归模型，我们将预测两个因素/变量之间的关系。我们所期待的变量叫做因变量。</p><p id="b027" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性回归模型有两种类型:</p><ul class=""><li id="9327" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">简单线性回归:它只包含一个自变量，我们用一条直线来预测因变量。</li><li id="230d" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">多元线性回归，包括一个以上的独立变量。</li></ul><blockquote class="nh"><p id="309a" class="ni nj it bd nk nl nm nn no np nq lu dk translated">在本文中，我们将集中讨论简单的线性回归模型。</p></blockquote><h2 id="eb89" class="lv lw it bd lx ly nr dn ma mb ns dp md li nt mf mg lm nu mi mj lq nv ml mm mn bi translated">简单线性回归</h2><p id="aec3" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们有一家公司的数据，其中包含营销支出金额以及与该营销预算相对应的销售额。</p><p id="09ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/221ebc38e9375a0d29df3e3fbe1dc124.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*pGZANrAzJ8MxJGrlEQ32pA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">示例营销数据</p></figure><blockquote class="nh"><p id="6ab0" class="ni nj it bd nk nl nm nn no np nq lu dk translated">从<a class="ae ky" href="https://github.com/Kaushik-Varma/Linear_Regression" rel="noopener ugc nofollow" target="_blank">这里</a>下载以上excel数据。</p></blockquote><p id="6bb2" class="pw-post-body-paragraph kz la it lb b lc nx ju le lf ny jx lh li nz lk ll lm oa lo lp lq ob ls lt lu im bi translated">使用Microsoft Excel图表，我们可以为上述数据制作一个如下所示的散点图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/7578733d0748ff366356996e586cda9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xzGAvCH1T2BjYEUgfP02zA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上述数据的散点图</p></figure><p id="6a9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的图表示根据给定数据的所有数据点的散点图。现在，我们必须通过数据点拟合一条直线，这有助于我们预测未来的销售。</p><p id="deb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们知道直线被表示为:</p><p id="a2cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe od oe of og b">y = mx + c</code></p><p id="a133" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们称这条线为回归线，它表示为:</p><p id="cbae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe od oe of og b">Y = β0 + β1X</code></p><p id="4989" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，可以有这么多的直线可以通过数据点。我们必须找出可以作为模型的最佳拟合线，以用于未来的预测。</p><p id="8832" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了在所有线中找到最佳拟合线，我们将引入一个称为<strong class="lb iu">残差(e)的参数。</strong></p><p id="2f9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">残差是Y轴的实际值和基于特定x的直线方程的Y轴预测值之间的差值。</p><p id="a0ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们有散点图和直线，如下图所示，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/464502b2f4d705db38c77261596d8864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*rEdGMgFLYq4ouHtATrL4Nw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者提供的图片-使用图表计算残值</p></figure><p id="54a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，使用上图，x = 2的残值为:</p><p id="1a43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe od oe of og b">Residual(e) = Actual value of Y — the predicted value of Y using the line</code></p><p id="f975" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">e = 3–4 =-1</p><p id="b008" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，x = 2的残差是-1。</p><p id="8552" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，我们对每个数据点都有一个残差值，它是实际Y值和预测Y值之间的差值。</p><p id="c0b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe od oe of og b">ei = yi — y^i</code></p><p id="cd59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，为了找出最佳拟合线，我们将使用一种叫做<strong class="lb iu">普通最小二乘法</strong>或<strong class="lb iu">残差平方和(RSS)法的方法。</strong></p><p id="6201" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe od oe of og b">RSS = e1²+e2²+e3²+……+en²</code></p><p id="3b70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最佳拟合线的RSS值最小。</p><h2 id="4ee9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">价值函数</h2><p id="9819" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">通常，机器学习模型为特定问题定义成本函数。然后，我们试图根据我们的要求最小化或最大化成本函数。在上面的回归模型中，<strong class="lb iu"> RSS </strong>是成本函数；我们想降低成本，找出直线方程的β0和β1。</p><p id="4273" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们回到excel表格中的营销数据集。对上面的散点图使用<code class="fe od oe of og b">Trendline</code>中的<code class="fe od oe of og b">Linear Forecast</code>选项，我们将直接得到散点图的最佳拟合线，无需手动计算残差值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/6c0359d560fd629328f264bfac84c035.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KICdfLmKgJyx3R09ACExJQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用Microsoft Excel散点图选项的最佳拟合线</p></figure><p id="a8e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，<br/>斜率(β1) = 0.0528 <br/>截距(β0) = 3.3525</p><p id="eee5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用上面的直线方程计算所有数据点(X)的预测销售额(Y)。</p><p id="b5bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预计销售额将会是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/78c2daa54deefacade9d97cdad8bdab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*BKlzzYR1Q_JRKU9_mIDgaQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用<strong class="bd ok"> (y=0.0528x+3.33525) </strong>公式预测销售额</p></figure><p id="ffb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，让我们也计算每个数据点的残差平方值。</p><p id="c341" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">残差平方=(实际Y值-预测Y值)</p><p id="17f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">应用上述公式计算残差平方后，我们来看excel表。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/0538207254d32df4fcd5537101b88269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PWKUpNxkPvlUKAsqRPaTfQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">计算残差平方后的数据集</p></figure><p id="c6a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，RSS是上表中所有剩余平方值的总和。</p><p id="897b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RSS = 28.77190461</p><p id="296b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为这是最佳拟合线，所以我们在这里得到的RSS值是最小值。</p><p id="fdd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们在这里观察RSS值，它是一个绝对量。在未来，如果我们改变以十亿而不是百万来衡量销售的问题设置，RSS数量将会改变。</p><p id="ef24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们需要定义一个相对的替代度量，而不是绝对的量。这种替代措施被称为<strong class="lb iu">总平方和(TSS)。</strong>使用TSS，我们将计算R值，这将决定模型是否可行。</p><p id="1e45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe od oe of og b">TSS = (Y1-Ȳ)² + (Y2-Ȳ)² + (Y3-Ȳ)² + ……. + (Yn-Ȳ)²</code></p><p id="c7d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，<br/> Y1，Y2，Y3，…..，Yn是来自数据点的值。<br/>ȳ是y轴柱的平均值</p><p id="1558" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，在计算TSS之后，我们将计算R . <br/> <code class="fe od oe of og b">R² = 1-(RSS/TSS)</code></p><p id="b448" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">r值总是介于0和1之间。<br/>如果R接近1，那么我们的模型是优秀的，我们可以用模型来预测分析。如果该值接近0，则该模型不适合于预测分析。</p><p id="458b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们计算excel数据集中的TSS。</p><p id="0471" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将找出每个数据点的(yn-ȳ)值，ȳ(平均y值)是15.564705888881</p><p id="97d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，数据集看起来像，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/b7cfa6502aeb0fd1940426958976c772.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wv0l_O_KH5C-BoWc-VMKqQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用Y值和所有Y值的平均值计算平方和</p></figure><p id="4e90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TSS =数据集中所有平方和的总和</p><p id="f4af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TSS = 297.5188235</p><p id="1778" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们已经计算了上面的RSS。我们来求出R的值，<br/> R = 1-(RSS/TSS) = 0.903293834。</p><p id="83a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们观察散点图，上面是最佳拟合线，下面是直线方程，excel已经计算出R值为0.9033，这是我们使用所有计算得到的值。</p><p id="7233" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于R值大于90%，因此强烈建议使用该模型来预测未来的分析。</p><h1 id="4e04" class="on lw it bd lx oo op oq ma or os ot md jz ou ka mg kc ov kd mj kf ow kg mm ox bi translated">结论</h1><p id="a594" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">回归模型是机器学习中的基本模型之一。使用这个模型，我们可以预测变量的结果。如果输出变量是分类的，我们将使用另一种称为分类模型的模型。</p><p id="b6f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一篇文章中，我们将看到如何在Python中使用线性回归模型。</p><p id="f257" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">感谢您阅读</strong>和<strong class="lb iu">快乐编码！！！</strong></p><h1 id="9a9d" class="on lw it bd lx oo op oq ma or os ot md jz ou ka mg kc ov kd mj kf ow kg mm ox bi translated">在这里查看我以前关于Python的文章</h1><ul class=""><li id="fa1d" class="mt mu it lb b lc mo lf mp li oy lm oz lq pa lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/joins-views-and-ctes-mysql-workbench-c1f64d88447f"> <strong class="lb iu">联接、视图和cte:MySQL工作台</strong> </a></li><li id="3b67" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/database-design-and-creation-mysql-workbench-488bffa8dbc5"> <strong class="lb iu">数据分析使用基本命令:MySQL Workbench </strong> </a></li><li id="9337" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/exploratory-data-analysis-eda-python-87178e35b14"> <strong class="lb iu">探索性数据分析(EDA): Python </strong> </a></li><li id="b47c" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/central-limit-theorem-clt-data-science-19c442332a32"> <strong class="lb iu">中心极限定理(CLT):数据科学</strong> </a></li><li id="2c4e" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/inferential-statistics-data-analysis-e59adc75c6eb"> <strong class="lb iu">推断统计:数据分析</strong> </a></li><li id="fa09" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/seaborn-python-8563c3d0ad41"><strong class="lb iu">Seaborn:Python</strong>T29】</a></li><li id="5b54" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://levelup.gitconnected.com/pandas-python-e69f4829fee1" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">熊猫:蟒蛇</strong> </a></li><li id="5759" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://levelup.gitconnected.com/matplotlib-python-ecc7ba303848" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">Matplotlib:Python</strong></a></li><li id="eee1" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://medium.com/coderbyte/numpy-python-f8c8f2bbd13e" rel="noopener"> <strong class="lb iu"> NumPy: Python </strong> </a></li></ul><h1 id="b881" class="on lw it bd lx oo op oq ma or os ot md jz ou ka mg kc ov kd mj kf ow kg mm ox bi translated">参考</h1><ul class=""><li id="a474" class="mt mu it lb b lc mo lf mp li oy lm oz lq pa lu my mz na nb bi translated"><strong class="lb iu">用于机器学习的线性回归:</strong><a class="ae ky" href="https://machinelearningmastery.com/linear-regression-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machinelingmastery . com/Linear-Regression-for-Machine-Learning/</a></li><li id="a831" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">线性回归:</strong><a class="ae ky" href="https://ml-cheatsheet.readthedocs.io/en/latest/linear_regression.html" rel="noopener ugc nofollow" target="_blank">https://ml-cheat sheet . readthedocs . io/en/latest/Linear _ Regression . html</a></li><li id="ba59" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">实现机器学习的线性回归:</strong><a class="ae ky" href="https://www.edureka.co/blog/linear-regression-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://www . edu reka . co/blog/Linear-Regression-for-Machine-Learning/</a></li><li id="acca" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">什么是机器学习中的线性回归:</strong><a class="ae ky" href="https://www.knowledgehut.com/blog/data-science/linear-regression-for-machine-learning" rel="noopener ugc nofollow" target="_blank">https://www . knowledge hut . com/blog/data-science/Linear-Regression-for-Machine-Learning</a></li></ul></div></div>    
</body>
</html>