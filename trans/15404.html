<html>
<head>
<title>Something From Nothing: Use NLP and ML to Extract and Structure Web Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从无到有:使用NLP和ML提取和结构化Web数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/something-from-nothing-use-nlp-and-ml-to-extract-and-structure-web-data-3f49b2f72b13?source=collection_archive---------11-----------------------#2020-10-23">https://towardsdatascience.com/something-from-nothing-use-nlp-and-ml-to-extract-and-structure-web-data-3f49b2f72b13?source=collection_archive---------11-----------------------#2020-10-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="83db" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="e0f4" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用NLTK、Spacy和BeautifulSoup等Python库从非结构化web数据创建结构化数据集。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/c3cc07dc9ba2a84c34e264c5f939b437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JYslOjFTIHANyeG33owWsg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">掌握你的数据。利用自然语言处理技术来构建最混乱的web数据。</p></figure><h1 id="358f" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">介绍</h1><p id="e93b" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在本文中，我们将基于<a class="ae ms" href="http://www.understandingwar.org/" rel="noopener ugc nofollow" target="_blank">战争研究所</a> (ISW)生产库创建一个结构化文档数据库。ISW为外交和情报专业人员创造信息产品，以更深入地了解世界各地发生的冲突。</p><p id="5834" class="pw-post-body-paragraph lw lx iq ly b lz mt ka mb mc mu kd me mf mv mh mi mj mw ml mm mn mx mp mq mr ij bi translated">要查看与本文相关的原始代码和笔记本，<a class="ae ms" href="https://colab.research.google.com/drive/1pTrOXW3k5VQo1lEaahCo79AHpyp5ZdfQ?usp=sharing" rel="noopener ugc nofollow" target="_blank">点击此链接</a>。要访问托管在Kaggle上的最终结构化数据集，<a class="ae ms" href="https://www.kaggle.com/connerbrew2/isw-web-scrape-and-nlp-enrichment" rel="noopener ugc nofollow" target="_blank">请点击此链接</a>。</p><p id="9e59" class="pw-post-body-paragraph lw lx iq ly b lz mt ka mb mc mu kd me mf mv mh mi mj mw ml mm mn mx mp mq mr ij bi translated">这篇文章将是一个web抽取、自然语言处理(NLP)和命名实体识别(NER)的练习。对于NLP，我们将主要使用开源Python库<strong class="ly ja"> NLTK </strong>和<strong class="ly ja"> Spacy </strong>。本文旨在演示web抽取和NLP的一个用例，<strong class="ly ja">而不是</strong>介绍这两种技术用法的综合初学者教程。如果您是NLP或web提取的新手，我会建议您遵循不同的指南，或者浏览一下<a class="ae ms" href="https://spacy.io/api/doc" rel="noopener ugc nofollow" target="_blank">空间</a>、<a class="ae ms" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">美丽群组</a>和<a class="ae ms" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>文档页面。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="a409" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">初始化变量</h1><p id="0176" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">首先，我们将在最终的结构化数据中初始化我们想要的数据字段。对于每个文档，我都要提取出<strong class="ly ja">标题</strong>、<strong class="ly ja">出版日期</strong>、<strong class="ly ja">人名</strong>、<strong class="ly ja">地名</strong>以及其他各种信息。我们还将增强文档中已经存在的信息——例如，我们将使用文档中的地名来获取相关坐标，这对以后可视化数据可能很有用。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="7d05" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">提取Hrefs</h1><p id="2fbe" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">我们将从ISW的产品库中提取我们的文档。首先，我们将抓取<strong class="ly ja">‘browse’</strong>页面来获取每个产品的href链接。然后，我们将这些链接存储在一个<em class="na">列表</em>中，供我们的提取函数稍后访问。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="338b" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">网页提取</h1><p id="989a" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">我们将编写的前几个函数是相当简单的文本提取。本教程并不是关于BeautifulSoup用法的教程——关于Python中web抓取的介绍，请点击这里查看文档<a class="ae ms" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="9412" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">获取日期</h2><p id="de05" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">对于我们的第一个函数，我们将提取出版日期。它扫描从产品网页中提取的html文档，找到一个类别为<strong class="ly ja">‘submitted’</strong>的字段。这包含我们的生产日期。</p><h2 id="5c46" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">获得标题</h2><p id="d321" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">接下来，我们需要产品标题。同样，这个字段被方便地标记为一个类<strong class="ly ja">‘title’</strong>。</p><h2 id="3063" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">获取所有文本</h2><p id="41c7" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">最后，我们将提取文档的全文。当我提取文本时，我通常遵循“先提取，后过滤”的网页提取方式。这意味着，在我的初始文本提取中，我对文本执行最少的过滤和处理。我更喜欢在以后的分析中进行处理，因为这是必要的。但是，如果您更高级，您可能希望对提取的文本进行比下面的函数演示的更多的预处理。我再次建议您遵循<a class="ae ms" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">文档</a>进行参考。</p><p id="5a9a" class="pw-post-body-paragraph lw lx iq ly b lz mt ka mb mc mu kd me mf mv mh mi mj mw ml mm mn mx mp mq mr ij bi translated">对于我的<em class="na"> get_contents </em>函数，我坚持使用最简单的方法——我在黑名单中列出了一些html父类，用于我不想提取的文本。然后，我从页面中提取所有文本，并将其附加到一个临时字符串中，该字符串又被附加到<em class="na">列表</em> <strong class="ly ja"> content_text </strong>中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="2d79" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">自然语言处理</h1><p id="9886" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">接下来，我们将弄清楚产品中引用了哪些国家。有许多API可以用来检查国家的文本内容，但是这里我们将使用一个简单的方法:一个世界上所有国家的列表。这个列表来自维基百科。</p><p id="6084" class="pw-post-body-paragraph lw lx iq ly b lz mt ka mb mc mu kd me mf mv mh mi mj mw ml mm mn mx mp mq mr ij bi translated">该函数在文档中识别出<strong class="ly ja">所有提及的国家</strong>后，使用基本的统计分析来识别哪些国家最突出，这些国家最有可能成为文档叙述的焦点。为此，该函数计算一个国家在整个文档中被提及的次数，然后找到被提及次数超过平均值的国家。这些国家随后被追加到一个<strong class="ly ja">关键国家</strong>T4】列表中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="0e74" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">命名实体识别:地点</h1><p id="62ce" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">接下来，我们要丰富我们的数据。最终，结构化数据的目标通常是执行某种分析或可视化-在这种国际冲突信息的情况下，按地理位置绘制信息很有价值。为此，我们需要与文档相对应的坐标。</p><h2 id="a193" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">获取地名</h2><p id="7326" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">首先，我们将使用<strong class="ly ja">自然语言处理(NLP) </strong>和<strong class="ly ja">命名实体识别(NER) </strong>从文本中提取地名。NLP是机器学习的一种形式，其中计算机算法使用语法和句法规则来学习文本中单词之间的关系。利用这种学习，NER能够理解某些单词在句子或段落中的作用。本教程并不是对NLP的全面介绍——要获得这样的资源，请在Medium 上尝试<a class="ae ms" href="https://medium.com/@ODSC/an-introduction-to-natural-language-processing-nlp-8e476d9f5f59" rel="noopener">这篇文章。</a></p><h2 id="4e47" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">从外部API获取坐标</h2><p id="fe10" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">为了找到地名的坐标，我们将使用<strong class="ly ja"> Open Cage API </strong>来查询坐标；您可以在这里创建一个免费帐户并获得一个API密钥<a class="ae ms" href="https://opencagedata.com/api" rel="noopener ugc nofollow" target="_blank">。有许多其他流行的地理编码API可供选择，但通过反复试验，我发现Open Cage在给定中东模糊地名的情况下具有最佳性能。</a></p><p id="2d92" class="pw-post-body-paragraph lw lx iq ly b lz mt ka mb mc mu kd me mf mv mh mi mj mw ml mm mn mx mp mq mr ij bi translated">首先，我们遍历从文档中检索到的每个地名，并在Open Cage中查询它。完成后，我们将交叉引用Open Cage结果和之前创建的<strong class="ly ja">提到的_countries </strong>列表。这将确保我们检索的查询结果位于正确的位置。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="9eb6" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">命名实体识别:人</h1><p id="27c5" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">接下来，我们将提取文档中提到的人名。为此，我们将再次使用来自<strong class="ly ja"> NER-D python库</strong>的NER算法。</p><h2 id="46ce" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">获取全名</h2><p id="d24d" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在最终的结构化数据中，我只想要全名。找到一个带有“杰克”或“约翰”的<em class="na">‘被提及人’</em>的数据条目会不会令人困惑？为了做到这一点，我们将再次使用一些基本的统计数据。当提到全名时，该函数将跟踪它们，通常是在文本的开头。</p><p id="b94b" class="pw-post-body-paragraph lw lx iq ly b lz mt ka mb mc mu kd me mf mv mh mi mj mw ml mm mn mx mp mq mr ij bi translated">当稍后提到部分名称时，它将引用全名列表来标识部分名称所引用的人。例如，如果一篇新闻报道是这样的:'<em class="na">乔·拜登正在竞选总统。乔最广为人知的身份是前总统巴拉克·奥巴马的副总统。</em>我们知道<strong class="ly ja">乔</strong>指的是<strong class="ly ja">乔·拜登</strong>，因为他的全名早在文中就给出了。该功能将以相同方式运行。</p><h2 id="f585" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">消除相似名称的冲突</h2><p id="9ab9" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在出现重复的情况下，该函数将使用之前用于country函数的相同统计数据。它将计算一个名字被提及的次数，并将其作为最可能的标识符。例子:乔·拜登和他的儿子亨特·拜登是受欢迎的美国政治家。乔·拜登是前任副总统。拜登现在正在与现任总统唐纳德·特朗普竞选总统我们知道<strong class="ly ja">“拜登”</strong>是指<strong class="ly ja">“乔·拜登”</strong>的上下文。根据文本的统计重点，这段话显然是关于乔·拜登，而不是亨特·拜登。</p><h2 id="a0c1" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">验证名称</h2><p id="a825" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">一旦该函数计算出所有提到的全名，它将把它们添加到一个列表中。然后，它将查询<strong class="ly ja">维基百科</strong>中的每个名字，以验证它是值得包含在结构化数据中的有影响力的人的名字。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="4eab" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">关键词提取:词频-逆文档频率</h1><p id="78ba" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">我们的下一个任务是从文本中提取关键词。最常见的方法是使用名为<strong class="ly ja">术语频率-逆文档频率(TF-IDF) </strong>的方法。基本上，TF-IDF模型测量一个术语或单词在单个文档中的使用频率，然后将其与它在整个文档语料库中的平均使用频率进行比较。如果一个术语在单个文档中频繁使用，而在整个文档语料库中很少使用，则该术语很可能代表该特定文档特有的关键字。本文并不打算全面概述TF-IDF模型。欲了解更多信息，请查看媒体上的<a class="ae ms" href="https://medium.com/datadriveninvestor/tf-idf-in-natural-language-processing-8db8ef4a7736" rel="noopener">这篇文章。</a></p><p id="6e55" class="pw-post-body-paragraph lw lx iq ly b lz mt ka mb mc mu kd me mf mv mh mi mj mw ml mm mn mx mp mq mr ij bi translated">首先，我们的函数将创建一个通常所说的<em class="na">‘单词包’</em>。这将跟踪每个文档中使用的每个单词。然后，它会统计每个文档中每个单词的每一次使用——<strong class="ly ja">词频</strong>。然后，取包含该术语的每个文档中每个句子的常用对数，即<strong class="ly ja">逆文档频率</strong>。然后将这些值写入一个矩阵中的坐标，然后对其进行排序，以帮助我们找到最有可能代表我们文档的唯一关键字的单词。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="6d22" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">主题建模</h1><p id="c6a3" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">NLP中最常见的任务之一就是<strong class="ly ja">主题建模</strong>。这是一种聚类形式，试图根据文本内容自动将文档分类。在这个具体的例子中，我想知道ISW正在报道什么话题。通过根据文本内容将文档分类，我可以很容易地对文档的主要思想有一个粗略的了解。</p><h2 id="9bdc" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">…向量化…</h2><p id="7687" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">对于这个例子，我将使用一个<a class="ae ms" href="https://medium.com/dataseries/k-means-clustering-explained-visually-in-5-minutes-b900cc69d175" rel="noopener"> <em class="na"> k-means聚类</em> </a>算法来进行主题建模。首先，我将再次使用TF-IDF算法对每个文档进行矢量化。<strong class="ly ja">矢量化</strong>是一个机器学习术语，指的是将非数字数据转换成计算机可以用来执行机器学习任务的数字空间数据。</p><h2 id="f498" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">最佳化</h2><p id="4e05" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">一旦文档被矢量化，辅助函数就会检查最佳的集群数量。<em class="na"/><strong class="ly ja"><em class="na">k</em></strong><em class="na">中</em><strong class="ly ja"><em class="na">k-意为</em> </strong> <em class="na"> ) </em>。在这种情况下，最佳数量为<strong class="ly ja"> 50 </strong>。一旦我找到了最佳的数字，在这个例子中我注释掉了那行代码，手动调整参数等于50。这是因为我正在分析的数据集不会经常改变，所以我可以预计最佳聚类的数量会随着时间的推移保持不变。对于变化更频繁的数据，您应该以变量的形式返回最佳聚类数，这将有助于您的聚类算法自动设置其最佳参数。我在我的时序分析文章中展示了一个例子。</p><h2 id="a620" class="nb lf iq bd lg nc nd dn lk ne nf dp lo mf ng nh lq mj ni nj ls mn nk nl lu iw bi translated">使聚集</h2><p id="b1ec" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">一旦每个聚类完成，我将每个聚类的编号<em class="na">(1–50)</em>保存到列表<strong class="ly ja"> cluster_numbers </strong>中，并将组成每个聚类的关键字保存到列表<strong class="ly ja"> cluster_keywords </strong>中。稍后将使用这些集群关键字为每个主题集群添加标题。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="8f3c" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">把它放在一起</h1><p id="ed33" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">最后，我们将提取我们的数据。使用我们之前得到的hrefs列表，是时候将我们所有的提取函数应用到web内容上了。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="85af" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">主题建模丰富化</h1><p id="4e93" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">我们的下一个问题是这样的:我们的聚类给了我们一个与每个聚类相关的单词列表，但是这些聚类的标题仅仅是数字。这给了我们绘制单词云或其他有趣的可视化的机会，可以帮助我们理解每个集群，但它对于结构化数据集中的<em class="na">一目了然的</em>理解来说并不有用。此外，我认为有些文档可能属于多个主题类别。k-means不支持多重聚类，所以我必须手动识别这些文档。首先，我将打印前几行关键字，以了解我正在处理的数据。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/7aa54ebf5860db5958358024306197a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ST8LWNZhhKOIDlPAV2Y4Sw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">与每个主题群相关联的一些关键词。我们将使用这些关键字将集群分类到预定义的类别中。</p></figure><p id="5d82" class="pw-post-body-paragraph lw lx iq ly b lz mt ka mb mc mu kd me mf mv mh mi mj mw ml mm mn mx mp mq mr ij bi translated">在对各种技术进行大量实验后，我决定采用一种非常简单的方法。我浏览了与每个集群相关的每个关键词列表，并注意到了每个列表中与特定主题相关的重要关键词。在这个阶段，<strong class="ly ja">领域知识</strong>是关键。例如，我知道，在一份ISW文件中，阿勒颇几乎肯定是指叙利亚内战。对于您的数据，如果您缺乏适当的领域知识，您可能需要做进一步的研究，咨询团队中的其他人，或者定义一种更高级的编程方法来命名您的分类。</p><p id="c581" class="pw-post-body-paragraph lw lx iq ly b lz mt ka mb mc mu kd me mf mv mh mi mj mw ml mm mn mx mp mq mr ij bi translated">然而，对于这个例子，简单的方法工作得很好。在记录了聚类列表中出现的几个重要的关键字之后，我自己制作了几个列表，其中包含了与结构化数据中我想要的最终主题类别相关的关键字。该函数只是将每个集群的关键字列表与我创建的列表进行比较，然后根据列表中的匹配项分配一个主题名称。然后，它将这些最终主题附加到一个列表<strong class="ly ja"> topic_categories </strong>中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="4b27" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">数据库创建</h1><p id="56b7" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">最后一步是将所有提取的数据汇集在一起。对于这个数据，我更喜欢<strong class="ly ja"> JSON </strong>格式。这是因为我想以不同的方式构建某些类型的数据——例如,<strong class="ly ja">位置</strong>字段将包含一个包含地名、纬度和经度的<strong class="ly ja">字典列表</strong>。在我看来，JSON格式是将这种格式化数据存储到本地磁盘的最有效方式。我还在文档数据库<strong class="ly ja"> MongoDB </strong>中备份了这个数据库的副本，但这不是本文的重点。如果您对将结构化数据保存到文档数据库感兴趣，请尝试使用媒体上的<a class="ae ms" href="https://medium.com/free-code-camp/learn-mongodb-a4ce205e7739" rel="noopener">这篇文章。</a></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="my mz l"/></div></figure><h1 id="9f5f" class="le lf iq bd lg lh li lj lk ll lm ln lo kf lp kg lq ki lr kj ls kl lt km lu lv bi translated">摘要</h1><p id="1671" class="pw-post-body-paragraph lw lx iq ly b lz ma ka mb mc md kd me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">现在我们完成了！我们从网页中提取链接，然后使用这些链接从网站中提取更多的内容。我们使用这些内容，然后使用<strong class="ly ja">外部API</strong>、ML <strong class="ly ja">聚类算法</strong>和<strong class="ly ja"> NLP </strong>来提取和增强这些信息。如今，NLP是商业智能社区中最流行的词汇之一，现在您可以自信地在NLP中执行中级操作来进行文档分析。可以进行<strong class="ly ja"> TF-IDF矢量化</strong>、<strong class="ly ja">关键词提取</strong>、<strong class="ly ja">主题建模</strong>。这些都是NLP的基石。如果您有更多的问题或需要信息，请联系<a class="ae ms" href="https://www.linkedin.com/in/cmbrew/" rel="noopener ugc nofollow" target="_blank">并祝您在未来的NLP工作中好运！</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/b5363995905a326e7267a0795d71d80c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-haR32bNzkjLZ_j9HSScPw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">我们的最终产品。一个ISW产品的文档数据库条目。</p></figure></div></div>    
</body>
</html>