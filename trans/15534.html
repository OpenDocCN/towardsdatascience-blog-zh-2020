<html>
<head>
<title>A basic intro to GANs (Generative Adversarial Networks)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成对抗网络的基本介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-basic-intro-to-gans-generative-adversarial-networks-c62acbcefff3?source=collection_archive---------24-----------------------#2020-10-26">https://towardsdatascience.com/a-basic-intro-to-gans-generative-adversarial-networks-c62acbcefff3?source=collection_archive---------24-----------------------#2020-10-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0093" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><div class=""><h2 id="2546" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">甘是如何工作的？他们为什么这么有趣？</h2></div><p id="7b39" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">我有机会在甘斯做了3个月的研究实习。我读了很多科学论文和博客。在这篇文章中，我试图传达我所学到的和觉得值得分享的基本知识。</em></p><h1 id="f954" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">目录</h1><p id="571a" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">1)简介<br/>2)GANs是如何工作的？<br/> 2.1)原理:生成器vs鉴别器<br/> 2.2)数学上:双人极大极小游戏<br/> 3)为什么GANs这么有趣？<br/> 4)结论和参考文献</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mi"><img src="../Images/445ffc29afa8f97f9462a5bef01b8a99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9RZd1Gk5kMgM0GymWP8YGg.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated"><strong class="bd my">图1 </strong>:使用GANs从原始图像生成的现实而虚构的名人肖像。来源:英伟达<strong class="bd my">【4】</strong>。</p></figure></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="66d1" class="ll lm iq bd ln lo ng lq lr ls nh lu lv kf ni kg lx ki nj kj lz kl nk km mb mc bi translated">1)简介</h1><p id="d47a" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">在过去的十年里，可用数据量的爆炸式增长——大数据——算法的优化和计算能力的不断进化，使<strong class="kq ja">人工智能</strong> (AI)能够执行越来越多的人类任务。2017年，Andrey Ng预测<a class="ae nl" href="https://www.gsb.stanford.edu/insights/andrew-ng-why-ai-new-electricity" rel="noopener ugc nofollow" target="_blank">人工智能将像电一样产生深远的影响</a>。</p><p id="0f0f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果我们声称AI的目的是模拟人类的智能，那么主要的难点就是创造力。在人工智能领域，我们谈论<strong class="kq ja">生成模型</strong>，当今最流行的模型之一是GANs(表示“生成对抗网络”)。在2016年的一次研讨会上，<a class="ae nl" href="https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/" rel="noopener ugc nofollow" target="_blank"> Yann LeCun称GANs是“过去20年深度学习领域最酷的想法”</a>。</p><p id="901a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">甘斯<strong class="kq ja"/>引入了<strong class="kq ja">对抗学习</strong>的概念，因为它们存在于两个神经网络之间的竞争中。这些技术使研究人员能够创建看起来逼真但完全由计算机生成的人脸照片。他们还允许制作有争议的“深度造假”视频。实际上，GANs可以用来模仿任何数据分布(图像、文本、声音等。).</p><p id="d0b7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">GANs 2018年的结果示例见<strong class="kq ja">图1 </strong>:这些图像是假的，但非常真实。这些虚构的名人肖像的生成，来自Celeba-HQ的真实肖像数据库，由30，000幅图像组成，耗时19天。生成的图像大小为1024×1024。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="f45b" class="ll lm iq bd ln lo ng lq lr ls nh lu lv kf ni kg lx ki nj kj lz kl nk km mb mc bi translated">GANs是如何工作的？</h1><p id="a493" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated"><strong class="kq ja">生成对抗网络</strong> (GANs)是一种带有隐式密度估计的生成模型，是无监督学习的一部分，使用两个神经网络。因此，我们理解“生成性对抗网络”中的“生成性”和“网络”这两个术语。</p><h2 id="907b" class="nm lm iq bd ln nn no dn lr np nq dp lv kx nr ns lx lb nt nu lz lf nv nw mb iw bi translated">2.1)原理:发生器与鉴别器</h2><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nx"><img src="../Images/24d9f9027c1b80affe99ad6c4bc65d80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uzJMtPVXbmmgbr_--wSYfg.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated"><strong class="bd my">图二</strong>:发生器和鉴别器的作用。来源:斯坦福cs 231n<strong class="bd my">【2】</strong>。</p></figure><p id="177d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其原理是一个双人游戏:一个被称为生成器的神经网络和一个被称为鉴别器的神经网络。<strong class="kq ja">发生器</strong>试图通过生成看起来真实的图像来欺骗鉴别器，而<strong class="kq ja">鉴别器</strong>试图区分真实和虚假的图像。因此，我们理解“生成对抗网络”中的“对抗”一词。参见<strong class="kq ja">图2 </strong>。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ny"><img src="../Images/5d848f167ec82ef0c746782a179399fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S380jjAl-bXiz3K2H3hiVw.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated"><strong class="bd my">图3 </strong>:解释:发生器和鉴别器的作用。来源:<a class="ae nl" href="https://www.tensorflow.org/beta/tutorials/generative/dcgan" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>。</p></figure><p id="ed4f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在<strong class="kq ja">图2 </strong>的左下方，我们可以看到我们的发生器样本来自一个简单的分布:随机噪声。生成者可以解释为艺术家，鉴别者可以解释为艺术批评家。参见<strong class="kq ja">图3 </strong>。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ny"><img src="../Images/d552d133b41ebd04b7c1ec2bd7873224.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ObRIjyLfGwJRAQ0Km_mvoQ.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated"><strong class="bd my">图4 </strong>:发电机和鉴别器培训。来源:<a class="ae nl" href="https://www.tensorflow.org/beta/tutorials/generative/dcgan" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>。</p></figure><p id="8968" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在训练过程中，发生器逐渐变得更擅长创建看起来真实的图像，而鉴别器变得更擅长区分它们。当鉴别器不再能够区分真实图像和伪造图像时，该过程达到平衡。参见<strong class="kq ja">图4 </strong>。因此，如果鉴别器训练有素，并且生成器设法生成看起来真实的图像来欺骗鉴别器，那么我们就有了一个良好的生成模型:我们正在生成看起来像训练集的图像。</p><p id="65f8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这个训练阶段之后，我们只需要生成器对新的(错误的)真实数据进行采样。我们不再需要鉴别器了。请注意，随机噪声保证了发生器不会总是产生相同的图像(这会欺骗鉴别器)。</p><p id="7e89" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">请注意，在图4 中的<strong class="kq ja">训练开始时，发生器仅产生一个看起来不像训练数据的随机噪声。</strong></p><h2 id="45cc" class="nm lm iq bd ln nn no dn lr np nq dp lv kx nr ns lx lb nt nu lz lf nv nw mb iw bi translated">2.2)数学上:双人极大极小游戏</h2><p id="8138" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">生成器<em class="lk"> G </em>和鉴别器<em class="lk"> D </em>以<strong class="kq ja">双人极大极小游戏</strong>的形式联合训练。最小最大目标函数是:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nz"><img src="../Images/5f0f4234c89c614b7c7c667b75d657a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fiwFI-CUQvYnyPLXnOMpiA.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated"><strong class="bd my">方程式(1) </strong></p></figure><p id="3849" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中<em class="lk"> θ_g </em>为<em class="lk"> G </em>的参数，<em class="lk"> θ_d </em>为<em class="lk"> D </em>的参数。</p><p id="5445" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面我们简单的把<em class="lk"> D_{θ_d} </em>称为<em class="lk"> D </em>，把<em class="lk"> G_{θ_g} </em>称为<em class="lk"> G </em>。</p><p id="5626" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">根据定义，<em class="lk"> D </em>输出真实图像在区间<em class="lk"> [0，1]</em>:<br/><em class="lk">D(x)</em>等于<em class="lk"> 1 </em>(或者接近于<em class="lk"> 1 </em>)如果<em class="lk"> D </em>认为<em class="lk"> x </em>是真实数据，<br/><em class="lk">D(x)</em>等于<em class="lk">0<em class="lk"/></em></p><p id="c701" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以证明，在均衡状态下，<em class="lk"> D </em>处处输出<em class="lk"> 1/2 </em>，因为<em class="lk"> D </em>不知道如何区分虚假生成的数据和真实数据。</p><p id="9e49" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因为<em class="lk">x∞p _ { data }</em>，<em class="lk"> x </em>是实数据。根据<em class="lk"> G </em>的定义，<em class="lk"> G(z) </em>是一个假生成的数据。例如，<em class="lk"> x </em>将是一只猫的真实图像，而<em class="lk"> G(z) </em>将是一只猫的假生成图像。因此，<em class="lk"> D(x) </em>是鉴别器对于真实输入<em class="lk"> x </em>的输出，而<em class="lk">D(G(z)】</em>是鉴别器对于伪生成数据<em class="lk"> G(z) </em>的输出。</p><p id="ab74" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在<strong class="kq ja">【1】</strong>之后，来自<strong class="kq ja">等式(1) </strong>的两人极大极小游戏被写成使得<em class="lk"> θ_g </em>和<em class="lk"> θ_d </em>进化，使得子节<strong class="kq ja"> 2.1) </strong>中的以下几点为真:<br/>鉴别器<em class="lk"> D </em>试图区分真实数据<em class="lk"> x </em><br/>更准确地说，鉴别器<em class="lk"> D </em>与<em class="lk"> θ_d </em> ( <em class="lk"> θ_g </em>固定)一起运行，以最大化目标函数，使得<em class="lk"> D(x) </em>接近于<em class="lk"> 1 </em> ( <em class="lk"> x </em>为真实数据)，并且使得<em class="lk">D(G(z)</em>接近于<em class="lk"> 0<br/>生成器<em class="lk"> G </em>试图欺骗鉴别器<em class="lk"> D </em>认为其生成的假数据是真实的。<br/>更准确地说，生成器<em class="lk"> G </em>与<em class="lk"> θ_g </em> ( <em class="lk"> θ_d </em>固定)一起运行，以最小化目标函数，使得<em class="lk">D(G(z)】</em>接近于<em class="lk"> 1 </em>(一个错误生成的数据被鉴别器检测为真)。</em></p><p id="a49a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">虽然我们是在无监督学习中(数据没有标注)，但是我们选择由<em class="lk"> G </em>生成的数据有一个<em class="lk"> 0 </em>标签为假(不管鉴别器返回什么)，真实的学习数据有一个<em class="lk"> 1 </em>标签为真。因此，我们可以定义一个损失函数。</p><p id="c151" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">论文<strong class="kq ja">【1】</strong>证明了极小极大对策对于<em class="lk"> p_g = p_{data} </em>有一个全局(唯一)最优，其中<em class="lk"> p_g </em>是生成分布，<em class="lk"> p_{data} </em>是真实数据分布。然而，在实践中，让<em class="lk"> p_g </em>向<em class="lk"> p_{data} </em>收敛并不容易。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="c77c" class="ll lm iq bd ln lo ng lq lr ls nh lu lv kf ni kg lx ki nj kj lz kl nk km mb mc bi translated">3)为什么甘这么有意思？</h1><p id="c815" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">生成模型有几个非常有用的应用:彩色化、超分辨率、艺术作品的生成等。一般来说，使用模拟模型优于真实模型的优点是计算速度更快。</p><p id="26ca" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Goodfellow的教程<strong class="kq ja">【3】</strong>和Stanford的讲座<strong class="kq ja">【2】</strong>中给出了很多有趣的例子。特别是Goodfellow在4:15到12:33的会议“<a class="ae nl" href="https://youtu.be/HGYYEUSm-0Q?t=255" rel="noopener ugc nofollow" target="_blank">生成性对抗性网络(NIPS 2016教程)</a>”中给出的例子，让人印象深刻。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi oa"><img src="../Images/5b427533620664da4861dfb06eb6857e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ap1aL0-wmznNK7tdiH3teA.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated"><strong class="bd my">图5 </strong> : CycleGAN:用GANs把真实的影像转置成现实的虚构影像。来源:柏克莱人工智能研究(BAIR)实验室<strong class="bd my">【5】</strong>。</p></figure><p id="6fec" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">图5 给出了一个例子。伯克利大学研究人员开发的CycleGan将这些真实图像转换成现实的虚构图像，反之亦然。这个概念被称为<strong class="kq ja">图像到图像转换</strong>，是一类视觉和图形问题，其目标是使用对齐图像对的训练集来学习输入图像和输出图像之间的映射。对于Tensorflow，CycleGAN上有一个<a class="ae nl" href="https://www.tensorflow.org/tutorials/generative/cyclegan" rel="noopener ugc nofollow" target="_blank">教程</a>。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ob"><img src="../Images/cfb7b43fdb664f114c5dc89da7a5e175.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qNEaI8j-rupiedmROmtoKw.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated"><strong class="bd my">图6 </strong>:使用GANs的几种图像变换。来源:柏克莱人工智能研究(BAIR)实验室<strong class="bd my">【6】</strong>。</p></figure><p id="be90" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第二个例子如图6 中的<strong class="kq ja">所示。例如，空中转地图功能对谷歌地图或类似的应用程序非常有用，边缘转照片功能可以帮助设计师。</strong></p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="05ce" class="ll lm iq bd ln lo ng lq lr ls nh lu lv kf ni kg lx ki nj kj lz kl nk km mb mc bi translated">4)结论</h1><p id="9e71" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">GANs的应用增长迅速，尤其是在图像方面。我相信GANs对公司来说是非常有趣的。例如，GANs可以生成新医学图像的逼真图像，图像到图像的翻译可以帮助设计人员绘图并更具创造性。此外，当我们只有一百张图像并且希望有更多时，GANs可以用于<strong class="kq ja">数据扩充</strong>。</p><p id="a01c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">GANs也被开发用于二进制输出(生病与否)或离散输出(四舍五入的血压、四舍五入的体重……)<strong class="kq ja">【7】</strong>。这项关于表格数据的新研究带来了很多好处，特别是对于<strong class="kq ja">隐私</strong>的目的。例如，医院可以向他们的合作伙伴发送虚假的真实数据(保持特征之间的相关性),而不是发送Excel表格中的机密数据。</p><p id="72f4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">感谢阅读，希望这篇文章对你有用。不要犹豫，在评论中给出反馈。随时联系我 <a class="ae nl" href="https://twitter.com/sylvaincom" rel="noopener ugc nofollow" target="_blank"> <em class="lk">推特</em> </a> <em class="lk">。</em></p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="3e8d" class="ll lm iq bd ln lo ng lq lr ls nh lu lv kf ni kg lx ki nj kj lz kl nk km mb mc bi translated">参考</h1><p id="f9ff" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">伊恩·古德菲勒、让·普热-阿巴迪、米尔扎、徐炳、戴维·沃德-法利、谢尔吉尔·奥泽尔、亚伦·库维尔和约舒阿·本吉奥。"<a class="ae nl" href="https://www.semanticscholar.org/paper/Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie/54e325aee6b2d476bbbb88615ac15e251c6e8214" rel="noopener ugc nofollow" target="_blank">生成对抗网</a>"<em class="lk"> NIPS </em> (2014)。<br/><strong class="kq ja">【2】</strong>费-、和杨威。<a class="ae nl" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank"> CS231n:用于视觉识别的卷积神经网络</a>。<a class="ae nl" href="https://www.youtube.com/watch?v=5WoItGTWV54" rel="noopener ugc nofollow" target="_blank">第13讲|生成模型</a>。<em class="lk">斯坦福大学</em>(2017年春季)。<br/><strong class="kq ja">【3】</strong>伊恩·古德菲勒。"<a class="ae nl" href="https://www.semanticscholar.org/paper/NIPS-2016-Tutorial%3A-Generative-Adversarial-Networks-Goodfellow/2c740e574eea66fdcf473e15ed2c228baef2eccd" rel="noopener ugc nofollow" target="_blank"> NIPS 2016教程:生成对抗网络</a>"ArXiv abs/1701.00160  (2017)。<br/><strong class="kq ja">【4】</strong>泰罗·卡拉斯、蒂莫·艾拉、s·莱恩和j·莱蒂宁。<a class="ae nl" href="https://www.semanticscholar.org/paper/Progressive-Growing-of-GANs-for-Improved-Quality%2C-Karras-Aila/744fe47157477235032f7bb3777800f9f2f45e52" rel="noopener ugc nofollow" target="_blank">为了提高质量、稳定性和多样性而逐步种植甘蔗。<em class="lk">ArXiv ABS/1710.10196</em>(2018)。<br/><strong class="kq ja">【5】</strong>朱俊彦、t·帕克、菲利普·伊索拉和阿列克谢·阿·埃夫罗斯。"</a><a class="ae nl" href="https://www.semanticscholar.org/paper/Unpaired-Image-to-Image-Translation-Using-Networks-Zhu-Park/c43d954cf8133e6254499f3d68e45218067e4941" rel="noopener ugc nofollow" target="_blank">使用循环一致对抗网络的不成对图像到图像翻译</a>"<em class="lk"> 2017 IEEE计算机视觉国际会议(ICCV)</em>(2017):2242–2251。<br/><strong class="kq ja">【6】</strong>菲利普·伊索拉、、周廷辉和阿列克谢·埃夫罗斯。"<a class="ae nl" href="https://www.semanticscholar.org/paper/Image-to-Image-Translation-with-Conditional-Isola-Zhu/8acbe90d5b852dadea7810345451a99608ee54c7" rel="noopener ugc nofollow" target="_blank">用条件对抗网络进行图像到图像的翻译</a>"<em class="lk"> 2017年IEEE计算机视觉与模式识别大会(CVPR)</em>(2017):5967–5976。<br/><strong class="kq ja"/>e .崔、s .比斯瓦尔、b .马林、j .杜克、w .斯图尔特和孙。<a class="ae nl" href="https://www.semanticscholar.org/paper/Generating-Multi-label-Discrete-Patient-Records-Choi-Biswal/5320c90d52541d5581f0a8c4b75d9b2da81299ce" rel="noopener ugc nofollow" target="_blank">使用生成式对抗网络生成多标签离散患者记录</a>。<em class="lk"> MLHC </em> (2017)。</p></div></div>    
</body>
</html>