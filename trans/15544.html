<html>
<head>
<title>What Twitter learned from the Recsys 2020 Challenge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter从Recsys 2020挑战赛中学到了什么</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-twitter-learned-from-the-recsys-2020-challenge-d3ae2f7ccf0f?source=collection_archive---------34-----------------------#2020-10-26">https://towardsdatascience.com/what-twitter-learned-from-the-recsys-2020-challenge-d3ae2f7ccf0f?source=collection_archive---------34-----------------------#2020-10-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7f04" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a>，2020年推荐系统挑战</h2><div class=""/><div class=""><h2 id="1a05" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">今年，Twitter赞助了<a class="ae kr" href="https://recsys-twitter.com/" rel="noopener ugc nofollow" target="_blank"> RecSys 2020挑战赛</a>，提供了大量的用户参与数据集。在本帖中，我们描述了获胜团队的挑战和见解。</h2></div><p id="93f7" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><em class="lo">本文由来自Twitter Cortex的卢卡·贝利、阿波夫·夏尔马、·谢、、丹·谢伯勒、马克斯·汉斯迈尔和·施共同撰写。</em></p></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><p id="ceee" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi lw translated">电子商务系统是现代社交网络和电子商务平台的重要组成部分。他们旨在最大限度地提高用户满意度以及其他关键业务目标。与此同时，科学界在构建和测试新模型以根据用户兴趣定制内容时，缺乏大规模的公共社交网络数据集。在过去的一年里，我们一直在努力解决这个问题。</p><p id="7bde" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">Twitter与<a class="ae kr" href="https://recsys.acm.org/recsys20/" rel="noopener ugc nofollow" target="_blank"> RecSys conference </a>合作赞助<a class="ae kr" href="https://recsys-twitter.com/" rel="noopener ugc nofollow" target="_blank"> 2020挑战赛</a>。我们发布了一个由两周内的推文和用户参与组成的数据集，在两周内有1.6亿条公共推文用于培训，4000万条公共推文用于验证和测试。</p><p id="f8bd" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在这篇文章中，我们描述了由Nvidia，Learner和Wantely团队提交的数据集和三个获奖作品。我们试图对帮助获胜者取得成果的选择做出一般性的结论，特别是:</p><ul class=""><li id="65e3" class="mf mg it ku b kv kw ky kz lb mh lf mi lj mj ln mk ml mm mn bi translated">最重要的功能</li><li id="67de" class="mf mg it ku b kv mo ky mp lb mq lf mr lj ms ln mk ml mm mn bi translated">特征选择和模型训练的实验速度极快</li><li id="0fd2" class="mf mg it ku b kv mo ky mp lb mq lf mr lj ms ln mk ml mm mn bi translated">一般化的对抗性验证[1]</li><li id="98be" class="mf mg it ku b kv mo ky mp lb mq lf mr lj ms ln mk ml mm mn bi translated">内容功能的使用</li><li id="f437" class="mf mg it ku b kv mo ky mp lb mq lf mr lj ms ln mk ml mm mn bi translated">在神经网络上使用决策树</li></ul><p id="634f" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我们希望这些发现将对更广泛的研究社区有用，并启发推荐系统的未来研究方向。</p><p id="e397" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi lw translated">挑战的参与者被要求预测用户参与四种互动中任何一种的概率:<em class="lo">喜欢</em>，<em class="lo">回复</em>，<em class="lo">转发</em>，以及<em class="lo">引用</em>推文。根据两个指标对提交的内容进行评估:相对于我们提供的简单基线的相对<a class="ae kr" href="https://en.wikipedia.org/wiki/Cross_entropy" rel="noopener ugc nofollow" target="_blank">交叉熵</a> (RCE)，以及精度-召回曲线下的<a class="ae kr" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" rel="noopener ugc nofollow" target="_blank">面积</a> (PR-AUC)。</p><figure class="mu mv mw mx gt my gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi mt"><img src="../Images/3cf1f949ca87d9a2f2328a8b2a5b85b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Al2K3kALHwve5NI6"/></div></div><p class="nf ng gj gh gi nh ni bd b be z dk translated">一段时间内训练、测试和验证数据集的表示。</p></figure><p id="b6ca" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">特别注意保持数据集与推特平台同步。该数据集反映了平台的变化，例如，当一条推文被删除时，用户将其个人资料设为私有，或者将其完全删除。提交的内容也会被重新评估，排行榜也会根据重新计算的指标进行更新[2]。</p><figure class="mu mv mw mx gt my gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nj"><img src="../Images/8c96c6693faf5aed856bda3a324418b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uncdoGmsvqoBG1gz"/></div></div><p class="nf ng gj gh gi nh ni bd b be z dk translated">数据集要素的表示。它们分为用户功能(针对作者和读者)、推文功能和参与功能。</p></figure><p id="3a5f" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">今年的挑战赛竞争尤为激烈，注册用户超过1000人。参与者在整个挑战过程中积极提交解决方案，并在挑战的第一阶段修改其团队组成(根据提交指南)。最后阶段有20个竞争者，平均团队规模为4人。此外，团队开发了127种不同的方法试图赢得挑战。在整个挑战过程中，参与者的活跃度一直很高，在最后几天，当参与者完善他们的提交材料时，活跃度达到顶峰。最终结果出现在<a class="ae kr" href="https://recsys-twitter.com/final_leaderboard/results" rel="noopener ugc nofollow" target="_blank">排行榜</a>上。</p><p id="20da" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">伴随而来的<a class="ae kr" href="https://recsys.acm.org/recsys20/challenge-workshop/" rel="noopener ugc nofollow" target="_blank">RecSys Challenge 2020 Workshop</a>共收到12篇论文，由计划委员会评审。其中九篇论文被接受。</p><h1 id="bda1" class="nk nl it bd nm nn no np nq nr ns nt nu ki nv kj nw kl nx km ny ko nz kp oa ob bi translated">第一名:英伟达</h1><p id="b7a1" class="pw-post-body-paragraph ks kt it ku b kv oc kd kx ky od kg la lb oe ld le lf of lh li lj og ll lm ln im bi translated"><strong class="ku jd">面向推荐系统的GPU加速特征工程和训练。</strong> Nvidia的论文[3]描述了训练<a class="ae kr" href="https://xgboost.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"> xgboost </a>模型来预测每个交互事件。总的重点是为这个模型创建有用的特性。它强调了快速特征提取和模型训练是该方法成功的关键。本文在附录中列出了4个模型中每个模型的15个最有用的特性。</p><p id="3ada" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">从数据集中快速提取特征并重新训练是获胜者和亚军之间的关键区别。功能工程管道和培训管道运行时间都不到一分钟。除此之外，<em class="lo">目标编码</em>(均值编码+加法平滑)用于不同的分类特征和特征组合，包括这些组合的目标均值。作者还从推文的内容中创建分类特征(例如，两个最流行的词和两个最不流行的词)。<em class="lo">针对特征重要性和选择的对抗性验证</em>用于通过选择更一般化的特征来防止过度拟合。基于树的模型的集成方法用于产生最终模型。</p><h1 id="7386" class="nk nl it bd nm nn no np nq nr ns nt nu ki nv kj nw kl nx km ny ko nz kp oa ob bi translated">第二名:学习者</h1><p id="c977" class="pw-post-body-paragraph ks kt it ku b kv oc kd kx ky od kg la lb oe ld le lf of lh li lj og ll lm ln im bi translated"><strong class="ku jd">用深度语言模型预测Twitter参与度。</strong>学习者方法[4]将深度学习与梯度增强决策树(GBDT)相结合，并专注于创建不同的功能。作者使用启发式方法设计了467个功能，并使用<a class="ae kr" href="https://en.wikipedia.org/wiki/BERT_(language_model)" rel="noopener ugc nofollow" target="_blank">伯特</a>和<a class="ae kr" href="https://arxiv.org/abs/1911.02116" rel="noopener ugc nofollow" target="_blank"> XLM-R </a>创建了推文的文本表示(使用了目标推文文本和最近参与推文的文本)。</p><p id="df5b" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这个条目和其他条目之间的关键区别是使用了预先训练的自然语言处理(NLP)模型BERT和XLM-R以及微调。第一层微调是以无人监管的方式完成的。接下来，将语言模型与其他特征相结合，以在监督设置中进行微调。该模型是一个多层感知(MLP ),有四个头，每个头对应一种参与类型。该论文还使用注意力来创建用户过去十次交互的嵌入。将注意力和目标tweet作为关键，将这些嵌入结合起来。此外，使用启发式特征，例如参与用户、推特创建者、推特特征和用户-创建者交互特征的不同表示。与其他条目一样，本文使用<a class="ae kr" href="https://xgboost.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"> xgboost </a>进行特征工程和选择，并将<a class="ae kr" href="https://en.wikipedia.org/wiki/Power_transform#Yeo%E2%80%93Johnson_transformation" rel="noopener ugc nofollow" target="_blank"> Yeo-Johnson变换</a>应用于分类特征和非标准化连续特征。</p><h1 id="3847" class="nk nl it bd nm nn no np nq nr ns nt nu ki nv kj nw kl nx km ny ko nz kp oa ob bi translated">第三名:肆意</h1><p id="5546" class="pw-post-body-paragraph ks kt it ku b kv oc kd kx ky od kg la lb oe ld le lf of lh li lj og ll lm ln im bi translated">用于预测多种类型推特参与度的堆叠集成模型。 Wantely的提交材料[5]提出了一种预测推特参与度的两阶段方法。第一级分类器是轻量级的，并且仅使用概括不同目标(例如，转发等)的特征，并且具有相似的训练/测试准确度。第二级分类器使用轻量级分类器的输出作为特征以及特定于目标的特征。</p><p id="80bc" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">上游可归纳模型生成下游模型使用的特征。通过这样做，作者认为，每种参与类型的下游模型都能够通过消耗通用上游模型的预测，从所有其他参与的数据中受益。除此之外，本文还通过对抗验证<em class="lo">、</em>直接评估训练和测试数据集之间的特性分布差距，来确定哪些特性是可概括的，如Nvidia条目中所示。</p><p id="c98c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi lw translated"><span class="l lx ly lz bm ma mb mc md me di"> T </span>以下是所有提交材料中的许多共同见解。我们强调主要主题:</p><p id="2201" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><strong class="ku jd">获奖机型中使用的有用功能——目标编码为王。</strong>首先，<em class="lo">目标编码</em>(用目标变量的均值代替一个分类变量)让问题更简单。它同时用于用户和作者id，从而对用户的平均参与度进行编码。第二，大量的<a class="ae kr" href="https://developers.google.com/machine-learning/crash-course/feature-crosses/video-lecture" rel="noopener ugc nofollow" target="_blank">特性交叉</a>被使用【6】。</p><p id="456a" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><strong class="ku jd">特征选择的快速实验。</strong>快速测试多种假设的能力一直是数据科学竞赛不可或缺的一部分，并再次证明了这一挑战的决定性。Nvidia团队能够在GPU上运行整个管道。这使得他们训练一个模型(包括特征工程)只需要2分18秒，而在CPU上则需要几个小时。</p><p id="d012" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><strong class="ku jd">用对抗性验证应对过度拟合。</strong>竞争对手使用的一种常见技术是构建一个鉴别器来预测训练集和测试/验证集之间的差异。基于在模型的特征选择中使用的重要性分数，通过移除最重要的特征，可以帮助模型更好地概括。这项技术有助于避免过度拟合训练数据。</p><p id="e070" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><strong class="ku jd">内容特性的使用。</strong>今年的数据集与去年的一个显著区别是我们提供的内容特征。在三篇获奖论文中，有两篇论文对BERT的内容特性进行了复杂的运用。NLP的深度学习已经证明了它对推荐系统的有用性，尽管我们认为在这个领域还有更多改进的空间。</p><p id="1908" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><strong class="ku jd">决策树vs深度学习。</strong><a class="ae kr" rel="noopener" target="_blank" href="/machine-learning-part-18-boosting-algorithms-gradient-boosting-in-python-ef5ae6965be4">梯度增强决策树</a> (GBDT)的一个显著优势是，不需要标准化和计算出单个特征的规模。这有助于加快所有获奖论文的迭代速度。</p><p id="04be" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi lw translated"><span class="l lx ly lz bm ma mb mc md me di">在</span>计算机视觉和NLP等领域，深度学习模型通过利用<a class="ae kr" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank"> CNN </a> s和transformers展示了令人印象深刻的进步。基于这一挑战的结果，我们仍然不明白什么是推荐系统中深度学习的良好架构。我们呼吁研究社区共同寻找推荐系统的最佳深度学习架构。</p><p id="6a9c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我们还注意到，虽然我们只评估了提交的模型性能，但我们的生产系统中还有许多其他约束。延迟对我们来说是一个大问题:模型需要在毫秒内对推文进行评分。在这种情况下，需要仔细检查集合方法的使用。整体中每一步的附加延迟可能导致它们对于我们的目的来说太慢。</p><p id="50f8" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">我们感谢所有参与者和我们的同事，是他们让这项挑战成为可能。我们相信，发布大规模数据集将有助于在推荐系统领域取得新的进展。Twitter现在比以往任何时候都更致力于帮助外部研究工作，最近为学术研究人员发布了<a class="ae kr" href="https://developer.twitter.com/en/use-cases/academic-researchers" rel="noopener ugc nofollow" target="_blank">新的API端点</a>，以帮助促进进一步的探索和合作。</p></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><p id="5d1b" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[1] J. Pan等.<a class="ae kr" href="https://arxiv.org/pdf/2004.03045.pdf" rel="noopener ugc nofollow" target="_blank">针对用户导向自动化系统中概念漂移问题的对抗性验证方法</a> (2020) arXiv:2004.03045 .引入了对抗性验证，这是一种被多个参与者使用的强大技术。</p><p id="4478" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[2] L. Belli等人<a class="ae kr" href="https://arxiv.org/pdf/2004.13715.pdf" rel="noopener ugc nofollow" target="_blank">Twitter主页时间线上的隐私感知推荐系统挑战</a> (2020) arXiv:2004.13715提供了关于挑战和数据集的详细信息。</p><p id="6adc" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[3] B. Schifferer等人，<a class="ae kr" href="https://github.com/rapidsai/deeplearning/blob/main/RecSys2020/RecSysChallenge2020.pdf" rel="noopener ugc nofollow" target="_blank">面向推荐系统的GPU加速特征工程与训练</a> (2020)。继续。推荐系统挑战2020。Nvidia的提交，也在他们的<a class="ae kr" href="https://medium.com/rapids-ai/winning-solution-of-recsys2020-challenge-gpu-accelerated-feature-engineering-and-training-for-cd67c5a87b1f" rel="noopener">博客文章</a>中描述。</p><p id="b945" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[4] M. Volkovs等人，用深度语言模型预测Twitter参与度(2020)。继续。推荐系统挑战2020。学习者的提交。</p><p id="fa2f" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[5] S .戈达等人，预测多种类型推特参与的堆叠集成模型(2020)。继续。推荐系统挑战2020。万特利的屈服。</p><p id="9057" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[6]在<a class="ae kr" href="https://github.com/rapidsai/deeplearning/blob/main/RecSys2020/RecSysChallenge2020.pdf" rel="noopener ugc nofollow" target="_blank"> Nvidia论文</a>的附录中提供了对不同目标具有重要性的功能的完整列表，如转发/回复。</p></div><div class="ab cl lp lq hx lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="im in io ip iq"><p id="d77e" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><em class="lo"/><a class="ae kr" href="https://recsys.acm.org/recsys20/challenge/" rel="noopener ugc nofollow" target="_blank"><em class="lo">RecSys挑战赛</em> </a> <em class="lo">由Nazareno Andrade、Walter Anelli、Amra、Jessie Smith、Gabriele Sottocornola组织，Luca Belli、Michael Bronstein、Alexandre Lung Yut Fong、Sofia Ira Ktena、Frank Portman、Alykhan Tejani、Xie、和Shi对数据集做出了贡献。</em></p><p id="6ed0" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated"><em class="lo">见我的</em> <a class="ae kr" rel="noopener" target="_blank" href="https://towardsdatascience.com/graph-deep-learning/home"> <em class="lo">其他帖子</em> </a> <em class="lo">上媒，或者关注我的</em> <a class="ae kr" href="https://twitter.com/mmbronstein" rel="noopener ugc nofollow" target="_blank"> <em class="lo">推特</em> </a> <em class="lo">。</em></p></div></div>    
</body>
</html>