<html>
<head>
<title>Beyond CUDA: GPU Accelerated Python for Machine Learning on Cross-Vendor Graphics Cards Made Simple</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超越CUDA: GPU加速Python，简化跨厂商显卡的机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3?source=collection_archive---------10-----------------------#2020-11-13">https://towardsdatascience.com/beyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3?source=collection_archive---------10-----------------------#2020-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e5f4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">跨供应商显卡(AMD、高通、NVIDIA &amp; friends)上GPU加速Python的实际深度探讨使用Kompute Python框架和Vulkan SDK构建机器学习算法</h2></div><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="kk kl l"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">博客帖子的视频版本</p></figure><p id="aa72" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">机器学习算法——以及许多其他高级数据处理范式——非常适合GPU计算提供的并行架构。这推动了近年来用于加速计算的显卡的发展和采用的大幅增长。这也推动了围绕并发优化技术的令人兴奋的研究，例如<a class="ae lm" href="https://mxnet.apache.org/versions/1.7/api/faq/model_parallel_lstm.html" rel="noopener ugc nofollow" target="_blank">模型并行</a>和<a class="ae lm" href="https://en.wikipedia.org/wiki/Data_parallelism" rel="noopener ugc nofollow" target="_blank">数据并行</a>。</p><p id="d1e6" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在本文中，您将学习如何用Python编写自己的GPU加速算法，您将能够在几乎任何GPU硬件上运行这些算法，包括非NVIDIA GPUs。我们将介绍核心概念，并展示如何用几行代码就能开始使用<a class="ae lm" href="https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute" rel="noopener ugc nofollow" target="_blank"> <strong class="ks ir"> Kompute Python框架</strong> </a> <strong class="ks ir">。</strong></p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi ln"><img src="../Images/7531f258641c84235d4548ba1526aecc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EZ27EB0hMtEdgm0d"/></div></div><p class="km kn gj gh gi ko kp bd b be z dk translated">本农、塔尔和托尔斯滕·霍夫勒。“揭开并行和分布式深度学习的神秘面纱:深度并发分析。”<em class="lv">美国计算机学会计算调查(CSUR)</em>52.4(2019):1–43。</p></figure><p id="0d08" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">首先，我们将构建一个简单的GPU加速Python脚本，该脚本将并行相乘两个数组，这将介绍GPU处理的基础知识。然后，我们将在GPU上从头开始编写一个逻辑回归算法。以下是我们将涉及的核心主题，以及相应的资源链接:</p><ol class=""><li id="60be" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll mb mc md me bi translated"><a class="ae lm" href="https://pypi.org/project/kp/" rel="noopener ugc nofollow" target="_blank"> Kompute python包</a>安装</li><li id="eba5" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">Python中GPU加速的<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute/blob/master/python/test/test_array_multiplication.py" rel="noopener ugc nofollow" target="_blank">数组乘法示例</a></li><li id="52aa" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">Python中GPU加速的<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute/blob/master/python/test/test_logistic_regression.py" rel="noopener ugc nofollow" target="_blank">逻辑回归示例</a></li></ol><p id="4f44" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">阅读这篇文章的人只需要<strong class="ks ir">基本编程经验</strong>，不需要GPU计算知识。你可以在<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute" rel="noopener ugc nofollow" target="_blank"> <strong class="ks ir">主库</strong>、</a>中找到完整的代码，我们还创建了一个在线Google Colab笔记本，在那里你可以免费使用GPU运行这个例子——你可以在<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute/tree/master/examples/python" rel="noopener ugc nofollow" target="_blank"> <strong class="ks ir">中找到这个链接</strong> </a>。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi mk"><img src="../Images/38ac557b4bc9e7f921981934a73735a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LBLVNwHYnCmZ6IDZ.jpg"/></div></div><p class="km kn gj gh gi ko kp bd b be z dk translated">带有GPU示例的Google Colab笔记本</p></figure><h1 id="6bc0" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">进入Kompute &amp; Vulkan SDK</h1><p id="d2dd" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">我们今天将使用的Python框架有两个部分，这两个部分都在名称本身中——Vulkan SDK和Kompute。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/69fe34f4969de848be6f3e7c63c68b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/0*mzEbYNdCJ129eSz3"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">与Khronos成员一起玩“瓦尔多在哪里”(图片由Vincent Hindriksen通过<a class="ae lm" href="https://streamhpc.com/blog/2017-05-04/what-is-khronos-as-of-today/" rel="noopener ugc nofollow" target="_blank"> StreamHPC </a>提供)</p></figure><p id="0440" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Vulkan SDK是由Khronos Group领导的一个开源项目，Khronos Group是一个由众多技术公司组成的联盟，致力于定义和推进移动和桌面媒体(和计算)技术的开放标准。</p><p id="fec7" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">大量备受瞩目的(和新的)机器学习框架，如谷歌的<a class="ae lm" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>、脸书的<a class="ae lm" href="https://github.com/pytorch/pytorch" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>、腾讯的<a class="ae lm" href="https://github.com/Tencent/ncnn" rel="noopener ugc nofollow" target="_blank"> NCNN </a>、阿里巴巴的<a class="ae lm" href="https://github.com/alibaba/MNN" rel="noopener ugc nofollow" target="_blank">MNN</a>——等等——已经采用Vulkan作为他们的核心跨供应商GPU计算SDK。这主要是为了启用跨平台和跨厂商显卡支持的框架。</p><p id="f790" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">正如您所想象的，Vulkan SDK提供了对GPU的非常低级的C / C++访问，这允许非常专业的优化。这对GPU计算来说是一项巨大的资产，主要缺点是冗长，需要500–2000多行C++代码才能获得编写应用程序逻辑所需的基本样板文件。这可能导致昂贵的开发周期和错误，从而导致更大的问题。这是我们启动Kompute项目的主要动机之一。</p><p id="9e8d" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute#vulkan-kompute" rel="noopener ugc nofollow" target="_blank"><strong class="ks ir">Kompute Python包</strong> </a>通过优化的C++绑定构建在Vulkan SDK之上，暴露了Vulkan的核心计算能力。Kompute是Python <a class="ae lm" href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units" rel="noopener ugc nofollow" target="_blank"> GPGPU框架</a>，我们将在本教程中使用它来构建GPU加速机器学习算法。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nj"><img src="../Images/d2dcfcf18bf93b58d2dd857ee46bc8cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hkFiBPfbdHQqhHKA.png"/></div></div><p class="km kn gj gh gi ko kp bd b be z dk translated">Kompute <a class="ae lm" href="https://ethicalml.github.io/vulkan-kompute/" rel="noopener ugc nofollow" target="_blank">文档</a>(图片由作者提供)</p></figure><h1 id="2f1f" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">安装Python Kompute包</h1><p id="3961" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">为了让我们开始使用Kompute Python包，我们需要安装它所需的依赖项。该包在Pypi中可用，这意味着我们可以用<code class="fe nk nl nm nn b">pip install</code>来安装它。但是，在使用机器之前，您需要在机器上安装以下关键组件:</p><ul class=""><li id="0ea1" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated">CMAKE v3.41+(安装在<a class="ae lm" href="https://tulip.labri.fr/TulipDrupal/?q=node/1081" rel="noopener ugc nofollow" target="_blank"> Windows </a>、<a class="ae lm" href="https://vitux.com/how-to-install-cmake-on-ubuntu-18-04/" rel="noopener ugc nofollow" target="_blank"> Linux (Ubuntu) </a>、<a class="ae lm" href="https://stackoverflow.com/a/59825656/1889253" rel="noopener ugc nofollow" target="_blank"> Mac </a>)</li><li id="d025" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated">通过<a class="ae lm" href="https://vulkan.lunarg.com/sdk/home" rel="noopener ugc nofollow" target="_blank">官网</a>安装的Vulkan SDK</li><li id="ec8a" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated">C++编译器(例如用于linux / mac的gcc，用于Windows的MSVC)</li></ul><p id="6907" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一旦安装了这些依赖项，您只需运行:</p><ul class=""><li id="b7d8" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">pip install kp==0.5.1</code></li></ul><p id="989c" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">您现在应该会看到一条成功消息，确认Kompute Python包已经安装。你可以在库中提供的Google Colab笔记本<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute/tree/master/examples/python" rel="noopener ugc nofollow" target="_blank">中自己尝试一下，可以用GPU设置。</a></p><h1 id="84b6" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">编写你的第一个Kompute: GPU乘法</h1><p id="b1a5" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">为了使用Kompute构建我们的第一个简单的数组乘法GPU计算应用程序，我们将编写一个简单的python程序来完成以下任务:</p><ol class=""><li id="eebf" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll mb mc md me bi translated">创建一个Kompute管理器(默认选择设备0)</li><li id="4a71" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">创建Kompute张量来保存数据(两个输入一个输出)</li><li id="ec95" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">在GPU中初始化Kompute张量</li><li id="a1dc" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">定义在GPU上运行的代码</li><li id="ef6e" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">针对Kompute张量调度GPU着色器执行</li><li id="11f5" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">使用Kompute操作将GPU输出数据映射到本地张量</li><li id="3491" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">打印您的结果</li></ol><p id="0679" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">所需的完整Python代码非常少，因此我们可以在下面展示完整的脚本。我们将更详细地分解每个部分。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="f3b4" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">1.创建一个Kompute管理器(默认选择设备0)</h2><p id="880c" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">首先，我们将创建Kompute管理器，它负责创建和管理所有底层Vulkan资源。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="e72d" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">正如你所看到的，这里我们正在初始化我们的Kompute管理器，默认情况下，它在设备0上创建所有的基本Vulkan资源(在我的例子中，它是一个NVIDIA卡，设备1是我的集成显卡)。对于更高级的用例，还可以提供您想要加载的底层GPU队列——在<a class="ae lm" rel="noopener" target="_blank" href="/parallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc">另一篇教程</a>中，我们展示了这如何导致显著的加速，但这超出了本文的范围。</p><h2 id="b949" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">2.创建Kompute张量来保存数据(两个输入一个输出)</h2><p id="0a49" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">我们现在将创建用于输入和输出的Kompute张量。这些将保存所需的数据，这些数据将被映射到GPU来执行这个简单的乘法。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="b450" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">创建张量时，数据仅在本地CPU内存(即RAM)中初始化，但是为了在GPU中使用它，我们必须将数据映射到GPU内存中。</p><h2 id="6ff2" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">3.在GPU中初始化Kompute张量</h2><p id="3272" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">现在我们已经用本地数据创建了张量，我们将把数据映射到GPU中。为此，我们将使用<code class="fe nk nl nm nn b">eval_tensor_create_def</code>，它将初始化底层Vulkan缓冲区和GPU内存，并执行各自到GPU的映射。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="1102" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">4.定义在GPU上运行的代码</h2><p id="58ec" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">现在我们已经初始化了必要的Kompute张量分量，并且它们被映射到GPU内存中，我们可以添加将在GPU中执行的Kompute算法。这被称为“着色器”代码，我们使用<code class="fe nk nl nm nn b">pyshader </code>库构建它。你可以在下面看到完整的着色器代码，我们将分解下面的每一部分。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="853e" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">GPU着色器代码可以用装饰器<code class="fe nk nl nm nn b">@ps.python2shader</code>定义为Python函数，这里的参数包括我们将使用的变量。这包括我们将要处理的张量输入和输出，参数格式如下:</p><ul class=""><li id="3151" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">&lt;param≥=(“&lt;memory&gt;”, &lt;binding&gt;, &lt;type&gt;, ...)</code></li></ul><p id="b9f3" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这种情况下，我们使用带浮点值的张量，它本质上等同于<code class="fe nk nl nm nn b">ps.Array</code>值，用<code class="fe nk nl nm nn b">ps.f32</code>浮点值作为元素。</p><p id="cfbd" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">第一个参数<code class="fe nk nl nm nn b">index</code>的类型为<code class="fe nk nl nm nn b">GlobalInvocationId</code>，为着色器提供执行GPU分派结构中的当前索引位置。这使我们能够知道我们当前正在并行执行循环中运行什么索引，这是我们从组件<code class="fe nk nl nm nn b">i = index.x</code>中提取的内容——我们在这里选择<code class="fe nk nl nm nn b">x</code>的原因是因为执行索引可以定义为一个<code class="fe nk nl nm nn b">vec3</code>组件，其中将有<code class="fe nk nl nm nn b">inedx.x</code>、<code class="fe nk nl nm nn b">index.y</code>和<code class="fe nk nl nm nn b">index.z</code>的执行索引。</p><p id="6469" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">最后一部分是实际使用的等式，在这种情况下，它是第一个和第二个参数的简单乘法，并存储在输出(第三个)参数中。</p><h2 id="6be5" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">5.针对Kompute张量调度GPU着色器执行</h2><p id="cc8c" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">为了运行上面的着色器，我们将使用<code class="fe nk nl nm nn b">eval_algo_data_def </code>函数。这个Kompute操作所需的参数包括绑定到GPU指令的张量，以及我们在上面的Python函数中定义的GPU着色器代码。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="bbb7" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">值得一提的是，Kompute还允许用户将着色器作为原始glsl字符串传递，或者作为SPIR-V二进制文件或原始glsl/hlsl文件的文件路径。对于上下文，<a class="ae lm" href="https://www.khronos.org/opengl/wiki/SPIR-V" rel="noopener ugc nofollow" target="_blank"> SPIR-V是GPU可以用来处理相关操作的中间表示</a>。</p><h2 id="c25c" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">6.使用Kompute操作将GPU输出数据映射到本地张量</h2><p id="ad40" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">一旦算法成功运行，结果数据现在将被我们保存在我们的输出张量的GPU内存中。我们现在可以使用函数<code class="fe nk nl nm nn b">eval_tensor_sync_local_def</code>将张量GPU内存同步到本地张量中。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="69d4" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">7.打印您的结果</h2><p id="68f0" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">最后，我们可以打印出张量的输出数据。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="4fa1" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">当你运行它时，你会看到输出张量的值被打印出来。就这样，你写了你的第一个Kompute！</p><p id="9c8d" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">虽然看起来不明显，但上面介绍了GPU计算中核心概念和设计思维的一些直觉，同时还抽象了一些更深入的概念。在接下来的几节中，我们将提供更具体的术语，最后我们还将概述一组文章，如果您有兴趣了解更多信息，可以深入研究。</p><h1 id="6c88" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">潜入机器学习直觉</h1><p id="4241" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">现在，我们将研究更高级的GPU计算用例，具体实现“你好，机器学习世界”:<strong class="ks ir">逻辑回归</strong>。在讨论实现之前，我们将提供一些概念和术语的直觉，这些概念和术语将在下面的章节中使用。</p><p id="4d63" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在机器学习中，我们总是有两个阶段，训练和推理。在下图中，您可以看到两个简化的流程。最上面是训练流程，在这里你识别一些数据，提取一些特征，训练一个模型，直到你对精度满意为止。一旦您有了一个经过训练的模型，您就可以持久化模型“权重”,并将模型部署到第二个工作流中，在第二个工作流中，模型将对看不见的数据执行推理。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi oc"><img src="../Images/10ce29488bcbfca55aafb9bc4f5d25bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qjzd2Q5vinPtO5c6"/></div></div><p class="km kn gj gh gi ko kp bd b be z dk translated">数据科学流程(图片由作者提供)</p></figure><p id="f680" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这种情况下，我们将有一个输入数据集<code class="fe nk nl nm nn b">X</code>，其中每个元素是一对<code class="fe nk nl nm nn b">xi</code>和<code class="fe nk nl nm nn b">xj</code>。我们的输入数据如下:</p><ul class=""><li id="9d59" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">xi = { 0, 1, 1, 1, 1 }</code></li><li id="2e84" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">xj = { 0, 0, 0, 1, 1 }</code></li></ul><p id="77ee" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">利用该输入数据，要预测的预期目标值<code class="fe nk nl nm nn b">Y</code>将如下:</p><ul class=""><li id="86d6" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">Y = {0, 0, 0, 1, 1}</code></li></ul><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi od"><img src="../Images/20466429c92984ce5c97be7d0eea198b.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*C9Sl7wor6-pydyD7NXcC5Q.png"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">来自<a class="ae lm" href="https://www.datasciencecentral.com/profiles/blogs/why-logistic-regression-should-be-the-last-thing-you-learn-when-b" rel="noopener ugc nofollow" target="_blank"> DS Central </a>的逻辑回归示例</p></figure><p id="71d9" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们在机器学习中的核心目标是学习使用这些训练数据来找到函数(和参数),这将允许我们从新的“以前看不见的”输入中预测值<code class="fe nk nl nm nn b">Y</code>。</p><p id="f738" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">值得注意的是，预测值将被定义为<code class="fe nk nl nm nn b">ŷ</code>，它是用我们的“预测”函数计算的值，不同于我们上面定义的<code class="fe nk nl nm nn b">Y</code>的“真”或“实际”值。</p><p id="a769" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将用于逻辑回归的函数如下:</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/19c357a4ded8af30cc6d1268af9def43.png" data-original-src="https://miro.medium.com/v2/resize:fit:204/format:webp/0*4FrI-KB2_9n7y0Go.png"/></div></figure><p id="c9d3" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们来分解这个函数:</p><ul class=""><li id="8416" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">z</code> —是我们的线性映射函数</li><li id="feca" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">ŷ</code>—结果预测输出</li><li id="b8ca" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">X</code>ᵀ——向量矩阵的转置，我们将表示为<code class="fe nk nl nm nn b">x_i</code>和<code class="fe nk nl nm nn b">x_j</code></li><li id="4ca7" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">σ</code>—sigmoid函数，将在下文详细介绍</li></ul><p id="4eeb" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们希望通过机器学习算法学习的参数是:</p><ul class=""><li id="b7fe" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">w</code> —将应用于输入的权重</li><li id="f084" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">b</code> —将要添加的偏差</li></ul><p id="56b3" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">还有环绕函数<code class="fe nk nl nm nn b">σ </code>也就是sigmoid函数。该函数迫使我们的输入更接近0或1，这可以直观地视为我们的预测为“真”或“假”的概率，定义如下:</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi of"><img src="../Images/9af0d474a479168f7634cf5d15210a46.png" data-original-src="https://miro.medium.com/v2/resize:fit:234/format:webp/0*B4vJKaqNBrPgeAG_.png"/></div></figure><p id="f429" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这就是现在的预测/推理功能，它将允许我们处理来自新数据点的预测。例如，如果我们说我们有一组新的看不见的输入<code class="fe nk nl nm nn b">X = { (0, 1) }</code>，并且我们假设在通过我们的训练数据运行我们的机器学习算法之后，学习到的参数是<code class="fe nk nl nm nn b">W = (1, 1), b = 0 </code>(稍后我们将这样做)，那么我们将能够通过我们的预测函数来运行它，方法是将这些值代入如下:</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi og"><img src="../Images/1b53b2b2bd2fe2500a8800df2a449cb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/0*vPB55aWa874FYfwa.png"/></div></figure><p id="2bf2" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这种情况下，预测是<code class="fe nk nl nm nn b">0.73...</code>，这将是一个积极的预测。当然，这只是为了演示一旦我们知道了参数<code class="fe nk nl nm nn b">W</code>和<code class="fe nk nl nm nn b">b.</code>，我们的推理函数会是什么样子</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/27f47a93433b6c683e51cc3609a5eecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/1*e88JKNWAFok3vpjeuPfHig.gif"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">从<a class="ae lm" href="https://mi-academy.com/2018/10/04/the-history-of-gradient-descent/" rel="noopener ugc nofollow" target="_blank"> ML学院</a>可视化梯度下降</p></figure><p id="6b64" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们学习参数的方法是进行预测，计算误差，然后相应地重新调整权重。用于基于“预测误差”来“重新调整”权重的方法将通过利用梯度下降来完成。这将被重复多次以找到更精确的参数。</p><p id="5155" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为此，我们将需要使用每个公式的导数。第一个，是我们的线性映射函数<code class="fe nk nl nm nn b">z</code>的导数，使用变量<code class="fe nk nl nm nn b">w</code>、<code class="fe nk nl nm nn b">z </code>和<code class="fe nk nl nm nn b">b. </code>的偏导数。首先，偏导数<code class="fe nk nl nm nn b">∂z</code>:</p><ul class=""><li id="8b5b" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">∂z = z(X) — y</code></li></ul><p id="8ae7" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">其中变量定义如下:</p><ul class=""><li id="fb89" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">∂z</code> —线性映射函数的偏导数<code class="fe nk nl nm nn b">z(x)</code></li><li id="e9cf" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">z(X)</code> —应用于输入<code class="fe nk nl nm nn b">x</code>的线性映射函数的结果</li><li id="822b" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">y</code> —输入x预期的实际值标签</li></ul><p id="2dd3" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">类似地，w和b的导数分别如下:</p><ul class=""><li id="3de4" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">∂w = (X — ∂z)/m</code></li><li id="3d38" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">∂b = ∂z/m</code></li></ul><p id="9581" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这种情况下，<code class="fe nk nl nm nn b">m</code>是输入元素的总数。</p><p id="fca0" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们现在能够使用上述方法重新调整参数，如下所示:</p><ul class=""><li id="c6e4" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">w = w — θ · ∂w</code></li><li id="722a" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">b = b — θ · ∂b</code></li></ul><p id="1279" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这种情况下,<code class="fe nk nl nm nn b">θ</code>是学习率，顾名思义，它控制每次迭代中参数被修改的比率。直观地说，越小，算法收敛所需的迭代次数就越多，然而，如果学习速率太大，它将超调，导致永远无法收敛(从上面的图像中，你可以想象它将不断从一边跳到另一边，永远不会到达底部)。</p><p id="bbac" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了计算损失，我们将使用对数损失函数，也称为交叉熵损失函数。该功能定义如下:</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/438f3c7e5939cdf5b9919cd184f6fd0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/0*TgKVkmzh9rpbnlaD.png"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">对数损失(交叉熵损失)函数</p></figure><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi oj"><img src="../Images/77a242942a7e6a22a1e8dfe5b796bc39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SQh95-Fn58JTDgzX.png"/></div></div><p class="km kn gj gh gi ko kp bd b be z dk translated">直观的图表显示ML Mastery 的成本函数<a class="ae lm" href="https://machinelearningmastery.com/how-to-score-probability-predictions-in-python/" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="4ed4" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">函数本身是这样设置的，预测类和期望类之间的差异越大，误差就越大(你可以看到如果预测类在完全不同的标签上，它会受到多大的惩罚)。</p><p id="1110" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">损失函数将为我们提供一个在迭代中改进算法的思路。</p><p id="1192" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">最后，这里最重要的一点将是我们如何利用GPU的并行架构来优化计算背后的直觉。在这种情况下，我们可以同时处理多个输入参数，称为微批处理，然后批量重新调整参数。这被称为数据并行化，是许多可用技术之一。在下一节中，我们将看到这是如何实现的，即传递一小批输入，存储权重，然后在下一次迭代之前重新调整它们。</p><blockquote class="ok ol om"><p id="adec" class="kq kr on ks b kt ku jr kv kw kx ju ky oo la lb lc op le lf lg oq li lj lk ll ij bi translated">注意:在这篇文章中，我们不会深入研究太多细节，也不会研究机器学习的最佳实践，但是在文章的最后，我们将列出一系列广泛的来源，供有兴趣将其机器学习(或GPU计算)知识提升到一个新水平的人使用。</p></blockquote><p id="4398" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在我们已经讨论了一些核心概念，我们将能够了解实现。</p><h1 id="6125" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">机器学习GPU着色器实现</h1><p id="8bda" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">首先，我们将从GPU计算着色器开始，它是将在GPU中执行的代码。完整的着色器概述如下，我们将详细分解每个部分来解释每个部分是做什么的。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="44a7" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">1.定义输入和输出参数</h2><p id="e6a9" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">首先，我们定义所有输入参数，这些参数类似于我们在前面章节中提到的输入和输出组件。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="fbc4" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果您还记得，在上一节的结尾，我们提到了如何利用微批处理的概念来使用GPU处理的并行架构。这在实践中意味着，我们将把X的多个实例一次传递给GPU来处理，而不是期望GPU一个接一个地处理它。这就是为什么我们看到上面有一个分别用于<code class="fe nk nl nm nn b">xi, xj, y, wOuti, wOutj, </code>和<code class="fe nk nl nm nn b">bOut</code>的数组。</p><p id="6999" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">更详细地说:</p><ul class=""><li id="f148" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated">作为数组<code class="fe nk nl nm nn b">x_i</code>和<code class="fe nk nl nm nn b">x_j</code>的输入<code class="fe nk nl nm nn b">X </code>将保存微批量的输入</li><li id="5c5b" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated">数组<code class="fe nk nl nm nn b">y </code>将保存微批量输入的所有预期标签</li><li id="213e" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated">两个输入权重参数<code class="fe nk nl nm nn b">w_in_i</code>和<code class="fe nk nl nm nn b">w_out_j</code>将用于计算预测</li><li id="1436" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated">将用于计算预测的输入参数<code class="fe nk nl nm nn b">b</code></li><li id="1fca" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated">输出权重<code class="fe nk nl nm nn b">w_out_i</code>和<code class="fe nk nl nm nn b">w_out_j </code>包含权重，并将存储所有应减去的微量批次的W的导数</li><li id="6438" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated">类似地，输出偏置数组包含所有微批次的<code class="fe nk nl nm nn b">b </code>的导数，这些导数应在批次中减去</li><li id="ccfd" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated">最后<code class="fe nk nl nm nn b">l_out</code>包含了损失将被返回的输出数组</li></ul><h2 id="ab8d" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">2.将输入缓冲区的大小定义为M</h2><p id="439d" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">我们还收到常数<code class="fe nk nl nm nn b">M</code>，它将是元素的总数——如果你记得这个参数将用于导数的计算。我们还将看到这些参数是如何从Python Kompute端传递到着色器的。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="a021" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在我们已经定义了所有的输入和输出参数，我们可以开始定义核心逻辑，它将包含我们的机器学习训练算法的实现。</p><h2 id="479a" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">3.跟踪执行索引</h2><p id="386c" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">我们需要跟踪全局调用的当前索引。由于GPU并行执行，这些运行中的每一个都将直接并行运行，因此这允许当前执行一致地跟踪当前正在执行的迭代索引。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="7e2f" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">4.根据输入参数定义变量</h2><p id="7a90" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">我们现在可以开始准备所有的变量，我们将在整个算法中使用。我们所有的输入都是缓冲数组，所以我们希望将它们存储在<code class="fe nk nl nm nn b">vec2 </code>和<code class="fe nk nl nm nn b">float32</code>变量中。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="eec6" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这种情况下，我们基本上明确了当前“线程运行”所使用的变量。GPU架构由稍微更细微的执行结构组成，涉及线程块、内存访问限制等——但是我们不会在本文中讨论这些。</p><p id="c23c" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在我们进入更有趣的部分——实现推理/预测逻辑。下面我们将实现推理逻辑来计算<code class="fe nk nl nm nn b">ŷ</code>，这涉及到线性映射函数，以及我们上面定义的sigmoid函数。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="54e0" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">5.计算导数以“重新调整”参数</h2><p id="7761" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">现在我们有了<code class="fe nk nl nm nn b">y_hat</code>，我们现在可以用它来计算导数(<code class="fe nk nl nm nn b">∂z</code>、<code class="fe nk nl nm nn b">∂w</code>和<code class="fe nk nl nm nn b">∂b</code>)，在本例中是当前执行的索引输入元素的导数。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="c597" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">6.计算当前迭代的损失</h2><p id="1591" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">使用预期的预测输出和计算的预测输出，我们现在能够计算当前迭代的损失。如上所述，我们使用对数损失(交叉熵)函数来计算损失。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="0695" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">7.存储输出参数的数据</h2><p id="ee11" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">最后，我们能够将所有相应的计算指标传递到输出缓冲区。这将允许我们为下一次迭代重新调整。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="64e8" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们现在已经完成了着色器，它将使我们能够在GPU中训练逻辑回归算法-我们现在将涵盖调用该着色器并协调机器学习训练和推理的其余逻辑。下面概述了完整的脚本，您也可以在带有GPU的Google Colab笔记本中尝试一下。</p><h1 id="f3da" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">Kompute的机器学习编排</h1><p id="362d" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">我们将使用Kompute的一些更高级的组件，这些组件可以在下图中更直观地看到。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi or"><img src="../Images/108e55e577c2bd0430e080d0d85f5272.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/0*Env2QAL1QVnE-XeR.jpg"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">Kompute <a class="ae lm" href="https://ethicalml.github.io/vulkan-kompute/overview/reference.html" rel="noopener ugc nofollow" target="_blank">建筑设计</a>(图片由作者提供)</p></figure><p id="7951" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Kompute的核心是Kompute“序列”和“操作”，用于GPU动作。一个Kompute段可以记录和执行一批Kompute操作，以便更有效地处理。在这个例子中，我们将利用序列来管理机器学习处理的更有效的执行。</p><p id="58c1" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">类似于上面的例子，我们将会设置以下步骤:</p><ol class=""><li id="c20e" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll mb mc md me bi translated">用明确定义的设备创建Kompute管理器</li><li id="f4b7" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">创建所有需要的Kompute张量</li><li id="2f4a" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">通过Kompute管理器执行Kompute Tensor GPU初始化</li><li id="7ea5" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">创建Kompute序列并记录执行操作</li><li id="7671" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">迭代100次:运行微批处理执行并更新权重</li><li id="7d68" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll mb mc md me bi translated">打印结果参数，用于将来的推断</li></ol><p id="5d58" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如你所见，这比我们上面使用的简单例子更复杂。在这种情况下，我们将使用Kompute序列，而不是直接使用Kompute管理器，因为我们希望对命令进行更深入的控制，这些命令可以被记录下来并批量发送到GPU。我们将在讲述每个步骤时更详细地讨论这一点。让我们开始吧。</p><h2 id="271b" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">1.用明确定义的设备创建Kompute管理器</h2><p id="07f5" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">我们将创建带有明确定义的设备0的Kompute管理器——您可以根据需要定义另一个设备。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="421d" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">2.创建所有需要的Kompute张量</h2><p id="116d" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">现在我们将创建所有需要的张量。在这一小节中，你会注意到我们将引用着色器中使用的所有缓冲区/数组。我们还将介绍参数传递的顺序如何与数据绑定到着色器的方式相关联，以便可以访问数据。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="1c51" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们还将它们存储在一个列表<code class="fe nk nl nm nn b">params</code>中，以便于访问:</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="c71c" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">3.通过Kompute管理器执行Kompute Tensor GPU初始化</h2><p id="bda4" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">Kompute张量初始化是相当标准的，所以我们将能够通过管理器直接完成这一步，就像我们之前在简单的数组乘法示例中所做的那样。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="874d" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">4.创建Kompute序列并记录执行操作</h2><p id="333c" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">在本节中，我们将清除Kompute序列的先前记录，并开始记录一组序列。您会注意到，与上一节不同，在这种情况下，我们不会直接运行<code class="fe nk nl nm nn b">eval()</code>,因为我们必须首先记录操作。</p><p id="df7b" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">您还会注意到，我们将通过不同的功能记录三种类型的Kompute操作:</p><ul class=""><li id="d2d9" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><code class="fe nk nl nm nn b">record_tensor_sync_device(...)</code> —此操作通过将张量的本地数据映射到GPU数据，确保张量与其GPU内存同步。在这种情况下，这些张量使用设备专用内存来提高处理效率，因此在操作中使用分级张量来执行映射(为了提高效率，在整个操作中重复使用分级张量)。在这里，我们只想同步输入权重，因为这些权重将随各自的导数在本地更新。</li><li id="c3ad" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">record_algo_base_data(...)</code> —这是Kompute操作，它将我们上面编写的着色器与所有本地CPU/主机资源绑定在一起。这包括提供张量。值得一提的是，作为参数提供的张量的索引是它们通过各自的绑定在着色器中映射的顺序。</li><li id="61d9" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><code class="fe nk nl nm nn b">record_tensor_sync_local(...)</code> —该Kompute操作执行与上述同步操作类似的一组指令，但它不是将数据复制到GPU存储器，而是相反。这个Kompute操作将GPU内存中的数据映射到本地张量向量，因此可以从GPU/主机访问它。如你所见，我们只在输出张量中运行这个操作。</li></ul><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="8486" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">5.迭代100次:运行微批处理执行并更新权重</h2><p id="3cfc" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">现在我们已经记录了命令，我们可以开始运行这些预加载命令的执行。在这种情况下，我们将运行一个微批处理迭代的执行，然后在本地更新参数，以便在接下来的迭代中使用它们。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><h2 id="60b5" class="nq mm iq bd mn nr ns dn mr nt nu dp mv kz nv nw mx ld nx ny mz lh nz oa nb ob bi translated">7.打印结果参数，用于将来的推断</h2><p id="b5a2" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">我们现在有了一个经过训练的逻辑回归模型，或者至少我们已经能够优化其各自的功能，以确定合适的参数。我们现在能够打印这些参数，并在看不见的数据集中使用这些参数进行推理。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="np kl l"/></div></figure><p id="1d30" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们完事了。</p><p id="5232" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">您可以在示例存储库中找到这个完整的示例，您将能够运行和扩展它。</p><h1 id="7a78" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">接下来呢？</h1><p id="e0a3" class="pw-post-body-paragraph kq kr iq ks b kt nd jr kv kw ne ju ky kz nf lb lc ld ng lf lg lh nh lj lk ll ij bi translated">恭喜你，你一路走到了最后！虽然这篇文章涵盖了广泛的主题，但是也有大量的概念被浏览过。其中包括底层Vulkan概念、GPU计算基础、机器学习最佳实践和更高级的Kompute概念。幸运的是，网上有大量的资源可以扩展你在这些方面的知识。我推荐作为进一步阅读的一些链接包括:</p><ul class=""><li id="9f1c" class="lw lx iq ks b kt ku kw kx kz ly ld lz lh ma ll no mc md me bi translated"><a class="ae lm" href="https://kompute.cc/" rel="noopener ugc nofollow" target="_blank"> Kompute文档</a>了解更多细节和更多示例</li><li id="f38e" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><a class="ae lm" href="https://ethical.institute/mle.html" rel="noopener ugc nofollow" target="_blank">机器学习工程师时事通讯</a>如果你想了解关于机器学习的最新文章</li><li id="bfe4" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><a class="ae lm" href="https://github.com/EthicalML/awesome-production-machine-learning/" rel="noopener ugc nofollow" target="_blank">出色的生产机器学习</a>开源工具列表，用于部署、监控、版本化和扩展您的机器学习</li><li id="6418" class="lw lx iq ks b kt mf kw mg kz mh ld mi lh mj ll no mc md me bi translated"><a class="ae lm" href="https://www.fast.ai/2018/09/26/ml-launch/" rel="noopener ugc nofollow" target="_blank">FastAI的ML for Coders课程简介</a>进一步学习机器学习概念</li></ul><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi os"><img src="../Images/aa611da83e07f127d91855c0988ade77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*OeK5rt6Taw51IDAFNT2I-Q.gif"/></div></div><p class="km kn gj gh gi ko kp bd b be z dk translated">作者图片</p></figure></div></div>    
</body>
</html>