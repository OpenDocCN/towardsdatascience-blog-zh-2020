<html>
<head>
<title>6 Things to Know to Master K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">掌握K-均值聚类需要知道的6件事</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/6-things-to-know-to-master-k-means-clustering-1d5be9b189dd?source=collection_archive---------53-----------------------#2020-10-19">https://towardsdatascience.com/6-things-to-know-to-master-k-means-clustering-1d5be9b189dd?source=collection_archive---------53-----------------------#2020-10-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3d10" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解最流行的聚类方法之一</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/318e39c70df98e27b1a28a6fc3673fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GikJYNx9gqK7_mKX"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">亚历山大·安德鲁斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="293e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">市场上有多少种类型的客户？NBA有多少种类型的球员？常春藤盟校有多少种学生？</p><p id="bb5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现实生活中有很多这样的问题——这些问题试图理解特定环境中的人(以及物体)的类型。通过了解我们对什么类型的人感兴趣，我们可以制定相应的策略来满足我们的特殊需求。</p><p id="8642" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，我们假设市场研究发现市场上有两种类型的客户——一种对价格上涨更敏感，另一种对价格上涨不太敏感。通过研究你产品的顾客，你可以决定是否要提高产品价格来弥补增加的成本。假设你的大多数顾客对价格敏感，那么如果你决定提价，你应该更加小心潜在的销售下降。</p><p id="28cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这只是一个说明聚类分析实际应用的小例子。这是来自<a class="ae ky" href="https://en.wikipedia.org/wiki/Cluster_analysis" rel="noopener ugc nofollow" target="_blank">维基百科</a>页面的聚类定义。</p><blockquote class="lv lw lx"><p id="a10d" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><strong class="lb iu">聚类分析</strong>或<strong class="lb iu">聚类</strong>是对一组对象进行分组的任务，使同一组中的对象(称为<strong class="lb iu">聚类</strong>)比其他组(聚类)中的对象彼此更加相似(在某种意义上)。</p></blockquote><p id="8160" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与上面给出的例子相关，为你的产品识别客户类型的过程是进行聚类分析。需要注意的是，聚类方法有很多种，最常用的一种叫做<strong class="lb iu"> K-means聚类</strong>。在本文中，我将回顾K-means的一些关键方面，并希望您对这种流行的聚类方法有更好的理解。</p><p id="2198" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们开始研究K-means之前，下图直观地向您展示了一个常见的K-means如何通过多次迭代来达到最终的聚类结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/68e8b2771b55a98cab1478fdb9446e69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/1*Nx6IyGfRAV1ly6uDGnVCxQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自K-means <a class="ae ky" href="https://en.wikipedia.org/wiki/K-means_clustering#/media/File:K-means_convergence.gif" rel="noopener ugc nofollow" target="_blank">维基百科</a>(由<a class="ae ky" href="https://commons.wikimedia.org/wiki/User:Chire" rel="noopener ugc nofollow" target="_blank"> Chire </a>创作，授权:<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a>)</p></figure></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h2 id="b474" class="mk ml it bd mm mn mo dn mp mq mr dp ms li mt mu mv lm mw mx my lq mz na nb nc bi translated">1.K-means是基于原型的。</h2><p id="bb6b" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">第一个问题是我们如何确定聚类，或者我们如何确定一个特定的样本应该被分配到哪个聚类。有几种可用的聚类方法，包括基于连接性的(即分层的)、基于网格的、基于分布的、基于密度的和基于原型的。其中<strong class="lb iu"> K-means聚类属于基于原型的范畴。</strong></p><p id="ab55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了概念化基于原型的聚类方法，您可以认为对于每个聚类，都有一个原型数据点，它表示特定聚类的典型成员应该是什么样子。应该注意的是，原型数据点是从属于该聚类的数据点估计的，并且不必是原始数据集的实际情况。</p><p id="9120" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，一些算法要求原型数据点必须是实际的数据点，这被称为<strong class="lb iu"> K-medoid </strong>聚类。在大多数涉及连续特征的应用中，K均值指的是使用<strong class="lb iu">质心</strong>作为原型数据点。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h2 id="2e84" class="mk ml it bd mm mn mo dn mp mq mr dp ms li mt mu mv lm mw mx my lq mz na nb nc bi translated">2.聚类分配和迭代</h2><p id="d8d4" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">使用如上所示的动画图像作为例子，假设我们已经为聚类选择了三个质心作为初始种子。我们如何确定应该将样本分配给哪个组？</p><p id="9e70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要指定一个数据点，我们需要计算该数据点和我们刚才选择的每个质心之间的距离。距离被认为是数据点之间的相似性-数据点与质心之间越接近越相似。最常用的度量是平方欧几里德距离(sed)，如上所示。如果考虑一个二维特征，它基本上是我们最熟悉的笛卡尔平面上两个数据点之间的距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/7f37ae88455013ebc4b8e909601ce7c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lf4RfsU1eb3ZYIUcXEpv2w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图来自<a class="ae ky" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="e666" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过计算这些距离，我们能够将数据点分配给产生最小SED的聚类。一旦分配了每个数据点，我们就能够为我们的聚类获得更新的质心，并计算每个聚类中所有适用SED的误差平方和(SSE)。如果你熟悉机器学习的术语。您可以将<strong class="lb iu">类内SSE视为K均值聚类试图最小化的成本函数的输出，这使得K均值或多或少成为一个优化问题。</strong></p><p id="ae4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一次迭代中，我们将数据点分配给更新后的质心，并再次计算SSE以查看它是否减少。直到没有进一步的改进(上证指数已经变得足够小和稳定)，我们可以得出结论，K均值聚类已经完成。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h2 id="7b06" class="mk ml it bd mm mn mo dn mp mq mr dp ms li mt mu mv lm mw mx my lq mz na nb nc bi translated">3.您必须事先指定聚类的数量。</h2><p id="b6d7" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">当我们运行K-means聚类分析时，我们必须指定聚类的数量，<em class="ly">先验</em>。这有时被认为是K-means方法的一个缺点，因为对于某些数据集，我们不知道有多少个聚类是合理的。毕竟，我们没有关于我们的数据点所属的聚类的基本事实，否则，如果我们有，它就变成了一个监督学习任务。</p><p id="7fb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们只处理2维或3维数据，我们可以将数据可视化，以获得一些关于聚类数量的假设。然而，对于更高的维度，以人类可理解的方式可视化数据是不太可能的。因此，您最好使用相关的背景内容专业知识，并对您的数据的大概聚类数进行有根据的猜测。以此为起点，看看您的集群效果如何。</p><p id="dc0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是突出的问题是<strong class="lb iu"> <em class="ly">当我们有不同数量的聚类时，我们如何评估哪一个聚类性能比其他的好。</em> </strong></p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h2 id="56aa" class="mk ml it bd mm mn mo dn mp mq mr dp ms li mt mu mv lm mw mx my lq mz na nb nc bi translated">4.聚类评估和肘方法</h2><p id="16d7" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">我们已经在第2节中讨论了使用SED的数据点聚类分配和使用SSE的迭代优化。在迭代结束时，我们得到了一个SSE最少的模型(所有成员的特定集群分配)。</p><p id="f98d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过改变同一数据集的每次聚类分析的聚类数，我们可以得出每个模型的SSE值。有了这些数据，我们可以绘制一个线图，作为聚类数和SSE值的函数，后者通常被称为失真。下面显示了一个假设聚类模型的简单示例。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/f543fea912afd51f75fae4df70e2017a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*BpBRr1BZL23y9EYGg9Np5A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">肘法(作者自创)</p></figure><p id="a98d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如图所示，当簇数为3时，有一个急转弯。这意味着除了这三种聚类方法之外，我们的聚类性能没有任何有意义的提高(没有多少降低)。因此，说3是一个很好的聚类数是有意义的。</p><p id="bee5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，除了肘方法，我们还可以使用侧影图来评估不同聚类数的模型之间的性能。如果你感兴趣，这里有一篇关于这个话题的极好的<a class="ae ky" rel="noopener" target="_blank" href="/clustering-metrics-better-than-the-elbow-method-6926e1f723a6">中型文章</a>。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h2 id="e9e6" class="mk ml it bd mm mn mo dn mp mq mr dp ms li mt mu mv lm mw mx my lq mz na nb nc bi translated">5.你需要标准化你的数据点。</h2><p id="f83a" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">当K-means聚类有多个特征时，这些特征的初始数据集可能有不同的尺度。例如，让我们说一个尺度是以米为单位测量的学生身高，另一个尺度是以千克为单位测量的体重。正如您所料，这些尺度的方差绝对值可能会非常不同。</p><p id="9fef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于身高，方差可能在小数值水平，然而，体重可以有大得多的方差。当我们的K-means聚类迭代优化模型时，它会尽最大努力更多地依赖于减少权重贡献的SSE。看到问题了吗？通过或多或少地忽略来自高度尺度的贡献，优化将走捷径。</p><p id="6413" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解决方案是，我们应该通过将单个尺度带到相同或相似的范围水平来标准化数据点。通常，我们可以运行Z分数归一化，并对每个要素使用标准化的Z分数。或者，您也可以运行最小-最大缩放。请注意，这两种方法的性能将取决于数据集，并且没有关于哪一种方法一定比另一种方法更好的固定规则。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h2 id="d438" class="mk ml it bd mm mn mo dn mp mq mr dp ms li mt mu mv lm mw mx my lq mz na nb nc bi translated">6.初始化很重要</h2><p id="83dc" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">当我们运行K-means聚类分析时，我们从随机选取的质心开始。通过多次迭代，我们将能够得到一个SSE达到最小值的模型——这个最小值可能与随机选取的初始质心直接相关。如前所述，质心迭代更新，每次迭代都建立在前一次迭代的结果上。</p><p id="4985" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们将得到的最终模型将与第一次迭代之前选取的质心相关。换句话说，质心的初始化直接影响我们得到的最终模型。</p><p id="6ef9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在实践中，例如，在scikit-learn实现中，我们通常多次运行K-means聚类分析，并在这些模型中挑选最佳表现者。虽然我们可以随机选择初始质心，但更好的方法是使用所谓的K-means++初始化方法。简而言之，K-mean++不是随机选择质心，而是一种使用概率分布来挑选初始质心的算法，这提高了K-means聚类的性能。</p><p id="3278" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顺便提一下，在scikit-learn K-means实现中，默认的初始化方法是K-means++方法，所以我们不需要担心初始质心的选择。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h2 id="4e9c" class="mk ml it bd mm mn mo dn mp mq mr dp ms li mt mu mv lm mw mx my lq mz na nb nc bi translated">结论</h2><p id="5404" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">总之，本文回顾了进行K-means聚类分析的一些关键方面。下面是一个典型的K均值聚类分析步骤的快速概述。</p><ul class=""><li id="f920" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated">使用K-means++初始化方法选取初始质心，其数量与指定的聚类数匹配(请注意，我们可以使用elbow方法来确定特定数据集的聚类数)</li><li id="ea93" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">使用平方欧几里得距离(SED)将数据集的每个数据点分配到最近的质心</li><li id="f7f7" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">用每个簇中的所有成员更新质心</li><li id="aa8c" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">通过最小化组内误差平方和(SSE)重复前两步</li><li id="676c" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated">在指定的迭代次数之后，或者模型没有更好的改进(例如，SSE中的变化)，我们得到了最终的模型</li></ul></div></div>    
</body>
</html>