<html>
<head>
<title>From Research to Production with Deep Semi-Supervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用深度半监督学习从研究到生产</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-research-to-production-with-deep-semi-supervised-learning-7caaedc39093?source=collection_archive---------9-----------------------#2020-09-25">https://towardsdatascience.com/from-research-to-production-with-deep-semi-supervised-learning-7caaedc39093?source=collection_archive---------9-----------------------#2020-09-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8c3f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="6825" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">分享经验，将研究带入现实世界。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ede469b0088c4178312592605f382952.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_kYIsM2OUhAIms2aVysLnw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">我从2019年6月开始的一叠半监督学习论文，上面是我在该领域阅读的第一篇论文:mix match——我不建议为了很好地回忆你所阅读的内容而在所有东西下面划线。<em class="lh">(图片作者)</em></p></figure><p id="24ae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di"> T </span>今天大多数深度学习算法的成功很大程度上是几十年研究的结果，GPU和数据的可用性越来越大。但并不是任何类型的数据——那种丰富、干净、标记为 的<strong class="lk jd">。</strong></p><p id="0e0e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">ImageNet、CIFAR10、SVHN等数据集让研究人员和从业者在计算机视觉任务上取得了显著进展，对我们自己的实验非常有用。然而，对于许多寻求从这一进步中受益的应用程序(如医学)来说，最大的困难恰恰是数据必须是丰富的、干净的和有标签的。</p><p id="0a8b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">半监督学习(SSL)，</strong>结合了监督和非监督学习的子领域，在过去几年中，在深度学习研究社区中变得越来越受欢迎。很有可能，至少在短期内，SSL方法可以成为标签繁重的监督学习和数据高效建模的未来之间的桥梁。</p><p id="ed93" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本帖中，我们将讨论何时应该考虑在您的生产环境中使用SSL方法，以及我们在<a class="ae mo" href="http://uizard.io" rel="noopener ugc nofollow" target="_blank"> Uizard </a>使用它们来改进我们的对象检测模型时学到的经验。当然，我们会尽最大努力分享大图，但对我们自己保留一些魔法的细节。</p><blockquote class="mp mq mr"><p id="e8f6" class="li lj mn lk b ll lm kd ln lo lp kg lq ms ls lt lu mt lw lx ly mu ma mb mc md im bi translated"><strong class="lk jd">我们希望通过展示SSL如何以及何时对我们起作用以及不起作用，并通过分享我们从研究到生产的旅程中所学到的技巧，我们可以激励您在工作中抓住SSL的机会，并释放您未标记数据的潜力。</strong></p></blockquote><p id="7708" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">简而言之，这里有一些我们强调的教训:</p><ul class=""><li id="8c05" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated"><strong class="lk jd">简单才是王道。</strong>SSL中从研究转化为生产的最成功的方法是那些最容易复制的方法。具体来说，我们将阐述“与吵闹的学生一起自我训练”(<a class="ae mo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank">谢等人，2019 </a>)是如何为我们工作的。</li><li id="a764" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated">使用启发式算法的伪标签精化可能非常有效。伪标签是SSL方法的一个受欢迎的组成部分，我们发现使用简单的试探法来改进未标签数据中的伪标签可以提高不同大小的未标签数据集的性能。</li><li id="dc11" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated"><strong class="lk jd">半监督图像分类的进展很难转化为目标检测。</strong>我们跟踪的SSL的大部分进展是测量图像分类的性能，并承诺在对象检测方面有类似的改进，但我们发现在实践中很难适当地调整它们。因此，在半监督目标检测领域需要更多的工作和研究。</li></ul></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="8e3a" class="nq nr it bd ns nt nu nv nw nx ny nz oa ki ob kj oc kl od km oe ko of kp og oh bi translated">什么是半监督学习(SSL)？</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/c043a7b3170976998c01de4872d2a93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yJ4lyWJQhPCaLP1kwHlIzw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">半监督学习与监督学习的区别的简单说明。<em class="lh">(图片作者)</em></p></figure><p id="e9d1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">顾名思义，半监督学习(SSL)是指介于监督和非监督学习之间的一类算法，旨在使用标记和未标记数据来建模分布。</p><blockquote class="oj"><p id="d8ca" class="ok ol it bd om on oo op oq or os md dk translated">SSL的目标通常是比单独使用带标签的数据做得更好，能够模拟目标分布，就好像我们也可以访问所有未标记数据的标签一样。</p></blockquote><p id="7b31" class="pw-post-body-paragraph li lj it lk b ll ot kd ln lo ou kg lq lr ov lt lu lv ow lx ly lz ox mb mc md im bi translated">这种算法并不是一个新的想法，尽管在过去的18个月中，深度半监督学习已经有了相当多的兴趣、进展和应用，我们将在下面讨论。</p><h1 id="1860" class="nq nr it bd ns nt oy nv nw nx oz nz oa ki pa kj oc kl pb km oe ko pc kp og oh bi translated">我什么时候适合在生产中使用SSL？</h1><p id="91c7" class="pw-post-body-paragraph li lj it lk b ll pd kd ln lo pe kg lq lr pf lt lu lv pg lx ly lz ph mb mc md im bi translated">如果您正在考虑使用SSL来解决某个问题，那一定是因为您的数据集很大，并且有许多未标记的数据点。你的数据集的一部分可能会被标记，当然标记的数据越多越好——但是希望<strong class="lk jd">至少有</strong>和标记的数据一样多的未标记的数据，或者更多的数量级。</p><p id="ebf3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果您可用的大部分数据都是带标签的，或者未带标签的数据集来自与带标签的数据集显著不同的分布，那么SSL现在可能不太适合您的应用程序。对于后一种情况，请查看域自适应。</p><p id="8150" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">考虑到这一点，有两个主要的设置证明了在现实应用程序中研究SSL方法的合理性:</p><ul class=""><li id="2404" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated">您正在处理一个<strong class="lk jd">高价值问题</strong>，对于该问题，仅标记的数据不足以产生足够的性能，但是<strong class="lk jd">多几倍(10–100倍以上)</strong>未标记的数据是可用的和/或容易获得的。</li></ul><p id="0368" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种情况下，我们强调值得生产的性能的可能性较低——但是在给定一个数量级或更多的未标记数据以及足够的激励、时间和资源的情况下，为几乎没有标记数据的任务尝试SSL可能是有意义的。</p><ul class=""><li id="e861" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated">你正在解决一个问题，对于这个问题，有标记的数据本身就足以产生足够的性能，但是你有一个未标记的样本集合，你想用T2进一步提高性能。</li></ul><p id="8405" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种情况下，您可能已经有了一个运行良好或几乎达到要求的模型，但是您希望继续提高性能，而不需要花费太多精力来标记新数据。因此，SSL可以被视为改进建模的许多其他工具之一，如获得更清晰的标记数据集、训练更大的模型等。对于差错率相对降低5–10%以上的性能关键型应用程序，以及可获得未标记数据的应用程序，SSL尤其适用。</p><p id="6755" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">值得注意的是，特别是因为Uizard是一家拥有快速增长的beta用户群的初创公司，<strong class="lk jd"> <em class="mn">在持续/主动学习环境中使用的SSL也有可能创造出您在下面看到的循环。</em> </strong>未标记的数据用于在我们的平台中训练和部署改进的模型，这反过来驱动额外的用户，从而产生额外的未标记数据来从头开始该过程。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pi"><img src="../Images/379d597e7bd8905f61ebc089e359b15f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7AyBtQyTsqyqFHmcyWpoVg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">半监督学习(SSL)模型在生产环境中的生命周期，其中不断增长的用户群可以创建一个正反馈循环。(图片由作者提供)</p></figure><h1 id="60ee" class="nq nr it bd ns nt oy nv nw nx oz nz oa ki pa kj oc kl pb km oe ko pc kp og oh bi translated"><strong class="ak">研究的方法</strong></h1><p id="65c2" class="pw-post-body-paragraph li lj it lk b ll pd kd ln lo pe kg lq lr pf lt lu lv pg lx ly lz ph mb mc md im bi translated">以下是我们在图像分类和对象检测方面尝试的一些方法，但SSL同样可以应用于其他领域，如NLP ( <a class="ae mo" href="https://www-cs.stanford.edu/~pliang/papers/meng-thesis.pdf" rel="noopener ugc nofollow" target="_blank"> Liang等人，2005 </a>)和音频/语音处理(<a class="ae mo" href="https://www.sciencedirect.com/science/article/abs/pii/S0167639304000962" rel="noopener ugc nofollow" target="_blank"> Tur等人，2005 </a>)。</p><p id="b250" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">图像分类</strong></p><ul class=""><li id="5160" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated">MixMatch(贝特洛等人，2019)[ <a class="ae mo" href="https://arxiv.org/pdf/1905.02249.pdf" rel="noopener ugc nofollow" target="_blank"> pdf </a> ][ <a class="ae mo" href="https://github.com/google-research/mixmatch" rel="noopener ugc nofollow" target="_blank">代码</a></li><li id="2fef" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated">无监督数据增强(UDA)(谢等，2019)[<a class="ae mo" href="https://arxiv.org/pdf/1904.12848.pdf" rel="noopener ugc nofollow" target="_blank">pdf</a>][<a class="ae mo" href="https://github.com/google-research/uda" rel="noopener ugc nofollow" target="_blank">code</a>]</li><li id="2ef6" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated">FixMatch (Sohn等人，2020-A)[ <a class="ae mo" href="https://arxiv.org/pdf/2001.07685.pdf" rel="noopener ugc nofollow" target="_blank"> pdf </a> ][ <a class="ae mo" href="https://github.com/google-research/fixmatch" rel="noopener ugc nofollow" target="_blank">代码</a> ]</li></ul><p id="524c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">物体检测</strong></p><ul class=""><li id="359c" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated">CSD (Jeong等人，2020年)[ <a class="ae mo" href="https://papers.nips.cc/paper/9259-consistency-based-semi-supervised-learning-for-object-detection.pdf" rel="noopener ugc nofollow" target="_blank"> pdf </a> ][ <a class="ae mo" href="https://github.com/soo89/CSD-SSD" rel="noopener ugc nofollow" target="_blank">代码</a></li><li id="1da2" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated">STAC (Sohn等人，2020-B)[ <a class="ae mo" href="https://arxiv.org/pdf/2005.04757.pdf" rel="noopener ugc nofollow" target="_blank"> pdf </a> ][ <a class="ae mo" href="https://github.com/google-research/ssl_detection/" rel="noopener ugc nofollow" target="_blank">代码</a></li></ul><p id="8a0d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">任务无关</strong></p><ul class=""><li id="0758" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated">吵闹的学生(谢等，2019)[<a class="ae mo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank">pdf</a>][<a class="ae mo" href="https://github.com/google-research/noisystudent" rel="noopener ugc nofollow" target="_blank">code</a>]</li></ul><p id="a533" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然我们不会详细讨论上面的每一种方法，但是下面关于半监督学习的博客非常棒，涵盖了上面列出的许多技术。</p><ul class=""><li id="ba7a" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated"><a class="ae mo" href="https://amitness.com/2020/07/semi-supervised-learning/" rel="noopener ugc nofollow" target="_blank">计算机视觉中的半监督学习</a>，作者Amit Chaudhary</li><li id="2504" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated"><a class="ae mo" href="https://yassouali.github.io/ml-blog/deep-semi-supervised/" rel="noopener ugc nofollow" target="_blank">深度半监督学习</a>，作者亚辛·奥阿利</li><li id="2d7b" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated"><a class="ae mo" href="https://ruder.io/semi-supervised/" rel="noopener ugc nofollow" target="_blank">Sebastian Ruder的半监督学习的代理标签方法概述</a></li></ul></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="3733" class="nq nr it bd ns nt nu nv nw nx ny nz oa ki ob kj oc kl od km oe ko of kp og oh bi translated">第一课:简单是王道。</h1><p id="609f" class="pw-post-body-paragraph li lj it lk b ll pd kd ln lo pe kg lq lr pf lt lu lv pg lx ly lz ph mb mc md im bi translated">在2019年6月我们对半监督学习方法的最初文献综述中，读到MixMatch和UDA在SSL方面取得了显著进展，特别是在标签数据极其有限的情况下，这令人着迷。我们能够相对轻松地在CIFAR10和SVHN上重现他们的结果，这让我们对他们将这些性能提升转化到我们的数据集的能力充满信心。</p><p id="4335" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，我们这样做的体验并不理想，主要是因为——惊喜！—超参数调谐。论文中使用的数据集的许多开箱即用的超参数对我们数据集的性能变化更敏感。我们还注意到，我们的标记数据集在分布上与未标记数据集略有不同，这个问题通常会降低SSL技术的性能，并在<a class="ae mo" href="https://arxiv.org/pdf/1804.09170.pdf" rel="noopener ugc nofollow" target="_blank"> Oliver et al .，2018 </a>中提出，作为SSL需要克服的挑战，以用于“现实”设置(请参见本博客末尾的附录A，了解我们对此的研究工作)。截至2019年9月，现有的最先进的SSL技术似乎不够简单或灵活，不足以让我们继续前进。</p><p id="91ed" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">快进到2020年6月，已经发布了两个关于SSL的新作品，主要关注简单的实现——fix match和嘈杂学生的自我训练。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pj"><img src="../Images/50e68fb316494d73718021ea4d992ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pCkPpXIYuUo4Z_SekG9v6A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">FixMatch中如何使用未标记图像的示意图。(图片来自<a class="ae mo" href="https://arxiv.org/pdf/2001.07685.pdf" rel="noopener ugc nofollow" target="_blank"> Sohn等人，2020 </a>)</p></figure><p id="ddf7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> FixMatch </strong>是其前身MixMatch的一个更简单但更有效的版本，我们成功地在论文中提出的数据集上复制了他们的结果。这一次，我们能够在我们自己的图像分类数据集上看到良好的结果，性能对超参数的选择不太敏感，并且可调整的超参数更少。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pk"><img src="../Images/b53ff57dfd1a51033e53b7d867e4d854.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jXQIXV0_JeVfM2sXUJKBwQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">有吵闹学生的自我训练图。(图片来自<a class="ae mo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank">谢等人2019 </a>)</p></figure><p id="a9a1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">嘈杂的学生</strong>训练由一个迭代过程组成，在这个过程中，我们训练一个教师模型(可以访问标记数据的模型)，使用这个模型来推断未标记数据的输出，然后根据标记数据和伪标记数据重新训练一个新模型，称为学生。然后，我们可以重复这个循环，称为<em class="mn">自训练</em>，通过使用这个学生模型在未标记集合上推断新的伪标签。在<a class="ae mo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank"> Xie et al .，2019 </a>中，他们展示了上述框架如何在使用300M未标记图像时提高ImageNet分类精度，并强调了各种类型噪声的添加(增强、丢失等。)作为几项消融研究成功的关键。</p><p id="9b9e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">值得注意的是，嘈杂的学生方法是一个任务无关的框架，可以广泛应用于:图像分类，对象检测，情感分析等。<strong class="lk jd"> <em class="mn">对我们来说，在我们尝试的所有技术中，嘈杂的学生方法是最成功的对象检测方法。</em> </strong>我们在第3课中讨论了为什么FixMatch的对象检测对应物(STAC)和其他方法可能对我们不起作用，但是我们坚信吵闹学生的<strong class="lk jd">简单性和灵活性</strong>与其他方法相比是我们看到生产模型改进的原因。</p><p id="d8e8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为什么很简单？<em class="mn">现有训练超参数和设置几乎没有变化。</em>以下是完整管道所需的内容:</p><ol class=""><li id="ea28" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md pl nb nc nd bi translated">把我们现有的生产模式当成教师模式。</li><li id="d3d4" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md pl nb nc nd bi translated">与老师一起编写几个脚本来推断和提炼无标签数据上的伪标签(有关伪标签提炼的更多信息，请参见第2课)。</li><li id="5d86" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md pl nb nc nd bi translated">用添加的噪声(增强等)训练“学生”模型。).</li><li id="8add" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md pl nb nc nd bi translated">按照嘈杂的学生图中所示的框架重复该过程。</li></ol><p id="3621" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其他注意事项和想法:</p><ul class=""><li id="2f53" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated">当<strong class="lk jd">可用的未标记数据少于标记数据时，我们惊讶地看到用嘈杂学生方法实现的一些模型有所改进。</strong>第二课将详细介绍这一点。不过一般来说，如<a class="ae mo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank">谢等，2019 </a>所述，未标记的数据越多越好。</li><li id="006f" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated">我们看到，使用普通的自我训练，我们的学生模型的性能有所改善，而没有实现<a class="ae mo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank">谢等人，2019 </a>的一些部分，如辍学、随机深度或软伪标签。这些部分一旦被添加，可能会像在ImageNet上那样进一步提升我们的性能。</li><li id="807e" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated">使用更大的学生模型的结果是混合的——对我们来说，这意味着在我们的检测模型中从ResNet-50到ResNet-101主干。</li></ul><p id="8245" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总的来说，当涉及到图像分类或物体检测时，<strong class="lk jd">简单是王道。与MixMatch相比，FixMatch明显更容易适应我们的自定义图像分类数据集，而Noisy Student只需要对我们现有的对象检测管道进行很小的更改，就可以看到性能的提高。</strong></p><h1 id="cda1" class="nq nr it bd ns nt oy nv nw nx oz nz oa ki pa kj oc kl pb km oe ko pc kp og oh bi translated">第二课:<strong class="ak">启发式伪标签提炼非常有效。</strong></h1><p id="97d0" class="pw-post-body-paragraph li lj it lk b ll pd kd ln lo pe kg lq lr pf lt lu lv pg lx ly lz ph mb mc md im bi translated">伪标记，也称为自我训练，是SSL中的一种范式，早在20世纪60年代和70年代就出现了，并且由于其简单性而一直存在(<a class="ae mo" href="https://ieeexplore.ieee.org/document/1053799" rel="noopener ugc nofollow" target="_blank"> Scudder，1965</a>；<a class="ae mo" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1975.10479874" rel="noopener ugc nofollow" target="_blank">麦克拉克伦，1975 </a>。深度SSL伪标记的引入(<a class="ae mo" href="http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf" rel="noopener ugc nofollow" target="_blank"> Lee，2013 </a>)展示了用标记数据训练模型，使用该模型推断未标记数据上的标签(现在称为伪标签)，然后用标记和伪标记数据进行重新训练的想法是多么简单而强大。今天，许多SSL技术使用某种形式的伪标记，包括FixMatch和嘈杂学生的自我训练。</p><p id="db4f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，这些伪标签经常会有噪声，并且需要某种形式的改进才能被使用。在FixMatch和Noisy Student中，这意味着将阈值(比如0.7或0.9)应用于推断的伪标签，并且仅采用softmax置信度得分高于该阈值的那些预测。我们发现这是获得高质量伪标签的一种有用的启发式方法，但是<strong class="lk jd">还发现对伪标签应用其他领域特定的启发式方法在嘈杂的学生设置中有很大帮助。</strong></p><p id="6e45" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们在谈论什么样的启发法？例如，假设您正在为一家房地产公司构建一个对象检测分类器，该公司需要为家中的不同对象添加边框注释。您注意到(教师)模型的预测通常是好的，但是，分类器倾向于在未标记的集合上产生几个不正确的、高置信度的预测，即一些梳妆台实际上是厨房岛。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pm"><img src="../Images/0b6a2397d61c90095c5110751f31fd7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zNQsCy3AxqME_UX7eR4lYQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">我们可以在嘈杂的学生训练中使用特定领域的启发式算法来改进伪标签，以提高半监督性能。(图片由作者提供)</p></figure><p id="e962" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里有一些启发性的例子，我们可以从中选择来完善这个标签:</p><ul class=""><li id="fe23" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated">如果在同一个图像中预测了岛和床，请将岛标签转换为梳妆台。</li><li id="d0dc" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated">如果梳妆台和岛预测在同一图像中，请将岛标签转换为梳妆台。</li><li id="ca10" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated">如果在同一个图像中预测了岛、床和梳妆台，请将岛标签转换为梳妆台。</li></ul><p id="089f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以上哪种启发最有意义？这将取决于您的数据集和最常见的错误类型。如果模型在检测床方面做得很好，也许像第一个或第三个例子这样的启发式方法可能会有用，因为我们不希望床和厨房岛出现在同一张图像中。</p><blockquote class="oj"><p id="bd75" class="ok ol it bd om on oo op oq or os md dk translated"><strong class="ak">特别是在对象检测中，当对象的位置和大小遵循您的应用领域中的特定规则时，您可以定义类似这样的试探法来优化嘈杂的伪标签，并帮助您的学生模型学习教师模型无法学习的更好的表示。</strong></p></blockquote><p id="17bb" class="pw-post-body-paragraph li lj it lk b ll ot kd ln lo ou kg lq lr ov lt lu lv ow lx ly lz ox mb mc md im bi translated">我们能够在我们自己的有噪声的学生模型中实现更好的性能，使用启发式伪标签细化，在某些情况下，使用<strong class="lk jd">,无标签数据比有标签数据少一个数量级。</strong>我们还发现有趣的是，这一课听起来与<a class="ae mo" href="https://www.ri.cmu.edu/pub_files/pub4/rosenberg_charles_2005_1/rosenberg_charles_2005_1.pdf" rel="noopener ugc nofollow" target="_blank">罗森伯格等人2005年</a>发表的题为<em class="mn">对象检测模型的半监督自我训练</em>的论文中的观察结果惊人地相似:</p><blockquote class="mp mq mr"><p id="a252" class="li lj mn lk b ll lm kd ln lo lp kg lq ms ls lt lu mt lw lx ly mu ma mb mc md im bi translated">…独立于检测器定义的训练数据选择度量大大优于基于检测器生成的检测置信度的选择度量。</p></blockquote><p id="d282" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是您所有数据和建模问题的解决方案吗？当然不是——但它说明了启发式仍然是深度(半监督)学习管道中有用的一部分。同样，这里应用的试探法是特定领域的，只有仔细研究您的数据和模型的偏差，才能揭示有用的伪标签细化。</p><h1 id="2a67" class="nq nr it bd ns nt oy nv nw nx oz nz oa ki pa kj oc kl pb km oe ko pc kp og oh bi translated">第三课:<strong class="ak">半监督图像分类的进展很难转化为目标检测。</strong></h1><p id="4ad8" class="pw-post-body-paragraph li lj it lk b ll pd kd ln lo pe kg lq lr pf lt lu lv pg lx ly lz ph mb mc md im bi translated">我们跟踪的SSL研究的大部分进展都是测量图像分类的性能，希望能够轻松地将技术应用于其他任务的类似改进，如对象检测。然而，在我们自己尝试将图像分类方法用于对象检测时，我们遇到了几个挑战，这导致我们坚持使用第1课中提到的最简单的半监督对象检测方法。以下是其中的一些挑战:</p><ul class=""><li id="8709" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated"><strong class="lk jd">在线与离线伪标签生成</strong></li></ul><p id="d151" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在许多用于图像分类的SSL技术(FixMatch、UDA等)中。)，未标记数据的伪标记目标在训练期间<em class="mn">或<strong class="lk jd">在线</strong>被更新/计算。在<strong class="lk jd">离线</strong>中，学习培训分为多个阶段。首先用标记样本训练模型，然后用标记样本生成伪标签。然后可以用标记的和伪标记的样本训练新的模型。</em></p><p id="e023" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">FixMatch和UDA是SSL技术的示例，它们使用在线学习来通过阈值取得良好效果，仅允许预测高于某个阈值的未标记样本对训练信号有所贡献——在嘈杂的学生和STAC(fix match的对象检测变体)中，然而，伪标签是离线生成的。</p><p id="fee8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然在线学习似乎是有利的——允许在稍后的训练步骤中纠正早期训练中的不良伪标签— <strong class="lk jd">,但它使得训练在计算上更加昂贵，对于训练对象检测模型来说更是如此。</strong>为什么？两件事:数据扩充和批量大小。关于数据扩充，让我们重温一下在第1课FixMatch中首次出现的图表。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pj"><img src="../Images/50e68fb316494d73718021ea4d992ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pCkPpXIYuUo4Z_SekG9v6A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">FixMatch中如何使用未标记图像的示意图。(图片来自<a class="ae mo" href="https://arxiv.org/pdf/2001.07685.pdf" rel="noopener ugc nofollow" target="_blank"> Sohn等人，2020 </a>)</p></figure><p id="b130" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们看到，每个未标记的示例在训练期间都是“弱增强”和“强增强”的，并且需要将两个增强图像通过网络向前传递以计算损失。这种数据扩充是许多SSL方法的基础，并且尽管对于图像分类是可行的，但是对于大图像(512x512+)上的对象检测任务的处理训练时间扩充会显著减慢训练。</p><p id="3f9f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在批量大小方面，许多作品(MixMatch、UDA、FixMatch、Noisy Student)和我们自己的实验也强调，未标记的批量大小是标记的批量大小的几倍对于SSL方法的成功至关重要。对对象检测任务的这种要求与存储器中的大图像以及对无标签批次中的所有样本的必要扩充相结合，产生了极大的计算负担。<em class="mn">数据扩充和无标签批量大小这两个挑战是我们无法将像FixMatch这样的工作一对一转换为对象检测的最终原因。</em></p><p id="a22c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在与STAC的作者的讨论中，他们也注意到了半监督对象检测空间中在线学习带来的沉重资源开销。我们希望未来的工作将更深入地研究这个问题，并且在未来几年中取得的计算成果将使研究人员更容易进行这样的工作。</p><ul class=""><li id="eea2" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated"><strong class="lk jd">用阶级平衡管理长尾</strong></li></ul><p id="ee0c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">SSL研究中的许多基准数据集，如CIFAR10、CIFAR100和STL-10，都使用类平衡标记的训练集。我们的数据集，像许多真实世界的数据集一样，是极其长尾的。类别平衡被认为是许多SSL方法的关键组成部分(<a class="ae mo" href="https://arxiv.org/abs/1911.04252" rel="noopener ugc nofollow" target="_blank">谢等人，2019 </a>，<a class="ae mo" href="https://arxiv.org/pdf/1912.00594.pdf" rel="noopener ugc nofollow" target="_blank">宋等人，2020 </a>)，在图像分类中，上采样和下采样技术是常见的做法。然而，在对象检测设置中，有效的类平衡技术并不简单。</p><p id="ad5f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果类平衡对于SSL在实践中的成功至关重要，那么我们如何在半监督对象检测中实现类平衡呢？解决这个问题的未来研究肯定会受到欢迎。</p><h1 id="9e9a" class="nq nr it bd ns nt oy nv nw nx oz nz oa ki pa kj oc kl pb km oe ko pc kp og oh bi translated">其他提示</h1><p id="cfa9" class="pw-post-body-paragraph li lj it lk b ll pd kd ln lo pe kg lq lr pf lt lu lv pg lx ly lz ph mb mc md im bi translated"><strong class="lk jd">迁移学习和自我培训是相加的</strong></p><p id="9d06" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如在<a class="ae mo" href="https://arxiv.org/pdf/2006.06882.pdf" rel="noopener ugc nofollow" target="_blank"> Zoph等人关于COCO训练的2020 </a>中所发现的，执行从COCO到我们数据集的迁移学习，然后在嘈杂的学生环境中执行自我训练，所产生的结果比单独执行这两个步骤中的任何一个都要好。很可能任何应用于生产模型的迁移学习也可以应用于SSL模型，并带来同等或更多的好处。</p><p id="cc11" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">适当的数据扩充很重要</strong></p><p id="31f7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于数据扩充是现代SSL方法的主要组成部分，所以要确保这些扩充对您的领域有意义。例如，如果可用的增强集包括水平翻转，那么应该被训练来区分左箭头和右箭头的边界框的分类器显然会受到影响。</p><p id="7369" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，在(<a class="ae mo" href="https://arxiv.org/pdf/2005.04757.pdf" rel="noopener ugc nofollow" target="_blank"> Sohn等人，2020-B </a>)和吵闹的学生(<a class="ae mo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank">谢等人，2019 </a>)中，他们观察到，在自我训练中，对教师模型使用数据增强会导致下游学生模型较差。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/372f52acb073f93321560cd38f2e4c10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*5iOb61XqcGYlBLqRNf9bYg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(表6来自<a class="ae mo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank">谢等，2019 </a>)。在这项消融研究中，他们说明了具有增强功能的教师模型比没有增强功能的教师模型表现稍差(在130万张未标记图像上，84.4%对85.1%)。</p></figure><p id="1705" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，我们发现嘈杂的学生和STAC在我们的数据集上的表现与增强的教师模型相等或略好于非增强的教师模型。虽然我们的结果对于我们自己的数据集来说可能是一个特例，但我们相信这表明了广泛实验的<strong class="lk jd"> <em class="mn">重要性，以及对你在论文中读到的观点的所谓成功和失败感到好奇。</em> </strong>论文中显示的经验结果是一个很好的开端，但成功肯定是无法保证的，而且从理论角度来看，SSL中仍有许多东西没有得到很好的理解。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="f358" class="nq nr it bd ns nt nu nv nw nx ny nz oa ki ob kj oc kl od km oe ko of kp og oh bi translated">离别赠言</h1><p id="172a" class="pw-post-body-paragraph li lj it lk b ll pd kd ln lo pe kg lq lr pf lt lu lv pg lx ly lz ph mb mc md im bi translated">半监督学习(SSL)在过去的一年中一直是我们工作的一个令人兴奋的领域，它在我们的生产模型中的最终结果向我们(希望你们所有人)表明，在某些情况下可以并且应该考虑SSL。</p><p id="8e07" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特别是，对吵闹的学生进行自我训练对改进我们的目标检测模型是有效的。以下是我们在研究和生产深层SSL技术时学到的3个主要经验:</p><ul class=""><li id="893c" class="mv mw it lk b ll lm lo lp lr mx lv my lz mz md na nb nc nd bi translated"><strong class="lk jd">简约为王。</strong></li><li id="b05b" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated"><strong class="lk jd">启发式伪标签精化非常有效。</strong></li><li id="5c95" class="mv mw it lk b ll ne lo nf lr ng lv nh lz ni md na nb nc nd bi translated"><strong class="lk jd">半监督图像分类的进展很难转化为目标检测。</strong></li></ul><p id="fa95" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天，许多深度学习工程仍然在为潜在的应用进行反复试验，我们希望你带着更多的先验知识离开，以推进半监督学习的工作。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><blockquote class="mp mq mr"><p id="4097" class="li lj mn lk b ll lm kd ln lo lp kg lq ms ls lt lu mt lw lx ly mu ma mb mc md im bi translated"><strong class="lk jd">作者Varun Nair，杜克大学四年级本科生，前</strong><a class="ae mo" href="https://uizard.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd"/></a><strong class="lk jd">深度学习研究实习生。</strong></p><p id="52e8" class="li lj mn lk b ll lm kd ln lo lp kg lq ms ls lt lu mt lw lx ly mu ma mb mc md im bi translated">致谢:</p><p id="4f6f" class="li lj mn lk b ll lm kd ln lo lp kg lq ms ls lt lu mt lw lx ly mu ma mb mc md im bi translated">非常感谢<strong class="lk jd"> Javier Fuentes Alonso </strong>和<strong class="lk jd"> Tony Beltramelli </strong>阅读了这篇文章的几份初稿，并在我在Uizard工作期间成为了令人惊叹的同事和导师。我还要感谢Uizard的整个团队，感谢他们支持我，为我创造了一个绝佳的工作环境，无论是面对面的还是远程的。如果你有兴趣了解更多关于Uizard的工作和职位空缺，请查看我们的网站<a class="ae mo" href="https://uizard.io/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="d80d" class="li lj mn lk b ll lm kd ln lo lp kg lq ms ls lt lu mt lw lx ly mu ma mb mc md im bi translated">也感谢北卡罗来纳大学/谷歌的<strong class="lk jd">Colin raff El</strong>博士对这篇文章的早期草稿提供了很好的见解和反馈，感谢谷歌的<strong class="lk jd">Kihyuk Sohn</strong>博士对我关于他的作品的问题的积极和开放的回答。</p></blockquote></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="c65b" class="nq nr it bd ns nt nu nv nw nx ny nz oa ki ob kj oc kl od km oe ko of kp og oh bi translated">附录</h1><p id="d5a4" class="pw-post-body-paragraph li lj it lk b ll pd kd ln lo pe kg lq lr pf lt lu lv pg lx ly lz ph mb mc md im bi translated"><strong class="lk jd"> A —对非分布样本的稳健性</strong></p><p id="512e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我们过去的工作RealMix ( <a class="ae mo" href="https://arxiv.org/pdf/1912.08766.pdf" rel="noopener ugc nofollow" target="_blank"> Nair et al .，2019 </a>)中，我们通过模仿<a class="ae mo" href="https://arxiv.org/pdf/1804.09170.pdf" rel="noopener ugc nofollow" target="_blank"> Oliver et al .，2018 </a>中首次建立的一个实验，研究了SSL网络中对分布外未标记样本的鲁棒性。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/cee3cfe45f560a844e4a198af3fadb4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*-FMMm1TkyzHzeprOJsHBJg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)原载于<a class="ae mo" href="https://arxiv.org/pdf/1912.08766.pdf" rel="noopener ugc nofollow" target="_blank">奈尔等人，2019 </a>。</p></figure><p id="4e56" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们最近在75%的标签错配设置下对FixMatch进行了相同的鲁棒性实验，并在下面展示了这些结果。FixMatch是一个更好的SSL应用程序，在标记和未标记的分布之间的不匹配率为0%和75%,但是，在这种情况下，它的性能与MixMatch一样差。有可能通过将RealMix中的元素与FixMatch结合起来，这种结合的技术可以克服这个问题。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pp"><img src="../Images/dbc5f33eeb0ada319f94da112f0046b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fwAKvrxSR0GqsXTCgPOs5Q.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">在六类CIFAR10上进行0%和75%分布不匹配实验的错误率。(图片由作者提供)</p></figure></div></div>    
</body>
</html>