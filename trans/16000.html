<html>
<head>
<title>What you see is what you guess</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你所看到的是你所猜测的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-you-see-is-what-you-guess-cab74d486ab9?source=collection_archive---------55-----------------------#2020-11-03">https://towardsdatascience.com/what-you-see-is-what-you-guess-cab74d486ab9?source=collection_archive---------55-----------------------#2020-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4821" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">第一次接触微软Azure计算机视觉</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/47bff29b8d1b4f6e55364a6e1a368ecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9YK81sP8Kd3D_hjQ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Alessandro Vallainc 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="bffb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">浏览微软云服务平台提供的服务菜单时，我遇到了计算机视觉(CV)。我决定玩一会儿，感受一下这项服务能提供什么。</p><p id="5516" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以我用我的github证书创建了一个免费账户，并在常规验证步骤后成功登陆(<a class="ae kv" href="https://azure.microsoft.com/en-us/free/" rel="noopener ugc nofollow" target="_blank">链接【美国T5】)。然后，我按照说明创建了一个CV实例，并获得了我的API键。</a></p><p id="5692" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该服务分析用户提供的或互联网上公开的图像和视频内容。该服务在前12个月是免费的，上限为每月5000笔交易，最大速率为每分钟20笔，这足以进行一些测试。</p><p id="6b21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从技术上讲，该服务是通过REST web服务交付的，这使我认为我可以很快开始测试它，我也确实这样做了。</p><h2 id="3d62" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">它提供了什么</h2><p id="55b5" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在CV的各种服务中，我将重点介绍图像分析。在这种情况下，CV为您提供了以下信息:</p><ul class=""><li id="faee" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated"><strong class="ky ir">标签</strong>:从数千个标签的宇宙中，CV列出了你图像中已识别的物体类型，比如<em class="mz">狗</em>、<em class="mz">树</em>或<em class="mz">车</em>。</li><li id="66e7" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated"><strong class="ky ir">对象</strong>:只要有可能，CV还会提供一个由图片中的矩形所包围的对象列表。因此，如果有三辆已识别的自行车，它将给出这三辆自行车的边界框的坐标。</li><li id="52da" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated"><strong class="ky ir">品牌</strong>:它可以从一组数以千计的知名品牌中检测标志。</li><li id="c9ab" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated"><strong class="ky ir">类别</strong>:从预先定义的86个类别的固定列表中，CV会给你的照片分配最合适的类别(例如:<em class="mz">美食_烧烤</em>或<em class="mz">户外_街道</em>)</li><li id="71f7" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated"><strong class="ky ir">描述</strong>:以您选择的语言对整个图像进行描述。实际上这是我感兴趣的特性，所以我将在这里停止列举。完整列表见<a class="ae kv" href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/overview" rel="noopener ugc nofollow" target="_blank">本</a>。</li></ul><p id="0197" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">足够的文献，让我们写一些python代码，并把一些Unsplash图像扔给CV来开始乐趣</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/cd41af4eca4295e20ca28b49c48d9000.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lhCSVSNmMc4IVrZl"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第一次尝试:托比亚斯·亚当在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><h2 id="ce06" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">简化的计算机视觉客户端</h2><p id="fb9b" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">REST web服务基本上可以在任何通用编程语言中使用。我们将在这里使用Python处理这条线上方的图像。看看吧，看看评论:</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="c7e9" class="ls lt iq nh b gy nl nm l nn no">import requests<br/>import json<br/><br/># connection details<br/># Replace this silly pun with your API<br/>azure_cv_api_key = "MyAPI Heat"<br/># same here<br/>azure_cv_endpoint = "somesubdomain.cognitiveservices.azure.com"<br/>azure_cv_resource = "vision/v3.1/analyze"<br/>language = "en"<br/># We just ask for some features<br/>visual_features = "Objects,Categories,Description"<br/>image_path = "c:/work/images/tobias-adam-Twm64rH8wdc-unsplash.jpg"<br/><br/>azure_cv_url = "https://{}/{}".format(azure_cv_endpoint,<br/>                                      azure_cv_resource)<br/>headers = {'Ocp-Apim-Subscription-Key': azure_cv_api_key,<br/>           'Content-Type': 'application/octet-stream'}<br/><br/>params = {"visualFeatures": visual_features, "language": language}<br/><br/># We need to read the image as a byte stream<br/>image_data = open(image_path, "rb").read()<br/><br/>response = requests.post(azure_cv_url, params=params, data=image_data, headers=headers)<br/><br/># assume you get a 200 status (ok)<br/>content = json.loads(response.content.decode(response.encoding))<br/><br/># This is where the picture description can be found<br/>print("Description\n{}".format(content["description"]["captions"][0]["text"]))</span><span id="ccec" class="ls lt iq nh b gy np nm l nn no"># Which objects have you found?<br/>for o in content["objects"]:<br/>    print("Object {} Parent {} Grandparent {}".format(o["object"], o["parent"]["object"]), o["parent"]["parent"]["object"])</span></pre><p id="8904" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们运行它并得到:</p><blockquote class="nq nr ns"><p id="1d96" class="kw kx mz ky b kz la jr lb lc ld ju le nt lg lh li nu lk ll lm nv lo lp lq lr ij bi translated">描述<br/>一只小象走在它妈妈的旁边<br/>对象非洲象母象祖父母哺乳动物<br/>对象非洲象母象祖父母哺乳动物</p></blockquote><p id="8573" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">哇——我知道，更大的大象可能是父亲或阿姨，但听起来真的很好。</p><h2 id="f472" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">改变语言</h2><p id="b92c" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在语言分配中，我们用“es”代替“en”。我期待的是将英语原文直接翻译成西班牙语，但这是我们得到的结果(省略了对象):</p><blockquote class="nq nr ns"><p id="c699" class="kw kx mz ky b kz la jr lb lc ld ju le nt lg lh li nu lk ll lm nv lo lp lq lr ij bi translated">描述<br/>火车上的一个小孩</p></blockquote><p id="4923" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">哪个<strong class="ky ir">不是</strong>的直译——如果你不相信我，谷歌翻译一下。这是为什么呢？我不知道，我的猜测是模型在不同的语言中被不同地训练，否则我不知道为什么会发生这种情况。</p><p id="e43b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">顺便说一句，Unsplash中由人类创作的标题是这样的:</p><blockquote class="nq nr ns"><p id="1a37" class="kw kx mz ky b kz la jr lb lc ld ju le nt lg lh li nu lk ll lm nv lo lp lq lr ij bi translated">两只灰色的大象走在灰色的天空下</p></blockquote><h2 id="44a0" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">又一次尝试</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/e13c28ad050ba7d5040cd3db0338a565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-Jv3vUuy9S-J48gR"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第二次尝试:照片由<a class="ae kv" href="https://unsplash.com/@quinoal?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Quino Al </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="b5fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我替换<code class="fe nx ny nz nh b">image_path</code>如下</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="8c69" class="ls lt iq nh b gy nl nm l nn no">image_path = "c:/work/images/quino-al-iRt9yOWzfOk-unsplash.jpg"</span></pre><p id="9bdd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">得到这个结果</p><blockquote class="nq nr ns"><p id="56b8" class="kw kx mz ky b kz la jr lb lc ld ju le nt lg lh li nu lk ll lm nv lo lp lq lr ij bi translated">描述<br/>穿衣服的人<br/>对象人<br/>对象人<br/>对象人</p></blockquote><p id="60b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该人未被识别为跑步者或运动员。为什么？也许她的腿不在画面上并没有帮助。用西班牙语说:</p><blockquote class="nq nr ns"><p id="91c3" class="kw kx mz ky b kz la jr lb lc ld ju le nt lg lh li nu lk ll lm nv lo lp lq lr ij bi translated">描述<br/>一个人的馅饼</p></blockquote><p id="cb30" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有趣的是，CV已经认出了照片中的第三个人，即使照片很模糊，而且只有不到三分之一的身体是可见的。</p><h2 id="2a52" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">光学字符识别</h2><p id="9bd7" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">CV中提供的另一个服务是从提供的图像中提取文本。要调用服务，请替换资源:</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="0411" class="ls lt iq nh b gy nl nm l nn no">azure_cv_resource = "vision/v3.1/ocr"</span></pre><p id="f9ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">参数是:</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="c190" class="ls lt iq nh b gy nl nm l nn no">params = {'language': 'unk', 'detectOrientation': 'true'}</span></pre><p id="a6c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在生成的字典<code class="fe nx ny nz nh b">(content)</code>中，您会发现一个名为<code class="fe nx ny nz nh b">regions</code>的列表，其中包含CV找到的所有填充文本框。我已经用几张图片试过了，结果好坏参半。不要用超bif图片尝试，有大小限制。</p><h2 id="71df" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">结论</h2><p id="60cb" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">计算机视觉和图像识别的进步是惊人的。虽然图像分析还没有达到完美，但CV等服务的潜在应用是巨大的。</p><p id="3a23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">CV提供了更多的可能性，例如使用定制模型(称为定制视觉的独立服务)或分析视频。</p><p id="9e1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该服务主要是将这一功能集成到第三方开发应用程序中。写这篇文章是为了鼓励你使用这个服务，并想象这个额外的功能可能带来的新的应用。</p></div></div>    
</body>
</html>