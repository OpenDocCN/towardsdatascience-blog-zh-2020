<html>
<head>
<title>Pitfalls To Avoid while Interpreting Machine Learning-PDP/ICE case</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释机器学习时要避免的陷阱——PDP/ICE案例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pitfalls-to-avoid-while-interpreting-machine-learning-pdp-ice-case-c63eeb596590?source=collection_archive---------26-----------------------#2020-10-21">https://towardsdatascience.com/pitfalls-to-avoid-while-interpreting-machine-learning-pdp-ice-case-c63eeb596590?source=collection_archive---------26-----------------------#2020-10-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a3ee3f77ff16f17268a40d3a46833fa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NKckelJV_DUlRj-G"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">莱奥·麦克拉伦(@leiomclaren) 在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="f25b" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">摘要</h2><p id="6e23" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">今天你可以找到很多关于可解释人工智能的文章，其中一些可以在这里找到<a class="ae kc" href="https://towardsdatascience.com/tagged/xai" rel="noopener" target="_blank"><strong class="lb ir"/></a><strong class="lb ir">。最标准的可解释人工智能指南无疑是克里斯托夫·莫尔纳尔的这本书。</strong>当我看到最近的论文<a class="ae kc" href="https://arxiv.org/abs/2007.04131" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir">解读机器学习模型时要避免的陷阱</strong> </a> <strong class="lb ir">，</strong>时，我决定写一些关于它的博客。这是本文中提出的一个方面。</p><p id="1f5b" class="pw-post-body-paragraph kz la iq lb b lc lu le lf lg lv li lj km lw ll lm kq lx lo lp ku ly lr ls lt ij bi translated">本文的重点是在解释部分依赖图(PDPs个体条件期望图(ICE)时我们需要避免的陷阱。这些是事后技术，用于观察模型如何通过保持所有外部变量不变来做出决策，除了一个(在PDP的情况下还有两个)被视为感兴趣的<strong class="lb ir">特征</strong>。这个变量可以取所有可能的值，我们观察它对模型决策的边际影响。要有正确的理解请参考<a class="ae kc" href="https://christophm.github.io/interpretable-ml-book/pdp.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir">本</strong> </a>。</p><h2 id="3b5b" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">定义</h2><p id="ed0f" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">使用加性模型时，要素依赖性是一个问题，因为多重共线性会导致普通最小二乘法失败，或者使数据科学家难以解释模型的系数。但基于树的模型就不是这样了，无论它是决策树还是袋装集成(例如随机森林)还是提升树(像梯度提升机器)。在使用这种模型时，我们从来不关心严格检查外生变量之间的特征依赖性。为什么我们要？树基于单变量要素分割工作，最终多重共线性不会像Logit那样造成混乱。</p><p id="08be" class="pw-post-body-paragraph kz la iq lb b lc lu le lf lg lv li lj km lw ll lm kq lx lo lp ku ly lr ls lt ij bi translated">然而，PDP/ICE的工作假设感兴趣的特征和互补的特征集应该是独立的。他们为什么要独立？PDP/ICE技术基于数据点的扰动。感兴趣特征的扰动由以下因素产生:</p><ul class=""><li id="6a91" class="lz ma iq lb b lc lu lg lv km mb kq mc ku md lt me mf mg mh bi translated">从特征等距网格替换。</li><li id="372d" class="lz ma iq lb b lc mi lg mj km mk kq ml ku mm lt me mf mg mh bi translated">数值的随机抽样。</li><li id="e15c" class="lz ma iq lb b lc mi lg mj km mk kq ml ku mm lt me mf mg mh bi translated">使用分位数替换。(我们的图将基于百分位数)</li></ul><p id="58b6" class="pw-post-body-paragraph kz la iq lb b lc lu le lf lg lv li lj km lw ll lm kq lx lo lp ku ly lr ls lt ij bi translated">在所有这三种情况下，当扰动时，从属特征会导致联合分布，该分布将具有在现实世界中不可行的外推数据点。在这种情况下解释一个特性的边际贡献会导致错误的解释。我们将很快在我们的例子中观察到这种现象。</p><h2 id="504e" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">数据和问题陈述</h2><p id="4974" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">我们从来自<strong class="lb ir"/><a class="ae kc" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"><strong class="lb ir">ka ggle</strong></a><strong class="lb ir">的<a class="ae kc" href="https://www.kaggle.com/c/bike-sharing-demand/data" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir">自行车共享数据集</strong> </a> <strong class="lb ir"> </strong>开始分析。</strong>记录自行车共享信息的地点在华盛顿特区，在<strong class="lb ir">北半球</strong>(这对我们的分析很重要)。根据时间、季节、天气信息，我们需要预测预订数量(自行车租赁)。相应的<a class="ae kc" href="https://www.kaggle.com/satyads/pitfalls-to-avoid-while-using-pdp-or-ice-plots" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir">笔记本</strong> </a>为本文。</p><p id="5706" class="pw-post-body-paragraph kz la iq lb b lc lu le lf lg lv li lj km lw ll lm kq lx lo lp ku ly lr ls lt ij bi translated">我们从导入库开始</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="ccb9" class="kd ke iq ms b gy mw mx l my mz">import numpy as np<br/>import pandas as pd<br/>import calendar<br/>import seaborn as sns<br/>from sklearn.ensemble import RandomForestRegressor<br/>from sklearn.model_selection import train_test_split<br/>from yellowbrick.target import FeatureCorrelation<br/>from yellowbrick.regressor import ResidualsPlot<br/>from pdpbox import pdp, info_plots<br/>import statsmodels.formula.api as smf<br/>import matplotlib.pyplot as plt<br/>plt.rcParams['figure.dpi'] = 100</span></pre><p id="ee67" class="pw-post-body-paragraph kz la iq lb b lc lu le lf lg lv li lj km lw ll lm kq lx lo lp ku ly lr ls lt ij bi translated">我们加载数据集，提取基于时间的特征，并检查它。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="3df9" class="kd ke iq ms b gy mw mx l my mz">df = pd.read_csv('train.csv')<br/>df['datetime'] = pd.to_datetime(df['datetime'])#Convert to Pandas Datetime Type<br/>df['year'] = df['datetime'].dt.year#Extract the Year as a Feature<br/>df['month'] = df['datetime'].dt.month#Extract the Month as a Feature<br/>df['hour'] = df['datetime'].dt.hour#Extract the Hour as a Feature<br/>df.head() #Print the top 5 rows of the dataframe</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/515576a562ba7c4f78a026867b6d33aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Bd-hWXHd398JdcjJ-nJNA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">数据样本(来源:作者)</p></figure><h2 id="f0c9" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">特征相关性(连续变量)</h2><p id="ca3d" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">我们计算连续变量的皮尔逊相关。我们观察到温度(“temp”)和“感觉”温度(“atemp”)高度相关。这为我们提供了评估PDP图的案例。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="6fb1" class="kd ke iq ms b gy mw mx l my mz">#Pearson Correlation for Continiuos Variables<br/>continious_variables = df[['temp', 'atemp', 'humidity', 'windspeed','count']]<br/>corr = continious_variables.corr()<br/>corr = sns.heatmap(corr, <br/>        xticklabels=corr.columns,<br/>        yticklabels=corr.columns,<br/>           annot=True, fmt="f",cmap="Blues")</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/052ed5fdeec4f58f1277543c1fcf848a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DY9D9WwSCPYitkog9zx-EQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">皮尔森相关性(来源:作者)</p></figure><h2 id="1575" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">特征相关性(分类变量到连续变量)</h2><p id="d52b" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">我们观察到租赁预订的连续特征—温度因素(“temp”)和两个分类因素—季节(“season”)和月份(“month”)之间的相关性。计算两个相关性的方差分析表，即带有“季节”的“温度”和带有“月份”的“温度”。我们观察到在两种情况下F统计量的P值都为零。这表明在“月”和“季”的类别中，温度(“temp”)的组均值在统计上是不同的。这表明这些特征与<strong class="lb ir">线性相关</strong>。这是非常直观的，因为不同月份/季节的平均温度肯定会有所不同。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="0d2c" class="kd ke iq ms b gy mw mx l my mz">#Fit an OLS with temperature as the continious target variable <br/>#and season as the explanatory categorical variable.<br/>model = smf.ols(formula='temp ~ C(season)', data=df)  <br/>res = model.fit()<br/>print('ANOVA - temp~season')<br/>summary = res.summary() #OLS Summary<br/>print(summary.tables[0]) #Print the Anova Table only</span><span id="a248" class="kd ke iq ms b gy nc mx l my mz">#Fit an OLS with temperature as the continious target variable <br/>#and month as the explanatory categorical variable.<br/>model = smf.ols(formula='temp ~ C(month)', data=df)<br/>res = model.fit()<br/>print('ANOVA - temp~month')<br/>summary = res.summary() #OLS SUmmary<br/>print(summary.tables[0]) #Print the Anova Table only</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/b4fc0c6fd1f1851cce97df548daca731.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j5cqDGcFO_fzAPX_m18aKA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">方差分析表(来源:作者)</p></figure><h2 id="1b75" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">部分相关图(无相关变量)</h2><p id="5678" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">我们首先拟合一个随机森林回归变量，确保我们不采用任何连续或分类的因变量。我们确保我们有一个很好的契合。残差图(如下所示)表明残差是均匀随机分布的，其平均值约为<strong class="lb ir">零</strong>。更不用说训练和测试的<strong class="lb ir">良好的R平方</strong>值。这两个因素都表明很适合。为了解释模型的预测决策，一个拟合良好的模型是绝对必要的。</p><p id="b643" class="pw-post-body-paragraph kz la iq lb b lc lu le lf lg lv li lj km lw ll lm kq lx lo lp ku ly lr ls lt ij bi translated">除了PDP图(下面粗线所示)，我们还有两个<strong class="lb ir">集群</strong>版本的ICE图。两条细细的<strong class="lb ir">蓝色</strong>线代表各种冰图(分别对应‘temp’高于平均值和低于平均值的边际效应)。PDP从平均值<strong class="lb ir"> ~77 </strong>(出租销售)开始。随着温度(“temp”)的升高，租赁销售额持续增加，直到“temp”值达到<strong class="lb ir"> ~30。</strong>此后，销量下降，最终平均在<strong class="lb ir"> ~217 </strong>左右。相应的代码和情节如下。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="e209" class="kd ke iq ms b gy mw mx l my mz">#Drop the correlated variable 'atemp' and then fit<br/>X,y = df[['year','hour','temp','humidity','windspeed','holiday','workingday']],df['count']<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)</span><span id="955b" class="kd ke iq ms b gy nc mx l my mz">model = RandomForestRegressor(n_estimators=200) #Fit a Random Forest with 2oo Trees<br/>visualizer = ResidualsPlot(model, qqplot=True) #Instantiate a Residual Plot Class</span><span id="f93c" class="kd ke iq ms b gy nc mx l my mz">visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer<br/>visualizer.score(X_test, y_test)  # Evaluate the model on the test data<br/>visualizer.show()</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/9213f99cae19419f606b215ec5f2c7a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B6ZC2DhNtYc59jcr1OOmdw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">拟合优度(没有因变量的回归)(来源:作者)</p></figure><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="732d" class="kd ke iq ms b gy mw mx l my mz">pdp_temp = pdp.pdp_isolate(<br/>    model=model, dataset=X_train, model_features=X_train.columns, feature='temp'<br/>)<br/>fig, axes = pdp.pdp_plot(pdp_temp, 'temp',center=False, cluster=True,n_cluster_centers=2,\<br/>                         plot_lines=True, x_quantile=True, show_percentile=True, plot_pts_dist=True )</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/8f7429a5f177db3d333f71e9445514b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PA4CbdUMCOcuMsiSg5IB_Q.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">部分相关图(有<strong class="bd ne">无</strong>因变量)。左边的红色方块在大约77处，右边的在大约217处，标志着PDP的结束(来源:作者)</p></figure><h2 id="74e3" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">部分相关图(有相关变量)</h2><p id="c51b" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">在这种情况下，我们考虑两个高度相关的连续变量—“temp”和“atemp”都作为回归变量。PDP看起来更平了，不是吗？PDP起始值为<strong class="lb ir"> ~146 </strong>(租赁的平均销售额)。这与上面那个从<strong class="lb ir"> ~77 </strong>开始的形成对比。该图这次在大约值<strong class="lb ir"> ~211 </strong>处结束。<strong class="lb ir">为什么两个情节不一样？</strong></p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="208e" class="kd ke iq ms b gy mw mx l my mz">#Include the correlated variable 'atemp' and then fit<br/>X,y = df[['year','hour','temp','atemp','humidity','windspeed','holiday','workingday']],df['count']<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)</span><span id="57c8" class="kd ke iq ms b gy nc mx l my mz">model = RandomForestRegressor(n_estimators=200)<br/>visualizer = ResidualsPlot(model, qqplot=True)</span><span id="111e" class="kd ke iq ms b gy nc mx l my mz">visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer<br/>visualizer.score(X_test, y_test)  # Evaluate the model on the test data<br/>visualizer.show()</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/c62265b5717aa7cfa7d18d42102a9a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UFyr1nZRCJnujFE2qYQQog.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">拟合优度(因变量回归)(来源:作者)</p></figure><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/0efcf31be121f7c4d5f3c6c337b82599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lrn_lfNhevkg24EfPRrVTA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">部分相关图(有因变量)。左边的红色方块在146左右，右边的在211左右，标志着PDP的结束(来源:作者)</p></figure><h2 id="4204" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">要避免的陷阱</h2><p id="ac16" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">PDP与扰动一起工作，即对于每个数据点，我们外推感兴趣的特征的值(这里以百分位数替换)。相关变量导致虚假数据点。例如，在下表中，我们看到七月份的外推值<strong class="lb ir">为0.82 </strong>，以及“atemp”值<strong class="lb ir">为32.5 </strong>(在表格中以红色框突出显示)。这样的数据点是不可行的(华盛顿特区7月的气温永远不可能是0.82)。因此，每个变量的影响变得平滑，我们看到虚假的PDP(在我们的情况下是一个更平坦的曲线)。<strong class="lb ir">对此的解决方案- </strong>是在拟合之前移除一个相关变量(“temp”或“atemp”)(在这种情况下使用皮尔逊相关)。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="2e0e" class="kd ke iq ms b gy mw mx l my mz">X_train['month'] = df[df.index.isin(X_train.index)]['month']<br/>X_train['month'] = X_train['month'].apply(lambda x: calendar.month_abbr[x]) #Get the month<br/>#Get all the possible values the feature temp(based on the quantile grids) is allowed to take w.r.t <br/>#to all the data points and values of other features reamining constant.<br/>X_train['extrapolated_temp'] = [pdp_temp.feature_grids.tolist()]*len(X_train)<br/>X_train = X_train.explode('extrapolated_temp')<br/>X_train.head()</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/70a8ea80d28031ca2ae9e1d5ecfc863e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EScgYI0HhBjgnerHgMP_bw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">七月份温度的外推值为0.82(来源:作者)</p></figure><h2 id="8824" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">部分相关图—分类情况(无相关变量)</h2><p id="a241" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">现在，我们去掉‘temp’(以及‘atemp’)，取而代之的是‘season’作为回归变量。因为季节是一个分类变量，所以我们取它的一次性编码版本。我们评估拟合优度并获得PDP。PDP揭示的是，随着“季节”的变化，春季或冬季的平均租赁销售量分别为118.8和201.476。夏季和秋季销量最高(平均分别为217辆和230.4辆)。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="abb0" class="kd ke iq ms b gy mw mx l my mz">#Removing the variable 'temp' and instead using the variable 'season'<br/>X,y = df[['year','hour','season','humidity','windspeed','holiday','workingday']],df['count']<br/>X = pd.get_dummies(X,columns=['season']) #One hot encode<br/>X = X.rename(columns = {'season_1':'spring','season_2':'summer',<br/>                       'season_3':'fall','season_4':'winter'}) #Proper Renaming of Dummies<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)<br/>X_train.head()</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/9f8fd8d8d408e61ad9ee3834a4b1d85c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Bw9AB_7U0O9ystFWliznA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">一个热编码变量“季节”(来源:作者)</p></figure><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="dda2" class="kd ke iq ms b gy mw mx l my mz">model = RandomForestRegressor(n_estimators=200)<br/>visualizer = ResidualsPlot(model, qqplot=True)</span><span id="5016" class="kd ke iq ms b gy nc mx l my mz">visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer<br/>visualizer.score(X_test, y_test)  # Evaluate the model on the test data<br/>visualizer.show()</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/61b3fe8c3117ae7e5d4b36d851fa1801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SiC1N-T2Jb9nsNRrHE0_pw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">拟合优度——分类案例(无因变量的<strong class="bd ne">回归)(来源:作者)</strong></p></figure><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="a28b" class="kd ke iq ms b gy mw mx l my mz">pdp_season = pdp.pdp_isolate(<br/>    model=model, dataset=X_train, model_features=X_train.columns, <br/>    feature=['spring', 'summer', 'fall', 'winter']<br/>)<br/>fig, axes = pdp.pdp_plot(pdp_season,'season', center=False, cluster=True,n_cluster_centers=2,\<br/>                         plot_lines=True, x_quantile=True, show_percentile=True)</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/db3c52de73316a7438744e20a268dd9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pNLX15E9G4hxojNfAsUk9w.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">部分相关图(有因变量)。春季、夏季、秋季和冬季的PDP值分别为118.5、217.1、230.5和204.7。(来源:作者)</p></figure><h2 id="eff5" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">部分相关图—分类情况(有相关变量)</h2><p id="b836" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">从我们的ANOVA表中，我们知道“季节”和“温度”是相互依赖的，所以现在除了“季节”，我们还包括“温度”。我们评估拟合优度，并最终评估PDP。我们看到非常相似的结果，与没有相关变量的情况相比，这种情况下的PDP又平坦了很多。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="9552" class="kd ke iq ms b gy mw mx l my mz">#Included the dependent variable 'temp'<br/>X,y = df[['year','hour','temp','season','humidity','windspeed','holiday','workingday']],df['count']<br/>X = pd.get_dummies(X,columns=['season'])<br/>X = X.rename(columns = {'season_0':'spring','season_1':'summer',<br/>                       'season_2':'fall','season_3':'winter'})<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)</span><span id="15b5" class="kd ke iq ms b gy nc mx l my mz">#Fit the model<br/>model = RandomForestRegressor(n_estimators=200)<br/>visualizer = ResidualsPlot(model, qqplot=True)</span><span id="f47d" class="kd ke iq ms b gy nc mx l my mz">visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer<br/>visualizer.score(X_test, y_test)  # Evaluate the model on the test data<br/>visualizer.show()</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/7098524639785378f8f876cbeb7d27be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RJ-T1zIQ3m-nZO9L4CoL3w.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">拟合优度—分类案例(因变量回归)(来源:作者)</p></figure><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="b106" class="kd ke iq ms b gy mw mx l my mz">pdp_season = pdp.pdp_isolate(<br/>    model=model, dataset=X_train, model_features=X_train.columns, <br/>    feature=['spring', 'summer', 'fall', 'winter']<br/>)<br/>fig, axes = pdp.pdp_plot(pdp_season,'season', center=False, cluster=True,n_cluster_centers=2,\<br/>                         plot_lines=True, x_quantile=True, show_percentile=True)</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/3881b3b283967015f157b3c4ca6df29c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-VWtaeYBNjZuudnleHqYSw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">部分相关图(有因变量)。春季、夏季、秋季和冬季的PDP值分别为165.6、199.6、208.6和215.2。(来源:作者)</p></figure><h2 id="e0eb" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">要避免的陷阱</h2><p id="1f62" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">因为“季节”和“温度”是相互依赖的，所以当两者都被用作回归变量时，我们看到这两个特征的效果变得平滑。这就是第二个PDP平坦很多的原因。更深入地说，我们观察“季节”的推断值。例如，第一行显示“七月”对应的外推季节是“春天”(在表中以红色突出显示)。这是一个不可行的数据点，因此会产生虚假的结果，因为两个因变量的边际效应相互抵消，并且图是平坦的。<strong class="lb ir">解决方案- </strong>我们必须检查连续分类依赖性，并从我们的回归变量列表中删除其中一个(使用<strong class="lb ir"> ANOVA </strong>)。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="b521" class="kd ke iq ms b gy mw mx l my mz">X_train['month'] = df[df.index.isin(X_train.index)]['month'] #Get the Month<br/>X_train['month'] = X_train['month'].apply(lambda x: calendar.month_abbr[x])#Get the Month<br/>#Get all the possible values the feature season is allowed to take w.r.t to all <br/>#the data points and values of other features reamining constant.<br/>X_train['extrapolated_season'] = [pdp_season.feature_grids.tolist()]*len(X_train)<br/>X_train = X_train.explode('extrapolated_season')<br/>X_train.head()</span></pre><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/3e7a8b7eb138bab982249f75fb209670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZY8Z8Ljag61Bdb2mh_uToA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">一个推断的七月“春天”的季节(来源:作者)</p></figure><h2 id="8949" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">结论</h2><p id="9160" class="pw-post-body-paragraph kz la iq lb b lc ld le lf lg lh li lj km lk ll lm kq ln lo lp ku lq lr ls lt ij bi translated">特性依赖不仅仅是关于相关性。我们可以使用<strong class="lb ir">卡方</strong>测试，以及<strong class="lb ir">非线性</strong>特性依赖测试(例如基于<strong class="lb ir">内核方法</strong>的测试)来进一步检查分类到分类的关系。上述相同的扣除也适用于<strong class="lb ir"> ICE </strong>地块。</p><p id="d5f1" class="pw-post-body-paragraph kz la iq lb b lc lu le lf lg lv li lj km lw ll lm kq lx lo lp ku ly lr ls lt ij bi translated">在本文中，我们展示了PDP和ICE图是如何因为依赖关系而被误解的。</p><h1 id="9ca8" class="nm ke iq bd kf nn no np ki nq nr ns kl nt nu nv kp nw nx ny kt nz oa ob kx oc bi translated">参考</h1><ol class=""><li id="5edd" class="lz ma iq lb b lc ld lg lh km od kq oe ku of lt og mf mg mh bi translated">Christoph Molnar、Gunnar knig、Julia Herbinger、Timo Freiesleben、Susanne Dandl、Christian A. Scholbeck、Giuseppe Casalicchio、Moritz Grosse-Wentrup、Bernd Bischl-<a class="ae kc" href="https://arxiv.org/abs/2007.04131" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2007.04131</a></li><li id="6f0b" class="lz ma iq lb b lc mi lg mj km mk kq ml ku mm lt og mf mg mh bi translated"><a class="ae kc" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">https://christophm.github.io/interpretable-ml-book/</a></li><li id="e3bd" class="lz ma iq lb b lc mi lg mj km mk kq ml ku mm lt og mf mg mh bi translated"><a class="ae kc" href="https://compstat-lmu.github.io/iml_methods_limitations/pdp-correlated.html" rel="noopener ugc nofollow" target="_blank">https://compstat-lmu . github . io/IML _ methods _ limits/PDP-correlated . html</a></li></ol><h2 id="20a6" class="kd ke iq bd kf kg kh dn ki kj kk dp kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">使用的库/数据</h2><ol class=""><li id="8c43" class="lz ma iq lb b lc ld lg lh km od kq oe ku of lt og mf mg mh bi translated"><a class="ae kc" href="https://www.kaggle.com/c/bike-sharing-demand/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/bike-sharing-demand/data</a></li><li id="2ae3" class="lz ma iq lb b lc mi lg mj km mk kq ml ku mm lt og mf mg mh bi translated"><a class="ae kc" href="https://www.scikit-yb.org/en/latest/" rel="noopener ugc nofollow" target="_blank">https://www.scikit-yb.org/en/latest/</a></li><li id="7b66" class="lz ma iq lb b lc mi lg mj km mk kq ml ku mm lt og mf mg mh bi translated"><a class="ae kc" href="https://www.statsmodels.org/stable/generated/statsmodels.formula.api.ols.html#statsmodels.formula.api.ols" rel="noopener ugc nofollow" target="_blank">https://www . stats models . org/stable/generated/stats models . formula . API . ols . html # stats models . formula . API . ols</a></li><li id="1a9d" class="lz ma iq lb b lc mi lg mj km mk kq ml ku mm lt og mf mg mh bi translated"><a class="ae kc" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . randomforestclassifier . html</a></li><li id="bb0a" class="lz ma iq lb b lc mi lg mj km mk kq ml ku mm lt og mf mg mh bi translated"><a class="ae kc" href="https://pdpbox.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> https://pdpbox.readthedocs.io/en/latest/ </a></li></ol></div></div>    
</body>
</html>