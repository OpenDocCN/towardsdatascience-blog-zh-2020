<html>
<head>
<title>Report is too long to read? Use NLP to create a summary</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">报告太长无法阅读？使用NLP创建摘要</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/report-is-too-long-to-read-use-nlp-to-create-a-summary-6f5f7801d355?source=collection_archive---------12-----------------------#2020-10-29">https://towardsdatascience.com/report-is-too-long-to-read-use-nlp-to-create-a-summary-6f5f7801d355?source=collection_archive---------12-----------------------#2020-10-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/048371ef12a9ebf8495bbd0dd7fe381d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-LO-i2tda4IonjZW"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">塞巴斯蒂安·赫尔曼在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="ef6e" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">创建个人文本摘要的指南</h2></div><p id="b562" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你是否曾经有过多的报告需要阅读，而你只是想快速总结每份报告？你有没有遇到过这样的情况，每个人都只想读一份摘要而不是一份完整的报告？</p><p id="ec07" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在21世纪，摘要已经成为解决数据过载问题的一种非常有用的方法。在这个故事中，我将向您展示如何使用Python中的自然语言处理(NLP)创建您的个人文本摘要。</p><p id="7279" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">前言:创建个人文本摘要并不困难——初学者很容易做到！</em></p><h1 id="82f6" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">什么是文本摘要？</h1><p id="1fba" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">这基本上是一个任务，生成一个准确的总结，同时保持关键信息，不失去整体意义。</p><p id="39b3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有两种常见的总结类型:</p><ul class=""><li id="74c5" class="mp mq jg kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated"><strong class="kx jh">抽象概括</strong> &gt; &gt;从原文生成新句子。</li><li id="6034" class="mp mq jg kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated"><strong class="kx jh">摘录摘要</strong> &gt; &gt;识别重要的句子，并使用这些句子创建摘要。</li></ul><h1 id="fe80" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated"><strong class="ak">我应该使用哪种总结方法，为什么？</strong></h1><p id="4a09" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">我使用提取摘要是因为我可以将这种方法应用于许多文档，而不必进行大量(令人生畏的)机器学习模型训练任务。</p><p id="2138" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">除此之外，提取摘要比抽象摘要给出更好的摘要结果，因为抽象摘要必须从原始文本生成新的句子，这是比数据驱动的方法更难提取重要句子的方法。</p><h1 id="3eab" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">如何创建自己的文本摘要？</h1><p id="83bc" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">我们将使用单词直方图来排列句子的重要性，然后创建摘要。这样做的好处是，您不需要训练您的模型将它用于您的文档。</p><h2 id="13a9" class="nd lt jg bd lu ne nf dn ly ng nh dp mc le ni nj me li nk nl mg lm nm nn mi no bi translated">文本摘要工作流</h2><p id="3d8e" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">下面是我们将遵循的工作流程…</p><p id="4050" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">导入文本&gt; &gt; &gt; &gt;清理文本并拆分成句子&gt; &gt;移除停用词&gt; &gt;构建词直方图&gt; &gt;排列句子&gt; &gt;选择前N个句子进行汇总</em></p><p id="469d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> (1)样本文本</strong></p><p id="9ba2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我使用了一篇名为<strong class="kx jh">苹果以5000万美元收购人工智能初创公司的新闻文章中的文字来推进其应用程序。</strong>你可以在这里找到原来的新闻文章<a class="ae jd" href="https://analyticsindiamag.com/apple-acquires-ai-startup-for-50-million-to-advance-its-apps/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="2f75" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">也可以从<a class="ae jd" href="https://github.com/louisteo9/personal-text-summarizer" rel="noopener ugc nofollow" target="_blank"> my Github </a>下载文本文档。</p><p id="1ff8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> (2)导入库</strong></p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="1e71" class="nd lt jg nu b gy ny nz l oa ob"># Natural Language Tool Kit (NLTK)<br/>import nltk<br/>nltk.download('stopwords')<br/>nltk.download('punkt')</span><span id="d484" class="nd lt jg nu b gy oc nz l oa ob"># Regular Expression for text preprocessing<br/>import re</span><span id="9cd6" class="nd lt jg nu b gy oc nz l oa ob"># Heap (priority) queue algorithm to get the top sentences<br/>import heapq</span><span id="61cf" class="nd lt jg nu b gy oc nz l oa ob"># NumPy for numerical computing<br/>import numpy as np</span><span id="b5dc" class="nd lt jg nu b gy oc nz l oa ob"># pandas for creating DataFrames<br/>import pandas as pd</span><span id="8702" class="nd lt jg nu b gy oc nz l oa ob"># matplotlib for plot<br/>from matplotlib import pyplot as plt<br/>%matplotlib inline</span></pre><p id="65b4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> (3)导入文本并进行预处理</strong></p><p id="8674" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有很多方法可以做到这一点。这里的目标是有一个清晰的文本，我们可以把它输入到我们的模型中。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="ed65" class="nd lt jg nu b gy ny nz l oa ob"># load text file<br/>with open('Apple_Acquires_AI_Startup.txt', 'r') as f:<br/>    file_data = f.read()</span></pre><p id="53a1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这里，我们使用正则表达式来做文本预处理。我们将(A)用空格(如果有的话)替换参考号，即[1]、[10]、[20]，(B)用单个空格替换一个或多个空格。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="847a" class="nd lt jg nu b gy ny nz l oa ob">text = file_data<br/># replace reference number with empty space, if any..<br/>text = re.sub(r'\[[0-9]*\]',' ',text) </span><span id="dd37" class="nd lt jg nu b gy oc nz l oa ob"># replace one or more spaces with single space<br/>text = re.sub(r'\s+',' ',text)</span></pre><p id="523d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们用小写字母(没有特殊字符、数字和额外的空格)形成一个<strong class="kx jh">干净的文本</strong>,并将其分割成单个单词，用于单词得分计算和单词直方图的形成。</p><p id="7c94" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">形成干净文本的原因是算法不会将例如<strong class="kx jh">“理解”</strong>和<strong class="kx jh">理解</strong>视为两个不同的单词。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="bf33" class="nd lt jg nu b gy ny nz l oa ob"># convert all uppercase characters into lowercase characters<br/>clean_text = text.lower()</span><span id="98c6" class="nd lt jg nu b gy oc nz l oa ob"># replace characters other than [a-zA-Z0-9], digits &amp; one or more spaces with single space<br/>regex_patterns = [r'\W',r'\d',r'\s+']<br/>for regex in regex_patterns:<br/>    clean_text = re.sub(regex,' ',clean_text)</span></pre><p id="91c1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> (4)将文本分割成句子</strong></p><p id="95e9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们使用NLTK <strong class="kx jh"> sent_tokenize() </strong>方法将文本分割成句子。我们将评估每个句子的重要性，然后决定我们是否应该在总结中包含每个句子。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="b161" class="nd lt jg nu b gy ny nz l oa ob">sentences = nltk.sent_tokenize(text)</span></pre><p id="4c59" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> (5)删除停止字</strong></p><p id="ad85" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">停用词是对句子没有多大意义的英语单词。可以安全地忽略它们，而不会牺牲句子的含义。我们已经在“(2)导入库”部分下载了一个带有英文停用词的文件。</p><p id="1074" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里，我们将获得停用词列表，并将其存储在<strong class="kx jh"> stop_word </strong>变量中。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="a063" class="nd lt jg nu b gy ny nz l oa ob"># get stop words list<br/>stop_words = nltk.corpus.stopwords.words('english')</span></pre><p id="293e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> (6)建立单词直方图</strong></p><p id="12da" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们根据每个单词在整篇文章中出现的次数来评估它的重要性。</p><p id="c35f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将通过(1)拆分<strong class="kx jh"> clean_text </strong>中的单词，(2)删除停用词，然后(3)检查每个单词在文本中出现的频率。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="7f4f" class="nd lt jg nu b gy ny nz l oa ob"># create an empty dictionary to house the word count<br/>word_count = {}</span><span id="9263" class="nd lt jg nu b gy oc nz l oa ob"># loop through tokenized words, remove stop words and save word count to dictionary<br/>for word in nltk.word_tokenize(clean_text):<br/>    # remove stop words<br/>    if word not in stop_words:<br/>        # save word count to dictionary<br/>        if word not in word_count.keys():<br/>            word_count[word] = 1<br/>        else:<br/>            word_count[word] += 1</span></pre><p id="9adc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们绘制单词直方图，看看结果。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="bb01" class="nd lt jg nu b gy ny nz l oa ob">plt.figure(figsize=(16,10))<br/>plt.xticks(rotation = 90)<br/>plt.bar(word_count.keys(), word_count.values())<br/>plt.show()</span></pre><figure class="np nq nr ns gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/5ca2f18d422a14fdb18f2235e42ad5d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UdsTZJByLiZtWTSALDfT5w.png"/></div></div></figure><p id="6b64" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">啊啊啊啊……看剧情有点难。让我们将其转换为水平条形图，并只显示前20个单词，下面有一个帮助函数。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="dcd1" class="nd lt jg nu b gy ny nz l oa ob"># helper function for plotting the top words.<br/>def plot_top_words(word_count_dict, show_top_n=20):<br/>    word_count_table = pd.DataFrame.from_dict(word_count_dict, orient = 'index').rename(columns={0: 'score'})<br/>    word_count_table.sort_values(by='score').tail(show_top_n).plot(kind='barh', figsize=(10,10))<br/>    plt.show()</span></pre><p id="629c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们展示前20个单词。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="a091" class="nd lt jg nu b gy ny nz l oa ob">plot_top_words(word_count, 20)</span></pre><figure class="np nq nr ns gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/4b0f12c2201068abdf8a9ea270622cf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*hbG_AYOy98reTdZYnp2KjQ.png"/></div></figure><p id="ae2d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从上面的剧情中，我们可以看到<strong class="kx jh">‘ai’</strong>和<strong class="kx jh">‘apple’</strong>这几个字出现在顶部。这很有意义，因为这篇文章是关于苹果收购一家人工智能初创公司的。</p><p id="eb39" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> (6)根据分数对句子进行排序</strong></p><p id="1f7e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们将根据句子得分对每个句子的重要性进行排名。我们将:</p><ul class=""><li id="1f21" class="mp mq jg kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated">删除超过30个单词的句子，认识到长句子并不总是有意义的* *；</li><li id="dc5e" class="mp mq jg kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">然后，将构成句子的每个单词的得分(计数)相加，形成句子得分。</li></ul><p id="6d1c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">得分高的句子将构成我们的顶级句子。上面的句子将构成我们以后的总结。</p><p id="2114" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">** <strong class="kx jh">注:</strong>以我的经验来看，<strong class="kx jh"> 25 </strong>到<strong class="kx jh"> 30 </strong>之间的任何字数都应该给你一个很好的总结。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="6be0" class="nd lt jg nu b gy ny nz l oa ob"># create empty dictionary to house sentence score    <br/>sentence_score = {}</span><span id="bcdc" class="nd lt jg nu b gy oc nz l oa ob"># loop through tokenized sentence, only take sentences that have less than 30 words, then add word score to form sentence score<br/>for sentence in sentences:<br/>    # check if word in sentence is in word_count dictionary<br/>    for word in nltk.word_tokenize(sentence.lower()):<br/>        if word in word_count.keys():<br/>            # only take sentence that has less than 30 words<br/>            if len(sentence.split(' ')) &lt; <strong class="nu jh">30</strong>:<br/>                # add word score to sentence score<br/>                if sentence not in sentence_score.keys():<br/>                    sentence_score[sentence] = word_count[word]<br/>                else:<br/>                    sentence_score[sentence] += word_count[word]</span></pre><p id="f3e6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将<strong class="kx jh"> sentence_score </strong>字典转换成数据帧，并显示句子和分数。</p><p id="fe70" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">注意</strong> : dictionary不允许你根据分数对句子进行排序，所以你需要将dictionary中存储的数据转换成DataFrame。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="60c1" class="nd lt jg nu b gy ny nz l oa ob">df_sentence_score = pd.DataFrame.from_dict(sentence_score, orient = 'index').rename(columns={0: 'score'})<br/>df_sentence_score.sort_values(by='score', ascending = False)</span></pre><figure class="np nq nr ns gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/a8dad21c47c4ac4a976b29048b9b056c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*354O9moWFr-MbtZH-MYVpw.png"/></div></div></figure><p id="6835" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> (7)选择排名靠前的句子进行总结</strong></p><p id="f9a9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们使用堆队列算法选择前3个句子并存储在<strong class="kx jh"> best_sentences </strong>变量中。</p><p id="d91b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通常3-5句话就足够了。根据你的文档的长度，随意改变要显示的顶部句子的数量。</p><p id="6750" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这种情况下，我选择了<strong class="kx jh"> 3 </strong>，因为我们的文本是一篇相对较短的文章。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="cc47" class="nd lt jg nu b gy ny nz l oa ob"># display the best 3 sentences for summary  <strong class="nu jh"> </strong>          <br/>best_sentences = heapq.nlargest(<strong class="nu jh">3</strong>, sentence_score, key=sentence_score.get)</span></pre><p id="34a2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们使用循环函数的<strong class="kx jh"> print() </strong>和<strong class="kx jh">来显示我们的总结文本。</strong></p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="dd1e" class="nd lt jg nu b gy ny nz l oa ob">print('SUMMARY')<br/>print('------------------------')</span><span id="dee8" class="nd lt jg nu b gy oc nz l oa ob"># display top sentences based on their sentence sequence in the original text<br/>for sentence in sentences:<br/>    if sentence in best_sentences:<br/>        print (sentence)</span></pre><p id="3b98" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">这里是</strong> <a class="ae jd" href="https://github.com/louisteo9/personal-text-summarizer" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh">我的Github </strong> </a> <strong class="kx jh">的链接，来获取这个Jupyter笔记本。</strong></p><p id="e34f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是完整的Python脚本，您可以立即使用它来总结您的文本。</p><figure class="np nq nr ns gt is"><div class="bz fp l di"><div class="og oh l"/></div></figure><h1 id="43b5" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">让我们来看看算法的运行情况！</h1><p id="20b7" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">以下是一篇题为<strong class="kx jh">苹果以5000万美元收购AI初创公司以推进其应用</strong> <em class="lr">的新闻文章的原文(原文可在此处找到</em><a class="ae jd" href="https://analyticsindiamag.com/apple-acquires-ai-startup-for-50-million-to-advance-its-apps/" rel="noopener ugc nofollow" target="_blank"><em class="lr"/></a><em class="lr">)</em>:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="dcb6" class="nd lt jg nu b gy ny nz l oa ob">In an attempt to scale up its AI portfolio, Apple has acquired Spain-based AI video startup — Vilynx for approximately $50 million.</span><span id="90ca" class="nd lt jg nu b gy oc nz l oa ob">Reported by Bloomberg, the AI startup — Vilynx is headquartered in Barcelona, which is known to build software using computer vision to analyse a video’s visual, text, and audio content with the goal of “understanding” what’s in the video. This helps it categorising and tagging metadata to the videos, as well as generate automated video previews, and recommend related content to users, according to the company website.</span><span id="fb79" class="nd lt jg nu b gy oc nz l oa ob">Apple told the media that the company typically acquires smaller technology companies from time to time, and with the recent buy, the company could potentially use Vilynx’s technology to help improve a variety of apps. According to the media, Siri, search, Photos, and other apps that rely on Apple are possible candidates as are Apple TV, Music, News, to name a few that are going to be revolutionised with Vilynx’s technology.</span><span id="af94" class="nd lt jg nu b gy oc nz l oa ob">With CEO Tim Cook’s vision of the potential of augmented reality, the company could also make use of AI-based tools like Vilynx.</span><span id="82d3" class="nd lt jg nu b gy oc nz l oa ob">The purchase will also advance Apple’s AI expertise, adding up to 50 engineers and data scientists joining from Vilynx, and the startup is going to become one of Apple’s key AI research hubs in Europe, according to the news.</span><span id="fc3c" class="nd lt jg nu b gy oc nz l oa ob">Apple has made significant progress in the space of artificial intelligence over the past few months, with this purchase of UK-based Spectral Edge last December, Seattle-based Xnor.ai for $200 million and Voysis and Inductiv to help it improve Siri. With its habit of quietly purchasing smaller companies, Apple is making a mark in the AI space. In 2018, CEO Tim Cook said in an interview that the company had bought 20 companies over six months, while only six were public knowledge.</span></pre><figure class="np nq nr ns gt is gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/9d0b3b1dee3c26de0a0c6001a4234e41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*f9PYpAxKWMz7cGH7G-Fmug.gif"/></div></figure><p id="461a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">…文本摘要如下:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="e519" class="nd lt jg nu b gy ny nz l oa ob">In an attempt to scale up its AI portfolio, Apple has acquired Spain-based AI video startup — Vilynx for approximately $50 million.<br/>With CEO Tim Cook’s vision of the potential of augmented reality, the company could also make use of AI-based tools like Vilynx.<br/>With its habit of quietly purchasing smaller companies, Apple is making a mark in the AI space.</span></pre><h1 id="a5d0" class="ls lt jg bd lu lv lw lx ly lz ma mb mc km md kn me kp mf kq mg ks mh kt mi mj bi translated">结论…还有最后一个提示</h1><p id="17f2" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">恭喜你！</p><p id="905c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您已经用Python创建了自己的文本摘要器。我希望这份总结看起来相当不错。</p><p id="15dd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">需要注意的是，我们在文档中使用了<strong class="kx jh">词频</strong>来对句子进行排序。使用这种方法的优点是，它不需要任何事先培训，可以处理任何文本。另一个技巧是，您可以根据自己的喜好进一步调整汇总器，基于:</p><p id="a058" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">(1) <strong class="kx jh">顶句数量:</strong>这里简单的经验法则是，摘要的长度不要超过原文的1/4——可以是一句话，一段话，也可以是多段话，取决于原文的长度和你获取摘要的目的。如果你要总结的文字比较长，那么可以增加顶句的数量；或者</p><p id="6c68" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">(2) <strong class="kx jh">句子长度:</strong>平均来说，今天一个句子的长度在<a class="ae jd" href="https://techcomm.nz/Story?Action=View&amp;Story_id=106#:~:text=How%20many%20words%20should%20we,2009%3B%20Vincent%2C%202014)." rel="noopener ugc nofollow" target="_blank"> 15到20个单词</a>之间。因此，限制你的总结者只采用长度超过25-30个单词的句子就足够了；但是，可以随意增减字数。</p></div><div class="ab cl oj ok hu ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="ij ik il im in"><p id="17d0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">谢谢你读了这个故事。在<a class="ae jd" href="https://louisteo9.medium.com/" rel="noopener"> medium </a>上关注我，获得更多关于数据科学和机器学习的分享。</p></div></div>    
</body>
</html>