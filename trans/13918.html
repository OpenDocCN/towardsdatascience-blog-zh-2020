<html>
<head>
<title>CORD Crusher: Slicing the COVID-19 Data into Summaries</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CORD Crusher:将新冠肺炎数据分割成摘要</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cord-crusher-slicing-the-cord-19-data-into-summaries-ca5d8f95e276?source=collection_archive---------40-----------------------#2020-09-24">https://towardsdatascience.com/cord-crusher-slicing-the-cord-19-data-into-summaries-ca5d8f95e276?source=collection_archive---------40-----------------------#2020-09-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cf5d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我第一次使用自然语言处理深入研究文本数据</h2></div><p id="1661" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在12月新冠肺炎疫情爆发的早期，我和妻子在舒适的被窝里等待我们儿子的出生。在他出生后，很明显，新冠肺炎病毒的爆发控制了世界。1985年底，也就是1986年4月切尔诺贝利灾难的前几个月，我开始更多地思考自己的出生。似乎在一个不断发展的世界里，新的生活和新的挑战总是相伴而生。所以每当儿子睡觉的时候(没有我本来想的那么多)，我就悄悄拿起电脑开始涉水，然后游泳，最后一头扎进python中的自然语言处理(NLP)。</p><p id="7e25" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2020年3月，<a class="ae lb" href="https://www.whitehouse.gov/briefings-statements/call-action-tech-community-new-machine-readable-covid-19-dataset/" rel="noopener ugc nofollow" target="_blank">白宫科技政策办公室</a>发布了CORD 19数据集和行动呼吁:</p><blockquote class="lc"><p id="94e5" class="ld le iq bd lf lg lh li lj lk ll la dk translated">“呼吁国家人工智能专家开发新的文本和数据挖掘技术，帮助科学界回答与新冠肺炎相关的高优先级科学问题”</p></blockquote><figure class="ln lo lp lq lr ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi lm"><img src="../Images/bbdcd505354ad49fc1d7b95dfbe4ec3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*u-jrEq-r3MEQ8LGJ"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">由<a class="ae lb" href="https://unsplash.com/@caleblaz?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Caleb Perez </a>在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="7ecb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CORD 19是开发代码以找到关于新型冠状病毒的相关和及时信息的绝佳机会。可用的NLP包和技术的数量多得令人应接不暇(例如<a class="ae lb" href="https://medium.com/analytics-vidhya/6-steps-to-build-roberta-a-robustly-optimised-bert-pretraining-approach-e508ebe78b96" rel="noopener"> RoBERTa </a>，这也是我岳母的名字，她向我们宣布了新病毒的消息)，并且这个列表还在扩展。在本文中，我将演示如何将这些NLP包放在一起构建一个名为CORD crusher的摘要代码。我将放大我的NLP代码的组件，解释它们的功能，并展示它们是如何组合在一起的。五个主要步骤是:</p><ol class=""><li id="4d66" class="md me iq kh b ki kj kl km ko mf ks mg kw mh la mi mj mk ml bi translated">按出版年份将数据划分为时间范围</li></ol><p id="1fc2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.根据广泛的主题提取关键词和分组论文</p><p id="1de8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.从每个主题的关键词建立主题</p><p id="a68a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">4.将关键词提炼为更具体的主题短语</p><p id="daf6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">5.搜索代码19文本并按相似性排序</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h2 id="6e15" class="mt mu iq bd mv mw mx dn my mz na dp nb ko nc nd ne ks nf ng nh kw ni nj nk nl bi translated">粗略但快速提取的关键字</h2><p id="8d37" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">我发现<a class="ae lb" href="https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents" rel="noopener ugc nofollow" target="_blank"> RAKE </a>(快速自动关键词提取)既是一种快速的算法，也是一种直观的算法。像“新型冠状病毒”这样的关键词将包含多个单词，每个文档可能使用不同的术语:“新型冠状病毒”、“COVID 19”、“2019-nCoV”。RAKE只考虑单个文档中的关键字，而不是所有的CORD 19出版物。这有助于根据单个出版物的术语查找关键字。</p><p id="2695" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">RAKE关键字评分是基于词频和与其他词共现的图表。直观上，这可以理解为单词相关矩阵，其中对角线是词频，其他条目是一个单词与另一个单词相邻的概率。这种简单的方法降低了计算成本，是提高算法速度的关键(120个单词不到1毫秒)。</p><p id="56bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于关键字强烈地代表了文档的上下文，我希望出版物的标题和摘要是查找关键字的主要位置。出版物的这些部分是为了给读者提供所有内容的概要。</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="8197" class="mt mu iq nw b gy oa ob l oc od"><strong class="nw ir">Full abstract and title<br/>Are pangolins the intermediate host of the 2019 novel coronavirus (SARS-CoV-2)?</strong><br/>The outbreak of a novel corona Virus Disease 2019 (COVID-19) in the city of Wuhan, China has resulted in more than 1.7 million laboratory confirmed cases all over the world. Recent studies showed that SARS-CoV-2 was likely originated from bats, but its intermediate hosts are still largely unknown. In this study, we assembled the complete genome of a coronavirus identified in 3 sick Malayan pangolins. The molecular and phylogenetic analyses showed that this pangolin coronavirus (pangolin-CoV-2020) is genetically related to the SARS-CoV-2 as well as a group of bat coronaviruses but do not support the SARS-CoV-2 emerged directly from the pangolin-CoV-2020. Our study suggests that pangolins are natural hosts of Betacoronaviruses. Large surveillance of coronaviruses in pangolins could improve our understanding of the spectrum of coronaviruses in pangolins. In addition to conservation of wildlife, minimizing the exposures of humans to wildlife will be important to reduce the spillover risks of coronaviruses from wild animals to humans.</span><span id="34e8" class="mt mu iq nw b gy oe ob l oc od"><strong class="nw ir">Top 20 Rake keywords:<br/></strong>million laboratory confirmed cases novel corona virus disease sick <strong class="nw ir">malayan pangolins</strong> <strong class="nw ir">novel coronavirus</strong> unknown recent studies showed <strong class="nw ir">phylogenetic analyses</strong> showed pangolins improve emerged coronavirus identified wild animals risks natural hosts originated large surveillance <strong class="nw ir">intermediate hosts</strong> intermediate host related <strong class="nw ir">complete genome</strong></span></pre><p id="dbbd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的例子中，180个单词的全文被浓缩为40个单词，其中关键词包含的信息足以识别该文章是关于新冠肺炎的，关键词是“新型冠状病毒”，并且是关于“系统发育分析”中穿山甲的潜在中间宿主。算法还成功配对了“马来亚”和“穿山甲”。这40个单词并不概括摘要，而是标记出可以用来标记出版物主题的最多的关键词，并将其与提到相同单词的其他关键词进行分组。</p><p id="8080" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上述示例还表明，许多关键词仍然过于笼统，例如“最近的研究”或“实验室确诊病例”，但这些将在稍后阶段使用<em class="of">术语频率逆文档频率权重</em> (TFIDF)进行处理，以找到更具体的罕见关键词。</p><h2 id="f6e1" class="mt mu iq bd mv mw mx dn my mz na dp nb ko nc nd ne ks nf ng nh kw ni nj nk nl bi translated">几十年来的CORD 19数据</h2><p id="8435" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">作为物理学家，时间维度一直是衡量系统演化的一个重要特征。此外，将CORD-19的元数据csv文件划分为时间范围是管理代码的内存和CPU使用的一种有用技术。选择正确的时间范围还可以根据下图中的特征对出版物进行大致分组。</p><figure class="nr ns nt nu gt ls gh gi paragraph-image"><div class="gh gi og"><img src="../Images/3d156fca21fe3f3811c705df7776ce1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*nOMKlkTCv5EXp63yzJJrVw.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">(作者图片)出版年份与CORD-19数据集中的出版物数量。</p></figure><p id="62ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CORD 19的出版物可以追溯到1870年，但是早期的出版物通常没有机器可读的全文。到1970年，只有少数出版物可用于文本挖掘，其中大多数是关于动物中的冠状病毒(人畜共患冠状病毒)。关于人类冠状病毒株(如229E和OC43)的出版物数量也很少，因为这些病毒导致轻微症状而不是流行病。出版物的大幅增长出现在2002年SARS流行期间，导致了2002年至2005年红线内出版物的峰值。在2012年中东呼吸综合征疫情期间，紫色线也出现了一个较小的峰值。正如预期的那样，数据集中的大多数出版物都是2019年至2020年新冠肺炎疫情期间的出版物。</p><p id="21d4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">元数据按照这些趋势分为时间范围:1970-1990年，1990-2002年，2002-2005年，2005-2012年，2012-2019年，2019年至今。元数据可以作为pandas数据帧被加载，并且“publish_time”列被转换为datetime64:</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="2c39" class="mt mu iq nw b gy oa ob l oc od">##For a given path to the CORD 19 data and a range [startyear, endyear]<br/>df=pd.read_csv(‘%s/metadata.csv’%PATH)<br/>df[“publish_time”] = df[“publish_time”].astype(“datetime64”)<br/>df=df[(df[‘publish_time’]&lt;’%d-1–1' %endyear) &amp; (df[‘publish_time’]&gt;=’%d-1–1' %startyear)]</span></pre><p id="0ff0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于每个时间范围，我们预计某些关键词会更流行，如公共卫生是2002年SARS爆发后更常见的关键词。在2002年之前，我们预计大多数关键词都与动物冠状病毒有关，而不是人类病毒株。2019年后，大部分出版物都以新冠肺炎术语为关键词。这种时间切片利用了SARS、MERS和新冠肺炎(大约相隔10年)等不同冠状病毒爆发之间的明显差异。</p><p id="d71e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">空间为我的代码提供了主干。SpaCy提供了一个管道，可以自动将文本分解成标记，分配词性，并根据单词之间的相互依赖关系分配标签。它还将PyTextRank和RAKE等包集成到处理管道中，以提高速度和一致性。选择特定的空间模型可以改善结果，对于CORD 19，有一个针对生物医学数据进行训练的<a class="ae lb" href="https://allenai.github.io/scispacy/" rel="noopener ugc nofollow" target="_blank">科学空间</a>。</p><p id="3e5c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">SpaCy也是将关键字匹配到CORD 19文本的强大工具。在每个出版物的摘要中找到的匹配关键词被用于根据主题(例如，公共卫生、重症监护、诊断技术)来标记该出版物。匹配<a class="ae lb" href="https://spacy.io/usage/rule-based-matching#phrasematcher" rel="noopener ugc nofollow" target="_blank">的两种主要方式是短语匹配</a>(用于寻找更精确的术语)和基于<a class="ae lb" href="https://spacy.io/usage/rule-based-matching#matcher" rel="noopener ugc nofollow" target="_blank">规则的匹配</a>(寻找更多样的术语)。短语匹配往往运行得很快，因为字符串存储为哈希值(以节省内存)，并且使用词汇字典在哈希值和字符串之间进行转换。“重症监护室”下面的模式既用作分配为匹配模式的主题“ICU”的关键字:</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="030e" class="mt mu iq nw b gy oa ob l oc od">##Simple Phrase matching</span><span id="eff7" class="mt mu iq nw b gy oe ob l oc od">matcher = PhraseMatcher(nlp.vocab, attr='LOWER')<br/>patterns=[nlp.make_doc(‘intensive care unit’)]### Don't need full spacy pipeline only need the text<br/> matcher.add(“ICU”, None, *patterns)### store string as a hash value</span><span id="5afd" class="mt mu iq nw b gy oe ob l oc od">for doc in docs:#### for a list of docs<br/>        #print(doc.text)<br/>        matches=matcher(doc)### Return matched values<br/>        FoundMatches=[]<br/>        for match_id, start, end in matches:<br/>            FoundMatches.append(nlpsci.vocab.strings[match_id])### convert hash value to string and store it in a list</span></pre><p id="71db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于规则的匹配依赖于知道产生给定术语的可能记号、记号的顺序或标点符号的分隔。下面的代码匹配一个术语“计算机断层扫描”(CT)。下面基于规则的模式使用带有“IN”属性的列表作为逻辑OR，用于列表中的任何单词。逻辑运算“+”要求列表中的每个单词至少匹配一次。这就产生了一组ct术语，如“胸部扫描”、“ct扫描”、“胸部发现”和“CT发现”。也可以通过“+”操作找到类似“胸部ct扫描”的模式。在这种情况下，使用几个关键字来匹配主题ct，而不是主题ICU，在ICU中只有一个字符串“重症监护室”。(关于空间匹配模式和代码练习的更多信息，请查看Ines Montani的<a class="ae lb" href="https://course.spacy.io/en" rel="noopener ugc nofollow" target="_blank">教程</a></p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="453c" class="mt mu iq nw b gy oa ob l oc od">#### Rule based matching<br/>matcher = Matcher(nlp.vocab)<br/>CT=[{“LOWER”:{“IN”:[“chest”,”ct”]},”OP”:”+”}<br/>, {“LOWER”:{“IN”:[“scans”,”findings”, “ct”]}, “OP”:”+”}]<br/> matcher.add(“CT”,None,CT)</span></pre><figure class="nr ns nt nu gt ls gh gi paragraph-image"><div class="gh gi og"><img src="../Images/5ed11991936f9174c64cd6394991dc47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*s_UGdVxuFinCBy0XrgqXCw.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">(作者拍摄的照片)2020年的月份与出版物数量的对比，分为以新冠肺炎为关键词的总出版物和包括更具体关键词的出版物。(最新CORD 19更新于2020年9月20日)</p></figure><p id="b99c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的图中，我只使用找到新冠肺炎匹配模式的出版物，并查看最常见的关联模式。查看出版物数量最多的2020年，您可以看到每月出版物主题的细分:</p><ul class=""><li id="f3de" class="md me iq kh b ki kj kl km ko mf ks mg kw mh la oh mj mk ml bi translated">最常发表的主题是公共卫生、识别易受感染的病人和诊断方法。</li><li id="3140" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la oh mj mk ml bi translated">新冠肺炎与SARS和MERS一起被提及，以吸取以往疫情的经验。ACE2这个词每月都频繁出现，就像与新冠肺炎相关的SARS和MERS一样。这可能是由于SARS病毒和新冠肺炎病毒与相同的人类ACE2细胞受体结合。</li><li id="0c9b" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la oh mj mk ml bi translated">重症监护的主题在3月前爆发的早期更为罕见，但随后由于有更多的病例数据，每月都有数百篇出版物。</li><li id="2973" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la oh mj mk ml bi translated">最罕见的关键词是与新冠肺炎一起被提及的冠状病毒动物毒株。在数以千计被贴上新冠肺炎标签的出版物中，每月只有大约10种。</li></ul><h2 id="2dcb" class="mt mu iq bd mv mw mx dn my mz na dp nb ko nc nd ne ks nf ng nh kw ni nj nk nl bi translated">将关键字组合成二元模型和三元模型</h2><p id="2ca8" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">N-gram是N个单词的序列，对于将单个标记组合成更具描述性的特征非常有用。一些术语，如“计算机断层摄影”是有用的二元模型(N=2 ),用于研究诊断主题。三元模型(N=3)也经常出现在CORD 19数据中，如“世界卫生组织”、“重症监护病房”或“急性呼吸窘迫”。为了查看不同N-gram的频率，我使用了类似CountVectorizer的<a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> sklearn特征提取工具</a>，该工具还设置了序列的最小和最大范围:</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="686c" class="mt mu iq nw b gy oa ob l oc od">tf_vectorizer = CountVectorizer(ngram_range=(2,3)) ### Uses only bigrams up to trigrams<br/>tf=tf_vectorizer.fit_transform(skl_texts)####transform and learn the vocab from the list of keywords in skl_texts</span></pre><p id="be40" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面给出了二元模型和三元模型计数(tf)的矩阵，可以将其转换为一系列用于绘图:</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="3272" class="mt mu iq nw b gy oa ob l oc od">d = pd.Series(tf.toarray().sum(axis=0),index = features).sort_values(ascending=False)<br/> ax = d[:no_most_frequent].plot(kind=’bar’, figsize=(8,8), width=.8, fontsize=12, rot=50,title=’Most Frequent Keywords’) #### plot the top no_most_frequent </span></pre><p id="48b7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以新冠肺炎和公共卫生为例，我得到了下面的直方图:</p><figure class="nr ns nt nu gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi on"><img src="../Images/93ec889465ee824253e90c4268a2c606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ggFwdmRLTpeQyIO99gdfw.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">(作者照片)关于新冠肺炎和公共卫生的出版物中倾斜关键词的计数(在将二元模型合并到三元模型之前)</p></figure><figure class="nr ns nt nu gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oo"><img src="../Images/4174e17aa2d4809ff0cb82b343ac90d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3y_b1MWPUr4MS3f-6a6Klg.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">(作者图片)基于Levenshtein距离将二元模型合并为三元模型后倾斜关键词的计数。</p></figure><p id="2a63" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管一些关键词看起来很有用(如“社会距离”、“重症监护室”)，但一些三元组被错误地拆分，如“世界卫生”和“卫生组织”应拼凑成“世界卫生组织”。为了进行这种关联，我使用了<a class="ae lb" href="https://medium.com/nlpgurukool/fuzzy-matching-1baac719aa25" rel="noopener">模糊字符串匹配</a>，并基于<a class="ae lb" rel="noopener" target="_blank" href="/fuzzywuzzy-how-to-measure-string-distance-on-python-4e8852d7c18f"> Levenshtein距离</a>给出了二元模型与三元模型相似程度的比率窗口。我存储了一个二元模型字典，其中三元模型的Levenshtein距离在64到100之间。这说明“世界卫生组织”是出现频率最高的词。像“个人防护装备”这样的三元组在从“个人防护”拼凑回来时也变得更加频繁。这种与模糊字符串匹配的合并显示了对特征的更精确的计数，这些特征可以被输入到代码的下一阶段以用于主题构建。</p><h2 id="f932" class="mt mu iq bd mv mw mx dn my mz na dp nb ko nc nd ne ks nf ng nh kw ni nj nk nl bi translated">从主题构建主题</h2><p id="e38d" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">上述主题仅给出了一个宽泛的主题类型，将论文粗略地划分为几组特征。计数直方图已经显示了一个特征趋势:不太频繁的词往往是关于更具体的主题，如“社交距离”，而非常频繁的词过于笼统，会匹配大量的文本，如“世界卫生组织”。</p><p id="98d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">说明这种趋势的一个好方法是将关键词表示为<a class="ae lb" rel="noopener" target="_blank" href="/tf-term-frequency-idf-inverse-document-frequency-from-scratch-in-python-6c2b61b78558">术语-频率逆文档频率</a> (TF-IDF)矩阵。术语频率是文档中关键字的计数除以总字数。逆文档频率是文档总数除以所有文档的特征计数。该比率的对数允许计算大量文档的TF-IDF分数。TF-IDF分数是通过将两个术语相乘来计算的:术语频率和逆文档频率。对于在所选数据中频繁出现的词，如“世界卫生组织”或“公共卫生”，得分较低。与所有文档相比，在一个文档中频繁出现的单词的TF-IDF得分较高，如“社交距离”。特征的这种表示根据它们作为有用搜索词的相关性对它们进行适当的加权。</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="635d" class="mt mu iq nw b gy oa ob l oc od">##### Can also use only the top TF scored features (set with max_features) and require them to have a more than 5000 for their document frequency (set with max_df)<br/>tfidf_vectorizer = TfidfVectorizer(max_features=no_features,ngram_range=(2,3),max_df=5000)</span><span id="0905" class="mt mu iq nw b gy oe ob l oc od">####Create the TF-IDF matrix and score the list of features in skl_texts <br/>tfidf = tfidf_vectorizer.fit_transform(skl_texts)</span></pre><p id="60a2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如何处理特征的TF-IDF值矩阵？答案是将其分解成更小的矩阵，这些矩阵的乘积近似等于原始矩阵。我们可以利用TF-IDF矩阵是一个非负矩形矩阵的事实(维数为<em class="of"> N </em>个文档和<em class="of"> M </em>个关键词)所以<a class="ae lb" href="https://en.wikipedia.org/wiki/Nonnegative_matrix" rel="noopener ugc nofollow" target="_blank">它可以近似地被两个非负矩阵</a>分解。因子的矩形矩阵(<em class="of"> WH </em>)需要有一个指定的参数，即主题或聚类的数量:</p><blockquote class="lc"><p id="1f12" class="ld le iq bd lf lg lh li lj lk ll la dk translated"><strong class="ak">V[行:列]=V [文档:术语]=W(文档:主题)H(主题:</strong>术语<strong class="ak"> ) </strong></p></blockquote><p id="788e" class="pw-post-body-paragraph kf kg iq kh b ki op jr kk kl oq ju kn ko or kq kr ks os ku kv kw ot ky kz la ij bi translated">使用成本函数找到这些因素，一个简单的成本函数如<em class="of"> ||V-WH|| </em>(误差平方和)产生了<a class="ae lb" rel="noopener" target="_blank" href="/k-means-clustering-with-scikit-learn-6b47a369a83c">K-均值聚类算法</a>。对于我的代码，我使用了用于<a class="ae lb" rel="noopener" target="_blank" href="/latent-semantic-analysis-sentiment-classification-with-python-5f657346f6a3">潜在语义分析的相同成本函数</a><a class="ae lb" href="https://medium.com/@cotra.marko/making-sense-of-the-kullback-leibler-kl-divergence-b0d57ee10e0a" rel="noopener">kul back-lei bler成本函数</a>，它基于对数似然比<em class="of"> P/Q </em>为相同的数据X将主题模型<em class="of"> P </em>与主题模型<em class="of"> Q </em>分开。如果<em class="of"> P </em>是比<em class="of"> Q </em>更好的模型，数据<em class="of"> X </em>将给出更大的对数似然值。这种模式的非负矩阵分解(NMF)可以使用<a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>来完成:</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="a828" class="mt mu iq nw b gy oa ob l oc od">#### Specify the number of topics and the loss function, then fit to the TF-idf matrix to get the factorized model<br/>nmf = NMF(n_components=no_topics,beta_loss=’kullback-leibler’).fit(tfidf)</span></pre><p id="76d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">主题的数量可能是一个关键参数，太少可能无法最大化分离能力，导致主题不一致。过多的主题会导致冗余的主题，每个主题包含的信息很少。如果不观察2D的主题群，很难理解这种分离的力量。t-SNE 是一种有用的方法，可以看到投射到2D(甚至3D)平面的主题群(从更高维度)。</p><figure class="nr ns nt nu gt ls gh gi paragraph-image"><div class="gh gi og"><img src="../Images/971040c83d6ee451b8d29015a84d293c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*PtgRHvl4tcLAuSpwq6XWjw.gif"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">(作者拍摄的照片)动画图，使用在受试者新冠肺炎和ACE2细胞受体中找到的关键字，为每一帧运行不同数量主题(2，4，8，10，15)的NMF。基于上述15个主题，最大化主题分离，同时保持主题集群相当一致。</p></figure><p id="4461" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">主题数量合适的2D投影应该看起来像是烟花爆炸的碎片。这些簇应该彼此分开，并且每个簇中的点应该靠近质心。</p><p id="b8e5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用NMF创建的主题有什么用处？</p><ul class=""><li id="00ad" class="md me iq kh b ki kj kl km ko mf ks mg kw mh la oh mj mk ml bi translated">每个受试者(如COVID-19和ACE2)都可以分解成更具体的主题。每个主题只是一个排序的关键字列表(二元模型和三元模型)，可用于在CORD 19数据中查找相似的文本。(接下来将对此进行描述)</li><li id="d801" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la oh mj mk ml bi translated">NMF模型还可以用于预测添加到CORD 19的新文档的主题，而不必再次运行该算法</li><li id="0b3d" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la oh mj mk ml bi translated">原始的TFIDF矩阵可以进行类似的转换，以找到每个主题的最典型的文档标题。</li></ul><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="bf3d" class="mt mu iq nw b gy oa ob l oc od">### Print keywords per topic:</span><span id="7888" class="mt mu iq nw b gy oe ob l oc od">feature_names = tfidf_vectorizer.get_feature_names()</span><span id="210d" class="mt mu iq nw b gy oe ob l oc od">for topic_idx, topic in enumerate(nmf.components_):<br/>   print(", ".join([feature_names[i]for i in topic.argsort()[:-no_top_words - 1:-1]]))</span><span id="598d" class="mt mu iq nw b gy oe ob l oc od">##### predict topic for new publications</span><span id="0752" class="mt mu iq nw b gy oe ob l oc od">tfidf_LatestCORDData = tfidf_vectorizer.transform(new_keywordsinAbstract)</span><span id="8926" class="mt mu iq nw b gy oe ob l oc od">X_new = nmf.transform(tfidf_LatestCORDData)#### this makes an embedding</span><span id="ae4b" class="mt mu iq nw b gy oe ob l oc od">predicted_topics = [np.argsort(each)[::-1][0] for each in X_new]### Most likely topic per document</span><span id="2549" class="mt mu iq nw b gy oe ob l oc od">#### Lookup the most typical paper titles per topic</span><span id="4b04" class="mt mu iq nw b gy oe ob l oc od">nmf_embedding = nmf.transform(tfidf)### Transform original TFIDF matrix used to predict topics</span><span id="0987" class="mt mu iq nw b gy oe ob l oc od">nmf_embedding = (nmf_embedding - <br/>nmf_embedding.mean(axis=0))/nmf_embedding.std(axis=0)### see how far away the scores are from the average</span><span id="05f7" class="mt mu iq nw b gy oe ob l oc od">top_idx = np.argsort(nmf_embedding,axis=0)[-10:]### Top 10 document indices</span><span id="5b3a" class="mt mu iq nw b gy oe ob l oc od">for idxs in top_idx.T:#### A loop over topics</span><span id="dbef" class="mt mu iq nw b gy oe ob l oc od">    for idx in idxs:print(SelectedRows.iloc[idx]['title'])### Top 10 most common documents per topic where idx is the index in the dataframe that stored the keywords, abstract and titles for the selected papers</span></pre><p id="98c9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了看事情如何具体地结合在一起，我用NMF建立了3个关于新冠肺炎及其动物传染病起源的话题。下面的文本框显示了每个主题的前10个主题关键字和前3个文档标题:</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="745d" class="mt mu iq nw b gy oa ob l oc od">#####Topic Keywords#######<br/>Topic 0:<br/>seafood wholesale market, world health organization, major public health, huanan seafood wholesale, viral rna, public health emergency, global public health, <strong class="nw ir">species transmission</strong>, codon usage, confirmed cases</span><span id="4782" class="mt mu iq nw b gy oe ob l oc od">Topic 1:<br/>time evolution signal, antiviral drugs, <strong class="nw ir">genomic sequences</strong>, host taxa, feline infectious peritonitis, neuromyelitis optica, phylogenetic tree, sequence identity, length genome, animal health</span><span id="9207" class="mt mu iq nw b gy oe ob l oc od">Topic 2:<br/><strong class="nw ir">spike protein</strong> insertions, epidemic diarrhea virus, potential therapeutic options, receptor binding domain, major public health, infectious peritonitis virus, porcine epidemic diarrhea, feline infectious peritonitis, amino acid, water samples</span><span id="8167" class="mt mu iq nw b gy oe ob l oc od">##### Top 3 Document titles from the Transform #######<br/>Topic 0:<br/><strong class="nw ir">Cross-species transmission</strong> of the newly identified coronavirus 2019-nCoV<br/>The Natural History, Pathobiology, and Clinical Manifestations of SARS-CoV-2 Infections<br/>Global genetic patterns reveal host tropism versus cross-taxon transmission of bat Betacoronaviruses</span><span id="03bb" class="mt mu iq nw b gy oe ob l oc od">Topic 1: <br/>COVID-19, Companion Animals, Comparative Medicine, and One Health<br/><strong class="nw ir">Mapping genome variation</strong> of SARS-CoV-2 worldwide highlights the impact of COVID-19 super-spreaders<br/>Identification and Analysis of Unstructured, Linear B-Cell Epitopes in SARS-CoV-2 Virion Proteins for Vaccine Development.</span><span id="43a7" class="mt mu iq nw b gy oe ob l oc od">Topic 2: <br/>Development of a TaqMan-probe-based multiplex real-time PCR for the simultaneous detection of emerging and reemerging swine coronaviruses<br/>Genome based evolutionary lineage of SARS-CoV-2 towards the development of novel chimeric vaccine<br/>Structural basis of SARS-CoV-2 <strong class="nw ir">spike protein</strong> induced by ACE2.</span></pre><p id="08b7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于以上所述，主题0很可能带有“跨物种传播”的标签，因为该术语出现在排名关键词和最典型文档的标题中。出于类似的原因，主题1可能带有“基因组序列”的标签。根据标题和主题关键字，主题2不太清楚，因此我们将在下一节中以该主题为例。</p><h2 id="b753" class="mt mu iq bd mv mw mx dn my mz na dp nb ko nc nd ne ks nf ng nh kw ni nj nk nl bi translated">匹配和排列文本</h2><p id="a9db" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">在实际开采的类比中，在文本开采的这一点上，我们有粗切的石头，可以进一步提炼为珍贵的宝石，以备鉴定。提炼的过程包括从主题关键词中构建短语，以便可以基于抽象的短语进行更具体的文本搜索。评估取决于给定的出版物、匹配句子的段落或单句与CORD 19数据中其他内容的相关程度。</p><p id="d5e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了提炼关键词，我在出版物摘要上使用PyTextRank来获得更具体的主题短语。主题短语包含主题单词和附加的上下文信息，以改进搜索。<a class="ae lb" href="https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf" rel="noopener ugc nofollow" target="_blank"> PyTextRank </a>是TextRank算法的python实现，它根据图形中的关联对主题短语进行排序。它通常用于摘录摘要，因为它可以推断主题短语(图中的顶点)之间的链接，并根据顶点的重要性按相关性对它们进行排序。与RAKE相比，PyTextRank运行速度较慢，但也能更准确地指示论文的上下文。</p><p id="c830" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回到上一步的例子，关于新冠肺炎的动物传染病起源的话题2很难用话题词来确定。有些话题词像“氨基酸”还是很模糊的。在下面的文本框中，您可以看到主题短语如何使主题单词“氨基酸”更加具体:</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="c5a5" class="mt mu iq nw b gy oa ob l oc od">Topic 2:<br/>spike protein insertions, epidemic diarrhea virus, potential therapeutic options, receptor binding domain, major public health, infectious peritonitis virus, porcine epidemic diarrhea, feline infectious peritonitis, <strong class="nw ir">amino acid</strong>, water samples</span><span id="373b" class="mt mu iq nw b gy oe ob l oc od">PyTextRank Phrases:<br/>'multiple amino acids', 'two secondary water samples', 'influent, secondary and tertiary effluent water samples', 'five amino acids', 'effluent water samples', 'feline infectious peritonitis virus', 'coronavirus spike protein receptor binding domain', 'key amino acids', '<strong class="nw ir">one noncritical amino acid difference</strong>', '<strong class="nw ir">92.2% amino acid identity</strong>', '<strong class="nw ir">a double amino acid insertion</strong>', '<strong class="nw ir">these variable amino acids</strong>', 'porcine epidemic diarrhea virus', '<strong class="nw ir">a noncritical amino acid</strong>', '<strong class="nw ir">a relatively low amino acid similarity</strong>', 'the spike surface glycoprotein receptor binding domain', 'all tertiary water samples', '<strong class="nw ir">gene and amino acid sequence homologies</strong>', '<strong class="nw ir">a distinct 4 amino acid insert</strong>', '<strong class="nw ir">many amino acid changes</strong>', 'negative all secondary and tertiary treated water samples', 'basic amino acids', 'the 2019-ncov spike protein insertions', '<strong class="nw ir">the nucleocapsid protein amino acid and gene sequence</strong>', 'the receptor binding domain', 'a feline infectious peritonitis (fip) virus', 'a major public health concern', '<strong class="nw ir">22 amino acid insertions</strong>'</span></pre><p id="94aa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似地，其他主题词如“水样”也可以通过上面的主题短语变得更加具体。如果主题词确实代表相关的搜索词，它们应该出现在与其他短语相比PyTextRank得分较高的主题短语中。下图显示了这两种情况的散点图。高PyText等级分数(&gt; 0.02)也导致较低的计数频率，因为与低等级分数相比，它们代表更具体的上下文。停用词的得分为0.0(如we、is、the)。包含主题词“冠状病毒刺突蛋白<em class="of">受体结合域</em>的得分最高的短语明确了结合域在冠状病毒刺突蛋白上。基于主题短语，主题2可能具有标签“刺突蛋白氨基酸插入”。</p><figure class="nr ns nt nu gt ls gh gi paragraph-image"><div class="gh gi og"><img src="../Images/d2bb02672905e6cefc6efae35d639303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*QK7CY_hCYzaM4SXv2_zaFg.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">(作者提供图片)主题短语计数与其PyTextRank得分的散点图。通过在包含主题关键词的出版物摘要上使用PyTextRank来找到短语。上面的点显示了所有的短语，以及包含主题词的短语。核密度估计显示所有短语倾向于大部分处于较低的等级分数，而那些包含主题关键词的短语处于较大的值。</p></figure><p id="38ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面的图表显示了新冠肺炎动物传染病起源的三个主题中的一些主题短语。一般来说，短语的等级越高，在出版物摘要中出现的频率就越低。这提供了更具体的搜索短语，用于搜索CORD 19文本以获得有价值的见解。</p><figure class="nr ns nt nu gt ls gh gi paragraph-image"><div class="gh gi og"><img src="../Images/76f742199712d9dde01b5fc09b97654a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Ub-VeoybdgxI62Qi6UJXRg.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">(作者拍摄)关于新冠肺炎动物传染病起源的3个主题的主题短语示例。等级分数越大(越相关)，短语越不频繁(越具体)。</p></figure><p id="ecc9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">SpaCy短语匹配器再次用于在出版物正文中查找匹配的文本。考虑到具有匹配文本或来自NMF嵌入的所有出版物，可以使用余弦相似度来比较出版物的全文:</p><pre class="nr ns nt nu gt nv nw nx ny aw nz bi"><span id="1b82" class="mt mu iq nw b gy oa ob l oc od">Corpus=[]<br/>for pub in PubPaths:### Loop over publications<br/>    BodyText=[]<br/>    SkimmedText=SkimallText(Filepath+p,nlpsci)#### return all lines of the paper<br/>    BodyText.extend(SkimmedText)####Full text not just the abstract<br/>    Doc=".".join(BodyText)<br/>    Corpus.append(Doc)<br/>tfidf_vectorizer = TfidfVectorizer()####Build TF-IDF matrix<br/>tfidf = tfidf_vectorizer.fit_transform(Corpus)####Score all the text data<br/>SimilarityArray=cosine_similarity(tfidf, tfidf)#### Make a similarity matrix from the TF-IDF matrix <br/>nx_graph = nx.from_numpy_array(SimilarityArray)#### Convert similarity matrix into a graph<br/>scores = nx.pagerank(nx_graph)#### Use page rank to score graph vertices<br/>for i,s in enumerate(Titles):##### Print out titles and their scores<br/>        rank.append(scores[i])<br/>        titles.append(s)</span></pre><p id="430b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与主题2最相似的前3个文档是:</p><ol class=""><li id="f2be" class="md me iq kh b ki kj kl km ko mf ks mg kw mh la mi mj mk ml bi translated"><a class="ae lb" href="https://www.ncbi.nlm.nih.gov/pubmed/32320687" rel="noopener ugc nofollow" target="_blank">新型冠状病毒刺突蛋白的系统发育分析和结构建模揭示了一个进化独特且蛋白水解敏感的激活环</a></li><li id="7449" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la mi mj mk ml bi translated"><a class="ae lb" href="https://www.ncbi.nlm.nih.gov/pubmed/32344679/" rel="noopener ugc nofollow" target="_blank">新冠肺炎疫情:分类学、遗传学、流行病学、诊断、治疗和控制的全面综述</a></li><li id="e3cf" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la mi mj mk ml bi translated"><a class="ae lb" href="https://www.sciencedirect.com/science/article/pii/S1567134820302203" rel="noopener ugc nofollow" target="_blank">探索新型冠状病毒刺突糖蛋白的基因组和蛋白质组变异:一种计算生物学方法</a></li></ol><p id="ea9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似地，如果上面代码块中的语料库填充了文档中匹配文本的段落(而不是完整的正文文本)，则可以用余弦相似度对段落进行排序。排名最高的段落是:</p><blockquote class="ou ov ow"><p id="75f0" class="kf kg of kh b ki kj jr kk kl km ju kn ox kp kq kr oy kt ku kv oz kx ky kz la ij bi translated">“在S1内，发现N-末端结构域(NTD)与受体结合结构域(RBD，74%同一性)相比保守性较低(51%同一性)……然而， 暴露的环特征已经在模型和cryo-EM CoV S结构中得到证实，在S1/S2位点具有相似的氨基酸序列……系统发育分析中使用的S蛋白的氨基酸序列从图4获得……显示了S1/S2和S2位点的氨基酸序列……发现结构域(NTD)与受体结合结构域(RBD，74%同一性)相比保守性较低(51%)……然而， 在S1/S2作者/资助者处，已在具有相似氨基酸序列的模型化和cryo-EM CoV S结构中证明了暴露的环特征…获得了用于系统发育分析的S蛋白的氨基酸序列…S1/S2和S2位点的氨基酸序列显示为“<a class="ae lb" href="https://doi.org/10.1101/2020.02.10.942185" rel="noopener ugc nofollow" target="_blank"><em class="iq">”。2019年新型冠状病毒(nCoV)刺突蛋白的结构模型揭示了蛋白水解敏感的激活环，作为与SARS-CoV和相关SARS样冠状病毒</em> </a>相比的区别特征</p></blockquote><p id="b493" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的段落仍然过于密集，无法理解是否有有用的见解，因此匹配文本的每个句子(由“…”分隔)都可以用余弦相似性对该主题进行排序。该主题的所有匹配文本中排名最大的句子是:</p><blockquote class="ou ov ow"><p id="43e5" class="kf kg of kh b ki kj jr kk kl km ju kn ox kp kq kr oy kt ku kv oz kx ky kz la ij bi translated">“此外，我们的分析表明，来自R. <em class="iq"> </em> malayanus的病毒RmYN02，其特征是在刺突蛋白的S1和S2亚基的连接位点插入多个氨基酸，与RaTG13和新型冠状病毒属于同一进化枝，这为新型冠状病毒在该地区的自然起源提供了进一步的支持”<a class="ae lb" href="https://doi.org/10.1038/s41467-020-17687-3" rel="noopener ugc nofollow" target="_blank"> <em class="iq">起源和蝙蝠冠状病毒在中国的跨物种传播</em> </a></p></blockquote><p id="42d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最细粒度的信息，即所选CORD 19数据中的句子，用余弦相似度排序可以得出简明的结论。根据上面的论文，在新型冠状病毒的刺突蛋白中插入氨基酸，负责新冠肺炎，支持了病毒起源于马头蝠(<em class="of">马来菊头蝠</em>)的证据。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="c41d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想，如果我要简要总结我的挖掘工作，我会按照上面演示的步骤对文本进行剪切、筛选和排序。这将成千上万的文档压缩成一个简短的阅读列表。公共卫生、医学或流行病学方面的专家可以浏览这些见解，找到与他们的研究相关的有趣结论，或者调查重要的公开问题。对于数据科学家来说，将这种算法扩展到无监督的学习方法可能是有用的。最后一步可以和第一步联系起来，这样阅读列表就可以用来找到更多的关键词来标注主题。以这种方式，主题和主题将更健壮地寻找相关信息。</p><h1 id="51a7" class="pa mu iq bd mv pb pc pd my pe pf pg nb jw ph jx ne jz pi ka nh kc pj kd nk pk bi translated">相关文章:</h1><ul class=""><li id="07ac" class="md me iq kh b ki nm kl nn ko pl ks pm kw pn la oh mj mk ml bi translated">代码的灵感来自于<a class="ae lb" href="https://medium.com/analytics-vidhya/avalanches-of-data-text-mining-inspired-by-proton-collisions-32bd50f8c2a5" rel="noopener"> <strong class="kh ir">数据雪崩中描述的粒子物理和质子碰撞领域:受质子碰撞启发的文本挖掘</strong> </a></li><li id="d0af" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la oh mj mk ml bi translated">我还总结了本文中全套主题的见解:<a class="ae lb" href="https://medium.com/rebel-public-health/insights-from-the-infodemic-fa43307ef42e" rel="noopener"> <strong class="kh ir">信息时代的见解</strong> </a></li><li id="1fac" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la oh mj mk ml bi translated">要阅读完整的代码，请点击这个github链接<a class="ae lb" href="https://github.com/rpatelCERN/CORD19/" rel="noopener ugc nofollow" target="_blank"> CORDCrusher </a>，并且<a class="ae lb" href="https://github.com/rpatelCERN/CORD19/wiki" rel="noopener ugc nofollow" target="_blank"> wiki区域包括</a>所有主题和题目的排名出版物、段落和句子。我的计划是随着CORD 19每周更新继续挖矿！</li><li id="2226" class="md me iq kh b ki oi kl oj ko ok ks ol kw om la oh mj mk ml bi translated"><a class="ae lb" href="https://www.semanticscholar.org/cord19/download" rel="noopener ugc nofollow" target="_blank">链接到CORD 19上的数据</a>语义学者</li></ul><h1 id="9559" class="pa mu iq bd mv pb pc pd my pe pf pg nb jw ph jx ne jz pi ka nh kc pj kd nk pk bi translated">参考</h1><p id="f67b" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">[1]王陆、露西等人<a class="ae lb" href="https://arxiv.org/abs/2004.10706" rel="noopener ugc nofollow" target="_blank"> CORD-19:新冠肺炎开放研究数据集</a>(2020年4月22日)<em class="of"> ArXiv </em>预印本。<br/>(上文引用的论文)<br/>【2】Javier a . Jaimes，Nicole M. André，Jean K. Millet，Gary r . Whittaker<a class="ae lb" href="https://www.sciencedirect.com/science/article/pii/S0022283620302874?via%3Dihub" rel="noopener ugc nofollow" target="_blank">2019-新型冠状病毒(nCoV)刺突蛋白的结构建模揭示了一种蛋白水解敏感的激活环，作为与SARS-CoV和相关SARS样冠状病毒的区别特征</a>(2020年5月)<em class="of">分子生物学杂志<br/></em>【3】Latinne，a .，Hu，b .，Olival，K.J<em class="of">Nat Commun</em>T17】11、 4235 (2020)。</p></div></div>    
</body>
</html>