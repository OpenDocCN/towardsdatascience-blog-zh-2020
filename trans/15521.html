<html>
<head>
<title>Choosing Performance Metrics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">选择绩效指标</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/choosing-performance-metrics-61b40819eae1?source=collection_archive---------11-----------------------#2020-10-26">https://towardsdatascience.com/choosing-performance-metrics-61b40819eae1?source=collection_archive---------11-----------------------#2020-10-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3f12" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">准确性、敏感性与特异性、精确性与回忆性以及F1分数</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/bc6c553cd15849ac5b0a30cc5296c7df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*87T6eV6PvX3AdXYZ2duxDA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">分类_报告</a>来自scikit-learn。</p></figure><p id="f854" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">准确度、召回率、精确度、F1分数--如何选择衡量模型性能的指标？一旦你选择了，你想要宏观平均值吗？加权平均？对于这些指标中的每一个，我将更仔细地研究它是什么以及它的最佳用例是什么。我还将介绍如何从scikit-learn的<code class="fe ls lt lu lv b"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">classification_report</a></code>中读取输出表，如上图所示。</p><h1 id="5fd6" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">准确(性)</h1><p id="7178" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">我从准确性开始，因为我认为，从它的名字来看，我们觉得我们对它有一个直观的理解，而没有见过任何数学公式。“我们想要一个更准确的模型。”一直都是，我们甚至还没有严格意义上的定义。我确实从项目的准确性开始(现在仍然如此),因为它感觉熟悉而不专业。</p><p id="a0ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从理论上讲，准确性就是预测正确的百分比，用0 (0%的预测正确)到1 (100%的预测正确)之间的小数表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/da316251a9f88af4bfdd1ede6136e8be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CNfkZN41axVggzq_0yqEYw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="8ffd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为预测TP(真阳性)、FP(假阳性)、TN(真阴性)和FN(假阴性)对后面的指标很重要，所以让我们继续讨论它们与准确性的关系。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/4aefa9e17139dbe4ba9ed295d2d627ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sluS7bgqYOjd4835VegbJw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对于二元分类问题。作者图片</p></figure><p id="bf21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">举一个例子，如果我们试图将图像分为两类，狗和非狗，我们的模型将只预测1)图像是狗，在这种情况下它可能是正确的，并且图像确实是狗(TP)，或者不正确的，并且图像不是狗，尽管模型认为它是(FP)；或者2)模型可以预测图像不是狗，在这种情况下，它可以再次是正确的，并且图像确实不是狗(TN)，或者是不正确的，并且图像实际上是狗，尽管模型认为它不是(FN)。</p><p id="c8ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面看，我们可以看出，无论我们使用哪种准确性定义，我们只是将模型正确的预测数除以其预测总数。</p><p id="d8c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于你遇到的大多数普通的、不复杂的数据集来说，准确性确实是一种“金发姑娘”。<strong class="ky ir">只要类别或多或少是平衡的</strong>(在前面的例子中，狗和非狗图像的数量相等)，准确性在融合特异性和敏感性、召回率和精确度方面做得很好。<em class="mu">特异性</em>和<em class="mu">灵敏度</em>在这个例子中本身就是相当<em class="mu">具体的</em>词语，<em class="mu">回忆</em>和<em class="mu">精度</em>也是如此，接下来我们要谈到它们。</p><h1 id="c3b2" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated"><strong class="ak">敏感性(回忆)和特异性</strong></h1><p id="fefd" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">就像准确性一样，我认为我们已经对特异性和敏感性有了相当直观的理解，或者至少感觉我们有，但现实是它们在统计学领域有一些相当具体的定义。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/1d708b33f1552632dd9fb2b30d0f1414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rMQvdpGIDSzsmDI7P0gHAg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">TPR代表真阳性率，FNR代表假阴性率。作者图片</p></figure><p id="a47b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">敏感度</strong>，剧透一下，和<strong class="ky ir">回忆</strong>是同一个东西，也被称为<strong class="ky ir">真阳性率(TPR) </strong>，用通俗英语来说，就是所有被放入正确箱子的真阳性的分数；在前面的例子中，在<em class="mu">实际上是</em>的狗的图像中，模型得到了其中的多少部分，并且称之为狗？这个模型在捕捉“是”方面有多好？敏感度/回忆/TPR就是这么回答的。</p><p id="381b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你会注意到一些有趣的事情:我们没有包括任何关于非狗的图片。事实上，如果你认真思考上面等式，你会意识到那些非狗或没有图像，以及模型预测或分类它们的成功或失败(TN和FP)，根本不会影响灵敏度/回忆。事实上，再举一个早先的例子，一个对每一张图像都预测“是的，狗”的模型将具有完美的灵敏度/回忆/TPR。</p><p id="55c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这给了sensitivity/recall/TPR一个非常具体的用例，它可以归结为:当你所寻找的每一个实例都太珍贵而不能错过时，就使用它。例子包括检测恐怖袭击、检测疾病、检测欺诈等。在每一种情况下，一个以敏感度为中心的模型将捕捉所有真正的恐怖袭击，所有真正的心脏病病例，以及所有真正的欺诈性信用卡购买<em class="mu">，同时警告</em>它也将提取一些假阳性的实例:将有一些无辜的旅行者，一些健康的人，一些正常的目标购买被检测到。</p><p id="83f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">特异性</strong>，也称为真阴性率(TNR)，是敏感性的另一面。它关心敏感做的每一件事，但不关心“不”的情况(真的不是狗)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/8484a93dbe6cab22224ec86ffb955290.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8CMB61wgsPIUZxMeHRjQEg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">TNR为真阴性率，FPR为假阳性率。作者图片</p></figure><p id="522a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个对每一张图像都称之为“不是狗”的模型将具有完美的特异性(因此，灵敏度为0)。这与敏感性/回忆相反，通常两者之间的选择归结为你关注的是或否。在理想的世界中，你会得到一个在两方面都出色的模型，但有时我们被迫做出选择，特别是在<a class="ae kv" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity#cite_note-1" rel="noopener ugc nofollow" target="_blank">医疗保健领域，特异性和敏感性之间的区别源于</a>。</p><h1 id="068e" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">召回率和精确度</h1><p id="e37d" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated"><strong class="ky ir">回想一下</strong>我们已经讨论过——它是敏感性——和<strong class="ky ir">精确性</strong>,第三方面——万圣节快乐，各位——是这样的:在所有被模型认为是(狗)的东西中，有多少是正确的(真的是狗)？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/7482213c60ceed3524f786a194e9a429.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x16UX1WoAOX4g3EVG8XQmQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="90af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像灵敏度和特异性一样，在计算精度时，有一个模型性能的元素被忽略，但这一次是模型判断为“否”的所有东西被忽略。如果有1000张照片，500张狗的照片，500张非狗的照片，而模型只正确地分类了5只狗，并将其他所有照片都称为非狗，那将是完美的，精度为1.0(即使分类器错过了495张狗的照片)。</p><p id="2829" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，Precision也有一个非常具体的用例。当你想对模型给你的“是”有信心时，就把注意力集中在它上面。当然，它会错过一些是，但它会做什么，如果模型有很好的精度，你可以放心。</p><h1 id="5fc3" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">F1分数</h1><p id="4aa3" class="pw-post-body-paragraph kw kx iq ky b kz mo jr lb lc mp ju le lf mq lh li lj mr ll lm ln ms lp lq lr ij bi translated">简答，<strong class="ky ir"> F1评分是召回率和准确率的调和平均值，取0到1之间的值。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/ce67c9c41a32be34b808b17386bdc56b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yEtZmFiR-sp0lQurEi8UfQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="8b9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当您用它们的TP/FP/TN/FN定义替换recall和precision时，F1分数的定义如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/54d307b742d0282a3f9a9d84df5c1d0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FL6nadrpcxBmFV5YVbp76w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="29f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">也许，你和我一样，从来没有听说过<a class="ae kv" href="https://en.wikipedia.org/wiki/Harmonic_mean" rel="noopener ugc nofollow" target="_blank">谐音的意思是</a>。<a class="ae kv" href="https://www.youtube.com/watch?v=kfEuqcA6vYw" rel="noopener ugc nofollow" target="_blank">这里有一个很好的视频</a>用一个例子来解释它，但快速和肮脏的是，它最常见的用例是平均利率，我们熟悉的算术平均值并不足够。</p><p id="3c85" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你回到F1得分的第一个等式，你可以通过查看第二个定义，即分子中的召回率乘以精度，来判断<strong class="ky ir">如果召回率或精度为0，那么F1得分也为0</strong>。这使得它成为召回率和精确度之间的一个很好的折衷，这样你就不会遇到像我刚才给出的例子那样的极端情况。在最近的例子中，只有5张正确分类的狗的图片，精度是1.0，但是回忆是5/500 = 0.01，所以F1分数类似地被抑制在(大约)0.02。准确地说，是0.51。</p><p id="8b71" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，精确度和F1(分别为0.51和0.02)都反映了较差的整体性能，但这是因为这是一个平衡的数据集。<strong class="ky ir"> <em class="mu">在一个不平衡的数据集中，F1分数而不是准确率会在查全率和查准率之间取得一个很差的平衡</em> </strong>。那是F1 score的用例。</p><p id="1ff6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个例子:5张狗的图片，995张其他东西的图片(不平衡)。我们让一个分类器运行，它正确地将其中一张狗的图片分类，但称其他图片都不是狗。这意味着有4张错误分类的狗的图片。召回率是0.2(相当差)，精确度是1.0(完美)，但是精确度是0.999，并没有反映出这个模型在捕捉这些狗的图片上做得有多差；F1分数等于0.33，反映了查全率和查准率之间的不均衡。</p><h1 id="a1b8" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">阅读分类报告</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/70f76126a278e3e6580a4da769eea2da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kfacEb7uQ7_BcsAQAvUH2g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我的标记版本<a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">分类_报告</a>来自scikit-learn。</p></figure><p id="d842" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一次看到scikit-learn时，它对我来说非常难以理解，以至于我推迟了为项目选择指标，因为我无法找出它们在报告中的位置。我希望有人给了我上面的小抄。</p><p id="298f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我认为让它如此难以阅读的部分原因是它打印出了<code class="fe ls lt lu lv b">accuracy</code>，然后是<code class="fe ls lt lu lv b">macro avg</code>和<code class="fe ls lt lu lv b">weighted avg</code>，我的大脑认为是<code class="fe ls lt lu lv b">accuracy</code>；但那是错的，他们属于<code class="fe ls lt lu lv b">precision</code>、<code class="fe ls lt lu lv b">recall</code>、<code class="fe ls lt lu lv b">f1-score</code>。恰好有一个数字属于<code class="fe ls lt lu lv b">accuracy</code>，我在上面用红色画了一个虚线框。</p><p id="b0ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">精确度、召回率和F1分数，每个都在上面自己的绿框中，都按类别细分，然后给出每个的宏观平均值和加权平均值。宏观平均数是我们习惯看到的通常平均数。把它们加起来，然后除以它们的数量。加权平均值考虑了计算中每个类别的数量，因此一个类别的数量越少，意味着它的精确度/召回率/F1分数对每个类别的加权平均值的影响就越小。橙色框中的<code class="fe ls lt lu lv b">support</code>表示每个职业有多少个:1个<code class="fe ls lt lu lv b">class 0</code>，1个<code class="fe ls lt lu lv b">class 1</code>，3个<code class="fe ls lt lu lv b">class 2.</code></p><p id="26ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，阅读上面的图表可能是这样的:对于<code class="fe ls lt lu lv b">class 0</code>、<code class="fe ls lt lu lv b">class 1</code>和<code class="fe ls lt lu lv b">class 2</code>，精度分别是0.5、0和1。这意味着在模型归类为0类的事物中，只有50%是真实的；在模型归类为1类的事物中，0%是真实的；在模型归类为第二类的事物中，100%都是真实的。宏观平均精度为0.5，加权平均精度为0.7。此模型的加权平均值较高，因为精度下降的地方是类1，但它在此数据集中的代表性不足(仅1/5)，因此在加权平均值中所占比例较小。</p><h1 id="7958" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">何时使用什么(概述)</h1><ul class=""><li id="cf73" class="nb nc iq ky b kz mo lc mp lf nd lj ne ln nf lr ng nh ni nj bi translated">使用<strong class="ky ir">精确度</strong>获得带有<strong class="ky ir">平衡数据集</strong>的模型性能的一般报告。</li><li id="16b2" class="nb nc iq ky b kz nk lc nl lf nm lj nn ln no lr ng nh ni nj bi translated">当你寻找的每一个实例都太珍贵而不能错过时，使用<strong class="ky ir">特异性/回忆性/敏感性</strong>。示例包括医疗保健、欺诈检测和安全事务中的测试。你会得到一些假警报，但这是让真正的疾病/欺诈/危险逃脱的较小的罪恶。</li><li id="15bb" class="nb nc iq ky b kz nk lc nl lf nm lj nn ln no lr ng nh ni nj bi translated">当你想确信你的模型是真的时，使用<strong class="ky ir"> precision </strong>。您正在寻找的一些东西会跑掉，但您可以确信，当您的模型pings某个东西时，它确实是它所说的那样。想想申请人筛选。一些可行的申请人将会逃脱，但是当模型pings一个可行的申请人时，你可以对此有信心。</li><li id="f216" class="nb nc iq ky b kz nk lc nl lf nm lj nn ln no lr ng nh ni nj bi translated">使用<strong class="ky ir"> F1分数</strong>作为召回率和精确度的平均值，尤其是在使用<strong class="ky ir">不平衡数据集</strong>时。如果召回率或精确度是0，F1分数将反映an也是0。举例来说，我最近试图按情绪对推文进行分类，积极的、消极的或中性的，但数据集不平衡，中性的评论比积极或消极的评论多得多。只有macro F1 score很好地描述了整体模型性能(同等关注所有三个类)。</li></ul><h1 id="f215" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">进一步阅读</h1><ul class=""><li id="caa0" class="nb nc iq ky b kz mo lc mp lf nd lj ne ln nf lr ng nh ni nj bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Sensitivity_and_specificity</a></li><li id="8248" class="nb nc iq ky b kz nk lc nl lf nm lj nn ln no lr ng nh ni nj bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Precision_and_recall</a></li><li id="543b" class="nb nc iq ky b kz nk lc nl lf nm lj nn ln no lr ng nh ni nj bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/F-score" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/F-score</a></li><li id="bb99" class="nb nc iq ky b kz nk lc nl lf nm lj nn ln no lr ng nh ni nj bi translated"><a class="ae kv" href="https://sebastianraschka.com/faq/docs/computing-the-f1-score.html" rel="noopener ugc nofollow" target="_blank">https://sebastianraschka . com/FAQ/docs/computing-the-f1-score . html</a></li><li id="b0d6" class="nb nc iq ky b kz nk lc nl lf nm lj nn ln no lr ng nh ni nj bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/beyond-accuracy-precision-and-recall-3da06bea9f6c">https://towards data science . com/beyond-accuracy-precision-and-recall-3da 06 bea 9 f6c</a></li><li id="c228" class="nb nc iq ky b kz nk lc nl lf nm lj nn ln no lr ng nh ni nj bi translated"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . metrics . class ification _ report . html</a></li></ul></div></div>    
</body>
</html>