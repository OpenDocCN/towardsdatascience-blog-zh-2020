<html>
<head>
<title>What the Human Brain Has That Deep Learning Desperately Needs: A Guide to Zero-Shot Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习迫切需要的人类大脑:零射击学习指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-the-human-brain-has-that-deep-learning-desperately-needs-a-guide-to-zero-shot-learning-2e296741ce51?source=collection_archive---------17-----------------------#2020-10-11">https://towardsdatascience.com/what-the-human-brain-has-that-deep-learning-desperately-needs-a-guide-to-zero-shot-learning-2e296741ce51?source=collection_archive---------17-----------------------#2020-10-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/afc2404e2cfd749e26cc966ecf416069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DVsrNJbj86bzZxe-j_iMtQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://unsplash.com/photos/cAQZuqdvba8" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><div class=""/><div class=""><h2 id="0b53" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">以及令人尴尬的简单ZSL算法</h2></div><p id="7c39" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">深度学习有一个很大的问题:它需要吞噬大量的数据，然后才能合理地推广并变得有用。这实际上是深度学习的局限性之一，限制了它在许多数据不丰富或难以获得的领域的应用。</p><p id="4ac3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">相比之下，人类虽然被描绘为人类与机器智能之战的输家，但却可以通过少量训练样本来学习复杂的概念。不知道什么是猫或狗的宝宝，在看到几张猫的图片和几张狗的图片后，就可以学会给它们分类了。即使当我们学习更复杂的概念时，我们也能够通过一个小的数据集获得大部分知识。</p><p id="ec2d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个属性使得教授人类概念变得费力，但却是可能的。一个四年级学生可以通过几十道题和好老师掌握基本代数原理。深度学习需要精心设计的架构、成千上万(如果不是更多)以专门格式编码的痛苦拼凑的问题和答案，以及几天的计算时间。</p><p id="4ac1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">也许人类大脑更有趣的一点是，我们可以轻松处理数百甚至数千个类。想想你周围环境中的所有物体——你的电脑、电脑上的应用程序、这些应用程序中的功能、几十种颜色、你同事的名字、所有英语单词。</p><p id="8321" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，即使你以前从未见过概念<em class="lu">，你也能认出它们。考虑以下想法(希望你以前没见过这些):将它们归类。这些类的实际名称并不重要——如果您愿意，可以称它们为zookildezonk。</em></p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lv"><img src="../Images/c05673c95d7b757e9a6f6b5acb942f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OpCnoQuMYbfJ3RRm6wZvkA.png"/></div></div></figure><p id="b4a7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是一个与新物种命名非常相似的过程。如果一位科学家发现了几只秃鹰，他或她可以简单地给这个物种命名为“秃鹰”，这些秃鹰有相似的特征:翼展6-7英尺，深棕色的尾巴，白色的尾巴，白色的头，明亮的黄色眼睛。尽管他或她事先并不知道“秃鹰”到底是什么。</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ma"><img src="../Images/b71cbf2c287f7ff75a3a45b63a24d841.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZD2_NL0vFWArhs862IzsWw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">这些都是鹰，但我们可以识别以前未学习的类，并给它们命名。来源:<a class="ae jg" href="https://pixabay.com/photos/bird-eagle-animal-bald-eagle-341898/" rel="noopener ugc nofollow" target="_blank">第一张</a>、<a class="ae jg" href="https://pixabay.com/photos/bald-eagle-bird-wildlife-eagle-140793/" rel="noopener ugc nofollow" target="_blank">第二张</a>、<a class="ae jg" href="https://pixabay.com/photos/golden-eagle-eagle-golden-bird-2247269/" rel="noopener ugc nofollow" target="_blank">第三张</a>、<a class="ae jg" href="https://pixabay.com/photos/bald-eagle-adler-bird-of-prey-723540/" rel="noopener ugc nofollow" target="_blank">第四张</a>图片(均来自Pixabay)</p></figure><p id="962b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们不需要给概念起名字来识别它们；名字是任意的，只是一种快速获取想法的方式。类似地，我们可以用任何我们喜欢的名字对这些抽象形状进行分类，只要这些名字表明了一个更广泛的概念(在这种情况下，两个正方形代表‘Zonkizonk’，三个正方形代表‘Bonkibonk’)。</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mb"><img src="../Images/c547b3073d518dd1f08650d690c9d365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RN820Pcwt6mKOFdXIIMhFg.png"/></div></div></figure><p id="c103" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">零射击学习是一种努力，将人类识别以前看不见的概念的能力带给机器。显然，这是迈向真正的人工智能和构建更像人类一样思考的算法的关键一步，但在有太多类，或者数据有限或获取成本高昂的问题中，这也非常实用。</p><p id="05e5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在深度学习尚未解决的问题越来越多地涉及错综复杂和类似人类的认知的世界中，零射击学习是一个答案。</p><p id="afe3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，一次性或少量学习指的是只给定一个或几个来自该类的训练示例，就能理解整个类，如<a class="ae jg" rel="noopener" target="_blank" href="/the-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b">双头连体网络</a>。</p><p id="c8de" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一种简单但有效的零镜头学习方法被称为“令人尴尬的简单零镜头学习”(ESZSL)，它以创造性的方式使用矩阵分解和无监督学习来产生一个产生令人惊讶的好结果的模型。理解它可以让你直观地了解许多其他零射击学习技巧的动态。</p><p id="c0d3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ESZSL在由数万个对象组成的<a class="ae jg" href="https://groups.csail.mit.edu/vision/SUN/" rel="noopener ugc nofollow" target="_blank"> SUN数据集</a>上对训练期间从未见过的类产生了超过65%的准确率。查看<a class="ae jg" href="http://proceedings.mlr.press/v37/romera-paredes15.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>以深入总结该方法在合成和真实数据数据集上的结果。</p><p id="c33f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从根本上说，ESZSL是一个线性模型。给定形状为<code class="fe mc md me mf b">(number of rows, number of features)</code>的输入矩阵<em class="lu"> X </em>和形状为<code class="fe mc md me mf b">(number of features, number of classes)</code>的权重矩阵，线性组合输出将为形状<code class="fe mc md me mf b">(number of rows, number of classes)</code>。</p><figure class="lw lx ly lz gt iv"><div class="bz fp l di"><div class="mg mh l"/></div></figure><p id="bbab" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ESZSL的目标是找到权重矩阵<em class="lu"> W </em>的值。</p><p id="7fe1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑一个相当复杂的模型必须完成的两个步骤:</p><ul class=""><li id="4573" class="mi mj jj la b lb lc le lf lh mk ll ml lp mm lt mn mo mp mq bi translated">通过将特征空间(input <em class="lu"> X </em>)映射到维度为<em class="lu"> a </em>的属性空间来解释输入，其中属性可以是诸如图像是否有四只脚、它是否是棕色的等等。每个属性的含义需要由模型决定。</li><li id="2aff" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mn mo mp mq bi translated">将来自属性空间的知识组合成输出。例如，如果图像有四只脚，并且是棕色的，则输出是狗。</li></ul><p id="b2c8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这两个目的可以用矩阵来表示。</p><ul class=""><li id="9089" class="mi mj jj la b lb lc le lf lh mk ll ml lp mm lt mn mo mp mq bi translated"><em class="lu"> V </em>有形状(特征数，<em class="lu"> a </em>)。<br/>当<em class="lu"> X </em>乘以<em class="lu"> V </em>时，结果有形状(行数，<em class="lu"> a </em>)。现在，每一行都由学习到的属性表示。这非常类似于神经网络层中的连接(没有偏置和激活)。</li><li id="05dc" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mn mo mp mq bi translated"><em class="lu"> S </em>有形(<em class="lu"> a </em>，类数)。<br/>当<em class="lu"> V </em>乘以<em class="lu"> S </em>时，结果有形状(行数，类数)。这种乘法结合了来自属性空间的学习以产生输出。这就像是神经网络的输出层。</li></ul><p id="802a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们可以将模型写成:</p><figure class="lw lx ly lz gt iv"><div class="bz fp l di"><div class="mw mh l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">上标代表矩阵的形状。r是数据集中的行数，f是特征数，a是中间层学习的属性数，c是类数。</p></figure><p id="dd11" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">原来，管道的后半部分——<em class="lu">S</em>，某些学习到的属性和类之间的关系——可以通过无监督的学习方法找到，如PCA，或者使用<a class="ae jg" rel="noopener" target="_blank" href="/manifold-learning-t-sne-lle-isomap-made-easy-42cfd61f5183?source=your_stories_page-------------------------------------">更复杂的流形学习技术，如局部线性嵌入和t-SNE </a>。</p><ol class=""><li id="047c" class="mi mj jj la b lb lc le lf lh mk ll ml lp mm lt mx mo mp mq bi translated">训练一个降维算法(PCA，LLE等。)在<em class="lu"> X </em>上，将训练输入数据，转换成<em class="lu"> a </em>尺寸。</li><li id="478f" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mx mo mp mq bi translated">得到的数据应该有shape ( <em class="lu"> r </em>，<em class="lu"> a </em>，其中<em class="lu"> r </em>是行数，<em class="lu"> a </em>是学习到的属性数。称这个矩阵为<em class="lu"> M </em>。</li><li id="0d6c" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mx mo mp mq bi translated">分配大小为(<em class="lu"> a </em>，<em class="lu"> c </em>的矩阵<em class="lu"> S </em>，其中<em class="lu"> c </em>为类数。</li><li id="7da4" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mx mo mp mq bi translated">对于每个唯一的类，在<em class="lu"> M </em>中找到标签与该类匹配的行。找出每一行的平均学习属性<em class="lu"> a </em>，并将信息填入<em class="lu"> S </em>。</li></ol><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/9e05f8dc97f3dc947a8e3a069962c3ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qxf6enI24S0nw5hsXhlZVQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">这里，E[(a，b)，(c，d)]表示期望值，或平均值。结果是((a+c)/2，(b+d)/2)。‘a1’和‘A2’代表属性1和属性2。</p></figure><p id="a47c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是导出<em class="lu"> S </em>的一种非常简单和优雅的方式，因为它利用了无监督的提取特征的方法，这对于零触发学习是有用的，因为它不会暴露于测试中可能出现的任何标签。在零触发学习算法中使用聚类也是有意义的，因为新类的识别是非常复杂的聚类任务。</p><p id="6235" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，训练和预测过程如下:</p><ul class=""><li id="3e77" class="mi mj jj la b lb lc le lf lh mk ll ml lp mm lt mn mo mp mq bi translated">在训练期间，使用上述无监督方法从<code class="fe mc md me mf b">X train</code>和<code class="fe mc md me mf b">y train</code>数据集计算<em class="lu"> S </em>。然后，使用标准优化方法(如梯度下降)计算<em class="lu"> V </em>，使模型的预测损失最小。</li><li id="4fae" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mn mo mp mq bi translated">测试时，形成两个数据集，<code class="fe mc md me mf b">X test-train &amp; y test-train</code>和<code class="fe mc md me mf b">X test &amp; y test</code>。前者是测试集的一部分，有标签；这允许<em class="lu"> S </em>将类合并到测试集中，而不是训练集中。在后一种情况下，算法没有标签。<br/>用上述非监督方法从<code class="fe mc md me mf b">X test-train</code>和<code class="fe mc md me mf b">y test-train</code>数据集计算<em class="lu"> S </em>。由于已经计算出了将输入转换到属性空间的<em class="lu"> V </em>，因此模型已经完成。</li></ul><p id="4c96" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">即使是“简单得令人尴尬”的零距离学习法也有点难以理解。让我们以MNIST数据集为例，该数据集由从0到9的手写数字组成。</p><ol class=""><li id="8080" class="mi mj jj la b lb lc le lf lh mk ll ml lp mm lt mx mo mp mq bi translated">我们将在0到4的数字上训练模型，然后让它在测试集中识别5到9的数字。</li><li id="7b93" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mx mo mp mq bi translated">根据训练集计算<em class="lu"> S </em>。然后，找到<em class="lu"> V </em>。</li><li id="5891" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mx mo mp mq bi translated">形成测试训练组，这是来自测试集的数字的小样本(数字5到9)。由此，计算更新的<em class="lu"> S </em>。输出将对应于从5到9的数字，而不是从0到4(当在训练集上计算时)。</li><li id="af69" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mx mo mp mq bi translated">通过模型运行测试集的剩余部分，更新的<em class="lu"> S </em>和<em class="lu"> V </em>来自训练。</li></ol><p id="3fd8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，在测试集期间对<em class="lu"> S </em>的计算有点可疑，如果你非常严谨，你可能会反对它是真正的<em class="lu">零命中率</em>，因为部分预测<em class="lu"> S </em>依赖于标签。或者，有人可能会认为这是必要的，并且在整个训练和测试过程中，<em class="lu">V</em>——负责编码输入的所有工作——保持不变。无论你站在哪里，这都是一个很好的了解零射击算法背后思想的机会。</p><p id="4dd6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，一般来说，零触发学习方法遵循三种学习范例中的一种:</p><ul class=""><li id="a6fa" class="mi mj jj la b lb lc le lf lh mk ll ml lp mm lt mn mo mp mq bi translated"><em class="lu">学习属性</em>。类伴随着结构化的描述；例如,“白头”和“黄嘴”在描述秃鹰时。这允许算法将输入分解成所描述的类的元素，即使它没有看到来自该类的任何显式示例。</li><li id="ef7c" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mn mo mp mq bi translated"><em class="lu">学习文字描述</em>。类伴随着文本的自然语言描述，就像字典或百科全书中的一个单词。这允许模型解释和映射一个输入到一个只有类描述的类。</li><li id="251b" class="mi mj jj la b lb mr le ms lh mt ll mu lp mv lt mn mo mp mq bi translated"><em class="lu">自主学习</em>。类被嵌入到一个连续的空间中，零触发分类器解释嵌入的位置以确定输出。这是ESZSL遵循的范例；由于不需要每个类的属性或文本描述，这种方法更符合零起点学习的目标，但性能可能会更差。</li></ul><p id="67d3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">零镜头学习应用于图像分类、语义分割、图像生成、对象检测和自然语言处理，以及其他更具体的用例，如语言翻译。该领域的研究数量每年都在快速增长，其中很多都是对传统深度学习方法的创造性背离——毕竟，困难的任务需要更多的创新。</p><p id="d49f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读！</p><p id="f563" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你对最新的文章感兴趣，可以考虑订阅。如果你想支持我的写作，通过我的推荐链接加入Medium是一个很好的方式。干杯！</p><div class="is it gp gr iu mz"><a rel="noopener follow" target="_blank" href="/the-two-headed-neural-network-shaking-up-image-recognition-8c3c7093d61b"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd jk gy z fp ne fr fs nf fu fw ji bi translated">双头神经网络抖动图像识别</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">暹罗网络的魔力</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">towardsdatascience.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn ja mz"/></div></div></a></div><p id="e163" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">图片由作者创作，除非另有说明。</em></p></div></div>    
</body>
</html>