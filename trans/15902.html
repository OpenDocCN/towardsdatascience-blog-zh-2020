<html>
<head>
<title>Class Imbalance, SMOTE, borderline SMOTE, ADASYN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">等级不平衡，SMOTE，临界SMOTE，ADASYN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/class-imbalance-smote-borderline-smote-adasyn-6e36c78d804?source=collection_archive---------15-----------------------#2020-11-02">https://towardsdatascience.com/class-imbalance-smote-borderline-smote-adasyn-6e36c78d804?source=collection_archive---------15-----------------------#2020-11-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="564b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">类别不平衡会使我们的算法失去平衡</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f88c5957c746d77f9d7a1a1f885e2c3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cHiyV3FR6ZBCT53z"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/photos/t1XLQvDqt_4" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><p id="4e34" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di">那是在20世纪90年代末，当时南佛罗里达大学的一名研究生Niesh V . Chawla(SMOTE背后的主脑)正在研究一个二元分类问题。他正在处理乳房x光摄影图像，他的任务是建立一个分类器，该分类器将像素作为输入，并将它分类为正常像素或癌变像素。当他达到97%的分类准确率时，他相当高兴。当他看到97.6%的像素正常时，他的快乐是短暂的。</span></p><p id="eb7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可能在想，这有什么问题？有两个问题</p><ul class=""><li id="b949" class="mb mc iq ky b kz la lc ld lf md lj me ln mf lr mg mh mi mj bi translated">假设在一个100个像素的样本中，98个是正常的，2个是癌性的，如果我们写一个程序，它可以预测任何正常的东西。分类准确率会是多少？高达98%。<strong class="ky ir">程序学会了吗？一点也不。</strong></li><li id="a28e" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated">还有另一个问题。分类器努力在训练数据中获得良好的性能，并且随着正常观察值越来越多，<strong class="ky ir">它们将更加专注于学习“正常”类的模式</strong>。这就像任何学生知道98%的问题来自代数，2%来自三角学时会做的一样。他们会安全地忽略三角测量</li></ul><p id="e1e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，为什么这个问题会表现出来呢？这是因为上课的频率和次数之间有很大的差异。<strong class="ky ir">我们称这样的数据集为展示类不平衡。正常阶层被称为多数阶层，罕见阶层被称为少数阶层。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/314df59c8fa39ce72e349a8f22fd0aa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*55LNSk2pwICvSPuIj8uNuw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作为少数派的海鸥(<a class="ae kv" href="https://unsplash.com/photos/SQBtDa6cKDA" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/SQBtDa6cKDA</a>)</p></figure><p id="5303" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现实应用中存在这种情况吗？以垃圾邮件检测、假新闻检测、欺诈检测、可疑活动检测、入侵检测等为例，其中表现出了类别不平衡问题。</p><h1 id="3a0e" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">实现某种平衡的解决方案:</h1><p id="d94d" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">基本的方法被称为重采样技术。有两种基本方法。</p><p id="5032" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">欠采样:- </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/48d3903ae098479f77a9d0925833281f.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*vMijhDml-HKNtzY_dIv-nA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">欠采样或欠采样多数类(图像源作者)</p></figure><p id="1a79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们从多数类中随机选取样本，并使其等于少数类计数。这被称为<strong class="ky ir">欠采样或多数类</strong>的下采样。</p><p id="6760" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">问题:<strong class="ky ir">忽略或放弃这么多原始数据并不是一个好主意。</strong></p><p id="e121" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">过采样:- </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/87714537d4d414dd1613f3feea5fc887.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*MuQK8jnk0d-fQSuPn_VRlQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对少数类进行过采样或上采样(图片来源作者)</p></figure><p id="ac38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，替换抽样应用于少数类，以创建与多数类一样多的观察值，并且这两个类是平衡的。这被称为<strong class="ky ir">过采样或</strong>少数类上采样。</p><p id="2c2a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">问题:<strong class="ky ir">相同少数类数据的重复导致过度拟合。</strong></p><p id="cfa1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">重击:</strong></p><p id="a251" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">SMOTE的完整形式，综合技术。这里的综合观察是从少数类中产生的</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/e7d6f4b720da5cf3b65c31376409718f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R70XkU6wg9kKWC6OjxgKww.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">SMOTE，合成少数观察生成过程(来源:作者)</p></figure><p id="7284" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设有来自少数类的两个观察值(x1，y1)和(x2，y2)。作为第一步，创建一个介于0和1之间的随机数，我们称之为r。合成点将是(x1 + r*(x2 -x1)，y1 + r*(y2 -y1))。下面的例子进一步说明了这一点。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/b1e94dd8d65e0515a34565319c262e66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*TIniOUSnxwmX-EnwRoQaNQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从少数类生成的合成点(图片来源:作者)</p></figure><p id="692e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【SMOTE的一个问题:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/f6bb9f3c3fd4e776898c9308a47f80cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ymikOVElRqXH9tM_SIF9Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">左侧:原始数据右侧:应用SMOTE后的数据(图片来源:作者)</p></figure><p id="c54d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果少数类中的观察值是外围的并且出现在多数类中，则通过创建与多数类的线桥，会给SMOTE带来问题。</p><p id="af19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">临界击打:- </strong></p><p id="b224" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这解决了上述问题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/0620d5a4672f59d449a46a4dd44c1987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1J4D5SJ2xbiHZVFjv3IPg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">边界线SMOTE:(图片来源作者)</p></figure><p id="0f8d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该算法首先对少数类观测值进行分类。如果所有邻居都是多数类，则它会将任何少数观察分类为噪声点，并且在创建合成数据时会忽略此类观察(类似于DBSCAN)。此外，它将几个点分类为具有多数和少数类作为邻域的边界点，并完全从这些点重新采样(支持向量通常会关注的极端观察)。</p><p id="a4f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">问题:结束对这些极端观察的更多关注。</p><p id="e2b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">阿达辛:</strong></p><p id="9a73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ADASYN是一个更通用的框架，对于每个少数观察值，它首先通过取邻域中多数观察值与k的比值来找到邻域的杂质。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/23840bf84ab1556a710c2e5e18d1b7f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*l81waY6SFbRaz9xCz2fe9g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">阿达辛杂质比率</p></figure><p id="1e29" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，首先，通过使总和为1，将该杂质比转换成概率分布。那么该比率越高，为该特定点生成的合成点就越多。因此，为Obs 3创建的合成观测数据的数量将是Obs 2 的两倍。因此，它不像边界平滑那样极端，噪声点、边界点和常规少数点之间的边界要柔和得多。(不是硬性边界)。因此得名自适应。</p><p id="df4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个在下面的视频教程里也有讲解，请给它一个<a class="ae kv" href="https://youtu.be/mKG7lnZNAOk" rel="noopener ugc nofollow" target="_blank">看</a></p><p id="86d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">尾注</strong>:</p><p id="426e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">阶层失衡是一个非常现实的问题。基于重采样的方法没有前途，这促使研究人员开发SMOTE，并通过borderline SMOTE、ADASYN等逐渐改进。要了解更多的变体，参考文献2是一个很好的读物。</p><p id="d79d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">参考</p><p id="6e89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1]舒拉NV，鲍耶KW，霍尔LO，凯格尔迈耶WP。SMOTE:合成少数过采样技术。人工智能研究杂志。2002年6月1日；16:321–57.</p><p id="cc2c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]费尔南德斯A、加西亚S、埃雷拉F、舒拉NV。SMOTE从不平衡数据中学习:进步与挑战，15周年纪念。人工智能研究杂志。2018年4月20日；61:863–905.</p></div></div>    
</body>
</html>