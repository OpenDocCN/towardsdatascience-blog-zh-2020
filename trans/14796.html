<html>
<head>
<title>Deep Learning vs Puzzle Games</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习vs益智游戏</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-vs-puzzle-games-e996feb76162?source=collection_archive---------28-----------------------#2020-10-12">https://towardsdatascience.com/deep-learning-vs-puzzle-games-e996feb76162?source=collection_archive---------28-----------------------#2020-10-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7c6a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">深度学习是否比古老的强力技术更适合解决流量自由？</h2></div><p id="7694" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们都经历过。你无聊地玩着手机，有一些时间可以消磨，所以你决定——违背你更好的判断——访问app store的游戏部分，看看有什么趋势。你看到一个看起来很有趣的益智应用，但这并不重要，因为你只会玩半个小时，然后删除它并忘记它，<em class="lb">对吗？</em></p><p id="e27a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">两个月后，我完成了2000多级的<a class="ae lc" href="https://www.bigduckgames.com/" rel="noopener ugc nofollow" target="_blank">免流量</a>，坚持在每一级都获得“完美”评级。这款游戏是自2012年发布以来iOS和Android上最受欢迎的手机游戏之一，它的前提非常简单:在2D网格上连接不同颜色的“阀门”，没有两条线相交:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/28324a26f9232b5e16a6fb8a738c1fb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*O5f4SVdxQqaEQ93UdZiwVg.png"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">自由流动——你可以从一张截图中很好地理解这个游戏</p></figure><p id="af46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">截图中的关卡看似简单，但确实越来越难。随着关卡的进展，我发现自己想出了一些策略来帮助我更快地解决这些高级关卡(例如，尽可能坚持最外面的未填充边界，避免创建未填充方块的“入口”，等等)。)浏览网络论坛，看到其他玩家都有自己的技术，有些和我的相似，有些不同。这就引出了一个问题——一台计算机，不是通过蛮力，而是通过“经验”,也能学习这些技术吗？</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/f98a5cf48c32157525494d35dab97a56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*9Xux0uvZ1y-ys0yDt6Ei8w.gif"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">一个人类(你真正的)正在解决一个自由流动的难题</p></figure></div><div class="ab cl lq lr hu ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ij ik il im in"><h1 id="6836" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">从基础开始:A*</h1><p id="d3cd" class="pw-post-body-paragraph kf kg iq kh b ki mp jr kk kl mq ju kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">如今的深度学习问题大多归结为决定使用哪种算法。我从搜索开始。即使它本身不是深度学习，它也让我们很好地了解了问题的内在复杂性，并让我们有机会尝试一些更高级的算法<em class="lb">可以</em>自己解决的启发式算法。</p><p id="21c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">空间复杂度太大，无法一次解决整个棋盘，所以我从逐颜色递归解决开始(如果给定的路径被“阻塞”，则回溯到上一个颜色)。作为启发，我使用了可靠的曼哈顿距离。我在4种尺寸的电路板上测试了我的算法:小型(2x4)、小型(5x5)、中型(8x8)和大型(14x14)。我确保了中型和大型棋盘的颜色比普通棋盘少<em class="lb">种</em>种，因为这实际上使谜题变得更加困难，对人类和计算机都是如此(更多可能的路径/选项/状态)。</p><p id="3d1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这在小型电路板上运行良好，但需要相当多的时间。因此，我在下一个状态函数中添加了一些规则，希望强化学习算法能够自己找出这些规则:防止颜色相同的非连续相邻方块或空“入口”:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/05fd0dd35d418c378a85f43c0ba9dbfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*n6NV2s0S9J6tcQrMbFFbCA.png"/></div></figure><p id="f8f4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我用了7年的电脑上的结果更令人鼓舞，但仍需要改进:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/5380cc486bd18a8d51ffc4c1764e04a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*DMC3MmRfrwDFrBmbygdHZg.png"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">我很惭愧地说，我可能花了更多的时间在我的Tkinter绘图功能上，而不是实际的人工智能</p></figure><h1 id="0754" class="lx ly iq bd lz ma mw mc md me mx mg mh jw my jx mj jz mz ka ml kc na kd mn mo bi translated">如果你认为你是第一个这样做的人，你可能错了</h1><p id="2937" class="pw-post-body-paragraph kf kg iq kh b ki mp jr kk kl mq ju kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">在进入强化学习之前，我正在进一步优化我的A*搜索，这时我发现了Matt Zucker 的这篇<a class="ae lc" href="https://mzucker.github.io/2016/08/28/flow-solver.html" rel="noopener ugc nofollow" target="_blank">优秀博客文章，他已经为Flow Free构建了一个A*求解器(很高兴看到我不是唯一一个痴迷于此的人)，并且更加仔细地考虑了要从他的A*搜索中删除的州。更重要的是，他发现<strong class="kh ir">一个只有6条规则的简单SAT算法胜过了他非常先进的A*搜索</strong>，并且用SAT得到了非常好的求解时间(甚至对于14x14的电路板也是亚秒)。</a></p><p id="7f16" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">到目前为止，我们似乎都得出了同样令人沮丧的结论:对于这种类型的(非对抗性的、封闭的)益智游戏，简单的暴力技术将胜过基本的人工智能算法。</p><p id="ad19" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，停留在那里是没有用的。毕竟，启动这一探索的问题仍然存在:作为人类玩家，我们在玩了几个级别后，发现了更有效地击败流自由谜题的特定技术。为什么机器不能学习同样的技术？</p></div><div class="ab cl lq lr hu ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ij ik il im in"><h1 id="4220" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">线索强化学习</h1><p id="ef3f" class="pw-post-body-paragraph kf kg iq kh b ki mp jr kk kl mq ju kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">我非常兴奋能在Flow Free上尝试Q-learning，因为这才是“人工智能”中的“我”真正开始发挥作用的地方。A*搜索的工作绝不是浪费时间，因为我们可以用它作为Q学习代理的状态-动作空间。我们认为状态空间是棋盘上哪些方格被哪种颜色占据，以及哪条路径(颜色)当前是“活动的”的组合。一个动作就是填充该路径的下一个方块。</p><p id="bc7a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">学习代理在一开始犯了一些基本错误后，很快学会了如何解决小问题(1.5s内迭代100次)——目前看起来不错。然而，在中型板上，在10，000次迭代之后仍然没有骰子，这花费了10分钟:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nb"><img src="../Images/039bd4233b671c481777fac15e4f1605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VJwNG5eokzfrxwJuZNTeNw.png"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">不完全是你听到“人工智能”时想到的</p></figure><p id="38d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了改善这一点，我开始摆弄那些帮助不大的标准Q-learning参数(学习率α、折现率γ、探索/开采率ε)，于是我把注意力转向了奖励函数。除了玩实际的奖励之外，奖励函数本质上还有一个参数可以切换(或者有变得过于规定性的风险，这将违背整个机器学习练习):代理是否会因为解决了一条路径而不是整个谜题而获得奖励。不幸的是，这并没有带来多大的不同。</p><p id="0bc1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，很明显，该算法在较大的电路板上很难运行，仅仅是因为选项空间太大。与A*搜索相比，Q-learning确实在这种情况下有所帮助，因为它做出了更聪明的选择，但是仍然有太多的情况，即使在10，000次迭代之后，确切的Q-learning代理还没有看到。因此，下一个自然的步骤是:</p><h1 id="a658" class="lx ly iq bd lz ma mw mc md me mx mg mh jw my jx mj jz mz ka ml kc na kd mn mo bi translated">近似Q学习</h1><p id="5d86" class="pw-post-body-paragraph kf kg iq kh b ki mp jr kk kl mq ju kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">近似Q学习的应用非常吸引人，尤其是在游戏中。这个想法不是让代理在给定的状态下决定最佳行动，而是给它一些直观的特征，它可以在每一步快速计算，与确切的状态(棋盘的配置)无关，并让它决定哪些是最重要的。这可能是像Pacman这样的游戏中的游戏规则改变者(例如，根据到最近的小球和最近的幽灵的距离来决定你的下一步行动，而不是针对每个可能的状态的行动)，或者当然是自由流动，其中可能的状态的数量对于精确的Q学习来说太多了，以至于没有效果。</p><p id="9628" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">权衡的结果是，现在由开发人员来选择“正确的”特性。我将列表缩小到我知道在许多情况下很重要的特征(例如，关闭每条路径的剩余曼哈顿总距离)，以及一些我怀疑很重要(但没有办法证明)的特征，我会让算法找出这些特征。其中包括:</p><ul class=""><li id="18ae" class="ng nh iq kh b ki kj kl km ko ni ks nj kw nk la nl nm nn no bi translated">关闭每条路径的剩余曼哈顿总距离</li><li id="229e" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">“圈数”</li><li id="e366" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">“盒子”的数量</li><li id="b6b0" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">箱中阀门的数量</li><li id="e9f7" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">没有阀门的盒子的数量(人们可以从逻辑上证明这种情况永远不会发生——我想看看算法是否能解决这个问题)</li><li id="bab8" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">一条路径是否“靠墙”(即，一条路径是否能粘住另一条相邻的路径)</li></ul><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/b83b083304eb078da309298df1900ed3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*3FhPdAWnft23ozLqm_6FNg.png"/></div></figure><p id="236c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不幸的是，有了这些特性，Q-learning agent甚至不能解决小棋盘，即使在改变Q-learning参数之后。然而，看到它的运行是一个有趣的练习。例如，<em class="lb"> </em>该算法给“没有阀门的盒子”附加了一个很大的负权重，这意味着<strong class="kh ir">它能够了解到，有一个没有阀门的盒子会导致谜题无法解决</strong>。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nv"><img src="../Images/4019cb01d08262619dac23dd7e120f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oF9OL62cxs-lZpikV0uaCQ.png"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">近似Q学习检测更好的游戏策略</p></figure><p id="4dc6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">也许有了更大的谜题样本，它可以更好地学习实际解决它们，但我很兴奋地看到它实际上选择了什么是重要的。这是人工智能中一个迷人的现象，尤其是在游戏人工智能中非常普遍:<strong class="kh ir">即使一个算法不能赢得比赛，它也可以找到帮助人类更好地比赛的技术。</strong></p></div><div class="ab cl lq lr hu ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="ij ik il im in"><h1 id="c8fc" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">走向监督:卷积神经网络</h1><p id="dd5c" class="pw-post-body-paragraph kf kg iq kh b ki mp jr kk kl mq ju kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">起初，我对自由流动的监督方法的想法有偏见。首先，它需要一个大样本的解决流量免费游戏，很难在公共互联网上找到。第二，似乎最接近无流匹配的监督方法——神经网络——是一个臭名昭著的黑箱，它将排除练习中最有趣的部分:看到算法学习解决难题的技术。</p><p id="c1db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，我在《走向数据科学》杂志上看到了希瓦·维尔马的一篇文章<a class="ae lc" rel="noopener" target="_blank" href="/solving-sudoku-with-convolution-neural-network-keras-655ba4be3b11">，他在文章中对数独做了一些非常类似的事情:本质上将数独棋盘视为图像，并使用<em class="lb">卷积</em>神经网络(CNN)来解决它。作者在数独上取得了很好的结果，这让我重新审视了我最初的保留意见，并尝试了这种无流量的方法。</a></p><p id="e17a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，第一个障碍是获取输入数据；以可解析文本格式解决的自由流谜题比数独谜题更难找到。我一开始发现的最好的方法是查看Android应用程序的代码，它有一千多个以文本格式存储的谜题:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nw"><img src="../Images/9b21e971c019641a7ee26007ec1dd332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CDhpw1qMgli4dT6S9N3Szw.png"/></div></div></figure><p id="7116" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CNN的最初结果令人失望:测试样本中只有0%的谜题被解决，尽管<strong class="kh ir"> CNN正在学习它应该制作路径</strong>，而不仅仅是孤立地填充颜色。</p><h2 id="db93" class="nx ly iq bd lz ny nz dn md oa ob dp mh ko oc od mj ks oe of ml kw og oh mn oi bi translated">我们需要更多的数据</h2><p id="7b04" class="pw-post-body-paragraph kf kg iq kh b ki mp jr kk kl mq ju kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">调整层、时代、内核大小和其他类似的常见问题没有多大帮助。看起来我们又回到了数据科学家最常见的问题上:<strong class="kh ir">如果没有足够的数据，世界上最好的算法就什么也不是</strong>。我找到的最好的其他数据来源是www.flowfreesolutions.com，有数以千计的全新谜题的免费解答，但都是图片格式的。</p><p id="69f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管我多次尝试通过各种渠道与他们联系(甚至提供了经济激励)，我还是无法让他们给我发送他们解决方案的可解析文本版本。嗯，这不是一篇没有意义的人工智能文章——当一个人拥有现代图像处理时，谁还需要底层的解决方案矩阵？提示一个子项目来构建一个<a class="ae lc" href="https://github.com/kgaspard/flow-free-ai/blob/master/imageParser.py" rel="noopener ugc nofollow" target="_blank">无流解决方案图像处理器</a>:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oj"><img src="../Images/4c9b5daacd954b53a7a0f5de04cd33c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ri5CxccSjwncSj6TewyV8A.png"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">sci kit-图像FTW</p></figure><h2 id="2f7a" class="nx ly iq bd lz ny nz dn md oa ob dp mh ko oc od mj ks oe of ml kw og oh mn oi bi translated">利用对称性来增加我们可用的数据</h2><p id="5385" class="pw-post-body-paragraph kf kg iq kh b ki mp jr kk kl mq ju kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">这又产生了几千个数据点，但这仍然不多。但我随后意识到，就CNN而言，<em class="lb">颜色的确切值并不重要，重要的是颜色不同的事实</em>。因此，我们可以改变周围的颜色，仍然有另一个<em class="lb">非冗余</em>数据点。即使5x5电路板有多达6种不同的颜色，这给我们的CNN多达6种！=要处理的数据点增加了720倍(当然，更大的电路板和更多颜色的组合可供选择):</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ok"><img src="../Images/9b3cc5c9f0bd6e3dd5a9d23727385761.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8dilzqOd32VjEbyIajuQ8Q.png"/></div></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">数学家将从群论中认识对称群S_n</p></figure><p id="1989" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有朋友指出，这其实是游戏AI中常用的增加数据点的方法。有了720倍的数据点，我们终于取得了一些进展——在我7岁的GPU上运行20个时期的模型，大约200，000个数据点，测试数据的准确率为12%。请注意，我们在这里使用了一个严格的成功标准:即使电路板差了一个单元，我们也认为这是一次失败。</p><p id="70f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，这里的失败比成功有趣得多。在几乎所有的失败中，<strong class="kh ir">CNN正确地解决了大部分问题，足以让人类轻松完成。</strong>从这个意义上说，CNN能够解决文章的原始前提:直观地学习人类的技术:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/f821a8d5c0018f542df7ef2d8699d494.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*tVo3_29b6WpRz9KZ7AJ7JA.png"/></div></figure><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi om"><img src="../Images/e571abaabe366577051f0313a4e0ca8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*b3Jeiqou42ttjqq4fZmH7A.png"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">CNN的误差分布</p></figure><h1 id="8148" class="lx ly iq bd lz ma mw mc md me mx mg mh jw my jx mj jz mz ka ml kc na kd mn mo bi translated">结论</h1><ul class=""><li id="3d73" class="ng nh iq kh b ki mp kl mq ko on ks oo kw op la nl nm nn no bi translated">简单的方法通常更适合解决基于网格的、非对抗性的益智游戏。事实上，随着方法逐渐变得更先进，性能变得更差。</li><li id="d1ac" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">然而，尽管更先进的ML方法不会很快解决这个难题，但它们确实找到了有趣的见解，并帮助人类找到更好的解决方案——卷积神经网络在这方面做得最好。此外，它们的性能比更传统的解决方案更具扩展性。</li><li id="02de" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">更好的数据胜过更好的算法。</li></ul><h1 id="de65" class="lx ly iq bd lz ma mw mc md me mx mg mh jw my jx mj jz mz ka ml kc na kd mn mo bi translated">更进一步:读者和编辑建议</h1><p id="2961" class="pw-post-body-paragraph kf kg iq kh b ki mp jr kk kl mq ju kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">我请一些更有经验的人工智能/人工智能专家(非常感谢<a class="ae lc" href="https://mzucker.github.io/swarthmore/" rel="noopener ugc nofollow" target="_blank">马特·祖克</a>、<a class="ae lc" href="https://www.researchgate.net/profile/Youssef_Keyrouz" rel="noopener ugc nofollow" target="_blank">优素福·基鲁兹</a>和<a class="ae lc" href="https://medium.com/@marksaroufim" rel="noopener">马克·萨鲁菲姆</a>)来评论这篇文章，他们建议尝试以下想法来改进CNN算法。这可能是第2部分文章的主题，或者您可以在https://github.com/kgaspard/flow-free-ai的<a class="ae lc" href="https://github.com/kgaspard/flow-free-ai" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir"/></a>上随意尝试一下(以及本文中详述的方法):</p><ul class=""><li id="694a" class="ng nh iq kh b ki kj kl km ko ni ks nj kw nk la nl nm nn no bi translated">改变CNN的层数(消融似乎没有帮助)</li><li id="c1d7" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">除了使用对称来增加我们的数据点，还使用旋转/反射</li><li id="164a" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">使用CNN预测作为强化学习代理的特征</li></ul></div></div>    
</body>
</html>