<html>
<head>
<title>Joint Deep Modeling of Users and Items Using Reviews for Recommendation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用评论进行推荐的用户和项目的联合深度建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/joint-deep-modeling-of-users-and-items-using-reviews-for-recommendation-50e75d5e10aa?source=collection_archive---------56-----------------------#2020-09-21">https://towardsdatascience.com/joint-deep-modeling-of-users-and-items-using-reviews-for-recommendation-50e75d5e10aa?source=collection_archive---------56-----------------------#2020-09-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a406dae762d9870ef93f0543bbc3be2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lunBgxpBK4jlZ4U0D1anjg.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">照片由<a class="ae kf" href="https://www.freepik.com/vanitjan" rel="noopener ugc nofollow" target="_blank"> vanitjan </a>在<a class="ae kf" href="https://www.freepik.com/free-photo/empty-living-room-with-blue-sofa-plants-table-empty-white-wall-background-3d-rendering_9928644.htm" rel="noopener ugc nofollow" target="_blank"> Freepik </a>上拍摄</p></figure><p id="94bb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如今，推荐系统经常出现在我们的日常生活中，比如网上购物、阅读文章和看电影。人们可以根据自己的兴趣从推荐系统中看到推荐的商品。许多推荐系统使用协同过滤方法，该方法的技术表明，过去有相似偏好的人将来倾向于有相似的选择。挑战在于很少有用户对物品发表评论。该文章关注深度合作神经网络(DeepCoNN)，针对评分预测问题从用户和项目获取评论。</p><p id="5781" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">在本文中，你将学习推荐系统的奇异值分解和截断奇异值分解:</strong></p><p id="68e0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(1)模型架构</p><p id="40ef" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(2)单词表征</p><p id="0694" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(3) CNN层</p><p id="ebd1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(4)共享层</p><p id="f1cb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(5)网络培训</p><p id="72ce" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(6)对DeepCoNN的分析</p><p id="ee7b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(7)基线模型</p><h2 id="50da" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">模型概述</h2><p id="c4bb" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在深度合作神经网络(DeepCoNN)中，有一个用于学习项目属性和用户行为的评论数据集，以及在最后几层组合的两个并行神经网络。一个网络关注用户的评论以从用户的行为中提取特征，另一个网络主要利用物品的评论以突出物品的属性。</p><h1 id="8509" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">模型架构</h1><p id="6f20" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">有两个并行的神经网络，一个用于用户的网络(Netu)和一个用于项目的网络(Neti)，这两个网络合并在最后一层。对于两个网络，输入数据是Netu中的用户评论，Neti中的商品评论，然后是作为输出的评级。</p><p id="9ac8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于也称为查找层的第一层，从用户评论中生成单词嵌入，用于语义提取。接下来，使用卷积层、最大池层和全连接层构建模型，以生成用户和项目的要素。最后，最终的顶层实现了用户和物品之间隐藏的潜在因素的交互。</p><p id="850b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">DeepCoNN计算426目标函数以缩小来自Netu和Neti输出的潜在因子的评级预测误差。我们将详细介绍Netu的过程，同样的过程也适用于Neti，因为Netu和Neti具有相同的输入。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mt"><img src="../Images/bd5418c258afc8514f3cbf250298b58c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ruUAhx0rZAKVpbsWC_KglA.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">情节:模型架构</p></figure><h1 id="e5d1" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">单词表示法</h1><p id="50ee" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">一个单词嵌入f: M→ N_n .一个把单词字典变换成N维分布向量的映射函数。男:单词字典。N_n: n维分布向量。</p><p id="4927" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">利用词的表示来提取评论的语义。评论被转换成单词嵌入矩阵，用于查找层的语义提取。所有用户的书面评论u合并成一个文档d*u_(1-n)共n个单词。下面内置一个字向量矩阵V*u_(1:n):</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div class="gh gi my"><img src="../Images/9b67c06fc487378f02bb6da014ed345c.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*rk3lrmKjVrcmBnkfAFs2PQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">等式:单词向量</p></figure><p id="174b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">d*u_k:文档d的第k个单词<br/> d*u_(1:n):查找函数<br/> φ(d*u_k):返回单词<br/> ⊕:连接运算符对应的c维单词向量</p><p id="5678" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与词袋技术相比，在矩阵V * u(1:n)中保持了词的顺序</p><h1 id="a6af" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">CNN图层</h1><p id="2096" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">CNN模型包括卷积层、最大池和全连接层。卷积层中有m个神经元，通过对用户u的单词向量V*u_(1:n)应用卷积算子来产生新的特征。在卷积层中，每个神经元j在大小为t的单词窗口上应用滤波器Kj ∈ n(c*t)。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/be4125c65f95138ee9164a1c74cf48f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*5VPj7ZpWzdwbmCPxb0uwqA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">等式:带内核的卷积层</p></figure><p id="a078" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">*:卷积算子<br/> b_j:偏置项<br/> f: relu激活函数</p><p id="0cc5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面指定了Relu激活。具有ReLU的深度卷积神经网络的训练周期比tanh激活函数快得多。</p><p id="8349" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">f(x) = max{0，x}</p><p id="8dc9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面的等式是特征图上的最大池，并从特定内核中提取最大值作为特征。特征图中的最高值是最重要的特征。汇集层可以应用于不同的文本长度。在最大汇集操作之后，卷积结果被转换成固定大小的向量。</p><p id="a409" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">o_j = max{z_1，z_2，…，z _(n t+1)}</p><p id="6529" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">模型中的多个过滤器生成了各种特征。下面的等式是卷积层的输出向量</p><p id="842b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">O = {o_1，o_2，o_3，…，o_n1 }，</p><p id="630a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">o_n1:卷积层中内核的数量</p><p id="9d5d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">X_u = f(W × O + g)</p><p id="7f87" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">max-pooling层输出到下一个具有权重矩阵w的全连接层上式是全连接层的输出xu ∈ n*(n_2*1)。最后，我们可以从用户和项目x_u和y_i的CNN层获得输出。</p><h1 id="bfcf" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">共享层</h1><p id="87ce" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">作为特征的项目和用户的输出在不同的特征空间中，并且不可比较。共享层被引入到Netu和Neti之上，以在特征空间中映射它们。单个向量ˇz =(xu，yi)由Xu和yi连接而成。为了模拟z中所有嵌套变量的相互作用，因子分解机(FM)被引入作为相应等级的估计器。下面的等式是给定一批N个训练示例t的成本。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div class="gh gi na"><img src="../Images/bfc14565b097ffeb043663dc0233b689.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*hXVMvOzV2GRWyH4eZ3RtEA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">等式:批量的成本函数</p></figure><p id="c092" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ˇw0:全局偏差<br/>ˇwi:模拟z中第I个变量的强度</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/60c1408d733d6255c229eba834db29c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:186/format:webp/1*8OFQzHjglVqdZSGiXEoDpw.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">模拟二阶相互作用</p></figure><h1 id="a527" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">网络培训</h1><p id="27d8" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">目标是最小化上面指定的成本函数，并且相对于z检索导数J。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/50e5af8921fd3cb527ecb65779e20eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*PUhENC59epwcz6N7e5jYRg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">等式:成本函数的导数</p></figure><p id="11da" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过应用链式法则，可以计算不同层中其他参数的导数。利用N元组的训练集T，通过RMSprop对混洗小批量进行优化。RMSprop是为梯度更新方法引入的，它根据梯度的绝对值自适应地管理步长。当RMSprop计算梯度范数的平均值时，权重将被更新。下图显示了网络参数集θ的更新规则。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/88ec95c930934cb76f79a641322e7ec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*NZFO4zmZHgJACzETBKhQBg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">等式:RMSprop优化函数</p></figure><p id="dd83" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">λ:学习率<br/> ε:数值稳定性的小附加值</p><p id="4525" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，在两个网络的完全连接层之上应用了脱落层，以防止过度拟合。</p><h1 id="0881" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">DeepCoNN分析</h1><h2 id="6e98" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">词序保持</h2><p id="6c42" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">常见的是，推荐系统在用户评论上应用主题建模来建模用户或项目。潜在的主题变量使用单词袋技术，忽略了单词的顺序。然而，对于文本建模应用程序来说，考虑单词的顺序是至关重要的。DeepCoNN与单词嵌入一起应用，以创建单词嵌入，同时保持单词的顺序，但不使用主题建模方法。因此，卷积层提供了一种在文本建模中表征单词顺序的技术。</p><h2 id="a341" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">在线学习</h2><p id="ffe6" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">许多推荐系统注意到可伸缩性和处理项目的动态池。对于推荐系统来说，时间敏感性是在线学习潜在因素的一个具有挑战性的任务。DeepCoNN可根据训练数据的数据可伸缩性进行调整，并且该模型可以灵活地用神经网络中的新数据进行训练和更新。从历史数据中更新项目或用户的潜在因素是独立的。主题建模不包括考虑时间因素和数据更新。</p><h2 id="b705" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">基线模型</h2><p id="267a" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">矩阵分解(MF)和概率矩阵分解(PMF)被应用于推荐系统中的评论数据集。此外，大多数推荐系统使用主题建模来支持用户评论。为了比较推荐系统和主题建模，选择了4种深度学习模型:潜在狄利克雷分配模型(LDA)、协同主题回归模型(CTR)、主题隐藏因子模型(HFT)和深度推荐系统。推荐系统将引入最新的深度推荐系统——协同深度学习(CDL)。为了改进模型预测，除了MF和PMF以外，所有基线都在模型中加入了审查信息。在所有的协同过滤方法中，MF是最流行的一种。输入数据集是评级矩阵，MF将估计两个低秩矩阵来预测评级。交替最小二乘(ALS)技术用于最小化目标函数。</p><p id="f238" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">PMF:该模型应用了用户和项目潜在因素的高斯分布。</p><p id="6560" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">LDA:潜在狄利克雷分配是一种流行的主题建模算法。它用于从每个项目的一组评论中学习主题分布。为每个项目的潜在特征提取学习的主题分布。为了优化评分预测精度，通过梯度下降更新每个用户的潜在特征。</p><p id="069b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CTR:协作主题回归也被应用，并在用户感兴趣或不感兴趣的单类协作过滤问题上表现良好。</p><p id="864b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">HFT:隐藏因素作为主题被应用于主题分布，以从用户或项目评论中提取潜在因素。在实验中，基于项目的主题分发比用户主题分发具有更好的性能。</p><p id="92e5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CDL:协作深度学习的特点是堆叠去噪自动编码器和PMF的贝叶斯公式。自动编码器和PMF与自动编码器的中间层相连。</p><h1 id="cd0b" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">python代码的实践经验</h1><h1 id="348b" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">数据描述:</h1><p id="c24b" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">数据是从Amazon review数据集中提取的，带有杂志订阅的子类别。<a class="ae kf" href="http://deepyeti.ucsd.edu/jianmo/amazon/index.html" rel="noopener ugc nofollow" target="_blank">将</a>链接到数据源。数据集中有各种列，如评论(评级、文本、有用性投票)、产品元数据(描述、类别信息、价格、品牌和图像特征)和链接(也查看过/也购买过的图表)。</p><h1 id="c0a8" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">DeepCoNN建模</h1><p id="b7dc" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">对于建模方法，DeepConn模型是卷积神经网络模型，它在Pytorch模型中实现。此外，模型的优化是adam优化器，损失度量是通过MSE评估的。</p><h1 id="6610" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">数据预处理</h1><p id="408d" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">从Magazine_Subscriptions.json，我们在评论数据集上实现了一些预处理步骤，如过滤标点符号，保留单词和字符，排除nan和null值，以及过滤长度大于1的单词。在数据集中，有用户多次对相同的产品留下评论。输入数据集也被从相同的userid和itemid的重复行中排除，因此模型将具有相同的所有条目和用户的评论数据的输入长度。</p><figure class="mu mv mw mx gt ju"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h2 id="f2d0" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">添加用户和项目功能</h2><p id="4294" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">在user_reviews表中，索引被设置为userID和productID以及用户评论的列。另一个表是movie_reviews表，索引设置为userID和productID以及电影评论列。数据集还添加了两个附加功能，一个是用户评论列，另一个是电影评论列。</p><figure class="mu mv mw mx gt ju"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h2 id="301a" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">单词嵌入</h2><figure class="mu mv mw mx gt ju"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="35c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">单词嵌入是手套嵌入的输入，每个单词的向量大小为200。手套嵌入是一种无监督的学习方法，通过单词的共现来分组单词，以生成单词向量。相似性度量是通过两个单词向量之间的欧几里德距离(或余弦相似性)来计算的。相似的单词放在附近，而没有相似语义的单词放在更远的地方。对于用户和项目的评论数据集，用手套嵌入和pad值向量输入单词。用户和项目的评论用相同大小的向量填充。</p><figure class="mu mv mw mx gt ju"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h2 id="a3f8" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">DeepConn型号:</h2><p id="0b42" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">对于模型输入，输入的数据结构的嵌入大小为200，用户序列长度为61，项目序列长度为45。有两个独立的数据输入，一个是具有(1910，6，200)的3d形状的项目评论输入矩阵，另一个是具有(1910，20，200)的3d形状的用户评论输入矩阵。标签是评级栏。该模型根据80%的输入数据进行训练，并根据20%的验证数据进行测试。</p><p id="f6e6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">DeepConn模型有1个卷积层，内核大小为3，滤波器大小为2。下一层是max-pooling层的输入，以从每个内核中提取最大值作为特征。然后，将特征展平并转发到密集层进行模型预测。最后一层结合了来自项目评审和用户评审矩阵的输入。将组合的特征带入模型，模型将特征和输入连接到最后的密集层。优化函数是Adam，损失函数是模型评估指标的均方误差。</p><figure class="mu mv mw mx gt ju"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h2 id="f689" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">评估图:</h2><p id="9c6e" class="pw-post-body-paragraph kg kh it ki b kj lx kl km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">该模型在100个时期上用80%的训练数据分割进行训练，并在20%的测试数据集上进行测试。训练损失在0.1514左右持续下降，测试损失达到2.6左右。测试损耗在60个周期后变得稳定。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/281ccaf1b0b56b72d426cf15818b9139.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*RJa5VLJ_JW7puraap0vYIw.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:训练和测试数据集的损失性能</p></figure><h2 id="c43b" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">最后</h2><ul class=""><li id="317b" class="nh ni it ki b kj lx kn ly kr nj kv nk kz nl ld nm nn no np bi translated">评论数据集的特点是通过一个映射函数将单词字典转换成n维分布向量，从而实现单词的嵌入。单词嵌入是手套嵌入的输入，手套嵌入是一种无监督的学习方法，通过单词的共现来分组单词以生成单词向量。</li><li id="9836" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">CNN模型包括卷积层、最大池和全连接层。卷积层中有m个神经元，它们通过对单词向量应用卷积算子来产生新的特征。max-pooling图层从要素地图中提取最高值作为最重要的要素。汇集层可以应用于不同的文本长度。在最大汇集操作之后，卷积结果被转换成固定大小的向量。</li><li id="885e" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">作为特征的项目和用户的输出在不同的特征空间中，并且不可比较。共享层被引入到Netu和Neti之上，以在特征空间中映射它们。单个向量ˇz =(xu，yi)由Xu和yi连接而成。为了对z中的所有嵌套变量交互进行建模，因子分解机(FM)被引入作为相应评级的估计器，它将两个评论的特征连接起来，并在其上对下一个密集层应用点函数。</li></ul><h2 id="a318" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">模型优势</h2><ul class=""><li id="e1cc" class="nh ni it ki b kj lx kn ly kr nj kv nk kz nl ld nm nn no np bi translated">深度合作神经网络(DeepCoNN)是一种使用文本评论对用户行为和项目属性进行建模的方法。存在从共享层连接的两个并行网络，使得用户和项目表示的交互可以预测评级。</li><li id="e6f9" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">评论由Glove转化为词嵌入，以语义和评论情感为特征。DeepCoNN可以通过利用评论来缓解稀疏性问题。</li></ul><blockquote class="nv"><p id="f594" class="nw nx it bd ny nz oa ob oc od oe ld dk translated">这是推荐系统主题的结尾</p></blockquote><figure class="og oh oi oj ok ju gh gi paragraph-image"><div class="gh gi of"><img src="../Images/5535c03f020eb1f395464cc255e2f180.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*1qHg4FtFMZdt6NGAaRlb1g.jpeg"/></div></figure><h1 id="5fe0" class="mc lf it bd lg md me mf lj mg mh mi lm mj mk ml lp mm mn mo ls mp mq mr lv ms bi translated">参考</h1><ul class=""><li id="9da1" class="nh ni it ki b kj lx kn ly kr nj kv nk kz nl ld nm nn no np bi translated">使用评论对用户和项目进行联合深度建模<br/><a class="ae kf" href="https://dl.acm.org/doi/pdf/10.1145/3018661.3018665" rel="noopener ugc nofollow" target="_blank">https://dl.acm.org/doi/pdf/10.1145/3018661.3018665</a></li><li id="e093" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">使用用于推荐的评论对用户和项目进行联合深度建模Github知识库<br/>【https://github.com/richdewey/DeepCoNN T4】</li><li id="039f" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">手套嵌入<br/><a class="ae kf" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">https://nlp.stanford.edu/projects/glove/</a></li></ul></div></div>    
</body>
</html>