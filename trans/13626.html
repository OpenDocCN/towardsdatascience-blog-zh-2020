<html>
<head>
<title>ML Programming Hacks that every Data Engineer should know — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每个数据工程师都应该知道的ML编程技巧——第2部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ml-programming-hacks-that-every-data-engineer-should-know-part-2-61c0df0f215c?source=collection_archive---------44-----------------------#2020-09-18">https://towardsdatascience.com/ml-programming-hacks-that-every-data-engineer-should-know-part-2-61c0df0f215c?source=collection_archive---------44-----------------------#2020-09-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="41aa" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">现实世界中的DS</h2><div class=""/><div class=""><h2 id="2ece" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">数据科学家和机器学习从业者的更广泛的备忘单。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/9326e47df4377f1435b0fd08b1053010.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bdlpu4F-IRPP3mOW"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@bermixstudio?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Bermix工作室</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><h2 id="105f" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">这篇文章是下述文章的续篇。</h2><div class="md me gp gr mf mg"><a rel="noopener follow" target="_blank" href="/programming-hacks-that-every-data-engineer-should-know-part-1-fb7cd436c40"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd jd gy z fp ml fr fs mm fu fw jc bi translated">每个数据工程师都应该知道的ML编程技巧——第1部分</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">数据科学家和机器学习从业者的更广泛的备忘单。</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">towardsdatascience.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu lb mg"/></div></div></a></div><p id="76f4" class="pw-post-body-paragraph mv mw it mx b my mz kd na nb nc kg nd lr ne nf ng lv nh ni nj lz nk nl nm nn im bi translated">在上面的帖子中，我提出了一些重要的编程要点，在执行机器学习实践时要知道并牢记在心，以使您的实现更快更有效。接下来我们会看到更多这样的黑客。让我们开始吧。</p><h1 id="b2d5" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">11.操作宽长数据帧:</h1><p id="b61c" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">转换宽到长数据和长到宽数据最有效的方法分别是pandas.melt()和pandas.pivot_table()函数。除了这些函数之外，您不需要其他任何东西来将长而宽的数据相互转换。</p><h2 id="8897" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">a.宽到长(融化)</h2><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="980b" class="li lj it of b gy oj ok l ol om">&gt;&gt;&gt; import pandas as pd<br/># create wide dataframe<br/>&gt;&gt;&gt; df_wide = pd.DataFrame(<br/>...    {"student": ["Andy", "Bernie", "Cindy", "Deb"],<br/>...     "school":  ["Z", "Y", "Z", "Y"],<br/>...     "english": [66, 98, 61, 67],  # eng grades<br/>...     "math":    [87, 48, 88, 47],  # math grades<br/>...     "physics": [50, 30, 59, 54]   # physics grades<br/>...    }<br/>...  )<br/>&gt;&gt;&gt; df_wide<br/>  student school  english  math  physics<br/>0    Andy      Z       66    87       50<br/>1  Bernie      Y       98    48       30<br/>2   Cindy      Z       61    88       59<br/>3     Deb      Y       67    47       54<br/><strong class="of jd">&gt;&gt;&gt; df_wide.melt(id_vars=["student", "school"],<br/>...               var_name="subject",  # rename<br/>...               value_name="score")  # rename</strong><br/>   student school  subject  score<br/>0     Andy      Z  english     66<br/>1   Bernie      Y  english     98<br/>2    Cindy      Z  english     61<br/>3      Deb      Y  english     67<br/>4     Andy      Z     math     87<br/>5   Bernie      Y     math     48<br/>6    Cindy      Z     math     88<br/>7      Deb      Y     math     47<br/>8     Andy      Z  physics     50<br/>9   Bernie      Y  physics     30<br/>10   Cindy      Z  physics     59<br/>11     Deb      Y  physics     54</span></pre><h2 id="5c1e" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">b.长到宽(数据透视表)</h2><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="3224" class="li lj it of b gy oj ok l ol om">&gt;&gt;&gt; import pandas as pd<br/># create long dataframe<br/>&gt;&gt;&gt; df_long = pd.DataFrame({<br/>...         "student":<br/>...             ["Andy", "Bernie", "Cindy", "Deb",<br/>...              "Andy", "Bernie", "Cindy", "Deb",<br/>...              "Andy", "Bernie", "Cindy", "Deb"],<br/>...         "school":<br/>...             ["Z", "Y", "Z", "Y",<br/>...              "Z", "Y", "Z", "Y",<br/>...              "Z", "Y", "Z", "Y"],<br/>...         "class":<br/>...             ["english", "english", "english", "english",<br/>...              "math", "math", "math", "math",<br/>...              "physics", "physics", "physics", "physics"],<br/>...         "grade":<br/>...             [66, 98, 61, 67,<br/>...              87, 48, 88, 47,<br/>...              50, 30, 59, 54]<br/>... })<br/>&gt;&gt;&gt; df_long<br/>   student school    class  grade<br/>0     Andy      Z  english     66<br/>1   Bernie      Y  english     98<br/>2    Cindy      Z  english     61<br/>3      Deb      Y  english     67<br/>4     Andy      Z     math     87<br/>5   Bernie      Y     math     48<br/>6    Cindy      Z     math     88<br/>7      Deb      Y     math     47<br/>8     Andy      Z  physics     50<br/>9   Bernie      Y  physics     30<br/>10   Cindy      Z  physics     59<br/>11     Deb      Y  physics     54<br/><strong class="of jd">&gt;&gt;&gt; df_long.pivot_table(index=["student", "school"], <br/>...                     columns='class', <br/>...                     values='grade')</strong><br/>class           english  math  physics<br/>student school                        <br/>Andy    Z            66    87       50<br/>Bernie  Y            98    48       30<br/>Cindy   Z            61    88       59<br/>Deb     Y            67    47       54</span></pre><h1 id="b0b8" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">12.交叉制表:</h1><p id="5e9c" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">当您需要总结数据时，交叉制表在汇总两个或更多因素并计算值的频率表中起着重要作用。它可以用pandas.crosstab()函数来实现，该函数还允许在使用“normalize”参数打印输出时找到归一化的值。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="2747" class="li lj it of b gy oj ok l ol om">&gt;&gt;&gt; import numpy as np<br/>&gt;&gt;&gt; import pandas as pd<br/>&gt;&gt;&gt; p = np.array(["s1", "s1", "s1", "s1", "b1", "b1",<br/>...               "b1", "b1", "s1", "s1", "s1"], dtype=object)<br/>&gt;&gt;&gt; q = np.array(["one", "one", "one", "two", "one", "one",<br/>...               "one", "two", "two", "two", "one"], dtype=object)<br/>&gt;&gt;&gt; r = np.array(["x", "x", "y", "x", "x", "y",<br/>...               "y", "x", "y", "y", "y"], dtype=object)<br/><strong class="of jd">&gt;&gt;&gt; pd.crosstab(p, [q, r], rownames=['p'], colnames=['q', 'r'])</strong><br/>q  one    two   <br/>r    x  y   x  y<br/>p               <br/>b1   1  2   1  0<br/>s1   2  2   1  2</span><span id="d8c1" class="li lj it of b gy on ok l ol om"># get normalized output values<br/><strong class="of jd">&gt;&gt;&gt; pd.crosstab(p, [q, r], rownames=['p'], colnames=['q', 'r'], normalize=True)</strong><br/>q        one                 two          <br/>r          x         y         x         y<br/>p                                         <br/>b1  0.090909  0.181818  0.090909  0.000000<br/>s1  0.181818  0.181818  0.090909  0.181818</span></pre><h1 id="6604" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">13.Jupyter主题:</h1><p id="754f" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">Python中最好的库之一是jupyterthemes，它允许您更改和控制大多数ML从业者使用的笔记本视图的样式。不同的主题，如黑暗模式、光明模式等。或者定制样式是大多数程序员的首选，它可以在Jupyter笔记本中使用jupyterthemes库来实现。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/19bab40920c8e3bf3187544d949381a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zThx9mx0Drk9eIxMhF-0Cw.png"/></div></div></figure><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="3e09" class="li lj it of b gy oj ok l ol om"># pip install<br/>$ pip install jupyterthemes</span><span id="df9c" class="li lj it of b gy on ok l ol om"># conda install<br/>$ conda install -c conda-forge jupyterthemes</span><span id="e1d4" class="li lj it of b gy on ok l ol om"># list available themes<br/>$ jt -l<br/>Available Themes:<br/>   chesterish<br/>   grade3<br/>   gruvboxd<br/>   gruvboxl<br/>   monokai<br/>   oceans16<br/>   onedork<br/>   solarizedd<br/>   solarizedl</span><span id="b24b" class="li lj it of b gy on ok l ol om"># apply the theme<br/>jt -t chesterish</span><span id="6ac4" class="li lj it of b gy on ok l ol om"># reverse the theme<br/>!jt -r</span></pre><p id="cb9d" class="pw-post-body-paragraph mv mw it mx b my mz kd na nb nc kg nd lr ne nf ng lv nh ni nj lz nk nl nm nn im bi translated">你可以在https://github.com/dunovank/jupyter-themes的Github <a class="ae lh" href="https://github.com/dunovank/jupyter-themes" rel="noopener ugc nofollow" target="_blank">上找到更多相关信息。</a></p><h1 id="ad5d" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">14.将分类变量转换为虚拟变量:</h1><p id="c2b0" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">使用pandas.get_dummies()函数，您可以直接将DataFrame中的分类特征转换为虚拟变量，并使用drop_first=True删除第一个冗余列。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="11ad" class="li lj it of b gy oj ok l ol om">&gt;&gt;&gt; import pandas as pd<br/>&gt;&gt;&gt; df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],<br/>...                     'C': [1, 2, 3]})</span><span id="9c76" class="li lj it of b gy on ok l ol om">&gt;&gt;&gt; df<br/>   A  B  C<br/>0  a  b  1<br/>1  b  a  2<br/>2  a  c  3</span><span id="c31e" class="li lj it of b gy on ok l ol om"><strong class="of jd">&gt;&gt;&gt; pd.get_dummies(df[['A','B']])</strong><br/>   A_a  A_b  B_a  B_b  B_c<br/>0    1    0    0    1    0<br/>1    0    1    1    0    0<br/>2    1    0    0    0    1</span><span id="43b1" class="li lj it of b gy on ok l ol om"><strong class="of jd">&gt;&gt;&gt; dummy = pd.get_dummies(df[['A','B']], drop_first=True)<br/>&gt;&gt;&gt; dummy</strong><br/>   A_b  B_b  B_c<br/>0    0    1    0<br/>1    1    0    0<br/>2    0    0    1</span><span id="bef0" class="li lj it of b gy on ok l ol om"># concat dummy features to existing df<strong class="of jd"><br/>&gt;&gt;&gt; df = pd.concat([df, dummy], axis=1)<br/></strong>&gt;&gt;&gt; df<br/>   A  B  C  A_b  B_b  B_c<br/>0  a  b  1    0    1    0<br/>1  b  a  2    1    0    0<br/>2  a  c  3    0    0    1</span></pre><h1 id="8448" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">15.转换成数字:</h1><p id="ed5d" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">在将数据集加载到pandas中时，有时数值列被作为对象类型，并且不能在其上执行数值操作。为了将它们转换成数字，我们可以使用pandas.to_numeric()函数并更新现有的系列或DataFrame中的列。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="acbb" class="li lj it of b gy oj ok l ol om">&gt;&gt;&gt; import pandas as pd<br/>&gt;&gt;&gt; s = pd.Series(['1.0', '2', -3, '12', 5])<br/>&gt;&gt;&gt; s<br/>0    1.0<br/>1      2<br/>2     -3<br/>3     12<br/>4      5<br/>dtype: object</span><span id="af11" class="li lj it of b gy on ok l ol om"><strong class="of jd">&gt;&gt;&gt; pd.to_numeric(s)</strong><br/>0     1.0<br/>1     2.0<br/>2    -3.0<br/>3    12.0<br/>4     5.0<br/><strong class="of jd">dtype: float64</strong></span><span id="5766" class="li lj it of b gy on ok l ol om"><strong class="of jd">&gt;&gt;&gt; pd.to_numeric(s, downcast='signed')</strong><br/>0     1<br/>1     2<br/>2    -3<br/>3    12<br/>4     5<br/><strong class="of jd">dtype: int8</strong></span></pre><h1 id="454d" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">16.分层取样/分割:</h1><p id="ddb1" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">当分割数据集时，我们有时需要在数据分割中获得样本总体。当数据集中的类不够平衡时，它会更有效。<code class="fe op oq or of b"><a class="ae lh" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection" rel="noopener ugc nofollow" target="_blank"><strong class="mx jd">sklearn.model_selection</strong></a></code>在<strong class="mx jd">。train_test_split() </strong>函数中，名为“分层”的参数可与目标类特征一起设置，以正确分割不同类的数据，其比率与未分割数据集中的比率相同。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="5c54" class="li lj it of b gy oj ok l ol om">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = <strong class="of jd">train_test_split</strong>(X, y,<br/>                                                    <strong class="of jd">stratify=y</strong>, <br/>                                                    test_size=0.25)</span></pre><h1 id="3038" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">17.按类型选择要素:</h1><p id="aadb" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">在大多数数据集中，我们有两种类型的列，即数值型和非数值型。我们经常需要只提取数据集中的数字列或分类列，并对其执行一些可视化功能或自定义操作。在pandas库中，我们有<strong class="mx jd">data frame . select _ dtypes()</strong>函数，它从给定的数据集中选择与指定数据类型匹配的特定列。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="ca0d" class="li lj it of b gy oj ok l ol om">&gt;&gt;&gt; import pandas as pd<br/>&gt;&gt;&gt; df = pd.DataFrame({'a': [1, 2] * 3,<br/>...                     'b': [True, False] * 3,<br/>...                     'c': [1.0, 2.0] * 3})<br/>&gt;&gt;&gt; df<br/>   a      b    c<br/>0  1   True  1.0<br/>1  2  False  2.0<br/>2  1   True  1.0<br/>3  2  False  2.0<br/>4  1   True  1.0<br/>5  2  False  2.0</span><span id="687a" class="li lj it of b gy on ok l ol om"><strong class="of jd">&gt;&gt;&gt; df.select_dtypes(include='bool')</strong><br/>       b<br/>0   True<br/>1  False<br/>2   True<br/>3  False<br/>4   True<br/>5  False</span><span id="b8a6" class="li lj it of b gy on ok l ol om"><strong class="of jd">&gt;&gt;&gt; df.select_dtypes(include=['float64'])</strong><br/>     c<br/>0  1.0<br/>1  2.0<br/>2  1.0<br/>3  2.0<br/>4  1.0<br/>5  2.0</span><span id="41c8" class="li lj it of b gy on ok l ol om"><strong class="of jd">&gt;&gt;&gt; df.select_dtypes(exclude=['int64'])</strong><br/>       b    c<br/>0   True  1.0<br/>1  False  2.0<br/>2   True  1.0<br/>3  False  2.0<br/>4   True  1.0<br/>5  False  2.0</span></pre><h1 id="c0af" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">18.随机搜索CV:</h1><p id="a321" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">RandomizedSearchCV是来自<code class="fe op oq or of b"><a class="ae lh" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection" rel="noopener ugc nofollow" target="_blank">sklearn.model_selection</a></code>类的一个函数，用于确定上述学习算法的随机超参数集，它为每个提供的超参数随机选择不同的值，以对每个选择的值进行调整和应用交叉验证，并使用搜索时提供的不同评分机制确定其中的最佳值。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="0fcf" class="li lj it of b gy oj ok l ol om">&gt;&gt;&gt; from sklearn.datasets import load_iris<br/>&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression<br/>&gt;&gt;&gt; from sklearn.model_selection import RandomizedSearchCV<br/>&gt;&gt;&gt; from scipy.stats import uniform<br/>&gt;&gt;&gt; iris = load_iris()<br/>&gt;&gt;&gt; logistic = LogisticRegression(solver='saga', tol=1e-2, <br/>...                               max_iter=300,random_state=12)<br/>&gt;&gt;&gt; distributions = dict(C=uniform(loc=0, scale=4),<br/>...                      penalty=['l2', 'l1'])</span><span id="821d" class="li lj it of b gy on ok l ol om"><strong class="of jd">&gt;&gt;&gt; clf = RandomizedSearchCV(logistic, distributions, random_state=0)<br/></strong>&gt;&gt;&gt; search = clf.fit(iris.data, iris.target)</span><span id="e417" class="li lj it of b gy on ok l ol om"><strong class="of jd">&gt;&gt;&gt; search.best_params_</strong><br/>{'C': 2..., 'penalty': 'l1'}</span></pre><h1 id="e9b2" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">19.神奇功能—%历史记录:</h1><p id="f5c9" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">笔记本中的一批先前运行的命令可以使用“%history”神奇功能来访问。这将提供所有以前执行的命令，并且可以提供自定义选项来选择特定的历史命令，您可以使用“%history？”来检查这些命令在朱庇特笔记本里。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="ffe3" class="li lj it of b gy oj ok l ol om">In [1]: import math<br/><br/>In [2]: math.sin(2)<br/>Out[2]: 0.9092974268256817<br/><br/>In [3]: math.cos(2)<br/>Out[3]: -0.4161468365471424</span><span id="fcc8" class="li lj it of b gy on ok l ol om">In [16]: %<strong class="of jd">history</strong> -n 1-3<br/>   1: import math<br/>   2: math.sin(2)<br/>   3: math.cos(2)</span></pre><h1 id="03a2" class="no lj it bd lk np nq nr ln ns nt nu lq ki nv kj lu kl nw km ly ko nx kp mc ny bi translated">20.下划线快捷键(_):</h1><p id="d154" class="pw-post-body-paragraph mv mw it mx b my nz kd na nb oa kg nd lr ob nf ng lv oc ni nj lz od nl nm nn im bi translated">在python中，可以使用带下划线的print(_)函数直接打印解释器最后发送的输出。这可能没什么帮助，但是在IPython (jupyter notebook)中，这个特性已经被扩展了，您可以在print()函数中使用n个下划线来打印任何n个最后的输出。例如，带有两个下划线的print(__)将给出倒数第二个输出，跳过所有没有输出的命令。</p><p id="1918" class="pw-post-body-paragraph mv mw it mx b my mz kd na nb nc kg nd lr ne nf ng lv nh ni nj lz nk nl nm nn im bi translated">另外，另一个是下划线，后跟行号，打印相关的输出。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="8773" class="li lj it of b gy oj ok l ol om">In [1]: <strong class="of jd">import</strong> <strong class="of jd">math</strong><br/><br/>In [2]: math.sin(2)<br/>Out[2]: 0.9092974268256817<br/><br/>In [3]: math.cos(2)<br/>Out[3]: -0.4161468365471424</span><span id="78dd" class="li lj it of b gy on ok l ol om">In [4]: <strong class="of jd">print</strong>(_)<br/>-0.4161468365471424<br/><br/>In [5]: <strong class="of jd">print</strong>(__)<br/>0.9092974268256817</span><span id="f337" class="li lj it of b gy on ok l ol om"><strong class="of jd">In [6]: _2</strong><br/>Out[13]: 0.9092974268256817</span></pre><p id="879a" class="pw-post-body-paragraph mv mw it mx b my mz kd na nb nc kg nd lr ne nf ng lv nh ni nj lz nk nl nm nn im bi translated">目前就这些。在接下来的几个部分中，我将介绍更多这些每个数据工程师都应该了解的重要技巧/功能。</p><p id="fe93" class="pw-post-body-paragraph mv mw it mx b my mz kd na nb nc kg nd lr ne nf ng lv nh ni nj lz nk nl nm nn im bi translated">敬请关注。</p><div class="md me gp gr mf mg"><a rel="noopener follow" target="_blank" href="/what-makes-logistic-regression-a-classification-algorithm-35018497b63f"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd jd gy z fp ml fr fs mm fu fw jc bi translated">是什么让逻辑回归成为一种分类算法？</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">对数优势，基线的逻辑回归解释。</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">towardsdatascience.com</p></div></div><div class="mp l"><div class="os l mr ms mt mp mu lb mg"/></div></div></a></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/620adcd7d762b082d905f71372da6102.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*039qi-FKqsrRpj6_"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">豪伊·R在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="7cb8" class="pw-post-body-paragraph mv mw it mx b my mz kd na nb nc kg nd lr ne nf ng lv nh ni nj lz nk nl nm nn im bi translated">感谢阅读。你可以在这里找到我的其他<a class="ae lh" href="https://towardsdatascience.com/@imsparsh" rel="noopener" target="_blank">机器学习相关的帖子</a>。</p><p id="0365" class="pw-post-body-paragraph mv mw it mx b my mz kd na nb nc kg nd lr ne nf ng lv nh ni nj lz nk nl nm nn im bi translated">希望这篇帖子有用。我感谢反馈和建设性的批评。如果你想谈论这篇文章或其他相关话题，你可以在这里或在<a class="ae lh" href="https://www.linkedin.com/in/imsparsh/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>给我发短信。</p><div class="md me gp gr mf mg"><a rel="noopener follow" target="_blank" href="/assumptions-in-linear-regression-528bb7b0495d"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd jd gy z fp ml fr fs mm fu fw jc bi translated">线性回归中的假设你可能不知道。</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">模型应该符合这些假设，以产生与数据的最佳线性回归拟合。</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">towardsdatascience.com</p></div></div><div class="mp l"><div class="ou l mr ms mt mp mu lb mg"/></div></div></a></div></div></div>    
</body>
</html>