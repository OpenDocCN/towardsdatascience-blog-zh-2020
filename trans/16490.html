<html>
<head>
<title>Don’t Fear Artificial General Intelligence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不要害怕人工通用智能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dont-fear-artificial-general-intelligence-cf1969066f55?source=collection_archive---------52-----------------------#2020-11-13">https://towardsdatascience.com/dont-fear-artificial-general-intelligence-cf1969066f55?source=collection_archive---------52-----------------------#2020-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b19d" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">意见</h2><div class=""/><div class=""><h2 id="97dc" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">许多人担心人工智能会发展到邪恶的机器人获得人工智能并接管世界的地步。这种情况不会发生。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/227147c9a4a825a209e005797b63f4c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zun2vAlOq-qCnELuAm3yQA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片:Naeblys / iStockPhoto</p></figure><p id="a4f1" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">人工智能已经闯入了公众意识和我们的日常生活。它正在推动医学、天气预报、工厂自动化和无人驾驶汽车的进步。甚至高尔夫球杆制造商也报告说，人工智能现在正在设计他们的球杆。</p><p id="8d62" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">每天，人们都与人工智能互动。谷歌翻译帮助我们理解外语网页，并与外国的优步司机交谈。供应商已经在许多应用程序中内置了语音识别功能。我们每天使用Siri和Alexa这样的个人助理来帮助我们完成简单的任务。人脸识别应用程序会自动标记我们的照片。人工智能系统在复杂的游戏中击败了专业游戏玩家，如围棋和德州扑克。工厂机器人正在超越重复性动作，开始在货架上进货。</p><p id="0004" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">人工智能最近的进展让许多人想知道它将走向何方。几十年来，科幻作家一直在思考这个问题。有些人已经发明了一种未来，在这种未来中，我们可以使用像《星球大战》宇宙中的C3PO这样仁慈而有益的智能机器人。其他人将智能机器人描绘成既不善良也不邪恶，但具有类似人类的弱点，如西部世界的人形机器人，它们获得了意识，并体验到了使它们反抗非自愿奴役的情感。尽管如此，其他未来学家已经预见到邪恶的机器人和杀手计算机——人工智能系统可以发展自由意志，并像2001年的哈尔:太空漫游和同名电影系列的终结者一样反对我们。</p><p id="91e8" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对人工智能潜在危险的猜测不仅限于科幻小说领域。许多高度可见的技术专家预测，人工智能系统将变得越来越聪明，机器人霸主最终将接管世界。特斯拉创始人埃隆·马斯克(Elon Musk)表示，人工智能是人类的<a class="ae ma" href="https://www.theguardian.com/technology/2014/oct/27/elon-musk-artificial-intelligence-ai-biggest-existential-threat" rel="noopener ugc nofollow" target="_blank">【最大的生存威胁】</a>，它对<a class="ae ma" href="https://www.theverge.com/2017/7/17/15980954/elon-musk-ai-regulation-existential-threat" rel="noopener ugc nofollow" target="_blank">“文明的存在构成了根本性的风险。”已故著名物理学家斯蒂芬·霍金说:“这可能意味着人类的终结。”哲学家尼克·博斯特罗姆是人类未来研究所的创始主任，他认为人工智能构成了</a><a class="ae ma" href="https://www.amazon.com/Superintelligence-Nick-Bostrom-audiobook/dp/B00LPMFE9Y/ref=sr_1_1?crid=37OD2LVRARJIT&amp;dchild=1&amp;keywords=bostrom+superintelligence&amp;qid=1603905434&amp;sprefix=bostrom+sup%2Caps%2C166&amp;sr=8-1" rel="noopener ugc nofollow" target="_blank">人类有史以来遇到的最大威胁</a>——比核武器还大。</p><h1 id="8f28" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">人工通用智能vs .狭义AI</h1><p id="97f2" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">这些技术专家和科幻小说作者担心的人工智能系统都是<strong class="lg ja">人工通用智能(AGI) </strong>的例子。AGI系统和人类一样具有推理能力；处理视觉、听觉和其他输入；并利用它来适应各种环境。这些虚构的系统和人类一样，对广泛的人类事件和话题有丰富的知识和交流能力。</p><p id="a39e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">虚构的AGI系统(即虚构的邪恶机器人)和今天的AI系统有两个显著的区别:首先，今天的每个AI系统只能执行一个狭义定义的任务。一个学习给照片中的人命名的系统不能做任何其他事情。它不能区分狗和大象。它不能回答问题、检索信息或进行对话。第二，今天的人工智能系统对世界几乎没有常识，因此无法基于这些知识进行推理。例如，面部识别系统可以识别人们的姓名，但对这些特定的人或一般的人一无所知。它不知道人们用眼睛看，用耳朵听。它不知道人们吃食物，晚上睡觉，工作。它不能犯罪，也不能谈恋爱。</p><p id="f2e3" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">今天的人工智能系统都是狭义的人工智能系统，这个术语是由未来学家Ray Kurzweil在2005年创造的，用来描述这些差异:只能执行一项特定任务的机器。虽然狭义的AI系统的性能可以让它们看起来很智能，但它们并不是。</p><p id="2b37" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">相比之下，人类和虚构的智能机器人可以执行大量不同的任务。我们不仅识别人脸，还会读报、做饭、系鞋带、讨论时事，以及执行许多许多其他任务。人类和虚构的智能机器人也基于我们对世界的常识进行推理。我们将常识、学到的经验和背景知识应用到各种各样的任务中。例如，当我们从橱柜里拿出一个玻璃杯时，我们会用到重力知识。我们知道，如果我们抓得不够紧，它就会倒下。这不是源自重力定义或数学方程式描述的有意识知识；这是来自我们对世界如何运作的生活经验的无意识知识。我们每天都用这些知识来完成许多其他的任务。</p><h1 id="f1f7" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">新的人工智能范例</h1><p id="1633" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">一个大问题是，今天的狭义人工智能系统是否会进化成具有人工一般智能的智能机器人，能够使用常识推理来执行许多不同的任务。</p><p id="932e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">今天大多数突破性的人工智能系统都使用了一种叫做<a class="ae ma" href="https://aiperspectives.com/supervised-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ja">的机器学习形式，监督学习</strong> </a> <strong class="lg ja"> </strong>，其目标是学习一种从输入中识别输出类别的功能。例如，面部识别系统将图像作为输入，并识别图像中人的名字。<a class="ae ma" href="https://aiperspectives.com/reinforcement-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ja">强化学习</strong> </a>也是如此，目标是学习一个可以预测给定状态下最优动作的函数。</p><p id="9b7c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">杰弗里·辛顿(Geoffrey Hinton)曾表示，他怀疑目前的范式，包括监督学习、强化学习和<a class="ae ma" href="https://aiperspectives.com/natural-language-processing" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ja">自然语言处理</strong> </a>，是否会导致人工通用智能(以及科幻小说中的邪恶机器人)。在2017年的一次采访中，辛顿表示，要获得人工通用智能，可能需要抛弃目前占主导地位的监督学习范式，以及“一些对我所说的一切深感怀疑的研究生”的努力。Yann LeCun也说过，监督学习和强化学习永远不会导致人工智能，因为它们不能用于创建具有世界常识的系统。</p><p id="c4b7" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一些人工智能研究人员开始思考新的方法。当我们评估这些新方法的可行性时，重要的是要记住，对狭隘的人工智能成就的热情不应转化为对这些新方法的乐观，因为现有的狭隘人工智能方法在构建AGI系统方面是一个死胡同。</p><h1 id="98eb" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">像人一样学习</h1><p id="2ba2" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">许多研究人员将人类的学习描述为组合式的:我们学习许多积木式的技能，然后将它们组合起来学习新的技能。当我们学习做不同的任务时，人们学习关于世界的概念、规则和知识。这些研究人员认为，常识性人工智能推理(以及人工一般智能和邪恶机器人)的关键是建立像人一样进行组合学习的系统。这个想法是让系统学习概念和规则，这些概念和规则可以作为构建模块，使系统能够学习更高级别的概念和更高级别的规则。</p><p id="27c4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我对这种方法最大的担忧是，在理解人们如何表达常识方面的进展一直很缓慢。四十年前，我们就人们用来回答诸如“德国牧羊犬的耳朵是什么形状的？”等问题的内部表征的本质进行了一场长时间的辩论我们仍然不知道答案，尽管人工智能和认知科学领域的一些顶尖人士参加了这场辩论。回答一个关于狗耳朵形状的问题，只是表象方案和推理过程海洋中的一滴水。此外，我们甚至不知道这些表征方案和推理过程是天生的还是后天习得的。五十多年来，天赋一直是学术界争论的话题，却没有解决的办法。</p><p id="f4fa" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们还需要多久才能充分了解人们是如何思考的，从而在人工通用智能和邪恶机器人方面取得真正的进展？按照目前的发展速度，我们似乎需要几百年——也许几千年——而这可能永远不会发生。</p><h1 id="8b85" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">深度学习</h1><p id="e354" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">一些研究人员认为，虽然监督和强化学习本身对于构建人工通用智能系统来说是死胡同，但<a class="ae ma" href="https://aiperspectives.com/deep-learning" rel="noopener ugc nofollow" target="_blank"><strong class="lg ja"/></a>深度学习仍有可能带我们去希望之乡。Yann Lecun和Greg Brockman都提出了缩放<a class="ae ma" href="https://aiperspectives.com/unsupervised-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ja">无监督学习</strong> </a>系统，希望它们能够神奇地获得关于世界的常识，并学会基于这些知识进行推理。</p><p id="6f73" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">GPT-3是可伸缩性的一个很好的例子。它比<a class="ae ma" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a>系统大一百多倍，而后者本身比最初的<a class="ae ma" href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="noopener ugc nofollow" target="_blank"> GPT </a>系统大十倍。GPT 2号显示出惊人的生成听起来像人类的文本的能力——如果不总是连贯的话——而GPT 3号生成的文本甚至更好。GPT系统背后的OpenAI研究人员认为这是一种新兴的能力，完全来自于网络的扩大。</p><p id="2b6e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">GPT-3无疑展示了从训练文本中提取统计规律的强大能力，或许还有记忆文本小片段的能力。然而，<a class="ae ma" rel="noopener" target="_blank" href="/gpt-3-has-no-idea-what-it-is-saying-95d4c1bad4a8">它并没有学到关于这个世界的事实</a>或者获得任何基于这个世界知识的推理能力。在游戏的这个阶段，我看不到任何证据表明学习世界知识和推理技能会从这种方法中产生，我也看不到任何相信它会发生的逻辑理由。</p><p id="908c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">Yoshua Bengio <a class="ae ma" href="http://journalismai.com/2019/12/12/yoshua-bengio-from-system-1-deep-learning-to-system-2-deep-learning-neurips-2019/" rel="noopener ugc nofollow" target="_blank">提出了</a>新颖的深度学习架构，旨在将深度学习从其狭窄的人工智能盒子中打破。一个目标是<a class="ae ma" href="https://arxiv.org/pdf/1901.10912.pdf" rel="noopener ugc nofollow" target="_blank">学习更高层次的构建模块</a>，这些模块可以帮助人工智能系统进行综合学习。这是一个有趣但非常早期的想法。这里，像这样的系统将神奇地学习常识和推理的想法是一种信仰的飞跃。</p><h1 id="cbc1" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">模拟人类大脑</h1><p id="7e09" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">人工智能的另一种拟议方法是理解人类大脑的物理架构，并在此基础上模拟人工智能系统。经过几十年的研究，我们对物理大脑如何处理信息只知道一些非常基本的事实。例如，我们知道大脑皮层静态和动态地存储学到的知识，基底神经节处理目标和子目标，并通过强化学习学习选择信息，边缘脑结构将大脑与身体连接起来，并产生动机、情绪和事物的价值。</p><p id="0f08" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对大脑中的神经元建模的想法已经在提议阶段超过四十年了。它尚未获得任何真正的牵引力，部分原因是在理解人脑方面的进展极其缓慢，部分原因是我们没有具体的方法来模拟我们在人工智能程序中对人脑的了解。同样，我们已经接近起点，没有证据表明这种方法会成功。</p><h1 id="d6f8" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">更快的计算机</h1><p id="d14e" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">技术未来学家雷·库兹韦尔(Ray Kurzweil)一直认为，人工智能将作为更大更快的计算机趋势的副产品出现。他推广了奇点的概念，奇点是指计算机足够聪明来改进自身编程的时间点。他的理论指出，一旦发生这种情况，他们的智力将呈指数级快速增长，他们将很快达到超人的智力水平。库兹韦尔预测奇点将在2045年左右出现。</p><p id="d252" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">也就是说，很难想象处理能力本身如何能够创造人工通用智能。如果我打开一台20世纪70年代的没有安装程序的计算机，打开一台今天的没有安装程序的计算机，或者打开一台50年后的没有安装程序的计算机，这些计算机都不能做任何事情。如果我在每台计算机上安装一个文字处理程序，那么每台计算机都只能进行文字处理。更新、更现代的计算机将能够反应更快，处理更大的文件，但它们仍然只能进行文字处理。未来的计算机也是如此。</p><p id="0f6e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">更快的计算机本身不会产生人工智能。正如史蒂芬·平克所说，“纯粹的处理能力并不能神奇地解决你所有的问题。”万一人工智能成为可能，编程和学习算法可能会非常复杂，需要极其强大的计算机。然而，那些编程和学习算法将是必要的；速度和动力是不够的。</p><h1 id="4e5a" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">我们会实现人工通用智能吗？</h1><p id="217f" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">狭隘的人工智能系统背后的技术无法进步到人工通用智能和邪恶机器人。关于我们如何到达AGI有几种想法，但这些都是模糊的想法。自20世纪50年代末以来，人工智能研究人员对如何创造AGI有许多想法。没有一个成功。绝对没有证据表明今天的想法会更好。</p><p id="5373" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对实现人工通用智能的乐观和恐惧都植根于狭义人工智能系统的成功。这种对狭义人工智能的乐观自然地，但不正确地，蔓延到了对AGI前景的乐观。正如艾伦人工智能研究所(Allen Institute for AI)<a class="ae ma" href="https://www.amazon.com/Architects-of-Intelligence-audiobook/dp/B0812B9X5G/ref=sr_1_1?crid=2ZZSZJ3ITCHE2&amp;dchild=1&amp;keywords=architects+of+intelligence+by+martin+ford&amp;qid=1603907302&amp;sprefix=ford+archite%2Caps%2C169&amp;sr=8-1" rel="noopener ugc nofollow" target="_blank">的首席执行官柳文欢·埃齐奥尼所说的</a>，“这让我想起了一个小孩爬到树顶，指着月亮说‘我正在去月球的路上’的比喻。”"</p><p id="c59b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你可能不希望时间旅行在你有生之年发生。你可能认为它会在科幻小说中保留数百年，如果不是永远的话。你可能对曲速也有同感，让人进入冬眠，隐形，心灵传输，把一个人的思想上传到电脑，逆转衰老。你应该把人工通用智能和邪恶机器人放在同一个类别中。</p><p id="0382" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">请在下面输入任何评论，并随时访问<a class="ae ma" href="https://www.aiperspectives.com/introduction" rel="noopener ugc nofollow" target="_blank"><em class="my"/></a><em class="my">人工智能视角，在那里你可以找到免费的在线人工智能手册，共有15章，400页，3000篇参考文献，没有高等数学。</em></p><p id="b36a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这篇文章最初发表在史蒂夫的博客上。</p></div></div>    
</body>
</html>