<html>
<head>
<title>Perfect Recipe for Classification Using Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用逻辑回归进行分类的完美方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-perfect-recipe-for-classification-using-logistic-regression-f8648e267592?source=collection_archive---------3-----------------------#2020-11-07">https://towardsdatascience.com/the-perfect-recipe-for-classification-using-logistic-regression-f8648e267592?source=collection_archive---------3-----------------------#2020-11-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/99969f38d9b38f99c4228af30e508000.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*15Q_BciczaQktxERtgvYzg.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由来自<a class="ae jd" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2964231" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae jd" href="https://pixabay.com/users/kellepics-4893063/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2964231" rel="noopener ugc nofollow" target="_blank">斯蒂芬·凯勒</a>拍摄</p></figure><div class=""/><div class=""><h2 id="b5f7" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">用逻辑回归解决分类问题</h2></div><p id="2aaa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">监督学习是机器学习的重要组成部分。当要预测的变量是分类变量时，使用分类技术。分类问题的一个常见例子是试图在三种不同的种类中对鸢尾花进行分类。</p><p id="e9e2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Logistic回归是机器学习从统计学领域借用的一种分类技术。逻辑回归是一种用于分析数据集的统计方法，其中有一个或多个决定结果的独立变量。使用逻辑回归的目的是找到描述因变量和自变量之间关系的最佳拟合模型。</p><p id="6d8a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这篇文章中，我们将首先从理论上探讨什么是逻辑回归，然后我们将建立我们的第一个分类模型。但是在开始写这篇文章之前，我建议你看一下我的<a class="ae jd" rel="noopener" target="_blank" href="/getting-started-with-the-basics-of-machine-learning-35954a94e961">上一篇文章</a>，借助机器学习，了解一下分类问题到底是什么</p><h1 id="0a61" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">为什么不是线性回归:</strong></h1><p id="9bf8" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">考虑一个场景，其中我们需要对特定类型的癌症是否是恶性的进行分类。如果我们对这个问题使用线性回归，则需要设置一个阈值，基于该阈值可以进行分类，因为线性回归返回连续值。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mo"><img src="../Images/376cd8b126dea0db8f3ab3dba988b621.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Ba7LqnrsRnhjJyJl5LPW6Q.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="http://gfycat.com" rel="noopener ugc nofollow" target="_blank"> Gfycat </a></p></figure><p id="5ddc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是在实际类别是恶性的情况下，预测的连续值是0.4。假设阈值为0.5，数据点将被分类为非恶性，这可能导致严重的后果。因此，可以推断线性回归不适用于分类问题，因为它是无界的，并且预测值是连续的，而不是概率性的。</p><p id="55a0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">将预测概率转换为类别标签的决定由称为<strong class="kx jh">阈值</strong>的参数决定。高于该阈值的值表示一个类别，而低于该阈值的值表示另一个类别。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mt"><img src="../Images/cfc8ea05a4a4bf9df1ba94c05484d66f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7VZOcTlEdfm1Oy2PO3Cfig.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="http://freepik.com" rel="noopener ugc nofollow" target="_blank"> Freepik </a></p></figure><p id="890d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不仅如此，线性回归对不平衡数据也非常敏感，因为它试图通过最小化误差(直线和实际值之间的距离)来拟合直线。结果可以推断，线性回归更适合于回归问题，而不适合于分类问题，这使得逻辑回归成为可能。</p><h1 id="a0a9" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">逻辑回归:</strong></h1><p id="fbd5" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">逻辑回归<strong class="kx jh"> </strong>是机器学习中使用的一种分类技术。它使用逻辑函数来模拟因变量。因变量本质上是二分法的，即可能只有两种可能的类别(例如:癌症是恶性的还是非恶性的)。因此，在处理二进制数据时使用这种技术。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/15743180de3eaa7fd6530e269705e82e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*Jg8YrW8EyPRI8TsEEHsIlw.gif"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="http://gfycat.com" rel="noopener ugc nofollow" target="_blank"> Gfycat </a></p></figure><h2 id="f9a6" class="mv ls jg bd lt mw mx dn lx my mz dp mb le na nb md li nc nd mf lm ne nf mh ng bi translated"><strong class="ak">逻辑回归的类型:</strong></h2><p id="170b" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">尽管通常用于预测二元目标变量，但逻辑回归可以扩展并进一步分类为三种不同类型，如下所述:</p><ol class=""><li id="3ebb" class="nh ni jg kx b ky kz lb lc le nj li nk lm nl lq nm nn no np bi translated"><strong class="kx jh">二项式</strong>:目标变量只能有两种可能的类型。<strong class="kx jh">例如</strong>。:预测邮件是否为垃圾邮件。</li><li id="a779" class="nh ni jg kx b ky nq lb nr le ns li nt lm nu lq nm nn no np bi translated"><strong class="kx jh">多项式</strong>:目标变量有三种或三种以上可能类型，可能没有任何数量意义。<strong class="kx jh">例如</strong>。:预测疾病。</li><li id="d69f" class="nh ni jg kx b ky nq lb nr le ns li nt lm nu lq nm nn no np bi translated"><strong class="kx jh">序数</strong>:目标变量有有序的类别。<strong class="kx jh">例如</strong>。:网络系列评分从1到5。</li></ol><p id="bd90" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在逻辑回归中，为了将预测值映射到概率，使用了sigmoid函数。该函数将任何实数值映射为0到1之间的另一个值。这个函数在每一点都有一个非负导数，并且只有一个拐点。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/3530673327af77567fb2c8a17ddbeb6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*7Vrklo7TQewSOvjRW48kQA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://www.freepik.com/free-photos-vectors/computer" rel="noopener ugc nofollow" target="_blank"> Freepik </a></p></figure><h2 id="6b2a" class="mv ls jg bd lt mw mx dn lx my mz dp mb le na nb md li nc nd mf lm ne nf mh ng bi translated"><strong class="ak">成本函数</strong></h2><p id="1dca" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">成本函数是一个数学公式，用于量化预测值和期望值之间的误差。简而言之，成本函数是衡量模型在估计x和y之间关系的能力方面有多错误的标准。成本函数返回的值被称为<strong class="kx jh">成本</strong>或<strong class="kx jh">损失</strong>或简称为<strong class="kx jh">误差</strong>。对于逻辑回归，成本函数由以下等式给出:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/7c49da5d70730fc2db50368bb1fcacd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*T4LWRNUp_qd23sWEkNVwMA.jpeg"/></div></figure><p id="51a0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个负函数是因为我们在训练的时候，需要通过最小化损失函数来最大化概率。假设样本是从完全独立的分布中抽取的，降低成本将增加最大似然。</p><p id="53f3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在你对什么是逻辑回归有了一个概念，我们现在将建立我们自己的逻辑回归模型。这个分类模型的代码和其他资源可以在<a class="ae jd" href="https://github.com/ashwinraj-in/MachineLearningRecipes/blob/master/LogisticRegression.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="38ee" class="mv ls jg bd lt mw mx dn lx my mz dp mb le na nb md li nc nd mf lm ne nf mh ng bi translated"><strong class="ak">第一步:导入所需的库</strong></h2><p id="3ae8" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我们的第一步是导入构建模型所需的库。没有必要在一个地方导入所有的库。首先，我们将导入<strong class="kx jh">熊猫</strong>和<strong class="kx jh"> Numpy </strong>库。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/4bdc9f61482f8d2f344c6c6843ec77ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*xW_U2LQ6JvgQEzv_PeJogA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://www.freepik.com/vectors/home" rel="noopener ugc nofollow" target="_blank"> Freepik </a></p></figure><p id="c918" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦导入了这些库，我们的下一步将是获取数据集并将数据加载到我们的笔记本中。我们将在这个例子中使用的数据集是关于心脏病的。</p><pre class="mp mq mr ms gt nx ny nz oa aw ob bi"><span id="2e54" class="mv ls jg ny b gy oc od l oe of"><em class="og">#Import the Libraries and read the data into a Pandas DataFrame</em></span><span id="85cd" class="mv ls jg ny b gy oh od l oe of">import pandas as pd<br/>import numpy as np</span><span id="bf50" class="mv ls jg ny b gy oh od l oe of">df = pd.read_csv("framingham_heart_disease.csv")<br/>df.head()</span></pre><p id="cc73" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">熊猫图书馆用于访问数据。<strong class="kx jh"> read_csv </strong>函数输入格式的数据。csv进入熊猫数据框。</p><p id="b45c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> head() </strong>函数用于显示数据帧的前几条记录。默认情况下，该函数显示前五条记录，但是可以通过输入所需的值来显示任意数量的记录。</p><h2 id="5f25" class="mv ls jg bd lt mw mx dn lx my mz dp mb le na nb md li nc nd mf lm ne nf mh ng bi translated"><strong class="ak">步骤2:清理数据集</strong></h2><p id="f77a" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">数据清理是通过识别不完整、不正确或不相关的数据部分，然后替换、修改或删除粗略数据，来检测和纠正表或数据库中损坏或不准确的记录的过程。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/c6f681629aace843c99cc18ac02775ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*_QAKbQg8FOh1Foq2SauWHA.jpeg"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="http://freepik.com" rel="noopener ugc nofollow" target="_blank"> Freepik </a></p></figure><p id="da43" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以使用<strong class="kx jh"> isnull </strong>函数检测数据集的缺失值。这些缺少值的记录要么被删除，要么用记录的平均值填充。然而，输入近似值可能会在模型中引入<strong class="kx jh">方差</strong>和/或<strong class="kx jh">偏差</strong>。</p><p id="d6d0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">偏差</strong>误差是学习算法中错误假设产生的误差。高偏差会导致算法错过特征和目标输出之间的相关关系，从而导致<strong class="kx jh">欠拟合</strong>。</p><pre class="mp mq mr ms gt nx ny nz oa aw ob bi"><span id="d35e" class="mv ls jg ny b gy oc od l oe of"><em class="og">#Handling missing data</em></span><span id="3e02" class="mv ls jg ny b gy oh od l oe of">series = pd.isnull(df['cigsPerDay'])</span></pre><p id="c78e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">另一方面，<strong class="kx jh">方差</strong>是由于模型对训练集中的小波动的敏感性而引起的误差。高方差会导致算法对训练数据中的这些波动进行建模，从而导致模型的<strong class="kx jh">过拟合</strong>。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/6621686007d864c1c3f28fbf72411a68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fxfBcSCckFvMW4409MoR_w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片作者<a class="ae jd" href="http://ashwinraj-in.medium.com" rel="noopener">作者</a></p></figure><p id="8ad0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本例中，我们还注意到数据集的某些特征(如教育)在决定输出时不起作用。此类特征应在构建模型前删除。</p><pre class="mp mq mr ms gt nx ny nz oa aw ob bi"><span id="b5af" class="mv ls jg ny b gy oc od l oe of">#<em class="og">Dropping unwanted columns</em></span><span id="ce71" class="mv ls jg ny b gy oh od l oe of">data = df.drop(['currentSmoker','education'], axis = 'columns')<br/>cigs = data['cigsPerDay']</span><span id="ab15" class="mv ls jg ny b gy oh od l oe of">cig = cigs.mean()<br/>integer_value = math.floor(cig)<br/>cigs.fillna(integer_value, inplace = True)<br/>data.dropna( axis = 0, inplace = True)</span></pre><p id="ff86" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">像CigsPerDay这样的某些特征已经表明这个人是吸烟者，因此CurrentSmoker列实际上是没有用的。</p><h2 id="0165" class="mv ls jg bd lt mw mx dn lx my mz dp mb le na nb md li nc nd mf lm ne nf mh ng bi translated"><strong class="ak">步骤3:分析数据集</strong></h2><p id="d886" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">既然我们的数据集是干净的，没有不规则性，下一步将为心脏病高风险人群和心脏病低风险人群创建两个独立的数据框架。</p><p id="2b64" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这一步也可以称为<strong class="kx jh">特征工程</strong>。另一个重要的步骤是可视化数据，因为它非常有助于确定选择哪些特征可以产生最佳结果..</p><pre class="mp mq mr ms gt nx ny nz oa aw ob bi"><span id="a105" class="mv ls jg ny b gy oc od l oe of"><em class="og">#Analyzing The Dataset</em></span><span id="1962" class="mv ls jg ny b gy oh od l oe of">Heart_Attack = data[data.TenYearCHD == 1]<br/>No_Heart_Attack = data[data.TenYearCHD == 0]</span><span id="7f99" class="mv ls jg ny b gy oh od l oe of">final = data.drop(['diaBP','BMI','heartRate'], axis = 'columns')</span></pre><p id="a6ca" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">特征工程的另一个重要步骤是<strong class="kx jh">缩放数据</strong>，因为逻辑回归对数据是否被缩放很敏感。如果数据没有缩放，模型可能会认为3000克大于5千克，这可能会导致错误的预测。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/e0a3c04b14c9c182e9e752e215a1df83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*IbpfcaRJxWXtzP1tuHoyBA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.freepik.es%2Fvector-premium%2Filustracion-plana-concepto-analisis-personas_9129785.htm&amp;psig=AOvVaw07h75tnxakMHNjTI66uSWc&amp;ust=1605153658370000&amp;source=images&amp;cd=vfe&amp;ved=0CAMQjB1qFwoTCOCFp8fN-ewCFQAAAAAdAAAAABAh" rel="noopener ugc nofollow" target="_blank"> Freepik </a></p></figure><p id="700b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本例中，我还删除了<strong class="kx jh"/>【diaBP】【身体质量指数】和【心率】的值，因为它们与十年一次的值相似。</p><h2 id="9d78" class="mv ls jg bd lt mw mx dn lx my mz dp mb le na nb md li nc nd mf lm ne nf mh ng bi translated"><strong class="ak">步骤4:准备模型</strong></h2><p id="84cf" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">既然我们已经清理了数据并选择了有效的特征，我们就可以根据我们的训练数据来拟合模型了。为此，我们首先需要将数据集分成具有给定随机状态<strong class="kx jh">的训练和测试数据，以便每次执行程序时输出保持不变。在这个例子中，随机状态是99。</strong></p><pre class="mp mq mr ms gt nx ny nz oa aw ob bi"><span id="63e0" class="mv ls jg ny b gy oc od l oe of"><em class="og">#Preparing the model</em></span><span id="90be" class="mv ls jg ny b gy oh od l oe of">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20, random_state = 99)</span><span id="6757" class="mv ls jg ny b gy oh od l oe of">from sklearn.linear_model import LogisticRegression<br/>model = LogisticRegression()</span><span id="5b1f" class="mv ls jg ny b gy oh od l oe of">model.fit(X_train, y_train)<br/>model.score(X_test,y_test)</span></pre><p id="62c9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">完成后，从<strong class="kx jh"> sklearn.linear_model </strong>导入LogisticRegression，并根据训练数据拟合回归方程。可以通过计算<strong class="kx jh">模型得分</strong>来评估模型的性能。</p><p id="7c65" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本例中，该模型的准确率为85.6%。<strong class="kx jh">混淆矩阵</strong>也是总结预测模型性能的好技术。其中有两种可能的预测类别——阳性和阴性。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/e57cc1949d3c927f432dabec2e0b0dc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*jecRZI5K865d3sCNih_NVw.jpeg"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="http://ashwinraj-in.medium.com" rel="noopener">作者</a></p></figure><p id="73a3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">混淆矩阵可以进一步用于确定各种重要的度量，包括<strong class="kx jh">准确度</strong>、<strong class="kx jh"> ROC得分</strong>、<strong class="kx jh">精确度</strong>、<strong class="kx jh"> F得分</strong>等。</p><h1 id="0d79" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">逻辑回归的优势</strong></h1><p id="5c35" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">逻辑回归是解决分类问题最有效的技术之一。使用逻辑回归的一些优势如下所述。</p><ol class=""><li id="8f15" class="nh ni jg kx b ky kz lb lc le nj li nk lm nl lq nm nn no np bi translated">逻辑回归更容易实现、解释，并且训练起来非常有效。它对未知记录的分类速度非常快。</li><li id="70e6" class="nh ni jg kx b ky nq lb nr le ns li nt lm nu lq nm nn no np bi translated">当数据集是线性可分的时，它表现得很好。</li><li id="2730" class="nh ni jg kx b ky nq lb nr le ns li nt lm nu lq nm nn no np bi translated">它可以将模型系数解释为特征重要性的指标。</li></ol><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/f12711c8f058a95dc4ccb3c866fd9cc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*blOad1e0c5V8EsTx03chWg.gif"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="http://gfycat.com" rel="noopener ugc nofollow" target="_blank"> Gfycat </a>提供</p></figure><h1 id="655f" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">Logistic回归的缺点</strong></h1><p id="88c8" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">尽管广泛使用，逻辑回归也有一些限制，如下所述:</p><ol class=""><li id="00aa" class="nh ni jg kx b ky kz lb lc le nj li nk lm nl lq nm nn no np bi translated">它构建了线性边界。逻辑回归需要独立变量与对数概率线性相关。</li><li id="1d10" class="nh ni jg kx b ky nq lb nr le ns li nt lm nu lq nm nn no np bi translated">逻辑回归的主要限制是因变量和自变量之间的线性假设。</li><li id="79b7" class="nh ni jg kx b ky nq lb nr le ns li nt lm nu lq nm nn no np bi translated">更强大和紧凑的算法，如神经网络，可以轻松胜过这种算法。</li></ol><h1 id="1c21" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">总结你学到的东西</h1><p id="3d5b" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">为了总结我们在本文中学到的东西，首先我们讨论了什么是逻辑回归，以及如何用它来建立分类模型。然后，我们讨论了各种不同类型的逻辑回归、其成本函数和用于评估分类模型性能的指标。</p><p id="6ffe" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后，我们动手体验了该算法，构建了我们自己的分类模型。为了支持我们的学习，我们还讨论了这种技术的优点和缺点。</p><p id="03ab" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">至此，我们已经到了这篇文章的结尾。我希望这篇文章能够帮助你对什么是逻辑回归以及何时在你的机器学习之旅中使用它有一个坚实的理解。如果你有任何问题，或者如果你认为我犯了任何错误，请随时与我联系！您可以通过<a class="ae jd" href="http://rajashwin733@gmail.com" rel="noopener ugc nofollow" target="_blank">电子邮件</a>或<a class="ae jd" href="https://www.linkedin.com/in/rajashwin/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>与我联系。快乐学习！</p></div></div>    
</body>
</html>