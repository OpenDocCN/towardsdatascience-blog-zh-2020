<html>
<head>
<title>Street View House Number Generation Using DCGAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用DCGAN生成街景门牌号</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/street-view-house-number-generation-using-dcgan-8cc5222408f3?source=collection_archive---------32-----------------------#2020-09-25">https://towardsdatascience.com/street-view-house-number-generation-using-dcgan-8cc5222408f3?source=collection_archive---------32-----------------------#2020-09-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2a1e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习</h2><div class=""/><div class=""><h2 id="d78c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用DCGANs生成新的门牌号图像</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/7c81ef0b422bed8cefed213b06ec7971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9QmSMrsHyFz8I_oa"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@kmvrlv?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">卡拉·亚历山大</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="689f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我将带您完成一个有趣的项目，在这个项目中，您将实现一个用于街景门牌号生成的DCGAN。</p><p id="ccc4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将利用街景门牌号(SVHN)数据集来训练我们的对抗网络。</p><blockquote class="me mf mg"><p id="6677" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated"><em class="it">如果你不熟悉GANs及其工作方式，请阅读这篇关于走向数据科学的文章。</em></p></blockquote><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/generative-adversarial-networks-6a17673db367"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">生成对抗网络</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">用解读甘博弈</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc lb mo"/></div></div></a></div></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="98b9" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">街景门牌号(SVHN)数据集</h2><p id="b834" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">您将在街景门牌号码(SVHN)数据集上训练DCGAN。这些是从谷歌街景收集的门牌号的彩色图像。SVHN图像是彩色的，比MNIST图像更加多变。</p><p id="0da9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据可以从<a class="ae lh" href="http://ufldl.stanford.edu/housenumbers/" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><blockquote class="me mf mg"><p id="a09a" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">我们将使用深度卷积GANs。如果你想了解DCGANs，可以看看这篇文章。</p></blockquote><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">深度卷积生成对抗网络</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">生成对抗网络最有趣的部分之一是生成网络的设计。的…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="oh l mz na nb mx nc lb mo"/></div></div></a></div><h2 id="e612" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">预处理和数据加载</h2><p id="0284" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们只需要将数据转换成张量，并准备好数据加载器。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="c727" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">可视化我们的训练数据</h2><p id="87bf" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们现在将生成一批数据，并将其可视化。请注意，np.transpose函数按照指定的顺序转换图像尺寸。例如，在调用以下函数时，形状3x32x32的RGB图像将转换为32x32x3:</p><pre class="ks kt ku kv gt ok ol om on aw oo bi"><span id="2b04" class="nk nl it ol b gy op oq l or os">np.transpose(img,(1,2,0))</span></pre><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/3a0fb6c6834d90bcc1187e4b68eb836e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EPP3hVhhzbAZUlxw0hO2oA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由作者提供。</p></figure><p id="aa47" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们的批次大小是128，所以在这种情况下，我们只绘制20个图像，而不是绘制一个批次的所有128个图像。</p><h2 id="2db8" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">缩放图像</h2><p id="ed8c" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">缩放图像是很重要的，因为Tanh函数的值在-1到1的范围内，所以我们需要将我们的训练图像重新缩放到-1到1的范围。(目前，它们在0-1的范围内。)</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="d39a" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">辅助函数—卷积和转置卷积</h2><p id="9324" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">为了简化我们的代码，我们将定义帮助函数来定义我们的鉴别器和生成器网络。</p><p id="b9f5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些助手功能的原因是什么？回答——干！😅</p><p id="d9d1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">卷积辅助函数</strong></p><blockquote class="me mf mg"><p id="e51b" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated"><em class="it">注:要了解CNN，请查看下面的斯坦福笔记。</em></p></blockquote><div class="ml mm gp gr mn mo"><a href="https://cs231n.github.io/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">用于视觉识别的CS231n卷积神经网络</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">斯坦福CS231n课程材料和笔记:视觉识别的卷积神经网络。</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">cs231n.github.io</p></div></div></div></a></div><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><p id="bbaa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">转置卷积辅助函数</strong></p><blockquote class="me mf mg"><p id="c732" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">注意:如果你想了解转置卷积，可以看看下面的文章。</p></blockquote><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/transposed-convolution-demystified-84ca81b4baba"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">转置卷积去神秘化</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">转置卷积对于图像分割、超分辨率等应用来说是一个革命性的概念</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="ou l mz na nb mx nc lb mo"/></div></div></a></div><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="72a3" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">鉴别器架构</h2><p id="8077" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们现在将定义我们的鉴别器网络。正如我们所知，鉴别器负责将图像分类为真或假。因此这是一个典型的分类器网络。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="2d2c" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">发电机架构</h2><p id="465f" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">生成器网络负责生成假图像，这些假图像可以欺骗鉴别器网络将其归类为真实图像。随着时间的推移，生成器在欺骗鉴别器方面变得相当不错。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="f69f" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">参数初始化</h2><p id="0644" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们将通过从正态分布中抽取随机值来初始化网络的权重和偏差。这导致更好的结果。我们为其定义了一个函数，将一个层作为输入。</p><p id="ce0a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于权重，我使用0均值和0.02标准差。</p><p id="7cb4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于偏差，我使用0。</p><blockquote class="me mf mg"><p id="77a3" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated"><em class="it">现在这应该被替换，所以函数后面的_(下划线)也是如此。</em></p></blockquote><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="cd7f" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">损失函数和优化器</h2><p id="ca92" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们将使用学习率为0.002的Adam优化器。这与DCGANs的原始研究论文一致。你可以在下面查看一下。</p><div class="ml mm gp gr mn mo"><a href="https://arxiv.org/abs/1511.06434" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">深度卷积生成对抗网络的无监督表示学习</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">近年来，卷积网络的监督学习(CNN)在计算机视觉领域得到了广泛应用…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">arxiv.org</p></div></div></div></a></div><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><p id="ddd0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们使用BCEwithLogitsLoss()，它结合了一个sigmoid激活函数(我们希望鉴别器输出一个0–1的值来指示一个图像是真的<em class="mh">还是假的</em>)和二进制交叉熵损失。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/ce6b6dc52bb305d02fc6ed69137a76ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*1I9MpiCXDgoY2XvY42tYQA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Binar交叉熵损失方程。图片由作者提供。</p></figure><h2 id="73eb" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">培训阶段</h2><p id="9833" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">为了更好的结果，我们将训练50个时代。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="1858" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">策划损失</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/41adb0057daf86bf311ee523afed0a6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*ghHd20iJvHgJ9wHF7yzH6g.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由作者提供。</p></figure><h2 id="f89f" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">样本生成</h2><p id="cbd0" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">现在让我们生成几个样本。重要的是，我们要将这些值重新调整回像素范围(0–255)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><p id="8da9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，下面是我们生成的街景小时数。👀</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/4f5d9d418ff25e91b597dc1e950178a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HdVsNGucLsuB730dvaGDwA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由作者提供。</p></figure></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="a22f" class="oy nl it bd nm oz pa pb np pc pd pe ns ki pf kj nv kl pg km ny ko ph kp ob pi bi translated">结论</h1><p id="9a6e" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们已经看到了如何在SVHN数据集上使用DCGAN实现来生成街景门牌号。通过调整超参数，可以进一步改善生成的图像。你也可以选择比这里更深的层次。然而，这样做将导致参数数量的增加，这又将花费大量时间来训练。现在打开你的Jupyter笔记本，执行同样的操作。在下一篇文章中，我将带您完成CycleGANs的图像到图像转换。干杯！</p><h1 id="9b96" class="oy nl it bd nm oz pj pb np pc pk pe ns ki pl kj nv kl pm km ny ko pn kp ob pi bi translated">谢谢你。</h1></div></div>    
</body>
</html>