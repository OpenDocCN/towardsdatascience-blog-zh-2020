<html>
<head>
<title>Overcoming Apache Spark’s biggest pain points</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">克服Apache Spark最大的痛点</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/overcoming-apache-sparks-biggest-pain-points-b374cebcf6a4?source=collection_archive---------7-----------------------#2020-10-10">https://towardsdatascience.com/overcoming-apache-sparks-biggest-pain-points-b374cebcf6a4?source=collection_archive---------7-----------------------#2020-10-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="6920" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="77f6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">关于Spark最具挑战性的方面以及数据科学家和工程师如何克服它们的高级指南</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ffadd355f7bffc1fa783fe92be5dc3ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LAH0igikvKiajz-A31fR4g.jpeg"/></div></div></figure><p id="c51b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">卡姆拉奈季诺夫创作的<em class="lz">电脑照片—</em><a class="ae ma" href="https://www.freepik.com/photos/computer" rel="noopener ugc nofollow" target="_blank"><em class="lz">www.freepik.com</em></a></p><p id="c548" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">大约6年前，我第一次使用Apache Spark，当时，它是“大数据”分析领域的开端。毫无疑问，掌握Spark是任何想成为数据科学家或数据工程师的人的职责；毕竟，除此之外，如何利用海量数据和分布式CPU计算来创建尽可能最好的机器学习模型？</p><p id="35d7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果那时我可以看到2020年的未来，我可能会有点惊讶，很大一部分ML/AI从业者仍然不使用Spark或只将其用于数据工程，而不是机器学习。一部分自然是因为兴趣部分转移到面向GPU，而不是面向CPU的机器学习技术，尤其是深度学习。但是对于图像和自然语言处理之外的大多数应用程序，面向CPU的技术的有用性是毋庸置疑的，令人惊讶的是许多数据科学家仍然严重依赖单机ML工具，如Scikit-learn以及XGBoost和LightGBM的非分布式版本。</p><p id="5220" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">就我个人而言，我觉得这很遗憾，因为如果使用得当，Spark对于任何处理数据的人来说都是一个非常强大的工具，可以帮助我们避免浪费时间来找出如何将大型数据集放入内存和处理器，并允许我们完全控制数据分析工作流，包括提取数据、生成模型以及将模型部署到生产和测试中。</strong></p><p id="ad80" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在Apache Spark上举办了研讨会并指导了几十名数据科学家和工程师，我能够理解用户在使用该工具时通常面临的最大困难，为什么会发生这些问题以及如何克服它们。这份由两部分组成的指南是为那些不仅想使用Spark，而且想真正理解Spark的内部原理以解决复杂问题并生成高性能、稳定代码的人准备的。</p><p id="4342" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><em class="lz">注意，我假设读者已经对Spark有了基本的了解，例如，什么是Spark驱动程序和执行器，数据集被划分为分区，什么是懒求值以及Spark的基本数据结构。</em></p><h1 id="b3c9" class="mb mc it bd md me mf mg mh mi mj mk ml ki mm kj mn kl mo km mp ko mq kp mr ms bi translated">第1部分:Spark的分区和资源管理</h1><h2 id="d36c" class="mt mc it bd md mu mv dn mh mw mx dp ml lm my mz mn lq na nb mp lu nc nd mr iz bi translated">挑战</h2><p id="048d" class="pw-post-body-paragraph ld le it lf b lg ne kd li lj nf kg ll lm ng lo lp lq nh ls lt lu ni lw lx ly im bi translated">与单处理器的vanilla Python(例如Pandas)不同，在Pandas中，内部处理的细节是一个“黑盒”,使用Spark执行分布式处理需要用户做出大量决策:</p><ul class=""><li id="1437" class="nj nk it lf b lg lh lj lk lm nl lq nm lu nn ly no np nq nr bi translated"><strong class="lf jd">每个数据集使用多少个分区</strong>？</li><li id="47a7" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly no np nq nr bi translated">何时对数据集进行<strong class="lf jd">重新分区</strong>？</li><li id="b9d1" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly no np nq nr bi translated">要用多少个<strong class="lf jd"> Spark执行器</strong>，给它们分配多少内存和多少内核？</li><li id="5edc" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly no np nq nr bi translated">给<strong class="lf jd">火花驱动器</strong>分配多少内存？</li></ul><p id="c21a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让事情变得更复杂的是:</p><ul class=""><li id="1c65" class="nj nk it lf b lg lh lj lk lm nl lq nm lu nn ly no np nq nr bi translated">一个典型的处理流水线将涉及多个操作，每个操作可能会产生大小显著不同的数据集，这使得<strong class="lf jd">不太可能找到适合整个数据流水线</strong>的单一参数集。</li><li id="bcb6" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly no np nq nr bi translated"><strong class="lf jd">某些Spark操作会自动改变分区的数量</strong>，这使得用户更难跟踪每个数据集使用了多少分区。例如，连接操作会将输出数据集的分区数量更改为在<code class="fe nx ny nz oa b">spark.sql.shuffle.partitions</code>配置参数中指定的数量。</li></ul><h2 id="7b6d" class="mt mc it bd md mu mv dn mh mw mx dp ml lm my mz mn lq na nb mp lu nc nd mr iz bi translated">知道什么是重要的</h2><p id="9a86" class="pw-post-body-paragraph ld le it lf b lg ne kd li lj nf kg ll lm ng lo lp lq nh ls lt lu ni lw lx ly im bi translated">关于分区和资源管理的每个决定的含义可以总结如下:</p><ol class=""><li id="f3df" class="nj nk it lf b lg lh lj lk lm nl lq nm lu nn ly ob np nq nr bi translated">如果我们为一个特定的表使用太多的分区，由于优化和并行化开销等多种原因，可能会导致资源的缓慢/浪费，因为<strong class="lf jd">Spark作为单个分区处理一定量的数据所需的CPU总量比作为多个分区处理要快得多</strong>。即使在同一个物理服务器中处理分区时也是如此；</li><li id="8bc0" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly ob np nq nr bi translated">如果我们为一个特定的表使用太少的分区，这可能会导致资源的缓慢/浪费，因为<strong class="lf jd">许多执行器在处理完他们的分区</strong> s后将会“空闲”,等待其他分区完成处理；</li><li id="a667" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly ob np nq nr bi translated">如果我们过于频繁地执行重新分区，可能会由于<strong class="lf jd">改组而导致速度变慢/浪费资源，改组包括在执行器之间重新安排分区</strong>。洗牌是一种高成本的操作，无论是从处理还是内存方面来说，它都严重限制了我们稍后将讨论的Spark的处理优化；</li><li id="2547" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly ob np nq nr bi translated">如果我们没有使用足够的重新分区，可能会由于不平衡分区导致的执行器过载和空闲而导致速度变慢/浪费资源；即<strong class="lf jd">非常大的分区可能会导致执行器在内核和内存方面资源不足，并使其他执行器在等待分区处理时处于空闲状态</strong>；</li><li id="22da" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly ob np nq nr bi translated">如果我们在每个执行器上使用太多的内核，由于并行化水平低于预期，可能会导致速度变慢/资源浪费。当执行器控制多个内核时，它会尝试创建多个线程来同时处理多个分区，从而允许线程共享内存中的变量。然而，<strong class="lf jd">这种并行化并不完美，可能会受到I/O操作</strong>的限制(例如写入HDFS或其他分布式数据存储)。通常，即使用户为每个执行器分配了多个内核，也会使用单个内核。此外，由于一个执行器只能在一个物理服务器上运行，因此不可能在执行器中分配用户请求的所有内核。用户可以通过Spark UI监控执行器有效使用的内核数量；</li><li id="b25b" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly ob np nq nr bi translated">如果我们在每个执行器上使用的内核太少，由于创建每个执行器所需的开销，可能会导致速度变慢/资源浪费。由于Spark知道同一个执行器中的内核肯定在同一个物理服务器中，因此它可以优化处理，使它们之间的并行化开销比跨执行器的并行化开销小得多。</li></ol><p id="0194" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了处理流水线的多个步骤中分区和资源需求的变化，以及跟踪每个中间数据集的分区数量的困难，有两种策略可以单独使用或组合使用:</p><ul class=""><li id="b223" class="nj nk it lf b lg lh lj lk lm nl lq nm lu nn ly no np nq nr bi translated">当计算资源在用户池中共享或用户同时运行多个作业时，<strong class="lf jd">通过<code class="fe nx ny nz oa b">spark.dynamicAllocation.maxExecutors</code>和<code class="fe nx ny nz oa b">spark.dynamicAllocation.enabled</code>参数激活执行器</strong>的动态分配可以大大减少Spark计算资源的闲置；</li><li id="302e" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly no np nq nr bi translated"><strong class="lf jd">将一个大型处理任务分割成多个较小的任务</strong>，每个任务的数据集大小变化较小，这使我们能够更好地调整配置参数和每个步骤的分区数量。对于每一个更小的任务，我们也可以适当地设置参数<code class="fe nx ny nz oa b">spark.default.parallelism</code>和<code class="fe nx ny nz oa b">spark.sql.shuffle.partitions</code>，以避免不断的重新分区。像Airflow这样的管道工具对于设置和部署由较小作业组成的复杂数据任务非常有用。</li></ul><h1 id="8519" class="mb mc it bd md me mf mg mh mi mj mk ml ki mm kj mn kl mo km mp ko mq kp mr ms bi translated">第2部分:Spark的不变性、惰性评估和执行计划优化</h1><h2 id="f7c4" class="mt mc it bd md mu mv dn mh mw mx dp ml lm my mz mn lq na nb mp lu nc nd mr iz bi translated">挑战</h2><p id="2eb9" class="pw-post-body-paragraph ld le it lf b lg ne kd li lj nf kg ll lm ng lo lp lq nh ls lt lu ni lw lx ly im bi translated">Spark用户首先学到的两件事是不变性和惰性求值的概念。<strong class="lf jd">不变性</strong>意味着Spark数据集不能被修改；对数据集的每个操作都会创建一个新的数据集。<strong class="lf jd">惰性评估</strong>基于数据集上有两种操作的事实:</p><ul class=""><li id="deda" class="nj nk it lf b lg lh lj lk lm nl lq nm lu nn ly no np nq nr bi translated"><strong class="lf jd">转换</strong>产生一个新的Spark数据集作为输出(Spark具有不变性，因此它永远不能修改现有的数据集，只能创建新的数据集)；</li><li id="f78f" class="nj nk it lf b lg ns lj nt lm nu lq nv lu nw ly no np nq nr bi translated"><strong class="lf jd">动作</strong>将Spark数据集作为输入，但会产生Spark数据集以外的东西，比如写入存储、创建局部(非Spark)变量或在用户UI中显示某些东西。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/a5f2bd51b230f538ba06f9e4b19c0126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PtXSuntpXs_t7r2sKFiHAw.png"/></div></div><p class="od oe gj gh gi of og bd b be z dk translated">转换与行动说明(图片由作者提供)</p></figure><p id="2be8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当流程调用转换操作时，这会导致创建一个<strong class="lf jd">不可变的、内存中的“执行计划”</strong>，该计划描述了如何基于其他数据集生成数据集。但是，此时不会生成实际数据。只有当一个动作操作被调用时，Spark <strong class="lf jd">才会评估输入的执行计划</strong>，以生成计算输出所需的数据。因为输入本身可能有依赖于其他数据集的执行计划，所以这些计划被递归地评估，并且该过程继续。</p><p id="00ea" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果在某个时刻触发了另一个动作，要求再次重新创建相同的中间数据集，则该过程重复进行；重新创建执行计划，并且需要再次执行执行计划的所有步骤。为了防止这种情况发生，用户可以<strong class="lf jd">“保存”中间数据集</strong>。当通过触发执行计划创建“持久化”数据集时，数据集将被保存到分布式内存中(或一些配置的分布式存储，如果内存中没有足够的空间)，它将保留在那里，直到手动“取消持久化”或直到Spark的垃圾收集器识别出数据集“超出范围”(不能由运行的代码访问)。</p><p id="4379" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">许多Spark用户没有深入思考不变性和惰性评估的概念及其实际后果，认为知道我们应该<strong class="lf jd">“持久化”一个将被多次使用的中间数据集</strong>就足够了，防止重复计算不止一个操作需要相同的中间数据集。</p><p id="547a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">然而，事实是，很好地利用不变性和懒惰评估远不止于此。事实上，它们与一个鲜为人知的方面密切相关，即通过Spark Catalyst完成的<strong class="lf jd">执行计划优化</strong>。不深入理解这些概念很容易导致缓慢、不稳定的Spark处理，以及用户在调试和解密神秘的错误消息上浪费大量时间。</p><h2 id="c393" class="mt mc it bd md mu mv dn mh mw mx dp ml lm my mz mn lq na nb mp lu nc nd mr iz bi translated">知道什么是重要的</h2><ul class=""><li id="93f2" class="nj nk it lf b lg ne lj nf lm oh lq oi lu oj ly no np nq nr bi translated"><strong class="lf jd"> <em class="lz"> Spark在分区级别执行转换，而不是数据集级别</em> </strong></li></ul><p id="5182" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可能会有一个错误的印象，即调用一个操作会导致该操作之前的一系列转换被逐个执行，每个步骤都会生成一个中间数据集。如果是这样的话，如果数据帧2是通过转换数据帧1生成的，Spark将首先创建数据帧1，然后创建数据帧2，就像我们使用Pandas时的情况一样。</p><p id="88c6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">但事情没那么简单。当一个动作被调用时，所有必要的执行计划实际上被合并成一个执行计划，除了洗牌的情况，每个分区的处理都是独立完成的。这意味着<strong class="lf jd">转换是在分区级别完成的，而不是数据集级别</strong>。因此，对于一个分区，Spark可能仍在生成数据帧1，而对于另一个分区，Spark可能已经在从数据帧1生成数据帧2。例如，我们可能有如下情况:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/7211eb42df88e8f340428fb99262d211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*3FKjNwB6SlDIMIbUQNf4Ig.png"/></div><p class="od oe gj gh gi of og bd b be z dk translated">(图片由作者提供)</p></figure><p id="7d7a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">从性能角度来看，这是一种强大的机制，因为它<strong class="lf jd">防止处理器和内存浪费</strong>，即在移动到下一个中间数据集之前等待整个中间数据集生成。分区级转换的另一个优点是，我们将在下一节看到，它允许Spark更好地优化处理。</p><ul class=""><li id="454c" class="nj nk it lf b lg lh lj lk lm nl lq nm lu nn ly no np nq nr bi translated"><strong class="lf jd"> <em class="lz"> Spark优化执行计划，执行计划越大，优化效果越好</em> </strong></li></ul><p id="6a54" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> Spark催化剂</strong>无疑是Spark最有价值的特性之一。，因为实现高效的分布式处理比实现高效的单核或单内存处理要复杂得多。本质上，<strong class="lf jd">Catalyst将优化执行计划以最大化分布式性能。</strong>例如，在Spark中，一次在同一行中执行多个操作，然后移动到下一行，以此类推，比在同一列中执行多个操作，然后移动到下一列要快得多，因此执行计划会相应地得到优化。</p><p id="21bc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">需要考虑的一个重要因素是<strong class="lf jd">单个大型执行计划比多个小型执行计划有更大的优化潜力</strong>。类似地，通过利用转换是在分区级别而不是数据集级别完成的这一事实，Spark可以为相同的分区组合多个转换，并优化它们以获得更好的性能。以我们之前的例子为例，优化后的结果如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/e4dc6fea9f12de8e0a08e7860198bf2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*EDDz3p4xDtgQoRcMWH2wcQ.png"/></div><p class="od oe gj gh gi of og bd b be z dk translated">(图片由作者提供)</p></figure><ul class=""><li id="b73a" class="nj nk it lf b lg lh lj lk lm nl lq nm lu nn ly no np nq nr bi translated"><strong class="lf jd"> <em class="lz"> Spark的惰性求值和分区级转换使得调试更加复杂</em> </strong></li></ul><p id="595c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">然而，从开发/调试的角度来看，如果发生了错误或者出现了性能瓶颈，惰性评估与分区级转换相结合，会使用户很难准确地找出是哪个处理步骤导致了错误或瓶颈。毕竟，Spark UI只会告诉用户哪个触发操作导致了错误或瓶颈，而不是实际的转换。</p><p id="badd" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">解决方案是<strong class="lf jd">“强制”Spark每次</strong>生成一个完整的中间数据集，方法是插入多个<code class="fe nx ny nz oa b">persist()</code>语句，后跟动作，如<code class="fe nx ny nz oa b">count()</code>或<code class="fe nx ny nz oa b">take()</code>。然而，由于前面提到的处理器/内存浪费和缺乏优化，这些代码的效率非常低，所以最好只在开发目的(而不是生产)和临时的基础上使用这种解决方案。</p><ul class=""><li id="38f2" class="nj nk it lf b lg lh lj lk lm nl lq nm lu nn ly no np nq nr bi translated"><strong class="lf jd"> <em class="lz">太大/太多的执行计划也会成为问题</em> </strong></li></ul><p id="0f10" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我观察到的一件事是，执行计划并不总是与操作的数量成线性关系，有时是多项式或指数关系。由于执行计划存储在Spark驱动程序的内存中(与存储在Spark执行器内存中的持久化对象不同)，这可能会导致Spark<strong class="lf jd">耗尽驱动程序内存，或者由于Spark Catalyst的优化</strong>而变得极其缓慢。这有点讽刺，因为Catalyst应该在部署到Spark执行器时使代码运行得更快；但是在火花驱动器中运行的催化剂会成为处理本身的瓶颈。</p><p id="7d35" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于具有数千列的数据帧来说尤其如此，在这种情况下，我们需要跨所有列执行多个操作。Spark的不变性使情况变得更糟，因为它不断地有新的执行者计划实例被Catalyst创建和评估。</p><p id="c266" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">坚持可能是处理这个问题的有效策略。它将消除在生成持久化的中间数据集之前创建执行器计划的新实例的需要，以及防止Catalyst在创建数据集之前试图优化执行计划。</p><p id="5e9f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">然而，对于复杂、长的管道，执行计划变得非常庞大，甚至<strong class="lf jd">不频繁的持久化也不能防止由优化或驱动程序耗尽内存导致的缓慢</strong>，因为持久化可以防止大型执行计划的多个实例化，但不能首先防止它们的创建。此外，<strong class="lf jd">过多的持久化本身也会成为一个问题</strong>，因为它会占用分布式内存和存储空间。虽然经常尝试去持久化和/或尝试构建代码以最大化垃圾收集肯定有所帮助，但这是一项艰巨的工程任务，并不能总是防止资源耗尽。</p><p id="949a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一种解决方案是名为<strong class="lf jd">检查点</strong>的技术，它包括从用户定义的适当存储系统中保存和加载中间结果。当有效使用时，检查点既可以防止执行计划规模的巨大增长，又可以防止Spark的分布式资源与持久化对象发生冲突。</p><p id="d738" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">另一个解决方案，已经提到过，是<strong class="lf jd">将一个大的处理任务分割成更小的任务</strong>。这样，执行计划就不会变得太大，也不需要担心驱动程序或执行程序内存中的剩余对象。</p><h1 id="6c66" class="mb mc it bd md me mf mg mh mi mj mk ml ki mm kj mn kl mo km mp ko mq kp mr ms bi translated">结论</h1><p id="f389" class="pw-post-body-paragraph ld le it lf b lg ne kd li lj nf kg ll lm ng lo lp lq nh ls lt lu ni lw lx ly im bi translated">当然，关于Spark，本文还会涉及更多内容，例如，如何构建代码以提高Catalyst优化的质量。但是我希望这篇文章可以帮助一些人克服Spark的困难，并利用它在数据工程和机器学习方面的非凡能力和多功能性。虽然Spark仍然是一个具有挑战性的工具，但我可以诚实地证明，在我使用它的6年时间里，Databricks和开源社区如何在用户友好性和灵活性方面大大改进了它。</p><p id="5e73" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果你想学习如何使用Spark和Apache Hadoop YARN并行运行多个分布式作业，比如模型训练的多个实例，<a class="ae ma" rel="noopener" target="_blank" href="/how-to-train-multiple-machine-learning-models-and-run-other-data-tasks-in-parallel-by-combining-2fa9670dd579">查看我的另一篇文章</a>。</p></div></div>    
</body>
</html>