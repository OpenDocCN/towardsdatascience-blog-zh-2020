<html>
<head>
<title>Why Does No One Use Advanced Hyperparameter Tuning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么没人用高级超参数调优？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-does-no-one-use-advanced-hyperparameter-tuning-ac139a5bf9e3?source=collection_archive---------38-----------------------#2020-10-08">https://towardsdatascience.com/why-does-no-one-use-advanced-hyperparameter-tuning-ac139a5bf9e3?source=collection_archive---------38-----------------------#2020-10-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="169d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从我们在Determined AI的集成深度学习训练平台中构建最先进的超参数调整的经验中获得的收获。</h2></div><p id="ba3b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization" rel="noopener ugc nofollow" target="_blank">超参数调整</a> (HP调整)是机器学习开发过程中不可或缺的一部分，可以在最大化模型预测性能方面发挥关键作用。因此，超参数调整算法在学术界得到了广泛的研究，<a class="ae lb" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization" rel="noopener ugc nofollow" target="_blank">这些算法的许多软件实现可以在网上找到</a>。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/760f222b35416e98ff1e016a66967795.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RpYRwiSrLJE_gnmP11HKlg.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图1:一个超参数调整问题的例子，我们考虑深度神经网络的左侧搜索空间。右侧评估了多种配置，以找到最佳设置。(<em class="ls">图片由作者提供。)</em></p></figure><p id="9f6d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，在实现学术研究论文中提出的伪代码和作为端到端机器学习工作流的一部分执行大规模惠普调优之间存在很大差距。即使在众所周知现代惠普调优方法远远优于随机搜索和网格搜索的ML研究社区中，<a class="ae lb" href="http://gael-varoquaux.info/science/survey-of-machine-learning-experimental-methods-at-neurips2019-and-iclr2020.html" rel="noopener ugc nofollow" target="_blank">研究人员仍然主要使用这些简单的方法</a>，因为更高级的方法太难使用。当我从研究生阶段开发<a class="ae lb" href="https://arxiv.org/abs/1603.06560" rel="noopener ugc nofollow" target="_blank"> Hyperband惠普调优算法</a>，到在谷歌运行大规模问题的惠普调优算法，再到最近将最先进的(SOTA)惠普调优功能集成到Determined的培训平台时，我自己就经历过这种情况。在这篇博文中，我将分享我在整个旅程中获得的见解，以便您可以开始将SOTA惠普调优应用于您最紧迫的ML问题。</p><p id="25cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lt">那么，为什么在实践中使用高级惠普调优技术如此困难呢？</em>根据我的经验，在端到端ML工作流程中应用SOTA惠普调优方法的三个主要挑战是:</p><ol class=""><li id="bbcf" class="lu lv iq kh b ki kj kl km ko lw ks lx kw ly la lz ma mb mc bi translated"><strong class="kh ir">解决大问题</strong>:惠普大规模调优与在scikit-learn中将惠普调优应用于小数据集截然不同。单个模型可能需要几天或几周的时间来训练，这意味着我们必须利用并行计算，同时最大限度地提高资源效率，以使问题易于处理，包括以分布式方式高效地执行惠普搜索和训练所考虑的模型。</li><li id="7a51" class="lu lv iq kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated"><strong class="kh ir">与后端系统集成</strong>:可扩展的调优算法和训练方法需要在分布式计算实例上执行，这些实例通过网络连接在一起，以交流中间结果。此外，这些实例需要连接到数据存储，以便可以保存和跟踪实验工件的再现性。</li><li id="0c24" class="lu lv iq kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated"><strong class="kh ir">提供明智的用户界面</strong>:实现一个适用于大规模问题的高效惠普调优算法只有在用户能够实际使用的情况下才有用！实际上，SOTA调优方法比传统的随机或网格搜索要复杂得多，因此，除了最高级的用户之外，对所有人来说，抽象掉这种额外的复杂性是非常重要的。</li></ol><p id="93e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据上面的讨论，很明显，HP调优算法本身只是在实践中应用HP调优的一部分；这些挑战需要通过其他同等重要的功能来解决，如分布式培训、集群管理和可用性。这些功能已经在<a class="ae lb" href="https://determined.ai/product/" rel="noopener ugc nofollow" target="_blank"> Determined的深度学习集成平台</a>中得到支持，因此用户可以专注于模型开发，而不会陷入与深度学习相关的操作复杂性中。</p><p id="1391" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在接下来的章节中，我将分享我们如何通过利用我们的专业知识和在我们的集成系统中构建现有功能，来应对应用SOTA惠普调谐的这些关键挑战。特别是，我将高度概括以下我们认为在实践中对高级惠普调优必不可少的功能:</p><p id="60ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="#f6e7" rel="noopener ugc nofollow"> <strong class="kh ir"> 1。缩放到大问题</strong> </a></p><ul class=""><li id="3a69" class="lu lv iq kh b ki kj kl km ko lw ks lx kw ly la mi ma mb mc bi translated"><a class="ae lb" href="#0c99" rel="noopener ugc nofollow">利用大规模并行性的高效调优算法</a></li><li id="5f04" class="lu lv iq kh b ki md kl me ko mf ks mg kw mh la mi ma mb mc bi translated"><a class="ae lb" href="#8595" rel="noopener ugc nofollow">自动检查点，有效提前停止</a></li><li id="b554" class="lu lv iq kh b ki md kl me ko mf ks mg kw mh la mi ma mb mc bi translated"><a class="ae lb" href="http://0b12" rel="noopener ugc nofollow" target="_blank">大型模型分布式训练</a></li></ul><p id="7f88" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="#0c7e" rel="noopener ugc nofollow">②<strong class="kh ir">。与后端系统集成</strong> </a></p><ul class=""><li id="b0db" class="lu lv iq kh b ki kj kl km ko lw ks lx kw ly la mi ma mb mc bi translated"><a class="ae lb" href="#d923" rel="noopener ugc nofollow">自动化集群管理</a></li><li id="922c" class="lu lv iq kh b ki md kl me ko mf ks mg kw mh la mi ma mb mc bi translated"><a class="ae lb" href="#c2ec" rel="noopener ugc nofollow">再现性的工件跟踪</a></li></ul><p id="2d99" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="#8d42" rel="noopener ugc nofollow"> <strong class="kh ir"> 3。提供合理的用户界面</strong> </a></p><ul class=""><li id="998c" class="lu lv iq kh b ki kj kl km ko lw ks lx kw ly la mi ma mb mc bi translated"><a class="ae lb" href="#c774" rel="noopener ugc nofollow">友好的界面设计便于使用</a></li><li id="c188" class="lu lv iq kh b ki md kl me ko mf ks mg kw mh la mi ma mb mc bi translated"><a class="ae lb" href="#8079" rel="noopener ugc nofollow">用于实验管理的图形网络用户界面</a></li></ul><h1 id="f6e7" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">扩展到大型问题</h1><h2 id="0c99" class="nb mk iq bd ml nc nd dn mp ne nf dp mt ko ng nh mv ks ni nj mx kw nk nl mz nm bi translated">利用大规模并行性的高效调优算法</h2><p id="7217" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">随着模型越来越大，训练时间越来越长，有效利用大规模并行性的超参数调整算法对于大规模应用至关重要。我们选择惠普调优算法的两个标准是:</p><ol class=""><li id="043a" class="lu lv iq kh b ki kj kl km ko lw ks lx kw ly la lz ma mb mc bi translated"><strong class="kh ir">效率</strong>:找到一个高质量的惠普配置需要多少计算量？</li><li id="9e23" class="lu lv iq kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated"><strong class="kh ir">并行</strong>:分布式计算的算法有多合适？例如，有多少计算可以并行完成，以及在出现掉队者和任务失败的情况下，算法的表现如何？</li></ol><p id="4970" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就效率而言，领先的惠普调优算法利用提前停止来降低计算成本；主要思想是分配较少的资源给较差的HP设置，以便可以更快地找到高质量的配置。在我研究生学习的过程中，我和我的合作者通过提前停止引入了<a class="ae lb" href="https://arxiv.org/abs/1603.06560" rel="noopener ugc nofollow" target="_blank"> Hyperband进行高效的HP调优。我们的结果显示，Hyperband比简单的随机搜索快20倍以上，并通过击败以前的SOTA贝叶斯优化方法展示了SOTA性能。从那以后，由于其简单性和理论上的合理性，Hyperband成为HP调优最流行的方法之一。</a></p><p id="96c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于第二个标准，大规模惠普调优算法需要对现实世界计算集群中常见的干扰(如掉队者和任务失败)具有鲁棒性。在这方面，虽然Hyperband算法易于并行化，但随着故障率的增加，该算法中的同步步骤引入了严重的瓶颈。为了解决这个问题，我们最近推出了一种用于大规模并行惠普调优的改进算法，称为异步连续减半(ASHA)，在MLSys 发表的论文<a class="ae lb" href="https://arxiv.org/abs/1810.05934" rel="noopener ugc nofollow" target="_blank">中实现了SOTA性能。</a></p><p id="9b2a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Determined通过<a class="ae lb" href="https://docs.determined.ai/latest/topic-guides/hp-tuning-det/hp-adaptive-asha.html#topic-guides-hp-tuning-det-adaptive-asha" rel="noopener ugc nofollow" target="_blank">我们的自适应惠普调优算法</a>提供SOTA惠普调优功能，该算法构建于ASHA之上，以提高易用性。我们的自适应算法利用早期停止来评估比随机和网格搜索等强力方法多100倍的超参数设置(参见<a class="ae lb" href="https://blog.ml.cmu.edu/2018/12/12/massively-parallel-hyperparameter-optimization/" rel="noopener ugc nofollow" target="_blank">这篇在ASHA的博客文章了解更多细节</a>)。作为ML实践者，我们很清楚宣称SOTA性能是一回事，用真实世界的实验证明它是另一回事。出于好奇，请随意<a class="ae lb" href="#1629" rel="noopener ugc nofollow">跳到我们的基准测试结果</a>来看看Determined的自适应惠普调优算法。</p><h2 id="8595" class="nb mk iq bd ml nc nd dn mp ne nf dp mt ko ng nh mv ks ni nj mx kw nk nl mz nm bi translated">自动检查点，高效提前停止</h2><p id="9b48" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">暂停和恢复训练而不浪费太多计算的能力对于最大化基于早期停止的HP调优方法的效率是至关重要的；Determined的自适应HP调优算法也不例外。在这一过程中，随着算法自适应地将训练资源分配给更高性能的HP设置，数千次试验被暂停和恢复。如果不支持有状态对象的有效保存和恢复，当自适应调整算法决定恢复进一步训练的尝试时，计算的有意义部分将被重复。</p><p id="8017" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了通过Determined的自适应惠普调整算法达到SOTA性能，我们支持高效的早期停止，就像我们支持一般容错机器学习一样:通过自动保存模型和其他有状态对象，以便我们可以在失败后恢复训练而不会丢失太多计算。代替确定，用户必须根据存储位置(例如，AWS S3、Google云存储或分布式文件系统)编写样板代码来正确地保存和恢复模型。要正确做到这一点非常重要，而且分布式培训和<a class="ae lb" href="#c2ec" rel="noopener ugc nofollow">再现性</a>的相关要求会使这一点变得更加复杂。Determined为您处理这些更复杂的用例，并允许您指定一个检查点策略来控制您的实验的存储足迹(参见<a class="ae lb" href="https://docs.determined.ai/latest/topic-guides/checkpoints.html#checkpoint-garbage-collection" rel="noopener ugc nofollow" target="_blank">检查点gc </a>和<a class="ae lb" href="https://docs.determined.ai/latest/reference/experiment-config.html" rel="noopener ugc nofollow" target="_blank">检查点策略</a>)。</p><h2 id="0b12" class="nb mk iq bd ml nc nd dn mp ne nf dp mt ko ng nh mv ks ni nj mx kw nk nl mz nm bi translated">大规模模型的分布式训练</h2><p id="2256" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">光靠SOTA惠普调优不足以进行大规模深度学习，尤其是在<a class="ae lb" href="https://arxiv.org/pdf/2004.08900.pdf" rel="noopener ugc nofollow" target="_blank">模型需要数千小时训练</a>的情况下；对于用户来说，等待几周或几个月来完成一个实验是很难的。幸运的是，分布式培训可以显著减少培训时间(例如，在药物研发应用中确定的<a class="ae lb" href="https://determined.ai/assets/images/resources/Recursion-Drug-Discovery-with-Determined-Training-Platform.pdf" rel="noopener ugc nofollow" target="_blank">24倍加速</a>)。</p><p id="ddc1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Determined中，自适应惠普调优和分布式培训的结合实现了真正的大规模模型开发，以接近零的样板代码开发前沿人工智能。在Determined中启用分布式培训就像切换<em class="lt">单个</em>实验配置字段一样简单:</p><pre class="ld le lf lg gt ns nt nu nv aw nw bi"><span id="845e" class="nb mk iq nt b gy nx ny l nz oa">resources:<br/>    slots_per_trial: 64</span></pre><p id="f8bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这种配置下，HP调优实验中的每次尝试将使用64个GPU来训练单个HP设置。在幕后，Determined为您处理与数据分片和模型参数通信相关的复杂性。Determined还支持<a class="ae lb" href="https://docs.determined.ai/latest/topic-guides/optimizing-distributed-training.html#advanced-optimizations" rel="noopener ugc nofollow" target="_blank">更高级的分布式训练优化选项</a>，可以进一步加速你的实验。</p><p id="e42e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鉴于Determined的自适应HP调整算法通常可以在训练单个模型收敛所需的时间内找到高质量的HP配置，分布式训练使得HP调整即使对于最大的模型也是易处理的。</p><h1 id="0c7e" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">与后端系统集成</h1><h2 id="d923" class="nb mk iq bd ml nc nd dn mp ne nf dp mt ko ng nh mv ks ni nj mx kw nk nl mz nm bi translated">自动化集群管理</h2><p id="cf98" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">以分布式方式运行大规模HP调优实验需要跨多个实例进行协调，以执行HP调优算法指示的工作负载。与随机搜索和网格搜索相比，需要将中间结果传递给算法，以便可以更新算法状态来生成未来的工作负载。建立这样一个集群既耗时又繁琐，而且通常需要为每个计算平台提供单独的解决方案。Determined通过自动在AWS/GCP上提供资源来建立一个集群，然后在集群启动后安排实验，从而处理深度学习的许多操作方面。</p><p id="eae0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">资源供应</strong></p><p id="7fbe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Determined中，用户可以用一条命令启动<a class="ae lb" href="https://docs.determined.ai/latest/topic-guides/aws.html" rel="noopener ugc nofollow" target="_blank"> AWS </a>或<a class="ae lb" href="https://docs.determined.ai/latest/how-to/installation/gcp.html" rel="noopener ugc nofollow" target="_blank"> GCP </a>集群:</p><pre class="ld le lf lg gt ns nt nu nv aw nw bi"><span id="df03" class="nb mk iq nt b gy nx ny l nz oa">det-deploy aws/gcp up --cluster-id &lt;&gt; --project-id &lt;&gt;</span></pre><p id="e35d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用该命令，Determined将创建一个集群，在实例之间建立必要的网络，以便进行HP调优和分布式培训。然后，Determined会根据需要自动放大和缩小实例，以训练活动实验。</p><p id="3e9b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用户还可以<a class="ae lb" href="https://determined.ai/blog/scale-your-model-development-on-a-budget/" rel="noopener ugc nofollow" target="_blank">利用通常便宜3倍的现场/可抢占实例</a>，让他们的计算预算更上一层楼。使用现场/可抢占的实例当然有浪费计算的风险，因为当需求增加时它们可以被关闭。有了Determined，这些风险在很大程度上被我们在上一节中讨论的对保存和恢复实验的内置支持所减轻。</p><p id="1cdc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">实验日程</strong></p><p id="7c7d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">先进先出(FIFO)调度对于计算集群来说仍然是相当普遍的，这是由于它的简单性和作为工作负载管理器的默认状态，如<a class="ae lb" href="https://slurm.schedmd.com/overview.html" rel="noopener ugc nofollow" target="_blank"> SLURM </a>和<a class="ae lb" href="https://en.wikipedia.org/wiki/Oracle_Grid_Engine" rel="noopener ugc nofollow" target="_blank"> Sun Grid Engine </a>。然而，由于两个主要原因，这种调度机制不太适合机器学习集群。首先，从资源利用的角度来看，要求用户为每个实验指定静态资源需求可能是次优的。举例来说，考虑一个具有10个插槽的集群和一个HP调优实验，该实验在探索阶段可以受益于10个插槽，但在整个实验过程中平均只需要4个插槽。其次，FIFO调度可能会导致用户之间的群集资源共享不佳，因为单个大型作业可能会使群集饱和并阻塞所有其他用户作业，例如，请参见下图。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ob"><img src="../Images/9cdb2f034156cb64381e609ebe59e106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mAtOvRvY0M3rU5di.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图2:普通FIFO调度器与Determined使用的公平共享调度器的比较。使用Determined，大型作业不会阻止其他用户提交的作业的进度。此外，Determined自适应地将资源分配给作业，以最大化可用利用率，而不是将固定资源分配给每个作业。(<em class="ls">图片作者。)</em></p></figure><p id="9b05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过使用集中的公平共享调度程序，使每个人都能高效工作，同时最大限度地提高集群利用率。调度器自适应地在实验被提交和处理时给它们分配资源。这允许实验在计算资源可用时利用最大程度的并行性。然而，在存在资源争用的情况下，我们的调度程序跨实验共享资源，以允许所有用户取得进展。这种行为对于团队来说尤其可取，因为在任何给定时间，集群都必须处理不同规模的实验，从需要单个GPU的笔记本电脑到具有数千次不同试验的惠普调优实验。</p><h1 id="c2ec" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">再现性的伪影跟踪</h1><p id="27bc" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">再现性对于减少错误和建立在他人工作的基础上是很重要的。尽管我们已经看到对机器学习(例如<a class="ae lb" href="https://www.wired.com/story/artificial-intelligence-confronts-reproducibility-crisis/" rel="noopener ugc nofollow" target="_blank"> 1 </a>、<a class="ae lb" href="https://sites.google.com/view/icml-reproducibility-workshop/home" rel="noopener ugc nofollow" target="_blank"> 2 </a>)中关于<a class="ae lb" href="https://determined.ai/blog/reproducibility-in-ml/" rel="noopener ugc nofollow" target="_blank">再现性的挑战的认识不断提高，但是由于在整个模型开发过程中存在大量移动部件，再现性仍然难以实现。此外，由于算法的异步性质，SOTA并行HP调优方法为再现性增加了另一层复杂性。</a></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ob"><img src="../Images/b539626e49e732e406b648bce9175bc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JVq21P4FGWvfz9j4.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图3: Determined自动跟踪训练中使用的许多工件，只需点击一个按钮即可实现再现性。(<em class="ls">图片作者。)</em></p></figure><p id="3251" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Determined将上面提到的所有实验工件存储在一个托管数据库中，以便于将来访问。这使用户能够执行以下操作:(1)恢复惠普调优实验，并从停止的地方继续；(2)派生一个实验，并使用不同的配置运行；(3)<a class="ae lb" href="https://determined.ai/blog/warm-starting-deep-learning/" rel="noopener ugc nofollow" target="_blank">通过指定检查点ID，从检查点</a>进行热启动培训。</p><h1 id="8d42" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">提供合理的用户界面</h1><h2 id="c774" class="nb mk iq bd ml nc nd dn mp ne nf dp mt ko ng nh mv ks ni nj mx kw nk nl mz nm bi translated">友好的界面易于使用</h2><p id="815f" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">我们之前观察到，大多数ML研究人员仍然使用简单的HP调优方法，如手动、网格或随机搜索，这也许并不令人惊讶，因为使用高级HP调优方法会引入显著的复杂性。特别是，在实践中很难应用这些方法，因为</p><ol class=""><li id="dfaf" class="lu lv iq kh b ki kj kl km ko lw ks lx kw ly la lz ma mb mc bi translated">它们具有内部超参数，需要进行配置以获得合适的性能，并且</li><li id="5373" class="lu lv iq kh b ki md kl me ko mf ks mg kw mh la lz ma mb mc bi translated">它们需要修改模型代码来处理外部库中的实现。</li></ol><p id="71ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Determined的自适应HP调整算法中，对于(1)，我们已经通过使用健壮的默认值配置搜索算法来简化用户界面，这些默认值在大范围的HP调整实验中运行良好。要在Determined中为您的实验使用自适应HP tuning，只需如下指定实验配置的搜索器部分。</p><pre class="ld le lf lg gt ns nt nu nv aw nw bi"><span id="f48a" class="nb mk iq nt b gy nx ny l nz oa">searcher:<br/>   name: adaptive_asha<br/>   metric: top1_accuracy<br/>   smaller_is_better: false<br/>   max_trials: 1000<br/>   max_length:<br/>       epochs: 300</span></pre><p id="220a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">已确定通过跟踪所有试验的中间性能以便后续重放，实现可重复的HP调整。在试验级别，Determined通过跟踪和保存所有有状态对象(包括随机生成器)来提供容错再现性。这些功能伴随着通过设计使测定可再现的其他组件(见下图)。通过自动跟踪环境、代码和实验工件，Determined允许用户只需点击一个按钮即可重现惠普调优实验。</p><p id="1068" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过设计，用于自适应镜像随机搜索和网格搜索的搜索器配置方案，其中主要输入对应于要评估的HP设置(即，试验)的数量，以及每次试验训练多长时间。高级用户可以选择指定提前停止模式，更积极的提前停止可能会使用更嘈杂的信号来分配训练资源，从而提供更高的加速。随着<a class="ae lb" href="https://docs.determined.ai/latest/topic-guides/hp-tuning-det/index.html#other-supported-methods" rel="noopener ugc nofollow" target="_blank">其他惠普调整算法</a>的出现，对自适应行为的更细粒度控制也得到支持。</p><p id="eb64" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于(2)，我们的惠普调优功能与我们的集成系统无缝协作，因此您可以轻松地从训练单个模型转移到跨多台机器调优您的模型的超参数。这仅仅需要<a class="ae lb" href="https://docs.determined.ai/latest/reference/experiment-config.html#hyperparameters" rel="noopener ugc nofollow" target="_blank">用您想要在实验配置中搜索的超参数和相关范围</a>指定搜索空间。无需处理跨多台机器的调度，也无需修改您的代码来使用不同的惠普调优库。</p><h2 id="8079" class="nb mk iq bd ml nc nd dn mp ne nf dp mt ko ng nh mv ks ni nj mx kw nk nl mz nm bi translated">用于实验管理的图形化web用户界面</h2><p id="ca76" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">启动惠普调优实验后，监控进度并根据需要进行调整非常重要。作为一名研究人员，我借助于监控日志来检查我的结果，并且通常等到整个HP调优实验完成之后才分析结果。有了Determined，用户可以通过我们的web UI监控和管理实验(见下图)。对于给定的实验，该界面显示了迄今为止任何试验所达到的最佳验证性能，并总结了所有评估的超参数设置。用户还可以容易地管理他们的实验，例如，如果已经识别出合适的HP设置，则暂停实验，如果需要进一步调整，则恢复实验，并且分叉实验以用修改的搜索空间运行。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oc"><img src="../Images/e5d6e799d0271df8d898d06f90a09ce7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Zhx4foHM25L7LBVg.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图Determined用户友好的web UI中的实验总结页面。(<em class="ls">图片作者。)</em></p></figure><h1 id="1629" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">决心付诸行动</h1><p id="22e2" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">让我们将这一切与Determined的自适应搜索器的基准测试结合起来，与<a class="ae lb" href="https://arxiv.org/pdf/1810.05934.pdf" rel="noopener ugc nofollow" target="_blank"> ASHA论文</a>和<a class="ae lb" href="https://arxiv.org/abs/1807.01774" rel="noopener ugc nofollow" target="_blank"> BOHB </a>中使用的参考实现进行比较，后者是另一种流行的惠普调优方法。特别是，我们将使用ASHA论文中研究的两个基准，在经过充分研究的搜索空间上进行<a class="ae lb" href="https://en.wikipedia.org/wiki/Neural_architecture_search" rel="noopener ugc nofollow" target="_blank">神经架构搜索</a> (NAS)。为Determined的自适应搜索器复制结果的代码可在这里<a class="ae lb" href="https://github.com/determined-ai/determined/tree/master/examples/hp_search_benchmarks" rel="noopener ugc nofollow" target="_blank">获得</a>供您跟随。</p><p id="a928" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据搜索速度和搜索质量来评估HP调优方法；即，算法能多快找到高质量的HP设置？为了评估这一点，我们跟踪通过搜索方法找到的最佳性能HP设置的验证指标，并比较所得的学习曲线。对于下面的两个基准测试，我们对5次HP调优实验的结果进行了平均，以便进行更可靠的比较。</p><h2 id="e0f6" class="nb mk iq bd ml nc nd dn mp ne nf dp mt ko ng nh mv ks ni nj mx kw nk nl mz nm bi translated">寻找RNN建筑</h2><p id="f872" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">这个搜索空间包括超过150亿个可能的架构，对应于语言建模的不同循环单元。我们在<a class="ae lb" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/rnn_ctxt.pdf" rel="noopener ugc nofollow" target="_blank"> Penn Treebank数据集</a>上训练和评估了不同的架构，并随着自适应搜索器的进展记录了最佳验证<a class="ae lb" href="https://en.wikipedia.org/wiki/Perplexity" rel="noopener ugc nofollow" target="_blank">困惑</a>(越低越好)。下图显示，Determined的自适应搜索器略优于ASHA的参考实现，并在BOHB占据主导地位。事实上，在短短两个小时内，Determined能够通过考虑300多种配置，自动找到一个困惑度低于76的模型；六个小时后，Determined研究了大约1k种不同的配置，而随机搜索只评估了大约20种配置。从这个角度来看，使用可抢占实例评估1k配置的成本为50美元，而使用按需实例评估1k配置的随机搜索成本为7k美元。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi od"><img src="../Images/7cefd679eaa0f52fe6a2675f57ba5cbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gYCFvPiO3OUItQqo.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图5:在一个用于设计RNNs的神经架构搜索任务中，Determined的自适应HP调整算法与ASHA的最新研究结果相匹配。该实验使用16个GPU运行，结果是5个HP调优实验的平均值。(<em class="ls">图片作者。)</em></p></figure><h2 id="2c18" class="nb mk iq bd ml nc nd dn mp ne nf dp mt ko ng nh mv ks ni nj mx kw nk nl mz nm bi translated">搜索CNN架构</h2><p id="db24" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">该搜索空间包括对应于用于计算机视觉的不同卷积神经网络的超过五万亿(或10 ⁸)个可能的架构。我们在<a class="ae lb" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a>上训练和评估了不同的架构，并随着自适应搜索器的进展记录了最佳验证精度。下图显示，Determined的自适应搜索器与ASHA的参考实现相匹配，并且在找到一个好的CNN架构方面比BOHB更快。这里的情况类似于RNN搜索领域的情况:20小时后，Determined在可抢占的实例上仅用150美元就探索了约1k种不同的配置，相比之下，随机搜索使用按需实例评估1k种配置需要23k美元。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi od"><img src="../Images/06804eda7b21300fa46d07a1b518392f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jLFWDVeqHULdTNNS.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图6:在一个用于设计CNN的神经架构搜索任务中，Determined的自适应HP调整算法与ASHA的最新研究结果相匹配。该实验使用16个GPU运行，结果是在5 HP调优实验中得到的平均值。(<em class="ls">图片由作者提供。)</em></p></figure><h2 id="705d" class="nb mk iq bd ml nc nd dn mp ne nf dp mt ko ng nh mv ks ni nj mx kw nk nl mz nm bi translated">坚定地走得更远</h2><p id="7b96" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">让我们继续使用NAS CNN基准来演示使用Determined的端到端模型开发是什么样子。</p><p id="f280" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在执行惠普调整以确定一个好的CNN架构之后，我们需要通过使用多个随机初始化来训练该架构，并在测试集上对其进行评估，从而进一步验证该架构。在一个批处理大小为96的GPU上，这个步骤通常需要将近40个小时。使用Determined，我们通过将批处理大小增加到256并在2个GPU上并行化，轻松地将时间减少了两倍。请注意，您可以进一步提高并行度，并以更高的加速为目标(例如，在这个<a class="ae lb" href="https://determined.ai/blog/faster-nlp-with-deep-learning-distributed-training/" rel="noopener ugc nofollow" target="_blank"> NLP示例中，我们使用Determined将训练速度提高了44倍</a>)。</p><p id="2b5e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自适应搜索找到的最佳架构在CIFAR-10上的测试精度为97.21，优于本文<a class="ae lb" href="https://arxiv.org/pdf/1902.07638.pdf" rel="noopener ugc nofollow" target="_blank"/>(参见表5)中的ASHA基准，并达到或超过许多复杂NAS方法的性能(例如<a class="ae lb" href="https://arxiv.org/pdf/1802.03268" rel="noopener ugc nofollow" target="_blank">【ENAS】</a>、<a class="ae lb" href="https://arxiv.org/pdf/1806.09055" rel="noopener ugc nofollow" target="_blank">飞镖</a>、<a class="ae lb" href="https://arxiv.org/pdf/1810.05749" rel="noopener ugc nofollow" target="_blank"> GHN </a>、<a class="ae lb" href="https://arxiv.org/pdf/1812.09926" rel="noopener ugc nofollow" target="_blank"> SNAS </a>)。</p><p id="a177" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当您找到您满意的模型时，您可以将它保存到<a class="ae lb" href="https://docs.determined.ai/latest/tutorials/model-registry.html#organizing-models" rel="noopener ugc nofollow" target="_blank">模型注册表</a>中，用于模型版本控制/跟踪和在下游应用程序中的方便访问:</p><pre class="ld le lf lg gt ns nt nu nv aw nw bi"><span id="1aba" class="nb mk iq nt b gy nx ny l nz oa"><strong class="nt ir">from</strong> <strong class="nt ir">determined.experimental</strong> <strong class="nt ir">import</strong> Determined<br/><br/>det = Determined() <em class="lt"># Connect to the master<br/></em>model = det.create_model(<br/>         "nas_cnn",<br/>         description="cnn architectures from the DARTS NAS",<br/>       )<br/>checkpoint = det.get_experiment(exp_id).top_checkpoint()<br/>model_version = model.register_version(checkpoint.uuid)</span></pre><h1 id="2cd5" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">我如何开始？</h1><p id="f648" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">在本帖中，我们分享了Determined如何解决在端到端ML工作流中应用SOTA惠普调谐的关键挑战。我们的基准测试结果显示，使用我们的集成系统进行的惠普调整与SOTA研究得出的惠普调整结果相匹配。要尝试我们的SOTA惠普调优解决您的问题，请看一下本教程<a class="ae lb" href="https://docs.determined.ai/latest/how-to/hyperparameter-tuning.html#hyperparameter-tuning" rel="noopener ugc nofollow" target="_blank">开始吧！</a></p><p id="44a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上述基准测试还展示了如何将Determined应用于NAS问题。我们的结果证实了我们之前的工作，表明<a class="ae lb" href="https://arxiv.org/pdf/1902.07638.pdf" rel="noopener ugc nofollow" target="_blank"> ASHA是NAS </a>的一个强基线。您可以<a class="ae lb" href="https://docs.determined.ai/latest/how-to/install-main.html#install-cluster" rel="noopener ugc nofollow" target="_blank">安装一个确定的集群</a>并在提供的代码中修改数据加载器，以尝试NAS来完成您今天的ML任务！</p></div><div class="ab cl oe of hu og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="ij ik il im in"><p id="ef9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lt">原载于2020年10月8日</em><a class="ae lb" href="https://determined.ai/blog/why-does-no-one-use-advanced-hp-tuning/" rel="noopener ugc nofollow" target="_blank"><em class="lt">https://determined . ai</em></a><em class="lt">。</em></p></div></div>    
</body>
</html>