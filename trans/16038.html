<html>
<head>
<title>The Applications and Benefits of a PreTrained Model –– Kaggle’s DogsVSCats</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预训练模型的应用和优势Kaggle的DogsVSCats</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-applications-and-benefits-of-a-pretrained-model-kaggles-dogsvscats-50221902c696?source=collection_archive---------36-----------------------#2020-11-04">https://towardsdatascience.com/the-applications-and-benefits-of-a-pretrained-model-kaggles-dogsvscats-50221902c696?source=collection_archive---------36-----------------------#2020-11-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f38edb1eeefde644cf4faab960b558ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kSw-njRsFwVlqbTElIX8oQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">凯文·Ku上<a class="ae kc" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">的Unsplash </a></p></figure><p id="f3fe" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于图像识别任务，使用预先训练的模型是很好的。首先，它们更容易使用，因为它们为您提供了“免费”的架构此外，他们通常有更好的结果，并且通常需要较少的培训。</p><p id="da5a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了看到这一理论的实际应用，我将使用Kaggle的CatVSDogs数据集来尝试讨论使用不同方法的结果。</p><p id="8e13" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些步骤如下:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="4eac" class="lk ll iq lg b gy lm ln l lo lp">1) Imports</span><span id="5c3c" class="lk ll iq lg b gy lq ln l lo lp">2) Download and Unzip Files</span><span id="53b4" class="lk ll iq lg b gy lq ln l lo lp">3) Organize the Files</span><span id="d8ca" class="lk ll iq lg b gy lq ln l lo lp">4) Set-up and Train Classic CNN Model </span><span id="d617" class="lk ll iq lg b gy lq ln l lo lp">5) Test the CNN Model</span><span id="efd0" class="lk ll iq lg b gy lq ln l lo lp">6) Set-up and Train Pre-Trained Model</span><span id="7805" class="lk ll iq lg b gy lq ln l lo lp">7) Test the Pre-Trained Model</span></pre><p id="7fae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 1。进口</strong></p><p id="314e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在任何机器学习项目中，导入都是必要的。对于这个项目，有各种各样的进口是必需的。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="adaf" class="lk ll iq lg b gy lm ln l lo lp">import warnings</span><span id="7c49" class="lk ll iq lg b gy lq ln l lo lp">warnings.filterwarnings("ignore", category=UserWarning, module="torch.nn.functional") </span><span id="d79e" class="lk ll iq lg b gy lq ln l lo lp">from google.colab import drive</span><span id="1910" class="lk ll iq lg b gy lq ln l lo lp">drive.mount('/content/gdrive')  # connects to data stored on google drive</span><span id="4862" class="lk ll iq lg b gy lq ln l lo lp">import os</span><span id="1f73" class="lk ll iq lg b gy lq ln l lo lp">os.chdir('/content/gdrive/My Drive/')</span><span id="702f" class="lk ll iq lg b gy lq ln l lo lp">import shutil</span><span id="c51c" class="lk ll iq lg b gy lq ln l lo lp">import re</span><span id="09ca" class="lk ll iq lg b gy lq ln l lo lp">import torch</span><span id="28d9" class="lk ll iq lg b gy lq ln l lo lp">import torchvision</span><span id="6ea1" class="lk ll iq lg b gy lq ln l lo lp">from torchvision import transforms</span><span id="9908" class="lk ll iq lg b gy lq ln l lo lp">import torch.nn as nn</span><span id="b3a1" class="lk ll iq lg b gy lq ln l lo lp">import torch.nn.functional as F</span><span id="3dba" class="lk ll iq lg b gy lq ln l lo lp">import torch.optim as optim</span><span id="1219" class="lk ll iq lg b gy lq ln l lo lp">from google.colab import files</span><span id="7618" class="lk ll iq lg b gy lq ln l lo lp">import zipfile</span></pre><p id="976a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然这些导入中的大部分在以后才会用到，但是最好现在就全部导入。这些进口往往分为两类:PyTorch的进口和google collab所需的进口。</p><p id="6fa4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Google Colab为每个人提供了一个免费的GPU，所以使用起来非常棒，尤其是对于初学者。使用下面的代码检查您是否正在使用GPU。如果它不打印cuda，打开你的GPU！</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="69c7" class="lk ll iq lg b gy lm ln l lo lp">device = torch.device("cuda" if torch.cuda.is_available() else "cpu") </span><span id="b957" class="lk ll iq lg b gy lq ln l lo lp">print(device)</span></pre><p id="3195" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PyTorch，类似地，倾向于对初学者倾斜，因为它有一个更容易的界面。然而，它仍然可以完成任何机器学习任务！</p><p id="0c6e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 2。下载并解压文件</strong></p><p id="e403" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些数据将直接从Kaggle(一个开源的机器学习网站)中获取。文件可以在<a class="ae kc" href="https://www.kaggle.com/c/dogs-vs-cats/data" rel="noopener ugc nofollow" target="_blank">这里</a>找到。按下载全部。然后，将zip文件拖到您的驱动器中，并将其放在任何所需的位置。</p><p id="cea7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不要直接从Google Drie或通过你的电脑解压。这将需要大量的时间。因此，在Google Drive中编写一个解压文件并组织它们的方法是对你最有利的。</p><p id="339a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在解压缩之前，创建一个DogsVS Cats文件夹。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="bb28" class="lk ll iq lg b gy lm ln l lo lp">os.mkdir('/content/gdrive/My Drive/DogsVSCats')</span></pre><p id="647c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我将存储解压缩后的数据。</p><p id="5272" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要解压缩，运行以下命令。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="f132" class="lk ll iq lg b gy lm ln l lo lp">with zipfile.ZipFile('/content/gdrive/My Drive/dogs-vs-cats.zip') as zf:</span><span id="cb40" class="lk ll iq lg b gy lq ln l lo lp">zf.extractall('/content/gdrive/My Drive/DogsVSCats')</span></pre><p id="157a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这将提取dogs-vs-cats压缩文件，并将其放在新文件夹中。之后，我们需要解压缩test1.zip和train.zip文件。您可以删除示例submission.csv文件；在本教程中，我们不需要它。</p><p id="e33b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要解压缩train.zip文件，请运行以下命令:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="32aa" class="lk ll iq lg b gy lm ln l lo lp">with zipfile.ZipFile('/content/gdrive/My Drive/DogsVSCats/train.zip') as zf:</span><span id="1f21" class="lk ll iq lg b gy lq ln l lo lp">zf.extractall('/content/gdrive/My Drive/DogsVSCats/')</span></pre><p id="e812" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要解压缩test1.zip文件，请运行以下命令:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="165e" class="lk ll iq lg b gy lm ln l lo lp">with zipfile.ZipFile('/content/gdrive/My Drive/DogsVSCats/test1.zip') as zf:</span><span id="8543" class="lk ll iq lg b gy lq ln l lo lp">zf.extractall('/content/gdrive/My Drive/DogsVSCats/')</span></pre><p id="c7d6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这可能需要一些时间，但是之后所有的文件都应该在它们相应的文件夹中。</p><p id="6061" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 3。整理文件</strong></p><p id="80bb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦所有文件都被解压缩，根据它们的真实分类来组织它们是至关重要的。对于这个数据集，我们将文件组织到“dog”和“cat”文件夹中。</p><p id="271a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">制作所需的文件夹。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="e06e" class="lk ll iq lg b gy lm ln l lo lp">os.mkdir('/content/gdrive/My Drive/DogsVSCats/train/cat')</span><span id="ac58" class="lk ll iq lg b gy lq ln l lo lp">os.mkdir('/content/gdrive/My Drive/DogsVSCats/train/dog')</span></pre><p id="578d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">设置分类。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="c818" class="lk ll iq lg b gy lm ln l lo lp">train_dr= '/content/gdrive/My Drive/DogsVSCats/train/'</span><span id="a6da" class="lk ll iq lg b gy lq ln l lo lp">train_dog_dir = '/content/gdrive/My Drive/DogsVSCats/train/dog'</span><span id="3bde" class="lk ll iq lg b gy lq ln l lo lp">train_cat_dir = '/content/gdrive/My Drive/DogsVSCats/train/cat'</span><span id="4d78" class="lk ll iq lg b gy lq ln l lo lp"><br/>files = os.listdir('/content/gdrive/My Drive/DogsVSCats/train')</span></pre><p id="9524" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，组织。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="650a" class="lk ll iq lg b gy lm ln l lo lp">train = os.listdir("/content/gdrive/My Drive/DogsVSCats/train")</span><span id="9295" class="lk ll iq lg b gy lq ln l lo lp">for f in files:</span><span id="f044" class="lk ll iq lg b gy lq ln l lo lp">   catSearchObj = re.search("cat", f)</span><span id="77f1" class="lk ll iq lg b gy lq ln l lo lp">   dogSearchObj = re.search("dog", f)</span><span id="780c" class="lk ll iq lg b gy lq ln l lo lp">   if catSearchObj:</span><span id="c62b" class="lk ll iq lg b gy lq ln l lo lp">      shutil.move(f'{train_dr}/{f}', train_cat_dir)</span><span id="0eb8" class="lk ll iq lg b gy lq ln l lo lp">      print("moved!-cat")</span><span id="eb52" class="lk ll iq lg b gy lq ln l lo lp">   elif dogSearchObj:</span><span id="1cff" class="lk ll iq lg b gy lq ln l lo lp">      shutil.move(f'{train_dr}/{f}', train_dog_dir)</span><span id="821a" class="lk ll iq lg b gy lq ln l lo lp">      print("moved!-dog")</span></pre><p id="60e4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实际上<em class="lr">没有</em>来添加打印语句，但是看到这种运动很酷！</p><p id="7b76" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们需要将一些训练数据移动到验证数据集中。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="3a2e" class="lk ll iq lg b gy lm ln l lo lp">os.mkdir('/content/gdrive/My Drive/DogsVSCats/val/cat')</span><span id="241e" class="lk ll iq lg b gy lq ln l lo lp">os.mkdir('/content/gdrive/My Drive/DogsVSCats/val/dog')</span><span id="6a3e" class="lk ll iq lg b gy lq ln l lo lp"><br/>val_dog_dir = '/content/gdrive/My Drive/DogsVSCats/val/dog'</span><span id="3fcd" class="lk ll iq lg b gy lq ln l lo lp">val_cat_dir = '/content/gdrive/My Drive/DogsVSCats/val/cat'</span></pre><p id="ecb3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从train dog文件夹中重新定位1，000个文件，并将其发送到验证文件夹。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="e68a" class="lk ll iq lg b gy lm ln l lo lp">files = os.listdir(train_dog_dir)</span><span id="6806" class="lk ll iq lg b gy lq ln l lo lp">for f in files:</span><span id="1756" class="lk ll iq lg b gy lq ln l lo lp">   valDogSearch = re.search("5\d\d\d", f)</span><span id="8063" class="lk ll iq lg b gy lq ln l lo lp">   if valDogSearch:</span><span id="ffa6" class="lk ll iq lg b gy lq ln l lo lp">        shutil.move(f'{train_dog_dir}/{f}', val_dog_dir)</span><span id="1be2" class="lk ll iq lg b gy lq ln l lo lp">!ls {val_dog_dir} | head -n 5</span></pre><p id="8d92" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，对cat trained文件夹执行相同的操作。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="125b" class="lk ll iq lg b gy lm ln l lo lp">files = os.listdir(train_cat_dir)</span><span id="2564" class="lk ll iq lg b gy lq ln l lo lp">for f in files:</span><span id="c983" class="lk ll iq lg b gy lq ln l lo lp">   valCatSearch = re.search("5\d\d\d", f)</span><span id="6acd" class="lk ll iq lg b gy lq ln l lo lp">   if valCatSearch:</span><span id="8954" class="lk ll iq lg b gy lq ln l lo lp">       shutil.move(f'{train_cat_dir}/{f}', val_cat_dir)</span><span id="eb17" class="lk ll iq lg b gy lq ln l lo lp">!ls {val_cat_dir} | head -n 5</span></pre><p id="8f8c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这一部分的最后一步是转换数据，以便更容易训练和扫描。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="e7cb" class="lk ll iq lg b gy lm ln l lo lp">transforms = torchvision.transforms.Compose([torchvision.transforms.Resize((224,224)),</span><span id="d3e7" class="lk ll iq lg b gy lq ln l lo lp">torchvision.transforms.ToTensor()])train_image_folder = torchvision.datasets.ImageFolder('/content/gdrive/My Drive/DogsVSCats/train/', transform=transforms)</span><span id="d8c8" class="lk ll iq lg b gy lq ln l lo lp">train_loader = torch.utils.data.DataLoader(train_image_folder, batch_size=64, shuffle=True, num_workers=4)</span><span id="6ea8" class="lk ll iq lg b gy lq ln l lo lp">val_image_folder = torchvision.datasets.ImageFolder('/content/gdrive/My Drive/DogsVSCats/val/', transform=transforms)</span><span id="b9d2" class="lk ll iq lg b gy lq ln l lo lp">val_loader = torch.utils.data.DataLoader(val_image_folder, batch_size=64, shuffle=True, num_workers=4)</span></pre><p id="d9fe" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 4。设置和训练经典CNN模型</strong></p><p id="8578" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们到了实际训练部分！在这个变体中，我们将使用一个经典的CNN模型。</p><p id="3e33" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该模型如下:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="40c9" class="lk ll iq lg b gy lm ln l lo lp">class DogDetector(nn.Module):</span><span id="ffc6" class="lk ll iq lg b gy lq ln l lo lp">   def __init__(self):</span><span id="d782" class="lk ll iq lg b gy lq ln l lo lp">      super().__init__()</span><span id="7ed8" class="lk ll iq lg b gy lq ln l lo lp">      self.cnn_layers = nn.Sequential(</span><span id="e7f1" class="lk ll iq lg b gy lq ln l lo lp">         nn.Conv2d(3, 6, kernel_size=3, stride=1, padding=1),</span><span id="9bf1" class="lk ll iq lg b gy lq ln l lo lp">         nn.ReLU(inplace=True),</span><span id="efd4" class="lk ll iq lg b gy lq ln l lo lp">         nn.MaxPool2d(kernel_size=2, stride=2),</span><span id="e101" class="lk ll iq lg b gy lq ln l lo lp">         nn.Conv2d(6, 12, kernel_size=3, stride=1, padding=1),</span><span id="558a" class="lk ll iq lg b gy lq ln l lo lp">         nn.ReLU(inplace=True),</span><span id="8e2c" class="lk ll iq lg b gy lq ln l lo lp">         nn.MaxPool2d(kernel_size=2, stride=2), <br/>      <br/>      )<br/>      <br/>      self.linear_layers = nn.Sequential(</span><span id="7416" class="lk ll iq lg b gy lq ln l lo lp">         nn.Linear(256*7*7*3, 196),</span><span id="801a" class="lk ll iq lg b gy lq ln l lo lp">         nn.Linear(196, 1),</span><span id="528c" class="lk ll iq lg b gy lq ln l lo lp">         nn.Sigmoid(),<br/>      )</span><span id="e7ac" class="lk ll iq lg b gy lq ln l lo lp">   <br/>  def forward(self, x):</span><span id="af94" class="lk ll iq lg b gy lq ln l lo lp">     x = self.cnn_layers(x)</span><span id="74d9" class="lk ll iq lg b gy lq ln l lo lp">     x = x.view(x.size(0), -1)</span><span id="3a56" class="lk ll iq lg b gy lq ln l lo lp">     x = self.linear_layers(x)</span><span id="39a4" class="lk ll iq lg b gy lq ln l lo lp">     return x</span><span id="a0cc" class="lk ll iq lg b gy lq ln l lo lp">dog_detector = DogDetector()</span><span id="90f9" class="lk ll iq lg b gy lq ln l lo lp">dog_detector.cuda()</span></pre><p id="054c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，将dog_detector设置为类，并将其放在GPU上。</p><p id="4bfd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练模型是一个简单的过程。因为我们使用Kaggle文件只是为了测试，而不是为了直接竞争，所以我们不需要测试文件。相反，我们可以基于验证集进行训练，而不需要提交给Kaggle。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="1f1c" class="lk ll iq lg b gy lm ln l lo lp">optimizer = optim.Adam(dog_detector.parameters(), lr = 0.0001)</span><span id="754f" class="lk ll iq lg b gy lq ln l lo lp">loss_func = nn.BCELoss().cuda()</span><span id="1baf" class="lk ll iq lg b gy lq ln l lo lp">EPOCHS = 5</span><span id="a952" class="lk ll iq lg b gy lq ln l lo lp">for epoch in range(EPOCHS):</span><span id="4eaf" class="lk ll iq lg b gy lq ln l lo lp">   print(f"epoch: {epoch}")</span><span id="6d01" class="lk ll iq lg b gy lq ln l lo lp">   for i, data in enumerate(train_loader):</span><span id="6cad" class="lk ll iq lg b gy lq ln l lo lp">      if i % 50 == 0:</span><span id="0a7e" class="lk ll iq lg b gy lq ln l lo lp">         print(f"  batch: {i}")</span><span id="ddc4" class="lk ll iq lg b gy lq ln l lo lp">         X, y = data</span><span id="bac0" class="lk ll iq lg b gy lq ln l lo lp">         y = y.type(torch.FloatTensor).view(len(y), -1).cuda()</span><span id="43d8" class="lk ll iq lg b gy lq ln l lo lp">         dog_detector.zero_grad()</span><span id="c82c" class="lk ll iq lg b gy lq ln l lo lp">         output = dog_detector(X.view(-1, 3, 224, 224).cuda())</span><span id="bd75" class="lk ll iq lg b gy lq ln l lo lp">         loss_val = loss_func(output, y)</span><span id="7f9b" class="lk ll iq lg b gy lq ln l lo lp">         loss_val.backward()</span><span id="8506" class="lk ll iq lg b gy lq ln l lo lp">         optimizer.step()</span><span id="63b6" class="lk ll iq lg b gy lq ln l lo lp">    print(f"loss: {loss_val}")</span></pre><p id="287c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">损失值倾向于在大约0.4-0.6左右徘徊。</p><p id="da53" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 5。测试CNN模型</strong></p><p id="8cba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为我们是在没有Kaggle的情况下进行测试，所以我们需要自己检查准确性，这给了我们更直接的结果。这可以通过以下方式实现:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="722c" class="lk ll iq lg b gy lm ln l lo lp">correct = 0</span><span id="676e" class="lk ll iq lg b gy lq ln l lo lp">total = 0</span><span id="f8c4" class="lk ll iq lg b gy lq ln l lo lp">with torch.no_grad():</span><span id="4b24" class="lk ll iq lg b gy lq ln l lo lp">   for data in val_loader:</span><span id="adb8" class="lk ll iq lg b gy lq ln l lo lp">   X, y = data </span><span id="2081" class="lk ll iq lg b gy lq ln l lo lp">   output = dog_detector(X.view(-1, 3, 224, 224).cuda())</span><span id="55d9" class="lk ll iq lg b gy lq ln l lo lp">   correct_sum = output.round().transpose(0, 1).cpu() == y</span><span id="2297" class="lk ll iq lg b gy lq ln l lo lp">   correct += correct_sum.sum().item()</span><span id="55e4" class="lk ll iq lg b gy lq ln l lo lp">   total += len(y)</span><span id="1488" class="lk ll iq lg b gy lq ln l lo lp">print(f"Accuracy: {round(correct/total, 3)}")</span></pre><p id="b33a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">测试时，准确率往往徘徊在73.6%左右。这并不坏，但远远称不上伟大。</p><p id="fd72" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 6。设置并训练预训练模型</strong></p><p id="7e62" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">预训练模型的设置要简单得多。</p><p id="db11" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，下载预先训练好的模型。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="8674" class="lk ll iq lg b gy lm ln l lo lp">model_resnet18 =  torchvision.models.resnet18(pretrained=True)</span><span id="6361" class="lk ll iq lg b gy lq ln l lo lp"><br/>new_lin = nn.Sequential(</span><span id="b386" class="lk ll iq lg b gy lq ln l lo lp">   nn.Linear(512, 1),</span><span id="dd8d" class="lk ll iq lg b gy lq ln l lo lp">   nn.Sigmoid()  </span><span id="8eaf" class="lk ll iq lg b gy lq ln l lo lp">)</span><span id="5a95" class="lk ll iq lg b gy lq ln l lo lp">model_resnet18.fc = new_lin</span></pre><p id="48da" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">冻结训练不需要的层。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="7876" class="lk ll iq lg b gy lm ln l lo lp">for name, param in model_resnet18.named_parameters():</span><span id="e7c3" class="lk ll iq lg b gy lq ln l lo lp">   if("bn" not in name):</span><span id="080a" class="lk ll iq lg b gy lq ln l lo lp">      param.requires_grad = False</span></pre><p id="efa7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，将模型发送到GPU。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="a9fe" class="lk ll iq lg b gy lm ln l lo lp">model_resnet18.cuda()</span></pre><p id="13cf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样！现在是再次训练的时候了。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="0ac0" class="lk ll iq lg b gy lm ln l lo lp">optimizer = optim.Adam(model_resnet18.parameters(), lr = 0.0001)</span><span id="ff13" class="lk ll iq lg b gy lq ln l lo lp">loss_func = nn.BCELoss().cuda()</span><span id="cfc2" class="lk ll iq lg b gy lq ln l lo lp">EPOCHS = 5</span><span id="8548" class="lk ll iq lg b gy lq ln l lo lp">for epoch in range(EPOCHS):</span><span id="f7fa" class="lk ll iq lg b gy lq ln l lo lp">   print(f"epoch: {epoch}")</span><span id="ec41" class="lk ll iq lg b gy lq ln l lo lp">   for i, data in enumerate(train_loader):</span><span id="0822" class="lk ll iq lg b gy lq ln l lo lp">      if i % 50 == 0:</span><span id="750c" class="lk ll iq lg b gy lq ln l lo lp">      print(f"  batch: {i}")</span><span id="1506" class="lk ll iq lg b gy lq ln l lo lp">      X, y = data</span><span id="b8f1" class="lk ll iq lg b gy lq ln l lo lp">      y = y.type(torch.FloatTensor).view(len(y), -1).cuda()</span><span id="5fa2" class="lk ll iq lg b gy lq ln l lo lp">      model_resnet18.zero_grad()</span><span id="49d3" class="lk ll iq lg b gy lq ln l lo lp">      output = model_resnet18(X.view(-1, 3, 224, 224).cuda())</span><span id="5b8e" class="lk ll iq lg b gy lq ln l lo lp">      loss_val = loss_func(output, y)</span><span id="83bc" class="lk ll iq lg b gy lq ln l lo lp">      loss_val.backward() </span><span id="3d3c" class="lk ll iq lg b gy lq ln l lo lp">optimizer.step()</span><span id="6f89" class="lk ll iq lg b gy lq ln l lo lp">print(f"loss: {loss_val}")</span></pre><p id="9df2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">损耗范围在0.2–0.4之间，明显优于CNN模型。</p><p id="4d2c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 7。测试预训练模型</strong></p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="d427" class="lk ll iq lg b gy lm ln l lo lp">correct = 0</span><span id="2cf3" class="lk ll iq lg b gy lq ln l lo lp">total = 0</span><span id="4ada" class="lk ll iq lg b gy lq ln l lo lp">with torch.no_grad():</span><span id="a7e4" class="lk ll iq lg b gy lq ln l lo lp">   for data in val_loader:</span><span id="85ea" class="lk ll iq lg b gy lq ln l lo lp">      X, y = data</span><span id="5095" class="lk ll iq lg b gy lq ln l lo lp">      output = model_resnet18(X.view(-1, 3, 224, 224).cuda())</span><span id="e8a9" class="lk ll iq lg b gy lq ln l lo lp">      correct_sum = output.round().transpose(0, 1).cpu() == y</span><span id="80b2" class="lk ll iq lg b gy lq ln l lo lp">      correct += correct_sum.sum().item()</span><span id="f18d" class="lk ll iq lg b gy lq ln l lo lp">      total += len(y)</span><span id="e8ec" class="lk ll iq lg b gy lq ln l lo lp">print(f"Accuracy: {round(correct/total, 3)}")</span></pre><p id="40ad" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">测试该模型给出了97.3%的近似准确度，这明显优于CNN模型。</p><p id="0821" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">总而言之，这次测试的结果是显而易见的；出于几个原因，对许多图像识别任务使用预训练模型是有益的。</strong>第一个原因是，使用预训练模型需要较少的训练，并且在构建模型架构时需要较少的努力。相反，模型的定义是“免费的”另一个积极的方面是准确性。使用预先训练的模型比使用定制的卷积神经网络(CNN)要精确得多。因此，当执行图像识别任务时，从预先训练的模型开始是有意义的，因为这几乎总是最佳的行动过程。</p></div></div>    
</body>
</html>