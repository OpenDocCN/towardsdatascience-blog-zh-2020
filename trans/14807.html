<html>
<head>
<title>Grid search for parameter tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">参数调整的网格搜索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/grid-search-for-parameter-tunning-3c6ff94e7a25?source=collection_archive---------39-----------------------#2020-10-12">https://towardsdatascience.com/grid-search-for-parameter-tunning-3c6ff94e7a25?source=collection_archive---------39-----------------------#2020-10-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3579" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习这个简单易行的技术来调整你的机器学习模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bbe383e19803f631ce606ca049b72f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pcEFQ3v3ab20y-O5l7Tcfg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/users/pollydot-160618/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=337695" rel="noopener ugc nofollow" target="_blank"> PollyDot </a>来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=337695" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="7355" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">简介</strong></p><p id="5900" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦你建立了一个机器学习模型，你会想要调整它的参数以获得最佳性能。每个数据集的最佳参数是不同的，因此它们需要调整，以便算法可以获得其最大潜力。</p><p id="2c1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我见过很多初学数据的科学家用手做参数调优。这意味着运行模型，然后在笔记本中更改一个或多个参数，等待模型运行，收集结果，然后一次又一次地重复这个过程。通常，人们会在途中忘记哪些参数是最好的，他们需要重新做一次。</p><p id="9ba2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，上述策略并不是最高效的。幸运的是，由于sci-kit learn library的作者添加了GridSeachCV，这个过程可以很容易地自动化。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="1504" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">什么是GridSearchCV？</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mc"><img src="../Images/063276cf3746ad9c17f001fe83df0750.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7GXr5KQD7mMTMyQdfse3KQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1548260" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae ky" href="https://pixabay.com/users/ndv-2997446/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1548260" rel="noopener ugc nofollow" target="_blank"> Nicolás Damián Visceglio </a></p></figure><p id="d48d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GridSearchCV是我上面描述的简单方法的替代方法。不用手动调整参数并多次重新运行算法，您可以列出您希望算法尝试的所有参数值，并将其传递给GridSeachCV。</p><p id="3bb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GridSearchCV将尝试这些参数的所有组合，使用交叉验证和您提供的评分标准来评估结果。最终它会吐槽出最适合你数据集的参数。</p><p id="88fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GridSearchCV可以与sci-kit learn库中的任何监督学习机器学习算法一起使用。如果你提供一个合适的度量标准，它将同时适用于回归和分类。</p><p id="a2ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用一个真实的例子来看看它是如何工作的。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="e860" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> GridSearchCV代码示例</strong></p><p id="eaf0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了说明，让我们加载虹膜数据集。这个数据集有三种不同鸢尾物种的150个例子。数据集没有缺失值，因此不需要清理数据。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="7ff6" class="mi mj it me b gy mk ml l mm mn">from sklearn.datasets import load_iris<br/>import pandas as pd<br/>%matplotlib inline</span><span id="895d" class="mi mj it me b gy mo ml l mm mn">data = load_iris()<br/>df = pd.DataFrame(data['data'], columns=data['feature_names'])<br/>df['species'] = data['target']<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/c02770a9004e8dcd6661615b1d8f2bcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*fr-g4zeRG5K9OH3AThwqVQ.png"/></div></figure><p id="b2b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们将数据集划分为训练和测试。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="8990" class="mi mj it me b gy mk ml l mm mn">from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test = train_test_split(df.drop('species', axis=1), df.species ,test_size = 0.2, random_state=13)</span></pre><p id="d468" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们划分了数据集，我们就可以用我们选择的算法建立网格搜索。在我们的例子中，我们将使用它来调整随机森林分类器。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="fc3d" class="mi mj it me b gy mk ml l mm mn">from sklearn.model_selection import GridSearchCV<br/>from sklearn.ensemble import RandomForestClassifier</span><span id="f47e" class="mi mj it me b gy mo ml l mm mn">rfc = RandomForestClassifier()</span><span id="8cae" class="mi mj it me b gy mo ml l mm mn">grid_values = {'n_estimators': [10, 30, 50, 100],<br/>               'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],<br/>               'max_depth' : [4,5,6,7,8],<br/>              }</span><span id="7cd5" class="mi mj it me b gy mo ml l mm mn">grid_search_rfc = GridSearchCV(rfc, param_grid = grid_values, scoring = 'accuracy')<br/>grid_search_rfc.fit(x_train, y_train)</span></pre><p id="cd71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的代码中，我们首先通过使用不带参数的构造函数来设置随机森林分类器。然后，我们定义参数以及grid_values变量中每个参数的值。“grid_values”变量随后被传递给GridSearchCV，同时传递的还有随机森林对象(我们之前已经创建过)和评分函数的名称(在我们的例子中是“accuracy”)。最后，我们通过调用网格搜索对象上的fit函数来拟合它。</p><p id="6636" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在为了找到最佳参数，可以使用best_params_ attribute:</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="e663" class="mi mj it me b gy mk ml l mm mn">grid_search_rfc.best_params_</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/d45161fad196ed04519fd6a1b3dc2ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*7OY7PGrJ42-Q6uTcXRmyiw.png"/></div></figure><p id="ac84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用max_features参数的75 %的特征并使用10个估计器，我们得到了具有六层深度的树的最高准确度。</p><p id="0489" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这比手动尝试所有参数要容易得多。</p><p id="aa2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您可以使用网格搜索对象，使用最佳参数进行新的预测。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="bee2" class="mi mj it me b gy mk ml l mm mn">grid_search_rfc = grid_clf_acc.predict(x_test)</span></pre><p id="b85a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并在测试集上运行分类报告，以查看模型在新数据上的表现。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="c147" class="mi mj it me b gy mk ml l mm mn">from sklearn.metrics import classification_report<br/>print(classification_report(y_test, predictions))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/d7181312293d1bc6a6744ea18aa769db.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*SXVY1Tfr9y56n_VbBMVwFw.png"/></div></figure><p id="e8e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以看到所有类别的准确度、召回率、精确度和f分数的详细结果。</p><p id="8c0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，我们使用精确度来调整模型。这可能不是最好的选择。我们实际上可以使用其他指标，如精确度、召回率和f值。让我们开始吧。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="2e69" class="mi mj it me b gy mk ml l mm mn">from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score</span><span id="61c3" class="mi mj it me b gy mo ml l mm mn">scoring = {'accuracy': make_scorer(accuracy_score),<br/>           'precision': make_scorer(precision_score, average = 'macro'),<br/>           'recall': make_scorer(recall_score, average = 'macro'),<br/>           'f1': make_scorer(f1_score, average = 'macro')}</span><span id="f627" class="mi mj it me b gy mo ml l mm mn">grid_search_rfc = GridSearchCV(rfc, param_grid = grid_values, scoring = scoring, refit='f1')<br/>grid_search_rfc.fit(x_train, y_train)</span></pre><p id="9be3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的代码中，我们设置了四个评分标准:准确度、精确度、召回率和f-score，我们将它们存储在列表中，稍后作为评分参数传递给grid search。我们还将refit参数设置为等于评分函数之一。这是f-score是我们的情况。</p><p id="73c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们运行它，我们可以获得f-score的最佳参数:</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="627a" class="mi mj it me b gy mk ml l mm mn">grid_search_rfc.best_params_</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/e1909591388767c1da1989508605092a.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*jRYvOReWu74YQfQ7ZZY9SQ.png"/></div></figure><p id="3f92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我们可以使用cv_results_ attribute来了解有关grid_search设置的更多信息。</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="d7f7" class="mi mj it me b gy mk ml l mm mn">grid_search_rfc.cv_results_</span></pre><p id="a52c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想查看其他指标的结果，可以使用cv _ results[' mean _ test _【T0]']。因此，为了获得我们之前设置为评分函数之一的召回结果，您可以使用:</p><pre class="kj kk kl km gt md me mf mg aw mh bi"><span id="2f86" class="mi mj it me b gy mk ml l mm mn">grid_search_rfc.cv_results_['mean_test_recall']</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/32a32b6bf4c6b3118ee2362b44f886ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*Fa5tg2ktMnVKe5Gy8uIkSA.png"/></div></figure><p id="3bad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面我们可以看到网格搜索参数组合的所有召回值。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="d58f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> GridSearchCV缺点</strong></p><p id="3652" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你有没有注意到所有召回结果的清单很长？它实际上有100个元素。这意味着grid已经尝试了100种不同的参数组合。这非常多，而且非常耗时，尤其是在大型数据集上。</p><p id="71f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，grid search对100个不同的随机森林设置进行了五重交叉验证。想象一下，如果我们有更多的参数要调整！</p><p id="63ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GridSearchCV有一个替代方案叫做RandomizedSearchCV。它不是尝试所有参数，而是只从给定分布中采样参数的子集，因此可能更快更有效。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="fb3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">总结</strong></p><p id="3d4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，您了解了如何使用网格搜索来优化参数调整。是时候在不同的数据集上使用不同的模型而不是随机森林来尝试您新获得的技能了。编码快乐！</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="2f20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mu">最初发布于aboutdatablog.com: </em> <a class="ae ky" href="https://www.aboutdatablog.com/post/learn-how-to-use-grid-search-for-parameter-tunning" rel="noopener ugc nofollow" target="_blank">学习如何使用网格搜索进行参数整定</a>，<em class="mu">2020年10月8日。</em></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="81a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mu"> PS:我正在Medium和</em><a class="ae ky" href="https://www.aboutdatablog.com/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="mu">aboutdatablog.com</em></strong></a><em class="mu">上撰写以简单易懂的方式解释基本数据科学概念的文章。你可以订阅我的</em> <a class="ae ky" href="https://medium.com/subscribe/@konkiewicz.m" rel="noopener"> <strong class="lb iu"> <em class="mu">邮件列表</em> </strong> </a> <em class="mu">在我每次写新文章的时候得到通知。如果你还不是中等会员，你可以在这里加入</em><a class="ae ky" href="https://medium.com/@konkiewicz.m/membership" rel="noopener"><strong class="lb iu"><em class="mu"/></strong></a><em class="mu">。</em></p><p id="e435" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面还有一些你可能喜欢的帖子</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><div class="kj kk kl km gt mv"><a rel="noopener follow" target="_blank" href="/9-things-you-did-not-know-about-jupyter-notebook-d0d995a8efb3"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">关于jupyter笔记本你不知道的9件事</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">用这些建议提高你的工作效率</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj ks mv"/></div></div></a></div><div class="nk nl gp gr nm mv"><a rel="noopener follow" target="_blank" href="/best-data-science-books-be1ab472876d"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">最佳数据科学书籍</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">帮助您学习数据科学的前三本书</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="nn l ng nh ni ne nj ks mv"/></div></div></a></div><div class="nk nl gp gr nm mv"><a rel="noopener follow" target="_blank" href="/medium-writers-you-should-follow-as-an-aspiring-data-scientist-13d5a7e6c5dc"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">作为一名有抱负的数据科学家，你应该关注的中型作家</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">我最喜欢的10个数据科学博主，让你的学习之旅更轻松。</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="no l ng nh ni ne nj ks mv"/></div></div></a></div></div></div>    
</body>
</html>