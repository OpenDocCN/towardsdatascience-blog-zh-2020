<html>
<head>
<title>Understanding Deep Learning Models with Integrated Gradients</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解具有集成梯度的深度学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-deep-learning-models-with-integrated-gradients-24ddce643dbf?source=collection_archive---------7-----------------------#2020-11-04">https://towardsdatascience.com/understanding-deep-learning-models-with-integrated-gradients-24ddce643dbf?source=collection_archive---------7-----------------------#2020-11-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="19a7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解并实现各种深度学习网络的集成梯度技术，以解释模型的预测</h2></div><p id="a8e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">本帖将帮助你理解积分梯度的两个基本公理，以及如何使用迁移学习模型使用TensorFlow实现积分梯度。</em>T3】</strong></p><p id="4dc3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">什么是积分渐变？</em></p><blockquote class="lf"><p id="ccbe" class="lg lh it bd li lj lk ll lm ln lo ld dk translated">集成梯度(IG)是用于深度神经网络的可解释性或可解释性技术，其可视化了有助于模型预测的输入特征重要性</p></blockquote><p id="3c50" class="pw-post-body-paragraph ki kj it kk b kl lp ju kn ko lq jx kq kr lr kt ku kv ls kx ky kz lt lb lc ld im bi translated"><em class="le">IG可以只应用于深度学习的特定用例，还是只应用于特定的神经网络架构？</em></p><p id="2264" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">集成梯度(IG)计算模型预测输出到其输入特征<strong class="kk iu"> </strong>和<strong class="kk iu">的梯度，不需要对原始深度神经网络进行修改。</strong></p><p id="e441" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> IG可以应用于任何可区分的模型，如图像、文本或结构化数据。</strong></p><p id="2f7d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">IG可用于</p><ul class=""><li id="2253" class="lu lv it kk b kl km ko kp kr lw kv lx kz ly ld lz ma mb mc bi translated"><strong class="kk iu">通过从网络中提取规则来理解特征重要性</strong></li><li id="9369" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu">调试深度学习模型性能</strong></li><li id="644f" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu">通过理解对预测有贡献的重要特征来识别数据偏差</strong></li></ul><p id="f830" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">积分渐变是如何工作的？</em></p><p id="2461" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">解释IG使用深度学习模型进行图像分类</em> </strong></p><p id="e15e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">积分梯度建立在两个需要满足的公理之上:</strong></p><ol class=""><li id="385c" class="lu lv it kk b kl km ko kp kr lw kv lx kz ly ld mi ma mb mc bi translated"><strong class="kk iu">灵敏度和</strong></li><li id="3fc0" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld mi ma mb mc bi translated"><strong class="kk iu">实现不变性</strong></li></ol><h2 id="cf40" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">灵敏度:</h2><p id="672c" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">为了计算灵敏度，我们建立一个基线图像作为起点。然后，我们构建一系列图像，从基线图像插值到实际图像，以计算综合梯度。</p><h2 id="94d4" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">实现不变性</h2><p id="3bfe" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">当两个功能等效的网络对于相同的输入图像和基线图像具有相同的属性时，实现不变性被满足。</p><p id="fed4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当两个网络的输出对所有输入都相等时，尽管它们的实现非常不同，但它们在功能上是等效的。</p><h1 id="7447" class="nh mk it bd ml ni nj nk mo nl nm nn mr jz no ka mu kc np kd mx kf nq kg na nr bi translated">计算和可视化集成梯度(IG)</h1><p id="d9ba" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated"><strong class="kk iu">步骤1: </strong>从基线开始，基线可以是像素值全为零的黑色图像或全白图像，也可以是随机图像。基线输入是一种中性的预测，是任何解释方法和可视化像素要素重要性的核心。</p><p id="2a8b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第二步:</strong>生成基线和原始图像之间的线性插值。插值图像是基线和输入图像之间的特征空间中的小步长(α),并且随着每个插值图像的强度不断增加。</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi ns"><img src="../Images/61ec8944b1c8b720eb41a6e2927ad945.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mmFpzqDqMp3ADEt6gW88MQ.png"/></div></div></figure><p id="0628" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">步骤3:计算梯度以测量特征变化和模型预测变化之间的关系。</strong></p><p id="c3e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">梯度告知哪个像素对模型预测的类别概率具有最强的影响。</p><p id="c8ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">改变变量会改变输出，并且变量将获得一些属性来帮助计算输入图像的特征重要性。不影响输出的变量没有属性。</p><p id="5ce8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第四步:通过平均梯度计算数值近似值</strong></p><p id="da4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">步骤5:将IG缩放到输入图像</strong>以确保在多个插值图像上累积的属性值都是相同的单位。用像素重要性表示输入图像上的IG。</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/c234fb327ecdb798d0cea2488c44afe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*Due0LN7PqdhGN5sJw1sfOw.png"/></div></figure><p id="9af1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">如何使用Tensorflow实现积分渐变？</em></p><p id="fb2a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">导入所需的库</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="588a" class="mj mk it og b gy ok ol l om on"><strong class="og iu">import matplotlib.pylab as plt<br/>import numpy as np<br/>import tensorflow as tf<br/>import tensorflow_hub as hub<br/>from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_v2_preprocess_input</strong></span></pre><p id="ba5f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">使用MobileNetV2作为Imagenet数据集上的传输学习模型</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="4783" class="mj mk it og b gy ok ol l om on"><strong class="og iu">model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),                                               include_top=True,                                               weights='imagenet')</strong></span></pre><p id="9145" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">加载Imagenet标签</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="b143" class="mj mk it og b gy ok ol l om on"><strong class="og iu">def load_imagenet_labels(file_path):<br/>  labels_file = tf.keras.utils.get_file('ImageNetLabels.txt', file_path)<br/>  with open(labels_file) as reader:<br/>    f = reader.read()<br/>    labels = f.splitlines()<br/>  return np.array(labels)<br/>imagenet_labels = load_imagenet_labels('</strong><a class="ae oo" href="https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'" rel="noopener ugc nofollow" target="_blank"><strong class="og iu">https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'</strong></a><strong class="og iu">)</strong></span></pre><p id="f26c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">加载并预处理图像</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="3c1b" class="mj mk it og b gy ok ol l om on"><strong class="og iu">def read_image(file_name):<br/>  image = tf.io.read_file(file_name)<br/>  image = tf.image.decode_jpeg(image, channels=3)<br/>  image = tf.image.convert_image_dtype(image, tf.float32)  <br/>  image = tf.image.resize_with_pad(image, target_height=224, target_width=224)<br/>  return image</strong></span><span id="85c6" class="mj mk it og b gy op ol l om on"><strong class="og iu">img = {'Peacock':'Peacock.jpg'}</strong></span><span id="d9ab" class="mj mk it og b gy op ol l om on"><strong class="og iu">img_name_tensors = {name: read_image(img_path) for (name, img_path) in img.items()}</strong></span></pre><p id="1d95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">显示原始输入图像</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="bfc6" class="mj mk it og b gy ok ol l om on"><strong class="og iu">plt.figure(figsize=(5, 5))<br/>ax = plt.subplot(1, 1, 1)<br/>ax.imshow(img_name_tensors['Peacock'])<br/>ax.set_title("Image")<br/>ax.axis('off')<br/>plt.tight_layout()</strong></span></pre><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/89e75626b32cb6d84c93a019632d42fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*sHqfB0H1O8VKbRBy7Itviw.png"/></div></figure><p id="991b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">预测输入图像模型的前三个预测值</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="2e3e" class="mj mk it og b gy ok ol l om on"><strong class="og iu">def top_k_predictions(img, k=3):<br/>  image = tf.expand_dims(img, 0)<br/>  predictions = model(image)<br/>  probs = tf.nn.softmax(predictions, axis=-1)<br/>  top_probs, top_idxs = tf.math.top_k(input=probs, k=k)<br/>  top_labels = np.array(tuple(top_idxs[0]) )<br/>  return top_labels, top_probs[0]</strong></span><span id="1ec9" class="mj mk it og b gy op ol l om on">#Display the image with top 3 prediction from the model<br/><strong class="og iu">plt.imshow(img_name_tensors['Peacock'])<br/>plt.title(name, fontweight='bold')<br/>plt.axis('off')<br/>plt.show()</strong></span><span id="5e62" class="mj mk it og b gy op ol l om on"><strong class="og iu">pred_label, pred_prob = top_k_predictions(img_name_tensors['Peacock'])<br/>for label, prob in zip(pred_label, pred_prob):<br/>    print(f'{imagenet_labels[label+1]}: {prob:0.1%}')</strong></span></pre><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi or"><img src="../Images/6357b7c12b4ae1268a284f37a953aece.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*vEGu5Kubr3YFLTzOQcQkuA.png"/></div></figure><p id="9737" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">创建一个黑色基线图像，作为计算特征重要性的起点</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="a452" class="mj mk it og b gy ok ol l om on"><strong class="og iu">baseline = tf.zeros(shape=(224,224,3))</strong></span></pre><p id="334a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">生成基线和原始输入图像之间的线性插值</strong></p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi os"><img src="../Images/98755ab60ca7050d5b3e82c2ea5b1768.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*gpfln0SXter6_YdAilh5-Q.png"/></div><p class="ot ou gj gh gi ov ow bd b be z dk translated">图像插值</p></figure><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="45d1" class="mj mk it og b gy ok ol l om on"><strong class="og iu">m_steps=50<br/>alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)</strong> </span><span id="29e6" class="mj mk it og b gy op ol l om on"><strong class="og iu">def interpolate_images(baseline,<br/>                       image,<br/>                       alphas):<br/>  alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]<br/>  baseline_x = tf.expand_dims(baseline, axis=0)<br/>  input_x = tf.expand_dims(image, axis=0)<br/>  delta = input_x - baseline_x<br/>  images = baseline_x +  alphas_x * delta<br/>  return images</strong></span><span id="e423" class="mj mk it og b gy op ol l om on"><strong class="og iu">interpolated_images = interpolate_images(<br/>    baseline=baseline,<br/>    image=img_name_tensors['Peacock'],<br/>    alphas=alphas)</strong></span></pre><p id="5fdf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">可视化插值图像</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="6df3" class="mj mk it og b gy ok ol l om on"><strong class="og iu">fig = plt.figure(figsize=(20, 20))</strong></span><span id="b500" class="mj mk it og b gy op ol l om on"><strong class="og iu">i = 0<br/>for alpha, image in zip(alphas[0::10], interpolated_images[0::10]):<br/>  i += 1<br/>  plt.subplot(1, len(alphas[0::10]), i)<br/>  plt.title(f'alpha: {alpha:.1f}')<br/>  plt.imshow(image)<br/>  plt.axis('off')</strong></span><span id="1e16" class="mj mk it og b gy op ol l om on"><strong class="og iu">plt.tight_layout();</strong></span></pre><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi ox"><img src="../Images/76557e23425d52a684f783834d813a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e45adHdV2vguWDclnjnhfQ.png"/></div></div><p class="ot ou gj gh gi ov ow bd b be z dk translated">插值图像</p></figure><p id="1705" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">计算模型输出和插值输入之间的梯度</strong></p><p id="fb35" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">计算梯度<strong class="kk iu">测量特征变化和模型预测变化之间的关系。</strong>我们用<strong class="kk iu"> <em class="le"> tf。GradientTape </em> </strong>计算插值图像与顶部预测类Id之间的梯度，顶部预测类Id指示哪些像素对模型预测的影响最大</p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="39f8" class="mj mk it og b gy ok ol l om on"><strong class="og iu">def compute_gradients(images, target_class_idx):<br/>  with tf.GradientTape() as tape:<br/>    tape.watch(images)<br/>    logits = model(images)<br/>    probs = tf.nn.softmax(logits, axis=-1)[:, target_class_idx]<br/>  return tape.gradient(probs, images)</strong></span><span id="2534" class="mj mk it og b gy op ol l om on"><strong class="og iu">path_gradients = compute_gradients(<br/>    images=interpolated_images,<br/>    target_class_idx=84)</strong></span></pre><p id="dcd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">使用黎曼梯形累积梯度</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="034a" class="mj mk it og b gy ok ol l om on"><strong class="og iu">def integral_approximation(gradients):</strong><br/>  # riemann_trapezoidal<br/>  <strong class="og iu">grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)<br/>  integrated_gradients = tf.math.reduce_mean(grads, axis=0)<br/>  return integrated_gradients</strong></span></pre><p id="bc16" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将所有步骤放入一个函数中以计算积分梯度</p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="f519" class="mj mk it og b gy ok ol l om on"><a class="ae oo" href="http://twitter.com/tf" rel="noopener ugc nofollow" target="_blank"><strong class="og iu">@tf</strong></a><strong class="og iu">.function<br/>def integrated_gradients(baseline,<br/>                         image,<br/>                         target_class_idx,<br/>                         m_steps=50,<br/>                         batch_size=1):</strong><br/>  # 1. Generate alphas.<br/> <strong class="og iu"> alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)</strong></span><span id="72b9" class="mj mk it og b gy op ol l om on"># Initialize TensorArray outside loop to collect gradients.    <br/> <strong class="og iu"> gradient_batches = tf.TensorArray(tf.float32, size=m_steps+1)</strong><br/>    <br/>  # Iterate alphas range and batch computation for speed, memory #efficiency, and scaling to larger m_steps.<br/>  <strong class="og iu">for alpha in tf.range(0, len(alphas), batch_size):<br/>    from_ = alpha<br/>    to = tf.minimum(from_ + batch_size, len(alphas))<br/>    alpha_batch = alphas[from_:to]</strong></span><span id="a44e" class="mj mk it og b gy op ol l om on"># 2. Generate interpolated inputs between baseline and input.<br/>  <strong class="og iu">  interpolated_path_input_batch = interpolate_images(baseline=baseline,                                                       image=image,                                                       alphas=alpha_batch)</strong></span><span id="ebf9" class="mj mk it og b gy op ol l om on"># 3. Compute gradients between model outputs and interpolated inputs.<br/>    <strong class="og iu">gradient_batch = compute_gradients(images=interpolated_path_input_batch,                                       target_class_idx=target_class_idx)</strong><br/>    <br/>    # Write batch indices and gradients to extend TensorArray.<br/>    <strong class="og iu">gradient_batches = gradient_batches.scatter(tf.range(from_, to), gradient_batch)  </strong>  <br/>  <br/>  # Stack path gradients together row-wise into single tensor.<br/> <strong class="og iu"> total_gradients = gradient_batches.stack()</strong></span><span id="9f1d" class="mj mk it og b gy op ol l om on"># 4. Integral approximation through averaging gradients.<br/><strong class="og iu">  avg_gradients = integral_approximation(gradients=total_gradients)</strong></span><span id="46e3" class="mj mk it og b gy op ol l om on"># 5. Scale integrated gradients with respect to input.<br/>  <strong class="og iu">integrated_gradients = (image - baseline) * avg_gradients</strong></span><span id="63d2" class="mj mk it og b gy op ol l om on"><strong class="og iu">return integrated_gradients</strong></span><span id="9a32" class="mj mk it og b gy op ol l om on"><strong class="og iu">ig_attributions = integrated_gradients(baseline=baseline,                                       image=img_name_tensors['Peacock'],                                       target_class_idx=84,                                       m_steps=283)</strong></span></pre><p id="b3ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">可视化属性和综合梯度以解释对输入图像的预测</strong></p><pre class="nt nu nv nw gt of og oh oi aw oj bi"><span id="c302" class="mj mk it og b gy ok ol l om on"><strong class="og iu">def plot_img_IG(baseline,<br/>                          image,<br/>                          target_class_idx,<br/>                          m_steps=50,<br/>                          cmap=None,<br/>                          overlay_alpha=0.4):</strong></span><span id="cda7" class="mj mk it og b gy op ol l om on"><strong class="og iu">  attributions = integrated_gradients(baseline=baseline,                                          image=image,                                      target_class_idx=target_class_idx,                                      m_steps=m_steps)</strong></span><span id="736b" class="mj mk it og b gy op ol l om on"><strong class="og iu">  attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)</strong></span><span id="4560" class="mj mk it og b gy op ol l om on"><strong class="og iu">  fig, axs = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize=   (8, 8))<br/>  axs[0, 0].set_title('Attribution mask')<br/>  axs[0, 0].imshow(attribution_mask, cmap=cmap)<br/>  axs[0, 0].axis('off')</strong></span><span id="2020" class="mj mk it og b gy op ol l om on"><strong class="og iu">  axs[0, 1].set_title('Overlay IG on Input image ')<br/>  axs[0, 1].imshow(attribution_mask, cmap=cmap)<br/>  axs[0, 1].imshow(image, alpha=overlay_alpha)<br/>  axs[0, 1].axis('off')</strong></span><span id="9e35" class="mj mk it og b gy op ol l om on"><strong class="og iu">  plt.tight_layout()<br/>  return fig</strong></span><span id="635f" class="mj mk it og b gy op ol l om on"><strong class="og iu">_ = plot_img_IG(image=img_name_tensors['Peacock'],<br/>                          baseline=baseline,<br/>                          target_class_idx=84,<br/>                          m_steps=240,<br/>                          cmap=plt.cm.inferno,<br/>                          overlay_alpha=0.4)</strong></span></pre><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/91e9e1882a9001b2b010861f39b5fc74.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*9CzB_cpui1SMQKqeQx2C1A.png"/></div></figure><h2 id="0074" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">结论:</h2><p id="ddaa" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">集成梯度(IG)通过突出特征重要性来帮助你解释深度学习模型看什么来进行预测。这是通过计算模型的预测输出到其输入要素的梯度来实现的。它不需要对原始的深度神经网络进行任何修改，可以应用于图像、文本以及结构化数据。IG基于敏感性和实现不变性两个公理。</p><h2 id="0b3f" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">参考资料:</h2><p id="21cb" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated"><a class="ae oo" href="https://arxiv.org/pdf/1703.01365.pdf" rel="noopener ugc nofollow" target="_blank">深度网络的公理属性</a></p><div class="oz pa gp gr pb pc"><a href="https://www.tensorflow.org/tutorials/interpretability/integrated_gradients" rel="noopener  ugc nofollow" target="_blank"><div class="pd ab fo"><div class="pe ab pf cl cj pg"><h2 class="bd iu gy z fp ph fr fs pi fu fw is bi translated">集成梯度|张量流核心</h2><div class="pj l"><h3 class="bd b gy z fp ph fr fs pi fu fw dk translated">本教程演示了如何实现综合梯度(IG)，一个可解释的人工智能技术介绍了…</h3></div><div class="pk l"><p class="bd b dl z fp ph fr fs pi fu fw dk translated">www.tensorflow.org</p></div></div><div class="pl l"><div class="pm l pn po pp pl pq oc pc"/></div></div></a></div><p id="2e53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae oo" href="http://theoryy.stanford.edu/~ataly/Talks/sri_attribution_talk_jun_2017.pdf" rel="noopener ugc nofollow" target="_blank">http://theory y . Stanford . edu/~ ataly/Talks/Sri _ attribution _ talk _ jun _ 2017 . pdf</a></p></div></div>    
</body>
</html>