<html>
<head>
<title>Running Google’s Cloud Data Fusion batch pipelines at “scale”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“大规模”运行谷歌的云数据融合批处理管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/running-googles-cloud-data-fusion-batch-pipelines-at-scale-f1064b869dff?source=collection_archive---------30-----------------------#2020-11-03">https://towardsdatascience.com/running-googles-cloud-data-fusion-batch-pipelines-at-scale-f1064b869dff?source=collection_archive---------30-----------------------#2020-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f66f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="237d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">为数据科学工作流测试云数据融合</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/9afae6481aff04e5f8f6ad96b93b40f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kqAev7LW6IkIEiWvMHHI_w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">将数据从遗留sqlserver转移到BigQuery的典型CDF管道。作者图片</p></figure><p id="e157" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">TLDR:当通过REST api大规模提交批量云数据融合(CDF)管道时，在每次调用之间暂停几秒钟，让CDF跟上进度。</p><p id="c60e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">背景:作为我们参与的迁移的一部分，我们的数据科学团队正在将数百个遗留的MS Sqlserver ODS表迁移到BigQuery中。虽然我们的工程团队正在处理实际的迁移，但我们(DS团队)希望我们自己能够快速地在GCP构建、原型制作和迁移我们的模型，而无需等待我们的工程团队所承担的所有质量和范围广泛的要求。进入<a class="ae ma" href="https://cloud.google.com/data-fusion" rel="noopener ugc nofollow" target="_blank">谷歌的云数据融合</a>。基于<a class="ae ma" href="https://cdap.io/" rel="noopener ugc nofollow" target="_blank"> CDAP </a>，这是对我们团队问题的一个很好的解决方案:我们希望定期将遗留表复制到BigQuery中，以服务于我们的模型。我们，数据科学团队，完全控制调度和范围，CDF“无代码”接口使所有团队成员可以直接利用spark的能力。遵循一些简单的标准，很容易添加额外的管道。</p><p id="1276" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">问题:在迁移开始时，我们确定了要复制到BigQuery的所有表和源——基本上是迁移的范围。我们有大约100个表，我们构建了1个管道来迁移1个表，所以总共有大约100个管道。管道运行的节奏在每日和每月之间变化，大多数表介于两者之间。有一段时间一切都很好，直到我们构建了一个需要60个表同时加载的模型。我不会解释为什么我们要构建一个需要60个表的模型，而是强调这个需求是如何对云数据融合的可伸缩性进行有趣的测试的。</p><p id="99ec" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这一点上，我们都同意CDF不是同时执行60个管道的最佳工具，每个管道迁移一个表，其中许多在10分钟内完成，但这是我们发现自己所处的情况。CDF不太适合这项任务，原因有很多，其中一个原因是，它需要60个小型MR/spark集群来完成大部分10分钟的迁移任务。实际上，这些MR/spark集群(GCP的dataproc，AWS的e MR)的配置时间只有2-3分钟，成本实际上并不多。我们首先构建了一个管道列表，遍历该列表，并从GCE VM 通过CDAP的REST api在bash脚本中执行它们。虽然我们最终异步调度了这些任务，但是我们想证明我们可以同时执行这些任务，并且CDF可以根据我们的需求进行扩展。</p><p id="3197" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们最初的发现令我们失望。我们的脚本通过REST api在一秒左右的时间内执行了启动管道命令，在60个管道中，有25个失败了，几乎没有日志。当我们解析CDF的App Fabric服务日志时，我们遇到了一个有趣的错误:</p><blockquote class="mb mc md"><p id="b978" class="le lf me lg b lh li ka lj lk ll kd lm mf lo lp lq mg ls lt lu mh lw lx ly lz ij bi translated"><em class="iq">2020–10–30 22:27:34，715—WARN[pool-10-thread-1:I . c . c . I . a . s . runrecordcorrectorservice @ 148]—修复了25个状态为[正在启动、正在运行、已暂停]的运行记录，但程序实际上并未运行</em></p><p id="ba00" class="le lf me lg b lh li ka lj lk ll kd lm mf lo lp lq mg ls lt lu mh lw lx ly lz ij bi translated"><em class="iq">2020–10–30 22:27:34，716—INFO[pool-10-thread-1:I . c . c . I . a . s . runrecordcorrectorservice @ 103]—更正了25条状态为[正在启动、正在运行、已暂停]的运行记录，这些记录没有实际运行的程序。这类程序很可能已经崩溃或被外部信号杀死</em></p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mi"><img src="../Images/65093202be7362e8731a9e08b41fa294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vOutawSu7YCOOMaLRROudQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">一个dataproc集群，它托管了我们的一个失败的管道，成功的和失败的管道的集群在日志方面是相同的。作者图片</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mj"><img src="../Images/d06d747cdcc6e4d29fbcc3a0be6ab73d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y-Ef1WT-O0XqkqsHCxIcoA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">纱线容器数与时间。在下午6点以后，可以看到成功创建了dataproc集群。作者图片</p></figure><p id="3dfc" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">虽然CDF收到了60个“执行管道”api调用，但它错过了25个运行记录。有趣的是，当我们查看dataproc日志时，我们发现它成功地创建了60个集群。也就是说，我们观察到成功创建的集群，甚至是托管失败管道的集群——这帮助我们认识到，我们在创建dataproc集群时没有可伸缩性问题，而是在创建CDF“主”时有问题。问题在于CDF的簿记/跟踪，而不是dataproc集群的创建。作为数据科学家，而不是工程师或架构师，我们对这是如何工作的知识有限，但我们假设当我们在大约1秒钟内用60个api调用淹没系统时，我们过载了使用的任何跟踪数据库。我们再次尝试在每个api调用之间添加一些填充。我们发现，等待大约10秒钟会导致所有60个管道执行调用被成功提交和执行。虽然不是最优雅的解决方案，但它为我们完成了工作，因此我们可以考虑其他事情，这在数据科学中非常重要。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><p id="e054" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">更新:我们已经探索并正在我们的工程团队的Cloud Composer实例上执行和调度这些带有气流的管道，但是当昂贵而复杂的编排资源不可用时，上面概述的方法仍然是一个可靠的选择。</p></div></div>    
</body>
</html>