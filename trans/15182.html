<html>
<head>
<title>Creating a class-based TF-IDF with Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scikit-Learn创建基于类的TF-IDF</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-a-class-based-tf-idf-with-scikit-learn-caea7b15b858?source=collection_archive---------12-----------------------#2020-10-19">https://towardsdatascience.com/creating-a-class-based-tf-idf-with-scikit-learn-caea7b15b858?source=collection_archive---------12-----------------------#2020-10-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/5dd8f5344b1a5f6ed34354fa8176f9ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uZHfU9RrQjOHW3nUH83geQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者与<a class="ae jg" href="https://www.woordwolk.nl/" rel="noopener ugc nofollow" target="_blank">https://www.woordwolk.nl/</a>一起创作</p></figure><h2 id="5291" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph">自然语言处理</h2><div class=""/><div class=""><h2 id="df83" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">提取每个类别的信息词</h2></div><p id="66c4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在我之前的一篇帖子中，我谈到了与<strong class="lj jt"> BERT </strong> 的<a class="ae jg" href="https://github.com/MaartenGr/BERTopic" rel="noopener ugc nofollow" target="_blank">主题建模，其中涉及到一个基于</a><a class="ae jg" href="https://github.com/MaartenGr/cTFIDF" rel="noopener ugc nofollow" target="_blank">类的版本<strong class="lj jt"> TF-IDF </strong> </a>。这个版本的TF-IDF允许我从一组文档中提取有趣的主题。</p><p id="f95f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我认为深入一点这个方法可能会很有趣，因为它可以用于更多的应用，而不仅仅是主题建模！</p><p id="c670" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">可能的应用概述:</p><ul class=""><li id="f48d" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated"><strong class="lj jt">每个班级的信息词汇</strong>:哪些词汇让一个班级与众不同？</li><li id="750a" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><strong class="lj jt">类别减少:</strong>使用c-TF-IDF减少类别数量</li><li id="8ac3" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><strong class="lj jt">半监督建模:</strong>仅使用余弦相似度和c-TF-IDF来预测未见过的文档的类别</li></ul><p id="0d88" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">本文将主要讨论<code class="fe mr ms mt mu b"><strong class="lj jt">c-TF-IDF</strong></code>的应用，但也会给出一些模型的背景。</p><p id="3b72" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果你想跳过所有这些，直接进入<strong class="lj jt">代码</strong>你可以从回购<a class="ae jg" href="https://github.com/MaartenGr/cTFIDF" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jt">这里</strong> </a> <strong class="lj jt">开始。</strong></p><h1 id="6c45" class="mv mw jj bd mx my mz na nb nc nd ne nf ky ng kz nh lb ni lc nj le nk lf nl nm bi translated">基于类的TF-IDF</h1><p id="e567" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">在探讨这种基于类的TF-IDF的可能性之前，让我们先看看TF-IDF是如何工作的，以及我们需要采取哪些步骤来将其转换为c-TF-IDF。</p><h2 id="733b" class="ns mw jj bd mx nt nu dn nb nv nw dp nf lq nx ny nh lu nz oa nj ly ob oc nl jp bi translated">TF-IDF</h2><p id="fc41" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">TF-IDF是一种从文本文档生成特征的方法，它是两种方法相乘的结果:</p><ul class=""><li id="f31c" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">词频(<strong class="lj jt"> TF </strong>)</li><li id="a0ca" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">逆文档频率(<strong class="lj jt"> IDF </strong>)</li></ul><p id="dd69" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="od">词频</em>仅仅是文档中的原始字数，其中每个字数被认为是一个特征。</p><p id="3dcb" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="od">逆文档频率</em>通过计算一个单词在一个文档中的频率与它在所有其他文档中的频率相比，来提取<strong class="lj jt">某些单词的信息量</strong>。</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/5bb017ae1fbb3eb0511d24b858126189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x8JmPE7LXtvWpPJeBbUHPg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">逆文档频率。此处检索到<a class="ae jg" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"/>。</p></figure><p id="e5f8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你可以想象诸如<code class="fe mr ms mt mu b">the</code>、<code class="fe mr ms mt mu b">and</code>、<code class="fe mr ms mt mu b">I</code>等词语。是非常常见的单词，但包含的信息非常少，因为它们几乎出现在每个文档中。逆文档频率惩罚过于常见的单词。</p><p id="04b1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">结果是一个稀疏的特征矩阵，可用于特征提取、预测建模和文档相似性。</p><h2 id="81c6" class="ns mw jj bd mx nt nu dn nb nv nw dp nf lq nx ny nh lu nz oa nj ly ob oc nl jp bi translated">将TF-IDF转化为c-TF-IDF</h2><p id="0680" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">基于类的TF-IDF的目标是为单个类中的所有文档提供相同的<strong class="lj jt">类向量</strong>。为了做到这一点，我们必须开始从基于类的角度而不是单个文档的角度来看待TF-IDF。</p><p id="5d1d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果文档不是个体，而是一个更大的集体的一部分，那么通过将所有文档<strong class="lj jt">加入到一个类中，实际上把它们看作个体可能会很有趣。</strong></p><p id="972f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">结果将是一个非常长的文档，它本身实际上是不可读的。想象一下阅读一份由10 000页组成的文档！</p><p id="a6ab" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然而，这允许我们开始从基于类的角度来看待TF-IDF。</p><p id="b035" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后，不是将TF-IDF应用于新创建的长文档，我们必须考虑到，自从我们合并文档以来，TF-IDF将采用类的数量而不是文档的数量。</p><p id="85b0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对TF-IDF的所有这些更改导致以下公式:</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/79ad8ad5e7d01b5d589af60f7eba9fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IIiWxVq6QqDz6ise"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片由作者提供。</p></figure><p id="2ee2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">其中为每个类别<code class="fe mr ms mt mu b"><strong class="lj jt">i</strong></code>提取每个单词<code class="fe mr ms mt mu b"><strong class="lj jt">t</strong></code>的<strong class="lj jt">频率</strong>并除以单词总数<code class="fe mr ms mt mu b"><strong class="lj jt">w</strong></code>。这个动作可以看作是对课堂上常用词的一种正则化形式。接下来，未连接的文档总数<code class="fe mr ms mt mu b"><strong class="lj jt">m</strong></code>除以所有类别<code class="fe mr ms mt mu b"><strong class="lj jt">n</strong></code>中单词<code class="fe mr ms mt mu b"><strong class="lj jt">t</strong></code>的总频率。</p><h2 id="7f13" class="ns mw jj bd mx nt nu dn nb nv nw dp nf lq nx ny nh lu nz oa nj ly ob oc nl jp bi translated">密码</h2><p id="131f" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">当我在BERT 帖子的<a class="ae jg" rel="noopener" target="_blank" href="/topic-modeling-with-bert-779f7db187e6">主题建模中介绍c-TF-IDF时，我使用了一种低效的方法来计算c-TF-IDF。</a></p><p id="0c4f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">从那以后，我创建了一个c-TF-IDF版本，它不仅允许大幅加速，而且还利用了T21 Scikit-Learn中的TFidfTransformer，它允许我们使用sci kit-Learn提供的稳定性。</p><figure class="of og oh oi gt iv"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="25bc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如你所看到的，我们从<code class="fe mr ms mt mu b">TfidfTransformer</code>开始，只采用拟合和变换的方法使其成为<code class="fe mr ms mt mu b">CtfidfVectorizer</code>。矢量器接收包含原始计数数据的稀疏矩阵。</p><p id="38b3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">创建c-TF-IDF矩阵的最基本示例如下:</p><figure class="of og oh oi gt iv"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="de18" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们确保类中的所有文档在通过CountVectorizer之前被合并在一起，以计算最终通过CTFIDFVectorizer的原始计数数据。</p><p id="04eb" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">注</strong>:通过<code class="fe mr ms mt mu b">CTFIDFVectorizer</code>的<code class="fe mr ms mt mu b">n_samples</code>是未接合<strong class="lj jt">单据的总数。这是必要的，因为如果通过的是<strong class="lj jt">合并的</strong>文档数，IDF值会变得太小。</strong></p><h1 id="5715" class="mv mw jj bd mx my mz na nb nc nd ne nf ky ng kz nh lb ni lc nj le nk lf nl nm bi translated">应用程序</h1><p id="de6b" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">如前所述，c-TF-IDF大概有三种使用情况:</p><ul class=""><li id="83e5" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">与其他所有的单词相比，哪些单词是某一特定类别的典型单词？</li><li id="3fb2" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">如何才能减少使用c-TF-IDF的班级数量？</li><li id="257d" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">如何在预测建模中使用c-TF-IDF？</li></ul><h2 id="d650" class="ns mw jj bd mx nt nu dn nb nv nw dp nf lq nx ny nh lu nz oa nj ly ob oc nl jp bi translated">每类信息词</h2><p id="2c10" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">与TF-IDF相比，c-TF-IDF的独特之处在于我们可以采用它来搜索组成特定类别的单词。</p><p id="a660" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果我们有一个被标记为<strong class="lj jt"> space </strong>的类，那么我们会期望找到与空间相关的单词，对吗？</p><p id="f3d1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为此，我们只需提取c-TF-IDF矩阵，并找出每类中的最高值:</p><figure class="of og oh oi gt iv"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi om"><img src="../Images/55aaf5fdd5dda094f11ab043f8dd8bcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vuhc1f3uKBpkoIiX_fq2Jw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">每类中价值最高的单词。图片由作者提供。</p></figure><p id="0585" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不出所料，这些单词很好地代表了它们所属的类别。您可以将此c-TF-IDF过程视为该课程内容的总结。</p><h2 id="b0ce" class="ns mw jj bd mx nt nu dn nb nv nw dp nf lq nx ny nh lu nz oa nj ly ob oc nl jp bi translated">班级缩减</h2><p id="8081" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">有时，拥有多个类可能不利于清晰的分析。您可能需要一个更全面的概述来了解数据中的主要类。</p><p id="ec89" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">幸运的是，我们可以使用c-TF-IDF将类的数量减少到您想要的任何值。</p><p id="af1f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以通过将所有类别的c-TF-IDF向量相互比较来做到这一点，以便合并最相似的类别:</p><figure class="of og oh oi gt iv"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/3b05d3c221e972cd8949979b991d8ea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xce9EF8WWxBUlOLF4sFvLA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">在合并之前提取最相似的类。图片由作者提供。</p></figure><p id="956c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在c-TF-IDF向量上使用余弦相似性似乎有效！我们正确地发现，类<code class="fe mr ms mt mu b">atheism</code>和<code class="fe mr ms mt mu b">christian</code>可以合并成我们所谓的<code class="fe mr ms mt mu b">religion</code>。我们发现<code class="fe mr ms mt mu b">autos</code>和<code class="fe mr ms mt mu b">motorcycles</code>的结果相似，它们可以组合在一起。</p><p id="1ad0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">使用这种方法，我们可以选择最相似的类，只要它们足够相似，就可以进行组合。</p><h2 id="6ac7" class="ns mw jj bd mx nt nu dn nb nv nw dp nf lq nx ny nh lu nz oa nj ly ob oc nl jp bi translated">半监督建模</h2><p id="73a7" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">使用c-TF-IDF，我们甚至可以直接执行半监督建模，而不需要预测模型。</p><p id="76bb" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们首先为训练数据创建一个c-TF-IDF矩阵。结果是每个类的一个向量，它应该代表那个类的内容。最后，我们检查以前未见过的数据，该向量与所有类别的向量有多相似:</p><figure class="of og oh oi gt iv"><div class="bz fp l di"><div class="ok ol l"/></div></figure><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oo"><img src="../Images/4a558f6da3c9dda7eae6f1fbff48e090.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9HZhcBWIGJgvfAOd_x9GQ.png"/></div></div></figure><p id="e508" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">虽然我们可以看到结果没有什么值得大书特书的，准确率大约为<strong class="lj jt"> 50% </strong> …这个准确率比随机猜测的类别<strong class="lj jt"> 5%要好得多。</strong></p><p id="e58f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在没有任何复杂的预测模型的情况下，我们设法用一个快速且相对简单的模型获得了相当不错的准确性。我们甚至没有对数据进行预处理！</p><h1 id="292c" class="mv mw jj bd mx my mz na nb nc nd ne nf ky ng kz nh lb ni lc nj le nk lf nl nm bi translated">感谢您的阅读！</h1><p id="e3fc" class="pw-post-body-paragraph lh li jj lj b lk nn kt lm ln no kw lp lq np ls lt lu nq lw lx ly nr ma mb mc im bi translated">如果你像我一样，对人工智能、数据科学或心理学充满热情，请随时在<a class="ae jg" href="https://www.linkedin.com/in/mgrootendorst/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上添加我，或者在<a class="ae jg" href="https://twitter.com/MaartenGr" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我。</p><p id="4a4a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">本文中的所有示例和代码都可以在这里找到:</p><div class="is it gp gr iu op"><a href="https://github.com/MaartenGr/cTFIDF" rel="noopener  ugc nofollow" target="_blank"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd jt gy z fp ou fr fs ov fu fw js bi translated">MaartenGr/cTFIDF</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">c-TF-IDF是一个基于类的TF-IDF过程，可用于根据文本文档生成特征…</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">github.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd ja op"/></div></div></a></div></div></div>    
</body>
</html>