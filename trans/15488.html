<html>
<head>
<title>How to bring your modern data pipeline to production</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将您的现代数据管道投入生产</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-bring-your-modern-data-pipeline-to-production-2f14e42ac200?source=collection_archive---------13-----------------------#2020-10-25">https://towardsdatascience.com/how-to-bring-your-modern-data-pipeline-to-production-2f14e42ac200?source=collection_archive---------13-----------------------#2020-10-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="608c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Azure DevOps、Databricks Spark、Cosmos DB Gremlin API和Azure Data Factory</h2></div><h1 id="6a37" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">A.介绍</h1><p id="6787" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">创建数据管道是一回事；将其投入生产是另一个问题。对于使用多种服务进行高级分析的现代数据管道来说，尤其如此。例如将非结构化数据转换为结构化数据、训练ML模型和嵌入OCR。多种服务的集成可能很复杂，并且必须控制生产部署。在这篇博客中，提供了一个示例项目如下:</p><ul class=""><li id="7303" class="lw lx it lc b ld ly lg lz lj ma ln mb lr mc lv md me mf mg bi translated">1.为连续部署设置Azure DevOps项目</li><li id="8f80" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated">2.使用基础设施作为代码部署数据管道的Azure资源</li><li id="84d4" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated">3.运行和监控数据管道</li></ul><p id="bc81" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">项目的<a class="ae mp" href="https://github.com/rebremer/blog-datapipeline-cicd" rel="noopener ugc nofollow" target="_blank">代码</a>可以在这里找到，现代数据管道的步骤描述如下。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mq"><img src="../Images/5646da5d9b6d5d50b4ddf2ad4762fb4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xxtjirlOFlmCJc3hyx1ung.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">1.高级数据流，作者图像</p></figure><p id="6e45" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">这个项目的结构将在下一章讨论。随后，提供了如何部署和运行项目的教程。如果你想学习如何将数据科学项目投入生产，请参见我之前的<a class="ae mp" rel="noopener" target="_blank" href="/how-to-bring-your-data-science-project-in-production-b36ae4c02b46">博客</a>。</p><h1 id="8e8f" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">B.体系结构</h1><p id="c315" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这个项目中，流行的Azure服务的功能被结合起来，以创建一个现代化的数据管道。数据管道的主要资源如下:</p><ul class=""><li id="2b33" class="lw lx it lc b ld ly lg lz lj ma ln mb lr mc lv md me mf mg bi translated"><strong class="lc iu"> Azure数据工厂(ADFv2) </strong> : ADFv2允许你大规模移动数据。ADFv2自带90个连接器，并具有许多企业就绪功能，如托管身份(MI)、自托管集成运行时(IR)以连接本地数据源、<a class="ae mp" href="https://docs.microsoft.com/en-us/azure/data-factory/managed-virtual-network-private-endpoint" rel="noopener ugc nofollow" target="_blank">VNET中的Azure IR</a>以及git/Azure DevOps集成。转换可以在ADFv2中使用数据流来完成，更复杂的转换可以在ADFv2中使用Azure Databricks来编排。另请参见<a class="ae mp" href="https://demoignitemdwstor.blob.core.windows.net/demo30video/transforming_and_enriching_data.mp4" rel="noopener ugc nofollow" target="_blank">我的视频</a>了解ADFv2的运行情况。</li><li id="3b61" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated"><strong class="lc iu">Azure data bricks</strong>:data bricks是一个托管的Spark环境，使您能够大规模转换数据。Azure Databricks在Azure中作为PaaS服务提供，并与Azure AD集成。可以从ADFv2协调笔记本电脑</li><li id="9e88" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated"><strong class="lc iu">Cosmos DB Gremlin API</strong>:Cosmos DB是一个完全托管的多数据库服务，使您能够在全球范围内构建高度响应的应用程序。作为Cosmos DB的一部分，graph数据库支持Gremlin。</li><li id="2887" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated"><strong class="lc iu"> Azure存储</strong> : ADLSgen2可以让你以低成本存储你无限量的数据。它还支持使用RBAC和/或Posix的细粒度访问控制。</li></ul><p id="23dc" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">数据管道的内部工作和资源整合如下:</p><ul class=""><li id="1d01" class="lw lx it lc b ld ly lg lz lj ma ln mb lr mc lv md me mf mg bi translated"><strong class="lc iu">数据流</strong>:使用ADFv2将数据从csv转换为ADLSgen2中的parquet。随后，ADFv2触发Databrick笔记本，从ADLSgen2读取数据，并根据拼花数据创建图表。最后，Databricks使用Gremlin API将数据写入Cosmos DB</li><li id="3a53" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated"><strong class="lc iu">访问</strong> : ADFv2托管身份(MI)用于访问ADLSgen2中的数据。ADFv2 MI还用于Azure数据块来触发笔记本。Azure Databricks使用一个secret scope来检索可以访问ADLSgen2以读取parquet数据的服务主体和可以访问Cosmos DB以写入图形数据的密钥。数据块秘密范围可以由数据块或Azure密钥库支持(参见下面详细架构中的步骤3b2)</li><li id="a0ea" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated"><strong class="lc iu">防火墙:</strong>adlsgen 2和AKV防火墙中启用了可信的微软服务，这样ADFv2 MI就可以访问。此外，Databricks VNET被列入ADLSgen2和AKV防火墙的白名单，所有其他流量均被拒绝。只有VNET的数据被列入了Cosmos DB防火墙的白名单。</li></ul><p id="11c2" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">另请参见下面的详细架构。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi ng"><img src="../Images/cbb7b1d84095fa4660be8288992fb455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TWGTfox9tguTskkyloBEyg.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">B.高层建筑，详细，作者图片</p></figure><h1 id="3ace" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">C.部署和运行现代数据管道</h1><p id="9a5f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这一章中，项目开始运行，现代数据管道使用b章中描述的体系结构。</p><ul class=""><li id="29b8" class="lw lx it lc b ld ly lg lz lj ma ln mb lr mc lv md me mf mg bi translated">C0。先决条件</li><li id="7544" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated">C1。设置Azure DevOps项目</li><li id="9bf6" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated">C2。部署Azure资源</li><li id="cbd3" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated">C3。监控数据管道</li></ul><h2 id="8cee" class="nh kj it bd kk ni nj dn ko nk nl dp ks lj nm nn ku ln no np kw lr nq nr ky ns bi translated">C0。先决条件</h2><p id="2384" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">本教程需要以下资源:</p><ul class=""><li id="6703" class="lw lx it lc b ld ly lg lz lj ma ln mb lr mc lv md me mf mg bi translated"><a class="ae mp" href="https://azure.microsoft.com/en-us/free/" rel="noopener ugc nofollow" target="_blank"> Azure账户</a></li><li id="17bb" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated"><a class="ae mp" href="https://visualstudio.microsoft.com/team-services/" rel="noopener ugc nofollow" target="_blank">蔚蓝DevOps </a></li><li id="f8c0" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated"><a class="ae mp" href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest" rel="noopener ugc nofollow" target="_blank"> Azure CLI </a>(推荐，也用于故障排除)</li></ul><p id="6aaa" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">最后，转到Azure门户并创建一个资源组，所有Azure资源都将部署在该资源组中。这也可以使用以下Azure CLI命令来完成:</p><pre class="mr ms mt mu gt nt nu nv nw aw nx bi"><span id="452e" class="nh kj it nu b gy ny nz l oa ob">az group create -n &lt;&lt;your resource group&gt;&gt; -l &lt;&lt;your location&gt;&gt;</span></pre><h2 id="737d" class="nh kj it bd kk ni nj dn ko nk nl dp ks lj nm nn ku ln no np kw lr nq nr ky ns bi translated">C1。设置Azure DevOps项目</h2><p id="4e30" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">Azure DevOps是一个工具，可以持续地构建、测试和部署你的代码到任何平台和云。按照本教程<a class="ae mp" href="https://docs.microsoft.com/en-us/azure/devops/organizations/projects/create-project?view=azure-devops&amp;tabs=preview-page&amp;viewFallbackFrom=vsts" rel="noopener ugc nofollow" target="_blank">在Azure DevOps中创建新项目。创建新项目后，单击存储库文件夹并选择导入以下存储库:</a></p><pre class="mr ms mt mu gt nt nu nv nw aw nx bi"><span id="8896" class="nh kj it nu b gy ny nz l oa ob"><a class="ae mp" href="https://github.com/rebremer/blog-datapipeline-cicd" rel="noopener ugc nofollow" target="_blank">https://github.com/rebremer/blog-datapipeline-cicd</a></span></pre><p id="b87d" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">另请参见下图:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi oc"><img src="../Images/f995e7f8a9c22d1701fbefb0cb251880.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*N4czC4i7tgclry5T.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">C1.1将存储库添加到您的Azure DevOps项目中，图片由作者提供</p></figure><p id="5ed1" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">从Azure DevOps访问资源组中的资源需要服务连接。转到项目设置，服务连接，然后选择Azure资源管理器，另见下图。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi od"><img src="../Images/17cd7013d03dfd6345109e45c533e52f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ieWW2S8BGU9n6bBx.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">C1.2按作者创建服务连接、图像</p></figure><p id="72bf" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">选择服务主体身份验证，并将范围限制到您之前创建的资源组，另请参见下图。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi oe"><img src="../Images/866da9368741e509136aa45e83064b60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8DnO_09-JWdqRDN62Y6ejw.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">C1.3将范围限制为资源组，按作者分类的图像</p></figure><p id="303e" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">默认情况下，服务连接的服务主体(SPN)拥有资源组的参与者权限。但是，对于此管道，SPN需要对资源组的所有者权限(或贡献者旁边的附加用户访问管理员权限)，因为ADFv2 MI需要获得对ADLSgen2帐户的RBAC权限。在Azure DevOps中点击你的服务连接上的“管理服务主体”时，可以找到应用id。使用以下Azure CLI脚本向SPN分配所有者权限(也可以在门户中完成):</p><pre class="mr ms mt mu gt nt nu nv nw aw nx bi"><span id="1567" class="nh kj it nu b gy ny nz l oa ob"># get your subscriptioin id<br/>az account list<br/># create role<br/>az role assignment create --assignee "&lt;&lt;application id&gt;&gt;" --role "Owner" --scope "/subscriptions/&lt;&lt;your subscription Id&gt;&gt; /resourcegroups/&lt;&lt;resource group name&gt;&gt;"</span></pre><p id="15d1" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">最后，验证SPN是否在Azure门户中或使用下面的CLI命令为您的资源组分配了所有者角色。</p><pre class="mr ms mt mu gt nt nu nv nw aw nx bi"><span id="17d9" class="nh kj it nu b gy ny nz l oa ob">az role assignment list --resource-group <!-- -->&lt;&lt;resource group name&gt;&gt;</span></pre><h2 id="b7bb" class="nh kj it bd kk ni nj dn ko nk nl dp ks lj nm nn ku ln no np kw lr nq nr ky ns bi translated">C2。部署Azure资源</h2><p id="43ea" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">转到您的Azure DevOps项目，选择管道，然后单击“新建管道”。转到向导，选择您之前创建的Azure Repos Git和git repo。在“配置”选项卡中，选择“现有Azure Pipelines YAML文件”,然后选择可以在git repo中找到的azure-pipelines.yml，另请参见下文。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi of"><img src="../Images/9d3857a2c4a12a6e1a90278e98938257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K4VFi8ziARnZvUZZ5jM0bQ.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">C2.1 .在管道配置向导中，选择现有的Azure管道YAML文件，按作者排序的图像</p></figure><p id="98f5" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">随后，需要用您自己的值替换以下变量:</p><pre class="mr ms mt mu gt nt nu nv nw aw nx bi"><span id="6b44" class="nh kj it nu b gy ny nz l oa ob">variables: <br/>  # Azure DevOps settings<br/>  AzureServiceConnectionId: '&lt;&lt;your service connection name&gt;&gt;'<br/>  # Change environment variables used in bash scripts with your own<br/>  RG: 'blog-datapipelineprod-rg'  <br/>  SUB: '&lt;&lt;your subscription&gt;&gt;' <br/>  AKV: 'blogdatapipelineakv123' # unique value <br/>  STOR: 'blogdatapipelinestor123' # unique value<br/>  COSMOSDBNAME: 'blog-datapipeline-cosmos123' #unique value<br/>  DBRWORKSPACE: 'blog-datapipeline-dbr123' #unique value</span></pre><p id="cbb5" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">一旦变量被替换，管道就被创建并立即运行，见下文</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi og"><img src="../Images/89859d4d3e193d1415c92c6724a8bad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TFBYiwTTFZeZd9P6xOLPaA.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">C2.2 Azure DevOps部署现代数据管道，作者图片</p></figure><p id="0b7f" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">当一切都部署好了，你会看到下图:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi oh"><img src="../Images/9aa0f977754e588f8f5f6537bf59e0af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TKT6Zp4eWWjklxj6_0mpbQ.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">C2.3成功部署，作者图片</p></figure><h2 id="5b12" class="nh kj it bd kk ni nj dn ko nk nl dp ks lj nm nn ku ln no np kw lr nq nr ky ns bi translated">C3。监控数据管道</h2><p id="289b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">azure-pipelines.yml的最后一步是执行ADFv2管道。这样做是为了建立一个端到端的示例，但是，ADFv2管道通常不是从Azure DevOps触发的，而是使用ADFv2自己的schedular或企业使用的另一个调度程序。Azure数据工厂管道运行可以在ADFv2 monitor pipelines选项卡中进行验证，另请参见下图。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi oi"><img src="../Images/f2dab0ac7aa9cf43568dbb72e9136c1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YTCIPwf0EnlhaRxEdznxCg.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">c 3.1 . ADF v2管道成功运行，作者提供图像</p></figure><p id="c2d1" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">Azure Databricks笔记本向Cosmos DB Graph API添加数据。当您在门户中打开Azure Cosmos DB帐户时，在防火墙规则中启用从门户的访问，然后转到数据浏览器，这可以被验证，见下文。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi oj"><img src="../Images/6868bdc5d9e3f2c8b02dbfc7bbaa2f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pkYTyC2C0NMbQ_dx_R1X8g.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">c 3.2 . cosmos db gremlin API中的图形数据，图片由作者提供</p></figure><h1 id="e94b" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">D.结论</h1><p id="bb8d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">创建数据管道是一回事；将其投入生产是另一个问题。对于使用多种服务进行高级分析的现代数据管道来说，尤其如此。在这个博客中，提供了以下内容:</p><ul class=""><li id="23d1" class="lw lx it lc b ld ly lg lz lj ma ln mb lr mc lv md me mf mg bi translated">Azure DevOps管道可以控制Azure Databricks、Azure Data Factory和Azure Cosmos DB的部署和集成</li><li id="312d" class="lw lx it lc b ld mh lg mi lj mj ln mk lr ml lv md me mf mg bi translated">Architecute和<a class="ae mp" href="https://github.com/rebremer/blog-datapipeline-cicd" rel="noopener ugc nofollow" target="_blank"> Github项目</a>将csv文件转换为parquet，创建图形数据并将其存储在Cosmos DB Gremlin中</li></ul><p id="c107" class="pw-post-body-paragraph la lb it lc b ld ly ju lf lg lz jx li lj mm ll lm ln mn lp lq lr mo lt lu lv im bi translated">该示例项目可用于将您的现代数据管道投入生产，参见下面的架构。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi ng"><img src="../Images/cbb7b1d84095fa4660be8288992fb455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TWGTfox9tguTskkyloBEyg.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">D.高层建筑，详细，作者图片</p></figure></div></div>    
</body>
</html>