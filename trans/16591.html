<html>
<head>
<title>Complete Introduction to PySpark- Part 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PySpark完整介绍-第3部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/complete-introduction-to-pyspark-part-3-9c06e2c5e13d?source=collection_archive---------57-----------------------#2020-11-15">https://towardsdatascience.com/complete-introduction-to-pyspark-part-3-9c06e2c5e13d?source=collection_archive---------57-----------------------#2020-11-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4e15" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用PySpark对数据集执行SQL操作</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b91066c14b2d5cbfae699df3c9fee9ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2toNcag7x2v6qqA8"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">弗兰基·查马基在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="0eba" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是SQL(结构化查询语言)？</h1><p id="3814" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">SQL是一种用于对数据执行不同操作的语言，如存储、操作和检索。它在关系数据库上工作，在关系数据库中数据以行和列的形式存储。</p><p id="6ead" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">根据属性，SQL命令可以分为三种类型:</p><ol class=""><li id="dbbf" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated"><strong class="lt iu"> DDL(数据定义语言)</strong></li></ol><p id="c9b8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">顾名思义，DDL命令用于定义数据。DDL中包含的命令有创建、插入、截断、删除等。</p><p id="5404" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> 2。DML(数据操作语言)</strong></p><p id="a62e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">数据操作命令用于根据用户要求改变和更新数据。DDL下定义的一些命令是ALTER、UPDATE、DELETE等。</p><p id="6c32" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> 3。数据控制语言</strong></p><p id="616a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这种情况下，定义的命令用于控制对定义的数据库的访问。其中定义的一些命令有GRANT、REVOKE等。</p><h1 id="95eb" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">将PySpark用于SQL操作</h1><p id="6dba" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了使用PySpark执行SQL操作，我们需要在本地机器上安装PySpark。如果你已经安装了它，我们就可以开始了，或者通过下面的链接来安装PySpark，并使用PySpark在DataFrame上执行一些基本操作。</p><div class="nb nc gp gr nd ne"><a href="https://medium.com/python-in-plain-english/complete-introduction-to-pyspark-part-1-7d16d7c62cc9" rel="noopener follow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd iu gy z fp nj fr fs nk fu fw is bi translated">PySpark完整介绍</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">第1部分:从头开始在Windows上安装PySpark</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">medium.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns ks ne"/></div></div></a></div><div class="nb nc gp gr nd ne"><a rel="noopener follow" target="_blank" href="/complete-introduction-to-pyspark-part-2-135d2f2c13e2"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd iu gy z fp nj fr fs nk fu fw is bi translated">PySpark完整介绍-第2部分</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">使用PySpark进行探索性数据分析</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">towardsdatascience.com</p></div></div><div class="nn l"><div class="nt l np nq nr nn ns ks ne"/></div></div></a></div><h1 id="dd44" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">加载所需的库</h1><p id="7d0a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我们的机器上安装了pyspark并对其进行配置之后，我们将打开一个jupyter笔记本来启动SQL操作。我们将从导入所需的库和创建PySpark会话开始。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="e1c2" class="nz la it nv b gy oa ob l oc od">import findspark<br/>findspark.init()</span><span id="592f" class="nz la it nv b gy oe ob l oc od">import pyspark # only run after findspark.init()<br/>from pyspark.sql import SparkSession<br/>from pyspark.sql import SQLContext<br/>spark = SparkSession.builder.getOrCreate()</span></pre><h1 id="4488" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">加载数据集</h1><p id="8829" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了执行SQL操作，我们需要一个数据集。在本文中，我们将使用波士顿数据集，它可以使用Kaggle轻松下载，并将使用PySpark加载它。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="6529" class="nz la it nv b gy oa ob l oc od">df = spark.read.csv('Boston.csv', inferSchema=True, header=True)<br/>df.show(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/0be8c2cc0e806eadbf3b6835ee0a82ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n2F3HKyni3mlvlzE7Y9rLA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集(来源:作者)</p></figure><p id="42f4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，让我们开始对数据集执行SQL操作，我们将首先创建一个表和一个SQLContext对象，它将用于在该表上运行查询。</p><h2 id="d3ef" class="nz la it bd lb og oh dn lf oi oj dp lj ma ok ol ll me om on ln mi oo op lp oq bi translated"><strong class="ak"> 1。正在创建表格</strong></h2><p id="9275" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了创建一个表，我们需要使用PySpark的register函数。类似地，我们还将创建一个SQLContext对象，用于在表上运行查询。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="0bf8" class="nz la it nv b gy oa ob l oc od">df.registerTempTable('BostonTable')<br/>sqlContext = SQLContext(spark)</span></pre><h2 id="69dc" class="nz la it bd lb og oh dn lf oi oj dp lj ma ok ol ll me om on ln mi oo op lp oq bi translated">2.选择查询</h2><p id="e117" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">选择查询用于根据用户需求选择数据。我们可以使用“*”选择整个表，或者我们可以传递用“，”分隔的列的名称，这是我们想要看到的。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="cb96" class="nz la it nv b gy oa ob l oc od">#Select Whole Table(only three records because we used show(3))<br/>sqlContext.sql('select * from BostonTable').show(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/35d6267da5288786f8380371991ea161.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LcN-nbynFDsROjJrd_a9IA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">选择表格(来源:作者)</p></figure><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="7b4a" class="nz la it nv b gy oa ob l oc od">#Select column using column names<br/>sqlContext.sql('select _c0, CRIM, ZN, INDUS, CHAS from BostonTable').show(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/8fd72e857a23238ec34519d65949ad99.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*2TIuQdoeKZfP6kWXySEhlg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">选择列(来源:按作者)</p></figure><h2 id="3c29" class="nz la it bd lb og oh dn lf oi oj dp lj ma ok ol ll me om on ln mi oo op lp oq bi translated">3.聚合函数</h2><p id="3edb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">SQL中定义了一些预定义的聚合函数，可用于根据用户需求选择数据。这些功能是:</p><p id="ce13" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">a.min()<br/>b . max()<br/>c . count()<br/>d . sum()<br/>e . var()<br/>等。</p><p id="7412" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面给出了下列函数的语法。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="c0de" class="nz la it nv b gy oa ob l oc od">#Using max functions<br/>sqlContext.sql('select max(AGE) from BostonTable').show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/5705591955d316fef8d12e4a1d3639c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*8SQVa66JweNHY9GQYXJ_6g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">max函数(来源:作者)</p></figure><p id="ce4d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">同样，我们可以根据用户需求使用其他函数来显示输出。</p><h2 id="680e" class="nz la it bd lb og oh dn lf oi oj dp lj ma ok ol ll me om on ln mi oo op lp oq bi translated">4.条件查询</h2><p id="107c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">通过使用条件查询，我们可以生成符合用户传递的特定条件的输出。使用最多的条件表达式是“where”。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="a019" class="nz la it nv b gy oa ob l oc od">sqlContext.sql('select CRIM, NOX, B from BostonTable where B = 396.9').show(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/2640c5399e593b5ec971dc1562da591e.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*EWloZG6rzM7CHWJ-3E5ltw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">条件数据(来源:作者)</p></figure><p id="886a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们可以在条件查询中使用不同的支持函数，这有助于更具体地了解输出，并有助于在单个查询中运行多个条件。这些功能是:</p><p id="e302" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">a.具有<br/> b .和<br/> c .或<br/> d .然后<br/> e .(用于范围)<br/>等。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="4fc8" class="nz la it nv b gy oa ob l oc od">sqlContext.sql('select CRIM, NOX, B, RAD from BostonTable where RAD &gt; 2 and B = 396.9').show(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/5e8a4600fdd31db27dcb132b1b2ab688.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*lOW44Navmi_LbH7pDT-SVg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">条件表达式(来源:作者)</p></figure><p id="08c6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">类似地，我们可以使用上面给出的相同语法来使用不同的函数。</p><h2 id="ccbe" class="nz la it bd lb og oh dn lf oi oj dp lj ma ok ol ll me om on ln mi oo op lp oq bi translated">5.嵌套查询</h2><p id="8429" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们可以在同一行代码中运行多个查询，这通常称为嵌套查询。这是一种复杂的查询形式，我们根据用户需求传递不同的条件来生成输出。下面给出了一个嵌套查询的例子。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="1b47" class="nz la it nv b gy oa ob l oc od">sqlContext.sql('select * from BostonTable where AGE between 40 and 50 and TAX not in (311,307)').show(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/cc67debec06d9977631b7d4f4b005e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KA5DLXodPQb51k1WEOFreQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">嵌套查询(来源:作者)</p></figure><p id="3615" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">同样，您可以根据需要的输出尝试不同的嵌套查询。</p><p id="a6b2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">本文为您提供了关于使用PySpark进行SQL查询的基本信息。继续尝试这些，如果你遇到任何困难，请在回复部分告诉我。</p><h1 id="4a39" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">在你走之前</h1><p id="4535" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu"> <em class="ow">感谢</em> </strong> <em class="ow">阅读！如果你想与我取得联系，请随时在hmix13@gmail.com上联系我或我的</em> <a class="ae ky" href="http://www.linkedin.com/in/himanshusharmads" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> <em class="ow"> LinkedIn个人资料</em> </strong> </a> <em class="ow">。可以查看我的</em><a class="ae ky" href="https://github.com/hmix13" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu"><em class="ow">Github</em></strong><em class="ow"/></a><em class="ow">简介针对不同的数据科学项目和包教程。还有，随意探索</em> <a class="ae ky" href="https://medium.com/@hmix13" rel="noopener"> <strong class="lt iu"> <em class="ow">我的简介</em> </strong> </a> <em class="ow">阅读我写过的与数据科学相关的不同文章。</em></p></div></div>    
</body>
</html>