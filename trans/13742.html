<html>
<head>
<title>Airbnb Price Prediction: Multilayer Perceptrons with TensorFlow’s Keras API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Airbnb价格预测:多层感知器与TensorFlow的Keras API</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/airbnb-price-prediction-multilayer-perceptrons-with-tensorflows-keras-api-9096e7d0c340?source=collection_archive---------32-----------------------#2020-09-21">https://towardsdatascience.com/airbnb-price-prediction-multilayer-perceptrons-with-tensorflows-keras-api-9096e7d0c340?source=collection_archive---------32-----------------------#2020-09-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="33a9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">这个项目是我在深度学习领域的第一步，使用TensorFlow和Keras开发了一个回归模型，能够尽可能低地用MAE进行价格预测。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1820f1c5d54aa1ac9975e6d08c81fa61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aRJE8p9q4dO_lUfW"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">泰勒·维克在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="a923" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">语境</strong></h1><p id="ddc5" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">当我在希望成为数据科学家的旅程中第一次遇到深度学习时，它是一个难以消化的领域。我最初之所以偏见地假设它令人困惑的复杂性，是因为这一领域的潜在逻辑和机制。然而，在花了一些时间来吸收深度学习的巨大适用性，特别是神经网络之后，我开始对利用它来解决数据科学问题产生兴趣。</p><p id="12b0" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">在进入这个项目之前，我想提请注意机器学习和深度学习之间的激烈比较<strong class="lx ir"><em class="mw"/></strong>这可能已经闪过我们的脑海，至少一次。本质上，当机器学习使用算法解码中到大规模的数据来做出决策时，深度学习创建了多层神经网络，需要更长的时间来训练，以产生更高精度的模型。</p><p id="5b8d" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">如果你热衷于尝试深度学习，请随意查看Kaggle <a class="ae kv" href="https://www.kaggle.com/stevezhenghp/airbnb-price-prediction" rel="noopener ugc nofollow" target="_blank">在此</a>公开分享的数据集，并关注以下内容。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="dcbf" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">1.解释数据分析</h1><p id="a4e0" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated"><em class="mw">作为一名数据分析师/数据科学家，在数据可用于建模之前，我们70%的时间都花在了数据清理和准备上。</em></p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="a420" class="nc le iq my b gy nd ne l nf ng">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="9be0" class="nc le iq my b gy nh ne l nf ng">df = pd.read_csv("airbnb-price-prediction.csv")</span><span id="87c6" class="nc le iq my b gy nh ne l nf ng">df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/d6ab772b44b03f8b2a6edeff1b2de13d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KqCk-1OxdMnO8pUcI1Xwiw.png"/></div></div></figure><p id="0d66" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">注意</strong> : <em class="mw">由于本文的重点是开发神经网络模型，我将只介绍EDA中的重要操作，但是您可以在本文末尾的Github库中查看完整的EDA。</em></p><p id="3ba4" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">在加载数据集后，立即给我留下深刻印象的是“便利设施”变量，它嵌入了每行的非结构化值。如果它被构造成一个JSON字段，对我们来说将它展平并将每个子变量解析到不同的列中会更容易。然而，根据我的观察，该变量包括每个列表的不同娱乐项目，因此为了使其更有用，我决定<strong class="lx ir">格式化值并合并唯一的值</strong>以计算每个列表的娱乐项目占总数的百分比:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="e3d9" class="nc le iq my b gy nd ne l nf ng">df.amenities = df.amenities.map(lambda x: "|".join([i.replace("}", "").replace("{", "").replace('"', "") for i in x.split(",")])</span><span id="fa27" class="nc le iq my b gy nh ne l nf ng">df.amenities = df.amenities.map(lambda x: x.split("|")</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/f5228305e21fe1ecca7c1e312d867b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LB_ISOdynfn6Zw2LhKxILg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">df.map()</p></figure><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="a252" class="nc le iq my b gy nd ne l nf ng">amenities_list = list(np.unique(np.concatenate(df.amenities))[1:-2])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/ffe096610201ad14f03acadf631dc858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q2CvtWR11bZSXt0hO4rftQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">唯一的()</p></figure><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="06d7" class="nc le iq my b gy nd ne l nf ng">df['amenities_percentage'] = df.amenities.apply(lambda x: len(x)/len(amenities_list)*100)</span></pre><p id="fd1f" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">然后，我继续进行<strong class="lx ir">检查是否有空值</strong>来删除或填充实际值:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="d74e" class="nc le iq my b gy nd ne l nf ng">df_new.isna().sum()</span><span id="d999" class="nc le iq my b gy nh ne l nf ng">#Removing null values that would not help the modelling</span><span id="b4cd" class="nc le iq my b gy nh ne l nf ng">df_new = df_new[df_new.bathrooms.notna()]<br/>df_new = df_new[df_new.bedrooms.notna()]<br/>df_new = df_new[df_new.beds.notna()]<br/>df_new = df_new[df_new.host_since.notna()]</span><span id="f820" class="nc le iq my b gy nh ne l nf ng">#Fill null values with actual values</span><span id="9bcd" class="nc le iq my b gy nh ne l nf ng">df_new.host_response_rate = df_new.host_response_rate.fillna("0%")<br/>df_new.review_scores_rating = df_new.review_scores_rating.fillna(0)</span></pre><p id="5bf5" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">此外，正如我们可能都知道的，异常值对建模过程相对敏感，所以我们应该<strong class="lx ir">小心地处理异常值</strong>(移除或转换)，以便模型可以更有效地学习数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/3de140acecd39a019338655add1ba5f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DzGTHdD7HXsQaSeFDcER8Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">sns.boxplot(df_new.price)</p></figure><p id="cc99" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">由于价格变量遵循高斯分布，我们将创建一个函数来移除超出固定范围的异常值:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="0dc0" class="nc le iq my b gy nd ne l nf ng">from numpy import mean<br/>from numpy import std</span><span id="fcae" class="nc le iq my b gy nh ne l nf ng">def remove_outliers(x):<br/>    data_mean = mean(x)<br/>    data_std = std(x)<br/>    cutoff = data_std*3<br/>    lower = data_mean - cutoff<br/>    upper = data_mean + cutoff<br/>    return lower, upper</span><span id="0e29" class="nc le iq my b gy nh ne l nf ng">lower, upper = remove_outliers(df_new.price)</span><span id="c77f" class="nc le iq my b gy nh ne l nf ng">df_new = df_new.loc[(df_new.price &gt; lower) &amp; (df_new.price &lt; upper)]</span></pre></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="c5e5" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">2.特征工程和缩放</h1><p id="6855" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated"><em class="mw">类似于机器学习的建模，特征工程有助于预处理和转换原始数据集为更易消化的数据集，以训练模型。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/4afd92f652c49a8c50228dd6feeb6e1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FagGZh_x1aLhcVsPVjR_HQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">df.head()</p></figure><p id="1cf7" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">除了那些数字变量，我们需要转换模型可以理解和学习的分类变量。简而言之，我们将对二进制和多类变量分别应用不同的技术:<strong class="lx ir">标签编码器和OneHotEncoder </strong>。然而，在进行任何预处理步骤之前，我们<strong class="lx ir"> <em class="mw">必须始终将数据集分为训练集和测试集</em> </strong>，以避免建模期间的数据泄漏。</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="43e1" class="nc le iq my b gy nd ne l nf ng">from sklearn.model_selection import train_test_split</span><span id="7097" class="nc le iq my b gy nh ne l nf ng">x = df_new.iloc[:, 1:-1]<br/>y = df_new.iloc[:, -1]</span><span id="3e51" class="nc le iq my b gy nh ne l nf ng">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)</span></pre><p id="9a36" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">然后，我们为转换导入标签编码器和OneHotEncoder:在训练集上拟合并在两者上转换。</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="a2d7" class="nc le iq my b gy nd ne l nf ng">from sklearn.preprocessing import LabelEncoder, OneHotEncoder</span><span id="36c2" class="nc le iq my b gy nh ne l nf ng"><strong class="my ir">#Binary variables</strong></span><span id="d54b" class="nc le iq my b gy nh ne l nf ng">le = LabelEncoder()</span><span id="03a8" class="nc le iq my b gy nh ne l nf ng">binary_var = ['cleaning_fee', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']</span><span id="95c9" class="nc le iq my b gy nh ne l nf ng">for i in binary_var:<br/>    le.fit(x_train[i])<br/>    x_train[i] = le.transform(x_train[i])<br/>    x_test[i] = le.transform(x_test[i])</span><span id="e0e2" class="nc le iq my b gy nh ne l nf ng"><strong class="my ir">#Multi-category variables</strong></span><span id="71a2" class="nc le iq my b gy nh ne l nf ng">oe = OneHotEncoder(sparse=False, handle_unknown = 'error')</span><span id="3bb5" class="nc le iq my b gy nh ne l nf ng">oe.fit(x_train[['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'city']])</span><span id="e4e9" class="nc le iq my b gy nh ne l nf ng">#Transform the train set</span><span id="e567" class="nc le iq my b gy nh ne l nf ng">multi = oe.transform(x_train[['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'city']])<br/>df_multi = pd.DataFrame(index = x_train.index, data=multi, columns=oe.get_feature_names(['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'city']))<br/>x_train = pd.concat([x_train, df_multi], axis=1)<br/>x_train.drop(columns=['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'city'], inplace=True)</span><span id="a74c" class="nc le iq my b gy nh ne l nf ng">#Transform the test set</span><span id="8ea0" class="nc le iq my b gy nh ne l nf ng">multi_test = oe.transform(x_test[['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'city']])<br/>df_multi_test = pd.DataFrame(index = x_test.index, data=multi_test, columns=oe.get_feature_names(['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'city']))<br/>x_test = pd.concat([x_test, df_multi_test], axis=1)<br/>x_test.drop(columns=['property_type', 'room_type', 'bed_type', 'cancellation_policy', 'city'], inplace=True)</span></pre><p id="4fc0" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">此外，由于每个变量都有不同的数据范围，我们需要对独立变量进行缩放，以便模型可以更快、更有效地学习数据。在这种情况下，我选择了<strong class="lx ir">最小最大缩放器</strong>将数据压缩到(0，1)的范围内，这对我们将在下一节中使用的算法很有用:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="e686" class="nc le iq my b gy nd ne l nf ng">from sklearn.preprocessing import MinMaxScaler</span><span id="a6f7" class="nc le iq my b gy nh ne l nf ng">mn = MinMaxScaler()</span><span id="c3b4" class="nc le iq my b gy nh ne l nf ng">x_train_scaled = pd.DataFrame(mn.fit_transform(x_train), columns = x_train.columns)<br/>x_test_scaled = pd.DataFrame(mn.fit_transform(x_test), columns = x_test.columns)</span></pre><p id="c31e" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">好了，我们都准备好了！</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="5f7b" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">3.神经网络建模</h1><p id="f3e1" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated"><em class="mw">什么是神经网络，为什么我们需要同时结合建模和优化？</em></p><p id="5df8" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">在进入什么是神经网络之前，我想强调一下我们不能停留在建模阶段的惯例；更确切地说，<strong class="lx ir"> <em class="mw">这是一个建立模型和测试不同参数</em> </strong>的连续过程，以产生最高精度的模型。</p><p id="7cf5" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">回到神经网络的概念，简而言之:</p><blockquote class="nm nn no"><p id="8217" class="lv lw mw lx b ly mr jr ma mb ms ju md np mt mg mh nq mu mk ml nr mv mo mp mq ij bi translated">神经网络是一系列算法，通过模拟人脑运行方式的过程，努力识别一组数据中的潜在关系。——投资媒体。</p></blockquote><p id="b5c9" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">如果你想更深入地了解这个概念，请点击这里查看3Blue1Brown <a class="ae kv" href="https://www.youtube.com/watch?v=aircAruvnKk&amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi" rel="noopener ugc nofollow" target="_blank">的一系列视频，这些视频对神经网络的底层项目提供了全面的解释。</a></p><p id="1182" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">在深度学习中，特别是神经网络，我们使用3种常见的标准模型来进行预测:<strong class="lx ir">多层感知器(MLP) </strong>、<strong class="lx ir">卷积神经网络(CNN) </strong>和<strong class="lx ir">递归神经网络(RNN) </strong>。对于这个项目，我已经从MLP开始，以获得深度学习的基本概念，但请关注我即将开展的项目，这些项目用更先进的模型解决数据科学问题。</p><p id="dee9" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">那么，MLP到底是什么，它在预测方面做了什么？</p><p id="ed65" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">根据定义，</p><blockquote class="nm nn no"><p id="51b1" class="lv lw mw lx b ly mr jr ma mb ms ju md np mt mg mh nq mu mk ml nr mv mo mp mq ij bi translated">多层感知器模型，简称MLP，是一个标准的全连接神经网络模型。它由节点层组成，每个节点连接到前一层的所有输出，每个节点的输出连接到下一层节点的所有输入。—Machinelearningmastery.com</p></blockquote><p id="0a69" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">为了更容易可视化，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/958c47d0de420e2b9a64d4350f18b488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HdgZYIbLq06G7Up8.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来源:ResearchGate</p></figure><p id="2eb4" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">TensorFlow和Keras是一个开源库，能够执行深度学习中的各种任务，即回归和分类。由于其复杂性，需要遵循几个步骤:</p><ol class=""><li id="f176" class="nt nu iq lx b ly mr mb ms me nv mi nw mm nx mq ny nz oa ob bi translated">定义模型</li><li id="55d7" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">编译模型</li><li id="f0e2" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">符合模型</li><li id="5aa3" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">评估模型</li><li id="9c32" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">做一个预测</li></ol><p id="8810" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">为了更详细地解释，让我们看一下MLP模型的全步骤实现，如下所示:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="e873" class="nc le iq my b gy nd ne l nf ng">from tensorflow.keras import Sequential<br/>from tensorflow.keras.layers import Dense, Dropout<br/>from tensorflow.keras.callbacks import EarlyStopping</span><span id="56df" class="nc le iq my b gy nh ne l nf ng"><strong class="my ir">#Step1. Define the model</strong></span><span id="500e" class="nc le iq my b gy nh ne l nf ng">model = Sequential()</span><span id="e6a8" class="nc le iq my b gy nh ne l nf ng">model.add(Dense(16, activation = 'relu', kernel_initializer = 'he_normal', input_shape = (x_train_scaled.shape[1],)))<br/>model.add(Dense(8, activation = 'relu', kernel_initializer = 'he_normal'))<br/>model.add(Dense(1))</span><span id="ad9b" class="nc le iq my b gy nh ne l nf ng"><strong class="my ir">#Step2. Compile the model</strong></span><span id="4d43" class="nc le iq my b gy nh ne l nf ng">model.compile(optimizer = 'adam', loss = 'mse', metrics = 'mae')</span><span id="5402" class="nc le iq my b gy nh ne l nf ng"><strong class="my ir">#Step3. Fit the model</strong></span><span id="be8b" class="nc le iq my b gy nh ne l nf ng">history = model.fit(x_train_scaled, y_train, validation_data=(x_test_scaled, y_test), epochs=50,batch_size=64, verbose=0)</span><span id="6d59" class="nc le iq my b gy nh ne l nf ng"><strong class="my ir">#Step4.1 Evaluate the model</strong></span><span id="df01" class="nc le iq my b gy nh ne l nf ng">loss, mae = model.evaluate(x_test_scaled, y_test)</span><span id="45a2" class="nc le iq my b gy nh ne l nf ng"><strong class="my ir">#Step4.2 Plot the learning curve</strong></span><span id="167e" class="nc le iq my b gy nh ne l nf ng">plt.plot(history.history['loss'], label='train')<br/>plt.plot(history.history['val_loss'], label='val')<br/>plt.show()</span></pre><p id="8c2d" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">(1)-定义模型:</p><ul class=""><li id="d4db" class="nt nu iq lx b ly mr mb ms me nv mi nw mm nx mq oh nz oa ob bi translated"><strong class="lx ir">模型类型</strong>:我们可以从TensorFlow中选择<strong class="lx ir">顺序或功能模型API </strong>。虽然顺序模型是实现起来最简单的模型，它以线性方式提供了一个一层接一层的“顺序”路径，但是功能模型是一个更复杂且更灵活的模型，它需要我们手动指定输入和输出层。</li><li id="3333" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq oh nz oa ob bi translated"><strong class="lx ir">节点数量</strong>:这取决于你希望你的模型有多复杂。没有“一刀切”的选择，而是我们需要测试和学习，看看每层有多少节点产生最高的准确性。</li><li id="c602" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq oh nz oa ob bi translated"><strong class="lx ir">激活</strong>:对于每层中的每个节点，神经网络计算输入的加权和(并添加一个偏差)，然后决定是否应该“激活”该节点。这意味着加权总和应该超过某个阈值，节点才会被“激活”。为了找到边界，我们需要确定激活函数来帮助定义边界的上限和下限。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/4ea29e3e6792624f73afb747657abb99.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/0*PNlGpyWCRf1p8Bs0.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来源:StackExchange</p></figure><ul class=""><li id="d77b" class="nt nu iq lx b ly mr mb ms me nv mi nw mm nx mq oh nz oa ob bi translated"><strong class="lx ir">初始化器</strong>:如上所述，初始化器帮助定义设置输入层初始随机权重(w)的方式。有许多不同的初始化器适合不同的激活函数，我们将在下面的内容中测试它们。</li></ul><p id="1558" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">(2)-编译模型:</p><ul class=""><li id="085e" class="nt nu iq lx b ly mr mb ms me nv mi nw mm nx mq oh nz oa ob bi translated"><strong class="lx ir">优化器</strong>:优化器帮助改变神经网络的属性(例如，权重、学习率等。)以便尽可能减少模型的损失。类似于激活和初始化器，有一些优化器我们应该测试一下，看看哪个产生的模型精度最高。</li><li id="0737" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq oh nz oa ob bi translated"><strong class="lx ir">损失</strong>:顾名思义，损失函数表示模型为了减少误差而采用的优化方法。从技术上讲，损失用于计算梯度，梯度用于更新神经网络的权重。</li><li id="48f3" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq oh nz oa ob bi translated"><strong class="lx ir">指标</strong>:根据我们构建的模型类型(例如回归、分类)，我们将选择相关的指标来评估模型的训练情况(例如回归的MAE/MSE/RMSE和分类的准确性)</li></ul><p id="0c51" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">(3)-拟合模型:</p><ul class=""><li id="211c" class="nt nu iq lx b ly mr mb ms me nv mi nw mm nx mq oh nz oa ob bi translated"><strong class="lx ir">时期</strong>:时期的数量是训练集中整个例子的完整次数。例如，如果我们将历元数设置为5，这意味着在模型产生最终结果之前，训练集将循环5次。</li><li id="d066" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq oh nz oa ob bi translated"><strong class="lx ir"> Batch_size </strong>:批次大小是在模型更新之前，用于估计模型误差的一个时期中的样本数。例如，如果我们将批量大小设置为32，这意味着训练集的32个样本将用于训练模型和更新模型。然后，将使用接下来的32个样本，直到在一个时期中没有留下任何样本。如果我们有1个以上的历元，将重复该过程。</li></ul><p id="7147" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">(4)-评估模型:</p><ul class=""><li id="0b54" class="nt nu iq lx b ly mr mb ms me nv mi nw mm nx mq oh nz oa ob bi translated"><strong class="lx ir">。evaluate() </strong>:我们将在测试集上调用这个函数，打印出错误值以及我们希望模型优化的指标。</li><li id="fe2b" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq oh nz oa ob bi translated"><strong class="lx ir">学习曲线</strong>:我建议我们应该为我们测试的每个模型绘制学习曲线，因为重要的是要看到模型在每个时期是如何被训练的，以及模型是过拟合还是欠拟合。</li></ul><p id="ee57" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">好了，这是我们在神经网络中应该熟悉的所有核心参数。现在让我们打印出上面第一次试验模型的结果和学习曲线。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/553373f5b9eedfc0226823ba7b8ad482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FPToVwBoQy8qrsCcbUIgbw.png"/></div></div></figure><p id="7c65" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">如所见，我们通过上述模型的设置实现了0.3356的MAE。让我们将这个数字作为基准，看看我们是否可以在优化模型时获得更小的MAE。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><h1 id="0775" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">4.神经网络优化</h1><p id="b61a" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">下面是我将使用的所有优化方法的快速总结，供您参考:</p><ol class=""><li id="a91f" class="nt nu iq lx b ly mr mb ms me nv mi nw mm nx mq ny nz oa ob bi translated">具有特征选择的神经网络(相关热图/PCA)</li><li id="3414" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">具有附加层的神经网络(增加模型复杂性)</li><li id="f720" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">具有不同优化器的神经网络</li><li id="d8ae" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">具有更高纪元的神经网络(早期停止)</li><li id="b8d5" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">正则化神经网络(辍学和L1/L2)</li><li id="b8f3" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">具有不同激活和初始化的神经网络</li><li id="1da0" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">批量较小的神经网络</li></ol><p id="a4d9" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">对于(1)方法，我想看看减少独立变量(特征)的数量或选择更重要的变量是否有助于改进模型。我依赖的两个选项是关联热图(手动选择)和PCA(机器学习选择):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/194f6e71c9a67f35ed0e134d2baea811.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*Mvbt5PqLmv324A-6L80sCQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">df.corr()</p></figure><p id="e159" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">正如你所看到的，并不是所有的特征都与基于色阶的目标变量(价格)高度相关。因此，我只选择了与目标有更好相关性的变量(高度正/负)，但似乎模型并没有改进得更好:MAE &gt;基准。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/0e416739141e00db88fdf44351f8758c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zO6wd_weDtpAuIP4as8qAw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">具有关联热图的模型:MAE = 0.3544(&gt;基准= 0.3356)</p></figure><p id="1b5b" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">使用PCA，模型也没有改善多少，但是该模型的MAE优于我们手动选择的特征:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/71d980a8f0eedc49138cba21cbba835d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bhxwuWN3KjLGTj9oXw80NQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">带PCA的模型:MAE = 0.3475(&gt;基准= 0.3356)</p></figure><p id="21ce" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">对于(2)方法，我想看看<strong class="lx ir">通过增加几个额外的层</strong>来增加模型的复杂性是否有助于降低MAE值。</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="71a5" class="nc le iq my b gy nd ne l nf ng">#Step1. Define the model4</span><span id="5c1a" class="nc le iq my b gy nh ne l nf ng">model4 = Sequential()</span><span id="3542" class="nc le iq my b gy nh ne l nf ng">model4.add(Dense(32, activation = 'relu', kernel_initializer = 'he_normal', input_shape = (x_train_scaled.shape[1],)))<br/>model4.add(Dense(16, activation = 'relu', kernel_initializer = 'he_normal'))<br/>model4.add(Dense(8, activation = 'relu', kernel_initializer = 'he_normal'))<br/>model4.add(Dense(8, activation = 'relu', kernel_initializer = 'he_normal'))<br/>model4.add(Dense(1))</span><span id="5b35" class="nc le iq my b gy nh ne l nf ng">#Step2 - 4 follows the same as the 1st model</span></pre><p id="d0d4" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">如果第一个模型只有2个隐藏层，分别有16个和8个节点，我在现有的基础上添加了2个额外的层，并增加了节点的数量。如下所示，与上述方法相比，该模型略有改进，但与基准相比仍不够显著。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/67112b402216fb84755b8f2e2704f1b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zZhqHpTQtdXA3l-MxnoO3g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">添加了额外的隐藏层:MAE = 0.3358(&gt;基准= 0.3356)</p></figure><p id="e26a" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">对于(3)方法，我想<strong class="lx ir">测试一个不同的优化器</strong>，而不是通常推荐的“Adam”:“rms prop”。没有看到改进，但值得注意的是，模型在训练期间经常波动(正如您从橙色线—测试集上的评估中看到的):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/b7db05f93b931b75d7cd080287ec3af5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HAAj_QrmAyfCu_WPySxMDg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">具有optimizer = "rmsprop "的模型:MAE= 0.3375(&gt;基准= 0.3356)</p></figure><p id="1c26" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">对于(4)方法，历元的<strong class="lx ir">数量</strong>可能会影响模型的结果。如果你熟悉机器学习，你会有和我一样的担心——“<em class="mw">多少个历元足够训练模型？</em>“坦率地说，我们无法说出确切的数字，只能测试和学习。然而，Keras提前停止<strong class="lx ir">有助于阻止模型进一步循环/训练，这可能会导致过度拟合。</strong></p><p id="cf24" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">为了实现，我们只需要定义EarlyStopping这个变量，并设置“耐心”作为阈值，如果通过，模型将停止学习:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="3c0a" class="nc le iq my b gy nd ne l nf ng">es = EarlyStopping(monitor = 'val_loss', patience=5)</span><span id="a11b" class="nc le iq my b gy nh ne l nf ng">history = model6.fit(x_train_scaled, y_train, validation_data=(x_test_scaled, y_test), epochs=200, batch_size=64, verbose=0, callbacks = [es])</span></pre><p id="3b88" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">如果你看到上面，我设置了monitor = 'val_loss '和patience = 5，这意味着如果val_loss值(测试集)在连续5个时期后高于loss值(训练集)，模型将停止学习。如下，模型在20+历元处停止。该方法不仅<strong class="lx ir"> <em class="mw">防止模型过拟合</em> </strong>，而且<strong class="lx ir"> <em class="mw">显著提高了模型的运行时间</em> </strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/fbf5a745b73a6052cbefbc1ce9a64ca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HB33wWbdYykfR1GhH8-szw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">具有提前停止的模型:MAE = 0.3371(&gt;基准= 0.3356)</p></figure><p id="f03c" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">对于(5)方法，<strong class="lx ir">正则化</strong>是一种在模型学习时对其进行修改以便更好地推广的技术。这是通过在模型学习时最小化样本外测试误差来实现的，这也有助于减少过度拟合。你可能听说过机器学习中的“<strong class="lx ir"> L1/L2正则子</strong>，它缩小了特征，但我们在神经网络中还有另一种常见的正则子——<strong class="lx ir">DropOut。</strong>让我们看看哪一个在当前数据集下表现更好:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="15f1" class="nc le iq my b gy nd ne l nf ng">#Step1. Define the model7</span><span id="91b2" class="nc le iq my b gy nh ne l nf ng">model7 = Sequential()</span><span id="9157" class="nc le iq my b gy nh ne l nf ng">model7.add(Dense(32, activation = 'relu', kernel_initializer = 'he_normal', input_shape = (x_train_scaled.shape[1],)))<br/>model7.add(Dense(16, activation = 'relu', kernel_initializer = 'he_normal'))<br/>model7.add(Dropout(0.3))<br/>model7.add(Dense(8, activation = 'relu', kernel_initializer = 'he_normal'))<br/>model7.add(Dropout(0.3))<br/>model7.add(Dense(8, activation = 'relu', kernel_initializer = 'he_normal'))<br/>model7.add(Dropout(0.3))<br/>model7.add(Dense(1))</span><span id="ac71" class="nc le iq my b gy nh ne l nf ng">#Step 2 - 4 follows the same as the 1st model</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/1fd3bc95b09453f6b4b232f1943ba3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pKs2bICRysu3pBOIOQGgWA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">辍学模型:MAE = 0.3660(&gt;基准= 0.3356)</p></figure><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="e314" class="nc le iq my b gy nd ne l nf ng">#Step1. Define the model8</span><span id="2a9f" class="nc le iq my b gy nh ne l nf ng">model8 = Sequential()</span><span id="898c" class="nc le iq my b gy nh ne l nf ng">model8.add(Dense(32, activation = 'relu', kernel_initializer = 'he_normal', input_shape = (x_train_scaled.shape[1],)))<br/>model8.add(Dense(16, activation = 'relu', kernel_initializer = 'he_normal', kernel_regularizer = 'l1'))<br/>model8.add(Dense(8, activation = 'relu', kernel_initializer = 'he_normal', kernel_regularizer = 'l1'))<br/>model8.add(Dense(8, activation = 'relu', kernel_initializer = 'he_normal', kernel_regularizer = 'l1'))<br/>model8.add(Dense(1))</span><span id="26f3" class="nc le iq my b gy nh ne l nf ng">#Step 2 - 4 follows the same as the 1st model</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/bf92601354197cbf16b33701a1338061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aa3ON-odO5zPPGjUaTHqFA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">具有L1正则化子的模型:MAE = 0.3344 ( &lt; benchmark = 0.3356)</p></figure><p id="ccc9" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">Voila! Finally, the model has improved, even slightly significantly as compared to the 1st model thanks to L1 Regularizer!</p><p id="1b20" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">For (6) method, testing <strong class="lx ir">激活和初始化器的不同组合</strong>是一个很好的简单方法来查看模型是否改进。以下是实践中常用的组合:</p><ol class=""><li id="eaa4" class="nt nu iq lx b ly mr mb ms me nv mi nw mm nx mq ny nz oa ob bi translated">activation = 'sigmoid '，kernel _ initializer = ' glorot _ normal '</li><li id="8f87" class="nt nu iq lx b ly oc mb od me oe mi of mm og mq ny nz oa ob bi translated">activation = 'relu '，kernel_initializer = 'he_uniform '</li></ol><p id="731d" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">但是，对于这个数据集，没有看到任何改进，所以我们可以传递这个方法。</p><p id="15b6" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">转到最后一个，建议<strong class="lx ir">在我们优化模型时测试更小的批量</strong>，因为更小的批量提供了更好的正则化效果/更低的泛化误差，并改善了运行时间。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><p id="2b13" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">瞧啊。这个项目到此结束——用TensorFlow的Keras API进行Airbnb价格预测。我希望这篇文章对你有用并且容易理解。</p><p id="d062" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">在不久的将来，一定要关注我的<strong class="lx ir">即将到来的数据科学和机器学习项目</strong>！与此同时，您可以在这里查看我的Github以获得完整的资源库:</p><p id="671b" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">github:<a class="ae kv" href="https://github.com/andrewnguyen07" rel="noopener ugc nofollow" target="_blank">https://github.com/andrewnguyen07</a>T14】LinkedIn:<a class="ae kv" href="http://www.linkedin.com/in/andrewnguyen07" rel="noopener ugc nofollow" target="_blank">www.linkedin.com/in/andrewnguyen07</a></p><p id="818a" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">谢谢！</p></div></div>    
</body>
</html>