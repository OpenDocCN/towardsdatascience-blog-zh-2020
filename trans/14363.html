<html>
<head>
<title>Computer Vision-Object Location Through Ai Self Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉——通过人工智能自我学习进行物体定位</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/computer-vision-object-location-through-ai-self-learning-52467ef3fb99?source=collection_archive---------21-----------------------#2020-10-03">https://towardsdatascience.com/computer-vision-object-location-through-ai-self-learning-52467ef3fb99?source=collection_archive---------21-----------------------#2020-10-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="fc21" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">我希望我有一个机器人可以扫描我的房子，找到我丢失的钥匙</h2><div class=""/><p id="4bb2" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">随着像脸书这样的公司在增强现实上花费数百万美元，在不久的将来，简单的眼镜将取代世界上几乎每一个屏幕，包括电视、手机，并将我们所有的环境转换成现实和屏幕的混合物。</p><blockquote class="ku kv kw"><p id="d90e" class="jw jx kx jy b jz ka kb kc kd ke kf kg ky ki kj kk kz km kn ko la kq kr ks kt ij bi translated">我相信我的房子里有一个喜欢每天早上吃掉所有钥匙的洞，这是每次我上班迟到时它们从地球上消失的唯一原因。</p></blockquote><p id="9514" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">但我仍然会等待有一天，我可以让我的眼镜或机器人扫描我的房间，找到我每天早上都在努力寻找的钥匙或我在房子某个地方丢失的耳机。</p><p id="d334" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">尽管每天都在不停地挣扎，但我决定为未来可能的机器人创建一个小小的后端项目，机器人/人工智能可以扫描房子的周围，为我找到东西。尽管:</p><ul class=""><li id="f930" class="lb lc iq jy b jz ka kd ke kh ld kl le kp lf kt lg lh li lj bi translated">问题的第一部分是告诉计算机一个物体看起来像什么，所以计算机知道实际上要找什么，所以我选择了最明显的方法，我们都做的检查一个物体看起来像什么，即通过在谷歌上搜索，所以当我告诉机器人在房间里找到我的钥匙或AirPods时，首先Ai会进行谷歌搜索，看看钥匙或AirPods实际上看起来像什么。</li><li id="0078" class="lb lc iq jy b jz lk kd ll kh lm kl ln kp lo kt lg lh li lj bi translated">问题的第二部分是让人工智能意识到物体在图像中的位置，人工智能可以自动学习并决定物体的实际形状和大小，并可以在图像中定位物体。为了解决这个问题，我实现了<strong class="jy ja">最小生成树聚类的研究工作——</strong>你可以在这里找到研究论文——&gt;<a class="ae lp" href="http://cs.brown.edu/people/pfelzens/segment/" rel="noopener ugc nofollow" target="_blank">http://cs.brown.edu/people/pfelzens/segment/</a></li><li id="adb3" class="lb lc iq jy b jz lk kd ll kh lm kl ln kp lo kt lg lh li lj bi translated">问题的第三部分是教Ai，如何定制训练一个<strong class="jy ja">物体检测YOLO模型，——</strong>所以不管我要求什么，不管是钥匙，AirPods，还是我丢失的u盘 AI将自动— <br/> 1谷歌搜索对象的图像<br/> 2从这些图像中生成训练数据<br/> 3标记/标注图像中的对象<br/> 4写下YOLO模型所需的所有适当的注释和文本文件<br/> 5编辑具有适当配置的YOLO·YAML文件<br/> 6训练图像，生成推理图，然后机器人将最终知道“钥匙”是什么，<strong class="jy ja">因此它可以打开摄像机并开始寻找它</strong></li></ul><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/600524f22a689153b511005e13505c8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xiUmfnqtaJmgPWCKvKfH3A.jpeg"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">自学模式的结果</p></figure><h2 id="f082" class="mg mh iq bd mi mj mk dn ml mm mn dp mo kh mp mq mr kl ms mt mu kp mv mw mx iw bi translated">这是完整自动化过程的算法-</h2><p id="5126" class="pw-post-body-paragraph jw jx iq jy b jz my kb kc kd mz kf kg kh na kj kk kl nb kn ko kp nc kr ks kt ij bi translated">1 <strong class="jy ja"> Google通过AI搜索物体的图片</strong> - <br/>在Colab环境中安装Google chrome和Selenium</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="7f44" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">制作一个数据框，从谷歌获取前200个图像结果。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="bd43" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">这里计算机/机器人会问你想看什么，我用了键，然后得到200个图像</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="f902" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">最小生成树聚类<br/> </strong>通过这种聚类分割，Ai将理解对象在图像中的位置，并通过在它周围制作一个方框来标记它，以创建一个训练数据，实现自研究论文<a class="ae lp" href="http://cs.brown.edu/people/pfelzens/segment/" rel="noopener ugc nofollow" target="_blank">http://cs.brown.edu/people/pfelzens/segment/</a></p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><div class="lr ls lt lu gt ab cb"><figure class="nf lv ng nh ni nj nk paragraph-image"><img src="../Images/92c0c75636a25bcb6ac09ab6c7e88509.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*2MS8dAgDZUIBmpPEMZIYEg.png"/></figure><figure class="nf lv nl nh ni nj nk paragraph-image"><img src="../Images/23c170d2ab622042ac46e5878ce58d6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*a0FxUZw4Va4FtHmFoEwESA.png"/><p class="mc md gj gh gi me mf bd b be z dk nm di nn no translated">人工智能标记的对象</p></figure></div><p id="b435" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">现在物体被标记了，是时候找到Ai在物体周围创建的黄色轮廓的“框”值了。我们需要找到xmin，xmax，ymin，ymax，这样就可以为YOLO对象模型编写注释了</p><p id="31ff" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja"> Ai自/自动Yolo模型训练和注释编写</strong></p><p id="1f0b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">为了得到物体周围盒子的xmin、xmax、ymin和ymax，我们需要找到物体周围所有黄色的像素点，然后从所有这些点，我们可以很容易地得到我们的坐标。</p><p id="8114" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">按照下面我创建的代码，Ai将首先在我们的训练数据中寻找每个图像中对象周围的所有黄色点，然后用坐标</strong>创建一个熊猫数据框</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/19aa8ccddf835a8c4743718e7f5305b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*qQW-Dqv7-nPq5Y-hdloEug.jpeg"/></div></figure><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="de8f" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">要编写YOLO注释，人工智能必须遵循一定的格式，人工智能需要在包含图像的同一文件夹中创建每个图像的文本文件，然后人工智能必须创建一个包含所有图像路径的train.txt文件。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="11b4" class="mg mh iq nr b gy nv nw l nx ny">image text file formula and fromat<br/>&lt;class_number&gt; (&lt;absolute_x&gt; / &lt;image_width&gt;) (&lt;absolute_y&gt; / &lt;image_height&gt;) (&lt;absolute_width&gt; / &lt;image_width&gt;) (&lt;absolute_height&gt; / &lt;image_height&gt;)<br/></span></pre><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="3009" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">上面的代码将会给Ai训练一个定制的<strong class="jy ja"> YOLO物体检测模型</strong>所需的所有文本文件</p><p id="2790" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja"> Ai将在YOLO上训练数据集</strong></p><p id="9d7a" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">现在，人工智能将从图像和标记的注释中学习，一把钥匙或任何其他物体看起来是什么样子，</p><p id="b604" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">使用下面的代码，Ai正在做三件事<br/> 1安装Yolo API <br/> 2将train.txt拆分成训练和测试数据<br/> 3打开Yolo模型的YAML文件并编辑所有必要的东西，如类的数量、训练的链接、测试数据和类名——在这种情况下，类名是键</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="ab5c" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">训练数据和保存重量</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="0e65" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">打开网络摄像头并检测物体<br/>现在，人工智能已经学会了什么是钥匙，现在我们可以将这个人工智能放入机器人或我们的增强眼镜中，然后它可以为我们扫描房间并找到钥匙。虽然眼镜或机器人还需要一些时间才能进入市场。所以现在我只是用我的笔记本电脑摄像头测试。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nz"><img src="../Images/74665d1790a6aa045fa09044a0854783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FPbNsxi46QHV8VtwPFFjZw.jpeg"/></div></div></figure></div><div class="ab cl oa ob hu oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="ij ik il im in"><p id="6f38" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated"><strong class="jy ja">结论</strong></p><p id="a660" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">看到Ai学习自己并检测物体是非常令人兴奋的，但整个笔记本需要3分钟来完成学习过程，这对于实际使用来说太长了。但随着量子计算的发展和并行处理的更好编码，实时自我训练和学习过程可能在未来几年内完成。虽然这个项目确保了让一个机器人去寻找你家丢失的东西不再是科幻幻想</p><p id="386b" class="pw-post-body-paragraph jw jx iq jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ij bi translated">对于，完整的jupyter笔记本和代码，可以通过<a class="ae lp" href="https://github.com/Alexamannn/Computer-Vision-Object-Location-through-Ai-Self-Learning" rel="noopener ugc nofollow" target="_blank">github.com</a>——<a class="ae lp" href="https://github.com/Alexamannn/Computer-Vision-Object-Location-through-Ai-Self-Learning" rel="noopener ugc nofollow" target="_blank">https://github . com/Alexa Mann/Computer-Vision-Object-Location-through-Ai-Self-Learning</a>查看我的知识库</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="nd ne l"/></div></figure></div></div>    
</body>
</html>