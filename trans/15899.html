<html>
<head>
<title>How to Create Representations of Entities in a Knowledge Graph using pyRDF2Vec</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用pyRDF2Vec创建知识图中实体的表示</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-create-representations-of-entities-in-a-knowledge-graph-using-pyrdf2vec-82e44dad1a0?source=collection_archive---------12-----------------------#2020-11-02">https://towardsdatascience.com/how-to-create-representations-of-entities-in-a-knowledge-graph-using-pyrdf2vec-82e44dad1a0?source=collection_archive---------12-----------------------#2020-11-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="dd6f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="832b" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">关于如何处理知识图中表示的数据的下游ML任务的教程。</h2></div><h1 id="a4b8" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">目录</h1><ul class=""><li id="4c86" class="lg lh iq li b lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated"><a class="ae ly" href="#1f07" rel="noopener ugc nofollow">用知识图表示数据</a></li><li id="954d" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#294a" rel="noopener ugc nofollow">运行实例:DBpedia中的国家</a></li><li id="191c" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#0861" rel="noopener ugc nofollow">用RDF2Vec创建实体嵌入</a></li><li id="3b7b" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#08bc" rel="noopener ugc nofollow">pyrdf 2 vec简介</a></li><li id="03fd" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#6a7a" rel="noopener ugc nofollow">有偏差的行走或采样策略</a></li><li id="dd7d" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#20d7" rel="noopener ugc nofollow">行走修改和变换</a></li><li id="0421" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#240f" rel="noopener ugc nofollow">用pyRDF2Vec装载kg</a></li><li id="5d75" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#a134" rel="noopener ugc nofollow">创建我们的第一个嵌入</a></li><li id="fdc2" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#4037" rel="noopener ugc nofollow">调节超参数</a></li><li id="c26a" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated">尝试不同的行走策略</li><li id="bc6d" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#62a0" rel="noopener ugc nofollow">采样深度行走</a></li><li id="82e4" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#1c6e" rel="noopener ugc nofollow">rdf 2 vec的缺点和研究挑战</a></li><li id="7893" class="lg lh iq li b lj lz ll ma ln mb lp mc lr md lt lu lv lw lx bi translated"><a class="ae ly" href="#8a76" rel="noopener ugc nofollow">代码和数据可用性</a></li></ul><h1 id="1f07" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">用知识图表示数据</h1><p id="1d79" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated"><strong class="li ja">图</strong>是用来表示无处不在的现象的数据结构，比如社交网络、化学分子和推荐系统。它们的优势之一在于，它们明确地对各个单元(即<strong class="li ja">节点</strong>)之间的关系(即<strong class="li ja">边</strong>)进行建模，这为数据增加了额外的维度。</p><p id="a0f2" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">我们可以使用<a class="ae ly" href="https://relational.fit.cvut.cz/dataset/CORA" rel="noopener ugc nofollow" target="_blank"> Cora引用网络</a>来说明这种数据丰富的附加值。该数据集包含数百篇论文的词袋表示以及这些论文之间的引用关系。如果我们应用降维(t-SNE)来创建单词袋表示的2D图(图1，左侧)，我们可以看到集群(根据其研究主题进行着色)出现，但它们重叠。如果我们产生一个嵌入的图形网络(图1，右)，考虑到引用信息，我们可以看到集群被更好地分离。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/f13764b276aba8e96a1e57a37016e692.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/0*y332aTSAuQIkzz_K.png"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated"><strong class="bd ni">图1: </strong>左图:每篇论文的词袋表示的t-SNE嵌入。右:图网络产生的嵌入，考虑了论文之间的引用。来源:<a class="ae ly" href="https://arxiv.org/abs/1809.10341" rel="noopener ugc nofollow" target="_blank">“深度图Infomax”，Velickovic等人</a></p></figure><p id="fdc4" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated"><strong class="li ja">知识图</strong> (KG)是一种特定类型的图。它们是<em class="nj">多关系</em>(即不同类型的关系有不同的边)和<em class="nj">有向</em>(即关系有主语和宾语)。这些属性允许以统一的格式表示来自不同来源的信息。我们可以将知识图转换成规则的有向图，这有助于进一步的分析，如图2所示。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nk"><img src="../Images/df2d36ba540fed63bbd376b0a5bd6571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JpUPmG3LU1pcCR-b.png"/></div></div><p class="ne nf gj gh gi ng nh bd b be z dk translated"><strong class="bd ni">图2: </strong>转换一个正则有向图中的多关系有向KG。图片作者。</p></figure><h1 id="294a" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">运行示例:DBpedia中的国家</h1><p id="7f60" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">在这篇文章中，我们将使用一个运行的例子。让我们首先关注为世界各地随机选择的几个国家创建表示。我们将从<a class="ae ly" href="https://wiki.dbpedia.org/about" rel="noopener ugc nofollow" target="_blank"> DBpedia </a>中提取每个国家的信息，DBpedia是从<a class="ae ly" href="http://www.wikipedia.org" rel="noopener ugc nofollow" target="_blank"> Wikipedia </a>中创建的大型通用KG。</p><p id="5bf5" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">让我们来看看KG在一个特定的国家附近是什么样子的:🇧🇪比利时🇧🇪.这个过程类似于转到其<a class="ae ly" href="http://dbpedia.org/page/Belgium" rel="noopener ugc nofollow" target="_blank">对应的DBpedia页面</a>，然后递归地点击该页面上的所有链接。我们在下面的图3中对此进行了描述。我们注意到，迭代地扩展这个邻域会使事情变得很快复杂，即使我们通过删除一些部分引入了一些简化。尽管如此，我们看到DBpedia包含了一些关于比利时的有用信息(例如，它的国歌、最大的城市、货币……)。</p><p id="3e44" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">我们通过使用<a class="ae ly" href="https://dbpedia.org/sparql" rel="noopener ugc nofollow" target="_blank"> DBpedia SPARQL端点</a>创建了一个包含国家信息的定制数据集。我们从曼海姆的<a class="ae ly" href="https://www.uni-mannheim.de/dws/research/resources/sw4ml-benchmark/" rel="noopener ugc nofollow" target="_blank">大学的“机器学习语义网”存储库中检索了一个国家列表</a>。每个国家都包含有关其通货膨胀和学术产出的信息。这些信息被二进制化为“高”和“低”(因此两个二进制分类任务)。此外，对于每个国家，我们检索了他们的大陆(欧洲、亚洲、美洲、非洲或大洋洲)，这给了我们一个5级分类任务。包含这些国家信息的KG是DBpedia的一个子集:对于每个国家，我们通过将KG扩展三次来检索所有信息。这个过程与图3中描述的完全一致。由于SPARQL端点的速率限制，深度为3的节点及其父节点最多只能包含10000个。KG(Turtle语法)可以在<a class="ae ly" href="https://www.dropbox.com/s/naysvkn55jqxxeo/countries.ttl" rel="noopener ugc nofollow" target="_blank">这里</a>下载，带有国家及其标签列表的CSV文件可以在<a class="ae ly" href="https://www.dropbox.com/s/ymo3pjfqzscsvey/countries.csv" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi np"><img src="../Images/ccac36fa4ea642af7ceea6719d34d2d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-fo07n-06Obzqks4hoGQyg.png"/></div></div><p class="ne nf gj gh gi ng nh bd b be z dk translated"><strong class="bd ni">图3: </strong>递归扩展知识图让事情变得复杂得很快。图片作者。</p></figure><h1 id="0861" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">用RDF2Vec创建实体嵌入</h1><p id="76c9" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated"><strong class="li ja"> RDF2vec </strong>代表资源描述框架To Vector。这是一种无监督的、任务不可知的算法，以数字形式表示KG中的节点，允许它们用于进一步的(下游)机器学习任务。RDF2Vec建立在现有的自然语言处理技术之上:它结合了来自<a class="ae ly" href="https://dl.acm.org/doi/pdf/10.1145/2623330.2623732" rel="noopener ugc nofollow" target="_blank"> DeepWalk </a>和<a class="ae ly" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" rel="noopener ugc nofollow" target="_blank"> Word2Vec </a>的见解。Word2Vec能够为提供的句子集合(通常称为语料库)中的每个单词生成嵌入。为了生成一个KG的语料库，我们提取行走。提取walks类似于访问一个实体的DBpedia页面并点击链接。你点击的次数相当于一次散步的跳数。这种步行的一个例子，对于比利时来说，将是:<a class="ae ly" href="http://dbpedia.org/resource/Belgium" rel="noopener ugc nofollow" target="_blank">比利时</a>-&gt;-<a class="ae ly" href="http://dbpedia.org/ontology/capital" rel="noopener ugc nofollow" target="_blank">dbo:首都</a>-&gt;-<a class="ae ly" href="http://dbpedia.org/resource/City_of_Brussels" rel="noopener ugc nofollow" target="_blank">布鲁塞尔市</a>-&gt;-<a class="ae ly" href="http://dbpedia.org/ontology/mayor" rel="noopener ugc nofollow" target="_blank">dbo:市长</a>-&gt;-<a class="ae ly" href="http://dbpedia.org/resource/Yvan_Mayeur" rel="noopener ugc nofollow" target="_blank">Yvan Mayeur</a>。注意，我们在遍历中没有区分谓词/属性(例如，dbo:capital和dbo:mayor)和实体(例如，比利时、布鲁塞尔、Yvan Mayeur等等)，如图2所示。现在，每一步都可以被视为一个句子，该步中的每一跳都对应于一个句子的标记(单词)。一旦我们提取了大量植根于我们想要为其创建嵌入的实体的遍历，我们就可以将其作为语料库提供给Word2Vec。Word2Vec将学习每个唯一跳的嵌入，然后可以用于ML任务。</p><h1 id="08bc" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">pyRDF2Vec简介</h1><p id="93ab" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">pyRDF2Vec是一个存储库，包含了<a class="ae ly" href="http://rdf2vec.org/" rel="noopener ugc nofollow" target="_blank"> RDF2Vec </a>算法的Python实现。在原始算法的基础上，还实现了不同的扩展。</p><blockquote class="nq nr ns"><p id="0dae" class="me mf nj li b lj mr ka mg ll ms kd mh nt mt mj mk nu mu mm mn nv mv mp mq lt ij bi translated">在本教程中，我将解释我们如何使用pyRDF2Vec在KG中生成实体的嵌入。此外，我将简要解释RDF2Vec的一些扩展，以及如何在pyRDF2Vec中使用这些扩展。 </p></blockquote><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nw"><img src="../Images/55f257f0c5a6b7ab60aa7647e22d68f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dgij9Wdt9LgEo-CCltet8g.png"/></div></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">图片取自<a class="ae ly" href="https://github.com/IBCNServices/pyRDF2Vec" rel="noopener ugc nofollow" target="_blank">我们的知识库</a>。</p></figure><h1 id="6a7a" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">有偏向的行走或采样策略</h1><p id="05f7" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">现在，从图3中可以注意到，我们可以提取的可能行走的数量随着深度呈指数增长。当我们使用像DBpedia这样的大kg时，这就成了问题。在<a class="ae ly" href="https://madoc.bib.uni-mannheim.de/41307/1/Ristoski_RDF2Vec.pdf" rel="noopener ugc nofollow" target="_blank">最初的RDF2Vec论文</a>中，行走只是从图中随机抽样，但是<a class="ae ly" href="https://dl.acm.org/doi/pdf/10.1145/3102254.3102279" rel="noopener ugc nofollow" target="_blank">科切兹等人提出了几个度量来偏向行走</a>。这些走步当时被称为有偏走步，但是我们将它们称为符合pyRDF2Vec术语的采样策略。一个可能的采样策略示例如图4所示。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nx"><img src="../Images/fb98e3192437cf1315ed8041c14501b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tap3__Gh5xtia5A6FA2NzA.png"/></div></div><p class="ne nf gj gh gi ng nh bd b be z dk translated"><strong class="bd ni">图4: </strong>对行走中的下一跳进行采样的一种可能方式是根据外出边的数量来缩放权重。这只是一个例子，有许多不同的指标(基于频率，PageRank，度，…)。图片作者。</p></figure><h1 id="20d7" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">行走修改和变换</h1><p id="2f80" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">到目前为止，我们将行走算法解释为从节点的邻居连续采样，直到达到某个深度。但是，我们可以对该算法进行修改(提取算法)，或者我们可以对行走进行后处理以包含额外的信息(转换算法)。<a class="ae ly" href="https://arxiv.org/pdf/2009.04404.pdf" rel="noopener ugc nofollow" target="_blank">这是我们在IDLab </a>一直在研究的内容。这些策略应用于一个简单的例子，如图5所示。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/42f1485340e0dca4ce16526f7262981b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*MZboCTMObVfEu_GW7J6WiQ.png"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated"><strong class="bd ni">图5: </strong>从图中提取行走(深度2)的不同策略。在这个图中，A和F是我们想要从中提取行走的根。c和H属于同一个社区(社区检测)。来源:<a class="ae ly" href="https://arxiv.org/pdf/2009.04404.pdf" rel="noopener ugc nofollow" target="_blank">“知识图中RDF2Vec节点嵌入的行走提取策略”，Vandewiele等人</a>(博客作者)。</p></figure><p id="004e" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">既然我们已经介绍了这些改进的行走策略，我们现在讨论RDF2Vec算法的三个主要构建模块:(I)一个<strong class="li ja">行走策略</strong> , (ii)一个<strong class="li ja">采样策略</strong>,( iii)一个<strong class="li ja">嵌入算法</strong> (NLP)。正如我们将进一步讨论的，这些构建块中的每一个都可以在pyRDF2Vec中配置。</p><h1 id="240f" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">用pyRDF2Vec加载kg</h1><p id="39b6" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">知识通常以资源描述框架(RDF)格式表示。pyRDF2Vec可以通过包装<a class="ae ly" href="https://rdflib.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> rdflib </a>轻松加载不同RDF语法的文件。这将把整个KG加载到RAM存储器中。然而，当KG大于可用的RAM内存时，这就成问题了。因此，我们也支持与端点的交互:KG可以托管在某个服务器上，我们的KG对象将在任何需要的时候与那个端点进行交互。这大大减少了所需的RAM内存，但代价是延迟更长。</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="nz oa l"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">用pyRDF2Vec加载元数据和知识图</p></figure><h1 id="a134" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">创建我们的第一个嵌入</h1><p id="b780" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">现在我们已经将KG加载到内存中，我们可以开始创建嵌入了！为了做到这一点，我们创建一个<code class="fe ob oc od oe b">RDF2VecTransformer</code>，然后用新加载的KG和一个实体列表调用<code class="fe ob oc od oe b">fit()</code>函数。一旦模型被拟合，我们可以通过<code class="fe ob oc od oe b">transform()</code>函数检索它们的嵌入。与常规的scikit-learn流程(我们在训练数据上调用<code class="fe ob oc od oe b">fit()</code>，在测试数据上调用<code class="fe ob oc od oe b">predict()</code>或<code class="fe ob oc od oe b">transform()</code>)不同的一点是，训练和测试实体都必须提供给<code class="fe ob oc od oe b">fit()</code>函数(类似于t-SNE在scikit-learn中的工作方式)。由于RDF2Vec在无人监督的情况下工作，这不会引入标签泄漏。</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="nz oa l"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">用默认的超参数创建我们的初始嵌入。我们为每个提供的实体获得100维的嵌入。</p></figure><p id="448d" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">上面的代码片段会给我们一个列表列表。对于向转换方法提供的每个实体，将返回100维的嵌入。现在，为了用肉眼检查这些嵌入，我们需要进一步降低维数。一个很好的方法是使用t-SNE。我们可以使用下面的代码片段来做到这一点:</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="nz oa l"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">用t-SNE进一步降低我们嵌入的维数，从100D到2D，以便可视化它们。</p></figure><p id="fb7a" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">这给了我们如图6所示的结果。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi of"><img src="../Images/3ebf4aeba6037f9833fc1e5335592e1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gzX8W7M0q7wHSPQuw3EV1w.png"/></div></div><p class="ne nf gj gh gi ng nh bd b be z dk translated"><strong class="bd ni">图6: </strong>我们初始嵌入的t-SNE图。我们可以开始看到国家集群的出现。图片作者。</p></figure><p id="c8ad" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">现在让我们来看看这些嵌入有多好，以便解决我们已经讨论过的三个ML任务:两个二元分类任务(高/低通货膨胀和高/低学术产出)和一个多类分类任务(预测大陆)。应该注意的是，由于RDF2Vec是无监督的，在创建这些嵌入的过程中，从来没有使用过这个标签信息！RDF2Vec是任务不可知的，从我们的节点到嵌入的投影不是为特定的任务定制的，嵌入可以用于多个不同的下游任务。让我们创建一个效用函数，它将生成的嵌入作为输入，然后对所有三个任务执行分类:</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="nz oa l"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">为三个不同任务的嵌入装配分类器。</p></figure><p id="6a44" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">现在让我们调用<code class="fe ob oc od oe b">classify(walk_embeddings)</code>来看看我们基线嵌入的性能:</p><pre class="mx my mz na gt og oe oh oi aw oj bi"><span id="503f" class="ok kp iq oe b gy ol om l on oo"><strong class="oe ja">Research Rating</strong><br/>Accuracy = 0.765625<br/>[[26  8]<br/> [ 7 23]]<br/><br/><strong class="oe ja">Inflation Rating</strong><br/>Accuracy = 0.5882352941176471<br/>[[14 16]<br/> [12 26]]<br/><br/><strong class="oe ja">Continent</strong><br/>Accuracy = 0.6716417910447762<br/>[[13  3  1  1  0]<br/> [ 4 11  0  1  0]<br/> [ 0  1  7  3  0]<br/> [ 1  3  1 14  0]<br/> [ 0  1  0  2  0]]</span></pre><p id="3943" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">研究评级、通货膨胀和大陆分类的准确率分别为76.56%、58.82%和67.16%。虽然这些准确性远非完美，但它确实显示了所有这些任务的一些信息存在于生成的嵌入中。这些较低精确度的一个可能原因是，由于DBpedia的公共API的速率限制，只使用了DBpedia数据的一个子集。此外，我们只使用默认的超参数来生成我们的嵌入。</p><h1 id="4037" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">调整超参数</h1><p id="c5d2" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">如前所述，RDF2Vec算法的三个构建模块(行走算法、采样策略和嵌入技术)都是可配置的。现在，让我们尝试提取更深层次的遍历并生成更大的嵌入:</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="nz oa l"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">设置不同的行走深度和嵌入大小。</p></figure><p id="f060" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">我们指定我们想要使用<em class="nj">随机</em>行走策略来提取深度为3的行走，这对应于从某个DBpedia页面跟随3个链接，或者在我们转换的KG中采取6次跳跃(参见图1)。我们还指定我们想要为每个实体详尽地提取<strong class="li ja">深度为3的所有</strong>可能的遍历，由<code class="fe ob oc od oe b">None</code>参数指示。我们没有指定任何采样策略，但是指定了我们想要使用Word2Vec嵌入技术来产生大小为500的嵌入。这种超参数配置为我们提供了以下精度:</p><pre class="mx my mz na gt og oe oh oi aw oj bi"><span id="3ccf" class="ok kp iq oe b gy ol om l on oo"><strong class="oe ja">Research Rating</strong><br/>Accuracy = 0.78125<br/>[[25  9]<br/> [ 5 25]]<br/><br/><strong class="oe ja">Inflation Rating</strong><br/>Accuracy = 0.6470588235294118<br/>[[14 16]<br/> [ 8 30]]<br/><br/><strong class="oe ja">Continent</strong><br/>Accuracy = 0.6865671641791045<br/>[[15  0  0  3  0]<br/> [ 6  9  0  1  0]<br/> [ 1  2  6  2  0]<br/> [ 0  3  0 16  0]<br/> [ 0  0  0  3  0]]</span></pre><p id="fb3e" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">如我们所见，三项任务中有两项的准确性有所提高，而第三项任务(通货膨胀分类)的准确性保持不变。</p><h1 id="def9" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">尝试不同的行走策略</h1><p id="6347" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">pyRDF2Vec允许我们使用不同的行走策略，不同策略的概述如图5所示。此外，我们可以组合不同的策略:pyRDF2Vec将提取每个策略的遍历，并在提供给嵌入技术之前将提取的遍历连接在一起。让我们试着结合几种行走策略:</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="52dc" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">我们现在得到的精度是:</p><pre class="mx my mz na gt og oe oh oi aw oj bi"><span id="afe0" class="ok kp iq oe b gy ol om l on oo"><strong class="oe ja">Research Rating</strong><br/>Accuracy = 0.71875<br/>[[24 10]<br/> [ 8 22]]<br/><strong class="oe ja"><br/>Inflation Rating</strong><br/>Accuracy = 0.6764705882352942<br/>[[14 16]<br/> [ 6 32]]<br/><br/><strong class="oe ja">Continent</strong><br/>Accuracy = 0.7910447761194029<br/>[[15  0  0  3  0]<br/> [ 5 11  0  0  0]<br/> [ 2  0  9  0  0]<br/> [ 0  1  0 18  0]<br/> [ 0  1  0  2  0]]</span></pre><p id="9eac" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">因此，通胀评级和大陆任务有所改善，但研究评级的表现有所下降。</p><h1 id="62a0" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">采样更深的行走</h1><p id="4e38" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">现在，如果我们想要提取更深的行走，我们很快就会遇到内存问题，因为行走的次数会随着行走的深度呈指数增长。这就是抽样策略发挥作用的地方。作为最后一个实验，让我们使用上一节中的行走策略对深度为6的5000次行走进行采样:</p><figure class="mx my mz na gt nb"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="5716" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">总共提取了854901次行走。这为我们提供了以下精度:</p><pre class="mx my mz na gt og oe oh oi aw oj bi"><span id="7c12" class="ok kp iq oe b gy ol om l on oo"><strong class="oe ja">Research Rating</strong><br/>Accuracy = 0.671875<br/>[[30  4]<br/> [17 13]]<br/><br/><strong class="oe ja">Inflation Rating</strong><br/>Accuracy = 0.5<br/>[[14 16]<br/> [18 20]]<br/><br/><strong class="oe ja">Continent</strong><br/>Accuracy = 0.8059701492537313<br/>[[17  0  0  1  0]<br/> [ 4 10  0  2  0]<br/> [ 0  2  9  0  0]<br/> [ 0  1  0 18  0]<br/> [ 0  3  0  0  0]]</span></pre><p id="5ca1" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">因此，只有一个大陆分类的改进和其他两个任务的显著恶化。当然，人们可以调整RDF2VecTransformer的许多超参数(行走和采样策略及其相应的超参数)和随机森林(或任何其他分类技术)来获得最佳精度，但我们将此作为练习留给读者！</p><h1 id="1c6e" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">RDF2Vec的缺点和研究挑战</h1><p id="9a2f" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">当前版本的RDF2Vec存在一些缺点，需要进一步研究来解决这些缺点:<br/>–<strong class="li ja">最初的RDF2Vec实现没有结合NLP领域的最新见解:</strong>自2017年RDF2Vec问世以来，NLP领域已经取得了许多进展。我们目前正在致力于将不同的NLP嵌入技术(比如BERT)实现到pyRDF2Vec中。<br/><strong class="li ja">–随机游走产生的嵌入的表达能力是有限的:</strong>游走只是单链，它们捕捉的信息有些有限。行走策略试图缓解这一缺点，但需要在这一方向进行进一步的研究。此外，我们或许可以将不同策略生成的行走组合在一起。<br/><strong class="li ja">–RDF2Vec无法扩展到大型kg:</strong>由于可以提取的可能行走的数量随深度呈指数增长，rdf 2 vec无法很好地扩展到具有大量节点的kg，尤其是当它包含许多高度连接的节点时。采样策略提高了可伸缩性，但是还可以做更多的研究。<br/><strong class="li ja">–rdf 2 vec不能很好地处理KG中的数值:</strong>目前，遍历中的所有跳，对应于KG中的节点，都被作为分类数据处理。这对于有序数据(例如，居民人数和国家大小)来说是次优的。<br/>–<strong class="li ja">rdf 2 vec不能处理易变数据:</strong>如前所述，训练和测试数据都需要提供给我们的<code class="fe ob oc od oe b">fit()</code>方法。但是如果我们的一些测试数据还不可用呢？这里有一些技术可以提供帮助，比如在线和渐进式学习。</p><p id="b89a" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">我们希望，通过发布pyRDF2Vec，提供一个工具包，可以促进解决这些挑战的研究。</p><h1 id="8a76" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">代码和数据可用性</h1><p id="5d96" class="pw-post-body-paragraph me mf iq li b lj lk ka mg ll lm kd mh ln mi mj mk lp ml mm mn lr mo mp mq lt ij bi translated">pyRDF2Vec库可以在Github 上找到。如果你喜欢这个知识库，请给我们一颗星，我们将不胜感激！此外，我们欢迎各种贡献。</p><p id="788c" class="pw-post-body-paragraph me mf iq li b lj mr ka mg ll ms kd mh ln mt mj mk lp mu mm mn lr mv mp mq lt ij bi translated">这篇博文中使用的自定义数据集可以下载:<a class="ae ly" href="https://www.dropbox.com/s/naysvkn55jqxxeo/countries.ttl" rel="noopener ugc nofollow" target="_blank"> KG </a>和<a class="ae ly" href="https://www.dropbox.com/s/ymo3pjfqzscsvey/countries.csv" rel="noopener ugc nofollow" target="_blank"> CSV </a>。我们还在一个<a class="ae ly" href="https://colab.research.google.com/drive/1kTj7_tEgI2cUWzaUkXfGtwJ-QMjW3c2-?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>中提供了所有的代码，这样你就可以从你的浏览器中交互地运行它了！</p></div></div>    
</body>
</html>