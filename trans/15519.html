<html>
<head>
<title>Deep Learning with CIFAR-10</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用CIFAR-10进行深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-with-cifar-10-image-classification-64ab92110d79?source=collection_archive---------9-----------------------#2020-10-26">https://towardsdatascience.com/deep-learning-with-cifar-10-image-classification-64ab92110d79?source=collection_archive---------9-----------------------#2020-10-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6fb2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于CNN的图像分类</h2></div><p id="a27d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">神经网络是可编程的模式，有助于解决复杂的问题，并带来最佳的可实现的输出。我们都知道深度学习比机器学习领先一步，它有助于训练神经网络来获得未回答问题的解决方案或改进解决方案！</p><p id="a290" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我们将使用CIFAR-10数据集实现一个深度学习模型。数据集通常用于深度学习，用于测试图像分类的模型。它有60，000幅彩色图像，包括10个不同的类别。图像大小为32×32，数据集包含50，000幅训练图像和10，000幅测试图像。人们可以在这里找到CIFAR-10数据集<a class="ae lb" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="6fba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">导入数据</strong></p><p id="1fca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">深度学习模型需要具有高计算能力的机器。一般建议使用类似Kaggle或Google Collaboratory的在线GPU。我已经在谷歌合作实验室实施了该项目。对于这个项目，我们将使用TensorFlow和matplotlib库。由于数据集是全局使用的，因此可以直接从TensorFlow库的keras模块导入数据集。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="c641" class="ll lm iq lh b gy ln lo l lp lq">import tensorflow as tf<br/>import matplotlib.pyplot as plt<br/>from tensorflow.keras.datasets import cifar10 </span></pre><p id="b66e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">数据预处理</strong></p><p id="f874" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">任何机器学习、深度学习或数据科学项目的第一步都是对数据进行预处理。我们将定义类的名称，数据集分布在这些类上。大小为32x32的彩色图像有10种不同的类别。一旦我们设置了类名。我们需要标准化图像，以便我们的模型可以更快地训练。彩色图像的像素范围是0–255。我们将图像的每个像素除以255，因此像素范围将在0-1之间。实际上，我们将把它除以255.0，因为它是一个浮点运算。对于该模型，我们将使用卷积神经网络(CNN)。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="9a6d" class="ll lm iq lh b gy ln lo l lp lq"># setting class names<br/>class_names=[‘airplane’,’automobile’,’bird’,’cat’,’deer’,’dog’,’frog’,’horse’,’ship’,’truck’]</span><span id="2a45" class="ll lm iq lh b gy lr lo l lp lq">x_train=x_train/255.0<br/>x_train.shape<br/>x_test=x_test/255.0<br/>x_test.shape</span></pre><p id="1a86" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在shape的输出中，我们看到4个值，例如(50000，32，32，3)。这4个值如下:第一个值，即(50，000/10，000)表示图像的数量。第二个和第三个值显示图像大小，即图像高度和宽度。这里的图像大小为32x32。第四个值显示“3”，它显示RGB格式，因为我们使用的图像是彩色图像。</p><p id="c533" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">建立CNN模型</strong></p><p id="202c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CNN模型分三个阶段工作。在第一阶段，卷积层提取图像/数据的特征。在第二阶段，池层减少了图像的维度，因此小的变化不会对模型产生大的变化。简单地说，它防止过度拟合。在第三阶段，展平层将我们的模型转换为一维，并将其提供给完全连接的致密层。这个密集层然后执行图像预测。一个好的模型有多层卷积层和池层。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ls"><img src="../Images/bd6b4aa1194ae08491be40cd7f11ffae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*45D2GKyphL5G7fcCJL1BnA.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">CNN架构(图片由作者提供，灵感来自<a class="ae lb" href="https://debuggercafe.com/convolutional-neural-network-architectures-and-variants/" rel="noopener ugc nofollow" target="_blank">https://debugger cafe . com/convolutionary-neural-network-architectures-and-variants/</a></p></figure><p id="0025" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在创建神经网络模型时，一般使用两种API:<em class="me">顺序API </em>和<em class="me">功能API </em>。<em class="me">顺序API </em>允许我们逐层创建模型，并将其添加到顺序类中。顺序API的缺点是我们不能用它来创建一个模型，在这个模型中我们想要使用多个输入源并在不同的位置得到输出。为了克服这个缺点，我们使用函数式API。通过使用<em class="me">功能API </em>我们可以创建多个输入和输出模型。但是，在大多数情况下，使用的是顺序API 。我们将为我们的CNN模型使用<em class="me">顺序API </em>。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="5d2c" class="ll lm iq lh b gy ln lo l lp lq">cifar10_model=tf.keras.models.Sequential()<br/># First Layer<br/>cifar10_model.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, padding=”same”, activation=”relu”, input_shape=[32,32,3]))</span></pre><p id="f69f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用卷积神经网络，因此我们将使用卷积层。最常用和我们正在使用的层是<em class="me"> Conv2D。Conv2D </em>表示卷积发生在2轴上。它将卷积扩展到三个层次，红色、绿色和蓝色。另一类卷积层是<em class="me"> Conv1D。Conv1D </em>一般用于“文本”，<em class="me"> Conv2D </em>一般用于“图像”。我想大多数读者都知道什么是卷积以及如何做，但是这个视频将帮助你清楚卷积在CNN是如何工作的。</p><p id="2134" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">Conv2D层的参数</strong></p><p id="82bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一个参数是<strong class="kh ir"> <em class="me">【滤镜】</em> </strong>。号码。滤波器的值表示CNN模型和卷积层将从中学习的滤波器的数量。从每个这样的过滤器，卷积层学习一些关于图像，像色调，边界，形状/特征。参数的值应该是2的幂。</p><p id="5577" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二个参数是“<strong class="kh ir"><em class="me"/></strong>”。内核指的是一个过滤器，它将在图像中移动，并使用点积提取零件的特征。内核大小是指过滤器的尺寸(高x宽)。内核大小的值通常是奇数，例如3，5，7..等等。这里我们使用的内核大小为3，这意味着过滤器大小为3 x 3。</p><p id="999a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下一个参数是“<strong class="kh ir"><em class="me">”</em></strong>。有两种类型的填充，同样&amp;有效。在有效填充中，图像边界上没有零填充。因此当卷积发生时，会有数据丢失，因为一些特征不能被卷积。在相同的填充中，在图像的所有边界上都填充了一层零，因此没有数据丢失。此外，卷积后图像输出的维数与图像输入的维数相同。上述是这种衬垫命名的原因。因为在初始层中我们不能丢失数据，所以我们使用了相同的填充。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mf"><img src="../Images/d9075f50c6164b6a5650e721248e5ad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JOQLy5nX6AeNooUnwvnSUQ.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">图像和填充(作者提供的图像)</p></figure><p id="fcca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用深度学习模型的原因是为了解决复杂的功能。为了得到更好的输出，我们需要以过于复杂的方式来拟合模型，因此我们需要使用能够解决模型的非线性复杂性的函数。这是通过使用激活层来完成的。在任何深度学习模型中，最少需要一个具有<strong class="kh ir"> <em class="me">激活功能</em> </strong>的层。激活函数的工作是给模型添加非线性。如果我们不添加这一层，模型将是一个简单的线性回归模型，不会达到预期的结果，因为它无法拟合非线性部分。</p><p id="e286" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有4个著名的激活功能:</p><ol class=""><li id="4979" class="mg mh iq kh b ki kj kl km ko mi ks mj kw mk la ml mm mn mo bi translated">)Sigmoid函数:取值范围在0到1之间。该图是一个陡峭的图，所以即使是很小的变化也能带来很大的不同。它主要用于二元分类，因为当值高于或低于0.5时可以很容易地进行划分。</li></ol><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/6f95d03bd4dd138c32d6f3a7008d71d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*cYpHB8uDtVOTdDxIxmMxgw.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">Sigmoid函数的图形(图片由作者提供，创建于<a class="ae lb" href="https://www.mathsisfun.com/data/function-grapher.php#functions" rel="noopener ugc nofollow" target="_blank">https://www . maths isfun . com/data/function-grapher . PHP # functions</a>)</p></figure><p id="9d00" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.)双曲正切函数:是正切双曲函数的缩写。它是Sigmoid函数的衍生函数。这些激活函数背后的数学原理超出了本文的范围，所以我不会跳到这里。该值的范围在-1到1之间。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/4e84a35e18fc0fa90d48a10e062e0cc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*JSRB9KgnI9G6o1vGDS8o5Q.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">双曲正切函数图(图片由作者提供，创建于<a class="ae lb" href="https://keisan.casio.com/exec/system/1223039747?lang=en&amp;charset=utf-8&amp;var_x=tanh%28x%29&amp;ketasu=14" rel="noopener ugc nofollow" target="_blank">https://keisan.casio.com/exec/system/1223039747?lang=en&amp;charset = utf-8&amp;var _ x = TanH % 28x % 29&amp;ketasu = 14</a></p></figure><p id="532e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.)ReLu函数:是整流线性单元的缩写。是深度学习最著名的激活。这是著名的，因为它更容易计算，因为数学函数比其他激活函数更容易和简单。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/3e7f7d3a85b8bad6ca4a19242266e0ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*__CpYdp4EJS6w9g8B0R8Pg.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">ReLu函数的图形(图片由作者提供，创建于<a class="ae lb" href="https://www.mathsisfun.com/data/function-grapher.php#functions" rel="noopener ugc nofollow" target="_blank">https://www . maths isfun . com/data/function-grapher . PHP # functions</a>)</p></figure><p id="986e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">4.)SoftMax函数:SoftMax函数是Sigmoid函数的更多阐明形式。它用于多类分类。该函数计算函数中特定类的概率。因此，该函数的输出值范围在0到1之间。Sigmoid函数和SoftMax函数的主要区别在于，Sigmoid函数可用于二分类，而SoftMax函数也可用于多分类。</p><p id="fe9d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">汇集层</strong></p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="ebe4" class="ll lm iq lh b gy ln lo l lp lq">#MaxPoolingLayer<br/>cifar10_model.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2, padding=’valid’))</span></pre><p id="5bcf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">池层用于减小图像的大小，同时保留角色中的重要参数。这样有助于减少模型中的计算量。在执行卷积时，卷积层保留了关于特征的确切位置的信息。因此不太重要的特征也被完美地定位。因此，我们会遇到一个问题，即使是像素或特征的微小变化也会导致模型输出的巨大变化。通过最大池化，我们缩小了所有特性的范围，只考虑最重要的特性。因此，上述问题得以解决。池化有两种方式:平均池化或最大池化。通常使用最大池。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/a47b5f7a82b55fa3a2bfbf2f3e4f5ac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*ITj2wCf8okpYrKoICJqsnA.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">平均池(图片由作者提供，灵感来自<a class="ae lb" href="https://people.minesparis.psl.eu/fabien.moutarde/ES_MachineLearning/TP_convNets/convnet-notebook.html" rel="noopener ugc nofollow" target="_blank">https://people . mines Paris . PSL . eu/fabien . moutarde/ES _ machine learning/TP _ conv nets/conv net-notebook . html</a>)</p></figure><p id="2de4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在平均池中，取池大小的平均值。在最大池中，取池大小的最大值。这个概念将从上面和下面的图像中被清除。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/287e8d3dca9f98097834443e2acc4cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*Z4qJMP4U7-F2SrHUEApgqQ.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">Max Pooling(图片由作者提供，灵感来自<a class="ae lb" href="https://people.minesparis.psl.eu/fabien.moutarde/ES_MachineLearning/TP_convNets/convnet-notebook.html" rel="noopener ugc nofollow" target="_blank">https://people . mines Paris . PSL . eu/fabien . moutarde/ES _ machine learning/TP _ conv nets/conv net-notebook . html</a>)</p></figure><p id="3142" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">池大小是指将取其最大值的过滤器的大小。这里的池大小2表示将使用2x2的池，在该2x2池中，平均值/最大值将成为输出。池将穿过图像。它将根据步幅值移动。</p><p id="122a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">步幅意味着泳池的大小能跳多远。如果步幅为1，2x2池将从一列逐渐向右移动到另一列。我使用了stride 2，这意味着池大小将一次移动两列。我前面用来解释最大池化和平均池化的图像的池大小为2，步幅= 2。</p><p id="1a82" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在池中，我们使用填充“有效”，因为我们准备丢失一些信息。因为池的功能是减少图像的空间维度并减少模型中的计算。</p><p id="d938" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">最后一层</strong></p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="121d" class="ll lm iq lh b gy ln lo l lp lq"># Flattening Layer<br/>cifar10_model.add(tf.keras.layers.Flatten())</span></pre><p id="1bf9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在卷积层和汇集层的堆叠之后添加了展平层。展平层将3d图像矢量转换为1d。因为在前面提到的层的堆叠之后，添加了最终的完全连接的致密层。现在，密集层要求数据以一维方式传递，因此扁平化层是最重要的。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/2c99a6a912c70ca0dbbc430cc0157d19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*7mu8MsyNgClPqelFkwGx9g.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">平整层的工作(图片由作者提供)</p></figure><p id="8a31" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">展平一层后，还有一层致密层。致密层是一个完全连接的层，将先前功能的所有输出提供给所有神经元。密集层具有权重W、偏差B和传递给每个元素的激活。<em class="me">用一种清晰的方式说，它把所有的点连接起来。</em>这一层使用之前提取的所有特征，并完成训练模型的工作。提到的单位显示了模型将要使用的神经元的数量。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="b26d" class="ll lm iq lh b gy ln lo l lp lq"># Droput Layer<br/>cifar10_model.add(Dropout(0.2))<br/># Adding the first fully connected layer<br/>cifar10_model.add(tf.keras.layers.Dense(units= 128,activation='relu’))</span></pre><p id="5f8f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，为了防止过度拟合，增加了一个脱落层。在数据训练期间，一些神经元被随机禁用。传递给神经元的值意味着在一次迭代中想要丢弃的神经元的比例。因此，在训练之后，神经元不会受到其他神经元的权重的很大影响。因此该模型可以更好地推广。</p><figure class="lc ld le lf gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mv"><img src="../Images/d26e2e844b79b692936acf6bc7c263ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8S2WrThp7Zts4I_uhwIxXQ.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">辍学层的工作(图片由作者提供，灵感来自<a class="ae lb" href="https://people.minesparis.psl.eu/fabien.moutarde/ES_MachineLearning/TP_convNets/convnet-notebook.html" rel="noopener ugc nofollow" target="_blank">https://people . mines Paris . PSL . eu/fabien . moutarde/ES _ machine learning/TP _ conv nets/conv net-notebook . html</a></p></figure><p id="1f0e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">输出层</strong></p><p id="0341" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在输出中，图层根据数据集中的类数量使用单位数量。这里我们用10，因为有10个单位。在输出中，我们使用SOFTMAX激活，因为它给出了每个类的概率。</p><p id="c1c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在编制模型时，我们需要考虑损失函数。通常使用两种损失函数，稀疏分类交叉熵(scce)和分类交叉熵(cce)。稀疏分类交叉熵(scce)在类别互斥、类别完全不同时使用。当一个标签或部分可以有多个类别时，使用分类交叉熵。在我们的场景中，类是完全不同的，所以我们使用稀疏分类交叉熵。</p><p id="e025" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用普遍使用的Adam优化器。Adam是“自适应学习率法”的缩写。这个优化器使用梯度的初始值来适应学习速率。现在使用Adam代替ML中使用的随机梯度下降，因为它可以在每次迭代后更新权重。</p><p id="055f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">玩了一会儿epochs后的最终输出是:</p><p id="ea84" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用这个模型，我能够得到78%的准确率。因此，在本文中，我们将使用Google Collaboratory完成深度学习项目。我们了解卷积神经网络的卷积层和池层中使用的参数。在CNN中提取特征后，我们需要一个密集层和一个dropout来实现识别图像的这一特征。最后，我们看到了一些损失函数和亚当优化。</p><p id="49bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以在我的git资源库中找到完整的代码:<a class="ae lb" href="https://github.com/aaryaab/CIFAR-10-Image-Classification" rel="noopener ugc nofollow" target="_blank">https://github.com/aaryaab/CIFAR-10-Image-Classification</a>。</p><p id="254a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请随时联系我，电话:【https://www.linkedin.com/in/aarya-brahmane-4b6986128/ T2】</p><p id="f035" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参考资料:你可以在<a class="ae lb" href="https://www.mathsisfun.com/data/function-grapher.php#functions" rel="noopener ugc nofollow" target="_blank">找到并制作一些有趣的图表</a></p><p id="b71d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图形图像是我在Power point上制作的。</p><p id="74e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">快乐深度学习！</p><p id="c060" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和平！！</p></div></div>    
</body>
</html>