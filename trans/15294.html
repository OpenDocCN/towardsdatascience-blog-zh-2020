<html>
<head>
<title>A complete guide to AI accelerators for deep learning inference — GPUs, AWS Inferentia and Amazon Elastic Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习推理的人工智能加速器完全指南——GPU、AWS推理和亚马逊弹性推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c?source=collection_archive---------2-----------------------#2020-10-21">https://towardsdatascience.com/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1c?source=collection_archive---------2-----------------------#2020-10-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="73ce" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解CPU、GPU、AWS推理和Amazon弹性推理，以及如何为推理部署选择正确的AI加速器</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/97d519894d818e13cce891ff48242db1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AGpm_2l-32AfXUAfOxwUKA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">如何选择—推理用GPU、AWS推理和亚马逊弹性推理(<em class="kv">作者图解</em>)</p></figure><h2 id="41bf" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">让我们从回答“什么是AI加速器”这个问题开始。</h2><p id="03c9" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">人工智能加速器是一种专用处理器，旨在加速机器学习计算。机器学习，特别是它的子集，深度学习主要由大量的线性代数计算组成，(即矩阵-矩阵，矩阵-向量运算)，这些运算可以很容易地并行化。人工智能加速器是一种专门的硬件，旨在加速这些基本的机器学习计算，提高性能，减少延迟，并降低部署基于机器学习的应用程序的成本。</p><h2 id="ff96" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">机器学习(ML)推理需要AI加速器吗？</h2><p id="13ec" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">假设你有一个ML模型作为你软件应用的一部分。预测步骤(或推断)通常是应用程序中最耗时的部分，会直接影响用户体验。一个需要数百毫秒来生成文本翻译或对图像应用过滤器或生成产品推荐的模型，可以让用户远离你的“迟缓”、“缓慢”、“令人沮丧”的应用。</p><p id="ee5e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">通过加速推理，您可以减少应用程序的整体延迟，并提供可以用“流畅”、“爽快”和“令人愉快”来描述的应用程序体验。你可以通过将ML模型预测计算卸载到AI加速器来加速推断。</p><p id="3562" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">随着巨大的市场需求而来的是大量的替代产品，因此自然有多种方式来加速您在云中的ML模型。</p><p id="b0a7" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在这篇博文中，我将探索三种流行的选择:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/b8061d16ac4264af9677f42a47697de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cn429sy-CrlfzFUjz4SzvQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者插图</em>)</p></figure><ol class=""><li id="7c36" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk mw mx my mz bi translated"><strong class="lu ir">GPU</strong>:特别是高性能的英伟达T4和英伟达V100 GPUs</li><li id="f9e8" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated"><strong class="lu ir"> AWS推理</strong>:AWS定制设计的机器学习推理芯片</li><li id="c18d" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated"><strong class="lu ir">Amazon Elastic Inference(EI)</strong>:一个加速器，通过为不需要专用GPU的模型提供可变大小的GPU加速来节省成本</li></ol><p id="81e6" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">为您的工作负载选择正确的硬件加速类型可能是一个很难做出的选择。在这篇文章的其余部分，我将带您了解各种考虑因素，如目标吞吐量、延迟、成本预算、模型类型和大小、框架选择以及其他因素，以帮助您做出决策。我还将展示大量代码示例，并讨论开发人员友好性和选项的易用性。</p><blockquote class="nf ng nh"><p id="5c88" class="ls lt ni lu b lv ml jr lx ly mm ju ma nj mn mc md nk mo mf mg nl mp mi mj mk ij bi translated">免责声明:本文中的观点和建议是我自己的，不代表我现在或过去的雇主的观点。</p></blockquote><h1 id="40b9" class="nm kx iq bd ky nn no np lb nq nr ns le jw nt jx li jz nu ka lm kc nv kd lq nw bi translated">一点硬件加速器的历史</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/323eaf9c44ce26c6bea93e7d17fc79a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qGoEKQ-hOTlyf77Ay054CQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者插图</em>)</p></figure><p id="8a12" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在计算的早期(70年代和80年代)，为了加快计算机上的数学计算，你将CPU(中央处理器)与FPU(浮点单元)配对，也就是数学协处理器。想法很简单——允许CPU将复杂的浮点数学运算卸载到专门设计的芯片上，这样CPU就可以专注于执行应用程序的其余部分，运行操作系统等。由于系统有不同类型的处理器(CPU和数学协处理器)，这种设置有时被称为异构计算。</p><p id="f8f0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">快进到90年代，CPU变得更快、更好、更高效，并开始配备集成浮点硬件。更简单的系统占了上风，而协处理器和异构计算对于普通用户来说已经过时了。</p><p id="1407" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">大约在同一时间，特定类型的工作负载开始变得更加复杂。设计师需要更好的图形，工程师和科学家需要更快的计算机进行数据处理、建模和模拟。这意味着对高性能处理器有一些需求(和市场),这种处理器可以比CPU更快地加速“特殊程序”,从而释放CPU来做其他事情。计算机图形是工作负载被卸载到特殊处理器的早期例子。你可能知道这种特殊的处理器的通用名，古老的GPU。</p><p id="bd36" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">2010年代初，又出现了另一类工作负载——深度学习，或具有深度神经网络的机器学习——需要硬件加速才能实现，就像计算机图形一样。GPU已经出现在市场上，经过多年的发展，已经变得高度可编程，不像早期的GPU是固定功能的处理器。自然地，ML从业者开始使用GPU来加速深度学习训练和推理。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/8c1014808f3c295e2ffad876b78cff00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IjdsDLwkjVW8_DGhN6ZUiQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">CPU可以将复杂的机器学习操作卸载到人工智能加速器上(作者的<em class="kv">插图)</em></p></figure><p id="13b5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如今的深度学习推理加速格局有趣多了。CPU获得了对高级向量扩展(AVX-512)的支持，以加速深度学习中常见的矩阵数学计算。GPU获得了新的功能，例如支持简化精度算法(FP16和INT8)，进一步加快了推理速度。</p><p id="1fc9" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">除了CPU和GPU，今天你还可以使用专门的硬件，定制设计的芯片只是为了深度学习推理而构建的。如果处理器支持您的工作负载，这些专用处理器，也称为专用集成电路或ASICs，与通用处理器相比，性能更高，成本更低。这种专用处理器的一个很好的例子是AWS Inferentia，这是AWS为加速深度学习推理而定制设计的ASIC。</p><p id="3e5e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">一开始，为您的应用选择正确的硬件加速可能并不明显。在下一节中，我们将讨论每种方法的优势和考虑事项，如吞吐量、延迟、成本和其他会影响您选择的因素。</p><h1 id="85b7" class="nm kx iq bd ky nn no np lb nq nr ns le jw nt jx li jz nu ka lm kc nv kd lq nw bi translated">人工智能加速器和如何选择正确的选项</h1><p id="6421" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">很难回答“GPU比CPU好吗？”或者“CPU比GPU便宜吗”或者“ASIC总是比GPU快吗”。实际上，没有一种硬件解决方案能适用于所有使用情形，答案取决于您的工作负载和几个考虑因素:</p><ol class=""><li id="baa6" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk mw mx my mz bi translated"><strong class="lu ir">模型类型和可编程性:</strong>模型大小、定制操作符、支持的框架</li><li id="490f" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated"><strong class="lu ir">目标吞吐量、延迟和成本:</strong>在预算范围内提供良好的客户体验</li><li id="cca9" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated"><strong class="lu ir">编译器和运行时工具链的易用性:</strong>应该有快速的学习曲线，不需要硬件知识</li></ol><p id="46bc" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">虽然模型支持和目标延迟等考虑是客观的，但易用性可能是非常主观的。因此，我反对不考虑上述所有具体应用的一般性建议。这种高水平的建议往往是有偏见的。</p><p id="53b8" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">让我们回顾一下这些关键考虑事项。</p><h2 id="a86d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 1。型号类型和可编程性</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/ba26bc8cee78f92c36f16e4dfddf612a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*517MwFvZqBpm32Kf1rJWRg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者插图</em>)</p></figure><p id="598b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">对人工智能加速器进行分类的一种方式是基于它们的可编程程度。在“完全可编程”的一端，有CPU。作为通用处理器，你可以用定制的层、架构和操作为你的机器学习模型编写定制的代码。</p><p id="5d84" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">另一个极端是ASICs，如AWS Inferentia，它通过AWS Neuron SDK编译器公开了一组固定的受支持操作。介于两者之间，但更接近ASIC的是GPU，它比ASIC更具可编程性，但远不如CPU通用。在通用和提供性能之间总会有一些折衷。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/b11937d2c1b18e35a4659fd06bf76c17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I31UVROQUhXZCE_gbikXaQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">定制代码可能会退回到CPU执行，从而降低整体吞吐量(作者的<em class="kv">插图)</em></p></figure><p id="dceb" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果您正在通过自定义神经网络操作来拓展深度学习研究的边界，您可能需要为自定义操作编写自定义代码。你通常用像Python这样的高级语言来做这件事。</p><p id="951b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">大多数人工智能加速器不能自动加速用高级语言编写的定制代码，因此这段代码将退回给CPU执行，降低了整体推理性能。</p><p id="71de" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">NVIDIA GPUs的优势在于，如果你想提高自定义代码的性能，你可以使用CUDA编程语言重新实现它们，并在GPU上运行它们。但是如果你的ASIC的编译器不支持你需要的操作，那么CPU回退可能会导致较低的性能。</p><h2 id="dd81" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 2。目标吞吐量、延迟和成本</strong></h2><p id="a02f" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">一般来说，与通用处理器相比，专用处理器(如AWS Inferentia)往往提供更低的性价比，并改善延迟。但在人工智能加速的世界里，所有的解决方案都可能是有竞争力的，这取决于工作负载的类型。</p><p id="5fb5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">GPU是吞吐量处理器，可以在指定的延迟时间内提供高吞吐量。如果延迟不重要(批处理、离线推理)，那么GPU利用率可以保持在较高水平，使其成为云中最具成本效益的选项。CPU不是并行吞吐量设备，但是对于较小模型的实时推理，CPU可能是最具成本效益的，只要推理延迟低于您的目标延迟预算。如果您的模型完全受AWS Neuron SDK compiler支持，AWS Inferentia的性能和较低的成本可能使其成为相对于CPU和GPU最具成本效益和性能的选择。</p><p id="5eea" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这确实是一个微妙的话题，并且非常依赖于工作负载。在接下来的章节中，我们将进一步了解每个加速器的性能、延迟和成本。如果某个特定的选择不适合你，没关系，在云中切换选项很容易，直到你找到适合你的选项。</p><h2 id="6b73" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 3。编译器和运行时工具链以及易用性</strong></h2><p id="0f76" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">为了在人工智能加速器上加速您的模型，您通常必须经历一个编译步骤，该步骤分析计算图形并针对目标硬件进行优化，以获得最佳性能。当部署在CPU上时，深度学习框架拥有您需要的一切，因此通常不需要额外的SDK和编译器。</p><p id="5bf9" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果你正在部署一个GPU，你可以依靠深度学习框架来加速你的模型进行推理，但你将把性能留在桌面上。为了充分利用你的GPU，你必须使用一个专用的推理编译器，比如NVIDIA TensorRT。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/50edea9cad83ca36ee9d390d0c050133.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/0*ZDB7D4HSl2NE8HBh"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者截图</em>)</p></figure><p id="6b4a" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在某些情况下，与使用深度学习框架相比，您可以获得10倍以上的额外性能(见图)。我们将在后面的代码示例部分看到如何重现这些结果。</p><p id="a574" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">NVIDIA TensorRT是两件事——推理编译器和运行时引擎。通过使用TensorRT编译您的模型，您可以获得更好的性能和更低的延迟，因为它执行了许多优化，如图形优化和量化。同样，当以AWS推理为目标时，AWS Neuron SDK编译器将执行类似的优化，以充分利用您的AWS推理处理器。</p><p id="3b93" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">让我们更深入地挖掘一下这些人工智能加速器选项</p></div><div class="ab cl oc od hu oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="ij ik il im in"><h1 id="3456" class="nm kx iq bd ky nn oj np lb nq ok ns le jw ol jx li jz om ka lm kc on kd lq nw bi translated">加速器选项1:用于推理的GPU加速</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/93e8608e9ecc5d0fde6ac503737881e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*9koZpeCzmIzM7nYv_RoLCg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者插画</em>)</p></figure><p id="04a8" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">您在GPU上训练您的模型，因此很自然会考虑将GPU用于推理部署。毕竟，GPU大大加快了深度学习训练，而推理只是你已经在GPU上加速的神经网络的向前传递。这是真的，GPU确实是推理的优秀硬件加速器。</p><p id="1c4c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">首先，我们来谈谈GPU到底是什么。</p><p id="22cf" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">GPU首先是吞吐量处理器，正如NVIDIA的这篇<a class="ae op" href="https://developer.nvidia.com/blog/cuda-refresher-reviewing-the-origins-of-gpu-computing/" rel="noopener ugc nofollow" target="_blank">博客文章所解释的</a>。它们旨在利用算法中固有的并行性，并通过并行计算来加速算法。GPU最初是作为计算机图形的专用处理器出现的，但今天的GPU已经发展成为可编程处理器，也称为通用GPU (GPGPU)。它们仍然是专门的并行处理器，但也是高度可编程的，用于可以通过并行化来加速的狭窄范围的应用。</p><p id="eb0e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">事实证明，早在深度学习之前，高性能计算(HPC)社区就已经在使用GPU来加速线性代数计算了。深度神经网络计算主要由类似的线性代数计算组成，因此用于深度学习的GPU是寻找问题的解决方案。毫不奇怪，Alex Krizhevsky的AlexNet深度神经网络赢得了ImageNet 2012竞赛，并(重新)向世界介绍了深度学习，它是在NVIDIA现成的可编程消费GPU上训练的。</p><p id="f7c0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">自那以后，GPU的速度变得更快了<a class="ae op" href="https://developer.nvidia.com/deep-learning-performance-training-inference" rel="noopener ugc nofollow" target="_blank">我会让你去NVIDIA的网站了解他们最新的流行机型的训练和推理基准</a>。虽然这些基准很好地表明了GPU的能力，但您的决定可能取决于下面讨论的其他因素。</p><h2 id="0ccd" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 1。GPU推理吞吐量、延迟和成本</strong></h2><p id="3b17" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">由于GPU是吞吐量设备，如果您的目标是最大限度地提高吞吐量，它们可以根据所需的延迟提供同类最佳的吞吐量，具体取决于部署的GPU类型和型号。GPU大放异彩的一个用例是离线或批量推理。GPU还将为小批量预测提供一些最低的延迟，但如果您无法始终将GPU利用率保持在最高水平，例如由于零星的推理请求(波动的客户需求)，您的成本/推理请求会上升(因为您为相同的GPU实例成本提供的请求较少)。对于这些情况，您最好使用Amazon Elastic Inference，它可以让您以较低的成本获得足够的GPU加速。</p><p id="ad72" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在示例部分，我们将看到不同精度(FP32、FP16、INT8)的GPU性能比较。</p><h2 id="3512" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 2。GPU推理支持的模型大小和选项</strong></h2><p id="c376" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在AWS上，您可以使用不同的NVIDIA GPUs、vCPUs数量、系统内存和网络带宽启动18个不同的Amazon EC2 GPU实例。两种最受欢迎的深度学习推理GPU是G4 EC2 instance type提供的英伟达T4 GPU和P3 EC2 instance type提供的英伟达V100 GPUs。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/3f7da47a8fb8339f5a0f1e6de89345eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KUPqoBsgOK93wOvM61NNJA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">博文:<a class="ae op" rel="noopener" target="_blank" href="/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86?source=friends_link&amp;sk=a7b056b6fdbed24ecb5e23f6ea8625cc">为AWS上的深度学习选择合适的GPU</a>(<em class="kv">作者截图</em>)</p></figure><p id="d253" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">关于AWS所有GPU实例类型的完整总结，请阅读我之前的博客文章:<a class="ae op" rel="noopener" target="_blank" href="/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86?source=friends_link&amp;sk=a7b056b6fdbed24ecb5e23f6ea8625cc">为AWS上的深度学习选择正确的GPU</a></p><p id="09a9" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">G4实例类型应该是深度学习推理部署的首选GPU实例。</p><p id="3389" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">基于英伟达图灵架构，英伟达T4 GPU具有FP64、FP32、FP16、张量内核(混合精度)和INT8精度类型。它们还拥有16 GB的GPU内存，对于大多数型号来说已经足够了，并结合了降低的精度支持。</p><p id="0d6e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果您需要更大的吞吐量或每个GPU需要更多的内存，那么P3实例类型提供了更强大的NVIDIA V100 GPU，通过<code class="fe or os ot ou b">p3dn.24xlarge</code>实例大小，您可以访问NVIDIA V100，它具有高达32 GB的GPU内存，可用于大型模型或大型图像或其他数据集。</p><h2 id="84ef" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">3.GPU推理模型类型、可编程性和易用性</h2><p id="0a12" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">与固定功能处理器的AWS Inferentia等ASICs不同，开发人员可以使用NVIDIA的CUDA编程模型来编写自定义层，这些层可以在NVIDIA GPU上加速。这正是Alex Krizhevsky在2012年对AlexNet所做的。他手工编写定制的CUDA内核，在GPU上训练他的神经网络。他称他的框架为cuda-convnet，你可以说cuda-convnet是第一个深度学习框架。如果你正在推动深度学习的边界，并且不想将性能留在桌面上，GPU是你的最佳选择。</p><blockquote class="nf ng nh"><p id="1c64" class="ls lt ni lu b lv ml jr lx ly mm ju ma nj mn mc md nk mo mf mg nl mp mi mj mk ij bi translated"><strong class="lu ir">可编程性与性能是GPU最大的优势之一</strong></p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/61125db6005607d043a8a44517635785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yf_4YRzuM9dRDvsLZ1NM-Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用NVIDIA的CUDA编程模型来编写可以在NVIDIA GPU上加速的自定义层。(<em class="kv">作者插图</em>)</p></figure><p id="7c7d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">当然，你不需要写低级别的GPU代码来做深度学习。NVIDIA已经通过cuDNN和cuBLAS等库提供了神经网络原语，TensorFlow、PyTorch和MXNet等深度学习框架在幕后使用这些库，因此您只需使用这些框架就可以免费获得GPU加速。这就是GPU在易用性和可编程性方面获得高分的原因。</p><h2 id="cb02" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">4.NVIDIA TensorRT的GPU性能</h2><p id="7347" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">如果你真的想让你的GPU发挥最佳性能，NVIDIA提供了TensorRT，一个用于推理部署的模型编译器。对经过训练的模型进行额外的优化，完整的列表可在NVIDIA的TensorRT网站上找到。需要注意的关键优化是:</p><ul class=""><li id="646d" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk ov mx my mz bi translated"><strong class="lu ir">量化</strong>:将模型精度从FP32(单精度)降低到FP16(半精度)或INT8 (8位整数精度)，从而减少计算量，加快推理速度</li><li id="bb17" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk ov mx my mz bi translated"><strong class="lu ir">图形融合</strong>:在GPU上将多个层/操作融合成一个对CUDA内核的函数调用。这减少了每个层/操作的多个函数调用的开销</li></ul><p id="ac46" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用NVIDIA TensorRT部署FP16非常简单。TensorRT编译器将在编译步骤中自动量化您的模型。</p><p id="9933" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">要使用INT8 precision进行部署，需要量化模型的权重和激活，以便可以使用适当的范围将浮点值转换为整数。你有两个选择。</p><ul class=""><li id="b03f" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk ov mx my mz bi translated"><strong class="lu ir">选项1 </strong>:执行量化感知训练。在量化感知训练中，从量化权重和张量到INT8的误差在训练期间被建模，允许模型适应和减轻该误差。这需要在培训期间进行额外的设置。</li><li id="cc24" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk ov mx my mz bi translated"><strong class="lu ir">选项二:</strong>进行训练后量化。在量化后培训中，不需要任何部署前准备。您将提供全精度(FP32)的训练模型，还需要提供训练数据集中的数据集样本，TensorRT编译器可以使用该样本来运行校准步骤以生成量化范围。在下面的示例2中，我们将看看选项2的实现。</li></ul><h2 id="e485" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">GPU加速推理示例</strong></h2><p id="4678" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">使用以下AWS深度学习AMI在亚马逊EC2 <code class="fe or os ot ou b">g4dn.xlarge</code>上测试了以下示例:深度学习AMI (Ubuntu 18.04)版本35.0。为了运行TensorRT，我使用了以下NVIDIA TensorFlow Docker映像:<code class="fe or os ot ou b">nvcr.io/nvidia/tensorflow:20.08-tf2-py3</code></p><p id="bd53" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">数据集</strong>:50000张测试图片的ImageNet验证数据集，转换为TFRecord <br/> <strong class="lu ir">模型</strong>:resnet 50的TensorFlow实现</p><p id="805c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">您可以在Jupyter笔记本上找到以下示例的完整实现:</p><blockquote class="nf ng nh"><p id="9321" class="ls lt ni lu b lv ml jr lx ly mm ju ma nj mn mc md nk mo mf mg nl mp mi mj mk ij bi translated"><a class="ae op" href="https://github.com/shashankprasanna/ai-accelerators-examples/blob/main/gpu-tf-tensorrt-resnet50.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/ai-accelerators-examples/blob/main/GPU-TF-tensorrt-resnet 50 . ipynb</a></p></blockquote><h2 id="87d3" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">示例1:部署ResNet50 TensorFlow模型(1)框架的原生GPU支持和(2)NVIDIA tensort</strong></h2><p id="e02c" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">TensorFlow的原生GPU加速支持开箱即用，无需额外设置。您不会获得NVIDIA TensorRT所能提供的额外性能，但当一切正常工作时，生活会变得多么轻松，这一点毋庸置疑。</p><p id="ec96" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用框架的本地GPU支持运行推理需要3行代码:</p><pre class="kg kh ki kj gt ow ou ox oy aw oz bi"><span id="58a8" class="kw kx iq ou b gy pa pb l pc pd">model = tf.keras.models.load_model(saved_model_dir)</span><span id="c52e" class="kw kx iq ou b gy pe pb l pc pd">for i, (validation_ds, batch_labels, _) in enumerate(dataset):<br/>    pred_prob_keras = model(validation_ds)</span></pre><p id="95ec" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">但是你真的把性能留在桌面上了(有时是性能的10倍)。为了提高GPU的性能和利用率，您必须使用推理编译器和运行时，如NVIDIA TensorRT。</p><p id="a36e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">下面的代码展示了如何用TensorRT编译您的模型。你可以在GitHub 上找到<a class="ae op" href="https://github.com/shashankprasanna/ai-accelerators-examples/blob/main/gpu-tf-tensorrt-resnet50.ipynb" rel="noopener ugc nofollow" target="_blank">的完整实现</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/46d20bcf2b0bf899deed33ed3ea7c04b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uh61gYo7kzVYZSbusxrd4Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">摘自:<a class="ae op" href="https://github.com/shashankprasanna/ai-accelerators-examples/blob/main/gpu-tf-tensorrt-resnet50.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/ai-accelerators-examples/blob/main/GPU-TF-tensorrt-resnet 50 . ipynb</a>(<em class="kv">作者截图</em>)</p></figure><p id="fa96" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">TensorRT编译有以下步骤:</p><ol class=""><li id="59f6" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk mw mx my mz bi translated">向TensorRT的<code class="fe or os ot ou b">TrtGraphConverterV2</code>(用于TensorFlow2)提供您未编译的TensorFlow保存模型</li><li id="8758" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated">指定TensorRT编译参数。最重要的参数是精度(FP32、FP16、INT8)。如果您正在使用INT8支持进行编译，TensorRT希望您从训练集中提供一个代表性样本来校准比例因子。当您调用<code class="fe or os ot ou b">converter.convert()</code>时，您将通过为参数<code class="fe or os ot ou b">calibration_input_fn</code>提供一个python生成器来实现这一点。您不需要为FP32和FP16优化提供额外的数据。</li><li id="8dd7" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated">TensorRT编译您的模型并将其保存为TensorFlow保存的模型，该模型包括特殊的TensorRT运算符，可加速GPU上的推理并更有效地运行它们。</li></ol><p id="2bc4" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">以下是TensorFlow ResNet50推理的准确性和性能对比:</p><ol class=""><li id="b1cf" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk mw mx my mz bi translated">TensorFlow原生GPU加速</li><li id="bef7" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated">tensor flow+tensort FP32精度</li><li id="74bb" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated">tensor flow+tensort FP16精度</li><li id="abbc" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated">tensor flow+tensort int 8精度</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/390854405c4404a370ba1f4bdd83b3b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/0*Vc5BxFyljqPDQiMK"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者截图</em>)</p></figure><p id="daef" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我测量的不仅仅是性能，还有精度，因为降低精度意味着信息的损失。在ImageNet测试数据集上，我们看到所有精度的精度损失可以忽略不计，而吞吐量略有增加。您的里程可能因型号而异。</p><h2 id="5517" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">示例2:使用Amazon SageMaker托管ResNet50 TensorFlow模型</strong></h2><p id="4d4a" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在示例1中，我们离线测试了性能，但是在大多数情况下，您将在云中托管您的模型，作为客户端应用程序可以向其提交推理请求的端点。最简单的方法之一是使用Amazon SageMaker托管功能。</p><p id="4282" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这个例子是在亚马逊SageMaker Studio笔记本上测试的。使用以下亚马逊SageMaker Studio conda环境运行该笔记本:TensorFlow 2 CPU优化。完整的实现可从以下网址获得:</p><blockquote class="nf ng nh"><p id="a9bc" class="ls lt ni lu b lv ml jr lx ly mm ju ma nj mn mc md nk mo mf mg nl mp mi mj mk ij bi translated"><a class="ae op" href="https://github.com/shashankprasanna/ai-accelerators-examples/blob/main/sagemaker-tf-cpu-gpu-ei-resnet50.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/ai-accelerators-examples/blob/main/sage maker-TF-CPU-GPU-ei-resnet 50 . ipynb</a></p></blockquote><p id="6b90" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用SageMaker托管模型端点包括以下简单步骤:</p><ol class=""><li id="6bba" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk mw mx my mz bi translated">使用您的TensorFlow保存的模型创建tar.gz存档文件，并将其上传到亚马逊S3</li><li id="152a" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated">使用Amazon SageMaker SDK API创建一个TensorFlowModel对象</li><li id="30a1" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated">使用英伟达T4 GPU将TensorFlowModel对象部署到G4 EC2实例</li></ol><p id="057b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用TensorFlow保存的模型创建model.tar.gz:</p><pre class="kg kh ki kj gt ow ou ox oy aw oz bi"><span id="1e55" class="kw kx iq ou b gy pa pb l pc pd">$ tar cvfz model.tar.gz -C resnet50_saved_model .</span></pre><p id="f143" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">将模型上传到S3并部署:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="652e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">您可以通过调用端点来测试模型，如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="1c74" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/897fc7550501b5a9366e42b5f33bbcca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*iTc5BrZ-lyqVVJq4"/></div></figure></div><div class="ab cl oc od hu oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="ij ik il im in"><h1 id="07f2" class="nm kx iq bd ky nn oj np lb nq ok ns le jw ol jx li jz om ka lm kc on kd lq nw bi translated">加速器选项2: AWS推理</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/28a8d0adc79a1163ff4b3685feeaa634.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*TQnaZ6cdrCPRSKJ4FHKymg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者插画</em>)</p></figure><p id="9fdf" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">AWS推理是亚马逊设计的定制芯片，用于经济高效、高吞吐量、低延迟的推理。</p><p id="38f8" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">詹姆斯·汉密尔顿(AWS副总裁兼杰出工程师)在他的博客文章<a class="ae op" href="https://perspectives.mvdirona.com/2018/11/aws-inferentia-machine-learning-processor/" rel="noopener ugc nofollow" target="_blank"> AWS推理机器学习处理器</a>中深入探讨了ASICs、通用处理器、AWS推理以及围绕它们的经济学，如果你对人工智能硬件感兴趣，我鼓励你阅读这篇文章。</p><p id="16b2" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">针对特定工作负载使用特定处理器的想法并不新鲜。降噪耳机中的芯片和DVD播放器中的视频解码器是专用芯片的例子，有时也称为专用集成电路(ASIC)。</p><p id="d561" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">ASICs有一项工作(或有限的责任)，并被优化来做好它。与通用处理器(CPU)或可编程加速器(GPU)不同，大部分芯片并不专用于运行任意代码。</p><p id="f59d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">AWS推理是专门为在云中以最低的成本提供高推理性能而构建的。AWS推理芯片可以通过Amazon EC2 Inf1实例访问，这些实例有不同的大小，每个实例有1个AWS推理芯片，每个实例最多有16个AWS推理芯片。每个AWS推理芯片有4个神经元，支持FP16、BF16和INT8数据类型。NeuronCore是一个高性能的<a class="ae op" href="https://en.wikipedia.org/wiki/Systolic_array" rel="noopener ugc nofollow" target="_blank">脉动阵列</a>矩阵乘法引擎，每个都有一个两级内存层次，一个非常大的片上缓存。</p><p id="a5d1" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在大多数情况下，如果您的模型:</p><ul class=""><li id="d3a5" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk ov mx my mz bi translated">曾在MXNet、TensorFlow、PyTorch接受培训或已转换为ONNX</li><li id="7e88" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk ov mx my mz bi translated">拥有由AWS Neuron SDK 支持的<a class="ae op" href="https://github.com/aws/aws-neuron-sdk/tree/master/release-notes/neuron-cc-ops" rel="noopener ugc nofollow" target="_blank">操作符</a></li></ul><p id="442f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果您有AWS Neuron SDK不支持的操作符，您仍然可以在Inf1实例上成功地部署它，但是这些操作将在主机CPU上运行，并且不会在AWS Inferentia上加速。正如我前面所说的，每个用例都是不同的，所以用AWS Neuron SDK编译您的模型，并测量性能，以确保它满足您的性能、延迟和吞吐量需求。</p><h2 id="b083" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">1.AWS推理吞吐量、延迟和成本</h2><p id="a215" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">AWS比较了流行模型的AWS推理与GPU实例的性能，并报告了流行模型的较低成本:<a class="ae op" href="https://aws.amazon.com/blogs/machine-learning/improving-performance-for-deep-learning-based-object-detection-with-an-aws-neuron-compiled-yolov4-model-on-aws-inferentia/" rel="noopener ugc nofollow" target="_blank"> YOLOv4模型</a>、<a class="ae op" href="https://aws.amazon.com/blogs/machine-learning/deploying-tensorflow-openpose-on-aws-inferentia-based-inf1-instances-for-significant-price-performance-improvements/" rel="noopener ugc nofollow" target="_blank"> OpenPose </a>，并提供了TensorFlow、MXNet和PyTorch 的BERT和SSD的<a class="ae op" href="https://github.com/aws/aws-neuron-sdk/tree/master/src/examples" rel="noopener ugc nofollow" target="_blank">示例。对于实时应用程序，AWS Inf1实例是AWS上可用的所有加速选项中最便宜的，与GPU和CPU相比，AWS Inferentia可以在目标延迟下以更低的成本提供更高的吞吐量。最终，您的选择可能取决于下面讨论的其他因素。</a></p><h2 id="5df1" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 2。AWS推理支持的模型、运算符和精度</strong></h2><p id="fb21" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">AWS推理芯片支持通过AWS Neuron SDK公开的一组固定的神经网络操作符。当您使用AWS Neuron SDK编译一个面向AWS推理的模型时，编译器将检查您的模型中是否有您的框架支持的<a class="ae op" href="https://github.com/aws/aws-neuron-sdk/tree/master/release-notes/neuron-cc-ops" rel="noopener ugc nofollow" target="_blank">操作符。如果不支持某个操作符，或者如果编译器确定某个特定操作符在CPU上执行效率更高，它将对图形进行分区，以包括CPU分区和AWS推理分区。亚马逊弹性推理也是如此，我们将在下一节讨论。如果您将TensorFlow与AWS推理一起使用，这里列出了所有在AWS推理</a>上加速的<a class="ae op" href="https://github.com/aws/aws-neuron-sdk/blob/master/release-notes/neuron-cc-ops/neuron-cc-ops-tensorflow.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow操作。</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pl"><img src="../Images/3b001b139d4449c91b2da46c95e08b47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*par-L2Rw8OOTtHiR"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">定制操作将是CPU分区的一部分，并将在主机实例的CPU上运行(作者的<em class="kv">插图)</em></p></figure><p id="aeda" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果您在FP32(单精度)中训练您的模型，AWS Neuron SDK编译器会自动将您的FP32模型转换为BF16以提高推理性能。如果您更喜欢在FP16中提供模型，无论是通过在FP16中训练还是通过执行训练后量化，AWS Neuron SDK将直接使用您的FP16权重。虽然INT8受AWS推理芯片支持，但AWS Neuron SDK编译器目前不提供支持INT8的部署方式。</p><h2 id="2aaf" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 3。AWS推理灵活性和对如何使用推理神经元的控制</strong></h2><p id="3eee" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在大多数情况下，AWS Neuron SDK使AWS推理真正易于使用。使用AWS推理和GPU的用户体验的一个关键区别是，AWS推理让您可以更好地控制每个内核的使用方式。</p><p id="18d8" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">AWS Neuron SDK支持两种利用所有NeuronCores提高性能的方式:<strong class="lu ir"> (1)批处理</strong>和<strong class="lu ir"> (2)流水线</strong>。因为AWS Neuron SDK编译器是一个超前编译器，所以您必须在编译阶段显式启用这些选项。</p><p id="e43c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">让我们看看这些是什么以及它们是如何工作的。</p><h2 id="8d1d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> a .使用批处理来最大化较大批量的生产量</strong></h2><p id="4a58" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">当您使用AWS Neuron SDK编译器编译一个大于1的模型时，批处理将被启用。在推理过程中，您的模型权重存储在外部存储器中，当开始向前传递时，由神经元运行时确定的层权重子集被复制到片上缓存中。使用缓存中该图层的权重，对整个批次计算向前传递。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pm"><img src="../Images/5d6a8107c462aac0f55c97db6b6b6b3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Za4q2JzHhOMLeouaf4gw8A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者插图</em>)</p></figure><p id="2cdf" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">之后，将下一组图层权重加载到缓存中，并对整个批次计算向前传递。这个过程继续进行，直到所有的权重都用于推理计算。当层仍在缓存中时，通过对大批量进行推理，批处理允许更好地分摊从外部存储器读取权重的成本。</p><p id="2619" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">所有这些都发生在后台，作为用户，您只需在编译期间使用示例输入设置所需的批处理大小。</p><p id="9d65" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">即使批处理大小是在编译阶段设置的，在启用动态批处理的情况下，模型也可以接受可变大小的批处理。在内部，neuron runtime将把用户批量分解为编译后的批量，并运行推理。</p><h2 id="cc4d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> b .使用流水线技术，通过跨多个神经元缓存模型来改善延迟</strong></h2><p id="2eae" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在批处理期间，模型权重从外部存储器逐层加载到片内缓存。借助流水线技术，您可以将整个模型权重加载到多核的片上缓存中。这可以减少延迟，因为神经元运行时不必从外部存储器加载权重。同样，所有这些都发生在幕后，作为用户，您只需在编译阶段使用<code class="fe or os ot ou b">—-num-neuroncores</code>设置所需的内核数量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pn"><img src="../Images/e3297a8bcc511e6aaab259d9537c6d9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i3-B23KxhwWod1jMBPjHzw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者插图</em>)</p></figure><p id="3821" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">批处理和流水线可以一起使用。但是，您必须尝试不同的流水线内核和编译批处理大小的组合，以确定最适合您的模型的组合。</p><p id="408b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在编译步骤中，批次大小和神经元核心数量的所有组合(对于流水线)可能都不适用。您必须通过扫描不同的值并监控编译器错误来确定批处理大小和神经元核心数量的工作组合。</p><h2 id="f166" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">在你的Inf1实例上使用所有神经核心</strong></h2><p id="8780" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">根据您编译模型的方式，您可以:</p><ol class=""><li id="7234" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk mw mx my mz bi translated">编译您的模型，以便在具有特定批处理大小的单个NeuronCore上运行</li><li id="1e76" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated">通过管道将模型编译到具有特定批处理大小的多个神经元</li></ol><p id="b716" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">成本最低的Amazon EC2 Inf1实例类型，<code class="fe or os ot ou b">inf1.xlarge</code>有1个AWS推理芯片和4个神经元。如果您将模型编译为在单个NeuronCore上运行，<code class="fe or os ot ou b">tensorflow-neuron</code>将自动在所有4个neuron core上并行执行数据。这相当于将您的模型复制4次，并将其加载到每个NeuronCore中，然后运行4个Python线程将数据输入到每个核心中。自动数据并行执行在1 AWS推理芯片之外不起作用。例如，如果您想将您的模型复制到一个<code class="fe or os ot ou b">inf1.6xlarge</code>上的所有16个神经元，您必须生成多个线程来向所有AWS推理芯片提供数据。在python中你可以使用<a class="ae op" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor" rel="noopener ugc nofollow" target="_blank">concurrent . futures . threadpoolexecutor</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi po"><img src="../Images/fc972e3241aa72dd246a9881b473a342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qr5uUH0DS2P8L0FjJ2cYog.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者截图</em>)</p></figure><p id="0848" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">当你为多个神经核心编译一个模型时，运行时将为每个神经核心分配不同的子图(作者截图)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pp"><img src="../Images/cd973e1aabf605cf6688500da43036c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QsYfbW9_ud52f0xGG7LawA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">当你用流水线编译一个模型时，运行时会给每个NeuronCore分配不同的子图(作者截图)</p></figure><h2 id="82b4" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 4。在Inf1实例上部署多个模型</strong></h2><p id="bffe" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">AWS Neuron SDK允许您将神经元分组到逻辑组中。每组可以有一个或多个神经元，可以运行不同的模型。例如，如果您在inf1.6xlarge EC2 Inf1实例上进行部署，您可以访问4个推理芯片，每个芯片有4个神经内核，即总共有16个神经内核。你可以把16个神经元分成3组。第1组有8个神经元核心，将运行一个使用流水线来使用所有8个核心的模型。第2组使用4个神经元核心，运行用1个神经元核心编译的模型的4个副本。第3组使用4个神经元核，并运行用2个神经元核通过流水线编译的模型的2个副本。您可以使用neuron core _ GROUP _ size环境变量来指定此配置，并将其设置为NEURONCORE _ GROUP _ SIZES =，1，1，1，1，2，2</p><p id="19c0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">之后，您只需在单个python进程中按指定顺序加载模型，即首先加载编译为使用8个内核的模型，然后加载编译为使用1个内核的模型四次，然后使用加载编译为使用2个内核的模型两次。适当的核心将被分配给模型。</p><h2 id="b133" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">Amazon EC2 Inf1实例上的AWS推理加速推理示例</h2><p id="b131" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">AWS Neuron SDK预装在AWS深度学习AMI上，你也可以<a class="ae op" href="https://github.com/aws/aws-neuron-sdk/blob/master/docs/neuron-install-guide.md" rel="noopener ugc nofollow" target="_blank">安装SDK和神经元加速的框架和库</a> TensorFlow、TensorFlow Serving、TensorBoard(带神经元支持)、MXNet和PyTorch。</p><p id="a578" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">下面的例子是在亚马逊EC2 <code class="fe or os ot ou b">Inf1.xlarge</code>和深度学习AMI(Ubuntu 18.04)35.0版本上测试的。</p><p id="6592" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">您可以在Jupyter笔记本上找到以下示例的完整实现:</p><blockquote class="nf ng nh"><p id="9e05" class="ls lt ni lu b lv ml jr lx ly mm ju ma nj mn mc md nk mo mf mg nl mp mi mj mk ij bi translated"><a class="ae op" href="https://github.com/shashankprasanna/ai-accelerators-examples/blob/main/inf1-neuron-sdk-resnet50.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/ai-accelerators-examples/blob/main/in f1-neuron-SDK-resnet 50 . ipynb</a></p></blockquote><h2 id="a4fe" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">示例1:在AWS推理系统</strong>上部署带有AWS Neuron SDK的ResNet50 TensorFlow模型</h2><p id="1257" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在这个例子中，我比较了3个不同的选项</p><ol class=""><li id="7722" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk mw mx my mz bi translated"><strong class="lu ir">无批处理，无流水线</strong>:编译ResNet50模型，批量= 1，核数= 1</li><li id="ed0a" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated"><strong class="lu ir">有批处理，无流水线</strong>:编译ResNet50模型，批处理大小= 5，内核数= 1</li><li id="5f22" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk mw mx my mz bi translated"><strong class="lu ir">无批处理，带流水线</strong>:编译ResNet50模型，批量= 1，核数= 4</li></ol><p id="26ff" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">你可以在这个Jupyter笔记本中找到完整的实现<a class="ae op" href="https://github.com/shashankprasanna/ai-accelerators-examples/blob/main/inf1-neuron-sdk-resnet50.ipynb" rel="noopener ugc nofollow" target="_blank">。我就在这里回顾一下结果。</a></p><p id="f5bf" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">下面的比较表明，在Inf1.xlarge实例上，使用选项2(批处理大小= 1，无流水线)可以获得最佳吞吐量。您可以在大型Inf1实例上用其他组合重复这个实验。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pq"><img src="../Images/5679ed1fd18bd7ddbbaab0c19f3aca01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*swfrd1XcjNg4Frm6"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者截图</em>)</p></figure></div><div class="ab cl oc od hu oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="ij ik il im in"><h1 id="08c6" class="nm kx iq bd ky nn oj np lb nq ok ns le jw ol jx li jz om ka lm kc on kd lq nw bi translated">加速器选项3:亚马逊弹性推理(EI)推理加速</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pr"><img src="../Images/0e6e1b39fcc8da05f0ab68582efa183b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GCofxPd9KSEDl5Zayrs3vQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">亚马逊弹性推理(<em class="kv">作者插图</em>)</p></figure><p id="f6c0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><a class="ae op" href="https://aws.amazon.com/machine-learning/elastic-inference/" rel="noopener ugc nofollow" target="_blank">亚马逊弹性推理(EI) </a>允许您向纯CPU实例添加经济高效的可变大小GPU加速，而无需配置专用的GPU实例。要使用Amazon EI，您只需提供一个纯CPU实例，如Amazon EC2 C5实例类型，并在发布时从6个不同的EI加速器选项中进行选择。</p><p id="276a" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">EI加速器不是构成您的CPU实例的硬件的一部分，相反，EI加速器通过使用AWS PrivateLink端点服务的网络连接，该服务将流量从您的实例路由到使用您的实例配置的弹性推理加速器。当您使用支持EI的服务框架(如TensorFlow serving)时，所有这些都在幕后无缝发生。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ps"><img src="../Images/4e248985bc74e4341585f5929a5bcd63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f9brsKYeX8GpnfWWSfKvbQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">弹性推理允许您访问可变大小的GPU加速(<em class="kv">作者插图</em>)</p></figure><p id="8181" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">Amazon EI使用GPU来提供GPU加速，但与专用GPU实例不同，您可以选择添加6种不同加速器大小的GPU加速，您可以通过每秒万亿次浮点运算(TFLOPS)或GPU内存来选择。</p><h2 id="67a5" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">为什么选择Amazon EI而不是专用GPU实例？</strong></h2><p id="a896" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">正如我前面所讨论的，GPU主要是吞吐量设备，当处理实时应用程序常见的较小批量时，当您部署不需要GPU的全部处理能力或全部内存的模型时，GPU往往得不到充分利用。此外，如果您没有足够的需求或多个模型来服务和共享GPU，那么单个GPU可能不具成本效益，因为成本/推理会上升。</p><p id="56ae" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">您可以从6种不同的EI加速器中进行选择，这些加速器提供1–4 TFLOPS和1–8 GB的GPU内存。假设您有一个计算要求较低的模型，内存占用较小，您可以将最小的EI加速器(如<code class="fe or os ot ou b">eia1.medium</code>)连接到一个CPU实例，该加速器提供1 TFLOPS的FP32性能和1 GB的GPU内存。如果您有一个要求更高的模型，您可以将一个具有4 TFLOPS性能和8 GB GPU内存的<code class="fe or os ot ou b">eia2.xlarge</code> EI加速器附加到一个CPU实例上。</p><p id="9858" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">CPU实例+ EI加速器的成本仍然比专用GPU实例便宜，并且可以降低推理成本。您不必担心GPU利用率的最大化，因为您添加的容量刚好满足需求，不会过度配置。</p><h2 id="e377" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">什么时候选择亚马逊EI而不是GPU，选择什么样的EI加速器尺寸？</strong></h2><p id="6b38" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">让我们考虑下面的假设场景。比方说，如果您的总延迟(应用+网络+模型预测)低于200毫秒，您的应用可以提供良好的客户体验。比方说，使用G4实例类型，您可以将总延迟降至40毫秒，这完全在您的目标延迟范围内。您还尝试了使用纯CPU C5实例类型进行部署，您只能获得400毫秒的总延迟，这不符合您的SLA要求，导致客户体验不佳。</p><p id="8116" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">通过弹性推理，您可以将足够的GPU加速通过网络连接到一个CPU实例。在探索了不同的EI加速器尺寸(比如<code class="fe or os ot ou b">eia2.medium</code>、<code class="fe or os ot ou b">eia2.large</code>、<code class="fe or os ot ou b">eia2.xlarge</code>)之后，您可以使用<code class="fe or os ot ou b">eia2.large</code> EI加速器将总延迟降至180毫秒，低于预期的200毫秒。由于EI比配置专用GPU实例便宜得多，因此您可以节省总部署成本。</p><h2 id="0dc4" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 1。亚马逊弹性推理性能</strong></h2><p id="2210" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">由于GPU加速是通过网络添加的，因此与专用GPU实例相比，EI会增加一些延迟，但仍比纯CPU实例更快，并且比专用GPU实例更具成本效益。与EI相比，专用GPU实例仍将提供更好的推理性能，但如果额外的性能没有改善您的客户体验，使用EI您将保持在目标延迟SLA之下，提供良好的客户体验，并节省总体部署成本。AWS有许多<a class="ae op" href="https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-elastic-inference/" rel="noopener ugc nofollow" target="_blank">博客帖子，谈论与使用流行的深度学习框架的CPU和GPU相比的性能和成本节省</a>。</p><h2 id="169c" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak"> 2。支持的型号类型、可编程性和易用性</strong></h2><p id="0372" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">亚马逊EI支持在TensorFlow、Apache MXNet、Pytorch和ONNX模型上训练的模型。在您启动一个连接了Amazon EI的Amazon EC2实例后，要访问加速器，您需要一个支持EI的框架，比如TensorFlow、PyTorch或Apache MXNet。</p><p id="cb80" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">支持EI的框架预装在<a class="ae op" href="https://docs.aws.amazon.com/dlami/latest/devguide/what-is-dlami.html" rel="noopener ugc nofollow" target="_blank"> AWS深度学习AMI </a>上，但如果你更喜欢<a class="ae op" href="https://docs.aws.amazon.com/elastic-inference/latest/developerguide/ei-tensorflow.html" rel="noopener ugc nofollow" target="_blank">手动安装，</a>Python wheel文件也已可用。</p><p id="6b61" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">大多数流行的模型，如Inception，ResNet，SSD，RCNN，GNMT，都经过测试，在与Amazon EI一起部署时，可以节省成本。如果您正在部署带有自定义操作符的自定义模型，则支持EI的框架会对图形进行分区，以便在主机CPU上运行不支持的操作符，并在通过网络连接的EI加速器上运行所有支持的操作。这使得使用EI非常简单。</p><h2 id="defa" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">示例:使用Amazon EI部署ResNet50 TensorFlow模型</strong></h2><p id="8906" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">这个例子是在亚马逊EC2 c5.2xlarge下面的AWS深度学习AMI上测试的:深度学习AMI (Ubuntu 18.04)版本35.0</p><p id="da8d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">您可以在此处找到Jupyter笔记本的完整实现:</p><blockquote class="nf ng nh"><p id="5f28" class="ls lt ni lu b lv ml jr lx ly mm ju ma nj mn mc md nk mo mf mg nl mp mi mj mk ij bi translated"><a class="ae op" href="https://github.com/shashankprasanna/ai-accelerators-examples/blob/main/ei-tensorflow-resnet50.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/ai-accelerators-examples/blob/main/ei-tensor flow-resnet 50 . ipynb</a></p></blockquote><p id="413b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">Amazon EI enabled TensorFlow提供的API允许您使用EI加速器加速模型，其行为就像TensorFlow API一样。作为一名开发人员，您应该尽可能少地修改代码。</p><p id="ac25" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">要加载模型，只需运行以下代码:</p><pre class="kg kh ki kj gt ow ou ox oy aw oz bi"><span id="172b" class="kw kx iq ou b gy pa pb l pc pd">from ei_for_tf.python.predictor.ei_predictor import EIPredictor</span><span id="abf0" class="kw kx iq ou b gy pe pb l pc pd">eia_model = EIPredictor(saved_model_dir,accelerator_id=0)</span></pre><p id="1d7c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果有多个EI加速器连接到您的实例，您可以使用accelerator_id参数来指定它们。只需用eia_model替换TensorFlow模型对象，脚本的其余部分保持不变，您的模型现在在Amazon EI上加速了。</p><p id="dba7" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">下图比较了在同一个CPU实例上的纯CPU推理和EI加速推理。在本例中，您可以看到使用EI加速器后速度提高了6倍以上。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/9d1fea328f46aea40c2e0891391d3ffd.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/0*7jgl7I8p8Sp1XCjH"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<em class="kv">作者截图</em>)</p></figure><h1 id="e947" class="nm kx iq bd ky nn no np lb nq nr ns le jw nt jx li jz nu ka lm kc nv kd lq nw bi translated">摘要</h1><p id="27ae" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">如果我想让你从这篇博文中学到什么，那就是:部署需求是独一无二的，没有放之四海而皆准的方法。回顾您的部署目标，将它们与本文中的讨论进行比较，并测试所有选项。云让你在提交之前尝试变得简单。</p><p id="59a5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在选择时，请牢记以下注意事项:</p><ul class=""><li id="1f1f" class="mr ms iq lu b lv ml ly mm lf mt lj mu ln mv mk ov mx my mz bi translated">模型类型和可编程性(模型大小、自定义操作符、支持的框架)</li><li id="7db4" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk ov mx my mz bi translated">目标吞吐量、延迟和成本(在预算范围内提供良好的客户体验)</li><li id="645c" class="mr ms iq lu b lv na ly nb lf nc lj nd ln ne mk ov mx my mz bi translated">编译器和运行时工具链的易用性(快速学习曲线，不需要硬件知识)</li></ul><p id="b8bc" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果可编程性非常重要，并且您的性能目标较低，那么CPU可能正好适合您。</p><p id="58d7" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果可编程性和性能很重要，那么您可以为在GPU上加速的定制操作开发定制CUDA内核。</p><p id="c35e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果您想要最低成本的选项，并且您的模型在AWS推理上受支持，那么您可以节省总体部署成本。</p><p id="32b6" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">易用性是主观的，但没有什么能打败原生框架体验。但是，稍加努力，AWS Neuron SDK for AWS Inferentia和NVIDIA TensorRT for NVIDIA GPUs都可以提供更高的性能，从而降低成本/推理。</p><p id="dc38" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">感谢您的阅读。在本文中，我只能给你一瞥我们在本文中讨论的所有样本代码。如果您想重现结果，请访问以下GitHub repo:</p><blockquote class="nf ng nh"><p id="9f8c" class="ls lt ni lu b lv ml jr lx ly mm ju ma nj mn mc md nk mo mf mg nl mp mi mj mk ij bi translated"><a class="ae op" href="https://github.com/shashankprasanna/ai-accelerators-examples" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/ai-accelerators-examples</a></p></blockquote><p id="7c4f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果你觉得这篇文章有趣，请看看我在<a class="ae op" href="https://medium.com/@shashankprasanna" rel="noopener">媒体</a>上的其他博文。</p><p id="147f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">想让我写一个特定的机器学习主题吗？我很想收到你的来信！在twitter ( <a class="ae op" href="https://twitter.com/shshnkp" rel="noopener ugc nofollow" target="_blank"> @shshnkp </a>)，<a class="ae op" href="https://www.linkedin.com/in/shashankprasanna/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>关注我或者在下面留言评论。</p></div></div>    
</body>
</html>