<html>
<head>
<title>LDA Topic Modeling
for High Blood Pressure
Drugs Reviews</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高血压药物综述的LDA主题建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lda-topic-modeling-for-high-blood-pressure-drugs-reviews-ff40af2ee319?source=collection_archive---------34-----------------------#2020-11-03">https://towardsdatascience.com/lda-topic-modeling-for-high-blood-pressure-drugs-reviews-ff40af2ee319?source=collection_archive---------34-----------------------#2020-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f5ef729115fa0681163e0c141af7b12a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HANgbWke7_R_UFmKeUzKsw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图片由作者“联合国新冠肺炎对策”提供</p></figure><p id="1598" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">主题建模是一种利用无监督机器学习算法的文本分析技术。主题建模的最终目标是在大量文本文档中发现主题，并发现隐藏的主题。语料库中的每个文档将由至少一个主题组成，如果不是多个主题的话。主题建模对于文档聚类和非结构化文本的信息检索非常有用。</p><p id="68b3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir">潜在狄利克雷分配</strong> </a> (LDA)是一种用于主题建模的算法，用于将文档中的文本聚类成主题列表。</p><p id="cb66" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这里我们将把LDA应用于一组高血压药物综述文档，并把它们分成主题。</p><h1 id="bbcc" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">动机</h1><p id="b9f0" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">目标是通过对这些分组主题的分析，从这些评论中获得深刻见解:</p><ul class=""><li id="5e85" class="me mf iq ke b kf kg kj kk kn mg kr mh kv mi kz mj mk ml mm bi translated">从综述中探索所有高血压药物共有的潜在主题。</li><li id="a5b7" class="me mf iq ke b kf mn kj mo kn mp kr mq kv mr kz mj mk ml mm bi translated">预测给定评论文本的评分。</li></ul><p id="59c8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们开始吧！</p><h1 id="6021" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据集</h1><p id="0127" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">该分析中使用的数据集是从WebMD药物评论数据集(可从<a class="ae la" href="https://www.kaggle.com/rohanharode07/webmd-drug-reviews-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载)中提取的约18，000份患者对用于治疗高血压的药物的评论列表。数据提供者通过抓取<a class="ae la" href="https://www.webmd.com/drugs/2/index" rel="noopener ugc nofollow" target="_blank"> WebMD </a>站点获取数据集。原始数据集中约有36万行独特的评论，更新到2020年3月。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="3d73" class="nb lc iq mx b gy nc nd l ne nf">import pandas as pd</span><span id="4b93" class="nb lc iq mx b gy ng nd l ne nf"># Read data into papers<br/>drug_df = pd.read_csv('C:/Users/Johnny Phua/Metis/Project4/Drug Review/webmd.csv')</span><span id="e0bc" class="nb lc iq mx b gy ng nd l ne nf">hbp_drug_df = drug_df[drug_df["Condition"] == 'High Blood Pressure']</span></pre><p id="e68c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">看一眼数据。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="f0a9" class="nb lc iq mx b gy nc nd l ne nf">print(len(hbp_drug_df))<br/>hbp_drug_df.head()</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/d7bea6f065ff0862f68296b3b253421f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*je5vbjhfZWBqnjLgSzt54w.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图1:药品评论数据集的前5行。</p></figure><h1 id="cfea" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据预处理</h1><p id="f567" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">执行了以下步骤:</p><ul class=""><li id="195d" class="me mf iq ke b kf kg kj kk kn mg kr mh kv mi kz mj mk ml mm bi translated"><strong class="ke ir">小写</strong>单词并删除非字母字符。</li><li id="ab3d" class="me mf iq ke b kf mn kj mo kn mp kr mq kv mr kz mj mk ml mm bi translated">字<strong class="ke ir"> &lt;三字</strong>被<strong class="ke ir">去掉</strong>。</li><li id="f4de" class="me mf iq ke b kf mn kj mo kn mp kr mq kv mr kz mj mk ml mm bi translated"><strong class="ke ir">分词</strong>:将文本拆分成单词。</li><li id="6efe" class="me mf iq ke b kf mn kj mo kn mp kr mq kv mr kz mj mk ml mm bi translated">所有<strong class="ke ir">停用字</strong>都被移除。</li><li id="fe6d" class="me mf iq ke b kf mn kj mo kn mp kr mq kv mr kz mj mk ml mm bi translated">单词被<strong class="ke ir">词条化</strong>:第三人称的单词被改为第一人称，过去时态和将来时态的动词被改为现在时态。</li><li id="4803" class="me mf iq ke b kf mn kj mo kn mp kr mq kv mr kz mj mk ml mm bi translated">单词被词干化:单词被还原成它们的词根形式。</li></ul><p id="3d9e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">以下功能用于小写单词、删除非字母字符以及删除少于3个字符的单词:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="029e" class="nb lc iq mx b gy nc nd l ne nf">import re</span><span id="236a" class="nb lc iq mx b gy ng nd l ne nf">def clean_non_alpha(text):<br/>    return re.sub('[^a-zA-Z]',' ', str(text))</span><span id="4250" class="nb lc iq mx b gy ng nd l ne nf">def remove_short_word(text):<br/>    return  re.sub(r'\b\w{1,3}\b', '', str(text))</span><span id="6677" class="nb lc iq mx b gy ng nd l ne nf">def convert_to_lower(text):<br/>    return re.sub(r'([A-Z])', lambda m: m.group(1).lower(),  <br/>    str(text))</span></pre><p id="1a6e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">标记化</strong></p><p id="1254" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">标记化就是将一个字符串拆分成一系列标记的过程<strong class="ke ir">。标记是整体的一部分，所以在我们的上下文中，单词是句子中的标记。</strong></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="93d7" class="nb lc iq mx b gy nc nd l ne nf">from nltk.tokenize import RegexpTokenizer</span><span id="692d" class="nb lc iq mx b gy ng nd l ne nf">def get_tokenize(text):<br/>    """<br/>    function to tokenize text to list of words.<br/>    """<br/>    tokenizer = RegexpTokenizer(r'\w+')<br/>    return tokenizer.tokenize(str(text))</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/09c19efc0ad64f48c2d2a6adf0d42292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IvFDT9i07VrAuDrS0FsdqQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图2:标记化后列表中的单词</p></figure><p id="a8f3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">删除停用词、词汇化、词干</strong></p><p id="42bc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">下面的函数做的工作是去除停止字，词汇化和词干化。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="3025" class="nb lc iq mx b gy nc nd l ne nf">from nltk.stem import WordNetLemmatizer<br/>lemma = WordNetLemmatizer()<br/>from nltk.stem import PorterStemmer<br/>stemmer = PorterStemmer()<br/>from nltk.corpus import stopwords<br/>stop_words = stopwords.words('english')</span><span id="78e9" class="nb lc iq mx b gy ng nd l ne nf">def remove_stopwords(token):<br/>    """<br/>    function to remove stopwords<br/>    """<br/>    return [item for item in token if item not in stop_words]</span><span id="a23c" class="nb lc iq mx b gy ng nd l ne nf">def clean_lemmatization(token):<br/>    #from nltk.stem import WordNetLemmatizer<br/>    #lemma = WordNetLemmatizer()<br/>    return [lemma.lemmatize(word=w,pos='v') for w in token]</span><span id="d0b6" class="nb lc iq mx b gy ng nd l ne nf">def clean_stem(token):<br/>    #from nltk.stem import PorterStemmer<br/>    #stemmer = PorterStemmer()<br/>    return [stemmer.stem(i) for i in token]</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/09c19efc0ad64f48c2d2a6adf0d42292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IvFDT9i07VrAuDrS0FsdqQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图3:去除停用词、词汇化和词干后的标记。</p></figure><p id="f7f1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">数据集现在是干净的，并且格式正确。它现在可以用于LDA建模。</p><p id="43d6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然而，在我们开始训练模型之前，我们将如何决定使主题可解释性的最佳主题数量。</p><p id="bf64" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> 1)主题建模中主题数(k)的确定方法是什么？</strong></p><p id="4bf9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">确定主题模型的最佳主题数(k)的方法之一是通过比较C_V一致性分数。最佳的话题数量会产生最高的C_V连贯分数。Coherence查看每个生成的主题中最频繁出现的单词，对它们之间的语义相似性进行评级(使用UCI或Umass进行成对计算)，然后找到模型中所有主题的平均一致性分数。(<a class="ae la" href="http://qpleple.com/topic-coherence-to-evaluate-topic-models/" rel="noopener ugc nofollow" target="_blank">http://qp ple . com/topic-coherence-to-evaluate-topic-models/</a>)</p><p id="9033" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们如何评估和提高模型结果的可解释性？</p><p id="72db" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">一旦我们选择了主题的最佳数量，接下来要问的问题是如何最好地评估和提高这些主题的可解释性。一种方法是可视化我们的主题模型的结果，以确保它们对我们的场景有意义。我们可以使用pyLDAvis工具来可视化您的LDA模型对主题及其热门词的拟合。</p><h1 id="2736" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">一袋单词</h1><p id="0387" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">从“reviews_docs”创建一个字典，包含一个单词在训练集中出现的次数。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="7fac" class="nb lc iq mx b gy nc nd l ne nf">from gensim import corpora<br/>dictionary = corpora.Dictionary(reviews)<br/></span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/1741d2d87e1163ebfcb1072bc5c9c86c.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*tcD_hG-klXlbeMj6iDtpuA.jpeg"/></div></figure><p id="ae5b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用Gensim.filter_extremes内置函数过滤出出现在，</p><ul class=""><li id="b153" class="me mf iq ke b kf kg kj kk kn mg kr mh kv mi kz mj mk ml mm bi translated">少于15份文件(绝对数量)或</li><li id="ce93" class="me mf iq ke b kf mn kj mo kn mp kr mq kv mr kz mj mk ml mm bi translated">超过0.5个文档(总语料库大小的一部分，而不是绝对数量)。</li><li id="76e6" class="me mf iq ke b kf mn kj mo kn mp kr mq kv mr kz mj mk ml mm bi translated">在上述两个步骤之后，只保留那些出现次数为11及以上的标记，换句话说，只保留前2130个最频繁的标记。</li></ul><p id="6433" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">通过检查整个单词字典的频率分布(按频率降序排列)，我们可以知道前2130个单词/记号对于每个记号具有11个及以上的出现次数。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="b95e" class="nb lc iq mx b gy nc nd l ne nf"># first get a list of all words<br/>all_words = [word for item in      list(hbp_drug_df['reviews_text_processed']) for word in item]</span><span id="b19a" class="nb lc iq mx b gy ng nd l ne nf"># use nltk FreqDist to get a frequency distribution of all words<br/>fdist = FreqDist(all_words)  </span><span id="1dfa" class="nb lc iq mx b gy ng nd l ne nf"># choose k and visually inspect the bottom 10 words of the top k<br/>k = 2130<br/>top_k_words = fdist.most_common(k)<br/>top_k_words[-10:]</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/75271f810efba615d6e147a90994fc0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*Nfz8AhP8SiFdRVX4BAPF9g.jpeg"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图5:语料库的词频分布。</p></figure><p id="a4b6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">将上述过滤器应用于gensim字典:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="1c37" class="nb lc iq mx b gy nc nd l ne nf">dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=2130)</span></pre><p id="bf2b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然后，我们为每个文档创建一个文档单词矩阵，报告有多少单词以及这些单词出现了多少次。将此保存到‘doc _ term _ matrix’。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="7461" class="nb lc iq mx b gy nc nd l ne nf">from gensim import corpora<br/>doc_term_matrix = [dictionary.doc2bow(rev) for rev in reviews]</span></pre><h1 id="e394" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">使用单词包运行LDA</h1><p id="d867" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">准备好字典和doc_term_matrix后，现在我们可以使用<strong class="ke ir">gensim . models . LDA model . LDA model</strong>来训练LDA模型。</p><p id="bb1d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然而，此时，我们需要问的下一个问题是，我们应该使用多少个主题(k)来训练我们的模型？我们可以利用c_v coherence score和pyLDAvis可视化工具来决定我们的模型的最佳主题数量。</p><p id="d674" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">计算c_v一致性分数:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a6fb" class="nb lc iq mx b gy nc nd l ne nf">#Calculate the c_v Coherence Score for different k from 1 to 10.<br/>from tqdm import tqdm<br/>from gensim.models import LdaModel<br/><br/>coherenceList_cv = []<br/>num_topics_list = np.arange(1,10)</span><span id="cc51" class="nb lc iq mx b gy ng nd l ne nf">for num_topics in tqdm(num_topics_list):<br/>    <br/>    lda_model =  LdaModel(corpus=doc_term_matrix,id2word=dictionary,num_topics=num_topics,random_state=100, update_every=1, chunksize=1000, passes=50, alpha='auto', per_word_topics=True)<br/>    <br/>    cm_cv = CoherenceModel(model=lda_model, corpus=doc_term_matrix, texts=reviews, dictionary=dictionary, coherence='c_v')<br/>    <br/>    coherenceList_cv.append(cm_cv.get_coherence())</span></pre><p id="331d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">绘制pyLDAvis:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="483e" class="nb lc iq mx b gy nc nd l ne nf"># Plotting tools<br/>import pyLDAvis<br/>import pyLDAvis.gensim</span><span id="a71a" class="nb lc iq mx b gy ng nd l ne nf"># Visualize the topics<br/>pyLDAvis.enable_notebook()<br/>vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)<br/>vis</span></pre><p id="05c9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">什么是话题连贯？</strong></p><p id="c64e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">连贯性测量在每个生成的主题中最频繁出现的单词，评定它们之间的语义相似性；利用UCI或Umass来执行成对计算；然后为该模型计算所有主题的平均<a class="ae la" href="http://qpleple.com/topic-coherence-to-evaluate-topic-models/" rel="noopener ugc nofollow" target="_blank">一致性分数</a>。</p><p id="d1c8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">从下面我们的模型中不同k个主题的c_v一致性分数分布可以看出，主题数k=3和k=5给出了同样高的分数。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/c1c403c6942690b4e5102d5b37ca556f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vhc1adurkwLZB9a-9hoxWA.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图6:k个主题的c_v连贯分数</p></figure><p id="e265" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然而，如果我们绘制pyLDAvis图，很明显，k=3将比k=5给出更有希望的结果。可以注意到，对于k=5，主题1、2和3彼此高度重叠。而对于k=3，主题在不同的象限中被很好地分开。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/aa1501ddf34429941291dfa73d3bcf79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ujo1eh8mCetIJgwmo2C-7w.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图7:k从1到10的pyLDAvis图</p></figure><p id="3493" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">t-SNE图也清楚地表明，k=3比k=5好得多，因为可以注意到，当k=5时，有3个主题相互重叠。</p><div class="ms mt mu mv gt ab cb"><figure class="nn jr no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/1f2e447c7786b08680af0c1d96eb5bc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*MVODsC-fK07VsleaJoClxQ.png"/></div></figure><figure class="nn jr no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/018b8f6e7834f343b920d308665c0754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*CLqmrt9NTzedqMcKKM3McQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk nt di nu nv translated">图8:k = 3和k=5时的t-SNE图</p></figure></div><p id="0af8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，我们可以使用k=3来生成LDA模型。让α和β超参数自动生成。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="fc78" class="nb lc iq mx b gy nc nd l ne nf">import gensim</span><span id="eac4" class="nb lc iq mx b gy ng nd l ne nf"># Creating the object for LDA model using gensim library<br/>LDA = gensim.models.ldamodel.LdaModel</span><span id="bfc8" class="nb lc iq mx b gy ng nd l ne nf"># Build LDA model<br/>lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=3, random_state=100, chunksize=1000, passes=50, update_every=1, alpha='auto', eta='auto', per_word_topics=True)</span></pre><p id="e720" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">您可以使用<em class="nw"> lda_model.show_topic(): </em>查看每个主题的前10个关键词以及每个关键词的权重(重要性)</p><p id="c0e7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">0 [('天'，0.043550313)，('感觉'，0.03116778)，('时间'，0.030068435)，('得到'，0.0252915)，('喜欢'，0.020811914)，('迪子'，0.017624224)，('使'，0.017559748)，('胎'，0.01706512</p><p id="d9a3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">1 [('压'，0.046297483)，('效'，0.045646794)，('血'，0.044705234)，('方'，0.041772064)，('功'，0.027191896)，('年'，0.026943726)，('医'，0.024851086)，('下'，0.0203996)。</p><p id="2368" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">2 [('咳嗽'，0.038522985)，('疼痛'，0.021691399)，('药物'，0.02127608)，(' caus '，0.017660549)，(' sever '，0.01583576)，('走'，0.01558094)，('医生'，0.01529741)，('停'，0.015242598</p><h1 id="196c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">词云</h1><p id="85fd" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">我们来看看模型的词云分布。</p><div class="ms mt mu mv gt ab cb"><figure class="nn jr nx np nq nr ns paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/7ea2bccb6375c7b01b340b8b43791fc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*Ar4Dgs4q2J7VoVxbuQgaoQ.png"/></div></figure><figure class="nn jr ny np nq nr ns paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/331e9ba5d519dab60b83e91e32e90b71.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*bYXv4m31m7wc2O8CLI0VUw.png"/></div></figure><figure class="nn jr nz np nq nr ns paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/fcb3fd6afe544d9715a5f85ffbda3308.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*oc4iqQSI2KWHaiwRlcGzDg.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk oa di ob nv translated">图9:单词云</p></figure></div><p id="17f0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">通过参考高血压药物的一些常见副作用的列表，可以注意到主题0和主题2显示了下面提到的列表中的一些副作用。</p><p id="1053" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">高血压药物的一些常见副作用包括:</p><p id="579b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">咳嗽</strong></p><p id="83d5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">腹泻或便秘</p><p id="d12e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">头晕</strong>或头晕</p><p id="1ccd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">剧烈而突然的脚部<strong class="ke ir">疼痛</strong></p><p id="fd4f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">感到紧张</p><p id="09db" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">感觉<strong class="ke ir">疲倦</strong>、虚弱、困倦或缺乏能量</p><p id="1e24" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">头痛</strong></p><p id="ac68" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">恶心或呕吐</p><p id="f9bb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">皮疹</p><p id="3be3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">无需尝试就能减肥或增重</p><ul class=""><li id="34e8" class="me mf iq ke b kf kg kj kk kn mg kr mh kv mi kz mj mk ml mm bi translated"><strong class="ke ir">腿肿</strong></li></ul><h1 id="7330" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">获得洞察力</h1><p id="5243" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">通过从数据集中随机读取耐心的评论，可以注意到，主题0和主题2的评论显示耐心对于这两个主题经历了不同类型的副作用。而专题2的综述表明，这类患者的耐心比专题0经历了更严重的副作用，因为专题2的患者采取了诸如停止服用该药物并改用另一种药物的行动。然而，对于以主题1为主导主题的耐心的评论显示，该药物对他们有效，并且仅经历轻微的副作用症状。</p><p id="e57f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在我们可以给这个主题贴上如下标签:</p><p id="a619" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">主题0:副作用类型I —“头晕”、“疲倦”、“头痛”</p><p id="26ac" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">话题1:药物有效</p><p id="27d8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">主题2:第二类副作用——“咳嗽”、“肿胀”、“疼痛”</p><div class="ms mt mu mv gt ab cb"><figure class="nn jr oc np nq nr ns paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/f547f2fbbc0af79bc67eb299ac996cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*eu1u6c0jh7lEA18VhxgkLA.png"/></div></figure><figure class="nn jr oc np nq nr ns paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/54a05036efbd4fbe474a5f9de27cc566.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*HCW3IzHBErKSSve6a5YRIA.png"/></div></figure><figure class="nn jr oc np nq nr ns paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/8abb7c6f81b646442af45deb9649578b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*o2ZtEJC8qzkLI8oKoBlHhw.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk od di oe nv translated">图10:各主题满意率统计</p></figure></div><p id="27fa" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">从上述三幅图中可以看出，在主题1中聚集了评论的患者对等级为3及以上的药物最满意。而主题0和主题2的患者对2级及以下的评分大多不满意。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi of"><img src="../Images/993663d75df5591383808ef6fb691864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*CXWY2bIIfSB7h9M4jZ3K8A.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图11:每个主题的文档数。</p></figure><p id="636f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">从上面的图表可以看出，大约55%服用高血压药物的患者会出现某种副作用症状。</p></div></div>    
</body>
</html>