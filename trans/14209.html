<html>
<head>
<title>Training a Neural Network to do 18 different things.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练一个神经网络做18种不同的事情。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-the-same-cnn-to-do-18-different-things-and-visualizing-what-it-learned-b7d6db26aadf?source=collection_archive---------45-----------------------#2020-09-30">https://towardsdatascience.com/training-the-same-cnn-to-do-18-different-things-and-visualizing-what-it-learned-b7d6db26aadf?source=collection_archive---------45-----------------------#2020-09-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/c0ef200d6f07e9c5bfc45935778d9b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C1dic71bNXQoCICsV_8A9w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">卡通形象</p></figure><div class=""/><p id="f1ef" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke jg">卷积神经网络(CNN) </strong>架构对于视觉任务来说是非常通用的。在本文中，我将讲述我在18个不同的分类任务中使用相同网络架构的经验。</p><p id="cfe6" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">分类任务包括面部特征，如下巴长度(3个等级)、头发类型(111种类型)和头发颜色(10种头发颜色)等。</p><p id="3efd" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我将使用谷歌提供的100k图像数据集<a class="ae la" href="https://google.github.io/cartoonset/download.html" rel="noopener ugc nofollow" target="_blank">这里</a>。我为这些实验编写的代码可以在<a class="ae la" href="https://github.com/prwlnght/deep_learning/blob/master/vision/toons_classifier.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="4303" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">对于这些实验，我使用了10K版本的数据集。在最初的探索中，数据集由10个文件夹组成。首要任务是从<a class="ae la" href="https://google.github.io/cartoonset/download.html" rel="noopener ugc nofollow" target="_blank">网站</a>下载数据集并提取出来。您将看到这10个文件夹:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="2c4d" class="lk ll jf lg b gy lm ln l lo lp">['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']</span></pre><p id="6416" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">每个子文件夹中都有。png '图像文件和一个. csv描述符文件。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="c91c" class="lk ll jf lg b gy lm ln l lo lp">['cs11502169095236683120.csv',<br/> 'cs11502169095236683120.png',<br/> 'cs11502298889929094331.csv',<br/> 'cs11502298889929094331.png',<br/> 'cs11502404786906647764.csv',<br/> 'cs11502404786906647764.png',<br/> 'cs11502407216397343631.csv',<br/> 'cs11502407216397343631.png',<br/> 'cs11502919926067511421.csv',<br/> 'cs11502919926067511421.png']</span></pre><p id="213d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们做一个快速的可视化:(在<a class="ae la" href="https://github.com/prwlnght/deep_learning/blob/master/vision/toons_classifier.ipynb" rel="noopener ugc nofollow" target="_blank"> github </a>中检查我的代码)</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lq"><img src="../Images/47781226520ba64393319287bb04cdef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OGPUBU7C5jP09Key5agI0g.png"/></div></div></figure><p id="d62d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">有对应的。csv文件(与图像同名)，其描述格式如下:</p><p id="06ce" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">“脸型”，4，7 <br/>“面部_头发”，14，15 <br/>“头发”，29，111 <br/>“眼睛_颜色”，2，5 <br/> …</p><p id="0c4e" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这些描述中的每一个都可能是“特征”，我们可以沿着这些特征建立一个深度学习网络来对图像进行分类。根据数据集描述<a class="ae la" href="https://google.github.io/cartoonset/download.html" rel="noopener ugc nofollow" target="_blank">页面</a>可知，“这些集合中的每个卡通人脸都由<strong class="ke jg"> 18个组件</strong>组成，这些组件在<strong class="ke jg"> 10个图稿属性</strong>、<strong class="ke jg"> 4个颜色属性</strong>、<strong class="ke jg"> 4个比例属性</strong>上有所不同。每个属性的选项数量(将成为每个模型的类)的范围是下巴长度3，发型111。</p><p id="7bea" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">根据数据集设计<a class="ae la" href="https://google.github.io/cartoonset/download.html" rel="noopener ugc nofollow" target="_blank">页面</a>，“这些组件中的每一个及其变化都是由同一个艺术家Shiraz Fuman绘制的，产生了大约<strong class="ke jg"> 250个</strong>卡通组件艺术品和<strong class="ke jg"> ~10^13 </strong>可能的组合”。</p><p id="6f09" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">正如我所承诺的，我将建立总共18个网络，它们都应该被专门化(希望如此)为特征分类器。在随后的文章中，我将用迁移学习和多标签分类的几种不同方法来解决这个问题。</p><p id="71fc" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">首先是网络定义:</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/aa3a8ff1e402fa14f1f614ad622dc721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*ghLfYRCLo5Nb7lWAHV-kmA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">我使用的神经网络的结构。我用Keras做了一个。你会注意到，在每一个卷积层之后，我都做了一个最大池化、一个批量归一化和一个丢弃。这些层的确切顺序实际上是一个见仁见智的问题，不应该影响性能。您可以颠倒batch_norm和dropout的顺序，看看它是否工作得更好。我的猜测是，无论如何都不会有太大的改变。注意只有最终的密集层对于不同的分类具有不同数量的节点。</p></figure><h1 id="c4fb" class="ls ll jf bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">各层的一点背景</h1><p id="8ab4" class="pw-post-body-paragraph kc kd jf ke b kf mp kh ki kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz ij bi translated"><a class="ae la" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank"><strong class="ke jg"/></a>卷积层帮助网络学习移位或空间不变特征，并将这种先验信念引入网络结构。从这个意义上说，卷积神经网络是神经网络的正则化版本，有助于大大减少学习的参数数量。如上图所示，这种网络结构需要训练的参数略多于一百万。</p><p id="7be3" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank"> <strong class="ke jg">最大池层数</strong> </a>用于基于样本的离散化，目的是对输入表示进行下采样。您可以看到，要素地图从(256，256，3)的输入大小开始，由于最大池化图层和选定的跨距，随着它穿过网络，慢慢变得越来越窄和越来越深。</p><p id="8950" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank"> <strong class="ke jg">批量标准化</strong> </a>是一种将输入移至零均值和单位方差的方法。一个非常高层次的理解是，这有助于使数据跨功能进行比较。众所周知，它能提高学习速度(尽管对其有效性还有其他解释)。</p><p id="45fa" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最后，<a class="ae la" href="https://jmlr.org/papers/v15/srivastava14a.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ke jg"> Dropout </strong> </a>是一种正则化技术，近似训练具有许多不同架构的大量神经网络。它通过随机丢弃每层中各种节点的激活来实现这一点(由丢弃概率指定)。效果是它在训练过程中引入了噪声，因此像任何正则化技术一样帮助网络更好地泛化。</p><p id="46f8" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，继续训练网络。为了快速迭代，我想利用keras '<a class="ae la" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory" rel="noopener ugc nofollow" target="_blank"><strong class="ke jg">image _ dataset _ from _ directory</strong></a>，因为它负责图像大小转换、验证分割、插值和批处理。该函数产生一个张量流数据集，操作和处理起来非常简单。</p><blockquote class="mu mv mw"><p id="6e8c" class="kc kd mx ke b kf kg kh ki kj kk kl km my ko kp kq mz ks kt ku na kw kx ky kz ij bi translated">train _ dataset = TF . keras . preprocessing . image _ dataset _ from _ directory(<br/>training _ dir，<br/>labels = " extruded "，<br/> label_mode="int "，<br/> class_names=None，<br/> color_mode="rgb "，<br/> batch_size=32，<br/> image_size=(256，256)，<br/> shuffle=True，<br/> seed=42，<br/> validation_split=.2，【t</p></blockquote><p id="9367" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因此，为了方便起见，我编写了一个函数，将文件复制到一个缓存临时目录中。我使用了一个SSD位置来加速IO。该功能是在<a class="ae la" href="https://github.com/prwlnght/deep_learning/blob/master/vision/toons_classifier.ipynb" rel="noopener ugc nofollow" target="_blank"> github </a> repo中提供的copy_images_to_labels_folder。</p><p id="c321" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">此外，我设置了一个tensorboard回调来可视化损失。这是为分类“脸型”而构建的神经网络的可视化示例。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/a37529ea770dc25075d275c31203542f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_YgG-Z_LeeivKSO3EJVM1A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">数据集中总共有6种脸型。神经网络的结构似乎很擅长区分脸型，这可以从训练和验证损失非常快地接近0看出。训练了30个时期的模型的最终准确度是100%。有趣的是，验证损失比训练损失下降的速度快得多。这是因为训练是拖尾平滑的测量。</p></figure><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/86226dbc09b03797d89236f6091db799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*NOiaL6TRYlMtvUXeaYmD_A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">对于“面部颜色”检测器，网络显示过度拟合，如绿色(验证)和粉色(训练)度量之间的差异所示。这应该通过增加正则化参数(如退出概率)或通过获得更多的训练数据来减轻。最终网络获得了一个不错的准确度。或者可能在从rgba到rgb的转换过程中缺少alpha通道会把事情弄糟。</p></figure><p id="df17" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最后，下表显示了各种网络获得的精度。我用NVIDIA 2080 Ti训练了所有这些。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/e9ddf3467280bd57c3c2992fa29e58c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*SX1sb_yJXaKFcpQePnXgag.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">CNN在相同架构上训练30个时期后获得的准确度。第一项是空白的，因为有一些损坏的数据。第二列表示每个面部维度的类别数。</p></figure><p id="2d62" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">第一次，我觉得一切都很好，但对于一些像“眼睫毛”这样的情况，网络之前没有收敛。具体来说，损失值为“nan ”,这表示爆炸梯度或消失梯度问题。以下是我发现的nan在训练convnet时出现的主要原因。这并不意味着是一份详尽的清单。</p><p id="a775" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">爆炸渐变——你的LR太大了</p><p id="696c" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">b) <strong class="ke jg">故障损失函数</strong> —您使用的是自定义损失，还是正确使用标准损失。有一次，我使用了一个节点数少于我预测的类数的输出层，结果一整天都是nans。</p><p id="feda" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">c) <strong class="ke jg">输入数据</strong> —是否存在腐败实例？就像这里的第一个网络一样。</p><p id="598c" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">d) <strong class="ke jg">超参数</strong> —其中一些具有相互依赖性，因此在更改默认值之前，请查看文档。</p><p id="3c80" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">e)<strong class="ke jg">LR不合适</strong> —尝试使用Adam这样的自适应技术，看看是否有帮助。</p><h1 id="13bd" class="ls ll jf bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">最后，可解释性。</h1><p id="9a06" class="pw-post-body-paragraph kc kd jf ke b kf mp kh ki kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz ij bi translated">我利用了一种技术，通过一种叫做<a class="ae la" href="https://arxiv.org/abs/1703.01365" rel="noopener ugc nofollow" target="_blank">综合梯度</a>的过程，将深度网络的预测归因于其输入特征。下图可以解释为网络在做出决策时“关注”的地方。(<a class="ae la" href="https://github.com/prwlnght/deep_learning/blob/master/vision/model_interpretability.ipynb" rel="noopener ugc nofollow" target="_blank"> github页面</a>用于代码和其他可视化)。<a class="ae la" href="https://arxiv.org/abs/1703.01365" rel="noopener ugc nofollow" target="_blank">参考</a>页面了解更多信息。</p><p id="5ac3" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">下巴长度:97%</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/0cade78da74146e07e0d945e4be38646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uLaeDVdl51IaqMc--qKxYg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">首先是下巴长度分类器:正常梯度和综合梯度似乎都发现了下巴曲率的重要性。然而，仍然没有完全磨练出来。</p></figure><p id="cfc9" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">眼睛颜色:85%</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/00502a9a29dbf942c881bc9b101e68e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*enUkfH72PsqSGJsLzhV13g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">眼睛颜色分类器。正常梯度看起来一点不错。你几乎要眯着眼看它。积分梯度没那么大。也许是因为我没有正确设置一些实现超参数。</p></figure><p id="81ab" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">眼眉距离:84%</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/b981265ba43ec37c799c3e495e372811.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zqhFcNHD4pnI7MdYQOm6A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">这个是眉毛距离分类器。渐变是准确的。</p></figure><p id="49a3" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">眼镜颜色:54.66%</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/962033d1b18c20840d31cfe95afc7fa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Gk4rcI_RV57azMVIFUCHg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">正常梯度看起来像他们在预期的位置。但是颜色区分绝对不是这个CNN的强项。你能猜到原因吗？(提示:考虑渠道信息—它们何时以及如何组合)。我将在以后的帖子中包括一个缓解策略。</p></figure><p id="74e0" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">面部颜色:26.04%</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/2d5c42e1f04a7b368301a73abd38bdab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QToDpYx9s4V5TdvSmseYeQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">这又是一个与颜色分类有关的坏问题。CNN似乎是色盲。(有些人会说，这并不总是坏事)。因此，只看梯度图也是一种了解神经网络是否至少在做直观的事情的好方法。(顺便说一下，这张图片被错误分类了)。</p></figure><p id="7166" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这是这次培训的情况:</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/4b0d3cb297796b35f61e5d8a5d5fb394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*9bWrN53_hCdKQee_BMOwbA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">训练显示了验证损失的剧烈变化，训练曲线相对平滑。也有迹象表明过度合身。考虑到我几乎完全关闭了退出(为了速度)，并且依赖于批处理规范化所具有的一点点正则化效果，一个快速的补救实验将是使用一个合适的退出级别。</p></figure><p id="91a5" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">发色:96.13%</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/4ff25c98e6fed83906b010c776f4f4a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ff_pL6ZNKoy4uydrPuczFg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">头发颜色分类器比预期的要好得多。</p></figure><p id="f6b2" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">发型:99.70%</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/f4b5408da93fe9c5aaf37c585bdc8032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ps2m8M3Nu-QV7WDiUUhD_g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">具有111个类别的发型分类器在仅30个时期内具有超过99.7 %的验证准确度，并且表现得令人惊讶地好。</p></figure><p id="de08" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你想知道更多关于可解释性和可解释人工智能的一般子领域的信息，请看这篇<a class="ae la" rel="noopener" target="_blank" href="/should-ai-explain-itself-or-should-we-design-explainable-ai-so-that-it-doesnt-have-to-90e75bb6089e">帖子</a>。</p><p id="9fee" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">耗时分析:</p><p id="75ea" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我花了大约3个小时编写代码，所有18个模型在NVIDIA 2080 Ti上训练了30个时代。</p><h1 id="84ff" class="ls ll jf bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated"><strong class="ak">结论:</strong></h1><p id="e393" class="pw-post-body-paragraph kc kd jf ke b kf mp kh ki kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz ij bi translated">在这篇文章中，我分享了我建立和训练CNN的经验，在没有任何干预和超参数调整的情况下，解决了18个不同的分类任务。这些网络的性能肯定可以通过利用更多数据、迁移学习、更健壮的架构或更仔细地选择超参数来提高，但这几乎不是重点。关键是，CNN是相当通用的，现在做得很好，不需要花太多时间。</p><p id="5d1b" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果您觉得这篇文章或代码有帮助，或者有建议，让我们在评论部分继续讨论。</p><p id="57c9" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">对计算机视觉、生成网络或强化学习感兴趣？未来的文章请关注我，并在L<a class="ae la" href="https://www.linkedin.com/in/paudyalprajwal/" rel="noopener ugc nofollow" target="_blank">ink din</a>上关注我。</p></div></div>    
</body>
</html>