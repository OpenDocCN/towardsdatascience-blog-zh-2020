<html>
<head>
<title>Text Vectorization: Bag of Words (BoW)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本矢量化:单词包(BoW)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-vectorization-bag-of-words-bow-441d1bfce897?source=collection_archive---------20-----------------------#2020-09-28">https://towardsdatascience.com/text-vectorization-bag-of-words-bow-441d1bfce897?source=collection_archive---------20-----------------------#2020-09-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ec57" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何将文本特征转换成矢量</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/98380dc8446743830e275125967da6d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U0hBA8NnTD6l7L8Z2j-eiQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://unsplash.com/photos/BVyNlchWqzs" rel="noopener ugc nofollow" target="_blank">阿玛多·洛雷罗</a>拍摄，来自Unsplash</p></figure><p id="ecf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文本数据用于自然语言处理(NLP)，它使用自然语言在人类和机器之间进行交互。文本数据有助于分析电影评论、使用亚马逊评论的产品等。但这里出现的问题是<strong class="lb iu">在建立机器学习模型时，如何处理文本数据？</strong></p><p id="741c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过各种技术将文本数据转换成实值向量。一种这样的方法是<strong class="lb iu">单词包(BoW)，</strong>，这将在本文中讨论。但是<strong class="lb iu">为什么我们要把文本转换成矢量呢？为什么不能用文本数据建立机器学习模型？</strong></p><h2 id="939e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">需要文本矢量化</h2><p id="420b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">假设我们有一个产品的评论。客户提供的文本评论长度不同。通过将文本转换成数字，我们可以用有限长度的向量来表示评论。这样，无论文本长度如何，每次评论的向量长度都是相等的。</p><p id="41a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单词包是文本到向量的最简单的表示。向量的每一列代表一个单词。行中每个单元格中的值显示一个单词在句子中出现的次数。</p><p id="e4be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">例子</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/8b98673614b1542b36953df8e7f1b060.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*PuyVAffx2GLwqzZmmOE52w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="2ca0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一步是找到一个独特单词的<strong class="lb iu">词汇表</strong>(忽略标点符号和大小写)。上面例子中的词汇:</p><p id="a0e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">【这个，电影，是，那个，好，的，时代，不是，我，爱，看，你，会，它，太】</strong></p><p id="dfdf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的词汇中，有15个独特的单词。所以<strong class="lb iu">每一条影评都用一个15维的向量来表示</strong>(每个词代表一个维度)。对于第一次审查:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/d145dfb037b45055fc3661c0503f0383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fojk86PrWNcu4Y5K8oQlyw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="c63c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对应于每个单词的值显示了一个单词在评论中出现的次数。类似地，15维向量表示剩余的评论。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/03d0008bb861e425e36312ca3fe71860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S8uW62e3AbYw3gnylm4eDg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="7237" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在现实问题中，文本数据在矢量化之前必须进行预处理。预处理包括删除标点符号，将所有单词转换为小写，以及删除对文本没有任何价值的不必要的单词。</p><p id="c0fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在自然语言处理(NLP)中，不必要的单词被称为<strong class="lb iu">停用词</strong>。nltk 库已经包含了停用词列表。英语中有179个停用词。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/3728482dfe74b5d1795c3c454d80f7ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*2WnkBwFQ8IXPTIjc6vHRdQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/1ed229a438c2376e3c1951b1df661da6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BYraN4G6KT0Nyiwdld305g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="e4b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将看到我们的例子后，删除停用词。</p><p id="928c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">词汇<strong class="lb iu">——【电影，好，时代，爱情，看点】</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/5bb90702ab42f9c613f29cbe3e3c87d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*O45Br4kasWksn6E0vxWRTg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="e1da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，review 1和2的向量是相同的，因为“not”出现在停用词中。该模型认为两个评论是相同的，因为两者的向量是相等的。这个问题的一个解决方案是使用<strong class="lb iu"> n元语法。</strong></p><h2 id="ec8e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">n-grams</h2><p id="aa23" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">n元语法是n个单词的相邻序列。n可以是任何正整数。</p><p id="2804" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，“单词包”是三个字母，“文本矢量化”是两个字母。</p><p id="d308" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，我们使用了一元语法。这意味着每个单词都被认为是一个特征。删除停用词将删除诸如“not”之类可能有用的词。基于单字的单词包(BoW)不考虑序列信息。为了考虑序列信息，我们使用<strong class="lb iu">二元语法、三元语法</strong>等。</p><p id="2c61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，如果我们使用二元语法，词汇可以改为:</p><p id="46af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">【这部电影，电影是，是好的，这部电影，不是，不是好的，我爱，爱这个，看电影，看你，你会，会爱，爱它，它太】</strong></p><p id="187c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，n-grams将比基于单-gram的模型给出更好的结果。</p><h2 id="cf7e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">弓的缺点</h2><ol class=""><li id="7e82" class="mz na it lb b lc mo lf mp li nb lm nc lq nd lu ne nf ng nh bi translated">向量的长度可以很长，大部分值为零。从计算上来说，如果词汇量很大，效率就不高。</li><li id="09d1" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">基于单字的BoW无法捕捉文本的上下文。二元模型和三元模型可以完成这项工作，但是计算量很大。</li></ol><h2 id="836b" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">结论</h2><p id="b110" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">单词包是一种文本矢量化技术，可以将文本转换为有限长度的向量。boW模型易于实现和理解。单词袋有一些缺点，可以通过使用先进的技术来克服。</p><p id="0374" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读！</p></div></div>    
</body>
</html>