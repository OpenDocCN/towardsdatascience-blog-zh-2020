<html>
<head>
<title>Image Segmentation Using Keras and W&amp;B</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">åŸºäºKeraså’ŒW&amp;Bçš„å›¾åƒåˆ†å‰²</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/image-segmentation-using-keras-and-w-b-98223c38e4d4?source=collection_archive---------28-----------------------#2020-09-22">https://towardsdatascience.com/image-segmentation-using-keras-and-w-b-98223c38e4d4?source=collection_archive---------28-----------------------#2020-09-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="339c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">è¯¥æŠ¥å‘Šåˆ©ç”¨Kerasä¸­ç±»ä¼¼UNETçš„æ¶æ„æ¢ç´¢è¯­ä¹‰åˆ†å‰²ï¼Œå¹¶äº¤äº’å¼å¯è§†åŒ–æ¨¡å‹å¯¹æƒé‡åå·®çš„é¢„æµ‹&amp;ã€‚</strong></h2></div><h2 id="3f59" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">ç‚¹å‡»æŸ¥çœ‹äº’åŠ¨æŠ¥é“<a class="ae lb" href="https://wandb.ai/ayush-thakur/image-segmentation/reports/Image-Segmentation-Using-Keras-and-W-B--VmlldzoyNTE1Njc" rel="noopener ugc nofollow" target="_blank">ã€‚è¿™é‡Œæœ‰</a><a class="ae lb" href="https://colab.research.google.com/drive/1rXV31gdyqEiXCtmSgff-H-VRuOSzv7IH?usp=sharing" rel="noopener ugc nofollow" target="_blank">çš„Colabç¬”è®°æœ¬</a>ã€‚</h2><h1 id="bd41" class="lc kg iq bd kh ld le lf kk lg lh li kn jw lj jx kr jz lk ka kv kc ll kd kz lm bi translated">ä»‹ç»</h1><p id="58b8" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv ko lw lx ly ks lz ma mb kw mc md me mf ij bi translated">æ‚¨æ˜¯å¦æœ‰å…´è¶£äº†è§£å›¾åƒä¸­æŸä¸ªå¯¹è±¡çš„ä½ç½®ï¼Ÿè¿™ä¸ªç‰©ä½“çš„å½¢çŠ¶æ˜¯ä»€ä¹ˆï¼Ÿå“ªäº›åƒç´ å±äºå¯¹è±¡ï¼Ÿä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦åˆ†å‰²å›¾åƒï¼Œå³å°†å›¾åƒçš„æ¯ä¸ªåƒç´ åˆ†ç±»åˆ°å®ƒæ‰€å±çš„å¯¹è±¡ï¼Œæˆ–è€…ç»™å›¾åƒçš„æ¯ä¸ªåƒç´ ä¸€ä¸ªæ ‡ç­¾ï¼Œè€Œä¸æ˜¯ç»™å›¾åƒä¸€ä¸ªæ ‡ç­¾ã€‚</p><p id="6985" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated"><strong class="lp ir">å› æ­¤ï¼Œå›¾åƒåˆ†å‰²æ˜¯ä¸ºå›¾åƒä¸­çš„æ¯ä¸ªå¯¹è±¡å­¦ä¹ é€åƒç´ æ©æ¨¡çš„ä»»åŠ¡ã€‚</strong>ä¸ä¸ºå›¾åƒä¸­å‡ºç°çš„æ¯ä¸ªå¯¹è±¡ç»™å‡ºè¾¹ç•Œæ¡†åæ ‡çš„å¯¹è±¡æ£€æµ‹ä¸åŒï¼Œå›¾åƒåˆ†å‰²å¯¹å›¾åƒä¸­çš„å¯¹è±¡ç»™å‡ºäº†æ›´ç²¾ç»†çš„ç†è§£ã€‚</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/fdd859833edccfebe5adb18f3edb7077.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*at8_d54v1l9DbWhF9SAovg.png"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">å›¾1 </strong>:è¯­ä¹‰åˆ‡åˆ†å’Œå®ä¾‹åˆ‡åˆ†ã€‚(<a class="ae lb" href="https://www.researchgate.net/figure/Semantic-segmentation-left-and-Instance-segmentation-right-8_fig1_339616270" rel="noopener ugc nofollow" target="_blank">æ¥æº</a>)</p></figure><p id="6805" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">å›¾åƒåˆ†å‰²å¯ä»¥å¤§è‡´åˆ†ä¸ºä¸¤ç§ç±»å‹:</p><ul class=""><li id="95ff" class="my mz iq lp b lq mg lt mh ko na ks nb kw nc mf nd ne nf ng bi translated"><strong class="lp ir">è¯­ä¹‰åˆ†å‰²:</strong>è¿™é‡Œï¼Œæ¯ä¸ªåƒç´ å±äºä¸€ä¸ªç‰¹å®šçš„ç±»ã€‚å›¾1ä¸­çš„å·¦å›¾æ˜¯è¯­ä¹‰åˆ†å‰²çš„ä¸€ä¸ªä¾‹å­ã€‚åƒç´ æˆ–è€…å±äºäºº(ä¸€ä¸ªç±»åˆ«)ï¼Œæˆ–è€…å±äºèƒŒæ™¯(å¦ä¸€ä¸ªç±»åˆ«)ã€‚</li><li id="f76f" class="my mz iq lp b lq nh lt ni ko nj ks nk kw nl mf nd ne nf ng bi translated"><strong class="lp ir">å®ä¾‹åˆ†å‰²:</strong>è¿™é‡Œï¼Œæ¯ä¸ªåƒç´ å±äºä¸€ä¸ªç‰¹å®šçš„ç±»ã€‚ä½†æ˜¯ï¼Œå±äºç¦»æ•£å¯¹è±¡çš„åƒç´ ç”¨ä¸åŒçš„é¢œè‰²(è’™ç‰ˆå€¼)æ ‡è®°ã€‚å›¾1ä¸­çš„å³å›¾æ˜¯ä¸€ä¸ªå®ä¾‹åˆ†å‰²çš„ä¾‹å­ã€‚å±äºè¯¥äººç‰©ç±»åˆ«çš„åƒç´ è¢«ä¸åŒåœ°ç€è‰²ã€‚</li></ul><p id="b2de" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">è¯¥æŠ¥å‘Šå°†<strong class="lp ir">å»ºç«‹ä¸€ä¸ªè¯­ä¹‰åˆ†å‰²æ¨¡å‹</strong>ï¼Œå¹¶åœ¨<a class="ae lb" href="https://www.robots.ox.ac.uk/%7Evgg/data/pets/" rel="noopener ugc nofollow" target="_blank">ç‰›æ´¥-IIIT Petæ•°æ®é›†</a>ä¸Šå¯¹å…¶è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬å°†<strong class="lp ir">äº¤äº’å¯è§†åŒ–æˆ‘ä»¬æ¨¡å‹çš„é¢„æµ‹</strong>æƒé‡&amp;åå·®ã€‚</p><h1 id="2825" class="lc kg iq bd kh ld le lf kk lg lh li kn jw lj jx kr jz lk ka kv kc ll kd kz lm bi translated">æ•°æ®é›†</h1><p id="b5b2" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv ko lw lx ly ks lz ma mb kw mc md me mf ij bi translated">æˆ‘ä»¬å°†ä½¿ç”¨<a class="ae lb" href="https://www.robots.ox.ac.uk/%7Evgg/data/pets/" rel="noopener ugc nofollow" target="_blank">ç‰›æ´¥-IIIT Petæ•°æ®é›†</a>æ¥è®­ç»ƒæˆ‘ä»¬çš„ç±»UNETè¯­ä¹‰åˆ†å‰²æ¨¡å‹ã€‚</p><p id="489c" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">æ•°æ®é›†ç”±å›¾åƒåŠå…¶åƒç´ å¼æ©è†œç»„æˆã€‚é€åƒç´ é®ç½©æ˜¯æ¯ä¸ªåƒç´ çš„æ ‡ç­¾ã€‚</p><ul class=""><li id="572a" class="my mz iq lp b lq mg lt mh ko na ks nb kw nc mf nd ne nf ng bi translated">ç¬¬1ç±»:å±äºå® ç‰©çš„åƒç´ ã€‚</li><li id="9294" class="my mz iq lp b lq nh lt ni ko nj ks nk kw nl mf nd ne nf ng bi translated">ç¬¬2ç±»:å±äºå® ç‰©è½®å»“çš„åƒç´ ã€‚</li><li id="6605" class="my mz iq lp b lq nh lt ni ko nj ks nk kw nl mf nd ne nf ng bi translated">ç¬¬ä¸‰ç±»:å±äºèƒŒæ™¯çš„åƒç´ ã€‚</li></ul><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/fa2fa2cd655c9a0c05b2d01b850ec885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*YBiN4_DGAoLi6SpqrvUBBQ.png"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">å›¾2 </strong>:å® ç‰©å’Œå®ƒä»¬çš„åƒç´ å¼é®ç½©ã€‚</p></figure><h2 id="dedc" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">ä¸‹è½½æ•°æ®é›†</h2><pre class="mm mn mo mp gt nn no np nq aw nr bi"><span id="d210" class="kf kg iq no b gy ns nt l nu nv">!curl -O <a class="ae lb" href="http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz" rel="noopener ugc nofollow" target="_blank">http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz</a></span><span id="7b40" class="kf kg iq no b gy nw nt l nu nv">!curl -O <a class="ae lb" href="http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz" rel="noopener ugc nofollow" target="_blank">http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz</a></span><span id="8a1d" class="kf kg iq no b gy nw nt l nu nv">!tar -xf images.tar.gz<br/>!tar -xf annotations.tar.gz</span></pre><h2 id="8358" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">æ•°æ®é›†å‡†å¤‡</h2><p id="03ef" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv ko lw lx ly ks lz ma mb kw mc md me mf ij bi translated"><code class="fe nx ny nz no b">images/</code>å’Œ<code class="fe nx ny nz no b">annotations/trimaps</code>ç›®å½•åŒ…å«æå–çš„å›¾åƒåŠå…¶æ³¨é‡Š(æŒ‰åƒç´ çš„é®ç½©)ã€‚æ‰€éœ€å›¾åƒä¸º<code class="fe nx ny nz no b">.jpg</code>æ ¼å¼ï¼Œè€Œæ³¨é‡Šä¸º<code class="fe nx ny nz no b">.png</code>æ ¼å¼ã€‚ä½†æ˜¯ï¼Œåœ¨è¿™äº›ç›®å½•ä¸­æœ‰ä¸€äº›æˆ‘ä»¬ä¸éœ€è¦çš„æ–‡ä»¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å‡†å¤‡ä¸¤ä¸ªåˆ—è¡¨- <code class="fe nx ny nz no b">input_img_paths</code>å’Œ<code class="fe nx ny nz no b">annotation_img_paths</code>ï¼Œå…¶ä¸­åŒ…å«æ‰€éœ€å›¾åƒå’Œæ³¨é‡Šçš„è·¯å¾„ã€‚</p><pre class="mm mn mo mp gt nn no np nq aw nr bi"><span id="beb9" class="kf kg iq no b gy ns nt l nu nv">IMG_PATH = 'images/'<br/>ANNOTATION_PATH = 'annotations/trimaps/'<br/><br/>input_img_paths = sorted(<br/>    [<br/>        os.path.join(IMG_PATH, fname)<br/>        for fname in os.listdir(IMG_PATH)<br/>        if fname.endswith(".jpg")<br/>    ]<br/>)<br/>annotation_img_paths = sorted(<br/>    [<br/>        os.path.join(ANNOTATION_PATH, fname)<br/>        for fname in os.listdir(ANNOTATION_PATH)<br/>        if fname.endswith(".png") and not fname.startswith(".")<br/>    ]<br/>)<br/><br/>print(len(input_img_paths), len(annotation_img_paths))</span></pre><p id="9011" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">æ€»å…±æœ‰7390å¼ å›¾ç‰‡å’Œæ³¨é‡Šã€‚æˆ‘ä»¬å°†ä½¿ç”¨1000å¹…å›¾åƒåŠå…¶æ³¨é‡Šä½œä¸ºéªŒè¯é›†ã€‚</p><h2 id="35d1" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">ä½¿ç”¨<code class="fe nx ny nz no b">tf.data</code>çš„æ•°æ®åŠ è½½å™¨</h2><p id="ff85" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv ko lw lx ly ks lz ma mb kw mc md me mf ij bi translated">æˆ‘ä»¬å°†ä½¿ç”¨<code class="fe nx ny nz no b">tf.data.Dataset</code>æ„å»ºæˆ‘ä»¬çš„è¾“å…¥ç®¡é“ã€‚</p><pre class="mm mn mo mp gt nn no np nq aw nr bi"><span id="716c" class="kf kg iq no b gy ns nt l nu nv">IMG_SHAPE = 128<br/>AUTO = tf.data.experimental.AUTOTUNE<br/>BATCH_SIZE = 32<br/><br/>def scale_down(image, mask):<br/>  # apply scaling to image and mask<br/>  image = tf.cast(image, tf.float32) / 255.0<br/>  mask -= 1<br/>  return image, mask<br/><br/>def load_and_preprocess(img_filepath, mask_filepath):<br/>   # load the image and resize it<br/>    img = tf.io.read_file(img_filepath)<br/>    img = tf.io.decode_jpeg(img, channels=3)<br/>    img = tf.image.resize(img, [IMG_SHAPE, IMG_SHAPE])<br/><br/>    mask = tf.io.read_file(mask_filepath)<br/>    mask = tf.io.decode_png(mask, channels=1)<br/>    mask = tf.image.resize(mask, [IMG_SHAPE, IMG_SHAPE])<br/><br/>    img, mask = scale_down(img, mask)<br/><br/>    return img, mask<br/><br/># shuffle the paths and prepare train-test split<br/>input_img_paths, annotation_img_paths = shuffle(input_img_paths, annotation_img_paths, random_state=42)<br/>input_img_paths_train, annotation_img_paths_train = input_img_paths[: -1000], annotation_img_paths[: -1000]<br/>input_img_paths_test, annotation_img_paths_test = input_img_paths[-1000:], annotation_img_paths[-1000:]<br/><br/>trainloader = tf.data.Dataset.from_tensor_slices((input_img_paths_train, annotation_img_paths_train))<br/>testloader = tf.data.Dataset.from_tensor_slices((input_img_paths_test, annotation_img_paths_test))<br/><br/>trainloader = (<br/>    trainloader<br/>    .shuffle(1024)<br/>    .map(load_and_preprocess, num_parallel_calls=AUTO)<br/>    .batch(BATCH_SIZE)<br/>    .prefetch(AUTO)<br/>)<br/><br/>testloader = (<br/>    testloader<br/>    .map(load_and_preprocess, num_parallel_calls=AUTO)<br/>    .batch(BATCH_SIZE)<br/>    .prefetch(AUTO)<br/>)</span></pre><h1 id="6dde" class="lc kg iq bd kh ld le lf kk lg lh li kn jw lj jx kr jz lk ka kv kc ll kd kz lm bi translated">æ¨¡å‹</h1><p id="5fc2" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv ko lw lx ly ks lz ma mb kw mc md me mf ij bi translated">è¿™é‡Œä½¿ç”¨çš„æ¨¡å‹æ˜¯é¦™è‰<a class="ae lb" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> UNETå»ºç­‘</a>ã€‚å®ƒç”±ç¼–ç å™¨å’Œè§£ç å™¨ç½‘ç»œç»„æˆã€‚è¿™ä¸ªæ¶æ„çš„è¾“å…¥æ˜¯å›¾åƒï¼Œè€Œè¾“å‡ºæ˜¯é€åƒç´ çš„è´´å›¾ã€‚æ‚¨å¯ä»¥é€šè¿‡W &amp; B æŠ¥å‘Šåœ¨<a class="ae lb" href="https://wandb.ai/ayush-thakur/keras-gan/reports/Towards-Deep-Generative-Modeling-with-W-B--Vmlldzo4MDI4Mw" rel="noopener ugc nofollow" target="_blank">æ·±åº¦ç”Ÿæˆå»ºæ¨¡ä¸­äº†è§£æ›´å¤šå…³äºç¼–ç å™¨-è§£ç å™¨(Autoencoder)ç½‘ç»œçš„ä¿¡æ¯ã€‚</a></p><p id="23e8" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">ç±»ä¼¼UNETçš„æ¶æ„åœ¨è‡ªæˆ‘ç›‘ç£çš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­å¾ˆå¸¸è§ï¼Œå¦‚<a class="ae lb" href="https://www.wandb.com/articles/introduction-to-image-inpainting-with-deep-learning" rel="noopener ugc nofollow" target="_blank">å›¾åƒä¿®å¤</a>ã€‚</p><p id="3696" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">ä½ å¯ä»¥åœ¨è¿™ä¸ª<a class="ae lb" rel="noopener" target="_blank" href="/unet-line-by-line-explanation-9b191c76baf5">é€è¡Œè§£é‡Š</a>ä¸­äº†è§£æ›´å¤šå…³äºUNETå»ºç­‘çš„ä¿¡æ¯ã€‚</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oa"><img src="../Images/4c18c4c37b8f56fb8c304351503518e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DtGOVs833TJOtWEbLTBoOg.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">å›¾3 :å…¸å‹çš„UNETå»ºç­‘ã€‚(<a class="ae lb" rel="noopener" target="_blank" href="/unet-line-by-line-explanation-9b191c76baf5">æ¥æº</a>)</p></figure><p id="2236" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">ä¸‹é¢æ˜¾ç¤ºçš„ä»£ç ç‰‡æ®µæ„å»ºäº†æˆ‘ä»¬çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹æ¶æ„ã€‚</p><pre class="mm mn mo mp gt nn no np nq aw nr bi"><span id="8b3e" class="kf kg iq no b gy ns nt l nu nv">class SegmentationModel:<br/>  '''<br/>  Build UNET like model for image inpaining task.<br/>  '''<br/>  def prepare_model(self, OUTPUT_CHANNEL, input_size=(IMG_SHAPE,IMG_SHAPE,3)):<br/>    inputs = Input(input_size)<br/><br/>    # Encoder <br/>    conv1, pool1 = self.__ConvBlock(32, (3,3), (2,2), 'relu', 'same', inputs) <br/>    conv2, pool2 = self.__ConvBlock(64, (3,3), (2,2), 'relu', 'same', pool1)<br/>    conv3, pool3 = self.__ConvBlock(128, (3,3), (2,2), 'relu', 'same', pool2) <br/>    conv4, pool4 = self.__ConvBlock(256, (3,3), (2,2), 'relu', 'same', pool3) <br/>    <br/>    # Decoder<br/>    conv5, up6 = self.__UpConvBlock(512, 256, (3,3), (2,2), (2,2), 'relu', 'same', pool4, conv4)<br/>    conv6, up7 = self.__UpConvBlock(256, 128, (3,3), (2,2), (2,2), 'relu', 'same', up6, conv3)<br/>    conv7, up8 = self.__UpConvBlock(128, 64, (3,3), (2,2), (2,2), 'relu', 'same', up7, conv2)<br/>    conv8, up9 = self.__UpConvBlock(64, 32, (3,3), (2,2), (2,2), 'relu', 'same', up8, conv1)<br/>    <br/>    conv9 = self.__ConvBlock(32, (3,3), (2,2), 'relu', 'same', up9, False)<br/>    <br/>    # Notice OUTPUT_CHANNEL and activation<br/>    outputs = Conv2D(OUTPUT_CHANNEL, (3, 3), activation='softmax', padding='same')(conv9)<br/><br/>    return Model(inputs=[inputs], outputs=[outputs])  <br/><br/>  def __ConvBlock(self, filters, kernel_size, pool_size, activation, padding, connecting_layer, pool_layer=True):<br/>    conv = Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)<br/>    conv = Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)<br/>    if pool_layer:<br/>      pool = MaxPooling2D(pool_size)(conv)<br/>      return conv, pool<br/>    else:<br/>      return conv<br/><br/>  def __UpConvBlock(self, filters, up_filters, kernel_size, up_kernel, up_stride, activation, padding, connecting_layer, shared_layer):<br/>    conv = Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)<br/>    conv = Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)<br/>    up = Conv2DTranspose(filters=up_filters, kernel_size=up_kernel, strides=up_stride, padding=padding)(conv)<br/>    up = concatenate([up, shared_layer], axis=3)<br/><br/>    return conv, up</span></pre><p id="329f" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated"><strong class="lp ir">æ³¨æ„</strong>å¯¹äºæˆ‘ä»¬çš„æ•°æ®é›†æ¥è¯´<code class="fe nx ny nz no b">OUTPUT_CHANNEL</code>æ˜¯3ã€‚è¿™æ˜¯å› ä¸ºæœ‰ä¸‰ç±»åƒç´ ï¼Œå¦‚æ•°æ®é›†éƒ¨åˆ†æ‰€è¿°ã€‚è€ƒè™‘æˆ‘ä»¬æ­£åœ¨è¿›è¡Œå¤šç±»åˆ†ç±»ï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ å¯ä»¥å±äºä¸‰ç±»ä¸­çš„ä»»ä½•ä¸€ç±»ã€‚</p><p id="99a9" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">è¿˜æœ‰ï¼Œ<strong class="lp ir">æ³¨æ„</strong>ç”±äºæ˜¯æ¯åƒç´ å¤šç±»åˆ†ç±»é—®é¢˜ï¼Œæ‰€ä»¥è¾“å‡ºæ¿€æ´»å‡½æ•°æ˜¯<code class="fe nx ny nz no b">softmax</code>ã€‚</p><pre class="mm mn mo mp gt nn no np nq aw nr bi"><span id="dadf" class="kf kg iq no b gy ns nt l nu nv">OUTPUT_CHANNEL = 3<br/><br/>model = SegmentationModel().prepare_model(OUTPUT_CHANNEL)<br/>model.compile(optimizer="adam", loss="sparse_categorical_crossentropy")</span></pre><p id="bc9d" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">æœ€åç”¨<code class="fe nx ny nz no b">sparse_categorical_crossentropy</code>ç¼–è¯‘æ¨¡å‹ã€‚ç¨€ç–ï¼Œå› ä¸ºæŒ‰åƒç´ çš„é®ç½©/æ³¨é‡Šæ˜¯æ•´æ•°ã€‚</p><h1 id="bb7e" class="lc kg iq bd kh ld le lf kk lg lh li kn jw lj jx kr jz lk ka kv kc ll kd kz lm bi translated"><code class="fe nx ny nz no b">SemanticLogger</code>å›è°ƒ-é¢„æµ‹çš„äº¤äº’å¼å¯è§†åŒ–</h1><p id="a8f5" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv ko lw lx ly ks lz ma mb kw mc md me mf ij bi translated">åœ¨è¿›è¡Œè¯­ä¹‰åˆ†å‰²æ—¶ï¼Œæ‚¨å¯ä»¥åœ¨æƒé‡å’Œåå·®ä¸­äº¤äº’å¼åœ°å¯è§†åŒ–æ¨¡å‹çš„é¢„æµ‹ã€‚å¦‚æœæ‚¨çš„å›¾åƒå¸¦æœ‰ç”¨äºè¯­ä¹‰åˆ†æ®µçš„é®ç½©ï¼Œæ‚¨å¯ä»¥è®°å½•é®ç½©å¹¶åœ¨UIä¸­æ‰“å¼€å’Œå…³é—­å®ƒä»¬ã€‚ç‚¹å‡»æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£<a class="ae lb" href="https://docs.wandb.com/library/log#images-and-overlays" rel="noopener ugc nofollow" target="_blank">ã€‚</a></p><p id="e43c" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">Stacey Svetlichnaya<a class="ae lb" href="https://wandb.ai/stacey" rel="noopener ugc nofollow" target="_blank">çš„æŠ¥å‘Š</a><a class="ae lb" href="https://wandb.ai/stacey/deep-drive/reports/Image-Masks-for-Semantic-Segmentation--Vmlldzo4MTUwMw" rel="noopener ugc nofollow" target="_blank">è¯­ä¹‰åˆ†å‰²çš„å›¾åƒé®ç½©</a>å°†å¸¦æ‚¨äº†è§£è¯¥å·¥å…·çš„äº¤äº’æ§ä»¶ã€‚å®ƒæ¶µç›–äº†æ—¥å¿—å›¾åƒå’Œé®ç½©çš„å„ç§éº»çƒ¦ã€‚</p><p id="1fbf" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">ä¸‹é¢æ˜¾ç¤ºçš„ä»£ç ç‰‡æ®µæ˜¯æˆ‘ä»¬çš„<code class="fe nx ny nz no b">SemanticLogger</code>å›è°ƒçš„åŠ©æ‰‹å‡½æ•°ã€‚å‡½æ•°<code class="fe nx ny nz no b">labels</code>è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­<code class="fe nx ny nz no b">key</code>æ˜¯ç±»å€¼ï¼Œ<code class="fe nx ny nz no b">value</code>æ˜¯æ ‡ç­¾ã€‚å‡½æ•°<code class="fe nx ny nz no b">wandb_mask</code>ä»¥æ‰€éœ€çš„æ ¼å¼è¿”å›å›¾åƒã€é¢„æµ‹æ©ç å’ŒåŸºæœ¬äº‹å®æ©ç ã€‚</p><pre class="mm mn mo mp gt nn no np nq aw nr bi"><span id="0657" class="kf kg iq no b gy ns nt l nu nv">segmentation_classes = ['pet', 'pet_outline', 'background']<br/><br/># returns a dictionary of labels<br/>def labels():<br/>  l = {}<br/>  for i, label in enumerate(segmentation_classes):<br/>    l[i] = label<br/>  return l<br/><br/># util function for generating interactive image mask from components<br/>def wandb_mask(bg_img, pred_mask, true_mask):<br/>  return wandb.Image(bg_img, masks={<br/>      "prediction" : {<br/>          "mask_data" : pred_mask, <br/>          "class_labels" : labels()<br/>      },<br/>      "ground truth" : {<br/>          "mask_data" : true_mask, <br/>          "class_labels" : labels()<br/>      }<br/>    }<br/>  )</span></pre><p id="6b4a" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">æˆ‘ä»¬çš„<code class="fe nx ny nz no b">SemanticLogger</code>æ˜¯ä¸€ä¸ªå®šåˆ¶çš„Keraså›è°ƒå‡½æ•°ã€‚æˆ‘ä»¬å¯ä»¥å°†å®ƒä¼ é€’ç»™<code class="fe nx ny nz no b">model.fit</code>æ¥è®°å½•æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¸€ä¸ªå°å‹éªŒè¯é›†ä¸Šçš„é¢„æµ‹ã€‚æƒé‡å’Œåå·®å°†è‡ªåŠ¨è¦†ç›–å›¾åƒä¸Šçš„è’™ç‰ˆã€‚</p><pre class="mm mn mo mp gt nn no np nq aw nr bi"><span id="5266" class="kf kg iq no b gy ns nt l nu nv">class SemanticLogger(tf.keras.callbacks.Callback):<br/>    def __init__(self):<br/>        super(SemanticLogger, self).__init__()<br/>        self.val_images, self.val_masks = next(iter(testloader))<br/><br/>    def on_epoch_end(self, logs, epoch):<br/>        pred_masks = self.model.predict(self.val_images)<br/>        pred_masks = np.argmax(pred_masks, axis=-1)<br/>        # pred_masks = np.expand_dims(pred_masks, axis=-1)<br/><br/>        val_images = tf.image.convert_image_dtype(self.val_images, tf.uint8)<br/>        val_masks = tf.image.convert_image_dtype(self.val_masks, tf.uint8)<br/>        val_masks = tf.squeeze(val_masks, axis=-1)<br/>        <br/>        pred_masks = tf.image.convert_image_dtype(pred_masks, tf.uint8)<br/><br/>        mask_list = []<br/>        for i in range(len(self.val_images)):<br/>          mask_list.append(wandb_mask(val_images[i].numpy(), <br/>                                      pred_masks[i].numpy(), <br/>                                      val_masks[i].numpy()))<br/><br/>        wandb.log({"predictions" : mask_list})</span></pre><p id="ea1a" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">æˆ‘ä»¬å¾ˆå¿«å°±ä¼šçœ‹åˆ°ç»“æœã€‚</p><h1 id="ec32" class="lc kg iq bd kh ld le lf kk lg lh li kn jw lj jx kr jz lk ka kv kc ll kd kz lm bi translated">ç»“æœ</h1><p id="ad98" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv ko lw lx ly ks lz ma mb kw mc md me mf ij bi translated">ç°åœ¨åˆ°äº†æ¿€åŠ¨äººå¿ƒçš„éƒ¨åˆ†ã€‚æˆ‘å·²ç»è®­ç»ƒäº†15ä¸ªçºªå…ƒçš„æ¨¡å‹ã€‚æŸå¤±å’ŒéªŒè¯æŸå¤±æŒ‡æ ‡å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚<em class="of">éšæ„è®­ç»ƒæ›´é•¿æ—¶æœŸçš„æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å…¶ä»–è¶…å‚æ•°ã€‚</em></p><div class="og oh gp gr oi oj"><a href="https://colab.research.google.com/drive/1rXV31gdyqEiXCtmSgff-H-VRuOSzv7IH?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd ir gy z fp oo fr fs op fu fw ip bi translated">è°·æ­Œè”åˆå®éªŒå®¤</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">ç¼–è¾‘æè¿°</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">colab.research.google.com</p></div></div><div class="os l"><div class="ot l ou ov ow os ox mr oj"/></div></div></a></div><p id="e838" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">åŸ¹è®­å’ŒéªŒè¯æŸå¤±å¦‚å›¾<strong class="lp ir">å›¾3 </strong>æ‰€ç¤ºã€‚ç»è¿‡ä¸€äº›æ—¶æœŸåï¼Œæ¨¡å‹å¼€å§‹è¿‡åº¦æ‹Ÿåˆã€‚</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oy"><img src="../Images/2f5e976ab5893530f80033e0c59cd473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pIf6-Ay_UXzHlHv4t-_caA.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">å›¾4 </strong>:åŸ¹è®­å’ŒéªŒè¯æŸå¤±æŒ‡æ ‡ã€‚(<a class="ae lb" href="https://wandb.ai/ayush-thakur/image-segmentation/reports/Image-Segmentation-Using-Keras-and-W-B--VmlldzoyNTE1Njc" rel="noopener ugc nofollow" target="_blank">ç‚¹å‡»è¿™é‡ŒæŸ¥çœ‹äº’åŠ¨æŠ¥é“ã€‚</a>)</p></figure><p id="6d68" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated"><code class="fe nx ny nz no b">SemanticLogger</code>çš„ç»“æœå¦‚ä¸‹æ‰€ç¤ºã€‚<strong class="lp ir">ç‚¹å‡»ä¸‹é¢</strong> <a class="ae lb" href="https://wandb.ai/ayush-thakur/image-segmentation/reports/Image-Segmentation-Using-Keras-and-W-B--VmlldzoyNTE1Njc#Results-7" rel="noopener ugc nofollow" target="_blank"> <strong class="lp ir">åª’ä½“é¢æ¿</strong> </a> <strong class="lp ir">ä¸­çš„âš™ï¸å›¾æ ‡(SemanticLoggerçš„ç»“æœ)æŸ¥çœ‹äº¤äº’æ§ä»¶</strong>ã€‚æ‚¨å¯ä»¥åˆ†åˆ«å¯è§†åŒ–å›¾åƒå’Œé®ç½©ï¼Œå¹¶å¯ä»¥é€‰æ‹©è¦å¯è§†åŒ–çš„è¯­ä¹‰ç±»ã€‚</p><h1 id="4544" class="lc kg iq bd kh ld le lf kk lg lh li kn jw lj jx kr jz lk ka kv kc ll kd kz lm bi translated">è§‚å¯Ÿ</h1><ul class=""><li id="0313" class="my mz iq lp b lq lr lt lu ko oz ks pa kw pb mf nd ne nf ng bi translated">è¯¥æ¨¡å‹å­¦ä¹ å¾ˆå¥½åœ°é¢„æµ‹<code class="fe nx ny nz no b">pet</code>å’Œ<code class="fe nx ny nz no b">background</code>ç±»ã€‚</li><li id="dd24" class="my mz iq lp b lq nh lt ni ko nj ks nk kw nl mf nd ne nf ng bi translated">æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹å¾ˆéš¾ç»†åˆ†<code class="fe nx ny nz no b">pet_outline</code>ç±»ã€‚è¿™æ˜¯å› ä¸ºé«˜ç­‰çº§çš„ä¸å¹³è¡¡ï¼Œå¹¶ä¸”æ¨¡å‹æ²¡æœ‰è¢«æ­£åˆ™åŒ–ä»¥å¯¹æŠ—è¿™ç§ä¸å¹³è¡¡ã€‚</li></ul><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pc"><img src="../Images/6794a02795a377202382e239c603c97e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A6yZSwXxXP73pVLZddGm2g.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><strong class="bd mx">å›¾5 </strong>:è¯­ä¹‰è®°å½•å™¨å›è°ƒç»“æœã€‚(<a class="ae lb" href="https://wandb.ai/ayush-thakur/image-segmentation/reports/Image-Segmentation-Using-Keras-and-W-B--VmlldzoyNTE1Njc" rel="noopener ugc nofollow" target="_blank">ç‚¹å‡»æ­¤å¤„æŸ¥çœ‹äº’åŠ¨æŠ¥é“ã€‚</a>)</p></figure><h1 id="3148" class="lc kg iq bd kh ld le lf kk lg lh li kn jw lj jx kr jz lk ka kv kc ll kd kz lm bi translated">ç»“è®ºå’Œæœ€ç»ˆæƒ³æ³•</h1><p id="c3ff" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv ko lw lx ly ks lz ma mb kw mc md me mf ij bi translated">æˆ‘å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡å…³äºè¯­ä¹‰åˆ†å‰²çš„æŠ¥å‘Šã€‚è¿™ä»½æŠ¥å‘Šæœ‰ä¸¤ä¸ªç›®çš„:</p><ul class=""><li id="3e94" class="my mz iq lp b lq mg lt mh ko na ks nb kw nc mf nd ne nf ng bi translated">è®©æ„Ÿå…´è¶£çš„äººæ›´å®¹æ˜“ä½¿ç”¨è¯­ä¹‰åˆ†å‰²æŠ€æœ¯ã€‚</li><li id="3f3c" class="my mz iq lp b lq nh lt ni ko nj ks nk kw nl mf nd ne nf ng bi translated">å±•ç¤ºæƒé‡å’Œåå·®å¦‚ä½•å¸®åŠ©äº¤äº’å¼åœ°å¯è§†åŒ–æ¨¡å‹çš„é¢„æµ‹å’Œåº¦é‡ã€‚æ­¤å¤–ï¼Œå±•ç¤ºäººä»¬å¯ä»¥ä»è¿™äº›å¯è§†åŒ–ä¸­å¾—åˆ°çš„è§‚å¯Ÿç»“æœã€‚</li></ul><p id="310b" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">æœ€åï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å€¼å¾—ä¸€è¯»çš„èµ„æº:</p><ul class=""><li id="d74d" class="my mz iq lp b lq mg lt mh ko na ks nb kw nc mf nd ne nf ng bi translated"><a class="ae lb" href="https://www.jeremyjordan.me/semantic-segmentation/" rel="noopener ugc nofollow" target="_blank">è¯­ä¹‰å›¾åƒåˆ†å‰²æ¦‚è¿°</a></li><li id="d999" class="my mz iq lp b lq nh lt ni ko nj ks nk kw nl mf nd ne nf ng bi translated"><a class="ae lb" href="https://www.tensorflow.org/tutorials/images/segmentation" rel="noopener ugc nofollow" target="_blank">å›¾åƒåˆ†å‰²</a></li><li id="843b" class="my mz iq lp b lq nh lt ni ko nj ks nk kw nl mf nd ne nf ng bi translated"><a class="ae lb" href="https://wandb.ai/stacey/deep-drive/reports/The-View-from-the-Driver-s-Seat--Vmlldzo1MTg5NQ" rel="noopener ugc nofollow" target="_blank">é©¾é©¶åº§ä¸Šçš„è§†é‡</a></li></ul><p id="2279" class="pw-post-body-paragraph ln lo iq lp b lq mg jr ls lt mh ju lv ko mi lx ly ks mj ma mb kw mk md me mf ij bi translated">æˆ‘å¾ˆæƒ³åœ¨è¯„è®ºåŒºå¾—åˆ°ä½ çš„åé¦ˆã€‚ğŸ˜„</p></div></div>    
</body>
</html>