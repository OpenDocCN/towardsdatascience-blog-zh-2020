<html>
<head>
<title>Detecting Muon Momentum in the CMS Experiment at CERN using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习检测CERN CMS实验中的μ子动量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-muon-momentum-in-the-cms-experiment-at-cern-using-deep-learning-934b0ef24586?source=collection_archive---------42-----------------------#2020-11-14">https://towardsdatascience.com/detecting-muon-momentum-in-the-cms-experiment-at-cern-using-deep-learning-934b0ef24586?source=collection_archive---------42-----------------------#2020-11-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="de92" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/9163d231e352efca2492580c414972c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jxATeU3jER1PUHme"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图CMS束管的移除(图片由Maximilien Brice/Julien Ordan/CERN提供——来源:<a class="ae kl" href="https://home.cern/news/news/experiments/whats-store-cms-detector-over-next-two-years" rel="noopener ugc nofollow" target="_blank"> CERN </a></p></figure><p id="da52" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在欧洲核子研究中心<strong class="ko ja"> CMS实验</strong>中<strong class="ko ja">探测μ介子</strong>是一项<strong class="ko ja">重要的</strong>任务。欧洲核子研究中心的CMS物理项目深入研究了许多物理实验，通常预期会产生μ子。例如，研究著名的希格斯玻色子粒子的一种方法是通过一个衰变通道，在那里希格斯玻色子衰变为四个μ子。</p><p id="a2cc" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于μ子可以穿透几米厚的铁而没有明显的能量损失，它们很难被CMS系统的任何一层阻止。因此，μ子探测器是最外面的，远离相互作用点。<strong class="ko ja">当前μ子横向动量探测器</strong>、<strong class="ko ja">桶μ子轨迹探测器</strong>使用查找表来估计μ子的<strong class="ko ja">横向动量</strong>。后者是使用伪快度η测量的<strong class="ko ja">，伪快度η是与带电粒子从这些碰撞中出现的角度相关的空间量，方位角φ是碰撞路径与z轴形成的角度。(来源:<a class="ae kl" href="http://www.infn.it/thesis/PDF/getfile.php?filename=12755-Diotalevi-magistrale.pdf" rel="noopener ugc nofollow" target="_blank"> CMS一级触发带有机器学习的μ子动量分配</a> —托马索·迪奥塔列维)</strong></p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi lk"><img src="../Images/b8e937585dee502c822bbd40f74d9b67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5WGmO9Zxb1uwRIL4.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图2:采用的坐标系</p></figure><p id="8a63" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这个水平上的μ介子的任何检测被称为<strong class="ko ja">触发</strong>。</p><h1 id="44dd" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">问题描述</h1><p id="bf58" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">需要更加复杂的技术来<strong class="ko ja">提高动量检测的精度</strong>以降低触发率。由于瞬发μ子光谱遵循<strong class="ko ja">指数分布</strong>，精度上的任何<strong class="ko ja">微小改进</strong>都可以<strong class="ko ja">显著减少触发</strong>的数量，特别是通过减少被误归类为高动量μ子的低动量μ子的数量。</p><p id="7886" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这就是<strong class="ko ja">机器学习发挥作用的地方</strong>。通过应用更智能的算法，如<strong class="ko ja">神经网络、</strong>，我们可以提高触发系统的精度，以准确检测μ子及其相应的横向动量。(来源:<a class="ae kl" href="http://www.infn.it/thesis/PDF/getfile.php?filename=12755-Diotalevi-magistrale.pdf" rel="noopener ugc nofollow" target="_blank"> CMS一级触发带有机器学习的μ子动量分配</a>——托马索·迪奥塔列维)</p><p id="b2a6" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在下面的文章中，我们将应用<strong class="ko ja">几种深度学习方法来准确预测μ介子动量</strong>。我们将在CMS实验中使用来自阴极条室(CSC)的蒙特卡罗模拟数据。该数据集包含超过300万个利用皮媞亚产生的μ子事件。</p><h1 id="5cab" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">探索数据集</h1><p id="fa35" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">我们检索的数据组织如下:</p><ul class=""><li id="e61a" class="ms mt iq ko b kp kq kt ku kx mu lb mv lf mw lj mx my mz na bi translated">有<strong class="ko ja"> 87个特征</strong> : 84个与探测器相关；3个作为路径变量</li><li id="0965" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated">CSC内部有<strong class="ko ja"> 12个探测器面</strong>，每个探测器面有<strong class="ko ja"> 7个特征</strong> (12*7=84)</li></ul><p id="7eaf" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些功能组织如下:</p><ul class=""><li id="a327" class="ms mt iq ko b kp kq kt ku kx mu lb mv lf mw lj mx my mz na bi translated"><strong class="ko ja">0–11</strong>:φ坐标</li><li id="9c27" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja">12–23</strong>:角坐标</li><li id="3b2d" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja">24–35</strong>:弯曲角度</li><li id="c8d9" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja">36–47</strong>:时间信息</li><li id="a39d" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja">48–59</strong>:环号</li><li id="f137" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja">60–71</strong>:前/后击</li><li id="e2cb" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja">72–83</strong>:面罩</li><li id="dc04" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja">84–86</strong>:X _ road</li><li id="b3db" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja">87</strong>:φ角度</li><li id="1f10" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja"> 88 </strong> : Eta角度</li><li id="ddea" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj mx my mz na bi translated"><strong class="ko ja"> 89 </strong> : q/pt(横向μ子动量)——<strong class="ko ja">目标标签</strong></li></ul><p id="1710" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在μ介子室内，有多个探测器站，如下图所示。这些探测器平面被组织在特定的室中。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/0e84cca1536ff54b454f82616ddae5f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/0*3w05amTujkY9JpsR.png"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图3:CMS象限的示意图(来源:<a class="ae kl" href="https://cds.cern.ch/record/1223872/plots" rel="noopener ugc nofollow" target="_blank"> CERN文件服务器</a>)</p></figure><p id="85fb" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，我们只关心CSC室中的<strong class="ko ja">μ介子击中，因此只与CSC室相关的特征。</strong></p><p id="530b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们首先删除那些不需要的特性:</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="9023" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们已经删除了这些要素，接下来我们可以将所有要素放入一个紧凑的Pandas数据框中，以便于以后进行数据分析。</p><h1 id="7f46" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">探索性数据分析</h1><p id="b966" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">让我们用熊猫的<strong class="ko ja">描述</strong>方法来看一下数据统计:</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">表1:具有缺失值的要素的统计数据</p></figure><p id="6d91" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">快速查看会发现一些特征，如<strong class="ko ja">φangle 1</strong>、<strong class="ko ja"> Theta angle1 </strong>和<strong class="ko ja"> Bend angle1 </strong>有一些缺失值。让我们找出每个要素的空值的确切百分比:</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e5953164cf8ff2a0081643edee2992e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/0*vQ2cN2WePCmvaWyV.png"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图4:缺失值分布</p></figure><p id="9756" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们注意到<strong class="ko ja">前/后1 </strong>、<strong class="ko ja">φ角度1 </strong>、<strong class="ko ja">θ角度1 </strong>、<strong class="ko ja">弯曲角度1 </strong>、<strong class="ko ja">时间1 </strong>和<strong class="ko ja">环1 </strong>特征有超过70%的缺失值！我们需要稍后删除这些特性，对于缺失值少于25%的其他特性，我们将用每列的平均值填充缺失值。</p><p id="34a2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">接下来，我们将可视化所有特征的数据分布。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/db1e832ffb13f754a60187107cba4a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/0*99Xri-FjkJYzF2pB.png"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图5:选定的特性直方图</p></figure><p id="05e8" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们注意到如上图所示，如果我们想要提高模型的学习速度，一些特征如<strong class="ko ja"> Theta angle1 </strong>、<strong class="ko ja"> Theta angle2 </strong>、<strong class="ko ja"> Theta angle3 </strong>和<strong class="ko ja"> X Road1 </strong>需要转换成正态分布(使用标准化)。</p><h1 id="b4b4" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">预处理用于训练的数据</h1><h2 id="0eab" class="nl lq iq bd lr nm nn dn lv no np dp lz kx nq nr md lb ns nt mh lf nu nv ml iw bi translated">将问题框定为分类任务</h2><p id="6a40" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">不要试图应用回归来预测μ子动量值(<strong class="ko ja"> q/pt </strong>)，让我们首先尝试将动量分成4类:<strong class="ko ja">0–10 GeV、10–30 GeV、30–100 GeV和&gt; 100 GeV </strong>，并因此将问题构建为分类任务。</p><p id="fd47" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了对动量进行分组，我们将使用<strong class="ko ja">目标特征的倒数的绝对值(pt/q) </strong>。让我们来看看这个新生成的要素的数据分布</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/bb1833e7a6a233cdf890bd9224f20a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/0*5oowJEKHZk94k6Hc.png"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图6:pt/q的数据分布</p></figure><p id="5bb6" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如图所示，很明显存在不同大小的不同组。让我们使用Pandas 的<strong class="ko ja"> cut方法对数据进行聚类，并检查新生成的组分布。</strong></p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/5636507b164ccd7c0648c26aa5afb43d.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/0*xmkoydOOXfZYHZAm.png"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图7:目标类的数据分布</p></figure><p id="dd70" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们已经成功地将标签分组，我们可以观察到<strong class="ko ja">类不平衡</strong>，因此每当我们开始训练我们的神经网络<strong class="ko ja">以避免任何偏差</strong>时，我们都需要平衡它们。</p><h2 id="a367" class="nl lq iq bd lr nm nn dn lv no np dp lz kx nq nr md lb ns nt mh lf nu nv ml iw bi translated">将数据集分为训练集和测试集</h2><p id="e200" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">接下来，让我们将数据分为训练和测试数据，我们将使用90%-10%的分割。重要的是<strong class="ko ja">使测试集代表原始数据集中的目标类分布</strong>。因此，我们将使用Scikit-Learn中的<strong class="ko ja"> StratifiedShuffleSplit </strong>方法来使训练数据和测试数据都代表类的原始分布，而不是随机分割我们的原始数据集。</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="7fba" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们检查新生成的集合中的类分布:</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">表2:比较原始、训练和测试集之间的类分布</p></figure><p id="2a67" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如上表所示，训练集和测试集都代表原始数据集。我们现在可以安全地进入预处理的最后一步:<strong class="ko ja">准备管道</strong>。</p><h2 id="a9f1" class="nl lq iq bd lr nm nn dn lv no np dp lz kx nq nr md lb ns nt mh lf nu nv ml iw bi translated">准备预处理管道</h2><p id="a144" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">该管道将执行以下任务:</p><ol class=""><li id="df28" class="ms mt iq ko b kp kq kt ku kx mu lb mv lf mw lj nx my mz na bi translated">删除缺失值超过70%的列</li><li id="c14b" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj nx my mz na bi translated">使用Scikit-Learn <strong class="ko ja">简单估算器</strong>用相应的方法估算缺失值的其他列</li><li id="21bd" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj nx my mz na bi translated">用Scikit-Learn <strong class="ko ja">标准定标器</strong>将数据标准化</li><li id="5bde" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj nx my mz na bi translated">将目标特征编码成四个<strong class="ko ja">一个热编码特征</strong></li></ol><p id="1a8c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以下是管道完整代码:</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div></figure><h1 id="c265" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">构建神经网络</h1><p id="d3d0" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">我们将使用<strong class="ko ja"> Tensorflow的Keras库来构建我们的神经网络</strong>。神经网络将有<strong class="ko ja"> 5个隐藏层</strong>，每层的神经元数量为<strong class="ko ja"> 512、256、128、64和32 </strong>。我们还在网络中添加了<strong class="ko ja">脱落层</strong>以减少过度拟合。输出层将有<strong class="ko ja"> 4个神经元</strong>(与类的数量相同)，我们将对每个输出神经元应用<strong class="ko ja"> softmax </strong>激活函数，以获得<strong class="ko ja">每个类的概率</strong>。</p><p id="21e5" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于这是一个分类任务，我们选择的<strong class="ko ja">损失函数</strong>是<strong class="ko ja">分类交叉熵，</strong>和<strong class="ko ja"> Adam </strong>将被用作优化器:</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="446d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们为模型设置一些回调，包括一个<strong class="ko ja">检查点回调</strong>和<strong class="ko ja">提前停止回调</strong>，它们都将监控模型的<strong class="ko ja">验证准确性</strong>。我们将使用<strong class="ko ja"> 25%的验证分割</strong>、<strong class="ko ja">500</strong>的批量，并将<strong class="ko ja">训练200个周期</strong>。现在我们终于可以开始训练了！</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="0184" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们已经完成了模型的训练，让我们来看看它在训练时期的性能演变。</p><div class="ll lm ln lo gt ab cb"><figure class="ny ka nz oa ob oc od paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><img src="../Images/8be6ef88f594fbe68843738466cffb73.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*Kh4Rtkict0tAzirj.png"/></div></figure><figure class="ny ka nz oa ob oc od paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><img src="../Images/929dede37b4aaa0890a13c1ddc52f007.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*4LEYJhU0PGs44NKs.png"/></div></figure><figure class="ny ka oe oa ob oc od paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><img src="../Images/b4689c627ee7a623fdabe3a1aefc2c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/0*cE37YHw-gJpd4JG8.png"/></div><p class="kh ki gj gh gi kj kk bd b be z dk of di og oh translated">图8:分类器度量在训练时期的演变</p></figure></div><p id="5403" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">看起来我们在验证集上达到了84%的准确率。令人印象深刻！但如果说我从机器学习中学到了什么的话，那就是<strong class="ko ja">从来不依靠准确性，只依靠</strong>和<strong class="ko ja">来判断模型性能</strong>。我们需要更深入地了解这个案例。</p><h1 id="329a" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">测试模型</h1><p id="4581" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">让我们使用<strong class="ko ja"> Scikit-Learn的分类报告</strong>来检查模型在训练集和测试集上的性能。它包括一系列重要的分类指标，包括<strong class="ko ja">精确度、召回率和f1分数:</strong></p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">表3:列车数据评估报告</p></figure><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">表4:测试数据评估报告</p></figure><p id="29d4" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">令人印象深刻！似乎增加类别权重肯定会减少偏差，我们在测试数据上达到了0.85 的<strong class="ko ja">加权f1分数！</strong></p><h1 id="da04" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">回归实验</h1><p id="9d12" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">让我们尝试直接<strong class="ko ja">预测每个μ子动量的q/pT </strong>值，而不是将目标标签分成四组，因此将问题框架化为<strong class="ko ja">回归</strong>任务。我们<strong class="ko ja">只改变了模型</strong>的最后一层，用一个线性激活函数的输出神经元<strong class="ko ja">代替了softmax的4个神经元。</strong></p><p id="386d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于这是一个回归任务，我们将选择<strong class="ko ja">均方误差</strong>作为我们的<strong class="ko ja">损失函数</strong>，类似于分类任务，我们将使用<strong class="ko ja"> Adam </strong>作为优化器。</p><p id="a836" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们来看看回归模型在训练时期的性能演变:</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/0c17f998fb2e2cbce9a10dea5ae14fb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/0*7kMlY2E2HuJIW_3F.png"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图8:模型训练的演变和训练时期的验证损失</p></figure><p id="acd8" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们在训练集和测试集上检查模型的性能。我们将找到均方根误差，以便更好地了解这些值:</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="952f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">训练数据的均方根误差为0.046，测试数据的均方根误差为0.047 </strong>。一点都不差！与目标值相比，这些值似乎是相对可接受的，但肯定还有改进的空间。</p><h1 id="1b06" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">未来方向</h1><ol class=""><li id="4c25" class="ms mt iq ko b kp mn kt mo kx oj lb ok lf ol lj nx my mz na bi translated">我们发现<strong class="ko ja">分类器</strong>模型<strong class="ko ja">在检测少数类</strong>方面不太好。因此，我们需要寻找更多的技术来<strong class="ko ja">使模型更少偏差</strong>(例如<strong class="ko ja">上采样少数类</strong>或<strong class="ko ja">下采样多数类</strong>)。</li><li id="e2ad" class="ms mt iq ko b kp nb kt nc kx nd lb ne lf nf lj nx my mz na bi translated">我们可以通过<strong class="ko ja">网格搜索</strong>调整<strong class="ko ja">超参数</strong>来进一步提高我们的回归模型的性能。</li></ol><h1 id="dbbc" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">最后的想法</h1><p id="1082" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">在这个项目中，我们尝试了几种<strong class="ko ja">深度学习方法</strong>来准确<strong class="ko ja">预测μ介子动量</strong>。首先，在<strong class="ko ja">预处理</strong>用于训练的数据之前，我们研究了<strong class="ko ja">数据属性</strong>。然后，我们训练<strong class="ko ja">一个分类器来预测μ子动量类别</strong>，并使用<strong class="ko ja">多重分类度量</strong>来评估分类器对新数据的性能。接下来，我们训练了一个<strong class="ko ja">回归模型</strong>来<strong class="ko ja">预测μ子动量值</strong>而不是它们的类别。这两种方法都相当成功，我们计划采用<strong class="ko ja">更先进的技术来减少模型偏差并提高性能。</strong></p></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><p id="9128" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="ot">原载于2020年11月14日</em><a class="ae kl" href="https://anisdismail.com/muon-mom-pred-blog.html" rel="noopener ugc nofollow" target="_blank"><em class="ot">【https://anisdismail.com】</em></a><em class="ot">。</em></p></div></div>    
</body>
</html>