<html>
<head>
<title>What is batch normalization?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是批量正常化？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-batch-normalization-46058b4f583?source=collection_archive---------17-----------------------#2020-09-18">https://towardsdatascience.com/what-is-batch-normalization-46058b4f583?source=collection_archive---------17-----------------------#2020-09-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0955" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习</h2><div class=""/><div class=""><h2 id="16ae" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">有什么帮助？</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ae8a11bd4cf21e277a8725bb76c8c31f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Rbw91cP12mKPlfC9"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">里卡多·阿尔塞在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="f076" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">批量标准化</h1><p id="53a1" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">批量规范化是由Sergey Ioffe和Christian Szegedy在2015年的论文<a class="ae lh" href="https://arxiv.org/pdf/1502.03167.pdf" rel="noopener ugc nofollow" target="_blank">中引入的:批量规范化:通过减少内部协变量移位来加速深度网络训练</a>。</p><p id="e8db" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated"><strong class="mc jd"> <em class="nb">批量标准化缩放层输出，使平均值为0，方差为1。输出以这样的方式缩放，以便更快地训练网络。它还减少了由于参数初始化不佳而导致的问题。</em>T9】</strong></p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="4beb" class="li lj it bd lk ll nj ln lo lp nk lr ls ki nl kj lu kl nm km lw ko nn kp ly lz bi translated">规范化背后的直觉</h1><p id="6fdd" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我们知道标准化或特征缩放可以加快学习过程。批处理规范化背后的直觉是相似的。<strong class="mc jd">批量标准化对隐藏单元做同样的事情。</strong></p><p id="818b" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">为什么用批次这个词？<strong class="mc jd"> </strong>因为它规格化了当前批次中的值。这些有时被称为<strong class="mc jd">批量统计</strong>。</p><blockquote class="no"><p id="6d19" class="np nq it bd nr ns nt nu nv nw nx mv dk translated">具体来说，批量标准化通过<strong class="ak">减去批量平均值并除以批量标准偏差</strong>来标准化前一层的输出。</p></blockquote><p id="bec4" class="pw-post-body-paragraph ma mb it mc b md ny kd mf mg nz kg mi mj oa ml mm mn ob mp mq mr oc mt mu mv im bi translated">这非常类似于特征缩放，这样做是为了加速学习过程并收敛到一个解决方案。</p><h2 id="b269" class="od lj it bd lk oe of dn lo og oh dp ls mj oi oj lu mn ok ol lw mr om on ly iz bi translated">内部协方差移位</h2><p id="9de2" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">在谈论批处理规范化时，您可能听过一个时髦的词，那就是<strong class="mc jd">内部协方差移位</strong>。考虑一个学习将x映射到y的函数的网络。内部协方差偏移指的是输入x的分布的变化。如果发生变化，我们的网络将不够有效，并且不能泛化。因此我们必须从头开始训练。</p><p id="01e4" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">考虑这个例子来理解协方差移动。如果我们训练一个网络来检测棕色狗的图像，然后你停止将这个网络应用于彩色狗图像的数据，它将不能很好地执行，我们将不得不再次训练。输入分布的这种变化就是协方差移动。那么批处理规范化在这里有什么帮助呢？</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="4fd3" class="li lj it bd lk ll nj ln lo lp nk lr ls ki nl kj lu kl nm km lw ko nn kp ly lz bi translated">批量标准化到救援</h1><p id="edb1" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">如果每一层的输入分布都相同，则网络是有效的。<strong class="mc jd">批量标准化使图层输入的分布标准化，以对抗内部协方差偏移。</strong>它控制隐藏单位的移动量。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="f079" class="li lj it bd lk ll nj ln lo lp nk lr ls ki nl kj lu kl nm km lw ko nn kp ly lz bi translated">如何进行批量归一化？</h1><p id="66b6" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">我们取每层的平均值，称为<strong class="mc jd"> μB </strong>。这被称为计算为层<strong class="mc jd"> x_i </strong>的所有值的总和除以所有<strong class="mc jd"> m </strong>值<strong class="mc jd">的平均值。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/cab125077886abf3e39b98f8aea6b52c.png" data-original-src="https://miro.medium.com/v2/resize:fit:392/format:webp/1*OpamPv9PZSuQkW62T-6iFQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">卑鄙。图片由作者提供。</p></figure><p id="7eef" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">然后我们计算方差σ B如下:<br/> 1。从每个值中减去μB，即每个值的偏差，并对偏差的平方取平方<br/> 2。对每个值的结果求和，然后除以值的数量<strong class="mc jd"> m </strong>，得到平均值或均方差。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/4721226901c21307b08a46503fb457d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Jrb_lcnNIoSrYyt2Up7azg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">方差。图片由作者提供。</p></figure><p id="1285" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">然后我们发现标准差是均方根偏差和ε的和。ε是小至0.001的恒定值。这是为了避免被零除的情况，也是为了增加方差。</p><p id="37c3" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated"><strong class="mc jd">方差的增加有什么帮助？</strong></p><p id="5f13" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">既然我们已经计算了平均值和标准偏差，我们可以如下进行归一化。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/8cca73012bc3d2f60ac308dc33316f0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*uekEO7cHOTbe6zdNM95ghQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">标准化值。图片由作者提供。</p></figure><p id="cbc7" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">然后，归一化值乘以γ，再加上β。这些是可学习的参数，用于进一步缩放标准化值。最终批次标准化值如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/8d9f8c58d9e765fcb5044ee2788104e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:344/format:webp/1*EZWSKDZuS3aIDwsKU0DM-g.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">批量标准化值。图片由作者提供。</p></figure><p id="868f" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">可以在激活功能之前和之后应用批量标准化。然而，研究表明，在激活功能之前使用效果最好。</p><blockquote class="os ot ou"><p id="1301" class="ma mb nb mc b md mw kd mf mg mx kg mi ov my ml mm ow mz mp mq ox na mt mu mv im bi translated"><em class="it">在PyTorch中，可以使用</em><strong class="mc jd"><em class="it">batch norm 1d</em></strong><em class="it">对线性输出进行批量归一化，对于卷积层过滤后的图像，可以使用</em><strong class="mc jd"><em class="it">batch norm 2d</em></strong><em class="it">进行2d输出。</em></p></blockquote></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="2eb1" class="li lj it bd lk ll nj ln lo lp nk lr ls ki nl kj lu kl nm km lw ko nn kp ly lz bi translated">有什么好处？</h1><ol class=""><li id="2791" class="oy oz it mc b md me mg mh mj pa mn pb mr pc mv pd pe pf pg bi translated">训练更快。</li><li id="a6be" class="oy oz it mc b md ph mg pi mj pj mn pk mr pl mv pd pe pf pg bi translated">使用更高的学习率。</li><li id="13af" class="oy oz it mc b md ph mg pi mj pj mn pk mr pl mv pd pe pf pg bi translated">参数初始化更容易。</li><li id="ce77" class="oy oz it mc b md ph mg pi mj pj mn pk mr pl mv pd pe pf pg bi translated">通过调节输入使激活功能可行。</li><li id="1c07" class="oy oz it mc b md ph mg pi mj pj mn pk mr pl mv pd pe pf pg bi translated">总体效果更好。</li><li id="5c4f" class="oy oz it mc b md ph mg pi mj pj mn pk mr pl mv pd pe pf pg bi translated">它会添加噪声，从而通过调整效果减少过拟合。因此，在应用批处理规范化时，请确保使用较少的丢失，因为丢失本身会增加噪声。</li></ol></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="5519" class="li lj it bd lk ll nj ln lo lp nk lr ls ki nl kj lu kl nm km lw ko nn kp ly lz bi translated">结论</h1><p id="d43e" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">当应用于神经网络时，批量标准化通过将输入标准化到隐藏层来产生更好的结果。有趣的是，批处理规范化是在VGG之后引入的，所以VGG可以通过批处理规范化得到改进，从而在ImageNet上获得更好的结果。使用更高的学习率而不消失或爆炸梯度的能力也是有希望的。注意到批处理规范化解决的问题后，我希望您现在对此有了更好的理解。</p><h2 id="4cbc" class="od lj it bd lk oe of dn lo og oh dp ls mj oi oj lu mn ok ol lw mr om on ly iz bi translated">下一场见！谢谢你。</h2></div></div>    
</body>
</html>