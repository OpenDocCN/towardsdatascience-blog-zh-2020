<html>
<head>
<title>Deep reinforcement learning, symbolic learning and the road to AGI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度强化学习、符号学习和AGI之路</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/language-models-symbolic-learning-and-the-road-to-agi-75725985cdf7?source=collection_archive---------25-----------------------#2020-10-15">https://towardsdatascience.com/language-models-symbolic-learning-and-the-road-to-agi-75725985cdf7?source=collection_archive---------25-----------------------#2020-10-15</a></blockquote><div><div class="fc ig ih ii ij ik"/><div class="il im in io ip"><h2 id="5343" class="iq ir is bd b dl it iu iv iw ix iy dk iz translated" aria-label="kicker paragraph"><a class="ae ep" href="https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2" rel="noopener ugc nofollow" target="_blank">苹果</a> | <a class="ae ep" href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz" rel="noopener ugc nofollow" target="_blank">谷歌</a> | <a class="ae ep" href="https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU" rel="noopener ugc nofollow" target="_blank"> SPOTIFY </a> | <a class="ae ep" href="https://anchor.fm/towardsdatascience" rel="noopener ugc nofollow" target="_blank">其他</a></h2><div class=""/><div class=""><h2 id="0740" class="pw-subtitle-paragraph jy jb is bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">Tim rocktschel在<a class="ae kq" rel="noopener" target="_blank" href="https://towardsdatascience.com/podcast/home"> TDS播客</a></h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/947c37169e64ed122d021e27967b8ec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T2srec3j4uDwmZogQFDrOQ.png"/></div></div></figure><p id="2223" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated"><em class="lz">编者按:这一集是我们关于数据科学和机器学习新兴问题的播客系列的一部分</em>，<em class="lz">由Jeremie Harris主持。除了主持播客，Jeremie还帮助运营一家名为</em><a class="ae kq" href="http://sharpestminds.com" rel="noopener ugc nofollow" target="_blank"><em class="lz">sharpes minds</em></a><em class="lz">的数据科学导师初创公司。可以听下面的播客:</em></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="116c" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">强化学习可以做一些令人印象深刻的事情。它可以优化广告定位，帮助运行自动驾驶汽车，甚至赢得星际争霸游戏。但是当前的RL系统仍然是高度特定于任务的。特斯拉的自动驾驶汽车算法无法在星际争霸中获胜，DeepMind的AlphaZero算法可以与围棋大师对抗，但无法优化你公司的广告支出。</p><p id="e6b1" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">那么，我们如何从利用强化学习来解决特定问题的狭义人工智能系统，向能够在世界中自我定位的更通用的系统飞跃呢？蒂姆·洛克特尔出场了，他是伦敦<a class="ae kq" href="https://research.fb.com/category/facebook-ai-research/" rel="noopener ugc nofollow" target="_blank">脸书人工智能研究所</a>的科学家，也是伦敦<a class="ae kq" href="https://www.ucl.ac.uk/" rel="noopener ugc nofollow" target="_blank">大学学院</a>计算机科学系<a class="ae kq" href="http://www.cs.ucl.ac.uk/home" rel="noopener ugc nofollow" target="_blank">的讲师。Tim的大部分工作都集中在如何让RL代理使用相对较少的数据进行学习，使用被称为样本有效学习的策略，希望提高他们解决更一般问题的能力。蒂姆加入了我这一集的播客。</a></p><p id="bcb4" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">以下是我在对话中最喜欢的一些观点:</p><ul class=""><li id="4305" class="mc md is lf b lg lh lj lk lm me lq mf lu mg ly mh mi mj mk bi translated">强化学习在由相对简单的规则结构管理的环境中工作得很好，如视频游戏、国际象棋、围棋和受约束的模拟。但是他们还不能在混乱、开放的现实世界中运作。这在很大程度上是因为他们一开始是“白板”模型，必须为他们承担的每项任务从头开始接受培训。</li><li id="ae8c" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">语言模型是解决这个问题的一种方法:为了有效地生成文本，算法需要开发一个相当全面的世界模型。然后，该模型可以被RL代理重新利用，以开发对各种对象和概念如何相互关联的基本理解，从而不必从头开始学习这些关系。举个例子:当前的RL系统无法承担像《我的世界》这样的游戏，在那里你会得到一些物体，它们的外观或名称会提示你它们的用途(例如，你在游戏中拿起一个火炬，并隐含地理解它可以用来烧毁东西)。语言模型可以帮助引导代理理解“火炬”和“燃烧的东西”之间的关系，这样代理就可以更清楚地知道它的所有潜在行为，而不必在学习如何在环境中移动和定位自己的同时学习火炬。</li><li id="d0c6" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">蒂姆还研究了基于神经网络的符号学习方法。符号学习使用符号来表示某些对象和概念，并允许开发人员显式地定义它们之间的关系。在某些方面，这是好的:因为符号系统明确地而不是隐含地学习想法或指令，它们不太可能被巧妙设计的对抗性攻击所愚弄而做错事情。不幸的是，它们还需要开发人员手动为它们提供推理结构，这使得这些系统在解决更需要隐式学习的一般问题时不切实际。蒂姆的方法包括训练神经网络学习符号逻辑——这是一种理想地结合了符号逻辑的严谨性和深度学习的灵活性的策略。原则上，这可以让神经网络理解像“父亲的任何父亲都是祖父”这样的概念，同时也正确地识别像“祖父”、“祖父”、“祖父”等这样的词，作为“祖父”的象征性等价物。</li><li id="bff9" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">符号学习可能会对人工智能安全产生影响，因为符号可以用来捕捉更强大的规则和关系，我们不希望机器误解这些规则和关系(例如，“不要杀人”)，而不会牺牲它们的实际效用。</li></ul><p id="9e7e" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">你可以<a class="ae kq" href="https://twitter.com/_rockt" rel="noopener ugc nofollow" target="_blank">在推特上关注蒂姆</a>，你也可以<a class="ae kq" href="https://twitter.com/jeremiecharris" rel="noopener ugc nofollow" target="_blank">在推特上关注我</a>。</p></div><div class="ab cl mq mr hw ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="il im in io ip"><h2 id="398a" class="mx my is bd mz na nb dn nc nd ne dp nf lm ng nh ni lq nj nk nl lu nm nn no iy bi translated">本集引用的链接:</h2><p id="9334" class="pw-post-body-paragraph ld le is lf b lg np kc li lj nq kf ll lm nr lo lp lq ns ls lt lu nt lw lx ly il bi translated">如果你有兴趣在蒂姆在播客中提到的NetHack环境中培训自己的强化学习代理，<a class="ae kq" href="https://github.com/facebookresearch/nle" rel="noopener ugc nofollow" target="_blank">看看这个GitHub repo </a>！</p></div><div class="ab cl mq mr hw ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="il im in io ip"><h2 id="9b1b" class="mx my is bd mz na nb dn nc nd ne dp nf lm ng nh ni lq nj nk nl lu nm nn no iy bi translated">章节:</h2><ul class=""><li id="9f80" class="mc md is lf b lg np lj nq lm nu lq nv lu nw ly mh mi mj mk bi translated">0:00介绍</li><li id="ca11" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">0:43什么是可解释的机器学习？</li><li id="4fa9" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">强化学习和自然语言处理之间的关系</li><li id="5983" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">9:11适合强化学习的游戏</li><li id="8b66" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">13:36探索和适应新环境</li><li id="625f" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">18:32问答系统—维基百科</li><li id="b3b3" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">20:21应用于深度学习系统</li><li id="00d0" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">25:34人工智能校准</li><li id="9950" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">31:19语言作为知识图谱</li><li id="03be" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">33:07当前人工智能研究的目标</li><li id="4cba" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">35:6大局</li><li id="702d" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">41:45哲学上为GPT-4做好准备</li><li id="39ea" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">44:57与技术相关的生存风险</li><li id="77bd" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">45:34下一步</li><li id="4d6a" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">50:05符号推理</li><li id="f623" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">51:38人工智能内部的模糊界限</li><li id="2403" class="mc md is lf b lg ml lj mm lm mn lq mo lu mp ly mh mi mj mk bi translated">53:13总结</li></ul></div><div class="ab cl mq mr hw ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="il im in io ip"><h2 id="687d" class="mx my is bd mz na nb dn nc nd ne dp nf lm ng nh ni lq nj nk nl lu nm nn no iy bi translated">下面是第二季第二集的脚本:</h2><p id="cb11" class="pw-post-body-paragraph ld le is lf b lg np kc li lj nq kf ll lm nr lo lp lq ns ls lt lu nt lw lx ly il bi translated">Jeremie (00:00): <br/>大家好，我是Jeremie，我是“走向科学状态”播客的主持人，也是最敏锐思维数据科学导师项目团队的一员。今天，我们继续我们关于数据科学和机器学习中新出现的问题的系列，欢迎Tim Rochdechel来到播客。蒂姆是脸书人工智能研究所的研究科学家，他在那里从事许多与高级人工智能系统相关的项目，包括样本高效机器学习，该项目专注于减少训练机器学习模型所需的数据量，以及符号人工智能等事物。</p><p id="1f88" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">Jeremie (00:31): <br/>现在，Tim对机器学习的当前状态有了深入的了解，我们将讨论这一点，以及人工通用智能研究的潜在未来方向。我希望你喜欢这次谈话。</p><p id="f6e8" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(00:43): <br/>好的，我和蒂姆·罗彻尔在一起。所以他是脸书人工智能研究所的研究助理，抱歉，是研究科学家，也是伦敦大学学院人工智能中心的讲师。他会告诉你所有这些东西，但他的工作真的很有趣，专注于他所谓的样本高效和可解释的机器学习。我肯定我们会深入了解这意味着什么。我们将对此进行全面的讨论，以及该领域的一些最新发展，强化学习，开放Eye的GPT-3模型，我相信会有一些出现。我们有很多内容要讲，但首先，我想问你，Tim，你能用自己的话介绍一下你正在研究的领域吗？你每天处理的一些有趣的问题。</p><p id="284c" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(01:43): <br/>当然可以。首先，非常感谢邀请。非常非常高兴来到这里。所以，我想我过去一直在强化学习和自然语言处理的交叉领域工作，现在也是。所以在强化学习中，我想我会想象很多听众对基本的设置很熟悉，你有一个环境，你有一个代理。你的代理人不是与环境一起行动，而是从环境中获得[听不清00:02:16]并旨在随着时间的推移最大化预期的未来回报，一些未来的回报。</p><p id="0607" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(02:23): <br/>这是一种非常通用的方法，对吗？一些非常通用的东西，你可以潜在地应用于许多不同的情况，然后与此同时，我想强化学习在适用于现实生活问题方面的进展相对有限[听不清00:02:42]我们可以稍后再谈。</p><p id="d359" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">Tim (02:44): <br/>同时，正如我提到的，我偶尔会研究自然语言处理问题，所以问题是，我们如何才能开发出能够处理并在某种程度上利用自然语言文本的机器？例如，自然语言处理中的一个常见问题是问答。我能开发出模型，给它一个问题，给你一个自由形式的答案吗？</p><p id="77f6" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(03:12): <br/>嗯嗯(肯定的)。</p><p id="9714" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(03:12): <br/>或者，这并不是实际生活中的问题，而是一类非常受欢迎的模型，即所谓的语言模型，这些模型在给定一些文本的情况下，能够很好地预测文本中的下一个单词，然后生成文本。因此，在过去的几年里，我们已经看到了很多进步。</p><p id="2846" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(03:34): <br/>有意思。强化学习和自然语言处理之间的联姻有什么原因吗？因为至少从历史上看，这是我从30000英尺的角度理解的，从历史上看，强化学习和计算机视觉可能会有更紧密的互动，重点是自动驾驶汽车，也许还有机器人。你认为NLP是这里有趣的成分之一是有原因的吗，还是说，它只是碰巧同时发生的两条独立的研究路线？</p><p id="e936" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">Tim (04:08): <br/>没有。我确实看到了两者之间的许多协同作用，所以这是一个非常好的问题。首先，传统上，人们一直在自然语言处理任务中应用来自强化学习的各种技术。因此，人们一直在使用增强来直接优化机器翻译性能，而不是对[听不清00:04:31]模型使用负面[听不清00:04:30]训练。所以已经做了很多了。然后，反过来，人们也一直在研究指令跟随，所以给定一个智能体需要实现的目标的某种自然语言描述，我们如何设计能够以这样的自然语言信息为条件的智能体，然后在环境中实现目标？</p><p id="9c05" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">Tim (04:53): <br/>我之所以坚信自然语言处理和强化学习之间的结合，在很大程度上是因为到目前为止，我们已经看到了很多强化学习的成功案例，在这些环境中，你基本上可以从头开始训练。这意味着，随着时间的推移，您的到期策略允许代理充分学习或探索环境，以便提出非常非常好的策略。举例来说，这在你的环境动力有限的环境中是可行的。举个例子，我认为围棋是一个很好的例子，它在几年前就开始流行了，对吗？通过深刻的思考。</p><p id="5d76" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(05:46): <br/>这是一项令人印象深刻的成就，因为他们能够训练一个人工智能，在围棋比赛中击败人类专家。然而，重要的是要注意，围棋中的动力学相对简单，对吗？规则非常清楚，所以你有一个规定的时间步，有一个特定的动作，下一个时间步会发生什么是绝对清楚的。所以基本上，你可以进行蒙特卡罗树搜索。这意味着你实际上可以试着提前计划特定的行动顺序会发生什么。</p><p id="d300" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(06:23): <br/>但是在很多其他环境中，人们会带来很多领域知识、常识和工作知识，只有这样他们才能在这些环境中做得很好，对吗？例如，我认为一个很好的例子是《我的世界》。所以如果你玩《我的世界》，有很多事情与现实世界中的事情非常相似，对吗？因此，如果你有一个火把，你开始燃烧一棵树，它只是烧毁。我觉得这很令人兴奋，对吧？那么，我们如何确保我们的代理人能够利用人类随着时间的推移收集的知识财富，他们在维基上写下来，他们写在表格里等等？他们[听不清00:07:15]</p><p id="5d39" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(07:17): <br/>这其中的一部分，或者至少是我一直理解的，是我们的知识的一部分，当然，是随着时间的推移学习的，就像你说的，我们阅读维基或阅读教科书，或者只是被世界所教的东西，但是我想，另一部分也是先天的，是通过一个缓慢得多的过程，即进化教给我们的。所以我们生来就不是一张白纸，而是生来就对看起来像某个样子的面孔有特定的偏好，等等。我想，在某种程度上，这似乎涵盖了这两个方面。如果你真的能总结出一大堆人类知识，我不知道，维基百科语料库或人们写的所有语言，我想希望你涵盖了这两个基础？这样说公平吗？</p><p id="68f4" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(08:03): <br/>嗯，我认为这是一个非常好的观点。我相信你必须在某种程度上把它们分开，对吗？你必须说，“好吧，有人们写下来的知识。他们在一生中获得的东西，他们想和其他人分享这些知识，可能在某个时候，和代理人，人工代理人分享。”这是我大部分时间都在关注的事情。然后你提到的另一个方面，进化和天生的某些行为允许你，例如，要么直接在环境中表现得很好，要么允许你很快学会什么是环境中的好政策。我认为这也是一个非常令人兴奋的领域。我不太熟悉那个研究领域正在发生的事情，除了，我相信，我强烈认为我们需要像信使一样的代理人去探索。</p><p id="4afc" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">Tim (09:01): <br/>所以这是不够的，对于许多现实的环境来说，试图根据环境给你的奖励来最大化奖励真的是不够的，对吗？</p><p id="0edd" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(09:10): <br/>是的。</p><p id="2324" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(09:11): <br/>在许多环境中，我认为给自己设定目标是绝对重要的，因为你遇到了意想不到的事情，增加了你对环境的了解。我认为这是非常关键的一点。这就是为什么人们喜欢玩像《我的世界》这样的游戏，他们只是了解某些事情是如何工作的。我在这里说了很多关于《我的世界》的事情，但实际上，我相信还有其他游戏可能更适合强化学习。</p><p id="ac47" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(09:41): <br/>喜欢什么类型的游戏？</p><p id="357a" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(09:42): <br/>几周或几个月前，我们发布了NetHack学习环境。所以这是一个强化学习环境，围绕着一个非常古老的游戏，叫做NetHack。NetHack最初是在1987年发布的。它在终端播放，所以这确实是一个甚至没有任何彩色屏幕的时代。</p><p id="12c4" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(10:06): <br/>是啊。</p><p id="9891" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">Tim (10:06): <br/>你真的在Linux终端上玩过这个。所以所有的观察值都是[听不清00:10:12]字符。看起来很神秘，很刺激。所以基本上，你被扔进了这个地牢。你的玩家就是这个“at”符号。你可以在地牢里走动。怪物是其他askey字符，像D可能是一只狐狸或可能是一只狗或类似的东西。你走来走去，发现物品，武器，盔甲等等。这个游戏真正令人兴奋的一个方面，实际上类似于《我的世界》，是它是按程序生成的。所以，也许多谈一点会更有趣。</p><p id="1242" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(10:48): <br/>当深度强化学习变得非常流行时，研究人员正在使用神秘的学习环境。所以Atari games，为了测试代理是否能学会玩Pong或者Pacman女士或者Montezuma的复仇之类的游戏。这真的推动了强化和研究很长一段时间。但有趣的是，到现在为止，我觉得这些游戏几乎都被人工智能吃掉了。</p><p id="8f19" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(11:19): <br/>嗯嗯(肯定)。</p><p id="e4fb" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(11:20): <br/>通常，这告诉我们更多关于实际环境和突出问题的信息，它告诉我们人工智能有多智能。这很重要的原因是因为在雅达利，环境在某种意义上是静态的。所以每次你玩这个游戏，都是一样的。</p><p id="8373" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(11:40): <br/>是啊。</p><p id="6019" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(11:41): <br/>对吗？所以每次你玩Pong或者Breakout的时候，你看到的观察结果并没有太大的变化。同样的，你想想超级马里奥，对吧？每次你玩超级马里奥，等级都是一样的。</p><p id="dd7e" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶肋米亚(11:53): <br/>是啊。</p><p id="1e2b" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(11:54): <br/>因此，随着时间的推移，你将学会做的几乎是记住为了做好你必须做的行动的顺序。</p><p id="4aa4" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(12:00): <br/>是啊，[相声00:12:01]你太适应你的环境了。</p><p id="0d61" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">提摩太书(12:03): <br/>完全正确，对吗？具体来说，环境是决定性的。这意味着，如果你发现自己在同样的情况下，你会做同样的行动，你会看到同样的结果。所以这是确定性的，我称之为静态的，就环境观测变量而言。最近成功的方法没有探索这一点。所以，我认为，2018年优步人工智能有一个非常惊人的工作，叫做“探索”，他们解决了这个非常非常难的雅达利游戏，叫做“蒙特祖马的复仇”。他们基本上是通过确保重置代理或环境来做到这一点的，实际上，他们将代理或环境重置为以前访问过的状态，然后从那里开始浏览。对吗？所以，真的随着时间的推移，代理人通过游戏记忆特定的动作序列。</p><p id="ed60" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(12:56): <br/>这让许多研究人员开始考虑所谓的过程生成环境。这意味着，有一个生成过程，每次你开始一集，观察基本上是在你面前生成的。这意味着每次你开始一集，你会看到你以前从未见过的东西，比如在《我的世界》，对吗？每当你玩新的《我的世界》游戏时，这个世界就会产生。</p><p id="2488" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">提摩太书(13:20):<br/>NetHack也是这样。所以每次你被扔进地牢，你真的不知道在地牢的拓扑结构或特定房间和暗门的安排等方面会发生什么。这就迫使我们的特工，为了做得更好，去归纳这些新奇的情况。</p><p id="fa8a" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶肋米亚(13:36): <br/>有趣。所以，这是，我猜这和蒙特祖马的复仇是一个质的不同的问题。如果我记得的话，那一个也有类似的问题，奖励经常被隐藏或者稍微远一点。你必须做一些违反直觉的事情来获得这些奖励。我想这是一个不同的问题，现在你面临着一个全新的环境，你实际上学习做的不仅仅是，嗯，在某种程度上，这感觉像是一个探索/开发的事情。你不想过度投资开发这种确定性环境。你还需要善于在这个新环境中探索和定位自己，而弄清楚自己身在何处的技能，现在人们已经开始在努力了？这是这项研究的目的吗？</p><p id="0444" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(14:21): <br/>是的，我认为这是一个相对较好的评估。所以，在蒙特祖马的复仇中，你是对的，这是一个稀疏的奖励环境。这意味着你不会真的撞上许多来自环境的外在奖励，所以你真的必须探索很长时间，才能从环境中获得积极的信号，表明你正在做正确的事情。但有趣的是，蒙特祖马的复仇已经利用了许多人类的先验知识和偏见。所以，在蒙特祖马的复仇中，你必须收集钥匙，你必须开门，如果你作为一个人类玩家在蒙特祖马的复仇中跑来跑去，你看到一把钥匙并捡起来，那么你知道，好吧，一定有一扇锁着的门在某个地方，然后当你看到一扇锁着的门时，你就打开它。</p><p id="9359" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(15:01): <br/>但是对于强化学习方法，至少是那些已经存在了很长时间的方法，他们有非常多的探索策略，对吗？他们偶尔会尝试一个随机的动作，看看是否真的有帮助。所以我们真正需要的是能够进行结构化和目标导向的解释的方法，这种方法能够激励他们自己，以一种非常有针对性的方式探索环境的某些方面。随着时间的推移，他们了解环境动态，了解你可以与之互动的事物以及如何与之互动。</p><p id="67a0" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(15:36): <br/>在蒙特祖马的《复仇》中，你可以看到钥匙和门等等。在NetHack中，你有数百个对象。各种各样的事情，对不对？各种武器，各种工具，比如开罐器，土地，钥匙等等，对吗？而且真的有如此大量的对象要学习，也有如此大量的敌人要打败，以至于人类玩家在学习玩网络黑客时，几乎所有人都必须自己查阅外部知识来源。所以有一个非常大的维基百科，叫做NetHack Wiki，在那里人类玩家收集他们关于这个游戏如何运作的共享智慧，你可以做什么，你应该做什么和不应该做什么。当人们玩这个游戏时，他们真的学会了，嗯，在环境中做事，同时也在这个网络黑客维基上查找东西。</p><p id="ca27" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(16:30): <br/>这似乎很大程度上取决于你的创造能力，或者有一个连贯的世界模型来补充你的探索。我认为这实际上与GPT 3有关，当然，这是最近几个月发行的。让我想到这个的原因是，GPT 3是那些面向自然语言的方法之一，至少试图构建一个相当完整，相当连贯的世界模型。我可以想象，仅仅基于GPT-3似乎能够做的一些事情，它似乎能够得出的一些联系，就承担这样的问题而言，它将是一个不错的知识基础。你认为这是一个公平的评价吗？你能把它用于迁移学习并和RL结合起来吗？</p><p id="f765" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(17:18): <br/>是的，我认为至少有两种不同的方式可以利用这些预先训练好的语言模型。因此，一种方法是，假设你有一个外部文本知识源，如NetHack Wiki，你想根据这些文本信息来调节你的强化代理。那么通常，试图学习语言，同时试图从头开始学习如何在环境中表现，这是一个坏主意，对吗？所以强化学习很难，自然语言处理从零开始也很难。如果你同时做这两件事，事情不会变得更容易。所以你想做的是，你想有一个好的起点，对吗？</p><p id="e938" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(17:59): <br/>你希望有一个已经可以为你建立的模型，相对好地表达维基百科中所写的句子，这样你就可以在整个维基百科或NetHack Wiki上运行预先训练好的语言模型。你建立起所有的句子表征，或者单词和上下文表征，或者你想称之为什么的东西，然后你可以在环境中行动的同时尝试查询这些神经表征。这给了你一个操作维基的方法。</p><p id="fa05" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(18:32): <br/>虽然据我所知，这还没有完成，但对于复杂的强化学习任务，如NetHack学习环境，这还没有真正完成，我们有理由相信这是一种明智的方法，因为有问答系统能够处理如此大规模的维基。例如，整个维基百科。对吗？</p><p id="5d80" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(18:54): <br/>第二种方法是，或者第二个方向是……我想这可能是你的意思。是使用预先训练好的语言模型，比如GPT-3，作为一个很好的先验，比如，物体的启示，对吗？你可以查询GPT-3，我有一扇门，我能用它做什么？它可能会告诉你，你可以打开它，用钥匙打开它，踢它进去，无论什么，对吗？它可能会给你一些你可能想尝试的明智的东西，并且，很明显，可以用于你的强化代理可以应用的更好的探索策略[听不清00:19:35]</p><p id="c869" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(19:35): <br/>是的。我一直觉得语言建模，尤其是更完整的语言模型，如GPT 3和GPT 4，以及其他即将出现的语言模型，对这类事情来说特别有前途，你提出的表格化的想法，空白的石板。你如何教会一个智能体从零开始在世界中定位自己，或者你如何避免不得不这样做？是的，用这些预先训练好的模型来支撑它，这看起来是一个很有前途的策略。所以，我认为一个很酷的主题，我们可以在你的研究背景下谈论，它似乎有很大一部分涉及到，找到将人类水平的信息传递给神经网络和机器学习模型的方法，我想是在非常抽象的意义上。</p><p id="82eb" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">Jeremie (20:21): <br/>我们已经谈过你对NLP的关注，以及与RL的互动。在我们开始讨论之前，你也提到过你一直在深度学习系统上做这项工作，并试图让它们基本上与逻辑规则一起工作，因此允许人类传达逻辑规则来约束深度学习系统的行为。你介意稍微探索一下，解释一下这项工作的内容吗？</p><p id="8f26" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(20:43): <br/>是的，当然。这是我在博士期间主要做的工作。我认为深度学习系统真的很棒。像GPT-3或深度强化代理这样的深度学习系统，他们真的很擅长从大量数据中学习。对吗？但是，问题是，对于许多领域，我们没有很多训练数据，或者我们可能想确保我们有一定的保证，在我们训练完系统后，它会做出一些预测。举一个例子，它总是预言人终有一死。这很有趣，因为在符号人工智能中有一个非常悠久的传统，人们一直在思考如何使用逻辑规则，如何根据现有的知识，现有的事实和现有的逻辑推断新事物[听不清00:21:46]</p><p id="9ba5" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(21:46): <br/>这真的很有趣，因为你不需要任何训练数据，对吗？所以你可以写下特定领域的事实，你可以写下特定领域的规则，然后你就可以做出推论。此外，你还有很强的保证。你知道，如果你有一个规则，告诉你每个人都会死，每次你有一个特定的人，你会预测那个人会死。如果你研究深度学习系统，就会发现有很多对抗性攻击的例子，对吗？比如说，你有一个系统，它对交通灯进行分类，你改变图像中的特定像素，预测就会不同，这显然会产生各种灾难性的后果。</p><p id="5a26" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(22:31): <br/>现在，符号系统中逻辑规则的问题是，它们不能概括你明确写下的东西。对吗？你必须写下所有你需要写下的东西，基本上，对吗？所以，给你一个具体的例子，假设你有辛普森一家，你有巴特·辛普森，荷马辛普森和辛普森爷爷。亚伯，对吧？因为辛普森爷爷。你有事实证明霍默·辛普森是巴特·辛普森的父母，阿贝·辛普森是霍默·辛普森的父母，你有一条规则规定，父母的每一个父亲都是祖父。对吗？所以现在你可以断定，实际上，亚伯·辛普森是巴特·辛普森的祖父。</p><p id="5fae" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">提摩太书(23:15): <br/>但那只是为了那个特定的象征，即关系的祖父。但是爷爷呢？对吗？爷爷和祖父，他们是两个不同的词，他们是两个不同的符号，所以你如何确保我们也能做出更柔和的推论？在那里，我看了很多，我想，结合了深度学习的神经表示以及符号系统的优点，所以是基于规则的系统。我们已经…是的。</p><p id="485f" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(23:44): <br/>这是有道理的，因为你需要那种灵巧……在某种程度上，你需要为爷爷嵌入，然后你需要在那个嵌入空间附近的单词说，“哦，是的，这些可能是同义词。”这是想法的一部分吗？</p><p id="65be" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(24:00): <br/>是的，所以我们当时遵循两个方向，一个是，你有一个工作的神经元，它试图预测给定的特定事实，就像Bart的祖父Abe一样。试图预测该事实是否是真的，并且有一些模型试图仅根据这两个实体的神经表示来预测。在这种情况下，安倍和巴特，以及关系的代表，祖父的。在那里，我们使用逻辑规则来约束或直接调整这些习得的表征，以便在未来，每当我们在神经表征中有祖父关系[听不清00:24:42]时，我们很可能在某人的父母的父亲之间预测它。</p><p id="c134" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">提摩太书(24:47): <br/>这是一项工作，另一项工作与你提到的更接近。所以这是个好主意。我是说你的评论非常好。这是NeurIPS在2017年发表的一篇论文，我们实际上采用了现有的数据锁证明系统，我们基本上把整个所谓的反向链接算法(用于序言和数据日志，老式人工智能系统)转变成了一个神经网络。那是在人们非常重视使用现有的算法和数据结构的时候，做的事情，是的，被称为神经化它们，基本上把它们变成神经网络，使它们[听不清00:25:31]这样他们就可以做这种软比较，可以训练[听不清00:25:35]</p><p id="fd28" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(25:34): <br/>这真有趣。所以，我发现这如此引人注目的原因之一是一个大焦点…实际上，这个播客系列的一个大焦点，也是我个人的一个大焦点，也是这个问题的人工智能对齐。只是这个想法，随着我们的智能系统变得越来越强大，越来越有效，我们需要能够向它们传达人类的价值，我们需要能够传达约束，我们不想要一个物理体现的RL系统或任何东西。我们不希望有一个这样的系统四处运行，对人们造成伤害，因为它是在一个分布式的环境中运行的，或者它没有考虑到一些奇怪的，敌对的可能性。</p><p id="b29f" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(26:13): <br/>这看起来就像是让我们在符号层面上交流的想法，使用逻辑，直接与神经网络交流，至少开辟了某种途径来确保，例如，你可以实际传达这样的想法，例如，不要杀人。或者类似的东西。不是说这么简单。很明显，正如你提到的，下游非常复杂。“人民”这个词将如何解释？“杀”这个词将如何解释？诸如此类。但它确实让我们和机器交流变得更容易了，在某种程度上，通过这些算法。我不严格地使用了沟通这个词，但是你是否认为它在这个外部校准问题中扮演了一个潜在的角色，让人类至少以一种更有效的方式向机器传达他们想要的东西？</p><p id="cff7" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(26:59): <br/>我认为这是一个很棒的问题。首先，我应该诚实地说，我不是人工智能对齐或人工智能安全方面的专家，所以我在这方面说的任何话都应该持保留态度。我确实相信，我们现在有新的方法来约束人工的[听不清00:27:20]使用领域专家知识，例如以逻辑规则的形式。然而，那是假设你能以逻辑规则的形式写下所有你想教给你的人工智能系统的东西，对吗？这是一个很大的假设。我能想象出无数的场景，在这些场景中，那个简单的规则，不要杀人，对吧，是非常有问题的。我很确定，实际上，我知道人们一直在思考这种豁免。所以这是一个问题。</p><p id="3bb1" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(27:48): <br/>另一个问题是，我认为我们还没有完全解决我们在多大程度上完全执行逻辑规则，在多大程度上我们希望给模型足够的自由，对吗，去了解我们生活的这个混乱的世界，对吗？如果你以自然语言为例，这里有很多混乱的东西，对吗？作为人类，我们甚至面临如此多的模糊性和问题，我们的人工智能系统或前期语言模型和自然语言理解系统仍然难以处理。所以，我确实相信我们还有很长的路要走。</p><p id="c4d7" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(28:32): <br/>但与此同时，我认为在某种程度上有一些协同作用，因为这不仅仅是要确保我们的人工智能与我们的价值观保持一致，还涉及到我们如何确保我们的人工智能系统是高效的，所以这意味着，它们能快速学习以适应新的情况吗？他们能有效地探索环境吗？为此，他们也必须学会理解，我认为，自然语言，我们的意图，我们的过去和偏见。</p><p id="5f6b" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(29:05): <br/>实际上，我认为有一个假设一直在我的脑海中，但没有说出来，那就是你刚才想到的最后一句话是，为什么自然语言是构建这些世界模型的如此好的候选语言？也许，我不知道，你想详细阐述一下这个想法吗？为什么一个语言模型会比，比如说，我不知道，一个在ImageNet或类似的东西上训练的计算机视觉模型更好？是什么让语言作为世界模型的来源变得很有前途，然后可以应用于强化学习代理，给他们一条腿，让他们不必从头开始学习这些东西？</p><p id="e443" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(29:48): <br/>好吧，我可以给你举一个例子。再一次，这是以我之前提到的NetHack这个游戏为中心的，因为你也许可以使用…比如说，如果有NetHack的3D渲染，这并不…实际上，它确实存在，但是假设有NetHack的3D渲染。显然，你可以使用预先训练的计算机视觉模型来给你的模型一种什么是某些物体的感觉，对吗？也许某处有一把椅子，什么的，比如某处的盔甲。但在像NetHack这样的游戏中，或者在许多我认为我们在现实世界中关心的实际环境中，重要的是我们有书面的知识和程序性的文本，告诉我们如何做某些事情，对吗？</p><p id="354e" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(30:33):<br/>net hack，维基上有很多战略指导，告诉你在某些情况下应该做什么，不应该做什么，这种知识，我们作为人类，至少可以用自然语言传达。这并不意味着自然语言是构建世界模型的最佳方式。我可以想象你可以拥有人工智能，如果它们真的很聪明，它们可能会想出各种各样的内部表示来编码世界是如何工作的，这可能不会反映或连接到我们人类的自然语言。但至少现在，这是唯一的来源，例如，我为了让代理学习网络黑客，对不对？因为在[听不清00:31:19]中，人们一直在使用自然语言来写什么该做，什么不该做</p><p id="e970" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(31:19): <br/>对，我想，在某种程度上，人类可以通过语言相互传递任意的知识，在某种程度上，我可以教你，或者你可以教我，任何人类可以通过书写来了解的知识。这意味着语言是这个知识图表，是这个世界的隐含模型，是人类几乎能够储存的最完整的模型。你不同意那个想法吗？</p><p id="a64e" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(31:47): <br/>嗯，我认为还有很多知识我们无法用自然语言传达，对吗？我想在某些情况下，我不得不说，“看，我可以向你演示我是如何做某些事情的，但你必须亲自体验。”我可以试着向你解释，尽管我很想解释，当我做某些动作时，不管是空手道动作还是其他什么动作，那种味道对我来说是什么样的，或者那种感觉对我来说是什么样的。但是你真的要去训练，你要自己去体验。</p><p id="fff9" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(32:21): <br/>所以，我认为，是的，公平地说，仍然有很多知识我们无法用自然语言表达或传达。但是我相信，我想，在这种推理水平上，这显然是非常[听不清00:32:35]的术语，对吗？但这是我期望人工智能在游戏或模拟环境中能够做到的推理。我认为很多都是用自然语言传达的，对于很多游戏来说，我们有这些文本维基资源，我们应该在训练强化代理时加以利用。我还认为，从长远来看，这将使我们能够训练强化智能体，使其能够解决更多真实世界的任务，而不仅仅是这些模拟任务。</p><p id="3f17" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(33:07): <br/>也许这对你来说是一个好的长期发展。对你来说，现在正在进行的人工智能研究的目标是什么？是关于接近，比如说，AGI的终点线吗？它是关于让我们有人工智能起飞的点，还是更多，你认为那是更远的，现在，我们只是在一系列狭窄的任务上工作？</p><p id="6fc0" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(33:33): <br/>我认为这是一个非常好的问题。老实说，我不认为我是那种会说在努力创造人工智能的人。我认为有一个公开的争论，即使是人类也能在多大程度上拥有一般的智力。我们在现实中看到的是，人们在某些领域非常专业。举个例子，我可能是一个不错的科学家，但是我现在肯定不能驾驶飞机。我或许可以学会，但那显然会带来各种额外的成本，而且我在现实世界中所能学到的东西是有限的。这种想法是，我们将拥有能够完成各种任务的人工智能，我认为这是一个开放的问题，如果这是可能的话。而且老实说，我一直……我一直在努力设定相当雄心勃勃的研究目标，对吧？让代理可以在这些程序生成的环境中学习，这些环境必须以外部知识源为条件。</p><p id="3b8b" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(34:41): <br/>我认为这是我们认为在一两年内不会发生的事情。我认为这是一个长期的努力，我对预训练语言模型的最新进展感到非常高兴，但我不认为这将带我们走到那一步。我认为在我们的代理人能够解决网络黑客问题之前，还有很多事情需要做。听起来很有趣，对吧？因为这是一个愚蠢的游戏。</p><p id="b7ed" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(35:06): <br/>是啊。因此，我很乐意听取你的意见，因为我认为这对于这个领域的许多人来说是一个非常热门的话题。很明显，这在很大程度上是受GPT-3的启发。实际上，也许值得简单提一下，GPT-3是什么，因为我们已经提到过几次了。我觉得我对这个词的使用太随意了。你介意提供一个什么是GPT-3的快速总结，然后也许我们可以把它联系到这个更大的图片吗？</p><p id="09f8" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(35:32): <br/>当然可以。所以，GPT-3是一个语言模型。语言模型在自然语言处理中有着悠久的传统。例如，它们已经被用作机器翻译系统的一部分。一个语言模型基本上只是一个模型，它允许你给一个单词序列打分，它允许你给这个单词序列的可能性打分。例如，你可能想为英语训练一个语言模型，现在它可以给你一个特定的句子，语言模型会告诉你这个句子有一定的概率。你可以想象这有多有用，因为如果我有一个机器翻译系统，需要从一种特定的源语言翻译成一种[听不清00:36:13]语言，如果我可以列举多种可能的翻译，然后我可以使用一个语言模型来评分哪一种是最好的，对吗？举例来说，这可以让你有一个很好的解码器来把它从一种特定的语言翻译成另一种语言。</p><p id="e766" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(36:30): <br/>几年前，人们一直在使用各种语言模型的统计方法，即所谓的MREM模型，在大型文本语料库中计算特定单词的单字母词、双字母词和三字母词等出现的频率，然后你可以使用这些方法对单词序列进行评分。然后，再一次，我猜几年前，人们开始使用深度人工神经网络进行语言建模。以及最近所谓的变压器架构。</p><p id="7310" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(37:09): <br/>首先，这些模型对你的词汇中的每个单词都有一个表示，基本上，在大型文本序列中，可能有500个左右的单词。在每一个时间点上，他们试图根据前一个单词的历史来预测下一个单词。事实证明，如果你让这些深度人工神经网络变得非常大，并且你收集了一个巨大的文本语料库，那么我们谈论的是数十亿字节的文本数据……我们谈论的是这些人工神经网络中超过1000亿个参数。你把这些放在一起，这样一个非常大的模型和一个非常大的高质量的文本语料库，然后你得到像GPT-2和GPT-3这样的东西。所以，真正擅长创造特定历史记号的语言模型，[听不清00:38:04]词汇的历史产生了下一个[听不清00:38:06]</p><p id="7d6a" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(38:07): <br/>我认为真正令人惊讶的是，在GPT-3的情况下，你可以启动这些模型，所以你可以开始，例如，给GPT-3举一些例子，比如，你可以用Java给我编码吗，如何反转列表？然后你写下[听不清00:38:31]列出的Java程序。再给它几个这样的例子，然后它就准备好了，你就可以开始用自然语言编码了。我想，你可以用自然语言进行查询，比如，你现在能数出列表中元素的数量吗？它会给你可执行的，让我们说Java代码为你做到这一点。这很令人兴奋，但同时，我认为，考虑到模型的整体规模和高质量文本数据的规模，这并不令人惊讶。那是用过的[听不清00:39:00]</p><p id="b776" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(39:00): <br/>我记得这是一个有争议的问题，大约在两三年前。在人工智能比对社区或担心缩放这些模型的人之外，你可以只是，这个所谓的缩放假设，你可以只是让模型变得更大，投入更多的计算，投入更多的数据，你不仅会得到更高质量的结果，还会从中获得更多的泛化能力。比如说，你可以从一个被美化的自动完成算法发展到现在，就像你说的，只需要相对最少的启动，就可以用Javascript或者别的什么来编码。我认为公平地说，它的这一方面是最近两三年的新事物，这样说公平吗？</p><p id="74cd" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(39:42): <br/>对，我认为可以这么说。我认为总有一些声音，我也是其中之一，我会说，“看，我真的不相信我们只是越来越多地缩放模型，我们只是向它扔更多的数据和更多的计算，我们会得到更令人印象深刻的结果。”但到目前为止，情况仍然是这样，我非常肯定我们将在某个时候拥有GPT-4，这将更加令人印象深刻。所以，我想，我们还没有按下按钮，但我认为仅仅训练语言模型存在一些根本性的问题。</p><p id="940a" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(40:17): <br/>很明显，人们已经开始把这一点拆开，研究这些模型的系统归纳能力或推理能力，对吗？举例来说，一开始，给它一个质数序列，然后你想让它继续产生更多的质数，它就是不工作，不明白，对吗？而人类，在某些时候，他们会意识到，好的，啊，这是[听不清00:40:38]为你产生更多的质数。</p><p id="b6f7" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(40:41): <br/>所以，还有很多事情要做，无论谁认为GPD将是我们所有问题的解决方案，并将我们直接带到AGI，我都不同意这种说法。</p><p id="1d2d" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(40:56): <br/>是的，不，这是一个有趣的观点，我听到一些人这样说，虽然不一定有希望。我认为也有潜在的担忧，因为人工智能安全研究和人工智能对齐研究还没有准备好真正适应可推广或一般水平的人类智能。关于你提到的神经网络的许多交流困难，我们不知道如何将我们想要的嵌入到这些神经网络中，如何设置我们的损失函数，使它们在道德上是一致的，等等。但是我想，我也发现了一件值得注意的事情，那就是GPT 3号，或者不好意思，GPT 2号，基本上不会做加法或者很难做简单的算术加法，即使是一位数和多位数的加法。</p><p id="8426" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(41:45): <br/>和GPT-3，至少是它的大版本，你可以看到，当他们按比例放大时，你可以看到这些越来越大的加法和越来越多的数字的功效。我想这里有一个悬而未决的问题，在多大程度上这算是推理。但我的感觉是，我们已经在某种程度上改变了目标，潜在的是，我们在这里学到的可能更多，不是GPT-3比我们想象的更强大，而是可能只是人类的大脑没有我们想象的强大。也许是因为我们不仅针对参数效率进行了优化，还针对能效进行了优化。我们有各种各样额外的进化限制。飞机远不如鸟节能，但与鸟相比，它能跑得非常快。我想，不好意思，我对这个问题的一个担心是，也许我们会一次又一次地感到惊讶，GPT 4号可能会给我们带来某种程度的能力，而我们在哲学上还没有准备好适应这种能力。在这个阶段，你认为这是可能的还是不可能的？</p><p id="bdfa" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(42:55): <br/>我认为我们离那还很远。我认为，首先，你是对的，我们一直在改变目标。我们过去一直都是这么做的，对吧？我们一直在用国际象棋做这个。我一直在参加这一集的会议。我一直在有目标地做这件事，对吗？我一直在说，“看，这是超级令人印象深刻的，结果也是超级令人印象深刻的，”但是为了学习目标，你必须从现实世界中转移的东西实际上是零，对吗？有点像《我的世界》，但NetHack在这方面有所不同。</p><p id="e5b4" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(43:24): <br/>所以我们一直在改变目标，我们将来也会这样做。我认为GPT-4，肯定会令人印象深刻，但即使是GPT-3，我认为如果你[听不清00:43:34]足够长的时间，如果你用它从未见过的数字展示它，那是非常大的，对吗？如果我告诉你这两个数字，一个是一万亿左右，另一个是一万亿左右，你就能算出来，对吗？因为你可以写下一个算法，或者你可以写下一些我给你的任务的符号表示，你每次都能可靠地解决它。然而，随着GPT-3和GPT-4的出现，只要你只关注训练一个语言模型，你仍然会很挣扎。这将是令人印象深刻的，它也将有各种下游应用，对不对？</p><p id="b0c9" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(44:17): <br/>这太棒了，对吧？正如我提到的，我们可以潜在地利用它们来处理文本数据，进行强化学习。基于GPT-3的各种有趣的应用程序层出不穷，但不知何故，我相信我们总有一天会碰壁。我不能确定，对吧？如果可以的话，我可能现在就写一篇关于这个的论文。但是我的直觉告诉我，如果我们训练这样做，如果我们集中精力，这将不会达到我们能够达到的可靠推理的水平。</p><p id="4aa0" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(44:57): <br/>有意思。我想，推理的门槛也很重要，因为在某种程度上，对于那些更担心下游，甚至是与技术相关的存在风险的人来说，就像，你真的需要多少推理才能让一个人工智能系统有一些关于如何迭代自我改进的想法？目前还不清楚其中有多少是新颖的推理，因为也许在它的语料库中，有足够的信息让它进行模式匹配，直到它得出结论，或者其他什么。但我认为这是一个非常有趣的可能性空间。这也太违反直觉了。</p><p id="d4fe" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(45:34): <br/>但是我要给你最后一个很难回答的问题，因为你在这个领域非常专业，如果你要猜测你需要什么技术才能与GPT-3这样的东西结合，打破这种模式，你会发现这种模式似乎没有你所说的推理能力。它肯定缺乏任何一种代理或内在动机。我肯定有一大堆不同的可能性，但只是问你一个不公平的问题，让你为难，你对下一步会是什么有什么想法吗？</p><p id="35a9" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(46:07): <br/>对我来说，什么是绝对不清楚的，我认为可能有很多其他研究人员已经从神经科学的角度探索了这一领域，这是我们人类能够做到的概念和符号的出现，对吗？我们想出了数学，我们能够外化我们的思维过程。如果我把它写在纸上，我就能写下一个算法，或者写下方程来解决一个特定的任务。除非我们在这些深度学习系统中有一些东西，人工神经网络，鼓励这种清晰概念的形成，然后他们可以在符号层面上进行推理，我认为我们会碰壁。因此，神经处理和符号处理的结合，我认为我们将不得不在这方面取得很大进展。</p><p id="a5cf" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(47:02): <br/>那么，可以说那是你的AGI火警吗？如果你看到GPT-4展示了逻辑推理和推论的象征性水平，对你来说，会不会像这样，好吧，现在我改变主意了，现在我认为这种策略可能行得通？或者…</p><p id="8c24" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(47:23): <br/>是的，但是，这是一个很大的但是，我们仍然能够，当我们进行所有这些逻辑推理时，我们仍然能够被扔进完全陌生的情况中，并迅速适应，或者至少是理智的。我认为如果你把两者结合起来，对吗？如果你看到两者都发生了，那么，我想，是的，我会很感动。</p><p id="8da5" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(47:48): <br/>真有意思。是的，实际上，这让我意识到这也是有区别的，在…所以首先，我们对AGI有一个非常模糊的定义。我认为G才是真正让我们犯错的地方。普遍聪明是什么意思？人们谈论图灵测试是我们将要使用的东西，现在图灵测试，我认为人们可以公平地说，嗯，我们已经做出了可以通过它的系统，其中一些人假装自己是一个无能或不善言辞的人…我认为其中一个人假装自己是一个不善言辞的俄罗斯少年。</p><p id="9203" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(48:20): <br/>所以，这就像是，一个人工智能系统可以表现得像一个不善言辞的俄罗斯青少年吗？好吧，好吧，是的，你技术上通过了图灵测试，但这到底说明了什么？但我猜这揭示了什么，至少对我来说，是AGI和潜在风险水平，高能力，人工智能之间的差异。这在技术上可能是狭隘的，但尽管如此，可能会带来风险。这符合你的观点吗？</p><p id="0497" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(48:47): <br/>对，绝对是。我想，我们已经有了很多公开的、道德的问题，关于我们有能力开发的人工智能，对吗？有很多基于人的图像的人脸检测、性别检测或其他检测的例子。我们现在有能力合成高质量的人脸，对吗？也有这样的例子。你可以想象对它的各种误用。也可以想象语言模型的各种误用。是的，回到你对图灵测试的评论，我想我会很好奇的一件事…基本上，当人们问我，“好吧，我们应该用什么来测试系统的普遍智能？”</p><p id="bd53" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(49:35): <br/>我想把一位哲学家放在有这样一个系统的房间里一天，如果这位哲学家后来说，“嗯，我一整天都在进行有趣的对话”，那就是说，好吧，很明显，这个系统做得很好。需要明确的是，[听不清00:49:52]现在的语言模型根本不具备这种能力。从表面上看，这段文字[听不清00:49:58]如果你仔细观察细节，你会发现它非常容易被发现。什么是[听不见的00:50:04]</p><p id="034c" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(50:05): <br/>这看起来像是象征性的推理，那么，对你来说，这真的是圣杯吗？如果它能做符号逻辑，那么我们就有了真正有意义的东西？</p><p id="85ea" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">提摩太书(50:13): <br/>是的。正如我之前提到的，我想，一个人必须小心谨慎。符号推理与符号解算器和符号人工智能系统配合得非常好，对吗？所以这还不够。同时，它还必须证明这种概括和样本有效学习和分布概括</p><p id="7cf8" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">提后书(50:35): <br/>所以两者都在一起。你必须设计，基本上测试这是不是你想要做的，对吗？您必须设计一个测试来测试这两种能力。如果你测试符号化的AI系统可以泛化到什么程度，比方说在飓风中间检测特定的交通标志，它会完全失败，对吗？但有些也可能是[听不清00:50:54]人工的，或人工神经网络。我会说，你必须基本上测试这两种能力。</p><p id="5bc3" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(51:02): <br/>如果这两种能力都存在，那么对于一个有这两种能力的代理人，你会说我们的道德责任是什么？你真的认为这是道德上可识别的行为吗？只为你个人。我肯定这不是你做过研究的事情，但是…</p><p id="a802" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(51:22): <br/>是啊。我想说，我对这类问题最接近的体验是在电影《她》中，我很确定你知道这部电影。</p><p id="010b" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(51:34): <br/>我实际上没有看过那部电影，但是抱歉，请继续。是啊。</p><p id="627c" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">提后书(51:38): <br/>当然可以。在某种程度上，如果人工智能按照自己设定的意图行事，并表现出同理心和所有这些事情，对，人工和非人工之间的界限变得非常模糊，有很多科幻电影以此为核心主题。在这一点上，对我个人来说，我会发现关闭这样一个系统是非常困难的，对吗？在这一点上，你想的更多的是杀死有个性的东西，但对我来说，至少现在和在可预见的未来，这是我能说的科幻小说，对吗？看看我们最近在人工智能方面的突破，并试图推断，至少我很难在我的有生之年看到这成为现实。</p><p id="88bf" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(52:35): <br/>哦，有意思。甚至在你有生之年。所以你在这件事上有很长的时间跨度。</p><p id="02d4" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(52:41): <br/>是啊。是的，我会这么说。我认为我们可能会看到另一个人工智能的冬天，我们也会超越它，但我不认为我们会有与人类智能无法区分的东西，在不久的将来，我们会有所有这些同理心，零射击概括和符号推理的结合。是的，我认为我们谈论的是超过几十年的时间。</p><p id="2624" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(53:13): <br/>迷人。好的，非常酷。非常感谢。我真的很感激你在谈话的最后，也放纵了一些更哲学的一面。那么，蒂姆，如果人们想关注你的工作，有没有什么地方可以让他们在社交媒体上关注你？</p><p id="b1e3" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(53:26): <br/>哦，是的，我在推特上。去找蒂姆·罗彻尔。显然，你可以看看我的个人网页上的出版物。</p><p id="6826" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">耶雷米(53:38): <br/>甜。是的，我们肯定会链接到下面的所有内容。Tim在我们讨论的所有主题上做了大量的工作，所以请务必查看一下，尤其是如果你对RL、深度学习以及我们今天在这里讨论的任何内容感兴趣的话。蒂姆，非常感谢你加入我们的播客。</p><p id="7155" class="pw-post-body-paragraph ld le is lf b lg lh kc li lj lk kf ll lm ln lo lp lq lr ls lt lu lv lw lx ly il bi translated">蒂姆(53:51): <br/>好的，非常感谢您的谈话。</p></div></div>    
</body>
</html>