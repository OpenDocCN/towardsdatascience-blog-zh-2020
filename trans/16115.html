<html>
<head>
<title>Tackling Gender Bias in Word Embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解决词语嵌入中的性别偏见</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tackling-gender-bias-in-word-embeddings-c965f4076a10?source=collection_archive---------14-----------------------#2020-11-06">https://towardsdatascience.com/tackling-gender-bias-in-word-embeddings-c965f4076a10?source=collection_archive---------14-----------------------#2020-11-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="804d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一篇试图减轻单词嵌入中的性别偏见的技术论文的摘要</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c069e2fd6c197c64c26395abb7661306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BpYc-xGjof3-jgre"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@dainisgraveris?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Dainis Graveris </a>拍摄</p></figure><p id="332e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated">ord嵌入是自然语言处理的基础。但是他们没有固有的偏见吗？想象一下，谷歌搜索“<em class="mb">酷酷的程序员t恤</em>”，谷歌只回复男性t恤。随着已经显示出性别偏见迹象的BERT被纳入谷歌搜索，人们不需要想象。随着我们不断看到这些系统在日常生活中的使用越来越多，保持定义人工智能的“智能”本质上无偏见是必不可少的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/70812ece0278c72e6fd2db2e59e65e1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*bWjPyPOuTElfcwY4y6vNsw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">这可能是单词嵌入最广为人知的成就。(来源—此处)。</p></figure><p id="4998" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当Word2Vec首次公布其成果时，这种关系也让计算机科学界产生了怀疑。单词的向量表示的概念是NLP的主要支柱之一。然而，正是这些词的嵌入甚至可以吸收人类世界的偏见。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi md"><img src="../Images/9f819bf1d5f4540d3ecfa68816e30b8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NHmzotQcEagWnJS7NM0IVA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">事实上——当我在谷歌新闻向量上尝试时，我得到了惊人的结果。(来源——自己)</p></figure><p id="0aaa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(In)上述著名结果真正指出了问题的隐含本质<em class="mb">。事实上，这些庞大的模型是基于人类文学的语料库来训练的，这些语料库是有偏见的。</em></p><p id="8012" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="mb">博鲁克巴斯等人</em>。男人对于电脑程序员就像女人对于家庭主妇一样？消除单词嵌入的偏见 ”进一步阐明了对这种性别偏见的一些分析，以及我们如何努力克服它。幸运的是，这些模型包含了足够的信息，甚至可以在一定程度上减轻这种偏差。</p><h1 id="667c" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">问题是</h1><p id="a334" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">本质上，模型被训练的语料库有一些性别中性的词，如“<em class="mb">垒球</em>”、“<em class="mb">接待员</em>”和“<em class="mb">程序员</em>”。还有一些性别专有的术语，如“<em class="mb">女商人</em>”、“<em class="mb">父亲</em>”和“<em class="mb">母亲</em>”。据观察，性别中立的术语获得刻板印象和偏见，由于他们在语料库中出现的语境。</p><blockquote class="nb nc nd"><p id="c9f8" class="kw kx mb ky b kz la jr lb lc ld ju le ne lg lh li nf lk ll lm ng lo lp lq lr ij bi translated">例如，假设对于卡内基梅隆大学的计算机科学博士生，搜索查询是“cmu计算机科学博士生”。现在，该目录为学生提供了127个几乎相同的网页——这些网页只是学生的名字不同...然而，单词嵌入也将与计算机科学相关的术语排序为更接近男性名字而不是女性名字…结果是，在两个仅名字Mary和John不同的页面之间，单词嵌入将影响搜索引擎将John的网页排序高于Mary。</p></blockquote><p id="d9b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目标是“去偏向”这些性别中立的向量，同时保留嵌入中相同的语义关系。</p><h2 id="4836" class="nh mf iq bd mg ni nj dn mk nk nl dp mo lf nm nn mq lj no np ms ln nq nr mu ns bi translated">直接和间接偏见</h2><p id="d0b1" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">偏见本身有两种类型，直接和间接。</p><p id="aed4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">直接偏见</strong>可以分为“<em class="mb">足球</em>”天生更接近男性“<em class="mb">接待员</em>”更接近女性。<strong class="ky ir">间接偏见</strong>源于语料库中的细微关联，导致“<em class="mb">簿记员</em>”更接近于“<em class="mb">垒球</em>”而不是“<em class="mb">足球</em>”，因为它们的女性联想更大。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/a30abf30890c0592301cfd982a771ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_I4xVncNr3ehYkJQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在“他-她”空间上表示的向量。X轴上方的是中性术语，X轴下方的是特定性别术语。(资料来源——报纸)</p></figure><p id="69ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如上所示，性别中立术语应该与<em class="mb">他-她</em>对等距，而性别特定术语应该继续传达其中嵌入的性别信息。</p><h1 id="ee2d" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">方法</h1><h2 id="8401" class="nh mf iq bd mg ni nj dn mk nk nl dp mo lf nm nn mq lj no np ms ln nq nr mu ns bi translated">性别子空间的识别</h2><p id="a0d6" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">首先捕获这个性别嵌入的<em class="mb">子空间</em>。这是通过取定义性别概念本身的一些预先知道的集合的差来完成的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/3a25103e141b41dec257a23b1f9a7ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*IwEbAHLZQxgILwdawLKVpA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">等式对的子集用于确定性别子空间。(资料来源——报纸)</p></figure><p id="5825" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对这种相反性别对的子集执行SVD，以最终获得这种偏差的方向或子空间。这种平滑是为了消除一些术语不同含义的影响，如“<em class="mb"> man </em>”。</p><h2 id="db3a" class="nh mf iq bd mg ni nj dn mk nk nl dp mo lf nm nn mq lj no np ms ln nq nr mu ns bi translated"><strong class="ak">硬去偏置:中和并均衡</strong></h2><p id="6794" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">位于该子空间中的向量(性别中立项)被“中和”，使得它们与类似“<em class="mb">他-她</em>”的等式对保持等距。从技术上讲，所发生的是从向量中减去嵌入在偏移方向上的投影。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/9fda3ce170b7bd7601ad6e294913613f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UQrsnmhe8CuVRs8RXVmx7g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">左侧—中和前，右侧—中和后。(来源——自己)</p></figure><p id="2503" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个方向之外的嵌入(性别特定的术语)被“均衡”，或者平均为具有相同的向量长度。这样做是为了确保中性项与所有等式对等距。例如，术语<em class="mb">医生</em>应该与<em class="mb">男女孩</em>和<em class="mb">男女人</em>等距。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/117fc2974fddfac43931a6abfa660031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*Ku7NMAlriC73o0Moh9D9wg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">左侧—均衡前，右侧—均衡后。(来源——自己)</p></figure><h2 id="46b8" class="nh mf iq bd mg ni nj dn mk nk nl dp mo lf nm nn mq lj no np ms ln nq nr mu ns bi translated"><strong class="ak">软去偏置</strong></h2><p id="736d" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">有时性别专用术语可能包含更多需要捕捉的含义，例如:<em class="mb">到祖父法规</em>。在这种情况下，我们可能只想基于一个参数“软化”性别偏见对嵌入的影响，比如说<strong class="ky ir"> λ </strong>。</p><p id="1eb4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，我们不完全中和嵌入，而是仅在<strong class="ky ir"> λ </strong>的范围内这样做。如果<strong class="ky ir"> λ </strong> = 0，那么本质上与硬去偏相同。</p><h1 id="5439" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">结果和结论</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/a0f03887569253da2e52b22c4ed3ac9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yj1hv2TxOBaTGLZcKo34-Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用不同(无)偏向嵌入、左定型类比和右适当类比生成的类比数量。(资料来源——报纸)</p></figure><p id="c15e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面显示的结果与任务的目标相一致，成功地从嵌入中消除了偏差，而不影响性能。对于所描述的问题，还有其他方法，比如清理语料库本身。</p><p id="0306" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从本质上说，去除单词嵌入的偏见有助于满足对无偏见世界不断增长的需求。至少，机器学习不应该被用来无意中放大这些偏见，因为我们已经看到这种情况会自然发生。</p><p id="5a20" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用论文作者在GitHub 上发布的<a class="ae kv" href="https://github.com/tolga-b/debiaswe" rel="noopener ugc nofollow" target="_blank">代码，我对我之前使用的Google新闻向量进行了硬去偏置，并获得了以下结果。</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/ea9b5ef3dd995866eaf237405b312a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U_dp9cKU0ASN9DfZZJLgkg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">检验去偏见模型——性别偏见明显减轻。(来源——自己)</p></figure><p id="669a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们看到这种方法是如何利用中和与均衡来减少明显的偏差的。</p><p id="e215" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有些人认为嵌入中的性别偏见捕获了有用的统计数据。然而，机器学习算法有很大的可能性放大性别刻板印象和歧视，最好在无偏见的系统上运行。</p><p id="4c91" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于性别只是单词嵌入所表现出的偏见之一，种族或民族偏见的识别也会随之而来，这是迈向真正的<strong class="ky ir">#伦理</strong>的一大步</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="ee3d" class="me mf iq bd mg mh og mj mk ml oh mn mo jw oi jx mq jz oj ka ms kc ok kd mu mv bi translated">参考</h1><p id="9d4b" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">T .博卢克巴斯，K .常，J .邹，V .萨利格拉玛和A .卡莱。男人对于电脑程序员就像女人对于家庭主妇一样？去偏置词嵌入。T19】2016T21。 </p></div></div>    
</body>
</html>