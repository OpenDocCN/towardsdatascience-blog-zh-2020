<html>
<head>
<title>Introduction to Text Classification with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python文本分类简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-text-classification-with-python-c9db137b9d80?source=collection_archive---------24-----------------------#2020-10-18">https://towardsdatascience.com/introduction-to-text-classification-with-python-c9db137b9d80?source=collection_archive---------24-----------------------#2020-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/9c80c85143d2d1cac754d440e4a555ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mHzCWTK2VLCjwbn1LrHfYQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@alfonsmc10?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">阿尔方斯·莫拉莱斯</a>在<a class="ae jg" href="https://unsplash.com/s/photos/bookshelf?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><div class=""/><div class=""><h2 id="3156" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">基于朴素贝叶斯模型的文本分类。</h2></div><p id="e6e0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated">在过去的几年里，在线学习的影响力越来越大。使用它已经有很多应用，从市场营销、生物信息学、城市规划等等。机器学习是一种从数据中学习表示的方法，因此我们可以使用它来提取知识或基于它预测标签。这种方法的应用之一是文本分类。</p><p id="5ef6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">文本分类是我们将文本分类到它们所属的类别的任务。在机器学习成为一种趋势之前，这项工作大多由几个标注者手工完成。这在未来会成为一个问题，因为数据变得越来越大，光是做这件事就要花很多时间。因此，我们应该使任务自动化，同时也获得更高的准确性。</p><p id="00c1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我将向您展示如何使用Python进行文本分类。对于数据集，我们将使用一个名为真实与否的Kaggle竞赛的数据集。灾难推文的NLP。我还在Google Colab上做了这个笔记本，你可以在这里<a class="ae jg" href="https://colab.research.google.com/drive/1nIJDAhMHeBrOtkyicQW1Z7Iykb2kB6mA?usp=sharing" rel="noopener ugc nofollow" target="_blank">找到它</a>。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="18c9" class="mk ml jj bd mm mn mo mp mq mr ms mt mu kp mv kq mw ks mx kt my kv mz kw na nb bi translated">概述</h1><p id="1d3d" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">本文将分为几个部分:</p><ul class=""><li id="1808" class="nh ni jj la b lb lc le lf lh nj ll nk lp nl lt nm nn no np bi translated"><strong class="la jk">清洗正文</strong></li><li id="c448" class="nh ni jj la b lb nq le nr lh ns ll nt lp nu lt nm nn no np bi translated"><strong class="la jk">用TF-IDF权重建立文档术语矩阵</strong></li><li id="fbb3" class="nh ni jj la b lb nq le nr lh ns ll nt lp nu lt nm nn no np bi translated"><strong class="la jk">朴素贝叶斯的概念</strong></li><li id="6732" class="nh ni jj la b lb nq le nr lh ns ll nt lp nu lt nm nn no np bi translated"><strong class="la jk">使用Python实现</strong></li></ul></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="c0af" class="mk ml jj bd mm mn mo mp mq mr ms mt mu kp mv kq mw ks mx kt my kv mz kw na nb bi translated">该过程</h1><h2 id="1665" class="nv ml jj bd mm nw nx dn mq ny nz dp mu lh oa ob mw ll oc od my lp oe of na og bi translated">清理文本</h2><p id="bfb1" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">我们要做的第一步是准备和清理数据集。清理数据集是删除任何无意义的单词或无用的术语(如标签、提及、标点等等)的必要步骤。</p><p id="5deb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了清理文本，我们可以利用re之类的库来删除带有模式的术语，利用NLTK来删除单词，例如停用词。我还解释了如何使用Python一步一步地清理文本，您可以在这里看到，</p><div class="is it gp gr iu oh"><a rel="noopener follow" target="_blank" href="/cleaning-text-data-with-python-b69b47b97b76"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jk gy z fp om fr fs on fu fw ji bi translated">使用Python清理文本数据</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">你需要的只是NLTK和re库。</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov ja oh"/></div></div></a></div><p id="ce96" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是一些文本在预处理前的样子，</p><pre class="ow ox oy oz gt pa pb pc pd aw pe bi"><span id="31bd" class="nv ml jj pb b gy pf pg l ph pi"><strong class="pb jk">Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</strong></span><span id="51f6" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">Forest fire near La Ronge Sask. Canada</strong></span><span id="82af" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</strong></span><span id="dcf4" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">13,000 people receive #wildfires evacuation orders in California </strong></span><span id="4217" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school </strong></span><span id="7641" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">#RockyFire Update =&gt; California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires</strong></span><span id="e309" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas</strong></span><span id="0bee" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">I'm on top of the hill and I can see a fire in the woods...</strong></span><span id="c81d" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">There's an emergency evacuation happening now in the building across the street</strong></span><span id="f65e" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">I'm afraid that the tornado is coming to our area...</strong></span></pre><p id="c014" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">执行该任务的代码如下所示，</p><pre class="ow ox oy oz gt pa pb pc pd aw pe bi"><span id="64ce" class="nv ml jj pb b gy pf pg l ph pi"><strong class="pb jk"># # In case of import errors<br/># ! pip install nltk<br/># ! pip install textblob</strong></span><span id="0ab2" class="nv ml jj pb b gy pj pg l ph pi">import re<br/>from textblob import TextBlob<br/>import nltk<br/>from nltk.stem import WordNetLemmatizer<br/>from nltk.corpus import stopwords</span><span id="0cb8" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk"># # In case of any corpus are missing <br/># download all-nltk</strong><br/>nltk.download()</span><span id="c5b4" class="nv ml jj pb b gy pj pg l ph pi">df = pd.read_csv('train.csv')<br/>test = pd.read_csv('test.csv')</span><span id="cf5d" class="nv ml jj pb b gy pj pg l ph pi">stop_words = stopwords.words("english")</span><span id="b8b8" class="nv ml jj pb b gy pj pg l ph pi">def text_preproc(x):<br/>  x = x.lower()<br/>  # x = ' '.join(wordnet.lemmatize(word, 'v') for word in x.split())<br/>  x = ' '.join([word for word in x.split(' ') if word not in stop_words])<br/>  x = x.encode('ascii', 'ignore').decode()<br/>  x = re.sub(r'https*\S+', ' ', x)<br/>  x = re.sub(r'@\S+', ' ', x)<br/>  x = re.sub(r'#\S+', ' ', x)<br/>  x = re.sub(r'\'\w+', '', x)<br/>  x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)<br/>  x = re.sub(r'\w*\d+\w*', '', x)<br/>  x = re.sub(r'\s{2,}', ' ', x)<br/>  return x</span><span id="d11e" class="nv ml jj pb b gy pj pg l ph pi">df['clean_text'] = df.text.apply(text_preproc)<br/>test['clean_text'] = test.text.apply(text_preproc)</span></pre><p id="9213" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是清洁步骤后的结果，</p><pre class="ow ox oy oz gt pa pb pc pd aw pe bi"><span id="fefd" class="nv ml jj pb b gy pf pg l ph pi"><strong class="pb jk">deeds reason may allah forgive us</strong></span><span id="631a" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">forest fire near la ronge sask canada</strong></span><span id="56a7" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">residents asked place notified officers evacuation shelter place orders expected</strong></span><span id="4e1b" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">people receive evacuation orders california</strong></span><span id="5775" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">got sent photo ruby smoke pours school</strong></span><span id="08e6" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">update california hwy closed directions due lake county fire</strong></span><span id="271e" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">heavy rain causes flash flooding streets manitou colorado springs areas</strong></span><span id="7b90" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">i top hill see fire woods</strong></span><span id="5a27" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">there emergency evacuation happening building across street</strong></span><span id="63c9" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">i afraid tornado coming area</strong></span></pre><blockquote class="pk pl pm"><p id="e9f5" class="ky kz pn la b lb lc kk ld le lf kn lg po li lj lk pp lm ln lo pq lq lr ls lt im bi translated">还有，记笔记！确保从NLTK下载所有的包和语料库(基本上是单词的集合)。</p></blockquote><h2 id="e5a0" class="nv ml jj bd mm nw nx dn mq ny nz dp mu lh oa ob mw ll oc od my lp oe of na og bi translated">使用TF-IDF权重构建术语-文档矩阵</h2><p id="519f" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">在我们清理完数据之后，现在我们可以构建一个文本表示，这样计算机就可以轻松地读取数据。我们将使用术语-文档矩阵作为文本的表示。</p><p id="5de6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">术语-文档矩阵(TDM) </strong>是一个矩阵，其中行代表每个文档，列代表每个术语(词)，单元格用数字填充。</p><p id="5cef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">单元格由每个文档的字数组成。我们可以用来填充它的一种方法叫做词频——逆文档频(TF-IDF)。</p><p id="8cc8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">词频—逆文档频率(TF-IDF) </strong>是一个文档上的一个词的频率(词频)和一个词在所有文档上的逆频率(逆文档频率)的乘积。</p><p id="2f8e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">词频(TF) </strong>是计算文档中一个词的数量的公式。因为单词之间的数量不同，我们应用以10为底的对数来重新调整它。它看起来像这样，</p><figure class="ow ox oy oz gt iv gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/503bc5b1527f5ad267af1a33a9bb00fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*c8cUOl5st_tL98t0.png"/></div></figure><p id="47a4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">逆文档频率(IDF) </strong>是一个计算所有文档上单词稀有度的公式。如果数量很少，这个词就很常用。但如果大一点，这个词就不那么频繁了。这个公式将被用作TF的权重，它看起来像这样，</p><figure class="ow ox oy oz gt iv gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/345543ec40f73142a920094ea63c2628.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/0*PUU7Z5liC5ifRz3y.png"/></div></figure><p id="e02a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要创建术语-文档矩阵(TDM ),我们可以使用sklearn库中名为TfidfVectorizer的函数。代码看起来会像这样，</p><pre class="ow ox oy oz gt pa pb pc pd aw pe bi"><span id="8627" class="nv ml jj pb b gy pf pg l ph pi"><strong class="pb jk">vectorizer = TfidfVectorizer()</strong></span><span id="cbc1" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">X = vectorizer.fit_transform(df['clean_text']).toarray()<br/>df_new = pd.DataFrame(X, columns=vectorizer.get_feature_names())</strong></span><span id="782f" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk">X_test = vectorizer.transform(test['clean_text']).toarray()<br/>test_new = pd.DataFrame(X_test, columns=vectorizer.get_feature_names())</strong></span></pre><p id="d9db" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当您编写代码时，您必须非常小心对每个数据集使用哪个函数。对于训练数据，请确保使用fit_transform方法，因为它将根据训练数据中的项数进行拟合，并将其转换为矩阵。</p><p id="30a4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同时，在测试数据上，确保您使用了transform方法，因为它会将文本转换为具有相同数量的训练数据列的矩阵。如果我们也对其使用fit_transform，它将根据测试数据的项数创建一个矩阵。因此，它在列上不会有相同的维度，所以请确保检查您将使用的方法。</p><p id="7ce8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们做对了，它会给出具有相同列维数的矩阵，以及一个类似这样的矩阵，</p><figure class="ow ox oy oz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pt"><img src="../Images/a0d5df8f7214edbbfb51c94879165f35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I8-W0hYl3DiE63Bjzl0uKw.png"/></div></div></figure><h2 id="5e1c" class="nv ml jj bd mm nw nx dn mq ny nz dp mu lh oa ob mw ll oc od my lp oe of na og bi translated">朴素贝叶斯的概念</h2><p id="9d2b" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">有了矩阵后，现在我们可以将它应用到模型中。我们将使用的模型是朴素贝叶斯。</p><p id="6b6c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">朴素贝叶斯是一种机器学习模型，通过计算数据属于某个类的概率来解决监督学习任务。</p><p id="f8d3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它基于贝叶斯原理，并假设文档中的每个术语都是相互独立的。计算这个的公式是这样的，</p><figure class="ow ox oy oz gt iv gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/88bb57046652e2b87cd1c2fafa3b6076.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*drnQ-o9DutPyS2C3HWxUZQ.png"/></div></figure><p id="70df" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我解释一下它的每一部分，</p><ul class=""><li id="9390" class="nh ni jj la b lb lc le lf lh nj ll nk lp nl lt nm nn no np bi translated">P(c|d)代表文档属于一个类别的概率，</li><li id="6ce6" class="nh ni jj la b lb nq le nr lh ns ll nt lp nu lt nm nn no np bi translated">阿尔法符号对应于两边的比例，</li><li id="8158" class="nh ni jj la b lb nq le nr lh ns ll nt lp nu lt nm nn no np bi translated">P(c)是通过计算一个类别的数量与文档总数的比例而得到的该类别的先验概率。公式看起来像这样，</li></ul><figure class="ow ox oy oz gt iv gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/98ca31f181ad575a9ffd0c98c0765cbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*AbvWkyOdpv05pfcHskJluQ.png"/></div></figure><p id="e2d1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中Nc是数据集中相应类的数量，N是数据集中文档的数量。</p><ul class=""><li id="6f6a" class="nh ni jj la b lb lc le lf lh nj ll nk lp nl lt nm nn no np bi translated">P(t id | c)的乘积是文档(d)中属于类别(c)的每一项的概率结果的乘积。公式看起来像这样，</li></ul><figure class="ow ox oy oz gt iv gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/eb3dd5d2785d0952a4ed91ca75e16b4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*qF8Gp9Zw3-jxNzmlYTrhRw.png"/></div></figure><p id="5aed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中，T ct对应于类别内的该项的数量，T CT’的总和对应于给定类别的项的总数，B代表训练数据集上不同词汇的数量，1代表模型的平滑以避免零。</p><p id="affb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">P(t id | c)公式会根据我们对问题的表述而不同。前一个问题把它表述为一个多项式问题，我们计算一个类中有多少确切的项。我们有时称这个模型为<strong class="la jk">多项式朴素贝叶斯</strong>。</p><p id="1a3b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有一个模型叫做<strong class="la jk">伯努利朴素贝叶斯</strong>，这里P(t id | c)的计算是不同的。它将计算包含该术语的文档数量占所有文档总数的比例。公式看起来像这样，</p><figure class="ow ox oy oz gt iv gh gi paragraph-image"><div class="gh gi px"><img src="../Images/c841ce41532996176036b30b4dd7c2cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:392/format:webp/1*rMJzjELwWWBV4lM1BfGELg.png"/></div></figure><p id="d280" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中Nct对应于包含该类别的术语的文档总数，Nc对应于该类别的文档总数。</p><p id="e6cc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们计算每个概率后，我们将选择概率最高的最佳类。</p><figure class="ow ox oy oz gt iv gh gi paragraph-image"><div class="gh gi py"><img src="../Images/b2930fbcdea1c7e86ae8536b9fcd3476.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*niIXzsHwEmjl3_iYj6sVSg.png"/></div></figure><h2 id="0b97" class="nv ml jj bd mm nw nx dn mq ny nz dp mu lh oa ob mw ll oc od my lp oe of na og bi translated">使用Python的实现</h2><p id="db05" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">在我向您解释了这些概念之后，让我们继续讨论实现。对于这一步，我将使用scikit-learn库来完成。</p><p id="e440" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们建立模型时，要知道的重要方面是模型是否给出了很好的结果，尤其是在看不见的数据上，所以我们有信心使用它。我们可以通过一个叫做交叉验证的概念来做到这一点。代码看起来像这样，</p><pre class="ow ox oy oz gt pa pb pc pd aw pe bi"><span id="f677" class="nv ml jj pb b gy pf pg l ph pi">from sklearn.naive_bayes import MultinomialNB, BernoulliNB<br/>from sklearn.model_selection import KFold<br/>from sklearn.metrics import f1_score</span><span id="5045" class="nv ml jj pb b gy pj pg l ph pi">X = df_new.values<br/>y = df.target.values</span><span id="0b98" class="nv ml jj pb b gy pj pg l ph pi">kfold = KFold(n_splits=10)</span><span id="6ef4" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk"># Define the model</strong><br/>nb_multinomial = MultinomialNB()<br/>nb_bernoulli = BernoulliNB()</span><span id="1e53" class="nv ml jj pb b gy pj pg l ph pi"><strong class="pb jk"># As a storage of the model's performance</strong><br/>def calculate_f1(model):<br/> metrics = []<br/> <br/> for train_idx, test_idx in kfold.split(X):<br/>   X_train, X_test = X[train_idx], X[test_idx]<br/>   y_train, y_test = y[train_idx], y[test_idx]<br/>   model.fit(X_train, y_train)<br/>   y_pred = model.predict(X_test)<br/>   metrics.append(f1_score(y_test, y_pred))<br/> <br/> <strong class="pb jk"># Retrieve the mean of the result</strong><br/> print("%.3f" % np.array(metrics).mean())</span><span id="7be6" class="nv ml jj pb b gy pj pg l ph pi"><br/>calculate_f1(nb_multinomial)<br/>&gt;&gt;&gt; 0.681</span><span id="5909" class="nv ml jj pb b gy pj pg l ph pi">calculate_f1(nb_bernoulli)<br/>&gt;&gt;&gt; 0.704</span></pre><p id="2f71" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">calculate_f1函数是怎么回事？</p><ul class=""><li id="cbac" class="nh ni jj la b lb lc le lf lh nj ll nk lp nl lt nm nn no np bi translated">首先，它将模型作为输入。</li><li id="d5ff" class="nh ni jj la b lb nq le nr lh ns ll nt lp nu lt nm nn no np bi translated">然后，它将在k次中进行交叉验证，在每次循环中，它将数据集分为训练和测试数据集，然后模型拟合训练数据并预测测试数据上的标签。</li><li id="13eb" class="nh ni jj la b lb nq le nr lh ns ll nt lp nu lt nm nn no np bi translated">最后，我们计算每个交叉验证分数的平均值。</li></ul><p id="8d19" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在此基础上，我们得出了伯努利朴素贝叶斯模型的得分(0.704)优于多项式朴素贝叶斯模型的得分(0.681)。</p><p id="4358" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们将使用伯努利朴素贝叶斯作为我们的模型来预测真实的测试集数据。代码看起来像这样，</p><pre class="ow ox oy oz gt pa pb pc pd aw pe bi"><span id="bc3c" class="nv ml jj pb b gy pf pg l ph pi">from sklearn.naive_bayes import BernoulliNB</span><span id="ae20" class="nv ml jj pb b gy pj pg l ph pi">def predict_to_csv(model, X, y):<br/>  model.fit(X, y)<br/>  X_test = test_new.values<br/>  y_pred = model.predict(X_test)</span><span id="338b" class="nv ml jj pb b gy pj pg l ph pi">  <strong class="pb jk"># Preparing submission</strong><br/>  submission = pd.DataFrame()<br/>  submission['id'] = test['id']<br/>  submission['target'] = y_pred<br/>  submission.to_csv('file_name.csv', index=False)</span><span id="6135" class="nv ml jj pb b gy pj pg l ph pi">  <strong class="pb jk"># Validate</strong><br/>  submission = pd.read_csv('file_name.csv')<br/>  print(submission.head())</span><span id="5c06" class="nv ml jj pb b gy pj pg l ph pi"><br/>nb_bernoulli = BernoulliNB()<br/>X = df_new.values<br/>y = df.target.values</span><span id="c700" class="nv ml jj pb b gy pj pg l ph pi">predict_to_csv(nb_bernoulli, X, y)<br/>&gt;&gt;&gt; id  target<br/>0   0        1<br/>1   2        0<br/>2   3        1<br/>3   9        0<br/>4  11        1</span></pre><p id="982c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们在上面看到的，我们用真实的训练数据拟合模型，并预测测试数据的标签。之后，我们创建一个数据框并将结果保存为CSV格式。最后你可以把那个提交给Kaggle，你就知道结果好不好了。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="2252" class="mk ml jj bd mm mn mo mp mq mr ms mt mu kp mv kq mw ks mx kt my kv mz kw na nb bi translated">最后的想法和建议</h1><p id="7b7e" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">我想给你一些建议。对于这项任务，朴素贝叶斯是一个很好的机器学习模型，但还有很多空间来改进结果。您可以使用任何其他模型，如支持向量机、决策树、递归神经网络等等。</p><p id="3779" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，您可以执行一些特征工程来移除数据上的无意义信息，或者您可以调整模型上的超参数。</p><p id="8c5c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">终于，我们到了这篇文章的结尾。希望你从中有所收获，有想法可以在下面评论下来。此外，如果你对我的帖子感兴趣，你可以关注我的媒体来了解我的下一篇文章。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h2 id="587a" class="nv ml jj bd mm nw nx dn mq ny nz dp mu lh oa ob mw ll oc od my lp oe of na og bi translated">参考</h2><p id="8db7" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">[1] Pedregosa等人，2011年。sci kit-learn:Python中的机器学习，<em class="pn"> JMLR 12，第2825–2830页</em>。<br/> [2]曼宁等，2011。信息检索导论。<em class="pn">剑桥大学出版社</em>，<em class="pn">第234–265页。</em><br/>【3】麦卡勒姆a .和尼甘K. 1998。朴素贝叶斯文本分类的事件模型比较。<em class="pn"> Proc。AAAI/ICML-98文本分类学习研讨会，第41-48页。</em><br/>【4】哈立德，I. A. 2020。使用Python创建简单的搜索引擎。<em class="pn">走向数据科学。</em><a class="ae jg" rel="noopener" target="_blank" href="/create-a-simple-search-engine-using-python-412587619ff5">https://towardsdatascience . com/create-a-simple-search-engine-using-python-412587619 ff 5</a><br/><a class="ae jg" href="https://www.kaggle.com/c/nlp-getting-started" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/nlp-getting-started</a><br/>【6】<a class="ae jg" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Naive_Bayes_classifier</a></p></div></div>    
</body>
</html>