<html>
<head>
<title>Training with Controlled Randomness</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可控随机性训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6?source=collection_archive---------37-----------------------#2020-11-09">https://towardsdatascience.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6?source=collection_archive---------37-----------------------#2020-11-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="ec79" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/petsafe-plants-fastai" rel="noopener" target="_blank">用fast.ai对宠物安全植物进行分类</a></h2><div class=""/><div class=""><h2 id="8c18" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">创建和比较fast.ai学习者</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/a24f730e6a2a43203596469de17f963a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OF2zR2ZqZs35G6hDW_IXuA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@mancity17" rel="noopener ugc nofollow" target="_blank">大卫·克拉克</a>上<a class="ae le" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank">下</a></p></figure><p id="5689" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在<a class="ae le" href="https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-a29587f3f04c" rel="noopener">第一部分:建立一个数据库</a>中，我们已经在网上搜集了关于植物及其对宠物毒性的信息，对照第二个数据库交叉引用了这些字段，然后最终通过Google Images下载了每个类别的独特图像。在这一部分，我们将训练基线神经网络(使用新的fast.ai框架)，以根据图片识别植物的种类。然后，我们将评估我们收集的数据集对于训练神经网络有多好，并寻找改进的方法。</p><blockquote class="mb mc md"><p id="a04f" class="lf lg me lh b li lj ka lk ll lm kd ln mf lp lq lr mg lt lu lv mh lx ly lz ma ij bi translated"><strong class="lh ja">这里的主要目标是比较改变每类图像数量的影响，以及我们如何通过控制随机性来公平地比较每次训练。</strong></p></blockquote><p id="5d99" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我发现fast.ai是一个非常有用的框架(位于PyTorch库之上),可以直接用于机器学习。杰瑞米·霍华德(fast.ai的创始研究员)用了一个类比，类似于学习如何踢足球——我们是想研究如何踢球的精确物理和力学，还是融入其中，边踢边学？后者更吸引人，由于网上有大量的可用资源，我们可以在学习的过程中获得重要的理论知识。其中一个例子是fast.ai自己的<a class="ae le" href="https://github.com/fastai/fastbook" rel="noopener ugc nofollow" target="_blank">书</a>，它很好地概述了这个过程，并包含了一个关于<a class="ae le" href="https://github.com/fastai/fastbook/blob/master/03_ethics.ipynb" rel="noopener ugc nofollow" target="_blank">数据伦理</a>的特别有趣的章节。</p><h1 id="ea98" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">目录</h1><ol class=""><li id="4b67" class="na nb iq lh b li nc ll nd lo ne ls nf lw ng ma nh ni nj nk bi translated"><a class="ae le" href="https://medium.com/p/13b8ba6289e6#a60d" rel="noopener">一个训练基线</a> <br/> 1.1 - <a class="ae le" href="https://medium.com/p/13b8ba6289e6#b088" rel="noopener">导入和播种随机性</a> <br/> 1.2 - <a class="ae le" href="https://medium.com/p/13b8ba6289e6#5e92" rel="noopener">将数据加载到Colabs </a> <br/> 1.3 - <a class="ae le" href="https://medium.com/p/13b8ba6289e6#043b" rel="noopener">数据块和数据加载器</a> <br/> 1.4 - <a class="ae le" href="https://medium.com/p/13b8ba6289e6#e4a2" rel="noopener">分层拆分</a> <br/> 1.5 - <a class="ae le" href="https://medium.com/p/13b8ba6289e6#736d" rel="noopener">创建数据块和数据加载器</a> <br/> 1.6 - <a class="ae le" href="https://medium.com/p/13b8ba6289e6#d872" rel="noopener">创建学习器</a></li><li id="ca82" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><a class="ae le" href="https://medium.com/p/13b8ba6289e6#826a" rel="noopener">训练模型</a> <br/> 2.1 - <a class="ae le" href="https://medium.com/p/13b8ba6289e6#0a40" rel="noopener">我们如何选择学习率？</a> <br/> 2.2 - <a class="ae le" href="https://medium.com/p/13b8ba6289e6#3c2d" rel="noopener">示例训练运行</a></li><li id="12d4" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><a class="ae le" href="https://medium.com/p/13b8ba6289e6#6feb" rel="noopener">训练模型</a> <br/> 3.1 - <a class="ae le" href="https://medium.com/p/13b8ba6289e6#1539" rel="noopener">为什么图像越多越好？</a></li></ol><h1 id="a60d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">1.训练基线</h1><h2 id="b088" class="nq mj iq bd mk nr ns dn mo nt nu dp ms lo nv nw mu ls nx ny mw lw nz oa my iw bi translated">1.1 -导入和植入随机性</h2><p id="c4cd" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">fast.ai正在<a class="ae le" href="https://pypi.org/project/fastai/#history" rel="noopener ugc nofollow" target="_blank">快速更新</a>，这需要安装特定的包版本以实现可再现性。为了便于使用，我们将简单地把我们需要的所有东西(以及我们以后需要的东西)导入到全局名称空间中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="4e86" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了比较训练运行，我们需要控制系统中存在的随机性来源(扩充、分裂等。)虽然有很多关于这个主题的<a class="ae le" href="https://forums.fast.ai/t/solved-reproducibility-where-is-the-randomness-coming-in/31628/23" rel="noopener ugc nofollow" target="_blank">讨论</a>，但我发现，对于Colabs来说，在创建<code class="fe og oh oi oj b">DataBlock</code>之前使用下面的函数将允许即使在内核重启之间也能产生可再现的结果。您还需要在您的数据加载器中设置<code class="fe og oh oi oj b">num_workers = 0 (or 1)</code>,但是默认情况下它是0，我们不会在这里更改它。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">在NumPy、PyTorch和random包中设置随机种子。</p></figure><p id="084b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">请注意，如果您调用任何使用随机设置的函数(如<code class="fe og oh oi oj b">learn.dls.show_batch()</code>)或更改使用的GPU(如特斯拉P100 vs Colabs上的V100)，结果将会改变。这可能导致需要在工厂重置运行时并重新连接，直到提供相同的GPU。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">驱动版本和CUDA版本的一致性也很重要。</p></figure><h2 id="5e92" class="nq mj iq bd mk nr ns dn mo nt nu dp ms lo nv nw mu ls nx ny mw lw nz oa my iw bi translated">1.2 -将数据加载到Colabs中</h2><p id="2ba2" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">目前，这些数据保存在Google Drive中带有类别标签的文件夹中，共有150张图片。jpgs)。Colab可以<a class="ae le" href="https://colab.research.google.com/notebooks/io.ipynb" rel="noopener ugc nofollow" target="_blank">直接将</a>链接到您的Google Drive，但是简单地将您的学习者指向该驱动器并继续进行培训将会大大减慢该过程，因为每批培训都需要不断地传输图像。</p><p id="bb96" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了解决这个问题，我们可以递归地将包含每个子文件夹的文件夹直接复制到当前内核中(但是，如果您有大量小文件，这可能会相对较慢)。</p><blockquote class="mb mc md"><p id="2c76" class="lf lg me lh b li lj ka lk ll lm kd ln mf lp lq lr mg lt lu lv mh lx ly lz ma ij bi translated">r<!-- -->ecursife意味着<code class="fe og oh oi oj b">cp</code>复制目录的内容，如果一个目录有子目录，它们也被复制。</p></blockquote><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">执行主文件夹的递归复制。</p></figure><p id="c8bc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果这种方法太慢，我们可以先下载文件，压缩文件，然后上传到Google Drive。然后，每当我们需要数据时，我们可以简单地下载该文件并在内核中解压缩。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">下载并解压缩包含所有文件夹的文件。</p></figure><p id="f306" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">不管怎样，我们在这里所做的确保我们的图像出现在Colabs内核上的工作将会在训练中节省大量的时间。</p><h2 id="043b" class="nq mj iq bd mk nr ns dn mo nt nu dp ms lo nv nw mu ls nx ny mw lw nz oa my iw bi translated">1.3 -数据块和数据加载器</h2><p id="d972" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">现在，我们的数据直接呈现在内核中，可以在训练期间轻松访问。为了使用这些数据，fast.ai开发了一个名为<code class="fe og oh oi oj b">DataBlock</code> <em class="me"> </em> API的灵活系统。在高层次上，<code class="fe og oh oi oj b">DataBlock</code>只是在构建批处理和我们的<code class="fe og oh oi oj b">DataLoaders</code>时作为一个指令列表。这在fastai书的第5章中有更详细的讨论。</p><p id="9b4a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们的<code class="fe og oh oi oj b">DataBlock</code>会是这样的:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用的数据块结构。</p></figure><ol class=""><li id="a4f2" class="na nb iq lh b li lj ll lm lo ok ls ol lw om ma nh ni nj nk bi translated"><code class="fe og oh oi oj b">blocks = (ImageBlock, CategoryBlock)<br/>blocks</code>使用内置块元组指定自变量和因变量类型。在这种情况下，我们传入图像并寻找类别。</li><li id="cd18" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><code class="fe og oh oi oj b">splitter = stratifiedsplitter</code> <br/> <code class="fe og oh oi oj b">splitter</code>定义使用什么函数将数据分割成训练集和验证集。<code class="fe og oh oi oj b">stratifiedsplitter</code>是一个简单的定制函数，它将基于数据帧中的一列进行拆分(我们将在后面看到)，但是可以定义任何类型的拆分——从随机拆分到基于文件夹位置或名称的拆分。</li><li id="5efa" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><code class="fe og oh oi oj b">get_x = get_x</code> <br/> <code class="fe og oh oi oj b">get_x</code>定义使用什么函数来获取我们数据集中的图像列表。</li><li id="634d" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><code class="fe og oh oi oj b">get_y = get_y</code> <br/> <code class="fe og oh oi oj b">get_y</code>定义使用什么函数为数据集创建分类标签。</li><li id="b0d2" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><code class="fe og oh oi oj b">item_tfms = item_tfms</code> <br/> <code class="fe og oh oi oj b">item_tfms</code>是运行在每个单独项目上的代码片段。fastai包括许多预定义的变换，这个步骤通常用于标准化每个图像的大小。</li><li id="d99d" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><code class="fe og oh oi oj b">batch_tfms = batch_tfms</code> <br/> <code class="fe og oh oi oj b">batch_tfms</code>作为一个组合操作在GPU上只能应用一次。与单独执行操作和多次插值相比，这保持了图像清晰度并减少了伪影的数量。这里通常是定义图像增强步骤(如调整大小和旋转)的地方。</li></ol><h2 id="e4a2" class="nq mj iq bd mk nr ns dn mo nt nu dp ms lo nv nw mu ls nx ny mw lw nz oa my iw bi translated">1.4 -分层分裂</h2><p id="5d5d" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated"><code class="fe og oh oi oj b">splitter</code>定义了哪些图像将出现在训练数据集和验证数据集中。有许多方法可以实现这一点，但这里我们准备了一个函数，它查看包含每个类的图像的所有文件夹的路径，并返回一个包含将一个类与每个图像配对的数据帧。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">一个简单的函数，创建一个数据帧，包含“类”和“路径”列，从路径到文件夹，包含每个类的图像文件夹。</p></figure><p id="b2ab" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在我们有了这个数据框架，我们可以选择我们想要如何进行拆分。为了实现未来的k折叠验证，让我们准备一种生成分层折叠的方法，它保留了每个类的样本百分比。我们在sklearn的<code class="fe og oh oi oj b">StratifiedKFold</code>函数的帮助下做到这一点，将数据帧的适当列作为<code class="fe og oh oi oj b">X</code>和<code class="fe og oh oi oj b">y</code>传入。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用sklearn的StratifiedKFold函数，在提供的数据帧上准备分层k-fold分割。</p></figure><p id="efe4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">太好了！现在我们有了一个DataFrame(上面例子中的<code class="fe og oh oi oj b">df_cnn</code>，它包含了<code class="fe og oh oi oj b">Class</code>、<code class="fe og oh oi oj b">Path</code>和<code class="fe og oh oi oj b">is_valid</code>标签。</p><p id="a11e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，由于我们希望尽可能公平地比较具有不同数量图像的数据集之间的训练情况，<strong class="lh ja">我们不想每次都使用随机训练/验证分割</strong>。如果我们这样做，用于训练和验证的图像的差异将固有地改变模型性能。为了对此进行控制，我们首先对所有图像进行随机分层分割(见下面的<em class="me"> a </em>)。然后，在我们从数据集中移除任何图像后，我们对之前定义的分割进行内部连接，以便任何图像仍保留在与之前相同的训练或验证集中(创建伪分层分割，参见下面的<em class="me"> b </em>，因为我们不能保证每组中保留的图像的<em class="me">比例与</em>完全相同)。</p><blockquote class="mb mc md"><p id="ac31" class="lf lg me lh b li lj ka lk ll lm kd ln mf lp lq lr mg lt lu lv mh lx ly lz ma ij bi translated">修复所有的随机性可能通常不是一个好主意，因为不同运行之间的高变化可能会给你一些错误的提示。如果使用交叉验证，分数的自然变化可以帮助你获得更好的分数。</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/f480e1e51bfb62ec7d2e18e98f4e656f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5y2d83HGRp6BmWqcX4gKpQ.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(a)从所有图像中创建主混洗分层分割。(b)在数据集中的一些图像被移除之后，先前定义的分裂上的内部连接将保持相同的训练/验证分裂。</p></figure><h2 id="736d" class="nq mj iq bd mk nr ns dn mo nt nu dp ms lo nv nw mu ls nx ny mw lw nz oa my iw bi translated">1.5 -创建数据块和数据加载器</h2><p id="aff5" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">如前所述，拆分是在<code class="fe og oh oi oj b">DataLoader</code>的<code class="fe og oh oi oj b">DataBlock</code>中定义的，这里我们使用一个<code class="fe og oh oi oj b">get_dataloader</code>函数来自动化这个过程。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oo"><img src="../Images/1e07a27404189ca218cffb913f52355b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ariysk40pHe27DTFE7Qd3w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://gist.github.com/kenichinakanishi/c210a52f74a4d17e1462afc0d6087a04" rel="noopener ugc nofollow" target="_blank">创建数据块和数据加载器。</a></p></figure><p id="2b58" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">该功能首先定义<code class="fe og oh oi oj b">get_x</code>、<code class="fe og oh oi oj b">get_y</code>、<code class="fe og oh oi oj b">splitter</code>、<code class="fe og oh oi oj b">item_tfms</code>和<code class="fe og oh oi oj b">batch_tfms</code>。这里，<code class="fe og oh oi oj b">get_x</code>和<code class="fe og oh oi oj b">get_y</code>告诉我们的<code class="fe og oh oi oj b">DataBlock</code>查看数据帧中适当的列，分别找到图像路径和标签。如前所述，<code class="fe og oh oi oj b">splitter</code>使用“is_valid”列将图像识别为训练或验证。</p><p id="f43d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于我们的变换，我们遵循一个<a class="ae le" href="https://github.com/fastai/fastbook/blob/master/05_pet_breeds.ipynb" rel="noopener ugc nofollow" target="_blank">预调整</a>策略，其中<code class="fe og oh oi oj b">item_tfms</code>将每个图像调整到一个比目标训练尺寸大得多的尺寸，而<code class="fe og oh oi oj b">batch_tfms</code>将所有常见的增强操作(包括调整到最终目标尺寸)组合成一个GPU的组合操作。</p><p id="f108" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">注意，这里的<code class="fe og oh oi oj b">batch_tfms</code>使用由fastai定义的基础<code class="fe og oh oi oj b">aug_transforms</code>，它应用翻转、旋转、缩放、扭曲、光照变换的<a class="ae le" href="https://docs.fast.ai/vision.augment#aug_transforms" rel="noopener ugc nofollow" target="_blank">列表，然后使用ImageNet stats应用归一化。我们添加一个随机擦除变换的附加条款，这将在后面讨论。最后，如前所述，这些片段中的每一个都被用在了<code class="fe og oh oi oj b">DataBlock</code>的定义中。</a></p><p id="f54d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，我们检查是否已经定义了一组图像的<code class="fe og oh oi oj b">split_path</code>，我们应该使用该组图像准备一个“主”分层分割，如果已经定义了，则在我们的<code class="fe og oh oi oj b">img_path</code>中应用图像的内部连接来定义我们的伪分层分割。否则，我们为<code class="fe og oh oi oj b">img_path</code>中的图像生成分层分割。该过程包含前两个函数(<code class="fe og oh oi oj b">create_path_df</code>和<code class="fe og oh oi oj b">stratified_split</code>)，采用之前定义的参数。</p><p id="edea" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">该函数的输出是一个<code class="fe og oh oi oj b">DataLoader</code>，它<a class="ae le" href="https://docs.fast.ai/data.load" rel="noopener ugc nofollow" target="_blank">表示一个具有扩展功能的数据集上的Python iterable</a>，支持自动批处理、混排和多进程数据加载等功能。</p><h2 id="d872" class="nq mj iq bd mk nr ns dn mo nt nu dp ms lo nv nw mu ls nx ny mw lw nz oa my iw bi translated">1.6 -创建学习者</h2><p id="280f" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">同样，为了让我们接下来的工作更加方便，我们将把目前为止我们编写的所有内容包装到一个函数中，该函数定义了参数，并通过fastai便利函数<code class="fe og oh oi oj b">cnn_learner</code>提供这些参数，最终得到我们的学习者。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi op"><img src="../Images/0dce9c691c9ebb95b4f7f1dc4e6c0002.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z2tlZ6CquFLduLDEMQXcgQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://gist.github.com/kenichinakanishi/00440867d8beac0d4df9cd0c552d0403" rel="noopener ugc nofollow" target="_blank">创建一个基本cnn学习者。</a></p></figure><p id="ebb8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里，我们为默认的学习者设置一些参数。我们将使用224x224像素大小的图像，批量大小为64。使用预训练的ResNet34架构，这是一个经典且可靠的神经网络。在调用<code class="fe og oh oi oj b">random_seed</code>函数修复所有随机性之前，我们使用的优化函数(Adam)的参数也在函数体中定义。我们还设置了一系列有用的回调，将结果保存为. csv格式，并在图中显示训练和验证损失，在训练期间实时显示。最后，在添加切换到混合精度训练的选项之前，我们使用fastai便利函数创建学习者，该函数接受我们之前准备的所有单独的项目。</p><p id="3a17" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">唷！我们准备好训练了。达到这一步需要做很多工作，而且没有必要以这种方式设置。然而，努力将事情包装成一个简单的函数将在以后带来好处，因为我们现在可以轻松地改变一系列参数(以一致的方式)，包括数据集中的图像数量和神经网络的架构。这样做可以让一切变得更整洁，避免每次都需要复制和粘贴代码，从而降低出错的可能性。</p><h1 id="826a" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">2.训练模型</h1><p id="aae4" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">正如我们在<code class="fe og oh oi oj b">create_simple_cnn_learner</code>函数中看到的，我们将从一个简单但健壮的CNN开始，ResNet34。让我们首先创建一个只使用1/3数据集的学习者(每个类150张图片中的50张)。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用50张(共150张)图像创建学习者。</p></figure><p id="d4c5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，我们可以使用以下工具来查看这些图像</p><pre class="kp kq kr ks gt oq oj or os aw ot bi"><span id="964f" class="nq mj iq oj b gy ou ov l ow ox">learn.dls.show_batch(max_n=9)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/6fa46754976a66f6994053317206e613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*TPRfrfSe6I53045XDQaTtw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">显示一批9幅图像。感谢我们随机性的播种，这将是每次都一样。</p></figure><p id="34f4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用从<a class="ae le" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>预训练的权重，将使用转移学习程序来微调我们图像的网络。迁移学习背后的基本思想是，由<code class="fe og oh oi oj b">create_simple_cnn_learner</code>函数创建的预训练ResNet34模型在识别ImageNet数据集中存在的东西方面已经有了一个不错的想法。由于我们使用的图像与ImageNet中使用的真实图像不会有太大的不同，所以我们不希望过多地改变权重是有道理的。使用迁移学习的理论和决策可能更加细致入微，参见<a class="ae le" href="https://blog.slavv.com/a-gentle-intro-to-transfer-learning-2c0b674375a0" rel="noopener ugc nofollow" target="_blank">这篇出色的博客文章以获得更深入的解释</a>。</p><p id="2f03" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里，我们将在解冻所有内容之前，使用冻结的初始层中的权重训练我们的模型(仅训练最后完全连接的层的权重)，并以相对较低的<a class="ae le" rel="noopener" target="_blank" href="/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10">区别学习速率</a> s对所有权重进行“微调”训练。这意味着在fastai定义的层组中，学习速率将从小(在早期层中)交错到相对较大(当我们接近最终层时)。直观地说，这与每一层所看到的图像细节有关。早期图层倾向于查看图像的大致轮廓，如梯度、边缘和拐角，所有细节的权重都不需要进行任何重大程度的重新训练。对于后面的层反之亦然。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">我们将使用迁移学习程序来确定我们的训练结果。</p></figure><p id="a348" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">上面的代码展示了我们将在这里用来训练我们的分类器的基本迁移学习过程。固定的学习速率和时期将用于比较训练运行，10个时期用于训练模型头部，另外10个时期用于微调网络。注意,<code class="fe og oh oi oj b">enumerate_params</code>是一个小函数，当被调用时，它告诉我们一个给定的学习者有多少冻结和未冻结的参数。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oe of l"/></div></figure><h2 id="0a40" class="nq mj iq bd mk nr ns dn mo nt nu dp ms lo nv nw mu ls nx ny mw lw nz oa my iw bi translated">2.1 -我们如何选择学习率？</h2><p id="a330" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">许多优秀的<a class="ae le" rel="noopener" target="_blank" href="/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10">博客文章</a>解释了为手头的问题选择合适的学习率的重要性。由于这不是这篇文章的重点，我们将不会进入太多的细节。在这里(按照Leslie N. Smith的建议，许多人也是这样做的)，我们使用内置的fastai函数<code class="fe og oh oi oj b">learn.lr_find()</code>来绘制损失与学习率的关系，并在损失仍然改善的最小值之前选择一个值，以确定转移过程中每一步的适当学习率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oz"><img src="../Images/22a7118439ac4e707a20c47fa398d6ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OexldSs7rrcS2wHqsagqtQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">learn.lr_find()的结果示例，所选的学习率用红色标记。</p></figure><p id="9aa4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在实践中，我们使用<code class="fe og oh oi oj b">fit_one_cycle</code>函数，所用的学习率代表余弦退火的<a class="ae le" href="https://fastai1.fast.ai/callbacks.one_cycle.html" rel="noopener ugc nofollow" target="_blank">单周期策略</a>中的最大学习率，如下所示。请注意，下面的x轴代表通过学习者的批次数量。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pa"><img src="../Images/cfd0604c007c13fcb4dbce0a5007c3a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C5vdq8NxE95F9mFdLVT0YA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">余弦退火的单周期策略。</p></figure><p id="3f23" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这项政策是<a class="ae le" href="https://arxiv.org/abs/1803.09820" rel="noopener ugc nofollow" target="_blank"> Leslie Smith的工作</a>在超参数(学习率、动量和重量衰减)方面的成果，结合fastai的调整，在复杂模型的训练中提供快速结果。直观上，我们可以认为该策略从一个较低的值开始，以预热培训。随着我们的进展，学习率增加，动量减少，以鼓励优化器快速调查损失函数的新区域，作为一种正则化方法，通常落在具有更平坦最小值的区域(这些区域<a class="ae le" href="https://arxiv.org/pdf/1706.10239.pdf" rel="noopener ugc nofollow" target="_blank">更擅长泛化</a>)。在单周期策略的最后部分，学习率的降低允许优化器在较平坦的区域内进入较陡的局部最小值。参见Nachiket Tanksdale 的这篇精彩文章，了解更详细的解释。</p><h2 id="3c2d" class="nq mj iq bd mk nr ns dn mo nt nu dp ms lo nv nw mu ls nx ny mw lw nz oa my iw bi translated">2.2 -训练运行示例</h2><p id="d624" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">在跑完<code class="fe og oh oi oj b">baseline_fit(learn)</code>之后，一次单独的训练跑将会看起来像这样。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/dca4e9e0abe6bc559b1bf66c3c752814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1-pfQkA6jZHL2dbUJB4znQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">训练运行示例。</p></figure><p id="1519" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以看到<code class="fe og oh oi oj b">ShowGraphCallback()</code>的用处，它可以在过度训练发生时给我们一个指示。通常，我们可能会寻找训练和验证损失的差异，如果验证损失开始增加，我们应该特别小心。</p><h1 id="6feb" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">3.训练模型</h1><p id="a45f" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">现在我们已经设置好了一切，我们可以开始做一些有趣的比较。让我们先来比较一下，当我们改变第1部分<a class="ae le" rel="noopener" target="_blank" href="/creating-a-plant-pet-toxicity-classifier-a29587f3f04c">的数据集合中的图像数量时(在创建学习器时使用<code class="fe og oh oi oj b">pct_images</code>参数),我们的前5个精度是如何变化的。</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pc"><img src="../Images/276484a94fd0cfbc0a153215117dc50a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-eEoB6yTsz2RaXmBwvON3w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">验证准确性随所用图像数量的变化。</p></figure><p id="ebef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">虽然总训练时间与图像数量成线性比例，但我们看到，当每类使用150幅图像时，模型的前5名准确度会下降。啊哦。通常我们会期望更多的图像给我们一个更好的结果！</p><h2 id="1539" class="nq mj iq bd mk nr ns dn mo nt nu dp ms lo nv nw mu ls nx ny mw lw nz oa my iw bi translated">3.1 -为什么图像越多越好？</h2><p id="a352" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">这个问题与我们为创建数据库而下载的图像的<strong class="lh ja"><em class="me"/></strong>质量有关。回想一下<a class="ae le" href="https://medium.com/r?url=https%3A%2F%2Ftowardsdatascience.com%2Fcreating-a-plant-pet-toxicity-classifier-a29587f3f04c" rel="noopener">每个文件夹的图片都是根据每种植物的学名从谷歌图片上下载的。</a>让我们来看看一个随机类的早期搜索结果和后期搜索结果，比如说<em class="me"> Peperomia peltifolia </em>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pd"><img src="../Images/71d78c7d23f2f1a98acdedcad79adce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tg-PfCjxtm003JMLsWRucA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">从谷歌图片Peperomia peltifolia。</p></figure><p id="314d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">啊哈！在我们可以为每个类生成150个独特的图像之前，必须查看150多个搜索结果(仅这个随机类就有430多个)。)随着我们越来越深入搜索结果，我们的结果会变得越来越不相关。这将产生像图画、图表和事实表这样的图像——它们都不擅长训练我们的模型做我们想要它做的事情(根据自然照片对植物进行分类)。事实上，我们对训练结果的比较表明，由于包含了许多糟糕的训练示例，试图在每个类别中使用超过100个图像会开始损害我们的模型。</p><p id="da35" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们希望对这些图像进行一些清理，而不必手动检查500多个文件夹中的每个文件。请加入我们的第3部分:锁定和删除不良训练数据，我们将研究一些方法来实现这一点。</p></div></div>    
</body>
</html>