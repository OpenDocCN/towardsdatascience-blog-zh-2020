<html>
<head>
<title>Machine Learning in Java</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Java中的机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-in-java-e335b9d80c14?source=collection_archive---------2-----------------------#2020-10-13">https://towardsdatascience.com/machine-learning-in-java-e335b9d80c14?source=collection_archive---------2-----------------------#2020-10-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="249a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何在Java中构建和部署ML模型？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/151a090e8aedde03b12d5d96612f949d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_GNCAliJziMztyBkB7eKNA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">迈克·肯尼利在<a class="ae kv" href="https://unsplash.com/s/photos/java?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2062" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">机器学习(ML)已经在学术界和工业界的不同领域获得了重大承诺。随着时间的推移，ML在图像、语音识别、模式识别、优化、自然语言处理和推荐等众多应用领域的参与度不断提高。</p><blockquote class="ls lt lu"><p id="c6d5" class="kw kx lv ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">给计算机编程以从经验中学习，最终将消除对这种细致编程工作的需求。阿瑟·塞缪尔1959年。</p></blockquote><p id="de11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">机器学习可以分为四种主要技术:回归、分类、聚类和强化学习。这些技术主要以两种形式解决不同性质的问题:监督学习和非监督学习。监督学习要求在训练模型之前对数据进行标记和准备。无监督学习可以方便地处理未标记的数据或具有未知特征的数据。本文不描述ML的概念，也不深入描述这个领域中使用的术语。如果你是全新的，请看看我以前的<a class="ae kv" href="https://medium.com/@moh.alhamid/my-roadmap-to-machine-learning-80eeb292489" rel="noopener">文章</a>开始你的ML学习之旅。</p><h1 id="f09b" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">Java中的机器学习库</h1><p id="0ff9" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">这里是一个众所周知的用于ML的Java库的列表。我们将逐一描述它们，并给出使用其中一些框架的真实例子。</p><ul class=""><li id="8437" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated"><a class="ae kv" href="https://www.cs.waikato.ac.nz/ml/weka/" rel="noopener ugc nofollow" target="_blank"> Weka </a></li><li id="6c44" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><a class="ae kv" href="https://mahout.apache.org" rel="noopener ugc nofollow" target="_blank">阿帕奇看象人</a></li><li id="3f88" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><a class="ae kv" href="https://deeplearning4j.org" rel="noopener ugc nofollow" target="_blank">深度学习4j </a></li><li id="7c3b" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><a class="ae kv" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwi1xbfVs8XrAhXMMd8KHZHoAmAQFjABegQICBAC&amp;url=http%3A%2F%2Fmallet.cs.umass.edu%2F&amp;usg=AOvVaw1PzoHpu0Ge5FT6p5vbGyKj" rel="noopener ugc nofollow" target="_blank">木槌</a></li><li id="3f36" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">火花MLlib</li><li id="ec53" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><a class="ae kv" href="https://www.heatonresearch.com/encog/" rel="noopener ugc nofollow" target="_blank">Encog机器学习框架</a></li><li id="c40b" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><a class="ae kv" href="https://moa.cms.waikato.ac.nz" rel="noopener ugc nofollow" target="_blank">金属氧化物避雷器</a></li></ul><p id="1188" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在每个库的旁边，下面的图标将指示每个框架中默认提供的算法的主要类别。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/ddf58a1f3b537d76793b79bc50afddf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*hodPHcT4lyTIhTn3shXRRQ.png"/></div></figure></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h2 id="3e72" class="ns ma iq bd mb nt nu dn mf nv nw dp mj lf nx ny ml lj nz oa mn ln ob oc mp od bi translated">新西兰黑秧鸡</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/135efb9a5655166b50d88b900dd052c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*34eoY3AEleRar_pq986Rdw.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/b2209e4b802120ef90a982708f1625ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GZhtlb_JIQfApC220AI0ow.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Weka GUI工具包的截图。</p></figure><p id="d289" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Weka是由新西兰怀卡托大学开发的开源图书馆。Weka是用Java编写的，对于通用机器学习来说非常有名。Weka提供了一种数据文件格式，称为ARFF。ARFF分为两部分:报头和实际数据。标题描述了属性及其数据类型。</p><h2 id="e33b" class="ns ma iq bd mb nt nu dn mf nv nw dp mj lf nx ny ml lj nz oa mn ln ob oc mp od bi translated">阿帕奇看象人</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/ab7ce68b9af90c6f4da9a532bf5a757c.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/1*RsqyIO8YiCUKVIryf6x5Ig.png"/></div></figure><p id="14b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Apache Mahout提供了一个可扩展的机器学习库。Mahout使用MapReduce范式，可用于分类、协作过滤和聚类。Mahout利用Apache Hadoop处理多个并行任务。除了分类和聚类之外，Mahout还提供了推荐算法，比如协作过滤，从而促进了快速构建模型的可伸缩性。</p><h2 id="42b6" class="ns ma iq bd mb nt nu dn mf nv nw dp mj lf nx ny ml lj nz oa mn ln ob oc mp od bi translated">深度学习4j</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ed332329392f1dbc98149c5661fe407f.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*TwtKdflk6P4wNTrUXv5PGw.png"/></div></figure><p id="31b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Deeplearning4j是另一个专注于深度学习的java库。这是一个很棒的Java深度学习开源库。它也是用Scala和Java编写的，可以与Hadoop和Spark集成，提供高处理能力。当前的版本是测试版，但是有很好的文档和快速入门的例子(<a class="ae kv" href="https://deeplearning4j.org" rel="noopener ugc nofollow" target="_blank">点击这里</a>)。</p><h2 id="9bf4" class="ns ma iq bd mb nt nu dn mf nv nw dp mj lf nx ny ml lj nz oa mn ln ob oc mp od bi translated">木槌</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/9f47b9bd48eaf28c9f2210f29f1fb039.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*fuqydXG0fTrPA6L4cTPPyQ.png"/></div></figure><p id="9dd7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Mallet代表语言工具包的机器学习。它是少数几个用于自然语言处理的专门工具包之一。它提供了主题建模、文档分类、聚类和信息提取的能力。有了Mallet，我们可以用ML模型来处理文本文档。</p><h2 id="4567" class="ns ma iq bd mb nt nu dn mf nv nw dp mj lf nx ny ml lj nz oa mn ln ob oc mp od bi translated">火花MLlib</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/b8fea6a0a1d633114ca9567e645e21c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*38oGpnGCdR1uiKtUyNOXRg.png"/></div></figure><p id="9e4d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">众所周知，Spark可以提高处理大量数据的可伸缩性和整体性能。Spark MLlib还拥有高性能算法，可在Spark上运行，并嵌入Hadoop工作流。</p><h2 id="e7fa" class="ns ma iq bd mb nt nu dn mf nv nw dp mj lf nx ny ml lj nz oa mn ln ob oc mp od bi translated">Encog机器学习框架</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ed332329392f1dbc98149c5661fe407f.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*TwtKdflk6P4wNTrUXv5PGw.png"/></div></figure><p id="620a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Encog是一个用于ML的Java和C#框架。Envog有用于构建SVM、神经网络、贝叶斯网络、HMM和遗传算法的库。Encog已经开始作为一个研究项目，并得到了近1000个关于谷歌学术的引用。</p><h2 id="71af" class="ns ma iq bd mb nt nu dn mf nv nw dp mj lf nx ny ml lj nz oa mn ln ob oc mp od bi translated">恐鸟</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/e936b6541708f228ad55b12ad24b0f31.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*w0sEib0-d7Jp8F-y48RQwA.png"/></div></figure><p id="e828" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">海量在线分析(MOA)提供了用于分类、回归、聚类和推荐的算法。它还提供了异常检测和漂移检测的库。它是为实时处理产生的数据流而设计的。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="d335" class="lz ma iq bd mb mc ol me mf mg om mi mj jw on jx ml jz oo ka mn kc op kd mp mq bi translated">Weka示例:</h1><p id="3d8c" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我们将使用一个小型糖尿病数据集。我们将首先使用Weka加载数据:</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="2bb2" class="ns ma iq or b gy ov ow l ox oy">import weka.core.Instances;<br/>import weka.core.converters.ConverterUtils.DataSource;<br/><br/>public class Main {<br/><br/>    public static void main(String[] args) throws Exception {<br/>        // Specifying the datasource<br/>        DataSource dataSource = new DataSource("data.arff");<br/>        // Loading the dataset<br/>        Instances dataInstances = dataSource.getDataSet();<br/>        // Displaying the number of instances<br/>        <em class="lv">log</em>.info("The number of loaded instances is: " + dataInstances.numInstances());<br/><br/>        <em class="lv">log</em>.info("data:" + dataInstances.toString());<br/>    }<br/>}</span></pre><p id="4e1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集中有768个实例。我们来看看如何得到属性(特征)的数量，应该是9。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="c01a" class="ns ma iq or b gy ov ow l ox oy"><em class="lv">log</em>.info("The number of attributes in the dataset: " + dataInstances.numAttributes());</span></pre><p id="7fc2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在构建任何模型之前，我们希望确定哪一列是目标列，并查看在该列中找到了多少个类:</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="a372" class="ns ma iq or b gy ov ow l ox oy">// Identifying the label index<br/>dataInstances.setClassIndex(dataInstances.numAttributes() - 1);<br/>// Getting the number of <br/><em class="lv">log</em>.info("The number of classes: " + dataInstances.numClasses());</span></pre><p id="0388" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">加载数据集并确定目标属性后，现在是构建模型的时候了。我们来做一个简单的树分类器，J48。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="f70d" class="ns ma iq or b gy ov ow l ox oy">// Creating a decision tree classifier<br/>J48 treeClassifier = new J48();<br/>treeClassifier.setOptions(new String[] { "-U" });<br/>treeClassifier.buildClassifier(dataInstances);</span></pre><p id="5c2c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的三行中，我们指定了一个选项来指示一个未修剪的树，并为模型训练提供了数据实例。如果我们在训练后打印生成的模型的树结构，我们可以遵循模型如何在内部构建它的规则:</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="44bd" class="ns ma iq or b gy ov ow l ox oy">plas &lt;= 127<br/>|   mass &lt;= 26.4<br/>|   |   preg &lt;= 7: tested_negative (117.0/1.0)<br/>|   |   preg &gt; 7<br/>|   |   |   mass &lt;= 0: tested_positive (2.0)<br/>|   |   |   mass &gt; 0: tested_negative (13.0)<br/>|   mass &gt; 26.4<br/>|   |   age &lt;= 28: tested_negative (180.0/22.0)<br/>|   |   age &gt; 28<br/>|   |   |   plas &lt;= 99: tested_negative (55.0/10.0)<br/>|   |   |   plas &gt; 99<br/>|   |   |   |   pedi &lt;= 0.56: tested_negative (84.0/34.0)<br/>|   |   |   |   pedi &gt; 0.56<br/>|   |   |   |   |   preg &lt;= 6<br/>|   |   |   |   |   |   age &lt;= 30: tested_positive (4.0)<br/>|   |   |   |   |   |   age &gt; 30<br/>|   |   |   |   |   |   |   age &lt;= 34: tested_negative (7.0/1.0)<br/>|   |   |   |   |   |   |   age &gt; 34<br/>|   |   |   |   |   |   |   |   mass &lt;= 33.1: tested_positive (6.0)<br/>|   |   |   |   |   |   |   |   mass &gt; 33.1: tested_negative (4.0/1.0)<br/>|   |   |   |   |   preg &gt; 6: tested_positive (13.0)<br/>plas &gt; 127<br/>|   mass &lt;= 29.9<br/>|   |   plas &lt;= 145: tested_negative (41.0/6.0)<br/>|   |   plas &gt; 145<br/>|   |   |   age &lt;= 25: tested_negative (4.0)<br/>|   |   |   age &gt; 25<br/>|   |   |   |   age &lt;= 61<br/>|   |   |   |   |   mass &lt;= 27.1: tested_positive (12.0/1.0)<br/>|   |   |   |   |   mass &gt; 27.1<br/>|   |   |   |   |   |   pres &lt;= 82<br/>|   |   |   |   |   |   |   pedi &lt;= 0.396: tested_positive (8.0/1.0)<br/>|   |   |   |   |   |   |   pedi &gt; 0.396: tested_negative (3.0)<br/>|   |   |   |   |   |   pres &gt; 82: tested_negative (4.0)<br/>|   |   |   |   age &gt; 61: tested_negative (4.0)<br/>|   mass &gt; 29.9<br/>|   |   plas &lt;= 157<br/>|   |   |   pres &lt;= 61: tested_positive (15.0/1.0)<br/>|   |   |   pres &gt; 61<br/>|   |   |   |   age &lt;= 30: tested_negative (40.0/13.0)<br/>|   |   |   |   age &gt; 30: tested_positive (60.0/17.0)<br/>|   |   plas &gt; 157: tested_positive (92.0/12.0)</span><span id="a6be" class="ns ma iq or b gy oz ow l ox oy">Number of Leaves  :  22</span><span id="9f36" class="ns ma iq or b gy oz ow l ox oy">Size of the tree :  43</span></pre><h1 id="9193" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">Deeplearning4j示例:</h1><p id="2902" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">此示例将构建一个卷积神经网络(CNN)模型来对MNIST图书馆进行分类。如果你不熟悉MNIST或者CNN是如何对手写数字进行分类的，我推荐你快速浏览一下我之前的帖子，它详细描述了这些方面。</p><p id="7e24" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像往常一样，我们将加载数据集并显示其大小。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="1d43" class="ns ma iq or b gy ov ow l ox oy">DataSetIterator MNISTTrain = new MnistDataSetIterator(batchSize,true,seed);<br/>DataSetIterator MNISTTest = new MnistDataSetIterator(batchSize,false,seed);</span></pre><p id="e1fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们仔细检查一下我们是否从数据集中获得了10个唯一的标签:</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="bd2d" class="ns ma iq or b gy ov ow l ox oy"><em class="lv">log</em>.info("The number of total labels found in the training dataset " + MNISTTrain.totalOutcomes());<br/><em class="lv">log</em>.info("The number of total labels found in the test dataset " + MNISTTest.totalOutcomes());</span></pre><p id="0d1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，让我们配置模型的架构。我们将使用两个卷积层加上一个输出扁平化层。Deeplearning4j有几个选项可以用来初始化权重方案。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="3786" class="ns ma iq or b gy ov ow l ox oy">// Building the CNN model<br/>MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()<br/>        .seed(seed) // random seed<br/>        .l2(0.0005) // regularization<br/>        .weightInit(WeightInit.<em class="lv">XAVIER</em>) // initialization of the weight scheme<br/>        .updater(new Adam(1e-3)) // Setting the optimization algorithm<br/>        .list()<br/>        .layer(new ConvolutionLayer.Builder(5, 5)<br/>                //Setting the stride, the kernel size, and the activation function.<br/>                .nIn(nChannels)<br/>                .stride(1,1)<br/>                .nOut(20)<br/>                .activation(Activation.<em class="lv">IDENTITY</em>)<br/>                .build())<br/>        .layer(new SubsamplingLayer.Builder(PoolingType.<em class="lv">MAX</em>) // downsampling the convolution<br/>                .kernelSize(2,2)<br/>                .stride(2,2)<br/>                .build())<br/>        .layer(new ConvolutionLayer.Builder(5, 5)<br/>                // Setting the stride, kernel size, and the activation function.<br/>                .stride(1,1)<br/>                .nOut(50)<br/>                .activation(Activation.<em class="lv">IDENTITY</em>)<br/>                .build())<br/>        .layer(new SubsamplingLayer.Builder(PoolingType.<em class="lv">MAX</em>) // downsampling the convolution<br/>                .kernelSize(2,2)<br/>                .stride(2,2)<br/>                .build())<br/>        .layer(new DenseLayer.Builder().activation(Activation.<em class="lv">RELU</em>)<br/>                .nOut(500).build())<br/>        .layer(new OutputLayer.Builder(LossFunctions.LossFunction.<em class="lv">NEGATIVELOGLIKELIHOOD</em>)<br/>                .nOut(outputNum)<br/>                .activation(Activation.<em class="lv">SOFTMAX</em>)<br/>                .build())<br/>        // the final output layer is 28x28 with a depth of 1.<br/>        .setInputType(InputType.<em class="lv">convolutionalFlat</em>(28,28,1))<br/>        .build();</span></pre><p id="8681" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">架构设置好之后，我们需要初始化模式，设置训练数据集，触发模型训练。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="61aa" class="ns ma iq or b gy ov ow l ox oy">MultiLayerNetwork model = new MultiLayerNetwork(conf);<br/>// initialize the model weights.<br/>model.init();<br/><br/><em class="lv">log</em>.info("Step2: start training the model");<br/>//Setting a listener every 10 iterations and evaluate on test set on every epoch<br/>model.setListeners(new ScoreIterationListener(10), new EvaluativeListener(MNISTTest, 1, InvocationType.<em class="lv">EPOCH_END</em>));<br/>// Training the model<br/>model.fit(MNISTTrain, nEpochs);</span></pre><p id="43f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在训练期间，分数收听者将提供分类准确度的混淆矩阵。让我们看看十次训练后的准确度:</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="d37d" class="ns ma iq or b gy ov ow l ox oy">=========================Confusion Matrix=========================<br/>    0    1    2    3    4    5    6    7    8    9<br/>---------------------------------------------------<br/>  977    0    0    0    0    0    1    1    1    0 | 0 = 0<br/>    0 1131    0    1    0    1    2    0    0    0 | 1 = 1<br/>    1    2 1019    3    0    0    0    3    4    0 | 2 = 2<br/>    0    0    1 1004    0    1    0    1    3    0 | 3 = 3<br/>    0    0    0    0  977    0    2    0    1    2 | 4 = 4<br/>    1    0    0    9    0  879    1    0    1    1 | 5 = 5<br/>    4    2    0    0    1    1  949    0    1    0 | 6 = 6<br/>    0    4    2    1    1    0    0 1018    1    1 | 7 = 7<br/>    2    0    3    1    0    1    1    2  962    2 | 8 = 8<br/>    0    2    0    2   11    2    0    3    2  987 | 9 = 9</span></pre><h1 id="50e1" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">木槌示例:</h1><p id="7136" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">如前所述，Mallet是一个强大的自然语言建模工具包。我们将使用Mallet包中的工具David Blei提供的样本语料库。Mallet有一个专门的库，用于为分类标注文本标记。在我们加载数据集之前，Mallet有管道定义的概念，您定义管道，然后提供要通过的数据集。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="b08d" class="ns ma iq or b gy ov ow l ox oy">ArrayList&lt;Pipe&gt; pipeList = new ArrayList&lt;Pipe&gt;();</span></pre><p id="c5e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">管道被定义为一个“数组列表”，它包含了我们在构建主题模型之前通常要做的步骤。文档中的每个文本都将通过以下步骤:</p><ol class=""><li id="49d7" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr pa nc nd ne bi translated">小写关键字</li><li id="8960" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr pa nc nd ne bi translated">标记文本</li><li id="acf8" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr pa nc nd ne bi translated">删除停用词</li><li id="2d63" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr pa nc nd ne bi translated">映射到要素</li></ol><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="82b2" class="ns ma iq or b gy ov ow l ox oy">pipeList.add( new CharSequenceLowercase() );<br/>pipeList.add( new CharSequence2TokenSequence(Pattern.<em class="lv">compile</em>("\\p{L}[\\p{L}\\p{P}]+\\p{L}")) );<br/>// Setting the dictionary of the stop words<br/>URL stopWordsFile = getClass().getClassLoader().getResource("stoplists/en.txt");<br/>pipeList.add( new TokenSequenceRemoveStopwords(new File(stopWordsFile.toURI()), "UTF-8", false, false, false) );<br/><br/>pipeList.add( new TokenSequence2FeatureSequence() );</span></pre><p id="4ea3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦定义了管道，我们将传递代表每个文档原始文本的实例。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="a248" class="ns ma iq or b gy ov ow l ox oy">InstanceList instances = new InstanceList (new SerialPipes(pipeList));</span></pre><p id="f779" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在到了传递输入文件来填充实例列表的步骤。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="f058" class="ns ma iq or b gy ov ow l ox oy">URL inputFileURL = getClass().getClassLoader().getResource(inputFile);<br/>Reader fileReader = new InputStreamReader(new FileInputStream(new File(inputFileURL.toURI())), "UTF-8");<br/>instances.addThruPipe(new CsvIterator (fileReader, Pattern.<em class="lv">compile</em>("^(\\S*)[\\s,]*(\\S*)[\\s,]*(.*)$"),<br/>        3, 2, 1)); // data, label, name fields</span></pre><p id="c4db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从最后一个命令行中，您可以注意到我们提供了关于CSV文件如何构造的说明。资源文件夹中的源文件大约有2000行。每行代表一个原始文档文本，由逗号分隔的三个属性组成(名称、标签和文档内容)。我们可以使用以下命令打印在输入文档中找到的实例数量:</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="8349" class="ns ma iq or b gy ov ow l ox oy"><em class="lv">log</em>.info("The number of instances found in the input file is: " + instances.size());</span></pre><p id="0220" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们为文档的主题建模。假设我们在2k文档中有100个不同的主题。Mallet使我们能够设置两个变量:alpha和beta权重。Alpha控制主题词分布的集中程度，beta表示主题词分布上的前词权重。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="a3f0" class="ns ma iq or b gy ov ow l ox oy"><br/>int numTopics = 100;</span><span id="633c" class="ns ma iq or b gy oz ow l ox oy">// defining the model <br/>ParallelTopicModel model = new ParallelTopicModel(numTopics, 1.0, 0.01);<br/>// adding the instances to the model<br/>model.addInstances(instances);</span></pre><p id="845e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在这个例子中选择的模型是LDA(潜在狄利克雷分配)的实现。该算法使用一组观察到的关键词相似度来分类文档。</p><p id="2bc3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我喜欢Mallet的一点是它的API功能可以很容易地设计并行处理。在这里，我们可以为每个子样本定义多线程处理。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="60df" class="ns ma iq or b gy ov ow l ox oy">model.setNumThreads(2);</span></pre><p id="fdec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在只剩下两件事，定义模型训练的迭代次数，并开始训练。</p><pre class="kg kh ki kj gt oq or os ot aw ou bi"><span id="6a5f" class="ns ma iq or b gy ov ow l ox oy">model.setNumIterations(50);<br/>model.estimate();</span></pre><p id="4d04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于如何在github上的完整示例中显示主题建模结果，我留下了更多的细节。</p><h1 id="8e35" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">进一步阅读</h1><ul class=""><li id="62d7" class="mw mx iq ky b kz mr lc ms lf pb lj pc ln pd lr nb nc nd ne bi translated"><strong class="ky ir">【书】:</strong><a class="ae kv" href="https://www.oreilly.com/library/view/machine-learning-in/9781784396589/" rel="noopener ugc nofollow" target="_blank">botjan kalu la著，O'Reilly出版的Java中的机器学习</a>。</li><li id="d5c3" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">【书籍】:</strong>机器学习:Java开发者端到端指南，作者:Richard M. Reese，Jennifer L. Reese，Bostjan Kaluza，Uday Kamath博士，Krishna Choppella。</li><li id="35df" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">【教程】</strong> <a class="ae kv" href="http://spark.apache.org/examples.html" rel="noopener ugc nofollow" target="_blank"> Spark MLlib示例。</a></li><li id="c50d" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">【教程】</strong> <a class="ae kv" href="http://mallet.cs.umass.edu/mallet-tutorial.pdf" rel="noopener ugc nofollow" target="_blank">用木槌进行机器学习。</a></li></ul><p id="c4f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="lv">本帖中提供的所有例子都可以在</em></strong><a class="ae kv" href="https://github.com/malhamid/ml_in_java" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"><em class="lv">my Github</em></strong></a><strong class="ky ir"><em class="lv">reprasority上找到。</em> </strong></p></div></div>    
</body>
</html>