<html>
<head>
<title>Logistic Regression in Classification model using Python: Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python的分类模型中的逻辑回归:机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0?source=collection_archive---------4-----------------------#2020-11-03">https://towardsdatascience.com/logistic-regression-in-classification-model-using-python-machine-learning-dc9573e971d0?source=collection_archive---------4-----------------------#2020-11-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="60af" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习如何使用python构建机器学习中的基本逻辑回归模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b95e67b4463862bcf819f4871f2e5de6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x79T2-26lkEpdoErqbtgqw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·温克勒在<a class="ae ky" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="edf7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">逻辑回归是各种行业(如银行、医疗保健)中常用的模型，因为与其他分类模型相比，逻辑回归模型很容易解释。</p><h2 id="549a" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">二元分类</h2><p id="5e20" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">二元分类是最常用的逻辑回归。二元分类问题的一些例子是:</p><ul class=""><li id="da15" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">一家金融公司想知道客户是否违约</li><li id="b47d" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">预测电子邮件是否是垃圾邮件</li><li id="6978" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">无论一个人是否患有糖尿病</li></ul><p id="9c9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">二元分类总是只有两种可能的结果，要么是‘是’&amp;‘否’，要么是‘1’&amp;‘0’等等。</p><p id="dfe8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就像上一篇文章《<a class="ae ky" rel="noopener" target="_blank" href="/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a"> <strong class="lb iu">多元线性回归模型</strong> </a>》中所说的，一个自变量往往不足以捕捉逻辑回归的目标变量的所有不确定性。</p><p id="ef96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们在Jupyter笔记本中使用python构建一个逻辑回归模型。</p><blockquote class="nh"><p id="d7a6" class="ni nj it bd nk nl nm nn no np nq lu dk translated">对于整篇文章，我们使用来自<a class="ae ky" href="https://www.kaggle.com/bandiatindra/telecom-churn-prediction/data?select=WA_Fn-UseC_-Telco-Customer-Churn.csv" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的数据集。</p></blockquote><p id="73d6" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">我们将关注电信客户流失预测数据集。它有21个与客户行为相关的变量，用于预测特定客户是否会转向另一家电信提供商(即，客户流失与否)。</p><h2 id="8f0e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">导入必要的库和数据</h2><p id="790a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">首先，我们将从导入必要的库到笔记本开始，并将<code class="fe nw nx ny nz b">.csv</code>文件转换成pandas数据框。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="1672" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/bec20938dcb6a2c9fad4a939a1c99e0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B5QprPyhMaUgxZO8cMz7Ug.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">电信流失数据集</strong></p></figure><p id="2e61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面数据集中的目标变量是<code class="fe nw nx ny nz b">Churn</code>列。</p><h2 id="3dfc" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">检查数据帧</h2><p id="7bed" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们用<code class="fe nw nx ny nz b">.shape</code>、<code class="fe nw nx ny nz b">.describe</code>和<code class="fe nw nx ny nz b">.info</code>的方法检查数据帧。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="df07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">代码的输出将是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/6212a131248782ded9931c9c70cecd55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*mluAGwCKSJ3dTMjjdOK6CA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供— <strong class="bd od">检查数据</strong></p></figure><p id="e620" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所看到的，数据集中有<code class="fe nw nx ny nz b">7043 rows</code>和<code class="fe nw nx ny nz b">21 columns</code>，数值变量的值从最小值到最大值也没有明显的跳跃，并且数据集没有空值。</p><h2 id="80f8" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">数据准备</h2><p id="e317" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在，让我们通过将变量中的“是”和“否”值转换为“1”和“0”来准备数据。我们将通过定义一个函数并将“是”和“否”值映射到“1”和“0”来将值映射到“1”和“0”。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="1990" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">映射值后，数据集如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/fada13d8c40ba30f397b7b700b792af1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YXXvMa0U7I11N0isjr3d_g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供— <strong class="bd od">为二进制列映射值</strong></p></figure><p id="b5eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">创建虚拟变量<br/> </strong>对于具有两个以上值的列，我们将创建类似于在“<a class="ae ky" rel="noopener" target="_blank" href="/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a"> <strong class="lb iu">多元线性回归模型</strong> </a>”文章中创建的虚拟变量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="675e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出将是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/d46431e2f70fbfc2e7b596157128677d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TAYheRoREK7ny_hzNfMosw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">创建虚拟变量</strong></p></figure><p id="20b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们观察上面的数据集，列的数量从<code class="fe nw nx ny nz b">21 columns</code>增加到<code class="fe nw nx ny nz b">29 columns</code>。</p><p id="acd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们正在为剩余的分类变量创建虚拟变量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="6f9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为所有变量创建虚拟变量后的数据集将是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/56429f61fca3196d56c3ae40c161c01a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LReP7FUHNeIdewK8eHkPyQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">为所有剩余的列创建虚拟变量</strong></p></figure><p id="9b80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">删除原来的变量<br/> </strong>现在我们将删除我们为其创建虚拟变量的变量，如果它们之间有任何差异，我们将转换列的数据类型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="b0b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集的信息看起来像，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/53881713ac859ff3cf97caa47950b8de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*Bni-N4cOBVtDiamYPY1g6g.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供— <strong class="bd od">创建所有必要虚拟变量后的数据集</strong></p></figure><p id="7a31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">异常值和缺失值<br/> </strong>现在，在继续建模之前，让我们再次检查数据集中的异常值和空值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="02b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出将是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/76a193a8a7d81a34fd8338591b4a3866.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*c1502tEynSFcFdng7ukoIg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">连续变量在不同百分位数的分布</strong></p></figure><p id="0021" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从分布数据中，我们可以看到数据中没有异常值。人数在逐渐增加。</p><p id="d18a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们检查数据集中缺失的值并处理数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/8f4acbb6ae78acce69213ed74e0505f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*BliD9zK4to7xLV6L8xwCng.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">列中的空值</strong></p></figure><p id="2bcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查列中null值的百分比，以便就如何处理这些值做出明智的决定。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="4892" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/795e2ce7ad3d5db21ff61ba328c441a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*Wd1wo-q35yYYeeDqvS5IUw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">空值的百分比</strong></p></figure><p id="35ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们观察，<code class="fe nw nx ny nz b">Total Charges</code>列的空值不到0.2%。因此，最好是删除这些行，而不是向其中输入一些值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="4e3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">处理空值后的输出将是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/343f4ee14c82b21c48a068604aa440ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*VQLZ4k-Q33ZEaNDZS3AtPA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者排序的图像— <strong class="bd od">删除列后空值的百分比</strong></p></figure><p id="ebb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们已经处理了空值，现在让我们继续构建模型。</p><h2 id="2e35" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">模型结构</h2><p id="e1be" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在建立模型之前，我们将数据分成<code class="fe nw nx ny nz b">train</code>和<code class="fe nw nx ny nz b">test</code>数据，类似于线性回归模型。因此，我们将使用<code class="fe nw nx ny nz b">train</code>数据建立模型，并根据<code class="fe nw nx ny nz b">test</code>数据评估模型。</p><h2 id="7d59" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">测试列车分离</h2><p id="73e2" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">通过使用<code class="fe nw nx ny nz b">sklearn</code>库，我们将导入<code class="fe nw nx ny nz b">test_train_split</code>来分割数据。但是在分割数据之前，我们将数据集分成两个数据帧X和y。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="8cd1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将删除<code class="fe nw nx ny nz b">customerID</code>列，因为它对我们的模型没有用，并删除<code class="fe nw nx ny nz b">churn</code>列，因为它是我们的目标变量。测试数据看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/6006476cf34dd60a340ddcd9b8201c6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uRyB2-GdQxevQDDyumlS4w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">拆分后的测试数据</strong></p></figure><p id="b042" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们将目标变量指定为y，并将数据分成测试集和训练集。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="de23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“y”数据集看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/5f43a13fd8dc0bbe5c45d3ea8db295ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*AAunxJng2vOCkQQFVrGyJw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od"> y数据集</strong></p></figure><h2 id="b6a4" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">缩放变量</h2><p id="e03a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如果我们观察数据，数据集中的所有数值都在不同的范围内。一个在100以下的区间，一个在200的区间，还有一个在1500以上。如果我们使用这些值构建模型，模型的系数将是不同的单位，因此不容易比较它们来做出明智的决定。</p><p id="d96e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们将重新调整所有连续变量。为此，我们将使用来自<code class="fe nw nx ny nz b">sklearn</code>的<code class="fe nw nx ny nz b">StandardScaler</code>方法。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="f279" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">缩放特征后的数据集，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/e770f970cdf27712303b6022b9953eac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VHHZhXyBgoO3WMwi4iPw8Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像— <strong class="bd od">缩放后的数据集</strong></p></figure><p id="2b3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查从数据集中流失的客户的百分比，以了解有多少客户转移到了其他网络。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="b957" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">产量是26.578498293515356 <br/>因此，我们有将近27%的流失率。</p><h2 id="db17" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">相关</h2><p id="dc1e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们看看变量之间的相关性。假设变量之间的相关性很高。在这种情况下，我们可以删除列，因为如果两个变量高度相关，那么就没有必要使用这两个变量来构建模型。我们可以用这两个变量中的一个来解释目标变量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="d112" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">变量之间的关联热图看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/e60c86335a5d0033cfbf7073ee394490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y9IesefsUwTgrn5pXezSIA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由作者提供的图片— <strong class="bd od">数据集中的关联热图</strong></p></figure><p id="2589" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们观察热图，一些变量彼此高度相关。所以我们将从数据集中删除这些变量。</p><p id="3663" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">删除高度相关的虚拟变量<br/> </strong>我们将从上面创建的X_train和X_test数据集中删除高度相关的变量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="2702" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们重新检查X_train数据集中的相关性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="0276" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">删除变量后的关联热图，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/40de1b3cf83ec043a8fb5e01b9afe790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tXdohH_OEFB2f1n1YHEIaQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">删除变量后的关联热图</strong></p></figure><p id="c3f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有一些相关性很高的变量，但是我们可以在建模的时候去掉。就这么办吧。</p><h2 id="7626" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">运行我们的第一个培训模型</h2><p id="58ff" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们将使用<code class="fe nw nx ny nz b">stasmodel</code>库来构建我们的第一个模型。让我们看看，如果我们考虑所有的变量，我们的模型是什么样的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="6773" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们第一个模型的统计数据是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/f6673de05ecdb149dd65905893962a2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*FIcp5qHbdcfXeTcPTb1osA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">我们第一款</strong>的统计</p></figure><p id="389b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的模型不是一个好的模型，因为一些变量具有高p值，这意味着这些变量是无关紧要的。我们将使用一种叫做RFE的方法来选择模型的前15个变量，并根据p值和VIF值删除不太重要的变量，而不是一次删除一个变量并一次又一次地建立模型。</p><h2 id="dc36" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">使用RFE的特征选择</h2><p id="3a0e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们将选择前15个变量，这有助于在我们的逻辑回归中建立模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="9502" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前15个变量是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/7569c5ef435c494ff45b7c11a1efb916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*0q2sE-JL8O8e_0COA8qK2g.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片— <strong class="bd od">使用RFE的前15个变量</strong></p></figure><p id="d98a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显示为<code class="fe nw nx ny nz b">True</code>的变量是我们感兴趣的变量，如果我们想要添加15个以上的变量，我们可以根据它们各自的排名逐一添加。</p><p id="273e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">使用上述15个变量建立模型<br/> </strong>让我们使用从RFE得到的15个变量建立第二个模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="3369" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型统计将是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/47a12fc189ab31d7d821fea150762d1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*fOatOwPjEj5PBuw0raD5Hw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供— <strong class="bd od">使用RFE变量的逻辑回归模型</strong></p></figure><p id="d16b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里我们使用来自<code class="fe nw nx ny nz b">statsmodels.api</code>库的<strong class="lb iu"> GLM(广义线性模型)</strong>方法。<code class="fe nw nx ny nz b">Binomial</code>in family参数告诉<code class="fe nw nx ny nz b">statsmodels</code>它需要用logit曲线拟合二项式数据(即目标变量只有两个值，在本例中为‘流失’和‘非流失’)。</p><p id="a2ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个简单的logit曲线看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/5679d73c8a545721fdb6263288546f2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b47_DfHypjqJjPBwZoMnAg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按统计数学-自己的工作，抄送BY-SA 4.0，<a class="ae ky" href="https://commons.wikimedia.org/w/index.php?curid=92801334" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/w/index.php?curid=92801334</a></p></figure><p id="dcb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">预测产出概率<br/> </strong>逻辑回归曲线给我们带来了<strong class="lb iu">搅动和不搅动的概率</strong>。我们可以通过简单地使用<strong class="lb iu">‘predict’</strong>函数来得到这些概率。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="7f46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预测的概率是</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/90a5b2ec9d9d0b0eb0054917b73a601e.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*JGUDNPpl7r1LTiRpHPiYaQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图片-预测概率</p></figure><p id="6cd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们创建一个包含实际流失列和预测概率的数据框架。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="d804" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述程序的数据框架如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/e02be6643cf513137ed01626d608f284.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*S1ZvQ2rQaPf9XLLATBc5jw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像——实际流失及其概率的数据框架</p></figure><p id="46e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于逻辑曲线给出的是概率，而不是<strong class="lb iu">‘流失’</strong>和<strong class="lb iu">‘非流失’</strong>的实际分类，我们需要找到一个<strong class="lb iu">阈值概率</strong>来将客户分类为‘流失’和‘非流失’</p><p id="9159" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，让我们选择0.5作为任意临界值，其中如果特定客户流失的概率小于0.5，我们会将其分类为<strong class="lb iu">“非流失”，</strong>，如果大于0.5，我们会将其分类为<strong class="lb iu">“流失”</strong></p><p id="42bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">创建新列<br/> </strong>在这个阶段，0.5的选择完全是任意的，我们将学习如何在“模型评估”中找到最佳临界值</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="2d42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">选择任意截止值后，数据帧如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/ae03cbdfca7f7b65158973dce5baaca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*9KVzyZZagQuSy3MuQdYvzw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像—任意截断后的数据帧</p></figure><p id="2276" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我们使用0.5的临界值将客户分为'<strong class="lb iu">流失客户</strong>'和'<strong class="lb iu">非流失客户</strong>'既然这些都是概率，那就一定会有误差。</p><p id="b9e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们会遇到两种类型的错误:</p><ul class=""><li id="0fe7" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">'流失</strong>'客户被错误归类为'<strong class="lb iu">非流失</strong>'</li><li id="3af6" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">'非流失</strong>'客户被错误分类为'<strong class="lb iu">流失</strong>'</li></ul><h2 id="ed82" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">混淆矩阵</h2><p id="2f14" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了找到这些错误和模型的健康状况，我们将使用一种叫做“混淆矩阵”的现象</p><p id="1926" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">典型的混淆矩阵如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/f14c0db8155b26f49efeac403465502b.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*OEKXfca_BMMiblfCUAnbWg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片-混淆矩阵</p></figure><blockquote class="nh"><p id="bb3b" class="ni nj it bd nk nl pa pb pc pd pe lu dk translated">注意:以上矩阵中显示的值只是一个示例</p></blockquote><p id="6019" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">如果我们观察上面的矩阵:</p><ul class=""><li id="17da" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">第一行第一列(1250)是实际有'<strong class="lb iu">未搅过</strong>'的客户数；该模型还预测它们为“<strong class="lb iu">未搅动</strong>”这一列被称为<strong class="lb iu">真阴性(TN)。</strong></li><li id="b9b3" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">第一行和第二列(150)是实际上'<strong class="lb iu">没有搅动</strong>，'但模型预测他们为'<strong class="lb iu">搅动</strong>'的客户数量这一列被称为<strong class="lb iu">假阳性(FP)。</strong></li><li id="b2bd" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">第二行第一列(290)是实际上'<strong class="lb iu">搅动了</strong>，'但是模型预测他们为'<strong class="lb iu">没有搅动</strong>'此列称为<strong class="lb iu">假阴性(FN)。</strong></li><li id="f5bd" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">第二行第二列(343)是实际“<strong class="lb iu">搅了</strong>”的客户数；此外，该模型还预测它们会被“搅动”<strong class="lb iu"/>。这一列被称为<strong class="lb iu">真阳性(TP)。</strong></li></ul><p id="72f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过从<code class="fe nw nx ny nz b">sklearn</code>导入<code class="fe nw nx ny nz b">metrics</code>库，在python中创建这个混淆矩阵。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="262f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述代码的混淆矩阵如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/6e91c61185e9128517b1e6d62fd73b5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*soAHxsrvJc_C50owGK1RTg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片-混淆矩阵</p></figure><p id="9980" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">评估模型的方法有很多种；我们为上述模型测量的指标之一是<strong class="lb iu">准确性</strong>。</p><h2 id="be8d" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">准确(性)</h2><p id="876c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">准确度是正确预测的标签的百分比。从矩阵中正确预测的标签将是:</p><ul class=""><li id="1a31" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">真阳性(TP): </strong>流失客户被预测为<strong class="lb iu">流失</strong></li><li id="f0a1" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">真阴性(TN): </strong>非流失客户被预测为非流失客户。</li></ul><p id="6d1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="pg">准确度=(正确预测的标签)/(标签总数)</em></p><p id="3aa4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">准确度= (TN+TP )/ (TN+FP+FN+TP)</p><p id="5236" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据我们上面的模型，</p><p id="b7b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TN = 3270<br/>FP = 365<br/>FN = 579<br/>TP = 708</p><p id="1409" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">精确度将是，</p><p id="db74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ACC =(3270+708)/(3270+365+579+708)= 0.808 = 80.8%</p><p id="4f61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们建立的模型大约有81%的准确性。</p><p id="c368" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以直接用python计算精度，</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="f260" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们通过上面的代码得到的精度是</p><pre class="kj kk kl km gt ph nz pi pj aw pk bi"><span id="8203" class="lv lw it nz b gy pl pm l pn po">0.8082080455099553</span></pre><h2 id="678b" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">检查VIF</h2><p id="53e7" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在让我们检查上述模型的VIF值，看看是否有任何变量高度相关。</p><blockquote class="nh"><p id="c689" class="ni nj it bd nk nl nm nn no np nq lu dk translated">我已经在我的上一篇文章“多元线性回归”中解释了VIF及其工作原理我们将遵循同样的程序。</p></blockquote><figure class="pp pq pr ps pt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="512c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看模型中变量的VIF值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/d29f1058850419b0803fb44299a37a3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*QVs1PbHOSJMH5x0I46vnrQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像-用于查找多重共线性的VIF值</p></figure><p id="530e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">高VIF有几个变量。最好放弃这些变量。变量<code class="fe nw nx ny nz b">PhoneService</code>具有最高的VIF。因此，让我们从放弃它开始，重新构建模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="2729" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面代码的模型是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/f639c5116754953be652c063ad7ed201.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*Ei8GtG2I2PsvkjOyp77l3Q.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像-逻辑回归模型统计</p></figure><p id="effb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将预测这些值，并打印由原始流失值和预测值组成的数据帧。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="b397" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据帧看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/ba50fe0c235c2273bd1feae9d84e53d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*b5nG5V3QseS7--JJWLumHw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像-原始值和预测值的数据框架</p></figure><p id="c26e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查模型的准确性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="87a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型的准确性将是</p><pre class="kj kk kl km gt ph nz pi pj aw pk bi"><span id="2968" class="lv lw it nz b gy pl pm l pn po">0.8051605038602194</span></pre><p id="b5ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这与原来的差距并不大。我们必须重新检查VIF值，删除变量，建立模型，并计算精确度。我们将继续下去，直到每个变量的VIF值都小于5。</p><p id="656c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于最终的模型，在反复遵循上述过程后，我们得到的混淆矩阵是，</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="9e67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">矩阵看起来像这样，</p><pre class="kj kk kl km gt ph nz pi pj aw pk bi"><span id="9220" class="lv lw it nz b gy pl pm l pn po">array([[3269,  366],<br/>       [ 595,  692]],)</span></pre><p id="e5a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终矩阵的精确度= 0.80。18866.888888888687</p><p id="34cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，出现的问题是——准确性是我们用来评估我们建立的模型的好坏的唯一标准吗？<br/>答案是<strong class="lb iu">否</strong></p><p id="39c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">考虑一个例子:</strong>假设我们试图为癌症患者建立一个逻辑回归模型，其中1表示患者“患癌”，0表示患者“未患癌”在这种情况下，如果我们错误地预测一些患者“没有患癌症”，这将是非常危险的。在这种情况下，我们不考虑整体精度，而是正确预测1。</p><p id="4d91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在另一种情况下，如果我们为银行构建一个模型来阻止客户识别欺诈，其中1表示阻止，0表示不阻止，我们更关心0是否正确。是因为我们不想把好客户挡在门外。</p><p id="4eac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">理解我们试图解决的整体业务问题，了解我们想要使用的度量标准是至关重要的。</p><p id="23a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，除了<strong class="lb iu">准确性，</strong>我们还有另外三个更重要的指标:</p><ul class=""><li id="6fb8" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">灵敏度/召回率</strong></li><li id="4fa9" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">特异性</strong></li><li id="30b7" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">精度</strong></li></ul><h2 id="d8d6" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">灵敏度/召回率</strong></h2><p id="a7da" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">对于癌症类型的问题，我们使用敏感性。所以我们应该建立一个模型，这个模型的结果是高灵敏度，即<strong class="lb iu"> FN(假阴性)</strong>的值应该尽可能的低。</p><blockquote class="nh"><p id="c59e" class="ni nj it bd nk nl nm nn no np nq lu dk translated">灵敏度= (TP)/(TP+FN)</p></blockquote><h2 id="f670" class="lv lw it bd lx ly pw dn ma mb px dp md li py mf mg lm pz mi mj lq qa ml mm mn bi translated"><strong class="ak">特异性</strong></h2><p id="42cb" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">对于欺诈交易类型的案件，我们建立一个具有高特异性的模型，即<strong class="lb iu"> FP(False Positive) </strong>的值应该尽可能低。</p><blockquote class="nh"><p id="15a3" class="ni nj it bd nk nl nm nn no np nq lu dk translated">特异性= (TN)/(TN+FP)</p></blockquote><h2 id="1f16" class="lv lw it bd lx ly pw dn ma mb px dp md li py mf mg lm pz mi mj lq qa ml mm mn bi translated"><strong class="ak">精度</strong></h2><p id="8687" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如果我们想要建立一个模型来预测一封电子邮件是否是垃圾邮件，我们将使用精确度指标<strong class="lb iu">。</strong>在这种情况下，我们必须开发具有高精度的模型，即<strong class="lb iu"> FP(假阳性)</strong>的值应该尽可能低。</p><blockquote class="nh"><p id="870b" class="ni nj it bd nk nl nm nn no np nq lu dk translated">精度= (TP)/(TP+FP)</p></blockquote><p id="62f4" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">现在，让我们找出我们之前建立的最终模型的灵敏度和特异性的值。</p><p id="8b3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将从最终矩阵中分配TP、TN、FP和FN值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="1cad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，<strong class="lb iu">混淆</strong>是我们之前创建的矩阵的名字。</p><p id="2849" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们找出不同指标的值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="4ad0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述代码的灵敏度和特异性值是，</p><pre class="kj kk kl km gt ph nz pi pj aw pk bi"><span id="8a8c" class="lv lw it nz b gy pl pm l pn po"><strong class="nz iu"># Sensitivity</strong><br/>0.5376845376845377</span><span id="be2f" class="lv lw it nz b gy qb pm l pn po"><strong class="nz iu"># Specificity</strong><br/>0.8993122420907841</span></pre><p id="b4cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们的模型具有<strong class="lb iu">高准确性(80.4%) </strong>和<strong class="lb iu">高特异性(89.9%) </strong>，但<strong class="lb iu">低</strong><strong class="lb iu">【53.7%)</strong>，我们对识别可能流失的客户感兴趣，因此我们需要处理这一点。但是是什么导致了如此低的敏感度呢？</p><p id="ebbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们记得，当预测模型为0和1时，我们选择了0.5的截止值，这个截止值是随机选择的，没有特定的逻辑。</p><p id="e123" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预测的标签完全取决于我们选择的截止值。对于低截止值，我们将有更多的客户预测为1，这意味着更多的客户被识别为“流失”类似地，对于高截止值，我们将低数量的客户预测为0，这意味着高数量的客户被识别为“非流失客户”</p><h2 id="acc2" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">寻找最佳截止点</h2><p id="451a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在我们的问题中，我们试图找到一个最佳的临界值，在灵敏度和特异性之间取得平衡。首先，我们将找到从0.1到0.9的不同临界值的预测值</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="9d7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不同截止值下的流失概率看起来像，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qc"><img src="../Images/8ace2ad23c76ca6bd4e1376a14cd3d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C2jlhuDnD0PkUkV1Y_P_8g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像—不同截止点的流失概率</p></figure><p id="6779" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们计算这些临界值的准确性、敏感性和特异性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="7827" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">度量的不同值将是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/5331556f90fcccf0c172ae862804847b.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*Cd6aErIqLVlW7a88myUQ0g.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像—准确性、敏感性和特异性值</p></figure><p id="e38b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们绘制一个线形图，看看在这些概率下准确性、敏感性和特异性是如何表现的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="3f0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线形图如下所示，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/b19e507d112140a444251e9de0e6b241.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*SE-YPfaTv6dw5am5luRNrg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像-折线图</p></figure><p id="cdc2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的曲线来看，0.3或稍大一点是将其作为截止概率的最佳点。为了便于理解，我们将0.3作为临界值。</p><p id="5927" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用这个0.3作为最终截止值来预测模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="ccf0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出将是</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qf"><img src="../Images/a1fd42bbfb2cfc9053d8190ffa5ad731.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-YRuj_9BAHY9holKvLnBmA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片—最终预测</p></figure><p id="3faa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们找出准确性、特异性、敏感性和混淆矩阵。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="b0a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述代码的输出是:</p><pre class="kj kk kl km gt ph nz pi pj aw pk bi"><span id="4052" class="lv lw it nz b gy pl pm l pn po"><strong class="nz iu"># Accuracy</strong><br/>0.771434376269809</span><span id="8448" class="lv lw it nz b gy qb pm l pn po"><strong class="nz iu"># Confusion Matrix<br/></strong>array([[2793,  842],<br/>       [ 283, 1004]])</span><span id="6edc" class="lv lw it nz b gy qb pm l pn po"><strong class="nz iu"># Sensitivity</strong><br/>0.7801087801087802</span><span id="8318" class="lv lw it nz b gy qb pm l pn po"><strong class="nz iu"># Specificity<br/></strong>0.768363136176066</span></pre><p id="7055" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们有了最终的模型，让我们根据测试数据来评估我们的模型。</p><h2 id="30d7" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">模型评估</h2><p id="09e0" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们使用最终模型对测试数据进行预测。首先，我们将扩展测试数据，类似于我们在分割后对训练数据所做的那样。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="e47f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测试集看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qg"><img src="../Images/758aa80123437390527e5543f7968a7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i7CmktbWJY5xyl0nTXmbNw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者排序的图像—缩放后的测试集</p></figure><p id="6c8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们现在对测试数据进行预测，仔细遵循下面的代码；我们正在对数据集进行许多更改。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="3c18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终数据集是在所有更改完成后生成的，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qh"><img src="../Images/fb48c9cc5efbafcba9a79937d7963b01.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*L_ijNL6aaqUql71Tmf69vg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像-最终数据集</p></figure><p id="e215" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了便于理解，让我们重命名该列并重新排列它们。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="f30b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集看起来像，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/8fe04234a2ee3efd7665b297e0c22ff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*PjD_rKQPnZnpWc6vx2nbrQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像-最终数据集</p></figure><p id="27b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用0.3作为截止值来预测模型，这是我们之前在训练数据集上获得的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="95f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测试集的预测值是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qj"><img src="../Images/39e53a1221a72d70c7f0b2265fe9e6ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*HtGDTOAeQ4hPiw5LfXHY-A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的图像-预测值</p></figure><p id="de77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查测试数据的准确性、敏感性和特异性值，并进行比较。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="29ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测试集的值是:</p><pre class="kj kk kl km gt ph nz pi pj aw pk bi"><span id="3994" class="lv lw it nz b gy pl pm l pn po"><strong class="nz iu"># Accuracy</strong><br/>0.7440758293838863</span><span id="3b97" class="lv lw it nz b gy qb pm l pn po"><strong class="nz iu"># Confusion Matrix</strong><br/>array([[1150,  378],<br/>       [ 162,  420]],)</span><span id="eaa2" class="lv lw it nz b gy qb pm l pn po"><br/><strong class="nz iu"># Sensitivity</strong><br/>0.7216494845360825</span><span id="bc11" class="lv lw it nz b gy qb pm l pn po"><strong class="nz iu"># Specificity<br/></strong>0.7526178010471204</span></pre><p id="40be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们比较训练数据集的准确性，敏感性和特异性值，没有太大的变化。因此，我们建立的模型足以预测任何未来的电信数据。</p><h1 id="35f6" class="qk lw it bd lx ql qm qn ma qo qp qq md jz qr ka mg kc qs kd mj kf qt kg mm qu bi translated">结论</h1><p id="8a10" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">总而言之，我们已经看到了构建基本逻辑回归模型所需的步骤。我们还可以学习更多的概念，如ROC曲线、精确度、召回率等。但是要构建一个基本的逻辑回归模型，我们在本文中看到的过程已经足够好了。一旦我们掌握了这个过程，我们就可以在这个模型中探索更多的东西。</p><p id="d933" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">感谢您阅读</strong>和<strong class="lb iu">快乐编码！！！</strong></p><h1 id="999c" class="qk lw it bd lx ql qm qn ma qo qp qq md jz qr ka mg kc qs kd mj kf qt kg mm qu bi translated">点击这里查看我以前的文章</h1><ul class=""><li id="df30" class="mt mu it lb b lc mo lf mp li qv lm qw lq qx lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/multiple-linear-regression-model-using-python-machine-learning-d00c78f1172a"> <strong class="lb iu">使用Python的多元线性回归模型:机器学习</strong> </a></li><li id="eb36" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/simple-linear-regression-model-using-python-machine-learning-eab7924d18b4"> <strong class="lb iu">使用Python的简单线性回归模型:机器学习</strong> </a></li><li id="38ff" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/exploratory-data-analysis-eda-python-87178e35b14"> <strong class="lb iu">探索性数据分析(EDA): Python </strong> </a></li><li id="eef6" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/central-limit-theorem-clt-data-science-19c442332a32"> <strong class="lb iu">中心极限定理(CLT):数据科学</strong> </a></li><li id="6e66" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/inferential-statistics-data-analysis-e59adc75c6eb"> <strong class="lb iu">推断统计:数据分析</strong> </a></li><li id="6ef7" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/seaborn-python-8563c3d0ad41"><strong class="lb iu">Seaborn:Python</strong>T27】</a></li><li id="067f" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://levelup.gitconnected.com/pandas-python-e69f4829fee1" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">熊猫:蟒蛇</strong> </a></li><li id="6a14" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://levelup.gitconnected.com/matplotlib-python-ecc7ba303848" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">Matplotlib:Python</strong></a></li><li id="67c5" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://medium.com/coderbyte/numpy-python-f8c8f2bbd13e" rel="noopener"> <strong class="lb iu"> NumPy: Python </strong> </a></li></ul><h1 id="a71c" class="qk lw it bd lx ql qm qn ma qo qp qq md jz qr ka mg kc qs kd mj kf qt kg mm qu bi translated">参考</h1><ul class=""><li id="8ef5" class="mt mu it lb b lc mo lf mp li qv lm qw lq qx lu my mz na nb bi translated"><strong class="lb iu">机器学习—逻辑回归:</strong><a class="ae ky" href="https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_classification_algorithms_logistic_regression.htm" rel="noopener ugc nofollow" target="_blank">https://www . tutorialspoint . com/Machine _ Learning _ with _ python/Machine _ Learning _ with _ python _ classification _ algorithms _ Logistic _ Regression . htm</a></li><li id="709b" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">逻辑回归:</strong><a class="ae ky" href="https://machinelearningmastery.com/logistic-regression-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/Logistic-Regression-for-machine-learning/</a></li><li id="b08a" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">逻辑回归:</strong><a class="ae ky" href="https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html" rel="noopener ugc nofollow" target="_blank">https://ml-cheat sheet . readthedocs . io/en/latest/Logistic _ Regression . html</a></li><li id="5214" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">用于机器学习和分类的逻辑回归:</strong><a class="ae ky" href="https://kambria.io/blog/logistic-regression-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://kambria . io/blog/Logistic-Regression-For-Machine-Learning/</a></li></ul></div></div>    
</body>
</html>