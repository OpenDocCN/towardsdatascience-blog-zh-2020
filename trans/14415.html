<html>
<head>
<title>Knowledge Transfer in Self Supervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自我监督学习中的知识转移</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/knowledge-transfer-in-self-supervised-learning-680208f2092f?source=collection_archive---------40-----------------------#2020-10-04">https://towardsdatascience.com/knowledge-transfer-in-self-supervised-learning-680208f2092f?source=collection_archive---------40-----------------------#2020-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4c71" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自我监督学习是一个有趣的研究领域，其目标是在没有任何人工注释的情况下从无标签数据中学习丰富的表示。</p><p id="cf12" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这可以通过创造性地公式化一个问题来实现，比如你使用数据本身的一部分作为标签，并试图预测它。这样的公式被称为借口任务。</p><p id="e5a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，您可以设置一个托词任务，在给定灰度版本的情况下预测图像的彩色版本。同样，您可以移除图像的一部分，并训练一个模型从周围环境中预测该部分。还有很多这样的<a class="ae kl" href="https://amitness.com/2020/02/illustrated-self-supervised-learning/" rel="noopener ugc nofollow" target="_blank">借口任务</a>。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/2a35daa64682699951f9e36d57c125ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cJxdlFmUUEhiT9Qt.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">作者图片</em></p></figure><p id="0a4d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过在借口任务上的预训练，希望模型将学习有用的表示。然后，我们可以对模型进行微调，以完成下游任务，如图像分类、对象检测和语义分割，只需一小组已标记的训练数据。</p><h1 id="0c20" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">评估表示的挑战</h1><p id="9c33" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">所以借口任务可以帮助我们学习表征。但是，这提出了一个问题:</p><blockquote class="mg mh mi"><p id="6fdb" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated"><em class="iq">如何确定一个有学问的表征有多好？</em></p></blockquote><p id="308a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目前，衡量表示的标准方法是在一组标准任务和基准数据集上进行评估。</p><ul class=""><li id="79c9" class="mn mo iq jp b jq jr ju jv jy mp kc mq kg mr kk ms mt mu mv bi translated"><strong class="jp ir">线性分类</strong>:使用冻结特征的图像网络分类</li><li id="7271" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk ms mt mu mv bi translated"><strong class="jp ir">低数据状态</strong>:仅使用1%到10%数据的ImageNet分类</li><li id="ee0f" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk ms mt mu mv bi translated"><strong class="jp ir">迁移学习</strong>:PASCAL VOC上的对象分类、对象检测和语义分割</li></ul><p id="5177" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，上述评估方法要求我们对借口任务和目标任务使用相同的模型架构。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/9e83deebd71bedb15f33b21d1bf47a04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/0*bpsDGJWMct12kvhJ.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">作者图片</em></p></figure><p id="ae7c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这带来了一些有趣的挑战:</p><ol class=""><li id="cd15" class="mn mo iq jp b jq jr ju jv jy mp kc mq kg mr kk nc mt mu mv bi translated">对于借口任务，我们的目标是在大规模的未标记数据集上学习，因此更深的模型(例如ResNet)将帮助我们学习更好的表示。</li><li id="7812" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk nc mt mu mv bi translated">但是，对于下游任务，我们更喜欢实际应用的浅层模型(例如AlexNet)。因此，我们目前在设计借口任务时必须考虑这一限制。</li><li id="4f90" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk nc mt mu mv bi translated">如果一些方法使用更简单的架构，而另一些方法使用更深入的架构，那么就很难公平地比较哪种前文本任务更好。</li><li id="7cf1" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk nc mt mu mv bi translated">我们无法将从托词任务中学到的表征与手工制作的特征(如HOG)进行比较。</li><li id="67d4" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk nc mt mu mv bi translated">我们可能希望在借口任务中利用几个数据域，如声音、文本和视频，但目标任务可能会限制我们的设计选择。</li><li id="c91f" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk nc mt mu mv bi translated">在托词任务上训练模型可能学到对一般视觉识别没有用的额外知识。目前，最终的特定于任务的层被忽略，并且仅取特定卷积层的权重或特征。</li></ol><h1 id="54f2" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">知识转移</h1><p id="c2b6" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">Noroozi等人在2018年的论文<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">“通过知识转移促进自我监督学习”</a>中提出了一个简单的想法来解决这些问题。</p><h1 id="8d8f" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">直觉</h1><p id="a5f1" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">作者观察到，在一个好的表示空间中，语义相似的数据点应该靠得很近。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nd"><img src="../Images/b420c9d61fa1527169c72cc772319bc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lVEHRqifwe73rIFH.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><em class="lc">作者图片</em></p></figure><p id="d5eb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在常规的监督分类中，图像语义相似的信息通过由人标注的标签来编码。在这种标签上训练的模型将具有对语义相似的图像进行分组的表示空间。</p><p id="4593" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，对于自我监督学习中的文本前任务，目标是隐含地学习使相同类别图像相似而不同类别图像不相似的度量。因此，如果我们能够以某种方式将语义相关的图像编码到相同的标签，我们可以提供对所学习的表示的鲁棒估计。</p><h1 id="062e" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">总体框架</h1><p id="917d" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">作者提出了一个新的框架，将知识从深度自我监督模型转移到一个独立的浅层下游模型。您可以为借口任务和下游任务使用不同的模型架构。</p><p id="e5a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">关键创意:</strong></p><blockquote class="mg mh mi"><p id="0739" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated"><em class="iq">对来自托词任务的特征进行聚类，并分配聚类中心作为未标记图像的伪标记。然后，在伪标签上重新训练具有目标任务架构的小网络，以预测伪标签并学习新颖的表示。</em></p></blockquote><p id="20db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">端到端流程描述如下:</p><h2 id="f11b" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">1.借口任务</h2><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/862a7c7a3805394b0bd867ab9157c151.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*ELx8QCImZGOg49kIT-EGQA.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><p id="dbc3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我们选择一些深度网络架构，并在一些数据集上根据我们选择的一些借口任务来训练它。在模型被训练之后，我们可以从一些中间层提取特征。</p><h2 id="c4c3" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">2.k均值聚类</h2><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/b0e36d4f62f696814b2504ed4cecb04b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*37rVRb0BBPXoG6wYSgi1qg.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><p id="7161" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于数据集中所有未标记的图像，我们从借口任务模型计算特征向量。然后，我们运行K-means聚类来分组语义相似的图像。其想法是，聚类中心将与ImageNet中的类别保持一致。</p><p id="7ced" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在论文中，作者在一个Titan X GPU上运行K-means 4小时，将130万张图像聚类成2000个类别。</p><h2 id="29b5" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">3.伪标记</h2><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/934a0527fc6585fdec6893ce463466c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*Tp-8ZAPY30uhBOWnS2MJqg.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><p id="5191" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">聚类中心被视为伪标签。我们可以使用与上述步骤相同的数据集，也可以使用不同的数据集本身。然后，我们计算这些图像的特征向量，并为每个图像找到最近的聚类中心。该聚类中心被用作伪标签。</p><h2 id="0dab" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">4.伪标签训练</h2><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/597bcc9fbcd37a9e4a16b8a6adb9ddea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*_SWht4AFNV44mJWmfQTdaA.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><p id="8d03" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们采用将用于下游任务的模型架构，并训练它将未标记的图像分类到伪标记中。因此，目标架构将学习新的表示，使得它将在预训练的特征空间中最初接近的图像映射到接近点。</p><h1 id="4e3d" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">知识转移的优势</h1><p id="c753" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">我们看到了如何通过对特征进行聚类，然后使用伪标签，我们可以将来自任何借口任务表示的知识带入像AlexNet这样的公共参考模型。</p><p id="954d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们现在可以轻松地比较不同的托辞任务，即使它们使用不同的体系结构和不同的数据域进行培训。这也允许我们通过使用深度模型和挑战借口任务来改进自我监督的方法。</p><h1 id="4639" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">这个框架的效果如何？</h1><p id="ab14" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">为了定量评估这一想法，作者进行了如下实验:</p><h1 id="4dda" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">a.增加借口任务的复杂性(Jigsaw++)</h1><p id="b8e8" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">为了评估他们的方法，作者进行了一项名为“拼图”的古老的类似拼图的借口任务，其中我们需要预测用于随机洗牌3*3正方形图像网格的排列。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/086b2a063c5e20d1bd54a985843974e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*W0I4EAIjG9KW7Od39btlNg.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><p id="bd20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">他们通过在一些随机位置用另一张随机图像的瓷砖随机替换0到2个瓷砖来扩展这项任务。这增加了难度，因为现在我们需要仅使用剩余的补丁来解决问题。新的托辞任务被称为“Jigsaw++”。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nv"><img src="../Images/502c2babf31c6c8de3ced655be52280f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mL1Z8twOVATdA92EMa9Dhg.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><p id="1526" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在论文中，他们使用了701个最小汉明距离为3的排列。它们在每个图像块上独立地应用平均值和标准偏差归一化。他们还使图像在70%的时间内灰度化，以防止网络用低级统计数据作弊。</p><h1 id="4e42" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">b.使用更深层次的网络来解决借口任务</h1><p id="5c61" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">作者使用VGG-16解决借口任务和学习表征。随着VGG-16的容量增加，它可以更好地处理“拼图++”任务的复杂性增加，从而提取更好的表示。</p><h1 id="3ac4" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">c.将知识传回AlexNet</h1><p id="85b7" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">来自VGG-16的代表被聚类，聚类中心被转换成伪标签。然后，训练AlexNet对伪标签进行分类。</p><h1 id="4867" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">d.在评估数据集上微调AlexNet</h1><p id="f265" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">对于下游任务，用来自伪标签分类的权重初始化AlexNet模型的卷积层，并且随机初始化完全连接的层。然后，预训练的AlexNet在各种基准数据集上进行微调。</p><h1 id="7b77" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">e.结果</h1><p id="a503" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">使用像VGG-16这样的更深层次的网络会导致更好的表示和伪标签，也会在基准测试任务中产生更好的结果。它在2018年的几个基准测试中获得了最先进的结果，并进一步缩小了监督和自我监督方法之间的差距。</p><h2 id="114c" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">1.PASCAL VOC的迁移学习</h2><p id="f51b" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">作者在PASCAL VOC 2007数据集上测试了他们的方法，并在PASCAL VOC 2012数据集上测试了他们的方法。</p><h2 id="43bd" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">洞察力</h2><ul class=""><li id="8d34" class="mn mo iq jp b jq mb ju mc jy nw kc nx kg ny kk ms mt mu mv bi translated">用VGG16训练Jigsaw++并使用AlexNet预测聚类给出了最好的性能。</li><li id="2686" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk ms mt mu mv bi translated">切换到具有挑战性的托词任务“Jigsaw++”比“Jigsaw”提高了性能。</li><li id="a43f" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk ms mt mu mv bi translated">在Jigsaw++和下游任务中使用相同架构AlexNet时，知识转移不会产生显著影响。</li></ul><h2 id="d501" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">2.ImageNet上的线性分类</h2><p id="efa9" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">在这种情况下，线性分类器在不同的卷积层上根据从AlexNet提取的特征进行训练。对于ImageNet，使用VGG-16并使用聚类将知识转移到AlexNet会带来2%的大幅提升。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/2f119cfed0eb2f909c7aa4d636cb5136.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/0*2pVkEGvxJtaN_SkO.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><h2 id="e97f" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">3.ImageNet上的非线性分类</h2><p id="2ca2" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">对于非线性分类器，使用VGG-16并使用聚类将知识转移到AlexNet会在ImageNet上给出最佳性能。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/72d13bcb7c5e93407a419415f443d24e.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/0*G1JLbMXaiwIT5ujB.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><h1 id="106d" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">论文中的其他见解</h1><h2 id="2e80" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">1.集群数量如何影响性能？</h2><p id="ed69" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">网络不会受到集群数量的显著影响。作者测试了AlexNet在对象检测任务中对来自不同数量集群的伪标签进行的训练。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/1af9b36d5d526c23abed4ac4901bad94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/0*viLOQ4lXtAI0SOWd.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><h2 id="a0f9" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">2.这和知识蒸馏有什么不同？</h2><p id="d39d" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">知识转移与知识升华有着本质的不同。这里，目标是只保留来自表示的图像的聚类关联，并将其转移到目标模型。不像蒸馏，我们不对老师的确切输出做任何回归。</p><h2 id="edb5" class="ne le iq bd lf nf ng dn lj nh ni dp ln jy nj nk lr kc nl nm lv kg nn no lz np bi translated">3.你能在聚类和预测伪标签中使用不同的数据集吗？</h2><p id="60a2" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">是的，这种方法很灵活，你可以在一个数据集上进行预训练，在另一个数据集上进行聚类，并为第三个数据集获取伪标签。</p><p id="ad3a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作者做了一个实验，他们在ImageNet的表示上训练聚类，然后在“位置”数据集上计算聚类中心，以获得伪标签。对象分类的性能仅略有下降(-1.5%)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oc"><img src="../Images/cd17559513602c9eddbd8ccc4993ac37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GSu6a-euJ-3acJ6t.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片来自<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">诺鲁齐等人</a></p></figure><h1 id="6385" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">结论</h1><p id="daf7" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">因此，知识转移是一种简单而有效的方式来将表示从深层模型映射到浅层模型。</p><h1 id="c3d9" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">参考</h1><ul class=""><li id="92a1" class="mn mo iq jp b jq mb ju mc jy nw kc nx kg ny kk ms mt mu mv bi translated">Mehdi Noroozi等人，<a class="ae kl" href="https://arxiv.org/abs/1805.00385" rel="noopener ugc nofollow" target="_blank">“通过知识转移促进自我监督学习”</a></li><li id="fd81" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk ms mt mu mv bi translated">Mehdi Noroozi等人，<a class="ae kl" href="https://arxiv.org/abs/1603.09246" rel="noopener ugc nofollow" target="_blank">“通过解决拼图游戏对视觉表征的无监督学习”</a></li><li id="a1bb" class="mn mo iq jp b jq mw ju mx jy my kc mz kg na kk ms mt mu mv bi translated">景岛乐·冈野原等，<a class="ae kl" href="https://www.aclweb.org/anthology/P07-1010/" rel="noopener ugc nofollow" target="_blank">“一个带有伪否定样本的判别性语言模型”</a></li></ul></div><div class="ab cl od oe hu of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="ij ik il im in"><p id="0841" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mj">原载于2020年10月4日https://amitness.com</em><em class="mj"/><a class="ae kl" href="https://amitness.com/knowledge-transfer/" rel="noopener ugc nofollow" target="_blank"><em class="mj">。</em></a></p></div></div>    
</body>
</html>