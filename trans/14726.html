<html>
<head>
<title>Cleaning Text Data with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python清理文本数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cleaning-text-data-with-python-b69b47b97b76?source=collection_archive---------2-----------------------#2020-10-11">https://towardsdatascience.com/cleaning-text-data-with-python-b69b47b97b76?source=collection_archive---------2-----------------------#2020-10-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/98d6096dbebf67469ae19f37e1e74955.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nHxKi9OMy-9j11bVHlfq6w.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">安妮·斯普拉特在<a class="ae jg" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="0225" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">你需要的只是NLTK和re库。</h2></div><p id="8051" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated">数据格式并不总是表格格式。随着我们进入大数据时代，数据以非常多样化的格式出现，包括图像、文本、图表等等。</p><p id="91ed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为格式相当多样，从一种数据到另一种数据，所以将这些数据预处理成计算机可读的格式是非常必要的。</p><p id="6b84" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我想向您展示如何使用Python预处理文本数据。如题所示，你所需要的就是NLTK和re库。</p><p id="c43b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了向您展示这是如何工作的，我将从一个名为<a class="ae jg" href="https://www.kaggle.com/c/nlp-getting-started/overview" rel="noopener ugc nofollow" target="_blank">的Kaggle竞赛中获取一个数据集。灾难推文NLP</a>。</p><blockquote class="md me mf"><p id="9272" class="ky kz mg la b lb lc kk ld le lf kn lg mh li lj lk mi lm ln lo mj lq lr ls lt im bi translated">我已经创建了一个谷歌Colab笔记本，如果你想跟着我一起。要访问，你可以点击这个链接<a class="ae jg" href="https://colab.research.google.com/drive/1DzUJllfwvD0Ct_GxknWCIPygejZohwJY?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a></p></blockquote></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="e80d" class="mr ms jj bd mt mu mv mw mx my mz na nb kp nc kq nd ks ne kt nf kv ng kw nh ni bi translated">该过程</h1><h2 id="9541" class="nj ms jj bd mt nk nl dn mx nm nn dp nb lh no np nd ll nq nr nf lp ns nt nh nu bi translated">将文本小写</h2><p id="6664" class="pw-post-body-paragraph ky kz jj la b lb nv kk ld le nw kn lg lh nx lj lk ll ny ln lo lp nz lr ls lt im bi translated">在我们开始处理文本之前，最好先把所有的字符都小写。我们这样做的原因是为了避免任何区分大小写的过程。</p><p id="18cc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设我们想从字符串中删除停用词，我们使用的技术是将非停用词组合成一个句子。如果我们不是小写那些，停止字不能被发现，它将导致相同的字符串。这就是为什么降低文本的大小写是必要的。</p><p id="eb69" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在Python中做到这一点很容易。代码看起来像这样，</p><pre class="oa ob oc od gt oe of og oh aw oi bi"><span id="6e32" class="nj ms jj of b gy oj ok l ol om"><strong class="of jk"># Example</strong><br/>x = "Watch This Airport Get Swallowed Up By A Sandstorm In Under A Minute <a class="ae jg" href="http://t.co/TvYQczGJdy" rel="noopener ugc nofollow" target="_blank">http://t.co/TvYQczGJdy</a>"</span><span id="b5ae" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Lowercase the text</strong><br/>x = x.lower()</span><span id="eae5" class="nj ms jj of b gy on ok l ol om">print(x)</span><span id="069b" class="nj ms jj of b gy on ok l ol om"><strong class="of jk">&gt;&gt;&gt; watch this airport get swallowed up by a sandstorm in under a minute </strong><a class="ae jg" href="http://t.co/tvyqczgjdy" rel="noopener ugc nofollow" target="_blank"><strong class="of jk">http://t.co/tvyqczgjdy</strong></a></span></pre><h2 id="cb0f" class="nj ms jj bd mt nk nl dn mx nm nn dp nb lh no np nd ll nq nr nf lp ns nt nh nu bi translated">删除Unicode字符</h2><p id="eac5" class="pw-post-body-paragraph ky kz jj la b lb nv kk ld le nw kn lg lh nx lj lk ll ny ln lo lp nz lr ls lt im bi translated">一些推文可能包含Unicode字符，当我们以ASCII格式看到它时，它是不可读的。大多数情况下，这些字符用于表情符号和非ASCII字符。为了消除这一点，我们可以使用这样的代码，</p><pre class="oa ob oc od gt oe of og oh aw oi bi"><span id="957a" class="nj ms jj of b gy oj ok l ol om"><strong class="of jk"># Example</strong><br/>x = "Reddit Will Now QuarantineÛ_ <a class="ae jg" href="http://t.co/pkUAMXw6pm" rel="noopener ugc nofollow" target="_blank">http://t.co/pkUAMXw6pm</a> #onlinecommunities #reddit #amageddon #freespeech #Business <a class="ae jg" href="http://t.co/PAWvNJ4sAP" rel="noopener ugc nofollow" target="_blank">http://t.co/PAWvNJ4sAP</a>"</span><span id="b8b3" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Remove unicode characters</strong><br/>x = x.encode('ascii', 'ignore').decode()</span><span id="625f" class="nj ms jj of b gy on ok l ol om">print(x)</span><span id="5a82" class="nj ms jj of b gy on ok l ol om"><strong class="of jk">&gt;&gt;&gt; Reddit Will Now Quarantine_ </strong><a class="ae jg" href="http://t.co/pkUAMXw6pm" rel="noopener ugc nofollow" target="_blank"><strong class="of jk">http://t.co/pkUAMXw6pm</strong></a><strong class="of jk"> #onlinecommunities #reddit #amageddon #freespeech #Business </strong><a class="ae jg" href="http://t.co/PAWvNJ4sAP" rel="noopener ugc nofollow" target="_blank"><strong class="of jk">http://t.co/PAWvNJ4sAP</strong></a></span></pre><h2 id="7e50" class="nj ms jj bd mt nk nl dn mx nm nn dp nb lh no np nd ll nq nr nf lp ns nt nh nu bi translated">删除停用词</h2><p id="1cc9" class="pw-post-body-paragraph ky kz jj la b lb nv kk ld le nw kn lg lh nx lj lk ll ny ln lo lp nz lr ls lt im bi translated">这样做之后，我们可以删除属于停用词的单词。停用词是一种对文本意义没有显著贡献的词。因此，我们可以删除这些词。为了检索停用词，我们可以从NLTK库中下载一个语料库。这是如何做到这一点的代码，</p><pre class="oa ob oc od gt oe of og oh aw oi bi"><span id="7d8b" class="nj ms jj of b gy oj ok l ol om">import nltk<br/>nltk.download()<br/><strong class="of jk"># just download all-nltk</strong></span><span id="a6e4" class="nj ms jj of b gy on ok l ol om">stop_words = stopwords.words("english")</span><span id="7d37" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Example</strong><br/>x = "America like South Africa is a traumatised sick country - in different ways of course - but still messed up."</span><span id="bc61" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Remove stop words</strong><br/>x = ' '.join([word for word in x.split(' ') if word not in stop_words])</span><span id="95c9" class="nj ms jj of b gy on ok l ol om">print(x)</span><span id="77a5" class="nj ms jj of b gy on ok l ol om"><strong class="of jk">&gt;&gt;&gt; America like South Africa traumatised sick country - different ways course - still messed up.</strong></span></pre><h2 id="5da2" class="nj ms jj bd mt nk nl dn mx nm nn dp nb lh no np nd ll nq nr nf lp ns nt nh nu bi translated">删除提及、标签、链接等术语。</h2><p id="f90a" class="pw-post-body-paragraph ky kz jj la b lb nv kk ld le nw kn lg lh nx lj lk ll ny ln lo lp nz lr ls lt im bi translated">除了我们删除Unicode和停用词，还有几个术语我们应该删除，包括提及、标签、链接、标点等等。</p><p id="b707" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要去除这些，如果我们只依赖一个定义好的角色，那是很有挑战性的。因此，我们需要通过使用正则表达式(Regex)来匹配我们想要的术语的模式。</p><p id="2efe" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Regex是一个特殊的字符串，它包含的模式可以匹配与该模式相关的单词。通过使用它，我们可以使用名为re的Python库搜索或删除那些基于模式的内容。为此，我们可以这样实现它，</p><pre class="oa ob oc od gt oe of og oh aw oi bi"><span id="a02c" class="nj ms jj of b gy oj ok l ol om">import re</span><span id="a117" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Remove mentions</strong><br/>x = "<a class="ae jg" href="http://twitter.com/DDNewsLive" rel="noopener ugc nofollow" target="_blank">@DDNewsLive</a> <a class="ae jg" href="http://twitter.com/NitishKumar" rel="noopener ugc nofollow" target="_blank">@NitishKumar</a>  and <a class="ae jg" href="http://twitter.com/ArvindKejriwal" rel="noopener ugc nofollow" target="_blank">@ArvindKejriwal</a> can't survive without referring @@narendramodi . Without Mr Modi they are BIG ZEROS"</span><span id="fd77" class="nj ms jj of b gy on ok l ol om">x = re.sub("@\S+", " ", x)</span><span id="39d3" class="nj ms jj of b gy on ok l ol om">print(x)<br/><strong class="of jk">&gt;&gt;&gt;      and   can't survive without referring   . Without Mr Modi they are BIG ZEROS</strong></span><span id="724d" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Remove URL</strong><br/>x = "Severe Thunderstorm pictures from across the Mid-South <a class="ae jg" href="http://t.co/UZWLgJQzNS" rel="noopener ugc nofollow" target="_blank">http://t.co/UZWLgJQzNS</a>"</span><span id="ef5d" class="nj ms jj of b gy on ok l ol om">x = re.sub("https*\S+", " ", x)</span><span id="cb46" class="nj ms jj of b gy on ok l ol om">print(x)<br/><strong class="of jk">&gt;&gt;&gt; Severe Thunderstorm pictures from across the Mid-South</strong></span><span id="b62d" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Remove Hashtags</strong><br/>x = "Are people not concerned that after #SLAB's obliteration in Scotland #Labour UK is ripping itself apart over #Labourleadership contest?"</span><span id="a50e" class="nj ms jj of b gy on ok l ol om">x = re.sub("#\S+", " ", x)</span><span id="04fa" class="nj ms jj of b gy on ok l ol om">print(x)<br/><strong class="of jk">&gt;&gt;&gt; Are people not concerned that after   obliteration in Scotland   UK is ripping itself apart over   contest?</strong></span><span id="72c9" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Remove ticks and the next character</strong><br/>x = "Notley's tactful yet very direct response to Harper's attack on Alberta's gov't. Hell YEAH Premier! <a class="ae jg" href="http://t.co/rzSUlzMOkX" rel="noopener ugc nofollow" target="_blank">http://t.co/rzSUlzMOkX</a> #ableg #cdnpoli"</span><span id="6860" class="nj ms jj of b gy on ok l ol om">x = re.sub("\'\w+", '', x)</span><span id="9dce" class="nj ms jj of b gy on ok l ol om">print(x)<br/><strong class="of jk">&gt;&gt;&gt; Notley tactful yet very direct response to Harper attack on Alberta gov. Hell YEAH Premier! </strong><a class="ae jg" href="http://t.co/rzSUlzMOkX" rel="noopener ugc nofollow" target="_blank"><strong class="of jk">http://t.co/rzSUlzMOkX</strong></a><strong class="of jk"> #ableg #cdnpoli</strong></span><span id="533a" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Remove punctuations</strong><br/>x = "In 2014 I will only smoke crqck if I becyme a mayor. This includes Foursquare."</span><span id="657c" class="nj ms jj of b gy on ok l ol om">x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)</span><span id="dbdc" class="nj ms jj of b gy on ok l ol om">print(x)<br/><strong class="of jk">&gt;&gt;&gt; In 2014 I will only smoke crqck if I becyme a mayor. This includes Foursquare.</strong></span><span id="4cb9" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Remove numbers</strong><br/>x = "C-130 specially modified to land in a stadium and rescue hostages in Iran in 1980... <a class="ae jg" href="http://t.co/tNI92fea3u" rel="noopener ugc nofollow" target="_blank">http://t.co/tNI92fea3u</a> <a class="ae jg" href="http://t.co/czBaMzq3gL" rel="noopener ugc nofollow" target="_blank">http://t.co/czBaMzq3gL</a>"</span><span id="3ba6" class="nj ms jj of b gy on ok l ol om">x = re.sub(r'\w*\d+\w*', '', x)</span><span id="7fb0" class="nj ms jj of b gy on ok l ol om">print(x)<br/><strong class="of jk">&gt;&gt;&gt; C- specially modified to land in a stadium and rescue hostages in Iran in ... </strong><a class="ae jg" href="http://t.co/" rel="noopener ugc nofollow" target="_blank"><strong class="of jk">http://t.co/</strong></a><strong class="of jk"> </strong><a class="ae jg" href="http://t.co/" rel="noopener ugc nofollow" target="_blank"><strong class="of jk">http://t.co/</strong></a></span><span id="a71f" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># Replace the over spaces</strong><br/>x = "     and   can't survive without referring   . Without Mr Modi they are BIG ZEROS"</span><span id="5378" class="nj ms jj of b gy on ok l ol om">x = re.sub('\s{2,}', " ", x)</span><span id="0cc7" class="nj ms jj of b gy on ok l ol om">print(x)<br/><strong class="of jk">&gt;&gt;&gt;  and can't survive without referring . Without Mr Modi they are BIG ZEROS</strong></span></pre><h2 id="2696" class="nj ms jj bd mt nk nl dn mx nm nn dp nb lh no np nd ll nq nr nf lp ns nt nh nu bi translated">组合它们</h2><p id="2c6a" class="pw-post-body-paragraph ky kz jj la b lb nv kk ld le nw kn lg lh nx lj lk ll ny ln lo lp nz lr ls lt im bi translated">在您了解预处理文本的每个步骤之后，让我们将它应用于一个列表。如果你仔细观察这些步骤的细节，你会发现每种方法都是相互关联的。因此，有必要将它应用到一个函数上，这样我们就可以同时按顺序处理它。在我们应用预处理步骤之前，这里是样本文本的预览，</p><pre class="oa ob oc od gt oe of og oh aw oi bi"><span id="cf27" class="nj ms jj of b gy oj ok l ol om"><strong class="of jk">Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all<br/>Forest fire near La Ronge Sask. Canada<br/>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected<br/>13,000 people receive #wildfires evacuation orders in California <br/>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</strong></span></pre><p id="8a5e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们应该做几个步骤来预处理文本列表。他们是，</p><ol class=""><li id="1360" class="oo op jj la b lb lc le lf lh oq ll or lp os lt ot ou ov ow bi translated">创建一个包含所有预处理步骤的函数，它返回一个预处理过的字符串</li><li id="e5b9" class="oo op jj la b lb ox le oy lh oz ll pa lp pb lt ot ou ov ow bi translated">使用名为Apply的方法应用函数，并用该方法链接列表。</li></ol><p id="3e91" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">代码看起来会像这样，</p><pre class="oa ob oc od gt oe of og oh aw oi bi"><span id="e523" class="nj ms jj of b gy oj ok l ol om"><strong class="of jk"># # In case of import errors<br/># ! pip install nltk<br/># ! pip install textblob</strong></span><span id="7e37" class="nj ms jj of b gy on ok l ol om">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import re<br/>import nltk<br/>import string<br/>from nltk.corpus import stopwords</span><span id="1cf8" class="nj ms jj of b gy on ok l ol om"><strong class="of jk"># # In case of any corpus are missing <br/># download all-nltk</strong><br/>nltk.download()</span><span id="07e1" class="nj ms jj of b gy on ok l ol om">df = pd.read_csv('train.csv')<br/>stop_words = stopwords.words("english")<br/>wordnet = WordNetLemmatizer()</span><span id="7e81" class="nj ms jj of b gy on ok l ol om">def text_preproc(x):<br/>  x = x.lower()<br/>  x = ' '.join([word for word in x.split(' ') if word not in stop_words])<br/>  x = x.encode('ascii', 'ignore').decode()<br/>  x = re.sub(r'https*\S+', ' ', x)<br/>  x = re.sub(r'@\S+', ' ', x)<br/>  x = re.sub(r'#\S+', ' ', x)<br/>  x = re.sub(r'\'\w+', '', x)<br/>  x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)<br/>  x = re.sub(r'\w*\d+\w*', '', x)<br/>  x = re.sub(r'\s{2,}', ' ', x)<br/>  return x</span><span id="22b5" class="nj ms jj of b gy on ok l ol om">df['clean_text'] = df.text.apply(text_preproc)</span></pre><p id="6c5c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是它的结果，</p><pre class="oa ob oc od gt oe of og oh aw oi bi"><span id="6e7b" class="nj ms jj of b gy oj ok l ol om"><strong class="of jk">deeds reason may allah forgive us<br/>forest fire near la ronge sask canada<br/>residents asked place notified officers evacuation shelter place orders expected<br/> people receive evacuation orders california <br/>got sent photo ruby smoke pours school</strong></span></pre></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="db86" class="mr ms jj bd mt mu mv mw mx my mz na nb kp nc kq nd ks ne kt nf kv ng kw nh ni bi translated">最后的想法</h1><p id="d9a4" class="pw-post-body-paragraph ky kz jj la b lb nv kk ld le nw kn lg lh nx lj lk ll ny ln lo lp nz lr ls lt im bi translated">这就是如何使用Python对文本进行预处理。希望你可以应用它来解决文本数据相关的问题。如果有什么想法，可以在下面评论下来。此外，您可以在Medium上跟踪我，以便跟进我的文章。谢谢你。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h2 id="5cc9" class="nj ms jj bd mt nk nl dn mx nm nn dp nb lh no np nd ll nq nr nf lp ns nt nh nu bi translated">参考</h2><p id="b78b" class="pw-post-body-paragraph ky kz jj la b lb nv kk ld le nw kn lg lh nx lj lk ll ny ln lo lp nz lr ls lt im bi translated">[1]<a class="ae jg" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank">https://docs.python.org/3/library/re.html</a><br/>【2】<a class="ae jg" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank">https://www.nltk.org/</a><br/>【3】<a class="ae jg" href="https://www.kaggle.com/c/nlp-getting-started/overview" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/nlp-getting-started/overview</a></p></div></div>    
</body>
</html>