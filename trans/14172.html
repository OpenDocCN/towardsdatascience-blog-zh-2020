<html>
<head>
<title>How to Reduce Training Time for a Deep Learning Model using tf.data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用tf.data减少深度学习模型的训练时间</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-reduce-training-time-for-a-deep-learning-model-using-tf-data-43e1989d2961?source=collection_archive---------8-----------------------#2020-09-30">https://towardsdatascience.com/how-to-reduce-training-time-for-a-deep-learning-model-using-tf-data-43e1989d2961?source=collection_archive---------8-----------------------#2020-09-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6b55" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">学习为图像创建输入管道，以高效地使用CPU和GPU资源来处理图像数据集，并减少深度学习模型的训练时间。</em></h2></div><p id="47f5" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><em class="lf">在这篇文章中，你将学到</em></p><ul class=""><li id="e470" class="lg lh it kl b km kn kp kq ks li kw lj la lk le ll lm ln lo bi translated"><em class="lf">在模型训练中，CPU和GPU资源是如何以一种天真的方式使用的？</em></li><li id="7ebb" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated"><em class="lf">如何高效利用CPU和GPU资源进行数据预处理和训练？</em></li><li id="7345" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated"><em class="lf">为什么要用tf.data构建高效的输入管道？</em></li><li id="865b" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated"><em class="lf">如何使用tf.data为图像建立高效的输入数据管道？</em></li></ul><p id="97b8" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> <em class="lf">一个朴素的方法如何为输入数据管道和模型训练工作？</em>T15】</strong></p><p id="bc8d" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在创建输入数据管道时，我们通常执行ETL(提取、转换和加载)过程。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lu"><img src="../Images/3d025b28992e2b4f832e88dbd8a316cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Zi3_VUAYh5w78KGLoO37g.png"/></div></div></figure><ul class=""><li id="c033" class="lg lh it kl b km kn kp kq ks li kw lj la lk le ll lm ln lo bi translated"><strong class="kl iu">提取</strong>、<strong class="kl iu">从不同的数据源提取数据，如本地数据源、</strong>可以从硬盘或远程数据源提取数据，如云存储。</li><li id="12df" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated"><strong class="kl iu">转换</strong>，你将<strong class="kl iu">洗牌数据，创建批次，应用矢量化或图像放大。</strong></li><li id="a131" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated"><strong class="kl iu">加载数据包括清理数据并将其塑造成一种我们可以传递给深度学习模型进行训练的格式</strong>。</li></ul><p id="34bd" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">数据的预处理发生在CPU上，模型通常在GPU/TPU上训练。</p><p id="79eb" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在简单的模型训练方法中，<strong class="kl iu"> CPU预处理数据，为模型训练做好准备，而GPU/TPU处于空闲状态</strong>。当GPU/TPU开始训练模型时，CPU是空闲的。这不是管理资源的有效方式，如下所示。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi mg"><img src="../Images/1cee603f09c59ef8ede2afc0938cfac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I7ut3YQiEqMuUBIgp_UHgw.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">原始数据预处理和训练方法</p></figure><p id="af64" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">有哪些方法可以加快培训过程？ </p><p id="62fd" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">为了加快训练，我们需要优化数据提取、数据转换和数据加载过程，所有这些都发生在CPU上。</p><p id="c328" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu">数据提取:优化从数据源读取的数据</strong></p><p id="2c8c" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu">数据转换:并行化数据扩充</strong></p><p id="0d9f" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu">数据加载:在训练前一步预取数据</strong></p><p id="134f" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这些技术将有效地利用CPU和GPU/TPU资源进行数据预处理和训练。</p><p id="9269" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> <em class="lf">怎样才能实现输入管道的优化？</em>T41】</strong></p><h2 id="f543" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">优化数据提取</h2><p id="77cb" class="pw-post-body-paragraph kj kk it kl b km ne ju ko kp nf jx kr ks ng ku kv kw nh ky kz la ni lc ld le im bi translated">通过同时处理多个文件来优化数据提取。<strong class="kl iu"> tf.data.interleave()通过交错读取文件的I/O操作和应用数据预处理的map()优化数据提取过程</strong>。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi nj"><img src="../Images/b37a699fbbeb34c4fd1df42b7c533ef6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5UNiEJw6y6_DiudO35qeEg.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">来源:<a class="ae nk" href="https://www.tensorflow.org/guide/data_performance#parallelizing_data_extraction" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/guide/data _ performance # parallelising _ data _ extraction</a></p></figure><p id="36c5" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">要重叠的数据集数量由<strong class="kl iu"> <em class="lf"> cycle_length </em> </strong>参数指定，而并行度由<strong class="kl iu"><em class="lf">num _ parallel _ calls</em></strong>参数设置。您可以使用AUTOTUNE来决定要实现的并行级别。</p><p id="221a" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"><em class="lf">num _ parallel _ calls</em>产生多个线程，利用机器上的多个内核，通过使用多个CPU来并行化数据提取过程。</strong></p><p id="8fa2" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> <em class="lf">如何知道要用多少个CPU或核心？</em> </strong></p><p id="51d1" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">您可以找到机器上的内核数量并指定，但更好的选择是使用<strong class="kl iu">tf.data . experimental . auto tune .</strong>将并行级别委托给TF . data</p><ul class=""><li id="5240" class="lg lh it kl b km kn kp kq ks li kw lj la lk le ll lm ln lo bi translated">自动调优将要求tf.data在运行时动态调优该值。</li><li id="ed93" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated">tf.data将在所有可调操作中找到正确的CPU预算。</li><li id="a1ef" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated">自动调优决定缓冲区大小、CPU预算以及I/O操作的并行级别。</li></ul><h2 id="17c6" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">并行数据转换</h2><p id="1822" class="pw-post-body-paragraph kj kk it kl b km ne ju ko kp nf jx kr ks ng ku kv kw nh ky kz la ni lc ld le im bi translated">图像增强是预处理的一部分，发生在CPU上。图像的每一次放大、归一化、重新缩放都是一种代价高昂的操作，并且会减慢训练过程。</p><p id="db0c" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">如果你能通过并行处理利用所有内核来运行所有这些图像操作。</p><p id="890a" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> <em class="lf"> tf.data.map() </em>可以采用用户定义的函数，该函数包含您想要应用于数据集的所有图像增强。</strong></p><p id="0988" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> tf.data.map()有一个参数<em class="lf"> num_parallel_calls </em>来产生多个线程，以利用机器上的多个内核来使用多个CPU并行化预处理。</strong></p><h2 id="6d2c" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">缓存数据</h2><p id="e29e" class="pw-post-body-paragraph kj kk it kl b km ne ju ko kp nf jx kr ks ng ku kv kw nh ky kz la ni lc ld le im bi translated"><strong class="kl iu"> <em class="lf"> cache() </em>允许将数据缓存在指定文件或内存中</strong>。</p><ul class=""><li id="f459" class="lg lh it kl b km kn kp kq ks li kw lj la lk le ll lm ln lo bi translated">在内存中缓存时，第一次迭代数据时，将缓存数据，所有后续迭代，将从缓存中读取数据。</li><li id="1278" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated">当缓存一个文件时，即使是第一次迭代数据也会从缓存的文件中读取。</li><li id="80bd" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated">缓存为每次迭代产生相同的元素，在缓存数据后，使用shuffle()随机化迭代中的元素。</li></ul><h2 id="500c" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">通过重叠数据处理和训练来预取数据</h2><p id="4002" class="pw-post-body-paragraph kj kk it kl b km ne ju ko kp nf jx kr ks ng ku kv kw nh ky kz la ni lc ld le im bi translated"><strong class="kl iu">TF . data中的预取功能重叠了数据预处理和模型训练。数据预处理比训练提前一步运行，</strong>如下所示，这减少了模型的总训练时间。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi nl"><img src="../Images/2c538f26b154e4a558a845aa60030cf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RGa6052Ac2p1G6KZayR9pQ.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">来源:<a class="ae nk" href="https://www.tensorflow.org/guide/data_performance#prefetching" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/guide/data _ performance #预取</a></p></figure><p id="cd23" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">要预取的元素数量应该等于或大于用于单个训练步骤的批量大小。我们可以使用AUTOTUNE来提示tf.data在运行时动态分配缓冲区大小值。</p><p id="3c66" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu">所有的操作:<em class="lf">映射</em>，<em class="lf">预取</em>，<em class="lf">交错</em>，<em class="lf">批量</em>，<em class="lf">重复</em>，<em class="lf">混洗，</em>和<em class="lf">缓存</em>都是tf.data的一部分，可以让你构建</strong></p><ul class=""><li id="b7f1" class="lg lh it kl b km kn kp kq ks li kw lj la lk le ll lm ln lo bi translated">通过使用计算资源、GPU、CPU和TPU，更快、更高效地建立数据管道，高效地从数据源获取数据。</li><li id="0441" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated">灵活处理不同的数据格式，如文本数据、图像和包含数字和分类数据的结构化数据。</li><li id="fad8" class="lg lh it kl b km lp kp lq ks lr kw ls la lt le ll lm ln lo bi translated">通过应用数据扩充、混排数据集和创建用于训练的批量数据，轻松构建复杂的输入数据管道</li></ul><p id="ddf0" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> <em class="lf">如何使用tf.data为自定义影像数据集构建数据管道？</em> </strong></p><p id="60a8" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在本节中，您将为来自Kaggle 的流行的C <a class="ae nk" href="https://www.kaggle.com/c/dogs-vs-cats/data" rel="noopener ugc nofollow" target="_blank"> ats和Fogs数据集构建一个数据输入管道。</a></p><p id="7031" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这里我们将使用MobileNetV2和TensorFlow 2.3进行迁移学习</p><h2 id="7315" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">导入所需的库</h2><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="f73b" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">import tensorflow as tf<br/>config = tf.compat.v1.ConfigProto()<br/>config.gpu_options.allow_growth = True<br/>sess = tf.compat.v1.Session(config=config)<br/>import numpy as np<br/>import pandas as pd<br/>import pathlib<br/>import os<br/>from os import getcwd<br/>import pandas as pd<br/>from glob import glob<br/>import multiprocessing<br/>from tensorflow.keras.applications.mobilenet_v2 import preprocess_input</strong></span></pre><p id="a2bd" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">为数据集设置train和val目录</p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="f0b7" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">train_dir=r'\dogs-vs-cats\train_data'<br/>val_dir=r'\dogs-vs-cats\validation_data'</strong></span></pre><h2 id="4512" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">将文件转换为数据集对象</h2><p id="0638" class="pw-post-body-paragraph kj kk it kl b km ne ju ko kp nf jx kr ks ng ku kv kw nh ky kz la ni lc ld le im bi translated">使用<strong class="kl iu"><em class="lf">TF . data . dataset . list _ files()</em></strong>根据匹配的glob模式返回文件名。这里我们希望所有的文件都来自train_dir和val_dir文件夹下的子文件夹，所以我们指定了“\*\\*”</p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="85ff" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">train_files = tf.data.Dataset.list_files(str(train_dir + '\\*\\*'), shuffle=False)</strong><br/><strong class="nn iu">val_files = tf.data.Dataset.list_files(str(val_dir + '\\*\\*'), shuffle=False)</strong></span><span id="d6b0" class="ml mm it nn b gy nv ns l nt nu">#getting the number of files in train and val dataset<br/><strong class="nn iu">train_num_files=len([file for file in glob(str(train_dir + '\\*\\*'))])<br/>val_num_files=len([file for file in glob(str(val_dir + '\\*\\*'))])<br/></strong>print("No. of files in Train folder: ",train_num_files)<br/>print("No. of files in Val folder: ",val_num_files)</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/62b2e2bf9aa83c0dd8951a845056fee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*UMgvFwzlxH3XSbNj9yW7Tg.png"/></div></figure><h2 id="6c67" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">预处理训练和验证数据集</h2><p id="95d3" class="pw-post-body-paragraph kj kk it kl b km ne ju ko kp nf jx kr ks ng ku kv kw nh ky kz la ni lc ld le im bi translated">设置参数</p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="63c7" class="ml mm it nn b gy nr ns l nt nu">epoch=10<br/>batch_size = 32<br/>img_height = 224<br/>img_width = 224</span></pre><p id="9637" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu">应用MobileNet的预处理技术</strong></p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="3d59" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">#Get class names from the folders<br/>class_names = np.array(sorted([dir1 for dir1 in os.listdir(train_dir)]))<br/>class_names</strong></span><span id="5246" class="ml mm it nn b gy nv ns l nt nu">#To process the label<br/><strong class="nn iu">def get_label(file_path):</strong><br/>  # convert the path to a list of path components separated by sep<br/> <strong class="nn iu"> parts = tf.strings.split(file_path, os.path.sep)</strong><br/>  # The second to last is the class-directory<br/>  <strong class="nn iu">one_hot = parts[-2] == class_names</strong><br/>  # Integer encode the label<br/>  <strong class="nn iu">return tf.argmax(tf.cast(one_hot, tf.int32))</strong></span><span id="1122" class="ml mm it nn b gy nv ns l nt nu"># To process the image<br/><strong class="nn iu">def decode_img(img):</strong><br/>  # convert the compressed string to a 3D uint8 tensor<br/> <strong class="nn iu"> img = tf.image.decode_jpeg(img, channels=3)</strong>  <br/>  # resize the image to the desired size<br/>  <strong class="nn iu">return tf.image.resize(img, [img_height, img_width])</strong></span><span id="430c" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">def process_TL(file_path):<br/>  label = get_label(file_path)</strong> <br/># load the raw data from the file as a string<br/>  <strong class="nn iu">img = tf.io.read_file(file_path) <br/>  img = decode_img(img)<br/>  img = preprocess_input(img)<br/>  return img, label</strong></span></pre><h2 id="b985" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">通过交错优化数据提取和数据转换过程</h2><p id="00fe" class="pw-post-body-paragraph kj kk it kl b km ne ju ko kp nf jx kr ks ng ku kv kw nh ky kz la ni lc ld le im bi translated"><strong class="kl iu"> <em class="lf"> Interleave() </em> </strong>将通过交错读取文件的I/O操作和<strong class="kl iu"> <em class="lf"> map() </em> </strong>将数据预处理应用到数据集的内容来并行化数据加载步骤。</p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="03cf" class="ml mm it nn b gy nr ns l nt nu">#Interleaving the train dataset  to read the file and apply preprocessing<strong class="nn iu"><br/>train_dataset = train_files.interleave(lambda x: tf.data.Dataset.list_files(str(train_dir + '\\*\\*'), shuffle=True), cycle_length=4).map(process_TL, num_parallel_calls=tf.data.experimental.AUTOTUNE)</strong></span><span id="6835" class="ml mm it nn b gy nv ns l nt nu">#Interleaving the val dataset  to read the file and apply preprocessing<strong class="nn iu"><br/>val_dataset = val_files.interleave(lambda x: tf.data.Dataset.list_files(str(val_dir + '\\*\\*'), shuffle=True), cycle_length=4).map(process_TL, num_parallel_calls=tf.data.experimental.AUTOTUNE)</strong></span></pre><p id="87d0" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">要重叠的数据集数量设置为4，这由<strong class="kl iu"> <em class="lf"> cycle_length </em> </strong>参数指定。并行级别由<strong class="kl iu"> <em class="lf"> num_parallel_calls、</em> </strong>指定，后者设置为<strong class="kl iu"> <em class="lf"> </em> AUTOTUNE </strong></p><h2 id="a2f5" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">加载数据集进行训练</h2><p id="a29e" class="pw-post-body-paragraph kj kk it kl b km ne ju ko kp nf jx kr ks ng ku kv kw nh ky kz la ni lc ld le im bi translated"><strong class="kl iu">在内存中缓存数据集</strong></p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="e743" class="ml mm it nn b gy nr ns l nt nu">##Cache the dataset in-memory<br/><strong class="nn iu">train_dataset = train_dataset.cache()<br/>val_dataset = val_dataset.cache()</strong></span><span id="2e94" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">train_dataset = train_dataset.repeat().shuffle(buffer_size=512 ).batch(batch_size) <br/> <br/>val_dataset = val_dataset.batch(batch_size)</strong></span></pre><p id="4126" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu">TF . data . dataset类的repeat() </strong>方法用于重复数据集中的张量。</p><p id="0a4f" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> shuffle () </strong>使用大小为512的缓冲区对train_dataset进行混洗，以便挑选随机条目。</p><p id="c5bb" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> batch() </strong>将根据设置的批量大小获取前32个条目，并从中进行批量处理</p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="6dd4" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">train_dataset = train_dataset.repeat().shuffle(buffer_size=512 ).batch(batch_size)</strong></span><span id="4614" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">val_dataset = val_dataset.batch(batch_size)</strong></span></pre><p id="2ce6" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu">TF . data中的预取功能重叠了数据预处理和模型训练</strong></p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="a287" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">train_dataset =train_dataset.prefetch(tf.data.experimental.AUTOTUNE )<br/>val_dataset =val_dataset.prefetch(tf.data.experimental.AUTOTUNE )</strong></span></pre><p id="ebd3" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">创建用于垂直和水平翻转图像、旋转图像、缩放和应用对比度的数据增强。</p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="957a" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">data_augmentation = tf.keras.Sequential([                      tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),                      tf.keras.layers.experimental.preprocessing.RandomFlip('vertical'),                      tf.keras.layers.experimental.preprocessing.RandomRotation(0.45),                      tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),                      tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),])</strong></span></pre><p id="d9c2" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">通过首先应用数据扩充来创建迁移学习模型</p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="288e" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">def create_model():<br/>    input_layer = tf.keras.layers.Input(shape=(224, 224, 3))<br/>    x= data_augmentation(input_layer)<br/>    base_model = tf.keras.applications.MobileNetV2(input_tensor=x,                                                   weights='imagenet',include_top=False)<br/>    <br/>    base_model.trainable = False<br/>    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)<br/>    x = tf.keras.layers.Dense(2, activation='softmax')(x)<br/>    <br/>    model = tf.keras.models.Model(inputs=input_layer, outputs=x)<br/>    model.compile(optimizer='adam',<br/>                  loss='sparse_categorical_crossentropy',<br/>                  metrics=['accuracy'])<br/>    return model</strong></span><span id="13e7" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">model= create_model()</strong></span></pre><p id="8a3d" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">创建检查点阈值，训练将继续，直到我们获得99.96%的验证准确率，或者直到完成指定数量的时期。</p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="910c" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">class MyThresholdCallback(tf.keras.callbacks.Callback):<br/>    def __init__(self, threshold):<br/>        super(MyThresholdCallback, self).__init__()<br/>        self.threshold = threshold</strong></span><span id="e247" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">def on_epoch_end(self, epoch, logs=None): <br/>        val_acc = logs["val_accuracy"]<br/>        if val_acc &gt;= self.threshold:<br/>            self.model.stop_training = True</strong></span><span id="7661" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">my_callback = MyThresholdCallback(threshold=0.9996)</strong></span></pre><p id="9a40" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu">将训练数据集拟合到模型中</strong></p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="6de2" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">import time<br/>start_time= time.perf_counter()<br/>history_tfdata =model.fit(train_dataset,<br/>          steps_per_epoch=int((train_num_files)/batch_size),<br/>          validation_data=   val_dataset,<br/>          validation_steps=int(val_num_files/batch_size),<br/>                           callbacks=[my_callback],<br/>         <br/>          epochs=epoch)</strong></span><span id="6cb1" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">print(time.perf_counter()-start_time)</strong></span></pre><p id="8b4c" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">如果我们使用如下所示的ImageDataGenerator训练数据集，我们可以比较训练时间的差异。</p><pre class="lv lw lx ly gt nm nn no np aw nq bi"><span id="f9db" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img<br/>from tensorflow.keras.models import load_model<br/>from tensorflow.keras import optimizers, callbacks</strong></span><span id="09c9" class="ml mm it nn b gy nv ns l nt nu">#Creating Image Train DataGenerator<br/><strong class="nn iu">image_gen_train = ImageDataGenerator(rescale=1./255, <br/>                                     zoom_range=0.1, <br/>                                     rotation_range=45,<br/>                                     shear_range=0.1,<br/>                                     horizontal_flip=True,<br/>                                     vertical_flip=True)<br/>train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,                                               directory=train_dir, <br/>shuffle=True,                                                     target_size=(224,224),                                                     class_mode='sparse')</strong></span><span id="d55c" class="ml mm it nn b gy nv ns l nt nu"># Val data generator<br/><strong class="nn iu">image_gen_val = ImageDataGenerator(rescale=1./255)<br/>val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,directory=val_dir, target_size=(224,224),class_mode='sparse')</strong></span><span id="f73c" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">def create_model():<br/>    input_layer = tf.keras.layers.Input(shape=(224, 224, 3))<br/>    input_layer=preprocess_input(input_layer)<br/>   <br/>    base_model = tf.keras.applications.MobileNetV2(input_tensor=input_layer,<br/>                                                   weights='imagenet',<br/>                                                   include_top=False)<br/>    <br/>    base_model.trainable = False<br/>    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)<br/>    x = tf.keras.layers.Dense(2, activation='softmax')(x)<br/>    <br/>    model = tf.keras.models.Model(inputs=input_layer, outputs=x)<br/>    model.compile(optimizer='adam',<br/>                  loss='sparse_categorical_crossentropy',<br/>                  metrics=['accuracy'])<br/>    return model</strong></span><span id="5b73" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">model_idg=create_model()</strong></span><span id="3448" class="ml mm it nn b gy nv ns l nt nu"><strong class="nn iu">start_time2= time.perf_counter()<br/>history = model_idg.fit(<br/>    train_data_gen,<br/>    steps_per_epoch=len(train_data_gen),<br/>    epochs=10,<br/>callbacks=[tboard_callback],<br/>    validation_data=val_data_gen,<br/>    validation_steps=len(val_data_gen)<br/>)<br/>print(time.perf_counter()-start_time2)</strong></span></pre><p id="0ad9" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">将使用tf.data输入管道完成训练的时间与使用ImageDataGenerator完成训练的时间进行比较</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi nx"><img src="../Images/e70871f7c088fc38e9d2a0d9ac3851d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UfymcWYpI8uFPw5Zoz1XDg.png"/></div></div></figure><p id="7040" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">您可以看到使用tf.data完成训练的时间是290.53秒，而使用ImageDataGenerator完成相同数据的训练是2594.89秒，这在训练时间方面是一个很大的进步</p><p id="ceb0" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">代码可用<a class="ae nk" href="https://github.com/arshren/Image_Input_TF2.3/blob/master/Cat%20n%20Dog.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a></p><h2 id="6428" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">结论:</h2><p id="cd14" class="pw-post-body-paragraph kj kk it kl b km ne ju ko kp nf jx kr ks ng ku kv kw nh ky kz la ni lc ld le im bi translated">tf.data允许您通过高效地使用GPU、CPU和TPU等计算资源，为不同的数据格式构建高效的输入数据管道，从而减少训练时间。</p><h2 id="c32c" class="ml mm it bd mn mo mp dn mq mr ms dp mt ks mu mv mw kw mx my mz la na nb nc nd bi translated">参考资料:</h2><div class="ny nz gp gr oa ob"><a href="https://www.tensorflow.org/guide/data" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">tf.data:构建TensorFlow输入管道| TensorFlow核心</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">创建数据集有两种不同的方法:将TensorFlow作为tf导入pathlib导入os导入…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">www.tensorflow.org</p></div></div><div class="ok l"><div class="ol l om on oo ok op me ob"/></div></div></a></div><div class="ny nz gp gr oa ob"><a href="https://www.tensorflow.org/guide/data_performance" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">使用tf.data API | TensorFlow核心提高性能</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">GPU和TPU可以从根本上减少执行单个训练步骤所需的时间。实现最佳性能…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">www.tensorflow.org</p></div></div><div class="ok l"><div class="oq l om on oo ok op me ob"/></div></div></a></div><p id="fc44" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><a class="ae nk" href="https://github.com/tensorflow/docs/blob/master/site/en/guide/data.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/docs/blob/master/site/en/guide/data . ipynb</a></p></div></div>    
</body>
</html>