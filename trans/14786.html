<html>
<head>
<title>Data Augmentation in Medical Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">医学图像中的数据增强</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-augmentation-in-medical-images-95c774e6eaae?source=collection_archive---------18-----------------------#2020-10-12">https://towardsdatascience.com/data-augmentation-in-medical-images-95c774e6eaae?source=collection_archive---------18-----------------------#2020-10-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="1703" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="4e5a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">如何通过重塑和重采样数据来提高视觉模型的性能</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/e625c6561f2fa96bd21317f25f5c6730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*p7LEra3tBHiLZ_Zy"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@cdc?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">疾控中心</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="af69" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">机器学习的普及以奇妙的方式改变了我们的世界。机器学习的一些著名应用允许我们做以前不可想象的事情，比如确定一幅图像是不是热狗。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi me"><img src="../Images/771657316c3e2eecab19d9f59f52ddd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VLM-bk-JdSYVyMKPtAvkbw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">截图来自HBO在《硅谷》节目中“SeeFood Technologies”开发的Not Hotdog应用。</p></figure><p id="7c96" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">随着TensorFlow和PyTorch等开源神经网络框架的发布，开发图像识别和分类应用程序的便利性在过去几年得到了简化。这些神经网络框架的使用是基于标记的训练数据的可用性，这在云基础设施中变得更加容易访问。神经网络需要大量的数据来适当地加权各层之间的函数。然而，在医学成像等领域，大量标记的训练数据并不总是可用的。对于那些对医学成像数据感兴趣的人，可以在Giorgos Sfikas的GitHub 找到大量资源。在<a class="ae lh" href="https://neptune.ai/blog/data-augmentation-in-python" rel="noopener ugc nofollow" target="_blank"> Neptune.ai </a>上可以找到关于数据增强技术和工具的一个很好的资源。</p><p id="8329" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如何有效地训练一个神经网络，用有限的训练数据对医学图像进行分类。一个答案是增加你已经有的标签数据，并将转换后的图像输入到你的模型中。扩充有两个目的。首先，理论上来自增强的附加标记训练数据将提高您的图像分类模型准确性<strong class="lk jd">【警告！！！</strong>会导致过度拟合】。第二，转换将允许模型在方向变化上进行训练。当在测试或真实世界数据中遇到微妙的变化时，可能提供模型灵活性。</p><p id="35bd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">它真的有用吗？</strong></p><p id="e65b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以下是经过数据增强和未经数据增强训练的模型的准确性。我将在本文后面更详细地介绍这些结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/1c39a624e04973974958055845c1c3fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*o6EcwINw9I6kiuaik7VnVQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用不同形式增强的x射线多类分类的性能高于随机的类别数涉及大于0.5的曲线下面积(AUC)分数。图片作者。</p></figure><p id="f4e8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个小训练集的不错的改进。我只使用了40GB总数据中的2GB来训练模型。数据增强让我想起了半监督学习，因为你正在创建新的标记数据来训练模型。数据扩充也类似于过采样技术。对于那些有兴趣了解更多关于半监督方法的人，请查看下面这篇由Andre Ye撰写的文章。</p><div class="mg mh gp gr mi mj"><a rel="noopener follow" target="_blank" href="/supervised-learning-but-a-lot-better-semi-supervised-learning-a42dff534781"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd jd gy z fp mo fr fs mp fu fw jc bi translated">监督学习，但是更好:半监督学习</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">为什么半监督学习是ML的未来</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx lb mj"/></div></div></a></div><p id="5e08" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据扩充最常用于图像。数据扩充有两个主题。第一个是图像转换，第二个是合成图像创建。出于本文的目的，我将主要关注使用python在医学成像中的图像转换应用。本演示中使用的部分代码改编自<a class="ae lh" href="https://www.deeplearning.ai/" rel="noopener ugc nofollow" target="_blank"> deeplearning.ai </a>的《医疗诊断人工智能》课程。代码库可以在<a class="ae lh" href="https://github.com/Datadolittle/augmentation" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到，用于建模的数据可以从<a class="ae lh" href="https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345" rel="noopener ugc nofollow" target="_blank"> NIH临床中心胸部x光数据库</a>中获得。</p><h2 id="8b95" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">我们如何执行数据扩充？</h2><p id="6506" class="pw-post-body-paragraph li lj it lk b ll nq kd ln lo nr kg lq lr ns lt lu lv nt lx ly lz nu mb mc md im bi translated">python中的图像操作可以使用多个库来执行。<a class="ae lh" href="https://python-pillow.org/" rel="noopener ugc nofollow" target="_blank"> PIL </a>和<a class="ae lh" href="https://github.com/mdbloice/Augmentor" rel="noopener ugc nofollow" target="_blank">增强器</a>是两个可以直接在图像上操作的库的例子。Augmentor还包括一个流水线功能，可以一次处理多个图像。出于本文的目的，我利用了keras _预处理的一部分<a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank"> ImageDataGenerator </a>。图像增强的类型包括旋转、裁剪、缩放、颜色范围变化、灰度和翻转。增强器，还包括一个随机噪声分段创建对象检测模型。执行任何类型的数据扩充时，请务必记住模型的输出以及扩充是否会影响最终的分类。例如，在X射线数据中，心脏通常在图像的右侧，然而下图显示了水平翻转增强无意中产生了一种医学状况，称为situs inversus。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nv"><img src="../Images/d76b5a013bf6739a8b1c7dade622fd70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RgdYyoHz_FWcM55SgR_x7g.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">如果位置很重要，数据扩充可能会产生分类标签问题。黄色圆圈突出心脏。这是水平翻转的同一个图像。图片作者。</p></figure><h2 id="e562" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">本文中使用的数据扩充</h2><p id="263b" class="pw-post-body-paragraph li lj it lk b ll nq kd ln lo nr kg lq lr ns lt lu lv nt lx ly lz nu mb mc md im bi translated">出于本文的目的，我使用了三个级别的数据扩充。首先，我运行了一个没有任何增强图像的模型。接下来，我使用了基本的颜色正常化增强。最后，我使用复杂的增强技术创建了一个模型，比如缩放、旋转和裁剪图像，如下例所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nw"><img src="../Images/bdce1042f6cae6b18dedc0ca96814800.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m0_-UxGL3bgExReSes6jnw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">复杂增强训练中使用的数据增强示例。图片作者。</p></figure><h1 id="601c" class="nx mz it bd na ny nz oa nd ob oc od ng ki oe kj nj kl of km nm ko og kp np oh bi translated">实现增强方法(代码)</h1><h2 id="e3fe" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">数据和库</h2><p id="7a4a" class="pw-post-body-paragraph li lj it lk b ll nq kd ln lo nr kg lq lr ns lt lu lv nt lx ly lz nu mb mc md im bi translated">完整代码可以在文章<a class="ae lh" href="https://github.com/Datadolittle/augmentation" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。本教程的数据可以从<a class="ae lh" href="https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/37178474737" rel="noopener ugc nofollow" target="_blank"> NIH临床中心胸部x光</a>数据库中找到。在这个例子中，我只利用了images_001.tar.gz中的数据，它被解压缩成大约5K的图像(~2GB)。还有，我下载了图片标签为<a class="ae lh" href="https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345" rel="noopener ugc nofollow" target="_blank">Data _ Entry _ 2017 _ v 2020 . CSV</a>。用于执行数据扩充的库需要<a class="ae lh" href="https://anaconda.org/conda-forge/keras" rel="noopener ugc nofollow" target="_blank"> keras </a>和<a class="ae lh" href="https://anaconda.org/conda-forge/keras-preprocessing" rel="noopener ugc nofollow" target="_blank">keras-预处理</a>。我用conda安装了这些包。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="e1bc" class="my mz it oj b gy on oo l op oq">### Augmentation<br/>from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img</span><span id="e7d8" class="my mz it oj b gy or oo l op oq">### Visuals<br/>import matplotlib.pyplot as plt<br/>import pandas as pd</span><span id="f9b2" class="my mz it oj b gy or oo l op oq">### Modeling<br/>from tensorflow.keras.applications.densenet import DenseNet121<br/>from tensorflow.keras.layers import Dense, GlobalAveragePooling2D<br/>from tensorflow.keras.models import Model<br/>from keras.models import load_model<br/>from keras import backend as K</span></pre><p id="eb1c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">创建模型时，我遇到了以下错误:</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="66b5" class="my mz it oj b gy on oo l op oq">AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'</span></pre><p id="ac0a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">解决方案:在keras导入调用之前添加tensorflow，如下所示</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="8a21" class="my mz it oj b gy on oo l op oq">from tensorflow.keras.applications.densenet import DenseNet121<br/>from tensorflow.keras.layers import Dense, GlobalAveragePooling2D<br/>from tensorflow.keras.models import Model</span></pre><h2 id="4d14" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">准备图像和元数据</h2><p id="f0b6" class="pw-post-body-paragraph li lj it lk b ll nq kd ln lo nr kg lq lr ns lt lu lv nt lx ly lz nu mb mc md im bi translated">为了给x射线图像分配标签，我需要将元数据中的condition列二进制化。这项研究中有15个独特的条件:</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="b667" class="my mz it oj b gy on oo l op oq">['Cardiomegaly', 'Emphysema', 'Effusion', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Atelectasis','Pneumothorax','Pleural_Thickening', 'Pneumonia', 'Fibrosis', 'Edema', 'Consolidation', 'No Finding']</span></pre><p id="4636" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在x光检查中，病人可能有不止一种情况。我使用scikit-learn将数据转换成适当的格式，其中包含14种条件的二进制值，不包括“无发现”类别。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="d408" class="my mz it oj b gy on oo l op oq">from sklearn.preprocessing import MultiLabelBinarizer<br/>### Binarise labels<br/>mlb = MultiLabelBinarizer()<br/>expandedLabelData = mlb.fit_transform(df["labels"])<br/>labelClasses = mlb.classes_</span><span id="f8c8" class="my mz it oj b gy or oo l op oq">### Create a DataFrame from our output<br/>expandedLabels = pd.DataFrame(expandedLabelData, columns=labelClasses)<br/>expandedLabels['Images'] = df['Image Index']<br/>expandedLabels['ID'] = df['Patient ID']</span></pre><p id="bb13" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我将路径添加到相应的x射线图像，作为多列二进制数据帧中的新列。</p><p id="48dc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，为了测试建模性能，我将数据分为训练组(80%)和测试组(20%)。下图显示了训练数据集中类的频率。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/ebf6df21a1027454932d09265848ebf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*fH35DoOLADtv6x2ZnkOwEQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">训练数据中条件的频率。图片作者。</p></figure><h2 id="0168" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">建造生成器来增强图像</h2><p id="cc43" class="pw-post-body-paragraph li lj it lk b ll nq kd ln lo nr kg lq lr ns lt lu lv nt lx ly lz nu mb mc md im bi translated">ImageDataGenerator能够将图像处理成一个生成器对象，以避免将所有图像转换加载到内存中。ImageDataGenerator也能够直接从熊猫数据帧创建生成器。我用下面的代码构建了生成器:</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="9fa6" class="my mz it oj b gy on oo l op oq">def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):</span><span id="eea8" class="my mz it oj b gy or oo l op oq">    ### Perform data augmentation here<br/>    image_generator = ImageDataGenerator(rotation_range = 5, shear_range = 0.02,zoom_range = 0.02, samplewise_center=True, samplewise_std_normalization= True)<br/>    <br/>    ### Create the image generator<br/>    generator = image_generator.flow_from_dataframe(<br/>            dataframe=df,<br/>            directory=image_dir,<br/>            x_col=x_col,<br/>            y_col=y_cols,<br/>            class_mode="raw",<br/>            batch_size=batch_size,<br/>            shuffle=shuffle,<br/>            seed=seed,<br/>            target_size=(target_w,target_h))<br/>    <br/>    return generator</span></pre><p id="e84f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">要更改增强量，通过调整ImageDataGenerator中调用的变量来更改分配给image_generator的值。</strong>要调用该生成器，请使用以下代码行:</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="5c37" class="my mz it oj b gy on oo l op oq">IMAGE_DIR = "images/"<br/>train_generator = get_train_generator(training, IMAGE_DIR, "Images", labels)</span></pre><p id="0d53" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我还为测试数据构建了一个生成器。</p><h2 id="2da4" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">构建深度学习模型</h2><p id="a42e" class="pw-post-body-paragraph li lj it lk b ll nq kd ln lo nr kg lq lr ns lt lu lv nt lx ly lz nu mb mc md im bi translated">我使用了一个来自imagenet的<a class="ae lh" href="https://arxiv.org/abs/1608.06993" rel="noopener ugc nofollow" target="_blank"> DenseNet121架构</a>来预训练模型。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="ab41" class="my mz it oj b gy on oo l op oq">### Pre-trained model<br/>base_model = DenseNet121(weights='imagenet', include_top=False)</span><span id="1ef5" class="my mz it oj b gy or oo l op oq">x = base_model.output</span><span id="414e" class="my mz it oj b gy or oo l op oq">### Add spatial average pooling and logistic layer<br/>x = GlobalAveragePooling2D()(x)<br/>predictions = Dense(len(labels), activation="sigmoid")(x)</span><span id="4824" class="my mz it oj b gy or oo l op oq">model = Model(inputs=base_model.input, outputs=predictions)<br/>model.compile(optimizer='adam', loss='categorical_crossentropy')</span><span id="64d5" class="my mz it oj b gy or oo l op oq">### Build model and predict<br/>model.fit(train_generator, validation_data=valid_generator,steps_per_epoch=100, validation_steps=25, epochs = 10)</span><span id="f669" class="my mz it oj b gy or oo l op oq">predicted_vals = model.predict(valid_generator, steps = len(valid_generator))</span></pre><h2 id="be17" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">可视化输出</h2><p id="064d" class="pw-post-body-paragraph li lj it lk b ll nq kd ln lo nr kg lq lr ns lt lu lv nt lx ly lz nu mb mc md im bi translated">使用AUC曲线可视化模型预测。每次迭代的AUC值保存在下表中:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/cdbf2ae89d0d0980f56f88a8d7e8afe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*wxguGZOkAfZYX8vbrlLLnw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">按增强状态划分的AUC值。图片作者。</p></figure><p id="6e70" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我为每种情况和增强状态创建了AUC曲线。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="63e0" class="my mz it oj b gy on oo l op oq">import numpy as np<br/>from sklearn.metrics import roc_auc_score, roc_curve</span><span id="b353" class="my mz it oj b gy or oo l op oq">def get_roc_curve(labels, predicted_vals, generator):<br/>    auc_roc_vals = []<br/>    for i in range(len(labels)):<br/>        try:<br/>            gt = generator.labels[:, i]<br/>            pred = predicted_vals[:, i]<br/>            auc_roc = roc_auc_score(gt, pred)<br/>            auc_roc_vals.append(auc_roc)<br/>            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)<br/>            plt.figure(1, figsize=(10, 10))<br/>            plt.plot([0, 1], [0, 1], 'k--')<br/>            plt.plot(fpr_rf, tpr_rf,<br/>                     label=labels[i] + " (" + str(round(auc_roc, 3)) + ")")<br/>            plt.xlabel('False positive rate')<br/>            plt.ylabel('True positive rate')<br/>            plt.title('ROC curve')<br/>            plt.legend(loc='best')<br/>        except:<br/>            print(<br/>                f"Error in generating ROC curve for {labels[i]}. "<br/>                f"Dataset lacks enough examples."<br/>            )<br/>    plt.show()<br/>    return auc_roc_vals</span><span id="cd34" class="my mz it oj b gy or oo l op oq">auc_rocs = get_roc_curve(labels, predicted_vals, valid_generator)</span></pre><h2 id="e738" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">没有增加</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/406358fd1d8efa43f916755f325976c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*OLOdMKoHHouUxzDJ9HmQ5w.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">无增强模型的性能。图片作者。</p></figure><h2 id="af0b" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">基本增强</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/3fe17eadf026b02650abb358045aa210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*BK_XXM8spa4J5JoC1JPMDA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">具有基本增强的模型的性能。图片作者。</p></figure><h2 id="4a74" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">复合扩增</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/3b62986c8b1fcd3edc02ec151a925ed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*66vse1WkrEp3yzf_vKWPpA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">具有复杂扩充的模型的性能。图片作者。</p></figure><p id="f080" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下表总结了使用增强功能的模型的性能:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/1c39a624e04973974958055845c1c3fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*o6EcwINw9I6kiuaik7VnVQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用不同形式增强的x射线多类分类的性能高于随机的类别数涉及大于0.5的曲线下面积(AUC)分数。图片作者。</p></figure><h2 id="3725" class="my mz it bd na nb nc dn nd ne nf dp ng lr nh ni nj lv nk nl nm lz nn no np iz bi translated">讨论和结论</h2><p id="c824" class="pw-post-body-paragraph li lj it lk b ll nq kd ln lo nr kg lq lr ns lt lu lv nt lx ly lz nu mb mc md im bi translated">在本文中，我介绍了数据扩充的概念，并在一个小型多类识别任务中演示了它的相对性能改进。数据增强是一种有用的工具，可以扩展深度学习模型的可用标记数据量。我描述了一些类型的数据扩充，并介绍了在不考虑分类方向的情况下进行扩充的潜在缺陷。在这个数据集中，复杂的增强在胸部x光片中表现不佳。疝通常出现在腹部底部附近的组织中。通过复杂的增强，由于颜色调整或旋转，我可能会改变模型区分疝和周围组织的能力。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/ad9ed4c86f60d70136bc49cb9e09e4e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L9uhGMvvIItNIUFUeewDPA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">显示食管裂孔疝相对位置的图像。图片来自维基百科。</p></figure><p id="5ea9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">建模只利用了全部可用数据的一小部分。超过4000幅训练图像(在复杂扩增中为24000幅)时，数据扩增的优势可能更加明显。这篇文章的代码可以在<a class="ae lh" href="https://github.com/Datadolittle/augmentation" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。同样，对于那些对医学成像数据集感兴趣的人来说，可以在<a class="ae lh" href="https://github.com/sfikas/medical-imaging-datasets" rel="noopener ugc nofollow" target="_blank"> Giorgos Sfikas的GitHub </a>找到大量资源。我的名字是<a class="ae lh" href="https://codyglickman.com/" rel="noopener ugc nofollow" target="_blank">科迪·格利克曼</a>，可以在<a class="ae lh" href="https://www.linkedin.com/in/codyglickman/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上找到我。一定要看看我下面的其他文章:</p><div class="mg mh gp gr mi mj"><a rel="noopener follow" target="_blank" href="/creating-photo-mosaics-using-python-49100e87efc"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd jd gy z fp mo fr fs mp fu fw jc bi translated">使用Python创建照片镶嵌</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">一步一步的教程，让你自己的美丽的图像</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ms l"><div class="ow l mu mv mw ms mx lb mj"/></div></div></a></div><div class="mg mh gp gr mi mj"><a rel="noopener follow" target="_blank" href="/to-beard-or-not-to-beard-that-is-the-question-b46864d7e003"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd jd gy z fp mo fr fs mp fu fw jc bi translated">刮胡子，还是不刮胡子，这是个问题</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">使用深度学习对有胡须和无胡须的照片进行年龄分类</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ms l"><div class="ox l mu mv mw ms mx lb mj"/></div></div></a></div><div class="mg mh gp gr mi mj"><a rel="noopener follow" target="_blank" href="/what-or-why-in-machine-learning-e2a73da528c8"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd jd gy z fp mo fr fs mp fu fw jc bi translated">机器学习中的什么或为什么</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">使用Python解释模型的综合指南</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ms l"><div class="oy l mu mv mw ms mx lb mj"/></div></div></a></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/8d3d4d738cde52875ff1a00b39935f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LMzIY-QzUoJbfBN8VpHpTA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">旋转增强。图片作者。</p></figure></div></div>    
</body>
</html>