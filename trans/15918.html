<html>
<head>
<title>Budget Automation for Bounding Box Annotation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于边界框注释的预算自动化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/budget-automation-for-bounding-box-annotation-500a76b4deb7?source=collection_archive---------31-----------------------#2020-11-02">https://towardsdatascience.com/budget-automation-for-bounding-box-annotation-500a76b4deb7?source=collection_archive---------31-----------------------#2020-11-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f797" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="2954" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">了解如何使用TensorFlow.js加速数据注记</h2></div><h1 id="b8e1" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">介绍👋</h1><p id="9f24" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae mc" href="https://www.bitsy.ai/automate-bounding-box-annotation-with-tensorflow-and-automl/" rel="noopener ugc nofollow" target="_blank">最初发布于bitsy.ai </a></p><p id="9a5d" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">数据收集和准备是每个机器学习应用的基础。你以前听说过:“垃圾输入，垃圾输出”，指的是算法纠正不准确、质量差或有偏见的输入数据的能力有限。</p><p id="740c" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">高质量标注数据的成本促使工具/平台的家庭工业加速数据标注过程。除了SaaS/本地创业生态系统，每个主要的云提供商(AWS、微软、谷歌)在过去两年都推出了自动化数据标签产品。可以理解的是，开发这些服务时通常会考虑到高级/企业用户、功能和价位。</p><h2 id="22a6" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">在有限的预算下，我是不是只能手工给<em class="mt">的所有东西</em>贴标签？</h2><p id="7c74" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">好消息。稍加努力，你就可以为你自己或一个小团队自动化边界框注释。在这篇博文中，我将向您展示我用来快速原型化3D打印故障检测模型的自动化技术。</p><p id="76ec" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">您将学习如何:</p><ol class=""><li id="5e1e" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb mz na nb nc bi translated">为人类贴标机创建详细的说明</li><li id="1dc7" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb mz na nb nc bi translated">训练制导模型</li><li id="e702" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb mz na nb nc bi translated">使用<a class="ae mc" href="https://github.com/microsoft/VoTT" rel="noopener ugc nofollow" target="_blank"> Microsoft VoTT </a>(可视对象标记工具)和TensorFlow.js自动标注边界框</li></ol><p id="d9ef" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">图为:自定义TensorFlow模型在微软VoTT(可视对象标记工具)中自动标注一个视频帧。</p><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi ni"><img src="../Images/99488a3abb64135a6c833013a7074fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*kVKPmyeGrXsWd5WNJ23tmw.gif"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">自定义张量流模型在Microsoft VoTT(可视对象标记工具)中自动注释视频帧。图片作者。</p></figure><h1 id="8f2f" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">第一遍注释🏷</h1><p id="5b2e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">如果您是从没有标签的地方开始，您确实需要硬着头皮手工注释一些数据。为注释决策创建书面指南和评估标准，需要手动标记至少几百个示例。</p><h2 id="cf5f" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">从源代码安装VoTT(视觉对象跟踪工具)</h2><p id="4f9b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">Microsoft VoTT是一个开源工具，用于用边界框(对象检测)和多边形(分割)来注释图像和视频。我使用VoTT是因为它:</p><ul class=""><li id="ec3a" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb ny na nb nc bi translated">支持多种导出格式</li><li id="5025" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">可以作为web应用程序托管</li><li id="4cc4" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">让我从TensorFlow.js模型预填充边界框建议</li></ul><p id="696b" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">安装先决条件:</p><ul class=""><li id="3ea2" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb ny na nb nc bi translated">NodeJS (&gt;= 10.x)和NPM。我推荐<a class="ae mc" href="https://github.com/nvm-sh/nvm" rel="noopener ugc nofollow" target="_blank"> NVM </a>(节点版本管理器)来管理NodeJS安装和环境。</li></ul><p id="598d" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">克隆VoTT repo并从源安装:</p><pre class="nj nk nl nm gt nz oa ob oc aw od bi"><span id="f61d" class="mi kp iq oa b gy oe of l og oh">$ git clone https://github.com/microsoft/VoTT <br/>$ cd VoTT <br/>$ npm ci <br/>$ npm i @tensorflow/tfjs@2.7.0 <br/>$ npm start</span></pre><p id="f98c" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">要使用较新的ops，必须升级TensorFlow.js包。</p><p id="1eee" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">参考<a class="ae mc" href="https://github.com/microsoft/VoTT#using-vott" rel="noopener ugc nofollow" target="_blank">使用VoTT </a>创建新项目并设置数据连接。</p><p id="95d5" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">寻找数据集？<a class="ae mc" href="https://datasetsearch.research.google.com" rel="noopener ugc nofollow" target="_blank">试试谷歌的数据集搜索</a>。</p><h2 id="7664" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">手动标记一些示例</h2><p id="0e93" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">您需要手动标记的图像数量取决于问题领域，从几十个图像到几千个图像。我通过以下方式为我的问题(检测3D打印缺陷)获得了合理的结果:</p><ul class=""><li id="dd6c" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb ny na nb nc bi translated">5个标签(分布如下)</li><li id="bb5f" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">67个打印延时视频，每秒采样3帧</li><li id="ae8e" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">浏览了6 248张图片</li><li id="b5b1" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">在3，215幅图像上绘制了9，004个边界框，平均每幅图像3个边界框。</li><li id="f51b" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">八小时，分几天完成。我在没有早晨通勤的情况下赶上了我一直忽略的播客。</li></ul><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/af1bb1d72e62a67e8cc3bf515ffcf0d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/0*GQPu6sgLks5OwFmK.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">VoTT(视觉对象跟踪工具)提供的数据集统计。图片作者。</p></figure><h2 id="3e03" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">编写注释指南</h2><p id="c375" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">当这个任务还历历在目时，花点时间写下清晰的指南(如下例),以保持标签的一致性，并涵盖常见的边缘情况。请随意使用我的指示作为你自己的模板。</p></div><div class="ab cl oj ok hu ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="ij ik il im in"><h1 id="3660" class="ko kp iq bd kq kr oq kt ku kv or kx ky kf os kg la ki ot kj lc kl ou km le lf bi translated">边界框注释指南</h1><h2 id="db2e" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">概念</h2><p id="5b12" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">2-3句话介绍任务/概念</p><p id="de17" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated"><em class="ov">该数据集包含失败的3D打印作业的延时视频。图像是按时间顺序排列的。您的任务是在所有可识别的像素周围画出紧密的方框，以匹配打印缺陷或对象。</em></p><h2 id="d156" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">标签</h2><p id="4283" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">id、文本名称、标签和边缘案例的书面描述、正面和负面示例</p><ul class=""><li id="1ff0" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb ny na nb nc bi translated">标签应该从0还是1开始？</li><li id="0242" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">0是否为背景/未知类保留？</li></ul><h2 id="6f1d" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">0背景</h2><h2 id="7429" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">1个喷嘴</h2><p id="bd1f" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">打印喷嘴是一个金属物体，它挤出热丝。</p><p id="164c" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">如果喷嘴被部分遮挡，围绕整个对象(包括遮挡的像素)绘制一个边界框。</p><p id="370d" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">如果喷嘴完全堵塞，不要贴标签。</p><h2 id="b102" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">2个木筏</h2><p id="54d2" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">“筏”是围绕印刷品前几层的薄轮廓。</p><p id="866a" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">如果筏子被部分遮挡(通常被印迹遮挡)，在整个筏子周围画一个边界框。</p><h2 id="43e6" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">3打印</h2><p id="a1a5" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">正在打印的对象。如果要打印多个对象或多个部分，请在每个不同的对象周围画一个边框。</p><h2 id="1b9e" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">4附着力</h2><p id="9b4f" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi">…</p><h2 id="ce83" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">5根意大利面条</h2><p id="86e5" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi">…</p><h2 id="203a" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">指导方针</h2><ul class=""><li id="593b" class="mu mv iq li b lj lk lm ln lp ow lt ox lx oy mb ny na nb nc bi translated">输入格式</li><li id="9fe1" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">标签格式</li><li id="9030" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">每帧1个还是多个对象？</li><li id="73c4" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">每个对象“实例”有1个还是多个盒子？</li><li id="ddfb" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">盒子是紧的还是松的？</li><li id="a2bd" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">标签反射(镜子，水)？</li></ul></div><div class="ab cl oj ok hu ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="ij ik il im in"><h2 id="6c3f" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">用AutoML训练制导模型🤖</h2><p id="5927" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">AutoML(自动机器学习)是一种属于“强力”算法类别的技术。基于云的AutoML平台是一个很好的工具，用来验证你的问题<em class="ov">可以</em>和<em class="ov">应该</em>用机器学习来解决。</p><p id="100c" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">即使你计划训练一个模型，也要考虑先把AutoML模型放在客户面前。尽早收集客户反馈，并将这些信息整合到定制模型的开发中。一些见解的例子…</p><ul class=""><li id="c35e" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb ny na nb nc bi translated">客户对误报不敏感(通过短信报告缺陷，但打印没问题)。</li><li id="da7b" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">大多数客户喜欢印刷进度的可视化更新，即使检测机不正确。</li><li id="7c4b" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">令人惊讶的是，一些客户报告的假阳性引起了安全感。</li></ul><p id="d739" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">我使用了<a class="ae mc" href="https://cloud.google.com/vision/automl/object-detection/docs" rel="noopener ugc nofollow" target="_blank">谷歌云自动视觉</a> Edge(物体检测)，我选择它是因为:</p><ul class=""><li id="35cb" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb ny na nb nc bi translated"><a class="ae mc" href="https://cloud.google.com/vision/automl/object-detection/docs/edge-quickstart" rel="noopener ugc nofollow" target="_blank"> S </a>支持模型导出到TensorFlow Lite、TensorFlow.js和ops，兼容Edge TPU、ARM和NVIDIA硬件加速。</li><li id="0973" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">披露:我是一名<a class="ae mc" href="https://developers.google.com/community/experts" rel="noopener ugc nofollow" target="_blank">谷歌开发专家</a>🤓</li></ul><h2 id="171f" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">从VoTT导出数据集</h2><p id="b3b5" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在项目的导出设置中，选择CSV提供程序。选中“包括图像”，保存配置，然后导出数据。如果您要导出数千幅图像，这将需要几分钟时间。休息一下！</p><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi oz"><img src="../Images/98998977b1f5a3ca080ad13665e61973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UVbqClfGGxHBaXlA.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">VoTT导出设置。图片作者。</p></figure><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi pa"><img src="../Images/c0991b35f9f905edff76577f890c58e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gSmNgWbWKWCdChqt.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">从VoTT导出的文件。图片作者。</p></figure><h2 id="92cb" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">检查和预处理数据</h2><p id="2e79" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">如果提供了两个顶点，AutoML Vision需要以下格式的CSV数据:</p><p id="3894" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated"><code class="fe pb pc pd oa b">SET,gs://path/to/img,label,x_min,y_min,,,x_max,y_max</code></p><p id="528f" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">坐标必须是相对于图像尺寸的<strong class="li ja">，落在范围【0，1】内。</strong></p><p id="0a52" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated"><a class="ae mc" href="https://gist.github.com/leigh-johnson/293f3380f15c496934e2846ec7f9ad16" rel="noopener ugc nofollow" target="_blank"> Github Gist </a>中提供的代码</p><pre class="nj nk nl nm gt nz oa ob oc aw od bi"><span id="6e09" class="mi kp iq oa b gy oe of l og oh">import pandas as pd<br/><br/># load VoTT CSV export<br/># notice: coordinates are absolute<br/>df = pd.read_csv('/path/to/vott-csv-export/{project name}-export.csv')<br/>df.head()</span></pre><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi pe"><img src="../Images/72758c90940138abf4ea43cb4783d44c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*P2VSjx9XMzK561_a.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">图片作者。</p></figure><pre class="nj nk nl nm gt nz oa ob oc aw od bi"><span id="81df" class="mi kp iq oa b gy oe of l og oh">import cv2<br/><br/>base_path = '/path/to/vott-csv-export/'<br/><br/>LOG_INTERVAL=2000<br/><br/># convert absolute coordinates to relative coordinates in [0, 1] range<br/>for index, row in df.iterrows():<br/>    if index % LOG_INTERVAL == 0:<br/>        print(f'finished {index} / {len(df)}')<br/>    filename = row['image_path'].split('/')[-1]<br/>    img = cv2.imread(f'{base_path}{filename}')<br/>    height, width, channels = img.shape<br/>    df.at[index, 'x1_n'] = row['x1'] / width<br/>    df.at[index, 'x2_n']= row['x2'] / width  <br/>    df.at[index, 'y1_n'] = row['y1'] / height<br/>    df.at[index, 'y2_n'] = row['y2'] / height<br/> <br/> <br/># replace relative image paths with a Google Storage bucket path<br/>df['set'] = 'UNASSIGNED'<br/>df['gs_path'] = df['image'] + 'gs://bucket-name/path/to/upload'<br/><br/># write CSV with columns expected by AutoML Vision<br/># the "none" columns are required for boxes defined by 2 vertices<br/>df['none'] = ''<br/>df.to_csv('/home/leigh/datasets/spaghetti/labeled/vott-csv-export/spaghetti_v1-normalized-export.csv', <br/>    columns=['set', 'image_path', 'label', 'x1_n', 'y1_n', 'none', 'none', 'x2_n', 'y2_n', 'none', 'none'],<br/>    index=False<br/>    )</span></pre><p id="1fc0" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">有关更多信息，请参考<a class="ae mc" href="https://cloud.google.com/vision/automl/object-detection/docs/prepare" rel="noopener ugc nofollow" target="_blank">准备您的培训数据</a>。</p><h2 id="22e9" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">上传数据</h2><p id="fc07" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">将数据上传到谷歌云存储桶。<strong class="li ja">注意:</strong>如果您正在创建一个新的时段，AutoML Vision exports在后面的步骤中要求目标时段在us-central-1地区。</p><ul class=""><li id="3ae7" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb ny na nb nc bi translated">新来GCP吗？在开始设置项目和认证之前，遵循<a class="ae mc" href="https://cloud.google.com/vision/automl/docs/edge-quickstart#before_you_begin" rel="noopener ugc nofollow" target="_blank">中的步骤。</a></li><li id="1827" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated"><a class="ae mc" href="https://cloud.google.com/storage/docs/gsutil" rel="noopener ugc nofollow" target="_blank">安装gsutil </a></li><li id="991f" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated"><code class="fe pb pc pd oa b">gsutil rsync -r /path/to/vott-csv-export gs://your-bucket-name/vott-csv-export/</code></li></ul><h2 id="fc43" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">将数据导入AutoML Vision</h2><ul class=""><li id="60bf" class="mu mv iq li b lj lk lm ln lp ow lt ox lx oy mb ny na nb nc bi translated">在GCP的控制台中打开<a class="ae mc" href="https://console.cloud.google.com/vision/datasets" rel="noopener ugc nofollow" target="_blank"> AutoML视觉数据集浏览器</a>。</li><li id="a468" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">创建新的数据集。在导入选项卡中，从存储桶中选择您的CSV文件。</li></ul><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/a8efede629de67d0b66aa36ac800994e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/0*ZnhwAqapeUgdwxqY.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">图片作者。</p></figure><p id="3045" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">数据导入时休息一下！👏</p><p id="e0b3" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">在训练之前，对导入的数据进行全面检查，并验证标签是否正确。</p><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi pg"><img src="../Images/16cbf8d73cc454e500385447b6cccb1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SokJkPZoS_ZRvtEB.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">3D打印的“筏”是一次性的支撑结构。图片作者。</p></figure><h2 id="1c61" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">火车模型</h2><p id="7991" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">AutoML的价格体系是基于<strong class="li ja">节点小时，</strong>与“挂钟”或运行时间不同。我的一个批评是，提前为培训工作定价需要一些额外的努力。</p><p id="3449" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated"><a class="ae mc" href="https://cloud.google.com/vision/automl/pricing?_ga=2.231171871.-1460275601.1603318024#free-trial" rel="noopener ugc nofollow" target="_blank"> AutoML Vision定价</a>(美元价格如下所示)因功能而异，不同的定价表适用于:</p><ul class=""><li id="0834" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb ny na nb nc bi translated">云托管分类和对象检测—3.15美元/节点小时，75.6美元/ 24小时</li><li id="189e" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">边缘(分类)-4.95美元/节点小时，118.80美元/ 24小时</li><li id="4de6" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">边缘(物体检测)——18.00美元/节点小时，432美元/ 24小时</li></ul><p id="387f" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">如果这些价格超出了您项目的预算，我将在未来的帖子中介绍我如何使用<a class="ae mc" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow的对象检测API </a>训练模型。关注或<a class="ae mc" href="https://www.bitsy.ai/" rel="noopener ugc nofollow" target="_blank">订阅我的简讯</a>以获得出版通知。</p><p id="4ac9" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">对于这个特殊的问题(检测3D打印缺陷)，我看到了使用我的数据集大小的推荐训练时间(24节点小时)的合理结果。深入到单个标签，“喷嘴”检测的表现明显比其他标签差。</p><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi ph"><img src="../Images/4c611aa99dcef05858468439d13a0fe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_492ET1xXxWctyTr.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">所有标签的指标。图片作者。</p></figure><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi pi"><img src="../Images/9dd074f5f4b140db6481fe12b3afdc0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BSFMzaAw_idpS_X0.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">“喷嘴”标签的指标。图片作者。</p></figure><p id="cccc" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">左:所有标签的精度/召回曲线。右图:“喷嘴”的精度/召回曲线</p><p id="bf88" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">经过更仔细的检查，我发现高的假阳性率显著影响了模型的精度分数。精度是<em class="ov">真阳性/(真阳性+假阳性)之和。我很兴奋地发现了一些例子，在这些例子中，我没有在地面真实数据中标注喷嘴。</em></p><p id="9e72" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">🤯即使我在第一次贴标签的过程中变得草率，指导模型已经足够好来捕捉这些错误。哇！如果我不得不手动标记这些数据的整体，它将充满错误。</p><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi pj"><img src="../Images/f22c7440f7230d2fcf4adbb433615bb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_yi3miIQonnIqWNw.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">我的模型自信地在这些图像中检测到“喷嘴”物体，由于人为错误标记地面真实数据，这些物体被评为“假阳性”。图片作者。</p></figure><h2 id="ea36" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">使用TensorFlow.js自动标注VoTT🤖</h2><p id="63bb" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">下一节将向您展示如何使用自定义TensorFlow.js模型来建议具有VoTT“主动学习”功能的边界框。</p><p id="eeac" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">“主动学习”使用TensorFlow.js模型在帧上执行推理，应用非最大抑制，并为每个检测到的对象绘制最佳框建议。</p><h2 id="2943" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">导出TensorFlow.js模型</h2><p id="1014" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">模型训练完成后，您可以在“测试和使用”选项卡中导出TensorFlow.js包。该模型将导出到一个存储桶中(目标桶必须在美国中部-1地区)。</p><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi pk"><img src="../Images/15ca1f3015840d822d843eba86fb86c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UWIXpkkbPre_leGU.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">谷歌云自动视觉边缘导出。图片作者。</p></figure><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi pl"><img src="../Images/6915a9c81ebb1ce3889a65cb7bd82a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6hYD_H7uoTXdq3LK.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">谷歌云自动视觉边缘导出。图片作者。</p></figure><h2 id="73de" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">创建classes.json文件</h2><p id="95d0" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我手动修复了这个。AutoML Vision Edge导出新行分隔的标签文件。VoTT要求的格式如下。标签索引必须从1！</p><pre class="nj nk nl nm gt nz oa ob oc aw od bi"><span id="96ec" class="mi kp iq oa b gy oe of l og oh">[{"id":1,"displayName":"nozzle"}, ... ]</span></pre><h2 id="f249" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">修补VoTT以修复TensorFlow 1.x -&gt; 2.x错误</h2><p id="f69a" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">VoTT自带@tensorflow/tfjs的v1。AutoML Vision Edge模型使用需要更新版本的操作系统(如AddV2)。我用以下补丁修复了几个小问题:</p><ul class=""><li id="ad53" class="mu mv iq li b lj md lm me lp mw lt mx lx my mb ny na nb nc bi translated">模型需要float32输入</li><li id="101c" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">使用较新的TF . image . nonmaxsupressionasync()fn</li></ul><pre class="nj nk nl nm gt nz oa ob oc aw od bi"><span id="f59b" class="mi kp iq oa b gy oe of l og oh">diff --git a/src/providers/activeLearning/objectDetection.ts b/src/providers/activeLearning/objectDetection.ts<br/>index 196db45..a8dff06 100755<br/>--- a/src/providers/activeLearning/objectDetection.ts<br/>+++ b/src/providers/activeLearning/objectDetection.ts<br/>@@ -151,6 +151,8 @@ export class ObjectDetection {<br/>         const batched = tf.tidy(() =&gt; {<br/>             if (!(img instanceof tf.Tensor)) {<br/>                 img = tf.browser.fromPixels(img);<br/>+                // model requires float32 input<br/>+                img = tf.cast(img, 'float32');<br/>             }<br/>             // Reshape to a single-element batch so we can pass it to executeAsync.<br/>             return img.expandDims(0);<br/>@@ -166,7 +168,8 @@ export class ObjectDetection {<br/>         const result = await this.model.executeAsync(batched) as tf.Tensor[];<br/> <br/>         const scores = result[0].dataSync() as Float32Array;<br/>-        const boxes = result[1].dataSync() as Float32Array;<br/>+        // tf.image.nonMaxSepressionAsync() expects tf.Tensor as input<br/>+        const boxes = result[1].dataSync()<br/> <br/>         // clean the webgl tensors<br/>         batched.dispose();<br/>@@ -177,10 +180,8 @@ export class ObjectDetection {<br/>         const prevBackend = tf.getBackend();<br/>         // run post process in cpu<br/>         tf.setBackend("cpu");<br/>-        const indexTensor = tf.tidy(() =&gt; {<br/>-            const boxes2 = tf.tensor2d(boxes, [result[1].shape[1], result[1].shape[3]]);<br/>-            return tf.image.nonMaxSuppression(boxes2, maxScores, maxNumBoxes, 0.5, 0.5);<br/>-        });<br/>+        const boxes2d = tf.tensor2d(boxes, [result[1].shape[0], result[1].shape[1]]);<br/>+        const indexTensor = await tf.image.nonMaxSuppressionAsync(boxes2d, maxScores, maxNumBoxes, 0.5, 0.5);<br/> <br/>         const indexes = indexTensor.dataSync() as Float32Array;<br/>         indexTensor.dispose();<br/>@@ -188,7 +189,9 @@ export class ObjectDetection {<br/>         // restore previous backend<br/>         tf.setBackend(prevBackend);<br/> <br/>-        return this.buildDetectedObjects(width, height, boxes, maxScores, indexes, classes);<br/>+        // _.buildDetectedObjects expects Float32Array input<br/>+        const fboxes = boxes as Float32Array<br/>+        return this.buildDetectedObjects(width, height, fboxes, maxScores, indexes, classes);<br/>     }</span></pre><h2 id="c8c3" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">自动包围盒建议✨</h2><ul class=""><li id="1fd0" class="mu mv iq li b lj lk lm ln lp ow lt ox lx oy mb ny na nb nc bi translated">修补VoTT后运行<code class="fe pb pc pd oa b">npm start</code></li><li id="76a3" class="mu mv iq li b lj nd lm ne lp nf lt ng lx nh mb ny na nb nc bi translated">在“主动学习”选项卡中，配置“模型路径”以指向您的TensorFlow.js导出。我建议启用“自动检测”功能，否则你必须手动按ctrl/cmd+d来对每一帧执行检测。</li></ul><figure class="nj nk nl nm gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi pm"><img src="../Images/4e97eeafca17342d4120b68d06e46ddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*H0GUyfYvwUXz09Sw.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">微软VoTT主动学习配置。图片作者。</p></figure><h2 id="fed7" class="mi kp iq bd kq mj mk dn ku ml mm dp ky lp mn mo la lt mp mq lc lx mr ms le iw bi translated">包扎</h2><p id="a96d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">您刚刚学习了如何将几个小时和几百美元用于自动边界框注释工作流。作为一个额外的奖励，指导模型可以适用于原型甚至是初始生产运行。我希望这能为你的下一个物体探测项目节省一点时间/精力！</p><p id="457b" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">与其他云产品相比，AutoML产品价格昂贵——但它们远不如从零开始开发一个可比较的模型或甚至使用重量转移学习这样的资源密集型产品<em class="ov">或</em>。</p><p id="9678" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">你目前正在使用物体探测器解决问题吗？请在下面的评论中告诉我更多关于你的理念和方法。</p><p id="e33b" class="pw-post-body-paragraph lg lh iq li b lj md ka ll lm me kd lo lp mf lr ls lt mg lv lw lx mh lz ma mb ij bi translated">订阅我的时事通讯@ <a class="ae mc" href="https://www.bitsy.ai/" rel="noopener ugc nofollow" target="_blank"> bitsy.ai </a>获取更多关于Raspberry Pi、Arduino和其他小型设备的ML应用的技巧、教程和详细文章。我目前正在为<a class="ae mc" href="https://octoprint.org/" rel="noopener ugc nofollow" target="_blank"> Octoprint </a>打造一个隐私优先的3D打印监控插件。</p></div></div>    
</body>
</html>