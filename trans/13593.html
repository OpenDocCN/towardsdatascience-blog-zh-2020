<html>
<head>
<title>Using machine learning to predict Rhine water levels</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习预测莱茵河水位</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-machine-learning-to-predict-rhine-water-levels-44afce697074?source=collection_archive---------11-----------------------#2020-09-18">https://towardsdatascience.com/using-machine-learning-to-predict-rhine-water-levels-44afce697074?source=collection_archive---------11-----------------------#2020-09-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e829" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">LSTM模型如何极大地改善了我的预测</strong></h2></div></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><p id="22a5" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">长短期记忆(LSTM)模型是一种功能强大的神经网络，非常适合预测与时间相关的数据。莱茵河的水位正好属于这一类:它们随着时间的推移而变化，取决于一系列变量，如雨水、温度和阿尔卑斯山的积雪。</p><p id="164a" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">莱茵河是欧洲的命脉。几个世纪以来，它一直是将货物运往德国、法国、瑞士和中欧的主要通道。然而，随着气候变化，河流水位可能会变得更加多变。因此，准确预测河流水位是从航运公司到大宗商品交易商和工业集团等一系列行为者的首要关切。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/619706abe97d17653ee9b26196ce27b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IkA1LZfGJy8I9hrxrxh6JQ.jpeg"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">一艘满载煤炭的驳船在莱茵河航行(来源:<a class="ae mb" href="https://commons.wikimedia.org/wiki/File:Coal_barge_Chilandia_on_Rhine_-_looking_south.jpg" rel="noopener ugc nofollow" target="_blank">https://commons . wikimedia . org/wiki/File:Coal _ barge _ Chilandia _ on _ Rhine _-_ looking _ south . jpg</a></p></figure><p id="e43b" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">与经典的基于回归的模型不同，LSTMs能够捕捉不同变量之间的非线性关系；更准确地说，这些变量之间的序列相关性。这篇博客关注的是使用LSTMs预测莱茵河的问题，而不是这些模型背后的理论。</p><h2 id="4404" class="mc md it bd me mf mg dn mh mi mj dp mk ky ml mm mn lc mo mp mq lg mr ms mt mu bi translated">眼前的问题</h2><p id="ea00" class="pw-post-body-paragraph kp kq it kr b ks mv ju ku kv mw jx kx ky mx la lb lc my le lf lg mz li lj lk im bi translated">我们在这里寻求解决的问题如下:我们希望尽可能精确地预测德国西部关键阻塞点Kaub的第二天水位。</p><p id="d879" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们有从2000年1月2日到2020年7月27日的历史每日数据，相当于7513次观测。数据集包括15个不同的类别，显示为列:</p><ul class=""><li id="1fa2" class="na nb it kr b ks kt kv kw ky nc lc nd lg ne lk nf ng nh ni bi translated">“日期”:观察的日期</li><li id="fea4" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“Kaub”:Kaub水位每天的差异，以厘米为单位——这是我们试图预测的“y”值(来源:WSV)</li><li id="0b2c" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">莱茵费尔登:瑞士莱茵费尔登的水流量的绝对值，单位为立方米每秒(来源:符拔)</li><li id="f8ec" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“Domat”:靠近莱茵河源头的Domat的水流量的绝对值，单位为立方米每秒(来源:符拔)</li><li id="8304" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“precip_middle”:莱茵河沿岸20个气象站记录的平均日降雨量，单位为毫米(来源:DWD)</li><li id="258d" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“avgtemp_middle”:在相同站点记录的平均温度，单位为摄氏度</li><li id="e1ab" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“最高温度_中间值”:在相同站点记录的最高温度</li><li id="d702" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“mintemp_middle”:相同站点记录的最低温度</li><li id="b34c" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“precip_main”:莱茵河主要支流美因河沿岸8个气象站记录的平均日降雨量，单位为毫米(来源:DWD)</li><li id="46d2" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“avgtemp_main”:在相同站点记录的平均温度，单位为摄氏度</li><li id="a62d" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“maxtemp_main”:在相同站点记录的最高温度</li><li id="d9bc" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“mintemp_main”:在相同站点记录的最低温度</li><li id="a9d0" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">precip _ neck ar:neck ar沿岸7个气象站记录的平均日降雨量，也是莱茵河的主要支流，单位为毫米(来源:DWD)</li><li id="5dc7" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“avgtemp_neckar”:在相同站点记录的平均温度，单位为摄氏度</li><li id="eed7" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“maxtemp_neckar”:在相同站点记录的最高温度</li><li id="0ba0" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">“mintemp_neckar”:在相同站点记录的最低温度</li></ul><p id="cff7" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">请注意，变量的选择完全是我的，是基于我处理莱茵分析的经验。无论是使用经典回归模型还是神经网络，选择正确的输入是时间序列分析中最重要的步骤之一。如果选择的变量太少，模型可能无法捕捉数据的全部复杂性(这称为欠拟合)。相比之下，如果选择太多输入，模型很可能会过度适应训练集。这很糟糕，因为这可能意味着模型很难归纳到一个新的数据集，而这个数据集对于预测是必不可少的。</p><p id="f096" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">首先，让我们加载本练习所需的所有库:</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="bc30" class="mc md it np b gy nt nu l nv nw">import datetime<br/>import matplotlib as mpl<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>import tensorflow as tf<br/>from sklearn.preprocessing import LabelEncoder<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.metrics import mean_squared_error<br/>import joblib</span></pre><p id="7240" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">下面是数据集前几行的示例。我们可以通过熊猫图书馆轻松加载它:</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="68d1" class="mc md it np b gy nt nu l nv nw"># first, we import data from excel using the read_excel function<br/>df = pd.read_excel('RhineLSTM.xlsx')<br/># then, we set the date of the observation as the index<br/>df.set_index('date', inplace=True)<br/>df.head()</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nx"><img src="../Images/031f8acbd320be848837e0092b4dd515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D-cb13kMnV9bobEexgYwYg.png"/></div></div></figure><p id="59a9" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">加载后，我们可以使用Matplotlib库绘制数据集:</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="defa" class="mc md it np b gy nt nu l nv nw"># specify columns to plot<br/>columns = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]<br/>i = 1<br/>values = df.values</span><span id="8c81" class="mc md it np b gy ny nu l nv nw"># define figure object and size<br/>plt.figure(figsize=(9,40))<br/># plot each column with a for loop<br/>for variable in columns:<br/>     plt.subplot(len(columns), 1, i)<br/>     plt.plot(values[:, variable])<br/>     plt.title(df.columns[variable], y=0.5, loc='right')<br/>     i += 1<br/>plt.show()</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nz"><img src="../Images/4e7cee913bc14e063308c36f8b62e00d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aYgq2-zWLvjXnZKnMBWmaA.png"/></div></div></figure><p id="7b3f" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">绘制变量直方图通常也是一个好主意:</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="8a77" class="mc md it np b gy nt nu l nv nw"># histograms of the variables<br/>df.hist(figsize=(9,18))<br/>plt.show()</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4c926d75981b85311f65a64b54b0aa08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*HU4ShFadbm6l2GQMWnmQMA.png"/></div></figure><p id="04b0" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">使用Seaborn库，您可以创建一个violin图来了解每个变量的分布:</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="1674" class="mc md it np b gy nt nu l nv nw"># calculate dataset mean and standard deviation<br/>mean = df.mean()<br/>std = df.std()<br/># normalise dataset with previously calculated values<br/>df_std = (df - mean) / std<br/># create violin plot<br/>df_std = df_std.melt(var_name='Column', value_name='Normalised')<br/>plt.figure(figsize=(12, 6))<br/>ax = sns.violinplot(x='Column', y='Normalised', data=df_std)<br/>_ = ax.set_xticklabels(df.keys(), rotation=90)</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ob"><img src="../Images/288659d48c9756b35a5220329048bd8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Myo1rrkwK0N0voOIYcNsHg.png"/></div></div></figure><h2 id="f112" class="mc md it bd me mf mg dn mh mi mj dp mk ky ml mm mn lc mo mp mq lg mr ms mt mu bi translated">评估不同的模型</h2><p id="0e76" class="pw-post-body-paragraph kp kq it kr b ks mv ju ku kv mw jx kx ky mx la lb lc my le lf lg mz li lj lk im bi translated">我在莱茵数据集上训练了不同类型的模型，以确定哪一个最适合:</p><ul class=""><li id="8165" class="na nb it kr b ks kt kv kw ky nc lc nd lg ne lk nf ng nh ni bi translated">基线模型，也称为持久性模型，返回Kaub水位的当前变化率作为预测(本质上预测“无变化”)。这是一个合理的基线，因为莱茵河水位通常会因更广泛的天气现象而在几天内发生变化(例如，阿尔卑斯山的缓慢融化逐渐向下游移动)。</li><li id="0d72" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">您可以训练的最简单模型假定输入变量和预测输出之间存在线性关系。与更复杂的模型相比，它的主要优点是易于解释，但是它的性能只比基线网络稍好。</li><li id="c6e7" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">密集网络更强大，但看不到输入变量如何随时间变化。多步密集和卷积神经网络解决了这一缺点，它采用多个时间步作为每次预测的输入。</li><li id="07da" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated">LSTM模型名列前茅，在验证和测试集上具有较低的平均绝对错误率。</li></ul><p id="4cc5" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">创建这个图表所需的Python代码对于这个博客来说太长了，但是你可以在这里访问它<a class="ae mb" href="https://www.tensorflow.org/tutorials/structured_data/time_series" rel="noopener ugc nofollow" target="_blank">，应用于不同的数据集。</a></p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/ffb3a43d48a28244d793cebd160ba867.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*HERgemdj375OuV9avrUXtw.png"/></div></figure><h2 id="9031" class="mc md it bd me mf mg dn mh mi mj dp mk ky ml mm mn lc mo mp mq lg mr ms mt mu bi translated">LSTM回归模型</h2><p id="a364" class="pw-post-body-paragraph kp kq it kr b ks mv ju ku kv mw jx kx ky mx la lb lc my le lf lg mz li lj lk im bi translated">LSTM网络是一种可以学习长数据序列的递归神经网络。它们不是神经元，而是由通过层相互连接的记忆块组成。内存块包含管理其状态和输出的门(输入、遗忘、输出)，使其比典型的神经元更聪明。</p><p id="37b2" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">它们在学术界被广泛用于预测河流高度，并被证明在某些情况下<a class="ae mb" href="https://arxiv.org/abs/1907.08456" rel="noopener ugc nofollow" target="_blank">优于</a>经典水文模型。</p><p id="6b43" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">让我们从本文开头的代码重新开始加载Rhine数据库:</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="b359" class="mc md it np b gy nt nu l nv nw">import datetime<br/>import matplotlib as mpl<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>import tensorflow as tf<br/>from sklearn.preprocessing import LabelEncoder<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.metrics import mean_squared_error<br/>import joblib</span><span id="d0ad" class="mc md it np b gy ny nu l nv nw"># first, we import data from excel using the read_excel function<br/>df = pd.read_excel('RhineLSTM.xlsx', sheet_name='Detailed4_MAIN’)<br/># then, we set the date of the observation as the index<br/>df.set_index('date', inplace=True)</span></pre><p id="45da" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr iu"> <em class="od">数据准备</em> </strong></p><p id="1e6b" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">要构建正常运行的LSTM网络，第一步(也是最困难的一步)是准备数据。</p><p id="aa5e" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们将把问题框定为根据今天和前6天的天气和瑞士上游流量(backward_steps = 7)预测今天Kaub水位(t)的变化率。</p><p id="2cab" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">使用Scikit-Learn库中的StandardScaler()函数对数据集进行标准化。对于数据帧的每一列，该列中的每个值减去平均值，然后除以整列的标准偏差。对于大多数机器学习模型来说，这是一个非常普通的步骤，并允许整个网络更快地学习(下面将详细介绍)。</p><p id="1ff4" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">然后，数据帧通过一个转换函数。对于每一列，我们为前7天的值创建一个副本(15 * 7 = 120列)。得到的数据帧的形状是7506行×120列。</p><p id="7473" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">很多代码都是受这篇精彩的<a class="ae mb" href="https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/" rel="noopener ugc nofollow" target="_blank">博客文章</a>的启发。</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="f197" class="mc md it np b gy nt nu l nv nw"># load dataset<br/>values = df.values<br/># ensure all data is float<br/>values = values.astype('float32')<br/># normalise each feature variable using Scikit-Learn<br/>scaler = StandardScaler()<br/>scaled = scaler.fit_transform(values)<br/># save scaler for later use<br/>joblib.dump(scaler, 'scaler.gz')</span><span id="f83b" class="mc md it np b gy ny nu l nv nw"># specify the number of lagged steps and features<br/>backward_steps = 7<br/>n_features = df.shape[1]</span><span id="6725" class="mc md it np b gy ny nu l nv nw"># convert series to supervised learning<br/>def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):<br/>     n_vars = 1 if type(data) is list else data.shape[1]<br/>     df = pd.DataFrame(data)<br/>     cols, names = list(), list()<br/>     # input sequence (t-n, ... t-1)<br/>     for i in range(n_in, 0, -1):<br/>          cols.append(df.shift(i))<br/>          names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]<br/>     # forecast sequence (t, t+1, ... t+n)<br/>     for i in range(0, n_out):<br/>          cols.append(df.shift(-i))<br/>          if i == 0:<br/>                names += [('var%d(t)' % (j+1)) for j in range(n_vars)]<br/>          else:<br/>               names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]<br/>      # put it all together<br/>      agg = pd.concat(cols, axis=1)<br/>      agg.columns = names<br/>      # drop rows with NaN values<br/>      if dropnan:<br/>          agg.dropna(inplace=True)<br/>      return agg</span><span id="51b2" class="mc md it np b gy ny nu l nv nw"># frame as supervised learning<br/>reframed = series_to_supervised(scaled, backward_steps, 1)</span></pre><p id="d513" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr iu"> <em class="od">定义训练和测试数据集</em> </strong></p><p id="4e08" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们必须将准备好的数据帧分成训练和测试数据集，以便对我们的结果进行公正的评估。训练数据集代表80%的值，我们将使用剩余的20%进行评估。当我们处理按时间顺序排列的数据时，打乱数据集的顺序是一个非常糟糕的主意，所以我们让它保持原样。接下来，我们将训练和测试数据集重塑为三维，以备后用。</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="ce0b" class="mc md it np b gy nt nu l nv nw"># split into train and test sets<br/>values = reframed.values<br/>threshold = int(0.8 * len(reframed))<br/>train = values[:threshold, :]<br/>test = values[threshold:, :]<br/># split into input and outputs<br/>n_obs = backward_steps * n_features<br/>train_X, train_y = train[:, :n_obs], train[:, -n_features]<br/>test_X, test_y = test[:, :n_obs], test[:, -n_features]<br/>print(train_X.shape, len(train_X), train_y.shape)<br/># reshape input to be 3D [samples, timesteps, features]<br/>train_X = train_X.reshape((train_X.shape[0], backward_steps, n_features))<br/>test_X = test_X.reshape((test_X.shape[0], backward_steps, n_features))<br/>print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)</span></pre><p id="0b93" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr iu"> <em class="od">拟合模型</em> </strong></p><p id="43d2" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">最后，我们能够适应我们的LSTM网络。多亏了TensorFlow/Keras库，这只需要几行代码。我选择了64个内存块，批量大小为72。我使用Adam优化算法，它比经典的梯度下降法更有效。</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="72bd" class="mc md it np b gy nt nu l nv nw"># design network<br/>model = tf.keras.models.Sequential()<br/>model.add(tf.keras.layers.LSTM(64, input_shape=(train_X.shape[1], train_X.shape[2])))<br/>model.add(tf.keras.layers.Dense(1))<br/>model.compile(loss='mae', optimizer='adam')<br/># define early stopping parameter<br/>callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)<br/># fit network<br/>history = model.fit(train_X, train_y, epochs=25, callbacks=[callback], batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)<br/># plot history<br/>plt.figure(figsize=(12, 6))<br/>plt.plot(history.history['loss'], label='train')<br/>plt.plot(history.history['val_loss'], label='test')<br/>plt.ylabel('mean absolute error [Kaub, normalised]')<br/>plt.legend()<br/>plt.show()</span></pre><h2 id="0722" class="mc md it bd me mf mg dn mh mi mj dp mk ky ml mm mn lc mo mp mq lg mr ms mt mu bi translated">模型结果</h2><p id="7314" class="pw-post-body-paragraph kp kq it kr b ks mv ju ku kv mw jx kx ky mx la lb lc my le lf lg mz li lj lk im bi translated">模型拟合后，我们可以启动预测并反转比例以获得最终结果。然后，我们可以计算模型的误差分数。在这里，该模型实现了6.2厘米的均方根误差(RMSE)，这是很好的，但可能还可以改进。</p><pre class="lm ln lo lp gt no np nq nr aw ns bi"><span id="54b0" class="mc md it np b gy nt nu l nv nw"># make a prediction<br/>yhat = model.predict(test_X)<br/>test_X = test_X.reshape((test_X.shape[0], backward_steps*n_features))<br/># invert scaling for forecast<br/>inv_yhat = np.concatenate((yhat, test_X[:, -(n_features - 1):]), axis=1)<br/>inv_yhat = scaler.inverse_transform(inv_yhat)<br/>inv_yhat = inv_yhat[:,0]<br/># invert scaling for actual<br/>test_y = test_y.reshape((len(test_y), 1))<br/>inv_y = np.concatenate((test_y, test_X[:, -(n_features - 1):]), axis=1)<br/>inv_y = scaler.inverse_transform(inv_y)<br/>inv_y = inv_y[:,0]<br/># calculate RMSE<br/>rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))<br/>print('Test RMSE: %.3f' % rmse)</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oe"><img src="../Images/b6e4e3fc910844ec60a58fcfee94afa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNqkugfwQwT-68o-R2QK8Q.png"/></div></div></figure><p id="6277" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我还检查了该模型在极端天气事件中的性能，例如2016年5月至6月在欧洲记录的大范围洪水，仅在巴伐利亚就造成了超过10亿欧元的损失。该模型通常能够跟踪水位的上升，但是在两个特定的高峰期间(一个在4月中旬，另一个在6月初)，它给出的数字很低。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oe"><img src="../Images/5c717f48604b4a52dad2ee8528caf209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2wQ6j21wI7FwPWp4Tz3BXg.png"/></div></div></figure><p id="59d6" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">经过训练的LSTM网络在2019年5月的阿克塞尔风暴期间也表现良好，该风暴导致连续两天水位高度快速上升超过1米。然而，当洪水达到峰值时，它再次给出了比实际数字略低的估计。</p><p id="0e55" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在这两种情况下，我怀疑低的数字是由于一个主要的莱茵河支流，摩泽尔河，它被排除在分析之外，因为缺乏可靠的气象数据。摩泽尔河在考布以北的科布伦茨与莱茵河汇合。这是未来可能改进的领域。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oe"><img src="../Images/81f1b6ae525522b93f65ad9b6d1bfd50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cjYe7gmefpboOePCCnIrVQ.png"/></div></div></figure><h2 id="8750" class="mc md it bd me mf mg dn mh mi mj dp mk ky ml mm mn lc mo mp mq lg mr ms mt mu bi translated">模型性能</h2><p id="23d7" class="pw-post-body-paragraph kp kq it kr b ks mv ju ku kv mw jx kx ky mx la lb lc my le lf lg mz li lj lk im bi translated">寻找最佳超参数是机器学习中最重要(也是最耗时)的任务之一。为了找到最佳设置，我运行了许多不同版本的网络:</p><ul class=""><li id="4b77" class="na nb it kr b ks kt kv kw ky nc lc nd lg ne lk nf ng nh ni bi translated"><em class="od">预处理:</em>对于那些熟悉Scikit-Learn的人来说，我发现StandardScaler()比MinMaxScaler()更适合莱茵数据集，后者将所有值归一化到0到1之间。使用MinMaxScaler()对值进行归一化会产生不稳定的性能。快速浏览一下本文开头绘制的直方图可以发现，大多数莱茵输入变量遵循高斯分布，因此这是合乎逻辑的。</li><li id="726f" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated"><em class="od">倒退:</em>我发现7天是天气分析的合理时间框架，并给出了水从阿尔卑斯山流下所需的时间。增加超过这个数字的步骤对模型的性能没有有意义的改进。</li><li id="58e2" class="na nb it kr b ks nj kv nk ky nl lc nm lg nn lk nf ng nh ni bi translated"><em class="od">神经元:</em>由16个记忆细胞组成的小型网络表现不佳，但由32个或更多神经元组成的大型网络则相当相似。我为我的模型选择了64个记忆单元。</li></ul><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi of"><img src="../Images/1fab1280f58dd7048d01cf8b0546498a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1lgQgoSR4sNfdG5b368-GQ.png"/></div></div></figure><ul class=""><li id="389e" class="na nb it kr b ks kt kv kw ky nc lc nd lg ne lk nf ng nh ni bi translated"><em class="od"> Epochs: </em>一旦算法遍历数据集25次，我就选择停止训练。超过这个阈值，性能开始趋于平稳，模型开始过度适应训练集。</li></ul><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi gj"><img src="../Images/a9c67cf8f1285f45fb4acf65687fc2cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bm9PbL7FjeSOpNKWGYO4_w.png"/></div></div></figure><p id="669b" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我已经在网上部署了这个模型的一个版本。其性能可以在<a class="ae mb" href="http://www.rhineforecast.com/" rel="noopener ugc nofollow" target="_blank">这里</a>进行监控。</p><p id="8f4a" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我将在未来通过添加/删除变量和进一步调整超参数来尝试改进这个模型。如果你有任何想法，不要犹豫<a class="ae mb" href="mailto:%20oliv.lejeune@gmail.com" rel="noopener ugc nofollow" target="_blank">与我联系</a>。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi og"><img src="../Images/fcf658488545ce5baf4e578c4b249e55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T5AiXqHi0zA0svO2yU1j9A.png"/></div></div></figure></div></div>    
</body>
</html>