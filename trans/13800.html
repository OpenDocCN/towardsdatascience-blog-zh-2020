<html>
<head>
<title>How to generate synthetic tabular data?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何生成合成表格数据？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-generate-synthetic-tabular-data-bcde7c28038a?source=collection_archive---------20-----------------------#2020-09-22">https://towardsdatascience.com/how-to-generate-synthetic-tabular-data-bcde7c28038a?source=collection_archive---------20-----------------------#2020-09-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="766c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">生成敌对网络的Wasserstein损失</h2></div><p id="c91e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在过去的一篇博客文章中，我已经介绍了什么是生成性对抗网络，以及我们如何使用它们来生成设计为私有的数据，在这篇文章中，我介绍了T2的普通GAN和条件GAN。但是，尽管非常有前景，但这些生成性对抗网络的训练非常具有挑战性，并且它们生成的数据没有足够的质量用于ML工作负载作为真实数据的替代。还有许多其他有趣的GAN架构，其中一些引入了更稳定的训练和更少的模式崩溃倾向的改进，今天我将涵盖<a class="ae le" href="https://arxiv.org/pdf/1701.07875.pdf" rel="noopener ugc nofollow" target="_blank"> Wasserstein GAN </a>。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="cb30" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">瓦瑟斯坦·甘</h1><p id="2843" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">Wasserstein GAN被认为是Ian good fellow提出的生成性对抗网络的延伸。WGAN是由Martin Arjovsky在2017年推出的，承诺在训练模型时提高稳定性，并引入能够与生成事件的质量相关联的损失函数。<em class="mj">听起来不错吧</em>？但是和WGAN引入的核心区别是什么？</p><h2 id="63e0" class="mk ln it bd lo ml mm dn ls mn mo dp lw kr mp mq ly kv mr ms ma kz mt mu mc mv bi translated">WGAN有什么新功能？</h2><p id="d215" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">GAN没有使用“鉴别器”的概念来分类或预测某个生成事件的真实或虚假的概率，而是引入了“评论家”的概念，简而言之，该概念对给定事件的真实或虚假进行评分。这种变化主要是由于当训练生成器时，理论上我们应该寻求在训练数据集中观察到的数据分布和在生成的例子中观察到的分布之间的距离的最小化。</p><p id="8e79" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以将WGAN引入的主要差异总结如下:</p><ol class=""><li id="0001" class="mw mx it kk b kl km ko kp kr my kv mz kz na ld nb nc nd ne bi translated">使用从Wasserstein距离导出的新损失函数。</li><li id="316f" class="mw mx it kk b kl nf ko ng kr nh kv ni kz nj ld nb nc nd ne bi translated">critic函数每次梯度更新后，将权重箝位在一个小的固定范围内，[-c，c]。这允许实施Lipschitz约束。</li><li id="742e" class="mw mx it kk b kl nf ko ng kr nh kv ni kz nj ld nb nc nd ne bi translated">向歧视者——批评家提出的替代方案。</li><li id="f78d" class="mw mx it kk b kl nf ko ng kr nh kv ni kz nj ld nb nc nd ne bi translated">使用线性激活函数作为Critic网络的输出线性。</li><li id="02dc" class="mw mx it kk b kl nf ko ng kr nh kv ni kz nj ld nb nc nd ne bi translated">生成器和评论家网络的更新次数不同。</li></ol><h2 id="c6b4" class="mk ln it bd lo ml mm dn ls mn mo dp lw kr mp mq ly kv mr ms ma kz mt mu mc mv bi translated">好处</h2><p id="8a69" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">前面提到的和WGAN引入的变化在训练这些网络时带来了一系列好处:</p><ul class=""><li id="fc04" class="mw mx it kk b kl km ko kp kr my kv mz kz na ld nk nc nd ne bi translated">与例如最初提出的GAN相比，WGAN的训练更加稳定。</li><li id="0d81" class="mw mx it kk b kl nf ko ng kr nh kv ni kz nj ld nk nc nd ne bi translated">它对模型架构的选择不太敏感(生成器和评论家的选择)</li><li id="66ef" class="mw mx it kk b kl nf ko ng kr nh kv ni kz nj ld nk nc nd ne bi translated">此外，受超参数选择的影响较小，尽管这对于获得良好结果仍然非常重要。</li><li id="aae8" class="mw mx it kk b kl nf ko ng kr nh kv ni kz nj ld nk nc nd ne bi translated">最后，我们能够将批评家的损失与生成事件的整体质量联系起来。</li></ul><h2 id="6ce3" class="mk ln it bd lo ml mm dn ls mn mo dp lw kr mp mq ly kv mr ms ma kz mt mu mc mv bi translated">使用Tensorflow 2.0实施</h2><figure class="nl nm nn no gt np"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="dd2e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们已经完成了导入，让我们来看看网络:生成器和评论家。</p><figure class="nl nm nn no gt np"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="b78f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与生成器类似，我决定为评论家选择一个简单的网络。在这里，我有一个4密集层网络，也Relu激活。但是，我想在这里强调一下最后一行代码。与普通GAN不同，我们通常将它作为网络的最后一层:</p><pre class="nl nm nn no gt ns nt nu nv aw nw bi"><span id="07a0" class="mk ln it nt b gy nx ny l nz oa">x = Dense(1, activation=’sigmoid’)(x))</span></pre><p id="ced8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它在鉴别器的输出层使用sigmoid函数，这意味着它预测给定事件为真实事件的可能性。当谈到WGAN时，critic模型需要线性激活，以便预测给定事件的“真实度”得分。</p><pre class="nl nm nn no gt ns nt nu nv aw nw bi"><span id="a40b" class="mk ln it nt b gy nx ny l nz oa">x = Dense(1)(x)</span></pre><p id="0dcb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">或者</p><pre class="nl nm nn no gt ns nt nu nv aw nw bi"><span id="3918" class="mk ln it nt b gy nx ny l nz oa">x = Dense(1, activation=’linear’)(x)</span></pre><figure class="nl nm nn no gt np"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="9d78" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我提到的，WGAN模型的主要贡献是使用了一个新的损失函数Wasserstein损失。在这种情况下，我们可以在Keras中将Wasserstein损失实现为一个自定义函数，它计算真实事件和生成事件的平均分数。</p><p id="d6ab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分数是真实事件最大化，生成事件最小化。下面实施瓦瑟斯坦损失:</p><figure class="nl nm nn no gt np"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="cbd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一个重要的变化是为评论家网络引入了权重裁剪。在这种情况下，我决定用下面的方法定义扩展Keras约束类:</p><figure class="nl nm nn no gt np"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="f54b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们已经介绍了主要的变化，您可以在这个<a class="ae le" href="https://github.com/ydataai/gan-playground" rel="noopener ugc nofollow" target="_blank"> open GitHub存储库中找到WGAN的完整实现，由YData </a>提供支持。</p><h2 id="2901" class="mk ln it bd lo ml mm dn ls mn mo dp lw kr mp mq ly kv mr ms ma kz mt mu mc mv bi translated">WGAN面临的挑战</h2><p id="a820" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">尽管WGAN为数据生成领域带来了许多好处，但它仍然有一些需要解决的挑战:</p><ul class=""><li id="1a7e" class="mw mx it kk b kl km ko kp kr my kv mz kz na ld nk nc nd ne bi translated">尽管与其他架构相比更加稳定，但仍然存在训练不稳定的问题</li><li id="523a" class="mw mx it kk b kl nf ko ng kr nh kv ni kz nj ld nk nc nd ne bi translated">权重裁剪后收敛缓慢-当裁剪窗口太大时</li><li id="d2f7" class="mw mx it kk b kl nf ko ng kr nh kv ni kz nj ld nk nc nd ne bi translated">消失渐变—当剪辑窗口太小时</li></ul><p id="e92f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自其发表以来，基于WGAN主要问题与所选权重裁剪方法相关的事实，一些建议的改进是最有前途的改进之一，并使用了梯度惩罚— <a class="ae le" href="https://arxiv.org/abs/1704.00028" rel="noopener ugc nofollow" target="_blank"> WGAN-GP文章</a>。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="2003" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">表格数据生成</h1><p id="bf2d" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">现在，我们已经介绍了WGAN及其实现的大部分理论知识，让我们开始使用它来生成合成的表格数据。</p><p id="3288" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">出于这个练习的目的，我将使用我之前在这篇博文中提到的存储库中的WGAN实现。</p><p id="e8e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将用于此目的的数据集是数据科学界非常熟悉的一个数据集，即<a class="ae le" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">信用欺诈数据集</a>。</p><figure class="nl nm nn no gt np"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="82a4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">出于演示的目的，我决定选择这个数据集的一个较小的样本。在这种情况下，我决定只综合欺诈事件。</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div role="button" tabindex="0" class="oc od di oe bf of"><div class="gh gi ob"><img src="../Images/fd14bc5c784e793ef5bfa8940f7c9347.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPGSLzaGTbdniOsNrnJYcg.png"/></div></div><p class="oi oj gj gh gi ok ol bd b be z dk translated"><a class="ae le" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">信用欺诈数据集</a>的小样本。</p></figure><figure class="nl nm nn no gt np"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="6c96" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在对数据进行几个<a class="ae le" href="https://github.com/ydataai/gan-playground/blob/master/preprocessing/credit_fraud.py" rel="noopener ugc nofollow" target="_blank">预处理步骤</a>之后，我们准备好将数据输入WGAN。</p><h2 id="4dfb" class="mk ln it bd lo ml mm dn ls mn mo dp lw kr mp mq ly kv mr ms ma kz mt mu mc mv bi translated">更新批评家的次数要比生成器多</h2><p id="112a" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">在其他GAN架构中，如<a class="ae le" href="https://www.sciencedirect.com/science/article/pii/S1877050918308019" rel="noopener ugc nofollow" target="_blank"> DCGAN </a>，发生器和鉴频器模型必须在相同的时间内更新。但是对于WGAN来说，这并不完全正确。在这种情况下，critic模型必须比generator模型更新更多次。</p><p id="abca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是为什么我们有一个输入参数，我称之为<em class="mj">n _ critic</em>——这个参数控制critic从每批生成器获得更新的次数。在这种情况下，我将它设置为3次。但是你可以为其他人设置并检查最终结果的影响。</p><figure class="nl nm nn no gt np"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="6cd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与其他<a class="ae le" href="https://medium.com/ydata-ai/generating-synthetic-tabular-data-with-gans-part-2-a0aba150539?source=friends_link&amp;sk=68627fc6289ec0650ad746d17407ed4d" rel="noopener"> GAN架构</a>的训练过程相比，在使用相同数据集的情况下，可以看出WGAN训练确实不太容易出现不稳定性，产生的结果更接近真实数据集分布，尽管并不完美。</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div class="gh gi om"><img src="../Images/9e2bfa4c0f61d91dba57a14ff6ed3558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*oCfWirFylHUOECKNroBr4Q.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">WGAN在1000个时期后为V1和V10变量生成数据点</p></figure><p id="2b20" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我还决定通过利用主成分分析和TSNE算法来降低数据集的维度，选择两个分量，以简化数据的可视化。下面你可以找到这些图，我比较了WGAN生成的数据和原始数据的PCA和TSNE结果。很明显，WGAN未能符合原始数据中捕获的一些行为，尽管如此，结果还是很有希望的。</p><figure class="nl nm nn no gt np gh gi paragraph-image"><div role="button" tabindex="0" class="oc od di oe bf of"><div class="gh gi on"><img src="../Images/9de9f1a0393c65a1dc8c0b2f54676581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*meIlSU92ZlDmUVACIBQIMw.png"/></div></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">PCA和TSNE对合成和原始欺诈事件进行了计算，包括两个部分</p></figure><figure class="nl nm nn no gt np gh gi paragraph-image"><div role="button" tabindex="0" class="oc od di oe bf of"><div class="gh gi oo"><img src="../Images/b66d68f1a6f4d355197a64cdca06a557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Om8i21mIjQfFSKPsDW40w.png"/></div></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">合成数据集和原始数据集之间的基本统计差异。越轻差别越小。</p></figure></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="b65c" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">结论</h1><p id="c1b6" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">与使用GANs生成具有真实价值的合成数据以用于机器学习任务并以保护隐私的方式共享相比，本文中显示的结果仍然非常简单。与其他架构相比，Wasserstein作为损失函数的引入无疑有助于使训练更加稳定，并且对网络架构和超参数的选择不太敏感。</p><p id="18c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于那些对生成合成表格数据感兴趣并想尝试一下的人，可以看看这个<a class="ae le" href="https://github.com/ydataai/gan-playground" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>。我们将使用新的GAN架构和新的数据集示例对其进行更新，并邀请您参与合作。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="8948" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae le" href="https://www.linkedin.com/in/fabiana-clemente/" rel="noopener ugc nofollow" target="_blank"> <em class="mj">法比亚娜</em> </a> <em class="mj">是CDO在</em> <a class="ae le" href="https://ydata.ai/?utm_source=medium&amp;utm_medium=signature&amp;utm_campaign=blog" rel="noopener ugc nofollow" target="_blank"> <em class="mj"> YData </em> </a> <em class="mj">。</em></p><p id="4130" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">改进了人工智能的数据</strong></p><p id="fa47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae le" href="https://ydata.ai/?utm_source=medium&amp;utm_medium=signature&amp;utm_campaign=blog" rel="noopener ugc nofollow" target="_blank"> <em class="mj"> YData为数据科学家提供了一个以数据为中心的开发平台，致力于高质量的合成数据。</em>T19】</a></p></div></div>    
</body>
</html>