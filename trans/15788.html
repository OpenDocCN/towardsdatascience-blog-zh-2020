<html>
<head>
<title>Incremental window functions using AWS Glue Bookmarks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用AWS粘合书签的增量窗口函数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/incremental-window-functions-using-aws-glue-bookmarks-edb71990a58d?source=collection_archive---------33-----------------------#2020-10-30">https://towardsdatascience.com/incremental-window-functions-using-aws-glue-bookmarks-edb71990a58d?source=collection_archive---------33-----------------------#2020-10-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e0a7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">无序数据着陆问题</h2></div><h1 id="1694" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">无序数据着陆问题</h1><p id="794c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果数据无序到达(相对于应用窗口函数的维度)，对数据应用窗口函数是很重要的。为了清楚起见，让我们把这个例子中的时间序列数据作为我们的窗口维度。如果时间序列数据从一周的星期二到星期四到达，那么该周的星期一的数据在较晚的时间到达，则数据到达是无序的。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/c9a2fe199ead7f7624550b86de43ae73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IoYB5aTrnpDamVT0"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">里卡多·戈麦斯·安吉尔在<a class="ae mj" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7499" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">由于窗函数输出在时间空间上对其周围环境敏感，窗函数的结果将被到达的新的无序数据改变。所有受影响的数据都需要重新处理。</p><p id="53cf" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">当数据无序到达时，您可以重新处理所有数据。但是，当数据量很大时，重新处理整个数据集变得不切实际。本文讨论了一种有效的方法，使用我在以前的<a class="ae mj" rel="noopener" target="_blank" href="/incremental-join-using-aws-glue-bookmarks-ad8fb2b05505">文章</a>中描述的构建AWS粘合谓词下推的方法。这种方法仅重新处理受已到达的无序数据影响的数据。</p><h1 id="e5b3" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">解决办法</h1><h1 id="1fe4" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">粘附ETL作业环境设置</h1><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="mp mq l"/></div></figure><h1 id="d410" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">检查新数据</h1><p id="3164" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用AWS粘合书签只将新数据输入粘合ETL作业。</p><pre class="lu lv lw lx gt mr ms mt mu aw mv bi"><span id="713b" class="mw kg iq ms b gy mx my l mz na">new = glueContext.create_dynamic_frame.from_catalog(database="db", table_name="table", transformation_ctx='new')</span></pre><p id="f728" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">为新数据涉及的每个分区找到最早的时间戳分区。</p><p id="ed53" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">注意:在下面的示例中，数据被分区为<code class="fe nb nc nd ms b">partition1</code> &gt; <code class="fe nb nc nd ms b">timestamp_partition</code>，其中<code class="fe nb nc nd ms b">timestamp_partition</code>是唯一的时间序列分区。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="f539" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">从需要处理/重新处理的整个数据集中构建数据的下推谓词字符串。对于没有无序数据的分区，手动定义一个数据窗口来解锁过去的数据，以确保正确处理新的有序数据。</p><p id="058c" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">注意:在下面的例子中，我们按照日期在<code class="fe nb nc nd ms b">timestamp_partition</code>中进行分区。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="mp mq l"/></div></figure><h1 id="27c8" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">对所有需要的数据应用窗口函数</h1><p id="4d8e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在，我们可以使用刚刚构建的谓词字符串加载所有需要处理/重新处理的数据。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="c690" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">然后，我们可以在加载的所有数据上定义我们的窗口。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="7d0c" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">在你的窗口上应用你的函数，这里我们以<code class="fe nb nc nd ms b">last</code>函数为例。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="a6dd" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">为了确保在重新处理过程中被更改的任何旧数据被覆盖，请使用PySpark API <code class="fe nb nc nd ms b">overwrite</code>模式直接访问S3。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="mp mq l"/></div></figure><h1 id="85a8" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">结论</h1><p id="f1c8" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">根据从AWS粘合书签传递的新数据构建下推谓词字符串仅允许处理/重新处理数据集的所需分区，即使在使用窗口函数时也是如此，窗口函数对其在数据集中的周围环境固有地敏感。</p></div><div class="ab cl ne nf hu ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ij ik il im in"><p id="335b" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated"><em class="nl">原载于</em><a class="ae mj" href="https://datamunch.tech." rel="noopener ugc nofollow" target="_blank"><em class="nl">https://data munch . tech .</em></a></p></div></div>    
</body>
</html>