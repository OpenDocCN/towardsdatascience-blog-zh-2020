<html>
<head>
<title>Finding Important Features using Genetic Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用遗传算法寻找重要特征</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-mini-project-4-finding-important-features-using-genetic-algorithms-for-heart-d069e205305f?source=collection_archive---------10-----------------------#2020-11-05">https://towardsdatascience.com/machine-learning-mini-project-4-finding-important-features-using-genetic-algorithms-for-heart-d069e205305f?source=collection_archive---------10-----------------------#2020-11-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="6547" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="http://towardsdatascience.com/tagged/mini-projects" rel="noopener" target="_blank">机器学习迷你项目</a></h2><div class=""/><div class=""><h2 id="7be6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">(用于心力衰竭存活预测)</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/28d53937aebbdd7ec8021d33570eebc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*g20uYkr27JTxsZZV"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@nci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">国立癌症研究所</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="8a6c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">原文如下:</p><blockquote class="me mf mg"><p id="90e0" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">机器学习可以仅从血清肌酐和射血分数预测心力衰竭患者的存活率。<em class="it"> BMC Med通知Decis Mak </em> <strong class="lk jd"> 20，</strong> 16 (2020)。<a class="ae lh" href="https://doi.org/10.1186/s12911-020-1023-5" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1186/s12911-020-1023-5</a></p></blockquote><p id="957f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个数据集有12个特征，你可以从<a class="ae lh" href="https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records" rel="noopener ugc nofollow" target="_blank"> UCI机器学习库</a>下载。它是一个二元分类、监督学习问题，以“死亡_事件”为目标变量，1表示死亡，0表示幸存。</p><p id="6696" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> <em class="mh">问题来了:寻找最佳学习者(算法)和最佳特征子集的最高效方法是什么？有时，令人惊讶的是，一小部分功能比全部功能表现得更好。找到那个集合的最好方法是什么？</em> </strong></p><p id="cfbe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，让我们把最好的学习者的问题放在一边。我们知道的一件事是，有些学习者比其他人训练得更快。如果您想测试用于特征选择的遗传学习算法，您会发现使用逻辑回归是最快的方法，而像Random Forest或LightGBM这样基于树的方法需要更长的时间，甚至可能无法正常工作，这取决于您使用的库。</p><h2 id="150b" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">纸质结果</h2><p id="f966" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">奇克和朱尔曼的发现是:</p><ul class=""><li id="1b3a" class="ni nj it lk b ll lm lo lp lr nk lv nl lz nm md nn no np nq bi translated">随机森林是最好的算法</li><li id="abb2" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">统计和机器学习方法都表明<strong class="lk jd">射血分数</strong>和<strong class="lk jd">血清肌酸酐</strong>是最重要的特征之一，你可以仅仅根据这些特征建立一个模型。</li></ul><h2 id="fb44" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">这个实验的结果</h2><ul class=""><li id="5245" class="ni nj it lk b ll nd lo ne lr nw lv nx lz ny md nn no np nq bi translated">遗传算法可以挑选各种特征子集</li><li id="fc26" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">由此得出的结果取决于您为算法选择的超参数，但这也需要您使用某种形式的交叉验证评分来仔细审查每个候选项。甚至您的交叉验证参数(折叠次数和重复次数)也会改变结果。</li><li id="ea5b" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated"><strong class="lk jd">血清肌酸酐</strong>和<strong class="lk jd">射血分数</strong>，正如他们所说，非常重要。该论文的第一个实验没有使用<strong class="lk jd">时间</strong>特征，这是随访后几个月的时间，因为它本身不是一个临床特征。然而，在他们论文的第二个实验中，他们确实包括了它。对于这个项目，我是<strong class="lk jd"> <em class="mh">排除</em> </strong>的时间特性。</li></ul><p id="ce04" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">安装库</strong></p><p id="7ab7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">大多数情况下，<strong class="lk jd"> sklearn-genetic </strong>用于遗传算法(GA)方法，如果你想使用一些autoML类型的方法，安装<strong class="lk jd"> pycaret </strong>。除此之外，我们只需要熊猫和熊猫。</p><h2 id="7dbf" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">什么是遗传算法？</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/7c4d792636d8934ed04f40ee6b79b275.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*algo5ZAof27-xf_p67RThQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自<a class="ae lh" href="https://commons.wikimedia.org/wiki/File:Evolutionary_Algorithm.svg" rel="noopener ugc nofollow" target="_blank">维基媒体</a></p></figure><p id="2ad6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">基本上，在我们的例子中，我们将一个特性的包含或排除视为一个二进制字符串，即一个由1和0组成的字符串，其中1表示该特性被包含，0表示它不被包含。这意味着，由于我们有12个特性，显然有2种可能性或整个特性集的子集需要考虑。遗传算法的要点不是测试所有这些，而是考虑几个子集——让我们称之为几个“个体”——然后评估它们的“适应度”值，这当然意味着一个数学函数。因此，让我们说，我们不是使用2个“个体”，而是使用大约20或50个个体，找到那些具有更大“适应度”值的个体，让它们“繁殖”，并产生具有其父母某些特征的后代，同时还允许随机突变——生物学101！当然，多少混合和变异是你可以控制的，这是随机的，但概率是你可以调整的算法的超参数。你还可以决定你想要多少代——显然，你的代数越多，你找到全局最优解的机会就越大，这是一个基因“最适合”的群体。你还需要考虑一些提前停止的标准，这样这个过程就不会陷入局部极小值或者比需要的时间更长。下图解释了一般过程:</p><p id="72f6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">交叉率</strong>决定了基因如何传递给后代——也就是说，后代在什么点上，以什么概率从父母那里获得基因。换句话说，它决定了父母和后代之间的“混合”程度或基因相似程度。显然，你不希望后代成为他们父母的副本——你可能也希望有一些突变的后代，只是为了在混合物中加入更多的遗传多样性，希望在某个时候，不屈不挠的适应性的完美突变出现，随之而来的是你无法超越的机器学习模型。所以你也有<strong class="lk jd">突变率</strong>作为超参数。</p><p id="33e6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你可以在这里阅读对遗传算法<a class="ae lh" href="http://Introduction to Genetic Algorithms — Including Example Code ...towardsdatascience.com › introduction-to-genetic-algor..." rel="noopener ugc nofollow" target="_blank">的更好的解释。让我们来看一个简单的方法来解决这个监督学习问题。</a></p><h2 id="45e6" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">逻辑回归+遗传算法</h2><p id="e624" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">这是遗传算法的代码，它将为我们选择一个特征子集:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="86d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">代码中需要注意的事项:</p><ul class=""><li id="8aa2" class="ni nj it lk b ll lm lo lp lr nk lv nl lz nm md nn no np nq bi translated">学习者的选择:这件事可能需要很长时间。为了节省时间，首先要做的是:<em class="mh">使用逻辑回归(LR) </em>，因为它总是训练速度最快的方法之一。论文的作者提到随机森林模型是好的，但是如果你在这个GA过程中使用RF，你会发现它比LR花费更多的时间。然而，基于树的模型可以考虑功能交互和其他可能影响功能选择的因素。因此，您可能希望在特性选择过程中包括RF，以确保不会遗漏任何东西。</li><li id="1b22" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated"><em class="mh">交叉验证方案</em>。开始的时候少尝试劈叉，意思是5折交叉，开始的时候不要做那么多重复。当然，你最好能重复100或1000次，但也许一开始做1次、5次或20次会让你充分意识到哪些特性是重要的。</li><li id="875d" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated"><em class="mh">人口</em>设定为50。你可以更高，比如100，200，500。变异率——变异率越高，你获得多样性的机会就越多，但这并不能保证你会得到最佳选择。这取决于需要多少代的变异和交叉来创造更多合适的候选者。</li><li id="3875" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">每个实验的分数来自selector.generation_score，它是每一代分数(Matthews相关系数)的列表，通常分数会在每一代中提高，所以我只使用最后一个分数作为模型的最终分数(selector.generation_score[-1])</li></ul><p id="8d0f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">长话短说——摆弄参数。这张表格显示了我的最终结果:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/7d18529c51afe521e71a9565abe3f26c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-VfbLWkj5o30oWSvI1yMvw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">GA算法发现4或5个特征子集工作良好。</p></figure><p id="ca70" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个算法的“赢家”:基数为5的特征子集，具有<strong class="lk jd">{年龄，肌酸酐_磷酸激酶，糖尿病，射血分数，血清肌酸酐} </strong>作为特征。我们可以预计MCC值约为0.40。现在让我们使用<strong class="lk jd"> <em class="mh"> pycaret </em> </strong>更彻底地测试一下，这是一个autoML类型的包，让一切都变得容易。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="def0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">比较模型</strong>函数向我们展示了这一点:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/bd8973238c59f402dee37fa0fcf2ae04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-4vaPU6xB_ev2Fedb3W3dw.png"/></div></div></figure><p id="7a02" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，你可以看到，正如论文作者所声称的那样，随机森林分类器是最好的。这是使用5折20次重复的方案。让我们看看当我们创建一个随机森林模型时会发生什么，但是有5个分裂和50个重复，即250个训练模型:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oe"><img src="../Images/001a3a1756830ccec69d77cc5c6e3815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1B0-EpszBe3uvILLoMshaA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">随机森林模型，5重CV和50次重复。</p></figure><p id="dd77" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以看到<strong class="lk jd"> <em class="mh">标准差为0.1305，相当高</em> </strong>。它表明，虽然RF比大多数更好，但在给定的train/val集合上，它可能并不总是表现得更好。</p><p id="c403" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在学习者对比表中可以看到，XGBoost和LightGBM似乎全线0。我不确定这是为什么，但我只是使用常规的sklearn和相同的cross-val方案进行了实验。<strong class="lk jd">在本次实验中，XGBoost得分为0.359，LGBM得分为0.378 </strong>，处于群体中间。</p><h2 id="5511" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated"><strong class="ak">基线—无特征选择</strong></h2><p id="ec9f" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">没有任何特性选择，pycaret向我们展示了这一点</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/c53b013d535fce0c333ca5abb58170dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*suoGUCp5KJnKCieQ-qbIcA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">这是针对所有特征的，没有特征选择。整体性能下降。还有，CatBoost和RF一样好。</p></figure><p id="905b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以看到，整体的MCC分数低于遗传特征选择时的分数。这也与论文中所声称的一致。</p><p id="505f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当您这样做，但是py caret“feature _ selection”参数设置为True(它执行自己的特征选择)时，我们会发现</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/3a7f8f0a5c12eaa4d84a9c987ac3acea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_qL3AlJuTCPHptrOKKKflA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">pycaret，但feature_selection = True。艾达绕过这个。</p></figure><p id="8b26" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这有点令人惊讶，因为不仅LDA是最好的模型，而且RF和其他GBM也不如它们通常的表现。</p><h2 id="af62" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">从模型中选择</h2><p id="af55" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">从模型中选择是sklearn内置的特征选择方法之一。我们用它作为与气体比较的手段。它选择的特征是:{ <strong class="lk jd">'年龄'，'肌酐_磷酸激酶'，'射血分数'，'血小板'，'血清肌酐'，'血清钠' } </strong>。然后，我们将这个特性集再次通过pycaret运行，下面是我们的发现:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/5a04de78a1264a417c901516d9255051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YQfSnVAlTx76u_Aqa7VPuQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用“从模型中选择”功能比较模型</p></figure><p id="9419" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以这个特征子集也不错，但是比来自遗传算法的更小的子集略胜一筹。有一点是清楚的:有特征选择倾向于提高分数。更多详情，请看我打开的<a class="ae lh" href="https://colab.research.google.com/drive/17NqqAoSm24N9a6nXLN2vzPxXkP8AlygM?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>。</p><p id="4bdd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，您可以看到，虽然在GA算法评分过程中，特征子集是按性能排序的，但这并不意味着当cross_val更改为100次重复时，它们会按该顺序评分。最高分来自第6个候选人，其选择的特征为<strong class="lk jd"> {“年龄”、“肌酐_磷酸激酶”、“射血分数”、“血清肌酐”、“吸烟”、“时间”} </strong>，得分为a <strong class="lk jd"> 0.868 <em class="mh">。</em> </strong></p><p id="fb32" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">也就是说，除了最后一个都在0.86以上。其实倒数第二个的分数是<strong class="lk jd"> 0.863 </strong>，只有特征<strong class="lk jd"> {“射血分数”、“血清肌酐”、“性别”、“时间”} </strong>。这意味着，如果您正在尝试或需要一个更简洁的模型，那么使用这个特性子集是合理的。这些模型中的任何一个即使不比具有所有特性的基线模型更好，也一样好，所以没有压倒性的理由将所有特性保留在模型中。</p><h2 id="ca41" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">逻辑回归+从模型中选择</h2><p id="531c" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">这是sklearn中的SelectFromModel:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="31fb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从这个过程来看，胜出者是<strong class="lk jd"> {“年龄”、“射血分数”、“血清_肌酐”、“时间”} </strong>，得分<strong class="lk jd"> 0.864。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/69ce9a4a684d2eb961bc63cff4acdea5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*54x9fItoD6nyAIDPWIfSBg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从各种功能组合的模型得分结果中进行选择。</p></figure><h2 id="26cc" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">逻辑回归+顺序浮动特征选择(SFSS)</h2><p id="b5eb" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">这种方法有点贵，涉及一种测试各种功能组合的算法，尽管与GA不同，它不涉及任何交叉或变异过程，它基本上是，找到一个好的功能，再添加一个，看看是否有帮助，如果有帮助，就保留它并添加另一个，当添加更多功能似乎没有帮助时停止。这种算法的“浮动”版本允许您去掉它们没有帮助的功能，这允许您通过替换可能看起来不错但后来发现不“玩得好”的功能来测试更多的组合，添加更新的功能。这有点像在团队运动中进行替换或交易——有时你必须移除一名优秀的球员，因为没有这名球员可能会有更好的组合。</p><p id="46a7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你可以从sklearn 的一个<a class="ae lh" href="https://scikit-learn.org/dev/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html" rel="noopener ugc nofollow" target="_blank">实验版本中得到SFSS，但是我刚刚从</a><a class="ae lh" href="http://rasbt.github.io/mlxtend/" rel="noopener ugc nofollow" target="_blank"> mlxtend </a>中得到它，这对我来说更容易。这里有一个链接，链接到我的<a class="ae lh" href="https://colab.research.google.com/drive/17NqqAoSm24N9a6nXLN2vzPxXkP8AlygM#scrollTo=gH6CKF5A5HU8&amp;line=3&amp;uniqifier=1" rel="noopener ugc nofollow" target="_blank"> Colab笔记本中有我的代码</a>的单元格。</p></div></div>    
</body>
</html>