<html>
<head>
<title>Three level sentiment classification using SVM with an imbalanced Twitter dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于不平衡Twitter数据集的SVM三级情感分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-three-level-sentiment-classification-task-using-svm-with-an-imbalanced-twitter-dataset-ab88dcd1fb13?source=collection_archive---------33-----------------------#2020-09-21">https://towardsdatascience.com/a-three-level-sentiment-classification-task-using-svm-with-an-imbalanced-twitter-dataset-ab88dcd1fb13?source=collection_archive---------33-----------------------#2020-09-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b17b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从现场反应推文到2016年第一次电视直播的共和党辩论，中国人正在学习情绪分类</h2></div><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi kn"><img src="../Images/4f5697ffc5481fa2c28d9911a3e7013a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KJ1OHcQS9idCWlBG"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">由<a class="ae ld" href="https://unsplash.com/@historyhd?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">在<a class="ae ld" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上高清拍摄的历史</a></p></figure><p id="b12d" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">作为一名新闻迷，我喜欢看到政治如何在社交媒体上获得如此情绪化的回应，并想知道这种轶事般的激情感是否可以转化为机器学习分类。我发现了一个针对2016年第一次共和党总统辩论的推文数据集(<a class="ae ld" href="https://data.world/crowdflower/first-gop-debate" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ir"> h </strong> </a> <strong class="lg ir"> ere </strong>)，并希望创建一个三级情感分类器，可以从推文文本中解释情感。这篇文章是我整理的一套方法和技术的一部分，现在我将只关注一个方面；不起眼的支持向量机。作为次要任务，我注意到数据集严重不平衡，所以想尝试对少数类进行增采样，以提高分类器在所有标签中的有用性(这有望帮助分类器在所有类别中得到改进)。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="0543" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">数据探索和清理</h1><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/97b5acb4f583791876bfb9f4d3b823c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*FZ6OjyJfPGisT3_ac5uxIg.jpeg"/></div><p class="kz la gj gh gi lb lc bd b be z dk translated">谁能想到Twitter如此负面？作者图片</p></figure><p id="3ecf" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">从数据集细分的原始数据中，我们立即看到了推文传播的问题。负面推文很普遍，是中性和正面推文总和的两倍多。这可能会对分类器在实践中的表现产生影响。(最有可能的是，如果像这样训练，分类器会很好地理解负面推文，但不会有太多识别其他任何东西的练习！)</p><p id="efc6" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">“清理”数据的第一步是将所有字母转换成小写，然后从推文中删除标点符号、数字、网址和用户名。</p><p id="4cc2" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">使用“NLTK”停用词语料库从推文中删除停用词，并从推文中提取空白，每个词都被标记化，以便表示被视为停用词的单独数据块。</p><p id="4c8f" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">重复的推文随后被删除。在其他预处理步骤之后，我们决定删除重复的内容，因为Twitter的本质是由“转发”组成的，回复其他用户或评论的用户名可能会有完全相同的内容。这剩下总共9836条独特的推文准备分类。阴性:5692，中性:2521，阳性:1623。数据集被分成80%用于训练，20%用于测试</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="a89b" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">矢量化— TF/IDF</h1><p id="b598" class="pw-post-body-paragraph le lf iq lg b lh na jr lj lk nb ju lm ln nc lp lq lr nd lt lu lv ne lx ly lz ij bi translated">出于对文本进行大多数数学建模的目的，以及出于该实验的目的，实施了不同的“矢量化”过程。</p><p id="94af" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">文本内容在没有被转换成数字以供机器学习算法读取的情况下，不能单独被改变和强制到数学空间中。</p><p id="775f" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这就是为什么在本项目中，出于监督方法的目的，使用不同类型的矢量化将定性数据转换为定量数据，以便进行数学处理。这些向量成为模型的嵌入特征。</p><p id="26b0" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">术语频率/逆文档频率(TF/IDF) </strong></p><p id="c79f" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这是用于支持向量机模型的矢量化技术。TF/IDF在训练数据上使用了一种单字方法，该方法将每个单词作为一个术语。“术语频率”是指某个单词在文本中出现的频率，“逆文档频率”是指降低在所有文本中出现频率最高的单词的重要性。</p><p id="3a0f" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这用于产生在给定文档中频繁出现但不一定在所有文档中出现的单词。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="8c4b" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">数据平衡和采样技术</h1><p id="1f6f" class="pw-post-body-paragraph le lf iq lg b lh na jr lj lk nb ju lm ln nc lp lq lr nd lt lu lv ne lx ly lz ij bi translated">随机过采样、合成少数过采样和真实世界不平衡方法形式的数据平衡都被利用和比较。</p><p id="752b" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">采样技术</strong></p><p id="9d90" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">考虑数据平衡问题和协议是至关重要的，因为每一项行动都应减少偏差和提高真实性能，但也要尝试和减少过度拟合，并对模型的潜力有更细致的表示。考虑上采样技术很重要，因为它可以使模型更容易地勾勒出其决策边界。决定不使用欠采样技术，因为在这种情况下，由于数据集最初非常小，并且由于预处理措施和训练分割而进一步减少，所以感觉这对于提高性能没有什么作用。</p><p id="abed" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">没有采样</strong></p><p id="91a2" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">班级可能会不平衡，因为模型正在接受训练，以准确了解推文在现实生活中的表现。如果认为模型在之前没有进行上采样的情况下可能表现不佳，那就太天真了。如果给定领域中的数据天生严重不平衡，那么对不平衡数据的训练可以产生最佳输出。</p><p id="11c2" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">随机过采样</strong></p><p id="f6b2" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">随机过采样是从两个少数类中提取重复样本并将其添加到训练集中的过程。样本是从训练集中的少数类中随机选择的，然后被复制并添加到训练集中，在那里它们有可能被再次选择。</p><p id="ac5b" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因为重复是精确的，并且重复的例子有可能出现多次，所以存在用这种方法过度拟合少数类的风险，并且对于实现这种技术的模型来说，数据的一般化增加了。</p><p id="c260" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了这个实验的目的，少数类都被上采样到与多数负类相同的值，因此在应用上采样之后，每个类有5，692个样本。</p><p id="b5ee" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">合成少数过采样技术SMOTE </strong></p><p id="d03e" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">研究人员；舒拉、鲍耶、霍尔和凯格尔迈尔在他们的论文中创建了这种上采样技术，该论文以题为“SMOTE:合成少数过采样技术”的技术命名(<a class="ae ld" href="https://arxiv.org/pdf/1106.1813.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ir">看这里！</strong></a><strong class="lg ir"/></p><p id="f58c" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">SMOTE是另一种有用的上采样方法。与从少数类创建数据点的精确副本的随机过采样相反，SMOTE使用一种类型的数据扩充来“合成”全新且独特的示例。通过在特征空间中选择彼此接近的实例，并在这些实例之间创建边界，以及在沿着该边界的某个点创建新样本，来实现SMOTE。这种方法往往是有效的，因为新的合成推文更接近特征空间中的其他示例，因此它们的极性可能比随机上采样的示例更接近，并且因为它们与随机过采样中的示例不完全相同，所以过拟合的可能性降低了。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="52c5" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">估价</h1><p id="d28b" class="pw-post-body-paragraph le lf iq lg b lh na jr lj lk nb ju lm ln nc lp lq lr nd lt lu lv ne lx ly lz ij bi translated">实验评估指标各不相同，通常取决于所执行任务的性质。一些常用于分析程序分析的评估指标包括但不限于:准确度、精确度、召回率、均方误差、损失函数分析、曲线下面积、F1分数。不同领域中的不同模型将导致每个指标的不同结果，必须确定合适的模型，并且必须满足必要的评估标准。</p><p id="b8fe" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">精度</strong></p><p id="c1a3" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">准确性是分类任务中最常测量的评估度量之一，并且最常被定义为正确分类的标签的数量与总预测数量的比例。</p><p id="70ae" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">F1-得分</strong></p><p id="e023" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">“F1分数”、“F分数”或“F度量”是用于评估基于自然语言的任务的常见度量。它通常被认为是“精确度和召回率的调和平均值”，或者传达了精确度和召回率之间的平衡。</p><p id="3ff8" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">F-Measure表达了精确度和召回率之间的平衡。由于准确性仅给出了模型正确结果的百分比，但并未显示出模型在寻找真正的正面结果方面的熟练程度，因此根据需要，这两种方法都有优点。</p><p id="40dd" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">接收机工作特性(ROC) </strong></p><p id="c9e5" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">ROC是显示分类模型在其真阳性率(TPR)和假阳性率(FPR)方面的性能的图表。TPR定义为模型输出的真阳性总数除以真阳性数加上假阴性总数。</p><p id="90f3" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">曲线下面积(AUC) </strong></p><p id="7070" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">AUC统计是ROC曲线下的维度空间的度量。该图给出了所有潜在分类阈值的模型性能的综合得分。<br/>对此的一种解释是，该模型将一个正的随机例子置于比一个随机负的例子更高的位置。AUC总是介于0和1之间的数字。</p><p id="3bc5" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">ROC度量是有用的，因为它对数据中的先验类别概率或类别流行度以及AUC具有不变性。这对于这项研究很重要，因为这些阶层是严重不平等的。负面类别的大量存在表明模型随机正确分类正面推文的概率增加了。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="d04c" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">结果</h1><p id="0c5f" class="pw-post-body-paragraph le lf iq lg b lh na jr lj lk nb ju lm ln nc lp lq lr nd lt lu lv ne lx ly lz ij bi translated">以下是从支持向量机获得的结果，该支持向量机利用各种过采样技术对少数类训练有词频率/逆文档频率向量。</p><p id="b129" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下图显示了根据不平衡训练数据训练的支持向量机模型的结果。此处模型的总体准确率为60%，但从这种方法的精确度、召回率和f1分数来看，我们可以看到该模型在对较小的类别进行分类时表现不佳。该模型理解负类，但未能从较小的类学到很多，这从中性类和正类相当低的18%和19%的“f1”中可以清楚地看出。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi nf"><img src="../Images/a5dd31a9fbd1330a82404ff2b08cc695.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pfIKir228igq6jyyjlelMQ.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="ebc5" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">从下面显示的ROC曲线和AUC中，我们看到了模型性能的更全面的观点。除了中性组的AUC比其他组低1%之外，所有三组的真实阳性率几乎相同。即使该模型具有60%真阳性率的总体准确度，该模型的总体分类能力也不是特别明显。</p><p id="2908" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">从所示的混淆矩阵中，我们看到了SVM模型的实际预测值。该模型清楚地显示了其在对负面类别进行分类时的最佳性能。</p><p id="50de" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这个班有1086个正确的预测。然而，我们只看到37个负类的正确预测，比这里正确预测的10%略少。中性类有55个正确的预测，比这里的负类略有改进。有趣的是，这个模型错误地将一条推文标记为负面的情况比其他任何类别都多。显示了该模型如何严重依赖于负面类别来影响其决策。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi ng"><img src="../Images/af2990d5221f360789105f27d138b5ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mDsQzyr09oeOvwH9FqZ5nA.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/f2ceaabf95583b4a7de6522a08576dcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*KkkzITK-ngM--WDLkEVRUQ.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="1ba6" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">支持向量机TF/IDF随机过采样类</strong></p><p id="c682" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下面显示的分类报告显示了应用随机过采样技术对少数类进行上采样时SVM TF/IDF模型的结果。值得注意的是，这种方法的总体准确性与具有不平衡类别的相同方法没有不同，但是模型在正确分类较小类别方面的性能确实略有提高，如负面类别上改进的f1分数所示。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi ni"><img src="../Images/280c34088c1d0114860f0bc2b552002d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VAR42R7wQcBrMmTowiAppg.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="081f" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下图显示了采用随机过采样的SVM模型的ROC曲线和AUC图。该模型在所有类别中的真实阳性率在所有类别中至少提高了4%。该模型不仅通过增加少数民族类别的样本来改进其对否定类别的分类，而且该模型在所有类别中都有相当大的改进。该模型仍然最擅长发现负类，但是当呈现更多样化的训练示例时，它也没有丢失任何这种知识。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi nj"><img src="../Images/d27afc4f72e17fcef4defa1d2048e6f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xxHmufgOvT6C43gDw_Rgvg.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="481c" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下图显示了SVM ROS模型的混淆矩阵。值得注意的是，当与不平衡数据集相比时，分类器在正确分类负面类别方面稍差(分别为1086对977)，但其正确分类正面类别的能力几乎加倍(37对70)。中性类的正确预测数量显著增加(从55到140)。还需要指出的是，错误分类的负面例子的总数显著减少。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/42222e9cf1fa644c01d9e1a8d3fdee7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*t_N2JszzmbmdprD9eTzuJQ.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="3ecc" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ir">支持向量机TF/IDF SMOTE </strong></p><p id="0bb8" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下图显示了应用SMOTE上采样技术的SVM-TF/IDF的分类报告。该模型的总体准确性保持在60%的静态水平，但是，与不平衡方法而不是随机向上采样方法相比，我们确实看到两个少数类的f1得分有所提高。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi nl"><img src="../Images/ee2618105c0f63c9bb05a30c6ed6c435.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8HEbLkE-V-3709U8AlPmSg.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="6f92" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下图显示了SMOTE SVM的ROC曲线和AUC数。通过比较下面的两个图表和指标可以清楚地看出，与ROS方法相比，真正的正数明显下降。当与不平衡方法相比时，这种方法仅略微有所改进。当与没有上采样相比时，负类的分类具有2%的改进，并且通常该模型对任何类的分类能力降低1%到2%。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi nm"><img src="../Images/ac8b8b9e8a2760fcd4d7cb9e7d81a5b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xe8yJquotwc4k_L8nCvIZQ.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="46b2" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最后，下图显示了带SMOTE的SVM的混淆矩阵。负面类别仍然是分类器正确识别的标签，但有趣的是，当使用这种技术时，中性类别的正确预测与ROS相比下降了几乎一半(72对140)。与ROS相比，这里的分类器使用这种技术也将推文错误分类为负面的。在这种情况下，分类器严重依赖于否定类标签，而不是使它做出的预测范围多样化。同样值得注意的是，这个模型不仅比ROS模型对阳性类别的错误分类更多，而且对这个标签的总预测也少得多。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/81ee788507de53b9afb15c2e90a9db6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*UvDkAWK33I_91mWoiy2NeA.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="81a8" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">评估和结论</h1><p id="d576" class="pw-post-body-paragraph le lf iq lg b lh na jr lj lk nb ju lm ln nc lp lq lr nd lt lu lv ne lx ly lz ij bi translated">当在不平衡的训练数据上训练时，支持向量机发现很难做出正确的分类。不使用参数调整技术和简单的线性方法也可能导致问题。</p><p id="a04e" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">SVM对不平衡的数据很敏感，对自然平衡的类工作得最好。这可能导致性能下降。这也解释了为什么不平衡的实验产生了不太有用的结果。</p><p id="9425" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">就一般意义上的总体精度而言，所有三种上采样技术给出了相同的精度度量，但是直观上清楚的是，最好的性能始终是标记负类。</p><p id="e62a" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">参考分类器的“F1-Measure ”,随机上采样模型给出了最好的结果。但是，必须记住，随机过采样数据会精确地重新创建实例，这有可能导致过度拟合。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><p id="14bd" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在GitHub repo <a class="ae ld" href="https://github.com/apcoyne/SVM-GOP-TWEETS" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ir">这里</strong> </a>上可以找到Jupyter笔记本以及伴随该报告的所有python代码！:)</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><p id="cfe6" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">爱尔兰都柏林自由数据科学家艾伦·科因撰写的报告和代码</p></div></div>    
</body>
</html>