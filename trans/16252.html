<html>
<head>
<title>Learn NLP the Stanford way — Lesson 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">以斯坦福的方式学习NLP第1课</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learn-nlp-the-stanford-way-lesson-1-3f1844265760?source=collection_archive---------28-----------------------#2020-11-09">https://towardsdatascience.com/learn-nlp-the-stanford-way-lesson-1-3f1844265760?source=collection_archive---------28-----------------------#2020-11-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="183e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">给你的邀请，介绍自然语言处理和词向量</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8af74115bc6400cf3cff8788d5632631.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rRjYOSQ8ZJ_hdx4upQ4KIg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com/s/photos/academic?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@inakihxz?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">伊尼基·德尔·奥尔莫</a>拍摄的照片</p></figure><p id="56d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自然语言处理(NLP)的人工智能领域，通过其庞大的语言模型——是的，GPT 3号，我在看着你——展示了它被视为机器执行最独特语言任务能力的一场革命。</p><p id="2bc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于这一点，公众对整体的看法是分裂的:一些人认为这些新的语言模型将为天网类型的技术铺平道路，而另一些人则认为它们是炒作推动的技术，将在很短时间内或根本不会存在于尘土飞扬的架子或硬盘驱动器中。</p><h1 id="97cd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">邀请</h1><p id="80a8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">受此激励，我创作了这一系列故事，以一种友好的方式从头开始接近NLP。</p><h2 id="7a35" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">我也邀请你和我一起参加这个系列来学习NLP，并且精通人工智能语言模型塑造的未来。</h2><p id="5f8b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">要加入我，你需要有一点Python和Jupyter笔记本的经验，在大多数情况下，我甚至不会要求你在你的机器上安装任何东西。</p><p id="e054" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">这个系列将在统计学和微积分的深度上与斯坦福课程有显著的不同。</strong>我将尽力避免涉及细节，因为在大多数情况下，我们将使用已经实现了我们将需要的大部分结构的Python库。但是，如果你想了解更多关于这些主题的知识，我强烈建议你学习课程笔记。</p><p id="7bfa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用<a class="ae ky" href="https://deepnote.com" rel="noopener ugc nofollow" target="_blank"> Deepnote </a>创建我们的Python笔记本，并使用云开发整个课程。</p><p id="8beb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">为什么选择Deepnote？Deepnote通过实时协作扩展了Jupyter笔记本的体验，并提供无预装的免费计算。你可以在这里复制我的Deepnote笔记本<a class="ae ky" href="https://deepnote.com/publish/a0986055-32dd-4f1e-b536-e62a47a91318" rel="noopener ugc nofollow" target="_blank">，并跟随我完成这个项目以获得最佳体验。</a></strong></p><p id="1187" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这门课程，我们将使用斯坦福大学2020年冬季CS224N材料的指南，因为它有一个全面的方法，一个包含课程的<a class="ae ky" href="https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z" rel="noopener ugc nofollow" target="_blank"> Youtube播放列表</a>，以及斯坦福大学学生提供的其他资源。如果你想了解更多的课程，你可以访问它的<a class="ae ky" href="https://web.stanford.edu/class/cs224n/" rel="noopener ugc nofollow" target="_blank">网站</a>。</p><p id="391f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将首先从自然语言处理的基础开始，然后学习它的关键方法:RNN、注意力、变形金刚等等。本课程结束时，我们将能够创建以下一些应用程序:</p><ul class=""><li id="a26d" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu nj nk nl nm bi translated">字义</li><li id="bffa" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">依存句法分析</li><li id="76f2" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">机器翻译</li><li id="21dd" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">问题回答</li></ul><h1 id="9ce7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">自然语言处理简介</h1><blockquote class="ns nt nu"><p id="4eb7" class="kz la nv lb b lc ld ju le lf lg jx lh nw lj lk ll nx ln lo lp ny lr ls lt lu im bi translated"><strong class="lb iu">“自然语言处理</strong> ( <strong class="lb iu"> NLP </strong>)是<a class="ae ky" href="https://en.wikipedia.org/wiki/Linguistics" rel="noopener ugc nofollow" target="_blank">语言学</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Computer_science" rel="noopener ugc nofollow" target="_blank">计算机科学</a>和<a class="ae ky" href="https://en.wikipedia.org/wiki/Artificial_intelligence" rel="noopener ugc nofollow" target="_blank">人工智能</a>的一个分支，涉及计算机和人类语言之间的交互，特别是如何给计算机编程，以处理和分析大量的<a class="ae ky" href="https://en.wikipedia.org/wiki/Natural_language" rel="noopener ugc nofollow" target="_blank">自然语言</a>数据。”—维基百科</p></blockquote><p id="44f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据这个定义，除了看到NLP是一个广阔的多学科领域，它还将我们引向一个问题:<strong class="lb iu">我们如何让计算机程序分析自然语言数据？</strong></p><p id="1c6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一步是学习我们如何在计算环境中表示单词及其含义。</p><h2 id="647d" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">词语的含义</h2><p id="b48c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">几年来，NLP的工作主要是基于对单词同义词和上位词的建模。找出这些集合的一个方法是查看字典中的单词定义。</p><p id="6e93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过使用Python和一个名为<a class="ae ky" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>的库来做到这一点。</p><h2 id="fb5d" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">试用NLTK</h2><blockquote class="ns nt nu"><p id="0c7e" class="kz la nv lb b lc ld ju le lf lg jx lh nw lj lk ll nx ln lo lp ny lr ls lt lu im bi translated">“NLTK是构建Python程序来处理人类语言数据的领先平台。它为超过50个语料库和词汇资源如WordNet提供了易于使用的接口，以及一套用于分类、标记化、词干化、标记、解析和语义推理的文本处理库，工业级自然语言处理库的包装器，以及一个活跃的论坛—Nltk.org</p></blockquote><p id="a1a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了NLTK，我们可以使用一个名为WordNet的内置词汇数据库来搜索一个单词的意思。WordNet将名词、动词、形容词和副词分组为认知同义词集— <em class="nv">同义词集— </em>，每个同义词集<em class="nv">代表一个不同的概念。</em></p><p id="7e95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们在Deepnote上登录创建一个“新项目”。打开笔记本，让我们通过在单元格中键入并使用Shift+Enter运行来安装NLTK库——对于那些使用不同Python笔记本平台的人来说，您知道的快捷方式应该可以正常工作。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/d22505c5bb4885610a9a4b3af75d034b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LXQJ_QQksg5Hn11PpUudCQ.png"/></div></div></figure><p id="3c11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们需要导入NLTK库并下载WordNet数据库。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/9f37335d328aef340dc3e9c94979a964.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ifNDb01erxawZuWKjP78IQ.png"/></div></div></figure><p id="127f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了这个，我们就都准备好了。为了从像<em class="nv"> 'language，</em>这样的单词中获取<em class="nv"> synsets </em>对象，我们必须导入WordNet数据库并使用方法。<code class="fe ob oc od oe b"><em class="nv">synsets()</em></code> <em class="nv">。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/be7048ae43407bd8bba744debf25ddef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lOOQPnW9bxk0bd6RFXUBQQ.png"/></div></div></figure><p id="066d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看起来结果对象并没有给我们所有需要的关于这个单词的信息，只是一些关于每个<code class="fe ob oc od oe b"><em class="nv">synset</em></code> <em class="nv">的类似加密的信息。</em>为了更好地查看<em class="nv"> </em>，我们可以循环查看结果，并使用<code class="fe ob oc od oe b"><em class="nv">pos() </em></code> <em class="nv">和</em> <code class="fe ob oc od oe b"><em class="nv">lemmas()</em></code> <em class="nv"> </em>格式化<em class="nv"> synset </em>对象，借助一个自定义的对象列表来“漂亮地打印”单词表示。</p><blockquote class="ns nt nu"><p id="e38f" class="kz la nv lb b lc ld ju le lf lg jx lh nw lj lk ll nx ln lo lp ny lr ls lt lu im bi translated">关于NLTK中WordNet包的更多信息，您可以查看这个<a class="ae ky" href="https://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html" rel="noopener ugc nofollow" target="_blank">链接</a></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/05fe80694afc80f8198bc83f491a1d4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*--2JZsbZippD9hAg9cET8Q.png"/></div></div></figure><h2 id="30d0" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">NLTK陷阱</h2><p id="c1b5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">您可以看到它作为字典工作正常，但是在开发NLP应用程序时有一些问题。</p><p id="cf70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这很主观。它需要大量的人力，所以实际上不可能维持语料库。它也不会有效地计算单词相似度，而这对于我们的应用程序来说是非常重要的。那会导致我们编写不可靠或容易过时的人工智能软件。</p><h2 id="d49d" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">离散表示</h2><p id="e3a1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">另一种方法是使用离散向量(包含0和1的向量)来表示不同的单词，但是这种方法也有一些缺陷。例如，它主要依赖WordNet的同义词列表，这会给我们带来一些问题。</p><p id="07b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于这个原因，该领域转向另一种方法，即使用单词向量来表示单词。</p><h1 id="b8a3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">根据上下文来表示单词</h1><blockquote class="ns nt nu"><p id="6b68" class="kz la nv lb b lc ld ju le lf lg jx lh nw lj lk ll nx ln lo lp ny lr ls lt lu im bi translated">从一个人交的朋友身上，你就可以知道这个人是什么样的人。</p></blockquote><p id="1d11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单词向量的概念使我们能够处理单词和中心单词的上下文(附近的单词)。这使我们能够研究不同语境中单词之间的相似性。</p><h2 id="2a3f" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">单词向量(也称为嵌入或表示)</h2><p id="e076" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">单词向量由包含非零值的n维向量表示，通过单词与其他单词的关系来表示单词。为每个单词构建一个密集向量，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/9333a2a02f97aaba45c64d60a5eb0a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*lrd6hrEm3jjy5BZYZiOLIA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由100维单词向量表示的单词“medium”</p></figure><p id="7ebd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想扩展你在单词向量方面的知识，我推荐这本由艾莉森·帕里什写的<a class="ae ky" href="https://gist.github.com/aparrish/2f562e3737544cf29aaf1af30362f469" rel="noopener ugc nofollow" target="_blank">超棒的笔记本</a>。</p><p id="4633" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以用不同的方法创建单词向量。在斯坦福的CS224N课程中，呈现了word 2 vec(miko lov et al . 2013)<a class="ae ky" href="https://arxiv.org/abs/1301.3781" rel="noopener ugc nofollow" target="_blank">【1】</a><a class="ae ky" href="https://arxiv.org/abs/1310.4546" rel="noopener ugc nofollow" target="_blank">【2】</a><em class="nv">框架</em>:</p><h2 id="9728" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">Word2Vec概述:</h2><ul class=""><li id="2f8c" class="ne nf it lb b lc mn lf mo li oi lm oj lq ok lu nj nk nl nm bi translated">收集大量的文本</li><li id="ccd7" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">用n维向量表示固定词汇表中的每个单词</li><li id="4838" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">对于文本中的每个位置，定义一个中心词和上下文词。</li><li id="9c4a" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">使用向量的相似度来计算给定中心词的上下文的概率。</li><li id="3bca" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">重复单词向量以最大化这个概率</li></ul><p id="e917" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个过程主要是通过使用神经网络学习单词之间的关联来实现的。我们不会实现Word2Vec框架来训练一个模型；相反，我们将使用Python库<a class="ae ky" href="https://radimrehurek.com/gensim/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="nv"> gensim </em> </a>中的Word2Vec模型。</p><blockquote class="ns nt nu"><p id="1fa0" class="kz la nv lb b lc ld ju le lf lg jx lh nw lj lk ll nx ln lo lp ny lr ls lt lu im bi translated">“Gensim是一个Python库，用于大型语料库的<em class="it">主题建模</em>、<em class="it">文档索引</em>和<em class="it">相似性检索</em>。目标受众是T21的自然语言处理(NLP)和信息检索(IR)社区— <a class="ae ky" href="https://radimrehurek.com/gensim/index.html" rel="noopener ugc nofollow" target="_blank"> Gensim网站</a></p></blockquote><h1 id="cdc0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">探索单词向量与gensim库的关系</h1><p id="4280" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这个例子将使用<em class="nv"> gensim的</em>嵌入式<code class="fe ob oc od oe b">api</code>和<code class="fe ob oc od oe b">Word2Vec</code>模块下载一个文本语料库，并创建一个Word2Vec模型来可视化一些有趣的单词向量特征。首先，我们需要安装<em class="nv"> gensim </em>包。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/6a577f43a10875eb5ae035596debac65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D_eduklrhcQrnRP-NCP-lw.png"/></div></div></figure><p id="2199" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">现在我们需要获得用于创建Word2Vec模型的语料库。为此，我们可以使用<code class="fe ob oc od oe b">api</code>模块。我们将下载从维基百科中提取的文本创建的text8语料库。之后，我们需要使用语料库来创建我们的Word2Vec模型，我们通过导入Word2Vec模型并实例化它，将语料库作为构造函数参数传递来完成。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/c1a34bb7921dd7e745a31b200e232ec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_tUvvnkyZ5SUgs0iR3tVew.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">这可能需要一些时间:)</p></figure><p id="370d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">我们已经可以通过执行诸如查找相似单词和选择不属于一个组的单词这样的任务来处理单词向量。</strong>你可以阅读<a class="ae ky" href="https://radimrehurek.com/gensim/auto_examples/index.html" rel="noopener ugc nofollow" target="_blank"> gensim的文档</a>了解更多关于可用的词向量运算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/51febf4bcdada7a10c7c2e91abc3e582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3QDb_86iG0MZ6QQ5MiG74Q.png"/></div></div></figure><p id="8b73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还记得NLTK最大的缺陷可能是无法计算两个单词之间的相似度吗？通过使用单词向量，我们可以使用这个特性来执行更复杂的任务。例如，我们可以找到几组单词之间的相似之处。</p><p id="cea2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以用单词和模型表达式进行数学运算，比如:<strong class="lb iu">“国王—男人+女人=？”</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/87e145afbe0ce134362bf2ea0145784a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TkRUyWjifRw21zDtpXeFaQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摘自<a class="ae ky" href="https://youtu.be/8rXD5-xhemo" rel="noopener ugc nofollow" target="_blank">第一讲</a>的视频</p></figure><p id="a71e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使用<em class="nv"> gensim、</em>对表达式求值，我们可以使用<code class="fe ob oc od oe b">most_similar()</code>方法，将正值<code class="fe ob oc od oe b">‘woman’ </code>和<code class="fe ob oc od oe b">‘king’</code>以及负值<code class="fe ob oc od oe b">‘man’</code>作为参数传递。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/4024b8412b4ff90b09211ea98c26d8d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1_QOUGjHheTjePUO_Pb2Aw.png"/></div></div></figure><p id="714a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以创建一个<code class="fe ob oc od oe b">analogy</code>函数来简化这个操作:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/def3553cca8b2fbb25816ca642ac7b04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TII8DvzZSSEmjmD7etTvyQ.png"/></div></div></figure><p id="4c31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单词向量为现代分布式单词表示奠定了基础，从而为NLP的发展铺平了道路。</p><h2 id="f9be" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">对于第2课，您可以访问以下链接:</h2><div class="os ot gp gr ou ov"><a href="https://thiago-gcandido.medium.com/learn-nlp-the-stanford-way-lesson-2-7447f2c12b36" rel="noopener follow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd iu gy z fp pa fr fs pb fu fw is bi translated">以斯坦福的方式学习NLP第2课</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">深入了解单词2vec、手套和词义</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">thiago-gcandido.medium.com</p></div></div><div class="pe l"><div class="pf l pg ph pi pe pj ks ov"/></div></div></a></div><h1 id="d42b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="7657" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在下一篇文章中，我们将讨论单词向量和词义，这是斯坦福课程第二讲的主题。我希望你喜欢阅读这篇文章。</p><p id="a50b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nv">如果你有，考虑在</em> <a class="ae ky" href="https://twitter.com/ogaihtcandido" rel="noopener ugc nofollow" target="_blank"> <em class="nv">推特</em> </a> <em class="nv">上关注我。</em></p><p id="de26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谢谢你的时间。保重，继续编码！</p><h2 id="9a88" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">参考</h2><ul class=""><li id="d995" class="ne nf it lb b lc mn lf mo li oi lm oj lq ok lu nj nk nl nm bi translated"><a class="ae ky" href="https://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture01-wordvecs1.pd" rel="noopener ugc nofollow" target="_blank"> CS 224N第一讲幻灯片</a></li><li id="6dc5" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated"><a class="ae ky" href="https://youtu.be/8rXD5-xhemo" rel="noopener ugc nofollow" target="_blank"> CS 224N第一讲视频</a></li><li id="86f0" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">[1] — <a class="ae ky" href="https://arxiv.org/abs/1301.3781" rel="noopener ugc nofollow" target="_blank">向量空间中单词表示的有效估计</a></li><li id="6cc6" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">[2] — <a class="ae ky" href="https://arxiv.org/abs/1310.4546" rel="noopener ugc nofollow" target="_blank">单词和短语的分布式表示及其组合性</a></li></ul><h2 id="f87a" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">软件和库</h2><ul class=""><li id="6ee2" class="ne nf it lb b lc mn lf mo li oi lm oj lq ok lu nj nk nl nm bi translated"><a class="ae ky" href="https://deepnote.com/" rel="noopener ugc nofollow" target="_blank">深度笔记</a></li><li id="3f2b" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated"><a class="ae ky" href="https://radimrehurek.com/gensim/" rel="noopener ugc nofollow" target="_blank"> Gensim </a></li><li id="7348" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated"><a class="ae ky" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a></li></ul></div></div>    
</body>
</html>