<html>
<head>
<title>How to Build Audience Clusters With Website Data Using BigQuery ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用BigQuery ML利用网站数据构建受众群</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-audience-clusters-with-website-data-using-bigquery-ml-6b604c6a084c?source=collection_archive---------15-----------------------#2020-11-04">https://towardsdatascience.com/how-to-build-audience-clusters-with-website-data-using-bigquery-ml-6b604c6a084c?source=collection_archive---------15-----------------------#2020-11-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e963" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="fae7" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">收集受众见解和建立客户细分的技术指南</h2></div><p id="fe85" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一个常见的营销分析挑战是理解消费者行为并开发客户属性或原型。随着组织更好地解决这个问题，他们可以激活营销策略，将更多的客户知识融入到他们的活动中。使用一种叫做聚类的技术，使用BigQuery ML构建客户档案比以往任何时候都容易。在这篇文章中，你将学习如何创建细分市场，以及如何利用这些受众进行营销活动。</p><h1 id="0554" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">为什么聚类算法如此重要？</h1><p id="d7c4" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">聚类算法可以将相似的用户行为分组在一起，以建立用于营销的细分。随着我们进入个性化时代，聚类算法可以帮助公司通过基于网站行为的广告向现有客户或潜在客户发送专门的信息。</p><h1 id="5cc5" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">聚类算法是如何工作的？</h1><p id="908e" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">在本教程中，我将提供对聚类算法的简单理解，然而，大部分内容将涵盖过程和实现，而不是幕后发生的事情。一般来说，聚类属于无监督机器学习的范畴。我们正在运行一个算法，具体来说，在这个过程中，我们将使用k-means，在不给算法一个目标变量来训练的情况下，找出数据如何逻辑地分组在一起。例如，假设我们想根据年龄和估计收入这两个特征对您的受众进行分类。聚类是自动为您完成这一任务的过程。我们面临的唯一输入是我们的数据中存在多少个聚类。在下面的例子中，三个集群“感觉”正确。这个例子可能看起来很简单，但是您可以看到这个问题是如何变得无法手工处理更多的特性的。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/04aeb89078c870716799a91e3762cd65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8Jfq6Wctzh7pF_SM"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">作者图片</p></figure><p id="a3d7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">聚类的数量通常更难确定，并且通常是执行分析的人的主要挑战。我们将花时间给出一个示例工作流和流程来帮助应对这一挑战。现在，考虑将操作集群化，以自动将我们的数据分组在一起。</p><h1 id="07f1" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">数据</h1><p id="e010" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">我们将使用公开可用的<a class="ae mx" href="https://support.google.com/analytics/answer/7586738?hl=en" rel="noopener ugc nofollow" target="_blank"> Google Analytics 360样本数据集</a>，它托管在BigQuery上，包含来自<a class="ae mx" href="https://shop.googlemerchandisestore.com/" rel="noopener ugc nofollow" target="_blank"> Google商品商店</a>的12个月(2016年8月至2017年8月)模糊的Google Analytics 360数据，这是一家销售Google品牌商品的真实电子商务商店。我们还将构建合成的CRM数据来展示线下+线上数据的力量，这将提供一个更加全面的用户行为视图。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi my"><img src="../Images/07c1228114428169c4a76dce542881d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*alz2fuHXfRsNqZDc"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">来自谷歌商品商店的截图</p></figure><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi my"><img src="../Images/45f62f0596a8b707cb31ee9e637af7d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SeDTCI4OJV5r9dH4"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">这是来自谷歌分析360的一些原始数据的样本</p></figure><h1 id="6cfb" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">处理数据</h1><p id="73b9" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">为聚类构建特征(我们关心的个人属性)完全取决于我们试图解决的问题。在花太多时间处理数据集之前，您应该首先确定业务挑战。为了做到这一点，请咨询您的业务利益相关者，以确定您想要解决的问题。例如，您可能会假设人口统计和地理数据、SKU或产品类别、重复购买者或首次购买者以及当前客户价值之间的关系。你会注意到这包括了分类特征和连续特征的混合。通常，如果您使用scikit-learn、statsmodels或其他软件包，这意味着需要时间来规范化和在数据中创建一个热编码。BigQuery ML的一个直接优势是这个需求不存在！您可以以原始格式传递要素，而无需预处理。当然，花时间做探索性的数据分析并理解您的数据集，但是享受使用BigQuery ML节省的时间。</p><p id="11fe" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="mz">本教程的一些问题和注意事项:</em></p><p id="805b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在本教程中，我们将做一些假设。例如，我们将简化方法，并假设当pagetype = "EVENT "时发生购买。您的Google Analytics 360设置可能会有所不同，因此您可能需要进行相应的调整。我们还使用fullVisitorID作为我们的cookie标签。虽然这是正确的，但我们建议您将clientID设置为自定义维度，其中clientID只是fullVisitorID的哈希版本。当你想在以后的道路上激活观众时，这是一个要求。我们还假设您有可以映射到fullVisitorID的离线数据。我们将创建3个BigQuery视图。第一个视图是聚合GA360数据，第二个视图是聚合CRM数据，最后是连接在一起，最终用于建模。这样，我们就可以创建我们的第一个视图了(注意，SQL很长，所以我会在这篇博客中将其缩短，但是完整的代码可以在这个<a class="ae mx" href="https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/blob/master/retail/clustering/bqml/bqml_scaled_clustering.ipynb" rel="noopener ugc nofollow" target="_blank"> github repo </a>中找到)</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="9e15" class="nf ll iq nb b gy ng nh l ni nj"><em class="mz"># We start with GA360 data, and will eventually build synthetic CRM as an example.  </em><br/><em class="mz"># This block is the first step, which is just working with GA360<br/># I am cutting this code short for formatting.  See github for full code.</em></span><span id="fd89" class="nf ll iq nb b gy nk nh l ni nj">ga360_only_view = 'GA360_View'<br/>shared_dataset_ref = client.dataset(DATA_SET_ID)<br/>ga360_view_ref = shared_dataset_ref.table(ga360_only_view)<br/>ga360_view = bigquery.Table(ga360_view_ref)</span><span id="6646" class="nf ll iq nb b gy nk nh l ni nj">ga360_query = '''<br/>SELECT<br/>  fullVisitorID,<br/>  ABS(farm_fingerprint(fullVisitorID)) AS Hashed_fullVisitorID, <br/>  MAX(device.operatingSystem) AS OS, <br/>  SUM (CASE<br/>       WHEN REGEXP_EXTRACT (v2ProductCategory, <br/>                           r'^(?:(?:.*?)Home/)(.*?)/') <br/>                           = 'Apparel' THEN 1 ELSE 0 END) AS Apparel,...<br/>FROM<br/>  `bigquery-public-data.google_analytics_sample.ga_sessions_*`,<br/>  UNNEST(hits) AS hits,<br/>  UNNEST(hits.product) AS hits_product<br/>WHERE<br/>  _TABLE_SUFFIX BETWEEN '20160801'<br/>  AND '20160831'<br/>  AND geoNetwork.country = 'United States'<br/>  AND type = 'EVENT'<br/>GROUP BY<br/>  1,<br/>  2<br/>'''</span><span id="0829" class="nf ll iq nb b gy nk nh l ni nj">ga360_view.view_query = ga360_query.format(PROJECT_ID)<br/>ga360_view = client.create_table(ga360_view)  <em class="mz"># API request</em></span></pre><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nl"><img src="../Images/22f85e6bee75aa7760a43fc2942a1b7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PmtrVDz9RriZkQA9"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">视图以这种格式创建数据</p></figure><p id="7998" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们有了利用网站行为的基线数据集，我们希望将它与我们可能也了解的用户的离线数据结合起来。为了最好地展示这一点，我们将简单地生成合成数据。如果您有更好的数据源，请随意用您自己的流程替换这一部分。如果没有，请遵循以下步骤:</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="12b6" class="nf ll iq nb b gy ng nh l ni nj"><em class="mz"># Create synthetic CRM data in SQL</em></span><span id="8574" class="nf ll iq nb b gy nk nh l ni nj">CRM_only_view = 'CRM_View'<br/>shared_dataset_ref = client.dataset(DATA_SET_ID)<br/>CRM_view_ref = shared_dataset_ref.table(CRM_only_view)<br/>CRM_view = bigquery.Table(CRM_view_ref)</span><span id="e04c" class="nf ll iq nb b gy nk nh l ni nj"><em class="mz"># Query below works by hashing the fullVisitorID, which creates a random distribution.  </em><br/><em class="mz"># We use modulo to artificially split gender and hhi distribution.</em></span><span id="2186" class="nf ll iq nb b gy nk nh l ni nj">CRM_query = '''<br/>SELECT<br/>  fullVisitorID,<br/>IF<br/>  (MOD(Hashed_fullVisitorID,2) = 0,<br/>    "M",<br/>    "F") AS gender,<br/>  CASE<br/>    WHEN MOD(Hashed_fullVisitorID,10) = 0 THEN 55000<br/>    WHEN MOD(Hashed_fullVisitorID,10) &lt; 3 THEN 65000<br/>    WHEN MOD(Hashed_fullVisitorID,10) &lt; 7 THEN 75000<br/>    WHEN MOD(Hashed_fullVisitorID,10) &lt; 9 THEN 85000<br/>    WHEN MOD(Hashed_fullVisitorID,10) = 9 THEN 95000<br/>  ELSE<br/>  Hashed_fullVisitorID<br/>END<br/>  AS hhi<br/>FROM (<br/>  SELECT<br/>    fullVisitorID,<br/>    ABS(farm_fingerprint(fullVisitorID)) AS Hashed_fullVisitorID,<br/>  FROM<br/>    `bigquery-public-data.google_analytics_sample.ga_sessions_*`,<br/>    UNNEST(hits) AS hits,<br/>    UNNEST(hits.product) AS hits_product<br/>  WHERE<br/>    _TABLE_SUFFIX BETWEEN '20160801'<br/>    AND '20160831'<br/>    AND geoNetwork.country = 'United States'<br/>    AND type = 'EVENT'<br/>  GROUP BY<br/>    1,<br/>    2)<br/>'''</span><span id="68b9" class="nf ll iq nb b gy nk nh l ni nj">CRM_view.view_query = CRM_query.format(PROJECT_ID)<br/>CRM_view = client.create_table(CRM_view)  <em class="mz"># API request</em></span></pre><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/e24a7ef61bcf749cf3fc73226d5511ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/0*H2tyStrq20cDA-oZ.png"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">综合CRM数据的输出</p></figure><p id="73b8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">运行上面的作业后，我们现在有了前两个视图。要将两者结合在一起，并创建我们的最终视图，过程非常简单:</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="000f" class="nf ll iq nb b gy ng nh l ni nj"><em class="mz"># Build a final view, which joins GA360 data with CRM data</em></span><span id="bdff" class="nf ll iq nb b gy nk nh l ni nj">final_data_view = 'Final_View'<br/>shared_dataset_ref = client.dataset(DATA_SET_ID)<br/>final_view_ref = shared_dataset_ref.table(final_data_view)<br/>final_view = bigquery.Table(final_view_ref)</span><span id="9fea" class="nf ll iq nb b gy nk nh l ni nj">final_data_query = f'''<br/>SELECT<br/>    g.*,<br/>    c.* EXCEPT(fullVisitorId)<br/>FROM <strong class="nb ja">{</strong>ga360_view.full_table_id.replace(":", ".")<strong class="nb ja">}</strong> g<br/>JOIN <strong class="nb ja">{</strong>CRM_view.full_table_id.replace(":", ".")<strong class="nb ja">}</strong> c<br/>ON g.fullVisitorId = c.fullVisitorId<br/>'''</span><span id="78bf" class="nf ll iq nb b gy nk nh l ni nj">final_view.view_query = final_data_query.format(PROJECT_ID)<br/>final_view = client.create_table(final_view)  <em class="mz"># API request</em></span><span id="48f0" class="nf ll iq nb b gy nk nh l ni nj">print(f"Successfully created view at <strong class="nb ja">{</strong>final_view.full_table_id<strong class="nb ja">}</strong>")</span></pre><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nn"><img src="../Images/147dc4f8fd7e2b652b655b4ebcf0ab84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zkG1N3Ni3C9Kjf9w"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">用于建模的最终数据集就是这个形状。我们现在可以开始建模了。</p></figure><h1 id="a128" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">创建我们的初始模型</h1><p id="3bef" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">在这一节中，我们将建立我们的初始k均值模型。我们不会关注最优k(我们构建的集群数量)或其他超参数。</p><p id="3e4d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一些附加要点:</p><ol class=""><li id="472d" class="no np iq kq b kr ks ku kv kx nq lb nr lf ns lj nt nu nv nw bi translated">我们删除了作为输入的fullVisitorId，因为它不是一个有用的特性。请记住，高基数数据对分组没有用处。</li><li id="a016" class="no np iq kq b kr nx ku ny kx nz lb oa lf ob lj nt nu nv nw bi translated">我们既有分类特征，也有数字特征。</li><li id="87e8" class="no np iq kq b kr nx ku ny kx nz lb oa lf ob lj nt nu nv nw bi translated">我们不需要规范化任何数字特征，因为BigQuery ML会自动为我们做这件事。</li><li id="9e5e" class="no np iq kq b kr nx ku ny kx nz lb oa lf ob lj nt nu nv nw bi translated">我们不为分类特征构建一个热编码，因为BigQuery ML也会为我们做这件事。</li></ol><h1 id="4948" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">构建一个函数来构建我们的模型</h1><p id="d49b" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">我们将构建一个简单的python函数来构建我们的模型，而不是用SQL做所有的事情。这种方法意味着我们可以异步启动几个模型，让BQ并行运行。另一种方法是使用<a class="ae mx" href="https://cloud.google.com/bigquery/docs/reference/standard-sql/scripting" rel="noopener ugc nofollow" target="_blank"> BigQuery脚本</a>(虽然串行完成，因此速度较慢)。</p><p id="cc2e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将从构建一个简单的模型开始，确保一切看起来都是正确的，然后改进我们的流程。第一步如下:</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="376f" class="nf ll iq nb b gy ng nh l ni nj"><strong class="nb ja">def</strong> makeModel (n_Clusters, Model_Name):<br/>    sql =f'''<br/>    CREATE OR REPLACE MODEL `<strong class="nb ja">{</strong>PROJECT_ID<strong class="nb ja">}</strong>.<br/>                             <strong class="nb ja">{</strong>DATA_SET_ID<strong class="nb ja">}</strong>.<br/>                             <strong class="nb ja">{</strong>Model_Name<strong class="nb ja">}</strong>` <br/>    OPTIONS(model_type='kmeans',<br/>    kmeans_init_method = 'KMEANS++',<br/>    num_clusters=<strong class="nb ja">{</strong>n_Clusters<strong class="nb ja">}</strong>) AS</span><span id="9f4f" class="nf ll iq nb b gy nk nh l ni nj">SELECT * except(fullVisitorID, Hashed_fullVisitorID) <br/>    FROM `<strong class="nb ja">{</strong>final_view.full_table_id.replace(":", ".")<strong class="nb ja">}</strong>`<br/>    '''</span><span id="2b95" class="nf ll iq nb b gy nk nh l ni nj">job_config = bigquery.QueryJobConfig()<br/>    client.query(sql, job_config=job_config)  <em class="mz"># Make an API request.</em></span></pre><p id="9bf8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这创建了一个函数，将为我们建立一个模型，并允许用户定义k(我们将建立多少个集群)。为了测试，让我们调用k=3的函数。</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="b539" class="nf ll iq nb b gy ng nh l ni nj">makeModel(3, "test")</span></pre><p id="350f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一旦训练完成，您现在就有了一个存储在BigQuery中的模型对象，您可以通过单击模型在Bigquery UI中查看和引用它。我们建议您在开始时回顾一下您的模型对象的细节、训练、评估和模式，以理解我们刚刚做了什么。在后面的小节中，我们将向您展示如何以编程方式检索最终模型的统计数据。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi my"><img src="../Images/ecd6a9e63df14daaf0562feac4ec8de2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1JjmhmzkqnZqqegv"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">“模型评估”选项卡提供汇总统计数据</p></figure><h1 id="172d" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">建立一个更好的模型</h1><p id="680c" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">尽管我们刚刚完成了第一个k-means模型的构建，但我们仍然没有解决实现聚类过程时的主要问题——我们应该构建多少个聚类(k )?确定k的正确值完全取决于用例。有一些简单明了的例子可以告诉您需要多少个集群。假设您正在预处理手写数字——这告诉我们k应该是10。或者，也许你的企业利益相关者只想开展三种不同的营销活动，并需要你识别三个客户群，那么设置k=3将是有意义的。但是，使用案例有时更加开放，您可能想要探索不同数量的聚类，以查看如何在每个聚类内以最小的误差将数据分组在一起。为此，我们可以使用肘方法，这是简单的图表损失对k，以及<a class="ae mx" href="https://en.wikipedia.org/wiki/Davies%E2%80%93Bouldin_index" rel="noopener ugc nofollow" target="_blank">戴维斯-波尔丁分数</a>。</p><p id="7f83" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面我们将创建几个模型来执行肘法并得到戴维斯-波尔丁评分。您可以更改low_k和high_k等参数。我们的流程将在这两个值之间创建模型。还有一个名为model_prefix_name的参数。我们建议您保留其当前值。它用于为我们的模型生成命名约定。</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="6467" class="nf ll iq nb b gy ng nh l ni nj"><em class="mz"># Define upper and lower bound for k, then build individual models for each k. </em><br/><em class="mz"># After running this loop, look at the UI to see several model objects that exist.</em></span><span id="3f98" class="nf ll iq nb b gy nk nh l ni nj">low_k = 3<br/>high_k = 15<br/>model_prefix_name = 'kmeans_clusters_'</span><span id="c243" class="nf ll iq nb b gy nk nh l ni nj">lst = list(range (low_k, high_k+1)) <em class="mz">#build list to iterate through k values</em></span><span id="9e75" class="nf ll iq nb b gy nk nh l ni nj"><strong class="nb ja">for</strong> k <strong class="nb ja">in</strong> lst:<br/>    model_name = model_prefix_name + str(k)<br/>    makeModel(k, model_name)<br/>    print(f"Model started: <strong class="nb ja">{</strong>model_name<strong class="nb ja">}</strong>")</span></pre><p id="bb41" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们可以开始分析我们的模型了。这样做的目的是为我们的用例确定正确的模型。</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="2a39" class="nf ll iq nb b gy ng nh l ni nj"><em class="mz"># This will create a dataframe with each model name, the Davies-Bouldin Index, and Loss.  </em><br/><em class="mz"># It will be used for elbow method and to help determine optimal K</em></span><span id="84e8" class="nf ll iq nb b gy nk nh l ni nj">df = pd.DataFrame(columns=['davies_bouldin_index',           'mean_squared_distance'])<br/>models = client.list_models(DATA_SET_ID)  <em class="mz"># Make an API request.</em><br/><strong class="nb ja">for</strong> model <strong class="nb ja">in</strong> models:<br/>    full_model_id = f"<strong class="nb ja">{</strong>model.dataset_id<strong class="nb ja">}</strong>.<strong class="nb ja">{</strong>model.model_id<strong class="nb ja">}</strong>"<br/>    sql =f'''<br/>        SELECT <br/>            davies_bouldin_index,<br/>            mean_squared_distance <br/>        FROM ML.EVALUATE(MODEL `<strong class="nb ja">{</strong>full_model_id<strong class="nb ja">}</strong>`)<br/>    '''</span><span id="a2f8" class="nf ll iq nb b gy nk nh l ni nj">job_config = bigquery.QueryJobConfig()</span><span id="33d8" class="nf ll iq nb b gy nk nh l ni nj"><em class="mz"># Start the query, passing in the extra configuration.</em><br/>    query_job = client.query(sql, job_config=job_config)  <br/>    df_temp = query_job.to_dataframe()  <br/>    df_temp['model_name'] = model.model_id<br/>    df =  pd.concat([df, df_temp], axis=0)</span></pre><p id="f128" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，我们将绘制我们的值与聚类数的关系图，并得到一些值得分析的东西！</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="7ed7" class="nf ll iq nb b gy ng nh l ni nj"><em class="mz"># Plot the dataframe above</em></span><span id="8c27" class="nf ll iq nb b gy nk nh l ni nj">df['n_clusters'] = df['model_name'].str.split('_').map(<strong class="nb ja">lambda</strong> x: x[2])<br/>df['n_clusters'] = df['n_clusters'].apply(pd.to_numeric)<br/>df = df.sort_values(by='n_clusters', ascending=<strong class="nb ja">True</strong>)<br/>df.plot.line(x='n_clusters', y=['davies_bouldin_index', 'mean_squared_distance'])</span></pre><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/efb5199351e7eb018f7627e916118e8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/0*FA3YdX8AYSV8SZGY"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">作者图片</p></figure><p id="f5bd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果您选择了自己的数据，或者如果您使用了一组不同的初始化标准，那么您可能会得到一些不同的值。如果您希望一致地返回相同的集群进行延伸运行，您可以<a class="ae mx" href="https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#kmeans_init_method" rel="noopener ugc nofollow" target="_blank">通过超参数选择</a>明确选择您的初始化。</p><p id="4662" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">上图中有几个标注值得讨论。首先从我们的橙色线开始(loss vs n_clusters)。我们看到，一般来说，随着集群的增加，我们的损失会减少，这是意料之中的。该线也以相对稳定的速度下降。这很常见，也是为什么用肘法不够的原因。偶尔，你可能会惊喜地发现，在某个点上，损耗变平了，形成了肘部形状。如果是这样，这表明连续的集群没有提供额外的价值。</p><p id="7e5c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因为我们看不到这个形状，我们可以继续看蓝线，戴维斯-波尔丁指数。一个简单的描述是，您可能希望使用该得分最低的聚类数。我们看到，在k=5时，我们有一个相对较低的分数，直到k=10时才被击败。我们决定评估10个独立的消费者群是没有意义的，因此我们将在k=5处结束。</p><h1 id="da55" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">分析我们最后的集群</h1><p id="c176" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">如前所述，您可以在前端检查模型性能。我们建议您从这里开始，但是，有些用例需要以编程方式检索结果。为了做到这一点，使用ML.CENTROIDS。</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="a76d" class="nf ll iq nb b gy ng nh l ni nj">model_to_use = 'kmeans_clusters_5' <em class="mz"># User can edit this</em><br/>final_model = DATA_SET_ID+'.'+model_to_use</span><span id="f426" class="nf ll iq nb b gy nk nh l ni nj">sql_get_attributes = f'''<br/>SELECT<br/>  centroid_id,<br/>  feature,<br/>  categorical_value<br/>FROM<br/>  ML.CENTROIDS(MODEL <strong class="nb ja">{</strong>final_model<strong class="nb ja">}</strong>)<br/>WHERE<br/>  feature IN ('OS','gender')<br/>'''</span><span id="87f8" class="nf ll iq nb b gy nk nh l ni nj">job_config = bigquery.QueryJobConfig()</span><span id="88eb" class="nf ll iq nb b gy nk nh l ni nj"><em class="mz"># Start the query</em><br/>query_job = client.query(sql_get_attributes, job_config=job_config) <br/>df_attributes = query_job.result()<br/>df_attributes = df_attributes.to_dataframe()<br/>df_attributes.head()</span></pre><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi od"><img src="../Images/2020f2d925e90a6d8ba6d3c826811e07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EhLE-Lqi7ta_yUn7.png"/></div></div></figure><p id="a229" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们还可以使用下面更多的SQL来计算额外的汇总统计数据。两种ML的组合。预测和ML。质心是有帮助的。</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="aa35" class="nf ll iq nb b gy ng nh l ni nj"><em class="mz"># get numerical information about clusters</em></span><span id="31ed" class="nf ll iq nb b gy nk nh l ni nj">sql_get_numerical_attributes = f'''<br/>WITH T AS (<br/>SELECT <br/>  centroid_id,<br/>  ARRAY_AGG(STRUCT(feature AS name, <br/>                   ROUND(numerical_value,1) AS value) <br/>                   ORDER BY centroid_id) <br/>                   AS cluster<br/>FROM ML.CENTROIDS(MODEL <strong class="nb ja">{</strong>final_model<strong class="nb ja">}</strong>)<br/>GROUP BY centroid_id<br/>),</span><span id="c90d" class="nf ll iq nb b gy nk nh l ni nj">Users AS(<br/>SELECT<br/>  centroid_id,<br/>  COUNT(*) AS Total_Users<br/>FROM(<br/>SELECT<br/>  * EXCEPT(nearest_centroids_distance)<br/>FROM<br/>  ML.PREDICT(MODEL <strong class="nb ja">{</strong>final_model<strong class="nb ja">}</strong>,<br/>    (<br/>    SELECT<br/>      *<br/>    FROM<br/>      <strong class="nb ja">{</strong>final_view.full_table_id.replace(":", ".")<strong class="nb ja">}</strong><br/>      )))<br/>GROUP BY centroid_id<br/>)</span><span id="8b67" class="nf ll iq nb b gy nk nh l ni nj">SELECT<br/>  centroid_id,<br/>  Total_Users,<br/>  (SELECT value from unnest(cluster) WHERE name = 'Apparel') AS Apparel,<br/>  (SELECT value from unnest(cluster) WHERE name = 'Office') AS Office,<br/>  (SELECT value from unnest(cluster) WHERE name = 'Electronics') AS Electronics,<br/>  (SELECT value from unnest(cluster) WHERE name = 'LimitedSupply') AS LimitedSupply,<br/>  (SELECT value from unnest(cluster) WHERE name = 'Accessories') AS Accessories,<br/>  (SELECT value from unnest(cluster) WHERE name = 'ShopByBrand') AS ShopByBrand,<br/>  (SELECT value from unnest(cluster) WHERE name = 'Bags') AS Bags,<br/>  (SELECT value from unnest(cluster) WHERE name = 'productPrice_USD') AS productPrice_USD,<br/>  (SELECT value from unnest(cluster) WHERE name = 'hhi') AS hhi</span><span id="ab42" class="nf ll iq nb b gy nk nh l ni nj">FROM T LEFT JOIN Users USING(centroid_id)<br/>ORDER BY centroid_id ASC<br/>'''</span><span id="0bd3" class="nf ll iq nb b gy nk nh l ni nj">job_config = bigquery.QueryJobConfig()</span><span id="7078" class="nf ll iq nb b gy nk nh l ni nj"><em class="mz"># Start the query</em><br/>query_job = client.query(sql_get_numerical_attributes, job_config=job_config) <em class="mz">#API Request</em><br/>df_numerical_attributes = query_job.result()<br/>df_numerical_attributes = df_numerical_attributes.to_dataframe()<br/>df_numerical_attributes.head()</span></pre><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oe"><img src="../Images/21d9b72dd1728264e1311d26d582bca9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XbaXDkCWLZjBYgdt.png"/></div></div></figure><p id="73e4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们现在可以开始理解集群是如何基于上面提供的值构建的。我们看到以下内容:</p><p id="78c1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第一类:服装购物者，他们也比平常购买得更多。这一部分(尽管是合成数据)偏向女性。</p><p id="5118" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">集群2:最有可能按品牌购物，并对包感兴趣。该细分市场的平均购买量低于第一个集群，但是，这是价值最高的客户。</p><p id="f053" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">集群3:人口最多的集群，这个购买量小，平均花费少。这部分人是一次性购买者，而不是品牌忠诚者。</p><p id="fa3c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">群组4:对配件最感兴趣，购买频率不如群组1和群组2，但购买频率高于群组3。</p><p id="7d89" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">群组5:这是一个异常值，因为只有1个人属于这个群组。</p><p id="716d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">通过单击模型，还可以从BigQuery的UI中获得简单的输出。输出如下所示。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi my"><img src="../Images/32c6715323f86229acc86f6fe1135496.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GrXNOCxiLssnmPLc"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">“模型评估”选项卡提供汇总统计数据</p></figure><h1 id="4596" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">使用模型对新网站行为进行分组，然后将结果推送到Google Analytics 360进行营销激活</h1><p id="13d6" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">在我们有了一个最终确定的模型后，我们想用它来进行推理。下面的代码概述了如何对用户进行评分或将其分配到集群中。这些被标记为质心ID。虽然这本身是有帮助的，但我们也推荐一个将这些分数吸收回GA360的过程。将您的BigQuery ML预测导出到Google Analytics 360的最简单方法是使用调制解调器(营销模型部署，<a class="ae mx" href="https://github.com/google/modem" rel="noopener ugc nofollow" target="_blank">https://github.com/google/modem</a>)。MoDeM帮助您将数据加载到Google Analytics中，以便最终在Google Ads中激活，显示&amp;视频360和搜索广告360。</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="a24e" class="nf ll iq nb b gy ng nh l ni nj">sql_score = f'''<br/>SELECT * EXCEPT(nearest_centroids_distance)<br/>FROM<br/>  ML.PREDICT(MODEL <strong class="nb ja">{</strong>final_model<strong class="nb ja">}</strong>,<br/>    (<br/>    SELECT<br/>      *<br/>    FROM<br/>      <strong class="nb ja">{</strong>final_view.full_table_id.replace(":", ".")<strong class="nb ja">}</strong><br/>      LIMIT 1))<br/>'''</span><span id="b3f1" class="nf ll iq nb b gy nk nh l ni nj">job_config = bigquery.QueryJobConfig()</span><span id="5c6b" class="nf ll iq nb b gy nk nh l ni nj"><em class="mz"># Start the query</em><br/>query_job = client.query(sql_score, job_config=job_config) <em class="mz">#API Request</em><br/>df_score = query_job.result()<br/>df_score = df_score.to_dataframe()</span><span id="7658" class="nf ll iq nb b gy nk nh l ni nj">df_score</span></pre><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oe"><img src="../Images/7e15149d4e8a8f3bdde70b9f9166e085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-XZotmU6X_k-jSKJ.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">新的得分用户</p></figure><h1 id="7169" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">清理:删除模型和表</h1><p id="05ce" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">下面的简单过程将删除所有模型和表格</p><pre class="mi mj mk ml gt na nb nc nd aw ne bi"><span id="43ad" class="nf ll iq nb b gy ng nh l ni nj"><em class="mz"># Are you sure you want to do this? This is to delete all models</em></span><span id="2e20" class="nf ll iq nb b gy nk nh l ni nj">models = client.list_models(DATA_SET_ID) <em class="mz"># Make an API request.</em><br/><strong class="nb ja">for</strong> model <strong class="nb ja">in</strong> models:<br/>    full_model_id = f"<strong class="nb ja">{</strong>model.dataset_id<strong class="nb ja">}</strong>.<strong class="nb ja">{</strong>model.model_id<strong class="nb ja">}</strong>"<br/>    client.delete_model(full_model_id)  <em class="mz"># Make an API request.</em><br/>    print(f"Deleted: <strong class="nb ja">{</strong>full_model_id<strong class="nb ja">}</strong>")</span><span id="90d2" class="nf ll iq nb b gy nk nh l ni nj"><em class="mz"># Are you sure you want to do this? This is to delete all tables and views</em></span><span id="7223" class="nf ll iq nb b gy nk nh l ni nj">tables = client.list_tables(DATA_SET_ID)  <em class="mz"># Make an API request.</em><br/><strong class="nb ja">for</strong> table <strong class="nb ja">in</strong> tables:<br/>    full_table_id = f"<strong class="nb ja">{</strong>table.dataset_id<strong class="nb ja">}</strong>.<strong class="nb ja">{</strong>table.table_id<strong class="nb ja">}</strong>"<br/>    client.delete_table(full_table_id)  <em class="mz"># Make an API request.</em><br/>    print(f"Deleted: <strong class="nb ja">{</strong>full_table_id<strong class="nb ja">}</strong>")</span></pre><h1 id="1a8a" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">把一切都包起来</h1><p id="8013" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">在这个练习中，我们用BigQuery ML中的k-means完成了一些很酷的事情。最值得一提的是，我们能够将在线和离线用户级别的信息结合起来，以便更深入地了解我们客户的整体情况。我们已经对用户行为进行了建模，并详细介绍了一种确定最佳集群数量的方法。我们能够通过推理将这种洞察力应用到未来的行为中。最后，我们可以将这个推断分数导入GA360，用于未来的营销活动。</p><h1 id="42e0" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">想要更多吗？</h1><p id="2f80" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">请留下您的意见和任何建议或更正。</p><p id="b190" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我是Tai Conley，谷歌云平台的AI/ML专家客户工程师。你可以在<a class="ae mx" href="https://www.linkedin.com/in/taiconley/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上找到我。</p><p id="4273" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">感谢审稿人</strong> : Abhishek Kashyap，Polong Lin和Oly Bhaumik。</p></div></div>    
</body>
</html>