<html>
<head>
<title>Language Model like Pre-Training for Acoustic Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">语言模型，如声学数据的预训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/language-model-like-pre-training-for-acoustic-data-f6057b3701ca?source=collection_archive---------30-----------------------#2020-10-29">https://towardsdatascience.com/language-model-like-pre-training-for-acoustic-data-f6057b3701ca?source=collection_archive---------30-----------------------#2020-10-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/968736ddbeab500442c93546f5e81ea5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tn4EL_RnVu6UqnX8wuDmFQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">基于自监督表示学习的声学数据模型— wav2vec [1]，Mockingjay [4]，Audio ALBERT [5]，vq-wav2vec [3]，CPC[6]</p></figure><p id="c92a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">密切关注自然语言处理(NLP)研究的人会知道，最近引入的语言模型，如伯特[7]，GPT，正在从根本上改变NLP领域。在自然语言处理中，无监督的语言模型预训练改善了许多任务，如文本分类、语义文本相似性、机器翻译。<strong class="ke ir">你有没有想过，除了自由文本，这些无监督的语言模型预训练如何帮助序列时间序列数据？</strong></p><p id="60ad" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最近，我得到了一个处理声学数据的机会，我们必须根据记录的声音数据来识别机器的运行组件，比如电机或压缩机。由于没有用于尝试监督学习的标记数据，我不得不寻找替代方法。令我惊讶的是，我遇到了很多使用无监督语言模型(如预训练)即兴完成语音识别任务的研究工作。</p><p id="d35b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你想对声学时间序列数据使用无监督语言模型预训练的能力，那么这篇文章就是为你准备的。</p></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><h2 id="bdff" class="lh li iq bd lj lk ll dn lm ln lo dp lp kn lq lr ls kr lt lu lv kv lw lx ly lz bi translated">语言模型预训练</h2><p id="5274" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz ij bi translated">迁移学习现在相当流行，一个为一个任务训练的模型被重新用于另一个目标任务。在计算机视觉(CV)中，迁移学习广泛存在；例如，为了获得可靠的性能，通常会针对目标任务微调在ImageNet数据集上预先训练的模型。但这里的问题是，很难找到像ImageNet这样的NLP或声学时间序列数据的大规模标记数据集。</p><p id="ed3f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了利用维基百科这样的在线免费文本数据，人们开始使用语言模型预训练。在传统的语言模型设置中，我们的目标通常是使用前面的上下文单词来预测序列中的nᵗʰ单词。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mf"><img src="../Images/d4b38d5a50acb0e4f0c3a8b9892305d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7vSegUHJoLZiw8CckV5_Lw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">伯特蒙面LM的描绘—作者照片</p></figure><p id="9e32" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在当今时代，一个著名的语言模型预训练任务是伯特的蒙面LM (MLM) [7]。在MLM，目标是恢复句子中的屏蔽词。上面提到的图描述了MLM，其中BERT试图根据上下文预测屏蔽的输入单词。从根本上说，在语言建模中，我们试图计算单词序列的联合概率分布。</p><p id="583f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">语言模型预训练允许我们获得有用的基于上下文的单词嵌入，然后我们可以在任何目标任务中使用它。词语嵌入是一种表征方式，它能让意义相似的词语有相似的表征。更正式地，语言模型预训练将属于无监督/自监督表示学习。</p></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><h2 id="8345" class="lh li iq bd lj lk ll dn lm ln lo dp lp kn lq lr ls kr lt lu lv kv lw lx ly lz bi translated">wav2vec</h2><p id="64bd" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz ij bi translated">像预训练这样的语言模型开始在声学任务中显示出一些有希望的结果，如语音识别、音频分割或通过利用未标记的音频数据进行异常检测。wav2vec [1]，Audio ALBERT [5]，wav2vec 2.0 [2]，Mockingjay [4]，vq-wav2vec [3]是其中值得注意的一些。未标记的音频数据比标记的数据更容易访问。</p><p id="c1b0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在本文中，我们将简要地研究脸书的wav2vec模型。wav2vec模型的预训练任务是从给定的信号上下文中预测未来的样本[1]。这项任务的目的基本上是训练模型，这些模型理解波形并生成有意义的声音嵌入。理想情况下，听起来相似的音频片段在这些模型生成的嵌入中具有相似的表示。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/dd63b77d4449e696ae2a5c600dd5837c.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*nz2681IyejEJPd_2VrUnzQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">音频数据“X”的wav2vec预训练图[1]</p></figure><p id="3370" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">wav2vec架构由两个多层卷积神经网络叠加而成，如上图所示。编码器网络将原始音频输入<em class="ml">‘X’</em>映射到表示<em class="ml">‘Z’</em>，其中每个向量覆盖大约30毫秒的音频。上下文网络使用那些<em class="ml">‘Z’</em>向量来生成其表示<em class="ml">‘C’</em>，其覆盖了高达一秒的更大跨度【1】。有关wav2vec的更多信息，请访问此<a class="ae mm" href="https://ai.facebook.com/blog/wav2vec-state-of-the-art-speech-recognition-through-self-supervision/" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="6c15" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">继wav2vec之后，脸书最近发布了vq-wav2vec [3]和wav2vec 2.0 [2]。wav2vec 2.0模型的预训练任务与伯特的MLM非常相似[2]。</p></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><h2 id="6176" class="lh li iq bd lj lk ll dn lm ln lo dp lp kn lq lr ls kr lt lu lv kv lw lx ly lz bi translated">培训定制wav2vec模型</h2><p id="1a31" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz ij bi translated">要基于您的未标记音频数据集训练您自己的定制wav2vec模型，我想推荐脸书AI Research的序列建模工具包，名为<strong class="ke ir"/><a class="ae mm" href="https://github.com/pytorch/fairseq" rel="noopener ugc nofollow" target="_blank"><strong class="ke ir">fair seq</strong></a>。Fairseq提供CLI工具来快速训练您自己的wav2vec系列模型。Fairseq有wav2vec，vq-wav2vec，wav2vec 2.0的示例实现。有关wav2vec系列型号的fairseq的更多信息，请访问此<a class="ae mm" href="https://github.com/pytorch/fairseq/blob/master/examples/wav2vec/README.md" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="159d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">对于其他模型架构，如Mockingjay、Audio ALBERT等。，我想提一下即将推出的名为自我监督语音预训练和表征学习工具包(<a class="ae mm" href="https://github.com/andi611/Self-Supervised-Speech-Pretraining-and-Representation-Learning" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir"> S3PRL语音工具包</strong> </a>)的库。如果你打算研究除了wav2vec系列之外的上述任何型号，一定要看看它们。</p><p id="36a3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><em class="ml">2021年7月18日更新:wav2vec车型现提供</em> <a class="ae mm" href="https://huggingface.co/blog/fine-tune-wav2vec2-english" rel="noopener ugc nofollow" target="_blank"> <em class="ml">抱脸</em>🤗<em class="ml">变形金刚</em>T7】</a></p></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><p id="fa0b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">是时候让有标签的数据集休息一下，开始利用无标签的数据集了。在许多情况下，未标记的数据相对容易收集。</p><p id="41bb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">无监督/自我监督表示学习开始在NLP之外的任务中表现良好。正如本文所讨论的，它已经为声学数据显示了一些有希望的结果。甚至CV也开始使用像预训练一样的无监督语言模型，例如<a class="ae mm" href="https://openai.com/blog/image-gpt/" rel="noopener ugc nofollow" target="_blank">图像GPT </a>。</p><h2 id="90a4" class="lh li iq bd lj lk ll dn lm ln lo dp lp kn lq lr ls kr lt lu lv kv lw lx ly lz bi translated">参考</h2><p id="e479" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv me kx ky kz ij bi translated">[1] Steffen Schneider，Alexei Baevski，Ronan Collobert和Michael Auli，<a class="ae mm" href="https://arxiv.org/abs/1904.05862" rel="noopener ugc nofollow" target="_blank"> wav2vec:语音识别的无监督预训练</a> (2019)</p><p id="dddb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[2] Alexei Baevski，Henry Zhou，Abdelrahman Mohamed，和Michael Auli，<a class="ae mm" href="https://arxiv.org/abs/2006.11477" rel="noopener ugc nofollow" target="_blank"> wav2vec 2.0:语音表征的自我监督学习框架</a> (2020)</p><p id="8a97" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[3] Alexei Baevski，Steffen Schneider和Michael Auli，<a class="ae mm" href="https://arxiv.org/abs/1910.05453" rel="noopener ugc nofollow" target="_blank"> vq-wav2vec:离散语音表示的自我监督学习</a> (2019)</p><p id="c4a7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[4] Andy T. Liu，，Po-Han Chi，Po-chun Hsu和hong-yi Lee，<a class="ae mm" href="https://arxiv.org/abs/1910.12638" rel="noopener ugc nofollow" target="_blank"> Mockingjay:使用深度双向变压器编码器的无监督语音表示学习</a> (2019)</p><p id="6748" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[5]迟宝汉、钟沛鸿、宗吴晗、谢春城、李尚文和李洪义，<a class="ae mm" href="https://arxiv.org/abs/2005.08575" rel="noopener ugc nofollow" target="_blank">音频阿尔伯特:一个用于音频表征自我监督学习的Lite BERT</a>(2020)</p><p id="9611" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[6] Aaron van den Oord，Yazhe Li，和Oriol Vinyals，<a class="ae mm" href="https://arxiv.org/abs/1807.03748" rel="noopener ugc nofollow" target="_blank">使用对比预测编码的表征学习</a> (2018)</p><p id="40c2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[7] Jacob Devlin，Ming-Wei Chang，Kenton Lee，和Kristina Toutanova，<a class="ae mm" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> BERT:用于语言理解的深度双向转换器的预训练</a> (2018)</p></div></div>    
</body>
</html>