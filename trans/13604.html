<html>
<head>
<title>Animations of Neural Networks Transforming Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络转换数据的动画</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/animations-of-neural-networks-transforming-data-42005e8fffd9?source=collection_archive---------22-----------------------#2020-09-18">https://towardsdatascience.com/animations-of-neural-networks-transforming-data-42005e8fffd9?source=collection_archive---------22-----------------------#2020-09-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="398f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们可以对神经网络为什么以及如何工作有更好的直觉</h2></div><p id="602f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谈到分类算法，对它们如何工作的解释可以是<em class="le">直观的</em>:</p><ul class=""><li id="3ba1" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated"><strong class="kk iu">逻辑回归</strong>和<strong class="kk iu"> SVM </strong>找到一个<strong class="kk iu">超平面</strong>将空间“切割”成两个。(但是这两种算法的途径不一样，所以最终的超平面也不一样。)</li><li id="b4ed" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">如果数据不是线性可分的，使用<strong class="kk iu">内核技巧</strong>，<strong class="kk iu"> SVM </strong>将数据转换到<strong class="kk iu">一个更高维度的空间</strong>，然后将其“切割”成两个。</li><li id="b4fd" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated"><strong class="kk iu">决策树</strong>将数据分组到<strong class="kk iu">超矩形</strong>中，超矩形将包含一个类的大部分。</li><li id="8ff1" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated"><strong class="kk iu"> K最近邻</strong>分析<strong class="kk iu">新观测值的邻居</strong>来预测该观测值的类别。</li></ul><p id="e54f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么<strong class="kk iu">神经网络</strong>呢？</p><h1 id="f3f8" class="lt lu it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">隐藏层的变换</h1><p id="18d7" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">我们举个简单的数据集例子:两个类，两个特征x1和x2，数据<em class="le">不线性可分</em>。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="e61d" class="mz lu it mv b gy na nb l nc nd">import numpy as np</span><span id="9bbc" class="mz lu it mv b gy ne nb l nc nd">np.random.seed(1)</span><span id="7055" class="mz lu it mv b gy ne nb l nc nd">x1=np.concatenate((np.random.normal(0.5,0.1,100),<br/>np.random.normal(0.2,0.05,50),<br/>np.random.normal(0.8,0.05,50))).reshape(-1,1)</span><span id="3ecc" class="mz lu it mv b gy ne nb l nc nd">x2=np.concatenate((np.random.normal(0.5,0.2,100),<br/>np.random.normal(0.5,0.2,50),<br/>np.random.normal(0.5,0.2,50))).reshape(-1,1)</span><span id="cfe4" class="mz lu it mv b gy ne nb l nc nd">X=np.hstack((x1,x2))</span><span id="8714" class="mz lu it mv b gy ne nb l nc nd">y=np.concatenate((np.repeat(0,100),np.repeat(1,100)))</span></pre><p id="6e6c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可视化如下，数据也是标准化的。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="e16c" class="mz lu it mv b gy na nb l nc nd">from sklearn.preprocessing import StandardScaler<br/>scaler = StandardScaler()<br/>X=scaler.fit_transform(X)</span><span id="c7fa" class="mz lu it mv b gy ne nb l nc nd">plt.scatter(X[:, 0], X[:, 1], c=y,s=20)<br/>plt.axis('equal')</span></pre><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/699e02c89dfab7cd71a3dbf69bf0411a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*pof-LKTPx311wNyHUjkrEg.png"/></div></figure><p id="d3ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于该数据集，神经网络最简单的合适结构是具有<strong class="kk iu">两个神经元的一个隐藏层</strong>的结构。如果你看不出为什么，那就继续，你会直观地理解。</p><p id="1ccf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也可以认为激活函数是<strong class="kk iu"> sigmoid函数</strong>。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="ea11" class="mz lu it mv b gy na nb l nc nd">from sklearn.neural_network import MLPClassifier</span><span id="ff3b" class="mz lu it mv b gy ne nb l nc nd">clf = MLPClassifier(solver=’lbfgs’,hidden_layer_sizes=(2,),<br/>activation=”logistic”,max_iter=1000)</span><span id="6cc3" class="mz lu it mv b gy ne nb l nc nd">clf.fit(X, y)</span></pre><p id="a3f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">初始数据通过隐藏层进行转换。由于隐藏层有两个神经元，我们可以在2D平面上可视化这两个神经元的输出。</p><p id="9389" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，初始2D数据集被转换到另一个2D空间。</p><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nj"><img src="../Images/9b5def013b1d7778ad9a5d355f9cd933.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kX-GA1kr-U-_Cg4qkte0tQ.png"/></div></div></figure><p id="734c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以用相应的权重计算隐藏层A1的值:</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="2853" class="mz lu it mv b gy na nb l nc nd">A1=1/(1+np.exp(-(X@clf.coefs_[0]+clf.intercepts_[0])))</span></pre><p id="df7f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们可以将A1层可视化:</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="7caf" class="mz lu it mv b gy na nb l nc nd">fig, ax = plt.subplots(figsize=(5,5))<br/>ax.scatter(A1[:, 0], A1[:, 1], c=y,s=30)<br/>ax.set_xlim(-0.1, 1.1)<br/>ax.set_ylim(-0.1, 1.1)</span></pre><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi no"><img src="../Images/9af52cfb0036faa7ddc47ec1dcbd8ec8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ywuh0dGCp53Nldeto0iMXQ.png"/></div></div></figure><p id="65f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，如何将初始数据转换成这些值？我们可以将这个过程动画化:</p><ul class=""><li id="7ed9" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated">一开始，我们有原始数据集(记住，它不是线性可分的)</li><li id="3a08" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">最后，我们将在(0，1)方块中得到转换后的数据，因为sigmoid函数的输出介于0和1之间。你看到数据的形式了吗？是的，这就是奇迹发生的时候…</li></ul><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/e32c6a1fa3a910a1955ea43776a32e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/1*MSJ9RqrMr2zLFmpvBzz1gw.gif"/></div></figure><h1 id="4507" class="lt lu it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">输出神经元的性质</h1><p id="0060" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">我们可以看到最后，<strong class="kk iu">数据集变成线性可分！</strong>对于二元分类，输出神经元是一个逻辑回归。并且很容易找到线性决策边界。在这种情况下，超平面分隔符将是一条直线。</p><blockquote class="np"><p id="d3d9" class="nq nr it bd ns nt nu nv nw nx ny ld dk translated">因此，神经网络背后的直觉是，隐藏层将非线性可分离的初始数据转换到它们几乎线性可分离的空间。</p></blockquote><h1 id="6dfa" class="lt lu it bd lv lw lx ly lz ma mb mc md jz nz ka mf kc oa kd mh kf ob kg mj mk bi translated">神经网络的整体结构</h1><p id="be42" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">结合隐藏层和输出层，我们有一个表面，我们可以在下面可视化。它是一个曲面，因为输入有两个变量，输出是概率，所以我们可以用z轴来表示。</p><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi oc"><img src="../Images/c505c03f4ca68a634edf96b5e2ea001a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L2f-g3q-y8IcY6VIthi6CA.png"/></div></div></figure><p id="a93a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们可以看到，这两个神经元“切割”了两个类之间的两个边界。</p><h1 id="74b2" class="lt lu it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">稍微复杂一点的数据</h1><p id="af6d" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">现在让我们考虑下面的数据集。一个类在另一个类里面，有一个循环的形式。在使用神经网络之前，哪些算法可以解决这个问题？</p><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi od"><img src="../Images/0bbdddd7edaf602605d40f7dac20da7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*skh1CDlajCnl4q3T8fmRBg.png"/></div></div></figure><ul class=""><li id="7620" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated"><strong class="kk iu">二次判别分析</strong>是合适的候选，因为两类协方差矩阵不同，中心相同。决策边界将是一个几乎完美的圆，以区分黄色点和紫色点。</li><li id="493c" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated"><strong class="kk iu">带RBF </strong>(径向基函数)<strong class="kk iu">核</strong>的SVM也会很完美。</li><li id="b158" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">一个<strong class="kk iu">神经网络</strong>怎么样？两个神经元意味着你只“切”两次，这里我们至少需要三个。</li></ul><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nj"><img src="../Images/28815d99408014c2189e30ec11dff725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NJxRBh9I4cWcvn6c7ITLHw.png"/></div></div></figure><h2 id="2b88" class="mz lu it bd lv oe of dn lz og oh dp md kr oi oj mf kv ok ol mh kz om on mj oo bi translated">最终神经网络表示</h2><p id="417d" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">我们可以首先看到下面的最终表面，决策边界实际上是一种三角形。</p><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi op"><img src="../Images/44a22d62eab5eaeb5e5fb7e55f8955c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DD8VtzgIwuYr_rRL5NgtsQ.png"/></div></div></figure><h2 id="8fdf" class="mz lu it bd lv oe of dn lz og oh dp md kr oi oj mf kv ok ol mh kz om on mj oo bi translated">隐藏层的变换</h2><p id="767e" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">初始的2D空间被转换成具有3个神经元的3D空间。我们可以让这种转变生动起来。</p><ul class=""><li id="a28b" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated">一开始，数据集在一个平面上。我们将认为z轴的值为零。</li><li id="dcf0" class="lf lg it kk b kl lo ko lp kr lq kv lr kz ls ld lk ll lm ln bi translated">最后，数据集被映射到(0，1)立方体中，因为sigmoid函数的输出介于0和1之间。</li></ul><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/bf4df40d836c0a68e97960f73c9224ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/1*kOVIEQihU2bKPu2-13b5Jw.gif"/></div></figure><p id="6ccb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在你能看到数据集在这个立方体中几乎是线性可分的吗？让我们通过旋转立方体来创建另一个动画。现在你看到了，用一架飞机，我们可以很容易地把黄色的点和紫色的点分开？</p><figure class="mq mr ms mt gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi or"><img src="../Images/b1267764651246d8345b5cc023feec35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/1*2YhFLrZYCQqhZuCdgIKpkw.gif"/></div></div></figure></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><p id="40cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了理解算法是如何工作的，我喜欢用简单的数据创建可视化。如果你也觉得它们有帮助，请评论。</p><p id="70a5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些情节首先是用python创建的，然后我用gifmaker制作动画。</p></div></div>    
</body>
</html>