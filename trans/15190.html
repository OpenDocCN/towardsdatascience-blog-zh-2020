<html>
<head>
<title>FACTOR ANALYSIS-MY ML OREO DETECTOR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">因子分析-我的ML奥利奥检测器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/factor-analysis-my-ml-oreo-detector-2e02abc2bb30?source=collection_archive---------20-----------------------#2020-10-19">https://towardsdatascience.com/factor-analysis-my-ml-oreo-detector-2e02abc2bb30?source=collection_archive---------20-----------------------#2020-10-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7d7c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kl">“美貌得眼球，个性得人心”。这些线条描绘了我们视野之外的事物的重要性。一种机器学习算法怎么样，它可以找到关于内在美的信息，比如我的心脏，它可以找到奥利奥的奶油层，尽管外面有令人倒胃口的松脆饼干。</em>T3】</strong></p><h1 id="bb54" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">要素分析</h1><p id="23ee" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">因子分析是一种用于降维的无监督机器学习算法。该算法从观察变量中创建因子来表示公共方差，即由于观察变量之间的相关性而产生的方差。是的，这听起来有点专业，所以让我们把它分成比萨饼和切片。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/c8e9d3ba6951913535eeed895750eab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*dlZRhuOKXeBMXvpQer8sSA.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">用因素表示特征(作者提供的图片)</p></figure><p id="b05c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kl"> x </em> </strong>为变量，<strong class="jp ir"> <em class="kl"> F </em> </strong>为因子，<strong class="jp ir"> l </strong>为因子载荷，也可视为因子对相应变量的权重。因子的数量等于变量的数量。</p><h1 id="8bee" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">故事时间</h1><p id="e3b9" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">让我们用一个例子让一切更清楚。假设我们每个人现在都是招聘人员，我们想为我们的公司招聘员工。采访过程已经结束，对于被采访者的每一种性格，我们都给他们打了分。受访者的各种性格有疏远、放松、粗心、健谈、懒惰等..大约有32个变量。我们可以看到放松、粗心和懒惰的特征是相互关联的，因为这些人不会成功。由于这些变量是相关的，我们可以尝试形成一个称为“不成功行为”的因素，它将解释常见的差异，即由于这些特征之间的相关性而产生的差异。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/95f23fed1c816bd1a103bccf0d135267.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*B_NI7tlOfRnttlXU2wsMlA.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">相似或相关的特征可以被分组并表示为因素(图片由作者提供)</p></figure><p id="bd8d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据集和代码可以从我的<a class="ae mc" href="https://github.com/Dhamodaran-Babu/Machine-Learning-Exercises/tree/master/12.Factor%20Analysis" rel="noopener ugc nofollow" target="_blank"> GithubRepo </a>下载</p><h1 id="4f12" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">因子分析的步骤</h1><p id="0e2b" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">因子分析涉及的各个步骤是</p><ul class=""><li id="26bf" class="md me iq jp b jq jr ju jv jy mf kc mg kg mh kk mi mj mk ml bi translated">巴特利特球形度试验和KMO试验</li><li id="643f" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">确定因子的数量</li><li id="19bf" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">解释这些因素</li></ul><p id="ef90" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">确保您已经移除了异常值，对数据进行了标准缩放，并且要素必须是数字。</p><p id="5037" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将在以下软件包的帮助下用python实现这一点</p><ul class=""><li id="fe10" class="md me iq jp b jq jr ju jv jy mf kc mg kg mh kk mi mj mk ml bi translated">因子分析器</li><li id="a08d" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">numpy</li><li id="3606" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">熊猫</li><li id="63dc" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">matplotlib</li></ul><h1 id="3fae" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">巴特利特球形试验</h1><p id="d11c" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">Bartlett检验检查给定数据中是否存在相关性。它测试相关矩阵是一个相同矩阵的零假设(H0)。全同矩阵包括所有对角元素为1。因此，零假设假设变量之间不存在相关性。我们想要拒绝这个零假设，因为因子分析旨在解释共同方差，即由于变量之间的相关性而产生的变化。如果p检验统计值小于0.05，我们可以确定相关性不是相同的矩阵，即相关性存在于具有95%置信水平的变量中。</p><pre class="lq lr ls lt gt mr ms mt mu aw mv bi"><span id="1fb4" class="mw kn iq ms b gy mx my l mz na">from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity</span><span id="5527" class="mw kn iq ms b gy nb my l mz na">chi2,p = calculate_bartlett_sphericity(dataframe)<br/>print("Chi squared value : ",chi2)<br/>print("p value : ",p)</span><span id="41de" class="mw kn iq ms b gy nb my l mz na">#OUTPUT:</span><span id="ecd3" class="mw kn iq ms b gy nb my l mz na">Bartlett Sphericity Test</span><span id="1f52" class="mw kn iq ms b gy nb my l mz na">Chi squared value : 4054.19037041082<br/>p value : 0.0</span></pre><p id="1ed6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用pandas读取数据集并将数据集存储在dataframe中。我们将数据集存储在名为“dataset”的数据帧中。只需将“数据集”通过calculate _ bartltett _ sphericty函数，它将测试零假设并返回卡方值和p检验统计量。由于p检验统计量小于0.05，我们可以得出结论，变量之间存在相关性，这是应用因子分析的绿色信号。</p><h1 id="6b50" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">凯泽-迈耶-奥尔金(KMO)试验</h1><p id="2a71" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">KMO检验测量的是变量中可能是普通方差的方差的比例。预计会有更大的比例，因为它代表变量之间存在更多的相关性，从而为因子分析等维度缩减技术的应用让路。KMO分数总是在0到1之间，大于0.6的值非常受欢迎。我们也可以说它是衡量我们的数据对因子分析的适合程度的一个标准。</p><pre class="lq lr ls lt gt mr ms mt mu aw mv bi"><span id="f4b3" class="mw kn iq ms b gy mx my l mz na">from factor_analyzer.factor_analyzer import calculate_kmo</span><span id="2f19" class="mw kn iq ms b gy nb my l mz na">kmo_vars,kmo_model = calculate_kmo(dataset)<br/>print(kmo_model)</span><span id="30f9" class="mw kn iq ms b gy nb my l mz na">#OUTPUT:<br/>KMO Test Statistic 0.8412492848324344</span></pre><p id="516d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">只需将包含数据集信息的dataframe传递给calculate_kmo函数。该函数将返回存储在变量“kmo_vars”中的每个变量的方差比例，并且我们的整个数据的方差比例存储在“kmo_model”中。我们可以看到，我们的数据的总体方差比例为0.84。这表明我们的数据有更多的相关性和降维技术，如因子分析可以应用。</p><h1 id="0af1" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">确定因子的数量</strong></h1><p id="d02f" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">数据集中因子的数量等于数据集中变量的数量。所有的因素都不能提供大量有用的关于变量间共同方差的信息。所以我们必须决定因素的数量。因子的数量可以根据因子解释的公共方差的数量来决定。一般来说，我们将画出因子和它们的特征值。特征值只不过是因子解释的方差的数量。我们将选择特征值大于1的因子的数量。</p><p id="6366" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是为什么要选择特征值大于1的因子呢？答案很简单。在均值为0、标准差为1的标准正态分布中，方差为1。因为我们对数据进行了标准缩放，所以特征的方差为1。这就是选择特征值(方差)大于1的因子的原因，即这些因子比单个观察变量解释更多的方差。</p><pre class="lq lr ls lt gt mr ms mt mu aw mv bi"><span id="d3c4" class="mw kn iq ms b gy mx my l mz na">from factor_analyzer import FactorAnalyzer</span><span id="08e6" class="mw kn iq ms b gy nb my l mz na">fa = FactorAnalyzer(rotation = None,impute = "drop",n_factors=dataframe.shape[1])</span><span id="32d4" class="mw kn iq ms b gy nb my l mz na">fa.fit(dataframe)<br/>ev,_ = fa.get_eigenvalues()</span><span id="867c" class="mw kn iq ms b gy nb my l mz na">plt.scatter(range(1,dataframe.shape[1]+1),ev)<br/>plt.plot(range(1,dataframe.shape[1]+1),ev)<br/>plt.title('Scree Plot')<br/>plt.xlabel('Factors')<br/>plt.ylabel('Eigen Value')<br/>plt.grid()</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/77d0c9e83acb051f33614f2df6bfc6af.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*981ioYA_KuVocqtlCPXt4A.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">确定因素数量(图片由作者提供)</p></figure><p id="7c05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">特征值函数将返回原始特征值和公因数特征值。现在，我们将只考虑原始特征值。从图中我们可以看到，特征值从第7个因子下降到1以下。因此，最佳因子数为6。</p><h1 id="1a2f" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">解释这些因素</h1><p id="49c5" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">创建最佳数量的因子，在我们的示例中为6。然后，我们必须利用负荷、方差和共性来解释这些因素。</p><h2 id="4d61" class="mw kn iq bd ko nd ne dn ks nf ng dp kw jy nh ni la kc nj nk le kg nl nm li nn bi translated">装货</h2><pre class="lq lr ls lt gt mr ms mt mu aw mv bi"><span id="7be4" class="mw kn iq ms b gy mx my l mz na">fa = FactorAnalyzer(n_factors=6,rotation='varimax')<br/>fa.fit(dataset)<br/>print(pd.DataFrame(fa.loadings_,index=dataframe.columns))</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi no"><img src="../Images/afddbfbab53e8657ed6e0899f8f50421.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*_u8YHRVPWR84fqecah1LiA.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">因子加载(图片由作者提供)</p></figure><p id="0f1d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">负荷表明一个因素在多大程度上解释了一个变量。加载分数的范围从-1到1。接近-1或1的值表示因子对这些变量有影响。值接近0表示因子对变量的影响较小。</p><p id="4cf3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，在因子0中，我们可以看到特征“疏远”和“害羞”健谈比其他变量具有更高的负载。由此我们可以看出，因子0解释了矜持人群中的普遍差异，即疏远和害羞人群中的差异。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi np"><img src="../Images/b9838a16eee287bf6a6644a14ce5fcd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*C1MXclgNRLA3Iz-MFx0SwA.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">因子0(保留)(图片由作者提供)</p></figure><h2 id="ac02" class="mw kn iq bd ko nd ne dn ks nf ng dp kw jy nh ni la kc nj nk le kg nl nm li nn bi translated">差异</h2><p id="4acf" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">使用“get_factor_variance”函数可以找出每个因素解释的差异量。</p><pre class="lq lr ls lt gt mr ms mt mu aw mv bi"><span id="b2b4" class="mw kn iq ms b gy mx my l mz na">print(pd.DataFrame(fa.get_factor_variance(),index=['Variance','Proportional Var','Cumulative Var']))</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/1e8d78302e98ee3116dd2bf2d6eff0b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*yJm52ud1QL3H4CwALRLEgQ.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">由因素解释的差异(图片由作者提供)</p></figure><p id="1ec6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一行代表由每个因素解释的方差。比例方差是由总方差中的一个因子解释的方差。累积方差只不过是每个因素的比例方差的累积和。在我们的案例中，这6个因素合起来可以解释总方差的55.3%。</p><p id="dd91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在非旋转情况下，方差将等于特征值。旋转会改变比例方差的分布，但累积方差将保持不变。倾斜旋转允许因子之间相关，而正交旋转保持因子不相关。</p><h2 id="3fe4" class="mw kn iq bd ko nd ne dn ks nf ng dp kw jy nh ni la kc nj nk le kg nl nm li nn bi translated">社区</h2><p id="de58" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">公度是每个变量的方差的比例，可以用因子来解释。旋转对变量的公度没有任何影响。</p><pre class="lq lr ls lt gt mr ms mt mu aw mv bi"><span id="cbc7" class="mw kn iq ms b gy mx my l mz na">print(pd.DataFrame(fa.get_communalities(),index=dataframe.columns,columns=['Communalities']))</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/829602ec627fc42fafbe002810676e56.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*mxPe6Jf9M5J1xPZA6_nY0w.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">社群(作者图片)</p></figure><p id="6954" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由因子解释的每个变量的方差的比例可以从上面推断出来。例如，我们可以考虑变量“talkatv ”,其方差的62.9%可以由所有因素共同解释。</p><p id="642b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是关于因子分析的全部内容，因子分析可用于发现潜在的方差，这是由于观察到的变量之间的相关性，比如我的心脏发现了奥利奥的奶油层，尽管外层松脆的饼干令人倒胃口。</p></div></div>    
</body>
</html>