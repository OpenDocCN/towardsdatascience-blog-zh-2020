<html>
<head>
<title>How to identify Spam using Natural Language Processing (NLP)?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用自然语言处理(NLP)识别垃圾邮件？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-identify-spam-using-natural-language-processing-nlp-af91f4170113?source=collection_archive---------17-----------------------#2020-10-26">https://towardsdatascience.com/how-to-identify-spam-using-natural-language-processing-nlp-af91f4170113?source=collection_archive---------17-----------------------#2020-10-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d5a7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Python自然语言处理的垃圾邮件检测</h2></div><p id="08a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">人类掌握了数百万个单词，但从计算上来说:我们如何使用编程技术操纵大量文本？</p><p id="fd39" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">计算机可以理解普通语言并与人类对话的想法一直是科幻小说的主题。然而，二十世纪上半叶又有一篇经典论文设想由<a class="ae lb" href="https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir"/></a>艾伦·图灵(1950)作为计算智能的标志。</p><p id="b8e5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文将关注计算机系统如何使用自然语言处理(NLP)来分析和解释文本。为此，你应该安装自然语言工具包，你可以从<a class="ae lb" href="http://www.nltk.org/" rel="noopener ugc nofollow" target="_blank">http://nltk.org</a>开始安装。在引用的网站上可以找到说明以及需要安装的相关包的细节，包括Python本身，它也是免费的。</p><h2 id="e0db" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">什么是自然语言处理(NLP)？</h2><p id="ebd2" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">自然语言处理(NLP)是<a class="ae lb" href="https://medium.com/@patriziacastagnod/artificial-intelligence-ai-d741e3549fe" rel="noopener">人工智能(AI) </a>的一个子集，它基本上负责机器或机器人对人类语言的理解。</p><p id="eba1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">NLP中的一个重要子主题是<strong class="kh ir"><em class="ma">【NLU】</em></strong>自然语言理解，原因是它用于理解人类语言的结构和意义，然后在计算机科学的帮助下将这些语言知识转化为基于规则的机器学习算法，这些算法可以解决特定的问题并执行所需的任务。</p><h1 id="cb92" class="mb ld iq bd le mc md me lh mf mg mh lk jw mi jx ln jz mj ka lq kc mk kd lt ml bi translated">PYTHON语言处理</h1><p id="84a0" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">这篇文章的目的是告诉你如何检测垃圾短信。</p><p id="7cfb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，我们使用来自<a class="ae lb" href="https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> UCI数据集</strong> </a>的数据集，这是一个公共数据集，包含为手机垃圾邮件研究而收集的带SMS标签的消息。它有一个由5.574条英文短信组成的集合，根据合法(ham)或垃圾邮件进行标记。</p><p id="6611" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们将训练一个模型来学习自动区分火腿/垃圾邮件。然后我们将使用“测试数据”来测试模型。最后，为了评估我们的模型是否有效，我们将计算准确率、分类报告和混淆矩阵。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="3113" class="mb ld iq bd le mc mt me lh mf mu mh lk jw mv jx ln jz mw ka lq kc mx kd lt ml bi translated">探索性数据分析</h1><p id="baf2" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">要开始，我们应该首先导入所有的库，然后加载数据并重命名names列:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="2928" class="lc ld iq nd b gy nh ni l nj nk"># Import library</span><span id="60af" class="lc ld iq nd b gy nl ni l nj nk">import pandas as pd<br/>import numpy as np<br/>import string<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from nltk.corpus import stopwords<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.feature_extraction.text import TfidfTransformer<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.svm import SVC<br/>from collections import Counter<br/>from sklearn.metrics import classification_report,confusion_matrix<br/>from sklearn.model_selection import GridSearchCV<br/>%matplotlib inline</span><span id="e0ab" class="lc ld iq nd b gy nl ni l nj nk"># Load data<br/>data = pd.read_excel('data.xlsx')</span><span id="bb92" class="lc ld iq nd b gy nl ni l nj nk"># Rename names columns <br/>data.columns = ['label', 'messages']</span></pre><p id="29fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看我们的数据描述:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="5f1f" class="lc ld iq nd b gy nh ni l nj nk">data.describe()</span></pre><figure class="my mz na nb gt nn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/063327bb5c7ed001e5917b8c73ccfb98.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*gCwjrr1jvMS91wwsF__5lg.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">数据描述(图片由作者提供)</p></figure><p id="47b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，我们的数据包含5574条短信的集合，而且我们只有2个标签:火腿和垃圾邮件。现在，我们创建一个名为“length”的列，以了解文本消息有多长，然后根据标签绘制它:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="caa1" class="lc ld iq nd b gy nh ni l nj nk">data["length"] = data["messages"].apply(len)<br/>data.sort_values(by='length', ascending=False).head(10)</span></pre><figure class="my mz na nb gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi nu"><img src="../Images/9f8b8eac774c2c002b7cc2c17794282b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*qktIxDaMVNpZRh4YjAflBw.png"/></div></div></figure><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="116a" class="lc ld iq nd b gy nh ni l nj nk">data.hist(column = 'length', by ='label',figsize=(12,4), bins = 5)</span></pre><figure class="my mz na nb gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi nz"><img src="../Images/5b222dea04be33d9d1d7072d1f9681c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6b1GLxjtfsCHJYhFJRVH_g.png"/></div></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">长度和标签之间的直方图(图片由作者提供)</p></figure><p id="2f07" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，通过直方图，我们已经能够发现垃圾邮件往往有更多的字符。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="445d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最有可能的是，您遇到的大多数数据都是数值型或分类型的，但是当它是字符串类型(文本格式)时会发生什么呢？</p><p id="9291" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可能已经注意到，我们的数据是string类型的。因此，我们应该将它转换成一个数字向量，以便能够执行分类任务。为此，我们使用<a class="ae lb" href="https://en.wikipedia.org/wiki/Bag-of-words_model#:~:text=The%20bag%2Dof%2Dwords%20model,word%20order%20but%20keeping%20multiplicity." rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">单词袋</strong> </a>，其中文本中的每个唯一单词将由一个数字表示。但是在做这个转换之前，我们要去掉所有的标点符号，然后常见的词像:['我'，'我'，'我自己'，'我们'，'我们的'，'我们的'，'我们自己'，'你'，'是'…]。这个过程叫做<strong class="kh ir">标记化</strong>。在这个过程之后，我们将字符串序列转换成数字序列。</p><ol class=""><li id="45fb" class="oa ob iq kh b ki kj kl km ko oc ks od kw oe la of og oh oi bi translated"><strong class="kh ir">去掉所有标点:</strong>假设我们有下面这句话:<br/><strong class="kh ir">* * * * * * * * * *大家好！！！很高兴遇见你********** </strong></li></ol><p id="7aa3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">而且我们要去掉<strong class="kh ir">！！！</strong>和<strong class="kh ir">。</strong></p><p id="5aae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们加载导入字符串库，并执行以下操作:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="bf86" class="lc ld iq nd b gy nh ni l nj nk">message = "Hi everyone!!! it is a pleasure to meet you."</span><span id="b652" class="lc ld iq nd b gy nl ni l nj nk">message_not_punc = []</span><span id="105d" class="lc ld iq nd b gy nl ni l nj nk">for punctuation in message:<br/>    if punctuation not in string.punctuation:<br/>           message_not_punc.append(punctuation)</span><span id="45f3" class="lc ld iq nd b gy nl ni l nj nk"># Join the characters again to form the string.<br/>message_not_punc = ''.join(message_not_punc)<br/>print(message_not_punc)</span><span id="5b17" class="lc ld iq nd b gy nl ni l nj nk"><strong class="nd ir">&gt;&gt;&gt; Hi everyone it is a pleasure to meet you</strong></span></pre><p id="4e13" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.<strong class="kh ir">删除常用词:</strong></p><p id="457e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，我们使用nltk库，即nltk.corpus中的<strong class="kh ir">导入停用词</strong></p><p id="5fdc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">重要的是要知道<strong class="kh ir">停用词</strong>支持23种语言(这个数字必须是最新的)。在这种情况下，我们使用英语:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="737a" class="lc ld iq nd b gy nh ni l nj nk">from nltk.corpus import stopwords</span><span id="28cc" class="lc ld iq nd b gy nl ni l nj nk"># Remove any stopwords for remove_punc, but first we should to transform this into the list.</span><span id="0845" class="lc ld iq nd b gy nl ni l nj nk">message_clean = list(message_not_punc.split(" "))</span><span id="2088" class="lc ld iq nd b gy nl ni l nj nk"># Remove any stopwords</span><span id="35c9" class="lc ld iq nd b gy nl ni l nj nk">i = 0<br/>while i &lt;= len(message_clean):<br/> for mess in message_clean:<br/>     if mess.lower() in stopwords.words(‘english’):<br/>                  message_clean.remove(mess)<br/> <br/> i =i +1<br/> <br/>print(message_clean)</span><span id="ad04" class="lc ld iq nd b gy nl ni l nj nk"><strong class="nd ir">&gt;&gt;&gt; ['Hi', 'everyone', 'pleasure', 'meet']</strong></span></pre><p id="8f83" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，通过步骤1和2，我们可以创建以下函数:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="1a1a" class="lc ld iq nd b gy nh ni l nj nk">def transform_message(message):<br/>    message_not_punc = [] # Message without punctuation<br/>    i = 0<br/>    for punctuation in message:<br/>        if punctuation not in string.punctuation:<br/>            message_not_punc.append(punctuation)<br/>    # Join words again to form the string.<br/>    message_not_punc = ''.join(message_not_punc) <br/><br/>    # Remove any stopwords for message_not_punc, but first we should     <br/>    # to transform this into the list.<br/>    message_clean = list(message_not_punc.split(" "))<br/>    while i &lt;= len(message_clean):<br/>        for mess in message_clean:<br/>            if mess.lower()  in stopwords.words('english'):<br/>                message_clean.remove(mess)<br/>        i =i +1<br/>    return  message_clean</span></pre><p id="399a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以通过以下方式将上述函数应用于我们的数据分析:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="d969" class="lc ld iq nd b gy nh ni l nj nk">data['messages'].head(5).apply(transform_message)</span><span id="46ca" class="lc ld iq nd b gy nl ni l nj nk">&gt;&gt;&gt;<br/>0    [Go, jurong, point, crazy, Available, bugis, n...<br/>1                       [Ok, lar, Joking, wif, u, oni]<br/>2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...<br/>3        [U, dun, say, early, hor, U, c, already, say]<br/>4    [Nah, dont, think, goes, usf, lives, around, t...<br/>Name: messages, dtype: object</span></pre><h1 id="3b7e" class="mb ld iq bd le mc md me lh mf mg mh lk jw mi jx ln jz mj ka lq kc mk kd lt ml bi translated">…向量化…</h1><p id="658b" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">请注意，我们将消息作为令牌列表。因此，下一步是将这些消息转换成一个向量。</p><p id="b026" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，我们从Scikit Learn中使用<a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">计数矢量器</strong> </a>。CountVectorizer将文档集合转换为令牌计数数组。如果你想看Python中countvectorizer的例子，我们邀请你阅读下面这篇文章:<a class="ae lb" href="https://www.educative.io/edpresso/countvectorizer-in-python" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir"><em class="ma">Python中的count vector izer</em></strong></a></p><p id="50d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们从sklearn learn导入计数矢量器:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="8d8e" class="lc ld iq nd b gy nh ni l nj nk">from sklearn.feature_extraction.text import CountVectorizer</span></pre><p id="6a84" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CountVectorizer有很多参数，但是我们只使用“<strong class="kh ir"> analyzer </strong>”，这是我们自己之前定义的函数:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="fec0" class="lc ld iq nd b gy nh ni l nj nk">vectorization = CountVectorizer(analyzer = transform_message )</span><span id="33ce" class="lc ld iq nd b gy nl ni l nj nk">X = vectorization.fit(data['messages'])</span></pre><p id="4cc3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们应该将消息的整个数据帧转换成向量表示。为此，我们使用<strong class="kh ir">变换</strong>函数:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="baa6" class="lc ld iq nd b gy nh ni l nj nk">X_transform = X.transform([data['messages']])</span><span id="6f67" class="lc ld iq nd b gy nl ni l nj nk">print(X_transform)<br/>&gt;&gt;&gt; :	:<br/>  (0, 11383)	9<br/>  (0, 11384)	20<br/>  (0, 11385)	14<br/>  (0, 11386)	2<br/>  (0, 11387)	4<br/>  (0, 11391)	11<br/>  (0, 11393)	5<br/>  (0, 11396)	1<br/>  (0, 11397)	1<br/>  (0, 11398)	18<br/>  (0, 11399)	18<br/>  (0, 11405)	2<br/>  (0, 11408)	1<br/>  (0, 11410)	1<br/>  (0, 11411)	8<br/>  (0, 11412)	7<br/>  (0, 11413)	1<br/>  (0, 11414)	1<br/>  (0, 11415)	27<br/>  (0, 11417)	3<br/>  (0, 11418)	104<br/>  (0, 11420)	9<br/>  (0, 11422)	1<br/>  (0, 11423)	7<br/>  (0, 11424)	1<br/></span></pre></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h1 id="89ef" class="mb ld iq bd le mc mt me lh mf mu mh lk jw mv jx ln jz mw ka lq kc mx kd lt ml bi translated">TF-IDF</h1><p id="5692" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在对我们的数据应用“计数矢量器”之后，我们使用TF-IDF。你肯定想知道TD-FT是什么？我们为什么要使用它？让我给你解释一下:</p><p id="56ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> TF-IDF </strong> </a>是<strong class="kh ir"> <em class="ma">的缩写逆文档频率</em> </strong>是一个数值度量，表示一个词与集合中的一个文档的相关程度。</p><p id="e1b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TF-IDF的值与单词在文档中出现的次数成比例地增加，并且被该单词在文档集合中的频率抵消，这允许处理一些单词通常比其他单词更常见的事实。</p><h1 id="13cf" class="mb ld iq bd le mc md me lh mf mg mh lk jw mi jx ln jz mj ka lq kc mk kd lt ml bi translated"><strong class="ak">如何计算TF-IDF？</strong></h1><p id="7b58" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated"><strong class="kh ir"> TF-IDF </strong>由两项组成:第一项是<strong class="kh ir">项频率(TF) </strong>，第二项是<strong class="kh ir">逆文档频率(IDF)</strong></p><p id="66f2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">词频(TF): </strong>衡量一个词在文档中出现的频率，即一个词在文档中出现的次数除以该文档中的总字数:</p><p id="c1f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> TF(t) =(术语t在文档中出现的次数)/(文档中的总术语数)</strong></p><p id="5e69" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">逆文档频率(IDF): </strong>衡量一个术语的重要性，计算方法是语料库中文档数量的对数除以特定术语出现的文档数量。</p><p id="fa43" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> IDF(t) = log_e(文档总数/包含术语t的文档数)</strong></p><p id="9eda" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更多信息请参考<a class="ae lb" href="http://www.tfidf.com/#:~:text=TF(t)%20%3D%20(Number,terms%20are%20considered%20equally%20important.&amp;text=IDF(t)%20%3D%20log_e(,with%20term%20t%20in%20it)." rel="noopener ugc nofollow" target="_blank"><em class="ma"/><strong class="kh ir"><em class="ma">TF-IDF是什么意思？”</em>T34</strong></a></p><p id="710a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">继续我们的代码，我们从sk learn . feature _ extraction . text导入TfidfVectorizer，然后:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="4d97" class="lc ld iq nd b gy nh ni l nj nk">tfidf_transformer = TfidfTransformer().fit(X_transform)</span></pre><p id="7d40" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要一次将整个词袋语料库转换为TF-IDF语料库:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="d7cf" class="lc ld iq nd b gy nh ni l nj nk">X_tfidf = tfidf_transformer.transform(X_transform)<br/>print(X_tfidf.shape)</span><span id="aea9" class="lc ld iq nd b gy nl ni l nj nk">&gt;&gt;&gt; (5572, 11425)</span></pre><h1 id="8bc5" class="mb ld iq bd le mc md me lh mf mg mh lk jw mi jx ln jz mj ka lq kc mk kd lt ml bi translated">分类模型</h1><p id="fe08" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">将特征表示为向量，我们最终可以训练我们的垃圾邮件/垃圾邮件分类器。你可以使用任何分类算法。这里我们用<strong class="kh ir"> <em class="ma"> </em> </strong> <a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> <em class="ma">支持向量分类(SVC) </em> </strong> </a>算法。</p><p id="476e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们将数据分为训练数据和测试数据。我们采用80 % (0.80)的训练数据和30% (0.30)的测试数据，并使用SVC拟合模型:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="33ec" class="lc ld iq nd b gy nh ni l nj nk">X_train, X_test, y_train, y_test = train_test_split(X_tfidf, data['messages'], test_size=0.30, random_state = 50)    <br/>clf = SVC(kernel='linear').fit(X_train, y_train)</span></pre><h1 id="518d" class="mb ld iq bd le mc md me lh mf mg mh lk jw mi jx ln jz mj ka lq kc mk kd lt ml bi translated">试验模型</h1><p id="23e4" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">为了测试模型，我们使用之前计算的X_test:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="eaef" class="lc ld iq nd b gy nh ni l nj nk">predictions = clf.predict(X_test)<br/>print('predicted', predictions)</span><span id="b5db" class="lc ld iq nd b gy nl ni l nj nk">&gt;&gt;&gt; predicted ['spam' 'ham' 'ham' ... 'ham' 'ham' 'spam']</span></pre><h1 id="bc06" class="mb ld iq bd le mc md me lh mf mg mh lk jw mi jx ln jz mj ka lq kc mk kd lt ml bi translated">我们的模型可靠吗？</h1><p id="1915" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">出现的问题是:我们的模型在整个数据集上可靠吗？</p><p id="a19f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，我们可以使用SciKit Learn的内置分类报告，它返回<strong class="kh ir"> P </strong> <a class="ae lb" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> recision，Recall </strong> </a>，<a class="ae lb" href="https://en.wikipedia.org/wiki/F-score" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">F1-Score</strong></a><strong class="kh ir"/>以及<strong class="kh ir"> </strong> <a class="ae lb" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">混淆矩阵</strong> </a> <strong class="kh ir"> x </strong></p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="6f5c" class="lc ld iq nd b gy nh ni l nj nk">from sklearn.metrics import classification_report<br/>print (classification_report(y_test, predictions))</span></pre><figure class="my mz na nb gt nn gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oj"><img src="../Images/415849cd7a7cafcb63d49b12b4777cc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ym5sJ9rGtYKIcV1Nt-bKKQ.png"/></div></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">分类报告(图片由作者提供)</p></figure><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="121f" class="lc ld iq nd b gy nh ni l nj nk">from sklearn.metrics import confusion_matrix<br/>print(confusion_matrix(y_test,predictions))</span></pre><figure class="my mz na nb gt nn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/905cc9aa350e40dbd36dd545ecc00b91.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*KrExOegM0nLQgNuXCpX3fw.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">困惑矩阵(图片由作者提供)</p></figure><p id="bb6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">准确性是了解模型是否有效的好方法，但这不足以说明我们的模型是好的，为此我们使用了分类报告和混淆矩阵。你可以看到获得的结果相当好。</p><p id="1024" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们完了！！！希望这些信息对您有用。如果您对完整代码感兴趣，可以从下面的链接中获得:<a class="ae lb" href="https://github.com/patrycas/How-to-identify-Spam-using-Natural-Language-Processing-NLP-" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">如何使用NLP </strong> </a>识别垃圾邮件</p></div></div>    
</body>
</html>