<html>
<head>
<title>Why We Care About the Log Loss</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么我们关心日志丢失</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-we-care-about-the-log-loss-50c00c8e777c?source=collection_archive---------27-----------------------#2020-10-06">https://towardsdatascience.com/why-we-care-about-the-log-loss-50c00c8e777c?source=collection_archive---------27-----------------------#2020-10-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="33f4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Kaggle比赛中最常用的度量标准</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f27d8e57532e2c91db8aba3af4b3aaae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NKbZceeKpk2VJRp4MZsH0w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="8d9e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">机器学习管道中最关键的部分是性能评估。要了解模型的性能和缺点，需要一个强大而全面的评估过程。</p><p id="172c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于分类任务，日志丢失是最常用的指标之一。它也被称为交叉熵损失。如果您关注或参加Kaggle竞赛，您会发现原木损失是评估指标的主要选择。</p><p id="307f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本帖中，我们将看到是什么让日志丢失成为首选。在开始举例之前，让我们简要解释一下什么是日志损失。</p><p id="4eaf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对数损失(即交叉熵损失)通过比较实际类别标签和预测概率来评估性能。使用交叉熵来量化比较。</p><p id="9a39" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">交叉熵量化了两个概率分布的比较。在监督学习任务中，我们有一个目标变量，我们试图预测。使用交叉熵比较目标变量的实际分布和我们的预测。结果是交叉熵损失，也称为对数损失。</p><p id="47cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在计算对数损失时，我们取预测概率的自然对数的负值。我们对预测越有把握，测井损失就越低(假设预测是正确的)。</p><p id="47d9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，-log(0.9)等于0.10536，而-log(0.8)等于0.22314。因此，90%的把握比80%的把握会导致更低的测井损失。</p><p id="b369" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想进一步阅读，我在另一篇<a class="ae lu" rel="noopener" target="_blank" href="/all-the-way-from-information-theory-to-log-loss-in-machine-learning-c78488dade15">文章</a>中详细解释了熵、交叉熵和对数损失的概念。这篇文章更像是一个实践指南，展示了日志丢失如此重要的原因。</p><p id="6f28" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在分类任务中，模型通常为每个类别输出一个概率值。那么具有最高概率的类别被指定为预测类别。传统的度量标准，如分类准确度、精确度和召回率，通过比较预测类和实际类来评估性能。</p><p id="c38a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑下面的情况。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="c6c8" class="ma mb it lw b gy mc md l me mf">import numpy as np</span><span id="e84a" class="ma mb it lw b gy mg md l me mf">y_true = np.array([1,0,0,1,1])</span></pre><p id="f510" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是一个二元分类任务，有5个观察值标记为0或1。这是两个不同模型的输出。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="86ad" class="ma mb it lw b gy mc md l me mf">y_pred1 = np.array(<br/>[[0.2, 0.8],        #predict 1<br/>[0.6, 0.4],         #predict 0<br/>[0.7, 0.3],         #predict 0<br/>[0.65, 0.35],       #predict 0<br/>[0.25, 0.75]])      #predict 1</span><span id="1f87" class="ma mb it lw b gy mg md l me mf">y_pred2 = np.array(<br/>[[0.1, 0.9],        #predict 1<br/>[0.7, 0.3],         #predict 0<br/>[0.85, 0.15],       #predict 0<br/>[0.55, 0.45],       #predict 0<br/>[0.2, 0.8]])        #predict 1</span></pre><p id="6158" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然预测的概率不同，但是当选择具有最高概率的类别时，预测的类别是相同的。</p><p id="675d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，如果我们使用分类准确度来比较这两个模型，则两个模型的结果将是相同的。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2cb8" class="ma mb it lw b gy mc md l me mf">from sklearn.metrics import log_loss, accuracy_score</span><span id="e16e" class="ma mb it lw b gy mg md l me mf">y_pred1_classes = np.array([1,0,0,0,1])<br/>y_pred2_classes = np.array([1,0,0,0,1])</span><span id="ff04" class="ma mb it lw b gy mg md l me mf">accuracy_score(y_true, y_pred1_classes)<br/>0.8</span><span id="dde3" class="ma mb it lw b gy mg md l me mf">accuracy_score(y_true, y_pred2_classes)<br/>0.8</span></pre><p id="150f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">两个模型都正确地预测了5次观察中的4次，因此精确度为0.8。看起来这些模型的表现是一样的。这样想是错误的，因为预测的概率之间有很大的差异。</p><p id="60b7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们基于日志损失来比较它们。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="9074" class="ma mb it lw b gy mc md l me mf">log_loss(y_true, y_pred1)<br/>0.4856</span><span id="cb39" class="ma mb it lw b gy mg md l me mf">log_loss(y_true, y_pred2)<br/>0.3292</span></pre><p id="d26f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，差别很大。认为这两个模型表现相同是错误的。</p><p id="1e70" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果预测是正确的，则测井损失奖励在预测时更加确定。90%的对数损失小于80%的对数损失。</p><p id="92d2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一方面，如果预测是错误的，它也惩罚更高的概率。假设对于特定的观察，真实的类标签是1。两个模型预测结果为0，概率分别为0.65 (65%)和0.55 (55%)。0.65的对数损失高于0.55的对数损失。</p><p id="644d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑下面的场景。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/da2c2c32c3a79b715bc2acccd50e9082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*8d4qHOrLHdw0gqLAm_4eQA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="6b06" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所有预测的概率都是相同的，除了一个观察结果是唯一的错误预测。第二个模型更能确定错误的预测。让我们计算这种情况下的对数损失。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="e7e9" class="ma mb it lw b gy mc md l me mf">log_loss(y_true, y_pred1)<br/>0.4856</span><span id="17ac" class="ma mb it lw b gy mg md l me mf">log_loss(y_true, y_pred2)<br/>0.6550</span></pre><p id="7ca3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第二个模型的对数损失更高，因为错误预测的概率更高。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><p id="e698" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对数损失考虑了预测的概率。它不仅基于正确的预测来评估性能，而且根据预测的概率来惩罚错误的预测。</p><p id="1160" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是为什么log loss是一种稳健且全面的评估度量，并被广泛用于机器学习领域的原因。</p><p id="91d3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>