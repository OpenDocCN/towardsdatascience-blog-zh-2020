<html>
<head>
<title>Silhouette Method — Better than Elbow Method to find Optimal Clusters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">轮廓法——比肘法更好的寻找最优聚类的方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891?source=collection_archive---------0-----------------------#2020-10-18">https://towardsdatascience.com/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891?source=collection_archive---------0-----------------------#2020-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="65e6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">k-Means聚类中寻找最优聚类的剪影法深度分析</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/dfc6a8d3078d02f7ef3e01edbd624d30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*GsstWuZUuQDSBTwT3PYoGA.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://pixabay.com/users/mediamodifier-1567646/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3033203" rel="noopener ugc nofollow" target="_blank"> Mediamodifier </a>来自<a class="ae ku" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3033203" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="2d00" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi lr translated"><span class="l ls lt lu bm lv lw lx ly lz di"> H </span> <strong class="kx iu">超参数</strong>是定义模型的模型配置属性，在模型训练期间保持不变。可以通过调整超参数来改变模型的设计。对于K均值聚类，有3个主要的超参数需要设置，以定义模型的最佳配置:</p><ul class=""><li id="607e" class="ma mb it kx b ky kz lb lc le mc li md lm me lq mf mg mh mi bi translated">聚类的初始值</li><li id="a8fa" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">距离测量</li><li id="d3c1" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">聚类数</li></ul><p id="78b5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">聚类的初始值对聚类模型有很大的影响，有各种算法来初始化这些值。距离度量用于寻找到聚类中心的聚类中的点，不同的距离度量产生不同的聚类。</p><p id="8d5a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">聚类数(<strong class="kx iu"> k </strong>)是K-Means聚类中最重要的超参数。如果我们事先已经知道要将数据分组到的聚类数，那么就没有必要调整k的值。例如，对于MNIST数字分类数据集，k=10。</p><p id="d843" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果不知道k的最佳值，那么有各种方法可以找到k的最佳值。在本文中，我们将介绍两种这样的方法:</p><ul class=""><li id="6429" class="ma mb it kx b ky kz lb lc le mc li md lm me lq mf mg mh mi bi translated"><strong class="kx iu">肘法</strong></li><li id="d604" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated"><strong class="kx iu">剪影法</strong></li></ul><h1 id="558b" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">弯头方法:</h1><p id="7431" class="pw-post-body-paragraph kv kw it kx b ky ng ju la lb nh jx ld le ni lg lh li nj lk ll lm nk lo lp lq im bi translated"><strong class="kx iu">肘方法</strong>是一种为数据集寻找最佳聚类数的经验方法。在此方法中，我们选取一系列K的候选值，然后使用每个K值应用K均值聚类。找出聚类中每个点到其质心的平均距离，并在图中表示出来。选择k的值，此时<strong class="kx iu">平均距离突然下降</strong>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/d8569532cf5de47cc13d9a17d441a31c.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*VP1ilPn4SYoigi2vxMAQ6g.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(图片由作者提供)，肘法求最优k</p></figure><p id="1b25" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">随着聚类数(k)的增加，平均距离减小。要找到最佳聚类数(k ),请观察该图并找到距离急剧下降时的k值。这将是k的一个最佳点，在这里出现一个弯头。</p><p id="1eb2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在上图中，平均距离在<strong class="kx iu"> k=2、3和4 </strong>处急剧下降。这里出现了选择k的最佳值的困惑。在下图中，观察对于<strong class="kx iu"> k=2、3和4 </strong>形成的集群及其平均距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi no"><img src="../Images/435d0480345a4767b1587fd92c9a4752.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R0r2umHV83jFF97S8iSQCQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(图片由作者提供)，k=2、3和4时形成的簇的散点图</p></figure><p id="71bb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这个数据是2-D的，所以很容易可视化并挑选k的最佳值，即k=4。对于更高维的数据，我们可以使用<strong class="kx iu">剪影法</strong>来寻找最佳k，这是一种比肘法更好的<strong class="kx iu">替代方法。</strong></p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="773b" class="mo mp it bd mq mr oa mt mu mv ob mx my jz oc ka na kc od kd nc kf oe kg ne nf bi translated"><strong class="ak">剪影方法:</strong></h1><p id="cb12" class="pw-post-body-paragraph kv kw it kx b ky ng ju la lb nh jx ld le ni lg lh li nj lk ll lm nk lo lp lq im bi translated"><strong class="kx iu">剪影法</strong>也是一种寻找最佳聚类数以及解释和验证数据聚类一致性的方法。剪影方法计算每个点的剪影系数，该系数测量一个点与其自己的聚类相比与其他聚类相似的程度。通过提供一个<strong class="kx iu">简洁的图形表示</strong>来显示每个对象的分类情况。</p><blockquote class="of og oh"><p id="e357" class="kv kw oi kx b ky kz ju la lb lc jx ld oj lf lg lh ok lj lk ll ol ln lo lp lq im bi translated">计算每个点的<strong class="kx iu">轮廓系数</strong>，对所有样本进行平均，得到<strong class="kx iu">轮廓分数</strong>。</p></blockquote><p id="0308" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">剪影值是一个对象与其自己的聚类(<strong class="kx iu">内聚</strong>)相比与其他聚类(<strong class="kx iu">分离</strong>)相似程度的度量。轮廓值的范围在[1，-1]之间，其中高值表示对象与其自己的簇匹配良好，而与相邻簇匹配较差。如果大多数对象都有较高的值，那么集群配置是合适的。如果许多点具有低值或负值，则聚类配置可能具有太多或太少的聚类。</p><h2 id="fc88" class="om mp it bd mq on oo dn mu op oq dp my le or os na li ot ou nc lm ov ow ne ox bi translated">计算轮廓系数:</h2><p id="ff1a" class="pw-post-body-paragraph kv kw it kx b ky ng ju la lb nh jx ld le ni lg lh li nj lk ll lm nk lo lp lq im bi translated">求第I个点的轮廓系数的步骤:</p><ol class=""><li id="0e41" class="ma mb it kx b ky kz lb lc le mc li md lm me lq oy mg mh mi bi translated">计算a(i):该点与同一聚类中所有其他点的平均距离。</li><li id="4f28" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq oy mg mh mi bi translated">Compute b(i):该点与离其聚类最近的聚类中所有点的平均距离。</li><li id="fe03" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq oy mg mh mi bi translated">使用下述公式计算s(I)-轮廓系数或第I点。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/86150221ee1a4058a8d55fdaede1453e.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*fOlkxm7NXLSopIA02flxng.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/f1ac4db97d36e86f4f68a32fc2fcf4e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*cNzzMupO355ohnVqXnvxEA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(图片由作者提供)，a(i)和b(i)的图解表示，根据上述公式计算轮廓系数— s(i)</p></figure><p id="3ae5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">计算出每个点的轮廓系数后，将其平均以获得轮廓分数。</p><h1 id="09e6" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">轮廓分析:</h1><p id="a2b5" class="pw-post-body-paragraph kv kw it kx b ky ng ju la lb nh jx ld le ni lg lh li nj lk ll lm nk lo lp lq im bi translated">轮廓是对聚类算法执行情况的一种度量。在计算了数据集中每个点的轮廓系数之后，绘制它以获得数据集被聚类到k个聚类中的程度的可视化表示。轮廓图显示了一个聚类中的每个点与相邻聚类中的点的接近程度，从而提供了一种视觉评估聚类数量等参数的方法。这个度量的范围是[-1，1]。</p><pre class="kj kk kl km gt pb pc pd pe aw pf bi"><span id="5ba6" class="om mp it pc b gy pg ph l pi pj"><strong class="pc iu">Important Points:<br/>The Silhouette coefficient of +1</strong> indicates that the sample is far away from the neighboring clusters.<br/><strong class="pc iu">The Silhouette </strong>coefficient <strong class="pc iu">of 0</strong> indicates that the sample is on or very close to the decision boundary between two neighboring clusters.<br/><strong class="pc iu">Silhouette </strong>coefficient <strong class="pc iu">&lt;0</strong> indicates that those samples might have been assigned to the wrong cluster or are outliers.</span></pre><h2 id="af21" class="om mp it bd mq on oo dn mu op oq dp my le or os na li ot ou nc lm ov ow ne ox bi translated">使用轮廓分析找到“k”的最佳值:</h2><p id="19e6" class="pw-post-body-paragraph kv kw it kx b ky ng ju la lb nh jx ld le ni lg lh li nj lk ll lm nk lo lp lq im bi translated">与之前的Elbow方法类似，我们选取K(聚类数)的一系列候选值，然后为每个K值训练K均值聚类。对于每个K均值聚类模型，在图中表示轮廓系数，并观察每个聚类的波动和异常值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/5e80293263dfa8af9ba5333be5b512a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*FDahPZQHWMxaZSSf369NHA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(图片由作者提供)，Silhoutte得分与聚类数</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi pl"><img src="../Images/f29e1cd3c978d8808d455dc1a6bcebad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yZjgg9p_FmZh-NIoR1yI5Q.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(图片由作者提供)，KMeans中每个聚类的轮廓分析和散点图，使用n_cluster=[2，3，4，5，6]对整个数据进行聚类</p></figure><h2 id="8c49" class="om mp it bd mq on oo dn mu op oq dp my le or os na li ot ou nc lm ov ow ne ox bi translated">从上面的轮廓图观察:</h2><ul class=""><li id="1e2e" class="ma mb it kx b ky ng lb nh le pm li pn lm po lq mf mg mh mi bi translated">轮廓图显示了<strong class="kx iu"> 3 </strong>的n_cluster值是一个糟糕的选择，因为cluster_label=0的聚类中的所有点都低于平均轮廓分数。</li><li id="908b" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">轮廓图显示<strong class="kx iu"> 5 </strong>的n_cluster值是一个糟糕的选择，因为cluster_label=2和4的聚类中的所有点都是低于平均的轮廓分数。</li><li id="4637" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">剪影图显示了<strong class="kx iu"> 6 </strong>的n_cluster值是一个不好的选择，因为cluster_label=1、2、4和5的群集中的所有点都是低于平均的剪影分数，并且还由于异常值的存在。</li><li id="8322" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">剪影分析在决定2和4之间更加矛盾。</li><li id="8631" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">当n_clusters=2时，cluster_label=1的聚类的轮廓图的厚度在尺寸上更大，这是由于将3个子聚类分组为一个大聚类。</li><li id="ee1a" class="ma mb it kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">对于n_clusters=4，所有曲线或多或少具有相似的厚度，因此具有相似的大小，这可以被认为是<strong class="kx iu">最佳“k”。</strong></li></ul></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="1f23" class="mo mp it bd mq mr oa mt mu mv ob mx my jz oc ka na kc od kd nc kf oe kg ne nf bi translated">实施:</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">代码<a class="ae ku" href="https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py" rel="noopener ugc nofollow" target="_blank">来源</a>，作者编辑</p></figure></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="df6b" class="mo mp it bd mq mr oa mt mu mv ob mx my jz oc ka na kc od kd nc kf oe kg ne nf bi translated">结论:</h1><p id="fd7d" class="pw-post-body-paragraph kv kw it kx b ky ng ju la lb nh jx ld le ni lg lh li nj lk ll lm nk lo lp lq im bi translated">肘和剪影方法用于寻找最佳数量的集群。对于选取k值的肘方法，会出现不确定性。侧影分析可用于研究所得聚类之间的分离距离，并且与肘方法相比，被认为是更好的方法。</p><p id="dcb5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">剪影分析</strong>还增加了<strong class="kx iu">优势</strong>以发现<strong class="kx iu">异常值(如果存在于聚类</strong>)。</p><h1 id="3f85" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">参考资料:</h1><p id="ee0b" class="pw-post-body-paragraph kv kw it kx b ky ng ju la lb nh jx ld le ni lg lh li nj lk ll lm nk lo lp lq im bi translated">[1]维基百科:<a class="ae ku" href="https://en.wikipedia.org/wiki/Silhouette_(clustering)#:~:text=The%20silhouette%20value%20is%20a,poorly%20matched%20to%20neighboring%20clusters" rel="noopener ugc nofollow" target="_blank">剪影(聚类)</a>，(2020年9月14日)</p><p id="39f5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">[2] Scikit学习文档:<a class="ae ku" href="https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py" rel="noopener ugc nofollow" target="_blank">选择对KMeans聚类进行轮廓分析的聚类数</a></p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><p id="6959" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">喜欢这篇文章吗？成为 <a class="ae ku" href="https://satyam-kumar.medium.com/membership" rel="noopener"> <em class="oi">中等会员</em> </a> <em class="oi">继续无限制学习。如果你使用下面的链接，我会收到你的一小部分会员费，不需要你额外付费。</em></p><div class="pp pq gp gr pr ps"><a href="https://satyam-kumar.medium.com/membership" rel="noopener follow" target="_blank"><div class="pt ab fo"><div class="pu ab pv cl cj pw"><h2 class="bd iu gy z fp px fr fs py fu fw is bi translated">加入我的推荐链接-萨蒂扬库马尔媒体</h2><div class="pz l"><h3 class="bd b gy z fp px fr fs py fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="qa l"><p class="bd b dl z fp px fr fs py fu fw dk translated">satyam-kumar.medium.com</p></div></div><div class="qb l"><div class="qc l qd qe qf qb qg ko ps"/></div></div></a></div><blockquote class="qh"><p id="5541" class="qi qj it bd qk ql qm qn qo qp qq lq dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>