<html>
<head>
<title>Lego Minifigure Gender Classification Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的乐高迷你人物性别分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lego-minifigure-gender-classification-using-deep-learning-2358f4082842?source=collection_archive---------68-----------------------#2020-10-12">https://towardsdatascience.com/lego-minifigure-gender-classification-using-deep-learning-2358f4082842?source=collection_archive---------68-----------------------#2020-10-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="57be" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="8393" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">与CNN的和转移学习</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/65572f06d5b3b513b2532578e0687e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qY6fT0mVvy44-StO"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@jamesponddotco?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">詹姆斯·庞德</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="d15a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通过我在<a class="ae le" rel="noopener" target="_blank" href="/how-i-learned-deep-learning-in-9-months-f5ddaefd3e3b"> Udacity的深度学习纳米学位</a>的卷积神经网络(CNN)部分的工作旅程，我决定从事我自己的项目，看看CNN是否能够对乐高迷你人物的性别进行分类。</p><p id="6168" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我决定这样做的原因是因为我是一个乐高迷，多年来一直在收集迷你玩具。我想我现在有超过200个小家伙，大部分是从<a class="ae le" href="https://www.lego.com/en-ca/product/series-20-71027" rel="noopener ugc nofollow" target="_blank">盲袋</a>中获得的。</p><p id="d4dc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">哦，我还拍了他们的照片，分享到Instagram上！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mb"><img src="../Images/4f591bc11728ddcc6f8ac03e4c3ae2f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*obnvYXbQ2j92tmNCrxFTxA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Instagram: @Let_It_Lego</p></figure><h1 id="1a3d" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">为什么要用迁移学习？</h1><p id="1e72" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">迁移学习是指使用预先训练好的神经网络，并将其用于不同的数据集。</p><p id="94cf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于我有一个小数据集，我想利用<a class="ae le" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet的</a>预训练图像，因为它有许多人和衣服的照片，所以应该更容易确定迷你人物的特征。由于人体特征和迷你人物服装的相似性，我会将我的数据集归类为与ImageNet中的相似。</p><p id="5822" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">根据Udacity的说法，如果新数据集很小，并且与原始训练数据相似，则必须按如下方式更改神经网络:</p><ul class=""><li id="b3a7" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">切掉神经网络的末端</li><li id="ad7f" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">添加与新数据集中的类数量相匹配的新完全连接图层</li><li id="cab8" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">随机化新的全连接层的权重；冻结预训练网络的所有权重(以避免过度拟合)</li><li id="54ab" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">训练网络以更新新的全连接层的权重</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/0c739ddb6df9719c59d67db477fe6bbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j9gm6-6Cm796k2V1BcuNcQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">在神经网络的末端添加并训练全连接层。资料来源:Udacity</p></figure><p id="775f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您将在后面的代码中看到我是如何做到这一点的。</p><h1 id="6d86" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">收集数据</h1><p id="4469" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">我给我自己的迷你人像拍了照片来组成数据集。由于我只有有限的数量(超过200张)，我从不同的角度拍摄了每个迷你人像的照片，以便为数据集获取更多的照片。</p><div class="kp kq kr ks gt ab cb"><figure class="no kt np nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/a095b4b271086e59fa6e838de049c17f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*AAvIZOhQNcP0SB0ULLWJeg.jpeg"/></div></figure><figure class="no kt np nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/49f4527196bb113d174e66e20f830ac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*D_zAF0SVvFZzepCCYmuOGA.jpeg"/></div></figure></div><div class="ab cb"><figure class="no kt np nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/12e64da3b6503926d15090419d9eada7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Ka7VHEuwG35ADp0ejU5wYg.jpeg"/></div></figure><figure class="no kt np nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/0b9e4ba302fdf998a1099dfdf17e9e2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Q0WhaiV-q5KLxgHTKTNmMA.jpeg"/></div></figure></div><p id="95dd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了确保CNN不会接触到不容易区分男性和女性的物品，我确保脱下了迷你人佩戴的任何配饰，比如这些:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/837480ddcb3ba5e94bf1c23f2a830464.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*haEMuS9lKBXdsZl3TgLpyA.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">斗篷，服装，怪异的帽子，等等。</p></figure><p id="fb68" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我也没有包括像这些人一样不是人类的迷你人:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nv"><img src="../Images/50820a6acb10c70f4ac3478c7cc9a52e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l9ajBMLHwJekt4fstCbgfg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">海绵宝宝！</p></figure><p id="dcc4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，我的数据集看起来像这样:</p><div class="kp kq kr ks gt ab cb"><figure class="no kt nw nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/c280d3d70adc7fb09e299dedc8f2cbc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*aG4ESP22ibj_eXbsjo4v-w.png"/></div></figure><figure class="no kt nx nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/3c318f102a5662353fc5096628f009f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*_nZZcr3sePpQggloUpACdg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk ny di nz oa translated">照片数据集的片段。</p></figure></div><h1 id="e930" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">代码</h1><p id="968d" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">我首先在库中加载:</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="8804" class="og md iq oc b gy oh oi l oj ok">%matplotlib inline<br/>%config InlineBackend.figure_format = 'retina'</span><span id="611e" class="og md iq oc b gy ol oi l oj ok">import matplotlib.pyplot as plt<br/>import numpy as np<br/>import torch<br/>from torch import nn<br/>from torch import optim<br/>import torch.nn.functional as F<br/>from torchvision import datasets, transforms, models</span></pre><p id="565b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">并检查了Cuda是否可用，以便我可以利用谷歌Colab的GPU。</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="3a5b" class="og md iq oc b gy oh oi l oj ok">train_on_gpu = torch.cuda.is_available()</span><span id="925b" class="og md iq oc b gy ol oi l oj ok">if not train_on_gpu:<br/>    print('CUDA is not available.  Training on CPU ...')<br/>else:<br/>    print('CUDA is available!  Training on GPU ...')</span></pre><h1 id="6de1" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">加载和转换数据集</h1><p id="90eb" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">我将完成的数据集作为zip文件保存到Dropbox中，其中的内容被拆分到一个Train/Test文件夹中，另一个Boy/Girl文件夹位于其中。</p><div class="kp kq kr ks gt ab cb"><figure class="no kt om nq nr ns nt paragraph-image"><img src="../Images/6b1ac4c0791afd0d7c0e415ffd955ea2.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*pfScIotwLB_Rk7UpDrL6-g.png"/></figure><figure class="no kt on nq nr ns nt paragraph-image"><img src="../Images/6af6ae93518426ad9900065b365fff69.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*y5nvy08e4UW8iXPvSlIvYQ.png"/></figure></div><p id="a485" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后我生成了一个下载链接，这样我就可以使用<code class="fe oo op oq oc b">!wget</code>和<code class="fe oo op oq oc b">!unzip</code>将图片加载到Google Colab中。</p><p id="b4c6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于我拍摄的图像尺寸很大，我需要对它们进行转换，以便输入数据可以与预先训练的模型所期望的(在我的例子中，是VGG16)一起工作。我还使用了PyTorch的ImageFolder类，以便能够从我在zip文件中创建的train和test文件夹中加载数据。</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="5fb9" class="og md iq oc b gy oh oi l oj ok">data_dir = 'Lego (compressed pics)'</span><span id="66a0" class="og md iq oc b gy ol oi l oj ok"># VGG-16 Takes 224x224 images as input, so we resize all of them<br/>data_transform = transforms.Compose([transforms.Resize((224, 224)),<br/>                                     transforms.ToTensor()])</span><span id="a968" class="og md iq oc b gy ol oi l oj ok">train_data = datasets.ImageFolder(data_dir + '/Train',              <br/>transform=data_transform)</span><span id="e79b" class="og md iq oc b gy ol oi l oj ok">test_data = datasets.ImageFolder(data_dir + '/Test',             <br/>transform=data_transform)</span></pre><p id="aaab" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这里你可以看到我是如何将照片分配到一个训练和测试集的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/c9c293cd2b261c6917cabd2d0dd9c267.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*8HRx6pcpeMkeSx8WXDp5ug.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">训练和测试图像的数量。</p></figure><p id="4df3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为训练和测试数据集创建数据加载器:</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="081c" class="og md iq oc b gy oh oi l oj ok"># how many samples per batch to load<br/>batch_size = 20</span><span id="9f35" class="og md iq oc b gy ol oi l oj ok"># number of subprocesses to use for data loading<br/>num_workers = 0</span><span id="cd94" class="og md iq oc b gy ol oi l oj ok">train_loader = torch.utils.data.DataLoader(train_data, <br/>batch_size=batch_size, num_workers=num_workers, shuffle=True)</span><span id="6e2a" class="og md iq oc b gy ol oi l oj ok">test_loader = torch.utils.data.DataLoader(test_data, <br/>batch_size=batch_size, num_workers=num_workers, shuffle=True)</span><span id="4fff" class="og md iq oc b gy ol oi l oj ok"># specify the image classes<br/>classes = ['Boy', 'Girl']</span></pre><p id="292a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在我们来可视化一批训练数据。</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="2129" class="og md iq oc b gy oh oi l oj ok"># obtain one batch of training images<br/>dataiter = iter(train_loader)<br/>images, labels = dataiter.next()<br/>images = images.numpy()  # convert images to numpy for display</span><span id="c99b" class="og md iq oc b gy ol oi l oj ok"># plot the images in the batch, along with the corresponding labels<br/>fig = plt.figure(figsize=(25,4))<br/>for idx in np.arange(20):<br/>  ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])   <br/>  plt.imshow(np.transpose(images[idx], (1, 2, 0)))   <br/>  ax.set_title(classes[labels[idx]])</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi os"><img src="../Images/d3927463d6129b3ed6ee0ea30399b41f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NwwbKdaU4BFY7gQbiSAyzQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">可视化一批训练数据。</p></figure><h1 id="3642" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">定义模型</h1><p id="1ed1" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">这将通过加载预训练的VGG16模型来实现。</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="2cde" class="og md iq oc b gy oh oi l oj ok"># Load the pretrained model from PyTorch<br/>vgg16 = models.vgg16(pretrained=True)</span><span id="e34e" class="og md iq oc b gy ol oi l oj ok"># Freeze training for all feature layers so the model doesn't change # the parameters it was pre-trained on<br/>for param in vgg16.features.parameters(): <br/>    param.requires_grad = False</span></pre><p id="f52c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如前所述，预训练模型的分类器不符合我们试图实现的目标，因为它的最后一层输出1000个特征，而我们只需要2个(因为我们只有男孩和女孩两个类)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/63e5a822e78bde09f1b778172c427c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*ibFMBhjW-0UoxBwK5fUSlA.png"/></div></figure><p id="a4de" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所以我们需要去掉最后一层，用我们自己的线性分类器代替它。</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="a1f2" class="og md iq oc b gy oh oi l oj ok">n_inputs = vgg16.classifier[6].in_features<br/>last_layer = nn.Linear(n_inputs, len(classes))</span><span id="ab3b" class="og md iq oc b gy ol oi l oj ok">vgg16.classifier[6] = last_layer</span><span id="c6be" class="og md iq oc b gy ol oi l oj ok">if train_on_gpu:<br/>    vgg16.cuda()</span></pre><p id="2b4e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在分类器就是我们想要的了！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/2324a7cc8218fc1c996601286fc0a84f.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*EPTsHe2gb_CtOb2jD7OQgQ.png"/></div></figure><p id="d7fd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">指定损失函数和优化器。</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="fb9c" class="og md iq oc b gy oh oi l oj ok">criterion = nn.CrossEntropyLoss()<br/>optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)</span></pre><h1 id="014b" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">训练网络</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ov"><img src="../Images/3e8f3dcc4262e87e6b230bebbe65491e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_tAcB0H2Hjfogz3wZsiOQg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">训练网络。</p></figure><h1 id="8fc2" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">测试</h1><p id="bc48" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">下面，您可以看到通过对以前看不到的数据测试训练模型来确定每个性别类别的准确性。换句话说，我们使用训练好的模型来预测迷你人的性别，并将其与实际性别(目标)进行比较。</p><div class="kp kq kr ks gt ab cb"><figure class="no kt ow nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/a4f55ca41392c0bdb1eb6c54063e269b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*GamUAXZtyk2ELZp-BUnGlw.png"/></div></figure><figure class="no kt ox nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/49ecb63b4a14952f3d86f542344cbe0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*YD5Zbe3Tf5UQOpO0ESb8uw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk oy di oz oa translated">确定测试精度。</p></figure></div><h1 id="52d3" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">可视化测试结果</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pa"><img src="../Images/edf653a6b6ca0a70e72ea7fc2b09cc84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EcsLCf6iOCPzHEypKUhcCA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">可视化样本的测试结果。</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi os"><img src="../Images/8ef139a2a9698a3a9a1760902a5604f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-oUQPr_jmNJk78POfkWSAw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">样本结果！</p></figure><h1 id="a748" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">结论</h1><p id="b3ca" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">结果似乎相当不错！在测试的20幅样本图像中，只有一幅预测了错误的性别。请记住，我只使用了一个小数据集，所以如果我有一个更大的数据集，结果可能会改变。</p><p id="491f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你有兴趣更详细地阅读我的代码，请访问下面我的Github。</p><div class="pb pc gp gr pd pe"><a href="https://github.com/oscarkwok/Lego-Gender/blob/main/Classifying_Lego_Minifigure_Gender.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">oscarkwok/乐高-性别</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">GitHub是超过5000万开发者的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">github.com</p></div></div><div class="pn l"><div class="po l pp pq pr pn ps ky pe"/></div></div></a></div><p id="a533" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是一个有趣的项目，我能够应用我从Udactiy的深度学习纳米学位中学到的东西。随着课程的进展，我希望能写更多关于我的项目，敬请关注！</p><p id="6275" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果您有任何问题或意见，请在下面留下您的反馈。你也可以在<a class="ae le" href="https://www.linkedin.com/in/oscarkwok/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上关注我，或者在这里与我<a class="ae le" href="https://linktr.ee/oscarkwok" rel="noopener ugc nofollow" target="_blank">联系。</a></p></div></div>    
</body>
</html>