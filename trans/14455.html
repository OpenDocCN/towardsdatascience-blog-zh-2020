<html>
<head>
<title>Convolutional Neural Network Champions — Part 2: AlexNet (TensorFlow 2.x)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络冠军第2部分:AlexNet (TensorFlow 2.x)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-network-champions-part-2-alexnet-tensorflow-2-x-de7e0076f3ff?source=collection_archive---------34-----------------------#2020-10-05">https://towardsdatascience.com/convolutional-neural-network-champions-part-2-alexnet-tensorflow-2-x-de7e0076f3ff?source=collection_archive---------34-----------------------#2020-10-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d5e0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">关于最流行的卷积神经网络(CNN)架构的多部分系列的第2部分，包含可复制的Python笔记本</h2></div><p id="88dc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">卷积神经网络是一种特殊类型的神经网络，用于对具有强空间相关性的数据进行建模，例如图像、多元时间序列、地球科学研究(地震分类和回归)以及许多其他应用。自1998年以来，卷积网络经历了重大变化，在这一系列文章中，我的目标是再现著名的模型架构冠军，如LeNet、AlexNet、ResNet等。我的目标是与更广泛的受众分享我的发现和研究，并提供可复制的Python笔记本。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/b5760fe678e7604f452b6cc2c12110cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gQVfaBQsfNROWm-lnlRVng.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">信用:<a class="ae lr" href="https://unsplash.com/@cbarbalis" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@cbarbalis</a></p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="a287" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第一部分:</strong>tensor flow中的Lenet-5和MNIST分类:</p><div class="lz ma gp gr mb mc"><a rel="noopener follow" target="_blank" href="/convolutional-neural-network-champions-part-1-lenet-5-7a8d6eb98df6"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ir gy z fp mh fr fs mi fu fw ip bi translated">卷积神经网络冠军第1部分:LeNet-5</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">关于最流行的卷积神经网络(CNN)架构的多部分系列，具有可再现的Python…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq ll mc"/></div></div></a></div><p id="2b06" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第三部分</strong>:ImageNet和Tensorflow上的VGGnet分类；</p><div class="lz ma gp gr mb mc"><a rel="noopener follow" target="_blank" href="/convolutional-neural-network-champions-part-3-vggnet-tensorflow-2-x-ddad77492d96"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ir gy z fp mh fr fs mi fu fw ip bi translated">卷积神经网络冠军第3部分:VGGNet (TensorFlow 2.x)</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">这个多部分系列的第3部分介绍了最流行的卷积神经网络(CNN)架构，包括…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="mr l mn mo mp ml mq ll mc"/></div></div></a></div></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><blockquote class="ms mt mu"><p id="8d08" class="kf kg mv kh b ki kj jr kk kl km ju kn mw kp kq kr mx kt ku kv my kx ky kz la ij bi translated">用于这项研究的Python笔记本位于我的<a class="ae lr" href="https://github.com/anejad/Convolutional-Neural-Network-Champions/tree/master/AlexNet" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> Github </strong> </a>页面中。</p><p id="f721" class="kf kg mv kh b ki kj jr kk kl km ju kn mw kp kq kr mx kt ku kv my kx ky kz la ij bi translated">本研究中使用的Tensorflow版本为2.3。</p></blockquote></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="1186" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">LeNet-5模型展示了阅读和分类手写数字的卓越能力。尽管LeNet-5网络结构在MNIST数据集上表现良好，但对CIFAR-10等更复杂图像进行分类的实际测试表明，该模型学习如此复杂模式的能力太低。因此，更强大的架构的开发进入了休眠状态，直到2012年AlexNet诞生。AlexNet被认为是第一个深度CNN模型，由Krizhevesky等人提出。在此期间，有几项发展抑制了神经网络分类准确性的提高，即:</p><ol class=""><li id="c8b4" class="mz na iq kh b ki kj kl km ko nb ks nc kw nd la ne nf ng nh bi translated"><strong class="kh ir"> Max pooling </strong> : Pooling层用于降低神经网络模型对图像中特征位置的敏感性。在最初的LeNet-5模型中，使用了平均池层。然而，Ranzato等人[2007]通过使用最大池层学习不变特征展示了良好的结果。最大池化图层会歧视激活函数不太重要的要素，并且仅选择最高值。这样，只有最重要的特性才会通过池层提供。更多信息请参考本系列的第1部分(<a class="ae lr" rel="noopener" target="_blank" href="/convolutional-neural-network-champions-part-1-lenet-5-7a8d6eb98df6">链接</a>)。</li><li id="3243" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated"><strong class="kh ir"> GPU/CUDA编程</strong>:在神经网络的早期发展中，模型训练过程中的一个主要瓶颈是计算机的计算能力，因为它们主要使用CPU来训练模型。2007年，NVIDIA公司推出了CUDA(计算统一设备架构)编程平台，以促进GPU(图形处理单元)上的并行处理。CUDA支持在GPU上进行模型训练，与CPU相比，训练时间要短得多。因此，培训更大的网络成为可能。</li><li id="3670" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated"><strong class="kh ir"> ReLU激活函数</strong> : Nair和hint on【2010】展示了修正线性单元(ReLU)提高受限玻尔兹曼机器分类精度的能力。ReLU单元只是让任何大于零的值通过过滤器，并抑制任何小于零的值。ReLU函数是不饱和的，这意味着当输入增加时函数的极限接近无穷大，因此它可以缓解消失梯度问题。</li><li id="7fd3" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated">ImageNet:深度学习领域取得成功的另一个催化剂是费-李非教授的团队在斯坦福大学建立的ImageNet数据库。ImageNet包含来自数千个类别的数百万张带注释的图像。一年一度的ImageNet大规模视觉识别挑战赛(ILSVRC)见证了包括AlexNet在内的卷积神经网络结构的许多进步。训练数据是2012年发布的ImageNet的子集，具有属于1，000个类的120万个图像。验证数据集由属于1，000个类的50，000个图像组成(每个类50个图像)。在下面的示例中可以看到ImageNet图像的示例:</li></ol><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/e5656898a1c12946b348669518a90e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*wAd1pRUgU4Ruwnee3epctw.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">ImageNet图片示例(l .飞飞,《ImageNet:众包、基准和其他很酷的东西》, CMU·VASC研讨会，2010年3月)</p></figure><p id="4086" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mv">下载资料注意事项:ImageNet官网(</em> <a class="ae lr" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> <em class="mv">链接</em> </a> <em class="mv">)可向个人提供图片。但是，提交请求后，我没有收到任何下载链接。下载图像最简单的方法是通过ImageNet对象本地化挑战(</em> <a class="ae lr" href="https://www.kaggle.com/c/imagenet-object-localization-challenge/" rel="noopener ugc nofollow" target="_blank"> <em class="mv">链接</em> </a> <em class="mv">)。</em></p><h1 id="8ee5" class="no np iq bd nq nr ns nt nu nv nw nx ny jw nz jx oa jz ob ka oc kc od kd oe of bi translated">AlexNet模型结构</h1><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi og"><img src="../Images/f3c04873e1517e47d98928e3b60b70ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Qr0kCBpebh5fpyZK9by6Q.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">克里日夫斯基、亚历克斯、伊利亚·苏茨基弗和杰弗里·e·辛顿。"使用深度卷积神经网络的图像网络分类."神经信息处理系统进展。2012.</p></figure><p id="3e38" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">AlexNet在ILSVRC-2012比赛中取得了15.3%的前5名测试错误率(之前的模型错误率为26%)的胜利。网络架构类似于LeNet-5模型(阅读更多关于LeNet-5: <a class="ae lr" rel="noopener" target="_blank" href="/convolutional-neural-network-champions-part-1-lenet-5-7a8d6eb98df6"> Link </a>的内容)，但具有更多卷积层，因此模型更深入。</p><p id="3ab9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">模型中使用的主要激活函数是非饱和整流线性单元(ReLU)函数。该模型主要由8层组成:5个卷积层和3个密集层。内核大小从11×11减小到3×3。每个卷积层后面都有一个最大池层。该模型在前两个完全连接的层中使用dropout以避免过度拟合。下面给出了AlexNet在Tensorflow中的实现。</p><p id="e38f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用随机梯度下降(SGD)优化算法训练该模型。学习率初始化为0.01，动量为0.9，权重衰减为0.0005。在Tensorflow中构建AlexNet模型的代码片段如下所示:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="3e58" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，模型中使用的优化器是带动量的梯度下降。这个优化器位于一个名为<code class="fe oj ok ol om b">tensorflow_addons</code>的独立包中(更多信息可以在<a class="ae lr" href="https://www.tensorflow.org/addons" rel="noopener ugc nofollow" target="_blank">这里</a>看到)。</p><h1 id="a192" class="no np iq bd nq nr ns nt nu nv nw nx ny jw nz jx oa jz ob ka oc kc od kd oe of bi translated">2节课的AlexNet演示</h1><p id="edc9" class="pw-post-body-paragraph kf kg iq kh b ki on jr kk kl oo ju kn ko op kq kr ks oq ku kv kw or ky kz la ij bi translated">在整个ImageNet数据集上训练AlexNet非常耗时，并且需要GPU计算能力。因此，在本节中，我将在ImageNet数据集上演示AlexNet类型结构的训练，该数据集由两个类组成:</p><ul class=""><li id="2d4b" class="mz na iq kh b ki kj kl km ko nb ks nc kw nd la os nf ng nh bi translated">类别<code class="fe oj ok ol om b"><em class="mv">n03792782</em></code>:山地车、全地形车、越野车</li><li id="f09b" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la os nf ng nh bi translated"><code class="fe oj ok ol om b"><em class="mv">n03095699</em></code>级:集装箱船，集装箱船</li></ul><p id="f21c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练数据集由属于两类的2，600幅图像组成。调用<code class="fe oj ok ol om b">AlexNet </code>函数会产生一个超过6200万可训练参数的网络，如下图所示:</p><pre class="lc ld le lf gt ot om ou ov aw ow bi"><span id="10cc" class="ox np iq om b gy oy oz l pa pb">Model: "AlexNet"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d (Conv2D)              (None, 55, 55, 96)        34944     <br/>_________________________________________________________________<br/>max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         <br/>_________________________________________________________________<br/>conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    <br/>_________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    <br/>_________________________________________________________________<br/>conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   <br/>_________________________________________________________________<br/>conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    <br/>_________________________________________________________________<br/>max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         <br/>_________________________________________________________________<br/>flatten (Flatten)            (None, 9216)              0         <br/>_________________________________________________________________<br/>dense (Dense)                (None, 4096)              37752832  <br/>_________________________________________________________________<br/>dropout (Dropout)            (None, 4096)              0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 4096)              16781312  <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 4096)              0         <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 1000)              4097000   <br/>_________________________________________________________________<br/>dense_3 (Dense)              (None, 2)                 2002      <br/>=================================================================<br/>Total params: 62,380,346<br/>Trainable params: 62,380,346<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><h1 id="3072" class="no np iq bd nq nr ns nt nu nv nw nx ny jw nz jx oa jz ob ka oc kc od kd oe of bi translated">模型训练和评估</h1><p id="97ee" class="pw-post-body-paragraph kf kg iq kh b ki on jr kk kl oo ju kn ko op kq kr ks oq ku kv kw or ky kz la ij bi translated">AlexNet模型在整个训练数据上训练90个时期，并在来自验证数据集的50K个图像上验证。CPU上的训练模型示例如下所示(要在GPU上训练，使用<code class="fe oj ok ol om b">tf.distribute.MirroredStrategy</code>):</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="016f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">经过充分训练的AlexNet模型在2个类上可以达到95%的准确率。下图显示了学习曲线以及训练集和验证集的损失。可以看出，验证集上的训练损失在20个时期后保持不变，并且模型学习不能被改进。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pc"><img src="../Images/7e41d64a23d766f99018cc972e77ff31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WNFRnKcZoM0tee2Ux1Tv_Q.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">学习曲线(作者图片)</p></figure><p id="fdd6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">评估模型性能的另一种方法是使用一种叫做<strong class="kh ir">混淆矩阵</strong>的方法。混淆矩阵是表格布局，由数据类别和使用训练好的分类器得到的预测组成。这里可以看到一个混淆矩阵的例子。这个混淆矩阵是通过在100个验证图像(每个类别50个图像)上运行训练好的神经网络分类器而获得的。可以看出，该模型在bikes类别中只错误分类了1个图像(用0表示)。然而，该模型将3幅图像错误分类到船只类别(用1表示)。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/8af3252b88c0bc5ef9a406137b2c4b64.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*ColAXyt3q68smTnK102L5w.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">困惑矩阵(图片由作者提供)</p></figure><p id="7fbb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">4个错误分类的图像如下图所示。在以下情况下，模型似乎无法完全识别图像中的对象:</p><ul class=""><li id="b456" class="mz na iq kh b ki kj kl km ko nb ks nc kw nd la os nf ng nh bi translated">图像中的对象被裁剪(部分可见的对象)</li><li id="7ca5" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la os nf ng nh bi translated">对象在背景中或被周围环境覆盖</li></ul><div class="lc ld le lf gt ab cb"><figure class="pe lg pf pg ph pi pj paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/6854b37fcb5fee767a93a52fa3b18b8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*53e5KNKTcPaUD2BlodPuRw.png"/></div></figure><figure class="pe lg pk pg ph pi pj paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/11df37dd559859bc34dfeb9d2eab4a71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*Dvx_cMWW45Ew6qiwfKG6jA.png"/></div></figure></div><div class="ab cb"><figure class="pe lg pl pg ph pi pj paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/882d6da4b98f46e47005ac5056160dde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*BuPwrTRWWHzVVfMhwx_TFw.png"/></div></figure><figure class="pe lg pl pg ph pi pj paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/8d78bed454ef14a0817be740da1a90e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*HYtgyPCahuhMWET9hAMfXA.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk pm di pn po translated">错误分类的图片(作者图片，修改后的ImageNet)</p></figure></div><p id="e863" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看上面的图像并将它们与训练图像进行比较，很难看出这些图像分类错误背后的原因。使CNN模型更加透明的一种方法是可视化对预测“重要”的输入区域。有许多方法可以完成这项任务，如<code class="fe oj ok ol om b">GradCAM</code>、<code class="fe oj ok ol om b">GradCAM++</code>、<code class="fe oj ok ol om b">ScoreCAM</code>等。我使用<code class="fe oj ok ol om b"> tf-keras-vis</code>库中的<code class="fe oj ok ol om b">GradCAM</code>(更多信息:<a class="ae lr" href="https://pypi.org/project/tf-keras-vis/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/tf-keras-vis/</a>)来检查错误分类图像上的模型行为。结果可以在下面看到。可以看出，模型很难聚焦于导入区域(用红色表示)。</p><div class="lc ld le lf gt ab cb"><figure class="pe lg pp pg ph pi pj paragraph-image"><img src="../Images/315fbc9bb7fdd6297b237299d9caa4a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*irhQayI9UQqiJ7YGf-DIQg.png"/></figure><figure class="pe lg pp pg ph pi pj paragraph-image"><img src="../Images/bf8dccf1d6c8377977ad16392108f541.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*QfABWQ7oAVZwwmcgWDqpKw.png"/></figure><figure class="pe lg pp pg ph pi pj paragraph-image"><img src="../Images/99acab4f53a4b681136bbdf7eb0d3f53.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*YEX5LY0jqZQEtyUlzbssLg.png"/></figure></div><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/cf527ebec4cb76854cd9ff6c68db0053.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*v-uzrrAKfz0Kg2uiiNn83A.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">分类错误的例子(作者图片，修改后的ImageNet)</p></figure><p id="5ab1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下图像展示了正确分类的图像示例。可以看出，该模型关注图像中的重要特征，并且正确地预测图像的类别。有趣的是，经过训练的模型似乎能够识别自行车和骑自行车的人。一种不仅检测物体而且检测物体在图像中的位置的物体识别模型可以适当地解决这个问题。AlexNet只能检测对象，但不能识别图像中的对象。物体识别的主题将在本系列的后续章节中讨论。</p><div class="lc ld le lf gt ab cb"><figure class="pe lg pl pg ph pi pj paragraph-image"><img src="../Images/b0f8f39a0ff714cfdf72b538181964f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*_P4lgKmkizZSlDtb7WExPw.png"/></figure><figure class="pe lg pl pg ph pi pj paragraph-image"><img src="../Images/fafa4674996ffb30eadcd38be0e6aaaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*uUndFMmeRZYr05jrHduojg.png"/><p class="ln lo gj gh gi lp lq bd b be z dk pm di pn po translated">正确分类的图片示例(作者图片，修改后的ImageNet)</p></figure></div><h1 id="081f" class="no np iq bd nq nr ns nt nu nv nw nx ny jw nz jx oa jz ob ka oc kc od kd oe of bi translated">摘要</h1><p id="7371" class="pw-post-body-paragraph kf kg iq kh b ki on jr kk kl oo ju kn ko op kq kr ks oq ku kv kw or ky kz la ij bi translated">AlexNet开启了计算机视觉和深度学习的新时代。AlexNet引入(或在某些情况下推广)了许多今天使用的相关计算机视觉方法，如conv+池设计、dropout、GPU、并行计算和ReLU。因此，作为这些发明的结果，AlexNet能够减少ImageNet数据集上的分类错误。然而，AlexNet模型需要提高分类精度。因此，许多模型都建立在AlexNet的成功之上，比如<strong class="kh ir"> VGGNet、</strong>，我将在下一篇文章中探讨和讨论这些模型。敬请关注，并在下面告诉我你的看法。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><blockquote class="ms mt mu"><p id="9629" class="kf kg mv kh b ki kj jr kk kl km ju kn mw kp kq kr mx kt ku kv my kx ky kz la ij bi translated"><em class="iq">感谢阅读！我叫</em> <strong class="kh ir"> <em class="iq">阿米尔·内贾德博士。</em> </strong> <em class="iq">我是一名数据科学家，也是</em><a class="ae lr" href="https://medium.com/quantjam" rel="noopener"><strong class="kh ir"><em class="iq">QuantJam</em></strong></a><em class="iq">的编辑，我喜欢分享我的想法，并与其他数据科学家合作。可以在</em><a class="ae lr" href="https://github.com/anejad" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir"><em class="iq">Github</em></strong></a><em class="iq"/><a class="ae lr" href="https://twitter.com/Dr_Nejad" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir"><em class="iq">Twitter</em></strong></a><em class="iq"/><strong class="kh ir"><em class="iq"/></strong><em class="iq">和</em><a class="ae lr" href="https://www.linkedin.com/in/amir-nejad-phd-8690a44b/" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir"><em class="iq">LinkedIn</em></strong></a><em class="iq">上和我联系。</em></p></blockquote><p id="0c38" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">QuantJam:</p><div class="lz ma gp gr mb mc"><a href="https://medium.com/quantjam" rel="noopener follow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ir gy z fp mh fr fs mi fu fw ip bi translated">QuantJam</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">Quantjam是一个媒体发布平台，提供金融、算法交易和…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">medium.com</p></div></div><div class="ml l"><div class="pr l mn mo mp ml mq ll mc"/></div></div></a></div><p id="2276" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以在以下网址看到我的其他作品:</p><div class="lz ma gp gr mb mc"><a href="http://amirnejad.medium.com/" rel="noopener follow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ir gy z fp mh fr fs mi fu fw ip bi translated">阿米尔·内贾德-中等</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">Python在金融数据集中的多部分时间序列分析时间序列是一系列数据…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">amirnejad.medium.com</p></div></div><div class="ml l"><div class="ps l mn mo mp ml mq ll mc"/></div></div></a></div></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="a1d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mv">所有图片均由作者制作，除非另有说明。</em></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="e2e0" class="no np iq bd nq nr pt nt nu nv pu nx ny jw pv jx oa jz pw ka oc kc px kd oe of bi translated">附录</h1><p id="d827" class="pw-post-body-paragraph kf kg iq kh b ki on jr kk kl oo ju kn ko op kq kr ks oq ku kv kw or ky kz la ij bi translated"><strong class="kh ir"> Relu激活功能:</strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi py"><img src="../Images/80da12cb4133479dbdf267f802cbce38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8pNy8pjEqJuHKJ5VtMJWBA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">Relu激活功能(图片由作者提供)</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="3995" class="no np iq bd nq nr pt nt nu nv pu nx ny jw pv jx oa jz pw ka oc kc px kd oe of bi translated">参考</h1><ul class=""><li id="3040" class="mz na iq kh b ki on kl oo ko pz ks qa kw qb la os nf ng nh bi translated">克里日夫斯基、亚历克斯、伊利亚·苏茨基弗和杰弗里·e·辛顿。"使用深度卷积神经网络的图像网络分类."神经信息处理系统进展。2012.</li><li id="dc46" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la os nf ng nh bi translated">第九讲，CNN建筑，费-李非&amp;杨小琳，2017 ( <a class="ae lr" href="https://youtu.be/DAOcjicFr1Y?t=196" rel="noopener ugc nofollow" target="_blank"> Youtube </a>)</li></ul><p id="0c4c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">最大池:</strong></p><ul class=""><li id="e07b" class="mz na iq kh b ki kj kl km ko nb ks nc kw nd la os nf ng nh bi translated">不变特征层次的无监督学习及其在物体识别中的应用。2007年IEEE计算机视觉和模式识别会议。IEEE，2007年。</li></ul><p id="6cc6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> ReLU: </strong></p><ul class=""><li id="75f5" class="mz na iq kh b ki kj kl km ko nb ks nc kw nd la os nf ng nh bi translated">奈尔、维诺德和杰弗里·e·辛顿。"校正的线性单位改进了受限的玻尔兹曼机器."ICML。2010.</li></ul><p id="e75a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> CUDA: </strong></p><ul class=""><li id="b26d" class="mz na iq kh b ki kj kl km ko nb ks nc kw nd la os nf ng nh bi translated"><em class="mv"> E. Lindholm、J. Nickolls、s .奥伯曼和J. Montrym，“NVIDIA Tesla:统一的图形和计算架构”，IEEE Micro，第28卷，第2期，第39–55页，2008年3月。</em></li></ul><p id="8c0c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> ImageNet: </strong></p><ul class=""><li id="578b" class="mz na iq kh b ki kj kl km ko nb ks nc kw nd la os nf ng nh bi translated"><em class="mv"> Russakovsky，Olga等，“Imagenet大规模视觉识别挑战”国际计算机视觉杂志115.3(2015):211–252。</em></li><li id="4cb7" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la os nf ng nh bi translated"><a class="ae lr" href="https://www.learnopencv.com/keras-tutorial-using-pre-trained-imagenet-models/" rel="noopener ugc nofollow" target="_blank"><em class="mv">https://www . learnopencv . com/keras-tutorial-using-pre-trained-imagenet-models/</em></a></li></ul></div></div>    
</body>
</html>