<html>
<head>
<title>Extractive Summarization using BERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用BERT的抽取摘要</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/extractive-summarization-using-bert-966e912f4142?source=collection_archive---------4-----------------------#2020-10-30">https://towardsdatascience.com/extractive-summarization-using-bert-966e912f4142?source=collection_archive---------4-----------------------#2020-10-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="28bb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种利用BERT嵌入能力的监督方法</h2></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><p id="d1f8" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">摘要总结是一项具有挑战性的任务，直到最近才变得实用。像NLP的许多东西一样，这种进步的一个原因是像BERT这样的transformer模型所提供的高级嵌入。这个项目使用BERT句子嵌入来建立一个提取摘要器，采用两种监督方法。第一种只考虑嵌入及其导数。这符合我们的直觉，一个好的总结者可以分析意思，应该纯粹根据文章的内部结构来选择句子。这种方法的基线是无监督的<em class="li"> TextRank </em>模型。另一种方法结合了序列信息，并利用了众所周知的新闻语料库特有的Lead3现象。这是一个观察，前三个句子通常能很好地概括文章。事实上，许多出版商都明确部署了这一策略。导联3用作第二种方法的基线。在这两种情况下，监督模型都优于Rouge-1和Rouge-L F1指标的基线。</p><p id="50ec" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> <em class="li">背景</em> </strong></p><p id="3fb3" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">总结策略通常分为提取型、抽象型和混合型。提取策略选择最能代表文章要点的前<em class="li"> N </em>句。摘要试图用新词再现文章的要点。混合策略要么在确定一个抽象的中间状态后产生一个抽象的总结，要么可以根据文本的细节选择使用哪种方法(例如:指针模型)。</p><p id="6c1a" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">提取策略被设置为二元分类问题，其中目标是识别属于摘要的文章句子。摘要需要识别关键点，然后添加生成性元素。最后，混合策略需要结合这些元素，并提供一种机制来决定何时应该使用每种模式。</p><p id="e039" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir">指标</strong></p><p id="afb7" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">摘要评估面临的挑战之一是它需要一组参考或黄金摘要的存在。对于大多数主题来说，这些都不是自然可得的，这也解释了为什么新闻文集和科学期刊主导了研究。科学论文有摘要，而新闻出版商通常在他们的网站上使用综述或横幅。摘要和翻译任务的自动评估是一个有趣但有争议的话题。这个马蜂窝在TDS上<a class="ae lj" rel="noopener" target="_blank" href="/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213">这里</a>覆盖得很好。对于当前的目的，知道Rouge-N系列度量标准已经成为标准度量标准并具有以下特性就足够了:</p><p id="4c18" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Rouge-N测量预测和gold汇总之间的n-grams重叠</p><p id="87cf" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">胭脂召回通过黄金总结的长度使重叠正常化</p><p id="3077" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Rouge precision通过预测摘要的长度来归一化重叠，从而抵消回忆失败以说明简明。例如，一个非常长的预测摘要可以获得完美的回忆，尽管有许多多余的或误导性的单词</p><p id="395f" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Rouge-1 F1(召回率和精确度的调和平均值)是主要的评估指标</p><p id="8097" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Rouge-1是一个更严格的衡量标准，也考虑到了顺序，通常与Rouge-1一起报告</p><p id="f14b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> <em class="li">数据集</em> </strong></p><p id="fede" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">康乃尔新闻编辑室<a class="ae lj" href="http://lil.nlp.cornell.edu/newsroom/index.html" rel="noopener ugc nofollow" target="_blank">数据库</a>包含130万篇文章摘要对，来源于39种出版物。该数据集代表一组不同的汇总策略，这些策略基于透明算法被标记为(提取的、抽象的、混合的)。</p><p id="05f3" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">用于该项目的数据集仅过滤了提取的文章摘要对，并将该选择截断为5000个样本。</p><p id="b9cb" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> <em class="li">管道</em> </strong></p><p id="e81b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><em class="li">注意事项</em></p><p id="9762" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">总结的一些重要注意事项是:</p><p id="af4d" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">句子排名:每篇文章都需要返回一个非空的摘要，但可能会有一些文章的所有句子都没有越过概率阈值。事实上，摘要的长度通常是一个棘手的问题，但一个常见的实用解决方案是指定返回的句子数量作为固定的用户输入k。在这种情况下，句子按照预测概率的降序排列，并选择前<em class="li"> k </em>个句子。当前项目将使用<em class="li"> k=3。</em></p><p id="d897" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">rouge:rouge分数不是一个标准的评估指标，需要自定义实现</p><p id="9925" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">混淆矩阵:使用句子排序和Rouge的一个结果是模型之间的评估结果可能与标准混淆矩阵显著不同。例如，一个模型可能无法预测阈值以上的许多句子，但在返回前3个句子后仍然得分高或模糊。</p><p id="4255" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><em class="li">示意图</em></p><p id="0be2" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">预处理</p><p id="c43b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">火车</p><p id="7266" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">预测概率</p><p id="b766" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">选择前3个句子作为总结并连接</p><p id="13fa" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">使用rouge-score包通过自定义实现计算rouge分数</p><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="lp lq l"/></div></figure><p id="1e2f" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> <em class="li">预处理</em> </strong></p><p id="5db6" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><em class="li">特性</em></p><p id="338b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">BERT足够复杂，可以从语言的所有细微差别中解析出意思，并且有意忽略了停用词移除、词干提取和小写转换等步骤。</p><p id="c3de" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">预处理包括:</p><p id="cc4c" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">将数据从JSONL加载到Pandas数据框架</p><p id="e64d" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">使用spaCy将文本分割成句子，清理短句，并通过句子转换器包使用BERT嵌入</p><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="lp lq l"/></div></figure><p id="cc3f" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">通过计算句子嵌入的平均值来计算冠词的含义</p><p id="f38c" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">计算文章中每个句子的句数</p><p id="130c" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><em class="li">目标</em></p><p id="e13c" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">数据集的提取标记依赖于一种算法，该算法在相关类别中对文章策略进行宁滨之前，在连续体上对文章策略进行评分。结果，摘要并不都是<em class="li">完全</em>摘录的，也不是所有的句子在文章文本中都有<em class="li">精确</em>匹配。下面的算法用于识别摘要中的句子</p><p id="a62d" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">计算每个摘要句子和文章句子之间的余弦相似度矩阵</p><p id="fc46" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">将具有最大值的句子标记为in-summary(设置为等于<em class="li"> 1 </em>)</p><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="lp lq l"/></div></figure><p id="222b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><em class="li">文件级的培训-测试-拆分</em></p><p id="fe2b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">虽然句子是第一组模型中的样本单元，但是训练测试分离需要发生在文档级别，以确保文章级别的摘要可以被合理地连接起来用于Rouge评估。这需要一个训练-测试-分割的自定义功能。</p><p id="7c8f" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> <em class="li">数据探索</em> </strong></p><p id="2b39" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">第一步是对文章和摘要的长度有一个高层次的概述，用句子来衡量。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/2a4e85414bac3c2565f680834b878e71.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*4oiSrsirm4jyBD_RvMjwJg.png"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">句子中文本长度的统计(作者自己的图像)</p></figure><p id="2b3f" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Lead3现象在数据集中非常明显，超过50%的摘要中的句子来自前3篇文章的句子。随着与文章开头距离的增加，摘要收录的下降也同样明显。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/8994bd2631b6b0a6add19f6761906f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*1-B54Z7jnl8zZvHW_eIoJA.png"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">引导句现象在语料库中高度可见(作者自己的图像)</p></figure><p id="cd9f" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">主题域可以使用t-sne和简单的标签分配方法来可视化</p><p id="f5c3" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">计算“娱乐”、“犯罪”、“商业”和“政治”作为四个领域参考嵌入的BERT嵌入</p><p id="7c02" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">计算每篇文章相对于四篇参考文献的余弦相似度</p><p id="6caf" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">用最接近的参考文献(最高余弦相似度)标记文章</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/6133e1aa4900316de06ae1c3514727d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/0*4TNzJTDVZMnPeOso"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">作者自己的形象</p></figure><p id="2160" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">尽管有大量的信息丢失，但特定主题领域的密集程度是显而易见的，政治在左下角，犯罪在右下角，商业在左上角，娱乐在右上角。同样值得注意的是，政治和犯罪占据了底部，而商业和娱乐占据了顶部。广义的解释是，政治和犯罪共同关注社会和法律问题，而商业和娱乐有着共同的商业目标。主题域决不是预期可分离的，并且观察到的分散程度并不令人惊讶。</p><p id="4f15" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> <em class="li">方法1 </em> </strong></p><p id="7639" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">这种方法的目标是仅使用句子嵌入及其派生来获得摘要，以便训练能够解析文章内部结构的监督模型。<em class="li"> TextRank </em>被选为该方法的基线。一系列逻辑回归模型和神经网络用以下总结结果进行训练:</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/c7859c2a73182b6a3d29b8417f9e1658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*BM0ozw-skysBKZ0FIDKbZg.png"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">最优logistic回归模型是l1 _比值为0.25、正则化倒数为0.5的弹性网。最佳神经网络是一个双层密集网络，每层25个神经元。(作者自己的图片)</p></figure><p id="5a2b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">整个测试过程中一个值得注意的特点是，微调，甚至是平衡数据的调整产生的益处很少。例如，所有尝试的逻辑回归模型得分在41%和42%之间。这并不奇怪，因为这些模型调整不太可能改变句子排名，这是他们各自胭脂分数差异的唯一来源。对于Rouge-1和Rouge-L，这两个监督模型都轻松击败了文本排名基线，得分相当令人印象深刻。它们的优势在召回率和精确度方面也是一致的。一个令人惊讶的方面是，弹性网络模型略微优于神经网络。一个原因可能是仅提供句子嵌入和文章含义的特征集没有为神经网络的非线性提供足够的上下文信息来充分探索。在<em class="li">进一步思考</em>中讨论了可能的补救措施。</p><p id="5f26" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> <em class="li">进场2 </em> </strong></p><p id="8113" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">Lead3是Rouge metrics的强大对手，本节通过包含顺序信息，利用了新闻语料库中已知的顺序结构。使用句子数量作为句子嵌入和文章含义的附加特征来训练逻辑回归模型。各种LSTM体系结构，自然地结合了顺序信息，在与上一节相同的嵌入特性上进行训练:</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/8d5d1a4a60a44167f4b3c93429c5a3d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*V6pOKxkpn8_EplqrM86Uww.png"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">LEDE3取前导三句。LogReg def是SK-learn中的默认逻辑回归模型，LSTM Bi 50是在Keras中实现的50神经元双向LSTM网络，没有填充，纪元为1，并使用Adam优化器。(作者本人图片)</p></figure><p id="d7ce" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">虽然逻辑回归模型滞后，但LSTM在LEAD3基线上享有优势。再深入分析一下，LSTM的召回率与领先3相似，但在精确度方面有很大优势。这表明，在LSTM不同于Lead3的情况下，它在选择同样相关但更简洁的句子方面做得相对较好。</p><p id="c36c" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="ko ir"> <em class="li">进一步的想法</em> </strong></p><p id="f652" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">在每个句子给出的信息很少的情况下，仅嵌入方法的结果令人惊讶地好。一个有趣的方法是通过创造性特征工程为模型提供更多关于文章内部结构的信息。这可能特别有利于从神经网络的非线性中提取更多信息。一种想法是，可以根据一些属性在语料库中标记句子，然后将文章级质心作为一个新的特征。有监督的方法可以基于词性标注为每个句子分配一个功能标签。无监督选项可以使用聚类算法来分割整个语料库上的句子嵌入空间。</p><p id="45f4" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">进一步工作的更简单选项包括(I)使用在<em class="li"> TextRank </em>中获得的相似性矩阵作为监督模型的特征集，(ii)使用比这里使用的5000篇文章多得多的数据来训练模型，当然，(iii)添加注意机制或使用转换器来获得更细微的结果。</p><p id="ac41" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">最后，值得记住的是，语料库仅被过滤为摘录摘要，下一步将包括对数据集中更广泛的策略类型采取相同的方法。</p><p id="75c4" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">感谢您阅读我的文章。欢迎所有反馈，记得查看我的<a class="ae lj" href="https://github.com/gslicht/Extractive-Summarization-of-a-News-Corpus-Using-BERT" rel="noopener ugc nofollow" target="_blank"> GitHub </a>的代码和更详细的分析。</p></div></div>    
</body>
</html>