<html>
<head>
<title>How to Handle Imbalance Data and Small Training Sets in ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何处理ML中的不平衡数据和小训练集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-handle-imbalance-data-and-small-training-sets-in-ml-989f8053531d?source=collection_archive---------6-----------------------#2020-10-28">https://towardsdatascience.com/how-to-handle-imbalance-data-and-small-training-sets-in-ml-989f8053531d?source=collection_archive---------6-----------------------#2020-10-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="587f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不平衡数据是指每个类的观察值数量分布不均，通常有一个主要类占数据集的比例较大，而次要类没有足够的示例。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/8029596086f69daf8bf7ef487f31e95f.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*CkItiHtZWN5MBAs0VPlwdw.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">按作者分类的图表</p></figure><p id="b0d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">小的训练集也苦于没有足够的例子。这两个问题在现实应用中非常普遍，但幸运的是有几种方法可以克服这个问题。本文将通过许多不同的技术和视角来应对不平衡数据。特别是，您将了解到:</p><ul class=""><li id="dadd" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">采样技术(上采样和下采样)</li><li id="4569" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">加权损失</li><li id="9d60" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">数据扩充技术</li><li id="38b5" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">迁移学习</li></ul><h1 id="f6cb" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">不平衡的数据如何影响你的模型？</h1><p id="043d" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">不平衡数据是数据科学中常见的问题。从图像分类到欺诈检测或医疗诊断，数据科学家面临不平衡的数据集。不平衡的数据集会降低模型对少数类的敏感度。让我们用简单的数学来解释一下:</p><p id="3099" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">想象一下，你有10000张肺部x光图像，其中只有100张被诊断为肺炎，这是一种传染病，会使一个或两个肺部的气囊发炎，并使它们充满液体。如果你训练一个模型，预测每个例子都是健康的，你会得到99%的准确率。哇，多棒啊？<strong class="jp ir">错了</strong>，你刚刚用你的模型杀了很多人。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/00727f3567da63c08fb7f61788385910.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*ZxquEZcxNNJRvpH5WeiNMQ.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">作者图片</p></figure><p id="aba2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通常，我们通过准确性来衡量模型的表现，但是不平衡的数据会误导我们，就像上面的例子一样。这篇文章的重点是如何处理这些情况，我不会详细介绍如何衡量您的模型，但请记住，要将衡量指标从准确性改为<strong class="jp ir">精确度、召回、F1 </strong>分数。但是即使他们实际上也没有那么伟大。在处理不平衡数据时，我建议选择:<strong class="jp ir"> AUC曲线、</strong> <strong class="jp ir">平均精度</strong>。这是一个令人惊叹的github知识库，它通过谈论一个特定的不平衡数据集示例来深入研究这些指标的细节:<a class="ae mp" href="https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_4_PerformanceMetrics/Introduction.html" rel="noopener ugc nofollow" target="_blank">信用卡欺诈</a>。</p><p id="44ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">比方说，我们有一个不平衡的数据集，我们无法访问更多的数据。所以我们应该创建自己的数据。下一章将在高抽象层次上介绍这些技术，我还添加了一些用Python实现这些技术的参考资料。</p><h1 id="0c65" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">取样技术</h1><p id="9f33" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">您可以通过重采样来平衡数据。以下是两种不同的重采样技术:</p><ul class=""><li id="b39d" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">向上采样(增加你的少数类)</li><li id="e614" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">向下采样(减少多数类)</li></ul><p id="54dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于这两者，我们将使用Sklearn重采样函数。让我们导入库并将我们的数据定义为<code class="fe mq mr ms mt b">df</code>:</p><pre class="km kn ko kp gt mu mt mv mw aw mx bi"><span id="f4b4" class="my lm iq mt b gy mz na l nb nc"># Importing the libraries<br/>import numpy as np<br/>import pandas as pd<br/>from sklearn.utils import resample</span><span id="7bc9" class="my lm iq mt b gy nd na l nb nc"># Importing the dataset<br/># Read dataset<br/>df= pd.read_csv('data.csv')</span></pre><p id="e5ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本例中，我们有一个二元分类问题，其中多数类表示为1，少数类表示为0。让我们把它们分开:</p><pre class="km kn ko kp gt mu mt mv mw aw mx bi"><span id="8cf1" class="my lm iq mt b gy mz na l nb nc"># Separate majority and minority classes<br/>df_majority = df[df.iloc[:,4608]==1]<br/>df_minority = df[df.iloc[:,4608]==0]</span></pre><p id="b30b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以对多数类进行下采样，对少数类进行上采样，或者两者兼而有之。你应该试一试，看看哪一款最适合你。您可以调整的另一个超参数是<code class="fe mq mr ms mt b">n_samples</code>，它是您重新采样的样本数。</p><pre class="km kn ko kp gt mu mt mv mw aw mx bi"><span id="a323" class="my lm iq mt b gy mz na l nb nc"># Separate majority and minority classes<br/>df_majority = df[df.iloc[:,4608]==1]<br/>df_minority = df[df.iloc[:,4608]==0]<br/> <br/># Downsample majority class<br/>df_majority_downsampled = resample(df_majority, <br/>                                 replace=False,    <br/>                                 n_samples=1000)</span><span id="91ce" class="my lm iq mt b gy nd na l nb nc">#Upsample minority class<br/>df_minority_upsampled = resample(df_minority, <br/>                                 replace=True,     <br/>                                 n_samples=1000)</span><span id="c071" class="my lm iq mt b gy nd na l nb nc"># Combine minority class with downsampled majority class<br/>df_up_down_sampled = pd.concat([df_majority_downsampled, df_minority_upsampled])</span></pre><p id="9d88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后显示新的班级人数:</p><pre class="km kn ko kp gt mu mt mv mw aw mx bi"><span id="9373" class="my lm iq mt b gy mz na l nb nc">df_downsampled.prediction.value_counts()</span></pre><p id="76aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">恭喜你，你给权力带来了平衡。🎉</p><p id="0269" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">编辑:我最近被问到的一个面试问题:</strong> <em class="ne">你如何确保你的上采样&amp;下采样数据来自良好的分布/你如何衡量这些方法的性能？</em></p><p id="af71" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">衡量这些方法性能的一个简单方法是获取用这些额外数据训练的新模型的测试结果。大多数情况下，进行上采样时，您可能会先看到性能有所提高，然后趋于平稳，甚至有所下降。我会选择数量最少、性能最高的上采样数据。</p><p id="78ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是有时候重采样本身是不够的。本文继续介绍更高级的技术。</p><h1 id="1cd8" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">加权损失</h1><p id="ee0b" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">避免阶级失衡的另一个方法是用不同的方式来衡量损失。要选择权重，首先需要计算类别频率。</p><pre class="km kn ko kp gt mu mt mv mw aw mx bi"><span id="b39f" class="my lm iq mt b gy mz na l nb nc"><em class="ne"># Count up the number of instances of each class (drop non-class columns from the counts)</em><br/>class_counts = df_classes.sum()</span><span id="d29f" class="my lm iq mt b gy nd na l nb nc">#print the class frequencies<strong class="mt ir"><br/>for</strong> column <strong class="mt ir">in</strong> class_counts.keys():<br/>    print(f"The class <strong class="mt ir">{</strong>column<strong class="mt ir">}</strong> has <strong class="mt ir">{</strong>df_classes[column].sum()<strong class="mt ir">}</strong> samples")</span></pre><p id="1b76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过更改损失函数中的权重，数据科学家可以平衡每个类别的贡献。一种方法是将每个类中的每个例子乘以一个特定于类的权重因子，这样每个类的总体贡献是相同的。</p><p id="8069" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">感谢Sklearn，在大多数ML算法中有一个内置的参数class_weight，它可以帮助你平衡每个类的贡献。例如，在Sklearn的<a class="ae mp" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank"> RandomForestClassifier </a>中，您可以选择balanced、balanced_subsample，或者您可以手动给每个类一个字典的权重。</p><pre class="km kn ko kp gt mu mt mv mw aw mx bi"><span id="24f2" class="my lm iq mt b gy mz na l nb nc">#Fitting RandomForestClassifier<br/>from sklearn.ensemble import RandomForestClassifier</span><span id="9798" class="my lm iq mt b gy nd na l nb nc">model = RandomForestClassifier(n_estimators=1000, class_weight={0:0.10, 1:0.90})</span></pre><p id="5439" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Amazing🥳，现在你学会了一个非常普通的技术，你可以用每一种最大似然算法应用几乎每一种数据。让我们深入了解更先进的技术。</p><h1 id="7208" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">数据扩充</h1><p id="2e07" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">从现在开始，我将要提到的技术主要适用于计算机视觉和图像。使用图像时，有多种方法可以生成数据。</p><p id="6e8c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">众所周知，数据扩充是一种非常强大的技术，用于在现有图像中人工创建变化，以扩展现有图像数据集。这从代表可能图像的综合集合的现有图像数据集中创建新的和不同的图像。以下是增加数据集的几种方法。</p><ul class=""><li id="8888" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">轻弹</li><li id="4db0" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">一款云视频会议软件</li><li id="5169" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">轮流</li><li id="bc8d" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">剪羊毛</li><li id="6cbd" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">种植</li><li id="90cd" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">最后用生成性对抗网络生成新图像。</li></ul><p id="62fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:有时候使用这些技术对你的模型有害无益。让我们假设相同的肺部X射线数据集情况，其中我们有许多不同的X射线。如果你翻转图片，你会在右边看到一颗心，它可以被看作是一个cist。你又杀了人=(所以要小心使用这些增强技术。</p><p id="604e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mp" rel="noopener" target="_blank" href="/data-augmentation-techniques-in-python-f216ef5eed69">你可以在这里了解更多信息</a></p><h1 id="0850" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">迁移学习</h1><p id="16f3" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">如果您没有足够的数据来概括您的模型，您可以使用预先训练的模型，并针对您自己的任务调整它们。这被称为迁移学习，在计算机视觉领域非常普遍。自从培训以来，庞大的模型需要花费如此多的时间和资源，人们正在获得像DenseNet这样的预培训模型并使用它们。方法如下:</p><ul class=""><li id="ffa8" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">找到符合你要求的型号</li><li id="4a6f" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">重用模型。这可能涉及使用模型的全部或部分或神经网络的第一层。由于要素的复杂性随着层数的增加而增加，因此第一层总是具有更多可以成功使用的通用要素。</li><li id="aadc" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">微调:通过深入，神经网络在任务上变得专业化，所以你可能想要为你自己的任务调整最后几层，这被称为微调。</li></ul><p id="42d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mp" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">你可以从这里了解更多信息</a></p><h1 id="6987" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">摘要</h1><p id="54c4" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">我们学习了4种不同的技术，您可以将其应用于不平衡的数据/小型训练集。现在，您知道如何通过以下方式提高模型的性能:</p><ul class=""><li id="91b2" class="kx ky iq jp b jq jr ju jv jy kz kc la kg lb kk lc ld le lf bi translated">使用取样技术</li><li id="c2a0" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">改变损失函数的类权重</li><li id="16aa" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">使用数据增强技术</li><li id="37c4" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated">利用迁移学习</li></ul><p id="866e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中最后两个更专门针对计算机视觉。我希望这篇文章能帮助你理解如何用不同的技术克服不平衡数据问题。祝贺你完成这篇文章，感谢你一直以来的阅读。</p><h1 id="1c3a" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">参考资料:</h1><ul class=""><li id="89e5" class="kx ky iq jp b jq mj ju mk jy nf kc ng kg nh kk lc ld le lf bi translated"><a class="ae mp" href="https://machinelearningmastery.com/resample-interpolate-time-series-data-python/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/resample-interpolate-time-series-data-python/</a></li><li id="968b" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated"><a class="ae mp" rel="noopener" target="_blank" href="/data-augmentation-techniques-in-python-f216ef5eed69">https://towards data science . com/data-augmentation-techniques-in-python-f 216 ef 5 eed 69</a></li><li id="c88e" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated"><a class="ae mp" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/transfer-learning-for-deep-learning/</a></li><li id="ce97" class="kx ky iq jp b jq lg ju lh jy li kc lj kg lk kk lc ld le lf bi translated"><a class="ae mp" href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/tactics-to-combat-unbalanced-classes-in-your-machine-learning-dataset/</a></li></ul></div></div>    
</body>
</html>