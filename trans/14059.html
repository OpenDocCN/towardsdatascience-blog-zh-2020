<html>
<head>
<title>What deep learning needs for better COVID-19 detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习需要什么来更好地检测新冠肺炎</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/domain-expertise-what-deep-learning-needs-for-better-covid-19-detection-56cdeefde564?source=collection_archive---------49-----------------------#2020-09-27">https://towardsdatascience.com/domain-expertise-what-deep-learning-needs-for-better-covid-19-detection-56cdeefde564?source=collection_archive---------49-----------------------#2020-09-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0b43" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/data-science-in-the-real-world/home" rel="noopener"> <strong class="ak">现实世界中的数据科学</strong> </a></h2><div class=""/><div class=""><h2 id="f1c5" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">这个世界可能不需要另一个神经网络，但它需要与那些在第一线的人进行咖啡聊天。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/fba23d1937d16cf0ce8e377abf381f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ut9gqxujQcbDivVo"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@aboutiwe?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">欧文·</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="ce58" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">到目前为止，你可能已经看过一些关于深度学习如何帮助检测新冠肺炎的文章。特别是，通过分析患者的计算机断层扫描(CT)扫描，卷积神经网络(CNN)已经被研究为黄金标准聚合酶链式反应测试的更快更便宜的替代方案。这并不奇怪，因为CNN在图像识别方面非常出色；许多地方有CT扫描仪，而不是新冠肺炎检测工具(至少在最初)。</p><p id="86e5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">尽管CNN在图像识别任务中取得了成功，如ImageNet challenge，但它真的能帮助医生检测新冠肺炎吗？如果可以，它能做到多准确？众所周知，CT扫描是敏感的，但不是针对新冠肺炎的。也就是说，新冠肺炎几乎总是产生CT扫描可见的异常肺模式。然而，其他肺炎也可以产生同样的异常模式。强大且有时神奇的CNN能解决这个模糊问题吗？</p><p id="f200" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们有机会自己回答这些问题(与我的同事<a class="ae le" href="https://www.linkedin.com/in/yuchen-shi-2830ba158/?originalSubdomain=sg" rel="noopener ugc nofollow" target="_blank">和顾问</a><a class="ae le" href="https://www.eng.nus.edu.sg/isem/staff/chen-nan/" rel="noopener ugc nofollow" target="_blank"> A/P陈</a>)。我将带你看一个新冠肺炎分类器，这是我们为2020年QSR数据挑战<a class="ae le" href="https://connect.informs.org/HigherLogic/System/DownloadDocumentFile.ashx?DocumentFileKey=f404f7b8-fcd6-75d5-f7a7-d262eab132e7" rel="noopener ugc nofollow" target="_blank">建造的入口。如果您不熟悉CNN，或者想重温CNN的主要功能，我强烈建议您首先阅读这篇文章:</a></p><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/a-math-free-introduction-to-convolutional-neural-network-ff38fbc4fc76"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">卷积神经网络:它与其他网络有何不同？</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">CNN有什么独特之处，卷积到底是做什么的？这是一个无数学介绍的奇迹…</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms ky me"/></div></div></a></div><p id="bb0c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">另外，如果你想亲自动手，你可以从这个Github <a class="ae le" href="https://github.com/YangXiaozhou/CNN-COVID-19-classification-using-chest-CT-scan" rel="noopener ugc nofollow" target="_blank"> repo </a>中获得所有代码和数据。</p><h2 id="105a" class="mt mu iq bd mv mw mx dn my mz na dp nb lo nc nd ne ls nf ng nh lw ni nj nk iw bi translated">关键要点</h2><ol class=""><li id="e9c4" class="nl nm iq lh b li nn ll no lo np ls nq lw nr ma ns nt nu nv bi translated">使用预训练的CNN的迁移学习可以在新冠肺炎分类上实现非常强的基线性能(85%的准确度)。</li><li id="4f24" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">然而，需要基于领域专业知识的特征工程和适应来将CNN(或其他ML方法)提升到医学上令人信服的水平。</li></ol><h1 id="b69a" class="ob mu iq bd mv oc od oe my of og oh nb kf oi kg ne ki oj kj nh kl ok km nk ol bi translated">挑战是什么？</h1><p id="a2cc" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">新冠肺炎·疫情改变了世界各地的生活。据<a class="ae le" href="https://covid19.who.int/" rel="noopener ugc nofollow" target="_blank">世卫组织</a>报道，这是截至2020/09/26的现状。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi op"><img src="../Images/a80e5628ed28550c5f852df72f006602.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*78ByyR_b6foIFRpx.png"/></div></div></figure><p id="53fd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">CT扫描已被用于筛查和诊断新冠肺炎，尤其是在拭子检测资源严重缺乏的地区。这项数据挑战的目标是使用胸部CT扫描诊断新冠肺炎。因此，我们需要建立一个<strong class="lh ja">分类模型</strong>，它可以根据患者的胸部CT扫描<strong class="lh ja">尽可能准确地将患者分类为COVID或非COVID</strong>。</p><h2 id="9422" class="mt mu iq bd mv mw mx dn my mz na dp nb lo nc nd ne ls nf ng nh lw ni nj nk iw bi translated">提供什么？</h2><p id="381b" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">提供相对偶数的COVID和非COVID图像来训练模型。比赛还要求，模型的训练与提供的数据必须少于一个小时。</p><ul class=""><li id="8a77" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ot nt nu nv bi translated">训练数据集:251个COVID图像和292个非COVID图像</li><li id="3a18" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ot nt nu nv bi translated">元信息:患者信息、严重性、图像标题等。</li></ul><p id="7757" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所有质询数据均取自公共<a class="ae le" href="https://github.com/UCSD-AI4H/COVID-CT" rel="noopener ugc nofollow" target="_blank">数据集</a>。</p><h1 id="b355" class="ob mu iq bd mv oc od oe my of og oh nb kf oi kg ne ki oj kj nh kl ok km nk ol bi translated">模型性能</h1><p id="88a9" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">我们先来看看结果，好吗？</p><p id="f867" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">用一组独立的测试数据对训练好的模型进行评估。这里你可以看到混淆矩阵。总体准确率约为85%，灵敏度略高于特异性，即真阳性率&gt;真阴性率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/77b39cc7bd0f9294c15413d421b428b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/0*pO2AAWjUiay7QyL9.png"/></div></figure><h1 id="7e72" class="ob mu iq bd mv oc od oe my of og oh nb kf oi kg ne ki oj kj nh kl ok km nk ol bi translated">履行</h1><p id="a215" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">值得注意的是，挑战在于区分COVID和非COVID CT扫描，而不是COVID和正常扫描。事实上，可能有一些不属于其他肺炎患者的ct扫描(特异性问题)。以下是COVID和其他肺炎CT扫描的一个示例:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ov"><img src="../Images/cfe5e2b47bfd6163c5601becad4b650a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tz8e2Sz8o4muqSGA8uDRdg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">新冠肺炎引起的肺炎患者的CT扫描。资料来源:SJin，y，Cai，l，Cheng，z等人/ <a class="ae le" href="https://creativecommons.org/licenses/by/4.0" rel="noopener ugc nofollow" target="_blank"> CC BY </a></p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/8a764bc2a17d382e2bc733b089411aca.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*X3mh93j98OgkTmpQAQaaxw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">非细菌性肺炎的CT扫描。来源:詹姆斯·海尔曼，医学博士/ <a class="ae le" href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener ugc nofollow" target="_blank"> CC BY-SA </a></p></figure><h2 id="ff39" class="mt mu iq bd mv mw mx dn my mz na dp nb lo nc nd ne ls nf ng nh lw ni nj nk iw bi translated">训练-验证分割</h2><p id="871d" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">我们保留20%的数据进行验证。由于一些连续的图像来自同一个患者，它们往往彼此相似。也就是说，我们的很多数据都是<strong class="lh ja">而非独立</strong>。为了防止数据泄漏(训练数据的信息溢出到验证数据)，我们保留原始图像序列，并使用最后20%作为验证集。拆分后，我们有两对数据:</p><p id="818a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">1.X_train，y_train <br/> 2。x值，y值</p><p id="9f89" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">x是CT扫描的列表，y是二进制标签的列表(0表示非COVID，1表示COVID)。</p><h2 id="7f40" class="mt mu iq bd mv mw mx dn my mz na dp nb lo nc nd ne ls nf ng nh lw ni nj nk iw bi translated">数据扩充</h2><p id="f02c" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">数据扩充是在训练数据中包含更多随机变化的常用方法。这有助于防止过度拟合。对于图像相关的学习问题，增强通常意味着应用<strong class="lh ja">随机</strong>几何(例如，裁剪、翻转、旋转等。)和外观变换(例如，对比度、边缘滤波、高斯模糊等。).我们使用<code class="fe ox oy oz pa b">tf.keras.Sequential</code>创建一个管道，其中输入图像通过以下操作进行随机转换:</p><ol class=""><li id="d94b" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ns nt nu nv bi translated">随机水平和垂直翻转</li><li id="b9a5" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">在[-5%，5%]*2pi范围内随机旋转度数</li><li id="6a7c" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">高度随机放大5%</li><li id="7943" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">随机翻译5%</li><li id="ff34" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">随机对比度调整5%</li></ol><h2 id="a55a" class="mt mu iq bd mv mw mx dn my mz na dp nb lo nc nd ne ls nf ng nh lw ni nj nk iw bi translated">使用预先训练的CNN作为主干</h2><p id="3eb4" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">我们不能从零开始建立CNN。对于只有少量训练图像的图像相关问题，建议使用预训练模型作为主干，并在其上进行<a class="ae le" href="https://cs231n.github.io/transfer-learning/" rel="noopener ugc nofollow" target="_blank">迁移学习</a>。选择的型号是<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0" rel="noopener ugc nofollow" target="_blank"> EfficientNetB0 </a>。它属于谷歌研究人员提出的名为<a class="ae le" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">高效网络</a>的模型家族。EfficientNets是当前用于计算机视觉任务的最先进的CNN之一。他们</p><ol class=""><li id="a026" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ns nt nu nv bi translated">需要数量少得多的参数，</li><li id="66cd" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">在ImageNet上取得了非常高的准确率，</li><li id="5da7" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">很好地转移到其他图像分类任务。</li></ol><p id="2561" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">EfficientNets和其他众所周知的预训练模型可以很容易地从<code class="fe ox oy oz pa b">tf.keras.applications</code>加载。我们首先导入预先训练的EfficientNetB0，并将其用作我们的模型主干。我们删除了EfficientNetB0的原始输出层，因为它是为1000类分类而训练的。此外，我们冻结了模型的权重，以便它们不会在初始训练期间更新。</p><pre class="kp kq kr ks gt pb pa pc pd aw pe bi"><span id="0395" class="mt mu iq pa b gy pf pg l ph pi"># Create a base model from the pre-trained EfficientNetB0<br/>base_model = keras.applications.EfficientNetB0(input_shape=IMG_SHAPE, include_top=False)<br/>base_model.trainable = False</span></pre><h2 id="4eb5" class="mt mu iq bd mv mw mx dn my mz na dp nb lo nc nd ne ls nf ng nh lw ni nj nk iw bi translated">用我们的模型包裹它</h2><p id="fc32" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">导入EfficientNet后，我们可以用它来包装我们的分类模型，从而解决我们的问题。你可以把EfficientNetB0想象成一个训练有素的特征提取器。最终模型具有:</p><ol class=""><li id="c489" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ns nt nu nv bi translated">输入层</li><li id="ebe7" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated"><strong class="lh ja"> EfficientNetB0基本型号</strong></li><li id="33ab" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">平均池层:通过平均操作来池化信息</li><li id="0d01" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">丢弃层:将输入的百分比设置为零</li><li id="44ca" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">分类层:输出不一致的概率</li></ol><p id="175c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们也可以使用<code class="fe ox oy oz pa b">tf.keras.utils.plot_model</code>来可视化我们的模型。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/728288bbe3199caa0a8b203a6f76c890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/0*V-TV2s1iA94XhMbT.png"/></div></figure><p id="b195" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以看到:</p><ol class=""><li id="a6c8" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ns nt nu nv bi translated">输入和输出形状中的<code class="fe ox oy oz pa b">?</code>是为样本数预留的位置，模型还不知道。</li><li id="9143" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">EfficientNetB0位于输入层之后。</li><li id="32f1" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">最后一层(分类层)的输出为1维:非VID的概率。</li></ol><h2 id="84e6" class="mt mu iq bd mv mw mx dn my mz na dp nb lo nc nd ne ls nf ng nh lw ni nj nk iw bi translated">训练我们的模型</h2><p id="9326" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated"><strong class="lh ja">公共数据预训练</strong>:为了帮助NetB0更有效地适应COVID与非COVID图像分类，我们实际上已经在另一个公共CT扫描数据集<a class="ae le" href="https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset" rel="noopener ugc nofollow" target="_blank">上训练了我们的模型</a>。希望在CT扫描上训练模型将允许它学习我们的新冠肺炎分类任务的特定特征。我们不会深入到公共数据训练部分，但是这个过程本质上和我下面要展示的是一样的。</p><p id="035b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">迁移学习工作流程</strong>:我们使用一个典型的迁移学习工作流程:</p><ol class=""><li id="5389" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ns nt nu nv bi translated">阶段1(特征提取):固定EfficientNetB0的权重，仅更新最后一个分类层的权重。</li><li id="e19f" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">阶段2(微调):允许一些EfficientNetB0 '权重也进行更新。</li></ol><p id="9ce0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你可以在这里阅读更多关于工作流程<a class="ae le" href="https://www.tensorflow.org/guide/keras/transfer_learning#the_typical_transfer-learning_workflow" rel="noopener ugc nofollow" target="_blank">的信息。</a></p><p id="97ea" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">关键配置</strong>:我们使用以下指标和损失函数:</p><ol class=""><li id="3285" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ns nt nu nv bi translated"><strong class="lh ja">指标</strong>:评估模型性能</li></ol><ul class=""><li id="1dfb" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ot nt nu nv bi translated">二元精度</li><li id="506d" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ot nt nu nv bi translated">假阳性和真阳性</li><li id="4673" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ot nt nu nv bi translated">假阴性和真阴性</li></ul><p id="b9ef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> 2。损失函数</strong>:引导梯度搜索</p><ul class=""><li id="ea61" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ot nt nu nv bi translated">二元交叉熵</li></ul><p id="c2e4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们使用<code class="fe ox oy oz pa b">Adam</code>优化器，对于这两个阶段，学习率被设置为<code class="fe ox oy oz pa b">[1e-3, 1e-4]</code>，训练次数被设置为<code class="fe ox oy oz pa b">[10, 30]</code>。两阶段训练迭代两次。</p><p id="b9d3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">训练历史</strong>:让我们把训练历史形象化；</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pk"><img src="../Images/53603616092709ed89f181a994cc9fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QxhvuNkHx2ZLAktI.png"/></div></div></figure><p id="cd00" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这里，你可以看到，在我们允许一些层的效率网络更新后(在纪元10之后)，我们在分类准确性方面获得了显著的提高。最终的训练和验证准确率在98%和82%左右。</p><h1 id="3d00" class="ob mu iq bd mv oc od oe my of og oh nb kf oi kg ne ki oj kj nh kl ok km nk ol bi translated">它在测试数据上的表现如何？</h1><p id="1295" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">我们可以从包含105个非COVID图像和98个COVID图像的相同数据报告中获得一组测试数据。让我们看看训练好的模型在他们身上表现如何。下面是使用<code class="fe ox oy oz pa b">sklearn.metrics.classification_report</code>的测试数据的结果分析:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/8cfe28b2a56f500010450d155b19dab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*z0huZaCx6ejqLyc_hsxZqw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">分类报告</p></figure><p id="eac6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是ROC曲线:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/acbaced17be67ea72772e4de6a3d7144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/0*e6qeQW7QuxAr2Yir.png"/></div></figure><h1 id="f873" class="ob mu iq bd mv oc od oe my of og oh nb kf oi kg ne ki oj kj nh kl ok km nk ol bi translated">什么是正确和错误分类的CT扫描？</h1><p id="15f4" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">我们可以深入分类结果，看看哪些是正确识别的，哪些是错误识别的。<strong class="lh ja">发现的潜在模式</strong>可以用来帮助进一步改进模型。请看这个jupyter <a class="ae le" href="https://github.com/YangXiaozhou/CNN-COVID-19-classification-using-chest-CT-scan/blob/master/notebooks/2-COVID-19-classification-based-on-CT-scan.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>中的图片。从这些图像中，我们看到:</p><ol class=""><li id="8d46" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ns nt nu nv bi translated">真阳性有明显的异常模式，肺结构保存完好。</li><li id="cbc1" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">很多真阴性都是完全黑肺(无异常模式)。</li><li id="f11d" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">很多假阳性的肺边界不清楚。</li></ol><p id="dd38" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">关键是，对于像我这样的非医学人士来说，许多COVID和非COVID图像看起来是一样的。当一些图像具有不清楚的肺边界时，模糊甚至更严重。看起来我们的CNN也很难区分这些图像。</p><h1 id="d03f" class="ob mu iq bd mv oc od oe my of og oh nb kf oi kg ne ki oj kj nh kl ok km nk ol bi translated">我们将何去何从？</h1><p id="e46d" class="pw-post-body-paragraph lf lg iq lh b li nn ka lk ll no kd ln lo om lq lr ls on lu lv lw oo ly lz ma ij bi translated">从上面的结果，我们可以看到，一个预训练的CNN可以适应实现一个真正强大的基线性能。然而，深度学习模型(或任何其他模型)单独能够实现的目标有明显的限制。在这种情况下，计算机视觉研究人员和医学专家需要以一种有意义的方式进行合作，以便最终模型既有计算能力又有医学可靠性。</p><p id="04be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以从几个方面改进模型:</p><ol class=""><li id="3bef" class="nl nm iq lh b li lj ll lm lo oq ls or lw os ma ns nt nu nv bi translated"><strong class="lh ja">肺部分割</strong>:对每一幅图像进行处理，只保留CT扫描的肺部区域，例如这里的<a class="ae le" href="https://pubs.rsna.org/doi/full/10.1148/rg.2015140232" rel="noopener ugc nofollow" target="_blank">见</a>。</li><li id="fbf8" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated">更复杂的<strong class="lh ja">迁移学习</strong>设计:例如，参见多任务<a class="ae le" href="https://ruder.io/multi-task/" rel="noopener ugc nofollow" target="_blank">学习</a>或监督域<a class="ae le" href="https://en.wikipedia.org/wiki/Domain_adaptation#The_different_types_of_domain_adaptation" rel="noopener ugc nofollow" target="_blank">适配</a>。</li><li id="b4b5" class="nl nm iq lh b li nw ll nx lo ny ls nz lw oa ma ns nt nu nv bi translated"><strong class="lh ja">集合</strong>模型:这似乎是一个普遍的信念，尤其是在Kaggle用户中，构建一个集合<a class="ae le" href="https://scikit-learn.org/stable/modules/ensemble.html" rel="noopener ugc nofollow" target="_blank">模型</a>几乎总是会给你额外增加几个百分点的准确度。</li></ol><p id="a211" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="pn">以上就是我们CNN新冠肺炎CT扫描分类！谢谢大家！</em></p></div><div class="ab cl po pp hu pq" role="separator"><span class="pr bw bk ps pt pu"/><span class="pr bw bk ps pt pu"/><span class="pr bw bk ps pt"/></div><div class="ij ik il im in"><p id="64c2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="pn">原载于</em><a class="ae le" href="https://yangxiaozhou.github.io/data/2020/09/27/detecting-covid19-using-cnn.html" rel="noopener ugc nofollow" target="_blank"><em class="pn">https://yang xiaozhou . github . io</em></a><em class="pn">。</em></p></div></div>    
</body>
</html>