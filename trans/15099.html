<html>
<head>
<title>Neural Style Transfer — A high-level approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经类型转移——一种高级方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-style-transfer-a-high-level-approach-250d4414c56b?source=collection_archive---------20-----------------------#2020-10-17">https://towardsdatascience.com/neural-style-transfer-a-high-level-approach-250d4414c56b?source=collection_archive---------20-----------------------#2020-10-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/69988ffd030aa8590998d8bb0b95265c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*00Sir2feZekSKPd7"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">保罗·本丹迪<a class="ae kf" href="https://unsplash.com/photos/hZUlyk-EeuU" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/hZUlyk-EeuU</a></p></figure><p id="f836" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">今天我想谈谈神经风格转移和卷积神经网络(CNN)。已经有相当多的文章和教程可用。有时内容只是复制，有些提供了新颖的实现。所有的共同点是快速深入细节。在我看来太具体了。不仅如此，通常还有一些实现细节，这使得从整体上关注主要概念变得更加困难。</p><p id="4326" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章可以被认为是对其他文章(列在我的“灵感”部分)的概述和理解，在更高的层次上理解这个概念。我的意图是去掉一些实现细节，对初学者来说足够高，并激发阅读原始研究论文和后续实现的好奇心。</p><h1 id="0e0c" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">目录</h1><ul class=""><li id="ee77" class="mc md it ki b kj me kn mf kr mg kv mh kz mi ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#disclaimer" rel="noopener ugc nofollow" target="_blank">免责声明</a></li><li id="91c8" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#requirements" rel="noopener ugc nofollow" target="_blank">要求</a></li><li id="2de8" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#neural-style-transfer" rel="noopener ugc nofollow" target="_blank">神经风格转移</a></li><li id="e18f" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#architectural-and-process-overview" rel="noopener ugc nofollow" target="_blank">架构和流程概述</a></li><li id="edcb" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#transfer-learning-and-style-transfer" rel="noopener ugc nofollow" target="_blank">迁移学习和风格迁移</a></li><li id="8542" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#1-transfer-learning" rel="noopener ugc nofollow" target="_blank"> 1。转移学习</a></li><li id="2dbf" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#2-style-transfer" rel="noopener ugc nofollow" target="_blank"> 2。风格转移</a></li><li id="f929" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#style-and-content" rel="noopener ugc nofollow" target="_blank">风格和内容</a></li><li id="800b" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#cost-calculation" rel="noopener ugc nofollow" target="_blank">成本计算</a></li><li id="d3e8" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#content-cost" rel="noopener ugc nofollow" target="_blank">内容成本</a></li><li id="945c" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#style-cost" rel="noopener ugc nofollow" target="_blank">款式成本</a></li><li id="6393" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#total-variation-cost" rel="noopener ugc nofollow" target="_blank">总变更成本</a></li><li id="1a91" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#inspriation" rel="noopener ugc nofollow" target="_blank">灵感</a></li><li id="f8c1" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd/Writing/blob/master/2020/articles/understandingCNN.md#about" rel="noopener ugc nofollow" target="_blank">关于</a></li></ul><h1 id="9202" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">放弃</h1><p id="c92e" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">我与本文中使用的任何服务都没有关联。</p><p id="adf6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我不认为自己是专家。如果你觉得我错过了重要的步骤或者忽略了什么，可以考虑在评论区指出来或者联系我。</p><p id="28d0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我总是乐于听取建设性的意见以及如何改进。</p><p id="f83f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">这篇文章写于2020年10月17日。我无法监控我的所有文章。当你阅读这篇文章时，提示很可能已经过时，过程已经改变。</strong></p><p id="bcf2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你需要更多关于某些部分的信息，请在评论中指出来。</p><h1 id="401c" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">要求</h1><p id="0e63" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">我假设理解卷积神经网络(CNN)。架构对于计算机视觉和深度学习中的许多事情都非常关键。网上有很多可用的资源。作为复习，我建议这篇<a class="ae kf" href="https://medium.com/@himadrisankarchatterjee/a-basic-introduction-to-convolutional-neural-network-8e39019b27c4" rel="noopener">文章</a>。</p><h1 id="0bdb" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">神经类型转移</h1><p id="99df" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">研究论文<a class="ae kf" href="https://arxiv.org/pdf/1508.06576.pdf" rel="noopener ugc nofollow" target="_blank">一种艺术风格的神经算法</a>——Leon A . Gatys，Alexander S. Ecker，Matthias Bethge</p><blockquote class="mv mw mx"><p id="a481" class="kg kh my ki b kj kk kl km kn ko kp kq mz ks kt ku na kw kx ky nb la lb lc ld im bi translated"><em class="it">在美术中，尤其是绘画，人类已经掌握了通过在图像的内容和风格之间构建复杂的相互作用来创造独特视觉体验的技能。到目前为止，这个过程的算法基础还是未知的，也不存在具有类似能力的人工系统。然而，在视觉感知的其他关键领域，如物体和人脸识别，最近一类被称为深度神经网络的生物启发视觉模型展示了接近人类的表现。在这里，我们介绍一个基于深度神经网络的人工系统，它可以创建高感知质量的艺术图像。</em></p><p id="b230" class="kg kh my ki b kj kk kl km kn ko kp kq mz ks kt ku na kw kx ky nb la lb lc ld im bi translated">该系统使用神经表示来分离和重组任意图像的内容和风格，为艺术图像的创建提供神经算法。此外，鉴于性能优化的人工神经网络和生物视觉之间惊人的相似性，我们的工作提供了一条通往人类如何创造和感知艺术意象的算法理解的道路。</p></blockquote><h1 id="3ffd" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">架构和流程概述</h1><p id="6b8e" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">对于CNN如何处理神经类型转移，有许多很好的可视化。本来想自己画的，后来发现已经有很好看的了。所以我只展示这些并引用创建者。</p><p id="b79a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是我认为很棒的。</p><p id="d978" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先是这个。它非常漂亮地展示了损失是如何计算的，以及它是如何在总体结果中组合在一起的。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/977779a03f3581271f3b0fd6a25c8704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*goi9lRLrQMuOQ8y-.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来自迈克·高斯<a class="ae kf" href="https://www.mikegao.net/graphics/summary/neural_style.html" rel="noopener ugc nofollow" target="_blank">的博客</a>和<a class="ae kf" href="https://creativecommons.org/licenses/by-nc/4.0/" rel="noopener ugc nofollow" target="_blank">的知识共享许可</a></p></figure><p id="638c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个也不错。示出了不同层上的重建过程。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nh"><img src="../Images/c4fb69732da83af6860341bd86d95b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f4HvaYeQhVnPmrgH.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来自<a class="ae kf" href="https://arxiv.org/help/license" rel="noopener ugc nofollow" target="_blank"> arxiv许可要求</a>下的<a class="ae kf" href="https://arxiv.org/pdf/1508.06576.pdf" rel="noopener ugc nofollow" target="_blank">原始研究论文</a></p></figure><p id="d1d4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了理解随后的计算，有必要说一下CNN的不同层代表什么。</p><ul class=""><li id="9160" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld mj mk ml mm bi translated">CNN的较浅层倾向于检测较低级别的特征，例如边缘和简单纹理。</li><li id="db7e" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">更深的层倾向于检测更高级的特征，例如更复杂的纹理以及对象类别。</li></ul><p id="16e5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为生成的图像应该具有与输入图像相似的内容。建议在中间使用一个层，高度表示内容。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nl"><img src="../Images/6103dc2c1a0ff20f17b395c46561a371.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GxgSk4vWT5wB_U0g.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">研究论文<a class="ae kf" href="https://www.researchgate.net/publication/334388209_Automatic_Mass_Detection_in_Breast_Using_Deep_Convolutional_Neural_Network_and_SVM_Classifier" rel="noopener ugc nofollow" target="_blank">中的VGG19架构使用深度卷积神经网络和SVM分类器</a>和<a class="ae kf" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享许可</a>进行乳房自动肿块检测</p></figure><h1 id="9b02" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">迁移学习与风格迁移</h1><p id="294f" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">另一个重要的概念是使用预先训练的网络。最常见的是VGG-19。值得注意的是，我们利用了所谓的“迁移学习”。</p><p id="deeb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里我们有两个概念需要区分:</p><ol class=""><li id="70c2" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld nm mk ml mm bi translated">迁移学习</li><li id="8eba" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld nm mk ml mm bi translated">风格转移</li></ol><p id="1524" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管两者都使用了“传输”这个词，但从实现的角度来看，它们是完全不同的。</p><h1 id="3f8f" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">1.迁移学习</h1><p id="3f97" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">这个概念本身非常有趣，并且可以通过使用已建立的模型来创建新的解决方案。</p><p id="4a03" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">精彩的介绍，我可以推荐这篇文章:<a class="ae kf" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/transfer-learning-for-deep-learning/</a>。</p><p id="71b8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">理解它在风格转换的概念中是如何使用的是至关重要的。</p><p id="c1f0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简而言之，我们可以说</p><blockquote class="mv mw mx"><p id="e367" class="kg kh my ki b kj kk kl km kn ko kp kq mz ks kt ku na kw kx ky nb la lb lc ld im bi translated"><em class="it">迁移学习和领域适应指的是这样一种情况，在一种环境中所学的知识被用来提高在另一种环境中的概括能力</em></p></blockquote><p id="fac5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这在计算机视觉中特别有用，因为这些模型的计算和训练非常耗费资源。使用一个在大型数据集上训练过的模型，其结果现在可以免费获得，实际上非常适合个人实验。</p><p id="3808" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以将迁移学习用于:</p><ol class=""><li id="685e" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld nm mk ml mm bi translated">直接使用预先训练的模型</li><li id="abd5" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld nm mk ml mm bi translated">预训练模型的特征提取</li><li id="b496" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld nm mk ml mm bi translated">改变预训练模型的最后一层的权重</li></ol><p id="b772" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的例子中，我们将使用第二种方法。使用特征提取，其中来自输出层之前的层的模型输出被用作新分类器的输入。</p><h1 id="a33d" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">2.风格转移</h1><p id="2d87" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">来自原始论文:</p><blockquote class="mv mw mx"><p id="6412" class="kg kh my ki b kj kk kl km kn ko kp kq mz ks kt ku na kw kx ky nb la lb lc ld im bi translated"><em class="it">概念上最密切相关的是使用纹理转移来实现艺术风格转移的方法。然而，这些先前的方法主要依赖于非参数技术来直接操纵图像的像素表示。相比之下，通过使用在对象识别上训练的深度神经网络，我们在明确表示图像的高级内容的特征空间中执行操作。</em></p></blockquote><p id="86bd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，这意味着深度学习方法的专长是提取图像的风格，而不是仅仅通过风格图片的像素观察，而是结合风格图像的内容提取预训练模型的特征。所以，本质上，为了发现图像的风格，我们</p><ol class=""><li id="5029" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld nm mk ml mm bi translated">通过分析样式图像的像素来处理样式图像</li><li id="17c7" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld nm mk ml mm bi translated">将该信息馈送到预训练模型的层，以“理解”/将所提供的输入分类为对象</li></ol><p id="3273" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如何做到这一点，我们将在“风格成本”一节中探讨。</p><h1 id="7d26" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">风格和内容</h1><p id="a68d" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">基本思想是将图像的风格转换为图像的内容。</p><p id="4b81" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们需要理解两件事:</p><ol class=""><li id="e547" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld nm mk ml mm bi translated">图像的内容是什么</li><li id="ea9e" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld nm mk ml mm bi translated">图像的风格是什么</li></ol><p id="0542" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不严格地说，图像的内容就是我们人类在图像中识别的对象。汽车、桥、房子等。风格更难定义。这很大程度上取决于形象。就是整体质感，选色，对比等。</p><p id="79fb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些定义需要以数学方式表达，以便在机器学习的世界中实现。</p><h1 id="dee9" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">成本计算</h1><p id="2f32" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">一、为什么要进行成本/损失计算？重要的是要明白，在这种情况下，成本仅仅是原始图像和生成图像之间的差异。关于如何计算它有多种方法(MSE、欧几里德距离等)。通过最小化图像的差异，我们能够传递风格。</p><p id="4d2e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们开始在损失上有很大差异时，我们会看到风格转移并不是那么好。我们可以看到风格的转移，但这似乎是粗糙和不直观的。随着成本最小化的每一步，我们都朝着更好地融合风格和内容的方向前进，最终得到更好的图像。</p><p id="c3b5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我们所看到的，这个过程的核心要素是损失计算。需要计算3项成本:</p><ol class=""><li id="f03c" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld nm mk ml mm bi translated">内容成本</li><li id="fe70" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld nm mk ml mm bi translated">风格成本</li><li id="759e" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld nm mk ml mm bi translated">总(变动)成本</li></ol><p id="0a34" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我看来，这些步骤是最难理解的，所以让我们一个一个地深入研究。</p><p id="7989" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请始终记住，我们是在将原始输入与生成的图像进行比较。这些差异就是成本。我们希望将这一成本降至最低。</p><p id="72f1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">理解这一点非常重要，因为在这个过程中还会计算其他差异。</p><h1 id="edef" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">内容成本</h1><p id="2100" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">什么是内容成本？正如我们之前发现的，我们通过图像的对象来定义图像的内容。我们人类能够识别的事物。</p><p id="0de9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">了解了CNN的结构后，现在很明显，在神经网络的末端，我们可以访问一个层，它很好地代表了对象(内容)。通过池层，我们失去了图像的风格部分，但就获取内容而言，这是所期望的。</p><p id="e3b4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，在不同物体的存在下，CNN的更高层中的特征地图被激活。因此，如果两幅图像具有相同的内容，它们在较高层中应该具有相似的激活。</p><p id="a769" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是定义成本函数的前提。</p><p id="e8c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下图有助于理解图层是如何展开的，以便为计算做准备(本文不涉及):</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/d9279ba11a9b1ac4c667072fd9092756.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Th3siJwhyCpUObIi.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来自<a class="ae kf" href="https://github.com/Adi-iitd/AI-Art" rel="noopener ugc nofollow" target="_blank">阿迪蒂亚·古普塔斯的文章</a>在<a class="ae kf" href="https://github.com/Adi-iitd/AI-Art/blob/add-license-1/LICENSE" rel="noopener ugc nofollow" target="_blank">麻省理工学院的许可下</a></p></figure><h1 id="900a" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">风格成本</h1><p id="7eb0" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">现在它变得越来越复杂。</p><p id="7a24" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一定要理解图像的风格和图像的风格损失之间的区别。两种计算都不一样。一个是检测“风格表示”(纹理、颜色等)，另一个是将原始图像的风格与生成图像的风格进行比较。</p><p id="680e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总样式成本分两步计算:</p><ol class=""><li id="d4e4" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld nm mk ml mm bi translated">所有卷积层的样式开销。识别样式图像的样式</li></ol><p id="e8c9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">a.从卷积层获取特征向量</p><p id="4d46" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">b.将这些向量与另一层的特征向量进行比较(找出其相关性)</p><p id="4a79" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.原之间的风格成本(原风格形象！)和生成的图像。</p><p id="cea1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了找到风格，通过将特征图与其转置相乘来捕捉相关性，从而得到gram矩阵。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/798dce6bff1d54698dd4fa8cca85d7d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TMSwaYO049ykKF2N.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来自<a class="ae kf" href="https://github.com/Adi-iitd/AI-Art" rel="noopener ugc nofollow" target="_blank">Aditya Gupta的文章</a>在<a class="ae kf" href="https://github.com/Adi-iitd/AI-Art/blob/add-license-1/LICENSE" rel="noopener ugc nofollow" target="_blank">麻省理工学院的许可下</a></p></figure><p id="d654" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">幸运的是，CNN为我们提供了多个层次，我们可以选择找到正确的风格。比较不同的层和它们的相互关系，我们可以识别图像的风格。</p><p id="22c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们不使用层的原始输出，而是使用单个层的特征图的gram矩阵来识别图像的风格。</p><p id="cf03" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一个成本是这些gram矩阵之间的差异，即相关性的差异。第二个成本也是原始图像和生成图像之间的差异。这实质上是“风格转移”。</p><h1 id="8dc0" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">总变动成本</h1><p id="8387" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">它的作用就像一个正则化器，可以提高生成图像的平滑度。这在原始论文中没有使用，但是改进了结果。本质上，我们在生成的图像中消除了风格和内容传递之间的差异。</p><h1 id="cfb3" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">灵感</h1><p id="d2d3" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">本节提供了撰写本文时使用的阅读材料。这是一个与风格转移相关的文章选集。</p><ul class=""><li id="c0a8" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld mj mk ml mm bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee">https://towards data science . com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e 46697 ee</a></li><li id="eead" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/what-is-deep-transfer-learning-and-why-is-it-becoming-so-popular-91acdcc2717a">https://towards data science . com/what-is-deep-transfer-learning-and-why-it-be-so-popular-91 acdcc 2717 a</a></li><li id="81a8" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/neural-networks-intuitions-2-dot-product-gram-matrix-and-neural-style-transfer-5d39653e7916">https://towards data science . com/neural-networks-intuitions-2-dot-product-gram-matrix-and-neural-style-transfer-5d 39653 e 7916</a></li><li id="1fd8" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/art-with-ai-neural-style-transfer-63d0ef76596a">https://towards data science . com/art-with-ai-neural-style-transfer-63d 0 ef 76596 a</a></li><li id="c398" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://medium.com/@sanjivgautamofficial/understanding-neural-style-transfer-from-another-medium-post-c61d19afdf1d" rel="noopener">https://medium . com/@ sanjivgautamoficial/understanding-neural-style-transfer-from-another-medium-post-c 61d 19 af df1d</a></li><li id="a47d" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/transfer-learning-for-deep-learning/</a></li><li id="bbda" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-use-transfer-learning-when-development-convolutionary-neural-network-models/</a></li><li id="fa77" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/aleju/papers/blob/master/neural-nets/A_Neural_Algorithm_for_Artistic_Style.md" rel="noopener ugc nofollow" target="_blank">https://github . com/aleju/papers/blob/master/Neural-nets/A _ Neural _ Algorithm _ for _ Artistic _ style . MD</a>发表论文摘要</li><li id="bb77" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">【https://www.mikegao.net/graphics/summary/neural_style.html】by<a class="ae kf" href="https://www.mikegao.net/" rel="noopener ugc nofollow" target="_blank">麦克高</a></li><li id="1437" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Adi-iitd/AI-Art" rel="noopener ugc nofollow" target="_blank">https://github.com/Adi-iitd/AI-Art</a></li></ul><p id="9626" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码实现:</p><ul class=""><li id="02ee" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld mj mk ml mm bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/neural-style-transfer-4d7c8138e7f6">https://towards data science . com/neural-style-transfer-4d 7c 8138 E7 f 6</a></li><li id="73b5" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="http://ziqingguan.net/index.php/2020/05/30/deep-learning-art-neural-style-transfer/" rel="noopener ugc nofollow" target="_blank">http://ziqing Guan . net/index . PHP/2020/05/30/deep-learning-art-neural-style-transfer/</a></li><li id="bd39" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://www.tensorflow.org/tutorials/generative/style_transfer" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/tutorials/generative/style _ transfer</a></li><li id="dcd2" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398" rel="noopener">https://medium . com/tensor flow/neural-style-transfer-creating-art-with-deep-learning-using-TF-keras-and-eager-execution-7d 541 AC 31398</a></li><li id="355f" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://medium.com/analytics-vidhya/nst-creating-artworks-with-the-help-of-machine-56ebd3eb780c" rel="noopener">https://medium . com/analytics-vid hya/NST-creating-artworks-with-the-help-of-the-machine-56 EBD 3 EB 780 c</a></li><li id="c4ec" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://keras.io/examples/generative/neural_style_transfer/" rel="noopener ugc nofollow" target="_blank">https://keras.io/examples/generative/neural_style_transfer/</a></li><li id="6931" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://medium.com/gradientcrescent/neural-art-style-transfer-with-keras-theory-and-implementation-91b7fb08ee81" rel="noopener">https://medium . com/gradient crescent/neural-art-style-transfer-with-keras-theory-and-implementation-91 b 7 FB 08 ee 81</a></li></ul><p id="9884" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">研究论文:</p><ul class=""><li id="8382" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld mj mk ml mm bi translated"><a class="ae kf" href="https://arxiv.org/pdf/1508.06576.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1508.06576.pdf</a>一种艺术风格的神经算法</li><li id="b71f" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://arxiv.org/pdf/1701.01036.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1701.01036.pdf</a>揭秘神经类型转移</li></ul><h1 id="618e" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">关于</h1><p id="6c47" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">丹尼尔是一名企业家、软件开发人员和商业法毕业生。他曾在各种IT公司、税务咨询、管理咨询和奥地利法院工作。</p><p id="365f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">他的知识和兴趣目前围绕着编程机器学习应用程序及其所有相关方面。从本质上说，他认为自己是复杂环境的问题解决者，这在他的各种项目中都有所体现。</p><p id="4250" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您有想法、项目或问题，请不要犹豫与我们联系。</p><p id="667e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以在https://www.buymeacoffee.com/createdd<a class="ae kf" href="https://www.buymeacoffee.com/createdd" rel="noopener ugc nofollow" target="_blank">上支持我</a></p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div class="gh gi np"><img src="../Images/d43c79beeeb321b32c2d0b2d6d7a0f26.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/0*mzNRtzHVWD8fTYms"/></div></figure><p id="9b0a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">连接到:</p><ul class=""><li id="6427" class="mc md it ki b kj kk kn ko kr ni kv nj kz nk ld mj mk ml mm bi translated"><a class="ae kf" href="https://www.linkedin.com/in/createdd" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="7b3e" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd" rel="noopener ugc nofollow" target="_blank"> Github </a></li><li id="557a" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://medium.com/@createdd" rel="noopener">中等</a></li><li id="17de" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://twitter.com/_createdd" rel="noopener ugc nofollow" target="_blank">推特</a></li><li id="830a" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://www.instagram.com/create.dd/" rel="noopener ugc nofollow" target="_blank"> Instagram </a></li><li id="c7a0" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://www.createdd.com/" rel="noopener ugc nofollow" target="_blank">createdd.com</a></li></ul></div></div>    
</body>
</html>