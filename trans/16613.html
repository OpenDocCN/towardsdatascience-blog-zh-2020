<html>
<head>
<title>Complete Introduction to PySpark-Part 4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PySpark完整介绍-第4部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/complete-introduction-to-pyspark-part-4-62a99ce3552a?source=collection_archive---------14-----------------------#2020-11-16">https://towardsdatascience.com/complete-introduction-to-pyspark-part-4-62a99ce3552a?source=collection_archive---------14-----------------------#2020-11-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c41c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用PySpark执行数据可视化</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4de1974fc0d3badfe5c96b46cd185a7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5ExcEFCFFL6LqP10"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">威廉·艾文在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="3b6c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据可视化</h1><p id="c05b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">数据可视化在数据分析中起着重要的作用，因为只要人眼看到一些图表或图形，他们就会试图在该图形中找到模式。</p><p id="d020" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">数据可视化是使用不同的图/图形/图表直观地表示数据，以找出模式、异常值以及数据集不同属性之间的关系。它是数据的图形表示。</p><h1 id="8a41" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">使用PySpark实现数据可视化</h1><p id="0f06" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们可以使用PySpark执行数据可视化，但在此之前，我们需要在本地机器上设置它。为了在您的本地机器上安装PySpark并对PySpark的工作原理有一个基本的了解，您可以浏览下面的文章。</p><div class="ms mt gp gr mu mv"><a href="https://medium.com/python-in-plain-english/complete-introduction-to-pyspark-part-1-7d16d7c62cc9" rel="noopener follow" target="_blank"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">PySpark完整介绍</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">第1部分:从头开始在Windows上安装PySpark</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">medium.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj ks mv"/></div></div></a></div><div class="ms mt gp gr mu mv"><a rel="noopener follow" target="_blank" href="/complete-introduction-to-pyspark-part-2-135d2f2c13e2"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">PySpark完整介绍-第2部分</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">使用PySpark进行探索性数据分析</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="nk l ng nh ni ne nj ks mv"/></div></div></a></div><p id="7d31" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">安装PySpark之后，让我们从打开jupyter笔记本并加载所需的库开始。</p><h1 id="cd92" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">加载所需的库</h1><p id="e497" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们将从加载所有需要的库和创建PySpark会话开始。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="8d43" class="nq la it nm b gy nr ns l nt nu">import findspark<br/>findspark.init()</span><span id="b896" class="nq la it nm b gy nv ns l nt nu">import pyspark # only run after findspark.init()<br/>from pyspark.sql import SparkSession<br/>from pyspark.sql import SQLContext</span><span id="3608" class="nq la it nm b gy nv ns l nt nu">import seaborn as sns<br/>import matplotlib.pyplot as plt</span><span id="2fa9" class="nq la it nm b gy nv ns l nt nu">spark = SparkSession.builder.getOrCreate()</span></pre><h1 id="06e4" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">加载数据集</h1><p id="3f7b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本文中，我们将使用PySpark执行数据可视化，为此我们将使用波士顿数据集，该数据集可从Kaggle下载。让我们加载数据并开始可视化。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="6200" class="nq la it nm b gy nr ns l nt nu">df = spark.read.csv('Boston.csv', inferSchema=True, header=True)<br/>df.show(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/d54a834c4dcad05f51595cb370892082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RkS-eByHvdlObWCik-hgBg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集(来源:作者)</p></figure><h2 id="e5fa" class="nq la it bd lb nx ny dn lf nz oa dp lj ma ob oc ll me od oe ln mi of og lp oh bi translated">创建饼图</h2><p id="457f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在创建可视化之前，我们需要使用SQL创建一个数据集的表，以便了解更多关于使用PySpark的SQL操作。</p><p id="3e14" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用SQL创建一个表，并运行所需的查询来相应地生成一个饼图。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="ae78" class="nq la it nm b gy nr ns l nt nu">#Creating Table<br/>df.registerTempTable('BostonTable')<br/>sqlContext = SQLContext(spark)</span><span id="4d73" class="nq la it nm b gy nv ns l nt nu">#Running Query<br/>df1 = sqlContext.sql("SELECT * from BostonTable").toPandas()<br/>df2 = sqlContext.sql("SELECT AGE, TAX from BostonTable where LSTAT &lt; 2").toPandas()</span><span id="261f" class="nq la it nm b gy nv ns l nt nu">#Creating Visualization<br/>fig = plt.pie(df2['AGE'], autopct='%1.1f%%', startangle=140,labels=df2['AGE'])<br/>plt.title('No of age group where lstat &lt; 2')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/bea4bbfa915a187eeb537da61e144bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*UBMzVE2vV8Ico2T121ojFQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">饼状图(来源:作者)</p></figure><p id="c63c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">类似地，我们可以对不同的输出运行不同的查询，因此我们可以改变饼图的可视化。</p><h2 id="813c" class="nq la it bd lb nx ny dn lf nz oa dp lj ma ob oc ll me od oe ln mi of og lp oh bi translated">相关矩阵</h2><p id="6caa" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">相关矩阵用于分析和可视化数据集不同列之间的关系。让我们看看如何使用PySpark创建一个相关矩阵。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="de8b" class="nq la it nm b gy nr ns l nt nu">df1.corr().style.background_gradient(cmap='coolwarm').set_precision(2)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/2779c7ac1b4c9a689ee7d87b5eaf6b36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Q0dcekibg2H-OVj7SkpKA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">相关性(来源:作者)</p></figure><p id="21a1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">类似地，我们可以创建不同类型的可视化，如盒状图、小提琴图、条形图等。下面给出了这些图的一些例子。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="b8de" class="nq la it nm b gy nr ns l nt nu">#box plot<br/>plt.boxplot(df2)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/a746f3b745cd072f22077c051a8cc8aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*TEibt8_ej2HXaOPC-3hFBg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">方框图(来源:作者)</p></figure><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="0028" class="nq la it nm b gy nr ns l nt nu">#Scatter Plot<br/>df3 = sqlContext.sql("SELECT PTRATIO, TAX from BostonTable").toPandas()<br/>fig=plt.figure()<br/>ax=fig.add_axes([0,0,1,1])<br/>ax.scatter(df3['TAX'],df3['PTRATIO'], color='r')<br/>ax.set_xlabel('TAX')<br/>ax.set_ylabel('PTRATIO')<br/>ax.set_title('scatter plot')<br/>plt.title('PTRATIO Vs TAX')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/bfd3a774a0518cd463c774ad69868e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*nJ09dJP3XUgDZh7Hns039w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">散布(来源:作者)</p></figure><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="a139" class="nq la it nm b gy nr ns l nt nu">#Violoin Plot<br/>df5 = sqlContext.sql("SELECT RM from BostonTable").toPandas()<br/>fig = plt.figure()<br/>ax = fig.add_axes([0,0,1,1])<br/>bp = ax.violinplot(df5['RM'])<br/>plt.title('Average number of rooms per dwelling')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/71cd79174a96ef8ad776c1538dad87f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*CjfKho61FRO_hzetoMrLvQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">小提琴情节(来源:作者)</p></figure><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="6945" class="nq la it nm b gy nr ns l nt nu">#3d Scatter Plot<br/>df6 = sqlContext.sql("SELECT CHAS, NOX, RM from BostonTable").toPandas()<br/>fig = plt.figure()<br/>ax = plt.axes(projection='3d')<br/>ax.scatter(df6['CHAS'], df6['NOX'], df6['RM'])<br/>ax.set_title('CHAS Vs NOX Vs RM')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/509a530bca31b32d8b7234cb4138a505.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*QftoTgQWeOW4VFEqr5xx6A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">3D绘图(来源:作者)</p></figure><p id="125c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">本文为您提供了关于使用PySpark进行数据可视化的基本信息。继续尝试这些，如果你遇到任何困难，请在回复部分告诉我。</p><h1 id="d125" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">在你走之前</h1><p id="7f26" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu"> <em class="oo">感谢</em> </strong> <em class="oo">的阅读！如果你想与我取得联系，请随时通过hmix13@gmail.com联系我或我的</em> <a class="ae ky" href="http://www.linkedin.com/in/himanshusharmads" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> <em class="oo"> LinkedIn个人资料</em> </strong> </a> <em class="oo">。可以查看我的</em><a class="ae ky" href="https://github.com/hmix13" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu"><em class="oo">Github</em></strong><em class="oo"/></a><em class="oo">简介针对不同的数据科学项目和包教程。还有，随意探索</em> <a class="ae ky" href="https://medium.com/@hmix13" rel="noopener"> <strong class="lt iu"> <em class="oo">我的简介</em> </strong> </a> <em class="oo">，阅读我写过的与数据科学相关的不同文章。</em></p></div></div>    
</body>
</html>