<html>
<head>
<title>Humans in the loop</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">循环中的人类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/humans-in-the-loop-ac3699040380?source=collection_archive---------44-----------------------#2020-11-11">https://towardsdatascience.com/humans-in-the-loop-ac3699040380?source=collection_archive---------44-----------------------#2020-11-11</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><h2 id="11ef" class="it iu iv bd b dl iw ix iy iz ja jb dk jc translated" aria-label="kicker paragraph"><a class="ae ep" href="https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2" rel="noopener ugc nofollow" target="_blank">苹果</a> | <a class="ae ep" href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz" rel="noopener ugc nofollow" target="_blank">谷歌</a> | <a class="ae ep" href="https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU" rel="noopener ugc nofollow" target="_blank"> SPOTIFY </a> | <a class="ae ep" href="https://anchor.fm/towardsdatascience" rel="noopener ugc nofollow" target="_blank">其他</a></h2><div class=""/><div class=""><h2 id="0740" class="pw-subtitle-paragraph kb je iv bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">迪伦·哈德菲尔德-梅内尔在<a class="ae kt" href="https://towardsdatascience.com/tagged/tds-podcast" rel="noopener" target="_blank"> TDS播客</a></h2></div><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="kz la l"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">要选择章节，请访问我们的Youtube视频<a class="ae kt" href="https://youtu.be/NfElDoZ5O4Y" rel="noopener ugc nofollow" target="_blank">此处</a>。</p></figure><p id="2223" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated"><strong class="lh jf"> <em class="mb">编者按</em> </strong> <em class="mb">:这一集是我们关于</em> <a class="ae kt" rel="noopener" target="_blank" href="/emerging-problems-in-data-science-and-machine-learning-36d37f6531a8"> <em class="mb">数据科学和机器学习中出现的问题</em> </a>，<em class="mb">的播客系列的一部分，由Jeremie Harris主持。除了主持播客，Jeremie还帮助运营一家名为</em><a class="ae kt" href="http://sharpestminds.com" rel="noopener ugc nofollow" target="_blank"><em class="mb">sharpes minds</em></a><em class="mb">的数据科学导师初创公司。可以听下面的播客:</em></p><figure class="ku kv kw kx gt ky"><div class="bz fp l di"><div class="mc la l"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">收听<a class="ae kt" href="https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2" rel="noopener ugc nofollow" target="_blank">苹果</a>、<a class="ae kt" href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz" rel="noopener ugc nofollow" target="_blank">谷歌</a>、<a class="ae kt" href="https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU" rel="noopener ugc nofollow" target="_blank"> Spotify </a></p></figure><p id="4e0c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">在越来越多的高风险任务中，人类正在与人工智能合作。我这里说的不仅仅是机器人辅助手术或无人驾驶汽车——每天，社交媒体应用程序都向我们推荐内容，这些内容确实塑造了我们的世界观和文化。我们中很少有人知道这些非常重要的建议是如何产生的。</p><p id="a0de" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">随着时间的推移，我们可能会越来越依赖我们的机器，将越来越多的思考外包给它们。如果我们不考虑我们做这件事的方式，我们可能会创造一个不反映我们当前价值观或目标的世界。这就是为什么人类/人工智能协作和互动的领域如此重要——这也是我想在本期“走向数据科学”播客中与伯克利人工智能研究员迪伦·哈德菲尔德-梅内尔交谈的原因。迪伦的工作专注于设计可以让人类和机器人更具建设性地合作的算法，他是专注于人工智能伦理和人工智能对齐领域的一个小型但不断增长的人工智能研究人员群体之一。</p><p id="154d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">以下是我们谈话中我最喜欢的一些带回家的东西:</p><ul class=""><li id="cf4f" class="md me iv lh b li lj ll lm lo mf ls mg lw mh ma mi mj mk ml bi translated">当我们处理某些人工智能问题时，我们做出的一个基本选择是决定将世界的哪一部分视为“问题解决代理”，以及将世界的哪一部分视为“环境”。当我们考虑人类/人工智能交互时，这变得更加重要:我们应该将人工智能视为代理，将人类+世界其他部分视为其环境，还是想象人类+人工智能实际上是一个集成的代理，它们一起面对周围的世界？迪伦的研究采用了第二种方法，试图更好地理解人类和机器如何合作解决实际问题。</li><li id="8596" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">如果你说“我认为学生的考试成绩是衡量教师表现的一个很好的指标”，你可以预期教师将开始改变他们的教学风格以提高学生的考试成绩，即使这意味着牺牲实际的学生学习(例如，通过强调教师认为可能在考试中出现的主题或问题，而不是对学生更有普遍价值的主题)。类似地，当政客们开始将股市视为整体经济表现的代表时，他们就有动机采取牺牲公民金融福祉的举措来推动股指上涨。这个问题被称为古德哈特定律:一旦你指定了一个你想要优化的指标(如股票指数，或学生考试成绩)，人们就会开始攻击这个指标，随着时间的推移，它将失去作为你真正关心的事情(经济的健康状况，或教育质量)的代表的价值。</li><li id="982e" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">古德哈特定律也适用于人工智能系统，因为人工智能通常被训练来优化目标函数——一种旨在反映我们所重视的结果的目标指标。不幸的是，选择真正捕捉我们想要的目标函数非常困难；更常见的情况是，它们与我们认为自己想要的东西相差甚远，这可能会产生危险的影响。例如，我们可能认为自动驾驶汽车的一个好的目标函数是最小化到达某个指定目的地的总驾驶时间，但当然，最小化驾驶时间的路径几乎肯定既不安全，也不合法。因为机器从字面上理解它们的目标函数，所以它们经常提出原创但高度病态的解决方案，这些解决方案往往随着它们变得越来越聪明而变得越来越原创、越来越病态。</li><li id="4459" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">在将人工智能与人类价值观对齐时，一个重要的考虑因素是分布外采样的风险，在这种情况下，人工智能遇到的样本与其在训练中遇到的样本表现不一样。迪伦最近的一些工作专注于培训代理，当他们所处的环境与他们的培训环境不匹配时，他们可以注意到他们在培训期间学到的经验教训。随着人工智能比人类更有能力评估其训练的上下文相关性，这种鲁棒性将变得越来越重要。</li></ul><p id="9e7e" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">你可以<a class="ae kt" href="https://twitter.com/dhadfieldmenell" rel="noopener ugc nofollow" target="_blank">在推特上关注迪伦</a>，你也可以<a class="ae kt" href="https://twitter.com/jeremiecharris" rel="noopener ugc nofollow" target="_blank">在推特上关注我</a>。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi mr"><img src="../Images/91646fa55c3b18c517e5d2a4548e50e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3lw6S3_BZbh7w1qoETEGdA.png"/></div></div></figure><h2 id="3d23" class="my mz iv bd na nb nc dn nd ne nf dp ng lo nh ni nj ls nk nl nm lw nn no np jb bi translated">章节:</h2><ul class=""><li id="0d7c" class="md me iv lh b li nq ll nr lo ns ls nt lw nu ma mi mj mk ml bi translated">0:00介绍</li><li id="75b1" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">1:57迪伦的背景</li><li id="1465" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">4:58价值取向问题</li><li id="f23b" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">8:15简化流程的最佳实践</li><li id="9048" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">12:39确定损失函数的长期目标</li><li id="4f69" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">14:07人工智能变得“更加复杂”</li><li id="c2b3" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">18:15人类幸福的例子</li><li id="5d69" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">21:51迪伦的研究</li><li id="82ac" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">27:51艾的结论</li><li id="7210" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">32:59其他选项</li><li id="6ff4" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">38:30进化优化过程</li><li id="dc3e" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">42:55抽象级别</li><li id="7ff3" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">47:49系统安全</li><li id="895a" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">51:50艾绝对主义</li><li id="8683" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">54:34机器人与人类的互动</li><li id="ce72" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">1:02:25生产力和社交媒体</li><li id="6203" class="md me iv lh b li mm ll mn lo mo ls mp lw mq ma mi mj mk ml bi translated">1:03:40总结</li></ul></div><div class="ab cl nv nw hz nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="io ip iq ir is"><h2 id="a0c1" class="my mz iv bd na nb nc dn nd ne nf dp ng lo nh ni nj ls nk nl nm lw nn no np jb bi translated">下面是第二季第四集的脚本:</h2><p id="66d9" class="pw-post-body-paragraph lf lg iv lh b li nq kf lk ll nr ki ln lo oc lq lr ls od lu lv lw oe ly lz ma io bi translated">杰里米(00:00:00): <br/>大家好，我是杰里米，播客的主持人，也是最敏锐思维数据科学导师项目团队的一员。我今天带来了一个非常激动人心的插曲，事实上，我们正在和迪伦谈话，他是加州大学伯克利分校的一名研究员。他实际上在那里完成了他的博士学位，在那里他一直在研究不同类型的人机交互，人类与人工智能的交互，他的目标是弄清楚人类和人工智能如何以一种更积极的方式相互作用。</p><p id="f219" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:00:30): <br/>每当人类需要向人工智能传达他们的偏好时，人们经常会担心他们的偏好可能会被误解。人工智能系统越强大，误解造成的伤害就越大。迪伦专注于让人类与人工智能系统高效沟通的方案，并探索不同的方式来设置系统，使它们最大限度地保持稳健。这里的希望是人工智能将在某种程度上学会适度的谦逊和不确定性，特别是当他们要去执行真正重要的行动，真正重要的行动时。</p><p id="f154" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:01:05): <br/> Dylan正在研究这个问题，他也对所谓的人工智能对齐问题更感兴趣，即我们如何让人工智能按照我们希望的方式行事。我真的很兴奋能和他说话。他有各种各样的深刻见解，包括对人工智能调整真正意味着什么以及如何建立与我们的价值观正确一致的系统的新观点。我真的很期待能深入其中。我希望你喜欢这次谈话，我们在另一方面再见。</p><p id="891c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">杰瑞米(00:01:30): <br/>你好，迪伦，非常感谢你参加我的播客。</p><p id="dee9" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:01:34): <br/>很高兴来到这里。谢谢你邀请我。</p><p id="825a" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">杰瑞米(00:01:35): <br/>你能来这里我真的很兴奋。你是专注于人工智能安全问题的研究人员中的一员，这个研究队伍正在不断壮大，但仍然相当小。当然，你有一个专业，一个你关注的子领域，我很想听听你的看法，首先是你是如何做到这一点的，你是如何开始关注人工智能安全的，然后是你目前的研究是什么样的。</p><p id="26af" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:01:57): <br/>我的研究起源故事，如果你愿意，开始于机器人的集成任务和运动规划。我感兴趣的是如何让机器人帮你洗衣服。这涉及到长期的规划和许多实际系统建设的细节。在建立这个系统的过程中，你要做的一件关键事情就是解决一个叫做运动规划的问题。有很多不同的方法可以解决这个问题。我们使用的一种方法是轨迹优化。但是运动规划的概念是，你已经让你的机器人处于一个特定的配置，你已经有了一个你想让它朝着的目标配置，你需要找出一系列的关节控制，实际上把你从初始位置带到目标位置，而不会碰到任何东西。</p><p id="8b48" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:02:49): <br/>事实证明，这是一件非常困难的事情，也是我们在日常生活中认为理所当然的人类智慧的例子之一。长话短说，在应用轨迹优化时，你要做的是指定一个成本函数，对不同的轨迹，从A点到b点的不同方式进行排序。它会说，发生碰撞非常糟糕。但是更快到达那里也是好的。</p><p id="1105" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:03:20): <br/>你最终必须指定这些权衡，这些权重。在我的一些演讲中，我举了一个界面的例子，展示了你所经历的这种设计过程，比如说，你在避免碰撞的效果和你想要的速度之间进行权衡。</p><p id="c226" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:03:40): <br/>最终，我意识到这些重量代表了你想要什么样的轨迹。在指定这些目标时，这实际上是一种编程过程，其中我们指定我们想要什么类型的行为。你可以在一大堆不同的人工智能环境中看到这种类型的范式，其中我们将指定我们想要什么的问题简化为某种奖励函数或得分函数。在强化学习的情况下，这是一种类似于度量或奖励函数的东西。在监督学习的情况下，这是数据集上的经验损失函数。你可以想出很多其他的例子，我们真的把我们的偏好编码到这些排名函数中，这些类型的效用函数，然后用通用的方法来优化它们。</p><p id="ce7f" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:04:39): <br/>大约两年后，在解决这些问题并熟悉这种模式后，我开始将我的研究转向研究这个问题的实际情况，以及做好它意味着什么，以及我们可以尝试避免哪些陷阱？这就是我认为的人工智能中的价值定位问题。</p><p id="853c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:04:58): <br/>好的，这就是我们所理解的……你对价值调整问题的描述包括提出我们想要优化的参数。这样说公平吗？它包括损失函数。</p><p id="3a2a" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:05:12): <br/>对。在某种程度上，你可以把损失函数看作一种编程语言，我们可以把优化看作一种编译器，你可以从一种表示，比如说，一种分类行为，从像素到二进制01的映射，相机狗。最终，会有一些行为集合，一些权重集合来代表对事物进行适当的分类。我们不知道如何手工编程，那太疯狂了。但同时，我们也不知道如何直接用机器代码编程。</p><p id="0b3c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:05:48): <br/>对。</p><p id="ca70" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:05:50): <br/>我认为你可以在这种快速可执行的行为表现形式(类似于神经网络的权重)和我们为获得这些行为而优化的目标(即捕捉我们对猫的图片的概念的数据集)之间进行很好的类比。</p><p id="a843" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:06:11): <br/>有意思。我想这种类比的一个有趣的结果是，它很好地映射了某人第一次尝试编程的主观体验，以及某人尝试做一种幼稚的机器学习。当我第一次编程时，我会对机器感到非常沮丧，因为我会告诉它做一些事情，而我的代码会中断，机器会明确无误地告诉我，“嘿，你犯了一个错误。”我不能接受。我一直在想，嗯，不，我没有犯错。很明显，你没有正确理解我让你做的事情。</p><p id="e7f5" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:06:44): <br/>当然，我现在认识到这是一个愚蠢的错误。但是看起来我们正在犯类似的错误，或者至少我们有可能在机器学习上犯类似的错误，在机器学习中，我们只是字面上的而不是认真的，比如说机器。就对齐问题的来源而言，这是两者之间的公平映射吗？</p><p id="6700" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:07:06): <br/>是的，我想是的。我认为这就像在你有真正好的编译器之前，你工作在基准代码上，或者你不知道人们对写什么程序感兴趣，你写的编译器工作在你最好的表示上。有一些特定的程序是用来复制你可能需要编译的某些类型的负载的，比如内存管理中的快速数据访问或者类似的东西。但归根结底，它们是综合问题。如果你看看人工智能，那么，我认为科学界对什么是智能以及这类问题有着普遍的兴趣。但是，实际上，如果你想想我们实际上使用这些系统是为了什么，我们有数据集来表示我们希望能够做的事情，这很好，非常非常有用。但这并不能帮助我们练习这个过程，这是我们如何对我们想要的东西有一个非常松散的想法，然后同意如何以某种方式来表示它，我们实际上可以训练一个系统来做我们想要的事情。</p><p id="0630" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:08:15): <br/>现在出现了什么样的最佳实践，或者你正在制定什么样的策略来简化这一过程？我们如何帮助人类更好地指定他们想要什么，以便机器人不会离开并做错事情？</p><p id="351d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:08:30): <br/>老实说，我认为它的很大一部分是重新定义从事机器学习或作为机器学习工程师的人的规则。如果你想一想你在ML入门课程中学到了什么。你走进去，就像第一天，标准的，有指导的学习。我记得很清楚，对我来说，第一天，就像，嗯，一个监督学习问题由一个数据集，一组标签，一个损失函数，一个假设类组成，对吗？这就是问题的定义。</p><p id="ed78" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:09:11): <br/>这真的很好，但这就像说，嗯，程序是由来自一些语法的一组术语定义的，而您的工作是将它们忠实地转换成机器代码。它是准确的，但它没有关注实际使这些系统工作的方面，这些系统通常与您实际获取数据的方式有关，确保数据标记过程实际上与您关心的世界中的因果机制相关联。监控数据流并确保数据不会随时间推移而移动。</p><p id="ab91" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:09:47): <br/>我认为最终的问题是，如何建立一个包含人类和机器人的系统，最终确保系统表现出的行为代表我们可以与人的目标联系起来的东西。这听起来不像是一个超级具体的建议。但我认为，其中一部分只是认识到，通过更仔细地了解从哪里获得数据、如何标记数据以及如何实际解决问题，可以解决多少问题。</p><p id="3c98" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:10:22): <br/>我这里的一个经典例子与招聘场景有关，在这里你可以看这个问题，你可以说，我认为，好的招聘意味着什么？嗯，我想我需要在绩效评估中表现出色的人。我想学会预测谁会得到好的绩效评估。我觉得这听起来很有道理。如果你没有非常仔细地思考这代表了什么，以及这与你的公司或国家的历史或不同的背景有什么关系，这是一个非常好的方法。我认为，如果你想得更多一点，你会开始意识到，实际上编码为，我们如何才能雇用我们过去想雇用的人？</p><p id="4d11" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:11:13): <br/>这是一个非常有趣的问题，但可能不是为了雇佣你现在想雇佣的人而应该优化的问题，也不是你应该认真考虑的问题。假设在过去和现在之间发生转移，事情会出现在招聘偏见方面，有些公司已经有了评估候选人的偏见系统。然后，这些公司投入了大量的时间，他们雇佣了谁，他们如何进行培训，以及他们如何进行招聘过程，以消除这方面的偏见。</p><p id="305e" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:11:51): <br/>然后，与此同时，你引入训练有素的系统来复制这种偏见，并以一种新的方式引入这种偏见。我认为这是一个失败，没有真正思考我正在解决的问题的重要部分，而不是关注我可以从我的模型中获得什么样的AUC？这是您最终要达到的目标，坦白地说，也是一个更容易衡量的目标。如果你是一家公司的工程师，你正在努力争取升职，那将会…拥有这样的机会肯定是你想要达到的目标，而且更难描述和量化的工作是确保我们确实在解决我们最初真正想要解决的问题。</p><p id="5075" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:12:39): <br/>嗯，这似乎引发了人们对古德哈特定律的一些思考，也就是说，当你定义了一个你想要优化的指标时，如果它值得优化，它就不再是一个指标，因为人们会在它周围找到巧妙的方法。我想，对于古德哈特定律的应用，我的一个担心是，这是否意味着，这是一个棘手的问题，甚至是试图确定一个损失函数，这是我们应该长期努力的目标？</p><p id="db2b" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:13:12): <br/>我认为这是一个非常好的问题。我认为…在高层次上…我们应该讨论古德哈特定律是什么吗-</p><p id="f36b" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:13:25): <br/>实际上是的。</p><p id="0cc7" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:13:25):<br/>……再深入一点？</p><p id="8e69" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:13:27): <br/>根据我的理解，古德哈特定律是这样一种想法，例如，当你选择一个你想要优化的指标时，比如Twitter上的粉丝，你可能会在第一天认为这将导致你做出你会与你钦佩的人联系在一起的行为。如果我在Twitter上有很多关注者，我会成为一个我崇拜的人。但是你意识到你想的越多，你花在优化这个指标上的时间和精力就越多，你开始意识到它们是你可以应用的小技巧。你可以玩一个跟随，跟随回来的游戏，或者你可以在Twitter上说一些让你获得更多追随者的离谱的事情，即使它并不能帮助你在你最初想做的事情上取得进展。</p><p id="cc85" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:14:07): <br/>我想这里的想法是人工智能系统，随着它们变得越来越复杂，特别是当它们在解决几乎任意任务时开始完全超过人类的表现，我们将能够投入计算周期，使人类对特定指标的适应能力相形见绌。最终，不管你指定什么样的损失函数，你都会得到离谱的解。无论你花多少时间去思考一个你想要优化的目标函数，机器都会找到一种方法做得很好，以至于超越了程序的最初目的。</p><p id="3e82" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:14:41): <br/>对。我认为这是一个很好的总结，我认为涵盖了相当广泛的范围。让我们先把古德哈特定律和人工智能之间的关系放在一边，只关注古德哈特定律的种类，以及它是如何出现在人们身上的，因为它最终是从那里产生的。之所以这样表述，是因为古德哈特实际上是在说，没有能力实施有效的货币政策，这有点奇怪。但它基本上是说，在某些方面，人们有自己的目标和目的。如果你改变一个标准，你不太可能真正有意义地改变他们的行为，他们只会适应。因此，您将看到使您的指标上升的最小可能变化，这实际上不会改变他们正在做的事情。</p><p id="3a7e" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:15:43): <br/>我认为，正如人工智能，特别是安全，人工智能系统和社会科学中的人们更广泛地解释的那样，一般来说，有一种观察认为这是一种特殊的说法，即当处于优化压力下时，观察到的统计相关性，或者我可能弄错了它的细节，将不会停止存在。</p><p id="5ba2" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:16:11): <br/>我认为，如果你以更一般的形式来看待这个问题，你会发现写下一个奖励函数或指定你的目标是不可靠的。我认为，从很多方面来说，这是我们在生活中一直在处理的事情，在某种程度上，我们都有不同的激励计划，我们要么受制于，要么取决于你可能强加给别人的情况，如果你教学生，你会想很多你实施的激励计划，以及那些计划的含义。</p><p id="ac5a" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:16:52): <br/>我还认为，如果你有员工，你会想到如何衡量他们的表现，这也会带来类似的问题。你可以思考不同测量方法的含义，以及人们围绕它们工作的方式。对他们想要的东西有一些默认的偏见，他们会稍微改变他们的行为。但在很多情况下，如果有人信任你，你可以让他们的行为朝着你想要的方向转变，而不必使用激励手段。激励机制非常脆弱，这是我的总结。有一种方法，你可以…你指定的目标中的一点点误差似乎会被放大。</p><p id="4edb" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:17:41): <br/>这很有意思。当你接近参数空间中的峰值时，你会说误差的放大，或者说误差越来越明显？我想，我试图想象这一点的方式，如果我在这里完全显而易见，请纠正我，但我在想象一个人工智能系统，它试图…基本上，它是一个优化器，它试图在参数空间中攀登一个高峰。我们希望这一高峰的顶点将与我们真正深切渴望的结果相吻合。</p><p id="fc33" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:18:15): <br/>我告诉我的AI，我想让你让股票市场上涨。可能是我分配给它的最后一个功能。但我真正想要的是我希望它能让所有人都非常非常开心。</p><p id="0302" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:18:27): <br/>当然。</p><p id="1e23" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:18:27): <br/>最初在黑暗时代，当一切都是绝对的垃圾时，股票市场的顶峰似乎与让人们快乐不谋而合，因为从远处看，让股票市场真正高涨和让所有人真正快乐之间的差异相对来说似乎很小，但是只有当我们开始攀升时，我们才注意到，哇，这两个目标之间开始出现巨大的差异。这是一个准确的框架吗？</p><p id="8f2e" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:18:54): <br/>我认为这在某种程度上是存在的，尽管我不确定这是否有助于建立直觉。作为一个目标，让所有人快乐的一件大事是，有很多人甚至不同意你可以达成一致的方式来表达这意味着什么。比方说，我认为这带来了一层我们现在可能想要回避的复杂性。但我认为，如果你想象为了考试而教学，这是一种本质，在某种程度上，为sat而学习确实有助于你变得更聪明，或者在某些类型的数学方面变得更好。总的来说，有些事情你必须做得更好。但是一旦你达到了某一点，我认为大多数试图申请大学的人都会以某种方式达到这一点，除了擅长考试之外，为此而学习不会让你在任何事情上变得更好。</p><p id="2c7f" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:20:04): <br/>是的。</p><p id="5371" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:20:06): <br/>我认为是那种感觉真正推动了这些事情。如果我们想思考人工智能系统，有一些非常明显的例子，我们实际上已经作为一个领域处理过了。对我来说，我觉得最大的一个就是过拟合。如果我们考虑什么是过度拟合，这是观察，嗯，你想优化真正的风险。虽然你没有真正的风险，但你有经验风险。在一段时间内，优化经验风险是有帮助的，过一段时间后，就没有帮助了，过一段时间后，它就变得与真实风险完全无关了。</p><p id="a065" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:20:55): <br/>仔细想想，我们在预测方面所做的大量工作都是为了应对和克服经验风险和真实风险之间的不一致。我们有关于收敛的定理，它告诉我们，这里有一类回报函数，我们假设可以通过从固定分布中抽取新样本来进行迭代采样，我们知道这类是朝着我们关心的目标的极限趋势。从这个意义上说，它是一组目标，最终以一种严格的数学方式趋向于你所关心的目标。</p><p id="9868" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:21:40): <br/>这将在大量数据的限制范围内</p><p id="baa8" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:21:44): <br/>完全正确。大量带标签的数据，这是一个非常重要的区别。</p><p id="ad6e" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:21:51): <br/>是的，这似乎真的以一种有趣的方式把我们带到了你的一些研究中，我们受到带宽的限制，我认为公平地说，在我们与机器的互动方面，如果人类可以提供关于机器如何以超快的方式执行我们要求他们做的任务的反馈，那将是非常棒的，这样我们就可以确保他们做的每项任务都得到完美的监督，我们不能。我想很多研究都涉及到回答这个问题，我们如何能更有效地做到这一点？我们如何以更有建设性的方式让人类参与进来？你能稍微解释一下吗？</p><p id="b53c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:22:30): <br/>当然。我的研究是关于观察一个人和一个机器人在一个团队中工作。我认为，当我们做这项工作时，当我们看假设的代理人时，你必须做这件事，那就是围绕什么算代理人，什么算环境？我们对人工智能系统的许多建模和我们对它的许多思考方式，代理是某种机器人，它是某种预测系统。我的研究提出了这样一个问题，如果我们在人和机器人周围画一个盒子，会是什么样子？这是对一个特定类型的人类机器人系统进行建模，在这个系统中，你对真正的目标是什么，如何实际完成这个目标有部分信息，你必须通过某种嘈杂的渠道进行交流。</p><p id="f95c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:23:23): <br/>一个人可能采取的一般行动。这可能是你通过行为的示范来传达它，这必须在新的环境中被模仿。你也可以想象这是自然语言，或者是某种有标签的数据集。</p><p id="86dd" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:23:40): <br/>我的研究着眼于如何将这些系统结合起来，从而有效地实现这些目标？现在，这实际上会是什么样子呢？我关注的一个特别的想法是一个叫做反向奖励设计的想法，我认为，它采用了我们使用的这种互动的最简单的版本，并试图在人类机器人如何互动中寻找一个额外的复杂层。</p><p id="3c4f" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:24:09): <br/>这里的想法是你观察一个奖励函数。你知道两件事，一是这个奖励函数实际上不是真正的目标。在某种程度上，它是错误的，也是一致的。第二，这是一个很好的信息来源，告诉你在任何时候应该做什么。</p><p id="fa67" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:24:34): <br/>好，但不完美。</p><p id="1b39" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:24:36): <br/>正是如此。你实际上如何识别可能出现的错误类型？在这个问题上，你要做的第一件事就是认识到，就其本身而言，你无法回答这个问题。如果我只告诉你这里有一个奖励函数，它可能是错的，你不知道其他的，你对此无能为力。我在这项工作中所做的是，我们引入了度量环境的概念。您有一组现有的选项可供选择，并且您有一个度量标准可供选择。基本上，你对这个系统的承诺是什么，这个指标在这些环境或背景下导致良好的行为。</p><p id="f77a" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:25:15): <br/>好的。</p><p id="bbaa" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:25:16): <br/>现在，这给了你一些更有条理的信息。你能做的实际上是说，这个指标是一种指定不同行为排名的方式，我可以把它视为观察到的行为排名。由此，推断不同环境下新行为的可能性，或者更有用的是，计算出这些行为如何外推到新环境的分布，如果它非常非常紧密，你有很高的信心，哦，这是一个类似于系统设计者心目中的环境，所以我可以适当地表现。或者如果范围很广，你可以说，啊，这不好，我可能不应该过去。选择去获取更多信息，或者选择一个替代的，也许更安全的行动方案。</p><p id="7d83" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:26:12): <br/>我们举了一个例子，我们称之为……在这种情况下，你有一个机器人试图在一些2D环境中行驶，你有一些不同类型的现象需要它去观察。想象一下，在你想要寻找的环境中，有一些东西就像一罐罐的金子。对于你心目中的环境，实际上有两种类型的地形，草地和泥土。有泥路，然后有草坪和其他东西，你希望它大部分时间呆在泥土上，找到这些物体，穿过草坪，在它必须去的地方。</p><p id="cb65" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:26:45): <br/>现在，你可以通过收集这些地形类型的例子，你想去寻找的金罐的例子，训练分类器，然后指定一个使用这些分类器的奖励函数。</p><p id="a1c3" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:26:59): <br/>问题是，如果你忘记了你的机器人将被部署在夏威夷，那么实际上也有熔岩，一切都会变得混乱。你不会有一个一致的预测，它应该对熔岩做什么，因为根据你看到的数据，没有明确的暗示，或者可能没有。这完全取决于你所使用的学习算法的特征空间和偏差。但关键是，它在那种情况下做什么是任意的。</p><p id="5a78" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:27:33): <br/>你会得到一堆指标，它们在没有熔岩的世界里会说同样的话，在有熔岩的世界里会说完全不同的话。这给了你一个想法，也许我的度量不太适合这个环境。</p><p id="4739" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:27:51): <br/>这似乎给这个系统带来了一点谦卑和自省，让你先看看你的环境，然后说:“好吧，那么，我能在多大程度上将我的夏威夷经历映射到我的旧金山经历？”我猜，机器人或人工智能会基于此得出什么结论？它会不会倾向于说，好吧，我只是不打算采取任何行动，因为我不确定我是否处于一个新的环境中，这个环境与我以前看到的环境不太相符？还是留给开发人员做练习？</p><p id="0100" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:28:27): <br/>我认为以一种非常谦逊的方式，这是留给开发人员的一个练习。从这个意义上说，这不是我该说的。我认为，实际上，从这项工作中得出的一个重要结论是，作为开发者，你应该注意哪些事情？我认为，在这种情况下，数学上实际上漏掉的一件事，以一种非常好的方式，是指定当你太不确定时的回退行为。我不知道你的听众想要什么样的数学细节。</p><p id="505d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:29:06): <br/>是的，我想我们可能会保持合理的高水平，只是为了……但是如果你有-</p><p id="fbb9" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:29:11): <br/>我认为它的高级版本是……你认为人们会熟悉概率模型中可识别性的概念吗？或许吧？</p><p id="08c3" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:29:29): <br/>我还没有完全。也许我们可以从那里开始。</p><p id="e0aa" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:29:31): <br/>可识别性是指你能从数据中找出什么样的潜在变量？这方面的经典例子是，如果你有一个混合的高斯分布，这些高斯分布来自于……你有一些潜在的变量，它们是这些高斯分布的均值和方差。当你做聚类时，你观察这些数据，然后你拟合这些潜在变量。在无限数据的极限下，你可以证明你会平均识别出正确的均值和协方差。有了无限量的数据，你最终会到达那里。然而-</p><p id="d9fc" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:30:11): <br/>这是……我能根据输出重建神经网络的参数吗，我的预测-</p><p id="8c68" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:30:17): <br/>算是吧。问题是均值的值是可识别的，但它们在潜在变量向量中的排序是不可识别的。</p><p id="8c1e" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:30:29): <br/>哦，对了。是啊。</p><p id="f69e" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:30:30): <br/>在你的最终推断中，有一堆平行的假设会得到同等的权重。</p><p id="011c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:30:36): <br/>如果我错了，请纠正我，这在直觉上是有意义的，因为我可以想象，事实上，可能有无限数量的神经网络会产生相同的输入输出特性。</p><p id="f623" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:30:48): <br/>对。</p><p id="654a" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:30:49): <br/>或一般功能。抱歉，我说的是神经网络，而是功能。</p><p id="e79d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:30:54): <br/>你可以使用这里的任何东西。但关键是，如果你有两个不同的潜在变量设置，它们在数据上产生相同的分布，你永远无法从观察中找出哪一个是实际情况。这是一个非常普遍的概念，被称为可识别性。这是一项研究，根据你的数据中假设的因果结构，你能发现什么？</p><p id="d12d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:31:22): <br/>有意思，这似乎……这似乎指出了一个问题，我可以想象，比方说，两个不同的神经网络，其中一个给出了我想要的结果。最大化人类价值，或者不管我指的是什么，然后另一个是，真的很可怕，但我无法用我喂它的特定样本来检测。有可能存在一个任意大的算法集，其中大多数都是病态的，但是我只能在有限数量的样本上检查它们的行为，对吗？这是否说明了几乎是对齐的可验证性？</p><p id="af6c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:32:05): <br/>我认为这涉及到了一些问题，比如带有预测的“没有免费的午餐”定理，对吗？如果你问的是关于发行外性能的问题，在没有额外假设的情况下，我们没有给出保证的好方法。你知道这些假设在某些情况下会有帮助，但它们肯定比其他情况更有害。我觉得这只是同类的东西。</p><p id="d3e0" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:32:28): <br/>现在，我认为我的总体看法是理性，行为应该朝着一个目标优化的想法实际上是一种选择，它是一种工具，用于我们设计编译器，接受这些目标的表示，这些期望行为的表示，并进行交流。但我认为它不需要成为我们唯一的财产。</p><p id="2423" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:32:59): <br/>还有哪些其他选择？</p><p id="bdaf" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:33:01): <br/>嗯，我认为首先要说的是，如果你考虑理性，它是某人写下的和客观的高级启发。事实证明，你能做的大多数行为都是愚蠢的。大多数神经网络不会做任何有用的事情。引入这种为完成某项任务而优化的思想，这种范式基本上建立在至少做点什么的启发中。这减少了程序的空间，你必须用它来表示你想要的东西。因为你不需要区分事情是如何解决的所有细节，你可以说，我们以合理的方式做这件事，或者试图优化一些目标。</p><p id="99a0" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:33:50): <br/>我想你也可以说，我们并不真的想要一天结束时的纯粹理性行为，我们希望有更多规范的行为。我认为这是规范中应该包含的内容。你想想，我们默认不写直接优化经验风险的监督学习系统。在一些设置中，如果你有足够的数据，它是有效的，你仍然可以依靠其他物理属性来规范最终的行为。</p><p id="3077" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:34:22): <br/>在许多方面，我们确实依赖系统的计算约束来规范它们的行为。理论上，对于每一个RL环境，都有一个非常非常好的策略，就是以某种方式进行缓冲区溢出攻击，并在奖励计算来自的内存中写入非常大的数字，对吗？一方面，我们的系统不这样做的原因很明显，但很难解释。还不清楚在一组特定的权重中是否有简单的策略可以做到这一点。我认为我们有信心，实际上我们使用的优化技术的类型的属性意味着那不会是我们最终的结果。</p><p id="ac5f" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:35:23): <br/>真的吗？好吧。因为我想为什么我们不用-</p><p id="a37d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:35:26): <br/>我不认为我们知道如何描述他们。我不认为任何人真的担心你正在运行的优化会以某种方式偏离轨道。</p><p id="e837" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:35:41): <br/>是的。我看到人们探索缩放语言模型的可能性，例如，作为潜在的风险因素，就像GPT 10或其他什么，你不断地让神经网络变得更大更深，它从学习低级别的抽象开始，学习基本的如何把字母放在一起等等，最终学习语法等等，然后最终开发出某种世界模型。这个模型可能最终会包括对模型在世界中的位置的认识，可能会说，哦，看那个，因为它对预测句子中的下一个单词是有用的，我会意识到，嘿，我实际上是嵌入在这个世界中的，因此随之而来的，开始变得贪婪…有各种各样的[听不清00:36:31]</p><p id="0f25" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:36:31): <br/>对，这就像改变世界，以便更容易预测下一个单词。</p><p id="09db" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:36:38): <br/>对。我想这和你一直在谈论的是代理人和环境之间的区别。这将是算法意识到的时刻，嘿，我嵌入在这里的环境中，是时候开始模糊这些线了。</p><p id="48be" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:36:56): <br/>我认为这些观点都值得认真对待，但也很难反驳。我认为这是值得认真对待的事情，你应该给他们带来适当程度的怀疑，我认为是这样的。例如，有一个假设，基本上，如果唯一的字符是一个…好吧，让我这么说吧，我们有很多经济学的例子，理性行为是怪异和违反直觉的，从根本上说，不是人类，我认为在很多方面，对吗？经济人是一种不同类型的存在。</p><p id="3697" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:38:00): <br/>我认为，如果你对人工智能系统的唯一假设是，它们是具有任意效用函数的经济人的实例化，那就不好了。你最终会有不好的结果，因为你在假设一个场景…我认为，基本上，根据假设，你不会做得很好。</p><p id="c81c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:38:30): <br/>真遗憾。嗯，我想从定义上来说，几乎不可能找出确切的位置……如果我们能找出那个假设失败的地方，我们就会知道更多的事情。但在我看来,“经济人”不起作用的原因是，进化给我们设定了需求和欲望……嗯，我们不是随机的，而是与经济激励非常不一致。我们想要做一些事情…有时，我们会嫉妒别人。在人类存在的病理模式中，如果我们变得报复或其他什么，我们有时会把别人的痛苦看得比自己的幸福更重要，这就打乱了整个模式。</p><p id="453d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:39:16): <br/>我想，在机器学习模型的情况下，或者说，深度神经网络，本质上不受那些进化条件的限制，我想你可能会说，它正在经历一个进化优化的过程。也许那-</p><p id="4ec7" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:39:37): <br/>我认为没有人能告诉我，我们无法找出如何编写符合这种行为特征的程序，或者由最佳或理性代理或类似的东西很好地建模的程序。我当然不是说我认为那是不可能的。我并不是说我认为如果我们真的建造了它，我不认为它在很多方面是好的。我认为有些人可以通过存在风险来讨论这个问题。我认为你甚至不需要真的去谈论那种事情会导致的非常糟糕的结果。</p><p id="17a4" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:40:30): <br/>我完全同意。这是……说得清楚一点，当我们开始谈论爆发风险之类的事情时，我实际上把这框定为一个极端或者认为这是一个极端危险的结果类别。是啊。</p><p id="2e00" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:40:42): <br/>但我认为……我认为人工智能系统或人工智能研究的结果应该是这样的。像这样的争论需要迈出一步，也就是说，这是未来人工智能系统的模型。我想，如果你还同意我的观点，关于这个编译器的类比，在这个过程中的某个时刻，在构建这些系统的过程中有一个创新，那就是引入这些最佳行为的模型，并且说，我们应该让我们的编译器更有可能输出一些至少是有用的东西。这对人工智能研究和人工智能系统的进步非常有用。但这并不意味着我们必须推动这条研究路线直到最终完成，也不意味着人工智能系统必须朝着个体理性经济主体的方向努力。</p><p id="0c28" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:41:44): <br/>坦白地说，我认为有很多人想要建立这样的系统，我认为这并不好。我认为这源于某种类型的思维定势。但是我觉得不是必然的。我认为这是一个选择，实际上，我认为审视这些关于风险的争论的结果是，什么是正确的方向，什么是有用的选择？</p><p id="bc46" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:42:10): <br/>这是我真正感到有希望的地方，因为我们现在试图在世界上部署人工智能系统时遇到的问题，在某种程度上，就是这些类型的问题。它们不一定是预测误差的问题，尽管我认为你可以说它们是这样的。但是它们的问题是，不能恰当地表示许多重要设置的目标的最小可行产品，并且不能产生训练有素的从业者来做深入思考这些目标是什么的艰苦工作，作为在机器学习系统内表示它们的过程。</p><p id="6d3b" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:42:55): <br/>我完全同意，如果我们能够避免人们盲目地转向这种超级刺激的模式，那就太好了。我想我的担心是，从经济上来说，似乎在那个方向上有一个强大的强制功能，如果我们举个例子…好吧，这个超级放大的深度神经网络的玩具例子比我们曾经建造的任何东西都更庞大，那些试图制造的人，我不会把它叫做GPTN，因为这听起来好像我在挑选开放人工智能。我认为他们考虑到了很多风险。但是，有人试图让那个巨大的模型看起来像什么，实际上可能…他们可能不会试图过度拟合。他们可能试图尽最大努力，想出一个合理的损失函数，产生一个真正强大的模型，但不知道，在什么样的训练水平上，模型决定在什么样的抽象水平上爆发？</p><p id="2de5" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:43:57): <br/>他们甚至可能带着一种安全意识的心态来对待它，但是因为我们没有办法真正预测抽象飞跃将在什么点上发生，所以朝着那个方向推进本质上是危险的事情。</p><p id="35db" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:44:13): <br/>对。明确地说，我并不同意物质层面上的这种担忧。我认为我们可以担心这是一个问题，我还没有看到任何真正的论据使我相信这不太可能发生。我认为有直觉的争论，有人们对可能发生的事情的感知，无论是建立系统的经验还是其他方式的直觉。但我不认为有任何实际的，坚实的论据可以让我相信这不是一个问题。</p><p id="de49" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:44:59): <br/>坦白地说，如果它存在，并且有人知道它，我很乐意看到它。我认为我的观点是，同时，我认为我们可以认识到这一点，认识到这是一个挑战，然后也想知道什么是更严肃的证明形式，这是当前系统需要关注的问题？我看到的所有暗示风险的论点，都是四种不同的方式，比如……我们会谈到突破之类的想法。这并不是我试图思考这些事情的方式，因为我不知道如何使这个想法精确，我不知道如何定义这个想法，我不知道如何用这个表达做任何有用的事情。</p><p id="7766" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:45:48): <br/>同样，如果有人能够找到一种好的形式主义，一种好的方式来表现它，为它建模，我认为这很好。但我不确定它是从哪里来的。它的论点依赖于理性行为作为你的人工智能系统如何运作的公理。声称它会爆发，因为那对目标更好，因为你在系统中有它的表示。一方面，我认为这是真的，如果你接受这样的假设，即把它建模为经济人是好的。但是，我也想知道，好吧，有没有其他的假设真的会导致这样的结果？从数学上来说，有没有方法来构建实际上并不纯粹优化其目标的系统？</p><p id="968a" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:46:42): <br/>我认为在实践中，这肯定是正确的。我们有正规化。我们可以训练最大限度地利用经验数据集的东西，来预测导致这种情况的数据的真实分布，我们可以根据数据集的大小来调整它。这是你必须做的事情。没有人能告诉你将正则化参数设置在什么数字或特定的细节，但我们认识到这是一个问题，我们知道克服它是构建人工智能系统的核心部分。</p><p id="e0f9" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:47:16): <br/>我认为有一种完全相同的东西可能会出现在更高的抽象层，这与好吧，在监督学习的情况下，你想尝试模仿的实际人类认知过程是什么？在这里，作为从业者和领域，我们非常，非常偏向于什么是可用的，而不是我们需要什么？</p><p id="80e0" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:47:44): <br/>对，我想这是所有这些系统的普遍问题</p><p id="7959" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:47:48): <br/>我想是的。</p><p id="771b" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:47:49): <br/>是的，有趣的是，系统的安全性与其整体能力之间存在很大的相互作用，因为能够充分利用神经网络的所有能力来实现某个目标是一件很棒的事情。但最终，无论何时我们谈论安全，那都意味着强加某种约束。当你开始放开束缚的时候，你冒险进入-</p><p id="614b" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:48:16): <br/>我几乎会质疑这个假设。从这个意义上来说，好吧，如果我们可以假设一个完美的世界，你会想从系统中挤出最后一点性能。但是有一句关于优秀员工的沃伦·巴菲特名言。这是，你想要的人有一些…我肯定我理解错了，但这就像你想要的人有智慧，勇气和值得信赖。如果他们没有最后一个，要注意前两个。</p><p id="0648" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:48:49): <br/>是啊。</p><p id="f920" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (00:48:49): <br/>我认为这在实际意义上确实适用，不是对遥远的系统，而是对当前的系统。你可以接受，除了…例如，如果你现在去YouTube，你告诉他们，“我有一个方法让你…你在预测某人点击这个视频的可能性方面会做得更差，但我可以向你保证，它不会对青少年的福祉产生负面影响，正如研究所A、B和c所测量的那样。”</p><p id="8ea4" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:49:33): <br/>如果你去找他们，并且能够具体说明，我认为这是一件非常有价值的事情。这是你无法通过简单地重新标记你所拥有的数据来解决的。你也许可以通过从根本上重新设计人们与你的视频推荐系统之间的互动类型来达到这个目的。但是，有一个问题，他们想解决，但他们无法解决，他们无法指定，我认为，有效利用这项技术的障碍并没有真正提高预测性能，但实际上提高了轻松指定目标的能力。</p><p id="a0cd" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:50:23): <br/>对，我想是这样的。这就像因为您还没有指定您想要的精确优化目标，所以您被迫采取措施来限制系统整体的行为，使用更粗粒度的工具。基本上就是找个锤子稍微敲打一下你的神经网络。</p><p id="d309" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:50:47): <br/>我认为这是对的。比方说，你有一大堆行为，包括神经网络的不同参数化，你试图找出如何选择正确的行为，这是一个人无法独自完成的事情。我们发现，指定某种度量标准，然后优化这些预测损失是一种很好的方式，可以真正剔除一大堆糟糕的权重配置。</p><p id="b1bd" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:51:22): <br/>是啊。但仍然不是全部。</p><p id="eacb" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:51:27): <br/>但不全是错误的，事实证明，如果你过于专注，那么你很有可能以不同的方式出错。在这个范围的一端，你有无用的随机行为，在这个范围的另一端，你有…在概率为1的情况下，你可能实际上没有你想要的行为。</p><p id="b687" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:51:50): <br/>这是…事实上可能不存在客观损失函数或客观函数，而是人类可能希望优化的概念…我不知道，对于相信人工智能绝对主义或人工智能最终将做好一切的人来说，这有点令人担忧。</p><p id="85da" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:52:14): <br/>例如，山姆·哈里斯有本书，名为《道德景观》，他在书中谈到，从本质上讲，他认为自然界中存在一种客观的功能。但是每当有人以这种方式谈论道德时，对我来说似乎总是不够明确。你认为它们实际上可能是我们可以优化的东西吗，我甚至不知道我要在这里说什么，让人们快乐，最大限度地促进人类繁荣？</p><p id="4b11" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:52:42): <br/>我不一定认同那套关于事情最终会如何发展的信念。我感兴趣的是，我们可以建立什么样的系统来重建人类社会中的一些激励平衡，并将其整合到一般的人工智能系统中？我认为，在某种程度上，这是一个问题，作为人，我们可以用什么样的过程来讨论这些事情？在某种程度上，我不知道，试图复制我们作为一个物种建立和设计的过程，以规范群体行为和协调我们自己的规模？</p><p id="64f6" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:53:37): <br/>我认为有这样一个方面，我们发现了如何平衡我们个人以及社会和结构中的许多不同激励因素。有很多方法可以得到一个可信任的第三方或者有一个代理的想法。代理人已经是一份工作，有人可以做你的代理人，你可以雇佣房地产市场的人做你的代理人，代表你的利益。这不是凭空出现的，有人发明了这种方法来管理世界的复杂性。</p><p id="e61b" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:54:16): <br/>我们也可以用人工智能系统来做这件事。我们需要弄清楚那看起来像什么。在脸书上设置你想看什么类型的内容，什么时候你想看不同种类的东西时，你的代理是什么，可以被信任来代表你？</p><p id="8580" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:54:34): <br/>在一个机器人和机器正在做如此复杂的事情，以至于人类甚至无法理解这些决定的含义的世界里，你认为这种机器人与人类互动的画面能够保持下去吗？</p><p id="3b50" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:54:54): <br/>我认为这是一个非常棘手的问题。我认为更通俗的说法是，你如何在适当的背景下向人们展示信息，给他们最好的方式去做他们能做的决定？这包括，你如何提供一个适当的背景来说明这个决定的后果是什么？</p><p id="39c4" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(00:55:21): <br/>对。</p><p id="c2df" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:55:23): <br/>那是我们不知道如何去做的事情。我一直在思考价值定位与推荐系统的关系，尤其是像YouTube和脸书这样的内容推荐系统。这就是为什么我似乎总是回到那些例子。这是原因之一。但是我们不太擅长弄清楚如何让人们进入一种状态，在这种状态下，他们可以反思他们想在互联网上从事什么类型的事情。我对这个问题的看法是，我们确实可以想象遥远未来的可能系统，并谈论它。但实际上，这就像是，好吧，对于一个新存在的事物，这是一种通过算法过滤和选择的奇怪类型的内容提要，什么是…大多数人甚至不知道这是什么的适当术语，什么是推荐，当我出去，偶尔跑步时，这对我来说真的很有趣…这种情况不再经常发生了。但是你偶尔会碰到人。我会经常询问他们的建议。</p><p id="2700" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:56:38): <br/>每个人都有不同的理论来将他们获得的推荐或排名拟人化，以及他们了解了什么以及如何运作。他们总是深信不疑，他们通常在某些方面是错的，这没什么，因为没有人-</p><p id="3ebb" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:56:55): <br/>我肯定我的会是，是的。</p><p id="4d32" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:56:56): <br/>幕后实际发生的事情非常复杂。作为一个不在这两家公司工作的人，我真的不知道幕后发生了什么。事实上，有些东西就像你的信息过滤器，或者这个排名算法，它选择你看到的东西，这对你将成为的人，你将拥有的新闻消费类型，你应该关心什么样的事情有影响？你应该关心平衡，公平吗？这里有一大堆不同的价值观，你可能会关心它们在那里的表现。</p><p id="9ebb" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:57:32): <br/>真正的问题是，你如何开始这样的对话？你如何…这是公共教育的结合，帮助人们知道实际上存在一个问题，并围绕提供背景设计系统，帮助人们认识到他们应该解决的问题，帮助他们认识到你实际上要求他们做的认知工作的价值。</p><p id="ea19" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:57:54): <br/>我认为一个很大的讽刺是，你实际上拥有大量的工具和控件。看到人们在Twitter上说他们希望Twitter有一种方法可以更少地看到事情，这非常有趣。我在Twitter超级用户、有复选标记的人和许多关注者等身上多次看到这种情况。事实是Twitter有这个功能。它在那里。我不知道它在那里多久了，但它在那里。问题是，没有人知道它实际上会做什么，或者如何相信它将来会真正帮助他们。</p><p id="69c6" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:58:33): <br/>我想，这也是一个有趣的问题，即使你完全知道这个推荐系统是如何工作的，你完全知道所有的东西都是开源的，你仍然会有一个非常复杂的道德问题，那就是你想成为什么样的人。我可以看到YouTube上的一个视频，它有可能让我变成一个聪明的…我不知道，就像一个海洋生物学家，我可以跟着那个兔子洞，继续跟着视频。</p><p id="77c5" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (00:59:05): <br/>公平地说，我可以看一系列的视频来证明这一点。但是，如果我面临这个选择，或者另一个把我带到机器学习工程师那里作为最终状态的选择，或者一个把我变成纳粹、共产主义者或者其他什么的选择，我能知道我想要成为哪个版本的我吗？我不知道未来版本的我会希望我成为谁，如果他们知道所有不同的未来版本的我想要什么。我都不知道这是怎么回事。</p><p id="b2c1" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(00:59:37): <br/>这是你进入一些非常复杂的哲学的地方，你可以谈论思考它的方法。除了我自己，我当然不是回答这些问题的合适人选。但我认为，我认为大多数人都会同意的观察结果是，回答这些问题是很费力的。回答我想成为什么样的人这一问题，需要一项基本的认知工作。</p><p id="cf61" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (01:00:14): <br/>在某些方面，你必须弄清楚如何设计系统来克服，而不仅仅是你不知道那个人想成为谁的信息问题，或者更具体地说，他们想看到什么内容，这与他们想成为谁有关。事实上，你可以影响这一点，如果你只是不能影响某人…说，我不会影响某人明天是谁，基于我给他们看的东西。同样，这可能是你真正想要的东西。但是作为一个推荐系统的设计者，你不知道那是什么。但除此之外，这个人通常不知道这个问题的答案，也许甚至不知道如何真正进行这种类型的对话，或者不喜欢这种类型的思考，即我想成为什么样的人，这是一种特殊的思维方式，但不是每个人都喜欢参与。或者对我来说，我认为这是有代价的，对不同的人来说有不同的代价。</p><p id="e92d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(01:01:18): <br/>当人们只想在一些猫视频中消失一会儿时，你如何说服他们去经历这个代价高昂的过程？</p><p id="a949" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (01:01:25): <br/>是的，绝对是。</p><p id="df52" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(01:01:27): <br/>与此同时，很明显会有巨大的正外部性。如果我现在可以为社会挥舞一根魔杖，那可能是让每个人每周安排15分钟来反思他们如何消费信息，以及他们想要消费的信息类型。然后花五分钟做一些让他们成功的事情，以此为基础。我认为，如果每个人都这样做，这对社会来说将是一个巨大的正外部性，因为你的个人信息消费将会发生个人变化。</p><p id="2e3f" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Dylan (01:02:09): <br/>但这实际上改变了整体，实际上引导并包括了某些类型的认知过程，从而引导了人们的信息饮食。</p><p id="033d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">Jeremie (01:02:25): <br/>我无法释怀…例如，我最有效率的日子总是那些我不在Twitter上度过的日子。毫无疑问……现在的感觉是，我们不得不离开去处理信息的时间，相对于我们花费在消费信息上的时间，这种平衡在过去的10年里完全颠倒了。过去，你会在一天中看到一个大新闻，你可能会花一整天的时间来咀嚼它，也许会和几个人谈论同一个焦点故事，在这种情况下，故事的可靠性更重要。而现在只是不停地输入，输入，输入，几乎没有时间进行认知处理。事情发生方式的有趣转变。</p><p id="1745" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(01:03:12): <br/>如果你的世界信息更加稀缺，或者更难获取，这要求你实际上…这听起来有点傻，但如果你不得不选择去拿一份报纸，这种行动和选择会让你有点投入，它会让你进入一种略有不同的状态。然而，如果你只是想抽离……如果相反你要从那里获取信息，我不知道还能做什么，有一卷东西可以分散注意力。那是完全不同的事情。</p><p id="9c9d" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">杰雷米(01:03:40): <br/>说到这里，我想假惺惺地问一下，你是否有一个Twitter链接可以分享，是否有人想关注你，看看你的更多作品？</p><p id="368c" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(01:03:49): <br/>是的，当然。我是dhadfieldmenell。名字的首字母，姓氏，没有标点符号或任何类似的东西。我不能保证经常发微博。实际上我现在正在休息。但我肯定会发布论文更新，我倾向于偶尔发关于人工智能伦理和一般价值一致性主题的推特。</p><p id="2857" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">耶雷米(01:04:13): <br/>真棒。非常感谢您抽出时间，今天的讨论非常精彩，几乎囊括了所有内容。所以，我真的很感激。如果可以的话，我们会在播客附带的博客中发布一个链接，链接到你的Twitter和你的学术网站。</p><p id="59cc" class="pw-post-body-paragraph lf lg iv lh b li lj kf lk ll lm ki ln lo lp lq lr ls lt lu lv lw lx ly lz ma io bi translated">迪伦(01:04:26): <br/>是的，那太好了。非常感谢。这是一个真正的机会，我很高兴有机会和你们交谈。</p></div></div>    
</body>
</html>