<html>
<head>
<title>10 Hyperparameter optimization frameworks.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">10个超参数优化框架。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/10-hyperparameter-optimization-frameworks-8bc87bc8b7e3?source=collection_archive---------5-----------------------#2020-09-26">https://towardsdatascience.com/10-hyperparameter-optimization-frameworks-8bc87bc8b7e3?source=collection_archive---------5-----------------------#2020-09-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="3c46" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用开源优化库调整您的机器学习模型</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/2e2dbe391ceabe83509dfda1053079ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vcukIF93Qm0kbrydkxsAsA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片由来自<a class="ae le" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4747055" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae le" href="https://pixabay.com/users/FelixDesignStudio-2911466/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4747055" rel="noopener ugc nofollow" target="_blank">jrg Felix</a>拍摄</p></figure><h1 id="339f" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">介绍</h1><p id="b7b7" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><strong class="js iu">超参数</strong>是用于在建立模型时控制算法行为的参数。这些参数不能从常规训练过程中学习到。它们需要在训练模型之前被分配。</p><p id="e2b8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例子:<strong class="js iu">n _ neighbors</strong>(KNN)<strong class="js iu">kernel</strong>(SVC)<strong class="js iu">max _ depth</strong>&amp;<strong class="js iu">criterion</strong>(决策树分类器)等。</p><p id="6e4e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">机器学习中的超参数优化</strong>或<strong class="js iu">调整</strong>是选择提供最佳性能的超参数的最佳组合的过程。</p><p id="170c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">存在各种自动优化技术，当应用于不同类型的问题时，每种技术都有自己的优点和缺点。</p><p id="5d80" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如:网格搜索、随机搜索、贝叶斯搜索等。</p><div class="mi mj gp gr mk ml"><a href="https://medium.com/swlh/4-hyper-parameter-tuning-techniques-924cb188d199" rel="noopener follow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">4种超参数调整技术</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">每个数据科学家都应该知道的流行超参数调整技术</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">medium.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz ky ml"/></div></div></a></div><div class="mi mj gp gr mk ml"><a rel="noopener follow" target="_blank" href="/data-leakage-with-hyper-parameter-tuning-c57ba2006046"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">超参数调整的数据泄漏</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">超参数调优有时会打乱您的模型，并导致对看不见的数据产生不可预测的结果。</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">towardsdatascience.com</p></div></div><div class="mu l"><div class="na l mw mx my mu mz ky ml"/></div></div></a></div><p id="b05c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Scikit-learn是我们可以用于<strong class="js iu">超参数优化的框架之一，</strong>但是还有其他框架甚至可以表现得更好。</p><ol class=""><li id="3a0e" class="nb nc it js b jt ju jx jy kb nd kf ne kj nf kn ng nh ni nj bi translated">射线调谐</li><li id="8541" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">奥普图纳</li><li id="8b94" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">远视</li><li id="c287" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">多层机器</li><li id="5560" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">多轴</li><li id="de97" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">贝叶斯最优化</li><li id="c8ba" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">塔罗斯</li><li id="1edc" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">夏尔巴人</li><li id="6acd" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">sci kit-优化</li><li id="ba83" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">GPyOpt</li></ol><h1 id="7d9b" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">1.射线调谐</h1><p id="0e5a" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://docs.ray.io/en/latest/tune/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="np"> Tune </em> </a>是一个Python库，用于实验执行和任意比例的超参数调谐。[ <a class="ae le" href="https://github.com/ray-project/tune-sklearn" rel="noopener ugc nofollow" target="_blank"> GitHub </a> ]</p><h2 id="165c" class="nq lg it bd lh nr ns dn ll nt nu dp lp kb nv nw lt kf nx ny lx kj nz oa mb ob bi translated">关键特征</h2><ol class=""><li id="7d17" class="nb nc it js b jt md jx me kb oc kf od kj oe kn ng nh ni nj bi translated">用不到十行代码启动多节点<a class="ae le" href="https://docs.ray.io/en/latest/tune/tutorials/tune-distributed.html#tune-distributed" rel="noopener ugc nofollow" target="_blank">分布式超参数扫描</a>。</li><li id="f39d" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">支持任何机器学习框架，<a class="ae le" href="https://docs.ray.io/en/latest/tune/tutorials/overview.html#tune-guides" rel="noopener ugc nofollow" target="_blank">包括PyTorch、XGBoost、MXNet、Keras </a>。</li><li id="cc39" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">在最先进的算法中进行选择，如<a class="ae le" href="https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#tune-scheduler-pbt" rel="noopener ugc nofollow" target="_blank">基于人口的训练(PBT) </a>、<a class="ae le" href="https://docs.ray.io/en/latest/tune/api_docs/suggestion.html#bayesopt" rel="noopener ugc nofollow" target="_blank"> BayesOptSearch </a>、<a class="ae le" href="https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#tune-scheduler-hyperband" rel="noopener ugc nofollow" target="_blank"> HyperBand/ASHA </a>。</li><li id="7079" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">Tune的搜索算法是开源优化<a class="ae le" href="https://docs.ray.io/en/latest/tune/api_docs/suggestion.html" rel="noopener ugc nofollow" target="_blank">库</a>的包装器，如HyperOpt、SigOpt、蜻蜓和脸书Ax。</li><li id="65fe" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">使用TensorBoard自动可视化结果。</li></ol><blockquote class="of"><p id="91b6" class="og oh it bd oi oj ok ol om on oo kn dk translated">Scikit学习调谐</p><p id="8b2f" class="og oh it bd oi oj op oq or os ot kn dk translated">安装:pip install ray[tune]tune-sk learn</p></blockquote><figure class="ou ov ow ox oy kt"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h1 id="d737" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">2.奥普图纳</h1><p id="e021" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://optuna.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> <em class="np"> Optuna </em> </a>是一个自动超参数优化软件框架，专门为机器学习而设计。</p><h2 id="c40b" class="nq lg it bd lh nr ns dn ll nt nu dp lp kb nv nw lt kf nx ny lx kj nz oa mb ob bi translated">关键特征</h2><ol class=""><li id="e952" class="nb nc it js b jt md jx me kb oc kf od kj oe kn ng nh ni nj bi translated"><a class="ae le" href="https://optuna.readthedocs.io/en/stable/tutorial/004_distributed.html" rel="noopener ugc nofollow" target="_blank">简单并行</a></li><li id="7cbf" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated"><a class="ae le" href="https://optuna.readthedocs.io/en/stable/reference/visualization.html" rel="noopener ugc nofollow" target="_blank">快速可视化</a></li><li id="16bc" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated"><a class="ae le" href="https://optuna.readthedocs.io/en/stable/tutorial/007_pruning.html" rel="noopener ugc nofollow" target="_blank">高效优化算法</a></li><li id="a71c" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated"><a class="ae le" href="https://optuna.readthedocs.io/en/stable/tutorial/001_first.html" rel="noopener ugc nofollow" target="_blank">轻量级、通用且平台无关的架构</a></li><li id="d9c2" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated"><a class="ae le" href="https://optuna.readthedocs.io/en/stable/tutorial/002_configurations.html" rel="noopener ugc nofollow" target="_blank">python式搜索空间</a></li></ol><blockquote class="of"><p id="836c" class="og oh it bd oi oj ok ol om on oo kn dk translated">安装:pip安装optuna</p></blockquote><figure class="ou ov ow ox oy kt"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h1 id="4a03" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">3.远视</h1><p id="6afb" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://github.com/hyperopt/hyperopt" rel="noopener ugc nofollow" target="_blank"> Hyperopt </a>是一个Python库，用于在笨拙的搜索空间上进行串行和并行优化，搜索空间可能包括实值、离散和条件维度。</p><p id="9701" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">目前它支持三种算法:</p><ul class=""><li id="27b0" class="nb nc it js b jt ju jx jy kb nd kf ne kj nf kn pb nh ni nj bi translated"><a class="ae le" href="http://www.jmlr.org/papers/v13/bergstra12a.html?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">随机搜索</a></li><li id="f699" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn pb nh ni nj bi translated"><a class="ae le" href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" rel="noopener ugc nofollow" target="_blank">Parzen估计器树(TPE) </a></li><li id="6f9d" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn pb nh ni nj bi translated"><a class="ae le" href="https://www.electricbrain.io/blog/learning-to-optimize" rel="noopener ugc nofollow" target="_blank">自适应TPE </a></li></ul><h2 id="ca8b" class="nq lg it bd lh nr ns dn ll nt nu dp lp kb nv nw lt kf nx ny lx kj nz oa mb ob bi translated">关键特征</h2><ol class=""><li id="9267" class="nb nc it js b jt md jx me kb oc kf od kj oe kn ng nh ni nj bi translated">搜索空间<strong class="js iu">(你可以创建非常复杂的参数空间)</strong></li><li id="b763" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">持续并重启<strong class="js iu">(您可以保存重要信息并在以后加载，然后继续优化过程)</strong></li><li id="1247" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">速度和并行化<strong class="js iu">(您可以将计算分布在一个机器集群上)</strong></li></ol><blockquote class="of"><p id="3945" class="og oh it bd oi oj ok ol om on oo kn dk translated">安装:pip安装hyperopt</p></blockquote><figure class="ou ov ow ox oy kt"><div class="bz fp l di"><div class="oz pa l"/></div></figure><div class="mi mj gp gr mk ml"><a rel="noopener follow" target="_blank" href="/an-introductory-example-of-bayesian-optimization-in-python-with-hyperopt-aae40fff4ff0"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">用Hyperopt实现Python中贝叶斯优化的介绍性示例</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">学习强大优化框架基础的实践示例</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">towardsdatascience.com</p></div></div><div class="mu l"><div class="pc l mw mx my mu mz ky ml"/></div></div></a></div><h1 id="b36f" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">4.多层机器</h1><p id="45d2" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://github.com/petersontylerd/mlmachine#Installation" rel="noopener ugc nofollow" target="_blank"> mlmachine </a>是一个Python包，它有助于进行整洁有序的基于笔记本的机器学习实验，并完成实验生命周期的许多关键方面。</p><p id="498f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">mlmachine通过贝叶斯优化对多个估值器执行<a class="ae le" href="https://nbviewer.jupyter.org/github/petersontylerd/mlmachine/blob/master/notebooks/mlmachine_part_4.ipynb" rel="noopener ugc nofollow" target="_blank">超参数调整</a>，并包括可视化模型性能和参数选择的功能。</p><p id="5869" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一篇关于mlmachine的很好的解释文章。</p><div class="mi mj gp gr mk ml"><a rel="noopener follow" target="_blank" href="/mlmachine-hyperparameter-tuning-with-bayesian-optimization-2de81472e6d"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">基于贝叶斯优化的多机超参数整定</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">这个新的Python包加速了基于笔记本的机器学习实验</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">towardsdatascience.com</p></div></div><div class="mu l"><div class="pd l mw mx my mu mz ky ml"/></div></div></a></div><blockquote class="of"><p id="45ea" class="og oh it bd oi oj ok ol om on oo kn dk translated">安装:pip安装mlmachine</p></blockquote><h1 id="902f" class="lf lg it bd lh li lj lk ll lm ln lo lp lq pe ls lt lu pf lw lx ly pg ma mb mc bi translated">5.多轴</h1><p id="2599" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://polyaxon.com/docs/automation/optimization-engine/" rel="noopener ugc nofollow" target="_blank"> Polyaxon </a>是一个用于构建、培训和监控大规模深度学习应用的平台。它构建了一个系统来解决机器学习应用的可重复性、自动化和可扩展性。</p><p id="2066" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Polyaxon执行超参数调谐的方式是提供一系列可定制的搜索算法。Polyaxon既支持简单的方法，如<code class="fe ph pi pj pk b">random search</code>和<code class="fe ph pi pj pk b">grid search</code>，也为高级方法提供简单的接口，如<code class="fe ph pi pj pk b">Hyperband</code>和<code class="fe ph pi pj pk b">Bayesian Optimization</code>，它还集成了工具，如<code class="fe ph pi pj pk b">Hyperopt</code>，并提供运行定制迭代过程的接口。所有这些搜索算法都以异步方式运行，并支持并发和路由，以最大限度地利用集群的资源。</p><h2 id="67e7" class="nq lg it bd lh nr ns dn ll nt nu dp lp kb nv nw lt kf nx ny lx kj nz oa mb ob bi translated">关键特征</h2><ol class=""><li id="e726" class="nb nc it js b jt md jx me kb oc kf od kj oe kn ng nh ni nj bi translated">易于使用:Polyaxon的优化引擎是一项内置服务，可以通过向您的操作添加一个<code class="fe ph pi pj pk b">matrix</code>部分来轻松使用，您可以使用CLI、客户端和仪表板运行hyperparameter tuning。</li><li id="cecf" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">可扩展性:调整超参数或神经架构需要利用大量的计算资源，使用Polyaxon可以并行运行数百次试验，并直观地跟踪它们的进展。</li><li id="af8a" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">灵活性:除了丰富的内置算法，Polyaxon还允许用户定制各种超参数调谐算法、神经架构搜索算法、提前停止算法等。</li><li id="1a1a" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">效率:我们正集中精力从系统级和算法级进行更有效的模型调优。例如，利用早期反馈来加速调优过程。</li></ol><blockquote class="of"><p id="0ba8" class="og oh it bd oi oj ok ol om on oo kn dk translated"><a class="ae le" href="https://github.com/polyaxon/polyaxon" rel="noopener ugc nofollow" target="_blank">安装</a> : pip install -U polyaxon</p></blockquote><h1 id="a7dc" class="lf lg it bd lh li lj lk ll lm ln lo lp lq pe ls lt lu pf lw lx ly pg ma mb mc bi translated">6.贝叶斯优化</h1><p id="2a1b" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://github.com/fmfn/BayesianOptimization" rel="noopener ugc nofollow" target="_blank">贝叶斯优化</a>是另一个框架，是高斯过程贝叶斯全局优化的纯Python实现。这是一个基于贝叶斯推理和高斯过程的约束全局优化包，试图在尽可能少的迭代中找到未知函数的最大值。这种技术特别适合于高成本函数的优化，在这种情况下，勘探和开发之间的平衡非常重要。</p><blockquote class="of"><p id="45e5" class="og oh it bd oi oj op oq or os ot kn dk translated">安装:pip安装贝叶斯优化</p></blockquote><h1 id="eede" class="lf lg it bd lh li lj lk ll lm ln lo lp lq pe ls lt lu pf lw lx ly pg ma mb mc bi translated">7.塔罗斯</h1><p id="9a18" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://github.com/autonomio/talos" rel="noopener ugc nofollow" target="_blank"> Talos </a>通过完全自动化超参数调整和模型评估，彻底改变了普通的Keras工作流程。Talos完全公开了Keras功能，不需要学习新的语法或模板。</p><h2 id="4d81" class="nq lg it bd lh nr ns dn ll nt nu dp lp kb nv nw lt kf nx ny lx kj nz oa mb ob bi translated">关键特征</h2><ol class=""><li id="32d4" class="nb nc it js b jt md jx me kb oc kf od kj oe kn ng nh ni nj bi translated">单线优化预测流水线<code class="fe ph pi pj pk b">talos.Scan(x, y, model, params).predict(x_test, y_test)</code></li><li id="0c17" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">自动化超参数优化</li><li id="7d80" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">模型概括评估器</li><li id="d070" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">实验分析</li><li id="cc6d" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">伪、准和量子随机搜索选项</li><li id="fdb2" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">网格搜索</li><li id="2423" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">概率优化器</li><li id="352a" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">单个文件自定义优化策略</li></ol><div class="mi mj gp gr mk ml"><a href="https://autonomio.github.io/docs_talos/#introduction" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">Talos用户手册</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">欢迎来到塔罗斯！您可以使用Talos对Keras模型进行超参数优化。Talos允许您使用Keras…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">autonomio.github.io</p></div></div><div class="mu l"><div class="pl l mw mx my mu mz ky ml"/></div></div></a></div><div class="mi mj gp gr mk ml"><a rel="noopener follow" target="_blank" href="/smart-hyperparameter-optimization-of-any-deep-learning-model-using-tpu-and-talos-9eb48d09d637"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">使用TPU和塔罗斯对任何深度学习模型进行智能超参数优化</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">Keras API + Colab张量处理单元+ Talos</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">towardsdatascience.com</p></div></div><div class="mu l"><div class="pm l mw mx my mu mz ky ml"/></div></div></a></div><blockquote class="of"><p id="6d78" class="og oh it bd oi oj ok ol om on oo kn dk translated">安装:pip安装talos</p></blockquote><h1 id="5b6b" class="lf lg it bd lh li lj lk ll lm ln lo lp lq pe ls lt lu pf lw lx ly pg ma mb mc bi translated">8.夏尔巴人</h1><p id="e899" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://parameter-sherpa.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> SHERPA </a>是一个Python库，用于机器学习模型的超参数调优。</p><h2 id="dad6" class="nq lg it bd lh nr ns dn ll nt nu dp lp kb nv nw lt kf nx ny lx kj nz oa mb ob bi translated">它提供:</h2><ol class=""><li id="8e1d" class="nb nc it js b jt md jx me kb oc kf od kj oe kn ng nh ni nj bi translated">机器学习研究人员的超参数优化</li><li id="4b00" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">超参数优化算法的选择</li><li id="2fa7" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">能够满足用户需求的并行计算</li><li id="de82" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated">用于结果探索性分析的实时仪表板。</li></ol><blockquote class="of"><p id="2461" class="og oh it bd oi oj ok ol om on oo kn dk translated">安装:pip安装参数-sherpa</p></blockquote><figure class="ou ov ow ox oy kt"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h1 id="e24b" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">9.sci kit-优化</h1><p id="88e6" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://scikit-optimize.github.io/stable/user_guide.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Optimize </a>或<code class="fe ph pi pj pk b">skopt</code>，是一个简单而高效的库，可以最小化(非常)昂贵且嘈杂的黑盒函数。它实现了几种基于模型的顺序优化方法。<code class="fe ph pi pj pk b">skopt</code>旨在在多种环境下易于访问和使用。Scikit-Optimize支持调整scikit-learn库提供的ML算法的超参数，即所谓的超参数优化。</p><p id="b10a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该库建立在NumPy、SciPy和Scikit-Learn之上。</p><blockquote class="of"><p id="f324" class="og oh it bd oi oj op oq or os ot kn dk translated">安装:pip安装scikit-优化</p></blockquote><figure class="ou ov ow ox oy kt"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h1 id="dee0" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">10.GPyOpt</h1><p id="21a7" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><a class="ae le" href="https://github.com/SheffieldML/GPyOpt" rel="noopener ugc nofollow" target="_blank"> GPyOpt </a>是一个使用高斯过程优化(最小化)黑盒函数的工具。它已经被谢菲尔德大学的机器学习小组用Python实现了。GPyOpt基于<a class="ae le" href="https://github.com/SheffieldML/GPy" rel="noopener ugc nofollow" target="_blank"> GPy </a>，是Python中高斯流程建模的库。它可以通过稀疏高斯过程模型处理大型数据集。</p><h2 id="45eb" class="nq lg it bd lh nr ns dn ll nt nu dp lp kb nv nw lt kf nx ny lx kj nz oa mb ob bi translated"><a class="ae le" href="https://nbviewer.jupyter.org/github/SheffieldML/GPyOpt/blob/master/manual/index.ipynb" rel="noopener ugc nofollow" target="_blank">主要特点</a></h2><ol class=""><li id="0ede" class="nb nc it js b jt md jx me kb oc kf od kj oe kn ng nh ni nj bi translated"><a class="ae le" href="https://nbviewer.jupyter.org/github/SheffieldML/GPyOpt/blob/master/manual/GPyOpt_constrained_optimization.ipynb" rel="noopener ugc nofollow" target="_blank">任意约束的贝叶斯优化</a></li><li id="47bd" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated"><a class="ae le" href="https://nbviewer.jupyter.org/github/SheffieldML/GPyOpt/blob/master/manual/GPyOpt_parallel_optimization.ipynb" rel="noopener ugc nofollow" target="_blank">并行贝叶斯优化</a></li><li id="1838" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated"><a class="ae le" href="https://nbviewer.jupyter.org/github/SheffieldML/GPyOpt/blob/master/manual/GPyOpt_mixed_domain.ipynb" rel="noopener ugc nofollow" target="_blank">混合不同类型的变量</a></li><li id="76a2" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated"><a class="ae le" href="https://nbviewer.jupyter.org/github/SheffieldML/GPyOpt/blob/master/manual/GPyOpt_scikitlearn.ipynb" rel="noopener ugc nofollow" target="_blank">调整scikit-learn模型</a></li><li id="80df" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated"><a class="ae le" href="https://nbviewer.jupyter.org/github/SheffieldML/GPyOpt/blob/master/manual/GPyOpt_integrating_model_hyperparameters.ipynb" rel="noopener ugc nofollow" target="_blank">整合模型超参数</a></li><li id="f7cf" class="nb nc it js b jt nk jx nl kb nm kf nn kj no kn ng nh ni nj bi translated"><a class="ae le" href="https://nbviewer.jupyter.org/github/SheffieldML/GPyOpt/blob/master/manual/GPyOpt_external_objective_evaluation.ipynb" rel="noopener ugc nofollow" target="_blank">外部客观评价</a></li></ol><blockquote class="of"><p id="eebf" class="og oh it bd oi oj ok ol om on oo kn dk translated">安装:pip install gpyopt</p></blockquote><figure class="ou ov ow ox oy kt"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h1 id="4e93" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">感谢您的阅读！</h1><p id="1121" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">非常感谢您的任何反馈和意见！</p><p id="8883" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我的其他一些帖子你可能会感兴趣，</p><div class="mi mj gp gr mk ml"><a rel="noopener follow" target="_blank" href="/normality-tests-in-python-31e04aa4f411"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">Python中的10个正态性测试(分步指南2020)</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">正态性检验检查变量或样本是否呈正态分布。</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">towardsdatascience.com</p></div></div><div class="mu l"><div class="pn l mw mx my mu mz ky ml"/></div></div></a></div><div class="mi mj gp gr mk ml"><a href="https://medium.com/swlh/is-and-in-python-f084f36cbc0e" rel="noopener follow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd iu gy z fp mq fr fs mr fu fw is bi translated">Python中的“是”和“==”</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">加快字符串比较的速度</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">medium.com</p></div></div><div class="mu l"><div class="po l mw mx my mu mz ky ml"/></div></div></a></div></div></div>    
</body>
</html>