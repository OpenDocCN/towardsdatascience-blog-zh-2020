<html>
<head>
<title>One-Class Neural Network in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras中的单类神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/one-class-neural-network-in-keras-249ff56201c0?source=collection_archive---------10-----------------------#2020-11-02">https://towardsdatascience.com/one-class-neural-network-in-keras-249ff56201c0?source=collection_archive---------10-----------------------#2020-11-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4d26" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为单类分类任务开发卷积VGG</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/03e425cb3742925e51f5b12db50b99f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3LAvwK13dUmSVVOG"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@frostroomhead?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Rodion Kutsaev </a>拍照</p></figure><p id="2993" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无监督学习应用于一类分类，旨在发现在没有标签的情况下区分正常和异常数据的规则。一类SVM (OC-SVM)是一种常见的无监督方法来检测异常值。它将所有的数据点视为积极标记的实例，并在它们周围建立一个平滑的边界来检测“奇怪”的样本。</p><p id="8f5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近，基于特征提取模型的各种方法似乎是与OC-SVM一起使用的有效工具。随着深度神经网络作为特征提取器的惊人成功，利用深度学习和OC-SVM的不同方法被引入作为<strong class="lb iu">多步骤</strong>单类过程。</p><p id="6354" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们提出了一个单类卷积神经网络架构(如这里介绍的<a class="ae ky" href="https://arxiv.org/pdf/1901.08688.pdf" rel="noopener ugc nofollow" target="_blank"/>)，它合并了深度网络的能力，以提取有意义的数据表示以及单类目标，所有这些都在<strong class="lb iu">一步</strong>中完成。</p><h1 id="a6b9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型</h1><p id="a81a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">该结构由两部分组成:特征提取器和多层感知器。这种方法的一个基本方面是，任何预先训练的深度学习模型都可以用作特征提取的基础网络。最常见的选择是采用标准网络模块进行特征提取，例如，VGG、ResNet或Inception可能是这一特定任务的良好替代方案。对于在何处切割网络以生成有意义的要素制图表达，没有固定的规则。多层感知器部分位于末端，它接收嵌入的表示，并试图将它们分类为0或1。这里，1意味着输入样本属于真正的目标类，而0意味着输入样本属于噪声类。和以前一样，这部分的结构选择是不固定的。可以对其进行操作和调整，以实现更好的性能。</p><p id="0898" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在特征提取模块和最终的多层感知器网络之间发生了奇迹。正是在那里，我们可以找到整个过程的核心思想，它允许我们将特征提取与分类结合在一起，所有这些都在一个步骤中完成，并且只有一组标签可供处理。嵌入的数据样本被“破坏”,增加了一些零中心高斯噪声。然后，将这些修改后的样本与其原始配对进行批量连接。这种方法的结果是，我们有一批由原始样本(类别1)和损坏样本(类别0)形成的复制图像。我们的目标是，我们的分类层可以理解这种差异，并将真实图像与所有其他图像区分开来。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/11dfa04d504e64b3346298b61d4eb885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lFenbAJqxFi2uuFTBZ-fVQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">提议方法的模式。来源<a class="ae ky" href="https://arxiv.org/pdf/1901.08688.pdf" rel="noopener ugc nofollow" target="_blank">此处</a></p></figure><h1 id="11f7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">实验</h1><p id="3af6" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们尝试使用Tensorflow和Keras的多功能性来复制上述工作流程。首先，我们需要一个一类分类问题。所有的分类任务都可以看作是一类问题。我们可以简单地选择一个我们感兴趣的标签，然后训练一个模型来识别它，这正是我们所做的。</p><p id="2c11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">猫和狗的任务听起来不错。这是因为我们可以利用一些标准和预训练的深度学习模型来利用迁移学习的力量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/592b8b05a61fc902ece09f28214c2c47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f0VMCqxN8lW0E610xgGqHA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练样本图片<a class="ae ky" href="http://kaggle.com/tongpython/cat-and-dog" rel="noopener ugc nofollow" target="_blank">数据</a></p></figure><p id="b0cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始选择自己感兴趣的标签，比如说“猫”。我们在训练数据中只取猫的图像。这些狗在测试期间被找回。在猫，我们给它贴上1的标签。标签0是在训练期间自动创建的，由一些随机高斯图像组成。原来只有猫的批量输入是这样复制的，现在是由标记数据和随机信号形成的。真实图像被馈入特征提取器网络。在我们的例子中，它由一个预先训练好的VGG组成。VGG为我们的真实图像创建了一个有意义的嵌入式表示，这些图像与随机图像连接在一起。此时，它们通过一个多层感知器神经网络，其中的权重是可训练的。最后，我们有了一个完整的架构，可以识别猫，并且只对猫进行训练！模型的推论可以一如既往地计算出来。我们停用负责产生随机嵌入表示的网络部分，并且只保留特征提取器和多层感知器。我们测试程序传递给网络猫和狗的图像。如果成功，狗必须被归类为噪音(相当于标签0)。</p><p id="4bb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了得到可靠的结果，拟合过程必须应用于我们所掌握的所有类。在我们的例子中，我们仅用“猫”来拟合模型，然后仅用“狗”来拟合模型。总性能是所有单个任务性能的平均值。我们获得了大约85%的最终准确率，这对于一类学习过程来说是非常好的！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/62168dcccfe9fcfab4d3052deb1807d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O0r847Dygrw9vWBxYntm1g.png"/></div></div></figure><h1 id="60a7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="5aad" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这篇文章中，我们介绍了一个在单类分类任务上进行端到端训练的架构。这种方法适用于利用预先训练的迁移学习表示的每个领域。它也是一个很好的资源，可以应用于检索标记数据需要大量成本的每一个场景。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><p id="b20f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的GITHUB回购</strong> </a></p><p id="1c14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><p id="8e0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献</strong></p><p id="c47b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一类卷积神经网络。Poojan Oza，IEEE学生会员，和Vishal M. Patel，IEEE高级会员</p></div></div>    
</body>
</html>