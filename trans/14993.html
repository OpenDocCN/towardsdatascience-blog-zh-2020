<html>
<head>
<title>Prediction of P-Sonic Log in the Volve Oil Field using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于机器学习的Volve油田声波测井预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/prediction-of-p-sonic-log-in-the-volve-oil-field-using-machine-learning-9a4afdb92fe8?source=collection_archive---------21-----------------------#2020-10-15">https://towardsdatascience.com/prediction-of-p-sonic-log-in-the-volve-oil-field-using-machine-learning-9a4afdb92fe8?source=collection_archive---------21-----------------------#2020-10-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b04c" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="53b7" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用Scikit-Learn逐步解释</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/1ab1ea6e3633d0007818f83a164a6e18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nps3TfVy_nfsyss11X3FPQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">rsk Inspirer på Volve来自<a class="ae le" href="https://communicationtoolbox.equinor.com/brandcenter/en/equinorbc/component/default/22936" rel="noopener ugc nofollow" target="_blank"> Equinor照片档案馆</a></p></figure><p id="2445" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">2018年，挪威石油公司Equinor披露了北海Volve油田的大规模地下和作业数据集。两年来，对于所有热衷于改善和解决大学、研究机构和公司油气领域研究挑战的人来说，这是一个好消息。以下是来自“马科动物的首席运营官”<a class="ae le" href="https://www.equinor.com/en/about-us/corporate-executive-committee/jannicke-nilsson.html" rel="noopener ugc nofollow" target="_blank">扬尼克·尼尔森</a>的一段鼓舞人心的话。</p><blockquote class="mb"><p id="53eb" class="mc md iq bd me mf mg mh mi mj mk ma dk translated">“Volve是我们如何寻找各种可能性来延长油田寿命的一个例子。现在，我们希望分享所有Volve数据，以确保未来解决方案的学习和开发。”</p></blockquote><p id="e229" class="pw-post-body-paragraph lf lg iq lh b li ml ka lk ll mm kd ln lo mn lq lr ls mo lu lv lw mp ly lz ma ij bi translated">Volve是一个油田，位于北海挪威区块南端斯塔万格以西200公里处，于2008年至2016年生产。</p><p id="7c7c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当我查看每个人都可以通过这个网站<a class="ae le" href="https://www.equinor.com/en/how-and-why/digitalisation-in-our-dna/volve-field-data-village-download.html" rel="noopener ugc nofollow" target="_blank">访问的数据库</a>时，我看到了里面巨大的宝藏！我开始提出一些想法来探索引入机器学习的可能性，直到我想到了进行<strong class="lh ja">声波测井预测</strong>的想法，原因我在本文的<strong class="lh ja">动机</strong>部分中阐述。</p><p id="818d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我将这个项目保存在我的名为<strong class="lh ja"><em class="mq">volve-machine-learning</em></strong>的<a class="ae le" href="https://github.com/yohanesnuwara/volve-machine-learning" rel="noopener ugc nofollow" target="_blank"> GitHub </a>资源库中(你可以访问这个资源库)。</p><h2 id="c51b" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">数据集概述</h2><p id="9c91" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">在Volve油田开放数据库中，有24口井。在这项研究中，只使用了5口井。油井名称为15/9-F-11A、15/9-F-11B、15/9-F-1A、15/9-F-1B和15/9-F-1C。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/c91d51099f9e930f787ea57f281a5f68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHPGnEWaS4kPbNkxxVzdrA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">测井数据代表地球上的每个岩层(<a class="ae le" href="https://www.intechopen.com/books/fractal-analysis-and-chaos-in-geosciences/well-logs-data-processing-using-the-fractal-analysis-and-neural-network" rel="noopener ugc nofollow" target="_blank"> Aliouane等人，2012 </a>)</p></figure><p id="2ab5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">每口井都有他们所谓的<strong class="lh ja">测井记录</strong>。测井记录是代表深度范围内每个岩层属性的某些物理测量值。以下是我们将使用的日志列表。</p><ul class=""><li id="185c" class="np nq iq lh b li lj ll lm lo nr ls ns lw nt ma nu nv nw nx bi translated">NPHI是地层孔隙度，单位为v/v</li><li id="08ed" class="np nq iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">RHOB是地层体积密度，单位为克每立方厘米。</li><li id="a8a5" class="np nq iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">GR是地层放射性含量，用API测量。</li><li id="fd93" class="np nq iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">RT是地层真实电阻率，单位为欧姆米。</li><li id="d89e" class="np nq iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">PEF是地层光电吸收因子，无量纲。</li><li id="67b2" class="np nq iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">CALI是钻孔直径，单位为英寸。</li><li id="7e09" class="np nq iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">DT是纵波传播时间，单位是微秒每英尺。</li><li id="9c41" class="np nq iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">DTS是剪切(横波)传播时间，与DT类似。</li></ul><p id="1a84" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这些测井数据集的文件格式为LAS 2.0，这是测井的一种特定格式。你可以在这里找到数据集。</p><h2 id="b79d" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">动机</h2><p id="8933" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">5口井中有3口井(15/9-F-11A井、15/9-F-1A井和15/9-F-1B井)拥有这套完整的测井资料，<strong class="lh ja">除了</strong>之外，另外2口井(15/9-F-11A井和15/F-1C井)没有DT和DTS测井资料。<strong class="lh ja">这就是为什么</strong>我们可以使用监督学习，通过回归模型在这个不完整的数据集中生成DT日志。</p><p id="aa6e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有DT日志的3个数据集作为<strong class="lh ja">训练数据</strong>，没有的作为<strong class="lh ja">测试数据</strong>。NPHI、RHOB、GR、RT、PEF和CALI测井用作<strong class="lh ja">特征</strong>；而DT是用于预测的<strong class="lh ja">目标</strong>。目前，不会使用DTS日志。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi od"><img src="../Images/0ddec1af009a31faf054ac6a49918ba2.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*yYcUcgToyQdBe4n-VNgmvg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">scikit-从<a class="ae le" href="https://github.com/scikit-learn/scikit-learn/blob/master/doc/logos/scikit-learn-logo.svg" rel="noopener ugc nofollow" target="_blank"> GitHub </a>学习徽标</p></figure><p id="7d04" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通过监督学习，这些训练数据会用<a class="ae le" href="https://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"><em class="mq">Scikit-Learn</em></a><em class="mq">中的一些<strong class="lh ja">回归模型</strong>进行训练。</em>然后，该模型将用于根据特征预测产生新的DT测井曲线。</p><p id="0008" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我将把工作流程分成<strong class="lh ja">七个步骤</strong>。您也可以在我的GitHub repo中访问我的IPython笔记本，它从头到尾运行这个工作流。</p><blockquote class="oe of og"><p id="d224" class="lf lg mq lh b li lj ka lk ll lm kd ln oh lp lq lr oi lt lu lv oj lx ly lz ma ij bi translated"><strong class="lh ja">访问我的IPython </strong> <a class="ae le" href="https://github.com/yohanesnuwara/volve-machine-learning/blob/main/notebook/volve_p_sonic_prediction_final.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">笔记本</strong> </a></p></blockquote><h2 id="78a3" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">第一步。显示测井数据集</h2><p id="c5ca" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">一个名为<a class="ae le" href="https://lasio.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <em class="mq"> lasio </em> </a>的Python库用于读取这些LAS数据集。在任何地层评价中，显示测井记录都是例行公事。以下是使用<em class="mq"> Matplotlib </em>生成的其中一个训练数据15/9-F-1B井的显示。每个图代表一条测井曲线；正如我们已经讨论过的，NPHI、RHOB、GR、RT、PEF和CALI是特征，而DT是目标。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/e94c7a43205d6de2988400b37698c24b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9pMaPnOjNeoxP-o0gclgow.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">1B 15/9井的测井显示</p></figure><p id="e152" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">以下是15/9-F-1C井的测井曲线显示，该井是没有DT测井的两口井之一，因此我们将预测产生一个新的DT测井曲线。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/0e3ce96d6591c46655c61147388039a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U7t4amvEI1NMuB0GMjDg-w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">15/9-F-1C井的测井显示</p></figure><h2 id="d42e" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">第二步。数据准备</h2><p id="ed5c" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">第二步是工作流程中最关键的部分，因为它会影响整个预测的成功。<em class="mq">熊猫</em>对数据处理很有用。</p><p id="028b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">首先，我们需要确保我们的整个数据不包含任何<strong class="lh ja">非数字值</strong> (NaNs)。过滤数据的一个技巧是<strong class="lh ja">设置最小和最大深度限制</strong>，这样所有数据<strong class="lh ja">都以数值</strong>开始和结束。例如，之前显示的15/9-F-1B井从3100米到3400米的深度开始。示例代码:</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="fc9e" class="mr ms iq on b gy or os l ot ou">df = df.loc[(df['DEPTH'] &gt;= 3100) &amp; (df['DEPTH'] &lt;= 3400)]</span></pre><p id="045e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">之后，我们检查数据中是否存在nan。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="e5be" class="mr ms iq on b gy or os l ot ou">df.isnull().sum()</span></pre><p id="9a53" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果一切归零，我们就安全了。在我们现在的情况下，它变为零，我们已经没有NaNs了。否则，我们需要处理NaN值。这个动作在<a class="ae le" href="https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html" rel="noopener ugc nofollow" target="_blank">这里</a>详细讨论。</p><p id="8e25" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">接下来，我们<strong class="lh ja">将各个井数据集</strong>合并到两个更大的单个数据框中，每个数据框用于训练和测试数据集。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="58fe" class="mr ms iq on b gy or os l ot ou">df = pd.concat([df1, df2, df3])</span></pre><p id="b2b6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在我们有了训练和测试数据框架，最后我们分配井名。这样做的原因是为了便于我们在预测期间检索任何井。你可以在笔记本里看到我是如何分配井名的。</p><p id="8e99" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面是训练数据的最终数据框。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ov"><img src="../Images/bba2a3b13bcf6cb9e906b2fc70f7d7b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*joBREm2A4_nM_1xTgEx6lQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">训练数据帧</p></figure><h2 id="6c97" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">第三步。探索性数据分析</h2><p id="344d" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">探索性数据分析(EDA)对于理解我们的数据至关重要。我们想知道的两件重要的事情是每个单独特征的<strong class="lh ja">分布</strong>和一个特征到另一个特征的<strong class="lh ja">相关性</strong>。</p><p id="170c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了观察多元分布，我们可以在<em class="mq"> Seaborn </em>包中使用一个pair-plot。以下是特征和目标的多元分布。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ow"><img src="../Images/f5474fc190e2adbc6e59adca9d31490e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PFZLdoQT008vhu7JwRYI0A.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">训练数据集的配对图</p></figure><p id="6cbd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们从结对图中至少得到了3点。首先，我们观察大多数分布是如何偏斜的，并且<strong class="lh ja">不是理想的高斯</strong>，尤其是RT。然而，对于机器学习，高斯或不太偏斜的数据是优选的。我们可以对这些数据进行标准化，这将在下面讨论。第二，我们可以看到数据里面的<strong class="lh ja">离群值</strong>。同样在下一部分，我们将讨论如何去除这些异常值。第三，我们看到一些数据对几乎<strong class="lh ja">线性(因此高度)相关</strong>，比如NPHI和DT；和<strong class="lh ja">反向相关</strong>，比如RHOB和DT。配对图说明了很多事情。</p><p id="a614" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们通过计算<a class="ae le" href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> Spearman相关性</strong> </a>来查看更多特征和目标之间的相关性，并使用<strong class="lh ja">热图</strong>来可视化结果。以下是我们数据的Spearman相关热图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ox"><img src="../Images/620d207e7472dec9a1241c56b515852c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zcMK5oJhWaxZVUT5L0MitA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">训练数据的Spearman相关热图</p></figure><p id="3589" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">只关注DT行，我们获得了DT和NPHI之间的2个最大相关(正相关为. 95)以及DT和RHOB之间的2个最大相关(负相关为. 79)。这个相关结果与我们之前在配对图中看到的结果相匹配。还有，除了CALI，其他数据似乎都和DT有很高的相关性。CALI似乎与其他特征也没有什么关联。</p><p id="676d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">作为惯例，任何相关性非常低的特征都被排除在预测之外，因此CALI可以被排除。然而在这里，我将保留CALI作为一个特性。</p><h2 id="a8d6" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">第四步。正常化</h2><p id="b476" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">我们以前从配对图中知道，大多数分布似乎是偏斜的。为了提高我们的预测性能，稍后，我们最好做一个归一化(其他人可能称之为<strong class="lh ja">缩放</strong>)。规范化是一种转换数据(不改变数据)以更好地分布数据的技术。</p><p id="fcc4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在进行任何标准化之前，我倾向于先对电阻率数据进行<strong class="lh ja">测井转换。</strong></p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="bc26" class="mr ms iq on b gy or os l ot ou">df['RT'] = np.log10(df['RT'])</span></pre><p id="4b97" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，我用<em class="mq"> Scikit-Learn </em>中的函数<code class="fe oy oz pa on b">fit_transform</code>进行规范化。有几种标准化技术；广泛使用的有<strong class="lh ja">标准化</strong>(用均值和标准差转换)和<strong class="lh ja"> min-max </strong>(用最小值和最大值)。在尝试了所有的方法后，我找到了使用<a class="ae le" href="https://en.wikipedia.org/wiki/Power_transform#Yeo%E2%80%93Johnson_transformation" rel="noopener ugc nofollow" target="_blank"><strong class="lh ja">Yeo-Johnson</strong></a><strong class="lh ja">方法</strong>的<strong class="lh ja">力量转换</strong>技巧。</p><p id="5475" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">归一化后，我们可以看到数据现在是如何使用pair-plot再次分布的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ow"><img src="../Images/45e5f9445bddd6062bc65c8f641b7a0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t0q7nk8IomVEJVO6x_T9_Q.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用Yeo-Johnson方法进行幂变换后的训练数据对图</p></figure><p id="a8fa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">看看NPHI、DT和RT现在如何不那么偏斜，更像高斯分布。虽然RHOB和GR分布看起来是多峰的，但归一化后它变得更加集中。</p><h2 id="3bc3" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">第五步。移除异常值</h2><p id="a04b" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">此外，我们刚刚观察到数据中有许多异常值。异常值的存在会降低预测性能。因此，我们做离群点剔除。</p><p id="3517" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="mq"> Scikit-Learn </em>提供了几种离群点剔除方法，如<strong class="lh ja">隔离森林</strong>、<strong class="lh ja">使用椭圆包络的最小协方差</strong>、<strong class="lh ja">局部离群因子</strong>、<strong class="lh ja">单类支持向量机</strong>。除此之外，最广泛使用的异常值去除方法，也是最基本的方法，是使用<strong class="lh ja">标准差方法</strong>。在这种方法中，我们将阈值指定为偏离标准偏差的最小值和最大值。我们可以自己建造。</p><pre class="kp kq kr ks gt om on oo op aw oq bi"><span id="3a1a" class="mr ms iq on b gy or os l ot ou">threshold = 3<br/>df = df[np.abs(df - df.mean()) &lt;= (threshold * df.std())]</span></pre><p id="1c02" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所有5种方法都已实现。我用两种方法来比较哪种方法去除异常值的效果最好。一种方法是对每种方法计算剔除异常值之前的数据和剔除异常值之后的数据。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/bcc030337b625c4a4ecdf869bea633c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lp7AKO_P8lu7HnW70S1ZYQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">标准化前后的数据计数</p></figure><p id="216c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">从该结果中，我们看到<strong class="lh ja">标准差</strong>方法移除的异常值最少(最多只有302个)，其次是<strong class="lh ja">单类SVM </strong>和<strong class="lh ja">最小协方差</strong>，与其他方法相比异常值相对较少(&gt; 10，000)。您可能已经知道，<strong class="lh ja">剔除的异常值越少越好</strong>。</p><p id="d2ae" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，为了决定标准差和一类SVM之间哪个更好，我使用<em class="mq">熊猫</em>为归一化前后的每个特征生成了<strong class="lh ja">箱线图</strong>。下面是箱线图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pc"><img src="../Images/d9e71de29527467fd4a344de24c13d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GJ6tDH2P-P5a1dsEE5oroQ.png"/></div></div></figure><p id="711d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">关键的观察结果是，在剔除异常值前后，<strong class="lh ja">异常值仍然存在于新计算的汇总统计数据的数据</strong>中。这(间接地)是选择哪种方法是最好的直观表示。</p><p id="2ad3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，通过观察异常值的数量，可以看出<strong class="lh ja">一类SVM比标准差方法表现得</strong>更“干净”。尽管最小的协方差也是干净的，仍然一级SVM是赢家。</p><p id="814d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">结论是:我们用<strong class="lh ja">一级SVM </strong>。同样，我们制作一个配对图来观察我们数据的最终结果。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ow"><img src="../Images/2a07d75571a16c6d6d932cf31fa39a8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CypC7XQUdD-EYYVLIH1fyA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用一类SVM方法去除异常值后的训练数据对图</p></figure><p id="d771" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">看看离群值现在是如何减少的。我们都为机器学习做好了准备。</p><h2 id="9e65" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">第五步。预测！第一次尝试</h2><p id="18ba" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">现在主菜来了！第五步，我们还没有对我们的真实测试数据(没有DT测井的井15/F-11B和15/F-1C)进行实际预测。耐心点！我们需要评估我们使用的每个回归模型的性能，方法是<strong class="lh ja">训练训练数据，并用训练数据本身测试模型</strong>，然后我们评估预测的DT日志与真实DT日志的接近程度。</p><blockquote class="mb"><p id="1546" class="mc md iq bd me mf mg mh mi mj mk ma dk translated">在此步骤中，测试数据=训练数据</p></blockquote><p id="e603" class="pw-post-body-paragraph lf lg iq lh b li ml ka lk ll mm kd ln lo mn lq lr ls mo lu lv lw mp ly lz ma ij bi translated">我尝试了来自<strong class="lh ja"> Scikit-Learn </strong>的6个回归模型，分别是经典的<strong class="lh ja">线性回归</strong>、<strong class="lh ja">随机森林</strong>、<strong class="lh ja">支持向量机</strong>、<strong class="lh ja">决策树</strong>、<strong class="lh ja">梯度推进</strong>、<strong class="lh ja">K-最近邻</strong>回归器。</p><p id="2457" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">请记住，在完成预测后，我们总是需要对结果进行反规范化，因为我们刚刚进行了规范化。在<em class="mq"> Scikit-Learn </em>中，我们使用一个<code class="fe oy oz pa on b">inverse_transform</code>函数来完成这项工作。</p><p id="7f1a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我使用R和均方根误差(RMSE)作为评分标准来衡量每个回归模型的性能。以下是每个回归变量的评分标准的结果。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pd"><img src="../Images/f58e8093fe705c09daf0eaf86b325aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lqSDTF8ZiUQQpuBxVjhE7w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">6个回归变量的评分标准</p></figure><p id="e86c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">从结果来看，我们看到回归器的表现非常出色！可以理解为什么经典的线性回归器不如其他回归器(最低的R和RMSE)表现得好。原因是并非所有的特征都是完美的线性相关的。</p><p id="1fb2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，我们可以显示真实的DT日志和预测的DT日志，以比较两者的接近程度。以下是使用梯度推进回归器对每口井预测DT测井的真实值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pe"><img src="../Images/e634a440d345d9c369065bb654c6712e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G0hkoBfjJTYYoMGBsw3Fww.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用梯度推进回归器的真实与预测DT测井</p></figure><p id="d9fe" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">事实上，我使用的所有回归变量仍然使用默认的超参数。例如，梯度增强的几个超参数中的两个是估计器的数量和最大深度。默认值分别为100和3。</p><p id="6038" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">根据梯度推进的评分标准，我们已经知道R和RMSE分别达到了0.94和0.22左右。我们可以进行<strong class="lh ja">超参数调整</strong>以确定最佳超参数值，从而提高性能得分。</p><h2 id="54d1" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">第六步。超参数调谐</h2><p id="e881" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">梯度推进回归器上的超参数调谐通过执行<strong class="lh ja">训练-测试分割</strong>开始，该分割由0.7训练和0.3测试组成。然后，通过产生的训练和测试分裂，进行具有定义的搜索超参数集的<strong class="lh ja">网格搜索</strong>和<strong class="lh ja">三重交叉验证</strong>。以下是搜索到的参数网格。</p><ul class=""><li id="4d66" class="np nq iq lh b li lj ll lm lo nr ls ns lw nt ma nu nv nw nx bi translated">估计数<code class="fe oy oz pa on b">n_estimators</code> : 100和1000</li><li id="5545" class="np nq iq lh b li ny ll nz lo oa ls ob lw oc ma nu nv nw nx bi translated">最大深度<code class="fe oy oz pa on b">max_depth</code> : 10和100</li></ul><p id="2e36" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">调整超参数花费了大约5分钟，直到给出估计器数量为<strong class="lh ja"> 1，000，最大深度为</strong>100的结果作为最佳超参数。</p><p id="207f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，通过包含超参数重复前面的步骤，并打印新的得分度量，如下所示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/6307c191e93e2809e6f28fd36f7d70fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*mXnpMwdBn9RfSqaNPJYH3w.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">超参数调整后梯度增强的评分标准</p></figure><p id="dcc5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">R和RMSE都提高了很多，分别是0.98和0.12左右！有了这个结果，我们有足够的信心使用梯度推进进行预测。以下是超参数调整后的真实与预测DT对数图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pe"><img src="../Images/2cda3e7d354a2d2f31c5e0d1ac475068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y6Nzb5y8bxEx4SFCAz5f2Q.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">超参数调整后使用梯度推进回归器的真实与预测DT测井</p></figure><h2 id="4a3a" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">第七步。为最终预测编译调整后的梯度推进回归器</h2><p id="ea44" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">最后我们做真正的预测！现在，用之前根据我们的实际测试数据调整的超参数(估计数= 1000，最大深度= 10)编译梯度推进回归器。记住，我们真正的测试数据是没有DT测井的井；15/9-F-11B井和15/9-F-1C井，或所谓的2井和5井。</p><p id="0ac2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">以下是2井和5井的预测DT测井。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pg"><img src="../Images/c77b53b048659e1b2ac52f0ef7c511e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*j4fBxSbyKAdFORhrbQPrsQ.png"/></div></div></figure><p id="9330" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">15/9-F-11B井和15/9-F-1C井的预测测井曲线令人满意！为了关闭我们的工作流程，我们可以<strong class="lh ja">将预测结果</strong>导入到原始数据集并写入CSV文件。</p><p id="eed7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">以下是最终的CSV结果:井<a class="ae le" href="https://github.com/yohanesnuwara/volve-machine-learning/blob/main/results/15_9-F-11B_Predicted_DT.csv" rel="noopener ugc nofollow" target="_blank"> 15/9-F-11B </a>和<a class="ae le" href="https://github.com/yohanesnuwara/volve-machine-learning/blob/main/results/15_9-F-1C_Predicted_DT.csv" rel="noopener ugc nofollow" target="_blank"> 15/9-F-1C </a></p><h2 id="0022" class="mr ms iq bd mt mu mv dn mw mx my dp mz lo na nb nc ls nd ne nf lw ng nh ni iw bi translated">结论</h2><p id="a5ae" class="pw-post-body-paragraph lf lg iq lh b li nj ka lk ll nk kd ln lo nl lq lr ls nm lu lv lw nn ly lz ma ij bi translated">我们已经证明了监督学习在Equinor拥有的Volve油田公开数据集上的成功应用。通过这一工作流程，使用梯度推进方法，在两口原本没有压力声波测井记录的油井上预测了新的压力声波测井记录。</p><p id="4ed5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我希望这篇文章能为地球科学中的任何ML从业者带来新鲜空气，开始探索这个数据集中ML的其他可能性。与此同时，我正在考虑其他的可能性，我会在我的<a class="ae le" href="https://github.com/yohanesnuwara/volve-machine-learning" rel="noopener ugc nofollow" target="_blank"> GitHub </a> ( <strong class="lh ja">关注我的工作以获得更新</strong>)中积极更新，并且很快会再写一篇！</p></div></div>    
</body>
</html>