<html>
<head>
<title>How to choose the best Linear Regression model — A comprehensive guide for beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何选择最佳线性回归模型——初学者综合指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-choose-the-best-linear-regression-model-a-comprehensive-guide-for-beginners-754480768467?source=collection_archive---------11-----------------------#2020-10-02">https://towardsdatascience.com/how-to-choose-the-best-linear-regression-model-a-comprehensive-guide-for-beginners-754480768467?source=collection_archive---------11-----------------------#2020-10-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/432fedfc0f2976a3f9ef01c8f5553506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eJn9eEX7Lx8UCfRf2tgW0g.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">由<a class="ae kf" href="https://unsplash.com/@element5digital" rel="noopener ugc nofollow" target="_blank">元件5数码</a>在<a class="ae kf" href="https://unsplash.com/photos/OyCl7Y4y0Bk" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的图像</p></figure><p id="091f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你是数据科学或统计学的初学者，有一些线性回归的背景，并且正在寻找评估你的模型的方法，那么这个指南可能适合你。</p><p id="265d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文将讨论以下用于选择“最佳”线性回归模型的指标:R平方(R)、平均绝对误差(MAE)、均方误差(MSE)、均方根误差(RMSE)、赤池信息标准(AIC)以及考虑偏差的修正变量。将假定您了解线性回归。我希望你喜欢读这篇文章，觉得它有用，并学到一些新东西:)</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h2 id="c0b2" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated"><strong class="ak"> R平方(R ) </strong></h2><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi me"><img src="../Images/d097affe02ec405139ed081f8f8ed932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c5k5I5sqiwttIkRy9Frcdg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">y =因变量值，y_hat =模型预测值，y _ bar =的平均值</p></figure><p id="c206" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">R值，也称为<strong class="ki iu">决定系数，</strong>告诉我们用y_hat表示的预测数据，<strong class="ki iu">解释了用y表示的</strong>实际数据。换句话说，它代表了拟合的强度，但是它并没有说模型本身的任何事情-它没有告诉你模型是否好，你选择的数据是否有偏差，或者你是否选择了正确的建模方法。我将用下面的例子来说明这一点。</p><p id="13fa" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">R值的范围从0到1，较高的值表示强拟合，较低的值表示弱拟合。通常，大家都同意:</p><blockquote class="mj"><p id="6975" class="mk ml it bd mm mn mo mp mq mr ms ld dk translated">R &lt; 0.5 → Weak fit</p><p id="5a60" class="mk ml it bd mm mn mo mp mq mr ms ld dk translated">0.5 ≤ R² ≤ 0.8 → Moderate fit</p><p id="8a34" class="mk ml it bd mm mn mo mp mq mr ms ld dk translated">R² &gt; 0.8 →强配合</p></blockquote><p id="61bc" class="pw-post-body-paragraph kg kh it ki b kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld im bi translated"><strong class="ki iu">注意:理论上R &lt; 0是可能的，但是这些会出现在<em class="my">明显</em>可怕的配合中，因此本文不会讨论。</strong></p><p id="d7c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可能会想，如果R不代表模型有多好，那么“拟合强度”到底是什么意思？这意味着，<strong class="ki iu">平均而言</strong>，你的预测值(y_hat)与你的实际数据(y)偏差不大。下面的例子将说明这一点。</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mz"><img src="../Images/51c11836c3d00b4970d8ab160ff1fc93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dn0UrGB5KSFR2BU-TSICZw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">(左)线性预测的二次模型，(右)线性预测的线性模型</p></figure><p id="695e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的两个模型都预测了给出“强”拟合的线，因为它们具有高R值，并且还捕捉了实际数据点与拟合线的小偏差。然而，很明显，尽管左边的模型具有更高的R值，但是右边的模型是更好的模型。事实上，最左边的模型很糟糕，因为它没有捕捉到数据的曲率。<strong class="ki iu">因此，高R并不意味着拟合良好或合适，它只是意味着实际点与拟合点的偏差平均来说很小。</strong></p><p id="0062" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有时，一个模型可能有一个低R值，但实际上是一个很好的数据模型。考虑下面的例子:</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi na"><img src="../Images/aa55c46e38f0e51579c81e8f13cd0d01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gZ7PcyyPgDJRDKKAwmCWoQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">(左)用直线拟合正弦曲线，(中)用有小噪声的直线拟合故意偏斜的直线，(右)用有大噪声的直线拟合正确的直线</p></figure><p id="c8fe" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与前面的例子一样，左边的模型非常不适合，但“适合度”适中，因此与右边的模型相比，仅根据R值，人们可能会认为最左边的模型更好。如图所示，这是错误的。中间款呢？它的R是右边模型的三倍，而且，从视觉上看，似乎并不完全离谱。因此，有人可能会得出这样的结论:中间模式比正确模式好得多？</p><p id="2810" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不对。</p><p id="b0f8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">中间和右边模型中的数据点基于同一条线，<strong class="ki iu"> y=x+e </strong>，其中<strong class="ki iu"> e </strong>是正态分布中随机产生的误差。它们之间的唯一区别是，误差幅度在最右边的图中被放大了。中间的模型比右边的<strong class="ki iu">更差</strong>，因为我故意扭曲了它，所以它的等式是这样的:</p><p id="0842" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> y_hat = 1.25*x-25 </strong></p><p id="ab80" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，右边的模型是正确的:它是<strong class="ki iu"> y_hat = x </strong>，与生成数据点的线完全相同。为了直观地证实这一点，您可以看到中间模型的偏斜，而右边的模型似乎位于数据点的正中心，正如您所料。<strong class="ki iu">因此，具有低R的模型仍然可以正确地预测数据的形状，但是会遭受数据的较大变化。</strong></p><p id="44a6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管如此，如果问题的本质是预测值，那么中间模型可能会由于数据点的较低变化而表现得更好，但是这并不一定使它成为更好的模型。</p><p id="5862" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> R总结</strong></p><blockquote class="nb nc nd"><p id="9865" class="kg kh my ki b kj kk kl km kn ko kp kq ne ks kt ku nf kw kx ky ng la lb lc ld im bi translated">R度量给出了模型与您的数据拟合程度的指示，但无法解释您的模型是否良好</p></blockquote><p id="e5f6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">优点:</strong></p><ol class=""><li id="94de" class="nh ni it ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">给出模型拟合程度的指示</li></ol><p id="fc98" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">缺点:</strong></p><ol class=""><li id="1a95" class="nh ni it ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">向模型中添加预测值可能会由于偶然性而增加R的值，使结果具有误导性(参见<strong class="ki iu">调整后的R </strong></li><li id="7831" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">向模型中添加预测值会导致“过度拟合”，即模型试图预测数据中的“噪声”。这降低了它在以前从未见过的“新”数据上表现更好的能力。</li><li id="eac3" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">r对于非线性模型没有意义</li></ol></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h2 id="b4f3" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated">调整后的R (Adj. R ) </h2><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/fdbf0f0fedc9e497d05b55712fef2a7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zym7on7W3p0ORO_qMgpjwg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">n =样本中数据点的数量，k =包括模型中变量的数量，不包括常数项(截距)</p></figure><p id="5f61" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如前所述，<strong class="ki iu">即使模型的性能没有改善，向模型添加预测值也会导致R增加。</strong>对此的解决方案是使用调整后的R而不是R来衡量模型的表现。</p><p id="e0e0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上式可以看出，多了两个变量:<strong class="ki iu"> <em class="my"> n </em> </strong> <em class="my"> </em>和<strong class="ki iu"> <em class="my"> k </em> </strong> <em class="my">。</em>前者代表模型中数据点的数量，后者代表模型中变量的数量，不包括常数项。</p><p id="0169" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，如果模型的形式为:</p><p id="6512" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> y_hat =a0 + a1*x1 + a2*x2 </strong></p><p id="54b9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后你有<strong class="ki iu"> <em class="my"> k = 2 </em> </strong> <em class="my">，</em>既然你有两个预测器，<strong class="ki iu"> a1 </strong>和<strong class="ki iu"> a2。</strong></p><p id="6d8a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">那么为什么调整后的R平方比R平方好呢？</strong></p><p id="c50e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑以下两种模型:</p><p id="d379" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> y_hat = x </strong></p><p id="72e9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">y _ hat = A0+a1 * x1+a2 * x+a3 * x+a4*x⁴⁴+a5*x⁵⁵+a6*x⁶⁶+a7*x⁷⁷</strong></p><p id="8eb2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同样的数据，基于<strong class="ki iu"> y=x+e </strong>被模型预测，结果如下所示:</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nw"><img src="../Images/02fff549ab8658bc860e5be943e8f92f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kRo-Ivdimb7yUirFNI3r_A.png"/></div></div></figure><p id="0684" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如图所示，左边模型(有更多项)的R高于右边模型，这表明它是一个更好的模型。我们知道这不是真的，因为数据是建立在<strong class="ki iu"> y=x+e </strong>之上的。</p><p id="c435" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们检查调整后的R值时，我们看到最右侧模型的R值基本保持不变，而最左侧模型的R值发生了显著变化，这表明增加项数会对R值产生影响。在这种特殊情况下，人们可能会选择最左边的模型，因为即使考虑了额外的项，它也具有更高的调整后R。我们知道这是错误的，它可能只是随机误差的结果。<strong class="ki iu">从本文第一部分我们也知道，R越高并不代表型号越好！</strong></p><p id="13ad" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以通过使用相同的模型拟合“新数据集”来进一步检验这一点，从而消除“训练偏差”。</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nx"><img src="../Images/6b9388373d4a15b69e27e172aae97575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BM9XbcYweqHm-7YRz1Z2uw.png"/></div></div></figure><p id="8b77" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，线性模型的拟合度明显优于多项式模型(左)，R值和调整后的R值与之前的数据集相当。然而，多项式模型的表现很好，因为它“适合”误差和噪声，表现非常糟糕，当根据变量的数量进行调整时，R甚至下降更多。</p><p id="8a6e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与往常一样，对于R和Adj. R，绘制结果模型是一种很好的做法，以直观地检查结果是否有意义，如果结果没有意义，添加额外的数据点或使用不同的“测试”数据集可能会提供更多的洞察力。</p><p id="b154" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">调整后的R汇总</strong></p><blockquote class="nb nc nd"><p id="c533" class="kg kh my ki b kj kk kl km kn ko kp kq ne ks kt ku nf kw kx ky ng la lb lc ld im bi translated">调整后的R在R的基础上有所改进，它让我们了解模型的R值是因为拟合度好，还是因为它的复杂性</p></blockquote><p id="5bf0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">优点:</strong></p><ol class=""><li id="ccbf" class="nh ni it ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">对过度拟合问题有了更深入的了解</li><li id="aeb8" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">降低随机性对R值的影响(即，如果由于随机性而导致R值较高，调整后的R将会反映这一点)</li></ol><p id="d874" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">缺点:</strong></p><ol class=""><li id="d524" class="nh ni it ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">仍然存在与R相关的其他问题</li></ol></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h2 id="4d9f" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated"><strong class="ak">平均绝对误差</strong></h2><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ny"><img src="../Images/85d5d94728936ad6f0395601a664544c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ZaWrLdDK4tOb4jGoKygFg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">n =点数，y =实际点，y_hat =预测点</p></figure><p id="91a9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MAE是所有误差幅度的总和除以点数，因此本质上是平均误差。</p><p id="f372" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，MAE越低，模型中的误差越小。</p><h2 id="6492" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated"><strong class="ak">均方误差</strong></h2><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/c612cc31c43c45d31de773969b546bf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8bYH8ji8ACMC-E49uDmvsg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">n =点数，y =实际点，y_hat =预测点</p></figure><p id="f903" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MSE是所有误差的<strong class="ki iu">平方和</strong>除以点数。请注意，由于在每个实例中，误差实际上都是平方的，因此不能直接与MAE进行比较，因为它总是更高阶的。</p><p id="2cb8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，与MAE一样，MSE越低，模型中的误差越小。</p><h2 id="c816" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated"><strong class="ak">均方根误差(RMSE) </strong></h2><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oa"><img src="../Images/e605a621e57f310c57768d70ee8fcfcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z1nGnHTQpK6ayqlwBYI9Gg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">n =点数，y =实际点，y_hat =预测点</p></figure><p id="b784" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">RMSE是均方差的平方根。这在某种程度上是一个更有用的度量，现在因为梅和RMSE都有相同的误差“阶”,他们可以互相比较。</p><p id="28e2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与MAE和MSE一样，较低的MSAE →较低的误差。</p><p id="0e13" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">那么，这在实践中是怎样的呢？</strong></p><p id="24ba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我这里有两个例子。</p><p id="64c0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一个非常简单，我已经创建了一条线<strong class="ki iu"> y_hat = 2x +5 </strong>，还有一条带有噪声，所以<strong class="ki iu"> y = 2x + 5 + e. </strong></p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/9fc97c4fb72e5d0b7d51125ee941fcd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nsWHP4SSUqptFoxvBWRJ2w.png"/></div></div></figure><p id="d16b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，我们可以看到平均寿命和RMSE彼此非常接近，都表明该模型具有相当低的误差(记住，平均寿命或RMSE越低，误差越小！).</p><p id="879a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是你可能会问，梅和RMSE有什么不同？MAE为什么更低？</p><p id="f5f7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个是有答案的。</p><p id="a8f9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们看梅和RMSE的方程时，我们注意到RMSE有一个平方项…因此:大的误差将被平方，因此将增加RMSE的值。因此，我们可以得出结论，RMSE更善于捕捉数据中的大误差，而MAE只是给出平均误差。<strong class="ki iu">由于RMSE在取平均值之前也对平方和进行求和，因此它必然会高于平均误差。</strong></p><p id="c543" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要在示例中看到这一点，请考虑以下情况:</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/830e6678dbe32f90ca71ee1b503aec73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i5N5vy1DQFZJnjWOz_zp-g.png"/></div></div></figure><p id="b230" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">橙色线代表我之前描述的等式<strong class="ki iu">y _ hat = 2x+5</strong>……然而‘y’现在的形式是:</p><p id="219f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> y = y + sin(x)*exp(x/20) + e </strong></p><p id="6010" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<strong class="ki iu"> exp() </strong>表示指数函数(因此我们看到点的偏差增加。</p><p id="3613" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如您所见，RMSE几乎是MAE值的两倍，因为它捕捉到了误差的“大”值(尤其是从<strong class="ki iu"> x = 80 </strong>开始的误差)。</p><p id="d06c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">所以你可能会想:总是使用RMSE不是更好吗？</strong></p><p id="8189" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">号码</p><p id="bd4f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MAE确实有一些优势。</p><p id="5684" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们可能希望将小错误视为大错误。例如，假设您正在拟合除了一个大的异常数据点之外，一般没有大误差的数据。<strong class="ki iu">如果你选择基于最小RMSE的线性回归模型，你的模型可能会过拟合，因为你会<em class="my">尝试</em>捕捉异常。</strong></p><p id="955c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，假设您的数据通常是一致的，几乎没有明显的大误差，选择MAE最低的回归模型可能更合适。</p><p id="62b7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除此之外，比较不同样本大小的模型的RMSE变得有点问题和不一致。</p><p id="7abe" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">MAE、MSE和RMSE总结:</strong></p><blockquote class="nb nc nd"><p id="a208" class="kg kh my ki b kj kk kl km kn ko kp kq ne ks kt ku nf kw kx ky ng la lb lc ld im bi translated">MAE是拟合的平均误差；MSE是误差平方的平均值；RMSE是均方差的平方根，用于比较。RMSE惩罚重大失误。</p></blockquote><p id="8611" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">梅/ RMSE的优点:</strong></p><ol class=""><li id="b036" class="nh ni it ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">两者都捕捉到了模型中的“错误”</li><li id="0d69" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">MAE是“真正的”平均值，因为它是平均误差的度量；RMSE稍微有点微妙，因为它被误差大小等因素扭曲了</li></ol><p id="d214" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">美/ RMSE的缺点:</strong></p><ol class=""><li id="851d" class="nh ni it ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">MAE不会拾取非常大的错误；RMSE会拾取较大的误差，因此对可能不想捕捉的异常值很敏感</li><li id="f02f" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated">两个<em class="my">都倾向于</em>随着模型复杂度的增加而增加(即容易过度拟合)，类似于R随着复杂度的增加而增加</li></ol><p id="2c34" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，也有这些修正的变体，例如MSEc，其中c代表修正的。该等式的不同之处仅在于，平均值不再是<strong class="ki iu"> 1/ <em class="my"> n </em> </strong>，而是<strong class="ki iu">1/(<em class="my">n</em>+<em class="my">k</em>+1)，</strong>其中<strong class="ki iu"> <em class="my"> k </em> </strong>是预测数(不包括截距)。这类似于调整后的R，因为它惩罚了模型的复杂程度。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h2 id="b112" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated"><strong class="ak">赤池的信息准则(AIC) </strong></h2><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/af0efb7fa37e23acfea5ee45472a683b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*PECsDuyw78_c1MxVtl8yGA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">k =预测值的数量(包括系数！)，L =最大对数似然</p></figure><p id="5a64" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">AIC有点难以解释:它是对数据符合模型的程度和模型的复杂程度的一种度量。因此，在某种程度上，它是R和调整后的R的混合。它所做的是<strong class="ki iu">因其复杂性而惩罚</strong>一个模型，但<strong class="ki iu">因其符合数据而奖励</strong>。</p><p id="856c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个值几乎总是负的。</p><p id="2298" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从本质上讲，<strong class="ki iu">降低</strong>AIC(即更负)，而<strong class="ki iu">更好</strong>模型如何<strong class="ki iu">拟合</strong>数据，以及它如何<strong class="ki iu">避免</strong> overfitting⁴(记住，复杂性→过度拟合，所以如果AIC惩罚复杂性，那么它惩罚过度拟合)。</p><p id="78cf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看一个例子。</p><p id="1353" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回想一下我们用于调整R的例子，我们有一个非常复杂的模型来模拟带噪声的线性线。</p><p id="c83c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我重新运行了这个模型，这次还添加了一个AIC分数:让我们看看结果。</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi od"><img src="../Images/942e5ab3706ff6aeeb3c240a95c5730a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wJ176-nKADw_cOVTY7Ru5g.png"/></div></div></figure><p id="f37c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以在这里看到很多东西，这也是很好的复习。</p><p id="8248" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">左图的R比右图的高，但是我们<strong class="ki iu">知道</strong>最右边的是正确的。对于更复杂的模型，这是R变大的一个征兆。</p><p id="710e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，我们调整后的R表明简单模型更好(请记住，由于随机性，情况并不总是如此，但我们仍然可以通过测量调整后的R和R之间的差异来了解模型有多好→更简单的模型损失更低)</p><p id="cfa6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也有AIC来帮助我们:AIC越消极，就越适合，越不会过度适合。因此，仅从AIC参数，我们可以得出结论，越简单的模型越好(也就是说，记得总是勾画你的情节，并试图推理它们，不要只相信数字！).</p><p id="706a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看模型对测试数据的表现:</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oe"><img src="../Images/8df9f78ed556ae6e54f1ebaef8d041d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NaeABF6V1X9vK1iiX9eLMA.png"/></div></div></figure><p id="cabc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如预测的那样，更复杂模型的R更高。这里我们还注意到，调整后的R也更高。我们也有精彩的AIC，这再次表明，越简单的模式越好。</p><p id="2579" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> AIC总结:</strong></p><blockquote class="nb nc nd"><p id="ecc0" class="kg kh my ki b kj kk kl km kn ko kp kq ne ks kt ku nf kw kx ky ng la lb lc ld im bi translated">AIC越低，模型在拟合度和避免过度拟合方面就越好。</p></blockquote><p id="6092" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">优点:</strong></p><ol class=""><li id="4bc5" class="nh ni it ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">AIC是模型质量的一个很好的指标，因为它既解释了拟合，也解释了模型过拟合的程度</li></ol><p id="195f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">缺点:</strong></p><ol class=""><li id="c9b4" class="nh ni it ki b kj kk kn ko kr nj kv nk kz nl ld nm nn no np bi translated">从数学上讲，AIC只对无限数据集有效。在计算上，误差可以通过具有非常大的样本大小来抵消。对于较小的样品，必须添加校正系数。</li></ol></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h2 id="4a2e" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated"><strong class="ak">结论:</strong></h2><p id="2020" class="pw-post-body-paragraph kg kh it ki b kj of kl km kn og kp kq kr oh kt ku kv oi kx ky kz oj lb lc ld im bi translated">我希望您已经了解了不同的参数、它们的使用案例以及它们是如何具有欺骗性的。</p><p id="e179" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我想以一个真实的例子来结束这篇文章。</p><p id="07f8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于这个项目，我试图预测桥梁单位长度(Y)的维护成本，作为桥龄(X1)和长度(X2)的函数。</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ok"><img src="../Images/8b41386b40b4839086faf6a92592b3ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_H-Pjz7xeeTm7DzuiVaCCQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">显示桥梁单位长度的维护成本与长度的图表</p></figure><p id="2215" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我想出了许多不同的模型，其中一些非常复杂。</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ol"><img src="../Images/62f09dbcab42a403a93096f46857b95b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dqrr5vGoZk6qJJAvqBx_fQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><strong class="bd om">注:</strong>部分数学表达式有误。X1代表年龄，X2代表长度</p></figure><p id="ed98" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如您所看到的，这里涉及到许多不同的东西，但我们看到大多数模型都有非常相似的指标。这就是将不同的指标结合起来使用的时候了，这就是为什么了解所有指标或者尽可能多的指标是好的。</p><p id="b797" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，人们认为最差的模型是“二次”型，因为它具有最高的AIC <strong class="ki iu">和最低的R调整值</strong>。</p><p id="a2d4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最佳模型被认为是“线性”模型，因为它具有最高的AIC和相当低的R调整值(实际上，它与R调整值最高的“poly31”模型的误差在1%以内)。</p><h2 id="bd60" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated"><strong class="ak">读者注意:</strong></h2><p id="1bc3" class="pw-post-body-paragraph kg kh it ki b kj of kl km kn og kp kq kr oh kt ku kv oi kx ky kz oj lb lc ld im bi translated">我希望您喜欢阅读本文，并且对所描述的指标有更好的理解。由于这是我的第一篇文章，如果你能给我反馈，我将不胜感激:什么是好的？什么不好？少了什么？我能有什么不同的解释？</p><p id="d3c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">非常感谢，我希望你继续你的学习之旅:)</p><h2 id="0986" class="ll lm it bd ln lo lp dn lq lr ls dp lt kr lu lv lw kv lx ly lz kz ma mb mc md bi translated"><strong class="ak">来源:</strong></h2><ol class=""><li id="8d05" class="nh ni it ki b kj of kn og kr on kv oo kz op ld nm nn no np bi translated"><a class="ae kf" href="https://www.investopedia.com/terms/r/r-squared.asp#:~:text=R-squared%20(R2),variables%20in%20a%20regression%20model." rel="noopener ugc nofollow" target="_blank">https://www . investopedia . com/terms/R/R-squared . ASP #:~:text = R-squared % 20(R2)，变量%20in%20a%20regression%20model。</a></li><li id="e238" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated"><a class="ae kf" href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/#:~:text=Overfitting%20refers%20to%20a%20model%20that%20models%20the%20training%20data%20too%20well.&amp;text=This%20means%20that%20the%20noise,the%20models%20ability%20to%20generalize." rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/over fitting-and-under fitting-with-machine-learning-algorithms/#:~:text = over fitting % 20 refers % 20 to % 20a % 20 model % 20 that % 20 models % 20 training % 20 data % 20 too % 20 well。&amp;text =这% 20意味着% 20那% 20噪音% 20型号% 20能力% 20到% 20通用化。</a></li><li id="ba5c" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated"><a class="ae kf" href="https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d" rel="noopener">https://medium . com/human-in-a-machine-world/Mae-and-RMSE-metric-is-better-e 60 AC 3 bde 13d</a></li><li id="a1f9" class="nh ni it ki b kj nq kn nr kr ns kv nt kz nu ld nm nn no np bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/the-akaike-information-criterion-c20c8fd832f2">https://towards data science . com/the-a kaike-information-criterion-c 20 c8 FD 832 f 2</a></li></ol><p id="11d5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="my">除非另有说明，所有图片均由作者提供。</em></p></div></div>    
</body>
</html>