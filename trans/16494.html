<html>
<head>
<title>Machine Learning Pipelines With Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scikit-Learn的机器学习管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-pipelines-with-scikit-learn-d43c32a6aa52?source=collection_archive---------3-----------------------#2020-11-14">https://towardsdatascience.com/machine-learning-pipelines-with-scikit-learn-d43c32a6aa52?source=collection_archive---------3-----------------------#2020-11-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9def" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">构建机器学习管道的分步教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6ddd88be049ed4cd90910b8f3476bb26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OegG1bf_3BsjtmWINRNSUg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@quinten149?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">昆腾·德格拉夫</a>在<a class="ae ky" href="https://unsplash.com/s/photos/pipeline?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h2 id="a8e1" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">概观</h2><p id="bc7c" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">这篇文章将作为一步一步的指南来建立流水线，简化机器学习的工作流程。我将在本教程中使用臭名昭著的泰坦尼克号数据集。数据集是从<a class="ae ky" href="https://www.kaggle.com/c/titanic/data" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu"> Kaggle </strong> </a>获得的。目标是预测一个给定的人是否幸存。我将实现各种分类算法，以及网格搜索和交叉验证。该数据集包含每位乘客的记录，由10个变量组成(<em class="mo">见下面的数据字典</em>)。出于本教程的目的，我将只使用<code class="fe mp mq mr ms b">train</code>数据集，它将被分成训练集、验证集和测试集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/d0f844c7c1cf8e3204d80e1faec38273.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*86suKCX7I7v0SJNxUJmYlg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><h2 id="66f6" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">为什么是管道？</h2><p id="1938" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">机器学习工作流由数据准备的许多步骤组成(例如，处理缺失值、缩放/编码、特征提取)。当第一次学习这个工作流程时，我们一次执行一个步骤的数据准备。这可能会变得很耗时，因为我们需要对训练和测试数据都执行准备步骤。管道允许我们通过编译准备步骤来简化这个过程，同时减轻模型调整和监控的任务。Scikit-Learn的Pipeline类提供了一种结构，用于应用一系列数据转换，然后是一个估计器(Mayo，2017)。有关更详细的概述，请查看<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu">文档</strong> </a>。实现管道有很多好处:</p><ul class=""><li id="7201" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">便利性和封装性:</strong>我们只对数据调用一次<code class="fe mp mq mr ms b">fit</code>和<code class="fe mp mq mr ms b">predict</code>，以适应整个估计器序列。</li><li id="91c8" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated"><strong class="lx iu">联合参数选择:</strong>我们可以对管道中所有估计器的参数进行网格搜索。</li><li id="0848" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated"><strong class="lx iu">交叉验证:</strong>管道有助于避免数据在交叉验证过程中从测试数据泄露到训练好的模型中。这是通过确保使用相同的样本来训练变压器和预测器来实现的。</li></ul><p id="a514" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">是时候看看管道的运行了！下面，我将安装并导入必要的库。然后继续加载数据集并处理缺失值。一旦数据准备好了，我将为不同的数据类型创建转换器，并创建一个列转换器来封装预处理步骤。最后，我将编写一个函数来训练一个具有交叉验证的模型，以及一个类似的函数，包括网格搜索交叉验证。</p><ul class=""><li id="f942" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">安装Scikit-Learn </strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="bff5" class="kz la it ms b gy nr ns l nt nu">!pip install -U scikit-learn</span></pre><ul class=""><li id="3dcd" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">导入必要的库</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="3c06" class="kz la it ms b gy nr ns l nt nu"><strong class="ms iu"><em class="mo"># Standard Imports</em><br/></strong>import pandas as pd<br/>import seaborn as sns<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pickle<br/><br/><strong class="ms iu"><em class="mo"># Transformers</em><br/>from sklearn.preprocessing</strong> import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler<br/><br/><strong class="ms iu"><em class="mo"># Modeling Evaluation</em><br/>from sklearn.model_selection</strong> import train_test_split, cross_val_score, KFold, GridSearchCV<br/><strong class="ms iu">from sklearn.metrics</strong> import accuracy_score, precision_score, recall_score,f1_score, confusion_matrix, classification_report<br/><strong class="ms iu">from IPython.display</strong> import display, Markdown<strong class="ms iu"><br/></strong><br/><strong class="ms iu"><em class="mo"># Pipelines</em></strong><br/><strong class="ms iu">from sklearn.pipeline</strong> import Pipeline, FeatureUnion<br/><strong class="ms iu">from sklearn.base</strong> import BaseEstimator, TransformerMixin<br/><strong class="ms iu">from sklearn.compose</strong> import ColumnTransformer<strong class="ms iu"><br/></strong><br/><strong class="ms iu"><em class="mo"># Machine Learning</em></strong><br/><strong class="ms iu">from sklearn.tree</strong> import DecisionTreeClassifier<br/><strong class="ms iu">from sklearn.ensemble</strong> import RandomForestClassifier<br/><strong class="ms iu">from</strong> <strong class="ms iu">sklearn.model_selection</strong> <strong class="ms iu">import</strong> KFold<br/><strong class="ms iu">from</strong> <strong class="ms iu">sklearn.neighbors</strong> <strong class="ms iu">import</strong> KNeighborsClassifier</span></pre><ul class=""><li id="4008" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">加载数据并查看前5行</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="2690" class="kz la it ms b gy nr ns l nt nu"><strong class="ms iu">df = </strong>pd.read_csv("titanic.csv")<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/1e7fa6704b71f41cba71d64c094932f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EnrhHdhRdxlTbgXNcH8KRQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><ul class=""><li id="9b76" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">检查缺失值</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="8763" class="kz la it ms b gy nr ns l nt nu">df.isna().sum()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/24bf9fd5a9e8adc65a654e629b36deb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*Y91BnY8i195g8HcfuVliQQ.png"/></div></figure><p id="ebc5" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">在<code class="fe mp mq mr ms b">Age</code>列中有891个缺失值中的177个。出于本管道教程的目的，我将继续用平均年龄填充缺失的<code class="fe mp mq mr ms b">Age</code>值。在<code class="fe mp mq mr ms b">Cabin</code>列中有891个缺失值中的687个。我正在删除这个特性，因为大约77%的值丢失了。<code class="fe mp mq mr ms b">Embarked</code>特性只缺少2个值，所以我们可以用最常见的值来填充它们。<code class="fe mp mq mr ms b">Name</code>和<code class="fe mp mq mr ms b">Ticket</code>功能对每个乘客都有独特的价值，预测分类不需要这些功能，因此也将被删除。</p><ul class=""><li id="f500" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">下降特性</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="bed9" class="kz la it ms b gy nr ns l nt nu">df.drop(["Name", "Ticket", "Cabin"], axis=1, inplace=True)</span></pre><ul class=""><li id="4fd9" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">填充na值为</strong> <code class="fe mp mq mr ms b"><strong class="lx iu">Embarked</strong></code> <strong class="lx iu">特征中出现频率最高的值，</strong> <code class="fe mp mq mr ms b"><strong class="lx iu">S</strong></code> <strong class="lx iu">。</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="f784" class="kz la it ms b gy nr ns l nt nu"><strong class="ms iu">df.Embarked =</strong> df.Embarked.fillna(value='S')</span></pre><p id="9f6c" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">既然我们已经处理了数据集中的缺失值，我们可以继续定义连续变量和分类变量。</p><ul class=""><li id="5260" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">为数据帧中的列定义变量，以执行训练测试分割。</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="dc49" class="kz la it ms b gy nr ns l nt nu"><strong class="ms iu">columns =</strong> ['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked']</span><span id="87c8" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">numerical_columns =</strong> ['Age', 'Fare']</span><span id="676f" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">categorical_columns =</strong> ["Pclass", "Sex",<br/>                       "SibSp", "Parch", "Embarked"]</span></pre><p id="0f0c" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">接下来，我将创建两个函数。第一个函数<code class="fe mp mq mr ms b">cross_validate</code>将接受一个分类器和cv(交叉验证器),将训练数据分成训练集和测试集，使分类器适合训练，并对其进行预测。然后，该函数将对保留验证集进行预测，并返回来自训练集和测试集的分数。</p><p id="f55e" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">管道允许我们在一个步骤中执行预处理(例如标准化、编码、模型拟合)。一个管道可以接受任意数量的预处理步骤，每个步骤都有<code class="fe mp mq mr ms b">.fit()</code>和<code class="fe mp mq mr ms b">.transform()</code>方法。下面，我正在创建两个变压器，一个标准的定标器和一个热编码器。两个不同的转换器将用于不同的数据类型。</p><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="0964" class="kz la it ms b gy nr ns l nt nu"><strong class="ms iu">#Creating </strong><strong class="ms iu">ss</strong><strong class="ms iu"> transformer to scale the continuous numerical data with </strong><strong class="ms iu">StandardScaler()</strong></span><span id="15a6" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">ss =</strong> Pipeline(steps=[('ss', StandardScaler())])</span><span id="657f" class="kz la it ms b gy nx ns l nt nu">--------------------------------------------------------------------</span><span id="757e" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">#Creating ohe transformer to encode the categorical data with </strong><strong class="ms iu">OneHotEncoder()</strong></span><span id="41aa" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">ohe =</strong> Pipeline(steps=[('ohe', OneHotEncoder(drop='first'))])</span><span id="b63b" class="kz la it ms b gy nx ns l nt nu">--------------------------------------------------------------------</span><span id="efc3" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">#Creating preprocess column transformer to combine the ss and ohe pipelines</strong></span><span id="497f" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">preprocess =</strong> ColumnTransformer(<br/>                    transformers=[<br/>                        ('cont', ss, numerical),<br/>                        ('cat', ohe, categorical)<br/>                    ])</span></pre><ul class=""><li id="c3ab" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">创建评估函数以绘制混淆矩阵并返回准确度、精确度、召回率和f1分数</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="a88d" class="kz la it ms b gy nr ns l nt nu">def evaluation(y, y_hat, title = 'Confusion Matrix'):<br/>    cm = confusion_matrix(y, y_hat)<br/>    precision = precision_score(y, y_hat)<br/>    recall = recall_score(y, y_hat)<br/>    accuracy = accuracy_score(y,y_hat)<br/>    f1 = f1_score(y,y_hat)<br/>    print('Recall: ', recall)<br/>    print('Accuracy: ', accuracy)<br/>    print('Precision: ', precision)<br/>    print('F1: ', f1)<br/>    sns.heatmap(cm,  cmap= 'PuBu', annot=True, fmt='g', annot_kws=    {'size':20})<br/>    plt.xlabel('predicted', fontsize=18)<br/>    plt.ylabel('actual', fontsize=18)<br/>    plt.title(title, fontsize=18)<br/>    <br/>    plt.show();</span></pre><ul class=""><li id="394f" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">对数据执行train _ test _ split</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="69f3" class="kz la it ms b gy nr ns l nt nu"><strong class="ms iu">X =</strong> df.drop(['Survived'], axis=1)<br/><strong class="ms iu">y =</strong> df.Survived<br/><strong class="ms iu">y =</strong> LabelEncoder().fit_transform(y)<br/><strong class="ms iu">X_train, X_test, y_train, y_test =</strong> train_test_split(X, y, random_state=42)</span></pre><h2 id="e777" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">创建<code class="fe mp mq mr ms b">cross_validate</code>功能</h2><ul class=""><li id="ddf2" class="mu mv it lx b ly lz mb mc li ny lm nz lq oa mn nb nc nd ne bi translated">定义带有预处理和分类器管道的完整管道</li><li id="f6d5" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated">遍历交叉验证器中的每个折叠(默认为5)</li><li id="9d3f" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated">将分类器安装在训练装置上，<code class="fe mp mq mr ms b">train_ind</code>(防止测试装置的数据泄漏)</li><li id="dc2a" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated">根据训练集进行预测</li><li id="4bdb" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated">对验证集进行预测</li><li id="5b03" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated">打印一份评估报告，其中包含混淆矩阵以及训练集和验证集的平均准确度分数</li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="c536" class="kz la it ms b gy nr ns l nt nu">def cross_validate(classifier, cv):<br/>    pipeline = Pipeline(steps=[<br/>        ('preprocess', preprocess),<br/>        ('classifier', classifier)<br/>    ])<br/>    train_acc = []<br/>    test_acc = []<br/>    for train_ind, val_ind in cv.split(X_train, y_train):<br/>        X_t, y_t = X_train.iloc[train_ind], y_train[train_ind]<br/>        pipeline.fit(X_t, y_t)<br/>        y_hat_t = pipeline.predict(X_t)</span><span id="4cad" class="kz la it ms b gy nx ns l nt nu">        train_acc.append(accuracy_score(y_t, y_hat_t))</span><span id="3ec1" class="kz la it ms b gy nx ns l nt nu">        X_val, y_val = X_train.iloc[val_ind], y_train[val_ind]<br/>        y_hat_val = pipeline.predict(X_val)</span><span id="fcd1" class="kz la it ms b gy nx ns l nt nu">        test_acc.append(accuracy_score(y_val, y_hat_val))<br/>    print(evaluation(y_val, y_hat_val))<br/>    print('Training Accuracy: {}'.format(np.mean(train_acc)))<br/>    print('\n')<br/>    print('Validation Accuracy: {}'.format(np.mean(test_acc)))<br/>    print('\n')</span></pre><p id="ced9" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">在函数中，我使用交叉验证器来分割训练数据，以便得到一个支持测试集(X_test，y_test)。现在我们可以通过输入想要的分类器和交叉验证器来使用上面的函数。</p><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="a5b3" class="kz la it ms b gy nr ns l nt nu">cross_validate(DecisionTreeClassifier(), KFold())</span></pre><p id="aaca" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/659be9d820ff200b9bae70fe47661584.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*DMjCtTqel3E7bJZXQuk6Dw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><ul class=""><li id="42f1" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">用K最近邻分类器</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="8f09" class="kz la it ms b gy nr ns l nt nu">cross_validate(KNeighborsClassifier(), KFold())</span></pre><p id="e2aa" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/ff9bc45f23aec16b8d464dc399564e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*IRZSLrvVKu_xYsrXRZe5Cw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="fa6d" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">网格搜索</h2><p id="0dec" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">假设我们想在管道中找到模型的最佳参数，我们可以创建一个网格搜索管道。要复习网格搜索，请查看<a class="ae ky" href="https://scikit-learn.org/stable/modules/grid_search.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu"> <em class="mo">文档</em> </strong> </a>。我们可以创建一个类似上面的函数来进行交叉验证，但是要稍微修改一下来执行网格搜索。该函数将接收所需的分类器、参数网格和交叉验证器。然后，将通过网格搜索完成与<code class="fe mp mq mr ms b">cross_validate</code>功能相同的过程。</p><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="1bc6" class="kz la it ms b gy nr ns l nt nu">def grid_search(classifier, param_grid, cv):<br/>    search = GridSearchCV(Pipeline(steps=[<br/>        ('preprocess', preprocess),<br/>        ('classifier', classifier)<br/>    ]), param_grid, cv=cv)<br/>    train_acc = []<br/>    test_acc = []<br/>    for train_ind, val_ind in cv.split(X_train, y_train):<br/>        X_t, y_t = X_train.iloc[train_ind], y_train[train_ind]<br/>        search.fit(X_t, y_t)<br/>        y_hat_t = search.predict(X_t)</span><span id="e6bc" class="kz la it ms b gy nx ns l nt nu">        train_acc.append(accuracy_score(y_t, y_hat_t))</span><span id="4f4b" class="kz la it ms b gy nx ns l nt nu">        X_val, y_val = X_train.iloc[val_ind], y_train[val_ind]<br/>        y_hat_val = search.predict(X_val)</span><span id="d494" class="kz la it ms b gy nx ns l nt nu">        test_acc.append(accuracy_score(y_val, y_hat_val))<br/>    print(evaluation(y_val, y_hat_val))<br/>    print('Training Accuracy: {}'.format(np.mean(train_acc)))<br/>    print('\n')<br/>    print('Validation Accuracy: {}'.format(np.mean(test_acc)))<br/>    print('\n')<br/>    print('Grid Search Best Params:')<br/>    print('\n')<br/>    print(search.best_params_)</span></pre><ul class=""><li id="781b" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu"> GridSearchCV与随机森林</strong></li></ul><p id="1fc5" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">为管道中的模型创建参数网格时，需要将模型名称附加到每个参数上。在下面的代码块中，我添加了<code class="fe mp mq mr ms b">'classifier__'</code>来匹配管道中模型的名称(在管道中命名为模型‘classifier’)。</p><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="4792" class="kz la it ms b gy nr ns l nt nu"><strong class="ms iu">#Creating parameter grid for Random Forest<br/></strong>rand_forest_parms = {'classifier__n_estimators': [100, 300, 500],<br/>                     'classifier__max_depth':[6, 25, 50, 70],<br/>                     'classifier__min_samples_split': [2, 5, 10],<br/>                     'classifier__min_samples_leaf': [1, 2, 10]}</span><span id="4f49" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">#Calling the grid_search function using the parameters above<br/></strong>grid_search(RandomForestClassifier(), rand_forest_parms)</span></pre><p id="ea87" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/4dfaca511833879346c02dc81379a558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*FclFZCWShQHzZH92uh6hlQ.png"/></div></figure><p id="89e6" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">在模型训练期间，重要的是执行特征选择，以确保模型具有最强的预测能力，并确保我们的模型不会太复杂。我们可以使用<code class="fe mp mq mr ms b">eli5</code>库来检查管道中分类器的特征重要性。为此，我们需要创建一个包含数字特征列和编码列的列表。然后，用网格搜索管道的<code class="fe mp mq mr ms b">best_estimator_</code>和它的<code class="fe mp mq mr ms b">named_steps</code>调用<code class="fe mp mq mr ms b">eli5.explain_weights_df</code>。当然，我们可以将它添加到我们的网格搜索函数中，通过修改该函数来接受一个将打印出这些特性的布尔值，从而返回前十个特性的重要性。</p><h2 id="befb" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">具有特征重要性的网格搜索功能</h2><ul class=""><li id="c951" class="mu mv it lx b ly lz mb mc li ny lm nz lq oa mn nb nc nd ne bi translated"><strong class="lx iu">在下面的函数中包含特性重要性的修改以粗体显示。</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="39dd" class="kz la it ms b gy nr ns l nt nu">def grid_search(classifier, param_grid, cv, <strong class="ms iu"><em class="mo">print_feat=False</em></strong>):<br/>    cv = cv<br/>    search = GridSearchCV(Pipeline(steps=[<br/>        ('preprocess', preprocess),<br/>        ('classifier', classifier)<br/>    ]), param_grid, cv=cv)<br/>    train_acc = []<br/>    test_acc = []<br/>    for train_ind, val_ind in cv.split(X_train, y_train):<br/>        X_t, y_t = X_train.iloc[train_ind], y_train[train_ind]<br/>        search.fit(X_t, y_t)<br/>        y_hat_t = search.predict(X_t)</span><span id="fc4b" class="kz la it ms b gy nx ns l nt nu">        train_acc.append(accuracy_score(y_t, y_hat_t))</span><span id="28df" class="kz la it ms b gy nx ns l nt nu">        X_val, y_val = X_train.iloc[val_ind], y_train[val_ind]<br/>        y_hat_val = search.predict(X_val)</span><span id="46f5" class="kz la it ms b gy nx ns l nt nu">        test_acc.append(accuracy_score(y_val, y_hat_val))<br/>    <strong class="ms iu"><em class="mo">if print_feat:<br/>        ohe_cols = list(search.best_estimator_.named_steps['preprocess'].named_transformers_['cat'].named_steps['ohe'].get_feature_names(<br/>        input_features=categorical))<br/>        num_feats = list(numerical)<br/>        num_feats.extend(ohe_cols)<br/>        feat_imp = eli5.explain_weights_df(search.best_estimator_.named_steps['classifier'], top=10, feature_names=num_feats)<br/>        print(feat_imp)</em></strong><br/>    print('\n')<br/>    print(evaluation(y_val, y_hat_val))<br/>    print('Training Accuracy: {}'.format(np.mean(train_acc)))<br/>    print('\n')<br/>    print('Validation Accuracy: {}'.format(np.mean(test_acc)))<br/>    print('\n')<br/>    print('Grid Search Best Params:')<br/>    print('\n')<br/>    print(search.best_params_)</span></pre><ul class=""><li id="7e8a" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">执行网格搜索并返回前十个重要特征及其权重</strong></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="a0d6" class="kz la it ms b gy nr ns l nt nu">grid_search(RandomForestClassifier(), rand_forest_parms, KFold(), print_feat=True)</span></pre><p id="7b7f" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/dc6420040f52d9ffd626b07340556c3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PQb5V2oU1sjExPqJGh-14Q.png"/></div></div></figure><p id="7210" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">假设网格搜索管道中的随机森林分类器表现最好。下一步将是观察经过训练的模型在坚持测试数据上的表现。我们需要做的就是用GridSearchCV创建一个最终的管道，并使其适合整个X_train和y_train。然后，在X_test上预测。</p><ul class=""><li id="f268" class="mu mv it lx b ly mw mb mx li my lm mz lq na mn nb nc nd ne bi translated"><strong class="lx iu">将最终管线拟合到</strong> <code class="fe mp mq mr ms b"><strong class="lx iu">X_train</strong></code> <strong class="lx iu">和</strong> <code class="fe mp mq mr ms b"><strong class="lx iu">y_train</strong></code> <strong class="lx iu">，并预测到</strong> <code class="fe mp mq mr ms b"><strong class="lx iu">X_test</strong></code></li></ul><pre class="kj kk kl km gt nn ms no np aw nq bi"><span id="5a7a" class="kz la it ms b gy nr ns l nt nu">final_pipeline = GridSearchCV(Pipeline(steps=[<br/>        ('preprocess', preprocess),<br/>        ('classifier', RandomForestClassifier())<br/>    ]), rand_forest_parms, cv=KFold())</span><span id="e00d" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">#Fit and predict on train data</strong></span><span id="5877" class="kz la it ms b gy nx ns l nt nu">final_pipeline.fit(X_train, y_train)<br/>train_pred = final_pipeline.best_estimator_.predict(X_train)<br/>print('Evaluation on training data \n')<br/>print(evaluation(y_train, train_pred))<br/>print('\n')</span><span id="70f9" class="kz la it ms b gy nx ns l nt nu"><strong class="ms iu">#Predict on test data</strong></span><span id="1457" class="kz la it ms b gy nx ns l nt nu">test_pred = final_pipeline.best_estimator_.predict(X_test)<br/>print('Evaluation on testing data \n')<br/>print(evaluation(y_test, test_pred))</span></pre><p id="e151" class="pw-post-body-paragraph lv lw it lx b ly mw ju ma mb mx jx md li nk mf mg lm nl mi mj lq nm ml mm mn im bi translated">输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/03549e930e2f6f2ac2814edf81b0355e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dl9BORBpft0dWCneHOzghw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="0a23" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结论</h2><p id="483a" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">管道封装了我们的预处理步骤和模型，使机器学习工作流程变得更加容易。如果需要，我们可以在管道中拟合模型之前应用多个预处理步骤。对我来说，主要的好处是能够回到一个项目，并遵循我用管道设置的工作流程。在我了解管道之前，这个过程需要几个小时。我希望本教程能够成为学习管道工作流的有用资源。</p><h2 id="2a55" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">资源</h2><ul class=""><li id="d893" class="mu mv it lx b ly lz mb mc li ny lm nz lq oa mn nb nc nd ne bi translated"><em class="mo">使用Scikit-learn管道管理机器学习工作流第1部分:简介。(未注明)。检索自</em><a class="ae ky" href="https://www.kdnuggets.com/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html" rel="noopener ugc nofollow" target="_blank"><em class="mo">https://www . kdnugges . com/2017/12/managing-machine-learning-workflows-sci kit-learn-pipelines-part-1 . html</em></a></li><li id="2467" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated"><em class="mo">柯恩，S. (2019年08月09日)。构建机器学习管道。检索自</em><a class="ae ky" rel="noopener" target="_blank" href="/architecting-a-machine-learning-pipeline-a847f094d1c7"><em class="mo">https://towards data science . com/architecting-a-machine-learning-pipeline-a 847 f 094 D1 c 7</em></a></li><li id="0575" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated"><em class="mo">sk learn . pipeline . pipeline .(n . d .)。检索自</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank"><em class="mo">https://scikit-learn . org/stable/modules/generated/sk learn . pipeline . pipeline . html</em></a></li><li id="8915" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated"><em class="mo"> M，S. (2019年12月13日)。机器学习中的流水线是什么？如何创建一个？检索自</em><a class="ae ky" href="https://medium.com/analytics-vidhya/what-is-a-pipeline-in-machine-learning-how-to-create-one-bda91d0ceaca#:~:text=A" rel="noopener"><em class="mo">https://medium . com/analytics-vid hya/what-A-pipeline-in-machine-learning-how-to-create-one-BDA 91d 0 ce ACA #:~:text = A</em></a><em class="mo">机器学习管道用于帮助机器学习工作流程自动化。&amp;text =机器学习(ML)流水线组成，并实现一个成功的算法。</em></li><li id="1486" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated"><em class="mo">泰坦尼克号:机器从灾难中学习。(未注明)。检索自</em><a class="ae ky" href="https://www.kaggle.com/c/titanic/data" rel="noopener ugc nofollow" target="_blank"><em class="mo">https://www.kaggle.com/c/titanic/data</em></a></li><li id="7c43" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated"><em class="mo"> 3.2。调整估计器的超参数。(未注明)。检索自</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/grid_search.html" rel="noopener ugc nofollow" target="_blank"><em class="mo">https://scikit-learn.org/stable/modules/grid_search.html</em></a></li><li id="a3da" class="mu mv it lx b ly nf mb ng li nh lm ni lq nj mn nb nc nd ne bi translated"><em class="mo">概述。(未注明)。检索自【https://eli5.readthedocs.io/en/latest/overview.html】<a class="ae ky" href="https://eli5.readthedocs.io/en/latest/overview.html" rel="noopener ugc nofollow" target="_blank"><em class="mo"/></a></em></li></ul></div></div>    
</body>
</html>