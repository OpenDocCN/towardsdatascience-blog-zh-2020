<html>
<head>
<title>End to End Adaptation of ResNet in Google Colab — Part 3: Image Pre-Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google Colab中ResNet的端到端适配第3部分:图像预处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/end-to-end-adaptation-of-resnet-in-google-colab-part-3-image-pre-processing-fe30917d9aa2?source=collection_archive---------44-----------------------#2020-10-14">https://towardsdatascience.com/end-to-end-adaptation-of-resnet-in-google-colab-part-3-image-pre-processing-fe30917d9aa2?source=collection_archive---------44-----------------------#2020-10-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="3dff" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">端到端Resnet</h2><div class=""/><div class=""><h2 id="6956" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">为训练准备数据集</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/906af147ece9a90e40c318dfc413586b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4mriRfYOCQhokOEsX0Cc4Q.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Unsplash.com</p></figure><p id="c4f6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">快速回顾一下我们到目前为止所做的工作:</p><p id="8d60" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" rel="noopener" target="_blank" href="/end-to-end-adaptation-of-resnet-in-google-colab-part-1-5e56fce934a6">第一部分</a> —整个项目概述。不需要python，只需要一个Google和Kaggle账户。希望您已经说服自己，您个人能够完整地运行代码，并对其进行测试。</p><p id="4de6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" rel="noopener" target="_blank" href="/end-to-end-adaptation-of-resnet-in-google-colab-part-2-hardware-dataset-setup-f23dd4e0004d">第二部分</a> —库和数据库都是从Kaggle导入的。它被解压缩到一个文件夹中。我们还做了一个简短的概述，介绍了如何确定您正在使用哪种硬件。在处理像我们这样的图像数据库时，GPU信息很重要。</p><p id="b714" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">链接到Colab笔记本:</strong> <a class="ae le" href="https://colab.research.google.com/drive/1W5tU1X3w1uIY-R1HpQredT1vpiLGcDIQ?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">猫&amp;狗— Resnet-18 </strong> </a></p><p id="4b4b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我们能够将图像“加载”到架构中进行训练之前，我们必须首先对它们进行预处理。</p><h1 id="4859" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">创建文件夹结构</h1><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="6957" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">上面的代码创建了以下结构(val和train位于主数据集文件夹下，而dogs和cats文件夹位于它们各自的子文件夹中):</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="28a0" class="na mc iq mw b gy nb nc l nd ne">dataset_dogs_vs_cats<br/>     train<br/>          dogs<br/>          cats<br/>     val<br/>          dogs<br/>          cats</span></pre><p id="f01a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于那些想要命名的人，我们正在这里用标记的数据执行<em class="nf">监督的</em>机器学习。我们给数据“贴标签”的方式是把它放在一个文件夹里。代码将被告知使用包含图像的文件夹的名称作为标签。</p><h1 id="8a42" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">旁白</h1><p id="b31e" class="pw-post-body-paragraph lf lg iq lh b li ng ka lk ll nh kd ln lo ni lq lr ls nj lu lv lw nk ly lz ma ij bi translated">将来我几乎肯定会在这个问题上犯错，但你对神经网络了解得越多，“建模”和“模型”这两个词就开始变得模糊，你总是会说“我们正在用这个特定的模型来建模我们的问题。”</p><p id="928d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当提到模型的技术定义时，我鼓励你使用<strong class="lh ja">架构</strong>这个词。我承认我的代码会有类似‘train _ model’的语句，但在这种情况下，model = architecture，即ResNet-18架构。“我们正在用这种特殊的架构来建模我们的问题”听起来更容易接受。</p><h1 id="e11c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">整理我们的数据</h1><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="226c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一步是将数据分为训练和测试。我们将使用训练数据来训练我们的架构(调整参数)。ResNet-18有1100万个可训练参数。测试集将用于衡量架构的执行情况，以“测试”的形式向其显示新数据。</p><p id="4815" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">“src_directory”包含所有图像。“listdir”获取源目录中所有文件的列表，如果文件以“cat”开头，我们将它放在cats文件夹中，与dog相同。这是在“file.startswith('cat或dog ')”中捕获的。</p><p id="b731" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您可以看到，默认情况下，目的地是“train”文件夹，除非一个随机数(默认为0到1之间)小于0.25，这种情况应该发生在25%左右，在这种情况下，文件会被传送到“val”文件夹。</p><h1 id="3d12" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">图像转换</h1><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="7ed4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里需要解释一下。让我去掉一行——“调整大小”。ResNet架构要求图像为224x224(为什么不在本文讨论范围之内)，因此train和val(验证)图像都必须调整大小。</p><p id="0b07" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们倒着做。行“ToTensor()”设置我们的图像用于计算。它本质上是一个多维数组(高度、宽度、颜色空间)。每个[train，val]的“归一化”功能根据三个RGB通道归一化数据。第一组数字是平均值，第二组是标准差。使用这些特定的归一化值是因为torchvision架构(如ResNet)已经在ImageNet上进行了训练，并基于数百万张图像进行了计算。</p><p id="4e18" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">剩下三种变换—旋转、RandomHorizontalFlip和RandomResizedCrop。与“为什么”相比，这些转换的“是什么”更容易理解。本质上，您希望向您的网络呈现尽可能多的<strong class="lh ja">不同的</strong>训练图像。增加这些图片种类的一种方法是使用庞大的数据集——在这种情况下，有近19，000张训练图像。</p><p id="2d5a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们能够通过对图像进行小的修改来人为地增加图像的多样性。</p><p id="987b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">旋转和RandomHorizontalFlip是不言自明的。</p><p id="d56b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">RandomResizedCrop从图像(本例中为224x224)中选取一小块，随机选取的范围在0.96到1.0之间，随机选取的纵横比在0.95到1.05之间。</p><h1 id="19c7" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">数据加载器</h1><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="f8ec" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">数据加载器允许将数据集批量交付到用于培训的架构中。它们对于确保简化的数据流至关重要。相应地，您看到设置的第一个变量是batch_size = 16。如果您在训练时遇到困难(尤其是GPU内存问题)，请以2的倍数减少批量。</p><p id="8bfb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Data_dir设置训练和验证图像的主目录。数据集。“ImageFolder”允许像我们之前所做的那样设置标签——文件夹的名称是标签本身(而不是嵌入在文件名中或存储在其他地方的标签)。您可以看到，我们在上面定义的“数据转换”应用于“图像数据集”变量中。</p><p id="e153" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">“torch.utils.data.DataLoader”允许将“image_datasets”合并到“dataloaders”变量中。</p><p id="b403" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们后来在最后两行中将“dataloaders”变量拆分为“train_dataloader”和“val_dataloader”。</p><p id="2501" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，确保使用GPU:device = torch . device(" cuda:0 ")。在接下来的步骤中，我们将确保架构加载到GPU上。</p><p id="5f09" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">请在下面留下任何问题，我会尽力回答。</p><h1 id="f176" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">参考</h1><p id="4edd" class="pw-post-body-paragraph lf lg iq lh b li ng ka lk ll nh kd ln lo ni lq lr ls nj lu lv lw nk ly lz ma ij bi translated">[1] <a class="ae le" href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" rel="noopener ugc nofollow" target="_blank">深度学习与Pytorch </a>，2020年10月访问</p><p id="f3be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html" rel="noopener ugc nofollow" target="_blank">【2】神经网络与Pytorch。【2020年10月接入</a></p><p id="46fd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[3] <a class="ae le" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="noopener ugc nofollow" target="_blank">为计算机视觉转移学习。【2020年10月接入</a></p><p id="9c98" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[4] <a class="ae le" href="https://github.com/Kaggle/kaggle-api" rel="noopener ugc nofollow" target="_blank"> Kaggle API。【2020年10月访问</a></p></div></div>    
</body>
</html>