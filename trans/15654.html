<html>
<head>
<title>Isolation Forest: A Tree-based Algorithm for Anomaly Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">隔离森林:一种基于树的异常检测算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/isolation-forest-a-tree-based-algorithm-for-anomaly-detection-4a1669f9b782?source=collection_archive---------11-----------------------#2020-10-28">https://towardsdatascience.com/isolation-forest-a-tree-based-algorithm-for-anomaly-detection-4a1669f9b782?source=collection_archive---------11-----------------------#2020-10-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="45ed" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于异常检测算法的小数据科学</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2b0ea95172978f1645e0b53122aa0d40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qJD51dmcl_uQZche"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">托德·夸肯布什在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="4089" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我写的关于异常检测中常用的算法的一系列小文章中的第10篇(我会在最后放上所有其他文章的链接)。在今天的文章中，我将重点介绍一种基于树的机器学习算法——隔离森林——它可以有效地从多维数据集中隔离出离群值。</p><p id="80c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在这里的目的是给出算法如何工作的直觉，以及如何用几行代码实现它作为演示。所以我不会深入理论，但足以帮助读者理解基础知识。如果您对算法的某个特定部分感兴趣，您可以随时搜索和查找细节。所以让我们开始吧！</p><h2 id="d6c3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">什么是隔离林？</h2><p id="e6bc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">隔离森林或iForest是较新的算法之一，于2008年首次提出[1]，后来在2012年的一篇论文中发表[2]。大约在2016年，它被并入Python Scikit-Learn库。</p><p id="1546" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它是一种基于树的算法，围绕决策树和随机森林理论构建。当呈现数据集时，该算法根据随机阈值将数据分成两部分。这个过程递归地继续，直到每个数据点被隔离。一旦该算法贯穿整个数据，它就过滤掉比其他数据点花费更少步骤的数据点，以将其隔离。<code class="fe mt mu mv mw b">sklearn</code>中的隔离森林是集合模型类的一部分，它返回每个实例的异常分数来衡量异常。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/d7107a54a66252f573f1ab8644abbf40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*gUiQQQfA-VaIgNRo.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图:分割数据以隔离隔离林中的异常(来源:<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_isolation_forest.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a>)</p></figure><p id="b633" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在大多数非监督方法中，首先对“正常”数据点进行分析，如果异常数据点与该分析不相似，则报告异常数据点。另一方面，隔离森林采取了不同的方法；它明确地隔离异常数据点。</p><p id="8050" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">值得一提的是，隔离森林是一种无监督的机器学习算法。也就是说，该过程中不涉及实际的“训练”或“学习”,并且在数据集中不存在预先确定的“异常值”或“非异常值”标签。所以没有传统机器学习意义上的精度测试。</p><p id="3599" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们用5个步骤来实现这个算法。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h2 id="4a3e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">第一步:导入库</strong></h2><p id="4691" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">你将需要<code class="fe mt mu mv mw b">pandas</code>和<code class="fe mt mu mv mw b">numpy</code>来处理数据，需要<code class="fe mt mu mv mw b">matplotlib</code>来进行数据可视化，当然，还需要<code class="fe mt mu mv mw b">sklearn</code>库中的算法本身。</p><pre class="kj kk kl km gt nf mw ng nh aw ni bi"><span id="6702" class="lv lw it mw b gy nj nk l nl nm"># libraries<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.ensemble import IsolationForest</span></pre><h2 id="23aa" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">第二步:准备数据</strong></h2><p id="28b8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了便于您理解，我没有导入任何外部数据集，而是创建了一个简单的二维<code class="fe mt mu mv mw b">numpy</code>数组，其中只有一个异常值，如二维图所示。</p><pre class="kj kk kl km gt nf mw ng nh aw ni bi"><span id="cf34" class="lv lw it mw b gy nj nk l nl nm"># dataset<br/>X = np.array([[1, 2], [2, 1], [3, 2], [0, 1], [25, 30], [3, 5]])</span><span id="656c" class="lv lw it mw b gy nn nk l nl nm"># using just numpy array for visualization<br/>plt.scatter(X[:,0], X[:,1], color = "r", s = 50)<br/>plt.grid()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/f54c949a3a90ee1f98c655c6759d6384.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*laknWiipAlxKFHj-TR7LKg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带有异常值的二维numpy数组</p></figure><h2 id="9dde" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">步骤3:实例化并拟合模型</h2><p id="3f45" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">像Scikit Learn库中的大多数算法一样，实例化和拟合模型只需要几行代码。</p><p id="9b8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">构建模型的两个重要参数是<em class="np"> n_estimators </em>和<em class="np">contaminance</em>，后者指定被识别为异常值的数据的百分比。</p><pre class="kj kk kl km gt nf mw ng nh aw ni bi"><span id="48c9" class="lv lw it mw b gy nj nk l nl nm"># instantiate model<br/>model = IsolationForest(n_estimators = 10)</span><span id="7cbe" class="lv lw it mw b gy nn nk l nl nm"># fit model<br/>model.fit(X)</span></pre><h2 id="61d8" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">第四步:预测</h2><p id="6186" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">当进行预测时，该过程包括向模型显示一个二维数组，该模型将对正常数据给出1，对异常值给出-1。</p><pre class="kj kk kl km gt nf mw ng nh aw ni bi"><span id="3671" class="lv lw it mw b gy nj nk l nl nm"># predict on new data <br/>new_data = np.array([[10, 15]])<br/>model.predict(new_data)</span><span id="2b98" class="lv lw it mw b gy nn nk l nl nm">&gt;&gt; array([-1])</span></pre><h2 id="e7b3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">第五步:异常分数</h2><p id="4d11" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">就像我在开始所说的，算法使用异常分数作为度量，它代表输入样本的平均异常分数。</p><pre class="kj kk kl km gt nf mw ng nh aw ni bi"><span id="faca" class="lv lw it mw b gy nj nk l nl nm"># average anomaly score<br/>model.decision_function(np.array(new_data))</span><span id="fb0b" class="lv lw it mw b gy nn nk l nl nm">&gt;&gt; array([-0.11147288])</span></pre></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h2 id="1d0b" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">最后一个字</strong></h2><p id="dd06" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">感谢您的阅读，希望这篇文章有助于您直观地了解什么是隔离林以及如何在Python <code class="fe mt mu mv mw b">sklearn</code>库中实现它。我在这份出版物中写了一系列文章，重点关注其他几种算法。如果你有兴趣去看看，下面是链接。和往常一样，请随时通过<a class="ae ky" href="https://twitter.com/DataEnthus" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或<a class="ae ky" href="https://www.linkedin.com/in/mab-alam/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我，并在<a class="ae ky" href="https://medium.com/@mab.datasc" rel="noopener"> Medium </a>上关注我，获取最新文章的通知。</p><ul class=""><li id="052b" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/k-nearest-neighbors-knn-for-anomaly-detection-fdf8ee160d13"> 1。k-最近邻(kNN) </a></li><li id="3f28" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/support-vector-machine-svm-for-anomaly-detection-73a8d676c331"> 2。支持向量机(SVM) </a></li><li id="5cff" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/dbscan-a-density-based-unsupervised-algorithm-for-fraud-detection-887c0f1016e9"> 3。无监督算法</a></li><li id="0752" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-for-anomaly-detection-elliptic-envelope-2c90528df0a6"> 4。椭圆形信封</a></li><li id="2d2c" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/anomaly-detection-with-local-outlier-factor-lof-d91e41df10f2"> 5。局部异常值因子(LOF) </a></li><li id="8e87" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/z-score-for-anomaly-detection-d98b0006f510"> 6。z分数</a></li><li id="058f" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">7 .<a class="ae ky" rel="noopener" target="_blank" href="/boxplot-for-anomaly-detection-9eac783382fd">。箱线图</a></li><li id="0b01" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/statistical-techniques-for-anomaly-detection-6ac89e32d17a"> 8。统计技术</a></li><li id="079f" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/time-series-anomaly-detection-with-anomalize-library-67472003c003"> 9。时间序列异常检测</a></li></ul><p id="80ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献</strong></p><p id="1e6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[1]刘，费托尼，丁，，周，张志华.“隔离林。”数据挖掘，2008。08年的ICDM。第八届IEEE国际会议。</p><p id="69b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]刘，费托尼，丁，，周，张志华.“基于隔离的异常检测。”《美国计算机学会数据知识发现汇刊》6.1 (2012): 3。</p></div></div>    
</body>
</html>