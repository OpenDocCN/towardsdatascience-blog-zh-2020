<html>
<head>
<title>Using LSTM Autoencoders on multidimensional time-series data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对多维时间序列数据使用LSTM自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-lstm-autoencoders-on-multidimensional-time-series-data-f5a7a51b29a1?source=collection_archive---------4-----------------------#2020-11-10">https://towardsdatascience.com/using-lstm-autoencoders-on-multidimensional-time-series-data-f5a7a51b29a1?source=collection_archive---------4-----------------------#2020-11-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/90c9761b3c6c6328f6e58b44e45b74a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JqUyVz-f97I_Yn_D"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">埃菲社在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="251a" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">实践中的深度学习</h2><div class=""/><div class=""><h2 id="cb4e" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">演示如何使用LSTM自动编码器分析多维时间序列</h2></div><p id="520a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在本文中，我将展示一个非常有用的模型来理解时间序列数据。我已经将这种方法用于无监督的异常检测，但它也可以用作通过降维进行预测的中间步骤(例如，对潜在嵌入层和完整层进行预测)。</p><p id="6e1d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">简而言之，这种方法<strong class="lg jq">将一个多维序列</strong>(想想多个计数的窗口时间序列，来自传感器或点击等)<strong class="lg jq">压缩成一个表示该信息的单一向量</strong>。有了有效的编码器/解码器，我们可以使用潜在向量作为多层感知器的输入，或者作为更大的多头网络中的另一组特征。</p><p id="1605" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我不打算讨论LSTMs或自动编码器的细节。对于这些信息，我强烈推荐以下文章:</p><div class="ip iq gp gr ir ma"><a rel="noopener follow" target="_blank" href="/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd jq gy z fp mf fr fs mg fu fw jp bi translated">LSTM和GRU的图解指南:一步一步的解释</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">嗨，欢迎来到长短期记忆(LSTM)和门控循环单位(GRU)的图解指南。我是迈克尔…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">towardsdatascience.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ix ma"/></div></div></a></div><div class="ip iq gp gr ir ma"><a rel="noopener follow" target="_blank" href="/applied-deep-learning-part-3-autoencoders-1c083af4d798"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd jq gy z fp mf fr fs mg fu fw jp bi translated">应用深度学习-第3部分:自动编码器</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">概观</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">towardsdatascience.com</p></div></div><div class="mj l"><div class="mp l ml mm mn mj mo ix ma"/></div></div></a></div><p id="1ef3" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">当我们从潜在向量中重建原始时间序列时，通常会有一定程度的误差。对于训练有素的编码器/解码器，该误差可以提供很多信息。</p><p id="84f8" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于异常检测，我们会查看误差的大小。<strong class="lg jq"> <em class="mq">幅度</em> </strong>让我们了解输入时间序列的<strong class="lg jq"> <em class="mq">不规则性</em> </strong>。我们可以用这个作为识别异常的代理。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="998a" class="my mz jg bd na nb nc nd ne nf ng nh ni kv nj kw nk ky nl kz nm lb nn lc no np bi translated">数据</h1><p id="c00f" class="pw-post-body-paragraph le lf jg lg b lh nq kq lj lk nr kt lm ln ns lp lq lr nt lt lu lv nu lx ly lz ij bi translated">我使用了一组我在以前的文章中用过的数据(链接如下):</p><div class="ip iq gp gr ir ma"><a href="https://samsachedina.medium.com/calculating-a-features-importance-with-xgboost-and-gini-impurity-3beb4e003b80" rel="noopener follow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd jq gy z fp mf fr fs mg fu fw jp bi translated">用XGBoost和Gini杂质计算特征的重要性</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">使用XGBoost回归识别重要特征</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">samsachedina.medium.com</p></div></div><div class="mj l"><div class="nv l ml mm mn mj mo ix ma"/></div></div></a></div><p id="adaa" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这些数据是2020年10月26日交易时段的分笔成交点数据。每一个分笔成交点代表一个价格变化，或者是证券的收盘价、买价或卖价。订单簿数据被快照并在每个分笔成交点返回。订单簿可能会“偏离分笔成交点”波动，但只有在产生分笔成交点时才会被记录，这样可以进行更简单的基于时间的分析。</p><p id="8213" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下面是一个记录示例:</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0eeb9a108428e0bf51cbd7a73c169f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/0*7ZsAfy0OmSRKCTow.png"/></div></figure><p id="b302" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们有一个时间字段、我们的定价字段和“md_fields”，它们代表以不同于当前要价/出价的价格增量卖出(“要价”)或买入(“出价”)的需求。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="f2cb" class="my mz jg bd na nb nc nd ne nf ng nh ni kv nj kw nk ky nl kz nm lb nn lc no np bi translated">模型</h1><p id="8b23" class="pw-post-body-paragraph le lf jg lg b lh nq kq lj lk nr kt lm ln ns lp lq lr nt lt lu lv nu lx ly lz ij bi translated">我将创建一个“堆叠”自动编码器。数据被重新整形，允许我通过超参数调整来优化窗口大小。</p><p id="0302" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">查看我如何通过函数“generate_datasets_for_training”返回train_x、train_y、test_x和test_y的示例</p><figure class="nx ny nz oa gt is"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="86a1" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">模型从一个<strong class="lg jq">编码器</strong>开始:首先是输入层。输入图层是LSTM图层。接着是另一个较小尺寸的LSTM层。然后，我获取从第2层返回的序列——然后将它们提供给一个重复向量。重复向量获取单个向量，并以某种方式对其进行整形，以允许其被馈送到我们的<strong class="lg jq">解码器</strong>网络，该网络与我们的编码器对称。<strong class="lg jq"> <em class="mq">注意，不一定要对称，但这是标准做法。</em> </strong></p><p id="5683" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们的最后一层是一个时间分布的密集层，它产生一个类似于我们输入的序列。</p><p id="45b3" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最后，我们计算基于原始输入的均方误差损失:由我们的最终层产生的序列和原始输入序列之间的误差。最小化这成为我们网络学习的优化过程。</p><p id="03d1" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这是我们最后的网络</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div class="gh gi od"><img src="../Images/35ea1e453d2a910460426c8251f307da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*sLjQV3f_s6_09AZTHv1UGQ.png"/></div></figure><p id="0296" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">请注意，中间层是一个重复向量，它获取encoder_3(我们的潜在表示)的输出，并在我们的回看窗口中重复它的步数。</p><p id="1b1f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果我们需要(1，4)的潜在表示，我们只需将编码器层压缩成那个形状。要压缩一个时间序列窗口，我们需要做的就是从最后一个编码层提取输出。</p><p id="2e10" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">看到这个要点的例子，如何建立！</p><figure class="nx ny nz oa gt is"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="d78c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这是将时间序列数据表示为密集潜在表示的基本介绍。</p><p id="0d93" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我希望你喜欢这篇文章！</p><p id="130d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果你喜欢这个，你可能会喜欢:</p><div class="ip iq gp gr ir ma"><a href="https://medium.com/the-innovation/yolov4-in-10-minutes-715f016bcf42" rel="noopener follow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd jq gy z fp mf fr fs mg fu fw jp bi translated">约洛夫4十分钟后</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">在10分钟内获得视频注释</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">medium.com</p></div></div><div class="mj l"><div class="oe l ml mm mn mj mo ix ma"/></div></div></a></div></div></div>    
</body>
</html>