<html>
<head>
<title>Develop an Image-to-Image Translation Model to Capture Local Interactions in Mechanical Networks (GAN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">开发一个图像到图像的转换模型，以捕捉机械网络(GAN)中的局部相互作用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/develop-a-image-to-image-translation-model-to-capture-local-interactions-in-mechanical-networks-9c2f45230849?source=collection_archive---------45-----------------------#2020-10-23">https://towardsdatascience.com/develop-a-image-to-image-translation-model-to-capture-local-interactions-in-mechanical-networks-9c2f45230849?source=collection_archive---------45-----------------------#2020-10-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d8dd" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><div class=""><h2 id="326c" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">生成式对抗网络，用于在各种机械网络的图像上自动绘制链接。</h2></div><h1 id="52ee" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">概观</h1><p id="b63f" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">超材料是一种机械性能依赖于其结构的材料，这种结构赋予了它们传统系统中没有的变形模式。超材料的一个流行模型由通过机械链接相互连接的构建模块组成，这定义了材料的结构。这些被称为<strong class="li ja">机械网络</strong>。两个机械网络的不同之处在于:</p><ul class=""><li id="405a" class="mc md iq li b lj me lm mf lp mg lt mh lx mi mb mj mk ml mm bi translated">积木是如何连接的。这将定义我们处理的系统类别(例如Kagome系统、正方形、三角形等..).</li><li id="c601" class="mc md iq li b lj mn lm mo lp mp lt mq lx mr mb mj mk ml mm bi translated">区块在空间中的分布情况，即区块之间的距离。</li></ul><p id="54c9" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">换句话说，为了对系统进行分类并掌握其机械特性，了解块体的位置和连接性是至关重要的。通常情况下，机械网络可以用一个<em class="mv">晶格表示</em> : <strong class="li ja">点</strong>(也称为位置)来直观地描述，代表建筑块，并通过<strong class="li ja">键</strong>(也称为边)连接。在研究界经常被考虑的一个典型的机械网络是Kagome系统，如下图所示。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/db2b3f3887273872c5f1b5cd34cd3201.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*r0QviD-BqV80IV8LgsY8AQ.jpeg"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">Kagome点阵:点(黑点)由边(直线)连接。图片作者。</p></figure><h1 id="5a99" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">问题陈述和方法</h1><p id="b701" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在某些情况下，特别是在处理微观超材料时，用户/研究人员将只处理构件(点)的图像，连接键太小而无法检测，但仍然存在并对系统的机械性能有贡献。该项目旨在使用深度学习和神经网络在仅包含点的图像上自动绘制出键连接。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/ecc415a2fada54460e259f2409861643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*KsWO2bCk7NxWezoNUKMQOQ.jpeg"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">用户仅提供块的图像；模型绘制连接键。图片作者。</p></figure><p id="0794" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">为此，我们将使用Jason Brownless博士的<a class="ae nj" href="https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/" rel="noopener ugc nofollow" target="_blank">文章</a>介绍如何开发一个<strong class="li ja">生成式对抗网络(GAN) </strong>作为<strong class="li ja">图像到图像</strong>算法。该模型仅通过对三种不同机械网络(Kagome、三角形和正方形网格)的90张图像进行训练，就成功地在看不见的系统图像上绘制了连接键。虽然结果相当惊人，但了解该模型的架构也同样令人着迷。</p><p id="7003" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">用于训练/测试/验证模型的数据包括由<em class="mv"> Mathematica </em>生成的图像，Mathematica 是一个经常用于研究和学术社区的程序。提供的每个图像实际上由一对图像组成，分别是具有和不具有结合的相同系统(即，点在空间上相同分布)。然后，我们选择30个随机生成的Kagome点阵，以及另外30个正方形点阵和30个三角形点阵:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/c29b541b737020f9756e1c8cbcc66d98.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*zKCZfS4oTocmuA_qill1Zw.jpeg"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">无键和有键的变形正方晶格。图片作者。</p></figure><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/cf8ec32db54f46d3c6798c6ec198a982.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*-LrVei9KrmQH0FQW_qzFYA.jpeg"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">变形的三角形晶格，有键和无键。图片作者。</p></figure><p id="a3cc" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">这里使用的代码显然是由<strong class="li ja"> Python </strong>编写的，并且主要依赖于包<strong class="li ja"> Keras </strong>(以及常见的嫌疑人<em class="mv"> numpy </em>和<em class="mv"> matplotlib </em>)来构建和训练多个神经网络。笔记本(可以在这里找到<a class="ae nj" href="https://github.com/adriensaremi/Springboard/blob/master/Capstone_2%20-%20GAN%20and%20Mechanical%20Networks%20/image2image.ipynb" rel="noopener ugc nofollow" target="_blank"/>)是通过Google Colab编写的，它允许我们利用Google的GPU服务。</p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="4845" class="ko kp iq bd kq kr nt kt ku kv nu kx ky kf nv kg la ki nw kj lc kl nx km le lf bi translated">生成对抗网络</h1><p id="0ecd" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">GAN的架构由两个以对抗方式训练在一起的主要模型组成——鉴别器和生成器——以及将它们绑定和训练在一起的其他功能</p><h2 id="b3e6" class="ny kp iq bd kq nz oa dn ku ob oc dp ky lp od oe la lt of og lc lx oh oi le iw bi translated">鉴别器</h2><p id="3c48" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">鉴别器是一个深度<strong class="li ja">卷积神经网络(CNN) </strong>，它获取图像形状并执行条件图像分类。总之，它获取源图像(无焊接)和目标图像(有焊接),并分类目标是否是源的<em class="mv">真实</em>转换。在被传送到网络之前，这两幅图像被连接成一幅图像。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/98b792ff922100fdd0bc564ff53bffa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*UV3DoGbERjYNsQOjnS1uZg.jpeg"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">鉴别器模型。图片作者。</p></figure><p id="18e1" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">深度CNN由6层组成，每一层都缩小前一层的输出图像，以输出一个分数，该分数用作<em class="mv">分类度量</em>。</p><h2 id="5a18" class="ny kp iq bd kq nz oa dn ku ob oc dp ky lp od oe la lt of og lc lx oh oi le iw bi translated">发电机</h2><p id="779e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">生成器遵循U-net架构，由三部分组成:编码器(收缩)、瓶颈和解码器(扩展)。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/e8f337926c1619999af5bcd5367feef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*NyjzAnoXJZc5IwApK8yz4Q.jpeg"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">发电机型号。Jason Brownless关于机器学习掌握的图片。</p></figure><ol class=""><li id="15dd" class="mc md iq li b lj me lm mf lp mg lt mh lx mi mb ol mk ml mm bi translated">编码器部分由多个对输入图像进行下采样的模块组成。每个块都是一个卷积层，具有数量不断增加的过滤器。</li><li id="8c2d" class="mc md iq li b lj mn lm mo lp mp lt mq lx mr mb ol mk ml mm bi translated">相反，解码器由几个扩展模块组成，滤波器数量不断减少。重要的是，每个扩展层的输入既有前一个扩展块的输出，也有相应收缩块的输出。这确保了在编码阶段学习的特征被重新用于在解码阶段重建图像。</li><li id="6725" class="mc md iq li b lj mn lm mo lp mp lt mq lx mr mb ol mk ml mm bi translated">瓶颈部分连接编码和解码部分。</li></ol><h2 id="2351" class="ny kp iq bd kq nz oa dn ku ob oc dp ky lp od oe la lt of og lc lx oh oi le iw bi translated">复合模型和训练模型</h2><p id="700d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">生成对抗网络是一个同时包含鉴别器和生成器的复合模型。当生成器通过鉴别器更新其权重时，鉴别器不被训练并“自己”更新其权重。关键特征是，与生成器相比，鉴别器的权重更新需要较慢，因此生成器可以快速学习绘制焊接。</p><p id="8211" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">每个训练步骤包括使用复合模型以及来自训练数据的“真实”图像和来自生成器的“虚假”生成图像。这个想法是，真实目标和假生成图像的组合，分别被分类为1和0，将帮助生成器建立一个模型，更快地收敛到一个解决方案。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi om"><img src="../Images/4d4c1fd3b45351e0b2b2ca0958304492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*OIgt8Xz4Fp6DkQ8-lcjynQ.png"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">GAN的整体架构及其训练方式。图片作者。</p></figure><p id="52fe" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">这个模型中有许多可调参数和复杂的设计。为了保持这篇文章的简单和可读性，我故意忽略了代码的复杂性，但是请读者查看我的Github库以获得更多细节。</p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="3383" class="ko kp iq bd kq kr nt kt ku kv nu kx ky kf nv kg la ki nw kj lc kl nx km le lf bi translated">结果</h1><p id="491a" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们在90幅图像上训练该模型，分成3批，这意味着在每个时期的每批中随机抽取30幅图像。我们选择在500个历元上训练模型，这意味着总共有500 x 30 = 15，000个迭代步骤。虽然在本地机器上训练模型可能需要长达一天的时间，但谷歌GPU将这一过程加快到不到2小时！通过迭代过程，我们显示了从训练数据集中随机抽取的样本的生成图像:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi on"><img src="../Images/4dd84c7950391e2988451b2203f9f820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*BNsOsDx1TgnwEkAfTtK9tQ.jpeg"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">通过模型训练生成的图像(随机选择)的演变。图片作者。</p></figure><p id="01fe" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">对照模型自己的训练集测试模型不是检查其性能的好选择，但它让我们了解生成功能执行得有多好。因此，我们还需要展示模型如何处理看不见的数据:</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/415aacceeb9872e39f0fa0fa8b222cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*IkYbYquBjizTvChjSkem1w.jpeg"/></div><p class="ne nf gj gh gi ng nh bd b be z dk translated">验证集:戈薇，正方形和三角形格子。图片作者。</p></figure><p id="f2b1" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">最初，我的目标是只针对Kagome类构建模型。然后，我决定扩大模型的应用范围，将正方形和三角形格子包括在内:</p><ul class=""><li id="13ba" class="mc md iq li b lj me lm mf lp mg lt mh lx mi mb mj mk ml mm bi translated">顶行:第一个模型仅在Kagome系统的图像上进行训练，显然在绘制正方形和三角形的连接方面存在困难</li><li id="ef1a" class="mc md iq li b lj mn lm mo lp mp lt mq lx mr mb mj mk ml mm bi translated">底部一行:第二个模型包含了所有三个格子，产生了更好更重要的结果</li></ul><p id="56e4" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">非常重要的是，除了绘制键之外，第二个模型还保持所生成图形上的点的位置，这是一个必须保持不变的关键属性，因为这些点的位置决定了系统的机械属性(如上所述)。</p><h1 id="1817" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">结论和进一步改进</h1><p id="2800" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">通过只对90对图像进行训练，该模型可以获取部分完整的机械网络的看不见的图像，并绘制正确的键连接，这是理解系统力学的关键特征。这样做，模型不会改变材料的基本属性(点/块的位置),并为研究者提供额外的信息。令人兴奋的是，该模型能够在不止一个，而是三个机械系统上区分和执行其图像到图像的翻译功能:Kagome，正方形和三角形晶格。</p><p id="2304" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">虽然这是一个令人满意的结果，但是可以做许多事情来提高模型的性能。特别是，我们可以:</p><ul class=""><li id="b414" class="mc md iq li b lj me lm mf lp mg lt mh lx mi mb mj mk ml mm bi translated">在更大的一组图像上训练模型并持续更长的时间(更多的时期)</li><li id="b84e" class="mc md iq li b lj mn lm mo lp mp lt mq lx mr mb mj mk ml mm bi translated">扩大训练批次，以包括额外的超材料类别，特别是更复杂的结构，如每个站点的平均连接数比我们迄今为止看到的更多</li></ul><h1 id="e87a" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">参考文献和致谢</h1><p id="b81b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">同样，代码、幻灯片和报告可以在<a class="ae nj" href="https://github.com/adriensaremi/Springboard/tree/master/Capstone_2%20-%20GAN%20and%20Mechanical%20Networks%20" rel="noopener ugc nofollow" target="_blank">这里</a>找到。所有图片(除非另有说明)均由作者制作。我要特别感谢我在Springboard的导师卢卡斯·艾伦(Lucas Allen)，感谢他在这个项目中的指导。我还要感谢Brownlee博士在帮助开发人员构建机器学习模型方面的多个在线教程。</p><p id="f250" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ms lr ls lt mt lv lw lx mu lz ma mb ij bi translated">[1] J. Brownlee，<a class="ae nj" href="https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/" rel="noopener ugc nofollow" target="_blank">如何开发一个Pix2Pix GAN用于图像到图像的翻译</a> (2020)，机器学习之谜</p></div></div>    
</body>
</html>