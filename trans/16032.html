<html>
<head>
<title>Graph Embeddings For Social Media: How to Profile and Cluster Millions of Users</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">社交媒体的图形嵌入:如何描述和聚类数百万用户</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/graph-embeddings-for-social-media-how-to-profile-and-cluster-millions-of-users-a34be8c216c3?source=collection_archive---------30-----------------------#2020-11-04">https://towardsdatascience.com/graph-embeddings-for-social-media-how-to-profile-and-cluster-millions-of-users-a34be8c216c3?source=collection_archive---------30-----------------------#2020-11-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="3a2e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a>，营销</h2><div class=""/><div class=""><h2 id="1b56" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">还记得寻找合适的影响者所花费的时间吗？</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/995775ffad4057df2bd52b224b7f92a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b96nfcPqlaiFl6PzzjRNuw.jpeg"/></div></div></figure><blockquote class="ld"><p id="8a79" class="le lf it bd lg lh li lj lk ll lm ln dk translated"><em class="lo">在这篇文章中，我想介绍一下在社交媒体挖掘领域的一些发现，描述一个Word2Vec模型的实现，该模型用于索引整个用户群，提供一个工具来查找社区中的相似用户。</em></p></blockquote><h1 id="25d5" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki ma kj mb kl mc km md ko me kp mf mg bi translated">简介:</h1><p id="b91d" class="pw-post-body-paragraph mh mi it mj b mk ml kd mm mn mo kg mp mq mr ms mt mu mv mw mx my mz na nb ln im bi translated">尽管许多不同的社交媒体平台已经提供了发现相似用户的方法，但这组功能主要是为最终用户构建的，这意味着目标是向他们展示他们想要看到的内容，而不是从商业角度来看实际上与他们相似的用户。</p><p id="b6b3" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">能够瞄准相似用户的算法被用于脸书广告等工具的背后，这使得广告商有可能瞄准与特定条件(如品牌、口味或其他人口统计数据)相似的用户。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/0f4d1f1f1e690f51fd5432f68a0ebbdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NwNDXq7e7dhGpRBx9rGapg.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">作者图片</p></figure><p id="96cc" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi nm translated">让我们从一个例子开始:我们有一组<code class="fe nv nw nx ny b">n</code>用户关注一个特定的品牌/档案。这些用户中的每一个都可以像<code class="fe nv nw nx ny b">n</code>用户一样关注。通常，在追随特定品牌的一组用户中，这些用户之间存在关系。一些用户跟随彼此是因为他们只是彼此认识，一些其他用户跟随特定用户是因为后者是“影响者”，相同用户群中的一些其他用户可能跟随非常知名的品牌。</p><p id="07cb" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">拥有用户群的“映射”表示可以帮助企业回答不同的问题，其中包括:</p><ul class=""><li id="cb0f" class="nz oa it mj b mk nc mn nd mq ob mu oc my od ln oe of og oh bi translated">怎样才能找到类似<code class="fe nv nw nx ny b">xyz</code>的影响者？</li><li id="b329" class="nz oa it mj b mk oi mn oj mq ok mu ol my om ln oe of og oh bi translated">用户<code class="fe nv nw nx ny b">xyz</code>和用户<code class="fe nv nw nx ny b">zyx</code>有多相似？</li><li id="f46c" class="nz oa it mj b mk oi mn oj mq ok mu ol my om ln oe of og oh bi translated">我可以在没有任何关于用户的附加数据的情况下将我的用户群分组到特定的组中吗？</li><li id="5d2f" class="nz oa it mj b mk oi mn oj mq ok mu ol my om ln oe of og oh bi translated">我的社区中最有影响力的人是谁？</li></ul><h1 id="b7f6" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki on kj mb kl oo km md ko op kp mf mg bi translated">战略:</h1><p id="4a45" class="pw-post-body-paragraph mh mi it mj b mk ml kd mm mn mo kg mp mq mr ms mt mu mv mw mx my mz na nb ln im bi translated">本研究的主要目标是创建一个品牌社区中每个用户的数字表示，可用数据包括用户名列表和每个用户关注的个人资料列表:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/082b18978382010152ce7e70557cb663.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXz7sXlhUJsqBEhjtoL2Yw.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">数据的图形表示。(图片由作者提供)</p></figure><p id="12ca" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">如果有可能用数字表示空间内的用户，也有可能计算用户之间的操作，例如计算相似性，发现社区中的聚类和趋势。</p><p id="44c6" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">在思考如何应对这一挑战的阶段，我想到的主要想法是将每个用户视为不同的项目集，类似于何时在商店购物:我们有自己的购物篮(社交媒体档案)，我们将这个篮子装满我们想要的东西；不同的购物者对他们的购物篮做同样的事情，因此分析这些数据可以帮助了解顾客之间的模式。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/d1f37e84a48f7e9d09a1e5a78639c316.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OSrakY5TaY3VT6pCz7bSIw.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">只需用社交媒体档案代替物品，神奇的事情就发生了……(图片由作者提供)</p></figure><p id="9d1f" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">这类任务可以通过实现<a class="ae oq" href="https://en.wikipedia.org/wiki/Apriori_algorithm" rel="noopener ugc nofollow" target="_blank"> apriori </a>这样的算法来完成。这类算法通常用于频繁项集挖掘，它不是一种机器学习方法，而是来自一组称为关联规则学习的算法。</p><p id="bc88" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">这种方法的问题是，它不能度量实例之间的相似性，因为数据集中的每个实例都没有被转换成数学表示，而只是使用两个奇特的度量来表示:<a class="ae oq" href="https://www.kdnuggets.com/2016/04/association-rules-apriori-algorithm-tutorial.html" rel="noopener ugc nofollow" target="_blank">置信度和</a>。</p><p id="7a12" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">然而，apriori的酷之处在于它提供了用图表表示关联规则的可能性，这对于评估和报告非常有用。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/eef89516fd567cba20c1189b9c7aeb9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Ram0NGp1LBWW4gyZHQa2A.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">来源:<a class="ae oq" href="https://www.kdnuggets.com/2016/04/association-rules-apriori-algorithm-tutorial.html" rel="noopener ugc nofollow" target="_blank"> KDNuggets </a></p></figure><p id="91a8" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">在那一刻，有必要后退一步，专注于最终目标:我需要找到一种方法，让我以数学的方式编码用户，保留他们之间的关系。</p><p id="db3f" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">当回过头来从宏观层面分析这种情况时，我意识到这其中的主要问题是将用户名“转换”成“数字”，因此问题很清楚:哪种算法、模型或任何东西可以将文本转换成数字？</p><p id="6417" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">同时，我意识到已经有一个非常强大的工具叫做<a class="ae oq" href="https://projector.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow嵌入式投影仪</a>。它允许将高维数据投影到三维空间中，并自动执行PCA(减少维数)等操作，并计算向量之间的距离，因此它可以显示一个词与另一个词的相似程度。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/44cff2daf93d877cc1907b55038c141c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*VaMFfPq5FYTDJLGTJ4f8oA.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">Tensorflow嵌入式投影仪的一个例子。(图片由作者提供)</p></figure><h1 id="54f8" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki on kj mb kl oo km md ko op kp mf mg bi translated">实施:</h1><p id="ef71" class="pw-post-body-paragraph mh mi it mj b mk ml kd mm mn mo kg mp mq mr ms mt mu mv mw mx my mz na nb ln im bi translated">主要想法是试图根据用户追随者数据训练一个Word2Vec模型，以测试该模型是否能够学习用户之间的关系。</p><p id="8302" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">Word2Vec是一个神经网络，能够生成单词的密集表示。这种算法，更具体地说是一种无监督学习算法，试图基于单词的邻居来预测单词，因此，在这种情况下，该算法将基于用户来预测追随者。</p><p id="9449" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">Word2Vec可以主要使用两种不同的策略进行训练:Skip-gram和CBOW。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/9e7d3516e88635b7c9bc4ddab8c6cc63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*Wx2Jgd9eM3-UH6KyWi4ITA.gif"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">CBOW与Skip-gram的图形表示。(图片由作者提供)</p></figure><p id="eef3" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">在CBOW中，组合一组周围的单词(用户)来预测中间的单词(用户)。相反，Skip-gram将单词(用户)放在中间来预测周围的上下文。</p><p id="48b9" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">为了实际实现这一点，我选择使用Amazon SageMaker及其Word2Vec实现，名为<a class="ae oq" href="https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext.html" rel="noopener ugc nofollow" target="_blank"> <strong class="mj jd"> BlazingText </strong> </a>。</p><h1 id="f743" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki on kj mb kl oo km md ko op kp mf mg bi translated">输入数据:</h1><p id="66f2" class="pw-post-body-paragraph mh mi it mj b mk ml kd mm mn mo kg mp mq mr ms mt mu mv mw mx my mz na nb ln im bi translated">输入数据由一个简单的<code class="fe nv nw nx ny b">.txt</code>文件组成，该文件为每个用户包含一个逗号分隔的特定用户正在关注的配置文件列表。输入数据的总大小包括大约520万个条目。</p><h1 id="e153" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki on kj mb kl oo km md ko op kp mf mg bi translated">培训阶段:</h1><p id="9a21" class="pw-post-body-paragraph mh mi it mj b mk ml kd mm mn mo kg mp mq mr ms mt mu mv mw mx my mz na nb ln im bi translated">训练在<code class="fe nv nw nx ny b">ml.c4.xlarge</code>机器上进行，使用接近默认的超参数，此外，由于预算原因，没有进行超参数优化。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/19eb9850bebbb84177572340c66ab1fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZQrEWbEAO9X8tFi_iGSt1g.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">作者图片</p></figure><p id="9056" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">由于选择了训练策略skip-gram，所以训练进行了五个时期，使用100个用户的<code class="fe nv nw nx ny b">min_count</code>来预测下一个时期(这是理解用户遵循哪种简档的合理数量。)，对于每个输出向量，我选择了100维的大小。其余的超参数保持默认。有关可用超参数的完整列表，请参考<a class="ae oq" href="https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext_hyperparameters.html" rel="noopener ugc nofollow" target="_blank">官方文档</a>。</p><p id="a17c" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">培训阶段持续了大约9个小时。</p><h1 id="656f" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki on kj mb kl oo km md ko op kp mf mg bi translated">评估:</h1><p id="63bb" class="pw-post-body-paragraph mh mi it mj b mk ml kd mm mn mo kg mp mq mr ms mt mu mv mw mx my mz na nb ln im bi translated">理解评估该模型的正确方法超出了本文的范围，但是，出现了几个有趣的点:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/3eabeef4a6b6920da6237c1c7cba6728.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*iLat3sIO-Vi0ZYON0uSuIg.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">一个用二维空间表示的单词向量的例子。(图片由作者提供)</p></figure><ul class=""><li id="0a18" class="nz oa it mj b mk nc mn nd mq ob mu oc my od ln oe of og oh bi translated">由于任务包括映射一个社区内的所有用户，没有这个应用程序的训练和测试集，矛盾的是，我在寻找一个完美的数据溢出。</li><li id="5af9" class="nz oa it mj b mk oi mn oj mq ok mu ol my om ln oe of og oh bi translated">从推荐系统中借用一些知识，是否有可能以类似于测试推荐者的方式来测试这个系统:隐藏实例之间的一些关系，并检查推荐者是否仍然能够找到模糊的关系。</li><li id="14da" class="nz oa it mj b mk oi mn oj mq ok mu ol my om ln oe of og oh bi translated">Word2Vec模型确实考虑了单词出现的顺序。这在该任务中是无用的，这就是为什么指定了100的<code class="fe nv nw nx ny b">window_size</code>,以便给模型一个预上下文来帮助预测下一个追随者。</li></ul><p id="bcc6" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">一旦训练完成，我最终得到了一个巨大的<code class="fe nv nw nx ny b">.tar.gz</code>模型，解压缩后有两个文件:<code class="fe nv nw nx ny b">vectors.txt</code>和<code class="fe nv nw nx ny b">vectorz.bin</code>，它们完全兼容<code class="fe nv nw nx ny b">gensim</code>提供的<code class="fe nv nw nx ny b"><a class="ae oq" href="https://radimrehurek.com/gensim/models/keyedvectors.html" rel="noopener ugc nofollow" target="_blank">keyedvectors</a></code> <a class="ae oq" href="https://radimrehurek.com/gensim/models/keyedvectors.html" rel="noopener ugc nofollow" target="_blank">格式</a>。</p><p id="567c" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">使用<code class="fe nv nw nx ny b">gensim</code>读取向量和followers一样容易，此外，我们可以使用<code class="fe nv nw nx ny b">most_similar</code>方法对模型进行一些手动测试:</p><pre class="ks kt ku kv gt ou ny ov ow aw ox bi"><span id="8d4d" class="oy lq it ny b gy oz pa l pb pc">from gensim.models import KeyedVectorsword_vectors = KeyedVectors.load_word2vec_format(‘vectors.txt’, binary=False)</span></pre><p id="945b" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">为了了解模型对实体间差异的理解有多精确，有多好，特别是当差异非常细微时，我决定选择Zara和Louis Vuitton这两个知名品牌。</p><p id="0cf7" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">Zara是一家快时尚零售商，而路易威登(仍然)被认为是一家法国时装和奢侈品公司。</p><p id="232e" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">这里是它们中最常见的实体:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/675c8a3aa3c0cfd6852f51ee57735a43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F1yASQk6e8lfMmYDcIrHgg.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">作者图片</p></figure><p id="cdeb" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">从上面的结果来看，该模型似乎能够区分一些奢侈品和Fas时尚品牌，返回实际上有意义的结果。</p><p id="56b7" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">让我们尝试一些不同的东西，这一次，两位音乐家属于两个完全不同的流派，Lady Gaga和Solomun:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/766b20cdff991c978361baeb8f8fbb22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oxd8-mlXMIQzHyqi-rZCzA.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">作者图片</p></figure><p id="a172" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">令人惊讶的是，该模型还学习了不同音乐家的向量，能够为Lady Gaga返回不同的流行/商业艺术家，为Solomun返回更多的技术艺术家。</p><p id="8b12" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">回到之前提到的有趣的图形可视化，现在也有可能做到这一点:模型为每个实体生成100维向量，为了在2-D空间上绘制它，有必要降低维度，实现这一点的一种方法是使用<code class="fe nv nw nx ny b">scikit-learn</code> <code class="fe nv nw nx ny b"><a class="ae oq" href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html" rel="noopener ugc nofollow" target="_blank">TSNE</a></code>类，该类将数据点之间的相似性转换为连接概率。另一种方式可以是计算一个<a class="ae oq" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" rel="noopener ugc nofollow" target="_blank"> PCA </a>。</p><p id="e941" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">下图由使用<code class="fe nv nw nx ny b">TSNE</code>和<code class="fe nv nw nx ny b">matplotlib</code>可视化的300个最常见向量组成:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pd"><img src="../Images/0c17066a5d400809d760ef819471141b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MIBancyGDT_BFRWWzOsoPQ.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">作者图片</p></figure><p id="f515" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">很明显，存在一些数据聚类，这意味着该模型成功地学习了跨实体的相似性。例如，在左上角，我们可以看到一些零售品牌，而在右下角的名人和一些音乐人。</p><p id="fb44" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">最后，我们还可以将计算出的向量和元数据导出为<code class="fe nv nw nx ny b">.tsv</code>格式，使其对于前面提到的另一个工具来说是可读的:<a class="ae oq" href="https://projector.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">Tensroflow Embedding Projector</a>。</p><p id="3ad3" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">这里的优点是，嵌入式投影仪可以计算不同类型的维度缩减，使用户有可能尝试一些算法。此外，将整个矢量和元数据从Word2Vec模型导出到嵌入的投影仪并加载这些文件也很简单。关于如何做的简单教程可以在<a class="ae oq" href="https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="01d5" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">下图显示了通过嵌入投影仪计算的三维PCA，突出显示的单词表示与标有“chanelofficial”的点最近的点。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/ffece334f81439facf288f5cc4e13e4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7A0acNfWkrexsDThUUkp_w.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">作者图片</p></figure><p id="80fb" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">另一个例子，使用“宝马”作为搜索查询和神话般的黑暗模式:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/0d4a680ec457cf1ec86788546f80303f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*caOEdg1ij_W0G-RRbrLJDA.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">作者图片</p></figure><p id="3b1a" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">可以看出在这两个例子中，搜索查询如何返回在上下文中有意义的值，此外，比较来自二维降维和由嵌入投影仪生成的三维的值，后者似乎不太“分类”和更具包容性，返回严格来说不属于同一类别的实体(例如Zara和h&amp;m)但对相似性的不同观点更开放(例如奔驰和劳力士)。</p><h1 id="c140" class="lp lq it bd lr ls lt lu lv lw lx ly lz ki on kj mb kl oo km md ko op kp mf mg bi translated">结论:</h1><p id="64fd" class="pw-post-body-paragraph mh mi it mj b mk ml kd mm mn mo kg mp mq mr ms mt mu mv mw mx my mz na nb ln im bi translated">在本研究结束时，可以进行一些考虑:提供一个能够识别实体之间相似性的系统的最初目标似乎已经实现，但是，一个事物与另一个事物有多少相似性的想法仅仅是主观的或面向领域的，例如，同一领域中两个品牌之间的相似性可能会被在完全不同的领域中运营的其他品牌的存在所扭曲。类似于算术平均值如何误导样本中的许多异常值。</p><p id="e5c1" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">另一个需要考虑的问题是Word2Vec模型在这种情况下的使用方式:像本研究中这样对整个数据集进行矢量化有助于索引数据集中的实例，这意味着新实体(也称为词汇外标记)可以进行矢量化定位，并且只有在重复整个训练过程的情况下才能进行定位。</p><p id="676c" class="pw-post-body-paragraph mh mi it mj b mk nc kd mm mn nd kg mp mq ne ms mt mu nf mw mx my ng na nb ln im bi translated">出于这些原因，我认为这个工具更像一个索引器，有助于品牌在用户群中发现相似的实例。一个例子是，当在社区中寻找有影响的人时，品牌经理可能有一个想法或认识一些用户，这可能是好的，但是，像这样的工具可以帮助经理在他们的社区中找到其他类似的用户，由于这种算法，这些用户已经被索引。</p></div><div class="ab cl pe pf hx pg" role="separator"><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj"/></div><div class="im in io ip iq"><pre class="ks kt ku kv gt ou ny ov ow aw ox bi"><span id="47bb" class="oy lq it ny b gy oz pa l pb pc"><strong class="ny jd">I have a newsletter 📩.</strong> </span><span id="f4bc" class="oy lq it ny b gy pl pa l pb pc">Every week I’ll send you a brief findings of articles, links, tutorials, and cool things that caught my attention. If tis sounds cool to you subscribe. </span><span id="74f3" class="oy lq it ny b gy pl pa l pb pc"><em class="pm">That means </em><strong class="ny jd"><em class="pm">a lot</em></strong><em class="pm"> for me.</em></span></pre><div class="pn po gp gr pp pq"><a href="https://relentless-creator-2481.ck.page/68d9def351" rel="noopener  ugc nofollow" target="_blank"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd jd gy z fp pv fr fs pw fu fw jc bi translated">5-bullet数据科学与技术📡</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">编辑描述</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">无情-创造者-2481.ck.page</p></div></div></div></a></div></div></div>    
</body>
</html>