<html>
<head>
<title>Making deep learning your artist with Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用风格转移让深度学习成为你的艺术家</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/making-deep-learning-your-artist-with-style-transfer-4854055f79b7?source=collection_archive---------42-----------------------#2020-11-13">https://towardsdatascience.com/making-deep-learning-your-artist-with-style-transfer-4854055f79b7?source=collection_archive---------42-----------------------#2020-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="f07f" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">"风格是我们每个人已经拥有的东西，我们需要做的只是找到它."— <strong class="jt ir">黛安·冯·芙丝汀宝</strong></p></blockquote><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/c4f695fb492cc76e7e2d251ea975998e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uaone_m1FHesQ8Rk"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">由<a class="ae lf" href="https://unsplash.com/@alienwannabe?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马修·科莫伊</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="083a" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">为了用CNN对图像进行分类，我们需要首先提取特征，然后将这些特征输入到我们的分类器中。这些特征不仅有助于分类，也有助于图像重建，并且是风格转移和<a class="ae lf" href="https://en.wikipedia.org/wiki/DeepDream" rel="noopener ugc nofollow" target="_blank">深度梦境</a>的基础。由深度卷积神经网络的进步所驱动的计算机视觉算法已经能够提取图像的纹理、边缘、颜色和其他更高级的特征，并将这些特征融合到另一幅图像中。这个过程就是我们所说的风格转换。</p><p id="e878" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated"><a class="ae lf" href="https://www.tensorflow.org/tutorials/generative/style_transfer" rel="noopener ugc nofollow" target="_blank"> Tensorflow page </a>将样式转移定义为:“神经样式转移是一种优化技术，用于获取两个图像——一个<em class="js">内容</em>图像和一个<em class="js">样式参考</em>图像(如著名画家的作品)——并将它们混合在一起，以便输出图像看起来像内容图像，但以样式参考图像的样式“绘制”</p><h1 id="b637" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">CNN和Images背景下的内容和风格是什么？</h1><p id="3c7e" class="pw-post-body-paragraph jq jr iq jt b ju mh jw jx jy mi ka kb lg mj ke kf lh mk ki kj li ml km kn ko ij bi translated">如果我们有几层CNN堆叠在一起，随着我们在网络中深入，我们的CNN学会从图像中提取更复杂的特征，并在池层的帮助下丢弃那些对我们的图像分类无用的噪声。因此，我们在CNN网络中的图像的最后一层将理想地表示图像的内容，其中像像素颜色和纹理这样的细节已经被移除，并且我们留下了表示对象以及它在输入图像中如何排列的高级内容。换句话说，网络较高层中的特征表示被称为内容表示</p><p id="f546" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">图像中的样式代表了图像中的纹理、颜色和曲率。风格转移的目的是分离出艺术形象的风格(风格形象)，并将其与内容形象融合或适应，以产生一种新的形象，称为目标形象。</p><h1 id="76cd" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">我们如何隔离内容和风格？</h1><p id="f6d3" class="pw-post-body-paragraph jq jr iq jt b ju mh jw jx jy mi ka kb lg mj ke kf lh mk ki kj li ml km kn ko ij bi translated">这篇文章将描述2014年CVPR题为“使用卷积神经网络的图像风格转换”的论文中使用的方法</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/e71e463033a7afe8f7e508ac03404a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*U6_b8aNUtOgdkRlP3b9Vpg.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">VGG19架构(<a class="ae lf" href="https://www.researchgate.net/publication/325137356_Breast_cancer_screening_using_convolutional_neural_network_and_follow-up_digital_mammography" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="6ebe" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">仔细观察上面的网络，可以看到它是由5个由最大汇集层分隔的2或4个卷积层堆叠而成。每个堆叠中的层的深度是标准值，但是深度随着堆叠从64增加到512。网络通常接受彩色图像。在我们的例子中，彩色图像是内容图像、风格图像和目标图像。本文利用了来自<strong class="jt ir"> conv4_2层的特征响应。</strong>可以使用任何更深的层，并且仍然获得一些好的结果。该算法的目标之一是最小化内容表示和我们想要产生的实际新艺术图像之间的差异。也就是说，新样式的图像(目标表示)和原始内容图像彼此非常接近，网络几乎会将它们视为同一图像。损失被表示为内容表示和目标表示的平均差。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/42eea33a311b1660425be580bcc87f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*WDPlHy4aj5ImmfT40Oa5JA.png"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/537c17a21ad11b64f87c67bd1bfcdcff.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*tW6GysrNknv1H5qnVmMb9g.png"/></div></figure><p id="71a0" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">由于我们使用预训练的VGG19网络，我们不需要进行任何训练来提取特征。我们只需要将内容和目标图像输入到网络优化中，使得它们之间的平均差异尽可能地接近。应该注意，我们的内容图像的内容表示没有改变。然而，目标图像的内容表示将继续改变，直到内容损失被最小化。</p><p id="33d7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">表示图像的样式有点复杂，但和前面讨论的内容表示一样简单。</p><p id="83f9" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">通过计算每一层的相关性(相似性)来找到风格表示？每一层的相关性由一个<a class="ae lf" href="https://en.wikipedia.org/wiki/Gramian_matrix" rel="noopener ugc nofollow" target="_blank"> Gram矩阵给出。</a>让我们记住最大池层的工作是丢弃每个连续层的样式。因此，我们在丢弃发生之前获取特征图。</p><h2 id="dcdf" class="mp lk iq bd ll mq mr dn lp ms mt dp lt lg mu mv lx lh mw mx mb li my mz mf na bi translated"><strong class="ak">如何求克矩阵</strong></h2><p id="9630" class="pw-post-body-paragraph jq jr iq jt b ju mh jw jx jy mi ka kb lg mj ke kf lh mk ki kj li ml km kn ko ij bi translated">让我们举一个例子，我们有一个8*8的图像与20个特征图或内核卷积。结果输出将是20*8*8。这意味着我们有20个特征图，我们想找到它们之间的相关性。为了找到这种相关性，我们首先需要对该特征图中的值进行矢量化(或多或少地将20*8*8的3维重新成形为2维)。因为我们有20个8*8的向量，所以我们展平8*8图像的x和y维度，以给出1*64的长度，其现在表示特征地图。堆叠20行1*64的特征地图将得到20*64的特征地图。现在，通过将20*64特征图与其转置相乘来给出gram矩阵，以给出20*20矩阵，该矩阵是我们的特征图的非局部化信息，其在正交空间中是不相关的。从上面我们可以看出，Gram矩阵的维数只是一个平方矩阵，其维数是特征图的数目，并且不依赖于输入图像的维数。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="0edf" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">Gram矩阵的x行和y列简单地表示了图层中第x个和第y个特征图之间的相关性。由此，gram矩阵的对角线将简单地具有相关值1，因为在这种情况下，我们正在寻找特征图和它本身之间的相似性。</p><p id="3df4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">风格损失简单地被给定为我们的风格图像和目标图像的gram矩阵之间的均方差之和。目标是最小化这种差异。再次，表示样式图像的样式表示的样式图像的gram矩阵不变。然而，目标图像的样式表示将继续改变，直到目标被最小化。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/2cf4661dae44741ed73030b2e21bdf11.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*k4Qx_DG5xgNbb59XqB_j8w.png"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/fee2e1913ca13bcc80bdc1f1fdf96078.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*8rujyayGgeC56wpV3tCqoQ.png"/></div></figure><p id="b0b1" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">每层中的权重w是给出某种偏好的值(根据层的不同，权重更大或更小)</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/5d83327f062ccd2cad9a6a19abbcd064.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*kjeY6-KVRPGNMgTzLZq5Iw.png"/></div></figure><p id="ec54" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">上面给出的总损失函数是样式损失和内容损失的权重之和。但是，这两种损失的计算方式不同，大小也不同。因此，内容损失可能会对我们的目标图像产生更大的影响，我们希望确保这两种损失对最终目标图像的影响几乎相等。α和β在原始论文中被引入作为权重，用于使总权重显示内容损失和风格损失之间的平衡。实际上，β值总是比α值大。α-β比率越低，我们的最终目标图像将越有风格，因为这意味着在这种情况下β具有非常高的幅度。因此，Alpha和beta是超参数，我们可以根据图像的类型和我们想要的结果输出风格来调整和选择。</p><p id="1e26" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">对于本文中给出的例子，选择α为1，β为0.00001。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ng"><img src="../Images/9f2b5d25fb03214b558c2d9a2b90e353.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JFtWn8SN2pfbnVMOEiSq-w.png"/></div></div></figure><h2 id="ad3d" class="mp lk iq bd ll mq mr dn lp ms mt dp lt lg mu mv lx lh mw mx mb li my mz mf na bi translated">初始化目标图像</h2><p id="26ff" class="pw-post-body-paragraph jq jr iq jt b ju mh jw jx jy mi ka kb lg mj ke kf lh mk ki kj li ml km kn ko ij bi translated">再次需要注意的是，目标形象是我们想要产生的新的艺术形象。我们可以使用任何随机噪声值来初始化图像，或者使其成为恒定的彩色图像或具有0的行和列的黑色图像，或者具有1的行和列的白色图像。在这项工作中，目标映像已经用内容映像的副本进行了初始化。</p><h1 id="c221" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">一些结果</h1><p id="d018" class="pw-post-body-paragraph jq jr iq jt b ju mh jw jx jy mi ka kb lg mj ke kf lh mk ki kj li ml km kn ko ij bi translated">下面的结果显示了我们试图实现最小化目标时的优化过程示例。我们会看到，如下图所示，这种风格正在逐渐被学习并在内容图像上进行调整。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nh"><img src="../Images/f06d5e1bfbe73dd2d5181d531db72530.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yrfBPeHjY9Qw_MSKQ5MbmQ.png"/></div></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nh"><img src="../Images/055b1f0cd3f7dfdaae5ef7651e9b52d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Pct2Jwt5TyMBpScA_0SVA.png"/></div></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nh"><img src="../Images/225b62f37b573989fe824995eb9605b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HPZt-M122eOHwbz10sK4Mw.png"/></div></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nh"><img src="../Images/02b9371fcf99e607c36ee4c96a71d184.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iJofuLWDhcBNUhcPibEghw.png"/></div></div></figure><p id="d7bd" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">最终的样式图像如下所示:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ni"><img src="../Images/99c75363d33455df2c9221ae7852ac87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JJAWZYDnsrhbCEspQCyZBw.png"/></div></div></figure><p id="ac1d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lg kd ke kf lh kh ki kj li kl km kn ko ij bi translated">用于这项工作的代码可以在<a class="ae lf" href="https://github.com/jimohafeezco/style_transfer" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h2 id="ba98" class="mp lk iq bd ll mq mr dn lp ms mt dp lt lg mu mv lx lh mw mx mb li my mz mf na bi translated">最后一点:风格转移的应用</h2><ul class=""><li id="601c" class="nq nr iq jt b ju mh jy mi lg ns lh nt li nu ko nv nw nx ny bi translated">照片和视频编辑:我实际上已经使用了几个移动应用程序将样式应用到我的图像中，事实上，深度学习原理在这里很方便，它让我们了解后台可能发生的事情。</li><li id="4ecd" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko nv nw nx ny bi translated">商业艺术:<a class="ae lf" href="https://dl.acm.org/doi/abs/10.1145/2897824.2925968" rel="noopener ugc nofollow" target="_blank">这里</a>是另一篇有用的论文，题为“使用卷积神经网络的头像绘画风格转换”</li><li id="6f76" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko nv nw nx ny bi translated">游戏:你会发现<a class="ae lf" href="https://www.youtube.com/watch?v=K4610QkRCnI" rel="noopener ugc nofollow" target="_blank">这个视频</a>很有趣，视频游戏看起来像另一个有风格转移的游戏。这里是另一个引人入胜的<a class="ae lf" href="https://www.youtube.com/watch?v=yF1bZiH-wJQ" rel="noopener ugc nofollow" target="_blank">视频</a>及其<a class="ae lf" href="https://twinfinite.net/2019/03/google-stadia-action-demo-videos/" rel="noopener ugc nofollow" target="_blank">文章</a>。</li><li id="9bac" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko nv nw nx ny bi translated">虚拟现实:这是一份报告的参考文献<a class="ae lf" href="http://stanford.edu/class/ee267/Spring2018/report_lei_castillo.pdf" rel="noopener ugc nofollow" target="_blank"/>,展示了它在虚拟现实中的应用</li></ul></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><h2 id="9de8" class="mp lk iq bd ll mq mr dn lp ms mt dp lt lg mu mv lx lh mw mx mb li my mz mf na bi translated">参考</h2><ol class=""><li id="bb6c" class="nq nr iq jt b ju mh jy mi lg ns lh nt li nu ko oe nw nx ny bi translated">Gatys、Leon A .、Alexander S. Ecker和Matthias Bethge。"使用卷积神经网络的图像风格转换."<em class="js">IEEE计算机视觉和模式识别会议论文集</em>。2016.</li><li id="c21f" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko oe nw nx ny bi translated">Tensorflow关于风格传递的文档:<a class="ae lf" href="https://www.tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/hub/tutorials/tf2 _ arbitrary _ image _ stylization</a></li><li id="b459" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko oe nw nx ny bi translated">郑，于峰，Clifford Yang和Alex Merkulov。“使用卷积神经网络和后续数字乳腺摄影进行乳腺癌筛查。”<em class="js">计算成像III </em>。第10669卷。国际光学与光子学会，2018。</li><li id="ed31" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko oe nw nx ny bi translated">用神经网络风格转移让《我的世界》看起来像其他游戏:<a class="ae lf" href="https://www.youtube.com/watch?v=K4610QkRCnI" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=K4610QkRCnI</a></li><li id="739e" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko oe nw nx ny bi translated">EE267虚拟现实，2018春季Style Transfer for VR:<a class="ae lf" href="http://stanford.edu/class/ee267/Spring2018/report_lei_castillo.pdf" rel="noopener ugc nofollow" target="_blank">http://Stanford . edu/class/ee 267/Spring 2018/report _ lei _ Castillo . pdf</a></li><li id="e70b" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko oe nw nx ny bi translated">Google Stadia-Style Transfer ML演示:【https://www.youtube.com/watch?v=yF1bZiH-wJQ T4】</li><li id="63aa" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko oe nw nx ny bi translated">观看令人印象深刻的演示视频中的谷歌Stadia将于2019年推出:<a class="ae lf" href="https://twinfinite.net/2019/03/google-stadia-action-demo-videos/" rel="noopener ugc nofollow" target="_blank">https://twin finite . net/2019/03/Google-stadia-action-demo-videos/</a></li><li id="01f4" class="nq nr iq jt b ju nz jy oa lg ob lh oc li od ko oe nw nx ny bi translated">使用卷积神经网络的头像绘画风格转换:<a class="ae lf" href="https://dl.acm.org/doi/abs/10.1145/2897824.2925968" rel="noopener ugc nofollow" target="_blank">https://dl.acm.org/doi/abs/10.1145/2897824.2925968</a></li></ol></div></div>    
</body>
</html>