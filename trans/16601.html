<html>
<head>
<title>Importing 100M+ Records into DynamoDB in Under 30 Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在30分钟内将1亿多条记录导入DynamoDB</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dynamo-exports-may-get-your-data-out-but-this-is-still-the-fastest-way-to-move-data-in-5bcd9748cc00?source=collection_archive---------2-----------------------#2020-11-16">https://towardsdatascience.com/dynamo-exports-may-get-your-data-out-but-this-is-still-the-fastest-way-to-move-data-in-5bcd9748cc00?source=collection_archive---------2-----------------------#2020-11-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1b20" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">AWS上周发布了一个新功能，只需点击几下就可以导出一个完整的Dynamo表，但了解如何用任何规模的数据来水合一个表也是值得的。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/19ba8a9d43bbd28aa72854b0a9830b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1kxaQsDlI8xWj8HW_8OxUA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">杰瑞米·毕晓普在<a class="ae ky" href="https://unsplash.com/s/photos/background?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="5e7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在设置将DynamoDB表<a class="ae ky" href="https://aws.amazon.com/about-aws/whats-new/2020/11/now-you-can-export-your-amazon-dynamodb-table-data-to-your-data-lake-in-amazon-s3-to-perform-analytics-at-any-scale/" rel="noopener ugc nofollow" target="_blank">完全导出</a>到S3的过程中，任何人都不会受到影响。</p><p id="1a89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，对于希望将数据导入Dynamo表的人来说，情况就不一样了。尤其是数据量大且速度快。</p><p id="f2c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当表中的记录损坏时，可能需要快速大容量导入，修复它们的最简单方法是删除并重新创建整个表。或者在将数据流式传输到表中时，运行夜间批处理“校正”作业来纠正可能已经发生的任何日间异常是很有用的。</p><p id="7930" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将这些类型作业的完成时间从一个多小时缩短到不到一分钟，让您对任何给定时间点的数据状态更有信心。它为在您的数据上构建低潜在应用程序提供了更稳定的基础。</p><h1 id="7329" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">简单的写作方式</h1><p id="cc77" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">假设我们在A点的S3存储桶中有数据，我们想把它移到B点的发电机表中…我们如何做呢？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/6d8a633a92755d3c37acd55d90831601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8WwqGgvAWdngrXzvKa39qg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将数据从S3转移到迪纳摩就像从A点转移到B点一样简单！|作者图片</p></figure><p id="1f0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最简单的方法是编写一个小脚本，将文件读入DataFrame对象，遍历该对象的行，然后执行一个<code class="fe mt mu mv mw b">dynamo.Table().batch_writer().put_item()</code>操作将项目插入到表中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="d78a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在500k行数据帧上运行此脚本会产生以下写入性能:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/7d3565d646a5827db205aab3d6c14983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PnqgkmhHDpbaRohyQwroLQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单线程发电机写进程的性能。|作者图片</p></figure><p id="a755" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，每秒对表的写入次数(w/s)的上限约为650 w/s。Amazon指出，对Dynamo的单个进程写入的真正限制是1，000 w/s，但是由于网络和其他开销，观察到的值更低(从我的笔记本电脑本地运行)。</p><p id="2fe5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于500，000条记录，将所有记录插入表中大约需要15分钟。根据您的使用情况，这可能是可以接受的。但是对于大型数据集的大容量插入—比如1亿行(！)—很明显，提高写吞吐率会有所帮助。</p><p id="d18a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们能做得更好吗？</p><h1 id="9324" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">达到发电机的速度极限</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/a566c0c5afc293e262d2dc369d725a4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NHY_SQo4L0eKrYs3uxjAYg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@kvedula?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">卡梅什·维杜拉</a>在<a class="ae ky" href="https://unsplash.com/s/photos/black-hole?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="547f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了提高写性能，显然需要不止一个进程向表中写入数据。那么，我们如何让多个进程并行写入呢？</p><p id="68db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我发现实现这个的最优雅的方法是同时调用多个Lambda函数编写器实例<strong class="lb iu"/>。每一个都拾取数据集的一部分，并将其并行写入Dynamo表。</p><p id="c5fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其工作方式是通过设置一个Lambda函数来触发SQS队列。这意味着如果一条消息被放入队列，Lambda函数将调用并执行它的代码——将SQS消息值作为函数输入参数。</p><p id="9546" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更进一步——如果这样一个Lambda包含类似上面的<code class="fe mt mu mv mw b">simple_dynamo_write.py </code>片段中的代码，并且放在队列中的消息是指向我们想要写入的数据的S3文件路径指针，那么应该清楚这些数据将如何进入Dynamo！</p><p id="1004" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个Lambda实例将以750到1000 w/s的速度写入表，因此一旦我们同时执行多个实例，我们就可以实现更高的写入速度！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/52aaba8a0025e22beed2666ba459f595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jn2enW0u2SequhXaL4GeMQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">更新了A到B架构。|作者图片</p></figure><p id="3845" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">诀窍是以一种Lambda可以高效无误地处理数据的方式来拆分和组织数据。AWS对可以同时调用多少个Lambda(1000)、单个Lambda调用在关闭前可以运行多长时间(15分钟)以及单个 Dynamo表每秒可以处理多少个<a class="ae ky" href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html" rel="noopener ugc nofollow" target="_blank">写操作(40000)都有限制</a><a class="ae ky" href="https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="f385" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nc">在使用服务时，知道相关的配额总是明智的，通常AWS在记录和提供这些信息方面做得很好。</em></p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="ab5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑到这些限制，应该清楚的是，在完全并行化的情况下，我们不能将数据集分布到超过1000个SQS消息中，否则我们将达到1000个并发Lambda调用的限制。</p><p id="234f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个文件也不能太大，否则Lambda将需要超过15分钟才能把它写到表中(提醒一下，之前写一个500，000行的文件需要将近15分钟)。Lambda关闭中间文件并不好，因为如果不重新处理整个文件，就无法保证所有行都被写入。</p><p id="0161" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">控制所有这些因素的方法是创建最多40条SQS消息，由数据的S3文件路径的逗号分隔字符串组成。</strong></p><p id="4fdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果我们在S3有3个文件要写入Dynamo，我们可以创建一个SQS消息，如下所示:</p><pre class="kj kk kl km gt nk mw nl nm aw nn bi"><span id="5bd9" class="no lw it mw b gy np nq l nr ns">'s3://bucket/file1.csv,s3://bucket/file2.csv,s3://bucket/file3.csv'</span></pre><p id="59bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将此消息作为输入，Lambda所做的是:</p><ol class=""><li id="febe" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated">从输入字符串中弹出最后一个文件路径。</li><li id="b4fa" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">将文件数据写入Dynamo表。</li><li id="0246" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">在SQS队列上创建一个新消息，该消息在只剩下未处理的文件的情况下触发自身。</li></ol><p id="3681" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以在编写完一个文件后，创建的新SQS消息将如下所示，关键是Lambda函数的一个新实例将几乎立即调用以开始处理<code class="fe mt mu mv mw b">file2</code>。</p><pre class="kj kk kl km gt nk mw nl nm aw nn bi"><span id="f290" class="no lw it mw b gy np nq l nr ns">'s3://bucket/file1.csv,s3://bucket/file2.csv'</span></pre><p id="d3f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦<code class="fe mt mu mv mw b">file2</code>得到处理，一个新的SQS消息将被放入队列:</p><pre class="kj kk kl km gt nk mw nl nm aw nn bi"><span id="dcc2" class="no lw it mw b gy np nq l nr ns">'s3://bucket/file1.csv'</span></pre><p id="b01f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在写入<code class="fe mt mu mv mw b">file1</code>之后，不再生成队列消息，不再调用Lambdas，也不再有数据不在Dynamo表中！</p><p id="890f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了更形象地展示这种递归策略，下面是一个Lambda函数代码示例:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="db5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您将看到更多令人兴奋的视觉效果，而不是有限的写容量指标图！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/d040559cd0775344edac9c9b532960da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*cXlH70hagjqlRSQio7AI3A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">达到每秒75，000次写入！|作者图片</p></figure><h1 id="886d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">包扎</h1><p id="3e68" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">使用这种架构，我们可以实现每秒向Dynamo写入高达40k的速度，因为最多可以并行运行40个进程，每个进程每秒写入1k行。</p><p id="eb1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以前，100M行的数据集在1，000 w/s的速度下需要40个小时，而在提高的速度下，我们只需40分钟就可以导入完整的数据集！(<em class="nc">顺便说一句，Dynamo表上的40k最大写入速度限制只是AWS的默认设置，可以根据要求增加</em>)。</p><p id="fc7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在使用Dynamo作为几个数据密集型应用程序的后端时，我发现以这种方式快速刷新整个数据集的能力非常有用。在特定行可能已损坏或被错误处理的情况下，修复数据的更多外科手术方法可能容易出错且耗时，因此不推荐使用。</p><p id="09b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，还有几个其他因素我没有机会在本文中涉及，比如对Dynamo Capacity模式的理想处理，以及Dynamo流等相关流程是如何受到影响的。</p><p id="365b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你对这些感到好奇，可以在下面的评论中提问或者在<a class="ae ky" href="https://twitter.com/home" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上联系。</p><p id="2124" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢莱恩·凯利和迈克尔·彼得雷辛为本文提供灵感。</p><h2 id="f241" class="no lw it bd lx oi oj dn mb ok ol dp mf li om on mh lm oo op mj lq oq or ml os bi translated">更多来自保罗·辛格曼</h2><div class="ot ou gp gr ov ow"><a href="https://medium.com/whispering-data/transcribe-your-zoom-meetings-for-free-with-aws-963f39a2aa3f" rel="noopener follow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">使用AWS免费转录您的Zoom会议！</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">如果你同意“最模糊的墨迹比最强的记忆更强大”，那么你应该知道如何便宜地…</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">medium.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk ks ow"/></div></div></a></div><div class="ot ou gp gr ov ow"><a href="https://medium.com/whispering-data/tackling-fragmentation-in-serverless-data-pipelines-b4027f506ee5" rel="noopener follow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">解决无服务器数据管道中的碎片问题</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">如何在管理数十到数百个lambda支持的存储库时保持理智…</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">medium.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk ks ow"/></div></div></a></div></div></div>    
</body>
</html>