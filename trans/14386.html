<html>
<head>
<title>Learning To Differentiate using Deep Metric Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度度量学习来学习区分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-metric-learning-76fa0a5a415f?source=collection_archive---------11-----------------------#2020-10-04">https://towardsdatascience.com/deep-metric-learning-76fa0a5a415f?source=collection_archive---------11-----------------------#2020-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="6c41" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated">最近，计算机视觉算法为使用卷积神经网络(CNN)开发非常高效的视觉搜索工作流做出了巨大贡献。由于近来数据量已经增加，对象识别模型能够识别对象并按比例概括图像特征。然而，在一个具有挑战性的分类设置中，类别的数量是巨大的，有几个约束需要解决，以设计有效的视觉搜索工作流。</p><ul class=""><li id="e059" class="ku kv iq jp b jq jr ju jv jy kw kc kx kg ky kk kz la lb lc bi translated">对象类别数量的增加也增加了CNN倒数第二层的权重数量。这使得很难在设备上部署它们，因为它们最终也会增加<em class="ld">型号的大小</em>。</li><li id="9e78" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk kz la lb lc bi translated">当每类只有<em class="ld">个图像时，很难实现更好的收敛，从而很难在各种光照差异、对象比例、背景、遮挡等情况下实现良好的性能。</em></li><li id="7c91" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk kz la lb lc bi translated">在工程空间中，通常需要设计适应产品生态系统的视觉搜索工作流，该产品生态系统包含不稳定的产品，或者根据季节趋势或地理位置而变化。这种情况使得以<em class="ld">循环</em>(特定时间间隔后的训练)或<em class="ld">在线</em>(实时数据训练)的方式训练/微调模型变得棘手。</li></ul><h1 id="8583" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">深度度量学习</h1><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/74f0e753d79214e5154f68f54a570415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aJ4anPtLNTXydg5KjylfkQ.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图1给定椅子和桌子的两幅图像，度量学习的思想是使用适当的距离度量来量化图像的相似性。当我们的目标是区分对象而不是识别它们时，这在很大程度上提高了模型的可扩展性，因为我们不再依赖于给定图像所属的类别。</p></figure><p id="ef11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了缓解这些问题，深度学习和度量学习共同形成了深度度量学习(DML)的概念，也称为距离度量学习。它提出训练基于CNN的非线性特征提取模块(或编码器)，该模块将语义相似的提取的图像特征嵌入(也称为嵌入)到附近的位置，同时使用适当的距离度量(例如欧几里德或余弦距离)将不相似的图像特征推开。与判别分类算法(如K-最近邻、支持向量机和朴素贝叶斯)一起，我们可以使用提取的图像特征执行对象识别任务，而不受类别数量的限制。注意，这种经过训练的CNN模块的辨别能力描述了具有紧凑的类内变化和可分离的类间差异的特征。这些特征也足够一般化，甚至可以用来区分新的看不见的类。在下一节中，我们将使用基于<em class="ld">对</em>的训练范例来形式化训练和评估用于DML的CNN的过程。</p><h2 id="dd85" class="mx lk iq bd ll my mz dn lp na nb dp lt jy nc nd lx kc ne nf mb kg ng nh mf ni bi translated">形式主义</h2><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nj"><img src="../Images/06ae95f8b2b7956002acedbed9f3f0dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c_xrqunnWDMFOl0nZDwGlA.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图2是使用CNN提取的示例图像xᵢ和特征嵌入向量f(xᵢ。</p></figure><p id="cd12" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">设X = {(xᵢ，yᵢ)} <em class="ld">，</em>I∈<em class="ld"/>【1，2，… n】为n幅图像的数据集，其中(xᵢ，yᵢ)建议iᵗʰ图像及其对应的类别标签。数据集中存在的类的总数为c，即yᵢ ∈ [1，2，… C]。让我们考虑f(xᵢ)一个特征向量(或者一个嵌入)对应一个图像xᵢ ∈ Rᴰ，其中f: Rᴰ→Rᵈ是一个参数为θ的可微深度网络。这里，<em class="ld"> D </em>和<em class="ld"> d </em>分别指原始图像尺寸和特征尺寸。形式上，我们将两个图像特征之间的欧几里德距离定义为Dᵢⱼ = ||f(xᵢ) — f(xⱼ)||，这是分别对应于图像xᵢ和xⱼ的深层特征f(xᵢ)和f(xⱼ)之间的距离。注意，尽管我们在这里关注欧几里德距离，但是在文献中有几个其他度量经常用于优化嵌入空间。我们将在以后的文章中讨论这个问题。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nk"><img src="../Images/d4070b150da192a3f77cd94a007f0f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*314bOHqAyFeX_IYSLsuxug.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图三。<strong class="bd nl">相对相似性约束</strong> : R = {(xᵢ、xⱼ、xₖ): xᵢ比xₖ}.更像xⱼdᵢⱼdᵢₖ+α&gt;0量化了一对锚正图像和锚负图像之间的相似性。三重损失、N对损失、提升结构、代理NCA损失是使用相对相似性约束的一些损失函数。<strong class="bd nl">绝对相似性约束</strong> : S = {(xᵢ，xⱼ) : xᵢ和xⱼ相似}，D = {(xᵢ，xₖ) : xᵢ和xₖ不相似}。Dᵢⱼ和Dᵢₖ量化了分别共享相似和不相似类别标签的一对正图像和一对负图像的相似性和不相似性的度量。对比丢失和排序列表丢失使用该约束来学习距离度量。</p></figure><p id="a55e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了学习距离度量函数<em class="ld"> f </em>，大多数DML算法使用相对相似性或绝对相似性约束，使用如图2和图3所示的一对或三对碱基方法。图像的三元组可以定义为(f(xᵢ)、f(xⱼ)、f(xₖ)，其中f(xᵢ)、f(xⱼ)和f(xₖ)分别对应于主播xᵢ、正面xⱼ和负面图像x⃈的特征向量。xᵢ和xⱼ有着相似的阶级标签，而xₖ有着不同于锚和正面形象的阶级标签。一对图像特征对应一个图像pair(xᵢ,xⱼ)，定义为(f(xᵢ),f(xⱼ)).如果两幅图像共享相似的标签，则称为正对，否则称为负对。<br/>训练端到端DML模型的整个过程可以总结为如图4所示。最初，为了得到聚类不均匀性的概念，对一批图像进行采样。每批包含对象类P，每个类有Q个图像。我们使用下面讨论的取样策略，用这个批次形成一个或多个小批次。这些小批量用于计算损失并通过反向传播进行训练。让我们总结一下使用DML损失函数训练深度学习模型的训练过程。稍后，我们将讨论这个框架的几个重要的训练组件，采样和损失函数。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nm"><img src="../Images/6b7ae632cda18b9f4bde5ea02b3e6bf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*meKSezQ59UspwYTf0k2rIQ.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图4。DML的培训程序</p></figure><h2 id="9586" class="mx lk iq bd ll my mz dn lp na nb dp lt jy nc nd lx kc ne nf mb kg ng nh mf ni bi translated">培训程序</h2><p id="06a0" class="pw-post-body-paragraph jn jo iq jp b jq nn js jt ju no jw jx jy np ka kb kc nq ke kf kg nr ki kj kk ij bi translated">1.批量抽样:批量B，类别数P，每个类别的图像数q。输入:嵌入函数f(即预先训练的CNN的Imagenet数据集)、学习速率B、批量B和图像类别数量P、一批中的图像总数B = PQ <br/> 3。特征提取:给定参数状态θₜ，使用CNN前馈所有批次图像，获得图像嵌入f( <em class="ld"> xᵢ </em>)。<br/> 4。抽样:从批量中进行小批量计算。根据批次的大小，可以形成对应于步骤1中采样的图像的一个或多个小批次的特征向量。<br/> 5。损失计算和训练:对于每个小批量计算梯度和反向传播，以更新从θₜ到θₜ₊₁.的参数状态</p><h2 id="fbd3" class="mx lk iq bd ll my mz dn lp na nb dp lt jy nc nd lx kc ne nf mb kg ng nh mf ni bi translated">度量学习损失函数</h2><p id="feb1" class="pw-post-body-paragraph jn jo iq jp b jq nn js jt ju no jw jx jy np ka kb kc nq ke kf kg nr ki kj kk ij bi translated">当我们使用卷积神经网络来识别目标时，Softmax交叉熵(CE)损失函数是最常见的选择。然而，当插入这个损失函数来学习DML模型时，有一些必须考虑的事项。</p><ul class=""><li id="5b39" class="ku kv iq jp b jq jr ju jv jy kw kc kx kg ky kk kz la lb lc bi translated">Softmax交叉熵(CE)损失被视为<em class="ld"> max </em>算子的软版本。如果使用恒定缩放因子<em class="ld"> s、</em>来缩放，则Logit向量或类别概率不会影响给定图像的类别分配。结果，分离良好的特征拥有更大的量级，并且它促进了类的可分离性。总之，如下图所示，它使特征分布呈“放射状”,并且使用鉴别特征学习算法(例如KNN分类器)对特征进行分类，关键是要有一个不仅可分离而且可鉴别的嵌入空间。度量学习损失函数被设计成学习有区别的特征空间。</li></ul><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ns"><img src="../Images/2208f384e2c632e036674466c87d83e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rZLtrVB4s3TmLGyvzLAG-w.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图5从为给定数据集训练的CNN的倒数第二层提取的特征模式，并投影到2D特征空间。左图:使用Softmax损失的2D特征分布。右图:使用DML损失函数的区别特征分布。</p></figure><ul class=""><li id="c470" class="ku kv iq jp b jq jr ju jv jy kw kc kx kg ky kk kz la lb lc bi translated">CE loss不直接利用小批量图像中样本的结构关系，因为每个图像(随机选择)单独负责计算损失数。通过引入解决图像之间语义差异的惩罚，具有区分一对或三组图像的训练范例有效地检查了图像之间的关系。</li></ul><p id="1d39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">认识到这些方面，研究团体已经提出了各种损失函数来使用DML学习区分特征空间。提升结构损失函数就是其中之一。</p><div class="nt nu gp gr nv nw"><a rel="noopener follow" target="_blank" href="/metric-learning-loss-functions-5b67b3da99a5"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd ir gy z fp ob fr fs oc fu fw ip bi translated">利用损失函数深入挖掘度量学习</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">关于度量学习损失函数的介绍性注释。</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">towardsdatascience.com</p></div></div><div class="of l"><div class="og l oh oi oj of ok mr nw"/></div></div></a></div><p id="c6e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">提升结构损失充分利用了小批量，改进了小批量随机梯度下降训练。一方面，三重损失或对比损失分别使用三重或一对图像来计算损失项，提升结构损失提出通过提升小批量(O(m))中可用的所有图像对来采用成对距离度量(O(m))。此外，与仅关于锚图像定义负样本的三重损失或对比损失相反，提升结构损失训练给定对、锚和正中的图像，以从小批量图像中找到它们的负样本。关于DML中使用的损失函数的更多信息，请参考上面的博文。提升结构损失的公式如下。</p><p id="1ba5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，<em class="ld"> (i，j) </em>表示对应于共享相似标签图像(xᵢ,xⱼ)的正图像对。Dᵢⱼ是一对图像之间的距离。Dᵢₖ和Dⱼₗ是迷你批次中从锚和正面到其余负面图像的距离。α是指距离余量。<strong class="jp ir"> <em class="ld"> P </em> </strong>和<strong class="jp ir"> <em class="ld"> N </em> </strong>分别是小批量可用的所有正负线对。</p><h2 id="f891" class="mx lk iq bd ll my mz dn lp na nb dp lt jy nc nd lx kc ne nf mb kg ng nh mf ni bi translated">抽样</h2><p id="a20c" class="pw-post-body-paragraph jn jo iq jp b jq nn js jt ju no jw jx jy np ka kb kc nq ke kf kg nr ki kj kk ij bi translated">诚然，直接作用于特征对之间的距离直观地引导我们向学习图像的有意义嵌入的目标前进。因此，标准交叉熵损失主要被DML社区忽略了。<br/>在DML训练机制中，我们分别使用一对或三对图像来使用绝对或相对相似性，在将图像馈送到CNN时，有意义地对图像批次进行采样是必要的。对于数据集，其中用于前馈图像的小批量比数据集中的类的总数大得多，随机馈送图像将保证大多数图像样本在小批量中将具有具有相似类标签的其他图像。但是，当我们考虑具有大量图像类的数据集时，例如，斯坦福在线产品数据集，其中图像类的数量接近22000，随机采样的小批量图像不一定包含共享相似标签的图像对。在这种情况下，尽管每个批次都遇到了类间变化(因为存在具有不同类标签的图像)，但是它未能解决类内变化(因为没有必要具有两个具有相似类标签的图像)，最终未能实现更好的收敛。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ol"><img src="../Images/137d3610c2f433940ee61971ff652cd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0u0pVSh_mmtrKhopbeFCCA.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图六。负类挖掘抽样</p></figure><p id="9cdd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然使用DML的训练需要对图像对或三元组进行采样，但是这种采样分别粗略地增加了O(m)或O(m)数量级的数据集大小。此外，如果图像对或图像对是随机采样的，随着训练的进行，大多数图像对或图像对以较小的方式起作用，因为不是所有的图像都违反了余量α(例如，在三个一组丢失的情况下)。很难计算有意义的损失，这不可避免地导致收敛缓慢。<br/>为了克服这些问题，有各种各样的采样策略，我们可以用来更快更好地收敛训练参数。</p><p id="5377" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">硬负数据挖掘策略在基于距离的度量学习算法中很常见。它包括计算硬的负面或正面特征实例，以形成给定锚例的正面或负面对。然而，当给定的批处理中涉及大量的类时，这个过程在计算上是具有挑战性的。在这样的场景中，可以方便地执行负的“<em class="ld">类</em>挖掘，而不是负的“<em class="ld">实例</em>挖掘。遵循下面的过程来为基于对的损失函数执行负“类”挖掘。</p><ol class=""><li id="efd6" class="ku kv iq jp b jq jr ju jv jy kw kc kx kg ky kk om la lb lc bi translated">为了具有给定参数状态θₜ的嵌入空间的有意义的表示，对包含几百个类(即上述训练过程中的p)的大批量图像进行采样。对于每个基于对的损失函数，对于给定批次中的每个给定类别，必须有至少两个示例图像。例如，在斯坦福在线产品数据集的情况下，必须随机采样至少2个图像(Q=2)。</li><li id="a991" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">对于给定CNN的给定参数状态θₜ，提取步骤1中采样的每个图像的特征向量。使用这些图像特征获得类别表示向量或类别代理(平均嵌入向量)。</li><li id="ef9a" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">对于从步骤1中采样的P个类别中随机选择的每个类别，我们对最近的类别进行采样，并对相应的图像重新排序，如上图5所示。这一步骤也可以使用基于边缘的类选择来执行，如果只有一个具有距离边缘的类被选择作为给定锚类的最近类。</li><li id="527f" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">根据计算能力，我们可以形成一个或多个小批量的特征向量，如图5所示，以计算损失和梯度。</li></ol><h2 id="ef07" class="mx lk iq bd ll my mz dn lp na nb dp lt jy nc nd lx kc ne nf mb kg ng nh mf ni bi translated">评估和推理</h2><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi on"><img src="../Images/967934d7228070e6ea223e24bbc59393.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*52blxPY9In_6UsQYeeCAxg.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图DML的推理过程。图像被馈送到网络以从瓶颈层获得特征向量。因为它们是用DML损失函数训练的，所以它们将创建区别特征嵌入空间，如图中2D所示。</p></figure><p id="de62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与传统的对象识别模型(其中图像被馈送以生成对象类别概率)相反，DML图像被馈送以提取图像特征。评估这些图像特征的聚类质量和检索性能。F1和归一化互信息(NMI)分数是标准的评估度量，我们用来估计聚类质量度量。对于检索，k处的召回率是我们在处理DML训练时使用的基准评估度量。为了本文的完整性，我们在这里总结了这些评估指标。</p><ul class=""><li id="1d95" class="ku kv iq jp b jq jr ju jv jy kw kc kx kg ky kk kz la lb lc bi translated"><em class="ld">在K </em>回忆:对于每个查询图像(来自测试数据集)，我们使用来自相同测试集的适当距离度量(欧几里德或余弦)检索K个最近邻。如果在检索到的K个最近邻居中存在来自相同类别的图像，则查询图像得到分数1。K值召回表示测试数据集中所有法师的召回次数。</li><li id="bc9f" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk kz la lb lc bi translated"><em class="ld"> F1 </em> : F1度量值定义为在K处测量的精度和召回率的调和平均值，即F1 = 2PR/(P+R)。</li><li id="671f" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk kz la lb lc bi translated"><em class="ld">归一化互信息</em> ( <em class="ld"> NMI </em>):对于一组输入聚类赋值ω和地面真实聚类ℂ，NMI得分是互信息与聚类平均熵和标签熵的比值。即NMI = I(ω；ℂ)/2(h(ω)+h(ℂ)).这里，ω={ω₁，ω₂ … ωₙ}，这是聚类的输入集，ℂ = {c₁，c₂，… cₙ}是基础真值类。具有聚类分配<em class="ld"> i </em>的示例被给定为ωᵢ，而具有基础真实类标签j的示例被定义为cᵢ.</li><li id="f5c4" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk kz la lb lc bi translated">K处的准确性:这个度量标准服务于我们的目标，即以无监督的方式使用这个训练过的模型作为对象识别模型。对于图像，使用适当的度量获得K个最近邻。查询图像被分配给在K个最近邻居中出现次数最多的类别。K处的准确度对测试数据集中的每个查询图像的准确度进行平均。</li></ul><h2 id="79f7" class="mx lk iq bd ll my mz dn lp na nb dp lt jy nc nd lx kc ne nf mb kg ng nh mf ni bi translated">结论</h2><p id="b577" class="pw-post-body-paragraph jn jo iq jp b jq nn js jt ju no jw jx jy np ka kb kc nq ke kf kg nr ki kj kk ij bi translated">我们描述了一种深度度量学习范式来解决对象识别问题。这种模型训练提供了如下几个优点。</p><ul class=""><li id="ac27" class="ku kv iq jp b jq jr ju jv jy kw kc kx kg ky kk kz la lb lc bi translated">它们不会增加<em class="ld">模型的大小</em>，因为我们总是可以使用相同的维度嵌入层来训练模型。</li><li id="5c4f" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk kz la lb lc bi translated">由于我们正在<em class="ld">学习区分和不识别</em>物体，我们可以利用这样一个范例，该范例可以使用各种采样策略以每类更少的图像来执行<em class="ld">训练，并且甚至可以推断对<em class="ld">不可见的</em>类的识别。</em></li><li id="41ea" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk kz la lb lc bi translated">以<em class="ld">循环</em>或<em class="ld">在线</em>的方式对一组较新的产品类别进行微调将会传播渐变。</li></ul><p id="72dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些属性使我们能够为给定的产品生态系统设计灵活且可扩展的可视化搜索工作流。此外，我们还描述了采样对于使用DML损失函数训练CNN的重要性。请跟进<a class="ae oo" rel="noopener" target="_blank" href="/metric-learning-loss-functions-5b67b3da99a5"> <em class="ld">这篇</em> </a>文章的附加损耗功能。随着近来这一领域的发展，我们也可以有效地练习一些其他的训练程序来达到同样的目的。我们将在以后的文章中讨论其中的一些。</p></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><h1 id="5a84" class="lj lk iq bd ll lm ow lo lp lq ox ls lt lu oy lw lx ly oz ma mb mc pa me mf mg bi translated">参考</h1><ol class=""><li id="5678" class="ku kv iq jp b jq nn ju no jy pb kc pc kg pd kk om la lb lc bi translated">王，x，华，y，柯迪洛夫，e，胡，g，卡尼尔，r .，&amp;罗伯逊，N. M. (2019)。深度度量学习的排序列表丢失。在<em class="ld">IEEE计算机视觉和模式识别会议论文集</em>(第5207–5216页)中。</li><li id="9248" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">movshowitz-Attias，y .，Toshev，a .，Leung，T. K .，Ioffe，s .，&amp; Singh，S. (2017)。没有大惊小怪的距离度量学习使用代理。IEEE计算机视觉国际会议论文集(第360–368页)。</li><li id="0e59" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">Ranjan，r .，Castillo，C. D .，&amp; Chellappa，R. (2017年)。用于鉴别性人脸验证的L2约束软最大损失。<em class="ld"> arXiv预印本arXiv:1703.09507 </em>。</li><li id="309e" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">2017年10月，王，项，程，陈建杰，尤妮尔。人脸验证的L2超球面嵌入。第25届ACM多媒体国际会议论文集(第1041–1049页)。</li><li id="4b44" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">Wu c . y .，Manmatha，r .，Smola，A. J .，&amp; Krahenbuhl，P. (2017年)。深度嵌入学习中的采样问题。在<em class="ld">IEEE计算机视觉国际会议论文集</em>(第2840-2848页)。</li><li id="9817" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">温，张，李，张，乔，(2016年10月)。一种用于深度人脸识别的鉴别特征学习方法。在<em class="ld">欧洲计算机视觉会议</em>(第499–515页)。斯普林格，查姆。</li><li id="9c8c" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">刘，张，罗，邱，王，唐，(2016)。Deepfashion:通过丰富的注释支持强大的服装识别和检索。在<em class="ld">IEEE计算机视觉和模式识别会议论文集</em>(第1096-1104页)。</li><li id="d47c" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">Oh Song，h .，Xiang，y .，Jegelka，s .，&amp; Savarese，S. (2016年)。基于提升结构特征嵌入的深度度量学习。在<em class="ld">IEEE计算机视觉和模式识别会议论文集</em>(第4004–4012页)。</li><li id="616d" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">Sohn，K. (2016年)。具有多类n对损失目标的改进深度度量学习。在<em class="ld">神经信息处理系统的进展</em>(第1857-1865页)。</li><li id="a0e1" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">Schroff，d . Kalenichenko和j . Phil bin(2015年)。Facenet:人脸识别和聚类的统一嵌入。IEEE计算机视觉和模式识别会议论文集<em class="ld">(第815–823页)。</em></li><li id="621b" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">Bellet，a .，Habrard，a .，和Sebban，M. (2013年)。特征向量和结构化数据的度量学习综述。<em class="ld"> arXiv:1306.6709 </em>。</li><li id="149f" class="ku kv iq jp b jq le ju lf jy lg kc lh kg li kk om la lb lc bi translated">哈德塞尔，r .，乔普拉，s .，&amp;勒村，Y. (2006年6月)。通过学习不变映射进行降维。在<em class="ld"> 2006年IEEE计算机学会计算机视觉和模式识别会议(CVPR’06)</em>(第2卷，第1735-1742页)。IEEE。芝加哥</li></ol></div></div>    
</body>
</html>