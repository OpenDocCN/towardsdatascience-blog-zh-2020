<html>
<head>
<title>Smart way to levitate Convolutional Neural Network’s performance: EfficientNet Google AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提升卷积神经网络性能的聪明方法:EfficientNet Google AI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/smart-way-to-levitate-convolutional-neural-networks-performance-efficientnet-google-ai-c87a1f67b084?source=collection_archive---------41-----------------------#2020-09-29">https://towardsdatascience.com/smart-way-to-levitate-convolutional-neural-networks-performance-efficientnet-google-ai-c87a1f67b084?source=collection_archive---------41-----------------------#2020-09-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/642a1ad24b382719205b5c94ba222d33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHogdcAAdpJdvnwH2N_87Q.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">照片由<a class="ae kf" href="https://unsplash.com/@alicia2joy?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Alicia Quan </a>在<a class="ae kf" href="https://unsplash.com/s/photos/marvel-black-panther?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="6fdc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">卷积神经网络(CNN)已经成为图像分类、目标检测和许多其他应用的首选模型。但是就像来自黑豹的T4·首里建议的那样，CNN必须被改进以提供更好的准确性来解决正在研究的问题</p><blockquote class="lf lg lh"><p id="b999" class="kg kh le ki b kj kk kl km kn ko kp kq li ks kt ku lj kw kx ky lk la lb lc ld im bi translated">"仅仅因为某些东西有效，并不意味着它不能被改进."—首里(<a class="ae kf" href="https://www.theedgesusu.co.uk/film/cinema/2018/02/15/review-black-panther/" rel="noopener ugc nofollow" target="_blank">黑豹</a>，2018)</p></blockquote><h1 id="ad42" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">传统方法</h1><p id="40b6" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">提高CNN性能的传统方式是通过增加<strong class="ki iu">深度学习模型</strong>的<strong class="ki iu">深度</strong>。这里的深度意味着在已经可用的深度卷积模型之间或之上添加额外的层。深度的增加可能会适得其反，因为它需要更多的计算能力和资源。此外，在一定深度之后，系统中的<a class="ae kf" href="https://docs.paperspace.com/machine-learning/wiki/weights-and-biases" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">权重</strong> </a> <strong class="ki iu"> </strong>趋向于<strong class="ki iu">饱和</strong>，而没有任何进一步的改进。</p><h1 id="e0f6" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">聪明的方法</h1><p id="aa12" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">为了解决上述问题，谷歌大脑团队提出了一个名为<strong class="ki iu"> EfficientNet </strong>的解决方案，该方案通过<strong class="ki iu">在所有方向</strong>上高效缩放来提高模型精度和计算需求，不仅包括<strong class="ki iu">深度</strong>，还包括<strong class="ki iu">宽度</strong>和<strong class="ki iu">分辨率</strong>。它理想地导致每个维度相对于另一个维度的最佳平衡。通过这种方式，EfficientNet不需要像CNN那样多的计算需求，从而获得更好的准确性</p><p id="f633" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们尝试围绕EfficientNet做一些因果分析，并理解普遍性的问题——为什么、在哪里以及这些深度神经网络是什么。</p><h1 id="3a3a" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">为什么选择高效网络？</h1><p id="b4a3" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">为了理解为什么我们在构建深度模型时要保持高效率，首先，让我们了解不同类型的<strong class="ki iu"> <em class="le">缩放方法</em> </strong>和<strong class="ki iu"> <em class="le">复合缩放</em> </strong>的实际含义</p><h2 id="6060" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">传统缩放方法:</h2><p id="7796" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated"><strong class="ki iu">宽度缩放:</strong>图像的宽度一般是指通道，就像彩色图像中的R、G、B。在这种缩放方法中，随着网络的增长，CNN模型会尝试添加更多的频道，使网络变宽。这些广域网络(例如WideResNet和MobileNets)在捕获高级特征方面存在困难</p><p id="6530" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">深度缩放:</strong>CNN由几层组成，理解输入图像。增加层数在某个点上是有利的，在该点之后，模型由于<a class="ae kf" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" rel="noopener ugc nofollow" target="_blank">消失梯度问题</a>和复杂性而无法学习。</p><p id="dd01" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">分辨率缩放:</strong>图像的分辨率就是图像的高度x宽度。与尺寸为256 x 256的图像相比，尺寸为512 x 512的图像包含更多信息。然而，采用高分辨率输入总是倾向于增加计算需求的负荷，并且在某个阈值之后将不会对模型的性能提供显著的增益。</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi na"><img src="../Images/1ce4ae0bed2f3dd00ef26fe98b2154ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NMlN05sduEXpHiF0c1gccA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">模型缩放:a)宽度缩放b)深度缩放c)分辨率缩放。图片来自高效网论文:<a class="ae kf" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1905.11946</a></p></figure><h2 id="3cbf" class="mo lm it bd ln mp mq dn lr mr ms dp lv kr mt mu lz kv mv mw md kz mx my mh mz bi translated">复合缩放</h2><p id="15bb" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">使用固定缩放系数的复合缩放方法可以解决单个缩放的痛点。在这种方法中，基于具有固定比例系数集的可用计算资源，网络在深度、宽度和分辨率上被均匀地<strong class="ki iu">缩放。</strong></p><p id="0be2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">应该在不改变底层函数F(x)(我们试图匹配的模式)的情况下确定最佳的层架构模型。因为有多个参数必须改变(深度、宽度、分辨率、资源)，所以设计空间考虑相当大。为了减少这种设计空间，使用恒定比率来缩放参数。复合缩放的目标是在给定的约束条件下找到一个最佳比率—内存&amp;<a class="ae kf" href="https://en.wikipedia.org/wiki/FLOPS" rel="noopener ugc nofollow" target="_blank"><em class="le">FLOPS</em></a><em class="le"/>并获得最大精度</p><p id="be75" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">原始论文</a>建议借助<a class="ae kf" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search" rel="noopener ugc nofollow" target="_blank">网格搜索</a>尝试不同的缩放组合以找到最佳的缩放系数。后来，在流行数据集<a class="ae kf" href="http://www.image-net.org" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>上的现有模型如<a class="ae kf" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"> MobileNet </a>和<a class="ae kf" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet </a>上实现了这种系数缩放，分别提高了1.4%和0.7%的精度。</p><p id="71b4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">准确性的提高并不仅限于上述两个模型，而是在几个模型上给出了显著的结果，如下图所示</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nf"><img src="../Images/b5b7d298abf8cdebf85f6c38f79ce03e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gjnAtK0BlOxrb0LfzDPctQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图片来自原论文:<a class="ae kf" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1905.11946</a></p></figure><p id="ece7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，从上面的参考资料来看，在我们的模型开发阶段，EfficientNet确实值得考虑。</p><h1 id="4c1c" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">什么是效率网？</h1><p id="b47d" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">一个好的基线模型对于在它的基础上进一步构建具有更好性能的模型是必要的。在EfficientNet中，使用类似于<a class="ae kf" href="https://arxiv.org/abs/1801.04381" rel="noopener ugc nofollow" target="_blank"> MobileNetV2 </a>和<a class="ae kf" href="https://arxiv.org/abs/1807.11626" rel="noopener ugc nofollow" target="_blank"> MnasNet </a>的移动反向瓶颈卷积(MBConv)构建基准模型EfficientNet-B0。稍后对基线模型进行改进，以获得<em class="le">效率网</em>系列</p></div><div class="ab cl ng nh hx ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="im in io ip iq"><p id="3c55" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我简单介绍一下什么是MBConv以及EfficientNet的其他构建模块。MBConv块只不过是最初在MobineNetV2 CNN架构中提出的<em class="le">反向残差块</em>。</p><p id="97c5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在正常的<a class="ae kf" href="https://en.wikipedia.org/wiki/Residual_neural_network" rel="noopener ugc nofollow" target="_blank"> <em class="le">剩余块</em></a><em class="le"/>中，网络流量通常从<em class="le">宽到窄再到宽</em>的结构相对于信道数量而言。最后一层恢复到要添加的输入的形状(剩余块的目的是防止渐变消失)</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/dfabf179c8b91daf68b14eaf071b6313.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2thy1DDMhC8sXKWzNTPzA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">残留块。图片来自papers with code:<a class="ae kf" href="https://paperswithcode.com/method/bottleneck-residual-block" rel="noopener ugc nofollow" target="_blank">https://paperswithcode.com/method/bottleneck-residual-block</a>免费</p></figure><p id="31e7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<em class="le">反转残差块中，</em>图层从<em class="le">窄到宽再到与残差块相反的</em>。因此，它最初采用低维输入，并使用1×1卷积层对其进行扩展，随后是3×3深度方向卷积，并使用1×1卷积层返回到输入形状。</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/82b294ce33a3fee8ad72bfaf29ac7d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T_Lwag-xVNyCmh7Uzr6CbA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">反向剩余块。作者图片</p></figure><p id="ddff" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">采用反向残差块的原因是，在原始残差块中，中间的扩展层仅仅是实现细节。该信息仍然可以在低维上相关，导致较少的计算需求和运行时间。</p></div><div class="ab cl ng nh hx ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="im in io ip iq"><p id="474b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如图所示，baseline EfficientNet的架构由深层的<em class="le"> MBConv </em>模块组成</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi np"><img src="../Images/e6ff758b036b610e837dcfe0a1c45075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TyE_wIgWgodxYr80V2u5JA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图片来自谷歌人工智能博客— <a class="ae kf" href="https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="9729" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用不同的比例系数获得效率网B1到B7。下面给出了<a class="ae kf" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">原始文件</a>中所述的整体模型和性能比较</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/3b3b2ebc55e4cbd2fa1b4852fa02847a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iauU8HMAMXNKdBMldqUAPQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图片来自高效网纸—<a class="ae kf" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1905.11946</a></p></figure><h1 id="cae0" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">哪里可以使用高效网络？</h1><p id="3f58" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">由于用于计算的参数数量很少，EfficientNet可以很好地用于快速处理，尤其是在<strong class="ki iu"> MobileAI </strong>中。随后可以引入多维度进行缩放，并在CNN上开辟了全新的研究领域。</p><h1 id="f51c" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">外卖</h1><p id="02b7" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">EfficientNet开辟了一个广阔的研究领域，以改善一些计算机视觉任务的结果。它可能有助于在选择模型的深度、宽度和分辨率方面提供一个好的解决方案，以从中获得最大的结果。</p><p id="384b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在谷歌人工智能团队公布这个模型之后，已经有一些研究将EfficientNet视为主干，如优化分辨率差异的<a class="ae kf" href="https://arxiv.org/pdf/2003.08237v3.pdf" rel="noopener ugc nofollow" target="_blank"> FixEfficientNet </a>，可以广泛用于对象检测任务的<a class="ae kf" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> EfficientDet </a>。</p><p id="737c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了！感谢您阅读这篇文章，希望对您有所帮助🙌</p><h1 id="4a9a" class="ll lm it bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">参考📙</h1><p id="4093" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated"><strong class="ki iu">原文:</strong><a class="ae kf" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1905.11946</a></p><p id="778c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">谷歌AI博客:</strong><a class="ae kf" href="https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html" rel="noopener ugc nofollow" target="_blank">https://AI . Google Blog . com/2019/05/efficient net-improving-accuracy-and . html</a></p><p id="14d1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">倒转残块:</strong>【https://paperswithcode.com/method/inverted-residual-block】T2</p></div></div>    
</body>
</html>