<html>
<head>
<title>Parallelizing GPU-intensive Workloads via Multi-Queue Operations using Kompute &amp; Vulkan</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Kompute和Vulkan通过多队列操作并行处理GPU密集型工作负载</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/parallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc?source=collection_archive---------17-----------------------#2020-10-18">https://towardsdatascience.com/parallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc?source=collection_archive---------17-----------------------#2020-10-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="41d9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过使用Kompute和Vulkan SDK利用多队列操作并行性，在GPU密集型工作负载上实现2倍以上的性能提升</h2></div><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="kk kl l"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">博文视频版(Kompute部分13:33开始)</p></figure><p id="5e44" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">GPU已经证明<a class="ae lm" href="https://arxiv.org/abs/1802.09941" rel="noopener ugc nofollow" target="_blank">对于高度并行的数据处理用例</a>非常有用。例如，在机器学习&amp;深度学习中发现的计算范式非常适合<a class="ae lm" href="http://cs149.stanford.edu/fall19/lecture/gpuarch/" rel="noopener ugc nofollow" target="_blank">图形卡提供的处理架构</a>。</p><p id="64b0" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">然而，当涉及到多个GPU工作负载时，人们会认为这些工作负载会被并发处理，但事实并非如此。虽然单个GPU计算工作负载在众多GPU核心上实现了并行化，但多个工作负载是按顺序逐一运行的。那当然是<strong class="ks ir">直到最近显卡架构的改进</strong>，现在支持跨多个工作负载的硬件并行化。这可以通过将工作负载提交给支持并发的不同底层物理GPU“队列系列”来实现。受益于此的机器学习实用技术包括<a class="ae lm" href="https://mxnet.apache.org/versions/1.7/api/faq/model_parallel_lstm" rel="noopener ugc nofollow" target="_blank">模型并行</a>和<a class="ae lm" href="https://en.wikipedia.org/wiki/Data_parallelism" rel="noopener ugc nofollow" target="_blank">数据并行</a>。</p><p id="b2d7" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在本例中，我们将展示如何通过简单地跨两个队列系列提交多个工作负载，使这些工作负载并行运行，从而在同步示例上实现2倍的性能提升。</p><p id="a3d6" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这是一项重要的优化技术，因为最近在本文档第19页的NVIDIA Ampere GA10x架构规范<a class="ae lm" href="https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf" rel="noopener ugc nofollow" target="_blank">中概述的公告</a>将实现<strong class="ks ir">3倍的性能提升</strong>(即跨一个图形队列和两个计算队列的并发性)<strong class="ks ir">，</strong>表明这一趋势只会继续带来该领域的进一步优化改进。</p><p id="8049" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将使用Vulkan和<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute" rel="noopener ugc nofollow" target="_blank"> Kompute框架</a>来实现这一点。更具体地说，我们将涵盖:</p><ul class=""><li id="1d55" class="ln lo iq ks b kt ku kw kx kz lp ld lq lh lr ll ls lt lu lv bi translated">GPU处理中“异步”和“并行”的歧义消解</li><li id="711d" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll ls lt lu lv bi translated">我们将在此基础上构建一个基本的同步示例</li><li id="72f4" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll ls lt lu lv bi translated">扩展异步工作负载提交示例的步骤</li><li id="7089" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll ls lt lu lv bi translated">扩展并行多队列GPU处理示例的步骤</li></ul><p id="7e20" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">你可以在这个文件 中找到<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute/blob/0b221c9ebd3c8d7c8a81ef2ce80627c9460ec9c2/test/TestAsyncOperations.cpp#L10" rel="noopener ugc nofollow" target="_blank"> <strong class="ks ir">的完整代码——关于如何使用CMAKE运行完整套件的说明可以在<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute#build-overview" rel="noopener ugc nofollow" target="_blank">主Kompute库构建部分</a>中找到。</strong></a></p><h1 id="b768" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">关于Vulkan和Kompute</h1><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/bbbd9f2e2157b90c2422c419cff44445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/0*hkZp9ffOun6EHRlD"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">Khronos成员(图片由Vincent Hindriksen通过<a class="ae lm" href="https://streamhpc.com/blog/2017-05-04/what-is-khronos-as-of-today/" rel="noopener ugc nofollow" target="_blank"> StreamHPC </a>提供)</p></figure><p id="d069" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://en.wikipedia.org/wiki/Vulkan_(API)" rel="noopener ugc nofollow" target="_blank"><strong class="ks ir">Vulkan SDK</strong></a><strong class="ks ir"/>是由<a class="ae lm" href="https://www.khronos.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ks ir"> Khronos Group </strong> </a>领导的一个开源项目，能够实现高度优化的跨厂商/跨平台GPU处理。</p><p id="e8b0" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://github.com/axsaucedo/vulkan-kompute#vulkan-kompute" rel="noopener ugc nofollow" target="_blank"> <strong class="ks ir"> Kompute </strong> </a>是一个构建在Vulkan SDK之上的框架，它抽象了所需的数千行样板代码，介绍了展示Vulkan核心计算能力的最佳实践。Kompute是<a class="ae lm" href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units" rel="noopener ugc nofollow" target="_blank"> GPGPU计算框架</a>，我们将在本教程中使用它来构建核心异步和并行代码实现。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mw"><img src="../Images/a840bbe17c3ebfa0de3b13e94529b0d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ASHn5x_l8sB6OXhm.gif"/></div></div><p class="km kn gj gh gi ko kp bd b be z dk translated">来自<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute" rel="noopener ugc nofollow" target="_blank"> Kompute Repo </a>的“电脑”(图片由作者提供)</p></figure><h1 id="95bb" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">异步与并行处理</h1><p id="1270" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">在深入研究代码之前，有必要澄清两个概念，即<strong class="ks ir">异步工作负载提交</strong>和<strong class="ks ir">并行工作负载处理</strong>。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/4ade1d2f58e3b4e6caad9d2e57533c13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*gEBXV6hJGPMfRZWvF3kENQ.png"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">简化的Vulkan建筑(图片由作者提供)</p></figure><p id="99a3" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">使用<strong class="ks ir"> Vulkan SDK </strong>到<strong class="ks ir"> GPU队列</strong>提交并行工作负载进行处理的方式。这可以在简化的Vulkan架构图中看到(为简单起见，省略了管道和描述符组件)。</p><h2 id="808f" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">异步工作负载提交</h2><p id="9972" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">异步处理包括CPU主机端能够在GPU处理工作负载的同时执行其他工作的能力。“其他工作”可以包括调用其他C++函数，甚至向相同或其他GPU队列提交进一步的工作负载。当CPU想要检查GPU工作负载是否完成时，它可以使用一个<strong class="ks ir"> Vulkan“栅栏”</strong>，这基本上是一个信号量资源，允许CPU在GPU工作负载完成时得到通知。</p><p id="b4e3" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">值得注意的是，当多个工作负载被提交到同一个队列时，即使这些是从多个C++线程中完成的，预期的执行顺序仍然是连续的——至少在今天的GPU架构中是这样。</p><h2 id="0e4a" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">并行工作量处理</h2><p id="041b" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">并行工作负载处理由GPU同时执行两个或更多工作负载组成。更具体地说，如果您有两个GPU任务，每个任务需要10秒钟来处理，理论上两个任务的并行执行仍然需要10秒钟，因为它们将同时执行。</p><p id="3cb9" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了实现并行工作负载处理，底层GPU必须首先支持这一点。这一点之所以重要，是因为即使您要跨不同的GPU队列提交工作负载，处理仍可能由底层硬件基于其限制按顺序完成。</p><h1 id="43a0" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">基本顺序处理示例</h1><p id="cbf6" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">我们现在来看一下将在本文中使用的代码。代码的第一个版本将是顺序流——我们将能够将其转换成异步代码，并最终转换成并行代码。我们将基本上运行一个工作负载，在该工作负载中，我们将执行以下操作:</p><ol class=""><li id="07bc" class="ln lo iq ks b kt ku kw kx kz lp ld lq lh lr ll nt lt lu lv bi translated">创建一个Kompute管理器来协调所有的GPU工作</li><li id="1299" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll nt lt lu lv bi translated">在将用于处理数据的CPU主机中创建Kompute张量</li><li id="867d" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll nt lt lu lv bi translated">将Kompute张量映射到GPU设备内存中</li><li id="be86" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll nt lt lu lv bi translated">定义计算着色器，让GPU忙碌几个100毫秒</li><li id="bb4f" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll nt lt lu lv bi translated">使用张量在GPU中运行计算着色器进行数据处理</li><li id="abcf" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll nt lt lu lv bi translated">将Kompute张量的结果映射回CPU主机内存</li><li id="41d0" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll nt lt lu lv bi translated">验证操作是否成功</li></ol><p id="ff5a" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了测量时间，我们将使用标准库中的<code class="fe nu nv nw nx b">&lt;chrono&gt;</code>。我们将主要使用它来计算使用<code class="fe nu nv nw nx b">std::chrono::high_resolution_clock::now()</code>检索的开始和结束时间之间的差异，如下所示:</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><p id="038a" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">您可以在这个文件中找到<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute/blob/1053cde1f0d27799f0d7dbd8043919656498f8bf/test/TestAsyncOperations.cpp#L8" rel="noopener ugc nofollow" target="_blank">的可运行代码，它是Kompute测试套件的一部分。</a></p><h2 id="6b51" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">1.创建一个Kompute管理器来协调所有的GPU工作</h2><p id="1e8b" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">首先我们必须创建Kompute管理器，它执行所有需要的内存管理并创建所有需要的Vulkan资源。默认情况下，Kompute管理器将选择GPU设备0，但是您可以传递您想要初始化的特定设备索引，如果您已经有Vulkan应用程序，您可以传递您的Vulkan资源。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h2 id="b90a" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">2.在CPU主机中创建将用于处理数据的Kompute张量</h2><p id="0d54" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">我们现在将能够创建一组Kompute张量。我们首先在CPU主机中初始化数据，该数据由长度为10的零数组组成。我们将使用两个张量，因为我们将运行两个算法执行。我们将能够在最后检查这些Kompute张量，以确认执行已经成功。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h2 id="58f5" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">3.将Kompute张量映射到GPU设备内存中</h2><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi nz"><img src="../Images/d25bff9e2908f18f98f781d0c4a1958f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZl2b3znOUwPBW1a1Zz51g.png"/></div></div><p class="km kn gj gh gi ko kp bd b be z dk translated"><strong class="bd oa">斯坦福CS149课程</strong> <a class="ae lm" href="http://cs149.stanford.edu/fall19/lecture/gpuarch/slide_038" rel="noopener ugc nofollow" target="_blank"> <strong class="bd oa"> 2019幻灯片</strong> </a></p></figure><p id="5ed1" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们现在能够将Kompute张量的主机数据复制到GPU设备内存中。</p><p id="cccf" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这是一个重要的步骤，因为默认情况下，Kompute张量使用仅设备可见的内存，这意味着GPU操作需要用staging tensor复制它。</p><p id="e9d9" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Kompute允许我们创建缓冲区和GPU内存块，以及通过<code class="fe nu nv nw nx b">kp::OpTensorCreate</code>操作使用分段缓冲区执行复制。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h2 id="a1a8" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">4.定义计算着色器，让GPU忙碌几个100毫秒</h2><p id="72bc" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">我们创建的计算着色器有一个相对较大的循环来模拟“昂贵的计算”。它基本上为<code class="fe nu nv nw nx b">100000000</code>次迭代执行一个单位加法，并将结果加到输入张量上。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h2 id="2deb" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">5.使用张量在GPU中运行计算着色器进行数据处理</h2><p id="6cf8" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">现在我们能够通过<code class="fe nu nv nw nx b">kp::OpAlgoBase</code>操作提交计算着色器来执行。这基本上允许我们用各自的张量执行着色器的提交。这个初始实现同步运行执行，所以它将首先用<code class="fe nu nv nw nx b">tensorA</code>运行着色器的执行，然后用<code class="fe nu nv nw nx b">tensorB</code>运行同一个着色器的执行。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h2 id="a0d9" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">6.将Kompute张量的结果映射回CPU主机内存</h2><p id="8fa1" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">最后，我们希望将GPU设备内存中的结果检索到CPU主机内存中，这样我们就可以从C++中访问它。为此，我们可以使用<code class="fe nu nv nw nx b">kp::OpTensorSync</code>操作。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h2 id="c017" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">7.验证操作是否成功</h2><p id="c5a8" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">最后，我们可以检查两个结果<code class="fe nu nv nw nx b">kp::Tensor</code>都包含了<code class="fe nu nv nw nx b">100000000</code>的预期值。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h1 id="44f1" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">扩展异步工作负载提交</h1><p id="4fac" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">在这种情况下，我们需要为异步提交扩展的步骤非常少。我们唯一需要做的就是用<code class="fe nu nv nw nx b">evalOpDefault</code>函数代替<code class="fe nu nv nw nx b">evalOpAsyncDefault</code>函数，然后使用<code class="fe nu nv nw nx b">evalOpAwaitDefault(&lt;timeInNanoSecs&gt;)</code>等待任务完成。这基本上如下所示:</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><p id="9a04" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">正如您所看到的，我们能够异步提交两个任务进行处理，然后使用Await函数等待它们完成。</p><p id="4d20" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">值得指出的是，每次我们调用<code class="fe nu nv nw nx b">evalOpAsyncDefault</code>时，它都会创建一个新的托管序列，而<code class="fe nu nv nw nx b">evalOpAwaitDefault</code>只等待最近的默认序列。这意味着在上面的代码片段中，我们只等待第二个异步操作。对于我们的例子来说，这不是问题，但是如果我们现在知道的话，这可能会引入错误。正确的方法是使用显式创建的“命名序列”——我们将在下一节中这样做。</p><h1 id="8ae8" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">扩展并行工作负载处理</h1><p id="f696" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">现在我们知道我们能够异步执行多个工作负载，我们能够扩展这一点，以利用GPU中的多个队列来实现工作负载的并行执行。</p><h2 id="a570" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">在NVIDIA 1650显卡上运行</h2><p id="3c30" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">为了展示一个有用的例子，我们将深入探讨如何在<a class="ae lm" href="http://vulkan.gpuinfo.org/displayreport.php?id=9700" rel="noopener ugc nofollow" target="_blank"> NVIDIA 1650显卡</a>中实现这一点。您可以通过检查视频卡的设备报告(即可用的队列系列和并行处理功能)来亲自尝试。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/958cf8215f43aa6c372dd2ae9b25d78d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*SvqJ5S7FLPnIz_EscgtsGw.png"/></div><p class="km kn gj gh gi ko kp bd b be z dk translated">NVIDIA 1650中队列的概念性概述(图片由作者提供)</p></figure><p id="2391" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">NVIDIA 1650 GPU有3个队列系列。NVIDIA 1650使用<code class="fe nu nv nw nx b">G</code>进行图形处理，使用<code class="fe nu nv nw nx b">T</code>进行传输，使用<code class="fe nu nv nw nx b">C</code>进行计算，其<code class="fe nu nv nw nx b">familyIndex 0</code>中的<code class="fe nu nv nw nx b">G+T+C</code>系列有16个队列，<code class="fe nu nv nw nx b">familyIndex 1</code>上的<code class="fe nu nv nw nx b">T</code>系列有2个队列，<code class="fe nu nv nw nx b">familyIndex 2</code>上的<code class="fe nu nv nw nx b">T+C</code>系列有8个队列。</p><p id="1c17" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">截至今天(2020年10月)，当工作跨同一系列内的多个队列提交时，NVIDIA不支持并行处理工作负载。但是，当跨队列系列提交工作负载时，它支持并行化。这意味着图形和计算系列队列之间的工作负载可以并行化，我们将在实施中使用这一知识。</p><h2 id="a4fe" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">并行工作流执行的实现</h2><p id="9189" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">到目前为止，我们已经将所有GPU工作负载提交到一个队列，即使用底层队列索引0的图形<code class="fe nu nv nw nx b">familyIndex 0</code>。在我们使用GPU 1650的情况下，如果我们跨图形系列和计算系列提交工作负载，我们将能够实现并行处理。下面的图表应该为我们将要做的事情提供一个直觉。</p><figure class="kf kg kh ki gt kj gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi oc"><img src="../Images/fd26bbdbc6111c27f239a468526f24be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jFMAnHpNFQaAGOFnqWYWSA.png"/></div></div><p class="km kn gj gh gi ko kp bd b be z dk translated">通过多个系列队列并行执行操作(图片由作者提供)</p></figure><p id="aed7" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了做到这一点，我们需要修改三个关键的东西:</p><ol class=""><li id="a28c" class="ln lo iq ks b kt ku kw kx kz lp ld lq lh lr ll nt lt lu lv bi translated">我们用相应的可用队列初始化Kompute管理器</li><li id="eb98" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll nt lt lu lv bi translated">我们创建了两个Kompute序列，每个序列都分配了相应的队列</li><li id="3526" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll nt lt lu lv bi translated">我们在每个队列上运行操作</li></ol><p id="ff93" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将深入研究这三点。</p><h2 id="c7c2" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">1.我们用相应的可用队列初始化Kompute管理器</h2><p id="9180" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">当初始化一个管理器时，我们能够传递一个包含我们想要获取的队列的数组。在这种情况下，我们只获取一个图形队列和一个计算队列，但是，根据NVIDIA 1650的硬件规格，我们将能够请求多达16个图形队列(familyIndex 0)、2个传输队列(familyIndex 1)和8个计算队列(familyIndex 2)。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h2 id="c614" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">2.我们创建了两个Kompute序列，每个序列都分配了相应的队列</h2><p id="613c" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">现在，我们能够显式初始化两个托管序列，每个序列都分配到不同的队列，引用我们在上一步中传递的数组的索引。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h2 id="ef71" class="nh mc iq bd md ni nj dn mh nk nl dp ml kz nm nn mn ld no np mp lh nq nr mr ns bi translated">3.我们在每个队列上运行操作</h2><p id="ad3a" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">现在，我们能够运行提交到各个队列的操作。在这种情况下，并行提交两个GPU工作负载。</p><figure class="kf kg kh ki gt kj"><div class="bz fp l di"><div class="ny kl l"/></div></figure><h1 id="4da2" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">并行工作负载执行结果</h1><p id="aecc" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">运行上面提供的代码时，我们可以看到由于并行系列队列提交工作负载，执行时间提高了2倍。您还可以看到，如果我们从图形或计算队列提交到额外的队列，我们将不会看到任何进一步的速度提升，因为该NVIDIA 1650卡不支持队列内并行化。</p><p id="f033" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">你可以在这个文件中找到完整的代码并运行它——关于如何使用CMAKE运行完整套件的说明可以在<a class="ae lm" href="https://github.com/EthicalML/vulkan-kompute" rel="noopener ugc nofollow" target="_blank">主Kompute库</a>中找到。</p><p id="f1ff" class="pw-post-body-paragraph kq kr iq ks b kt ku jr kv kw kx ju ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这是一个特别重要的结果，因为根据NVIDIA最近发布的300x显卡，Ampere GA10x架构有所改进，允许同时处理两个计算工作负载。相对于上面的示例，这意味着如果我们使用一个图形队列和两个计算队列，我们可以看到3倍的性能提升(以及使用传输队列进行传输操作的额外性能)。</p><h1 id="88db" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">后续步骤</h1><p id="faaa" class="pw-post-body-paragraph kq kr iq ks b kt nb jr kv kw nc ju ky kz nd lb lc ld ne lf lg lh nf lj lk ll ij bi translated">恭喜你，你一路走到了最后！虽然这篇文章涵盖了广泛的主题，但是也有大量的概念被浏览过。其中包括底层的Vulkan概念、GPU计算基础和更高级的Kompute概念。幸运的是，网上有资源可以扩展你在这些方面的知识。以下是我推荐的一些进一步阅读的链接:</p><ul class=""><li id="594d" class="ln lo iq ks b kt ku kw kx kz lp ld lq lh lr ll ls lt lu lv bi translated">"<a class="ae lm" rel="noopener" target="_blank" href="/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a">利用Kompute简化移动设备中的机器学习&amp;跨供应商GPU&amp;Vulkan</a>文章，深入探讨理论和概念</li><li id="b935" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll ls lt lu lv bi translated"><a class="ae lm" href="https://axsaucedo.github.io/vulkan-kompute/" rel="noopener ugc nofollow" target="_blank"> Kompute文档</a>了解更多细节和更多示例</li><li id="48ba" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll ls lt lu lv bi translated"><a class="ae lm" rel="noopener" target="_blank" href="/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a">移动设备中的机器学习&amp;利用Kompute简化跨厂商GPU&amp;Vulkan</a></li><li id="8f76" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll ls lt lu lv bi translated"><a class="ae lm" rel="noopener" target="_blank" href="/gpu-accelerated-machine-learning-in-your-mobile-applications-using-the-android-ndk-vulkan-kompute-1e9da37b7617">用GPU加速你的移动应用程序使用安卓NDK &amp; Kompute </a>加速机器学习</li><li id="2b05" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll ls lt lu lv bi translated"><a class="ae lm" rel="noopener" target="_blank" href="/supercharging-game-development-with-gpu-accelerated-ml-using-vulkan-kompute-the-godot-game-engine-4e75a84ea9f0"> GPU使用Godot引擎和Kompute加速ML</a></li><li id="4834" class="ln lo iq ks b kt lw kw lx kz ly ld lz lh ma ll ls lt lu lv bi translated"><a class="ae lm" href="https://vulkan-tutorial.com/" rel="noopener ugc nofollow" target="_blank"> Vulkan SDK教程</a>深入了解底层Vulkan组件</li></ul></div></div>    
</body>
</html>