<html>
<head>
<title>Fill your world with colors: ChromaGANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让你的世界充满色彩:色度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fill-your-world-with-colors-chromagans-6e916bbff9aa?source=collection_archive---------59-----------------------#2020-10-02">https://towardsdatascience.com/fill-your-world-with-colors-chromagans-6e916bbff9aa?source=collection_archive---------59-----------------------#2020-10-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="646d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解色原以及如何使用它们为图像着色</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d31cd0899953140ec71ca34c4f116ea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*usFdIPBvjKEJQcEm"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">阿瑟·马齐在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="cfa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将灰度图像转换成彩色图像似乎是一个古老的问题，但是传统的方法有多少次合理地将图像彩色化了呢？随着时间的推移，随着深度学习的进步，已经提出了各种基于CNN的方法来做同样的事情，这些方法已经成功地胜过了它们以前的方法。无论如何，在今天的这篇文章中，我们将看到一种这样的方法，它基于<a class="ae ky" href="https://arxiv.org/pdf/1907.09837.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>的对抗学习技巧。</p><p id="4d08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了完全理解这篇文章，建议读者对GANs及其工作原理有一个基本的了解。如果你觉得你没有必备的知识，这篇文章不是一个正确的起点。我推荐这样的读者阅读这篇<a class="ae ky" href="https://medium.com/r?url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-generative-adversarial-networks-gans-cd6e4651a29" rel="noopener">博客</a>并回到这篇文章。</p><h2 id="fa1f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">损失函数</h2><p id="5108" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">熟悉GANs的人都知道，与其他为不同目的设计的基于视觉的架构不同，在影响发电机网络输出方面，损失函数比其他超参数起着更大的作用。有时，损失函数在很大程度上决定了发电机的输出类型。因此，理解它们以获得发电机如何学习产生特定类型输出的要点是极其重要的。现在，在色度GANs中，总损失函数可以分解为三个子损失函数。</p><ul class=""><li id="7874" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">类分布损失:</strong></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/f4abace35762e3f8421c1a367a42ab2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*zHyAe0LvxZcEPvMe_bUI4A.png"/></div></figure><p id="1f33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">级分配损耗</em>测量发电机(发电机2)输出和VGG-16输出之间的<strong class="lb iu">KL</strong>T4】误差。你们很多人都知道KL误差代表Kullback-Leibler散度。为了简单地解释，它计算一个概率分布如何不同于给定的参考概率分布。根据上面的公式<strong class="lb iu"> <em class="nd"> Y </em> ᵥ </strong>是从用于灰度图像的VGG-16模型的输出分布中采样的，并且用作参考概率分布。因此，我们将计算发电机的预测分布(<em class="nd">发电机2 </em>)与VGG-16模型的预测分布有何不同。两个概率分布例如Pand和Q之间的KL散度由下式给出，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/5f6f9defc2e28f10d3a170c3da9b19e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*5VdPVQjrwMHCBsehGDZS9Q.png"/></div></figure><p id="cd81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当所有<em class="nd">x</em>的<em class="nd"> P </em>与<em class="nd"> Q </em>相同时，KL损失为零</p><ul class=""><li id="fbcd" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">颜色误差损失:</strong></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/ebd9e4f1773acaaa0265eabb47516344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*HCproZGw89pWjhaxf_25zw.png"/></div></figure><p id="4792" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nd">颜色误差损失</em>简单地计算发生器(发生器1)产生的输出和输入图像(真实彩色图像)的色度通道之间的<strong class="lb iu">均方误差</strong></p><ul class=""><li id="a905" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu"> WGAN损耗:</strong></li></ul><p id="0aea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在一个香草GAN中，两个概率分布之间的距离用<a class="ae ky" href="https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html#kullbackleibler-and-jensenshannon-divergence" rel="noopener ugc nofollow" target="_blank"> <em class="nd"> JS散度(简森-香农散度)</em> </a> <em class="nd">来度量。</em>它有几个问题，因此被替换为<em class="nd">瓦塞尔斯坦距离</em>也称为<em class="nd">推土机距离。</em>避免了消失梯度、模式崩溃，实现了更稳定的训练。它量化了将一种概率分布转换成另一种概率分布所需的能量或成本。让我们取两个连续的概率分布<strong class="lb iu"><em class="nd">【pᵣ】</em></strong>(对于真实数据)<strong class="lb iu"><em class="nd">p</em>【𝓰】</strong>(对于生成的数据)<em class="nd"/>并让<strong class="lb iu"><em class="nd">π(pᵣ</em></strong>、<strong class="lb iu"><em class="nd">p</em>𝓰<em class="nd">)</em></strong>为<em class="nd"> P </em>和<em class="nd"> Q定义所有联合概率分布的集合 </em> γ( <em class="nd"> x，y </em>)表示<em class="nd"> x </em>变为<em class="nd"> y </em>的数值变化量。 <em class="nd">瓦塞尔斯坦距离</em>或<em class="nd">推土机距离</em>由下式给出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/29067311801772d691756e842fb6c0b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*wL8wYhp2FDod5kwWkZcCkA.png"/></div></figure><p id="cfa4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"> E( <em class="nd"> x，y</em>)∨γ∨<em class="nd">x</em>—<em class="nd">y</em>∨=∑γ(x，y)∨x y∨</strong>。最后，在计算E( <em class="nd"> x，y </em>)后我们取其中的<strong class="lb iu">最小代价</strong>(下确界—最大下界)<strong class="lb iu"> </strong>。</p><p id="c12e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注:</strong>为了不偏离文章主旨，说明是有限制的。人们可以参考这个<a class="ae ky" href="https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html#wasserstein-gan-wgan" rel="noopener ugc nofollow" target="_blank">帖子</a>来获得详细的解释。</p><h2 id="f0df" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">体系结构</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/8a8cbdfc89f99bfd9e2a078a091221ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UL--iOuZ9WLjCuvaqziNPA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://arxiv.org/pdf/1907.09837.pdf" rel="noopener ugc nofollow" target="_blank">原文</a></p></figure><p id="9520" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上图可以看出，绿色部分对应于鉴别器，其余部分对应于发生器。发电机由两个子网络G1 <em class="nd">(发电机1) </em>和G2 <em class="nd">(发电机2) </em>组成。黄色、紫色、红色和蓝色的<strong class="lb iu">是G1 </strong>，红色和灰色的<strong class="lb iu">是G2 </strong>。我们来详细看看各个网络是做什么的。</p><ul class=""><li id="0411" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">发电机网络:</strong></li></ul><p id="b8ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">发电机分为网络G1和G2。由于GAN必须将灰度图像转换成彩色图像，每个网络接收尺寸为<strong class="lb iu"><em class="nd">H</em>x<em class="nd">w .</em>T5】的灰度图像，G1输出色度信息(<em class="nd"> a，b </em>)，其中<em class="nd"> a </em>和<em class="nd"> b </em>是CIE Lab空间中的色度通道。<strong class="lb iu">所以G1( <em class="nd"> L </em> ) = ( <em class="nd"> a，b) </em> </strong> <em class="nd">。</em> G2输出类别分布向量<em class="nd"> y </em>，因此<strong class="lb iu">G2(<em class="nd">L</em>)=<em class="nd">y</em></strong>(<em class="nd">y</em>属于Imagenet上预定义的VGG-16模型的输出分布向量)<strong class="lb iu"> <em class="nd">。</em> </strong></strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/161d5403c3e5734556322ae7d93bc5c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*6_DQdDsJMj1dWLUv2CFsvA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在上面的图像中，紫色块和整形后的矢量被融合，然后输入到蓝色(conv-雷鲁)块中。</p></figure><ul class=""><li id="608d" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">鉴别器网络:</strong></li></ul><p id="b4d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">鉴别器架构基于来自<a class="ae ky" href="https://arxiv.org/pdf/1611.07004.pdf" rel="noopener ugc nofollow" target="_blank"> PatchGAN </a>的马尔可夫架构。PatchGAN的鉴别器从输入图像中取出一个<em class="nd"> N </em> x <em class="nd"> N </em>的补丁，并尝试识别该补丁是真的还是假的。输出将在来自相应面片的所有输出上进行平均。由于这些补片可能比原始图像小得多，鉴别器将使用较少数量的参数运行，使其计算快速，并允许其任意应用于较大的图像。该模型的主要优点是，即使颜色误差损失(L2范数)未能捕获高频结构，它也可以跟踪高频结构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/7c25e9c7d8b577e4dcae99d51ef2c67c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SdaBYWCxLoCvV9EYbJLU0Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">鉴别器架构(此图对应于整体架构中的绿色部分)</p></figure><h2 id="eb67" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">培训流程:</h2><p id="1ef5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><em class="nd"> G1 </em>和<em class="nd"> G2 </em>都是用单一反向传播步骤训练的。根据该论文的超参数配置是10个图像的批量大小、2e-5的学习速率、adam优化器的beta(0.5，0.999)。图像大小调整为224x224，并转换为三个通道的灰度图像(通过将同一通道复制三次)。首先，图像通过发生器网络发出色度通道(a，b ),然后与真实图像的L通道融合。现在，从生成的图像中获得一小块，然后鉴别器试图预测它。然后，训练过程与任何敌对网络几乎相同。</p><h2 id="27b6" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">结果:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/d934bde7c81dbecca180fb6a0c76d0dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fl40hKPJkjQ-AO35YrFzlw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">与其他网络结果的相对比较(图片来自<a class="ae ky" href="https://arxiv.org/pdf/1907.09837.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/ce0f246c3db5f865a4baf5b2a9f781f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JT1n7sEmLXKiqpEoXsR2Pw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用ChromaGAN对历史黑白图像进行着色(图像来自<a class="ae ky" href="https://arxiv.org/pdf/1907.09837.pdf" rel="noopener ugc nofollow" target="_blank">纸</a></p></figure><p id="50d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这个GitHub链接中查看作者的官方实现。</p><div class="nm nn gp gr no np"><a href="https://github.com/pvitoria/ChromaGAN" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd iu gy z fp nu fr fs nv fu fw is bi translated">pvitoria/ChromaGAN</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">ChromaGAN的官方Keras实现:带有语义类分布的对立图片彩色化</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">github.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od ks np"/></div></div></a></div></div></div>    
</body>
</html>