<html>
<head>
<title>Debugging in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow中的调试</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/debugging-in-tensorflow-392b193d0b8?source=collection_archive---------8-----------------------#2020-10-06">https://towardsdatascience.com/debugging-in-tensorflow-392b193d0b8?source=collection_archive---------8-----------------------#2020-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8618" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何在不失去理智的情况下调试TensorFlow训练程序</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/82af9bfa4a1e78badc8bb23dcda675b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oKQ0u4xD3RuRTsAC"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">戴维·克洛德在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><pre class="kg kh ki kj gt kw kx ky kz aw la bi"><span id="1a20" class="lb lc iq kx b gy ld le l lf lg">If debugging is the process of removing software bugs, then programming must be the process of putting them in.<br/>Edsger Dijkstra. From https://www.azquotes.com/quote/561997</span></pre><p id="197d" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">在我以前的一些帖子中(<a class="ae kv" href="https://medium.com/@julsimon/making-amazon-sagemaker-and-tensorflow-work-for-you-893365184233" rel="noopener">这里</a>、<a class="ae kv" href="https://medium.com/@julsimon/deep-dive-on-tensorflow-training-with-amazon-sagemaker-and-amazon-s3-12038828075c" rel="noopener">这里</a>和<a class="ae kv" rel="noopener" target="_blank" href="/tensorflow-performance-analysis-314b56dceb59">这里</a>)，我告诉过你一些关于我在Mobileye(官方名称为Mobileye，英特尔公司)的团队如何使用<a class="ae kv" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>、亚马逊SageMaker<a class="ae kv" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank">和亚马逊s3 </a>来训练我们的深度神经网络处理大量数据。在这篇文章中，我想谈谈TensorFlow中的调试。</p><p id="3271" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">众所周知，程序调试是软件开发中不可或缺的一部分，花费在调试上的时间常常超过了编写原始程序的时间。</p><p id="22de" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">调试是困难的，已经有很多关于如何设计和实现一个人的程序以增加错误的再现性，并简化根本原因分析的过程的文章。</p><p id="2c41" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">在机器学习中，调试任务由于机器学习算法固有的随机性以及算法通常在远程机器上的专用硬件加速器上运行的事实而变得复杂。</p><p id="cc95" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">TensorFlow 中的调试<em class="md">由于使用了符号执行(也称为图形模式)而变得更加复杂，这提高了训练会话的运行时性能，但同时也限制了自由读取图形中任意张量的能力，这种能力对于调试非常重要。</em></p><p id="5732" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">在这篇文章中，我将阐述调试TensorFlow训练程序的困难，并提供一些如何解决这些困难的建议。</p><p id="9aa2" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">出于法律目的，我想澄清，尽管我精心选择了副标题，但我不能保证我在这里写的任何东西都会防止你失去理智。相反，我认为我几乎可以保证，不管我写了什么，当你调试TensorFlow程序时，你可能会失去理智。但是，也许，你会少失去一点理智。</p><p id="1aaa" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">在我们开始之前，让我们澄清一下我们讨论的范围。</p><h1 id="8b61" class="me lc iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">调试的类型</h1><p id="a8bc" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">在本文的上下文中，调试指的是识别代码或数据中导致培训突然中断的错误的艺术。</p><p id="c7a6" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">另一种类型的调试(不在本文讨论范围之内)指的是修复或调整一个不收敛的模型，或者对某一类输入产生不令人满意的预测的模型(例如，车辆检测模型无法识别粉红色汽车)。该过程可能涉及定义和评估模型指标，收集和统计分析模型工件(如梯度、激活和权重)，使用工具，如<a class="ae kv" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank"> TensorBoard </a>和<a class="ae kv" href="https://medium.com/@chaimrand/debugging-in-tensorflow-392b193d0b8" rel="noopener"> Amazon Sagemaker调试器</a>，超参数调整，重新架构，或使用增强和增强等技术修改您的数据输入。调整模型可能是一项极具挑战性、耗时且常常令人沮丧的任务。</p><h2 id="5f22" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">错误的类型</h2><p id="b46e" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">在解决代码或数据中的错误方面，我喜欢区分两类错误:<em class="md">错误</em>和<em class="md">怪物错误</em>。</p><p id="8052" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">通过<em class="md">bug</em>我指的是相对容易重现的问题。<em class="md">错误</em>的例子是对输入张量大小的假设与训练数据不匹配，试图连接不匹配的张量，或对无效数据类型执行tf运算。这些通常不依赖于特定的模型状态和数据，并且通常相对容易重现。它们不一定容易修复，但与怪物bug相比简直是小儿科。</p><p id="5cf5" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated"><em class="md">怪物bug</em>是偶发的、不可预测的bug。仅在模型的特定状态、特定数据样本或模型状态和数据输入的特定组合上重现的错误可能会带来严重的挑战，并可能构成一个<em class="md">怪物错误</em>。</p><p id="9632" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">以下是一个基于真实事件的场景示例，它肯定会增加您的血压:</p><p id="679f" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">现在是星期五下午，你的模特已经成功训练了几天。损失似乎正在很好地融合，你开始想象一个放松的，释放后的周末假期，在你选择的地方。你回头看了一会儿屏幕，注意到突然之间，没有任何警告，你的损失变成了NaN。“当然”，你对自己说，“这一定是由于一些完全随机的、瞬间的、宏观的故障”，然后你立即从你最后一个有效的模型检查点恢复训练。又过了几个小时，这种情况又发生了，一次又一次。现在你开始恐慌，你周末天堂的梦幻图片现在被需要解决一个<em class="md">怪物错误</em>的诱人努力的想法所取代。</p><p id="5217" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">我们一会儿将回到这个令人悲伤的例子。但是首先，让我们检查一些强制性的“调试”复选框。</p><h1 id="49c8" class="me lc iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">Tensorflow中的调试技巧</h1><p id="2cb5" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">在调试的艺术上，更重要的是，在开发可调试代码的艺术上，已经花了很多笔墨。在本节中，我将提到一些与张量流应用相关的技术。这份清单并不全面。</p><h2 id="ba2d" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">保存模型检查点</h2><p id="463e" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">这可能是我在这篇文章中写的最重要的东西。始终配置您的培训课程，使其定期保存您的模型的快照。</p><p id="cd2e" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">编程错误并不是你的训练失败的唯一原因...如果您在云中运行，您可能会得到一个现场实例终止，或者遇到一个内部服务器错误。如果您在本地运行，可能会停电，或者您的GPU可能会爆炸。如果你已经训练了几天，没有储存中间检查点，伤害可能是极端的。如果您每小时保存一个检查点，那么您最多丢失一个小时。TensorFlow提供了用于存储检查点的实用程序，例如<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint" rel="noopener ugc nofollow" target="_blank"> keras模型检查点回调</a>。您需要做的只是，通过权衡存储检查点的开销和培训课程中意外中断的成本，来决定捕获此类快照的频率。</p><h2 id="7218" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">接触者追踪</h2><p id="e19c" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">我为我选择这一小节的标题向我的同辈人道歉，我实在忍不住了。通过联系跟踪，我指的是跟踪输入培训管道的培训数据的能力。</p><p id="598a" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">假设您的训练数据被分成100，000个tfrecord文件，其中一个文件有格式错误，导致您的程序崩溃或停止。缩小问题文件搜索范围的一种方法是记录进入管道的每个文件。一旦你点击崩溃，你可以回头看看你的日志，看看最近输入的文件是什么。正如我在以前的帖子中提到的，我们使用Amazon SageMaker管道模式功能进行训练。管道模式中最近增加的一项功能是管道模式服务器端日志，它记录了进入管道的文件。</p><p id="5386" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">记录进入pipeline的数据有助于提高重现bug的能力，这就引出了我们的下一点。</p><h2 id="c10c" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">可复制性</h2><p id="2fd2" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">bug重现的容易程度直接影响到解决它的容易程度。我们总是想写我们的代码，以确保可重复性。这在TensorFlow程序中并不容易。机器学习应用通常依赖于随机变量的使用。我们随机初始化模型权重，我们随机增加数据，我们随机分割数据用于分布式训练，我们随机应用漏失，我们在每个时期之前混洗我们的输入数据，然后在创建批次之前再次混洗它(使用tf.dataset.shuffle)。我们可以用我们记录的伪随机种子来播种所有的伪随机操作，但是请记住，可能有许多不同的地方引入了随机化，并且跟踪所有这些很容易成为簿记噩梦。我无法告诉你有多少次我认为我已经去除了随机化的所有元素，却发现我漏掉了一个。此外，还有一些无法植入的随机流程。如果使用多个过程来导入训练数据，您可能无法控制数据记录的实际输入顺序(例如，如果在<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/data/Options" rel="noopener ugc nofollow" target="_blank"> tf.data.Options </a>())中将experimental_deterministic设置为false)。当然，您可以在每个样本进入管道时对其进行记录，但这将会产生很高的开销，而且可能会令人望而却步。</p><p id="f881" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">底线是，虽然构建可重复的训练程序是绝对可能的，但我认为更明智的做法是接受非确定性，接受训练的不可重复性质，并找到克服这种调试限制的方法。</p><h2 id="abce" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">模块化程序设计</h2><p id="26ae" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">创建可调试程序的一个关键技术是以模块化的方式构建应用程序。应用于TensorFlow训练循环，这意味着能够分别测试训练管道的不同子集，如数据集、损失函数、不同的模型层和回调。这并不总是容易做到的，因为一些训练模块(如损失函数)非常依赖于其他模块。但是有很大的创造空间。例如，在应用数据集操作的子集时，可以通过简单地迭代数据集来测试输入管道上的不同函数。可以通过创建一个只运行损失函数或回调的应用程序来测试损失函数或回调。人们可以通过用虚拟损失函数代替它来抵消损失函数。我喜欢使用多个输出点来构建我的模型，即能够轻松修改模型中的层数，以便测试不同层的影响。</p><p id="0b72" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">在构建程序时，你对程序的模块化和可调试性考虑得越多，你以后遭受的痛苦就越少。</p><h2 id="d4da" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">急切的执行</h2><p id="c9f5" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">如果您是TensorFlow的普通用户，您可能会遇到诸如“急切执行模式”、“图形模式”和“tf函数限定符”之类的术语。你可能听过一些(有些误导)的说法，比如“在急切执行模式下调试是小菜一碟”，或者“tensorflow 2在急切执行模式下运行”。你可能和我一样，狂热地一头扎进了<a class="ae kv" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank"> tensorflow源代码</a>，试图弄清楚不同的执行模式，结果却在抽泣中崩溃了，你的自尊从此粉碎。为了全面理解它是如何工作的，我向你推荐<a class="ae kv" href="https://www.tensorflow.org/guide/function" rel="noopener ugc nofollow" target="_blank">张量流文档</a>，祝你好运。这里我们将提到它的要点，因为它与调试有关。运行TensorFlow训练的最佳方式是在<a class="ae kv" href="https://www.tensorflow.org/guide/intro_to_graphs" rel="noopener ugc nofollow" target="_blank">图形模式</a>下运行。图形模式是一种符号执行模式，这意味着我们不能任意访问图形张量。用<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/function" rel="noopener ugc nofollow" target="_blank"> tf.function </a>限定符包装的函数将在图形模式下运行。当您使用<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit" rel="noopener ugc nofollow" target="_blank"> tf.keras.model.fit </a>训练时，默认情况下，训练步骤以图形模式执行。当然，不能访问任意的图形张量，使得在图形模式下调试很困难。在急切执行模式下，您可以访问任意张量，甚至可以使用调试器进行调试，(前提是您将断点放在model.call()函数中的适当位置)。当然，当你在热切执行模式下运行时，你的训练会运行得慢很多。要对您的模型进行编程以在急切执行模式下进行训练，您需要调用函数<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile" rel="noopener ugc nofollow" target="_blank"> model.compile() </a>,并将run _ eagerly标志设置为true。</p><p id="7333" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">底线是，当你训练时，以图形模式运行，当你调试时，以急切执行模式运行。不幸的是，某些bug只在图形模式下重现而不在急切执行模式下重现的情况并不少见，这实在令人失望。此外，当您在本地环境中调试时，急切执行很有帮助，但在云中就不那么有用了。在调试<em class="md">怪物bug</em>的时候往往不是很有用...除非你首先找到一种方法在你的本地环境中重现这个bug(下面会详细介绍)。</p><h2 id="1c5e" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">TensorFlow日志记录和调试实用程序</h2><p id="ce28" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">尽量利用TensorFlow测井仪。调试问题时，请将记录器设置为信息最丰富的级别。</p><p id="c6d1" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated"><a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/debugging" rel="noopener ugc nofollow" target="_blank"> tf.debugging </a>模块提供了一堆断言实用程序以及数字检查功能。特别是，<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/debugging/enable_check_numerics" rel="noopener ugc nofollow" target="_blank">TF . debugging . enable _ check _ numerics</a>实用程序有助于找出有问题的函数。</p><p id="0380" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated"><a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/print" rel="noopener ugc nofollow" target="_blank"> tf.print </a>函数能够打印出任意的图形张量，这是一个额外的实用程序，我发现它对调试非常有用。</p><p id="6f3e" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">最后但同样重要的是，添加您自己的打印日志(在代码的非图形部分)，以便更好地了解您的程序出故障的地方。</p><h2 id="96e9" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">解密张量流错误消息</h2><p id="60a9" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">有时候，你会幸运地得到一个TensorFlow错误消息。不幸的是，如何使用它们并不总是一目了然。我经常收到同事发来的带有神秘TensorFlow信息的邮件，请求帮助。当我看到消息时，例如:</p><pre class="kg kh ki kj gt kw kx ky kz aw la bi"><span id="2946" class="lb lc iq kx b gy ld le l lf lg">tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [5,229376] vs. shape[2] = [3,1]</span></pre><p id="1983" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">或者</p><pre class="kg kh ki kj gt kw kx ky kz aw la bi"><span id="1311" class="lb lc iq kx b gy ld le l lf lg">node DatasetToGraphV2 (defined at main.py:152) (1) Failed precondition: Failed to serialize the input pipeline graph: Conversion to GraphDef is not supported.</span></pre><p id="d43c" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">或者</p><pre class="kg kh ki kj gt kw kx ky kz aw la bi"><span id="5318" class="lb lc iq kx b gy ld le l lf lg">ValueError: slice index -1 of dimension 0 out of bounds. for 'loss/strided_slice' (op: 'StridedSlice') with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = &lt;-1&gt;, input[2] = &lt;0&gt;, input[3] = &lt;1&gt;.</span></pre><p id="c997" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">我问自己(稍微修改了一下，使帖子对孩子友好)“我到底应该怎么做？”或者“为什么友好的TensorFlow工程师不能给我更多的工作呢？”。但我很快让自己平静下来，(有时借助酒精饮料)，并说:“Chaim，不要被宠坏了。回去工作吧，感谢你收到了任何信息。”你应该做的第一件事，是尝试在急切执行模式下重现错误，和/或使用调试器。不幸的是，如上所述，这并不总是有帮助。</p><p id="db3a" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">无可争议的事实是，像上面这样的信息是没有多大帮助的。但是不要绝望。有时候，在一些调查工作的帮助下，你会发现一些线索，可能会把你引向正确的方向。仔细检查调用堆栈，看它是否提供了任何提示。如果信息包括形状大小，试着将它们与你的图形中可能具有相同形状的张量进行匹配。当然还有网上搜一下，看看别人有没有遇到过类似的问题，在什么场景下。不要绝望。</p><h2 id="e5d8" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">在本地环境中运行</h2><p id="a376" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">自然，在本地环境中调试比在远程机器或云中调试更容易。当您第一次创建模型时尤其如此。你的目标应该是在开始远程训练之前，在你当地的环境中解决尽可能多的问题。否则，你很可能会浪费大量的时间和金钱。</p><p id="0215" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">为了提高可再现性，您应该尽量使您的本地环境与远程环境相似。如果您在远程环境中使用docker映像或虚拟环境，请尝试在本地使用相同的映像或虚拟环境。(如果你的远程培训是在亚马逊SageMaker上，你可以<a class="ae kv" href="https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-pull-ecr-image.html" rel="noopener ugc nofollow" target="_blank">调出所用的docker图片</a>。)</p><p id="ad24" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">当然，远程培训环境中的某些要素可能无法在本地复制。例如，你可能遇到了一个只有在使用<a class="ae kv" href="https://aws.amazon.com/blogs/machine-learning/using-pipe-input-mode-for-amazon-sagemaker-algorithms/" rel="noopener ugc nofollow" target="_blank">亚马逊SageMaker管道模式</a>时才会重现的bug，目前只有在云中运行时才支持。(在这种情况下，您可以考虑使用<a class="ae kv" href="https://medium.com/@julsimon/deep-dive-on-tensorflow-training-with-amazon-sagemaker-and-amazon-s3-12038828075c" rel="noopener">替代方法从s3 </a>访问您的数据。)</p><p id="4f11" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">我希望我能告诉你，这里描述的技术将解决你所有的问题。但是，唉，事实并非如此。在下一节中，我们将回到我们上面举例说明的<em class="md">怪物bug </em>场景，并介绍最后一种调试技术。</p><h1 id="e7fa" class="me lc iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">使用TensorFlow自定义训练循环进行调试</h1><p id="64a9" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">在我们上面描述的场景中，经过几天的训练，模型的特定状态和特定训练批次样本的组合，突然导致损失变成NaN。</p><p id="9762" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">让我们评估一下如何使用上面的调试技术来调试这个问题。</p><ul class=""><li id="5ea4" class="nl nm iq lj b lk ll ln lo lq nn lu no ly np mc nq nr ns nt bi translated">如果我们对用于所有随机操作的种子保持细致的跟踪，并且没有不受控制的非确定性事件，那么理论上我们可以通过从头开始训练来重现bug...但那需要几天时间。</li><li id="c258" class="nl nm iq lj b lk nu ln nv lq nw lu nx ly ny mc nq nr ns nt bi translated">在本地环境中或在急切执行模式下进行复制可能需要几周时间。</li><li id="81d7" class="nl nm iq lj b lk nu ln nv lq nw lu nx ly ny mc nq nr ns nt bi translated">我们可以从最近的检查点恢复，但是如果我们可以从完全相同的样本恢复，并且具有所有伪随机生成器的完全相同的状态，我们将只能再现相同的模型状态和批样本。</li><li id="42c9" class="nl nm iq lj b lk nu ln nv lq nw lu nx ly ny mc nq nr ns nt bi translated">添加<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/print" rel="noopener ugc nofollow" target="_blank"> tf.prints </a>会有所帮助，但是会带来巨大的开销</li><li id="345e" class="nl nm iq lj b lk nu ln nv lq nw lu nx ly ny mc nq nr ns nt bi translated">添加<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/debugging/enable_check_numerics" rel="noopener ugc nofollow" target="_blank">TF . debugging . enable _ check _ numerics</a>将非常有助于查明它失败的函数。如果函数中有明显的bug，这可能就足够了。但是这并不能让我们重现这个错误。</li></ul><p id="515a" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">理想情况下，我们将能够在损失变得不可收拾之前捕获输入和模型状态。然后，我们可以在受控(本地)环境中，以急切执行模式和调试器重现该问题。</p><p id="2907" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">问题是我们不知道问题将要发生，直到它真正发生。当损失被报告为NaN时，模型已经用NaN权重更新，并且导致错误的批次样本已经被迭代。</p><p id="0d8c" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">我想提出的解决方案是定制训练循环，以便我们记录每一步的当前样本，并且仅在梯度有效时更新模型权重。如果梯度无效，我们将停止训练并连同当前模型快照一起转储出最后一批样本。这可以带到您的本地环境中，在那里您加载模型，并在急切执行模式下输入捕获的数据样本，以便重现(并解决)bug。</p><p id="878e" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">我们一会儿将讨论代码，但是首先，说几句使用定制训练循环的利与弊。</p><h2 id="cff1" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">定制培训循环与高级API</h2><p id="cc3f" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">TensorFlow用户之间有一个由来已久的争议，即是否要编写定制的训练循环或依赖于高级API，如<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit" rel="noopener ugc nofollow" target="_blank"> tf.keras.model.fit </a>()。</p><p id="a895" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">定制培训循环的支持者，预示着对如何执行培训进行逐行控制的能力，以及创造性的自由。高级API的支持者称它提供了许多便利，最显著的是内置的回调实用程序和分布式策略支持。使用高级API还可以确保您使用的是一个无错误的、高度优化的训练循环实现。</p><p id="f72b" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">从2.2版本开始，TensorFlow引入了覆盖<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="noopener ugc nofollow" target="_blank"> tf.keras.model </a>类的<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#train_step" rel="noopener ugc nofollow" target="_blank"> train_step </a>和<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#make_train_function" rel="noopener ugc nofollow" target="_blank"> make_train_function </a>例程的能力。这使用户能够引入某种程度的定制，同时继续享受model.fit()的便利。我们将演示如何以这样一种方式覆盖这些函数，使我们能够捕获有问题样本输入和模型状态，以便进行本地调试。</p><h2 id="44c6" class="lb lc iq bd mf na nb dn mj nc nd dp mn lq ne nf mp lu ng nh mr ly ni nj mt nk bi translated">自定义采集循环</h2><p id="257a" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">在下面的代码块中，我们使用train_step和make_train_functions例程的自定义实现来扩展tf.keras.models.Model对象。为了全面理解这个实现，我建议您将它与github 中例程的<a class="ae kv" href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/engine/training.py#L716-L760" rel="noopener ugc nofollow" target="_blank">默认实现进行比较。您会注意到，为了使代码更具可读性，我删除了所有与指标计算和策略支持相关的逻辑。需要注意的主要变化是:</a></p><ul class=""><li id="3a7e" class="nl nm iq lj b lk ll ln lo lq nn lu no ly np mc nq nr ns nt bi translated">在将梯度应用到模型权重之前，我们测试NaN的梯度。只有当NaN不出现时，渐变才会应用于权重。否则，向训练循环发送遇到错误的信号。信号的一个例子可以是将损耗设置为预定值，例如零或NaN。</li><li id="8861" class="nl nm iq lj b lk nu ln nv lq nw lu nx ly ny mc nq nr ns nt bi translated">训练循环存储每一步的数据特征和标签(x和y)。注意，为了做到这一点，我们将数据集遍历(下一个(迭代器)调用)移到了@tf.function范围之外。</li><li id="7435" class="nl nm iq lj b lk nu ln nv lq nw lu nx ly ny mc nq nr ns nt bi translated">该类有一个布尔“崩溃”标志，通知主函数是否遇到了错误。</li></ul><pre class="kg kh ki kj gt kw kx ky kz aw la bi"><span id="7e9c" class="lb lc iq kx b gy ld le l lf lg"><strong class="kx ir">class</strong> <strong class="kx ir">CustomKerasModel</strong>(tf.keras.models.Model):<br/>    <strong class="kx ir">def</strong> __init__(self, **kwargs):<br/>        super(CustomKerasModel, self).__init__(**kwargs)<br/><br/>        <em class="md"># boolean flag that will signal to main function that <br/>        # an error was encountered</em><br/>        self.crash = <strong class="kx ir">False</strong><br/><br/>    @tf.function<br/>    <strong class="kx ir">def</strong> train_step(self, data):<br/>        x, y = data<br/><br/>        <strong class="kx ir">with</strong> tf.GradientTape() <strong class="kx ir">as</strong> tape:<br/>            y_pred = self(x, training=<strong class="kx ir">True</strong>)  <em class="md"># Forward pass</em><br/>            <em class="md"># Compute the loss value</em><br/>            <em class="md"># (the loss function is configured in `compile()`)</em><br/>            loss = self.compiled_loss(<br/>                     y, y_pred, regularization_losses=self.losses)<br/><br/>        <em class="md"># Compute gradients</em><br/>        trainable_vars = self.trainable_variables<br/>        gradients = tape.gradient(loss, trainable_vars)<br/><br/>        <em class="md"># concatenate the gradients into a single tensor for testing</em><br/>        concat_grads = <br/>                tf.concat([tf.reshape(g,[-1]) <strong class="kx ir">for</strong> g <strong class="kx ir">in</strong> gradients],0)<br/><br/>        <em class="md"># In this example, we test for NaNs, <br/>        # but we can include other tests</em><br/>        <strong class="kx ir">if</strong> tf.reduce_any(tf.math.is_nan(concat_grads)):<br/>            <em class="md"># if any of the gradients are NaN, send a signal to the  <br/>            # outer loop and halt the training. We choose to signal<br/>            # to the outer loop by setting the loss to 0.</em><br/>            <strong class="kx ir">return</strong> {'loss': 0.}<br/>        <strong class="kx ir">else</strong>:<br/>            <em class="md"># Update weights</em><br/>            self.optimizer.apply_gradients(<br/>                       zip(gradients, trainable_vars))<br/>            <strong class="kx ir">return</strong> {'loss': loss}<br/><br/>    <strong class="kx ir">def</strong> make_train_function(self):<br/>        <strong class="kx ir">if</strong> self.train_function <strong class="kx ir">is</strong> <strong class="kx ir">not</strong> <strong class="kx ir">None</strong>:<br/>            <strong class="kx ir">return</strong> self.train_function<br/><br/>        <strong class="kx ir">def</strong> train_function(iterator):<br/>            data = next(iterator)<br/>            <em class="md"># records the current sample</em><br/>            self.x, self.y = data<br/>            res = self.train_step(data)<br/>            <strong class="kx ir">if</strong> res['loss'] == 0.:<br/>                self.crash = <strong class="kx ir">True</strong><br/>                <strong class="kx ir">raise</strong> <strong class="kx ir">Exception</strong>()<br/>            <strong class="kx ir">return</strong> res<br/><br/>        self.train_function = train_function<br/>        <strong class="kx ir">return</strong> self.train_function<br/><br/><strong class="kx ir">if</strong> __name__ == '__main__':<br/><br/>    <em class="md"># train_ds = </em><br/>    <em class="md"># inputs = </em><br/>    <em class="md"># outputs =</em><br/>    <em class="md"># optimizer =</em><br/>    <em class="md"># loss =  </em><br/>    <em class="md"># epochs =</em><br/>    <em class="md"># steps_per_epoch = </em><br/>    model = CustomKerasModel(inputs=inputs, outputs=outputs)<br/>    opt = tf.keras.optimizers.Adadelta(1.0)<br/><br/>    model.compile(loss=loss, optimizer=optimizer)<br/><br/>    <strong class="kx ir">try</strong>:<br/>        model.fit(train_ds, epochs=epochs,                         <br/>                  steps_per_epoch=steps_per_epoch)<br/>    <strong class="kx ir">except</strong> <strong class="kx ir">Exception</strong> <strong class="kx ir">as</strong> e:<br/>        <em class="md"># check for signal</em><br/>        <strong class="kx ir">if</strong> model.crash:<br/>            model.save_weights('model_weights.ckpt')<br/>            <em class="md"># pickle dump model.x and model.y</em><br/>            features_dict = {}<br/>            <strong class="kx ir">for</strong> n, v <strong class="kx ir">in</strong> model.x.items():<br/>                features_dict[n] = v.numpy()<br/>            <strong class="kx ir">with</strong> open('features.pkl','wb') <strong class="kx ir">as</strong> f:<br/>                pickle.dump(features_dict,f)<br/>            labels_dict = {}<br/>            <strong class="kx ir">for</strong> n, v <strong class="kx ir">in</strong> model.y.items():<br/>                labels_dict[n] = v.numpy()<br/>            <strong class="kx ir">with</strong> open('labels.pkl', 'wb') <strong class="kx ir">as</strong> f:<br/>                pickle.dump(labels_dict, f)<br/>            <strong class="kx ir">raise</strong> e</span></pre><p id="4f00" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">值得注意的是，这种技术有一个小的训练运行时成本，它来自于以急切执行模式而不是图形模式从数据集中读取数据。(天下没有免费的午餐。)精确的成本将取决于模型的大小；模型越大，感觉到的变化就越小。您应该在自己的模型上评估这种技术的开销，然后决定是否以及如何使用它。</p><h1 id="2c43" class="me lc iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">摘要</h1><p id="c4c7" class="pw-post-body-paragraph lh li iq lj b lk mv jr lm ln mw ju lp lq mx ls lt lu my lw lx ly mz ma mb mc ij bi translated">只要我们人类参与到人工智能应用的开发中，编程错误的流行几乎是肯定的。在设计代码时考虑到可调试性，并获得解决bug的工具和技术，可能会防止一些严重的问题。</p><p id="4254" class="pw-post-body-paragraph lh li iq lj b lk ll jr lm ln lo ju lp lq lr ls lt lu lv lw lx ly lz ma mb mc ij bi translated">最重要的是，不要绝望。</p></div></div>    
</body>
</html>