<html>
<head>
<title>End to End Adaptation of ResNet in Google Colab — Part 4: Training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google Colab中ResNet的端到端适配—第4部分:培训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/end-to-end-adaptation-of-resnet-in-google-colab-part-4-training-fad7d5bff1df?source=collection_archive---------52-----------------------#2020-11-03">https://towardsdatascience.com/end-to-end-adaptation-of-resnet-in-google-colab-part-4-training-fad7d5bff1df?source=collection_archive---------52-----------------------#2020-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="6cc0" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/end2end" rel="noopener" target="_blank">端到端ResNet </a></h2><div class=""/><div class=""><h2 id="1bd5" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">继续，但现在是“大卡哈纳”</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/243e3f72c0aedaaf3e0e30e351f23e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kpALqjlWoQSz6Ysu"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://unsplash.com/photos/rD2dc_2S3i0" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="0d56" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，我们必须解决整个项目的核心问题，以及在此之前的所有问题，以便无缝地进行培训——下载数据集，格式化所有内容以便输入网络，为图像处理创建数据转换，以及创建有助于以结构化方式插入图像的数据加载器。</p><p id="c674" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你刚刚加入，我已经做了一个colab笔记本，让你运行整个代码(一次点击)，最后，允许你上传一张图片进行测试。这个特殊的数据集和网络旨在区分狗和猫，但你可以上传任何你想生成输出的图片。</p><p id="0669" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这样做实际上是很有启发性的，尤其是对你将来想做的任何工作。<strong class="lh ja">了解基础数据、其问题和偏差对于解释结果至关重要。</strong>每个数据集都有偏差，都是不完美的，这并不一定意味着它是无用的。</p><p id="dc1d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">以下是前面部分的链接:</p><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/end-to-end-adaptation-of-resnet-in-google-colab-part-1-5e56fce934a6"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">Google Colab中ResNet的端到端改编—第1部分</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">只需点击几下鼠标，就能训练出一个深度神经网络</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms ky me"/></div></div></a></div><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/end-to-end-adaptation-of-resnet-in-google-colab-part-2-hardware-dataset-setup-f23dd4e0004d"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">Google Colab中ResNet的端到端适配—第2部分:硬件和数据集设置</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">评估您的硬件— CPU和GPU，并设置您的数据集</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="mt l mp mq mr mn ms ky me"/></div></div></a></div><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/end-to-end-adaptation-of-resnet-in-google-colab-part-3-image-pre-processing-fe30917d9aa2"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">Google Colab中ResNet的端到端适配第3部分:图像预处理</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">为训练准备数据集</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="mu l mp mq mr mn ms ky me"/></div></div></a></div><p id="ae13" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面我们先来解开train_model到底是怎么回事:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="3752" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我粘贴了上面的整个函数，只是为了大致了解它有多大，但它将被分成几个部分:</p><h1 id="2f48" class="mx my iq bd mz na nb nc nd ne nf ng nh kf ni kg nj ki nk kj nl kl nm km nn no bi translated">几个定义</h1><p id="e16c" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo nr lq lr ls ns lu lv lw nt ly lz ma ij bi translated"><strong class="lh ja"> Epoch </strong> —底层数据对模型的一个完整呈现(呃，<em class="nu">架构，</em>正如我告诉自己我会说的)。</p><p id="2999" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">训练阶段</strong> —如果您还记得，我们使用了75/25的比率(80/20和70/30也很常见)，我们随机分割数据集，将75%分配给训练集，25%分配给验证集。随机地做是很重要的，因为如果你把所有的图片都按顺序排列，如果不随机的话，你可能会在训练阶段过度表现狗或猫(结果，架构会更好地“训练”一种动物而不是另一种动物)。</p><p id="8111" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">验证阶段</strong> —我们分配给验证集的25%不应用于培训。这是向网络显示新数据的最佳方式，以查看它是否学习得很好。就像教一个孩子加法一样，你不会想提出同样的问题，而是一个<em class="nu">相似的</em>问题来看看孩子是否学会了加法。</p><p id="e03a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">优化零毕业生</strong>——这本身并不是一个“词汇”术语，但知道这一点很重要。当梯度在小批量中生成时，它们将继续传播通过(这是每个训练周期所不希望的；你想重新开始)。zero_grad功能使您能够为每个迷你批次重新开始计算梯度。</p><h1 id="9417" class="mx my iq bd mz na nb nc nd ne nf ng nh kf ni kg nj ki nk kj nl kl nm km nn no bi translated">重物搬运</h1><p id="8d49" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo nr lq lr ls ns lu lv lw nt ly lz ma ij bi translated">大部分繁重的工作都在这里完成:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="522f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一个if/else语句将模型设置为训练或评估模式(pytorch特性)。默认情况下，模型处于训练模式。有趣的是，如果您不使用dropout layers或批处理规范化，这个约定并不太重要，但是拥有这个约定对于将来验证您的代码(以及您如何使用pytorch)是非常重要的。</p><p id="29d6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后使用数据加载器迭代数据，并使用“inputs.to(device)”和“labels.to(device)”行将代码加载到GPU中。我们之前讨论过通过Colab使用高端GPU的能力。</p><p id="228a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">with torch . set _ grad _ enabled(phase = = ' train ')-括号仅在阶段确实处于训练模式时为真，允许在训练模式期间计算梯度，loss.backward(同样，在训练期间)将计算梯度，optimizer.step使用最近的计算更新所有梯度。</p><p id="d1ef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，如果阶段不是列车，则set_grad_enabled变为False，不计算梯度，也不更新任何内容。模型只评估输入的图像(这是你在训练中想要的)。</p><p id="b675" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">“scheduler.step()”是一行很小的代码，但是对于获得更低的错误率是至关重要的。改变学习率对超参数调整至关重要。开始时，你希望学习率高，这样才有效，随着训练的进行，你希望降低学习率。想象一下，试图找到一个领域的最低点。你希望一开始就迈出大步，这样你就不会错过任何山谷，也不会被困在地图的一个小角落里。但是当你发现山谷时，你不会想在山谷的墙壁上反弹，因为你的脚步很大。让你的步数(这里是学习率)变小会让你更有效地找到最低点。</p><p id="093c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，计算精度，并且如果该特定精度的历元比最佳精度(初始设置为0)好，则更新best_acc变量，并且也更新模型权重，并且重复整个过程。</p><h1 id="a457" class="mx my iq bd mz na nb nc nd ne nf ng nh kf ni kg nj ki nk kj nl kl nm km nn no bi translated"><strong class="ak">模型下载&amp;参数确定</strong></h1><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="9189" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">名副其实，我们使用的是Resnet18型号。全连接层(model_ft.fc)有两个最终输出(猫对狗)。然后，我们将模型加载到GPU上，并将损失函数定义为<strong class="lh ja"> CrossEntropyLoss </strong>。</p><p id="f1c4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对这个损失函数的讨论超出了一个介绍性系列，但可以说，它非常常用于分类(而不是回归)模型，并且被许多其他帖子和视频所涵盖。</p><p id="82df" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">优化函数(<strong class="lh ja">SGD——随机梯度下降</strong>)也是我鼓励你阅读(或观看youtube视频)的内容。</p><p id="6109" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后是学习率调度器——如上所述，我们希望学习率随着epoch #变大而变小，以便更好地微调架构(权重)和降低损耗。</p><p id="c24f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，我们将所有这些放在一起，让它运行:</p><pre class="kp kq kr ks gt nv nw nx ny aw nz bi"><span id="e815" class="oa my iq nw b gy ob oc l od oe">model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=10)</span></pre><p id="b79d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我建议你至少做5-10个周期来说服自己有一个合理的停止点，迭代超过100个周期会大大减少收益。</p><p id="af27" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你正在阅读上面的文章，并发现它过于简单，我为你领先我几光年而鼓掌。但是，如果上面的某些部分没有意义，请留下评论，我会将您连接到适当的资源。</p><p id="4960" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">本系列的目标不是深入研究神经网络——我没有资格这么做。我们的目标是让您相信这种架构对您来说是可行的，您可以在高端计算上运行它，并上传您自己的映像以供最终测试——我已经对此进行了概述。</p><p id="ef0e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下一次——上传一张照片和相关的细节。</p><h1 id="d522" class="mx my iq bd mz na nb nc nd ne nf ng nh kf ni kg nj ki nk kj nl kl nm km nn no bi translated">参考</h1><p id="1b6a" class="pw-post-body-paragraph lf lg iq lh b li np ka lk ll nq kd ln lo nr lq lr ls ns lu lv lw nt ly lz ma ij bi translated">[1] <a class="ae le" href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" rel="noopener ugc nofollow" target="_blank">深度学习用Pytorch </a>，2020年10月访问</p><p id="958e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2] <a class="ae le" href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html" rel="noopener ugc nofollow" target="_blank">神经网络与Pytorch。【2020年10月访问</a></p><p id="7c3e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">【3】<a class="ae le" href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html" rel="noopener ugc nofollow" target="_blank">计算机视觉的迁移学习。2020年10月访问</a></p><p id="66bc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[4] <a class="ae le" href="https://github.com/Kaggle/kaggle-api" rel="noopener ugc nofollow" target="_blank"> Kaggle API。</a>2020年10月访问</p></div></div>    
</body>
</html>