<html>
<head>
<title>Introducing PyTorch Forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch预测简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introducing-pytorch-forecasting-64de99b9ef46?source=collection_archive---------1-----------------------#2020-09-19">https://towardsdatascience.com/introducing-pytorch-forecasting-64de99b9ef46?source=collection_archive---------1-----------------------#2020-09-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/6d366673f5947990aded111188def0fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L8iOJqsoXThGiqjTJ50p3g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">PyTorch预测示例</p></figure><div class=""/><div class=""><h2 id="180f" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated"><strong class="ak">最先进的神经网络预测变得简单</strong></h2></div><p id="a4d6" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我很高兴地宣布开源Python包<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyTorch预测</a>。对于数据科学从业者和研究人员来说，它使得用神经网络进行时间序列预测变得简单。</p><h1 id="1b77" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated"><strong class="ak">为什么准确预测如此重要？</strong></h1><p id="d43c" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">预测时间序列在许多情况下都很重要，并且与机器学习实践者高度相关。举个例子，需求预测是许多用例的来源。几乎每个制造商都会受益于更好地了解对其产品的需求，从而优化生产数量。生产不足，你会损失收入，生产过度，你将被迫折价出售多余的产品。与此密切相关的是定价，它本质上是一种需求预测，特别关注价格弹性。定价几乎与所有公司都相关。</p><p id="62ee" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">对于大量额外的机器学习应用，时间是至关重要的:预测性维护、风险评分、欺诈检测等。—你说吧。事件的顺序和它们之间的时间对于创建可靠的预测至关重要。</p><p id="ab45" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">事实上，虽然时间序列预测可能不像图像识别或语言处理那样耀眼，但它在工业中更常见。这是因为图像识别和语言处理对该领域来说相对较新，通常用于推动新产品，而预测已经存在了几十年，是许多决策(支持)系统的核心。<strong class="kz jj">采用高精度机器学习模型，如</strong> <a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj"> PyTorch预测</strong> </a> <strong class="kz jj">中的模型，可以更好地支持决策制定，甚至使其自动化，往往会直接带来数百万美元的额外利润。</strong></p><h2 id="5329" class="mr lv ji bd lw ms mt dn ma mu mv dp me lg mw mx mg lk my mz mi lo na nb mk nc bi translated">深度学习成为一种强大的预测工具</h2><p id="7b7a" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">深度学习(神经网络)只是在最近才在时间序列预测方面超过传统方法，而且与图像和语言处理相比，差距较小。事实上，在预测纯时间序列(这意味着没有协变量，例如，价格对需求)时，<a class="ae lt" href="https://eng.uber.com/m4-forecasting-competition" rel="noopener ugc nofollow" target="_blank">深度学习仅在两年前就已经超越了传统的统计方法</a> [1]。然而，随着该领域的快速发展，与神经网络相关的<strong class="kz jj">准确性优势变得显著</strong>，这使得它们在时间序列预测中的应用越来越多。例如，最新的架构<a class="ae lt" href="https://openreview.net/forum?id=r1ecqn4YwB" rel="noopener ugc nofollow" target="_blank"> N-BEATS </a>在M4竞赛数据集上显示，与下一个最好的非基于神经网络的方法(即统计方法的集合)相比，sMAPE减少了11%。这个网络也在<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io/en/latest/api/pytorch_forecasting.models.nbeats.NBeats.html" rel="noopener ugc nofollow" target="_blank"> PyTorch预报</a>中实现。</p><p id="dd3d" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">此外，即使与其他流行的机器学习算法(如梯度提升树)相比，深度学习也有两个优势。首先，<strong class="kz jj">神经网络架构可以设计为具有对时间的固有理解</strong>，即它们自动在时间上接近的数据点之间建立连接。因此，它们可以捕捉复杂的时间依赖关系。相反，传统的机器学习模型需要手动创建时间序列特征，例如过去x天的平均值。这削弱了这些传统机器学习算法对时间依赖性建模的能力。第二，大多数基于树的模型通过设计输出阶跃函数。因此，它们不能预测投入变化的边际影响，而且，众所周知，在域外预测中它们是不可靠的。例如，如果我们只观察到30欧元和50欧元的价格，则基于树的模型无法评估价格从30欧元变为35欧元对需求的影响。因此，它们通常不能直接用于优化投入。然而，这通常是创建机器学习模型的全部目的——价值在于协变量的优化。<strong class="kz jj">与此同时，神经网络采用连续激活函数，尤其擅长高维空间的插值，即它们可用于优化输入，如价格。</strong></p><h1 id="c993" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated"><strong class="ak">什么是PyTorch预测？</strong></h1><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/609143aa435ec666fd949642f9725c87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rljR4jjmzOitL41tpqjg-w.png"/></div></div></figure><p id="6549" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyTorch Forecasting </a>旨在通过神经网络简化现实世界案例和研究的时间序列预测。<strong class="kz jj">它通过提供最先进的时间序列预测架构来做到这一点，这些架构可以通过</strong> <a class="ae lt" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj"> pandas </strong> </a> <strong class="kz jj">数据框架轻松训练。</strong></p><ul class=""><li id="4b90" class="ni nj ji kz b la lb ld le lg nk lk nl lo nm ls nn no np nq bi translated">这个高级API极大地减少了用户的工作量，因为不需要具体的知识来准备使用PyTorch进行训练的数据集。<code class="fe nr ns nt nu b">TimeSeriesDataSet</code>类负责变量转换、缺失值、随机子采样、多历史长度等。您只需要提供pandas数据框架，并指定模型应该学习哪些变量。</li><li id="3e35" class="ni nj ji kz b la nv ld nw lg nx lk ny lo nz ls nn no np nq bi translated"><code class="fe nr ns nt nu b">BaseModel</code>类提供了通用的可视化，比如显示预测与实际值和部分依赖图。培训进度以指标和示例的形式自动记录在<a class="ae lt" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank"> tensorboard </a>中。</li><li id="116c" class="ni nj ji kz b la nv ld nw lg nx lk ny lo nz ls nn no np nq bi translated">国家的最先进的网络实施预测有和没有协变量。它们还带有专用的内置翻译功能。例如，<a class="ae lt" href="https://arxiv.org/pdf/1912.09363.pdf" rel="noopener ugc nofollow" target="_blank">时态融合转换器</a> [3]在基准测试中击败了亚马逊的DeepAR 36–69 %,提供了变量和时间重要性测量。在下面的例子中可以看到更多。</li><li id="72ba" class="ni nj ji kz b la nv ld nw lg nx lk ny lo nz ls nn no np nq bi translated">存在许多多时段时间序列指标来评估多个预测时段的预测。</li><li id="de64" class="ni nj ji kz b la nv ld nw lg nx lk ny lo nz ls nn no np nq bi translated">为了实现可扩展性，网络被设计为与<a class="ae lt" href="https://pytorch-lightning.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning </a>一起工作，后者允许对CPU和单个及多个(分布式)GPU进行开箱即用的培训。Ranger优化器用于更快的模型训练。</li><li id="e094" class="ni nj ji kz b la nv ld nw lg nx lk ny lo nz ls nn no np nq bi translated">为了便于实验和研究，增加网络是很简单的。代码是专门为PyTorch专家设计的。他们会发现即使是复杂的想法也很容易实现。事实上，为了立即启用日志和解释功能，只需从<code class="fe nr ns nt nu b">BaseModel</code>类继承并遵循forward方法输入和输出的约定。</li></ul><p id="3b7b" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">首先，文档展示了端到端工作流中的详细教程。我还将在本文后面讨论一个具体的例子。</p><h1 id="a5bd" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated">我们为什么需要这个包？</h1><p id="4f6d" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated"><a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj"> PyTorch预测</strong> </a> <strong class="kz jj">有助于克服深度学习用法的重要障碍。</strong>虽然深度学习已经在图像和语言处理中占据主导地位，但在时间序列预测中却不那么重要。该领域仍由传统的统计方法(如ARIMA)和机器学习算法(如梯度推进)占据主导地位，贝叶斯模型例外。深度学习尚未成为时间序列预测主流的原因有两个，所有这些都已经可以克服:</p><ol class=""><li id="c944" class="ni nj ji kz b la lb ld le lg nk lk nl lo nm ls oa no np nq bi translated">训练神经网络几乎总是需要GPU，而GPU并不总是容易获得。硬件需求通常是一个重要的障碍。然而，通过将计算转移到云中，这个障碍是可以克服的。</li><li id="19aa" class="ni nj ji kz b la nv ld nw lg nx lk ny lo nz ls oa no np nq bi translated">神经网络比传统方法更难使用。时间序列预测尤其如此。缺少一个与流行框架协同工作的高级API，如脸书的PyTorch或谷歌的Tensorflow。对于传统的机器学习，sci-kit learn生态系统的存在为从业者提供了一个标准化的界面。</li></ol><p id="77fe" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这第三个障碍在深度学习社区被认为是至关重要的，因为它的用户友好性需要大量的软件工程。下面的推文总结了许多人的情绪:</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="ob oc l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">深度学习实践者的典型观点</p></figure><p id="9970" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">有些人甚至认为该声明微不足道:</p><figure class="ne nf ng nh gt iv"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="a883" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">简单来说，</strong> <a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj"> PyTorch预测</strong> </a> <strong class="kz jj">旨在做</strong><a class="ae lt" href="https://www.fast.ai" rel="noopener ugc nofollow" target="_blank"><strong class="kz jj">fast . ai</strong></a><strong class="kz jj">为图像识别和自然语言处理所做的事情。</strong>这极大地促进了神经网络从学术界向现实世界的扩散。<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyTorch Forecasting </a>试图通过为<a class="ae lt" href="https://pytorch.org" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>提供一个可以直接使用<a class="ae lt" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> pandas </a> dataframes的高级API来做时间序列预测的等效工作。为了便于学习，与<a class="ae lt" href="https://www.fast.ai" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>不同，该软件包没有创建一个全新的API，而是建立在成熟的<a class="ae lt" href="https://pytorch.org" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>和<a class="ae lt" href="https://pytorch-lightning.readthedocs.io" rel="noopener ugc nofollow" target="_blank">py torch Lightning</a>API的基础上。</p><h1 id="76c6" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated">如何使用PyTorch预测？</h1><p id="ae68" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">这个小例子展示了这个包的强大功能及其最重要的抽象。我们将</p><ol class=""><li id="4955" class="ni nj ji kz b la lb ld le lg nk lk nl lo nm ls oa no np nq bi translated">创建训练和验证数据集，</li><li id="2c13" class="ni nj ji kz b la nv ld nw lg nx lk ny lo nz ls oa no np nq bi translated">训练<a class="ae lt" href="https://arxiv.org/pdf/1912.09363.pdf" rel="noopener ugc nofollow" target="_blank">时间融合变压器</a>【2】。这是一个由牛津大学和谷歌开发的架构，在基准测试中击败了亚马逊的DeepAR 36–69 %,</li><li id="0efd" class="ni nj ji kz b la nv ld nw lg nx lk ny lo nz ls oa no np nq bi translated">检查验证集的结果并解释训练好的模型。</li></ol><p id="58a6" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">注</strong>:以下代码仅适用于PyTorch预报0.4.1版和PyTorch闪电0.9.0版。运行最新版本只需很少的修改。最新代码的完整教程可以在<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/stallion.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="c270" class="mr lv ji bd lw ms mt dn ma mu mv dp me lg mw mx mg lk my mz mi lo na nb mk nc bi translated">创建用于训练和验证的数据集</h2><p id="4d09" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">首先，我们需要将时间序列转换成pandas数据框架，其中每一行都可以用时间步长和时间序列来标识。幸运的是，大多数数据集已经是这种格式了。对于本教程，我们将使用来自Kaggle 的<a class="ae lt" href="https://www.kaggle.com/utathya/future-volume-prediction" rel="noopener ugc nofollow" target="_blank"> Stallion数据集来描述各种饮料的销售。我们的任务是对库存单位(SKU)的销售量进行六个月的预测，即由代理机构(即商店)销售的产品。大约有21 000个月的历史销售记录。除了历史销售额之外，我们还有销售价格、代理机构的位置、特殊日子(如节假日)以及整个行业的销售量等信息。</a></p><pre class="ne nf ng nh gt od nu oe of aw og bi"><span id="9efd" class="mr lv ji nu b gy oh oi l oj ok">from pytorch_forecasting.data.examples import get_stallion_data</span><span id="59c4" class="mr lv ji nu b gy ol oi l oj ok">data = get_stallion_data()  # load data as pandas dataframe</span></pre><p id="53bd" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">数据集的格式已经正确，但缺少一些重要的功能。最重要的是，我们需要添加一个时间索引，每个时间步长递增1。此外，添加日期特性是有益的，在这种情况下，这意味着从日期记录中提取月份。</p><pre class="ne nf ng nh gt od nu oe of aw og bi"><span id="67d5" class="mr lv ji nu b gy oh oi l oj ok"># add time index<br/>data["time_idx"] = data["date"].dt.year * 12 + data["date"].dt.monthdata["time_idx"] -= data["time_idx"].min()</span><span id="1904" class="mr lv ji nu b gy ol oi l oj ok"># add additional features<br/># categories have to be strings<br/>data["month"] = data.date.dt.month.astype(str).astype("category")<br/>data<strong class="nu jj">[</strong>"log_volume"<strong class="nu jj">]</strong> <strong class="nu jj">=</strong> np<strong class="nu jj">.</strong>log<strong class="nu jj">(</strong>data<strong class="nu jj">.</strong>volume <strong class="nu jj">+</strong> <strong class="nu jj">1e-8)</strong><br/>data<strong class="nu jj">[</strong>"avg_volume_by_sku"<strong class="nu jj">]</strong> <strong class="nu jj">=</strong> (<br/>    data<br/>    <strong class="nu jj">.</strong>groupby<strong class="nu jj">([</strong>"time_idx"<strong class="nu jj">,</strong> "sku"<strong class="nu jj">], </strong>observed<strong class="nu jj">=True)<br/>    .</strong>volume<strong class="nu jj">.</strong>transform<strong class="nu jj">(</strong>"mean"<strong class="nu jj">)<br/></strong>)<br/>data<strong class="nu jj">[</strong>"avg_volume_by_agency"<strong class="nu jj">]</strong> <strong class="nu jj">=</strong> (<br/>    data<br/>    <strong class="nu jj">.</strong>groupby<strong class="nu jj">([</strong>"time_idx"<strong class="nu jj">,</strong> "agency"<strong class="nu jj">], </strong>observed<strong class="nu jj">=True)<br/>    .</strong>volume<strong class="nu jj">.</strong>transform<strong class="nu jj">(</strong>"mean"<strong class="nu jj">)<br/>)</strong></span><span id="77e7" class="mr lv ji nu b gy ol oi l oj ok"># we want to encode special days as one variable and <br/># thus need to first reverse one-hot encoding<br/>special_days = [<br/>    "easter_day", "good_friday", "new_year", "christmas",<br/>    "labor_day", "independence_day", "revolution_day_memorial",<br/>    "regional_games", "fifa_u_17_world_cup", "football_gold_cup",<br/>    "beer_capital", "music_fest"<br/>]</span><span id="6933" class="mr lv ji nu b gy ol oi l oj ok">data[special_days] = (<br/>    data[special_days]<br/>    .apply(lambda x: x.map({0: "-", 1: x.name}))<br/>    .astype("category")<br/>)</span><span id="d3f0" class="mr lv ji nu b gy ol oi l oj ok"># show sample data<br/>data.sample(10, random_state=521)</span></pre><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi om"><img src="../Images/d0e4888a3dbd2b92c2daaf4dc8a26016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CvDOHQrI4Wk6a8x-8h6NmA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来自数据帧的随机行样本</p></figure><p id="37fb" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">下一步是将数据框架转换成<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyTorch预测</a>数据集。除了告诉数据集哪些特征是分类的，哪些是连续的，哪些是静态的，哪些是随时间变化的，我们还必须决定如何归一化数据。这里，我们分别对每个时间序列进行标准标度，并指出值总是正的。</p><p id="fd07" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们还选择使用过去六个月作为验证集。</p><pre class="ne nf ng nh gt od nu oe of aw og bi"><span id="4d8d" class="mr lv ji nu b gy oh oi l oj ok">from pytorch_forecasting.data import (<br/>    TimeSeriesDataSet,<br/>    GroupNormalizer<br/>)</span><span id="8507" class="mr lv ji nu b gy ol oi l oj ok">max_prediction_length = 6  # forecast 6 months<br/>max_encoder_length = 24  # use 24 months of history<br/>training_cutoff = data["time_idx"].max() - max_prediction_length</span><span id="be40" class="mr lv ji nu b gy ol oi l oj ok">training = TimeSeriesDataSet(<br/>    data[lambda x: x.time_idx &lt;= training_cutoff],<br/>    time_idx="time_idx",<br/>    target="volume",<br/>    group_ids=["agency", "sku"],<br/>    min_encoder_length=0,  # allow predictions without history<br/>    max_encoder_length=max_encoder_length,<br/>    min_prediction_length=1,<br/>    max_prediction_length=max_prediction_length,<br/>    static_categoricals=["agency", "sku"],<br/>    static_reals=[<br/>        "avg_population_2017",<br/>        "avg_yearly_household_income_2017"<br/>    ],<br/>    time_varying_known_categoricals=["special_days", "month"],<br/>    # group of categorical variables can be treated as <br/>    # one variable<br/>    variable_groups={"special_days": special_days},<br/>    time_varying_known_reals=[<br/>        "time_idx",<br/>        "price_regular",<br/>        "discount_in_percent"<br/>    ],<br/>    time_varying_unknown_categoricals=[],<br/>    time_varying_unknown_reals=[<br/>        "volume",<br/>        "log_volume",<br/>        "industry_volume",<br/>        "soda_volume",<br/>        "avg_max_temp",<br/>        "avg_volume_by_agency",<br/>        "avg_volume_by_sku",<br/>    ],<br/>    target_normalizer=GroupNormalizer(<br/>        groups=["agency", "sku"], coerce_positive=1.0<br/>    ),  # use softplus with beta=1.0 and normalize by group<br/>    add_relative_time_idx=True,  # add as feature<br/>    add_target_scales=True,  # add as feature<br/>    add_encoder_length=True,  # add as feature<br/>)</span><span id="6671" class="mr lv ji nu b gy ol oi l oj ok"># create validation set (predict=True) which means to predict the<br/># last max_prediction_length points in time for each series<br/>validation = TimeSeriesDataSet.from_dataset(<br/>    training, data, predict=True, stop_randomization=True<br/>)</span><span id="7bdb" class="mr lv ji nu b gy ol oi l oj ok"># create dataloaders for model<br/>batch_size = 128<br/>train_dataloader = training.to_dataloader(<br/>    train=True, batch_size=batch_size, num_workers=0<br/>)<br/>val_dataloader = validation.to_dataloader(<br/>    train=False, batch_size=batch_size * 10, num_workers=0<br/>)</span></pre><h2 id="68e7" class="mr lv ji bd lw ms mt dn ma mu mv dp me lg mw mx mg lk my mz mi lo na nb mk nc bi translated">训练时间融合转换器</h2><p id="eb56" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">现在是时候创建我们的模型了。我们用PyTorch闪电训练模型。在培训之前，您可以使用学习率查找器确定最佳学习率(参见<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/stallion.html#Train-PyTorch-Forecasting-model" rel="noopener ugc nofollow" target="_blank">文档</a>中的示例)。</p><pre class="ne nf ng nh gt od nu oe of aw og bi"><span id="9556" class="mr lv ji nu b gy oh oi l oj ok">import pytorch_lightning as pl<br/>from pytorch_lightning.callbacks import (<br/>    EarlyStopping,<br/>    LearningRateLogger<br/>)<br/>from pytorch_lightning.loggers import TensorBoardLogger<br/>from pytorch_forecasting.metrics import QuantileLoss<br/>from pytorch_forecasting.models import TemporalFusionTransformer</span><span id="232e" class="mr lv ji nu b gy ol oi l oj ok"># stop training, when loss metric does not improve on validation set<br/>early_stop_callback = EarlyStopping(<br/>    monitor="val_loss",<br/>    min_delta=1e-4,<br/>    patience=10,<br/>    verbose=False,<br/>    mode="min"<br/>)<br/>lr_logger = LearningRateLogger()  # log the learning rate<br/>logger = TensorBoardLogger("lightning_logs")  # log to tensorboard</span><span id="cc49" class="mr lv ji nu b gy ol oi l oj ok"># create trainer<br/>trainer = pl.Trainer(<br/>    max_epochs=30,<br/>    gpus=0,  # train on CPU, use gpus = [0] to run on GPU<br/>    gradient_clip_val=0.1,<br/>    early_stop_callback=early_stop_callback,<br/>    limit_train_batches=30,  # running validation every 30 batches<br/>    # fast_dev_run=True,  # comment in to quickly check for bugs<br/>    callbacks=[lr_logger],<br/>    logger=logger,<br/>)</span><span id="89c5" class="mr lv ji nu b gy ol oi l oj ok"># initialise model<br/>tft = TemporalFusionTransformer.from_dataset(<br/>    training,<br/>    learning_rate=0.03,<br/>    hidden_size=16,  # biggest influence network size<br/>    attention_head_size=1,<br/>    dropout=0.1,<br/>    hidden_continuous_size=8,<br/>    output_size=7,  # QuantileLoss has 7 quantiles by default<br/>    loss=QuantileLoss(),<br/>    log_interval=10,  # log example every 10 batches<br/>    reduce_on_plateau_patience=4,  # reduce learning automatically<br/>)<br/>tft.size() # 29.6k parameters in model</span><span id="5830" class="mr lv ji nu b gy ol oi l oj ok"># fit network<br/>trainer.fit(<br/>    tft,<br/>    train_dataloader=train_dataloader,<br/>    val_dataloaders=val_dataloader<br/>)</span></pre><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/a381cbea1a4c6764bd6285f93d50e5e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y1pgiNG1CB21FepP-eNw4Q.png"/></div></div></figure><p id="cbae" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">在我的Macbook上，训练大约需要三分钟，但对于更大的网络和数据集，可能需要几个小时。在训练过程中，我们可以监控<a class="ae lt" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank">张量板</a>，它可以用<code class="fe nr ns nt nu b">tensorboard --logdir=lightning_logs</code>旋转起来。例如，我们可以监控训练集和验证集上的示例预测。如下图所示，预测看起来相当准确。如果你想知道，灰线表示模型在进行预测时对不同时间点的关注程度。这是<a class="ae lt" href="https://arxiv.org/pdf/1912.09363.pdf" rel="noopener ugc nofollow" target="_blank">时间融合转换器</a>的一个特殊功能。</p><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oo"><img src="../Images/20c04b0fcdd69b755f045284f0e7fb6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9suwgfP5xgUgjPsoTSnGGw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">显示训练示例的Tensorboard面板</p></figure><h2 id="5e0e" class="mr lv ji bd lw ms mt dn ma mu mv dp me lg mw mx mg lk my mz mi lo na nb mk nc bi translated">评估已训练的模型</h2><p id="c881" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">训练之后，我们可以评估验证数据集和几个示例上的指标，以查看模型的表现如何。鉴于我们只对21 000个样本进行研究，结果非常令人放心，可以与梯度助推器的结果相媲美。</p><pre class="ne nf ng nh gt od nu oe of aw og bi"><span id="e902" class="mr lv ji nu b gy oh oi l oj ok">from pytorch_forecasting.metrics import MAE</span><span id="469f" class="mr lv ji nu b gy ol oi l oj ok"># load the best model according to the validation loss (given that<br/># we use early stopping, this is not necessarily the last epoch)<br/>best_model_path = trainer.checkpoint_callback.best_model_path<br/>best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)</span><span id="8e1c" class="mr lv ji nu b gy ol oi l oj ok"># calculate mean absolute error on validation set<br/>actuals = torch.cat([y for x, y in iter(val_dataloader)])<br/>predictions = best_tft.predict(val_dataloader)</span><span id="47d7" class="mr lv ji nu b gy ol oi l oj ok">MAE(predictions, actuals)</span></pre><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/19c855144e6296ca151536c2d499e04e.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*FQFSbRns_G6-6Z0PJfrcEg.png"/></div></figure><p id="04c2" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">从sMAPE的角度来看最差的表现，可以让我们了解模型在可靠预测方面的问题。这些例子可以为如何改进模型提供重要的指导。这种实际值与预测值的对比图适用于所有模型。</p><pre class="ne nf ng nh gt od nu oe of aw og bi"><span id="71ea" class="mr lv ji nu b gy oh oi l oj ok">from pytorch_forecasting.metrics import SMAPE</span><span id="63c5" class="mr lv ji nu b gy ol oi l oj ok"># calculate metric by which to display<br/>predictions, x = best_tft.predict(val_dataloader)<br/>mean_losses = SMAPE(reduction="none")(predictions, actuals).mean(1)<br/>indices = mean_losses.argsort(descending=True)  # sort losses</span><span id="9cbb" class="mr lv ji nu b gy ol oi l oj ok">raw_predictions, x = best_tft.predict(val_dataloader, mode="raw, return_x<strong class="nu jj">=True)</strong></span><span id="8a24" class="mr lv ji nu b gy ol oi l oj ok"># show only two examples for demonstration purposes<br/>for idx in range(2):<br/>    best_tft.plot_prediction(<br/>        x,<br/>        raw_predictions,<br/>        idx=indices[idx],<br/>        add_loss_to_title=SMAPE()<br/>    )</span></pre><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/c73baac85c3055cf66b82a9f7a5321d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*olt4CwVIznyLJCpDWHVpdA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">验证集上两个最差的预测。白线表示变压器对给定时间点的关注程度。</p></figure><p id="02d6" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">类似地，我们也可以从我们的模型中看到随机的例子。PyTorch预测的另一个特点是对训练好的模型进行解释。例如，所有的模型都允许我们容易地计算部分相关图。然而，为了简洁起见，我们将在这里展示时间融合转换器的一些内置解释功能。它通过设计神经网络来实现可变的重要性。</p><pre class="ne nf ng nh gt od nu oe of aw og bi"><span id="b53d" class="mr lv ji nu b gy oh oi l oj ok">interpretation = best_tft.interpret_output(<br/>    raw_predictions, reduction="sum"<br/>)</span><span id="fe51" class="mr lv ji nu b gy ol oi l oj ok">best_tft.plot_interpretation(interpretation)</span></pre><figure class="ne nf ng nh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/3e1165be860a39faac530752de9812d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DYm8utV38CDYr5wVV5eKxQ.png"/></div></div></figure><p id="a7f4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">不出所料，过去观察到的音量特征作为编码器中的首要变量和价格相关变量是解码器中的首要预测因素。也许更有趣的是，该机构在静态变量中仅排名第五。然而，考虑到第二个和第三个变量与位置有关，如果这两个变量不包括在模型中，我们可以预计代理机构的排名会高得多。</p><h1 id="059b" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated">摘要</h1><p id="f4e7" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">用<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyTorch Forecasting </a>训练一个模型并洞察其内部运作是非常容易的。作为从业者，您可以使用这个包来训练和解释开箱即用的最新模型。与<a class="ae lt" href="https://pytorch-lightning.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning </a>集成训练和预测是可扩展的。作为一名研究人员，您可以利用该包为您的架构获得自动跟踪和自省功能，并将其无缝地应用于多个数据集。</p><h1 id="a460" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated"><strong class="ak">代码、文档和如何投稿</strong></h1><p id="7349" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">本教程的代码可以在本笔记本中找到:<a class="ae lt" href="https://github.com/jdb78/pytorch-forecasting/blob/master/docs/source/tutorials/stallion.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/jdb 78/py torch-forecasting/blob/master/docs/source/tutorials/stallion . ipynb</a></p><p id="12ef" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">安装<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyTorch预测</a>和</p><pre class="ne nf ng nh gt od nu oe of aw og bi"><span id="4882" class="mr lv ji nu b gy oh oi l oj ok">pip install pytorch-forecasting</span></pre><p id="c791" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">或者</p><pre class="ne nf ng nh gt od nu oe of aw og bi"><span id="ce41" class="mr lv ji nu b gy oh oi l oj ok">conda install -c conda-forge pytorch-forecasting</span></pre><p id="2062" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">GitHub库:<a class="ae lt" href="https://github.com/jdb78/pytorch-forecasting" rel="noopener ugc nofollow" target="_blank">https://github.com/jdb78/pytorch-forecasting</a></p><p id="c79e" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">文档(包括教程):<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank">https://py torch-forecasting . readthedocs . io</a></p><p id="2d49" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">该软件包在允许商业使用的MIT许可下是开源的。非常欢迎投稿！请提前阅读<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io/en/latest/contribute.html" rel="noopener ugc nofollow" target="_blank">投稿指南</a>，以确保您的投稿被迅速合并。</p><h1 id="a497" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated">相关著作</h1><p id="4307" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated"><a class="ae lt" href="https://gluon-ts.mxnet.io/" rel="noopener ugc nofollow" target="_blank">亚马逊</a>的Gluon-TS旨在提供类似的界面，但与<a class="ae lt" href="https://pytorch-forecasting.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyTorch预测</a>相比有两个明显的缺点。首先，该包的后端是<a class="ae lt" href="https://mxnet.apache.org/" rel="noopener ugc nofollow" target="_blank"> MXNet </a>，一个受欢迎程度落后于<a class="ae lt" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>和<a class="ae lt" href="https://www.tensorflow.org" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>的深度学习框架。第二，尽管它是一个强大的框架，但由于其复杂的对象继承结构和组件的紧密耦合，它可能很难掌握和修改。</p><h1 id="6b6d" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated">参考</h1><p id="5911" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">[1] <a class="ae lt" href="https://eng.uber.com/author/slawek-smyl/" rel="noopener ugc nofollow" target="_blank"> S. Smyl </a>、<a class="ae lt" href="https://eng.uber.com/author/jai-ranganathan/" rel="noopener ugc nofollow" target="_blank"> J .阮冈纳赞</a>和<a class="ae lt" href="https://eng.uber.com/author/andrea-pasqua/" rel="noopener ugc nofollow" target="_blank"> A .帕斯夸</a>、<a class="ae lt" href="https://eng.uber.com/m4-forecasting-competition" rel="noopener ugc nofollow" target="_blank"> M4预测赛:引入全新混合ES-RNN车型</a> (2018)、<a class="ae lt" href="https://eng.uber.com/m4-forecasting-competition" rel="noopener ugc nofollow" target="_blank">https://eng.uber.com/m4-forecasting-competition</a></p><p id="de65" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">[2] B. N. Oreshkin等人，N-BEATS: <a class="ae lt" href="https://openreview.net/forum?id=r1ecqn4YwB" rel="noopener ugc nofollow" target="_blank">可解释时间序列预测的神经基础扩展分析</a> (2020)，学习表征国际会议</p><p id="b004" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">[3] B. Lim，S. O. Arik，N. Loeff和T. Pfister，<a class="ae lt" href="https://arxiv.org/abs/1912.09363" rel="noopener ugc nofollow" target="_blank">用于可解释的多时段时间序列预测的时间融合变换器</a> (2019)，arXiv:1912.09363</p></div></div>    
</body>
</html>