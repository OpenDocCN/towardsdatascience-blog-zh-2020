<html>
<head>
<title>Predict Employee Churn with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用机器学习预测员工流失</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/will-your-employee-leave-a-machine-learning-model-8484c2a6663e?source=collection_archive---------8-----------------------#2020-10-10">https://towardsdatascience.com/will-your-employee-leave-a-machine-learning-model-8484c2a6663e?source=collection_archive---------8-----------------------#2020-10-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="26cc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">对14，249名员工进行分类模型培训</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/e73a8e69fadd9a6c35b2dad7d7df87b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S1cWdTfyeF-Rp64ht1rkuQ.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片来源:Shutterstock。</p></figure><p id="6553" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">众所周知，招聘新员工比留住现有人才要昂贵得多。离开的员工会从你的组织中带走宝贵的经验和知识。据《福布斯》报道，一个初级职位的周转成本估计为该员工工资的50%。对中层员工来说，估计是工资的125%，对高层管理人员来说，是工资的200%。</p><p id="263a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将在一个<a class="ae lq" href="https://www.anaconda.com/products/individual" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>中训练一些机器学习模型，使用关于员工的<strong class="kw iu"> <em class="lr">职位</em></strong><strong class="kw iu"><em class="lr">快乐</em></strong><strong class="kw iu"><em class="lr">绩效</em></strong><strong class="kw iu"><em class="lr">工作量</em> </strong>和<strong class="kw iu"> <em class="lr">任期</em> </strong>的数据来预测他们是会留下还是离开。</p><p id="ea53" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的目标变量是分类的，因此ML任务是分类。(对于数值目标，任务变成<a class="ae lq" rel="noopener" target="_blank" href="/predict-house-prices-with-machine-learning-5b475db4e1e">回归</a>。)</p><p id="2aa3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将使用来自elitedatascience.com的数据集，模拟一家拥有14249名过去和现在员工的大公司。有10列。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/729426e793b79e32f11020923a9feae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*epFFa-FQrOqPsAXgsmOQBw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">原始数据集的快照。</p></figure><p id="a1ed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些步骤是:</p><ol class=""><li id="ab60" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp mc md me mf bi translated"><strong class="kw iu"> EDA &amp;数据处理:</strong>探索、可视化和清理数据。</li><li id="8901" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated"><strong class="kw iu">特性工程:</strong>利用领域专业知识，创造新特性。</li><li id="1047" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated"><strong class="kw iu">模型训练:</strong>我们将训练和调整一些屡试不爽的分类算法，比如逻辑回归、随机森林和梯度推进树。</li><li id="8ab9" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated"><strong class="kw iu">性能评估:</strong>我们将看看包括F1和AUROC在内的一系列分数。</li><li id="b7c0" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated"><strong class="kw iu">部署:</strong>批量运行还是弄几个数据工程师/ ML工程师来建一个自动化流水线？</li></ol><p id="50c4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">理想情况下，该公司将对其目前的永久员工运行该模型，以识别那些处于风险中的员工。这是机器学习提供<strong class="kw iu"> <em class="lr">可操作</em> </strong>商业洞察的一个例子。</p><p id="d6fc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在此加入Medium <a class="ae lq" href="https://col-jung.medium.com/membership" rel="noopener">并获得<strong class="kw iu">无限制访问</strong>互联网上最好的数据科学文章。</a></p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="cd43" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">1.数据探索和处理</h1><p id="5416" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated"><strong class="kw iu">探索性数据分析(EDA) </strong>帮助我们理解数据，为<strong class="kw iu">数据清洗</strong>和<strong class="kw iu">特征工程</strong>提供思路和见解。数据清理为我们的算法准备数据，而特征工程是真正帮助我们的算法从数据集中提取潜在模式的神奇调味汁。请记住:</p><blockquote class="np"><p id="2a5f" class="nq nr it bd ns nt nu nv nw nx ny lp dk translated">更好的数据总是胜过更好的算法！</p></blockquote><p id="5b62" class="pw-post-body-paragraph ku kv it kw b kx nz ju kz la oa jx lc ld ob lf lg lh oc lj lk ll od ln lo lp im bi translated">我们首先将一些标准的数据科学Python包加载到JupyterLab中。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="07be" class="oj mt it of b gy ok ol l om on">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sb</span><span id="1154" class="oj mt it of b gy oo ol l om on">from sklearn.linear_model import LogisticRegression<br/>from sklearn.ensemble import RandomForestClassifier,<br/>                             GradientBoostingClassifier</span><span id="e98a" class="oj mt it of b gy oo ol l om on">from sklearn.model_selection import train_test_split<br/>from sklearn.pipeline import make_pipeline<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.model_selection import GridSearchCV</span><span id="e70d" class="oj mt it of b gy oo ol l om on">from sklearn.metrics import confusion_matrix, accuracy_score,<br/>                            f1_score, roc_curve, roc_auc_score</span><span id="d320" class="oj mt it of b gy oo ol l om on">import pickle</span></pre><p id="5894" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">导入数据集:</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="756b" class="oj mt it of b gy ok ol l om on">df = pd.read_csv('employee_data.csv')</span></pre><p id="a9dd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是我们数据帧的快照。形状为(14，249，10)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/729426e793b79e32f11020923a9feae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*epFFa-FQrOqPsAXgsmOQBw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">原始数据集的快照。</p></figure><p id="5c27" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">目标变量是<strong class="kw iu">状态</strong>。该分类变量采用值<em class="lr">使用</em>或<em class="lr">离开</em>。</p><p id="da06" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">共有25个栏目/功能:</p><ul class=""><li id="d4a4" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated"><strong class="kw iu">部门</strong></li><li id="21c8" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">工资</strong></li><li id="ebab" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">满意，提起_投诉</strong> —代理<strong class="kw iu"> <em class="lr">幸福</em> </strong></li><li id="cf4b" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">上次_评估，最近_提升</strong>—<strong class="kw iu"><em class="lr">绩效代理</em> </strong></li><li id="0f61" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu"> avg_monthly_hrs，n _ projects</strong>—<strong class="kw iu"><em class="lr">工作量的代理</em> </strong></li><li id="db51" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">任期</strong> —代理<strong class="kw iu"> <em class="lr">经验</em> </strong></li></ul></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h2 id="17f0" class="oj mt it bd mu oq or dn my os ot dp nc ld ou ov ne lh ow ox ng ll oy oz ni pa bi translated"><strong class="ak"> 1.1数字特征</strong></h2><p id="4ac0" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">让我们绘制一些快速直方图来了解我们的数字特征的分布。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="4d46" class="oj mt it of b gy ok ol l om on">df.hist(figsize=(10,10), xrot=-45)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi pb"><img src="../Images/f57f4f86e6fe3368c1dad413ea860d9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nJtE_OVrW-BV5rb1OfhBcQ.png"/></div></div></figure><p id="b6b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对我们的数字特征要做的事情，以确保数据与我们的算法配合良好:</p><ul class=""><li id="6719" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated">将<strong class="kw iu">投诉</strong>和<strong class="kw iu">最近提升</strong>中的NaN转换为0。它们的标签贴错了。</li><li id="033e" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">在将NaN转换为零之前，为<strong class="kw iu"> last_evaluation </strong>特征中的缺失数据创建一个指示变量。</li></ul><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="d051" class="oj mt it of b gy ok ol l om on">df.filed_complaint.fillna(0, inplace=True)<br/>df.recently_promoted.fillna(0, inplace=True)</span><span id="56f9" class="oj mt it of b gy oo ol l om on">df['last_evaluation_missing'] =         <br/>df.last_evaluation.isnull().astype(int)<br/>df.last_evaluation.fillna(0, inplace=True)</span></pre><p id="b7e2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是我们数字特征的<strong class="kw iu">关联热图</strong>。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="90a4" class="oj mt it of b gy ok ol l om on">sb.heatmap(df.corr(),<br/> annot=True,<br/> cmap=’RdBu_r’,<br/> vmin=-1,<br/> vmax=1)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/ae0e5ea7e7332a7b043bd231aded6ed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*K_1BNBQ7JTiwMhzhz86ZiQ.png"/></div></figure></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h2 id="30b4" class="oj mt it bd mu oq or dn my os ot dp nc ld ou ov ne lh ow ox ng ll oy oz ni pa bi translated">1.2分类特征</h2><p id="1883" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">让我们为我们的分类特征绘制一些快速柱状图。Seaborn在这方面很棒。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="2740" class="oj mt it of b gy ok ol l om on">for feature in df.dtypes[df.dtypes=='object'].index:<br/>    sb.countplot(data=df, y='{}'.format(features))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi pd"><img src="../Images/35cbdc1911201a57d4f2994242a7ef44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*TuHw2roNNSyQQRTkxehpsw.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/3ce44bc44773711909d3e34887f940d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*_7PmpHwTy5ZuhPB5BXAung.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/fe0cd0f4e80924843bd2696b26fbd5b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*yAESp3ECfp8bkD2mTBFC3g.png"/></div></figure><p id="3bb2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最大的<strong class="kw iu">部门</strong>是<em class="lr">销售部</em>。只有一小部分员工处于<em class="lr">高</em>低<strong class="kw iu">工资</strong>的阶层。我们的数据集是<strong class="kw iu">不平衡</strong>，因为只有少数员工离开了公司，也就是说，只有一小部分员工的<strong class="kw iu">状态= </strong> <em class="lr">离开了</em>。这对我们选择用来评估算法性能的指标有影响。我们将在结果中详细讨论这一点。</p><p id="40f0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从数据清理的角度来看，<strong class="kw iu">部门</strong>特性的<em class="lr"> IT </em>和<em class="lr"> information_technology </em>类应该合并在一起:</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="1888" class="oj mt it of b gy ok ol l om on">df.department.replace('information_technology', 'IT', inplace=True)</span></pre><p id="9c98" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">而且HR只关心<strong class="kw iu">永久</strong>员工，所以要过滤掉<em class="lr">临时</em>部门:</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="2d4d" class="oj mt it of b gy ok ol l om on">df = df[df.department != 'temp']</span></pre><p id="4f32" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，我们的<strong class="kw iu">部门</strong>功能看起来应该更像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/1bf919afedb5f29a3cd5eed0f07af271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*Xcwq6DK4OvdtbYJ09OKRQw.png"/></div></figure><p id="b219" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对我们的分类特征要做的事情，以确保数据与我们的算法配合良好:</p><ul class=""><li id="fe99" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated"><strong class="kw iu">部门</strong>特征的缺失数据应该被集中到它自己的<em class="lr">缺失</em>类中。</li><li id="e6a5" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">部门</strong>和<strong class="kw iu">薪资</strong>分类特征也应该是<strong class="kw iu">一键编码</strong>。</li><li id="1e53" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">目标变量<strong class="kw iu">状态</strong>应转换为二进制。</li></ul><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="095a" class="oj mt it of b gy ok ol l om on">df['department'].fillna('Missing', inplace=True)</span><span id="60ff" class="oj mt it of b gy oo ol l om on">df = pd.get_dummies(df, columns=['department', 'salary'])</span><span id="f8bf" class="oj mt it of b gy oo ol l om on">df['status'] = pd.get_dummies(df.status).Left</span></pre></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h2 id="b5bb" class="oj mt it bd mu oq or dn my os ot dp nc ld ou ov ne lh ow ox ng ll oy oz ni pa bi translated">1.3细分</h2><p id="36bb" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">我们可以通过将数字特征与分类特征进行分割来获得进一步的见解。让我们从一些<strong class="kw iu">单变量分割</strong>开始。</p><p id="f377" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">具体来说，我们将通过我们的分类目标变量<strong class="kw iu">状态</strong>来细分代表快乐、绩效、工作量和体验的数字特征。</p><p id="88e8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">按状态划分的细分市场满意度:</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="1df7" class="oj mt it of b gy ok ol l om on">sb.violinplot(y='status', x='satisfaction', data=df)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/1203988284d785745afc791e629aca74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*W61Fp9-fRllk9aWzZnolcg.png"/></div></figure><p id="6a47" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有一种观点认为，许多被解雇的员工对他们的工作非常满意。</p><p id="e66f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">细分市场最后_评估状态:</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="1a23" class="oj mt it of b gy ok ol l om on">sb.violinplot(y='status', x='last_evaluation', data=df)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/577cd80d0e84a82946841b470d507188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*xgGCaEcAW_QO-g0vtyQZjg.png"/></div></figure><p id="a455" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一种观点认为，大量被解雇的员工都是高绩效员工。也许他们觉得留下来没有进一步发展的机会？</p><p id="5fd7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">按状态细分平均每月小时数和项目数:</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="79cd" class="oj mt it of b gy ok ol l om on">sb.violinplot(y='status', x='avg_monthly_hrs', data=df)<br/>sb.violinplot(y='status', x='n_projects', data=df)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/c54584baeff474ac5eee89041bb335fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fnIjiGiyMQd5Fp6rSOe8aw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/d65cb0c7b170e5de35249d7bfb376208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Wt4UEmws0cblZShubJ7PwA.png"/></div></figure><p id="be51" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">似乎那些翻腾的人要么工作量相当大，要么工作量相当低。这些代表了精疲力竭、无所事事的前员工吗？</p><p id="ea84" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">按状态划分的细分任期:</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="443d" class="oj mt it of b gy ok ol l om on">sb.violinplot(y='status', x='tenure', data=df)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/3786902a67c575f8499638c4445ac6eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*QvOVHMVWhfgRptpa7PEUNw.png"/></div></figure><p id="a4b9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们注意到员工在第三年突然流失。那些6年后还在的人倾向于留下来。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="c57b" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">2.特征工程</h1><p id="5a82" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">查看下面的<strong class="kw iu">双变量分割</strong>，这将推动我们以后的特征工程。</p><p id="6692" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于每个情节，我们将按照<strong class="kw iu">状态</strong>来分割<em class="lr">两个</em>数字特征(代表快乐、表现、工作量或经历)。这可能会给我们一些基于员工刻板印象的聚类。</p><p id="8608" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">表现和快乐:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/d12fd8346e09e6f7017ff77cf0fd78ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*cF8d7UptEhqTWA8StN27kg.png"/></div></figure><p id="3e38" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">哎呦，雇佣的<em class="lr">工人让这个图很难看。让我们只显示剩下的<em class="lr">工人，因为他们才是我们真正想要了解的。</em></em></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="1f40" class="oj mt it of b gy ok ol l om on">sb.lmplot(x='satisfaction',<br/>          y='last_evaluation',<br/>          data=df[df.status=='Left'],<br/>          fit_reg=False<br/>         )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/865ddf3f97ddd14315ebab45e938d7a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*XbO6sFSjPtbQ7mYyd5mc_w.png"/></div></figure><p id="36f6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们有三组不安分的员工:</p><ul class=""><li id="0516" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated"><strong class="kw iu">表现不佳者</strong>:最后_评价&lt; 0.6</li><li id="4d9d" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">不开心</strong>:满意度_等级&lt; 0.2</li><li id="2a6c" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">超额完成者</strong>:上次评估&gt; 0.8，满意度&gt; 0.7</li></ul><p id="1ce0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">工作负载和性能:</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="0cdb" class="oj mt it of b gy ok ol l om on">sb.lmplot(x='last_evaluation',<br/>          y='avg_monthly_hrs',<br/>          data=df[df.status=='Left'],<br/>          fit_reg=False<br/>         )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/ff5f744f693429ba33beba922c5125bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*MAL0NJCKl_QTTwO-BgGQoQ.png"/></div></figure><p id="4eac" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们有两群焦躁不安的员工:</p><ul class=""><li id="a8af" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated"><strong class="kw iu">星级</strong> : avg_monthly_hrs &gt; 215，last_evaluation &gt; 0.75</li><li id="67d4" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">懒鬼</strong> : avg_monthly_hrs &lt; 165，last_evaluation &lt; 0.65</li></ul><p id="e12a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">工作量和幸福感:</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="5132" class="oj mt it of b gy ok ol l om on">sb.lmplot(x='satisfaction',<br/>          y='avg_monthly_hrs',<br/>          data=df[df.status=='Left'],<br/>          fit_reg=False,<br/>         )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/20a1859be4dfc19f7422d237b2c8e777.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*LDkcBUdwwKOHwjbV8R1uiw.png"/></div></figure><p id="5292" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们有三组不安分的员工:</p><ul class=""><li id="5da1" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated"><strong class="kw iu">工作狂</strong>:平均每月工时&gt; 210，满意度&gt; 0.7</li><li id="1ba8" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">刚刚参加工作:平均每月工作时间&lt; 170</li><li id="1e7d" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">过度劳累</strong>:平均每月小时数&gt; 225，满意度&lt; 0.2</li></ul><p id="7414" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们为这8个“典型”员工群体设计新功能:</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="b676" class="oj mt it of b gy ok ol l om on">df['underperformer'] = ((df.last_evaluation &lt; 0.6) &amp; (df.last_evaluation_missing==0)).astype(int)<br/>df['unhappy'] = (df.satisfaction &lt; 0.2).astype(int)<br/>df['overachiever'] = ((df.last_evaluation &gt; 0.8) &amp; (df.satisfaction &gt; 0.7)).astype(int)</span><span id="a1c5" class="oj mt it of b gy oo ol l om on">df['stars'] = ((df.avg_monthly_hrs &gt; 215) &amp; (df.last_evaluation &gt; 0.75)).astype(int)<br/>df['slackers'] = ((df.avg_monthly_hrs &lt; 165) &amp; (df.last_evaluation &lt; 0.65) &amp; (df.last_evaluation_missing==0)).astype(int)</span><span id="c4ad" class="oj mt it of b gy oo ol l om on">df['workaholic'] = ((df.avg_monthly_hrs &gt; 210) &amp; (df.satisfaction &gt; 0.7)).astype(int)<br/>df['justajob'] = (df.avg_monthly_hrs &lt; 170).astype(int)<br/>df['overworked'] = ((df.avg_monthly_hrs &gt; 225) &amp; (df.satisfaction &lt; 0.2)).astype(int)</span></pre><p id="2b4e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看一下这8个组中每个组的员工比例。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="fe0d" class="oj mt it of b gy ok ol l om on">df[['underperformer', 'unhappy', 'overachiever', 'stars', <br/>    'slackers', 'workaholic', 'justajob', 'overworked']].mean()</span><span id="b4a5" class="oj mt it of b gy oo ol l om on">underperformer    0.285257<br/>unhappy           0.092195<br/>overachiever      0.177069<br/>stars             0.241825<br/>slackers          0.167686<br/>workaholic        0.226685<br/>justajob          0.339281<br/>overworked        0.071581</span></pre><p id="dea8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">34%的员工是刚参加工作的员工——没有灵感，只是来领周薪的——而只有7%的人是超负荷工作的。</p><p id="3690" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">分析基表:</strong>应用所有这些数据清洗步骤和特征工程后的数据集就是我们的<strong class="kw iu">分析基表</strong>。这是我们训练模型的数据。</p><p id="5bd1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的ABT有14，068名员工和31个栏目——请看下面的片段。<em class="lr">回想一下，我们的原始数据集有14，249名员工，只有10列！</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi pi"><img src="../Images/e4e1525d48f6630f2a3dfcc869ebc669.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JVTFEvYuVKP2uFrABieoOg.png"/></div></div></figure></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="d5a1" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">3.系统模型化</h1><p id="c3d5" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">我们将训练四个屡试不爽的分类模型:</p><ul class=""><li id="2a28" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated"><strong class="kw iu">逻辑回归</strong> (L1和L2——正规化)</li><li id="3943" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">随机森林</strong></li><li id="e9ba" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">梯度增强树</strong></li></ul><p id="5655" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，让我们拆分我们的分析基表。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="0f68" class="oj mt it of b gy ok ol l om on">y = df.status<br/>X = df.drop('status', axis=1)</span></pre><p id="303d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后我们将分成训练集和测试集。我们的数据集有点不平衡，所以我们将使用<strong class="kw iu">分层抽样</strong>进行补偿。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="b50b" class="oj mt it of b gy ok ol l om on">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234, stratify=df.status)</span></pre><p id="e302" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将设置一个<strong class="kw iu">管道对象</strong>来训练。这将简化我们的模型训练过程。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="5f50" class="oj mt it of b gy ok ol l om on">pipelines = {<br/>       'l1': make_pipeline(StandardScaler(), <br/>             LogisticRegression(penalty='l1', random_state=123)),<br/>       'l2': make_pipeline(StandardScaler(), <br/>             LogisticRegression(penalty='l2', random_state=123)),<br/>       'rf': make_pipeline(<br/>             RandomForestClassifier(random_state=123)),<br/>       'gb': make_pipeline(<br/>             GradientBoostingClassifier(random_state=123))<br/>            }</span></pre><p id="fb96" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们还想调整每个算法的<strong class="kw iu">超参数</strong>。对于逻辑回归，最有影响的超参数是正则化的强度，<strong class="kw iu"> C </strong>。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="1e5e" class="oj mt it of b gy ok ol l om on">l1_hyperparameters = {'logisticregression__C' : [0.001, 0.005, 0.01, <br/>                       0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]<br/>                     }</span><span id="8939" class="oj mt it of b gy oo ol l om on">l2_hyperparameters = {'logisticregression__C' : <br/>                       [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, <br/>                        1, 5, 10, 50, 100, 500, 1000]<br/>                     }</span></pre><p id="67d3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于我们的随机森林，我们将调整估计器的数量(<strong class="kw iu"> n_estimators </strong>)、分割期间要考虑的最大特征数量(<strong class="kw iu"> max_features </strong>)以及作为叶子的最小样本数量(<strong class="kw iu"> min_samples_leaf </strong>)。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="9323" class="oj mt it of b gy ok ol l om on">rf_hyperparameters = {<br/>    'randomforestclassifier__n_estimators' : [100, 200],<br/>    'randomforestclassifier__max_features' : ['auto', 'sqrt', 0.33],<br/>    'randomforestclassifier__min_samples_leaf' : [1, 3, 5, 10]<br/>    }</span></pre><p id="836a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于我们的梯度增强树，我们将调整估计器的数量(<strong class="kw iu">n _估计器</strong>)，<strong class="kw iu">学习速率</strong>，以及每棵树的最大深度(<strong class="kw iu"> max_depth </strong>)。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="62f7" class="oj mt it of b gy ok ol l om on">gb_hyperparameters = {<br/>    'gradientboostingclassifier__n_estimators' : [100, 200],<br/>    'gradientboostingclassifier__learning_rate' : [0.05, 0.1, 0.2],<br/>    'gradientboostingclassifier__max_depth' : [1, 3, 5]<br/>    }</span></pre><p id="5f1d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将把这些超参数保存在字典中。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="050c" class="oj mt it of b gy ok ol l om on">hyperparameters = {<br/>    'l1' : l1_hyperparameters,<br/>    'l2' : l2_hyperparameters,<br/>    'rf' : rf_hyperparameters,<br/>    'gb' : gb_hyperparameters<br/>    }</span></pre><p id="32be" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，我们将拟合和调整我们的模型。使用<strong class="kw iu"> GridSearchCV </strong>我们可以训练所有这些模型，只需几行代码就可以对我们声明的所有超参数进行交叉验证！</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="7527" class="oj mt it of b gy ok ol l om on">fitted_models = {}<br/>for name, pipeline in pipelines.items():<br/>    model = GridSearchCV(pipeline, <br/>                         hyperparameters[name], <br/>                         cv=10, <br/>                         n_jobs=-1)<br/>    model.fit(X_train, y_train)<br/>    fitted_models[name] = model</span></pre></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="1635" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">4.估价</h1><p id="c275" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">我写了一篇关于流行的机器学习指标的<a class="ae lq" rel="noopener" target="_blank" href="/popular-machine-learning-performance-metrics-a2c33408f29">专门文章</a>，包括下面使用的那些。</p><h2 id="b7c8" class="oj mt it bd mu oq or dn my os ot dp nc ld ou ov ne lh ow ox ng ll oy oz ni pa bi translated">4.1绩效得分</h2><p id="4567" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">我们将从打印<strong class="kw iu">交叉验证分数</strong>开始。这是10个保留折叠的平均性能，是仅使用您的训练数据获得模型性能<strong class="kw iu">的可靠估计的一种方式。</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="0ef1" class="oj mt it of b gy ok ol l om on">for name, model in fitted_models.items():<br/>    print(name, model.best_score_)</span><span id="24d6" class="oj mt it of b gy oo ol l om on"><strong class="of iu">Output:<br/>l1 0.9088324151412831<br/>l2 0.9088324151412831<br/>rf 0.9793851075173272<br/>gb 0.975475386529234</strong></span></pre><p id="1117" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">转到<strong class="kw iu">测试数据</strong>，我们将:</p><ul class=""><li id="3139" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated">计算<strong class="kw iu">精度</strong>；</li><li id="7162" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">打印<strong class="kw iu">混淆矩阵</strong>并计算<strong class="kw iu">精度，调出</strong>和<strong class="kw iu">F1-得分</strong>；</li><li id="0d49" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">显示<strong class="kw iu"> ROC </strong>并计算<strong class="kw iu"> AUROC </strong>分数。</li></ul><p id="6466" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">准确性</strong>衡量正确标记的预测的比例，但它不适用于不平衡的数据集，例如垃圾邮件过滤(垃圾邮件与非垃圾邮件)和医疗测试(生病与未生病)。例如，如果我们的数据集只有1%的员工满足<strong class="kw iu">目标</strong> = <em class="lr">离开</em>，那么一个总是预测该员工仍在该公司工作的模型将立即获得99%的准确率。在这些情况下，<strong class="kw iu">精确</strong>或<strong class="kw iu">召回</strong>更为合适。你经常使用哪一个取决于你是想最小化<strong class="kw iu">类型1错误</strong>(假阳性)还是<strong class="kw iu">类型2错误</strong>(假阴性)。对于垃圾邮件，类型1错误更糟糕(一些垃圾邮件是可以的，只要你没有意外过滤掉一封重要的邮件！)而第二类错误对于医学测试来说是不可接受的(告诉别人他们没有患癌症是一场灾难！).<strong class="kw iu"> F1分数</strong>通过对精确度和召回率进行加权平均，让你两全其美。</p><p id="dbeb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">ROC下的面积，被称为AUROC是分类问题的另一个标准度量。这是对分类器区分类别和从噪声中分离信号的能力的有效测量。这种度量对于不平衡数据集也是稳健的。</p><p id="5d5a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面是生成这些分数和图表的代码:</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="dcba" class="oj mt it of b gy ok ol l om on">for name, model in fitted_models.items():<br/>    print('Results for:', name)<br/>    <br/>    # obtain predictions<br/>    pred = fitted_models[name].predict(X_test)</span><span id="b22a" class="oj mt it of b gy oo ol l om on">    # confusion matrix<br/>    cm = confusion_matrix(y_test, pred)<br/>    print(cm)</span><span id="db97" class="oj mt it of b gy oo ol l om on">    # accuracy score<br/>    print('Accuracy:', accuracy_score(y_test, pred))<br/>    <br/>    # precision<br/>    precision = cm[1][1]/(cm[0][1]+cm[1][1])<br/>    print('Precision:', precision)<br/>    <br/>    # recall<br/>    recall = cm[1][1]/(cm[1][0]+cm[1][1])<br/>    print('Recall:', recall)<br/>    <br/>    # F1_score<br/>    print('F1:', f1_score(y_test, pred))<br/>    <br/>    # obtain prediction probabilities<br/>    pred = fitted_models[name].predict_proba(X_test)<br/>    pred = [p[1] for p in pred]</span><span id="54ac" class="oj mt it of b gy oo ol l om on">    # plot ROC<br/>    fpr, tpr, thresholds = roc_curve(y_test, pred) <br/>    plt.title('Receiver Operating Characteristic (ROC)')<br/>    plt.plot(fpr, tpr, label=name)<br/>    plt.legend(loc='lower right')<br/>    plt.plot([0,1],[0,1],'k--')<br/>    plt.xlim([-0.1,1.1])<br/>    plt.ylim([-0.1,1.1])<br/>    plt.ylabel('True Positive Rate (TPR) i.e. Recall')<br/>    plt.xlabel('False Positive Rate (FPR)')<br/>    plt.show()<br/>    <br/>    # AUROC score<br/>    print('AUROC:', roc_auc_score(y_test, pred))</span></pre><p id="3170" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">逻辑回归(L1正则化):</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="fedf" class="oj mt it of b gy ok ol l om on"><strong class="of iu">Output:<br/>[[2015  126]<br/> [ 111  562]]<br/><br/>Accuracy:  0.9157782515991472<br/>Precision: 0.8168604651162791<br/>Recall:    0.8350668647845468<br/>F1:        0.8258633357825129<br/>AUROC:     0.9423905869485105</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/53103a491ac381185bdad4ab1f684257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*xqm3FrFSSzbs-TCPhhg9eQ.png"/></div></figure><p id="9d26" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">逻辑回归(L2正则化):</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="7875" class="oj mt it of b gy ok ol l om on"><strong class="of iu">Output:<br/>[[2014  127]<br/> [ 110  563]]<br/><br/>Accuracy:  0.9157782515991472<br/>Precision: 0.8159420289855073<br/>Recall:    0.836552748885587<br/>F1:        0.8261188554658841<br/>AUROC:     0.9423246556128734</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/e619269b40c58606f89c2d2a5d0ae626.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*qjpmPnJYT--4d6o2kA3I_g.png"/></div></figure><p id="604d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">渐变增强树:</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="6b75" class="oj mt it of b gy ok ol l om on"><strong class="of iu">Output:<br/>[[2120   21]<br/> [  48  625]]<br/><br/>Accuracy:  0.9754797441364605<br/>Precision: 0.9674922600619195<br/>Recall:    0.9286775631500743<br/>F1:        0.9476876421531464<br/>AUROC:     0.9883547910913578</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/a466b8a8eb790dba850ba6a5502e3956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*vpmpvwkp3VvWAB6SUhwcWA.png"/></div></figure><p id="6005" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">随机森林:</strong></p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="89f5" class="oj mt it of b gy ok ol l om on"><strong class="of iu">Output:<br/>[[2129   12]<br/> [  45  628]]</strong></span><span id="9fcf" class="oj mt it of b gy oo ol l om on"><strong class="of iu">Accuracy:  0.9797441364605544<br/>Precision: 0.98125<br/>Recall:    0.9331352154531947<br/>F1:        0.9565879664889566<br/>AUROC:     0.9916117990718256</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/7c556d4710de4ba8ba7dc2ef2a06da46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*6ht3PxT9NJXsMgFGNC3ZWQ.png"/></div></figure><p id="5956" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">获胜的算法是AUROC为99%、F1得分为96%的随机森林。这种算法有99%的几率区分出<em class="lr">左</em>和<em class="lr">受雇的</em>工人……相当不错！</p><p id="dcfb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在测试集中的2814名员工中，算法:</p><ul class=""><li id="34bd" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated">正确分类628个<em class="lr">左</em>工人(<em class="lr">真阳性</em>，同时得到12个错误(<em class="lr">I型错误</em>，以及</li><li id="6702" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">正确分类的2129个<em class="lr">雇佣的</em>工人(<em class="lr">真否定</em>)，同时得到45个错误(<em class="lr">第二类错误</em>)。</li></ul><p id="4ac5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">仅供参考，这里是获胜随机森林的超参数，使用GridSearchCV进行了调整。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="3cef" class="oj mt it of b gy ok ol l om on">RandomForestClassifier(bootstrap=True, <br/>                       class_weight=None, <br/>                       criterion='gini',<br/>                       max_depth=None, <br/>                       max_features=0.33, <br/>                       max_leaf_nodes=None,<br/>                       min_impurity_decrease=0.0,<br/>                       min_impurity_split=None,<br/>                       min_samples_leaf=1, <br/>                       min_samples_split=2,<br/>                       min_weight_fraction_leaf=0, <br/>                       n_estimators=200,<br/>                       n_jobs=None, <br/>                       oob_score=False, <br/>                       random_state=123,<br/>                       verbose=0, <br/>                       warm_start=False<br/>                      )</span></pre></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h2 id="d28a" class="oj mt it bd mu oq or dn my os ot dp nc ld ou ov ne lh ow ox ng ll oy oz ni pa bi translated"><strong class="ak"> 4.2特性重要性</strong></h2><p id="4338" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">考虑下面的代码。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="334d" class="oj mt it of b gy ok ol l om on">coef = winning_model.feature_importances_<br/>ind = np.argsort(-coef)</span><span id="e132" class="oj mt it of b gy oo ol l om on">for i in range(X_train.shape[1]):<br/>    print("%d. %s (%f)" % (i + 1, X.columns[ind[i]], coef[ind[i]]))</span><span id="0173" class="oj mt it of b gy oo ol l om on">x = range(X_train.shape[1])<br/>y = coef[ind][:X_train.shape[1]]</span><span id="055a" class="oj mt it of b gy oo ol l om on">plt.title("Feature importances")<br/>ax = plt.subplot()<br/>plt.barh(x, y, color='red')<br/>ax.set_yticks(x)<br/>ax.set_yticklabels(X.columns[ind])<br/>plt.gca().invert_yaxis()</span></pre><p id="ae40" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这将打印按重要性排序的特性列表和相应的条形图。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="1a00" class="oj mt it of b gy ok ol l om on"><strong class="of iu">Ranking of feature importance:<br/>1. n_projects (0.201004)<br/>2. satisfaction (0.178810)<br/>3. tenure (0.169454)<br/>4. avg_monthly_hrs (0.091827)<br/>5. stars (0.074373)<br/>6. overworked (0.068334)<br/>7. last_evaluation (0.063630)<br/>8. slackers (0.028261)<br/>9. overachiever (0.027244)<br/>10. workaholic (0.018925)<br/>11. justajob (0.016831)<br/>12. unhappy (0.016486)<br/>13. underperformer (0.006015)<br/>14. last_evaluation_missing (0.005084)<br/>15. salary_low (0.004372)<br/>16. filed_complaint (0.004254)<br/>17. salary_high (0.003596)<br/>18. department_engineering (0.003429)<br/>19. department_sales (0.003158)<br/>20. salary_medium (0.003122)<br/>21. department_support (0.002655)<br/>22. department_IT (0.001628)<br/>23. department_finance (0.001389)<br/>24. department_management (0.001239)<br/>25. department_Missing (0.001168)<br/>26. department_marketing (0.001011)<br/>27. recently_promoted (0.000983)<br/>28. department_product (0.000851)<br/>29. department_admin (0.000568)<br/>30. department_procurement (0.000296)</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi pk"><img src="../Images/4d4f7e60da6b0714611e2dcb9a824f07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zq9AjFRW8EXT8lM9QJM5pQ.png"/></div></div></figure><p id="4272" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">员工流失有三个特别强的预测因素:</p><ul class=""><li id="96f9" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated"><strong class="kw iu"> n_projects </strong>(工作量)</li><li id="2e9d" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">满意度</strong>(幸福感)和</li><li id="ce5a" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">任期</strong>(经验)。</li></ul><p id="883e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此外，这两个工程特性在特性重要性上排名也很高:</p><ul class=""><li id="724b" class="lx ly it kw b kx ky la lb ld lz lh ma ll mb lp op md me mf bi translated"><strong class="kw iu">明星</strong>(高幸福&amp;工作量)，以及</li><li id="6868" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated"><strong class="kw iu">劳累过度</strong>(低幸福感&amp;高工作量)。</li></ul><p id="ff5f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有趣，但并不完全令人惊讶。明星们可能为了更好的机会而离开，而过度劳累的人则在筋疲力尽后离开。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="7743" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">5.部署</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi pl"><img src="../Images/31dd3261125fefcb14fdf597ea873c3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iVqnRvZ4AQ0W-AjpYeZ9ag.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae lq" href="https://unsplash.com/@thisisengineering" rel="noopener ugc nofollow" target="_blank"> ThisisEngineering RAEng </a>提供。</p></figure><p id="b3d8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此模型的可执行版本(。pkl)可以从Jupyter笔记本中保存。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="7da5" class="oj mt it of b gy ok ol l om on">with open('final_model.pkl', 'wb') as f:<br/>    pickle.dump(fitted_models['rf'].best_estimator_, f)</span></pre><p id="97a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">人力资源可以在将新员工数据输入训练模型之前对其进行预处理。这被称为批量运行。</p><p id="dfb7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在大型组织中，他们可能希望通过与<strong class="kw iu">数据工程师</strong>和<strong class="kw iu">机器学习工程师</strong>合作，将模型部署到<strong class="kw iu">生产环境</strong>中。这些专家围绕我们的模型建立了一个自动化的管道，确保新的数据能够得到预处理，并定期向人力资源部门报告预测。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="c37a" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">最终意见</h1><p id="dd7e" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">我们从一个<strong class="kw iu">业务问题</strong>开始:一家大公司的人力资源想要对他们的员工流失有可操作的见解。</p><p id="3498" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们在包含超过14，000名过去和现在员工的大量历史数据上训练了一个获胜的随机森林模型。</p><p id="cf48" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">人力资源部可以在我们训练有素的员工身上运行新数据。pkl文件，或者可以由他们的工程部门构建自动管道。</p><p id="da02" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的模型是二元分类模型，其中目标变量是分类的。它预测了一系列不连续的可能性——这里是<em class="lr">流失</em>或<em class="lr">不流失</em>。</p><p id="0736" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">监督学习硬币的另一面是<strong class="kw iu">回归模型</strong>，其目标变量是数值。在<a class="ae lq" rel="noopener" target="_blank" href="/predict-house-prices-with-machine-learning-5b475db4e1e">这里</a>，我训练了一个预测房价的。</p><p id="e0e3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，我在这里写了一篇关于机器学习在数学建模领域的位置的文章。</p><p id="9aa3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在<a class="ae lq" href="https://www.youtube.com/c/CryptoFilmmaker" rel="noopener ugc nofollow" target="_blank"> YouTube </a>和<a class="ae lq" href="https://twitter.com/col_jung" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我。</p><h1 id="3614" class="ms mt it bd mu mv pm mx my mz pn nb nc jz po ka ne kc pp kd ng kf pq kg ni nj bi translated">无限制媒体访问</h1><p id="d4bb" class="pw-post-body-paragraph ku kv it kw b kx nk ju kz la nl jx lc ld nm lf lg lh nn lj lk ll no ln lo lp im bi translated">提升你的知识和技能到一个新的水平。</p><p id="fb6a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://col-jung.medium.com/membership" rel="noopener">加入Medium </a>享受<strong class="kw iu">无限制访问</strong>互联网上的<strong class="kw iu">最佳分析&amp;数据科学文章</strong>。你可以在这里加入<a class="ae lq" href="https://col-jung.medium.com/membership" rel="noopener">来支持我和其他顶级作家。</a></p><h1 id="2d17" class="ms mt it bd mu mv pm mx my mz pn nb nc jz po ka ne kc pp kd ng kf pq kg ni nj bi translated">我的数据科学文章</h1><ul class=""><li id="823b" class="lx ly it kw b kx nk la nl ld pr lh ps ll pt lp op md me mf bi translated">微分方程与机器学习——这里<a class="ae lq" href="https://medium.com/swlh/differential-equations-versus-machine-learning-78c3c0615055" rel="noopener">这里</a></li><li id="b030" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">新冠肺炎的数学建模与机器学习— <a class="ae lq" href="https://medium.com/swlh/math-modelling-and-machine-learning-for-covid-19-646efcbe024e" rel="noopener">此处</a></li><li id="2170" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">用回归预测房价— <a class="ae lq" rel="noopener" target="_blank" href="/predict-house-prices-with-machine-learning-5b475db4e1e">此处</a></li><li id="bbb7" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">分类预测员工流失— <a class="ae lq" rel="noopener" target="_blank" href="/will-your-employee-leave-a-machine-learning-model-8484c2a6663ea">此处</a></li><li id="3329" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">流行的机器学习性能指标— <a class="ae lq" rel="noopener" target="_blank" href="/popular-machine-learning-performance-metrics-a2c33408f29">此处</a></li><li id="513e" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">Jupyter笔记本与Dataiku DSS — <a class="ae lq" rel="noopener" target="_blank" href="/jupyter-notebooks-versus-dataiku-dss-for-data-science-e02264a753ca">此处</a></li><li id="81c4" class="lx ly it kw b kx mg la mh ld mi lh mj ll mk lp op md me mf bi translated">Power BI —从数据建模到令人惊叹的报告— <a class="ae lq" rel="noopener" target="_blank" href="/intro-to-power-bi-from-data-modelling-to-stunning-reports-b34aac43d8a1">此处</a></li></ul></div></div>    
</body>
</html>