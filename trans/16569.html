<html>
<head>
<title>AUC-ROC: Simplified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AUC-ROC:简化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/auc-roc-simplified-5914185d24e?source=collection_archive---------35-----------------------#2020-11-15">https://towardsdatascience.com/auc-roc-simplified-5914185d24e?source=collection_archive---------35-----------------------#2020-11-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="773f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">直觉的理解</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b46d5ed03871e1320f8447efbf574c3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hxh2lPpuQvUy0hmrUJioDA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:https://pxhere.com</p></figure><h1 id="e2a2" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="fb79" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">机器学习的一个重要方面是模型评估。你需要一些机制来评估你的模型。这就是这些性能指标发挥作用的地方，它们让我们感觉到你的模型有多好。如果你熟悉机器学习的一些基础知识，那么你必须了解这些指标，如准确度、精确度、召回率、auc-roc等。</p><p id="7a39" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">假设您正在处理一个二元分类问题，并提出了一个准确率为95%的模型，现在我问您这实际上意味着什么，您可以很快说出您的模型做出的100个预测中，有95个是正确的。让我们更进一步，现在基本的指标是回忆，我问同样的问题，你可能会花一点时间，但最终你会得出一个解释，比如在100个相关数据点(一般为正类)中，你的模型能够识别其中的80个。到目前为止，我们假设您使用AUC-ROC作为指标评估您的模型，得到0.75的值，我再次问您同样的问题，0.75或75%意味着什么，现在您可能需要思考一下，有些人可能会说模型有75%的机会正确识别数据点，但现在您应该已经意识到不是这样。让我们试着对分类问题中最流行的一个性能指标有一个直观的理解。</p><h1 id="fa4b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">历史</h1><p id="9211" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如果你参加过任何在线机器学习竞赛/黑客马拉松，那么你一定遇到过曲线下面积-接收器操作员特征，也称为AUC-ROC，其中许多人将它作为他们分类问题的评估标准。让我们承认，当你第一次听说它的时候，你一定有过这样的想法，这个又长又花哨的名字是怎么回事？ROC曲线的起源可以追溯到第二次世界大战，它最初用于分析雷达信号。美国陆军试图测量他们的雷达接收机在信号噪声中正确识别日本飞机的能力。现在我们有了一个小小的起源故事，让我们进入正题</p><h1 id="2fa7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">几何解释</h1><p id="ae4d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这是你在谷歌上搜索AUC-ROC时会遇到的最常见的定义。基本上，ROC曲线是显示分类模型在所有可能阈值下的<strong class="lq ir">性能的图表(阈值是一个特定值，超过该值，您就说某个点属于特定类别)。曲线绘制在两个参数之间</strong></p><ul class=""><li id="7f40" class="mp mq iq lq b lr mk lu ml lx mr mb ms mf mt mj mu mv mw mx bi translated">真阳性率</li><li id="c3cb" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">假阳性率(FPR)</li></ul><p id="1203" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在理解TPR和FPR之前，让我们先快速看一下混淆矩阵。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/03d22ef3bdc558960d6a117757b5e21f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*lK17g_LKDGcU7UjKlZn1tQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" rel="noopener ugc nofollow" target="_blank">知识共享</a></p></figure><ul class=""><li id="73e9" class="mp mq iq lq b lr mk lu ml lx mr mb ms mf mt mj mu mv mw mx bi translated"><strong class="lq ir">真阳性</strong>:实际阳性和预测阳性</li><li id="f5f5" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated"><strong class="lq ir">真阴性</strong>:实际阴性，预测为阴性</li><li id="a6eb" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated"><strong class="lq ir">假阳性(I型错误)</strong>:实际阴性但预测为阳性</li><li id="b58f" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated"><strong class="lq ir">假阴性(II型错误)</strong>:实际阳性但预测为阴性</li></ul><p id="2b06" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">简单来说，你可以把假阳性称为<strong class="lq ir">假报警</strong>，把假阴性称为<strong class="lq ir">漏警<em class="ne">。</em> </strong>现在让我们看看TPR和FPR是什么情况。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/88c7fe184af70dd5b9313bc08a6b3283.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*b6UGjxJ9bwlOdDZ91iYgWw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/0003e296ac30501ac614ca49d209606f.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*cVW_c9blXFK7MLsl2dUEUg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="77f4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">基本上，TPR/回忆/灵敏度是正确识别的阳性样本的比率<strong class="lq ir"/>，FPR是错误分类的阴性样本的比率<strong class="lq ir"/>，如前所述，ROC只不过是TPR和FPR之间跨越所有可能阈值的图，AUC是该ROC曲线下的整个面积。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/c7f5fbf92c1ad1975ec917f5c042038e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b7VjjLuBouZWfBgFb81F-w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://creativecommons.org/licenses/by-sa/3.0/deed.en" rel="noopener ugc nofollow" target="_blank">知识共享</a></p></figure><h1 id="5531" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">概率解释</h1><p id="671f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们看了几何解释，但我想这仍然不足以开发0.75 AUC实际含义背后的直觉，现在让我们用概率的观点看一下AUC-ROC。</p><p id="c7c3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">让我先谈谈AUC的工作，稍后我们将在此基础上建立我们的理解</p><blockquote class="ni nj nk"><p id="6078" class="lo lp ne lq b lr mk jr lt lu ml ju lw nl mm lz ma nm mn md me nn mo mh mi mj ij bi translated">AUC衡量模型区分类别的能力</p></blockquote><p id="9da6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">0.75的AUC实际上意味着假设我们取属于不同类别的两个数据点，那么有75%的机会模型能够分离它们或者正确地对它们进行<strong class="lq ir">排序</strong>，即正点比负类具有更高的预测概率。(假设较高的预测概率意味着该点理想情况下属于正类)</p><p id="0a90" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下面举个小例子，让事情更清楚。</p><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="214b" class="nt kx iq np b gy nu nv l nw nx">╔═══════╦═══════╦═════════════╗<br/>║ Index ║ Class ║ Probability ║<br/>╠═══════╬═══════╬═════════════╣<br/>║ P1    ║     1 ║ 0.95        ║<br/>║ P2    ║     1 ║ 0.90        ║<br/>║ P3    ║     0 ║ 0.85        ║<br/>║ P4    ║     0 ║ 0.81        ║<br/>║ P5    ║     1 ║ 0.78        ║<br/>║ P6    ║     0 ║ 0.70        ║<br/>╚═══════╩═══════╩═════════════╝</span></pre><p id="58be" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这里我们有6个点，其中P1、P2、P5属于第1类，P3、P4、P6属于第0类，并且在概率列中有相应的预测概率，正如我们说过的，如果我们取两个属于不同类的点，那么模型秩正确排序它们的概率是多少</p><p id="8caf" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们将采取所有可能的配对，这样一个点属于类1，另一个点属于类0，我们将有总共9个这样的配对，下面是所有这9个可能的配对</p><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="c77e" class="nt kx iq np b gy nu nv l nw nx">╔═══════╦═════════╦═══════════╗<br/>║ Index ║  Pair   ║ IsCorrect ║<br/>╠═══════╬═════════╬═══════════╣<br/>║     1 ║ (P1,P3) ║ Yes       ║<br/>║     2 ║ (P1,P4) ║ Yes       ║<br/>║     3 ║ (P1,P6) ║ Yes       ║<br/>║     4 ║ (P2,P3) ║ Yes       ║<br/>║     5 ║ (P2,P4) ║ Yes       ║<br/>║     6 ║ (P2,P6) ║ Yes       ║<br/>║     7 ║ (P3,P5) ║ No        ║<br/>║     8 ║ (P4,P5) ║ No        ║<br/>║     9 ║ (P5,P6) ║ Yes       ║<br/>╚═══════╩═════════╩═══════════╝</span></pre><p id="e3dc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">此处，列<strong class="lq ir"> isCorrect </strong>表示所提及的点对是否是基于预测概率的正确排序，即1类点比0类点具有更高的概率，在这9个可能的点对中的7个中，1类点的排序高于0类点，或者我们可以说，如果选择一对属于不同类的点，模型将有77%的机会能够正确区分它们。沃拉。现在，我认为您可能对这个AUC数字有一点直觉，只是为了澄清任何进一步的疑问，让我们使用scikit learn的AUC-ROC实现来验证它</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/1b355a25d18c05b3d217b95d467649bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JWNXQBolv3ApUF1bWF8G6A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">AUC验证的样本代码(图片由作者提供)</p></figure><h1 id="c51f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">何时使用</h1><p id="3327" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">尽管如此，AUC-ROC在某些地方可能并不理想。</p><ul class=""><li id="5537" class="mp mq iq lq b lr mk lu ml lx mr mb ms mf mt mj mu mv mw mx bi translated">AUC-ROC在数据集严重失衡的情况下效果不佳，为了给出一些直觉，让我们回顾一下这里的几何解释。基本上ROC是TPR和FPR之间的情节(假设少数阶级是积极阶级)，现在让我们再次仔细看看FPR公式</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/0003e296ac30501ac614ca49d209606f.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*cVW_c9blXFK7MLsl2dUEUg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="d746" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">FPR的分母有一个真阴性作为一个因素，因为阴性类占多数。FPR的分母由真阴性主导，这使得FPR对少数类预测的任何变化不太敏感(由于分母较高，假阳性数字的任何变化在FPR没有得到适当反映)。为了克服这个问题，使用精确召回曲线代替接收方操作者特征曲线，然后计算AUC，尝试自己回答这个问题精确召回曲线如何处理这个问题<em class="ne">(提示:比较PR曲线和ROC输入，召回和TPR是相同的，技术上只有FPR被精确代替，只需比较两者的分母，并尝试评估PR曲线中不平衡问题是如何解决的)</em></p><ul class=""><li id="9ad3" class="mp mq iq lq b lr mk lu ml lx mr mb ms mf mt mj mu mv mw mx bi translated">AUC-ROC试图衡量分类的等级排序是否正确，它没有考虑实际预测的概率，让我用一小段代码来说明这一点</li></ul><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="35a0" class="nt kx iq np b gy nu nv l nw nx">import pandas as pd</span><span id="189d" class="nt kx iq np b gy nz nv l nw nx">y_pred_1 = [0.99,0.98,0.97,0.96,0.91,0.90,0.89,0.88]<br/>y_pred_2 = [0.99,0.95,0.90,0.85,0.20,0.15,0.10,0.05]<br/>y_act = [1,1,1,1,0,0,0,0]<br/>test_df = pd.DataFrame (zip(y_act,y_pred_1,y_pred_2),columns=['Class','Model_1','Model_2'])<br/>test_df</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/eba3ac91a7dac786b9f5d106664a1995.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*68CuLayPAqABWHt0H8IVNg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">两个样本模型(图片由作者提供)</p></figure><p id="c246" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如上所述，我们有两个模型Model_1和Model_2，这两个模型都很好地隔离了这两个类别，但是如果我让你从它们中选择一个，你会选择哪一个，请稍等片刻，让我先画出这些模型的概率。</p><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="27c6" class="nt kx iq np b gy nu nv l nw nx">import matplotlib.pyplot as plt</span><span id="04bd" class="nt kx iq np b gy nz nv l nw nx">cols = ['Model_1','Model_2']<br/>fig,axs = plt.subplots(1,2,figsize=(15,5))<br/>for index,col in enumerate(cols): <br/>    sns.kdeplot(d2[d2['Status']==1][col],label="Class 1",shade=True,ax=axs[index])<br/>    sns.kdeplot(d2[d2['Status']==0][col],label="Class 0",shade=True,ax = axs[index])<br/>    axs[index].set_xlabel(col)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/32ed295faa3e9b4d945ef9b9c953a195.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jAkUpaE104I5ukJ32JTdeQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">预测概率分布(图片由作者提供)</p></figure><p id="0a6f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果之前有任何轻微的疑问，我想现在你的选择将是非常清楚的，Model_2是一个明显的赢家。但两者的AUC-ROC值是相同的，这是它的缺点，它只是测量模型是否能够正确地对类进行排序，它不查看模型区分两个类的程度，因此，如果您需要使用实际预测的概率，那么AUC-ROC可能不是正确的选择，对于那些好奇的人来说，log loss是解决此问题的一种度量</p><p id="cb1c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">因此，理想情况下，当数据集没有严重的不平衡，并且您的用例不要求您处理实际预测的概率时，应该使用AUC-ROC。</p><h1 id="f16d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">多类别的AUC</strong></h1><p id="d2ad" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对于多类设置，我们可以简单地使用一个对所有的方法，每个类都有一条ROC曲线。假设您有四个类别A、B、C、D，那么所有四个类别都有ROC曲线和相应的AUC值，即，一旦A是一个类别，B、C和D组合起来就是其他类别，类似地B是一个类别，A、C和D组合起来就是其他类别，等等。</p><h1 id="0348" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结束注释</h1><p id="daf2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">AUC-ROC是您在处理分类问题时会经常遇到的东西，无论是在线黑客马拉松还是您的组织中分配给您的项目。我希望我能够对AUC-ROC到底是什么以及何时使用它给出一些基本的理解。如果您想讨论什么或有任何建议，可以通过以下方式联系我:</p><p id="bcc8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">领英:【https://www.linkedin.com/in/ravindra-sharma-832a04156 T2】</p><h1 id="1e9d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><p id="56c1" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">[1]: <a class="ae kv" href="http://www.math.utah.edu/~gamez/files/ROC-Curves.pdf" rel="noopener ugc nofollow" target="_blank">《利用受试者工作特征(ROC)曲线分析分类模型:历史兴趣的最后注解》</a> (PDF)。<em class="ne">犹他大学数学系</em>。犹他大学数学系。检索于2017年5月25日</p></div></div>    
</body>
</html>