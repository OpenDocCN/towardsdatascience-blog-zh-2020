<html>
<head>
<title>Spark and Docker: Your Spark development cycle just got 10x faster!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark和Docker:您的Spark开发周期刚刚快了10倍！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spark-and-docker-your-spark-development-cycle-just-got-10x-faster-f41ed50c67fd?source=collection_archive---------7-----------------------#2020-11-03">https://towardsdatascience.com/spark-and-docker-your-spark-development-cycle-just-got-10x-faster-f41ed50c67fd?source=collection_archive---------7-----------------------#2020-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/9a7d8d49e771ae2c9b55643c9223ec56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iFITBfnMLl0z37mKhfd2Fw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">Spark &amp; Docker开发迭代周期。图片作者。</p></figure><p id="bd18" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用Docker容器的好处是众所周知的:它们提供了一致和隔离的环境，因此应用程序可以以可重复的方式部署在任何地方——本地、开发/测试/生产环境、所有云提供商和内部。</p><p id="3e37" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">软件工程界已经完全采用了Docker，围绕Docker的许多工具已经改变了我们构建和部署软件的方式——测试、CI/CD、依赖管理、版本控制、监控、安全。Kubernetes作为容器编排和基础设施管理的新标准的流行源于T2 Docker的流行。</p><p id="ed75" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在大数据和<a class="ae la" href="https://www.datamechanics.co/apache-spark" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>场景中，大多数应用程序仍然直接运行在虚拟机上，没有受益于容器化。Spark的主流集群管理器Hadoop YARN直到最近的<a class="ae la" href="https://hadoop.apache.org/docs/r3.1.1/hadoop-yarn/hadoop-yarn-site/DockerContainers.html" rel="noopener ugc nofollow" target="_blank"/>(Hadoop 3.1版本)才支持Docker容器，甚至今天对Docker的支持仍然是“实验性的和不完整的”。</p><p id="6a27" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">对Docker的本地支持实际上是公司选择在Kubernetes上部署<a class="ae la" href="https://www.datamechanics.co/blog-post/pros-and-cons-of-running-apache-spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank"> Spark而不是YARN </a>的主要原因之一。Spark-on-Kubernetes项目得到了社区的大力支持，直到2021年3月Apache Spark 3.1宣布<a class="ae la" href="https://datamechanics.co/blog-post/apache-spark-3-1-release-spark-on-kubernetes-is-now-ga" rel="noopener ugc nofollow" target="_blank">全面可用并准备好生产。</a></p><p id="9f32" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在本文中，我们将通过在<a class="ae la" href="https://www.datamechanics.co/blog-post/video-tour-of-data-mechanics-the-serverless-spark-platform" rel="noopener ugc nofollow" target="_blank"> Data Mechanics </a>的许多用户使用的端到端开发周期来说明<a class="ae la" href="https://www.datamechanics.co/apache-spark" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>的Docker的好处。</p><h1 id="6694" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">Docker为Apache Spark带来的好处</h1><h2 id="0825" class="lz lc iq bd ld ma mb dn lh mc md dp ll kn me mf lp kr mg mh lt kv mi mj lx mk bi translated">1.一次构建您的依赖项，随处运行</h2><p id="9191" class="pw-post-body-paragraph kc kd iq ke b kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv mp kx ky kz ij bi translated">无论在哪里运行，您的应用程序都将以相同的方式运行:在用于开发/测试的笔记本电脑上，或者在您的任何生产环境中。在您的Docker映像中，您将:</p><ul class=""><li id="cb5a" class="mq mr iq ke b kf kg kj kk kn ms kr mt kv mu kz mv mw mx my bi translated">打包您的应用程序代码</li><li id="7754" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz mv mw mx my bi translated">打包你所有的依赖(python: pypi，eggs，conda，scala / java: jars，maven系统依赖性)</li><li id="0d1e" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz mv mw mx my bi translated">定义环境变量来调整运行时的行为</li><li id="e755" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz mv mw mx my bi translated">按照您想要的方式定制您的操作系统</li><li id="affc" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz mv mw mx my bi translated">如果在Kubernetes上运行:你可以为每个单独的Docker图像自由选择你的Spark版本！这与YARN不同，YARN必须为整个集群使用相同的全局Spark版本。</li></ul><h2 id="c1cf" class="lz lc iq bd ld ma mb dn lh mc md dp ll kn me mf lp kr mg mh lt kv mi mj lx mk bi translated">2.使Spark在生产中更可靠、更具成本效益。</h2><p id="6331" class="pw-post-body-paragraph kc kd iq ke b kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv mp kx ky kz ij bi translated">由于您可以在构建Docker映像时控制整个环境，这意味着您不需要在运行时执行任何init脚本/引导操作。</p><p id="167b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这些脚本有几个问题:</p><ul class=""><li id="ea18" class="mq mr iq ke b kf kg kj kk kn ms kr mt kv mu kz mv mw mx my bi translated">它们并不可靠——库安装可能会由于虚假的网络故障而失败，并对生产中的Spark管道故障负责。</li><li id="3348" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz mv mw mx my bi translated">它们很慢——这些运行时脚本会给每个Spark节点增加几分钟的设置时间，从而增加成本。</li><li id="f9cb" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz mv mw mx my bi translated">它们很难开发、维护和调试。</li></ul><h2 id="593c" class="lz lc iq bd ld ma mb dn lh mc md dp ll kn me mf lp kr mg mh lt kv mi mj lx mk bi translated">3.加快你的迭代周期。</h2><p id="db30" class="pw-post-body-paragraph kc kd iq ke b kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv mp kx ky kz ij bi translated">在Data Mechanics，我们的用户享受20-30秒的迭代周期，从他们在IDE中进行代码更改到这一更改在我们的平台上作为Spark应用程序运行。</p><p id="a47c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这主要是因为Docker缓存了以前构建的层，而且Kubernetes启动/重启Docker容器的速度非常快。</p><figure class="nf ng nh ni gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/e75a3dd708728bd674f70713366fad29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8rdDPa8X8YEkv_Bd.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">Spark &amp; Docker开发迭代周期。图片作者。</p></figure><h1 id="40f4" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">教程:如何使用Docker将您的Spark开发周期加快10倍</h1><p id="e18f" class="pw-post-body-paragraph kc kd iq ke b kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv mp kx ky kz ij bi translated">在这一节中，我们将逐步向您展示如何使用Spark和Docker。示例截屏和代码样本取自在Data Mechanics平台上运行PySpark应用程序，但是这个示例可以简单地进行修改以在其他环境中工作。</p><h2 id="c983" class="lz lc iq bd ld ma mb dn lh mc md dp ll kn me mf lp kr mg mh lt kv mi mj lx mk bi translated">1.建立码头工人形象</h2><p id="53b7" class="pw-post-body-paragraph kc kd iq ke b kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv mp kx ky kz ij bi translated">我们将从一个包含一些依赖项的本地PySpark项目和一个解释如何为这个项目构建Docker映像的Docker文件开始。一旦构建了Docker映像，我们可以直接在本地运行它，或者先推送至Docker注册表，然后在Data Mechanics集群上运行它。</p><p id="94e5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">多亏了Docker，不需要在脆弱的zip文件中打包第三方依赖项和定制模块。您可以将主脚本及其依赖项放在同一位置。</p><p id="2aa2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这个例子中，我们采用了大多数Python开发人员应该熟悉的项目布局:一个主脚本、一个需求文件和定制模块。</p><figure class="nf ng nh ni gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/c86bd020b059c0d4d02ec52b8e1f215f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/0*WvA2xT3k3GXdWVs_.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图片作者。</p></figure><p id="03d0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们看看docker文件。在本例中:</p><ol class=""><li id="44d1" class="mq mr iq ke b kf kg kj kk kn ms kr mt kv mu kz nk mw mx my bi translated">我们从Data Mechanics发布的基本图像开始。该图像对应于主火花图像(此处为3.0)。我们将在本文末尾详细讨论这一选择。</li><li id="b66d" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz nk mw mx my bi translated">然后我们安装我们的依赖项。我们在这里使用了pip，但是我们也可以使用conda。</li><li id="d9b5" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz nk mw mx my bi translated">我们最后复制我们自己的代码和主文件。因为这是我们将主要迭代的代码，所以建议在最后这样做，这样当我们更改代码时，Docker就不需要从头开始重建映像。</li><li id="b6e9" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz nk mw mx my bi translated">在这一步设置环境变量也很容易。</li></ol><figure class="nf ng nh ni gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/93b97f25a6b9f88643f7af7182c7445a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H1I3ItI2kMAq6k8h-EpCAQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">示例Dockerfile文件。图片作者。</p></figure><h2 id="f1af" class="lz lc iq bd ld ma mb dn lh mc md dp ll kn me mf lp kr mg mh lt kv mi mj lx mk bi translated">2.本地运行</h2><figure class="nf ng nh ni gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/098ab7e991a6f4fa13b179f737fd080b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Glj390kVbtvDwGHS.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图片作者。</p></figure><p id="98bb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然后，您可以构建这个映像并在本地运行它。这意味着Spark将以本地模式运行；作为笔记本电脑上的一个单独的容器。您将不能处理大量的数据，但是如果您只想测试您的代码正确性(可能使用真实数据的一个小的子集)，或者运行单元测试，这是有用的。</p><figure class="nf ng nh ni gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/abdf444259e26b6d94a0ee0607d581eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rQ5buV5Ye9FUlIFN.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图片作者。</p></figure><p id="691b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在普通的笔记本电脑上，这需要15秒。如果你打算在这个阶段进行大量迭代，并希望进一步优化速度；然后，您可以简单地将本地文件(从笔记本电脑上的工作目录)挂载到映像中的工作目录，而不是重新构建映像。</p><h2 id="7f0e" class="lz lc iq bd ld ma mb dn lh mc md dp ll kn me mf lp kr mg mh lt kv mi mj lx mk bi translated">3.规模化经营</h2><p id="613a" class="pw-post-body-paragraph kc kd iq ke b kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv mp kx ky kz ij bi translated">代码看起来是正确的，我们现在想要在完整的数据集上运行这个图像。我们将把图像推送到Docker注册中心，然后在<a class="ae la" href="https://docs.datamechanics.co/docs/first-application" rel="noopener ugc nofollow" target="_blank"> REST API调用</a>中提供图像名称作为参数，将这个Spark应用程序提交给数据机制。</p><figure class="nf ng nh ni gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/4fe8062434a4b71015b6dfb1ff2bff30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OrJ8KQDbLstK-lxC.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图片作者。</p></figure><p id="bf3a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这个阶段拥有一个快速的迭代周期也很重要——即使您在本地运行了映像——因为您需要在整个数据集上验证管道的正确性和稳定性。很可能你需要不断迭代你的代码和你的基础设施配置。</p><p id="c73e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在一台普通的笔记本电脑上，完成这一步需要20秒钟:10秒钟构建和推送映像，10秒钟应用程序启动数据机制——这意味着Spark驱动程序开始执行我们的<strong class="ke ir"> main.py </strong>代码。</p><p id="4bc2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在不到30秒的时间内，您就可以迭代您的Spark代码，并在生产数据上运行它！并且您可以在不离开IDE的情况下做到这一点(您不需要将代码粘贴到笔记本或交互式shell中)。对于Spark开发者来说，这是一个游戏规则的改变，比行业平均速度快10倍。</p><blockquote class="np nq nr"><p id="afa1" class="kc kd ns ke b kf kg kh ki kj kk kl km nt ko kp kq nu ks kt ku nv kw kx ky kz ij bi translated">“我真的很高兴我们可以使用Docker来打包我们的数据机制代码。这是简化PySpark部署的巨大胜利。根据我完成的迭代，部署和运行该应用不到30秒”</p><p id="62e4" class="kc kd ns ke b kf kg kh ki kj kk kl km nt ko kp kq nu ks kt ku nv kw kx ky kz ij bi translated">— Max，Weather2020的数据工程师。</p></blockquote><p id="68a8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这种快速的迭代周期得益于Docker缓存了图像的前几层，以及Data Mechanics平台(部署在Kubernetes上)优化了快速容器启动和应用程序重启。</p><h1 id="dfef" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">如何选择你的火花基地码头形象</h1><p id="0195" class="pw-post-body-paragraph kc kd iq ke b kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv mp kx ky kz ij bi translated">自2021年4月以来，<a class="ae la" href="https://www.datamechanics.co/blog-post/optimized-spark-docker-images-now-available" rel="noopener ugc nofollow" target="_blank"> Data Mechanics维护着一个Docker映像的公共舰队</a>，这些映像内置了Spark、Java、Scala、Python、Hadoop，以及与S3、GCS、Azure Data Lake、Delta Lake等公共数据源的连接器。每当发布新版本的Spark或其中一个包含的依赖项时，我们都会定期向这些映像推送更新，并在各种工作负载和虚拟环境中测试它们。</p><figure class="nf ng nh ni gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nw"><img src="../Images/2709fa368ec96048d74bc6d0ad067eaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yJ82mi6DUTkL2-E8.png"/></div></div></figure><p id="2378" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因此，我们希望它们能为您服务，开箱即用，让您摆脱复杂的依赖问题。要找到适合你的图像:</p><ul class=""><li id="1a8c" class="mq mr iq ke b kf kg kj kk kn ms kr mt kv mu kz mv mw mx my bi translated">如果你是数据力学的客户，请参考我们的<a class="ae la" href="https://docs.datamechanics.co/docs/docker-images" rel="noopener ugc nofollow" target="_blank">文档</a>。我们的平台映像具有更高的可用性保证，以及一些独有的平台改进(如Jupyter笔记本支持)。</li><li id="536c" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz mv mw mx my bi translated">对于非数据力学客户，我们的优化图像现在可以在我们的<a class="ae la" href="https://hub.docker.com/r/datamechanics/spark" rel="noopener ugc nofollow" target="_blank">公共DockerHub库</a>上免费获得。你可以让他们在本地、Kubernetes或其他架构上运行Spark。</li></ul><h1 id="ccac" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><ul class=""><li id="1b30" class="mq mr iq ke b kf ml kj mm kn nx kr ny kv nz kz mv mw mx my bi translated">以简单的方式打包您的依赖项并控制您的环境。</li><li id="b7d2" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz mv mw mx my bi translated">通过在本地或大规模快速运行Spark，在IDE中迭代您的代码</li><li id="9759" class="mq mr iq ke b kf mz kj na kn nb kr nc kv nd kz mv mw mx my bi translated">使Spark在生产中更可靠、更具成本效益。最后，您可以告别缓慢和古怪的引导脚本和运行时下载！</li></ul><p id="c46b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们已经展示了Docker如何帮助您:</p><p id="8ad2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果这听起来像是您想在数据机制平台上尝试的东西，<a class="ae la" href="https://calendly.com/datamechanics/demo" rel="noopener ugc nofollow" target="_blank">向我们的团队预订一个演示</a>来开始数据机制的试用——我们将帮助您采用这个基于Docker的开发工作流，作为我们入职的第一步。</p><p id="9bfc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">以Docker原生和云不可知的方式在Kubernetes上运行Spark还有许多其他好处。例如，您可以使用上面的步骤构建一个CI/CD管道，每当您提交一个pull请求来修改您的一个生产管道时，它就会自动构建和部署Spark测试应用程序。我们将在未来的博客文章中对此进行报道，敬请关注！</p></div></div>    
</body>
</html>