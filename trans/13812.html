<html>
<head>
<title>Run your Spark data processing workloads using OpenDataHub, OCS, and an external Ceph cluster</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用OpenDataHub、OCS和外部Ceph集群运行Spark数据处理工作负载</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/run-your-spark-data-processing-workloads-using-opendatahub-ocs-and-an-external-ceph-cluster-8922f166f884?source=collection_archive---------32-----------------------#2020-09-22">https://towardsdatascience.com/run-your-spark-data-processing-workloads-using-opendatahub-ocs-and-an-external-ceph-cluster-8922f166f884?source=collection_archive---------32-----------------------#2020-09-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/3a7a2f4081b05a2276230adeebab404f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NS3kHIL2w57XEUJ3"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://unsplash.com/@ev?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> ev </a>在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c78d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Kubernetes已经成为事实上的标准容器编排平台。通过这种方法，组织试图围绕Kubernetes收集所有的应用程序和平台，以利用其稳定性、敏捷性和简单性。在Kubernetes中运行您的整个堆栈将允许您拥有一个单一的API和一种通用语言，无论是用于需要部署的应用程序、数据库还是存储引擎。</p><p id="bcfa" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">几年前，人们认为，为了获得更高的大数据工作负载性能，您的应用程序需要主要基于闪存介质的高性能本地磁盘。将计算和存储放在一起带来了自身的挑战，主要是在出现故障和升级时，因为组织必须将它们作为一个整体来对待。</p><p id="c11b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">今天，我们看到许多数据处理引擎，如Spark、Presto等使用S3作为存储后端。使用S3处理大数据工作负载有多种原因:</p><ul class=""><li id="075a" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">S3是一个面向吞吐量的存储系统，可以支持来回传输大量数据</li><li id="3444" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">S3是基于HTTP的，当必须开发一个连接器来访问它时，它是非常可移植的</li><li id="09ef" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">S3拥有自己的智能数据管理功能，如存储桶生命周期、存储类别、版本控制等，可以减轻最终用户的数据管理负担</li></ul><p id="43ab" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">今天，我想和你重点谈谈如何使用S3存储后端在Kubernetes上运行你的数据处理引擎。为此，让我们简单介绍一下我们将要使用的平台:</p><ul class=""><li id="3ea0" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">Ceph —将用作Openshift集群外部的S3网关</li><li id="b48d" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">Openshift集装箱存储—将为我们提供类似Kubernetes的功能来处理我们的S3，将在稍后讨论</li><li id="b701" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">开放式数据中心——将用作我们的spark集群和Jupyter笔记本电脑的数据处理供应器，以运行我们的Spark工作负载</li></ul><h1 id="ef26" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">先决条件</h1><ul class=""><li id="a587" class="le lf it ki b kj mq kn mr kr ms kv mt kz mu ld lj lk ll lm bi translated">正在运行的Openshift 4.5集群</li><li id="4b4e" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">正在运行的RHCS 4.1集群</li><li id="67c4" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">这两者之间的网络连接</li></ul><p id="fdba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们要部署的第一个组件是OCS (Openshift Container Storage ),它将成为我们S3存储后端的Kubernetes管理平台。使用昨天发布的OCS 4.5，您可以将外部Ceph集群连接到OCS管理平面，以利用其资源。这种部署方法称为“独立模式”,主要用于正在处理的工作负载和容量超过OCS内部模式处理能力的情况。(内部模式将在Openshift上运行您的Ceph集群，这对于中小型数据工作负载非常有用)。</p><p id="800d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们连接到Openshift集群，进入<code class="fe mv mw mx my b">Operator Hub</code>选项卡，并安装OCS操作符。该运营商将部署我们的OCS管理平台，并将连接到外部Ceph集群:</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mz"><img src="../Images/969ccae9e4c414c0bfef0143a06114ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qhwuVl2ktCFm4v5OOl12qg.png"/></div></div></figure><p id="beff" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">安装好操作员后，让我们创建一个独立的集群，为此我们点击<code class="fe mv mw mx my b">Create Storage Cluster</code>和<code class="fe mv mw mx my b">independent mode</code>。这将要求在我们的Ceph集群上运行一个脚本，该脚本将收集将OCS连接到我们的外部Ceph集群所需的所有信息。该脚本将抛出一个JSON文件到STDOUT，请将它粘贴到代码片段中。</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ne"><img src="../Images/b031e3a5468c4448f3956c54fd881fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fp9qAStyihJ_PZyoXDFgGg.png"/></div></div></figure><p id="1d24" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建集群后，我们应该让它处于<code class="fe mv mw mx my b">Ready</code>状态:</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nf"><img src="../Images/d7debe5d321e1a775775fefb134db64a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-sLlJd7HBbEBXDQTuPG_Mw.png"/></div></div></figure><p id="a771" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们已经准备好了S3后端，让我们创建一个<code class="fe mv mw mx my b">Object Bucket Claim</code>,这样我们的Spark应用程序就可以使用它来处理数据。OBC(对象桶声明)是一种将桶视为Kubernetes持久卷声明的方式。这个对象对于OCS是唯一的，并且减轻了开发人员跟踪其凭证、bucket名称和端点URL的需要。要创建bucket claim，只需转到Openshift控制台中的<code class="fe mv mw mx my b">Object Bucket Claims</code>(存储选项卡下)，创建一个OBC并选择RGW存储类作为目标。</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ng"><img src="../Images/52c20ac43a2a495deb7bcb372eff5dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ivLjbI-4eXkkFE7JD2aXA.png"/></div></div></figure><p id="2de2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种自动化将在我们的外部Ceph集群中创建一个用户和一个存储桶，并将所有信息存储在ConfigMaps中，并将机密存储在我们的Openshift集群中。凭据将存储为机密，而存储桶名称、存储桶端口和端点URL将存储为ConfigMap。</p><p id="5381" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了验证确实创建了bucket，让我们使用<code class="fe mv mw mx my b">radosgw-admin</code>命令访问我们的Ceph集群并列出我们拥有的bucket:</p><pre class="na nb nc nd gt nh my ni nj aw nk bi"><span id="4571" class="nl lt it my b gy nm nn l no np">$ radosgw-admin bucket list | grep spark<br/>    "spark-bucket-1143d1c8-e321-496a-821c-9c1b89297685"</span></pre><p id="5d66" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到我们有一个由OBC创建的存储桶，现在让我们尝试获取有关我们创建的存储桶的更多信息:</p><pre class="na nb nc nd gt nh my ni nj aw nk bi"><span id="9323" class="nl lt it my b gy nm nn l no np">$ radosgw-admin bucket stats --bucket spark-bucket-1143d1c8-e321-496a-821c-9c1b89297685<br/>{<br/>    "bucket": "spark-bucket-1143d1c8-e321-496a-821c-9c1b89297685",<br/>    "num_shards": 11,<br/>    "tenant": "",<br/>    "zonegroup": "c6f894d0-256a-425f-92ec-b5c41366c1cb",<br/>    "placement_rule": "default-placement",<br/>    "explicit_placement": {<br/>        "data_pool": "",<br/>        "data_extra_pool": "",<br/>        "index_pool": ""<br/>    },<br/>    "id": "9cdf5d28-ceb4-4629-b507-13509f8c99ab.84164.2",<br/>    "marker": "9cdf5d28-ceb4-4629-b507-13509f8c99ab.84164.2",<br/>    "index_type": "Normal",<br/>    "owner": "ceph-user-bbX0Qdrn",<br/>    "ver": "0#1,1#1,2#1,3#1,4#1,5#1,6#1,7#1,8#1,9#1,10#1",<br/>    "master_ver": "0#0,1#0,2#0,3#0,4#0,5#0,6#0,7#0,8#0,9#0,10#0",<br/>    "mtime": "2020-09-17 14:15:12.993277Z",<br/>    "max_marker": "0#,1#,2#,3#,4#,5#,6#,7#,8#,9#,10#",<br/>    "usage": {},<br/>    "bucket_quota": {<br/>        "enabled": false,<br/>        "check_on_raw": false,<br/>        "max_size": -1,<br/>        "max_size_kb": 0,<br/>        "max_objects": -1<br/>    }<br/>}</span></pre><p id="205b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到还创建了一个新用户(在<code class="fe mv mw mx my b">Owner</code>部分下)。现在，让我们验证我们的信息是否如保证的那样位于我们的Openshift集群中。让我们描述一下我们称为<code class="fe mv mw mx my b">spark-bucket</code>的OBC对象:</p><pre class="na nb nc nd gt nh my ni nj aw nk bi"><span id="a46f" class="nl lt it my b gy nm nn l no np">$ oc describe secret spark-bucket<br/>                                                                                                               <br/>Name:         spark-bucket<br/>Namespace:    amq-streams<br/>Labels:       bucket-provisioner=openshift-storage.ceph.rook.io-bucket<br/>Annotations:  &lt;none&gt;<br/>Type:  Opaque<br/>Data<br/>====<br/>AWS_ACCESS_KEY_ID:      20 bytes<br/>AWS_SECRET_ACCESS_KEY:  40 bytes</span></pre><p id="96c2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到，我们将访问密钥和秘密密钥作为秘密存储在Openshift集群中。现在让我们做同样的事情，描述配置图，看看我们是否有其余的信息:</p><pre class="na nb nc nd gt nh my ni nj aw nk bi"><span id="96c8" class="nl lt it my b gy nm nn l no np">$ oc describe cm spark-bucket</span><span id="8d38" class="nl lt it my b gy nq nn l no np">Name:         spark-bucket<br/>Namespace:    amq-streams<br/>Labels:       bucket-provisioner=openshift-storage.ceph.rook.io-bucket<br/>Annotations:  &lt;none&gt;</span><span id="18a9" class="nl lt it my b gy nq nn l no np">Data<br/>====<br/>BUCKET_NAME:<br/>----<br/>spark-bucket-1143d1c8-e321-496a-821c-9c1b89297685<br/>BUCKET_PORT:<br/>----<br/>8080<br/>BUCKET_REGION:<br/>----<br/>us-east-1<br/>BUCKET_SUBREGION:<br/>----</span><span id="2723" class="nl lt it my b gy nq nn l no np">BUCKET_HOST:<br/>----<br/>10.32.0.3<br/>Events:  &lt;none&gt;</span></pre><p id="8b92" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了！我们已经获得了所需的信息，这样我们的Spark应用程序就可以到达我们的S3后端。让我们创建一个名为<code class="fe mv mw mx my b">odh</code>的新项目，它将存储<code class="fe mv mw mx my b">Open Data Hub</code>工作负载。</p><pre class="na nb nc nd gt nh my ni nj aw nk bi"><span id="6f5e" class="nl lt it my b gy nm nn l no np">$ oc new-project odh</span></pre><p id="b3cc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">之后，我们将安装Open Data Hub operator，这样我们就可以启动和配置我们的Spark集群:</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/ac975c5abe55ce652665a89a3add6b80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pH5x4g-rkqeFFzKAR4GDIw.png"/></div></div></figure><p id="1888" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们成功安装了ODH操作符之后，我们将创建一个<code class="fe mv mw mx my b">Open Data Hub</code>定制资源，它将提供所有需要的对象供我们使用。创建CR后，将为您的<code class="fe mv mw mx my b">Jupyter Hub</code>笔记本创建一条路线，从<code class="fe mv mw mx my b">s2i-spark-minimal-notebook:3.6</code>映像创建一个新笔记本。</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/3aac215c443fed14a283c74911bcdd94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UutzR-fvVwhLnvf6AW_AxA.png"/></div></div></figure><p id="ead1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建这个笔记本将创建一个spark集群，其中的每一个pod都充当一个Spark executor。这还将创建一个笔记本数据库，用于存储笔记本中保存的所有信息。这是与您的用户1:1的关系，所以下次您登录时，您将看到相同的笔记本。</p><p id="1c4f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们看看豆荚是否真的被创造出来了:</p><pre class="na nb nc nd gt nh my ni nj aw nk bi"><span id="ec0d" class="nl lt it my b gy nm nn l no np">$ oc get pods</span><span id="df8a" class="nl lt it my b gy nq nn l no np">NAME                                    READY   STATUS      RESTARTS   AGE<br/>jupyterhub-1-2bglz                      1/1     Running     0          17m<br/>jupyterhub-1-deploy                     0/1     Completed   0          17m<br/>jupyterhub-db-1-72fbr                   1/1     Running     0          17m<br/>jupyterhub-db-1-deploy                  0/1     Completed   0          17m<br/>jupyterhub-nb-kube-3aadmin              2/2     Running     0          14m<br/>opendatahub-operator-6c96795b8b-kmhhh   1/1     Running     0          19m<br/>spark-cluster-kube-admin-m-9w69r        1/1     Running     0          14m<br/>spark-cluster-kube-admin-w-wb54g        1/1     Running     0          14m<br/>spark-cluster-kube-admin-w-x5zn9        1/1     Running     0          14m<br/>spark-operator-74cfdf544b-mrdzf         1/1     Running     0          17m</span></pre><p id="86f8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了！我们有自己的基础设施。现在让我们验证我们的<code class="fe mv mw mx my b">Jupyter Notebook</code>是持久的:</p><pre class="na nb nc nd gt nh my ni nj aw nk bi"><span id="ff77" class="nl lt it my b gy nm nn l no np">$ oc get pv<br/>                                                                                                                          <br/>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                STORAGECLASS                              REASON   AGE<br/>pvc-6ec75973-a17a-44d6-b308-42cc4c4664fd   1Gi        RWO            Delete           Bound    odh/jupyterhub-db                    ocs-independent-storagecluster-ceph-rbd            43m<br/>pvc-b3064182-ef7c-434f-a3f3-10c8f198a7d8   2Gi        RWO            Delete           Bound    odh/jupyterhub-nb-kube-3aadmin-pvc   ocs-independent-storagecluster-ceph-rbd            39m</span></pre><p id="d0a5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为奖励，ODH运营商将为我们的笔记本电脑数据库连接一个PVC，该PVC取自存储在我们外部Ceph集群中的RBD池，我们在一个系统中获得了两个存储协议，多么令人兴奋！</p><p id="c9c8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们简单介绍一下我们的Spark工作负载。在这个工作负载中，我们将上传一个包含学生成绩的CSV文件到我们的S3存储桶。这个CSV文件包含了学生的名字，以及他们在4个年级的分数，也就是最后的成绩。我们的目标是使用火花处理为每个等级收集频率。</p><p id="2349" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来看看我们的Jupyter笔记本:</p><figure class="na nb nc nd gt ju"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="f530" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对我们在这里看到的做一点解释:</p><ul class=""><li id="ca16" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">在第一阶段，我们检查spark集群中的连通性，输出以Spark执行器的名字打印，可以与pods运行相关联。</li><li id="a693" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">稍后，我们使用<code class="fe mv mw mx my b">wget</code>将CSV文件下载到我们的本地笔记本中，并将其保存在我们的DB中</li><li id="bf2a" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">我们使用<code class="fe mv mw mx my b">boto</code>库，以便使用从我们的bucket claim收集的信息将CSV文件上传到我们的S3 bucket</li><li id="380a" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">然后，我们使用相同的变量来设置Spark <code class="fe mv mw mx my b">s3a</code>连接器使用的配置</li><li id="0ba1" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">我们从我们的S3桶中读取CSV文件并打印分数。注意了！我们有一个错误的值，即第9个单元格中的“A ”,这会影响我们数据的可靠性</li><li id="69c7" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">我们清理这个值，最后建立一个等级频率图</li></ul><h1 id="9db2" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">结论</h1><p id="7b50" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr nv kt ku kv nw kx ky kz nx lb lc ld im bi translated">我们看到了如何利用Openshift平台，以一种简单、可访问的方式运行我们的Spark处理工作负载。利用OCS的优势，我们简化了处理S3存储后端的方式，并获得了双存储协议存储引擎解决方案来存储我们的数据集和笔记本电脑的数据库。希望你喜欢这个演示，下次再见:)</p></div></div>    
</body>
</html>