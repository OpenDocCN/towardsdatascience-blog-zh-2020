<html>
<head>
<title>Deformable Convolution and Its Applications in Video Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可变形卷积及其在视频学习中的应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deformable-convolution-and-its-applications-in-video-learning-e21005cab58e?source=collection_archive---------42-----------------------#2020-11-04">https://towardsdatascience.com/deformable-convolution-and-its-applications-in-video-learning-e21005cab58e?source=collection_archive---------42-----------------------#2020-11-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a5bd" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="21c2" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">利用带有稀疏标记数据的视频帧</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/240ae70b399f8876b5a47191f6f65b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KWWQpg4ZwDJwXL2JHuIAMw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(<a class="ae lh" href="https://www.researchgate.net/figure/The-illustration-of-deformable-convolution-The-offset-ranges-in-the-width-and-the-height_fig1_334104866" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="f079" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">卷积层是卷积神经网络的基本层。虽然它广泛应用于计算机视觉和深度学习，但它有几个缺点。例如，对于特定的输入特征图，核权重是固定的，并且不能适应局部特征变化，因此我们需要更多的核来建模特征图的复杂上下文，这是多余的并且效率不高。此外，由于输出像素的感受野总是矩形，作为分层卷积的累积效应，感受野变得更大，其中将包含一些与输出像素无关的上下文背景。不相关的背景会给输出像素的训练带来噪声。</p><p id="19ec" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">想象一下，为了克服上述问题，你想对传统的卷积层做一个小小的改变:核可以适应局部特征变化，感受野可以收敛到与输出像素对应的语义背景。幸运的是，它已经实现了，细化卷积层的名称叫做可变形卷积层。</p><p id="f0b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本帖中，我将介绍这些话题:</p><ol class=""><li id="74a7" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">可变形卷积</li><li id="e20b" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">利用可变形卷积提高关键点估计的性能</li><li id="1386" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">使用可变形卷积增强实例分割的性能</li></ol></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h2 id="876c" class="mz na it bd nb nc nd dn ne nf ng dp nh lr ni nj nk lv nl nm nn lz no np nq iz bi translated">可变形卷积</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nr"><img src="../Images/1481b69f7b3be509e7883ba76187f3ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qv_B8L8iJTfx2ksN8WLZDw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(可变形卷积)</p></figure><p id="412a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">可变形卷积是卷积层加偏移学习。如上所示，对于卷积核的每个足迹，学习2D偏移，以便将足迹引导到对训练最优化的位置。偏移学习部分也是卷积层，其输出通道的数量是输入通道数量的两倍，因为每个像素有两个偏移坐标。基于该方法，核可以适应局部特征变化，有利于语义特征学习。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ns"><img src="../Images/60edfac88b97c60db06d00bfb70e810a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iwgotjMZqzTRP4s7Lyfglw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(覆盖区偏移示例)</p></figure><p id="d122" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是偏移学习的一个例子。a是传统的卷积，其中内核足迹完全不移动。b、c和d表示足迹的移动。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nt"><img src="../Images/5c8b2d483f696756fde9026c316ac770.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B_rapojPmA-JJ3TczIVkgA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(可变形卷积的感受野细化)</p></figure><p id="150e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">结果，在可变形卷积中，深像素的感受野集中于相应的物体。如上图，在a中，深蓝色像素(上图)属于大羊。然而，它的矩形感受野(底部)包含左下方的小绵羊，这可能会为实例分割等任务带来模糊性。b中感受野变形，集中在大羊上，其中避免了歧义。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h2 id="6c6f" class="mz na it bd nb nc nd dn ne nf ng dp nh lr ni nj nk lv nl nm nn lz no np nq iz bi translated">理解可变形卷积中的偏移</h2><p id="d79e" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">如上所述，偏移有助于局部特征的核心适应和感受野的集中。顾名思义，offset用于使内核足迹局部变形，从而使感受野整体变形。</p><p id="7f02" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在棘手的部分来了:既然可以学习偏移来适应当前图片中的对象，我们是否可以通过提供偏移来使当前图片中的对象适应另一张图片中的对象？</p><p id="5f7c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们把它具体化。假设我们有一个视频，其中每一帧都与其相邻帧相似。然后，我们稀疏地选择一些帧，并在像素级对它们进行标记，如语义分割或关键点等。既然这几类像素级的标签都很贵，那我们能不能用无标签的相邻帧来提高概化的精度呢？具体来说，用一种方法将未标记帧的特征图变形到其相邻的标记帧，以补偿标记帧中缺失的信息？</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h2 id="b773" class="mz na it bd nb nc nd dn ne nf ng dp nh lr ni nj nk lv nl nm nn lz no np nq iz bi translated">从稀疏标记视频中学习时间姿态估计</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/fd4656363470f79a24a0360b39d0c134.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ynu3F8t9LBH-8jkSWRj2bA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(特征地图扭曲模型)</p></figure><p id="31b3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这项研究很好地解决了上面讨论的问题。由于标记是昂贵的，所以在视频中只有少量的帧被标记。然而，标记帧图像中的固有问题，如遮挡、模糊等。阻碍模型训练的准确性和效率。为了解决这个问题，作者使用可变形卷积将未标记帧的特征映射变形为它们相邻的标记帧的特征映射，以补偿上面讨论的固有问题。偏移量就是已标记帧与其未标记相邻帧之间的优化特征差异。可变形部分由多分辨率特征金字塔构成，其中使用了不同的膨胀。这种方法的优点是，我们可以利用相邻的未标记帧来增强标记帧的特征学习，因此我们不需要标记视频的每一帧，因为相邻的帧是相似的。这种变形方法，也被作者称为“扭曲”方法，比其他一些视频学习方法，如光流或3D卷积等，更便宜，更有效。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/35a80ff69d3169348ad0b9249222bdff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8q0Mk1Xzl7_Z4OgB9c2LWg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(扭曲模型的训练和推断)</p></figure><p id="1a92" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如上所示，在训练期间，未标记帧B的特征图被扭曲到其相邻的标记帧A的特征图。在推断期间，帧A的基本事实可以使用训练的扭曲模型来传播，以获得帧B的关键点估计。此外，可以扭曲更多的相邻帧，聚集它们的特征图，以提高关键点估计的准确性。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h2 id="9de1" class="mz na it bd nb nc nd dn ne nf ng dp nh lr ni nj nk lv nl nm nn lz no np nq iz bi translated">具有掩模传播的视频中的实例分割</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/f69de791209aa6bd1d22a3194948c30f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IihDyRtvRysgUilLGz1q1w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(基于掩码RCNN的掩码传播)</p></figure><p id="26cd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">作者还通过在现有的Mask-RCNN模型中添加掩模传播头，提出了用于实例分割的掩模传播，其中在时间t的预测实例分割可以传播到其相邻的帧t + δ。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/84f7f124d8eca8ffce4d5bebd6e1587d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0FErIN3FTdjLZMB1AEx2hQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(掩模传播的网络结构)</p></figure><p id="bb06" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">网络结构类似于上面讨论的姿态估计网络，但有点复杂。它有三个部分:1)帧t的实例分割预测；2)帧t和t + δ之间的偏移优化和分割变形；3)用于帧t + δ处实例分割的最终预测的特征图聚集。在这里，作者还使用乘法层来过滤噪声，只关注对象实例存在的特征。利用来自相邻帧的特征集合，可以减轻遮挡、模糊的问题。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h2 id="dce1" class="mz na it bd nb nc nd dn ne nf ng dp nh lr ni nj nk lv nl nm nn lz no np nq iz bi translated">结论</h2><p id="d6e2" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">可变形卷积可以被引入到具有给定偏移的视频学习任务中，其中标签传播和特征聚集被实现以提高模型性能。与传统的一帧一标签学习方式相比，作者提出了多帧一标签学习方式，利用相邻帧的特征图来增强表征学习。因此，模型可以被训练来从相邻帧中看到被其他眼睛遮挡或模糊的内容。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h2 id="9edf" class="mz na it bd nb nc nd dn ne nf ng dp nh lr ni nj nk lv nl nm nn lz no np nq iz bi translated">参考</h2><p id="ce85" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated"><a class="ae lh" href="https://arxiv.org/pdf/1703.06211.pdf" rel="noopener ugc nofollow" target="_blank">可变形卷积网络，2017 </a> <br/> <a class="ae lh" href="https://arxiv.org/pdf/1906.04016.pdf" rel="noopener ugc nofollow" target="_blank">从稀疏标记的视频中学习时间姿态估计，2019 </a> <br/> <a class="ae lh" href="https://arxiv.org/pdf/1912.04573.pdf" rel="noopener ugc nofollow" target="_blank">利用掩模传播对视频中的对象实例进行分类、分割和跟踪，2020 </a></p><div class="od oe gp gr of og"><a href="https://dushuchen.medium.com/membership" rel="noopener follow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd jd gy z fp ol fr fs om fu fw jc bi translated">加入我的介绍链接-陈数杜媒体</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">阅读陈数·杜(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接支持…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">dushuchen.medium.com</p></div></div><div class="op l"><div class="oq l or os ot op ou lb og"/></div></div></a></div></div></div>    
</body>
</html>