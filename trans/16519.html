<html>
<head>
<title>Approximating stochastic functions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逼近随机函数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/approximating-stochastic-functions-be7d6ccf4f6?source=collection_archive---------28-----------------------#2020-11-14">https://towardsdatascience.com/approximating-stochastic-functions-be7d6ccf4f6?source=collection_archive---------28-----------------------#2020-11-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b36b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="9936" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">训练概率机器学习模型的通用方法</h2></div><p id="3693" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">你可以通过克隆github.com/narroyo1/sffnn<a class="ae lk" href="https://github.com/narroyo1/sffnn" rel="noopener ugc nofollow" target="_blank">来复制本文中的实验</a></p><h1 id="54ef" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">介绍</h1><p id="a0cc" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">神经网络是<a class="ae lk" href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" rel="noopener ugc nofollow" target="_blank">通用函数逼近器</a>。这意味着有足够多的隐藏神经元，神经网络可以用来逼近任何连续函数。然而，真实世界的数据通常具有噪声，这在某些情况下使得产生单个确定性值预测是不够的。以<strong class="kq ja">图1a </strong>中的数据集为例，它显示了一年内JFK国际机场航班的出发延误和到达延误之间的关系(2015年<a class="ae lk" href="https://www.kaggle.com/usdot/flight-delays" rel="noopener ugc nofollow" target="_blank">航班延误和取消</a>的子集)。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/9ca18e255b7a8afa47cdc6c32a55144f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*VAMcz6nddll1RpqZ4lmFhQ.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图1a </strong>从JFK出发到抵达的延误— <em class="mv">作者图片</em></p></figure><p id="65f7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">图1a </strong>还示出了完全训练的神经网络的预测，该神经网络在近似平均值方面做得很好，并且提供了关于数据集趋势的信息。然而，它无助于回答诸如<em class="mw">给定出发延迟，X%的航班的最大预期到达时间是多少？</em>或<em class="mw">给定一个出发延误，到达延误比Y长的概率是多少？</em>或者更有趣的是，编写一个模型，对给定出发延误的到达延误值进行采样，其分布与真实情况相同。</p><p id="3176" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有一些方法可以解决这个问题，例如，假设图1a 中的<strong class="kq ja">模型估计了平均值，就可以计算出整个数据集的标准偏差，利用这些参数就可以得出预期的正态分布。如果方差不恒定，也就是说，如果方差在整个输入空间内发生变化，您可以使用<a class="ae lk" href="https://machinelearningmastery.com/logistic-regression-with-maximum-likelihood-estimation/" rel="noopener ugc nofollow" target="_blank">带最大似然估计的逻辑回归</a>，它简单地训练一个模型来预测给定输入的特定分布函数的参数(例如，正态或高斯分布的平均值和标准偏差)。问题是它依赖于数据集分布的先验知识，这在某些情况下可能很困难，或者太不规则而无法匹配已知的分布。</strong></p><p id="100a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在出发至到达延迟数据集的情况下，我们可以从图中观察到分布似乎类似于正态分布，因此建立最大似然估计模型来计算正态分布的参数是有意义的。<strong class="kq ja">图1b </strong>示出了完全训练的模型的图，示出了平均值、平均值加/减标准偏差以及平均值加/减两倍标准偏差。该模型的误差为2.48%，相当不错。然而，数据集的分布并不是完全正态的，你可以看到除了其他不完善之处，上尾比下尾略长，这就是精度并不更好的原因。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/6101a54fef7591e6dc4ec0a904f5ab9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*hgBWC6qvnUQvJvO3SKFFXg.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图1b </strong>从JFK出发到抵达的延误和概率模型— <em class="mv">作者图片</em></p></figure><p id="39ca" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">本文介绍了一种训练概率机器学习模型的通用方法，该模型将产生适应真实数据的任何分布，甚至分支分布或在输入空间中改变形式的分布。</p><h1 id="116c" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">该方法</h1><p id="8fd8" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">假设产生数据的函数在输入<strong class="kq ja"> <em class="mw"> x ∈ X </em> </strong>处具有特定的分布<strong class="kq ja"> <em class="mw"> Y </em> </strong>我们可以将目标函数，或者我们实际上想要近似的函数定义为<strong class="kq ja"><em class="mw">y∾yₓ</em></strong>。我们想要创建一个算法，能够从任意给定的<strong class="kq ja"> <em class="mw"> x ∈ X </em> </strong>的<strong class="kq ja"> <em class="mw"> Yₓ </em> </strong>中采样任意数量的数据点。</p><p id="8230" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为此，我们引入一个二次输入<strong class="kq ja"> <em class="mw"> z </em> </strong>，它可以通过算法从一个均匀分布的空间<strong class="kq ja"> <em class="mw"> Z </em> </strong>中采样，并馈送给一个确定性函数<strong class="kq ja"> <em class="mw"> f </em> </strong>，使得<strong class="kq ja"> <em class="mw"> P(Z ≤ z) = P(Yₓ ≤f(x，z)</em></strong>。</p><p id="1e8d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">或者换句话说，我们想要一个确定性函数，对于任何给定的输入<strong class="kq ja"> <em class="mw"> x </em> </strong>，将一个随机(但均匀)变量<strong class="kq ja"><em class="mw"/></strong>映射到一个因变量<strong class="kq ja"><em class="mw">【yₓ】</em></strong>。</p><h1 id="b917" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">模型</h1><p id="5a92" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">所提出的近似<strong class="kq ja"><em class="mw">【yₓ】</em></strong>的模型是一个普通的前馈神经网络，除了一个输入<strong class="kq ja"> <em class="mw"> x </em> </strong>之外，还接受一个输入<strong class="kq ja"><em class="mw"/></strong>z<em class="mw"/>。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/b20e461af5d4acaf1ef37095efa7eed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*S6VuecLzUPAY-YIg3WQVaQ.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><em class="mv">作者图片</em></p></figure><h1 id="cf92" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">概观</h1><p id="953e" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">在每一点<strong class="kq ja"> <em class="mw"> x ∈ X </em> </strong>我们希望我们的模型<strong class="kq ja"> <em class="mw"> f(x，z∾z)</em></strong>以任意精度逼近<strong class="kq ja"> <em class="mw"> Yₓ </em> </strong>分布。让我们把<strong class="kq ja"> <em class="mw"> f(x，z∾z)</em></strong>和<strong class="kq ja"> <em class="mw"> Yₓ </em> </strong>想象成二维的(在<strong class="kq ja"> <em class="mw"> X </em> </strong>和<strong class="kq ja"> <em class="mw"> Z </em> </strong>都是一维的情况下)织物，它们可以在不同的区域以不同的尺度拉伸和收缩，分别降低或增加它们的密度。我们想要一种机制，它以与<strong class="kq ja"><em class="mw">【yₓ】</em></strong>中的收缩和伸展相匹配的方式来伸展和收缩<strong class="kq ja"> <em class="mw"> f(x，z∞z)</em></strong>。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi my"><img src="../Images/582c3ea97af3ef78c030364023b81778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*tvXLHbdpGAeVtnIccqcemw.gif"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图2 </strong>配合<strong class="bd mu"> <em class="mv"> x </em> </strong>添加均匀噪声的训练动画。— <em class="mv">作者图片</em></p></figure><p id="92ce" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在<strong class="kq ja">图2 </strong>中，我们可以看到经过训练的模型输出如何在每个时期一点一点地拉伸和收缩，直到它与目标函数匹配。</p><p id="15bb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">继续进行织物的拉伸和收缩模拟，我们希望将“针”放入覆盖织物(我们的模型)中，以便我们可以将它叠加在我们试图匹配的底层织物(目标数据集)上。我们将把这些大头针放入覆盖织物中的固定点，但在训练模型时，我们会将它们移动到底层织物的不同位置。首先，我们将它们固定在底层织物上的随机位置。当我们观察下层织物上的销相对于上层织物的位置时，我们将略微向上或向下移动销，以改善上层织物与下层织物的匹配。每一个针都会影响它在织物中的周围，与针的距离成比例。</p><p id="04b3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将首先在覆盖织物的任意给定经度的固定位置和织物高度的中点纬度放置1个大头针。然后，我们将在同一经度的基础结构中进行多次观察，也就是说，我们将在穿过所选引脚位置的垂直线处随机选取几个位置。</p><p id="0359" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于每个观察点，如果观察点低于其当前位置，我们会将底层结构上的固定位置(在覆盖结构上保持相同的固定位置)向下移动一小段预定义的距离，如果观察点高于当前位置，我们会将其向上移动。这意味着，如果在底层织物中针的位置上方有更多的观察点，总运动将向上，反之亦然，如果在其下方有更多的观察点。如果我们重复这一过程足够多次，针在底层织物中的位置将停留在将观察点减半的位置，也就是说，在其上的观察点的数量与在其下的观察点的数量相同。</p><blockquote class="nd ne nf"><p id="f472" class="ko kp mw kq b kr ks ka kt ku kv kd kw ng ky kz la nh lc ld le ni lg lh li lj ij bi translated"><strong class="kq ja">为什么我们要将大头针向上或向下移动预定义的距离，而不是与观察点成比例的距离？</strong> <em class="iq"> </em>原因是我们对匹配观察点不感兴趣。由于目标数据集是随机的，匹配随机观察值是没有意义的。我们从观察点得到的有趣信息是针是否将它们除以二(或另一个特定的比率)</p></blockquote><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nj"><img src="../Images/04ea41731e02ec2142728c94cc678f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*kaiIJsVKoV5wBGL-WDFp0A.gif"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图3 </strong>向观察点移动1个针，直到它停止。— <em class="mv">作者图片</em></p></figure><p id="178d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">图3 </strong>显示了针如何到达一个稳定的位置，将所有数据点分成两半，因为对于上面的数据点和下面的数据点，每次观察的移动量是相等的。如果上面观察的预定移动距离不同于下面观察的预定移动距离，则针将停留在以不同比率(不同于一半)划分数据点的位置。例如，让我们尝试使用2个销而不是1个销，第一个销将为上面的观察移动1个距离，为下面的观察移动0.5个距离，第二个销将做相反的事情。经过足够的迭代后，第一个引脚应该停留在将数据点除以上面的<strong class="kq ja"><em class="mw"/></strong>和下面的<strong class="kq ja"> <em class="mw"> 2/3 </em> </strong>的位置，而第二个引脚将除以上面的<strong class="kq ja"> <em class="mw"> 2/3 </em> </strong>和下面的<strong class="kq ja"> <em class="mw"> 1/3 </em> </strong>。这意味着我们将使<strong class="kq ja"><em class="mw"/></strong>的1/3位于第一个销上方，<strong class="kq ja"> <em class="mw">的1/3 </em> </strong>位于两个销之间，而<strong class="kq ja"> <em class="mw">的1/3 </em> </strong>位于第二个销下方，如图4 中的<strong class="kq ja">所示。</strong></p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nj"><img src="../Images/5a0b573d31d1f59381a2a0f79f1f8be1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*sWVPc8EEppvpL-z95Yz4-A.gif"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图4 </strong>向观察点移动2个销，直到它们停止。— <em class="mv">作者图片</em></p></figure><p id="3159" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果针将观察到的数据点分成大小为<strong class="kq ja"><em class="mw"/></strong>和<strong class="kq ja"> <em class="mw"> b </em> </strong>的两组，并且在训练之后，其固定位置位于从顶部开始的<strong class="kq ja"><em class="mw">【a/(a+b)</em></strong>纬度中的底层织物中，我们在两个织物之间具有单点映射，即在该经度处，针上方和下方的密度在两片织物中相等。我们可以推断出这个概念，并使用尽可能多的引脚，以便在两片织物之间创建更精细的映射。</p><h1 id="23a1" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">定义</h1><p id="155e" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">我们首先在尺寸为<strong class="kq ja"><em class="mw"/></strong>的<strong class="kq ja"> <em class="mw"> Z </em> </strong>中选择一组固定的点，我们称之为<strong class="kq ja"> <em class="mw"> z样本</em> </strong>。我们可以将这个集合定义为:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/6f3024710f6e9f4ffec7b2b1f0c5b842.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*JtTnRsHA3z1ACV3SF4HARw.png"/></div></figure><p id="9665" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">预测模型将被定义为:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/b89920fc22152457a46c4c3dd80eb335.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*q-tPlo5v4H8cMxX1CCm_Cw.png"/></div></figure><p id="47de" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这里的<strong class="kq ja"> <em class="mw"> x </em> </strong>将是来自输入域的任意输入元组，<strong class="kq ja"> <em class="mw"> z </em> </strong>将是来自均匀随机变量<strong class="kq ja"> <em class="mw"> Z </em> </strong>和<strong class="kq ja"> <em class="mw"> θ </em> </strong>是模型的内部状态，或者说是权重矩阵。</p><p id="94cc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后我们将任意输入<strong class="kq ja"> <em class="mw"> x </em> </strong>对于特定的<strong class="kq ja"> <em class="mw"> z ∈ Z </em> </strong>的预测误差定义为:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/818a2d49a7ad2656dd1046f0f5bd2a03.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*mXG6deiMmsqtk0g8zyZLxQ.png"/></div></figure><p id="e2fc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">即真实数据累积概率分布和预测累积概率分布之间的差异。</p><p id="77c2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，我们可以将我们的培训目标定义为:</p><p id="7310" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">目标1</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/9a5f1fe68ad5f4586fa383973ae2f182.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*Sp19UCHv3kvoIk-97y1DIg.png"/></div></figure><p id="58ab" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">换句话说，我们希望对于<strong class="kq ja"><em class="mw"/></strong>中的每一个<strong class="kq ja"><em class="mw">z’</em></strong>以及整个<strong class="kq ja"> <em class="mw"> X </em> </strong>输入空间的绝对误差<strong class="kq ja"><em class="mw">| e(z’)|</em></strong>最小化。这个第一个目标给了我们一个在<strong class="kq ja"> <em class="mw"> z样本</em> </strong>集合和<strong class="kq ja"> <em class="mw"> Yₓ </em> </strong>之间的近似离散有限映射。即使没有说任何关于<strong class="kq ja"><em class="mw"/></strong><strong class="kq ja"><em class="mw">z</em></strong>中所有不在<strong class="kq ja"><em class="mw">【zₛₐₘₚₗₑₛ</em></strong>中的点。</p><p id="dddd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">目标2</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/f53ea50db677eb05c8aac549a75fc673.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*h8gRMXWNWw2F6YzVHtXOKw.png"/></div></figure><p id="6236" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这个第二个目标给了我们，对于任意给定的<strong class="kq ja"> <em class="mw"> x </em> </strong>在<strong class="kq ja"> <em class="mw"> X </em> </strong>，<strong class="kq ja"> <em class="mw"> f </em> </strong>在<strong class="kq ja"> <em class="mw"> Z </em> </strong>中是单调递增函数。</p><p id="6911" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这两个目标都将在训练算法的测试步骤中根据经验进行测试。</p><h1 id="3911" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">模型精度</h1><p id="53fc" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">对于任意点<strong class="kq ja"><em class="mw">Z∾Z</em></strong>，并且<strong class="kq ja"><em class="mw">Z’</em></strong>和<strong class="kq ja"><em class="mw">Z”</em></strong>分别是立即变小和变大的<strong class="kq ja"> <em class="mw"> z样本</em> </strong>，并且假设<a class="ae lk" href="https://narroyo1.github.io/sffnn/#goal-2" rel="noopener ugc nofollow" target="_blank">目标2 </a>被满足，则我们有:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/35db0a3bb071c1565c1c8f729c689ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*UwIWxzbN3JejWEmaPy8pSw.png"/></div></figure><p id="a945" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">取代我们的预测误差:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/90fe9776b3d1f7dab9540ff2f754701f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*mk6kianT3Z78I10NOlwCwQ.png"/></div></figure><p id="0df4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果我们从每一项中减去<strong class="kq ja"> <em class="mw"> P(Z ≤ z) </em> </strong>:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nr"><img src="../Images/7265add1038b6ecc690a89c767d51599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-WK7xfLLuClINT1iWUChxg.png"/></div></div></figure><p id="ebfc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这意味着对于任意一点<strong class="kq ja"><em class="mw">Z∾Z</em></strong>预测误差error <strong class="kq ja"> <em class="mw"> E(z) </em> </strong>下界为<strong class="kq ja"><em class="mw">P(Z≤Z’)—P(Z≤Z)+E(Z’)</em></strong>，上界为<strong class="kq ja"><em class="mw">P(Z≤Z’)—P(Z≤Z)+E(Z’)</em></strong>。</p><p id="d478" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">假设<a class="ae lk" href="https://narroyo1.github.io/sffnn/#goal-1" rel="noopener ugc nofollow" target="_blank">目标1 </a>被满足，我们知道<strong class="kq ja"><em class="mw">【Z’)</em></strong>和<strong class="kq ja"><em class="mw">【E(Z’)</em></strong>是小数字，这使得<strong class="kq ja"><em class="mw">P(Z≤Z’)—P(Z≤Z)</em></strong>和<strong class="kq ja"><em class="mw">P(Z≤Z’)—P(Z≤Z)</em></strong>成为主导因素。任何<strong class="kq ja"> <em class="mw"> z </em> </strong>与其相邻<strong class="kq ja"> z样本</strong>之间的距离可以通过增加<strong class="kq ja"> <em class="mw"> z样本</em> </strong>或<strong class="kq ja"> <em class="mw"> S </em> </strong>的数量来最小化。换句话说，<strong class="kq ja"> <em class="mw"> f </em> </strong>的最大误差可以通过足够大的<strong class="kq ja"> <em class="mw"> S </em> </strong>任意最小化。</p><h1 id="2935" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">计算运动标量</h1><p id="eb1b" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">定义了我们的目标以及他们会给我们买什么之后，我们开始展示我们将如何实现目标1。为简单起见，我们将使用一个均匀分布在<strong class="kq ja"><em class="mw"/></strong>中的<strong class="kq ja"><em class="mw">Z-样本集，即:<strong class="kq ja"> <em class="mw"> {z[0]，z[1]，…，z[S-1]} ∈ Z s.t. z[0] &lt; z[1]，…，&lt; z[S] ∧ P(z[0] &lt; Z &lt;</em></strong></em></strong></p><p id="7df5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于<strong class="kq ja"/>中任意给定的<strong class="kq ja"> <em class="mw"> x </em> </strong>和<strong class="kq ja"><em class="mw"/></strong>中任意给定的<strong class="kq ja"><em class="mw">z’</em></strong>我们要<strong class="kq ja"> <em class="mw"> f </em> </strong>满足<strong class="kq ja"> <em class="mw"> P(Yₓ ≤ f(x，z’)= p(z≤z’</em></strong>。为此，我们假设我们在<strong class="kq ja"><em class="mw"/></strong>或<strong class="kq ja"><em class="mw">yₜᵣₐᵢₙ∾yₓ</em></strong>用一组足够有代表性的样本进行计数。</p><p id="3ec8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于给定的<strong class="kq ja"> <em class="mw"> x ∈ X </em> </strong>并且具有<strong class="kq ja"><em class="mw"/></strong>作为<strong class="kq ja"> <em class="mw"> Z </em> </strong>(即<strong class="kq ja"><em class="mw">Z’∈Z s . t . Pr(Z’≤Z)= 0.5</em></strong>，我们可以简单地训练<strong class="kq ja"> <em class="mw"> f </em> </strong>来改变<em class="mw">的值 z))</em>一个恒定的移动数<strong class="kq ja"> <em class="mw"> M </em> </strong>大于每个训练示例<strong class="kq ja"> <em class="mw"> y ∈ yₜᵣₐᵢₙ </em> </strong>它大于<strong class="kq ja"> <em class="mw"> f(x，z’)</em></strong>本身并且相同的恒定数小于每个较小的训练示例(记住2块织物和销的类比)。 这将导致在足够的迭代之后，当总移动等于0时，<strong class="kq ja"> <em class="mw"> f(x，z’)</em></strong>的值停留在将所有训练样本分成两半的位置。</p><p id="8b3d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果不是<strong class="kq ja"> <em class="mw"> Z </em> </strong>的中点<strong class="kq ja"><em class="mw">P(Z≤Z’)≠0.5</em></strong>那么更大和更小样本的移动常数必须不同。</p><p id="8d97" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">假设<strong class="kq ja"> <em class="mw"> a </em> </strong>是<strong class="kq ja"><em class="mw"/></strong>与<strong class="kq ja"> <em class="mw"> Z </em> </strong>或<em class="mw"> Zₘᵢₙ </em> 和<strong class="kq ja"> <em class="mw"> b </em> </strong>之间的距离<strong class="kq ja"><em class="mw"/></strong>与<strong class="kq ja">之间的距离</strong></p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/849822d590245639408e5b4d6d769cfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:220/format:webp/1*iGmh_XOeQd5akJTga77-pQ.png"/></div></figure><p id="ba29" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于<strong class="kq ja"> <em class="mw"> a </em> </strong>表示我们希望找到的训练样本的数量小于<strong class="kq ja"><em class="mw"/></strong>和<strong class="kq ja"> <em class="mw"> b </em> </strong>训练样本的数量大于<strong class="kq ja"><em class="mw">【z’</em></strong>我们需要2个标量<strong class="kq ja"> <em class="mw"> α </em> </strong>和<strong class="kq ja"/></p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/03e7244ab4523b9cc8417d9223478841.png" data-original-src="https://miro.medium.com/v2/resize:fit:110/format:webp/1*KnNbINqX0Ttc1rN_JjnLdQ.png"/></div></figure><p id="5ec3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些运动标量将作为乘数，分别与小于和大于<strong class="kq ja"><em class="mw">【z’</em></strong>的每个观察点上的恒定运动<strong class="kq ja"> <em class="mw"> M </em> </strong>一起使用。这个第一个等式保证了当<strong class="kq ja"><em class="mw">z’</em></strong>位于<strong class="kq ja"> <em class="mw"> Zₘᵢₙ + a </em> </strong>或<strong class="kq ja"> <em class="mw"> Zₘₐₓ — b </em> </strong>时的总运动将为0。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/2ac5823f6125b7695bfabadad3d27646.png" data-original-src="https://miro.medium.com/v2/resize:fit:156/format:webp/1*JyoH_jtcK11ti6WTqc3Ajg.png"/></div></figure><p id="b275" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第二个等式对标量进行归一化，使得<strong class="kq ja"><em class="mw"/></strong>中所有<strong class="kq ja"> <em class="mw"> z </em> </strong>的总运动具有相同的总运动。</p><p id="61fa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这给了我们:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/c5c37b6486add2162ed6411ce1bb99b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:174/format:webp/1*dWJVc28nUC2PCrTelCvwqw.png"/></div></figure><p id="dc0a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，这个逻辑在边缘处中断，即当一个<em class="mw"> z样本</em>等于<strong class="kq ja"> <em class="mw"> Zₘᵢₙ </em> </strong>或<strong class="kq ja"> <em class="mw"> Zₘₐₓ </em> </strong>时。在这些值处，a<strong class="kq ja"><em class="mw"/></strong>或<strong class="kq ja"> <em class="mw"> b </em> </strong>为0，如果其中一个为0，则<strong class="kq ja"> <em class="mw"> α </em> </strong>或<strong class="kq ja"> <em class="mw"> β </em> </strong>中的一个未定义。</p><p id="1a33" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当<strong class="kq ja"> <em class="mw"> a </em> </strong>或<strong class="kq ja"> <em class="mw"> b </em> </strong>接近0 <strong class="kq ja"> <em class="mw"> α </em> </strong>或<strong class="kq ja"> <em class="mw"> β </em> </strong>趋向于无穷大时，人们可能会试图用一个大的数字来代替它，但这并不实际，因为大的距离乘数将支配训练并最小化其他<strong class="kq ja"> <em class="mw"> zₛₐₘₚₗₑₛ </em></strong></p><p id="1ef7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">同样随着<strong class="kq ja"> <em class="mw"> α </em> </strong>或<strong class="kq ja"> <em class="mw"> β </em> </strong>中的一个趋于无穷大，另一个变成了一个同样不切实际但原因不同的小数字。边缘处的<strong class="kq ja"> <em class="mw"> zₛₐₘₚₗₑₛ </em> </strong>应该映射到<strong class="kq ja"><em class="mw"/></strong>yₓ的边缘，任何向相反方向的移动量都将导致<strong class="kq ja"><em class="mw"/></strong>或<strong class="kq ja"><em class="mw">【zₘₐₓ</em></strong>分别映射到<strong class="kq ja"><em class="mw"/></strong>中更大或更小的点。因此，边缘处的<strong class="kq ja"><em class="mw">【zₛₐₘₚₗₑₛ】</em></strong>【即<strong class="kq ja"><em class="mw">【z[0]</em></strong>和<strong class="kq ja"> <em class="mw"> z[S] </em> </strong>】的<strong class="kq ja"> <em class="mw"> α </em> </strong>和<strong class="kq ja"> <em class="mw"> β </em> </strong>将被指定为向内推的值0和预定义的值</p><h1 id="8b11" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">训练模型</h1><p id="b52e" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">为了训练神经网络，z样本<strong class="kq ja"><em class="mw"/></strong>，集合大小<strong class="kq ja"> <em class="mw"> S </em> </strong>根据期望的精度和可用的计算来选择。决定之后，必须定义<strong class="kq ja"> <em class="mw"> Z </em> </strong>。也就是说，必须选择维数及其范围。给定<strong class="kq ja"> <em class="mw"> Z </em> </strong>和训练级别，我们可以创建<strong class="kq ja"> <em class="mw"> z样本</em> </strong>集合。</p><p id="f101" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">例如，如果<strong class="kq ja"> <em class="mw"> Z </em> </strong>是一维的，范围定义为<strong class="kq ja"><em class="mw">【10.0，20.0】</em></strong><strong class="kq ja"><em class="mw">s = 9</em></strong>，则<em class="mw"> z样本</em>集合为<strong class="kq ja"> <em class="mw"> {z₀ (10.0)、z₁ (11.25)、z₂ (12.5)、z₃ (13.75)、z₄(13.75)</em></strong></p><p id="280c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先我们从大小为<strong class="kq ja"> <em class="mw"> n </em> </strong>的训练数据中选择一批数据，对于该批中的每个数据点，我们在每个<em class="mw"> z样本</em>上评估当前模型。这给了我们预测矩阵:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/ef1ed35281287e53f1acb81f25536f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*HCeIoWUz2IWrHaxXJw5Plg.png"/></div></figure><p id="760c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于批量中的每一个数据点<strong class="kq ja"><em class="mw">【xᵢ，yᵢ】</em></strong>，我们取输出值<strong class="kq ja"><em class="mw">【yᵢ</em></strong>，并与预测矩阵中其对应行的每一个值(即<strong class="kq ja"><em class="mw">【f(xᵢ，z₀】，【f(xᵢ，z₁】，…，f(xᵢ，z≠)</em></strong>)进行比较。在确定<strong class="kq ja"> <em class="mw"> yᵢ </em> </strong>大于还是小于每个预测值之后，我们为矩阵中的每个元素产生2个值:</p><h1 id="7cd4" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">运动标量</h1><p id="a104" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">如果<strong class="kq ja"><em class="mw"/><em class="mw">【z-sample】</em></strong>比预测的<strong class="kq ja">【z-sample】</strong>【yᵢ】小，如果 比预测的【z-sample】大。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/9e1e390c0e29eee5e9905188516ef4f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*KOMiSrc1eEJlv2XknZ4_oQ.png"/></div></figure><h1 id="d86d" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">目标值</h1><p id="57e8" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">如果<strong class="kq ja"><em class="mw"/></strong>比预测值小，则目标值为预测值本身加上预选的移动常数<strong class="kq ja"> <em class="mw"> M </em> </strong>乘以-1，如果<strong class="kq ja"> <em class="mw">比预测值大，则为1。您可以将目标值视为“我们希望预测的位置”值。</em></strong></p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/9fb8accf789b1b4d0131001ff7a74f23.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*cF66TYVmJFUN0BBwdX1K-g.png"/></div></figure><p id="f058" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在计算了这两个值之后，我们就可以准备组装在反向传播过程中使用的矩阵了。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/a88e5276d57bfb25a47ebaa93ff78179.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*9dS-zjdoeUTmgmfEVX-56g.png"/></div></figure><p id="ad56" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将预测矩阵结果添加到这个矩阵中，并传递给加权均方误差损失函数(WMSE)。损失函数看起来像这样:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/c1415c34b16b5db8fbedad3fc62d1c6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*Q_LXlZsq4XnLAYmOyT4pfw.png"/></div></figure><h1 id="81ce" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">测试模型</h1><p id="2984" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">均方误差(MSE)损失函数使用反向传播和目标值来训练模型，但是测试模型需要不同的方法。由于<strong class="kq ja"> <em class="mw"> f(x，Z) </em> </strong>和<strong class="kq ja"> <em class="mw"> Yₓ </em> </strong>都是随机变量，测量它们样本之间的差异是没有意义的。因此，模型的成功将通过两种方式来衡量:</p><h1 id="915a" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">推土机距离(EMD)</h1><blockquote class="nd ne nf"><p id="696c" class="ko kp mw kq b kr ks ka kt ku kv kd kw ng ky kz la nh lc ld le ni lg lh li lj ij bi translated"><em class="iq">在统计学中，</em> <strong class="kq ja"> <em class="iq">推土机的距离</em></strong><em class="iq">(</em><strong class="kq ja"><em class="iq">EMD</em></strong><em class="iq">)是一个区域内两个概率分布之间距离的度量</em><em class="iq">。在数学中，这被称为瓦瑟斯坦度规。非正式地，如果分布被解释为在区域</em> D <em class="iq">上堆积一定数量的灰尘的两种不同方式，EMD是将一堆灰尘变成另一堆灰尘的最小成本；其中成本假定为移动的灰尘量乘以移动的距离。</em><a class="ae lk" href="https://en.wikipedia.org/wiki/Earth_mover%27s_distance" rel="noopener ugc nofollow" target="_blank"><em class="iq">wikipedia.org</em></a></p></blockquote><p id="a7b7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">使用<a class="ae lk" href="https://en.wikipedia.org/wiki/Earth_mover%27s_distance" rel="noopener ugc nofollow" target="_blank"> EMD </a>我们可以获得<strong class="kq ja"> <em class="mw"> Yₓ </em> </strong>和<strong class="kq ja"> <em class="mw"> f(x，Z) </em> </strong>有多相似的指标。可以通过比较测试数据和预测数据集中的每个<strong class="kq ja"> <em class="mw"> x，y </em> </strong>数据点，并找到将一个数据点转换成另一个数据点所需的最小总移动量来计算。EMD数字告诉我们的是将预测数据集中的每一点转换为测试数据集中的平均距离。</p><p id="8270" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在下面的例子中，你可以看到，在一个厚度约为100的数据集上，平均EMD约为3.9。由于数据集的随机性质，EMD不能用作字面上的错误指标，但它可以用作进度指标，即告知模型是否随着训练而改进。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/765bb5c007c97a01f0c5e5ec60236c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*4CciObwFkVMAjhvwSAl42Q.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图5 </strong> EMD测试。— <em class="mv">作者图片</em></p></figure><h1 id="12c4" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">测试培训目标</h1><p id="bda3" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">培训目标1</p><p id="e59c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">理想情况下，为了测试<a class="ae lk" href="https://narroyo1.github.io/sffnn/#goal-1" rel="noopener ugc nofollow" target="_blank">目标1 </a>(即<strong class="kq ja"><em class="mw">∀x∈x∧∀z’∈zₛₐₘₚₗₑₛ: arg min | e(z’)|</em></strong>)我们将对给定的<strong class="kq ja"> <em class="mw"> x </em> </strong>和每个<strong class="kq ja"> <em class="mw"> z样本</em> </strong>评估<strong class="kq ja"> <em class="mw"> f </em> </strong>，然后将其与具有相同<strong class="kq ja">的任意数量的测试数据点进行比较然后，我们将继续为每个<strong class="kq ja"> <em class="mw"> z样本</em> </strong>计算比它小的测试数据点的数量。利用比计数(即<strong class="kq ja"> <em class="mw"> P(Yₓ ≤ f(x，z’)</em></strong>)小的矢量<em class="mw">，我们可以将它与每个<strong class="kq ja"><em class="mw">【z样本】</em> </strong>(即<strong class="kq ja"><em class="mw">p(z≤z’)</em></strong>)的规范计数进行比较，并测量误差。然而，在现实生活中，这是不可能的。现实生活中的数据集不太可能有任意数量的数据点具有相同的<strong class="kq ja"> <em class="mw"> x </em> </strong>(它们甚至不太可能有两个数据点具有相同的<strong class="kq ja"> <em class="mw"> x </em> </strong>)，这意味着我们需要使用接近于<strong class="kq ja"> <em class="mw"> x </em> </strong>(值<strong class="kq ja"> <em class="mw"> X </em> </strong>的<strong class="kq ja"> <em class="mw"> x </em> </strong>)来测试目标</em></strong></p><p id="cb1c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们首先创建一个排序(一个索引数组)<strong class="kq ja"> <em class="mw"> O = {o₀，o₁，…，o[m]} </em> </strong>，对<strong class="kq ja"><em class="mw">【xₜₑₛₜ</em></strong>【测试数据集中的<strong class="kq ja"> <em class="mw"> x </em> </strong>输入中的所有元素进行排序。然后我们选择数组<strong class="kq ja"> <em class="mw"> O' = {oᵢ，oᵢ₊₁，…，oⱼ} </em> </strong>的一个子串。</p><p id="4ee2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们可以对每个<strong class="kq ja"><em class="mw">x【o’】∣o’∈o’</em></strong>在每个<strong class="kq ja"> <em class="mw"> z-sample </em> </strong>上求值<strong class="kq ja"> <em class="mw"> f </em> </strong>，这就给出了矩阵:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/cf5e683ee2b96749bc08e175af249cdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*MvqiKy8DHcNuCdkWkCxMnA.png"/></div></figure><p id="6afb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，我们将每一行与输出<strong class="kq ja"><em class="mw">y[o '】∣o '∈o '</em></strong>进行比较</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/90f26e909b78c4710385837a8acb631a.png" data-original-src="https://miro.medium.com/v2/resize:fit:92/format:webp/1*3hIftFyZmJy2Ev6VCx6sLw.png"/></div></figure><p id="f40e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">并创建比计数小的<em class="mw">(即<strong class="kq ja"> <em class="mw"> P(Yₓ ≤ f(x，z)) </em> </strong>)，然后我们可以将它与每个<strong class="kq ja"> <em class="mw"> z样本</em> </strong>(即<strong class="kq ja"> <em class="mw"> P(Z ≤ z) </em> </strong>)的规范计数进行比较，以测量所选子串中的误差。</em></p><p id="7341" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将创建许多这样的子串，并将每个错误称为位于子串中心元素的本地邻近错误。</p><p id="d1d9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在下面的示例中，您可以看到目标1的平均误差约为1.6%，这可以用作模型的误差指标。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/ba338a25d2e8bab3c73d1f72d640d008.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*kfhSOGCbaa181yUzr5gTpA.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图6 </strong>训练目标1测试。— <em class="mv">作者图片</em></p></figure><p id="d119" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">培训目标2</p><p id="0a24" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了测试<a class="ae lk" href="https://narroyo1.github.io/sffnn/#goal-2" rel="noopener ugc nofollow" target="_blank">目标2 </a> <strong class="kq ja"> <em class="mw"> ∀ x ∈ X ∧ ∀ z₀，z₁ ∈ Z s.t. z₀ &lt; z₁: f(x，z₀) &lt; f(x，z₁) </em> </strong>我们在<strong class="kq ja"><em class="mw"/></strong>中选择一些随机点，并在<strong class="kq ja"><em class="mw"/></strong>中选择一组随机点，我们在我们的模型中运行它们并得到结果矩阵:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/1e42331562a44cc89d02c0a633266980.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*FodWQOzlNJH0J0z4z_l-vw.png"/></div></figure><p id="63b3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从这里开始，检查每一行是否单调递增是很容易的。为了提高检查的质量，我们可以增加在<strong class="kq ja"> <em class="mw"> X </em> </strong>中设置的测试点和在<strong class="kq ja"> <em class="mw"> Z </em> </strong>中设置的测试点的大小。</p><h1 id="258c" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">回到延迟</h1><p id="3805" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">现在我们可以回到出发延误到到达延误数据集，下面你可以看到MLE方法(<strong class="kq ja">图7a </strong>)和本文介绍的方法(<strong class="kq ja">图7b </strong>)并列。正如我们之前看到的，最大似然估计方法未能捕捉到小的缺陷，获得2.48%的目标1误差，而一般方法做得好得多，目标1误差为0.018%。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi og"><img src="../Images/58501c9b3c7c415a64b6affb395e11c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*213na_UMsl0m2UrQkKa6SQ.gif"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图7a </strong>概率模型MLE方法。<strong class="bd mu">图7b </strong>通用方法。— <em class="mv">作者图片</em></p></figure><h1 id="5901" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">实验</h1><p id="3ef1" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">以下是在不同数据集上进行的各种实验。</p><h1 id="9d05" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">x加高斯噪声</h1><p id="f165" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">让我们从一个简单的例子开始。添加了高斯噪声的函数<strong class="kq ja"> <em class="mw"> x </em> </strong>。在左侧面板中，您可以看到训练在180个时期内不断发展。在此面板的左上角，您可以看到目标1的误差局限在<strong class="kq ja"> <em class="mw"> X </em> </strong>上，在训练结束时，您可以看到最高局部误差约为2%，全局误差约为0.5%。在同一面板的右上角，您可以看到本地推土机的距离(EMD)。在左下角，您可以看到原始测试数据集(蓝色)和<strong class="kq ja"> <em class="mw"> z-samples </em> </strong>(橙色)的图，您可以看到它们是如何逐渐符合测试数据的。在右下方，您可以看到原始测试数据集(蓝色)和随机预测(带有<strong class="kq ja"><em class="mw">Z∾Z</em></strong>)的图表，您可以看到预测结果逐渐代表了测试数据。</p><p id="5ac5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在右侧面板中，您可以看到全局目标1误差(上图)和全局EMD值(下图)在培训过程中的变化图。</p><div class="mj mk ml mm gt ab cb"><figure class="oh mn oi oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/e7dfee490ba0d341e7919fdf0ee4154e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/1*bqmwL0FOGIT8twyiPJbOXw.gif"/></div></figure><figure class="oh mn on oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/3726286550579fe3f18adfded6dbd46e.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*_RjV9_CPRsNYr155f-LU0g.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk oo di op oq translated"><strong class="bd mu">图8 </strong>训练模型匹配<strong class="bd mu"> <em class="mv"> x </em> </strong>加高斯。— <em class="mv">作者图片</em></p></figure></div><h1 id="0452" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">一个x + bx + cx + d加截断高斯噪声</h1><p id="449a" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">这个有点复杂。添加了截断高斯噪声的3阶多项式(即在特定点截断的正态分布)。</p><div class="mj mk ml mm gt ab cb"><figure class="oh mn oi oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/4dcec64691efec255ddcb36d79cfaef1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/1*g-iIIInqaYkBviCjjDXrhw.gif"/></div></figure><figure class="oh mn on oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/d9bbbd2612f23fc3651c9cb89df8b01c.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*nrUDKHaGiu5j3Gy6YzJMmQ.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk oo di op oq translated"><strong class="bd mu">图9 </strong>训练模型匹配<strong class="bd mu"> <em class="mv"> x + bx + cx + d </em> </strong>加截断高斯。— <em class="mv">作者图片</em></p></figure></div><h1 id="0597" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">双sin(x)加高斯噪声乘以sin(x)</h1><p id="766d" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">这个更有趣。2镜像<strong class="kq ja"> <em class="mw"> sin(x) </em> </strong>函数带有由<strong class="kq ja"> <em class="mw"> sin(x) </em> </strong>本身缩放的高斯噪声。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/c7b902f20e5666ee73999d5fc0b7f363.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*aTCiderKa-SVyNqAdMWvug.png"/></div></figure><p id="a86a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">请注意，该模型如何成功地表示了密度较低的中间区域。</p><div class="mj mk ml mm gt ab cb"><figure class="oh mn oi oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/fb09d19d46c2ca19a8ad19e228f0505b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/1*0gN07a-RpL1ZOh84XZUdWw.gif"/></div></figure><figure class="oh mn on oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/80cb0735fedd4c1d0d8c0beafff368aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*8oHhcnwBMjM9a1kjh_gfEQ.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk oo di op oq translated"><strong class="bd mu">图10 </strong>训练模型匹配双<strong class="bd mu"><em class="mv"/></strong>加高斯倍<strong class="bd mu"><em class="mv">【sin(x)</em></strong>。— <em class="mv">作者图片</em></p></figure></div><h1 id="5486" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">分支函数加高斯噪声</h1><p id="e53d" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">这个实验用分支路径。它从围绕<strong class="kq ja"> <em class="mw"> 0 </em> </strong>的简单高斯噪声开始，然后开始在各个段的过程中以相等的概率分割它。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/29247a53e67f56ed2b7102468179efcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*LDQ7cDsctuLPg2VMzIHZAA.png"/></div></figure><p id="3951" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">尽管分布不是连续的，但该模型在逼近分布方面做得相当不错。</p><div class="mj mk ml mm gt ab cb"><figure class="oh mn oi oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/eeae5ca75907ba407b2bb885fb398cc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/1*0MT1FL9TX8IUgrZIDpRrpA.gif"/></div></figure><figure class="oh mn on oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/fb3de4da2fc581046abb34a427192b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*GKt_aAU-o1O7z3FUyvnDlg.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk oo di op oq translated"><strong class="bd mu">图11 </strong>匹配分支函数加高斯的训练模型。— <em class="mv">作者图片</em></p></figure></div><h1 id="3874" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">(x₀) + (x₁)加绝对高斯噪声</h1><p id="21f3" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">下一个例子有二维输入。<strong class="kq ja"> <em class="mw"> X₀ </em> </strong>(第一维)是<strong class="kq ja"><em class="mw">x</em></strong><strong class="kq ja"><em class="mw">x₁</em></strong>(第二维)是<strong class="kq ja"> <em class="mw"> x </em> </strong>加了绝对高斯噪声。显示略有不同，为了节省空间，省略了<strong class="kq ja"> <em class="mw"> z-samples </em> </strong>图。如您所见，每个维度都有一个面板，另外还有一个面板用于显示目标1错误和EMD错误历史。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ot"><img src="../Images/7e16827e44282a9388cacef18c9da746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*4yQLmC0FOiu8ps2DUn6ldA.gif"/></div></div></figure><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ot"><img src="../Images/db5ab367f152abbfd5ba1e278a493b58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*WX2OUISE2psCFIrNb3reTA.gif"/></div></div></figure><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ou"><img src="../Images/f04d46ac6fc34904c4eb762ae70913c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yXYQTuAW2BCxfplSMubKfA.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图12 </strong>训练模型匹配<strong class="bd mu"><em class="mv">(x₀)+</em></strong>加绝对高斯。— <em class="mv">作者图片</em></p></figure><h1 id="8aa3" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">加州住房数据集</h1><p id="a459" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">该实验使用真实数据代替生成数据，证明了该模型对真实数据的有效性。这是经典的<a class="ae lk" href="http://lib.stat.cmu.edu/datasets/houses.zip" rel="noopener ugc nofollow" target="_blank">加州住房数据集</a>。它有来自1990年加州人口普查的信息，有8个输入维度(收入中值、房龄等)。下面你可以看到每个维度的图。</p><div class="mj mk ml mm gt ab cb"><figure class="oh mn ov oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/6d332d785fafeda1364646018c956f3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*imQ_O9w1kVJUQ7Nmn5TsIQ.gif"/></div></figure><figure class="oh mn ov oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/575ce1d6cc20ca3c85a2814ecfc03446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*8EdLinNVYnz1Yy8yWy9TIQ.gif"/></div></figure></div><div class="ab cb"><figure class="oh mn ov oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/7cf2a782c1726b7e364eae2c0d2da866.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*qCQR_y2aKh-WHANYooFJJg.gif"/></div></figure><figure class="oh mn ov oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/5890df7768ed348c280caaa69492829f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*DOu-xO3lF5WU4w-3By9Nnw.gif"/></div></figure></div><div class="ab cb"><figure class="oh mn ow oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/30a2d3aa983d915d0c688d7f3ee8caf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/1*wwy50D8xtvLa77b9senWjQ.gif"/></div></figure><figure class="oh mn ox oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/1c77f1f79c8e6aedf6368f3fcebffa87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*EnsWQMHJ6xAILsOCp_elXg.gif"/></div></figure></div><div class="ab cb"><figure class="oh mn ox oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/92f347b979284599b902ab00154996fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*fSkbfutRPn1pT6q6VQvikg.gif"/></div></figure><figure class="oh mn ow oj ok ol om paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><img src="../Images/ae0930f8f5be8b7a434be7b4f04756f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/1*LwqSBL4oRbgFjGAVC-1BIQ.gif"/></div></figure></div><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ou"><img src="../Images/c00a449ea31ad33f1e0e4d9d3d45f0a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yOniZhW1j0Y0NgypRzhdwQ.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图13 </strong>匹配加州住房数据集的训练模型。— <em class="mv">作者图片</em></p></figure><h1 id="5e3a" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">结论</h1><p id="18b6" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">提出的方法允许以任意精度近似随机数据集的分布。该模型简单，训练速度快，可以用普通的前馈神经网络实现。它能够近似输入空间中的任何分布，这使它成为任何需要预测的任务的重要工具。</p></div></div>    
</body>
</html>