<html>
<head>
<title>Big Data Engineering — Flowman up and running</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据工程— Flowman启动并运行</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/big-data-engineering-flowman-up-and-running-cd234ac6c98e?source=collection_archive---------64-----------------------#2020-10-12">https://towardsdatascience.com/big-data-engineering-flowman-up-and-running-cd234ac6c98e?source=collection_archive---------64-----------------------#2020-10-12</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="7ad7" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">在您的机器上查看名为Flowman的开源、基于Spark的ETL工具。</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/c057eba6f9be09b943985e532ed07582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GhbLhPIKu7T2Mbd_"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">西蒙·威尔克斯在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="d0f2" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这是大数据环境中的数据工程系列的第4部分。它将反映我个人的经验教训之旅，并在我创建的开源工具<a class="ae kz" href="https://flowman.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> Flowman </a>中达到高潮，以承担在几个项目中一遍又一遍地重新实现所有锅炉板代码的负担。</p><ul class=""><li id="a783" class="lw lx iu lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated"><a class="ae kz" href="https://medium.com/@kupferk/big-data-engineering-best-practices-bfc7e112cf1a" rel="noopener">第1部分:大数据工程—最佳实践</a></li><li id="4090" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated"><a class="ae kz" href="https://medium.com/@kupferk/big-data-engineering-apache-spark-d67be2d9b76f" rel="noopener">第2部分:大数据工程— Apache Spark </a></li><li id="3283" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/big-data-engineering-declarative-data-flows-3a63d1802846">第3部分:大数据工程——声明性数据流</a></li><li id="a196" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">第4部分:大数据工程——flow man启动和运行</li></ul><h1 id="e207" class="mk ml iu bd mm mn mo mp mq mr ms mt mu ka mv kb mw kd mx ke my kg mz kh na nb bi translated">期待什么</h1><p id="35e6" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">本系列是关于用Apache Spark构建批处理数据管道的。上次我介绍了Flowman的核心思想，这是一个基于Apache Spark的应用程序，它简化了批处理数据管道的实现。现在是时候让<a class="ae kz" href="https://flowman.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> Flowman </a>在本地机器上运行了。</p></div><div class="ab cl nh ni hy nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="in io ip iq ir"><h1 id="5022" class="mk ml iu bd mm mn no mp mq mr np mt mu ka nq kb mw kd nr ke my kg ns kh na nb bi translated">先决条件</h1><p id="428a" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">为了按照说明在您的机器上安装一个正常工作的Flowman，您不需要太多:</p><ul class=""><li id="c821" class="lw lx iu lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">要求:64位Linux(抱歉，目前没有Windows或Mac OS)</li><li id="8c93" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">必选:Java (OpenJDK也可以)</li><li id="7228" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">可选:Maven和npm，如果您想从源代码构建Flowman</li><li id="9d4b" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">推荐:访问S3上的一些测试数据的AWS凭证</li></ul><h1 id="4aa4" class="mk ml iu bd mm mn mo mp mq mr ms mt mu ka mv kb mw kd mx ke my kg mz kh na nb bi translated">安装Hadoop和Spark</h1><p id="477c" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">尽管Flowman直接建立在Apache Spark的能力之上，但它并没有提供一个有效的Hadoop或Spark环境——这是有原因的:在许多环境中(特别是在使用Hadoop发行版的公司中),一些平台团队已经提供了Hadoop/Spark环境。Flowman尽最大努力不搞砸，而是需要一个工作的火花装置。</p><p id="31e7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">幸运的是，Spark很容易安装在本地机器上:</p><h2 id="2979" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">下载并安装Spark</h2><p id="060d" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">目前最新的Flowman版本是0.14.2，可以在<a class="ae kz" href="https://spark.apache.org/downloads.html" rel="noopener ugc nofollow" target="_blank"> Spark主页</a>上获得Spark 3.0.1的预构建版本。因此，我们从Apache归档文件中下载适当的Spark发行版，并对其进行解压缩。</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="bb95" class="nt ml iu og b gz ok ol l om on"># Create a nice playground which doesn't mess up your system<br/>$ <strong class="og iv">mkdir playground</strong><br/>$ <strong class="og iv">cd playground</strong></span><span id="e4ff" class="nt ml iu og b gz oo ol l om on"># Download and unpack Spark &amp; Hadoop<br/>$ <strong class="og iv">curl -L </strong><a class="ae kz" href="https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz" rel="noopener ugc nofollow" target="_blank"><strong class="og iv">https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz</strong></a><strong class="og iv"> | tar xvzf -</strong></span><span id="47c7" class="nt ml iu og b gz oo ol l om on"># Create a nice link<br/>$ <strong class="og iv">ln -snf spark-3.0.1-bin-hadoop3.2 spark</strong></span></pre><p id="c333" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">Spark包中已经包含了Hadoop，所以只需下载一次，您就已经安装了Hadoop，并且彼此集成。</p><h1 id="42be" class="mk ml iu bd mm mn mo mp mq mr ms mt mu ka mv kb mw kd mx ke my kg mz kh na nb bi translated">安装流量计</h1><h2 id="7b28" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">下载和安装</h2><p id="9b6a" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">你可以在GitHub 的相应<a class="ae kz" href="https://github.com/dimajix/flowman/releases" rel="noopener ugc nofollow" target="_blank">发布页面上找到预建的Flowman包。对于这个研讨会，我选择了</a><a class="ae kz" href="https://github.com/dimajix/flowman/releases/download/0.14.2/flowman-dist-0.14.2-oss-spark3.0-hadoop3.2-bin.tar.gz" rel="noopener ugc nofollow" target="_blank">flowman-dist-0.14.2-oss-spark3.0-hadoop3.2-bin.tar.gz</a>，它非常适合我们之前刚刚下载的Spark包。</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="35b7" class="nt ml iu og b gz ok ol l om on"># Download and unpack Flowman<br/>$ <strong class="og iv">curl -L </strong><a class="ae kz" href="https://github.com/dimajix/flowman/releases/download/0.14.2/flowman-dist-0.14.2-oss-spark3.0-hadoop3.2-bin.tar.gz" rel="noopener ugc nofollow" target="_blank"><strong class="og iv">https://github.com/dimajix/flowman/releases/download/0.14.2/flowman-dist-0.14.2-oss-spark3.0-hadoop3.2-bin.tar.gz</strong></a><strong class="og iv"> | tar xvzf -</strong></span><span id="99e4" class="nt ml iu og b gz oo ol l om on"># Create a nice link<br/>$ <strong class="og iv">ln -snf flowman-0.14.2 flowman</strong></span></pre><h2 id="d118" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">配置</h2><p id="6530" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">现在，在使用Flowman之前，您需要告诉它在哪里可以找到我们在上一步中刚刚创建的Spark主目录。这可以通过在<code class="fe op oq or og b">flowman/conf/flowman-env.sh</code>中提供一个有效的配置文件来完成(模板可以在<code class="fe op oq or og b">flowman/conf/flowman-env.sh.template</code>中找到)，或者我们可以简单地设置一个环境变量。为了简单起见，我们遵循第二种方法</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="4115" class="nt ml iu og b gz ok ol l om on"># This assumes that we are still in the directory "playground"<br/>$ <strong class="og iv">export SPARK_HOME=$(pwd)/spark</strong></span></pre><p id="2edb" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了在下面的例子中访问S3，我们还需要提供一个包含一些基本插件配置的默认名称空间<em class="os">。我们简单地复制提供的模板如下:</em></p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="ec4b" class="nt ml iu og b gz ok ol l om on"># Copy default namespace<br/>$ <strong class="og iv">cp flowman/conf/default-namespace.yml.template flowman/conf/default-namespace.yml</strong></span><span id="083a" class="nt ml iu og b gz oo ol l om on"># Copy default environment<br/>$ <strong class="og iv">cp flowman/conf/flowman-env.sh.template flowman/conf/flowman-env.sh</strong></span></pre><p id="0088" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这就是我们运行Flowman示例所需的全部内容。</p><h1 id="bd96" class="mk ml iu bd mm mn mo mp mq mr ms mt mu ka mv kb mw kd mx ke my kg mz kh na nb bi translated">天气示例</h1><p id="068e" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">下面的演练将使用“天气”示例，该示例对来自NOAA 的<a class="ae kz" href="https://www.ncdc.noaa.gov/isd" rel="noopener ugc nofollow" target="_blank">“综合地表数据集”的一些天气数据执行一些简单的处理。</a></p><h2 id="967c" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">项目详情</h2><p id="cd5a" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">“天气示例”执行三个典型的ETL处理任务:</p><ul class=""><li id="b0b8" class="lw lx iu lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">读入原始测量数据，提取一些属性，并将结果存储在拼花地板文件中</li><li id="8af8" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">读入工作站主数据并存储在拼花文件中。</li><li id="9402" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">将测量值与主数据整合，汇总每个国家和年份的测量值，计算最小值、最大值和平均值，并将结果存储在拼花文件中。</li></ul><p id="b929" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这三个任务包括许多ETL管道中常见的典型的“读取、提取、写入”、“集成”和“聚合”操作。</p><p id="eb65" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了简单起见，该示例没有使用Hive元存储，尽管我强烈建议将它用于任何严肃的Hadoop/Spark项目，作为管理元数据的中央权威。</p><h2 id="6e52" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">Flowman项目结构</h2><p id="5ee5" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">您将在目录<code class="fe op oq or og b">flowman/examples/weather</code>中找到Flowman项目。该项目由几个子文件夹组成，反映了Flowman的基本实体类型:</p><ul class=""><li id="046f" class="lw lx iu lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated"><strong class="lc iv"> config </strong> —该文件夹包含一些配置文件，这些文件包含Spark、Hadoop或Flowman本身的属性。</li><li id="9535" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated"><strong class="lc iv">模型</strong>—模型文件夹包含存储在磁盘或S3上的物理数据模型的描述。有些模型是指读入的源数据，有些模型是指将由Flowman生成的目标数据。</li><li id="6b9e" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated"><strong class="lc iv">映射</strong> —映射文件夹包含处理逻辑。这包括读入数据等简单步骤，以及连接和聚合等更复杂的步骤。</li><li id="0217" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated"><strong class="lc iv">目标</strong> —目标文件夹包含<em class="os">构建目标</em>的描述。Flowman认为自己是一个数据构建工具，因此它需要知道应该构建什么。目标通常只是简单地将映射的结果与数据模型耦合起来，用作接收器。</li><li id="0fef" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated"><strong class="lc iv">作业</strong>—最后，作业文件夹包含作业(在本例中只有一个)，它或多或少只是应该一起构建的目标列表。Flowman将负责正确的建造顺序。</li></ul><p id="dd8b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这种目录布局有助于将一些结构带入项目，但是您可以使用您喜欢的任何其他布局。你只需要指定<code class="fe op oq or og b">project.yml</code>文件中的目录，这个文件在例子的根目录下(即<code class="fe op oq or og b">flowman/examples/weather</code>)。</p><h1 id="54c2" class="mk ml iu bd mm mn mo mp mq mr ms mt mu ka mv kb mw kd mx ke my kg mz kh na nb bi translated">Flowman手动操作</h1><p id="d087" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">示例数据存储在我自己提供的S3存储桶中。为了访问数据，您需要在您的环境中提供有效的AWS凭据:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="34e6" class="nt ml iu og b gz ok ol l om on">$ <strong class="og iv">export AWS_ACCESS_KEY_ID=&lt;your aws access key&gt;</strong><br/>$ <strong class="og iv">export AWS_SECRET_ACCESS_KEY=&lt;your aws secret key&gt;</strong></span></pre><p id="bc92" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们通过运行交互式Flowman shell来启动Flowman。虽然这不是自动批处理中使用的工具(<code class="fe op oq or og b">flowexec</code>是该场景的合适工具)，但它让我们很好地了解了Flowman中的ETL项目是如何组织的。</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="a1cd" class="nt ml iu og b gz ok ol l om on"># This assumes that we are still in the directory "playground"<br/>$ <strong class="og iv">cd flowman</strong></span><span id="a56c" class="nt ml iu og b gz oo ol l om on"># Start interactive Flowman shell<br/>$ <strong class="og iv">bin/flowshell -f examples/weather</strong></span><span id="d5fd" class="nt ml iu og b gz oo ol l om on">20/10/10 09:41:21 INFO SystemSettings: Using default system settings<br/>20/10/10 09:41:21 INFO Namespace: Reading namespace file /home/kaya/tmp/playgroud/flowman-0.14.2-SNAPSHOT/conf/default-namespace.yml<br/>20/10/10 09:41:23 INFO Plugin: Reading plugin descriptor /home/kaya/tmp/playgroud/flowman-0.14.2-SNAPSHOT/plugins/flowman-example/plugin.yml<br/>...</span></pre><p id="778f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">日志输出完成后，您应该会看到一个提示<code class="fe op oq or og b">flowman:weather&gt;</code>，现在您可以输入一些要执行的命令。</p><h2 id="2d7d" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">建筑物</h2><p id="2ee4" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">首先，我们要执行<code class="fe op oq or og b">main</code>任务，并<em class="os">构建</em>所有已定义的目标。因为作业定义了一个参数<code class="fe op oq or og b">year</code>，每次调用只处理一年，所以我们需要为这个参数提供一个值。因此，我们通过下面的命令开始2011年<code class="fe op oq or og b">main</code>中所有目标的构建过程:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="13ad" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">job build main year=2011</strong></span><span id="3a71" class="nt ml iu og b gz oo ol l om on">20/10/10 09:41:33 INFO Runner: Executing phases 'create','build' for job 'weather/main'<br/>20/10/10 09:41:33 INFO Runner: Job argument year=2011<br/>20/10/10 09:41:33 INFO Runner: Running phase create of job 'weather/main'   with arguments year=2011<br/>20/10/10 09:41:33 INFO Runner: Environment (phase=create) basedir=file:///tmp/weather<br/>20/10/10 09:41:33 INFO Runner: Environment (phase=create) force=false<br/>20/10/10 09:41:33 INFO Runner: Environment (phase=create) job=main<br/>20/10/10 09:41:33 INFO Runner: Environment (phase=create) namespace=default<br/>20/10/10 09:41:33 INFO Runner: Environment (phase=create) phase=create<br/>20/10/10 09:41:33 INFO Runner: Environment (phase=create) project=weather<br/>20/10/10 09:41:33 INFO Runner: Environment (phase=create) year=2011<br/>...</span></pre><p id="34de" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">再次产生大量输出(部分由Spark的启动产生，但也由Flowman产生，因此您实际上可以跟踪Flowman在做什么。日志记录总是一个困难的主题——过多的日志记录会分散用户的注意力，而过少的输出会使问题的解决更加困难。</p><p id="6117" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">具体来说，您应该看到两个重要的事实:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="5606" class="nt ml iu og b gz ok ol l om on">...<br/>20/10/10 09:41:33 INFO Runner: Executing phases 'create','build' for job 'weather/main'<br/>20/10/10 09:41:33 INFO Runner: Running phase '<strong class="og iv">create</strong>' of job 'weather/main'   with arguments year=2011<br/>...</span></pre><p id="7cfe" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">后来呢</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="e51e" class="nt ml iu og b gz ok ol l om on">...<br/>20/10/10 09:41:37 INFO Runner: Running phase '<strong class="og iv">build</strong>' of job 'weather/main'   with arguments year=2011<br/>...</span></pre><p id="0de3" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这意味着指示flow man<em class="os">构建</em>一个任务的所有目标实际上执行了完整的<em class="os">构建生命周期</em>，它包括以下两个阶段</p><ul class=""><li id="5d63" class="lw lx iu lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">“<strong class="lc iv"> create </strong>”阶段创建和/或迁移构建目标中引用的所有物理数据模型，如目录结构、配置单元表或数据库表。这个阶段只关注<em class="os">模式管理</em>。</li><li id="dbe5" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">然后'<strong class="lc iv">构建</strong>'阶段将用从数据流中创建的记录填充这些关系，如映射和目标所定义的。</li></ul><p id="20ac" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">Flowman还支持清理生命周期，首先在“<strong class="lc iv"> truncate </strong>阶段删除数据，然后在“<strong class="lc iv"> destroy </strong>阶段删除所有目录和表格。</p><h2 id="0ef3" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">目标构建顺序</h2><p id="039d" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">当您研究weather项目的细节时，您会发现构建目标有一些隐含的运行时依赖性:首先，来自S3的原始数据需要传输到您的本地机器，并存储在一些本地目录中(实际上在<code class="fe op oq or og b">/tmp/weather</code>)。然后这些目录作为构建<code class="fe op oq or og b">aggregates</code>目标的输入。</p><p id="e183" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">您不会发现任何显式的依赖关系信息，Flowman会自己找出这些构建时依赖关系，并以正确的顺序执行所有操作。您可以在以下日志记录输出中看到这一点:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="956b" class="nt ml iu og b gz ok ol l om on">20/10/12 20:29:15 INFO Target: Dependencies of phase 'build' of target 'weather/measurements': <br/>20/10/12 20:29:15 INFO Target: Dependencies of phase 'build' of target 'weather/aggregates': weather/stations,weather/measurements<br/>20/10/12 20:29:15 INFO Target: Dependencies of phase 'build' of target 'weather/stations': <br/>20/10/12 20:29:15 INFO Runner: Executing phase 'build' with sequence: weather/measurements, weather/stations, weather/aggregates</span></pre><p id="ea41" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">Flowman首先收集所有隐式依赖项(前三个日志行)，然后找到所有目标的适当执行顺序(最后一个日志行)。</p><p id="2788" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">所有构建目标的自动排序在具有许多依赖输出的复杂项目中非常有用，在这些项目中很难手动跟踪正确的构建顺序。使用Flowman，您只需添加一个新的构建目标，所有的输出都会自动以正确的顺序写入。</p><h2 id="943c" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">重建</h2><p id="b914" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">当您现在尝试重建同一年时，Flowman将自动跳过处理，因为所有目标关系都已建立并包含2011年的有效数据:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="eb18" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">job build main year=2011</strong></span><span id="dd10" class="nt ml iu og b gz oo ol l om on">...<br/>20/10/10 10:56:03 INFO Runner: Target 'weather/measurements' not dirty in phase build, skipping execution<br/>...<br/>20/10/10 10:56:03 INFO JdbcStateStore: Mark last run of phase 'build' of job 'default/weather/main' as skipped in state database<br/>...</span></pre><p id="106a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">同样，这个逻辑是从经典的构建工具领域借用来的，比如<code class="fe op oq or og b">make</code>，它也跳过现有的目标。</p><p id="7a1d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当然，您可以通过在命令末尾添加一个<code class="fe op oq or og b">--force</code>标志来强制Flowman重新处理数据。</p><h2 id="ee83" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">检查关系</h2><p id="1fed" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">现在我们想直接在Flowman中检查一些结果(不需要借助一些命令行工具来检查Parquet文件)。这可以通过检查<em class="os">关系</em>来完成，这些关系总是代表存储在一些磁盘或数据库中的物理模型。</p><p id="9aab" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">首先，让我们获得项目中定义的所有关系的列表:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="ab7d" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">relation list</strong></span><span id="ccd3" class="nt ml iu og b gz oo ol l om on">aggregates<br/>measurements<br/>measurements-raw<br/>stations<br/>stations-raw</span></pre><p id="b284" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当您查看了<code class="fe op oq or og b">model</code>目录中的项目文件后，您应该会觉得很熟悉。该列表包含项目中定义的所有模型名称。</p><p id="db84" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在让我们检查存储在<code class="fe op oq or og b">stations</code>关系中的主数据:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="39e0" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">relation show stations</strong></span><span id="1772" class="nt ml iu og b gz oo ol l om on">...<br/>usaf,wban,name,country,state,icao,latitude,longitude,elevation,date_begin,date_end<br/>007018,99999,WXPOD 7018,null,null,null,0.0,0.0,7018.0,20110309,20130730<br/>007026,99999,WXPOD 7026,AF,null,null,0.0,0.0,7026.0,20120713,20170822<br/>007070,99999,WXPOD 7070,AF,null,null,0.0,0.0,7070.0,20140923,20150926<br/>008260,99999,WXPOD8270,null,null,null,0.0,0.0,0.0,20050101,20100920<br/>008268,99999,WXPOD8278,AF,null,null,32.95,65.567,1156.7,20100519,20120323<br/>008307,99999,WXPOD 8318,AF,null,null,0.0,0.0,8318.0,20100421,20100421<br/>008411,99999,XM20,null,null,null,null,null,null,20160217,20160217<br/>008414,99999,XM18,null,null,null,null,null,null,20160216,20160217<br/>008415,99999,XM21,null,null,null,null,null,null,20160217,20160217<br/>008418,99999,XM24,null,null,null,null,null,null,20160217,20160217<br/>...</span></pre><p id="b766" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">目前，所有数据都显示为CSV——这并不意味着数据存储为CSV(事实并非如此，它存储在Parquet文件中)。</p><p id="1564" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在让我们来考察一下<code class="fe op oq or og b">measurements</code>的数据:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="1c29" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">relation show measurements</strong></span><span id="c2c2" class="nt ml iu og b gz oo ol l om on">...<br/>usaf,wban,date,time,wind_direction,wind_direction_qual,wind_observation,wind_speed,wind_speed_qual,air_temperature,air_temperature_qual,year<br/>999999,63897,20110101,0000,155,1,H,7.4,1,19.0,1,2011<br/>999999,63897,20110101,0005,158,1,H,4.8,1,18.6,1,2011<br/>999999,63897,20110101,0010,159,1,H,4.4,1,18.5,1,2011<br/>999999,63897,20110101,0015,148,1,H,3.9,1,18.3,1,2011<br/>999999,63897,20110101,0020,139,1,H,3.6,1,18.1,1,2011<br/>999999,63897,20110101,0025,147,1,H,3.6,1,18.1,1,2011<br/>999999,63897,20110101,0030,157,1,H,4.0,1,18.0,1,2011<br/>999999,63897,20110101,0035,159,1,H,3.5,1,17.9,1,2011<br/>999999,63897,20110101,0040,152,1,H,3.0,1,17.8,1,2011<br/>999999,63897,20110101,0045,140,1,H,3.4,1,17.8,1,2011</span></pre><p id="b01c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">最后，让我们来看看总量。类似于<code class="fe op oq or og b">measurements</code>关系，<code class="fe op oq or og b">aggregates</code>关系也是分区的。我们还可以选择为分区列指定一个值:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="b349" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">relation show aggregates -p year=2011</strong></span><span id="201b" class="nt ml iu og b gz oo ol l om on">country,min_wind_speed,max_wind_speed,avg_wind_speed,min_temperature,max_temperature,avg_temperature,year<br/>SF,0.0,12.3,2.1503463,2.3,34.9,17.928537,2011<br/>US,0.0,36.0,2.956173,-44.0,46.4,11.681804,2011<br/>RS,0.0,12.0,3.3127716,-33.0,32.0,4.5960307,2011<br/>MY,0.0,10.8,2.0732634,21.0,34.0,27.85072,2011<br/>GM,0.0,15.4,3.910823,-10.0,30.0,9.442137,2011<br/>FI,0.0,21.0,3.911331,-34.4,30.7,3.1282191,2011<br/>IC,0.0,31.9,7.235976,-14.0,17.2,5.138462,2011<br/>SC,0.0,14.0,4.618577,20.0,32.0,27.329834,2011<br/>NL,0.0,31.4,4.969081,-8.2,34.0,10.753498,2011<br/>AU,0.0,15.9,1.9613459,-15.0,35.0,9.814931,2011</span></pre><h2 id="69b5" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">检查映射</h2><p id="ebdb" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">在ETL应用程序的开发过程中，能够查看一些中间结果通常非常有用。这些映射的中间结果可能并不总是在磁盘上或数据库中有物理表示。它们只是概念，记录在处理过程中只在内存中具体化。但是Flowman shell也支持通过查看映射的结果来检查这些中间结果。</p><p id="503f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在我们展示这个特性之前，我们首先需要提前执行一个有点笨拙的步骤:与关系相反，数据流本身依赖于参数<code class="fe op oq or og b">year</code>，并且在没有设置该参数的情况下无法执行或检查。此外，Flowman作业还可能设置一些执行所需的附加环境变量。</p><p id="da7c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了减轻对这种情况的处理，Flowman提供了一个特殊的命令来设置执行环境，因为它将由特定的作业提供:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="ab62" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">job enter main year=2011<br/></strong>flowman:weather/main&gt;</span></pre><p id="7a94" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">作为回报，提示符发生变化，现在还包含作业的名称。</p><p id="9c15" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在我们可以开始检查中间结果了。首先，让我们获得所有映射的列表:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="bb0b" class="nt ml iu og b gz ok ol l om on">flowman:weather/main&gt; <strong class="og iv">mapping list</strong></span><span id="992c" class="nt ml iu og b gz oo ol l om on">aggregates<br/>facts<br/>measurements<br/>measurements-extracted<br/>measurements-joined<br/>measurements-raw<br/>stations<br/>stations-raw</span></pre><p id="d5cc" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在，让我们从检查存储在S3的原始测量数据开始:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="05b7" class="nt ml iu og b gz ok ol l om on">flowman:weather/main&gt; <strong class="og iv">mapping show measurements-raw</strong></span><span id="bec1" class="nt ml iu og b gz oo ol l om on">043499999963897201101010000I+32335-086979CRN05+004899999V0201551H007419999999N999999999+01901+99999999999ADDAA101000991AO105000491CF1105210CF2105210CF3105210CG1+0120410CG2+0126710CG3+0122710CN1012610012110999990CN2+999990+0219100010CN30149971005638010CN40100000104001016010CO199-06CR10510210CT1+019010CT2+019110CT3+019010CU1+999990000410CU2+999990000410CU3+999990000410CV1+019010999990+020310999990CV2+019110999990+020310999990CV3+019010999990+020310999990CW100330101076010KA1010M+02031KA2010N+01901KF1+01951OB10050100101571099999900105210<br/>013399999963897201101010005I+32335-086979CRN05+004899999V0201581H004819999999N999999999+01861+99999999999ADDAO105000091CG1+0120410CG2+0126710CG3+0122710CO199-06CT1+018610CT2+018610CT3+018610CW100330102311010OB10050064101581099999900096910<br/>013399999963897201101010010I+32335-086979CRN05+004899999V0201591H004419999999N999999999+01851+99999999999ADDAO105000091CG1+0120410CG2+0126710CG3+0122710CO199-06CT1+018410CT2+018510CT3+018510CW100330102901010OB10050054101541099999900105010<br/>...</span></pre><p id="0348" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如您所见，原始数据很难处理。但是幸运的是，我们已经有了提取至少一些简单字段的映射:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="2826" class="nt ml iu og b gz ok ol l om on">flowman:weather/main&gt; <strong class="og iv">mapping show measurements-extracted</strong></span><span id="229b" class="nt ml iu og b gz oo ol l om on">wind_speed_qual,wban,usaf,air_temperature,date,wind_speed,air_temperature_qual,wind_direction,report_type,wind_direction_qual,time,wind_observation<br/>1,63897,999999,19.0,20110101,7.4,1,155,CRN05,1,0000,H<br/>1,63897,999999,18.6,20110101,4.8,1,158,CRN05,1,0005,H<br/>1,63897,999999,18.5,20110101,4.4,1,159,CRN05,1,0010,H<br/>1,63897,999999,18.3,20110101,3.9,1,148,CRN05,1,0015,H<br/>1,63897,999999,18.1,20110101,3.6,1,139,CRN05,1,0020,H<br/>1,63897,999999,18.1,20110101,3.6,1,147,CRN05,1,0025,H<br/>1,63897,999999,18.0,20110101,4.0,1,157,CRN05,1,0030,H<br/>1,63897,999999,17.9,20110101,3.5,1,159,CRN05,1,0035,H<br/>1,63897,999999,17.8,20110101,3.0,1,152,CRN05,1,0040,H<br/>1,63897,999999,17.8,20110101,3.4,1,140,CRN05,1,0045,H</span></pre><p id="e696" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">使用相同的命令，我们还可以检查<code class="fe op oq or og b">stations</code>映射:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="73d7" class="nt ml iu og b gz ok ol l om on">flowman:weather/main&gt; <strong class="og iv">mapping show stations</strong></span><span id="0333" class="nt ml iu og b gz oo ol l om on">usaf,wban,name,country,state,icao,latitude,longitude,elevation,date_begin,date_end<br/>007018,99999,WXPOD 7018,null,null,null,0.0,0.0,7018.0,20110309,20130730<br/>007026,99999,WXPOD 7026,AF,null,null,0.0,0.0,7026.0,20120713,20170822<br/>007070,99999,WXPOD 7070,AF,null,null,0.0,0.0,7070.0,20140923,20150926<br/>008260,99999,WXPOD8270,null,null,null,0.0,0.0,0.0,20050101,20100920<br/>008268,99999,WXPOD8278,AF,null,null,32.95,65.567,1156.7,20100519,20120323<br/>008307,99999,WXPOD 8318,AF,null,null,0.0,0.0,8318.0,20100421,20100421<br/>008411,99999,XM20,null,null,null,null,null,null,20160217,20160217<br/>008414,99999,XM18,null,null,null,null,null,null,20160216,20160217<br/>008415,99999,XM21,null,null,null,null,null,null,20160217,20160217<br/>008418,99999,XM24,null,null,null,null,null,null,20160217,20160217</span></pre><p id="080f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">最后，我们可以再次离开作业上下文(这将清除所有参数和特定于作业的环境变量):</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="14e1" class="nt ml iu og b gz ok ol l om on">flowman:weather/main&gt; <strong class="og iv">job leave</strong></span></pre><h2 id="6d15" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">执行历史</h2><p id="e5fe" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">Flowman还可以选择跟踪已经执行的所有过去运行的作业。这些信息存储在一个小型数据库中。这个历史数据库背后的想法是提供一个机会来记录成功和失败的运行，而不需要额外的外部监控系统。</p><p id="ce3d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们在开始时从一个模板复制的示例配置<code class="fe op oq or og b">default-namespace.yml</code>支持这种历史记录，并将信息存储在一个小型Derby数据库中。</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="551f" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">history job search</strong></span><span id="87c4" class="nt ml iu og b gz oo ol l om on">+---+---------+-------+----+------+----+-------+-----------------------------+-----------------------------+<br/>| id|namespace|project| job| phase|args| status|                     start_dt|                       end_dt|<br/>+---+---------+-------+----+------+----+-------+-----------------------------+-----------------------------+<br/>|  1|  default|weather|main|create|    |success|2020-10-09T11:37:35.161Z[UTC]|2020-10-09T11:37:40.211Z[UTC]|<br/>|  2|  default|weather|main| build|    |success|2020-10-09T11:37:40.230Z[UTC]|2020-10-09T11:38:43.435Z[UTC]|<br/>+---+---------+-------+----+------+----+-------+-----------------------------+-----------------------------+</span></pre><p id="503d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们也可以搜索所有已经建成的目标。在以下示例中，我们指定只搜索作为id为1的作业运行的一部分而构建的所有目标:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="ff34" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">history target search -J 1</strong></span><span id="9f94" class="nt ml iu og b gz oo ol l om on">+--+-----+---------+-------+------------+----------+------+-------+-----------------------------+-----------------------------+<br/>|id|jobId|namespace|project|      target|partitions| phase| status|                     start_dt|                       end_dt|<br/>+--+-----+---------+-------+------------+----------+------+-------+-----------------------------+-----------------------------+<br/>| 1|    1|  default|weather|measurements|          |create|success|2020-10-12T18:02:50.633Z[UTC]|2020-10-12T18:02:52.179Z[UTC]|<br/>| 2|    1|  default|weather|  aggregates|          |create|success|2020-10-12T18:02:52.244Z[UTC]|2020-10-12T18:02:52.261Z[UTC]|<br/>| 3|    1|  default|weather|    stations|          |create|success|2020-10-12T18:02:52.304Z[UTC]|2020-10-12T18:02:52.320Z[UTC]|<br/>+--+-----+---------+-------+------------+----------+------+-------+-----------------------------+-----------------------------+</span></pre><h2 id="ea59" class="nt ml iu bd mm nu nv dn mq nw nx dp mu lj ny nz mw ln oa ob my lr oc od na oe bi translated">放弃</h2><p id="60c7" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">最后，我们通过<code class="fe op oq or og b">exit</code>或<code class="fe op oq or og b">quit</code>退出Flowman shell:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="3d79" class="nt ml iu og b gz ok ol l om on">flowman:weather&gt; <strong class="og iv">quit</strong></span></pre><h1 id="a206" class="mk ml iu bd mm mn mo mp mq mr ms mt mu ka mv kb mw kd mx ke my kg mz kh na nb bi translated">执行项目</h1><p id="112e" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">到目前为止，我们只将Flowman shell用于项目的交互工作。实际上，开发shell的第二步是帮助分析问题和调试数据流。使用Flowman项目的主要命令是<code class="fe op oq or og b">flowexec</code>，用于非交互式批处理执行，例如在cron-jobs中。</p><p id="f062" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">它与Flowman shell共享大量代码，因此命令通常完全相同。主要的区别是使用<code class="fe op oq or og b">flowexec</code>你可以在命令行上指定命令，而<code class="fe op oq or og b">flowshell</code>会提供自己的提示。</p><p id="9291" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">例如，要运行2014年天气项目的“构建”生命周期，您只需运行:</p><pre class="kk kl km kn gu of og oh oi aw oj bi"><span id="7843" class="nt ml iu og b gz ok ol l om on">$ <strong class="og iv">bin/flowexec -f examples/weather job build main year=2014</strong></span><span id="b58b" class="nt ml iu og b gz oo ol l om on">...</span></pre></div><div class="ab cl nh ni hy nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="in io ip iq ir"><h1 id="3131" class="mk ml iu bd mm mn no mp mq mr np mt mu ka nq kb mw kd nr ke my kg ns kh na nb bi translated">谢谢！</h1><p id="9421" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">非常感谢您花时间阅读这篇冗长的文章。非常感谢您！发给所有试图在本地机器上实践这个例子的人。如果你对这个例子有疑问，请给我留言——简化这样的过程总是很困难的，我可能会忽略一些问题。</p><h1 id="e49c" class="mk ml iu bd mm mn mo mp mq mr ms mt mu ka mv kb mw kd mx ke my kg mz kh na nb bi translated">最后的话</h1><p id="2d98" class="pw-post-body-paragraph la lb iu lc b ld nc jv lf lg nd jy li lj ne ll lm ln nf lp lq lr ng lt lu lv in bi translated">这是关于使用Apache Spark构建健壮的数据管道的系列文章的最后一部分。现在，您应该对我构建数据管道的最佳实践的偏好以及我在Flowman中的实现有了一个概念，Flowman目前在两家不同的公司的生产中使用。整个方法已经为我提供了很好的服务，我仍然更喜欢它，而不是一个不统一的单个Spark应用程序集合，它们本质上做着非常相似的事情。</p><p id="4888" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果您对在您的项目中使用Flowman感兴趣，那么非常欢迎您尝试一下，并与我联系以解决任何问题。</p></div></div>    
</body>
</html>