<html>
<head>
<title>7 Over Sampling techniques to handle Imbalanced Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">7处理不平衡数据的过采样技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/7-over-sampling-techniques-to-handle-imbalanced-data-ec51c8db349f?source=collection_archive---------8-----------------------#2020-11-11">https://towardsdatascience.com/7-over-sampling-techniques-to-handle-imbalanced-data-ec51c8db349f?source=collection_archive---------8-----------------------#2020-11-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8e43" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">各种过采样技术的深度分析</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/52ecce7d3fe230850286231a963e53d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hRKKRduqmLoxytwqTzL7w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/users/ltdatehu-9079918/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=1095751" rel="noopener ugc nofollow" target="_blank"> LTD EHU </a>发自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=1095751" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="491b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> M </span>对不平衡数据建模是我们在训练模型时面临的主要挑战。为了处理分类问题，目标类别标签的类别平衡在建模中起着重要的作用。对于不平衡类问题，即数据集中存在少数类，模型会尝试只学习多数类，从而导致有偏差的预测。</p><p id="4d71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不平衡的阶级问题的一些著名例子是:</p><ol class=""><li id="f73e" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">信用卡欺诈检测</li><li id="89f8" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">疾病诊断</li><li id="880b" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">垃圾邮件检测等等</li></ol><p id="c948" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在训练模型之前，需要处理数据集的不平衡。有各种技术来处理类平衡，其中一些是过采样，欠采样，或两者的结合。本文将深入解释7种过采样技术:</p><ol class=""><li id="1be7" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated"><strong class="lb iu">随机过采样</strong></li><li id="c72b" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu">重击</strong></li><li id="18a2" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu">临界击打</strong></li><li id="b8eb" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu">克平均击打</strong></li><li id="77f0" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu"> SVM击杀</strong></li><li id="e795" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu">阿达辛</strong></li><li id="2ef9" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated"><strong class="lb iu"> Smote-NC </strong></li></ol><blockquote class="ms mt mu"><p id="5686" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">对于不同过采样模型的评估，我们使用来自Kaggle 的<a class="ae ky" href="https://www.kaggle.com/shubh0799/churn-modelling" rel="noopener ugc nofollow" target="_blank">流失建模数据集。</a></p></blockquote><p id="f853" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">不使用任何过采样或欠采样技术的逻辑回归模型的性能。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/86eecbbaf8972f571df3f15e16817b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OoC3Uq2pIFxTpGmFEsV2Q.jpeg"/></div></div></figure><h1 id="ef23" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">1.随机过采样:</h1><p id="01a5" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">随机过采样是平衡数据集不平衡性质的最简单的过采样技术。它通过复制少数类样本来平衡数据。这不会导致任何信息丢失，但是当复制相同的信息时，数据集容易过拟合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/f9d526f4893cb423f7538959d7feb0d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*90exXhMKCTfgA-HJz8Yxww.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd nx">左:</strong>随机过采样后的散点图，<strong class="bd nx">右:</strong>随机过采样后模型的性能</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="58dd" class="na nb it bd nc nd of nf ng nh og nj nk jz oh ka nm kc oi kd no kf oj kg nq nr bi translated">2.击打:</h1><p id="1e26" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">在随机过采样的情况下，当少数类样本被复制时，容易出现过拟合，这里SMOTE出现了。SMOTE代表合成少数过采样技术。它创建新的合成样本来平衡数据集。</p><p id="4c2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SMOTE通过利用<strong class="lb iu">k-最近邻</strong>算法来创建合成数据。使用Smote创建步骤示例:</p><ul class=""><li id="caa5" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu ok mk ml mm bi translated">识别特征向量及其最近邻</li><li id="d925" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ok mk ml mm bi translated">计算两个样本点之间的距离</li><li id="b913" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ok mk ml mm bi translated">用0到1之间的随机数乘以距离。</li><li id="b0a3" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ok mk ml mm bi translated">在计算出的距离处识别线段上的新点。</li><li id="47ec" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu ok mk ml mm bi translated">对识别的特征向量重复该过程。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/f97dd549cda3c2985cb22cc165700bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*79IhndprSLDk4cOWIFLqqw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd nx">左:</strong>SMOTE后散点图，<strong class="bd nx">右:</strong>SMOTE后模型表现</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="67fd" class="na nb it bd nc nd of nf ng nh og nj nk jz oh ka nm kc oi kd no kf oj kg nq nr bi translated">3.临界击打:</h1><p id="a9f5" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">由于多数类点区域内存在一些少数类点或异常值，因此会创建少数类点的桥。这是Smote中的一个问题，使用边界Smote可以解决这个问题。</p><p id="9f35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在边界线Smote技术中，只有边界线附近的少数样本被过采样。它将少数类点分类成噪声点、边界点。噪声点是少数类点，其大多数点都是其邻居中的多数点，而边界点在其邻居中既有多数类点也有少数类点。边界线Smote算法试图仅使用这些边界点来创建合成点，并忽略噪声点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/1cd3c6ea0dc53f2a7994661531595e43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JiMAeRA3yeLm8uwNvaEU-w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd nx">左:</strong>边界平滑后散点图，<strong class="bd nx">右:</strong>边界平滑后模型性能</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="1679" class="na nb it bd nc nd of nf ng nh og nj nk jz oh ka nm kc oi kd no kf oj kg nq nr bi translated">4.KMeans击打:</h1><p id="608f" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">K-Means SMOTE是一种用于类不平衡数据的过采样方法。它通过在输入空间的安全和关键区域生成少数类样本来帮助分类。该方法避免了噪声的产生，并且有效地克服了类之间和类内的不平衡。</p><p id="c224" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">K-Means SMOTE分五步工作:</p><ol class=""><li id="9376" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">使用k-means聚类算法对整个数据进行聚类。</li><li id="3235" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">选择具有大量少数类样本的聚类</li><li id="55db" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">将更多合成样本分配给少数类样本分布稀疏的聚类。</li></ol><p id="38ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，使用SMOTE对每个滤波后的聚类进行过采样。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/dcac2d55b1951ed797ea0ca514b2eca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-nSBqnhfkiPkKfFpIanbg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd nx">左:</strong>k means击打后散点图，<strong class="bd nx">右:</strong>k means击打后模型性能</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="d469" class="na nb it bd nc nd of nf ng nh og nj nk jz oh ka nm kc oi kd no kf oj kg nq nr bi translated">5.SVM击打:</h1><p id="cc8d" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">边界重击的另一个变体是边界重击SVM，或者我们可以称之为SVM重击。这种技术结合了SVM算法来识别错误分类点。</p><p id="1eb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在SVM-SMOTE中，在原始训练集上训练支持向量机分类器后，边界区域由支持向量近似。然后，沿着将每个少数类支持向量与其多个最近邻居连接起来的线，随机创建合成数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/d3692b4f25c05045535e923c4dd74929.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*brt5M5X1iQnD7aDSS0Bucw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd nx">左:</strong>SVM击杀后散点图，<strong class="bd nx">右:</strong>SVM击杀后模型表现</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="1aeb" class="na nb it bd nc nd of nf ng nh og nj nk jz oh ka nm kc oi kd no kf oj kg nq nr bi translated">6.自适应合成采样— ADASYN:</h1><p id="681e" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">边界线Smote更重要，或者仅使用作为边界点的极端观测值创建合成点，而忽略其余的少数类点。ADASYN算法解决了这个问题，因为它<strong class="lb iu">根据数据密度创建合成数据。</strong></p><p id="386e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">合成数据的生成与少数群体的密度成反比。与较高密度的区域相比，在低密度的少数民族类区域中创建了相对较大数量的合成数据。</p><p id="0cf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，在少数类的不太密集的区域，合成数据被创建得更多。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/9c1c1497a3e19ff6f70297033ae44f2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UEoKoMGAuX5Ilgn8VP3uaQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd nx">左:</strong>ADASYN后散点图，<strong class="bd nx">右:</strong>ADASYN后模型表现</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="b73c" class="na nb it bd nc nd of nf ng nh og nj nk jz oh ka nm kc oi kd no kf oj kg nq nr bi translated">7.Smote-NC:</h1><p id="e34f" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">Smote过采样技术仅适用于具有所有连续特征的数据集。对于具有分类特征的数据集，我们有一个Smote的变体，它是Smote-NC(名义的和连续的)。</p><p id="fb66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Smote也可以通过一键编码用于具有分类特征的数据，但它可能会导致维数增加。标签编码也可以用于将分类转换为数字，但是smote之后可能会产生不必要的信息。这就是为什么当我们有混合数据的情况下，我们需要使用SMOTE-NC。Smote-NC可以通过表示分类特征来使用，Smote会对分类数据进行重新采样，而不是创建合成数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/d5416a3d59b8696cfb8d6bcceb6557ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FWbKgJfSD3tb8emnat1tfA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd nx">左:</strong>SMOTE-NC前车型性能，<strong class="bd nx">右:</strong>SMOTE-NC后车型性能</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="f2d1" class="na nb it bd nc nd of nf ng nh og nj nk jz oh ka nm kc oi kd no kf oj kg nq nr bi translated">实施:</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者的代码实现)</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="5d93" class="na nb it bd nc nd of nf ng nh og nj nk jz oh ka nm kc oi kd no kf oj kg nq nr bi translated">结论:</h1><p id="a18e" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">对不平衡数据集建模是我们在训练模型时面临的主要挑战，使用上面讨论的各种过采样技术可以提高模型的性能。在本文中，我们还讨论了SMOTE-NC，它是SMOTE的一个变体，可以处理分类特征。</p><p id="27d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过使用各种欠采样技术，例如随机欠采样、TomekLinks等，以及过采样和欠采样技术的组合，例如SMOTEENN、SMOTETomek等，也可以提高不平衡数据集的模型性能。</p><h1 id="0480" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">参考资料:</h1><p id="4af0" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">[1] Imblearn文档:<a class="ae ky" href="https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.over_sampling" rel="noopener ugc nofollow" target="_blank">https://unbalanced-learn . readthedocs . io/en/stable/API . html # module-imb learn . over _ sampling</a></p><p id="2a3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]<a class="ae ky" href="https://pypi.org/project/kmeans-smote/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/kmeans-smote/</a></p><blockquote class="on"><p id="4da0" class="oo op it bd oq or os ot ou ov ow lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>