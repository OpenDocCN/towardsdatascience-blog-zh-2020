<html>
<head>
<title>How Many Neurons Should Your Neural Network Have?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的神经网络应该有多少个神经元？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/systematically-tuning-your-model-by-looking-at-bias-and-variance-4986662315b2?source=collection_archive---------48-----------------------#2020-09-21">https://towardsdatascience.com/systematically-tuning-your-model-by-looking-at-bias-and-variance-4986662315b2?source=collection_archive---------48-----------------------#2020-09-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="39ff" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">通过观察偏差和方差来系统地调整你的模型</strong></h2></div><p id="6550" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为数据科学家，我们在建立一个模型的时候经常会面临很多决策，比如<strong class="kh ir">用哪个模型</strong>、<strong class="kh ir">它应该有多大</strong>、<strong class="kh ir">需要多少数据</strong>、<strong class="kh ir">增加多少特征</strong>或者<strong class="kh ir">使用还是不使用正则化</strong>。虽然一些决策可以相对快速地进行评估，但其他决策(如收集更多数据)可能需要几个月的时间，然后才发现没有帮助。</p><p id="7d4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我将实际演示一种基于观察偏差和差异做出这些<strong class="kh ir">决策的方法，这种方法改变了我在几乎每个项目中进行的方式。</strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/0576a330ef2ffb5f31e694403f11bbbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rU2RZdOUtPSTtYij"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">由<a class="ae lr" href="https://unsplash.com/@valentinsalja?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Valentin Salja </a>在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="ecd8" class="lz ma iq bd mb mc md dn me mf mg dp mh ko mi mj mk ks ml mm mn kw mo mp mq mr bi translated">实践中的偏差和差异</h2><p id="edf1" class="pw-post-body-paragraph kf kg iq kh b ki ms jr kk kl mt ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">许多人在调整他们的模型时犯的错误是，他们只关注他们的验证错误。虽然这最终是最重要的数字(除了测试误差)，但同时观察训练误差可能会给你几个<strong class="kh ir">提示，告诉你该如何使用你的模型</strong>。</p><p id="4074" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">偏差和方差可能有不同的更正式的定义，但实际上是这样的:</p><blockquote class="mx my mz"><p id="757a" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated"><strong class="kh ir">偏差</strong>是训练集的错误率(1-训练精度)</p><p id="2352" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated"><strong class="kh ir">方差</strong>是验证集上的模型与训练集相比差多少的比率(训练精度-验证精度)</p></blockquote><p id="fb3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将用一个实际的例子来说明这些概念的重要性。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="f4bf" class="lz ma iq bd mb mc md dn me mf mg dp mh ko mi mj mk ks ml mm mn kw mo mp mq mr bi translated">创建数据集</h2><p id="0cbc" class="pw-post-body-paragraph kf kg iq kh b ki ms jr kk kl mt ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">让我们首先创建一个数据集，我们将使用它来训练和评估我们的模型。</p><p id="9383" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将使用sklearn的<a class="ae lr" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification" rel="noopener ugc nofollow" target="_blank"> make_classification </a>来完成这项工作，然后将数据集分成训练集和验证集。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h2 id="17ae" class="lz ma iq bd mb mc md dn me mf mg dp mh ko mi mj mk ks ml mm mn kw mo mp mq mr bi translated">场景#1:高偏差，低方差</h2><p id="fa96" class="pw-post-body-paragraph kf kg iq kh b ki ms jr kk kl mt ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">接下来，我们将开始使用<a class="ae lr" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>创建一个相对较小的神经网络，并在我们的数据集上训练它。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="a989" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">经过训练的模型得到以下结果:</p><pre class="lc ld le lf gt ng nh ni nj aw nk bi"><span id="e55b" class="lz ma iq nh b gy nl nm l nn no">Training accuracy: 62.83%<br/>Validation accuracy: 60.12%<br/><br/>Bias: 37.17%<br/>Variance: 2.71%</span></pre><p id="7b44" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，我们的模型有一个非常高的偏差，同时有一个相对较小的方差。这种状态俗称<strong class="kh ir">欠配合</strong>。</p><p id="486c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有几种<strong class="kh ir">方法可以减少偏差</strong>，让我们脱离这种状态:</p><blockquote class="mx my mz"><p id="a3bb" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">增加模型的尺寸</p><p id="e2b7" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">添加更多功能</p><p id="d3b0" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">减少正则化</p></blockquote><h2 id="fe59" class="lz ma iq bd mb mc md dn me mf mg dp mh ko mi mj mk ks ml mm mn kw mo mp mq mr bi translated">场景#2:低偏差，高方差</h2><p id="2f09" class="pw-post-body-paragraph kf kg iq kh b ki ms jr kk kl mt ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">让我们试试增加模型大小来减少偏差的方法，看看会发生什么。</p><p id="1cb6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了做到这一点，我增加了每个隐藏层中神经元的数量。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="26af" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们更大的模型得到以下结果:</p><pre class="lc ld le lf gt ng nh ni nj aw nk bi"><span id="6328" class="lz ma iq nh b gy nl nm l nn no">Training accuracy: 100.0%<br/>Validation accuracy: 89.82%<br/><br/>Bias: 0.0%<br/>Variance: 10.18%</span></pre><p id="2a78" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如你所看到的，我们已经成功地减少了模型的偏差。事实上，我们已经完全消除了它，但是，现在方差增加了。这种状态俗称<strong class="kh ir">过拟合</strong>。</p><p id="90b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">减少模型方差的<strong class="kh ir">方法有:</strong></p><blockquote class="mx my mz"><p id="f558" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">减小模型的尺寸</p><p id="cf1a" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">减少功能数量</p><p id="3727" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">添加正则化</p><p id="4e43" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">添加更多数据</p></blockquote><h2 id="750a" class="lz ma iq bd mb mc md dn me mf mg dp mh ko mi mj mk ks ml mm mn kw mo mp mq mr bi translated">场景#3:低偏差、低方差</h2><p id="cce2" class="pw-post-body-paragraph kf kg iq kh b ki ms jr kk kl mt ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">让我们这次尝试通过引入一些正则化来减少方差。</p><p id="54fc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我以Dropout(训练时随机忽略一组神经元)的形式将正则化添加到每一层。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="26ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们新模型的结果是:</p><pre class="lc ld le lf gt ng nh ni nj aw nk bi"><span id="315f" class="lz ma iq nh b gy nl nm l nn no">Training accuracy: 98.62%<br/>Validation accuracy: 95.16%<br/><br/>Bias: 1.38%<br/>Variance: 3.46%</span></pre><p id="1a34" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完美！我们现在非常接近一个<strong class="kh ir">最优状态</strong>，具有相对较低的偏差和相对较低的方差，这正是我们的目标。如果我们现在看看我们的验证误差(1-验证准确性或偏差+方差)，这是迄今为止最低的。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="812f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">也许你已经注意到，在最后一个场景中，与场景#2相比，偏差又增加了一点。你也可以看到减少偏差和减少方差的方法是完全相反的。这种特性称为<strong class="kh ir">偏差-方差权衡</strong>，如下图所示:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi np"><img src="../Images/bc8f0d72dcedc64a345988062f9afa8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*6yL1UO48otEI3N1zRQ2RQw.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">偏差-方差权衡|作者图片</p></figure><blockquote class="mx my mz"><p id="6b7f" class="kf kg na kh b ki kj jr kk kl km ju kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">基本上，我们试图找到偏差和方差之间的平衡，即<strong class="kh ir">最小化总误差</strong>。</p></blockquote></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="2982" class="lz ma iq bd mb mc md dn me mf mg dp mh ko mi mj mk ks ml mm mn kw mo mp mq mr bi translated">结论</h2><p id="7277" class="pw-post-body-paragraph kf kg iq kh b ki ms jr kk kl mt ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">我们经历了基于偏差和方差调整模型的3种不同场景，以及可以采取的相应步骤。</p><p id="bb4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可能存在第四种情况，即<strong class="kh ir">高偏置</strong>和<strong class="kh ir">高方差</strong>，这还没有被涵盖。然而，这通常意味着你的数据有问题(训练和验证分布不匹配，噪音数据等。)，因此，很难给你一个确切的指导方针。</p><p id="6731" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望这种方法能帮助你在项目中区分任务的优先级，并最终为你节省一些时间。</p><p id="0031" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我用的所有代码都可以在<a class="ae lr" href="https://github.com/sebastianpoliak/Bias-and-Variance-Medium-Post" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</p><p id="7886" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">灵感来自吴恩达对机器学习的向往。</p><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/how-much-time-can-you-save-with-active-learning-b4886f5da462"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd ir gy z fp ny fr fs nz fu fw ip bi translated">主动学习能节省多少时间？</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">在NLP数据集上的动手实验。</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh ll nt"/></div></div></a></div><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/zero-shot-learning-the-alphabetic-characters-an-experiment-with-code-d1a0f23f4b4c"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd ir gy z fp ny fr fs nz fu fw ip bi translated">零射击学习字母字符(代码实验)</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">是否有可能识别培训中未提供的字母字符？</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="oi l oe of og oc oh ll nt"/></div></div></a></div></div></div>    
</body>
</html>