<html>
<head>
<title>A Practical Guide to Stacking Using Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scikit-Learn进行堆叠的实用指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-guide-to-stacking-using-scikit-learn-91e8d021863d?source=collection_archive---------10-----------------------#2020-11-15">https://towardsdatascience.com/a-practical-guide-to-stacking-using-scikit-learn-91e8d021863d?source=collection_archive---------10-----------------------#2020-11-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8895" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用堆叠构建更健壮的模型？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0887d562d49308230456316e7c605e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_SPS88Pn84YlrwnTaTBxQA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">格雷格·罗森克在<a class="ae ky" href="https://unsplash.com/s/photos/stacked?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="d0fa" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="19d3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在过去的20年中，集成方法，如随机森林和梯度推进，这些<strong class="lt iu">使用投票或加权平均结合相同类型模型的几个实例来产生强模型</strong>，已经变得非常流行。然而，还有另一种方法可以让我们<strong class="lt iu">通过使用更高层次的模型</strong>将它们各自的预测结合起来，从而获得不同模型的好处。</p><p id="4c77" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">堆叠概括，也称为堆叠，是一种训练元模型以智能地组合不同基础模型的预测的方法。</p><p id="8a4c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">本文的目标不仅是解释这种赢得竞争的技术是如何工作的，而且还展示了如何用Scikit-learn中的几行代码来实现它。</strong></p><h1 id="dafa" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">堆叠的工作原理</h1><p id="abbd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">由于模型背后的假设所产生的偏见，每个机器学习模型都有优点和缺点。这是我在上一篇关于有监督机器学习的“没有免费的午餐”定理的帖子中提到的一个概念。</p><div class="ms mt gp gr mu mv"><a rel="noopener follow" target="_blank" href="/what-no-free-lunch-really-means-in-machine-learning-85493215625d"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">“没有免费的午餐”在机器学习中真正意味着什么</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">揭开这个经常被误解的定理。</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj ks mv"/></div></div></a></div><p id="3bae" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">不同的机器学习算法可能擅长以不同的方式解决问题。如果我们有多个算法一起工作来解决一个问题，一个算法的优点可能会掩盖另一个算法的缺点，反之亦然。这就是堆叠背后的想法。</p><p id="ce11" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">堆叠包括训练多个<strong class="lt iu">基础模型</strong>来预测机器学习问题中的目标变量，同时<strong class="lt iu">元模型</strong>学习<strong class="lt iu"> </strong>来使用<strong class="lt iu"> </strong>每个基础模型的预测来预测目标变量的值。下图展示了这一想法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/ae0527233cc1b9fb22cd74cd09416339.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3LgG3geyPppu52SwZ4b5kQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">堆叠模型的蓝图。图片由作者提供。</p></figure><p id="2792" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">正确训练堆叠模型的算法遵循以下步骤:</p><ol class=""><li id="aa6c" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm nq nr ns nt bi translated"><strong class="lt iu">将数据拆分成<em class="nu">k</em>-折叠就像在<em class="nu">k</em>-折叠</strong> <a class="ae ky" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">交叉验证</strong> </a> <strong class="lt iu">。</strong></li><li id="9bc9" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm nq nr ns nt bi translated"><strong class="lt iu">选择一个折叠进行验证，剩余的<em class="nu"> k-1 </em>折叠进行训练。</strong></li><li id="e616" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm nq nr ns nt bi translated"><strong class="lt iu">在训练集上训练基础模型，在验证集上生成预测。</strong></li><li id="0bab" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm nq nr ns nt bi translated"><strong class="lt iu">对剩余的<em class="nu"> k-1 </em>褶皱重复步骤2-3，并创建一个扩充数据集，将每个基础模型的预测作为附加特征包括在内。</strong></li><li id="177d" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm nq nr ns nt bi translated"><strong class="lt iu">在扩充数据集上训练最终元模型。</strong></li></ol><p id="da02" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请注意，模型的每个部分都是单独训练的，元模型学习使用基础模型的预测和原始数据来预测最终输出。</p><p id="518b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于那些不熟悉<em class="nu"> k </em>折叠交叉验证的人来说，这是一种将机器学习问题的数据分成<em class="nu"> k </em>折叠或不同子集，并在所有<em class="nu"> k </em>折叠中迭代评估模型的技术。在每一次迭代中，一个折叠用于评估，剩余的<em class="nu"> k-1 </em>折叠用于训练模型。</p><p id="79ec" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用一个<em class="nu"> k </em>倍交叉验证分割确保了基础模型在看不见的数据上生成预测，因为基础模型将在每次迭代中在不同的训练集上被重新训练。</p><p id="a73f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">堆叠的力量在于最后一步，在这一步中<strong class="lt iu">元模型实际上可以学习每个基础模型的优缺点，并智能地组合它们的预测，以产生最终的输出</strong>。</p><h1 id="cf36" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">使用Scikit-Learn的实际示例</h1><p id="b985" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Scikit-learn 0.22中引入了<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html" rel="noopener ugc nofollow" target="_blank"> StackingClassifier </a>和<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html#sklearn.ensemble.StackingRegressor" rel="noopener ugc nofollow" target="_blank"> StackingRegressor </a>模块。因此，请务必升级到Scikit的最新版本——学习使用下面的pip命令来完成这个示例:</p><p id="e040" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe oa ob oc od b">pip install --upgrade scikit-learn</code></p><h2 id="be69" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">导入基本库</h2><p id="273a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我在下面导入的大多数基本库都是数据科学项目中常用的，应该不会感到意外。然而，我也使用了Scikit-learn中的<strong class="lt iu"> make_classification </strong>函数来生成一些合成数据，并且我还使用了<strong class="lt iu"> Plotly </strong>来构建交互图。为了嵌入互动的情节，我还使用了<strong class="lt iu">数据面板</strong>。</p><pre class="kj kk kl km gt oq od or os aw ot bi"><span id="0b65" class="oe la it od b gy ou ov l ow ox">import numpy as np <br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>from sklearn.datasets import make_classification<br/>import plotly.graph_objects as go<br/>import datapane as dp<br/>%matplotlib inline</span></pre><h2 id="ea0d" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">生成数据集</h2><p id="bd9b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Scikit-learn的<strong class="lt iu"> make_classification </strong>函数对于生成可用于测试不同算法的合成数据集非常有用。我在此场景中生成的数据集旨在基于以下参数，以实际难度表示二元分类问题:</p><ul class=""><li id="11ca" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm oy nr ns nt bi translated"><strong class="lt iu"> n_features — </strong>数据集中的要素数量，我将其设置为20。</li><li id="0814" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm oy nr ns nt bi translated"><strong class="lt iu">n _信息和n _冗余— </strong>数据集中信息和冗余要素的数量。我加入了五个多余的特性来增加问题的难度。</li><li id="36e6" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm oy nr ns nt bi translated"><strong class="lt iu"> n_clusters_per_class </strong> —每个类中包含的聚类数。较高的值会使问题更加困难，所以我将这个值设置为五个集群。</li><li id="819b" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm oy nr ns nt bi translated"><strong class="lt iu"> class_sep </strong> —控制簇/类之间的分离。较大的值使任务更容易，所以我选择了一个低于默认值1.0的值0.7。</li><li id="20ec" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm oy nr ns nt bi translated"><strong class="lt iu"> flip_y </strong> —指定将被随机分配的分类标签的百分比。我将该值设置为0.03，以便向数据集添加一些噪声。</li></ul><pre class="kj kk kl km gt oq od or os aw ot bi"><span id="da61" class="oe la it od b gy ou ov l ow ox">X, y = make_classification(n_samples=50000, <br/>                           n_features=20, <br/>                           n_informative=15, <br/>                           n_redundant=5,<br/>                           n_clusters_per_class=5,<br/>                           class_sep=0.7,<br/>                           flip_y=0.03,<br/>                           n_classes=2)</span></pre><h2 id="18a9" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">培训和评估单个模型</h2><p id="3b5f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了获得与堆叠模型进行比较的基准性能水平，我对以下基本模型进行了培训和评估:</p><ul class=""><li id="36b8" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm oy nr ns nt bi translated"><strong class="lt iu">有50棵决策树的随机森林</strong></li><li id="1e6f" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm oy nr ns nt bi translated"><strong class="lt iu">支持向量机(SVM) </strong></li><li id="4bd5" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm oy nr ns nt bi translated"><strong class="lt iu">K-最近邻(KNN)分类器</strong></li></ul><p id="9a6e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了代码的可重用性，模型都存储在一个字典中。</p><pre class="kj kk kl km gt oq od or os aw ot bi"><span id="939d" class="oe la it od b gy ou ov l ow ox">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.svm import SVC<br/>from sklearn.neighbors import KNeighborsClassifierfrom sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold<br/>from collections import defaultdict</span><span id="c398" class="oe la it od b gy oz ov l ow ox">models_dict = {'random_forest':     RandomForestClassifier(n_estimators=50),<br/>               'svm': SVC(),<br/>               'knn': KNeighborsClassifier(n_neighbors=11)}</span></pre><p id="5175" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">每个模型都使用重复的五重交叉验证策略进行验证，其中每个折叠都使用不同的随机样本集进行重复。在每一次折叠中，每个模型用80%的数据进行训练，用剩下的20%进行验证。</p><p id="e022" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该方法为每个模型产生10个不同的准确度分数，这些分数存储在字典中，如下所示。</p><pre class="kj kk kl km gt oq od or os aw ot bi"><span id="4121" class="oe la it od b gy ou ov l ow ox">def evaluate_model(model, X, y):<br/>    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)<br/>    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, verbose=1, n_jobs=3, error_score='raise')<br/>    return scores</span><span id="aafe" class="oe la it od b gy oz ov l ow ox">model_scores = defaultdict()</span><span id="46c3" class="oe la it od b gy oz ov l ow ox">for name, model in models_dict.items():<br/>    print('Evaluating {}'.format(name))<br/>    scores = evaluate_model(model, X, y)<br/>    model_scores[name] = scores</span></pre><h2 id="dee3" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">可视化单个模型的结果</h2><p id="9d9c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下面定义的函数获取所有评估模型的交叉验证分数字典，并使用Plotly创建一个交互式箱线图，以比较每个模型的性能。正如我在本文中所做的，这个函数还创建了一个数据面板报告来嵌入这些图。</p><pre class="kj kk kl km gt oq od or os aw ot bi"><span id="d63b" class="oe la it od b gy ou ov l ow ox">def plot_results(model_scores, name):<br/>    <br/>    model_names = list(model_scores.keys())<br/>    results = [model_scores[model] for model in model_names]<br/>    fig = go.Figure()<br/>    for model, result in zip(model_names, results):<br/>        fig.add_trace(go.Box(<br/>            y=result,<br/>            name=model,<br/>            boxpoints='all',<br/>            jitter=0.5,<br/>            whiskerwidth=0.2,<br/>            marker_size=2,<br/>            line_width=1)<br/>        )<br/>    <br/>    fig.update_layout(<br/>    title='Performance of Different Models Using 5-Fold Cross-Validation',<br/>    paper_bgcolor='rgb(243, 243, 243)',<br/>    plot_bgcolor='rgb(243, 243, 243)',<br/>    xaxis_title='Model',<br/>    yaxis_title='Accuracy',<br/>    showlegend=False)<br/>    fig.show()<br/>    <br/>    report = dp.Report(dp.Plot(fig) ) #Create a report<br/>    report.publish(name=name, open=True, visibility='PUBLIC') </span><span id="9efd" class="oe la it od b gy oz ov l ow ox">plot_results(model_scores, name='base_models_cv')</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pa pb l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">三种基本型号的性能比较。</p></figure><p id="586f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">根据上面的箱线图，我们可以看到所有基本模型的平均准确率都超过了87%，但支持向量机的平均表现最好。令人惊讶的是，一个简单的KNN分类器，通常被描述为“懒惰学习算法”，因为它只记住训练数据，明显优于有50个决策树的随机森林。</p><h2 id="75ab" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">定义堆叠模型</h2><p id="ecf3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在让我们看看如果我们训练一个堆叠模型会发生什么。Scikit-learn的StackingClassifier有一个构造函数，它需要一个基本模型列表，以及产生最终输出的最终元模型。请注意，在下面的代码中，这个基本模型的列表被格式化为带有模型名称和模型实例的元组列表。</p><p id="5016" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">堆叠模型使用随机森林、SVM和KNN分类器作为基础模型，使用逻辑回归模型作为元模型，使用基础模型的数据和预测来预测输出。下面的代码演示了如何用Scikit-learn创建这个模型。</p><pre class="kj kk kl km gt oq od or os aw ot bi"><span id="bd75" class="oe la it od b gy ou ov l ow ox">from sklearn.ensemble import StackingClassifier<br/>from sklearn.neural_network import MLPClassifier<br/>from sklearn.linear_model import LogisticRegressionCV</span><span id="0b5c" class="oe la it od b gy oz ov l ow ox">base_models = [('random_forest', RandomForestClassifier(n_estimators=50)),<br/>               ('svm', SVC()),<br/>               ('knn', KNeighborsClassifier(n_neighbors=11))]<br/>meta_model = LogisticRegressionCV()<br/>stacking_model = StackingClassifier(estimators=base_models, <br/>                                    final_estimator=meta_model, <br/>                                    passthrough=True, <br/>                                    cv=5,<br/>                                    verbose=2)</span></pre><h2 id="6277" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">评估堆叠模型</h2><p id="9fcc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在下面的代码中，我简单地重用了我之前定义的函数来获取模型的交叉验证分数，并使用它来评估堆叠模型。</p><pre class="kj kk kl km gt oq od or os aw ot bi"><span id="692f" class="oe la it od b gy ou ov l ow ox">stacking_scores = evaluate_model(stacking_model, X, y)<br/>model_scores['stacking'] = stacking_scores</span></pre><h2 id="0508" class="oe la it bd lb of og dn lf oh oi dp lj ma oj ok ll me ol om ln mi on oo lp op bi translated">可视化和比较结果</h2><p id="9815" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我重用了前面定义的绘图函数，使用并排箱线图来比较基本模型和堆叠模型的性能。</p><pre class="kj kk kl km gt oq od or os aw ot bi"><span id="7158" class="oe la it od b gy ou ov l ow ox">plot_results(model_scores, name='stacking_model_cv')</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="af24" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">根据上面的图，我们可以清楚地看到堆叠带来了性能的提高，其中<strong class="lt iu">堆叠模型优于所有基本模型，并且实现了接近91%的中值精度</strong>。使用Scikit-learn的<strong class="lt iu"> StackingRegressor </strong>模块，可以对回归问题重复同样的过程，其行为方式类似。</p><h1 id="f161" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">堆叠的优点和缺点</h1><p id="3125" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">像机器学习中的所有其他方法一样，堆叠有优点也有缺点。以下是堆叠的一些优势:</p><ul class=""><li id="d10f" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm oy nr ns nt bi translated"><strong class="lt iu">叠加可以提高模型的性能。</strong></li><li id="01a9" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm oy nr ns nt bi translated"><strong class="lt iu">叠加通过组合多个模型的预测来减少方差并创建更稳健的模型。</strong></li></ul><p id="d1f6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请记住，堆叠也有以下缺点:</p><ul class=""><li id="3f88" class="nl nm it lt b lu mn lx mo ma nn me no mi np mm oy nr ns nt bi translated"><strong class="lt iu">与简单模型相比，堆叠模型的训练时间要长得多，并且需要更多内存。</strong></li><li id="c48f" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm oy nr ns nt bi translated"><strong class="lt iu">使用堆叠模型生成预测通常会更慢，计算成本也更高。如果您计划将堆叠模型部署到产品中，那么考虑这个缺点是很重要的。</strong></li></ul><h1 id="270a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">摘要</h1><p id="9eae" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">叠加是一种很好的方式，通过结合不同模型的预测来利用它们的优势。这种方法已经被用来赢得机器学习比赛，由于Scikit-learn，它非常容易实现。然而，堆栈带来的性能提高是以更长的训练和推理时间为代价的。</p><p id="a504" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您可以在<a class="ae ky" href="https://github.com/AmolMavuduru/GuideToStacking" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到用于实际示例的完整代码。如果你喜欢这篇文章，请随意看看我最近写的一些关于机器学习的文章。</p><div class="ms mt gp gr mu mv"><a rel="noopener follow" target="_blank" href="/what-no-free-lunch-really-means-in-machine-learning-85493215625d"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">“没有免费的午餐”在机器学习中真正意味着什么</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">揭开这个经常被误解的定理。</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj ks mv"/></div></div></a></div><div class="ms mt gp gr mu mv"><a rel="noopener follow" target="_blank" href="/why-xgboost-cant-solve-all-your-problems-b5003a62d12a"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">为什么XGBoost不能解决你所有的问题。</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">XGBoost和其他基于树的算法的一个关键限制。</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="pc l ng nh ni ne nj ks mv"/></div></div></a></div><div class="ms mt gp gr mu mv"><a rel="noopener follow" target="_blank" href="/fake-news-classification-with-recurrent-convolutional-neural-networks-4a081ff69f1a"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">基于递归卷积神经网络的假新闻分类</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">介绍</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">towardsdatascience.com</p></div></div><div class="ne l"><div class="pd l ng nh ni ne nj ks mv"/></div></div></a></div><h1 id="a2e3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">来源</h1><ol class=""><li id="3b69" class="nl nm it lt b lu lv lx ly ma pe me pf mi pg mm nq nr ns nt bi translated">D.H. Wolpert，<a class="ae ky" href="http://www.cs.utsa.edu/~bylander/cs6243/wolpert92stacked.pdf" rel="noopener ugc nofollow" target="_blank"/>，(1992)，神经网络<em class="nu">。</em></li><li id="1569" class="nl nm it lt b lu nv lx nw ma nx me ny mi nz mm nq nr ns nt bi translated">F.佩德雷戈萨<em class="nu">等，</em><a class="ae ky" href="http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html" rel="noopener ugc nofollow" target="_blank">sci kit-learn:Python中的机器学习</a>，(2011)，机器学习研究杂志。</li></ol></div></div>    
</body>
</html>