<html>
<head>
<title>What if multiple receptive fields are used for Image Inpainting?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如果使用多个感受野进行图像修复会怎样？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9?source=collection_archive---------35-----------------------#2020-11-06">https://towardsdatascience.com/what-if-multiple-receptive-fields-are-used-for-image-inpainting-ea44003ea7e9?source=collection_archive---------35-----------------------#2020-11-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d705" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">综述:基于生成多列卷积神经网络的图像修复</h2></div><p id="753a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">大家好。好久不见！今天，我们将讨论另一篇名为“通过生成式多列CNN(GM CNN)进行图像修复”的修复论文。本文使用的网络架构类似于我们在之前介绍过的那些论文<a class="ae lb" rel="noopener" target="_blank" href="/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0">。本文的主要贡献是对损失函数的一些修正。</a></p><h1 id="a103" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">简短回忆</h1><p id="e06f" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">正如我在<a class="ae lb" rel="noopener" target="_blank" href="/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0">之前的文章</a>中提到的，如何利用图像中剩余像素给出的信息对于高质量的图像修复至关重要。图像修复的一个非常直接的意义是直接复制图像本身中找到的最相似的图像补丁，并粘贴在缺失的区域上。有趣的是，我们应该认识到<strong class="kh ir"> <em class="lz">对于实践中的缺失区域</em> </strong>并没有“正确”的答案。在现实中，给定一个损坏/屏蔽的图像，您无法知道原始图像(地面真相)进行比较。于是，我们就有了这么<strong class="kh ir"> <em class="lz">许多答案中缺失的领域</em> </strong>。</p><h1 id="1f17" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">简介和动机</h1><p id="31ad" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">从以前的修复论文中，我们知道感受野对于图像修复是非常重要的。对于一个3×3的核，我们可以通过<strong class="kh ir"> <em class="lz">调整扩张率来控制它的</em> </strong>感受野。如果扩张率是1，我们就有一个3×3的感受野。如果扩张率是2，我们通过跳过一个相邻像素得到一个5×5的感受野，依此类推。你可以参考我以前的帖子来了解更多的细节。这里，<strong class="kh ir"> <em class="lz">如果我们采用3×3、5×5和7×7个具有扩展卷积的内核会怎么样？本文将其定义为多栏式结构。</em>T19】</strong></p><p id="f937" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我之前的<a class="ae lb" rel="noopener" target="_blank" href="/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0">关于上下文注意力层的帖子</a>中，搜索与缺失区域最相似的图像补片的过程被嵌入到生成器网络中(即，这个过程被用在训练和测试阶段)。在这项工作中，这一过程仅通过设计一个新的损失项在训练中使用。</p><p id="e8b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于对缺失区域没有“正确”答案的事实，逐像素重建精度损失项(即<em class="lz"> L </em> 1损失)似乎不适用于图像修复。作者提出<strong class="kh ir"> <em class="lz">基于丢失像素的空间位置对L1损失项进行加权。</em> </strong>靠近有效(剩余)像素的空间位置对于<em class="lz"> L </em> 1损失应该具有更高的权重，因为它们对于重建具有更合理的参考，反之亦然。</p><h1 id="78a5" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">解决方案(简而言之)和贡献</h1><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ma"><img src="../Images/89c6985b4391f826d5720f9f54352b98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*khibFpGzhICpdvWppiEqAQ.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图一。该方法给出了一些修复结果。图片来自王怡等人的<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a> [1]</p></figure><p id="7214" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我看来，这篇论文遵循了我们之前讨论过的图像修复的趋势。首先，作者采用了具有扩张卷积的多分支细胞神经网络，而不是单分支细胞神经网络。<strong class="kh ir"> <em class="lz">在三个不同的分支中使用三种不同的核大小，用于实现不同的感受野和提取不同分辨率的特征。</em>T13】</strong></p><p id="5294" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其次，<strong class="kh ir"> <em class="lz">引入两个新的损失项来训练网络</em> </strong>，即置信度驱动的重建损失和隐式多样化马尔可夫随机场(ID-MRF)损失。置信度驱动的重建损失是加权的<em class="lz"> L </em> 1损失，而ID-MRF损失与由预先训练的VGG网络计算的特征块比较相关。我们已经谈到了MRF的损失。你可以参考它来简单回忆一下。</p><p id="d8bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图1显示了所提出的方法的一些修复结果。您可以放大以更好地查看这些高质量的结果。</p><h1 id="f18f" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">方法</h1><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mq"><img src="../Images/8af916d616873cb704220dc767c99e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D2NjVHEoYwaZ4yybDSkhiw.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图二。提议的网络架构。图片来自王怡等人的<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a> [1]</p></figure><p id="22ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图2显示了提出的生成多列卷积神经网络(GMCNN)的网络架构。如您所见，有一个多列发生器网络、两个鉴别器(全局和局部)和一个用于计算ID-MRF损耗的预训练VGG19。</p><p id="8c8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lz">发电机网络中有三列，每列使用三种不同尺寸</em> </strong>的滤波器，即3×3、5×5和7×7。请注意，这三列的输出被连接起来，馈入另外两个卷积层，以获得完整的图像。</p><h1 id="3513" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">一维MRF正则化</h1><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mr"><img src="../Images/f0ff39f96bba346fdd16528328997fb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TN9hAr31ZEDczfgKn-lkwQ.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图3。使用不同的相似性度量搜索最近的邻居来修复结果。(a)使用余弦相似性的修补结果;( b)使用建议的相对相似性的修补结果;( c)地面真实图像(红色矩形突出显示填充区域)。图片来自王怡等人的<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a> [1]</p></figure><p id="06cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简单地说，对于MRF目标，我们希望<strong class="kh ir"> <em class="lz">最小化生成的特征和由预训练网络</em> </strong>计算的地面真实值的最近邻特征之间的差异。在大多数以前的工作中，余弦相似性度量被用来搜索最近的邻居(你可以阅读我以前的帖子[ <a class="ae lb" rel="noopener" target="_blank" href="/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0">这里</a> ]来回顾余弦相似性度量)。然而，这种相似性度量通常为不同的生成特征补丁提供相同的最近邻，并导致模糊的修复结果，如图3(a)所示。</p><p id="f30b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了避免使用余弦相似性度量可能导致的模糊完整图像，作者采用了相对距离度量，修复结果如图3(b)所示。你可以看到完成的图像具有更好的局部精细纹理。</p><p id="8bf4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来谈谈他们是如何进行相对距离测量的。设<strong class="kh ir"> Y </strong> (hat)_ <em class="lz"> g </em>为缺失区域的生成内容，<strong class="kh ir">y</strong>(hat)^<em class="lz">l</em>_<em class="lz">g</em>和<strong class="kh ir"> Y </strong> ^ <em class="lz"> L </em>为预训练网络第<em class="lz"> L </em>层的特征。对于分别从<strong class="kh ir">y</strong>(hat)^<em class="lz">l</em>_<em class="lz">g</em>和<strong class="kh ir"> Y </strong> ^ <em class="lz"> L </em>中提取的特征面片<strong class="kh ir"> v </strong>和<strong class="kh ir"> s </strong>，计算从<strong class="kh ir"> v </strong>到<strong class="kh ir"> s </strong>的相对相似度，</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ms"><img src="../Images/afc125b7ac1b57bc496c6908d9d38ea2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lRdnSJmZutsq0jWqkFVINw.png"/></div></div></figure><p id="be60" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="lz"> mu </em>(。, .)是余弦相似度。<strong class="kh ir"> r </strong>属于<strong class="kh ir"> Y </strong> ^ <em class="lz"> L </em>不包括<strong class="kh ir"> v </strong>。<em class="lz"> h </em>和<em class="lz">ε</em>为正常数。显然，如果<strong class="kh ir"> v </strong>比其他特征面片与<strong class="kh ir"> s </strong>更相似，RS( <strong class="kh ir"> v </strong>，<strong class="kh ir"> s </strong>)就会大。你也可以考虑一下，如果<strong class="kh ir"> v </strong>有两个相似的补丁<strong class="kh ir"> s </strong>和<strong class="kh ir"> r </strong>，那么RS( <strong class="kh ir"> v </strong>，<strong class="kh ir"> s </strong>)就会小。我们鼓励在缺失区域之外找到类似的补丁。</p><p id="bc63" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，RS归一化如下。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mt"><img src="../Images/7425288ce826e30facdcf8d24dc4fd60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T7DxTQF7yJ4mylt-n34QTg.png"/></div></div></figure><p id="bf65" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，计算出<strong class="kh ir">y</strong>(hat)^<em class="lz">l</em>_<em class="lz">g</em>和<strong class="kh ir"> Y </strong> ^ <em class="lz"> L </em>之间的建议ID-MRF损耗。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mu"><img src="../Images/20bc6cc5b57b7edff11b1f9e8008cd69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a-NF5UbUTi5sFJO3zwTAtA.png"/></div></div></figure><p id="743f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中参数max RS(bar)( <strong class="kh ir"> v </strong>，<strong class="kh ir"> s </strong>)表示<strong class="kh ir"> s </strong>是<strong class="kh ir"> v </strong>的最近邻，而<em class="lz"> Z </em>是归一化因子。如果我们考虑所有生成的特征片都接近特定特征片<strong class="kh ir"> s </strong>的极端情况，那么max RS(bar) ( <strong class="kh ir"> v </strong>，<strong class="kh ir"> r </strong>)将会很小，因此ID-MRF损失将会很大。</p><p id="9b12" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一方面，如果<strong class="kh ir"> Y </strong> ^ <em class="lz"> L </em>中的每个<strong class="kh ir"> r </strong>在<strong class="kh ir">y</strong>(hat)^<em class="lz">l</em>_<em class="lz">g</em>中有自己的最近邻居，那么最大RS(bar) ( <strong class="kh ir"> v </strong>，<strong class="kh ir"> r </strong>)将会很大，因此ID-MRF损失将会很大这里，<strong class="kh ir"> <em class="lz">的主要思想是强制/引导生成的特征面片具有不同的最近邻，从而生成的特征具有更好的局部纹理</em> </strong>。</p><p id="161b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与<a class="ae lb" href="https://medium.com/analytics-vidhya/review-high-resolution-image-inpainting-using-multi-scale-neural-patch-synthesis-4bbda21aa5bc" rel="noopener">之前的工作</a>相同，作者使用预训练的VGG19来计算ID-MRF损耗。注意，中间层<em class="lz"> conv </em> 3_2和<em class="lz"> conv </em> 4_2分别代表结构和语义特征。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mv"><img src="../Images/e891ab2a933961995126a5e4de2d8d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2IP2HItdiC0jeggqWigq_A.png"/></div></div></figure><p id="008b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者声称，这种损失与最近邻搜索有关，并且仅在训练阶段使用。这不同于在测试阶段搜索最近邻居的方法。</p><h1 id="f966" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">空间变化重建损失</h1><p id="cdca" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">所提出的空间变量重建损失实际上是加权的<em class="lz"> L </em> 1损失。有许多方法来决定权重，作者使用高斯滤波器来卷积掩模以创建加权掩模，用于计算加权的<em class="lz"> L </em> 1损失。感兴趣的读者可以参考<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">的论文</a>了解详情。加权<em class="lz"> L </em> 1损失的主要思想是靠近有效像素的缺失像素比远离有效像素的缺失像素受到更高的约束。因此，位于缺失区域中心的缺失像素应该具有较低的<em class="lz"> L </em> 1损失权重(即较少约束)。</p><h1 id="0b83" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">对抗性损失</h1><p id="8416" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">与<a class="ae lb" rel="noopener" target="_blank" href="/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0">之前的工作</a>类似，作者采用了改进的WGAN损失以及局部和全局鉴别器。再次强烈推荐感兴趣的读者阅读<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>。</p><h1 id="e838" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">最终损失函数</h1><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mw"><img src="../Images/15e4f8312039d66b3f6c7f724b349086.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YA_rLr45ZqQcNWW_Of8XRw.png"/></div></div></figure><p id="6024" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是用于训练建议模型的最终损失函数。类似于大多数修复纸，加权的<em class="lz"> L </em> 1损失(第一损失项)的重要性是1。<em class="lz">λ</em>_<em class="lz">mrf</em>和<em class="lz">λ</em>_<em class="lz">adv</em>是控制局部纹理MRF正则化和对抗性训练的重要性的参数。</p><h1 id="d685" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">实验</h1><p id="8ab6" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">作者在5个公共数据集上评估了他们的方法，即Paris StreetView，Places2，ImageNet，CelebA和CelebA-HQ数据集。在训练过程中，所有图像的大小都调整为256×256，最大的中心孔大小为128×128。供你参考，他们的发电机网络有12.562米的参数。在GPU上测试256×256和512×512大小的图像，每幅图像分别需要49.37 ms和146.11 ms。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mx"><img src="../Images/5be42ce8e66d27d53c1b08f25b27af2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xEZ-j7JUASli8ig4hJxj4Q.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图4。巴黎街景(上)和ImageNet(下)的定性比较。(a)输入图像(b)上下文编码器(c) MSNPS (d)上下文注意(e)建议方法。图片来自王怡等人的论文</p></figure><p id="4108" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图4显示了巴黎街景和ImageNet数据集的定性比较。请放大以更好地查看修复结果。显然，所提出的方法GMCNN给出了具有最佳视觉质量的修复结果。如果你对更多的修复结果感兴趣，请参考<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>或他们的项目网站。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi my"><img src="../Images/42215e07cf6adbdb20dd6b72ddc29f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zAkvhl96VcD1p8BQ3-v1Yw.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">表1。五个数据集的定量结果。王怡等人的数据来自他们的<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a> [1]</p></figure><p id="25f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我以前的帖子和这篇帖子开头提到的，<strong class="kh ir"> <em class="lz"> PSNR与像素重建精度有关，可能不适合评估图像修复</em> </strong>。研究人员仍然报告PSNR和SSIM供读者参考，因为这些数字指标是所有图像处理任务的基础。如表1所示，所提出的方法在五个数据集上实现了相当甚至更好的PSNR和SSIM。</p><h1 id="116f" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">消融研究</h1><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mz"><img src="../Images/6e78ec9d9e606604ef99b54ddbd84301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vrsgz2eLwKZHiyXa9bcLWg.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">表二。巴黎街景数据集上不同网络结构的定量结果。王怡等人的数据来自他们的论文</p></figure><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi na"><img src="../Images/e729c3b242adba8a7837a0a9c158e2d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9edmt18ZykOyXMkvXIAq8g.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图5。巴黎街景数据集上不同网络结构的定性比较。(a)输入图像(b)单个编码器-解码器(c)粗到细(d)在所有3个分支中具有固定感受野的GMCNN(e)具有变化感受野的GM CNN。图片来自王怡等人的<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a> [1]</p></figure><p id="a1e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者评估了图像修复任务中使用的不同网络结构的性能。我们已经介绍了<a class="ae lb" rel="noopener" target="_blank" href="/a-milestone-in-deep-image-inpainting-review-globally-and-locally-consistent-image-completion-505413c300df">编码器-解码器结构</a>和<a class="ae lb" rel="noopener" target="_blank" href="/a-breakthrough-in-deep-image-inpainting-review-generative-image-inpainting-with-contextual-1099c195f3f0">粗到细结构</a>。对于他们实验中由粗到细的结构，没有使用上下文注意。对于在所有3个分支中具有固定感受野的GMCNN，他们使用5×5大小的滤波器。对于具有不同感受野的GMCNN，在3个分支中分别使用3×3、5×5和7×7滤波器。定量和定性结果分别见表2和图5。显然，具有不同感受野的GMCNN提供了最好的修复结果。</p><p id="9394" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了网络结构的选择和多个感受野的使用，作者还研究了两个提出的损失项的有效性，即置信度驱动的重建损失和ID-MRF损失。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nb"><img src="../Images/6fc2944dbbe8f3b4c1304ee7e1ad163e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iWSKsoi6mwKmYu1LKfq_uQ.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图6。巴黎街景数据集上不同重建损失的定性比较。(a)输入图像(b)空间折扣损失(c)建议的置信度驱动的重建损失。图片来自王怡等人的论文</p></figure><p id="0e48" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图6显示了不同重建损失的视觉比较，即空间折扣损失和建议的置信度驱动重建损失。注意，空间折扣损失基于丢失像素的空间位置来获得权重掩模，而提出的置信度驱动的重建损失通过用高斯滤波器多次卷积掩模图像来获得权重掩模。作者声称他们的信心驱动重建损失效果更好。从我自己的经历来看，两次重建损失都差不多。也许你可以试一试。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nc"><img src="../Images/8db37e93d35b8179c97f644c827ada4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*du9rsYWD0sgD5IoNOTdLPw.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">表3。在巴黎街景数据集上使用不同lambda_ <em class="nd"> mrf </em>的量化结果。王怡等人的数据来自他们的<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>【1】</p></figure><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ne"><img src="../Images/ac7c35643d74823ef8d0bafae7352ec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SLiMbIWc8j3FpRYXzwq4qw.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图7。在巴黎街景数据集上是否使用ID-MRF损失的定性比较。(a)输入图像,( b)使用ID-MRF损失的修补结果,( c)不使用ID-MRF损失的修补结果。图片来自王怡等人的<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a> [1]</p></figure><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nf"><img src="../Images/4a52ed43a12910442f9621d58bee46c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dokn9J0MvnCkwiYtY6Uc4g.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图8。在巴黎街景数据集上使用不同lambda_mrf的ID-MRF损失的定性比较。(a)输入图像(b)λ_ MRF = 2(c)λ_ MRF = 0.2(d)λ_ MRF = 0.02(e)λ_ MRF = 0.002。图片来自王怡等人的<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="b76e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更重要的是，ID-MRF损失项是本文最有力的主张。因此，作者显示了这一损失项的重要性，定量结果列于表3。图7显示了使用ID-MRF损失和不使用ID-MRF损失训练的模型之间的差异。我们可以看到，ID-MRF的使用可以增强所生成像素的局部细节。此外，图8显示了使用不同的λ_<em class="lz">MRF</em>来控制ID-MRF损失的重要性的效果。您可以放大以更好地查看结果。个人觉得修复效果差不多。根据表3，lambda_ <em class="lz"> mrf </em> = 0.02在PSNR和视觉质量之间提供了良好的平衡。</p><h1 id="4e2d" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">结论</h1><p id="e29d" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">总之，本文的主要创新点是ID-MRF损失项，以进一步增强生成内容的局部细节。这种丢失的主要思想是引导生成的特征面片在丢失区域之外寻找它们的最近邻作为参考，最近邻应该是多样的，这样可以模拟更多的局部细节。</p><p id="c72c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">多个感受野(多列或多分支)的使用是由于感受野的大小对于图像修补任务很重要。由于局部相邻像素缺失，我们不得不借用远处空间位置给出的信息来填充缺失的像素。我想如果你关注过我之前的帖子，你就不难理解这个想法了。</p><p id="aaa6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用加权的<em class="lz"> L </em> 1损失也是由于缺少区域没有“正确”答案的事实。对于那些更靠近丢失区域边界的丢失像素，它们相对地受到附近有效像素的约束，因此应该给<em class="lz"> L </em> 1损失分配更高的权重。另一方面，对于位于缺失区域中心的缺失像素，它们应该受到较少的<em class="lz"> L </em> 1约束。</p><h1 id="dbef" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">外卖食品</h1><p id="78bc" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">参考我在上面的结论，我希望你能理解提出的ID-MRF损失的含义，因为这是本文的核心思想。对于另外两个观点，即多栏结构和加权的<em class="lz"> L </em> 1损失。实际上，如果你关注过我以前的帖子，我想你可以很好地理解背后的原因。我会说，多重/各种感受野的概念是深度图像修复中的常见做法。</p><p id="fe64" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于加权的<em class="lz"> L </em> 1损失，从我自己的经验来看，我认为并不能带来修复性能的明显提升。当然，实现加权<em class="lz"> L </em> 1损失的方法有很多。如果你对这个感兴趣，你可以试一试。我也会继续做这方面的实验！:)</p><h1 id="ab3c" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">下一步是什么？</h1><p id="3a49" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">在我的下一篇文章中，我将谈论如何处理不规则的口罩。到目前为止，我们已经介绍了几种著名的深度图像修复方法。然而，它们主要集中于规则的掩模(通常是一个大的中心矩形掩模或者有时是多个小的矩形掩模)。所以，我们来看看最近研究人员是如何处理不规则口罩的。</p><p id="d5bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你对图像修复的深度生成模型感兴趣，我强烈推荐你浏览我以前所有的帖子。希望你们喜欢:)</p><h1 id="8b7a" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">参考</h1><p id="617a" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">[1]，，，齐，，沈，贾亚亚，<a class="ae lb" href="https://arxiv.org/pdf/1810.08771.pdf" rel="noopener ugc nofollow" target="_blank">生成多列卷积神经网络图像修复</a>，<em class="lz"> Proc .神经信息处理系统</em>，2018。</p><p id="cdae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">再次感谢你阅读我的帖子！如果您有任何问题，请随时给我发电子邮件或在这里留言。欢迎任何建议。系统学习对我们来说极其重要。非常感谢，下次再见！:)</p></div></div>    
</body>
</html>