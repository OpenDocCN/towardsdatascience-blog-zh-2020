<html>
<head>
<title>Image Restoration with GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于高斯函数的图像恢复</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-gans-877dd689cac1?source=collection_archive---------20-----------------------#2020-10-22">https://towardsdatascience.com/introduction-to-gans-877dd689cac1?source=collection_archive---------20-----------------------#2020-10-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f9bf" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="b334" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">利用生成对抗网络恢复图像质量。</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/f3f25084b8bf4d272888f34d32ff085e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jzoXuyanMQfhu8D7"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@marvelous?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马文·迈耶</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="d64d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">自Goodfellow等人于2014年在<a class="ae le" href="http://papers.nips.cc/paper/5423-generative-adversarial-nets" rel="noopener ugc nofollow" target="_blank"> NIPS </a>推出以来，GANs(生成对抗网络)已经在深度学习和计算机视觉领域掀起了风暴。GANs的主要思想是同时训练两个模型；一个生成器模型<strong class="lh ja"> <em class="mb"> G </em> </strong>捕获某一数据分布，另一个鉴别器模型<strong class="lh ja"> <em class="mb"> D </em> </strong>确定样本是来自原始分布还是来自<strong class="lh ja"> <em class="mb"> G </em> </strong>。</p><p id="2126" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">GAN框架就像一个两人的最小最大游戏。<strong class="lh ja"> <em class="mb"> G </em> </strong>不断改进，生成更逼真、质量更好的图像。<strong class="lh ja"> <em class="mb"> D </em> </strong>提高了确定图像是否由<strong class="lh ja"> <em class="mb"> G </em> </strong>创建的能力。训练GAN可以完全通过反向传播来完成，这极大地简化了训练过程。通常，通过从<strong class="lh ja"> <em class="mb"> G </em> </strong>到<strong class="lh ja"> <em class="mb"> D </em> </strong>的定期切换来执行训练，以防止两个模型中的巨大性能差距。</p><h1 id="f08e" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">图像恢复</h1><p id="828e" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">为了更详细地解释GANs，我们将使用图像恢复的例子，使用来自fast.ai的<a class="ae le" href="https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres-gan.ipynb" rel="noopener ugc nofollow" target="_blank">第7课-v3 </a>的代码。您可以在<a class="ae le" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>上制作笔记本的副本，并在通读时自己运行代码，以获得更多的实践经验！一个优点是，我们只需要一个未标记的图像数据集来创建图像恢复模型。该模型的目的是恢复低分辨率图像和去除简单水印。以下是映像恢复过程的简要概述:</p><ol class=""><li id="7ca5" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">决定要使用的数据集。在本帖中，我们将使用<a class="ae le" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津-IIIT宠物数据集</a>，这是在<a class="ae le" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC 4.0许可下公开提供的</a>。</li><li id="ca27" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">通过对图像进行某些变换来“美化”数据集。</li><li id="a63e" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">预先训练一个带有<a class="ae le" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> UNet </a>架构的生成器网络，将伪造的图像转换回原始图像。</li><li id="553c" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">生成可用于预训练评论家的初始恢复图像集。</li><li id="5593" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">预先训练一个批评家网络，将生成的图像分类为“假的”，将原始图像分类为“真的”。</li><li id="b92f" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">训练整个GAN结构，根据<a class="ae le" href="http://papers.nips.cc/paper/5423-generative-adversarial-nets" rel="noopener ugc nofollow" target="_blank"> GAN文件</a>从发生器切换到批判器。</li><li id="4f35" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">最后，我们将获得一个生成器网络，可用于恢复其他质量较低的图像！</li></ol><h2 id="4c8e" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">数据集生成</h2><p id="af46" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">为了创建一个带标签的数据集，我们使用一个随机函数来“简化”我们的图像，下面是应用的变换:</p><ul class=""><li id="cb2b" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ny nf ng nh bi translated">添加随机文本/数字</li><li id="eb19" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ny nf ng nh bi translated">通过调整到较小的分辨率，然后调整回原始分辨率来降低图像质量</li></ul><p id="6c0e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面是左边的复制图片和右边的原始图片。我们可以看到质量严重下降，一些图像中添加了随机数水印！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/7dda7679d19dc7abe18972e55b21ef8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*nuyyaw9PkCRgUjjKhbrjSQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来自<a class="ae le" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津Pets数据集</a>的复制图像(左)、原始图像(右)。</p></figure><h2 id="a0cd" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">预培训生成者和评论家</h2><p id="39de" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">利用该数据集，我们对UNet模型进行预处理，以产生原始图像，并将经过处理的图像作为输入。这是使用均方误差损失来训练的。<a class="ae le" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet34 </a>被用作主干，这也是在ImageNet上预先训练的，这样我们可以节省一些计算时间！以下是仅经过5个纪元(在Google Colab免费GPU上大约10分钟)后预训练生成器网络的结果:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/a20860e96ab1a412592463aa42ba2ee7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*zrQ4K4zVXUxBUw_4XDEJSg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">预训练发电机网络的结果</p></figure><p id="525c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们观察到生成器模型能够部分恢复一些图像质量。此外，大多数带水印的数字都被模型删除和填充了！对于仅仅10分钟的训练时间来说，这已经是相当不错的表现了。但是画质还是有较大差距；显然，简单的均方误差损失不足以执行完整的图像恢复。</p><p id="db1f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了预先训练批评家，我们简单地使用上面的生成器输出，并将它们放入一个目录中。评论家将从目录名中检索标签，并将学会将这些图像分类为真实或虚假。以下是来自一批critic预训练数据集的一些样本:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/197d6999851f8745f0f2543664255994.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*AeFr0plTkFP6HbtPuOZJyw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">具有原件(标记为图像)和赝品(标记为image_gen)的评论家预训练数据集</p></figure><h2 id="976b" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">甘培训</h2><p id="2c23" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在这一部分，我将只简要说明甘训练的细节，而不是把重点放在直觉和技巧，以提高其稳定性。对于完整的解释，<a class="ae le" href="https://medium.com/@joseph.rocca" rel="noopener">约瑟夫·罗卡</a>有一大篇<a class="ae le" rel="noopener" target="_blank" href="/understanding-generative-adversarial-networks-gans-cd6e4651a29">T3T5】关于它！</a></p><p id="c93c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了训练GAN，我们需要在更新生成器<strong class="lh ja"> G </strong>和鉴别器/鉴别器<strong class="lh ja"> D </strong>之间交替。<strong class="lh ja"> G </strong>将使用对抗性损失进行训练，该损失描述了生成的样本欺骗<strong class="lh ja"> D </strong>的可能性。均方误差损失也用于确保<strong class="lh ja"> G </strong>不会开始产生看起来根本不像原始图像的样本。<strong class="lh ja"> D </strong>被单独训练使用相同的对抗性损失，但是与<strong class="lh ja"> G </strong>相比，试图将这个损失项推向另一个方向。在训练D时，我们希望最大化D 正确分类真假样本的可能性。</p><p id="4d41" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">GAN的训练过程非常复杂，并且需要大量的计算时间。这就是我们进行预培训的原因。预训练模型(甚至在低于标准的生成样本上)允许模型<strong class="lh ja"> G </strong>和<strong class="lh ja"> D </strong>以合理的网络参数开始。这是双重优势，因为它减少了培训失败的机会，也缩短了培训时间！</p><h2 id="3fb0" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">结果</h2><p id="1ca9" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在这里，我们展示了经过大约80个时期的训练(在Google Colab上将近3个小时)后生成的一些样本。利用简单的UNet模型和短的训练过程，我们能够恢复大部分图像质量并去除简单的水印。在下面的例子中，我们看到图像质量有了显著提高。数字水印也被几乎完美地去除了！但是，一些细节，如猫的头部和面部的精细纹理已经模糊了。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oc"><img src="../Images/2a22b62b413075365c7628affd01c97a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X0TOwG1dbnCJqQbxFGMjug.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/fd0951084f48082b7a7f17be6616acf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jTYtLAy3brRwb-XXatV2UA.png"/></div></div></figure><h2 id="c7df" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">结论</h2><p id="77d6" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">尽管随机图像生成是当今的热门话题，但GANs并不局限于这些生成任务(人脸、风景、绘画等)。如果我们跳出框框思考，有许多创造性的应用，GANs在其中同样有效！除了图像质量恢复，另一个很酷的例子是图像彩色化，我们可以通过相同的过程生成一个变色的数据集，并使用它来训练我们的GAN。</p></div></div>    
</body>
</html>