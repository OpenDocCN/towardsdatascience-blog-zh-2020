<html>
<head>
<title>[Deep learning] How to build an emotional chatbot</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">【深度学习】如何建立一个有情感的聊天机器人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-how-to-build-an-emotional-chatbot-part-2-the-dialogue-system-4932afe6545c?source=collection_archive---------29-----------------------#2020-09-18">https://towardsdatascience.com/deep-learning-how-to-build-an-emotional-chatbot-part-2-the-dialogue-system-4932afe6545c?source=collection_archive---------29-----------------------#2020-09-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5f5f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="#" rel="noopener ugc nofollow">情感聊天机器人</a></h2><div class=""/><div class=""><h2 id="8b55" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">第二部分:基于深度学习和强化学习的对话系统</h2></div><p id="5007" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">从<a class="ae ln" href="https://medium.com/@jay_hui/deep-learning-how-to-build-an-emotional-chatbot-part-1-bert-sentiment-predictor-3deebdb7ea30" rel="noopener">第一部分</a>，我们已经建立了伯特情绪预测器。我们现在开始结合它，建立情感对话系统。在进入细节之前，让我们先介绍一些先决条件。(但我仍然无法解释这里的所有术语……)</p><h1 id="c1fb" class="lo lp it bd lq lr ls lt lu lv lw lx ly ki lz kj ma kl mb km mc ko md kp me mf bi translated">深度学习的先决条件</h1><ul class=""><li id="fcfc" class="mg mh it kt b ku mi kx mj la mk le ml li mm lm mn mo mp mq bi translated"><strong class="kt jd">seq 2 seq model</strong><br/><a class="ae ln" href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">seq 2 seq model</a>是一种高级神经网络，旨在将一个序列变成另一个序列。Seq2seq由两个神经网络组成:EncoderRNN(为了避免消失梯度问题，更常被称为<a class="ae ln" rel="noopener" target="_blank" href="/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21"> LSTM或GRU </a>)对源句子进行编码，为解码器RNN提供隐藏状态。另一方面，解码器生成目标句子。</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/73da50b5ee2ef0418737bc4e4517e997.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*Q_N07G2KF3QPuQG8cs-yag.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated"><a class="ae ln" href="https://developer.nvidia.com/blog/introduction-neural-machine-translation-gpus-part-2/" rel="noopener ugc nofollow" target="_blank">用于机器翻译的编码器-解码器架构</a></p></figure><ul class=""><li id="fa12" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd">注意力是你需要的全部<br/> </strong>尽管Seq2Seq模型在NLP中带来了巨大的突破，但一个普通的Seq2Seq模型仍然遭受瓶颈和消失梯度问题。<a class="ae ln" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">注意力模型</a>是Seq2Seq之上的一项著名技术，它允许解码器直接专注于源的某些部分，这通过提供到遥远状态的捷径来缓解消失梯度问题。<br/> <br/>更多详情可以参考<a class="ae ln" href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html" rel="noopener ugc nofollow" target="_blank"> NLP从无到有:带序列到序列网络的翻译及注意</a>。</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/3884c52fc52289432afe5a65da93143c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*PBUeiAgiRrakZfQFavv03Q.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated"><a class="ae ln" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">注意力模型(变压器)架构</a></p></figure><ul class=""><li id="bfb1" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd"> PyTorch &amp; Texar包</strong> <br/>另外，推荐阅读:PyTorch 中的<a class="ae ln" href="https://pytorch.org/tutorials/beginner/chatbot_tutorial.html" rel="noopener ugc nofollow" target="_blank">聊天机器人教程和帮助你轻松构建复杂深度学习模型(尤其是NLP任务)的</a><a class="ae ln" href="https://github.com/asyml/texar" rel="noopener ugc nofollow" target="_blank"> Texar包，</a>。最后但同样重要的是，确保你有一个GPU来构建聊天机器人。</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/0a88231f0f85bb2527599a3db90e7cec.png" data-original-src="https://miro.medium.com/v2/resize:fit:318/format:webp/1*-A6EK4wVUo_896229b8JDg.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated"><a class="ae ln" href="https://medium.com/r?url=https%3A%2F%2Fgithub.com%2Fasyml%2Ftexar" rel="noopener"> Texar包</a></p></figure></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="ae39" class="lo lp it bd lq lr np lt lu lv nq lx ly ki nr kj ma kl ns km mc ko nt kp me mf bi translated">移情对话数据集</h1><p id="297e" class="pw-post-body-paragraph kr ks it kt b ku mi kd kw kx mj kg kz la nu lc ld le nv lg lh li nw lk ll lm im bi translated">来自ParlAI的<a class="ae ln" href="https://github.com/facebookresearch/EmpatheticDialogues" rel="noopener ugc nofollow" target="_blank"> EmpatheticDialogues数据集</a>包含大约33090个对话，其中每个对话包含几个句子，并被分类为不同的情绪情况。为简单起见，没有应用验证数据集。训练/测试被分割为90/10%(跳过了验证数据集)。</p><p id="13eb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">下面是一个守恒的例子(转换成一对源句和目标句):</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/aaff8c8d066f9729d104938ab7b374cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*smlscTqV0VpRUzWLKpmmnw.png"/></div></figure><p id="45db" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们准备的数据如下:</p><ol class=""><li id="69f4" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm ny mo mp mq bi translated">5个字以内30个字以上的句子去掉。</li><li id="7789" class="mg mh it kt b ku nz kx oa la ob le oc li od lm ny mo mp mq bi translated">标记数据，包括符号。英语中的许多缩写形式也被替换了。例如，“不能”将被转换为“不能”</li><li id="00b9" class="mg mh it kt b ku nz kx oa la ob le oc li od lm ny mo mp mq bi translated">构建所有单词的词汇表。词汇表的大小是24，408，完全基于训练数据。</li></ol></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="4156" class="lo lp it bd lq lr np lt lu lv nq lx ly ki nr kj ma kl ns km mc ko nt kp me mf bi translated">对话系统设计(编码器和损失函数)</h1><p id="5437" class="pw-post-body-paragraph kr ks it kt b ku mi kd kw kx mj kg kz la nu lc ld le nv lg lh li nw lk ll lm im bi translated">基于HKUST的论文“<a class="ae ln" href="https://arxiv.org/pdf/1906.08487.pdf" rel="noopener ugc nofollow" target="_blank"> HappyBot:通过改善用户体验前瞻</a>产生移情对话响应”，现在让我们来关注最有趣的部分。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/2b44161646e06f29a951fc913d1e3677.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*vuEf1IntgEpKEtjZo030Ig.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">结合情感预测器的网络结构</p></figure><ul class=""><li id="02cc" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd"> MLE损失</strong> <br/>模型结构如下。左边是<a class="ae ln" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">注意力模型</a>的结构，正常的对话系统。目标是嵌入每个句子输入(长度为T ),然后从vocab列表生成输出概率分布(w_t)。响应生成中的训练目标是最大化单词y*的可能性，并且其损失函数被写为:</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/ffe5be2bf6e1a99a70468720664686f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*yGQ2tlrBIsoqxKLH8xegJQ.png"/></div></figure><ul class=""><li id="c58f" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd">线性回归损失</strong> <br/>在我们结合情感的强化学习(RL)部分之前，我们引入另一个线性回归作为基线回报模型，估计每个句子的情感得分R如下:</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi og"><img src="../Images/37889e5eabee995273216014ea10bdfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*yW19iA2AL_d3lvr6XsxLvg.png"/></div></figure><p id="b4b8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">其中m_t是编码器在步骤t的隐藏状态，R是该句子的情感得分(奖励)，W_r和b_r是可训练参数。这种线性回归的目的是减少报酬r的方差。</p><ul class=""><li id="6758" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd">强化学习损失<br/> </strong>我们通过贪婪解码来解码我们预测的句子(我们这样做是为了时间有效性。我们将在下一节介绍“解码策略”)。之后，BERT模型将预测该句子的情感得分R。RL损耗计算如下:</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/876ecbd705d4ef330d4dd3bb83baf33b.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*roATNTN7cQAMdk6-BjBOBA.png"/></div></figure><p id="3bf6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">其中w_t是在步骤t单词的预测概率分布</p><p id="bc35" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">RL的含义:</strong>线性回归的输出(Rˇt)作为R的一个均值，当涉及到一个很大的情绪得分(即R&gt;Rˇt)时，最小化L_RL就是最大化w_t，也就是说我们要增加获得一个很大奖励的机会。另一方面，当R&lt;Rˇt时，需要最小化wt以减少损耗。这就是强化学习的原理:<strong class="kt jd">你想获得奖励的几率更高</strong>。(就像心理学中的操作性条件反射一样)</p><p id="abef" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最后，这三个损失函数组合如下:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/774b2a22bec4a1b278abb2b11172e720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*4vNkoQNKhfpsWvM-9sJxwQ.png"/></div></figure><p id="b2e3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">MLE、RL和B的λ(权重)是决定权重的三个超参数。</p></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="9c97" class="lo lp it bd lq lr np lt lu lv nq lx ly ki nr kj ma kl ns km mc ko nt kp me mf bi translated">对话系统设计(解码策略)</h1><p id="2cba" class="pw-post-body-paragraph kr ks it kt b ku mi kd kw kx mj kg kz la nu lc ld le nv lg lh li nw lk ll lm im bi translated">在用损失函数训练模型之后。为了从w_t的概率分布生成预测的句子，我们需要解码部分。这里我们将应用并比较两种解码策略:</p><ol class=""><li id="69ba" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm ny mo mp mq bi translated"><strong class="kt jd">贪婪解码<br/> </strong>每一步都取最可能的单词(由argmax)而不回溯。<br/> - <strong class="kt jd">优点:</strong>快速<br/> <strong class="kt jd"> -缺点:</strong>无法追溯生成过程，可能会引起一些奇怪的反应。(生成:我爱……，哦其实“爱”这个词不是我想要的！)</li><li id="0766" class="mg mh it kt b ku nz kx oa la ob le oc li od lm ny mo mp mq bi translated"><strong class="kt jd">前K个采样解码</strong> <br/>从w_t中随机采样，仅限于前K个最可能的单词。使用top-k采样，尤其是使用较大的k，响应将更加通用和多样。(注意，如果你想用AI写诗或小说，你需要top-k采样，而不是贪婪解码)</li></ol><p id="6f52" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">有关解码策略的更多信息，可以阅读下面的文章“<a class="ae ln" rel="noopener" target="_blank" href="/decoding-strategies-that-you-need-to-know-for-response-generation-ba95ee0faadc">您需要了解的响应生成解码策略</a>”</p><p id="1a70" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果您采用<a class="ae ln" href="https://texar.readthedocs.io/en/latest/code/modules.html#decoders" rel="noopener ugc nofollow" target="_blank"> Texar </a>包的解码，您可以通过“助手”实例轻松实现不同的解码策略。</p></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="6840" class="lo lp it bd lq lr np lt lu lv nq lx ly ki nr kj ma kl ns km mc ko nt kp me mf bi translated">模特培训</h1><p id="9cc3" class="pw-post-body-paragraph kr ks it kt b ku mi kd kw kx mj kg kz la nu lc ld le nv lg lh li nw lk ll lm im bi translated">培训期间采用了几种策略:</p><ul class=""><li id="80e9" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd">稍后启用强化学习部分的训练<br/> </strong>刚开始的时候，生成的句子不够精细，无法进行情感评分。所以我们在第19纪元开始RL部分。<strong class="kt jd">换句话说，聊天机器人通常在开始时学习，然后再考虑情感。</strong></li><li id="c0b7" class="mg mh it kt b ku nz kx oa la ob le oc li od lm mn mo mp mq bi translated"><strong class="kt jd">RL的最小权重</strong> <br/>注意到loss_RL的斜率较高(因为当输入为负时对数函数的斜率较高，因此其梯度下降)。我们采用了RL和B的一个极小的lambda(权重)来平衡它们与MLE的lambda。</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a6506f59f229f0488010eaf2c501d408.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*jm2hPbUX-eGh8ARi2Vht6Q.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">b损失和RL损失将在训练中占主导地位。</p></figure><ul class=""><li id="45a4" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd">提前停止</strong> <br/>由于loss_RL占优势，模型可能会以loss_MLE为代价降低它。因此，在我们的模型中采用了提前停止。如果loss_MLE大于其在添加loss_RL之前的平均值，则模型训练将终止。我们的模特训练在20世纪就结束了。</li></ul><p id="5780" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以下是模型20个时期的最终训练历史:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/6843eb9be911adfb2eedbd0c76a153cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*1t-Nei4yMhZz8p_rYUA5PA.png"/></div></figure></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="026c" class="lo lp it bd lq lr np lt lu lv nq lx ly ki nr kj ma kl ns km mc ko nt kp me mf bi translated">模型评估</h1><p id="9c0a" class="pw-post-body-paragraph kr ks it kt b ku mi kd kw kx mj kg kz la nu lc ld le nv lg lh li nw lk ll lm im bi translated">为了评估我们的方法，我们将构建另一个基线模型(没有强化学习部分)进行比较。我们将在回应生成中使用两个标准指标:</p><ul class=""><li id="0d76" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd"> BLEU metric </strong> <br/> <a class="ae ln" href="https://www.aclweb.org/anthology/P02-1040.pdf" rel="noopener ugc nofollow" target="_blank">双语评估替角评分(BLEU) </a>评估n-grams在地面实况和系统响应中的同现。n-gram精度计算如下:</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/0770129eec4651bce6819b28aafad622.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*KCWVGLumAg6lb-wE-nZbIg.png"/></div></figure><p id="2c5b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">r是基础真实响应，r^是系统响应，k索引所有可能的长度为n的n元文法，h(k，r)是r中n元文法的数量。选择BLEU-1(单元文法)和BLEU-2(双元文法)用于我们的评估。</p><ul class=""><li id="80ed" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd">Distinct metric<br/></strong>Distinct metric衡量生成句子的多样性，定义为不同n元语法的数量除以生成单词的总量。我们选择Distinct-1 (uni-gram)进行评估。</li></ul></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><ul class=""><li id="b782" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd">基于指标的评估<br/> </strong>我们已经训练了两组模型，基线模型(带有我们的强化学习部分)和非基线模型。对于解码策略，我们还评估了贪婪和top-k (k=5)来测试解码策略的影响。<br/> <br/>在下表中，发现我们的非基线模型通过在训练和测试数据集中具有最高的情感分数BLEU-1/2和独特分数(略好于基线模型)而胜过基线模型。</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/9d666e04e2882319dc73491770884d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*672J6bpoloFXbjoV5XJ5sw.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">对训练/测试数据的BLEU、独特和平均情感评分评估</p></figure><ul class=""><li id="628d" class="mg mh it kt b ku kv kx ky la nd le ne li nf lm mn mo mp mq bi translated"><strong class="kt jd">生成实例</strong></li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="oo op di oq bf or"><div class="gh gi on"><img src="../Images/a993c8ed68c34125fe790bcd756e705e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uconfRKmx2Q4jYL1CcWjdQ.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">括号内的分数是伯特的情感分数。</p></figure><h1 id="0cce" class="lo lp it bd lq lr ls lt lu lv lw lx ly ki lz kj ma kl mb km mc ko md kp me mf bi translated">结论</h1><p id="8cf6" class="pw-post-body-paragraph kr ks it kt b ku mi kd kw kx mj kg kz la nu lc ld le nv lg lh li nw lk ll lm im bi translated">与基线模型相比，我们的方法在保持高语言性能的同时，成功地生成了更多的积极响应。</p><p id="0b2d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">令人惊讶的是，我们发现贪婪方法不仅在语言性能方面与top-k采样(k=5)表现相似，而且由于top-k采样更有利于通用响应，因此它还产生了更多的正面响应。</p><h1 id="7eb2" class="lo lp it bd lq lr ls lt lu lv lw lx ly ki lz kj ma kl mb km mc ko md kp me mf bi translated">参考</h1><ul class=""><li id="47b4" class="mg mh it kt b ku mi kx mj la mk le ml li mm lm mn mo mp mq bi translated">Ashish Vaswani、Noam Shazeer、Niki Parmar、Jakob Uszkoreit、Llion Jones、AidanNGomez、Lukasz Kaiser和Illia Polosukhin。2017.你需要的只是关注。神经信息处理系统进展，6000-6010页。</li><li id="21d4" class="mg mh it kt b ku nz kx oa la ob le oc li od lm mn mo mp mq bi translated">H.拉什金，E. M .史密斯，m .李，y .布鲁走向共情的开放领域对话模式:一个新的基准和数据集</li><li id="2de6" class="mg mh it kt b ku nz kx oa la ob le oc li od lm mn mo mp mq bi translated">申洁敏、徐鹏、安德里亚·马多托和帕斯卡尔·冯。Happybot:通过提高用户体验前瞻性来产生移情对话响应。arXiv预印本arXiv:1906.08487，2019。</li><li id="ae34" class="mg mh it kt b ku nz kx oa la ob le oc li od lm mn mo mp mq bi translated">K.Papineni、S. Roukos、T. Ward和W. J. Zhu。BLEU:一种自动评估机器翻译的方法。在ACL，2002年。</li><li id="6d1e" class="mg mh it kt b ku nz kx oa la ob le oc li od lm mn mo mp mq bi translated">Sutskever，I .，Vinyals，o .，和Le，Q. (2014年)。用神经网络进行序列间学习。神经信息处理系统进展(NIPS 2014)。</li></ul></div></div>    
</body>
</html>