<html>
<head>
<title>Cross-Entropy Demystified.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">交叉熵去神秘化。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cross-entropy-demystified-f0886a64883f?source=collection_archive---------35-----------------------#2020-10-06">https://towardsdatascience.com/cross-entropy-demystified-f0886a64883f?source=collection_archive---------35-----------------------#2020-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8c54" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">深入研究交叉熵，其必要性和实用性背后的直觉和推理。</h2></div><h1 id="6d13" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">引言。</h1><p id="979c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">很长一段时间，我没有完全理解交叉熵损失。<strong class="kz ir">我们为什么要取指数(softmax)？那我们为什么要拿走木头？我们为什么要拍下这个日志？我们是如何以必须最小化的正损失结束的？</strong></p><p id="04cc" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">这些问题越来越让我困惑，以至于我只是接受了我必须使用交叉熵进行多标签分类，并没有想太多。</p><p id="001d" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">最近我开始浏览fastai的2020课程，Jeremy在解释交叉熵，尽管我认为他做得很好，但我之前的问题没有得到很好的回答。于是我开始琢磨和摆弄笔记本，终于弄明白了。</p><p id="3dae" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">在这篇文章中，我会问一些简单的问题，然后我会回答这些问题，希望之后你不会再有任何关于交叉熵的令人难以置信的问题。</p><h2 id="39ad" class="ly kg iq bd kh lz ma dn kl mb mc dp kp lg md me kr lk mf mg kt lo mh mi kv mj bi translated">损失函数的目标是什么？</h2><p id="1d31" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">损失函数的目标是简单地输出一个数字(我们如何得到这个数字很快就会清楚)，这个数字有2个要求。</p><ol class=""><li id="153c" class="mk ml iq kz b la lt ld lu lg mm lk mn lo mo ls mp mq mr ms bi translated">数字必须是正数。</li><li id="a073" class="mk ml iq kz b la mt ld mu lg mv lk mw lo mx ls mp mq mr ms bi translated">我们的模型越不准确，这个数字就应该越大。</li></ol><p id="1894" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">我们的目标是最小化这个数字，我们的损失越接近零，我们的模型就越精确。</p><blockquote class="my mz na"><p id="3905" class="kx ky nb kz b la lt jr lc ld lu ju lf nc lv li lj nd lw lm ln ne lx lq lr ls ij bi translated">注意:我不会探究为什么会这样，我假设你知道神经网络的目标是最小化损失。如果你想了解更多，请访问fast.ai，跟随杰里米的惊人深度学习课程。这适用于所有与交叉熵无关的问题，但是我愿意在评论中回答它们。</p></blockquote><h2 id="dcd6" class="ly kg iq bd kh lz ma dn kl mb mc dp kp lg md me kr lk mf mg kt lo mh mi kv mj bi translated">第一站，激活。</h2><p id="ac4d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们的第一站是激活。这些是神经网络的最后一层输出，是我们的网络对我们图像标签的猜测。激活离标签越近，我们的模型就越精确。</p><p id="cae8" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">让我们考虑一个网球的图像，我们试图找出这个图像是否是以下三个事物之一:</p><ol class=""><li id="9c95" class="mk ml iq kz b la lt ld lu lg mm lk mn lo mo ls mp mq mr ms bi translated">篮球</li><li id="0d5e" class="mk ml iq kz b la mt ld mu lg mv lk mw lo mx ls mp mq mr ms bi translated">网球</li><li id="24da" class="mk ml iq kz b la mt ld mu lg mv lk mw lo mx ls mp mq mr ms bi translated">足球</li></ol><p id="e5dd" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">网球的标号将是[0，1，0]。这些预测是100%准确的。猜测分别对应0%篮球，100%网球，0%足球。</p><p id="9f2f" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">现在假设我们的激活是[0.001，4.334，2.90]。这些只是我凭空想象出来的随机数。然而，如果我们假设这些是激活，我们可以清楚地看到网球的激活是最高的，然而，我们如何量化呢？或者用百分比概率怎么说呢？</p><p id="5173" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">此外，如果我们有一组不同的激活，比如[4.334，2.90，0.01]，现在最高的激活是篮球，但我们的图像是一个网球，如何量化我们的模型有多错误？</p><h1 id="722d" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">这就是交叉熵的用武之地。</h1><p id="14ba" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">交叉熵是一个损失函数，它量化了我们的模型有多错误。</p><p id="fb83" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">这种疯狂主要有3个步骤(尽管一旦你理解了它的超级简单和直观)。</p><h2 id="1837" class="ly kg iq bd kh lz ma dn kl mb mc dp kp lg md me kr lk mf mg kt lo mh mi kv mj bi translated">1.Softmax</h2><p id="d4a7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">第一步是使我们的激活值在0和1之间。我们这样做，所有激活值对应于图像属于某个类别的概率，现在我们可以简单地最大化对应于正确类别的一个值，这将自动减少对应于错误类别的值。如果我们使用原始激活，这个过程会困难得多。</p><blockquote class="my mz na"><p id="684f" class="kx ky nb kz b la lt jr lc ld lu ju lf nc lv li lj nd lw lm ln ne lx lq lr ls ij bi translated">注意:当我说我们想要最大化激活时，不要混淆。我们确实想最大化激活，我们只想最小化损失。激活是我们的模型做出的猜测，损失是我们模型错误的度量。<br/>我们想减少错误(丢失)，增加正确预测(正确标签对应的激活)。</p></blockquote><p id="32e7" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated"><strong class="kz ir"> <em class="nb">我们怎么做softmax？</em> </strong> <br/>对于每一项，取每一项的指数，除以所有项的指数之和。</p><p id="93da" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">对于我们的激活[4.334，2.90，0.01]，让我们计算每个项目的指数。</p><p id="095f" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">acts = [4.334，2.90，0.01]</p><p id="7407" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">exp_acts = [76.2487，18.1741，1.0101]</p><p id="4b88" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">sum(exp_acts) = 95.4329</p><p id="0dd1" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">acts_softmax = [0.7990，0.1904，0.0106]</p><p id="cac7" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">看看最高激活是如何对应最高概率的，这就是为什么我们做softmax</p><blockquote class="my mz na"><p id="5a73" class="kx ky nb kz b la lt jr lc ld lu ju lf nc lv li lj nd lw lm ln ne lx lq lr ls ij bi translated">侧边栏:我们为什么不干脆做acts = acts/sum(acts)呢？<br/>让我们试试:<br/> acts/sum(acts) = [0.5983，0.4003，0.0014] <br/>将此与softmax进行比较，较高的激活对应于使用softmax的概率比使用归一化的概率高。在分类中，这个特性在大多数时候是需要的，因此我们使用softmax。</p></blockquote><h2 id="1e23" class="ly kg iq bd kh lz ma dn kl mb mc dp kp lg md me kr lk mf mg kt lo mh mi kv mj bi translated">2.原木</h2><p id="e5ba" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">考虑2个交叉熵值，一个是0.99，第二个是0.999。他们看起来比较接近，如果我们根据softmax计算我们的损失，两者的损失不会相差太远。然而，这是不可取的。<br/>考虑10000个项目，第一个softmax为0.99，100个项目被误分类，而第二个softmax为0.999，只有10个项目被误分类。本质上0.999的softmax好了10倍，而不仅仅是好了一点点。这种质量上的差异最好用测井曲线来表示。</p><p id="717d" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">log(0.01)=-4.6051<br/>log(0.001)=-6.9077</p><p id="c764" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">尽管softmax值接近，但log值中的cast差异非常有用。<br/>也log(1) = 0，所以当softmax概率为正确类的100%时，损失(如果只是log(softmax)为0)。</p><p id="067a" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">我们计算损耗的方法是，其中label ==1，我们取-log(softmax)，这就是损耗。</p><h2 id="b1a5" class="ly kg iq bd kh lz ma dn kl mb mc dp kp lg md me kr lk mf mg kt lo mh mi kv mj bi translated">3.为什么是负的对数损失？</h2><p id="1e45" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在我们的例子中，softmax为1，log softmax为0，因此损失为零。这是正确的。</p><p id="3869" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">但当我们的softmax为0.01时，我们的log softmax为- <strong class="kz ir"> 4.6，</strong>但我们知道我们的损失必须是一个必须最小化的高正数，所以我们取它的负值，使我们的-log(softmax)为正，这是损失的正确值。</p><p id="7708" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">由于曲线的性质，Log为负。</p><figure class="ng nh ni nj gt nk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nf"><img src="../Images/b52e1b862c36a9781d58f7c4047af035.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7gTWdst1BI1J2F0e-8QLZA.png"/></div></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">许可证<a class="ae nv" href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-NC-SA 3.0 </a>下x &lt; 1 are negative. Image by <a class="ae nv" href="https://saylordotorg.github.io/text_intermediate-algebra/s10-03-logarithmic-functions-and-thei.html" rel="noopener ugc nofollow" target="_blank"> Saylor学院</a>的记录值</p></figure><p id="60b9" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">因为softmax值总是小于或等于1，所以log总是负的，因此-log(softmax)是正的。</p><p id="0a81" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated"><strong class="kz ir">重申一下:-Log(softmax)是我们的损失值。我们取数据集或小批量中每个损失值的平均值，以获得总损失，我们试图将其最小化。</strong></p><h1 id="0188" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">外卖想法</h1><ol class=""><li id="802d" class="mk ml iq kz b la lb ld le lg nw lk nx lo ny ls mp mq mr ms bi translated">我们采用激活指数使预测概率之间的差距更大。</li><li id="d648" class="mk ml iq kz b la mt ld mu lg mv lk mw lo mx ls mp mq mr ms bi translated">我们取softmax的对数，将softmax的小差异等同于损失的大差异，这是应该存在的。<strong class="kz ir">在某种意义上，我们使用softmax对激活进行处理，以帮助预测，但我们使用log对激活进行反处理，以准确评估损失。</strong></li><li id="8c7e" class="mk ml iq kz b la mt ld mu lg mv lk mw lo mx ls mp mq mr ms bi translated">我们对log取负值以得到正损失，因为log对小于1的值返回负值(softmax值就是这种情况)。</li></ol><h1 id="a2d3" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">信用</h1><ol class=""><li id="d93f" class="mk ml iq kz b la lb ld le lg nw lk nx lo ny ls mp mq mr ms bi translated">这里的许多想法来自杰瑞米·霍华德的Fastai课程，我只是试图解释我更好地理解的内容，并添加了我的一些想法。</li><li id="d4a4" class="mk ml iq kz b la mt ld mu lg mv lk mw lo mx ls mp mq mr ms bi translated"><a class="ae nv" href="https://saylordotorg.github.io/text_intermediate-algebra/s10-03-logarithmic-functions-and-thei.html" rel="noopener ugc nofollow" target="_blank">https://saylordotorg . github . io/text _ intermediate-algebra/S10-03-logarithus-functions-and-the I . html</a>，就是我得到对数图的地方。</li></ol></div></div>    
</body>
</html>