<html>
<head>
<title>A Complete Logistic Regression Algorithm From Scratch in Python: Step by Step</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中从头开始的完整逻辑回归算法:一步一步</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-complete-logistic-regression-algorithm-from-scratch-in-python-step-by-step-ce33eae7d703?source=collection_archive---------5-----------------------#2020-10-30">https://towardsdatascience.com/a-complete-logistic-regression-algorithm-from-scratch-in-python-step-by-step-ce33eae7d703?source=collection_archive---------5-----------------------#2020-10-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/31a2b1314ac351ad8db51c46956c18ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*77G-N9Fh7oW8sjVV"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">爱丽丝·华生在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="f48e" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">使用真实世界的数据集开发算法</h2></div><p id="e07a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">逻辑回归是上个世纪以来流行的一种方法。它建立了分类变量和一个或多个自变量之间的关系。这种关系在机器学习中用于预测分类变量的结果。它广泛应用于许多不同的领域，如医疗领域、贸易和商业、技术等。</p><blockquote class="lu lv lw"><p id="c762" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">本文解释了开发二元分类算法的过程，并在Kaggle的心脏病数据集上实现了该算法。</p></blockquote><h1 id="3814" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">问题陈述</h1><p id="045d" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在本文中，我们将使用来自Kaggle的数据集，其中包含人口的健康数据。它的最后有一栏包含一个人是否有心脏病。我们的目标是看看我们是否能利用表格中的其他列来预测一个人是否患有心脏病。</p><p id="4cec" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这里，我将加载数据集。为此，我将使用熊猫:</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="ac41" class="nh mc jj nd b gy ni nj l nk nl">import pandas as pd<br/>import numpy as np<br/>df = pd.read_csv('Heart.csv')<br/>df.head()</span></pre><p id="09f8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据集如下所示:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/0fdfde26eda6610ab892f0fc3b9ae8e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EDrhB986uJXLaQ6s.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Haert.csv数据集的前五行</p></figure><p id="ad37" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">查看数据集的最后一列。它是“AHD”。这表示有心脏病。我们将使用其余的专栏来预测心脏病。因此，在未来，如果我们有了所有的数据，我们将能够预测一个人是否患有心脏病，而无需医学检查。</p><p id="f62b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的输出将是0或1。如果一个人有心脏病，我们的算法将返回1，如果一个人没有心脏病，算法将返回0。</p><h1 id="1ae6" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">重要方程式</h1><p id="1523" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">记住线性回归公式。直线的最基本公式:</p><p id="24b3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Y= A+BX</p><p id="1378" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中A是截距，B是斜率。如果我们避开等式中的“截距”A，则公式变为:</p><p id="f1de" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Y = BX</p><p id="6ff3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">传统上，在机器学习中，它被表示为，</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/f0aa1e8074740dcc6ca1ddf63abc9877.png" data-original-src="https://miro.medium.com/v2/resize:fit:204/format:webp/0*1jEDpRGUMxY3CFe4.png"/></div></figure><p id="dba2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，“h”是假设或预测值，X是预测值或输入变量。θ在开始时被随机初始化，随后被更新。</p><p id="a8a6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于逻辑回归，我们需要使用一个返回从0到1的值的<strong class="la jk"> sigmoid函数</strong>来转换这个简单的假设。sigmoid函数也可以称为逻辑函数。逻辑回归使用sigmoid函数来预测输出。这是sigmoid激活函数:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi no"><img src="../Images/80b77e052fb708d499c3649a547e7df4.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/0*Wf4TXzXGeXDoxjWB.png"/></div></figure><p id="336a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">z是输入特征乘以随机初始化项θ。</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/30367d7b93bd12501768845e1e9baf93.png" data-original-src="https://miro.medium.com/v2/resize:fit:210/format:webp/0*A2HHISJjnJgSklAk.png"/></div></figure><p id="3229" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，X是输入特征，θ是将在该算法中更新的随机初始化值。</p><p id="5ca3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们需要使用逻辑函数的原因是，逻辑函数的曲线看起来像这样:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nq"><img src="../Images/79029d07d8ec9f1ecf88a4b829120d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HXCBO-Wx5XhuY_OwMl0Phw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="36b3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从上图可以看出，它返回0到1之间的值。所以，对分类很有帮助。因为我们今天将研究二元分类，</p><blockquote class="nr"><p id="3bc9" class="ns nt jj bd nu nv nw nx ny nz oa lt dk translated">如果逻辑函数返回的值小于0.5，我们将返回零；如果逻辑函数返回的值大于或等于0.5，我们将返回1</p></blockquote><blockquote class="lu lv lw"><p id="4433" class="ky kz lx la b lb ob kk ld le oc kn lg ly od lj lk lz oe ln lo ma of lr ls lt im bi translated"><strong class="la jk">成本函数</strong></p></blockquote><p id="9573" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">成本函数为您提供了预测输出(计算的假设“h”)与原始输出(数据集中的“AHD”列)之间的距离。</p><p id="8826" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在深入研究逻辑回归的成本函数之前，我想提醒你一下线性回归的成本函数，它要简单得多。线性回归的成本是:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi og"><img src="../Images/b04d3d0d8fda7b11be0b89250aaf34fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*Gaembkng1LbhcjQOJaTFGg.png"/></div></figure><p id="b80c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在哪里，</p><p id="5579" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">y是原始标签(数据集的“AHD”列)</p><p id="5bb0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">平均成本函数是:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/0747bf69f24e6b6723b8174a718fcc3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*jThMNkRtAJJduSZXOAgn8g.png"/></div></figure><p id="be56" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在哪里，</p><p id="fb8e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">m是训练数据的数量</p><p id="d2dc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面的等式首先取预测标签“h”和原始标签“y”之间的差。该公式包括平方以避免任何负值，并使用1/2来优化该平方。</p><p id="9e6e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个简单明了的方程适用于线性回归，因为线性回归使用一个简单的线性方程:(Y= A+BX)。</p><blockquote class="nr"><p id="26aa" class="ns nt jj bd nu nv nw nx ny nz oa lt dk translated">但是逻辑回归使用的是非线性的sigmoid函数。</p></blockquote><p id="5c93" class="pw-post-body-paragraph ky kz jj la b lb ob kk ld le oc kn lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated">我们不能在这里使用简单成本函数，因为它不会收敛到全局最小值。为了解决这个问题，我们将使用日志来正则化成本函数，以便它收敛到全局最小值。</p><p id="c253" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是我们将用来保证全局最小值的成本函数:</p><p id="286e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果y = 1，</p><p id="a260" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">成本(h，y) = -log(h)</p><p id="e21f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果y = 0，</p><p id="09c1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Cost(h，y) = -log(1 — h)</p><blockquote class="lu lv lw"><p id="7ef8" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">简化组合成本函数:</strong></p></blockquote><p id="96bf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是成本函数表达式:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/54cae5a319248c64b84784493524e81e.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*dfpXbYMY5AZsgOgr3URt3A.png"/></div></figure><p id="da8a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为什么是这个等式？看，我们只能有两种情况y = 0或1。在上面的成本函数等式中，我们有两项:</p><ol class=""><li id="9adf" class="oj ok jj la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated">y*logh和</li><li id="36f2" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated">(1-y)*对数(1-h)。</li></ol><p id="9854" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果y = 0，第一项变为0，第二项变为log(1-h)。在等式中，我们已经在开头加了一个负号。</p><p id="cb32" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果y = 1，第二项变为零，只剩下y长项，开头是负号。</p><p id="bec2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">希望现在有意义！</p><blockquote class="lu lv lw"><p id="3c24" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">梯度下降</strong></p></blockquote><p id="90dc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们需要更新随机初始化的θ值。梯度下降方程就是这样。如果我们对成本函数相对于θ取偏导数:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/c46f4a42a86bfb455c4186983e399db2.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*GksGEwMzfUcyQm0T5p4V3g.png"/></div></figure><p id="bf1f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用上面的这个表达式，梯度下降公式变成:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/dd885aed08fd21eab780c1e725002045.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*wbQktsXugyiQ2X84ZnNdkQ.png"/></div></figure><p id="7738" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，α是学习率。</p><p id="4abc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用这个等式，θ值将在每次迭代中更新。你什么时候用python实现thin，你就更清楚了。</p><p id="d6a7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是使用上述所有等式来开发算法的时候了</p><h1 id="a079" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">模型开发</h1><blockquote class="lu lv lw"><p id="a0db" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">第一步:提出假设。</p></blockquote><p id="c0e6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该假设只是sigmoid函数的实现。</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="1f65" class="nh mc jj nd b gy ni nj l nk nl">def hypothesis(X, theta):<br/>    z = np.dot(theta, X.T)<br/>    return 1/(1+np.exp(-(z))) - 0.0000001</span></pre><p id="c297" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我从这里的输出中减去了0.0000001，因为成本函数中有这样一个表达式:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/8c3a1ea17bce8af9e0eab6951669e319.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/format:webp/0*8wS5q278wgZw3DMk.png"/></div></figure><p id="2e96" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果假设表达式的结果是1，那么这个表达式将是0的对数。为了减轻这一点，我在最后用了这个很小的数字。</p><blockquote class="lu lv lw"><p id="abba" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">第二步:确定成本函数。</strong></p></blockquote><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="fa6e" class="nh mc jj nd b gy ni nj l nk nl">def cost(X, y, theta):<br/>    y1 = hypothesis(X, theta)<br/>    return -(1/len(X)) * np.sum(y*np.log(y1) + (1-y)*np.log(1-y1))</span></pre><p id="95dc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这只是上面的成本函数等式的简单实现。</p><blockquote class="lu lv lw"><p id="75fd" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">第三步:更新θ值。</strong></p></blockquote><p id="66c5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">θ值需要不断更新，直到成本函数达到最小值。我们应该得到最终的θ值和每次迭代的成本作为输出。</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="b9d6" class="nh mc jj nd b gy ni nj l nk nl">def gradient_descent(X, y, theta, alpha, epochs):<br/>    m =len(X)<br/>    J = [cost(X, y, theta)] <br/>    for i in range(0, epochs):<br/>        h = hypothesis(X, theta)<br/>        for i in range(0, len(X.columns)):<br/>            theta[i] -= (alpha/m) * np.sum((h-y)*X.iloc[:, i])<br/>        J.append(cost(X, y, theta))<br/>    return J, theta</span></pre><blockquote class="lu lv lw"><p id="00ad" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">第四步:计算最终预测和精度</strong></p></blockquote><p id="4af0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用“gradient_descent”函数得出的θ值，并使用sigmoid函数计算最终预测值。然后，计算精度。</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="77d9" class="nh mc jj nd b gy ni nj l nk nl">def predict(X, y, theta, alpha, epochs):<br/>    J, th = gradient_descent(X, y, theta, alpha, epochs) <br/>    h = hypothesis(X, theta)<br/>    for i in range(len(h)):<br/>        h[i]=1 if h[i]&gt;=0.5 else 0<br/>    y = list(y)<br/>    acc = np.sum([y[i] == h[i] for i in range(len(y))])/len(y)<br/>    return J, acc</span></pre><p id="5b95" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最终输出是每个时期的成本列表和精确度。让我们实现这个模型来解决一个实际问题。</p><h1 id="1589" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">数据预处理</h1><p id="1873" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我已经在开始展示了数据集。但是为了您的方便，我在这里再次包括它:</p><figure class="my mz na nb gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/0fdfde26eda6610ab892f0fc3b9ae8e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EDrhB986uJXLaQ6s.png"/></div></div></figure><p id="25ed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，数据集中有一些分类要素。我们需要将它们转换成数字数据。</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="4542" class="nh mc jj nd b gy ni nj l nk nl">df["ChestPainx"]= df.ChestPain.replace({"typical": 1, "asymptomatic": 2, "nonanginal": 3, "nontypical": 4})<br/>df["Thalx"] = df.Thal.replace({"fixed": 1, "normal":2, "reversable":3})<br/>df["AHD"] = df.AHD.replace({"Yes": 1, "No":0})</span></pre><p id="9a34" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">为偏差添加一个额外的列。这应该是一列1，因为任何实数乘以1都保持不变。</strong></p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="fa5f" class="nh mc jj nd b gy ni nj l nk nl">df = pd.concat([pd.Series(1, index = df.index, name = '00'), df], axis=1)</span></pre><p id="eecb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">定义输入特征和输出变量。输出列是我们要预测的分类列。输入特征将是除了我们之前修改的分类列之外的所有列。</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="5cc0" class="nh mc jj nd b gy ni nj l nk nl">X = df.drop(columns=["Unnamed: 0", "ChestPain", "Thal"])<br/>y= df["AHD"]</span></pre><h1 id="0d37" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">获得准确性结果</h1><p id="3043" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">最后，在一个列表中初始化theta值，并预测结果和计算精度。这里我初始化θ值为0.5。它可以初始化为任何其他值。由于每个特征应该具有相应的θ值，所以应该为X中的每个特征初始化一个θ值，包括偏差列。</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="09f5" class="nh mc jj nd b gy ni nj l nk nl">theta = [0.5]*len(X.columns)<br/>J, acc = predict(X, y, theta, 0.0001, 25000)</span></pre><p id="d927" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最终准确率为84.85%。我用0.0001作为学习率，25000次迭代。</p><blockquote class="nr"><p id="6be2" class="ns nt jj bd nu nv nw nx ny nz oa lt dk translated">我运行了几次这个算法来确定。</p></blockquote><p id="0851" class="pw-post-body-paragraph ky kz jj la b lb ob kk ld le oc kn lg lh od lj lk ll oe ln lo lp of lr ls lt im bi translated">请检查下面提供的这个项目我的GitHub链接。</p><p id="9b82" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">“预测”函数还会返回每次迭代的成本列表。在一个好的算法中，成本应该在每次迭代中保持下降。绘制每一次迭代的成本，以可视化趋势。</p><pre class="my mz na nb gt nc nd ne nf aw ng bi"><span id="52bc" class="nh mc jj nd b gy ni nj l nk nl">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>plt.figure(figsize = (12, 8))<br/>plt.scatter(range(0, len(J)), J)<br/>plt.show()</span></pre><figure class="my mz na nb gt iv gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/82861215446377e0e4093105d012c02d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/0*BIKwVBQGvI1fsKnL.png"/></div></figure><p id="8e44" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">成本在开始时下降很快，然后下降的速度慢了下来。这是一个完美的成本函数的行为！</p><h2 id="52b6" class="nh mc jj bd md pb pc dn mh pd pe dp ml lh pf pg mn ll ph pi mp lp pj pk mr pl bi translated">结论</h2><p id="68f6" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我希望这是有帮助的。如果你是一个初学者，一开始要掌握所有的概念会有点难。但是我建议请你在笔记本上自己运行所有代码，仔细观察输出。这将非常有帮助。这种类型的逻辑回归对于许多现实世界的问题是有帮助的。我希望，你会用它来开发一些很酷的项目！</p><p id="c076" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您在运行任何代码时遇到问题，请在评论部分告诉我。</p><p id="d7f6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这里您可以找到完整的代码:</p><div class="is it gp gr iu pm"><a href="https://github.com/rashida048/Machine-Learning-With-Python/blob/master/LogisticRegressionWithHeartDataset.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jk gy z fp pr fr fs ps fu fw ji bi translated">rashida 048/用Python进行机器学习</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">permalink dissolve GitHub是超过5000万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">github.com</p></div></div><div class="pv l"><div class="pw l px py pz pv qa ja pm"/></div></div></a></div><blockquote class="lu lv lw"><p id="2c82" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">更多阅读:</strong></p></blockquote><div class="is it gp gr iu pm"><a rel="noopener follow" target="_blank" href="/basic-linear-regression-algorithm-in-python-for-beginners-c519a808b5f8"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jk gy z fp pr fr fs ps fu fw ji bi translated">Python中的线性回归算法:一步一步</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">学习线性回归的概念，并使用python从头开始开发一个完整的线性回归算法</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qb l px py pz pv qa ja pm"/></div></div></a></div><div class="is it gp gr iu pm"><a rel="noopener follow" target="_blank" href="/a-complete-recommender-system-from-scratch-in-python-step-by-step-6fc17a4da054"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jk gy z fp pr fr fs ps fu fw ji bi translated">一个完整的推荐系统从零开始:一步一步</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">基于用户评分的线性回归电影推荐系统</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qc l px py pz pv qa ja pm"/></div></div></a></div><div class="is it gp gr iu pm"><a rel="noopener follow" target="_blank" href="/a-complete-anomaly-detection-algorithm-from-scratch-in-python-step-by-step-guide-e1daf870336e"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jk gy z fp pr fr fs ps fu fw ji bi translated">Python中从头开始的完整异常检测算法:分步指南</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">基于概率的异常检测算法</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qd l px py pz pv qa ja pm"/></div></div></a></div><div class="is it gp gr iu pm"><a rel="noopener follow" target="_blank" href="/multiclass-classification-algorithm-from-scratch-with-a-project-in-python-step-by-step-guide-485a83c79992"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jk gy z fp pr fr fs ps fu fw ji bi translated">使用Python从零开始的多类分类算法:分步指南</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">本文介绍两种方法:梯度下降法和优化函数法</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qe l px py pz pv qa ja pm"/></div></div></a></div><div class="is it gp gr iu pm"><a rel="noopener follow" target="_blank" href="/clear-understanding-of-a-knn-classifier-with-a-project-for-the-beginners-865f56aaf58f"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jk gy z fp pr fr fs ps fu fw ji bi translated">学习使用Python的Scikit_learn库通过项目开发KNN分类器</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">适合机器学习新手</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qf l px py pz pv qa ja pm"/></div></div></a></div><div class="is it gp gr iu pm"><a rel="noopener follow" target="_blank" href="/a-complete-guide-to-hypothesis-testing-for-data-scientists-using-python-69f670e6779e"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jk gy z fp pr fr fs ps fu fw ji bi translated">数据科学家使用Python进行假设检验的完整指南</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">用样本研究问题、解决步骤和完整代码清楚地解释</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qg l px py pz pv qa ja pm"/></div></div></a></div></div></div>    
</body>
</html>