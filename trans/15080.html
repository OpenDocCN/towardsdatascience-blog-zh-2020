<html>
<head>
<title>A Complete K Mean Clustering Algorithm From Scratch in Python: Step by Step Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中从头开始的完整K均值聚类算法:分步指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-complete-k-mean-clustering-algorithm-from-scratch-in-python-step-by-step-guide-1eb05cdcd461?source=collection_archive---------1-----------------------#2020-10-17">https://towardsdatascience.com/a-complete-k-mean-clustering-algorithm-from-scratch-in-python-step-by-step-guide-1eb05cdcd461?source=collection_archive---------1-----------------------#2020-10-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/651994de0a38398b41a79538544566d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*76T6rOdxl9CxTmy-"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">彼得·诺伊曼在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="be04" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">还有，如何使用K均值聚类算法对图像进行降维</h2></div><blockquote class="ky kz la"><p id="c1a1" class="lb lc ld le b lf lg kk lh li lj kn lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le jk">什么是K均值聚类？</strong></p></blockquote><p id="02f5" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">k均值聚类是最流行和最广泛使用的无监督学习模型。它也称为聚类，因为它通过对数据进行聚类来工作。与监督学习模型不同，非监督模型不使用标记数据。</p><blockquote class="ky kz la"><p id="5dfb" class="lb lc ld le b lf lg kk lh li lj kn lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">该算法的目的不是预测任何标签。取而代之的是更好地了解数据集并给它们贴上标签。</p></blockquote><p id="1a17" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">在k均值聚类中，我们将数据集聚类成不同的组。</p><blockquote class="ky kz la"><p id="d7ab" class="lb lc ld le b lf lg kk lh li lj kn lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le jk">下面是k均值聚类算法的工作原理</strong></p></blockquote><ol class=""><li id="d563" class="mb mc jj le b lf lg li lj ly md lz me ma mf lx mg mh mi mj bi translated">第一步，随机初始化几个点。这些点被称为簇形心。</li></ol><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/d71d058cca3c67f1ce5dfd87252fa278.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/0*M7QBnmPS9ftAqYit.png"/></div></figure><p id="9ef4" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">在上图中，红色和蓝色的点是星团的质心。</p><p id="89b3" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">可以选择任意数量的簇质心。但是聚类质心的数量必须少于数据点的总数。</p><p id="88bf" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">2.第二步是集群分配步骤。在这一步，我们需要遍历每个绿点。根据这个点是靠近红点还是蓝点，我们需要把它分配给其中一个点。</p><p id="547c" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">换句话说，根据绿点是更接近蓝色簇形心还是红色簇形心，将绿点涂成红色或蓝色。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/63cd6ef9123679beb51dec6c7db466dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/0*DM-b6ryzc9sJGJ8X.png"/></div></figure><p id="c3fd" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">3.下一步是移动簇的质心。现在，我们必须取分配给红色聚类质心的所有红点的平均值，并将红色聚类质心移动到该平均值。我们需要对蓝色星团的质心做同样的操作。</p><p id="fa66" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">现在，我们有了新的簇形心。我们必须回到第二步，集群分配步骤。我们需要将这些点重新排列成新的簇形心。在重复第三遍之后。</p><p id="fe8c" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">数字2和3需要重复几次，直到两个簇的质心都在合适的位置，如下图所示。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/4942b3cb41ed06700f36f5754a83413a.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/0*wzlnQQRU23IGYe6V.png"/></div></figure><p id="a95d" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">看，我们只是根据它们被分配到的簇质心给所有的绿点着色。蓝色群集质心位于蓝色群集的中心，而红色群集质心位于红色群集的中心。</p><p id="648a" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">当我们开发算法的时候，事情会变得更加清楚。我们将对此进行更详细的讨论。</p><h1 id="a088" class="mr ms jj bd mt mu mv mw mx my mz na nb kp nc kq nd ks ne kt nf kv ng kw nh ni bi translated">开发算法</h1><p id="28b4" class="pw-post-body-paragraph lb lc jj le b lf nj kk lh li nk kn lk ly nl ln lo lz nm lr ls ma nn lv lw lx im bi translated">我将用于该算法的数据集是从Coursera 的<a class="ae jg" href="https://www.coursera.org/learn/machine-learning/" rel="noopener ugc nofollow" target="_blank">吴恩达的机器学习课程中获得的。以下是开发k均值算法的逐步指南:</a></p><blockquote class="ky kz la"><p id="af96" class="lb lc ld le b lf lg kk lh li lj kn lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le jk"> 1。导入必要的包和数据集</strong></p></blockquote><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="757a" class="nt ms jj np b gy nu nv l nw nx">import pandas as pd<br/>import numpy as np<br/>df1 = pd.read_excel('dataset.xlsx', sheet_name='ex7data2_X', header=None)<br/>df1.head()</span></pre><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/6082176d56c82874879ad0969cab5ad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/0*sCyyPEbS8uyL83No.png"/></div></figure><p id="ee2e" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">数据集只有两列。我选择了两个特色数据集，因为它易于可视化。当你看到视觉效果时，你会更容易理解这个算法。但是同样的算法也适用于多维数据集。</p><p id="7297" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我将把数据帧df1转换成一个Numpy数组，因为我们将在这个过程中处理其他数组:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="0f87" class="nt ms jj np b gy nu nv l nw nx">X = np.array(df1)</span></pre><p id="1992" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">现在，我将遵循我上面讨论的三个步骤。</p><blockquote class="ky kz la"><p id="4a47" class="lb lc ld le b lf lg kk lh li lj kn lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le jk"> 2。第一步是随机初始化质心。</strong></p></blockquote><p id="75ba" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我将从数据集中随机初始化三个点。首先，我将在0和数据集长度之间选择三个数字。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="261e" class="nt ms jj np b gy nu nv l nw nx">import random<br/>init_centroids = random.sample(range(0, len(df1)), 3)<br/>init_centroids</span></pre><p id="b1c0" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">输出:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="8cfb" class="nt ms jj np b gy nu nv l nw nx">[95, 30, 17]</span></pre><p id="c121" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">以这三个数为指标，得到这些指标的数据点。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="ff8f" class="nt ms jj np b gy nu nv l nw nx">centroids = []<br/>for i in init_centroids:<br/>    centroids.append(df1.loc[i])<br/>centroids</span></pre><p id="c893" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">输出:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="4aaa" class="nt ms jj np b gy nu nv l nw nx">[0    3.907793<br/> 1    5.094647<br/> Name: 95, dtype: float64,<br/> 0    2.660466<br/> 1    5.196238<br/> Name: 30, dtype: float64,<br/> 0    3.007089<br/> 1    4.678978<br/> Name: 17, dtype: float64]</span></pre><p id="31f8" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">这三个点是我们的初始质心。</p><p id="6a4c" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我会把它们转换成二维数组。因为我更熟悉这种格式。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="306e" class="nt ms jj np b gy nu nv l nw nx">centroids = np.array(centroids)</span></pre><p id="9bd6" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">输出:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="2828" class="nt ms jj np b gy nu nv l nw nx">array([[3.90779317, 5.09464676],<br/>       [2.66046572, 5.19623848],<br/>       [3.00708934, 4.67897758]])</span></pre><blockquote class="ky kz la"><p id="096f" class="lb lc ld le b lf lg kk lh li lj kn lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le jk"> 3。实施集群分配步骤。</strong></p></blockquote><p id="9120" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">在这一步中，我们将遍历数据集中的所有数据点。</p><blockquote class="ky kz la"><p id="7499" class="lb lc ld le b lf lg kk lh li lj kn lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">一个数据点意味着一行数据</p></blockquote><p id="9053" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">让我们以单行数据为例，了解如何将该数据分配给一个集群。</p><p id="13ce" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我们将计算该数据到所有三个质心的距离。然后将该数据点分配给与它距离最小的质心。</p><p id="9611" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">正如我们看到的，我们必须计算两点之间的距离。让我们开发一个函数来计算距离。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="ab9e" class="nt ms jj np b gy nu nv l nw nx">def calc_distance(X1, X2):<br/>    return(sum((X1 - X2)**2))**0.5</span></pre><p id="dfd1" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">开发一个函数，将每个数据点分配给一个质心。我们的“质心”数组只有三个值。所以我们有三个指数:0，1，2。我们将这些指数中的一个分配给每个数据点。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="01ac" class="nt ms jj np b gy nu nv l nw nx">def findClosestCentroids(ic, X):<br/>    assigned_centroid = []<br/>    for i in X:<br/>        distance=[]<br/>        for j in ic:<br/>            distance.append(calc_distance(i, j))<br/>        assigned_centroid.append(np.argmin(distance))<br/>    return assigned_centroid</span></pre><p id="c25b" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">这是将数据点分配给聚类的功能。让我们使用这个函数来计算每个数据点的质心:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="e184" class="nt ms jj np b gy nu nv l nw nx">get_centroids = findClosestCentroids(centroids, X)<br/>get_centroids</span></pre><p id="2519" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">部分输出:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="a80a" class="nt ms jj np b gy nu nv l nw nx">[2,<br/> 0,<br/> 0,<br/> 2,<br/> 1,<br/> 2,<br/> 2,<br/> 2,<br/> 1,<br/> 1,<br/> 2,<br/> 2,<br/> 2,<br/> 2,<br/> 2,<br/> 2,<br/> 0,</span></pre><p id="887d" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">总输出长。我在这里展示了部分输出。输出中的第一个质心是2，这意味着它被分配给质心列表的索引2。</p><p id="045e" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated"><strong class="le jk"> <em class="ld"> 4。最后一步是根据数据点的平均值</em> </strong>移动质心</p><p id="58ff" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">在这一步中，我们将取每个质心的所有数据点的平均值，并将质心移动到该平均值。</p><p id="c3c4" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">例如，我们将找到在索引2处分配给质心的所有点的平均值，并将质心2移动到平均值。对索引0和1处的质心做同样的操作。</p><p id="f54d" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">让我们定义一个函数来做这件事:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="ced9" class="nt ms jj np b gy nu nv l nw nx">def calc_centroids(clusters, X):<br/>    new_centroids = []<br/>    new_df = pd.concat([pd.DataFrame(X), pd.DataFrame(clusters, columns=['cluster'])],<br/>                      axis=1)<br/>    for c in set(new_df['cluster']):<br/>        current_cluster = new_df[new_df['cluster'] == c][new_df.columns[:-1]]<br/>        cluster_mean = current_cluster.mean(axis=0)<br/>        new_centroids.append(cluster_mean)<br/>    return new_centroids</span></pre><p id="640c" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">这些都是我们需要开发的功能。</p><p id="f9d8" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">正如我之前讨论过的，我们需要重复这个聚类分配和移动质心的过程几次，直到质心在一个合适的位置。</p><p id="79d7" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">对于这个问题，我选择重复这个过程10次。我将在每次迭代后继续绘制质心和数据，直观地向您展示它是如何工作的。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="d60a" class="nt ms jj np b gy nu nv l nw nx">for i in range(10):<br/>    get_centroids = findClosestCentroids(centroids, X)<br/>    centroids = calc_centroids(get_centroids, X)<br/>    #print(centroids)<br/>    plt.figure()<br/>    plt.scatter(np.array(centroids)[:, 0], np.array(centroids)[:, 1], color='black')<br/>    plt.scatter(X[:, 0], X[:, 1], alpha=0.1)<br/>    plt.show()</span></pre><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/39981236b7b05e3e3ca6220660daa14a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9z3cOKxdscMWQN2H.png"/></div></div></figure><p id="14e7" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">经过五次迭代后，质心被设置到它们的最佳位置。所以在那之后他们没有改变立场。</p><blockquote class="ky kz la"><p id="3cbd" class="lb lc ld le b lf lg kk lh li lj kn lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我建议，在尝试降维之前，请运行上面的所有代码并学好它。</p></blockquote><p id="628a" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">否则你可能会不知所措！此外，我现在将移动得更快一点，因为我们已经详细解释了算法。</p><h1 id="a122" class="mr ms jj bd mt mu mv mw mx my mz na nb kp nc kq nd ks ne kt nf kv ng kw nh ni bi translated">维度缩减</h1><p id="3939" class="pw-post-body-paragraph lb lc jj le b lf nj kk lh li nk kn lk ly nl ln lo lz nm lr ls ma nn lv lw lx im bi translated">我想至少解释一下这个算法的一个用例。一个非常有用的用例是降维。</p><p id="bb80" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">想一个形象。一幅图像中可能有许多不同的像素。在任何计算机视觉问题中，如果我们能够降低图片的尺寸，设备读取该图片的速度将会快很多！不是吗？</p><p id="8fa9" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我们可以使用我们刚刚开发的算法来降低图片的尺寸。</p><p id="7f31" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我将用一只青蛙的图片来演示这一点:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/7e1c425f64a9fa44577883abc38401f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/0*3ZgMGJoN6M8Y7uu2.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="bdfc" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我把这张照片上传到了我笔记本的同一个文件夹里。让我们导入这个:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="3534" class="nt ms jj np b gy nu nv l nw nx">import cv2<br/>im = cv2.imread('frog.png')<br/>im</span></pre><p id="4d95" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">输出:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="e9cd" class="nt ms jj np b gy nu nv l nw nx">array([[[  2,  57,  20],<br/>        [  2,  57,  20],<br/>        [  2,  57,  21],<br/>        ...,<br/>        [  0,   5,   3],<br/>        [  8,  12,  11],<br/>        [ 91,  94,  93]],       [[  2,  56,  20],<br/>        [  1,  54,  20],<br/>        [  1,  56,  19],<br/>        ...,<br/>        [  0,   2,   1],<br/>        [  7,   9,   8],<br/>        [ 91,  92,  91]],       [[  2,  55,  20],<br/>        [  2,  53,  19],<br/>        [  1,  54,  18],<br/>        ...,<br/>        [  2,   4,   2],<br/>        [  8,  11,   9],<br/>        [ 91,  93,  91]],       ...,       [[  6,  76,  27],<br/>        [  6,  77,  26],<br/>        [  6,  78,  28],<br/>        ...,<br/>        [  6,  55,  18],<br/>        [ 13,  61,  25],<br/>        [ 94, 125, 102]],       [[  9,  79,  31],<br/>        [ 11,  81,  33],<br/>        [ 12,  82,  32],<br/>        ...,<br/>        [  6,  56,  19],<br/>        [ 14,  61,  27],<br/>        [ 96, 126, 103]],       [[ 43, 103,  63],<br/>        [ 44, 107,  66],<br/>        [ 46, 106,  66],<br/>        ...,<br/>        [ 37,  81,  50],<br/>        [ 47,  88,  59],<br/>        [118, 145, 126]]], dtype=uint8)</span></pre><p id="071c" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">检查阵列的形状，</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="ec39" class="nt ms jj np b gy nu nv l nw nx">im.sgape</span></pre><p id="8425" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">输出:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="b67f" class="nt ms jj np b gy nu nv l nw nx">(155, 201, 3)</span></pre><p id="5925" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我将整个数组除以255，使所有的值从0到1。</p><p id="720a" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">然后将其整形为155*201 x 3，使其成为二维数组。因为我们之前为二维数组开发了所有的函数。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="6630" class="nt ms jj np b gy nu nv l nw nx">im = (im/255).reshape(155*201, 3)</span></pre><p id="456d" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">正如你在上面看到的，这么多不同的像素值。我们想减少它，只保留10像素的值。</p><p id="ad1c" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">让我们初始化10个随机索引，</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="4dfb" class="nt ms jj np b gy nu nv l nw nx">random_index = random.sample(range(0, len(im)), 10)</span></pre><p id="ad37" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">现在，像我们在前面的例子中做的那样找到质心:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="3298" class="nt ms jj np b gy nu nv l nw nx">centroids = []<br/>for i in random_index:<br/>    centroids.append(im[i])<br/>centroids = np.array(centroids)</span></pre><p id="cbab" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">输出:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="a229" class="nt ms jj np b gy nu nv l nw nx">array([[0.00392157, 0.21176471, 0.06666667],<br/>       [0.03529412, 0.2627451 , 0.09803922],<br/>       [0.29411765, 0.3254902 , 0.26666667],<br/>       [0.00784314, 0.18431373, 0.05882353],<br/>       [0.29019608, 0.49411765, 0.28235294],<br/>       [0.5254902 , 0.61176471, 0.48627451],<br/>       [0.04313725, 0.23921569, 0.09803922],<br/>       [0.00392157, 0.23529412, 0.0745098 ],<br/>       [0.00392157, 0.20392157, 0.04705882],<br/>       [0.22352941, 0.48235294, 0.40784314]])</span></pre><p id="a1c6" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">现在我也要把' im '转换成一个数组，</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="cdef" class="nt ms jj np b gy nu nv l nw nx">im = np.array(im)</span></pre><p id="4959" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">数据准备好了。现在我们可以继续我们的聚类过程。但这一次，我不会把它形象化。因为数据不再是二维的了。所以，可视化并不容易。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="1f2c" class="nt ms jj np b gy nu nv l nw nx">for i in range(20):<br/>    get_centroids = findClosestCentroids(centroids, im)<br/>    centroids = calc_centroids(get_centroids, im)</span></pre><p id="d068" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我们现在得到了更新的质心。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="53b0" class="nt ms jj np b gy nu nv l nw nx">centroids</span></pre><p id="e5d2" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">输出:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="0bf4" class="nt ms jj np b gy nu nv l nw nx">[0    0.017726<br/> 1    0.227360<br/> 2    0.084389<br/> dtype: float64,<br/> 0    0.119791<br/> 1    0.385882<br/> 2    0.247633<br/> dtype: float64,<br/> 0    0.155117<br/> 1    0.492051<br/> 2    0.331497<br/> dtype: float64,<br/> 0    0.006217<br/> 1    0.048596<br/> 2    0.019410<br/> dtype: float64,<br/> 0    0.258289<br/> 1    0.553290<br/> 2    0.406759<br/> dtype: float64,<br/> 0    0.728167<br/> 1    0.764610<br/> 2    0.689944<br/> dtype: float64,<br/> 0    0.073519<br/> 1    0.318513<br/> 2    0.170943<br/> dtype: float64,<br/> 0    0.035116<br/> 1    0.273665<br/> 2    0.114766<br/> dtype: float64,<br/> 0    0.010810<br/> 1    0.144621<br/> 2    0.053192<br/> dtype: float64,<br/> 0    0.444197<br/> 1    0.617780<br/> 2    0.513234<br/> dtype: float64]</span></pre><p id="c731" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">这是最后一步。我们只会保留这10个点。</p><p id="e840" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">如果您也打印get_centroids，您将看到集群分配。</p><p id="feac" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">现在，我们要遍历整个数组' im ',并将数据更改为其对应的聚类质心值。这样，我们将只有这些质心值。</p><p id="fa91" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">我不想改变原来的数组，而是想做一个拷贝并在那里进行修改。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="34e9" class="nt ms jj np b gy nu nv l nw nx">im_recovered = im.copy()<br/>for i in range(len(im)):<br/>    im_recovered[i] = centroids[get_centroids[i]]</span></pre><p id="3ebe" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">正如你所记得的，我们改变了图像的维度，在开始时，使它成为一个二维数组。我们现在需要把它改成原来的形状。</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="5089" class="nt ms jj np b gy nu nv l nw nx">im_recovered = im_recovered.reshape(155, 201, 3)</span></pre><p id="4dec" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">在这里，我将并排绘制原始图像和缩小图像，向您展示两者的区别:</p><pre class="ml mm mn mo gt no np nq nr aw ns bi"><span id="3b14" class="nt ms jj np b gy nu nv l nw nx">im1 = cv2.imread('frog.png')<br/>import matplotlib.image as mpimg<br/>fig,ax = plt.subplots(1,2)<br/>ax[0].imshow(im1)<br/>ax[1].imshow(im_recovered)</span></pre><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/b490c764e0acecf62c593dfadb6e3b45.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/0*0XudXnQ6FuxWZ47u.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="adf5" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">看，我们把图像的尺寸缩小了很多。尽管如此，它看起来像一只青蛙！但是电脑阅读的速度会快得多！</p><h1 id="d202" class="mr ms jj bd mt mu mv mw mx my mz na nb kp nc kq nd ks ne kt nf kv ng kw nh ni bi translated">结论</h1><p id="09df" class="pw-post-body-paragraph lb lc jj le b lf nj kk lh li nk kn lk ly nl ln lo lz nm lr ls ma nn lv lw lx im bi translated">在本文中，我解释了k均值聚类是如何工作的，以及如何从头开始开发k均值聚类算法。我还解释了，如何使用这种算法来降低图像的维度。请尝试使用不同的图像。</p><p id="0649" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">这是我在本文中使用的数据集的链接。</p><div class="is it gp gr iu oc"><a href="https://github.com/rashida048/Machine-Learning-With-Python/blob/master/kmean.xlsx" rel="noopener  ugc nofollow" target="_blank"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">rashida 048/用Python进行机器学习</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">github.com</p></div></div><div class="ol l"><div class="om l on oo op ol oq ja oc"/></div></div></a></div><p id="e779" class="pw-post-body-paragraph lb lc jj le b lf lg kk lh li lj kn lk ly lm ln lo lz lq lr ls ma lu lv lw lx im bi translated">以下是完整代码的GitHub链接:</p><div class="is it gp gr iu oc"><a href="https://github.com/rashida048/Machine-Learning-With-Python/blob/master/k_mean_clustering_final.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">rashida 048/用Python进行机器学习</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">permalink dissolve GitHub是超过5000万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">github.com</p></div></div><div class="ol l"><div class="or l on oo op ol oq ja oc"/></div></div></a></div><h1 id="e0fc" class="mr ms jj bd mt mu mv mw mx my mz na nb kp nc kq nd ks ne kt nf kv ng kw nh ni bi translated">阅读推荐:</h1><div class="is it gp gr iu oc"><a rel="noopener follow" target="_blank" href="/basic-linear-regression-algorithm-in-python-for-beginners-c519a808b5f8"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">Python中的线性回归算法:一步一步</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">学习线性回归的概念，并使用python从头开始开发一个完整的线性回归算法</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="os l on oo op ol oq ja oc"/></div></div></a></div><div class="is it gp gr iu oc"><a rel="noopener follow" target="_blank" href="/multivariate-linear-regression-in-python-step-by-step-128c2b127171"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">Python中多元线性回归的逐步实现</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">学习用Python从头开始开发任意数量变量的多元线性回归。</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="ot l on oo op ol oq ja oc"/></div></div></a></div><div class="is it gp gr iu oc"><a rel="noopener follow" target="_blank" href="/multiclass-classification-algorithm-from-scratch-with-a-project-in-python-step-by-step-guide-485a83c79992"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">使用Python从零开始的多类分类算法:分步指南</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">本文介绍两种方法:梯度下降法和优化函数法</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="ou l on oo op ol oq ja oc"/></div></div></a></div><div class="is it gp gr iu oc"><a rel="noopener follow" target="_blank" href="/polynomial-regression-from-scratch-in-python-1f34a3a5f373"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">Python中从头开始的多项式回归</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">学习用一些简单的python代码从头开始实现多项式回归</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="ov l on oo op ol oq ja oc"/></div></div></a></div><div class="is it gp gr iu oc"><a href="https://medium.com/towards-artificial-intelligence/build-a-neural-network-from-scratch-in-python-f23848b5a7c6" rel="noopener follow" target="_blank"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">用Python从头开始构建神经网络</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">神经网络的详细说明和逐步实现</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">medium.com</p></div></div><div class="ol l"><div class="ow l on oo op ol oq ja oc"/></div></div></a></div><div class="is it gp gr iu oc"><a rel="noopener follow" target="_blank" href="/a-complete-anomaly-detection-algorithm-from-scratch-in-python-step-by-step-guide-e1daf870336e"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">Python中从头开始的完整异常检测算法:分步指南</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">基于概率的异常检测算法</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="ox l on oo op ol oq ja oc"/></div></div></a></div><div class="is it gp gr iu oc"><a rel="noopener follow" target="_blank" href="/great-quality-free-courses-to-learn-machine-learning-and-deep-learning-1029048fd0fc"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">学习机器学习和深度学习的优质免费课程</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">顶级大学高质量免费课程的链接</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="oy l on oo op ol oq ja oc"/></div></div></a></div></div></div>    
</body>
</html>