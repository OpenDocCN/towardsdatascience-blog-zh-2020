<html>
<head>
<title>Hopsworks ML Experiments — open-source alternative to MLflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Hopsworks ML实验MLflow的开源替代方案</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/one-function-is-all-you-need-for-ml-experiments-43c04bc331cb?source=collection_archive---------33-----------------------#2020-10-07">https://towardsdatascience.com/one-function-is-all-you-need-for-ml-experiments-43c04bc331cb?source=collection_archive---------33-----------------------#2020-10-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="f1e0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">TLDR；Hopsworks为机器学习(ML)实验提供支持。也就是说，它可以自动跟踪您的ML程序的工件、图形、性能、日志、元数据和依赖性。你们中的许多人已经知道像<a class="ae kl" href="https://mlflow.org/" rel="noopener ugc nofollow" target="_blank"> MLflow </a>这样的平台，那么为什么还要阅读Hopsworks实验呢？因为你不必重写你的tensor flow/py torch/Scikit-learn程序来获得免费的<strong class="jp ir">跟踪和分发ML</strong>，TensorBoard是内置的。我们将讨论Hopsworks如何独特地支持隐式起源来透明地创建元数据，以及它如何与遗忘训练函数相结合来使您的训练分布透明。</p><h1 id="bf40" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">Hopsworks游戏攻略</h1><p id="ad50" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">Hopsworks是数据科学和数据工程的单一平台，既有<a class="ae kl" href="http://github.com/logicalclocks/hopsworks" rel="noopener ugc nofollow" target="_blank">开源平台</a>又有<a class="ae kl" href="http://www.hopsworks.ai/" rel="noopener ugc nofollow" target="_blank"> SaaS平台</a>，包括内置的<a class="ae kl" href="https://www.logicalclocks.com/hopsworks-featurestore" rel="noopener ugc nofollow" target="_blank">功能库</a>。您可以在GPU上大规模训练模型，使用pip/conda轻松安装任何您想要的Python库，将Jupyter笔记本作为作业运行，将这些作业放在气流管道中，甚至编写大规模运行的(Py)Spark或Flink应用程序。</p><p id="0cc5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一个开发环境，Hopsworks提供了一个集中的协作开发环境，使机器学习团队能够轻松地与队友分享结果和实验，或为项目利益相关者生成报告。所有资源在Hopsworks中都有强大的安全性、数据治理、备份和高可用性支持，而资产则存储在单一的分布式文件系统中(数据存储在云中的S3上)。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/252ab3c3455fc851eb9fb85c323dd64d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KRfaz4gvhDwCR-vf.gif"/></div></div></figure><p id="153b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Hopsworks ML实验存储关于您的ML训练运行的信息:日志、图像、感兴趣的度量(准确性、损失)、用于训练模型的程序、其输入训练数据以及所使用的conda依赖性。可选输出为超参数、张量板和火花历史服务器。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mb"><img src="../Images/e85c28449468200fa665c51e62e24918.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*otN_jSnMue0Qoy5W.gif"/></div></div></figure><p id="839f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每个超参数试验的日志都可以通过点击其日志来检索，TensorBoard可以可视化不同的试验结果。TensorBoard HParams插件也可用于进一步深入测试。</p><h1 id="b3fb" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">跟踪</h1><p id="85dd" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">当您在Hopsworks平台上运行Python或PySpark应用程序时，它可以创建一个<strong class="jp ir">实验</strong>，其中包括程序生成的传统信息(结果、日志、错误)以及特定于ML的信息，以帮助跟踪、调试和重现您的程序及其输入和输出:</p><ul class=""><li id="490a" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated"><strong class="jp ir">超参数</strong>:ML程序本身不更新的训练运行参数；</li><li id="b2c3" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">度量</strong>:在这个实验中训练的模型的损失或准确性；</li><li id="56a2" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">程序神器</strong>:<em class="mq">python/pyspark/air flow</em><em class="mq">程序、</em>及其<em class="mq"> conda环境</em>；</li><li id="22b9" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">模型工件</strong>:序列化的<em class="mq">模型对象、</em> <em class="mq">模型模式</em>和<em class="mq">模型检查点</em>；</li><li id="5fda" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">执行</strong>:能够重新执行实验的信息，包括参数、输入的版本化特征、输出文件等；</li><li id="29db" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">版本化特征</strong>:为了能够重现一个实验，我们需要来自运行的精确的训练/测试数据，以及它是如何从特征库中被创建的；</li><li id="5b07" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">可视化</strong>:训练和评分过程中生成的图像。还可以使用TensorBoard可视化训练——hops works透明地聚合所有员工的结果；</li><li id="5f77" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">日志(用于调试)</strong>:模型权重、梯度、损耗、优化器状态；</li><li id="3d48" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><strong class="jp ir">自定义元数据</strong>:标记实验并对其进行自由文本搜索，管理实验(标记为‘PII’、‘数据保持期’等)，并重现训练运行。</li></ul><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mr"><img src="../Images/bc0b3f75226c27bea131f1399b99b8bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Vb1cy5xlQvRokpHi.png"/></div></div></figure><h1 id="2a2b" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">在一个库中进行实验跟踪和分布式ML</h1><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ms"><img src="../Images/68b4882003f6f179f58457edd1b968bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mGC-lOaYe5drJRYf.png"/></div></div></figure><pre class="lq lr ls lt gt mt mu mv mw aw mx bi"><span id="552f" class="my kn iq mu b gy mz na l nb nc">def train(data_path, max_depth, min_child_weight, estimators):<br/>    X_train, X_test, y_train, y_test = build_data(..)<br/>    ...<br/>    print("hello world") # monkeypatched - prints in notebook<br/>    ...<br/>    model.fit(X_train, y_train) # auto-logging<br/>    ...<br/>    hops.export_model(model, "tensorflow",..,model_name)<br/>    ...<br/>    # create local files ‘logile.txt’, ‘diagram.png’<br/>    return {'accuracy': accuracy, 'loss': loss, 'logfile':<br/>       'logfile.txt', 'diagram': 'diagram.png'} # track dict</span><span id="e9a1" class="my kn iq mu b gy nd na l nb nc">from maggy import experiment<br/>experiment.lagom(train, name="My Experiment", ...)</span><span id="c5b6" class="my kn iq mu b gy nd na l nb nc"># To launch as a distributed ML HParam Tuning job:<br/># sp=Searchspace(max_depth=('INTEGER',[2,8]),min_child_weight<br/># =('INTEGER', [2, 8]), )<br/># experiment.lagom(train, name=“HP, optimizer='randomsearch',<br/># direction='max', num_trials=15,)</span></pre><p id="7532" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">支持实验跟踪的平台要求用户在某个函数或某个显式作用域(如MLFlow中的“with … as xx:”参见附录A)中重构他们的训练代码，以确定实验何时开始，何时结束。在Hopsworks中，我们要求开发人员在函数中编写他们的训练代码。</p><p id="2674" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们称这个Python函数为<em class="mq">不经意训练函数</em>，因为这个函数不知道它是在Jupyter笔记本的Python内核上运行还是在集群中的许多工人上运行，详见我们的<a class="ae kl" href="https://www.logicalclocks.com/blog/unifying-single-host-and-distributed-machine-learning-with-maggy" rel="noopener ugc nofollow" target="_blank">博客</a>和<a class="ae kl" href="https://www.logicalclocks.com/blog/unifying-single-host-and-distributed-machine-learning-with-maggy" rel="noopener ugc nofollow" target="_blank"> Spark/AI峰会演讲</a>。也就是说，您只需编写一次训练代码，在笔记本电脑上训练小型模型时，或者在大型GPU或CPU集群上执行超参数调优或分布式训练时，就可以重用相同的函数。</p><p id="5581" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还使用这个“包装器”Python函数来启动/停止实验跟踪。实验跟踪和分布透明度在一个单一的功能，很好！</p><p id="3a1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在Hopsworks中，<a class="ae kl" href="https://github.com/logicalclocks/maggy" rel="noopener ugc nofollow" target="_blank">玛吉</a>库运行实验，见上面的代码片段。如您所见，与最佳实践TensorFlow程序相比，用户需要的唯一代码更改是:</p><ol class=""><li id="d1bc" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk ne mi mj mk bi translated">因子训练代码在一个用户定义的函数(<strong class="jp ir"> def train(..):</strong>)；</li><li id="d354" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk ne mi mj mk bi translated">返回一个Python dict，其中包含用户希望在实验中被跟踪以及稍后在实验UI中可访问的结果、图像和文件；和</li><li id="be6e" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk ne mi mj mk bi translated">使用<em class="mq">实验. lagom </em>功能调用训练功能。</li></ol><p id="a1c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">超参数可以在一次执行中固定下来，或者如代码片段的最后4行所示，您可以执行<em class="mq"> train函数</em>，作为一个分布式超参数调优作业，跨多个并行工作器执行(如果需要，可以使用GPU)。</p><p id="ad57" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Hopsworks将自动:</p><ul class=""><li id="946e" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated">追踪训练函数的所有参数作为这个实验的超参数，</li><li id="af3e" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">在model.fit中使用Keras回调自动记录日志；</li><li id="4496" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">在HopsFS中创建一个版本化的目录，其中聚集了程序的副本、它的conda环境以及来自所有workers的所有日志；</li><li id="e245" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">跟踪此应用程序的所有出处信息—来自此实验中使用的HopsFS的输入数据(来自功能存储的训练/测试数据集)，以及所有输出工件(模型、模型检查点、应用程序日志)；</li><li id="cbf0" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">将workers中执行的所有print语句重定向到Jupyter notebook单元格，以便于调试(见下面的GIF每个print语句都以worker ID为前缀)。</li></ul><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mb"><img src="../Images/90892cc26cb8d52891705885daf3e2ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*03vI3y-UlUXeCIwj.gif"/></div></div></figure><p id="0663" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在Hopsworks，工人的日志可以在培训期间打印在你的Jupyter笔记本上。拿着数据块！</p><h1 id="393b" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">张量板支架</h1><pre class="lq lr ls lt gt mt mu mv mw aw mx bi"><span id="f48e" class="my kn iq mu b gy mz na l nb nc">def train():<br/>from maggy import tensorboard<br/>...<br/>model.fit(.., callbacks=[TensorBoard(log_dir=tensorboard.logdir(),..)], ...)</span></pre><p id="ad42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">TensorBoard可以说是用于可视化、分析和调试机器学习实验的最常见和最强大的工具。Hopsworks实验与TensorBoard无缝集成。在训练函数内部，数据科学家可以简单地导入<em class="mq">tensorboard</em>python<em class="mq"/>模块，并获得写入所有tensor board文件的文件夹位置。然后从每个执行器收集文件夹的内容，并放在HopsFS的实验目录中。由于TensorBoard支持在同一个图形中显示多个实验运行，可视化和比较多个超参数组合变得像启动实验服务中集成的TensorBoard一样简单。默认情况下，Tensorboard配置了有用的插件，如HParam、Profiler和调试。</p><h1 id="845d" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">分析和调试</h1><p id="8c3b" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">Hopsworks 1.4.0附带了TensorFlow 2.3，其中包括TensorFlow分析器。一个期待已久的新功能，最终允许用户分析模型训练，以确定训练过程中的瓶颈，如CPU + GPU配置中缓慢的数据加载或糟糕的操作放置。</p><p id="b208" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">TensorFlow 2.3还包括调试器V2，可以轻松找到NaN之类的模型问题，这对于在复杂模型中找到问题的根本原因非常重要。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ms"><img src="../Images/5159645db32371c8e656ed0d243fd2d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JobDu301gZqx4lP4.png"/></div></div></figure><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ms"><img src="../Images/e49966ea267ef4217c2ae2ab8f30cd59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wYYE5WB4GY4pH8Ei.png"/></div></div></figure><h1 id="51c1" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">模型注册表</h1><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ms"><img src="../Images/4de7edc5c035b5ae60261dd15fa408b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HxDStk4v3SvsgdFc.png"/></div></div></figure><p id="1369" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在训练代码中，模型可以导出并保存到HopsFS。使用<a class="ae kl" href="https://hops-py.logicalclocks.com/" rel="noopener ugc nofollow" target="_blank">跳跃库</a>中的<em class="mq">模型</em> python模块，很容易对模型进行版本化并附加有意义的元数据，以反映给定模型版本的性能。</p><p id="088c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Hopsworks Model Registry是一项服务，其中列出了所有模型以及有用的信息，如哪个用户创建了模型、不同的版本、创建时间和评估指标(如准确性)。</p><p id="4130" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">模型注册中心提供了基于模型名称、版本号和导出模型的用户进行过滤的功能。此外，可以在UI中对模型版本的评估度量进行排序，以找到给定模型的最佳版本。</p><p id="b903" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在模型注册表UI中，您还可以导航到用于训练模型的实验，并从那里导航到用于训练模型的训练/测试数据，以及从那里导航到用于创建训练/测试数据的功能存储中的功能。谢谢出处！</p><h1 id="f5bd" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">导出模型</h1><p id="033f" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">通过使用<em class="mq">模型</em>模块中的<em class="mq">导出</em>功能，可以以编程方式导出模型。在导出模型之前，实验需要将模型写到HopsFS上的文件夹或路径中。然后，将该路径与模型的名称和应该附加的评估指标一起提供给函数。<em class="mq"> export </em>调用将把文件夹的内容上传到您的模型数据集中，它也将出现在模型注册表中，每次导出都会增加一个版本号。</p><pre class="lq lr ls lt gt mt mu mv mw aw mx bi"><span id="f6c2" class="my kn iq mu b gy mz na l nb nc">from hops import model</span><span id="8c58" class="my kn iq mu b gy nd na l nb nc"># local path to directory containing model (e.g. .pb or .pk)<br/>path = os.getcwd() + “/model_dir”</span><span id="46a5" class="my kn iq mu b gy nd na l nb nc"># uploads path to the model repository, metadata is a dict of metrics<br/>model.export(path, “mnist”, metrics={‘accuracy’: acc})</span></pre><h1 id="5dd4" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">获取最佳模型版本</h1><p id="0dfc" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">当将模型部署到实时服务基础架构或加载模型以进行离线批量推理时，应用程序可以查询模型库，以根据附加到模型版本的元数据(如模型的准确性)找到最佳版本。在以下示例中，将返回精确度最高的MNIST模型版本。</p><pre class="lq lr ls lt gt mt mu mv mw aw mx bi"><span id="5dc6" class="my kn iq mu b gy mz na l nb nc">from hops import model  F<br/>from hops.model import Metric<br/>MODEL_NAME=”mnist”<br/>EVALUATION_METRIC=”accuracy”</span><span id="7c28" class="my kn iq mu b gy nd na l nb nc">best_model = model.get_best_model(MODEL_NAME, EVALUATION_METRIC, Metric.MAX)</span><span id="2b4e" class="my kn iq mu b gy nd na l nb nc">print(‘Model name: ‘ + best_model[‘name’])<br/>print(‘Model version: ‘ + str(best_model[‘version]))<br/>print(best_model[‘metrics’])</span></pre><h1 id="465b" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">细节决定成败</h1><p id="fb7b" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">以上是Hopsworks实验和模型注册表的简要概述。您现在可以在<a class="ae kl" href="http://www.hopsworks.ai/" rel="noopener ugc nofollow" target="_blank"> www.hopsworks.ai </a>上试用它，或者在您可以接触到的任何服务器或虚拟机上安装Hopsworks Community或Enterprise。如果您想了解更多关于我们如何实现管道的信息，请继续阅读。</p><h1 id="bd2f" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">具有PySpark的透明分布式ML</h1><p id="0a42" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">Hopsworks使用PySpark透明地分发遗忘训练功能，以便在工人身上执行。如果GPU由工人使用，Spark会将GPU分配给工人，并支持动态执行器，确保在训练功能返回后释放GPU，<a class="ae kl" href="https://www.logicalclocks.com/blog/optimizing-gpu-utilization-in-hops" rel="noopener ugc nofollow" target="_blank">在此阅读更多信息</a>。这使您能够保持笔记本电脑打开，并以交互方式可视化培训结果，而不必担心您仍在为GPU付费。</p><p id="195f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与将<a class="ae kl" href="https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html" rel="noopener ugc nofollow" target="_blank">训练代码作为Docker映像(如AWS Sagemaker </a>)提供的方法相比，Hopsworks编程模型的优势在于，您可以就地编写定制的训练代码，并直接在笔记本上进行调试。您也不需要为训练代码编写Docker文件，Python的依赖关系可以通过使用来自Hopsworks UI 的<a class="ae kl" href="https://hopsworks.readthedocs.io/en/latest/user_guide/hopsworks/python.html?highlight=pip#installing-libraries" rel="noopener ugc nofollow" target="_blank"> PIP或Conda简单地安装库来管理(我们为您透明地编译Docker映像)。</a></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ca"><img src="../Images/908457ef37e1c2f081a51f89668adb81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Npj0XZLWLF58ES6_.png"/></div></div></figure><p id="a857" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">遗忘训练函数可以在不同的执行环境中运行:Python内核中的Jupyter笔记本(最左边)，并行ML实验(中间)，以及集体allreduce数据并行训练(最右边)。玛吉和霍普斯沃斯负责复杂的任务，如安排任务、收集结果和生成新的超参数试验。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nf"><img src="../Images/4b2e01ce3f3721c5e779191570c69e61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PO92tBkgsI2rPLLl.png"/></div></div></figure><p id="281e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">HopsFS存储实验数据和工人在培训期间生成的日志。当通过API启动一个实验时，会在HopsFS的实验数据集中创建一个子文件夹，并将关于该实验的元数据附加到该文件夹。Hopsworks使用隐式出处自动将这些元数据同步到elasticsearch。</p><p id="7a4a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">元数据可以包括诸如实验名称、实验类型、导出的模型等信息。由于实验的存在是由目录跟踪的，这也意味着删除文件夹也会从跟踪服务中删除实验及其关联的元数据。</p><h1 id="b57c" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">跟踪具有隐含出处的元数据</h1><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ng"><img src="../Images/c319216063fc73393c4263ab6f3ff899.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9su6KOzg1J9PYBmw.png"/></div></div></figure><p id="004b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用于跟踪ML工件谱系的现有系统，如TensorFlow Extended或MLFlow，需要开发人员更改他们的应用程序或库代码，以将跟踪事件记录到外部元数据存储中。</p><p id="2f33" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在Hopsworks中，我们主要使用隐式出处来捕获元数据，在这里我们使用我们的分布式文件系统、HopsFS和一些库来捕获对ML工件的更改，只需要对标准TensorFlow、PyTorch或Scikit-learn程序进行最少的代码更改(详见我们的<a class="ae kl" href="https://www.usenix.org/conference/opml20/presentation/ormenisan" rel="noopener ugc nofollow" target="_blank">USENIX OpML’20论文</a>)。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nh"><img src="../Images/f91b2c6d26c049b8a7536dfb38d42145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*H2wSuQb4AmDBmYEq.png"/></div></div></figure><p id="2a01" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">文件系统事件，例如从训练/测试数据集中读取特征，以及将模型保存到目录中，这些事件在HopsFS中被隐式记录为元数据，然后在Elasticsearch中被透明地索引。这允许在UI中对ML工件、元数据和实验进行自由文本搜索。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ni"><img src="../Images/1bbf64fbaa4bb68533b63efee72790e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ls5Su0_uAmwDWJhy.png"/></div></div></figure><p id="a8a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Hopsworks中的实验是ML训练管道的第一部分，从特征存储开始，到模型服务结束。ML工件(训练/测试数据集、实验、模型等)可以存储在HopsFS上，它们还可以附加定制的元数据。</p><p id="a9d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">定制元数据与工件紧密耦合(删除文件，其元数据将被自动清除)——这是通过将元数据存储在HopsFS使用的相同横向扩展元数据层中来实现的。这种定制元数据也会自动同步到Elasticsearch(使用一种叫做<a class="ae kl" href="https://ieeexplore.ieee.org/document/8752956" rel="noopener ugc nofollow" target="_blank"> ePipe </a>的服务)，从而在Hopsworks中实现对元数据的自由文本搜索。</p><h1 id="f20f" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">伙计们，现在就到这里吧！</h1><p id="61ff" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在所有用于数据科学的开发工具中，管理ML实验的平台近年来出现了最多的创新。开源平台已经出现，如MLFlow和我们的Hopsworks平台，以及专有的SaaS产品，如WandB、Neptune、Comet.ml和Valohai。</p><p id="7466" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Hopsworks实验的不同之处是什么？您可以编写干净的Python代码，并分别借助隐式出处和不经意训练函数免费获得实验跟踪和分布式ML。</p><p id="d113" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">越来越多的人一致认为，平台应该跟踪ML实验中进出的东西，以便进行调试和再现。您可以检测您的代码来跟踪输入/输出，或者您可以让框架使用隐式来源来管理它。</p><p id="26bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Hopsworks实验是我们降低ML投入生产的复杂性的任务中的一个关键组成部分。未来几个月，实时功能工程和监控运营模型领域将出现更多突破性创新。敬请期待！</p><h1 id="5ec2" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">附录A</h1><p id="3d40" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在下面的代码片段中，我们比较了如何使用MLFlow编写Hopsworks实验。相似之处多于不同之处，但是在Hopsworks中不需要显式记录到跟踪服务器。</p><pre class="lq lr ls lt gt mt mu mv mw aw mx bi"><span id="cd2b" class="my kn iq mu b gy mz na l nb nc">def train(data_path, max_depth, min_child_weight, estimators):<br/>    X_train, X_test, y_train, y_test = build_data(..)<br/>    ...<br/>    print("hello world") # monkeypatched - prints in notebook<br/>    ...<br/>    model.fit(X_train, y_train) # auto-logging<br/>    ...<br/>    hops.export_model(model, "tensorflow",..,model_name)<br/>    ...<br/>    # create local files ‘logile.txt’, ‘diagram.png’<br/>    return {'accuracy': accuracy, 'loss': loss, 'logfile':<br/>       'logfile.txt', 'diagram': 'diagram.png'} # track dict</span><span id="72a6" class="my kn iq mu b gy nd na l nb nc">from maggy import experiment<br/>experiment.lagom(train, name="My Experiment", ...)</span><span id="8308" class="my kn iq mu b gy nd na l nb nc"># To launch as a distributed ML HParam Tuning job:<br/># sp=Searchspace(max_depth=('INTEGER',[2,8]),min_child_weight<br/># =('INTEGER', [2, 8]), )<br/># experiment.lagom(train, name=“HP, optimizer='randomsearch',<br/># direction='max', num_trials=15,)</span><span id="3a95" class="my kn iq mu b gy nd na l nb nc">def train(data_path, max_depth, min_child_weight, estimators, model_name):  # distribution external<br/>X_train, X_test, y_train, y_test = build_data(..)<br/>mlflow.set_tracking_uri("jdbc:mysql://username:password@host:3306/database")<br/>mlflow.set_experiment("My Experiment")<br/>with mlflow.start_run() as run:<br/>    ...<br/>    mlflow.log_param("max_depth", max_depth)<br/>    mlflow.log_param("min_child_weight", min_child_weight)<br/>    mlflow.log_param("estimators", estimators)<br/>    with open("test.txt", "w") as f:<br/>        f.write("hello world!")<br/>    mlflow.log_artifacts("/full/path/to/test.txt")<br/>    ...<br/>    model.fit(X_train, y_train) # auto-logging<br/>    ...<br/>    mlflow.tensorflow.log_model(model, "tensorflow-model",<br/>      registered_model_name=model_name)</span></pre><p id="02f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">像MLFlow，但是更好？</p><h1 id="494a" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">附录B</h1><p id="789b" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated"><strong class="jp ir">管道</strong>是编排端到端培训和模型部署工作执行的程序。在Hopsworks中，您可以将Jupyter笔记本作为可调度作业在Hopsworks中运行，这些作业可以作为Airflow管道的一部分运行(Airflow也是Hopsworks的一部分)。管道运行后，数据科学家可以在实验服务中快速检查训练结果。</p><p id="d599" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">构成完整培训和部署流程的典型步骤包括:</p><ul class=""><li id="1f16" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated">通过从特征存储中选择特征来具体化训练/测试数据，</li><li id="0c25" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">对训练/测试数据进行模型训练并将模型导出到模型注册处，</li><li id="bfa8" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">模型的评估和验证，如果它通过了健壮性、偏差和准确性测试，模型部署。</li></ul><p id="208d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章最初发表在逻辑时钟网站上。所有图片版权归Logical Clocks AB所有，经许可使用。</p></div></div>    
</body>
</html>