<html>
<head>
<title>Random Forest for predictive maintenance of turbofan engines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">涡轮风扇发动机预测维修的随机森林</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/random-forest-for-predictive-maintenance-of-turbofan-engines-5260597e7e8f?source=collection_archive---------13-----------------------#2020-11-01">https://towardsdatascience.com/random-forest-for-predictive-maintenance-of-turbofan-engines-5260597e7e8f?source=collection_archive---------13-----------------------#2020-11-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a7c7fbff0f987e83bbafb390ce6fcfaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ejN4GrNEPFkiRAgD"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">戴维·科瓦连科在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="7dd3" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/exploring-nasa-turbofan" rel="noopener" target="_blank">探索美国宇航局的涡轮风扇数据集</a></h2><div class=""/><div class=""><h2 id="a6c8" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">FD003的探索性数据分析和超参数调整</h2></div><p id="ec73" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">&lt;<em class="md">免责声明:我的目的是展示模型开发过程中不同方法和选择的效果。这些影响经常使用测试集来显示，这被认为是(非常)不好的做法，但有助于教育目的。</em> &gt;</p><p id="7cc7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">欢迎来到“探索NASA的涡轮风扇数据集”系列的另一部分。在<a class="ae jg" rel="noopener" target="_blank" href="/survival-analysis-for-predictive-maintenance-of-turbofan-engines-7e2e9b82dc0e?sk=d290f4c4a5c112360e679f12234043bf">上一篇文章</a>中，我们看了生存分析，并总结了我们对数据集FD001的分析。虽然最终的RMSE没有我们之前创建的模型好，但这是一个非常有趣的技术，因为它可以处理经过审查的数据。今天，我们将深入第三个数据集(FD003)，其特征是发动机有两种可能的故障模式。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi me"><img src="../Images/f5022e9856dc0d79917cab04282e2f59.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*pyVb1L3A9TxUmIQV8J2XNQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">数据集元数据</p></figure><p id="465a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我选择了交换在FD002和FD003上发布的顺序，因为在我看来，这个顺序会使复杂性逐渐增加。起初，我已经开始在FD002上安装随机森林(RF ),但结果并不理想。FD002看起来确实需要更复杂的预处理和建模来处理各种操作条件。然而，在FD003上，我认为RF将表现得相当好，因为它自然能够区分故障模式。让我们一起来了解一下吧！</p><h1 id="355a" class="mj mk jj bd ml mm mn mo mp mq mr ms mt ky mu kz mv lb mw lc mx le my lf mz na bi translated">探索性数据分析</h1><p id="8017" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">我们可以在FD001上重复EDA中的许多步骤。首先，让我们读入数据。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="6999" class="nn mk jj nj b gy no np l nq nr"># returns<br/># (24720, 26)</span></pre><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/6fa852953fe457621570e49a65b5d022.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*5c2-P4yPhiyhBFz1y9yg_w.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">train.head()的结果</p></figure><p id="bfe5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">看起来不错，接下来我们将考察一些描述性统计。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/e6d84f4b86c5c3c66377de8c78ced084.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*eBEFVEYe6vRuDH6U2FwqYA.png"/></div></figure><p id="dad5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们的数据集包括24.7k行和26列，第一个引擎在145个时间周期后失败，而最后一个引擎在525个时间周期后失败。接下来，我们将检查传感器描述符。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/f9790dca0ada97eddc9e5f4811e8b849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*lpJpG8kewzRoscaJPRx3jA.png"/></div></figure><p id="4eb3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">根据(几乎)为零的标准偏差来判断，传感器1、5、16、18和19没有保存有价值的信息。</p><p id="dfb4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在我们开始绘制数据之前，让我们计算一下列车组的剩余使用寿命(RUL)。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">RUL在击穿时可以认为是0，我们天真地假设RUL是一个线性函数。意味着在击穿前的10个周期时RUL是10，在击穿前的50个周期时是50，等等。</p></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/ad121d7f2647a3a9a540ad9c963eadac.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*Y63oQbhMRXB-EVCwgdspBA.png"/></div></figure><p id="d9bd" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">既然已经添加了，我们将检查分布情况，以便获得比检查描述性表更好的理解。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/7b752b8fbf4563d6c5c0bd91f67a6aef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3szxwA2rd-v9905-ETp6ug.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">RUL的分布。</p></figure><p id="da66" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">RUL很明显是右斜的，左边根本没有尾巴。偏斜分布会对模型性能产生很大影响。EDA完成后，我们会将计算的RUL限制在125的上限，用于模型训练，因为它更好地代表了我们对训练集[1，2]的RUL的了解。</p><h2 id="97fb" class="nn mk jj bd ml nx ny dn mp nz oa dp mt lq ob oc mv lu od oe mx ly of og mz jp bi translated">标绘信号</h2><p id="f881" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">接下来，我们将检查传感器值，看看我们是否可以直观地区分不同的故障模式，并确定在模型开发中要放弃的传感器。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/0f283e1ce69673e18ad625cd80e78e53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FiTU4dl-mEKy3OVjP8qaWQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">S1对RUL的曲线图</p></figure><p id="6533" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">传感器1、5、16、18和19看起来都很相似。我们可以再次确认他们的排除，因为他们似乎没有任何信息。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/613f061816679ed5e78706557457619b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8t5BVPRQdZTjhVCsz2Hj_w.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">S2对RUL的曲线图</p></figure><p id="46b2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">传感器2、3、4、8、11、13和17显示出类似的上升趋势，应包括在模型开发中。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/e31e8900cabe5a6677c0931e9d7fdb6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bEswqOk24DzgPb76lh_uyw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">S6对RUL的图表</p></figure><p id="720d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">传感器6是一个有点奇怪的传感器，但在怀疑中受益。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ok"><img src="../Images/f190edd5b3aebfd7a0c76156f23b3f4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kvvC4dAIY7oomwK9yZ90zw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">七国集团对RUL的图表</p></figure><p id="60df" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">传感器7、12、15、20和21清楚地显示了两种故障模式，并且应该明确地包括在模型中。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/1fc37c6a8c4c0e3a36d6c26f5a812690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rcVRz0Dft3ibfdSGVHjWYA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">S9对RUL的图表</p></figure><p id="c362" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">传感器9和14显示了类似的趋势，但不能很好地区分故障模式。测试它们对模型性能的影响必须指出它们是否应该包含在内。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi om"><img src="../Images/6b3d7c9efa9b3ddef13b4f67053f82bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q8tBmZN1UYIzODXsqvAU3g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">s_10 vs RUL的图表</p></figure><p id="d0ed" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后，传感器10，也是一个奇怪的传感器，因为它似乎有上升趋势，所以被认为是有益的。EDA完成后，是时候创建基线模型了。</p><h1 id="575d" class="mj mk jj bd ml mm mn mo mp mq mr ms mt ky mu kz mv lb mw lc mx le my lf mz na bi translated">基线模型</h1><p id="25d6" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">就像我们对FD001所做的一样，我喜欢从一个最简单的模型开始，一个没有额外预处理的回归模型。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="707e" class="nn mk jj nj b gy no np l nq nr"># returns<br/># train set RMSE:19.33013490506061, R2:0.7736110804777467<br/># test set RMSE:22.31934448440365, R2:0.7092939799790338</span></pre><p id="b5e3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基线模型的测试RMSE是22.319，这将是我们要打破的分数。接下来是我们对随机森林回归器的第一次尝试。</p><h1 id="b038" class="mj mk jj bd ml mm mn mo mp mq mr ms mt ky mu kz mv lb mw lc mx le my lf mz na bi translated">随机森林</h1><p id="0959" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">与单一决策树相比，随机森林(RF)的一个关键优势是它们能够生成不同的树。让我解释一下。创建单个决策树时，该算法会尝试基于单个要素(所有可用要素中的一个)创建一个决策节点，该要素可以最好地分割数据集。对于下一个节点，它将重新检查所有可用的特征，以创建以下最佳分割。如果你在这些条件下第二次拟合决策树，它会生成完全相同的树。然而，当创建分割时，RF仅考虑所有特征的子集。这迫使算法生成不同的树，因为创建最佳分割的特征可能不可用。可能会产生比常规决策树的单个最佳分割更好的分割<em class="md">组合</em>。</p><p id="7545" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">虽然上面的描述是我学习RF工作原理的方式，但检查您使用的工具是否也以同样的方式实现它也很重要。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/eb4a4bd2604d783db138e157ae318969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*bfGjgpQyrcMFysS20VuKTg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">scikit的部分RF文档-了解v0.22.2 [3]</p></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/0255aac2c57fc1bf457eb350fbc3fb5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Us9Cc2-NqUc8kktW8G8CZw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">scikit的部分RF文档-了解v0.22.2 [3]</p></figure><p id="1b90" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">检查sklearns RandomForestRegressor的文档显示，它默认考虑所有特性，本质上是一遍又一遍地创建同一个树。因此，我们将max_features指定为可用功能的平方根。此外，我们设置了random_state，因此树总是以相同的方式生成。否则，随机树的生成将影响模型结果，使得很难判断一个模型是否因为我们改变了一些特征或由于随机性而表现得更好。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="1184" class="nn mk jj nj b gy no np l nq nr"># returns<br/># train set RMSE:5.9199939580022525, R2:0.9787661901585051<br/># test set RMSE:21.05308450085165, R2:0.7413439613827657</span></pre><p id="ddba" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">虽然RF已经比我们的基线模型表现得好一点。根据训练集和测试集之间的RMSE和方差的差异来判断，该模型似乎非常适合。让我们检查一些树的特征来验证我的怀疑。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="e393" class="nn mk jj nj b gy no np l nq nr"># returns<br/># 33<br/># array([15616, 11694,  7793, ...,     1,     1,     4], dtype=int64)</span></pre><p id="1d29" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这棵树的最长路径由33个节点组成，是我们放入的特征数量的两倍多。当查看n_nodes_samples时，我们可以看到树的最后几片叶子每个都包含很少的样本。该树变得如此具体，它创建了分裂标准，直到大多数样本可以被区分，这对于泛化来说是非常糟糕的(因此在训练集上过度拟合)。我们可以通过设置RF的max_depth和min_samples_leaf来尝试解决这个问题。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="49ba" class="nn mk jj nj b gy no np l nq nr"># returns<br/># train set RMSE:15.706704198492831, R2:0.8505294865338602<br/># test set RMSE:20.994958823842456, R2:0.7427702419664686</span></pre><p id="3cef" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">尝试这些设置可以减少过度拟合，同时获得轻微的性能提升。在没有s_6和s_10的情况下拟合相同的模型表现更差，因此保留了这些传感器。我们将把这个模型作为进一步改进的基础。</p><h2 id="c768" class="nn mk jj bd ml nx ny dn mp nz oa dp mt lq ob oc mv lu od oe mx ly of og mz jp bi translated">可视化射频</h2><p id="5643" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">我们可以将我们的树中的一棵形象化，试图找出改进点【4，5】。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oo"><img src="../Images/e5ad0916f273d1b169723d45bc82a898.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bGXKf_9tKR5p62WmyYvJKQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">决策树的一部分，请注意，此可视化仅代表RF的单个树</p></figure><p id="2e60" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">似乎有一些节点会导致非常不准确的预测(mse &gt; 500)。还记得传感器9和14吗，它们不能很好地区分故障模式？它们在树的这一部分显示为分裂标准，但结果仍然黯淡无光。让我们尝试在没有这两个传感器的情况下安装一个RF，并检查其性能。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="acfc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">重新运行粗略调整的RF返回:</p><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="a7e4" class="nn mk jj nj b gy no np l nq nr"># train set RMSE:17.598192835079978, R2:0.8123616776758054<br/># test set RMSE:22.186214762363356, R2:0.7127516253047333</span></pre><p id="4547" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不幸的是，性能变得相当糟糕，所以我们将保留传感器9和14。</p><h1 id="e726" class="mj mk jj bd ml mm mn mo mp mq mr ms mt ky mu kz mv lb mw lc mx le my lf mz na bi translated">浅谈特征工程</h1><p id="5fdf" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">对于这种特定的数据集-算法组合，没有太多的特征工程的可能性。随机森林天生擅长学习复杂的数据模式，并且对缩放或特征变换不变[6]。因为所有的特征都已经是数字了，所以我们没有更多的事情可做。</p><p id="329c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我试着用简单的移动平均数来平滑数据。理论上，这将使算法更容易正确地应用其分裂，并使其更容易区分故障，因为噪声已从信号中去除。但遗憾的是，性能并没有提升。平滑传感器信号的代码可以在笔记本上找到(文章底部的链接)。接下来，我们将深入研究超参数调优。</p><h1 id="0f85" class="mj mk jj bd ml mm mn mo mp mq mr ms mt ky mu kz mv lb mw lc mx le my lf mz na bi translated">超参数</h1><p id="570f" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">我们可以调整哪些参数？</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="1d36" class="nn mk jj nj b gy no np l nq nr"># returns<br/>{'bootstrap': True,<br/> 'ccp_alpha': 0.0,<br/> 'criterion': 'mse',<br/> 'max_depth': 8,<br/> 'max_features': 'sqrt',<br/> 'max_leaf_nodes': None,<br/> 'max_samples': None,<br/> 'min_impurity_decrease': 0.0,<br/> 'min_impurity_split': None,<br/> 'min_samples_leaf': 50,<br/> 'min_samples_split': 2,<br/> 'min_weight_fraction_leaf': 0.0,<br/> 'n_estimators': 100,<br/> 'n_jobs': None,<br/> 'oob_score': False,<br/> 'random_state': 42,<br/> 'verbose': 0,<br/> 'warm_start': False}</span></pre><p id="43c4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">有关所有参数的完整描述，请参考官方文档[3]。拟合随机森林的最大挑战是过度拟合。参数max_depth、min_samples_leaf、ccp_alpha和min _ infinity _ decrease有助于减少过拟合并生成整体性能更好的模型。因此，我选择这些来进行模型调整。</p><p id="1d40" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最大深度和最小样本叶应该是不言自明的，但是ccp阿尔法和最小杂质减少需要更多的解释。</p><h2 id="3b1b" class="nn mk jj bd ml nx ny dn mp nz oa dp mt lq ob oc mv lu od oe mx ly of og mz jp bi translated">ccp阿尔法</h2><p id="9150" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">成本复杂性修剪α是用于修剪树的参数。修剪是在拟合后删除节点，因此本质上CCP _阿尔法是使用最小_样本_叶子和最大_深度来防止过度拟合的替代方法。</p><p id="a24f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">节点的成本复杂度可以从拟合树中检索。较低的ccp阿尔法值表示较高的成本复杂度。通过移除具有小CCPα的节点，树被修剪，并且整体复杂性降低[7]。</p><p id="4dcc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了指示超参数调谐使用的CCPα的范围，最好将有效α与叶子的杂质可视化。注意，下面的分析来自RF的单个树。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/84937fe2d90e5e2a4b8ac14a3092b6a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t80rmhjGYlwN3tKZANyXdA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">总叶杂质与有效α的关系图</p></figure><p id="963f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当有效alpha从大约70下降到稍微超过20时，树的成本复杂性确实增加了，但是对于较低的alpha值，成本复杂性对叶子杂质的影响很难确定，让我们放大一点。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/21b0946f7c83fdb4f0d3e6d2cf4c224a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n0H6wLaIJgX-xDNkSozJuw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">总叶杂质与有效α的放大图</p></figure><p id="bcf5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当有效阿尔法从2下降到0时(成本复杂性达到最大值)，叶子杂质似乎减少了约50点，相当于约7个训练RMSE。鉴于我们的第一个RF的极端过拟合，这似乎是超参数调谐的合适范围。</p><h2 id="9e2c" class="nn mk jj bd ml nx ny dn mp nz oa dp mt lq ob oc mv lu od oe mx ly of og mz jp bi translated">最小杂质减少量</h2><p id="ed3a" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">最小杂质减少是一种测量方法，用于指示分离后误差的减少。杂质减少是一个加权值，计算如下:</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/5ca304a2391d1742ae6308f8fad6af0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sWhgXtw_GGO-54npvSSLjg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">计算杂质减少的公式[3]</p></figure><p id="6af9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">杂质减少通常是为单个决策树计算的。所以，我们先提取单棵树所需的数据。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="afb9" class="nn mk jj nj b gy no np l nq nr"># returns shape (227, 5)</span></pre><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi or"><img src="../Images/3a65d162ef6e58493ef7985937f8cabb.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*N4WGkNEE_PLMbRozweP32g.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">杂质结果_df.head(10)</p></figure><p id="54a3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在查看前几行时，您应该注意到一些child_id的值为-1。这表明父节点是一个叶节点，因此没有进行进一步的分割。</p><p id="1c59" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">利用数据帧中的所有数据，我们可以使用上述公式计算最小杂质减少量。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="300e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最好将结果可视化，以了解最小杂质减少的合适值。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi os"><img src="../Images/e8a8fae4d52cf7967d329da3b72815f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*wYz1Y3ac6lln2uERZQFXZA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">杂质减少直方图</p></figure><p id="3a4e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">杂质减少非常右偏，这可以通过树的前几个节点对减少误差贡献很大来解释。检查描述符显示25%的杂质减少值低于14.59，这似乎是最小杂质减少参数的合适上限。</p><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/cf7ae89c114802c852553ebbb336d2e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*qF0vizcBpsn0Js1Vt-KrqA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">杂质减少的描述性统计和放大直方图</p></figure><h1 id="0191" class="mj mk jj bd ml mm mn mo mp mq mr ms mt ky mu kz mv lb mw lc mx le my lf mz na bi translated">随机搜索</h1><p id="4c52" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">在研究完要优化的参数之后，我们现在可以设置合适的评估范围。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="7a52" class="nn mk jj nj b gy no np l nq nr"># returns<br/>1571724</span></pre><p id="644d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">注意，如果我们想测试所有可能的组合，我们必须适应超过150万个模型。乏味的任务。幸运的是，通过随机挑选60个独特的组合来应用Randomsearch应该可以得到95%的最优解[8]。</p><p id="3fb3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">增加迭代次数会增加找到更好解决方案的可能性。除了使用Randomsearch，我更喜欢保持较低的树数以加快训练时间。这种组合允许相对快速的搜索。</p><p id="af1c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我已经执行了几次搜索，选择了性能最好的设置。在展示代码之前，还有一件事需要讨论:我们需要创建验证集来验证所选择的超参数。</p><h2 id="7163" class="nn mk jj bd ml nx ny dn mp nz oa dp mt lq ob oc mv lu od oe mx ly of og mz jp bi translated">确认</h2><p id="dbba" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">为该数据创建验证集需要考虑一个重要因素。包含在训练集中的引擎不能包含在验证集中，反之亦然。</p><p id="bf01" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">通常，您会在数据中创建一个随机分割，其中80 %属于定型集，20 %属于验证集。然而，如果我们随机分割而不考虑单元号，我们可能会在训练集和验证集中结束单个引擎的部分数据。然后，该模型可以学习在时间步长之间进行外推，并对验证集进行非常准确的预测。然而，对于真正的新数据，模型性能会受到影响。</p><p id="3c5c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了防止这种形式的“数据泄漏”,我们必须确保将单个引擎的所有记录分配给训练集或验证集。为了实现这种形式的数据分割，我们将使用GroupKFold。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ou"><img src="../Images/ece103c960347e3f546db9319bc47c88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X6Oq6Wu0ddM9G8pgApTdXA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">随机搜索的打印进度</p></figure><p id="5b95" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">由于训练时间相对较短，我将迭代次数设置为300次。接下来，RandomizedSearchCV用裸RF、用于超参数调整的采样参数和GroupKFold实例化，其中组基于unit_nr。随机搜索需要不到15分钟的时间，我们可以将结果转换成数据帧以供进一步检查。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="mf mg mh mi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ov"><img src="../Images/4ee97817268fc7506503c60b127cd108.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dpRO_AEmJdyLH21JaiV5rg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">随机搜索的结果</p></figure><p id="b697" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">检查结果有助于了解哪些超参数表现良好，并有可能用于优化您的搜索空间(我们暂时不做讨论)。</p><p id="7149" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不幸的是，结果是不可重复的，这意味着重新启动内核并再次运行笔记本不会产生相同的结果。我将在下一篇分析中尝试解决这个问题。执行了几次搜索后，我找到的性能最好的参数集是:</p><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="8847" class="nn mk jj nj b gy no np l nq nr">{'min_samples_leaf': 11, 'min_impurity_decrease': 0.0, 'max_depth': 15, 'ccp_alpha': 0.125}.</span></pre><p id="8ca7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">平均测试分数为-16.577。</p><h1 id="7ad0" class="mj mk jj bd ml mm mn mo mp mq mr ms mt ky mu kz mv lb mw lc mx le my lf mz na bi translated">最终模型</h1><p id="f911" class="pw-post-body-paragraph lh li jj lj b lk nb kt lm ln nc kw lp lq nd ls lt lu ne lw lx ly nf ma mb mc im bi translated">使用这些参数，我们可以训练我们的最终模型。</p><figure class="mf mg mh mi gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><pre class="mf mg mh mi gt ni nj nk nl aw nm bi"><span id="174b" class="nn mk jj nj b gy no np l nq nr"># returns:<br/># train set RMSE:13.95446880579081, R2:0.8820190156933622<br/># test set RMSE:20.61288923394374, R2:0.7520472702746352</span></pre><p id="0b5b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在你有了它，一个没有特征工程(只有一些特征选择)但仍然有很好结果的调整随机森林。20.612的测试RMSE比我们的基线模型提高了7.65%。这可能看起来不多，但就RMSE而言，这个RF优于我们之前在FD001上拟合的时间序列模型(其RMSE为20.852)，而FD003是一个更复杂的数据集！</p><p id="1528" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">完整的笔记本你可以在这里查看我的github页面<a class="ae jg" href="https://github.com/kpeters/exploring-nasas-turbofan-dataset" rel="noopener ugc nofollow" target="_blank"/>。我要感谢迈克尔·格罗贝的意见和评论。<a class="ae jg" rel="noopener" target="_blank" href="/lagged-mlp-for-predictive-maintenance-of-turbofan-engines-c79f02a15329?sk=84c2225e20760c04e9f27234c3803175">下一次</a>，我们将使用Tensorflow深入研究更加复杂的FD002和神经网络。有任何问题或意见吗？请在下面的评论中告诉我！</p></div><div class="ab cl ow ox hx oy" role="separator"><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb"/></div><div class="im in io ip iq"><p id="9cc7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">参考文献<br/>【1】<a class="ae jg" rel="noopener" target="_blank" href="/the-importance-of-problem-framing-for-supervised-predictive-maintenance-solutions-cc8646826093?source=friends_link&amp;sk=ec51cbfa29f084ed94fe59d0daf51df0">监督预测维护解决方案问题框架的重要性</a><br/>【2】f . o . Heimes，“剩余使用寿命估计的递归神经网络”，<em class="md"> 2008年国际预测和健康管理会议</em>，丹佛，CO，2008，第1–6页，doi:10.1109/PHM . 2008 . 4711422 .<br/>【3】<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-https评估机器学习模型。奥莱利媒体公司2015</a></p></div></div>    
</body>
</html>