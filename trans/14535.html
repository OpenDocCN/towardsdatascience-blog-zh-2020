<html>
<head>
<title>Car Classification using Inception-v3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Inception-v3进行汽车分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/car-classification-using-inception-v3-71b63e9825b7?source=collection_archive---------20-----------------------#2020-10-07">https://towardsdatascience.com/car-classification-using-inception-v3-71b63e9825b7?source=collection_archive---------20-----------------------#2020-10-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8902" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">关于使用Monk训练3个模型来分类汽车的品牌、型号和年份，并通过Flask API部署它们的文章</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f9e4d0103347ed914f9ed545c5737003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TS_kqyO8xKjDmQdd"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">奥拉夫·特维特在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><h1 id="b75d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="7fec" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这篇文章是关于使用<a class="ae kv" href="https://github.com/Tessellate-Imaging/monk_v1" rel="noopener ugc nofollow" target="_blank"> Monk </a>训练3个深度卷积神经网络，这是一个计算机视觉的开源库，然后通过一个API部署它们。这些模型以汽车的图像作为输入，然后预测汽车的品牌、型号和年份。这些模型已经在<a class="ae kv" href="https://ai.stanford.edu/~jkrause/cars/car_dataset.html" rel="noopener ugc nofollow" target="_blank"> Cars数据集</a>上进行了训练。</p><p id="fd4e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于<strong class="lq ir">迁移学习</strong>，使用了带有预训练权重的<strong class="lq ir"> Inception-v3 </strong>架构。一些初始层被冻结，并且在剩余层上进行训练。</p><p id="add5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">训练之后，模型通过Flask API被<strong class="lq ir">部署</strong>。它通过POST请求接受图像，并将预测返回给用户。</p><p id="b1c8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于<strong class="lq ir">培训笔记本，</strong>勾选<a class="ae kv" href="https://github.com/PiyushM1/Car-make-model-and-year-classifier" rel="noopener ugc nofollow" target="_blank">本</a>。</p><p id="e625" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于<strong class="lq ir">烧瓶API，</strong>检查<a class="ae kv" href="https://github.com/PiyushM1/Car-classification-API" rel="noopener ugc nofollow" target="_blank">这个</a>。</p><h1 id="c9e4" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">目录</h1><ol class=""><li id="9b5f" class="mp mq iq lq b lr ls lu lv lx mr mb ms mf mt mj mu mv mw mx bi translated">安装Monk</li><li id="df40" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">数据集</li><li id="e80f" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">训练模型</li><li id="9e4d" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">培训结果</li><li id="a711" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">通过API部署模型</li><li id="6bbb" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">运行API</li><li id="7e60" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">结论</li></ol></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="f682" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">1.安装Monk</h1><p id="4373" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">Monk是一个开源的计算机视觉库。你不需要深入了解Python或任何深度学习框架就能使用它。它通过为流行的深度学习框架提供包装函数来简化计算机视觉，并使人们能够使用最少的代码来使用它们的功能。查看它的<a class="ae kv" href="https://github.com/Tessellate-Imaging/monk_v1" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>以获取更多信息。</p><p id="cb94" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">本文使用Monk库的PyTorch后端，但是如果您愿意，您可以安装任何其他版本的Monk。点击查看<a class="ae kv" href="https://github.com/PiyushM1/Car-make-model-and-year-classifier/blob/master/Car_make_model_year_classifier.ipynb" rel="noopener ugc nofollow" target="_blank">的详细安装说明。</a></p><ul class=""><li id="316c" class="mp mq iq lq b lr mk lu ml lx np mb nq mf nr mj ns mv mw mx bi translated"><strong class="lq ir"> CPU(非GPU) </strong> : <code class="fe nt nu nv nw b">pip install -U monk-pytorch-cpu</code></li><li id="18f0" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj ns mv mw mx bi translated"><strong class="lq ir">谷歌实验室</strong> : <code class="fe nt nu nv nw b">pip install -U monk-colab</code></li><li id="db9b" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj ns mv mw mx bi translated"><strong class="lq ir">卡格尔</strong> : <code class="fe nt nu nv nw b">pip install -U monk-kaggle</code></li><li id="96be" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj ns mv mw mx bi translated">对于支持<strong class="lq ir"> CUDA </strong>的版本，请遵循这里<a class="ae kv" href="https://github.com/PiyushM1/Car-make-model-and-year-classifier/blob/master/Car_make_model_year_classifier.ipynb" rel="noopener ugc nofollow" target="_blank">提供的说明</a>。</li></ul><p id="a518" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">要手动安装库<strong class="lq ir"/>，请遵循此处提供的说明<a class="ae kv" href="https://github.com/PiyushM1/Car-make-model-and-year-classifier/blob/master/Car_make_model_year_classifier.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="10b6" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">2.数据集</h1><p id="7f7d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">用于该任务的训练数据集是<a class="ae kv" href="https://ai.stanford.edu/~jkrause/cars/car_dataset.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir"> Cars数据集</strong> </a>。它包含196类汽车的16，185张图片。级别通常在<em class="nx">品牌、型号、年份</em>级别，例如特斯拉Model S 2012或宝马M3 coupe 2012。数据集附带一个devkit，其中包含每张图像的标签，以及汽车周围边界框的坐标。但是我们只用标签。这里给出的代码打算在python笔记本中运行。</p><p id="ee49" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">下载数据集:</strong></p><pre class="kg kh ki kj gt ny nw nz oa aw ob bi"><span id="8e29" class="oc kx iq nw b gy od oe l of og"><em class="nx"># Create a directory for the dataset</em><br/>! mkdir data</span><span id="5f14" class="oc kx iq nw b gy oh oe l of og"><em class="nx"># Download train dataset and extract it<br/></em>! wget "http://imagenet.stanford.edu/internal/car196/cars_train.tgz"<br/>! tar -xvf 'cars_train.tgz' -C 'data'</span><span id="5b64" class="oc kx iq nw b gy oh oe l of og"><em class="nx"># Download test dataset and extract it<br/></em>! wget "http://imagenet.stanford.edu/internal/car196/cars_test.tgz"<br/>! tar -xvf 'cars_test.tgz' -C 'data'</span><span id="32a7" class="oc kx iq nw b gy oh oe l of og"><em class="nx"># Download the devkit and extract it</em><br/>! wget "https://ai.stanford.edu/~jkrause/cars/cars_devkit.tgz"<br/>! tar -xvf 'cars_devkit.tgz' -C 'data'</span></pre><p id="2ab6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">准备标签:</strong></p><p id="b5ba" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">准备标签所需的devkit中的文件:</p><ul class=""><li id="afb0" class="mp mq iq lq b lr mk lu ml lx np mb nq mf nr mj ns mv mw mx bi translated"><strong class="lq ir"> cars_meta.mat </strong>:包含类名的单元格数组，每个类一个。</li><li id="8f59" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj ns mv mw mx bi translated"><strong class="lq ir"> cars_train_annos.mat </strong>:包含变量‘annotations’，其中每个元素都有边界框的坐标，字段‘class’是图像的整数类id，字段‘fname’是图像文件夹中图像的文件名。</li></ul><p id="3ab9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">要为培训准备标签:</p><ul class=""><li id="b95a" class="mp mq iq lq b lr mk lu ml lx np mb nq mf nr mj ns mv mw mx bi translated">首先，我们处理文件<strong class="lq ir"> cars_meta.mat </strong>来分离每个类id的品牌、型号和年份。</li><li id="0f47" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj ns mv mw mx bi translated">然后，我们处理文件<strong class="lq ir"> cars_train_annos.mat </strong>，为数据集中的每个图像分配标签，包括品牌、型号和年份。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><ul class=""><li id="e7f8" class="mp mq iq lq b lr mk lu ml lx np mb nq mf nr mj ns mv mw mx bi translated">从<a class="ae kv" href="http://imagenet.stanford.edu/internal/car196/cars_test_annos_withlabels.mat" rel="noopener ugc nofollow" target="_blank">此处</a>下载<strong class="lq ir">cars _ test _ annos _ with labels . mat</strong>后，可以按照类似的程序给测试图像分配标签。</li><li id="5be7" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj ns mv mw mx bi translated"><strong class="lq ir">或者</strong>，准备好的csv文件可以从<a class="ae kv" href="https://github.com/PiyushM1/Car-make-model-and-year-classifier/tree/master/Labels" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</li></ul><p id="b58a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">目录结构:</strong></p><pre class="kg kh ki kj gt ny nw nz oa aw ob bi"><span id="3b6c" class="oc kx iq nw b gy od oe l of og">./Project_directory/<br/>|<br/>|-------data (for dataset)<br/>|         |<br/>|         |------cars_test<br/>|         |         |----------00001.jpg<br/>|         |         |----------........(and so on)<br/>|         |------cars_train<br/>|         |         |----------00001.jpg<br/>|         |         |----------........(and so on)<br/>|         |------devkit<br/>|         |         |----------cars_meta.mat<br/>|         |         |----------cars_train_annos.mat<br/>|         |         |----------........(and other files)<br/>|                               _<br/>|------vehicles_make.csv         |<br/>|------vehicles_model.csv        |  (csv files with labels)<br/>|------vehicles_year.csv        _|<br/>|<br/>|------.......(and other files/folders)</span></pre></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="2235" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">3.训练模型</h1><p id="1b2b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">当使用<a class="ae kv" href="https://github.com/Tessellate-Imaging/monk_v1" rel="noopener ugc nofollow" target="_blank">和尚</a>时，实验模型变得非常容易。通过更改几个参数，我们可以很快看到它如何影响模型的整体性能。这也加快了原型制作的速度。</p><p id="c85b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们将使用Monk的PyTorch后端。但是，Keras和MXNet-gluon后端也是可用的。</p><p id="0311" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在这里，我将解释训练<strong class="lq ir"> Make分类器</strong>的程序。其他两个分类器可以用类似的方式训练。你可以在这里找到整个训练笔记本<a class="ae kv" href="https://github.com/PiyushM1/Car-make-model-and-year-classifier/blob/master/Car_make_model_year_classifier.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="8f99" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">导入并打开一个项目:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="96d8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">分配数据集:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="682d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">设置模型参数:</strong></p><p id="7d54" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们将用预训练的权重加载<strong class="lq ir"> Inception-v3 </strong>模型，以便使用<strong class="lq ir">迁移学习</strong>来训练分类器。当训练数据集不够大时，这通常会使模型表现得更好。</p><p id="72e3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我也尝试过训练ResNet-50模型，但是它的性能远不如Inception-v3。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="c6f2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">设置训练参数:</strong></p><p id="761f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在，我们将为5个时期训练模型。如果学习率和其他超参数足够好，训练可以从最后一个时期继续。我们将使用<strong class="lq ir"> softmax交叉熵</strong>作为损失函数，因为它通常对分类任务非常有用。对于乐观者来说，我已经试验了随机梯度下降，但是<strong class="lq ir"> RMSProp </strong>似乎表现得更好。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="9e8a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">培训:</strong></p><p id="a378" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这将把在每个时期之后获得的模型连同一些与训练相关的附加信息一起保存到工作空间目录中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="23a7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">运行<code class="fe nt nu nv nw b">ptf.Summary()</code>可获得培训的详细总结。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="f7cf" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">4.培训结果</h1><p id="eb51" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们将对整个测试数据运行模型以获得测试准确性，然后对一些单独的图像运行它们。</p><p id="fcd3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">根据测试数据评估模型:</strong></p><p id="a892" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下面的代码返回了总体测试精度以及基于类的单个精度，这可以用来获得关于其性能的一些有用的见解。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="8dfa" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">运行部分图像的训练模型:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="5c33" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">获得的结果:</strong></p><p id="e359" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在8，041幅图像的全部测试数据上评估模型。验证集与原始训练数据集有20%的差异。模型获得的精度:</p><ol class=""><li id="b92a" class="mp mq iq lq b lr mk lu ml lx np mb nq mf nr mj mu mv mw mx bi translated">制作分类器:最佳验证准确率:94.72%。测试准确率:84.27%</li><li id="73d7" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">模型分类器:<strong class="lq ir"> </strong>最佳验证准确率:96.50%。测试准确率:83.99%</li><li id="1300" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">年分类器:<strong class="lq ir"> </strong>最佳验证准确率:94.17%。测试准确率:83.19%</li></ol><div class="kg kh ki kj gt ab cb"><figure class="ok kk ol om on oo op paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/ecc0b2e0e10032e6e10d6f9b0dfd7311.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*x0qZfL_7cXg9v2-Zd8vA9Q.png"/></div></figure><figure class="ok kk oq om on oo op paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/1d262121005916aefb68bc70ad247b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*Q8_47ycKFvGUTp8iimD6ww.png"/></div></figure><figure class="ok kk or om on oo op paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/d2b96f19686068dd31ed92e034bff57d.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*vw7BWDryXwvu6eUUY3dhkg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk os di ot ou translated">从测试数据获得的图像预测</p></figure></div></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="55c8" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">5.通过API部署模型</h1><p id="374f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">当使用Monk训练模型时，它会自动创建一个工作空间目录。它包含所有的训练日志和在训练期间获得的所有中间模型。为了开发API，我们只需要最终的模型具有与创建它们时相同的目录结构。如果你已经训练了你的模型，你可以使用它们。否则，你可以从<a class="ae kv" href="https://github.com/PiyushM1/Car-classification-API/tree/master/workspace" rel="noopener ugc nofollow" target="_blank">这里</a>下载最终模型的工作空间。</p><p id="64fd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果只是想测试API，就勾选<a class="ae kv" href="https://github.com/PiyushM1/Car-classification-API" rel="noopener ugc nofollow" target="_blank">这个</a>。自述文件中有设置环境的详细说明。</p><p id="34f9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在项目目录中创建一个名为“uploads”的子目录，用户上传的文件将在返回预测之前保存在其中。设置<a class="ae kv" href="https://docs.python.org/3/tutorial/venv.html" rel="noopener ugc nofollow" target="_blank">虚拟环境</a>并安装所需的库。虚拟环境不是必需的，但建议使用。从<a class="ae kv" href="https://github.com/PiyushM1/Car-classification-API/blob/master/requirements.txt" rel="noopener ugc nofollow" target="_blank">这里</a>下载requirements.txt文件并运行<code class="fe nt nu nv nw b">pip install -r requirements.txt</code></p><p id="1985" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在工作区所在的项目目录下创建一个名为<strong class="lq ir"> app.py </strong>的文件。我们将在这个文件中编写API的代码。</p><p id="e484" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">导入和实用功能:</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="1db4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">响应HTTP请求的函数:</strong></p><p id="1731" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我已经为API提供了一个用户界面，但这不是必需的。如果你也想使用它，将<a class="ae kv" href="https://github.com/PiyushM1/Car-classification-API/tree/master/static" rel="noopener ugc nofollow" target="_blank">这个</a>和<a class="ae kv" href="https://github.com/PiyushM1/Car-classification-API/tree/master/templates" rel="noopener ugc nofollow" target="_blank">这个</a>目录下载到项目目录中，然后定义下面给出的index()函数，使API在通过浏览器访问时加载网页。</p><p id="2a11" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">upload()函数在“/predict”处响应POST请求，将其保存到名为“uploads”的子目录中，如果文件是有效的图像，则返回带有预测的字符串。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="35de" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">驱动功能:</strong></p><p id="60dc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">它加载模型并启动服务器。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div></figure></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="3ac5" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">6.运行API</h1><p id="8919" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">使用终端中的命令<code class="fe nt nu nv nw b">python3 app.py</code>运行应用程序。</p><p id="3bd9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">一旦服务器启动，您就可以通过使用cURL发送POST请求来测试API。为此，如果您还没有cURL，那么您首先需要安装它。然后，通过您的终端，在用图像的有效路径替换了<image_path>之后，运行下面的命令。</image_path></p><p id="1dbe" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><code class="fe nt nu nv nw b">curl -X POST -F file=@'&lt;image_path&gt;' ‘http://0.0.0.0:5000/predict'</code></p><p id="dbc9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这将把预测返回到您的终端本身。</p><p id="c0ea" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">或者</strong>，您可以在您的浏览器中进入<a class="ae kv" href="http://0.0.0.0:5000/" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir">http://0 . 0 . 0:5000</strong></a>查看用户界面。然后使用“选择”按钮上传任何图像，并单击“预测”。然后它会返回这样一个预测:</p><div class="kg kh ki kj gt ab cb"><figure class="ok kk ov om on oo op paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/6776fb10c114868fa4d072c52f7a72ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*w8fx5LONXTUGANz3Ghdpuw.png"/></div></figure><figure class="ok kk ov om on oo op paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/0a1bae7b24acb4f84c8568f4f6bb21a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qc7xJ0DjS3cC0rLcPV-R9g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk ow di ox ou translated">API的用户界面</p></figure></div></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="9665" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">7.结论</h1><p id="4b18" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">本文涵盖了整个过程，包括数据准备、训练图像分类模型，以及最终通过Flask API部署它们。我们还使用了数据标准化、随机水平翻转、迁移学习、自定义优化器、学习率和损失函数。根据测试数据评估模型，它们表现得非常好，准确率接近85%。然而，我对年份分类器具有如此好的准确性感到有点困惑，因为确实没有任何明显的特征可以帮助预测汽车的制造年份。我不确定仅仅用图像来预测年份是否是个好主意。</p><p id="60cd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">你也应该尝试调整一些超参数，或者使用不同的模型架构，看看它会怎么样。也可以用Monk同时测试模型或超参数的多个组合，点击<a class="ae kv" href="https://github.com/Tessellate-Imaging/monk_v1" rel="noopener ugc nofollow" target="_blank">查看</a>。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="62c4" class="kw kx iq bd ky kz nk lb lc ld nl lf lg jw nm jx li jz nn ka lk kc no kd lm ln bi translated">参考资料:</h1><ol class=""><li id="fa43" class="mp mq iq lq b lr ls lu lv lx mr mb ms mf mt mj mu mv mw mx bi translated">培训笔记本的GitHub存储库:<a class="ae kv" href="https://github.com/PiyushM1/Car-make-model-and-year-classifier" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/piyu shm 1/Car-make-model-and-year-classifier</a></li><li id="ee2f" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">API的GitHub存储库:<a class="ae kv" href="https://github.com/PiyushM1/Car-classification-API" rel="noopener ugc nofollow" target="_blank">https://github.com/PiyushM1/Car-classification-API</a></li><li id="55a8" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">数据集:<a class="ae kv" href="https://ai.stanford.edu/~jkrause/cars/car_dataset.html" rel="noopener ugc nofollow" target="_blank">https://ai.stanford.edu/~jkrause/cars/car_dataset.html</a></li><li id="267c" class="mp mq iq lq b lr my lu mz lx na mb nb mf nc mj mu mv mw mx bi translated">僧库:<a class="ae kv" href="https://github.com/Tessellate-Imaging/monk_v1" rel="noopener ugc nofollow" target="_blank">https://github.com/Tessellate-Imaging/monk_v1</a></li></ol><p id="f150" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">感谢阅读！如果你觉得这篇文章有帮助，请告诉我。我们通过<a class="ae kv" href="https://www.linkedin.com/in/piyushmaheshwari1/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>来连线。</p></div></div>    
</body>
</html>