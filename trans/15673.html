<html>
<head>
<title>Computer Vision: Intuition behind Panorama Stitching</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉:全景拼接背后的直觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/computer-vision-intuition-behind-panorama-snitching-5c4be7205426?source=collection_archive---------30-----------------------#2020-10-28">https://towardsdatascience.com/computer-vision-intuition-behind-panorama-snitching-5c4be7205426?source=collection_archive---------30-----------------------#2020-10-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/6f6d616bdbf7ca7b3c302f12edb7f628.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*hb6VY2AkslRvHpqOvFKUAQ.jpeg"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">田纳西州了望山顶的景色(1864年)来源:<a class="ae iz" href="https://en.wikipedia.org/wiki/Panoramic_photography" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Panoramic_photography</a></p></figure><div class=""/><p id="3388" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">全景拼接的工作原理有4个主要部分。在这篇文章中，我将给出一个非常简短的概述，能够充分(希望)建立图像拼接工作背后的直觉。这也意味着我很可能会跳过任何数学概念和计算。</p><ol class=""><li id="f8dc" class="kx ky jc kb b kc kd kg kh kk kz ko la ks lb kw lc ld le lf bi translated"><strong class="kb jd">探测兴趣点</strong></li><li id="4b74" class="kx ky jc kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated"><strong class="kb jd">描述这些兴趣点</strong></li><li id="c4c6" class="kx ky jc kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated"><strong class="kb jd">匹配我们兴趣点的这些描述符</strong></li><li id="c2d7" class="kx ky jc kb b kc lg kg lh kk li ko lj ks lk kw lc ld le lf bi translated"><strong class="kb jd">执行单应完成拼接</strong></li></ol><h1 id="36ce" class="ll lm jc bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">1.检测兴趣点</h1><p id="c348" class="pw-post-body-paragraph jz ka jc kb b kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks mn ku kv kw ij bi translated">当我们在图像中寻找兴趣点时，有几个特征。它们是:</p><p id="8098" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb jd"> a)可重复的兴趣点</strong></p><p id="5329" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们希望能够找到图像中的特征，这些特征最终可以告诉我们同一场景的不同图像之间的匹配位置(从附近的视点)。</p><p id="79f3" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb jd"> b)兴趣点的独特性</strong></p><p id="524a" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们希望能够可靠地确定一幅图像中的哪个兴趣点与另一幅图像中的相应兴趣点相匹配。</p><p id="2213" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb jd"> c)缩放和旋转不变性</strong></p><p id="c205" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们希望能够找到相同的兴趣点，即使图像被旋转、缩放或平移。</p><p id="36b6" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb jd"> d)地点</strong></p><p id="8299" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">局部特征将使我们对感兴趣点的检测对杂乱和遮挡更加鲁棒。</p><div class="mo mp mq mr gt ab cb"><figure class="ms is mt mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><img src="../Images/6a922eab5c8ebf329ead96e38fe60618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*gjroJVylToODYp-VKWlJoA.png"/></div></figure><figure class="ms is nc mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><img src="../Images/79bfff74fd8c15011584c61ed75fcfa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*9E8LANjkO2J2neduutxihw.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk nd di ne nf translated">图一。我的mac默认背景截图。</p></figure></div><p id="4a14" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">想象上面的两张图片(图1)，很容易看出，如果我们选择海洋作为兴趣点，很难将左侧图像中的海洋与右侧图像中的海洋特别匹配(因为海洋在大范围的空间中看起来是相同的)。我们还注意到，选择诸如小石峰(橙色圆圈)的区域能够为我们以后的匹配提供更有价值的信息。</p><p id="8445" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">事实证明，角实际上是一个非常好的特征，可以作为兴趣点！有一种叫做Harris角点检测器的算法，可以帮助我们在图像中找到这样的角点作为兴趣点。</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ng"><img src="../Images/78c0151f90b23010a2e69943bc4c48f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y9OORjjYQ0PgsDNhD0pl1g.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">哈里斯角探测器</p></figure><blockquote class="nh ni nj"><p id="9f68" class="jz ka nk kb b kc kd ke kf kg kh ki kj nl kl km kn nm kp kq kr nn kt ku kv kw ij bi translated">注意，哈里斯角点检测器只是帮助我们找到这些兴趣点的众多算法之一。还有其他方法，例如SIFT，它使用高斯差分(DoG)来检测不同尺度的兴趣点。我个人认为这篇文章很值得一读。在后面的部分中理解SIFT很重要，因为我们将使用SIFT描述符来描述我们发现的兴趣点。</p></blockquote><p id="2e92" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">本质上，在取局部最大值(非最大值抑制)的点之前，Harris角点算法从图像的梯度计算角点分数(使用二阶矩H矩阵)并将高于设定阈值的值标记为角点。哈里斯角对于旋转(因为H矩阵的特征值即使在旋转之后也保持不变)、平移和强度的附加变化是不变的。然而，它对于强度的缩放和比例不是不变的。为了使Harris角点在尺度上保持不变，我们需要一个额外的自动尺度选择步骤来找到一个给出我们的角点分数的局部最大值的尺度。</p><p id="137f" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">总结一下从图像中检测兴趣点的第一部分，角是兴趣点的良好表示，可以使用Harris角检测器找到。</p><h1 id="5626" class="ll lm jc bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">2.描述我们的兴趣点</h1><p id="0178" class="pw-post-body-paragraph jz ka jc kb b kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks mn ku kv kw ij bi translated">描述符基本上是以数学方式描述图像中某个区域的矢量表示。描述符也应该对旋转、缩放和平移不变。我将直接进入SIFT描述符，我们可以在我们的Harris角点检测器发现的兴趣点上使用它。</p><p id="d706" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">尺度不变特征变换<a class="ae iz" href="https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf" rel="noopener ugc nofollow" target="_blank"> (SIFT) </a>由David Lowe于2004年发表。如果他的论文太难阅读，你可以参考<a class="ae iz" href="https://aishack.in/tutorials/sift-scale-invariant-feature-transform-features/" rel="noopener ugc nofollow" target="_blank">这里的</a>快速阅读SIFT。SIFT实际上是一种检测兴趣点并描述它们算法。然而，在这种情况下，我将只关注描述符本身。</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/6f24a91374954fee81aacf0e2ba5e601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*UqSlKFwKeXvkS3Hx-nst7g.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">图2(显示了缩小的版本)。鸣谢:理查德·塞利斯基</p></figure><p id="d137" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">SIFT描述符的基本功能是在检测到的兴趣点周围提取一个16x16的窗口(图2)，然后将其划分为一个4x4的单元网格。在由高斯函数加权的窗口中的每个像素处计算梯度方向和幅度。然后，在每个单元中计算具有8个面元的加权梯度方向直方图(方向由其幅度加权)。最后，我们将这些直方图折叠成一个128(16×8)维的向量(每个向量有16个4×4的单元，每个单元有8个面元)。</p><p id="4c04" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">单元的划分给描述符一种空间知识的感觉，而主方向对直方图宁滨的移动使得描述符旋转不变。我们可以将最终向量归一化为单位长度，基于阈值箝位值，并再次重新归一化，以使其对光照变化相对更鲁棒。</p><p id="5e90" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">总而言之，SIFT对于一个描述符来说是非常健壮的。它对比例和旋转是不变的，可以处理视点的变化(高达60度的平面外旋转)并且可以处理照明的显著变化。</p><p id="1119" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，我们已经通过Harris角点找到了我们的兴趣点，并使用SIFT描述符将这些兴趣点描述为一个区域。现在剩下的是形成不同点之间的匹配，并执行单应性以将不同的图像缝合在一起以形成全景图！</p><h1 id="5a56" class="ll lm jc bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">3.匹配我们兴趣点的描述符</h1><p id="9508" class="pw-post-body-paragraph jz ka jc kb b kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks mn ku kv kw ij bi translated">为了在两幅图像的描述符之间形成匹配，我们使用最佳匹配的距离/第二最佳匹配的距离的比率距离方法。</p><div class="mo mp mq mr gt ab cb"><figure class="ms is np mu mv mw mx paragraph-image"><img src="../Images/7723db29f628857619f919a2a5fc770c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ZxQTEwZ_uI52K1g_123siw.jpeg"/></figure><figure class="ms is np mu mv mw mx paragraph-image"><img src="../Images/43fdd6b3e0476f8712a5473d781e3a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*4dgst889nI61RA4ULQ4ufw.jpeg"/><p class="iv iw gj gh gi ix iy bd b be z dk nq di nr nf translated">图3。图片来自Unsplash。作者:<a class="ae iz" href="https://unsplash.com/@ishanwaza" rel="noopener ugc nofollow" target="_blank">伊山·瓦扎尔瓦</a></p></figure></div><p id="c91c" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在图3中，如果我们只使用目标和最佳匹配的绝对距离(这里的距离指的是描述符的相似性——如果它们非常相似，那么距离就很小，反之亦然)，很容易看到有多个模糊匹配可用(这里有许多类似的栅栏作为图像中的兴趣点，因此，我们不能确定最佳匹配是要匹配的正确特征)。</p><p id="c57e" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">为了拒绝这些不明确的匹配，我们使用比率方法—接近1的高值表明匹配是不明确的，因为到最佳匹配的距离非常接近到第二最佳匹配的距离。然后，我们设置一个阈值(通常在0.5-0.7左右)，并接受低于该阈值的匹配。换句话说，我们拒绝包含高度不确定性的匹配——在图3的情况下，不确定性很高，因为许多木质尖端靠近目标。</p><h1 id="47fa" class="ll lm jc bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">4.执行单应</h1><blockquote class="nh ni nj"><p id="8922" class="jz ka nk kb b kc kd ke kf kg kh ki kj nl kl km kn nm kp kq kr nn kt ku kv kw ij bi translated">维基百科对单应性的解释是这样的:在<a class="ae iz" href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>领域，空间中同一平面的任意两幅图像都是通过一个<a class="ae iz" href="https://en.wikipedia.org/wiki/Homography" rel="noopener ugc nofollow" target="_blank"> <strong class="kb jd">单应性</strong> </a> <strong class="kb jd">联系起来的。</strong></p></blockquote><p id="ebbc" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">一旦我们能够想象当我们试图把不同的图像拼接在一起时，我们试图做什么，就很容易理解单应性。想象两个场景。</p><p id="731f" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">(1)-每次拍摄照片时向左移动一步，同时保持相机不动。</p><p id="0c71" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">(2)-站在固定的位置，手持相机旋转身体，并在旋转的同时拍摄不同的照片。</p><p id="0622" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果我们想将(1)中的图像拼接在一起，我们可以简单地将一张照片叠加在序列中的另一张照片上，并获得良好的效果。然而，在(2)中，如果我们想要通过简单地将图像依次叠加在另一个的顶部来将图像拼接在一起，我们将意识到拼接的结果是不好的(由于所捕获的图像的不同平面，区域将被遗漏)。因此，我们需要单应映射将一幅图像投影到另一幅图像的同一平面上，然后将它们拼接在一起。</p><p id="8525" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">接下来，您可以将单应性基本上视为一个矩阵——一个将点从一个图像转换到同一平面的另一个图像的矩阵。那么下一个问题是我们如何求解单应矩阵H？</p><p id="bf77" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们使用<a class="ae iz" href="https://en.wikipedia.org/wiki/Direct_linear_transformation" rel="noopener ugc nofollow" target="_blank">直接线性变换(DLT) </a>并通过计算<a class="ae iz" href="https://en.wikipedia.org/wiki/Singular_value_decomposition" rel="noopener ugc nofollow" target="_blank">奇异值分解(SVD) </a>来求解H，该计算最少需要4次对应。我将跳过数学，但如果你感兴趣的话，可以随意查阅。</p><p id="d3f6" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，DLT可以在噪声环境中产生坏的结果，因为DLT是线性最小二乘估计，其考虑了我们的匹配中的坏的离群值。(注意，即使我们在前面的步骤中在匹配描述符时设置了阈值，仍然有可能出现不正确的匹配)。然后，我们可以使用随机样本一致性(RANSAC)产生更稳健的结果，其中我们在H矩阵的计算中仅包括内联体(近似正确的匹配)。然后，我们利用DLT和RANSAC给我们更好的结果。</p><p id="fd3a" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">一旦我们解决了单应矩阵，我们就可以使用矩阵计算从图像A到图像B的点，并很好地扭曲它以完成我们的全景拼接！</p><h1 id="27cc" class="ll lm jc bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated"><strong class="ak">结论</strong></h1><p id="9e16" class="pw-post-body-paragraph jz ka jc kb b kc mj ke kf kg mk ki kj kk ml km kn ko mm kq kr ks mn ku kv kw ij bi translated">在这里，我简要介绍了全景拼接的工作原理。具体来说，我谈到了使用Harris角点来检测作为兴趣点的角点，使用SIFT描述符来描述我们的兴趣点周围的区域，我们如何匹配这些描述符，以及我们如何计算单应性来形成不同图像的拼接。请注意，由于这是一个简短的概述，我有意省略了数学细节，并试图不要深入每个特定的算法/概念，因为我的目标是建立整个概念背后的直觉！</p><p id="768f" class="pw-post-body-paragraph jz ka jc kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">还有，这其实是我第一篇关于medium的文章！我希望你喜欢这篇文章，并从这篇文章中学到了一些东西。谢谢！</p><h2 id="06bd" class="ns lm jc bd ln nt nu dn lr nv nw dp lv kk nx ny lz ko nz oa md ks ob oc mh od bi translated">参考</h2><ul class=""><li id="f9dd" class="kx ky jc kb b kc mj kg mk kk oe ko of ks og kw oh ld le lf bi translated"><a class="ae iz" href="https://aishack.in/tutorials/harris-corner-detector/" rel="noopener ugc nofollow" target="_blank">https://aishack.in/tutorials/harris-corner-detector/</a></li><li id="092b" class="kx ky jc kb b kc lg kg lh kk li ko lj ks lk kw oh ld le lf bi translated"><a class="ae iz" href="https://aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/" rel="noopener ugc nofollow" target="_blank">https://ai shack . in/tutorials/sift-scale-invariant-feature-transform-introduction/</a></li><li id="2ed4" class="kx ky jc kb b kc lg kg lh kk li ko lj ks lk kw oh ld le lf bi translated">https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf<a class="ae iz" href="https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf" rel="noopener ugc nofollow" target="_blank"/></li><li id="b64c" class="kx ky jc kb b kc lg kg lh kk li ko lj ks lk kw oh ld le lf bi translated">【https://en.wikipedia.org/wiki/Direct_linear_transformation T4】</li><li id="939c" class="kx ky jc kb b kc lg kg lh kk li ko lj ks lk kw oh ld le lf bi translated"><a class="ae iz" href="https://en.wikipedia.org/wiki/Singular_value_decomposition" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Singular_value_decomposition</a></li></ul><h1 id="aeb4" class="ll lm jc bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">感谢阅读！我希望你喜欢它，这篇文章对你有帮助！</h1></div></div>    
</body>
</html>