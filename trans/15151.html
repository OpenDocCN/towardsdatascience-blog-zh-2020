<html>
<head>
<title>K-nearest neighbor</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-最近邻</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-nearest-neighbor-85bd50ea3e4d?source=collection_archive---------30-----------------------#2020-10-18">https://towardsdatascience.com/k-nearest-neighbor-85bd50ea3e4d?source=collection_archive---------30-----------------------#2020-10-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1b0f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">邻居很重要！！</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b1c4140a374750e42c469d52b05a16f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ia7OW4xhluKs_oknjeyuDw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://www.pexels.com/photo/variety-of-food-2952869/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae kv" href="https://www.pexels.com/@enginakyurt?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Engin Akyurt </a>拍摄</p></figure><h2 id="b7a2" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">介绍</h2><p id="22c4" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">KNN或k-最近邻是一种监督学习算法。它可以应用于回归和分类问题的解决。KNN是一种基于其最近样本来识别样本空间中任何特定点的类别或类标签的技术。KNN中的字母k表示我们将在邻域中考虑多少样本，以预测我们在样本空间中关注点的类别标签。</p><p id="feb0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">KNN也被称为基于实例的学习算法<strong class="lu ir">。在基于实例的学习中，当我们获得训练样本时，我们不会处理它们并学习模型，而是存储训练样本，当我们需要对实例进行分类时，我们会对测试样本进行训练和类标签关联。所以基于实例的学习算法也被称为<strong class="lu ir">懒惰算法</strong>。</strong></p><h2 id="cd9e" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">分类中的KNN</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/ff31648013d5d0a2d556400ab4dbb462.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*FI5b_apTup8iniaaqjk5PA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="b948" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我们被给予不同的样本点(x₁,y₁),(x₂,y₂),(x₃,y₃),…..,(xₙ,yₙ).所有这些点都被归入类标签1或类标签2。我们引入一个点(xₜ,yₜ)and想预测它的类标签。因此，我们使用KNN方法，并遵循以下步骤。</p><p id="6afa" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">第一步:选择k的值</strong></p><p id="15d0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我们可以决定k的值，它将决定我们需要考虑的预测测试sample(xₜ,yₜ).值的最近样本的总数在我们的例子中，我们考虑k=5。</p><p id="2a77" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">第二步:计算距离</strong></p><p id="dd6f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用欧几里得距离公式确定5个最接近的样品w.r.t测试样品。对于任意两个给定点，欧几里德距离使用以下公式计算</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/23378b61cc32e532353ef1f2c4254908.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*P1t-1l0kBbM0aCQaXTmeyA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="98b9" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">步骤3:根据类别对最近的点进行分类</strong></p><p id="ef6f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">从图中可以观察到，在5个最近的点中，它们中的3个属于类别label-2，它们中的两个属于类别label-1。因此，根据大多数情况，可以得出结论，点(xₜ,yₜ)属于类label-2。</p><h2 id="4380" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">回归中的KNN</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/dd1535743dbae9321c19c8e4c9f25a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*pfjmVA4BwwfMQJPnjL2Hcg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="f4cf" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在KNN回归的情况下，我们将使用与分类几乎相同的方法。只有第3步有所不同，在这一步中，我们不会为测试样本取多数类别标签。相反，我们将取所有类标签的平均值，并将该值设置为测试样本的类标签。例如，在上图中，我们考虑k=5来确定测试样本的类别标签。通过使用距离公式，我们识别5个最近的训练样本点，并识别它们的类别标签。因为这是一个回归问题，所以所有5个训练样本的类别标签是相似的。因此，取所有测试样本的类别标签的平均值，就得到测试样本的类别标签。</p><h2 id="67ff" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">属性和权重</h2><p id="9fbe" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我们看到每个样本点都有自己的x和y坐标。但是除了坐标之外，还有代表样本空间中的点的特征或属性。这些属性也非常有助于将点分成各种类别标签。因此，在寻找最近的k点时，也必须从所有这些属性计算欧几里德距离。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/2c12e051282ee911f06f555ebed49cee.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*QiccgFo96JhOJIksDImZMw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="bdc2" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">现在我们知道我们考虑回归KNN问题的类别标签的平均值。当我们考虑k的大值时，那么在分类过程中有必要取类别标签的平均值，而不是多数考虑。以下是一些原因:</p><ol class=""><li id="9d87" class="mt mu iq lu b lv ml ly mm lf mv lj mw ln mx mk my mz na nb bi translated">属性中的噪声——由于噪声的存在，距离测试样本最近的样本点可能无法捕捉到测试样本的所有特征，而稍远的点可能能够捕捉到。</li><li id="efd1" class="mt mu iq lu b lv nc ly nd lf ne lj nf ln ng mk my mz na nb bi translated">类别标签中的噪声——由于类别标签中存在噪声，测试样本的错误分类几率很高</li><li id="cc2e" class="mt mu iq lu b lv nc ly nd lf ne lj nf ln ng mk my mz na nb bi translated">部分重叠的类别标签-类别标签的重叠导致算法无法分配样本测试点的正确类别标签。</li></ol><p id="2073" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">你有没有想过为什么我们不考虑属性的权重？如果认为所有属性的权重相等，则以下关于样本空间的假设将成立:</p><ol class=""><li id="329e" class="mt mu iq lu b lv ml ly mm lf mv lj mw ln mx mk my mz na nb bi translated">所有属性都具有相同的比例。拥有相同的尺度意味着所有的属性都使用相同的单位来测量，也就是说，用厘米和英尺来测量学生的身高是不相关的。</li><li id="5d97" class="mt mu iq lu b lv nc ly nd lf ne lj nf ln ng mk my mz na nb bi translated">所有属性的范围必须相同。例如，所有属性的值必须从0到100变化，而不是从0到1000。</li></ol><h2 id="405d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">限制</strong></h2><p id="c6dd" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated"><strong class="lu ir">不平衡</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8dcf676a9bf059a687ad9a41ae2c4572.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*aFFLUf5A-PyeNvjPOSSwZA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="8a82" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">考虑样本空间中的一种情况，其中大约有1000个点被分类为A类或b类。假设1000个点中有800个点属于A类，这表明数据集高度不平衡。这会影响新测试样本的分类吗？是的，肯定的！！考虑我们想要在样本空间中找到点X的类标签。如果我们认为k值非常大，比如大约150，那么不平衡的数据集将迫使点X落入A类，这可能导致错误分类。</p><p id="d8f8" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">异常值</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8878e84c3f5726c9a93e2870f440e690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*upgpzUupwlyB_z74dbJCxA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0061" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">考虑上面的图像具有属于类别1的异常值。假设我们想要预测1类标记异常值和2类标记训练点之间的点。测试点可能属于类别2标签，但由于类别1异常值的存在，这些点可能会被错误地分类到类别1中。</p><p id="d917" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">因此，KNN的局限性在于，由于不平衡或异常数据集的存在，它可能会对点进行错误分类。</p><h2 id="96cc" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">如何选择K的最佳值？</h2><p id="91ca" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">k的最佳值是提供最小误差和最大精度的值。我们集中于为k取一组随机的值，并且在训练和测试模型时验证我们获得最小错误率的k值。</p><h2 id="02be" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">编码和学习</h2><p id="1e35" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我们现在来看看Kaggle著名的Pima Indian糖尿病数据集任务，以便更好地理解KNN分类。这里，在给定的数据集中，我们有各种独立的特征，例如葡萄糖、血压、皮肤厚度、胰岛素、身体质量指数等，这些特征决定了该人是否患有糖尿病的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/0e66acb6cc82f1f9fe0ee144ab6f3d0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*luhIGosrupKURtryWH958Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="d78c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">因此，最初我们做一些探索性的分析，以发现独立特性之间的相互依赖性和相关性。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/4dc33d5ed4ab518b940ea1fa65dd0887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*5CZy7Xzf0yMgxD1lUI_z0w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="2c8c" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">拆分测试和训练数据</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="b29d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">调用KNN分类器对k=1的数据进行训练和测试</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="b31d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">使用混淆矩阵和分类报告检查准确性</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/e1b88672399fee5a28fa43433645f22b.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*_EGNC6jl_Ln0TOAXhFh2_g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="10a4" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">基于从1到50的k值对数据进行训练和测试。</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="2607" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">检查并绘制从1到50的所有k值的误差率。</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/515333a79222f44517bdbd16b1c0edb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*7aO5LMBh2KM65DPo1c26dQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="dfc8" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">k=13时误差最小。训练和测试数据，同时检查准确性</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/bf28d68b3dc19fbac040b197af6930e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*tV8DQ2J4kIInT1KFufDGxg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="31fd" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">感谢您阅读文章！！</p></div></div>    
</body>
</html>