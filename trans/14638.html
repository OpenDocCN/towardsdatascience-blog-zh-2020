<html>
<head>
<title>Tutorial: Uncertainty estimation with CatBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">教程:使用CatBoost进行不确定性估计</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tutorial-uncertainty-estimation-with-catboost-255805ff217e?source=collection_archive---------13-----------------------#2020-10-09">https://towardsdatascience.com/tutorial-uncertainty-estimation-with-catboost-255805ff217e?source=collection_archive---------13-----------------------#2020-10-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="267a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">理解为什么你的模型是不确定的，以及如何估计不确定性的水平</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/54a9be1671a70060d80fad79ea14c119.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-3KG8RV2kevlMTE2lut4FA.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">数据不确定性示例(图片由Yandex提供)。</p></figure><p id="5cf0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本教程涵盖以下主题:</p><ul class=""><li id="c577" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">什么是预测不确定性，为什么要关心它？</li><li id="a40e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">不确定性的两个来源是什么？</li><li id="c6b0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">如何使用CatBoost梯度增强库估计回归问题的不确定性</li></ul><p id="d596" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以使用<a class="ae mg" href="https://github.com/catboost/catboost/blob/master/catboost/tutorials/uncertainty/uncertainty_regression.ipynb" rel="noopener ugc nofollow" target="_blank">这个Jupyter笔记本</a>遵循所有步骤。</p><h1 id="3208" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">什么是不确定性？</h1><p id="4879" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">机器学习已经广泛应用于一系列任务。然而，在某些高风险应用中，如自动驾驶、医疗诊断和金融预测，一个错误可能会导致致命的后果或巨大的经济损失。在这些应用中，重要的是检测系统何时出错并采取更安全的措施。此外，还需要收集这些“故障场景”，标记它们，并通过主动学习教会系统做出正确的预测。</p><p id="7ddb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预测不确定性估计可用于检测误差。理想情况下，模型表明在可能出错的情况下存在高度的不确定性。这使我们能够发现错误并采取更安全的行动。至关重要的是，行动的选择可能取决于<em class="ne">为什么</em>模型是不确定的。不确定性的来源主要有两种:<em class="ne">数据不确定性</em>(也称任意不确定性)和<em class="ne">知识不确定性</em>(也称认知不确定性)。如果我们的目标是检测错误，就没有必要分离这两种不确定性。然而，如果我们的目标是主动学习，那么我们希望检测新的输入，而<em class="ne">知识不确定性</em>可以用于此。</p><p id="201c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据的不确定性源于数据固有的复杂性，如附加噪声或重叠类别。在这些情况下，模型知道输入具有多个类的属性或者目标有噪声。重要的是，数据不确定性<em class="ne">不能通过收集更多的训练数据来减少。</em></p><p id="1295" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当模型的输入来自训练数据稀疏覆盖的区域或远离训练数据的区域时，知识不确定性出现。在这些情况下，模型对这一地区知之甚少，很可能出错。与数据不确定性不同，知识不确定性可以通过从了解不多的区域收集更多的训练数据来减少。</p><p id="24d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇教程文章详细介绍了如何在CatBoost中量化数据和知识的不确定性。</p><h1 id="e0e1" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">CatBoost中的数据不确定性</h1><p id="709a" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">为了说明这些概念，我们将使用一个简单的合成示例。</p><p id="08b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设我们有两个分类特征x₁和x₂，每个有9个值，因此有81个可能的特征组合。目标取决于以下特征</p><pre class="kh ki kj kk gt nf ng nh ni aw nj bi"><span id="6ab4" class="nk mi iq ng b gy nl nm l nn no">y = mean(x₁,x₂) + eps(x₁,x₂)</span></pre><p id="37b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中均值<em class="ne"> (x₁,x₂) </em>是某个未知的固定值，eps <em class="ne"> (x₁,x₂) </em>是均值为0、方差为var <em class="ne"> (x₁,x₂) </em>的正态分布噪声(即数据不确定性)。在我们的示例中，mean <em class="ne"> (x₁,x₂) </em>是随机生成的，var <em class="ne"> (x₁,x₂) </em>有两个值(0.01和0.04)，分布如下:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi np"><img src="../Images/d9a86851517d1986673cd7317ea28ae9.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*yONKr9pSd9RD4jIzmmBtFw.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">数据中的差异。白色区域没有训练示例。</p></figure><p id="1386" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，心脏上的点比心脏外的点在目标中具有更多的噪声。请注意，我们为更好的可视化列举了类别，但是在数据集中，两个特征都是分类的，即没有给出顺序。</p><p id="fa61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们生成具有这种分布的数据集时，我们假设心脏内部没有任何训练样本，这些特征组合被视为数据集的异常值。</p><p id="9185" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用RMSE损失优化的标准模型只能预测mean(x₁,x₂).好吧，但是如果我们想估计y的方差，也就是数据不确定性呢？换句话说，如果我们想了解哪些预测是有噪声的呢？为了估计数据的不确定性，人们不得不使用<em class="ne">概率</em>回归模型预测<em class="ne">均值</em>和<em class="ne">方差</em>。为此，CatBoost中有一个新的损失函数，称为RMSEWithUncertainty。对于这种损失，CatBoost估计正态分布的均值和方差，优化负对数似然，并使用自然梯度，类似于NGBoost算法[1]。对于每个示例，CatBoost模型返回两个值:估计平均值和估计方差。</p><p id="4d4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们试着将这个损失函数应用到我们的简单例子中。我们得到以下方差:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi np"><img src="../Images/24df5fb2d2ebd4ed9e8a780513c70c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*hUZvLi9O5vTNq0msegrKtg.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">用RMSEWithUncertainty猫靴损失估计的方差(数据不确定性)。</p></figure><p id="dcf3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，CatBoost成功地预测了心脏内外的方差。在心脏内部，我们没有训练数据，所以任何事情都可以在那里预测。</p><h1 id="5531" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">CatBoost中的知识不确定性</h1><p id="1036" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">好，我们知道如何估计数据中的噪声。但是，如何衡量某个特定地区缺乏训练数据所带来的知识不确定性呢？如果我们想检测异常值，该怎么办？估计知识的不确定性需要一个<em class="ne">模型集合</em>。如果所有模型都理解一个输入，它们将给出相似的预测(低知识不确定性)。然而，如果模型不理解输入，那么它们很可能提供不同的预测，并且彼此强烈不一致(高知识不确定性)。对于回归，知识不确定性可以通过测量跨越<em class="ne">多个模型</em>的平均值的<em class="ne">方差来获得。注意，这不同于单个模型的<em class="ne">预测方差</em>，后者捕捉数据不确定性。</em></p><p id="c5db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们考虑如下生成的GBDT模型的<em class="ne">集合</em>:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="bc39" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用选项<em class="ne">后验采样</em>生成模型，因为这允许获得的(随机)预测很好地分布(具有良好的理论特性，这里我们参考[2]了解细节)。</p><p id="2a17" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，为了估计知识的不确定性，我们只需计算模型预测的平均值的方差:</p><pre class="kh ki kj kk gt nf ng nh ni aw nj bi"><span id="11d6" class="nk mi iq ng b gy nl nm l nn no">knowledge = np.var(ens_preds, axis=0)[:, 0]</span></pre><p id="2708" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们得到以下结果:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi np"><img src="../Images/a8da6b9178b6106e0e42410d66c3db29.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*wqTCLkgxzTM-e_bnKsYqHQ.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">通过模型集成估计知识不确定性。</p></figure><p id="0e66" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型正确地检测了心脏内部的知识不确定性(我们看不到原始心脏边界的痕迹)。这说明了如何通过估计知识的不确定性，我们可以检测异常输入。</p><p id="ca98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在实践中，训练几个CatBoost模型的集合可能过于昂贵。理想情况下，我们希望训练一个单一的模型，但仍然能够检测异常值。有一个解决方案:我们可以使用从单个<em class="ne">训练模型获得的<em class="ne">虚拟</em>集合:</em></p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="52f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于只有一个训练好的模型，CatBoost会为每个示例返回几个预测。这些预测是通过截断模型获得的:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ns"><img src="../Images/8fbf671776d947d2a77b2240dfa6220b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ysT-RTGOrFZvX_FxaqmqPg.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">虚拟合奏(图片由作者提供)</p></figure><p id="d626" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同样，我们使用选项<em class="ne">后验采样</em>来保证裁剪预测的理想分布。让我们看看我们得到了什么:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi np"><img src="../Images/af7defbddb148b36e64cb6e49a929c81.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*gQ38F9CT_Da5P_qwj842lA.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">由虚拟集合估计的知识不确定性。</p></figure><p id="37d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，知识不确定性的预测绝对值现在小得多，因为虚拟系综元素是相关的。但是，它仍然可以成功地检测未被占用的区域(异常值)。</p><p id="8531" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以使用<em class="ne">prediction _ type = ' total uncertainty '</em>,而不是<em class="ne">prediction _ type = ' virt ensembles '</em>返回几个模型的预测，这样更容易得到相同的结果。对于这种预测类型，CatBoost使用虚拟集合计算所有类型的不确定性。也就是说，对于RMSEWithUncertainty，它返回以下统计数据:[均值预测、知识不确定性、数据不确定性]:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="ad31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢您的关注！我希望这篇教程能帮助你更好地理解不确定性的概念，以及如何用CatBoost估计它。我们将在以后的文章中告诉你更多关于不确定性的应用。敬请期待😺</p><p id="e4c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1] T. Duan等，<a class="ae mg" href="https://proceedings.icml.cc/static/paper_files/icml/2020/3337-Paper.pdf" rel="noopener ugc nofollow" target="_blank"> NGBoost:概率预测的自然梯度推进</a> (2020)，2020</p><p id="c1d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] A. Ustimenko，L. Prokhorenkova和A. Malinin，<a class="ae mg" href="https://arxiv.org/pdf/2006.10562.pdf" rel="noopener ugc nofollow" target="_blank">通过系综</a>进行梯度增强的不确定性(2020)，arXiv预印本arXiv:2006.10562</p></div></div>    
</body>
</html>