<html>
<head>
<title>Important Considerations when Predictive Modeling with Tabular Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用表格数据进行预测建模时的重要考虑事项</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/important-considerations-to-make-while-predictive-modeling-17aac6b188d9?source=collection_archive---------36-----------------------#2020-10-10">https://towardsdatascience.com/important-considerations-to-make-while-predictive-modeling-17aac6b188d9?source=collection_archive---------36-----------------------#2020-10-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="32da" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我对Coursera.org“如何赢得顶级Kagglers的数据科学竞赛”的笔记</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1b58405b7d2a3944ad21c3b57b788375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9IpmhLbGwdHED6YmTIjaww.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.kaggle.com/progression" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/progression</a></p></figure><p id="0edb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总的来说，我觉得这门课很有帮助，也很有见地，4.79/5。有许多我以前没有考虑过的想法，所以我在这里贴了一些我的笔记。很有可能，你已经看到了这些想法的大部分，所以我将试着把重点放在最有趣的。这是课程的<a class="ae ky" href="https://www.coursera.org/learn/competitive-data-science/home/welcome" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h2 id="a5fc" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">火车运行公司</h2><ol class=""><li id="2bc7" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated"><strong class="lb iu">数据探索清单</strong></li><li id="4cbf" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">验证</strong></li><li id="7de8" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">目标泄漏</strong></li><li id="4157" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">度量和损失函数</strong></li><li id="1247" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">指标优化</strong></li><li id="d4c9" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">表示编码</strong></li><li id="781e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">编码提示</strong></li><li id="60ae" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">高级特征工程</strong></li><li id="cf7c" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">群策群力</strong></li><li id="4825" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">堆叠网</strong></li><li id="b924" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">创建一套多样化的模型</strong></li><li id="504d" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">元学习和堆叠技巧</strong></li><li id="45a3" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">XG boost中基于文本的功能</strong></li><li id="35d1" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">序列特征提取(XGBoost) </strong></li><li id="7947" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">半监督&amp;伪标签</strong></li><li id="f38f" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated"><strong class="lb iu">我的看法</strong></li></ol><h2 id="8298" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">数据探索清单</h2><ol class=""><li id="8286" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">检查缺失值和异常值</li><li id="9da2" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">检查分类变量的唯一计数</li><li id="3841" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">分割出数据类型，即数值型、分类型</li><li id="095d" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">创建“大于”列级比较矩阵</li><li id="43bf" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">寻找相关变量的聚类</li><li id="700a" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">创建图以找到强大的功能交互</li></ol><p id="d548" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">步骤1、2、3是几乎每个数据探索管道的一部分。步骤4、5、6涉及绘制和比较特征，即，使用pd.crosstab、相关矩阵或聚合数据。</p><h2 id="cd30" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">确认</h2><p id="fd57" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">K-Fold验证可以说是建模过程中最重要的步骤。出折叠(OOF)样本的预测用于评估模型的平均性能。这也用于超参数调整和模型性能比较。有趣的是，跨K个折叠的性能变化也可用于诊断目的，即检查每个折叠中预测的波动性。</p><h2 id="71fc" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">目标泄漏</h2><p id="30ca" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">目标泄漏是一个负载话题。基本上，我们不希望模型从生产环境中不可用的信息中学习。索引功能或索引功能的组合可能会导致目标泄漏。更一般地说，目标漏损可以是导致良好模型性能和低附加值的任何东西。</p><h2 id="5572" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">度量和损失函数</h2><p id="cf00" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">这里总结了常见的损失函数和指标。</p><ol class=""><li id="394a" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu mv mw mx my bi translated">MAE——平均绝对误差——当数据集包含大多数数据集不常见的异常值时，优于MSE</li><li id="dbb9" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">RMSLE——均方根对数误差——倾向于过度预测，而不是不足预测</li><li id="bc6f" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">MAPE-平均绝对百分比误差-对较大目标值的误差惩罚较少</li><li id="6c31" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">MSPE —均方百分比误差</li><li id="18fd" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">AUC——曲线下面积——估计高于随机的模型准确度百分比</li><li id="811c" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">混淆矩阵-分类器如何在类之间分配预测</li><li id="33d0" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">Weight Cohen's Kappa —使用误差矩阵和混淆矩阵来估计(加权误差)除以加权基线，以估计分类器性能。评分者同意系数。</li></ol><h2 id="19e9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">度量优化</h2><ol class=""><li id="2090" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">MAPE和MSPE可通过样本权重或重采样进行优化，即MAPE的1/y_i/sum(1/y_i)</li><li id="331e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">在分类模型中，模型的输出概率可能与目标变量的分布不匹配。概率可以用模型叠加来校准。校准可以用目标的分类概率和滚动平均值的CDF来可视化。</li><li id="8a51" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">当期望的度量在验证数据集上变得更差时，可以利用早期停止来停止训练。</li></ol><h2 id="97a5" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">平均编码</h2><p id="d487" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">均值编码是一个潜在的强大工具，但它也很有可能增加偏差。可以通过使用K倍插补、留一插补、平滑平均编码和扩展平均编码来减轻偏倚。这些策略的一些示例代码可以在我的GitHub <a class="ae ky" href="https://github.com/freedomtowin/data-eng-util/blob/master/machine-learning/mean-encoding-regularization.py" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="8145" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">K倍CV均值编码策略可总结如下:</p><ol class=""><li id="954f" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu mv mw mx my bi translated">分离训练和测试装置</li><li id="8890" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">分裂训练→ K折叠训练和OOF验证，</li><li id="c24e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">对K-fold训练进行均值编码，然后将值映射到OOF验证</li><li id="e475" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">组合来自OOF数据集的均值编码，然后追加到训练数据集</li><li id="e5eb" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">估计整个训练的编码，然后映射到测试集</li></ol><p id="b24f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类变量之间的相互作用也可以进行均值编码。显然，从XGBoost中挖掘特性交互是可能的，这里是<a class="ae ky" href="https://github.com/Far0n/xgbfi" rel="noopener ugc nofollow" target="_blank">链接</a>。通过计算两个要素在随机森林中同时出现的次数，您可以创建自己的函数来实现这一点。</p><h2 id="191f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">编码技巧</h2><ol class=""><li id="04fc" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">使用宏加速编码和编辑</li><li id="6bcb" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">尝试各种理论，并试图理解为什么一个理论行得通/行不通</li><li id="0b17" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">建立一个快速基线模型，并专注于功能开发</li><li id="1a3e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">修复模型的随机种子</li><li id="0f7d" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">将验证训练/测试分割保存在单独的文件中</li><li id="955e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">把预测建模想象成一个难题</li><li id="06eb" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">寻找团队成员，整合结果并分享见解</li><li id="91ac" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">将所有不同的模型保存在不同的文件中</li></ol><h2 id="13b3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">高级特征工程</h2><ol class=""><li id="fc8f" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">计算分类组中的最小值、最大值、平均值和标准值(类似于平均值编码)</li><li id="3333" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">最近邻统计，N个最近邻的平均值:平均目标变量，聚类中的平均距离，到分类值的平均距离</li><li id="8240" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">矩阵分解/降维/t-SNE</li></ol><h2 id="125e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">整体策略</h2><p id="3c20" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">集成策略使用几个模型的输出到单个预测模型中，通常可以改善结果。</p><ul class=""><li id="d8fe" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu nk mw mx my bi translated">加权平均</li><li id="39c5" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu nk mw mx my bi translated">制袋材料</li><li id="5143" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu nk mw mx my bi translated">加权推进</li><li id="e3f0" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu nk mw mx my bi translated">梯度推进</li><li id="0b05" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu nk mw mx my bi translated">堆垛</li></ul><p id="fac1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将模型输出一起平均可以降低任何一个模型中的噪声。可以使用K倍CV来调整集合权重。权重也可以针对特定类别或目标类进行调整。</p><p id="0bd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Bagging: </strong>创建同一模型的不同版本，并将结果平均在一起。通过改变随机种子、模型参数、行选择和/或列选择来创建不同的模型。</p><p id="348f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Boosting: </strong>通过一个接一个地顺序训练ML模型，将许多弱学习器转换为强估计器，其中每个模型被建立以校正前一个模型的错误。在梯度增强决策树(即XGBoost)中，梯度和Hessian矩阵用于确定哪些特征值得分裂。下面是一些关于XGBoost如何工作的有用链接:<a class="ae ky" rel="noopener" target="_blank" href="/how-does-xgboost-work-748bc75c58aa">简明解释</a>，<a class="ae ky" href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html" rel="noopener ugc nofollow" target="_blank">文档</a>，<a class="ae ky" href="https://arxiv.org/pdf/1603.02754.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>。</p><p id="8ba1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是boosting算法的简短总结:第一次迭代根据目标的平均值计算误差，其中平均值是预测堆栈中的第一个模型。所有后续模型通过学习速率η*来缩放。模型估计器的数量应该与学习率成反比。</p><p id="3484" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scikit-learn有一个为定制模型sk learn . ensemble . adaboostclassifier创建增强解决方案的实现。</p><p id="422e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">堆叠:</strong>将一组不同的模型组合到另一个模型中，即随机森林、线性模型等。这个过程需要减少目标泄漏。第一组模型的输出不应用于训练第二层第一层以前已经“看到”的数据。对于各种情况，有各种不同的堆叠策略。</p><p id="8b32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是本课程第四周的摘录:</p><p id="ff82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> a)简单维持方案</strong></p><ol class=""><li id="12bb" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu mv mw mx my bi translated">将列车数据分为三部分:partA、partB和partC。</li><li id="bb04" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">在partA上拟合N个不同的<strong class="lb iu">模型</strong>，分别为partB、partC、test_data获得<em class="nl">元特征</em> partB_meta、partC_meta和test_meta。</li><li id="2d2c" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">将<strong class="lb iu">元模型</strong>拟合到零件B_meta，同时在零件C_meta上验证其超参数。</li><li id="c9da" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">当<strong class="lb iu">元模型</strong>被验证后，将其拟合到[零件b _元，零件c _元]并预测测试_元。</li></ol><p id="21f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> b)具有OOF元功能的元维持方案</strong></p><ol class=""><li id="b6a3" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu mv mw mx my bi translated">将训练数据分成K份。遍历每个褶皱:在除当前褶皱之外的所有褶皱上重新训练N个不同的<strong class="lb iu">模型</strong>，预测当前褶皱。在这个步骤之后，对于train_data中的每个对象，我们将有N个<em class="nl">元特征</em>(也称为<em class="nl">非折叠预测，OOF </em>)。让我们称它们为train_meta。</li><li id="844e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">将<strong class="lb iu">模型</strong>拟合到<strong class="lb iu"> </strong>全列车数据，并对测试数据进行预测。我们姑且称这些特性为<strong class="lb iu"> </strong> test_meta。</li><li id="0e38" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">将train_meta拆分成两部分:train_metaA和train_metaB。将<strong class="lb iu">元模型</strong>拟合到train_metaA，同时在train_metaB上验证其超参数。</li><li id="cdca" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">当<strong class="lb iu">元模型</strong>被验证后，将其拟合到train_meta并预测test_meta。</li></ol><p id="3220" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具有OOF元特征的元文件夹方案</p><ol class=""><li id="fcb7" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu mv mw mx my bi translated">使用<strong class="lb iu"> b.1 </strong>和<strong class="lb iu"> b.2. </strong>获取<em class="nl"> OOF预测</em> train_meta <em class="nl"> </em>并测试元特性test_meta</li><li id="b175" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">使用train_meta上的KFold方案来验证<strong class="lb iu">元模型</strong>的超参数。一种常见的做法是将此KFold的种子固定为与用于获得<em class="nl"> OOF预测</em>的KFold的种子相同。</li><li id="e036" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">当<strong class="lb iu">元模型</strong>被验证后，将其拟合到train_meta并预测test_meta。</li></ol><p id="084b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> d)具有OOF元功能的维持方案</strong></p><ol class=""><li id="35ff" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu mv mw mx my bi translated">将训练数据分成两部分:部分a和部分b。</li><li id="5074" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">将partA拆分成K个折叠。遍历每个折叠:在除当前折叠之外的所有折叠上重新训练N个不同的<strong class="lb iu">模型</strong>，预测当前折叠。在这个步骤之后，对于partA中的每个对象，我们将有N个<em class="nl">元特征</em>(也称为<em class="nl">折叠外预测，OOF </em>)。让我们称它们为partA_meta。</li><li id="28d2" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">将<strong class="lb iu">模型</strong>拟合到<strong class="lb iu"> </strong>整个partA，并预测partB和test_data，分别得到partB_meta和test_meta。</li><li id="7fb3" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">将<strong class="lb iu">元模型</strong>拟合到零件A_meta，使用零件B_meta验证其超参数。</li><li id="5cb9" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">当<strong class="lb iu">元模型</strong>通过验证后，基本上执行2。第三。而不用把train_data分成几个部分，然后训练一个<strong class="lb iu">元模型</strong>。也就是说，首先使用<strong class="lb iu">模型获得train_data的<em class="nl">出叠预测</em> train_meta <em class="nl"> </em>。</strong>然后在train_data上训练<strong class="lb iu">模型</strong>，预测test_data，得到test_meta。在train_meta上训练<strong class="lb iu">元模型</strong>并预测test_meta。</li></ol><p id="5b36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> e)具有OOF元特征的k文件夹方案</strong></p><ol class=""><li id="12d6" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu mv mw mx my bi translated">为了验证模型，我们基本上做<strong class="lb iu"> d.1 — d.4 </strong>，但是我们使用具有M个折叠的k折叠策略将<strong class="lb iu">T5】训练数据分成部分partA和partB M次。</strong></li><li id="69ca" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">元模型通过验证后，执行<strong class="lb iu"> d.5. </strong></li></ol><p id="9e8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> f)时间序列中的k折叠方案</strong></p><p id="3ca4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在时间序列任务中，我们通常需要预测一段固定的时间。如日、周、月或持续时间为<strong class="lb iu"> T </strong>的任意时段。</p><ol class=""><li id="b0d6" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu mv mw mx my bi translated">将列车数据分割成持续时间为<strong class="lb iu"> T </strong>的数据块。选择第一个<strong class="lb iu"> M </strong>块。</li><li id="b20a" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">在这些<strong class="lb iu"> M </strong>个块上拟合N个不同的模型，并对块<strong class="lb iu"> M+1 </strong>进行预测。然后将这些模型拟合到第一个<strong class="lb iu"> M+1 </strong>组块上，并预测组块<strong class="lb iu"> M+2 </strong>等等，直到你到达终点。之后，使用所有训练数据来拟合模型并获得测试预测。现在，我们将拥有从编号<strong class="lb iu"> M+1 </strong>开始的组块的<em class="nl">元特征</em>，以及用于测试的<em class="nl">元特征</em>。</li><li id="ceef" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">现在我们可以从第一个<strong class="lb iu"> K个</strong>组块[ <strong class="lb iu"> M+1个</strong>，<strong class="lb iu"> M+2个</strong>，..，<strong class="lb iu"> M+K </strong>来拟合2级模型，并在组块<strong class="lb iu"> M+K+1 </strong>上验证它们。本质上，我们又回到了第一步。用较少的块和<em class="nl">元特征</em>代替特征。</li></ol><p id="bb3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> g)数据量有限的时间序列中的k折叠方案</strong></p><p id="ff9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可能经常遇到这样的情况，方案<strong class="lb iu"> f) </strong>不适用，尤其是在数据量有限的情况下。例如，当我们只有2014年、2015年、2016年的数据，而我们需要预测2017年全年的数据。在这种情况下，scheme <strong class="lb iu"> c) </strong>可能会有所帮助，但是有一个限制:KFold拆分应该在时间部分完成。例如，对于有几年数据的情况，我们将每年视为一个文件夹。</p><ol class=""><li id="b439" class="mo mp it lb b lc ld lf lg li nh lm ni lq nj lu mv mw mx my bi translated">将训练数据集分成两部分A &amp; B，测试数据C</li><li id="c2f7" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">在A上训练多个学习者，输出对B和C预测</li><li id="3542" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">使用先前模型的堆叠预测，在B上定型新模型</li><li id="bd31" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">时间元素应该在A B和C上单调增加</li></ol><h2 id="5fcb" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">StackNet</h2><ol class=""><li id="0786" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">多层元学习者可以堆叠在一起</li><li id="8db7" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">K-fold训练，生成每个K-Fold的预测，以便创建数据集B，可以以这种方式创建多个层</li><li id="cff6" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">每个图层都可以使用任何先前图层/模型的输出，甚至可以使用输入数据集</li><li id="c637" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">创建数据集C有两个选项1)模型可以使用整个训练数据进行训练，然后创建测试集的预测2)每个k-fold模型的每个模型将在测试数据集上进行预测，将对这些模型取平均值</li></ol><h2 id="463e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">创建一套多样化的模型</h2><ol class=""><li id="4d02" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">创建一组多样化的模型</li><li id="24ad" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">2-3个梯度提升树(在不同深度调整)</li><li id="1e65" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">2–3个神经网络(不同的架构)</li><li id="01ae" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">1棵额外的树/随机森林</li><li id="14e8" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">1–2k邻居模型</li><li id="4327" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">1因式分解机(所有成对交互)</li><li id="e18f" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">用于回归的RBF SVM</li><li id="6212" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">创建一组多样化的数据管道</li><li id="ad9c" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">使用不同的样本</li><li id="b734" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">使用不同的编码</li><li id="6e00" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">对数值变量使用不同的预处理</li><li id="3145" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">使用不同的交互变量</li></ol><h2 id="8304" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">元学习和堆叠技巧</h2><ol class=""><li id="dcd9" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">具有较低深度/较高正则化约束元模型</li><li id="4ae0" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">使用具有布雷柯蒂斯距离的KNN</li><li id="467c" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">考虑通过交叉验证强力寻找线性权重</li><li id="669e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">第二级特征应包括新信息，即元模型输出之间的成对差异、平均编码特征的KNN平均距离、分类组内的平均模型预测</li><li id="c017" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">交叉验证中的高K值可能导致目标泄漏，请检查测试性能</li><li id="bb77" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">最终层可以用线性模型来训练，而不用CV，因为它不会引入太多偏差</li></ol><h2 id="f0dc" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">XGBoost中基于文本的功能</h2><ol class=""><li id="9d2b" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">XGBoost可用于大型N元语法特征的特征选择</li><li id="d2c3" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">可以在多个文本字段之间创建文本相似性特征，即搜索查询、标题、描述:比较(查询、标题)(查询、描述)、查找匹配单词的数量、TFIDF表示之间的余弦距离、平均单词之间的距离2vec、Levenstien距离</li></ol><h2 id="33b3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">序列特征提取</h2><ol class=""><li id="adbd" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">滑动窗口上熵的分布统计</li><li id="5f3a" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">具有特征选择的n元文法</li><li id="42c8" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">特定关键字功能</li><li id="d04c" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">总序列长度、子序列长度</li><li id="b44e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">树模型特征选择和转换</li><li id="050c" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">非负矩阵分解(用于计数数据)</li><li id="2c71" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">移除罕见的一次性编码功能</li><li id="700e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">L1正则化的线性/SVM模型</li><li id="120c" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">基于OOF中最容易出错的数据点创建新要素</li><li id="0480" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">对目标变量分布使用替换抽样</li><li id="141d" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">多个(20)样本横截面的平均模型结果</li></ol><h2 id="7e78" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">半监督和伪标记</h2><p id="c247" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">可以使用伪标记方法将测试集包含到训练中(数据越多越好)。使用预测类别(半监督)或从类别分布中随机分配类别。测试集预测也是通过交叉验证计算的。</p><h2 id="c2e3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">我的看法</h2><p id="2610" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">对这些概念进行编码是相当容易的，但是对它们进行灵活编码以测试多个假设是困难的。在2020年，在表格数据竞赛中获得大师级地位是非常困难的。获得金牌需要达到排行榜上的前0.2%。我目前在所有Kaggle竞争者中排名4400，仅获得2枚铜牌。通常，有成千上万的竞争者可以使用相似的方法或策略。对于前10%的人来说，总体策略可能是相似的，但分数可能会随着功能开发、强力超参数调整和随机种子的微小变化而大幅变化。拥有灵活的工作流程非常重要。这些竞赛的最低计算门槛在过去几年里已经大大提高了。为了具有竞争力，您需要高端规格，即32GB+ RAM、6核+和2080 TI GPU+。我认为做一些表格数据竞赛来提高你的预测建模技能是值得的。</p></div></div>    
</body>
</html>