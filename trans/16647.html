<html>
<head>
<title>How to Code Linear Regression from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何从头开始编写线性回归代码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-code-linear-regression-from-scratch-9055a672eae0?source=collection_archive---------48-----------------------#2020-11-16">https://towardsdatascience.com/how-to-code-linear-regression-from-scratch-9055a672eae0?source=collection_archive---------48-----------------------#2020-11-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="807e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于正规方程的数值实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4567e6865ffaf1fc7b15fc01b2250f76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6yAFhJXAZw_NwzMvSRfZpw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">样本线性回归拟合(图片由作者提供)</p></figure><p id="b799" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如今，很容易用一个或另一个库来适应你能想到的几乎任何模型，但是通过调用你能真正学到多少。fit()和。预测()？虽然使用像python的statsmodels或scikit-learn这样的框架对于正常用例来说肯定更实用，但在学习数据科学时，了解这些模型实际上是如何工作的也同样合乎逻辑。下面我们展示如何使用numpy从头开始实现一个基本的线性回归模型。我们开始吧！</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="704e" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">这都是系数的问题</h1><p id="057c" class="pw-post-body-paragraph kv kw iq kx b ky mq jr la lb mr ju ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">回想一下你的第一堂代数课:你还记得直线方程吗？如果你说“y = mx + b”，那你绝对是对的。我认为从二维开始也是有帮助的，因为不使用任何矩阵或向量，我们已经可以看到，给定输入x和输出y，我们实际上寻找的不是一个，而是两个系数:m和b。</p><p id="1552" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">“但是等等！”你可能会说。这是斜率m，截距b，你又对了！但是为了找到最符合我们数据的线，我们不仅需要斜率，还需要截距，否则我们将会看到无限多条最佳拟合线，而不仅仅是我们要找的那一条。与其认为b被加到了x项上，不如将这个简单的等式改写为“y = m*x + b*1”。这使得下一点线性代数更容易理解。</p><h1 id="b017" class="ly lz iq bd ma mb mv md me mf mw mh mi jw mx jx mk jz my ka mm kc mz kd mo mp bi translated">关于矩阵和向量就足够了</h1><p id="09e4" class="pw-post-body-paragraph kv kw iq kx b ky mq jr la lb mr ju ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">让我们为我们的斜率截距方程设想一个非常简单的数据集，其中最佳拟合线实际上是完美的拟合。我们会说我们有要点:</p><p id="96e0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi">(1, 3)</p><p id="d931" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi">(2, 5)</p><p id="ae1d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi">(3, 7)</p><p id="a113" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi">(4, 9)</p><p id="c116" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们想要求解系数m和b，它们能最好地求解我们一会儿要定义的某个成本函数，但是为了更有效地完成这项工作，我们将首先再一次重写我们的方程。我们将定义一个向量y = [3，5，7，9]，我们将寻找一些系数(通常用θ，theta或β，beta表示)。我们的系数向量有多少个元素取决于我们的特征空间X中有多少个特征(注意，我们正在切换到大写的X来表示一个矩阵，我们现在将要讨论这个矩阵)。代替我们用来定义y项的向量，我们将在上面的x项列中增加一列1。按照惯例，我们将在X值前面放置一列1，因为您可以认为我们的常数系数比X的阶数低，看起来会像这样:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/2f6d83e6e88d06ebe79514ddba7fd439.png" data-original-src="https://miro.medium.com/v2/resize:fit:202/format:webp/1*wpMeZexEzvg27leGvzpnkA@2x.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="78b0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们的等式看起来像这样:</p><p id="8a6e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">xθ=<em class="nb">y</em></p><p id="82e2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来我们要做的是使用一个小技巧，不是所有的矩阵代数都像你可能习惯的那样工作，但只要我们的维度兼容，在等式的两边乘以相同的项通常是公平的，这就是我们要做的。我们在两边加上X的转置，转置看起来像这样:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/1b9b51c79ad5aeae18b91ff9d6b9318a.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*ZyHjoktnhtB8QZibstWrOQ@2x.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1897" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的新方程可以写成这样:</p><p id="ee89" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">(xᵀx)θ=xᵀ<em class="nb">y</em></p><p id="333b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这就是我们古怪操作的要点。这个方程叫做正规方程，它恰好有一些特殊的性质。<a class="ae nd" href="https://mathworld.wolfram.com/NormalEquation.html" rel="noopener ugc nofollow" target="_blank"> Wolfram将这个方程定义为“使Ax = b的左右两边的平方距离之和最小化的方程”,虽然他们使用了一些不同的符号，但这正是我们要找的。</a></p><p id="1da7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的最后一个技巧是分离θ，我们将通过取(XᵀX)的<a class="ae nd" href="https://mathworld.wolfram.com/MatrixInverse.html" rel="noopener ugc nofollow" target="_blank">逆</a>来完成，得到下面的等式，该等式将产生(XᵀX)可逆的所有情况下的解。我们将跳过一些细节，但是只要X的列是线性独立的，这应该是可行的。</p><p id="a332" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">θ=(xᵀx)⁻<em class="nb">y</em></p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="4a47" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">代码</h1><p id="6ddc" class="pw-post-body-paragraph kv kw iq kx b ky mq jr la lb mr ju ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">这是我们用Python写的解决方案，请随意尝试！我认为这段代码的工作原理和scikit-learn的线性回归差不多。例如，它将在Boston Housing数据集上产生相同的结果，您可以使用<a class="ae nd" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html" rel="noopener ugc nofollow" target="_blank">sk learn . datasets . load _ Boston</a>检索该数据集。你能想出一些它断裂的案例吗？(提示:查看上一节的最后一段)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="04b1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，对于那些想要一个简单方便的函数来测试该方法的输出与另一个库中的实现的人来说，可以随意使用它:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure></div></div>    
</body>
</html>