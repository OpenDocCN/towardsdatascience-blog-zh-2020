<html>
<head>
<title>5 Simple Tips To Improve Your Kaggle Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">改善你的Kaggle模型的5个简单技巧</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-simple-tips-to-improve-your-kaggle-models-159c00523418?source=collection_archive---------31-----------------------#2020-10-02">https://towardsdatascience.com/5-simple-tips-to-improve-your-kaggle-models-159c00523418?source=collection_archive---------31-----------------------#2020-10-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="16ba" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何在竞赛中获得高性能模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b8d7cc0f4d096c3f966ec79ccc526b50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PSXv8cgYGdODj3ha"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">🇨🇭·克劳迪奥·施瓦茨| @purzlbaum 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="a568" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你最近才开始使用Kaggle，或者你是该平台的老用户，你可能想知道如何轻松地提高你的模型的性能。这里是我在<a class="ae kv" href="https://www.kaggle.com/louise2001" rel="noopener ugc nofollow" target="_blank">我的卡格尔之旅</a>中积累的一些实用技巧。因此，要么构建自己的模型，要么从一个基线公共内核开始，并尝试实现这些建议！</p><h1 id="e663" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">1.总是回顾过去的比赛</h1><p id="d4db" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">虽然Kaggle的政策是决不会出现两次相同的比赛，但经常会出现非常相似的问题。例如，一些主持人每年提出一个相同主题的常规挑战(例如NFL的大数据碗)，只有很小的变化，或者在某些领域(例如医学成像)有很多目标不同但精神非常相似的比赛。</p><p id="7b71" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，回顾获胜者的解决方案(由于难以置信的Kaggle社区，总是在比赛结束后公布)可能是一个很好的补充，因为它给你提供了开始的想法和获胜的策略。如果你有时间回顾它们，你也会很快发现，即使在非常不同的比赛中，一些流行的基线模型似乎总是做得足够好:</p><ul class=""><li id="47f5" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">卷积神经网络或更复杂的ResNet或EfficientNet在<strong class="ky ir">计算机视觉挑战</strong>，</li><li id="5cfb" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><strong class="ky ir">音频处理中的WaveNet挑战</strong>(如果你只使用Mel频谱图，这也可以通过图像识别模型很好地处理)，</li><li id="8664" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">BERT及其衍生物(RoBERTa等)在<strong class="ky ir">自然语言处理挑战</strong>，</li><li id="8213" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">在<strong class="ky ir">表格数据</strong>上的光梯度增强方法(或其他梯度增强或树策略)…</li></ul><p id="e979" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你既可以直接在Kaggle平台上寻找类似的比赛，也可以看看<a class="ae kv" href="https://www.kaggle.com/sudalairajkumar/winning-solutions-of-kaggle-competitions" rel="noopener ugc nofollow" target="_blank">Sundalai Raj Kumar</a>的这篇很棒的总结。</p><p id="5076" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">回顾过去的比赛也可以帮助你得到以下解释的所有其他步骤的提示。例如，获得关于类似问题的预处理的提示和技巧，人们如何选择他们的超参数，他们在他们的模型中实现了哪些额外的工具以使他们赢得比赛，或者他们是否专注于只打包他们的最佳模型的类似版本，或者更确切地说是集合了所有可用公共内核的熔炉。</p><h1 id="3726" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">2.你永远不会在数据准备上花足够的时间</h1><p id="8e20" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这还远不是这份工作最激动人心的部分。然而，这一步的重要性怎么强调都不为过。</p><ul class=""><li id="cfda" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated"><strong class="ky ir">清理数据</strong>:永远不要认为主机为你提供了尽可能干净的数据。很多时候，是错的。填充异常值，移除异常值，将数据分成同类观测值的类别…</li><li id="0afa" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">做一些简单的<strong class="ky ir">探索性数据分析</strong>，对你正在做的事情有一个大致的了解(这将帮助你获得洞察力和想法)。<strong class="ky ir">这是现阶段最重要的一步</strong>。如果对数据的结构、所拥有的信息以及目标个体或集体的一般行为特征没有正确的认识，您将会盲目行事，对如何构建模型没有任何直觉。绘制图表、直方图、相关矩阵。</li><li id="889e" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">扩充你的数据:这可能是提高性能的最好方法之一。但是注意不要把它做得太大，以至于你的模型不能再处理它了。你可以在互联网上找到一些额外的数据集(非常小心权利，否则你可能会遭受与100万美元Deepfake检测挑战赛获胜者相同的命运)，或者在Kaggle平台上(在过去类似的比赛中！)，或者只是处理提供给你的数据:翻转和裁剪图像，叠加录音，回译或替换文本中的同义词…</li></ul><p id="f9be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预处理也是你必须仔细考虑你将依赖什么<strong class="ky ir">交叉验证方法</strong>的步骤。Kaggle的座右铭基本上可以是:<em class="nd">相信你的简历</em>。处理你的数据将帮助你知道如何分割它:根据目标值还是样本类别分层？你的数据不平衡吗？如果你有一个聪明的简历策略，并且完全依赖它而不是排行榜分数(尽管它可能非常诱人)，那么你很有可能在私人最终分数上获得惊喜。</p><h1 id="34a9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">3.尝试超参数搜索</h1><p id="72ee" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">超参数搜索可帮助您找到模型应该具有的最佳参数(学习速率、softmax的温度等)，以便获得最佳性能，而无需手动运行一千次枯燥的实验。</p><p id="2e64" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最常见的超参数搜索策略包括:</p><ul class=""><li id="ef65" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated"><strong class="ky ir">网格搜索</strong>(请不要这样做) :我认为最差的执行方法，因为您可能完全错过某个模式或某些值的非常局部的性能峰值，它包括测试平均分布在您定义的可能值区间上的超参数值；</li><li id="8f3e" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><strong class="ky ir">随机搜索</strong>(及其蒙特卡洛衍生物) :你尝试你的参数的随机值。它的主要问题在于，它是一种并行方法，测试的参数越多，成本就越大。但是，它有一个优点，使您能够在测试中包括先验知识:如果您想找到1e-4和1e-1之间的最佳学习速率，但您假设它必须在1e-3左右，您可以从以1e-3为中心的对数正态分布中抽取样本。</li><li id="ee50" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><strong class="ky ir">贝叶斯搜索</strong>:基本上是随机搜索，但经过改进，因为它是迭代的，因此成本更低。它基于当前模型迭代地评估有希望的超参数配置，然后更新它。这是三个中表现最好的。</li><li id="afe9" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">其他方法包括<strong class="ky ir">基于梯度的搜索</strong>或<strong class="ky ir">进化优化</strong>更加危险，一般不适用。在某些特殊情况下可以推荐使用。</li></ul><p id="5f8e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有许多自动化工具可以很好地为你完成这项工作。让我们来看看关于这个话题的优秀媒体&amp;数据资源:</p><ul class=""><li id="3166" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/how-to-beat-automl-hyperparameter-optimisation-with-flair-3b2f5092d9f5">https://towards data science . com/how-to-beat-automl-hyperparameter-optimization-with-flair-3b2f 5092 d9f 5</a></li><li id="1b17" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a">https://towards data science . com/automated-machine-learning-hyperparameter-tuning-in-python-dfda 59 b 72 f 8 a</a></li><li id="61e6" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><a class="ae kv" href="https://medium.com/@martsalz/automl-hyperparameter-tuning-with-nni-and-keras-ffbef61206cf" rel="noopener">https://medium . com/@ marts alz/automl-hyperparameter-tuning-with-nni-and-keras-ffbef 61206 cf</a></li></ul><p id="6c22" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，您必须小心，并对超参数值的含义保持坚定的直觉。如果没有可靠的验证集和同质数据，过度的超参数优化可能会导致过度拟合。总是更喜欢一些合理解释的参数选择，而不是在训练数据上取得小数精度。</p><h1 id="d779" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">4.简单的练习可以改变游戏</h1><p id="db8b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我发现有一些模型包装器可以用来获得更好的结果。他们在不同的层面上工作:</p><ul class=""><li id="501f" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">在优化过程中，永远不要忘记添加一个<strong class="ky ir">学习率调度器</strong>，它有助于获得更精确的训练(从小规模开始，当您的模型学习良好时逐步增加，例如减少平台上的步骤)。</li><li id="994a" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">仍然在优化过程中，您可以将<strong class="ky ir"> Lookahead </strong>包装在您的优化器周围；前瞻算法包括向前进行k个优化步骤，找到性能最佳的地方，然后向最优方向后退一步，并从那里重新开始训练。理论上你会得到更好的性能，尽管我从未发现这是真的；但是它稳定了训练，这在你的数据非常嘈杂的时候很好。</li><li id="9ee4" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">在开始训练之前，为你的权重找到一个好的初始化:如果你正在使用一个流行的架构，从基线权重开始(如图像识别中的<strong class="ky ir"> ImageNet </strong>，如果没有，尝试<strong class="ky ir">层顺序单元方差</strong>初始化(LSUV，最好的可能初始化——理论上)。它包括将您的权重初始化为正交，以及所有可训练层的单位方差。</li><li id="02b3" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">最后，我经常发现<strong class="ky ir">从神经网络的最后一层权重</strong>训练一个LGBM，而不是添加一个softmax作为输出层，可以出奇地好。</li></ul><h1 id="e0e9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">5.包，包，包，包！</h1><p id="c7d4" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">除了数据扩充，可能没有比混合(也称为打包)更有效的技术来提高您的性能。</p><p id="8811" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我的个人建议是，我总是保存我运行的每一个模型预测，包括我的折叠和最终模型，并对它们进行平均(只是基本的平均，我从未发现任何证据表明“聪明”的组合，如根据模型的独奏表现加权模型，会增加最终得分)。不要忘记混合公共内核。</p><p id="fb61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你的组合策略中有越多的模型，你就越有可能在私人排行榜变动中幸存下来。事实上，使你的模型多样化会使你的最终结果更加稳健。这与金融中一个潜在的投资组合多样化的想法是一样的:不是一种具有给定回报和给定方差的资产，而是许多具有相同回报和相同方差的不同资产，因为它们同时减少的可能性要小得多，一种资产的损失将由其他资产的盈利来补偿。同样的想法，不要只依赖一个模型，让很多不同的模型投票:它们中的大多数预测的目标(在分类中)或每个预测的目标的平均值(在回归中)将很可能更接近真实的答案。</p></div><div class="ab cl ne nf hu ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ij ik il im in"><h1 id="3d8f" class="ls lt iq bd lu lv nl lx ly lz nm mb mc jw nn jx me jz no ka mg kc np kd mi mj bi translated">希望你喜欢这篇文章，感谢theo Viel的评论。</h1></div></div>    
</body>
</html>