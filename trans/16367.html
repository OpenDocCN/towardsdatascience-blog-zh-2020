<html>
<head>
<title>Artificial Intelligence is a Supercomputing problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能是一个超级计算问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/artificial-intelligence-is-a-supercomputing-problem-4b0edbc2888d?source=collection_archive---------29-----------------------#2020-11-11">https://towardsdatascience.com/artificial-intelligence-is-a-supercomputing-problem-4b0edbc2888d?source=collection_archive---------29-----------------------#2020-11-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e3b7" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/supercomputing-for-a-i" rel="noopener" target="_blank">人工智能超级计算— 01 </a></h2><div class=""/><div class=""><h2 id="3d43" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">人工智能从业者不能回避我们的责任</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f576ba7e3e2fa5866c2cd28c931d3a00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tA-hIEJQBGIS7nbqdhFsew.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Marenostrum超级计算机—巴塞罗纳超级计算中心(图片来自<a class="ae lh" href="https://bsc.es/" rel="noopener ugc nofollow" target="_blank"> BSC </a></p></figure><p id="25fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">【本帖将在大师课程</strong> <a class="ae lh" href="https://www.fib.upc.edu/en/studies/masters/master-innovation-and-research-informatics/curriculum/syllabus/SA-MIRI" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> <em class="me">超级计算机体系结构</em></strong></a><strong class="lk jd">at</strong><a class="ae lh" href="https://www.upc.edu/en?set_language=en" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">UPC巴塞罗那理工</strong> </a> <strong class="lk jd">的支持下</strong><a class="ae lh" href="https://bsc.es" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">BSC</strong></a><strong class="lk jd"/></p><blockquote class="mf"><p id="1e28" class="mg mh it bd mi mj mk ml mm mn mo md dk translated">下一代人工智能应用提出了新的要求苛刻的计算基础设施。支持人工智能的计算机系统怎么样？我们是怎么到这里的？谁有权访问这些系统？我们作为人工智能从业者的责任是什么？</p></blockquote><p id="6db5" class="pw-post-body-paragraph li lj it lk b ll mp kd ln lo mq kg lq lr mr lt lu lv ms lx ly lz mt mb mc md im bi translated">对于人工智能来说，这是一个激动人心的时刻。我们在<a class="ae lh" href="https://bsc.es" rel="noopener ugc nofollow" target="_blank">巴塞罗那超级计算中心</a>拥有令人印象深刻的科学数据分析系统，涉及基因组学、生物信息学、天文学以及其他许多领域。这些系统可以做出几年前我们认为不可能的惊人之举。</p><p id="6015" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，对于通用应用程序，我们进展非常快。例如，在视频分析中，<a class="ae lh" href="https://www.bsc.es/discover-bsc/organisation/scientific-structure/emerging-technologies-artificial-intelligence/team-people" rel="noopener ugc nofollow" target="_blank">我们在UPC &amp; BSC </a>的研究小组通过引用表达式获得了有价值的视频对象分割结果。给定一个视频和一个语言短语，我们展示如何为短语所指的对象生成二进制掩码。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mu"><img src="../Images/9c8ebfdf8421602c198dcb198f09cec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XnFXFgXfYf2GPnExhx-xMA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由作者根据来自<a class="ae lh" href="https://arxiv.org/pdf/2010.00263.pdf" rel="noopener ugc nofollow" target="_blank"> RefVOS的图片制作:参考VOS、M. Bellver等人的表述。</a></p></figure><h1 id="96e9" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated"><strong class="ak">触发人工智能爆炸</strong></h1><p id="95c6" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">问题是，<strong class="lk jd">为什么是现在？</strong>人工智能从上世纪中叶就有了。<a class="ae lh" href="https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)" rel="noopener ugc nofollow" target="_blank">约翰·麦卡锡</a>在20世纪50年代创造了人工智能一词，与<a class="ae lh" href="https://en.wikipedia.org/wiki/Marvin_Minsky" rel="noopener ugc nofollow" target="_blank">马文·明斯基</a>一起成为人工智能的创始人之一。此外，在1958年，弗兰克·罗森布拉特建立了一个原型神经元网络，他称之为感知器。此外，用于计算机视觉的深度学习神经网络的关键思想在1989年就已经为人所知；此外，对于时间序列的深度学习的基本算法，例如LSTM，在1997年就已经开发出来了。那么，为什么现在会出现这种人工智能热潮呢？</p><p id="798d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们试着找出一个引发AI大爆发<strong class="lk jd">的导火索。</strong> <a class="ae lh" href="https://scholar.google.com/citations?hl=en&amp;user=NkzyCvUAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" rel="noopener ugc nofollow" target="_blank"> Oriol Vinyals </a>表示，根据他最近的一条推文<a class="ae lh" href="https://twitter.com/OriolVinyalsML/status/1253053130411032576" rel="noopener ugc nofollow" target="_blank"/>，数据集发挥了重要作用:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://twitter.com/OriolVinyalsML/status/1253053130411032576" rel="noopener ugc nofollow" target="_blank">https://Twitter . com/OriolVinyalsML/status/1253053130411032576</a></p></figure><p id="8015" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">显然，大数据集的可用性有助于深度学习的算法效率，<a class="ae lh" href="https://openai.com/blog/ai-and-efficiency/" rel="noopener ugc nofollow" target="_blank">在7年的时间里，每16个月翻一番</a>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/02801624104254a34824ac48436c5100.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UjqdiyXvIewzXDKr__lZFQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:<a class="ae lh" href="https://openai.com/blog/ai-and-efficiency/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/ai-and-efficiency/</a></p></figure><p id="5332" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这意味着，在2012年至2019年期间，训练分类器在<a class="ae lh" href="https://en.wikipedia.org/wiki/ImageNet#ImageNet_Challenge" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>上达到<a class="ae lh" href="https://en.wikipedia.org/wiki/AlexNet" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>级别性能所需的操作减少了44倍。</p><p id="e03d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在麻省理工学院的这个<a class="ae lh" href="https://www.youtube.com/watch?v=-fdexQBpRas&amp;t=721s" rel="noopener ugc nofollow" target="_blank">精彩演讲中，Oriol Vinyals还补充了大公司和大学在这个方向上的重要贡献，如TensorFlow、Pytorch、MXNet等开源项目。这些DL框架允许我们现在访问大量基本上最先进的组件，帮助研究人员专注于核心算法组件，我们认为这些组件可能过于关注实现的细节，这有助于加快算法的进展。</a></p><p id="cb9e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">大数据集和开源DL框架在创建“大”算法中扮演着重要角色。但目前的兴奋是由于另一个关键因素，这在2012年AlexNet赢得ImageNet之前并不存在。除了数据和算法，现在还有哪些东西是可用的？</p><blockquote class="nv nw nx"><p id="951e" class="li lj me lk b ll lm kd ln lo lp kg lq ny ls lt lu nz lw lx ly oa ma mb mc md im bi translated">我不想拒绝奥里奥尔·维尼亚的肯定；他是这个领域的老大！！！还有我们课题组的好朋友<a class="ae lh" href="https://twitter.com/DocXavi/status/1208077661173665794" rel="noopener ugc nofollow" target="_blank"/>！；-)</p></blockquote><p id="5e31" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">答案是<strong class="lk jd">大型计算机。</strong>“计算能力是人工智能进步的关键组成部分。如今，深度学习或强化学习是混合这三个组件的结果:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/29f48652c497a11656976aa9813aa9d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KiOU0SiRGgGJ8fgUdH58CA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="7707" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">计算如何进化以满足人工智能的需求？</p><p id="f620" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">看看这张来自OpenAI 的<a class="ae lh" href="https://blog.openai.com/ai-and-compute" rel="noopener ugc nofollow" target="_blank">图，它已经变得非常流行:</a></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/7f2240e7fb4b79717f8d4838cf9fba78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3h7vBSyrxcnR3VEeWxswcg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者(<a class="ae lh" href="https://blog.openai.com/ai-and-compute" rel="noopener ugc nofollow" target="_blank">数据源</a>)</p></figure><p id="d2cf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">自2012年以来，生成人工智能模型所需(或可用)的计算量呈指数增长(Y轴是对数轴)。</p><blockquote class="nv nw nx"><p id="8f5d" class="li lj me lk b ll lm kd ln lo lp kg lq ny ls lt lu nz lw lx ly oa ma mb mc md im bi translated">一个<a class="ae lh" href="https://en.wikipedia.org/wiki/FLOPS" rel="noopener ugc nofollow" target="_blank">petaflop</a>/s-day(PFS-day)由一天内每秒执行10到15次运算组成，即总共约10到20次运算。</p></blockquote><p id="b3c1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，在此期间，这些用于训练模型的计算需求增长了300，000多倍。在最大的人工智能训练中使用的计算量以3.4倍的月倍增时间呈指数增长。</p><h2 id="037b" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">摩尔定律的终结</h2><p id="9568" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">让我们回顾一下，看看计算是如何发展的。计算机性能的大部分改进来自几十年来计算机部件的小型化。你们都听说过摩尔定律。对吗？</p><p id="ea80" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">1975年，英特尔创始人<a class="ae lh" href="https://en.wikipedia.org/wiki/Gordon_Moore" rel="noopener ugc nofollow" target="_blank">戈登·摩尔</a>预测了这种小型化趋势的规律性，现在被称为摩尔定律，直到最近，计算机芯片上的晶体管数量每两年翻一倍。</p><blockquote class="nv nw nx"><p id="3fa0" class="li lj me lk b ll lm kd ln lo lp kg lq ny ls lt lu nz lw lx ly oa ma mb mc md im bi translated">原创论文:<a class="ae lh" href="http://ai.eecs.umich.edu/people/conway/VLSI/BackgroundContext/SMErpt/AppB.pdf" rel="noopener ugc nofollow" target="_blank">摩尔，g。数字集成电子学的进展。在<em class="it">国际电子设备会议的记录中</em>(华盛顿特区，12月)。IEEE，纽约，<strong class="lk jd"> 1975 </strong>，1113。</a></p></blockquote><p id="9faa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然摩尔定律持续了几十年，但它在2000年左右开始放缓，到2018年，摩尔的预测和当前能力(英特尔等公司制造的<a class="ae lh" href="https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext#R26" rel="noopener ugc nofollow" target="_blank">处理器)之间出现了大约15倍的差距。</a><a class="ae lh" href="https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext" rel="noopener ugc nofollow" target="_blank">目前的预期是，随着CMOS技术接近基本极限，这一差距将继续扩大！</a></p><p id="13c8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">可悲的是，就在我们需要快得多的机器进行深度学习的时候，摩尔定律开始变慢了！</p><p id="cb6a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">事实上，在计算机架构社区中还出现了其他重要的观察结果，这些观察结果伴随着摩尔定律:<a class="ae lh" href="https://ieeexplore.ieee.org/document/1050511" rel="noopener ugc nofollow" target="_blank"> Dennard Scaling </a>是Robert Dennard的一项预测，指出随着晶体管密度的增加，每个晶体管的功耗将会下降，因此每平方毫米硅的功耗将接近恒定。根据摩尔定律，每平方毫米硅片的计算能力随着每一代新技术的发展而提高，计算机将变得更加节能。然而，Dennard缩放预测在2007年开始明显放缓，其好处在2010年左右消失。</p><p id="35ae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">随着Dennard扩展的结束，增加芯片上的内核数量可以使功率以大约相同的速度增加。但是进入处理器的能量也必须以热量的形式带走。所以多核处理器受限于散热能力。</p><p id="7006" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">简而言之，应用所有这些观察的结果可以总结在下图中，该图基于最初的图<a class="ae lh" href="https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext" rel="noopener ugc nofollow" target="_blank">“计算机性能的增长”，由Hennessy和Patterson </a>创建:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/75ac7ba901d5c0178ea6cea84b3e2b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mkPbwCw7kFYMsGBV_NNSSA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者(<a class="ae lh" href="https://cacm.acm.org/magazines/2019/2/234352-a-new-golden-age-for-computer-architecture/fulltext" rel="noopener ugc nofollow" target="_blank">数据源</a>)</p></figure><p id="b285" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这张图中，我们可以看到，在20世纪80年代和90年代，当所有这些定律和观察结果都存在时，我们正在将晶体管变成快速计算机，因此当时大约每18个月性能就翻一番。</p><p id="4793" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">多好的时光啊！多么渴望啊！。现在，我们大约每20年才有同样的进步。综上所述，从每18个月因子2到每18个月因子1.05。</p><p id="4ff5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从一个非常普遍的角度来看，从来自伯克利的<a class="ae lh" href="https://people.eecs.berkeley.edu/~istoica/" rel="noopener ugc nofollow" target="_blank">扬·斯托伊察</a>教授在<a class="ae lh" href="https://events.linuxfoundation.org/ray-summit/" rel="noopener ugc nofollow" target="_blank">射线峰会</a>上的演讲中得到的想法，我们可以在前面的图表中直观地表示计算性能增长的影响(大约)。可以看出，考虑到我们正在对数Y轴上移动，在任何情况下，都不允许我们响应AI算法的需求。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi op"><img src="../Images/59ed05b46a21e2291e08ea333bb5a46e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uVzfL7LCQFV6cC41eVoUPg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="644c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">嗯，虽然摩尔定律可能已经终结，但对计算能力增长的需求并没有终结。所以，一个问题出现了，没有摩尔定律怎么得到更快的机器？</p><h2 id="5974" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">专门的硬件呢？</h2><p id="2824" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">为了应对这一挑战，计算机架构师们将注意力集中在构建特定领域的处理器上，以通用性换取性能。背后的理念是，“不要试图做所有的事，只是例外地做几件事”。各公司竞相打造专门的处理器，如Nvidia的GPU和谷歌的TPUs</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oq"><img src="../Images/94a0e80cfe15a5428b80ce895a23b057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qaEud8NSYYzMff-XzkBwsQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:谷歌和英伟达</p></figure><p id="4ca8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们说的“破例做几件事”是什么意思？例如，GPU包含数百个在4x4矩阵上操作的<a class="ae lh" href="https://www.nvidia.com/en-us/data-center/tensor-cores/" rel="noopener ugc nofollow" target="_blank">张量核</a>，这大大加速了深度学习中基本操作的计算，例如数据矩阵乘以权重矩阵，然后是偏差的和。</p><p id="189a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是最终，专门的硬件是不够的。与此同时，像GPU和TPU这样的加速器为桌面带来了更多的计算能力，它们本质上有助于将摩尔定律进一步延长到未来，而不是从根本上提高改进的速度。</p><p id="d48f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一般来说，使用同一个<a class="ae lh" href="https://blog.openai.com/ai-and-compute/" rel="noopener ugc nofollow" target="_blank"> OpenAI图</a>，我们可以直观地表示与CPU相关的专用架构的性能改进的影响。但是，可以看出，在任何情况下，都不允许响应深度学习和强化学习应用的需求:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/7180386dea63340515863ba77898e9ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e1QCCR0yDUSH0CNQBH1lag.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><h2 id="168d" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">并行性:不止一个特定于域的处理器</h2><p id="3654" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">也许我们可以让多个特定领域的处理器协同工作？。<strong class="lk jd"> </strong>让我们来看一个具体的例子，我们在<a class="ae lh" href="https://www.bsc.es/user-support/power.php#systemoverview" rel="noopener ugc nofollow" target="_blank"> BSC中使用了4个能够并行工作的GPU</a>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi os"><img src="../Images/bf23afc5f1be9292ab60654cbcc74956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qti5AW7eorlXuB4Tgx5gkg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:<a class="ae lh" href="https://bsc.es" rel="noopener ugc nofollow" target="_blank"> https://bsc.es </a></p></figure><p id="aa91" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://www.redbooks.ibm.com/redpapers/pdfs/redp5472.pdf" rel="noopener ugc nofollow" target="_blank">这台服务器由IBM提供，有两个CPU，power 9，和4个NVIDIA V100 GPU</a>。现在，我们如何利用这些资源来提高计算速度呢？在深度学习的情况下，我们通常有两种并行方法可以用来实现这一目的:</p><ul class=""><li id="2a85" class="ot ou it lk b ll lm lo lp lr ov lv ow lz ox md oy oz pa pb bi translated">模型并行性</li><li id="00ad" class="ot ou it lk b ll pc lo pd lr pe lv pf lz pg md oy oz pa pb bi translated">数据并行性</li></ul><p id="624a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在第一种方法中，我们将网络的不同层分布在不同的设备上；同时，在第二种方法中，我们在每一个GPU中都有相同的模型，但它们都在处理独立的数据片段，即小批量的独立部分。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ph"><img src="../Images/b45141792a30f9d82f07071d6b9d18b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vdhblzX3Bv4svsUwLJpvxQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="90a4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们有一个可能不适合单个GPU内存的大型模型时，模型并行性非常有用。</p><p id="f2e8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，数据并行性是大多数从业者通常用来扩大深度学习模型的训练过程的，因为他们有一个如此庞大的数据集，以至于在单个GPU上完成一个时期可能需要非常长的时间，可能是几个小时、几天甚至几周。</p><p id="34fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，当有可能共享数据集以加速训练时，我们会这样做，只要模型可以容忍更大的批量。</p><p id="d26a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以使用框架作为Pytorch 的<a class="ae lh" rel="noopener" target="_blank" href="/tensorflow-vs-pytorch-the-battle-continues-9dcd34bb47d4"> TensorFlow来编写多GPU训练。要并行化模型的训练，只需要在PyTorch中用<code class="fe pi pj pk pl b"><a class="ae lh" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html" rel="noopener ugc nofollow" target="_blank">torch.nn.parallel.DistributedDataParallel</a></code>包装模型，在TensorFlow中用<code class="fe pi pj pk pl b"><a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy" rel="noopener ugc nofollow" target="_blank">tf.distribute.MirroredStrategy</a></code>包装模型。非常容易！</a></p><p id="b851" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">TensorFlow和PyTorch需要一个软件堆栈，其中包括作为Python包安装在执行环境中的不同软件层。此外，NVIDIA的<code class="fe pi pj pk pl b"><a class="ae lh" href="https://developer.nvidia.com/cudnn" rel="noopener ugc nofollow" target="_blank">cuDNN</a></code>库帮助我们挤压所有加速器的能力，例如使用我提到的<a class="ae lh" href="https://www.nvidia.com/en-us/data-center/tensor-cores/" rel="noopener ugc nofollow" target="_blank">张量核</a>。</p><p id="cb5e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，当我在<a class="ae lh" href="https://www.bsc.es/user-support/power.php" rel="noopener ugc nofollow" target="_blank">我们的超级计算机</a>中执行深度学习代码时，我需要用<code class="fe pi pj pk pl b">module load </code>命令加载这里列出的所有模块:</p><pre class="ks kt ku kv gt pm pl pn po aw pp bi"><span id="94d0" class="od mw it pl b gy pq pr l ps pt"><strong class="pl jd">$ module load </strong>python/3.7.4_ML cudnn/7.6.4 cuda/10.2 nccl/2.4.8tensorrt/6.0.1 openmpi/4.0.1 atlas/3.10.3 scalapack/2.0.2fftw/3.3.8 szip/2.1.1 ffmpeg/4.2.1 opencv/4.1.1 gcc/8.3.0</span></pre><p id="2637" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个巨大的世界，我部分致力于此，并且非常重要，对于像你这样的深度学习用户来说通常是透明的。</p><p id="d3da" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但最终，4个GPU无法满足深度学习或强化学习中出现的挑战的需求:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi op"><img src="../Images/0df2fb5fda69d1b15aee0aff6239ba7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PAb-4uvrYpwSyWwoOyhhew.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="c32c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们在服务器中可以放置的GPU数量非常有限；<a class="ae lh" href="https://www.ibm.com/products/power-systems-ac922/details" rel="noopener ugc nofollow" target="_blank">在我们讨论的Power 9服务器的情况下，我们最多可以达到6个GPU</a>。</p><h2 id="e975" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">多服务器:分布式计算</h2><p id="ccd9" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">公司必须解决这个问题的方法是将许多这样的服务器放在一起！这就是我们在BSC所做的，利用这个研究平台<a class="ae lh" href="https://www.bsc.es/user-support/power.php" rel="noopener ugc nofollow" target="_blank">，54台服务器通过光纤上的InfiniBand网络连接在一起</a>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pu"><img src="../Images/a44a2d6bfe836eb931d70a3a2a7b047c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cl646VxVPEBwkpfuiTuEVA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="6438" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些服务器运行Linux作为它们的操作系统，并且每一个都由<a class="ae lh" href="https://www.redbooks.ibm.com/redpapers/pdfs/redp5472.pdf" rel="noopener ugc nofollow" target="_blank">两个Power 9处理器和四个512 GB主内存的NVIDIA GPU</a>组成，这意味着我们用两百多个GPU来计数。</p><p id="2d5a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://www.mellanox.com/pdf/whitepapers/IB_Intro_WP_190.pdf" rel="noopener ugc nofollow" target="_blank"> InfiniBand </a>是互连服务器的行业标准，允许从远程服务器快速访问一台服务器的本地内存。</p><p id="0b00" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这个新的场景中，我们需要软件堆栈的扩展来处理神经网络训练过程中的多个分布式GPU。还有其他选择，但是在我们BSC的研究小组中，我们决定使用来自优步的<a class="ae lh" rel="noopener" target="_blank" href="/distributed-deep-learning-with-horovod-2d1eea004c b2"> Horovod </a>。Horovod插入<a class="ae lh" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>、<a class="ae lh" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>和<a class="ae lh" href="https://mxnet.apache.org/versions/1.7.0/" rel="noopener ugc nofollow" target="_blank"> MXNet </a>。</p><p id="9c95" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/distributed-deep-learning-with-horovod-2d1eea004c b2"> Horovod </a>使用<a class="ae lh" href="https://en.wikipedia.org/wiki/Message_Passing_Interface" rel="noopener ugc nofollow" target="_blank">消息传递接口(MPI) </a>与以分布式方式执行的进程进行通信。MPI是一种普遍存在于任何超级计算机中的编程模型，用于通信在不同服务器中执行的进程。它还使用<a class="ae lh" href="https://developer.nvidia.com/nccl" rel="noopener ugc nofollow" target="_blank"> NVIDIA NCCL2库</a>来管理服务器中GPU之间的数据通信。</p><p id="5643" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了加速训练，Horovod使用了之前介绍的<em class="me">数据并行</em>训练模型。也就是说，所有工人都在不同的数据上训练，所有工人都有相同的模型副本，神经网络梯度也是交换的。</p><p id="ba55" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些年来，并行性和分布策略的总和使得人工智能社区对计算的需求不断增长。</p><h1 id="3973" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated"><strong class="ak">新的大型计算机:超级计算的怪物</strong></h1><p id="adc6" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">这种硬件和软件技术的结合创造了真正的超级计算怪兽。例如，谷歌拥有数百个TPU的计算基础设施，这些TPU可以放在一起合作解决深度学习和强化学习社区中出现的挑战。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pv"><img src="../Images/d2547a76f20291b8a0dcedc59e757509.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S9MUiL2GEcTVPWiJA4Y5sQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:<a class="ae lh" href="https://cloud.google.com/blog/products/ai-machine-learning/google-breaks-ai-performance-records-in-mlperf-with-worlds-fastest-training-supercomputer" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/blog/products/ai-machine-learning/Google-breaks-ai-performance-records-in-worlds-fast-training-super computer</a></p></figure><p id="fc19" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">谷歌最近的一篇论文提出了一个多语言翻译质量模型，有6000亿个参数。为了了解这个问题的严重性，我们可以将其与著名的<a class="ae lh" href="https://en.wikipedia.org/wiki/GPT-3" rel="noopener ugc nofollow" target="_blank"> GTP-3 </a>进行比较，这是OpenAI创建的第三代语言预测模型。它“只有”1750亿个参数。</p><p id="316d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种情况下，我们谈论的计算需求相当于22年1 TPU。在这篇论文中，作者用TPU年来衡量业绩。一个有趣的度量！。这意味着，如果我们只有一个可用的TPU，我们将需要22年来做培训。</p><p id="6025" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种情况下，Google将培训分布在2048个TPU上，仅用了4天就取得了成效。</p><blockquote class="nv nw nx"><p id="aa0c" class="li lj me lk b ll lm kd ln lo lp kg lq ny ls lt lu nz lw lx ly oa ma mb mc md im bi translated">关于谷歌TPU基础设施系统架构的详细信息可以在<a class="ae lh" href="https://cloud.google.com/tpu/docs/system-architecture" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="8ece" class="li lj me lk b ll lm kd ln lo lp kg lq ny ls lt lu nz lw lx ly oa ma mb mc md im bi translated">更新15/04/2021-来自微软、英伟达和斯坦福大学的研究:他们研究如何缩放一万亿参数模型的模型。参见论文<a class="ae lh" href="https://arxiv.org/pdf/2104.04473.pdf" rel="noopener ugc nofollow" target="_blank">GPU集群上的高效大规模语言模型训练</a>。</p></blockquote><h1 id="2165" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">新的大算法:深度强化学习</h1><p id="f6fa" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">在上一节中，我们考虑了一个深度学习问题，作为当今人工智能应用程序急切而快速地吞噬计算的一个例子。但实际上，人工智能领域的前沿应用是基于需要大量计算的深度强化学习模型。</p><blockquote class="nv nw nx"><p id="c904" class="li lj me lk b ll lm kd ln lo lp kg lq ny ls lt lu nz lw lx ly oa ma mb mc md im bi translated">如果你想通过介绍性的<a class="ae lh" href="https://towardsdatascience.com/tagged/deep-r-l-explained" rel="noopener" target="_blank">系列文章</a>了解强化学习，这些文章涵盖了强化学习和深度学习的基本概念，从深度强化学习领域开始，你可以在这里找到它<a class="ae lh" href="https://torres.ai/deep-reinforcement-learning-explained-series/" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote><p id="089e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">几年前，像<a class="ae lh" rel="noopener" target="_blank" href="/deep-q-network-dqn-i-bce08bdf2af"> DQN </a>这样的基础算法是为了消耗一些硬件资源而构思的；例如，1CPU+1GPU就足够了。如果我们按照时间线，分布式强化学习(RL)算法的初始版本只需要多几个CPUs例如<a class="ae lh" href="https://arxiv.org/pdf/1602.01783.pdf" rel="noopener ugc nofollow" target="_blank">异步演员-评论家方法</a> (A3C)，它在几个CPU和单个GPU上工作得非常好。</p><p id="f600" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，如果我们仔细看看强化学习算法的最新发展，我们会发现它们越来越需要更多的计算资源。例如，两年前，一个名为<a class="ae lh" href="https://arxiv.org/pdf/1802.01561.pdf" rel="noopener ugc nofollow" target="_blank">黑斑羚</a>的大规模分布式RL被设计成利用数百个CPU。</p><p id="1d09" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当前分布式强化学习代理的架构通常分为<em class="me">参与者</em>和<em class="me">学习者</em>。这是黑斑羚的例子:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/0201dd86b7daaa5dab2897fdea6486fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*746JcbjEd2hmuwg0tJAlmg.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://ai.googleblog.com/2020/03/massively-scaling-reinforcement.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2020/03/massively-scaling-reinforcement . html</a></p></figure><p id="023f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通常在CPU上执行的参与者在环境中采取步骤和在模型上运行推理之间迭代，以预测下一个动作。在收集了足够数量的观察数据后，参与者将向学习者发送观察数据和行动的轨迹。然后学习者优化模型，将模型的参数发送给行动者，每个行动者更新其推理模型的参数。在这种算法中，学习者使用来自数百台CPU机器上的分布式推理的输入在GPU上训练模型。</p><p id="ad1b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">分布式强化学习方法的最新版本，来自DeepMind的<a class="ae lh" href="https://arxiv.org/pdf/1910.06591.pdf" rel="noopener ugc nofollow" target="_blank">种子方法</a>，允许使用超过200个TPU，太神奇了，对吧！！允许我们认为真正的<em class="me">大规模强化学习</em>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/fac0cf5a93b76d74e9b20ee00f015f09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sXoD7RL_YHfAqubpmvNq6w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由Jordi Torres拍摄</p></figure><p id="b878" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">好吧，不进入细节，假设种子强化学习架构被设计来解决<a class="ae lh" href="https://ai.googleblog.com/2020/03/massively-scaling-reinforcement.html" rel="noopener ugc nofollow" target="_blank">IMPALA方法</a>中存在的一些缺点。在这种情况下，神经网络推理由学习者在TPUs上集中进行(而不是像IMPALA那样在actor中)，从而通过确保模型参数和状态保持在本地来实现加速推理和避免数据传输瓶颈。</p><p id="e839" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然actor在每个环境步骤都向学习者发送观察结果，但由于非常高效的网络库<a class="ae lh" href="https://grpc.io/" rel="noopener ugc nofollow" target="_blank"> gRPC </a>(在功能上等同于我之前提到的MPI)，延迟保持得很低。这使得在一台机器上每秒可以完成多达一百万次查询。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/ed4967e80a099397061fc98714a571f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*3QyIJcV7bPNT1EJlNZuHyQ.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:<a class="ae lh" href="https://ai.googleblog.com/2020/03/massively-scaling-reinforcement.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2020/03/massively-scaling-reinforcement . html</a></p></figure><p id="2236" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总之，学习器可以扩展到数千个核(例如，高达2048个TPU)，并且演员的数量可以扩展到数千个机器以充分利用学习器，使得以每秒数百万帧的速度训练成为可能。印象深刻吧。</p><h1 id="cca4" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">人工智能:超级计算能力是真正的推动者！</h1><p id="e8a9" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">我们可以得出结论，计算正在响应人工智能社区的需求，允许我们解决所提出的模型。我在这份出版物中的论点是，<em class="me">计算能力是真正的推动者</em>，或者，如果你喜欢，是人工智能进步的关键组成部分，当我们混合这三个组成部分时:大数据、大算法和大计算机。</p><p id="1618" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在此期间，是什么推动了有效计算的变化？OpenAI将人工智能和计算趋势分为摩尔定律和增加的支出/并行化，以及算法效率的进步:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi px"><img src="../Images/c7e3650a3f8c49e232d46751b0e366ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*_cKloCCRJXFjZnSKrBQs2w.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:<a class="ae lh" href="https://arxiv.org/pdf/2005.04305.pdf" rel="noopener ugc nofollow" target="_blank">测量神经网络的算法效率Danny Hernandez，Tom B. Brown OpenAI。</a></p></figure><p id="b61d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">作者估计，2012年至2018年间，最大规模的人工智能实验可用的有效训练计算将增加750万倍。</p><p id="c466" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">看起来计算将继续响应深度学习和强化学习社区的需求，允许他们解决所需的模型。</p><p id="59fc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">想象一下，谷歌需要更多的计算能力来实现一个新的强化学习算法，那么，谷歌唯一会做的就是聚合更多的并行和分布式服务器！仅此而已！</p><p id="f931" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，几个月前，<a class="ae lh" href="https://cloud.google.com/blog/products/ai-machine-learning/google-breaks-ai-performance-records-in-mlperf-with-worlds-fastest-training-supercomputer" rel="noopener ugc nofollow" target="_blank">谷歌在行业标准基准MLPerf </a>中打破AI性能记录。<a class="ae lh" href="https://mlperf.org" rel="noopener ugc nofollow" target="_blank"> MLPerf基准测试</a>模型被选为尖端机器学习工作负载的代表。</p><p id="7834" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种情况下，Google唯一需要做的就是聚合更多的服务器。最终的系统包括4096个TPU和数百台CPU主机，它们通过超高速互连连接在一起。总的来说，该系统提供了超过430 PFLOPs的峰值性能。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi py"><img src="../Images/55417b8f23166a642e2a91cc51d8c036.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*OmlfSHHDHUFDOfZb82PXKQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:<a class="ae lh" href="https://cloud.google.com/blog/products/ai-machine-learning/google-breaks-ai-performance-records-in-mlperf-with-worlds-fastest-training-supercomputer" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/blog/products/ai-machine-learning/Google-breaks-ai-performance-records-in-worlds-fast-training-super computer</a></p></figure><p id="02d2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">现在看来，增加服务器可以让我们对人工智能模型的需求做出反应。很简单，对吧？嗯，不是这样的！</strong></p><h1 id="23a0" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated"><strong class="ak">需要思考的事情</strong></h1><p id="5e5e" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">在完成我的文章之前，让我给你布置一些“家庭作业”让你自己做。你承诺去做吗？希望如此！</p><h2 id="18be" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">谁能拥有并支付这些超级计算机？</h2><p id="a632" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">在阅读了上一节之后，一个重要的问题出现了:解决这些挑战需要多少计算成本？你想过吗？</p><p id="bfd5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，根据下面的推文中的<a class="ae lh" href="https://twitter.com/eturner303/status/1266264358771757057" rel="noopener ugc nofollow" target="_blank">，我之前提到的训练使用深度学习产生类似人类文本的transformer GPT-3语言模型的估计成本在公共云上接近1200万美元。</a></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来源:<a class="ae lh" href="https://twitter.com/eturner303/status/1266264358771757057" rel="noopener ugc nofollow" target="_blank">https://twitter.com/eturner303/status/1266264358771757057</a></p></figure><blockquote class="nv nw nx"><p id="4574" class="li lj me lk b ll lm kd ln lo lp kg lq ny ls lt lu nz lw lx ly oa ma mb mc md im bi translated">2020年11月29日更新:<a class="ae lh" href="https://arxiv.org/abs/2011.12692" rel="noopener ugc nofollow" target="_blank">腾讯</a>的一篇新论文再次展示了规模的力量，他们使用了一个包含<strong class="lk jd"> 250，000个CPU内核</strong>和<strong class="lk jd"> 2，000个NVIDIA V100 GPU</strong>的集群进行培训。</p></blockquote><p id="e11b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">也许你已经听说过<a class="ae lh" href="https://www.top500.org" rel="noopener ugc nofollow" target="_blank"> top500榜单</a>，这个榜单记录了世界上最快的计算机，每年发布两次，分别在6月和11月世界两大超级计算大会期间(<a class="ae lh" href="https://sc20.supercomputing.org" rel="noopener ugc nofollow" target="_blank"> SC </a>、<a class="ae lh" href="https://www.isc-hpc.com" rel="noopener ugc nofollow" target="_blank"> ISC </a>)。</p><p id="b9fa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一般情况下，公共机构中托管有超级计算机，峰值性能以万亿次浮点运算(每秒10到12次运算)为单位，如下表所示。例如，Top1的峰值性能为500，000万亿次。</p><blockquote class="nv nw nx"><p id="59fe" class="li lj me lk b ll lm kd ln lo lp kg lq ny ls lt lu nz lw lx ly oa ma mb mc md im bi translated"><strong class="lk jd"> TFlop/s =每秒1 000 000 000 000次数值运算。</strong></p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pz"><img src="../Images/14d76c6605217e50f739742a0b9fa78e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D3FTNBSTHEtVgirFfXTr8w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">2020年6月500强榜单前十名(图片由Jordi Torres提供)</p></figure><blockquote class="nv nw nx"><p id="3c31" class="li lj me lk b ll lm kd ln lo lp kg lq ny ls lt lu nz lw lx ly oa ma mb mc md im bi translated">现在，Marenostrum 4，这台位于巴塞罗那的超级计算机，位于UPC大学校园的Torre Girona的<a class="ae lh" href="https://www.bsc.es/sites/default/files/public/gallery/2017_bsc_superordenador_marenostrum-4_barcelona-supercomputing-center.jpg" rel="noopener ugc nofollow" target="_blank">教堂，在这个列表中占据了第38位，对我们来说不错！(</a><a class="ae lh" href="https://www.bsc.es/discover-bsc/visit-our-supercomputer#virtual-visit-title" rel="noopener ugc nofollow" target="_blank">虚访</a>)。</p></blockquote><p id="74a7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">之前提到的谷歌系统，包括4096个TPU和数百个通过超高速互连连接的CPU主机，提供超过430，000 TFLOPs的峰值性能。接近世界第一(根据2020年6月榜单)，和第二以及其他人相差甚远！</p><p id="71b5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">为了创造人工智能，我们需要超级计算机。谁能拥有并支付这些超级计算机？仅民族国家和跨国公司？</strong></p><h2 id="8f9d" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">人工智能碳足迹</h2><p id="f8d8" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">上周，西班牙报纸《先锋报》刊登了这篇文章:数字世界是这个星球上的第三个污染者。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pv"><img src="../Images/1fb1ce94d049b9ab69ed61ba3817d209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Hla8Gp9Tix_QKnLCLjeoQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由Jordi Torres和Júlia Torres拍摄</p></figure><p id="ac45" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，麻省大学的研究对人工智能不可持续的成本提出了建议。他们声称，训练一个通用NLP模型的估计碳成本相当于从纽约到北京的125次往返航班产生的碳量。</p><p id="ad48" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些数字可能是相对的，因为组织可以使用可再生能源为他们的计算设施供电。然后他们可以减少碳足迹。例如，<a class="ae lh" href="https://www.scientific-computing.com/analysis-opinion/true-cost-ai-innov" rel="noopener ugc nofollow" target="_blank">冰岛的能源100%来自可再生的地热和水力发电，其国家电网现代化且可靠</a>；这意味着那里的人工智能系统运行更有效，提供更清洁的能源。</p><p id="60cc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是，即使这些数字是夸大的，人工智能计算需求的指数增长也很难想象我们可以在短期内只用绿色能源来驱动超级计算。</p><p id="b609" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">目前，绝大多数人工智能算法研究都集中于实现最高水平的准确性，而不太关注计算或能源效率。但随着世界的注意力转移到气候变化上，人工智能领域是否应该开始注意它的碳足迹？</strong></p><h2 id="4b86" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">我们不能逃避我们的责任</h2><p id="df72" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">人工智能肯定正在渗透社会，就像电一样，我们会期待什么？我们将“发明”的未来是我们共同做出的选择，而不是偶然发生的事情。</p><p id="3e93" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这很好！例如，遗传学和基因组学从DNA和<a class="ae lh" href="https://link.springer.com/article/10.1186/s13073-019-0689-8" rel="noopener ugc nofollow" target="_blank">的信息中寻找突变和疾病的联系。在人工智能</a>的帮助下，人体扫描可以早期发现疾病，并根据他们的遗传基因预测人们可能面临的健康问题。</p><p id="71d1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是就像生活中的大多数事情一样，哪里有光，哪里就有阴影。人工智能算法传播<a class="ae lh" href="https://theconversation.com/artificial-intelligence-has-a-gender-bias-problem-just-ask-siri-123937" rel="noopener ugc nofollow" target="_blank">性别偏见</a>，人工智能系统<a class="ae lh" href="https://carnegieendowment.org/2019/09/17/global-expansion-of-ai-surveillance-pub-79847" rel="noopener ugc nofollow" target="_blank">在未经公民知情同意的情况下对其进行监控</a>。在许多其他的坏事中！</p><p id="5ffa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们必须仔细考虑即将采用的人工智能及其影响。如果我们继续建设人工智能，而不考虑我们防止其滥用的责任，我们永远也不能指望看到人工智能帮助人类繁荣。</p><p id="c801" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们所有人，无论是正在研究还是想要研究这些课题的人，都不能回避我们的责任，否则，我们将来会后悔的。</p><p id="1a66" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">感谢您阅读本出版物！</p><p id="ea87" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">鸣谢:</strong>非常感谢<a class="ae lh" href="https://www.bsc.es/dominguez-bermudez-juan-luis" rel="noopener ugc nofollow" target="_blank">胡安·路易斯·多明格斯</a>、<a class="ae lh" href="https://www.bsc.es/jover-alvarez-alvaro" rel="noopener ugc nofollow" target="_blank">阿尔瓦罗·约弗·阿尔瓦雷斯</a>、<a class="ae lh" href="https://www.bsc.es/escobar-castells-miquel" rel="noopener ugc nofollow" target="_blank">米克尔·埃斯科瓦尔·卡斯特尔斯</a>和<a class="ae lh" href="https://www.bsc.es/garcia-fuentes-raul" rel="noopener ugc nofollow" target="_blank">劳尔·加西亚·富恩特斯</a>对本文件校对工作的贡献。</p></div><div class="ab cl qa qb hx qc" role="separator"><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf"/></div><div class="im in io ip iq"><h1 id="1a4e" class="mv mw it bd mx my qh na nb nc qi ne nf ki qj kj nh kl qk km nj ko ql kp nl nm bi translated">BSC-CNS人工智能研究组的新兴技术</h1><p id="aa2c" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">我们在<strong class="lk jd">巴塞罗那超级计算中心</strong> 和<a class="ae lh" href="https://www.upc.edu/en" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> UPC巴塞罗那理工</strong> </a> <strong class="lk jd"> </strong>的研究小组正在做这个课题的研究。</p><h2 id="f584" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">动机</h2><p id="22fa" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">现实世界的挑战，例如卫生或银行等部门的图像处理，正在推动基础研究，以创建新的大型深度和强化学习模型。然而，创建这些新模式只是解决这些挑战的一部分。这些模型的训练过程需要大量的计算和执行时间。但是，在今天的并行和分布式基础设施中扩大大型深度和强化学习模型已经成为一个重大挑战，因为它需要机器学习和超级计算方面的大量多学科专业知识。总的来说，这两个领域的研究到目前为止还没有走到一起；现在需要努力在这些算法的并行化中提供联合解决方案，不仅需要对它们重新编程，还需要知道如何有效地使用并行和分布式资源。因为正如强化学习的主要研究者之一Rich Sutton最近所说的那样，“通过大规模计算增强的一般方法是最有效的”。<strong class="lk jd">我们的研究小组旨在引入将这两个研究领域相结合的解决方案。人工智能革命不仅仅是关于新的数学模型；这是关于如何利用HPC为下一代深度和强化学习方法提供的前所未有的机会。</strong></p><h2 id="8608" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">我们在这方面的最新论文</h2><p id="ace1" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated"><a class="ae lh" href="https://arxiv.org/pdf/2002.03647.pdf" rel="noopener ugc nofollow" target="_blank">探索、发现和学习:状态覆盖技能的无监督发现</a>，发表于<a class="ae lh" href="https://icml.cc/" rel="noopener ugc nofollow" target="_blank">第37届国际机器学习会议(ICML2020) </a>。提出了一种新的强化学习无监督技能发现范式。是我们和<a class="ae lh" href="https://twitter.com/DocXavi" rel="noopener ugc nofollow" target="_blank"> @DocXavi </a>共同指导的博士生之一<a class="ae lh" href="https://twitter.com/vcampos7" rel="noopener ugc nofollow" target="_blank"> @vcampos7 </a>最后的贡献。本文由来自<a class="ae lh" href="https://einstein.ai/" rel="noopener ugc nofollow" target="_blank"> Salesforce Research </a>的<a class="ae lh" href="https://twitter.com/alexrtrott" rel="noopener ugc nofollow" target="_blank"> @alexrtrott </a>、<a class="ae lh" href="https://twitter.com/CaimingXiong" rel="noopener ugc nofollow" target="_blank"> @CaimingXiong </a>、<a class="ae lh" href="https://twitter.com/RichardSocher" rel="noopener ugc nofollow" target="_blank"> @RichardSocher </a>共同撰写。</p><h2 id="a3a8" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">关于BSC和UPC</h2><p id="3579" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated"><a class="ae lh" href="https://www.bsc.es/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">巴塞罗那超级计算中心</strong> </a> (BSC)是位于<a class="ae lh" href="https://en.wikipedia.org/wiki/Barcelona" rel="noopener ugc nofollow" target="_blank">巴塞罗那</a>的公共研究中心。它拥有一台13.7千万亿次的超级计算机，其中也包括新兴技术集群。2017年6月世界排名<a class="ae lh" href="https://en.wikipedia.org/wiki/TOP500" rel="noopener ugc nofollow" target="_blank">第13位</a>。</p><p id="8b12" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://www.upc.edu/en" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">加泰罗尼亚理工大学</strong></a>(<em class="me">Universitat politècnica de Catalunya</em>)，目前简称<strong class="lk jd"> BarcelonaTech </strong>，俗称<strong class="lk jd"> UPC </strong>，是西班牙加泰罗尼亚地区最大的工科大学。它还提供其他学科的课程，如数学和建筑。</p></div><div class="ab cl qa qb hx qc" role="separator"><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf"/></div><div class="im in io ip iq"><h2 id="6a43" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">本系列内容:</h2><h2 id="6cd9" class="od mw it bd mx oe of dn nb og oh dp nf lr oi oj nh lv ok ol nj lz om on nl iz bi translated">人工智能的超级计算</h2><ol class=""><li id="c69f" class="ot ou it lk b ll nn lo no lr qm lv qn lz qo md qp oz pa pb bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/artificial-intelligence-is-a-supercomputing-problem-4b0edbc2888d"> <strong class="lk jd">人工智能是超级计算问题</strong> </a></li><li id="5e27" class="ot ou it lk b ll pc lo pd lr pe lv pf lz pg md qp oz pa pb bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/using-supercomputers-for-deep-learning-training-3f9cc3f51d3"> <strong class="lk jd">利用超级计算机进行深度学习训练</strong> </a></li><li id="56fd" class="ot ou it lk b ll pc lo pd lr pe lv pf lz pg md qp oz pa pb bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/scalable-deep-learning-on-parallel-and-distributed-infrastructures-e5fb4a956bef"> <strong class="lk jd">并行和分布式基础设施上的可扩展深度学习</strong> </a></li><li id="20a3" class="ot ou it lk b ll pc lo pd lr pe lv pf lz pg md qp oz pa pb bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/train-a-neural-network-on-multi-gpu-with-tensorflow-42fa5f51b8af"> <strong class="lk jd">用TensorFlow </strong> </a>在多GPU上训练一个神经网络</li><li id="f921" class="ot ou it lk b ll pc lo pd lr pe lv pf lz pg md qp oz pa pb bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/distributed-deep-learning-with-horovod-2d1eea004cb2"> <strong class="lk jd">分布式深度学习与Horovod </strong> </a></li></ol></div><div class="ab cl qa qb hx qc" role="separator"><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf qg"/><span class="qd bw bk qe qf"/></div><div class="im in io ip iq"><div class="ks kt ku kv gt qq"><a href="https://torres.ai/deep-reinforcement-learning-explained-series/" rel="noopener  ugc nofollow" target="_blank"><div class="qr ab fo"><div class="qs ab qt cl cj qu"><h2 class="bd jd gy z fp qv fr fs qw fu fw jc bi translated">深度强化学习解释-乔迪托雷斯。人工智能</h2></div><div class="qx l"><div class="qy l qz ra rb qx rc lb qq"/></div></div></a></div></div></div>    
</body>
</html>