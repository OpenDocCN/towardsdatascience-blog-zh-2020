<html>
<head>
<title>Advanced AI is almost here, run.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高级AI快到了，快跑。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/advanced-ai-is-almost-here-run-d0d43d483d08?source=collection_archive---------20-----------------------#2020-11-08">https://towardsdatascience.com/advanced-ai-is-almost-here-run-d0d43d483d08?source=collection_archive---------20-----------------------#2020-11-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d914" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我们应该在多大程度上拥抱有意识机器的发展？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/50e855bdb92efc0513645b9a66a8c983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*z8gF3Nq_g90IyQhi"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@possessedphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">附身摄影</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="b2e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated">尽管人工智能已经在全球广泛使用，但它的发展应该得到专业和谨慎的处理，因为我们仍然不知道有意识的机器会对人类产生什么影响。该领域的领先研究人员警告其潜在后果，史蒂芬·霍金教授声称，超级智能机器可能会导致人类的末日。</p><p id="382c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人工智能是计算机系统的理论和发展，能够执行通常需要人类智能的任务。近年来，由于其快速的发展和广泛的应用，以及公众人物如埃隆·马斯克和比尔·盖茨对该主题的关注，它已经获得了主流媒体的关注。事实证明，这是计算机科学家和哲学家之间争论的话题，其中一些人表示，超级智能人工智能将是我们创造的最后一件东西。</p><p id="3cf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这份报告评估了来自杰出研究人员和学术报告的证据、研究和陈述，并得出结论认为，应该允许开发人工智能，但只能在严格到适度的监督和监管下进行。它致力于讨论研究问题:超级智能人工智能是否对人类构成生存威胁，创造有意识的机器是一个好主意吗，创造有意识的机器是否不道德？</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="2970" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">创造有意识的机器对人类来说是个好主意吗？</h1><h2 id="ecb8" class="na mj iq bd mk nb nc dn mo nd ne dp ms lf nf ng mu lj nh ni mw ln nj nk my nl bi translated">人工智能的种类—</h2><p id="70a4" class="pw-post-body-paragraph kw kx iq ky b kz nm jr lb lc nn ju le lf no lh li lj np ll lm ln nq lp lq lr ij bi translated">人工智能可以分解为三个categories⁴.人工狭义智能(ANI)是一种低水平的智能，ANI可以执行复杂的任务，但不能理解它为什么要这样做，它不会在有意识的层面上思考，例如Siri，Alexa。人工通用智能(AGI)是有意识的，它可以在与人类相同的水平上思考，有自我意识，可以理解它是一台机器。AGI还不存在。最后，人工超级智能(ASI)是比人类更高级的机器智能，它也尚不存在，但它能够解决超出我们理解的问题。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="91aa" class="na mj iq bd mk nb nc dn mo nd ne dp ms lf nf ng mu lj nh ni mw ln nj nk my nl bi translated">时间框架—</h2><p id="1199" class="pw-post-body-paragraph kw kx iq ky b kz nm jr lb lc nn ju le lf no lh li lj np ll lm ln nq lp lq lr ij bi translated">由于AGI和阿西还不存在，这是一个猜测的主题，他们是如何迫在眉睫，因此我们需要如何关注。field⁵的一项专家调查发现，受访者的中位数估计，到2040年，AGI将有二分之一的可能性被创造出来，到2075年，这一比例将上升至十分之九。他们还预测，不到30年后，ASI也将步其后尘。ASI对人类来说变成“坏”或“极其坏”的可能性估计为三分之一。</p><p id="01fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然该调查很有见地，并为我们提供了一个工作时间框架，但应谨慎依赖，因为该调查报告并未提及这些专家是谁，以及被归类为专家的标准是什么。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="75a4" class="na mj iq bd mk nb nc dn mo nd ne dp ms lf nf ng mu lj nh ni mw ln nj nk my nl bi translated">好处和威胁—</h2><p id="a70f" class="pw-post-body-paragraph kw kx iq ky b kz nm jr lb lc nn ju le lf no lh li lj np ll lm ln nq lp lq lr ij bi translated">据了解，有了意识，自主的决定和意见就形成了。这意味着有意识的机器可能有与其创造者不一致的目标。它们的处理时间比人快数百万倍，很难抵御。来自威斯康星大学麦迪逊分校的一份报告指出，创造一个人工智能可能导致人工智能武装race⁶.AGI将允许自主武器系统，它可以很快变得非常复杂，当机器从AGI转换到ASI时，我们可能会失去对它的控制。以及试图获得该技术的敌对国家。这可以被归类为一种生存威胁，因为人类对一台武装的超级智能机器无能为力。在同一篇论文中，进行了一项调查，48%的受访者同意“社会应该优先考虑将人工智能的潜在风险降至最低”。虽然现在的回应有点过时，观点可能也有所改变，但这反映了一个事实，即人们对开发有意识的机器存在担忧。</p><p id="1018" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">仅仅因为有意识的机器对人类来说是一大进步，它带来了威胁，这并不意味着它根本不应该被创造出来。AGI全球协作和政府法规等解决方案可以到位，以确保其得到负责任的发展。让-马克·里克利博士声称，AGI的好处将是巨大的，它可以在防止欺诈和发现网络攻击以及国防和anti-terrorism⁷.等活动中发挥重要作用虽然，里克利的想法很容易引起争议，因为AGI也可以帮助网络攻击和恐怖主义。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="41ab" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">创造人工意识对机器公平吗？</h1><p id="d19a" class="pw-post-body-paragraph kw kx iq ky b kz nm jr lb lc nn ju le lf no lh li lj np ll lm ln nq lp lq lr ij bi translated">当建造有意识的机器时，伦理是一件需要考虑的重要事情，因为它本质上是在创造生命。有太多限制的意识就像关在笼子里的动物。此外，无情地强迫一个意识去执行一个又一个的任务会让人想起我们现在回想起来并不愉快的历史事件，例如奴隶制。</p><p id="c734" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了防止历史重演，需要就对AGI能做什么和不能做什么制定指导方针。博斯特罗姆提出了一个被认为是ethical⁸的总清单，随着伦理不可避免的转变，这个清单可以更新。AI也应该遵守这个主列表。虽然这是一个很好的建议，但可能被认为是不现实的。Bostrom只提出了一个解决方案，但没有说明如何实施。假设每个人都会遵守它是不合理的。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="036d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">最后</h1><p id="4a93" class="pw-post-body-paragraph kw kx iq ky b kz nm jr lb lc nn ju le lf no lh li lj np ll lm ln nq lp lq lr ij bi translated">“制造一台有意识的机器对人类来说是个好主意吗？”这个问题似乎没有明确的答案，但如果不付诸行动，它还是会继续下去。因此，由于人工意识是如此不朽和改变世界，似乎最好继续创造它，但要有严格的规定来确保它安全和负责任地发展。</p><p id="d486" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">AGI很可能是对人类的生存威胁，赋予机器意识也可能是不道德的，如果不是出于责任感的话。确实有证据表明，AGIs的发明会给人类带来许多好处，但这并不意味着我们可以忽视威胁，这些威胁可能更重要。</p><p id="453d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在回答“创造人工意识对机器公平吗？”，就看谁在控制它了。这就是监管如此重要的原因，也是如此大规模的技术进步不能向世界隐瞒的原因。</p><p id="b141" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">技术的演变是不可避免的，但这并不意味着人类在这样做的时候不应该是道德的、安全的和前瞻性的，特别是在先进的人工智能的情况下。</p><p id="df72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="http://www.linkedin.com/in/joe-drury18" rel="noopener ugc nofollow" target="_blank">www.linkedin.com/in/joe-drury18</a></p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="6332" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">参考</h1><p id="488b" class="pw-post-body-paragraph kw kx iq ky b kz nm jr lb lc nn ju le lf no lh li lj np ll lm ln nq lp lq lr ij bi translated">[1]塞兰·琼斯博士，2014年。斯蒂芬·霍金警告人工智能可能会终结人类。英国广播公司新闻，2014年第2版</p><p id="9693" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]词典|英语。(2019).人工智能| Lexico对人工智能的定义。【在线】见:<a class="ae kv" href="https://www.lexico.com/en/definition/artificial_intelligence" rel="noopener ugc nofollow" target="_blank">https://www . lexico . com/en/definition/artificial _ intelligence</a>【2019年10月23日访问】。</p><p id="23cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3]n .博斯特罗姆，2003年。高级人工智能中的伦理问题。科幻小说与哲学:从时间旅行到超级智慧，第241页</p><p id="0803" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4]特威迪，M. (2017)。3种类型的人工智能:窄，一般，和超级人工智能。[在线]</p><p id="b96c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5]米勒，V.C .和n .博斯特罗姆，2016年。人工智能的未来发展:专家意见调查。《人工智能的基本问题》(第555-572页)。斯普林格，查姆。</p><p id="31ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[6] Ramamoorthy，a .和Yampolskiy，r .，2018年。超越疯狂？人工智能竞赛。国际电联J，1，第1-8页。</p><p id="5c53" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[7] Rickli，J.M .，3.2评估人工智能的风险。</p><p id="a9a6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[8]n . Bostrom和e . Yudkowsky，2014年。人工智能的伦理。《剑桥人工智能手册》，316，第334页</p><p id="290d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">代码机器人。可在:<a class="ae kv" href="https://codebots.com/artificial-intelligence/the-3-types-of-ai-is-the-third-even-possible" rel="noopener ugc nofollow" target="_blank">https://code bots . com/artificial-intelligence/the-3-types-of-ai-is the-third-even-possible</a>【2019年11月12日访问】。</p><p id="e995" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">https://unsplash.com/photos/YKW0JjP7rlU<a class="ae kv" href="https://unsplash.com/photos/YKW0JjP7rlU" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>