<html>
<head>
<title>Embedding and clustering combining Knime and Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">结合Knime和Python的嵌入和聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/umap-dimension-reduction-and-dbscan-for-clustering-mnist-database-within-knime-421f471fcbd?source=collection_archive---------28-----------------------#2020-11-13">https://towardsdatascience.com/umap-dimension-reduction-and-dbscan-for-clustering-mnist-database-within-knime-421f471fcbd?source=collection_archive---------28-----------------------#2020-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="c5c3" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="38ec" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">KNIME中聚类MNIST数据库的UMAP降维和DBSCAN</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/9cf2d0ee6dd98859c4fedacdbebf4e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QulhC6FiV6N2hV_CViZTAQ.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">聚类。橄榄和树叶。形状和颜色。(图片由作者提供)</p></figure><p id="a153" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae ma" href="http://www.knime.com" rel="noopener ugc nofollow" target="_blank"> Knime </a>是一个免费的开源数据分析、报告和整合平台。KNIME通过其模块化的数据流水线概念，集成了用于<a class="ae ma" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>和<a class="ae ma" href="https://en.wikipedia.org/wiki/Data_mining" rel="noopener ugc nofollow" target="_blank">数据挖掘</a>的各种组件。对于像我这样没有很强编码背景的人来说，Knime是端到端数据科学体验的大门。在过去两年与Knime的合作中，我已经能够理解数据科学的全球图景，我将我的恐惧抛在身后，现在我在充满挑战和令人惊叹的数据科学世界中越走越深。</p><p id="96ae" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">几天前，我在《走向数据科学》上读到了一篇文章，作者是<a class="mb mc ep" href="https://medium.com/u/fb562cc4a1e2?source=post_page-----421f471fcbd--------------------------------" rel="noopener" target="_blank">罗莎丽亚·西里波</a>和<a class="ae ma" href="https://www.linkedin.com/in/misha-lisovyi/" rel="noopener ugc nofollow" target="_blank">米莎·利索夫伊</a>，展示了一个非常好的<a class="ae ma" rel="noopener" target="_blank" href="/is-zero-closer-to-eight-or-to-one-c6392242b696"> Knime工作流，其中涉及应用于MNIST数据集的t-SNE </a>。我曾经和UMAP一起做过类似的工作流程，效果不错。</p><p id="ba6e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">受到Linkedin上的Rosaria Silipo的鼓励，我决定发表我的第一个故事。</p><h1 id="76b6" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">这个故事的提议是什么？</h1><p id="3e03" class="pw-post-body-paragraph le lf iq lg b lh mv ka lj lk mw kd lm ln mx lp lq lr my lt lu lv mz lx ly lz ij bi translated">本文的原始资料是闫乐存的从0到9的手写数字的OpenML 的<a class="ae ma" href="https://www.openml.org/d/554" rel="noopener ugc nofollow" target="_blank"> MNIST数据集。该数据集包含70000个28x28像素的手写数字，灰度等级为0-255。也就是说，我们有70000个向量，维数是784。</a></p><p id="47ea" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该数据在Knime内的Python脚本中读取，并在该Python脚本上应用UMAP降维算法，因此我们可以将数据集的每个图像映射到低维空间的一个点上。出于表现结果的目的，逻辑上，我使用2D和3D作为目标尺寸。</p><p id="9a3c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">之后，为了更有趣，由于生成的UMAP嵌入数据忽略了标签，我在Knime中应用了一个DBSCAN节点来对结果进行聚类。我们稍后将检查结果。</p><h1 id="530e" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">UMAP:降维的一致流形逼近和投影</h1><blockquote class="na nb nc"><p id="7365" class="le lf nd lg b lh li ka lj lk ll kd lm ne lo lp lq nf ls lt lu ng lw lx ly lz ij bi translated"><a class="ae ma" href="https://umap-learn.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">均匀流形近似和投影(UMAP) </a>是一种降维技术，可用于类似于t-SNE的可视化，也可用于一般的非线性降维。该算法基于对数据的三个假设</p><p id="f741" class="le lf nd lg b lh li ka lj lk ll kd lm ne lo lp lq nf ls lt lu ng lw lx ly lz ij bi translated">-数据在黎曼流形上均匀分布；</p><p id="09a2" class="le lf nd lg b lh li ka lj lk ll kd lm ne lo lp lq nf ls lt lu ng lw lx ly lz ij bi translated">-黎曼度量是局部常数(或者可以近似为常数)；</p><p id="a536" class="le lf nd lg b lh li ka lj lk ll kd lm ne lo lp lq nf ls lt lu ng lw lx ly lz ij bi translated">-歧管是局部连接的。</p></blockquote><p id="f64f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">什么是黎曼流形？等等！！什么是流形？流形是n维的拓扑对象，在一个点的邻域上，它的局部行为类似于n维欧几里得空间。一个好的外行例子是地球。Rieamannian流形是光滑的可微流形，其中可以定义函数的长度、曲线、角度、体积、梯度等概念。更多关于流形或黎曼流形的信息，试试这里的<a class="ae ma" rel="noopener" target="_blank" href="/manifolds-in-data-science-a-brief-overview-2e9dde9437e5"/>和这里的<a class="ae ma" rel="noopener" target="_blank" href="/geodesic-regression-d0334de2d9d8"/>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nh"><img src="../Images/0b58e44d3cfb5d759e1d0241052db9af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Mqpnv3PjcS84oTNL.jpg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">维基百科中的一个黎曼流形。(斯特拉特，公共领域，通过<a class="ae ma" href="http://StuRat, Public domain, via Wikimedia Commons" rel="noopener ugc nofollow" target="_blank">维基共享</a>)</p></figure><p id="096c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">UMAP有一些参数来控制其性能。</p><p id="bed4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"><em class="nd">n _ neighbors</em></strong><em class="nd">:n _ neighbors越大，算法寻找的邻域越大，并且趋向于全局整体结构。n_neighbors越低，UMAP将关注的细节结构越多。</em></p><p id="b426" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="nd">最小距离</em> </strong> <em class="nd">:定义算法将考虑在最终缩减空间中将点打包在一起的最小距离。这意味着较小的最小距离值将导致较小的聚类嵌入。另一方面，最小距离的高值将导致UMAP算法指向全局结构。</em></p><p id="dd4a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="nd">度量</em> </strong> <em class="nd">:我们可以定义算法在原始空间中计算距离的度量。</em></p><p id="5ad2" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">难以消化！我知道。对工程师来说近乎神奇。从黑暗中走出来，明确地(简单地！！)，UMAP通过n维点(n低至2)对每个高维对象进行建模，使得相似的对象通过附近的点进行建模，而不相似的对象通过远处的点进行建模的概率很高。</p><h1 id="392e" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">基于密度的噪声应用空间聚类</h1><p id="8e89" class="pw-post-body-paragraph le lf iq lg b lh mv ka lj lk mw kd lm ln mx lp lq lr my lt lu lv mz lx ly lz ij bi translated">DBSCAN，<a class="ae ma" href="https://www.dbs.ifi.lmu.de/Publikationen/Papers/KDD-96.final.frame.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ja">基于密度的具有噪声的应用的空间聚类</strong> </a>，是在无监督的lerning方法中考虑的一种聚类算法。基于三个输入参数，该算法能够通过将紧密地打包在一起的点(具有一定数量的附近邻居的点)分组在一起，将单独且远离地位于低密度区域(其最近的邻居太远)中的那些点标记为噪声，来将一组数据群集化。</p><p id="b6ea" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">可以想象，支配DBSCAN算法的性能的参数与决定一个点是否彼此靠近的距离<em class="nd"> epsilon </em>有关，并且还与认为一个点是“邻域”或核心点所必需的附近点的最小数目<em class="nd">最小点</em>。集群是所有核心点及其邻居的总和。最后，在Knime扩展<a class="ae ma" href="https://kni.me/e/He68zjghsrLBqltN" rel="noopener ugc nofollow" target="_blank"> KNIME距离矩阵</a>中包含的DBSCAN的KNIME节点中，我们可以看到需要一个度量输入，因此算法具有必要的距离模型来计算数据集上点之间的de距离。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/98e987cf39d0cd42e455d04533205b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*VbUop3ziH7YkgWjWZ-boLA.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">正在配置DBSCAN节点。(作者图片)</p></figure><p id="6c4a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">总结一下:</p><p id="4aa7" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="nd"> epsilon </em> </strong> <em class="nd">:指定点之间的距离，因此它们可以被认为是集群的一部分。如果两个点之间的距离小于epsilon，则这两个点将被视为属于同一集群的邻居。</em></p><p id="581e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="nd">最小点数</em> </strong> <em class="nd">:从点p可达的最小点数，使得点p可被视为核心点。</em></p><p id="1627" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="nd">距离模型</em> </strong> <em class="nd">如前所述，需要用距离模型通知DBSCAN节点对数据集中的点间距离进行评估。为此，我们使用Mumeric Distance节点。</em></p><p id="2a08" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">DBSCAN算法的显著优点是:</p><ul class=""><li id="95d7" class="nj nk iq lg b lh li lk ll ln nl lr nm lv nn lz no np nq nr bi translated">DBSCAN不需要用户指定群集的数量。</li><li id="9911" class="nj nk iq lg b lh ns lk nt ln nu lr nv lv nw lz no np nq nr bi translated">DBSCAN管理噪声概念，并丢弃和标记噪声点</li></ul><h1 id="f8ef" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">Knime工作流</h1><p id="88c2" class="pw-post-body-paragraph le lf iq lg b lh mv ka lj lk mw kd lm ln mx lp lq lr my lt lu lv mz lx ly lz ij bi translated">这两个Knime工作流均在Knime Hub中发布和提供:</p><p id="e200" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae ma" href="https://kni.me/w/wNDZj8xqFkJgbgzz" rel="noopener ugc nofollow" target="_blank"> UMAP DBSCAN MNIST 2D巨蟒</a>。UMAP 2D维嵌入</p><p id="b729" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae ma" href="https://kni.me/w/NCrq2LknJF3fUtui" rel="noopener ugc nofollow" target="_blank"> UMAP DBSCAN MNIST 3D巨蟒</a>。UMAP三维嵌入</p><p id="2e34" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我将只关注2D解释，因为两个工作流实际上是相同的。不过，我会在最后展示两者的比较结果。</p><p id="6b3f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">遵循你可以看到整个工作流程，稍后我会解释它逐块。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nx"><img src="../Images/3a807bc625752cffc7a26b359db5f222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xZnmtU5gOMQ6gGQjzLMa2w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">2D UMAP嵌入的工作流程。(图片由作者提供)</p></figure><h2 id="b8f4" class="ny me iq bd mf nz oa dn mj ob oc dp mn ln od oe mp lr of og mr lv oh oi mt iw bi translated">Python脚本</h2><p id="a0cf" class="pw-post-body-paragraph le lf iq lg b lh mv ka lj lk mw kd lm ln mx lp lq lr my lt lu lv mz lx ly lz ij bi translated">接下来，您可以找到第一个数据块的详细图片，使用该数据块从<a class="ae ma" href="https://kni.me/e/9Z2SYIHDiATP4xQK" rel="noopener ugc nofollow" target="_blank"> Knime Python扩展的Python源节点中提取数据并计算UMAP。</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/036e1b2505f149e345c1678eb358400b.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*dPqyBXnV9P3E18jIl_n1dA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Python抓取和UMAP。(图片由作者提供)</p></figure><p id="7368" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">中间的橙色块是Python源节点，包括用于从OpenML获取数据和执行UMAP技术的脚本。两个变量节点“Metric”和“Number of rows”被合并并像UMAP算法的输入一样被传递。对于最终的结果，我使用了欧几里德度量，关于“行数”整数输入节点，我只是在测试时用它来改变低数值。只是时间问题。在右边，我使用列重命名节点在工作流中用可理解的名称命名列。</p><p id="e322" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这里，您可以找到Python源节点中的代码:</p><pre class="kp kq kr ks gt ok ol om on aw oo bi"><span id="712b" class="ny me iq ol b gy op oq l or os">from pandas import DataFrame<br/>from sklearn.datasets import fetch_openml<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="3e73" class="ny me iq ol b gy ot oq l or os"># Dimension reduction and clustering libraries<br/>import umap</span><span id="6507" class="ny me iq ol b gy ot oq l or os">in_batch = flow_variables[‘input_batch’]<br/>umap_metric = flow_variables[‘metric’]</span><span id="67e8" class="ny me iq ol b gy ot oq l or os">#Varias metricas posibles<br/> # mnist_784<br/> # Fashion-MNIST<br/>mnist = fetch_openml(‘mnist_784’, version=1, as_frame=False)<br/>mnist.target = mnist.target.astype(int)</span><span id="71b7" class="ny me iq ol b gy ot oq l or os">standard_embedding = umap.UMAP(<br/> n_neighbors=30,<br/> min_dist=0.0,<br/> n_components=2,<br/> metric=umap_metric,<br/> random_state=42<br/> ).fit_transform(mnist.data[:in_batch, 1:])</span><span id="98f2" class="ny me iq ol b gy ot oq l or os">#Añadimos los target<br/>array2D_1=standard_embedding<br/>array2D_2=mnist.target[:in_batch]<br/>array2D_2=np.reshape(array2D_2,(in_batch,1))<br/>array_to_save=np.concatenate((array2D_1,array2D_2),axis=1)</span><span id="3235" class="ny me iq ol b gy ot oq l or os"># Output table for the node<br/>output_table = DataFrame(array_to_save)</span></pre><h2 id="1871" class="ny me iq bd mf nz oa dn mj ob oc dp mn ln od oe mp lr of og mr lv oh oi mt iw bi translated">第一次绘图</h2><p id="9359" class="pw-post-body-paragraph le lf iq lg b lh mv ka lj lk mw kd lm ln mx lp lq lr my lt lu lv mz lx ly lz ij bi translated">在执行了UMAP算法之后，我们有了MNIST数字的2D映射。为了比较结果，我使用了两种不同的绘图方法。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/2ec32ecc90f5a532d7e7a0e4da625877.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*cS2L2OivCNt3N7bialsnFQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">策划UMAP。(图片由作者提供)</p></figure><p id="9fc6" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="nd"> UMAP输出散点图(Plotly)结合色彩管理器</em></p><p id="09f8" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">来自<a class="ae ma" href="https://kni.me/e/NXfbxRi-JV1Tt7yC" rel="noopener ugc nofollow" target="_blank">的散点图Plotly Knime扩展</a>是一个非常好的节点。结果是交互式的，输出颜色可通过颜色管理器节点进行配置，因此缩减的2D空间中的数据集点可根据其在嵌入前在原始空间中的位数进行标注。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nh"><img src="../Images/b18ffba25e269af2ccd5424054b0b9b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ot-dTYZKlLLprt3nRUYyOg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用散点图绘制的UMAP算法定义的2D簇。(图片由作者提供)</p></figure><p id="b1a4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">或者，在3D中，我们可以使用散点图节点，而不是散点图节点，结果如下。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nh"><img src="../Images/6a7b6d6356ee3ffccac19681c40d85b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dzvgs9kONCVN32WYD0QVsg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用散点图3D绘制的UMAP算法定义的3D聚类。(图片由作者提供)</p></figure><p id="d8a0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">请注意，UMAP算法已经在2D和3D中检测和绘制了相同的10个清楚区分的簇。</p><p id="b80c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="nd">用Python视图输出UMAP</em></p><p id="57c5" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">使用Python源节点和一段代码，也可以找到类似的结果。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/9094056b7d3de801095aa1f792b51a47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*wu9_FCOXcOQr_izLlJKzLw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用Python绘制的UMAP算法定义的2D聚类。(图片由作者提供)</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ow"><img src="../Images/8e150884656b7fffc95f6aabb2c9070e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9dbQQdEZszb32NR-pSkQAA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用Python绘制的UMAP算法定义的三维聚类。(图片由作者提供)</p></figure><p id="7c64" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">接下来，您可以在Knime的Python视图节点中找到执行这两个绘图的代码片段。</p><p id="6d20" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了2D</p><pre class="kp kq kr ks gt ok ol om on aw oo bi"><span id="ad2a" class="ny me iq ol b gy op oq l or os">from io import BytesIO<br/>import matplotlib as mplt<br/>import matplotlib.pyplot as plt<br/>import numpy as np</span><span id="fd72" class="ny me iq ol b gy ot oq l or os">label_array=input_table['Col2']<br/>colors = ['red', 'blue', 'green', 'yellow', 'orange', 'peru', 'lime', 'pink', 'steelblue', 'olive']</span><span id="d308" class="ny me iq ol b gy ot oq l or os">plt.scatter(input_table['Col0'], input_table['Col1'],<br/>   c=label_array, alpha=0.5, marker='o',<br/>   cmap=mplt.colors.ListedColormap(colors),<br/>   s=0.1,<br/>            label="Label")<br/>plt.xlabel("X")<br/>plt.ylabel("Y")<br/>plt.legend(loc='best')</span><span id="2947" class="ny me iq ol b gy ot oq l or os">buffer=BytesIO()<br/>plt.savefig(buffer,format="svg")<br/>output_image = buffer.getvalue()</span></pre><p id="c36a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于3D:</p><pre class="kp kq kr ks gt ok ol om on aw oo bi"><span id="721e" class="ny me iq ol b gy op oq l or os">from io import BytesIO<br/>import matplotlib as mplt<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>from mpl_toolkits.mplot3d import Axes3D</span><span id="46b3" class="ny me iq ol b gy ot oq l or os">label=input_table['Col3']</span><span id="ff70" class="ny me iq ol b gy ot oq l or os">colors = ['red', 'blue', 'green', 'yellow', 'orange', 'peru', 'lime', 'pink', 'steelblue', 'olive']</span><span id="91b1" class="ny me iq ol b gy ot oq l or os">fig = plt.figure(figsize=(12,12))<br/>ax = fig.add_subplot(111, projection='3d')</span><span id="2669" class="ny me iq ol b gy ot oq l or os">ax.scatter(input_table['Col0'],input_table['Col1'] ,input_table['Col2'],<br/>           c=input_table['Col3'],<br/>           cmap=mplt.colors.ListedColormap(colors),<br/>           marker='o',<br/>           s=1)</span><span id="0266" class="ny me iq ol b gy ot oq l or os">ax.set_xlabel('X Label')<br/>ax.set_ylabel('Y Label')<br/>ax.set_zlabel('Z Label')</span><span id="aa22" class="ny me iq ol b gy ot oq l or os">buffer=BytesIO()<br/>plt.savefig(buffer,format="svg")<br/>output_image = buffer.getvalue()</span></pre><h2 id="b72b" class="ny me iq bd mf nz oa dn mj ob oc dp mn ln od oe mp lr of og mr lv oh oi mt iw bi translated">DBSCAN节点和sorroundings</h2><p id="a33c" class="pw-post-body-paragraph le lf iq lg b lh mv ka lj lk mw kd lm ln mx lp lq lr my lt lu lv mz lx ly lz ij bi translated">因此，到目前为止，我们有一组2D(或3D)点，代表一组700000个书面图像。我们知道哪个原始数字对应于缩减空间的每个点，因为原始标签已经添加到UMAP输出中，正如您在此处看到的:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ox"><img src="../Images/e045e8583cbfa37bce24256377608ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*accAX0ztJ3ztn4UQVidBFg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">第0列:X，第1列:Y，第2列:对应于原始数字的标签。(图片由作者提供)</p></figure><p id="fee4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">但是想象一下我们没有原始标签。我们会有大量没有进一步信息的点，如下所示:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nh"><img src="../Images/ee2816e9630aa6d7ea7262a8104ab1a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6IfBOahQvy0hnlndrhMTNA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">未标记的点，在灰色物质下面有什么结构吗？。(图片由作者提供)</p></figure><p id="2bfb" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在是时候使用DBSCAN并尝试找到在这个分散的无意义的图下面是什么结构了。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/98e987cf39d0cd42e455d04533205b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*VbUop3ziH7YkgWjWZ-boLA.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">DBSCAN节点。(图片由作者提供)</p></figure><p id="aad6" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们将UMAP的输出驱动到DBSCAN节点。此外，我们为其余的DBSCAN输入提供变量，尽管它们可以在节点内部配置。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oy"><img src="../Images/7486fde8cdedfceb66700c6e36e62828.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PPwPex_rnW-0ves_scT9Qg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">DBSCAN的配置屏幕。参见注释“Eps和Minpts”由变量控制。(图片由作者提供)</p></figure><p id="de76" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于2D DBSCAN，我使用了<em class="nd">ε= 0.15</em>和<em class="nd">最小点数=50 </em>。数值距离节点中的公制被配置为欧几里得。</p><p id="06b4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">经过一些字符串操作后，输出是一个包含聚集数据的表。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oz"><img src="../Images/0384064a21c48421a7e0042a06c8badf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M5kdlte6v7JYuoIJUi630Q.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">请参见包含集群数据的最后一列。请参阅高亮显示的行，其中一个点被认为是噪点。(图片由作者提供)</p></figure><p id="ab8f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果我们在2D或3D的缩减空间内绘制点，并用DBSCAN产生的聚类进行标记，我们会发现什么？</p><p id="9128" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们看看。</p><h1 id="e0a5" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">总体结果</h1><p id="561f" class="pw-post-body-paragraph le lf iq lg b lh mv ka lj lk mw kd lm ln mx lp lq lr my lt lu lv mz lx ly lz ij bi translated">在下图中，您可以看到DBSCAN识别的群集与UMAP根据原始映像交付的群集相同。这是非常令人满意和美好的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nh"><img src="../Images/bd5e11c2870b197c6e480989be57ce2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2rXVK3y3ScSAEIb5EuAtOw.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">2D数据库扫描聚类。(图片由作者提供)</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nh"><img src="../Images/e2afdc8f450df1606b724c67d5e5f8e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tnI48jyTzZqEp8_BeLq9bA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">3D DBSCAN聚类。(图片由作者提供)</p></figure><p id="2fee" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">DBSCAN的结果是否足够好与原始标签有关？</p><p id="0e48" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">与原始标签相关的DBSCAN聚类的准确率为95.9%。</p><p id="d4fa" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">所有这些工作都是在Knime中完成的，结合了原生Knime节点，并在其工作流中嵌入了Python代码，从而展示了Knime environement的功能。</p><p id="b480" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我正在思考的下一个故事，将是关于如何执行一个类似的分析，但用一个神经自动编码器达到嵌入状态。会随时通知你。</p></div></div>    
</body>
</html>