<html>
<head>
<title>Using Machine Learning to Distinguish Between What’s Real and What Is Not</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习来区分什么是真实的，什么不是</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-machine-learning-to-distinct-whats-real-and-what-is-not-9c1c74f73c8c?source=collection_archive---------42-----------------------#2020-10-14">https://towardsdatascience.com/using-machine-learning-to-distinct-whats-real-and-what-is-not-9c1c74f73c8c?source=collection_archive---------42-----------------------#2020-10-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8825" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">超现实世界中假新闻检测的神经网络方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ff8fd9b5d550893cb9fae94e128288c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1Ob1I7uIShsJSCoA"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的nij wam Swargiary拍摄</p></figure><p id="f9d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章是作为2020年后变得越来越不现实的想法出现的。这个世界正变得越来越陌生，我们从互联网上的各种来源接收到越来越多的信息，其中一些充其量是不诚实的。知道你读到的是假的还是真正离奇和令人震惊的能力变得越来越难。距离美国大选还有不到一个月的时间，能够从假新闻中辨别出真实是很重要的。</p><p id="8604" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将尝试使用一种机器学习(ML)技术来将标题分类为虚假与否，并将其与人类进行比较。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="da04" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">人类探讨</h2><p id="03e4" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我认为我们应该从实验开始。我会用两个标题，一个来自一篇假文章(来自洋葱)，另一个来自一篇真正的文章。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="0e0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">答案并不明显，遗憾的是，这并不是唯一的例子。你可以在文末找到答案但是不要宠坏自己。</p><p id="3846" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我决定再做一个小实验。我选了六个头条(三假三真)。然后我上了Instagram，在我的粉丝中做了一个民意调查。我知道，这个样本不仅仅是有偏见的，因为它只代表了我的朋友，尽管如此，它仍然是一个指标。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nb l"/></div></figure><p id="a35d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人类集体知识的成功率(准确率)为<strong class="lb iu"> 0.5 </strong>。实际上比扔硬币和依靠纯粹的运气好不了多少。</p><p id="7043" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看“机器”将会如何表现。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="4cd1" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">机器学习方法</h2><p id="09cd" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">GitHub 的一名用户从两个来源收集数据，一个是“假”新闻(来自《洋葱》),另一个是真实但怪异的新闻。</p><p id="6788" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“假”标题来自《洋葱新闻》。对于那些不知道“洋葱”的人来说，这是一个美国恶搞网站，以讽刺的口吻报道真实和虚构的事件，模仿真实的新闻机构。不是想骗人，是想娱乐人。所以，这不完全是坏的假新闻，我们只是使用这个数据集，因为我们知道我们可以很容易和客观地将它们归类为假的。</p><p id="91ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">真正的标题来自一个名为<a class="ae ky" href="https://www.reddit.com/r/nottheonion/top/?t=all" rel="noopener ugc nofollow" target="_blank"> r/NotTheOnion </a>的子编辑，它包含了来自真实世界的各种超现实的标题，用户可能会将其误解和/或希望为洋葱新闻。</p><p id="acdc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该数据集被广泛使用，并且有很多实验在数据上完成，其中一些比我的更准确。</p><p id="cac3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我决定实现一种不同于我在网上作为辅助项目找到的技术，来提高我的NLP(自然语言处理)技能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/9e11f4532dde1b2b1993144394ddade2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hOI06Fy3O5pArJNgZ678Yw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">工艺管道</p></figure><p id="cb35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在对数据进行预处理后，我制作了一个Tf-idF并训练了一个神经网络来对新闻进行分类。</p><p id="1c28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是首先让我们对数据集有一些基本的了解。</p><p id="4082" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有24k个标题，其中62.5%为非洋葱文章，37.5%为洋葱文章。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/63fa0e5084d46b22c238d25b6a2fe63c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zY7M1zyBueKf_HCi_qGgTw.png"/></div></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="b39b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们更深入地了解这个项目的技术方面。<strong class="lb iu">如果你不感兴趣，就直接跳到结果里。</strong></p><p id="046b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于该项目，我们将需要以下进口</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="30b0" class="mc md it ng b gy nk nl l nm nn">from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.model_selection import train_test_split<br/>from sklearn import metrics<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.model_selection import StratifiedKFold<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.model_selection import cross_validate</span><span id="2a97" class="mc md it ng b gy no nl l nm nn">from keras.wrappers.scikit_learn import KerasClassifier<br/>from keras.layers import  Dropout, Dense<br/>from keras.models import Sequential<br/>from keras import backend as K<br/>import tensorflow as tf<br/>import plotly.graph_objects as go</span><span id="71e8" class="mc md it ng b gy no nl l nm nn">import matplotlib.pyplot as plt<br/>import plotly.express as px<br/>import numpy as np<br/>import pandas as pd<br/>import nltk<br/>import re<br/>from wordcloud import WordCloud</span><span id="761e" class="mc md it ng b gy no nl l nm nn">nltk.download('punkt')<br/>nltk.download('stopwords')<br/>ENG_SW = set(nltk.corpus.stopwords.words('english'))</span></pre><p id="bc08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们应该开始数据的预处理。对于这一部分，我们将使用NLTK套件。</p><p id="5965" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们只保留小写字母数字字符，并丢弃特殊字符。然后，我们开始一个过程，在这个过程中，我们对单词进行标记，然后清除无用的单词，最后我们对单词进行词干处理。这是一个标准的NLP过程，NLTK可以很容易地帮助我们完成。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="2c45" class="mc md it ng b gy nk nl l nm nn">df = pd.read_csv("onion-or-not.csv")</span><span id="885b" class="mc md it ng b gy no nl l nm nn"><br/>def prepossessing(df):</span><span id="7a19" class="mc md it ng b gy no nl l nm nn">df["text"] = df["text"].apply(lambda x : x.lower())</span><span id="9e4a" class="mc md it ng b gy no nl l nm nn">df["text"] = df["text"].apply(lambda x :  re.sub('[^a-zA-z0-9\s]','',x))</span><span id="0a9b" class="mc md it ng b gy no nl l nm nn">df["text_list"] = df["text"].apply(lambda x : nltk.word_tokenize(x))</span><span id="ba30" class="mc md it ng b gy no nl l nm nn">df["cleaned_list"] = df["text_list"].apply(lambda x: [word for word in x if word not in ENG_SW])</span><span id="3b66" class="mc md it ng b gy no nl l nm nn">df["stemmed_cleaned_list"] = df["cleaned_list"].apply(lambda x : [nltk.PorterStemmer().stem(i) for i in x])</span><span id="3fdf" class="mc md it ng b gy no nl l nm nn">df['text_edited'] = df['stemmed_cleaned_list'].apply(lambda x : " ".join(x))</span><span id="98ec" class="mc md it ng b gy no nl l nm nn">return df['text_edited']</span><span id="2333" class="mc md it ng b gy no nl l nm nn">df_X = prepossessing(df)<br/>df_Y = df['label']</span></pre><p id="2a1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们已经完成了基本的文本预处理，在进行下一步之前，让我们可视化两个标签的单词云。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/9b79420b718e45c02d4bc32244c4fa3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*besf8LuH4IdZEBc4qkp7bw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不是洋葱</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/92ae793be8f2eef96dae66c9a9718a5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*2oydIU6hthIOLe9OcigIfg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">洋葱</p></figure><p id="bdcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步是分割数据集并生成数据的<a class="ae ky" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank">TF–IDF</a>。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="9448" class="mc md it ng b gy nk nl l nm nn">X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.25, random_state=seed)</span><span id="d3d9" class="mc md it ng b gy no nl l nm nn">print(X_train.shape, y_train.shape)<br/>print(X_test.shape, y_test.shape)<br/></span><span id="05cc" class="mc md it ng b gy no nl l nm nn">vectorizer_x = TfidfVectorizer()</span><span id="90f6" class="mc md it ng b gy no nl l nm nn">X_train_tfidf = vectorizer_x.fit_transform(X_train).toarray()<br/>X_test_tfidf = vectorizer_x.transform(X_test).toarray()</span></pre><p id="e6ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们有了tf-idf之后，我们将继续我们的模型。</p><p id="9db1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集很简单，因此我们将构建一个小型的基本模型。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="4d33" class="mc md it ng b gy nk nl l nm nn">def Build_Model_DNN_Text(shape, optimizer='Adam', nLayers= 1, neurons=16, dropout=0.85):</span><span id="13ca" class="mc md it ng b gy no nl l nm nn">"""</span><span id="6166" class="mc md it ng b gy no nl l nm nn">Build_Model_DNN_Tex(shape, nClasses,dropout)</span><span id="b54b" class="mc md it ng b gy no nl l nm nn">Build Deep neural networks Model for text classification</span><span id="da46" class="mc md it ng b gy no nl l nm nn">Shape is input feature space</span><span id="946a" class="mc md it ng b gy no nl l nm nn">"""</span><span id="20fc" class="mc md it ng b gy no nl l nm nn">model = Sequential()</span><span id="2c51" class="mc md it ng b gy no nl l nm nn"># number of hidden layers</span><span id="9462" class="mc md it ng b gy no nl l nm nn">model.add(Dense(64,input_dim=shape,activation='elu'))</span><span id="4316" class="mc md it ng b gy no nl l nm nn">model.add(Dropout(dropout))</span><span id="bbb3" class="mc md it ng b gy no nl l nm nn">for i in range(0, nLayers):</span><span id="5f96" class="mc md it ng b gy no nl l nm nn">model.add(Dense(neurons,input_dim=neurons,activation='elu'))</span><span id="3d78" class="mc md it ng b gy no nl l nm nn">model.add(Dropout(dropout))</span><span id="51d0" class="mc md it ng b gy no nl l nm nn">model.add(Dense(1, activation='sigmoid'))</span><span id="4f27" class="mc md it ng b gy no nl l nm nn">model.compile(loss='binary_crossentropy',</span><span id="ddf4" class="mc md it ng b gy no nl l nm nn">optimizer=optimizer,</span><span id="bb7f" class="mc md it ng b gy no nl l nm nn">metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])</span><span id="c3a9" class="mc md it ng b gy no nl l nm nn">return model</span></pre><p id="32a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们训练我们的模型</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="ce09" class="mc md it ng b gy nk nl l nm nn">model_DNN = Build_Model_DNN_Text(X_train_tfidf.shape[1])</span><span id="1461" class="mc md it ng b gy no nl l nm nn">history = model_DNN.fit(X_train_tfidf, y_train,</span><span id="fee9" class="mc md it ng b gy no nl l nm nn">validation_data=(X_test_tfidf, y_test),</span><span id="0613" class="mc md it ng b gy no nl l nm nn">epochs=100,</span><span id="5df4" class="mc md it ng b gy no nl l nm nn">batch_size=4096,</span><span id="76a4" class="mc md it ng b gy no nl l nm nn">verbose=2,</span><span id="123a" class="mc md it ng b gy no nl l nm nn">callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode = "max", patience=10)]</span><span id="36fd" class="mc md it ng b gy no nl l nm nn">)</span></pre></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="7341" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">结果</h2><p id="029e" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我们训练的结果</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nb l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/ea5ae9c3e22b6309cc7aaa0047d4a6a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*82AfDC7wzd6fLBLhMgqjJA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型精度图</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/3a39c26c0ce328d59205f7390b3807ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*mDOD__tKi2E240Fit7FDAg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型损失图</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/881ea57d009fee192c06d9be90019f1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*ZgNlcDVFl6LOA7lVRS-N1g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型回忆图</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/f5bd46d35ceeb9b169eb6fd3fe993977.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*94gUn2aZmPhwalj0C2b2qw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型精度图</p></figure><p id="44a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们运行我的Instagram实验的标题，看看它与人群相比如何。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="92cc" class="mc md it ng b gy nk nl l nm nn">titles = [{"text" : "Coronavirus homeschooling: 77 percent of parents agree teachers should be paid more after teaching own kids, study says", "label" : 0},</span><span id="cf1e" class="mc md it ng b gy no nl l nm nn">{"text" : "Police Department Celebrates Fourth Of July By Using Fireworks For Crowd Control ", "label" : 1},</span><span id="8c7f" class="mc md it ng b gy no nl l nm nn">{"text" : "ICE Director: ICE Can't Be Compared To Nazis Since We're Just Following Orders", "label" : 0},</span><span id="cbc0" class="mc md it ng b gy no nl l nm nn">{"text" : "Hackers Obtain Data Of 45 Million Target Customers Revealing What They’ve Done In Store Bathrooms", "label" : 1},</span><span id="2d90" class="mc md it ng b gy no nl l nm nn">{"text" : "US Military Could Lose Space Force Trademark to Netflix Series", "label" : 0},</span><span id="1a2f" class="mc md it ng b gy no nl l nm nn">{"text" : "Trump Blames China For Acting Too Late In Coordinating U.S. Coronavirus Response", "label" : 1}</span><span id="2516" class="mc md it ng b gy no nl l nm nn">]</span><span id="8f42" class="mc md it ng b gy no nl l nm nn">exp = pd.DataFrame(titles, columns=['text','label'])</span><span id="5f05" class="mc md it ng b gy no nl l nm nn">exp_x = prepossessing(exp)</span><span id="a7a9" class="mc md it ng b gy no nl l nm nn">exp_x_tfidf = vectorizer_x.transform(exp_x).toarray()</span><span id="cef4" class="mc md it ng b gy no nl l nm nn">model_DNN.evaluate(exp_x_tfidf, exp['label'])</span></pre><p id="2aa2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们评价的准确率比人群好0.83。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="20f0" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">结论</h2><p id="4d5e" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我们实现了一个基本模型，得到了一些下降结果，比人类实验更好。如果我们有更大的数据集和更好的技术，我们可以轻松达到90%以上的准确率。感谢您抽出宝贵的时间，并且<strong class="lb iu">我很乐意讨论任何反馈</strong>。</p><p id="a82c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该项目的GitHub可以在<a class="ae ky" href="https://github.com/ilias1111/onion-or-not" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="ba10" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">页（page的缩写）S</h2><p id="ba4e" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">不是洋葱</p><div class="ns nt gp gr nu nv"><a href="https://thehill.com/homenews/administration/353355-trump-dedicates-golf-trophy-to-puerto-rico-hurricane-victims" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">特朗普将高尔夫奖杯献给飓风受害者</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">特朗普总统周日将一座高尔夫奖杯献给了最近席卷德克萨斯州的强大飓风的受害者…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">thehill.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj ks nv"/></div></div></a></div><p id="82dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">洋葱</p><div class="ns nt gp gr nu nv"><a href="https://www.theonion.com/house-censures-ocasio-cortez-for-using-sexist-slur-on-f-1844498607" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">众议院指责奥卡西奥-科尔特斯在国会发言时使用性别歧视的诽谤</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">华盛顿——众议院投票通过了一项谴责这位新生的女议员行为的决议</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">www.theonion.com</p></div></div><div class="oe l"><div class="ok l og oh oi oe oj ks nv"/></div></div></a></div></div></div>    
</body>
</html>