<html>
<head>
<title>The best Machine Learning algorithm for Email Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">邮件分类的最佳机器学习算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-best-machine-learning-algorithm-for-email-classification-39888e7b1846?source=collection_archive---------5-----------------------#2020-10-18">https://towardsdatascience.com/the-best-machine-learning-algorithm-for-email-classification-39888e7b1846?source=collection_archive---------5-----------------------#2020-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3c99" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">实施机器学习算法对电子邮件进行分类</h2></div><p id="86d9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">邮件分类</strong>是一个机器学习问题，属于<strong class="kk iu">监督学习的范畴。</strong></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/695045b7e8de09b4e2d9d5dd4664d326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CWW88OTAHzRRjPaV"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">照片由<a class="ae lu" href="https://unsplash.com/@stereophototyp?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">莎拉·库菲</a>在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="1518" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个电子邮件分类的迷你项目的灵感来自J.K .罗琳以笔名出版的一本书。Udacity的<strong class="kk iu">“机器学习简介”</strong>提供了对算法和项目的全面研究。</p><div class="lv lw gp gr lx ly"><a href="https://www.udacity.com/course/intro-to-machine-learning--ud120" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">机器学习课程介绍| Udacity</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">机器学习是当今数据分析领域最令人兴奋的职业的头等舱门票。作为数据源…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.udacity.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm lo ly"/></div></div></a></div><p id="dc75" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">几年前，罗琳以罗伯特·加尔布雷斯的名字写了一本书，书名是《布谷鸟的呼唤》。这本书获得了一些好评，但没有人太关注它——直到Twitter上的一位匿名线人说这是J.K .罗琳。伦敦《星期日泰晤士报》邀请了两位专家将《布谷鸟》的语言模式与罗琳的《偶然的空缺》以及其他几位作者的书进行比较。在他们的分析结果强烈指向罗琳是作者后，时报直接问出版商他们是否是同一个人，出版商证实了。这本书一夜之间大受欢迎。</p><p id="8e23" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">电子邮件分类基于相同的基本概念。通过检查电子邮件的文本，我们将使用机器学习算法来预测电子邮件是由一个人还是另一个人写的。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="13b1" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">数据集</h1><p id="37ee" class="pw-post-body-paragraph ki kj it kk b kl nm ju kn ko nn jx kq kr no kt ku kv np kx ky kz nq lb lc ld im bi translated">数据集可以从以下GitHub存储库中获取:</p><div class="lv lw gp gr lx ly"><a href="https://github.com/MahnoorJaved98/Email-Classification" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">mahnoorjaved 98/电子邮件-分类</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">使用不同机器学习算法的电子邮件分类。几年前，J.K .罗琳(哈利·波特…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">github.com</p></div></div><div class="mh l"><div class="nr l mj mk ml mh mm lo ly"/></div></div></a></div><p id="3588" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个数据集中，我们有一组电子邮件，其中一半是一个人(Sara)写的，另一半是同一家公司的另一个人(Chris)写的。数据基于字符串列表。每个字符串都是经过一些基本预处理的电子邮件文本。</p><p id="248e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将根据邮件的内容将邮件分类为一个人写的或另一个人写的。我们将逐一使用以下算法:<strong class="kk iu">朴素贝叶斯、支持向量机、决策树、随机森林、KNN和AdaBoost分类器。</strong></p><p id="d076" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">存储库有两个pickle文件:word_data和email_authors。</p><p id="9189" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">email_preprocess python文件用于处理来自pickles文件的数据。它将数据分成0.1个测试数据的训练/测试。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="99e1" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">朴素贝叶斯:</h1><p id="b934" class="pw-post-body-paragraph ki kj it kk b kl nm ju kn ko nn jx kq kr no kt ku kv np kx ky kz nq lb lc ld im bi translated">朴素贝叶斯方法是一组基于贝叶斯定理的监督学习算法，假设给定类变量的值，每对特征之间条件独立且贡献相等。贝叶斯定理是一个简单的数学公式，用于计算条件概率。</p><p id="b003" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">高斯朴素贝叶斯</strong>是一种朴素贝叶斯，其中假设特征的似然性为高斯。假设与每个特征相关联的连续值按照高斯分布分布。绘制时，它给出一条钟形曲线，该曲线关于特征值的平均值对称。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ns"><img src="../Images/4b98926323a81a194e4743c26968bf72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ryXmjhkUH9FQ4OHqcpuR5Q.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图片来自<a class="ae lu" href="https://cdn.pixabay.com/photo/2019/08/27/03/56/dice-4433289_960_720.jpg" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="b16e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用scikit-learn库中的高斯朴素贝叶斯算法来对这两位作者的电子邮件进行分类。</p><p id="afca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是您可以在任何python IDE上实现的Python代码，系统上安装了所需的库。</p><pre class="lf lg lh li gt nt nu nv nw aw nx bi"><span id="3bac" class="ny mv it nu b gy nz oa l ob oc">import sys<br/>from time import time<br/>sys.path.append("C:\\Users\\HP\\Desktop\\ML Code\\")<br/>from email_preprocess import preprocess<br/>import numpy as np</span><span id="2ddc" class="ny mv it nu b gy od oa l ob oc"># using the Gaussian Bayes algorithm for classification of emails.<br/># the algorithm is imported from the sklearn library<br/>from sklearn.naive_bayes import GaussianNB<br/>from sklearn.metrics import accuracy_score</span><span id="15e0" class="ny mv it nu b gy od oa l ob oc"># initializaing the test and train features and labels<br/># the function preprocess is imported from email_preprocess.py <br/>features_train, features_test, labels_train, labels_test = preprocess()</span><span id="fdab" class="ny mv it nu b gy od oa l ob oc"># defining the classifier<br/>clf = GaussianNB()</span><span id="7fad" class="ny mv it nu b gy od oa l ob oc">#predicting the time of train and testing<br/>t0 = time()<br/>clf.fit(features_train, labels_train)<br/>print("\nTraining time:", round(time()-t0, 3), "s\n")<br/>t1 = time()<br/>pred = clf.predict(features_test)<br/>print("Predicting time:", round(time()-t1, 3), "s\n")</span><span id="3d9a" class="ny mv it nu b gy od oa l ob oc">#calculating and printing the accuracy of the algorithm<br/>print("Accuracy of Naive Bayes: ", accuracy_score(pred,labels_test))</span></pre><p id="0178" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">运行代码会产生以下结果:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/b9d1ed18b68fcce4919ba4a83951f35d.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*CqTka0JBhvn16e7C4p_a_Q.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">朴素贝叶斯结果(图片由作者提供)</p></figure><p id="e74e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<strong class="kk iu"> 0.9203 </strong>中，朴素贝叶斯对于这个特殊问题的准确性。相当不错吧？甚至算法的训练和预测次数也相当合理。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="b05e" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">支持向量机</h1><p id="5baf" class="pw-post-body-paragraph ki kj it kk b kl nm ju kn ko nn jx kq kr no kt ku kv np kx ky kz nq lb lc ld im bi translated">支持向量机也是一种监督学习，用于分类、回归以及异常值检测。我们可以使用SVM算法将数据点分成两类，通过一个平面将它们分开。SVM有一个直的决策边界。SVM算法非常通用，可以为决策函数指定不同的核函数。</p><p id="1def" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">SVM算法基于将两类分开的超平面，间隔越大，分类越好(也称为间隔最大化)。</p><p id="5916" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的分类器是具有线性核和C = 1的值的C-支持向量分类器</p><p id="ffc9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">clf = SVC(内核= '线性'，C=1)</p><pre class="lf lg lh li gt nt nu nv nw aw nx bi"><span id="e9eb" class="ny mv it nu b gy nz oa l ob oc">import sys<br/>from time import time<br/>sys.path.append("C:\\Users\\HP\\Desktop\\ML Code\\")<br/>from email_preprocess import preprocess<br/>from sklearn.svm import SVC<br/>from sklearn.metrics import accuracy_score</span><span id="706a" class="ny mv it nu b gy od oa l ob oc">### features_train and features_test are the features for the training<br/>### and testing datasets, respectively<br/>### labels_train and labels_test are the corresponding item labels<br/>features_train, features_test, labels_train, labels_test = preprocess()</span><span id="5aa9" class="ny mv it nu b gy od oa l ob oc">#defining the classifier<br/>clf = SVC(kernel = 'linear', C=1)</span><span id="bfd0" class="ny mv it nu b gy od oa l ob oc">#predicting the time of train and testing<br/>t0 = time()<br/>clf.fit(features_train, labels_train)<br/>print("\nTraining time:", round(time()-t0, 3), "s\n")<br/>t1 = time()<br/>pred = clf.predict(features_test)<br/>print("Predicting time:", round(time()-t1, 3), "s\n")</span><span id="e6d0" class="ny mv it nu b gy od oa l ob oc">#calculating and printing the accuracy of the algorithm<br/>print("Accuracy of SVM Algorithm: ", clf.score(features_test, labels_test))</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi of"><img src="../Images/d0ee93a66c54ae28de2869246184d9cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*p5KhI-AvjNfSF7f_Vy0A1g.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">SVM结果(作者图片)</p></figure><p id="3fcf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">SVM算法的精度是<strong class="kk iu"> 0.9596 </strong>。我们可以看到准确性和训练时间之间的明显权衡。算法准确性的提高是训练时间更长的结果(22.7秒，而在朴素贝叶斯的情况下为0.13秒)。我们可以利用<strong class="kk iu">训练数据</strong>以及<strong class="kk iu">内核</strong>来进行最佳选择，这将在更少的训练时间内产生<strong class="kk iu">良好的准确度分数！</strong></p><p id="a401" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将首先将训练数据集分割成其原始大小的<strong class="kk iu"> 1% </strong>，从而丢弃99%的训练数据。在代码的其余部分不变的情况下，我们可以观察到训练时间的显著减少和准确性的相应降低。代价是<strong class="kk iu">当我们减少训练数据</strong>时，准确性几乎总是下降。</p><p id="8d5c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用以下代码将定型数据分割为1%:</p><pre class="lf lg lh li gt nt nu nv nw aw nx bi"><span id="4153" class="ny mv it nu b gy nz oa l ob oc">features_train = features_train[:len(features_train)//100]<br/>labels_train = labels_train[:len(labels_train)//100]</span></pre><p id="0b17" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可以看出，使用1%的训练数据，算法的训练时间已经减少到<strong class="kk iu">0.01秒</strong>，精度减少到<strong class="kk iu"> 0.9055 </strong>。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi og"><img src="../Images/38c193a5802663e529b2bfeb7ab3b902.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*3CTY_8ZDMmkcD6AExmerpw.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">1%训练数据的SVM(图片由作者提供)</p></figure><p id="6c80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">10%的训练数据，精度为<strong class="kk iu"> 0.9550 </strong>，训练时间<strong class="kk iu">0.47秒</strong>。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/bdd04656e4c2a419a858ad2bac676c70.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*JNZwySmA94xuh0hr3yhH6g.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">具有10%训练数据的SVM(图片由作者提供)</p></figure><p id="42e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也可以改变scikit-learn的C-支持向量分类中的核和C的值。</p><p id="c7a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用100%的训练数据、RBF核，并且C的值设置为10000，我们得到的精度为<strong class="kk iu"> 0.9891 </strong>，训练时间为<strong class="kk iu"> 14.718 </strong>。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi of"><img src="../Images/f7f893a76d522d6b4153c9f96b09dbf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*PQz3BGol5ZgWvS73b8LQcQ.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">具有100%训练数据、RBF核和C=10000的SVM(图片由作者提供)</p></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="9d4a" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">决策树</h1><p id="1eb6" class="pw-post-body-paragraph ki kj it kk b kl nm ju kn ko nn jx kq kr no kt ku kv np kx ky kz nq lb lc ld im bi translated">决策树是一种用于分类和回归的非参数监督学习方法。决策树可以对数据集进行多类分类。使用从数据特征推断出的一些决策规则，在每个节点上对数据进行逐步分类。决策树很容易可视化。我们可以通过可视化贯穿树的数据集来理解该算法，并在各个节点做出决策。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oi"><img src="../Images/58e8c07686be2a26f3bc6d21dfeda8af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SMwvnB9VZt_JHf8NQ_lBvA.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图片来自<a class="ae lu" href="https://images.unsplash.com/photo-1535127022272-dbe7ee35cf33?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="3eee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看这个算法如何在我们的数据集上工作。</p><pre class="lf lg lh li gt nt nu nv nw aw nx bi"><span id="56b8" class="ny mv it nu b gy nz oa l ob oc">import sys<br/>from time import time<br/>sys.path.append("C:\\Users\\HP\\Desktop\\ML Code\\")<br/>from email_preprocess import preprocess<br/>from sklearn import tree</span><span id="0e60" class="ny mv it nu b gy od oa l ob oc">from sklearn.metrics import accuracy_score</span><span id="e597" class="ny mv it nu b gy od oa l ob oc">### features_train and features_test are the features for the training<br/>### and testing datasets, respectively<br/>### labels_train and labels_test are the corresponding item labels<br/>features_train, features_test, labels_train, labels_test = preprocess()</span><span id="f38d" class="ny mv it nu b gy od oa l ob oc"># defining the classifier<br/>clf = tree.DecisionTreeClassifier()</span><span id="d550" class="ny mv it nu b gy od oa l ob oc">print("\nLength of Features Train", len(features_train[0]))</span><span id="87df" class="ny mv it nu b gy od oa l ob oc">#predicting the time of train and testing<br/>t0 = time()<br/>clf.fit(features_train, labels_train)<br/>print("\nTraining time:", round(time()-t0, 3), "s\n")<br/>t1 = time()<br/>pred = clf.predict(features_test)<br/>print("Predicting time:", round(time()-t1, 3), "s\n")</span><span id="76cc" class="ny mv it nu b gy od oa l ob oc">#calculating and printing the accuracy of the algorithm<br/>print("Accuracy of Decision Trees Algorithm: ", accuracy_score(pred,labels_test))</span></pre><p id="b5f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">运行上面的代码，我们得到的准确度为<strong class="kk iu"> 0.9880 </strong>，训练时间为<strong class="kk iu">6.116秒。</strong>这是一个非常好的准确度分数，不是吗？我们有100%的训练数据用于训练模型。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/09f82f278817c2b1f70f93965b0fcd2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*5e72WEdVTW4CQL_LI243zw.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">决策树算法(作者图片)</p></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="3dcb" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">随机森林</h1><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ok"><img src="../Images/45aa2b34d4b91812e6fc60d0f37cca52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mGnQ6DuJDztHUMgy5ViqOw.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图片来自<a class="ae lu" href="https://images.unsplash.com/photo-1504868584819-f8e8b4b6d7e3?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=755&amp;q=80" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="cfab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随机森林是建立在决策树上的集成监督学习算法。随机森林用于回归和分类任务。该算法的名字来源于随机选择的特征。</p><p id="e7c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以在数据集上使用sklearn库中的随机森林算法:<strong class="kk iu">RandomForestClassifier()</strong>。</p><p id="9663" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是用于在我们的电子邮件分类问题上运行随机森林算法的代码。</p><pre class="lf lg lh li gt nt nu nv nw aw nx bi"><span id="920b" class="ny mv it nu b gy nz oa l ob oc">import sys<br/>from time import time<br/>sys.path.append("C:\\Users\\HP\\Desktop\\ML Code\\")<br/>from email_preprocess import preprocess<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import accuracy_score</span><span id="45a9" class="ny mv it nu b gy od oa l ob oc">### features_train and features_test are the features for the training<br/>### and testing datasets, respectively<br/>### labels_train and labels_test are the corresponding item labels<br/>features_train, features_test, labels_train, labels_test = preprocess()</span><span id="8531" class="ny mv it nu b gy od oa l ob oc"># defining the classifier<br/>clf = RandomForestClassifier(max_depth=2, random_state=0)</span><span id="2ac0" class="ny mv it nu b gy od oa l ob oc">#predicting the time of train and testing<br/>t0 = time()<br/>clf.fit(features_train, labels_train)<br/>print("\nTraining time:", round(time()-t0, 3), "s\n")<br/>t1 = time()<br/>pred = clf.predict(features_test)<br/>print("Predicting time:", round(time()-t1, 3), "s\n")</span><span id="c2cb" class="ny mv it nu b gy od oa l ob oc">#calculating and printing the accuracy of the algorithm<br/>print("Accuracy of Random Forest Algorithm: ", accuracy_score(pred,labels_test))</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/80d32a26951c6363d425af6c424ed931.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*yAC2zVjjvihmQAMYOcjYhg.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">随机森林算法(图片作者提供)</p></figure><p id="69ed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">算法的准确率相当低，即；0.7707.训练时间是1.2s，这是合理的，但总的来说，它不是解决我们问题的好工具。准确率低的原因是特征选择的随机性，这是随机森林的一个特性。随机森林是由许多决策树组成的模型。这个模型不是简单地对树(我们可以称之为“森林”)的预测进行平均，而是使用了两个关键概念，这两个概念赋予了它随机的名称:在构建树时对训练数据点进行随机采样。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="af7a" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">KNN — K个最近邻居</h1><p id="d7f5" class="pw-post-body-paragraph ki kj it kk b kl nm ju kn ko nn jx kq kr no kt ku kv np kx ky kz nq lb lc ld im bi translated">k最近邻是一种受监督的机器学习算法，可用于分类和回归预测问题。KNN是一个懒惰的学习者。它依赖于距离进行分类，因此规范化训练数据可以显著提高其准确性。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oi"><img src="../Images/9d020fc3a7fd9806e6a229d58330df24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yJSku90Qg5kGeDsumdSaaw.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图片来自<a class="ae lu" href="https://images.unsplash.com/photo-1586449480558-33ae22ffc60d?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="fb33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看使用来自sklearn库<strong class="kk iu"> KNeighborsClassifier() </strong>的KNN算法对电子邮件进行分类的结果，该算法具有5个最近邻居和欧几里德度量。</p><pre class="lf lg lh li gt nt nu nv nw aw nx bi"><span id="06ee" class="ny mv it nu b gy nz oa l ob oc">import sys<br/>from time import time<br/>sys.path.append("C:\\Users\\HP\\Desktop\\ML Code\\")<br/>from email_preprocess import preprocess<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.metrics import accuracy_score</span><span id="c70c" class="ny mv it nu b gy od oa l ob oc">### features_train and features_test are the features for the training<br/>### and testing datasets, respectively<br/>### labels_train and labels_test are the corresponding item labels<br/>features_train, features_test, labels_train, labels_test = preprocess()</span><span id="9866" class="ny mv it nu b gy od oa l ob oc"># defining the classifier<br/>clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')</span><span id="e72c" class="ny mv it nu b gy od oa l ob oc">#predicting the time of train and testing<br/>t0 = time()<br/>clf.fit(features_train, labels_train)<br/>print("\nTraining time:", round(time()-t0, 3), "s\n")<br/>t1 = time()<br/>pred = clf.predict(features_test)<br/>print("Predicting time:", round(time()-t1, 3), "s\n")</span><span id="350e" class="ny mv it nu b gy od oa l ob oc">#calculating and printing the accuracy of the algorithm<br/>print("Accuracy of KNN Algorithm: ", accuracy_score(pred,labels_test))</span></pre><p id="b7e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">算法的精度为<strong class="kk iu"> 0.9379 </strong>，训练时间为<strong class="kk iu"> 2.883s </strong>。然而，可以注意到，模型工具需要相当长的时间来预测类别。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/6272be523f7896f1036e239d686b0eb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*tqtSK-GeVvxHYmN5iiFZuw.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">KNN算法(图片作者提供)</p></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="f7c0" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated"><strong class="ak"> AdaBoost分类器</strong></h1><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi om"><img src="../Images/59c13b558a6c251c0a7c9596ee7c39b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FU74DXGhal0EjS_BEDr5Gg.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图片来自<a class="ae lu" href="https://images.unsplash.com/photo-1461749280684-dccba630e2f6?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1500&amp;q=80" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="3d69" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Ada-boost或自适应boosting也是一种集成Boosting分类器。它是一种元估计器，首先在原始数据集上拟合一个分类器，然后在同一数据集上拟合该分类器的附加副本，但是其中调整不正确分类的实例的权重，使得后续分类器更加关注困难的情况。</p><p id="d649" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用scikit库中的分类器。以下是代码:</p><pre class="lf lg lh li gt nt nu nv nw aw nx bi"><span id="2d96" class="ny mv it nu b gy nz oa l ob oc">import sys<br/>from time import time<br/>sys.path.append("C:\\Users\\HP\\Desktop\\ML Code\\")<br/>from email_preprocess import preprocess<br/>from sklearn.ensemble import AdaBoostClassifier<br/>from sklearn.metrics import accuracy_score</span><span id="fd98" class="ny mv it nu b gy od oa l ob oc">### features_train and features_test are the features for the training<br/>### and testing datasets, respectively<br/>### labels_train and labels_test are the corresponding item labels<br/>features_train, features_test, labels_train, labels_test = preprocess()</span><span id="47f4" class="ny mv it nu b gy od oa l ob oc"># defining the classifier<br/>clf = AdaBoostClassifier(n_estimators=100, random_state=0)</span><span id="35a0" class="ny mv it nu b gy od oa l ob oc">#predicting the time of train and testing<br/>t0 = time()<br/>clf.fit(features_train, labels_train)<br/>print("\nTraining time:", round(time()-t0, 3), "s\n")<br/>t1 = time()<br/>pred = clf.predict(features_test)<br/>print("Predicting time:", round(time()-t1, 3), "s\n")</span><span id="ca7f" class="ny mv it nu b gy od oa l ob oc">#calculating and printing the accuracy of the algorithm<br/>print("Accuracy of Ada Boost Classifier: ", accuracy_score(pred,labels_test))</span></pre><p id="19ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分类器的精度为<strong class="kk iu"> 0.9653 </strong>，训练时间为<strong class="kk iu">17.946秒</strong>。准确度相当好，但是，训练时间比要求的时间稍长。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi on"><img src="../Images/f3aef24a6472a7a5f580617db6b1f800.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*Z18KstGNZaUUzDxgP_URsg.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">Ada Boost分类器(图片由作者提供)</p></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="36b5" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">结论</h1><p id="9b73" class="pw-post-body-paragraph ki kj it kk b kl nm ju kn ko nn jx kq kr no kt ku kv np kx ky kz nq lb lc ld im bi translated">在这篇文章中，我们使用了几种机器学习算法来分类Chris和Sara之间的电子邮件。这些算法产生了0.77-0.98之间的不同准确度分数。从下表中可以看出，模型是按照精度递增的方式排列的:</p><ul class=""><li id="48ab" class="oo op it kk b kl km ko kp kr oq kv or kz os ld ot ou ov ow bi translated">随机森林算法的准确率最低</li><li id="35ac" class="oo op it kk b kl ox ko oy kr oz kv pa kz pb ld ot ou ov ow bi translated">SVM算法的训练时间最长</li><li id="93c8" class="oo op it kk b kl ox ko oy kr oz kv pa kz pb ld ot ou ov ow bi translated">优化参数为C=10000和RBF核的SVM算法的准确率最高</li><li id="e25f" class="oo op it kk b kl ox ko oy kr oz kv pa kz pb ld ot ou ov ow bi translated">朴素贝叶斯算法具有最快的预测时间</li></ul><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi pc"><img src="../Images/db05418ae1df31c688862c087b6f54c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xB7IpRQsjVoIsd9EbTTCVg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">结论(图片由作者提供)</p></figure><p id="1f47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然有许多其他分类算法可用于我们的任务，但对数据集上运行的基本算法的比较得出结论，对于我们的特定问题，SVM是最准确的，考虑到其参数根据我们正在处理的任务进行了优化。</p><p id="b6f2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你认为其他算法或模型会做得更好，或者同样好吗？</p><p id="0f63" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分享经验，关注我更多文章！</p></div></div>    
</body>
</html>