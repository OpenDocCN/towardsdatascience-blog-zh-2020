<html>
<head>
<title>5 Computer Vision and Deep Learning Fundamentals</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5计算机视觉和深度学习基础</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-computer-vision-and-deep-learning-fundamentals-f2b5f697dde9?source=collection_archive---------35-----------------------#2020-10-10">https://towardsdatascience.com/5-computer-vision-and-deep-learning-fundamentals-f2b5f697dde9?source=collection_archive---------35-----------------------#2020-10-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1c53" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">需要更好地理解最新的CV &amp; DL项目是如何工作的</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/99ecab2a0fc2af337068e743baddc00b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EEfKXip88xU1slwL"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马里乌斯·马萨拉尔在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3219" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我整理我以前的深度技术项目列表，然后谈论每个项目时，我意识到，编写一个简单易懂的指南，涵盖计算机视觉和深度学习的基础知识，以便非技术读者可以更好地了解最新的深度技术项目，这可能是一个好主意。第一部分是关于图像处理的基础知识(传统的计算机视觉技术，今天仍然适用)，然后第二部分是深度学习的相关内容:)</p><h2 id="24a6" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">为什么计算机视觉很重要？</h2><p id="9c70" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我个人把它理解为我们所知的虚拟世界和物理世界之间的桥梁。正是我们植入机器的眼睛让它们“获得意识”并以前所未有的智能方式导航我们的世界。它实际上用于:</p><ul class=""><li id="9545" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">机器人，</li><li id="6c9e" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">自动驾驶汽车，</li><li id="386d" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">智能商店(像<a class="ae ky" href="https://www.amazon.com/b?ie=UTF8&amp;node=16008589011" rel="noopener ugc nofollow" target="_blank">亚马逊Go </a>)，</li><li id="bfd7" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">优化营销内容，</li><li id="6f3b" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">面部识别应用，</li><li id="a0e9" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">医疗成像/手术、军事、娱乐等行业</li></ul><p id="89c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在有大量其他计算机视觉项目正在进行，毫无疑问，计算机视觉应用将激增，然后无缝集成到我们的日常生活中——改变我们的生活方式。所以废话不多说，</p><p id="4478" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧！ᕙ(^▿^-ᕙ)</p><h2 id="a217" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">数字图像基础</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/ae7621ccf83b724229979f3231003792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ej_FiUsKaGBhN9Q6o81HWQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者创建的图像</p></figure><p id="8b91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">参考上图，假设我们有一个尺寸为400 x 400的数字图像，这意味着我们的图像是400像素行(x方向)和400像素列(y方向)。所以数字图像是用二维矩阵来表示的。每个单独的像素将包含信息(如强度、数据类型、alpha值等)，计算机将理解如何基于这些信息解释或处理图像。</p><h2 id="8dd8" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">传统计算机视觉</h2><p id="c1c5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">自20世纪70年代以来，计算机视觉算法就已经存在，图像操作大体上可以分为两个主要类别— <strong class="lb iu">空间域</strong>和<strong class="lb iu">频域</strong>。了解哪些图像处理方法是可用的可能是有帮助的，因此可以在将图像馈送到深度学习算法之前进行图像预处理，以便产生更好的结果。</p><p id="f022" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">空间域方法</strong> —我们按原样处理数字图像(原始数字图像已经在空间域中)。参考上图，因为每个像素都包含一组特定的信息，所以我们可以基于特定的技术来操作和更改这些信息，以获得特定的结果。方法包括:</p><ul class=""><li id="6928" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">点处理变换(对图像的每个单独像素应用变换函数)，</li><li id="9bd2" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">区域/掩模处理变换(对图像中的像素邻域应用变换函数)，</li><li id="91e4" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">几何变换(如旋转、缩放和扭曲)，</li><li id="e2fd" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">帧处理转换(输出像素值是基于涉及两个或更多图像的操作生成的)</li></ul><p id="5045" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">频域方法</strong> —与空间域方法不同，我们首先将图像转换为频率分布(使用傅立叶变换、拉普拉斯变换或z变换等方法)，然后处理图像。在这之后，我们执行逆变换，然后在空间域中得到新的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/17e8882f4219f5263f63f040f56a506e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xbjdL3mHYK2B0x4seIN3Hw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者的图表，左边的图片取自作者在CZ4003课程中的作业</p></figure><p id="76be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们看上面的图表，我们可以看到左边的原始数字图像非常嘈杂(对角线穿过图像)。如果我们对该图像应用傅立叶变换，我们可以看到右侧的图像(应用了fftshift，因此零频率分量位于阵列中心)在图像中间有亮点(“峰值”)。这些峰值对应于左边的噪声模式(那些穿过图像的对角线/边缘)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/9fdaed5dfcc9b06138a26e92a5c75790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gSOUkynXKvl0iCiWZQwYgQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者的图表，右边的图片取自作者在CZ4003课程中的作业</p></figure><p id="2ed1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们将这些亮点的强度设置为0，然后进行傅里叶逆变换，我们可以看到一些对角线(噪声)逐渐消失。</p><p id="0a05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如本例所示，我们可以利用图像处理技术(空间域方法或频率域方法)首先对图像进行预处理，然后再将其输入到深度学习模型中。此外，一些最流行的传统计算机视觉技术包括:</p><ul class=""><li id="09d2" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">突出边缘、线条和显著区域的图像过滤和变换技术，</li><li id="696b" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">尺度不变特征变换(<a class="ae ky" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html" rel="noopener ugc nofollow" target="_blank"> SIFT </a>)，</li><li id="d045" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">加快了健壮的功能(<a class="ae ky" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_surf_intro/py_surf_intro.html" rel="noopener ugc nofollow" target="_blank"> SURF </a>)，</li><li id="b49b" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">来自加速分段测试(<a class="ae ky" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_fast/py_fast.html#theory" rel="noopener ugc nofollow" target="_blank">快速</a>)的特征，</li><li id="b9de" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">二元鲁棒独立基本特征(<a class="ae ky" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_brief/py_brief.html" rel="noopener ugc nofollow" target="_blank">简称</a>)，</li><li id="e40b" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">定向快速旋转简报(<a class="ae ky" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_orb/py_orb.html" rel="noopener ugc nofollow" target="_blank">圆球</a>)</li></ul><p id="c4d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我已经包含了链接，所以你可以点击它，阅读更多关于每个算法。接下来，我们将看看一些常见的计算机视觉任务，如果传统的计算机视觉技术不足以解决问题，深度学习可以帮助我们(并且正在该领域广泛探索)。</p><h2 id="3c68" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">具有深度学习的计算机视觉</h2><p id="95b1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">简而言之，深度学习是受人脑神经网络的启发和松散建模的——神经元相互连接，接收一些输入，然后根据权重和偏差值发出输出。深度学习帮助我们完成的常见计算机视觉任务包括——图像分类、定位/显著性检测、对象识别、检测和跟踪、人脸识别、场景理解、图像生成和图像分析。一些最流行的深度学习技术(监督、非监督、半监督)包括:</p><ul class=""><li id="27f8" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">卷积神经网络(CNN，或ConvNet)，</li><li id="3396" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">生成对抗网络(GAN)，</li><li id="5e0c" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">深度信念网络(DBNs)和深度波尔兹曼机器(DBMs)，</li><li id="876f" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">堆叠式自动编码器，</li><li id="c439" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">深度强化学习(DRL)，</li></ul><p id="7121" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有很多。我将尝试快速概述卷积神经网络(CNN)的工作原理(以使本文相对简短易读)。如果你想了解更多关于其他深度学习技术的信息，请尝试谷歌搜索——甘真的很酷，这是人们试图用来产生艺术的东西:)无论如何，这里是(CNN):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/2d422ae23a900f275815956abad5fa43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gzBFOLuEFZ9rU3bAZZFYiA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片——还有其他更好的图表和解释，比如(<a class="ae ky" href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/" rel="noopener ugc nofollow" target="_blank">链接</a>、<a class="ae ky" href="https://machinelearningmastery.com/object-recognition-convolutional-neural-networks-keras-deep-learning-library/" rel="noopener ugc nofollow" target="_blank">链接</a>)</p></figure><p id="d5aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简而言之，这就像通过一系列“东西”(更具体地说是卷积层、RELU层、汇集或下采样层，然后是全连接层<em class="nk">例如</em>)来传递一系列数字图像，这些层将提取和学习关于图像的最重要信息，然后建立神经网络模型。然后，一旦这个模型被训练，我们可以通过这个模型传递测试图像，如果这个模型产生良好的结果，它应该能够预测它是什么。如果你不想训练你自己的模型，网上也有各种预训练的模型。</p><p id="391e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">稍微不相干的旁注——我仍然记得在学校图书馆用<a class="ae ky" href="https://colab.research.google.com/notebooks/intro.ipynb#recent=true" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Google Collab </strong> </a>训练一个神经网络模型，然后因为他们不得不关门而把我赶出去的时候，我就站在图书馆门口等待我的模型完成训练，因为我需要无线网络(ㆆ_ㆆ).所以，重点是，如果你没有硬件(比如GPU)来训练你的模型，你可以考虑谷歌协作笔记本。你只需要无线网络。</p><p id="c8f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于数据集的快速说明—通常，我们使用数据集来训练、验证和测试我们的模型。使用的流行数据集:</p><ul class=""><li id="3b0c" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">COCODataset(查看他们的<a class="ae ky" href="https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoDemo.ipynb" rel="noopener ugc nofollow" target="_blank">演示</a></li><li id="d313" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">CIFAR-10或CIFAR-100(链接<a class="ae ky" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">此处</a>)</li><li id="2bf5" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">MNIST(手写数字，链接<a class="ae ky" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">此处</a>)</li><li id="ef05" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">时尚MNIST(链接<a class="ae ky" href="https://www.kaggle.com/zalando-research/fashionmnist" rel="noopener ugc nofollow" target="_blank">此处</a>)</li><li id="2ccc" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">ImageNet(链接<a class="ae ky" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank">此处</a>)</li><li id="597b" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">IMDB-Wiki数据集(链接<a class="ae ky" href="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/" rel="noopener ugc nofollow" target="_blank">此处</a>)</li><li id="9d28" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">打开图像(链接<a class="ae ky" href="https://storage.googleapis.com/openimages/web/factsfigures.html" rel="noopener ugc nofollow" target="_blank">此处</a>)</li><li id="e163" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">更详尽的名单，请点击<a class="ae ky" href="https://computervisiononline.com/datasets" rel="noopener ugc nofollow" target="_blank">这里</a></li></ul><p id="15eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文到此为止！正如在各种文章中提到的，我认为将传统的计算机视觉方法与深度学习技术相结合将更好地帮助我们解决我们的计算机视觉问题。此外，我知道你们中的一些可爱的读者是深度技术研究人员和从业者，他们比我更有经验和经验——如果有任何需要纠正的地方或您对此有任何想法，请随时告诉我。</p><p id="05bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">快乐的计算机视觉！</p></div></div>    
</body>
</html>