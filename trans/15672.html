<html>
<head>
<title>Detecting Habitability of Exoplanets with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用机器学习探测系外行星的可居住性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-habitability-of-exoplanets-with-machine-learning-b28c2d825760?source=collection_archive---------29-----------------------#2020-10-28">https://towardsdatascience.com/detecting-habitability-of-exoplanets-with-machine-learning-b28c2d825760?source=collection_archive---------29-----------------------#2020-10-28</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><blockquote class="jr"><p id="2cba" class="js jt iu bd ju jv jw jx jy jz ka kb dk translated">“宇宙是一个相当大的地方。如果只有我们，这似乎是对空间的极大浪费。”卡尔·萨甘</p></blockquote><figure class="kd ke kf kg kh ki gi gj paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gi gj kc"><img src="../Images/83d77c28e1782ec2544b3424107e0004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OP6RQeDARdTiNdCw"/></div></div><p class="kp kq gk gi gj kr ks bd b be z dk translated">山姆拍摄的照片🐷 on <a class="ae kt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="3f20" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">我们大多数人都想知道在我们的星球之外有生命吗？对我们的祖先来说，我们似乎首先是孤独的，但当我们检查星星时，我们意识到这是一个相当大的宇宙。然后我们开始问地外文明是否存在，它们在哪里？我们把这个问题称为费米悖论。它陈述了缺乏地外文明证据和对其概率的各种高估计之间的矛盾。</p><p id="0b6b" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">但是，正如卡尔·萨根所说:“缺乏证据并不是不存在的证据。”所以我们正在寻找外星人在哪里，或者他们是否存在的问题。<br/>系外行星研究的主要工作领域之一就是找到这个问题的答案。在不同的恒星系统中寻找可能适合居住的行星是系外行星研究的主要目标之一。到目前为止，我们已经发现了60颗可居住的系外行星，我们将继续寻找更多的系外行星。</p><figure class="ls lt lu lv gu ki gi gj paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gi gj lr"><img src="../Images/ed858a7b4161587cdb5ed75a75f27799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S923WcRt0l4klhyf"/></div></div><p class="kp kq gk gi gj kr ks bd b be z dk translated">照片由<a class="ae kt" href="https://unsplash.com/@mr_bcubed5?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Alazar Kassahun </a>在<a class="ae kt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="0ebf" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">所以，我决定开发一个机器学习项目来预测这些可居住的行星。通过进入这个项目，我提取了两个数据集:美国宇航局系外行星档案和PHL的可居住系外行星目录。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="5ab7" class="md me iu bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">数据知识</h1><p id="f0db" class="pw-post-body-paragraph ku kv iu kw b kx nb kz la lb nc ld le lf nd lh li lj ne ll lm ln nf lp lq kb in bi translated">因此，有两个数据集需要处理:<a class="ae kt" href="https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&amp;config=planets" rel="noopener ugc nofollow" target="_blank"> Nasa </a>系外行星档案和<a class="ae kt" href="http://phl.upr.edu/projects/habitable-exoplanets-catalog/data/database" rel="noopener ugc nofollow" target="_blank"> PL数据</a>，其中包含可居住性情况。我从美国宇航局获得的数据集是我的中心数据集，因为它有更多的恒星和行星的特征，例如；行星半径、恒星温度、轨道周期等等。我需要PHL的数据来使用可居住性功能。下图显示了目标特征的分布，这意味着可居住性。如您所见，我有一个不平衡的数据集，我将在下面的部分中处理它。</p><figure class="ls lt lu lv gu ki gi gj paragraph-image"><div class="gi gj ng"><img src="../Images/b24e5eb070301e30457c83693d2cf1fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*D3V-sI-qczoiLkQiT7To6Q.png"/></div><p class="kp kq gk gi gj kr ks bd b be z dk translated">目标特征的分布。作者图片</p></figure></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="66a8" class="md me iu bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">方法学</h1><p id="170e" class="pw-post-body-paragraph ku kv iu kw b kx nb kz la lb nc ld le lf nd lh li lj ne ll lm ln nf lp lq kb in bi translated">本项目遵循的方法是:</p><ol class=""><li id="c557" class="nh ni iu kw b kx ky lb lc lf nj lj nk ln nl kb nm nn no np bi translated">预处理和数据合并</li><li id="64fe" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nm nn no np bi translated">处理缺失数据</li><li id="8be7" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nm nn no np bi translated">探索性数据分析</li><li id="e969" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nm nn no np bi translated">机器学习模型的数据准备</li><li id="0cee" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nm nn no np bi translated">定义模型</li><li id="39fe" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nm nn no np bi translated">评估和优化</li></ol><p id="27fb" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">天文数据集通常会有很多缺失值，我的情况也是如此。因此，我从清除这些丢失的值开始。</p><figure class="ls lt lu lv gu ki gi gj paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gi gj nv"><img src="../Images/c73cf1b741a13d7ba47bc3cb384e2689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kfSvEj0YxmGUajNWZ-82Zg.png"/></div></div><p class="kp kq gk gi gj kr ks bd b be z dk translated">作者图片</p></figure><p id="4e97" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">这张图片显示了我丢失了多少价值。很明显，是很多。所以，我按照以下步骤来解决我的问题:</p><ul class=""><li id="5263" class="nh ni iu kw b kx ky lb lc lf nj lj nk ln nl kb nw nn no np bi translated">我删除了丢失数据超过40%的列。</li></ul><pre class="ls lt lu lv gu nx ny nz oa aw ob bi"><span id="e3e6" class="oc me iu ny b gz od oe l of og"># remove columns with more than 40% missing data<br/>def remove_missing(f):<br/>    count = len(planets[planets[f].isnull()])<br/>    if count/len(planets) &gt; 0.4:<br/>        return 1<br/>    else:<br/>        return 0<br/>    <br/>missing_values = [x for x in planets.columns if remove_missing(x)]<br/>planets = planets.drop(missing_values, axis=1)</span></pre><ul class=""><li id="754e" class="nh ni iu kw b kx ky lb lc lf nj lj nk ln nl kb nw nn no np bi translated">我删除了具有十个以上唯一值的分类特征。</li></ul><pre class="ls lt lu lv gu nx ny nz oa aw ob bi"><span id="d43c" class="oc me iu ny b gz od oe l of og"># remove categorical features with more than 10 unique values<br/>cols = [x for x in planets.columns if x not in planets._get_numeric_data().columns]<br/>for i in cols:<br/>    if(len(planets[i].unique()) &gt; 10):<br/>        planets = planets.drop(i, axis=1)</span></pre><ul class=""><li id="bfa2" class="nh ni iu kw b kx ky lb lc lf nj lj nk ln nl kb nw nn no np bi translated">对剩余分类特征的处理。</li><li id="4a51" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nw nn no np bi translated">数值的迭代计算。</li></ul><pre class="ls lt lu lv gu nx ny nz oa aw ob bi"><span id="b90f" class="oc me iu ny b gz od oe l of og"># IterativeImputer<br/># get only numeric values<br/>numeric_values = planets[planets._get_numeric_data().columns]<br/>imp = IterativeImputer(RandomForestRegressor(), max_iter=10, random_state=76)<br/>numeric_values = pd.DataFrame(imp.fit_transform(numeric_values), columns=numeric_values.columns)<br/>numeric_values.to_csv('Imputed Data.csv', index='rowid')</span></pre><p id="8763" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">在下面的步骤之后，我得到了一个包含131个条目的干净数据集，并继续进行合并过程。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h2 id="c744" class="oc me iu bd mf oh oi dn mj oj ok dp mn lf ol om mr lj on oo mv ln op oq mz or bi translated">合并数据集</h2><p id="815a" class="pw-post-body-paragraph ku kv iu kw b kx nb kz la lb nc ld le lf nd lh li lj ne ll lm ln nf lp lq kb in bi translated">正如我之前所说的，我有两个项目数据集，所以我需要将它们结合起来，以便在机器学习模型中使用。除了可居住性，我的所有特征都在美国宇航局的系外行星档案中。因此，我把它从PHL数据集中拿了出来，放在中央数据集中。</p><pre class="ls lt lu lv gu nx ny nz oa aw ob bi"><span id="67e4" class="oc me iu ny b gz od oe l of og">#drop not-habitable planets<br/>phl = phl[phl.P_HABITABLE != 0]</span><span id="c3f1" class="oc me iu ny b gz os oe l of og">#create habitable column for planets data with the help of phl #dataframe<br/>#get names of planets<br/>habitable_planets = phl.P_NAME.values<br/>planets['habitable'] = planets['pl_name'].isin(habitable_planets</span></pre><figure class="ls lt lu lv gu ki gi gj paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gi gj ot"><img src="../Images/c6e05f4b27af9fe5b7228d80e4a27c3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pyxO9WPfgPpPQe9tJHP_Yg.png"/></div></div><p class="kp kq gk gi gj kr ks bd b be z dk translated">质量-温度-可居住性关系。作者图片</p></figure></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="fdd6" class="md me iu bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">走向机器学习</h1><p id="1250" class="pw-post-body-paragraph ku kv iu kw b kx nb kz la lb nc ld le lf nd lh li lj ne ll lm ln nf lp lq kb in bi translated">我完成了清理和合并过程，但仍有工作要做。我应该做一些准备步骤，为机器学习模型准备数据。我仍然有这么多的功能，我不想从模型中得到过度拟合的结果。此外，我必须解决不平衡的问题。因此，我按照以下步骤编写了一些数据准备方法:</p><ul class=""><li id="4937" class="nh ni iu kw b kx ky lb lc lf nj lj nk ln nl kb nw nn no np bi translated">丢弃低相关性要素&amp;为模型数据集选择高相关性要素。</li><li id="5369" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nw nn no np bi translated">经过一些研究，我决定将这些特征添加到模型的数据集中:行星质量、行星径向速度振幅[m/s]、平衡温度[K]、行星半径[地球半径]和轨道周期[天]。但是，由于缺失值问题，我只有行星半径和轨道周期。</li><li id="c473" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nw nn no np bi translated">标准化和对数变换。</li><li id="90e3" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nw nn no np bi translated">SMOTE —过采样。</li></ul><pre class="ls lt lu lv gu nx ny nz oa aw ob bi"><span id="0ce0" class="oc me iu ny b gz od oe l of og">#Selecting highly correlated features<br/>unrelevant_features = corr_df[corr_df['habitable'] &lt;= 0.09]</span><span id="7d3f" class="oc me iu ny b gz os oe l of og">to_drop = [column for column in unrelevant_features.index]<br/>planets_c.drop(planets_c[to_drop[:97]], axis=1, inplace=True)</span><span id="83ea" class="oc me iu ny b gz os oe l of og">planets_c[['pl_rade', 'pl_orbper']] = planets[['pl_rade', 'pl_orbper']]</span><span id="e8cb" class="oc me iu ny b gz os oe l of og"># log transformation to decrease the effect of the outliers<br/>log_cols = ['gaia_plx', 'st_pm', 'gaia_pm', 'st_teff', 'pl_rade', 'pl_orbper']<br/>planets_c[log_cols] = (planets_c[log_cols]+1).transform(np.log)<br/>norm_cols = ['st_pmdec', 'gaia_pmdec']<br/>planets_c[norm_cols] = preprocessing.normalize(planets_c[norm_cols])</span></pre><p id="7920" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">嗯，我现在可以开始定义分类模型了。我从探索基本模型开始:KNN、逻辑回归、朴素贝叶斯、线性SVC和决策树。然后，集合模型就像:随机森林、AdaBoost、GradientBoosting和XGBoost。结果如下:</p><figure class="ls lt lu lv gu ki gi gj paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><div class="gi gj ou"><img src="../Images/700486b030894fd77548c161f1fd5f27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tUL2Xg86lGcIRD-MLDoZWw.png"/></div></div><p class="kp kq gk gi gj kr ks bd b be z dk translated">图片作者。</p></figure><p id="7026" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">首先，行星半径和轨道周期特征不在模型数据集中。没有这些功能，我得到的最好的F1分数只有54%，所以他们对结果做出了相当大的贡献。从特征重要度表也可以看出。</p><figure class="ls lt lu lv gu ki gi gj paragraph-image"><div class="gi gj ov"><img src="../Images/3eee7bca21680960ca683d20f5f2cba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*uB60AC9y_blgROnhKmWrCQ.png"/></div><p class="kp kq gk gi gj kr ks bd b be z dk translated">图片作者。</p></figure><p id="fb82" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">线性SVC是召回分数方面第二成功的模型。因此，我想比较他们的混淆矩阵:</p><div class="ls lt lu lv gu ab cb"><figure class="ow ki ox oy oz pa pb paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><img src="../Images/25ee25fb152ff786b3250423b031fd9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*ty2x84xiJBXqHdINjq2tEA.png"/></div></figure><figure class="ow ki pc oy oz pa pb paragraph-image"><div role="button" tabindex="0" class="kj kk di kl bf km"><img src="../Images/900f1d7b57176b51d480d3759e7f45fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*XCeijvVZNDL1q5a9fy1iIQ.png"/></div><p class="kp kq gk gi gj kr ks bd b be z dk pd di pe pf translated">作者图片。</p></figure></div></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="4904" class="md me iu bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">最后的想法</h1><ul class=""><li id="0f27" class="nh ni iu kw b kx nb lb nc lf pg lj ph ln pi kb nw nn no np bi translated">像行星半径、轨道天数、恒星表面重力和恒星表面温度这样的特征对模型有重大影响。</li><li id="95d2" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nw nn no np bi translated">机器学习算法在寻找可能的宜居行星方面做得很好，即使没有化学性质。</li><li id="ec4b" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nw nn no np bi translated">XGBoost在任务上真的很成功。这个模型预测了所有的系外行星，除了一个。</li><li id="7376" class="nh ni iu kw b kx nq lb nr lf ns lj nt ln nu kb nw nn no np bi translated">作为进一步的工作，我的目标是通过在学术论文上的NLP工作找到可居住性的相关特征。我还打算开发一个flask应用程序。</li></ul><blockquote class="pj pk pl"><p id="2cc2" class="ku kv pm kw b kx ky kz la lb lc ld le pn lg lh li po lk ll lm pp lo lp lq kb in bi translated">“以非常不同的方式，宇宙充满生命的可能性和我们完全孤独的相反可能性同样令人兴奋。不管怎样，对我来说，想更多地了解宇宙的欲望是不可抗拒的，我无法想象任何真正富有诗意的人会不同意。”理查德·道金斯</p></blockquote></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><p id="7a0d" class="pw-post-body-paragraph ku kv iu kw b kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq kb in bi translated">此外，如果你想了解更多，也可以看看我的<a class="ae kt" href="https://github.com/alpercakr/Planet-Hunting-and-Habitability-Detection-with-Machine-Learning" rel="noopener ugc nofollow" target="_blank"> Github </a>简介！</p></div></div>    
</body>
</html>