<html>
<head>
<title>Toxic Comments Detection in Russian</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">俄语中有毒评论的检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/toxic-comment-detection-in-russian-2950be3b9787?source=collection_archive---------22-----------------------#2020-10-25">https://towardsdatascience.com/toxic-comment-detection-in-russian-2950be3b9787?source=collection_archive---------22-----------------------#2020-10-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9dcd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">表达各种观点的自由，包括有毒、攻击性和辱骂性的评论，可能会对人们的意见和社会凝聚力产生长期的负面影响。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/c2c8b64a46170473fdd96f2564c37b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*r5OBabkQnYD1D4yzC_kvLQ.gif"/></div></figure><p id="fc0b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">因此，自动识别和调节互联网上的有毒内容以消除负面后果的能力是现代社会的必要任务之一。本文旨在自动检测俄语中的有毒评论。作为数据来源，我们利用匿名发布的Kaggle数据集，并额外验证其标注质量。为了建立分类模型，我们对两个版本的多语言通用句子编码器、来自Transformers的双向编码器表示和ruBERT进行了微调。微调后的ruBERT达到了<em class="lj"> F </em> 1 = 92.20%，展示了最好的分类得分。我们向研究社区公开了经过训练的模型和代码样本。</p><h1 id="35b3" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">1.介绍</h1><p id="dc17" class="pw-post-body-paragraph kn ko iq kp b kq mc jr ks kt md ju kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">如今，社交网站已经成为在线表达意见的主要方式之一。内容的快速增长导致未经核实的信息量每天都在增加。表达各种观点的自由，包括有毒、攻击性和辱骂性的评论，可能会对人们的意见和社会凝聚力产生长期的负面影响。因此，自动识别互联网上的有毒言论和不当内容以消除负面后果的能力是现代社会的必要任务之一。大公司已经进行了大量的研究[23]，[26]，[39]，[47]，然而，为了让社会接受这种限制言论自由权的制度，有必要进行深入的了解和公开的研究。</p><p id="2382" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">近年来，组织了越来越多的评估跟踪，如[3]、[21]、[42]，并对最佳检测方法进行了评估。目前，先进的深度学习技术往往是这项任务的优越方法[1]，[35]。虽然一些论文直接检查了俄语有毒语言、辱骂和仇恨言论的检测[2]、[8]、[17]，但只有一个公开可用的俄语有毒评论数据集[5]。该数据集是在Kaggle上发布的，没有关于注释过程的任何细节，因此在没有深入检查的情况下在学术和应用项目中使用该数据集可能是不可靠的。</p><p id="827f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">本文主要研究俄语文本中有害评论的自动检测。为此，我们对俄语毒性评论数据集进行了注释验证[5]。接下来，我们通过探索预训练多语言通用语句编码器(M-USE) [48]的预训练多语言版本、来自变压器(M-BERT) [13]和ruBERT [22]的双向编码器表示的迁移学习来建立分类模型。性能最好的模型ruBERT-Toxic在二元分类任务中实现了<em class="lj"> F </em> 1 = 92.20%。我们在GitHub上公开了示例代码和经过微调的M-BERT和M-USE模型。</p><div class="mh mi gp gr mj mk"><a href="https://github.com/sismetanin/toxic-comments-detection-in-russian" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab fo"><div class="mm ab mn cl cj mo"><h2 class="bd ir gy z fp mp fr fs mq fu fw ip bi translated">sis metanin/毒性-评论-俄语检测</h2><div class="mr l"><h3 class="bd b gy z fp mp fr fs mq fu fw dk translated">这个库包含来自Transformers (M-BERT)的经过微调的多语言双向编码器表示…</h3></div><div class="ms l"><p class="bd b dl z fp mp fr fs mq fu fw dk translated">github.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my kl mk"/></div></div></a></div><p id="097a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">文章的其余部分组织如下。在<strong class="kp ir">第2节</strong>中，我们给出了相关工作的简要概述，包括现有俄语注释数据集的总结。在<strong class="kp ir">第3节</strong>中，我们提供了俄语有毒评论数据集的概述，并描述了注释验证流程。在第4节中，我们描述了文本分类任务的语言模型的采用。在<strong class="kp ir">第4节</strong>中，我们描述了分类实验。最后，我们提出了系统的性能和进一步的研究方向。</p><h1 id="0364" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">2.相关著作</h1><p id="397f" class="pw-post-body-paragraph kn ko iq kp b kq mc jr ks kt md ju kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">针对不同数据源的有害评论检测已经进行了大量的工作。例如，Prabowo及其同事评估了朴素贝叶斯(NB)、支持向量机(SVM)和随机森林决策树(RFDT)算法，用于检测印度尼西亚Twitter上的仇恨言论和辱骂性语言[34]。实验结果表明，使用单词单字特征和SVM模型的分级方法的准确率为68.43%。在论文[15]中，Founta等人提出了一种基于深度GRU的神经网络，该网络具有用于有毒文本分类的预训练手套嵌入。所开发的模型在五个滥用文本数据集上取得了高性能，AUC值在92%到98%之间。</p><p id="8d01" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">越来越多的研讨会和比赛致力于有毒语言、仇恨言论和攻击性语言的检测。例如，SemEval-2019的HatEval和OffensEvalHASOC at FIRE-2019；在GermEval-2019和GermEval-2018上识别攻击性语言的共同任务；TRAC at COLING-2018。任务提交中使用的模型各不相同，从传统的机器学习，如SVM和逻辑回归，到深度学习，如RNN，LSTM，GRU，CNN，CapsNet，包括注意机制[45]，[49]，到最先进的深度学习模型，如ELMo [31] BERT [13]，以及USE [9]，[48]。相当数量的表现最好的团队[18]、[24]、[27]、[28]、[30]、[36]、[38]利用了所列的预训练语言模型中的嵌入。由于来自预训练语言模型的表示显示了高分类分数，它们被广泛用于进一步的研究。例如，来自洛林大学的学者使用两种方法对推文进行了多类和二元分类:使用预训练的单词嵌入训练DNN分类器，并微调预训练的BERT模型[14]。他们观察到，BERT微调比CNN和建立在FastText嵌入之上的双向LSTM神经网络表现得更好。</p><p id="129e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">虽然大量研究检查了俄语社交媒体源中的毒性和攻击性行为[7]、[33]、[41]，但直接探索文本毒性自动分类的研究论文数量有限。Gordeev利用卷积神经网络(CNN)和随机森林分类器(RFC)来检测英语和俄语文本中的攻击状态[17]。攻击性注释消息的语料库包括大约1000条俄语注释消息和大约1000条英语注释消息；然而，它没有公开。经过训练的CNN模型在俄语文本的攻击性二元分类中取得了66.68%的准确率。基于这些结果，作者认为细胞神经网络和深度学习方法在攻击检测任务中似乎更有前景。Andrusyak及其同事提出了一种无监督的概率方法，使用种子字典对来自YouTube的用乌克兰语和俄语编写的辱骂性评论进行分类[2]。作者发布了一个包含2000条评论的人工标注数据集，但它包含了俄语和乌克兰语的评论。因此，它不能直接应用于俄语内容的研究。</p><p id="ba77" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">最近的几项研究旨在自动识别俄语社交媒体中对移民和族裔群体的态度，包括识别基于身份的攻击。Bodrunova和他的同事通过分析来自俄语LiveJournal [8]的363，000个帖子，研究了人们对来自前苏联南部和其他国家的移民的态度。他们发现，在俄罗斯的博客中，移民既没有引发大量的讨论，也没有经历最糟糕的待遇。此外，北高加索人和中亚人受到非常不同的待遇。贝苏德诺夫的研究小组发现，传统上俄罗斯人对来自高加索和中亚的移民更加敌视；同时，他们普遍接受乌克兰人和摩尔多瓦人作为他们的潜在邻居[6]。然而，根据Koltsova及其同事的说法，各种中亚人和乌克兰人带头持否定态度[19]。尽管有些人讨论了旨在检测有毒语言、辱骂和仇恨言论的学术研究，但他们都没有向研究界公开他们的俄语数据集。据我们所知，俄语毒性评论数据集[5]是唯一公开可用的俄语毒性评论数据集。然而，这个数据集是在Kaggle上发布的，没有任何关于创建和注释过程的描述，因此在没有深入检查的情况下，在学术和应用项目中使用这个数据集可能是不可靠的。</p><p id="cf42" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">因此，由于针对俄语毒性检测的研究很少，我们决定在俄语毒性评论数据集上评估深度学习模型[5]。据我们所知，没有研究致力于有毒评论分类的基础上，这种来源的数据。在最近的文本分类论文中，我们将多语言BERT和多语言使用确定为最常见和最成功的语言模型之一。此外，只有这些语言模型正式支持俄语。我们决定利用微调作为迁移学习方法，因为最近的微调研究报告了最好的分类结果[13]、[22]、[43]、[48]。</p><h1 id="8741" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">3.有毒评论数据集</h1><p id="a4cd" class="pw-post-body-paragraph kn ko iq kp b kq mc jr ks kt md ju kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated"><a class="ae mz" href="https://www.kaggle.com/blackmoon/russian-language-toxic-comments" rel="noopener ugc nofollow" target="_blank"> Kaggle俄语有毒评论数据集</a>【5】是由<a class="ae mz" href="https://2ch.hk/" rel="noopener ugc nofollow" target="_blank"> 2ch </a>和<a class="ae mz" href="https://pikabu.ru/" rel="noopener ugc nofollow" target="_blank"> Pikabu </a>的注释评论集合而成，于2019年发布在Kaggle上。它包含14，412条评论，其中4，826条被标记为有毒，9，586条被标记为无毒。评论的平均长度是175个字符；最小长度为21，最大长度为7，403。</p><p id="f7e5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了验证数据集的标注质量，我们决定手动标注注释的子集，并使用注释者间协议度量来比较原始标签和我们的标签。我们决定假设数据集注释是有效的，以防注释者之间达成实质性或高级别的一致。首先，我们对这个数据集的一部分(3000条评论)进行人工注释，然后将我们的类标签与原始标签进行比较。这一注释是由众包平台Yandex上讲俄语的人进行的。托洛卡，这已经在一些关于俄语文本的学术研究中使用[10]、[29]、[32]、[44]。作为注释指南，我们使用Jigsaw毒性评论分类挑战中的毒性和子属性的注释说明。根据指导方针，注释者被要求在一组在线评论中检测文本的毒性。对于提供的每条评论，注释者需要选择评论中的毒性级别。为了从标注者那里获得更准确的响应，并限制作弊标注者对任务的访问，我们利用了以下技术:根据标注者对控制任务的响应为他们分配一项技能，并禁止给出错误响应的执行者；限制响应过快的注释者对池的访问；限制连续几次输入验证码失败的注释者对任务的访问。每篇文章都由3到8个注释者使用动态重叠技术进行注释。接下来，使用基于<a class="ae mz" href="https://yandex.ru/support/toloka-requester/concepts/categorization.html?lang=en" rel="noopener ugc nofollow" target="_blank">Yandex的Dawid-Skene方法[12]对结果进行汇总。Toloka的推荐</a>。根据Krippendorff的alpha值0.81，注释者表现出高度的注释者间一致性。最后，根据Cohen [11]的说法，原始标签和我们的聚合标签之间的Cohen kappa系数构成了0.68，这是注释者间协议的实质水平。因此，我们假设数据集注释是有效的，特别是考虑到注释指令中的潜在差异。</p><h1 id="0c7b" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">4.机器学习模型</h1><h2 id="9bba" class="na ll iq bd lm nb nc dn lq nd ne dp lu kw nf ng lw la nh ni ly le nj nk ma nl bi translated">4.1.基线</h2><p id="8033" class="pw-post-body-paragraph kn ko iq kp b kq mc jr ks kt md ju kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">作为基线方法，我们选择了一种基于基本机器学习的方法和一种基于现代神经网络的方法。在这两种情况下，我们应用了以下预处理技术:用关键字替换URL和用户名，删除标点符号，并将字符串转换为小写。</p><p id="655f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">第一种是多项式朴素贝叶斯(MNB)，它往往在文本分类任务中表现良好[16，40]。为了构建MNB模型，我们使用了词袋模型和TF-IDF矢量化。</p><p id="4b84" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">第二个是双向长短期记忆(BiLSTM)神经网络，它在最近的情感分析研究中表现出较高的分类分数。对于神经网络的嵌入层，我们在RuTweetCorp [37]的俄语推文集合上预先训练了Word2Vec嵌入(<em class="lj"> dim </em> = 300) [25]。在Word2Vec嵌入的顶部，我们添加了两个堆叠的双向LSTM层。接下来，我们添加了一个隐藏的完全连接层和sigmoid输出层。为了减少过拟合，具有高斯噪声的正则化层和丢弃层也被添加到神经网络中。我们使用Adam优化器，初始学习率为0.001，分类二进制交叉熵作为损失函数。我们用10个时期的冻结嵌入来训练我们的网络。我们试图在降低学习速率的同时解冻不同时期的嵌入，但未能获得更好的结果。这可能与训练数据集的大小有关[4]。</p><h2 id="84b3" class="na ll iq bd lm nb nc dn lq nd ne dp lu kw nf ng lw la nh ni ly le nj nk ma nl bi translated">4.2.来自变压器的双向编码器表示</h2><p id="139d" class="pw-post-body-paragraph kn ko iq kp b kq mc jr ks kt md ju kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">目前官方提供了两个多语种版本的BERT_BASE，但只有Cased版本是<a class="ae mz" href="https://github.com/google-research/bert/blob/master/multilingual.md" rel="noopener ugc nofollow" target="_blank">官方推荐的</a>。BERT_BASE接受一个不超过512个令牌的序列，并输出这个序列的表示。单词标记化由单词标记化器[46]通过初步的文本规范化和标点分裂来执行。基于BERTBASE案例，莫斯科物理与技术研究所的研究人员预先训练并发布了俄语的ruBERT模型[22]。我们使用了预先训练的多语言BERT_BASE Cased和ruBERT，支持104种语言，包括俄语，有12个堆叠的变压器块，隐藏大小为768，12个自关注头，一般有110M参数。微调阶段使用论文[43]和官方知识库<a class="ae mz" href="#_ftn2" rel="noopener ugc nofollow">【2】</a>中推荐的参数进行:训练周期数为3，预热步骤数为10%，最大序列长度为128，批量为32，学习速率为5e-5。</p><h2 id="820c" class="na ll iq bd lm nb nc dn lq nd ne dp lu kw nf ng lw la nh ni ly le nj nk ma nl bi translated">4.3.多语言通用句子编码器</h2><p id="ead1" class="pw-post-body-paragraph kn ko iq kp b kq mc jr ks kt md ju kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">作为输入数据，多语言USE_Trans取不超过100个令牌的序列，而多语言USE_CNN取不超过256个令牌的序列。句子片断标记化[20]用于所有支持的语言。我们使用预先训练的多语言USETrans，它支持包括俄语在内的16种语言，变压器编码器有6个变压器层，8个注意头，滤波器大小为2048，隐藏大小为512，一般有16个参数。我们还使用了预先训练的多语言USE_CNN，它支持包括俄语在内的N种语言，CNN编码器有2个CNN层，滤波器宽度为(1，2，3，5)，滤波器大小为256，一般有N个参数。对于这两个模型，我们使用了来自和<a class="ae mz" href="https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub" rel="noopener ugc nofollow" target="_blank"> TensorFlow Hub页面</a>的推荐参数:100个训练时段，32个批量，3e-4的学习率。</p><h1 id="7593" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">5.实验</h1><p id="235b" class="pw-post-body-paragraph kn ko iq kp b kq mc jr ks kt md ju kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">我们评估了以下基线和迁移学习方法:多项式朴素贝叶斯分类器、双向长短期记忆(BiLSTM)神经网络、来自变压器的双向编码器表示的多语言版本(M-BERT)、ruBERT、多语言通用句子编码器的两个版本(M-USE)。训练模型在测试子集(20%)上的分类性能可以在表2中找到。所有微调的语言模型在精确度、召回率和<em class="lj"> F </em> 1-measure方面都超过了基线方法。根据结果，ruBERT实现了<em class="lj"> F </em> 1 = 92.20%，展示了最好的分类分数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h1 id="53a8" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">6.结论</h1><p id="09a2" class="pw-post-body-paragraph kn ko iq kp b kq mc jr ks kt md ju kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">因此，我们微调了两个版本的多语言通用句子编码器[48]，来自Transformers [13]和RuBERT [22]的多语言双向编码器表示，用于俄语中的有毒评论检测。微调后的RuBERTToxic达到了<em class="lj"> F </em> 1 = 92.20%，展示了最好的分类得分。这项研究对实践和研究的贡献有三个方面。首先，我们概述了现有的关于俄语内容中有毒评论检测的知识库。在这样做的过程中，我们确定了现有的唯一一个公开可用的俄文毒性评论数据集。其次，我们对这个数据集的标注质量进行了验证，因为它是在Kaggle上匿名发布的。最后，为了给进一步的研究提供强有力的分类基线，我们向研究社区公开了预先训练的基于BERT、基于ruBERT和基于多语言使用的模型。</p><div class="mh mi gp gr mj mk"><a href="https://github.com/sismetanin/toxic-comments-detection-in-russian" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab fo"><div class="mm ab mn cl cj mo"><h2 class="bd ir gy z fp mp fr fs mq fu fw ip bi translated">sis metanin/毒性-评论-俄语检测</h2><div class="mr l"><h3 class="bd b gy z fp mp fr fs mq fu fw dk translated">这个库包含来自Transformers (M-BERT)的经过微调的多语言双向编码器表示…</h3></div><div class="ms l"><p class="bd b dl z fp mp fr fs mq fu fw dk translated">github.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my kl mk"/></div></div></a></div><h1 id="b715" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">参考</h1><p id="0b6f" class="pw-post-body-paragraph kn ko iq kp b kq mc jr ks kt md ju kv kw me ky kz la mf lc ld le mg lg lh li ij bi translated">你可以在会议<a class="ae mz" href="http://www.dialog-21.ru/media/5017/smetaninsi-029.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中找到所有参考资料。</p></div></div>    
</body>
</html>