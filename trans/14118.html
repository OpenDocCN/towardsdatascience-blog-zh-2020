<html>
<head>
<title>My Journey in Converting PyTorch to TensorFlow Lite</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我将PyTorch转换为TensorFlow Lite的历程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/my-journey-in-converting-pytorch-to-tensorflow-lite-d244376beed?source=collection_archive---------10-----------------------#2020-09-29">https://towardsdatascience.com/my-journey-in-converting-pytorch-to-tensorflow-lite-d244376beed?source=collection_archive---------10-----------------------#2020-09-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="12b8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">有时候一个傻瓜要做一个傻瓜该做的事</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f7f435dae3090c3f2099f9a466d8d3b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtw8Hf9P_JTHwduIdL9I2Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摘自<a class="ae ky" href="https://commons.wikimedia.org/wiki/Main_Page" rel="noopener ugc nofollow" target="_blank">维基媒体</a></p></figure><h1 id="8d34" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="1367" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我最近不得不将一个深度学习模型(一个<a class="ae ky" href="https://paperswithcode.com/method/mobilenetv2" rel="noopener ugc nofollow" target="_blank"> MobileNetV2 </a>变种)从<a class="ae ky" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>转换为<a class="ae ky" href="https://www.tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite </a>。这是一个漫长而复杂的旅程，要经历很多磨难才能成功。我发现自己从Stackoverflow帖子和GitHub问题中收集了一些信息。我的目标是分享我的经历，试图帮助其他像我一样迷失的人。</p><blockquote class="mn mo mp"><p id="598c" class="lr ls mq lt b lu mr ju lw lx ms jx lz mt mu mc md mv mw mg mh mx my mk ml mm im bi translated"><strong class="lt iu">免责声明:这不是关于如何正确进行转换的指南</strong>。我只想分享我的经历。我可能做错了(特别是因为我没有Tensorflow的经验)。如果你注意到一些我可以做得更好/不同的地方，请评论，我会相应地更新帖子。</p></blockquote><h1 id="6bc6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">任务</h1><p id="76ac" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">将深度学习模型(一个<a class="ae ky" href="https://paperswithcode.com/method/mobilenetv2" rel="noopener ugc nofollow" target="_blank"> MobileNetV2 </a>变体)从Pytorch转换为TensorFlow Lite。转换过程应该是:<br/>py torch→ONNX→tensor flow→TF lite</p><h1 id="059c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">试验</h1><p id="99d7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了测试转换后的模型，生成了一组大约1000个输入张量，并为每个张量计算PyTorch模型的输出。该集合随后被用于测试每个转换的模型，通过在整个集合上的平均误差度量，将它们产生的输出与原始输出进行比较。平均误差反映了在相同的输入下，转换后的模型输出与原始PyTorch模型输出的差异。<br/>我决定将平均误差小于1e-6的模型视为转换成功的模型。</p><p id="e51b" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">可能还需要注意的是，我在张量中添加了批次维度，尽管它是1。我这么做没有任何理由，除了我之前将PyTorch转换为<a class="ae ky" href="https://developer.qualcomm.com/docs/snpe/index.html" rel="noopener ugc nofollow" target="_blank"> DLC模型</a>的经验所带来的直觉。</p><h1 id="1f6d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">将Pytorch转换为ONNX</h1><p id="95de" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这绝对是最简单的部分。主要感谢PyTorch上优秀的文档，比如这里的<a class="ae ky" href="https://pytorch.org/docs/stable/onnx.html" rel="noopener ugc nofollow" target="_blank">这里的</a>和<a class="ae ky" href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html" rel="noopener ugc nofollow" target="_blank">这里的</a>。</p><p id="8c44" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">要求:</p><ul class=""><li id="e5a5" class="mz na it lt b lu mr lx ms ma nb me nc mi nd mm ne nf ng nh bi translated">ONNX ==1.7.0</li><li id="203d" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated">PyTorch ==1.5.1。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Pytorch至ONNX转换</p></figure><p id="b033" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">新创建的ONNX模型在我的示例输入上进行了测试，平均误差为1.39e-06。</p><p id="22b5" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">注意，为了在ONNX模型中运行它，您必须将<code class="fe np nq nr ns b">torch.tensor</code>示例转换成它们的对等示例<code class="fe np nq nr ns b">np.array</code>。</p><h1 id="418d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">将ONNX转换为张量流</h1><p id="8fb1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在我有了我的ONNX模型，我使用<a class="ae ky" href="https://github.com/onnx/onnx-tensorflow" rel="noopener ugc nofollow" target="_blank">ONNX-tensorflow</a>(<a class="ae ky" href="https://github.com/onnx/onnx-tensorflow/releases/tag/v1.6.0" rel="noopener ugc nofollow" target="_blank">v 1 . 6 . 0</a>)库来转换到tensor flow。我没有使用Tensorflow的经验，所以我知道这是事情变得具有挑战性的地方。</p><p id="2926" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">要求:</p><ul class=""><li id="6ce8" class="mz na it lt b lu mr lx ms ma nb me nc mi nd mm ne nf ng nh bi translated">tensor flow = = 2 . 2 . 0(onnx-tensor flow的先决条件。然而，它对我的tf-nightly build <code class="fe np nq nr ns b">2.4.0-dev20200923</code>也有效</li><li id="8e33" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated">张量流-附加项==0.11.2</li><li id="cfec" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated"><a class="ae ky" href="https://github.com/onnx/onnx-tensorflow" rel="noopener ugc nofollow" target="_blank">onnx-tensor flow</a>= =<a class="ae ky" href="https://github.com/onnx/onnx-tensorflow/releases/tag/v1.6.0" rel="noopener ugc nofollow" target="_blank">1 . 6 . 0</a></li></ul><p id="210e" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">我不知道确切的原因，但这种转换只在GPU机器上对我有效。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">ONNX到张量流转换</p></figure><p id="eb3f" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">我在创建的TensorflowRep对象上运行了我的测试(用它进行推理的例子<a class="ae ky" href="https://github.com/onnx/onnx-tensorflow/tree/master/example" rel="noopener ugc nofollow" target="_blank">在这里</a>)。运行<strong class="lt iu">非常慢</strong>(大约1小时而不是几秒钟！)所以让我很担心。然而，最终，测试产生了6.29e-07的平均误差，所以我决定继续前进。</p><p id="5121" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">此时最大的问题是——出口了什么？这个<code class="fe np nq nr ns b">.pb</code>文件是什么？在网上做了一番调查后，我意识到这是一个<code class="fe np nq nr ns b"><a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/Graph" rel="noopener ugc nofollow" target="_blank">tf.Graph</a></code>的例子。现在<strong class="lt iu"> <em class="mq">剩下的</em> </strong> <em class="mq"> </em>要做的就是把它转换成TensorFlow Lite。</p><h1 id="d8f9" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">将TensorFlow转换为TensorFlow Lite</h1><p id="d361" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对我来说，这就是事情变得非常棘手的地方。据我所知，<a class="ae ky" href="https://www.tensorflow.org/lite/convert" rel="noopener ugc nofollow" target="_blank"> Tensorflow提供了3种将TF转换为TFLite的方法</a> : SavedModel、Keras和concrete functions。我对这些选项不太熟悉，但是我已经知道onnx-tensorflow工具导出的是一个冻结的图形，所以这三个选项对我都没有帮助:(</p><p id="a2f5" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">在网上探索了一段时间后，<a class="ae ky" href="https://stackoverflow.com/questions/53182177/how-do-you-convert-a-onnx-to-tflite/58576060#58576060" rel="noopener ugc nofollow" target="_blank">这个家伙</a>基本上拯救了我的一天。原来在Tensorflow <code class="fe np nq nr ns b">v1</code>中支持从冻结图转换！我决定对剩下的代码使用<code class="fe np nq nr ns b">v1</code> API。</p><p id="4716" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">当运行转换函数时，出现了一个奇怪的问题，它与<code class="fe np nq nr ns b">protobuf</code>库有关。按照这个用户的建议，我能够继续前进。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">TF冻结图形到TFLite</p></figure><p id="83de" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">您可能会认为，在经历了所有这些麻烦之后，在新创建的<code class="fe np nq nr ns b">tflite</code>模型上运行<a class="ae ky" href="https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python" rel="noopener ugc nofollow" target="_blank">推理</a>可以平静地完成。但是我的麻烦并没有就此结束，更多的问题出现了。</p><p id="9a0f" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">其中一个与名为“<a class="ae ky" href="https://www.tensorflow.org/lite/guide/ops_compatibility" rel="noopener ugc nofollow" target="_blank"> ops </a>”(带有“<code class="fe np nq nr ns b">ops that can be supported by the flex.</code>”的错误消息)的东西有关。经过一番挖掘，我意识到我的模型架构需要在转换之前<a class="ae ky" href="https://www.tensorflow.org/lite/guide/ops_select" rel="noopener ugc nofollow" target="_blank">显式启用一些操作符</a>(见上文)。</p><p id="93f1" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">然后，原来我的网络使用的很多操作还在开发中，所以当时运行的TensorFlow版本(2.2.0)无法识别它们。这是通过安装<a class="ae ky" href="https://pypi.org/project/tf-nightly/" rel="noopener ugc nofollow" target="_blank"> Tensorflow的夜间构建</a>，特别是<code class="fe np nq nr ns b">tf-nightly==2.4.0.dev20299923</code>解决的。</p><p id="0671" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">我的另一个错误是“<code class="fe np nq nr ns b">The Conv2D op currently only supports the NHWC tensor format on the CPU. The op was given the format: NCHW</code>”。这在<a class="ae ky" href="https://github.com/onnx/onnx-tensorflow/issues/535#issuecomment-683366977" rel="noopener ugc nofollow" target="_blank">这位用户评论</a>的帮助下解决了。</p><p id="95d9" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">最终，这是用于测试的推理代码—</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">TFLite推理</p></figure><p id="b526" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">测试的平均误差为2.66-0.7</p><p id="3800" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">我希望我的经验对你有用，祝你好运！</p><h1 id="2694" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">相关链接</h1><p id="b8f7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">官方文件:</strong></p><ul class=""><li id="e50d" class="mz na it lt b lu mr lx ms ma nb me nc mi nd mm ne nf ng nh bi translated"><a class="ae ky" href="https://pytorch.org/docs/stable/onnx.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/onnx.html</a></li><li id="3570" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated"><a class="ae ky" href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/advanced/super _ resolution _ with _ onnx runtime . html</a></li><li id="02fa" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated">https://github.com/microsoft/onnxruntime<a class="ae ky" href="https://github.com/microsoft/onnxruntime" rel="noopener ugc nofollow" target="_blank"/></li><li id="6a44" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated">【https://github.com/onnx/tutorials T4】</li><li id="95ef" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated"><a class="ae ky" href="https://www.tensorflow.org/lite/guide/ops_compatibility" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/lite/guide/ops_compatibility</a></li><li id="9791" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated"><a class="ae ky" href="https://www.tensorflow.org/lite/guide/ops_select" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/lite/guide/ops_select</a></li><li id="36cc" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated"><a class="ae ky" href="https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/lite/guide/inference # load _ and _ run _ a _ model _ in _ python</a></li></ul><p id="7f13" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated"><strong class="lt iu">问题和堆栈溢出</strong></p><ul class=""><li id="99c1" class="mz na it lt b lu mr lx ms ma nb me nc mi nd mm ne nf ng nh bi translated"><a class="ae ky" href="https://stackoverflow.com/questions/53182177/how-do-you-convert-a-onnx-to-tflite/58576060" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/53182177/how-do-you-convert-a-onnx-to-TF lite/58576060</a></li><li id="8411" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated"><a class="ae ky" href="https://stackoverflow.com/questions/55475551/toco-from-protos-command-not-found" rel="noopener ugc nofollow" target="_blank"><em class="mq">https://stack overflow . com/questions/55475551/toco-from-protos-command-not-found</em></a></li><li id="f896" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated"><a class="ae ky" href="https://github.com/onnx/onnx-tensorflow/issues/535#issuecomment-683366977" rel="noopener ugc nofollow" target="_blank">https://github . com/onnx/onnx-tensor flow/issues/535 # issue comment-683366977</a></li><li id="8ccc" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated"><a class="ae ky" href="https://github.com/tensorflow/tensorflow/issues/41012" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/tensorflow/issues/41012</a></li></ul></div></div>    
</body>
</html>