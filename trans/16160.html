<html>
<head>
<title>How to evaluate Text Generation Models? Metrics for Automatic Evaluation of NLP Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何评价文本生成模型？自然语言处理模型自动评估的度量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-evaluate-text-generation-models-metrics-for-automatic-evaluation-of-nlp-models-e1c251b04ec1?source=collection_archive---------8-----------------------#2020-11-07">https://towardsdatascience.com/how-to-evaluate-text-generation-models-metrics-for-automatic-evaluation-of-nlp-models-e1c251b04ec1?source=collection_archive---------8-----------------------#2020-11-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0ba6" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/61c8a1f00a3bc7cbb60a045461cde593.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ub2P_xN5vfq1ajnR"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">由<a class="ae kl" href="https://unsplash.com/@maxcodes?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">麦斯威尔·尼尔森</a>在<a class="ae kl" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="17e3" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">文本生成是一个棘手的领域。学术界和工业界仍在为评估生成模型质量的相关指标而努力。每一个生成任务都是不同的，都有自己的微妙之处和独特之处——对话系统有不同于总结的目标指标，机器翻译也是如此。</p><p id="160c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我将讨论NLP中用于比较生成性或提取性任务的度量，其中要比较两个文本。我将在此讨论的指标可应用于以下任务:</p><ul class=""><li id="c739" class="lk ll iq ko b kp kq kt ku kx lm lb ln lf lo lj lp lq lr ls bi translated">短格式或长格式文本生成</li><li id="88cd" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">机器翻译</li><li id="1c2e" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">总结</li><li id="718b" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">聊天机器人和对话系统</li><li id="78bb" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">问题回答</li><li id="eed9" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">释义系统</li><li id="7373" class="lk ll iq ko b kp lt kt lu kx lv lb lw lf lx lj lp lq lr ls bi translated">多媒体系统，如语音2文本、图像字幕、自动视频配音</li></ul><p id="1311" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，让我们来谈谈这篇文章中的一些常用术语。在NLG，为了检查评估，机器生成的文本通常根据目标文本(真值)进行评估。这个<strong class="ko ja"> <em class="ly">目标文本</em> </strong>是期望模型理想生成的文本。<strong class="ko ja"> <em class="ly">生成文本</em> </strong>指机器产生的文本(模型的输出)，而<strong class="ko ja"> <em class="ly">目标或参考文本</em> </strong>指原始真值文本。其他一些基本术语是n-gram和单词建模包，它们是基本的NLP概念/术语。如果你还不知道他们，你可以在网上了解更多。我还展示了用python计算这些指标的代码片段。</p><h1 id="bcfc" class="lz ma iq bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">BLEU:双语评估替角分数</h1><p id="d1bb" class="pw-post-body-paragraph km kn iq ko b kp mx kr ks kt my kv kw kx mz kz la lb na ld le lf nb lh li lj ij bi translated">BLEU和Rouge是最流行的评估指标，用于比较NLG领域的模型。每一份NLG的报纸肯定都会报道标准数据集上的这些指标，永远如此。BLEU是一个专注于精度的指标，它计算参考文本和生成文本的n元语法重叠。这种n元语法重叠意味着除了n元语法的术语关联之外，评估方案是独立于单词位置的。在BLEU中需要注意的一点是——有一个简短的惩罚，即当生成的文本与目标文本相比太小时应用的惩罚。</p><p id="b6b1" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是使用python的ntlk库计算BLEU的代码片段。</p><figure class="nc nd ne nf gt ka"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="db4c" class="lz ma iq bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">胭脂:回忆导向的吉斯丁评价替角</h1><p id="bfc9" class="pw-post-body-paragraph km kn iq ko b kp mx kr ks kt my kv kw kx mz kz la lb na ld le lf nb lh li lj ij bi translated">如前所述，Rouge是另一个被广泛报道的指标。报告标准任务的Rouge和BLEU分数是一种非常常见的做法。它非常类似于BLEU的定义，不同之处在于<strong class="ko ja"> <em class="ly">胭脂是回忆聚焦的，而BLEU是精确聚焦的</em> </strong>。有3种类型的胭脂:n-胭脂，最常见的胭脂类型，这意味着n-gram重叠。例如(2-胭脂，1-胭脂分别代表2克和1克)。第二个是l-rouge，它检查最长的公共子序列，而不是n-gram重叠。第三个是以跳克为主的s-rouge。这些的标准实现可以在大多数ML库中找到，n-rouge是最常用的。下面是n-rouge的原始源代码。</p><figure class="nc nd ne nf gt ka"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="6050" class="lz ma iq bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">困惑</h1><p id="fd34" class="pw-post-body-paragraph km kn iq ko b kp mx kr ks kt my kv kw kx mz kz la lb na ld le lf nb lh li lj ij bi translated">困惑是一种常用于评估生成模型有效性的度量，它被用作由数据集上训练的模型产生句子的概率的度量。在信息论中，困惑是指概率分布对样本进行预测或分配概率的能力。困惑值越低，模型越好。困惑是根据句子的长度来标准化的。</p><figure class="nc nd ne nf gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ni"><img src="../Images/556b56f53d1bf1c7de4b9073a04b44a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sV80DaBOtmGSNG_pJvbUpw.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">这里T是句子中的总字数。</p></figure><p id="d4b7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于语言模型，我们最终想要检查测试集上的困惑值，并选择这个度量具有最低值的模型。这意味着—选择分配高概率的概率模型来建模/生成测试集语句。</p><p id="ddf2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果模型是完全哑的(最坏的可能)，困惑= |v|即词汇量的大小。</p><p id="12d0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">困惑是一个依赖于模型的分数。大多数创成式模型实现/库都会提供现成的。否则，你基本上需要根据特定的语言模型来计算句子中每个单词的概率，就像上面的公式所示。</p><h1 id="d193" class="lz ma iq bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">LSA:潜在语义分析</h1><p id="373b" class="pw-post-body-paragraph km kn iq ko b kp mx kr ks kt my kv kw kx mz kz la lb na ld le lf nb lh li lj ij bi translated">LSA用于根据两个文本中包含的单词计算两个文本的语义相似度。它使用预先计算的大型语料库中的单词共现计数。它使用单词包(BOW)方法来完成，这与单词位置无关。与其他指标不同，它不会过多地惩罚单词选择的变化，即该指标对“好”和“不错”比较宽容，而rouge和bleu则不会。</p><p id="efae" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">本质上，LSA是一种使用单词包方法将句子/文档编码成向量的方法。使用这些向量，我们可以计算相似性度量(余弦)来检查生成的文本和目标文本的相似性。关于LSA度规的详细解释在<a class="ae kl" href="https://moj-analytical-services.github.io/NLP-guidance/LSA.html" rel="noopener ugc nofollow" target="_blank">这里</a>给出。</p><h1 id="8870" class="lz ma iq bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">METEOR:使用显式排序评估翻译的度量</h1><p id="b62a" class="pw-post-body-paragraph km kn iq ko b kp mx kr ks kt my kv kw kx mz kz la lb na ld le lf nb lh li lj ij bi translated">METEOR是一个不常见的度量标准，用于单词对齐。它计算生成文本和参考文本中单词的一对一映射。传统上，它使用<a class="ae kl" href="https://wordnet.princeton.edu/" rel="noopener ugc nofollow" target="_blank"> WordNet </a>或porter stemmer。最后，它根据这些映射计算F分数。Meteor在NLG是一个相对较少使用的指标，尤其是在深度学习模型起飞之后。</p><p id="0b3c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这里给出了计算meteor的代码<a class="ae kl" href="http://cs.cmu.edu/~alavie/METEOR/README.html" rel="noopener ugc nofollow" target="_blank"/>，由metric的作者用java实现。</p><h1 id="8443" class="lz ma iq bd mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw bi translated">TER:翻译编辑率</h1><p id="e5f9" class="pw-post-body-paragraph km kn iq ko b kp mx kr ks kt my kv kw kx mz kz la lb na ld le lf nb lh li lj ij bi translated">TER的工作原理是将生成的文本转换成目标文本。它通过计算将一个字符串转换为另一个字符串所需的操作次数来衡量字符串之间的绝对差异。它紧密基于<a class="ae kl" href="https://en.wikipedia.org/wiki/Edit_distance" rel="noopener ugc nofollow" target="_blank">编辑距离</a>算法</p><figure class="nc nd ne nf gt ka gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/b259e96a93f7fbaf97ec0db5b8c8e63b.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*dn5rJIrKwSNuJzb53DkFmg.png"/></div></figure><figure class="nc nd ne nf gt ka"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="39e2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这就是NLG常用指标的列表。为了计算所有提到的分数，下面是代码。</p><figure class="nc nd ne nf gt ka"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="033f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我希望这有助于呈现可能对您有用的可能指标的概述。如果你需要更全面的解释，你可以在网上了解更多。</p></div></div>    
</body>
</html>