<html>
<head>
<title>Santander Customer Satisfaction — A Self Case Study using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">桑坦德银行客户满意度——使用Python的自我案例研究</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/santander-customer-satisfaction-a-self-case-study-using-python-5776d3f8b060?source=collection_archive---------35-----------------------#2020-10-12">https://towardsdatascience.com/santander-customer-satisfaction-a-self-case-study-using-python-5776d3f8b060?source=collection_archive---------35-----------------------#2020-10-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6e88" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">作为self案例研究的一部分，使用Python ( </em> <a class="ae kg" href="https://github.com/ashishthomaschempolil/Santander-Customer-Satisfaction" rel="noopener ugc nofollow" target="_blank"> github link </a>和<a class="ae kg" href="https://www.linkedin.com/in/ashishthomas7/" rel="noopener ugc nofollow" target="_blank">T5】Linkedin</a><strong class="ak">)</strong>对Kaggle中的桑坦德客户满意度数据集进行分类建模</h2></div><h1 id="6c54" class="kh ki iq bd kj kk kl km kn ko kp kq kr jw ks jx kt jz ku ka kv kc kw kd kx ky bi translated"><strong class="ak">目录</strong></h1><ol class=""><li id="6aa4" class="kz la iq lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">商业问题</li><li id="bb26" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">使用机器学习来解决业务问题</li><li id="8acf" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">评估指标(曲线下面积)</li><li id="01fc" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">探索性数据分析</li><li id="f732" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">特征工程</li><li id="9b4f" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">现有解决方案</li><li id="26c3" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">我的模型实验</li><li id="40be" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">摘要、结果和结论</li><li id="f1e5" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">未来的工作</li><li id="d0b2" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">链接到我的个人资料— Github代码和Linkedin</li><li id="dfba" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">参考</li></ol><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi lw"><img src="../Images/1a9f5f6ae140a5d9277a099bebb91b95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wa0XrjVPkRdCoS9z"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">加勒特·帕克在<a class="ae kg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="65d1" class="kh ki iq bd kj kk kl km kn ko kp kq kr jw ks jx kt jz ku ka kv kc kw kd kx ky bi translated">1.商业问题</h1><p id="3d76" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">本案例研究基于2016年开展的<a class="ae kg" href="https://www.kaggle.com/c/santander-customer-satisfaction" rel="noopener ugc nofollow" target="_blank"> Kaggle竞赛</a>。客户满意度是当今每个公司最重要的关键绩效指标之一，被视为公司成功的关键因素。不开心的顾客不会留下来。更重要的是，不开心的顾客很少在离开前表达他们的不满。桑坦德银行是一家西班牙跨国银行和金融公司，业务遍及欧洲、北美、南美和亚洲。在桑坦德银行举办的这场Kaggle竞赛中，我们需要根据公司提供的功能，提前预测客户是否对他们的服务不满意。这将有助于他们在客户离开之前采取主动措施提高客户满意度。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="fb5c" class="kh ki iq bd kj kk ng km kn ko nh kq kr jw ni jx kt jz nj ka kv kc nk kd kx ky bi translated">2.使用机器学习来解决业务问题</h1><p id="e1cc" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">这个问题是一个分类建模任务，以确定客户(数据点)是否不满意。</p><p id="d24c" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">我们有两个文件:test.csv和train.csv，其中包含大约370个匿名的特征和一个作为目标的依赖特征。每个数据点代表一个客户，如果客户对公司的服务不满意，TARGET中的值为1，如果客户满意，TARGET中的值为0，并且数据集严重失衡。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="7ddd" class="kh ki iq bd kj kk ng km kn ko nh kq kr jw ni jx kt jz nj ka kv kc nk kd kx ky bi translated">3.评估指标(曲线下面积)</h1><p id="1e67" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">这里使用的度量是ROC (接收器工作特性)曲线下的<strong class="lb ir">面积，ROC</strong>(接收器工作特性)曲线是在不同阈值下真阳性率(灵敏度或召回率)(TPR)和假阳性率(FPR)之间的图下的<strong class="lb ir">面积。AUC有助于确定模型是否擅长区分类别。AUC越高，模型预测0为0和1为1的能力越强。AUC为0.5意味着模型进行随机猜测(随机模型)，而AUC为0意味着模型预测0为1，1为0，而AUC为1是理想的分类器。</strong></p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/f7a455edd53dc627a2e0f1e6d73d1ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/0*aTjmvEn58RmgtuSa.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated"><a class="ae kg" rel="noopener" target="_blank" href="/understanding-auc-roc-curve-68b2303cc9c5">来源</a> — AUC是ROC曲线下的面积</p></figure><p id="f00c" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">这里有一篇关于AUC的非常好的文章。</p><div class="nr ns gp gr nt nu"><a rel="noopener follow" target="_blank" href="/understanding-auc-roc-curve-68b2303cc9c5"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd ir gy z fp nz fr fs oa fu fw ip bi translated">理解AUC - ROC曲线</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">在机器学习中，性能测量是一项基本任务。所以说到分类问题，我们可以…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="oe l of og oh od oi mg nu"/></div></div></a></div></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="c18b" class="kh ki iq bd kj kk ng km kn ko nh kq kr jw ni jx kt jz nj ka kv kc nk kd kx ky bi translated">4.探索性数据分析</h1><p id="ce8b" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">我们将首先深入研究数据集，并通过可视化观察所有特征，这将有助于我们获得结论以及特征工程的想法。总共有370个特征都是匿名的(不包括“目标”特征)。我们能够从文献综述中以及通过观察值的分布来获得匿名化特征所传达的信息。</p><p id="55b6" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">由于有许多特性，我们将检查具有<strong class="lb ir">零方差</strong>的特性(不包含任何信息，即仅存在1个唯一值)，如果发现，将删除它们。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="c906" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">发现34个特征具有零方差，并且这些都被移除。</p><p id="bc33" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">我们现在将检查重复的<strong class="lb ir">特征</strong>(即它们在数据点上共享相同的值，不需要相同的特征名称)。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="f99e" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">发现12个特征是重复的，其中6个被移除。</p><p id="4f80" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">我们现在将移除所有的<strong class="lb ir">稀疏特征</strong>(具有很少信息的特征)。设置一个条件，使得如果特征具有为0的99%的值，则它被认为是稀疏特征。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="a132" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">也没有发现缺失值。</p><p id="ca97" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">去除不必要的特征后的最终特征数是142。</p><p id="c101" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">现在，我们将探索每一项功能。</p><h2 id="5b13" class="ol ki iq bd kj om on dn kn oo op dp kr lg oq or kt li os ot kv lk ou ov kx ow bi translated">4.1目标</h2><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/df1b1e81deb52ce049ed084a7364ba60.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*L5d-Xfr_LvNLiAidLXvjLw.png"/></div></figure><p id="eca6" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">我们可以看到数据集非常不平衡，只有3.96%的客户不满意，96.04%的客户满意。</p><h2 id="8e75" class="ol ki iq bd kj om on dn kn oo op dp kr lg oq or kt li os ot kv lk ou ov kx ow bi translated">4.2 var3(地区)</h2><p id="ca5f" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">通过查看其他文献以及当前唯一值的数量(=208)，此功能可能包含客户所在地区的信息。此功能中还有一个异常值-999999，它可能缺少值。除了异常值，这些值的范围从0到208。发现最常见的唯一值是2(对于训练和测试数据，大约97%)。首先，我们将把所有-999999转换为-1值，并且只考虑不包括“2”的值来研究值计数。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/8af1720225525d1f1441d430905aa9dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*EV6w3gDPpCZTfO2EWo7Qog.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">“var3”的值计数，不包括最常见的值“2”</p></figure><p id="2347" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">由于查看值计数，我们可以看到-1仅代表整个数据集的一小部分(即使在排除2之后)。因此，我们将用此功能最常用的值“2”替换缺失的值。</p><h2 id="0074" class="ol ki iq bd kj om on dn kn oo op dp kr lg oq or kt li os ot kv lk ou ov kx ow bi translated">4.3 var15(年龄)</h2><p id="bbb0" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">在训练数据中发现var15的最小值为5，最大值为105。因为var15的值是从5到105，所以可以有把握地认为该特征暗示了客户的年龄。文献综述也证明了这一点。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi oz"><img src="../Images/72222365bada9b9ffdfd351f5a012015.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*88BAZgKOh7XEjRvVQmfb2A.png"/></div></div></figure><p id="c415" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">训练和测试数据具有相似的分布，两者都由最年轻的客户组成。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pa"><img src="../Images/e89521e02e085842f61446ac07e300ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6UDJil9fqMHUvaU5PTbH4Q.png"/></div></div></figure><p id="3973" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">不满意的顾客的最小年龄是23岁。似乎每个年轻顾客(23岁以下)总是很满意。因此，我们可以在特征工程期间创建一个新的特征，它本质上是告诉客户是否在23岁以下。</p><h2 id="e7a5" class="ol ki iq bd kj om on dn kn oo op dp kr lg oq or kt li os ot kv lk ou ov kx ow bi translated">4.4 var38(抵押价值)</h2><p id="88e9" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">从kaggle的各种文献可以推断，var38可能是抵押价值。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/1e945d4bf04179546c63999ddd5ac010.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*GyLH_R3_3j8_gnn49H3ikg.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">var38的值计数</p></figure><p id="9fe6" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">这里我们不能得到任何信息，因为一个值有很高的频率。我们将打印出每个百分点值。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/7475948734cc274aa692d441f07a73fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*_Vog7bn41XZMcSQRvvqICw.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">以百分位数表示的var38值</p></figure><p id="f1ca" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">我们可以看到，0百分位值和10百分位值之间有着巨大的差异。这与90百分位值和100百分位值的情况相同。现在，我们将检查低于97.5百分位的所有值的var38分布图(高于97.5百分位的值1占主导地位，无法提取可用信息)</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/6d4f11a2491572e62f037e6a3f8d7a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*gvSTqqU7qGGMTC8heG6_hA.png"/></div></figure><p id="036d" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">我们可以看到上面的图是右偏的，峰值在100，000到150，000之间。我们可以应用对数变换并检查结果分布。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/78c3c2b073fc4843d98d1263e30b4e73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*lYUZ8DdMPMXYMGTILz-vBg.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">应用对数变换后</p></figure><p id="cf11" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">我们可以看到它看起来类似于正态分布。由于机器学习模型在正态分布上工作得更好，因此我们可以为该特征创建具有对数变换和不具有对数变换的新数据集，并在特征工程阶段比较性能。</p><h2 id="52b8" class="ol ki iq bd kj om on dn kn oo op dp kr lg oq or kt li os ot kv lk ou ov kx ow bi translated">4.4带有关键字的功能</h2><p id="d860" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">有几个特征有特定的关键字，它们是:“imp”、“ind”、“num”、“saldo”。这些关键字被发现是从一些文献中获得的一些西班牙语单词的缩写形式。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/8ac778173dfe11dbd602ab3b26a5f288.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*LkmrzFnBYR6t0rzNRrgODA.png"/></div></figure><p id="42ab" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">“num”要素在数据集中具有最高的制图表达。</p><p id="9476" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">现在我们要做的是通过为每个关键字随机选择2个特征来逐个探索每个关键字的特征，然后我们将得出结论。</p><h2 id="fc65" class="ol ki iq bd kj om on dn kn oo op dp kr lg oq or kt li os ot kv lk ou ov kx ow bi translated"><strong class="ak">4 . 4 . 1‘imp’特性</strong></h2><p id="5f8c" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">imp' likey是importe的缩写词，在西班牙语中表示数量(从文献综述中推断)。带有“imp”关键字的特征的总数是14。通过查看包含“imp”关键字的两个随机选择的特性的值计数，我们可以看到这两个特性最常出现的值都是0。0在这两个特征中占了87%以上。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pg"><img src="../Images/c9cc981a974955c3a938813fba3cbd59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PhIlwXz5Lsu-dmtmlIzyiQ.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">随机选择的“imp”特征训练和测试数据的频率图</p></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ph"><img src="../Images/a5db30cf1f127af6147c8c9e8a8b2496.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iLdPGmSLmzBziZA-I1ljfw.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">对数变换后不包括0的随机选择的“imp”特征的分布</p></figure><p id="9e87" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">同样在对数变换之后，分布(不包括0)变得很像高斯分布。因此，我们可以为所有“imp”功能制定一个策略。</p><p id="cc2c" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated"><strong class="lb ir">imp特性的策略:</strong></p><ol class=""><li id="7a5e" class="kz la iq lb b lc nl le nm lg pi li pj lk pk lm ln lo lp lq bi translated">我们可以创建一个具有对数变换(不包括0) imp特征的新数据集。</li><li id="a1d9" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">我们还可以创建另一个没有应用转换的数据集(保持原样)。</li></ol><h2 id="f881" class="ol ki iq bd kj om on dn kn oo op dp kr lg oq or kt li os ot kv lk ou ov kx ow bi translated">4 . 4 . 1“saldo”功能</h2><p id="a19b" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">具有saldo关键字的特征的数量是26。现在，我们将像处理“imp”特征一样处理数据。通过查看这两个特征的值计数，我们可以看到0也是最常见的值(大约占整个训练数据集的95%)。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pl"><img src="../Images/d4e1abc49c2045d35db59ff1f20538ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BLqqdMsUKfUYxrrsKffKag.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">训练和测试数据的频率图</p></figure><p id="4fe7" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">发现所有“saldo”特征都是连续的。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pm"><img src="../Images/7904bef00d8b8af9664d091f7efda9e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rlxcdUq2FqGIm57wE2PC_w.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">对数变换后的随机“萨尔多”特征(不包括零)</p></figure><p id="5cbd" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">同样在这里(类似于“imp”功能)，我们可以创建新的数据集，将对数变换应用于saldo功能，除了0值将保持不变。</p><p id="0f13" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated"><strong class="lb ir">“萨尔多”特色战略:</strong></p><ol class=""><li id="95ea" class="kz la iq lb b lc nl le nm lg pi li pj lk pk lm ln lo lp lq bi translated">我们可以使用经过对数变换(不包括0)的saldo要素创建一个新数据集。</li><li id="084f" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">我们还可以创建另一个没有应用转换的数据集(保持原样)。</li></ol><h2 id="797f" class="ol ki iq bd kj om on dn kn oo op dp kr lg oq or kt li os ot kv lk ou ov kx ow bi translated">4.4.3“数量”特征</h2><p id="cd03" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">“num”可能是数字的缩写形式。探索所有“num”特征的值计数，我们可以说每个具有“num”关键字的特征本质上都是分类的。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pn"><img src="../Images/857cb1b89e7bf36e01d0d31a3f9f2346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ssBOK0vhRTFmkLQB2zGedw.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">一些带有“num”关键字的特性及其对应的唯一值的数量</p></figure><p id="2035" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">为带有“num”关键字的功能找到的唯一值的最大数量是172(总数据点约为70k)，最小数量是2。我们将为“数字”功能采用一种策略:</p><p id="7d05" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated"><strong class="lb ir">针对“数字”功能的战略</strong></p><ol class=""><li id="aba9" class="kz la iq lb b lc nl le nm lg pi li pj lk pk lm ln lo lp lq bi translated">我们将对允许的唯一值的最大数量设置一个阈值，以便将一个特征定义为分类特征。我们将阈值设置为10。</li><li id="bcf1" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">我们可以使用响应编码、一个热编码创建新数据集，并保留“num”个要素的要素不变。(这只适用于根据上述规则定义的分类特征)</li></ol><h2 id="ee27" class="ol ki iq bd kj om on dn kn oo op dp kr lg oq or kt li os ot kv lk ou ov kx ow bi translated">4 . 4 . 3“ind”特征</h2><p id="3d6b" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">“ind”功能可能指指示器。查看值计数后，所有具有“ind”特征的特征只有2个唯一值。</p><p id="2624" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated"><strong class="lb ir">针对“ind”特性的策略</strong></p><p id="4034" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">我们保留这些功能不变。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="2c79" class="kh ki iq bd kj kk ng km kn ko nh kq kr jw ni jx kt jz nj ka kv kc nk kd kx ky bi translated">5.特征工程</h1><p id="d885" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">从文献回顾中可以理解，对于特定数据点，不同特征上零的出现次数是识别客户是否不满意的一个重要特征。因此，我们将为预处理后的数据创建要素，如下所示:</p><p id="967d" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated"><strong class="lb ir"> no_zeros: </strong>一个数据点的不同特征中出现的零值数量</p><p id="197f" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated"><strong class="lb ir"> no_nonzeros: </strong>一个数据点的不同特征中存在的非零值的数量</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="3623" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">现在，我们将添加一个特性，该特性计算不同关键字特性(' saldo '，' ind '，' num '，' imp') 中的<strong class="lb ir">个零和非零值:</strong></p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="72c9" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">现在，我们将对具有50(不含)到210(含)个唯一值的所有特性的每个唯一值取所有“saldo”和“imp”特性的<strong class="lb ir">平均值，并将其添加为特性。</strong></p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="fce2" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated"><strong class="lb ir"> K均值聚类:</strong>我们将在对这个特定步骤应用标准化之后，添加k = 2，4，6，8，10的K均值聚类值作为特征。注意:我们在这个步骤之后获得的特征是不标准化的，因为我们需要应用对数变换。我们应用标准化来获得K-means聚类特征。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="0bdb" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated"><strong class="lb ir">移除与目标高度相关的特征和低相关的特征:</strong>我们将移除彼此高度相关的所有特征，保留一个。我们将移除与“目标”特征具有低相关性的所有特征。对于移除高相关特征，阈值保持为任何高于0.95相关值的特征，而对于移除与“目标”的低相关值，阈值是任何低于10**-3相关值的特征。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="f747" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated"><strong class="lb ir">创建新数据集:</strong></p><p id="326f" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">现在，我们将使用日志转换创建新的数据集。我们将对功能' var38 '，所有' saldo '和' imp '功能应用对数变换，零值除外，零值将保持不变。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="190f" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">现在我们有两个数据集，一个是对数转换的，另一个是普通数据集(没有任何对数转换)。现在，我们将对这些应用<strong class="lb ir">一个热编码</strong>和<strong class="lb ir">响应编码</strong>，并创建新的数据集。这里，编码应用于唯一值的数量在3和10之间(包括3和10)的那些特征。这里有一篇关于如何计算<a class="ae kg" href="https://medium.com/@thewingedwolf.winterfell/response-coding-for-categorical-data-7bb8916c6dc1" rel="noopener"> <strong class="lb ir">响应编码</strong> </a>的文章。对于响应编码，我使用拉普拉斯平滑来平滑数据(假设在测试数据中有一个在训练数据中没有看到的类别值，我们不希望该唯一值的概率为零，所以我们应用平滑)。通过手动检查从一组阿尔法中随机选择的特征的响应编码值，根据结果编码值的变化程度来找到最佳阿尔法。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi po"><img src="../Images/94bf616181d1dceaf61dd7f75161da4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_77DdkKImiMBi0p76X1icw.png"/></div></div></figure><p id="bf0e" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">最后，创建了6个数据集，它们是:</p><ol class=""><li id="025d" class="kz la iq lb b lc nl le nm lg pi li pj lk pk lm ln lo lp lq bi translated"><strong class="lb ir">正常</strong></li><li id="e37e" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">普通带一个热编码</strong></li><li id="e0c3" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">正常带响应编码</strong></li><li id="3126" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">测井转换</strong></li><li id="4206" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">用响应编码转换的日志</strong></li><li id="842c" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">用一个热编码转换的日志</strong></li></ol><p id="e274" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">现在我们将<strong class="lb ir">标准化</strong>所有数据集。标准化后，我们将应用<strong class="lb ir">主成分分析</strong>(这里n=2)并将其作为特征添加到每个数据集。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="4904" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">最初，我们只有142个用于训练和测试数据的特征。现在我们已经创建了6个数据集，要素的最终数量如下:</p><ol class=""><li id="c124" class="kz la iq lb b lc nl le nm lg pi li pj lk pk lm ln lo lp lq bi translated"><strong class="lb ir">正常:359特性</strong></li><li id="0900" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">普通带一个热编码:446个特征</strong></li><li id="19e9" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">正常带响应编码:374特征</strong></li><li id="7a9e" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">测井转换:359个特征</strong></li><li id="0c22" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">响应编码转换的日志:374个特征</strong></li><li id="8d98" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><strong class="lb ir">一次热编码转换的日志:446个特征</strong></li></ol></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="4d53" class="kh ki iq bd kj kk ng km kn ko nh kq kr jw ni jx kt jz nj ka kv kc nk kd kx ky bi translated">6.现有解决方案</h1><ol class=""><li id="c10c" class="kz la iq lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><a class="ae kg" href="https://beta.vu.nl/nl/Images/werkstuk-elsen_tcm235-865964.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir">德里克·范登艾森。(2017).桑坦德客户满意度</strong> </a> <strong class="lb ir"> : </strong>在预处理中，他去除了方差为零的特征、稀疏特征以及重复的列条。现在，在标准化之后，他移除了具有0.99或更高的高相关值的所有第一对相关特征。<strong class="lb ir">特征工程:</strong>从var3 (Nationality)特征中创建新的特征，其本质上携带了客户是否来自最普通的国家或具有最普通的价值的信息。var15(年龄)、var36和var38(抵押价值)也是如此，var15的值为-999999，这可能意味着缺少值。创建的另一个特性告诉我们数据点的值是否为-999999。创建此功能后，var3中的所有-999999值都被替换为最常用的值。对var36也是如此，因为它的值为99，与其他唯一值(包括0、1、2和3)相差甚远。Var36是一个热编码，因为其值表明它是分类的。另一个功能是计算数据点中0的数量(dmi3kno，2015)。此外，还为数据点功能创建了多个1。作者创建了3个模型:<strong class="lb ir">逻辑回归、随机森林和XGBoost </strong>，具有超参数调整的10折分层交叉验证。发现度量AUC对于XGBoost是最好的。</li><li id="2fa3" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><a class="ae kg" href="https://github.com/kweonwooj/kaggle_santander_customer_satisfaction/tree/master/34_wpppj" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir"> kweonwooj用Python </strong> </a> <strong class="lb ir"> : </strong>重新实现pjpan的第34位解(用R代码)，在这次重新实现中，用户删除了所有有常量(只有1个唯一值)的特性，删除了所有重复的特性，保留了一个。将9999999999和-99999等所有极值转换为-1。移除稀疏要素，条件是如果要素的99%值为0，则该要素被声明为稀疏。对于这组列“num_meses_var8_ult3”、“num_meses_var13_largo_ult3”、“num_op_var40_comer_ult1”，这组列中的所有meses列的值都被更改为int类型。而集合中的所有其他特征的值除以3(这些特征的唯一值为3的倍数)。数据在XGBoost上用10个分层的k折叠进行训练。预测的测试值是所有这些模型测试预测值的平均值，这些预测值符合10个分层的k倍。</li></ol><p id="17c5" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">对于我的方法，我已经创建了6个数据集，这在特征工程部分进行了详细说明，并将在这6个不同的数据集上建模。</p><h1 id="d276" class="kh ki iq bd kj kk kl km kn ko kp kq kr jw ks jx kt jz ku ka kv kc kw kd kx ky bi translated">7.我的建模实验</h1><p id="bd1f" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">我有6个数据集，所以我要做的是，对每个数据集，我将在<strong class="lb ir">逻辑回归、决策树、随机森林、XGBoost和LightGBM </strong>上建模。首先，对数据集进行随机分割，对“目标”进行分层(确保训练和测试中唯一“目标”值的比例相同)，分割比例为85:15。在数据集上建模后，我基于随机森林模型选择了<strong class="lb ir">个顶级特征，然后为每个数据集创建了包含前250个特征</strong>的新数据集。然后<strong class="lb ir">基于具有前250个特征的<strong class="lb ir">数据集</strong>创建随机森林、XGBoost和LightGBM模型</strong>。使用<strong class="lb ir">随机搜索CV进行逻辑回归、决策树和随机森林找到最佳超参数。</strong></p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pp"><img src="../Images/2742e47424ba20e9b950b7c6bedf2aef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yzfiT79IyPo8e-jx1QXTlA.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">用于随机搜索cv的不同超参数</p></figure><p id="7140" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">这里class_weight = 'balanced '处理了类的不平衡。对于<strong class="lb ir">决策树</strong>和<strong class="lb ir">随机森林</strong>，在拟合具有最佳超参数的模型之后，在这些模型之上拟合校准的分类器(以获得概率值)。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="3655" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">这里的模型不是<strong class="lb ir">决策树分类器</strong>就是<strong class="lb ir">随机森林分类器</strong>。</p><p id="f86a" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">对于<strong class="lb ir"> XGBoost </strong>和<strong class="lb ir"> LightGBM，</strong>我手动更改了每个参数，并根据以下文章找到了最佳参数。对这两个模型使用RandomSearchCV耗费了大量时间。</p><div class="nr ns gp gr nt nu"><a rel="noopener follow" target="_blank" href="/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd ir gy z fp nz fr fs oa fu fw ip bi translated">像老板一样在Python中微调XGBoost</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">XGBoost(或极端梯度推进)不再被引入，只是在太多的数据科学中被证明是相关的…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="pq l of og oh od oi mg nu"/></div></div></a></div><p id="2bd7" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">下面是<strong class="lb ir"> XGBoost </strong>的代码，类似的还有<strong class="lb ir"> LightGBM </strong>(除了物镜在<strong class="lb ir"> LightGBM </strong>中变成‘二进制’)。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="9a71" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">不同数据集的组合AUC图如下所示:</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pr"><img src="../Images/dd707efddecfc6ba87ddd598c9adf840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*neP5joZ_0PhxuO4eaBTIOQ.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ps"><img src="../Images/913dc06aca500a0a10f2b48f3b6a5879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0GqeIPUjzPOxqxTfc1jOyA.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pt"><img src="../Images/cce77c7d0f3db40407bfacced4702bfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A7BxAfUuR9Y6ILopcjTHPw.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pu"><img src="../Images/9157fa2190b91d2fa1eb7190ff4346df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SqkgAwY5Mdrdww8WFP_g9Q.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pv"><img src="../Images/70e43917da78ebf43051fd43402375a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cpy_P4MndwONtW5YG5mmqA.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pw"><img src="../Images/d1ac3af1655c95f50fa4001bbb69d666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pYNyXyC_ZhJcJFpx94gQxA.png"/></div></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi px"><img src="../Images/de9fcfcda8333f5bdf03f5db3f201fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eCVbwyiET5i-1eEq2eyJmg.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated"><strong class="bd py">日志</strong>数据集的AUC分数(已排序)</p></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi pz"><img src="../Images/3081b262350584184f675592f96a3cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7x94oqSkHwg_fHRLrC95SQ.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated"><strong class="bd py">正常</strong>数据集的AUC分数(已排序)</p></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi qa"><img src="../Images/df4f5bf249544fda529084799c93e6af.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*OG3dCbiN9pJhjsMCoByY9g.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">基于验证AUC的每个数据集的最佳模型</p></figure><p id="9658" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">然后，我们根据<strong class="lb ir">集合</strong>和<strong class="lb ir">堆叠</strong>的验证AUC，从每个数据集中选择最佳模型。我们不从所有模型中取出最好的模型，因为对于堆叠和集成，模型之间的差异越大(这确保我们从不同的数据集取出模型，否则在相同数据集上训练的模型将出现)，最终集成/堆叠分类器的性能将越好(每个模型将是不同主题的专家，即例如:如果我们建立狗分类器模型，我们可以建立分类器，使得一个模型将检测尾部， 另一个模型将检测人脸等，因此结合这些模型将提供更好的性能，这就是我所说的不同模型的意思)。 所以数据集之间的差异越大，模型之间的差异就越大。</p><p id="7509" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">然后，获得的最佳模型在提供的整个训练数据集上进行训练(我们之前分割了数据)，然后用于预测测试“目标”概率值。然后，获得的6个“目标”被用作创建新数据帧的特征。在该数据帧的顶部训练分类器(堆叠)。这里使用的分类器是<strong class="lb ir">逻辑回归</strong>(通过<strong class="lb ir">随机搜索CV </strong>找到的超参数)，并且在Kaggle中提交“目标”的测试概率值。还提交了从6个最佳模型获得的6个测试概率值，并记录了它们的公开AUC分数。然后，基于获得的公开AUC分数，选择最佳的2个模型(这里是“log re(top 250) xgb”和“normal re(top 250)”)，然后对概率值进行简单的平均集合。然后在Kaggle上提交获得的值，并记录公开的AUC分数。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="oj ok l"/></div></figure></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="2900" class="kh ki iq bd kj kk ng km kn ko nh kq kr jw ni jx kt jz nj ka kv kc nk kd kx ky bi translated">8.摘要、结果和结论</h1><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi qb"><img src="../Images/8a25788284db182eb51142b2ec718b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*Df_FgiAIz5jxyJD5p5C8tA.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">带有kaggle公共AUC分数的模型</p></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi qc"><img src="../Images/932aec769ea01afa0c7a7245ca75780b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N9tsfdVejyOqNF3tWE_fvw.png"/></div></div></figure><p id="8d5b" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">我们可以从上面的结果数据框中看到，拟合于对数变换响应编码(前250个特征)数据集的XGB模型和拟合于正常响应编码(前250个特征)数据集的XGB模型表现非常好。这两个模型的简单平均组合能够获得0.82746的kaggle公共AUC分数，仅比公共排行榜中的最高分数(0.84532)低约2%。在Log transformed(所有特征)上训练的xgb模型表现很差，因为它具有最差的公开分数。对分类特征进行响应编码极大地改进了模型，因为与在响应编码数据集上训练的模型相比，在其他数据集模型上训练的模型不会产生很好的结果。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/aeaf602626593cbc3e9c69fec1bdc994.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*BYWiDJCklRqoAFtuLZHY9w.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">日志响应编码(前250个功能)xgboost模型(前20个功能)</p></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/c3fa02e7f5ad37feeef8f2a918596b4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*A6YUGGbKUX59WxWM8kf6ag.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">正常响应编码(前250个功能)xgboost模型(前20个功能)</p></figure><p id="03fc" class="pw-post-body-paragraph mm mn iq lb b lc nl jr mo le nm ju mp lg nn mr ms li no mu mv lk np mx my lm ij bi translated">此外，从所使用的两个集合模型的特征重要性图中，我们可以看到，在这两个模型中，具有最高重要性的共同特征是“var15”(代表从文献综述中推断的“年龄”)，这意味着年龄是决定客户是否满意的重要因素。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="7ab0" class="kh ki iq bd kj kk ng km kn ko nh kq kr jw ni jx kt jz nj ka kv kc nk kd kx ky bi translated">9.未来的工作</h1><ol class=""><li id="73da" class="kz la iq lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">我们可以使用<strong class="lb ir">贝叶斯优化</strong>来找到每个模型的最佳超参数。</li><li id="c07f" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">我们也可以尝试实施<strong class="lb ir">深度学习模型</strong>来解决问题。</li></ol></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="bc9a" class="kh ki iq bd kj kk ng km kn ko nh kq kr jw ni jx kt jz nj ka kv kc nk kd kx ky bi translated">10.链接到我的个人资料— Github代码和Linkedin</h1><p id="6745" class="pw-post-body-paragraph mm mn iq lb b lc ld jr mo le lf ju mp lg mq mr ms li mt mu mv lk mw mx my lm ij bi translated">你可以在这个<a class="ae kg" href="https://github.com/ashishthomaschempolil/Santander-Customer-Satisfaction" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir"> github链接</strong> </a>上找到这个案例研究的完整代码。你可以在<a class="ae kg" href="https://www.linkedin.com/in/ashishthomas7/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb ir"> Linkedin </strong> </a>或<strong class="lb ir">ashishthomas7@gmail.com</strong>联系我。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="3ef6" class="kh ki iq bd kj kk ng km kn ko nh kq kr jw ni jx kt jz nj ka kv kc nk kd kx ky bi translated">11.参考</h1><ol class=""><li id="5fce" class="kz la iq lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><a class="ae kg" href="https://www.appliedaicourse.com/course/11/Applied-Machine-learning-course" rel="noopener ugc nofollow" target="_blank">https://www . Applied ai course . com/course/11/Applied-Machine-learning-course</a></li><li id="3825" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><a class="ae kg" href="https://beta.vu.nl/nl/Images/werkstuk-elsen_tcm235-865964.pdf" rel="noopener ugc nofollow" target="_blank">桑坦德银行客户满意度调查(2017年)</a></li><li id="0f5e" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><a class="ae kg" href="https://github.com/kweonwooj/kaggle_santander_customer_satisfaction/tree/master/34_wpppj" rel="noopener ugc nofollow" target="_blank"> kweonwooj用Python重新实现pjpan的第34位解决方案(用R代码实现)</a></li><li id="e882" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><a class="ae kg" rel="noopener" target="_blank" href="/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e">https://medium.com/r/?URL = https % 3A % 2F % 2f towards data science . com % 2f fine-tuning-xgboost-in-python-like-a-boss-b 4543 ed 8 B1 e</a></li><li id="3c79" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated">https://towards data science . com/mercari-price-re commendation-for-online-retail-sellers-979 C4 d07 f 45 c？gi=5873f2d314af </li><li id="85b7" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><a class="ae kg" href="https://medium.com/@thewingedwolf.winterfell/response-coding-for-categorical-data-7bb8916c6dc1" rel="noopener">https://medium . com/@ thewingdwolf . winterfell/response-coding-for-categorical-data-7bb 8916 c6dc 1</a></li><li id="9416" class="kz la iq lb b lc lr le ls lg lt li lu lk lv lm ln lo lp lq bi translated"><a class="ae kg" rel="noopener" target="_blank" href="/understanding-auc-roc-curve-68b2303cc9c5">https://towards data science . com/understanding-AUC-roc-curve-68b 2303 cc9 C5</a></li></ol></div></div>    
</body>
</html>