<html>
<head>
<title>Optimizing Model Training with TensorFlow Profiler</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用张量流剖面仪优化模型训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optimizing-model-training-with-tensorflow-profiler-eb94eab0ec18?source=collection_archive---------19-----------------------#2020-11-13">https://towardsdatascience.com/optimizing-model-training-with-tensorflow-profiler-eb94eab0ec18?source=collection_archive---------19-----------------------#2020-11-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0d28" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用TensorFlow优化GPU性能</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/711c8307b353bbf6dda20a37cd92ccb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*o1NQ2cGWyfj2xf63rNWDAg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者的TensorFlow Profiler漫游</p></figure><p id="b480" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们希望我们的模特训练得非常快。我们使用GPU使操作执行得更快。然而，即使在加速计算之后，该模型在流水线本身中也可能效率低下，因此可能训练得更慢。在这种情况下，调试代码变得非常困难，事实上，甚至很难判断什么是慢的。</p><p id="b378" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这可以通过使用张量流剖面仪来解决。分析器“分析”张量流代码的执行。在本文中，我们将讨论分析器、如何使用它、最佳实践以及如何优化GPU性能。</p><p id="3486" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">注意</strong>本文期望训练TensorFlow模型和使用Tensorboard的基础知识。你可以<a class="ae lu" rel="noopener" target="_blank" href="/a-quickstart-guide-to-tensorboard-fb1ade69bbcf">参考我在Tensorboard </a>上的文章，如果你不知道的话。</p><h1 id="4ec7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">张量流剖面仪</h1><p id="7ebc" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">首先，甚至在优化任何东西之前，让我们讨论一下分析器是什么，它提供了什么。</p><blockquote class="ms mt mu"><p id="783f" class="ky kz mv la b lb lc ju ld le lf jx lg mw li lj lk mx lm ln lo my lq lr ls lt im bi translated">分析有助于您了解模型中各种TensorFlow操作(ops)的硬件资源消耗(时间和内存),解决性能瓶颈，并最终使模型执行得更快。</p><p id="a1a8" class="ky kz mv la b lb lc ju ld le lf jx lg mw li lj lk mx lm ln lo my lq lr ls lt im bi translated">— <a class="ae lu" href="https://www.tensorflow.org/guide/profiler" rel="noopener ugc nofollow" target="_blank">张量流文档</a></p></blockquote><p id="c6a0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基本上，分析器监控模型训练。它记录了执行ops所需的时间、执行完整步骤所需的时间，收集了关于时间和内存方面的资源利用率的见解，并为理解这些见解提供了可视化效果。</p><p id="c4e0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在接下来的章节中，我们将了解如何使用分析器:</p><ol class=""><li id="3c44" class="mz na it la b lb lc le lf lh nb ll nc lp nd lt ne nf ng nh bi translated"><strong class="la iu">我们将通过分析训练一个简单的模型。</strong></li><li id="0e8a" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><strong class="la iu">探索剖析器，深入了解培训内容。</strong></li><li id="85fa" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><strong class="la iu">利用这些见解优化培训。</strong></li></ol><h1 id="5193" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">如何给模特做侧写？</h1><p id="54eb" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">要了解如何使用探查器，我们先来训练一个模型！我们将使用来自<a class="ae lu" href="https://www.tensorflow.org/datasets" rel="noopener ugc nofollow" target="_blank"> tensorflow-datasets </a>的著名mnist数据集:</p><p id="d60e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要安装TensorFlow Profiler，请使用:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="10c8" class="ns lw it no b gy nt nu l nv nw">pip install -U tensorboard_plugin_profile</span></pre><p id="db05" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">注意</strong> Profiler要求安装最新版本的TensorFlow和TensorBoard。</p><p id="e1cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，加载并预处理数据集:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="617d" class="ns lw it no b gy nt nu l nv nw">(ds_train, ds_test), ds_info = tfds.load(<br/>      'mnist',<br/>      split=['train', 'test'],<br/>      shuffle_files=True,as_supervised=True,with_info=True,                       )</span><span id="e322" class="ns lw it no b gy nx nu l nv nw">def rescale(image, label):<br/>      return tf.cast(image, tf.float32) / 255., label</span><span id="d808" class="ns lw it no b gy nx nu l nv nw">ds_train = ds_train.map(rescale)<br/>ds_train = ds_train.batch(128)</span></pre><p id="19fb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">构建模型:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="a85f" class="ns lw it no b gy nt nu l nv nw">model = tf.keras.models.Sequential([<br/>      tf.keras.layers.Flatten(input_shape=(28, 28, 1))<br/>      tf.keras.layers.Dense(128,activation='relu'),<br/>      tf.keras.layers.Dense(10, activation='softmax')<br/>])</span><span id="d5e7" class="ns lw it no b gy nx nu l nv nw">model.compile(<br/>      loss='sparse_categorical_crossentropy',<br/>      optimizer=tf.keras.optimizers.Adam(0.001),<br/>      metrics=['accuracy']<br/>)</span></pre><p id="c843" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，启用分析器非常简单。您只需要在tensorboard回调中添加一个额外的参数:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="e8cb" class="ns lw it no b gy nt nu l nv nw">tensorboard_callback = tf.keras.callbacks.TensorBoard(<br/>      log_dir = logs,<br/>      histogram_freq = 1,<br/><strong class="no iu">      profile_batch = '500,520'</strong><br/>)</span></pre><p id="bb58" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe ny nz oa no b">profile_batch</code>参数告诉TensorFlow捕获执行性能并对其进行分析。<strong class="la iu"><em class="mv">【500，520】</em></strong>指定您希望评测的批次，即<strong class="la iu">型号从批次500到520的性能将被捕获。</strong></p><p id="2d09" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们将像往常一样使用上面的回调来训练模型:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="9467" class="ns lw it no b gy nt nu l nv nw">model.fit(<br/>      ds_train,<br/>      epochs=2,<br/>      validation_data=ds_test,<br/>      <strong class="no iu">callbacks = [t</strong><strong class="no iu">ensor</strong><strong class="no iu">board_callback]</strong><br/>)</span></pre><h1 id="b69f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用分析器</h1><p id="32d4" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">现在我们已经训练了模型，让我们看看在分析器的帮助下我们做得如何:</p><h2 id="8988" class="ns lw it bd lx ob oc dn mb od oe dp mf lh of og mh ll oh oi mj lp oj ok ml ol bi translated">概览页面</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/3c2b92fa0ff44412b3716e74e21b030b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XPJMNcW9zS7M6F4KbBSvCw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的探查器概述页面</p></figure><p id="d910" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本节对模型性能进行了高度概括。以下是一些需要注意的事项:</p><ol class=""><li id="d89c" class="mz na it la b lb lc le lf lh nb ll nc lp nd lt ne nf ng nh bi translated"><strong class="la iu">步进时间图</strong>(右图)是<strong class="la iu"/><strong class="la iu">步数</strong> (x轴)<strong class="la iu"> v/s执行相应步骤</strong>(步进时间，y轴)所需时间的曲线图。它还显示了<strong class="la iu">每个类别</strong>(彩色分区)使用了该步进时间的哪一部分。看上面的图，我们可以知道我们的模型是<strong class="la iu">‘高度输入限制’，</strong>，也就是说，它在输入操作上花费了大量的训练时间。我们将在一段时间内对此进行优化:)</li><li id="258e" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><strong class="la iu">平均步进时间</strong>(在性能总结下)给出了平均步进时间的细分。在理想情况下，我们希望我们的模型将大部分时间花在实际的“训练”上，即保持GPU忙碌(<strong class="la iu">设备计算时间</strong>必须是最高的，所有其他开销必须尽可能低)。</li><li id="492c" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><strong class="la iu"> TF Op Placement </strong>(在性能摘要下)显示主机(CPU)与设备(GPU)上执行的操作百分比。为了最大化GPU利用率，设备操作位置必须最大化。</li></ol><blockquote class="ms mt mu"><p id="a3d7" class="ky kz mv la b lb lc ju ld le lf jx lg mw li lj lk mx lm ln lo my lq lr ls lt im bi translated">在理想情况下，您的程序应该具有高GPU利用率、最小的CPU(主机)到GPU(设备)通信，并且没有来自输入管道的开销。</p><p id="3395" class="ky kz mv la b lb lc ju ld le lf jx lg mw li lj lk mx lm ln lo my lq lr ls lt im bi translated">— <a class="ae lu" href="https://www.tensorflow.org/guide/gpu_performance_analysis" rel="noopener ugc nofollow" target="_blank">张量流文档</a></p></blockquote><h2 id="4c7b" class="ns lw it bd lx ob oc dn mb od oe dp mf lh of og mh ll oh oi mj lp oj ok ml ol bi translated">跟踪查看器</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/91493001535414b3774b337b7bcca3a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5nah_sw4c9cXXDBUOLAfA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者的跟踪查看器</p></figure><p id="0c4c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，在这个工具变得更加可怕之前，让我们来分解一下:</p><ul class=""><li id="c806" class="mz na it la b lb lc le lf lh nb ll nc lp nd lt on nf ng nh bi translated"><strong class="la iu">左边</strong>(垂直灰柱)，可以看到两大板块:<strong class="la iu"> </strong> <code class="fe ny nz oa no b">/device</code> <strong class="la iu"> </strong>和<code class="fe ny nz oa no b">/host</code>。这告诉我们哪个TensorFlow op在哪个设备(GPU或CPU)上执行。).</li><li id="f0c6" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt on nf ng nh bi translated"><strong class="la iu">到右侧</strong>，彩色条表示各TensorFlow操作已经执行的持续时间。</li></ul><blockquote class="ms mt mu"><p id="e998" class="ky kz mv la b lb lc ju ld le lf jx lg mw li lj lk mx lm ln lo my lq lr ls lt im bi translated">通常，主机执行输入操作，预处理训练数据并将其传输到设备，而设备执行实际的模型训练。</p><p id="65f5" class="ky kz mv la b lb lc ju ld le lf jx lg mw li lj lk mx lm ln lo my lq lr ls lt im bi translated">— <a class="ae lu" href="https://www.tensorflow.org/guide/profiler#trace_viewer" rel="noopener ugc nofollow" target="_blank">张量流文档</a></p></blockquote><p id="81bb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">探索这个工具将使您对这些持续时间有更好的了解(分别使用W和S来放大或缩小)。首先，看看这个:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/5d1d9e00f9cb1724cd63413124a89975.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8-NVrqQjodXNX48HL2QivA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">探索跟踪查看器</p></figure><ol class=""><li id="cf29" class="mz na it la b lb lc le lf lh nb ll nc lp nd lt ne nf ng nh bi translated"><strong class="la iu">流#19 </strong>显示了用于启动计算内核和制作设备到设备副本的时间线。</li><li id="42e1" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><strong class="la iu">流#20 </strong>用于主机到设备的拷贝，并且</li><li id="7b81" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><strong class="la iu"> <em class="mv">流</em> #21 </strong>用于设备托管拷贝。</li></ol><p id="ef99" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">理想情况下，GPU计算时间线必须是拥挤的(即，GPU繁忙)。主机到设备和设备到主机的拷贝应该最少。</p><p id="8652" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用<strong class="la iu">步骤</strong>时间线，您可以看到模型的不同阶段，如<strong class="la iu">向前传递</strong> ( <code class="fe ny nz oa no b">sequential</code>和<code class="fe ny nz oa no b">dense</code>)、<strong class="la iu">损失计算</strong> ( <code class="fe ny nz oa no b">sparse_categorical_crossentropy</code>)、<strong class="la iu">向后传递</strong> ( <code class="fe ny nz oa no b">gradient_tape</code>和<code class="fe ny nz oa no b">Adam</code>)。这些操作间应挤满<strong class="la iu">台阶</strong>之间的最小空间。空格表示GPU空闲时间，拥挤表示利用率。</p><p id="3837" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其余工具提供了关于概述页面和跟踪查看器中涵盖的特定类别或操作的全面见解。让我们快速浏览一下:</p><ol class=""><li id="8b7b" class="mz na it la b lb lc le lf lh nb ll nc lp nd lt ne nf ng nh bi translated"><strong class="la iu">输入管道分析器:</strong>输入管道分析器检查输入管道，并通知是否存在性能瓶颈。它还告诉我们，如果我们的模型是输入绑定的。</li><li id="c923" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><strong class="la iu"> GPU内核统计:</strong>这个工具显示每个GPU内核的性能统计数据和原始op。</li><li id="fd75" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><strong class="la iu">内存分析:</strong>该工具分析GPU内存使用情况。这可用于分析和调试GPU内存耗尽时引发的<strong class="la iu"> OOM </strong>(内存不足)错误。</li><li id="e1b5" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><strong class="la iu"> TensorFlow Stats: </strong>该工具给出了执行的每个 TensorFlow op的<strong class="la iu">性能概述。为了可读性，它为主机和设备操作提供了一个合适的分组。</strong></li></ol><h1 id="6b15" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">最佳化</h1><p id="c102" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在前面的部分中，我们训练了我们的模型，并看到了分析器如何帮助识别管道和资源利用中潜在的低效。本节将尝试解决这些效率低下的问题，看看我们的模型是否做得更好…</p><p id="5cb1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们已经看到我们的模型是高度'<strong class="la iu">输入受限的</strong>，也就是说，它的大部分训练时间都花在了输入操作上(例如，预处理)。如果你从<strong class="la iu">轨迹查看器</strong>中观察<code class="fe ny nz oa no b">tf_data_iterator_get_next</code> <strong class="la iu"> <em class="mv"> </em> </strong>，我们可以看到<code class="fe ny nz oa no b">tf.data</code>操作占了很多时间。这是因为我们的<code class="fe ny nz oa no b">tf.data.Dataset</code>在训练期间实时获取批次。</p><p id="6faf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以做的一件事就是使用<strong class="la iu"> <em class="mv">缓存</em> </strong>和<strong class="la iu"> <em class="mv">预取</em> </strong>。</p><ol class=""><li id="b986" class="mz na it la b lb lc le lf lh nb ll nc lp nd lt ne nf ng nh bi translated"><code class="fe ny nz oa no b"><a class="ae lu" href="https://www.tensorflow.org/guide/data_performance#caching" rel="noopener ugc nofollow" target="_blank">tf.data.Dataset.cache</a></code>将数据集加载到内存或本地存储器中。这将为昂贵的I/O操作节省时间，如在每个时期从文件<strong class="la iu">中打开和读取数据。</strong></li><li id="ddc0" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated"><code class="fe ny nz oa no b"><a class="ae lu" href="https://www.tensorflow.org/guide/data_performance#prefetching" rel="noopener ugc nofollow" target="_blank">tf.data.Dataset.prefetch</a></code>实质上是提前准备数据<strong class="la iu">和并行准备</strong>和<strong class="la iu">。</strong></li></ol><p id="5c32" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此<em class="mv"> </em>在没有预取的情况下，在给定的步骤<code class="fe ny nz oa no b">s</code>，首先在时间<code class="fe ny nz oa no b">t1</code>获取(并预处理)数据。然后，模型在时间<code class="fe ny nz oa no b">t2</code>中根据这些数据进行训练。现在步骤<code class="fe ny nz oa no b">s</code>的总步骤时间变为<code class="fe ny nz oa no b">(t1 + t2)</code>。</p><p id="37d8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是在预取的情况下，一个<strong class="la iu">后台线程</strong>获取步骤<code class="fe ny nz oa no b">(s + 1)</code> <strong class="la iu"> <em class="mv"> </em> </strong>的数据，同时模型正在针对步骤<code class="fe ny nz oa no b">s</code>的数据进行训练。因此，如果为步骤<code class="fe ny nz oa no b">(s + 1)</code>获取数据所需的时间是<code class="fe ny nz oa no b">t1</code>，为步骤<code class="fe ny nz oa no b">s</code>训练模型所需的时间是<code class="fe ny nz oa no b">t2</code>，那么步骤时间将是<code class="fe ny nz oa no b">max(t1, t2)</code>。</p><p id="8ad8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们在前面的代码中添加缓存和预取功能:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="c2d3" class="ns lw it no b gy nt nu l nv nw">ds_train = ds_train.map(rescale)<br/>ds_train = ds_train.batch(128)<br/>ds_train = ds_train.cache()<br/>ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)</span></pre><p id="1101" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，用和之前完全一样的方法训练模型。</p><p id="6a3f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们已经优化了我们的培训，让我们来看看评测器:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/203a8fe2c4481bacc59a7b0b6c3952f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eN1_St_Uf9EAMrWqEhIirw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">优化后的探查器</p></figure><ul class=""><li id="44be" class="mz na it la b lb lc le lf lh nb ll nc lp nd lt on nf ng nh bi translated">可以清楚地看到，输入开销显著降低。此外，平均步骤时间几乎减半(6.2到3.2)。你可以在推荐中看到，程序是'<strong class="la iu">适度输入绑定的。</strong></li><li id="7d9e" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt on nf ng nh bi translated">设备TF Op布局也有相当大的增加。</li></ul><p id="3522" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们检查跟踪查看器:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/b541fc73a32826ba423ba1cd9692f4df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R_BxvC7MUfD6FA_QLk2DYA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">优化后的跟踪查看器</p></figure><ul class=""><li id="10d0" class="mz na it la b lb lc le lf lh nb ll nc lp nd lt on nf ng nh bi translated">注意<strong class="la iu">流#19 </strong>现在更加拥挤，这意味着GPU利用率有所提高。</li><li id="dc6d" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt on nf ng nh bi translated"><strong class="la iu">流#20 </strong>和<strong class="la iu"> #21 </strong>已经最小化，因此主机到设备和设备到主机的拷贝已经减少。</li><li id="f56e" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt on nf ng nh bi translated">由于我们使用了<strong class="la iu">缓存</strong>和<strong class="la iu">预取，这次<code class="fe ny nz oa no b">tf_data_iterator_get_next</code>也不那么拥挤了。</strong></li></ul><h1 id="44a1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">关于优化的更多信息</h1><p id="bd4e" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在上一节中，我们看到了优化如何提高模型性能。为了便于演示，我只做了一个优化更改。但是优化远不止这些。</p><p id="486b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这一节中，我们将浏览一些优化来寻找:</p><ol class=""><li id="b8a5" class="mz na it la b lb lc le lf lh nb ll nc lp nd lt ne nf ng nh bi translated">首先，<strong class="la iu">使用GPU并不总是好的</strong>。在前面的章节中，我们已经看到，将计算卸载到GPU会产生设备到主机和主机到设备的复制开销。此外，启动GPU内核也会增加延迟。那么，<strong class="la iu">如果你的模型很小，以至于这些开销所需的时间比实际训练时间还多，那么使用GPU真的是正确的事情吗？</strong></li><li id="d1d7" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated">在跟踪查看器中，我们看到步骤之间的间隔应该很小(间隔表示GPU空闲时间)。我们在上一节中优化了输入管道，但我们看不到间隙长度有太大差异。其中一个可能的原因是:GPU在每一步开始时执行一些主机端活动，如复制数据或调度。同时，<code class="fe ny nz oa no b">tf.data</code>在线程上运行，在CPU端并行化输入流水线。这些CPU端线程有可能会干扰GPU活动。为此，您可以设置环境变量:<code class="fe ny nz oa no b">TF_GPU_THREAD_MODE=gpu_private</code>。<strong class="la iu">这确保了GPU内核从它们自己的专用线程中启动，而不会排在</strong> <code class="fe ny nz oa no b">tf.data</code> <strong class="la iu">工作之后。</strong></li><li id="7395" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated">即使在调试线程之后，如果步骤之间的间隔没有缩小，<strong class="la iu">检查您的回调、步骤之后的执行以及度量评估</strong>。如果禁用这些可以提高性能，那么您可能需要考虑只在几个步骤中计算这些。此外，对于定制培训，您可以使用<code class="fe ny nz oa no b"><a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/while_loop" rel="noopener ugc nofollow" target="_blank">tf.while_loop</a></code>。</li><li id="4890" class="mz na it la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated">我们已经讨论过，理想情况下，大多数运算必须放在GPU上。<strong class="la iu">总览页面上的TF Op位置</strong>有助于我们做到这一点。这减少了用于制作拷贝的主机-设备通信。这里有一个确保运算在GPU上得到最佳分配的技巧:<strong class="la iu">即使对于一个GPU，也要使用像</strong> <code class="fe ny nz oa no b"><a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/distribute/OneDeviceStrategy" rel="noopener ugc nofollow" target="_blank">tf.distribute.OneDeviceStrategy</a></code>这样的分配策略。</li></ol><h1 id="68d7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="4a95" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在这篇非常详尽的文章中，我们讨论了一个非常有用的TensorFlow工具，它可以用来调试模型。我们看到了该工具提供的功能、使用它的基础知识，以及在GPU上优化TensorFlow模型性能的方法。</p><p id="1970" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于分析器和优化还有很多，我鼓励您阅读文档(参考资料中的链接)了解更多！</p><p id="7a09" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文中我没有提到的一项重要优化技术是使用<a class="ae lu" href="https://www.tensorflow.org/xla" rel="noopener ugc nofollow" target="_blank"> XLA </a>和<a class="ae lu" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank"> fp16混合精度</a>。这实际上可能需要一段时间来涵盖，最好在一个单独的文章中解释！</p><h1 id="7d11" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><div class="or os gp gr ot ou"><a href="https://www.tensorflow.org/guide/profiler" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">使用Profiler | TensorFlow Core优化TensorFlow性能</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">使用分析器提供的工具来跟踪TensorFlow模型的性能。查看您的模型如何…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">www.tensorflow.org</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi ks ou"/></div></div></a></div><div class="or os gp gr ot ou"><a href="https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">张量流分析器:分析模型性能|张量板</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">机器学习算法通常计算量很大。因此，量化…的性能至关重要</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">www.tensorflow.org</p></div></div><div class="pd l"><div class="pj l pf pg ph pd pi ks ou"/></div></div></a></div><div class="or os gp gr ot ou"><a href="https://www.tensorflow.org/guide/gpu_performance_analysis" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">使用TensorFlow Profiler优化TensorFlow GPU性能</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">本指南面向利用GPU提高模型性能的TensorFlow用户。使用张量流剖面仪作为…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">www.tensorflow.org</p></div></div><div class="pd l"><div class="pk l pf pg ph pd pi ks ou"/></div></div></a></div><div class="or os gp gr ot ou"><a href="https://www.tensorflow.org/guide/data_performance" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">使用tf.data API | TensorFlow核心提高性能</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">GPU和TPU可以从根本上减少执行单个训练步骤所需的时间。实现最佳性能…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">www.tensorflow.org</p></div></div><div class="pd l"><div class="pl l pf pg ph pd pi ks ou"/></div></div></a></div><div class="or os gp gr ot ou"><a rel="noopener follow" target="_blank" href="/10-tensorflow-tricks-every-ml-practitioner-must-know-96b860e53c1"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">每个ML从业者必须知道的10个张量流技巧</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">为什么TensorFlow是完整的ML包</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">towardsdatascience.com</p></div></div><div class="pd l"><div class="pm l pf pg ph pd pi ks ou"/></div></div></a></div><div class="or os gp gr ot ou"><a rel="noopener follow" target="_blank" href="/a-quickstart-guide-to-tensorboard-fb1ade69bbcf"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">TensorBoard快速入门指南</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">如何使用TensorBoard可视化ML实验</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">towardsdatascience.com</p></div></div><div class="pd l"><div class="pn l pf pg ph pd pi ks ou"/></div></div></a></div></div></div>    
</body>
</html>