<html>
<head>
<title>Techniques for Handling Imbalanced Classification Datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于处理不平衡分类数据集的技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/techniques-for-handling-imbalanced-classification-datasets-5ee58b0b5e7a?source=collection_archive---------31-----------------------#2020-11-16">https://towardsdatascience.com/techniques-for-handling-imbalanced-classification-datasets-5ee58b0b5e7a?source=collection_archive---------31-----------------------#2020-11-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7101" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解处理结构化数据的不平衡分类数据集的常用技术</h2></div><p id="48eb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">在本文中，您将了解不平衡数据集以及分类数据集不平衡时出现的问题。了解常用技术，如过采样、欠采样、生成合成数据以处理不平衡数据集，最后，将所有概念应用于不平衡数据集。</em>T3】</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/72c153ffaa1875d45dba206bea808cbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VE96yWoITApdmW0N9uH2oA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">在<a class="ae lv" href="https://unsplash.com/s/photos/balance?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae lv" href="https://unsplash.com/@rouichi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Azzedine Rouichi </a>的照片</p></figure><blockquote class="lw"><p id="80c9" class="lx ly it bd lz ma mb mc md me mf ld dk translated">不平衡数据集是指一个类与其他类相比具有不成比例的观测值。数据集中的每个类并不具有相等的表示，不平衡会导致偏斜的类分布。</p></blockquote><p id="147d" class="pw-post-body-paragraph ki kj it kk b kl mg ju kn ko mh jx kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated"><em class="le">你必须运行分类算法来区分良性肿瘤和癌性肿瘤。良性肿瘤有20，000个观察值，而癌性肿瘤只有100个观察值；这导致数据集不平衡。</em></p><p id="2de9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">当观察结果的预测是良性时，不平衡数据集的影响是可见的，而它实际上是导致假阴性的癌性肿瘤。</em></p><p id="9672" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">精确度是分类最常见的性能度量，但避免使用精确度作为性能度量，因为它可能会产生误导，尤其是在不平衡数据集的情况下。当我们在数据集中有不成比例的类表示时，模型可能会预测所有预测的大多数类的值，并实现高分类准确性，也称为<strong class="kk iu">准确性悖论。</strong></p><p id="5808" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了确保一个模型在现实世界中运行良好，需要将假阳性和假阴性保持在最低限度。精确度有助于计算假阳性的成本，而回忆有助于理解假阴性的成本。因此，精确度、召回率和F1值是衡量模型性能的更好指标。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ml"><img src="../Images/cfe65021933c7178dc09cb2ab5a3fcdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mCWAPAdD9-dHo2gBx0tOQA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><h2 id="99a7" class="mm mn it bd mo mp mq dn mr ms mt dp mu kr mv mw mx kv my mz na kz nb nc nd ne bi translated">处理不平衡数据集的常用技术</h2><ol class=""><li id="f873" class="nf ng it kk b kl nh ko ni kr nj kv nk kz nl ld nm nn no np bi translated"><strong class="kk iu">成本敏感训练</strong>通过惩罚机器学习算法来考虑少数类的错误分类成本。这个想法是为了最小化分类的成本。</li><li id="266f" class="nf ng it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated"><strong class="kk iu">欠采样或下采样多数类</strong>其中多数类的观察值被随机移除，以减少其对机器学习算法的影响</li><li id="8347" class="nf ng it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated"><strong class="kk iu">过采样或上采样，少数类</strong>随机复制少数类的观察值，以增加对机器学习算法的影响</li><li id="46da" class="nf ng it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated"><strong class="kk iu">使用SMOTE(合成少数民族过采样技术)为少数民族类创建合成数据。</strong> SMOTE从少数类中随机抽取样本，找到其最近的k个邻居，然后在随机选取的数据点与其最近的k个邻居之间选择一个点，生成合成数据。</li></ol><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/00e810078c4ce2c908b3510e41777e18.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*2xrSk8G2BcN9JmWhG4RuwA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">SMOTE使用最近的k-邻居生成合成数据(图片由作者提供)</p></figure><p id="a38f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您将利用保险交叉销售的不平衡<a class="ae lv" href="https://www.kaggle.com/anmolkumar/health-insurance-cross-sell-prediction" rel="noopener ugc nofollow" target="_blank">数据集</a>来构建物流回归，以预测现有客户是否会对车辆保险感兴趣。</p><p id="268d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">导入所需的库并将数据读入数据框</p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="f4e1" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">import numpy as np<br/>import pandas as pd<br/>from sklearn.preprocessing import StandardScaler</strong><br/><strong class="nx iu">from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn.metrics import plot_confusion_matrix</strong><br/><strong class="nx iu">from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score</strong><br/><strong class="nx iu">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>%matplotlib inline</strong></span><span id="fdf8" class="mm mn it nx b gy of oc l od oe">#Reading the data from the csv file into a dataframe<strong class="nx iu"><br/>data= pd.read_csv(r'\Insurance_data\train.csv')</strong></span></pre><p id="94fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">显示数据集信息</p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="deb5" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">data.info()</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/aac3f0b3b34ab752f29edacd9bb45211.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*D5joSp37qi4c5v56TkOz4w.png"/></div></figure><p id="1456" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">将分类变量转换为指示器列</strong></p><p id="a574" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们有一些分类变量，如性别和车辆损坏，需要转换为虚拟变量或指标变量。这里，我们通过将<strong class="kk iu"> <em class="le"> drop_first </em> </strong>参数设置为True来移除第一层，以从k个分类层中获得k-1个虚拟层。</p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="10ba" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">data_2 = pd.get_dummies(data,drop_first=True)</strong></span></pre><p id="c25a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">查看数据</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oh"><img src="../Images/38a4bf71d761747dd27761c74ef93023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JAXl4k5fz3e2HIRIO9n2rQ.png"/></div></div></figure><p id="4c36" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">创建特征和目标变量</strong></p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="9c36" class="mm mn it nx b gy ob oc l od oe">X= data_2.iloc[:,[1,2,3,4,5,6,7,9,10,11,12]]<br/>y=data_2.iloc[:,8]</span></pre><p id="402e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">查看目标变量分布</strong></p><p id="e43b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">检查目标变量分布，以检查数据集是否平衡。</p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="ad3b" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">y.value_counts().plot(kind='bar',figsize=(3,3),title="Insurance sell")<br/>plt.xlabel("Insurance Response")<br/>plt.ylabel("Frequency")<br/>y_pos=50000<br/>x_pos=0<br/>for i, v in enumerate(data_count):<br/>    plt.text(i+x_pos, y_pos, v, horizontalalignment='center',      verticalalignment='center', fontsize=20)<br/>plt.show()</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/d211908d2bfec61ad0722d06bac433fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*TmkVnE6C8NeKA3z-jkMNRw.png"/></div></figure><p id="80c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">数据集是不平衡的，因为我们对不感兴趣购买车辆保险的客户的观察多于对购买车辆保险感兴趣的客户</strong>。</p><p id="e54e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">应用标准标量对特征进行标准化</strong></p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="13ce" class="mm mn it nx b gy ob oc l od oe"># define standard scaler<br/><strong class="nx iu">scaler = StandardScaler()<br/>X= pd.DataFrame(scaler.fit_transform(X))</strong></span></pre><p id="29b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">将数据集分为训练和测试</strong></p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="5c99" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">X_train, X_test, y_train, y_test=  train_test_split(X,y,test_size=0.2)</strong></span></pre><h2 id="ea1a" class="mm mn it bd mo mp mq dn mr ms mt dp mu kr mv mw mx kv my mz na kz nb nc nd ne bi translated">不平衡数据集的精度悖论</h2><p id="21ba" class="pw-post-body-paragraph ki kj it kk b kl nh ju kn ko ni jx kq kr oj kt ku kv ok kx ky kz ol lb lc ld im bi translated"><strong class="kk iu">对不平衡的训练数据集</strong>运行逻辑回归，显示准确度、精确度、召回率和F1分数。</p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="2cf3" class="mm mn it nx b gy ob oc l od oe">clf = LogisticRegression(random_state=0).fit(X_train, y_train)<br/>y_pred=clf.predict(X_test)</span></pre><p id="a84d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">绘制混淆矩阵</strong></p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="22a9" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">plot_confusion_matrix(clf,X_test, y_test)</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/112171a87c5e242c687766a4cc2b8f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*8-QJ1fJg3QGTciL4xTVx4w.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">不平衡数据集上使用逻辑回归的混淆矩阵</p></figure><p id="8086" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在不平衡测试数据集上检查准确度、精确度、召回率和F1分数。</p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="70c4" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">print("Accuracy",accuracy_score(y_test, y_pred))<br/>print("Precision", precision_score(y_test, y_pred))<br/>print("Recall",recall_score(y_test, y_pred))<br/>print("F1 score",f1_score(y_test, y_pred))</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/3bcd5a43c949102898e512745e152e3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:366/format:webp/1*NFTpC6cvn1OcHRcczBADHA.png"/></div></figure><p id="acda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以看到我们有相对较好的准确率，召回率和F1-score非常糟糕。这证明了<strong class="kk iu">准确性悖论</strong>，其中<strong class="kk iu">准确性不是模型性能的良好度量。检查精确度、召回率和F1值是个好主意。</strong></p><h2 id="2cf8" class="mm mn it bd mo mp mq dn mr ms mt dp mu kr mv mw mx kv my mz na kz nb nc nd ne bi translated">应用<strong class="ak">对成本敏感的培训</strong></h2><p id="7d65" class="pw-post-body-paragraph ki kj it kk b kl nh ju kn ko ni jx kq kr oj kt ku kv ok kx ky kz ol lb lc ld im bi translated">应用<strong class="kk iu"> class_weight="balanced" </strong>将根据课程频率自动调整权重。类别权重与输入数据中的类别频率成反比。</p><p id="7cd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">类权重=数据集中记录总数/(类总数*类内样本数)</em> </strong></p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="96ee" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">clf_cw = LogisticRegression(random_state=0, <em class="le">class_weight='balanced'</em>).fit(X_train, y_train)</strong></span><span id="5ec0" class="mm mn it nx b gy of oc l od oe"><strong class="nx iu">y_pred= clf_cw.predict(X_test)</strong></span><span id="8359" class="mm mn it nx b gy of oc l od oe"><strong class="nx iu">print("Accuracy",accuracy_score(y_test, y_pred))<br/>print("Precision", precision_score(y_test, y_pred))<br/>print("Recall",recall_score(y_test, y_pred))<br/>print("F1 score",f1_score(y_test, y_pred))</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/adb50b384b47fdc5a5980fe857d15644.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*-FfpFWIfTUaql3ihNt80og.png"/></div></figure><p id="15c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以看到准确性下降了，但我们有更好的F1成绩。</p><p id="52c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">应用class_weights后显示混淆矩阵</p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="17ab" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">plot_confusion_matrix(clf_cw, X_test, y_test)</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/7947ed10893c4e03cfa8caa34ee771b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*DF6DSXC4n5GF5AOd99z6lw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">混淆矩阵将class_weights应用于不平衡数据集</p></figure><p id="7c99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">安装<strong class="kk iu"> <em class="le"> imblearn </em> </strong>库，使用不同的技术处理不平衡的数据集</p><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="c8b5" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">pip install imblearn</strong></span></pre><h2 id="ca6b" class="mm mn it bd mo mp mq dn mr ms mt dp mu kr mv mw mx kv my mz na kz nb nc nd ne bi translated">应用随机欠采样</h2><p id="44d7" class="pw-post-body-paragraph ki kj it kk b kl nh ju kn ko ni jx kq kr oj kt ku kv ok kx ky kz ol lb lc ld im bi translated">在这里，您将使用一个类来执行随机欠采样，它通过随机选取有替换或无替换的样本来对大多数类进行欠采样。</p><p id="04df" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比较原始数据集和使用随机欠采样生成的训练数据集之间的观察数量</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/11235bc4a5b4870c4ff4f94a4ee20208.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*XKRBj_RXtOMhhd5xgvdd0g.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">欠采样或欠采样多数类</p></figure><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="8a0d" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">from imblearn.under_sampling import RandomUnderSampler</strong></span><span id="c848" class="mm mn it nx b gy of oc l od oe"># create the train and test dataset<br/><strong class="nx iu">X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2)</strong></span><span id="22a1" class="mm mn it nx b gy of oc l od oe"># Create an instance of RandomUnderSampler, fit the training data #and apply Logistics regression<br/><strong class="nx iu">rus= RandomUnderSampler()<br/>X_train, y_train = rus.fit_resample(X_train, y_train)<br/>clf_rus=  LogisticRegression(random_state=0).fit(X_train, y_train)</strong></span><span id="3920" class="mm mn it nx b gy of oc l od oe"># predict the test data<br/><strong class="nx iu">y_pred= clf_rus.predict(X_test)</strong></span><span id="e3d5" class="mm mn it nx b gy of oc l od oe"># print the model performance metrics<br/><strong class="nx iu">print("Accurcay",accuracy_score(y_test, y_pred))<br/>print("Precision", precision_score(y_test, y_pred))<br/>print("Recall",recall_score(y_test, y_pred))<br/>print("F1 score",f1_score(y_test, y_pred))<br/>plot_confusion_matrix(clf_rus, X_test, y_test)</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/8a2c73a4156e01763ea43e72cf48ee3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*QRdnTXu9toQfq5nlH1kLSg.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">使用随机欠采样的性能度量</p></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/a49320ea4a85505e7e69f31d9e94be37.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*m4AU6IID7gVdDIpOIlurZA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">使用随机欠采样的混淆度量</p></figure><h2 id="8511" class="mm mn it bd mo mp mq dn mr ms mt dp mu kr mv mw mx kv my mz na kz nb nc nd ne bi translated">应用随机过采样</h2><p id="3e69" class="pw-post-body-paragraph ki kj it kk b kl nh ju kn ko ni jx kq kr oj kt ku kv ok kx ky kz ol lb lc ld im bi translated">随机过采样通过替换随机选取样本来对少数类进行过采样。您可以将采样策略指定为参数，以对数据集进行重新采样。</p><p id="05ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比较原始数据集和使用随机过采样生成的训练数据集之间的观察次数。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/537b609b601794c066c8268cc2fd949a.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*9AeRQIvF-jvEoSDkOZdAWA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">过采样或上采样少数类</p></figure><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="c7df" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">from imblearn.over_sampling import RandomOverSampler</strong></span><span id="d124" class="mm mn it nx b gy of oc l od oe"># create the train and test dataset<br/><strong class="nx iu">X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2)</strong></span><span id="e88d" class="mm mn it nx b gy of oc l od oe"># Create an instance of RandomOverSampler, fit the training data #and apply Logistics regression<br/><strong class="nx iu">ros= RandomOverSampler(sampling_strategy='auto')<br/>X_train, y_train = ros.fit_resample(X_train, y_train)<br/>clf_ros=  LogisticRegression(random_state=0).fit(X_train, y_train)</strong></span><span id="d6a9" class="mm mn it nx b gy of oc l od oe"># predict the test data<br/><strong class="nx iu">y_pred= clf_ros.predict(X_test)</strong></span><span id="b8a4" class="mm mn it nx b gy of oc l od oe"># print the model performance metrics<br/><strong class="nx iu">print("Accurcay",accuracy_score(y_test, y_pred))<br/>print("Precision", precision_score(y_test, y_pred))<br/>print("Recall",recall_score(y_test, y_pred))<br/>print("F1 score",f1_score(y_test, y_pred))<br/>plot_confusion_matrix(clf_ros, X_test, y_test)</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/19bb1aee8f9c9e1a3ee621f5e5292f89.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*40AI4nbAa_rUnO4QvY8THA.png"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/aea352b98b97669ecd9167e3047c6877.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*QbMIukF33lP0ddPz0ebLdA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">使用随机过采样器的性能度量</p></figure><h2 id="8a40" class="mm mn it bd mo mp mq dn mr ms mt dp mu kr mv mw mx kv my mz na kz nb nc nd ne bi translated">应用合成少数过采样技术(SMOTE)</h2><p id="8d50" class="pw-post-body-paragraph ki kj it kk b kl nh ju kn ko ni jx kq kr oj kt ku kv ok kx ky kz ol lb lc ld im bi translated">SMOTE通过从少数类中抽取随机样本来执行过采样，找到其最近的k个邻居，这是一个可以指定的参数。在随机选择的数据点及其最近的k个邻居之间选择一个点，以生成合成数据。</p><p id="a820" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比较原始数据集和使用SMOTE生成的训练数据集之间的观察次数。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/1e2b3fb843a44fde1c29655b8b9b482c.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*OUWwwQsFA1GVmjW2IGM3xg.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">应用SMOTE生成合成数据</p></figure><pre class="lg lh li lj gt nw nx ny nz aw oa bi"><span id="b61f" class="mm mn it nx b gy ob oc l od oe"><strong class="nx iu">from imblearn.over_sampling import SMOTE</strong></span><span id="754c" class="mm mn it nx b gy of oc l od oe"># create the train and test dataset<br/><strong class="nx iu">X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2)</strong></span><span id="17aa" class="mm mn it nx b gy of oc l od oe">##Create an instance of SMOTE, fit the training data and apply #Logistics regression<br/><strong class="nx iu">sm = SMOTE(random_state=27, sampling_strategy='minority', k_neighbors=5)<br/>X_train, y_train = sm.fit_resample(X_train, y_train)<br/>clf_sm = LogisticRegression(random_state=0).fit(X_train, y_train)</strong></span><span id="bea3" class="mm mn it nx b gy of oc l od oe"># predict the test data<br/><strong class="nx iu">y_pred= clf_sm.predict(X_test)</strong></span><span id="fe14" class="mm mn it nx b gy of oc l od oe"># print the model performance metrics<br/><strong class="nx iu">print("Accurcay",accuracy_score(y_test, y_pred))<br/>print("Precision", precision_score(y_test, y_pred))<br/>print("Recall",recall_score(y_test, y_pred))<br/>print("F1 score",f1_score(y_test, y_pred))<br/>plot_confusion_matrix(clf_sm, X_test, y_test)</strong></span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/f493c55890e6de97ce30ec7646e5b9ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*L0as9d33LDuqKSxkA5BQvQ.png"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/4877a62389b806cf6a19796332ccb6a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*bD7or4Zuy0lP7SsDLG8-Fg.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">使用SMOTE的性能指标</p></figure><h2 id="0c9f" class="mm mn it bd mo mp mq dn mr ms mt dp mu kr mv mw mx kv my mz na kz nb nc nd ne bi translated">结论:</h2><p id="dc70" class="pw-post-body-paragraph ki kj it kk b kl nh ju kn ko ni jx kq kr oj kt ku kv ok kx ky kz ol lb lc ld im bi translated">一个类的观测值明显多于其他类的数据集会产生不平衡数据集，从而扭曲测试结果。有不同的技术，如过采样少数类、欠采样或下采样多数类、成本敏感技术或使用SMOTE创建合成数据。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/7cce240f93400de6229e355b5d9328f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*1-rOFHDaRcnCU2kuUVAUZg.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">应用不同技术处理不平衡数据集的类的观察数量比较(图片由作者提供)</p></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/7d1c6d831753c4227b22b83a60ab98bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*gz4NJhNlEA2eUiqkcVje8g.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">处理不平衡数据集的不同技术的性能指标比较(图片由作者提供)</p></figure></div></div>    
</body>
</html>