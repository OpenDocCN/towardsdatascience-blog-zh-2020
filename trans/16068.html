<html>
<head>
<title>K-Means 8x faster, 27x lower error than Scikit-learn’s in 25 lines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-意味着比Scikit-learn的25行代码快8倍，错误低27倍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-8x-faster-27x-lower-error-than-scikit-learns-in-25-lines-eaedc7a3a0c8?source=collection_archive---------8-----------------------#2020-11-05">https://towardsdatascience.com/k-means-8x-faster-27x-lower-error-than-scikit-learns-in-25-lines-eaedc7a3a0c8?source=collection_archive---------8-----------------------#2020-11-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5c00" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">脸书·费斯图书馆又罢工了</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/68e8b2771b55a98cab1478fdb9446e69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/1*Nx6IyGfRAV1ly6uDGnVCxQ.gif"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">k-均值迭代(<a class="ae kr" href="https://en.wikipedia.org/wiki/K-means_clustering#/media/File:K-means_convergence.gif" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><h2 id="2a53" class="ks kt iq bd ku kv kw dn kx ky kz dp la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">介绍</h2><p id="26eb" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lb lx ly lz lf ma mb mc lj md me mf mg ij bi translated">在我上一篇关于faiss库的文章<a class="ae kr" rel="noopener" target="_blank" href="/make-knn-300-times-faster-than-scikit-learns-in-20-lines-5e29d74e76bb">中，我用20行代码展示了如何使用</a><a class="ae kr" href="https://github.com/facebookresearch/faiss" rel="noopener ugc nofollow" target="_blank">脸书的faiss库</a>让kNN比Scikit-learn快300倍。但是我们可以用它做更多的事情，包括更快更准确的K-Means聚类，只用了25行代码！</p><p id="1092" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">K-Means是一种迭代算法，它将数据点聚类成k个聚类，每个聚类用一个均值/中心点(质心)表示。训练从一些最初的猜测开始，然后在两个步骤之间交替:分配和更新。</p><p id="c252" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">在分配阶段，我们将每个点分配给最近的聚类(使用点和质心之间的欧几里德距离)，在更新步骤中，我们重新计算每个质心，从当前步骤中分配给该聚类的所有点计算平均点。</p><p id="3f45" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">聚类的最终质量被计算为聚类内距离的总和，其中对于每个聚类，我们计算该聚类中的点与其质心之间的欧几里德距离的总和。这也叫惯性。</p><p id="2726" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">对于预测，我们在新点和质心之间执行1最近邻搜索(k=1的kNN)。</p><p id="1fb5" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated"><strong class="lq ir"> Scikit-learn vs faiss </strong></p><p id="8667" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">在这两个库中，我们必须指定算法超参数:聚类数、重启次数(每次都从其他初始猜测开始)和最大迭代次数。</p><p id="4e74" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">正如我们从例子中看到的，算法的核心是搜索最近的邻居，特别是最近的质心，用于训练和预测。这就是faiss比Scikit快几个数量级的地方——学习！它利用了优秀的C++实现、尽可能的并发性，甚至GPU，如果你愿意的话。</p><p id="0607" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated"><strong class="lq ir">用faiss实现K-Means聚类</strong></p><p id="7173" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">下面的Github要点也可以在我的定期Github(链接)上找到。</p><p id="e360" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">faiss的一个很大的特点是它既有安装和构建说明(安装文档)，又有一个优秀的文档和示例(入门文档)。安装完成后，我们可以编写实际的集群。代码非常简单，因为我们只是模仿了Scikit-learn API。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="6724" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">重要元素:</p><ul class=""><li id="c433" class="mo mp iq lq b lr mh lu mi lb mq lf mr lj ms mg mt mu mv mw bi translated">faiss专门为这个任务内置了<code class="fe mx my mz na b">Kmeans</code>类，但是它的参数名称与Scikit-learn中的不同(参见<a class="ae kr" href="https://github.com/facebookresearch/faiss/wiki/Faiss-building-blocks:-clustering,-PCA,-quantization" rel="noopener ugc nofollow" target="_blank">文档</a></li><li id="b433" class="mo mp iq lq b lr nb lu nc lb nd lf ne lj nf mg mt mu mv mw bi translated">我们必须确保使用<code class="fe mx my mz na b">np.float32</code>类型，因为faiss只使用这种类型</li><li id="2460" class="mo mp iq lq b lr nb lu nc lb nd lf ne lj nf mg mt mu mv mw bi translated"><code class="fe mx my mz na b">kmeans.obj</code>通过训练返回错误列表，为了得到像Scikit-learn中那样的最终错误，我们使用<code class="fe mx my mz na b">[-1]</code>索引</li><li id="caf9" class="mo mp iq lq b lr nb lu nc lb nd lf ne lj nf mg mt mu mv mw bi translated">使用<code class="fe mx my mz na b">Index</code>数据结构进行预测，这是faiss的基本构建块，用于所有最近邻搜索</li><li id="d38f" class="mo mp iq lq b lr nb lu nc lb nd lf ne lj nf mg mt mu mv mw bi translated">在预测中，我们使用k = 1执行kNN搜索，从<code class="fe mx my mz na b">self.cluster_centers_</code>返回最近质心的索引(索引<code class="fe mx my mz na b">[1]</code>，因为<code class="fe mx my mz na b">index.search()</code>返回距离和索引)</li></ul><h2 id="d717" class="ks kt iq bd ku kv kw dn kx ky kz dp la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">时间和准确度比较</h2><p id="6863" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lb lx ly lz lf ma mb mc lj md me mf mg ij bi translated">我选择了Scikit-learn中的一些流行数据集进行比较。比较列车时刻和预测时刻。为了便于阅读，我明确地写了基于faiss的集群比Scikit-learn的集群快多少倍。为了进行误差比较，我刚刚写了基于faiss的聚类实现了多少倍的低误差(因为数字很大并且不太能提供信息)。</p><p id="8569" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">所有这些时间都是用<code class="fe mx my mz na b">time.process_time()</code>函数测量的，该函数测量进程时间而不是挂钟时间，以获得更准确的结果。结果是100次运行的平均值，除了MNIST，在那里Scikit-learn花费了太长时间，我不得不运行5次。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ng"><img src="../Images/b49f487d827cc08675386bdd05f07f8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZhUKlMXDH1pvqG42LUGSvw.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">火车时间(图片由作者提供)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nl"><img src="../Images/4702376d8a639b2b44cdb3fd556c351a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_7DYkf53LyehzhMm40OoMQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">预测时间(图片由作者提供)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/e3be8178fe5077517df1580cd21593f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*yOheZ1zIVBNnGciatVuGrA.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">训练错误(图片由作者提供)</p></figure><p id="dcf4" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">正如我们所看到的，对于小数据集(前4个数据集)的K-Means聚类，基于faiss的版本对于训练来说更慢，并且具有更大的误差。对于预测来说，它的工作速度普遍更快。</p><p id="865c" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">对于更大的MNIST数据集，faiss显然是赢家。训练速度提高20.5倍是巨大的，特别是因为它将时间从几乎3分钟减少到不到8秒钟！1.5倍的预测速度也不错。然而，真正的成就是误差降低了惊人的27.5倍。这意味着对于更大的真实世界数据集，基于faiss的版本要精确得多。而这只需要25行代码！</p><p id="b86d" class="pw-post-body-paragraph lo lp iq lq b lr mh jr lt lu mi ju lw lb mj ly lz lf mk mb mc lj ml me mf mg ij bi translated">因此，基于这一点:如果你有大型(至少几千个样本)真实世界数据集，基于faiss的版本显然更好。对于小型玩具数据集，Scikit-learn是更好的选择；然而，如果你有一个GPU，GPU加速的faiss版本可能会更快(我没有检查它以进行公平的CPU比较)。</p><h2 id="57af" class="ks kt iq bd ku kv kw dn kx ky kz dp la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">摘要</h2><p id="49a2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lb lx ly lz lf ma mb mc lj md me mf mg ij bi translated">通过25行代码，我们可以利用faiss库为合理规模的数据集进行K-Means聚类，从而获得巨大的速度和准确性提升。如果你需要，你可以通过GPU、多个GPU等获得更好的性能，这在faiss文档中有很好的解释。</p></div></div>    
</body>
</html>