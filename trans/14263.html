<html>
<head>
<title>A light passage for LightGBM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于照明的光通道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-light-passage-for-lightgbm-76543bb09a07?source=collection_archive---------38-----------------------#2020-10-01">https://towardsdatascience.com/a-light-passage-for-lightgbm-76543bb09a07?source=collection_archive---------38-----------------------#2020-10-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1a45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一个决定将数据科学作为职业的非IT背景的人，我意识到有太多的知识需要扩展和技能需要利用，包括写作技能——以简单易懂的方式解释概念，而不管受众背景如何。因此，我决定开始在媒介上写作。</p><p id="0c0f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，本文将解释LightGBM。LightGBM代表光梯度提升机，我们试着用5W+1H来分解概念。</p><blockquote class="kl km kn"><p id="2439" class="jn jo ko jp b jq jr js jt ju jv jw jx kp jz ka kb kq kd ke kf kr kh ki kj kk ij bi translated">什么是光梯度助推机？</p></blockquote><p id="3b97" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LightGBM是一个梯度推进框架，使用基于树的学习算法。在我看来，基于树的算法是最直观的算法，因为它模仿人类如何做决定。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/b28ae40685ca205d139f8a2a02d88bc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uz_bIePpSeCqrFjNdDMGaw.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">现在是上午11点，你不知道是现在吃还是等会儿吃，所以你做了一个决策树。一个决策树由作为根本原因的根节点、作为判定节点的分支节点和作为判定结果的叶节点组成。图片由作者提供。</p></figure><p id="8a21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在回答问题之前，首先我们需要知道什么是boosting，以及梯度boosting框架。</p><p id="ad8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="ko"> Boosting </em>是一种用于创建预测器集合的集成技术，或者是将弱学习器组合成强学习器以预测输出的方法。这里的弱学习者是决策树的每一个。它之所以弱，是因为它在预测或分类方面表现不佳。为了获得更好的预测，我们组合弱学习者，其中每个学习者将产生一个假设，并将它组合在一起将在预测输出时创建一个最终假设。Boosting的工作方式是让树按顺序生长:每棵树都是使用以前生长的树的信息生长的。</p><p id="0092" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然我们想在我们的模型中添加许多弱学习者，我们可能会问，我们如何知道我们的模型是否被优化了？这里，我们使用<em class="ko">梯度推进</em>，我们应用梯度下降程序来寻找损失函数最小化的最佳模型。</p><p id="92e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这意味着要理解梯度推进，我们必须理解梯度下降，损失函数和优化函数。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi li"><img src="../Images/07500d53135570cd2689555b51a8789e.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/1*ECSP7yCz6tV0rTmnOhXyRg.gif"/></div><p class="le lf gj gh gi lg lh bd b be z dk translated">一个简单的gif来说明梯度下降，其中我们想找到一个损失函数为RMSE的线性回归的概念。绿线下降的梯度，直到找到梯度接近0的最小RMSE量。gif是作者做的。</p></figure><p id="3b7f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">优化函数是我们应用来达到我们想要的目标的函数，在这种情况下是最小化损失函数。损失函数将测量模型与实际数据的差距。如果模型或预测的结果相差甚远，损失函数将产生一个很大的数字。优化函数将逐渐减小损失函数/误差，直到它收敛到最小值。我们经常遇到的损失函数有回归问题的均方根误差(RMSE)和平均绝对误差(MAE ),分类问题的二元损失函数和交叉熵损失。梯度下降意味着梯度将随着损失函数变得最小而逐渐下降，直到梯度达到极限值0。</p><p id="a803" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">回到LightGBM，使用基于树的学习算法，弱学习器将依次增长，这意味着我们构建的第一个树将学习如何适应目标变量，然后第二个树将从第一个树学习并学习如何适应残差，下一个树将学习减少残差并适应来自前一个树的残差，这将继续，直到残差不变。误差的梯度在整个系统中传播，这被称为逐级树生长。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi lj"><img src="../Images/b8aac5cbf4a6e32165e9ee342581d8df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P1uHwsMu_f0zGEvh4YK0kg.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">摘自<a class="ae lk" href="https://lightgbm.readthedocs.io/en/latest/Features.html" rel="noopener ugc nofollow" target="_blank"> LightGBM文档</a>,描述了逐叶生长的树。</p></figure><p id="a3ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LightGBM与另一种梯度提升算法的不同之处在于，在XGBoost中，树的增长是逐级的，而CatBoost更适合分类变量。</p><blockquote class="kl km kn"><p id="2f37" class="jn jo ko jp b jq jr js jt ju jv jw jx kp jz ka kb kq kd ke kf kr kh ki kj kk ij bi translated">谁构建了LightGBM？</p></blockquote><p id="4919" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2017年，微软将LightGBM作为XGBoost的替代产品。lightGBM可以在Python、R和C++中使用。</p><blockquote class="kl km kn"><p id="62c5" class="jn jo ko jp b jq jr js jt ju jv jw jx kp jz ka kb kq kd ke kf kr kh ki kj kk ij bi translated">为什么我们需要使用LightGBM？</p></blockquote><p id="d141" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如文档中所述，LightGBM是梯度推进算法在效率、速度以及支持分布式并行处理和GPU方面的改进。</p><p id="81f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你想建立一个有大量数据的模型，LightGBM是适合使用的。如果你只有100个数据，最好使用其他机器学习算法，因为你的模型可能会导致过度拟合。</p><blockquote class="kl km kn"><p id="9287" class="jn jo ko jp b jq jr js jt ju jv jw jx kp jz ka kb kq kd ke kf kr kh ki kj kk ij bi translated">如何使用LightGBM？</p></blockquote><p id="1a16" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简而言之，我在使用lightGBM时采用了三个步骤:</p><ol class=""><li id="fa7d" class="ll lm iq jp b jq jr ju jv jy ln kc lo kg lp kk lq lr ls lt bi translated">准备训练和测试数据(数据预处理、探索性数据分析和分类变量的数据编码)</li><li id="5cc6" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lq lr ls lt bi translated">选择优化函数以获得调谐参数。你可以选择网格搜索、随机搜索、贝叶斯优化等等。几个重要的调整参数是:</li></ol><ul class=""><li id="1a58" class="ll lm iq jp b jq jr ju jv jy ln kc lo kg lp kk lz lr ls lt bi translated">learning_rate:在梯度下降中向损失函数的最小值移动时，每次迭代的步长</li><li id="f584" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lz lr ls lt bi translated">max_depth:树的最大深度，通过降低树的深度来处理过度拟合</li><li id="1b6f" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lz lr ls lt bi translated">min_data_in_lead:一个叶子可以拥有的最小记录数</li><li id="5da1" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lz lr ls lt bi translated">feature_fraction:在构建树的每次迭代中随机选择的特征/参数的分数</li><li id="7f4e" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lz lr ls lt bi translated">bagging_fraction:指定在创建新数据集的每次迭代中使用的数据的分数</li><li id="f624" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lz lr ls lt bi translated">λ:用于调节以解决过度拟合和特征选择的参数，l1范数用于套索回归，l2范数用于岭回归</li><li id="8bed" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lz lr ls lt bi translated">min_split_gain:在树中进行拆分的最小增益</li></ul><p id="c1c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.训练模型、拟合模型和评估模型</p><p id="a4da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您有兴趣了解变量和目标变量之间的关系，您可以使用feature_importance。特征重要性将显示哪些变量在预测/分类中起主要作用。</p><p id="467d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LightGBM是一种流行的boosting算法，广泛用于数据科学。它可以处理分类数据，速度快，并按叶子顺序增长树。</p><p id="5c9d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了关闭这个，</p><blockquote class="kl km kn"><p id="5492" class="jn jo ko jp b jq jr js jt ju jv jw jx kp jz ka kb kq kd ke kf kr kh ki kj kk ij bi translated">在哪里可以找到完整的文档、学习地点和项目示例？</p></blockquote><p id="0d76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">完整文档:<a class="ae lk" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> LightGBM </a></p><p id="24fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我遇到的很棒的教程和读物:</p><p id="fb69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae lk" href="http://faculty.marshall.usc.edu/gareth-james/ISL/" rel="noopener ugc nofollow" target="_blank">统计学习入门</a>一本学习的好书，而且是免费的！</p><p id="e707" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一本解释<a class="ae lk" rel="noopener" target="_blank" href="/catboost-vs-light-gbm-vs-xgboost-5f93620723db"> XGBoost、LightGBM和CatBoost </a>性能的好书</p><p id="824e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae lk" href="https://www.kaggle.com/jsaguiar/lightgbm-with-simple-features" rel="noopener ugc nofollow" target="_blank"> kaggle </a>中应用LightGBM的例子</p><p id="7f37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更多关于<a class="ae lk" href="https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/" rel="noopener ugc nofollow" target="_blank">梯度增强算法</a></p><p id="19bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于视听学习者来说，这是一个伟大的youtube频道，作者是Alexander Ihler教授</p><p id="c840" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">和LightGBM一样，我的写作是按顺序增长的。</p><p id="1aa0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你发现这篇文章有什么可以改进的地方，请随时给我留言。干杯！</p></div></div>    
</body>
</html>