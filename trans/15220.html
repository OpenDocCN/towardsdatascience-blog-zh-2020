<html>
<head>
<title>One Event to Rule them All</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个事件来统治他们</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/one-event-to-rule-them-all-e9adf04667a3?source=collection_archive---------50-----------------------#2020-10-19">https://towardsdatascience.com/one-event-to-rule-them-all-e9adf04667a3?source=collection_archive---------50-----------------------#2020-10-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9f82" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="0668" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><em class="ko">将实时分析提升到新的水平</em></h2></div><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/3aeee1b5f178ae26f09952fd544965c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJ8sFo38MmouRX6Jfj3UNA.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="ko">图片由</em> <a class="ae lf" href="https://www.shutterstock.com/g/garloon" rel="noopener ugc nofollow" target="_blank">鲁斯兰发牢骚</a> <em class="ko">经</em><a class="ae lf" rel="noopener ugc nofollow" target="_blank" href="/www.shutterstock.com"><em class="ko">shutterstock.com</em></a><em class="ko">下发给远出者</em></p></figure><p id="a29f" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们已经基于Apache Kafka、Spark Streaming和Apache Druid运行实时分析一年多了。在解决了连接这些技术的问题之后，正如我最近的博客文章所描述的，我们向我们的系统添加了许多用例。一般来说，每个用例都是根据以下原则构建的:从一个Kafka主题中读取原始事件，在Spark流作业中处理它们，写入另一个Kafka主题，并摄取到Apache Druid中。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mc"><img src="../Images/8566154197f46d3afc86f476af431616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*N-c5bmWpQEq53C68"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><p id="8e2c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">它使我们能够从实时仪表盘中获得广泛的洞察力。然而，每种类型的事件都有自己的流程和可视化，独立于其他类型的事件。例如，我们有一个单独的视图来显示我们所有的点击和我们的印象。我们可以创建一个仪表板，并排显示两个磁贴——一个用于点击，一个用于展示。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi md"><img src="../Images/0df56de49457030cd6e5dc7ec53cd546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ABf2OJ1zjnoWH-rv"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><p id="ae8d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">但是，我们无法同时获得基于这两个流的指标。例如，我们无法计算CTR — <a class="ae lf" href="https://en.wikipedia.org/wiki/Click-through_rate" rel="noopener ugc nofollow" target="_blank">点击率</a>——这是广告技术行业非常重要的指标。计算点击率需要特定时间段的点击数除以印象数。对于关系数据库来说，这是一项非常简单的任务——使用连接语法从两个或多个表中选择一个表来运行一个查询。德鲁伊就不是这样。<strong class="li ja">加入</strong>操作最近被添加到了最新的德鲁伊版本中，然而，它主要被用作查找功能的一部分。完整的连接支持预计将在下一个版本中提供，直到2020年底。</p><h1 id="51af" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">联合与加入</h1><p id="9ccf" class="pw-post-body-paragraph lg lh iq li b lj mw ka ll lm mx kd lo lp my lr ls lt mz lv lw lx na lz ma mb ij bi translated">为了最大限度地利用我们的实时分析系统，我们希望找到一种方法来根据不同类型的事件计算指标，而不使用连接。我们在寻找一个创新的想法。我们决定使用逻辑联合来解决这个问题。</p><p id="6d81" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">让我们考虑下面的例子:我们有一个包含两种类型事件的大表——点击和印象。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nb"><img src="../Images/aeb5cec50fc56079a98d635a8a5d0ed3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RmUtAHVCbexkJpL5dNjjYQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><p id="3fc1" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们看到，在特定的时间段内，我们获得了三次点击和五次展示。所以那段时间的CTR是3/5=0.6</p><p id="7478" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">类似地，我们可以计算另一个重要的指标——RPM——每千次展示的收入。</p><p id="596f" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这两个指标都是从单个表中计算出来的，不需要连接到其他表。这里的技巧是“标记”不同类型的事件，以便在查询期间区分它们。</p><h1 id="cb80" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">实时事件—实时数据的中心。</h1><p id="aa0b" class="pw-post-body-paragraph lg lh iq li b lj mw ka ll lm mx kd lo lp my lr ls lt mz lv lw lx na lz ma mb ij bi translated">基于这个例子，我们构建了一个系统，将几种不同的事件类型流式传输到一个Kafka主题，然后传输到Druid。该系统包含几个Spark流作业，每个作业处理一种特定类型的事件。每个作业从原始Kafka主题中读取事件级数据，用更多字段丰富它，并写入输出Kafka主题。注意，所有的作业都写进了<strong class="li ja">同一个卡夫卡主题。</strong>每个作业根据具体的业务逻辑，除了其他字段外，还为每个事件添加一个“event_type”字段。通常作业会添加一些布尔字段，例如处理点击的作业可以验证点击状态，并将“is_valid_click”设置为0或1。这使得这些字段能够在Druid和SQL查询中得到有效处理。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nc"><img src="../Images/d3d1cbd0ad9a5d6047949151aa206aca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rMlpCEEuQbY5bZpy"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><h1 id="613a" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">数据采样</h1><p id="d810" class="pw-post-body-paragraph lg lh iq li b lj mw ka ll lm mx kd lo lp my lr ls lt mz lv lw lx na lz ma mb ij bi translated">实时处理如此大量的数据是资源密集型的。我们需要Spark流集群中的资源来运行Spark流作业。我们需要Kafka集群中的资源来包含所有类型事件的统一主题。最后，我们需要Druid集群中的资源来存储所有这些事件。</p><p id="9fa2" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">让我们回顾一下——我们想从这个系统中获得什么好处？我们的目标是建立一个系统，为我们的数据提供实时视图。我们的目标是缩小基于批处理的主数据处理系统造成的差距，该系统每小时利用Hive、Vertica、Tableau和数百个ETL作业。批处理过程提供了对数据的可访问性，有几个小时的延迟。相比之下，基于Druid构建的系统应该快速灵活，我们还可以允许一些数据差异。因此，我们决定通过对数据进行采样来降低系统的负载。</p><h1 id="6c55" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">火花作业中的取样。</h1><p id="1227" class="pw-post-body-paragraph lg lh iq li b lj mw ka ll lm mx kd lo lp my lr ls lt mz lv lw lx na lz ma mb ij bi translated">我们使用<em class="nd"> RDD.sample </em> API对从Kafka主题中读取的事件进行采样。采样率是我们所有Spark工作的一个参数。</p><p id="de39" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="nd"> rdd.sample(false，sampleRate，seed)；</em></p><p id="f264" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">每个作业的采样率可以不同。例如，印象的数量远大于点击的数量，因此我们可以对100%的点击进行采样，但只能对1%的印象进行采样。</p><p id="1739" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这个技术减少了火花，卡夫卡和德鲁伊的负荷。然而，我们需要记住，我们只有德鲁伊所有事件的一部分。我们如何保证从德鲁伊那里查询的数据是正确的，并得到完整的图片？</p><h1 id="317b" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">在德鲁伊教中处理采样。</h1><p id="cf9f" class="pw-post-body-paragraph lg lh iq li b lj mw ka ll lm mx kd lo lp my lr ls lt mz lv lw lx na lz ma mb ij bi translated">假设我们在Spark流工作中对1%的印象事件进行采样。因此在德鲁伊中我们只有1%的印象。请注意，印象的所有记录都有以下标记字段:<em class="nd"> is_impression = 1 </em>。通常，在没有抽样的情况下，我们会在Druid中运行以下查询来获得印象数:</p><p id="1286" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="nd">从realtime_event中选择SUM(is _ impression)；</em></p><p id="947a" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">现在，对采样数据运行这个查询，我们需要记住结果应该乘以100。如果我们将采样率从1%提高到10%，会发生什么？在这种情况下，我们需要将来自Druid的查询结果乘以10。这种手动方法可以运行一些特定的查询。但是，对于包含多个Spark作业(每个作业都有自己的采样速率)的系统，它是不可伸缩的。此外，我们为来自不同团队的多个用户开发了我们的系统——采样方法应该对他们透明。他们应该能够简单透明地查询数据。</p><h1 id="07b3" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">添加样本因子</h1><p id="9097" class="pw-post-body-paragraph lg lh iq li b lj mw ka ll lm mx kd lo lp my lr ls lt mz lv lw lx na lz ma mb ij bi translated">为了能够透明地处理我们在Druid中的数据，我们提出了以下想法:我们为每个事件添加了一个“sampleFactor”字段，通过以下公式计算:</p><p id="37d1" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="nd">采样因子= 1/采样速率。</em></p><p id="2444" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">因此，对于1%的采样速率，采样因子为100。因此德鲁伊的度量值应该乘以100。</p><p id="9275" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们使用<em class="nd">样本因子</em>来计算德鲁伊在摄取卡夫卡时的重要度量。</p><h1 id="4b6a" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">选择抽样</h1><p id="d936" class="pw-post-body-paragraph lg lh iq li b lj mw ka ll lm mx kd lo lp my lr ls lt mz lv lw lx na lz ma mb ij bi translated">将这些实时数据应用到生产中时，我们面临一项新的需求——需要对特定流量进行“完全采样”的场景。例如，特定发布者的流量。使用Spark流作业可以轻松实现这一新要求。首先，我们检测事件是否属于特定的发布者，这应该是完全抽样的。如果是肯定的，我们不为此事件应用<em class="nd">rdd . sample()</em>；我们还将<em class="nd"> sampleFactor=1 </em>添加到该事件中。使用这种方法，我们仍然可以在德鲁伊得到正确的数字，即使一些事件被完全采样。</p><h1 id="eded" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">抽样与汇总</h1><p id="b94e" class="pw-post-body-paragraph lg lh iq li b lj mw ka ll lm mx kd lo lp my lr ls lt mz lv lw lx na lz ma mb ij bi translated">为什么我们开发我们的特别“抽样”机制，而不是使用Druid内置的rollup特性？原因是realtime_event数据源是几个事件类型的联合。它还包含各种维度的联合。该数据源中有100多个维度。我们可以根据需要相对容易地添加更多的维度。使用Druid的rollup特性来计算可用维度的数量是没有效率的。Druid为汇总数据源添加了内部计数器和总和。定义大约100维的rollup减少了两个事件具有完全相同的维(一分钟)的概率。然而，内部计数器和求和的开销仍然存在，使其效率低下。</p><h1 id="1df4" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">摘要</h1><p id="70e4" class="pw-post-body-paragraph lg lh iq li b lj mw ka ll lm mx kd lo lp my lr ls lt mz lv lw lx na lz ma mb ij bi translated">通过在Druid中将不同的事件类型合并到一个数据源中，我们构建了一个非常广泛的实时数据视图。这便于不同团队使用不同的数据分析用例。它还允许聚合传统上使用表间连接计算的各种度量。我们通过对事件进行采样来处理伸缩和资源问题。我们的采样技术可以根据需要轻松扩展。此外，我们管理Druid中的数据，以便底层采样对使用Druid数据的团队保持透明。</p></div></div>    
</body>
</html>