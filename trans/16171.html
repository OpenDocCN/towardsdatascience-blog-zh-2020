<html>
<head>
<title>Using TFRecords to Train a CNN on MNIST</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TFRecords训练CNN了解MNIST</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-tfrecords-to-train-a-cnn-on-mnist-aec141d65e3d?source=collection_archive---------19-----------------------#2020-11-07">https://towardsdatascience.com/using-tfrecords-to-train-a-cnn-on-mnist-aec141d65e3d?source=collection_archive---------19-----------------------#2020-11-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e7f3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">编写、读取和使用TFRecords的简短演练</h2></div><p id="429f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我开始使用TFRecords时，我花了一段时间来理解它的概念。有那么多新事物。为了让其他人免于这种麻烦，我创建了一个基于MNIST数据集的实践演练。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="4891" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:这篇博文现在在<a class="ae ll" rel="noopener" target="_blank" href="/training-a-neural-network-on-tfrecord-files-8bff3b6e9ff4">有一个更通用的版本</a>，包含了更多最新的概念。此外，还要注意的是，一旦你开始使用，TFRecord格式并不是那么难，这就是为什么我创建了一个<a class="ae ll" rel="noopener" target="_blank" href="/a-practical-guide-to-tfrecords-584536bc786c">的实用介绍</a>。要了解更多，在本教程之后，我建议您参考这两个资源。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><h1 id="b9f0" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated">概观</h1><p id="1071" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">MNIST数据集由黑白的数字化手写数字组成。每张图片28x28x1，非常小。整个数据集的内存占用只有32 MB。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/ee64a73f1b2b3d89df567aef016e3c96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*VxHZQO-adlbJZQy-uQVqRw.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">数据集概述。作者<a class="ae ll" href="https://commons.wikimedia.org/wiki/File:MnistExamples.png" rel="noopener ugc nofollow" target="_blank">约瑟夫·斯泰潘</a>。</p></figure><h1 id="ba3a" class="lm ln it bd lo lp mv lr ls lt mw lv lw jz mx ka ly kc my kd ma kf mz kg mc md bi translated">导入和助手函数</h1><p id="04e4" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">让我们从必要的进口开始；两个库，os和Tensorflow。此外，我们还设置了一个全局变量AUTOTUNE，我们稍后会用到它。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="55b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们将MNIST数据集下载到本地机器上。然后，我们将两个选项设置为True，<em class="nc"> shuffle_files </em>和<em class="nc"> as_supervised </em>。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="ab7a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们创建TFRecord数据集时，使用第一个选项；第二个选项允许稍微舒服一点的迭代。</p><p id="4e9f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还可以通过调用。基数()。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="9454" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下四个函数提高了可读性，并用于创建我们写入TFrecord文件的单个示例。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><h1 id="c298" class="lm ln it bd lo lp mv lr ls lt mw lv lw jz mx ka ly kc my kd ma kf mz kg mc md bi translated">写入TFRecords</h1><p id="df6b" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">接下来，我们检查所有拆分(这里，只有“训练”和“测试”)。</p><p id="0c65" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于每个分割，我们创建一个<em class="nc"> TFRecordWriter </em>，它将解析后的示例写入文件。请注意，我们将当前处理的分割添加到文件名中——这允许我们稍后通过字符串模式对文件进行分组。我们使用的额外索引用于计算我们写入磁盘的样本数量。这个小技巧对于自定义数据集很有帮助。cardinality()操作不会返回元素的数量。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="a9d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我们之前设置了as_supervised，所以现在我们可以迭代(例如，label)对。</p><p id="6441" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">主要的示例生成发生在临时字典<em class="nc">数据</em>的创建期间。首先，我们将稍后要使用的每个数据字段转换成一个<em class="nc"> tf.train.Feature </em>。对于图像的高度和宽度，我们使用一个<em class="nc"> _int64_feature </em>(因为这些数字是整数)；对于实际的图像数据，我们首先序列化数组，然后将其转换成一个<em class="nc"> bytes_list </em>。存储非标量数据需要这种转换。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="aafc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">定义好所有特性后，我们现在可以创建一个单独的<em class="nc">示例</em>并将其写入TFRecord文件。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="de0d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们继续进行，直到处理完当前拆分的所有示例，然后对以下子集重复该过程。</p><p id="3f77" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在处理完两个子集之后，我们已经创建了前两个TFRecord文件(耶！)，一个保存训练，一个保存测试数据。我们为每个子集的每个记录增加的索引在训练模型时很有用:</p><p id="531d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于tensorflow_datasets附带的数据集，只需调用。基数()。这不会报告像我们这样的自定义数据集的实际大小，而是返回-1，这意味着示例的数量是未知的。</p><p id="65e8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是，当在这样的数据集上训练时，我们必须知道我们的数据集可以交付多少批。否则，我们可能会在一个无限循环中运行；详情见下文。</p><p id="1719" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简单回顾一下:我们使用了MNIST数据集，并将所有示例写入TFRecord文件。</p><h1 id="eccf" class="lm ln it bd lo lp mv lr ls lt mw lv lw jz mx ka ly kc my kd ma kf mz kg mc md bi translated">正在读取TFRecords</h1><p id="8b54" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">在创建之后，我们希望将它们读回内存中。这个过程与上面类似，但方向相反:</p><p id="a932" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们创建了一个从TFRecord文件中读取示例的函数。在这里，我们创建了一个字典，其中包含了我们希望从示例中使用的所有字段；这本字典类似于我们用来写数据的那本。对于每个键，我们定义一个占位符。注意最后一个字段:它的类型是<em class="nc"> tf.string </em>(尽管我们将它存储为一个字节列表)；所有其他字段都用与以前相同的类型初始化。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="a697" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">准备好字典后，我们可以从TFRecord文件中提取示例。最后，我们获得原始图像数据。注意，我们将<em class="nc"> uint8 </em>设置为数据类型。如果我们的图像包含浮点，我们将设置<em class="nc"> float64 </em>为数据类型。由于MNIST数据的范围在0到255之间，因此我们可以接受整数:</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><h1 id="e511" class="lm ln it bd lo lp mv lr ls lt mw lv lw jz mx ka ly kc my kd ma kf mz kg mc md bi translated">创建数据集</h1><p id="1208" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">通过下面的函数，我们围绕TFRecord文件创建了一个数据集。以前，我们只定义了一个函数来得到一个例子；现在我们创建一个<em class="nc"> TFRecordDataset </em>来将所有的例子映射到这个函数。</p><p id="1bd9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在中间语句中这样做。这里，我们使用上面创建的自动调优器。在训练过程中，稍后，它会自动确定我们可以并行处理多少个示例。这可以减少GPU的空闲时间。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="2f8e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">之后，我们重组数据，设置批量大小，并设置repeat，不带参数；这意味着无休止地重复。这需要我们记住我们的数据集有多少个例子(如上所述)。</p><p id="a9ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[作为一种简单的替代方法，我们可以在这里将repeat设置为我们稍后想要训练的时期数，并将fit()-函数中的时期数设置为1。这使得数据集通过我们的网络解析“epoch”次(因为我们用epoch的数量设置了repeat()，但是只解析一次(因为我们用epochs = 1设置了fit())。]</p><p id="0303" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我们让自动调优器决定预取的最合适的例子数量。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="5b0f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到目前为止，我们只创建了一个数据集，并向它映射了一个数据生成函数。作为健全性检查，让我们看一下数据集给我们的一个样本。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="fbc4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它返回两个张量。第一个张量的形状为(32，28，28，1)(因为我们取了一个批次，批次大小为32)，第二个张量的形状为(32，)(因为我们有32个标签，在我们的批次中每个示例一个)。</p><p id="014e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到此为止，我们来回顾一下:</p><p id="5a2c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们创建了两个TFRecord文件，一个用于训练数据，一个用于测试数据。我们通过迭代原始MNIST数据集中的所有(影像，标注)对，将它们转换为tf.train.Feature。所有要素一起形成一个示例。然后，我们创建了一个函数来反转这一点；它从存储在TFRecord文件中的示例中提取特征。最后，我们将该函数映射到我们的数据集，并进行健全性检查，看看是否一切正常。</p><h1 id="34a9" class="lm ln it bd lo lp mv lr ls lt mw lv lw jz mx ka ly kc my kd ma kf mz kg mc md bi translated">培养</h1><p id="6437" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">我们的下一步是在TFRecordDataset上训练一个网络。</p><p id="fe81" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用一个简单的卷积神经网络；请随意尝试不同的架构。</p><p id="8998" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了保持可读性，我们编写了一个函数来返回我们的网络，并检查我们的输出层是否符合标签形状，</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="cb95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后在我们的训练数据集上拟合网络。我们将历元数(网络看到完整数据集的次数)设置为2。</p><p id="59d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们需要知道我们的训练数据集有多少个例子。由于我们将数据集设置为无限重复，所以我们需要告诉网络要查询多少批，直到完成一个历元；这是参数<em class="nc">步数每纪元:</em></p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="a60c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">训练完成后，在启用GPU的情况下，在Colab上大约需要30秒，我们将测试该模型。由于我们还将测试数据写入了TFRecord文件，我们可以使用我们的<em class="nc"> get_dataset() </em>函数从这些文件中快速创建另一个TFRecordDataset。</p><p id="9672" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于我们将函数调用中的第二个参数设置为“test”，所以我们的数据集不会重复；我们不需要确定步骤的数量。</p><p id="1f52" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们调用model.evaluate()，它返回两个值的数组。</p><figure class="mk ml mm mn gt mo"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="9211" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一个数字是损失；第二个数字是我们感兴趣的:精确度。仅仅过了两个时代，它就徘徊在95%左右，这是一个好的开始。</p><h1 id="cec3" class="lm ln it bd lo lp mv lr ls lt mw lv lw jz mx ka ly kc my kd ma kf mz kg mc md bi translated">摘要</h1><p id="bb82" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">我们把重点放在MNIST数据集上作为我们正在进行的例子。使用它，我们创建了两个TFRecord文件，一个用于训练数据，一个用于测试数据。接下来，我们讨论了将数据读回内存，以最终训练CNN。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="096c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇博文现在在<a class="ae ll" rel="noopener" target="_blank" href="/training-a-neural-network-on-tfrecord-files-8bff3b6e9ff4">有了一个更通用的版本</a>，包含了更多最新的概念。此外，还要注意的是，一旦你开始使用，TFRecord格式并不是那么难，这就是为什么我创建了一个<a class="ae ll" rel="noopener" target="_blank" href="/a-practical-guide-to-tfrecords-584536bc786c">的实用介绍</a>。要了解更多，在本教程之后，我建议您参考这两个资源。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="f9ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">涵盖整个过程的Colab笔记本在<a class="ae ll" href="https://colab.research.google.com/drive/19Ms8CwvTardmte9fk_jBWdBEZB8j5NP_?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>有售。</p><p id="b6c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章讨论了现有数据集环境中的TFRecords。如果你有兴趣看到这种用于自定义数据集的文件格式，请看一下<a class="ae ll" href="https://colab.research.google.com/drive/1yQRDYzJsHX8w5g042w02y0lm1S3vMscL?usp=sharing" rel="noopener ugc nofollow" target="_blank">这段代码</a></p><div class="nd ne gp gr nf ng"><a href="https://colab.research.google.com/drive/1yQRDYzJsHX8w5g042w02y0lm1S3vMscL?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd iu gy z fp nl fr fs nm fu fw is bi translated">谷歌联合实验室</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">创建自定义TFR数据集</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">colab.research.google.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu mp ng"/></div></div></a></div><p id="d1eb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于这个帖子</p><div class="nd ne gp gr nf ng"><a rel="noopener follow" target="_blank" href="/custom-audio-classification-with-tensorflow-af8c16c38689"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd iu gy z fp nl fr fs nm fu fw is bi translated">使用TensorFlow进行自定义音频分类</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">包含代码的端到端示例项目。</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">towardsdatascience.com</p></div></div><div class="np l"><div class="nv l nr ns nt np nu mp ng"/></div></div></a></div></div></div>    
</body>
</html>