<html>
<head>
<title>Targeting and Removing Bad Training Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">锁定并删除不良培训数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/targeting-and-removing-bad-training-data-8ccdac5e7cc3?source=collection_archive---------9-----------------------#2020-11-12">https://towardsdatascience.com/targeting-and-removing-bad-training-data-8ccdac5e7cc3?source=collection_archive---------9-----------------------#2020-11-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="cae1" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a>，<a class="ae ep" href="https://towardsdatascience.com/tagged/petsafe-plants-fastai" rel="noopener" target="_blank">用fast.ai对宠物安全植物进行分类</a></h2><div class=""/><div class=""><h2 id="2b1f" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">糟糕的形象阻碍了我们吗？</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/add93a83688a99326fd1e84bb6f9162a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nAF_cW7lu-oNXRIsd92OjA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@coleito" rel="noopener ugc nofollow" target="_blank">科尔·凯斯特</a>从<a class="ae le" href="https://unsplash.com" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄。</p></figure><p id="2dda" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在<a class="ae le" href="https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-a29587f3f04c" rel="noopener">第1部分:建立一个图像数据库</a>中，我们已经在网上搜集了关于植物及其对宠物的毒性的信息，对照第二个数据库交叉引用了这些字段，然后最终通过Google Images下载了每个类别的独特图像。</p><p id="e7c0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在<a class="ae le" href="https://kenichinakanishi.medium.com/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6" rel="noopener">第2部分:利用受控随机性进行训练</a>中，我们使用新的fast.ai框架训练神经网络，以基于图片识别植物的种类。我们实现了一种在NumPy、PyTorch和random包中播种随机性的方法，以及在单独的训练运行中将图像标记为训练或验证样本的灵活方法。这有助于我们更公平地比较改变分类器其他方面的影响。</p><p id="77db" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因为我们发现，我们的许多图像对我们的分类器的准确性有不利影响，因为我们的谷歌图像搜索结果的相关性越来越小，出现了像图画、图表和事实表这样的东西。这些将坏的训练样本放入我们的池中，使我们的模型在做我们想要它做的事情方面更差(根据自然照片对植物进行分类。)我们希望删除这些文件，但是手动检查500多个文件夹中的150个文件是一项非常艰巨的任务。用代码自动完成这项任务或者集中于最后的手工清理是一种更明智的做法。</p><blockquote class="mb mc md"><p id="8064" class="lf lg me lh b li lj ka lk ll lm kd ln mf lp lq lr mg lt lu lv mh lx ly lz ma ij bi translated"><strong class="lh ja">此处的主要目标将是检查我们如何能够尝试专门针对不利于训练的图像(例如，错误标记或类的坏例子)。)并测量它们的去除对整体训练准确度的影响。</strong></p></blockquote><p id="928c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所有相关代码都可以在我的<a class="ae le" href="https://github.com/kenichinakanishi/houseplant_classifier" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中找到。</p><h1 id="bd91" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">目录</h1><ol class=""><li id="4b67" class="na nb iq lh b li nc ll nd lo ne ls nf lw ng ma nh ni nj nk bi translated"><a class="ae le" href="https://medium.com/p/8ccdac5e7cc3#207f" rel="noopener">用fast.ai分类解释</a></li><li id="2724" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><a class="ae le" href="https://medium.com/p/8ccdac5e7cc3#26dd" rel="noopener">使用光学字符识别进行过滤</a></li><li id="ca82" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><a class="ae le" href="https://medium.com/p/8ccdac5e7cc3#eb3f" rel="noopener">使用色调分布过滤</a></li><li id="12d4" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><a class="ae le" href="https://medium.com/p/8ccdac5e7cc3#1570" rel="noopener">自动清理图像</a></li><li id="77a3" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><a class="ae le" href="https://medium.com/p/8ccdac5e7cc3#1021" rel="noopener">手动清理和训练结果</a></li></ol><h1 id="207f" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">1.利用fast.ai进行分类解释</h1><p id="b508" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">fast.ai内置了一系列有用的解释方法，用于分类问题，例如我们正在处理的问题。为了使用它们，我们首先重新创建一个学习者，并在使用<code class="fe nt nu nv nw b">ClassificationInterpretation.from_learner</code>准备解释类之前加载我们想要查看的保存状态。</p><p id="3540" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里我们使用一个在<a class="ae le" rel="noopener" target="_blank" href="/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6">第2部分:可控随机性训练</a>中创建和训练的学习器，它接受整个数据集，每个类150张图像。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nx ny l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">准备口译。</p></figure><p id="02a0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">fast.ai为我们提供了一种简单的方法，现在可以用<code class="fe nt nu nv nw b">interp.plot_confusion_matrix()</code>生成混淆矩阵，或者用<code class="fe nt nu nv nw b">interp.most_confused()</code>查看最常相互混淆的类。然而，有这么多的类(这里我们有超过500个类)，由于RAM的限制，我们会使试图生成如此密集的混淆矩阵的内核崩溃。幸运的是，fast.ai有一个有用的<code class="fe nt nu nv nw b">interp.plot_top_losses()</code>功能，可以向我们展示一些最让模型吃惊的图像(导致最大的损失)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nz"><img src="../Images/eb1f8090c74f5f7b8f044a48b8bc4f5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GdbQAwvJ8n9e9lYbkAryxw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">plot_top_losses向我们展示了学习者最自信的错误。从谷歌图片中抓取这些图片，大多数时候是因为图片标签不正确。</p></figure><p id="e03d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以看到，这些图像标签中有许多是不正确的，这表明数据集的一个主要问题是图像的错误标签。详细说明每个类别的F1分数的分类报告可以帮助我们识别模型正在努力解决的类别。</p><p id="c917" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用<code class="fe nt nu nv nw b">interp.print_classification_report()</code>将打印出分类报告。为了操作数据，我们应该用Jupyter的魔法命令拦截它，并将输入读回到数据帧中进行解释。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nx ny l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">捕获分类报告的输出。</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nx ny l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">将捕获的输出分配给一个变量，并解析成一个数据帧。</p></figure><p id="369e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有了这个<code class="fe nt nu nv nw b">class_report</code>数据框，我们可以一目了然地看到哪个班级的问题最多，并且可以更仔细地查看其文件夹中的图像。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oa"><img src="../Images/9b6ba200ea2d6eb8d8e6a7649156d9be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pSdiu5g8kkcnX_tWkJDQRw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">按F1分数排序的班级。</p></figure><p id="07b9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">绘制F1分数如何变化的图表也可以让我们了解这个问题的规模。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ob"><img src="../Images/8696ea1d228285ed07c8ec8272a24b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kNVD74uUFfVWBTxX-7JmQw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">500多个级别中每个级别的F1分数差异。</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oc"><img src="../Images/a5207f3016c7ffd0c7d0c4fecc386bb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VacoG79UEmYbMSznxudSmA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">8个最低得分等级的F1得分变化。</p></figure><p id="b381" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有趣的是，大约8个班级的F1分数急剧下降。让我们快速查看一个图像文件夹，以评估在训练分类器时哪些类型的图像可能会导致这些问题。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/f7b21efd639ab7eb011a57c1480bb5d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rl4A9xYg3OwaWLL7Wm1CcA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Peperomia peltifolia班级的最后60幅图像样本，该班级是F1分数最差的班级之一。</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oe"><img src="../Images/6ef4ffe312d94d5a31a6aa903344a0b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YtYJeHXtikgDfQC9lMLvkA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来自Iris domestica班级(F1分数最高的班级)的最后60幅图像的样本。</p></figure><p id="ff18" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">本质上，我们寻找的是与我们想象的用户用来识别特定植物的图像类型有显著差异的图像。在<em class="me"> Peperomia peltifolia </em>文件夹中的图像中散布着许多带有人工成分的图像(文本和/或图纸)以及许多分类错误或不相关的图像(科学图纸、种子样本)。这是由于谷歌图片搜索结果的相关性下降，因为越来越多的图片是从一个单一的查询中收集的。自然拥有更多可用搜索结果的类别较少受到这种趋势的影响(见<em class="me"> Iris domestica </em>图片)。</p><p id="9d12" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基于这一调查，我们可以得出两点结论:</p><ol class=""><li id="733f" class="na nb iq lh b li lj ll lm lo of ls og lw oh ma nh ni nj nk bi translated"><strong class="lh ja">错误分类的图像是最大损失的来源。这并不令人惊讶，需要进一步关注。每个班级的F1分数稍后会给我们一个好主意，让我们知道该看哪些文件夹。</strong></li><li id="0be1" class="na nb iq lh b li nl ll nm lo nn ls no lw np ma nh ni nj nk bi translated"><strong class="lh ja">人工图像是不好的训练样本，应该过滤掉。</strong>这些种类的图像与我们想象的用户用来识别给定植物的图像种类有本质上的不同。</li></ol><p id="7226" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们首先尝试用一些自动化过程来解决第二个问题。</p><h1 id="26dd" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">2.使用光学字符识别进行过滤</h1><p id="8c56" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">第一步过滤将使用光学字符识别(OCR)来尝试在我们的每个文档中查找文本。考虑到最有可能出现的文本与图像所呈现的植物名称有关，文本可能会出现某种形式的数据泄漏。除此之外，在我们想象的用例中(从自然图片中识别植物)，文本不太可能出现在任何图像中。</p><p id="b98d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Tesseract是OCR可用的开源软件，易于实现。在这里，我们使用它们的<code class="fe nt nu nv nw b">image_to_string</code>功能来检查用枕头打开后的图像。因为我们稍后需要查看整个图像文件夹，所以我们添加了一个简单的子句，告诉函数在返回找到的文本(如果有的话)之前，是否需要使用Pillow来打开图像。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nx ny l"/></div></figure><blockquote class="mb mc md"><p id="5f8b" class="lf lg me lh b li lj ka lk ll lm kd ln mf lp lq lr mg lt lu lv mh lx ly lz ma ij bi translated">在配置Tesseract时，PSM会参考页面分割模式，该模式会影响Tesseract如何将图像分割成文本和文字行。我们在这里使用全自动分段(- psm 3)和默认的OCR引擎模式(- oem 3)。</p></blockquote><p id="693d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于许多图像沿框架的顶部或底部边缘包含一些文本，我们希望能够裁剪图像并重新检查文本是否仍然存在，从而使我们能够保留尽可能多的图像。如果失败，我们将简单地从数据集中删除图像(从而删除坏的训练示例)。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nx ny l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">按图像总大小的给定百分比裁剪图像的顶部和底部。</p></figure><p id="8c96" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，我们将<code class="fe nt nu nv nw b">optical_character_recognition</code>和<code class="fe nt nu nv nw b">crop_image</code>函数合并成一个函数，我们可以用它来遍历一个图像文件夹来搜索文本，并有选择地尝试裁剪(这里是10%)图像的顶部和底部，看看这是否会删除文本，如果成功，则替换图像。因此，我们可以直接编辑和保留任何图像，只需少量的裁剪就可以轻松修复。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/195da777a73802e8455a7030a1d91640.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ao_kRlyoQhpCnDpnbbV-4w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用PyTesseract OCR在Peperomia Peltifolia文件夹上找到的示例图像和相关文本。这些图像可以被过滤掉，以改善我们的分类器的结果。</p></figure><p id="f2d6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这一阶段，我们将OCR过程的结果保存到数据帧中，供以后检查和处理。这样做是因为虽然过滤器捕捉到的许多图像可以被过滤掉而没有太大的后果，但是由于树叶、树枝和/或空白的排列，有大量完全没有文本的图像呈现为假阳性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oj"><img src="../Images/788047f9f46304499c9250991baba884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CBv1Scfa5xa5UgLAiRiMGw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">真阳性、假阳性和可裁剪图像的例子。</p></figure><p id="71fe" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">不幸的是，使用OCR检查图像没有考虑到图像在其他方面是人工的，这导致我们分析色调分布。</p><h1 id="eb3f" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">3.使用色调分布过滤</h1><p id="3785" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">每幅图像都由许多色调组成，这些色调可以在一系列色调和亮度之间变化。我们可以利用这一点来创建关于每个图像色调分布的量化指标，并尝试识别图像之间不利于训练分类器的任何共性。</p><p id="bd64" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">首先，让我们来看看神经网络将如何“看到”我们的图像。我们可以用PIL展开一幅图像，并把它转换成张量。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/a5ccd40f2374fc9da9f327e1c7b2c1ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qQsg-G3qHa9x3eI0gLuNeA.png"/></div></figure><p id="10f8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这表明每个图像只是一个单一的张量，有三个通道——红色、蓝色和绿色，按此顺序存储。我们可以分离出一个通道，并通过将其转换为彩色数据帧来进一步观察:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/70fe7a61b964431ffea98ef26a0936e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*xa7sWv4vzrNGB7XLXk4G-w.png"/></div></figure><p id="06c1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">沿着这一思路思考，我们可以识别出具有大块颜色且变化很小的图像，就像通常在具有人工创建的元素(如文本或图画)的图像中看到的那样。让我们通过获取图像中每个像素的色调和亮度(从转换到HLS)并绘制z轴作为给定(色调和亮度)对中存在的像素总数来准备一些图像统计图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oe"><img src="../Images/82ab9f2091c57872ffa3b554bc50014a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gz5I3pOqop8eJfbeqvEAUg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://gist.github.com/kenichinakanishi/4327cff12ddc51f44903c07f384ce8d0" rel="noopener ugc nofollow" target="_blank">从像素HSL值生成图像直方图的代码。</a></p></figure><p id="0bca" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用上面的<code class="fe nt nu nv nw b">image_histogram</code>函数，我们可以检查每张图像的色调分布，并沿着每张原始图像绘制出来。直方图显示了具有给定色调/亮度对的每个像素的数量。例如，在下图中，我们可以看到直方图中最密集的像素是较浅的绿色和黄色，这在真实图像中得到了很好的反映。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/e95409e3aac14d70a71e8c771514ad0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jv-fWbYTCuuHrm3gL_w1HQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">色调和亮度值均匀分布的自然照片。</p></figure><p id="0c53" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">总的来说，我们看到自然的照片在像素与像素之间的色调和亮度上会有细微的抖动，这些抖动被捕捉并编码到图像中。这导致色调-明度群体更加平坦且分布更加均匀，具有相对较大数量的色调-明度配对(大约2万到3万)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/8a97dded087fb07cd3f30da5f6de75a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y-17O8EqeU7J09uaJxYiiQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">即使在拥有人工增白背景的自然图像中，色调-明度群体也是均匀分布的。</p></figure><p id="bbad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">尽管这些图像看起来主要是绿色，但自然照片中细微的颜色变化会阻止任何特定的颜色阴影代表太大比例的像素。在上面的图像中，1000个最密集(最强烈)的色调-亮度配对代表不到40%的图像，即使在具有人工增白背景的图像中也是如此。</p><p id="8722" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">另一方面，当用颜色填充一个区域时，具有计算机生成元素的图像特别挑选出色调-明度对，导致给定色调-明度对的人为高群体密度。此外，人工图像可能只包含1000个独特的色调-亮度配对，与自然图像中常见的2万到3万个相差甚远。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oo"><img src="../Images/d97d25ac94ae33737ff52424d54ebe6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AOAVdinCueA32D54KOMQ5g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">一个人工图像，即使有一个梯度，将拥有相当少的变化，色调和亮度。</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/f3fbeafdb40f62ed5e0c0691ba5958d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wlINDuzjYpiI8ZS6TneU-Q.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">绘画也一样，在色调和亮度上显示较少的变化。</p></figure><p id="7b13" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><code class="fe nt nu nv nw b">image_histogram</code>函数还计算一些简单的度量，我们可以使用这些度量稍后将图像标记为人工的(用于检查和稍后的移除)。也就是说，我们计算存在的色调-明度配对的数量，取一些(<code class="fe nt nu nv nw b">color_width</code>)最多的配对，并计算它们所代表的图像的比例。从上面可以看出，那些具有人工成分的图像将有较大比例的图像由相对较少的色调/亮度对组成。让我们利用这一特性将图像标记为具有人工颜色分布！</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="5213" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里的关键参数是<code class="fe nt nu nv nw b">color_width</code>和<code class="fe nt nu nv nw b">threshold</code>。如果给定的数量(<code class="fe nt nu nv nw b">color_width</code>)最密集的色调/亮度配对代表整个图像的超过<code class="fe nt nu nv nw b">threshold</code>的比例，我们将该图像标记为在由该函数返回的数据帧中具有人工颜色分布。基于我们数据集的经验实验，我们使用1000对和70%的阈值来检测人工图像，但这些值将根据您正在处理的图像类型而变化。</p><h1 id="1570" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">4.自动化图像清理</h1><h2 id="c9b4" class="op mj iq bd mk oq or dn mo os ot dp ms lo ou ov mu ls ow ox mw lw oy oz my iw bi translated">4.1.标记图像</h2><p id="84ed" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">现在我们有了一些有用的指标(文本的存在和色调分布)，可以用来判断一幅图像是否是人工的。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nx ny l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">结合OCR和色调分布分析来标记人工图像。</p></figure><p id="27c6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">该功能旨在做两件事:</p><p id="6e5f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">如果没有检测到文本:</strong>如果给定数量(<code class="fe nt nu nv nw b">color_width</code>)最密集的色调/亮度配对代表整个图像的超过<code class="fe nt nu nv nw b">threshold</code>比例，即具有过浅的色调分布，则将图像标记为具有人为色调分布。这里我们用的是<code class="fe nt nu nv nw b">color_width</code> =1000对和一个70% <code class="fe nt nu nv nw b">threshold</code>。</p><p id="9cc6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">如果检测到文本:</strong>如前所述，仅使用OCR来识别不良训练样本的主要问题是经常出现误报。为了过滤掉这些，我们使用<code class="fe nt nu nv nw b">find_artifical_colors</code>函数来准备一个数据帧，该数据帧包含由所有图像的<code class="fe nt nu nv nw b">color_width</code>最密集的色调/亮度对所表示的像素比例(通过将<code class="fe nt nu nv nw b">return_all</code>设置为真)。然后我们运行<code class="fe nt nu nv nw b">find_artifical_text</code>并将结果内部连接到一个包含颜色比例数据的数据帧中。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pa"><img src="../Images/c526740a2fa55f03e6b294c65ebfc778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vQ7AcN_trQllCrx9-Ly0wA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">内联<code class="fe nt nu nv nw b">find_artifical_colors and find_artifical_text.</code>输出的结果</p></figure><p id="1c77" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这使我们能够根据颜色比例对这些图像进行阈值处理，与那些没有文本的图像处于不同的级别。直观上，与添加了文本的图像(通常具有单一字体颜色)相比，错误检测到文本的图像将具有明显更分散的色调分布。在经验实验之后，我们得出一个50%的阈值水平，这个水平可以很好地从我们的<code class="fe nt nu nv nw b">find_artifical_text</code>函数中去除任何假阳性。然后，假设检测到文本，在图像被标记为人工之前，我们需要一个较低的50%的<code class="fe nt nu nv nw b">text_threshold</code>。这允许自然图像逃脱标记，同时仍然捕获大多数具有文本的图像。这里使用的<code class="fe nt nu nv nw b">text_threshold</code>将决定我们在试图剔除误报时有多积极。</p><p id="dbb8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">以下是(a)来自OCR的不再被过滤掉的假阳性，和(b)真阳性的例子，都来自于<em class="me"> Zephyranthes drummondii </em>图像的文件夹。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/daa5a29f9a2a74a75739365f2747df69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HFHTBImn1tuW0-uhesVr6w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">西风东渐的光学字符识别结果。(A)错误地检测到字母T的假阳性。(b)真正的阳性。</p></figure><h2 id="c47b" class="op mj iq bd mk oq or dn mo os ot dp ms lo ou ov mu ls ow ox mw lw oy oz my iw bi translated">4.2.删除图像</h2><p id="4969" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">现在我们已经选择了图像标记的参数，我们可以遍历每个文件夹，找到人造图像并使用<code class="fe nt nu nv nw b">Path.unlink()</code>删除它们。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h1 id="54fc" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">4.用自动清理的数据集训练我们的分类器</h1><p id="ff55" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">现在，我们可以使用本系列第2部分中准备的学习器将我们的新数据集与原始数据集进行比较:<a class="ae le" rel="noopener" target="_blank" href="/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6">可控随机性训练</a>。在使用导入并使用所讨论的代码创建学习器之后，我们可以比较训练的结果，同时保持来自训练/验证、图像增强和批处理的随机性不变。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pc"><img src="../Images/50cbecef56e935235704d6d12cec88b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l79KQE49mfDZkCkMkpM4kw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用不同数量的图像比较训练的准确性。</p></figure><p id="4ebc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这里，我们看到这里详细描述的自动图像清理过程已经从数据集中移除了6000多幅图像，将前5名的精度从0.809提高到0.819。这表明我们确实(大体上)移除了作为每个类的差训练样本的图像。但是，结果仍然比简单地使用数据集中的前50或100幅图像要差！</p><p id="6186" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">检查F1分数在所有班级的分布揭示了一些有趣的事情。虽然F1分数总体上有所提高，但F1分数最低的班级实际上表现不如以前。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pd"><img src="../Images/cb65fd38cd9a01a8e09c5d084cee60e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-OAFIqwPQXFMCbEWc_caKA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">比较所有班级F1分数的变化。</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pe"><img src="../Images/c00e4ca110177e130afef9dd6217ff4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TfxgSyUyY78bmDh435xEhw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">在自动清理不良训练示例后F1分数最低的类。请注意，Peperomia peltifolia的F1得分已经下降到0，而它以前是0.06。</p></figure><p id="d7fc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们仔细看看<em class="me"> Peperomia peltifolia </em>文件夹，弄清楚到底是怎么回事。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oe"><img src="../Images/7a17a795ebb567934dd87fa414ff0394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QrzXWm_LMxVJZTCgEfu2pA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">自动清理后Peperomia peltifolia类的最后55幅图像的样本。大多数人工/差的图像已经被自动去除，而许多错误分类的图像仍然存在。</p></figure><p id="a691" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">看起来清理过程进行得相对较好，大多数图像是人为的/不良的训练样本，已经从文件夹中删除。然而，该过程不能识别和移除任何错误分类的图像。这导致该类别的F1分数总体降低，因为被移除的图像实际上具有许多相似性，而许多剩余的图像被错误分类并且具有很少或没有相似性。</p><p id="c41b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这一点上，提高我们的准确性的最好方法是通过一点点手动清理来专注于移除这些错误分类的图像。</p><h1 id="1012" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">5.手动清理和训练结果</h1><p id="c6b4" class="pw-post-body-paragraph lf lg iq lh b li nc ka lk ll nd kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">我们不想为了删除分类错误的图片而查看每个文件夹。解决这个问题的更有效的方法是将我们的努力集中在问题最多的班级上。正如我们在这篇文章的第一部分所探讨的那样(用fast.ai 进行<a class="ae le" href="https://medium.com/p/8ccdac5e7cc3#207f" rel="noopener">分类解释)，我们可以通过查看总体最高损失以及F1分数最低的类别来做到这一点。通过打开这些文件夹并删除我们认为是错误分类或较差训练样本的图像，我们可以快速提高分类器的性能。</a></p><p id="1e5c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我已经使用这种方法执行了许多手动清理步骤，然后每次都将这些数据集输入到相同的训练过程中，以查看我们的分类器如何改进。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oe"><img src="../Images/c2d1d6e7189189ebd4bb8982f994ad6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r9U5RhSKTbpDif1nrcOuow.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">经过几个手动清洗步骤后，分类准确度有所提高。</p></figure><p id="86cf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">正如我们所看到的，每次我们删除几百张图像时，我们的分类器的性能都会显著提高，尽管每次只删除总数据集的0.5%左右。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pf"><img src="../Images/7583bd38982ed11a5cb87da2d0c01747.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*51djwNU9kxvExsqyc8ftHw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">经过多轮手动图像清理后F1分数的最终分布。</p></figure><p id="a1fb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">检查F1分数的分布表明，F1分数总体上有所提高，同样，分布末端的几个班级除外。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pg"><img src="../Images/a2d965b54bb3e8b640698015b8424547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y8n_dpfpUqyjp3d3N6R1wg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">然而，一些班级的F1分数仍然很低。</p></figure><p id="be2e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这些分类是最难分类的，因为它们通常指的是更高的分类(<em class="me">龙血树</em>对<em class="me">香龙血树</em>)或非常具体的物种(<em class="me">盾叶胡椒树</em>对<em class="me">胡椒树</em>)。我们可以寻求改善这些类的性能的一种方法是出去专门为每个类收集高质量的训练图像，以使网络更容易区分相似的物种。目前，这不会影响我们对给定植物物种的毒性进行分类的目标，所以我们现在不会太担心它。</p><div class="kp kq kr ks gt ab cb"><figure class="ph kt pi pj pk pl pm paragraph-image"><img src="../Images/4ec80c63954eec16ad4d08f632ec662d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*W2rpoCYOqI1NHvvqrJHFPw.png"/></figure><figure class="ph kt pn pj pk pl pm paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/729da6b0145ec183e9ccf5ef993a3e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*4CJL4eXVjAJMq_AfgqKPmA.png"/></div></figure></div><p id="064e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">太好了！我们使用基线架构(ResNet34)通过自动(使用OCR和色调分布分析)和指导手动方式清理数据集，改善了训练结果。</p><p id="8e51" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">接下来，我们将使用这个精炼的数据集，并基于我们在<a class="ae le" rel="noopener" target="_blank" href="/creating-a-plant-pet-toxicity-classifier-13b8ba6289e6">第2部分:受控随机性训练</a>中创建的学习者。请尽快加入我的<a class="ae le" href="https://kenichinakanishi.medium.com/exploring-convolutional-neural-network-architectures-with-fast-ai-de4757eeeebf" rel="noopener">第4部分:探索fast.ai中的卷积神经网络架构</a>，我们将比较网络架构变化的原因、方式和影响。</p></div></div>    
</body>
</html>