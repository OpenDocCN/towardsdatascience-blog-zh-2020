<html>
<head>
<title>Machine Learning in Production</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生产中的机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-in-production-79e02a43b273?source=collection_archive---------55-----------------------#2020-09-30">https://towardsdatascience.com/machine-learning-in-production-79e02a43b273?source=collection_archive---------55-----------------------#2020-09-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8813" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">从生产分类模型中学到的有用技巧</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/e8c02a9ff0e0eb29ef12d0114d0f8dcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8pzwSmy1BINV7HMOVbgolg.jpeg"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">照片由<a class="ae kw" href="https://unsplash.com/@wthen?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Wojciech然后</a>在<a class="ae kw" href="https://unsplash.com/s/photos/adventure?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="b03a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在生产中，风险很高。人们将会阅读模型的输出。输出更有意义。</p><p id="27e3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">最近，我和我的团队创建了一个NLP分类器，并在一个大型保险数据集上投入使用。它使用TfidfVectorizer和LinearSVC对自由文本进行分类。</p><p id="cd18" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">但我很快意识到，把东西投入生产与理论是如此不同。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/a212b6bac7c2ca95d8fe2d756c8074a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*p0lyLffPmZwoGtO4.jpg"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">图片由<a class="ae kw" href="https://www.flprobatelitigation.com/about/" rel="noopener ugc nofollow" target="_blank"> Juan C. Antúnez </a>在<a class="ae kw" href="https://www.flprobatelitigation.com/2013/11/articles/white-papers-rpptl-comm/why-fiduciary-law-is-equitable/" rel="noopener ugc nofollow" target="_blank"> flprobatelitigation </a>上拍摄</p></figure><p id="41cb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我认为，在生产中，获得模型预测的概率非常重要。例如，如果您的模型以50%的概率对某件事情进行分类，那么应该有人对该预测进行调查。如果他们发现一个错误，你阻止了模型破坏公司的一个关键系统。</p><p id="bc79" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">但是获得一个预测的概率并不总是那么简单。</p><p id="0c0c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在本文中，我将介绍一种从scikit-learn的SVM分类器中提取概率的方法。</p><p id="7dbb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这对于将我们的模型投入生产至关重要。</p><h1 id="12e2" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">概率校准</h1><p id="c111" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">我们不仅想要预测的类别标签，还想要预测的概率。Scikit-learn在他们的文档中有一个关于这个主题的有趣章节。</p><p id="eca2" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们需要创建一个回归器(或校准器)，将分类器的输出映射到一个介于<code class="fe mr ms mt mu b">0</code>和<code class="fe mr ms mt mu b">1</code>之间的值。这个校准器会给我们每次预测的概率。</p><p id="95a7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">本质上，校准器将试图预测:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/eac2e9bbb53fe31b2a0a8af7b789316f.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/0*FlnTQSXzuqnSeJF4.png"/></div></figure><p id="a756" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">其中<code class="fe mr ms mt mu b">f</code>是分类器的输出。</p><p id="232a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">或者更直白地说:给定我们的分类器的输出，我们对这个输出100%确定的概率是多少？</p><p id="36e5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">约翰·普拉特的这篇<a class="ae kw" href="https://www.researchgate.net/publication/2594015_Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods" rel="noopener ugc nofollow" target="_blank">论文</a>指出，sigmoid函数可以用作回归变量。我们得到以下结果:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/a7b813c761f46ccf6eab2b51d156d7ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/0*z9kWyftswD2ax5By.png"/></div></figure><p id="472d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为了找到A和B，我们可以使用<a class="ae kw" href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation" rel="noopener ugc nofollow" target="_blank">最大似然估计</a>。这将涉及最小化负对数可能性:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi mx"><img src="../Images/95ea88226d0ed992835efb2f4d129fce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SdgXkM_POuh37pJj.png"/></div></div></figure><p id="80a7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">其中<code class="fe mr ms mt mu b">ti</code>是目标概率。</p><h1 id="9191" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">给我看看代码</h1><p id="144c" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">代码非常简单。Scikit-learn隐藏了抽象层背后的大部分复杂性。</p><p id="2bea" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">你需要做的就是这个:</p><pre class="kh ki kj kk gt my mu mz na aw nb bi"><span id="b27c" class="nc lv iq mu b gy nd ne l nf ng"># from: https://stackoverflow.com/questions/26478000/converting-linearsvcs-decision-function-to-probabilities-scikit-learn-python</span><span id="4d48" class="nc lv iq mu b gy nh ne l nf ng">svm = LinearSVC()<br/>clf = CalibratedClassifierCV(svm) <br/>clf.fit(X_train, y_train)</span></pre><p id="297f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">CalibratedClassifierCV将使用k重交叉验证方法来拟合训练数据。默认值为5倍。点击查看更多信息<a class="ae kw" href="https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="c980" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">然后，我们将提取所有k倍预测类的平均概率。<code class="fe mr ms mt mu b">predict_proba</code>是我们这里需要的函数。虽然函数本身看起来像一个未完成的句子，但它非常有用。</p><pre class="kh ki kj kk gt my mu mz na aw nb bi"><span id="d2e7" class="nc lv iq mu b gy nd ne l nf ng">y_proba = clf.predict_proba(X_test)</span></pre><p id="73c2" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">要得到预测的类，我们可以简单地使用预测函数。</p><pre class="kh ki kj kk gt my mu mz na aw nb bi"><span id="bd44" class="nc lv iq mu b gy nd ne l nf ng">clf.predict(X_test)</span></pre><h1 id="5996" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">评估校准品</h1><p id="e90b" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">校准器与数据的吻合程度如何？我们怎么知道？</p><p id="bf14" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为此，我们可以使用<code class="fe mr ms mt mu b">sklearn.metrics.brier_score_loss</code>。更多信息可在<a class="ae kw" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="7f90" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果这个分数非常高，那么我们就不能查看校准器的概率输出——它们是无用的。相反，我们需要寻找更好的方法来安装校准器。这篇<a class="ae kw" href="https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/" rel="noopener ugc nofollow" target="_blank">文章</a>提供了一些安装校准器的好方法。</p><h1 id="034e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">结束</h1><p id="887a" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">真的就是这样！</p><p id="2958" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我相信，随着我们继续保持这种模式，我会有更多的内容要添加。我想分享这个帮助我们有效地将模型投入生产的小技巧。希望有人会觉得它有用。</p><p id="3598" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果我犯了一个错误，或者你有兴趣寻求帮助，请随时通过推特<a class="ae kw" href="https://twitter.com/neeliyer11" rel="noopener ugc nofollow" target="_blank">联系我。</a></p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><p id="19c0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><em class="np">原载于2020年9月30日</em><a class="ae kw" href="https://spiyer99.github.io/Production-vs-Theory/" rel="noopener ugc nofollow" target="_blank"><em class="np">https://spiyer 99 . github . io</em></a><em class="np">。</em></p></div></div>    
</body>
</html>