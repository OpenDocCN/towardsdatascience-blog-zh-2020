<html>
<head>
<title>Predicting Customer Churn in the Telecommunications Industry</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测电信行业的客户流失</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-customer-churn-in-the-telecommunications-industry-99a369317e91?source=collection_archive---------21-----------------------#2020-10-11">https://towardsdatascience.com/predicting-customer-churn-in-the-telecommunications-industry-99a369317e91?source=collection_archive---------21-----------------------#2020-10-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8b91" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用特征重要性通过降维来简化问题，并为不平衡分类移动阈值。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6da3977c88b15d526601626dc584eb22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VlvA7l3_kCpKj_1CD7OIgw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">授权Leo Siu-Yin通过Shutterstock获取图像</em></p></figure><p id="7a46" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">为什么要预测客户流失？</strong></p><p id="97b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">获得新客户比留住现有客户要昂贵得多。一些研究表明，获得一个新客户的成本是保持一个现有客户的六到七倍。</p><p id="9dc9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">据<em class="ls"> BeyondPhilosophy.com: </em></p><p id="fc10" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">忠诚的客户会降低与消费者教育和营销相关的成本，尤其是当他们成为你组织的净推广者时</p><p id="5339" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，能够主动确定最有可能离开的客户并通过了解他们的需求和提供积极的客户体验来采取预防措施非常重要。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lu"><img src="../Images/2383f348a5dfbc55a13d55ebe2b9f640.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VdX5j78_1GWCWQoxgSITtA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae lt" href="https://unsplash.com/@sharonmccutcheon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Sharon McCutcheon </a>在<a class="ae lt" href="https://unsplash.com/s/photos/family-in-pandemic?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="cd8a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">方法论</strong></p><p id="3b73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该项目分为3个阶段:</p><ol class=""><li id="b52e" class="lv lw iq ky b kz la lc ld lf lx lj ly ln lz lr ma mb mc md bi translated">数据清理和探索性数据分析。</li><li id="731d" class="lv lw iq ky b kz me lc mf lf mg lj mh ln mi lr ma mb mc md bi translated">模型选择和阈值调整。</li><li id="db20" class="lv lw iq ky b kz me lc mf lf mg lj mh ln mi lr ma mb mc md bi translated">结果解释。</li></ol><p id="88b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">数据清理和探索性数据分析</strong></p><p id="e389" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据来自Kaggle，IBM数据集。数据集有些不平衡，流失率为26.5%。</p><p id="7786" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先检查数据的唯一客户ID。空格被替换为0，列在适用时被更改为数字类型。</p><p id="824b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">进行EDA是为了理解数据。像性别这样的特征对流失影响不大，会被去掉。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/3483d748a46b3869feacf18f28811bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*5VK679BNDQ65PPvE6KhSew.png"/></div></figure><p id="8131" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用热图绘制要素间的相关性，并丢弃彼此高度相关的要素(如下所示，相关性&gt; 0.6)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/2ede618dfb63e7796322bccbe3062398.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ekY_fl1pKtNTyXAAACD2-A.png"/></div></div></figure><p id="67cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后对分类特征进行一次热编码。并且通过使用算法的特征重要性属性的随机森林分类来选择前11个特征。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/5633f1b8f679a28fda68251038134a75.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*LfcGINVE9sDND2BT6J2eMg.png"/></div></figure><p id="9742" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">减少输入要素的数量将简化正在建模的问题并加快建模过程。</p><p id="61ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">模型选择和阈值调整</strong></p><p id="925e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用四种模型对最终数据进行建模:逻辑回归、C-支持向量分类、K近邻分类器和随机森林分类器。</p><p id="3092" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GridSearchCV用于调整超参数，并为每个模型找到最佳超参数。</p><p id="cac1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于阈值0.5的1类分类，发现逻辑回归模型具有最高的ROC-AUC得分、最低的对数损失、最高的F1得分和最高的回忆得分。因此，选择逻辑回归模型作为最终模型来进一步微调阈值，以提高我们数据的召回分数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/01521d0ab821d57e8c489ab31feb27ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*HBKcdraIgz4DlHQYzu6ixw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">ROC-AUC评分</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/6444a1a3c0774dcac946eadf208a0380.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*mkp_YzQ3hYplFI0ZgAiVEQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">原木损失</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/2fc734f0ef291a882795b58cd95fe930.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*ewHooGBaLAepf731jhawJA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">F1分数</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/1a434db0a415cbc0ed5e3b3e97ecbda1.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*jd3mBg_N5YP5IWfBuCLaNg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">精确</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/513f576189daa8bb8d1769ddbc2c905e.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*yJDG2vdFBj64r293FY4zcg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">回忆</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/41055575f3a1a39697b6b29a6be2f5cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*wb8xbxF9w4TndsXXvJFbJA.png"/></div></figure><p id="dd56" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">精度</strong>是相关实例在检索到的实例中所占的比例，<strong class="ky ir">召回</strong>(也称为<a class="ae lt" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="noopener ugc nofollow" target="_blank">敏感度</a>)是实际检索到的相关实例总数的比例。</p><p id="a9fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在预测客户流失时，较高的召回率优于较高的精确度，因为能够预测哪些客户流失的风险较高是最理想的。然而，调整阈值以获得更高的召回率是以降低精确度为代价的。因此，需要实现平衡。在这个项目中，我选择使用F1分数作为衡量标准来选择我的阈值。</p><p id="f511" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分类算法的工作原理是在概率被映射到类别标签之前预测概率。这是通过使用诸如0.5的阈值来实现的，其中等于或大于阈值的所有值被映射到一个类，而所有其他值被映射到另一个类。</p><p id="d1ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于数据具有类别不平衡，默认阈值会导致较差的分类。因此，调整用于将概率映射到分类标签的阈值非常重要。</p><p id="4403" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在默认阈值为0.5时，逻辑回归模型给出的F1值为0.58。基于0.62的最大F1分数，阈值结果是0.36。这个新的阈值将回忆分数从0.55提高到0.78。</p><p id="54be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">结果解读</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/137f604c92fbcf2a374421b40adcbaae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*00D0sLAOdTXW2NxGqxIV0Q.png"/></div></figure><p id="b5c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于逻辑回归模型，电信公司可以专注于前两项功能，并通过以下方式减少客户流失:</p><ol class=""><li id="2259" class="lv lw iq ky b kz la lc ld lf lx lj ly ln lz lr ma mb mc md bi translated">与客户签订长期合同。</li><li id="52fa" class="lv lw iq ky b kz me lc mf lf mg lj mh ln mi lr ma mb mc md bi translated">提高客户的在线安全性。</li></ol><p id="261d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里有一个<a class="ae lt" href="https://github.com/syleo22/SiuYin_Projects/tree/master/Project03" rel="noopener ugc nofollow" target="_blank">链接</a>到我的GitHub，你可以在那里找到我的代码和演示幻灯片。也可以通过<a class="ae lt" href="https://www.linkedin.com/in/syleo/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p></div></div>    
</body>
</html>