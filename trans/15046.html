<html>
<head>
<title>How to use gRPC API to Serve a Deep Learning Model?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用gRPC API服务一个深度学习模型？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/serving-deep-learning-model-in-production-using-fast-and-efficient-grpc-6dfe94bf9234?source=collection_archive---------18-----------------------#2020-10-16">https://towardsdatascience.com/serving-deep-learning-model-in-production-using-fast-and-efficient-grpc-6dfe94bf9234?source=collection_archive---------18-----------------------#2020-10-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6a21" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解什么是gRPC以及如何使用gRPC API服务深度学习模型的快速简单指南。</h2></div><p id="23e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">在本帖中，你将学习什么是gRPC，它是如何工作的，gRPC的好处，gRPC和REST API的区别，最后用Tensorflow Serving实现gRPC API来服务生产中的一个模型？</em>T3】</strong></p><p id="23b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> gRPC是Google开发的远程过程调用平台。</strong></p><blockquote class="lf"><p id="ff62" class="lg lh it bd li lj lk ll lm ln lo ld dk translated">GRPC是一个现代的开源、高性能、低延迟和高速吞吐量的RPC框架，它使用HTTP/2作为传输协议，使用协议缓冲区作为接口定义语言(IDL)以及它的底层消息交换格式</p></blockquote><h2 id="6abd" class="lp lq it bd lr ls lt dn lu lv lw dp lx kr ly lz ma kv mb mc md kz me mf mg mh bi translated"><strong class="ak"><em class="mi">gRPC是如何工作的？</em>T9】</strong></h2><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/b466246ca2e525b9c6f8c8dc2f218cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*Zjbd2vOlODNbtjyup-cY_Q.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">灵感来源:<a class="ae mv" href="https://www.grpc.io/docs/what-is-grpc/introduction/" rel="noopener ugc nofollow" target="_blank">https://www.grpc.io/docs/what-is-grpc/introduction/</a></p></figure><p id="f101" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建了一个<strong class="kk iu"> gRPC通道</strong>，该通道在指定的端口上提供到gRPC服务器的连接。<strong class="kk iu">客户端调用存根</strong>上的方法，就好像它是本地对象一样；<strong class="kk iu">服务器被通知客户端gRPC请求</strong>。gRPC使用 <strong class="kk iu">协议缓冲区在客户端和服务器</strong>之间交换消息。协议缓冲区是一种以高效、可扩展的格式对结构化数据进行编码的方式。</p><p id="8cd9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦<strong class="kk iu">服务器接收到客户端的请求，它就执行该方法，并将客户端的响应连同状态代码和可选元数据一起发回</strong>。gRPC允许客户端指定等待时间，以允许服务器在RPC调用终止之前做出响应。</p><h2 id="fbd3" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">使用gRPC有什么好处？</h2><ul class=""><li id="4d27" class="nb nc it kk b kl nd ko ne kr nf kv ng kz nh ld ni nj nk nl bi translated">gRPC使用二进制有效负载，这对于创建和解析是有效的，因此是轻量级的。</li><li id="fd25" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">双向流在gRPC中是可能的，但在REST API中却不是这样</li><li id="2383" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">gRPC API建立在HTTP/2之上，支持传统的请求和响应流以及双向流</li><li id="1c56" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated"><strong class="kk iu">消息传输速度比REST API快10倍</strong>，因为gRPC使用序列化协议缓冲区和HTTP/2</li><li id="1198" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated"><strong class="kk iu">客户机和服务器之间的松散耦合</strong>使得修改变得容易</li><li id="f454" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">gRPC允许<strong class="kk iu">集成用不同语言编程的API</strong></li></ul><h2 id="1f25" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">gRPC和REST API有什么区别？</h2><ul class=""><li id="ec9f" class="nb nc it kk b kl nd ko ne kr nf kv ng kz nh ld ni nj nk nl bi translated"><strong class="kk iu">有效载荷格式</strong> : REST使用JSON在客户端和服务器之间交换消息，而gRPC使用协议缓冲区。协议缓冲区比JSON压缩得更好，从而使gRPC更有效地通过网络传输数据。</li><li id="b2a9" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated"><strong class="kk iu">传输协议</strong> : REST大量使用HTTP 1.1协议，这是文本的，而gRPC是建立在新的HTTP/2二进制协议之上的，这种协议通过高效的解析来压缩报头，并且安全得多。</li><li id="1484" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated"><strong class="kk iu">流与请求-响应</strong> : <strong class="kk iu"> REST支持HTTP1.1中可用的请求-响应</strong>模型。<strong class="kk iu"> gRPC使用HTTP/2中可用的双向流</strong>功能，其中客户端和服务器使用读写流相互发送一系列消息。</li></ul><h2 id="a76f" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">深度学习模型如何用Python实现gRPC AI？</h2><h2 id="4625" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">使用TF服务为深度学习模型创建gRPC API的步骤</h2><ol class=""><li id="f3c9" class="nb nc it kk b kl nd ko ne kr nf kv ng kz nh ld nr nj nk nl bi translated">创建从客户端到服务器的请求负载作为协议缓冲区(。原型)文件。客户端通过存根调用API。</li><li id="da19" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld nr nj nk nl bi translated">运行docker映像，公开端口8500以接受gRPC请求并将响应发送回客户端</li><li id="fbda" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld nr nj nk nl bi translated">运行服务器和客户端。</li></ol><h2 id="a4fd" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">实现<strong class="ak"> <em class="mi"> gRPC API </em> </strong></h2><p id="b998" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">要使用Tensorflow服务实现REST API，请关注这个<a class="ae mv" rel="noopener" target="_blank" href="/deploying-a-tensorflow-model-to-production-made-easy-4736b2437103">博客</a>。</p><p id="5336" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于Windows 10，我们将使用TensorFlow服务图像。</p><h2 id="9c89" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">第一步:<a class="ae mv" href="https://docs.docker.com/docker-for-windows/install-windows-home/" rel="noopener ugc nofollow" target="_blank">安装Docker App </a></h2><h2 id="59e1" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">步骤2:提取TensorFlow服务图像</h2><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="abb8" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">docker pull tensorflow/serving</strong></span></pre><p id="e14b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦你有了张量流服务图像</p><ul class=""><li id="8fbf" class="nb nc it kk b kl km ko kp kr oe kv of kz og ld ni nj nk nl bi translated">为gRPC显示端口8500</li><li id="59b8" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">可选环境变量<code class="fe oh oi oj nw b"><strong class="kk iu">MODEL_NAME</strong></code>(默认为<code class="fe oh oi oj nw b">model</code>)</li><li id="53b7" class="nb nc it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">可选环境变量<code class="fe oh oi oj nw b"><strong class="kk iu">MODEL_BASE_PATH</strong></code>(默认为<code class="fe oh oi oj nw b">/models</code>)</li></ul><h2 id="8e2e" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">步骤3:创建并训练模型</h2><p id="6c9d" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">这里，我从张量流数据集中提取了MNIST数据集</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="458e" class="lp lq it nw b gy oa ob l oc od">#Importing required libraries<br/><strong class="nw iu">import os<br/>import json<br/>import tempfile<br/>import requests<br/>import numpy as np<br/>import tensorflow as tf<br/>import tensorflow_datasets as tfds</strong>#Loading MNIST train and test dataset<br/>#as_supervised=True, will return tuple instead of a dictionary for image and label<br/><strong class="nw iu">(ds_train, ds_test), ds_info = tfds.load("mnist", split=['train','test'], with_info=True, as_supervised=True)</strong>#to select the 'image' and 'label' using indexing coverting train and test dataset to a numpy array<br/><strong class="nw iu">array = np.vstack(tfds.as_numpy(ds_train))<br/>X_train = np.array(list(map(lambda x: x[0], array)))<br/>y_train = np.array(list(map(lambda x: x[1], array)))<br/>X_test = np.array(list(map(lambda x: x[0], array)))<br/>y_test = np.array(list(map(lambda x: x[1], array)))</strong>#setting batch_size and epochs<br/><strong class="nw iu">epoch=10<br/>batch_size=128</strong>#Creating input data pipeline for train and test dataset<br/># Function to normalize the images<strong class="nw iu">def normalize_image(image, label):<br/>  #Normalizes images from uint8` to float32<br/>  return tf.cast(image, tf.float32) / 255., label</strong># Input data pipeline for test dataset<br/>#Normalize the image using map function then cache and shuffle the #train dataset <br/># Create a batch of the training dataset and then prefecth for #overlapiing image preprocessing(producer) and model execution work #(consumer)<strong class="nw iu">ds_train = ds_train.map(<br/>    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)<br/>ds_train = ds_train.cache()<br/>ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)<br/>ds_train = ds_train.batch(batch_size)<br/>ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)</strong># Input data pipeline for test dataset (No need to shuffle the test #dataset)<br/><strong class="nw iu">ds_test = ds_test.map(<br/>    normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)<br/>ds_test = ds_test.batch(batch_size)<br/>ds_test = ds_test.cache()<br/>ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)</strong># Build the model<br/><strong class="nw iu">model = tf.keras.models.Sequential([<br/>  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),<br/>  tf.keras.layers.Dense(128,activation='relu'),<br/>  tf.keras.layers.Dense(196, activation='softmax')<br/>])</strong>#Compile the model<br/><strong class="nw iu">model.compile(<br/>    loss='sparse_categorical_crossentropy',<br/>    optimizer=tf.keras.optimizers.Adam(0.001),<br/>    metrics=['accuracy'],)</strong>#Fit the model<br/><strong class="nw iu">model.fit(<br/>    ds_train,<br/>    epochs=epoch,<br/>    validation_data=ds_test,<br/>    verbose=2)</strong></span></pre><h2 id="8950" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">步骤4:保存模型</h2><p id="9d06" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">通过将save_format指定为“tf”将模型保存到协议缓冲文件中。</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="92ab" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">MODEL_DIR='tf_model'<br/>version = "1"<br/>export_path = os.path.join(MODEL_DIR, str(version))</strong>#Save the model <br/><strong class="nw iu">model.save(export_path, save_format="tf")<br/>print('\nexport_path = {}'.format(export_path))<br/>!dir {export_path}</strong></span></pre><p id="e0d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以使用<strong class="kk iu"><em class="le">saved _ model _ CLI</em></strong>命令检查模型。</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="11f8" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">!saved_model_cli show --dir {export_path} --all</strong></span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/0aace65d985b383bdce69819604ec282.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*lsF286FxuXnU7EvQJr2JJw.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">对输入和输出及其数据类型和大小进行建模</p></figure><h2 id="0be0" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">步骤5:使用gRPC服务模型</h2><p id="fec1" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">为gRPC实施导入库</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="c1ab" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">import grpc<br/>from tensorflow_serving.apis import predict_pb2<br/>from tensorflow_serving.apis import prediction_service_pb2_grpc<br/>from tensorboard.compat.proto import types_pb2</strong></span></pre><p id="fa3b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用gRCP端口8500在客户端和服务器之间建立通道。为客户机创建客户机存根，以便与服务器通信</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="1c34" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">channel = grpc.insecure_channel('127.0.0.1:8500')</strong><br/><strong class="nw iu">stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)</strong></span></pre><p id="07c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过指定模型名称和模型输入、数据类型以及数据大小和形状，为服务器创建请求负载作为协议缓冲区。</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="89f5" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">request = predict_pb2.PredictRequest()<br/>request.model_spec.name = 'mnist'<br/>request.inputs['flatten_input'].CopyFrom(tf.make_tensor_proto(X_test[0],dtype=types_pb2.DT_FLOAT,  shape=[28,28,1]))</strong></span></pre><p id="e583" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果数据类型和数据大小与模型输入不匹配，您将得到错误“<strong class="kk iu">输入大小与签名</strong>不匹配”。</p><p id="a37b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">要解决此错误，请检查模型输入数据的类型和大小，并将其与发送给gRPC的请求进行匹配。</strong></p><p id="0b5a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">运行docker镜像，展示端口8500以接受gRPC请求</strong></p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="d4b2" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">docker run -p 8500:8500 --mount type=bind,source=C:\TF_serving\tf_model,target=/models/mnist/ -e MODEL_NAME=mnist -t tensorflow/serving</strong></span></pre><p id="8301" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">源应该是绝对路径。</p><p id="bbef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">服务器现在准备好接受客户端请求</p><p id="3639" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">为了预测请求的结果，从存根调用predict方法</strong></p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="138f" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">result=stub.Predict(request, 10.0)<br/>result</strong></span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/690c51f84fd3f860cbef36f0d3fbecff.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*9PYuF71qHa_KwR-CqycPXw.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">来自gRPC服务器的结果响应</p></figure><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="aab9" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">res=np.argmax(result.outputs['dense_1'].float_val)<br/>print(" predicted output :", res)</strong></span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi om"><img src="../Images/90d5709d7486d56f1767ca9c3784835f.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*RSBA7wdqLZNCni7JyY80sg.png"/></div></figure><p id="0ecf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用matplotlib显示输入图像</p><pre class="mk ml mm mn gt nv nw nx ny aw nz bi"><span id="3c29" class="lp lq it nw b gy oa ob l oc od"><strong class="nw iu">import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>img = X_test[0].reshape(28,28)<br/>plt.title(res)<br/>plt.imshow(img, cmap="gray")</strong></span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi on"><img src="../Images/3ad692c78b45ed091f805dea9e70de97.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*OEYZpK1P-wd1cvT63YrE7Q.png"/></div></figure><h2 id="cec5" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">结论:</h2><p id="d5f8" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">gRPC是Google新的远程过程调用API，比REST API快大约10倍。gRPC建立在HTTP/2之上，它使用协议缓冲区在客户机和服务器之间高效地交换双向消息。</p><h2 id="4601" class="lp lq it bd lr ls mw dn lu lv mx dp lx kr my lz ma kv mz mc md kz na mf mg mh bi translated">参考资料:</h2><p id="6148" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr ns kt ku kv nt kx ky kz nu lb lc ld im bi translated">【https://grpc.io/docs/what-is-grpc/core-concepts/ T4】</p></div></div>    
</body>
</html>