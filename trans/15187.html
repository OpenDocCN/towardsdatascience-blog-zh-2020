<html>
<head>
<title>Credit Card Customer Clustering with Autoencoder and K-means</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于自动编码器和K-means的信用卡客户聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/credit-card-customer-clustering-with-autoencoder-and-k-means-16654d54e64e?source=collection_archive---------17-----------------------#2020-10-19">https://towardsdatascience.com/credit-card-customer-clustering-with-autoencoder-and-k-means-16654d54e64e?source=collection_archive---------17-----------------------#2020-10-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="08c3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过改进模型进一步挖掘客户营销的商业智能</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c04c2f342f53a6a5601c0c6beb674d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4PSIrqhKSdqBSp1C.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自pixabay的Img通过<a class="ae ky" href="https://pixabay.com/photos/marketing-customer-polaroid-center-2483867/" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="8cdb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在之前的<a class="ae ky" rel="noopener" target="_blank" href="/stacked-auto-encoder-as-a-recommendation-system-for-movie-rating-prediction-33842386338">文章</a>中，我们为电影分级预测创建了一个堆栈式自动编码器模型。但正如我们所知，通过编码器部分，自动编码器模型也可以帮助进行特征提取。因此，在本文中，我们将继续使用自动编码器和k-means进行客户聚类。像往常一样，它被分成4个部分。</p><ol class=""><li id="00db" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">自动编码器简介</li><li id="3732" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">自动编码器建模</li><li id="c6e2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">k均值建模</li><li id="7c0c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">外卖食品</li></ol><p id="2d25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们开始旅程吧🏃‍♂️🏃‍♀️!</p><p id="0653" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1。自动编码器简介</strong></p><p id="f36b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自动编码器是一种人工神经网络，用于以无监督的方式学习特征表示。它使用相同的数据进行输入和输出。如图1所示，通过在网络中添加瓶颈，它迫使网络创建输入数据的压缩版本，这就是编码器的工作方式。同时，解码器将编码特征重构为其原始输入。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/d7e71b41a4e1987915f5cd1a14153ae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*z3I7djPVn_ulZpIofALgew.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1自动编码器模型结构(图片由作者提供)</p></figure><p id="15c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有不同类型的自动编码器模型。这里我们将创建一个堆栈式自动编码。在堆叠自动编码器模型中，编码器和解码器具有用于编码和解码的多个隐藏层，如图2所示</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/1751e3caff2b5cc40e5a7e03116367e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*SwVmnLznAjVauYSoGjtZbA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2堆叠式自动编码器模型结构(图片由作者提供)</p></figure><p id="d190" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。自动编码器建模</strong></p><p id="e843" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单介绍之后，让我们继续创建一个用于特征提取的自动编码器模型。</p><p id="4cc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2.1创建模型</strong></p><p id="7589" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用Keras来创建模型架构。具体来说，</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="5376" class="mq mr it mm b gy ms mt l mu mv">input_df = Input( shape = (17, ))<br/>x = Dense(7, activation = ‘relu’)(input_df)<br/>x = Dense(500, activation = ‘relu’, kernel_initializer=’glorot_uniform’)(x)<br/>x = Dense(500, activation = ‘relu’, kernel_initializer=’glorot_uniform’)(x)<br/>x = Dense(2000, activation = ‘relu’, kernel_initializer=’glorot_uniform’)(x)<br/>encoded = Dense(10, activation = ‘relu’, kernel_initializer=’glorot_uniform’)(x)</span><span id="664d" class="mq mr it mm b gy mw mt l mu mv">x = Dense(2000, activation = ‘relu’, kernel_initializer=’glorot_uniform’)(encoded)<br/>x = Dense(500, activation = ‘relu’, kernel_initializer=’glorot_uniform’)(x)<br/>decoded = Dense(17, kernel_initializer=’glorot_uniform’)(x)</span><span id="c0cd" class="mq mr it mm b gy mw mt l mu mv">autoencoder = Model(input_df, decoded)<br/>encoder = Model(input_df, encoded)<br/>autoencoder.compile(optimizer = ‘adam’, loss = ‘mean_squared_error’)</span></pre><p id="db01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对mention✨✨:来说有几分价值</p><ul class=""><li id="7cf3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu mx mb mc md bi translated">输入张量是一批17维向量，因为我们的数据有17个特征。</li><li id="4970" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu mx mb mc md bi translated">网络瓶颈的输出维度是10，因为我们的目标是将17个特征压缩到10个特征。</li><li id="8e53" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu mx mb mc md bi translated">网络的最终输出解码后的维数为17，与输入维数相同。</li><li id="2f52" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu mx mb mc md bi translated">Autoencoder模型将input_df作为输入，解码后作为输出。</li><li id="51e0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu mx mb mc md bi translated">编码器模型将<em class="my"> input_df </em>作为输入，将<em class="my">编码后的</em>作为输出。</li><li id="52ec" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu mx mb mc md bi translated">我们使用<strong class="lb iu"> glorot_uniform </strong>通过从均匀分布中抽取样本来初始化层权重。</li></ul><p id="f3ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2.2拟合&amp;提取</strong></p><p id="588f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建好模型后，让我们来拟合模型。注意，我们对模型输入和输出使用相同的数据！</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="ce7f" class="mq mr it mm b gy ms mt l mu mv">autoencoder.fit(creditcard_df_scaled, creditcard_df_scaled, batch_size= 120, epochs = 25, verbose = 1)</span></pre><p id="3c79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以使用编码器部分来提取特征表示。</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="7969" class="mq mr it mm b gy ms mt l mu mv">pred = encoder.predict(creditcard_df_scaled)</span></pre><p id="fff5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。k均值建模</strong></p><p id="0e92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3.1找K </strong></p><p id="1b88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">k-means的第一步是挑选聚类数。我们将使用肘法。为了实现它，我们对不同数量的聚类应用k-means。具体来说，</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="315d" class="mq mr it mm b gy ms mt l mu mv">score_2 = []<br/>range_values = range(1, 20)<br/>for i in range_values:<br/>    kmeans = KMeans(n_clusters = i)<br/>    kmeans.fit(pred)<br/>    score_2.append(kmeans.inertia_)</span></pre><p id="f771" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您还记得在之前的<a class="ae ky" href="https://medium.com/@vistaxjtu/credit-card-customer-clustering-with-k-means-b9ec023a7d6e" rel="noopener">文章</a>中，我们也应用了肘方法，但是使用了原始的特性。图3比较了原始数据集和编码数据集的WCSS变化。我们发现最佳的K是4。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/9a7d6bfa17c740882e9b5dae55414d1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*CCt-k5Xykxr67JB8MDaXmw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3 WCSS随聚类数的变化(图片由作者提供)</p></figure><p id="79c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3.2应用k均值</strong></p><p id="8d76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">决定了k之后，让我们对压缩数据集应用k-means。</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="b205" class="mq mr it mm b gy ms mt l mu mv">kmeans = KMeans(4)<br/>kmeans.fit(pred)<br/>labels = kmeans.labels_<br/>df_cluster_dr = pd.concat([creditcard_df, pd.DataFrame({‘cluster’: labels})], axis = 1)</span></pre><p id="3808" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3.3可视化集群</strong></p><p id="d92f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的部分来了！</p><p id="8b7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一个可视化是比较集群特征。由于功能太多，这里只分析5个关键功能，<em class="my">'余额'，'购买'，'一次性购买'，'分期付款_购买'，'现金_预付'。这里我们将进行一些定性观察。</em></p><p id="65e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仔细看看图4📣📣。你可以在下面找到:</p><ul class=""><li id="fc23" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu mx mb mc md bi translated">聚类3中的客户余额最低，与其他组相比，他们没有进行太多的购买和现金预支。所以，他们对信用卡并不积极或热衷。</li><li id="e9f1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu mx mb mc md bi translated">聚类2中的客户是一个余额非常高的群体，与聚类0和1相比，他们倾向于进行更多的购买，包括一次性购买和分期购买。</li><li id="92ed" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu mx mb mc md bi translated">聚类1中的客户的平均余额低于聚类0。他们的购买模式相似，但聚类0中的客户倾向于进行更多的一次性和分期付款购买，尽管他们的平均信用限额低于聚类1。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/555c4007611f1d9a54704a2b47b45b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*5-WsFAaHZsgOlrQ-8oLTig.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4比较聚类特征(图片由作者提供)</p></figure><p id="fa1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些发现可以使营销策略更有针对性和洞察力📣📣。</p><p id="662c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3.4 PCA可视化</strong></p><p id="655d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们想可视化聚类分布，我们的数据集与10个特征是不可能做到这一点。但是我们可以使用主成分分析进一步将特征压缩到2D空间。具体来说，</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="0803" class="mq mr it mm b gy ms mt l mu mv">pca = PCA(n_components = 2)<br/>prin_comp = pca.fit_transform(pred)</span></pre><p id="9abf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以查看如图5所示的集群分布。很好，现在我们可以看到4个没有太多重叠的集群。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/18be69eb39b0bb3e9b27fa5842d393b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*jmFSBWuUwoEQf-GIfHHDIA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5主成分分析空间上的聚类分布(图片由作者提供)</p></figure><p id="969b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4。外卖</strong></p><p id="510e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最初，我们使用k-means进行客户聚类，创建了8个组。这里，我们进一步重新创建了特性，并使用自动编码器模型将特性总数从17个压缩到10个。</p><p id="790d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们发现每一组都有一些有趣的特征。例如，分类3(上面的黄点)显示没有低余额的频繁购买。根据营销目的的不同，这些客户可以根据他们的习惯很好地定位。</p><p id="4e33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我们只做了一些定性的观察。我们更好地对每个集群的特征进行定量分析，这可以给我们更多有见地的发现。</p><p id="f9fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">太好了！这是所有的旅程。希望你喜欢它。如果你需要代码，请访问我的Github <a class="ae ky" href="https://github.com/luke4u/Credit-Card-Prediction/tree/master/customer_clustering" rel="noopener ugc nofollow" target="_blank"> repos </a>💕💕。</p></div></div>    
</body>
</html>