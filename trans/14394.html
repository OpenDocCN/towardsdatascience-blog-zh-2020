<html>
<head>
<title>Machine Learning With R: Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带R的机器学习:逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-with-r-logistic-regression-152ec20351db?source=collection_archive---------19-----------------------#2020-10-04">https://towardsdatascience.com/machine-learning-with-r-logistic-regression-152ec20351db?source=collection_archive---------19-----------------------#2020-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ae58" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">包括R代码中的分类基础知识</h2></div><p id="035c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们和<em class="le"> R </em>的机器学习小旅程还在继续！今天的主题是逻辑回归——作为机器学习分类任务的介绍。我们将涵盖众所周知的<em class="le">泰坦尼克号</em>数据集的数据准备、建模和评估。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/7b77c293c8119368cfa77a932938c6bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RxJOFpNnTEqWGvsnMKqwqA.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">照片由<a class="ae lv" href="https://unsplash.com/@aronvandepol?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">阿伦·范德波尔</a>在<a class="ae lv" href="https://unsplash.com/s/photos/abstract?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="5a73" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您想从头开始阅读本系列，这里有以前文章的链接:</p><ul class=""><li id="e24b" class="lw lx it kk b kl km ko kp kr ly kv lz kz ma ld mb mc md me bi translated"><a class="ae lv" rel="noopener" target="_blank" href="/machine-learning-with-r-linear-regression-558fa2edaaf0">带R的机器学习:线性回归</a></li></ul><p id="17f8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章的结构如下:</p><ul class=""><li id="9e29" class="lw lx it kk b kl km ko kp kr ly kv lz kz ma ld mb mc md me bi translated">逻辑回归简介</li><li id="6ba7" class="lw lx it kk b kl mf ko mg kr mh kv mi kz mj ld mb mc md me bi translated">数据集介绍和加载</li><li id="27d4" class="lw lx it kk b kl mf ko mg kr mh kv mi kz mj ld mb mc md me bi translated">数据准备</li><li id="28d3" class="lw lx it kk b kl mf ko mg kr mh kv mi kz mj ld mb mc md me bi translated">模型训练和评估</li><li id="9446" class="lw lx it kk b kl mf ko mg kr mh kv mi kz mj ld mb mc md me bi translated">结论</li></ul><p id="e874" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以在这里下载源代码<a class="ae lv" href="https://github.com/betterdatascience/MachineLearningWithR" rel="noopener ugc nofollow" target="_blank"/>。简介部分到此结束，我们有许多内容要讲，所以让我们直接进入正题。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="0c59" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">逻辑回归简介</h1><p id="7251" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">逻辑回归是从统计学领域借用的二元分类(两个类值)的一个很好的介绍性算法。该算法得名于其底层机制——逻辑函数(有时称为sigmoid函数)。</p><p id="cbc9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">逻辑函数是在统计中开发的S形函数，它接受任何实数值并将其映射到0到1之间的值。这正是我们进行二元分类所需要的，因为我们可以将阈值设置为0.5，并根据逻辑函数的输出进行预测。</p><p id="1194" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是逻辑函数的样子:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/ae1bb89bc371541c572c11a55c91ffd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*xeFiLhh9WZRING9N.png"/></div></figure><p id="e39b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你感兴趣，下面是逻辑函数的方程式。记住——它接受任何实数值，并将其转换为0到1之间的值。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi gj"><img src="../Images/472aaa78007d7bd8ca25e639ba0af05d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nDR83u0kLjG1WF2N.png"/></div></div></figure><p id="e0a8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这对于理论来说已经足够了。我重复一遍——这篇文章的目的不是覆盖理论，因为有太多的理论文章/书籍。是纯动手的作品。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="87ac" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">数据集介绍和加载</h1><p id="d35c" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">好了，现在我们对逻辑回归有了基本的了解，我们可以从编码部分开始了。如前所述，我们将使用泰坦尼克号数据集。你不必下载它，因为R已经为我们下载了。</p><p id="8a72" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是库导入和数据集加载的代码片段:</p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="caf1" class="nu ms it nq b gy nv nw l nx ny">library(dplyr) <br/>library(stringr) <br/>library(caTools) <br/>library(caret) </span><span id="c877" class="nu ms it nq b gy nz nw l nx ny">df &lt;- read.csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')</span></pre><p id="b25d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是前几行的样子:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oa"><img src="../Images/d630c6c88c60a1bb9b79c91dcc16ccef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-S-bhHBi_MOEoBcq.png"/></div></div></figure><p id="da08" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">厉害！数据集需要做一些准备才能转换成ml格式，所以这是我们接下来要做的。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="820e" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">数据准备</h1><p id="38bb" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">我们必须做几件重要的事情:</p><ul class=""><li id="0633" class="lw lx it kk b kl km ko kp kr ly kv lz kz ma ld mb mc md me bi translated">从名称属性中提取标题</li><li id="8c99" class="lw lx it kk b kl mf ko mg kr mh kv mi kz mj ld mb mc md me bi translated">照常/不寻常地重新映射提取的标题</li><li id="b428" class="lw lx it kk b kl mf ko mg kr mh kv mi kz mj ld mb mc md me bi translated">将小屋属性转换为二进制HasCabin</li><li id="6c79" class="lw lx it kk b kl mf ko mg kr mh kv mi kz mj ld mb mc md me bi translated">删除不必要的属性</li></ul><p id="f8b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个来自Kaggle 的<a class="ae lv" href="https://www.kaggle.com/tysonni/extracting-passenger-titiles-in-r" rel="noopener ugc nofollow" target="_blank">片段对标题提取和重新映射有很大帮助，只需稍加修改。其他要点相对简单，如下面的代码片段所示:</a></p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="895e" class="nu ms it nq b gy nv nw l nx ny">maleNobleTitles &lt;- c('Capt', 'Col', 'Don', 'Dr', 'Jonkheer', 'Major', 'Rev', 'Sir') <br/>femaleNobleTitles &lt;- c('Lady', 'Mlle', 'Mme', 'Ms', 'the Countess') </span><span id="a938" class="nu ms it nq b gy nz nw l nx ny">df$Title &lt;- str_sub(df$Name, str_locate(df$Name, ',')[ , 1] + 2, str_locate(df$Name, '\\.')[ , 1] - 1) <br/>df$Title[df$Title %in% maleNobleTitles] &lt;- 'MaleNoble' <br/>df$Title[df$Title %in% femaleNobleTitles] &lt;- 'FemaleNoble' <br/>df$HasCabin &lt;- ifelse(df$Cabin == '', 0, 1) <br/>df &lt;- df %&gt;% select(-PassengerId, -Name, -Ticket, -Cabin)</span></pre><p id="0d9a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们实际上为贵族头衔创建了两个数组，一个用于男性，一个用于女性，将头衔提取到title列，并用表达式“MaleNoble”和“FemaleNoble”替换贵族头衔。</p><p id="9264" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，ifelse函数帮助创建了<code class="fe ob oc od nq b">HasCabin</code>属性，如果Cabin的值不为空，则该属性的值为1，否则为0。最后，我们只保留了与分析相关的特性。</p><p id="2f2e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是数据集现在的样子:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oe"><img src="../Images/6649e55886f92301884fce383ce130b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*O83LYvtzeRp3KdDt.png"/></div></div></figure><p id="3ca1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">厉害！接下来我们来处理缺失值。</p><h2 id="cad6" class="nu ms it bd mt of og dn mx oh oi dp nb kr oj ok nd kv ol om nf kz on oo nh op bi translated">处理缺失数据</h2><p id="58dd" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">下面一行代码打印出每个属性有多少个缺失值:</p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="b2c0" class="nu ms it nq b gy nv nw l nx ny">lapply(df, function(x) { length(which(is.na(x))) })</span></pre><p id="759f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">属性<code class="fe ob oc od nq b">Age</code>是唯一包含缺失值的属性。由于本文涵盖了机器学习而不是数据准备，我们将用一个简单的平均值来进行插补。以下是片段:</p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="a610" class="nu ms it nq b gy nv nw l nx ny">df$Age &lt;- ifelse(is.na(df$Age), mean(df$Age, na.rm=TRUE), df$Age)</span></pre><p id="8376" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是归罪。只剩下一件事要做了，准备工作。</p><h2 id="fc03" class="nu ms it bd mt of og dn mx oh oi dp nb kr oj ok nd kv ol om nf kz on oo nh op bi translated">因子转换</h2><p id="3720" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">我们的数据集中有许多分类属性。r提供了一个简单的<code class="fe ob oc od nq b">factor()</code>函数，将分类属性转换成算法可以理解的格式。</p><p id="b8cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是我们的数据集在转换前的结构:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oq"><img src="../Images/f3522f0fc511ceb7e29fba65c3540a0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*q2a1SlM-eOwMS6j3.png"/></div></div></figure><p id="1674" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是执行转换的代码片段:</p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="4c7b" class="nu ms it nq b gy nv nw l nx ny">df$Survived &lt;- factor(df$Survived) <br/>df$Pclass &lt;- factor(df$Pclass) <br/>df$Sex &lt;- factor(df$Sex) <br/>df$SibSp &lt;- factor(df$SibSp) <br/>df$Parch &lt;- factor(df$Parch) <br/>df$Embarked &lt;- factor(df$Embarked) <br/>df$Title &lt;- factor(df$Title) <br/>df$HasCabin &lt;- factor(df$HasCabin)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi or"><img src="../Images/c6bc7723d94b63903879596612ff9b8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ix9SOXIvh3gzClk3.png"/></div></div></figure><p id="aaa5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据准备部分已经完成，现在我们可以继续建模了。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="7d25" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">模型训练和评估</h1><p id="239c" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">在实际的模型训练之前，我们需要在训练和测试子集上分割数据集。这样做可以确保我们有一个数据子集来评估，并且知道模型有多好。代码如下:</p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="7eeb" class="nu ms it nq b gy nv nw l nx ny">set.seed(42) </span><span id="66ed" class="nu ms it nq b gy nz nw l nx ny">sampleSplit &lt;- sample.split(Y=df$Survived, SplitRatio=0.7) <br/>trainSet &lt;- subset(x=df, sampleSplit==TRUE) <br/>testSet &lt;- subset(x=df, sampleSplit==FALSE)</span></pre><p id="1b55" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的代码将原始数据集分成70:30的子集。我们将对大多数(70%)进行训练，对其余的进行评估。</p><p id="8751" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在可以用函数来训练模型。我们将使用所有的属性，用点表示，列是目标变量。</p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="43fe" class="nu ms it nq b gy nv nw l nx ny">model &lt;- glm(Survived ~ ., family=binomial(link='logit'), data=trainSet)</span></pre><p id="31e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就这样——我们成功地训练了这个模型。让我们通过调用它的<code class="fe ob oc od nq b">summary()</code>函数来看看它是如何执行的:</p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="cf72" class="nu ms it nq b gy nv nw l nx ny">summary(model)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi os"><img src="../Images/74214d677113715925745a124108fbc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*i0lzAbrkXpqTqWRL.png"/></div></div></figure><p id="237c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里最令人兴奋的是P值，显示在<strong class="kk iu"> Pr( &gt; |t|) </strong>列中。这些值表示变量对预测不重要的概率。通常使用5%的显著性阈值，因此如果P值为0.05或更低，我们可以说它对分析不显著的可能性很低。</p><p id="7e89" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，最重要的属性/属性子集是<code class="fe ob oc od nq b">Pclass3</code>、<strong class="kk iu">、<em class="le">、</em>、</strong>、<strong class="kk iu">、、</strong>、<strong class="kk iu">、<em class="le">、</em>、<code class="fe ob oc od nq b">SibSp4</code>、<strong class="kk iu">、<em class="le">、</em>、</strong>和<code class="fe ob oc od nq b">HasCabin1</code>。</strong></p><p id="baa9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在对我们的模型有了更多的信息——我们知道决定一名乘客是否在泰坦尼克号事故中幸存的最重要的因素。现在，我们可以继续评估以前未见过的数据—测试集。</p><p id="c35a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们故意保持这个子集不变，只是为了模型评估。首先，我们需要计算预测概率和基于这些概率的预测类别。我们将设定0.5作为阈值——如果生还的机会小于0.5，我们就说乘客没有在事故中幸存。代码如下:</p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="6698" class="nu ms it nq b gy nv nw l nx ny">probabs &lt;- predict(model, testSet, type='response') <br/>preds &lt;- ifelse(probabs &gt; 0.5, 1, 0)</span></pre><p id="aafc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在很容易在此基础上进行构建。分类任务的主要方法是建立一个混淆矩阵——一个2×2矩阵，显示第一个和第四个元素的正确分类，以及第二个和第三个元素的错误分类(从左到右、从上到下阅读)。下面是如何通过代码获得它:</p><pre class="lg lh li lj gt np nq nr ns aw nt bi"><span id="9410" class="nu ms it nq b gy nv nw l nx ny">confusionMatrix(factor(preds), factor(testSet$Survived))</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/e95c39dcacc0a9845c672503ffbf2b83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*PM0G-Rjq4ekBMkoG.png"/></div></figure><p id="c148" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，总的来说，我们的模型在大约84%的测试案例中是正确的——对于几分钟的工作来说还不错。让我们在下一部分总结一下。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="299b" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">在你走之前</h1><p id="c7ac" class="pw-post-body-paragraph ki kj it kk b kl nj ju kn ko nk jx kq kr nl kt ku kv nm kx ky kz nn lb lc ld im bi translated">到目前为止，我们已经介绍了最基本的回归和分类机器学习算法。我知道这是一个相当乏味的过程，但却是为后面更复杂的算法和优化奠定基础所必需的。</p><p id="5522" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">KNN系列的下一篇文章将在几天后发表，敬请关注。</p><p id="04e7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读。</p><h2 id="3ab4" class="nu ms it bd mt of og dn mx oh oi dp nb kr oj ok nd kv ol om nf kz on oo nh op bi translated"><a class="ae lv" href="https://mailchi.mp/46a3d2989d9b/bdssubscribe" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">加入我的私人邮件列表，获取更多有用的见解。</strong>T24】</a></h2></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="73e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">喜欢这篇文章吗？成为 <a class="ae lv" href="https://medium.com/@radecicdario/membership" rel="noopener"> <em class="le">中等会员</em> </a> <em class="le">继续无限制学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="ou ov gp gr ow ox"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">通过我的推荐链接加入Medium-Dario rade ci</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">medium.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl lp ox"/></div></div></a></div></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><p id="4983" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">原载于2020年10月4日https://betterdatascience.com</em><a class="ae lv" href="https://betterdatascience.com/machine-learning-with-r-logistic-regression/" rel="noopener ugc nofollow" target="_blank"><em class="le"/></a><em class="le">。</em></p></div></div>    
</body>
</html>