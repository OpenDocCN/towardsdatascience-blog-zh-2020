<html>
<head>
<title>Your fancy proprietary AI model has no value to me</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你花哨的专有人工智能模型对我没有价值</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/your-fancy-proprietary-ai-model-has-no-value-to-me-2a7d40dfd8ca?source=collection_archive---------47-----------------------#2020-11-16">https://towardsdatascience.com/your-fancy-proprietary-ai-model-has-no-value-to-me-2a7d40dfd8ca?source=collection_archive---------47-----------------------#2020-11-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="af15" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">…除非您分享其目标、设计、测试和指标的细节</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/325c3eaf58db321701881739cc72f351.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LibCh2Cux6rkKuuv3A_yg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5246634" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>的Gerd Altmann 提供</p></figure><p id="2624" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">各地的厂商，请不要告诉我你的机器学习(或者更好的是‘AI’)模型有99%的准确率。不要告诉我，我们所需要做的就是‘插入你的数据’，然后一些闪亮的魔法就发生了。我不是唯一的一个。<a class="ae ky" href="https://www.nature.com/articles/s41586-020-2766-y.epdf?sharing_token=esGu0AMNcdnJWDaAaBr3BtRgN0jAjWel9jnR3ZoTv0M3qEeZVaYZS89U0ri_i4YI_lJ0an-lE15Ncv2e1v5F7I2jYVuc7_mR1WrnlDjpWJ6ANzSjO0KJiERmpzE097VzbFgywD7RRHVOYg305JycIUX7UQDWkLlgHtsoU72ppNzneeIGzsSR4Cr5dVRyVtV2UMxm2gs9pA22vydPt_RRBmPUqh6R2UPn-oziFm82hKA%3D&amp;tracking_referrer=www.technologyreview.com" rel="noopener ugc nofollow" target="_blank">最近，31名科学家对谷歌健康的一项研究</a>提出质疑，因为没有足够的公开证据来确定所提出的人工智能模型的可信度。我们都需要尽自己的一份力量来构建值得信赖的模型，为我们新的先进应用提供动力。被告知是减轻模型风险的第一步。</p><h1 id="c3a7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">给我提供背景</h1><p id="d3b7" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">当检查内部创建的模型或现成的供应商产品时，我会遵循一些必要的步骤。还有许多其他伟大的问题。请在评论区分享它们。</p><p id="f73c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先我们要明白，你在幕后做的是不是机器学习。如果你不能告诉我什么类型的模型产生的结果，让你的工程师打电话。</p><p id="b653" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">没有上下文，准确性度量是没有价值的。如果你正在为一个儿童动物学应用程序标记鱼的种类，百分之九点九的准确率是非常好的，但如果你正在识别来袭导弹，就没那么好了。</p><p id="bde8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在私下讨论任何指标之前，需要检查以下三个问题。</p><p id="d54e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">目标是什么？</strong></p><ul class=""><li id="c292" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">你是在促进什么还是阻止什么？</li></ul><p id="0f9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">事件发生的频率或罕见程度如何？</strong></p><ul class=""><li id="dec3" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">给我数据。“非常罕见”不是一个好的回答。</li></ul><p id="70ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">最坏的情况是什么？</strong></p><ul class=""><li id="f5f4" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">如果模型是错的会发生什么，包括假阳性和假阴性。</li><li id="da64" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">如果你不知道，你就不了解用例。你有工作要做。</li></ul><h1 id="2c4a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">给我提供证据和细节</h1><p id="a15c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">一旦我理解了这些基础知识，我们就可以进入细节了。</p><p id="10ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">你从哪里得到的训练数据？</strong></p><ul class=""><li id="3bd1" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">如果购买，供应商是谁？</li><li id="1e1e" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">您是否在建模数据的基础上构建模型？</li><li id="fd89" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">数据是如何收集和准备的？</li><li id="bee0" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">交易、电话调查、网络应用、电话应用</li></ul><p id="faeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">训练的模型类型:</strong></p><ul class=""><li id="373e" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">什么样的模型？</li><li id="bb0a" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">你是如何得到这些特别的模型的？</li><li id="df34" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">在做决定时，您是否依赖于特定的平台或架构？</li></ul><p id="d66d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">指标:</strong></p><ul class=""><li id="ad93" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">准确是好的，但不仅仅是准确。请给我看看混淆矩阵。模型哪里做得好，哪里做得不好？</li><li id="bf1e" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">你能告诉我最好的预测吗？我需要验证它们是否“有意义”关联值是多少？有没有可能<a class="ae ky" href="https://en.wikipedia.org/wiki/Leakage_%28machine_learning%29" rel="noopener ugc nofollow" target="_blank">数据泄露</a>？</li></ul><p id="4403" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">偏置:</strong></p><ul class=""><li id="da16" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">你认为你的训练数据中存在哪些偏见(人口统计、地区、收集方法(iPhone与Android)、种族、健康和福利)？如果偏见是不可避免的，你做了什么来减轻它？</li><li id="eefa" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">您是否通过分析模型实施的结果评估了可能的偏差影响？一个模型可以有绝对“干净”的数据，但仍然会产生意想不到的后果。性别、种族、民族和社会经济地位很容易泄露到数据库中，即使这些列没有被使用。如需详细示例，请阅读Obermeyer等人的“剖析用于管理人口健康的算法中的种族偏见”<em class="ng">SCIENCE</em>2019年10月25日:447–453。它很好地详细说明了选择一个看似合理的优化目标(降低慢性病患者的医疗保健成本)如何导致黑人社区中有价值的健康计划候选人服务不足。</li></ul><h1 id="27d9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="24f3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">随着机器学习和人工智能工作的快速发展，我们对模型设计和验证透明度的期望也应该快速发展。如果没有能力彻底理解模型及其产生的结果，对所有模型的不信任可能会出现，从而抑制增长和创造力。如果你还没有提问，请开始提问。我们所有的成功都有赖于此。</p><p id="4461" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献</strong></p><div class="nh ni gp gr nj nk"><a href="https://www.technologyreview.com/2020/11/12/1011944/artificial-intelligence-replication-crisis-science-big-tech-google-deepmind-facebook-openai/?itm_source=parsely-api" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">人工智能正在与复制危机搏斗</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">上个月,《自然》杂志发表了一篇由31名科学家撰写的对谷歌健康的一项研究的谴责性回应，该研究似乎…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">www.technologyreview.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny ks nk"/></div></div></a></div><div class="nh ni gp gr nj nk"><a href="https://www.nature.com/articles/s41586-020-2766-y.epdf?sharing_token=esGu0AMNcdnJWDaAaBr3BtRgN0jAjWel9jnR3ZoTv0M3qEeZVaYZS89U0ri_i4YI_lJ0an-lE15Ncv2e1v5F7I2jYVuc7_mR1WrnlDjpWJ6ANzSjO0KJiERmpzE097VzbFgywD7RRHVOYg305JycIUX7UQDWkLlgHtsoU72ppNzneeIGzsSR4Cr5dVRyVtV2UMxm2gs9pA22vydPt_RRBmPUqh6R2UPn-oziFm82hKA%3D&amp;tracking_referrer=www.technologyreview.com" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">人工智能中的透明性和再现性</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">订阅期刊获得为期1年的完整期刊访问权限199.00美元，每期仅3.90美元所有价格均为净价。增值税…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">www.nature.com</p></div></div></div></a></div><div class="nh ni gp gr nj nk"><a rel="noopener follow" target="_blank" href="/how-you-can-prevent-systemic-racism-in-your-own-small-way-fc33cb57fdde"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">你如何用自己的小方法防止系统性的种族歧视</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">这里有两种方法可以解决技术和数据科学中的偏见</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="nz l nv nw nx nt ny ks nk"/></div></div></a></div><p id="a5b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“剖析用于管理人口健康的算法中的种族偏见”，作者Obermeyer等人<em class="ng">SCIENCE</em>2019年10月25日:447–453</p></div></div>    
</body>
</html>