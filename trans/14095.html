<html>
<head>
<title>Costs prediction of a Marketing Campaign (Data Cleaning &amp; Feature Selection — Part II)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">营销活动的成本预测(数据清理和特征选择——第二部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/costs-prediction-of-a-marketing-campaign-data-cleaning-feature-selection-part-ii-6aa5298909b5?source=collection_archive---------35-----------------------#2020-09-28">https://towardsdatascience.com/costs-prediction-of-a-marketing-campaign-data-cleaning-feature-selection-part-ii-6aa5298909b5?source=collection_archive---------35-----------------------#2020-09-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ced7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">预测营销活动最佳目标候选人的数据科学方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/8828e54d7b1678b5358f91ea5b977f8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*XTD_4LsJOdgTXjdCso31WQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">数据清理和特征选择—gon alo GUI mares Gomes</p></figure><p id="59c9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在第一篇文章中，我进行了<a class="ae lq" href="https://bit.ly/3lDzknU" rel="noopener ugc nofollow" target="_blank">探索性的数据分析</a>，这让我们可以看得更远，超越最初的数据集。</p><p id="bee3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">EDA可能是一项非常耗时的任务，很少是一次性走完的，尽管我们可能会发现自己经常回到早期部分更改和尝试一些不同的方法，但详细的分析通常会有所帮助，并为我们提供大量有关数据和变量行为的信息。</p><p id="5289" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本文只关注第二部分，即<strong class="kw iu">清洁&amp;功能选择</strong>。</p><p id="0b44" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以在这里熟悉EDA部分<a class="ae lq" href="https://bit.ly/3lDzknU" rel="noopener ugc nofollow" target="_blank">。<br/>你可以在这里</a>找到这个项目<a class="ae lq" href="https://bit.ly/3hmI3YS" rel="noopener ugc nofollow" target="_blank">的代码。<br/>可点击</a>此处<a class="ae lq" href="https://bit.ly/31a0EAL" rel="noopener ugc nofollow" target="_blank">下载“bank_marketing_campaign.csv”数据集。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lr"><img src="../Images/5cbc7f3c0045b47971114179ead77522.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2ttu1yYd8nCED3WA"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated"><a class="ae lq" href="https://unsplash.com/@bradencollum?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">布拉登·科拉姆</a>在<a class="ae lq" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="6e00" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak">数字特征之间的相关性</strong></h1><p id="aad1" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">在降维的背景下，特征和目标变量之间的相关性分析被证明是双变量数据分析中的基本步骤，因为它帮助我们计算特征的重要性。</p><p id="f23a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们从指出皮尔逊和斯皮尔曼的相关系数概念开始。</p><p id="0c24" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">根据定义，<strong class="kw iu">皮尔逊相关系数</strong>，通常被称为<strong class="kw iu">皮尔逊相关系数<em class="mt">r</em>T25】，是描述两个随机变量线性相关的程度，它们的统计关系有多强，在哪个方向发生，在二元数据中是否偶然。</strong></p><p id="9c51" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">值的范围从-1.0到1.0，其中第一个值表示总的负线性相关，而第二个值表示相反的线性相关。值为0.0表明没有线性关系。</p><p id="a7b1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">另一个重要的推论是，皮尔逊相关性只能评估连续变量之间的线性关系，这意味着一个变量的变化意味着另一个变量以恒定的速率成比例地变化，否则它就是非线性关系。仅当变量呈正态分布时，才建议使用这种参数测试。</p><p id="df86" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">其中一个输出是相关性的<strong class="kw iu"> p值，粗略显示了不相关系统产生某一数量级相关值的概率。低p值(通常≤0.05)告诉我们，相关性很可能是显著的。具体来说，p值将揭示特征的预测能力。</strong></p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="eab7" class="mz lx it mv b gy na nb l nc nd"># Most correlated against the target (Pearson method)<br/>pearson = df_num.corr()<br/>corr_target = pearson.target<br/>display(corr_target.sort_values(ascending=False))<br/><br/>print("Ordered by rank in absolute values")<br/>display(corr_target.abs().sort_values(ascending=False))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/09dcd091af5fbfa1403446f79cfd7fe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*dYo-V2bLo82BjoAU02U2yg.png"/></div></figure><p id="98bd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">“Nr_employed”与目标最相关，其次是“pdays”、“euribor3m”和“emp_avr_rate”，同时，它们与目标的关系强度较低。下表让我们得出结论，所有特征都具有预测能力。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="787c" class="mz lx it mv b gy na nb l nc nd"># Subdivision of target<br/>ynum = df_num.target<br/>Xnum = df_num.drop(["target"], axis= "columns")</span><span id="5fad" class="mz lx it mv b gy nf nb l nc nd"># Identifying variables with predictive power (Pearson p-value)<br/>pd.DataFrame(<br/>    [scipy.stats.pearsonr(Xnum[col], ynum) for col in Xnum.columns],<br/>    columns=["Pearson Corr.", "p-value"],<br/>    index=Xnum.columns,<br/>).round(2).T</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/fd1bd9d6b3e8ccdf0aa805ca4b8f6df8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*pybHmQ7CpfVXvPKRtiQDcg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">所有变量都有预测能力。</p></figure><p id="57b5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">另一方面，<strong class="kw iu">斯皮尔曼相关系数</strong>，或<strong class="kw iu">斯皮尔曼相关系数</strong>，是一种秩序相关性的非参数度量，用于评估两个连续或有序变量之间的单调关系。</p><p id="9e86" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当出现以下情况之一时，出现单调关系:</p><p id="dab7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当一个变量的值增加时，其他变量的值也会增加</p><p id="2579" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">和</p><p id="bd3d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="mt"> b) </em> </strong>当一个变量的值增加时，其他变量的值就会减少</p><p id="fcfa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是</p><p id="ee48" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="mt"> a)+b) </em> </strong>不是以恒定的速率。</p><p id="5a15" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这意味着所有线性变量的关系同时是单调的，但反过来并不总是正确的，因为我们可以同时具有单调的非线性相关性。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="b827" class="mz lx it mv b gy na nb l nc nd"># Numeric variables with higher monotonicity (spearman)<br/>df_spearman = df_num.copy()<br/>df_spearman.drop(["target"], axis=1, inplace=True)</span><span id="4468" class="mz lx it mv b gy nf nb l nc nd">spearman_rank = pg.pairwise_corr(df_spearman, method='spearman').loc[:,['X','Y','r']]<br/>pos = spearman_rank.sort_values(kind="quicksort", by=['r'], ascending=False).iloc[:5,:]<br/>neg = spearman_rank.sort_values(kind="quicksort", by=['r'], ascending=False).iloc[-5:,:]<br/>con = pd.concat([pos,neg], axis=0)<br/>display(con.reset_index(drop=True))</span><span id="5f9f" class="mz lx it mv b gy nf nb l nc nd">mask = np.triu(df_spearman.corr(method='spearman'), 1)<br/>plt.figure(figsize=(19, 9))<br/>sns.heatmap(df_spearman.corr(method='spearman'), annot=True, vmax=1, vmin=-1, square=True, cmap='BrBG', mask=mask);</span></pre><p id="4842" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">10个最相关的数字对，Spearman方法:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8f0521bbb71777e8f957ca9ebec04df3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*OGbCEDZNNqJQuzTdpKVEiw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ni"><img src="../Images/ae0de5a5b16bbd660cbf3cb70ae02612.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mj0RZXh_BCu0FZgtPy6T7Q.png"/></div></div></figure><p id="f49a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">“nr_employed”与目标最相关。变量‘EMP _ var _ rate’，‘NR _ employed’和‘euribor 3m’非常多余，但我相信这并不代表什么大问题。<strong class="kw iu">策略:</strong>暂时保留所有特性。</p><h2 id="6763" class="mz lx it bd ly nj nk dn mc nl nm dp mg ld nn no mi lh np nq mk ll nr ns mm nt bi translated"><strong class="ak">分类变量</strong></h2><p id="2423" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">当我们想要检查两个分类变量之间是否存在关系时，使用<strong class="kw iu">卡方独立性检验</strong>(此外，我们正在处理一个二元分类问题，卡方检验非常适合在这里执行)。</p><p id="5a2f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，我将指定零假设和替代假设来运行测试。</p><p id="6920" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">替代假设总是我们试图证明的，而无效假设是我们试图证明证据反对的假设。</p><ul class=""><li id="1a85" class="nu nv it kw b kx ky la lb ld nw lh nx ll ny lp nz oa ob oc bi translated"><em class="mt">(零假设)</em> H0:特征和目标是独立的</li><li id="f803" class="nu nv it kw b kx od la oe ld of lh og ll oh lp nz oa ob oc bi translated"><em class="mt">(替代假设)</em> Ha:特征和目标不是独立的</li></ul><p id="548a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，对于被认为相关的特征，我们希望<strong class="kw iu">拒绝具有最低p值(p值≤0.05)的H0 </strong>(零假设)。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="28b6" class="mz lx it mv b gy na nb l nc nd"># Create categoric subset in order to see correlations results<br/>Xcat = df_cat.select_dtypes(exclude=['int64','float64']).copy()<br/>ycat = df.target</span><span id="729d" class="mz lx it mv b gy nf nb l nc nd"># Study chi² for independence:<br/>chi2 = []<br/>p_val = []<br/>for feature in cat_features:<br/>    table = pd.crosstab(df_cat[feature], ycat)<br/>    chi2.append(round(chi2_contingency(table)[0], 2))<br/>    p_val.append(round(chi2_contingency(table)[1], 2))</span><span id="79d8" class="mz lx it mv b gy nf nb l nc nd">pd.DataFrame([chi2,p_val], columns = cat_features, index = ['chi2', 'p_value'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/fa12b7732eaf136ff2f15295815271b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*p8K6cnkU1xNzeZURP3modA.png"/></div></figure><p id="13ef" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">策略:</strong>去除变量‘住房’和‘贷款’(p值≥ 0.05)。</p><h1 id="1aea" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">离群值、缺失值、异常和转换</h1><h2 id="d7d4" class="mz lx it bd ly nj nk dn mc nl nm dp mg ld nn no mi lh np nq mk ll nr ns mm nt bi translated">数字特征</h2><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="1627" class="mz lx it mv b gy na nb l nc nd"># Removing Target and creating a copy of the dataset<br/>df_drop = df_num.drop(["target"], axis=1).copy()</span><span id="6e34" class="mz lx it mv b gy nf nb l nc nd"># Visualization of numerical data dispersion (boxplots)<br/>fig, axs = plt.subplots(ncols=2, nrows=4, figsize=(16, 8))<br/>index = 0<br/>axs = axs.flatten()<br/>for k,v in df_drop.items():<br/>    sns.boxplot(y=k, data=df_drop, ax=axs[index], orient="h")<br/>    index += 1<br/>plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)</span><span id="998b" class="mz lx it mv b gy nf nb l nc nd">display(df_drop.describe().loc[["mean","50%","std"]])<br/>print(f"Any missing values: {df_drop.isnull().values.any()}")<br/>print("")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi oj"><img src="../Images/de86758678a031db7847eb31f1fa959b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iijlcQviI2poqguPkUiE3w.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ok"><img src="../Images/70b83f5e112a1afb10ec8dbbe4d5e231.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8LBpCGxOMwc1ju4gHVSuMQ.png"/></div></div></figure><p id="a1bc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所使用的技术确定了位于中位数的+1.5 IQR和-1.5 IQR的值，这是一种非参数方法，可用于我们发现的分布轮廓。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ol"><img src="../Images/23bb340255573283b95cb33782cbab96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nNms2YhmEGJq3WykViO4WA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来源:<a class="ae lq" href="https://upload.wikimedia.org/wikipedia/commons/1/1a/Boxplot_vs_PDF.svg" rel="noopener ugc nofollow" target="_blank">https://upload . wikimedia . org/Wikipedia/commons/1/1a/box plot _ vs _ pdf . SVG</a></p></figure><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="6dca" class="mz lx it mv b gy na nb l nc nd">for column in df_drop.columns:<br/>    median = df_drop[column].quantile()<br/>    iqr_1_5 = (df_drop[column].quantile(q = 0.75) - df_drop[column].quantile(q = 0.25)) * 1.5<br/>    outliers = df_drop[(df_drop[column]&lt; median - iqr_1_5) | (df_drop[column] &gt; median + iqr_1_5)][column].count()<br/>    outliers_pct = round(outliers / df_drop[column].count() * 100, 1)<br/>    print("'{}' = {} ({}%) outliers".format(column, outliers, outliers_pct))</span></pre><p id="e310" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">&gt;&gt;输出:<br/> 'age' = 910 (2.2%)异常值<br/> 'pdays' = 1515 (3.7%)异常值<br/> 'previous' = 5625 (13.7%)异常值<br/> 'emp_var_rate' = 0 (0.0%)异常值<br/> 'cons_price_idx' = 770 (1.9%)异常值<br/> 'cons_conf_idx' = 1841 (4.5%)异常值<br/>' EUR</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="01d8" class="mz lx it mv b gy na nb l nc nd"># Displaying visuals<br/>fig, ax  = plt.subplots(figsize = (18,10))<br/>ax.axis("off")<br/>v = 1<br/>for column in df_drop.columns:<br/>    ax1 = fig.add_subplot(2,4,v)<br/>    plt.hist(df_drop[column])<br/>    ax1.set_title(column)<br/>    v+=1<br/>    median = df_drop[column].quantile()<br/>    iqr_1_5 = (df_drop[column].quantile(q = 0.75) - df_drop[column].quantile(q = 0.25)) * 1.5<br/>    outliers = df_drop[(df_drop[column]&lt; median - iqr_1_5) | (df_drop[column] &gt; median + iqr_1_5)][column].count()<br/>    ax1.axvline(median - iqr_1_5, color='red', linewidth=2)<br/>    ax1.axvline(median + iqr_1_5, color='red', linewidth=2)</span><span id="11b8" class="mz lx it mv b gy nf nb l nc nd">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi om"><img src="../Images/5babac2b1b359e2c873b58b88891dc44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ssvuuoq_uimXPsLRxx-3bQ.png"/></div></div></figure><p id="c337" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我意识到用于识别异常值的方法选择了许多记录，最严重的情况是前一列中有将近14%的被选数据。</p><p id="8b66" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">据我所知，我决定保留所有类别的大部分记录，因为数据似乎已经被正确地测量并反映了现实。</p><p id="ad13" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了强调模型不受异常值数量扩展的影响，我们将只保证我们将使用标准化技术，该技术不会忽略中心值之间距离的细节。</p><p id="0d53" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从数值数据的离差分析来看，<strong class="kw iu">似乎没有异常值</strong>。“年龄”的绘制数据具有正常的行为，我假设变量“pdays”中的极端数据点是“超出范围”的值，至于其他的，每个变量似乎都有一个平衡的主体。</p><p id="9df2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">关于缺失值和其他异常，我已经分析了所有数值变量的唯一值和各自的计数，并且<strong class="kw iu">似乎没有缺失值</strong>。</p><h2 id="0b9e" class="mz lx it bd ly nj nk dn mc nl nm dp mg ld nn no mi lh np nq mk ll nr ns mm nt bi translated">分类变量</h2><p id="5ac0" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">继续讨论分类变量，检查是否有任何缺失值或其他需要处理的异常，以便通过各种技术将这些变量转换为数字特征，并根据降维和信息增益之间的最佳平衡进行逐案分析。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="955c" class="mz lx it mv b gy na nb l nc nd"># Creating a copy<br/>df_cat_t = df_cat.copy()</span><span id="2d99" class="mz lx it mv b gy nf nb l nc nd">df_cat.describe() # Describing the categorical dataframe</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi on"><img src="../Images/9612c9d35e4e1049f174152f153d57a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OK_AYibRSwmZ5cN5MlbQXw.png"/></div></div></figure><h2 id="d91d" class="mz lx it bd ly nj nk dn mc nl nm dp mg ld nn no mi lh np nq mk ll nr ns mm nt bi translated">变量:<strong class="ak">‘作业’</strong></h2><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="8ecb" class="mz lx it mv b gy na nb l nc nd">print(f"Unique values: {df_cat.job.nunique()}")</span><span id="1ae7" class="mz lx it mv b gy nf nb l nc nd"># Observations by class<br/>num_obs = df_cat.job.value_counts()<br/>num_o = pd.DataFrame(num_obs)<br/>num_o.rename(columns={"job":"Freq abs"}, inplace=True)<br/>num_o_pc = (df_cat.job.value_counts(normalize=True) * 100).round(decimals=2)<br/>num_obs_pc = pd.DataFrame(num_o_pc)<br/>num_obs_pc.rename(columns={"job":"percent %"}, inplace=True)<br/>n_obs = pd.concat([num_o,num_obs_pc], axis=1)<br/>display(n_obs)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/6b2a91e5093183af5d372b32b5be544c.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*fvdtp3fmWU8JWExmlKddAA.png"/></div></figure><p id="7b98" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这种情况下，“未知”是我们缺少的值。这里的策略是用最常见的值——模态值来估算“未知数”。我们先把它转换成np.nan，然后进行插补。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="ada1" class="mz lx it mv b gy na nb l nc nd"># Replacing 'unknown' by NaN<br/>df_cat_t.job.replace(to_replace="unknown", value=np.nan, inplace=True)</span><span id="ef3a" class="mz lx it mv b gy nf nb l nc nd"># Imputation missing values by the modal value<br/>df_cat_t['job'] = df_cat_t.job.fillna(df_cat_t.job.value_counts().index[0])</span><span id="5060" class="mz lx it mv b gy nf nb l nc nd"># Confirming and visualizing of "job"<br/>df_cat_t.job.value_counts(dropna=False).plot(kind='pie', figsize=(10,6), explode=(0.02, 0.02, 0.02, 0.02, <br/>                 0.02, 0.02, 0.02, 0.02,<br/>                 0.02, 0.02, 0.02));</span><span id="958d" class="mz lx it mv b gy nf nb l nc nd">print(f"Unique values: {df_cat_t.job.nunique()}")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi op"><img src="../Images/ab5dba11e35bc140cc31b8a58d1350ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nUaJrHj1UHWFxOJVMGaytQ.png"/></div></div></figure><p id="1deb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我还将显示在编码过程中，一个热编码和二进制编码会创建多少额外列的结果。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="75c2" class="mz lx it mv b gy na nb l nc nd"># Encoding 'job' OHE or BIN<br/>df_job = df_cat_t.job<br/>job_ohe = pd.get_dummies(df_job)<br/>binary_encoder_job = BinaryEncoder()<br/>job_bin = binary_encoder_job.fit_transform(df_job)</span><span id="d9d6" class="mz lx it mv b gy nf nb l nc nd">print(f'''<br/>*Results*<br/>job OHE: {job_ohe.shape[1]} columns<br/>job BIN: {job_bin.shape[1]} columns''')</span><span id="97e8" class="mz lx it mv b gy nf nb l nc nd">&gt;&gt; output:<br/>*Results*<br/>job OHE: 11 columns<br/>job BIN: 5 columns &lt;--- apply</span></pre><p id="00fb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">此处要应用的二进制编码</strong>。虽然与OHE相比有一些信息损失，但就降维而言，这是一个更好的权衡。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="06f6" class="mz lx it mv b gy na nb l nc nd"># Removing attribute 'job' and concatenation job_bin to df_cat_t<br/>df_cat_t.drop(["job"],axis=1,inplace=True)<br/>df_cat_t = pd.concat([df_cat_t,job_bin],axis=1)<br/>display(df_cat_t.head(2))<br/>display(df_cat_t.shape)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi oq"><img src="../Images/3d34569ee110c38f75fddf9c39ee7c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wnSTlRWLxZrJDqiP1Fd4Yg.png"/></div></div></figure><h2 id="3d19" class="mz lx it bd ly nj nk dn mc nl nm dp mg ld nn no mi lh np nq mk ll nr ns mm nt bi translated">变量:<strong class="ak">《婚姻大事》</strong></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/fbaa4d77ffc831133714c641aa0728f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*RGHXOvKcBnnwlP6smhzC_w.png"/></div></figure><p id="ee58" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">“未知”被解释为缺少值。这与“工作”变量的情况相同。策略是用最常见的值来估算缺失值。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="8846" class="mz lx it mv b gy na nb l nc nd"># Replacing 'unknown' by NaN<br/>df_cat_t.marital.replace(to_replace="unknown", value=np.nan, inplace=True)</span><span id="8043" class="mz lx it mv b gy nf nb l nc nd"># Imputation of missing values by modal value<br/>df_cat_t['marital'] = df_cat_t.marital.fillna(df_cat_t.marital.value_counts().index[0])</span><span id="5204" class="mz lx it mv b gy nf nb l nc nd"># Graph "pie"<br/>df_cat_t['marital'].value_counts(dropna=False).plot(kind='pie', figsize=(10,6), explode = (0.02, 0.02, 0.02), autopct='%1.1f%%', startangle=120);</span><span id="7608" class="mz lx it mv b gy nf nb l nc nd">print(f"Unique values: {df_cat_t.marital.nunique()}")</span></pre><p id="b5a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">同样，显示一个热编码和二进制编码将使用编码过程创建多少额外列的结果。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="d1e3" class="mz lx it mv b gy na nb l nc nd">df_marital = df_cat_t.marital<br/>marital_ohe = pd.get_dummies(df_marital)<br/>binary_encoder_marital = BinaryEncoder()<br/>marital_bin = binary_encoder_marital.fit_transform(df_marital)</span><span id="fb0a" class="mz lx it mv b gy nf nb l nc nd">print(f'''<br/>*Results*<br/>marital OHE: {marital_ohe.shape[1]} columns<br/>marital BIN: {marital_bin.shape[1]} columns''')</span><span id="e821" class="mz lx it mv b gy nf nb l nc nd">&gt;&gt; Output:<br/>*Results*<br/>marital OHE: 3 columns &lt;--- apply<br/>marital BIN: 3 columns</span></pre><p id="2775" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">此处应用一种热编码</strong>，因为与二进制编码相比，它保留了更多信息。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="be3d" class="mz lx it mv b gy na nb l nc nd">df_cat_t.drop(["marital"],axis=1,inplace=True)<br/>df_cat_t = pd.concat([df_cat_t,marital_ohe],axis=1)<br/>display(df_cat_t.head(2))<br/>display(df_cat_t.shape)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi os"><img src="../Images/0a69e85edd3c7d81c96365b34befa49f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AqEOO9K9dNssMD44RTlyDA.png"/></div></div></figure><h2 id="4097" class="mz lx it bd ly nj nk dn mc nl nm dp mg ld nn no mi lh np nq mk ll nr ns mm nt bi translated">变量:“教育”</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/c6ae2c85166779959d16fe7ef08c9662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*1Ko8XQENyc-LsrRGjKrkDQ.png"/></div></figure><p id="b4b5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们看的是同样的情况，其中“未知”被解释为缺少值。采用的策略是按最频繁值进行估算。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="fdaf" class="mz lx it mv b gy na nb l nc nd"># Replacing 'unknown' by NaN<br/>df_cat_t.education.replace(to_replace="unknown", value=np.nan, inplace=True)</span><span id="7e86" class="mz lx it mv b gy nf nb l nc nd"># Imputation of missing values by modal value<br/>df_cat_t['education'] = df_cat_t.education.fillna(df_cat_t.education.value_counts().index[0])</span><span id="7776" class="mz lx it mv b gy nf nb l nc nd"># Graph "pie"<br/>df_cat_t['education'].value_counts(dropna=False).plot(kind='pie', figsize=(10,6), explode = (0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01), autopct='%1.1f%%', startangle=0);</span><span id="08c5" class="mz lx it mv b gy nf nb l nc nd">print(f"Unique values: {df_cat_t.education.nunique()}")</span></pre><p id="e2fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">教育' '<strong class="kw iu"> </strong>有8个服从特定顺序的类，这意味着它将根据相同的等级进行编码。升序为:'文盲'，'基础. 4y '，' nasic.6y '，'基础. 9y '，'高中'，'专业.课程'，'大学.学位'。</p><p id="26dc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为此，我将应用一个地图功能。数据映射用于将一个序列中的一组特定值替换为另一组可能从一个函数、一个字典或一个序列中导出的值。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="37eb" class="mz lx it mv b gy na nb l nc nd">df_cat_t["education"] = df_cat_t.education.map({"university.degree":7, "professional.course":6, "high.school":5, "basic.9y":4, basic.6y":3, "basic.4y":2, "illiterate":1 })</span><span id="01dd" class="mz lx it mv b gy nf nb l nc nd">display(df_cat_t.education.value_counts())<br/>display(df_cat_t.head(2))<br/>display(df_cat_t.shape)</span><span id="3ff9" class="mz lx it mv b gy nf nb l nc nd">&gt;&gt; output:<br/>7    13899<br/>5     9515<br/>4     6045<br/>6     5243<br/>2     4176<br/>3     2292<br/>1       18</span></pre><h2 id="4908" class="mz lx it bd ly nj nk dn mc nl nm dp mg ld nn no mi lh np nq mk ll nr ns mm nt bi translated">变量:“默认”</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/c355af910a3e33a70a54343f70860c0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*crO5_Ju3znOcPF_wP5OZkw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ov"><img src="../Images/3ee1b1ed6ccaa2c71dfd0e0043b86d81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*97MVn0qNjSDAA5sX_wwyLg.png"/></div></div></figure><p id="e14c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这种情况下，“未知”值被解释为缺失值。“是”类是没有意义的，任何“未知”值的插补都可能严重损害所有结果。所以，还是去掉这个变量比较好。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="7108" class="mz lx it mv b gy na nb l nc nd">df_cat_t.drop(["default"], axis=1, inplace=True)<br/>display(df_cat_t.head(2))<br/>display(df_cat_t.shape)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ow"><img src="../Images/d2ae5c256eb29ae59cf6d672d046ebeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0xd0HjAfFAFW5qry8-1kGA.png"/></div></div></figure><h2 id="1288" class="mz lx it bd ly nj nk dn mc nl nm dp mg ld nn no mi lh np nq mk ll nr ns mm nt bi translated">变量:“poutcome”</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/d5c88c75ce37a89397e03bc24a590060.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*kc_jc4jQRHl0cHXEYylzHA.png"/></div></figure><p id="03cf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这种情况下，“不存在”被解释为相关值。要遵循的策略是不对这个变量进行任何转换。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="d46f" class="mz lx it mv b gy na nb l nc nd"># Encoding 'poutcome' OHE<br/>df_poutcome = df_cat_t.poutcome<br/>poutcome_ohe = pd.get_dummies(df_poutcome)<br/>binary_encoder_poutcome = BinaryEncoder()<br/>poutcome_bin = binary_encoder_poutcome.fit_transform(df_poutcome)</span><span id="6dc2" class="mz lx it mv b gy nf nb l nc nd">print(f'''<br/>*Results*<br/>poutcome OHE: {poutcome_ohe.shape[1]} columns<br/>poutcome BIN: {poutcome_bin.shape[1]} columns''')</span><span id="d423" class="mz lx it mv b gy nf nb l nc nd">&gt;&gt; Output:<br/>*Results*<br/>poutcome OHE: 3 columns &lt;--- Apply<br/>poutcome BIN: 3 columns</span><span id="50f9" class="mz lx it mv b gy nf nb l nc nd"># Remove 'poutcome' and concatenation poutcome_ohe</span><span id="eca8" class="mz lx it mv b gy nf nb l nc nd">df_cat_t.drop(["poutcome"],axis=1,inplace=True)<br/>df_cat_t = pd.concat([df_cat_t,poutcome_ohe],axis=1)<br/>display(df_cat_t.head(2))<br/>display(df_cat_t.shape)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi oy"><img src="../Images/a65135a188446d5b38bd2efc96e7e708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nYJPZkpPQRxn8brMTdSTyQ.png"/></div></div></figure><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="856a" class="mz lx it mv b gy na nb l nc nd"># Analysis of the transformed dataset<br/>display(df_cat_t.dtypes)<br/>print("")<br/>print(f"df_cat (original): ........ {df_cat.shape}")<br/>print(f"df_cat_t (transformed): ... {df_cat_t.shape}")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi oz"><img src="../Images/e97a22f18a4f71830215664dd81cea94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xp6LJiPfE4p2FCGc0N8JjQ.png"/></div></div></figure><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="9456" class="mz lx it mv b gy na nb l nc nd"># Concatenation of both numeric and categorical datasets<br/>df_numcat = pd.concat([df_cat_t,df_num], axis=1)</span><span id="a915" class="mz lx it mv b gy nf nb l nc nd"># Removing any NaN values<br/>df_numcat.dropna(how="any", axis=0)</span></pre><p id="23be" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这一阶段，在处理完所有缺失值和插补并将所有分类特征转化为数字特征后，让我们检查这些特征的相关性，确定并选择没有预测能力的变量。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="8f57" class="mz lx it mv b gy na nb l nc nd"># Subdivision of the target<br/>y_numcat = df_numcat.target<br/>X_numcat = df_numcat.drop(["target"], axis= "columns")</span><span id="a971" class="mz lx it mv b gy nf nb l nc nd"># Identifying all variables with great predictive power (Pearson Correlation p-value)<br/>dataframe = pd.DataFrame(<br/>      [scipy.stats.pearsonr(X_numcat[col], y_numcat) for col in X_numcat.columns],<br/>      columns=["Pearson Corr.", "p-value"],<br/>      index=X_numcat.columns,<br/>).round(2).sort_values(by="p-value", ascending=False)</span><span id="dfe0" class="mz lx it mv b gy nf nb l nc nd">display(dataframe)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi pa"><img src="../Images/5f335daad97a1880090096a268f773b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VPA1m0Dimoz0k6QEAgkmVA.png"/></div></div></figure><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="d970" class="mz lx it mv b gy na nb l nc nd"># Identifying columns in which p-value &gt; 0.05<br/>column = []<br/>for item in dataframe.index:<br/>    if dataframe['p-value'][item] &gt;= 0.05:<br/>        column.append(item)</span><span id="7820" class="mz lx it mv b gy nf nb l nc nd"># Removing statistically non significant columns<br/>df_numcat.drop(column, axis=1, inplace=True)</span><span id="c3d1" class="mz lx it mv b gy nf nb l nc nd">df_numcat</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi pb"><img src="../Images/ffe20b7f4714a2ae7fe426982dfea0d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wnf97sGLxgflESJ83SxMeQ.png"/></div></div></figure><p id="f78e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">就这样。我们已经准备好进行第三部分，也是最后一部分，肯定是我们项目中最激动人心的阶段，建模部分。在那里见。感谢阅读！</p><div class="pc pd gp gr pe pf"><a rel="noopener follow" target="_blank" href="/machine-learning-costs-prediction-of-a-marketing-campaign-exploratory-data-analysis-part-i-758b8f0ff5d4"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd iu gy z fp pk fr fs pl fu fw is bi translated">机器学习:营销活动的成本预测(探索性数据分析——第一部分)</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">预测营销活动最佳目标候选人的数据科学方法</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">towardsdatascience.com</p></div></div><div class="po l"><div class="pp l pq pr ps po pt ko pf"/></div></div></a></div><div class="pc pd gp gr pe pf"><a rel="noopener follow" target="_blank" href="/pandas-made-easy-the-guide-i-81834f075893"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd iu gy z fp pk fr fs pl fu fw is bi translated">熊猫变得容易(指南— I)</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">有许多最常用的函数和方法的例子</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">towardsdatascience.com</p></div></div><div class="po l"><div class="pu l pq pr ps po pt ko pf"/></div></div></a></div><p id="8e97" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想回顾这个项目的第一部分，EDA部分，<a class="ae lq" href="https://bit.ly/3lDzknU" rel="noopener ugc nofollow" target="_blank">点击这里</a>。<br/>你可以在这里找到这个项目<a class="ae lq" href="https://bit.ly/3hmI3YS" rel="noopener ugc nofollow" target="_blank">的全部代码。</a></p></div><div class="ab cl pv pw hx px" role="separator"><span class="py bw bk pz qa qb"/><span class="py bw bk pz qa qb"/><span class="py bw bk pz qa"/></div><div class="im in io ip iq"><h1 id="eedb" class="lw lx it bd ly lz qc mb mc md qd mf mg jz qe ka mi kc qf kd mk kf qg kg mm mn bi translated">联系人</h1><ul class=""><li id="a5b1" class="nu nv it kw b kx mo la mp ld qh lh qi ll qj lp nz oa ob oc bi translated"><a class="ae lq" href="http://bit.ly/2ybRqYT" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="a1dc" class="nu nv it kw b kx od la oe ld of lh og ll oh lp nz oa ob oc bi translated"><a class="ae lq" href="https://bit.ly/3gAwMTP" rel="noopener ugc nofollow" target="_blank">推特</a></li><li id="1152" class="nu nv it kw b kx od la oe ld of lh og ll oh lp nz oa ob oc bi translated"><a class="ae lq" href="https://bit.ly/3gDC5Sp" rel="noopener ugc nofollow" target="_blank">中型</a></li><li id="c751" class="nu nv it kw b kx od la oe ld of lh og ll oh lp nz oa ob oc bi translated"><a class="ae lq" href="https://bit.ly/3hHvuHR" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li><li id="0262" class="nu nv it kw b kx od la oe ld of lh og ll oh lp nz oa ob oc bi translated"><a class="ae lq" href="https://bit.ly/31Co038" rel="noopener ugc nofollow" target="_blank">卡格尔</a></li><li id="7a7e" class="nu nv it kw b kx od la oe ld of lh og ll oh lp nz oa ob oc bi translated"><a class="ae lq" href="mailto:goncaloggomes@gmail.com" rel="noopener ugc nofollow" target="_blank">电子邮件</a></li></ul><p id="c4c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">好的阅读，伟大的编码！</p></div></div>    
</body>
</html>