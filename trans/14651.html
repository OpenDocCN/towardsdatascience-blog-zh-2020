<html>
<head>
<title>[Machine Learning] How to do feature selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">【机器学习】如何做特征选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-how-to-do-the-feature-selection-2de56182cd9b?source=collection_archive---------26-----------------------#2020-10-09">https://towardsdatascience.com/machine-learning-how-to-do-the-feature-selection-2de56182cd9b?source=collection_archive---------26-----------------------#2020-10-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ab28" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">成为一名数据科学家。</h2><div class=""/><div class=""><h2 id="18a3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">你的第一份数据科学相关工作的一个重要问题</h2></div><p id="4362" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">当我参加一个数据科学相关工作的面试时，面试官问了我以下问题。事后我在面试的时候也问了应聘者同样的问题:给定一个大型数据集(1000多列，100000行(记录))，你会如何选择有用的特征来建立(监督)模型？</p><p id="535c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是一个很好的问题，可以区分你的数据科学知识是学生水平还是专业水平。当你是一名学生时，你从一个美丽而干净的数据集中学习算法。然而，在商业世界中，数据科学家在数据清洗方面投入了大量精力，以建立机器学习模型。</p><p id="8c04" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">回到我们的问题:</p><blockquote class="ln lo lp"><p id="06cf" class="kr ks lq kt b ku kv kd kw kx ky kg kz lr lb lc ld ls lf lg lh lt lj lk ll lm im bi translated">给定一个大型数据集(超过1000列，10000行(记录))，如何选择有用的特征来构建(监督)模型？</p></blockquote><p id="74a6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">事实上，这个问题没有绝对的答案，不过是测试你的逻辑思维和解释能力。在这篇文章中，我将分享一些方法(特性选择)来处理它。</p><p id="044a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae lu" href="https://www.kaggle.com/kkhuiaa/feature-selection-notebook" rel="noopener ugc nofollow" target="_blank"> Kaggle笔记本上传到这里</a>，这里我使用的数据集是<a class="ae lu" href="https://www.kaggle.com/c/prudential-life-insurance-assessment" rel="noopener ugc nofollow" target="_blank">保诚人寿承保数据</a>:</p><div class="lv lw gp gr lx ly"><a href="https://www.kaggle.com/kkhuiaa/feature-selection-notebook" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd jd gy z fp md fr fs me fu fw jc bi translated">功能选择笔记本</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自保诚人寿保险评估的数据</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.kaggle.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm mn ly"/></div></div></a></div><p id="cc68" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">此任务旨在预测人寿保险投保人的风险水平(承保)。关于特性选择的更多实现，您也可以查看<a class="ae lu" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>文章。</p><p id="6b62" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">首先，我们读取数据:</p><figure class="mo mp mq mr gt ms"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="mo mp mq mr gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mv"><img src="../Images/97508bccf8a708bef064d69894c8a8e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Me_UcuumIm6bsa91alydQ.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><p id="22ae" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这里，我将做一些简单的数据清理。大多数机器学习模型实现不接受字符串输入，因此我们必须将它们转换成数值。由于我们的目标是有序目标(即监督学习)，通过基本的OneHotEncoder转换分类变量会遭受“维数灾难”(通常在模型训练中也需要更多时间)。</p><p id="b757" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">相反，我们对分类列所做的如下:基于它的分类值，我们计算Y目标的相应平均值(通过“GroupBy”)并对它进行排序，从0到该列的唯一分类值的数量减1。这种映射可用于测试数据或以后的生产。</p><p id="7dc3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然后，我们按照标准程序填写缺失值:</p><figure class="mo mp mq mr gt ms"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="mo mp mq mr gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nf"><img src="../Images/86502a73f024e437fb877c209321be28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SJBMqrmOixHx4GJ2Wo7m6g.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><h1 id="6a1f" class="ng nh it bd ni nj nk nl nm nn no np nq ki nr kj ns kl nt km nu ko nv kp nw nx bi translated">0.足球队选拔的类比</h1><p id="cdac" class="pw-post-body-paragraph kr ks it kt b ku ny kd kw kx nz kg kz la oa lc ld le ob lg lh li oc lk ll lm im bi translated">假设你有200名足球运动员，你想选择其中的11人组成最好的足球队。你会如何选择他们？</p><figure class="mo mp mq mr gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi od"><img src="../Images/23128314fcc62985a277d9b25227f1b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KyETgk8ig_mzKkH_"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated"><a class="ae lu" href="https://buffer.com/library/free-images/" rel="noopener ugc nofollow" target="_blank"> unsplash照片，由Alora Griffiths上传</a></p></figure><h1 id="5bf5" class="ng nh it bd ni nj nk nl nm nn no np nq ki nr kj ns kl nt km nu ko nv kp nw nx bi translated">1.无监督方法</h1><p id="b55c" class="pw-post-body-paragraph kr ks it kt b ku ny kd kw kx nz kg kz la oa lc ld le ob lg lh li oc lk ll lm im bi translated">在足球运动员选择的类比中，无监督方法评估每个运动员的基本信息，如身高、身体质量指数、年龄和其他健康指标。这些都不是足球特有的(无人监管)，但绝大多数优秀的足球运动员都应该有很好的身体基础。</p><ul class=""><li id="b879" class="oe of it kt b ku kv kx ky la og le oh li oi lm oj ok ol om bi translated"><strong class="kt jd">删除丢失率高的列</strong> <br/>第一种也是最简单的方法是在无监督的方法中删除列。我们可以删除缺少太多值的列。</li></ul><figure class="mo mp mq mr gt ms"><div class="bz fp l di"><div class="mt mu l"/></div></figure><pre class="mo mp mq mr gt on oo op oq aw or bi"><span id="0529" class="os nh it oo b gy ot ou l ov ow">(59381, 127)<br/>(59381, 126)</span></pre><ul class=""><li id="c9db" class="oe of it kt b ku kv kx ky la og le oh li oi lm oj ok ol om bi translated"><strong class="kt jd">删除差异小的列</strong> <br/>另一种方法是删除差异太小的列，因为这些列通常提供的信息很少。</li></ul><figure class="mo mp mq mr gt ms"><div class="bz fp l di"><div class="mt mu l"/></div></figure><pre class="mo mp mq mr gt on oo op oq aw or bi"><span id="8c67" class="os nh it oo b gy ot ou l ov ow">number of columns after dropping by variance threshold: 16</span></pre><ul class=""><li id="ee4b" class="oe of it kt b ku kv kx ky la og le oh li oi lm oj ok ol om bi translated"><strong class="kt jd"> PCA </strong> <br/> PCA是一种更高级的执行特征选择的方式。主要优点是变换后的特征现在是独立的；然而，转换后的特征很难解释。关于Scikit-learn的PCA实现，您可以查看<a class="ae lu" href="https://stackabuse.com/implementing-pca-in-python-with-scikit-learn/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</li></ul></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><h1 id="e869" class="ng nh it bd ni nj pe nl nm nn pf np nq ki pg kj ns kl ph km nu ko pi kp nw nx bi translated">2.监督方法</h1><p id="89b4" class="pw-post-body-paragraph kr ks it kt b ku ny kd kw kx nz kg kz la oa lc ld le ob lg lh li oc lk ll lm im bi translated">更复杂的方法是通过监督学习来实现。回到我们对足球队选择的类比，我们分两轮进行:</p><p id="6e7b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在第一轮比赛中，我们对每个球员的足球技能(监督下)进行评估，如点球，射门，短传能力，并进行排名。假设我们现在可以从200名选手中选出前50名选手。</p><p id="5705" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">第二轮，既然要在50个玩家中找出11个玩家的最佳<strong class="kt jd">组合，就需要评估这50个玩家会如何合作。我们将最终找到最好的11名球员。(为什么不直接做第二轮？运行每个迭代需要很多时间，所以我们需要在第一轮进行初步测试。)</strong></p><p id="f6ac" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">从技术上讲，第一轮是<strong class="kt jd">“按模型选择特征”</strong>，第二轮是<strong class="kt jd">“递归特征消除”(RFE) </strong>。现在让我们回到机器学习和编码。</p><ul class=""><li id="d3bd" class="oe of it kt b ku kv kx ky la og le oh li oi lm oj ok ol om bi translated"><strong class="kt jd">基于模型的特征选择<br/> </strong>一些ML模型被设计用于特征选择，例如基于L1的线性回归和<strong class="kt jd"> Ext </strong> remely <strong class="kt jd"> Ra </strong>随机化<strong class="kt jd">树</strong> (Extra-trees model)。与L2正则化相比，L1正则化倾向于将不重要特征的参数强制为零。(知道为什么吗？)极度随机化的树随机地分裂叶子(不是通过信息增益或熵)。重要的特征应该仍然比不重要的特征更重要(通过基于杂质的特征重要性来测量)。<br/> <br/>我们用三个模型来评估它:</li></ul><figure class="mo mp mq mr gt ms"><div class="bz fp l di"><div class="mt mu l"/></div></figure><pre class="mo mp mq mr gt on oo op oq aw or bi"><span id="200d" class="os nh it oo b gy ot ou l ov ow">CPU times: user 15.9 s, sys: 271 ms, total: 16.2 s<br/>Wall time: 14.3 s</span><span id="6c7b" class="os nh it oo b gy pj ou l ov ow">========== LogisticRegression ==========<br/>Accuracy in training: 0.4138598854833277<br/>Accuracy in valid: 0.41020945163666983<br/>Show top 10 important features:</span></pre><figure class="mo mp mq mr gt ms gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/c671e79de1ff64ba0a267104fefe0701.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*ed-lTaniHsCbIfWgjYCmhQ.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><pre class="mo mp mq mr gt on oo op oq aw or bi"><span id="ee56" class="os nh it oo b gy ot ou l ov ow">========== ExtraTreesClassifier ==========<br/>Accuracy in training: 0.3467497473896935<br/>Accuracy in valid: 0.3467213977476055<br/>Show top 10 important features:</span></pre><figure class="mo mp mq mr gt ms gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/826a915e3d1503ad7cd61fcd1d6e8bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*Z6WRu39APhd6PLnNKMTQEQ.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><pre class="mo mp mq mr gt on oo op oq aw or bi"><span id="c704" class="os nh it oo b gy ot ou l ov ow">========== RandomForestClassifier ==========<br/>Accuracy in training: 0.3473391714381947<br/>Accuracy in valid: 0.34581622987053995<br/>Show top 10 important features:</span></pre><figure class="mo mp mq mr gt ms gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/b0e1834ae56a802a0e566d6919f63bd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*n1dpXDttrQ4F5o_Bb56JUQ.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><p id="b679" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们还为每个模型绘制了模型重要性排名:</p><figure class="mo mp mq mr gt ms gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/f6bb0ab10cab7c402e6b23d735de59f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*o4Wd67WFC2frzGvp1vfarw.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><p id="8a7e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由于基于L1的逻辑回归具有最高的准确性，因此我们将仅通过逻辑回归选择(从图中)前60个特征:</p><p id="16b9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">selected _ model = ' logistic regression '<br/>number _ of _ features = 60<br/>selected _ features _ by _ model = importance _ fatures _ sorted _ all[importance _ fatures _ sorted _ all[' model ']= = selected _ model]。索引[:特征数量]。tolist()</p><ul class=""><li id="578d" class="oe of it kt b ku kv kx ky la og le oh li oi lm oj ok ol om bi translated"><strong class="kt jd">递归特征消除(RFE) </strong> <br/>第二部分是选择<strong class="kt jd">最佳特征组合</strong>。我们通过<strong class="kt jd">“递归特征消除”(RFE) </strong>来实现。我们不是构建一个模型，而是构建n个模型(其中n =特征的数量)。在第一次迭代中，我们通过所有60个特征来训练模型，并计算交叉验证准确性和所有列的特征重要性。然后我们去掉最不重要的特征，所以我们现在有59个特征。基于这59个特征，我们重复上述过程，并且我们在最后一个单个特征处结束。这种方法需要时间，但会给你一个可靠的特征重要性排序。如果时间不允许用于大型数据集，可以考虑在每次迭代中采样或丢弃更多要素。</li></ul><figure class="mo mp mq mr gt ms"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="mo mp mq mr gt ms gh gi paragraph-image"><div class="gh gi po"><img src="../Images/daf29e228e23a794833bafe81ba65930.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*HrYcbtIHhNSQvziNOZN8Sw.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><pre class="mo mp mq mr gt on oo op oq aw or bi"><span id="5369" class="os nh it oo b gy ot ou l ov ow">CPU times: user 7min 2s, sys: 334 ms, total: 7min 2s<br/>Wall time: 26min 32s</span></pre><p id="7100" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如你所见，随着更多特征的训练，验证准确度将最终饱和(大约0.475)。我们现在可以查看我们的功能重要性排名:</p><figure class="mo mp mq mr gt ms"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="mo mp mq mr gt ms gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/7399acc6e1e7cb50114d2107bd302998.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*0HDfPuK02_CMtvgbl564WA.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><p id="b41d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">同样，没有黄金法则来执行特征选择。在生产的商业世界中，我们必须平衡硬件能力、所需时间、模型的稳定性和模型性能。找到最佳的列组合后，我们现在可以选择最佳的超参数集。</p></div></div>    
</body>
</html>