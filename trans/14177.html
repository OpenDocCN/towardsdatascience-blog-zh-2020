<html>
<head>
<title>Decoding: State Of The Art Recommender System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解码:最先进的推荐系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decoding-state-of-the-art-recommender-system-38ee800f6fe?source=collection_archive---------13-----------------------#2020-09-30">https://towardsdatascience.com/decoding-state-of-the-art-recommender-system-38ee800f6fe?source=collection_archive---------13-----------------------#2020-09-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="1d6c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">"<a class="ae ko" href="https://assets.amazon.science/96/71/d1f25754497681133c7aa2b7eb05/temporal-contextual-recommendation-in-real-time.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="js iu"/></a><strong class="js iu">"</strong>被<strong class="js iu"> </strong>宣布为应用数据科学领域的最佳论文，最近在2020年8月23日至27日举行的<a class="ae ko" href="https://www.kdd.org/kdd2020/" rel="noopener ugc nofollow" target="_blank"> SIGKDD-2020 </a>中。在这篇博客中，我将介绍<strong class="js iu"> HRNN元</strong>推荐模型的关键部分，该模型在各种数据集上实现了最先进的性能，并在<a class="ae ko" href="https://github.com/quankiquanki/skytrax-reviews-dataset" rel="noopener ugc nofollow" target="_blank">sky trax-reviews-dataset</a>上对HRNN和HRNN元模型进行了比较，以实现个性化的航空公司推荐。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/4f4470b86c44cc93b4f7d25c1288e6ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R1r6yc-nbCxtldaZG52Qfw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">均方根误差:20米电影镜头和网飞[ <strong class="bd lf">越低越好</strong> ]的Sqrt((真实评分-预测评分) )，图片由作者提供</p></figure><p id="89f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">HRNN-梅塔</strong>有效且高效地结合了以下主要思想，用于能够适应不同使用情况的black-bok推荐系统</p><ol class=""><li id="c8b5" class="lg lh it js b jt ju jx jy kb li kf lj kj lk kn ll lm ln lo bi translated">用于会话间和会话内动态的分级递归神经网络(<strong class="js iu"> HRNN </strong>)。</li><li id="d960" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn ll lm ln lo bi translated">字段因子分解机器(<strong class="js iu"> FFM </strong>)从元中提取丰富的上下文特征。</li><li id="7ae7" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn ll lm ln lo bi translated"><strong class="js iu">反馈编码</strong>理解隐含否定。</li><li id="7697" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn ll lm ln lo bi translated">使用<strong class="js iu">采样</strong>的高效训练技术。</li></ol><h1 id="160d" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">HRNN:</h1><p id="f766" class="pw-post-body-paragraph jq jr it js b jt ms jv jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">推荐系统已经从矩阵分解发展到关注两个重要的来源1)事件的时间顺序2)用户/项目元。事件的时间顺序用序列网络建模，如<a class="ae ko" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"> LSTM或GRU或香草RNN </a>。这些网络基于用户历史预测用户可能与之交互的下一个项目的概率，但可能会发现由于消失梯度而对长时间用户会话建模具有挑战性。</p><p id="1ca3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了对长会话建模，通过考虑不活动时段或使用任何其他事件，将会话划分为短会话。</p><p id="2af2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过使用两个序列网络来学习用户和会话表示，建议使用分层网络来模拟这些长用户会话，如下图所示。在第一个会话期间，用户状态被随机初始化，在会话结束时，SessionRNN初始化用户表示，如第一个图像所示，这又初始化了SessionRNN中下一个会话的状态，如第二个图像所示，并且还可以在整个第二个会话中使用，如第三个图像所示。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mx"><img src="../Images/08d17725c225ef0aeed96d43203aff03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RTwdXZRNnBo4s7leKlBt-A.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来自<a class="ae ko" href="https://youtu.be/M7FqgXySKYk" rel="noopener ugc nofollow" target="_blank">https://youtu.be/M7FqgXySKYk</a>[21:52]</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi my"><img src="../Images/37c37eefe37eb5c11ba5d9a4cd65c8ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*32S9nFoY0zQqwjNAmRSOzQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来自https://youtu.be/M7FqgXySKYk<a class="ae ko" href="https://youtu.be/M7FqgXySKYk" rel="noopener ugc nofollow" target="_blank"/>[22:25]</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mz"><img src="../Images/8977e0d752a15e6eba2adaf4335421f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ndY2PA1JIo0tzfPKRB-f8g.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来自https://youtu.be/M7FqgXySKYk<a class="ae ko" href="https://youtu.be/M7FqgXySKYk" rel="noopener ugc nofollow" target="_blank"/>[22:54]</p></figure><p id="08c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">想了解更多关于HRNN的细节，请看Alexandros Karatzoglou的精彩视频<a class="ae ko" href="https://youtu.be/M7FqgXySKYk" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="6ac9" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">FFM:</h1><p id="8515" class="pw-post-body-paragraph jq jr it js b jt ms jv jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated"><em class="na">“HRNN被扩展为包括用户和物品特征，如位置、物品价格等，通过场感知多层感知将上下文信息堆叠在相应的用户/物品潜在向量之上，这种扩展我们称为HRNN元。”【</em><a class="ae ko" href="https://assets.amazon.science/96/71/d1f25754497681133c7aa2b7eb05/temporal-contextual-recommendation-in-real-time.pdf" rel="noopener ugc nofollow" target="_blank"><em class="na">1</em></a><em class="na">】</em></p><p id="1291" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在因式分解机器中，每个特征只有一个潜在向量来学习潜在效果，而在场感知因式分解机器中，每个特征有几个潜在向量，并且根据其他特征的场，其中一个用于做内积。</p><p id="8ed5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，考虑三个特征ESPN、Vogue和NBC，属于领域<strong class="js iu">出版商</strong>，而另外三个特征耐克、古驰和阿迪达斯，属于领域<strong class="js iu">广告商</strong>。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nb"><img src="../Images/0b89be8a1d591ac859820c6f925f8727.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LeXaHmhrSI3x5tn3ZbsiuQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来自[ <a class="ae ko" href="https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf" rel="noopener ugc nofollow" target="_blank"> 5 </a></p></figure><p id="ca5c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">FM→wes pn w Nike+wes pn w male+w Nike w male。</p><p id="9444" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">FFM →威斯普，一个女的，P +威斯普，G男的，P +女的，G男的，一个</p><p id="f32a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该原始数据首先被转换为libffm格式，然后在馈送到网络之前被转换为one-hot编码。</p><p id="c2ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">LIBFFM的数据格式为:</p><p id="2be0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><label><field1>:<feature1>:<value1>:<field2>:<feature2>:<value2>…</value2></feature2></field2></value1></feature1></field1></label></p><p id="86bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了将原始数据转换为FFM格式，我们构建了两个字典，一个用于字段，一个用于要素</p><pre class="kq kr ks kt gt nc nd ne nf aw ng bi"><span id="ee18" class="nh lv it nd b gy ni nj l nk nl"><strong class="nd iu">#Field Dictionary<br/></strong>DictField[Publisher]  -&gt; 0<br/>DictField[Advertiser] -&gt; 1<br/>DictField[Gender] -&gt; 2</span><span id="059e" class="nh lv it nd b gy nm nj l nk nl"><strong class="nd iu">#Feature Dictionary<br/></strong>DictFeature[Publisher-ESPN]  -&gt; 0<br/>DictFeature[Publisher-Vogue]  -&gt; 1<br/>DictFeature[Publisher-NBC]  -&gt; 2<br/>DictFeature[Advertiser-Nike] -&gt; 3<br/>DictFeature[Advertiser-Gucci] -&gt; 4<br/>DictFeature[Advertiser-Adidas] -&gt; 5<br/>DictFeature[Gender-Female] -&gt; 6<br/>DictFeature[Gender-Male] -&gt; 7</span><span id="cd24" class="nh lv it nd b gy nm nj l nk nl"><strong class="nd iu">#Tranforming above example to FFM Format</strong><br/>1 0:0:1 1:3:1 2:7:1 (since all features are cateogorical, the values are all ones)</span></pre><h1 id="4c03" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">反馈编码</h1><p id="6089" class="pw-post-body-paragraph jq jr it js b jt ms jv jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">连同用户特征、反馈事件(例如，评级、购买、成本、观看持续时间等。)被连接作为输入上下文来预测下一项，如下面的HRNN元单元格所示。这提供了对隐式负面的更好的响应，如没有任何点击的刷新、内容打开但没有视频视图等。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/b8f26f79344dcb67b053958f0a2c3f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*l81hvJCCuIUbnvtN217mRA.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">HRNN-meta单元格，图像来自[ <a class="ae ko" href="https://assets.amazon.science/96/71/d1f25754497681133c7aa2b7eb05/temporal-contextual-recommendation-in-real-time.pdf" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]</p></figure><h1 id="989c" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">抽样</h1><p id="b0cc" class="pw-post-body-paragraph jq jr it js b jt ms jv jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">计算softmax以找出大词汇量中下一个项目的概率在计算上是具有挑战性的，并且在文献中提出了各种采样策略以利用softmax进行有效训练，例如:<strong class="js iu">噪声对比估计、重要性采样、负采样</strong>等。有两种方法</p><ul class=""><li id="17a8" class="lg lh it js b jt ju jx jy kb li kf lj kj lk kn no lm ln lo bi translated">软最大近似值</li><li id="7a25" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn no lm ln lo bi translated">基于抽样的</li></ul><p id="8e49" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所有基于采样的方法都使用一些其他损失来近似softmax，这对于计算是有效的，并且在训练时最有用。</p><p id="d7e5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">关于抽样策略的更多细节，请看看来自<a class="ae ko" href="https://ruder.io/word-embeddings-softmax/" rel="noopener ugc nofollow" target="_blank"> Sebastian Ruder </a>的精彩博客。HRNN依赖于<strong class="js iu">负采样</strong>，其中<strong class="js iu"> </strong>是噪声对比估计的近似值，并将softmax转换为逻辑损失。通过将项目频率提高到0.75次幂来对负项目进行采样。</p><p id="2ebd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> HRNN元</strong>是<strong class="js iu"> </strong>目前在<a class="ae ko" href="https://docs.aws.amazon.com/personalize/latest/dg/native-recipe-hrnn-metadata.html" rel="noopener ugc nofollow" target="_blank">亚马逊个性化</a>中可用，下图显示了它是如何工作的。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi np"><img src="../Images/918f03500745cb81ff63db515897c55d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4tsvLlAWwaPUHoMWt6Q5VA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:<a class="ae ko" href="https://aws.amazon.com/personalize/" rel="noopener ugc nofollow" target="_blank">https://aws.amazon.com/personalize/</a></p></figure><p id="9bb0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们在<a class="ae ko" href="https://github.com/quankiquanki/skytrax-reviews-dataset" rel="noopener ugc nofollow" target="_blank">sky trax-reviews-dataset</a>上使用Amazon Personalize对HRNN-meta w.r.t HRNN进行了快速检查，该数据集有大约41.4K条航空公司评论，用于基于用户历史和评论的个性化航空公司推荐。为了使用Amazon Personalize训练一个HRNN模型和<strong class="js iu">HRNN-梅塔</strong>模型，在创建一个环境后，我们按照<a class="ae ko" href="https://github.com/aws-samples/amazon-personalize-samples/blob/master/next_steps/workshops/Immersion_Day/personalize_hrnn_metadata_contextual_example.ipynb" rel="noopener ugc nofollow" target="_blank">个性化样本</a>进行上下文推荐，使用HRNN-梅塔vs HRNN的离线指标结果非常令人印象深刻，如下图所示。</p><ul class=""><li id="e916" class="lg lh it js b jt ju jx jy kb li kf lj kj lk kn no lm ln lo bi translated"><strong class="js iu">~ 80%</strong><a class="ae ko" href="https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html" rel="noopener ugc nofollow" target="_blank">覆盖率提高</a>，</li><li id="6a62" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn no lm ln lo bi translated"><a class="ae ko" href="https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html" rel="noopener ugc nofollow" target="_blank">中的<strong class="js iu"> ~17% </strong>表示倒数排名和ndcg </a>，</li><li id="f6d8" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn no lm ln lo bi translated"><strong class="js iu">~ 14%</strong><a class="ae ko" href="https://docs.aws.amazon.com/personalize/latest/dg/working-with-training-metrics.html" rel="noopener ugc nofollow" target="_blank">精度提高</a>。</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/ce9700cd5a3eebdc0848f1f088355946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*cgivs3VaTirAQftcKABjIQ.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">HRNN-meta vs HRNN离线指标比较，图片由作者提供</p></figure><p id="9f78" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你觉得这很有趣，并想训练HRNN元，请跟随<a class="ae ko" href="https://github.com/aws-samples/amazon-personalize-samples/tree/master/getting_started" rel="noopener ugc nofollow" target="_blank">开始亚马逊个性化样本</a>，它将带你从环境创建到在定制数据集上训练推荐器模型。</p><h1 id="1839" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">结论</h1><p id="7fe8" class="pw-post-body-paragraph jq jr it js b jt ms jv jw jx mt jz ka kb mu kd ke kf mv kh ki kj mw kl km kn im bi translated">HRNN元通过有效地将基于会话的推荐与场感知因子分解相结合来提供情境化的推荐，从而提供了一种高效/有效的推荐解决方案。还提供了各种方法，如<strong class="js iu">项目趋势分解</strong>来改善冷启动项目推荐。探索像<a class="ae ko" href="https://arxiv.org/abs/1904.06690" rel="noopener ugc nofollow" target="_blank"> BERT4Rec </a>这样的其他最近的方法将会很有趣，并且也可以看到用<a class="ae ko" href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" rel="noopener ugc nofollow" target="_blank">变压器</a>代替GRUs的潜力。</p><p id="5063" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢您阅读这篇文章，我希望这对您有所帮助。如果你有，请在你最喜欢的社交媒体上分享，这样其他人也可以找到它。此外，如果有不清楚或不正确的地方，请在评论区告诉我们。</p><h1 id="de6a" class="lu lv it bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">参考:</h1><ol class=""><li id="9bff" class="lg lh it js b jt ms jx mt kb nr kf ns kj nt kn ll lm ln lo bi translated"><a class="ae ko" href="https://assets.amazon.science/96/71/d1f25754497681133c7aa2b7eb05/temporal-contextual-recommendation-in-real-time.pdf" rel="noopener ugc nofollow" target="_blank">https://assets . Amazon . science/96/71/d1f 25754497681133 c 7 aa 2 b 7 EB 05/temporal-contextual-recommendation-in-real-time . pdf</a></li><li id="5d98" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn ll lm ln lo bi translated"><a class="ae ko" href="https://aws.amazon.com/personalize/" rel="noopener ugc nofollow" target="_blank">https://aws.amazon.com/personalize/</a></li><li id="4bb4" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn ll lm ln lo bi translated"><a class="ae ko" href="https://www.slideshare.net/AmazonWebServices/add-realtime-personalization-and-recommendations-to-your-applications-aim395-aws-reinvent-2018" rel="noopener ugc nofollow" target="_blank">https://www . slide share . net/Amazon web services/add-real time-personal ization-and-recommendation-to-your-applications-aim 395-AWS-reinvent-2018</a></li><li id="ace5" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn ll lm ln lo bi translated"><a class="ae ko" href="https://openreview.net/pdf?id=ByzxsrrkJ4" rel="noopener ugc nofollow" target="_blank">https://openreview.net/pdf?id=ByzxsrrkJ4</a></li><li id="3fc0" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn ll lm ln lo bi translated"><a class="ae ko" href="https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf" rel="noopener ugc nofollow" target="_blank">https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf</a></li><li id="dfc7" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn ll lm ln lo bi translated"><a class="ae ko" href="https://github.com/ycjuan/libffm" rel="noopener ugc nofollow" target="_blank">https://github.com/ycjuan/libffm</a></li><li id="ff0f" class="lg lh it js b jt lp jx lq kb lr kf ls kj lt kn ll lm ln lo bi translated"><a class="ae ko" href="https://arxiv.org/pdf/1602.02410.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1602.02410.pdf</a></li></ol></div></div>    
</body>
</html>