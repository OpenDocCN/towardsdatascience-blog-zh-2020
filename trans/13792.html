<html>
<head>
<title>Deep Learning With Weighted Cross Entropy Loss On Imbalanced Tabular Data Using FastAI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于FastAI的不平衡表格数据加权交叉熵损失深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-with-weighted-cross-entropy-loss-on-imbalanced-tabular-data-using-fastai-fe1c009e184c?source=collection_archive---------12-----------------------#2020-09-22">https://towardsdatascience.com/deep-learning-with-weighted-cross-entropy-loss-on-imbalanced-tabular-data-using-fastai-fe1c009e184c?source=collection_archive---------12-----------------------#2020-09-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="69ca" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">轻松构建深度学习模型同时避免陷阱的指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fb175f15b2c4e19f53efdf1ecc253743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eYiszUq4wh4YKcQN"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@aditya_pi2xl?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Aditya Das </a>拍摄</p></figure><p id="345f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">FastAI是一个非常方便和强大的机器学习库，将深度学习(DL)带给大众。我写这篇文章的动机是为了解决与训练二进制分类任务的模型相关的一些问题。我的目标是向您介绍使用FastAI为一个<strong class="ky ir"> <em class="ls">表格</em> </strong>，<strong class="ky ir"> <em class="ls">不平衡</em> </strong>数据集构建一个简单有效的DL模型所需的步骤，同时避免我曾经犯过的错误。本文中的讨论是根据下面列出的部分组织的。</p><ol class=""><li id="ecdf" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">资料组</li><li id="d292" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">示例代码</li><li id="230b" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">代码分解</li><li id="2ef8" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">FastAI与PySpark ML &amp; Scikit-Learn的比较</li><li id="f611" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">结论</li></ol></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h1 id="526e" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">1.资料组</h1><p id="a24f" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">数据集来自ad转换的上下文，其中<strong class="ky ir"> <em class="ls">二进制</em> </strong> <strong class="ky ir"> <em class="ls">目标变量</em> </strong> 1和0对应转换成功和失败。这个专有数据集(不，我没有权利)有一些特别有趣的属性，因为它的维度、类别不平衡以及特征和目标变量之间相当弱的关系。</p><p id="d705" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，数据的维度:这个表格数据集包含相当大量的记录和<strong class="ky ir"> <em class="ls">分类特征</em> </strong>，它们具有非常高的<strong class="ky ir"><em class="ls"/></strong>。</p><p id="db38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls">注</em> </strong>:在FastAI中，分类特征使用<strong class="ky ir"> <em class="ls">嵌入</em> </strong>来表示，这样可以提高高基数特征的分类性能。</p><p id="aeea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">二、二进制<strong class="ky ir"> <em class="ls">类标签</em> </strong>高度<strong class="ky ir"><em class="ls"/></strong>不平衡由于成功的广告转换比较少见。在本文中，我们通过算法级方法(加权交叉熵损失函数)来适应这种约束，而不是数据级方法(重采样)。</p><p id="f8a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">三、<strong class="ky ir"> <em class="ls">关系</em><em class="ls">特征</em> </strong>与<strong class="ky ir"> <em class="ls">目标变量</em> </strong>之间的 是相当弱的 。例如，在显著的模型调整后，逻辑回归模型的ROC曲线下的验证面积为0.74。</p><h2 id="b44c" class="nl mp iq bd mq nm nn dn mu no np dp my lf nq nr na lj ns nt nc ln nu nv ne nw bi translated">数据集属性摘要</h2><ul class=""><li id="3c2c" class="lt lu iq ky b kz ng lc nh lf nx lj ny ln nz lr oa lz ma mb bi translated">维度:17个特征，1个目标变量，3738937行</li><li id="1b65" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr oa lz ma mb bi translated">二元目标类</li><li id="4148" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr oa lz ma mb bi translated">阶层失衡比例为1:87</li><li id="bae3" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr oa lz ma mb bi translated">6个数字特征</li><li id="d6ca" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr oa lz ma mb bi translated">8个分类特征</li><li id="7fcc" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr oa lz ma mb bi translated">分类要素的组合基数为44，000</li></ul><h1 id="d368" class="mo mp iq bd mq mr ob mt mu mv oc mx my jw od jx na jz oe ka nc kc of kd ne nf bi translated">2.示例代码</h1><p id="68ef" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">这段代码是在<strong class="ky ir"> <em class="ls"> Google Cloud — AI平台</em> </strong>上的<strong class="ky ir"> <em class="ls"> Jupyter Lab </em> </strong>笔记本上运行的，规格如下。</p><ul class=""><li id="3e16" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr oa lz ma mb bi translated">4个N1标准vCPUs，15 GB内存</li><li id="60a9" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr oa lz ma mb bi translated">1个英伟达特斯拉P4 GPU</li><li id="1824" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr oa lz ma mb bi translated">环境:PyTorch 1.4</li><li id="4657" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr oa lz ma mb bi translated">操作系统:Debian 9</li></ul><p id="635e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型培训管道将在下一节中解释，如下所示。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用于表格数据二进制分类的FastAI流水线</p></figure><h1 id="1802" class="mo mp iq bd mq mr ob mt mu mv oc mx my jw od jx na jz oe ka nc kc of kd ne nf bi translated">3.代码分解</h1><h2 id="edd5" class="nl mp iq bd mq nm nn dn mu no np dp my lf nq nr na lj ns nt nc ln nu nv ne nw bi translated">导入包</h2><p id="3d58" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">通过命令终端安装<code class="fe oi oj ok ol b">fastai</code>和<code class="fe oi oj ok ol b">fastbook</code>。有关设置的更多详细信息，请查看此<a class="ae kv" href="https://course.fast.ai/start_gcp" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="750c" class="nl mp iq ol b gy oq or l os ot">conda install -c fastai -c pytorch fastai<br/>git clone https://github.com/fastai/fastbook.git<br/>pip install -Uqq fastbook</span></pre><p id="6f09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将FastAI库和熊猫导入笔记本。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="1cfd" class="nl mp iq ol b gy oq or l os ot">import pandas as pd <br/>from fastai.tabular.all import *</span></pre><h2 id="6f6e" class="nl mp iq bd mq nm nn dn mu no np dp my lf nq nr na lj ns nt nc ln nu nv ne nw bi translated">按要素类型加载数据和分组列名</h2><p id="8f93" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">由于隐私原因，列名必须匿名。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="af77" class="nl mp iq ol b gy oq or l os ot">df = pd.read_csv('data/training.csv')</span><span id="b357" class="nl mp iq ol b gy ou or l os ot"># Categorical Features<br/>CAT_NAMES = ['col_1', 'col_2', 'col_3', 'col_4', <br/>             'col_5', 'col_6', 'col_7', 'col_8'] </span><span id="d14e" class="nl mp iq ol b gy ou or l os ot"># Continuous Features<br/>CONT_NAMES = ['col_9', 'col_10', 'col_11', <br/>              'col_12', 'col_13', 'col_14'] </span><span id="0987" class="nl mp iq ol b gy ou or l os ot"># Target Variable<br/>TARGET = 'target'</span></pre><h2 id="d97d" class="nl mp iq bd mq nm nn dn mu no np dp my lf nq nr na lj ns nt nc ln nu nv ne nw bi translated">强制转换目标变量数据类型</h2><p id="81ef" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">将二进制目标变量的数据类型改为<em class="ls">类别</em>。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="cc56" class="nl mp iq ol b gy oq or l os ot">df[TARGET] = df[TARGET].astype('category')</span></pre><p id="b110" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">陷阱#1 </strong>:如果目标变量数据类型保留为数值，FastAI/PyTorch会将其视为数值，并产生<em class="ls">运行时错误</em>。</p><h2 id="b8c0" class="nl mp iq bd mq nm nn dn mu no np dp my lf nq nr na lj ns nt nc ln nu nv ne nw bi translated">实例化数据加载器</h2><p id="bfd5" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">接下来，列出数据预处理程序、训练/验证集拆分并创建表格数据加载器。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="edad" class="nl mp iq ol b gy oq or l os ot"># Data Processors<br/>procs = [Categorify, FillMissing, Normalize] </span><span id="978e" class="nl mp iq ol b gy ou or l os ot"># Training/Validation Dataset 80:20 Split <br/>splits = RandomSplitter(valid_pct=0.2)(range_of(df)) </span><span id="7a71" class="nl mp iq ol b gy ou or l os ot">dls = TabularDataLoaders.from_df(df,                                         <br/>                                 y_names=TARGET,                                  <br/>                                 cat_names=CAT_NAMES,                                 <br/>                                 cont_names=CONT_NAMES,                                 <br/>                                 procs=procs,                                 <br/>                                 splits=splits)</span></pre><p id="46ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用<code class="fe oi oj ok ol b">dls.xs</code>查看转换后的训练数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/02fc8e0660c815eb2d377dab98792038.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jUQeoKDFaUs1i_RVBdj01A.png"/></div></div></figure><p id="6ec8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">构造损失函数权重</strong></p><p id="a22d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">类别不平衡被用于创建交叉熵损失函数的权重，从而确保多数类别被相应地向下加权。此处使用的砝码公式与<em class="ls"> scikit-learn </em>和<em class="ls"> PySPark ML </em>中的公式相同。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="fdc7" class="nl mp iq ol b gy oq or l os ot">class_count_df = df.groupby(TARGET).count() <br/>n_0, n_1 = class_count_df.iloc[0, 0], class_count_df.iloc[1, 0] <br/>w_0 = (n_0 + n_1) / (2.0 * n_0)<br/>w_1 = (n_0 + n_1) / (2.0 * n_1) <br/>class_weights=torch.FloatTensor([w_0, w_1]).cuda()</span></pre><p id="a957" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">陷阱#2 </strong> : <strong class="ky ir"> </strong>确保将类权重转换为浮点张量，并通过<code class="fe oi oj ok ol b">.cuda()</code>启用cuda操作。否则，你会得到一个<em class="ls">类型的错误</em>。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="d450" class="nl mp iq ol b gy oq or l os ot">TypeError: cannot assign 'list' object to buffer 'weight' (torch Tensor or None required)</span></pre><p id="eec4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">实例化ROC指标下的区域</strong></p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="b4d8" class="nl mp iq ol b gy oq or l os ot">roc_auc = RocAucBinary()</span></pre><p id="cbd9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">陷阱#3 </strong>:对于二进制类标签，使用<code class="fe oi oj ok ol b">RocAucBinary()</code>而不是<code class="fe oi oj ok ol b">RocAuc()</code>，以避免<em class="ls">值错误</em>。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="2406" class="nl mp iq ol b gy oq or l os ot">ValueError: y should be a 1d array, got an array of shape (2000, 2) instead.</span></pre><p id="93e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">实例化损失函数</strong></p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="811e" class="nl mp iq ol b gy oq or l os ot">loss_func = CrossEntropyLossFlat(weight=class_weights)</span></pre><p id="5b2e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">陷阱#5: </strong>使用FastAI交叉熵损失函数，与<code class="fe oi oj ok ol b">torch.nn.CrossEntropyLoss()</code>的PyTorch等价函数相反，以避免错误。此处列出了FastAI损失函数<a class="ae kv" href="https://docs.fast.ai/losses" rel="noopener ugc nofollow" target="_blank">。使用PyTorch交叉熵损失给了我以下运行时错误。</a></p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="f410" class="nl mp iq ol b gy oq or l os ot">RuntimeError: Expected object of scalar type Long but got scalar type Char for argument #2 'target' in call to _thnn_nll_loss_forward</span></pre><p id="f6b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">实例化学习者</strong></p><p id="b750" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用FastAI中的<code class="fe oi oj ok ol b">tabular_learner</code>轻松实例化一个架构。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="0a0f" class="nl mp iq ol b gy oq or l os ot">learn = tabular_learner(dls, <br/>                        layers=[500, 250],    <br/>                        loss_func=loss_func, <br/>                        metrics=roc_auc)</span></pre><p id="c58c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">仔细检查<code class="fe oi oj ok ol b">learn</code>是否使用了正确的损失函数:</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="3eec" class="nl mp iq ol b gy oq or l os ot">learn.loss_func <br/>Out [1]: FlattenedLoss of CrossEntropyLoss()</span></pre><h2 id="195a" class="nl mp iq bd mq nm nn dn mu no np dp my lf nq nr na lj ns nt nc ln nu nv ne nw bi translated">模型训练和验证分数</h2><p id="3709" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">在所需的历元数上训练模型。</p><pre class="kg kh ki kj gt om ol on oo aw op bi"><span id="0d82" class="nl mp iq ol b gy oq or l os ot">learn.fit_one_cycle(3)</span></pre><p id="45b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练和验证集的性能度量和损失函数值如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/ecc9100492b4fc42d6c04a372ffbee0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*hbNle9pc_CDMiUTE21ONhA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">ROC曲线下面积在短短3个时期内达到0.75！</p></figure><p id="c625" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">太好了！通过最小的调整，FastAI模型比使用PySpark和Scikit-Learn精心构建的模型性能更好。</p><h1 id="871d" class="mo mp iq bd mq mr ob mt mu mv oc mx my jw od jx na jz oe ka nc kc of kd ne nf bi translated">4.FastAI与PySpark ML &amp; Scikit-Learn逻辑回归模型的比较</h1><p id="eec2" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">在这一节中，我们比较了这三个ML库的模型性能和计算时间。</p><p id="c1cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注:</strong>虽然神经网络在没有大量超参数调整的情况下表现良好，但PySpark ML和Scikit-Learn则不然。因此，我添加了这些时间，因为它们与训练下降模型相关。</p><p id="985a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">模型训练时间</strong></p><ol class=""><li id="138e" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">FastAI — 6分钟</li><li id="217f" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">PySpark ML — 0.7秒+ 38分钟用于超参数调整</li><li id="b1e3" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">Scikit-Learn — 36秒+ 8分钟用于超参数调整(基于数据的子样本)</li></ol><p id="7b98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">ROC曲线下面积</strong></p><ol class=""><li id="8b2b" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">FastAI — 0.75</li><li id="d803" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">PySpark ML — 0.74</li><li id="f103" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">Scikit-Learn — 0.73</li></ol><p id="c796" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更多详情，请查看我的Github <a class="ae kv" href="https://github.com/FyzHsn/ml-classification-exploration/tree/develop" rel="noopener ugc nofollow" target="_blank">回购</a>。</p><h1 id="4f3b" class="mo mp iq bd mq mr ob mt mu mv oc mx my jw od jx na jz oe ka nc kc of kd ne nf bi translated">5.结论</h1><p id="1614" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">在本文中，我们看到了FastAI在快速构建DL模型方面的强大功能。在使用FastAI之前，我会推迟使用神经网络，直到我已经尝试了逻辑回归、随机森林等等。因为神经网络难以调整且计算昂贵。然而，随着通过谷歌人工智能平台笔记本和分层FastAI方法对GPU的可访问性增加，现在它肯定会是我在大型复杂数据集上进行分类任务时首先使用的工具之一。</p></div></div>    
</body>
</html>