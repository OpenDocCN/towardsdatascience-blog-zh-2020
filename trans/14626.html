<html>
<head>
<title>Simple Linear Regression Model using Python: Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python的简单线性回归模型:机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simple-linear-regression-model-using-python-machine-learning-eab7924d18b4?source=collection_archive---------1-----------------------#2020-10-09">https://towardsdatascience.com/simple-linear-regression-model-using-python-machine-learning-eab7924d18b4?source=collection_archive---------1-----------------------#2020-10-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3371" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习如何使用Python中的Jupyter notebook在机器学习中构建简单的线性回归模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8c4b1cbe7e1f472a4ead64310c3d1f5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uRYLv7uBLfIPLUgurNGYZg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">凯文·Ku在<a class="ae ky" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="25f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上一篇文章中，<a class="ae ky" rel="noopener" target="_blank" href="/linear-regression-model-machine-learning-9853450c8bce"> <strong class="lb iu">线性回归模型，</strong> </a> <strong class="lb iu"> </strong>我们已经看到了线性回归模型在理论上是如何使用Microsoft Excel工作的。本文将介绍如何在Jupyter笔记本中使用Python构建线性回归模型。</p><h2 id="4582" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">简单线性回归</h2><p id="1f14" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了预测两个变量之间的关系，我们将使用一个简单的线性回归模型。</p><p id="bce0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在简单的线性回归模型中，我们将只使用一个自变量来预测一个称为因变量的变量的结果。</p><blockquote class="mt"><p id="5ee3" class="mu mv it bd mw mx my mz na nb nc lu dk translated">在本文中，我们将直接开始构建模型。更多关于线性回归模型和我们必须考虑的因素在这里<a class="ae ky" rel="noopener" target="_blank" href="/linear-regression-model-machine-learning-9853450c8bce">详细解释</a>。</p></blockquote><h2 id="d7b1" class="lv lw it bd lx ly nd dn ma mb ne dp md li nf mf mg lm ng mi mj lq nh ml mm mn bi translated">构建线性回归模型</h2><p id="f205" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了在python中构建线性回归模型，我们将遵循五个步骤:</p><ol class=""><li id="d8b8" class="ni nj it lb b lc ld lf lg li nk lm nl lq nm lu nn no np nq bi translated">阅读和理解数据</li><li id="c22c" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">可视化数据</li><li id="63cb" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">执行简单的线性回归</li><li id="d32e" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">残差分析</li><li id="e8f0" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">测试集上的预测</li></ol><h2 id="41f8" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">阅读和理解数据</h2><p id="4f9f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在这一步中，首先，我们将导入必要的库来导入数据。之后，我们将执行一些基本命令来理解数据的结构。</p><blockquote class="mt"><p id="22a7" class="mu mv it bd mw mx my mz na nb nc lu dk translated">我们可以从<a class="ae ky" href="https://github.com/Kaushik-Varma/linear_regression_model_python" rel="noopener ugc nofollow" target="_blank">这里</a>下载我们将在本文中使用的样本数据集。</p></blockquote><p id="6f84" class="pw-post-body-paragraph kz la it lb b lc nw ju le lf nx jx lh li ny lk ll lm nz lo lp lq oa ls lt lu im bi translated">让我们假设我们有一个公司的数据，其中有花费在不同类型广告上的金额及其随后的销售额。</p><p id="90b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">导入库<br/> </strong>我们将导入Jupyter笔记本中的<code class="fe ob oc od oe b">numpy</code>和<code class="fe ob oc od oe b">pandas</code>库，并使用<code class="fe ob oc od oe b">pandas</code>读取数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="f126" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集看起来像这样。这里我们的目标变量是销售列。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/fdb40471a8fc4c7f22132676225b9b9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*La-InR6oTYok42sARFsyoQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">公司的广告数据</p></figure><p id="26d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">理解数据<br/> </strong>让我们执行一些任务来理解数据，比如<code class="fe ob oc od oe b">shape</code>、<code class="fe ob oc od oe b">info</code>和<code class="fe ob oc od oe b">describe</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="ccda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们数据集的<code class="fe ob oc od oe b">shape</code>是，</p><pre class="kj kk kl km gt oi oe oj ok aw ol bi"><span id="91d5" class="lv lw it oe b gy om on l oo op">(200, 4)</span></pre><p id="f628" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<code class="fe ob oc od oe b">info</code>，我们可以看到数据中是否有空值。如果是，那么我们必须做一些数据操作。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/41855c0c057da2596aa1d6a3a3d5dd6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*d6Kq6fyzIYYUNNWf1gcBWw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集的信息</p></figure><p id="f7f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所观察到的，数据中没有空值。</p><p id="a71b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<code class="fe ob oc od oe b">describe</code>，我们将看到数据值是否有任何突然的跳跃。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/54d9bddd9cdbad18ea5cf83ad85a3608.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*Kv91HTqap1PYS3-6z6AQeA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">描述数据集</p></figure><p id="3bda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">列中显示的值在整个数据中相当一致。</p><h2 id="4828" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">可视化数据</h2><p id="8d33" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在让我们使用<code class="fe ob oc od oe b">matplolib</code>和<code class="fe ob oc od oe b">seaborn</code>库来可视化数据。我们将绘制所有列的配对图，并查看哪些列与<code class="fe ob oc od oe b">Sales</code>最相关。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="6a83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在两个数值变量之间使用散点图总是更好。上面代码的pairplot看起来像，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/9e8c9dbfc07c51576446dfb73117eba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-v7JZ_LMgyyzHnuHXClctg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">每个列的pair plot w . r . t . Sales列</p></figure><p id="7f0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们不能使用散点图来确定相关性，我们可以使用seaborn热图来可视化数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="e460" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">热图看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/29e5bd41b270e3e8f95ab5ed830fe298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*rF842ix82wypfKpddQl0JA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据中所有列的热图</p></figure><p id="3fa4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的图表中我们可以看出，电视栏目似乎与销售最相关。</p><p id="c48c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用电视作为特征变量来执行简单的线性回归模型。</p><h2 id="4248" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">执行简单的线性回归</h2><p id="a8ee" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">一元线性回归方程<br/> <code class="fe ob oc od oe b">y = c + mX</code></p><p id="3f84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中:<br/><code class="fe ob oc od oe b">y = c + m * TV</code><br/>m值称为<strong class="lb iu">模型系数</strong>或<strong class="lb iu">模型参数。</strong></p><p id="673e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将分四步执行简单的线性回归。</p><ol class=""><li id="0dca" class="ni nj it lb b lc ld lf lg li nk lm nl lq nm lu nn no np nq bi translated">创建X和y</li><li id="b2a8" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">创建训练和测试集</li><li id="7e36" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">训练你的模型</li><li id="acfd" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">评估模型</li></ol><p id="ebd5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">创建X和y </strong>首先，我们将特征变量/列<code class="fe ob oc od oe b">TV</code>指定为<code class="fe ob oc od oe b">X</code>，目标变量<code class="fe ob oc od oe b">Sales</code>指定为<code class="fe ob oc od oe b">y</code>。</p><p id="99fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概括地说，</p><p id="446c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自变量代表<code class="fe ob oc od oe b">X</code>，<code class="fe ob oc od oe b">y</code>代表简单线性回归模型中的目标变量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="c2b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建训练集和测试集我们需要将变量分成训练集和测试集。使用训练集，我们将构建模型并在测试集上执行模型。我们将把训练集和测试集分别分成7:3的比例。</p><p id="96ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将通过从<code class="fe ob oc od oe b">sklearn.model_selection</code>库中导入<code class="fe ob oc od oe b">train_test_split</code>来分割数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="6808" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来看看训练数据集，</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="a4a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">X_train数据拆分后是这样的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/8e5d0ba1752a46e7a18dfd3bc9bd1ee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*0omsPPJllGqhvzuTB_gujQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分割后的X_train数据</p></figure><p id="2382" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">y_train数据拆分后是这样的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/13095ac1852826ef6ab1f92ed939df96.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*TMdYK9fvw1LJ5BL0v88XcA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拆分后的y_train数据</p></figure><p id="6a59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">建立和训练模型<br/> </strong>使用下面的两个包，我们可以建立一个简单的线性回归模型。</p><ul class=""><li id="7906" class="ni nj it lb b lc ld lf lg li nk lm nl lq nm lu ow no np nq bi translated"><code class="fe ob oc od oe b">statsmodel</code></li><li id="4440" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><code class="fe ob oc od oe b">sklearn</code></li></ul><p id="828f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将使用<code class="fe ob oc od oe b">statsmodel</code>包来构建模型。为此，我们需要导入<code class="fe ob oc od oe b">statsmodel.api</code>库来执行线性回归。</p><p id="0db8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">默认情况下，<code class="fe ob oc od oe b">statsmodel</code>库适合一条穿过原点的线。但是如果我们观察简单的线性回归方程<code class="fe ob oc od oe b">y = c + mX</code>，它的截距值为<code class="fe ob oc od oe b">c</code>。因此，要进行截取，我们需要手动添加<code class="fe ob oc od oe b">add_constant</code>属性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="af22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们添加了常数，我们就可以使用<code class="fe ob oc od oe b">OLS</code>(普通最小二乘法)来拟合回归线。之后，我们将看到直线的参数，即<code class="fe ob oc od oe b">c</code>和<code class="fe ob oc od oe b">m</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="a4c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/bdabc6cd60c9c93450192052a6fc84b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*abrHW4Nviro4LfTdAQFL1Q.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">直线的截距和斜率</p></figure><p id="0cb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看回归线拟合的所有不同参数的汇总，如<code class="fe ob oc od oe b">R²</code>、<code class="fe ob oc od oe b">F-statistic</code>和<code class="fe ob oc od oe b">p-value</code>的概率。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="428f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述回归线的统计数据是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/16f2c64f1d3515262f10c2d5e96df777.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*Ns1IVFc-6n-8GorkpQZ6dA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上述最佳拟合线的所有统计数据</p></figure><p id="b7c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们主要关心的决定模型是否可行的统计数据是:</p><ol class=""><li id="cd05" class="ni nj it lb b lc ld lf lg li nk lm nl lq nm lu nn no np nq bi translated"><code class="fe ob oc od oe b">coefficients</code>及其<code class="fe ob oc od oe b">p-value</code>(意义)</li><li id="e932" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated"><code class="fe ob oc od oe b">R-squared</code>值</li><li id="5629" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated"><code class="fe ob oc od oe b">F-statistic</code>及其意义</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/ae5956a80bdadeb9d51c2f34af7d008d.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*LL9XqKsbaIUO_pTSJSA6fQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们需要看的统计数据</p></figure><p id="b725" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1.电视的<code class="fe ob oc od oe b">coefficient</code>为0.054，其对应的<code class="fe ob oc od oe b">p-value</code>很低，几乎为0。这意味着<code class="fe ob oc od oe b">coefficient</code>在统计上是显著的。</p><blockquote class="mt"><p id="6040" class="mu mv it bd mw mx my mz na nb nc lu dk translated">我们必须确保p值总是小于这个系数才是有效的</p></blockquote><p id="2c5f" class="pw-post-body-paragraph kz la it lb b lc nw ju le lf nx jx lh li ny lk ll lm nz lo lp lq oa ls lt lu im bi translated">2.<code class="fe ob oc od oe b">R-squared</code>值为0.816，这意味着<code class="fe ob oc od oe b">Sales</code>方差的81.6%可以通过使用此行的<code class="fe ob oc od oe b">TV</code>列来解释。</p><p id="e5c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.Prob <code class="fe ob oc od oe b">F-statistic</code>的<code class="fe ob oc od oe b">p-value</code>非常低，几乎为零，这让我们知道模型拟合在统计上是显著的。</p><p id="7eee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于拟合度很高，让我们继续观察直线与<code class="fe ob oc od oe b">TV</code>和<code class="fe ob oc od oe b">Sales</code>列之间的散点图的拟合度。</p><p id="14a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这些参数中，我们得到了直线的<code class="fe ob oc od oe b">intercept</code>和<code class="fe ob oc od oe b">slope</code>的值。这条线的方程式是，</p><p id="b836" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe ob oc od oe b">Sales = 6.948 + 0.054 * TV</code></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="d457" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图表看起来像这样，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/ed31168812914d037cee8d28660063f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*eqUjQR2SM4TJnY7TwC9VTA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最佳回归直线</p></figure><p id="afd5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是我们如何使用训练数据建立一个简单的线性回归模型。现在，在根据测试数据评估模型之前，我们必须执行残差分析。</p><h2 id="f084" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">残差分析</h2><p id="beab" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">线性回归模型的主要假设之一是误差项是正态分布的。</p><p id="9925" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe ob oc od oe b">Error = Actual y value - y predicted value</code></p><p id="87ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，从数据集中，<br/>我们必须使用<code class="fe ob oc od oe b">predict</code>属性从X的训练数据集中预测y值。之后，我们将从预测数据中创建误差项(残差)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="9604" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们画出残差的直方图，看看它是否像正态分布。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="8e43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">残差的直方图看起来像，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/d54b165bece7149ff143195a7e250c44.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*95ekOTycjpRkXn1tuZ10rQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">残差分布</p></figure><p id="f13e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所见，残差服从均值为0的正态分布图。</p><p id="a918" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，确保残差不遵循任何特定的模式。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="76c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">散点图看起来像，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/f9b232b959e8330369529899dd41bb8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*X5KbTz_3CD2Kk-Muj7TSlA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">残值散点图</p></figure><p id="3c0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于残差遵循正态分布，不遵循任何特定的模式，我们可以使用我们建立的线性回归模型来评估测试数据。</p><h2 id="5961" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">对测试数据的预测或评估模型</h2><p id="2cc5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在，我们已经在训练数据集上拟合了回归线，我们可以对测试数据进行一些预测。类似于训练数据集，我们必须<code class="fe ob oc od oe b">add_constant</code>测试数据，并使用<code class="fe ob oc od oe b">statsmodel</code>中的<code class="fe ob oc od oe b">predict</code>属性预测y值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="a3d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测试数据的预测y值为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/ba8de10a3c43ba40d4ebe78391f0e449.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*GGWnP19l-Hu3CT7PH3yrbw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预测y值</p></figure><p id="5bf2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们计算上面预测的y值的<code class="fe ob oc od oe b">R²</code>值。我们可以通过从<code class="fe ob oc od oe b">sklearn.metrics</code>包中导入<code class="fe ob oc od oe b">r2_score</code>库来实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="7187" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用上述代码得到的R值= 0.792</p><p id="c2df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们能从训练数据中记住，R值= 0.815</p><p id="0f09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于测试数据的R值在训练数据的R值的5%以内，我们可以得出结论，该模型相当稳定。这意味着，模型在训练集上学习的内容可以在看不见的测试集上推广。</p><p id="e9bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们想象一下测试数据上的线。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="41ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具有最佳拟合线的散点图看起来像，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/3109f47689db4a9c399e9984b78d6e66.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*CoNPnuOj0sNCZfihoil7PQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据的最佳拟合线</p></figure><p id="84d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是我们如何使用<code class="fe ob oc od oe b">statsmodel</code>包构建线性回归模型。</p><p id="2e8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了<code class="fe ob oc od oe b">statsmodel</code>，我们可以使用<code class="fe ob oc od oe b">sklearn</code>建立一个线性回归模型。使用来自<code class="fe ob oc od oe b">sklearn</code>的<code class="fe ob oc od oe b">linear_model</code>库，我们可以制作模型。</p><p id="ef8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与<code class="fe ob oc od oe b">statsmodel</code>类似，我们将数据分成<code class="fe ob oc od oe b">train</code>和<code class="fe ob oc od oe b">test</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="00db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于简单的线性回归，我们需要添加一列来正确地执行回归拟合。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="f83a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">X_train加列前的形状是<code class="fe ob oc od oe b">(140, )</code>。<br/>训练和测试数据的X形状为<code class="fe ob oc od oe b">(140, 1)</code>。</p><p id="e986" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们将这条线与从<code class="fe ob oc od oe b">sklearn.linear_model</code>导入<code class="fe ob oc od oe b">LinearRegression</code>库的图相匹配。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="29d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们找出模型的系数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="0299" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">截距和斜率的值是，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/4456f8fd8327e9b8dbdf1242cef4db6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*R3f5Hzrmfc2zTGDRLtjSIg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">系数值</p></figure><p id="c677" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们得到的上述值的直线方程是，<br/> <code class="fe ob oc od oe b">Sales = 6.948 + 0.054 * TV</code> <br/>如果我们观察，这里得到的方程和<code class="fe ob oc od oe b">statsmodel</code>中得到的方程是一样的。</p><p id="3f7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们将对数据进行预测，并通过比较R值来评估模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="58a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练和测试数据的R值为<br/>R train _ data = 0.816<br/>R test _ data = 0.792</p><p id="d0ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与<code class="fe ob oc od oe b">statesmodel</code>相同，测试数据的R值在训练数据的R值的5%以内。我们可以在未来将该模型应用于未知的测试集。</p><h1 id="5b4e" class="pg lw it bd lx ph pi pj ma pk pl pm md jz pn ka mg kc po kd mj kf pp kg mm pq bi translated">结论</h1><p id="68f6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">正如我们所见，我们可以使用<code class="fe ob oc od oe b">statsmodel</code>或<code class="fe ob oc od oe b">sklearn</code>构建一个线性回归模型。</p><p id="a044" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们必须确保遵循这五个步骤来构建简单的线性回归模型:</p><ol class=""><li id="29bb" class="ni nj it lb b lc ld lf lg li nk lm nl lq nm lu nn no np nq bi translated">阅读和理解数据</li><li id="5672" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">可视化数据</li><li id="fa5e" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">执行简单的线性回归</li><li id="9d91" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">残差分析</li><li id="47d3" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">测试集上的预测</li></ol><p id="0101" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一篇文章中，我们将看到多元线性回归模型是如何工作的。</p><p id="c9d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">感谢您阅读</strong>和<strong class="lb iu">快乐编码！！！</strong></p><h1 id="ccc3" class="pg lw it bd lx ph pi pj ma pk pl pm md jz pn ka mg kc po kd mj kf pp kg mm pq bi translated">点击这里查看我以前的文章</h1><ul class=""><li id="1dfa" class="ni nj it lb b lc mo lf mp li pr lm ps lq pt lu ow no np nq bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/linear-regression-model-machine-learning-9853450c8bce"> <strong class="lb iu">线性回归模型:机器学习</strong> </a></li><li id="6718" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/exploratory-data-analysis-eda-python-87178e35b14"> <strong class="lb iu">探索性数据分析(EDA): Python </strong> </a></li><li id="74a7" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/central-limit-theorem-clt-data-science-19c442332a32"><strong class="lb iu">(CLT)中心极限定理:数据科学</strong> </a></li><li id="e7a2" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/inferential-statistics-data-analysis-e59adc75c6eb"> <strong class="lb iu">推断统计:数据分析</strong> </a></li><li id="4c4e" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/seaborn-python-8563c3d0ad41"> <strong class="lb iu"> Seaborn: Python </strong> </a></li><li id="f075" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><a class="ae ky" href="https://levelup.gitconnected.com/pandas-python-e69f4829fee1" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">熊猫:蟒蛇</strong> </a></li><li id="3aa1" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><a class="ae ky" href="https://levelup.gitconnected.com/matplotlib-python-ecc7ba303848" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">Matplotlib:Python</strong></a></li><li id="04d5" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><a class="ae ky" href="https://medium.com/coderbyte/numpy-python-f8c8f2bbd13e" rel="noopener"> <strong class="lb iu"> NumPy: Python </strong> </a></li></ul><h1 id="f8bc" class="pg lw it bd lx ph pi pj ma pk pl pm md jz pn ka mg kc po kd mj kf pp kg mm pq bi translated">参考</h1><ul class=""><li id="33f4" class="ni nj it lb b lc mo lf mp li pr lm ps lq pt lu ow no np nq bi translated"><strong class="lb iu">机器学习—线性回归:</strong><a class="ae ky" href="https://www.w3schools.com/python/python_ml_linear_regression.asp" rel="noopener ugc nofollow" target="_blank">https://www . w3schools . com/python/python _ ml _ Linear _ Regression . ASP</a></li><li id="492a" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><strong class="lb iu">Python中的线性回归:</strong><a class="ae ky" href="https://realpython.com/linear-regression-in-python/" rel="noopener ugc nofollow" target="_blank">https://realpython.com/linear-regression-in-python/</a></li><li id="075a" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><strong class="lb iu">线性回归(Python实现):</strong><a class="ae ky" href="https://www.geeksforgeeks.org/linear-regression-python-implementation/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/Linear-Regression-Python-Implementation/</a></li><li id="b461" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu ow no np nq bi translated"><strong class="lb iu">用Scikit学习Python线性回归的初学者指南:</strong><a class="ae ky" href="https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2019/03/初学者指南-线性回归-python-scikit-learn.html </a></li></ul></div></div>    
</body>
</html>