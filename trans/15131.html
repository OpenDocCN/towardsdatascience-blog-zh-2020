<html>
<head>
<title>Active Learning — Say Yeah!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主动学习——说是！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/active-learning-say-yeah-7598767806b2?source=collection_archive---------10-----------------------#2020-10-18">https://towardsdatascience.com/active-learning-say-yeah-7598767806b2?source=collection_archive---------10-----------------------#2020-10-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/d85988bfb26f8252ccfb9ba32010bf2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kbK73DWJct84UbXX-B3gSQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">安妮·斯普拉特在<a class="ae kc" href="https://unsplash.com/s/photos/cactus?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><blockquote class="kd"><p id="689a" class="ke kf iq bd kg kh ki kj kk kl km kn dk translated">机器学习这个，机器学习那个！你知道该怎么做。让我们来谈一个人们此刻只在窃窃私语的话题，<strong class="ak">主动学习。</strong></p></blockquote><p id="c1b1" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk kn ij bi translated">主动学习是人工智能的一个子领域，它基于这样一个事实，即好奇的算法在<strong class="kq ir">效率</strong>和<strong class="kq ir">表达能力方面都是更好的学习者。</strong>核心思想是让算法挑选样本进行训练，而不是在所有可用的训练数据上训练模型。</p><h1 id="50f0" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">主动学习场景</h1><p id="e18d" class="pw-post-body-paragraph ko kp iq kq b kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk kn ij bi translated">主动学习可能是人工智能领域最简单的想法之一。这个想法有多种变化，但都有明确的主题。</p><blockquote class="kd"><p id="735f" class="ke kf iq bd kg kh mo mp mq mr ms kn dk translated">让模型挑选训练数据</p></blockquote><p id="6c97" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk kn ij bi translated">“让模型挑选训练数据”这句话可能意味着几件事。</p><ol class=""><li id="27fe" class="mt mu iq kq b kr mv kv mw kz mx ld my lh mz kn na nb nc nd bi translated">让模型创建训练数据(创成式模型)</li><li id="78b2" class="mt mu iq kq b kr ne kv nf kz ng ld nh lh ni kn na nb nc nd bi translated">让模型从未标记的数据流中挑选一个例子</li><li id="5f5f" class="mt mu iq kq b kr ne kv nf kz ng ld nh lh ni kn na nb nc nd bi translated">让模型从一堆未标记的数据中挑选一个例子</li></ol><p id="94a8" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">生成模型可能有些棘手，因为人类注释者可能很难标记数据，这违背了主动学习的目的。</p><p id="f2d1" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">一般来说，在实际设置中，模型从一个未标记的数据流/数据池中挑选例子，由人类注释者进行标记。</p><h1 id="8e71" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">主动学习策略</h1><p id="9f68" class="pw-post-body-paragraph ko kp iq kq b kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk kn ij bi translated">这一节我们来讨论几个主动学习策略。</p><h2 id="aff0" class="nm lm iq bd ln nn no dn lr np nq dp lv kz nr ns lz ld nt nu md lh nv nw mh nx bi translated">不确定抽样</h2><p id="4a5e" class="pw-post-body-paragraph ko kp iq kq b kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk kn ij bi translated">这种策略通常用于概率模型。可以用一个简单的流程图来概括。</p><figure class="nz oa ob oc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ny"><img src="../Images/b95c31bd89a6f1e04567ca855e4ab373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fCHPaMCXoxyzWwXjM98MKw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">不确定性采样流程图。[使用<a class="ae kc" href="https://app.code2flow.com/" rel="noopener ugc nofollow" target="_blank"> code2flow </a>生成]</p></figure><p id="d140" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">除了“标记最不确定的例子”这一步，上面的流程图几乎是不言自明的。</p><p id="15f4" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">让我们考虑一个将新闻分为7类的工作示例。我们有:-</p><ol class=""><li id="3b29" class="mt mu iq kq b kr mv kv mw kz mx ld my lh mz kn na nb nc nd bi translated">一套小型训练设备</li><li id="7e40" class="mt mu iq kq b kr ne kv nf kz ng ld nh lh ni kn na nb nc nd bi translated">在带标签的训练集上训练的简单模型</li><li id="cfed" class="mt mu iq kq b kr ne kv nf kz ng ld nh lh ni kn na nb nc nd bi translated">一大群没有标记的人</li></ol><p id="daae" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">让我们预测10个未标记的样本中所有类别的概率。</p><figure class="nz oa ob oc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/25c8eb0a6a458e0f12f015b4583db856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q9XWwChZ89q5GMsaZYUcoQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">10个未标记样本的分类概率。[作者图片]</p></figure><ol class=""><li id="b64b" class="mt mu iq kq b kr mv kv mw kz mx ld my lh mz kn na nb nc nd bi translated"><strong class="kq ir">选择一个最大概率类别值最小的例子</strong></li></ol><p id="c017" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">直觉告诉我们，如果模型对某个示例的顶部预测没有信心，那么该示例就相当困难，或者可能与模型已经看到的不同。</p><figure class="nz oa ob oc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/7fefd05191aaae1b13f95136ee75add4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zB4_P2quzK4-oBkj62_vAQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">例5具有最大的不确定性。[作者图片]</p></figure><p id="24e2" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">在上面的示例中，我们看到模型对第5个示例的顶部预测最没有信心。</p><p id="baf4" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">2.<strong class="kq ir">挑选一个前两个类别之间差异最小的例子</strong></p><p id="699a" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">直觉是，如果前两个预测之间的差异较小，那么模型一定是在两个类别之间混淆了。一个好的模型应该能够尽可能地分离类别，因此，在训练数据中考虑该示例是很重要的。</p><figure class="nz oa ob oc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/dcb17a5c59a3fa5fe5230569bb9b0131.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nQHASSS6ZeQj0wp_YPyhTA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">前两类的区别。[作者图片]</p></figure><p id="6228" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">3.<strong class="kq ir">利用熵测量不确定度</strong></p><p id="0b7d" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" rel="noopener ugc nofollow" target="_blank">维基百科</a>定义的熵是<strong class="kq ir"> <em class="og">变量可能结果中固有的“信息”、“惊喜”或“不确定性”的平均水平。</em> </strong>如果预测概率具有高熵，则意味着模型对某个例子感到困惑。</p><figure class="nz oa ob oc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi gj"><img src="../Images/d6ffe81e4f102f372e7300bfaf3a818f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bQQFG6X2gISp_hiEi39F_A.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">计算预测概率的熵。[作者图片]</p></figure><h2 id="8cbb" class="nm lm iq bd ln nn no dn lr np nq dp lv kz nr ns lz ld nt nu md lh nv nw mh nx bi translated">委员会的质询</h2><p id="6049" class="pw-post-body-paragraph ko kp iq kq b kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk kn ij bi translated">就整个过程而言，按委员会查询也非常类似于不确定性抽样。唯一的区别是我们如何选择最不确定的例子。在<strong class="kq ir">不确定性采样中，</strong>我们训练单个模型，并使用其输出概率来推断不确定性并挑选示例。</p><p id="c4a5" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">在按委员会查询中，我们创建不同类型模型的委员会，并在训练集上训练它们。当选择看不见的例子时，我们从所有例子的所有模型中得到预测。这些模型在很大程度上不一致的示例是困难的示例，应该出现在训练数据中。</p><blockquote class="kd"><p id="7513" class="ke kf iq bd kg kh mo mp mq mr ms kn dk translated">不同类型的模型(线性、树、邻居、贝叶斯)确保我们的查询策略不会受到单一类型的建模假设的影响，因此性能良好。</p></blockquote><figure class="oi oj ok ol om jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oh"><img src="../Images/7ffbdde77de89159f99e40df17f97952.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G9R-gYWecK3_luiWRZLyMw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">创建一个由7名分类员组成的委员会。[作者图片]</p></figure><figure class="nz oa ob oc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi on"><img src="../Images/9eb6813a7c0b9b676460b3616056c2b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CpdnarJgVz0EDvlyFQvdwA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">例5不同型号之间分歧最大。[作者图片]</p></figure><h1 id="30f3" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">主动学习的好处</h1><p id="91b2" class="pw-post-body-paragraph ko kp iq kq b kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk kn ij bi translated">在文章的开始，我提到了主动学习提高了模型的效率和表达能力。</p><blockquote class="kd"><p id="761b" class="ke kf iq bd kg kh mo mp mq mr ms kn dk translated">与学术界相反，行业从业者必须处理非标准数据集和问题</p></blockquote><p id="a128" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk kn ij bi translated">因此，任何ML项目的很大一部分都花费在获得正确的训练数据集上。人类注释者花费他们宝贵的时间来标记数据集进行训练，这是最大的开销和低效点。<strong class="kq ir"> <em class="og">主动学习法保证了标注者只标注最重要、最难的例子，从而使整个过程更加高效。</em>T15】</strong></p><blockquote class="oo op oq"><p id="e0a2" class="ko kp og kq b kr mv kt ku kv mw kx ky or nj lb lc os nk lf lg ot nl lj lk kn ij bi translated">当一个大数据集被无意识地标记时，它会带来不想要的类别不平衡，并冒着丢失尚未标记的重要示例的风险。</p></blockquote><p id="be21" class="pw-post-body-paragraph ko kp iq kq b kr mv kt ku kv mw kx ky kz nj lb lc ld nk lf lg lh nl lj lk kn ij bi translated">通过使用主动学习，我们挑选最有趣和最多样的例子，从而提高模型的表达能力。在这里，通过表达能力，我的意思是这个过程从大量未标记的数据中引出更多种类的要标记的例子，这些数据在无意识标记的情况下会保持未标记。</p><blockquote class="kd"><p id="c5c9" class="ke kf iq bd kg kh mo mp mq mr ms kn dk translated">所以如果都是金子和闪闪发光的东西，为什么我们不在这里谈论它呢？</p></blockquote><p id="bc87" class="pw-post-body-paragraph ko kp iq kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk kn ij bi translated"><a class="ou ov ep" href="https://medium.com/u/34ab754f8c5e?source=post_page-----7598767806b2--------------------------------" rel="noopener" target="_blank">杰瑞米·霍华德</a>在他出现在<a class="ou ov ep" href="https://medium.com/u/119b8eb57f8e?source=post_page-----7598767806b2--------------------------------" rel="noopener" target="_blank">莱克斯·弗里德曼</a>的播客中非常出色地抓住了这一点。</p><figure class="nz oa ob oc gt jr"><div class="bz fp l di"><div class="ow ox l"/></div></figure><h1 id="147f" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">结论</h1><p id="cd4d" class="pw-post-body-paragraph ko kp iq kq b kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk kn ij bi translated">主动学习，在我看来，是人工智能领域最接近于一顿“<strong class="kq ir">免费午餐</strong>”的事情。这个概念非常简单，其好处远远超过创建和管理培训数据的任何其他方法。虽然这不是一个非常著名的子领域，但令人敬畏的python社区已经创建了一些包，将主动学习的力量带给每个人。</p><ul class=""><li id="da3a" class="mt mu iq kq b kr mv kv mw kz mx ld my lh mz kn oy nb nc nd bi translated"><a class="ae kc" href="https://github.com/modAL-python/modAL" rel="noopener ugc nofollow" target="_blank">模态</a></li><li id="653b" class="mt mu iq kq b kr ne kv nf kz ng ld nh lh ni kn oy nb nc nd bi translated"><a class="ae kc" href="https://github.com/ntucllab/libact" rel="noopener ugc nofollow" target="_blank"> Libact </a></li><li id="d717" class="mt mu iq kq b kr ne kv nf kz ng ld nh lh ni kn oy nb nc nd bi translated"><a class="ae kc" href="https://github.com/NUAA-AL/ALiPy" rel="noopener ugc nofollow" target="_blank"> Alipy </a></li><li id="a345" class="mt mu iq kq b kr ne kv nf kz ng ld nh lh ni kn oy nb nc nd bi translated"><a class="ae kc" href="https://github.com/Draup-Zinnov/NERD" rel="noopener ugc nofollow" target="_blank">书呆子</a>(不要脸的塞！)</li></ul><h1 id="abec" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">参考</h1><ul class=""><li id="3333" class="mt mu iq kq b kr mj kv mk kz oz ld pa lh pb kn oy nb nc nd bi translated"><a class="ae kc" href="http://burrsettles.com/pub/settles.activelearning.pdf" rel="noopener ugc nofollow" target="_blank">主动学习文献调查</a></li><li id="3de3" class="mt mu iq kq b kr ne kv nf kz ng ld nh lh ni kn oy nb nc nd bi translated"><a class="ae kc" href="https://app.code2flow.com/" rel="noopener ugc nofollow" target="_blank">代码到流程图</a></li></ul></div></div>    
</body>
</html>