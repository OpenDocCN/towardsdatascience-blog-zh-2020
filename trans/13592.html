<html>
<head>
<title>Generate Subtitles for any video file using Mozilla DeepSpeech</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Mozilla DeepSpeech为任何视频文件生成字幕</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generating-subtitles-automatically-using-mozilla-deepspeech-562c633936a7?source=collection_archive---------10-----------------------#2020-09-18">https://towardsdatascience.com/generating-subtitles-automatically-using-mozilla-deepspeech-562c633936a7?source=collection_archive---------10-----------------------#2020-09-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d7ac" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">对于那些嘴里薯条的噪音让你无法看电影的时候:)</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a5146d2623793743586bd1b852daccc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wVVDijaHYTiUHIAQ"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">玛利亚·特内娃在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="7962" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在OTT平台时代，仍然有一些人喜欢从YouTube/脸书/Torrents下载电影/视频(嘘🤫)过流。我就是其中之一，有一次，我找不到我下载的某部电影的字幕文件。然后，<strong class="lb iu"> AutoSub </strong>的想法打动了我，因为我以前和<a class="ae ky" href="https://github.com/mozilla/DeepSpeech" rel="noopener ugc nofollow" target="_blank"> DeepSpeech </a>合作过，我决定用它来为我的电影制作字幕。</p><p id="c2e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给定一个视频文件作为输入，我的目标是生成一个<strong class="lb iu">。srt </strong>文件。字幕可以导入任何现代视频播放器。在本文中，我将带您浏览一些代码。你可以在我的GitHub <a class="ae ky" href="https://github.com/abhirooptalasila/AutoSub" rel="noopener ugc nofollow" target="_blank">上找到这个项目，这里有关于如何在本地安装的说明。</a></p><p id="6080" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">先决条件:对Python的中级理解，对<a class="ae ky" href="https://heartbeat.fritz.ai/a-2019-guide-for-automatic-speech-recognition-f1e1129a141c" rel="noopener ugc nofollow" target="_blank">自动语音识别引擎</a>的一些熟悉，以及对信号处理的基本理解将会很棒。</p><p id="71e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:这是我第一篇关于媒体的文章。如果你有任何建议/疑问，请写下来。快乐阅读:)</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="3d4e" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">Mozilla DeepSpeech</h1><p id="4c75" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">DeepSpeech是基于百度原创<a class="ae ky" href="https://arxiv.org/abs/1412.5567" rel="noopener ugc nofollow" target="_blank">深度语音研究论文的开源语音转文本引擎。鉴于其多功能性和易用性，它是最好的语音识别工具之一。它是使用</a><a class="ae ky" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank"> Tensorflow构建的，</a>可以使用自定义数据集进行训练，在庞大的<a class="ae ky" href="https://commonvoice.mozilla.org/en" rel="noopener ugc nofollow" target="_blank"> Mozilla Common Voice </a>数据集上进行训练，并在Mozilla Public License下获得许可。最大的好处是我们可以下载模型文件并在本地执行推理<strong class="lb iu">只需几分钟！</strong></p><p id="fad1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然，DeepSpeech确实有它的问题。该模型与非母语英语口音的语音进行斗争。对此有一个解决方法——使用我们想要预测的语言中的自定义数据集来微调模型。我将很快就如何做到这一点写另一篇文章。</p><p id="a9cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你正在处理语音识别任务，我强烈建议你看看DeepSpeech。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="de09" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">自动Sub</h1><p id="878b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">让我们从安装一些我们需要的包开始。所有命令都已经在Ubuntu 18.04的pip虚拟环境中进行了测试。</p><ol class=""><li id="9ade" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">FFmpeg是领先的多媒体框架，能够解码、编码、转码、复用、解复用、流式传输、过滤和播放人类和机器创造的几乎任何东西。我们需要它从我们的输入视频文件中提取音频。</li></ol><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="ee84" class="nn md it nj b gy no np l nq nr">$ sudo apt-get install ffmpeg</span></pre><p id="10c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<strong class="lb iu"> DeepSpeech </strong>:从PyPI安装python包，下载模型文件。记分员文件是可选的，但大大提高了准确性。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="e18b" class="nn md it nj b gy no np l nq nr"><em class="ns">$ </em>pip install deepspeech<em class="ns">==0.8.2</em></span><span id="6eaa" class="nn md it nj b gy nt np l nq nr"><em class="ns"># Model file (~190 MB)</em> <br/>$ wget https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/deepspeech-0.8.2-models.pbmm</span><span id="9bce" class="nn md it nj b gy nt np l nq nr"><em class="ns"># Scorer file (~900 MB)<br/></em>$ wget <a class="ae ky" href="https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/deepspeech-0.8.2-models.scorer" rel="noopener ugc nofollow" target="_blank">https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/deepspeech-0.8.2-models.scorer</a></span></pre><p id="063a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们都设置好了，让我们首先使用FFmpeg从我们的输入视频文件中提取音频。我们需要创建一个子进程来运行UNIX命令。DeepSpeech期望输入音频文件以16kHz采样，因此ffmpeg的参数如下。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="4e60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，假设我们的输入视频文件有2小时长。通常不建议对整个文件运行DeepSpeech推断。我试过了，效果不太好。解决这个问题的一个方法是将音频文件分割成无声片段。分割后，我们有多个小文件包含我们需要推断的语音。这是使用<a class="ae ky" href="https://github.com/tyiannak/pyAudioAnalysis" rel="noopener ugc nofollow" target="_blank"> pyAudioAnalysis </a>完成的。</p><p id="1b62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下函数使用pyAudioAnalysis中的函数<strong class="lb iu"> read_audio_file() </strong>和<strong class="lb iu"> silenceRemoval() </strong>，并从语音开始和结束的位置生成分段限制。参数以秒为单位控制平滑窗口大小，以(0，1)为单位控制权重因子。使用段限制，较小的音频文件被写入磁盘。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="c80a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在需要分别对这些文件运行DeepSpeech推断，并将推断的文本写入一个SRT文件。让我们首先创建一个DeepSpeech模型的实例，并添加scorer文件。然后，我们将音频文件读入一个NumPy数组，并将其送入语音转文本功能以产生推断。如上所述，pyAudioAnalysis保存的文件具有以秒为单位的段限制时间。在写入SRT文件之前，我们需要提取这些限制并将其转换成合适的形式。这里的定义了写功能<a class="ae ky" href="https://github.com/abhirooptalasila/AutoSub/blob/4f65218ee40207e1ccf3ec3ed49fa9dd300721f4/autosub/writeToFile.py#L7" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="bff9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">整个过程不应超过原始视频文件持续时间的60%。这里有一个视频，展示了在我的笔记本电脑上运行的一个例子。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">自动Sub演示</p></figure><p id="f219" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有一个领域我希望在未来改进。推断的文本是无格式的。我们需要添加适当的标点符号，纠正单词中可能的小错误(一个字母之外)，并将很长的片段分成较小的片段(尽管这很难自动化)。</p><p id="fc5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样！如果您已经到达这里，感谢您的坚持:)</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="6410" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里找到我:<a class="ae ky" href="https://www.linkedin.com/in/abhiroop1999/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>，<a class="ae ky" href="https://github.com/abhirooptalasila" rel="noopener ugc nofollow" target="_blank"> GitHub </a></p></div></div>    
</body>
</html>