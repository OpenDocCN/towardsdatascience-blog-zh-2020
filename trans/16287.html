<html>
<head>
<title>Fine-Tuning Pre-trained Model VGG-16</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微调预训练模型VGG-16</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fine-tuning-pre-trained-model-vgg-16-1277268c537f?source=collection_archive---------5-----------------------#2020-11-10">https://towardsdatascience.com/fine-tuning-pre-trained-model-vgg-16-1277268c537f?source=collection_archive---------5-----------------------#2020-11-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e901" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">本文旨在展示如何在迁移学习中微调而不是使用预训练模型作为特征提取器，并在RAVDESS音频数据集上比较结果。</em></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/f38edb1eeefde644cf4faab960b558ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kSw-njRsFwVlqbTElIX8oQ.jpeg"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">由<a class="ae kz" href="https://unsplash.com/@ikukevk" rel="noopener ugc nofollow" target="_blank">凯文·Ku</a>在<a class="ae kz" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="cd47" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在我的<a class="ae kz" href="https://medium.com/r?url=https%3A%2F%2Ftowardsdatascience.com%2Ftransfer-learning-in-speech-emotion-recognition-d55b6616ba83" rel="noopener">上一篇文章</a>中，我探索了使用预训练模型VGG-16作为在RAVDESS音频数据集上进行迁移学习的特征提取器。作为数据科学的新手，我通读了Medium上的文章，并看到了佩德罗·马塞利诺写的这篇便利的文章<a class="ae kz" rel="noopener" target="_blank" href="/transfer-learning-from-pre-trained-models-f2393f124751"/>，其中他描述了迁移学习的过程，但最有见地的是人们可以微调他们选择的预训练模型的三种策略。佩德罗马塞利诺还提供了一个有用的大小相似性矩阵，以帮助确定使用哪种策略。在阅读了他的文章后，我开始意识到，与其使用预训练的模型作为特征提取器，我应该通过训练一些层并保持其他层冻结来微调模型，因为我的数据集很小(1440个文件)，并且与VGG-16模型数据集不相似。在这里，我将探索这种对RAVDESS音频数据集上的VGG-16预训练模型的微调，并确定其对模型准确性的影响。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="879d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在导入了必要的库、我们的训练/测试集，并预处理了数据(在这里描述为<a class="ae kz" rel="noopener" target="_blank" href="/transfer-learning-in-speech-emotion-recognition-d55b6616ba83"/>)之后，我们开始建模:</p><ol class=""><li id="b5e9" class="md me it lc b ld le lg lh lj mf ln mg lr mh lv mi mj mk ml bi translated">首先，导入VGG16并传递必要的参数:</li></ol><pre class="kk kl km kn gt mm mn mo mp aw mq bi"><span id="c860" class="mr ms it mn b gy mt mu l mv mw">from keras.applications import VGG16</span><span id="169f" class="mr ms it mn b gy mx mu l mv mw">vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))</span></pre><p id="9333" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">2.接下来，我们设置一些层冻结，我决定解冻最后一块，使他们的权重在每个时期得到更新</p><pre class="kk kl km kn gt mm mn mo mp aw mq bi"><span id="6db1" class="mr ms it mn b gy mt mu l mv mw"># Freeze four convolution blocks<br/>for layer in vgg_model.layers[:15]:<br/>    layer.trainable = False</span><span id="c4b8" class="mr ms it mn b gy mx mu l mv mw"># Make sure you have frozen the correct layers<br/>for i, layer in enumerate(vgg_model.layers):<br/>    print(i, layer.name, layer.trainable)</span></pre><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi my"><img src="../Images/47b51fcc06331debd86a0451a140157f.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*RJQUESmW5x9scj0NetJC_w.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">作者图片</p></figure><p id="353f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">很好，所以我们将在预训练的VGG-16模型的最后四层训练我们的数据集。</p><p id="99ad" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3)我使用与我之前的VGG-16模型相同的模型架构作为特征提取器:</p><pre class="kk kl km kn gt mm mn mo mp aw mq bi"><span id="2ec9" class="mr ms it mn b gy mt mu l mv mw">x = vgg_model.output<br/>x = Flatten()(x) # Flatten dimensions to for use in FC layers<br/>x = Dense(512, activation='relu')(x)<br/>x = Dropout(0.5)(x) # Dropout layer to reduce overfitting<br/>x = Dense(256, activation='relu')(x)<br/>x = Dense(8, activation='softmax')(x) # Softmax for multiclass<br/>transfer_model = Model(inputs=vgg_model.input, outputs=x)</span></pre><p id="68d3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">4)我们来设置一些回调，比如ReduceLROnPlateau和ModelCheckpoint。ReduceLROnPlateau特别有助于微调我们的模型，因为正如佩德罗·马塞利诺所描述的，高学习率会增加丢失先前知识的风险，所以最好设置一个低学习率，有了ReduceLROnPlateau，这可以帮助我们解决这个问题！ModelCheckpoint总是有用的，因为它允许我们定义在哪里检查模型权重。</p><pre class="kk kl km kn gt mm mn mo mp aw mq bi"><span id="c1d4" class="mr ms it mn b gy mt mu l mv mw">from keras.callbacks import ReduceLROnPlateau</span><span id="ff60" class="mr ms it mn b gy mx mu l mv mw">lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)</span><span id="d9ce" class="mr ms it mn b gy mx mu l mv mw">checkpoint = ModelCheckpoint('vgg16_finetune.h15', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)</span></pre><p id="dab0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">4)接下来，我们编译并拟合我们的模型</p><pre class="kk kl km kn gt mm mn mo mp aw mq bi"><span id="b1d6" class="mr ms it mn b gy mt mu l mv mw">from tensorflow.keras import layers, models, Model, optimizers</span><span id="c675" class="mr ms it mn b gy mx mu l mv mw">learning_rate= 5e-5</span><span id="b256" class="mr ms it mn b gy mx mu l mv mw">transfer_model.compile(loss="categorical_crossentropy", optimizer=optimizers.Adam(lr=learning_rate), metrics=["accuracy"])</span><span id="294e" class="mr ms it mn b gy mx mu l mv mw">history = transfer_model.fit(X_train, y_train, batch_size = 1, epochs=50, validation_data=(X_test,y_test), callbacks=[lr_reduce,checkpoint])</span></pre><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi mz"><img src="../Images/95946c33144b7084efdaf4ece274ab67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*20juQh7Yud3M74oki4ysSg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">作者图片</p></figure><div class="kk kl km kn gt ab cb"><figure class="na ko nb nc nd ne nf paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/0215ea640c5cc736eafcb6ff7bbb9938.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*lgvhN_GP8oCanNXVtAapmA.png"/></div></figure><figure class="na ko ng nc nd ne nf paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/cb53a635ce846e74fac073c2544fed1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*QekPTEz59qPaRvOFNYa5Dw.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk nh di ni nj translated">作者图片</p></figure></div><p id="62d9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正如我们所看到的，该模型在很大程度上过度拟合了训练数据。经过50个时期后，我们的模型达到了<strong class="lc iu"> 78% </strong>的准确度，这比我们之前的分类器<strong class="lc iu">高9%</strong>，在我们之前的分类器中，我们使用预训练的VGG-16模型作为特征提取器，但与我们预训练的VGG-16模型一样，使用图像增强作为特征提取器。</p><p id="31c7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在让我们尝试用图像增强来微调VGG-16模型，看看这是否会提高模型精度。使用我们之前模型的<strong class="lc iu"> transfer_model </strong>变量中存储的相同的VGG-16模型对象，并解冻第五个卷积块，同时保持前四个块冻结。</p><pre class="kk kl km kn gt mm mn mo mp aw mq bi"><span id="aed8" class="mr ms it mn b gy mt mu l mv mw">for layer in vgg_model.layers[:15]:<br/>layer.trainable = False</span><span id="09d0" class="mr ms it mn b gy mx mu l mv mw">x = vgg_model.output<br/>x = Flatten()(x) # Flatten dimensions to for use in FC layers<br/>x = Dense(512, activation='relu')(x)<br/>x = Dropout(0.5)(x) # Dropout layer to reduce overfitting<br/>x = Dense(256, activation='relu')(x)<br/>x = Dense(8, activation='softmax')(x) # Softmax for multiclass<br/>transfer_model = Model(inputs=vgg_model.input, outputs=x)</span><span id="4a86" class="mr ms it mn b gy mx mu l mv mw">for i, layer in enumerate(transfer_model.layers):<br/>print(i, layer.name, layer.trainable)</span></pre><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/168841ac2cdbbd53a3acb1b55f3fb418.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*L2QtuMWUQvpFC8KAWKYcGQ.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">作者图片</p></figure><p id="ace2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">很好，现在第五个卷积块是可训练的，我们已经添加了自己的分类器。现在，我们将使用Keras的图像预处理模块的<strong class="lc iu"> ImageDataGenerator </strong>来增强我们的图像，使其适合我们的训练集，编译模型，然后拟合模型。</p><pre class="kk kl km kn gt mm mn mo mp aw mq bi"><span id="d478" class="mr ms it mn b gy mt mu l mv mw">#Augment images<br/>train_datagen = ImageDataGenerator(zoom_range=0.2, rotation_range=30, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2)</span><span id="f5ac" class="mr ms it mn b gy mx mu l mv mw">#Fit augmentation to training images<br/>train_generator = train_datagen.flow(X_train,y_train,batch_size=1)</span><span id="52ac" class="mr ms it mn b gy mx mu l mv mw">#Compile model<br/>transfer_model.compile(loss="categorical_crossentropy", optimizer='adam', metrics=["accuracy"])</span><span id="9871" class="mr ms it mn b gy mx mu l mv mw">#Fit model<br/>history = transfer_model.fit_generator(train_generator, validation_data=(X_test,y_test), epochs=100, shuffle=True, callbacks=[lr_reduce],verbose=1)</span></pre><p id="acc9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在100个时期之后，我们获得了<strong class="lc iu"> 70% </strong>的准确度分数，这比我们之前的模型降低了<strong class="lc iu"> 8% </strong>，并且作为特征提取器与我们的VGG-16模型表现相同(*在此插入巨大的悲伤面孔*)。</p><div class="kk kl km kn gt ab cb"><figure class="na ko nl nc nd ne nf paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/799429c816462a34eb3d2c5ab566b246.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*PAawbEH9qB5_KDm1ufjFWg.png"/></div></figure><figure class="na ko nm nc nd ne nf paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/9bb8f463acaa1dcefd3b416bc9afe091.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*PMe-TiNgEJpeAiafyOErCQ.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk nn di no nj translated">作者图片</p></figure></div><p id="0211" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">可以清楚地看到，该模型过度拟合于训练数据，并且在大约40个时期之后，准确度似乎达到平稳状态。通过微调，与使用预训练模型作为特征提取器相比，我没有看到模型准确性有多大提高，这是我没有预料到的，因为与VGG-16模型相比，我使用的数据集不同且更小。</p><p id="bc77" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我已尝试调整<strong class="lc iu"> ImageDataGenerator </strong>类的参数，但未能提高模型精度。如果有人对我的VGG-19模型有任何建议，请告诉我！感谢您的阅读:)</p></div></div>    
</body>
</html>