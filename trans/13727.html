<html>
<head>
<title>ZFNet: An Explanation of Paper with Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ZFNet:用代码解释论文</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/zfnet-an-explanation-of-paper-with-code-f1bd6752121d?source=collection_archive---------17-----------------------#2020-09-21">https://towardsdatascience.com/zfnet-an-explanation-of-paper-with-code-f1bd6752121d?source=collection_archive---------17-----------------------#2020-09-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f9ed" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">揭开神经网络如何看待我们的世界的秘密！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4faff2ce8308ec89b72f01bbbc076ce2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WLQj_Kx6DCLzCAnQ"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">丹尼尔·库切列夫在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="39c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在2013年的ImageNet大规模视觉识别挑战赛(ILSVRC)中，ZFNet受到了关注，与<a class="ae ky" rel="noopener" target="_blank" href="/alexnet-8b05c5eb88d4"> AlexNet </a>相比有了显著的改进。本文是黄金宝典，为您提供了许多概念的起点，如<strong class="lb iu">深度特征可视化</strong>、<strong class="lb iu">特征不变性</strong>、<strong class="lb iu">特征进化、</strong>和<strong class="lb iu">特征重要性</strong>。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="12b9" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">体系结构</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/01ea4d039cca931f8481ff38384aecfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TVaRxj15YHTK5jtgTexb1g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1311.2901.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2901.pdf</a></p></figure><ul class=""><li id="1752" class="mv mw it lb b lc ld lf lg li mx lm my lq mz lu na nb nc nd bi translated">我们的输入是<strong class="lb iu"> 224x224x3 </strong>的图像。</li><li id="1896" class="mv mw it lb b lc ne lf nf li ng lm nh lq ni lu na nb nc nd bi translated">接下来，<strong class="lb iu">以2 </strong>的<strong class="lb iu">步距执行7x7 </strong>的96个卷积，随后是<strong class="lb iu"> ReLU </strong>激活、<strong class="lb iu">以2 </strong>步距的3×3最大汇集和<strong class="lb iu">局部对比度归一化</strong>。</li><li id="1b43" class="mv mw it lb b lc ne lf nf li ng lm nh lq ni lu na nb nc nd bi translated">接下来是256个3×3的滤波器<strong class="lb iu">，每个滤波器然后再次被<strong class="lb iu">局部对比度归一化</strong>和<strong class="lb iu">汇集</strong>。</strong></li><li id="2cb9" class="mv mw it lb b lc ne lf nf li ng lm nh lq ni lu na nb nc nd bi translated">第三层和第四层与<strong class="lb iu"> 384个内核相同，每个</strong>3个。</li><li id="ba08" class="mv mw it lb b lc ne lf nf li ng lm nh lq ni lu na nb nc nd bi translated">第五层具有3x3的<strong class="lb iu"> 256个过滤器，接着是具有步幅2的3x3最大池</strong>和<strong class="lb iu">局部对比度归一化</strong>。</li><li id="8e62" class="mv mw it lb b lc ne lf nf li ng lm nh lq ni lu na nb nc nd bi translated">第六层和第七层分别容纳4096个密集的单元。</li><li id="b93c" class="mv mw it lb b lc ne lf nf li ng lm nh lq ni lu na nb nc nd bi translated">最后，我们输入1000个神经元的<strong class="lb iu">密集层，即ImageNet中的类的数量。</strong></li></ul><p id="620d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您不熟悉术语“局部对比度标准化”:</p><blockquote class="nj nk nl"><p id="09a7" class="kz la nm lb b lc ld ju le lf lg jx lh nn lj lk ll no ln lo lp np lr ls lt lu im bi translated"><strong class="lb iu">局部对比度归一化</strong>是一种执行局部减法和除法归一化的归一化，在特征图中的相邻特征之间以及不同特征图中相同空间位置的特征之间实施一种局部竞争。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/a46929a0087c419a2d91cbee3ab36a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wIYNe1vELVlBdi_70LNwYQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://cedar.buffalo.edu/~srihari/CSE676/12.2%20Computer%20Vision.pdf" rel="noopener ugc nofollow" target="_blank">https://cedar . buffalo . edu/~ Sri Hari/CSE 676/12.2% 20 computer % 20 vision . pdf</a></p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="f439" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">特征的可视化</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/bb5a2de7cc9bfa7f4d5534c3b0db4232.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*DntbO2Ts7uW03Wv7Wy1mXw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1311.2901.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2901.pdf</a></p></figure><p id="1046" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于特征的可视化，作者使用了<strong class="lb iu">去进化网络</strong> (deconvnet)。可以把deconvnet看作是自动编码器的解码器部分。它与普通的卷积网络相反，它使用非pooling和过滤器从特征中恢复像素。</p><p id="4251" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个网络中唯一令人困惑的部分是它是如何撤销池的，因为当任何池完成时，给定使用NxN过滤器，N个值中只有一个值剩余。整个数据不能被恢复，但是最大值仍然在那里，但是如果我们不知道它在卷积层的输出中的位置，它是没有用的。这就是为什么当进行汇集时存储最大值的位置以便以后使用。这些位置在文中被称为<strong class="lb iu">开关</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/944171bdbb2aad2477156c6b3f55b164.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uTUmbkTIzAaxXQ59teDssw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">【https://ieeexplore.ieee.org/document/6126474 T4】</p></figure><p id="ba43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用开关，最大值被放置在图层上正确的空间位置，从而允许将要素正确映射到像素。</p><p id="447d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，还有一点需要注意，卷积滤波器是在应用非线性之后应用的，这与卷积然后激活的正常流程相反。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/18517168069be741a904c17f0e3cf18e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*9w0skyI5-mnf7km36kVnHg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1311.2901.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2901.pdf</a></p></figure><p id="2d8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后作者提取了特征图中前9个激活的特征并展示出来。</p><p id="d52a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一层去掉了最简单的特征，图像中的各种频率。<strong class="lb iu">把它当成学习图像中的线条。</strong></p><p id="71a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二层是建模各种角落和边缘/颜色组合。<strong class="lb iu">把它想象成学习图像中的曲线。曲线是由小线条构成的。</strong></p><p id="e3ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第三层学习网格等更复杂的图案。<strong class="lb iu">把它想象成学习那些曲线的组合，即网格。曲线聚集在一起创建网格(想想篮子)。</strong></p><p id="0caa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第四层学习特定类别的特征，例如狗脸。<strong class="lb iu">把它想象成把篮子做成不同的形状并涂上不同的颜色。网格可以被转换成类似于面和各种复杂的对象。</strong></p><p id="9e1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第五层学习具有一些姿势变化(侧面、正面和其他)的整个对象。把它想象成把所有这些篮子排列成相似的不同物体。可以将类似较大物体的较小人工制品的网格排列在一起，以形成整个形状。</p><p id="2ff2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从特征的可视化中，作者还获得了在AlexNet的第一层中减少过滤器大小和步幅的想法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/0e7d8edefdb2f3acdaa13c5030275a33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6YLihn2YsXPFP12oVgbX0Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1311.2901.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2901.pdf</a></p></figure><p id="f92b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在(b)中，我们有AlexNet的第1层功能，在(c)中，我们有ZFNet的第1层功能。在(b)的情况下，我们可以看到一些灰色方块，这些是没有激活值的死亡神经元。这是一件坏事。另一个问题是在(a)中可以看到颜色/强度的低值和高值，但是不能看到颜色/强度的中间范围。</p><p id="acbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第三个问题是图像特征中的锯齿状视觉特征或混叠。当采样率不够高时，就会发生混叠(想象一下图像中有正方形)。在这种情况下，采样率是将要发生的卷积数。如果滤波器尺寸较大，则采样率较低。如果滤波器尺寸较小，则采样率将会较高。大步流星也会发生同样的事情。</p><p id="dfcf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是为什么这些问题的解决方案是减小滤波器尺寸和步幅，这两者都导致采样速率增加，并且由于现在步幅很小，颜色/强度的中间范围出现。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="f293" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">特征不变性</h1><p id="7dd2" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">卷积神经网络具有平移、缩放和旋转(给定对象具有旋转对称性)不变性。这是直观的证据:</p><div class="kj kk kl km gt ab cb"><figure class="oa kn ob oc od oe of paragraph-image"><img src="../Images/f39d1628926649b53b4e628a121d8a88.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*Nqkb9XMDO1VUILoXfGNyGA.png"/></figure><figure class="oa kn og oc od oe of paragraph-image"><img src="../Images/c2a97c55f880627a0823fb0d9534be08.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*dAzajuN091bOYSZjo4mxJw.png"/><p class="ku kv gj gh gi kw kx bd b be z dk oh di oi oj translated"><a class="ae ky" href="https://arxiv.org/pdf/1311.2901.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2901.pdf</a></p></figure></div><p id="775b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一行是为了显示翻译不会影响训练有素的CNN的表现。在第一行的第二列中，您可以看到图像属于其真实类别的概率。除了在极端情况下，曲线在大多数情况下都是稳定的，主要是因为在图像中不能看到有问题的物体。</p><p id="f4b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二行是为了显示缩放不影响经过训练的CNN的性能。在第二行的第二列中，您可以看到图像属于其真实类别的概率。除了娱乐中心之外，大多数对象的曲线都是稳定的，娱乐中心实际上一直类似于电视，因此是这样的行为。但是，总的来说，CNN看起来对缩放相当稳健。</p><p id="7d34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第三行是为了显示旋转确实会搞乱CNN。一个例外是，如果物体具有某种旋转对称性，那么CNN仍然保留其对该物体图像的预测能力。从第三行的第二列，你可以看到所有的曲线都乱了套，只有可爱的狮子狗和危险的非洲鳄鱼是稳定的，它们的图像看起来都是旋转对称的。CNN对于具有旋转对称性的物体的旋转是鲁棒的，因此，你应该记住这一点。</p><p id="7d54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，今天你就有了视觉证据，证明为什么CNN在图像任务上如此出色。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="e1ff" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">特征的演变</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/9f54a916499e075ce39c87959797b744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bkgnYglvj3po88MqAXnk_Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://pixabay.com/users/Alexas_Fotos-686414/" rel="noopener ugc nofollow" target="_blank"> Alexas_Fotos </a>拍摄</p></figure><p id="ac0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇论文给了我们关于神经网络在引擎盖下做什么的视觉直觉。没有人知道如何处理和如何调整这个引擎的黑盒神经网络已经不再是谜了。下图显示了网络中图层的影像要素。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/18517168069be741a904c17f0e3cf18e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*9w0skyI5-mnf7km36kVnHg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1311.2901.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2901.pdf</a></p></figure><p id="1781" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是图像特征如何在层上演变，但用简单的自然语言来说，这就是它是如何发生的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/14eef937925e18fdf160e460a789313f.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*6xaPs8U6sMVqucRuPZTMGA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:作者</p></figure><p id="8b56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对这一观点的更多支持是，在第一层，你有线，我们可以把它联系起来，因为这两个方程看起来像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/62977c350f303cb553ce20e3fd2a6c34.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*1fx3ys3kWmteu25Pu0pa8A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:作者</p></figure><p id="38d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正常神经元的方程式看起来像一条线。所以，第一层模拟图像中的线条。随着层数的增加，上面的x会越积越多。并且网络对越来越多的扭曲线及其组合进行建模。耶，我们得到了最好的算法来创建我们的模型。对于以上解释的更复杂的形式，请查阅通用逼近定理(UAT)和柯尔莫哥洛夫定理。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="93a9" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">特征重要性</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/5cdcf960a31bf19939be9f0a4b452836.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*1UiGRNdyC802O5Xvxq5iLw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">https://arxiv.org/pdf/1311.2901.pdf<a class="ae ky" href="https://arxiv.org/pdf/1311.2901.pdf" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="92b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">精彩的部分还不止于此。本文还包含有关各图层特征预测能力的有用信息。正如我们所见，最后一层功能是最强大的。因此，在堆叠或迁移学习时，这些都可以使用。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="da7a" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">密码</h1><p id="bee6" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">这里是上面广泛讨论的awesome网络的代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="0d45" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="db0a" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">ZFNet第一次让世人看到了神经网络的内心世界。由于人类是视觉学习者，这为计算机视觉领域打开了新的大门和途径。它向我们展示了神经网络的中心思想以及它们是如何形成的。</p></div></div>    
</body>
</html>