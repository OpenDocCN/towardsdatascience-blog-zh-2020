<html>
<head>
<title>How Convolutional Layers Work in Deep Learning Neural Networks?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习神经网络中卷积层是如何工作的？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-convolutional-layers-work-in-deep-learning-neural-networks-2913af333b72?source=collection_archive---------47-----------------------#2020-11-02">https://towardsdatascience.com/how-convolutional-layers-work-in-deep-learning-neural-networks-2913af333b72?source=collection_archive---------47-----------------------#2020-11-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="48c8" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><div class=""><h2 id="7449" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">理解卷积及其参数的生动方式</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/bece42cd6d57670ba83b0f02589cb4ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*25BPh0aec8L1Eam-bDfD5A.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由<a class="ae lh" href="https://pixabay.com/users/stokpic-692575/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=629726" rel="noopener ugc nofollow" target="_blank"> stokpic </a>来自<a class="ae lh" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=629726" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="b11c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在深度学习中，卷积层是许多深度神经网络的主要构建模块。该设计的灵感来自视觉皮层，在视觉皮层中，单个神经元对视野中被称为感受野的受限区域做出反应。这些区域的集合重叠覆盖了整个可视区域。</p><p id="21e2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然卷积层最初应用于计算机视觉，但其平移不变的特性允许卷积层应用于自然语言处理、时间序列、推荐系统和信号处理。</p><p id="228a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">理解卷积的最简单方法是将其视为应用于矩阵的滑动窗口函数。本文将介绍1D卷积的工作原理，并探讨每个参数的影响:</p><ul class=""><li id="debd" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">内核大小</li><li id="5a4f" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">填料</li><li id="199c" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">进展</li><li id="8d7f" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">扩张</li><li id="2a6e" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">组</li></ul><h1 id="a948" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">卷积是如何工作的？(内核大小= 1)</h1><p id="bf25" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">卷积是一种线性运算，涉及输入权重相乘并产生输出。乘法是在输入数据数组和权重数组(称为内核(或过滤器))之间执行的。在输入和内核之间应用的运算是元素点积的和。每个操作的结果都是一个值。</p><p id="86e6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们从最简单的例子开始，当你有1D数据时，使用1D卷积。对1D数组应用卷积会将内核中的值与输入向量中的每个值相乘。</p><p id="89f3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">假设我们的内核(也称为“权重”)中的值是“2”，我们将输入向量中的每个元素乘以2，一个接一个，直到输入向量的末尾，得到我们的输出向量。输出向量的大小与输入向量的大小相同。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/"><div class="gh gi np"><img src="../Images/5b72ebf54541638f00909399fefedebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*RCEtI16_atsjnz1nZ91bcw.gif"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">对大小为1的核应用卷积[<a class="ae lh" href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">作者的图像</a></p></figure><p id="512b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我们将1乘以权重2，得到第一个元素的“2”。然后我们将内核移动1步，用2乘以权重，2得到“4”。我们重复这个过程，直到最后一个元素，6，然后用6乘以权重，我们得到“12”。这个过程产生输出向量。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="12dc" class="nx mt it nt b gy ny nz l oa ob">in_x.shape torch.Size([1, 1, 6])<br/>tensor([[[1., 2., 3., 4., 5., 6.]]])<br/>out_y.shape torch.Size([1, 1, 6])<br/>tensor([[[ 2.,  4.,  6.,  8., 10., 12.]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><h1 id="f9b5" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">内核大小的影响(内核大小= 2)</h1><p id="9449" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">不同大小的内核将检测输入中不同大小的特征，并进而产生不同大小的特征图。让我们看另一个例子，其中内核大小为1x2，权重为“2”。像以前一样，我们在每个元素的输入向量上滑动内核。我们通过将每个元素乘以核来执行卷积，并将乘积相加以获得最终的输出值。我们一个接一个地重复这个乘法和加法，直到输入向量结束，并产生输出向量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/"><div class="gh gi np"><img src="../Images/5afe545d420a52c6a43fa345668aeb62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*g6g5I3nzpXwrOFcJCTFIkA.gif"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">对大小为2的核应用卷积[ <a class="ae lh" href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">作者的图像</a></p></figure><p id="8b63" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我们将1乘以2得到“2”，将2乘以2得到“2”。然后，我们将2和4这两个数字相加，得到“6”，这是输出向量中的第一个元素。我们重复相同的过程，直到输入向量结束，并产生输出向量。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="8f6f" class="nx mt it nt b gy ny nz l oa ob">in_x.shape torch.Size([1, 1, 6])<br/>tensor([[[1., 2., 3., 4., 5., 6.]]])<br/>out_y.shape torch.Size([1, 1, 5])<br/>tensor([[[ 6., 10., 14., 18., 22.]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><h1 id="983f" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">如何计算输出向量的形状</h1><p id="3a5e" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">您可能已经注意到，输出向量比以前稍微小了一些。这是因为我们增加了内核的大小，从1x1增加到1x2。查看<a class="ae lh" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d" rel="noopener ugc nofollow" target="_blank"> PyTorch文档</a>，我们可以用下面的公式计算输出向量的长度:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/bd81768bc87170f75891e8fed28125f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*luibXg2N7zDq9N4Q9A14BQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">计算输出的形状。【<a class="ae lh" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="ab77" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们将大小为1x2的核应用于大小为1x6的输入向量，我们可以相应地替换这些值，并得到1x5的输出长度:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/"><div class="gh gi od"><img src="../Images/9213d8073b52c1c22100fae169fb2b72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zCiqLcO6eWMigKnQwauUGA.png"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">应用1x2内核后输出向量的形状。[ <a class="ae lh" href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">作者图片</a></p></figure><p id="bb33" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果要构建神经网络架构，计算输出要素的大小至关重要。</p><h1 id="9654" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">常见的内核大小是奇数(内核大小= 3)</h1><p id="234d" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">在前面的例子中，内核大小为2有点不常见，所以让我们再举一个例子，我们的内核大小为3，其权重为“2”。像以前一样，我们通过将每个元素乘以内核并将乘积相加来执行卷积。我们重复这个过程，直到输入向量结束，产生输出向量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/"><div class="gh gi np"><img src="../Images/08822f53582436dc9e037302ec0842de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*G8mxr-gBVvgSJ_qHvTCB8w.gif"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">使用大小为3的内核应用卷积。[ <a class="ae lh" href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">作者图片</a> ]</p></figure><p id="7334" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">同样，输出向量小于输入向量。对1×6输入向量应用1×3内核将产生大小为1×4的特征向量。</p><p id="fa2f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在图像处理中，通常使用3×3、5×5大小的核。有时我们可能会对较大的输入图像使用大小为7×7的内核。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="a455" class="nx mt it nt b gy ny nz l oa ob">in_x.shape torch.Size([1, 1, 6])<br/>tensor([[[1., 2., 3., 4., 5., 6.]]])<br/>out_y.shape torch.Size([1, 1, 4])<br/>tensor([[[12., 18., 24., 30.]]])</span></pre><h1 id="d2c7" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">如何产生一个同样大小的输出向量？(填充)</h1><p id="5660" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">对1×6输入应用1×3内核的卷积，我们得到了更短的输出向量1×4。默认情况下，内核从向量的左侧开始。然后，核一次遍历输入向量的一个元素，直到最右边的核元素位于输入向量的最后一个元素上。因此，内核越大，输出向量就越小。</p><p id="eb8f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">什么时候使用衬垫？有时，希望产生与输入向量长度相同的特征向量。我们可以通过添加填充来实现。填充是在输入向量的开头和结尾添加零。</p><p id="fb30" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过向1x6输入向量添加1个填充，我们人为地创建了一个大小为1x8的输入向量。这将在输入向量的开头和结尾添加一个元素。执行核大小为3的卷积，输出向量基本上与输入向量大小相同。添加的填充值为零；因此，当应用内核时，它对点积运算没有影响。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/"><div class="gh gi np"><img src="../Images/ce34b4a1072202e02879b405e558e23b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*5KzQ75YMnCxs-oECKFe5hA.gif"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">对带有填充的内核应用卷积。[ <a class="ae lh" href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">作者图片</a></p></figure><p id="9ccd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于核大小为5的卷积，我们也可以通过在输入向量的前端和末端添加2个填充来产生相同长度的输出向量。同样，对于图像，将3x3内核应用于128x128图像，我们可以在图像外部添加一个像素的边界，以产生128x128大小的输出特征图。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="1b37" class="nx mt it nt b gy ny nz l oa ob">in_x.shape torch.Size([1, 1, 6])<br/>tensor([[[1., 2., 3., 4., 5., 6.]]])<br/>out_y.shape torch.Size([1, 1, 6])<br/>tensor([[[ 6., 12., 18., 24., 30., 22.]]])</span></pre><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="03ff" class="nx mt it nt b gy ny nz l oa ob">in_x.shape torch.Size([1, 1, 6])<br/>tensor([[[1., 2., 3., 4., 5., 6.]]])<br/>out_y.shape torch.Size([1, 1, 6])<br/>tensor([[[12., 20., 30., 40., 36., 30.]]])</span></pre><h1 id="2223" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">我们可以将内核移动更多的步数(步幅)</h1><p id="a9e2" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">到目前为止，我们一直在一步一步地滑动内核。内核对输入图像的移动量称为“步幅”，默认步幅值为1。但是我们总是可以通过增加步长来移动内核任意数量的元素。</p><p id="fa46" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，我们可以用步长3来移动我们的内核。首先，我们将前三个元素相乘并求和。然后我们将分三步滑动内核，并对接下来的三个元素执行相同的操作。因此，我们的输出向量大小为2。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/"><div class="gh gi np"><img src="../Images/7bb40dab5a215781fdd329a5bbe6b0d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ephNo-3AvCnhMRaqKub-Rw.gif"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">对步长为3的内核应用卷积。[ <a class="ae lh" href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">作者图片</a></p></figure><p id="91c0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">何时增加步幅？</strong>在大多数情况下，我们增加步长来对输入向量进行下采样。应用步长大小2会将向量的长度减少一半。有时，我们可以使用更大的步幅来取代池层，以减少空间大小，减少模型的大小，提高速度。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="2976" class="nx mt it nt b gy ny nz l oa ob">in_x.shape torch.Size([1, 1, 6])<br/>tensor([[[1., 2., 3., 4., 5., 6.]]])<br/>out_y.shape torch.Size([1, 1, 2])<br/>tensor([[[12., 30.]]])</span></pre><h1 id="6d87" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">增加卷积的感受野(扩张)</h1><p id="8c18" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">当你在阅读深度学习文献时，你可能已经注意到了术语“扩张的卷积”。膨胀卷积通过在内核元素之间插入空格来“膨胀”内核，并且有一个参数控制膨胀率。膨胀率为2意味着内核元素之间有一个空间。本质上，膨胀= 1的卷积核对应于常规卷积。</p><p id="f189" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在DeepLab架构中使用了膨胀卷积，这就是atrous空间金字塔池(ASPP)的工作方式。利用ASPP，提取高分辨率输入特征地图，并设法以多种尺度对图像背景进行编码。在我的工作中，我还<a class="ae lh" rel="noopener" target="_blank" href="/improve-glaucoma-assessment-with-brain-computer-interface-and-machine-learning-6c3b774494f8?sk=5883c05cc3668079ef78a0b932520c3c">将扩张卷积应用于信号处理，因为它可以有效地增加输出向量的感受域，而不增加核的大小(也不增加模型的大小)。</a></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/"><div class="gh gi np"><img src="../Images/907619931f81118c7381990f63986187.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*E-nvJK-hYZgSesuFnxbQZA.gif"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">对膨胀率为2的内核应用卷积。[ <a class="ae lh" href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">作者图片</a></p></figure><p id="1be6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">什么时候使用扩张脑回？</strong>一般来说，在<a class="ae lh" href="https://arxiv.org/pdf/1606.00915" rel="noopener ugc nofollow" target="_blank"> DeepLab </a>和<a class="ae lh" href="https://arxiv.org/pdf/1511.07122.pdf" rel="noopener ugc nofollow" target="_blank">利用膨胀卷积进行多尺度上下文聚合</a>中，膨胀卷积表现出更好的分割性能。如果你想要感受野的指数扩展而不损失分辨率或覆盖范围，你可能想要使用扩张卷积。这允许我们在保持分辨率的同时，以相同的计算和存储成本获得更大的感受野。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="7816" class="nx mt it nt b gy ny nz l oa ob">in_x.shape torch.Size([1, 1, 6])<br/>tensor([[[1., 2., 3., 4., 5., 6.]]])<br/>out_y.shape torch.Size([1, 1, 2])<br/>tensor([[[18., 24.]]])</span></pre><h1 id="3f69" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">分离重量(组)</h1><p id="d674" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">默认情况下，“<em class="oe">groups”</em>参数设置为1，其中所有输入通道卷积至所有输出。要使用groupwise卷积，我们可以增加"<em class="oe"> groups" </em>值；这将强制训练将输入向量的通道分成不同的特征分组。</p><p id="350c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当groups=2时，这基本上相当于并排有两个卷积层，每个卷积层只处理一半的输入通道。然后，每个组产生一半的输出声道，随后连接起来形成最终的输出矢量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/"><div class="gh gi np"><img src="../Images/3160b196b44810f22e53fb22b23abf32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*6nr3C_Djw4d8ZQHat_gDiQ.gif"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">应用分组卷积。[ <a class="ae lh" href="https://jinglescode.github.io/2020/11/01/how-convolutional-layers-work-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">作者图片</a></p></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="b49a" class="nx mt it nt b gy ny nz l oa ob">in_x.shape torch.Size([1, 2, 6])<br/>tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.],<br/>         [10., 20., 30., 40., 50., 60.]]])<br/>torch.Size([2, 1, 1])<br/>out_y.shape torch.Size([1, 2, 6])<br/>tensor([[[  2.,   4.,   6.,   8.,  10.,  12.],<br/>         [ 40.,  80., 120., 160., 200., 240.]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><p id="7c48" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">深度方向卷积。</strong>当我们想要执行深度方向卷积时，例如，如果我们想要分别提取R、G和B通道上的图像特征，则使用组。当groups == in_channels，out_channels == K * in_channels时；这种运算在文献中也称为深度方向卷积。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="6aa6" class="nx mt it nt b gy ny nz l oa ob">in_x.shape torch.Size([1, 2, 6])<br/>tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.],<br/>         [10., 20., 30., 40., 50., 60.]]])<br/>torch.Size([4, 1, 1])<br/>out_y.shape torch.Size([1, 4, 6])<br/>tensor([[[  2.,   4.,   6.,   8.,  10.,  12.],<br/>         [  4.,   8.,  12.,  16.,  20.,  24.],<br/>         [ 60., 120., 180., 240., 300., 360.],<br/>         [ 80., 160., 240., 320., 400., 480.]]], grad_fn=&lt;SqueezeBackward1&gt;)</span></pre><p id="d39f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2012年，AlexNet论文中引入了分组卷积，其主要动机是允许网络在两个GPU上进行训练。然而，这种工程黑客有一个有趣的副作用，那就是他们学会了更好的表达。训练具有和不具有分组卷积的AlexNet具有不同的精度和计算效率。没有分组卷积的AlexNet效率较低，也不太准确。</p><p id="27c5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/improve-glaucoma-assessment-with-brain-computer-interface-and-machine-learning-6c3b774494f8?sk=5883c05cc3668079ef78a0b932520c3c">在我的工作</a>中，我还应用分组卷积来有效地训练可扩展的多任务学习模型。我可以通过调整“组”参数来调整和扩展任意数量的任务。</p><h1 id="045a" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">1x1卷积</h1><p id="4213" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">一些论文使用1x1卷积，如网络中的<a class="ae lh" href="https://arxiv.org/abs/1312.4400" rel="noopener ugc nofollow" target="_blank">网络首先调查的。看到1x1卷积可能会令人困惑，并且看起来没有意义，因为它只是逐点缩放。</a></p><p id="e006" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，事实并非如此，因为，例如，在计算机视觉中，我们正在对三维体积进行操作；内核总是贯穿输入的整个深度。如果输入是128×128×3，那么进行1x1卷积将有效地进行三维点积，因为输入深度是3个通道。</p><p id="b744" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<a class="ae lh" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank"> GoogLeNet </a>中，1×1核用于降维和增加特征图的维度。1×1内核还用于增加池化后的特征图数量；这人为地创建了更多缩减采样要素的要素地图。</p><p id="64f6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<a class="ae lh" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet </a>中，1×1内核被用作投影技术，以在残差网络的设计中匹配输入到残差输出模块的滤波器数量。</p><p id="11b3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<a class="ae lh" href="https://arxiv.org/abs/1803.01271" rel="noopener ugc nofollow" target="_blank"> TCN </a>中，添加了1×1内核以解决不同的输入-输出宽度，因为输入和输出可以有不同的宽度。1×1核卷积确保元素加法接收相同形状的张量。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><div class="ks kt ku kv gt om"><a rel="noopener follow" target="_blank" href="/improve-glaucoma-assessment-with-brain-computer-interface-and-machine-learning-6c3b774494f8"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd jd gy z fp or fr fs os fu fw jc bi translated">利用脑-机接口和机器学习改进青光眼评估</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">我的研究使用多任务学习来提供快速的护理点诊断，以检测周边视觉损失</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa lb om"/></div></div></a></div><div class="pb pc gp gr pd om"><a rel="noopener follow" target="_blank" href="/illustrated-guide-to-transformer-cf6969ffa067"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd jd gy z fp or fr fs os fu fw jc bi translated">变压器图解指南</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">逐个组件的细分分析</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="pe l ox oy oz ov pa lb om"/></div></div></a></div><div class="ks kt ku kv gt ab cb"><figure class="pf kw pg ph pi pj pk paragraph-image"><a href="https://jinglescode.github.io/"><img src="../Images/e6191b77eb1b195de751fecf706289ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*fPTPd_WxZ4Ey7iOVElxwJQ.png"/></a></figure><figure class="pf kw pg ph pi pj pk paragraph-image"><a href="https://jinglesnote.medium.com/"><img src="../Images/7c898af9285ccd6872db2ff2f21ce5d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*airGp_q6AXwaoL1LYXwYeQ.png"/></a></figure><figure class="pf kw pg ph pi pj pk paragraph-image"><a href="https://jingles.substack.com/subscribe"><img src="../Images/d370b96eace4b03cb3c36039b70735d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ESxUX6V6tAqj_2ZFSr-pUw.png"/></a></figure></div></div></div>    
</body>
</html>