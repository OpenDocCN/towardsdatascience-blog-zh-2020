<html>
<head>
<title>Node Embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">节点嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/node-embeddings-e28799478cb9?source=collection_archive---------32-----------------------#2020-11-16">https://towardsdatascience.com/node-embeddings-e28799478cb9?source=collection_archive---------32-----------------------#2020-11-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="654b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/a04fd0ccd3ddc780db3c66a8bd71f5b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GcJcLFRm_Ja2Dwu4"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated"><a class="ae kl" href="https://unsplash.com/@urielsc26?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乌列尔SC </a>在<a class="ae kl" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="b1e3" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">介绍</h1><p id="58a0" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">这是从<a class="ae kl" href="https://www.linkedin.com/in/christos-ziakas-5783079a/" rel="noopener ugc nofollow" target="_blank">克里斯特斯·齐亚卡斯</a>、<a class="ae kl" href="https://www.linkedin.com/in/janruettinger/" rel="noopener ugc nofollow" target="_blank">扬·吕廷格</a>、<a class="ae kl" href="https://www.linkedin.com/in/till-richter-659334157/" rel="noopener ugc nofollow" target="_blank">到里希特</a>的节点嵌入调查。它是在TUM数据分析和机器学习小组的<a class="ae kl" href="https://www.in.tum.de/daml/lehre/machine-learning-lab/" rel="noopener ugc nofollow" target="_blank">机器学习实验室</a>中进行的。我们感谢<a class="ae kl" href="https://www.in.tum.de/daml/team/oleksandr-shchur/" rel="noopener ugc nofollow" target="_blank"> Oleksandr Shchur </a>监督我们的项目，并感谢<a class="ae kl" href="https://www.in.tum.de/daml/team/guennemann/" rel="noopener ugc nofollow" target="_blank">günnemann博士教授</a>让我们有可能在他的团队中进行研究。</p><p id="b9a2" class="pw-post-body-paragraph lk ll iq lm b ln mi lp lq lr mj lt lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">这个项目的代码可以在<a class="ae kl" href="https://github.com/richtertill/node_embeddings" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</p><p id="8211" class="pw-post-body-paragraph lk ll iq lm b ln mi lp lq lr mj lt lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">我们希望这篇文章有助于理解现代节点嵌入模型的基础，并提供一些不同方向的最佳实践。当然，类似的评估协议也是公开的。</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h1 id="1bb6" class="km kn iq bd ko kp mu kr ks kt mv kv kw kx mw kz la lb mx ld le lf my lh li lj bi translated">为什么是图表？</h1><p id="da9e" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">图表已经变得无处不在。你不能只把社交网络理解为图形结构，还可以理解为生物结构、搜索引擎等等。甚至图像分类任务也在用图结构进行探索。因此，对信息强大表示的研究兴趣增加了。然而，很难将经典的机器学习模型应用于图结构，因为它们是为不同的数据表示而设计的。此外，天真地将它们应用于图结构被证明是低效的。</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h1 id="9573" class="km kn iq bd ko kp mu kr ks kt mv kv kw kx mw kz la lb mx ld le lf my lh li lj bi translated">应用程序</h1><p id="1754" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">节点嵌入的潜在动机在于捕捉图或图的节点的特征的可能性。社区、邻近或节点的角色只是有趣应用的几个例子。利用嵌入式空间中的计算，可以利用矢量数据的标准机器学习模型。这样，就可以应用广泛和成熟的方法，如分类、预测或聚类。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/911d89ab30fdb7c78feae5a208e2a8ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*z91c4S6F3UjLGGryT0bGxw.jpeg"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">节点分类，按作者分类的图像</p></figure><p id="4cae" class="pw-post-body-paragraph lk ll iq lm b ln mi lp lq lr mj lt lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">节点分类可用于对节点进行分类，例如，如果某个机构的社交网络中的人更可能是博士生或教授。在我们的实验中，这种分类完全依赖于非属性图，基于图的结构和已知节点的类别。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/1fbb611408c1030c54272b6eb1edd9f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/1*2_f-kWNFiv791lf927IHWQ.jpeg"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">链接预测，作者图片</p></figure><p id="02f1" class="pw-post-body-paragraph lk ll iq lm b ln mi lp lq lr mj lt lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">例如，在给定两个人已经见过的人的情况下，链接预测可以回答这两个人见面的可能性有多大的问题。在这种情况下，甚至不需要考虑节点的类。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nf"><img src="../Images/8e10689865a9891bd28be7ceaa8be1c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*IXGBF0A2QXxorWoPbx1eUg.jpeg"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">节点聚类，按作者分类的图像</p></figure><p id="b30f" class="pw-post-body-paragraph lk ll iq lm b ln mi lp lq lr mj lt lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">由于社交网络中的人彼此接近，节点聚类可以应用于将他们分组在一起，例如，为了将大学教职员工中的机构聚集在一起。在这个例子中，来自一个研究所的员工比来自其他研究所的员工彼此更接近。这种接近可以表述为“相互了解”。</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h1 id="3996" class="km kn iq bd ko kp mu kr ks kt mv kv kw kx mw kz la lb mx ld le lf my lh li lj bi translated">动机</h1><p id="9896" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">许多科学家正在研究这一有趣的现象。在不同的想法之后，取得了巨大的成果。然而，这导致了不可比性。使用不同的评估协议，并且大多数资源当然被投入到新颖的方法中，而不是要击败的前辈。因此，进步的其他原因，如技术优势或更多的投入资源，可能不会在比较中进行审查。这些和其他方面导致在该领域中不完全可比的结果。这项工作的目标是提供一个基本原则的可靠比较，这些基本原则是大多数新颖想法的基础。为了实现这一目标，尽可能使用相同的环境和相同的评估协议。这使得结果具有可比性。在这个项目中，我们只依赖于非属性图，这意味着只有节点的类和图的结构是已知的。</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h1 id="4e30" class="km kn iq bd ko kp mu kr ks kt mv kv kw kx mw kz la lb mx ld le lf my lh li lj bi translated">嵌入技术</h1><p id="b500" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">我们遵循嵌入技术，除了流行的图形神经网络，奠定了节点嵌入的大多数新方法的基础。相比之下，我们更多地放弃了调整模型的现代方法。因此，这项工作为节点嵌入的基础技术提供了比较。这些模型被细分为不同的相似性得分，即显示图中节点邻近性的度量。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ng"><img src="../Images/0bed2fcc2b91fc52c3dae6fa6a57f86c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYTBUScaAsNaZJg898qltg.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图1:节点嵌入的损失，作者图片</p></figure><h2 id="1e37" class="nh kn iq bd ko ni nj dn ks nk nl dp kw lv nm nn la lz no np le md nq nr li iw bi translated">伯努利(4种型号)</h2><p id="5d57" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">对于伯努利模型，真实图的相似性得分以邻接矩阵的形式给出。因此，如果两个节点相连，则条目为1，否则为0。解码器给出嵌入空间中的相似性得分，其可以是sigmoid、指数、高斯或基于距离的嵌入。因此，给定嵌入矩阵，我们对损耗建模以生成邻接</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/17454cd637541d9ad84a6d678c61b69f.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*m4tEEMmye0bjahH7_vjDtg.jpeg"/></div></figure><figure class="na nb nc nd gt ka gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/7a5545c6634b0eaa60d211c8127f277f.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*cktvZFzd0EmxnZBqyjVg7g.jpeg"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">伯努利可能性，作者图片</p></figure><p id="e67b" class="pw-post-body-paragraph lk ll iq lm b ln mi lp lq lr mj lt lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">其中内核可以是</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/283549abae988e2ff18701c94416ac11.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*a9HX8NgVsnUycHiptU2AwA.jpeg"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">Sigmoidal，作者提供的图像</p></figure><figure class="na nb nc nd gt ka gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/ba1641818c077b0407f8157e7398fb48.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*ImxWZEEVwlVgtiW0zQu-jw.jpeg"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">指数，作者图片</p></figure><figure class="na nb nc nd gt ka gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/79c3fc9b4726062d668d4e11a1abe0b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*9IEszOlX4SUQMIWD9dLs5A.jpeg"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">高斯(也是径向基函数核)，图片作者</p></figure><figure class="na nb nc nd gt ka gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/ba35cea56d963b7dc2e873c83c6e4b50.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*pPG4G9FDBs3G0ggCUqSHrA.jpeg"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">基于距离的#2，图片由作者提供</p></figure><p id="ef98" class="pw-post-body-paragraph lk ll iq lm b ln mi lp lq lr mj lt lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">训练模型，即。让嵌入尽可能接近原图，对数似然最大化。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ny"><img src="../Images/7292768d2aa976eda4d08ecf1c86ead7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nz7AjN2PNPG7IWfn3k8ojw.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">伯努利可能性，作者图片</p></figure><h2 id="d8e9" class="nh kn iq bd ko ni nj dn ks nk nl dp kw lv nm nn la lz no np le md nq nr li iw bi translated">KL分歧(3个模型)</h2><p id="dc96" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">KL散度是一个概率分布与另一个概率分布的不同程度的度量。在我们的例子中，图表被建模为一个概率分布，即。图形矩阵的行数总和为1。使用不同的模型来捕获概率分布中的真实图形特征，即个性化页面排名、转移的幂和以及转移矩阵。当然，嵌入空间中的图也需要是有效的概率分布，以便KL散度有意义，因此Softmax应用于嵌入节点。为了使嵌入的图形尽可能接近原始图形，或者更准确地说，接近在各个编码器中捕获的图形特征，KL散度被最小化。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi nz"><img src="../Images/e75d94c39e7161ed5deddec311bc2086.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P2fW8A31WTYxWH44UiUhBQ.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">KL Divergence，作者图片</p></figure><h2 id="5b3c" class="nh kn iq bd ko ni nj dn ks nk nl dp kw lv nm nn la lz no np le md nq nr li iw bi translated">奇异值分解(7种型号)</h2><p id="29ba" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">在奇异值分解中，众所周知的方法被应用于能够捕捉图形特征的不同矩阵。这样，矩阵被嵌入到低维空间中。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oa"><img src="../Images/79dd23115911bf73043cf88735240618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RB5cJCSeEZCa2EBPPLrgZg.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">奇异值分解，作者图片</p></figure></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h1 id="b903" class="km kn iq bd ko kp mu kr ks kt mv kv kw kx mw kz la lb mx ld le lf my lh li lj bi translated">实验</h1><p id="7450" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">总共14种嵌入方法使用3个评估任务在4个流行的图数据集上进行比较。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ob"><img src="../Images/58c7048ae9dc84d5c21a8937321a1900.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYaEdHzxRFZj6vZUgKRiSw.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">实验概述，作者图片</p></figure><h1 id="06a3" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">调查的结果</h1><p id="ee60" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">对于结果，在不同的嵌入技术下，相同的相似性度量(例如邻接矩阵)之间的比较是特别有趣的。</p><h2 id="20dc" class="nh kn iq bd ko ni nj dn ks nk nl dp kw lv nm nn la lz no np le md nq nr li iw bi translated">关于链路预测:</h2><p id="bfa8" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">对于相同的相似性度量，对于随机矩阵，基于KL的模型优于基于SVD的模型。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oc"><img src="../Images/24823bbc248c6c723292b4552b143c37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TvrtHaNC5yrXxGkQZ6oZ9Q.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">链接预测的结果，图片由作者提供</p></figure><h2 id="13cc" class="nh kn iq bd ko ni nj dn ks nk nl dp kw lv nm nn la lz no np le md nq nr li iw bi translated">关于节点分类:</h2><p id="4b67" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">对于节点分类，所有模型都表现出相似的性能。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oc"><img src="../Images/a0209cd9057c7f4cf74bb7ad9d60e629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vP7ie5iDsThEVjxAkABvSg.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">节点分类结果，按作者分类的图像</p></figure><h2 id="8262" class="nh kn iq bd ko ni nj dn ks nk nl dp kw lv nm nn la lz no np le md nq nr li iw bi translated">关于节点群集:</h2><p id="1f05" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">基于KL的模型比基于Bernoulli和SVD的模型表现更好。特别是SVD由于在更高的维度中包含了太多的噪声而失去了这种比较。在奇异值分解结果中，对此进行了进一步分析。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oc"><img src="../Images/524b17d5aab759c6f3e73f23ca3d3c47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*muLmAL2FHG_Vmwh6VHVTwA.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">节点聚类的结果，按作者分类的图像</p></figure><h2 id="c1fc" class="nh kn iq bd ko ni nj dn ks nk nl dp kw lv nm nn la lz no np le md nq nr li iw bi translated">在SVD上:</h2><p id="03a2" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">随着嵌入维数的增加，SVD模型的节点聚类性能下降。</p><figure class="na nb nc nd gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi oc"><img src="../Images/d2a66177aa589a049fa37d9e881dc3bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*woYJOk16dyGC6E-eIt5j6A.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">增加嵌入维数下的奇异值分解结果，图片由作者提供</p></figure><h2 id="76d7" class="nh kn iq bd ko ni nj dn ks nk nl dp kw lv nm nn la lz no np le md nq nr li iw bi translated">关于伯努利:</h2><p id="2545" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">基于z_i - z_j的模型比基于ZZ^T的模型表现更好。其原因可能是随着乘法运算而出现的正则化的必要性。为了便于比较，正则化被排除在外。</p><h2 id="00bb" class="nh kn iq bd ko ni nj dn ks nk nl dp kw lv nm nn la lz no np le md nq nr li iw bi translated">关于收敛时间:</h2><p id="e9e9" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">尤其引人注目的是，基于KL的模型比基于Bernoulli的模型收敛得更快。</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h1 id="f204" class="km kn iq bd ko kp mu kr ks kt mv kv kw kx mw kz la lb mx ld le lf my lh li lj bi translated">结论</h1><p id="599e" class="pw-post-body-paragraph lk ll iq lm b ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">在这项工作中提供了节点嵌入的基本原则的基准。所进行的实验证明了这样的假设，即在开发新方法之前，应该重新考虑基本原理，因为结果可能是显著不同的性能。我们公开提供我们实验的代码。如有疑问和反馈，请随时联系我们！</p></div></div>    
</body>
</html>