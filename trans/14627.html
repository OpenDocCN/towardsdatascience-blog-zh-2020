<html>
<head>
<title>An easy tutorial about Sentiment Analysis with Deep Learning and Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于深度学习和Keras的情感分析的简单教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91?source=collection_archive---------2-----------------------#2020-10-09">https://towardsdatascience.com/an-easy-tutorial-about-sentiment-analysis-with-deep-learning-and-keras-2bf52b9cba91?source=collection_archive---------2-----------------------#2020-10-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8f56" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何轻松构建、训练和验证递归神经网络</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/36a39acf21c18d9ff1808416213fc780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qlueJ0eR69nVhwl5VYF_2A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">艾莉娜·格鲁布尼亚克在<a class="ae kv" href="https://unsplash.com/s/photos/network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7176" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">放松点，这将会花你几分钟的时间来阅读，但是希望你能坚持看完整篇文章。我将带您完成一项基础任务，作为数据科学家/机器学习工程师，您必须知道如何执行这项任务，因为在您职业生涯的某个阶段，您会被要求这样做。在本文的上下文中，我假设您对我接下来要讲的内容有一个基本的理解。我会在前进的过程中不断积累概念，保持一种非常低级的语言——如果你在字里行间感到有些困惑，不要担心，稍后我可能会澄清你的疑问。主要意思是让你明白我将要解释的内容。话虽如此，还是动手吧(顺便说一句，不要错过任何细节，从<a class="ae kv" href="https://github.com/sergiovirahonda/TweetsSentimentAnalysis" rel="noopener ugc nofollow" target="_blank">我的回购</a>下载整个项目。)</p><p id="179a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我将首先定义标题中的第一个不常见的术语:<strong class="ky ir">情感分析</strong>是文本分类中非常常见的术语，本质上是使用自然语言处理(通常简称为NLP)+机器学习来解释和分类文本信息中的情感。想象一下确定一个产品的评论是正面还是负面的任务；你可以自己通过阅读来完成，对吗？但是当你工作的公司每天销售2k产品时会发生什么呢？你是不是假装看完所有的评论，手动分类？老实说，你的工作会是有史以来最糟糕的。这就是情绪分析的用武之地，它让你的生活和工作变得更加轻松。</p><h1 id="4121" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">让我们进入这个问题</h1><p id="ca14" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">有几种方法可以实现情感分析，每个数据科学家都有他/她自己喜欢的方法，我将通过一个非常简单的方法来指导你，这样你就可以理解它涉及的内容，但也可以建议你一些其他的方法来研究它们。让我们先把重要的事情放在第一位:如果你不熟悉机器学习，你必须知道所有的算法只能理解和处理数字数据(尤其是浮点数据)，因此你不能给它们输入文本，然后等着它们来解决你的问题；相反，您必须对数据进行几次转换，直到它达到一个有代表性的数字形状。常见且最基本的步骤是:</p><ul class=""><li id="1aa8" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">从每个样本中删除网址和电子邮件地址——因为它们不会增加有意义的价值。</li><li id="6fcd" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">去掉标点符号——否则你的模型不会理解“好！”和“好”其实是一个意思。</li><li id="942c" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">全部文本小写——因为您希望输入文本尽可能通用，并避免出现这种情况，例如，短语开头的“good”与另一个示例中的“Good”理解不同。</li><li id="56e2" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">删除停用词——因为它们只会增加噪音，不会让数据更有意义。顺便说一下，停用词指的是一种语言中最常见的词，如“我”、“有”、“是”等。我希望你明白这一点，因为没有一个官方的停用词列表。</li><li id="4eba" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">词干化/词汇化:这一步是可选的，但是对于大多数数据科学家来说是至关重要的。我会告诉你，取得好的结果并不重要。词干化和词汇化是非常相似的任务，都期望从语料库数据的句子的每个单词中提取词根。词汇化通常返回有效的单词(存在的)，而词干技术返回(大多数情况下)缩短的单词，这就是为什么词汇化在现实世界的实现中使用得更多。lemmatizers vs. stemmers的工作方式是这样的:假设你想找到“caring”的词根:“Caring”-&gt;<em class="ls">lemmatizer</em>-&gt;“Care”。另一方面:‘牵挂’-&gt;<em class="ls">词干</em>-&gt;‘车’；你明白了吗？如果业务需要，您可以研究这两种方法并实施其中任何一种。</li><li id="c0cc" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">将数据集(文本)转换成数字张量——通常称为<em class="ls">矢量化</em>。如果你记得上面的一些行，我解释过，像所有其他神经网络一样，深度学习模型不接受原始文本作为输入:它们只对数字张量起作用，这就是为什么这一步没有商量的余地。有多种方法可以做到这一点；例如，如果你要使用一个经典的ML模型(不是DL ),那么你肯定应该使用CountVectorizer、TFIDF Vectorizer或者只是基本的但不太好的方法:单词袋。这取决于你。然而，如果你打算实现深度学习，你可能知道最好的方法是将你的文本数据(可以理解为单词序列或字符序列)转化为低维浮点向量——不要担心，我稍后会解释这一点。</li></ul><p id="a2a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个非常基本的文本清理Python函数的样子(这是一个非常简单的方法，您可以实现一个最适合您的目的的方法—外面有非常完整的库，如Gensim或NLTK):</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="ae85" class="nj lu iq nf b gy nk nl l nm nn">def depure_data(data):<br/>    <br/>    <em class="ls">#Removing URLs with a regular expression</em><br/>    url_pattern = re.compile(r'https?://\S+|www\.\S+')<br/>    data = url_pattern.sub(r'', data)<br/><br/>    <em class="ls"># Remove Emails</em><br/>    data = re.sub('\S*@\S*\s?', '', data)<br/><br/>    <em class="ls"># Remove new line characters</em><br/>    data = re.sub('\s+', ' ', data)<br/><br/>    <em class="ls"># Remove distracting single quotes</em><br/>    data = re.sub("<strong class="nf ir">\'</strong>", "", data)<br/>        <br/>    return data</span></pre><p id="cb84" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据最短和最长的单词通常没有用的想法，现在有一个非常简单的方法来从数据集中删除重复的单词:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="920f" class="nj lu iq nf b gy nk nl l nm nn">def sent_to_words(sentences):<br/>    for sentence <strong class="nf ir">in</strong> sentences:<br/>        yield(gensim.utils.simple_preprocess(str(sentence),     deacc=True))</span></pre><p id="ce12" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，一个去除所有句子标记的函数(这是因为我将使用单词嵌入，而不是这种老式的标记方法):</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="fa24" class="nj lu iq nf b gy nk nl l nm nn">def detokenize(text):<br/>    return TreebankWordDetokenizer().detokenize(text)</span></pre><p id="ea4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要以正确的顺序运行一切，您只需运行以下命令:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="f20b" class="nj lu iq nf b gy nk nl l nm nn">temp = []<br/><em class="ls">#Splitting pd.Series to list</em><br/>data_to_list = train['selected_text'].values.tolist()<br/>for i <strong class="nf ir">in</strong> range(len(data_to_list)):<br/>    temp.append(depure_data(data_to_list[i]))<br/>data_words = list(sent_to_words(temp))<br/>data = []<br/>for i <strong class="nf ir">in</strong> range(len(data_words)):<br/>    data.append(detokenize(data_words[i]))<br/>print(data[:5])</span></pre><p id="9bc5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此时，您已经将嘈杂的文本数据集转换成了一个非常简单的文本数据集。在这个特殊的例子中，你会从这个:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="500a" class="nj lu iq nf b gy nk nl l nm nn">['I`d have responded, if I were going',<br/> 'Sooo SAD',<br/> 'bullying me',<br/> 'leave me alone',<br/> 'Sons of ****,']</span></pre><p id="a09d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对此:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="30d8" class="nj lu iq nf b gy nk nl l nm nn">['have responded if were going', 'sooo sad', 'bullying me', 'leave me alone', 'sons of']</span></pre><p id="328c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想更进一步，那么走词干化或词尾化的道路，你会得到更好的结果。在这个具体的操作方法中，将保持这种方式，只有你可以跳过这一步，完全有可能取得伟大的成果(如果你在商业环境中建立你的模型，那么你将100%有义务这样做，不要跳过它！)</p><h1 id="bff5" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">从句子到单词嵌入</h1><p id="e395" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">好了，是时候理解在处理文本数据时必须处理的一个极其重要的步骤了。一旦您的文本数据完全清除了噪声，就该将它转换成浮点张量了。为了完成这个任务，我们将使用<em class="ls">单词嵌入。</em></p><p id="6297" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">单词嵌入</strong>(或有时称为<em class="ls">单词向量</em>)从数据中学习，本质上是低维浮点向量(密集向量，与从诸如one-hot-encoding等过程中获得的稀疏向量相反)，其在几个维度中打包信息。为什么你会使用这种方法而不是其他不同的更简单的方法呢？因为深度学习模型用密集向量比用稀疏向量更容易收敛。同样，它总是取决于数据集的性质和业务需求。</p><p id="9657" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有两种方法可以获得单词嵌入:</p><ul class=""><li id="96c8" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">在模型上使用预训练的单词嵌入堆栈，就像使用预训练的NN层(或层组)一样——这是一种非常少见的方法。</li><li id="c45a" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">从头开始学习单词嵌入。为了实现这一点，你可以从随机单词向量开始，逐步学习有意义的单词向量，就像神经网络学习其权重一样。这是我们将使用的选项，实际上，随着每一个新任务学习一个新的嵌入空间是合理的。幸运的是，对于TensorFlow或Keras，这一步非常简单，您可以实现单词嵌入，就像在NN堆栈中增加一层一样。</li></ul><p id="c1f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在前进之前，我们需要迈出前一步。我们需要将文本数组转换成2D数字数组:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="56d9" class="nj lu iq nf b gy nk nl l nm nn">from keras.preprocessing.text import Tokenizer<br/>from keras.preprocessing.sequence import pad_sequences<br/>from keras import regularizers<br/><br/>max_words = 5000<br/>max_len = 200<br/><br/>tokenizer = Tokenizer(num_words=max_words)<br/>tokenizer.fit_on_texts(data)<br/>sequences = tokenizer.texts_to_sequences(data)<br/>tweets = pad_sequences(sequences, maxlen=max_len)<br/>print(tweets)</span></pre><p id="b63c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您将得到的输出如下所示:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="4870" class="nj lu iq nf b gy nk nl l nm nn">[[   0    0    0 ...   68  146   41]<br/> [   0    0    0 ...    0  397   65]<br/> [   0    0    0 ...    0    0   11]<br/> ...<br/> [   0    0    0 ...  372   10    3]<br/> [   0    0    0 ...   24  542    4]<br/> [   0    0    0 ... 2424  199  657]]</span></pre><p id="a9b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上一步是什么意思？让我们从官方的Keras文档中获取定义，您会更好地理解这一点:</p><blockquote class="no np nq"><p id="5985" class="kw kx ls ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">这个函数将序列列表(长度为<code class="fe nu nv nw nf b">num_samples</code>)转换成形状为<code class="fe nu nv nw nf b">(num_samples, num_timesteps)</code>的2D Numpy数组。<code class="fe nu nv nw nf b">num_timesteps</code>或者是<code class="fe nu nv nw nf b">maxlen</code>参数(如果提供的话)，或者是列表中最长序列的长度。</p><p id="967b" class="kw kx ls ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">比<code class="fe nu nv nw nf b">num_timesteps</code>短的序列用<code class="fe nu nv nw nf b">value</code>填充，直到它们长到<code class="fe nu nv nw nf b">num_timesteps</code>。</p><p id="35ad" class="kw kx ls ky b kz la jr lb lc ld ju le nr lg lh li ns lk ll lm nt lo lp lq lr ij bi translated">长于<code class="fe nu nv nw nf b">num_timesteps</code>的序列被截断，以便符合所需的长度</p></blockquote><h1 id="1f25" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">嵌入层</h1><p id="f645" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">非常重要的是你要记住，无论你使用TensorFlow还是其他任何<em class="ls">as action API</em>比如Keras <em class="ls">、</em>在你的训练结束时你都应该得到相同的结果。在这次机会中，我们将使用Keras，原因很明显:它非常容易实现。这是创建嵌入层的方法:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="c283" class="nj lu iq nf b gy nk nl l nm nn">from keras.layers import Embedding<br/>embedding_layer = Embedding(1000, 64)</span></pre><p id="936b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的层采用形状的2D整数张量(样本，sequence_length)和至少两个参数:可能的记号的数量和嵌入的维数(这里分别是1000和64)。更形象地说，只需想象嵌入层是一个将整数索引链接到密集向量的字典。最后，它返回一个形状的3D浮点张量(样本，序列长度，嵌入维数)，现在可以由我们的神经网络处理。让我们来谈谈这个话题，特别是当需要处理文本相关序列时，递归神经网络是最好的。</p><h1 id="f131" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">递归神经网络变得简单</h1><p id="1d17" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">通常，其他类型的神经网络如密集连接网络或卷积网络没有记忆，这意味着每个输入都是独立处理的，与其他输入无关。这与你阅读一段文字时通常会做的事情相反:当你阅读时，你会在记忆中保留你在前面几行读到的内容，对吗？你有一个整体意义的感觉，这正是RNNs采用的原则。它们处理序列的方式是沿着序列元素进行迭代，并保存与迄今为止已处理的内容相关的信息。老实说，在RNN引擎盖下的数学是一个你应该自己去理解它的逻辑的话题。我建议你读一读汤姆·霍普的《<em class="ls">学习张量流</em>》(此处有<a class="ae kv" href="https://www.oreilly.com/library/view/learning-tensorflow/9781491978504/" rel="noopener ugc nofollow" target="_blank"/>)，它以一种非常简单的方式解释了所有的过程。</p><p id="886b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我将实现三种RNN类型:单一LSTM(长短期记忆)模型、双向LSTM和很少使用的Conv1D模型。作为奖励，我展示了如何实现一个SimpleRNN模型，但老实说，它并没有在生产中部署，因为它非常简单。</p><h2 id="7b88" class="nj lu iq bd lv nx ny dn lz nz oa dp md lf ob oc mf lj od oe mh ln of og mj oh bi translated">LSTM层</h2><p id="929a" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">回到我们的例子，这是实现单个LSTM层模型及其相应的嵌入层时的代码:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="4776" class="nj lu iq nf b gy nk nl l nm nn">from keras.models import Sequential<br/>from keras import layers<br/>from keras import regularizers<br/>from keras import backend as K<br/>from keras.callbacks import ModelCheckpoint</span><span id="7c8e" class="nj lu iq nf b gy oi nl l nm nn">model1 = Sequential()<br/>model1.add(layers.Embedding(max_words, 20)) #The embedding layer<br/>model1.add(layers.LSTM(15,dropout=0.5)) #Our LSTM layer<br/>model1.add(layers.Dense(3,activation='softmax'))<br/><br/><br/>model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])<br/><br/>checkpoint1 = ModelCheckpoint("best_model1.hdf5", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)</span><span id="973c" class="nj lu iq nf b gy oi nl l nm nn">history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])</span></pre><p id="7653" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的代码中有几件事情需要强调:当实现一个Keras顺序模型时，这都是关于堆叠层的。LSTM图层(以及所有其他RNN图层)可以接受几个参数，但我定义的参数是<em class="ls"> 15 </em>，这是图层中隐藏单元的数量(必须是正整数，表示输出空间的维度)和图层的丢失率。<strong class="ky ir"> Dropout是NNs </strong>最有效和最常用的正则化技术之一，包括在训练期间随机关闭隐藏单元，这样网络就不会100%依赖于所有的神经元，而是迫使自己在数据中找到更有意义的模式，以增加你试图优化的指标。还有几个其他的参数要传递，你可以在这里找到完整的文档<a class="ae kv" href="https://keras.io/api/layers/recurrent_layers/lstm/" rel="noopener ugc nofollow" target="_blank">，但是对于这个特殊的例子，这些设置会达到很好的效果。</a></p><p id="18b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">仅供参考，有时<strong class="ky ir">一个接一个地堆叠几个递归层</strong>是有用的，这样可以增加网络的代表性。如果你想这样做，那么<strong class="ky ir">你必须返回完整的输出序列</strong>。这是一个例子:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="4549" class="nj lu iq nf b gy nk nl l nm nn"><em class="ls">model0 = Sequential()</em><br/><em class="ls">model0.add(layers.Embedding(max_words, 15))</em><br/><em class="ls">model0.add(layers.SimpleRNN(15,return_sequences=True))<br/>model0.add(layers.SimpleRNN(15))<br/>model0.add(layers.Dense(3,activation='softmax'))</em></span></pre><p id="937c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的LSTM示例中，我堆叠了一个具有三个输出单元的密集图层，这三个输出单元将是数据集的3个可能的类。为了进行概率输出，最好在最后一层使用“softmax”作为激活函数。构建神经网络时使用下表，您会感到困惑:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/021f7508cfd7b625b042bd08557dff76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7M2qJVG9WN8whpZ16rIddQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">神经网络配置和训练的基本参数。</p></figure><p id="cdd7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当编译模型时，我使用RMSprop optimizer的默认学习速率，但实际上这取决于每个开发人员。有人爱Adam，有人爱Adadelta，以此类推。老实说，RMSprop或Adam在大多数情况下应该足够了。如果您不知道优化器是什么，它只是一种不断计算损失梯度并定义如何逆着损失函数移动以找到其全局最小值并因此找到最佳网络参数(模型内核及其偏差权重)的机制。作为损失函数，我使用categorical _ crossentropy(检查表格),它通常在处理多类分类任务时使用。另一方面，当需要二进制分类时，可以使用binary_crossentropy。</p><p id="ddfc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我使用检查点来保存在训练过程中获得的最佳模型。当您需要获得最能满足您试图优化的指标的模型时，这非常有用。然后是经典的model.fit步骤，等待它完成训练迭代。</p><p id="d518" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是该神经网络体系结构在上一个时期获得的验证分数:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="80cf" class="nj lu iq nf b gy nk nl l nm nn">Epoch 70/70<br/>645/645 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8881<br/>Epoch 00070: val_accuracy did not improve from 0.84558</span></pre><p id="6a11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们用一个更复杂的网络来比较一下。</p><h2 id="0eba" class="nj lu iq bd lv nx ny dn lz nz oa dp md lf ob oc mf lj od oe mh ln of og mj oh bi translated">双向层</h2><p id="8278" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">这是我们示例的BidRNN实现的样子:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="a8cc" class="nj lu iq nf b gy nk nl l nm nn">model2 = Sequential()<br/>model2.add(layers.Embedding(max_words, 40, input_length=max_len))<br/>model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))<br/>model2.add(layers.Dense(3,activation='softmax'))<br/>model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])<br/>checkpoint2 = ModelCheckpoint("best_model2.hdf5", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)<br/>history = model2.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])</span></pre><p id="d03e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们更好地理解双向层是如何工作的。它最大化了rnn的顺序敏感性:本质上，它由两个rnn(lstm或gru)组成，这两个rnn在一个不同的方向上处理输入序列，以最终合并表示。通过这样做，他们能够捕捉到比单个RNN层更复杂的图案。换句话说，其中一层按时间顺序解释序列，第二层按反时间顺序解释，这就是为什么双向rnn被广泛使用，因为它们比常规rnn提供更好的性能。</p><p id="4afa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它们的实现方式并不复杂，只是一层在另一层之内。如果你仔细阅读，我使用几乎相同的参数，但在其整体训练中实现了大约0.3%的验证准确性:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="4dd5" class="nj lu iq nf b gy nk nl l nm nn">Epoch 70/70<br/>644/645 [============================&gt;.] - ETA: 0s - loss: 0.2876 - accuracy: 0.8965<br/>Epoch 00070: val_accuracy did not improve from 0.84849</span></pre><p id="ab0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个非常好的数字，即使它是一个非常简单的模型，我并没有专注于超参数调整。我确信，如果你致力于调整它们，你会得到一个非常好的结果。不幸的是，没有神奇的公式可以做到这一点，这一切都是关于调整其架构，迫使它每次都学习更复杂的模式，并通过更多的正则化来控制其过度拟合的趋势。要强调的一件重要事情是，如果您看到您的模型精度/损失停留在某个值附近，这可能是因为学习率太小，因此使您的优化器停留在损失函数的局部最小值附近；增大LR，或者尝试另一个优化器。</p><p id="53c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在是时候尝试另一种类型的架构了，尽管它不是文本分类的最佳选择，但众所周知，它在处理文本数据集时会取得非常好的效果。让我们开始吧。</p><h2 id="a0e4" class="nj lu iq bd lv nx ny dn lz nz oa dp md lf ob oc mf lj od oe mh ln of og mj oh bi translated">更进一步——1D卷积神经网络</h2><p id="17af" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我希望你还和我在一起，因为这是谈论收敛时最快的模型之一——它需要更便宜的计算成本。根据以前的经验，我知道它倾向于在小数据集上非常快地过度拟合。从这个意义上来说，如果你感兴趣的话，我会实现它来告诉你怎么做，并且给你一个关于它如何工作的概述。</p><p id="3220" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它使用与用于图像分类的经典2D变换网相同的原理。卷积层从1D/2D张量中提取面片(取决于任务和层的类型)，并对每个面片应用相同的卷积变换(得到几个子序列作为输出)。我不会深入解释，因为这超出了本文的范围，但是如果你想完全理解这些层是如何工作的，我建议你查看一下之前推荐的书。这些层最重要的事实是，它们可以识别序列中的模式——在一个句子的某个位置学习的模式可以在后来的不同位置甚至在另一个句子中识别。</p><p id="49ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">1D通信网是这样实现的:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="9ef4" class="nj lu iq nf b gy nk nl l nm nn">model3.add(layers.Embedding(max_words, 40, input_length=max_len))<br/>model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))<br/>model3.add(layers.MaxPooling1D(5))<br/>model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))<br/>model3.add(layers.GlobalMaxPooling1D())<br/>model3.add(layers.Dense(3,activation='softmax'))<br/>model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])<br/>history = model3.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test))</span></pre><p id="3148" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<strong class="ky ir"> Conv1D </strong>层负责<strong class="ky ir">计算</strong> <strong class="ky ir">卷积运算</strong>，而<strong class="ky ir"> MaxPooling1D </strong>层的主要任务是<strong class="ky ir">降低每个卷积输出的维度</strong>。一旦执行了卷积运算，MaxPooling窗口将提取其中的最大值，并输出最大值的面片。在这种类型的配置中，强调正则化的重要性是很重要的，否则你的网络将会学习无意义的模式，并以极快的速度过度适应——仅供参考。</p><p id="48c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了对比之前模型的表现，这是上一个时期达到的指标:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="adf5" class="nj lu iq nf b gy nk nl l nm nn">Epoch 70/70<br/>645/645 [==============================] - 5s 7ms/step - loss: 0.3096 - acc: 0.9173 - val_loss: 0.5819 - val_acc: 0.8195</span></pre><p id="d627" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其最佳验证准确率约为82%。即使我已经实施了非常激烈的调整，它还是过拟合得非常快。</p><h1 id="80dc" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">验证我们的最佳模型</h1><p id="b9b0" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在这一点上，迄今为止最好的模型是双向RNN。请记住，这些指标是通过从很少到零的超参数调整获得的。为了更好地理解它的预测，让我们看看它的混淆矩阵:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/312e3102daf080e505a27171004e4a36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gV2PVoNv7ffpQ6G-hCCWUw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">最佳模特的困惑矩阵-作者图片。</p></figure><p id="e546" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面的图像中，我们可以推断出:81%的正面评级被归类为正面，80%的负面评级被归类为负面，91%的中性评级被归类为中性。这些并不是最好的预测，但却是建立更好模型的良好基础。在商业场景中，在最简单的情况下，您需要接近95%。</p><p id="89b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您想测试它如何处理您自己的输入，只需计算下面几行:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="8adb" class="nj lu iq nf b gy nk nl l nm nn">sentiment = ['Neutral','Negative','Positive']</span><span id="67bb" class="nj lu iq nf b gy oi nl l nm nn">sequence = tokenizer.texts_to_sequences(['this data science article is the best ever'])<br/>test = pad_sequences(sequence, maxlen=max_len)<br/>sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]</span></pre><p id="502a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出将是:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="c140" class="nj lu iq nf b gy nk nl l nm nn">'Positive'</span></pre><h1 id="d9d6" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">最后的想法</h1><p id="f6d6" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">好了，我们已经到了这篇文章的结尾。我鼓励您自己实现所有模型，并专注于超参数调优，这是需要较长时间的任务之一。一旦你达到一个好的数字，我会在这里见你，指导你通过该模型的部署😊。</p><p id="8da4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有几种方法可以完成这样的任务。你可以使用谷歌云平台，走Azure之路，甚至更便宜的Heroku之路，但让我们诚实地说:大多数最大的公司都采用AWS作为他们的主要公共云提供商，这些家伙有一个奇妙的平台来构建、培训和部署ML模型:<strong class="ky ir">AWS SageMaker</strong>；那里有大量的文档。我将会发布另一个逐步讲解的教程，讲述如何在上面轻松地部署模型。我希望在那里见到你！</p></div></div>    
</body>
</html>