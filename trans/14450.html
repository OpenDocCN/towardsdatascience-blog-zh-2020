<html>
<head>
<title>AWS DeepRacer: The fun way of Learning Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS DeepRacer:强化学习的有趣方式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/aws-deepracer-the-fun-way-of-learning-reinforcement-learning-c961cde9ce8b?source=collection_archive---------29-----------------------#2020-10-05">https://towardsdatascience.com/aws-deepracer-the-fun-way-of-learning-reinforcement-learning-c961cde9ce8b?source=collection_archive---------29-----------------------#2020-10-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><h1 id="11a9" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">欢迎来到AWS DeepRacer之旅</h1><p id="7b89" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">最近，我参加了一个训练营，将开始我学习强化学习(RL)的旅程。这个训练营是由亚马逊网络服务(AWS)和雅加达机器学习(JML)举办的。在接下来的三个月里，我们将接受AWS经验丰富的代表的指导，学习和应用强化学习理念。</p><blockquote class="lm ln lo"><p id="8143" class="ko kp lp kq b kr lq kt ku kv lr kx ky ls lt lb lc lu lv lf lg lw lx lj lk ll im bi translated">这将是一个令人兴奋的旅程，因为我们将使用AWS DeepRacer以有趣的方式学习强化学习，并带上您！</p></blockquote><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/3a13b3f5345f0aaa8dfebba7236b4caa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*umNglNLInmcgVqxi"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">尼古拉斯·佩罗尔在<a class="ae mo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="d496" class="jq jr it bd js jt mw jv jw jx mx jz ka kb my kd ke kf mz kh ki kj na kl km kn bi translated">了解AWS DeepRacer</h1><p id="1983" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们先从了解什么是AWS DeepRacer开始。DeepRacer是AWS将强化学习带到每个开发者手中的举措之一。这项倡议带来了一种有趣的学习机器学习的方法，特别是RL，使用自动驾驶赛车，3D在线赛车模拟器来建立你的模型，以及比赛。</p><h2 id="6fef" class="nb jr it bd js nc nd dn jw ne nf dp ka kz ng nh ke ld ni nj ki lh nk nl km nm bi translated">AWS深赛车</h2><p id="17b2" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">AWS DeepRacer Evo是一辆1/18比例的自动驾驶赛车，由强化学习驱动。这辆车配有左右前置摄像头，组成立体摄像头。立体摄像机可以帮助车辆学习图像中的深度信息，这些信息可用于感知和避免轨道上的物体被接近。这辆车还有一个向后的激光雷达传感器，用于检测车辆后面和旁边的物体。立体相机和激光雷达传感器的结合实现了物体回避和短兵相接的比赛。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nn"><img src="../Images/84c08feb64ff80b1513219e6c1720f60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*poGYEMwmY6JBOqmCZ2HqbA.gif"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">AWS DeepRacer Evo汽车。图片由AWS DeepRacer提供</p></figure><h2 id="73c0" class="nb jr it bd js nc nd dn jw ne nf dp ka kz ng nh ke ld ni nj ki lh nk nl km nm bi translated">AWS DeepRacer控制台</h2><p id="cc7b" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">作为开发人员，我们可以在3D在线赛车模拟器中训练、评估和调整RL模型。这个旅程可以从学习RL的基础开始。AWS提供了易于理解的学习材料来掌握基础知识。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi no"><img src="../Images/ef152bf994977c7f5ca7faed19da30dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t6x81SEFNyiXty3K5T6a9w.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">模型创建流程。作者图片</p></figure><p id="6814" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">然后，我们可以开始在AWS控制台中构建、训练和评估我们的模型。为了使它更容易，我们还可以开始使用预构建模型示例。AWS DeepRacer控制台也为我们提供了执行此类任务的能力:</p><ul class=""><li id="8321" class="np nq it kq b kr lq kv lr kz nr ld ns lh nt ll nu nv nw nx bi translated">创建RL训练作业，以创建具有特定奖励函数、优化算法、超参数和环境的模型。</li><li id="2927" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll nu nv nw nx bi translated">选择一个轨道来训练和评估一个模型。</li><li id="cd47" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll nu nv nw nx bi translated">克隆一个训练模型，通过调整超参数来优化模型的性能。</li><li id="aff5" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll nu nv nw nx bi translated">下载部署到AWS DeepRacer车辆的模型，以便它可以驾驶。</li><li id="5ea3" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll nu nv nw nx bi translated">提交一个模型到一个虚拟的比赛中，并与其他模型进行比较。</li></ul><h2 id="d94f" class="nb jr it bd js nc nd dn jw ne nf dp ka kz ng nh ke ld ni nj ki lh nk nl km nm bi translated">AWS深度赛车联盟</h2><p id="2fa3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">一旦我们的模型准备好了，我们就可以将模型部署到AWS DeepRacer的在线或离线AWS DeepRacer联赛中，从而有机会赢得AWS DeepRacer冠军杯。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi od"><img src="../Images/c357e7c01f2b64cb4f18566ab2b537b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*z7-jNLP-4_3ljcL4"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">约书亚·戈尔德在<a class="ae mo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="bff1" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">2020年AWS DeepRacer联赛有两种比赛方式。首先是在线虚拟电路，它允许你在世界任何地方进行比赛。AWS还提供免费等级，使您能够进行10小时的培训。所以你可以免费进入联盟。第二个是顶峰赛道，在这里你可以和其他车手在顶峰比赛。</p><p id="3586" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">今年，联盟提供了三种比赛形式。它们是头对头，物体回避和计时赛。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi oe"><img src="../Images/c77e1c72f27e7043265ae3873d333335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2LPL4O2QmAMEBN_sPI5NUA.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">AWS深赛车联盟比赛格式。作者图片</p></figure><ul class=""><li id="d591" class="np nq it kq b kr lq kv lr kz nr ld ns lh nt ll nu nv nw nx bi translated">在<strong class="kq iu">面对面</strong>排位赛中，我们需要完成几圈，同时避免AWS机器人赛车在赛道上移动。月底，前32名选手将被列入淘汰名单，我们需要与其他选手展开正面交锋。</li><li id="16b7" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll nu nv nw nx bi translated">在<strong class="kq iu">物体躲避</strong>比赛中，我们需要完成赛道，同时躲避路上指定数量的障碍物。最快的赛车手将晋级争夺冠军奖杯。</li><li id="e8e2" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll nu nv nw nx bi translated">在<strong class="kq iu">计时赛</strong>比赛中，我们需要在赛道上完成规定的圈数。谁跑得最快，谁就能晋级争夺冠军奖杯。</li></ul></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="f1c9" class="jq jr it bd js jt mw jv jw jx mx jz ka kb my kd ke kf mz kh ki kj na kl km kn bi translated">强化学习</h1><p id="8d16" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">现在，让我们看看车轮后面，了解强化学习的基本概念。RL是一种先进的机器学习(ML)技术，采用与其他机器学习方法非常不同的方法来训练模型。它的超级能力是，它可以在不需要任何标记训练数据的情况下学习非常复杂的行为，并可以在为长期目标优化的同时做出短期决策。</p><h2 id="8d7b" class="nb jr it bd js nc nd dn jw ne nf dp ka kz ng nh ke ld ni nj ki lh nk nl km nm bi translated">RL基础</h2><p id="e23e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在强化学习中，一个<strong class="kq iu">代理</strong>将探索一个<strong class="kq iu">环境</strong>来执行任务，采取<strong class="kq iu">行动</strong>并产生好的结果，避免坏的结果。该模型将从经验中学习，随着时间的推移，它将能够识别哪些活动会带来最佳的<strong class="kq iu">回报</strong>。</p><p id="2f17" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">这里有一个有趣的例子来解释强化学习。在实验中，给鸡的任务是只钉粉红色的纸。当小鸡钉住正确的纸时，小鸡会被奖励食物。当桌子上引入其他颜色时，挑战变得更加有趣。有趣的是，这只鸡仍然设法只盯住粉红色。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="of og l"/></div></figure><h2 id="94ec" class="nb jr it bd js nc nd dn jw ne nf dp ka kz ng nh ke ld ni nj ki lh nk nl km nm bi translated">AWS DeepRacer中的重要RL术语</h2><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi oh"><img src="../Images/3959523a325c04f1a7c3068cc75d153b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PkQwHZHBn5iMi2D5mYXEZw.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">AWS DeepRacer中的重要术语。作者图片</p></figure><p id="cfcd" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">有几个重要术语可用于探索这些想法，并理解它们与AWS DeepRacer的关系:</p><ol class=""><li id="bbf9" class="np nq it kq b kr lq kv lr kz nr ld ns lh nt ll oi nv nw nx bi translated"><strong class="kq iu">代理人。</strong>代理由需要培训的AWS DeepRacer车辆代表。更具体地说，它体现了控制车辆、接受输入和决定行动的神经网络。</li><li id="f921" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll oi nv nw nx bi translated"><strong class="kq iu">环境。</strong>该环境包含一条定义车辆行驶路线的轨道。代理探索环境以收集数据来训练底层神经网络。</li><li id="6ea6" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll oi nv nw nx bi translated"><strong class="kq iu">状态</strong>。状态表示代理在某个时间点所处环境的快照。前置摄像头捕捉车辆上的这种状态。</li><li id="b11e" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll oi nv nw nx bi translated"><strong class="kq iu">动作</strong>。动作是代理在当前状态下做出的决定。对于AWS DeepRacer，动作对应于车辆以特定速度和转向角度移动。</li><li id="902f" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll oi nv nw nx bi translated"><strong class="kq iu">奖励</strong>。奖励是当代理在给定的状态下采取行动时作为反馈给代理的分数。在训练AWS DeepRacer模型时，奖励由一个<em class="lp">奖励函数</em>返回。一般来说，您定义或提供一个奖励函数来指定在给定的状态下代理应该采取什么样的行动。</li><li id="430d" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll oi nv nw nx bi translated"><strong class="kq iu">剧集</strong>。一集是代理终止之前的一组过程。</li></ol><h2 id="0f8a" class="nb jr it bd js nc nd dn jw ne nf dp ka kz ng nh ke ld ni nj ki lh nk nl km nm bi translated">如何训练车辆</h2><p id="bce3" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在这一点上，我们将在高层次上探索如何培训AWS DeepRacer。训练过程是一个迭代的tass。在模拟器中，代理将探索环境并获得经验。收集的经验用于更新模型，更新的模型用于获得更多的经验。</p><p id="abe9" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">我们将在一个简化的环境中看到这些示例，以便真正了解培训过程是如何进行的。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi oj"><img src="../Images/65a755a4967b72cd430874ff131af297.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NhyMhAVJg3ASOgzmna8WJw.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">简化的学习过程。作者图片</p></figure><p id="5219" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">在这个例子中，我们希望车辆以最短的路径从起点到终点，而不离开赛道。然后我们可以将环境简化为一个正方形网格。每个方块代表一个单独的状态，我们将允许车辆在面向目标的方向上上下移动。</p><p id="007b" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">我们可以给网格中的每个方块分配一个分数，以决定激励什么行为。这里，我们将轨道边缘的方块指定为“停止状态”,这将告诉车辆它已经偏离了轨道并且失败了。因为我们想让车辆学会沿着轨道中心行驶，所以我们为中心线上的方块提供高奖励，而在其他地方提供低奖励。</p><p id="39a3" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">在强化训练中，车辆将从探索网格开始，直到它移动出界或到达目的地。当它四处行驶时，车辆从我们定义的分数中累积奖励。这个过程被称为<em class="lp">插曲</em>。学习将需要一些迭代，以使车辆能够获取知识。</p><p id="6022" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">代理人需要<em class="lp">探索</em>，看看在哪里可以获得最高的回报，然后才能使用或<em class="lp">利用</em>这些知识。随着代理获得越来越多的经验，它学会留在中央广场，以获得更高的奖励。</p><p id="a6cd" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">随着更多的经验，代理变得更好，最终可以可靠地到达目的地，并找到最高的奖励。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ok"><img src="../Images/2d66689e34d3b798640917248dc9c629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nKWy5q-I9qWC4lq-"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">照片由<a class="ae mo" href="https://unsplash.com/@a8ka?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">安东·舒瓦洛夫</a>在<a class="ae mo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="5ea7" class="jq jr it bd js jt mw jv jw jx mx jz ka kb my kd ke kf mz kh ki kj na kl km kn bi translated">结论</h1><p id="3d0c" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">到目前为止，你应该已经知道什么是AWS DeepRacer，以及AWS DeepRacer车辆、训练控制台和AWS DeepRacer League等每个组件。您还将了解强化学习的基础知识及其在AWS DeepRacer中的应用，包括重要术语和培训的执行方式。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="a77f" class="jq jr it bd js jt mw jv jw jx mx jz ka kb my kd ke kf mz kh ki kj na kl km kn bi translated">文献学</h1><ul class=""><li id="f205" class="np nq it kq b kr ks kv kw kz ol ld om lh on ll nu nv nw nx bi translated"><a class="ae mo" href="https://aws.amazon.com/deepracer/" rel="noopener ugc nofollow" target="_blank">https://aws.amazon.com/deepracer/</a></li><li id="d171" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll nu nv nw nx bi translated"><a class="ae mo" href="https://docs.aws.amazon.com/deepracer/latest/developerguide/what-is-deepracer.html?icmpid=docs_deepracer_console" rel="noopener ugc nofollow" target="_blank">https://docs . AWS . Amazon . com/deep racer/latest/developer guide/what-is-deep racer . html？ICM PID = docs _ deep racer _ console</a></li><li id="aceb" class="np nq it kq b kr ny kv nz kz oa ld ob lh oc ll nu nv nw nx bi translated"><a class="ae mo" href="https://d2k9g1efyej86q.cloudfront.net/" rel="noopener ugc nofollow" target="_blank"> AWS强化学习简介</a></li></ul></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="4540" class="jq jr it bd js jt mw jv jw jx mx jz ka kb my kd ke kf mz kh ki kj na kl km kn bi translated">关于作者</h1><p id="66d0" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">Bima是一名数据科学家，他总是渴望扩展自己的知识和技能。他毕业于万隆技术学院和新南威尔士大学，分别是采矿工程师。然后他通过HardvardX、IBM、Udacity等的各种在线课程开始了他的数据科学之旅。目前，他正与DANA Indonesia一起在印度尼西亚建立一个无现金社会。</p><p id="29e7" class="pw-post-body-paragraph ko kp it kq b kr lq kt ku kv lr kx ky kz lt lb lc ld lv lf lg lh lx lj lk ll im bi translated">如果您有任何疑问或任何要讨论的话题，请通过<a class="ae mo" href="https://www.linkedin.com/in/bpratama/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系Bima。</p></div></div>    
</body>
</html>