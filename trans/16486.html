<html>
<head>
<title>Cactus image classification using convolutional neural network (CNN) that reaches over 98% accuracy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用卷积神经网络(CNN)的仙人掌图像分类达到98%以上的准确率</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cactus-image-classification-using-convolutional-neural-network-cnn-that-reaches-98-accuracy-8432e068f1ea?source=collection_archive---------48-----------------------#2020-11-13">https://towardsdatascience.com/cactus-image-classification-using-convolutional-neural-network-cnn-that-reaches-98-accuracy-8432e068f1ea?source=collection_archive---------48-----------------------#2020-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="15ee" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我们的目标是构建一个分类器，将图像分类为“仙人掌”或“非仙人掌”</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/2089d2f47a2d2008c52575cdee29bb13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n7ntbl-2zqCvYZO8K3tc5g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://www.pexels.com/photo/landscape-mountains-sky-night-34107/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">像素</a>的<a class="ae kv" href="https://www.pexels.com/@pixabay?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>拍摄</p></figure><h1 id="b6ab" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">了解数据集</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lo"><img src="../Images/9cb67ef1c7b5e08391379c4aa81506c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zX2HuNca52o1tG_HOtsDA.png"/></div></div></figure><p id="1e54" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx ly lz ma mb mc md me mf mg mh mi mj mk ij bi translated">这个分类问题来自于<a class="ae kv" href="https://www.kaggle.com/irvingvasquez/cactus-aerial-photos" rel="noopener ugc nofollow" target="_blank">卡格尔挑战赛</a>中的一个。我们的目标是构建一个分类器，将图像分类为“仙人掌”或“非仙人掌”训练集包括17500幅图像，而验证集有4000幅图像。有仙人掌标志的图像在名为cactus的文件夹中，反之亦然。以下是来自训练数据集的示例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/c62fe87d83dc18ba4c99c569c90a28e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/format:webp/1*h4WFO0wpWXd2SXuj7tDAzQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">仙人掌</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/9de706aa9093f67e500fe57ac2799dc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*NosAx3Xl4LV_XTfUmbaO6A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">非仙人掌</p></figure><h1 id="8f13" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据预处理</h1><p id="1328" class="pw-post-body-paragraph lp lq iq lr b ls mn jr lu lv mo ju lx ly mp ma mb mc mq me mf mg mr mi mj mk ij bi translated">当我们通过使用Pyplot库简单地绘制这些图像来仔细查看其中一些图像时，我们可以观察到它们的大小不同，不适合后面的训练过程。另外，请注意，我们用1和0标记了所有图像，表示仙人掌和非仙人掌。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/6be71bdae64bbf8d935a58607ee0f8b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jMFwn0buxBJOqYqg3SI3Eg.png"/></div></div></figure><p id="6d4e" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx ly lz ma mb mc md me mf mg mh mi mj mk ij bi translated">因此，我们需要将所有的图像标准化为相同的大小。根据我们的实验，最佳策略是将这些图像裁剪为48×48像素的大小。下面是一些裁剪过的图片。第一行显示原始图像，第二行显示修改后的图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/a4a3ba2577df95d716252b717ac0ea35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5P-1odU3YdUOZnKDGIQC2w.png"/></div></div></figure><p id="8133" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx ly lz ma mb mc md me mf mg mh mi mj mk ij bi translated">这种方法的好处是它保存了图像的所有细节；然而，我们有时会丢失图像的边缘，如果图像太小，我们需要用黑色背景扩展图像，使其大小与其他图像相同。失去边缘可能是一个大问题，因为我们有可能用这种技术将仙人掌从图像中切掉。</p><h1 id="c2e1" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">CNN结构和培训</h1><p id="2c49" class="pw-post-body-paragraph lp lq iq lr b ls mn jr lu lv mo ju lx ly mp ma mb mc mq me mf mg mr mi mj mk ij bi translated">卷积神经网络包含3层卷积层和2个全连接层。每个卷积层都有一个3乘3滤波器，步长为2，输出为64个节点。之后，数据通过max-pooling层，以防止过度拟合并提取有用的信息。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="cfa1" class="mz kx iq mv b gy na nb l nc nd">model = Sequential()</span><span id="f3a8" class="mz kx iq mv b gy ne nb l nc nd">model.add(Conv2D(64, (3,3), input_shape = X_train.shape[1:]))</span><span id="a200" class="mz kx iq mv b gy ne nb l nc nd">model.add(Activation(‘relu’))</span><span id="2165" class="mz kx iq mv b gy ne nb l nc nd">model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="7d1a" class="mz kx iq mv b gy ne nb l nc nd">model.add(Conv2D(64, (3,3)))</span><span id="1ca4" class="mz kx iq mv b gy ne nb l nc nd">model.add(Activation(‘relu’))</span><span id="b5cd" class="mz kx iq mv b gy ne nb l nc nd">model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="366c" class="mz kx iq mv b gy ne nb l nc nd">model.add(Conv2D(64, (3,3)))</span><span id="907e" class="mz kx iq mv b gy ne nb l nc nd">model.add(Activation(‘relu’))</span><span id="89e1" class="mz kx iq mv b gy ne nb l nc nd">model.add(MaxPooling2D(pool_size=(2,2)))</span><span id="4935" class="mz kx iq mv b gy ne nb l nc nd">model.add(Flatten())</span><span id="d7bc" class="mz kx iq mv b gy ne nb l nc nd">model.add(Dense(64))</span><span id="69ec" class="mz kx iq mv b gy ne nb l nc nd">model.add(Dense(1))</span><span id="72c1" class="mz kx iq mv b gy ne nb l nc nd">model.add(Activation(‘sigmoid’))</span><span id="2250" class="mz kx iq mv b gy ne nb l nc nd">model.compile(loss=”binary_crossentropy”,</span><span id="307a" class="mz kx iq mv b gy ne nb l nc nd">optimizer=”adam”,</span><span id="5672" class="mz kx iq mv b gy ne nb l nc nd">metrics=[‘accuracy’])</span><span id="973b" class="mz kx iq mv b gy ne nb l nc nd">history = model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_split=0.1, use_multiprocessing=True)</span><span id="0302" class="mz kx iq mv b gy ne nb l nc nd">model.save(‘model_48_crop’)</span></pre><p id="2012" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx ly lz ma mb mc md me mf mg mh mi mj mk ij bi translated">下面是模型结构的概述。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/b8dc8aa02e47765a2f8ee342ab1d2172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*mHwAa0nhEP6zflcA5T4gXA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模型概述</p></figure><p id="41c1" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx ly lz ma mb mc md me mf mg mh mi mj mk ij bi translated">我们用10个纪元来训练模型，结果显示出惊人的效果。第一个精度是下面代码片段中的训练精度，第二个精度是验证精度。请注意，在最终预测之前，我们使用了部分(10%)训练集作为验证集。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/0bb212d718c1eeddfabe7311de6d940a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J610CxtGaoVMxrjTwKETew.png"/></div></div></figure><h1 id="5459" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">试验结果</h1><p id="9e73" class="pw-post-body-paragraph lp lq iq lr b ls mn jr lu lv mo ju lx ly mp ma mb mc mq me mf mg mr mi mj mk ij bi translated">我们使用Kaggle提供的validation_set作为我们的测试集，对我们训练好的模型进行最终预测。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="5a29" class="mz kx iq mv b gy na nb l nc nd">testdata = pd.read_pickle(“pickled_data_validation/crop_images(48, 48).pkl”)</span><span id="1794" class="mz kx iq mv b gy ne nb l nc nd">test_images = testdata.loc[:, data.columns != ‘class’]</span><span id="95e9" class="mz kx iq mv b gy ne nb l nc nd">test_images = test_images.to_numpy()</span><span id="1c10" class="mz kx iq mv b gy ne nb l nc nd">test_images = test_images.reshape((len(test_images),48, 48, 3))</span><span id="cfea" class="mz kx iq mv b gy ne nb l nc nd">test_images = test_images/255.0</span><span id="e8e4" class="mz kx iq mv b gy ne nb l nc nd">print(test_images.shape)</span><span id="8a4a" class="mz kx iq mv b gy ne nb l nc nd">test_labels = testdata[‘class’]</span><span id="b855" class="mz kx iq mv b gy ne nb l nc nd">test_labels = test_labels.to_numpy()</span><span id="3024" class="mz kx iq mv b gy ne nb l nc nd">type(test_labels)</span><span id="786b" class="mz kx iq mv b gy ne nb l nc nd">test_labels = test_labels.reshape((len(test_labels),1))</span><span id="94a2" class="mz kx iq mv b gy ne nb l nc nd">loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)</span><span id="dab6" class="mz kx iq mv b gy ne nb l nc nd">print(‘Restored model, accuracy: {:5.2f}%’.format(100*acc))</span></pre><p id="64bd" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx ly lz ma mb mc md me mf mg mh mi mj mk ij bi translated">这是结果。它达到了几乎99%的准确率，这是惊人的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8046e53d6ddb61c6bc3c058627c8efc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*yQQIqSMFYfyFmskR8rYeuA.png"/></div></figure><h1 id="4da1" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="bb8d" class="pw-post-body-paragraph lp lq iq lr b ls mn jr lu lv mo ju lx ly mp ma mb mc mq me mf mg mr mi mj mk ij bi translated">这篇文章的主要目标是与你分享卷积网络结构对这种二进制分类问题，如猫和狗的图像分类。希望你能对这类问题有更好的理解。</p></div></div>    
</body>
</html>