<html>
<head>
<title>Tuning a model with Bayesian Optimization on Google AI Platform</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Google AI平台上用贝叶斯优化调整模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tuning-a-model-with-bayesian-optimization-on-google-ai-platform-d9fe63b78576?source=collection_archive---------33-----------------------#2020-10-11">https://towardsdatascience.com/tuning-a-model-with-bayesian-optimization-on-google-ai-platform-d9fe63b78576?source=collection_archive---------33-----------------------#2020-10-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/d746310298da1fb67cdfc16cf835ecb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5BBMDjthBBQqtz9w"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">伊利亚·巴甫洛夫在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="6598" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">谷歌ML教程</h2><div class=""/><div class=""><h2 id="3ca1" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">如何使用Google云服务为您的机器学习模型找到最佳超参数</h2></div><p id="e979" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在<a class="ae jd" href="https://towardsdatascience.com/tagged/google-ml-tutorials" rel="noopener" target="_blank"> Google ML教程</a>系列的这篇文章中，我们将讨论如何使用<a class="ae jd" href="https://cloud.google.com/ai-platform" rel="noopener ugc nofollow" target="_blank"> AI平台</a>内置工具来调优你的机器学习模型的超参数！我们将使用一种叫做<strong class="lg jq">贝叶斯优化</strong>的方法来导航超参数空间，然后找到一个比缺省值更好的集合。</p><p id="2055" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在上一篇<a class="ae jd" rel="noopener" target="_blank" href="/training-a-model-on-google-ai-platform-84ceff87b5f3">文章</a>中，我们在一个<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank">银行营销数据集</a>上训练了一个<code class="fe ma mb mc md b">RandomForestClassifier </code>。我们使用了算法的默认超参数，取得了很好的效果。但是，如果我想调整这个模型，试图找到一个更好的超参数集呢？例如，我想调整:</p><ul class=""><li id="4661" class="me mf jg lg b lh li lk ll ln mg lr mh lv mi lz mj mk ml mm bi translated"><code class="fe ma mb mc md b">max_depth</code>:森林中每棵树的最大深度</li><li id="adbd" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated"><code class="fe ma mb mc md b">min_samples_split</code>:拆分树节点的最小样本数(或分数)</li><li id="5c39" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated"><code class="fe ma mb mc md b">max_features</code>:用于每棵树的<br/>训练的输入特征的数量(或分数)</li><li id="ccba" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated"><code class="fe ma mb mc md b">max_samples</code>:与<code class="fe ma mb mc md b">max_features</code>相同，但针对行</li></ul><p id="681a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">搜索最佳超参数的最常见方法是<strong class="lg jq">网格搜索</strong>和<strong class="lg jq">随机搜索</strong>方法。</p><ul class=""><li id="0c11" class="me mf jg lg b lh li lk ll ln mg lr mh lv mi lz mj mk ml mm bi translated">在网格搜索中，该算法为给定超参数的每个单一组合训练一个模型，然后返回具有最佳性能的集合。这种方法非常耗时，尤其是当您希望一次调整2–3个以上的超参数时，因为要训练的模型数量呈指数级增长。</li><li id="111c" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">在随机搜索中，该算法改为随机挑选超参数的<em class="ms"> n </em>个组合，并为每个组合训练一个模型。这里问题出在<em class="ms">随机</em>字上:算法可能会跳过最有效的超参数集，尤其是当我们设置一个低的<em class="ms"> n </em>时。</li></ul><p id="0fd6" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在本教程中，我们将在Google AI平台的一点帮助下使用贝叶斯优化方法！但首先，什么是贝叶斯优化？</p><p id="fad8" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">尽管在本文中，我们将更多地关注代码部分，而不是方法背后的理论，但我将尝试给出一个快速的概述。为了更全面和完整的介绍，我建议看看这些文章(<a class="ae jd" rel="noopener" target="_blank" href="/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f"> 1 </a> <br/>和<a class="ae jd" href="https://cloud.google.com/blog/products/gcp/hyperparameter-tuning-cloud-machine-learning-engine-using-bayesian-optimization" rel="noopener ugc nofollow" target="_blank"> 2 </a>)。</p><p id="5e16" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在某种程度上，贝叶斯优化从上述两种<br/>方法中获益:它确实从所有可能的超参数组合中挑选了一个子样本，但是挑选是以一种更明智的方式进行的。该算法用代理函数模拟目标函数的分布(比如我们模型的平均精度);这个函数的定义域是给定的超参数空间。然后，它探索这种分布，尝试不同的超参数集。在每一次尝试中，它获得了更多关于目标函数实际分布的信息(以Bayes方式),因此它可以移动到更“有希望”的域空间子集。</p><p id="600e" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">出于这个特定的原因，请记住，我们不能完全并行化贝叶斯优化的过程(与网格和随机搜索相反)，因为每次迭代都会从上一次迭代中学习。</p><p id="aa40" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在我们来训练一些模型！对于本教程，我们将遵循与<br/><a class="ae jd" rel="noopener" target="_blank" href="/training-a-model-on-google-ai-platform-84ceff87b5f3">培训教程</a>相同的步骤:</p><ul class=""><li id="676b" class="me mf jg lg b lh li lk ll ln mg lr mh lv mi lz mj mk ml mm bi translated">将数据存储在谷歌存储器上</li><li id="8e91" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">编写一个Python应用程序来训练模型</li><li id="045e" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">在人工智能平台上开展培训工作</li></ul><p id="fb6c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最大的区别在于Python应用程序本身:我们需要添加一个框架来将模型的性能结果与贝叶斯优化联系起来。这个框架叫做<a class="ae jd" href="https://github.com/GoogleCloudPlatform/cloudml-hypertune" rel="noopener ugc nofollow" target="_blank"> Hypertune </a>:用<code class="fe ma mb mc md b">pip install cloudml-hypertune</code>简单安装即可。</p><h1 id="cf93" class="mt mu jg bd mv mw mx my mz na nb nc nd kv ne kw nf ky ng kz nh lb ni lc nj nk bi translated">更改Python应用程序</h1><p id="9179" class="pw-post-body-paragraph le lf jg lg b lh nl kq lj lk nm kt lm ln nn lp lq lr no lt lu lv np lx ly lz ij bi translated">首先要做的是定义我们想要优化的超参数列表。<br/>我们必须训练这样的管道</p><pre class="nq nr ns nt gt nu md nv nw aw nx bi"><span id="bec1" class="ny mu jg md b gy nz oa l ob oc">pipeline = Pipeline([<br/>    ('data_prep',<br/>     ColumnTransformer([<br/>        ('num_prep', StandardScaler(), num_features),<br/>        ('cat_prep', OneHotEncoder(handle_unknown='ignore'),<br/>         cat_features)<br/>     ])),<br/>    # ML model<br/>    ('model',<br/>     RandomForestClassifier(<br/>         random_state=42,<br/>         n_estimators=500,<br/>         class_weight='balanced'<br/>     ))<br/>])</span></pre><p id="a1e0" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了将这些超参数传递给应用程序(和管道)，我们必须用<code class="fe ma mb mc md b">argparse</code>库定义一个参数列表，如下所示</p><pre class="nq nr ns nt gt nu md nv nw aw nx bi"><span id="109f" class="ny mu jg md b gy nz oa l ob oc">import argparse</span><span id="a5c7" class="ny mu jg md b gy od oa l ob oc">…</span><span id="93cc" class="ny mu jg md b gy od oa l ob oc"># Instantiate an argument parser<br/>parser = argparse.ArgumentParser()</span><span id="41f2" class="ny mu jg md b gy od oa l ob oc"># Define the list of input arguments<br/>parser.add_argument('--max-depth', type=int, default=10,<br/>                    help='Maximum depth of each tree in Random <br/>                          Forest model'<br/>                         ' (integer, default 10)')</span></pre><p id="dbfe" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然后我们解析参数，并将它们输入管道</p><pre class="nq nr ns nt gt nu md nv nw aw nx bi"><span id="cb8b" class="ny mu jg md b gy nz oa l ob oc"># Parse arguments<br/>args = parser.parse_args()</span><span id="01c3" class="ny mu jg md b gy od oa l ob oc">…</span><span id="e28d" class="ny mu jg md b gy od oa l ob oc">pipeline = Pipeline([<br/>    ('data_prep',<br/>     ColumnTransformer([<br/>        ('num_prep', StandardScaler(), num_features),<br/>        ('cat_prep', OneHotEncoder(handle_unknown='ignore'),<br/>         cat_features)<br/>     ])),<br/>    # ML model<br/>    ('model',<br/>     RandomForestClassifier(<br/>         random_state=42,<br/>         n_jobs=args.n_jobs,<br/>         n_estimators=args.n_estimators,<br/>         max_depth=args.max_depth,<br/>         max_features=args.max_features,<br/>         min_samples_split=args.min_samples_split,<br/>         class_weight='balanced',<br/>         max_samples=args.max_samples<br/>     ))<br/>])</span></pre><p id="dec8" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">之后，我们需要一个策略来评估每个给定超参数集的性能。我们使用<strong class="lg jq">交叉验证</strong>方法:<br/> 1。你把你的数据分成<em class="ms"> n </em>份<br/> 2份。选择一个分割作为<em class="ms">验证</em>3。连接剩余的<em class="ms"> n-1个</em>分割，并在这个新的<br/>数据集<br/> 4上训练模型。计算保持分离<br/> 5的性能。每次分割重复2-4次</p><p id="b927" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果你想稳健地评估一个模型，这种方法是合适的，因为你在<em class="ms"> n </em>潜在不同的场景中训练和验证它。</p><p id="b267" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们可以使用scikit-learn中预置的<code class="fe ma mb mc md b">cross_validate</code> <a class="ae jd" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate" rel="noopener ugc nofollow" target="_blank">函数</a>。</p><pre class="nq nr ns nt gt nu md nv nw aw nx bi"><span id="1669" class="ny mu jg md b gy nz oa l ob oc">from sklearn.model_selection import cross_validate</span><span id="2e69" class="ny mu jg md b gy od oa l ob oc">…</span><span id="2e15" class="ny mu jg md b gy od oa l ob oc">scores = cross_validate(pipeline, train, y_train,<br/>                        scoring=['accuracy', 'precision', 'recall',<br/>                                 'f1'],<br/>                        cv=5)</span></pre><p id="072e" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们提供:</p><ul class=""><li id="b415" class="me mf jg lg b lh li lk ll ln mg lr mh lv mi lz mj mk ml mm bi translated">一个有效的分类器(我们可以使用像<code class="fe ma mb mc md b">GradientBoostingClassifier</code>这样的模型，或者像我们的例子中的<br/>整个管道)</li><li id="7ac3" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">输入数据和目标</li><li id="b2b1" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">要计算的一个或多个度量(如准确度和精确度)；<a class="ae jd" href="https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter" rel="noopener ugc nofollow" target="_blank">这里是</a> <br/>可用指标的完整列表</li><li id="e95a" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated"><em class="ms">n</em>(<code class="fe ma mb mc md b">cv</code>参数)的一个值</li></ul><p id="80f8" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe ma mb mc md b">scores</code>结果是一个字典，其中包含每个给定指标的条目。例如，<code class="fe ma mb mc md b">scores['test_accuracy']</code>将是一个在5次迭代中具有5个计算精度的向量。</p><p id="acf8" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最后，我们必须使用<code class="fe ma mb mc md b">hyperopt</code>框架。由于整个优化基于单个值，我们必须选择一个特定的指标(<em class="ms"> F1-score </em>)并计算平均值。</p><pre class="nq nr ns nt gt nu md nv nw aw nx bi"><span id="d682" class="ny mu jg md b gy nz oa l ob oc"># Instantiate a hypertune object<br/>hpt = hypertune.HyperTune()</span><span id="63d0" class="ny mu jg md b gy od oa l ob oc"># Compute the average metric<br/>avg_f1 = scores[‘test_f1’].mean()</span><span id="10d8" class="ny mu jg md b gy od oa l ob oc"># Pass the value to hyperopt<br/>hpt.report_hyperparameter_tuning_metric(<br/>    hyperparameter_metric_tag='F1',<br/>    metric_value=avg_f1,<br/>    global_step=1<br/>)</span></pre><p id="d41f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这就是Python应用程序的全部内容！你可以在我的<a class="ae jd" href="https://github.com/MatteoFelici/medium/blob/master/ai-platform-tuning/src/tune.py" rel="noopener ugc nofollow" target="_blank"> Github repo </a>上找到整个应用程序</p><p id="11c9" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">但是嘿！我们已经定义了要优化的超参数，但没有定义应用程序必须尝试使用贝叶斯优化的值(或值的范围)。我们如何做到这一点？</p><h1 id="5b51" class="mt mu jg bd mv mw mx my mz na nb nc nd kv ne kw nf ky ng kz nh lb ni lc nj nk bi translated">指定超参数:配置文件</h1><p id="5377" class="pw-post-body-paragraph le lf jg lg b lh nl kq lj lk nm kt lm ln nn lp lq lr no lt lu lv np lx ly lz ij bi translated">我们创建一个新的配置文件，其中包含要优化的超参数列表。对于其中的每一个，我们指定:</p><ul class=""><li id="2138" class="me mf jg lg b lh li lk ll ln mg lr mh lv mi lz mj mk ml mm bi translated">类型，如分类或整数</li><li id="c0eb" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">如果是绝对的，它可以作为值的类别</li><li id="21d6" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">如果是数字，则为要应用的数字范围和缩放类型</li></ul><p id="4050" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">例如，对于<strong class="lg jq">最大深度</strong>超参数，我们指定:</p><ul class=""><li id="7f79" class="me mf jg lg b lh li lk ll ln mg lr mh lv mi lz mj mk ml mm bi translated">整数类型</li><li id="f899" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">介于4和20之间的值</li><li id="cc3d" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">线性缩放，因此可能值的空间线性缩放为(0，1)</li></ul><p id="7bb5" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于<strong class="lg jq">最小样本分割</strong>，我们可以指定:</p><ul class=""><li id="3dbe" class="me mf jg lg b lh li lk ll ln mg lr mh lv mi lz mj mk ml mm bi translated">浮动(双)型</li><li id="6895" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">介于0.001和0.1之间的值</li><li id="052e" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">因为我们想更多地取最左边的值而不是最右边的值，所以我们使用了一个<em class="ms">对数</em>标度</li></ul><p id="0f32" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">所有这些定义都放在一个<code class="fe ma mb mc md b">config.yaml</code>文件中:</p><pre class="nq nr ns nt gt nu md nv nw aw nx bi"><span id="e181" class="ny mu jg md b gy nz oa l ob oc">trainingInput:<br/>  hyperparameters:<br/>    goal: MAXIMIZE<br/>    hyperparameterMetricTag: F1<br/>    maxTrials: 20<br/>    maxParallelTrials: 2<br/>    params:<br/>    - parameterName: max-depth<br/>      type: INTEGER<br/>      minValue: 4<br/>      maxValue: 20<br/>      scaleType: UNIT_LINEAR_SCALE<br/>    - parameterName: min-samples-split<br/>      type: DOUBLE<br/>      minValue: 0.001<br/>      maxValue: 0.1<br/>      scaleType: UNIT_LOG_SCALE<br/>    - parameterName: max-features<br/>      type: DOUBLE<br/>      minValue: 0.1<br/>      maxValue: 0.9<br/>      scaleType: UNIT_LINEAR_SCALE<br/>    - parameterName: max-samples<br/>      type: DOUBLE<br/>      minValue: 0.1<br/>      maxValue: 0.9<br/>      scaleType: UNIT_LINEAR_SCALE</span></pre><p id="83f9" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们看看这个文件。</p><ul class=""><li id="ec3a" class="me mf jg lg b lh li lk ll ln mg lr mh lv mi lz mj mk ml mm bi translated">在顶部，我们确定哪个是调优作业的<code class="fe ma mb mc md b">goal</code>。我们想用标签<code class="fe ma mb mc md b">F1</code>来<code class="fe ma mb mc md b">MAXIMIZE</code>一个度量。请记住，这个标签应该与Python应用程序中的<code class="fe ma mb mc md b">hpt.report_hyperparameter_tuning_metric</code>相同。</li><li id="690f" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">然后，我们定义调优工作必须进行的试验(轮次)。我们说<br/>“总共20次试验，每次平行2次”。在时间和性能之间有一个折衷:我们指定的并行作业越多，花费的时间就越少。<br/>但是请记住，贝叶斯过程从前面的步骤中学习:学习步骤是<code class="fe ma mb mc md b">total trials / number of parallel trials</code>(在我们的例子中，是10)，所以如果我们“过多地”并行化，该过程将没有多少步骤要学习。</li><li id="46b3" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">最后，我们逐一列出具有上述特征的超参数。再次提醒，记住<code class="fe ma mb mc md b">parameterName</code>必须与Python应用程序的<code class="fe ma mb mc md b">argparse</code>部分中定义的<br/>相同。<a class="ae jd" href="https://cloud.google.com/ai-platform/training/docs/reference/rest/v1/projects.jobs#ParameterSpec" rel="noopener ugc nofollow" target="_blank">在这里</a>您可以找到超参数定义的完整文档。</li></ul><h1 id="676d" class="mt mu jg bd mv mw mx my mz na nb nc nd kv ne kw nf ky ng kz nh lb ni lc nj nk bi translated">在AI平台上运行调优作业</h1><p id="cb86" class="pw-post-body-paragraph le lf jg lg b lh nl kq lj lk nm kt lm ln nn lp lq lr no lt lu lv np lx ly lz ij bi translated">我们将使用应用于<a class="ae jd" rel="noopener" target="_blank" href="/training-a-model-on-google-ai-platform-84ceff87b5f3">培训</a>的相同命令，添加<code class="fe ma mb mc md b">config</code>文件的规范:</p><pre class="nq nr ns nt gt nu md nv nw aw nx bi"><span id="d023" class="ny mu jg md b gy nz oa l ob oc">gcloud ai-platform jobs submit training "$JOB_NAME" \<br/>    --module-name=src.tune \<br/>    --package-path=./src \<br/>    --job-dir=gs://bank-marketing-model/"$JOB_NAME" \<br/>    --region=$REGION \<br/>    --scale-tier=CUSTOM \<br/>    --master-machine-type=n1-standard-8 \<br/>    --python-version=3.7 \<br/>    --runtime-version=2.2 \<br/>    --config=./config.yaml \<br/>    -- \<br/>    --n-jobs=8</span></pre><p id="e8a1" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">当你提交代码时，一个新条目将出现在你的<a class="ae jd" href="https://console.cloud.google.com/ai-platform/jobs" rel="noopener ugc nofollow" target="_blank">谷歌人工智能平台作业控制台</a>中:</p><figure class="nq nr ns nt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oe"><img src="../Images/7ebf807a3cf17505e8d4bcaed4060e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q3trD8kdGWlOD76duTiPHg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="4141" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你可以弹出这个条目，查看20个试验中的每一个:一些将会完成，<br/>其他的将会运行。对于每个试验，都有所选择的超参数列表和F1指标的最终值。</p><p id="1de3" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">当所有的试验都完成后，如果我们点击“母亲”工作，我们会看到一个从最好到最差排序的试验结果的<br/>摘要。</p><figure class="nq nr ns nt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/6ab7addfc9e94e604aeef1da43401261.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gxunqYMg7kOqlKrP41RamQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="9495" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在本例中，我们可以看到<strong class="lg jq">最大深度</strong>和<strong class="lg jq">最小样本分割</strong>超参数非常稳定，最佳性能值分别为20和0.001。其他两个超参数尚未确定，但我们可以看到一个向区间的上半部分发展的趋势。</p><p id="e667" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了证明过程已经及时学习的事实，我们计算试验的次数和“到达”顺序之间的相关性。我们发现了一个<br/> -0.71的相关性！这意味着更高的试验编号(因此试验具有更多的<br/>“学习”过程)具有更低的到达点。</p><p id="2c34" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">当我们<a class="ae jd" rel="noopener" target="_blank" href="/training-a-model-on-google-ai-platform-84ceff87b5f3">在相同的数据上使用默认的超参数训练</a>相同的模型时，我们在训练中达到了52.44%的F1，在测试中达到了51.22%的F1。现在交叉验证+贝叶斯优化，我们达到了64.46%！接下来的步骤可能是:</p><ul class=""><li id="dab2" class="me mf jg lg b lh li lk ll ln mg lr mh lv mi lz mj mk ml mm bi translated">运行另一个优化作业，修复最大深度和最小样本分割，并关注其他超参数</li><li id="8da4" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">调整其他超参数，如<code class="fe ma mb mc md b">criterion</code>或<code class="fe ma mb mc md b">min_impurity_split</code></li><li id="ded5" class="me mf jg lg b lh mn lk mo ln mp lr mq lv mr lz mj mk ml mm bi translated">使用找到的最佳超参数集运行训练作业，以<br/>部署模型</li></ul><p id="7930" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">再次感谢您阅读这篇文章！我真的希望你能设法使用这个强大的工具来增强你的机器学习模型。请留下您的经验或反馈的评论！</p></div></div>    
</body>
</html>