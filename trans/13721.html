<html>
<head>
<title>Genetic Algorithm to Optimize Machine Learning Hyperparameters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优化机器学习超参数的遗传算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/genetic-algorithm-to-optimize-machine-learning-hyperparameters-72bd6e2596fc?source=collection_archive---------11-----------------------#2020-09-21">https://towardsdatascience.com/genetic-algorithm-to-optimize-machine-learning-hyperparameters-72bd6e2596fc?source=collection_archive---------11-----------------------#2020-09-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/b65d8e9b155bddd5759621bf65593f5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FKvd3HqKT56ZVwUNLjKePA.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来自<a class="ae kf" href="https://freeimages.com/" rel="noopener ugc nofollow" target="_blank">的照片</a></p></figure><p id="3c8b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">超参数调整对于机器学习模型的正确运行至关重要。您可以查看<a class="ae kf" rel="noopener" target="_blank" href="/how-to-optimize-hyperparameters-of-machine-learning-models-98baec703593">Timo bhm</a>的文章，了解超参数调整的概述。</p><p id="8cf0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">遗传算法为超参数调整提供了一种强大的技术，但它们经常被忽视。</p><p id="c18c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我将展示遗传算法的概述。我还将提供一个详细的分步指南，介绍如何利用可用的库，使用遗传算法来优化机器学习模型的超参数。</p><blockquote class="le"><p id="b4f8" class="lf lg it bd lh li lj lk ll lm ln ld dk translated">遗传算法利用自然选择进化的基本概念来优化任意函数。</p></blockquote></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="5343" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated"><span class="l mt mu mv bm mw mx my mz na di">文章概述</span></h1><p id="9a44" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">这篇短文将介绍<strong class="ki iu">差分进化</strong>，并教授如何利用它来优化<strong class="ki iu">核岭回归</strong>中使用的超参数。</p><p id="5b97" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我提供了一些代码片段来展示如何在Python中使用差分进化算法。完整的代码和图表也在GitHub库<a class="ae kf" href="https://github.com/marcosdelcueto/Tutorial_Differential_Evolution" rel="noopener ugc nofollow" target="_blank">中提供，因此任何人都可以深入了解细节。</a></p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="baeb" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">差分进化算法概述</h1><p id="168e" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">遗传算法，如差异进化，利用了自然选择进化的基本概念。在我们的例子中，我们有一个由包含具有不同值的<strong class="ki iu">参数</strong>的<strong class="ki iu">向量</strong>构成的<strong class="ki iu">群体</strong>。</p><p id="ca8d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">参数相当于生物系统中的基因。它们的精确值在不同的向量之间是不同的。参数的不同组合导致向量显示不同的适应值。</p><p id="3209" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随机参数突变被引入到群体中，并且具有较大适应度的向量比其他向量长寿。</p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nh"><img src="../Images/7c685724a2e595156f94b1e97138096c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J6DnNb530c_tyJdGWA-nNg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="adcc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用迭代过程，差分进化可以按照以下步骤<strong class="ki iu">最小化函数</strong>:</p><p id="9cd9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 1 —初始化:</strong>用边界内随机参数值的<em class="ng"> NP </em>个向量创建初始种群。</p><p id="093e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 2 —初始评估:</strong>计算<em class="ng"> NP </em>向量的函数值。</p><p id="2f4b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 3 —对于群体中的每个载体:</strong></p><p id="7df5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 3.1 —突变:</strong>我们构建了一个突变向量，其中每个参数的值被计算为从群体中随机选择的其他向量的参数的突变。计算该突变载体的常用策略是<em class="ng"> best1bin </em>，其中突变载体的每个参数<em class="ng"> pᵢ </em>如下式所示计算。突变参数是<em class="ng">最佳</em>载体(具有最低值的载体)的<em class="ng"> pᵢ </em>参数加上<em class="ng">突变率</em> <em class="ng"> (F) </em>乘以随机选择的两个载体<em class="ng">【r₁】</em>和<em class="ng"> r₂ </em>的<em class="ng"/>差的变化。</p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/5d3837e7dd7bb4a527273cbad60ce183.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eje0y4Q5DTbInB6BtAgZCQ.png"/></div></div></figure><p id="502d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 3.2 —重组:</strong>通过选择其每个参数作为当前载体的值或突变载体的值来创建试验载体。对于每个参数，我们在(0，1)区间内生成一个随机均匀数<em class="ng"> R </em>。如果<em class="ng"> R </em>低于a <em class="ng">重组率</em>，那么我们接受突变参数；否则，我们使用当前参数的参数。</p><p id="a783" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 3.3 —替换:</strong>评估试验矢量的功能。如果它比当前向量更稳定，就用试验向量代替当前向量。</p><p id="10c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 4 —重复步骤3，直到群体收敛:</strong>当群体中函数的标准偏差小于函数平均值的特定百分比时，迭代停止。如果在最大迭代次数后没有达到收敛，循环也会停止。</p><p id="96b1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所有这些过程都已经在主流编程语言的几个库中实现了。在这里，我们将使用Python中的<a class="ae kf" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html" rel="noopener ugc nofollow" target="_blank"> Scipy的实现</a>，它让我们只需使用几行代码就可以做任何我们想做的事情。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="4572" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">生成数据</h1><p id="4901" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">例如，我们将使用遵循二维函数<em class="ng">【f(x₁,x₂)=sin(x₁)+cos(x₂】</em>的数据，加上区间(-2，2)中的一个小的随机变化来增加趣味。因此，我们的数据将遵循以下表达式:</p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/bce263315f03fcbc7525d2571ae06ca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ceInXQxqGtH5o6_Ta_JDA.png"/></div></div></figure><p id="a046" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下图中，我们以灰度显示<em class="ng"> sin(x₁)+cos(x₂) </em>的值作为参考。然后，我们用彩色点来表示我们的441个点(21 <em class="ng"> x </em> 21网格)，在区间<em class="ng"> x₁ </em> :(-10，10)和<em class="ng"> x₂ </em> :(-10，10)中用上面的表达式计算。</p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/5781706c681887a0f363e0389f9b2b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*omitG7ApjR_oFINHJ9q6mg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="bac0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在下面提供了一个代码片段，其中包含用于生成数据的函数:</p><figure class="ni nj nk nl gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="1761" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">机器学习模型</h1><p id="fd0f" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">我们的目标是使用之前生成的数据来训练一个ML模型，该模型将能够预测函数<em class="ng"> f(x₁,x₂) </em>在不同配置下的值。</p><p id="00ea" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我将使用<strong class="ki iu">核岭回归</strong> (KRR)。我们将对KRR使用径向基函数核，它取决于高斯核方差<strong class="ki iu"> γ </strong>。对于KRR，我们还需要优化正则化超参数<strong class="ki iu"> α </strong>。如果你想知道更多关于KRR及其实现的细节，请随意查看我最近关于这个主题的教程。</p><p id="6669" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，我们使用10重交叉验证，其中我们的数据分为用于优化模型的训练集和用于测量模型准确性的测试集。作为准确性度量，我们将使用均方根误差(<strong class="ki iu"> RMSE </strong>)，它代表测试集中的<em class="ng"> f(x₁,x₂) </em>值与我们的模型预测的值之间的平均误差。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="04eb" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">上一步:探索超参数空间</h1><p id="4ea1" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">作为可选的第一步，我们可以执行网格搜索，查看RMSE如何随两个超参数α和γ的值而变化。</p><p id="a32e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在下面展示了这个网格的外观，以及用于执行超参数网格搜索的代码。下图让我们初步了解了什么样的超参数值会产生较小的RMSE。</p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/132fd48567c4863f8c40fd2ee8ad45b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XgBPXUTmFTYYxk8PAAw_sg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><figure class="ni nj nk nl gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="8c0b" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">超参数调谐</h1><p id="b4f6" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">最后，我们可以使用Scipy提供的差分进化算法，通过最小化我们模型的RMSE来优化超参数。</p><p id="adb2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Scipy的<em class="ng">差分进化</em>函数需要输入:</p><ul class=""><li id="4fc6" class="nr ns it ki b kj kk kn ko kr nt kv nu kz nv ld nw nx ny nz bi translated"><strong class="ki iu"><em class="ng">KRR _功能</em> </strong> <em class="ng">。</em>这是其输出(RMSE)将被最小化的功能。它需要输入:I)具有超参数的元组以优化(α和γ)和ii) <em class="ng"> X，y </em>包含我们的数据的变量。</li><li id="e508" class="nr ns it ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz bi translated"><strong class="ki iu">定义超参数可能值的边界</strong>。</li><li id="b87f" class="nr ns it ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz bi translated"><strong class="ki iu">由<em class="ng">KRR _函数</em>使用的额外变量</strong>。在我们的例子中，这将作为一个包含<em class="ng"> X </em>和<em class="ng"> y. </em>的元组给出</li><li id="45e9" class="nr ns it ki b kj oa kn ob kr oc kv od kz oe ld nw nx ny nz bi translated">差分进化算法的其他相关选项有:</li></ul><ol class=""><li id="20eb" class="nr ns it ki b kj kk kn ko kr nt kv nu kz nv ld of nx ny nz bi translated"><strong class="ki iu">策略</strong>。在我们的例子中，默认的<em class="ng">策略='best1bin' </em>已经足够好了。采用这种策略，突变载体的每个参数值作为该参数的最佳载体值的变化而获得，与另外两个随机载体的差异成比例。</li><li id="edad" class="nr ns it ki b kj oa kn ob kr oc kv od kz oe ld of nx ny nz bi translated"><strong class="ki iu">人口规模</strong>。这就选择了我们要考虑的矢量数量。一个较大的数字将会减慢进度，但会使它更有可能发现全局最小值。这里，我们使用默认值<em class="ng"> popsize=15。</em></li><li id="89f3" class="nr ns it ki b kj oa kn ob kr oc kv od kz oe ld of nx ny nz bi translated"><strong class="ki iu">突变常数</strong>。该值控制参数在突变阶段的变化程度。较大的值意味着较大的搜索半径，但会减慢收敛速度。我们使用<em class="ng">突变的默认值=0.5。</em></li><li id="73e7" class="nr ns it ki b kj oa kn ob kr oc kv od kz oe ld of nx ny nz bi translated"><strong class="ki iu">复合常数</strong>。该常数控制重组阶段试验载体的参数改变的可能性。更大的值意味着突变更容易被接受，这可能会加速收敛，但有导致群体不稳定的风险。我们使用默认值<em class="ng">重组=0.7。</em></li><li id="059e" class="nr ns it ki b kj oa kn ob kr oc kv od kz oe ld of nx ny nz bi translated"><strong class="ki iu">公差</strong>。该值控制算法何时被视为收敛。我们将使用<em class="ng"> tol=0.01 </em>，这意味着当群体中所有向量的RMSE的标准差小于平均RMSE的1%时，该算法被认为是收敛的。</li></ol><figure class="ni nj nk nl gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="ebe2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此代码返回导致最小化RMSE的收敛超参数值:</p><pre class="ni nj nk nl gt og oh oi oj aw ok bi"><span id="ef30" class="ol lw it oh b gy om on l oo op">Converged hyperparameters: alpha= 0.347294, gamma= 3.342522<br/>Minimum rmse: 1.140462</span></pre><p id="453e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以取消函数<em class="ng">KRR _函数</em>的最后一行的注释，以打印所有中间值:</p><pre class="ni nj nk nl gt og oh oi oj aw ok bi"><span id="2743" class="ol lw it oh b gy om on l oo op">alpha: 63.925979 . gamma: 19.290688 . rmse: 1.411122<br/>alpha: 59.527726 . gamma:  2.228886 . rmse: 1.421191<br/>alpha: 24.470318 . gamma:  3.838062 . rmse: 1.379171<br/>alpha: 61.944876 . gamma: 15.703799 . rmse: 1.407040<br/>alpha: 68.141245 . gamma:  0.847900 . rmse: 1.431469<br/>                        [...]<br/>alpha:  0.347408 . gamma:  3.342461 . rmse: 1.140462<br/>alpha:  0.347294 . gamma:  3.342522 . rmse: 1.140462<br/>alpha:  0.347294 . gamma:  3.342522 . rmse: 1.140462<br/>alpha:  0.347294 . gamma:  3.342522 . rmse: 1.140462</span></pre><p id="40aa" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以采用差分进化算法探索这些配置，并在之前的超参数网格搜索的基础上绘制它们:</p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/b62867eec113e83bab674283523c702f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*14fw0rrdBAl4xx30gSVGdg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="1397" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了研究的所有中间值，我们还用红色标出了收敛值。这样，我们可以观察算法如何在设定的边界内探索不同的配置，并最终收敛到最小化RMSE的(α，γ)组合。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="73da" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">结论</h1><p id="f843" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">我们已经介绍了如何生成一个简单的二维数据集，以及如何用核岭回归来拟合它。我们已经介绍了差分进化的基础知识，以及如何使用这种算法来优化机器学习模型的超参数。</p><p id="50b5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住这里展示的数据集、代码、图像等。在这个<a class="ae kf" href="https://github.com/marcosdelcueto/Tutorial_Differential_Evolution" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中提供。</p><p id="fa00" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你对遗传算法优化机器学习超参数的更复杂的应用感到好奇，请随时查看我们最近在利物浦大学与东北师范大学合作的工作。在这项工作中，我们使用差分进化算法来优化几个机器学习模型，以预测有机太阳能电池的效率。</p><p id="2c10" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章对你有帮助吗？让我知道你是否能够成功地使用差分进化算法来优化你的机器学习模型的超参数！</p></div></div>    
</body>
</html>