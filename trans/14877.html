<html>
<head>
<title>Implementation of Semi-Supervised Generative Adversarial Networks in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">半监督生成对抗网络在Keras中的实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementation-of-semi-supervised-generative-adversarial-networks-in-keras-195a1b2c3ea6?source=collection_archive---------30-----------------------#2020-10-13">https://towardsdatascience.com/implementation-of-semi-supervised-generative-adversarial-networks-in-keras-195a1b2c3ea6?source=collection_archive---------30-----------------------#2020-10-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ad32" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用半监督学习构建强大的分类器</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8a5284e83cac54a7b824d2a78837b623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WDo3SFj9IbH6uwzG"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">穆罕默德·阿里扎德在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="defe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个人都听说过监督学习和非监督学习，但在它们之间还有另一套学习技术，称为半监督学习。</p><p id="43f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">监督学习是机器学习中最常用的技术，但它有一个缺点，即它需要大量的标记数据。给数据贴标签需要花费大量的精力和时间。这就是半监督学习发挥作用的地方。</p><h2 id="c5ff" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">什么是半监督学习？</h2><p id="8320" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">半监督学习是一种技术，我们只使用大量未标记数据中的一小部分标记数据来训练我们的模型。</p><p id="8c1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这似乎是一个有趣的方法，而且标记数据的成本也大大降低了。</p><h2 id="f291" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">什么是生成性对抗网络？</h2><p id="ce1b" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated"><strong class="ky ir">生成对抗网络</strong>(GAN)是由Ian Goodfellow及其同事在2014年设计的一类生成模型。就生成模型而言，这是一个突破。</p><p id="09b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在甘的研究中，有两个神经网络试图击败对方(即一个网络的损失是另一个网络的收益)。这两个神经网络被称为生成器和鉴别器。</p><p id="187c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">生成器模型试图生成图像(类似于训练数据)，鉴别器的工作是将图像分类为真实的(来自训练数据)或虚假的(来自生成器)。所以基本上鉴别器试图不被发生器愚弄，而发生器试图愚弄鉴别器，这就是为什么这被称为博弈论方法，因为发生器和鉴别器都在博弈中试图战胜对方。</p><h2 id="64c1" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">如何使用GAN进行半监督学习？</h2><p id="ee4e" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">下面是半监督GAN的模型</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/7a5c551c0a03159cec2a957186be35c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fr04DDgq5ApAE0sE-CEnPw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">半监督甘，来源:图片由作者提供</p></figure><p id="9eed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来了解一下模型<br/>鉴别器通过三种类型的图像，即有标签的训练图像、无标签的训练图像和生成器生成的假图像。它的工作不仅是区分真实/虚假图像，而且将标记的训练图像分类到它们正确的类别中。</p><p id="7280" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">鉴频器有两种不同的输出:</p><ol class=""><li id="cdc4" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr mw mx my mz bi translated">Softmax激活，用于将标签数据分类到正确的类别，即这是受监督的鉴别器。</li><li id="fd03" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">自定义激活分类为真或假。我们将在实现中看到自定义激活。</li></ol><p id="f54a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法的强大之处在于，鉴别器不仅要训练有标签的数据，还要训练大量无标签的数据，因为它还必须区分真实/伪造的图像，因此对于这项任务，鉴别器需要学习提取用于将图像分类为真实或伪造的特征。这种对抗性训练将有助于鉴别器更准确地对标记数据进行分类，因为它在学习对真实/伪造图像进行分类的同时，还会识别其他模式，而这通常不会在一小组标记数据上进行。</p><p id="b8de" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看看上述模型在Keras <br/>中的实现。我将使用的数据集是古老的MNIST数据集(每个人的最爱)</p><h1 id="78e6" class="nf lt iq bd lu ng nh ni lx nj nk nl ma jw nm jx md jz nn ka mg kc no kd mj np bi translated">设置</h1><p id="08c1" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">首先导入所有必需的包</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="c04b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> z_dim </strong>是我们将传递给生成器的随机正态变量的维数。</p><h1 id="7068" class="nf lt iq bd lu ng nh ni lx nj nk nl ma jw nm jx md jz nn ka mg kc no kd mj np bi translated">资料组</h1><p id="6a6d" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我们需要准备如下两个数据集:</p><ol class=""><li id="65e7" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr mw mx my mz bi translated">监督鉴别器:数据集将是完整训练集的一个小子集。</li><li id="f94d" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">无监督鉴别器:数据集将是完整的训练集。</li></ol><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="3496" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里只需要解释<strong class="ky ir">batch _ label()</strong>函数</p><p id="ec50" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> batch_labeled() </strong>通过选择样本子集及其标签，为监督鉴别器准备数据集。我们将使用100个带标签的例子(即每类10个例子)来训练我们的分类器。</p><p id="96a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> batch_unlabeled() </strong>从数据集中随机抽取图像，图像数量等于给定的batch_size。</p><h1 id="3426" class="nf lt iq bd lu ng nh ni lx nj nk nl ma jw nm jx md jz nn ka mg kc no kd mj np bi translated">发电机网络</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">发电机网络</p></figure><p id="aa96" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用Keras顺序API构建我们的生成器模型。这是一个基本的发电机模型，因为我们的任务并不复杂。</p><p id="1f5d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">密集的</strong>层用于对我们的尺寸<strong class="ky ir"> z_dim </strong>进行整形，其形状为<strong class="ky ir"> (batch_size，100) </strong>到<strong class="ky ir"> (batch_size，7，7，256) </strong>，这样我们就可以在其上应用<strong class="ky ir"> Conv2DTranspose </strong>层来生成图像。</p><h1 id="672e" class="nf lt iq bd lu ng nh ni lx nj nk nl ma jw nm jx md jz nn ka mg kc no kd mj np bi translated">鉴别器网络</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">鉴别器网络</p></figure><p id="5137" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我们的鉴别器，它输入一个图像(假的或真的)，输出图像是真的还是假的，即“1”或“0”。</p><p id="c5d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的输出一直是密集层的输出，没有任何激活，因此这些值也可以是负的。下一步就会明白为什么要这样做了。</p><h2 id="3f42" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">监督鉴别器</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">监督鉴别器</p></figure><p id="b55c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">build _ discriminator _ supervised()</strong>将我们在上述步骤中创建的鉴别器模型作为输入，并使用<strong class="ky ir"> softmax </strong>激活将我们的输入图像分类为10个类别之一(针对MNIST)。</p><h2 id="8371" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">无监督鉴别器</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="4f84" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">build _ discriminator _ unsupervised()</strong>接受我们之前创建的鉴别器的输入，并对鉴别器的输出应用一个<strong class="ky ir"> custom_activation() </strong>。</p><p id="ea0e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们创建discriminator时，我们将它的输出保存为一个密集层的输出，该层在没有任何激活的情况下给出值。因此，自定义激活会执行以下操作</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/6883ec319586bf979357fc73e05c8efd.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*2IfhzOTsRzWnl3mTr3k2PQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">自定义激活功能</p></figure><p id="7a49" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里<strong class="ky ir"> z </strong>是没有任何激活的密集层的输出，<strong class="ky ir"> k </strong>对于我们的情况是10，<strong class="ky ir"> y </strong>在0和1之间。</p><p id="cd4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于图像真实或虚假的概率将是所有类别的概率之和，因此激活函数基本上是所有类别的和，并且在[0，1]之间缩放输出，以获得图像真实或虚假的概率。这个技巧比使用乙状结肠有效得多。</p><p id="c8b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">监督和非监督鉴别器使用的权重相同，只是两者使用的输出节点不同。</p><h1 id="4f98" class="nf lt iq bd lu ng nh ni lx nj nk nl ma jw nm jx md jz nn ka mg kc no kd mj np bi translated">建筑甘</h1><p id="7285" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated"><strong class="ky ir"> <em class="nt"> build_gan() </em> </strong>基本上接受生成器和鉴别器的输入，并将它们合并形成一个模型。这样做是为了训练发电机网络。这将被称为<strong class="ky ir">复合模型</strong>。</p><p id="443f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，这里的鉴别器是无监督的鉴别器，因为GAN仅用于未标记的图像。</p><h1 id="e175" class="nf lt iq bd lu ng nh ni lx nj nk nl ma jw nm jx md jz nn ka mg kc no kd mj np bi translated">训练半监督GAN</h1><p id="cbe5" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">首先，让我们通过编译上面创建的所有模型函数来构建我们的模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">定义模型</p></figure><p id="5b57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，在构建GAN ( <strong class="ky ir">复合模型</strong>)时，我们将<strong class="ky ir">Discriminator _ unsupervised</strong>保持为不可训练(第7行)，因为GAN的训练是在训练鉴别器然后训练生成器的步骤中完成的，所以在训练生成器时，我们不希望我们的鉴别器被更新。</p><p id="bc59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用的成本函数是用于无监督鉴别器的二元交叉熵和用于有监督鉴别器的分类交叉熵。</p><p id="237f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在主要的训练循环</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">主训练循环</p></figure><p id="3057" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们通过在一批真实的标记图像上训练监督鉴别器来开始我们的训练，然后我们在真实的未标记图像(标记为“1”)和由生成器生成的假图像(标记为“0”)上训练无监督鉴别器，最后，我们使用我们之前定义的复合模型通过鉴别器来训练我们的生成器。</p><p id="b0ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，发电机工作的培训方式如下:</p><ol class=""><li id="9c52" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr mw mx my mz bi translated">生成器生成一批假图像。</li><li id="922c" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">这些生成的假图像通过鉴别器进行分类，鉴别器的目标标签为真，即“1”(第31行)。<strong class="ky ir">注意:</strong>鉴别器在此步骤中不会更新。</li><li id="47e2" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">因此，如果图像看起来不真实，损失会非常高，因此为了最小化损失，生成器将开始生成看起来真实的图像，这是我们的目标。</li></ol><p id="2b27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，随着生成器在更多图像上得到训练，它开始生成更好的图像，并且鉴别器也开始变得更好，因为它不希望在对假图像或真图像进行分类时其损失变高。因此，这就是为什么鉴别器和生成器都在相互竞争，如果一个变得更好，另一个也需要改进。</p><p id="41f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练后，我们只需使用鉴别器并丢弃生成器，因为我们的主要目的是为MNIST构建一个分类器。</p><h1 id="ea82" class="nf lt iq bd lu ng nh ni lx nj nk nl ma jw nm jx md jz nn ka mg kc no kd mj np bi translated">结果</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/ab44906d534bb31678542606e733bfb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UZ1kkdD9OJhW4oMeT6pIzA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:作者图片</p></figure><p id="5927" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，在测试集上获得的准确度约为90.67 %，这是非常令人印象深刻的，因为我们刚刚使用了100幅标记图像(每类10幅)来训练我们的鉴别器。因此，这是一个强大的分类器，不需要大量的标记数据。当然，如果我们使用1000个标记图像，性能会提高更多，与现代数据集相比，这仍然很低。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/095da374c2c3e6ace91629390e5b7b48.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*0Qns3XYfoc2eep7rWMMg5w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由生成器生成的假图像，来源:作者提供的图像</p></figure><p id="ca09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以，这些是由生成器生成的假图像，除了少数例外，都相当真实。<br/>您还可以尝试在100张带标签的图像上训练没有GAN的相同鉴别器模型，看看它的表现如何。无疑会比用甘训练出来的鉴频器差。</p><p id="8a1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是与此实现相关联的Github Repo</p><p id="8ab1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/KunalVaidya99/Semi-Supervised-GAN" rel="noopener ugc nofollow" target="_blank">https://github.com/KunalVaidya99/Semi-Supervised-GAN<strong class="ky ir">T4</strong></a></p><p id="df6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想了解更多关于GAN的知识，你可以试着阅读这本书<strong class="ky ir">Jakub Langr，Vladimir Bok所著的《行动中的GAN与生成性对抗网络深度学习》。</strong></p><p id="3efc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我第一篇关于Medium的文章，如果你喜欢，请告诉我。感谢阅读！。</p><h1 id="7b3d" class="nf lt iq bd lu ng nh ni lx nj nk nl ma jw nm jx md jz nn ka mg kc no kd mj np bi translated">参考</h1><p id="265a" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated"><a class="ae kv" href="https://arxiv.org/pdf/1606.01583.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1606.01583.pdf</a></p></div></div>    
</body>
</html>