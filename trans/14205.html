<html>
<head>
<title>Software Engineering for Data Scientist — Test-Driven Development (Example)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向数据科学家的软件工程——测试驱动开发(示例)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/software-engineering-for-data-scientist-test-driven-development-example-3c737de7be88?source=collection_archive---------41-----------------------#2020-09-30">https://towardsdatascience.com/software-engineering-for-data-scientist-test-driven-development-example-3c737de7be88?source=collection_archive---------41-----------------------#2020-09-30</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><figure class="it iu gq gs iv iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj is"><img src="../Images/7f2fae616fb72ebec5b1a6d47471edcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2C2Sl-GlJV7ki9eTv59Sgw.jpeg"/></div></div><p class="jd je gk gi gj jf jg bd b be z dk translated">图片来源pix abay—<a class="ae jh" href="https://www.pexels.com/photo/abstract-business-code-coder-270348/" rel="noopener ugc nofollow" target="_blank">https://www . pexels . com/photo/abstract-business-code-coder-270348/</a></p></figure><div class=""/><p id="e2e7" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">这是本系列的第四篇文章。有关本系列文章的列表，请查看前几篇文章部分。</p><p id="104b" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">上一篇文章可在— <strong class="kj jl">数据科学家软件工程—测试驱动开发</strong><a class="ae jh" href="https://medium.com/@jaganadhg/software-engineering-for-data-scientist-test-driven-development-65f1cdf52d58" rel="noopener">https://medium . com/@ jaganadhg/Software-Engineering-for-Data-Scientist-Test-Driven-Development-65 f1 CDF 52d 58</a>获得</p><h2 id="ecaa" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">介绍</h2><p id="1c56" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">在上一篇文章中，我们讨论了数据科学中的测试驱动开发。本文介绍的两个具体测试案例包括针对虚拟/猜测机器的模型检查和预测一致性检查。本文是同一主题的快速教程。</p><p id="5330" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">在本教程中，我们正在建立一个二元分类器。本练习中使用的数据是取自Kaggle [1]的口袋妖怪数据。本练习将构建一个随机森林分类器，并将其与猜测机器(参考ROC AUC得分)进行比较，以及预测的一致性。</p><h2 id="6597" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">资料组</h2><p id="63b3" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">这个练习的数据是“用于数据挖掘和机器学习的口袋妖怪”[1]。该数据集包括第6代之前的口袋妖怪。该数据共有21个属性，包括身份属性(“数字”)。我们为该练习选择了以下属性:“isLegendary”、“Generation”、“Type_1”、“Type_2”、“HP”、“Attack”、“Def”、“Sp_Atk”、“Sp_Def”、“Speed”、“Color”、“Egg_Group_1”、“Height_m”、“Weight_kg”、“Body_Style”。属性“Generation”用于拆分数据，然后从数据集中删除。属性“isLegendary”是此处的目标。有五个分类属性，它们是‘Egg _ Group _ 1’，‘Body _ Style’，‘Color’，‘Type _ 1’，‘Type _ 2’。我们在训练/验证/测试之前一次性转换了这些属性。</p><h2 id="f6fc" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">软件</h2><p id="9b13" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">对于本教程，我们将使用以下Python包。</p><p id="c8df" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">熊猫</p><p id="6b42" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">sklearn 0.23.2</p><p id="b65a" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">pytest 6.1.0</p><p id="906d" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">ipytest 0.9.1</p><p id="c374" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">数字版本1.19.1</p><p id="a361" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">工具z 0.11.1</p><h2 id="95d4" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">模型结构</h2><p id="de4d" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">让我们建立我们的模型！</p><pre class="md me mf mg gu mh mi mj mk aw ml bi"><span id="1ba2" class="lf lg jk mi b gz mm mn l mo mp">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import sklearn as sl<br/>import pytest<br/>import ipytest<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import MinMaxScaler<br/>from sklearn.dummy import DummyClassifier<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import (confusion_matrix,<br/>                            classification_report,<br/>                            roc_auc_score)<br/>import toolz</span><span id="9c1e" class="lf lg jk mi b gz mq mn l mo mp">ipytest.autoconfig()</span><span id="c438" class="lf lg jk mi b gz mq mn l mo mp">data = pd.read_csv("../data/pokemon_alopez247.csv")</span></pre><p id="a2e1" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">我们从数据中选择以下属性。</p><pre class="md me mf mg gu mh mi mj mk aw ml bi"><span id="b105" class="lf lg jk mi b gz mm mn l mo mp">selected_cols = ['isLegendary','Generation', 'Type_1', 'Type_2', 'HP', 'Attack',<br/>                'Defense', 'Sp_Atk', 'Sp_Def', 'Speed','Color','Egg_Group_1',<br/>                'Height_m','Weight_kg','Body_Style']</span><span id="3d66" class="lf lg jk mi b gz mq mn l mo mp">data = data[selected_cols]</span></pre><p id="a342" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">属性“isLegendary”是我们的类标签。让我们把这个转换成int。</p><pre class="md me mf mg gu mh mi mj mk aw ml bi"><span id="b853" class="lf lg jk mi b gz mm mn l mo mp">data.isLegendary = data.isLegendary.astype(int)</span></pre><h2 id="704e" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">转换分类变量</h2><p id="514a" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">以下函数用于转换分类变量。</p><pre class="md me mf mg gu mh mi mj mk aw ml bi"><span id="f383" class="lf lg jk mi b gz mm mn l mo mp">def create_dummy(data: pd.DataFrame, categories: list) -&gt; pd.DataFrame:<br/>    """ Create dummay varibles a.k.a categorical encoding in a DataFrame<br/>        Parameters<br/>        -----------<br/>        data : A pandas DataFrame containing the original data<br/>        categories: the arribute/column names to be transfromed<br/>        <br/>        Returns<br/>        -----------<br/>        data_tf : Transfromed DataFrame<br/>    """<br/>    <br/>    for category in categories:<br/>        dummy_df = pd.get_dummies(data[category])<br/>        data = pd.concat([data,dummy_df],<br/>                          axis=1)<br/>        data.drop(category,<br/>                 axis=1,<br/>                 inplace=True)<br/>        <br/>    return data</span><span id="d826" class="lf lg jk mi b gz mq mn l mo mp">categ_cols = ['Egg_Group_1', 'Body_Style', 'Color','Type_1', 'Type_2']</span><span id="1ee7" class="lf lg jk mi b gz mq mn l mo mp">data = create_dummy(data,categ_cols)</span></pre><h2 id="b26d" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">创建培训测试和验证数据</h2><p id="82dd" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">首先，我们通过训练和测试来拆分数据。所有属于第一代的口袋妖怪都被选作训练。其余数据用作测试数据。训练数据被进一步分割以创建验证数据集。</p><pre class="md me mf mg gu mh mi mj mk aw ml bi"><span id="e8b5" class="lf lg jk mi b gz mm mn l mo mp">train_data = data[data.Generation != 1]<br/>test_data = data[data.Generation == 1]</span><span id="408c" class="lf lg jk mi b gz mq mn l mo mp">train_data.drop("Generation",<br/>                axis=1,<br/>                inplace=True)<br/>test_data.drop("Generation",<br/>               axis=1,<br/>               inplace=True)</span><span id="1982" class="lf lg jk mi b gz mq mn l mo mp">d:\anaconda2\envs\sweng\lib\site-packages\pandas\core\frame.py:4167: SettingWithCopyWarning: <br/>A value is trying to be set on a copy of a slice from a DataFrame<br/><br/>See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy<br/>  errors=errors,</span><span id="cc7e" class="lf lg jk mi b gz mq mn l mo mp">def create_x_y(data: pd.DataFrame, col_name : str) -&gt; list:<br/>    """ Cerate training X and y values<br/>        Parameters<br/>        -----------<br/>        data : DataFrame of data<br/>        col_name : Y column name<br/>        Returns<br/>        -----------<br/>        x_y_list: a list contaning DataFrem and y as list<br/>    """<br/>    X = data.drop(col_name,<br/>                 axis=1).values<br/>    y = data[col_name].values<br/>    <br/>    return (X,y)</span><span id="29ee" class="lf lg jk mi b gz mq mn l mo mp">X_train, y_train = create_x_y(train_data, "isLegendary")</span><span id="096f" class="lf lg jk mi b gz mq mn l mo mp">X_train, X_val, y_train, y_val = train_test_split(X_train,<br/>                                                  y_train,<br/>                                                  stratify=y_train,<br/>                                                  test_size=0.25)</span><span id="9cf6" class="lf lg jk mi b gz mq mn l mo mp">X_test, y_test = create_x_y(test_data, "isLegendary")</span></pre><p id="6e5e" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated"><strong class="kj jl">最小-最大缩放比例</strong></p><p id="767f" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">使用最小-最大缩放技术进一步处理数据。</p><pre class="md me mf mg gu mh mi mj mk aw ml bi"><span id="52e3" class="lf lg jk mi b gz mm mn l mo mp">def scale_data(dataset: pd.DataFrame) -&gt; np.array:<br/>    """ Scle the data <br/>        Parameters<br/>        -----------<br/>        dataset : input DataFrame<br/>        Returns<br/>        -----------<br/>        scled_data : a numpy array<br/>    """<br/>    transformer = MinMaxScaler()<br/>    <br/>    sclaed_data = transformer.fit_transform(dataset)<br/>    <br/>    return sclaed_data</span><span id="1cb8" class="lf lg jk mi b gz mq mn l mo mp">X_train_scaled = scale_data(X_train)<br/>X_test_scaled = scale_data(X_test)<br/>X_val_scaled = scale_data(X_val)</span></pre><h2 id="e0ea" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">创造一个猜测机器！</h2><p id="91b5" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">为了创建一个猜测机器，我们使用了scikit-learn的“DummyClassifier”。虚拟分类器设计用于制作快速基线模型。分类器为基线提供了不同的策略。分类器忽略除目标之外的输入数据。在本练习中，我们将使用分层方法来构建模型。</p><pre class="md me mf mg gu mh mi mj mk aw ml bi"><span id="9278" class="lf lg jk mi b gz mm mn l mo mp">dummy_classifier = DummyClassifier(strategy="stratified",<br/>                                  random_state=1995)<br/>_ = dummy_classifier.fit(X_train_scaled,<br/>                        y_train)</span></pre><h2 id="de05" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">创建随机森林分类器</h2><p id="4627" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">现在让我们创建一个随机森林分类器。</p><pre class="md me mf mg gu mh mi mj mk aw ml bi"><span id="6a07" class="lf lg jk mi b gz mm mn l mo mp">rf_classifier = RandomForestClassifier(criterion='entropy',<br/>                                      max_depth=5,<br/>                                      warm_start=True,<br/>                                      random_state=1925)</span><span id="1619" class="lf lg jk mi b gz mq mn l mo mp">_ = rf_classifier.fit(X_train_scaled,<br/>                     y_train)</span></pre><h2 id="c488" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">编写测试用例</h2><p id="1acb" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">现在我们正在编写模型和预测一致性的测试用例。我们使用pytest和ipytest来编写和执行JupyterNotebook中的测试用例。为测试用例创建了两个夹具。</p><p id="b94d" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">pytest fixture 'fixture_isbetter '使用虚拟分类器和随机森林分类器来创建预测。它返回虚拟分类器、随机森林分类器和实际标签的结果。下一个fixture是‘pred _ consist _ data’；它从验证数据中随机挑选五个例子。</p><p id="51f5" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">测试用例“test_is_better”检查随机森林分类器的ROC AUC分数是否优于猜测机器。理想情况下，应该是通过考验！接下来的两个测试用例“test_prediction_consistency”和“test_pred_proba_consistency”测试模型的一致性。测试背后的直觉是，如果相同的输入被提供给模型n次，它应该提供相同的结果(除了Reenforcemtn学习)。这里，第一个测试用例检查标签的一致性，第二个测试用例检查概率的一致性。</p><p id="ecac" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">例如，一致性测试的目的被分成两个测试用例。它也可以和一个结合。</p><pre class="md me mf mg gu mh mi mj mk aw ml bi"><span id="da97" class="lf lg jk mi b gz mm mn l mo mp">%%run_pytest[clean]<br/><br/>@pytest.fixture<br/>def fixture_isbetter():<br/>    """ Fixture for checking if model is better than guess"""<br/>    dumm_pred = dummy_classifier.predict(X_val_scaled)<br/>    clf_pred = rf_classifier.predict(X_val_scaled)<br/>    <br/>    return (dumm_pred,clf_pred, y_val)<br/><br/>@pytest.fixture<br/>def pred_consist_data():<br/>    """ Generate random 5 records from validation data<br/>        for prediction consistency test.<br/>    """<br/>    num_records = X_val.shape[0]<br/>    raandom_indics = np.random.choice(num_records,<br/>                                     size=5,<br/>                                     replace=False)<br/>    sample_for_test = X_val[raandom_indics, :]<br/>    <br/>    return sample_for_test<br/><br/><br/>def test_is_better(fixture_isbetter):<br/>    """ Test if the target classifier is better than the dummy classifier<br/>        Parameters<br/>    """<br/>    actuls = fixture_isbetter[-1]<br/>    pred_dummy = fixture_isbetter[0]<br/>    pred_clf = fixture_isbetter[1]<br/>    roc_auc_dummy = roc_auc_score(actuls, pred_dummy)<br/>    roc_auc_clf = roc_auc_score(actuls, pred_clf)<br/>    <br/>    print(f"ROC AUC for dummy classifer is {roc_auc_dummy} \<br/>          and ROC AUC score for RandomForest is {roc_auc_clf}")<br/>    <br/>    assert round(roc_auc_clf,4) &gt; round(roc_auc_dummy,4)<br/><br/>def test_prediction_consistency(pred_consist_data):<br/>    """ Test the prediction consistency"""<br/>    #import toolz<br/>    <br/>    predictions_list = list()<br/>    <br/>    for iteration in range(5):<br/>        preds = rf_classifier.predict(pred_consist_data)<br/>        predictions_list.append(list(preds))<br/>        <br/>    unique_if = list(map(list, toolz.unique(map(tuple,predictions_list))))<br/>    <br/>    assert len(unique_if) == 1<br/><br/><br/>def test_pred_proba_consistency(pred_consist_data):<br/>    """ Test prediction consistency"""<br/>    #import toolz<br/>    <br/>    pridct_proba = list()<br/>    <br/>    for iteration in range(5):<br/>        preds = rf_classifier.predict(pred_consist_data)<br/>        pridct_proba.append(list(preds))<br/>        <br/>    unique_if = list(map(list, toolz.unique(map(tuple,pridct_proba))))<br/>    <br/>    assert len(unique_if) == 1</span><span id="d6f4" class="lf lg jk mi b gz mq mn l mo mp">...                                                                                                              [100%]<br/>3 passed in 0.17s</span></pre><p id="90e1" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">瞧。三个测试用例全部通过！。可以有额外的测试用例来部署重新训练的模型。在这种情况下，最好用先前的模型替换测试用例的虚拟分类器。sklearn提供了一个虚拟分类器和回归器。如果您想将它应用到任何其他类型的模型，我们可能需要编写我们的模块来实现目标。！</p><h2 id="cb46" class="lf lg jk bd lh li lj dn lk ll lm dp ln ks lo lp lq kw lr ls lt la lu lv lw lx bi translated">以前的文章</h2><p id="d1c1" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">面向数据科学家的软件工程—测试驱动开发<a class="ae jh" href="https://medium.com/@jaganadhg/software-engineering-for-data-scientist-test-driven-development-65f1cdf52d58" rel="noopener">https://medium . com/@ jaganadhg/software-Engineering-for-Data-Scientist-Test-Driven-Development-65 f1 CDF 52d 58</a></p><p id="e799" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">面向数据科学家的软件工程—编写干净代码的艺术—<a class="ae jh" href="https://medium.com/@jaganadhg/software-engineering-for-data-scientist-art-of-writing-clean-code-f168bf8a6372" rel="noopener">https://medium . com/@ jaganadhg/software-Engineering-for-Data-Scientist-Art-of-Writing-Clean-Code-f 168 bf8a 6372</a></p><p id="fb4c" class="pw-post-body-paragraph kh ki jk kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">AI/ML/数据科学项目的软件工程—<a class="ae jh" href="https://medium.com/@jaganadhg/software-engineering-for-ai-ml-data-science-projects-bb73e556620e" rel="noopener">https://medium . com/@ jaganadhg/software-Engineering-for-AI-ML-Data-Science-Projects-bb73e 556620 e</a></p><h1 id="d3e0" class="mr lg jk bd lh ms mt mu lk mv mw mx ln my mz na lq nb nc nd lt ne nf ng lw nh bi translated">参考</h1><p id="a7e3" class="pw-post-body-paragraph kh ki jk kj b kk ly km kn ko lz kq kr ks ma ku kv kw mb ky kz la mc lc ld le in bi translated">[1]口袋妖怪数据集，<a class="ae jh" href="https://www.kaggle.com/alopez247/pokemon" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/alopez247/pokemon</a></p></div></div>    
</body>
</html>