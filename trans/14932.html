<html>
<head>
<title>How to guide: Set up, Manage &amp; Monitor Spark on Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何指导:在Kubernetes上建立、管理和监控Spark</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-guide-set-up-manage-monitor-spark-on-kubernetes-with-code-examples-c5364ad3aba2?source=collection_archive---------10-----------------------#2020-10-14">https://towardsdatascience.com/how-to-guide-set-up-manage-monitor-spark-on-kubernetes-with-code-examples-c5364ad3aba2?source=collection_archive---------10-----------------------#2020-10-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="528a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">带有代码示例</h2></div><p id="36b7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在2020 Spark + AI峰会上，我们提出了一个关于在Kubernetes (K8s) 上运行Apache Spark的<a class="ae lb" href="https://databricks.com/session_na20/running-apache-spark-on-kubernetes-best-practices-and-pitfalls" rel="noopener ugc nofollow" target="_blank">最佳实践和陷阱的会议。</a></p><p id="9217" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本帖中，我们将对该演示进行扩展，并与您讨论:</p><ol class=""><li id="b171" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">什么是Kubernetes？</li><li id="284a" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">为什么要在Kubernetes上运行Spark？</li><li id="546f" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Kubernetes上的Spark入门</li><li id="61aa" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">优化性能和成本</li><li id="263c" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">在Kubernetes上监控您的Spark应用</li><li id="c060" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Kubernetes上的Spark现已上市(<strong class="kh ir">更新:2021年3月</strong></li></ol><p id="d628" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你已经熟悉k8s以及为什么Kubernetes上的<a class="ae lb" href="https://www.datamechanics.co/apache-spark" rel="noopener ugc nofollow" target="_blank"> Spark </a>可能适合你，请随意跳过前几个部分，直接进入帖子的核心部分！</p><h1 id="f9af" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">什么是Kubernetes (k8s)？</h1><p id="ab56" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated"><a class="ae lb" href="https://kubernetes.io/" rel="noopener ugc nofollow" target="_blank"> Kubernetes </a>(也称为Kube或k8s)是一个开源的容器编排系统，最初由谷歌开发，<a class="ae lb" href="https://www.theregister.com/2020/07/13/ibm_kubernetes_experience_job_ad/" rel="noopener ugc nofollow" target="_blank">于2014年开源</a>，由云计算原生计算基金会维护。Kubernetes用于自动化容器化应用的部署、扩展和管理——最常见的是Docker容器。</p><p id="e2c8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它提供了许多对稳定性、安全性、性能和可扩展性至关重要的功能，例如:</p><ol class=""><li id="02c4" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">水平可扩展性</li><li id="b961" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">自动化推出和回滚</li><li id="6388" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">负载平衡</li><li id="907f" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">机密和配置管理</li><li id="2a90" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><a class="ae lb" href="https://luminousmen.com/post/kubernetes-101" rel="noopener ugc nofollow" target="_blank">…还有更多</a></li></ol><p id="e0c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Kubernetes已经成为传统软件开发领域基础设施管理的标准。但是Kubernetes在大数据领域并不那么受欢迎，因为大数据领域经常被像<a class="ae lb" href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="noopener ugc nofollow" target="_blank"> Hadoop YARN </a>这样的老技术所困扰。直到Spark-on-Kubernetes加入游戏！</p><h1 id="a274" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">为什么要在Kubernetes上打火？</h1><p id="0ab4" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">当Apache Spark 2.3中增加了对Kubernetes上原生运行Spark的支持时，许多公司决定改用它。这种流行的主要原因包括:</p><ul class=""><li id="6dd7" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la mn li lj lk bi translated">本地集装箱化和码头支持。</li><li id="8133" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">能够在彼此完全隔离的情况下运行Spark应用程序(例如，在不同的Spark版本上)，同时享受共享基础架构的成本效益。</li><li id="8410" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">将您的整个技术基础设施统一在一个与云无关的工具下(如果您已经将Kubernetes用于您的非Spark工作负载)。</li></ul><p id="5baa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最重要的是，与YARN相比，在Kubernetes上运行没有设置损失(如<a class="ae lb" href="https://www.datamechanics.co/blog-post/apache-spark-performance-benchmarks-show-kubernetes-has-caught-up-with-yarn" rel="noopener ugc nofollow" target="_blank">基准测试</a>所示)，Spark 3.0为Spark-on-Kubernetes带来了许多额外的改进，如支持动态分配。自<a class="ae lb" href="https://datamechanics.co/blog-post/apache-spark-3-1-release-spark-on-kubernetes-is-now-ga" rel="noopener ugc nofollow" target="_blank">Spark 3.1(2021年3月)以来，Kubernetes上的Spark已被正式宣布为正式上市</a>和生产就绪！</p><p id="ce1f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">阅读我们之前关于在Kubernetes 上运行Spark的利弊的帖子，了解关于这个主题的更多细节以及与主要替代方案的比较。</p><h1 id="dbcd" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">Kubernetes上的Spark入门</h1><h2 id="fa43" class="mo lr iq bd ls mp mq dn lw mr ms dp ma ko mt mu mc ks mv mw me kw mx my mg mz bi translated">架构:当你提交一个Spark应用到Kubernetes时会发生什么</h2><p id="03b4" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">您通过直接与Kubernetes(确切地说是主节点上的Kubernetes API服务器)对话来提交Spark应用程序，然后Kubernetes API服务器将为Spark驱动程序安排一个pod(简单地说，一个容器)。一旦Spark驱动程序启动，它将直接与Kubernetes通信来请求Spark执行器，这也将在pod上进行调度(每个执行器一个pod)。如果启用了动态分配，Spark执行器的数量会根据负载动态变化，否则它是一个静态数字。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi na"><img src="../Images/29d8e8c61826f453350d6afacc3449c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CTy-Valdm5L_CnScdsa7hw.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">Kubernetes参考架构上的Apache Spark。图片作者。</p></figure><h1 id="3fee" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">如何提交申请:spark-submit与spark-operator</h1><p id="455e" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">这是你需要尽早做的一个高层次的选择。向Kubernetes提交Spark应用程序有两种方式:</p><ul class=""><li id="d20a" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la mn li lj lk bi translated">使用spark附带的spark-submit方法。Spark应用程序的进一步操作将需要直接与Kubernetes pod对象进行交互</li><li id="2e19" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">使用<a class="ae lb" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator" rel="noopener ugc nofollow" target="_blank">火花操作器</a>。这个项目是由GCP开发的(并且是开源的)，但是它在任何地方都可以工作。它需要在集群上运行一个(单个)pod，但会将Spark应用程序转变为<a class="ae lb" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/" rel="noopener ugc nofollow" target="_blank">自定义Kubernetes资源</a>，可以像其他Kubernetes对象一样对其进行定义、配置和描述。它增加了其他细节，比如支持直接从Spark应用程序配置中挂载配置图和卷。</li></ul><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nq"><img src="../Images/8f36b46094b98e1c9a14c73396d3de60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oKkryNkbM7bcYHtI.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">Spark提交与Kubernetes运营商应用管理上的Spark。图片作者。</p></figure><p id="fc75" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们建议使用spark-operator，因为它更容易使用。</p><h1 id="d959" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">设置清单</h1><p id="95ca" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">根据您当前的基础架构和云提供商(或内部设置)，以下步骤会有所不同。但是在高层次上，这里是你完全自己开始使用Kubernetes上的Spark所需要设置的主要内容:</p><ul class=""><li id="2b06" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la mn li lj lk bi translated">创建一个Kubernetes集群</li><li id="b629" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">根据您的工作负载要求定义您想要的节点池</li><li id="d6de" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">根据您的网络需求加强安全性(我们建议将Kubernetes集群设为私有)</li><li id="9e30" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">为您的Spark docker映像创建docker注册表，并开始构建您自己的映像(<a class="ae lb" href="https://www.datamechanics.co/blog-post/optimized-spark-docker-images-now-available" rel="noopener ugc nofollow" target="_blank">更新:截至2021年4月，我们已经公开发布了我们针对Spark </a>优化的docker映像。</li><li id="8c0f" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">安装<a class="ae lb" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator" rel="noopener ugc nofollow" target="_blank">火花操作器</a></li><li id="1a38" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">安装Kubernetes <a class="ae lb" href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler" rel="noopener ugc nofollow" target="_blank">集群自动缩放器</a></li><li id="3825" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">将Spark驱动程序日志和Spark事件日志的集合设置到永久存储器中</li><li id="1357" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">安装Spark历史服务器(<a class="ae lb" href="https://github.com/helm/charts/tree/master/stable/spark-history-server" rel="noopener ugc nofollow" target="_blank">掌舵图</a>，或者使用我们的<a class="ae lb" href="https://www.datamechanics.co/blog-post/delight-the-new-improved-spark-ui-spark-history-server-is-now-ga" rel="noopener ugc nofollow" target="_blank">开源监控工具Delight </a>。</li><li id="ecb2" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">设置节点和火花指标(CPU、内存、I/O、磁盘)的收集</li></ul><p id="7c7e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如您所见，如果您在内部完成这项工作，这需要做大量的工作，并且需要维护大量移动的开源项目。</p><p id="15f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是我们构建托管Spark平台(<a class="ae lb" href="https://www.datamechanics.co/blog-post/video-tour-of-data-mechanics-the-serverless-spark-platform" rel="noopener ugc nofollow" target="_blank">数据机制</a>)的原因，目的是让Kubernetes上的Spark尽可能地简单易用。我们的平台负责这一设置，并提供额外的集成(如Jupyter、Airflow、IDEs)以及强大的优化，以使您的Spark应用程序更快，并降低您的云成本。</p><h1 id="d380" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">优化性能和成本</h1><h2 id="9a66" class="mo lr iq bd ls mp mq dn lw mr ms dp ma ko mt mu mc ks mv mw me kw mx my mg mz bi translated">尽可能使用固态硬盘或大磁盘，以获得Spark-on-Kubernetes的最佳洗牌性能</h2><p id="eddd" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">洗牌是Spark中经常出现的昂贵的全对全数据交换步骤。它们会占据你整个Spark工作的很大一部分，因此优化Spark shuffle性能很重要。我们已经在我们的<a class="ae lb" href="https://www.datamechanics.co/blog-post/apache-spark-performance-benchmarks-show-kubernetes-has-caught-up-with-yarn" rel="noopener ugc nofollow" target="_blank"> YARN vs Kubernetes性能指标评测</a>文章(阅读“如何在Kubernetes上使用Spark优化shuffle”)中讨论了这个主题，所以我们在这里只给出我们的高级技巧:</p><ul class=""><li id="07ad" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la mn li lj lk bi translated">尽可能使用本地SSD磁盘</li><li id="1add" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">当它们不可用时，增加磁盘的大小以提高其带宽</li></ul><h2 id="5a29" class="mo lr iq bd ls mp mq dn lw mr ms dp ma ko mt mu mc ks mv mw me kw mx my mg mz bi translated">优化您的火花舱尺寸，以避免浪费容量</h2><p id="f6f7" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">我们来看一个例子。假设:</p><ul class=""><li id="ed01" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la mn li lj lk bi translated">您的Kubernetes节点有4个CPU</li><li id="4c8a" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">您想在每个Kubernetes节点上安装一个Spark executor pod</li></ul><p id="0625" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，您将提交配置为<strong class="kh ir"><em class="nr">Spark . executor . cores = 4</em></strong>的Spark应用程序，对吗？不对。你的Spark app会卡死，因为executors装不下你的节点。您应该考虑下图中描述的开销。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi ns"><img src="../Images/779721ccb4346e3d616450df74f6782f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tHEh12UhE1O8f-d6.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">来自Kubernetes和Daemonsets的Apache Spark节点的开销。图片作者。</p></figure><p id="175b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通常，可分配的节点表示95%的节点容量。为<a class="ae lb" href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" rel="noopener ugc nofollow" target="_blank">daemonset</a>保留的资源取决于您的设置，但是请注意，daemonset在日志和指标收集、网络和安全性方面很受欢迎。让我们假设这为您的Spark执行器留下了90%的可用节点容量，即3.6个CPU。</p><p id="e59b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这意味着您可以使用配置<strong class="kh ir"><em class="nr">Spark . executor . cores = 3</em></strong><em class="nr">提交Spark应用程序。</em>但是这将仅保留3个CPU，并且会浪费一些容量。</p><p id="f3e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，在这种情况下，我们建议采用以下配置:</p><p id="aef5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">T15】spark . executor . cores = 4<br/>spark . kubernetes . executor . request . cores = 3600mT18】</strong></p><p id="03b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这意味着您的Spark执行器将请求正好3.6个可用的CPU，Spark将在这个执行器上并行调度多达4个任务。</p><blockquote class="nt nu nv"><p id="e2a5" class="kf kg nr kh b ki kj jr kk kl km ju kn nw kp kq kr nx kt ku kv ny kx ky kz la ij bi translated">高级提示:<br/>将<strong class="kh ir"> spark.executor.cores </strong>设置为比<strong class="kh ir">spark . kubernetes . executor . request . cores</strong>大2倍(通常为<strong class="kh ir">2倍</strong>或3倍)称为超额预订，可以显著提升CPU使用率较低的工作负载的性能。</p></blockquote><p id="3e04" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个例子中，我们已经向您展示了如何调整Spark executor pods的大小，使它们紧密地适合您的节点(每个节点一个pod)。公司还通常选择使用更大的节点，并在每个节点上安装多个pod。在这种情况下，您仍然应该关注Spark CPU和内存请求，以确保节点上执行器的装箱是高效的。这是由<a class="ae lb" href="https://www.datamechanics.co/" rel="noopener ugc nofollow" target="_blank">数据机制</a>平台提供的动态优化之一。</p><h2 id="dffc" class="mo lr iq bd ls mp mq dn lw mr ms dp ma ko mt mu mc ks mv mw me kw mx my mg mz bi translated">支持应用级动态分配和集群级自动扩展</h2><p id="fb75" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">如果您在云中运行，并且希望让您的数据基础架构具有反应能力和成本效益，这是绝对必要的。有两个级别动态缩放:</p><ul class=""><li id="3d54" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la mn li lj lk bi translated">App级动态分配。这是每个Spark应用程序在运行时请求Spark执行器(当有未决任务时)和删除它们(当它们空闲时)的能力。从Spark 3.0开始，通过设置以下配置，动态分配在Kubernetes上可用:</li><li id="e735" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">‍<strong class="kh ir">T3】spark . dynamic allocation . enabled = true<br/>spark . dynamic allocation . shuffle tracking . enabled = trueT6】</strong></li><li id="6be7" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">集群级自动伸缩。这意味着当Kubernetes集群需要更多的容量来调度pods时，它可以向云提供商请求更多的节点，反之亦然，当节点变得不可用时，就将其删除。</li></ul><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nz"><img src="../Images/f1eba4ff3847a04c35c6ee0f902525be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fxNfIk1rSKVfvVHn.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">针对Apache Spark的Kubernetes集群动态分配和自动缩放。图片作者。</p></figure><p id="f88f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这两项设置将使您的整个数据基础设施在Spark应用能够从新资源中受益时动态扩展，并在这些资源未被使用时缩减规模。实际上，当集群中有容量时，启动Spark pod只需要几秒钟。如果必须首先从云提供商处获取新节点，您通常需要等待1-2分钟(取决于云提供商、地区和实例类型)。</p><p id="2edb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您想保证您的应用程序总是在几秒钟内启动，您可以通过在Kubernetes集群上安排所谓的“暂停单元”来增加集群的规模。这些是低优先级的吊舱，基本上什么也不做。当Spark应用程序需要空间来运行时，Kubernetes将删除这些优先级较低的pods，然后重新安排它们(导致集群在后台扩大规模)。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi oa"><img src="../Images/682c80f86e51700a997197a1159b816a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Zb4k75Qf1Jal3cyi.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">应用级动态分配和集群级自动扩展的说明。图片作者。</p></figure><h2 id="e174" class="mo lr iq bd ls mp mq dn lw mr ms dp ma ko mt mu mc ks mv mw me kw mx my mg mz bi translated">使用点节点降低云成本</h2><p id="fce4" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">Spot(也称为preemptible)节点的成本通常比随需应变的机器低75%左右，换来的是较低的可用性(当您请求Spot节点时，不保证您会得到它们)和不可预测的中断(这些节点可能随时消失)。</p><p id="bb6c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Spark工作负载在spot节点上工作得非常好，只要您确保只有Spark执行器被放置在spot上，而Spark驱动程序在按需机器上运行。事实上，Spark可以从失去执行器(一个新的执行器将被放置在一个按需节点上，并重新运行丢失的计算)中恢复，但不能从失去驱动程序中恢复。</p><p id="b10f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要在Kubernetes中启用spot节点，您应该创建多个节点池(一些是按需节点，一些是spot节点)，然后使用节点选择器和节点关联将驱动程序放在按需节点上，执行器最好放在spot节点上。</p><h1 id="8cf8" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">在Kubernetes上监控您的Spark应用</h1><h2 id="c1e5" class="mo lr iq bd ls mp mq dn lw mr ms dp ma ko mt mu mc ks mv mw me kw mx my mg mz bi translated">使用Kubernetes仪表板监控pod资源使用情况</h2><p id="b6bd" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">Kubernetes仪表板是一个开源的基于web的通用监控UI。它将为您提供集群上运行的应用的可见性，以及对其性能进行故障排除的基本指标，如内存使用、CPU利用率、I/O、磁盘等。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi oa"><img src="../Images/e70062b1c62b91d2b3543a83db4d3867.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3gOrbaE-nJj_crgg.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">Kubernetes仪表板上的Pod资源使用监控。来源:<a class="ae lb" href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/" rel="noopener ugc nofollow" target="_blank"> Kubernetes.io </a></p></figure><p id="9dd6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个项目的主要问题是，将这些指标与实际的Spark工作/阶段协调起来很麻烦，而且当Spark应用程序结束时，这些指标中的大部分都会丢失。保持这些指标有点挑战性，但也是可能的，例如使用<a class="ae lb" href="https://www.slideshare.net/databricks/native-support-of-prometheus-monitoring-in-apache-spark-30" rel="noopener ugc nofollow" target="_blank">普罗米修斯</a>(从Spark 3.0开始内置servlet)或<a class="ae lb" href="https://github.com/cerndb/spark-dashboard" rel="noopener ugc nofollow" target="_blank"> InfluxDB </a>。</p><h2 id="ec8a" class="mo lr iq bd ls mp mq dn lw mr ms dp ma ko mt mu mc ks mv mw me kw mx my mg mz bi translated">如何访问Spark用户界面</h2><p id="fedb" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">Spark UI是Spark内置的重要监控工具。无论应用程序是否是实时的，访问它的方式都是不同的:</p><ul class=""><li id="3f5e" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la mn li lj lk bi translated">当应用程序运行时，Spark UI由Spark驱动程序直接在端口4040上提供服务。要访问它，您应该通过运行以下命令<a class="ae lb" href="https://kubernetesbyexample.com/pf/" rel="noopener ugc nofollow" target="_blank">port-forward</a>:<br/>$ ku bectl port-forward&lt;driver-pod-name&gt;4040:4040<br/>然后您可以在<a class="ae lb" href="http://localhost:4040/" rel="noopener ugc nofollow" target="_blank"> http://localhost:4040/ </a>打开Spark UI</li><li id="a421" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">当应用程序完成时，您可以通过运行Spark历史服务器并将其配置为从持久存储中读取Spark事件日志来重放Spark UI。你应该首先使用配置<strong class="kh ir"><em class="nr">spark . event log . dir</em></strong>将这些事件日志写到你选择的存储后端。然后，您应该按照这个<a class="ae lb" href="https://github.com/helm/charts/tree/master/stable/spark-history-server" rel="noopener ugc nofollow" target="_blank">文档</a>从一个Helm图表安装Spark历史服务器，并将其指向您的存储后端。</li></ul><p id="c9ac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Spark UI的主要问题是很难找到您正在寻找的信息，并且它缺乏以前工具的系统指标(CPU、内存、IO使用)。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi ob"><img src="../Images/2cf9d5606c9c693594798e590a48ffac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HhOr7iRvbVsk7btu.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">数据力学用户界面概述。图片作者。</p></figure><p id="b978" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">更新</strong>:</p><ul class=""><li id="edda" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la mn li lj lk bi translated">截至2020年11月，<a class="ae lb" href="https://www.datamechanics.co/blog-post/setting-up-managing-monitoring-spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank">我们已经发布了一个免费的、托管的、跨平台的Spark历史服务器</a>。这比自己托管Spark历史服务器更简单！</li><li id="10ed" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la mn li lj lk bi translated">截至2021年4月，这个免费的监控工具<a class="ae lb" href="https://www.datamechanics.co/delight" rel="noopener ugc nofollow" target="_blank"> Delight </a>还显示了你的Spark作业&amp;阶段之上的CPU &amp;内存指标。查看我们的<a class="ae lb" href="https://www.datamechanics.co/blog-post/delight-the-new-improved-spark-ui-spark-history-server-is-now-ga" rel="noopener ugc nofollow" target="_blank">博客文章</a> &amp; <a class="ae lb" href="https://github.com/datamechanics/delight" rel="noopener ugc nofollow" target="_blank"> github页面</a>了解更多信息。</li></ul><h1 id="8593" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">Kubernetes上的Spark现已正式发布(Spark 3.1更新)</h1><p id="93af" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">自2021年3月和Apache Spark 3.1发布以来，Kubernetes上的Spark已被正式宣布为生产就绪和正式可用。</p><p id="cfc5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最令人兴奋的功能是Spark能够预测执行程序点杀(通过收听云提供商提前发出的终止通知),并将shuffle文件和缓存数据从即将死亡的执行程序迁移到将存活的执行程序。该功能被称为<a class="ae lb" href="https://issues.apache.org/jira/browse/SPARK-20624" rel="noopener ugc nofollow" target="_blank">【SPARK-20624】更好地处理节点关闭</a>。并且在下面的GIF中有图解。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi oc"><img src="../Images/0b7a7139b430e829cf3073a5fe4820d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*82coAK_rg4kBhB2aEuUXdg.gif"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">优雅的节点退役Spark 3.1的一个新特性，使Apache Spark对定点清除更加健壮。目前仅在Kubernetes &amp;独立模式下可用。</p></figure><p id="f0af" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二个主要改进是能够在Kubernetes(一个网络支持的存储，可以由所有Spark应用程序共享，并预先填充数据)中装载共享的NFS卷，以及动态提供PersistentVolumeClaims(而不是静态)的能力，如果您试图在启用动态分配的情况下运行Spark应用程序，这尤其有用。</p><p id="c9bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看我们关于Spark 3.1发布的<a class="ae lb" href="https://datamechanics.co/blog-post/apache-spark-3-1-release-spark-on-kubernetes-is-now-ga" rel="noopener ugc nofollow" target="_blank">博客文章</a>以深入了解这些改进，并对Spark 3.1的新特性进行概述。</p><h1 id="f47f" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">结论</h1><p id="47ca" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">我们希望这篇文章能让你对Spark-on-Kubernetes以及如何成功使用它有所了解。</p><p id="a381" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您想以最简单的方式开始使用Spark-on-Kubernetes，<a class="ae lb" href="https://calendly.com/datamechanics/demo" rel="noopener ugc nofollow" target="_blank">与我们预约时间</a>，我们的数据力学团队将非常乐意帮助您交付您的用例。如果你想更好地了解我们的平台与Spark-on-Kubernetes开源平台相比如何，<a class="ae lb" href="https://www.datamechanics.co/blog-post/spark-on-kubernetes-made-easy-how-data-mechanics-improves-on-spark-on-k8s-open-source" rel="noopener ugc nofollow" target="_blank">查看这篇文章</a>。</p><p id="a3aa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章的最初版本发表在<a class="ae lb" href="https://www.datamechanics.co/blog-post/setting-up-managing-monitoring-spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank">数据力学博客</a>上</p></div></div>    
</body>
</html>