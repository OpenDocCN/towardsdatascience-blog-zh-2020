<html>
<head>
<title>Convolutional Neural Network: How is it different from the other networks?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络:它与其他网络有何不同？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-math-free-introduction-to-convolutional-neural-network-ff38fbc4fc76?source=collection_archive---------23-----------------------#2020-09-25">https://towardsdatascience.com/a-math-free-introduction-to-convolutional-neural-network-ff38fbc4fc76?source=collection_archive---------23-----------------------#2020-09-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9b2d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/inside-ai/home" rel="noopener"> <strong class="ak">内艾</strong> </a></h2><div class=""/><div class=""><h2 id="7ce9" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">CNN有什么独特之处，卷积到底是做什么的？这是对CNN奇迹的无数学介绍。</h2></div><p id="a2ad" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我不是深度学习研究人员，但我通过各种接触了解了一些关于神经网络的事情。我一直听说CNN是一种神经网络，特别擅长与图像相关的问题。但是，这到底意味着什么呢？<strong class="kt jd">卷积</strong>这个词是怎么回事？一个与图像相关的问题需要不同的网络，这有什么不寻常的？</p><p id="d097" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最近，我有机会研究新冠肺炎图像分类问题，并使用<code class="fe ln lo lp lq b">tensorflow.keras </code>构建了一个基于CNN的分类器，达到了85%的准确率。最后，我想我已经找到了这些问题的答案。让我用一种没有数学的方式和你分享那些答案。如果你已经熟悉CNN，这篇文章应该是一个很好的复习。如果没有，看一看，你可以对CNN背后的动机和定义CNN的独特功能有一个直观的了解。</p><h1 id="4764" class="lr ls it bd lt lu lv lw lx ly lz ma mb ki mc kj md kl me km mf ko mg kp mh mi bi translated">深度神经网络</h1><p id="1b82" class="pw-post-body-paragraph kr ks it kt b ku mj kd kw kx mk kg kz la ml lc ld le mm lg lh li mn lk ll lm im bi translated">在深入研究神经网络之前，我们先来看看机器学习的全貌:</p><blockquote class="mo mp mq"><p id="b8bc" class="kr ks mr kt b ku kv kd kw kx ky kg kz ms lb lc ld mt lf lg lh mu lj lk ll lm im bi translated"><strong class="kt jd"> <em class="it">机器学习</em> </strong> <em class="it"> (ML)是通过经验自动改进的计算机算法的研究。—维基百科</em></p></blockquote><p id="79c4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">看看ML试图解决的问题，ML经常被切成</p><ul class=""><li id="b6d8" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated">监督学习:预测标签，例如分类或连续变量；</li><li id="d29b" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">无监督学习:未标记数据的模式识别，例如聚类；</li><li id="91f3" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">强化学习:算法学习“行为”的最佳方式，例如AlphaGo、自动驾驶汽车。</li></ul><p id="73f7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">其中，深度学习是一种强大的机器学习形式，因其在计算机视觉(例如，图像识别)、自然语言处理等领域的成功而备受关注。神经网络的灵感来自生物系统中的信息处理和通信节点。按照设计，输入数据通过网络的各个层传递，这些层包含几个节点，类似于“神经元”。然后，系统输出信息的特定表示。DNN可能是最知名的深度学习网络，它可以通过训练很好地学习数据的特征。</p><p id="af12" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">粗略来说，组成一个神经网络有两个重要的操作:<br/> 1。正向传播<br/> 2。反向传播</p><h2 id="8773" class="nj ls it bd lt nk nl dn lx nm nn dp mb la no np md le nq nr mf li ns nt mh iz bi translated">正向传播</h2><p id="a5aa" class="pw-post-body-paragraph kr ks it kt b ku mj kd kw kx mk kg kz la ml lc ld le mm lg lh li mn lk ll lm im bi translated">这是<strong class="kt jd">预测</strong>步骤。网络读取输入数据，通过网络计算其值，并给出最终输出值。</p><p id="c5f5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">但是网络如何计算输出值呢？让我们看看当单层网络进行一次预测时会发生什么。它将输入作为一个数字向量。层中的每个节点都有其权重。当输入值通过图层时，网络会计算其加权和。这之后通常是(典型的非线性)激活函数，例如阶跃函数，其中加权和被“激活”。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/dc3ce72d44895f0763b5501cf07660cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*fSdhPRjTiAXO13tooELWaw.png"/></div><p class="oc od gj gh gi oe of bd b be z dk translated">单层感知。来源:感知器。米切尔，机器学习，p87。/ <a class="ae og" href="https://creativecommons.org/licenses/by-sa/3.0" rel="noopener ugc nofollow" target="_blank"> CC BY-SA </a></p></figure><p id="8286" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果您对代数有所了解，那么操作是这样进行的:</p><pre class="nv nw nx ny gt oh lq oi oj aw ok bi"><span id="1258" class="nj ls it lq b gy ol om l on oo">y = f(<strong class="lq jd">w </strong>•<strong class="lq jd"> x</strong>+ <strong class="lq jd">b</strong>)</span></pre><p id="5ce5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">其中<strong class="kt jd">w</strong><strong class="kt jd">x</strong>+<strong class="kt jd">b</strong>为加权和，f为激活函数，y为输出。现在，在更深层次的神经网络中，程序本质上是相同的，即<strong class="kt jd">输入- &gt;加权求和- &gt;激活</strong>过程对许多层重复。</p><h2 id="a207" class="nj ls it bd lt nk nl dn lx nm nn dp mb la no np md le nq nr mf li ns nt mh iz bi translated">反向传播</h2><p id="6fbe" class="pw-post-body-paragraph kr ks it kt b ku mj kd kw kx mk kg kz la ml lc ld le mm lg lh li mn lk ll lm im bi translated">这是<strong class="kt jd">训练</strong>步骤。通过比较网络的预测/输出和实际值，即计算损耗，网络调整其参数以提高性能。</p><p id="167a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">网络如何通过训练调整参数(权重和偏差)？这是通过称为<strong class="kt jd">反向传播</strong>或反向传播的操作完成的。网络获取损失，并递归计算损失函数相对于每个参数的斜率。计算这些斜率需要使用微积分中的链式法则；你可以在这里了解更多信息<a class="ae og" href="https://sebastianraschka.com/faq/docs/backprop-arbitrary.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="85e5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然后使用优化算法利用梯度信息更新网络参数，直到性能不能再提高为止。一种常用的优化器是随机梯度下降。</p><p id="a7d9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">经常用来解释基于梯度的优化的一个类比是徒步旅行。训练网络使损失最小化就像从山上下到地面的最低点。反向投影运算寻找损失函数梯度就像寻找向下的路径。优化算法是你实际走的路，最终到达最低点的那一步。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div class="gh gi op"><img src="../Images/07bcc7d3dccbe3cdfd565c6759fb5e87.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/1*iDYuAOgV1LIMLweOPFmHCQ.gif"/></div><p class="oc od gj gh gi oe of bd b be z dk translated">来源:雅格布·贝尔托洛蒂/ CC0</p></figure><p id="0dcb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我掩盖了许多细节，但我希望你现在知道DNN</p><ul class=""><li id="7163" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated">是一种强大的<strong class="kt jd">机器学习</strong>技术；</li><li id="538b" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">可用于解决<strong class="kt jd">有监督</strong>、<strong class="kt jd">无监督、</strong>和<strong class="kt jd">强化学习</strong>问题；</li><li id="569f" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">包括正向传播(<strong class="kt jd">输入到输出</strong>)和反向传播(<strong class="kt jd">误差到参数更新</strong>)。</li></ul><p id="bcc2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们准备好谈论CNN了！</p><h1 id="0020" class="lr ls it bd lt lu lv lw lx ly lz ma mb ki mc kj md kl me km mf ko mg kp mh mi bi translated">卷积神经网络</h1><p id="f7d4" class="pw-post-body-paragraph kr ks it kt b ku mj kd kw kx mk kg kz la ml lc ld le mm lg lh li mn lk ll lm im bi translated">我们上面讨论过的普通神经网络期望输入数据是数字的<strong class="kt jd">向量，即<strong class="kt jd">x</strong>=【x1，x2，x3，…】。如果我们想训练一个<strong class="kt jd">图像分类器</strong>，即使用一幅图像作为输入，该怎么办？先说一些数字图像基础知识。</strong></p><ul class=""><li id="97de" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated">一幅图像是像素的<strong class="kt jd">集合。例如，32乘32的图像有32*32 = 1024个像素。</strong></li><li id="dc7b" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">每个像素是由范围[0，255]中的数字表示的<strong class="kt jd">强度，其中0是黑色，255是白色。</strong></li><li id="5cf0" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">彩色图像有三个维度:<strong class="kt jd">【宽度、高度、深度】</strong>其中深度通常为3。</li><li id="c1f3" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">为什么深度是3？那是因为它编码了[ <strong class="kt jd"> R </strong> ed，<strong class="kt jd"> G </strong> reen，<strong class="kt jd"> B </strong> lue]的强度，即RGB值。</li></ul><p id="c497" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">所以，这张黑白林肯像只是一个整数矩阵。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="or os di ot bf ou"><div class="gh gi oq"><img src="../Images/698f65fcc998542272b032d14d597be7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*W7r-cBGAXmFklD5h.png"/></div></div><p class="oc od gj gh gi oe of bd b be z dk translated">作者:<a class="ae og" href="http://www.flong.com/" rel="noopener ugc nofollow" target="_blank">戈兰·莱文</a>于<a class="ae og" href="https://openframeworks.cc/ofBook/chapters/image_processing_computer_vision.html" rel="noopener ugc nofollow" target="_blank">图像处理与计算机视觉</a></p></figure><p id="1803" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由于数字图像可以表示为像素值的2D网格，我们可以拉伸/展平网格，将其转换为数字向量，并将其输入神经网络。那解决了问题…对吗？</p><p id="185f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然而，这种方法有两个主要限制。</p><ol class=""><li id="fc10" class="mv mw it kt b ku kv kx ky la mx le my li mz lm ov nb nc nd bi translated">它不能很好地缩放到更大的图像。</li></ol><ul class=""><li id="31a7" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated">虽然对于32*32 = 1024维的输入来说它仍然是可管理的，但是大多数现实生活中的图像都比这大。</li><li id="0f49" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">例如，大小为320x320x3的彩色图像将转换为尺寸为<strong class="kt jd"> 307200 </strong>的输入！</li></ul><p id="eaeb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> 2。它不考虑图像的属性。</strong></p><ul class=""><li id="45c8" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated"><em class="mr">位置</em>:附近的像素通常是强相关的(如看到林肯脸部的轮廓)。拉长它会打破这种模式。</li><li id="098a" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><em class="mr">平移不变性</em>:有意义的特征可以出现在图像的任何地方，例如，看到飞鸟。</li></ul><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="or os di ot bf ou"><div class="gh gi ow"><img src="../Images/93d3768bc9c34a8d426246271b09d800.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*46CJauZm48cMlaU4.png"/></div></div><p class="oc od gj gh gi oe of bd b be z dk translated">图片<a class="ae og" href="https://storage.googleapis.com/deepmind-media/UCLxDeepMind_2020/L3%20-%20UUCLxDeepMind%20DL2020.pdf" rel="noopener ugc nofollow" target="_blank">信用</a>。</p></figure><h2 id="d76f" class="nj ls it bd lt nk nl dn lx nm nn dp mb la no np md le nq nr mf li ns nt mh iz bi translated">卷积的力量</h2><p id="003b" class="pw-post-body-paragraph kr ks it kt b ku mj kd kw kx mk kg kz la ml lc ld le mm lg lh li mn lk ll lm im bi translated">另一方面，CNN被设计成很好地缩放图像，并利用这些独特的属性。它有两个独特的功能:</p><ol class=""><li id="c0d9" class="mv mw it kt b ku kv kx ky la mx le my li mz lm ov nb nc nd bi translated"><strong class="kt jd">权重共享</strong>:图像的所有局部部分都用相同的权重处理，这样可以在许多位置检测到相同的模式，例如水平边缘、曲线等。</li><li id="7db6" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm ov nb nc nd bi translated"><strong class="kt jd">特征层次</strong>:将开始时学习的较低层次的模式进行组合，形成跨层的较高层次的模式，例如从边缘到轮廓到面部轮廓。</li></ol><p id="2bcb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是通过<strong class="kt jd">卷积</strong>的操作完成的:</p><ol class=""><li id="f8d0" class="mv mw it kt b ku kv kx ky la mx le my li mz lm ov nb nc nd bi translated">定义滤波器:特定大小的2D加权矩阵，例如3乘3滤波器。</li><li id="2436" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm ov nb nc nd bi translated">用滤波器对整个图像进行卷积:将滤波器下的每个像素乘以权重。</li><li id="545c" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm ov nb nc nd bi translated">卷积输出形成新的图像:特征图。</li><li id="f0a5" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm ov nb nc nd bi translated">使用多个过滤器(每个具有不同的权重矩阵)，可以捕获不同的特征。</li></ol><h2 id="7954" class="nj ls it bd lt nk nl dn lx nm nn dp mb la no np md le nq nr mf li ns nt mh iz bi translated">卷积示例:均值滤波器</h2><p id="4516" class="pw-post-body-paragraph kr ks it kt b ku mj kd kw kx mk kg kz la ml lc ld le mm lg lh li mn lk ll lm im bi translated">其实还是用数字和图像来看操作吧。会更容易理解到底发生了什么。这里我们用0和1创建了一个明亮的正方形。<code class="fe ln lo lp lq b">matplotlib</code>将[0，1]中的值解释为与[0，255]中的值相同。</p><pre class="nv nw nx ny gt oh lq oi oj aw ok bi"><span id="202e" class="nj ls it lq b gy ol om l on oo">Original image pixel values: <br/> [[0. 0. 0. 0. 0. 0. 0.]<br/> [0. 0. 0. 0. 0. 0. 0.]<br/> [0. 0. 1. 1. 1. 0. 0.]<br/> [0. 0. 1. 1. 1. 0. 0.]<br/> [0. 0. 1. 1. 1. 0. 0.]<br/> [0. 0. 0. 0. 0. 0. 0.]<br/> [0. 0. 0. 0. 0. 0. 0.]]</span></pre><p id="c899" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是图像的样子:</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/7d2742043a7a2df1477fe21c5ca2ea0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/0*tWi8INpibGtpq2c1.png"/></div></figure><p id="4aa3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">回想一下，滤波器是一个2D加权矩阵。让我们创建一个示例过滤器，并将其命名为<strong class="kt jd">“均值过滤器”</strong>:</p><pre class="nv nw nx ny gt oh lq oi oj aw ok bi"><span id="e97b" class="nj ls it lq b gy ol om l on oo">[[0.11 0.11 0.11]<br/> [0.11 0.11 0.11]<br/> [0.11 0.11 0.11]]</span></pre><p id="95aa" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在卷积中，这种“均值滤波器”实际上会滑过图像，取9个相连像素的值，将每个值乘以权重(0.11)，然后返回总和，即原始9个值的加权平均值，因此称为“均值滤波器”:</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/c943f3961a51d9a53e491ab1012721d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Cl0Imc4UkJSyMvoB.gif"/></div></figure><p id="f18a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">您可以从过滤后的图像像素值中看到平均效果。它会模糊图像中的任何边缘。</p><pre class="nv nw nx ny gt oh lq oi oj aw ok bi"><span id="abcd" class="nj ls it lq b gy ol om l on oo">Filtered image pixel values: <br/> [[0.11 0.22 0.33 0.22 0.11]<br/> [0.22 0.44 0.67 0.44 0.22]<br/> [0.33 0.67 1.   0.67 0.33]<br/> [0.22 0.44 0.67 0.44 0.22]<br/> [0.11 0.22 0.33 0.22 0.11]]</span></pre><p id="a4ee" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">这和卷积神经网络有什么关系？</strong></p><p id="1434" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">CNN本质上应用了相同的卷积程序，但关键的区别在于<strong class="kt jd">通过反向传播(训练)来学习滤波器权重</strong>。</p><p id="ea4e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">此外，通常每个图层都有许多滤镜，每个滤镜都有不同的权重矩阵，应用于同一个图像。每个过滤器将捕捉同一图像的不同模式。CNN也可以有多层卷积。网络的复杂性允许捕捉不同尺度的特征。例如，这是过滤器从网络的早期到后期学习的特征的图示。</p><ul class=""><li id="2d5f" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated">早期的滤镜捕捉边缘和纹理。(<strong class="kt jd">通用</strong>)</li><li id="26e7" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">后面的过滤器形成部件和对象。(<strong class="kt jd">具体</strong>)</li></ul><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="or os di ot bf ou"><div class="gh gi oz"><img src="../Images/775723516a2d51fb7785f021281e1333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b6GEvwxftk4Ngiig.png"/></div></div><p class="oc od gj gh gi oe of bd b be z dk translated">图片<a class="ae og" href="https://distill.pub/2017/feature-visualization/" rel="noopener ugc nofollow" target="_blank">信用</a>。</p></figure><h2 id="f4f9" class="nj ls it bd lt nk nl dn lx nm nn dp mb la no np md le nq nr mf li ns nt mh iz bi translated">CNN的主要特点</h2><p id="25ef" class="pw-post-body-paragraph kr ks it kt b ku mj kd kw kx mk kg kz la ml lc ld le mm lg lh li mn lk ll lm im bi translated">虽然DNN使用许多全连接层，但CNN主要包含卷积层。最简单的形式，CNN是一个由一组层组成的网络，这些层将图像转换成一组类别概率。一些最受欢迎的图层类型有:</p><ul class=""><li id="11e7" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated"><strong class="kt jd">卷积层</strong> (CONV):图像经过滤波器的卷积。</li><li id="b804" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><strong class="kt jd"> RELU层</strong> (RELU):单元式非线性激活函数(与DNN之前的相同)。</li><li id="ac3d" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><strong class="kt jd">池层</strong>(池):图像经过均值(或最大值)滤波器的卷积，因此它被向下采样。</li><li id="9925" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><strong class="kt jd">全连通层</strong> (FC):通常作为最后一层输出一个类概率预测。</li></ul><p id="961b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，如果你是<em class="mr">设计自己的CNN </em>，有很多元素可以玩。它们通常分为两类:</p><ol class=""><li id="2bca" class="mv mw it kt b ku kv kx ky la mx le my li mz lm ov nb nc nd bi translated">卷积层的类型</li></ol><ul class=""><li id="12e9" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated"><strong class="kt jd">深度</strong>:每层使用的滤镜数量。</li><li id="1542" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><strong class="kt jd">步幅</strong>:在图像上滑动滤镜时的步幅，通常是1(见上面的卷积GIF)或2。</li><li id="77f1" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><strong class="kt jd">大小</strong>:每个卷积滤波器的大小，例如均值滤波器为3乘3。</li><li id="d68f" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><strong class="kt jd">填充</strong>:卷积时是否在图像周围使用填充。这决定了输出图像的大小。</li><li id="e460" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated">和其他人。</li></ul><p id="bbe6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">2.各层如何连接？</p><p id="a107" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">除了层的类型，你需要为你的CNN设计一个架构。这是一个活跃的研究领域，例如，什么是更好的架构？还是可以自动搜索更好的架构？如果你有兴趣，可以去“神经结构搜索”看看。一个常用的架构是这样的:</p><pre class="nv nw nx ny gt oh lq oi oj aw ok bi"><span id="226e" class="nj ls it lq b gy ol om l on oo"><strong class="lq jd">INPUT --&gt; [ [CONV --&gt; RELU]^N --&gt; POOL]^M --&gt; [FC --&gt; RELU]^K --&gt; FC</strong></span></pre><p id="97a2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">幂(N，M，K)意味着操作重复这些次数。</p><h1 id="6002" class="lr ls it bd lt lu lv lw lx ly lz ma mb ki mc kj md kl me km mf ko mg kp mh mi bi translated">下一步是什么？</h1><p id="8b63" class="pw-post-body-paragraph kr ks it kt b ku mj kd kw kx mk kg kz la ml lc ld le mm lg lh li mn lk ll lm im bi translated">谢谢你一直读到最后！我希望到现在为止，你可以看到CNN和普通DNN的区别，并且对卷积运算有一个直观的理解。请在评论区告诉我你的想法或任何反馈。</p><p id="2cfa" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在下一篇文章中，我们将探讨如何使用CNN来构建一个<strong class="kt jd">新冠肺炎CT扫描图像分类器</strong>。不出所料，一个预先训练好的CNN可以达到很强的基线表现(85%的准确率)。然而，要产生可靠和令人信服的结果，需要的不仅仅是一个神经网络。下面是这篇文章:</p><div class="pa pb gp gr pc pd"><a rel="noopener follow" target="_blank" href="/domain-expertise-what-deep-learning-needs-for-better-covid-19-detection-56cdeefde564"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd jd gy z fp pi fr fs pj fu fw jc bi translated">深度学习需要什么来更好地检测新冠肺炎</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">这个世界可能不需要另一个神经网络，但它需要与那些在第一线的人进行咖啡聊天。</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr oa pd"/></div></div></a></div><h1 id="50f1" class="lr ls it bd lt lu lv lw lx ly lz ma mb ki mc kj md kl me km mf ko mg kp mh mi bi translated">更多资源</h1><p id="b741" class="pw-post-body-paragraph kr ks it kt b ku mj kd kw kx mk kg kz la ml lc ld le mm lg lh li mn lk ll lm im bi translated">如果你有兴趣了解更多关于CNN的信息，请查阅👉：</p><ul class=""><li id="c667" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated"><a class="ae og" href="https://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank">用于视觉识别的CS231n卷积神经网络</a></li><li id="dcc3" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><a class="ae og" href="https://www.youtube.com/watch?v=shVKhOmT0HE&amp;ab_channel=DeepMind" rel="noopener ugc nofollow" target="_blank"> DeepMind x UCL |用于图像识别的卷积神经网络</a></li></ul><p id="c76e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以及如何实现它们👉：</p><ul class=""><li id="278f" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated">工程师Keras简介</li><li id="48ad" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><a class="ae og" href="https://www.tensorflow.org/tutorials/images/cnn" rel="noopener ugc nofollow" target="_blank"> Tensorflow Keras CNN指南</a></li></ul><p id="bce6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">尽情享受吧！👏👏👏</p></div><div class="ab cl ps pt hx pu" role="separator"><span class="pv bw bk pw px py"/><span class="pv bw bk pw px py"/><span class="pv bw bk pw px"/></div><div class="im in io ip iq"><p id="0d3f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="mr">原载于</em><a class="ae og" href="https://yangxiaozhou.github.io/data/2020/09/24/intro-to-cnn.html" rel="noopener ugc nofollow" target="_blank"><em class="mr">https://yang xiaozhou . github . io</em></a><em class="mr">。</em></p></div></div>    
</body>
</html>