<html>
<head>
<title>How the hell are GPUs so fast? A HPC walk along Nvidia CUDA-GPU architectures. From zero to nowadays.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GPU到底怎么这么快？沿着Nvidia CUDA-GPU架构的HPC之旅。从零到现在。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-the-hell-are-gpus-so-fast-a-e770d74a0bf?source=collection_archive---------19-----------------------#2020-10-06">https://towardsdatascience.com/how-the-hell-are-gpus-so-fast-a-e770d74a0bf?source=collection_archive---------19-----------------------#2020-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/783b4ed0dfc8ed4a637ee6708993ee9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2qoQXxvKXUJb8Hti"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">Rafael Pol 在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="18f4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有人将机器学习定义为数学(算法)、工程(高性能计算)和人类能力(经验)之间的完美和谐。因此，这些领域的任何进展都将有助于机器学习的发展。今天轮到了HPC，具体来说，我们正在讨论GPU的进步。</p><p id="f0e6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Nvidia刚刚宣布了其基于Ampere架构的<a class="ae kc" href="https://www.anandtech.com/show/16057/nvidia-announces-the-geforce-rtx-30-series-ampere-for-gaming-starting-with-rtx-3080-rtx-3090" rel="noopener ugc nofollow" target="_blank"> Geforce RTX 30系列</a> (RTX3090，RTX3080，RTX3070)。安培是我们最喜欢的GPU品牌的最后一个架构，但迄今为止已经发布了几代支持CUDA的GPU。在接下来的段落中，我将从头到尾描述CUDA架构的全球概况。今天，让我们一起驾驶有趣的道路，从费米到安培。但是在深入讨论细节之前，如果你不熟悉GPU计算，我强烈建议你访问我之前关于CUDA执行模型的文章。</p><p id="f08e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">遵循Nvidia GPUs的自然时间轴，该公司于2001年首次生产了一款能够进行可编程着色的芯片，Playstation 2和Xbox使用的<a class="ae kc" href="https://en.wikipedia.org/wiki/GeForce_3" rel="noopener ugc nofollow" target="_blank"><em class="lb">【GeForce 3】</em></a><em class="lb"/>。在GeForce 3(代号<em class="lb"> NV20 </em>)之前，还有其他一些:NV1 (1995)、NV3 (1997)、NV4 (1998)、NV5 (1999)、GeForce I(1999年年底)和GeForce II (2000)。然而，GeForce 3可能是第一款受欢迎的Nvidia GPU。</p><p id="d739" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">指出Nvidia世界中目标类别和架构之间的差异是很有趣的，这可能会让读者感到困惑。传统上，Nvidia为每个目标客户类别设计了不同类型的产品，为四种不同的产品命名:GeForce、Quadro、Tesla和(最近的)Jetson尽管这四种产品内部使用的基础架构是相同的。用Nvidia的话说，他们四个拥有相同的计算能力。GeForce系列专注于桌面和游戏玩家；Quadro被认为是为制作视频内容的工作站和开发者设计的；而特斯拉是为超级计算机和高性能计算设计的。最后，Jetson系列在芯片中包含嵌入式GPU。</p><p id="7bd3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们刚才在上面看到的，Nvidia在90年代初开始了它的冒险，专注于grapichs的GPU，但我们直到2007年才开始使用第一个CUDA架构:<a class="ae kc" href="http://developer.download.nvidia.com/compute/cuda/1.0/NVIDIA_CUDA_Programming_Guide_1.0.pdf" rel="noopener ugc nofollow" target="_blank"> Tesla </a>(是的，你是对的，他们后来为一个产品线使用了相同的架构名称，这就是为什么我说它可能会令人困惑)。Tesla是一个非常简单的架构，所以我决定直接从Fermi开始，它引入了纠错码存储器，真正改善了上下文切换、存储器层次结构和双精度。</p><h1 id="225e" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">费米体系结构</h1><p id="abb8" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">每个费米流式多处理器(SMI)由32个CUDA内核(流式处理器)、16个加载/存储单元(LD/ST单元)组成，以解决每个时钟16个线程的内存操作、四个特殊功能单元(SFU)以执行超越数学指令、一个内存层次结构和warp调度程序。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mf"><img src="../Images/e244200c760493adb3a80b3ff9287c78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SxMOBLleUqEnf1Lu99Al5A.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">费米流式多处理器(<em class="mk">图片作者</em></p></figure><p id="a897" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该板有六个64位内存分区，带有一个384位内存接口，支持高达6 GB的GDDR5 DRAM内存。CPU通过PCI-e总线连接到GPU。每个CUDA内核都有一个全流水线算术逻辑单元(ALU)和一个浮点单元(FPU)。为了执行双精度，32个CUDA内核可以执行16个FP64单元。每个SM有两个warp调度程序，可以同时发布和执行2个warp。</p><p id="0d67" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种架构的一个关键部分是内存层次结构。它引入了64 KB的可配置共享内存和每个SM的L1缓存，可以配置为16 KB的L1缓存和48 KB的共享内存；或者16 KB的共享内存和48 KB的L1缓存。尽管CPU L1缓存是为空间和时间局部性而设计的，但GPU L1仅针对空间局部性进行了优化。频繁访问缓存的L1内存位置不会增加命中数据的可能性，但是当几个线程访问相邻的内存空间时，这是很有吸引力的。768 KB的L2缓存是统一的，由服务于所有操作(加载、存储和纹理)的所有SMs共享。两个缓存都用于在本地和全局内存中存储数据，包括寄存器溢出。但是，需要配置是在L1和L2缓存读取数据，还是仅在L2缓存。这种架构被称为<em class="lb">计算能力2.x </em>，这是Nvidia专门用来描述GPU硬件版本的术语，由主版本号(左数字)和次版本号(右数字)组成。具有相同主要修订号的器件属于相同的核心架构，而次要修订号对应于核心架构的增量改进。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/22fdf39364fdd568f6b8a833e2808798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hj84wCPdkdPRg2zfYb2rbw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">费米记忆层级(<em class="mk">图片作者</em>)</p></figure><h1 id="ce45" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">开普勒建筑</h1><p id="0595" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">开普勒包括多达15个SMs和6个64位内存控制器。每个SM有192个单精度CUDA核，64个双精度单元，32个sfu，32个LD/ST单元和16个纹理单元。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mm"><img src="../Images/2e4a7406978b63f7c27f7dbb4ab5080c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DGU1Apz_junG9atfQrkLzA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">开普勒流式多处理器(<em class="mk">图片作者</em></p></figure><p id="5157" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，四个warp调度器，每个调度器有两个调度单元，允许四个warp并发执行。它还增加了每个线程访问的寄存器数量，从Fermi中的63个增加到255个；它引入了shuffle指令，并通过在全局内存中引入对FP64原子的本机支持来改进原子操作。它还介绍了CUDA动态并行性，即从内核启动内核的能力。此外，内存层次的组织方式与费米相似。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/52c5ea80b4683ad643c388cd8eb96a39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZnqdsgYXuMrkdmKulJsgrA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">开普勒记忆层次(<em class="mk">图片作者</em></p></figure><p id="796f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">64 KB共享内存/L1缓存通过允许在L1缓存和共享内存之间进行32 KB/32 KB分割而得到改进。它还将共享内存库宽度从Fermi中的32位增加到64位，并引入了48 KB只读数据缓存来缓存常量数据。L2缓存也增加到1536 KB，使费米L2缓存容量翻倍。此外，开普勒计算能力用<em class="lb"> 3.x </em>代码表示。</p><h1 id="0852" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">麦克斯韦建筑</h1><p id="c670" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">Maxwell由多达16个SMs和4个内存控制器组成。每个SM都经过重新配置，以提高性能功耗比。它包含四个warp调度器，每个能够在每个时钟周期为每个warp发送两条指令。SM分为四个32-CUDA核心处理模块，每个模块有八个纹理单元、八个sfu和八个LD/ST单元。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mn"><img src="../Images/229040cb17c5c69d75486b615f12664a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h1o8Jg9VxxuBt7hoHyxgEw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">麦克斯韦流多处理器(<em class="mk">图片作者</em>)</p></figure><p id="06ac" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于内存层次，它具有96 KB的专用共享内存(尽管每个线程块最多只能使用48 KB)，而L1缓存与纹理缓存功能共享。L2缓存提供2048 KB的容量。内存带宽也增加了，从Kepler中的192 GB/秒增加到224 GB/秒，并且在共享内存中引入了对FP32原子的本机支持。麦克斯韦被表示为计算能力<em class="lb"> 5.x </em>。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/23a1731244bf1b540c6115b4fc23fd84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wA43K50qz9cTXIM1xK0tzQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">麦克斯韦记忆层次(<em class="mk">图片作者</em>)</p></figure><h1 id="d46b" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">帕斯卡建筑</h1><p id="71f6" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">Pascal板由多达60个SMs和8个512位存储控制器组成。每个SM有64个CUDA内核和4个纹理单元。它拥有与开普勒和麦克斯韦相同数量的寄存器，但是提供更多的SMs，因此总的来说有更多的寄存器。它被设计为比以前的架构支持更多的活动经线和线程块。共享内存带宽加倍，以更高效地执行代码。它允许加载/存储指令的重叠，以提高浮点利用率，也改善了warp调度，其中每个warp调度器能够在每个时钟分派两个warp指令。CUDA核心能够处理16位和32位指令和数据，有利于深度学习程序的使用，但也为数值程序提供了32个FP64 CUDA核心。全局内存本机支持也扩展到包括FP64原子。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/fa7559b2d190ad8667a36aaed8331272.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHx98WnKg6P6TLd0ojwB6A.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">Pascal流多处理器(<em class="mk">图片作者</em></p></figure><p id="d7fb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">内存层次结构配置也发生了变化。每个内存控制器都连接到512 KB的L2缓存，提供4096 KB的L2缓存，并引入HBM2内存，提供732 GB/s的带宽。它为每个SM提供64 KB的共享内存，以及一个L1缓存，也可用作纹理缓存，作为合并缓冲区来提高warp数据的局部性。它的计算能力用<em class="lb"> 6.x </em>代码来表示。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/31a4e6123ea2a0224abb9f79eb14971c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zW_zvVDCbPdb6mOp6klgZA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">帕斯卡记忆层次(<em class="mk">图片作者</em>)</p></figure><p id="b27f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后介绍了NVLink技术。背后的想法是，任何4-GPU和8-GPU系统配置都可以处理相同的问题。甚至，几组多GPU系统正在使用InfiniBand和100 Gb以太网互连，以形成更大、更强大的系统。</p><h1 id="14f9" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">沃尔特建筑公司</h1><p id="1132" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">一个Volta板有多达84个SMs和8个512位存储控制器。每个SM有64个FP32 CUDA核心，64个INT32 CUDA核心，32个FP64 CUDA核心，8个用于深度学习矩阵运算的张量核心，32个LD/ST单元，16个sfu。每个SM分为4个处理模块，每个模块包含一个新的L0指令高速缓存，以提供比以前的指令缓冲区更高的效率，以及一个带有调度单元的warp调度程序，这与Pascal的2分区设置(每个子内核warp调度程序有两个调度端口)相反。这意味着Volta失去了在单个时钟周期内从一个线程发出第二条独立指令的能力。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mn"><img src="../Images/f53190fdbbe7a77829cc248a67f0281a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7yeWvKcteA__FkipNR42XQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">Volta流式多处理器(<em class="mk">图片作者</em>)</p></figure><p id="2700" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">引入了合并的128 KB L1数据缓存/共享内存，提供了96 KB的共享内存。HBM2带宽也得到了提高，达到900 GB/s。此外，完整的GPU包括总共6144 KB的L2缓存，其计算能力用<em class="lb"> 7.0 </em>代码表示。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/e3d4321380755f6c1009fb2fcf330112.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p3Nz2l7KXGZlg9FuN1zpyQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">伏打记忆层级(<em class="mk">图片作者</em>)</p></figure><p id="d5a5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，最大的变化来自于它的独立线程调度。以前的体系结构以SIMT方式执行扭曲，其中32个线程共享一个程序计数器。在发散的情况下，活动掩码指示在任何给定时间哪些线程是活动的，留下一些线程是不活动的，并串行化不同分支选项的执行。Volta包括一个程序计数器和每个线程的调用堆栈。它还引入了一个调度优化器，用于确定来自同一warp的哪些线程必须一起执行到SIMT单元中，从而提供更多的灵活性，因为线程现在可以在子warp粒度上分叉。</p><p id="f8ca" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Volta的最新突破性功能被称为<em class="lb">张量核心</em>，与之前的帕斯卡P100加速器相比，它的深度学习应用速度提高了12倍。它们本质上是混合精度FP16/FP32内核阵列。640个张量核中的每一个都在4x4矩阵上运行，它们相关的数据路径是定制设计的，以提高这种矩阵上的浮点计算吞吐量。每个张量核每时钟执行64次浮点融合乘加(FMA)运算，为训练和推理应用提供高达125 TFLOPS。</p><p id="96f0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，第二代NVLink为多GPU系统配置提供了更高的带宽、更多的链路和改进的可扩展性。Volta GV100支持多达6条NVLink链路和300 GB/秒的总带宽，而GP100支持4条NVLink链路和160 GB/秒的总带宽。</p><h1 id="dc17" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">图灵(不是全新的)架构</h1><p id="5d4b" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">NVIDIA首席执行官黄仁勋<a class="ae kc" href="https://seekingalpha.com/article/4199978-nvidia-corporation-nvda-ceo-jensen-huang-q2-2019-results-earnings-call-transcript" rel="noopener ugc nofollow" target="_blank">就Pascal、Volta和Turing之间的架构差异提供了一个有趣的</a>回复。基本上，他解释说伏打和图灵有不同的目标市场。Volta旨在用于大规模培训，最多可连接八个GPU，具有最快的HBM2和其他专门针对数据中心的功能。另一方面，图灵在设计时考虑了三个应用:专业可视化、视频游戏和使用张量核的图像生成。实际上，图灵拥有和Volta一样的计算能力，<em class="lb"> 7.x，</em>这就是为什么我说图灵不是一个全新的架构。</p><p id="0aaf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最显著的成就:使用GDDR6内存和引入RT内核，能够渲染视觉上逼真的3D游戏和复杂的专业模型:</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mq"><img src="../Images/973d13fab0adb7514674c37c8d747c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dHYl3E24azCURAuLUIEb5A.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图灵流式多处理器。来源:<a class="ae kc" href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf" rel="noopener ugc nofollow" target="_blank">英伟达</a></p></figure><p id="c2a3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像Volta一样，图灵SM被分成4个处理模块，每个模块都有一个warp调度程序和调度单元。图灵几乎等同于Volta在两个周期内执行指令，但调度程序可以在每个周期发出一条独立的指令。此外，与Pascal的per-warp不同，Volta和Turing有每个线程的调度资源，每个线程有一个程序计数器和堆栈来跟踪线程状态。</p><h1 id="d41b" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">安培架构</h1><p id="a5e8" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">最新的CUDA架构被称为Ampere，提供了迄今为止最高的GPU性能。有人在这里做了一个真正完整的回顾<a class="ae kc" href="https://medium.com/@jonathan_hui/ai-chips-a100-gpu-with-nvidia-ampere-architecture-3034ed685e6e" rel="noopener"/>，我强烈推荐。</p><p id="40f0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每个Ampere SM包含四个处理模块，每个模块都有用于数据缓存的L0缓存、warp调度器、16个INT32 CUDA内核、16个FP32 CUDA内核、8个FP64 CUDA内核、8个LD/ST内核、一个用于矩阵乘法的张量内核和一个16K 32位寄存器文件。每个SM都有一个192 KB的组合共享内存和L1数据缓存；在GPU级别，它有40MB的L2缓存来提高性能(比Volta中的V100大7倍)。L2缓存分为两个分区，以实现更高的带宽。</p><figure class="mg mh mi mj gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mr"><img src="../Images/3cc049fa0200da95f3531c0b4e195f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zNJtHQ4qC-5h6MhXtQBCww.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">安培流式多处理器。来源:<a class="ae kc" href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf" rel="noopener ugc nofollow" target="_blank">英伟达。</a></p></figure><p id="fb0b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">GA100 GPU芯片由128个sm组成，但主要是因为-营销-制造，不同的安培GPU只会启用其中的一部分。比如A100 GPU只暴露108条短信。总之，完整的GA100由8个GPC组成，每个GPC有16个SM和6个HBM2堆栈。在A100 GPU的情况下，这被转换为40 GB的HBM2 DRAM存储器，速度为1555 GB/s。</p><p id="e64c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它还引入了第三代NVIDIA张量内核(继Volta和Turing之后)，允许它每时钟计算8×4×8混合精度矩阵乘法(将8×4矩阵乘以4×8矩阵)。例如，每个A100张量核每时钟执行256个FP16 FMA(融合乘加)运算。Ampere在其张量核上支持许多数据类型，包括FP16、BF16、TF32、FP64、INT8、INT4和Binary。</p><p id="b749" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后在Ampere上呈现第三代NVLink。在A100 GPU的情况下，它有12个NVLink链接，总带宽为600 GB/s，用于多GPU计算。关于PCIe连接，A100 GPU支持PCIeGen 4，它提供每个方向31.5 GB/秒的带宽(用于x16连接)，是PCIe 3的两倍带宽。</p><h1 id="ea7c" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">参考</h1><p id="5a66" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated"><a class="ae kc" href="https://www.nvidia.com/content/PDF/fermi_white_papers/NVIDIAFermiComputeArchitectureWhitepaper.pdf" rel="noopener ugc nofollow" target="_blank">费米白皮书</a></p><p id="93f0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/NVIDIA-Kepler-GK110-GK210-Architecture-Whitepaper.pdf" rel="noopener ugc nofollow" target="_blank">开普勒白皮书</a></p><p id="f188" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.microway.com/download/whitepaper/NVIDIA_Maxwell_GM204_Architecture_Whitepaper.pdf" rel="noopener ugc nofollow" target="_blank">麦斯威尔白皮书</a></p><p id="b8f6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://images.nvidia.com/content/pdf/tesla/whitepaper/pascal-architecture-whitepaper.pdf" rel="noopener ugc nofollow" target="_blank">帕斯卡白皮书</a></p><p id="e5fe" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf" rel="noopener ugc nofollow" target="_blank">沃尔特白皮书</a></p><p id="7414" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf" rel="noopener ugc nofollow" target="_blank">图灵白皮书</a></p><p id="5fe7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf" rel="noopener ugc nofollow" target="_blank">安培白皮书</a></p><p id="a1b2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="http://gac.des.udc.es/tesis/AdrianPerezDieguez.pdf" rel="noopener ugc nofollow" target="_blank">GPU上的并行算法</a></p></div></div>    
</body>
</html>