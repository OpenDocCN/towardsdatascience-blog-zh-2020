<html>
<head>
<title>Billion-scale semantic similarity search with FAISS+SBERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于FAISS+SBERT的亿级语义相似性搜索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/billion-scale-semantic-similarity-search-with-faiss-sbert-c845614962e2?source=collection_archive---------3-----------------------#2020-10-18">https://towardsdatascience.com/billion-scale-semantic-similarity-search-with-faiss-sbert-c845614962e2?source=collection_archive---------3-----------------------#2020-10-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="00f3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">构建智能搜索引擎的原型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a57baedc902f19502587b38a6dd91e17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k7rgUFTqWdHyBY72PlCIow.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="583c" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">介绍</h2><p id="f07c" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">语义搜索是一种信息检索系统，它关注句子的含义，而不是传统的关键字匹配。尽管有许多文本嵌入可以用于此目的，但是很少有人讨论如何扩展它来构建可以从大量数据中获取数据的低延迟API。在这篇文章中，我将讨论我们如何使用SOTA句子嵌入(<a class="ae mk" href="https://arxiv.org/pdf/1908.10084.pdf" rel="noopener ugc nofollow" target="_blank">句子转换器</a>和<a class="ae mk" href="https://github.com/facebookresearch/faiss" rel="noopener ugc nofollow" target="_blank"> FAISS </a>)来实现一个最小语义搜索引擎。</p><h2 id="4de5" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">句子变形金刚</h2><p id="bfd6" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">它是一个框架或一组模型，给出句子或段落的密集向量表示。这些模型是变压器网络(BERT、RoBERTa等。)进行了微调，特别是针对语义文本相似性的任务，因为BERT对于这些任务的开箱即用表现不佳。下面给出了不同型号在STS基准测试中的性能</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/63ca4036cedacf772bd0048eef173e46.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*W_bJ7L-JY-InNwQkvB2o4Q.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来源:<a class="ae mk" href="https://github.com/UKPLab/sentence-transformers" rel="noopener ugc nofollow" target="_blank">句子变形金刚</a></p></figure><p id="750f" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">我们可以看到，句子转换模型远远优于其他模型。</p><p id="df65" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">但是如果你看一下排行榜上有代码为和<a class="ae mk" href="https://gluebenchmark.com/leaderboard" rel="noopener ugc nofollow" target="_blank">胶水</a>的<a class="ae mk" href="https://paperswithcode.com/sota/semantic-textual-similarity-on-sts-benchmark" rel="noopener ugc nofollow" target="_blank">论文，你会看到很多90以上的模型。那么我们为什么需要句子变形金刚呢？。</a></p><p id="d1d0" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">在这些模型中，语义文本相似度被认为是一项回归任务。这意味着每当我们需要计算两个句子之间的相似性得分时，我们需要将它们一起传递到模型中，模型输出它们之间的数值得分。虽然这对于基准测试很有效，但是对于现实生活中的用例来说，它的伸缩性很差，原因如下。</p><ol class=""><li id="51e3" class="mr ms iq lt b lu mm lx mn le mt li mu lm mv mj mw mx my mz bi translated">当您需要搜索10 k个文档时，您将需要执行10k个独立的推理计算，这是不可能单独计算嵌入和仅计算余弦相似性的。见作者<a class="ae mk" href="https://github.com/UKPLab/sentence-transformers/issues/405#issuecomment-689397806" rel="noopener ugc nofollow" target="_blank">解释</a>。</li><li id="e64f" class="mr ms iq lt b lu na lx nb le nc li nd lm ne mj mw mx my mz bi translated">最大序列长度(模型在一次传递中可以采用的单词/标记的总数)在两个文档之间共享，这导致表示由于分块而被稀释</li></ol><h2 id="ace0" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">费斯</h2><p id="969e" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">Faiss是一个基于C++的库，由脸书·艾创建，带有一个完整的python包装器，用于索引矢量化数据并对其进行有效搜索。Faiss根据以下因素提供不同的指数</p><ul class=""><li id="7126" class="mr ms iq lt b lu mm lx mn le mt li mu lm mv mj nf mx my mz bi translated">搜索时间</li><li id="075d" class="mr ms iq lt b lu na lx nb le nc li nd lm ne mj nf mx my mz bi translated">搜索质量</li><li id="addb" class="mr ms iq lt b lu na lx nb le nc li nd lm ne mj nf mx my mz bi translated">每个索引向量使用的内存</li><li id="2633" class="mr ms iq lt b lu na lx nb le nc li nd lm ne mj nf mx my mz bi translated">训练时间</li><li id="9040" class="mr ms iq lt b lu na lx nb le nc li nd lm ne mj nf mx my mz bi translated">无监督训练需要外部数据</li></ul><p id="d8e8" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">因此，选择正确的指数将是这些因素之间的权衡。</p><h2 id="fed6" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">加载模型并对数据集执行推理</h2><p id="301c" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">首先，让我们安装并加载所需的库</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="78f9" class="kv kw iq nh b gy nl nm l nn no">!pip install faiss-cpu<br/>!pip install -U sentence-transformers</span><span id="154b" class="kv kw iq nh b gy np nm l nn no">import numpy as np<br/>import torch<br/>import os<br/>import pandas as pd<br/>import faiss<br/>import time<br/>from sentence_transformers import SentenceTransformer</span></pre><p id="7182" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">加载带有<strong class="lt ir">百万个数据点</strong>的数据集</p><p id="0e28" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">我使用了一个来自Kaggle的数据集，其中包含了17年间发布的新闻标题。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="52dc" class="kv kw iq nh b gy nl nm l nn no">df=pd.read_csv("abcnews-date-text.csv")<br/>data=df.headline_text.to_list()</span></pre><p id="f4ed" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">加载预训练模型并执行推理</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="2a74" class="kv kw iq nh b gy nl nm l nn no">model = SentenceTransformer('distilbert-base-nli-mean-tokens')</span><span id="9f67" class="kv kw iq nh b gy np nm l nn no">encoded_data = model.encode(data)</span></pre><h2 id="ec45" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">索引数据集</h2><p id="1aeb" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">通过参考<a class="ae mk" href="https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index" rel="noopener ugc nofollow" target="_blank">指南</a>，我们可以根据我们的用例选择不同的索引选项。</p><p id="32d5" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">让我们定义索引并向其中添加数据</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="981d" class="kv kw iq nh b gy nl nm l nn no">index = faiss.IndexIDMap(faiss.IndexFlatIP(768))</span><span id="fdf7" class="kv kw iq nh b gy np nm l nn no">index.add_with_ids(encoded_data, np.array(range(0, len(data))))</span></pre><p id="fbd9" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">序列化索引</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="6c69" class="kv kw iq nh b gy nl nm l nn no">faiss.write_index(index, 'abc_news')</span></pre><p id="3bb5" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">串行化的索引然后可以被导出到用于托管搜索引擎的任何机器中</p><p id="b727" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">反序列化索引</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="8270" class="kv kw iq nh b gy nl nm l nn no">index = faiss.read_index('abc_news')</span></pre><h2 id="54a9" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">执行语义相似性搜索</h2><p id="1552" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">让我们首先为搜索构建一个包装器函数</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="f719" class="kv kw iq nh b gy nl nm l nn no">def search(query):<br/>   t=time.time()<br/>   query_vector = model.encode([query])<br/>   k = 5<br/>   top_k = index.search(query_vector, k)<br/>   print('totaltime: {}'.format(time.time()-t))<br/>   return [data[_id] for _id in top_k[1].tolist()[0]]</span></pre><p id="b0a5" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">执行搜索</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="5ad4" class="kv kw iq nh b gy nl nm l nn no">query=str(input())<br/>results=search(query)<br/>print('results :')<br/>for result in results:<br/>   print('\t',result)</span></pre><h1 id="d873" class="nq kw iq bd kx nr ns nt la nu nv nw ld jw nx jx lh jz ny ka ll kc nz kd lp oa bi translated">CPU上的结果</h1><p id="ed86" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">现在让我们看看搜索结果和响应时间</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/e38c03874edb0e73af0ccafb6098bc03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*NiBBSAiUPCdPif-0eogVFw.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者GIF</p></figure><p id="f9f2" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated"><strong class="lt ir">仅用<strong class="lt ir"> CPU后端</strong>对一个包含<strong class="lt ir">百万</strong>文本文档的数据集执行智能的基于含义的搜索只需要1.5秒</strong>。</p><h1 id="023d" class="nq kw iq bd kx nr ns nt la nu nv nw ld jw nx jx lh jz ny ka ll kc nz kd lp oa bi translated">GPU上的结果</h1><p id="ff59" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">首先，我们卸载Faiss的CPU版本，重装GPU版本</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="cc52" class="kv kw iq nh b gy nl nm l nn no">!pip uninstall faiss-cpu<br/>!pip install faiss-gpu</span></pre><p id="11c0" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">然后按照相同的过程，但在最后将索引移动到GPU。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="c715" class="kv kw iq nh b gy nl nm l nn no">res = faiss.StandardGpuResources()<br/>gpu_index = faiss.index_cpu_to_gpu(res, 0, index)</span></pre><p id="d5be" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">现在让我们把它放在搜索函数中，用GPU执行搜索。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/1b0d656e04775d769de51ed63e88400c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*Aw5iEUussR8E2O_ZZPH2Aw.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者GIF</p></figure><p id="3661" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">没错，使用比CPU后端快75倍的GPU (本实验中使用的是特斯拉T4)<strong class="lt ir">可以在<strong class="lt ir"> 0.02秒内得到结果</strong></strong></p><h2 id="aa23" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">但是，如果我可以等待几秒钟，为什么我不能序列化编码数据的NumPy数组而不是索引它们并使用余弦相似性呢？</h2><p id="fdbf" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">因为NumPy没有自带的序列化函数，所以唯一的方法是将其转换成JSON，然后保存JSON对象，但是这样一来，大小会增加五倍。例如，用普通索引编码成768维向量空间的100万个数据点大约是3GB，将其转换成JSON将是15GB，这是普通机器的RAM所不能容纳的。因此，每次执行搜索时，我们都必须运行一百万次计算推断，这是不实际的。</p><h1 id="fe24" class="nq kw iq bd kx nr ns nt la nu nv nw ld jw nx jx lh jz ny ka ll kc nz kd lp oa bi translated">最后的想法</h1><p id="7892" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">这是一个基本的实现，在语言模型部分和索引部分还有很多工作要做。有不同的索引选项，应根据使用情形、数据大小和可用的计算能力选择正确的选项。此外，这里使用的句子嵌入只是在一些公共数据集上进行微调，在特定领域的数据集上进行微调将改善嵌入，从而改善搜索结果。</p><h1 id="6d7c" class="nq kw iq bd kx nr ns nt la nu nv nw ld jw nx jx lh jz ny ka ll kc nz kd lp oa bi translated">参考</h1><p id="029b" class="pw-post-body-paragraph lr ls iq lt b lu lv jr lw lx ly ju lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated"><em class="oc"> [1]尼尔斯·雷默斯和伊琳娜·古雷维奇。</em> <a class="ae mk" href="https://arxiv.org/pdf/2004.09813.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="oc">制作单语句子嵌入多语使用知识蒸馏</em> </a> <em class="oc">。”arXiv (2020): 2004.09813。</em></p><p id="0bf5" class="pw-post-body-paragraph lr ls iq lt b lu mm jr lw lx mn ju lz le mo mb mc li mp me mf lm mq mh mi mj ij bi translated">[2]约翰逊，杰夫和杜泽，马特希斯和J{\'e}gou，赫夫{\'e} <em class="oc">。</em> <a class="ae mk" href="https://arxiv.org/abs/1702.08734" rel="noopener ugc nofollow" target="_blank">用GPU进行亿级相似性搜索</a><em class="oc"/>arXiv预印本arXiv:1702.08734 <em class="oc">。</em></p></div></div>    
</body>
</html>