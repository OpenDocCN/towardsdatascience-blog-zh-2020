<html>
<head>
<title>Animating Yourself as a Disney Character with AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用人工智能让你自己成为一个迪斯尼角色</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/animating-yourself-as-a-disney-character-with-ai-78af337d4081?source=collection_archive---------14-----------------------#2020-10-26">https://towardsdatascience.com/animating-yourself-as-a-disney-character-with-ai-78af337d4081?source=collection_archive---------14-----------------------#2020-10-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e6a3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">先睹为快数字艺术的未来</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9e1df6bc44e70fc9c93bc25d385bfd4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Xp6q6b1kMb2Y5wrpfUi1uA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">【作者生成的图片】【CC许可下来源于维基百科的名人图片:<a class="ae ky" href="https://en.wikipedia.org/wiki/Scarlett_Johansson#/media/File:Goldene_Kamera_2012_-_Scarlett_Johansson_3_(cropped).JPG" rel="noopener ugc nofollow" target="_blank"> Scarlet J. </a>，<a class="ae ky" href="https://en.wikipedia.org/wiki/Sherlock_(TV_series)#/media/File:Benedict_Cumberbatch_filming_Sherlock_cropped2.jpg" rel="noopener ugc nofollow" target="_blank"> Benedict C </a>。，<a class="ae ky" href="https://en.wikipedia.org/wiki/Will_Smith#/media/File:TechCrunch_Disrupt_2019_(48834434641)_(cropped).jpg" rel="noopener ugc nofollow" target="_blank">将S </a>。、<a class="ae ky" href="https://en.wikipedia.org/wiki/Emma_Watson#/media/File:Emma_Watson_2013.jpg" rel="noopener ugc nofollow" target="_blank"> Emma W. </a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Elon_Musk#/media/File:Elon_Musk_Royal_Society.jpg" rel="noopener ugc nofollow" target="_blank"> Elon M. </a>【奥巴马视频来源于<a class="ae ky" href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/" rel="noopener ugc nofollow" target="_blank"> VoxCeleb数据集</a>，CC BY 4.0】</p></figure><p id="bb4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上周，我在网上冲浪，无意中发现了贾斯汀·平克尼写的一篇有趣的文章。有什么好玩的？有人用这个想法做了一个很酷的应用！多伦·阿德勒(Doron Adler)用迪士尼人物对StyleGAN2模型进行了微调，然后将这些层与真实人脸模型(FFHQ)混合，并根据真实人脸生成迪士尼人物。</p><div class="kj kk kl km gt ab cb"><figure class="lv kn lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/aef142260a7449760cd980496544fc4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*I6lpWgucTIc04YGksEyTlg.png"/></div></figure><figure class="lv kn mb lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/572b05fa9ceae0adff0ff24998abfcc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*f56NJYM7zTMERnYJmG4P5w.png"/></div></figure><figure class="lv kn mc lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/fcc321cf6757465edc19e2ee552ffb0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*hHXhaMwKLQvHvvZ4dN540g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk md di me mf translated">根据CC许可，图片来源于维基百科:<a class="ae ky" href="https://en.wikipedia.org/wiki/Scarlett_Johansson#/media/File:Goldene_Kamera_2012_-_Scarlett_Johansson_3_(cropped).JPG" rel="noopener ugc nofollow" target="_blank">斯嘉丽·约翰逊</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Sherlock_(TV_series)#/media/File:Benedict_Cumberbatch_filming_Sherlock_cropped2.jpg" rel="noopener ugc nofollow" target="_blank">本尼迪克特·康伯巴奇</a>和<a class="ae ky" href="https://en.wikipedia.org/wiki/Will_Smith#/media/File:TechCrunch_Disrupt_2019_(48834434641)_(cropped).jpg" rel="noopener ugc nofollow" target="_blank">威尔·史密斯</a>。作者生成的动画图像。</p></figure></div><p id="91fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，贾斯汀·平克尼接着在<a class="ae ky" href="https://toonify.photos/original" rel="noopener ugc nofollow" target="_blank">上发布了这个模型，以此来统一</a>。你只需上传你的照片，就能立刻得到你的迪士尼角色。试试吧！</p><p id="4f24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，在这篇文章中，我们将学习如何以编程的方式来实现这一点，并制作角色动画！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/18df3e8b2d6f6da88bdf76b6abb74f54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/1*dzVgKRxJltMTPL18XedlUw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">埃隆·马斯克的动画角色(为GIF优化而压缩)[图片由作者生成][埃隆·马斯克图片来源于Flickr由<a class="ae ky" href="https://www.flickr.com/photos/teslaclubbe/12271223586/in/photolist-jGnefs-7B4UpY-9BSeXs-haF167-eX9YxQ-ozwwpo-d83K9o-bXaJjZ-eyW9oB-fr8vN5-fqTf5g-7TXJEu-7B1dzT-nVS8fa-gjVgTf-haETfc-anD1Gd-ccdkPb-e2rcqL-5ubGnz-z4XLj7-rRMLTf-4t8UwZ-oNtTSq-jGn7AL-DYXSbK-emx5tu-526A61-rdqdcL-52281c-dYpvQE-cex63W-cex65f-ftXbTC-feq9zf-rocWAZ-feq9zL-BcRSGv-8NFnMJ-GvCak7-vWRj6g-AWqF3z-uMdB5p-vDTKwn-GVHFMa-gm9SkQ-tuWDGY-sAgpsJ-92iXxj-bnvZh" rel="noopener ugc nofollow" target="_blank">特斯拉车主俱乐部比利时</a>，CC由2.0许可][奥巴马视频来源于<a class="ae ky" href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/" rel="noopener ugc nofollow" target="_blank"> VoxCeleb数据集</a>，CC由4.0]</p></figure><h1 id="c0a9" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">目录</h1><ol class=""><li id="36fa" class="mz na it lb b lc nb lf nc li nd lm ne lq nf lu ng nh ni nj bi translated">开始</li><li id="b225" class="mz na it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">StyleGAN</li><li id="23bc" class="mz na it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">图层交换的意义</li><li id="e329" class="mz na it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">用一阶运动制作动画</li><li id="deda" class="mz na it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">辅导的</li></ol><p id="9b0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您不想学习理论并直接学习编码，您可以跳到教程。</p><h1 id="ff68" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">生成对抗网络</h1><p id="1d29" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">这种角色生成背后的核心机制是一个称为生成性对抗网络(GAN)的概念，由于其生成性应用，该概念目前在社区中非常流行。甘是什么？这基本上是两个网络试图相互竞争，发电机和鉴别器。生成器试图欺骗鉴别器，使其相信其生成的图像是真实的，而鉴别器试图在真实图像和假(生成的)图像之间进行分类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/b092b12e193cd0355b4c7df1a6733e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x8SNjKu3-EBT-AQp.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">甘建筑<a class="ae ky" rel="noopener" target="_blank" href="/generating-anime-characters-with-stylegan2-6f8ae59e237b">【来源:作者用StyleGAN2生成动漫人物】</a></p></figure><p id="9643" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先通过向鉴别器显示来自数据集的真实图像和随机噪声(来自未训练的生成器的图像)来训练鉴别器。由于数据分布非常不同，鉴别器将能够容易地进行区分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/e0ec06d7c7ee075a4106e696db2f3de3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sfndp7Mh_c9TbuhTdu-gXg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">初始鉴别器训练[图片由作者提供][面部图像由<a class="ae ky" href="https://thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">thispersondoesnotexist.com</a>生成]</p></figure><p id="701a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nu">免责声明:由于我试图尽可能简化，该图可能无法准确反映GAN的情况。</em></p><p id="15a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将切换到训练发电机，同时冻结鉴别器。生成器将学习如何基于鉴别器的输出(真的或假的)生成更好的图像，直到鉴别器不能再正确鉴别为止。然后，我们切换回训练鉴别器，循环继续，两者都变得更好，直到生成器达到生成非常真实的图像的点，您可以停止训练。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/2e80cce1cacd4559dc36c03fb7f6ed1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u9TVfRvctGZgDkROgKvvVg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GAN培训概述。生成器将学习生成更好的图像，鉴别器将学习更好地分类，因为假图像开始看起来非常相似。最终，它会达到一个点，图像非常相似，而鉴别器只有一半的时间是正确的。[图片由作者提供][面部图片由<a class="ae ky" href="https://thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">thispersondoesnotexist.com</a>生成]</p></figure><h1 id="9a08" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">StyleGAN</h1><p id="2c7b" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">2018年，NVIDIA发表了一篇突破性的论文，该论文管理生成高质量的图像(1024x1024)，题为<a class="ae ky" href="https://arxiv.org/pdf/1812.04948.pdf" rel="noopener ugc nofollow" target="_blank">“基于风格的生成式对抗性网络生成器架构”</a>。其中一个新颖之处是，它解开了潜在的空间，使我们能够在不同的水平上控制属性。例如，较低层将能够控制姿势和头部形状，而较高层控制诸如照明或纹理的高级特征。</p><p id="c4f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过引入额外的映射网络来完成解缠结，该映射网络将输入<strong class="lb iu"><em class="nu"/></strong>(从正态分布采样的噪声/随机向量)映射到分离的向量<strong class="lb iu"> <em class="nu"> w </em> </strong>并将其馈送到层的不同级别。因此，z输入的每个部分控制不同级别的特征</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/377d0d2305c35fa61c337aab225876b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LiapTsrqMh6ZWeXh.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">StyleGAN生成器架构<a class="ae ky" rel="noopener" target="_blank" href="/generating-anime-characters-with-stylegan2-6f8ae59e237b">【来源:作者用StyleGAN2生成动漫角色】</a></p></figure><p id="3164" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，如果我们改变较低层(4x4，8x8)的输入，我们将会有高级特征的变化，例如头型、发型和姿势。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/6a19abc6128b2962f2759be884ea972e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eDxrKvi8mgkcrEk2.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">粗糙层次细节的变化(头型、发型、姿势、眼镜)[来源:<br/> <a class="ae ky" href="https://arxiv.org/pdf/1912.04958.pdf" rel="noopener ugc nofollow" target="_blank">分析和改善StyleGAN的图像质量</a></p></figure><p id="b171" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，如果您更改较高层(512x512，1024x1024)的输入，我们将在更精细的功能方面有所变化，如照明、肤色和头发颜色。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/f2509bcd401c217faa43e3e084b9a1f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hdRS8wWRg7g5g3fW.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">精细层次细节(头发颜色)的变化【来源:<br/> <a class="ae ky" href="https://arxiv.org/pdf/1912.04958.pdf" rel="noopener ugc nofollow" target="_blank">分析和改善StyleGAN的图像质量</a></p></figure><p id="4577" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以尝试通过分析激活图来进一步可视化解缠结，并像本文所做的那样对激活进行聚类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/14062895eb174b53c3e49af7ed00ebc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*gL7_JDI-cXU9CSEoevoZSg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用球形K-均值聚类的StyleGAN2层分析显示了StyleGAN语义的解开。每种颜色代表一个不同的集群[ <a class="ae ky" href="https://arxiv.org/pdf/2004.14367.pdf" rel="noopener ugc nofollow" target="_blank">来源:时尚编辑:揭示甘斯</a>的地方语义</p></figure><p id="7d48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">颜色代表一个集群，你可以把它看作是图像的可控部分。在最后一层，你可以看到照明的不同部分表现为不同的集群。在中间层中，诸如眼睛、鼻子或嘴的面部特征被表示为不同的聚类，这意味着这是面部特征的变化被控制的地方。最后，在前几层中，头部的不同部分被表示为不同的簇，这证明它控制着人的形状、姿势和发型。</p><p id="a6ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里观看这篇论文的演示视频。</p><div class="oa ob gp gr oc od"><a href="https://crossminds.ai/video/5f6e7419d81cf36f1a8e31e0/" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">时尚编辑:揭示GANs - Crossminds的本地语义</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">作者:Edo Collins，Raja Bala，Bob Price，Sabine Süsstrunk描述:虽然GAN图像合成的质量已经…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">crossminds.ai</p></div></div><div class="om l"><div class="on l oo op oq om or ks od"/></div></div></a></div><p id="c922" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了解开，StyleGAN还做了其他几个改进，如渐进增长架构。虽然他们在StyleGAN2中换成了类似<a class="ae ky" href="https://arxiv.org/abs/1903.06048" rel="noopener ugc nofollow" target="_blank"> MSG-GAN </a>的架构。关于最新的更新，你可以阅读这篇文章或者观看下面的StyleGAN2演示视频。</p><div class="oa ob gp gr oc od"><a href="https://crossminds.ai/video/5f6e71a6d81cf36f1a8e30ee/" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">StyleGAN - Crossminds图像质量的分析与改进</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">作者:Tero Karras，Samuli Laine，Miika Aittala，Janne Hellsten，Jaakko Lehtinen，Timo Aila</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">crossminds.ai</p></div></div><div class="om l"><div class="os l oo op oq om or ks od"/></div></div></a></div><p id="9dcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我也用这个网站来跟踪今年关于CVPR和ECCV的新论文。所以，还是挺有用的。</p><h1 id="1f4e" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">StyleGAN网络混合</h1><p id="72fa" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">StyleGAN独特的“解开缠绕”功能使我们能够混合不同的模型，并从一张脸上生成迪士尼角色。如果前几层控制面部特征，最后几层控制纹理，<strong class="lb iu">如果我们把最后几层和另一个模特的层互换会怎么样？</strong></p><p id="6371" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果我们将人脸模型的权重用于前几层，将绘画模型的权重用于层的其余部分，它将生成具有绘画风格的人脸！此外，它不仅可以复制第二个模型的纹理，而且还可以复制不同模型的面部特征风格，如迪士尼人物的眼睛或嘴巴。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/ace7e987687a3ee3b7974bdcf7d8a5dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RjkiuhZQ_QUBhNRGA4029A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">FFHQ模型和MetFaces模型在各层和16x16层的网络融合[图像由作者生成][使用的人脸是生成的，人不存在]</p></figure><h1 id="2b77" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">一阶运动模型</h1><p id="8714" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">在我们创造了迪斯尼角色之后，为什么不把它带到另一个层次，并制作出动画呢？一篇名为<a class="ae ky" href="https://arxiv.org/abs/2003.00196" rel="noopener ugc nofollow" target="_blank">“图像动画的一阶运动模型”</a>的有趣论文为我们提供了这样的能力。基本上，它试图使用关键点从驾驶视频中学习运动，并试图变形输入图像来实现运动。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/9a2bd8ef5ac2fc633b85cd9e4ef35905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2mb8ABL9PdZZkv6QJGdtFA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一阶运动模型概述[ <a class="ae ky" href="https://github.com/AliaksandrSiarohin/first-order-model" rel="noopener ugc nofollow" target="_blank">来源:图像动画一阶运动模型，CC BY 4.0] </a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/bcfd80fc6a336aa34f5d79ed8d06941a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SldcX9mk0y9QbXKw"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">时装模特的一阶运动模型。请注意，它能够制作模型背面的动画。【<a class="ae ky" href="https://github.com/AliaksandrSiarohin/first-order-model" rel="noopener ugc nofollow" target="_blank">来源:图像动画一阶运动模型，CC BY 4.0】</a></p></figure><h1 id="5bba" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">辅导的</h1><p id="efe1" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">现在我们已经对这个概念有了一点了解，让我们开始写代码吧！幸运的是，贾斯汀·平克尼提供了他的卡通化模型，并为它创建了一个实验室。我做了另一个Colab笔记本，基本上是他的代码，并添加了从Aliaksandr Siarohin的笔记本修改而来的动画代码。</p><p id="1f6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有<a class="ae ky" href="https://colab.research.google.com/drive/1er1ZA4xvDKmy0PkPaNM0_oWppAblB9xy?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>供你跟随！</p><p id="e3c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，确保你用的是GPU运行时和Tensorflow 1。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="9d1b" class="pb mi it ox b gy pc pd l pe pf">%tensorflow_version 1.x</span></pre><p id="d27a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="nu">注意:</em> </strong> <em class="nu"> %</em></p><p id="0b7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们克隆回购并创建我们将使用的文件夹。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="5c42" class="pb mi it ox b gy pc pd l pe pf">!git clone <a class="ae ky" href="https://github.com/justinpinkney/stylegan2" rel="noopener ugc nofollow" target="_blank">https://github.com/justinpinkney/stylegan2</a><br/>%cd stylegan2<br/>!nvcc test_nvcc.cu -o test_nvcc -run<br/>!mkdir raw<br/>!mkdir aligned<br/>!mkdir generate</span></pre><p id="4965" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="nu">注:</em> </strong> <em class="nu">'！'用于在Colab中运行shell命令，如果您在本地执行此操作，只需在您的shell/控制台上运行该命令。</em></p><p id="5ced" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，上传你的图像到raw文件夹，我们将使用一个脚本来裁剪面部和调整图像的大小，因此你的图像不必是全脸。但为了获得更好的效果，请确保您的面部分辨率至少为256x256。</p><p id="e672" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个例子中，我们将使用Elon Musk图像作为例子。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="641e" class="pb mi it ox b gy pc pd l pe pf">!wget <a class="ae ky" href="https://drive.google.com/uc?id=1ZwjotR2QWSS8jaJ12Xj00tXfM0V_nD3c" rel="noopener ugc nofollow" target="_blank">https://drive.google.com/uc?id=1ZwjotR2QWSS8jaJ12Xj00tXfM0V_nD3c</a> -O raw/example.jpg</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/473945960e0fe99a6535b327700a92e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*DsJlUzdMDG0BeFhlBpP77A.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">埃隆·马斯克图片【来源:Flickr by <a class="ae ky" href="https://www.flickr.com/photos/teslaclubbe/12271223586/in/photolist-jGnefs-7B4UpY-9BSeXs-haF167-eX9YxQ-ozwwpo-d83K9o-bXaJjZ-eyW9oB-fr8vN5-fqTf5g-7TXJEu-7B1dzT-nVS8fa-gjVgTf-haETfc-anD1Gd-ccdkPb-e2rcqL-5ubGnz-z4XLj7-rRMLTf-4t8UwZ-oNtTSq-jGn7AL-DYXSbK-emx5tu-526A61-rdqdcL-52281c-dYpvQE-cex63W-cex65f-ftXbTC-feq9zf-rocWAZ-feq9zL-BcRSGv-8NFnMJ-GvCak7-vWRj6g-AWqF3z-uMdB5p-vDTKwn-GVHFMa-gm9SkQ-tuWDGY-sAgpsJ-92iXxj-bnvZh" rel="noopener ugc nofollow" target="_blank">特斯拉车主俱乐部比利时</a>，CC BY 2.0】</p></figure><p id="82cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将加载由多伦的阿德勒和正常的FFHQ人脸模型的真实人脸和迪士尼人物的混合模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="8a8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为什么我们还需要加载正常的真实人脸(FFHQ)模型？请记住，StyleGAN模型仅采用潜在向量z，并基于潜在向量生成人脸。它不像图像到图像转换模型那样获取图像并转换图像。</p><p id="6a89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么我们如何生成一张我们想要的脸呢？StyleGAN2介绍了一种投射到潜在空间的方法。基本上，我们可以尝试使用梯度下降为我们想要的图像找到匹配的潜在向量。</p><p id="80c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但在我们试图找到匹配的潜在向量之前，我们需要首先裁剪和对齐图像。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="1cfd" class="pb mi it ox b gy pc pd l pe pf">!python align_images.py raw aligned</span></pre><p id="c275" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该脚本将源图像目录和输出目录作为输入，并将正确地裁剪和对齐我们的脸。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/408827c7aec309ed4004f5e7ab82c4da.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*9r7Rn4lFyj9lj9wWFDYmrA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">被裁剪和对齐的脸[来源:Flickr，作者:<a class="ae ky" href="https://www.flickr.com/photos/teslaclubbe/12271223586/in/photolist-jGnefs-7B4UpY-9BSeXs-haF167-eX9YxQ-ozwwpo-d83K9o-bXaJjZ-eyW9oB-fr8vN5-fqTf5g-7TXJEu-7B1dzT-nVS8fa-gjVgTf-haETfc-anD1Gd-ccdkPb-e2rcqL-5ubGnz-z4XLj7-rRMLTf-4t8UwZ-oNtTSq-jGn7AL-DYXSbK-emx5tu-526A61-rdqdcL-52281c-dYpvQE-cex63W-cex65f-ftXbTC-feq9zf-rocWAZ-feq9zL-BcRSGv-8NFnMJ-GvCak7-vWRj6g-AWqF3z-uMdB5p-vDTKwn-GVHFMa-gm9SkQ-tuWDGY-sAgpsJ-92iXxj-bnvZh" rel="noopener ugc nofollow" target="_blank">比利时特斯拉车主俱乐部</a></p></figure><p id="3e60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们将图像投影到潜在空间。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="ac33" class="pb mi it ox b gy pc pd l pe pf">!python project_images.py --num-steps 500 aligned generated</span></pre><p id="6b59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该脚本将获取<code class="fe pk pl pm ox b">aligned</code>目录中的图像，并在<code class="fe pk pl pm ox b">generated</code>文件夹中创建保存为<code class="fe pk pl pm ox b">.npy</code>文件的潜在向量。</p><p id="d824" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有了潜在向量，我们可以尝试使用我们的混合迪士尼模型来生成人脸。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="ecd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">生成的图像保存在<code class="fe pk pl pm ox b">generated</code>文件夹中。我们可以显示笔记本里面的图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/c62f6415d5b7dfa00923a56cfae39f5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*Y6RyQXjp51Qx3oEBhQh7uQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">埃隆·马斯克卡通化[图片由作者生成]</p></figure><p id="7335" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">瞧啊。我们有一个迪士尼化的埃隆·马斯克，但我们还没有完成。让我们来制作动画吧！</p><p id="19ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们在一阶模型上克隆Aliaksanr的回购。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="9cdb" class="pb mi it ox b gy pc pd l pe pf">!git clone https://github.com/AliaksandrSiarohin/first-order-model</span></pre><p id="b607" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将设置一个路径，这样我们就不必在一阶模型目录下进行python导入，或者你可以直接<code class="fe pk pl pm ox b">cd</code>到这个目录。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="7552" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，在加载关键点和视频生成器模型之前，我们需要先下载预先训练好的权重。该文件相当大~700 MB，您可能需要手动下载，因为Google不允许使用wget下载大文件。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="cede" class="pb mi it ox b gy pc pd l pe pf">!wget "https://drive.google.com/uc?export=download&amp;id=1jmcn19-c3p8mf39aYNXUhdMqzqDYZhQ_" -O vox-cpk.pth.tar</span></pre><p id="53ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用刚才下载的重量加载一阶模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="79c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们需要一个驾驶视频，我们将从那里获得动画。您可以使用示例视频或上传自己的视频。如果您上传视频，请确保相应地更改文件路径。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="9db0" class="pb mi it ox b gy pc pd l pe pf">!wget https://drive.google.com/uc?id=1LjDoFmeP0hZQSsUmnou0UbQJJzQ8rMLR -O src_video.mp4</span></pre><p id="8c2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们可以生成动画！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/f563ced3c8f7624d65b01e1154d8f9c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/1*APln77th8NVGRQ1cM-mYYQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[作者生成的图像][来自<a class="ae ky" href="http://www.robots.ox.ac.uk/~vgg/data/voxceleb/" rel="noopener ugc nofollow" target="_blank"> VoxCeleb数据集的中间视频] </a></p></figure><p id="35c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">耶！我们终于让我们的角色有了生气。祝贺你，如果你设法达到这一点🎉</p><h1 id="bdc6" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">下一步是什么？</h1><p id="b083" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">我们还有很多东西可以做实验。如果我们混合其他模型，如绘画的模型，或者我们也可以反向混合迪士尼人物和绘画，我们基于迪士尼人物或绘画生成一个真实的脸。我们也可以尝试加入Deepfake，用我们的迪士尼角色替换迪士尼电影中的面孔。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/c0ce12b46135e0b1a727cf67a0f1a4b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/1*D_KkWHz6crYDu7kM26-XIw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">涂脂抹粉的脸的动画【图片由作者生成】【名人图片来源于CC许可下的维基百科图片:<a class="ae ky" href="https://en.wikipedia.org/wiki/Scarlett_Johansson#/media/File:Goldene_Kamera_2012_-_Scarlett_Johansson_3_(cropped).JPG" rel="noopener ugc nofollow" target="_blank"> Scarlet J. </a>，<a class="ae ky" href="https://en.wikipedia.org/wiki/Sherlock_(TV_series)#/media/File:Benedict_Cumberbatch_filming_Sherlock_cropped2.jpg" rel="noopener ugc nofollow" target="_blank"> Benedict C </a>。，<a class="ae ky" href="https://en.wikipedia.org/wiki/Will_Smith#/media/File:TechCrunch_Disrupt_2019_(48834434641)_(cropped).jpg" rel="noopener ugc nofollow" target="_blank">将S </a>。，<a class="ae ky" href="https://en.wikipedia.org/wiki/Emma_Watson#/media/File:Emma_Watson_2013.jpg" rel="noopener ugc nofollow" target="_blank">艾玛W. </a>，<a class="ae ky" href="https://en.wikipedia.org/wiki/Elon_Musk#/media/File:Elon_Musk_Royal_Society.jpg" rel="noopener ugc nofollow" target="_blank">埃隆M. </a> ]</p></figure></div><div class="ab cl pq pr hx ps" role="separator"><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv"/></div><div class="im in io ip iq"><p id="0b36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢我的作品，看看我的其他文章！</p><div class="oa ob gp gr oc od"><a rel="noopener follow" target="_blank" href="/generating-anime-characters-with-stylegan2-6f8ae59e237b"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">使用StyleGAN2生成动画角色</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">了解如何生成这个很酷的动画人脸插值</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">towardsdatascience.com</p></div></div><div class="om l"><div class="px l oo op oq om or ks od"/></div></div></a></div><div class="oa ob gp gr oc od"><a rel="noopener follow" target="_blank" href="/how-to-train-stylegan2-ada-with-custom-dataset-dc268ff70544"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">如何使用自定义数据集训练StyleGAN2-ADA</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">了解如何训练人工智能生成您想要的图像</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">towardsdatascience.com</p></div></div><div class="om l"><div class="py l oo op oq om or ks od"/></div></div></a></div><p id="7469" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也可以在Linkedin上和我联系。</p><div class="oa ob gp gr oc od"><a href="https://www.linkedin.com/in/mfathyrashad/" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">Muhammad Fathy Rashad -计算机视觉和深度学习R &amp; D实习生- ViTrox公司…</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">在我16岁的时候，我以最年轻的学生的身份开始了我的学业，并出版了2款总安装量超过1.5K的手机游戏…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">www.linkedin.com</p></div></div><div class="om l"><div class="pz l oo op oq om or ks od"/></div></div></a></div><h1 id="ed64" class="mh mi it bd mj mk ml mm mn mo mp mq mr jz ms ka mt kc mu kd mv kf mw kg mx my bi translated">参考</h1><p id="487e" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">[1]t .卡拉斯、s .莱恩和t .艾拉(2019年)。一种基于风格的生成对抗网络生成器体系结构。在<em class="nu">IEEE计算机视觉和模式识别会议论文集</em>(第4401–4410页)。</p><p id="9198" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]t . Karras，Laine，s .，Aittala，m .，Hellsten，j .，Lehtinen，j .，&amp; Aila，T. (2020年)。stylegan图像质量的分析与改进。在<em class="nu">IEEE/CVF计算机视觉和模式识别会议论文集</em>(第8110–8119页)。</p><p id="9fce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3]Siarohin，a .，Lathuilière，s .，Tulyakov，s .，Ricci，e .，&amp; Sebe，N. (2019年)。图像动画的一阶运动模型。在<em class="nu">神经信息处理系统的进展</em>(第7137-7147页)。</p><p id="b37c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4]柯林斯，e .，巴拉，r .，普莱斯，b .，&amp; Susstrunk，S. (2020年)。风格编辑:揭示GANs的本地语义。在<em class="nu">IEEE/CVF计算机视觉和模式识别会议论文集</em>(第5771–5780页)。</p><p id="e12c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.justinpinkney.com/stylegan-network-blending/" rel="noopener ugc nofollow" target="_blank">https://www.justinpinkney.com/stylegan-network-blending/</a></p></div></div>    
</body>
</html>