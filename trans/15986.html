<html>
<head>
<title>Definitive Guide of Activations in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中激活的权威指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/manual-of-activations-in-deep-learning-30658167ffcb?source=collection_archive---------41-----------------------#2020-11-03">https://towardsdatascience.com/manual-of-activations-in-deep-learning-30658167ffcb?source=collection_archive---------41-----------------------#2020-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="44ab" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">列出你需要的所有激活功能</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/637147c96188ea17495eda2e1f4635aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/0*UiUIW1ZEYjrDV_-n.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="f2dd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于任何机器学习模型，最关键的决定之一是选择使用哪种激活。让我们来看看你想知道的所有激活功能。这个列表的顺序正在被越来越多地使用。</p><h1 id="1656" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">索引</h1><p id="5e64" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">如果你想直接进入其中，这里有一个快速列表。</p><ol class=""><li id="8e6d" class="mk ml iq kt b ku kv kx ky la mm le mn li mo lm mp mq mr ms bi translated">恒等函数和二元步长</li><li id="763c" class="mk ml iq kt b ku mt kx mu la mv le mw li mx lm mp mq mr ms bi translated">乙状结肠的</li><li id="12ce" class="mk ml iq kt b ku mt kx mu la mv le mw li mx lm mp mq mr ms bi translated">Softmax</li><li id="ffe7" class="mk ml iq kt b ku mt kx mu la mv le mw li mx lm mp mq mr ms bi translated">双曲正切值</li><li id="714e" class="mk ml iq kt b ku mt kx mu la mv le mw li mx lm mp mq mr ms bi translated">SoftPlus</li><li id="3eb9" class="mk ml iq kt b ku mt kx mu la mv le mw li mx lm mp mq mr ms bi translated">指数线性单位(ELU)及其缩放版本，SELU</li><li id="756b" class="mk ml iq kt b ku mt kx mu la mv le mw li mx lm mp mq mr ms bi translated">整流线性单位(ReLU)及其变体。</li></ol><p id="cabf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">有这么多要讲的，我们现在就开始吧。</p><h1 id="71c0" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">恒等函数和二元步长</h1><p id="12c3" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated"><strong class="kt ir"> <em class="my">恒等函数</em> </strong>实际上是将输入作为输出返回的函数。因此，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/526d49e030c94305d336523c1eca4dba.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*NGuvOEeDIkUMPtGH0PimPQ@2x.png"/></div></figure><p id="3fa4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个函数最近很少被使用，而且你是否想要使用它也是非常值得怀疑的。</p><p id="75ca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">恒等函数的图形简单如下。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/a8b422aeddaa5da0a3a5e6a83798a7b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*69D5XzO1vDqXO_0FNSJ_bg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="0912" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="my">二进制步骤</em> </strong>函数如果数字为正数则返回1，否则返回0。这是一个很少使用的功能。因此，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/52f401374898057a6fb6be272d8a95cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*WUZMqUehHr7zgOEWGDuemA@2x.png"/></div></figure><p id="1328" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">图表如下图所示，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/307998c76113bf1cb71e281acc929384.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*HYqysPkvVq2t1LJu35Ow5Q.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><h1 id="afdf" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">Sigmoid函数</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/a3698844bc3f72f4e84c5cc95431e57a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*FlFuf0m2s540cIIbt01xFA.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="c3d1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个函数以前是所有机器学习中使用最多的。该函数将一个数字映射到1和0之间，图形如下图所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/f59e96380d8f46a20a0628cde30c57b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*FNOoBeDxEbiUVYHuBx5o7g@2x.png"/></div></figure><p id="c2b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"><em class="my">sigmoid函数现在仅限于逻辑回归和神经网络的二进制分类问题的输出节点(输出0或1)，尽管早期它也用于隐藏单元。</em>T11】</strong></p><h1 id="8fb1" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">Softmax函数</h1><p id="8a67" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">softmax函数将一和概率应用于向量的各个分量。数学上，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/28894e8087b512c81bdd425cd2304c79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*AMXeHexhP2F9eOfs4gRgOQ@2x.png"/></div></figure><p id="c300" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，它也被称为标准化指数运算。</p><p id="070b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">单独地，应用下面的指数图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/4a9034f0f7464efcf96daa077a7e2f36.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*C8WjBKIhTIkrKHmZRpV4Iw.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="aa26" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="my">应用于多类分类问题的神经网络输出节点。</em>T15】</strong></p><h1 id="aee5" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">双曲正切</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/be4a606e86f3f8f7005872d3b2f43d09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*erkNfDQg_2erb2Qbdtj14w.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="f141" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">双曲正切函数是sigmoid的后继者，因为它在神经网络的隐藏层中始终给出更好的性能。您可能会观察到，双曲正切图与sigmoid非常相似，只是它稳定在-1和1，并以0为中心。</p><p id="c850" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">数学上它是双曲正弦和余弦的比值，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/a80f088768be6832ea702022fa829cad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*fsjFJpg8qz3fB4_zsHKRGQ@2x.png"/></div></figure><p id="769b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="my">如今，双曲正切函数也很少用于隐藏层，尽管一些特定的模型也使用双曲正切函数。range -1和1的输出需求的一些问题在输出节点使用tanh。</em>T19】</strong></p><h1 id="a85c" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">SoftPlus功能</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/ae91a77730ff57cd270b3599c4da4cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*rqVo-PGMRWpDu9-gS6piXg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="af1b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">SoftPlus函数是ReLU的更软或更平滑的版本，您将在后面看到。<br/>数学上，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/f3d4beabf857e9c350d5d020183dd579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*HQUhCzzi9R2fk1-wM5uzHw@2x.png"/></div></figure><p id="a643" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="my">当ReLU给出零梯度时，SoftPlus允许平滑梯度。因此，在这种情况下，您可以使用SoftPlus而不是ReLU。应当注意，SoftPlus函数在计算上要昂贵得多。</em>T3】</strong></p><h1 id="887b" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">指数线性单位</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/e776dd92c1dfcb97062b2dcbc9d22e01.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*Qwawo64o_-kMkm3avV2JfA.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="d6f6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">ELU或指数线性单位是一个新的和高精度的在隐藏层中被广泛使用的激活函数。它是一个<em class="my">参数化</em>函数，即它有一个参数(技术上是一个超参数或可调参数)称为α，符号为α。如果是正数，ELU返回数字本身，并给出alpha乘以<em class="my">输入的幂减1。</em></p><p id="ea4c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">数学上，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/bebcb03c8f9c8e346e7ded1152d0adc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*c4eg5IFoReVKOxawIoKpBQ@2x.png"/></div></figure><p id="3640" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="my">其中α通常是一个介于0.1和0.3之间的数字</em></p><p id="b14f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"><em class="my">ELU比ReLU有潜力获得更好的精度。然而，它的计算量更大。</em>T13】</strong></p><h1 id="37fa" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">标度指数线性单位</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/ef0cb52db9a880d7d81bfe0ddfd93ab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*bTFpv-1eIQgbVhfudroA4A.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="1965" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">SELU或按比例缩放的指数线性单位是对ELU的修改，可更好地帮助提高精度和归一化。增加一个额外的超参数λ，符号为λ。SELU被给定为，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/e84ad72a22a4ccc71c817ece9112f8bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*zWt3eBJX28d__LhPUBKH0w@2x.png"/></div></figure><p id="22ed" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="my">值为α = 1.67326，λ = 1.0507 </em></p><p id="5c29" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"><em class="my">SELU比ELU工作得更好，但是由于另一个增加的乘法，它在计算上更加昂贵。</em>T19】</strong></p><h1 id="9f59" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">整流线性单元</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/605017aa567819ee4a0c2c1a0ccc411c.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*BYgOD37LncysL7PYo1l5-A.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="bccb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现今最常用的激活函数之一是整流线性单元或ReLU函数。让它如此吸引人的是它的简单性和有效性。该函数通过使负值为零来消除负值。它保留实际输入的值。</p><p id="cce9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">数学上，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/a591a55ab02c92d8376d462d27e71569.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*uykVlww59TJkqrqIK89P2Q@2x.png"/></div></figure><p id="be73" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="my">尽管ReLU的性能不如eLU、SELU或其变体，但它的计算效率很高，因此是最常用的激活函数。</em></p><h1 id="2633" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">泄漏ReLU</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/27de5af6d1cabfeb784f5bd84a90a4a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*3xkoCOVk5jBMwD5o7q6I-Q.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者图片</p></figure><p id="cfd6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">ReLU激活功能具有使负梯度归零的不期望的属性<em class="my">，这导致了被称为死亡ReLU </em>的问题。为了解决这个问题，泄漏ReLU或LReLU通过将负值乘以值0.01来减小负值。</p><p id="c8d5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">数学上，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi np"><img src="../Images/8e0cd92febd7790bce7c8b2298be8732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gSvkaTtFdied5K0sNHMNDw@2x.png"/></div></div></figure><p id="6884" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="my">虽然泄漏ReLU通常能找到更好的最优解，但它的计算开销更大，因此需要更多的时间。因此，它较少用于以速度为更重要标准且计算资源较少的任务。</em> </strong></p><h1 id="f953" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">参数化ReLU</h1><p id="b425" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">PReLU或参数化ReLU将泄漏ReLU中的系数x变成一个参数，而不是一个固定的数字，可以通过反向传播来学习。这个用符号<em class="my"> α </em>写成<em class="my">α</em>。当配制时，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/5b73c754411b512d7bcec7b125e3796d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*vxl3BIApdC8oZPvgblJ8mw@2x.png"/></div></figure><p id="fb95" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">PReLU通常会找到比ReLU或Leaky ReLU更好的最优解，但会花费更多的历元和时间。因为它有一个额外的参数α，所以计算量很大。T3】</p><h1 id="ab84" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">s形ReLU</h1><p id="4784" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">SReLU或S形ReLU可以学习<em class="my">凹凸函数。</em>具体来说，它由三个分段线性函数组成，由四个可学习的参数表示。</p><blockquote class="nv nw nx"><p id="ce93" class="kr ks my kt b ku kv jr kw kx ky ju kz ny lb lc ld nz lf lg lh oa lj lk ll lm ij bi translated">SReLU是一个复杂的函数，因此它可以学习复杂性。</p></blockquote><p id="6c06" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">SReLU被表述为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/0586ed55226bac219ec193f7010eee00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*npgCWhLj0C1A83tW_D3geA@2x.png"/></div></figure><p id="583e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">SReLU是这个激活列表中计算开销最大的函数。这也是名单上最好的激活准确度之一。当计算资源高时，可以使用SReLU。T9】</p><h1 id="8586" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">正弦关系</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi oc"><img src="../Images/a4ba40e01406473e1d141d540faa2d32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*73urr35hbdHrwnMq.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><a class="ae od" href="https://medium.com/@wilder.rodrigues/sinerelu-an-alternative-to-the-relu-activation-function-e46a6199997d" rel="noopener">中等文章</a></p></figure><p id="da53" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Sine ReLU可能是列表中最新的函数。这是怀尔德·罗德里格斯发明的。要了解这个功能，可以看<a class="ae od" href="https://medium.com/@wilder.rodrigues/sinerelu-an-alternative-to-the-relu-activation-function-e46a6199997d" rel="noopener">中文</a>。效果很好，值得一试。其公式为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi oe"><img src="../Images/8d5b570681c8295a5460b58e70226fb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ntVe1yl8FKxdLZpndRZERA@2x.png"/></div></div></figure><p id="a555" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">提到的ε可以携带0.0025的基值，尽管他对密集层使用0.25。</p><p id="3154" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我看来，SineReLU在某些数据集上可以得到比以前所有函数更好的结果。这是你可以尝试的另一个功能。此外，它在计算上比Leaky-ReLU和ReLU更昂贵，尽管它可以胜过它们。 </p><h1 id="b4f4" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结论</h1><p id="5c01" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">选择太多了！选择哪一个最终取决于您，并且它的有效性也会随着您的应用程序而变化，所以请测试它们！随着经验的积累，你可能会对使用什么功能有一些直觉</p><p id="632e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我真的希望这对你有所帮助。如果你有任何建议，请在评论中给出反馈。</p><p id="448e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="my">注:所有LateX方程式图片均由作者提供</em></p></div></div>    
</body>
</html>