<html>
<head>
<title>Emulating a PID Controller with Long Short-term Memory: Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模拟具有长短期记忆的PID控制器:第2部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/emulating-a-pid-controller-with-long-short-term-memory-part-2-4a37d32e5b47?source=collection_archive---------22-----------------------#2020-10-16">https://towardsdatascience.com/emulating-a-pid-controller-with-long-short-term-memory-part-2-4a37d32e5b47?source=collection_archive---------22-----------------------#2020-10-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b53b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用温度控制实验室在Keras中训练长短期记忆神经网络以仿真PID控制器</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d98ab8fe28fee0225414a5881800db70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vdUQmHCpBWazPYiQ"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@ivorycirrus?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">皮尔莫·康</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="c831" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">欢迎来到这个激动人心的项目的第2部分！到目前为止，结果看起来很好，现在我们可以进入我们试图完成的内容了:用LSTM模拟PID控制器的行为。简要回顾一下，以下是我们到目前为止所探索的内容以及我们的发展方向:</p><ol class=""><li id="ea9f" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/@nrlewis929/emulating-a-pid-controller-with-long-short-term-memory-part-1-bb5b87165b08" rel="noopener">使用温度控制实验室创建比例积分微分控制器数据</a></li><li id="7132" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在Keras中训练一个长短期记忆神经网络来模拟PID控制器(本文)</li><li id="49d5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://nrlewis929.medium.com/emulating-a-pid-controller-with-long-short-term-memory-part-3-23da7df3e033" rel="noopener">用LSTM控制温控实验室</a></li><li id="fb11" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://nrlewis929.medium.com/emulating-a-pid-controller-with-long-short-term-memory-part-4-19ab327be61b" rel="noopener">用LSTM控制器代替PID控制器进行温度控制的实际应用</a></li></ol><p id="c004" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想自己运行这段代码，可以在<a class="ae ky" href="https://github.com/nrlewis929/TCLab_emulate_PID" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。它严重依赖于在您的计算机上使用TCLab设备，但最终我计划生成数据并添加一些笔记本，这样您也可以作为一个独立的项目来运行它。当然，我总是鼓励你看看你能从中吸取什么原则，并把它们应用到你自己的项目中。</p><h1 id="98f4" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">用LSTM模拟PID行为</h1><p id="6f4d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">完成<a class="ae ky" rel="noopener" target="_blank" href="/emulating-a-pid-controller-with-long-short-term-memory-part-1-bb5b87165b08">最后一段</a>后，我们有一些数据要处理，我们想看看LSTM是否能模拟PID控制器的行为。有一些关于LSTMs如何工作的优秀文章，所以如果您以前没有使用过它们，我会向您推荐这些文章。<a class="ae ky" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">这里</a>是我在研究它们背后的一些数学知识时去的地方之一，而<a class="ae ky" rel="noopener" target="_blank" href="/recurrent-neural-networks-by-example-in-python-ffd204f99470">这篇</a>是一篇关于数据科学的精彩文章，向我介绍了它们是如何用Python和Keras实现的。<a class="ae ky" rel="noopener" target="_blank" href="/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21">这里有</a>另一个有视频的很棒的教程。像往常一样，<a class="ae ky" href="http://apmonitor.com/do/index.php/Main/LSTMNetwork" rel="noopener ugc nofollow" target="_blank">APMonitor.com</a>是所有与机器学习和过程控制相关的丰富资源。</p><p id="99cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">LSTMs由于其多功能性，已经成为所有类型的机器学习模型的流行方法。我在序列预测任务、自然语言处理和异常检测中使用过它们；其他人已经找到了从图像处理到语音识别的应用。它与标准递归神经网络的区别在于其细胞存储单元的存在，这有助于解决<a class="ae ky" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" rel="noopener ugc nofollow" target="_blank">消失梯度问题</a>。</p><p id="b78d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">LSTMs在这类问题上工作得很好，因为我们想记住控制系统中以前发生过什么。如果我们只是将设定点从35°C更改为70°C，我们知道加热器将被置于最大温度一段时间，以达到该设定点。然而，如果我们只是从45°C降至42°C，或者在55°C保持稳定一段时间，控制器将不得不做出不同的解释。</p><p id="c6f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在仿真PID控制器的情况下，我们希望输入一个数据窗口，例如温度、设定点、误差或加热器值，并预测下一个加热器值应该是多少，以达到所需的设定点。这个预测是模拟具有给定调谐常数的PID控制器将会给我们的输出。当然，如果调谐常数改变，我们不再看到相同类型的控制器行为。这是一个有趣的想法，可以在第4部分中探讨。</p><h1 id="180d" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">模型特征和预处理</h1><p id="bfd1" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">第一步是查看哪些特性对输入模型有用。直观地说，PID控制器将传感器温度和设定点之间的误差作为输入，因此我们的LSTM很可能需要这些。Scikit-learn有很多有用的<a class="ae ky" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection" rel="noopener ugc nofollow" target="_blank">特性选择模型</a>来帮助我们理解一些好的输入。让我们使用<code class="fe ng nh ni nj b">SelectKBest</code>方法来缩小我们的选择范围。我们有传感器温度、设定值和加热器输出；我们还将导出误差，并将它们传递给<code class="fe ng nh ni nj b">SelectKBest</code>函数:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="4107" class="no mk it nj b gy np nq l nr ns"># Create new feature: setpoint error<br/>df['err'] = df['Tsp'] - df['T1']</span><span id="1ecc" class="no mk it nj b gy nt nq l nr ns"># Load possible features<br/>X = df[['T1','Tsp','err']]<br/>y = np.ravel(df[['Q1']])</span><span id="8c7c" class="no mk it nj b gy nt nq l nr ns"># SelectKBest feature selection<br/>bestfeatures = SelectKBest(score_func=f_regression, k='all')<br/>fit = bestfeatures.fit(X,y)<br/>plt.bar(x=X.columns,height=fit.scores_)</span></pre><p id="b29b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">绘制结果显示<code class="fe ng nh ni nj b">Tsp</code>(设定点温度)和<code class="fe ng nh ni nj b">err</code>(设定点和传感器之间的误差)是迄今为止最重要的特征，这验证了我们的直觉。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/2c13bd3710c0e2d9e7dad06969e392e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*Tjhlz7botNxNIVy0otfWsA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者的情节</p></figure><p id="b462" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于LSTM，我将使用Keras和Tensorflow后端；我发现这是一种直观有效的建模方式。在构建模型之前，我需要缩放数据并将其格式化为LSTM期望的样子。在这种情况下，我将采用我的<code class="fe ng nh ni nj b">Tsp</code>和<code class="fe ng nh ni nj b">err</code>特征，并以这样一种方式排列它们，即过去的15个时间点作为输入来预测加热器输出<code class="fe ng nh ni nj b">Q1</code>。一定要留出一些数据来测试模型性能。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="5545" class="no mk it nj b gy np nq l nr ns">X = df[['Tsp','err']].values<br/>y = df[['Q1']].values</span><span id="e015" class="no mk it nj b gy nt nq l nr ns"># Scale data<br/>s = MinMaxScaler()<br/>Xs = s.fit_transform(X)</span><span id="1962" class="no mk it nj b gy nt nq l nr ns"># Each input uses last 'window' number of Tsp and err to predict the next Q1<br/>X_lstm = []<br/>y_lstm = []<br/>for i in range(window,len(df)):<br/>    X_lstm.append(Xs[i-window:i])<br/>    y_lstm.append(y[i])</span><span id="211a" class="no mk it nj b gy nt nq l nr ns"># Reshape data to format accepted by LSTM<br/>X_lstm, y_lstm = np.array(X_lstm), np.array(y_lstm)</span><span id="7a2c" class="no mk it nj b gy nt nq l nr ns"># Split into train and test <br/>Xtrain, Xtest, ytrain, ytest = train_test_split(X_lstm,y_lstm,test_size=0.2,shuffle=False)</span></pre><h1 id="3865" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">训练LSTM</h1><p id="7b0c" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们可以查看大量的超参数来优化LSTM与PID控制器的保真度。我通常会使用一个非常有用的Python包，名为<a class="ae ky" href="http://hyperopt.github.io/hyperopt/" rel="noopener ugc nofollow" target="_blank"> Hyperopt </a>来调优这些，尤其是对于一个非常复杂的问题。以下是一些运行良好的超参数:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="0c7d" class="no mk it nj b gy np nq l nr ns">window = 15<br/>layers = 2<br/>batch_size = 100<br/>drop = 0.1<br/>units = 100</span></pre><p id="e85a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们准备构建LSTM模型。有很多关于如何做到这一点的教程，所以我将继续展示代码，然后评论几个亮点。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="49c8" class="no mk it nj b gy np nq l nr ns"># Keras LSTM model<br/>model = Sequential()</span><span id="6054" class="no mk it nj b gy nt nq l nr ns">if layers == 1:<br/>    model.add(LSTM(units=units, <br/>                   input_shape=(Xtrain.shape[1],Xtrain.shape[2])<br/>                  )<br/>             )<br/>    model.add(Dropout(rate=drop))<br/>else:<br/>    # First layer specifies input_shape and returns sequences<br/>    model.add(LSTM(units=units, <br/>                   return_sequences=True, <br/>                   input_shape=(Xtrain.shape[1],Xtrain.shape[2])<br/>                  )<br/>             )<br/>    model.add(Dropout(rate=drop))<br/>    # Middle layers return sequences<br/>    for i in range(layers-2):<br/>        model.add(LSTM(units=units,return_sequences=True))<br/>        model.add(Dropout(rate=drop))<br/>    # Last layer doesn't return anything<br/>    model.add(LSTM(units=units))<br/>    model.add(Dropout(rate=drop))</span><span id="eafd" class="no mk it nj b gy nt nq l nr ns">model.add(Dense(1))<br/>model.compile(optimizer='adam', loss='mean_squared_error')</span><span id="cf2e" class="no mk it nj b gy nt nq l nr ns">es = EarlyStopping(monitor='val_loss',<br/>                   mode='min',<br/>                   verbose=1,<br/>                   patience=25<br/>                  )</span><span id="2fdd" class="no mk it nj b gy nt nq l nr ns">result = model.fit(Xtrain, ytrain, <br/>                   verbose=0, <br/>                   validation_split=0.2,<br/>                   callbacks = [es,TqdmCallback(verbose=1)],<br/>                   batch_size=batch_size,<br/>                   epochs=350)</span><span id="0ed1" class="no mk it nj b gy nt nq l nr ns"># Show results<br/>epochs = es.stopped_epoch<br/>plt.semilogy(result.history['loss'],label='loss')<br/>plt.semilogy(result.history['val_loss'],label='val_loss')<br/>plt.legend();</span></pre><p id="0be1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">构建LSTM和Dropout图层后，我们有一个值为1的<code class="fe ng nh ni nj b">Dense</code>图层，因为模型仅预测1个输出值。我们使用<code class="fe ng nh ni nj b">adam</code>优化器和<code class="fe ng nh ni nj b">mean_squared_error</code>作为损失函数。我喜欢留出一些训练数据来用<code class="fe ng nh ni nj b">validation_split</code>参数进行验证。这使我能够监控一组单独数据的损失，如果我的损失达到稳定状态，就提前停止模型训练(你可以用<code class="fe ng nh ni nj b">patience</code>参数调整它达到稳定状态后等待的时间)，这可以防止模型过度拟合。<code class="fe ng nh ni nj b">TqdmCallback</code>是一个方便的进度条，比起Keras自带的默认进度条，我更喜欢它。最后，最好绘制损失函数，以确保训练损失和验证损失都呈现总体下降趋势。训练LSTM需要一点时间，但我们不会处理大数据集，所以这不是禁止性的。</p><h1 id="948e" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">测试LSTM</h1><p id="fb5a" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在我们使用LSTM控制TCLab之前，我们希望确保它的行为近似于PID控制器的行为。这不仅对于健全性检查很重要，而且也是一个重要的安全问题。你能想象在一个你不确定能否工作的反应器上使用温度控制器吗？如果没有达到预期效果，出现失控反应，可能会造成大混乱。</p><p id="6674" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，我们已经准备了一些样本数据，都是LSTM期望输入的正确格式。我们只需要看到，给定输入，来自LSTM的预测加热器输出与PID控制器将做的一致。请务必撤消数据的缩放，以便我们获得真实值。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="8d23" class="no mk it nj b gy np nq l nr ns"># Predict using LSTM<br/>yp_s = model.predict(Xtest)</span><span id="2d54" class="no mk it nj b gy nt nq l nr ns"># Unscale data<br/>Xtest_us = s_x.inverse_transform(Xtest[:,-1,:])<br/>ytest_us = s_y.inverse_transform(ytest)<br/>yp = s_y.inverse_transform(yp_s)</span><span id="adfa" class="no mk it nj b gy nt nq l nr ns"># Derive Tsp (setpoint) and T1 (sensor) from X data<br/>sp = Xtest_us[:,0]<br/>pv = Xtest_us[:,0] + Xtest_us[:,1]</span></pre><p id="e387" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是我们所看到的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/70e1363674633aac86488c5e3a3c2d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*zoEB8LeXja0hBZUu3EQWnA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者的情节</p></figure><p id="5044" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">太神奇了！您可以看到设定值和T1数据(我们从中得出误差)，以及来自PID控制器的实际数据。绿色显示的是在给定完全相同的输入数据集的情况下，LSTM的表现。看起来它非常逼真地遵循了PID控制器的行为，所以我有信心把它作为代理控制器来试用，只需要一次调整。请注意，LSTM输出有时会超出加热器限定的范围[0，100]。当我们把它作为控制器编码时，我们必须记住裁剪结果。</p><h1 id="e134" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">最后的想法</h1><p id="7c6d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们已经有了一个工作的LSTM模型，下一步是把它编码成控制器。这是一个相当大的项目，所以我们将把它留到本系列的下一篇文章中(2020年10月)。在此之前，请确保保存您的模型和用于预处理的任何参数。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="d381" class="no mk it nj b gy np nq l nr ns"># Save Keras LSTM model<br/>model.save('pid_emulate.h5')</span><span id="f656" class="no mk it nj b gy nt nq l nr ns"># Save preprocessing parameters<br/>model_params = dict()<br/>model_params['Xscale'] = s_x<br/>model_params['yscale'] = s_y<br/>model_params['window'] = window</span><span id="248a" class="no mk it nj b gy nt nq l nr ns">pickle.dump(model_params, open('model_params.pkl', 'wb'))</span></pre><p id="461f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有了。我们成功地训练了一个LSTM模型来模拟PID控制器的行为。下一个重要的步骤是将它投入使用。</p></div></div>    
</body>
</html>