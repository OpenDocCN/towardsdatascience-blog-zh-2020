<html>
<head>
<title>Fundamentals of Generative Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成对抗网络的基础</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fundamentals-of-generative-adversarial-networks-b7ca8c34f0bc?source=collection_archive---------17-----------------------#2020-11-02">https://towardsdatascience.com/fundamentals-of-generative-adversarial-networks-b7ca8c34f0bc?source=collection_archive---------17-----------------------#2020-11-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f532" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><div class=""><h2 id="a964" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">GANs——图解、解释和编码</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/b8f8a33c3eb8f5c3e7d1e124c19b5b26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*7WqgL4L9p0DOA8-aEeoFpw.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由GAN生成的合成手写数字。在本教程中，我们将创建自己的GAN，它可以像这样生成数字，以及创建上面这个动画的代码。请继续阅读！</p></figure><h1 id="8042" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">介绍</h1><p id="0b5d" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">2014年，一位名不见经传的博士生Ian Goodfellow向世界介绍了生成性对抗网络(GANs)。GANs不同于AI社区见过的任何东西，Yann LeCun将其描述为“<a class="ae mv" href="https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning" rel="noopener ugc nofollow" target="_blank">在ML </a>的过去10年中最有趣的想法”。</p><p id="f71d" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">从那时起，许多研究工作都倾注在GANs上，许多最先进的人工智能应用程序，如<a class="ae mv" href="https://github.com/NVlabs/stylegan2" rel="noopener ugc nofollow" target="_blank">英伟达的超现实人脸生成器</a>都源自Goodfellow对GANs的研究。</p><blockquote class="nb nc nd"><p id="7bd4" class="lz ma ne mb b mc mw kd me mf mx kg mh nf my mk ml ng mz mo mp nh na ms mt mu im bi translated">作者注:本文所有图片和动画均由作者创作。如果你想把这些图片用于教育目的，请在评论中给我留言。谢谢大家！</p></blockquote><h1 id="b858" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">什么是甘，他们能做什么？</h1><p id="1b35" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">在高层次上，GANs是一种神经网络，它学习如何生成真实的数据样本，并根据这些样本对其进行训练。例如，给定手写数字的照片，GANs学习如何生成更多手写数字的逼真照片。更令人印象深刻的是，GANs甚至可以学习生成人类的逼真照片，如下图所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ni"><img src="../Images/4fd2b8465404296552ada2768ecdc0f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o4tHrU3kVDfd0HOvi033yA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">GAN生成的人脸。以上这些面孔都不是真实的。来源:<a class="ae mv" href="https://thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">https://thispersondoesnotexist.com/</a></p></figure><p id="b9fd" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">那么GANs是如何工作的呢？从根本上说，GANs学习兴趣主题的分布。比如说。受过手写数字训练的GANs学习数据的分布。一旦学习了数据的分布，GAN可以简单地从分布中采样以产生真实的图像。</p><h1 id="396b" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">数据的分布</h1><p id="cba6" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">为了巩固我们对数据分布的理解，让我们考虑下面的例子。假设我们有下面的6张图片。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/be531e7d2c391cda8aee9a98e84308de.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*X88t6W_7mhj5jlnEK3niKg.png"/></div></figure><p id="fc64" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">每个图像都是一个浅灰色的盒子，为了简单起见，让我们假设每个图像只包含一个像素。换句话说，每个图像中只有一个灰色像素。</p><p id="8fe4" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">现在，假设每个像素都有一个介于-1和1之间的可能值，其中白色像素的值为-1，黑色像素的值为1。因此，6幅灰度图像将具有以下像素值:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/860305c958797a80322ba50efd82e085.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*2YEcHhXH9Y-LX9zpcGs6Dw.png"/></div></figure><p id="361f" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">关于像素值的分布，我们知道些什么？嗯，通过检查，我们知道大多数像素值都在0左右，只有少数值接近极值(-1和1)。因此，我们可以假设分布是高斯分布，平均值为0。</p><blockquote class="nb nc nd"><p id="a84d" class="lz ma ne mb b mc mw kd me mf mx kg mh nf my mk ml ng mz mo mp nh na ms mt mu im bi translated">注意:对于更多的样本，通过计算平均值和标准偏差来导出该数据的高斯分布是很简单的。然而，这不是我们的重点，因为计算复杂主题的数据分布是很困难的，不像这个简单的例子。</p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nl"><img src="../Images/447abd214d022e6dc64f201611efd0a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iRqCpZXdyZ7s0simdGTbOw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">我们像素的基本分布是平均值为0的高斯分布</p></figure><p id="c284" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">这种数据分布是有用的，因为它允许我们生成更多的灰色图像，就像上面的6。为了生成更多相似的图像，我们可以从分布中随机取样。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nm"><img src="../Images/f52f00c6e02521c3e7d3c2da795ba620.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*oKHGBklrAellAfXP0kkOEw.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从高斯分布中随机独立抽取10个像素。请注意，大多数像素值都接近平均值(0)，只有极少数异常值(-1和1)。</p></figure><p id="a44d" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">虽然计算出灰色像素的基本分布可能是微不足道的，但计算猫、狗、汽车或任何其他复杂对象的分布通常是数学上难以处理的。</p><p id="c6e2" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">那么，我们如何学习复杂对象的底层分布呢？显而易见的答案是使用神经网络。给定足够的数据，我们可以训练神经网络来学习任何复杂的功能，例如数据的基本分布。</p><h1 id="146f" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">生成器——分布式学习模型</h1><p id="13bd" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">在GAN中，生成器是学习数据底层分布的神经网络。更具体地说，生成器将随机分布(在GANs文献中也称为“噪声”)作为输入，并学习将输入映射到期望输出的映射函数，期望输出是数据的实际底层分布。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nn"><img src="../Images/c95a0ca791263707befa33474a7d20b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LGglCqrBVbDkMJ7qI3z3Hg.png"/></div></div></figure><p id="1071" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">但是，请注意，上面的体系结构中缺少一个关键组件。我们应该用什么损失函数来训练发电机？我们如何知道生成的图像实际上是否类似于实际的手写数字？一如既往，答案是“<em class="ne">使用神经网络</em>”。第二个网络被称为鉴别器。</p><h1 id="0dfe" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">鉴别器——生成器的对手</h1><p id="11d7" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">鉴别器的作用是判断和评估发生器输出图像的质量。从技术上讲，鉴别器是一个二元分类器。它接受图像作为输入，并输出图像是真实的(即实际的训练图像)还是虚假的(即来自生成器)的概率。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi no"><img src="../Images/3e54a95bc428e1c010aa608da6f73e92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*IYkoZtDGnlUxV82e1F6f8w.gif"/></div></div></figure><p id="c7fe" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">最初，生成器很难产生看起来真实的图像，鉴别器可以轻松区分真假图像，而不会犯太多错误。由于鉴别器是二进制分类器，我们可以使用二进制交叉熵(BCE)损失来量化鉴别器的性能。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi np"><img src="../Images/f4c1dbcac2add96dda53d19c2e564b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m5fH5TNZ-QhxI0bZxCm9_A.png"/></div></div></figure><p id="225a" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">鉴频器的BCE损耗是发生器的一个重要信号。回想一下，生成器本身并不知道生成的图像是否与真实图像相似。然而，发生器可以使用鉴别器的BCE损失作为信号来获得对其生成的图像的反馈。</p><p id="451d" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">它是这样工作的。我们将生成器输出的图像发送到鉴别器，它预测图像是真实的概率。最初，当生成器很差时，鉴别器可以很容易地将图像分类为假的，从而导致BCE损失很低。然而，生成器最终会改进，鉴别器开始犯更多的错误，将假图像误分类为真实图像，这导致了更高的BCE丢失。因此，鉴频器的BCE损耗表示发生器输出的图像质量，并且发生器寻求最大化该损耗。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nq"><img src="../Images/644cd8d46823409339ebff20fd7ced56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*d9Z1kuOR-Xjm5Pdg7P6gBw.gif"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nq"><img src="../Images/9ca79837c101ac0c28a5c45ba801464e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*yEIwNPZ7QDYq6YOcAcrR_A.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">鉴别器的BCE损失是发生器输出图像质量的指标</p></figure><p id="4bdc" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">从上面的动画中我们可以看到，鉴频器的BCE损耗与发生器产生的图像质量相关。</p><blockquote class="nr"><p id="52fc" class="ns nt it bd nu nv nw nx ny nz oa mu dk translated">发生器使用鉴频器的损耗作为其生成图像质量的指标。生成器的目标是调整其权重，使得来自鉴别器的BCE损失最大化，有效地“愚弄”鉴别器。</p></blockquote><h2 id="d705" class="ob li it bd lj oc od dn ln oe of dp lr mi og oh lt mm oi oj lv mq ok ol lx iz bi translated">训练鉴别器</h2><p id="faf4" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">但是鉴别器呢？到目前为止，我们从一开始就假设我们有一个完美工作的鉴别器。然而，这个假设是不正确的，鉴别器也需要训练。</p><p id="5a93" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">由于鉴别器是一个二元分类器，它的训练过程很简单。我们将向鉴别器提供一批标记的真实和虚假图像，并且我们将使用BCE损失来调整鉴别器的权重。我们训练鉴别器来识别真假图像，防止鉴别器被生成器“愚弄”。</p><h1 id="26fc" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">GANs——两个网络的故事</h1><p id="128e" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">现在让我们把所有的东西放在一起，看看GANs是如何工作的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/03f34c904db462468249773095a8cdd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xOgw_4Wv2KHvGzm_x0zeIQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">基本GAN的体系结构</p></figure><p id="4603" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">到目前为止，您已经知道GANs由两个相互连接的网络组成，即生成器和鉴别器。在传统的GANs中，发生器和鉴别器是简单的前馈神经网络。</p><blockquote class="nr"><p id="9777" class="ns nt it bd nu nv nw nx ny nz oa mu dk translated">甘斯的独特之处在于，生成器和鉴别器轮流接受训练，彼此对立。</p></blockquote><p id="b40f" class="pw-post-body-paragraph lz ma it mb b mc on kd me mf oo kg mh mi op mk ml mm oq mo mp mq or ms mt mu im bi translated">为了训练生成器，我们使用从随机分布中采样的噪声向量作为输入。在实践中，我们使用从高斯分布中抽取的长度为100的向量作为噪声向量。输入通过前馈神经网络中一系列完全连接的层。生成器的输出是一个图像，在我们的MNIST例子中，是一个<code class="fe os ot ou ov b">28x28</code>数组。发生器将其输出传递给鉴频器，并使用鉴频器的BCE损耗来调整其权重，目的是最大化鉴频器的损耗。</p><p id="aee1" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">为了训练鉴别器，我们使用来自生成器的标记图像以及实际图像作为输入。鉴别器学习将图像分类为真或假，并且使用BCE损失函数来训练。</p><p id="4423" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">在实践中，我们依次训练生成器和鉴别器。这种训练方案类似于两个玩家的minimax对抗游戏，因为生成器的目标是<strong class="mb jd">最大化</strong>鉴别器的损失，而鉴别器的目标是<strong class="mb jd">最小化</strong>它自己的损失。</p><h1 id="4fa5" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">创造我们自己的GAN</h1><p id="4d54" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">现在我们已经理解了GAN背后的理论，让我们通过使用PyTorch从头开始创建我们自己的GAN来将其付诸实践！</p><p id="82aa" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">首先，让我们引入MNIST数据集。<code class="fe os ot ou ov b">torchvision</code>库让我们可以轻松获得MNIST数据集。在将<code class="fe os ot ou ov b">28x28</code> MNIST图像展平为<code class="fe os ot ou ov b">784</code>张量之前，我们将对图像进行一些标准归一化。这种扁平化是必需的，因为网络中的层是完全连接的层。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="2358" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">接下来，让我们编写生成器类的代码。从我们前面看到的，生成器只是一个前馈神经网络，它接受一个<code class="fe os ot ou ov b">100</code>长度张量并输出一个<code class="fe os ot ou ov b">784</code>张量。在生成器中，密集层的大小通常会在每层之后翻倍(256、512、1024)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="d789" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">那很容易，不是吗？现在，让我们为discriminator类编写代码。鉴别器也是一个前馈神经网络，它接受一个<code class="fe os ot ou ov b">784</code>长度张量，并输出一个<code class="fe os ot ou ov b">1</code>大小的张量，表示输入属于类别1(真实图像)的概率。与生成器不同，我们在每个层(1024、512、256)之后将密集层的大小减半。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="2ce8" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">现在，我们将创建一个包含生成器和鉴别器类的GAN类。根据我们之前讨论的训练方案，这个GAN类将包含依次训练生成器和鉴别器的代码。为了简化我们的代码并减少样板代码，我们将使用<a class="ae mv" href="https://www.pytorchlightning.ai/" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning </a>来实现这一点。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="e0b3" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">上面的代码是注释过的，根据我们到目前为止所讨论的内容，它是非常简单明了的。请注意，使用PyTorch Lightning将我们的代码模块化是如何让它看起来如此整洁和易读的！</p><p id="cc7e" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">我们现在可以训练我们的GAN了。我们将使用GPU训练它100个纪元。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ow ox l"/></div></figure><h1 id="63cc" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">可视化生成的图像</h1><p id="9146" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">现在剩下的就是可视化生成的图像。在上面我们的GAN类的<code class="fe os ot ou ov b">training_epoch_end()</code>函数中，我们在每个训练时期之后将生成器输出的图像保存到一个列表中。</p><p id="54ab" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">我们可以把这些图像绘制在网格上，使之形象化。下面的代码随机选择了在第100个训练时期后生成的10幅图像，并将它们绘制在一个网格上。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="effb" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">这是输出结果:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/89138bdb7b3915014027048415c5b943.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPawmB4siR2yHYh2gSVIPQ.png"/></div></div></figure><p id="1b4d" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">那挺好的！输出类似于真正的手写数字。我们的发电机肯定学会了如何骗过鉴别器。</p><p id="bd88" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">最后，正如承诺的那样，我们将创建帖子顶部显示的动画。使用<code class="fe os ot ou ov b">matplotlib</code>中的<code class="fe os ot ou ov b">FuncAnimation</code>函数，我们将一帧一帧地制作图上图像的动画。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ow ox l"/></div></figure><h1 id="898d" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">下一步是什么？</h1><p id="e745" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">恭喜你。您已经完成了本教程的学习。我希望你喜欢读这篇文章，就像我喜欢写这篇文章一样。幸运的是，这不是我们旅程的终点。在Goodfellow推出最初的GAN后不久，科学界在这一领域投入了巨大的努力，这导致了基于GAN的AI模型的激增。</p><p id="dd95" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">我正在开始一系列这样的教程，在这些教程中，我将举例说明、解释和编码GAN的不同变体，包括一些重要的变体，如<strong class="mb jd">深度卷积GAN (DCGAN) </strong>和<strong class="mb jd">条件GAN (CGAN) </strong>。一定要关注我(如果你还没有！)以便在新教程发布时得到通知。</p></div><div class="ab cl oz pa hx pb" role="separator"><span class="pc bw bk pd pe pf"/><span class="pc bw bk pd pe pf"/><span class="pc bw bk pd pe"/></div><div class="im in io ip iq"><h1 id="cf0f" class="lh li it bd lj lk pg lm ln lo ph lq lr ki pi kj lt kl pj km lv ko pk kp lx ly bi translated">其他资源</h1><p id="7f84" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">这里的代码也可以在我的Github库中找到。我将不断更新这个库，在将来包含GANs的其他变体。</p><div class="pl pm gp gr pn po"><a href="https://github.com/jamesloyys/PyTorch-Lightning-GAN" rel="noopener  ugc nofollow" target="_blank"><div class="pp ab fo"><div class="pq ab pr cl cj ps"><h2 class="bd jd gy z fp pt fr fs pu fu fw jc bi translated">jamesloyys/py torch-Lightning-GAN</h2><div class="pv l"><h3 class="bd b gy z fp pt fr fs pu fu fw dk translated">使用py torch Lightning github.com实现各种GAN架构</h3></div></div><div class="pw l"><div class="px l py pz qa pw qb lb po"/></div></div></a></div></div></div>    
</body>
</html>