<html>
<head>
<title>What does computer vision see in the 2020-US Election news feed? (Part 1/2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉在2020年美国大选新闻提要中看到了什么？(第1/2部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-does-computer-vision-see-in-the-us-election-2020-news-feed-part-1-2-a558ec7ccaa0?source=collection_archive---------52-----------------------#2020-11-02">https://towardsdatascience.com/what-does-computer-vision-see-in-the-us-election-2020-news-feed-part-1-2-a558ec7ccaa0?source=collection_archive---------52-----------------------#2020-11-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b5f8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">第1部分-生成批量人工智能注释图像和预处理数据，以构建特征级图像数据集。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8c24dd7d6857baeb54d9d622aa190399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yb_e9b2TYRQ4_8e7DUiFsQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从美国选举2020图像的样本批次上标注的数据生成的数据可视化网格；<a class="ae kv" href="https://unsplash.com/@cameramandan83?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">丹丹尼斯</a>在<a class="ae kv" href="https://unsplash.com/s/photos/elections-usa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的背景照片；Srinivas Vadrevu的分析</p></figure><h2 id="31f0" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">编辑:</h2><p id="52bb" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">这是两部分系列的第一篇文章。你可以在这里找到第二部分<a class="ae kv" rel="noopener" target="_blank" href="/what-does-computer-vision-see-in-the-2020-us-election-news-feed-part-2-2-908e836fb066">的链接</a></p><p id="f844" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">由于图像在顾客购买过程中的普遍性和重要性，视觉内容策略现在已经成为市场营销不可或缺的一部分。然而，视觉内容创作主要植根于隐性知识和创造性领域。然而，随着计算机视觉的出现，公司应该将人工智能用于建立对图像特征的明确知识，以探索什么驱动印象并影响购买决策吗？换句话说，人工智能生成的数据补充创作过程的时机成熟了吗？随着美国大选的临近，我选择它作为当前的营销背景来使用Cloud Vision AI，并在本文的第一部分解释如何建立广泛的特征级数据集。</p><p id="8804" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我相信你一定听说过这句谚语...</p><blockquote class="mq"><p id="5cad" class="mr ms iq bd mt mu mv mw mx my mz mk dk translated">“一幅画胜过千言万语”</p></blockquote><figure class="nb nc nd ne nf kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/24818ebce7a52ebfeb58350d8fbb722b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UFHGFemRAU-jW3KVk7rjNA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:早期广告的模糊版本，强调形象的重要性，由弗兰克·巴纳德于1921年创作；来源:<a class="ae kv" href="http://www2.cs.uregina.ca/~hepting/projects/pictures-worth/" rel="noopener ugc nofollow" target="_blank">http://www2.cs.uregina.ca/~hepting/projects/pictures-worth/</a></p></figure><p id="61e0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi ng translated">你知道这句英语谚语起源于广告吗？虽然它最初是一句亚洲谚语，但一些早期的广告商用它来强调图片在产生印象中的重要性。</p><p id="9195" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">弗兰克·巴纳德在1921年的广告是这样说的:</p><blockquote class="np nq nr"><p id="2ed7" class="ls lt ns lu b lv ml jr lx ly mm ju ma nt mn mc md nu mo mf mg nv mp mi mj mk ij bi translated">“奶油甜很好吃”是一个很短的短语，但如果在一年中每天早上、中午和晚上向许多人展示该产品的诱人图片，它会比在相同数量的人面前放置一千字的广告销售更多的商品，一年中只有有限的几次…</p><p id="a436" class="ls lt ns lu b lv ml jr lx ly mm ju ma nt mn mc md nu mo mf mg nv mp mi mj mk ij bi translated">仅仅是对有价值产品的良好印象的优势提醒消费者一次又一次地购买它”——弗兰克·巴纳德</p></blockquote><div class="nw nx gp gr ny nz"><a href="http://www2.cs.uregina.ca/~hepting/projects/pictures-worth/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd ir gy z fp oe fr fs of fu fw ip bi translated">一张照片值| D. H .赫普廷博士</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">“一图抵一万字”这句话对你来说意味着什么？如果…它变得更有意义还是更无意义</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">www2.cs.uregina.ca</p></div></div><div class="oi l"><div class="oj l ok ol om oi on kp nz"/></div></div></a></div><p id="f8bb" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">虽然有点讽刺的是，你在上面的广告中看不到任何图片，但它强调了通过其媒体(在汽车上)的图像在给观众留下良好印象方面发挥着重要作用。这些印象可能会影响他们购买产品的决定。是的，当时“印象”这个词不仅仅是一个营销KPI指标。</p><p id="e7c5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">当你从1921年快进到今天，你发现自己在照片、广告牌、电视广告、互联网广告、模因、展示广告、Instagram feed和其他社交媒体等方面加速前进。在令人眼花缭乱的旅程之后，你看到你正在浏览Twitter上的一些帖子，这是你日常工作的一部分。弗兰克·巴纳德(Frank Barnard)的汽车作为获取用户的渠道，他们的印象现在被社交媒体feed取代。你在feed中看到一个帖子(见下文),在向下滚动之前花了五秒钟考虑新产品。你会对耳塞留下一个“印象”，这可能会影响你未来使用该产品的决定。弗兰克·巴纳德一点也不知道他对广告图像的拍摄在100年后仍有意义。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="905e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">最近的<a class="ae kv" href="https://www.brightlocal.com/research/local-consumer-review-survey/" rel="noopener ugc nofollow" target="_blank">调查</a>通过其发现强调了视觉图像在广告中的重要性和普遍性:</p><ul class=""><li id="a348" class="oq or iq lu b lv ml ly mm lf os lj ot ln ou mk ov ow ox oy bi translated">60%的消费者表示，他们更有可能考虑或联系在本地搜索结果中有图片显示的企业</li><li id="3b43" class="oq or iq lu b lv oz ly pa lf pb lj pc ln pd mk ov ow ox oy bi translated">67%的消费者表示，在选择和购买产品时，产品形象的质量至关重要。</li></ul><h2 id="1a58" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">动机和背景:</strong></h2><p id="2690" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">每3个顾客中就有2个依靠视觉创意做出购买决定，视觉创意在营销中的重要性怎么强调都不过分。然而，根据我最近和一些创业公司的经验以及阅读的大量材料，我认为视觉内容策略主要涉及(1)受众及其目标，(2)品牌形象及其目标，以及(3)分销媒体。然而，实际的图像内容和组成主要是一种创造性的努力，是建立在营销人员的隐性知识上的结果。所以这篇文章背后的动机是探索使用机器学习/计算机视觉来分析图像的可能性，并检查AI是否可以生成关于内容策略的明确知识，以补充创建视觉内容的创造性努力。在我看来，人工智能图像分析可以为视觉内容营销打开更多的可能性，正如sabermetrics在21世纪初对棒球世界所做的那样。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oo op l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">总统候选人发布的推文</p></figure><p id="ed2f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">设定背景:</strong>随着总统竞选活动如火如荼地进行，选举即将来临，我想不出比这更切合当前和相关的营销背景了，总统候选人正在积极主动地向美国民众推销自己，以争取投票(阅读。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="0249" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">购买)用于即将到来的2020年11月3日的选举。浏览下面列出的两篇文章，可以发现图像/图片(阅读视觉媒体)在影响选举(阅读购买决策)中的作用。此外，由于新冠肺炎，图像的作用只是被放大了。我知道这有点牵强，但我们似乎确实在政治活动和公司营销努力之间有相似之处，尤其是在形象的作用上。</p><div class="nw nx gp gr ny nz"><a href="https://time.com/4439540/winning-the-white-house-lightbox/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd ir gy z fp oe fr fs of fu fw ip bi translated">摄影如何在总统选举中扮演重要角色</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这张照片展示了巴拉克·奥巴马总统和他的妻子，第一夫人米歇尔·奥巴马，在一次…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">time.com</p></div></div><div class="oi l"><div class="pe l ok ol om oi on kp nz"/></div></div></a></div><div class="nw nx gp gr ny nz"><a href="https://journalism.uoregon.edu/news/six-ways-media-influences-elections" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd ir gy z fp oe fr fs of fu fw ip bi translated">媒体影响选举的六种方式</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">安德拉·布里恰切克的故事。瑞安隆德和亚伦纳尔逊视频。照片由谢弗邦纳和Karly DeWees。问唐纳德…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">journalism.uoregon.edu。</p></div></div><div class="oi l"><div class="pf l ok ol om oi on kp nz"/></div></div></a></div><p id="bc18" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在设置了背景之后，我决定分析当前主题美国2020年选举活动的视觉内容，这些内容来自不同的来源，如谷歌图像、报纸网站和新闻API，以将计算机视觉用于图像分析。我把主要文章分成三个部分-</p><ul class=""><li id="e2f0" class="oq or iq lu b lv ml ly mm lf os lj ot ln ou mk ov ow ox oy bi translated">围绕给定主题聚合一组图像(本文中的美国2020年大选)- <strong class="lu ir">第1a部分</strong></li><li id="b253" class="oq or iq lu b lv oz ly pa lf pb lj pc ln pd mk ov ow ox oy bi translated">通过视觉人工智能批量处理图像，为每幅图像添加注释特征- <strong class="lu ir">第1b部分</strong></li><li id="4e4e" class="oq or iq lu b lv oz ly pa lf pb lj pc ln pd mk ov ow ox oy bi translated">可视化特性以获得洞察力- <strong class="lu ir">第二部分</strong></li></ul><p id="0269" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在本文中，我将详细介绍前两个部分，以及从互联网上的一批图像中生成人工智能注释特征数据集的代码。在第2部分中，我将讨论更多关于绘制这些数据集的图表，并探索从中获得的见解。</p></div><div class="ab cl pg ph hu pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="ij ik il im in"><h2 id="710f" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">第1a部分:数据收集-围绕一个主题聚合一组图像-2020年美国大选</h2><p id="327f" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我想建立一个个人图像数据集，用于收集过去几周内关于2020年美国大选的照片。为此，我确定了创建图像数据库的不同来源，每张图片都将由ML进行注释。我列出了三个来源，代码，以及从这些来源收集URL的方法-</p><p id="58dc" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">a) <strong class="lu ir">新闻API </strong> —</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pn"><img src="../Images/0b4b473e59961287f340d2aee881b88e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lX0r-J7VhPlnEsYX"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@siora18?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Siora摄影</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="01f0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这是一个易于使用的HTTPS REST API，您可以在其中请求关于为查询生成的文章的“一切”。您文章的“一切”端点为您提供:</p><p id="41c1" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">状态、总结果、文章、来源、作者、标题、描述、URL、URL到图像&lt; the link to the image in the article&gt;、发布和内容<entire text="" of="" the="" article=""/></p><p id="dde5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">您可以找到下面的代码(Gist 1)来调用NewsAPI并将数据推入pandas数据框中，以便于阅读。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="po op l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">要点1:将新闻文章从NewsAPI拉入pandas数据框的代码</p></figure><p id="4455" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在要点中，我键入URL参数，并以JSON格式从NewsAPI收集响应。从JSON文件中，我选择文章并循环添加文章的属性，包括图片URL。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pp"><img src="../Images/5a252f80b4bd461543725bf5c263ba78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*A134waIQ2MkWXrlL"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@edhoradic?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Edho Pratama </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="fc64" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir"> b)谷歌图片搜索- </strong>围绕一个主题的另一个图片来源是谷歌图片。这是任何人寻找与某个主题相关的图片的单一接触点。在寻找将谷歌图片放入数据集的方法时，我看到了这篇由@fabianbosler 撰写的<a class="ae kv" rel="noopener" target="_blank" href="/image-scraping-with-python-a96feda8af2d">文章</a>。对于任何希望在互联网上负责任地抓取图片的人来说，这绝对是一本好书。</p><p id="2556" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我在那篇文章中使用了gist代码来提取美国选举新闻的图片和URL。</p><p id="07cc" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">新闻网站——除了新闻网站本身，还有什么更好的美国2020年选举新闻图片来源呢？许多受欢迎的新闻网站正在为开发者创建他们自己的API来访问他们的数据。你可以在他们的网站上找到API文档和端点。其中有几个是<a class="ae kv" href="https://developer.nytimes.com/" rel="noopener ugc nofollow" target="_blank">https://developer.nytimes.com/</a>和<a class="ae kv" href="http://developer.cnn.com/" rel="noopener ugc nofollow" target="_blank">http://developer.cnn.com/</a>(即将推出)。如果网站没有API，您可以尝试经典、漂亮的soup包来抓取网站的图像URL。</p><p id="62d5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">假设你想搜集abcdef.com网站上10月18日到10月31日之间的所有文章。首先，您可能希望检查网站URL的结构，以识别可以循环生成文章URL的任何日期字符串。对于每个URL，您可以找到网站上的所有图像，获取它的“src”，将它们附加到一个数据框中，并重复迭代您需要的所有文章URL(基于日期)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="po op l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">要点2:调用beautiful soup提取主文章URL中的图片URL</p></figure><p id="5034" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在你从网上刮下任何东西用于个人或商业用途之前，通读使用/服务条款以检查你是否违反了任何条款通常被认为是一种好的做法。</p><p id="bfbd" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用这些方法的组合，我从几个覆盖美国2020年选举新闻的热门网站收集了图像，以建立一个广泛的图像数据集来分析趋势。图像URL的列表存储在links_df中。可以将唯一的URL提取为注释列表。可能会有这样的情况，同一个URL可以从不同的来源提取，就像来自一个新闻网站的同一个图片出现在Google搜索图片中一样。</p><pre class="kg kh ki kj gt pq pr ps pt aw pu bi"><span id="417f" class="kw kx iq pr b gy pv pw l px py">url_list= links_df['urls'].unique().tolist()</span></pre><p id="c550" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">步骤1b:使用Cloud Vision API对收集的图像进行批量注释，并将JSON响应转换为数据帧</strong></p><p id="8374" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">准备好图像URL数据集后，我使用Cloud Vision API通过它们的REST API来注释各种功能。为此，我创建了一个GCP项目，启用了Cloud Vision API，创建了一个服务帐户，并以JSON格式生成了用于身份验证的私有凭证。然后，我使用终端创建了一个虚拟环境来安装谷歌云视觉库。</p><pre class="kg kh ki kj gt pq pr ps pt aw pu bi"><span id="fd0f" class="kw kx iq pr b gy pv pw l px py">virtualenv &lt;your-env&gt;<br/>source &lt;your-env&gt;/bin/activate<br/>&lt;your-env&gt;/bin/pip install google-cloud-vision</span></pre><p id="3f09" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果您还想为项目创建一个新的内核，您可以使用ipykernel包:</p><pre class="kg kh ki kj gt pq pr ps pt aw pu bi"><span id="f84f" class="kw kx iq pr b gy pv pw l px py">pip install ipykernel<br/>ipython kernel install --user-- --name=yourkernelname<br/>jupyter notebook</span></pre><p id="ddac" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">对于批处理，我想构建一个函数“<strong class="lu ir">runvisionai”</strong>，它为输入到函数中的一批URL生成一个特性类别数据集。在此之前，我必须决定每个要素类别级别数据集的结构。作为一个例子，我将带你从Unsplash为一张图片创建面部特征数据集。(见下图4)</p><pre class="kg kh ki kj gt pq pr ps pt aw pu bi"><span id="a713" class="kw kx iq pr b gy pv pw l px py">client = vision.ImageAnnotatorClient()<br/>image = vision.Image()</span><span id="96c8" class="kw kx iq pr b gy pz pw l px py">url= "https://images.unsplash.com/photo-1540502040615-df7f25a5b557?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=2550&amp;q=80"</span><span id="e050" class="kw kx iq pr b gy pz pw l px py">image.source.image_uri = url </span><span id="026d" class="kw kx iq pr b gy pz pw l px py">response_face_example = client.face_detection(image=image)<br/></span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qa"><img src="../Images/ffd79138492d4aaae22dead424a9ba48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GkForoS8B4q1YoGD"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4:<a class="ae kv" href="https://unsplash.com/@jairph?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">贾尔夫</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c9ae" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">一旦知道了响应JSON文件的“face_annotations”中的数据点，就需要选择追加要素类别数据框的粒度级别。</p><p id="9407" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在将图像发送到vision AI进行处理后，您可以在此处找到图像的JSON响应<a class="ae kv" href="https://gist.github.com/nufiniti/86aa92ae779a90d29bfc3c3047207fe8" rel="noopener ugc nofollow" target="_blank">。如果将该响应可视化，它将看起来像下面处理过的图像。根据JSON响应，可能有不同的粒度级别:</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qb"><img src="../Images/59b1a89fe81f70676f5f86ba0f6a64e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YcOX3QYi7WKMMOn3gKz2eg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图5:视觉AI的面部检测响应的视觉表示</p></figure><ol class=""><li id="3c84" class="oq or iq lu b lv ml ly mm lf os lj ot ln ou mk qc ow ox oy bi translated">在JSON <a class="ae kv" href="https://gist.github.com/nufiniti/86aa92ae779a90d29bfc3c3047207fe8" rel="noopener ugc nofollow" target="_blank">文件</a>中，你可以通过为每个面添加下面的数据点(我在这个项目中就是这么做的)来压缩这些数据点。</li></ol><pre class="kg kh ki kj gt pq pr ps pt aw pu bi"><span id="9690" class="kw kx iq pr b gy pv pw l px py">Face 1: <br/>roll_angle: -9.5155668258667<br/>  pan_angle: -5.019717216491699<br/>  tilt_angle: 1.8756755590438843<br/>  detection_confidence: 0.9624646902084351<br/>  landmarking_confidence: 0.6258678436279297<br/>  joy_likelihood: LIKELY<br/>  sorrow_likelihood: VERY_UNLIKELY<br/>  anger_likelihood: VERY_UNLIKELY<br/>  surprise_likelihood: VERY_UNLIKELY<br/>  under_exposed_likelihood: VERY_UNLIKELY<br/>  blurred_likelihood: VERY_UNLIKELY<br/>  headwear_likelihood: VERY_UNLIKELY<br/></span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qd"><img src="../Images/996db7b32933ed2d0036237051669c97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IXj8-CFbaekFewknchquqQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图6:我为每个面收集边界多边形顶点的数据框草图</p></figure><p id="120b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">2.或者…您可以在每个面的顶点级别收集数据，即，对于每个面，您可以收集包围该面的多边形的每个顶点的x和y坐标。</p><p id="155a" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在这种情况下，您可能希望在“runvisionai”函数的face循环中创建一个嵌套循环(该循环又嵌套在URL中)。我发现对于最近开始编码的人来说，画出数据集的轮廓并对代码进行逆向工程以得到它是很有用的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="po op l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">要点3:提取API响应中标注的面的边界顶点的代码</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qe"><img src="../Images/c99196db0d2fcf2116a9e6546697fbca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pdR32hCZKBoZaIvhJbJOWA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图6:要点3中代码的结果；它是一个数据框，单位是边界多边形的顶点；Srinivas Vadrevu的分析</p></figure><p id="f420" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">3.或者…您可以创建一个面部特征数据集，其中粒度级别固定在面部特征/面部标志级别。单位项目是身体面部特征。那么，在这种情况下，我的代码模式应该是</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qf"><img src="../Images/b7baecb21f682550bde97b56185066c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-4XXB48eM4LeGC9JA-TeVg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图7:我收集面部标志及其坐标的数据框草图</p></figure><p id="bf88" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">(1)循环URL →调用RunVisionAI →采集人脸。每个URL的注释JSON</p><p id="b260" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">(2)然后在脸部打圈脸。函数内部的注释→收集数据集中的人脸id→</p><p id="e9ba" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">(3)为每个面部创建嵌套的环形标志→在数据集中收集面部标志→</p><p id="7035" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">(4)在面部标志层附加x、y和z坐标。重复直到所有循环完成。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="po op l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">要点4:提取图像中标注的面部标志的顶点的代码</p></figure><p id="d0ac" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在确定了表面级别的数据粒度和数据框的结构后，我为每个要素类别创建了一个空数据框，以存储和追加每次URL迭代的数据框结果。我为面部数据集创建了一个face_df数据框来收集每个面部的特征——置信度得分、喜悦、悲伤、惊讶、愤怒和模糊。</p><pre class="kg kh ki kj gt pq pr ps pt aw pu bi"><span id="5945" class="kw kx iq pr b gy pv pw l px py">face_df=pd.DataFrame(columns['Source','Query/alt','URL','img_num',<br/>                    'face','confidence','joy','sorrow','surprise',<br/>                    'anger','blurred'])</span></pre><p id="4d52" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我将所有特征数据帧中每张图片的标识符设置为:<strong class="lu ir"> Source </strong>(来自NewsAPI/ News网站的谷歌图片搜索/新闻网站名称)、<strong class="lu ir"> Query/alt </strong>(包含谷歌图片搜索的搜索查询或图片的alt描述)，以及<strong class="lu ir"> URL </strong>(该图片的URL链接)</p><p id="717d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">逻辑与其他功能类别非常相似。您可以在Gist 5中找到下面所有特性类别的完整代码。此函数“runvisionai”成功地注释了一批URL，并将数据存储在不同要素类别的相应数据框中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="po op l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">要点RunvisionAI函数的代码，为输入其中的URL构建功能级别的数据集</p></figure><p id="d4e2" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">继续运行该函数，以获得您在步骤1中收集的一批URL的要素类别级别数据集。</p><pre class="kg kh ki kj gt pq pr ps pt aw pu bi"><span id="806a" class="kw kx iq pr b gy pv pw l px py">urls= list_df['URLs'].unique().tolist()<br/>runvisionai(urls)</span><span id="c593" class="kw kx iq pr b gy pz pw l px py">print(label_df)<br/>print(objects_df) # check if feature category dataset is prepared</span></pre><p id="d87a" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果在步骤1b结束时一切顺利，您将拥有所有填充的数据框，它们具有不同的单元(URL、面孔、位置、标签、徽标等)。)和每个功能类别的相应指标。</p><div class="kg kh ki kj gt ab cb"><figure class="qg kk qh qi qj qk ql paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/18edd9319cf62019ab39ed1b07ff9d1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*I8m-1elGsTsaY2KrbdbAAA.png"/></div></figure><figure class="qg kk qm qi qj qk ql paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/ad567b5462ed0ea27a642a945bf442f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*eC3bFuPiCkxKlFSInzJ8nw.png"/></div></figure></div><div class="ab cb"><figure class="qg kk qn qi qj qk ql paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/a08fe18af38b193adc315f0e78adad50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qxaWP1Sxb0V_gNJ1sNrC-A.png"/></div></figure><figure class="qg kk qn qi qj qk ql paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/77433d8c083f21fa19b65d6167a36e9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*gKERZvrUAanllYXrhZ3hoA.png"/></div></figure></div><div class="ab cb"><figure class="qg kk qn qi qj qk ql paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/1ed694c77e56c91d9c347caf0f17d9a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*nVLZLg3Js7jCtRDmJkneJQ.png"/></div></figure><figure class="qg kk qn qi qj qk ql paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/5a83b840f8825c337cd00fb672fb1003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*OUxQCg5yXRwpOvskl9dkhg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk qo di qp qq translated">图8:特征类别的输出数据帧；Srinivas Vadrevu的分析</p></figure></div><p id="b4d7" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">第二步:可视化</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qr"><img src="../Images/15fe5ab7100d0e28df1074586b7be771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jTO1jtC3xTJZq04K"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@jakaylatoney?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Jakayla Toney </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="30be" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在下一篇文章中，我将根据视觉人工智能提取的特征绘制和分析图像。我将很快更新这篇文章，提供第二部分的链接。作为下一篇文章的预览，我为CNN和NYT在过去三天(10月29日-10月31日)的美国大选报道中发布的图片标注了标签。y轴以图像中出现频率的降序排列标签。x轴代表计数/频率。我只考虑了置信度超过90%的图像中的标签。</p><p id="aaaa" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用下面的图片，你可以比较CNN和纽约时报网站在2020年10月29日至10月31日期间发布的图片中标注的标签</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qr"><img src="../Images/f95c48c92401a264b34266cebfffd0a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TTnx8710tz4R9rxJEMDSuQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图9:根据出现次数排列的顶部标签(在NYT图像中以超过90%的置信度识别);Srinivas Vadrevu的分析</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi qr"><img src="../Images/cb460b4dcf6db0c2e31cafe51ee38348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T7EGAa6bbI1SDnssZt1sYg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图10:按出现次数排列的顶部标签(在CNN图像中以超过90%的置信度识别);Srinivas Vadrevu的分析</p></figure><p id="5786" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">本文第1部分的结论</strong>:本文的主要目的是概述从一批图像生成大量特征数据集所涉及的代码和步骤。我用美国2020年大选作为营销背景，从互联网图像中提取特征。在我看来，图像特征成分有可能被用作解释视觉内容广告表现的因变量。换句话说，将这些图像数据集与活动营销分析数据(印象、喜欢、点击、点击率等)联系起来会非常有趣。).在这样做的时候，我推测我们可以找到姿势、标签、面部表情、物体、颜色组合和标志的某种组合有更好的表现，比如说点击率相对于其他组合。这种明确的知识可以反馈给参与视觉内容生成的创意团队。</p></div></div>    
</body>
</html>