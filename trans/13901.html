<html>
<head>
<title>Celebrity Face Generation With Deep Convolutional GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">名人脸一代与深卷积甘斯</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/celebrity-face-generation-with-deep-convolutional-gans-40b96147a1c9?source=collection_archive---------23-----------------------#2020-09-24">https://towardsdatascience.com/celebrity-face-generation-with-deep-convolutional-gans-40b96147a1c9?source=collection_archive---------23-----------------------#2020-09-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c0f7" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习</h2><div class=""/><div class=""><h2 id="5b93" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用DCGANs生成新的人脸图像</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/27af90cb75f8444b129c784fed12b506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mZhMuhHxtQKlo52m"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@johnjac?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">约翰·杰克逊</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="d1f4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我将带您完成一个有趣的项目，在这个项目中，您将实现一个用于人脸生成的DCGAN。</p><p id="b4ff" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将利用大规模名人面孔属性(celebA)数据集来训练我们的对抗网络。</p><blockquote class="me mf mg"><p id="8694" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">如果您不熟悉GANs及其工作方式，请阅读这篇关于走向数据科学的文章。</p></blockquote><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/generative-adversarial-networks-6a17673db367"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">生成对抗网络</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">用解读甘博弈</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc lb mo"/></div></div></a></div></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="b1ad" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">大规模名人面孔属性(celebA)数据集</h2><p id="a4c0" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated"><strong class="lk jd">名人脸属性数据集(CelebA) </strong>是一个大规模的人脸属性数据集，拥有超过<strong class="lk jd"> 200K </strong>张名人图片，每张图片都有<strong class="lk jd"> 40 </strong>个属性标注。</p><p id="2935" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据可以从<a class="ae lh" href="https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5be7eb6f_processed-celeba-small/processed-celeba-small.zip" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><blockquote class="me mf mg"><p id="8902" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">我们将使用深度卷积GANs。如果你想了解DCGANs，可以看看这篇文章。</p></blockquote><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">深度卷积生成对抗网络</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">生成对抗网络最有趣的部分之一是生成网络的设计。的…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="oh l mz na nb mx nc lb mo"/></div></div></a></div><h2 id="c79e" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">预处理和数据加载</h2><p id="4ef2" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们不需要注释，所以我们将不得不裁剪图像。这些是彩色图像。因此，深度为3(RGB-3个颜色通道)。</p><p id="3026" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以调整和裁剪图像到32x32的大小。这可以在以后转换成张量。</p><p id="0208" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">注意，我们在这里使用图像文件夹包装函数。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="c040" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">可视化我们的训练数据</h2><p id="8d84" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们现在将生成一批数据，并将其可视化。请注意，np.transpose函数按照指定的顺序转换图像尺寸。例如，在调用以下函数时，形状3x32x32的RGB图像将转换为32x32x3:</p><pre class="ks kt ku kv gt ok ol om on aw oo bi"><span id="42ec" class="nk nl it ol b gy op oq l or os">np.transpose(img,(1,2,0))</span></pre><p id="5d51" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们的批次大小是128，所以在这种情况下，我们只绘制20个图像，而不是绘制一个批次的所有128个图像。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/f19ea514abf9a79c6e1992ad012106c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*46kGgX40UXni9_kbbREGFg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">一批训练图像。图片由作者提供。</p></figure><h2 id="e474" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">缩放图像</h2><p id="0e3d" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">缩放图像是很重要的，因为Tanh函数的值在-1到1的范围内，所以我们需要将我们的训练图像重新缩放到-1到1的范围。(目前，它们在0-1的范围内。)</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="16af" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">辅助函数—卷积和转置卷积</h2><p id="987d" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">为了简化我们的代码，我们将定义帮助函数来定义我们的鉴别器和生成器网络。</p><p id="2ec0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些助手功能的原因是什么？回答——干！😅</p><p id="18b7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">卷积辅助函数</strong></p><blockquote class="me mf mg"><p id="e2d1" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">注意:要阅读CNN，请查看下面的斯坦福笔记。</p></blockquote><div class="ml mm gp gr mn mo"><a href="https://cs231n.github.io/" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">用于视觉识别的CS231n卷积神经网络</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">斯坦福CS231n课程材料和笔记:视觉识别的卷积神经网络。</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">cs231n.github.io</p></div></div></div></a></div><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><p id="187b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">转置卷积辅助函数</strong></p><blockquote class="me mf mg"><p id="02ba" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">注意:如果你想了解转置卷积，可以看看下面的文章。</p></blockquote><div class="ml mm gp gr mn mo"><a rel="noopener follow" target="_blank" href="/transposed-convolution-demystified-84ca81b4baba"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">转置卷积去神秘化</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">转置卷积对于图像分割、超分辨率等应用来说是一个革命性的概念</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="ou l mz na nb mx nc lb mo"/></div></div></a></div><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="a8f8" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">鉴别器架构</h2><p id="b1c9" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们现在将定义我们的鉴别器网络。正如我们所知，鉴别器负责将图像分类为真或假。因此这是一个典型的分类器网络。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="0f2f" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">发电机架构</h2><p id="8140" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">生成器网络负责生成假图像，这些假图像可以欺骗鉴别器网络将其归类为真实图像。随着时间的推移，生成器在欺骗鉴别器方面变得相当不错。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="4188" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">参数初始化</h2><p id="01a7" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们将通过从正态分布中抽取随机值来初始化网络的权重和偏差。这导致更好的结果。我们为其定义了一个函数，将一个层作为输入。</p><p id="a661" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于权重，我使用0均值和0.02标准差。</p><p id="a753" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于偏差，我使用0。</p><blockquote class="me mf mg"><p id="161c" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">现在这应该被替换，所以函数后面的_(下划线)也是如此。</p></blockquote><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="042f" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">损失函数和优化器</h2><p id="a381" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们将使用学习率为0.002的Adam优化器。这与DCGANs的原始研究论文一致。你可以在下面查看一下。</p><div class="ml mm gp gr mn mo"><a href="https://arxiv.org/abs/1511.06434" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab fo"><div class="mq ab mr cl cj ms"><h2 class="bd jd gy z fp mt fr fs mu fu fw jc bi translated">深度卷积生成对抗网络的无监督表示学习</h2><div class="mv l"><h3 class="bd b gy z fp mt fr fs mu fu fw dk translated">近年来，卷积网络的监督学习(CNN)在计算机视觉领域得到了广泛应用…</h3></div><div class="mw l"><p class="bd b dl z fp mt fr fs mu fu fw dk translated">arxiv.org</p></div></div></div></a></div><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><p id="16a8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们使用BCEwithLogitsLoss()，它结合了一个sigmoid激活函数(我们希望鉴别器输出一个0–1的值来指示一个图像是真的<em class="mh">还是假的</em>)和二进制交叉熵损失。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/ce6b6dc52bb305d02fc6ed69137a76ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*1I9MpiCXDgoY2XvY42tYQA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Binar交叉熵损失方程。图片由作者提供。</p></figure><h2 id="e703" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">培训阶段</h2><p id="bea2" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们将定义一个函数来训练我们的模型。这些参数将是鉴别器、发生器、纪元编号。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><h2 id="23bf" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">策划损失</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/c1e79423cea95c6081f5527843ab4ad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*5hyOLWe2k8d8yFpSpLImAw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由作者提供。</p></figure><h2 id="023e" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">样本生成</h2><p id="b80c" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">现在让我们生成几个样本。重要的是，我们要将这些值重新调整回像素范围(0–255)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oi oj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者代码。</p></figure><p id="760a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，下面是我们生成的人脸。👀</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/b968bcccbe0b2f9a02b765b2a3f0cffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kie4Oup4lryoVmtcLnAm5A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">生成的图像。图片由作者提供。</p></figure><p id="f585" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">嗯，对于一个小型网络来说，这是相当不错的！</p><h2 id="bfeb" class="nk nl it bd nm nn no dn np nq nr dp ns lr nt nu nv lv nw nx ny lz nz oa ob iz bi translated">外卖食品</h2><ol class=""><li id="40f8" class="oy oz it lk b ll oc lo od lr pa lv pb lz pc md pd pe pf pg bi translated">人脸包含多个特征，其中一些特征非常复杂，例如雀斑和胡须。为了生成合适的图像，我们可能需要高分辨率的图像。</li><li id="5e9e" class="oy oz it lk b ll ph lo pi lr pj lv pk lz pl md pd pe pf pg bi translated">为训练提供了高分辨率图像，我们可能需要建立一个更好、更深的模型，以获得更高的精确度。</li><li id="3593" class="oy oz it lk b ll ph lo pi lr pj lv pk lz pl md pd pe pf pg bi translated">基于输入图像，我们可以进一步增加模型的深度和层数。</li><li id="7814" class="oy oz it lk b ll ph lo pi lr pj lv pk lz pl md pd pe pf pg bi translated">提高分辨率肯定有助于我们改进模型并精确捕捉更多特征。</li><li id="8799" class="oy oz it lk b ll ph lo pi lr pj lv pk lz pl md pd pe pf pg bi translated">生成的样本可以通过调整参数，如学习率、批量大小和更多次数的训练来进一步改进。发电机的损耗是波动的，而不是减少的。</li><li id="e457" class="oy oz it lk b ll ph lo pi lr pj lv pk lz pl md pd pe pf pg bi translated">CelebA数据主要包含不同名人在不同角度和光照条件下的图像。</li></ol></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="d196" class="pm nl it bd nm pn po pp np pq pr ps ns ki pt kj nv kl pu km ny ko pv kp ob pw bi translated">结论</h1><p id="2dd0" class="pw-post-body-paragraph li lj it lk b ll oc kd ln lo od kg lq lr oe lt lu lv of lx ly lz og mb mc md im bi translated">我们已经看到了如何在celebA数据集上使用DCGAN实现生成逼真的人脸。通过调整超参数，可以进一步改善生成的图像。你也可以选择比这里更深的层次。然而，这样做将导致参数数量的增加，这又将花费大量时间来训练。现在打开你的Jupyter笔记本，执行同样的操作。在下一篇文章中，我将带您浏览使用SVHN数据集生成街景房屋号码的过程。下一场见。干杯！</p><h1 id="ffa9" class="pm nl it bd nm pn px pp np pq py ps ns ki pz kj nv kl qa km ny ko qb kp ob pw bi translated">谢谢你。</h1></div></div>    
</body>
</html>