<html>
<head>
<title>Face Unlock with 2D Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用2D数据进行面部解锁</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/face-unlock-with-2d-data-684b11e5aee1?source=collection_archive---------62-----------------------#2020-10-13">https://towardsdatascience.com/face-unlock-with-2d-data-684b11e5aee1?source=collection_archive---------62-----------------------#2020-10-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/3cf38b072325f4576b39af0996a93065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tpzEZB1QsDmQbn5DnpPllg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Eric TERRADE 在<a class="ae jg" href="https://unsplash.com/s/photos/gioconda?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。世界上最有名的脸！</p></figure><div class=""/><div class=""><h2 id="cd08" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated"><em class="ky">深度学习方法</em></h2></div><p id="737b" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有代码都可以在<a class="ae jg" href="https://github.com/FrancescoSaverioZuppichini/Face-Unlock" rel="noopener ugc nofollow" target="_blank">这里</a>找到。这篇文章的互动版本可以从<a class="ae jg" href="https://github.com/FrancescoSaverioZuppichini/Face-Unlock/blob/main/face_detection.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>下载</p><p id="64c3" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天我们要用深度学习来创建一个人脸解锁算法。为了完成我们的拼图，我们需要三个主要部分。</p><ul class=""><li id="a285" class="lv lw jj lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">一种人脸查找算法</li><li id="c5a7" class="lv lw jj lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">一种在向量空间中嵌入人脸的方法</li><li id="49c5" class="lv lw jj lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">比较编码人脸的函数</li></ul><h1 id="db50" class="mj mk jj bd ml mm mn mo mp mq mr ms mt kp mu kq mv ks mw kt mx kv my kw mz na bi translated">查找面孔</h1><p id="33ef" class="pw-post-body-paragraph kz la jj lb b lc nb kk le lf nc kn lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">首先，我们需要一种在图像中找到人脸的方法。我们可以使用一种叫做<a class="ae jg" href="https://arxiv.org/abs/1604.02878" rel="noopener ugc nofollow" target="_blank"> MTCNN </a>(多任务级联卷积网络)的端到端方法。</p><p id="0ad0" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就一点点技术背景，之所以叫<em class="ng">级联</em>是因为它是由多级组成的，每一级都有它的神经网络。下图显示了该框架。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/507d55c00c040d303877a65818e9b1f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ni4Z9SZSAcdqQwXW"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片来自<a class="ae jg" href="https://arxiv.org/abs/1604.02878" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1604.02878</a></p></figure><p id="8709" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们依赖于来自facenet-pytorch <a class="ae jg" href="https://github.com/timesler/facenet-pytorch" rel="noopener ugc nofollow" target="_blank"> repo </a>的MTCNN实现。</p><h2 id="f7a6" class="nm mk jj bd ml nn no dn mp np nq dp mt li nr ns mv lm nt nu mx lq nv nw mz nx bi translated">数据</h2><p id="cf68" class="pw-post-body-paragraph kz la jj lb b lc nb kk le lf nc kn lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们需要图像！我把自己、莱昂纳多·迪卡普里奥和马特·德蒙的一些照片放在一起。</p><p id="a1de" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">遵循PyTorch最佳实践，我使用<code class="fe ny nz oa ob b">ImageFolder</code>加载数据集。我创建了<code class="fe ny nz oa ob b">MTCNN</code>实例，并使用<code class="fe ny nz oa ob b">transform</code>参数将其传递给数据集。</p><p id="27c6" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的文件夹结构如下:</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="ed1a" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe ny nz oa ob b">MTCNN</code>自动裁剪和调整输入的大小，我使用了一个<code class="fe ny nz oa ob b">image_size=160</code>，因为模型将利用该尺寸的图像进行训练。我还添加了<code class="fe ny nz oa ob b">18</code>像素的空白，以确保我们包括了整张脸。</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><pre class="ni nj nk nl gt oe ob of og aw oh bi"><span id="22b4" class="nm mk jj ob b gy oi oj l ok ol">(tensor([[[ 0.9023, 0.9180, 0.9180, ..., 0.8398, 0.8242, 0.8242], [ 0.9023, 0.9414, 0.9492, ..., 0.8555, 0.8320, 0.8164], [ 0.9336, 0.9805, 0.9727, ..., 0.8555, 0.8320, 0.7930], ..., [-0.7070, -0.7383, -0.7305, ..., 0.4102, 0.3320, 0.3711], [-0.7539, -0.7383, -0.7305, ..., 0.3789, 0.3633, 0.4102], [-0.7383, -0.7070, -0.7227, ..., 0.3242, 0.3945, 0.4023]], [[ 0.9492, 0.9492, 0.9492, ..., 0.9336, 0.9258, 0.9258], [ 0.9336, 0.9492, 0.9492, ..., 0.9492, 0.9336, 0.9258], [ 0.9414, 0.9648, 0.9414, ..., 0.9570, 0.9414, 0.9258], ..., [-0.3633, -0.3867, -0.3867, ..., 0.6133, 0.5352, 0.5820], [-0.3945, -0.3867, -0.3945, ..., 0.5820, 0.5742, 0.6211], [-0.3711, -0.3633, -0.4023, ..., 0.5273, 0.6055, 0.6211]], [[ 0.8867, 0.8867, 0.8945, ..., 0.8555, 0.8477, 0.8477], [ 0.8789, 0.8867, 0.8789, ..., 0.8789, 0.8633, 0.8477], [ 0.8867, 0.9023, 0.8633, ..., 0.9023, 0.8789, 0.8555], ..., [-0.0352, -0.0586, -0.0977, ..., 0.7617, 0.7070, 0.7461], [-0.0586, -0.0586, -0.0977, ..., 0.7617, 0.7617, 0.8086], [-0.0352, -0.0352, -0.1211, ..., 0.7227, 0.8086, 0.8086]]]), 0)</span></pre><p id="4c85" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完美，数据集返回一个张量。让我们想象一下所有的输入。它们已经被MTCNN图像标准化，最后一排的最后三张图像是我自己的自拍:)</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/7edfac3392366fa245ad44a842e784ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/0*mRBlILJWFFTDBTwe"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">我们数据集中的人脸，后三张是我自己的照片！:)作者图片</p></figure><h1 id="1db3" class="mj mk jj bd ml mm mn mo mp mq mr ms mt kp mu kq mv ks mw kt mx kv my kw mz na bi translated">把…嵌入</h1><p id="1d8e" class="pw-post-body-paragraph kz la jj lb b lc nb kk le lf nc kn lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们的数据管道准备好了。为了比较人脸并找出两个是否相似，我们需要在向量空间中对它们进行编码，其中，如果两个人脸相似，与它们相关联的两个向量也相似(接近)。</p><p id="51e5" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用在著名的人脸数据集之一上训练的一个模型，例如<a class="ae jg" href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/" rel="noopener ugc nofollow" target="_blank"> vgg_face2 </a>，并使用分类头之前的最后一层(潜在空间)的输出作为编码器。</p><p id="8dd0" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这些数据集之一上训练的模型必须已经学习了关于输入的重要特征。最后一层(就在完全连接的层之前)对高级特征进行编码。因此，我们可以使用它来将我们的输入嵌入到一个向量空间中，希望在这个空间中，相似的图像彼此靠近。</p><p id="fb73" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具体来说，我们将使用在<code class="fe ny nz oa ob b">vggface2</code>数据集上训练的inception resnet。嵌入空间有<code class="fe ny nz oa ob b">512</code>个维度。</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><pre class="ni nj nk nl gt oe ob of og aw oh bi"><span id="a872" class="nm mk jj ob b gy oi oj l ok ol">torch.Size([8, 512])</span></pre><p id="1c2c" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">太好了，我们有了<code class="fe ny nz oa ob b">8</code>图像和<code class="fe ny nz oa ob b">8</code>向量</p><h1 id="3814" class="mj mk jj bd ml mm mn mo mp mq mr ms mt kp mu kq mv ks mw kt mx kv my kw mz na bi translated">类似</h1><p id="fb92" class="pw-post-body-paragraph kz la jj lb b lc nb kk le lf nc kn lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">为了比较我们的向量，我们可以使用<code class="fe ny nz oa ob b">cosine_similarity</code>来查看它们彼此有多接近<em class="ng"/>。余弦相似度将输出[-1，1]之间的值。在两个比较向量相同的简单情况下，它们的相似度是1。所以越接近1，越相似。</p><p id="e418" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以找到数据集中每对之间的所有距离。</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/5fad688b9d2c0a98957137349909388d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RRAs2rmSg5vQTgxu"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">显示数据集中所有面及其余弦相似性的热图。作者图片</p></figure><p id="76fc" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很明显，我和马特或利奥不太相似，但他们有一些共同点！</p><p id="a039" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以更进一步，对嵌入进行主成分分析，并将图像投影到二维平面上</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oo"><img src="../Images/5bc0c48412f42f37e71afb0cbf7a5af6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ssKGYro6cVwwYFpY"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">使用主成分分析将图像投影到2D平面上。作者图片</p></figure><p id="a6d0" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对这张图片要有所保留。我们将512维压缩为2维，因此我们丢失了大量数据。</p><p id="dcb5" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好了，我们有办法找到人脸，看看他们是否彼此相似，现在我们可以创建我们的人脸解锁算法。</p><p id="f3a3" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的想法是取允许的人的<code class="fe ny nz oa ob b">n</code>张图像，在嵌入空间中找到中心，选择一个阈值，看中心和一张新图像的余弦相似度是小于还是大于它。</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="34ca" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">来测试一下吧！</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/bfdd4c1a0d72d1ad897c080ac724915b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DH2Ab4Ic2lRk9ktd"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">锁定。图片来自<a class="ae jg" href="https://www.timesofisrael.com/in-court-nso-group-accuses-facebook-of-lying-disregarding-international-law/" rel="noopener ugc nofollow" target="_blank">https://www . timesofisrael . com/in-court-NSO-group-控告-Facebook-说谎-无视-国际法/ </a></p></figure><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/9298ae2abd1e4c23f8d62a782911001f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/0*RLd9oGKvHxORMHsO"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">锁定。图片来自<a class="ae jg" href="https://en.wikipedia.org/wiki/Elon_Musk#/media/File:Elon_Musk_Royal_Society.jpg" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Elon _ Musk #/media/File:Elon _ Musk _ Royal _ society . jpg</a></p></figure><p id="6379" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人们说我和《纸牌屋》里的里奥很像</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/997d0b37e36c044782c9dfae791d84cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*D-9EmSrAjXEXdIQ6"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">锁定。图片来自<a class="ae jg" href="https://falauniversidades.com.br/ator-la-casa-de-papel-elite-afastado-por-depressao-miguel-herran/" rel="noopener ugc nofollow" target="_blank">https://falauniversidades . com . br/ator-la-casa-de-papel-elite-afastado-por-depressao-Miguel-herran/</a></p></figure><p id="8123" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相似度得分比之前的图像高，所以我猜是真的！</p><p id="e968" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们试试我自己的新自拍照</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi os"><img src="../Images/77c941c9529e7bf4b2a8c1fe811de95e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/0*mGVTlM0l_6xnuIIg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">解锁。作者图片</p></figure><p id="9719" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">成功了，我加入。</p><h1 id="6713" class="mj mk jj bd ml mm mn mo mp mq mr ms mt kp mu kq mv ks mw kt mx kv my kw mz na bi translated">结论</h1><p id="c77d" class="pw-post-body-paragraph kz la jj lb b lc nb kk le lf nc kn lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们已经看到了一种仅使用2D数据(图像)来创建面部解锁算法的有吸引力的方式。它依靠神经网络在高维向量空间中对裁剪的人脸进行编码，其中相似的人脸彼此靠近。然而，我不知道模型是如何训练的，可能很容易骗过它(即使在我的实验中，算法运行良好)。</p><p id="95e0" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果模型在没有数据增强的情况下被训练会怎样？那么，很可能，简单地翻动同一个人就能破坏潜在表征。</p><p id="e0a9" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个更强大的训练程序将是一个无人监管的程序(类似于<a class="ae jg" href="https://arxiv.org/abs/2006.07733" rel="noopener ugc nofollow" target="_blank"> BYOL </a>)，它严重依赖于数据增强。</p><p id="6254" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。</p><p id="87cf" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">弗朗西斯科</p><p id="6c01" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不明确的</p></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><p id="0bab" class="pw-post-body-paragraph kz la jj lb b lc ld kk le lf lg kn lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【http://github.com】最初发表于<a class="ae jg" href="https://gist.github.com/a484f089227c8d76ba015b0d7c9e15d7" rel="noopener ugc nofollow" target="_blank"><em class="ng"/></a><em class="ng">。</em></p></div></div>    
</body>
</html>