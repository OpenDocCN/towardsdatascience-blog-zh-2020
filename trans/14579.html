<html>
<head>
<title>Machine Learning Visualization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习可视化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-visualization-fcc39a1e376a?source=collection_archive---------6-----------------------#2020-10-08">https://towardsdatascience.com/machine-learning-visualization-fcc39a1e376a?source=collection_archive---------6-----------------------#2020-10-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4cba" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><div class=""><h2 id="7f9c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">收集了一些有趣的技术，可以用来可视化机器学习管道的不同方面。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/a7febec3f75e222a924951b941d2ea83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*T0bkLLop2jOj4V3zzD17BQ.gif"/></div></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ld le l"/></div></figure><h1 id="d8dc" class="lf lg it bd lh li lj lk ll lm ln lo lp ki lq kj lr kl ls km lt ko lu kp lv lw bi translated">介绍</h1><p id="b50a" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">作为任何数据科学项目的一部分，<a class="ae mt" rel="noopener" target="_blank" href="/interactive-data-visualization-167ae26016e8">数据可视化</a>在了解更多可用数据和识别任何主要模式方面发挥着重要作用。</p><blockquote class="mu mv mw"><p id="b49d" class="lx ly mx lz b ma my kd mc md mz kg mf na nb mi mj nc nd mm mn ne nf mq mr ms im bi translated">如果有可能让机器学习也成为分析的一部分，那不是很好吗？</p></blockquote><p id="864c" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">在本文中，我们将探讨一些技术，可以帮助我们面对这一挑战，如:平行坐标图，汇总数据表，绘制人工神经网络图和更多。</p><p id="4b16" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">本文使用的所有代码都可以在我的<a class="ae mt" href="https://github.com/pierpaolo28/Data-Visualization/tree/master/Machine%20Learning%20Visualization" rel="noopener ugc nofollow" target="_blank"> Github </a>和<a class="ae mt" href="https://www.kaggle.com/pierpaolo28/notebooks" rel="noopener ugc nofollow" target="_blank"> Kaggle账户</a>上免费获得。</p><h1 id="0805" class="lf lg it bd lh li lj lk ll lm ln lo lp ki lq kj lr kl ls km lt ko lu kp lv lw bi translated">技术</h1><h2 id="d6f7" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">超参数优化</h2><p id="5279" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">超参数优化是机器/深度学习中最常见的活动之一。机器学习模型调整是一种优化问题。我们有一组超参数(如学习率、隐藏单元数等)，我们的目标是找出它们值的正确组合，这可以帮助我们找到函数的最小值(如损失)或最大值(如精度)。</p><p id="16ba" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">在我之前的文章<a class="ae mt" rel="noopener" target="_blank" href="/hyperparameters-optimization-526348bb8e2d">中，我详细介绍了我们可以在这个领域使用什么样的技术，以及如何在3D空间中测试它们，在这篇文章中，我将向您展示我们如何在2D空间中完成报告。</a></p><p id="f3fe" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">此类任务的最佳解决方案之一是使用<a class="ae mt" href="https://en.wikipedia.org/wiki/Parallel_coordinates" rel="noopener ugc nofollow" target="_blank">平行坐标图</a>(图1)。使用这种类型的图，我们实际上可以很容易地比较不同的变量(如特征)，以发现可能的关系。在超参数优化的情况下，这可以作为一个简单的工具来检查什么参数组合可以给我们最大的测试精度。平行坐标图在数据分析中的另一个可能用途是检查数据框中不同要素之间的值关系。</p><p id="d4db" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">在图1中，有一个使用Plotly创建的实例。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="4ec6" class="ng lg it ns b gy nw nx l ny nz">import plotly.express as px<br/><br/>fig = px.parallel_coordinates(df2, color="mean_test_score", <br/>          labels=dict(zip(list(df2.columns), <br/>          list(['_'.join(i.split('_')[1:]) for i <strong class="ns jd">in </strong>df2.columns]))),<br/>          color_continuous_scale=px.colors.diverging.Tealrose,<br/>          color_continuous_midpoint=27)<br/><br/>fig.show()</span></pre><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oa le l"/></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图1:平行坐标超参数优化图。</p></figure><p id="8c6c" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">可以使用不同的技术在Python中创建平行坐标图，例如使用Pandas、Yellowbrick、Matplotlib或Plotly。使用所有这些不同方法的一步一步的例子都可以在我的笔记本中找到，网址是<a class="ae mt" href="https://www.kaggle.com/pierpaolo28/parallel-coordinates-plots?scriptVersionId=35973765" rel="noopener ugc nofollow" target="_blank">这个链接。</a></p><p id="fd38" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">最后，另一种可能的解决方案是使用<a class="ae mt" href="https://www.wandb.com/articles/hyperparameter-tuning-as-easy-as-1-2-3" rel="noopener ugc nofollow" target="_blank">权重&amp;偏差扫描</a>功能来创建这种类型的图。weights&amp;bias是一款免费工具，可用于为个人或团队自动创建不同机器学习任务的图表和日志(如学习曲线、绘图模型等)。</p><h2 id="1aeb" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">数据包装器</h2><p id="3628" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated"><a class="ae mt" href="https://www.datawrapper.de/" rel="noopener ugc nofollow" target="_blank"> Data Wrapper </a>是一款为专业图表创作设计的免费在线工具。例如，纽约时报、Vox和WIRED等杂志的文章中就使用了这一工具。不需要登录，所有的过程都可以在网上完成。</p><p id="2198" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">今年已经为这个工具额外创建了一个<a class="ae mt" href="https://blog.datawrapper.de/datawrapper-python-package/" rel="noopener ugc nofollow" target="_blank"> Python包装器</a>。这可以通过以下方式轻松安装:</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="9631" class="ng lg it ns b gy nw nx l ny nz">pip install datawrapper</span></pre><p id="b42a" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">为了使用Python API，我们还需要注册Data Wrapper，进入设置并创建一个API密钥。使用这个API键，我们就能够远程使用数据包装器。</p><p id="70ef" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">此时，我们可以很容易地创建一个条形图，例如，通过使用下面几行代码并传递一个Pandas数据帧作为我们的<strong class="lz jd"> <em class="mx"> create_chart </em> </strong>函数的输入。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="ec8e" class="ng lg it ns b gy nw nx l ny nz">from datawrapper import Datawrapper<br/>dw = Datawrapper(access_token = "TODO")</span><span id="f18a" class="ng lg it ns b gy of nx l ny nz"><em class="mx">games_chart = dw.create_chart(title = "Most Frequent Game Publishers", chart_type = 'd3-bars', data = df)</em></span><span id="d47c" class="ng lg it ns b gy of nx l ny nz"><em class="mx">dw.update_description(</em><br/><em class="mx">    games_chart['id'],</em><br/><em class="mx">    source_name = 'Video Game Sales',</em><br/><em class="mx">    source_url = 'https://www.kaggle.com/gregorut/videogamesales',</em><br/><em class="mx">    byline = 'Pier Paolo Ippolito',</em><br/><em class="mx">)</em></span><span id="1095" class="ng lg it ns b gy of nx l ny nz"><em class="mx">dw.publish_chart(games_chart['id'])</em></span></pre><p id="a08c" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">生成的图表如下图所示。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="og le l"/></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图2:数据包装条形图</p></figure><p id="4ba8" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">一旦发布了我们的图表，我们就可以在我们的数据包装器帐户上创建的图表列表中找到它。点击我们的图表，我们会发现一个不同选项的列表，我们可以使用这些选项来轻松地共享我们的图表(例如，嵌入、HTML、PNG等)。所有不同类型的受支持图表的完整列表可在<a class="ae mt" href="https://developer.datawrapper.de/docs/chart-types" rel="noopener ugc nofollow" target="_blank">此链接获得。</a></p><h2 id="f178" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">Plotly预测表</h2><p id="b46c" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">当处理时间序列数据时，能够快速了解我们的模型在哪些数据点上表现不佳，以便尝试了解它可能面临的限制，有时会非常方便。</p><p id="10c8" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">一种可能的方法是创建一个汇总表，其中包含实际值和预测值，以及某种形式的指标，用于总结数据点预测的好坏。</p><p id="4838" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">使用Plotly，这可以通过创建一个绘图函数来轻松完成:</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="2d6d" class="ng lg it ns b gy nw nx l ny nz">import chart_studio.plotly as py<br/>import plotly.graph_objs as go<br/>from plotly.offline import init_notebook_mode, iplot<br/>init_notebook_mode(connected=True)<br/>import plotly</span><span id="59ee" class="ng lg it ns b gy of nx l ny nz">def predreport(y_pred, Y_Test):<br/>    diff = y_pred.flatten() - Y_Test.flatten()<br/>    perc = (abs(diff)/y_pred.flatten())*100<br/>    priority = []<br/>    for i in perc:<br/>        if i &gt; 0.4:<br/>            priority.append(3)<br/>        elif i&gt; 0.1:<br/>            priority.append(2)<br/>        else:<br/>            priority.append(1)</span><span id="91a8" class="ng lg it ns b gy of nx l ny nz">    print("Error Importance 1 reported in ", priority.count(1),<br/>          "cases\n")<br/>    print("Error Importance 2 reported in", priority.count(2), <br/>          "cases\n")                                 <br/>    print("Error Importance 3 reported in ", priority.count(3),    <br/>          "cases\n")<br/>    colors = ['rgb(102, 153, 255)','rgb(0, 255, 0)', <br/>              'rgb(255, 153, 51)', 'rgb(255, 51, 0)']</span><span id="ce32" class="ng lg it ns b gy of nx l ny nz">    fig = go.Figure(data=[go.Table(header=<br/>                    dict(<br/>                        values=['Actual Values', 'Predictions', <br/>                        '% Difference', "Error Importance"],<br/>                        line_color=[np.array(colors)[0]],<br/>                        fill_color=[np.array(colors)[0]],<br/>                                    align='left'),<br/>                    cells=dict(<br/>                       values=[y_pred.flatten(),Y_Test.flatten(),<br/>                               perc, priority], <br/>                       line_color=[np.array(colors)[priority]],<br/>                       fill_color=[np.array(colors)[priority]],  <br/>                                    align='left'))])</span><span id="1ff4" class="ng lg it ns b gy of nx l ny nz">    init_notebook_mode(connected=False)<br/>    py.plot(fig, filename = 'Predictions_Table', auto_open=True)<br/>    fig.show()</span></pre><p id="3427" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">调用这个函数将产生以下输出(请随意测试图3中的表格！):</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="b6e4" class="ng lg it ns b gy nw nx l ny nz">Error Importance 1 reported in  34 cases <br/><br/>Error Importance 2 reported in  13 cases <br/><br/>Error Importance 3 reported in  53 cases</span></pre><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oa le l"/></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图3:预测表</p></figure><h2 id="d2cc" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">决策树</h2><p id="e647" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">决策树是最容易解释的机器学习模型之一。由于它们的基本结构，通过查看树的不同分支上的条件，可以很容易地检查算法如何做出决定。此外，考虑到算法将认为对我们期望的分类/回归任务最有价值的特征放在树的顶层，决策树也可以用作<a class="ae mt" rel="noopener" target="_blank" href="/feature-selection-techniques-1bfab5fe0784">特征选择技术</a>。以这种方式，树底部的特征可以被丢弃，因为携带较少的信息。</p><p id="76e0" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">可视化分类/回归决策树最简单的方法之一是使用<a class="ae mt" href="https://scikit-learn.org/stable/modules/tree.html" rel="noopener ugc nofollow" target="_blank"><strong class="lz jd"><em class="mx">export _ graphviz</em></strong>from<strong class="lz jd"><em class="mx">sk learn . tree</em></strong></a><strong class="lz jd"><em class="mx">。</em> </strong>在本文中，使用<a class="ae mt" href="https://github.com/parrt/dtreeviz" rel="noopener ugc nofollow" target="_blank"> dtreeviz </a>库提供了一种不同且更完整的方法。</p><p id="ca4d" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">使用这个库，只需使用下面几行代码就可以创建一个分类决策树:</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="ac59" class="ng lg it ns b gy nw nx l ny nz">from dtreeviz.trees import *<br/><br/>viz = dtreeviz(clf,<br/>               X_train,<br/>               y_train.values,<br/>               target_name='Genre',<br/>               feature_names=list(X.columns),<br/>               class_names=list(labels.unique()),<br/>               histtype='bar', <br/>               orientation ='TD')<br/>              <br/>viz</span></pre><p id="90dd" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">结果图如图4所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/6ae91a158e0abb14bddac1f23d2f96ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4lBNCeRsjOHSX-3mWnPDQ.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图4:分类决策树</p></figure><p id="d2d2" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">在图4中，不同的类别用不同的颜色表示。所有不同类别的特征分布在树的起始节点中表示。只要我们向下移动每个分支，算法就会尝试使用每个节点图下面描述的功能来最好地分离不同的分布。沿着分布生成的圆表示在跟随某个节点之后被正确分类的元素的数量，元素的数量越大，圆的大小就越大。</p><p id="7bf6" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">图5显示了一个使用决策树回归器的例子。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/135cff6fef1b7e76cac5703763a1b2aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*IFS5wC5tgC2TDVwyOEqqcg.png"/></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图5:决策树回归器</p></figure><h2 id="835e" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">决策界限</h2><p id="c700" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">决策边界是以图形方式理解机器学习模型如何进行预测的最简单方法之一。在Python中绘制决策边界的最简单方法之一是使用<a class="ae mt" href="http://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/" rel="noopener ugc nofollow" target="_blank"> Mlxtend </a>。这个库实际上可以用于绘制机器学习和深度学习模型的决策边界。图6显示了一个简单的例子。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="10ad" class="ng lg it ns b gy nw nx l ny nz">from mlxtend.plotting import plot_decision_regions <br/>import matplotlib.pyplot as plt<br/>import matplotlib.gridspec as gridspec<br/>import itertools</span><span id="b792" class="ng lg it ns b gy of nx l ny nz">gs = gridspec.GridSpec(2, 2)<br/><br/>fig = plt.figure(figsize=(10,8))<br/><br/>clf1 = LogisticRegression(random_state=1,<br/>                          solver='newton-cg',<br/>                          multi_class='multinomial')<br/>clf2 = RandomForestClassifier(random_state=1, n_estimators=100)<br/>clf3 = GaussianNB()<br/>clf4 = SVC(gamma='auto')<br/><br/>labels = ['Logistic Regression','Random Forest','Naive Bayes','SVM']<br/>for clf, lab, grd <strong class="ns jd">in</strong> zip([clf1, clf2, clf3, clf4],<br/>                         labels,<br/>                         itertools.product([0, 1], repeat=2)):<br/><br/>    clf.fit(X_Train, Y_Train)<br/>    ax = plt.subplot(gs[grd[0], grd[1]])<br/>    fig = plot_decision_regions(X_Train, Y_Train, clf=clf, legend=2)<br/>    plt.title(lab)<br/><br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/169ce38caa9392378cc5bc310d878e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f3Uj0P7dwfYeMvjXyv4llg.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图6:绘制决策边界</p></figure><p id="fe94" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">Mlxtend的一些可能的替代方案是:Yellowbrick、Plotly或普通的Sklearn和Numpy实现。使用所有这些不同方法的一步一步的例子都可以在我的笔记本中找到，网址是<a class="ae mt" href="https://www.kaggle.com/pierpaolo28/machine-learning-visualization-5" rel="noopener ugc nofollow" target="_blank">这个链接。</a></p><p id="935f" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">此外，在我的网站<a class="ae mt" href="https://pierpaolo28.github.io/Projects/project9.html" rel="noopener ugc nofollow" target="_blank">链接上可以看到训练期间决策界限融合的不同动画版本。</a></p><p id="b0f2" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">绘制决策边界的主要限制之一是，它们只能在二维或三维中容易地可视化。由于这些限制，在绘制决策边界之前，大多数时候可能需要减少输入特征的维数(使用某种形式的<a class="ae mt" rel="noopener" target="_blank" href="/feature-extraction-techniques-d619b56e31be">特征提取技术</a>)。</p><h2 id="9ca9" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">人工神经网络</h2><p id="f0dc" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">当创建新的神经网络架构时，另一个非常有用的技术是可视化它们的结构。这可以使用<a class="ae mt" href="https://github.com/Prodicode/ann-visualizer" rel="noopener ugc nofollow" target="_blank"> ANN Visualiser </a>轻松完成(图7)。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="8357" class="ng lg it ns b gy nw nx l ny nz">from keras.models import Sequential<br/>from keras.layers import Dense<br/>from ann_visualizer.visualize import ann_viz<br/><br/>model = Sequential()<br/>model.add(Dense(units=4,activation='relu',<br/>                  input_dim=7))<br/>model.add(Dense(units=4,activation='sigmoid'))<br/>model.add(Dense(units=2,activation='relu'))<br/><br/>ann_viz(model, view=True, filename="example", title="Example ANN")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/c8df5b32a6182847e6f0bb40fd01a8e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CRJhzs40uqgeOmkm26oncA.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图7:人工神经网络图</p></figure><h2 id="2702" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">活线图</h2><p id="0df5" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">在训练和验证过程中，能够自动绘制实时神经网络损失和准确性，这对于立即查看网络是否随着时间推移取得任何进展非常有帮助。这可以通过使用<a class="ae mt" href="https://github.com/stared/livelossplot" rel="noopener ugc nofollow" target="_blank"> Livelossplot </a>轻松完成。</p><p id="2154" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">在图8中，提供了一个在Pytorch中实时创建的损耗图示例，同时训练一个变分自动编码器(VAE)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/fdf1750bfc19e3ada8b2bed70af5dd7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*kE4SGSkjhsF7LbHQAvmQDg.gif"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图8:现场VAE培训</p></figure><p id="84cc" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">使用Livelossplot，这可以通过将我们想要记录的所有指标存储在一个字典中并在每次迭代结束时更新绘图来轻松完成。如果我们对创建多个图表感兴趣，可以应用相同的过程(例如，一个用于损失，一个用于总体精度)。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="8abd" class="ng lg it ns b gy nw nx l ny nz">from livelossplot import PlotLosses</span><span id="9768" class="ng lg it ns b gy of nx l ny nz">liveloss = PlotLosses()</span><span id="9d03" class="ng lg it ns b gy of nx l ny nz">for epoch in range(epochs):<br/>    logs = {}<br/>    for phase in ['train', 'val']:<br/>        losses = []<br/>        <br/>        if phase == 'train':<br/>            model.train()<br/>        else:<br/>            model.eval()<br/>        <br/>        for i, (inp, _) in enumerate(dataloaders[phase]):<br/>            out, z_mu, z_var = model(inp)<br/>            rec=F.binary_cross_entropy(out,inp,reduction='sum')/<br/>                                       inp.shape[0]<br/>            kl=-0.5*torch.mean(1+z_var-z_mu.pow(2)-torch.exp(z_mu))<br/>            loss = rec + kl<br/>            losses.append(loss.item())<br/>        <br/>            if phase == 'train':<br/>                optimizer.zero_grad()<br/>                loss.backward()<br/>                optimizer.step()<br/>        <br/>        prefix = ''<br/>        if phase == 'val':<br/>            prefix = 'val_'</span><span id="d999" class="ng lg it ns b gy of nx l ny nz">        logs[prefix + 'loss'] = np.mean(losses)</span><span id="686b" class="ng lg it ns b gy of nx l ny nz">    liveloss.update(logs)<br/>    liveloss.send()</span></pre><p id="91dd" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">Livelossplot还可以与其他库一起使用，如Keras、Pytorch-Lightin、Bokeh等</p><h2 id="5a38" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">可变自动编码器</h2><p id="fe9b" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">变分自动编码器(VAE)是一种概率生成模型，用于创建一些输入数据(例如图像)的潜在表示，能够简明地理解原始数据并从中生成全新的数据(例如，用汽车设计的不同图像训练VAE模型，然后使模型能够创建全新的富有想象力的汽车设计)。</p><p id="6592" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">继续使用Livelossplot训练的示例variable auto encoder，我们甚至可以通过检查潜在空间(图9)如何从一次迭代到另一次迭代而变化(以及因此我们的模型在区分不同类别方面随着时间的推移改进了多少)来使我们的模型更有趣。</p><p id="be03" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">这可以通过在之前的训练循环中添加以下函数来轻松完成:</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="d96c" class="ng lg it ns b gy nw nx l ny nz">def latent_space(model, train_set, it=''):<br/>    x_latent = model.enc(train_set.data.float())<br/>    plt.figure(figsize=(10, 7))<br/>    plt.scatter(x_latent[0][:,0].detach().numpy(), <br/>                x_latent[1][:,1].detach().numpy(), <br/>                c=train_set.targets)<br/>    plt.colorbar()<br/>    plt.title("VAE Latent Space", fontsize=20)<br/>    plt.xlabel("X", fontsize=18)<br/>    plt.ylabel("Y", fontsize=18)<br/>    plt.savefig('VAE_space'+str(it)+'.png', format='png', dpi=200)<br/>    plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/a7febec3f75e222a924951b941d2ea83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*T0bkLLop2jOj4V3zzD17BQ.gif"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图9: VAE潜在空间演变</p></figure><p id="1c0f" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">最后，可以应用类似的程序来实时可视化我们的VAE在生成真实图像时是如何逐迭代改进的(图10)。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="2295" class="ng lg it ns b gy nw nx l ny nz">def manifold(model, it='', n=18, size=28): <br/>    result = torch.zeros((size * n, size * n))</span><span id="1678" class="ng lg it ns b gy of nx l ny nz">    # Defyining grid space<br/>    s, s2 = torch.linspace(-7, 7, n), torch.linspace(7, -7, n)<br/>    grid_x, grid_y = torch.std(s)*s, torch.std(s2)*s2</span><span id="9f68" class="ng lg it ns b gy of nx l ny nz">    for i, y_ex in enumerate(grid_x):<br/>        for j, x_ex in enumerate(grid_y):<br/>            z_sample = torch.repeat_interleave(torch.tensor([<br/>                       [x_ex, y_ex]]),repeats=batch_size, dim=0)<br/>            x_dec = model.dec(z_sample)<br/>            element = x_dec[0].reshape(size, size).detach()<br/>            result[i * size: (i + 1) * size, <br/>                   j * size: (j + 1) * size] = element</span><span id="f1c8" class="ng lg it ns b gy of nx l ny nz">    plt.figure(figsize=(12, 12))<br/>    plt.title("VAE Samples", fontsize=20)<br/>    plt.xlabel("X", fontsize=18)<br/>    plt.ylabel("Y", fontsize=18)<br/>    plt.imshow(result, cmap='Greys')<br/>    plt.savefig('VAE'+str(it)+'.png', format='png', dpi=300)<br/>    plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/d731e05493d7a9a629ef04ca82f678d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*5plD-hrElRvhqn12A0Q6XA.gif"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图10:随着时间的推移，创造新数字的VAE改进</p></figure><p id="3b9c" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">一个使用ONNX在线部署的变分自动编码器的实际演示，可以在我的个人网站上的<a class="ae mt" href="https://pierpaolo28.github.io/Projects/ONNX/home.html?fbclid=IwAR13tKnQFfobSq4udV-N9FMfFZ6wUmAvU7GVn5yl0Cj4ttOw3uyl6TNNbMw" rel="noopener ugc nofollow" target="_blank">链接获得。</a></p><h2 id="5670" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">单词嵌入</h2><p id="2f5f" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">神经网络嵌入是一类神经网络，旨在学习如何将某种形式的分类数据转换为数字数据。考虑到在转换数据时，他们能够了解数据的特征，因此构建更简洁的表示(创建潜在空间)，使用嵌入比使用其他技术(如一个热编码)更有优势。两种最著名的预训练单词嵌入类型是word2vec和Glove。</p><p id="eb89" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">作为一个简单的例子，我们现在要绘制一个嵌入空间来表示不同的书籍作者。首先，我们需要在一些可用的数据上创建一个训练模型，然后访问模型嵌入层的训练好的权重(在这种情况下称为<strong class="lz jd"> <em class="mx">嵌入</em> </strong>)并将它们存储在一个数据帧中。这个过程完成后，我们只需绘制三个不同的坐标(图11)。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="ce84" class="ng lg it ns b gy nw nx l ny nz">import matplotlib.pyplot as plt<br/>from mpl_toolkits.mplot3d import axes3d, Axes3D</span><span id="a0f0" class="ng lg it ns b gy of nx l ny nz">embedding_weights=pd.DataFrame(model.embed.weight.detach().numpy())<br/>embedding_weights.columns = ['X1','X2','X3']</span><span id="e527" class="ng lg it ns b gy of nx l ny nz">fig = plt.figure(num=None, figsize=(14, 12), dpi=80, <br/>                 facecolor='w', edgecolor='k')<br/>ax = plt.axes(projection='3d')<br/>for index, (x, y, z) in enumerate(zip(embedding_weights['X1'], <br/>                                      embedding_weights['X2'], <br/>                                      embedding_weights['X3'])):<br/>    ax.scatter(x, y, z, color='b', s=12)<br/>    ax.text(x, y, z, str(df.authors[index]), size=12, <br/>            zorder=2.5, color='k')</span><span id="669e" class="ng lg it ns b gy of nx l ny nz">ax.set_title("Word Embedding", fontsize=20)<br/>ax.set_xlabel("X1", fontsize=20)<br/>ax.set_ylabel("X2", fontsize=20)<br/>ax.set_zlabel("X3", fontsize=20)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/5181bd54d83a7cd0da702da8581a96b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*i3WMsuUNkXuJ9JWszK9Vnw.gif"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图11:单词嵌入</p></figure><p id="5a65" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">在这个例子中，网络的嵌入维度已经被直接设置为3，以便随后容易地创建3D可视化。另一个可能的解决方案是使用更高的嵌入输出大小，然后应用某种形式的<a class="ae mt" rel="noopener" target="_blank" href="/feature-extraction-techniques-d619b56e31be">特征提取技术</a>(例如t-SNE、PCA等)来可视化结果。</p><p id="e3f6" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">另一个可以用来可视化分类数据的有趣技术是单词云(图12)。例如，这种类型的表示可以通过创建图书作者姓名及其各自在数据集中的频率计数的字典来实现。在数据集中出现频率较高的作者将在图中以更大的字体显示。</p><pre class="ks kt ku kv gt nr ns nt nu aw nv bi"><span id="393c" class="ng lg it ns b gy nw nx l ny nz">from wordcloud import WordCloud</span><span id="de63" class="ng lg it ns b gy of nx l ny nz">d = {}<br/>for x, a in zip(df.authors.value_counts(),<br/>                df.authors.value_counts().index):<br/>    d[a] = x</span><span id="97e5" class="ng lg it ns b gy of nx l ny nz">wordcloud = WordCloud()<br/>wordcloud.generate_from_frequencies(frequencies=d)<br/>plt.figure(num=None, figsize=(12, 10), dpi=80, facecolor='w',<br/>           edgecolor='k')<br/>plt.imshow(wordcloud, interpolation="bilinear")<br/>plt.axis("off")<br/>plt.title("Word Cloud", fontsize=20)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/f963a53409156f6be3a79ca8df29a230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WftwV6bJMhbWMoSm_2Kbcg.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">图12: Wordcloud示例</p></figure><p id="3645" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">和往常一样，完整的代码可以在我的<a class="ae mt" href="https://github.com/pierpaolo28/Data-Visualization/tree/master/Machine%20Learning%20Visualization" rel="noopener ugc nofollow" target="_blank"> Github账户</a>上找到。</p><h2 id="7de9" class="ng lg it bd lh nh ni dn ll nj nk dp lp mg nl nm lr mk nn no lt mo np nq lv iz bi translated">可解释的人工智能</h2><p id="950c" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated"><a class="ae mt" rel="noopener" target="_blank" href="/need-for-explainability-in-ai-and-robotics-75dc6077c9fa">可解释的人工智能</a>如今是一个不断发展的研究领域。人工智能在决策应用(如就业)中的使用最近引起了个人和当局的一些关注。这是因为，当使用深度神经网络时，当前不可能(至少在完全程度上)理解算法在必须执行预定任务时执行的决策过程。由于决策过程缺乏透明度，公众可能会对模型本身的可信度产生困惑。因此，为了防止在人工智能模型中出现任何形式的偏见，对可解释人工智能的需求正在成为下一个预定的进化步骤。</p><p id="2855" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">在过去的几年中，为了使机器学习更容易解释，已经引入了不同的可视化技术，例如:</p><ul class=""><li id="6e11" class="op oq it lz b ma my md mz mg or mk os mo ot ms ou ov ow ox bi translated">探索卷积神经网络滤波器和特征映射。</li><li id="d969" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated">图形网络。</li><li id="bdaa" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated">基于贝叶斯的模型。</li><li id="63a9" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated">应用于机器学习的因果推理。</li><li id="d52c" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated">本地/全球代理模型。</li><li id="c6c3" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated">引入局部可解释的模型不可知解释(LIME)和Shapley值。</li></ul><p id="5658" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">如果你有兴趣了解更多关于如何使机器学习模型更具可解释性的信息，目前Python中最有趣的两个库是Pytorch的<a class="ae mt" href="https://captum.ai/" rel="noopener ugc nofollow" target="_blank"> Captum </a>和<a class="ae mt" href="https://github.com/EthicalML/XAI" rel="noopener ugc nofollow" target="_blank"> XAI </a>。</p><p id="f592" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">由于这一研究领域在不断改进，我将致力于在未来的一篇专门讨论可解释人工智能的文章中涵盖所有这些不同的主题(以及更多)。</p><h1 id="3dea" class="lf lg it bd lh li lj lk ll lm ln lo lp ki lq kj lr kl ls km lt ko lu kp lv lw bi translated">结论</h1><p id="92ad" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">如果您有兴趣了解更多机器学习可视化技术，Python<a class="ae mt" href="https://www.scikit-yb.org/en/latest/" rel="noopener ugc nofollow" target="_blank">yellow brick library</a>高度关注这个主题。提供的可视化工具的一些例子是:特征排序、ROC/AUC曲线、K肘图和各种文本可视化技术。</p><p id="c8ae" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated">最后，在过去的几年里，为了使机器学习可视化更容易，不同的框架已经开始被开发，例如:<a class="ae mt" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank"> TensorBoard </a>、<a class="ae mt" href="https://www.wandb.com/" rel="noopener ugc nofollow" target="_blank">Weights&amp;bias</a>和<a class="ae mt" href="https://neptune.ai/" rel="noopener ugc nofollow" target="_blank"> Neptune.ai </a>。</p></div><div class="ab cl pd pe hx pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="im in io ip iq"><p id="307b" class="pw-post-body-paragraph lx ly it lz b ma my kd mc md mz kg mf mg nb mi mj mk nd mm mn mo nf mq mr ms im bi translated"><em class="mx">希望您喜欢这篇文章，感谢您的阅读！</em></p><h1 id="3416" class="lf lg it bd lh li lj lk ll lm ln lo lp ki lq kj lr kl ls km lt ko lu kp lv lw bi translated">联系人</h1><p id="010f" class="pw-post-body-paragraph lx ly it lz b ma mb kd mc md me kg mf mg mh mi mj mk ml mm mn mo mp mq mr ms im bi translated">如果你想了解我最新的文章和项目<a class="ae mt" href="https://medium.com/@pierpaoloippolito28?source=post_page---------------------------" rel="noopener">，请在Medium </a>上关注我，并订阅我的<a class="ae mt" href="http://eepurl.com/gwO-Dr?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">邮件列表</a>。以下是我的一些联系人详细信息:</p><ul class=""><li id="6116" class="op oq it lz b ma my md mz mg or mk os mo ot ms ou ov ow ox bi translated"><a class="ae mt" href="https://uk.linkedin.com/in/pier-paolo-ippolito-202917146?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="2acb" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated"><a class="ae mt" href="https://pierpaolo28.github.io/blog/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">个人博客</a></li><li id="4a95" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated"><a class="ae mt" href="https://pierpaolo28.github.io/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">个人网站</a></li><li id="123c" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated"><a class="ae mt" href="https://towardsdatascience.com/@pierpaoloippolito28?source=post_page---------------------------" rel="noopener" target="_blank">中等轮廓</a></li><li id="10f1" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated">GitHub </li><li id="0170" class="op oq it lz b ma oy md oz mg pa mk pb mo pc ms ou ov ow ox bi translated"><a class="ae mt" href="https://www.kaggle.com/pierpaolo28?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">卡格尔</a></li></ul></div></div>    
</body>
</html>