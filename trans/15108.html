<html>
<head>
<title>Getting Started With Sentiment Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">情感分析入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-sentiment-analysis-731531ec880d?source=collection_archive---------29-----------------------#2020-10-17">https://towardsdatascience.com/getting-started-with-sentiment-analysis-731531ec880d?source=collection_archive---------29-----------------------#2020-10-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c64b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/nlpnotes" rel="noopener" target="_blank">自然语言处理笔记</a></h2><div class=""/><div class=""><h2 id="024c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">自然语言处理专业课程1第1周笔记</h2></div><p id="92ef" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在我的前两个帖子之后，我认为我们有必要开始一条新的道路。我们将一起浏览自然语言处理中的基本概念，作为新手的起步，并提醒长期从业者决定阅读的时间——从情感分析开始。</p><blockquote class="ln lo lp"><p id="4830" class="kr ks lq kt b ku kv kd kw kx ky kg kz lr lb lc ld ls lf lg lh lt lj lk ll lm im bi translated"><strong class="kt jd">注</strong>:这个系列的帖子将由我从Coursera 上的<a class="ae lu" href="https://www.coursera.org/specializations/natural-language-processing" rel="noopener ugc nofollow" target="_blank">自然语言处理专业中摘掉的笔记创建，我添加了额外的东西，因为我认为它很有用。</a></p></blockquote><p id="576b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">前两个帖子:</strong></p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/the-importance-of-branding-in-data-science-467b2d2b1e7f"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd jd gy z fp md fr fs me fu fw jc bi translated">品牌在数据科学中的重要性</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">最近，一个特别的话题在我和朋友的讨论中反复出现。品牌的重要性！我…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm mn ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/the-specialized-data-scientist-will-win-in-the-long-run-22c47342aa00"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd jd gy z fp md fr fs me fu fw jc bi translated">从长远来看，专业化的“数据科学家”将会胜出</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">成为专家会比成为多面手让你走得更远</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mo l mj mk ml mh mm mn ly"/></div></div></a></div><p id="0084" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在我们笔记中给出的例子中，我们打算用逻辑回归模型来拟合我们的特征。我不会深入研究逻辑回归的内部工作原理，但是如果你非常感兴趣，你可以从头开始阅读“<a class="ae lu" rel="noopener" target="_blank" href="/algorithms-from-scratch-logistic-regression-7bacdfd9738e"> <em class="lq">算法:逻辑回归</em> </a>”。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/algorithms-from-scratch-logistic-regression-7bacdfd9738e"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd jd gy z fp md fr fs me fu fw jc bi translated">从零开始的算法:逻辑回归</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">与普遍的看法相反，我在此声明，逻辑回归不是一个分类算法(就其本身而言)…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mp l mj mk ml mh mm mn ly"/></div></div></a></div></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><h2 id="0ea1" class="mx my it bd mz na nb dn nc nd ne dp nf la ng nh ni le nj nk nl li nm nn no iz bi translated">情感分析</h2><p id="191e" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">情感分析的目标是使用自然语言处理和机器学习来解释和分类主观数据。</p><p id="41a0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">随着世界变得更加数字化，情绪分析在今天的商业中是一项非常重要的技能，自新冠肺炎以来更是如此。许多企业采用情感分析来检测社会数据，更好地了解他们的品牌声誉，了解他们在数字世界中的客户。</p><p id="3d00" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">例如，一个企业(或任何人)可能会决定使用情感分析来自动确定关于他们公司(或任何东西)的推文的极性，以便更好地了解他们品牌的声誉；这个任务可以定义为一个监督学习问题，我们将输入特征输入到一个预测模型中，然后得到一个输出。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi nu"><img src="../Images/61eee3a76abbbc61326c18ac32bb394e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pWlZS0JxEJKEKhfzV_DJdw.png"/></div></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="bd oj">图1 </strong>:情感分析问题</p></figure><p id="a178" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了让我们执行情感分析，我们必须首先将我们的文本表示为特征(我们在图1中表示为X)，因为计算机不理解文本，在我们可以使用它来分类文本之前。</p><p id="400e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">那么，<strong class="kt jd">我们如何提取特征呢？</strong>很棒的问题。方法有很多。然而，在我们提取我们的特征并建立逻辑回归模型来分类我们数据的情感之前，我们必须讨论文本预处理。</p><h2 id="9104" class="mx my it bd mz na nb dn nc nd ne dp nf la ng nh ni le nj nk nl li nm nn no iz bi translated">文本预处理</h2><p id="dcaa" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">互联网上的文本通常被定义为非结构化数据——非结构化数据是没有预定义的数据模型或者没有以预定义的方式组织的信息(来源:<a class="ae lu" href="https://en.wikipedia.org/wiki/Unstructured_data" rel="noopener ugc nofollow" target="_blank">维基百科</a>)。因此，文本预处理就是将我们的文本组织成预定义的方式或预定义的数据模型。</p><p id="d59f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">有各种各样的技术可以用来预处理我们的文本，但是在这篇文章中，我们将主要关注其中的几种；</p><p id="7a8c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">小写</strong></p><p id="7ded" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这可能是最简单的文本预处理形式，我们可以确保所有的文本都是小写的。这种技术适用于许多文本挖掘和自然语言处理任务，当数据集很小时，这种技术非常有用。</p><figure class="nv nw nx ny gt nz"><div class="bz fp l di"><div class="ok ol l"/></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="ak">图2 </strong>:小写示例</p></figure><p id="48f6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">值得注意的是，尽管小写通常是一种标准做法，但在某些情况下，保持大写是很重要的。</p><p id="6dc1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">词干</strong></p><p id="3a7c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">当我们“词干”一个词形变化——<em class="lq">在语言形态学中，词形变化是一个构词的过程，在这个过程中，一个词被修饰以表达不同的语法范畴，如时态、格、语态、体、人称、数、性别、语气、动物性、确定性(来源:</em> <a class="ae lu" href="https://en.wikipedia.org/wiki/Inflection" rel="noopener ugc nofollow" target="_blank"> <em class="lq">维基百科</em> </a> <em class="lq">)。例如，who变成了who的</em>——我们把它简化为词根形式。</p><p id="9047" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">有许多不同的词干提取算法，但是最常见和最有效的英语词干提取算法是Porters算法。</p><figure class="nv nw nx ny gt nz"><div class="bz fp l di"><div class="ok ol l"/></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="ak">图3 </strong>:用PorterStemmer在Python中进行词干分析</p></figure><p id="4f37" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">词干通常对处理稀疏性和/或标准化词汇很有用。</p><p id="6981" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">词汇化</strong></p><p id="7d8e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">词汇化通常是指使用词汇和单词的形态学分析来正确地做事情，通常旨在仅删除屈折词尾，并返回单词的基本形式或字典形式，这被称为词汇(来源:<a class="ae lu" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">Stanford NLP Group</a>)。</p><p id="ee9c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">简单地说，词汇化旨在消除词尾变化，并以适当的方式将单词映射到其词根。</p><figure class="nv nw nx ny gt nz"><div class="bz fp l di"><div class="ok ol l"/></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="ak">图4 </strong>:使用WordNetLemmatizer的词汇化示例</p></figure><blockquote class="ln lo lp"><p id="ca32" class="kr ks lq kt b ku kv kd kw kx ky kg kz lr lb lc ld ls lf lg lh lt lj lk ll lm im bi translated"><strong class="kt jd">注意</strong>:不要犯交替使用词干化和词汇化的错误——词汇化会对单词进行词法分析。</p></blockquote><p id="838b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">停用词</strong></p><p id="7c46" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">停用词是语言中的常用词。这些词通常被认为是对文本没有任何意义的词(它们不重要)，因此我们要把它们去掉。</p><figure class="nv nw nx ny gt nz"><div class="bz fp l di"><div class="ok ol l"/></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="ak">图5</strong>:NLTK中的停用词列表</p></figure><p id="5648" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">删除停用词并不总是有效的策略。在某些情况下，移除停用词往往是有用的，例如主题提取，但在各种分类任务中，我们可以通过保留停用词来获得有用的见解。</p><p id="f57a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">正常化</strong></p><p id="2a3c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在文本可能有很多噪音的环境中，例如twitter和文本消息，规范化文本往往是一个重要但被忽视的步骤——我所说的噪音环境是指非正式很常见的地方。当我们规格化文本时，我们将文本转换成标准形式(即nvm变成nevermind)。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div class="gh gi om"><img src="../Images/18ef4c8594552299f5c121d3b0af8931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*3u2WuyeBGpokWXdWHwAAlg.png"/></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="bd oj">图6: </strong>文本的规范化(<strong class="bd oj">来源</strong>:<a class="on oo ep" href="https://medium.com/u/cd869a6dee38?source=post_page-----731531ec880d--------------------------------" rel="noopener" target="_blank">Kavita Ganesan</a>—<a class="ae lu" rel="noopener" target="_blank" href="/all-you-need-to-know-about-text-preprocessing-for-nlp-and-machine-learning-bc1c5765ff67">关于NLP和机器学习的文本预处理你需要知道的一切</a></p></figure><p id="d0fb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">文本规范化与词干化和词条化一样，没有标准的方法。这完全取决于手头的任务，因为我们不会像标准化讲课笔记那样标准化我们的短信(考虑到我们以非标准的方式记笔记)。</p><p id="85d3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">噪声去除</strong></p><p id="0ea2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">噪音会严重干扰我们的文本分析。例如，tweets通常包含各种各样的特殊字符，当我们做进一步的预处理步骤时，这些字符可能会损害我们的结果。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi op"><img src="../Images/243d3d9f96c387e845cbf855fb510b4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x5gfTIYCAPDPk9dXgEHI0A.png"/></div></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="bd oj">图7 </strong>:去噪前的词干处理与去噪后的词干处理—原始图片来自<a class="on oo ep" href="https://medium.com/u/cd869a6dee38?source=post_page-----731531ec880d--------------------------------" rel="noopener" target="_blank">卡维塔·加内桑</a> — <a class="ae lu" rel="noopener" target="_blank" href="/all-you-need-to-know-about-text-preprocessing-for-nlp-and-machine-learning-bc1c5765ff67">关于自然语言处理和机器学习的文本预处理，你需要知道的一切</a></p></figure><p id="c2c3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">有各种形式的噪音要从我们的文本中去除；</p><ul class=""><li id="b11d" class="oq or it kt b ku kv kx ky la os le ot li ou lm ov ow ox oy bi translated">特殊字符</li><li id="3760" class="oq or it kt b ku oz kx pa la pb le pc li pd lm ov ow ox oy bi translated">数字</li><li id="9177" class="oq or it kt b ku oz kx pa la pb le pc li pd lm ov ow ox oy bi translated">超文本标记语言</li><li id="68f6" class="oq or it kt b ku oz kx pa la pb le pc li pd lm ov ow ox oy bi translated">特定领域关键词(例如，RT表示Twitter上的转发)</li><li id="d2ce" class="oq or it kt b ku oz kx pa la pb le pc li pd lm ov ow ox oy bi translated">其他(还有很多)</li></ul><p id="dfb8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们移除哪些是领域特定的，哪些被确定为我们手头任务的“噪声”。</p><blockquote class="ln lo lp"><p id="125f" class="kr ks lq kt b ku kv kd kw kx ky kg kz lr lb lc ld ls lf lg lh lt lj lk ll lm im bi translated"><strong class="kt jd">注</strong>:关于文本预处理的更多内容，我强烈推荐你阅读<strong class="kt jd"> Kavita Ganesan </strong>的《<a class="ae lu" rel="noopener" target="_blank" href="/all-you-need-to-know-about-text-preprocessing-for-nlp-and-machine-learning-bc1c5765ff67"> <em class="it">关于自然语言处理和机器学习的文本预处理</em> </a>》。</p></blockquote><h2 id="3eff" class="mx my it bd mz na nb dn nc nd ne dp nf la ng nh ni le nj nk nl li nm nn no iz bi translated">特征提取</h2><p id="86c3" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">在将文本传递给逻辑回归模型之前，我们必须首先将文本表示为一个向量。我们有许多方法将文本表示为向量，但是对于我们的任务(情感分析)，我们将看两个向量表示；</p><ul class=""><li id="f6b1" class="oq or it kt b ku kv kx ky la os le ot li ou lm ov ow ox oy bi translated">一个热编码</li><li id="3fde" class="oq or it kt b ku oz kx pa la pb le pc li pd lm ov ow ox oy bi translated">正负频率</li></ul><p id="7ef1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">一键编码</strong></p><p id="45f8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了做到这一点，我们必须创造一个词汇。这可以通过从我们的数据中的每一条推文中创建一个独特的单词列表来实现。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi pe"><img src="../Images/8c2d0234b4f4c71b29390cf079047f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aa2TJlq_V_CfJJOKAmOs_w.png"/></div></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="bd oj">图8 </strong>:创建词汇表我们检查每条推文的每个单词，并向词汇表V添加单词，前提是该单词不在我们的词汇表中。</p></figure><p id="63ef" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了提取特征，我们提取一条推文，并将其标记为“1 ”,以表明我们词汇表中的单词出现在推文中，如果我们词汇表中的单词没有出现在推文中，则标记为“0 ”,参见<strong class="kt jd">图9。</strong></p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi pf"><img src="../Images/ad4dca3995c5eb508e0b3e868f10ce17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ax1b_hWnt3H6yn0BottcJw.png"/></div></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="bd oj">图9 </strong>:获取一条推文，并显示该推文在被应用一热编码后的特征向量。</p></figure><p id="9f5e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由于我们的tweet的向量长度为V(我们数据集中所有唯一的单词)，并且对于我们选择显示的特定tweet，它们只有5个值为1的特征(“我讨厌去上学”)，但有许多0(长度为V-5)，我们有所谓的稀疏向量表示，简单地说就是我们有大量的零，因此我们占用了不需要的空间来存储零。</p><p id="591c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果我们在我们的稀疏表示上训练我们的逻辑回归模型，我们的模型将不得不学习n + 1(对于偏差)个参数，其中n等于我们的词汇的大小V。随着V变得越来越大，我们将面临两个主要问题；</p><ul class=""><li id="151b" class="oq or it kt b ku kv kx ky la os le ot li ou lm ov ow ox oy bi translated">训练模型需要很长时间</li><li id="0f44" class="oq or it kt b ku oz kx pa la pb le pc li pd lm ov ow ox oy bi translated">推理时间长</li></ul><p id="7876" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">正&amp;负频率</strong></p><p id="ced3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">克服稀疏表示问题的一种技术是将向量转换为正负频率计数。更具体地说，给定一个单词，我们想要跟踪该单词在正面类中出现的次数，给定另一个单词，跟踪该单词在负面类中出现的次数。有了这些计数，我们可以提取特征，并将它们用作Logisitc回归模型的输入特征。</p><p id="1d7e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了执行正负频率技术，我们必须首先创建一个频率字典——频率字典只是给定目标标签的单词计数的映射。例如，我们有自己的词汇，我们计算一个词在正面推文中出现的次数，我们对负面推文也这样做。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi pg"><img src="../Images/8e6f9a18b10430d0c8289ae132d18c42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rLavf-KHSuql4wfSXwJb7g.png"/></div></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="bd oj">图10 </strong>:单词词典</p></figure><p id="aa97" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了将这转化为一个特征，我们简单地对推文中的每个词取正频率之和，然后取负频率之和——见<strong class="kt jd">图11 </strong>。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi ph"><img src="../Images/4b1e111b03516fb170f937ccac866c1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wgZflJwxybV3sQbHMyQyhQ.png"/></div></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="bd oj">图11 </strong>:对于每条推文，输入特征将是【偏差，正词频，负词频】。</p></figure><p id="c409" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因此，我们有一个直观的例子，我们将以tweet“我很难过，我不高”为例(因此<strong class="kt jd">Xm</strong>=“<em class="lq">我很难过，我不高</em>”)。在<strong class="kt jd">图5 </strong>中，我们可以看到单词在整个数据集中出现的频率，分为正类和负类，因此我们所要做的就是获取我们的tweet，并计算每个单词出现的次数——参见<strong class="kt jd">图12 </strong>。</p><figure class="nv nw nx ny gt nz gh gi paragraph-image"><div role="button" tabindex="0" class="oa ob di oc bf od"><div class="gh gi pi"><img src="../Images/f9a852aea7e43ca7c839f7c0604cf9bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9bUktTveKO6jdkzven73XQ.png"/></div></div><p class="of og gj gh gi oh oi bd b be z dk translated"><strong class="bd oj">图12 </strong>:提取推文“我很难过，我不高”的特征</p></figure><p id="dab1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因此，我们的逻辑回归模型的输入特征将是[1(偏差)，4 (PostiveWordCount)，10 (NegativeWordCount)]。</p><h2 id="b825" class="mx my it bd mz na nb dn nc nd ne dp nf la ng nh ni le nj nk nl li nm nn no iz bi translated">包裹</h2><p id="ac1d" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">通过这篇文章，你现在知道了各种预处理方法和两种提取特征的方法，我们可以将这些特征传递给一个逻辑回归模型。实践今天所学内容的一个好方法是在真实数据上尝试。</p><p id="5acf" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们继续LinkedIn上的对话:</p><div class="lv lw gp gr lx ly"><a href="https://www.linkedin.com/in/kurtispykes/" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd jd gy z fp md fr fs me fu fw jc bi translated">Kurtis Pykes -人工智能作家-走向数据科学| LinkedIn</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">在世界上最大的职业社区LinkedIn上查看Kurtis Pykes的个人资料。Kurtis有一个工作列在他们的…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.linkedin.com</p></div></div><div class="mh l"><div class="pj l mj mk ml mh mm mn ly"/></div></div></a></div></div></div>    
</body>
</html>