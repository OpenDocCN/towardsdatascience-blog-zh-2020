<html>
<head>
<title>Active and Semi-Supervised machine learning: Sep 28–Oct 9</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主动和半监督机器学习:9月28日至10月9日</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/active-and-semi-supervised-machine-learning-sep-28-oct-9-50813688c616?source=collection_archive---------72-----------------------#2020-10-13">https://towardsdatascience.com/active-and-semi-supervised-machine-learning-sep-28-oct-9-50813688c616?source=collection_archive---------72-----------------------#2020-10-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="1d16" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">主动学习时事通讯</h2><div class=""/><div class=""><h2 id="75df" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">关于主动(偶尔半监督或弱监督)深度学习的最新arXiv预印本精选</h2></div><p id="66b4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">前一期:</p><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/active-and-semi-supervised-machine-learning-sep-14-25-93f19ff60fb1"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">主动和半监督机器学习:9月14日至25日</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">关于主动(偶尔半监督或弱监督)深度学习的最新arXiv预印本精选</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me mf lq"/></div></div></a></div><p id="b0d9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae mg" href="https://towardsdatascience.com/tagged/active-learning-news" rel="noopener" target="_blank">你也可以在这里找到我迄今为止所有的主动学习简讯</a>。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/c8b1297245408451751aaff3c552f955.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CH-HrHzADceuGzkSGldVAQ.jpeg"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">照片由<a class="ae mg" href="https://unsplash.com/@joeel56?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">妮可·沃尔夫</a>在<a class="ae mg" href="https://unsplash.com/s/photos/reading?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="fe94" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">上周末是我过得特别无聊的一个周末:周六去了趟天文馆，然后疯狂观看了斯坦福CS224W课程讲座(T7)——强烈推荐，顺便说一句，你会获得疯狂观看的所有满足感，而没有任何负罪感。[完全披露:我坚信只要分心让你开心，就不要因为没有在你的待办事项清单上留下痕迹而责备自己。那只是很好的工作/生活平衡！请在评论中留下你对网飞的建议。]</p><p id="1f59" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">说到用图表进行机器学习，我有另外几份关于这个主题的预印本给你:</p><div class="ln lo gp gr lp lq"><a href="https://arxiv.org/abs/2009.13734" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">一种新的基于GCNN的半监督节点分类体系</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">存在于特定集群中的图的节点更有可能彼此连接，而不是与其他集群中的节点连接</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="0a4f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">和</p><div class="ln lo gp gr lp lq"><a href="https://arxiv.org/abs/2009.12966" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">基于图的半监督学习中的标签噪声分析</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">在机器学习中，人们必须获得标签来帮助监督一个能够推广到看不见的数据的模型…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="1653" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果你对基于图的机器学习完全陌生，但不愿意观看所有16个半小时的讲座来开始学习，我建议看足够多的<a class="ae mg" href="https://www.youtube.com/watch?v=uEPPnR22fxg&amp;ab_channel=HussainKaraFallah" rel="noopener ugc nofollow" target="_blank">讲座1 </a>来了解什么是图，然后观看讲座<a class="ae mg" href="https://www.youtube.com/watch?v=hTV44YH8Hd0&amp;ab_channel=HussainKaraFallah" rel="noopener ugc nofollow" target="_blank"> 6 </a>、<a class="ae mg" href="https://www.youtube.com/watch?v=4PTOhI8IWTo&amp;ab_channel=HussainKaraFallah" rel="noopener ugc nofollow" target="_blank"> 7 </a>和<a class="ae mg" href="https://www.youtube.com/watch?v=LdK9HzBAR8c&amp;ab_channel=HussainKaraFallah" rel="noopener ugc nofollow" target="_blank"> 8 </a>来了解如何将这种想法与机器学习模型联系起来。或者，这里是我的版本…</p><blockquote class="nd ne nf"><p id="1050" class="kr ks ng kt b ku kv kd kw kx ky kg kz nh lb lc ld ni lf lg lh nj lj lk ll lm im bi translated"><strong class="kt jd"> …简而言之，基于图的机器学习</strong></p><p id="d44c" class="kr ks ng kt b ku kv kd kw kx ky kg kz nh lb lc ld ni lf lg lh nj lj lk ll lm im bi translated">把你拥有的每个数据点想象成一个图的节点。假设每个节点对应一个人的脸书档案。我们将在脸书上彼此是朋友的那些节点之间画边(即连接)。节点可以但不必须具有特征(例如，人的年龄、性别、自我描述的政治观点以及他们是否养猫)。现在让我们假设你想弄清楚一个给定的人是否可能支持covid强制封锁的想法。换句话说，一个二进制分类任务。(您可以标记那些在其配置文件中明确表示支持或鄙视锁定的节点，并训练它们。)如果你不想做任何花哨的图形，你可以简单地用你的训练数据所具有的特征来训练一个分类器。然而，你假设一个朋友中有很多禁闭支持者的人比脸书朋友圈中坚决反对呆在家里命令的人更有可能分享这些观点。如果我们能在我们的建模中包含这种<strong class="kt jd">关系</strong>信息就好了……等等，我们实际上可以:只要我们使用<strong class="kt jd">图</strong>(节点+它们与其他节点的连接)而不仅仅是节点作为我们模型的输入。</p></blockquote><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/570914122b597d70eb7c28f8274d07d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*9YhmIe267zJ3OqE-.gif"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">用图表，卢克！图片来源:<a class="ae mg" href="https://giphy.com/gifs/starwars-star-wars-yoda-3ohuPp7uWLgTdU83iU" rel="noopener ugc nofollow" target="_blank">giphy.com</a></p></figure><blockquote class="nd ne nf"><p id="f08e" class="kr ks ng kt b ku kv kd kw kx ky kg kz nh lb lc ld ni lf lg lh nj lj lk ll lm im bi translated">这听起来可能很奇怪，但在某种程度上，你已经在做了。例如，考虑图像分类:一个1024 x 1024的图像可以被认为是一个网格——一个非常无聊的图形，除了图像边界之外，它恰好具有固定的大小和相同的拓扑结构。每个节点(像素)都有一组特征(定义像素的颜色)。将熟悉的ML概念从一个网格推广到一个任意复杂的图并不简单，但是可以做到。</p></blockquote><p id="d5c8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于那些已经精通使用图形进行机器学习的人来说，这里有一份大约两周前的数学含量更高的基于图形的预印本:</p><div class="ln lo gp gr lp lq"><a href="https://arxiv.org/abs/2009.12981" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">参数UMAP:学习嵌入深度神经网络的表现和…</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">我们提出了参数UMAP，UMAP(统一流形近似和投影)的参数变化…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">arxiv.org</p></div></div></div></a></div></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="4a0c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在半监督机制中训练的模型对选择哪些数据点是标记点高度敏感(事实上，优化这种选择是<a class="ae mg" href="https://medium.com/scaleway-cloud/active-learning-part-1-the-theory-239b7a43ddb5?source=friends_link&amp;sk=8c9e99904ab4de20035f15a046948a54" rel="noopener">主动学习</a>的中心目标)。因此，人们很容易把注意力集中在已标记子集的质量上，把我们得到的任何其他东西都扔进未标记的部分，让模型来处理它。然而，未标记训练样本中的非分布数据已经被证明对半监督模型的性能具有负面影响。当进行半监督机器学习时，未标记的训练集通常很大，仔细检查它以剔除任何不在分布范围内的点会违背最初的目的。以下预印本的作者通过利用批量标准化的方法解决了这个问题:</p><div class="ln lo gp gr lp lq"><a href="https://arxiv.org/abs/2010.03658" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">具有非分布数据的鲁棒半监督学习</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">基于深度神经网络的半监督学习(SSL)最近被证明是有效的。然而，最近…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">arxiv.org</p></div></div></div></a></div></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="dc3c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">图像分割任务是常见的计算机视觉用例，需要特别耗时的数据注释:勾勒出一个对象或一组同类对象的边界(有时需要像素级的精度)。当涉及到数据注释时，时间当然等于金钱，所以任何可以加速这一过程的事情都有可能在未来产生巨大的影响(这是对自动驾驶汽车的一种尝试)。不出所料，有许多小组正在研究图像分割的弱监督学习。典型地，弱标签仅需要图像范围的注释，例如比分割掩模更容易获得的分类标签。在<em class="ng">弱监督显著实例检测</em>中，作者将类别标签与图像中存在的对象数量配对，以训练三分支分割网络来产生分割掩模:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nl"><img src="../Images/28bbf9a331f86b4c307db62f5fbf2213.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mGdm8eyarx6qWl-Z6Sc_Vg.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图自https://arxiv.org/pdf/2009.13898.pdf<a class="ae mg" href="https://arxiv.org/pdf/2009.13898.pdf" rel="noopener ugc nofollow" target="_blank"/></p></figure><div class="ln lo gp gr lp lq"><a href="https://arxiv.org/abs/2009.13898" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">弱监督显著实例检测</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">现有的显著实例检测(SID)方法通常从像素级标注数据集学习。在本文中…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="deea" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">其他一些最近的弱监督图像分割预印本包括<em class="ng">弱监督语义分割的因果干预</em></p><div class="ln lo gp gr lp lq"><a href="https://arxiv.org/abs/2009.12547" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">弱监督语义分割的因果干预</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">我们提出了一个因果推理框架，以改善弱监督语义分割(WSSS)。具体来说，我们的目标是…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="3110" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以及<em class="ng">走向极端:弱监督医学图像分割</em>，其中弱标记以器官表面上的极值点的形式出现，由注释者在3D医学图像中选择:</p><div class="ln lo gp gr lp lq"><a href="https://arxiv.org/abs/2009.11988" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">走向极端:弱监督医学图像分割</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">医学图像标注是开发精确和鲁棒的机器学习模型的主要障碍。注释是…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">arxiv.org</p></div></div></div></a></div></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="fc26" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最后，如果我们不谈论主动学习，这就不是一篇主动学习时事通讯；-)住在巴黎，我不可能传递一篇标题中有<em class="ng">奥拉拉</em>的论文:</p><div class="ln lo gp gr lp lq"><a href="https://arxiv.org/abs/2010.01762" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">OLALA:基于对象级主动学习的布局标注</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">在布局对象检测问题中，通过标注对象实例来构造真实数据集</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="6468" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">文档布局检测是计算机视觉中的对象检测任务，其中所讨论的对象是文档图像中的不同内容区域。(自然地，大部分理论通常适用于物体检测。)当涉及到图像处理的主动学习时，查询通常在图像级完成，这意味着查询oracle来注释整个图像。然而，在某些类别的对象倾向于在同一幅图像中出现多次，而其他对象则不出现的用例中，图像级策略通常会导致训练集中常见对象的过度表示。对象级方法(也称为OLALA)通过查询图像中选定对象的标签来避免这个问题。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="97ad" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">回到图像分割的问题，主动学习当然是另一种减少选择分割模板所涉及的高数据注释成本的方法:</p><div class="ln lo gp gr lp lq"><a href="https://arxiv.org/abs/2010.01884" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">MetaBox+:一种新的基于区域的主动学习方法</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">提出了一种新的基于区域的主动学习语义图像分割方法，称为MetaBox+。对于…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="3f3e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">两周后见:)</p></div></div>    
</body>
</html>