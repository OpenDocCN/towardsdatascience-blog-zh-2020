<html>
<head>
<title>What is Image Classification? Data Augmentation? Transfer Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是图像分类？数据增强？转移学习？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-image-classification-data-augmentation-transfer-learning-689389c3f6c8?source=collection_archive---------15-----------------------#2020-10-03">https://towardsdatascience.com/what-is-image-classification-data-augmentation-transfer-learning-689389c3f6c8?source=collection_archive---------15-----------------------#2020-10-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/78081825736e47e0bf6426966a526bb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*udTGYZXI66T97r3w8C3lGA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">来源:图片由作者拍摄，并有他的注释</p></figure><div class=""/><div class=""><h2 id="e94c" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">技术及其应用之间的差异</h2></div><blockquote class="ku kv kw"><p id="e28e" class="kx ky kz la b lb lc kg ld le lf kj lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">本文是关于计算机视觉的三篇文章的第一部分。第2部分将解释对象识别。第3部分将是关于图像分割。</p><p id="5ded" class="kx ky kz la b lb lc kg ld le lf kj lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">随本文提供一个笔记本:<a class="ae lu" href="https://github.com/Christophe-pere/Image_classification" rel="noopener ugc nofollow" target="_blank">此处</a>在GitHub上</p></blockquote><h2 id="c66e" class="lv lw jf bd lx ly lz dn ma mb mc dp md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">介绍</h2><p id="98a1" class="pw-post-body-paragraph kx ky jf la b lb mr kg ld le ms kj lg me mt lj lk mi mu ln lo mm mv lr ls lt ij bi translated">有什么比看世界更刺激的？能够看到我们周围最好的东西？日落之美，令人难忘的瀑布，还是冰海？如果进化没有赋予我们眼睛，一切都是不可能的。</p><p id="e6ca" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">我们认识事物是因为我们已经学会了物体的形状，我们已经学会了估计与我们所遇到的不同形状可以与同一物体联系起来。我们通过经验学习，因为我们被给定了所述物体的名称。就像需要一个标签来将形状、细节、颜色与类别相关联的监督算法。狗和狼只是在像素上非常相似。计算机视觉方法已经使机器能够破译这些形状，并“学习”对它们进行分类。</p><p id="6aff" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">现在，算法，就像我们的眼睛可以识别图片或电影，物体或形状。方法不断进化完善，达到所谓的人的水平。但是，有几种方法，图像分类、对象检测或识别以及图像分割。在本文中，我们将探讨图像分类问题。第一部分将介绍从零开始训练模型，第二部分将介绍数据增强的训练，最后是预训练模型的迁移学习。</p><h2 id="bd60" class="lv lw jf bd lx ly lz dn ma mb mc dp md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">方法</h2><p id="d1d2" class="pw-post-body-paragraph kx ky jf la b lb mr kg ld le ms kj lg me mt lj lk mi mu ln lo mm mv lr ls lt ij bi translated"><strong class="la jg"> <em class="kz">图像分类从无到有</em> </strong></p><p id="d4e0" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">当你拥有的数据量足够大时，图像分类可以“T6”从零开始。想法是创建一个模型并从头开始训练它。</p><p id="e008" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">像任何分类问题一样，数据必须被注释。当涉及到图像时，如何进行？事实上很简单，同一类的数据必须存储在同一个文件夹中。有必要为所考虑的每个类或类别准备一个文件夹。像这样:</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="ce1d" class="lv lw jf nb b gy nf ng l nh ni">&gt; train/<br/>      ... forest/<br/>            ... img_1.jpeg<br/>            ... img_2.jpeg<br/>            ...<br/>      ... moutain/<br/>            ... img_1.jpeg<br/>            ... img_2.jpeg<br/>            ...<br/>      ... sea/<br/>            ... img_1.jpeg<br/>            ... img_2.jpeg<br/>      ...<br/>  validation/<br/>      ... forest/<br/>            ... img_1.jpeg<br/>            ... img_2.jpeg<br/>            ...<br/>      ... moutain/<br/>            ... img_1.jpeg<br/>            ... img_2.jpeg<br/>            ...<br/>      ... sea/<br/>            ... img_1.jpeg<br/>            ... img_2.jpeg<br/>  test/<br/>      ... forest/<br/>            ... img_1.jpeg<br/>            ... img_2.jpeg<br/>            ...<br/>      ... moutain/<br/>            ... img_1.jpeg<br/>            ... img_2.jpeg<br/>            ...<br/>      ... sea/<br/>            ... img_1.jpeg<br/>            ... img_2.jpeg</span></pre><p id="7af9" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">这种简单的方法允许模型将标签与图片关联起来。</p><p id="7bb7" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">之后，你建立你的神经网络。从现在开始，标准是针对卷积神经网络(<em class="kz"> CNN </em>)在处理图片时。所以你要建立一个CNN并用英特尔数据集训练它。您将添加一个卷积层，然后是一个汇集层，可能是一个下降层，以降低过度拟合的风险，并以密集的全连接层结束。最后一层会输出结果，或者说预测，这最后一层的单元数就是你要预测的类数。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="73f3" class="lv lw jf nb b gy nf ng l nh ni"><strong class="nb jg"><em class="kz"># building the model</em></strong><br/>model = tf.keras.Sequential([<br/>  layers.Conv2D(32, 3, activation='relu'),<br/>  layers.MaxPooling2D(),<br/>  layers.Dropout(0.5),<br/>  layers.Conv2D(32, 3, activation='relu'),<br/>  layers.MaxPooling2D(),<br/>  layers.Dropout(0.3),<br/>  layers.Conv2D(32, 3, activation='relu'),<br/>  layers.MaxPooling2D(),<br/>  layers.Flatten(),<br/>  layers.Dense(128, activation='relu'),<br/>  layers.Dense(num_classes, activation='softmax')<br/>])</span><span id="c85e" class="lv lw jf nb b gy nj ng l nh ni"><strong class="nb jg"><em class="kz"># compile the model with adam optimizer and sparse cross entropy</em></strong> model.compile(<br/>  optimizer='adam',<br/>  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),<br/>  metrics=['accuracy'])</span><span id="d7d2" class="lv lw jf nb b gy nj ng l nh ni"><strong class="nb jg"><em class="kz"># use early stopping to break the learning process if the model stop learning during 3 epochs<br/></em></strong>es = tf.keras.callbacks.EarlyStopping(patience=3)<br/>history = model.fit(<br/>  train_x,train_y,<br/>  validation_data=(valid_x, valid_y), callbacks=[es], batch_size=32,<br/>   epochs=30<br/>)</span></pre><p id="b0ad" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">在这里，我提出了一个小的CNN架构，其中num_classes是类的数量。在本文的上下文中，我们将预测6个类，所以<code class="fe nk nl nm nb b">num_classes=6</code>。<code class="fe nk nl nm nb b">EarlyStopping </code>约束模型在过度拟合时停止，参数<code class="fe nk nl nm nb b">patience=3</code>意味着如果在3个时期内模型没有改善，训练过程停止。</p><p id="f361" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">如果你有足够的数据，如果你的CNN不太深——但足够产生一个好的数据表示，你将获得好的结果。</p><p id="85d7" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">不幸的是，这种情况很少发生，您需要尝试其他选项。</p><p id="1c59" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated"><strong class="la jg"> <em class="kz">数据扩充</em> </strong></p><p id="8be3" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">所以，如果你的模型不能获得良好的性能。你可以改变你的网络结构。您可以添加或删除隐藏层。您可以减少或增加每层的单元数。您可以更改激活函数或损失函数。或者，您可以更改预处理或您的数据。</p><p id="0614" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">但是，不够怎么办？</p><p id="b42c" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">可以使用<em class="kz">数据增强</em>。这种技术允许您从内存中创建人工(合成)图像(这种方法不会影响您的原始数据)。它包括旋转等操作，相同的图片将被旋转不同的角度(创建新的图像)。移位，也就是说，图像的图案将从帧偏移，从而产生必须被内插的“洞”。这种操作可以水平进行，也可以垂直进行。缩放，新图像将是原始数据的一部分的缩放，等等…</p><p id="ebae" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">完成这项工作的完美工具是Keras[2] ( <code class="fe nk nl nm nb b">keras.preprocessing.image.ImageDataGenerator()</code>)提供的名为<code class="fe nk nl nm nb b">ImageDataGenerator </code>的对象。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="53dd" class="lv lw jf nb b gy nf ng l nh ni">from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>data_gen = ImageDataGenerator(<br/>        rotation_range=40,<br/>        width_shift_range=0.2,<br/>        height_shift_range=0.2,<br/>        rescale=1./255,<br/>        shear_range=0.2,<br/>        zoom_range=0.2,<br/>        horizontal_flip=True,<br/>        fill_mode='nearest')<br/>test_gen = ImageDataGenerator(rescale=1./255)</span></pre><p id="cac6" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">以下是我在笔记本中使用的示例值。</p><p id="f397" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">此工具将创建合成影像来增加数据集的容量。怎么用？</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="4911" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">CNN中数据扩充的快速实现。结果将显示在结果部分。</p><p id="3f91" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">不幸的是，是的，你可以有太少的图像，以获得良好的结果。如果你的数据集非常小，即使数据扩充也救不了你。接下来你会做什么？</p><p id="76c1" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated"><strong class="la jg"> <em class="kz">迁移学习【3】</em></strong></p><p id="12ae" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">不，现在不是逃避害怕转学的时候。什么是迁移学习？这是一种简单的方法，你可以将学到的知识用于一项任务，并将其输出到另一项任务中。</p><p id="90a2" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">在我们的案例中，迁移学习发生在相当大的模型(有数百万甚至上亿个参数)上，这些模型已经在海量数据(Imagenet[4]数据集)上进行了训练以进行归纳。</p><p id="bfe7" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">当您有一个小数据集时，您构建的模型不能很好地表示数据。因此，您必须使用将根据您的数据进行训练的预训练模型。</p><p id="45e0" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">方法很简单，取预先训练好的模型，冻结它们层的权重，只留下最后一层，或者最后几层，然后用你的数据训练它们。</p><p id="741e" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">神经网络根据其深度越来越专门化。第一层将检测一般模式，例如线条。然后形状会出现，直到你在最后一层达到非常精细的细节。这些是必须用来根据您的数据“调整”模型的。因此，使用迁移学习，您可以在几分钟/几小时内获得一个性能极佳的模型，而不是使用ImageNet数据集和您的数据重新训练完整的模型(这将花费数月时间，并需要大量资金投入)。</p><p id="7c6b" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">在笔记本上，我比较不同的预训练模型，看看哪个最适合我们的学习。为了轻松快速地更改预训练模型，下面的函数包含了根据数据调整预训练模型并使用指标对其进行评估的架构。返回的是一个包含度量结果的数据框，以及绘制学习曲线的模型历史。</p><p id="a9ab" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">下一个<em class="kz">要点</em>将告诉你如何使用该功能。</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="92bc" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">是的，你需要指标来评估不同算法的性能，你需要绘制学习曲线(准确性和损失)来观察你的训练行为。</p><p id="b25d" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated"><strong class="la jg"> <em class="kz">度量</em> </strong></p><p id="e050" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">为了评估分类模型，可以使用不同的度量，例如准确度、精确度、召回率、f1分数等。(这些指标的详细信息可以在<a class="ae lu" rel="noopener" target="_blank" href="/model-selection-in-text-classification-ac13eedf6146">这里</a>找到)。下面的代码显示了如何建立一个度量字典和将用于评估神经网络的函数。</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="871f" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">该函数可用于二值和多值分类问题。</p><p id="1f49" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated"><strong class="la jg"> <em class="kz">绘制学习曲线</em> </strong></p><p id="1d87" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">在训练深度学习模型时，查看学习曲线的行为以确定模型是偏差、过度拟合还是正常行为非常重要。为此，让我们看看下面的代码，它允许绘制训练集和评估集的准确度和损失曲线。</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="dd2e" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">至此，您知道了用于评估模型的不同方法和指标。</p><h2 id="8d7d" class="lv lw jf bd lx ly lz dn ma mb mc dp md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">数据</h2><p id="8b91" class="pw-post-body-paragraph kx ky jf la b lb mr kg ld le ms kj lg me mt lj lk mi mu ln lo mm mv lr ls lt ij bi translated">为了避免经典的MNIST[5]或FashionMNIST[6]进行分类，我们将采用英特尔提供的数据集(可在Kaggle[1]上获得)。这些数据更为奇特，它们代表了来自世界各地的场景，代表了6个类别(建筑、森林、山脉、冰川、海洋和街道)。对于本地计算机上的项目，数据量也是可访问的，因为训练集由14k图像组成，验证集包含3k图像和7k图像用于测试。每个图像的形状为(150x150)像素。</p><div class="mw mx my mz gt ab cb"><figure class="np is nq nr ns nt nu paragraph-image"><img src="../Images/b5e098866f5ae221a6893f031bb13de1.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*16k8ElKN8WEKJqIZT3RoxQ.jpeg"/></figure><figure class="np is nq nr ns nt nu paragraph-image"><img src="../Images/1b010df6461d85511b7ee52a8e04dd11.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*ZonjS637cl-OlRefGGRCFQ.jpeg"/><p class="iz ja gj gh gi jb jc bd b be z dk nv di nw nx translated">从列车组构建图像</p></figure></div><div class="ab cb"><figure class="np is nq nr ns nt nu paragraph-image"><img src="../Images/1631f44a75663a2d4b2228261a5fd757.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*kOcZkvXI4H2ZXxZrb_aWWQ.jpeg"/></figure><figure class="np is nq nr ns nt nu paragraph-image"><img src="../Images/3ba9b188cee4da34885dca740ff3d18f.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*lP46Dc99xU742X_JDnbEfw.jpeg"/><p class="iz ja gj gh gi jb jc bd b be z dk nv di nw nx translated">火车场景中的森林图像</p></figure></div><div class="ab cb"><figure class="np is nq nr ns nt nu paragraph-image"><img src="../Images/db73b8bdcc70fe6b303b37b157996ce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*hx0izWd_lY2NYMf7qnTsEQ.jpeg"/></figure><figure class="np is nq nr ns nt nu paragraph-image"><img src="../Images/321ea6a1899aae7783594bd54be7da98.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*dEP5JdqRP6NgVqzTIUJyIg.jpeg"/><p class="iz ja gj gh gi jb jc bd b be z dk nv di nw nx translated">火车场景中的冰川图像</p></figure></div><p id="ea29" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">比衣服好不是吗？</p><p id="caef" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">如何加载和准备数据？首先，您需要配置到达数据的不同路径。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="c294" class="lv lw jf nb b gy nf ng l nh ni"><strong class="nb jg"><em class="kz"># creating paths to retrieve the data</em></strong><br/>ROOT = "/mnt/d"<br/>FOLDER = "INTEL_images_classification"<br/>TRAIN = os.path.join(ROOT, FOLDER, 'seg_train/seg_train')<br/>TEST = os.path.join(ROOT, FOLDER, 'seg_test/seg_test')<br/>PRED  = os.path.join(ROOT, FOLDER, 'seg_pred/seg_pred')</span></pre><p id="a9af" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">然后你需要通过图片(。jpg)到NumPy值数组。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="f77a" class="lv lw jf nb b gy nf ng l nh ni">def prepare_dataset(path,label):<br/>    x_train=[]<br/>    y_train=[]<br/>    all_images_path=glob(path+'/*.jpg')<br/>    for img_path in tqdm(all_images_path) :<br/>       img=load_img(img_path, target_size=(150,150))<br/>       img=img_to_array(img)<br/>       img=img/255.0   <strong class="nb jg"><em class="kz"># here you normalize the data between 0 and 1</em></strong><br/>       x_train.append(img)<br/>       y_train.append(label)<br/>    return x_train,y_train</span></pre><p id="32d4" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">该函数将生成一个包含所有图像和相关标签的矩阵。您可以看到像素值将在[0，1]之间重新调整。深度学习模型在这个值范围内表现得更好，因为范围255是为'<em class="kz"> RGB </em>'颜色制作的，一种算法不理解'颜色'。好了，是时候提取数据了:</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="8ed6" class="lv lw jf nb b gy nf ng l nh ni"><strong class="nb jg"><em class="kz"># Train dataset</em></strong><br/>labels = os.listdir(TRAIN)<br/>x = []<br/>y = []<br/>for label in labels:<br/>    x_, y_ = prepare_dataset(os.path.join(TRAIN, label), label)<br/>    x.extend(x_)<br/>    y.extend(y_)<br/>x = np.array(x)<br/>y = np.array(y)</span><span id="3d62" class="lv lw jf nb b gy nj ng l nh ni"><strong class="nb jg"><em class="kz"># Test dataset</em></strong><em class="kz"> </em><br/>labels = os.listdir(TEST)<br/>x_test = []<br/>y_test = []<br/>for label in labels:<br/>    x_, y_ = prepare_dataset(os.path.join(TEST, label), label)<br/>    x_test.extend(x_)<br/>    y_test.extend(y_)<br/>x_test = np.array(x_test)<br/>y_test = np.array(y_test)</span></pre><p id="6ade" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">这里有一个训练集和一个测试集。接下来，您需要将训练集拆分为<em class="kz">训练</em>和<em class="kz">验证</em>集(80/20就足够了)。Scikit-learn为我们带来了<code class="fe nk nl nm nb b">train_test_split</code>功能:</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="c733" class="lv lw jf nb b gy nf ng l nh ni"># create a validation set <br/>from sklearn.model_selection import train_test_split<br/>train_x, valid_x, y_train, y_valid = train_test_split(x, y, random_state=42, stratify=y, test_size=0.2)</span></pre><p id="d02d" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">几乎完美，还有一点，标签还是<em class="kz">字符串</em>类型。模型不欣赏这种数据，所以需要对它们进行编码(需要int值):</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="0223" class="lv lw jf nb b gy nf ng l nh ni">from sklearn import preprocessing</span><span id="ab9c" class="lv lw jf nb b gy nj ng l nh ni"><strong class="nb jg"><em class="kz"># create the label encoder</em></strong><br/>encoder = preprocessing.LabelEncoder()<br/><strong class="nb jg"><em class="kz"># train it on the training labels set</em></strong> <br/>train_y = encoder.fit_transform(y_train)<br/><strong class="nb jg"><em class="kz"># apply it on the other corresponding labels</em></strong> <br/>valid_y = encoder.transform(y_valid)<br/>test_y  = encoder.transform(y_test)</span></pre><p id="e0c6" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">现在，它是完美的。您有方法、指标和数据。</p><h2 id="25e7" class="lv lw jf bd lx ly lz dn ma mb mc dp md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">结果</h2><p id="83e1" class="pw-post-body-paragraph kx ky jf la b lb mr kg ld le ms kj lg me mt lj lk mi mu ln lo mm mv lr ls lt ij bi translated"><strong class="la jg"> <em class="kz">从零开始</em> </strong></p><p id="a9bf" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">在<strong class="la jg"> <em class="kz">方法</em> </strong>一节中呈现的简单CNN模型已经在数据集上进行了训练。在10个时期之后，训练停止，因为算法不再学习。</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="b882" class="lv lw jf nb b gy nf ng l nh ni">Epoch 1/30<br/>351/351 [==============================] - 536s 2s/step - loss: 1.1578 - accuracy: 0.5443 - val_loss: 1.0311 - val_accuracy: 0.6138<br/>...<br/>Epoch 10/30<br/>351/351 [==============================] - 649s 2s/step - loss: 0.2364 - accuracy: 0.9146 - val_loss: 0.6711 - val_accuracy: 0.7887</span></pre><p id="8a08" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">相应的曲线表明，在3个时期之后，在测试集上达到大约75%的准确度。该模型在训练中继续学习，但是不能如验证准确性所示的那样进行概括。损失显示同样的事情，在3个时期之后，验证集上的损失没有改变。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/b3c436cba4391e34e6bf4de6a90ba5d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*8gDTONRBFJPgsDlZHbQp2g.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">“从头开始”模型的精确度和损耗曲线</p></figure><p id="6c07" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">相应的指标:</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="a9b4" class="lv lw jf nb b gy nf ng l nh ni">  accuracy          : 78.33%<br/>  balanced_accuracy': 78.44%<br/>  precision         : 78.94%<br/>  recall            : 78.33%<br/>  f1-score          : 78.31%<br/>  cohens_kappa      : 73.97%<br/>  matthews_corrcoef : 74.10%<br/>  roc_auc           : 93.37%</span></pre><p id="1e29" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">在测试集上的结果并不坏，在准确度、精确度和召回率上达到了78+%。这是分类的一个好的开始。</p><p id="ac84" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated"><strong class="la jg"> <em class="kz">数据扩充</em> </strong></p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="d2ad" class="lv lw jf nb b gy nf ng l nh ni">Epoch 1/50<br/>62/62 [==============================] - 1116s 18s/step - loss: 2.0628 - accuracy: 0.1857 - val_loss: 1.7963 - val_accuracy: 0.1925</span><span id="09bb" class="lv lw jf nb b gy nj ng l nh ni">...<br/>Epoch 11/50<br/>62/62 [==============================] - 984s 16s/step - loss: 0.9419 - accuracy: 0.6369 - val_loss: 0.9811 - val_accuracy: 0.5925</span></pre><p id="6aa4" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">训练以糟糕的结果结束。学习曲线表明培训不够好。这可以通过调整模型来改变。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/a2a7d012684d0ccbba9e582e3e1c567d.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*hUcwKxFnSzv_oWPVa8RFqw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">学习曲线数据扩充</p></figure><p id="2e87" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">如你所见，即使结果不是完美的，学习也是更好的。训练et和验证之间的曲线更接近。所以训练更稳定。</p><p id="4a67" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">相关指标如下所示:</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="7c27" class="lv lw jf nb b gy nf ng l nh ni">accuracy          | 68.60%<br/>balanced_accuracy | 68.13%<br/>precision         | 70.28%<br/>recall            | 68.61%<br/>f1-score          | 67.54%<br/>cohens_kappa      | 62.18%<br/>matthews_corrcoef | 62.76%<br/>roc_auc           | 93.73%</span></pre><p id="79f3" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated"><strong class="la jg"> <em class="kz">转移学习</em> </strong></p><p id="392a" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">本研究中测试的模型如下:</p><pre class="mw mx my mz gt na nb nc nd aw ne bi"><span id="982f" class="lv lw jf nb b gy nf ng l nh ni">Xception[7]           | ResNet50V2[12]  | InceptionV3[14]<br/>VGG16[8]              | ResNet101V2     | <br/>VGG19                 | ResNet152V2     | <br/>InceptionResNetV2[9]  | DenseNet121[13] | <br/>MobileNetV2[10]       | DenseNet169     |<br/>NASNetLarge[11]       | DenseNet201     |</span></pre><p id="8135" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">是的，Keras中实现了很多预先训练好的模型(这里只是其中的一部分)。他们每个人都在ImageNet数据集上进行了训练。下表显示了根据我们的数据训练的每个模型的结果。</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="nn no l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">使用不同的预训练模型获得的结果</p></figure><blockquote class="ku kv kw"><p id="2f1a" class="kx ky kz la b lb lc kg ld le lf kj lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">由于input_shape的原因，NASNetLarge模型尚未经过测试。该模型考虑了具有形状(331，331，3)的图片。</p></blockquote><p id="4681" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">这些结果是用<code class="fe nk nl nm nb b">EarlyStopping(patience=1)</code>获得的，这意味着如果模型没有从一个时期学习到另一个时期，学习过程就停止了。为什么一个？因为测试所有模型很费时间。这些结果也是通过仅调整每个模型的顶层而获得的。为了提高性能，可以调整更多的层。</p><h2 id="55de" class="lv lw jf bd lx ly lz dn ma mb mc dp md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">讨论</h2><p id="3182" class="pw-post-body-paragraph kx ky jf la b lb mr kg ld le ms kj lg me mt lj lk mi mu ln lo mm mv lr ls lt ij bi translated">数据扩充方法是最微妙的，结果不是预期的那样。为了提高性能，需要调整模型的复杂性。从头开始和迁移学习方法的实现是最容易建立的。</p><h2 id="3316" class="lv lw jf bd lx ly lz dn ma mb mc dp md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">结论</h2><p id="491a" class="pw-post-body-paragraph kx ky jf la b lb mr kg ld le ms kj lg me mt lj lk mi mu ln lo mm mv lr ls lt ij bi translated">使用迁移学习方法的预训练模型允许我们在数据集上获得最佳结果。通过减少对早期停止参数的限制和调整预训练模型的更多层，可以提高性能。显然，这会更费时间。<br/>“从零开始的<em class="kz"/>”和数据扩充方法已经显示出有趣的结果，但是没有超过迁移学习。<br/>resnet 101v 2模型在INTEL数据集(测试集)上取得了90.33%的准确率和90.36%的精度。它是比较的赢家。</p><p id="402b" class="pw-post-body-paragraph kx ky jf la b lb lc kg ld le lf kj lg me li lj lk mi lm ln lo mm lq lr ls lt ij bi translated">我希望你会对这篇文章感兴趣，并对你将来的图像分类项目有所帮助。计算机视觉的下一篇文章将是关于图像中的物体检测。回头见。</p><h2 id="0985" class="lv lw jf bd lx ly lz dn ma mb mc dp md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">参考</h2><p id="c9db" class="pw-post-body-paragraph kx ky jf la b lb mr kg ld le ms kj lg me mt lj lk mi mu ln lo mm mv lr ls lt ij bi translated">[1]<a class="ae lu" href="https://www.kaggle.com/puneet6060/intel-image-classification" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/puneet 6060/Intel-image-class ification</a><br/>【2】keras . io<br/>【3】Pratt，L. Y. (1993)。<a class="ae lu" href="http://papers.nips.cc/paper/641-discriminability-based-transfer-between-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">《基于区分度的神经网络间迁移》</a> (PDF)。NIPS会议:神经信息处理系统的进展。摩根·考夫曼出版社。第204-211页。<br/> [4] Olga Russakovsky等《ImageNet大规模视觉识别挑战赛》。IJCV，2015年。<br/>【5】<a class="ae lu" href="http://yann.lecun.com/exdb/publis/index.html#lecun-98" rel="noopener ugc nofollow" target="_blank">勒村，y .等人，1998年。"基于梯度的学习应用于文档识别."IEEE会议录，86(11):2278–2324</a><br/>【6】韩x .，卡希夫r .，罗兰v .，2017。Fashion-MNIST:一个用于对标机器学习算法的新型图像数据集<a class="ae lu" href="https://arxiv.org/abs/1708.07747" rel="noopener ugc nofollow" target="_blank"> arXiv预印本</a><br/>【7】Chollet f .，2016。例外:深度可分卷积深度学习<a class="ae lu" href="https://arxiv.org/abs/1610.02357" rel="noopener ugc nofollow" target="_blank"> arXiv预印本</a><br/>【8】Simon Yan k .和Zisserman A .，2014。用于大规模图像识别的极深度卷积网络<a class="ae lu" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"> arXiv预印本</a><br/>【9】Szegedy c .等人，2016。Inception-v4，Inception-ResNet和剩余连接对学习的影响<a class="ae lu" href="https://arxiv.org/abs/1602.07261" rel="noopener ugc nofollow" target="_blank"> arXiv预印本</a><br/>【10】Sandler m .等人，2019。MobileNetV2:反演残差和线性瓶颈<a class="ae lu" href="https://arxiv.org/pdf/1801.04381.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv预印本</a><br/>【11】Zoph b .等人，2018。可扩展图像识别的学习可转移架构<a class="ae lu" href="https://arxiv.org/pdf/1707.07012.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv预印本</a><br/>【12】何k等，2016。用于图像识别的深度残差学习<a class="ae lu" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> arXiv预印本</a><br/>【13】黄g .等，2017。密集连接的卷积网络<a class="ae lu" href="https://arxiv.org/abs/1608.06993" rel="noopener ugc nofollow" target="_blank"> arXiv预印本</a><br/>【14】Szegedy c .等人，2016。重新思考计算机视觉的初始架构<a class="ae lu" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank"> arXiv预印本</a></p></div></div>    
</body>
</html>