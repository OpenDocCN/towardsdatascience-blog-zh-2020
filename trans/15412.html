<html>
<head>
<title>Implementing TabNet in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在PyTorch中实现TabNet</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-tabnet-in-pytorch-fc977c383279?source=collection_archive---------19-----------------------#2020-10-23">https://towardsdatascience.com/implementing-tabnet-in-pytorch-fc977c383279?source=collection_archive---------19-----------------------#2020-10-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/0f32cca0e4658881057e3de431f3b9d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VMttO-wDWlgsyTVefMPBXg.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://unsplash.com/photos/Wpnoqo2plFA" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/Wpnoqo2plFA</a></p></figure><p id="6b01" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">深度学习已经接管了视觉、自然语言处理、语音识别和许多其他领域，取得了惊人的成果，甚至在某些领域取得了超人的表现。然而，使用深度学习对表格数据进行建模相对有限。</p><p id="15f1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于表格数据，最常见的方法是使用基于树的模型及其集成。基于树的模型全局选择减少熵最多的特征。像bagging、boosting这样的集成方法通过减少模型方差来进一步改进这些基于树的方法。最近基于树的组合，如XGBoost和LightGBM，已经主导了Kaggle竞赛。</p><p id="9b47" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TabNet是谷歌云AI研究团队开发的神经架构。它能够在回归和分类问题中的几个数据集上实现最先进的结果。它结合了神经网络的特性以适应非常复杂的函数和基于树的算法的<strong class="kf ir">特性选择</strong>属性。换句话说，模型在训练过程中学习只选择相关的特征。此外，与只能进行全局特征选择的基于树的模型相反，TabNet中的特征选择过程是基于实例的。TabNet的另一个令人满意的特性是<strong class="kf ir">可解释性</strong>。与大多数深度学习相反，在深度学习中，神经网络的行为就像黑盒一样，我们可以解释模型在TabNet的情况下选择了哪些特征。</p><p id="5731" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇博客中，我将带您一步一步地体验PyTorch中对初学者友好的TabNet实现。我们开始吧！！</p><p id="d7f3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">TabNet架构。</strong></p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lb"><img src="../Images/d44a70d9b631af1df37abe3d6df76452.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*twB1nZHPN5Cuxu2h_jpEPg.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">1)资料来源:<a class="ae kc" href="https://arxiv.org/pdf/1908.07442v1.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1908.07442v1.pdf</a></p></figure><p id="3a4d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图(1)取自最初的TabNet论文。我们将单独构建图像的每个组件，并在最后将它们组装起来。首先，让我们来看一下这个模型中使用的两个基本概念- <a class="ae kc" href="https://arxiv.org/pdf/1705.08741.pdf" rel="noopener ugc nofollow" target="_blank"> Ghost批处理规范化(GBN) </a>和<a class="ae kc" href="https://arxiv.org/pdf/1602.02068.pdf" rel="noopener ugc nofollow" target="_blank"> Sparsemax </a>。</p><p id="243e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> Ghost批量标准化(GBN): </strong> <br/> GBN让我们可以训练大批量的数据，同时也可以更好地进行归纳。简而言之，我们将输入批次分成大小相等的子批次(虚拟批次大小),并对它们应用<strong class="kf ir">相同的</strong>批次规范化层。除了应用于输入要素的第一个批处理规范化图层之外，模型中使用的所有批处理规范化图层都是GBN图层。它可以在PyTorch中实现，如下所示:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="a293" class="ll lm iq lh b gy ln lo l lp lq">class <strong class="lh ir">GBN</strong>(nn.Module):<br/>    def __init__(self,inp,vbs=128,momentum=0.01):<br/>        super().__init__()<br/>        self.bn = nn.BatchNorm1d(inp,momentum=momentum)<br/>        self.vbs = vbs<br/>    def forward(self,x):<br/>        chunk = torch.chunk(x,x.size(0)//self.vbs,0)<br/>        res = [self.bn(y) for y <strong class="lh ir">in</strong> chunk]<br/>        return torch.cat(res,0)</span></pre><p id="7edc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">稀疏最大值:</strong></p><p id="3063" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就像softmax一样，Sparsemax是一个非线性归一化函数，但是顾名思义，分布是“更稀疏”的。也就是说，与softmax相比，输出概率分布中的一些数字更接近1，而其他数字更接近0。这使得模型能够在每个决策步骤中更有效地选择相关特征。我们将使用sparsemax将特征选择步骤的掩码投影到一个更稀疏的空间。sparsemax的实现可以在https://github.com/gokceneraslan/SparseMax.torch<a class="ae kc" href="https://github.com/gokceneraslan/SparseMax.torch" rel="noopener ugc nofollow" target="_blank">的</a>找到</p><p id="9cf8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了进一步增加遮罩中的稀疏性，我们还将添加稀疏性正则化技术来惩罚不太稀疏的遮罩。这可以在每个决策步骤中实现，如下所示:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="af6a" class="ll lm iq lh b gy ln lo l lp lq">(mask*torch.log(mask+1e-10)).mean() #F(<strong class="lh ir">x</strong>)= -<strong class="lh ir">∑x</strong>log(<strong class="lh ir">x+eps</strong>)</span></pre><p id="59d5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有决策步骤上的该值的总和可以被添加到总损失中(在乘以正则化常数λ之后)。</p><p id="d747" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">注意力转换器:</strong> <br/>这是模型学习相关特征之间的关系并决定将哪些特征传递给当前决策步骤的特征转换器的地方。每个注意力转换器由一个全连接层、一个Ghost批处理规范化层和一个Sparsemax层组成。每个决策步骤中的注意力转换器接收输入特征、来自前一步骤的已处理特征以及关于已用特征的先验信息。先验信息由大小为batch_size x input_features的矩阵表示。它被初始化为1，并在每个决策步骤的注意力转换器处被传递和更新。还有一个松弛参数，用于限制某个特性在向前传递中可以使用的次数。较大的值意味着模型可以多次重复使用同一要素。我认为守则把一切都讲清楚了。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="cf29" class="ll lm iq lh b gy ln lo l lp lq">class <strong class="lh ir">AttentionTransformer</strong>(nn.Module):<br/>    def __init__(self,d_a,inp_dim,relax,vbs=128):<br/>        super().__init__()<br/>        self.fc = nn.Linear(d_a,inp_dim)<br/>        self.bn = GBN(out_dim,vbs=vbs)<br/>        self.smax = Sparsemax()<br/>        self.r = relax</span><span id="48ee" class="ll lm iq lh b gy lr lo l lp lq">    #a:feature from previous decision step<br/>    def forward(self,a,priors): <br/>        a = self.bn(self.fc(a)) <br/>        mask = self.smax(a*priors) <br/>        priors =priors*(self.r-mask)  #updating the prior<br/>        return mask</span></pre><p id="2303" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后将该掩膜乘以(按元素)归一化的输入要素。</p><p id="2f77" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">特征转换器:</strong></p><p id="eb16" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要素转换器是处理所有选定要素以生成最终输出的地方。每个特征变换器由多个门控线性单元块组成。GLU控制哪些信息必须被允许在网络中进一步流动。为了实现一个GLU模块，首先我们使用一个完全连接的层将GLU的输入特征的尺寸加倍。我们使用一个GBN层来标准化结果矩阵。然后，我们将一个<strong class="kf ir"> sigmoid应用于结果特征的第二部分</strong>，并将结果乘以第一部分。结果乘以一个比例因子(本例中为sqrt(0.5))并添加到输入中。该求和结果是序列中下一个GLU模块的输入。</p><p id="43c5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在所有决策步骤中共享一定数量的GLU块，以提高模型容量和效率(<strong class="kf ir">可选</strong>)。第一共享GLU块(或者第一独立块，如果没有块被共享的话)是唯一的，因为它将输入特征的维数减少到等于n_a+n_d的维数。n_a是输入到下一步骤的注意力转换器的特征的维数，n_d是用于计算最终结果的特征的维数。这些特征被一起处理，直到它们到达分割器。ReLU激活应用于n_d维向量。所有决策步骤的输出相加在一起，并通过完全连接的层将它们映射到输出维度。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="7443" class="ll lm iq lh b gy ln lo l lp lq">class <strong class="lh ir">GLU</strong>(nn.Module):<br/>    def __init__(self,inp_dim,out_dim,fc=None,vbs=128):<br/>        super().__init__()<br/>        if fc:<br/>            self.fc = fc<br/>        else:<br/>            self.fc = nn.Linear(inp_dim,out_dim*2)<br/>        self.bn = GBN(out_dim*2,vbs=vbs) <br/>        self.od = out_dim<br/>    def forward(self,x):<br/>        x = self.bn(self.fc(x))<br/>        return x[:,:self.od]*torch.sigmoid(x[:,self.od:])</span><span id="0041" class="ll lm iq lh b gy lr lo l lp lq">class <strong class="lh ir">FeatureTransformer</strong>(nn.Module):<br/>    def __init__(self,inp_dim,out_dim,shared,n_ind,vbs=128):<br/>        super().__init__()<br/>        first = True<br/>        self.shared = nn.ModuleList()<br/>        if shared:<br/>            self.shared.append(GLU(inp_dim,out_dim,shared[0],vbs=vbs))<br/>            first= False    <br/>            for fc <strong class="lh ir">in</strong> shared[1:]:<br/>                self.shared.append(GLU(out_dim,out_dim,fc,vbs=vbs))<br/>        else:<br/>            self.shared = None<br/>        self.independ = nn.ModuleList()<br/>        if first:<br/>            self.independ.append(GLU(inp,out_dim,vbs=vbs))<br/>        for x <strong class="lh ir">in</strong> range(first, n_ind):<br/>            self.independ.append(GLU(out_dim,out_dim,vbs=vbs))<br/>        self.scale = torch.sqrt(torch.tensor([.5],device=device))<br/>    def forward(self,x):<br/>        if self.shared:<br/>            x = self.shared[0](x)<br/>            for glu <strong class="lh ir">in</strong> self.shared[1:]:<br/>                x = torch.add(x, glu(x))<br/>                x = x*self.scale<br/>        for glu <strong class="lh ir">in</strong> self.independ:<br/>            x = torch.add(x, glu(x))<br/>            x = x*self.scale<br/>        return x</span></pre><p id="01ca" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，让我们将注意力转换器和特征转换器结合成一个决策步骤:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="05be" class="ll lm iq lh b gy ln lo l lp lq">class <strong class="lh ir">DecisionStep</strong>(nn.Module):<br/>    def __init__(self,inp_dim,n_d,n_a,shared,n_ind,relax,vbs=128):<br/>        super().__init__()<br/>        self.fea_tran = FeatureTransformer(inp_dim,n_d+n_a,shared,n_ind,vbs)<br/>        self.atten_tran =  AttentionTransformer(n_a,inp_dim,relax,vbs)<br/>    def forward(self,x,a,priors):<br/>        mask = self.atten_tran(a,priors)<br/>        sparse_loss = ((-1)*mask*torch.log(mask+1e-10)).mean()<br/>        x = self.fea_tran(x*mask)<br/>        return x,sparse_loss</span></pre><p id="a00b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们可以通过将几个决策步骤结合在一起来完成模型:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="f4ea" class="ll lm iq lh b gy ln lo l lp lq">class <strong class="lh ir">TabNet</strong>(nn.Module):<br/>    def __init__(self,inp_dim,final_out_dim,n_d=64,n_a=64,<br/>n_shared=2,n_ind=2,n_steps=5,relax=1.2,vbs=128):<br/>        super().__init__()<br/>        if n_shared&gt;0:<br/>            self.shared = nn.ModuleList()<br/>            self.shared.append(nn.Linear(inp_dim,2*(n_d+n_a)))<br/>            for x <strong class="lh ir">in</strong> range(n_shared-1):<br/>                self.shared.append(nn.Linear(n_d+n_a,2*(n_d+n_a)))<br/>        else:<br/>            self.shared=None<br/>        self.first_step = FeatureTransformer(inp_dim,n_d+n_a,self.shared,n_ind) <br/>        self.steps = nn.ModuleList()<br/>        for x <strong class="lh ir">in</strong> range(n_steps-1):<br/>            self.steps.append(DecisionStep(inp_dim,n_d,n_a,self.shared,n_ind,relax,vbs))<br/>        self.fc = nn.Linear(n_d,final_out_dim)<br/>        self.bn = nn.BatchNorm1d(inp_dim)<br/>        self.n_d = n_d<br/>    def forward(self,x):<br/>        x = self.bn(x)<br/>        x_a = self.first_step(x)[:,self.n_d:]<br/>        sparse_loss = torch.zeros(1).to(x.device)<br/>        out = torch.zeros(x.size(0),self.n_d).to(x.device)<br/>        priors = torch.ones(x.shape).to(x.device)<br/>        for step <strong class="lh ir">in</strong> self.steps:<br/>            x_te,l = step(x,x_a,priors)<br/>            out += F.relu(x_te[:,:self.n_d])<br/>            x_a = x_te[:,self.n_d:]<br/>            sparse_loss += l<br/>        return self.fc(out),sparse_loss</span></pre><p id="fdbb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">模型超参数的近似范围:<br/> </strong> n_d，n_a: 8到512 <br/>批量:256到32768 <br/>虚拟批量:128到2048 <br/>稀疏正则化常数:0到0.00001 <br/>共享GLU块数:2到10 <br/>独立判决块数:2到10 <br/>松弛常数:1到2.5 <br/>判决步数)</p><p id="eb80" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个TabNet模块可以扩展用于分类和回归任务。您可以为分类变量添加嵌入，将Sigmoid或Softmax函数应用于输出，等等。尝试一下，看看什么最适合你。在示例笔记本中，我尝试用Sigmoid替换Sparsemax，并能够获得稍好的精度。</p><p id="af9e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于<a class="ae kc" href="https://www.kaggle.com/c/lish-moa/data" rel="noopener ugc nofollow" target="_blank">行动机制(MoA)预测</a>数据集的用例示例，你可以在这里找到我的笔记本:<a class="ae kc" href="https://www.kaggle.com/samratthapa/drug-prediction" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/samratthapa/drug-prediction</a>。这是目前正在Kaggle上举行的一场比赛的数据集。</p><p id="6bde" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我对TabNet的实现是对DreamQuark慷慨的人们的工作的一个简短的改编。他们对TabNet的完整实现可以在:<br/><a class="ae kc" href="https://github.com/dreamquark-ai/tabnet/tree/develop/pytorch_tabnet" rel="noopener ugc nofollow" target="_blank">https://github . com/dream quark-ai/TabNet/tree/develop/py torch _ TabNet</a>找到。<br/>你应该考虑阅读<a class="ae kc" href="https://arxiv.org/abs/1908.07442v4" rel="noopener ugc nofollow" target="_blank">论文</a>以获得对TabNet更详细的描述。</p><p id="5011" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢您的阅读。我希望我能帮上忙。</p><p id="3823" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">参考文献:</strong> <br/> 1)塞尔詹·奥鲁克，托马斯·菲斯特。2020.TabNet:专注的可解释表格学习<a class="ae kc" href="https://arxiv.org/abs/1908.07442v4" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1908.07442v4</a><br/>2)扬·n·多芬、安吉拉·范、迈克尔·奥利和大卫·格兰吉尔。2016.用门控卷积网络进行语言建模。https://arxiv.org/pdf/1612.08083.pdf、埃拉德·霍弗、伊泰·胡巴拉和丹尼尔·苏德里。2017.训练时间越长，推广效果越好:缩小神经网络大批量训练中的推广差距。<br/><a class="ae kc" href="https://arxiv.org/pdf/1705.08741.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1705.08741.pdf</a><br/>4)安德烈·马丁斯和拉蒙·费尔南德斯·阿斯图迪略。2016.从Softmax到Sparsemax:注意力和多标签分类的稀疏模型。<br/><a class="ae kc" href="https://arxiv.org/abs/1602.02068" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1602.02068</a><br/>5)Sparsemax实现<a class="ae kc" href="https://github.com/gokceneraslan/SparseMax.torch" rel="noopener ugc nofollow" target="_blank">https://github.com/gokceneraslan/SparseMax.torch</a><br/>6)完成PyTorch TabNet实现<br/><a class="ae kc" href="https://github.com/dreamquark-ai/tabnet/tree/develop/pytorch_tabnet" rel="noopener ugc nofollow" target="_blank">https://github . com/dream quark-ai/TabNet/tree/develop/py torch _ TabNet</a></p></div></div>    
</body>
</html>