<html>
<head>
<title>How to Build a Fast “Most-Similar Words” Method in SpaCy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在SpaCy中建立快速的“最相似词”方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-fast-most-similar-words-method-in-spacy-32ed104fe498?source=collection_archive---------6-----------------------#2020-10-03">https://towardsdatascience.com/how-to-build-a-fast-most-similar-words-method-in-spacy-32ed104fe498?source=collection_archive---------6-----------------------#2020-10-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a00f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://pedram-ataee.medium.com/list/nlpinproduction-98dbb687a868" rel="noopener"> NLP-in-Production </a></h2><div class=""/><div class=""><h2 id="2231" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">以及对新发布的名为Owl的单词相似性API的介绍</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/468e5e6fdbaee795eaac28cf943f99fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Sx7qk79CUnfNnJYD"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@harleydavidson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">哈雷戴维森</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="5dda" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">自然语言处理(NLP)的最新发展引入了在生产中必须谨慎使用的语言模型。例如spaCy大型英文模型，<a class="ae lh" href="https://spacy.io/models/en#en_core_web_lg" rel="noopener ugc nofollow" target="_blank"><em class="me">en-core-we b-LG</em></a><strong class="lk jd"/>包含60多万个300-d向量。或者说，预先训练好的<a class="ae lh" href="https://code.google.com/archive/p/word2vec/" rel="noopener ugc nofollow" target="_blank"><em class="me">word 2 vec-Google-news-300</em></a>模型包含300万个300-d的单词和短语向量。当您想要计算这些高维向量的度量时，解决方案可能很容易受到计算能力的影响。</p><p id="98c8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇文章中，我想分享我是如何加速spaCy库以用于单词相似性API的。与Gensim相反，spaCy不支持高效的最相似方法。我最近发布了一个单词相似度API，名为Owl。这个API允许您使用包括spaCy在内的各种word2vec模型提取与目标单词最相似的单词。给定一个单词，这个API返回一个单词组列表，这些单词组与预定义上下文中的原始单词相似，比如News或General。一般语境使用spaCy大英语模式。</p><p id="c5e6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果您不熟悉Word2Vec模型，我推荐您先阅读下面的文章。<strong class="lk jd">你会发现为什么Word2Vec模型在机器学习中既简单又具有革命性。</strong></p><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/word2vec-models-are-simple-yet-revolutionary-de1fef544b87"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">Word2Vec模型简单而具有革命性</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">Gensim还是spaCy？不了解Word2Vec机型的基础知识也没关系。</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw lb mi"/></div></div></a></div><h2 id="faea" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">—如何使用spaCy提取最相似的单词？</h2><p id="34ad" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">没有捷径可走。我必须计算目标单词的向量与word2vec模型中存储的大量向量之间的距离。然而，我可以用过滤器<strong class="lk jd">细化搜索空间</strong>，用优化的计算库<strong class="lk jd">加速计算</strong>。</p><p id="b000" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我不需要恢复所有向量。我可以使用spaCy提供的<code class="fe nu nv nw nx b">.prob</code> <em class="me"> </em>属性来修剪向量(即细化搜索空间)。该属性有助于选择英语中最常用的单词<code class="fe nu nv nw nx b">w.prob &gt;= -15</code>。在这里，您可以使用任何适合您的问题的过滤器。例如，您可能想要使用代表一个单词的阳性或阴性的<code class="fe nu nv nw nx b">.sentiment</code>属性来过滤向量池。下面的代码展示了如何为spaCy构建一个最相似的方法。不过，这段代码并没有进行快速运行的优化。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ny nz l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://stackoverflow.com/questions/57697374/list-most-similar-words-in-spacy-in-pretrained-model" rel="noopener ugc nofollow" target="_blank">来源:<strong class="ak">堆栈溢出</strong> </a></p></figure><h2 id="4c9d" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">—如何使用spaCy加速最相似的单词？</h2><p id="98e6" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">延迟是API服务中的一个重要因素。我负担不起哪怕1秒钟的额外计算时间。因此，我优化了上面解释的最相似的方法，以满足我希望我的API满足的需求。</p><p id="a047" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我进行了大量实验，以确定实现中哪些部分最耗时。首先，我怀疑<code class="fe nu nv nw nx b">sort</code>方法必须修改。对代码进行分析后，我发现<code class="fe nu nv nw nx b">.similarity</code>方法是延迟的主要来源，必须进行优化。</p><p id="77d2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">SpaCy使用后端的余弦相似度来计算<code class="fe nu nv nw nx b">.similarity</code>。因此，我决定在上面的<code class="fe nu nv nw nx b">most_similar</code>方法中，用它的优化的对应物替换<code class="fe nu nv nw nx b">word.similarity(w)</code>。优化的方法<code class="fe nu nv nw nx b">cosine_similarity_numba(w.vector, word.vector)</code>使用Numba库来加速计算。结果得到了显著改善，即延迟从约5秒(API不可接受)降至约1.5秒(API可接受)。您应该用下面的行替换<code class="fe nu nv nw nx b">most_similar</code>方法中的第12行。</p><pre class="ks kt ku kv gt oa nx ob oc aw od bi"><span id="104c" class="mx my it nx b gy oe of l og oh">by_similarity = <em class="me">sorted</em>(queries, key=<em class="me">lambda </em>w: <strong class="nx jd">cosine_similarity_numba(w.vector, word.vector)</strong>, reverse=<em class="me">True</em>)</span></pre><p id="5cfe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面，您可以使用Numba库找到余弦相似性的优化实现。根据其文档介绍，<a class="ae lh" href="https://numba.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Numba </a>是一个开源的JIT (Just In Time)编译器，可以将Python和NumPy代码翻译成快速机器码。<strong class="lk jd">这个功能对于以最小的改动加速一个人的代码是至关重要的。</strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ny nz l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://medium.com/analytics-vidhya/speed-up-cosine-similarity-computations-in-python-using-numba-c04bc0741750" rel="noopener">来源-媒介</a></p></figure><h2 id="fc9d" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">—最好的最相似单词服务是什么？</h2><p id="2eba" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">必须根据结果的上下文和粒度来选择最相似的单词服务。<strong class="lk jd">上下文</strong>由word2vec模型表示<strong class="lk jd">，而<strong class="lk jd">粒度</strong>由聚类质量</strong>决定<strong class="lk jd"> </strong>。</p><p id="4e51" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://spacy.io/models/en#en_core_web_lg" rel="noopener ugc nofollow" target="_blank"> spaCy大型英语模型</a>包含在斯坦福大学手套项目培训的<a class="ae lh" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">手套普通爬行word2vec模型</a>。人们可能希望使用在特定数据语料库上训练的上下文化word2vec模型。所以，根据项目需求，必须选择word2vec模型。Owl API 让您有机会使用各种word2vec模型。</p><p id="89b3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">结果的粒度是最相似服务的一个重要特征。在下面，我想比较我在上面介绍的最相似方法和Owl API的最终结果。您将看到后一种方法的结果更加细化，因此更加有用。</p><pre class="ks kt ku kv gt oa nx ob oc aw od bi"><span id="be64" class="mx my it nx b gy oe of l og oh">"Owl (en-core-web-lg)": <strong class="nx jd">{</strong> <br/>0: <strong class="nx jd">[</strong>"seattle", "portland", "washington"<strong class="nx jd">]</strong>,<br/>1: <strong class="nx jd">[</strong>"denver", "chicago", "nashville"<strong class="nx jd">]</strong>,<br/>2: <strong class="nx jd">[</strong>"toronto", "montreal", "ontario", "sydney"<strong class="nx jd">]</strong>  <br/><strong class="nx jd">}</strong></span><span id="c05d" class="mx my it nx b gy oi of l og oh">"spaCy (en-core-web-lg)": <strong class="nx jd">[</strong><br/>"toronto","seattle","montreal","portland","ontario","denver",<br/>"washington","chicago","sydney","nashville"<br/><strong class="nx jd">]</strong></span></pre><p id="b22d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://rapidapi.com/pedram.ataee/api/word-similarity" rel="noopener ugc nofollow" target="_blank"> Owl API </a>建立在一系列word2vec模型之上，包括spaCy <em class="me"> en-core-web-lg </em>和高级聚类技术，以创建革命性的单词相似性服务。这个API可以用于各种项目，包括语言理解或推荐系统。你可以在这里找到更多关于Owl API <a class="ae lh" href="https://rapidapi.com/pedram.ataee/api/word-similarity" rel="noopener ugc nofollow" target="_blank">的信息</a>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/f99c0c790510f721656f9ed41925004d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*Gwx0V2rtKeoFlMMVjzDxpg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://rapidapi.com/pedram.ataee/api/word-similarity" rel="noopener ugc nofollow" target="_blank">词语相似度API (Owl) </a></p></figure><div class="mf mg gp gr mh mi"><a href="https://www.amazon.com/gp/product/B08D2M2KV1/ref=dbs_a_def_rwt_hsch_vapi_tkin_p1_i0" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">人工智能:非正统的教训:如何获得洞察力和建立创新的解决方案</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">亚马逊网站:人工智能:非正统课程:如何获得洞察力和建立创新的解决方案电子书…</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">www.amazon.com</p></div></div><div class="mr l"><div class="ok l mt mu mv mr mw lb mi"/></div></div></a></div><h2 id="a5a3" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">临终遗言</h2><p id="a4d2" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">当您想要在生产中使用NLP模型时，您必须使用子例程的优化实现来加速计算。例如，在自然语言处理中，余弦相似度经常为各种任务计算。因此，您必须确保它被有效地实现和编译，例如使用Numba库。另外，我强烈推荐使用Owl API。根据需要，您可以从上下文化和粒度化的结果中受益。</p><h1 id="9221" class="ol my it bd mz om on oo nc op oq or nf ki os kj ni kl ot km nl ko ou kp no ov bi translated">感谢阅读！</h1><p id="5340" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">如果你喜欢这个帖子，想支持我…</p><ul class=""><li id="72b2" class="ow ox it lk b ll lm lo lp lr oy lv oz lz pa md pb pc pd pe bi translated"><em class="me">跟我上</em> <a class="ae lh" href="https://medium.com/@pedram-ataee" rel="noopener"> <em class="me">中</em> </a> <em class="me">！</em></li><li id="2ca5" class="ow ox it lk b ll pf lo pg lr ph lv pi lz pj md pb pc pd pe bi translated"><em class="me">在</em> <a class="ae lh" href="https://www.amazon.com/Pedram-Ataee/e/B08D6J3WNW" rel="noopener ugc nofollow" target="_blank"> <em class="me">亚马逊</em> </a> <em class="me">上查看我的书！</em></li><li id="6029" class="ow ox it lk b ll pf lo pg lr ph lv pi lz pj md pb pc pd pe bi translated"><em class="me">成为</em> <a class="ae lh" href="https://pedram-ataee.medium.com/membership" rel="noopener"> <em class="me">中的一员</em> </a> <em class="me">！</em></li><li id="9a4e" class="ow ox it lk b ll pf lo pg lr ph lv pi lz pj md pb pc pd pe bi translated"><em class="me">连接上</em><a class="ae lh" href="https://www.linkedin.com/in/pedrama/" rel="noopener ugc nofollow" target="_blank"><em class="me">Linkedin</em></a><em class="me">！</em></li><li id="6b66" class="ow ox it lk b ll pf lo pg lr ph lv pi lz pj md pb pc pd pe bi translated"><em class="me">关注我</em> <a class="ae lh" href="https://twitter.com/pedram_ataee" rel="noopener ugc nofollow" target="_blank"> <em class="me">推特</em> </a> <em class="me">！</em></li></ul><div class="mf mg gp gr mh mi"><a href="https://pedram-ataee.medium.com/membership" rel="noopener follow" target="_blank"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">通过我的推荐链接加入Medium—Pedram Ataee博士</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">pedram-ataee.medium.com</p></div></div><div class="mr l"><div class="pk l mt mu mv mr mw lb mi"/></div></div></a></div></div></div>    
</body>
</html>