<html>
<head>
<title>Logistic Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-in-python-2f965c355b93?source=collection_archive---------26-----------------------#2020-10-27">https://towardsdatascience.com/logistic-regression-in-python-2f965c355b93?source=collection_archive---------26-----------------------#2020-10-27</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="089b" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">详细的逻辑回归</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/2f489da1163dfe97857fd7626735e52b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Am3Z7yAe68CEKmciDv7NIg.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">照片由<a class="ae kz" href="https://www.pexels.com/@tracehudson?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Trace Hudson </a>从<a class="ae kz" href="https://www.pexels.com/photo/car-on-road-2770933/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a></p></figure><h1 id="bd95" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">Python中的逻辑回归</h1><p id="41ee" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">逻辑回归用于机器学习中的分类问题。它用于处理二值分类和多值分类。在逻辑回归中，目标变量/因变量应该是离散值或分类值。</p><p id="f183" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">二元分类→ </strong>有两个类值的问题比如男/女，是/否，真/假，0/1，通过/失败。</p><p id="2532" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">多类分类→ </strong>超过2个类值的问题。</p><p id="87eb" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">让我们在这个故事中了解一下二元分类的逻辑回归。</p><h1 id="60e1" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">涵盖的主题</h1><ol class=""><li id="713f" class="mt mu iu lu b lv lw ly lz mb mv mf mw mj mx mn my mz na nb bi translated">为什么不是线性回归？</li><li id="0f84" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">Sigmoid或Logit函数</li><li id="dd92" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">对数损失函数</li><li id="b52c" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">准确度分数</li><li id="a1d9" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">为什么称之为逻辑回归？</li><li id="d7d2" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">线性回归与逻辑回归</li><li id="c277" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">使用sklearn实现逻辑回归</li></ol><h1 id="9609" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">为什么不是线性回归</h1><p id="fa6a" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">问题:如果一个学生学习了x个小时，他通过的可能性有多大？</p><p id="af3e" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">这是一个分类问题。这里我们必须预测一个学生通过/失败的可能性。在逻辑回归中，目标变量不应该是字符串类型。我们必须将通过/失败转换为0/1。所以，预测的范围是从0到1。但在线性回归中，范围是从<strong class="lu iv"> -∞到+∞。</strong></p><p id="3438" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">如果我们想预测一个学生学习x个小时所获得的分数，这将是一个线性回归问题。</p><p id="a583" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">让我们取大约20名学生的数据，学习时间与结果(通过/失败)</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nh"><img src="../Images/703f2cdef4ade3999b189239b3a294d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*p1xKLf3g06mcIppb-vKBOg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="6f3e" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">从数据点来看，我们可以解释，学习时间越长，结果越倾向于1(通过)。</p><p id="62bc" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">如果我们试着拟合一条线性回归线，它会是这样的。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ni"><img src="../Images/334c4a3c31c8fee54d0d5ec6f34ed994.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*aOfkwMmfzWzrPvoiEO882A.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="a0e1" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">线性回归线范围从<strong class="lu iv"> -∞到+∞。但是对于我们的分类问题，结果应该属于0或1，或者我们必须预测介于0和1之间的概率。<br/>我们的数据看起来不像是一条直线。我们强行排成一条直线。大部分数据点没有经过那条直线。<br/> <strong class="lu iv">解决方法:</strong> <br/> 1。我们的线应该穿过大部分数据点。<br/> 2。它应该介于0和1之间。<br/> 3。类似于<code class="fe nj nk nl nm b">S curve</code>的东西会穿过大多数数据点。<br/> 4。使用sigmoid函数将最佳拟合线转换成S曲线。</strong></p><p id="13f7" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">线性回归方程:<code class="fe nj nk nl nm b"> y=mx+c</code></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nn"><img src="../Images/ed1593b222d7558c21da5be47228196d.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*LT6iF6C-Iw7BUsFa4V4n8A.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="99db" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">使用此公式将最佳拟合线转换为S曲线。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj no"><img src="../Images/43a602054669908e7ffe1a7c10780773.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*lxHn8yrhoS6RYaKbnlYL_w.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><h1 id="6930" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">Sigmoid或logit函数</h1><p id="4a14" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们来看看sigmoid公式的解释。该函数也称为Logit函数。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj np"><img src="../Images/e7cd29e3fc368d36bd522775cc0d2aaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*SBgrDU4heGK7X0FlZclF_w.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="b420" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">e →欧拉常数</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nq"><img src="../Images/e4d372bb55396b34834c420912755b9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*OD4E81paZYMmlRmB3yiHFw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="fc83" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">因此，通过使用sigmoid方程，我们可以保证y总是在0和1之间。</p><p id="0f7d" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">这个等式还有另一种解释。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nr"><img src="../Images/63c5a9e93a56134aa13f8ebdf5509b6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*xN4uMcf8-JUYK8Bjre_GQw.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="11fc" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">这两个等式是一样的。</p><h1 id="6b6a" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">对数损失函数</h1><p id="6691" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">方程中m和c怎么算？</p><p id="1e27" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在<strong class="lu iv">线性回归方程</strong>中，最佳拟合线将最小化<strong class="lu iv">平方和误差</strong>。通过找出观察值和预测值之间的差异来计算误差平方和。我们把所有的误差平方，然后求和。</p><p id="b7a7" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在<strong class="lu iv">逻辑回归方程</strong>中，最佳曲线将最小化<strong class="lu iv"> logloss函数。</strong></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ns"><img src="../Images/37470614ee70a16ea0a0dcf58bab28f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*xWaNnc2Xd4ZoaZ8UKy-kXg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="4931" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">y值将始终为0或1。</p><p id="b0d1" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">ŷ值将介于0和1之间。</p><p id="c9f2" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">有两种情况</p><ol class=""><li id="341d" class="mt mu iu lu b lv mo ly mp mb nt mf nu mj nv mn my mz na nb bi translated">如果y=0</li></ol><p id="6b2d" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">logloss=-log(1-ŷ)</code></p><p id="75af" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">(因为<code class="fe nj nk nl nm b">ylog(ŷ)</code>会变成0)</p><p id="183e" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">2.如果y=1</p><p id="3f89" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">logloss=-log(ŷ)</code></p><p id="06fe" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">[因为<code class="fe nj nk nl nm b">log(1-ŷ)</code>会变成0]</p><p id="a282" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">通过最小化logloss函数，观测值和预测值会更接近。</p><h1 id="5107" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">准确度分数</h1><p id="8c63" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">准确度分数用于确定模型的整体预测准确度。</p><p id="d307" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">混淆矩阵</strong></p><p id="acc2" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">混淆矩阵</strong>是一个表格，通常用于描述一个分类模型对一组真实值已知的测试数据的性能。矩阵的每一行代表预测类中的实例，而每一列代表实际类中的实例(反之亦然)</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nw"><img src="../Images/315cba5fe7127e4b7b8b2d860a0ee698.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*FE53yUNjeSl1i1gztNQmyQ.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="6d1e" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">TP →真阳性<br/> FP →假阳性<br/> FN →假阴性<br/> TN →真阴性</p><p id="5eda" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">准确度得分</strong></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nx"><img src="../Images/6a3d1aff7893ca02af5edc34d06fd41b.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*OcblTkG4pcla1EtbZGi8PQ.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><h1 id="3ab1" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">为什么称之为逻辑回归？</h1><p id="9079" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">术语<strong class="lu iv">“逻辑”</strong>来源于用于分类的<strong class="lu iv">“逻辑函数”</strong>。<br/>使用术语<strong class="lu iv">“回归”</strong>是因为我们使用了类似于<strong class="lu iv">线性回归的技术。</strong></p><h1 id="fcfc" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">线性回归与逻辑回归</h1><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ny"><img src="../Images/50a516a2a61d3ada4c3c775820ff02e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*43HBEXq0vvBG-XBsqciezw.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure></div><div class="ab cl nz oa hy ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="in io ip iq ir"><h1 id="362f" class="la lb iu bd lc ld og lf lg lh oh lj lk ka oi kb lm kd oj ke lo kg ok kh lq lr bi translated">使用sklearn实现逻辑回归</h1><ol class=""><li id="e558" class="mt mu iu lu b lv lw ly lz mb mv mf mw mj mx mn my mz na nb bi translated">导入库</li><li id="4ddf" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">加载数据</li><li id="fcca" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">电子设计自动化(Electronic Design Automation)</li><li id="86da" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">数据争论(清理数据)</li><li id="4287" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">将特征分配给x和y</li><li id="9566" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">培训和测试</li><li id="2838" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">计算准确度</li><li id="ce2c" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">预言；预测；预告</li></ol><h2 id="6cff" class="ol lb iu bd lc om on dn lg oo op dp lk mb oq or lm mf os ot lo mj ou ov lq ow bi translated"><strong class="ak"> 1。导入库</strong></h2><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="90df" class="ol lb iu nm b gz pb pc l pd pe"><strong class="nm iv">import </strong>numpy <strong class="nm iv">as </strong>np<br/><strong class="nm iv">import </strong>pandas <strong class="nm iv">as </strong>pd<br/><strong class="nm iv">import </strong>seaborn <strong class="nm iv">as </strong>sns<br/><strong class="nm iv">import </strong>matplotlib.pyplot <strong class="nm iv">as </strong>plt</span></pre><h2 id="cb63" class="ol lb iu bd lc om on dn lg oo op dp lk mb oq or lm mf os ot lo mj ou ov lq ow bi translated"><strong class="ak"> 2。加载数据</strong></h2><p id="0fd4" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">数据集results.csv包含小时与结果。[学生学习的小时数与他们的成绩通过/未通过]。它包含<code class="fe nj nk nl nm b"> StudentId</code>列也。</p><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="69f6" class="ol lb iu nm b gz pb pc l pd pe">df=pd.read_csv(<strong class="nm iv">"results.csv"</strong>)<br/>df.head(5)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pf"><img src="../Images/c8a2dfdcacc675a9717ae78d6f477edf.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*_o5C-mI00UocEnCXNgHhMg.png"/></div></figure><p id="47b4" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">df.shape</code></p><p id="8cc6" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">(20,3)</code></p><p id="53c3" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">数据集包含20行和3列</p><p id="b4bc" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">df.info()</code></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pg"><img src="../Images/57dba36ac9037b1e68113c86175b92e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*HlEtwDRRtaJdJVRwpBORkg.png"/></div></figure><p id="684e" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">它包含三列Hours、StudentID和Result</p><h2 id="2900" class="ol lb iu bd lc om on dn lg oo op dp lk mb oq or lm mf os ot lo mj ou ov lq ow bi translated"><strong class="ak"> 3。EDA </strong></h2><p id="8a32" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">通过创建不同的图来分析数据，以检查变量之间的关系。</p><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="dc0b" class="ol lb iu nm b gz pb pc l pd pe">sns.countplot(x=<strong class="nm iv">"Result"</strong>,data=df)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ph"><img src="../Images/4a8288f6374ee0fdb877e86bbac04e32.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*coGr4TDx1XXK6ylMTRCRUA.png"/></div></figure><p id="c175" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">散点图</strong></p><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="31db" class="ol lb iu nm b gz pb pc l pd pe">plt.scatter(df.Hours,df.Result,color=<strong class="nm iv">'red'</strong>)<br/>plt.xlabel(<strong class="nm iv">"Hours"</strong>)<br/>plt.ylabel(<strong class="nm iv">"Pass"</strong>)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pi"><img src="../Images/420669307d31758102d30f18d1d172de.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*wCLsTeTFsFQC032iBKbuuA.png"/></div></figure><p id="7fda" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">从散点图中，我们可以看出学习时间越长的学生越有可能通过考试。</p><h2 id="8fb7" class="ol lb iu bd lc om on dn lg oo op dp lk mb oq or lm mf os ot lo mj ou ov lq ow bi translated"><strong class="ak"> 4。数据争论</strong></h2><ul class=""><li id="74a8" class="mt mu iu lu b lv lw ly lz mb mv mf mw mj mx mn pj mz na nb bi translated"><strong class="lu iv">检查是否有数据缺失</strong></li></ul><p id="415e" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">df.isnull().sum()</code></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pk"><img src="../Images/aabc1d5a046fd3ad475db78d09460cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*DXiuZG7ejE2R6-kbQeSoGw.png"/></div></figure><p id="08ef" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">只有小时列有两个缺失数据。我们可以不排了。如果我们的数据集有许多列，意味着我们不能删除行。我们可能需要来自其他列的数据，在这种情况下，我们可以通过均值替换缺失的值。</p><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="97c7" class="ol lb iu nm b gz pb pc l pd pe">df.dropna(inplace=<strong class="nm iv">True</strong>)<br/>df.shape</span></pre><p id="c58c" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">(18,3)</code></p><p id="5946" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">删除缺少值的两行。现在数据集中只有18行。</p><ul class=""><li id="1b19" class="mt mu iu lu b lv mo ly mp mb nt mf nu mj nv mn pj mz na nb bi translated"><strong class="lu iv">移除不需要的柱</strong></li></ul><p id="0e5e" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在我们的数据集中，不需要<code class="fe nj nk nl nm b">StudentID</code>列。我们不打算对StudentID列进行任何分析。我们将根据学生学习的小时数来预测结果。</p><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="96fe" class="ol lb iu nm b gz pb pc l pd pe">df1=df.drop(<strong class="nm iv">"StudentId"</strong>,axis=1)<br/>df1.head()</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pl"><img src="../Images/62a049700a5c9edb275f6b5ceb1610be.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*2s7aToougk8F7V96XJMdFQ.png"/></div></figure><p id="68a8" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">StudentID</code>列现在已从数据集中删除。</p><ul class=""><li id="cd24" class="mt mu iu lu b lv mo ly mp mb nt mf nu mj nv mn pj mz na nb bi translated">在逻辑回归中，它不会处理字符串数据类型。我们要预测结果→通过/失败。我们可以将该列转换为离散变量0和1。</li></ul><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="8539" class="ol lb iu nm b gz pb pc l pd pe">result=pd.get_dummies(df[<strong class="nm iv">"Result"</strong>])<br/>result.head(3)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pm"><img src="../Images/6e2aba3bc808a1c8129fd6b18ba85671.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*3bY-iwvM4aCIqd7wIwoOvA.png"/></div></figure><p id="558a" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">现在，我们可以保留失败/通过列，删除另一列。</p><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="8cb0" class="ol lb iu nm b gz pb pc l pd pe">result=pd.get_dummies(df[<strong class="nm iv">"Result"</strong>],drop_first=<strong class="nm iv">True</strong>)<br/>result.head(3)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pn"><img src="../Images/99d340707336326af963f5d2ee691981.png" data-original-src="https://miro.medium.com/v2/resize:fit:236/format:webp/1*ujns7zItLEHb9Erco2xBjw.png"/></div></figure><p id="1a0f" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在“通过”列中，0表示失败，1表示通过。</p><p id="8df5" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">现在将传递列连接到数据帧</p><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="4cce" class="ol lb iu nm b gz pb pc l pd pe">df1=pd.concat([df1,result],axis=1)<br/>df1.head(3)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj po"><img src="../Images/a3d2bba93b3e44b9926c639250fc5bea.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*069KD19f8tZilhIA-ff6Uw.png"/></div></figure><p id="8736" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">现在我们可以从dataframe中删除<code class="fe nj nk nl nm b">Result</code>列。我们已经将结果列转换为<code class="fe nj nk nl nm b">Pass</code>列。</p><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="0372" class="ol lb iu nm b gz pb pc l pd pe">df1=df1.drop(<strong class="nm iv">"Result"</strong>,axis=1)<br/>df1.head(3)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pp"><img src="../Images/845e71ec2234dbc5301f1e8bc754cccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*gZvhL8d_H_3HK1K73y3oNg.png"/></div></figure><h2 id="ff10" class="ol lb iu bd lc om on dn lg oo op dp lk mb oq or lm mf os ot lo mj ou ov lq ow bi translated"><strong class="ak"> 5。给x和y分配特征</strong></h2><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="89bb" class="ol lb iu nm b gz pb pc l pd pe">x=df1.iloc[:,0:1]<br/>x.head(3)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pq"><img src="../Images/ef357c2b6a45fc1f66a5c29447012200.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*QkEbuPO_hi5OTFjj4KnQPA.png"/></div></figure><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="49a9" class="ol lb iu nm b gz pb pc l pd pe">y=df1.iloc[:,1:]<br/>y.head(3)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pr"><img src="../Images/b715b6679fd824747d5884292285b005.png" data-original-src="https://miro.medium.com/v2/resize:fit:206/format:webp/1*8iiyBBeDZIu630TnqfQPdQ.png"/></div></figure><h2 id="47d4" class="ol lb iu bd lc om on dn lg oo op dp lk mb oq or lm mf os ot lo mj ou ov lq ow bi translated">6.训练和测试数据</h2><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="9514" class="ol lb iu nm b gz pb pc l pd pe"><strong class="nm iv">from </strong>sklearn.model_selection <strong class="nm iv">import </strong>train_test_split<br/>xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=2)<br/><strong class="nm iv">from </strong>sklearn.linear_model <strong class="nm iv">import </strong>LogisticRegression<br/>log_reg=LogisticRegression()<br/>log_reg.fit(xtrain,ytrain)</span></pre><h2 id="48f5" class="ol lb iu bd lc om on dn lg oo op dp lk mb oq or lm mf os ot lo mj ou ov lq ow bi translated">7.计算准确度</h2><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="0b8f" class="ol lb iu nm b gz pb pc l pd pe">predictions=log_reg.predict(xtest)<br/><strong class="nm iv">from </strong>sklearn.metrics <strong class="nm iv">import </strong>confusion_matrix<br/>cm=confusion_matrix(ytest,predictions)<br/>print (cm)</span></pre><p id="c18f" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">输出:<br/> </strong> [[2 1] <br/> [0 1]]</p><pre class="kk kl km kn gu ox nm oy oz aw pa bi"><span id="9948" class="ol lb iu nm b gz pb pc l pd pe"><strong class="nm iv">from </strong>sklearn.metrics <strong class="nm iv">import </strong>accuracy_score<br/>accuracy_score(ytest,predictions)</span></pre><p id="21d0" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">输出:</strong> 0.75</p><p id="b1c1" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">准确度得分为0.75。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ps"><img src="../Images/54ab1cb5ab27bda1e4f40992aa134d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*R4w7VaU2tqklYGe4-btb1g.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">根据混淆矩阵计算准确度分数[图片由作者提供]</p></figure><h2 id="0e92" class="ol lb iu bd lc om on dn lg oo op dp lk mb oq or lm mf os ot lo mj ou ov lq ow bi translated">8.预言；预测；预告</h2><p id="8140" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们来预测一下，如果一个学生学习7个小时，这个学生通过的可能性有多大？</p><p id="a406" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">log_reg.predict(np.array([[7]]))</code></p><p id="d407" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">输出:</strong>数组([1]，dtype=uint8)</p><p id="b2d4" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">1</code>表示通过。</p><p id="af84" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">预测概率</strong></p><p id="bdab" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><code class="fe nj nk nl nm b">log_reg.predict_proba(np.array([[7]]))</code></p><p id="1dfe" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">输出:</strong>数组([[0.00182823，0.99817177]])</p><p id="f204" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">0.00182823 →表示学生不及格的概率<br/> 0.99817177 →表示学生及格的概率</p><h1 id="4d1e" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">Github链接。</h1><p id="c328" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">这里使用的代码可以作为<a class="ae kz" href="https://github.com/IndhumathyChelliah/LogisticRegression" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本从我的GitHub下载。</a></p><h1 id="841f" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">我关于机器学习的其他博客</h1><div class="pt pu gq gs pv pw"><a rel="noopener follow" target="_blank" href="/line-of-best-fit-in-linear-regression-13658266fbc8"><div class="px ab fp"><div class="py ab pz cl cj qa"><h2 class="bd iv gz z fq qb fs ft qc fv fx it bi translated">线性回归中的最佳拟合线</h2><div class="qd l"><h3 class="bd b gz z fq qb fs ft qc fv fx dk translated">相关系数、决定系数、模型系数</h3></div><div class="qe l"><p class="bd b dl z fq qb fs ft qc fv fx dk translated">towardsdatascience.com</p></div></div><div class="qf l"><div class="qg l qh qi qj qf qk kt pw"/></div></div></a></div><div class="pt pu gq gs pv pw"><a rel="noopener follow" target="_blank" href="/an-introduction-to-support-vector-machine-3f353241303b"><div class="px ab fp"><div class="py ab pz cl cj qa"><h2 class="bd iv gz z fq qb fs ft qc fv fx it bi translated">支持向量机简介</h2><div class="qd l"><h3 class="bd b gz z fq qb fs ft qc fv fx dk translated">如何在分类问题中使用SVM？</h3></div><div class="qe l"><p class="bd b dl z fq qb fs ft qc fv fx dk translated">towardsdatascience.com</p></div></div><div class="qf l"><div class="ql l qh qi qj qf qk kt pw"/></div></div></a></div><div class="pt pu gq gs pv pw"><a rel="noopener follow" target="_blank" href="/an-introduction-to-k-nearest-neighbours-algorithm-3ddc99883acd"><div class="px ab fp"><div class="py ab pz cl cj qa"><h2 class="bd iv gz z fq qb fs ft qc fv fx it bi translated">K-最近邻算法简介</h2><div class="qd l"><h3 class="bd b gz z fq qb fs ft qc fv fx dk translated">什么是KNN？</h3></div><div class="qe l"><p class="bd b dl z fq qb fs ft qc fv fx dk translated">towardsdatascience.com</p></div></div><div class="qf l"><div class="qm l qh qi qj qf qk kt pw"/></div></div></a></div><div class="pt pu gq gs pv pw"><a href="https://pub.towardsai.net/naive-bayes-classifier-in-machine-learning-b0201684607c" rel="noopener  ugc nofollow" target="_blank"><div class="px ab fp"><div class="py ab pz cl cj qa"><h2 class="bd iv gz z fq qb fs ft qc fv fx it bi translated">机器学习中的朴素贝叶斯分类器</h2><div class="qd l"><h3 class="bd b gz z fq qb fs ft qc fv fx dk translated">使用sklearn的数学解释和python实现</h3></div><div class="qe l"><p class="bd b dl z fq qb fs ft qc fv fx dk translated">pub.towardsai.net</p></div></div><div class="qf l"><div class="qn l qh qi qj qf qk kt pw"/></div></div></a></div><div class="pt pu gq gs pv pw"><a href="https://pub.towardsai.net/naive-bayes-classifier-in-machine-learning-b0201684607c" rel="noopener  ugc nofollow" target="_blank"><div class="px ab fp"><div class="py ab pz cl cj qa"><h2 class="bd iv gz z fq qb fs ft qc fv fx it bi translated">机器学习中的朴素贝叶斯分类器</h2><div class="qd l"><h3 class="bd b gz z fq qb fs ft qc fv fx dk translated">使用sklearn的数学解释和python实现</h3></div><div class="qe l"><p class="bd b dl z fq qb fs ft qc fv fx dk translated">pub.towardsai.net</p></div></div><div class="qf l"><div class="qn l qh qi qj qf qk kt pw"/></div></div></a></div></div><div class="ab cl nz oa hy ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="in io ip iq ir"><p id="fb58" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">请关注此空间，了解更多关于Python和数据科学的文章。如果你喜欢看我的更多教程，就关注我的 <a class="ae kz" href="https://medium.com/@IndhumathyChelliah" rel="noopener"> <strong class="lu iv"> <em class="qo">中</em></strong></a><a class="ae kz" href="https://www.linkedin.com/in/indhumathy-chelliah/" rel="noopener ugc nofollow" target="_blank"><strong class="lu iv"><em class="qo">LinkedIn</em></strong></a><strong class="lu iv"><em class="qo"/></strong><a class="ae kz" href="https://twitter.com/IndhuChelliah" rel="noopener ugc nofollow" target="_blank"><strong class="lu iv"><em class="qo">Twitter</em></strong></a><strong class="lu iv"><em class="qo">。</em> </strong></p><p id="8416" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv"> <em class="qo">点击此处成为中等会员:</em> </strong></p><p id="9488" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><a class="ae kz" href="https://indhumathychelliah.medium.com/membership" rel="noopener"><em class="qo">https://indhumathychelliah.medium.com/membership</em></a></p></div></div>    
</body>
</html>