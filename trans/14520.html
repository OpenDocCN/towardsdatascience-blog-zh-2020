<html>
<head>
<title>Evaluation metrics &amp; Model Selection in Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归中的评价指标和模型选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/evaluation-metrics-model-selection-in-linear-regression-73c7573208be?source=collection_archive---------5-----------------------#2020-10-07">https://towardsdatascience.com/evaluation-metrics-model-selection-in-linear-regression-73c7573208be?source=collection_archive---------5-----------------------#2020-10-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f9cc" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">数据科学</h2><div class=""/><div class=""><h2 id="1c9b" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">揭开最常见的度量和模型选择方法的神秘面纱</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/698c423ca5b359c0e4f31812d7eb4654.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dy3h27CBsuC5NOc-"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">克里斯·利维拉尼在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="e32b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本文中，我们将回顾线性回归中最常见的评估指标以及模型选择策略。</p><h1 id="06fd" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">残差图-评估模型之前</h1><p id="3c02" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">我们知道，线性回归试图拟合一条线，使预测值和实际值之间的差异最小，这些差异也是无偏的。这种差异或误差也被称为<strong class="lh ja">残差。(</strong> <em class="my">无偏是指预测值没有系统的分布模式)</em></p><p id="3590" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">残差=实际值—预测值</strong></p><p id="757d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="my">e</em>=<em class="my">y</em>—<em class="my">ŷ</em></p><p id="6929" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">值得注意的是，在使用R平方等评估指标评估或评价我们的模型之前，我们必须利用残差图。</p><p id="a90f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="my">残差图暴露了一个比其他任何评价指标都有偏差的模型。如果你的残差图看起来正常，继续，用各种度量评估你的模型。</em>T19】</strong></p><p id="c959" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">残差图在y轴上显示残差值，在x轴上显示预测值。如果你的模型有偏差，你就不能相信结果。</p><p id="193e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">显示对应于预测值的误差的残差图必须是随机分布的。然而，如果有任何系统模式的迹象，那么你的模型是有偏见的。</p><p id="27cb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">但是随机分布的误差意味着什么呢？<br/> 线性回归模型的假设之一是误差必须是正态分布的。这意味着，对于整个预测值范围，确保残差分布在零附近。因此，如果残差是均匀分布的，那么您的模型可能表现良好。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="4608" class="mb mc iq bd md me ng mg mh mi nh mk ml kf ni kg mn ki nj kj mp kl nk km mr ms bi translated">线性回归模型的评估指标</h1><p id="dd38" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">评估指标是衡量模型表现的好坏以及它与关系的近似程度。让我们看看MSE、MAE、R平方、调整R平方和RMSE。</p><h2 id="1323" class="nl mc iq bd md nm nn dn mh no np dp ml lo nq nr mn ls ns nt mp lw nu nv mr iw bi translated">均方误差</h2><p id="3226" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">回归任务最常见的度量是MSE。它有一个凸起的形状。它是预测值和实际值之差的平均值。因为它是可微分的，并且具有凸形，所以更容易优化。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/48b4441172dc4c5842ce1af798487cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*aLt5bWtuBr_V7TrBILe3qQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">均方差。图片由作者提供。</p></figure><p id="3208" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">MSE惩罚大的错误。</p><h2 id="abf2" class="nl mc iq bd md nm nn dn mh no np dp ml lo nq nr mn ls ns nt mp lw nu nv mr iw bi translated">平均绝对误差</h2><p id="cc5c" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">这只是目标值和模型预测值之间的绝对差值的平均值。在异常值突出的情况下，不推荐使用。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/03fdfbab55a345cc66aed06e0aa34552.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*aRKkks7Fr302wcpJiaI5RA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">平均绝对误差。图片由作者提供。</p></figure><p id="d29d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">MAE不惩罚大的错误。</p><h2 id="8fa1" class="nl mc iq bd md nm nn dn mh no np dp ml lo nq nr mn ls ns nt mp lw nu nv mr iw bi translated">r平方或决定系数</h2><p id="a363" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">此指标表示由模型的自变量解释的因变量方差部分。它衡量模型和因变量之间的关系强度。</p><p id="8512" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了理解R-square真正代表什么，让我们考虑下面的情况，在有和没有独立变量的知识的情况下，我们测量模型的误差。</p><p id="283b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">计算回归误差<br/> </strong>当我们知道自变量的值时，我们可以计算回归误差。</p><p id="f190" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们知道残差是实际值和预测值之间的差值。因此，RSS(残差平方和)可以计算如下。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ny"><img src="../Images/63be395baed6f16e3a8361fca7560107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*glXqPbWKcdlQA3p8wtBasw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">剩余平方和。图片由作者提供。</p></figure><p id="366a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">计算平方残差<br/> </strong>考虑我们不知道自变量的值的情况。我们只有y的值。这样，我们就可以计算出<em class="my"> y </em>值的<strong class="lh ja">平均值。</strong>这个点可以表示为一条水平线。现在我们计算平均<strong class="lh ja">y值</strong>和每隔一个<strong class="lh ja">y<em class="my">y</em>T19】值之间的误差平方和。</strong></p><p id="c527" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Y中的总变化可以被给出为每个点之间的距离的平方差和Y值的算术平均值。这可以被称为<strong class="lh ja"> TSS </strong>(总平方和)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/0e2b36aa951ed3dca23c55012209268c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*nmhlSwtVwD3d244JcdBTvQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">y或TSS的总变化。图片由作者提供。</p></figure><p id="edf8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">用RSS &amp; TSS <br/> </strong>计算决定系数，因此我们想找出Y的总变化的百分比，由独立变量x描述。如果我们知道Y的总变化的百分比，即回归线描述的<strong class="lh ja">而不是</strong>，我们可以从1中减去相同的值以获得<strong class="lh ja">决定系数或R平方。</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oa"><img src="../Images/455a1195e780085360aa01b55ecfdb44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b0d8Q-gZ-2KL31Y7t4QK3Q.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片由作者提供。</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ob"><img src="../Images/3c7ac9f91b417c4afb1c9fc254d22274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1q9TBl7kDjol_Xq35OHmrg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">决定系数。图片由作者提供。</p></figure><blockquote class="oc od oe"><p id="ad31" class="lf lg my lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated"><em class="iq">如果数据点非常接近回归线，则该模型说明了大量的方差，从而导致高R值。</em></p><p id="e234" class="lf lg my lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated">然而，不要让R值欺骗了你。一个好的模型可以具有低的R值，而一个有偏差的模型也可以具有高的R值。这就是你应该利用剩余地块的原因。</p></blockquote><p id="4348" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">总之，残差(RSS)与总误差(TSS)的比率告诉您回归模型中还有多少总误差。从1中减去该比率，就可以得出使用回归分析消除了多少误差。这就是R平方误差。</p><p id="009d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="my">如果R很高(比如说1)，那么模型代表因变量的方差。</em> </strong></p><p id="6928" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="my">如果R非常低，那么模型不代表因变量的方差，回归并不比取平均值好，也就是说，你没有使用来自其他变量的任何信息。</em>T3】</strong></p><p id="14bd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="my">负R表示你做的比平均值差。如果预测值根本不能解释因变量，那么RSS ~ TSS可能为负值。</em> </strong></p><p id="a0d4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，R评估回归线周围的分散数据点。</p><p id="c7d5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">不可能看到R为1的模型。在这种情况下，所有预测值都与实际值相同，这实质上意味着所有值都落在回归线上。</p><h2 id="e19b" class="nl mc iq bd md nm nn dn mh no np dp ml lo nq nr mn ls ns nt mp lw nu nv mr iw bi translated">均方根误差(RMSE)</h2><p id="288b" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">这是预测值和实际值的平方差的平均值的平方根。</p><p id="edb5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">r平方误差优于RMSE。这是因为R平方是相对测量值，而RMSE是拟合的绝对测量值(高度依赖于变量，而不是归一化测量值)。</p><p id="d676" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基本上，RMSE只是残差平方平均值的根。我们知道残差是一个度量点离回归线有多远的指标。因此，RMSE测量这些残差的分散。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/51fc6976371a3b630bb7fb597c52cb11.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*bGLNxW-DvjRTvLMvol4vjQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">均方根误差。图片由作者提供。</p></figure><p id="7c8a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">RMSE惩罚大错误。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="58a4" class="mb mc iq bd md me ng mg mh mi nh mk ml kf ni kg mn ki nj kj mp kl nk km mr ms bi translated">模型选择和子集回归</h1><p id="4dd9" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">让我澄清一下，当你开发任何考虑到所有预测或回归变量的模型时，它被称为<strong class="lh ja">完整模型。<br/> </strong>如果你丢弃一个或多个回归变量或预测变量，那么这个模型就是一个<strong class="lh ja">子集模型。</strong></p><p id="c2f1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> <em class="my">子集回归背后的一般思想是找出哪个做得更好。子集模型或完整模型。</em> </strong></p><p id="0468" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们选择在所有可用候选预测值中表现最好的预测值子集，这样我们就有最大的<em class="my"> R </em>值、最大的调整R或最小的<em class="my"> MSE </em>。</p><p id="f496" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="my">然而，R从不用于比较模型，因为R的值随着预测因子数量的增加而增加(即使这些预测因子没有给模型增加任何值)。</em></p><blockquote class="oc od oe"><p id="9290" class="lf lg my lh b li lj ka lk ll lm kd ln of lp lq lr og lt lu lv oh lx ly lz ma ij bi translated"><strong class="lh ja">选择模型的原因<br/> </strong>我们着手选择能很好解释数据的预测因子的最佳子集。由于降低了复杂性，充分解释关系的更简单模型总是更好的选择。增加不必要的回归变量会增加噪声。</p></blockquote><p id="50dd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">我们现在来看看比较和选择最佳模型的最常见标准和策略。</strong></p><h2 id="9e3d" class="nl mc iq bd md nm nn dn mh no np dp ml lo nq nr mn ls ns nt mp lw nu nv mr iw bi translated">调整的R平方—选择标准</h2><p id="17fe" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><strong class="lh ja">调整后的R平方</strong>与R平方的主要区别在于，<strong class="lh ja"> R平方</strong>描述的是每个独立变量所代表的因变量的方差，而<strong class="lh ja">调整后的R平方</strong>测量的是仅由实际影响因变量的独立变量所解释的方差。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/3f16f7b6b7e89720ceb9b2daee3e7759.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*stA8fyU3xZI7sMhzNNeiCA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">调整后的R平方。图片由作者提供。</p></figure><p id="26b3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="my">在上面的等式中，n是数据点的数量，而k是模型中变量的数量，不包括常数。</em></p><p id="7271" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">r往往随着自变量数量的增加而增加。这可能会产生误导。因此，调整后的R平方由于增加了不符合模型的独立变量(方程中的k)而对模型不利。</p><h2 id="8b63" class="nl mc iq bd md nm nn dn mh no np dp ml lo nq nr mn ls ns nt mp lw nu nv mr iw bi translated">马洛的Cp —选择标准</h2><p id="240b" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Mallow的Cp衡量模型的有用性。它试图计算均方预测误差。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/38b3a4009ce62406678f4c7977da0456.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*PP1gP9yeIHW_aMbRE0_MXA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">马洛的Cp统计。作者图片。</p></figure><p id="2439" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里的<strong class="lh ja"> <em class="my"> p </em> </strong>是回归数，<strong class="lh ja"><em class="my"/></strong>是模型的RSS为给定的<strong class="lh ja"> <em class="my"> p </em> </strong>回归数，<strong class="lh ja"><em class="my"/></strong>是总MSE为<strong class="lh ja"> <em class="my"> k </em> </strong>总预测数，而<strong class="lh ja"> <em class="my"> n </em> </strong>是<strong class="lh ja"> <em class="my">这在n&gt;&gt;k&gt;</em></strong>时很有用</p><p id="a2aa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Mallow的Cp将完整模型与子集模型进行了比较。如果<strong class="lh ja"> <em class="my"> Cp </em> </strong>几乎等于<strong class="lh ja"> <em class="my"> p </em> </strong>(越小越好)，那么子集模型就是一个合适的选择。</p><p id="2a3d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">可以为每个子集模型绘制<strong class="lh ja"> <em class="my"> Cp对p </em> </strong>以找出候选模型。</p><h2 id="4b9a" class="nl mc iq bd md nm nn dn mh no np dp ml lo nq nr mn ls ns nt mp lw nu nv mr iw bi translated">穷举和最佳子集搜索</h2><p id="ae70" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><strong class="lh ja">穷举搜索</strong>查看所有模型。如果有<strong class="lh ja"> <em class="my"> k </em> </strong>个回归量，就有<strong class="lh ja"><em class="my"/></strong>个可能的模型。这是一个非常缓慢的过程。</p><p id="1f7c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">最佳子集策略</strong>通过为每个<strong class="lh ja"> <em class="my"> P值</em> </strong>寻找最小化RSS的模型来简化搜索。</p><h2 id="7b02" class="nl mc iq bd md nm nn dn mh no np dp ml lo nq nr mn ls ns nt mp lw nu nv mr iw bi translated">逐步回归</h2><p id="e42b" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">逐步回归比穷举和最佳子集搜索更快。选择最佳模型是一个反复的过程。<br/> <em class="my">逐步回归分为向后选择和向前选择。</em> <br/> <strong class="lh ja">逆向选择</strong>从一个完整的模型开始，然后我们一步一步减少回归变量，找到RSS最小、R最大或者MSE最小的模型。要删除的变量是那些具有高p值的变量。然而，重要的是要注意，你不能删除一个分类变量的一个层次。这样做会导致一个有偏见的模型。要么删除分类变量的所有级别，要么不删除。<br/> <strong class="lh ja">前向选择</strong>从一个空模型开始，然后我们逐步增加回归变量，直到我们无法再提高模型的误差性能。我们通常选择调整后R最高的模型。</p><div class="ol om gp gr on oo"><a href="https://bit.ly/3lSfQM2" rel="noopener  ugc nofollow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd ja gy z fp ot fr fs ou fu fw iz bi translated">机器学习中模型评估和选择的终极指南- neptune.ai</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">在高层次上，机器学习是统计和计算的结合。机器学习的关键在于…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">bit.ly</p></div></div><div class="ox l"><div class="oy l oz pa pb ox pc ky oo"/></div></div></a></div></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="608a" class="mb mc iq bd md me ng mg mh mi nh mk ml kf ni kg mn ki nj kj mp kl nk km mr ms bi translated">结论</h1><p id="3bda" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">我们讨论了线性回归中最常用的评估指标。我们看到了在多元线性回归和模型选择过程中使用的指标。在浏览了最常见的评估指标和选择策略的用例之后，我希望您理解了它们的潜在含义。下一场见。干杯。</p><h1 id="882f" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">谢谢你</h1></div></div>    
</body>
</html>