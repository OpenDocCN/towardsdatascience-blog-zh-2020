<html>
<head>
<title>Pipeline For Text Data Pre-processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于文本数据预处理的流水线</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pipeline-for-text-data-pre-processing-a9887b4e2db3?source=collection_archive---------20-----------------------#2020-11-13">https://towardsdatascience.com/pipeline-for-text-data-pre-processing-a9887b4e2db3?source=collection_archive---------20-----------------------#2020-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5384" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Python简化使用文本数据建模的所有准备工作</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/82812f8fdc5719e38c4073cc63f5ac9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3fjZr2evqA1GJWQV"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">迈克·本纳在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="eeed" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">GitHub <a class="ae kv" href="https://github.com/caseywhorton/Text-Pre-Processing" rel="noopener ugc nofollow" target="_blank">链接</a></h2><h1 id="7b34" class="ls kx iq bd ky lt lu lv lb lw lx ly le jw lz jx li jz ma ka lm kc mb kd lq mc bi translated">介绍</h1><p id="9d51" class="pw-post-body-paragraph md me iq mf b mg mh jr mi mj mk ju ml lf mm mn mo lj mp mq mr ln ms mt mu mv ij bi translated">如果你对这个比了解其背后的快速动机更感兴趣，请跳到实际的管道部分:<strong class="mf ir">文本预处理管道(博客中途)。</strong></p><p id="cd24" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">我一直在研究对文本数据执行机器学习，但有一些数据预处理步骤是我不习惯的文本数据所特有的。因此，我的Python代码包含了许多转换步骤，在这些步骤中，我会与数据争论，进行转换，然后转换训练数据，转换测试数据，然后对我想要进行的每种类型的转换重复这个过程。我记得曾经读到过Python有一种包装转换的便捷方法，但在此之前从未有过深入研究的理由。通常，我会对数字数据进行标准化缩放，或者创建一些虚拟变量，仅此而已。现在我进入了一个对我来说有点新的领域，我想保持这些转变并学习一些新的东西。</p><h1 id="0ee8" class="ls kx iq bd ky lt lu lv lb lw lx ly le jw lz jx li jz ma ka lm kc mb kd lq mc bi translated">导入必要的包</h1><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="a30d" class="kw kx iq nc b gy ng nh l ni nj">import numpy as np<br/>import pandas as pd<br/>from scipy import sparse as sp</span><span id="3c6c" class="kw kx iq nc b gy nk nh l ni nj">from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.feature_extraction.text import TfidfTransformer</span><span id="c285" class="kw kx iq nc b gy nk nh l ni nj">from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import LabelEncoder</span><span id="b52c" class="kw kx iq nc b gy nk nh l ni nj">from sklearn.feature_selection import chi2<br/>from sklearn.feature_selection import SelectKBest</span></pre><p id="c54a" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">如果你像我一年前一样是使用NLTK的新手，<a class="ae kv" href="https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/" rel="noopener ugc nofollow" target="_blank">这个网站将帮助你启动并运行</a>，并且被保存到我的收藏夹中，因为我在使用NLTK时经常使用它作为参考。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="790f" class="kw kx iq nc b gy ng nh l ni nj"># Import Natural language Toolkit example data and 'stopwords' set</span><span id="ea7a" class="kw kx iq nc b gy nk nh l ni nj">from nltk.corpus import movie_reviews<br/>from nltk.corpus import stopwords</span></pre><h1 id="30d2" class="ls kx iq bd ky lt lu lv lb lw lx ly le jw lz jx li jz ma ka lm kc mb kd lq mc bi translated">导入示例“电影评论”数据集</h1><p id="ab72" class="pw-post-body-paragraph md me iq mf b mg mh jr mi mj mk ju ml lf mm mn mo lj mp mq mr ln ms mt mu mv ij bi translated">“电影评论”数据有2000个电影评论，每个评论都有一个相应的类别(标签)，用于表示它是负面的(“负面”)还是正面的(“正面”)。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="ceed" class="kw kx iq nc b gy ng nh l ni nj">docs = [(str(movie_reviews.raw(fileid)), category)<br/> for category in movie_reviews.categories()<br/> for fileid in movie_reviews.fileids(category)]</span></pre><p id="19c4" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">现在只是把“文档”改成熊猫数据框架，主要是因为我习惯了这种格式。数据转换管道不仅仅适用于熊猫数据帧。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="85ed" class="kw kx iq nc b gy ng nh l ni nj">reviews = pd.DataFrame(docs)<br/>reviews.columns=('X','y')</span></pre><p id="a083" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">电影评论的“类别”最初是“负面”或“正面”，在这里分别更改为0和1:</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="85fa" class="kw kx iq nc b gy ng nh l ni nj">bin_encoder=LabelEncoder()<br/>reviews.y=bin_encoder.fit_transform(reviews.y)</span></pre><p id="51a1" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">此时，评审在一个数据框架中，其中<strong class="mf ir"> X </strong>列作为评审文本，<strong class="mf ir"> y </strong>列作为目标变量，评审类别。这更符合我目前习惯的机器学习项目的风格。以下是前5个观察结果的视图:</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="0148" class="kw kx iq nc b gy ng nh l ni nj">reviews.head(5)</span></pre><p id="c64d" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">故事情节:两对青少年夫妇去参加一个教堂聚会，… 0 1快乐私生子的快速电影评论\ndamn … 0 2正是这样的电影使一部令人厌倦的电影… 0 3《寻找卡梅洛特》是华纳兄弟公司出品的</p><p id="45b6" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">需要做的是将<strong class="mf ir"> X </strong>列标记化，删除停用词，并将每个观察结果矢量化，以便机器学习如何区分正面和负面评论。</p><h1 id="d80f" class="ls kx iq bd ky lt lu lv lb lw lx ly le jw lz jx li jz ma ka lm kc mb kd lq mc bi translated">停用词</h1><p id="0e7a" class="pw-post-body-paragraph md me iq mf b mg mh jr mi mj mk ju ml lf mm mn mo lj mp mq mr ln ms mt mu mv ij bi translated">NLTK和Scikit-Learn函数<em class="nl"> CountVectorizer </em>都有内置的停用词集合或列表，它们基本上是一串我们不希望在数据中出现的词。像“a”、“of”和“the”这样的词通常是没有用的，它们在句子或段落中出现的频率比其他词高。不过，有时你想添加一些你自己的自定义停用词，所以我在这里创建了我的列表，custom_stopwords :</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="e14b" class="kw kx iq nc b gy ng nh l ni nj">mystopwords = (stopwords.words())<br/>custom_stopwords = ('the','an','a','my','0','''''','!','nt','?','??','?!','%','&amp;','UTC','(UTC)')</span></pre><p id="1e51" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">现在，电影评论已经在一个数据帧中，并且有一个可以从电影评论中删除的停用词列表，我将展示我之前使用的文本预处理管道和我使用Sci-kit Learn的<em class="nl">管道</em>制作的管道。</p><h1 id="19ee" class="ls kx iq bd ky lt lu lv lb lw lx ly le jw lz jx li jz ma ka lm kc mb kd lq mc bi translated">文本预处理管道</h1><h2 id="ce97" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">用于文本转换的陈旧生锈的“管道”</h2><p id="cd06" class="pw-post-body-paragraph md me iq mf b mg mh jr mi mj mk ju ml lf mm mn mo lj mp mq mr ln ms mt mu mv ij bi translated">这个想法是将所有的句子放入一个大矩阵中，矩阵中的列代表单个单词，术语频率或术语频率逆文档频率作为相应单词下的观察值。<br/>通常，在机器学习项目中，你需要重复你对训练数据到测试数据所做的转换，所以我明确地保存了转换。这就是为什么我用一行来保存<em class="nl"> TfidfTransform </em>和另一行来实际转换训练数据。后来，我在测试数据集上使用了那个<em class="nl"> TfidfTransform </em>。我用<em class="nl">计数矢量器</em>做了同样的事情。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="cfe6" class="kw kx iq nc b gy ng nh l ni nj">count_vect = CountVectorizer(stop_words=mystopwords,lowercase=True)<br/>X_train_counts = count_vect.fit_transform(X)<br/>tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)<br/>X_train_tfidf = tf_transformer.transform(X_train_counts)</span></pre><p id="77cc" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">类似地，为了选择数据集的前k个特征(单词),我确保保存转换并将其应用于训练和测试数据集。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="57e4" class="kw kx iq nc b gy ng nh l ni nj">chi2(X_res,y_res)<br/>k=1000<br/>ch2_score = SelectKBest(chi2, k=k)<br/>toxic_feature_tran = ch2_score.fit(X,y)<br/>X_train_k = ch2_score.fit_transform(X, y)<br/>X_test_k = ch2_score.transform(X_test)</span></pre><p id="0eca" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">这不仅是一个麻烦，而且如果我不得不在任何时间点重复这个过程，那么我将不得不创建新的变量，并确保所有这些步骤按顺序进行，不要覆盖任何内容。这不是好的编码。这就是<em class="nl">管道</em>进入并清理一切的地方。</p><h2 id="21a1" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">新文本预处理转换</h2><p id="10cf" class="pw-post-body-paragraph md me iq mf b mg mh jr mi mj mk ju ml lf mm mn mo lj mp mq mr ln ms mt mu mv ij bi translated"><a class="ae kv" href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank">如果你的机器学习项目开始处理几个转换</a>，这是你需要下载和利用的包。对于Python中的每一个具有'<strong class="mf ir"> fit_transform()' </strong>方法的转换(我在这里使用的所有方法都是如此)，我们可以将它们包装在一个实际的管道中，该管道按顺序执行它们，甚至可以返回并查看每个转换的属性。此外，您可以为每个转换设置参数，语法在我刚刚分享的链接中。如果有什么不同的话，使用这个管道已经清理了我的代码，并且更好地组织了我的思维。</p><p id="25ac" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">使用这三个转换:</p><ul class=""><li id="e2c0" class="nm nn iq mf b mg mw mj mx lf no lj np ln nq mv nr ns nt nu bi translated"><strong class="mf ir">“计数矢量化器”</strong>:从句子转换为所有小写单词，删除停用词，矢量化</li><li id="f9cc" class="nm nn iq mf b mg nv mj nw lf nx lj ny ln nz mv nr ns nt nu bi translated"><strong class="mf ir">【chi 2s score】</strong>:基于卡方检验统计选择与目标相关的前k个特征的转换</li><li id="3762" class="nm nn iq mf b mg nv mj nw lf nx lj ny ln nz mv nr ns nt nu bi translated"><strong class="mf ir">‘TF _ transformer’</strong>:将顶部特征的向量转换为tf-idf表示的转换</li></ul><p id="f686" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">管道看起来像这样:</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="3c12" class="kw kx iq nc b gy ng nh l ni nj"># Using a variable for the top k features to be selected<br/>top_k_features=1000</span><span id="5d00" class="kw kx iq nc b gy nk nh l ni nj">text_processor = Pipeline([<br/> ('count vectorizer',CountVectorizer(stop_words=mystopwords,lowercase=True)),<br/> ('chi2score',SelectKBest(chi2,k=top_k_features)),<br/> ('tf_transformer',TfidfTransformer(use_idf=True))<br/>])</span></pre><p id="6c57" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">现在，一旦这适合于训练数据，<em class="nl"> text_preprocessor </em>管道具有transform方法，该方法对数据执行<strong class="mf ir">所有三个包含的转换<em class="nl"> </em> </strong>。</p><h2 id="5be1" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">适应和转换</h2><p id="535f" class="pw-post-body-paragraph md me iq mf b mg mh jr mi mj mk ju ml lf mm mn mo lj mp mq mr ln ms mt mu mv ij bi translated">与使用<strong class="mf ir"> fit_transform() </strong>方法的任何其他转换一样，<em class="nl"> text_processor </em>管道的转换是fit，并且数据被转换。<em class="nl"> proc_fit </em>可以用来以同样的方式转换测试数据。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="1392" class="kw kx iq nc b gy ng nh l ni nj">proc_text = text_processor.fit_transform(reviews.X,reviews.y)<br/>proc_fit = text_processor.fit(reviews.X,reviews.y)</span></pre><h2 id="b595" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">检查变化</h2><p id="475a" class="pw-post-body-paragraph md me iq mf b mg mh jr mi mj mk ju ml lf mm mn mo lj mp mq mr ln ms mt mu mv ij bi translated">仍然可以通过以下两个步骤来返回特定评论的最后1000个单词中的原始单词:</p><ol class=""><li id="e144" class="nm nn iq mf b mg mw mj mx lf no lj np ln nq mv oa ns nt nu bi translated">查找从“chi2score”转换返回的前1000个功能的索引</li><li id="e67b" class="nm nn iq mf b mg nv mj nw lf nx lj ny ln nz mv oa ns nt nu bi translated">找到“功能名称”，即原文中的单词</li></ol><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="271a" class="kw kx iq nc b gy ng nh l ni nj">proc_fit.named_steps['chi2score'].get_support(indices=True)[616]</span></pre><p id="754a" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">我从第一个变形的影评词中选出了数字616。原来这对应于原始特征中的特征号23078。(经过“chi2score”转换后，只剩下1000个特性，特性的数量也发生了变化。)</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="3e7f" class="kw kx iq nc b gy ng nh l ni nj">Out[49]:</span><span id="c828" class="kw kx iq nc b gy nk nh l ni nj">23078</span></pre><p id="8469" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">返回的内容:单词“music”是对应于来自原始电影评论文本数据的特征号<strong class="mf ir"> 23078 </strong>的单词，该文本数据被转换成计数向量。它现在是前1000个特性中的第616个特性。我们总是可以打印整个电影评论，看看这个词是否出现在那里。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="2278" class="kw kx iq nc b gy ng nh l ni nj">proc_fit.named_steps['count vectorizer'].get_feature_names()[23078]<br/>'music'<br/>print(reviews.iloc[0,0])</span></pre><p id="fa3b" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">检查第一篇评论，我们可以看到“音乐”这个词确实存在，而且这个词出现在整个电影评论语料库的前1000个精选特征中。</p><blockquote class="ob oc od"><p id="0292" class="md me nl mf b mg mw jr mi mj mx ju ml oe my mn mo of mz mq mr og na mt mu mv ij bi translated">工作室从导演那里拿走了这部电影，他们自己把它切碎了，然后它就出现了。在这里的某个地方可能会有一部相当不错的青少年心灵操电影，但我想《西装革履》决定将它变成一部没有多少棱角的 <strong class="mf ir"> <em class="iq">音乐</em> </strong> <em class="iq">视频，会更有意义。大部分演员都很出色，尽管韦斯·本特利似乎只是在扮演他在《美国丽人》中扮演的那个角色……</em></p></blockquote><p id="5508" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated">通常，不需要在原始数据中查找单个单词，并确保它在新的转换数据中具有特征。在这里，我花时间完成了这些步骤，以确保我构建的管道按预期工作，并展示了管道的所有部分如何显示它们的属性。</p><h1 id="7c7c" class="ls kx iq bd ky lt lu lv lb lw lx ly le jw lz jx li jz ma ka lm kc mb kd lq mc bi translated">结论</h1><p id="e6c2" class="pw-post-body-paragraph md me iq mf b mg mh jr mi mj mk ju ml lf mm mn mo lj mp mq mr ln ms mt mu mv ij bi translated">非结构化文本数据在机器学习项目中非常有用。需要将文本数据转换为机器可以学习的更结构化的格式，通常使用预构建的转换，如删除停用词和tf-idf转换。可以构建数据需要经过的转换管道来简化代码，并为文本预处理阶段提供一致性。利用<em class="nl">管道</em>函数可以帮助将几个转换打包成一个。</p><h1 id="12a4" class="ls kx iq bd ky lt lu lv lb lw lx ly le jw lz jx li jz ma ka lm kc mb kd lq mc bi translated">参考</h1><div class="oh oi gp gr oj ok"><a href="http://www.nltk.org/" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ir gy z fp op fr fs oq fu fw ip bi translated">自然语言工具包- NLTK 3.5文档</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">NLTK是构建Python程序来处理人类语言数据的领先平台。它提供了易于使用的…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">www.nltk.org</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy kp ok"/></div></div></a></div><div class="oh oi gp gr oj ok"><a href="https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd ir gy z fp op fr fs oq fu fw ip bi translated">Python编程教程</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">欢迎来到自然语言处理教程系列，使用自然语言工具包(NLTK)模块…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">pythonprogramming.net</p></div></div><div class="ot l"><div class="oz l ov ow ox ot oy kp ok"/></div></div></a></div><p id="30f1" class="pw-post-body-paragraph md me iq mf b mg mw jr mi mj mx ju ml lf my mn mo lj mz mq mr ln na mt mu mv ij bi translated"><a class="ae kv" href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank">http://scikit learn . org/stable/modules/generated/sk learn . pipeline . pipeline . html</a></p></div></div>    
</body>
</html>