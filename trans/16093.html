<html>
<head>
<title>The danger of bias in AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能中偏见的危险</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-danger-of-bias-in-ai-c3ce68eabbcc?source=collection_archive---------33-----------------------#2020-11-05">https://towardsdatascience.com/the-danger-of-bias-in-ai-c3ce68eabbcc?source=collection_archive---------33-----------------------#2020-11-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/f49232eb3720a8923220a76a1f41c1a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GS7R_rBFYjSO5nDhtCzwuA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">这张令人惊叹的照片归功于韦恩·达什伯格。如果AI的每个回合都潜伏着危险，那会怎样？</p></figure><div class=""/><div class=""><h2 id="c213" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated"><strong class="ak">为什么承认我们架构中的偏差是关键</strong></h2></div><p id="7235" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi lr translated">关于人工智能中偏见的危险，这是第一篇文章，我们想把重点放在一个特定的模型上。最近，基于“PULSE:通过生成模型的潜在空间探索进行自我监督的照片上采样”的模型Face-Depixelizer已经发布。这种模型可以从它的像素化版本输出原始图片。更严格地说，它将输出最接近的已知去像素化图像。</p><figure class="mb mc md me gt is gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/7de50008c57d8342391fd3ec5e9ef54f.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*xYavRh8Lv35Jl_ZOaQzkjw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图一。(x32)输入(顶部)被上采样到SR图像(中间)，该图像被下缩放(底部)到原始图像。来自<a class="ae jd" href="https://arxiv.org/pdf/2003.03808.pdf" rel="noopener ugc nofollow" target="_blank">原创论文。</a></p></figure><p id="21fd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据<a class="ae jd" href="https://github.com/tg-bomze/Face-Depixelizer" rel="noopener ugc nofollow" target="_blank"> github repo </a>上的描述，给定一个低分辨率的输入图像，Face Depixelizer搜索生成模型(此处为<a class="ae jd" href="https://github.com/NVlabs/stylegan" rel="noopener ugc nofollow" target="_blank"> StyleGAN </a>)的输出，以获得感知上真实并正确缩小的高分辨率图像。</p><p id="1f8d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">更准确地说，正如在<a class="ae jd" href="https://arxiv.org/pdf/2003.03808.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中所解释的那样:“【the】方法使用一个(预训练的)生成模型来生成图像，该模型近似于所考虑的自然图像的分布。对于给定的输入LR图像，我们遍历由生成模型的潜在空间参数化的流形，以找到正确缩小的区域。通过这样做，我们找到了适当缩小的真实图像的例子，如1所示</p><h2 id="cd72" class="mf mg jg bd mh mi mj dn mk ml mm dp mn le mo mp mq li mr ms mt lm mu mv mw mx bi translated"><strong class="ak">这个AI模型有什么问题？</strong></h2><p id="077b" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">如果你输入一张黑人的像素化图片，比如巴拉克·奥巴马或蒂埃里·亨利，不管这个黑人有多出名，它仍然会输出一张白人脸。下面的图2显示了这些例子的PULSE输出。这当然意味着该模型偏向于白人面孔。这可以推广到多种场景，我们的下一篇文章将更深入地讨论它们。现在，假设你的公司正在使用一个自动雇用候选人的模型。如果这个模型偏向于白人，那么这个模型最终会建议一个黑人作为新雇员是非常不可能的，甚至在某些情况下是不可能的。</p><figure class="mb mc md me gt is gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/ac871ffb87a65a43406ea7fb91b57e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*61Lx1zXDF3lfAWxWXOaKng.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图二。几个例子，脉冲得到一个非常遥远的图片作为像素化输出的重建。</p></figure><p id="4557" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这让我们想到了Yann Lecun的解释。</p><h2 id="e51e" class="mf mg jg bd mh mi mj dn mk ml mm dp mn le mo mp mq li mr ms mt lm mu mv mw mx bi translated">我们如何解决偏见？</h2><p id="3e13" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">如下所述，大多数时候，我们的模型只是根据本身有偏差的数据进行训练。只在狗和猫身上训练一个计算机视觉模型来对它们进行分类，它将不会知道如何对任何其他动物进行分类，例如鲸鱼。</p><blockquote class="ne nf ng"><p id="d382" class="kv kw nh kx b ky kz kh la lb lc kk ld ni lf lg lh nj lj lk ll nk ln lo lp lq ij bi translated">Lecun提出“当数据有偏差时，ML系统也有偏差。这个面部上采样系统让每个人看起来都是白人，因为该网络是在FlickFaceHQ上预训练的，其中主要包含白人照片。在塞内加尔的数据集上训练<strong class="kx jh">完全相同的</strong>系统，每个人都会看起来像非洲人。”</p></blockquote><p id="179d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这再清楚不过了。当然，首先要考虑的是数据本身。这就是为什么预处理和数据探索是机器学习中的关键步骤的主要原因。在不了解数据性质的情况下训练模型是没有意义的。如果我们希望在要分类的输入集中实现多样性，那么我们的数据集中就需要多样性。</p><p id="67be" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们通过观察面部去像素化数据集的多样性来快速验证Yann Lecun的说法。但是，在此之前，让我们从一个更普遍的角度来看这个问题。</p><h2 id="c313" class="mf mg jg bd mh mi mj dn mk ml mm dp mn le mo mp mq li mr ms mt lm mu mv mw mx bi translated"><strong class="ak">我们能评估数据集中的多样性吗？</strong></h2><p id="9c6d" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">在许多情况下，评估数据集是否足够多样化并不是一件轻而易举事情。然而，有一个问题要时刻牢记在心，那就是:“<strong class="kx jh">我的数据实际上代表了我感兴趣的人群吗？</strong>”。如果我对猫和狗的分类感兴趣，我有足够的多样性来展示所有可能的猫品种吗？对于新员工来说也是如此:如果公司捍卫多样性和包容性，那么在年龄、教育、性别、性偏好等方面，感兴趣的人群是否足够多样化？</p><p id="9e58" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，在许多不同的现实世界场景中，这变得更加困难。假设你拥有一个客户评论网站。人们可以在这些评论的基础上建立满意度评分。但这个满意度得分实际上反映了底层人群的真实满意度吗？仅根据文本审查来评估这一点是一项非常困难的任务。然而，这些评论中的许多可能是由对你的服务非常愤怒的人群中的一部分人写得非常好的。</p><h2 id="8322" class="mf mg jg bd mh mi mj dn mk ml mm dp mn le mo mp mq li mr ms mt lm mu mv mw mx bi translated">我们能评估人脸去像素化数据集的多样性吗？</h2><p id="04d0" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">面部去污剂正在使用罩下的<a class="ae jd" href="https://github.com/NVlabs/stylegan" rel="noopener ugc nofollow" target="_blank"> StyleGAN </a>。StyleGAN本身可以使用许多数据集进行训练:</p><ul class=""><li id="0f34" class="nl nm jg kx b ky kz lb lc le nn li no lm np lq nq nr ns nt bi translated">StyleGAN用Flickr-Faces-HQ数据集在1024×1024进行训练。</li><li id="9249" class="nl nm jg kx b ky nu lb nv le nw li nx lm ny lq nq nr ns nt bi translated">StyleGAN用1024×1024的CelebA-HQ数据集训练。</li><li id="a08e" class="nl nm jg kx b ky nu lb nv le nw li nx lm ny lq nq nr ns nt bi translated">StyleGAN使用256×256的LSUN Bedroom数据集进行训练。</li><li id="e84c" class="nl nm jg kx b ky nu lb nv le nw li nx lm ny lq nq nr ns nt bi translated">StyleGAN用512×384的LSUN Car数据集训练。</li><li id="be92" class="nl nm jg kx b ky nu lb nv le nw li nx lm ny lq nq nr ns nt bi translated">StyleGAN用256×256的LSUN Cat数据集训练。</li></ul><p id="d748" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据<a class="ae jd" href="https://arxiv.org/pdf/1812.04948.pdf" rel="noopener ugc nofollow" target="_blank">作者</a>的说法，FlickrFaces-HQ (FFHQ)是一个新的人脸数据集，由7万张分辨率为10242的高质量图像组成(<a class="ae jd" href="https://arxiv.org/pdf/1812.04948.pdf" rel="noopener ugc nofollow" target="_blank">论文的图7</a>)。“该数据集在年龄、种族和图像背景方面比CELEBA-HQ包含了更多的变化，并且还包含了更好的配饰，如眼镜、太阳镜、帽子等。这些图片是从Flickr抓取的(因此继承了该网站的所有偏见)，并自动对齐和裁剪。</p><p id="731d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作者没有清楚地解释多样化数据的过程。因此，很难清楚地说明多样性的程度。然而，他们提出了一个具有高级统计数据的视图，如图3所示。</p><figure class="mb mc md me gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nz"><img src="../Images/a17b6db7e6c89aa6c8a9646f15a58956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yAh8Ppcq8yDkk7U3S-Wfqw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图3。关于FFHQ数据集的高级统计信息。来自<a class="ae jd" href="https://github.com/NVlabs/ffhq-dataset" rel="noopener ugc nofollow" target="_blank"> github回购</a>。</p></figure><p id="89c7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用元数据可以是评估多样性程度的第一种方法。对于多样化的人脸数据集，代表的国家越多越好。不幸的是，如上面图3中的高级统计所示，85%的图像没有指定国家，因此被指定给未知的<strong class="kx jh"/>。</p><p id="5b5f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">另一种方法是建立一个模型，以不同的方式对数据进行采样。因此，给定一张图片，这种模型应该能够识别一些关键特征，例如年龄、种族和性别。基于这些特征，它可以从底层分布中进行采样。这种模型的一个简化版本如下图4所示，其中我们对美国政治舞台上的著名面孔进行了分类。</p><figure class="mb mc md me gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oa"><img src="../Images/7b1d2a3067efe7d6e734300d797e6d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lVlXQiOZ-a_kurNfdwBRSA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图4。用opencv检测性别和年龄。来自<a class="ae jd" href="https://github.com/smahesh29/Gender-and-Age-Detection" rel="noopener ugc nofollow" target="_blank"> github </a>的模型。</p></figure><p id="157a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面，我们使用了一个基本上做两件事的架构:I .检测所代表的个体的性别和ii .检测所代表的个人的年龄段。这种架构可以集成到采样模型中。如图4所示，这个模型正确地预测了性别，但是错误地预测了米歇尔和梅兰妮·特朗普的年龄。这是很重要的一点，因为这样的模型应该尽可能没有偏见。换句话说，如果想要在采样过程中集成这种模型，他们应该确保精度足够高，不会在管道中集成偏差。</p><p id="885d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">事实上，人们可以将采样模型视为ML管道中的一个重要模型。这种模型通过从源数据中正确取样，可以更好地代表潜在人口。在下面的图5中，我们展示了如何将这样的模型集成到ML管道中。</p><figure class="mb mc md me gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/620a4a52c86aea33069ad5cb740c9022.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fMwpnExB219REPXPDtFdRA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图5。简单化(上图)与智能采样模型(下图)。上述流程的第一步是从源数据中随机抽样，并获得典型的80%训练数据和20%测试数据。底层管道的第一步是关注关键特性，以帮助确保数据的多样性。例如，基于图2所示的模型，性别可能是一个关键特征。一旦我们确保了性别的合理分布，我们就可以从这个过滤的数据集中取样，并得到一个训练和测试数据集。</p></figure><p id="5dc1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">严格地说，当一个人构建一个训练集和一个测试集时，他们也从底层分布中进行采样。但是这种过程不会给采样增加任何约束，因此高度依赖于数据集的偏差程度。如果您怀疑数据集有偏差，那么在采样时遵循简单的均匀分布是不合适的！我最近写了一篇关于过采样的文章来解决类不平衡问题，这篇文章更详细地解释了采样时的均匀分布问题，并深入探讨了这个问题。处理不平衡的数据集自然可以看作是处理有偏差的数据集。例如，假设您事先知道您感兴趣的人群应该是50%男性和50%女性。因此，如果训练集并不紧密代表这种分布，并且包含例如70%男性和30%女性，那么对于下游任务来说，过采样通常是必要的，正如在这篇<a class="ae jd" href="https://arxiv.org/abs/1710.05381" rel="noopener ugc nofollow" target="_blank">必读论文</a>中所解释的。</p><p id="de21" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">“智能抽样模型”(ISM)可被视为一种函数，它采用性别和年龄等关键特征以及这些特征在基础人群中的预期分布。然后，在此基础上，ISM可以从源数据中进行采样，并确保采样数据中很好地代表了预期分布。可以讨论其他更精确的方法，但不在本文的讨论范围之内。下面的图6显示了ISM背后的一般思想。</p><figure class="mb mc md me gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oc"><img src="../Images/7c9e5b1e4f5f3d0780be425d8054b882.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IV8iI8iskLSb9EkTsB0rVw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图6。ISM背后的一般思想。ISM允许您根据性别等关键特征，按照一些预定义的要求从源数据中取样。在本例中，用户设置了一个性别先验，ISM确保这种分布在其输出中得到密切体现。我们从70%男性，30%女性的分布到52%男性和48%女性的分布。</p></figure><h2 id="fc9f" class="mf mg jg bd mh mi mj dn mk ml mm dp mn le mo mp mq li mr ms mt lm mu mv mw mx bi translated">结论:</h2><p id="fddd" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">正如Soumith Chintala在推特上正确指出的:</p><blockquote class="ne nf ng"><p id="ce6c" class="kv kw nh kx b ky kz kh la lb lc kk ld ni lf lg lh nj lj lk ll nk ln lo lp lq ij bi translated">“今天，ML研究人员无意中为许多非人工智能公司的产品提供了动力，这些公司无知地从互联网上的预训练伯特/雷斯内特/YOLO开始。可能忽略了许可证、自述文件、发布条款(…)”。</p></blockquote><p id="e8cd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">理解数据可能有偏差并透明地解决这一问题需要成为该领域日益关注的问题。</p><p id="1d8f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这篇文章很快介绍了一个体系结构，它很难推广到在训练数据中显示偏差的人群子集。正如FFHQ的作者含蓄地指出的，有时偏见很难消除，因此FFHQ数据集的图片依赖于Flickr固有的偏见。</p><p id="023c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在所有情况下，在ML管道中引入智能采样模型(<strong class="kx jh"> ISM </strong>)是关键，正如Yann Lecun所建议的，正确的数据采样是减少数据偏差的核心优先事项，因此在后续ML架构中也是如此。总之，<strong class="kx jh">承认我们架构中的偏见是关键，并且需要在未来受到越来越多的关注！</strong></p></div></div>    
</body>
</html>