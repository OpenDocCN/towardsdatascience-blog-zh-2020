<html>
<head>
<title>Image Segmentation using K-means</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于K-均值的图像分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-segmentation-using-k-means-6b450c029208?source=collection_archive---------30-----------------------#2020-09-27">https://towardsdatascience.com/image-segmentation-using-k-means-6b450c029208?source=collection_archive---------30-----------------------#2020-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7974" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用NumPy/SciPy从头开始图像分割</h2></div><p id="ad39" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然预先存在的库(如OpenCV)节省了时间和精力，但从头开始实现基本算法是另一种乐趣。</p><p id="c9a2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我将展示在python中使用k-means一步步实现图像分割。我们在从<a class="ae le" href="https://groups.csail.mit.edu/vision/SUN/" rel="noopener ugc nofollow" target="_blank">太阳数据库</a>中采样的8个类别的1100幅图像上训练管道。图像分割是将相似类型的像素组合在一起。流水线可以进一步扩展以对图像进行分类。例如，公园的图像将比高速公路的图像具有更多数量的绿色像素。我们将在以后的文章中讨论分类。</p><p id="26cf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们发现一个公园的图像会有更多的绿色像素。虽然颜色是区分像素的好方法，但它有时会产生问题(例如，水和天空具有相同的颜色)。因此，我们需要其他方法来表征像素。换句话说，我们需要从图像中提取有用的特征。深度学习算法，如CNN的自动为我们找到有用的功能，但这超出了本文的范围。</p><p id="807c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了提取特征，我们将使用四种具有多尺度的图像滤波器-高斯、高斯在x方向上的导数、高斯在y方向上的导数以及高斯的拉普拉斯算子。每个滤波器从图像中提取不同的特征集。较小的比例拾取较窄的要素，较大的比例拾取较宽的要素(想想森林和树木)。我们将不同尺度的滤波器集合称为“滤波器组”。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/23a5c0586d37a1799645563ec834ff7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*_nMF359rm5rseGBRLxIM1g.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">对滤波器组的图像响应(作者)</p></figure><p id="4bd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上图中的每一行代表一个特定的刻度，每一列代表一种不同类型的过滤器。高斯滤波器(第一列)模糊了图像并忽略了较高的频率。X方向的高斯导数(第二列)拾取垂直边缘。Y方向上的高斯导数(第三列)拾取水平边缘。高斯的拉普拉斯算子(第四列)检测快速强度变化的区域。</p><p id="ae1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在图像上运行滤波器组(这是一个大小为H*W*3的数组，其中H和W分别是图像的高度和宽度，3是通道的数量)。我们输出一个大小为(H*W*3F)的数组，其中F是滤波器组的大小。如果我们在5个不同的比例下使用4个滤波器，F就是4*5=20</p><p id="0765" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从T个训练图像中，我们得到大小为T*H*W*3F的滤波器响应向量。为了节省计算资源，我们从每个图像中选择阿尔法随机滤波器响应。因此，滤波器响应向量的最终大小是* T * F。</p><p id="c95b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用这个滤波器响应向量作为k-means算法的输入。它将输出K个(超参数)聚类中心。然后，测试图像的每个像素将被映射到最近的聚类中心，并涂上相应的颜色以形成“视觉图”。产生的“视觉地图”将具有相似的像素组合在一起，并且将是我们的“图像分割”算法的最终输出。</p></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><p id="6819" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太棒了，让我们看看整个管道的运作。我们将从定义超参数的值开始，这些值可以在以后进行调整以提高性能。</p><pre class="lg lh li lj gt ly lz ma mb aw mc bi"><span id="f2d9" class="md me it lz b gy mf mg l mh mi">filter_scales=[1,1.5,2]<br/>K=10<br/>alpha=25</span></pre><p id="ff9f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在定义函数extract_fiter_responses，它为大小为H*W*3和滤波器组大小为f的图像返回大小为H*W*3F的向量。我们使用scipy中的内置函数来生成filter_responses。</p><pre class="lg lh li lj gt ly lz ma mb aw mc bi"><span id="f7f1" class="md me it lz b gy mf mg l mh mi">def extract_filter_responses(filter_scales, img):<br/>    <br/>    <br/>    <br/>   <br/>    if len(img.shape)==2:     #convert image into 3 channel<br/>        img=np.dstack((img,img,img))<br/>    <br/>    <br/>    modified_img=skimage.color.rgb2lab(img)</span><span id="1dc6" class="md me it lz b gy mj mg l mh mi">    r_channel=modified_img[:,:,0]<br/>    g_channel=modified_img[:, :,1]<br/>    b_channel=modified_img[:, : ,2]</span><span id="8c72" class="md me it lz b gy mj mg l mh mi">    g=[]<br/>    for i in range(len(filter_scales)):<br/>        modified_r_channel=scipy.ndimage.gaussian_filter(r_channel,      filter_scales[i])<br/>        modified_g_channel=scipy.ndimage.gaussian_filter(g_channel, filter_scales[i])<br/>        modified_b_channel=scipy.ndimage.gaussian_filter(b_channel, filter_scales[i])<br/>        <br/>        modified_r_dog_X=scipy.ndimage.gaussian_filter(r_channel, filter_scales[i],(0,1))<br/>        modified_g_dog_X=scipy.ndimage.gaussian_filter(g_channel, filter_scales[i], (0,1))<br/>        modified_b_dog_X=scipy.ndimage.gaussian_filter(b_channel, filter_scales[i], (0,1))<br/>    <br/>        modified_r_dog_Y=scipy.ndimage.gaussian_filter(r_channel, filter_scales[i],(1,0))<br/>        modified_g_dog_Y=scipy.ndimage.gaussian_filter(g_channel, filter_scales[i], (1,0))<br/>        modified_b_dog_Y=scipy.ndimage.gaussian_filter(b_channel, filter_scales[i], (1,0))<br/>        <br/>        modified_r_log=scipy.ndimage.gaussian_laplace(r_channel, filter_scales[i])<br/>        modified_g_log=scipy.ndimage.gaussian_laplace(g_channel, filter_scales[i])<br/>        modified_b_log=scipy.ndimage.gaussian_laplace(b_channel, filter_scales[i])<br/>        <br/>        <br/>        <br/>        <br/>        a=np.dstack((modified_r_channel, modified_g_channel, modified_b_channel))<br/>        b=np.dstack((modified_r_dog_X, modified_g_dog_X, modified_b_dog_X))<br/>        c=np.dstack((modified_r_dog_Y, modified_g_dog_Y, modified_b_dog_Y))<br/>        d=np.dstack((modified_r_log, modified_g_log, modified_b_log))<br/>        filter_response=np.dstack((a,b,c,d))<br/>        g.append(filter_response)<br/>        <br/>        <br/>        <br/>    filter_responses=np.dstack(g)<br/>    <br/>    <br/>    return filter_responses</span></pre><p id="0138" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一个函数将从extract_filter_responses返回的向量中提取alpha随机过滤器响应</p><pre class="lg lh li lj gt ly lz ma mb aw mc bi"><span id="2a92" class="md me it lz b gy mf mg l mh mi">def compute_dictionary_one_image(alpha, img):<br/>   <br/>    response=extract_filter_responses(filter_scales, img)<br/> <br/>    d=response.shape[0]*response.shape[1]<br/>    response=response.reshape((d,-1)) <br/>    alphas=np.random.choice(d, alpha)</span><span id="ddf3" class="md me it lz b gy mj mg l mh mi">    alphaed_response=response[alphas]<br/>   <br/>    return alphaed_response</span></pre><p id="975d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一个函数将来自每个图像的alpha响应汇集到一个向量中，并应用来自scipy的k-means函数。该函数将训练文件路径作为参数。</p><pre class="lg lh li lj gt ly lz ma mb aw mc bi"><span id="8af0" class="md me it lz b gy mf mg l mh mi">def compute_dictionary(K, alpha, train_files):<br/><br/>    m=[]<br/>    for i in range(len(train_files)):       <br/>        img_path = train_files[i]<br/>        img = Image.open(img_path)<br/>        img = np.array(img).astype(np.float32)/255<br/>        re=compute_dictionary_one_image(alpha, img)<br/>        m.append(re)<br/>        <br/>    m=np.array(m)<br/>    n=m.shape[0]*m.shape[1]<br/>    final_response=m.reshape((n,-1))<br/>    <br/>    kmeans=KMeans(n_clusters=K).fit(final_response)</span><span id="6964" class="md me it lz b gy mj mg l mh mi">    dictionary=kmeans.cluster_centers_<br/>    return dictionary</span></pre><p id="57d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">酷毙了。所以现在我们有K个聚类中心。对于一个测试图像，我们需要用最近的聚类中心映射图像的每个像素，并绘制结果可视化。我们使用scipy.spatial.distance.cdist来查找最近的聚类中心的索引。下面的get_visual_maps()函数说明了这一点</p><pre class="lg lh li lj gt ly lz ma mb aw mc bi"><span id="19e9" class="md me it lz b gy mf mg l mh mi">def get_visual_words(filter_scales, img, dictionary):<br/>   </span><span id="e44e" class="md me it lz b gy mj mg l mh mi"><br/>   response=extract_filter_responses(filter_scales, img)<br/>   response=response.reshape(response.shape[0]*response.shape[1],-1)<br/>    <br/>   dist=scipy.spatial.distance.cdist(response, dictionary)<br/>    <br/>   visual_words=np.argmin(dist, axis=1)<br/>   visual_words=visual_words.reshape(img.shape[0],img.shape[1])<br/>    <br/>   return visual_words</span></pre></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h2 id="799f" class="md me it bd mk ml mm dn mn mo mp dp mq kr mr ms mt kv mu mv mw kz mx my mz na bi translated">把所有的加在一起</h2><p id="bfa5" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">我们现在将使用这些函数来创建一个管道，该管道在1177个图像的训练集上运行k-means，并在一个测试图像上检查性能。</p><pre class="lg lh li lj gt ly lz ma mb aw mc bi"><span id="e8da" class="md me it lz b gy mf mg l mh mi">#compute cluster centers<br/>compute_dictionary(K, alpha, train_files)</span><span id="bedd" class="md me it lz b gy mj mg l mh mi">#test on a image <br/>     <br/>img_path = 'image path'<br/>img = Image.open(img_path)<br/>img = np.array(img).astype(np.float32)/255<br/>wordmap = visual_words.get_visual_words(filter_scales, img, dictionary)</span><span id="288c" class="md me it lz b gy mj mg l mh mi">plt.imshow(wordmap)</span></pre><h1 id="5e25" class="ng me it bd mk nh ni nj mn nk nl nm mq jz nn ka mt kc no kd mw kf np kg mz nq bi translated">结果</h1><p id="1cd8" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">以下是该算法的一些可视化示例。我用的滤镜尺度=[1，1.5，2]，K=25，alpha=10。我们能够识别图像的不同区域。在(厨房的)第一张图片中，我们可以识别不同的区域，桌子、炉子等等。请随意调整这些参数，看看您是否能获得更好的结果！</p><p id="cbbb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下一篇文章中，我们将扩展按类型分类图像的管道(第一个是厨房的图像，第二个是高速公路的图像，等等..)</p><div class="lg lh li lj gt ab cb"><figure class="nr lk ns nt nu nv nw paragraph-image"><img src="../Images/58ca12680db4e96827b0143cdbff9094.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*6gCCvUIY4yiqHYRjdVxHSA.jpeg"/></figure><figure class="nr lk ns nt nu nv nw paragraph-image"><img src="../Images/1a2ebf9202b5f5c22e479b1f76102d2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*SUrCq3MUWoIm75YPkhSxdw.jpeg"/><p class="ln lo gj gh gi lp lq bd b be z dk nx di ny nz translated">k-means后的输出(由作者提供)</p></figure></div></div></div>    
</body>
</html>