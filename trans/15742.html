<html>
<head>
<title>Improve Model Performance using Feature Importance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用特征重要性提高模型性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/improve-model-performance-using-feature-importance-55742402fadc?source=collection_archive---------35-----------------------#2020-10-29">https://towardsdatascience.com/improve-model-performance-using-feature-importance-55742402fadc?source=collection_archive---------35-----------------------#2020-10-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6097" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解寻找特征重要性的不同方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8ae543b9ef7d27f5a3feb0801af7f968.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zHWe5uFsOce9bZg7"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">弗兰基·查马基在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="0f20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习模型性能是选择特定模型的最重要因素。为了选择机器学习模型，我们可以查看某些指标，这些指标可以帮助我们选择具有最高准确性和最小误差的最佳模型。</p><p id="4149" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无论是回归模型还是分类模型，特征变量在建立预测模型中起着重要的作用。拥有大量的特征并不好，因为这可能会导致过度拟合，这将使我们的模型特别适合它所训练的数据。此外，具有大量特征将导致维数灾难，即特征将增加问题的搜索空间的维数。</p><p id="abab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用不同的技术和方法进行降维和特征选择，并且为了使这些步骤更加有效，我们可以使用特征重要性，这为我们提供了在预测目标变量时哪些特征最重要的洞察力。</p><p id="cdfd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特征重要性是一种为我们提供每个特征变量的相关分数的技术，我们可以用它来决定哪些特征最重要，哪些特征对预测目标变量最不重要。</p><p id="bf28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将探索不同的技术，我们可以使用的功能的重要性，并找出他们的相对重要性分数。</p><h1 id="04b9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">加载数据集</h1><p id="e0c0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们将使用包含目标变量为0(非糖尿病)或1(糖尿病)的糖尿病数据集进行分类问题，并使用不同的机器学习模型找出最重要的特征变量。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="3535" class="mx lw it mt b gy my mz l na nb">import pandas as pd<br/>df = pd.read_csv('DIABETES.csv')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/760e376fcb3a71a158c9ed0fc7547b24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_d5HiD9z8JSSGZqvpXLOQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">糖尿病数据集(来源:作者)</p></figure><p id="6e28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在找出重要的特性之前，我们需要定义特性和目标变量。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="39d2" class="mx lw it mt b gy my mz l na nb">X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI','DiabetesPedigreeFunction','Age']]<br/>y = df['Outcome']</span></pre><h1 id="df35" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">特征重要性技术:</h1><h2 id="7198" class="mx lw it bd lx nd ne dn mb nf ng dp mf li nh ni mh lm nj nk mj lq nl nm ml nn bi translated">1.使用黄砖要素重要性</h2><p id="6eba" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Yellowbrick是一个可视化库，主要用于模型选择和模型性能可视化。它是使用sklearn构建的，基于matplotlib构建，用于可视化。</p><p id="382c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用yellowbrick的要素重要性可视化工具，它返回所有要素及其相对重要性分数。我们可以使用不同的模型来寻找特征的重要性。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="12a5" class="mx lw it mt b gy my mz l na nb">#Creating SVM Model<br/>from sklearn import svm<br/>model = svm.SVC(kernel='linear')<br/>#Importing Yellowbrick Feature Imporance and using it<br/>from yellowbrick.model_selection import FeatureImportances<br/>viz = FeatureImportances(model)<br/>viz.fit(X, y)<br/>viz.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/6ca88097610f27f733c6e035ae03f474.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KpTfmwFU-ttcnJ7zqZYgww.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SVM特色重要性(来源:作者)</p></figure><p id="5dba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，我们可以使用不同的模型，并找出该模型的特征重要性。让我们再看一个使用随机森林分类器的例子。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="fdfc" class="mx lw it mt b gy my mz l na nb">from sklearn.ensemble import RandomForestClassifier<br/>model = RandomForestClassifier()<br/>#Visualizing Feature Importance<br/>viz = FeatureImportances(model)<br/>viz.fit(X, y)<br/>viz.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/0ba606296f1a24fc19cc8f6ade97dbe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tXN6Btpr33ML4Vz7nTBqHA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机森林特征重要性(来源:作者)</p></figure><p id="6d0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.排列重要性</p><p id="de34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">置换重要性在Sklearn模型检验方法下定义。当数据是表格形式时，它可用于任何拟合的估计量。该函数计算给定数据集的估计量的特征重要性。n_repeats参数设置随机洗牌的次数，并返回特征重要性的样本。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="ac26" class="mx lw it mt b gy my mz l na nb">from sklearn.inspection import permutation_importance<br/>from sklearn.naive_bayes import GaussianNB<br/>import matplotlib.pyplot as plt</span><span id="0654" class="mx lw it mt b gy nq mz l na nb">#Defining the model<br/>model = GaussianNB()<br/>model.fit(X, y)</span><span id="ff34" class="mx lw it mt b gy nq mz l na nb"># perform permutation importance<br/>results = permutation_importance(model, X, y, scoring='accuracy')</span><span id="6e37" class="mx lw it mt b gy nq mz l na nb"># get importance<br/>importance = results.importances_mean</span><span id="74fc" class="mx lw it mt b gy nq mz l na nb"># summarize feature importance<br/>for i,v in enumerate(importance):<br/>    print('Feature: %0d, Score: %.5f' % (i,v))</span><span id="c0a6" class="mx lw it mt b gy nq mz l na nb"># plot feature importance<br/>plt.bar([x for x in range(len(importance))], importance)<br/>plt.xlabel=df.columns[:-1]<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/c1c418e5c2f76fe7569c5152610b8c35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*RoNx5sB_UmD2XoUGJtgoow.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">排列的重要性(来源:作者)</p></figure><p id="66e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，我们可以使用不同的模型来找出该模型的特征的重要性。让我们使用不同的模型来找出特性的重要性。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="8c0a" class="mx lw it mt b gy my mz l na nb">from sklearn.linear_model import LogisticRegression</span><span id="6c7b" class="mx lw it mt b gy nq mz l na nb">#Defining the model<br/>model = LogisticRegression()<br/>model.fit(X, y)</span><span id="bfdf" class="mx lw it mt b gy nq mz l na nb"># perform permutation importance<br/>results = permutation_importance(model, X, y, scoring='accuracy')</span><span id="54f2" class="mx lw it mt b gy nq mz l na nb"># get importance<br/>importance = results.importances_mean</span><span id="a6cf" class="mx lw it mt b gy nq mz l na nb"># summarize feature importance<br/>for i,v in enumerate(importance):<br/>    print('Feature: %0d, Score: %.5f' % (i,v))</span><span id="3013" class="mx lw it mt b gy nq mz l na nb"># plot feature importance<br/>plt.bar([x for x in range(len(importance))], importance)<br/>plt.xlabel=df.columns[:-1]<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/51085d7e8a8d4f6da7cc3f7fb6193e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*_KddQnSalNnxYzQGtYqG3w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">物流特征的重要性(来源:作者)</p></figure><p id="1c24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在这篇文章中讨论的方法易于使用，因为你不必考虑不同的参数，应该有如果通过传统的。在某种程度上，这些技术自动化了特性的重要性，因此节省了时间和精力。</p><p id="ef9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，您可以在具有不同模型的不同数据集上尝试这些技术。继续探索这些技术，并在这篇文章的回复中分享你的经验。</p><h1 id="4353" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">在你走之前</h1><p id="c121" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu"> <em class="nt">感谢</em> </strong> <em class="nt">的阅读！如果你想与我取得联系，请随时通过hmix13@gmail.com联系我或我的</em> <a class="ae ky" href="http://www.linkedin.com/in/himanshusharmads" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="nt"> LinkedIn个人资料</em> </strong> </a> <em class="nt">。可以查看我的</em><a class="ae ky" href="https://github.com/hmix13" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="nt">Github</em></strong><em class="nt"/></a><em class="nt">简介针对不同的数据科学项目和包教程。还有，随意探索</em> <a class="ae ky" href="https://medium.com/@hmix13" rel="noopener"> <strong class="lb iu"> <em class="nt">我的简介</em> </strong> </a> <em class="nt">，阅读我写过的与数据科学相关的不同文章。</em></p></div></div>    
</body>
</html>