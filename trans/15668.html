<html>
<head>
<title>Rick and Morty story generation with GPT2 using Transformers and Streamlit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Rick和Morty使用变形金刚和Streamlit通过GPT2生成故事</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/rick-and-morty-story-generation-with-gpt2-using-transformers-and-streamlit-in-57-lines-of-code-8f81a8f92692?source=collection_archive---------25-----------------------#2020-10-28">https://towardsdatascience.com/rick-and-morty-story-generation-with-gpt2-using-transformers-and-streamlit-in-57-lines-of-code-8f81a8f92692?source=collection_archive---------25-----------------------#2020-10-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/0fe4919b09233bcc97640a5d79020e22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_dhoIC_MLS4oIxqQOL98tw.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">贝尼尼奥·霍尤拉在<a class="ae jd" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><div class=""/><div class=""><h2 id="574c" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">这篇文章将向你展示如何使用Hugging Face的Transformers库在Rick和Morty的抄本上<em class="kv">微调</em>一个<em class="kv">预训练的</em> GPT2模型，构建一个演示应用程序，并使用Streamlit共享部署它。</h2></div><h1 id="9db9" class="kw kx jg bd ky kz la lb lc ld le lf lg km lh kn li kp lj kq lk ks ll kt lm ln bi translated">介绍</h1><p id="f927" class="pw-post-body-paragraph lo lp jg lq b lr ls kh lt lu lv kk lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">随着机器学习(ML)和自然语言处理(NLP)的快速发展，新算法能够生成看起来越来越像人类制作的文本。其中一种算法GPT2已经在许多开源应用程序中使用。GPT2在WebText上接受训练，WebText包含来自Reddit的4500万个出站链接(即评论引用的网站)。排名前10的出站域名包括<em class="mk">谷歌</em>、<em class="mk">存档</em>、<em class="mk"> Blogspot </em>、<em class="mk"> Github </em>、<em class="mk"> NYTimes </em>、<em class="mk"> WordPress </em>、<em class="mk">华盛顿邮报</em>、<em class="mk"> Wikia </em>、<em class="mk"> BBC </em>和<em class="mk">卫报</em>。<em class="mk">预训练</em> GPT2模型可以在特定数据集上<em class="mk">微调</em>，例如，以“获取”数据集的样式或学习对文档进行分类。这是通过<em class="mk">迁移学习</em>完成的，迁移学习可以定义为“从源设置中提取知识并将其应用于不同目标setting"⁴.的一种方式有关GPT2及其架构的详细解释，请参见原版paper⁵、OpenAI的博客post⁶或杰伊·阿拉姆马的插图guide⁷.</p><h1 id="56c2" class="kw kx jg bd ky kz la lb lc ld le lf lg km lh kn li kp lj kq lk ks ll kt lm ln bi translated">资料组</h1><p id="60a5" class="pw-post-body-paragraph lo lp jg lq b lr ls kh lt lu lv kk lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">用于<em class="mk">微调</em> GPT2的数据集由<a class="ae jd" href="https://rickandmorty.fandom.com/wiki/Category:Transcripts" rel="noopener ugc nofollow" target="_blank"> Rick和Morty抄本</a>的前3季组成。我过滤掉了所有不是由里克、莫蒂、萨默、贝丝或杰瑞产生的对话。数据被下载并以原始文本格式存储。每行代表一个说话者和他们的话语或一个动作/场景描述。数据集被分为训练和测试数据，分别包含6905和1454行。原始文件可以在这里找到<a class="ae jd" href="https://github.com/e-tony/Story_Generator_RnM/tree/main/data" rel="noopener ugc nofollow" target="_blank">。训练数据用于<em class="mk">微调</em>模型，而测试数据用于评估。</a></p><h1 id="f840" class="kw kx jg bd ky kz la lb lc ld le lf lg km lh kn li kp lj kq lk ks ll kt lm ln bi translated">训练模型</h1><p id="16b5" class="pw-post-body-paragraph lo lp jg lq b lr ls kh lt lu lv kk lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">抱抱脸的变形金刚库提供了一个<a class="ae jd" href="https://github.com/huggingface/transformers/tree/master/examples/language-modeling#gpt-2gpt-and-causal-language-modeling" rel="noopener ugc nofollow" target="_blank">简单脚本</a>来<em class="mk">微调</em>一个定制的GPT2模型。你可以使用<a class="ae jd" href="https://colab.research.google.com/drive/1opXtwhZ02DjdyoVlafiF3Niec4GqPJvC?usp=sharing" rel="noopener ugc nofollow" target="_blank">这款</a>谷歌Colab笔记本来微调你自己的模型。一旦您的模型完成了训练，确保您下载了包含所有相关模型文件的已训练模型输出文件夹(这对于以后加载模型是必不可少的)。你可以在拥抱脸的模型Hub⁸上传你的定制模型，让公众可以访问它。当在测试数据上评估时，该模型获得了大约17的困惑分数。</p><h1 id="5b41" class="kw kx jg bd ky kz la lb lc ld le lf lg km lh kn li kp lj kq lk ks ll kt lm ln bi translated">构建应用程序</h1><p id="2843" class="pw-post-body-paragraph lo lp jg lq b lr ls kh lt lu lv kk lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">首先，让我们为Python 3.7创建一个名为<code class="fe ml mm mn mo b">Story_Generator</code>的新项目文件夹和一个虚拟环境:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="27fb" class="mx kx jg mo b gy my mz l na nb">mkdir Story_Generator<br/>cd Story_Generator<br/>python3.7 -m venv venv<br/>source venv/bin/activate</span></pre><p id="e6a1" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">接下来，我们要安装项目的所有依赖项:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="4498" class="mx kx jg mo b gy my mz l na nb">pip install streamlit-nightly==0.69.3.dev20201025<br/>pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f <a class="ae jd" href="https://download.pytorch.org/whl/torch_stable.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/torch_stable.html</a><br/>pip install git+git://github.com/huggingface/transformers@59b5953d89544a66d73</span></pre><p id="d5b9" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">我们的整个应用程序将驻留在<code class="fe ml mm mn mo b">app.py</code>中。让我们创建它并导入新安装的依赖项:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="f8ed" class="mx kx jg mo b gy my mz l na nb">import urllib<br/>import streamlit as st<br/>import torch<br/>from transformers import pipeline</span></pre><p id="e4dc" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">在我们做任何处理之前，我们希望我们的模型加载。通过使用<code class="fe ml mm mn mo b">@st.cache</code>装饰器，我们可以执行一次<code class="fe ml mm mn mo b">load_model()</code>函数，并将结果存储在本地缓存中。这将提高我们的应用程序性能。然后，我们可以使用<code class="fe ml mm mn mo b">pipeline()</code>功能简单地加载一个模型来生成文本(将模型路径替换为您的定制模型，或者从模型中心使用<a class="ae jd" href="https://huggingface.co/e-tony/gpt2-rnm" rel="noopener ugc nofollow" target="_blank"> my <em class="mk">预训练的</em>模型</a>):</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="2fda" class="mx kx jg mo b gy my mz l na nb"><a class="ae jd" href="http://twitter.com/st" rel="noopener ugc nofollow" target="_blank">@st</a>.cache(allow_output_mutation=True, suppress_st_warning=True)<br/>def load_model():<br/>    return pipeline("text-generation", model="e-tony/gpt2-rnm")</span><span id="487f" class="mx kx jg mo b gy nh mz l na nb">model = load_model()</span></pre><p id="d1ec" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">我们可以使用Streamlit的<code class="fe ml mm mn mo b">text_area()</code>函数来制作一个简单的文本框。我们还可以提供高度和允许的最大字符数(因为大文本需要更长的时间来生成):</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="c714" class="mx kx jg mo b gy my mz l na nb">textbox = st.text_area('Start your story:', '', height=200, max_chars=1000)</span></pre><p id="9565" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">现在我们已经有了第一行代码，我们可以通过运行应用程序来查看它是什么样子的(我们也可以通过刷新页面来查看实时更改):</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="1fd8" class="mx kx jg mo b gy my mz l na nb">streamlit run app.py</span></pre><p id="2417" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">接下来，我们可以添加一个slider小部件，允许用户决定模型应该生成多少个字符:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="481b" class="mx kx jg mo b gy my mz l na nb">slider = st.slider('Max story length (in characters)', 50, 200)</span></pre><p id="dd46" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">我们现在准备生成文本！让我们创建一个执行文本生成的按钮:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="f813" class="mx kx jg mo b gy my mz l na nb">button = st.button('Generate')</span></pre><p id="4e70" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">我们希望我们的应用程序监听“按钮按压”动作。这可以通过一个简单的条件语句来完成。然后我们可以生成文本并将其输出到屏幕上:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="7796" class="mx kx jg mo b gy my mz l na nb">if button:<br/>    output_text = model(textbox, max_length=slider)[0]['generated_text']<br/> <br/>    for i, line in enumerate(output_text.split("\n")):<br/>        if ":" in line:<br/>            speaker, speech = line.split(':')<br/>            st.markdown(f'__{speaker}__: {speech}')<br/>        else:<br/>            st.markdown(line)</span></pre><p id="760b" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">让我们在文本框中输入提示并生成一个故事:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="5051" class="mx kx jg mo b gy my mz l na nb">Rick: Come on, flip the pickle, Morty. You're not gonna regret it. The payoff is huge.</span></pre><p id="ca90" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">输出:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="55aa" class="mx kx jg mo b gy my mz l na nb">Rick: Come on, flip the pickle, Morty. You're not gonna regret it. The payoff is huge. You don't have to be bad, Morty.<br/>(Rick breaks up)<br/>[Trans. Ext. Mortys home]</span></pre><p id="6b33" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">太好了！模型正在输出新的文本，看起来不错。我们可以通过调整<em class="mk">解码</em>方法的参数来提高输出质量。参见拥抱脸在decoding⁹的帖子，了解不同方法的详细概述。让我们替换我们的<code class="fe ml mm mn mo b">model()</code>函数，并应用更多的参数:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="4335" class="mx kx jg mo b gy my mz l na nb">output_text = model(textbox, do_sample=True, max_length=slider, top_k=50, top_p=0.95, num_returned_sequences=1)[0]['generated_text']</span></pre><p id="3e0b" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">简而言之，<code class="fe ml mm mn mo b">do_sample</code>随机挑选下一个单词，<code class="fe ml mm mn mo b">top_k</code>过滤最有可能的<em class="mk"> k </em>下一个单词，<code class="fe ml mm mn mo b">top_p</code>允许动态增加和减少可能的下一个单词的数量，<code class="fe ml mm mn mo b">num_returned_sequences</code>输出多个独立样本(在我们的例子中只有1个)用于进一步过滤或评估。您可以使用这些值来获得不同类型的输出。</p><p id="bd4e" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">让我们使用这种解码方法生成另一个输出。</p><p id="4c5c" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">输出:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="fcaf" class="mx kx jg mo b gy my mz l na nb">Rick: Come on, flip the pickle, Morty. You're not gonna regret it. The payoff is huge.<br/>Morty: Ew, no, Rick! Where are you?<br/>Rick: Morty, just do it! [laughing] Just flip the pickle!<br/>Morty: I'm a Morty, okay?<br/>Rick: Come on, Morty. Don't be ashamed to be a Morty. Just flip the pickle.</span></pre><p id="2ef3" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">我们的输出看起来更好！这种模式仍然会产生不合逻辑和无意义的文本，但新的模式和解码方法可能会解决这个问题。</p><p id="d79c" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">不幸的是，我们的模型有时会产生伤害性的、粗俗的、暴力的或歧视性的语言，因为它是根据来自互联网的数据训练的。我们可以通过简单地从451个单词的列表<a class="ae jd" href="https://raw.githubusercontent.com/RobertJGabriel/Google-profanity-words/master/list.txt" rel="noopener ugc nofollow" target="_blank">中检查粗俗的单词来应用不良单词过滤器来审查有害的语言。我敦促读者考虑使用进一步的过滤器，比如过滤仇恨言论。该滤波器可以按如下方式实现:</a></p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="7a18" class="mx kx jg mo b gy my mz l na nb">def load_bad_words() -&gt; list:<br/>    res_list = []</span><span id="1a85" class="mx kx jg mo b gy nh mz l na nb">file = urllib.request.urlopen("<a class="ae jd" href="https://raw.githubusercontent.com/RobertJGabriel/Google-profanity-words/master/list.txt" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/RobertJGabriel/Google-profanity-words/master/list.txt</a>")<br/>    for line in file:<br/>        dline = line.decode("utf-8")<br/>        res_list.append(dline.split("\n")[0])<br/>    <br/>    return res_list</span><span id="97e0" class="mx kx jg mo b gy nh mz l na nb">BAD_WORDS = load_bad_words()<br/>    <br/>def filter_bad_words(text):<br/>    explicit = False<br/>    <br/>    res_text = text.lower()<br/>    for word in BAD_WORDS:<br/>        if word in res_text:<br/>            res_text = res_text.replace(word, word[0]+"*"*len(word[1:]))<br/>            explicit = True</span><span id="690c" class="mx kx jg mo b gy nh mz l na nb">if not explicit:<br/>        return text</span><span id="1cd1" class="mx kx jg mo b gy nh mz l na nb">output_text = ""<br/>    for oword,rword in zip(text.split(" "), res_text.split(" ")):<br/>        if oword.lower() == rword:<br/>            output_text += oword+" "<br/>        else:<br/>            output_text += rword+" "</span><span id="0f71" class="mx kx jg mo b gy nh mz l na nb">return output_text</span><span id="05df" class="mx kx jg mo b gy nh mz l na nb">output_text = filter_bad_words(model(textbox, do_sample=True, max_length=slider, top_k=50, top_p=0.95, num_returned_sequences=1)[0]['generated_text'])</span></pre><p id="e184" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">我们最终的<code class="fe ml mm mn mo b">app.py</code>文件现在看起来像这样:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="9b57" class="mx kx jg mo b gy my mz l na nb">import urllib<br/>import streamlit as st<br/>import torch<br/>from transformers import pipeline</span><span id="8537" class="mx kx jg mo b gy nh mz l na nb">def load_bad_words() -&gt; list:<br/>    res_list = []</span><span id="97fd" class="mx kx jg mo b gy nh mz l na nb">file = urllib.request.urlopen("<a class="ae jd" href="https://raw.githubusercontent.com/RobertJGabriel/Google-profanity-words/master/list.txt" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/RobertJGabriel/Google-profanity-words/master/list.txt</a>")<br/>    for line in file:<br/>        dline = line.decode("utf-8")<br/>        res_list.append(dline.split("\n")[0])<br/>    <br/>    return res_list</span><span id="c8f0" class="mx kx jg mo b gy nh mz l na nb">BAD_WORDS = load_bad_words()<br/>    <br/><a class="ae jd" href="http://twitter.com/st" rel="noopener ugc nofollow" target="_blank">@st</a>.cache(allow_output_mutation=True, suppress_st_warning=True)<br/>def load_model():<br/>    return pipeline("text-generation", model="e-tony/gpt2-rnm")</span><span id="521b" class="mx kx jg mo b gy nh mz l na nb">def filter_bad_words(text):<br/>    explicit = False<br/>    <br/>    res_text = text.lower()<br/>    for word in BAD_WORDS:<br/>        if word in res_text:<br/>            res_text = res_text.replace(word, word[0]+"*"*len(word[1:]))<br/>            explicit = True</span><span id="9a3c" class="mx kx jg mo b gy nh mz l na nb">if not explicit:<br/>        return text</span><span id="4022" class="mx kx jg mo b gy nh mz l na nb">output_text = ""<br/>    for oword,rword in zip(text.split(" "), res_text.split(" ")):<br/>        if oword.lower() == rword:<br/>            output_text += oword+" "<br/>        else:<br/>            output_text += rword+" "</span><span id="325a" class="mx kx jg mo b gy nh mz l na nb">return output_text</span><span id="2b30" class="mx kx jg mo b gy nh mz l na nb">model = load_model()<br/>textbox = st.text_area('Start your story:', '', height=200, max_chars=1000)<br/>slider = slider = st.slider('Max text length (in characters)', 50, 1000)<br/>button = st.button('Generate')</span><span id="1b66" class="mx kx jg mo b gy nh mz l na nb">if button:<br/>    output_text = filter_bad_words(model(textbox, do_sample=True, max_length=slider, top_k=50, top_p=0.95, num_returned_sequences=1)[0]['generated_text'])<br/> <br/>    for i, line in enumerate(output_text.split("\n")):<br/>        if ":" in line:<br/>            speaker, speech = line.split(':')<br/>            st.markdown(f'__{speaker}__: {speech}')<br/>        else:<br/>            st.markdown(line)</span></pre><p id="3e94" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">您还可以在Github <a class="ae jd" href="https://github.com/e-tony/Story_Generator" rel="noopener ugc nofollow" target="_blank">资源库</a>中查看我的<a class="ae jd" href="https://share.streamlit.io/e-tony/story_generator/main/app.py" rel="noopener ugc nofollow" target="_blank">演示</a>的代码，因为它包含了修改应用程序功能和外观的有用代码。</p><p id="cbcc" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">它现在已经准备好上线了！</p><h1 id="0a2e" class="kw kx jg bd ky kz la lb lc ld le lf lg km lh kn li kp lj kq lk ks ll kt lm ln bi translated">部署应用程序</h1><p id="66cc" class="pw-post-body-paragraph lo lp jg lq b lr ls kh lt lu lv kk lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">可以使用Streamlit共享⁰.部署该应用程序您只需要有一个公共的Github存储库，存储库中有一个<code class="fe ml mm mn mo b">requirements.txt</code>和一个<code class="fe ml mm mn mo b">app.py</code>文件。您的<code class="fe ml mm mn mo b">requirements.txt</code>文件应该是这样的:</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="0d00" class="mx kx jg mo b gy my mz l na nb">-f <a class="ae jd" href="https://download.pytorch.org/whl/torch_stable.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/torch_stable.html</a><br/>streamlit-nightly==0.69.3.dev20201025<br/>torch==1.6.0+cpu<br/>torchvision==0.7.0+cpu<br/>transformers @ git+git://github.com/huggingface/transformers@59b5953d89544a66d73</span></pre><p id="e3f9" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">在Streamlit Sharing <a class="ae jd" href="https://share.streamlit.io/" rel="noopener ugc nofollow" target="_blank">网站</a>上，您可以简单地链接您的存储库，您的模型将很快上线！</p><h1 id="f08f" class="kw kx jg bd ky kz la lb lc ld le lf lg km lh kn li kp lj kq lk ks ll kt lm ln bi translated">道德考量</h1><p id="7ae7" class="pw-post-body-paragraph lo lp jg lq b lr ls kh lt lu lv kk lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">本文中介绍的应用程序仅用于娱乐目的！应该仔细考虑在其他场景中应用GPT2模型。虽然从原始训练数据中删除了某些域，但GPT2模型是在来自互联网的大量未经过滤的内容上进行预训练的，这些内容包含有偏见和歧视性的语言。OpenAI的<a class="ae jd" href="https://github.com/openai/gpt-2/blob/master/model_card.md#intended-uses" rel="noopener ugc nofollow" target="_blank">型号卡</a>指出了这些注意事项:</p><blockquote class="ni nj nk"><p id="55ac" class="lo lp mk lq b lr nc kh lt lu nd kk lw nl ne lz ma nm nf md me nn ng mh mi mj ij bi translated">以下是我们认为可能的一些次要使用案例:</p><p id="9269" class="lo lp mk lq b lr nc kh lt lu nd kk lw nl ne lz ma nm nf md me nn ng mh mi mj ij bi translated">-写作辅助:语法辅助、自动补全(针对普通散文或代码)</p><p id="e54b" class="lo lp mk lq b lr nc kh lt lu nd kk lw nl ne lz ma nm nf md me nn ng mh mi mj ij bi translated">-创造性写作和艺术:探索创造性虚构文本的生成；帮助诗歌和其他文学艺术的创作。</p><p id="49d2" class="lo lp mk lq b lr nc kh lt lu nd kk lw nl ne lz ma nm nf md me nn ng mh mi mj ij bi translated">-娱乐:创造游戏、聊天机器人和娱乐一代。</p><p id="449c" class="lo lp mk lq b lr nc kh lt lu nd kk lw nl ne lz ma nm nf md me nn ng mh mi mj ij bi translated">范围外的使用案例:</p><p id="bb86" class="lo lp mk lq b lr nc kh lt lu nd kk lw nl ne lz ma nm nf md me nn ng mh mi mj ij bi translated">因为像GPT-2这样的大规模语言模型不能区分事实和虚构，所以我们不支持要求生成的文本是真实的用例。此外，像GPT-2这样的语言模型反映了他们接受培训的系统固有的偏见，所以我们不建议将它们部署到与人类交互的系统中，除非部署者首先进行与预期用例相关的偏见研究。我们发现774M和1.5B之间在性别、种族和宗教偏见调查方面没有统计学上的显著差异，这意味着所有版本的GPT-2都应该以类似的谨慎程度对待对人类属性偏见敏感的用例。</p></blockquote><p id="073c" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">下面的例子展示了模型如何产生有偏差的预测(另一个例子可以在<a class="ae jd" href="https://huggingface.co/gpt2#limitations-and-bias" rel="noopener ugc nofollow" target="_blank">这里找到</a>):</p><pre class="mp mq mr ms gt mt mo mu mv aw mw bi"><span id="d1e2" class="mx kx jg mo b gy my mz l na nb">&gt;&gt;&gt; from transformers import pipeline, set_seed<br/>&gt;&gt;&gt; generator = pipeline('text-generation', model='gpt2')<br/>&gt;&gt;&gt; set_seed(42)<br/>&gt;&gt;&gt; generator("The man worked as a", max_length=10, num_return_sequences=5)</span><span id="0747" class="mx kx jg mo b gy nh mz l na nb">[{'generated_text': 'The man worked as a waiter at a Japanese restaurant'},<br/> {'generated_text': 'The man worked as a bouncer and a boun'},<br/> {'generated_text': 'The man worked as a lawyer at the local firm'},<br/> {'generated_text': 'The man worked as a waiter in a cafe near'},<br/> {'generated_text': 'The man worked as a chef in a strip mall'}]</span><span id="fec7" class="mx kx jg mo b gy nh mz l na nb">&gt;&gt;&gt; set_seed(42)<br/>&gt;&gt;&gt; generator("The woman worked as a", max_length=10, num_return_sequences=5)</span><span id="2498" class="mx kx jg mo b gy nh mz l na nb">[{'generated_text': 'The woman worked as a waitress at a Japanese restaurant'},<br/> {'generated_text': 'The woman worked as a waitress at a local restaurant'},<br/> {'generated_text': 'The woman worked as a waitress at the local supermarket'},<br/> {'generated_text': 'The woman worked as a nurse in a health center'},<br/> {'generated_text': 'The woman worked as a maid in Daphne'}]</span></pre><p id="1a3e" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">我敦促读者仔细考虑这些模型在真实场景中的应用和使用。有许多资源(如EML、艾诺)可用于了解道德规范。</p><h1 id="bc30" class="kw kx jg bd ky kz la lb lc ld le lf lg km lh kn li kp lj kq lk ks ll kt lm ln bi translated">结论</h1><p id="70f9" class="pw-post-body-paragraph lo lp jg lq b lr ls kh lt lu lv kk lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">恭喜你！您的应用程序现已上线！</p><p id="83f7" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">通过使用开源框架，我们能够快速微调GPT2模型，原型化有趣的应用程序，并部署它。通过使用更先进的<em class="mk">预训练</em>模型、<em class="mk">解码</em>方法，甚至<em class="mk">结构化语言预测</em>，可以进一步改进生成的故事。</p><p id="dcd1" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated"><em class="mk">你可以测试出</em><a class="ae jd" href="https://share.streamlit.io/e-tony/story_generator/main/app.py" rel="noopener ugc nofollow" target="_blank"><em class="mk">demo</em></a><em class="mk">或者在</em><a class="ae jd" href="https://github.com/e-tony/Story_Generator" rel="noopener ugc nofollow" target="_blank"><em class="mk">Github</em></a><em class="mk">上查看项目。</em></p><h1 id="36a3" class="kw kx jg bd ky kz la lb lc ld le lf lg km lh kn li kp lj kq lk ks ll kt lm ln bi translated">参考</h1><p id="b910" class="pw-post-body-paragraph lo lp jg lq b lr ls kh lt lu lv kk lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">[1]: <a class="ae jd" href="https://github.com/openai/gpt-2" rel="noopener ugc nofollow" target="_blank"> GPT2 </a></p><p id="e34c" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[2]: <a class="ae jd" href="https://awesomeopensource.com/projects/gpt-2" rel="noopener ugc nofollow" target="_blank">排名前30的Gpt2开源项目</a></p><p id="e780" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[3]: <a class="ae jd" href="https://ruder.io/state-of-transfer-learning-in-nlp/" rel="noopener ugc nofollow" target="_blank">自然语言处理中迁移学习的状态</a></p><p id="f7b9" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[4]: <a class="ae jd" href="https://github.com/openai/gpt-2/blob/master/domains.txt" rel="noopener ugc nofollow" target="_blank">网络文本中出现的前1000个域名</a></p><p id="a4d9" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[5]: A .、Jeffrey Wu、R. Child、David Luan、Dario Amodei和Ilya Sutskever 2019。语言模型是无人监督的多任务学习者。</p><p id="8e3e" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[6]: <a class="ae jd" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank">更好的语言模型及其含义</a></p><p id="e478" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[7]: <a class="ae jd" href="http://jalammar.github.io/illustrated-gpt2/" rel="noopener ugc nofollow" target="_blank">图解GPT-2(可视化变压器语言模型)</a></p><p id="39ae" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[8]: <a class="ae jd" href="https://huggingface.co/transformers/model_sharing.html" rel="noopener ugc nofollow" target="_blank">模型分享上传</a></p><p id="b4db" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[9]: <a class="ae jd" href="https://huggingface.co/blog/how-to-generate" rel="noopener ugc nofollow" target="_blank">如何生成文本:用变形金刚使用不同的解码方法进行语言生成</a></p><p id="ac19" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[10]: <a class="ae jd" href="https://docs.streamlit.io/en/stable/deploy_streamlit_app.html" rel="noopener ugc nofollow" target="_blank">部署一个app </a></p><p id="d89a" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[11]: <a class="ae jd" href="https://ethical.institute/" rel="noopener ugc nofollow" target="_blank">伦理人工智能研究所&amp;机器学习</a></p><p id="0178" class="pw-post-body-paragraph lo lp jg lq b lr nc kh lt lu nd kk lw lx ne lz ma mb nf md me mf ng mh mi mj ij bi translated">[12]: <a class="ae jd" href="https://ainowinstitute.org/" rel="noopener ugc nofollow" target="_blank">艾现在研究所</a></p></div></div>    
</body>
</html>