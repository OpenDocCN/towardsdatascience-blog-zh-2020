<html>
<head>
<title>Computer Vision — When Computers Can See &amp; Perceive!!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉——当计算机能够看见和感知的时候！！！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/computer-vision-ad2d0cbc6313?source=collection_archive---------39-----------------------#2020-11-03">https://towardsdatascience.com/computer-vision-ad2d0cbc6313?source=collection_archive---------39-----------------------#2020-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7e8b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">电脑能够看、听和学习。欢迎来到未来”——戴夫·沃尔特斯</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/af5dd8aebd8ade0a65e5fe4b1cf3ce86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aDpPeVj7AghCiJCdk2r44g.png"/></div></div></figure><p id="e1c5" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">众所周知，计算机的计算能力远远超过人类。因此，自20世纪中期以来，已经尝试通过利用计算机来逐渐自动化计算繁重的活动。随着机器学习(ML)应用的出现和日益熟练，预测模型已经占据了优先地位。ML接管的一些例子如下</p><ol class=""><li id="4307" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln lt lu lv lw bi translated"><em class="lx">通过主动识别可能终止订阅的客户来留住客户</em></li><li id="d536" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln lt lu lv lw bi translated"><em class="lx">销售、需求、收入等的预测。对于任何行业</em></li><li id="7f08" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln lt lu lv lw bi translated"><em class="lx">识别任何行业中交叉销售的客户</em></li><li id="f9c3" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln lt lu lv lw bi translated"><em class="lx">识别可能拖欠按揭付款的客户</em></li><li id="ee81" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln lt lu lv lw bi translated"><em class="lx">通过识别可能发生故障的机器进行预防性维护</em></li></ol><p id="ae82" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">然而，历史上需要人类感知来解决的问题超出了经典(静态)ML算法的范围。好消息是，随着2010年代初以来深度学习(DL)的大规模突破，在解决传统上需要人类直觉的问题时，可以观察到接近人类的表现。前面提到的感知问题需要处理声音和图像的技能。因此，通过听觉和视觉进行感知和处理的能力似乎是促进解决此类问题的主要技能。这些技能对人类来说是自然而直观的，但对机器来说却是难以捉摸的。下面给出了一些通过应用DL解决感知问题的例子</p><ul class=""><li id="d96e" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln md lu lv lw bi translated"><em class="lx">接近人体水平的图像分类和目标检测</em></li><li id="a081" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated"><em class="lx">接近人类水平的语音识别</em></li><li id="b37b" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated"><em class="lx">接近人类水平的笔迹转录</em></li><li id="aab0" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated"><em class="lx">改进的机器翻译</em></li><li id="2ac0" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated"><em class="lx">改进的文本到语音转换</em></li><li id="1ac2" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated"><em class="lx">Google Now、亚马逊Alexa等数字助手</em></li><li id="a7e8" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated"><em class="lx">接近人类水平的自动驾驶</em></li><li id="1127" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated">回答自然语言问题的能力</li></ul><p id="78c9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">然而，必须指出的是，这仅仅是一个开始，我们仅仅触及到所能取得的成就的表面。也有正在进行的对形式推理领域的研究。如果成功，这可能在科学、心理学、软件开发等领域帮助人类。</p><p id="5abd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我想到的问题是，机器如何做到这一点，即获得感知能力来解决需要人类直觉的问题。数字处理，解决处理数字和/或类别的问题，应用监督学习(或无监督学习)属于具有巨大计算能力的机器领域。能够看到和识别图像的组成部分是一项新技能，本文的重点是关注现在赋予计算机像人类一样解决图像问题的能力的过程。本文的内容包括以下内容</p><ol class=""><li id="3fcc" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln lt lu lv lw bi translated"><em class="lx">人工智能(AI)和深度学习(DL)简介</em></li><li id="090a" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln lt lu lv lw bi translated"><em class="lx">通过应用全连接层(FCN)即多层感知器(MLP)进行图像识别</em></li><li id="9363" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln lt lu lv lw bi translated"><em class="lx">卷积神经网络介绍(CNN) </em></li><li id="ea66" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln lt lu lv lw bi translated"><em class="lx">为什么CNN在解决图像相关问题时比MLPs更常用</em></li><li id="f074" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln lt lu lv lw bi translated"><em class="lx">CNN的工作</em></li><li id="da9a" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln lt lu lv lw bi translated"><em class="lx">MLP和CNN的表现对比</em></li></ol><h2 id="5a9e" class="me mf iq bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv mw bi translated"><strong class="ak">人工智能和DL简介</strong></h2><p id="ffbf" class="pw-post-body-paragraph ks kt iq ku b kv mx jr kx ky my ju la lb mz ld le lf na lh li lj nb ll lm ln ij bi translated">人工智能是一个通过应用逻辑、if-then规则、决策树和ML(包括DL)使计算机能够模仿人类智能的领域。人工神经网络是人工智能的一个分支。以下图示将进一步阐明AI的子集，即ML和DL。数据科学跨越了人工智能的所有层面。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/5cf1d29af8dd3665d608b8e5ac5948ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*r0ihHv33gKWPUw_KwChKgQ.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图1:人工智能子集(图片由作者提供)</p></figure><p id="4056" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">任何人工神经网络架构的基础都始于这样一个前提，即模型需要经历多次迭代，考虑到错误，从错误中学习，并在学习足够多的时候实现<em class="lx">拯救</em>或饱和，从而产生等于或类似于现实的结果。下图向我们简要介绍了人工神经网络，并介绍了DL神经网络。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nh"><img src="../Images/7e29b0936f0a6ade85a00324cb2afcb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RHRKyHlnICh38fkiC7oAVA.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图2:浅层网络与DLNN的比较(图片来自作者的早期文章<a class="ae ni" href="https://medium.com/analytics-vidhya/foundations-of-deep-learning-7832d4fe5458" rel="noopener"/></p></figure><p id="b016" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">人工神经网络本质上是一种由多层处理单元(即神经元)组成的结构，这些处理单元获取输入数据，并通过连续的层对其进行处理，以获得有意义的表示。深度学习中的deep这个词代表了这种连续层表示的思想。有多少层对一个数据模型有贡献，称为模型的深度。上图更好地说明了结构，因为我们有一个只有一个隐藏层的简单ANN和一个有多个隐藏层的DL神经网络(DNN)。因此，DL或DLNN是具有多个隐藏层的ANN。</p><p id="ed55" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">本文假设读者熟悉构成监督学习基础的概念，以及DL如何利用它来学习数据中的模式(在这种情况下是图像中的模式)以获得准确的结果。为了更好地理解本文的其余部分，需要对以下项目有概念性的理解</p><ul class=""><li id="7733" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln md lu lv lw bi translated">监督学习</li><li id="f6b1" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated">深度学习</li><li id="9142" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated">损失函数</li><li id="c1f4" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated">梯度下降</li><li id="b320" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated">向前和向后传播</li></ul><p id="0a72" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了复习，读者可以在互联网上探索关于这些主题的免费资料，或者浏览我发表的文章，<a class="ae ni" href="https://medium.com/analytics-vidhya/foundations-of-deep-learning-7832d4fe5458" rel="noopener">深度学习的基础</a>。深入研究上述每个概念超出了本文的范围。</p><h2 id="4ba3" class="me mf iq bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv mw bi translated"><strong class="ak">通过应用完全连接的层，即多层感知器的图像识别</strong></h2><p id="5c1a" class="pw-post-body-paragraph ks kt iq ku b kv mx jr kx ky my ju la lb mz ld le lf na lh li lj nb ll lm ln ij bi translated">现在让我们深入研究一个实例，说明如何利用人工神经网络来查看图像并将它们分类到适当的类别。我们将从在真实世界数据集上应用FCN开始，并衡量所实现的效率。假设读者对什么是FCN及其操作方式有更深的理解。在非常高的层次上，FCN或MLP是一个人工神经网络，其中每一层的每个元素都与下一层的每个元素相连接。下面的图3展示了FCN的样子。更多细节请参考我发表的文章，<a class="ae ni" href="https://medium.com/analytics-vidhya/foundations-of-deep-learning-7832d4fe5458" rel="noopener">深度学习的基础</a>。</p><p id="c5f9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们试图解决的问题包括从街道拍摄的门牌号图像中识别数字。数据集名为街景门牌号(SVHN)。SVHN是一个真实世界的图像数据集，用于开发机器学习和对象识别算法，对数据格式的要求最低，但来自一个明显更难、未解决的真实世界问题(识别自然场景图像中的数字和数字)。SVHN是从谷歌街景图片中的门牌号获得的。</p><p id="aacf" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们要实现的目标是从SVHN数据集获取一个图像，并确定该数字是什么。这是一个多类分类问题，有10个可能的类，每个类对应一个数字0-9。数字“1”的标签为1，“9”的标签为9，“0”的标签为10。虽然，在这个数据集中有接近6，000，000幅图像，但我们已经提取了60，000幅图像(42000幅训练图像和18000幅测试图像)来做这个项目。这些数据是以一个数字为中心的32乘32的RGB图像的类似MNIST的格式(许多图像在边上确实包含一些干扰物)。</p><p id="4cf0" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们将使用原始像素值作为网络的输入。这些图像是大小为32×32的矩阵。因此，我们将图像矩阵整形为一个大小为1024 ( 32*32)的数组，并将该数组提供给如下所示的人工神经网络。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/7eb0585a438fa1344075b8b6fb0fc37e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*5PJosWmdz48SkFk6VSE00Q.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图3: FCN建筑(图片由作者提供)</p></figure><p id="1e27" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">链接到数据集的是<a class="ae ni" href="https://drive.google.com/file/d/1L2-WXzguhUsCArrFUc8EEkXcj33pahoS/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里的</a>。</p><p id="2732" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">下面是加载数据和可视化一些图像的代码。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nk nl l"/></div></figure><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nm"><img src="../Images/af102098d81ae26d471239bb0473f39e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_vMZzMHbXTJ46QcHndChrQ.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图Jupyter笔记本的截图，显示了一些图片及其标签</p></figure><p id="71fe" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">用不同数量的隐藏层和每层中不同数量的神经元构建多个MLPs。对每个模型的结果进行比较，三个隐藏层的结果最好。模型架构如下所示。它达到了大约80%的准确率。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="7352" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">下面描述了损失如何逐渐减少和精确度如何迭代增加的可视化</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/663162271f62de62f5f0f88ed7328ca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*adZtQiW-HcUsLxzFO3sBMw.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图Jupyter笔记本截图</p></figure><p id="4eb8" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">预测了测试数据(未暴露于训练过程)中的一些图像。相同的可视化和与其原始标签的比较如下所示。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nk nl l"/></div></figure><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/b865e4b29fb52b65b9306eb682256011.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*vvyTRRDUpNs4kO3G9wYJ4Q.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图Jupyter笔记本截图</p></figure><p id="9fe9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们测试了来自可视化测试集的3幅图像，并且看到分类是准确的，这可以给我们成就感和舒适感。如前所述，在整个测试集上达到的准确度为80%。由于测试集由18000幅图像组成，80%的准确率是相当可接受的性能。然而，这是最好的方法吗？这是能达到的最好结果吗？或者有比这更好的方法吗？带着这些问题，让我们进入下一部分。</p><p id="abad" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">端到端项目的完整代码可以在我的github帐户中找到。代码的链接也可以在<a class="ae ni" href="https://jovian.ai/pranov1984/mnist-denselayers" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="0436" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">卷积神经网络介绍(CNN) </strong></p><p id="9a9a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">虽然上面解释的全连接网络(FCN)达到了可接受的精度，但它还可以进一步改进。除了FCN，还有另一类神经网络称为卷积神经网络(CNN)，其内部操作更符合视觉图像的处理要求。已经发现CNN在涉及图像的用例中给出更好的性能。</p><p id="0d07" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">CNN比FCN好得多，因为基于它们的共享权重架构和平移不变性特征，它们是平移不变或空间不变的人工神经网络。我们将在下一节中深入探讨这个问题。</p><p id="ffab" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在我们详细了解CNN如何工作以及为什么它们比fcn更好之前，让我们先了解一下CNN的基本操作。理解CNN最重要的概念是卷积运算。</p><p id="f4d1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">卷积是一种简单的数学运算，是许多常见图像处理运算符的基础。卷积提供了一种将通常大小不同但维数相同的两个数列“相乘”的方法，以产生维数相同的第三个数列。这可以用在图像处理中，以实现其输出像素值是某些输入像素值的简单线性组合的算子。</p><p id="2cdb" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在图像处理环境中，输入数组之一通常只是图像的像素表示。第二个数组通常小得多，并且通常是二维的(尽管它可能只有单个像素厚)，并且被称为内核。下面是图像和可用于卷积的内核的图形表示。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi no"><img src="../Images/85188ef24afaa49b5398d0a43e0fc7ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*Q21HCu0nJUX1Af8iVsV_9g.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图7:图像和内核(作者提供的图像)</p></figure><p id="c204" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">卷积是通过在图像上滑动内核来执行的，通常从左上角开始，以便将内核移动通过所有位置，其中内核完全适合图像的边界。(请注意，实现的不同之处在于它们在图像边缘做了什么，如下所述。)每个内核位置对应于单个输出像素，其值通过将内核值和内核中每个单元的底层图像像素值相乘，然后将所有这些数字相加来计算。</p><p id="4284" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">因此，在我们的示例中，输出图像中右下角像素的值将由下式给出:</p><h2 id="3a0c" class="me mf iq bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv mw bi translated">o33 = I33 * W11+I34 * W12+I43 * W21+I44 * W22</h2><p id="f346" class="pw-post-body-paragraph ks kt iq ku b kv mx jr kx ky my ju la lb mz ld le lf na lh li lj nb ll lm ln ij bi translated">由CNN完成的图像分类，通过获取输入图像、处理它并将其分类到某些类别下(例如，在我们的use SVHN用例中从0到9)来工作。计算机将输入图像视为像素阵列。基于图像分辨率，它会看到h x w x d( h =高度，w =宽度，d =尺寸)。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi np"><img src="../Images/3f2075d590a17a4fdd5de2b8ad15db14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*Op1JW0vEDDQhFnCzHrL9cw.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">计算机视觉:计算机如何看到图像(来源:<a class="ae ni" href="https://en.wikipedia.org/wiki/Convolutional_neural_network#/media/File:Conv_layers.png" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="265f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">卷积是从输入图像中提取特征的第一层。卷积通过使用输入数据的小方块学习图像特征来保持像素之间的关系。它是一种数学运算，需要两个输入，如图像矩阵和滤波器或内核。</p><p id="3f9c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">下图说明了卷积(或相关)运算是如何执行的。这里，I表示图像，W表示将对输入图像进行卷积的核。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nq"><img src="../Images/6a4d7dfb67dc210d8dd6a5a32d8ad830.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aPLyL4kW7gD50JSONx1cFg.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图8:卷积运算</p></figure><p id="ff97" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">上面的描述可以通过一个核的实际例子来进一步简化，该核在由像素表示的图像上充当过滤器。上面的公式用于图像输入和内核权重，以得到内核或滤波器输出。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nr"><img src="../Images/fa8a00d791f7c2b83437876519f59747.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qQL_fANVjHuQyAd2mzEgbQ.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图9:滤波器输出的计算</p></figure><p id="6ce3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">因此，当我们有一个更大的图像和一个典型的更小的内核时，内核将在图像上滑动，如下图所示，并通过卷积运算计算每次迭代的输出。滑过绿色方块的黄色方块就是内核。绿色方块是通过像素值表示的图像。卷积输出由右边的粉色方块表示，这实际上是学习到的特征。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ns nl l"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图10(来源:GIPHY链接此处为<a class="ae ni" href="https://media.giphy.com/media/i4NjAwytgIRDW/giphy.gif" rel="noopener ugc nofollow" target="_blank"/>。)</p></figure><h2 id="52ca" class="me mf iq bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv mw bi translated"><strong class="ak"> <em class="kf">为什么CNN比MLPs更能解决图像相关问题</em> </strong></h2><p id="8649" class="pw-post-body-paragraph ks kt iq ku b kv mx jr kx ky my ju la lb mz ld le lf na lh li lj nb ll lm ln ij bi translated">既然解决了卷积运算，让我们试着回答上面的问题。主要原因是</p><ul class=""><li id="9db5" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln md lu lv lw bi translated">一个简单的FCN需要大量的参数来训练模型</li><li id="a66f" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated"><em class="lx">在图像中，空间相关性是局部的</em></li><li id="adca" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated"><em class="lx">通常可用的图像数量有限</em></li><li id="6295" class="lo lp iq ku b kv ly ky lz lb ma lf mb lj mc ln md lu lv lw bi translated"><em class="lx">平移不变性是处理图像的关键要素</em></li></ul><blockquote class="nt nu nv"><p id="e938" class="ks kt lx ku b kv kw jr kx ky kz ju la nw lc ld le nx lg lh li ny lk ll lm ln ij bi translated">一个简单的FCN需要大量的参数来训练模型</p></blockquote><p id="e01b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">FCNs(或MLPs)对每个输入(例如，图像中的像素)使用一个感知器，并且对于大图像，权重的数量很快变得难以管理。它包含太多参数，因为它是完全连接的。每个节点都与上下一层中的所有其他节点相连，形成一个非常密集的网络。为了便于讨论，如果我们有一个如图3所示的人工神经网络，只有两个隐藏层的参数数量超过2亿个。这是一个尺寸只有32*32的图像。对于尺寸为200*200像素的中等大小的图像，需要训练的参数的数量将会达到顶点。因此，从(计算机的)计算能力的角度来看，使用FCN(或MLPs)来解决复杂的图像相关问题不是最佳方法。此外，如果可用图像的数量较少，用如此大量的参数进行训练将导致过度拟合。</p><blockquote class="nt nu nv"><p id="9b4c" class="ks kt lx ku b kv kw jr kx ky kz ju la nw lc ld le nx lg lh li ny lk ll lm ln ij bi translated"><em class="iq">在图像中，空间相关性是局部的。CNN帮助实现平移不变性</em></p></blockquote><p id="03a1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">另一个常见的问题是MLP对输入(图像)及其平移版本的反应不同，它们不是平移不变的。例如，如果一个航天飞机的图片出现在一个图片的图像的左上角，而在另一个图片的右下角，MLP将试图纠正自己，并假设航天飞机将总是出现在图像的这一部分。请参考下面的图11进行说明。因此，MLP不是图像处理的最佳选择。一个主要问题是，当图像被展平(矩阵到矢量)成MLP时，空间信息丢失。在FCN中，像素之间的相关性不是局部的，即航天飞机的组件与背景或图像中存在的任何其他对象相关(例如图11第一部分中的汽车)。因此，如果画面移动，模型中的学习就会受到影响。这是在CNN中解决的，因为它们依赖于卷积运算，并且即使图像移动，激活也将保持不变。当内核在图像上滑动以在每次迭代中提供激活时，激活被定位。重量是共享的。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nz"><img src="../Images/517ae74343f04a8845c62b96f9abeff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V5r0-EICN8BDKt_3s48OSQ.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图11:CNN中空间不变性的图示(图片由作者提供)</p></figure><h2 id="51f8" class="me mf iq bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv mw bi translated"><em class="kf">CNN的工作</em></h2><p id="92b9" class="pw-post-body-paragraph ks kt iq ku b kv mx jr kx ky my ju la lb mz ld le lf na lh li lj nb ll lm ln ij bi translated">下图是一个32*32大小的输入图像的CNN表示。我们有20个维数为5*5的核，它们执行前面解释的卷积运算。对图像进行第一次卷积运算后得到的特征图像的尺寸为28*28。下图中的CONV图层表示相同的图像，即20幅尺寸为28*28的特征图像。计算任何卷积运算的结果维数的数学公式将在本节后面给出。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi oa"><img src="../Images/bced37a8720ed530f469bdaf66ae9a5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fUXgCacXnee84raDbL6QQg.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图11:用于分类的CNN的端到端表示</p></figure><p id="fa1b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这里引入的新概念是上图中的池层所表示的池操作，这个概念之前没有讨论过。</p><p id="edb4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">汇集操作包括在特征图的每个通道上滑动二维过滤器，并总结位于过滤器覆盖的区域内的特征。池层的数学计算与卷积运算非常相似。卷积层有助于学习图像的特征，并产生与使用的核的数量一样多的特征图。汇集层执行下采样操作，并汇总由卷积层生成的多个要素地图所产生的要素。这有助于巩固网络中的感受领域。典型的CNN架构通常具有一个接一个堆叠的多个卷积层和池层。</p><p id="023d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">CNN中的卷积层系统地将学习的滤波器应用于输入图像，以便创建概括输入中那些特征的存在的特征图。</p><p id="e61a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">卷积层被证明是非常有效的，并且在深度模型中堆叠卷积层允许靠近输入的层学习低级特征(例如，线)，而在模型中更深的层学习高阶或更抽象的特征，如形状或特定对象。</p><p id="dcca" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">卷积图层的要素地图输出的局限性在于，它们记录了输入中要素的精确位置。这意味着输入图像中特征位置的微小移动将导致不同的特征地图。这可以通过引入池层来解决。汇集图层汇总了由卷积图层生成的要素地图区域中的要素。因此，将对汇总的要素而不是由卷积层生成的精确定位的要素执行进一步的操作。这使得模型对于输入图像中特征位置的变化更加鲁棒。下面给出了两种主要的汇集方法</p><ul class=""><li id="45e6" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln md lu lv lw bi translated"><strong class="ku ir">平均池</strong>:计算特征图上每个面片的平均值。</li></ul><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/da898ba1b64efdfd17a897f2666a3f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*HymNtZl6be37tc72FFABLQ.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图13:平均池操作的图示(<a class="ae ni" href="https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><ul class=""><li id="4338" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln md lu lv lw bi translated"><strong class="ku ir">最大池(或最大池)</strong>:计算特征图每个面片的最大值。</li></ul><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/df246ccf7c2fddfad08ce3628d30c028.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*pLGJMWesJlmHzKQSTOxnXg.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图14:最大池操作的图示(<a class="ae ni" href="https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="8c09" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在开始运行案例研究之前，我想解释的最后一件事是，当卷积图层应用于输入图像时，列出用于计算特征图维度的公式。相同的公式仍然适用于卷积和池的后续层。</p><p id="bde2" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">输出图像尺寸= (W - F +2P)/S +1</p><blockquote class="nt nu nv"><p id="ebe4" class="ks kt lx ku b kv kw jr kx ky kz ju la nw lc ld le nx lg lh li ny lk ll lm ln ij bi translated"><em class="iq">其中W =图像尺寸</em></p><p id="989b" class="ks kt lx ku b kv kw jr kx ky kz ju la nw lc ld le nx lg lh li ny lk ll lm ln ij bi translated"><em class="iq"> F =过滤器的尺寸</em></p><p id="0558" class="ks kt lx ku b kv kw jr kx ky kz ju la nw lc ld le nx lg lh li ny lk ll lm ln ij bi translated"><em class="iq"> P =填充</em></p><p id="79e8" class="ks kt lx ku b kv kw jr kx ky kz ju la nw lc ld le nx lg lh li ny lk ll lm ln ij bi translated"><em class="iq"> S =步幅</em></p></blockquote><p id="bf7e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">步幅</strong>表示我们在卷积中的每一步移动了多少步。默认情况下是一个。与<strong class="ku ir">步距</strong> 1卷积。我们可以观察到输出的大小小于输入。为了保持输入中输出的维度，我们使用<strong class="ku ir">填充</strong>。<strong class="ku ir">填充</strong>是对输入矩阵对称加零的过程。对这两者更详细的解释可以在互联网上更多的免费内容中找到。</p><h2 id="a5a8" class="me mf iq bd mg mh mi dn mj mk ml dp mm lb mn mo mp lf mq mr ms lj mt mu mv mw bi translated"><em class="kf">MLP和CNN的表现对比</em></h2><p id="aed9" class="pw-post-body-paragraph ks kt iq ku b kv mx jr kx ky my ju la lb mz ld le lf na lh li lj nb ll lm ln ij bi translated">让我们继续我们试图在SVHN数据集上解决的数字识别问题。我们之前使用FCNs(或MLPs)达到了80%的准确率。我们现在将在用于训练的数据集上试验CNN的应用。</p><p id="0b68" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">下面提供了加载数据和预处理数据(标准化输入和一个热编码标签)的代码</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="16c9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">第一个CNN尝试的模型架构如下</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="324b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">然后编译该模型，并通过它解析数据以进行训练。该模型在验证数据上给出了90%的准确度，这已经比MLP实现的性能提高了10%。下面给出了编译、训练和评估验证数据性能的代码</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="3f90" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">上面打印语句的输出是90%。</p><p id="1988" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">模型如何迭代地学习特征并逐渐提高性能的可视化表示如下。我们看到了一种趋势，即每一个时期的损耗都在减少，而精度却在提高。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi od"><img src="../Images/ea8d2947975deaeaf0eb3a5364e1e0da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*Fc8QazNoF16YfQsumAvuTg.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">Jupyter Notebook中模型精度随时期增加的图形表示</p></figure><p id="83a1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在用不同的模型架构进行了几次实验之后，从构建的7个CNN的集合中获得了最好的结果。准确率达到了95%。模型中的混淆矩阵如下所示。整个代码的链接是github中的<a class="ae ni" href="https://github.com/Pranov1984/Digit-Recognition-in-photographs/blob/master/Digit_Recognition_SVNH_UsingKeras_HypTuning.ipynb" rel="noopener ugc nofollow" target="_blank">这里的</a>。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/4a39e0d065803247c1bfa20f25f73d0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*0LIOlBXYrsReZpNb-_ynNw.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">Jupyter笔记本的模型输出</p></figure><h1 id="1ec7" class="of mf iq bd mg og oh oi mj oj ok ol mm jw om jx mp jz on ka ms kc oo kd mv op bi translated"><strong class="ak">结论</strong></h1><p id="5d41" class="pw-post-body-paragraph ks kt iq ku b kv mx jr kx ky my ju la lb mz ld le lf na lh li lj nb ll lm ln ij bi translated">在这篇文章中，我们介绍了两种不同的方法来解决图像分类问题，即FCNs和CNN。我们目睹了两种方法的性能差异，这是由于CNN优越的操作方式造成的。到目前为止，我们在CNN中看到的图像分类的优势进一步建立在解决更复杂的问题上，如对象检测和语义分割。它们都是复杂解决方案的关键组件，如自动驾驶汽车，机器必须识别汽车前方的不同物体及其结构，以便能够以适当的方向和角度驾驶汽车。本文开头的图片是我书房的桌子，后面是桌子上所有物品的标识。所有这些成就都建立在CNN潜在的和确定的概念之上。在接下来的几篇文章中，我们将探索一个称为迁移学习的新概念，它可以帮助我们处理训练图像数量不足的情况。敬请期待！！！</p></div></div>    
</body>
</html>