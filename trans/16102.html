<html>
<head>
<title>A Guide to Scraping HTML Tables with Pandas and BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用熊猫和BeautifulSoup抓取HTML表格的指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-guide-to-scraping-html-tables-with-pandas-and-beautifulsoup-7fc24c331cf7?source=collection_archive---------1-----------------------#2020-11-06">https://towardsdatascience.com/a-guide-to-scraping-html-tables-with-pandas-and-beautifulsoup-7fc24c331cf7?source=collection_archive---------1-----------------------#2020-11-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e55e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">也是一个实际的例子</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c6a623e41d5a06d0ce79a26d89abe2fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hKjnuXvxxZyPna45"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="e844" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">抓取网页时碰到HTML表格是很常见的，如果没有正确的方法，从这些表格中提取有用的、一致的数据可能会有点棘手。</p><p id="64e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，您将看到如何使用两种不同的方法快速、高效地抓取这些元素:仅使用Pandas库和使用传统的抓取库BeautifulSoup。</p><p id="dc57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">举个例子，我刮了英超分类表。这很好，因为这是一个常见的表格，基本上可以在任何体育网站上找到。虽然有必要通知您这一点，但当您阅读时，表被刮擦不会产生太大的影响，因为我试图使这篇文章尽可能地一般化。</p><h1 id="ed13" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">pandas.read_html():快捷方式</h1><p id="18ca" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">如果你想要的只是从一个页面中获取一些表格，而不是别的，你甚至不需要设置一个完整的刮刀来完成这项工作，因为熊猫可以自己完成这项工作。<code class="fe mq mr ms mt b">pandas.read_html() </code>函数使用一些抓取库，如<em class="mp"> BeautifulSoup </em>和<em class="mp"> Urllib </em>来返回一个包含页面中所有表的列表作为数据帧。你只需要传递页面的URL。</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="5e45" class="my lt iq mt b gy mz na l nb nc">dfs = pd.read_html(url)</span></pre><p id="260d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您现在需要做的就是从列表中选择您想要的数据帧:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="2a75" class="my lt iq mt b gy mz na l nb nc">df = dfs[4]</span></pre><p id="7e83" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您不确定列表中帧的顺序，或者如果您不希望您的代码依赖于这种顺序(网站可能会改变)，您可以随时搜索数据帧，通过其长度找到您正在寻找的数据帧…</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="1b40" class="my lt iq mt b gy mz na l nb nc">for df in dfs:<br/>    if len(df) == 20:<br/>        the_one = df<br/>        break</span></pre><p id="6f1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">…或者按其列的名称，例如。</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="65ce" class="my lt iq mt b gy mz na l nb nc">for df in dfs:<br/>    if df.columns == ['#', 'Team', 'MP', 'W', 'D', 'L', 'Points']:<br/>        the_one = df<br/>        break</span></pre><p id="0341" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是熊猫并没有让我们的生活变得更容易。这个函数接受一些有用的参数来帮助您获得正确的表。您可以使用<code class="fe mq mr ms mt b">match </code>来指定表应该匹配的正则表达式字符串；<code class="fe mq mr ms mt b">header </code>获取带有您传递的特定标题的表格；例如，<code class="fe mq mr ms mt b">attrs </code>参数允许您通过表的类或id来标识表。</p><p id="a795" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，如果你不是只抓取表，而是使用，比方说，获取页面的请求，那么鼓励你将<code class="fe mq mr ms mt b">page.text</code>传递给函数，而不是URL:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="edd1" class="my lt iq mt b gy mz na l nb nc">page = requests.get(url)<br/>soup = BeautifulSoup(page.text, 'html.parser')<br/><br/>dfs = pd.read_html(page.text)</span></pre><p id="77d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您使用Selenium的web驱动程序来获取页面，情况也是如此:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="7df0" class="my lt iq mt b gy mz na l nb nc">dfs = pd.read_html(driver.page_source)</span></pre><p id="d010" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是因为这样做可以显著减少代码运行的时间，因为<code class="fe mq mr ms mt b">read_html() </code>函数不再需要获取页面。检查每个场景中一百次重复所用的平均时间:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="9843" class="my lt iq mt b gy mz na l nb nc">Using the URL:<br/>Average time elapsed: 0.2345 seconds</span><span id="3c14" class="my lt iq mt b gy nd na l nb nc">Using page.text:<br/>Average time elapsed: 0.0774 seconds</span></pre><p id="7105" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用URL使得代码速度慢了三倍。因此，只有当您不打算首先使用其他库获得页面时，使用它才有意义。</p><h1 id="9e15" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">用BeautifulSoup获取表格的元素</h1><p id="0d0a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">虽然熊猫真的很棒，但它不能解决我们所有的问题。有时候，您需要按元素来抓取一个表，可能是因为您不想要整个表，或者是因为表的结构不一致，或者是出于其他任何原因。</p><p id="f685" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，我们首先需要了解HTML表格的标准结构:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="f54c" class="my lt iq mt b gy mz na l nb nc">&lt;table&gt;<br/>    &lt;tr&gt;<br/>        &lt;th&gt;<br/>        &lt;th&gt;<br/>        &lt;th&gt;<br/>        &lt;th&gt;<br/>        &lt;th&gt;<br/>        &lt;th&gt;<br/>        &lt;th&gt;<br/>    &lt;/tr&gt;<br/>    &lt;tr&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>    &lt;/tr&gt;<br/>    &lt;tr&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>        &lt;td&gt;<br/>    &lt;/tr&gt;<br/>.<br/>.<br/>.<br/>&lt;/table&gt;</span></pre><p id="a53b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中,<code class="fe mq mr ms mt b">tr </code>代表“表格行”,<code class="fe mq mr ms mt b">th </code>代表“表头”,<code class="fe mq mr ms mt b">td </code>代表“表格数据”,数据以文本形式存储在这里。</p><p id="19c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模式通常是有帮助的，所以我们剩下要做的就是使用BeautifulSoup选择正确的元素。</p><p id="1bb5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先要做的是找到桌子。<code class="fe mq mr ms mt b">find_all() </code>方法返回满足我们传递给它的需求的所有元素的列表。然后，我们必须在列表中选择我们需要的表:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="cadf" class="my lt iq mt b gy mz na l nb nc">table = soup.find_all('table')[4]</span></pre><p id="eb63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，根据网站的不同，有必要指定表类或id。</p><p id="9ec3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">剩下的过程现在几乎是直观的了，对吗？我们只需要选择所有的<code class="fe mq mr ms mt b">tr </code>标签和它们里面的<code class="fe mq mr ms mt b">th </code>和<code class="fe mq mr ms mt b">td </code>标签中的文本。我们可以再次使用<code class="fe mq mr ms mt b">find_all() </code>来查找所有的<code class="fe mq mr ms mt b">tr </code>标签，是的，但是我们也可以以更直接的方式迭代这些标签。</p><p id="02c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe mq mr ms mt b">children</code>属性返回一个iterable对象，所有标签都在父标签的正下方，父标签是<code class="fe mq mr ms mt b">table</code>，因此它返回所有的<code class="fe mq mr ms mt b">tr </code>标签。因为它是一个可迭代的对象，我们需要像这样使用它。</p><p id="48da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">之后，每个<code class="fe mq mr ms mt b">child</code>都是<code class="fe mq mr ms mt b">tr</code>标签。我们只需要提取其中每个<code class="fe mq mr ms mt b">td</code>标签的文本。以下是所有这些的代码:</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="7bfb" class="my lt iq mt b gy mz na l nb nc">for child in soup.find_all('table')[4].children:<br/>    for td in child:<br/>        print(td.text)</span></pre><p id="c7eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">过程就完成了！然后你就有了你要找的数据，你可以用最适合你的方式操作它。</p><h2 id="39e3" class="my lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">其他可能性</h2><p id="7bad" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">例如，假设您对表格的标题不感兴趣。不使用<code class="fe mq mr ms mt b">children</code>，您可以选择第一个<code class="fe mq mr ms mt b">tr</code>标签，它包含标题数据，并使用<code class="fe mq mr ms mt b">next_siblings</code>属性。这和<code class="fe mq mr ms mt b">children</code>属性一样，将返回一个iterable，但是带有所有其他的<code class="fe mq mr ms mt b">tr</code>标签，它们是我们选择的第一个标签的<strong class="ky ir">兄弟标签</strong>。你将会跳过表格的标题。</p><pre class="kg kh ki kj gt mu mt mv mw aw mx bi"><span id="523d" class="my lt iq mt b gy mz na l nb nc">for sibling in soup.find_all('table')[4].tr.next_siblings:<br/>    for td in sibling:<br/>        print(td.text)</span></pre><p id="00ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就像孩子和下一个兄弟姐妹一样，你也可以寻找上一个兄弟姐妹、父母、后代等等。可能性是无穷无尽的，所以请务必查看<a class="ae kv" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup文档</a>，为您的铲运机找到最佳选择。</p><h1 id="52f5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">现实生活中的一个例子</strong></h1><p id="c40a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">到目前为止，我们已经编写了一些非常简单的代码来使用Python提取HTML表格。然而，当真正这样做时，你当然会有一些其他的问题要考虑。</p><p id="3fd6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，你需要知道如何存储你的数据。会直接写在文本文件里吗？还是将它存储在一个列表或字典中，然后创建<em class="mp">。csv </em>文件？还是会创建一个空的数据帧并用数据填充它？当然有很多可能性。我的选择是将所有内容存储在一个大的列表列表中，该列表列表稍后将被转换为DataFrame并作为<em class="mp">导出。csv </em>文件。</p><p id="cc1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在另一个主题中，您可能希望在代码中使用一些<code class="fe mq mr ms mt b">try</code>和<code class="fe mq mr ms mt b">except</code>子句，让代码准备好处理一些可能会发现的异常。当然，为了不使服务器过载，您还需要插入一些随机的暂停，并且利用代理提供者，比如<a class="ae kv" href="https://infatica.io/" rel="noopener ugc nofollow" target="_blank"> Infatica </a>，来确保只要还有表需要清理，您的代码就会一直运行，并且您和您的连接会受到保护。</p><p id="f630" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个例子中，我在整个2019/20赛季的每一轮比赛后都用我在本文中介绍的大部分内容刮出了英超积分榜。这是它的全部代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="f150" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一切都准备好了:使用<code class="fe mq mr ms mt b">children </code>属性收集表中的所有元素，处理异常，将数据转换成DataFrame，导出一个. csv文件，并随机暂停代码几秒钟。在这一切之后，这段代码收集的所有数据生成了这个有趣的图表:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/462d89ac8866e4b9289a7d6d42926d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ESUWQbtLbpa2KT28_99kHw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="c59d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你不会在互联网上找到绘制这样一个图表所需的数据。但是这就是抓取的好处:你可以自己去获取数据！</p><p id="2ab5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为总结，我希望这是有用的，并且当你再次抓取HTML表时不会有问题。如果你有问题，有建议，或者只是想保持联系，请随时通过<a class="ae kv" href="https://twitter.com/_otavioss" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae kv" href="https://github.com/otavio-s-s" rel="noopener ugc nofollow" target="_blank"> GitHub </a>或<a class="ae kv" href="https://www.linkedin.com/in/otavioss28/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>联系。</p><p id="2700" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>