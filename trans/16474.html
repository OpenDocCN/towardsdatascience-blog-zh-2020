<html>
<head>
<title>Getting To Know Your Features In Seconds With RAPIDS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过急流在几秒钟内了解您的功能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-to-know-your-features-in-seconds-with-rapids-c9b44c568ebd?source=collection_archive---------36-----------------------#2020-11-13">https://towardsdatascience.com/getting-to-know-your-features-in-seconds-with-rapids-c9b44c568ebd?source=collection_archive---------36-----------------------#2020-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1ab0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在GPU上端到端运行数据预处理管道</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0d63abd4549aa1b19df8dff950465f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SIeG-q-kUDELI2eo"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">泰勒·拉斯托维奇在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="d851" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇博文旨在展示我最近在正在进行的<a class="ae kv" href="https://www.kaggle.com/c/lish-moa" rel="noopener ugc nofollow" target="_blank">Kaggle竞赛中发表的</a><a class="ae kv" href="https://www.kaggle.com/louise2001/rapids-feature-importance-is-all-you-need" rel="noopener ugc nofollow" target="_blank">特征选择笔记本</a>。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="c8ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当面对数据科学问题时，探索性数据分析，尤其是了解特性的重要性，是至关重要的一步。然而，如果您的数据库很大，有许多相互联系，使得分析在计算时间上很昂贵，那么这一步可能经常会很难。</p><p id="2fb3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GPU在提高计算时间方面非常棒…如果你能使用它们的话！事实上，由于强大的框架(Tensorflow或Pytorch是最著名的)使数百万开发者能够释放出他们不可思议的能力，它们的用途通常是用于训练神经网络。</p><p id="504d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，如果你要用pandas或scikit-learn完成一些脏的预处理，如果你的数据很大，那会非常繁重，因为这些包没有任何参数来帮助你在GPU上运行它们。综上所述，在这个阶段，你无法充分利用你的GPU。</p><p id="4dfc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://developer.nvidia.com/rapids" rel="noopener ugc nofollow" target="_blank"> <em class="lz"> RAPIDS </em> </a>是Nvidia AI开发的一套软件包，旨在完全在GPU上执行端到端的数据科学和分析管道。</p><p id="d1c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本笔记本的目标是对MoA竞赛中的每个特征的每个目标进行单变量回归，即<em class="lz"> 872 x 206 = 179632 </em>逻辑模型分别进行估计。</p><p id="7051" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好消息是什么？有了<em class="lz">激流</em>这在几分钟之内是可能的！</p><p id="7eaf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以注意到，我既不导入pandas(被cudf取代)，也不导入scikit-learn(被cuml取代)。</p><p id="037b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这本笔记本将是一个教程，旨在帮助你熟悉图书馆的使用。最后，你将能够在你的特征中选择那些看起来对预测你的目标最重要的特征。这将使您能够构建具有更好可解释性的健壮的中型模型。</p><p id="8fb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果想跳过处理直接跳到结果，可以直接看一下结果<a class="ae kv" href="https://www.kaggle.com/louise2001/moa-feat-importance-rapids" rel="noopener ugc nofollow" target="_blank">这里</a>。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="87d3" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">第一步:熟悉cuDF</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="d710" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我导入所有必需的包，并加载数据。</p><p id="0111" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以注意到cuDF完全等同于pandas，除了它在GPU上做所有的事情:使用<em class="lz"> read_csv </em>将数据直接读取到GPU，你也可以在数据帧上尝试任何常见的操作，功能和语法都是相似的，正如你可以从我使用的<em class="lz"> merge </em>方法中看出的。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="a9a8" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">第二步:熟悉cuML</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="2624" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该函数旨在返回特征重要性度量。</p><p id="a1bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最初，我报告了对每个目标、每个特征执行的单变量逻辑回归的二元交叉熵损失(我总共有近18万个任务要做)。单变量分析是一种原始但相当可靠且广泛使用的方法，用于估计给定目标的特征重要性。它使你能够分离出给定模型的单独解释能力。</p><p id="21da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以注意到，cuML类(这里是<em class="lz"> LogisticRegression </em>)、函数(这里是<em class="lz"> log_loss </em>)和方法(这里是<em class="lz"> fit </em>或<em class="lz"> predict_proba </em>)也完全等同于你可能已经习惯了的sklearn类。</p><p id="7e84" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，我必须缩放输出(为了在或多或少难以预测的目标之间进行比较，利用特征的平均损失)和反转值，以获得更好的可解释性:实际上，您会期望特征重要性在估计该特征上的给定目标的损失时降低。对于这一步，我使用cuML <em class="lz"> MinMaxScaler </em>预处理类，它的工作方式与sklearn一样。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="aac7" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">第三步:解读</h1><p id="0f28" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">计算某个特性在所有目标上的平均重要性对于全面了解它对您的整体模型的重要性非常重要。</p><p id="06ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，我不确定在区分要保留的特性和要删除的特性时，您是否应该完全依赖这个指标:事实上，一个给定的特性可能对一个特定的目标具有非常高的解释能力，而对所有其他目标都不相关，因此即使它的平均重要性分数很低，保留它对该目标的最终模型质量也是决定性的。我们的目标是保留对所有目标都具有高平均解释能力的特征(平均重要性阈值)，或者对其中一些目标特别相关的特征(最大重要性阈值)。请随意使用阈值！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/c4541833a17c170ecc0c2a7cdf3078f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*90QESpl6A-HNGyahm1Y9fw.png"/></div></figure><p id="0a1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可能已经注意到了我对我的数据应用的小方法:因为它存储在GPU上，只是为了绘图的目的，我需要把它转换成cpu。例如，这相当于您在cuda计算过程结束时在PyTorch上执行的<em class="lz"> to_cpu() </em>。</p><p id="92d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于用所选阈值操作的特征选择的进一步数据分析得出以下结论:</p><ul class=""><li id="ba1d" class="na nb iq ky b kz la lc ld lf nc lj nd ln ne lr nf ng nh ni bi translated">平均而言，在所有目标上，满足<strong class="ky ir">和</strong>两个标准的特性比不满足任何一个标准的特性平均重要0.15倍。</li><li id="e892" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">平均而言，满足<strong class="ky ir">一个</strong>标准的特性在所有目标上的最大重要性比不满足任何标准的特性高0.19。</li></ul><p id="8431" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据我们的分析，这是一个相当令人放心的观察结果。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="f24c" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">第四步:结论</h1><p id="00a8" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">为了获得全局概述，我们可以比较两个子集上按目标划分的缩放特征重要性的热图，这两个子集是满足两个标准的特征和不满足任何标准的特征。很快就可以看出，第一张图要淡得多，单独的重要性更高。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/fbb4fa7ac2e7be9b82c1dc13dbd2831c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJrkAN4mrw4nsLWTkRDeqw.jpeg"/></div></div></figure><p id="288b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，您可以依赖于您选择的功能，并使用它们来构建一个更轻的模型，更容易运行，也更容易解释！</p></div></div>    
</body>
</html>