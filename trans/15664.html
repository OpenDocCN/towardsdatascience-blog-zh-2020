<html>
<head>
<title>Train Conversational AI in 3 lines of code with NeMo and Lightning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用尼莫和闪电用3行代码训练对话式人工智能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-conversational-ai-in-3-lines-of-code-with-nemo-and-lightning-a6088988ae37?source=collection_archive---------21-----------------------#2020-10-28">https://towardsdatascience.com/train-conversational-ai-in-3-lines-of-code-with-nemo-and-lightning-a6088988ae37?source=collection_archive---------21-----------------------#2020-10-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9203" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="e5fa" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用NeMo和Lightning大规模训练最先进的语音识别、NLP和TTS模型</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/20cd8761b32f922fa4f1ab8ddc34c054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FISI15V0aGUHZ79ezgowig.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="56ea" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae ma" href="https://github.com/NVIDIA/NeMo" rel="noopener ugc nofollow" target="_blank"> NeMo </a>(神经模块)是英伟达的一个强大框架，旨在轻松训练、构建和操纵最先进的对话式人工智能模型。NeMo模型可以在多GPU和多节点上训练，有或没有混合精度，只需3行代码。继续阅读，了解如何使用NeMo和<a class="ae ma" href="https://github.com/PyTorchLightning/pytorch-lightning" rel="noopener ugc nofollow" target="_blank"> Lightning </a>在多个GPU上训练端到端语音识别模型，以及如何根据自己的使用情况扩展NeMo模型，如在西班牙语音频数据上微调预训练的强大ASR模型。</p><p id="9942" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在本文中，我们将重点介绍NeMo中的一些优秀特性，在<a class="ae ma" href="http://In this article we covered some of the great out of the box features within NeMo, steps to build your own ASR model on LibriSpeech and fine-tuning to your own datasets across different languages." rel="noopener ugc nofollow" target="_blank"> LibriSpeech </a>上构建自己的ASR模型的步骤，以及如何跨不同语言在自己的数据集上微调模型。</p><h1 id="7a58" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">构建SOTA对话式人工智能</h1><p id="d676" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">NeMo提供了一个轻量级的包装器来开发跨不同领域的模型，特别是ASR(自动语音识别)、TTS(文本到语音)和NLP。NeMo开箱即用，提供从头开始训练流行模型的示例，如谷歌研究所发布的臭名昭著的<a class="ae ma" href="https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html" rel="noopener ugc nofollow" target="_blank">语音合成Tactotron2 </a>模型，以及微调预训练变压器模型(如<a class="ae ma" href="https://arxiv.org/abs/1909.08053" rel="noopener ugc nofollow" target="_blank"> Megatron-LM </a>)的能力，用于下游NLP任务，如文本分类和问题回答。</p><p id="ab98" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">NeMo还对各种语音识别模型提供现成的支持，提供预训练的模型以便于部署和微调，或者提供从零开始训练的能力，并且易于修改配置，我们将在下面详细讨论。</p><p id="4b14" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">它使研究人员能够扩展他们的实验规模，并在模型、数据集和训练程序的现有实现基础上进行构建，而不必担心缩放、模板代码或不必要的工程。</p><p id="bbb1" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">NeMo建立在<a class="ae ma" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>、<a class="ae ma" href="https://pytorchlightning.ai/" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning </a>和许多其他开源库的基础上，提供了许多其他突出的功能，例如:</p><ul class=""><li id="e2cb" class="my mz iq lg b lh li lk ll ln na lr nb lv nc lz nd ne nf ng bi translated">使用<a class="ae ma" href="https://pytorch.org/docs/stable/onnx.html" rel="noopener ugc nofollow" target="_blank"> ONNX </a>或<a class="ae ma" href="https://pytorch.org/docs/stable/jit.html" rel="noopener ugc nofollow" target="_blank"> PyTorch TorchScript </a>导出模型</li><li id="e466" class="my mz iq lg b lh nh lk ni ln nj lr nk lv nl lz nd ne nf ng bi translated">通过<a class="ae ma" href="https://developer.nvidia.com/tensorrt" rel="noopener ugc nofollow" target="_blank">tensort</a>进行优化，并使用<a class="ae ma" href="https://developer.nvidia.com/nvidia-jarvis" rel="noopener ugc nofollow" target="_blank"> NVIDIA Jarvis </a>进行部署</li><li id="7cc1" class="my mz iq lg b lh nh lk ni ln nj lr nk lv nl lz nd ne nf ng bi translated">在<a class="ae ma" href="https://ngc.nvidia.com/catalog/models?orderBy=modifiedDESC&amp;pageNumber=0&amp;query=nemo&amp;quickFilter=models&amp;filters=" rel="noopener ugc nofollow" target="_blank"> NGC </a>有大量SOTA预培训车型</li></ul><h1 id="ccd1" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">由闪电驱动</h1><p id="63ab" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">NeMo团队没有从头开始构建对多个GPU和多个节点的支持，而是决定使用<a class="ae ma" href="https://github.com/PyTorchLightning/pytorch-lightning" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning </a>来处理所有的工程细节。每个NeMo模型实际上都是一个<a class="ae ma" href="https://pytorch-lightning.readthedocs.io/en/stable/lightning_module.html" rel="noopener ugc nofollow" target="_blank">照明模块</a>。这使得NeMo团队可以专注于建立人工智能模型，并允许NeMo用户使用闪电训练器，它包括许多加快训练速度的功能。通过与PyTorch Lightning的紧密集成，NeMo保证可以在许多研究环境中运行，并允许研究人员专注于重要的事情。</p><h1 id="c623" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">大规模培训端到端ASR模型</h1><p id="9c2a" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">为了展示使用NeMo和Lightning来训练对话式人工智能是多么容易，我们将建立一个可以用来转录语音命令的end 2 end语音识别模型。我们将使用<a class="ae ma" href="https://arxiv.org/pdf/1910.10261.pdf" rel="noopener ugc nofollow" target="_blank"> QuartzNet </a>模型，这是一种用于E2E(端到端)语音识别的完全卷积架构，它带有预先训练的模型，在大约3300小时的音频上训练，在使用更少参数的同时超越了以前的卷积架构。在大规模部署模型时，模型参数的数量成为准确性的关键权衡因素，尤其是在流式语音识别至关重要的在线设置中，如语音助理命令。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/b0df1a6e391b41fdac8e8ccacd84488f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zPgtQ_Be0UKQfUrG"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">NVIDIA 的QuartzNet BxR架构</p></figure><p id="6845" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们使用<a class="ae ma" href="http://www.openslr.org/12/" rel="noopener ugc nofollow" target="_blank"> LibriSpeech </a>作为我们的训练数据，这是一本流行的有声读物，标签为dataset。NeMo带有许多预设的数据集脚本，用于下载和格式化数据，以进行训练、验证和测试，可以在<a class="ae ma" href="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/datasets.html" rel="noopener ugc nofollow" target="_blank">这里</a>看到。</p><p id="9c54" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们使用预设的QuartzNet配置文件定义模型配置，修改我们的数据输入以指向我们的数据集。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="423c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">训练我们的模型只需要3行代码:定义模型配置，初始化闪电训练器，然后训练！</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="5289" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了提高速度，您可以增加GPU的数量，并启用原生混合精度。两者都非常容易使用闪电训练器。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="ac1f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你可以利用所有的Lightning特性，比如<a class="ae ma" href="https://pytorch-lightning.readthedocs.io/en/stable/trainer.html" rel="noopener ugc nofollow" target="_blank">检查点和实验管理以及更多的</a>！关于NeMo中的ASR功能的互动视图，请查看<a class="ae ma" href="https://colab.research.google.com/github/NVIDIA/NeMo/blob/main/tutorials/asr/01_ASR_with_NeMo.ipynb#scrollTo=ABUDaC5Js7AW" rel="noopener ugc nofollow" target="_blank"> Google Colab。</a></p></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="1606" class="mb mc iq bd md me nw mg mh mi nx mk ml kf ny kg mn ki nz kj mp kl oa km mr ms bi translated">定制您的模型</h1><p id="d6c7" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">NeMo使得训练技术或模型改变的实验变得极其容易。假设我们想用Adam替换我们的优化器，并更新我们的学习率计划以使用预热退火。这两者都可以通过配置文件来完成，而不需要使用预先构建的NeMo模块来修改代码。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nn no l"/></div></figure></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="0b3c" class="mb mc iq bd md me nw mg mh mi nx mk ml kf ny kg mn ki nz kj mp kl oa km mr ms bi translated">利用低资源语言的迁移学习</h1><p id="2981" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">我们已经看到NVIDIA在最近的论文<a class="ae ma" href="https://arxiv.org/abs/2005.04290" rel="noopener ugc nofollow" target="_blank">中展示的在语音识别中应用迁移学习的令人印象深刻的结果。与从头开始训练相比，微调一个强大的预训练模型在收敛性和准确性方面显示出优势。</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ob"><img src="../Images/7ae281f310ba50a22c90f609dca55f27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vijXFlQF0hDnO180"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">NVIDIA<a class="ae ma" href="https://developer.nvidia.com/blog/jump-start-training-for-speech-recognition-models-with-nemo/" rel="noopener ugc nofollow" target="_blank">从零开始比较训练和微调预训练模型</a></p></figure><p id="05fa" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">NeMo使获得迁移学习的好处变得简单。下面我们使用我们预先训练的英语QuartzNet模型，并在<a class="ae ma" href="https://commonvoice.mozilla.org/" rel="noopener ugc nofollow" target="_blank">普通语音</a>西班牙语数据集上进行微调。我们更新了训练数据输入、词汇表和一些优化配置。我们让教练处理剩下的事情。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nn no l"/></div></figure></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="db8a" class="mb mc iq bd md me nw mg mh mi nx mk ml kf ny kg mn ki nz kj mp kl oa km mr ms bi translated">从尼莫开始</h1><p id="baf3" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">在本文中，我们介绍了NeMo的一些现成特性，在LibriSpeech上构建自己的ASR模型的步骤，以及跨不同语言对自己的数据集进行微调的步骤。</p><p id="bbec" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这里有大量的Google Colab教程可供选择，涵盖了NLP、语音识别和语音合成。你也可以在PyTorch Lightning docs <a class="ae ma" href="https://pytorch-lightning.readthedocs.io/en/stable/asr_tts.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到更多信息。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="oc no l"/></div></figure></div></div>    
</body>
</html>