<html>
<head>
<title>A Brief Survey of Time Series Classification Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时间序列分类算法综述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-brief-introduction-to-time-series-classification-algorithms-7b4284d31b97?source=collection_archive---------0-----------------------#2020-09-22">https://towardsdatascience.com/a-brief-introduction-to-time-series-classification-algorithms-7b4284d31b97?source=collection_archive---------0-----------------------#2020-09-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c61a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">专门为时间序列分类设计的专用算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/b933f7feab62105674bfb0f745ddc985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*mZKzIcVy4kl71eCT_lisVA@2x.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">由<a class="ae ku" href="https://pixabay.com/users/geralt-9301/" rel="noopener ugc nofollow" target="_blank">杰拉德</a>在<a class="ae ku" href="https://pixabay.com/illustrations/mechanics-gear-gears-blue-4595804/" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a></p></figure><p id="d483" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">时间序列机器学习的一个常见任务是<strong class="kx iu">分类。</strong>给定一组带有类标签的时间序列，是否可以训练一个模型来准确预测新时间序列的类？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lr"><img src="../Images/6fef2df2c4c993fe5fcf58e2a46b1cb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hsdUIyKLq5oAtz-CMePNKQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来源:<a class="ae ku" href="https://github.com/alan-turing-institute/sktime/blob/master/examples/02_classification_univariate.ipynb" rel="noopener ugc nofollow" target="_blank">用sktime进行单变量时间序列分类</a></p></figure><p id="87aa" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="lw">专门用于时间序列分类的算法有很多！</em>这意味着您不必将数据放入scikit-learn分类器中，也不必求助于深度学习来解决每个时间序列分类任务。</p><p id="73ae" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在本文中，我将介绍五类时间序列分类算法，并详细介绍具体的算法。在大量不同的数据集上，这些特定的算法已经显示出比基线分类器(KNN)平均执行得更好[1]。</p><ol class=""><li id="0d7c" class="lx ly it kx b ky kz lb lc le lz li ma lm mb lq mc md me mf bi translated">基于距离(具有动态时间弯曲的KNN)</li><li id="64b9" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">基于间隔(时间序列森林)</li><li id="e513" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">基于字典(BOSS，cBOSS)</li><li id="9412" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">基于频率(上升-类似时间序列森林，但具有其他功能)</li><li id="807b" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">基于shape let(shape let变换分类器)</li></ol><p id="d4de" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后，我简要介绍了如何选择合适的算法。</p><p id="a457" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">本文描述的算法已经在<code class="fe ml mm mn mo b"><a class="ae ku" href="https://github.com/alan-turing-institute/sktime" rel="noopener ugc nofollow" target="_blank">sktime</a></code> python包中实现。</p><div class="mp mq gp gr mr ms"><a rel="noopener follow" target="_blank" href="/sktime-a-unified-python-library-for-time-series-machine-learning-3c103c139a55"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">Sktime:用于时间序列机器学习的统一Python库</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">用于时间序列预测、分类和回归的“sklearn”</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">towardsdatascience.com</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng ko ms"/></div></div></a></div><h1 id="5c7f" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">为什么要为时间序列设计专用算法？</h1><p id="780a" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">在时间序列分类问题上，时间序列分类算法往往比表格分类器表现更好。</p><p id="523a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">时间序列分类的一个常见但有问题的解决方案是将每个时间点视为一个单独的特征，并直接应用标准学习算法(例如scikit-learn分类器)。在这种方法中，算法忽略数据的时间顺序中包含的信息。如果要素顺序被打乱，预测不会改变。</p><p id="8262" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">使用深度学习对时间序列进行分类也很常见。LSTMs和CNN能够挖掘时间序列的动态特征，因此获得了成功。然而，神经网络有一些挑战，使它们不适合许多分类任务:</p><ul class=""><li id="7308" class="lx ly it kx b ky kz lb lc le lz li ma lm mb lq oe md me mf bi translated">选择高效的架构</li><li id="fe7c" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq oe md me mf bi translated">超参数调谐</li><li id="fff3" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq oe md me mf bi translated">有限的数据(神经网络需要许多例子)</li><li id="381f" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq oe md me mf bi translated">训练缓慢</li></ul><p id="3584" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">尽管存在这些挑战，但确实存在用于时间序列分类的特定神经网络架构。这些已经在<a class="ae ku" href="https://github.com/sktime/sktime-dl" rel="noopener ugc nofollow" target="_blank"> sktime-dl </a> python包中实现了。</p><h1 id="ae40" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">时间序列分类的基本概念</h1><h2 id="4b5d" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">时间序列转换</h2><p id="4296" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated"><strong class="kx iu">许多时间序列特定算法是转换后的时间序列和常规分类算法</strong>的组合，例如scikit-learn中的算法。</p><p id="7e0c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">特征提取非常多样和复杂。</p><p id="0ab8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">可以全局地(在整个时间序列上)或者局部地(在规则间隔/箱、随机间隔、间隔的滑动窗口等等上)提取特征<strong class="kx iu">。</strong></p><p id="5bee" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">系列可以转换成<strong class="kx iu">原始</strong>值(如平均值、标准差、斜率)或其他<strong class="kx iu">系列</strong>(如傅立叶变换、拟合自回归系数系列)。</p><p id="ec64" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后，变换可以是一维的<strong class="kx iu">或多维的</strong>。</p><div class="mp mq gp gr mr ms"><a href="https://medium.com/towards-artificial-intelligence/highly-comparative-time-series-analysis-a-paper-review-5b51d14a291c" rel="noopener follow" target="_blank"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">高度比较的时间序列分析——一篇论文综述</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">用于比较、聚类、分类和注释的时间序列特征提取分析</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">medium.com</p></div></div><div class="nb l"><div class="or l nd ne nf nb ng ko ms"/></div></div></a></div><h2 id="2e4f" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">收缩的</h2><p id="a78a" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated"><em class="lw">收缩</em>是本文描述的大多数算法中使用的关键概念。</p><p id="d8e1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">简单来说，<strong class="kx iu">收缩限制了算法的运行时间</strong>。直到分配的时间到期，算法继续迭代以学习给定的任务。</p><h1 id="2702" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">基于距离的分类</h1><p id="d04e" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">这些分类器使用距离度量来确定类成员。</p><h2 id="7fdc" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">时间序列的k-最近邻(具有动态时间弯曲)</h2><p id="a645" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">流行的<a class="ae ku" href="https://scikit-learn.org/stable/modules/neighbors.html#classification" rel="noopener ugc nofollow" target="_blank"> k最近邻</a> (KNN)算法可以通过用<a class="ae ku" href="https://en.wikipedia.org/wiki/Dynamic_time_warping" rel="noopener ugc nofollow" target="_blank">动态时间弯曲</a> (DTW)度量代替欧几里德距离度量来适应时间序列。DTW测量在时间、速度或长度上可能不完全一致的两个序列之间的相似性。(点击<a class="ae ku" rel="noopener" target="_blank" href="/how-to-apply-k-means-clustering-to-time-series-data-28d04a8f7da3">此处</a>了解我对时间序列聚类的DTW的解释)。</p><p id="3629" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">KNN与DTW通常被用作评估时间序列分类算法的基准，因为它简单，稳健，不需要大量的超参数调整。</p><p id="deee" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">虽然KNN和DTW很有用，但需要大量的空间和时间来计算。在分类期间，KNN-DTW将每个对象与训练集中的所有其他对象进行比较。此外，KNN提供的关于为什么将一个系列归入某一类的信息有限。</p><p id="1739" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">KNN也可能在有噪声的序列中表现不佳——序列中的噪声可能盖过形状的细微差异，而形状的细微差异对于类别区分是有用的[4]。</p><h1 id="3fe0" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">区间分类器</h1><p id="81e1" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">这些分类器基于包含在系列的不同区间中的信息进行分类。</p><h2 id="ac9e" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">时间序列森林分类器</h2><p id="a839" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">时间序列森林(TSF)分类器使随机森林分类器适应序列数据。</p><ol class=""><li id="1255" class="lx ly it kx b ky kz lb lc le lz li ma lm mb lq mc md me mf bi translated">将序列分割成随机间隔，具有随机起始位置和随机长度。</li><li id="fe33" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">将每个区间的汇总特征(均值、标准差和斜率)提取到单个特征向量中。</li><li id="1275" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">在提取的特征上训练决策树。</li><li id="d87a" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">重复步骤1-3，直到完成所需数量的树或时间用完。</li></ol><p id="ef11" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">新系列是根据森林中所有树木的多数投票进行分类的。(在多数投票中，预测是由最多的树预测的类是森林的预测)。</p><p id="5b31" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">实验研究表明，时间序列森林可以胜过基线竞争者，例如具有动态时间扭曲的最近邻[1，7]。</p><p id="24c2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">时序森林的计算效率也很高。</p><p id="8d64" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后，时间序列森林是一个可解释的模型。时间特征重要性可以从时间序列森林中提取，如<a class="ae ku" href="https://github.com/alan-turing-institute/sktime/blob/master/examples/02_classification_univariate.ipynb" rel="noopener ugc nofollow" target="_blank"> sktime单变量时间序列分类演示</a>所示。</p><h1 id="7e0a" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">基于词典的分类</h1><p id="9623" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">基于字典的分类器首先将实值时间序列转换成离散的“单词”序列。然后基于提取的符号词的分布进行分类。</p><p id="cc60" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">字典分类器都使用相同的核心过程:长度为<code class="fe ml mm mn mo b">w</code>的滑动窗口在一系列中运行。对于每个窗口，数字序列被转换成长度为<code class="fe ml mm mn mo b">l</code>的“单词”。这个单词由<code class="fe ml mm mn mo b">α</code>可能的字母组成。</p><h2 id="7785" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">SFA符号包(BOSS)</h2><p id="fa76" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">使用<a class="ae ku" href="https://www.openproceedings.org/2012/conf/edbt/SchaferH12.pdf" rel="noopener ugc nofollow" target="_blank">符号傅立叶近似</a> (SFA)变换从序列中提取BOSS分类器的单词特征:</p><ol class=""><li id="4a2f" class="lx ly it kx b ky kz lb lc le lz li ma lm mb lq mc md me mf bi translated">计算窗口的<a class="ae ku" href="https://en.wikipedia.org/wiki/Fourier_transform" rel="noopener ugc nofollow" target="_blank">傅立叶变换</a>(如果发生归一化，则忽略第一项)</li><li id="29cf" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">使用<a class="ae ku" href="https://pyts.readthedocs.io/en/stable/auto_examples/approximation/plot_mcb.html#:~:text=The%20Multiple%20Coefficient%20Binning%20%28MCB%29%20algorithm%20bins%20continuous,series%20independently%2C%20MCB%20bins%20each%20time%20point%20independently." rel="noopener ugc nofollow" target="_blank">多系数宁滨</a> (MCB)将第一个<code class="fe ml mm mn mo b">l</code>傅立叶项离散成符号，形成一个“单词”。MCB是一种监督算法，它将连续的时间序列分成一系列字母。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi os"><img src="../Images/74cd6d802c4c1d48263d0774881453cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8oGH6ASQfBLjOGEs3ZbICQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated"><em class="ot">如不同位置的绿线所示，MCB独立于其他时间点对每个时间点进行分类。SAX是另一种宁滨系列算法，它独立地对每个时间序列进行分类。来源:</em> <a class="ae ku" href="https://pyts.readthedocs.io/en/stable/auto_examples/approximation/plot_mcb.html#:~:text=The%20Multiple%20Coefficient%20Binning%20%28MCB%29%20algorithm%20bins%20continuous,series%20independently%2C%20MCB%20bins%20each%20time%20point%20independently" rel="noopener ugc nofollow" target="_blank"> <em class="ot"> pyts文档</em> </a></p></figure><p id="23d8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当窗口滑动时，这些单词的字典被构建，记录每个单词的频率。如果同一个单词是由两个或两个以上的连续窗口产生的，那么这个单词只计算一次。当滑动窗口完成时，序列被转换成基于字典的直方图。</p><p id="5215" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后，任何分类器都可以根据从系列中提取的单词直方图进行训练。</p><h2 id="5390" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">老板乐团</h2><p id="732a" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">最初的BOSS算法实际上是先前描述的BOSS分类器的集合。BOSS集成在单个BOSS分类器的参数(<code class="fe ml mm mn mo b">l</code>、<code class="fe ml mm mn mo b">α</code>、<code class="fe ml mm mn mo b">w</code>和<code class="fe ml mm mn mo b">p</code>)之间进行网格搜索。(<code class="fe ml mm mn mo b">p</code>控制子系列是否规范化。)集成仅保留其准确度在最佳分类器的92%准确度内的成员。</p><p id="e098" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">BOSS集成使用最近邻算法作为其分类器。分类器使用一个定制的非对称距离函数:一个部分欧几里德距离，只包括测试实例的直方图中包含的单词。</p><p id="9c05" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">由于在大的预定义参数空间上搜索，BOSS会带来时间开销和内存使用不稳定的风险。</p><p id="0340" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">BOSS ensemble是<a class="ae ku" href="https://www.researchgate.net/profile/Anthony_Bagnall/publication/301856632_The_Great_Time_Series_Classification_Bake_Off_An_Experimental_Evaluation_of_Recently_Proposed_Algorithms_Extended_Version/links/579b580e08ae80bf6ea33d12.pdf" rel="noopener ugc nofollow" target="_blank">大型时间序列分类竞赛</a>论文【1】中最准确的基于字典的分类器。</p><h2 id="e83e" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">可承包老板</h2><p id="8413" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">cBOSS算法比BOSS快一个数量级。与BOSS相比，cBOSS在UCR分类档案库中的数据集上的准确性没有显著差异。</p><p id="75f2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">cBOSS不像BOSS那样在整个参数空间进行网格搜索，而是从参数空间随机采样，没有替换。然后，cBOSS对每个基本分类器的数据进行二次采样。</p><p id="505a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">cBOSS通过保留固定数量的基分类器，而不是保留给定性能阈值以上的所有分类器，来提高BOSS的内存需求。最后，cBOSS根据训练精度指数加权每个基本分类器的贡献。</p><h1 id="aab1" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">基于频率的</h1><p id="6e50" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">基于频率的分类器依赖于从序列中提取的频率数据。</p><h2 id="7d43" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">随机间隔光谱集合</h2><p id="975d" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">随机区间光谱集合，或上升，是时间序列森林的一个流行的变种。</p><p id="34e9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">RISE在两个方面不同于时序森林。首先，它对每棵树使用一个时间序列间隔。第二，使用从系列中提取的光谱特征而不是汇总统计来训练它。</p><p id="028b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">RISE使用几个串到串特征提取变压器，包括:</p><ul class=""><li id="3816" class="lx ly it kx b ky kz lb lc le lz li ma lm mb lq oe md me mf bi translated">拟合自回归系数</li><li id="fc82" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq oe md me mf bi translated">估计的自相关系数</li><li id="5c81" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq oe md me mf bi translated">功率谱系数(傅立叶变换的系数)</li></ul><p id="a1ab" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">上升算法很简单:</p><ol class=""><li id="5f71" class="lx ly it kx b ky kz lb lc le lz li ma lm mb lq mc md me mf bi translated">选择一个系列的随机间隔(长度是2的幂)。(对于第一棵树，使用整个系列)</li><li id="bfa0" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">对于每个序列的相同间隔，应用序列到序列特征提取转换器(自回归系数、自相关系数和功率谱系数)</li><li id="1ee2" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">通过连接提取的特征来形成新的训练集</li><li id="91a3" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">训练决策树分类器</li><li id="0add" class="lx ly it kx b ky mg lb mh le mi li mj lm mk lq mc md me mf bi translated">合奏1-4</li></ol><p id="9d67" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">类别概率按基本分类器投票的比例计算。RISE通过创建一个自适应模型来控制构建单棵树的运行时间。这对于长序列(如音频)很重要，因为很大的间隔意味着很少的树。</p><h1 id="8653" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">基于Shapelet的分类器</h1><p id="2e60" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">Shapelets是代表一个类的时间序列的子序列或小的子形状。它们可用于检测“同一类别内系列之间的独立于相位的局部相似性”[1]。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/22bc88f397526395f0ca2839b9bceed2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*BHozGD5HQYSu0xBbHkSHxw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">蓝线是原始时间序列。红线是从中提取的shapelet。从[4]修改的图像。</p></figure><p id="9f59" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">单个shapelet是时间序列中的一个间隔。任何序列中的间隔都可以被枚举。例如，<code class="fe ml mm mn mo b">[1,2,3,4]</code>有5个区间:<code class="fe ml mm mn mo b">[1,2]</code>、<code class="fe ml mm mn mo b">[2,3]</code>、<code class="fe ml mm mn mo b">[3,4]</code>、<code class="fe ml mm mn mo b">[1,2,3]</code>、<code class="fe ml mm mn mo b">[2,3,4]</code>。</p><p id="0026" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">基于Shapelet的分类器搜索具有辨别能力的shape let。</p><p id="e913" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">然后，这些shapelet特征可用于解释基于shapelet的分类器-某些shape let的存在使一个类比另一个类更有可能。</p><h2 id="f5e9" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">Shapelet变换分类器</h2><p id="add9" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">在Shapelet变换分类器中，该算法首先识别数据集中的前<em class="lw"> k个</em>shape let。</p><p id="a650" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">接下来，计算新数据集的<em class="lw"> k </em>个特征。每个特征被计算为系列到每个<em class="lw">k s</em>shapelet的距离，每个shape let一列。</p><p id="19cc" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后，任何基于矢量的分类算法都可以应用于shapelet变换的数据集。在[1]中，使用了加权集成分类器。在[2]中，作者仅使用了一个<a class="ae ku" href="https://www.researchgate.net/publication/6806976_Rotation_Forest_A_New_Classifier_Ensemble_Method" rel="noopener ugc nofollow" target="_blank">旋转森林</a>分类器，这是一个基于树的集成，在PCA变换的特征子集上构建每棵树[5]。<strong class="kx iu">平均来说，对于具有连续特征的问题，旋转森林是最好的分类器，如图</strong><a class="ae ku" href="https://arxiv.org/abs/1809.06705" rel="noopener ugc nofollow" target="_blank"><strong class="kx iu">【6】</strong></a><strong class="kx iu">。</strong></p><p id="61b6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在<code class="fe ml mm mn mo b"><a class="ae ku" href="https://github.com/alan-turing-institute/sktime" rel="noopener ugc nofollow" target="_blank">sktime</a></code>中，默认使用随机森林分类器(500棵树)，因为python中还没有旋转森林[8]。</p><p id="3676" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="lw">算法如何识别和选择shapelets？</em></p><p id="2585" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在<code class="fe ml mm mn mo b">sktime</code>中，shapelet搜索过程不会完全枚举和评估所有可能的shape let。相反，它随机搜索shapelets进行评估。</p><p id="cf42" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">根据信息增益来评估所考虑的每个shapelet。保留最强的非重叠小形状。</p><p id="ef1c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">您可以指定在执行shapelet变换之前搜索shape let的时间。<code class="fe ml mm mn mo b">sktime</code>的默认时间是300分钟。</p><h1 id="5e02" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">集成分类器</h1><h2 id="64a3" class="of ni it bd nj og oh dn nn oi oj dp nr le ok ol nt li om on nv lm oo op nx oq bi translated">蜂巢</h2><p id="6377" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">基于变换的集成的分层投票集合(HIVE-COTE)是建立在前面讨论的分类器上的元集成。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ov"><img src="../Images/6567dca1df9069517c0994a6e2ebd236.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NpdcQ7Rh4ghXFMPubSrNzg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">" HIVE-COTE 1.0的系综结构概述."</p></figure><p id="65ac" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">HIVE-COTE预测是其成员生成的预测的加权平均值:shapelet转换分类器、BOSS、时序森林和RISE。</p><p id="cb41" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">每个子分类器估计每个类别的概率。控制单元然后组合这些概率(CAPWE)。权重被分配为在训练数据上找到的分类器的相对估计质量。</p><h1 id="d647" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">使用哪个分类器？</h1><p id="c029" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">选择时间序列分类器时有三个主要考虑因素:预测精度、时间/内存复杂性和数据表示。</p><p id="ad7e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在没有具体数据信息的情况下，从<a class="ae ku" href="https://www.sktime.org/en/latest/examples/rocket.html" rel="noopener ugc nofollow" target="_blank"> <em class="lw">火箭</em> </a>或<em class="lw">蜂巢</em>开始。(ROCKET是一个简单的线性分类器，基于随机卷积核——随机长度、权重、偏差、膨胀和填充)。[2]的作者认为“在没有相反的专家知识的情况下，最准确的算法设计是集成基于不同表示的分类器。”平均来说，ROCKET并不比HIVE-COTE差，而且要快得多。</p><div class="mp mq gp gr mr ms"><a href="https://link.medium.com/qYcaC7lL69" rel="noopener follow" target="_blank"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">ROCKET:快速准确的时间序列分类</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">“时间序列分类的任务可以被认为是学习或检测信号或模式…</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">link.medium.com</p></div></div><div class="nb l"><div class="ow l nd ne nf nb ng ko ms"/></div></div></a></div><p id="3e97" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="lw">当最佳特征可能是一系列中相位无关模式的存在或不存在时，基于Shapelet的分类器</em>会更好。</p><p id="bba4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当您可以使用模式的频率进行区分时，基于字典的<em class="lw"> (BOSS) </em>或基于频率的<em class="lw"> (RISE) </em>分类器会更好。</p><h1 id="ac76" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">最后一句话</h1><p id="6884" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">如果您喜欢这篇文章，请关注我，了解更多关于数据科学主题的内容！我计划继续撰写关于时间序列分类、聚类和回归的文章。</p><div class="mp mq gp gr mr ms"><a href="https://alexandra-amidon.medium.com/membership" rel="noopener follow" target="_blank"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">阅读亚历山德拉·阿米登(以及媒体上成千上万的其他作家)的每一个故事</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">alexandra-amidon.medium.com</p></div></div></div></a></div><p id="6c93" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">感谢Markus Loning对本文的反馈，感谢Anthony Bagnall对模型选择的指导。</p><h1 id="fa0b" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">参考</h1><p id="889d" class="pw-post-body-paragraph kv kw it kx b ky nz ju la lb oa jx ld le ob lg lh li oc lk ll lm od lo lp lq im bi translated">[1] <a class="ae ku" href="https://www.researchgate.net/profile/Anthony_Bagnall/publication/301856632_The_Great_Time_Series_Classification_Bake_Off_An_Experimental_Evaluation_of_Recently_Proposed_Algorithms_Extended_Version/links/579b580e08ae80bf6ea33d12.pdf" rel="noopener ugc nofollow" target="_blank"> Bagnall，Anthony等人，“伟大的时间序列分类烘焙:对最近算法进展的回顾和实验评估。”数据挖掘与知识发现31.3(2017):606–660。</a>还有</p><p id="f1b8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">[2] Bagnall，Anthony，等.<a class="ae ku" href="https://arxiv.org/abs/2004.06069" rel="noopener ugc nofollow" target="_blank">两个工具包的故事，报告之三:关于HIVE-COTE v1.0的使用和性能.</a>《2019</p><p id="8c5d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">[3] <a class="ae ku" href="https://arxiv.org/pdf/1809.04356" rel="noopener ugc nofollow" target="_blank"> Fawaz，Hassan Ismail等，“时间序列分类的深度学习:综述”数据挖掘与知识发现33.4(2019):917–963。</a></p><p id="739b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">[4] <a class="ae ku" href="https://core.ac.uk/download/pdf/81784396.pdf" rel="noopener ugc nofollow" target="_blank"> L .叶和e .基奥。时间序列shapelets:一种允许精确、可解释和快速分类的新技术。数据挖掘和知识发现，22(1–2):149–182，2011。</a></p><p id="eb82" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">[5] <a class="ae ku" href="https://www.researchgate.net/publication/6806976_Rotation_Forest_A_New_Classifier_Ensemble_Method" rel="noopener ugc nofollow" target="_blank"> Rodriguez，J，等.旋转森林:一种新的分类器集成方法。2006年11月IEEE模式分析与机器智能汇刊28(10):1619–30。DOI: 10.1109</a></p><p id="c3a5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">[6] <a class="ae ku" href="https://arxiv.org/abs/1809.06705" rel="noopener ugc nofollow" target="_blank"> Bagnall，Anthony等，“旋转森林是具有连续特征问题的最佳分类器吗？”2018.arXiv: 1809.06705。</a></p><p id="e472" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">[7]邓，H，等.<a class="ae ku" href="https://arxiv.org/abs/1302.2277" rel="noopener ugc nofollow" target="_blank">一种用于分类和特征提取的时间序列森林</a>信息科学239:142–153(2013)。</p><p id="6706" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">[8] Bagnall，Anthony等.“<a class="ae ku" href="https://arxiv.org/pdf/1909.05738.pdf" rel="noopener ugc nofollow" target="_blank">两个工具包的故事，报告第一个:对时间序列分类算法的正确性和效率进行基准测试。</a>“2019。</p><p id="fb8d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">[9] Dempster A，Petitjean F，Webb GI (2019) <a class="ae ku" href="https://arxiv.org/pdf/1910.13051.pdf" rel="noopener ugc nofollow" target="_blank"> ROCKET:使用随机卷积核的异常快速和准确的时间序列分类</a>。<a class="ae ku" href="https://arxiv.org/abs/1910.13051" rel="noopener ugc nofollow" target="_blank"> arXiv:1910.13051 </a></p><p id="8922" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><a class="ae ku" href="https://sktime.org/examples/dictionary_based_classification.html" rel="noopener ugc nofollow" target="_blank">sk time中基于字典的时间序列分类</a></p><p id="209c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">sktime的<a class="ae ku" href="https://github.com/alan-turing-institute/sktime/blob/master/examples/02_classification_univariate.ipynb" rel="noopener ugc nofollow" target="_blank">单变量时间序列分类教程</a></p></div></div>    
</body>
</html>