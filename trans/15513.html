<html>
<head>
<title>The Upper Confidence Bound (UCB) Bandit Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">置信上限(UCB) Bandit算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f?source=collection_archive---------3-----------------------#2020-10-26">https://towardsdatascience.com/the-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f?source=collection_archive---------3-----------------------#2020-10-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ab37" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a>，<a class="ae ep" href="https://towardsdatascience.com/tagged/baby-robot-guide" rel="noopener" target="_blank">一个婴儿机器人的强化学习指南</a></h2><div class=""/><div class=""><h2 id="018c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">多武装匪徒:第4部分</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6b1ed5855f315cd863421a374c76fb78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5EN3RNUburJPQrZY"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@artmatters?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿图尔·马托斯扬</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi li"><img src="../Images/5b3a6c07fb3fc34b11b265f9ccf4e249.png" data-original-src="https://miro.medium.com/v2/resize:fit:128/1*B1k0BRVMwLxzypQKmCHH1A.gif"/></div></figure><h1 id="e88a" class="lj lk it bd ll lm ln lo lp lq lr ls lt ki lu kj lv kl lw km lx ko ly kp lz ma bi translated">概观</h1><p id="90e7" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">这是我们关于多股武装匪徒系列的第四部分，我们将看看可以用来解决匪徒问题的置信上限(UCB)算法。</p><p id="b458" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">如果您还不熟悉bandit问题及其术语，您可能想先看看本系列的前几部分，如下所示:</p><ul class=""><li id="14f9" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw nh ni nj nk bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/multi-armed-bandits-part-1-b8d33ab80697"> <strong class="md jd">第1部分:数学框架和术语</strong></a><strong class="md jd"><br/></strong>——入门所需的全部基础信息</li><li id="320b" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/multi-armed-bandits-part-2-5834cb7aba4b"> <strong class="md jd">第二部分:Bandit框架</strong> </a> <br/> <em class="nq"> - </em>代码和测试框架的描述</li><li id="b92d" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/bandit-algorithms-34fd7890cb18"> <strong class="md jd">第三部分:土匪算法</strong></a><br/><em class="nq">-</em><a class="ae lh" rel="noopener" target="_blank" href="/bandit-algorithms-34fd7890cb18#d7a7"><em class="nq">贪婪算法</em></a><em class="nq"><br/>-</em><a class="ae lh" rel="noopener" target="_blank" href="/bandit-algorithms-34fd7890cb18#1519"><em class="nq">乐观-贪婪算法</em></a><em class="nq"><br/>-</em><a class="ae lh" rel="noopener" target="_blank" href="/bandit-algorithms-34fd7890cb18#0145"><em class="nq">ε-贪婪算法(ε-贪婪)</em></a><em class="nq"><br/>-</em><a class="ae lh" rel="noopener" target="_blank" href="/bandit-algorithms-34fd7890cb18#b390"><em class="nq"/></a></li></ul></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><p id="0a4d" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">bandit算法和测试框架的所有代码都可以在github上找到:<a class="ae lh" href="https://github.com/WhatIThinkAbout/BabyRobot/tree/master/Multi_Armed_Bandits" rel="noopener ugc nofollow" target="_blank"> Multi_Armed_Bandits </a></p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="f3fa" class="lj lk it bd ll lm ny lo lp lq nz ls lt ki oa kj lv kl ob km lx ko oc kp lz ma bi translated">概述</h1><blockquote class="od oe of"><p id="13d4" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated">机器人宝宝在商场走失。利用强化学习，我们想帮助他找到回到妈妈身边的路。然而，在他开始寻找她之前，他需要从一组电源插座充电，每个插座的电量略有不同。</p><p id="c611" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated">使用多臂强盗问题中的策略，我们需要在最短的时间内找到最好的插座，让机器人宝宝充电上路。</p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/16e75f0705fe5eef9cff8d9119a01d99.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ZQ3iLniVpZowr9UVByiEnQ.png"/></div></figure><blockquote class="od oe of"><p id="18c3" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated">机器人宝宝进入了一个充电室，里面有5个不同的电源插座。每个插座返回的电荷数量略有不同。我们希望在最短的时间内给机器人宝宝充电，所以我们需要找到最好的插座，然后使用它，直到充电完成。</p><p id="e26e" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated">这和多臂强盗问题是一样的，除了我们不是在找一个能给出最好回报的吃角子老虎机，而是在找一个能给出最多电量的电源插座。</p></blockquote></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/64b6341261c438f6e2a0301966e3afe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/1*et2_r7_Vah4d6TxMO9G5tA.gif"/></div></figure><h1 id="1b96" class="lj lk it bd ll lm ln lo lp lq lr ls lt ki lu kj lv kl lw km lx ko ly kp lz ma bi translated">介绍</h1><p id="0b71" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">在电源插座问题中，我们试图在最短的时间内获得最多的电量，我们已经看到，在探索、寻找最佳插座所花费的时间和利用目前回报最佳的插座所花费的时间之间存在权衡。如果我们花太长时间探索，那么我们可能会错过使用已经显示出高回报的插座。或者，如果我们只是利用性能良好的套接字，那么我们可能找不到最佳套接字，并可能错过获得最大可能回报的机会。</p><p id="6cde" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">显然，最好的方法是每次都选择最好的插座，这就是所谓的<em class="nq">最优策略</em>。同样显而易见的是，这种方法实际上并不实用，因为您最初并不知道哪个插座是最好的。如果你要找到最好的一个，就必须花一些时间去研究套接字的性能，因此不可能总是选择最好的动作。</p><p id="a6a2" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">最优策略虽然只是理论上的，但可以用来评估其他策略，看它们有多接近最优。最优策略所能获得的回报与测试中的策略实际获得的回报之间的差额被称为<strong class="md jd"> <em class="nq">后悔</em> </strong>。在这种情况下，回报是来自插座的电量，策略是用于选择要尝试的插座的方法或策略。</p><p id="9af0" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">正如我们已经看到的，<a class="ae lh" rel="noopener" target="_blank" href="/bandit-algorithms-34fd7890cb18#19ae">ε-贪婪有线性后悔</a>。它会继续探索所有动作的集合，即使它已经获得了足够的知识来知道这些动作中哪些是不好的动作。</p><p id="885f" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">从最大化总回报的角度来看，更好的方法是将一段时间内的抽样限制在表现最佳的行动上。这正是置信上限(UCB)策略所采用的方法。</p><h1 id="763d" class="lj lk it bd ll lm ln lo lp lq lr ls lt ki lu kj lv kl lw km lx ko ly kp lz ma bi translated">置信上限(UCB)算法</h1><p id="0878" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">UCB算法不是通过简单地选择任意动作来执行探索，而是随着它收集更多的环境知识来改变它的探索-利用平衡。它从主要集中于探索，当尝试最少的行动是首选时，转向集中于开发，选择估计回报最高的行动。</p><p id="4ce6" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">对于UCB，<em class="nq"> Aₜ'，</em>在时间步长<em class="nq"> t </em>选择的动作由下式给出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/1b3b534b8085df5319fee2289bb28997.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*wcizZuQ3W7_O6211deq65A.png"/></div></figure><p id="d427" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">哪里；</p><ul class=""><li id="82ab" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw nh ni nj nk bi translated"><em class="nq"> Qₜ(a)是在时间步“t”的动作“a”的估计值。</em></li><li id="4f29" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><em class="nq"> Nₜ(a)是在时间‘t’之前已经选择动作‘a’的次数。</em></li><li id="99de" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><em class="nq">‘c’是控制探索水平的置信度值。</em></li></ul><p id="9545" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">UCB公式可以认为是由两个不同的部分组成的:</p><p id="4b78" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><strong class="md jd"> <em class="nq">剥削:</em> </strong></p><ul class=""><li id="cac1" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw nh ni nj nk bi translated"><em class="nq"> Qₜ(a) </em>代表等式中的剥削部分。UCB基于“<strong class="md jd"> <em class="nq">对不确定的事实保持乐观</em> </strong>”的原则，这基本上意味着如果你不知道哪个行动是最好的，那么选择一个目前看起来是最好的。单独考虑这一半的等式将会做到这一点:目前具有最高估计回报的行动将是所选择的行动。</li></ul><p id="c987" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><strong class="md jd"> <em class="nq">探索:</em> </strong></p><ul class=""><li id="4c5e" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw nh ni nj nk bi translated">等式的后半部分增加了探索，探索的程度由超参数'<em class="nq"> c </em>'控制。实际上，等式的这一部分为行动的回报估计提供了不确定性的度量。</li><li id="bac2" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">如果一个动作没有经常尝试，或者根本没有尝试过，那么<em class="nq"> Nₜ(a) </em>就会变小。因此，不确定项将会很大，使得这个动作更有可能被选择。每当采取一项行动时，我们对它的估计就变得更有信心。在这种情况下，<em class="nq"> Nₜ(a) </em>增加，因此不确定项减少，使得该动作不太可能被选择作为探索的结果(尽管由于开发项，它仍可能被选择为具有最高值的动作)。</li><li id="42d9" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">当没有选择动作时，由于分子中的对数函数，不确定性项将缓慢增长。然而，每次选择该动作时，由于<em class="nq">【nₜ(a】</em>呈线性增加，不确定性将迅速缩小。因此，对于不经常选择的行动，探索期会更长，因为对其回报的估计存在不确定性。</li><li id="c513" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">随着时间的推移，探索项逐渐减少(因为as ' <em class="nq"> n </em>'趋于无穷大<em class="nq"> log n/n </em>趋于零)，直到最终仅基于开发项选择动作。</li></ul></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="7868" class="lj lk it bd ll lm ny lo lp lq nz ls lt ki oa kj lv kl ob km lx ko oc kp lz ma bi translated">UCB实施</h1><p id="c8b6" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">为了研究UCB算法的性能，我们将在测试系统中添加另一个套接字类。这个测试系统的全部细节在本系列的第2部分中有描述，所有的代码都可以在t 2的github库中找到。</p><p id="debd" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">UCB插座需要稍微修改基本的电源插座类，以增加它用来评估插座的度量的不确定性。因此'<em class="nq"> sample </em>'函数现在返回估计的平均回报和不确定性值之和，这是作为套接字被尝试的次数和当前时间步长的函数来计算的。</p><p id="0e43" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">套接字测试器类恢复为标准套接字测试器，仅基于从其样本函数返回最大值的套接字来选择套接字(即，不再需要ε-贪婪算法的随机采样)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="om on l"/></div></figure></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="3971" class="lj lk it bd ll lm ny lo lp lq nz ls lt ki oa kj lv kl ob km lx ko oc kp lz ma bi translated">UCB分析</h1><p id="55c0" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">使用我们的测试系统，我们可以分析UCB算法的性能。为了简化比较，我们只从我们的标准套件中选取了前2个插座。这两个插座的平均奖励值分别为6秒和4秒。在下图中可以清楚地看到每个勘探和开采术语的相对贡献。</p><p id="8427" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">这里需要注意的主要事项是:</p><ul class=""><li id="3d28" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw nh ni nj nk bi translated">每个条形的总高度代表总UCB值。因此，由于在每个时间步，我们都在选择给出最大UCB值的插座(这就是公式中的<em class="nq"> argmax </em>所做的)，具有最高条的插座将是被选择的插座。<br/>每个条形顶部给出的数字是该插座被选择的次数。因此，您可以看到，如果该插座在前一时间步中具有最高的杆，该值将会增加。</li><li id="3a3a" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">条形的阴影部分表示每个插座的实际输出的估计值(其<em class="nq"> Q </em>值)。随着时间的推移，这个估计收敛于每个插座的真实平均输出。因此，socket 1的<em class="nq"> Q </em>值(黄色阴影条)趋向于其真实输出6，socket 2的<em class="nq"> Q </em>值趋向于其真实平均值4。</li><li id="3902" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">每个条形的实线部分代表等式的探索部分。当一个插座被使用时，我们对它的真实输出变得更加确定，因此棒的实心部分将减小尺寸。另一方面，当一个套接字没有被测试时，我们变得不太确定它的输出，因此探索价值将开始增加。<br/>因此，在下图中，我们可以看到当socket 2未被选中时，socket 2的探索期限(由条形的绿色实线部分表示)如何逐渐增加，直到最终导致条形的总大小大于socket 1的总大小，此时，socket 2被选中。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/d9b5ee4d9f2f0604f2df513b170188f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eBnCApMHWi70OU8eLEPOYg.png"/></div></div></figure><blockquote class="od oe of"><p id="8326" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated"><strong class="md jd">对UCB图表的深入分析</strong></p><p id="d5f2" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated">从UCB图表中进一步观察到的一些情况如下:</p><p id="2f8f" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated">*如果尚未尝试套接字，则将套接字不确定性值设置为无穷大，导致执行初始启动回合，其中每个动作尝试一次以获得其初始值。当还没有尝试动作并且Nₜ(a等于零时，这就避免了探索项中被零除的错误。显然，这只适用于当可能的动作“k”比时间步长“<em class="it"> t </em>”少时，否则就没有足够的时间去尝试每一个动作。</p><p id="b35e" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated">*由于启动循环，图表从时间步长2开始。每个插座被选择的次数由每个栏顶部的数字显示。因此，在时间步骤2，可以看到每个插座已经被选择了一次。因为每个插座被尝试了相同的次数，所以不确定项的贡献对于每个插座是相同的。然而，由于其较大的回报估计“Q”，套接字1具有最大的总UCB值，因此被<em class="it"> argmax </em>函数选择。</p><p id="077c" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated">*在时间步长3，socket 1是在前一时间步长选择的socket，因此它被尝试的次数计数增加到2。结果，这个插座的不确定性项缩小了，所以可以看到蓝色实线的尺寸减小了。阴影黄色条也减少了，这是因为该插座已经被采样，并且形成了对真实插座回报的更好估计。<br/>另一方面，socket 2没有被选中，所以它的奖励估计值保持不变。它被选择的次数也保持不变，而时间步长的数量增加，因此其不确定项的大小增加，因此可以看到绿色实线变大。<br/>然而，套接字1的UCB项的总大小仍然大于套接字2的大小，因此再次选择了套接字。</p><p id="9676" class="mb mc nq md b me mx kd mg mh my kg mj og mz mm mn oh na mq mr oi nb mu mv mw im bi translated">*最终，在时间步骤5，套接字2的不确定性项增加到足以使其总UCB值大于套接字1的值，因此套接字被选中。一旦发生这种情况，它的估计回报值更接近真实的平均回报，它的不确定性项缩小，整个过程重新开始。</p></blockquote><h1 id="ad17" class="lj lk it bd ll lm ln lo lp lq lr ls lt ki lu kj lv kl lw km lx ko ly kp lz ma bi translated">置信度值“c”</h1><p id="75b1" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">UCB算法在一定置信值范围内的行为如下所示。置信度参数控制探索的级别。在我们简单的电源插座实验中，实际上可以看到，探索程度越高，平均总回报越低。这是因为每个套接字具有不同的值和有限范围的可能值，使得其他套接字不太可能生成相同范围内的值。</p><p id="d994" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">结果，在我们的简单实验中，看起来探索实际上是不必要的。在初始启动步骤之后，UCB算法已经锁定了最佳插座，并且当它能够利用这一知识时产生最佳结果。增加置信度参数的值会急剧降低平均总回报，并且这种降低会持续下去，直到算法变得不比随机搜索更好。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi op"><img src="../Images/30579689df8a9b6d39cba794e438a15e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tbs_GXiq8wu-E5lij5lpZA.png"/></div></div></figure><p id="a1cb" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">随着置信水平的增加，对平均总报酬的变化的更仔细的检查如下所示。这里可以看出，平均总报酬确实略有增加，从置信参数为零到大约0.6的值，之后迅速下降。所以需要少量的探索来获得最好的结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/ace3530300febcbcd1bf401d8ad1abcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*CR7ET4IKgx84LcB2A3Iflg.png"/></div></figure><p id="904d" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">在置信度参数设置为0.6(给出最大平均总回报的值，如上所示)的情况下，分析每个插座被选择的频率，给出如下图。这里可以看出，在初始启动期间，如果还没有尝试，当插座的不确定性被设置为无穷大时，在前5个时间步长期间，每个插座恰好被选择一次。在这一点之后，最佳插座(插座4)已经被识别为最佳插座，因此被选择用于几乎所有剩余的试验。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/0bce77f7bbd86c4f988489fffc1b269b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JNlmwDKMITRYolBqUAHAww.png"/></div></div></figure></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="4034" class="lj lk it bd ll lm ny lo lp lq nz ls lt ki oa kj lv kl ob km lx ko oc kp lz ma bi translated">UCB后悔了</h1><p id="a364" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">由于最佳行动被迅速确定，并且仅在其他行动具有高度不确定性时才尝试，UCB方法显示出比ε-贪婪方法低得多的后悔水平。</p><p id="0870" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">从下面的图表中可以看出，最佳回报和实际回报几乎是一样的(以至于实际回报被最佳回报所掩盖)，而遗憾几乎是持平的。</p><p id="16c7" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">绝大多数的遗憾发生在最初的启动过程中，每个套接字都被尝试一次以得到它的第一个估计值。事实上，已经表明UCB的预期累积遗憾在总时间步数中是对数的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/476ec7cba24c92e5e1f82b5d2afe747a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Caff9ue_ByY6QFF6Q2gWwA.png"/></div></div></figure><p id="055c" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">要深入了解UCB的遗憾和UCB的总体情况，请查阅以下资源:</p><ul class=""><li id="09fb" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw nh ni nj nk bi translated">Tor Lattimore和Csaba Szepesvari的关于强盗算法的 <a class="ae lh" href="https://banditalgs.com/2016/09/18/the-upper-confidence-bound-algorithm/" rel="noopener ugc nofollow" target="_blank"> <em class="nq">书籍和网站</em> </a></li><li id="c92a" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><em class="nq">赖和Robbins关于算法的开创性论文:</em> <a class="ae lh" href="http://dx.doi.org/10.1016/0196-8858(85)90002-8" rel="noopener ugc nofollow" target="_blank"> <em class="nq">渐近有效的自适应分配规则</em> </a> <em class="nq">。</em></li></ul></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="3e89" class="lj lk it bd ll lm ny lo lp lq nz ls lt ki oa kj lv kl ob km lx ko oc kp lz ma bi translated">摘要</h1><p id="1120" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">在诸如插座选择或多臂强盗的问题中，当面临如何在寻找给出最佳回报的动作和利用已经发现的动作之间取得平衡的困境时，使用可以修改探索和利用水平的方法是重要的。</p><p id="eaa2" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">正如我们看到的ε-贪婪算法，它只是保持一个恒定的探索水平，随着时间的推移继续探索所有动作的集合。因此，它有线性遗憾。它所获得的回报与最大可能回报之间的差异会随着时间的推移而不断增加。</p><p id="8c96" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">另一方面，置信上限(UCB)算法修改了它的探索和开发级别。最初，当它对可用的动作知之甚少，并且对要采取的最佳动作的信心较低时，它的等式的探索部分使它搜索所有可能动作的集合。</p><p id="9741" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">随着探索的进展，对每个行动所给予的回报会有更好的估计。因此，探索的程度可以降低，已经发现的好的行动的使用可以增加。算法的焦点逐渐从探索转向有利于开发。随着时间的推移，通过改变这种平衡，UCB算法减少了它的遗憾，因此，能够实现比ε-贪婪算法低得多的遗憾水平。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><p id="fcf3" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">在下一部分中，我们将研究汤普森取样，这是一种平衡勘探和开发的更复杂的方法。使用这个，我们将得到婴儿机器人充电，并准备在几乎没有时间！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi li"><img src="../Images/5b3a6c07fb3fc34b11b265f9ccf4e249.png" data-original-src="https://miro.medium.com/v2/resize:fit:128/1*B1k0BRVMwLxzypQKmCHH1A.gif"/></div></figure></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><pre class="ks kt ku kv gt os ot ou ov aw ow bi"><span id="75a8" class="ox lk it ot b gy oy oz l pa pb"><strong class="ot jd">&lt; Part 3: </strong><a class="ae lh" rel="noopener" target="_blank" href="/bandit-algorithms-34fd7890cb18"><strong class="ot jd">Bandit Algorithms</strong></a><strong class="ot jd">              Part 5: </strong><a class="ae lh" rel="noopener" target="_blank" href="/thompson-sampling-fc28817eacb8"><strong class="ot jd">Thompson Sampling</strong></a><strong class="ot jd"> &gt;</strong></span></pre></div></div>    
</body>
</html>