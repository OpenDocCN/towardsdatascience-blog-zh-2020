<html>
<head>
<title>The magic behind Ensemble Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集成学习背后的魔力</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-magic-behind-ensemble-learning-569be80fbab4?source=collection_archive---------30-----------------------#2020-10-11">https://towardsdatascience.com/the-magic-behind-ensemble-learning-569be80fbab4?source=collection_archive---------30-----------------------#2020-10-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1585" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用许多Kaggle竞赛获胜者使用的简单技术来提高模型的性能</h2></div><p id="5a54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">机器学习中最有用和最简单的技术之一是所谓的集成学习。集成学习(EL)是XGBoost、Bagging Trees、Random Forest和其他方法背后的方法，但还不止这些。</p><p id="b7f9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里有很多关于数据科学的非常好的文章(这里的<a class="ae lb" rel="noopener" target="_blank" href="/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205"/>和这里的<a class="ae lb" rel="noopener" target="_blank" href="/simple-guide-for-ensemble-learning-methods-d87cc68705a2"/>是我最欣赏的两个故事)。<em class="lc">那么，为什么又是一篇关于埃尔的文章呢？</em>因为我想用一个非常简单的例子向你展示<strong class="kh ir">它是如何工作的，这个例子让我确信它不是魔术！</strong></p><p id="7c2e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">嗯，我第一次看到EL运行时(只有几个非常简单的回归模型)，我简直不敢相信自己的眼睛，我仍然感谢教授我这项技术的教授。</p><p id="2360" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我有两个不同的模型(“弱学习者”)，样本外R分别为0.90和0.93。在查看结果之前，我会想到在两个原始R之间的某处获得一个R。换句话说，我认为EL可以用于避免一个模型的性能与最差的模型一样差，但不是一个可以<strong class="kh ir"> <em class="lc"> </em> </strong> <em class="lc">胜过最佳模型</em>的模型。</p><p id="af44" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">令我非常惊讶的是，预测的简单平均值的R为0.95。</p><blockquote class="ld le lf"><p id="8478" class="kf kg lc kh b ki kj jr kk kl km ju kn lg kp kq kr lh kt ku kv li kx ky kz la ij bi translated">起初，我寻找一个错误，然后我想这背后可能有什么神奇的东西！</p></blockquote><h2 id="1d78" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">什么是集成学习</h2><p id="dd1e" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">使用EL，您可以组合两个或更多模型的预测，以获得一个更健壮和性能更好的模型。集合模型有很多方法，但这里我只讨论两个最有用的，只是给出一个想法。</p><p id="20c8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<strong class="kh ir">回归</strong>中，您可以对可用模型的预测进行平均。</p><p id="2b7f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<strong class="kh ir">分类</strong>中，你可以让任何一个模特投票给一个标签。票数多的标签就是新机型选择的标签。</p><h2 id="0751" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">为什么效果更好</h2><p id="54e1" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">EL工作得更好的基本原因是每个预测都有误差(至少在概率意义上)，组合两个预测可以帮助减少误差，从而提高性能指标(RMSE，R .等)。).</p><p id="96d5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面的图表中，你可以看到两个弱学习者如何处理一个样本数据集。第一个学习者具有比它应该具有的高得多的角度系数，而第二个学习者具有几乎为零的角度系数(可能是过度正则化的结果)。整体看起来好多了。</p><p id="8d48" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看样本外R，我们得到-0.01，两个弱学习者的R为0.22，整体的R为0.73。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/50c663b35da0f9f4a0d3d25f5c01fe09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jtrRmPM6iOFqf8IJyAYz7w.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">作者图片</p></figure><p id="a2c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">即使在像这样的基本例子中，学习者也可能不是一个好模型的原因有很多:也许你选择使用正则化来避免过度拟合，或者你选择不排除一些异常值，或者你使用了错误次数的多项式回归(当你使用二次多项式，但你的测试数据显示明显的不对称更适合三次)。</p><h2 id="a31a" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">当它工作得更好的时候</h2><p id="ffc7" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">让我们看看另外两个有相同数据的学习者。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/8b429b5754d772bf6f22160542147d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T4X6spJFShLccfrKNhJzmQ.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">作者图片</p></figure><p id="a92b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个例子中，我们可以说组合这两个模型并没有提高多少性能，但是R对于学习者分别是-0.37，0.22，对于组合是-0.04。因此，EL模型的得分介于两个原始模型之间。</p><p id="59ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这两个例子之间有一个很大的区别:在前一个例子中，模型的误差是负相关的，而在后一个例子中，它们是正相关的(三个模型的系数不是估计的，而是作者为了举例而选择的)。</p><p id="58b7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，集成学习可以用于在任何情况下改善偏差/方差平衡，但是当<em class="lc">模型的误差不是正相关时，EL模式可以导致性能的提升</em>。</p><h2 id="9cd9" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">异构与同构模型</h2><p id="b085" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">EL通常用于同质模型(如本例或随机森林),但您可以将非常不同的模型(线性回归+神经网络+ XGBoost)与不同的解释变量集相结合。这可能会导致不相关的错误和性能的提高。</p><h2 id="692e" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">与投资组合多样化的比较</h2><p id="42ee" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated"><em class="lc"> EL的工作原理类似于投资组合理论中的多样化，但它甚至更好</em>。</p><p id="8a88" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在分散投资中，你试图减少投资于不相关股票的业绩差异。一篮子多元化的股票比最差的单只股票表现好，但永远不会比最好的单只股票好。</p><p id="fe32" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">引用沃伦·巴菲特的话:</p><blockquote class="mx"><p id="4173" class="my mz iq bd na nb nc nd ne nf ng la dk translated"><strong class="ak">“多元化</strong>是对无知的一种保护，对于那些知道自己在做什么的人来说，这没有什么意义。”</p></blockquote><p id="0051" class="pw-post-body-paragraph kf kg iq kh b ki nh jr kk kl ni ju kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">在机器学习中，EL有助于减少模型的方差，但它可能会导致一个整体性能优于最佳单一模型的模型。</p><h2 id="7fa4" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated"><strong class="ak">总结</strong></h2><p id="9b45" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">将更多模型组合在一个模型中是一种相对简单的技术，可以解决偏差-方差权衡问题并提高性能。</p><p id="8119" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你有两个或两个以上看起来不错的型号，不要选择:全部使用(小心)！</p><p id="ca23" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">关于我</strong></p><p id="70e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我是一名前数学家，对许多不同的事情都有热情:数据科学、数据可视化、金融、资产/负债管理，以及(但不要告诉任何人)会计！</p><p id="ae9b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您想知道，如果根据样本外数据计算，或者如果您的估计量不是OLS，R可能是负的</p></div></div>    
</body>
</html>