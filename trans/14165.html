<html>
<head>
<title>Softmax Activation Function — How It Actually Works</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Softmax激活功能——实际工作原理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/softmax-activation-function-how-it-actually-works-d292d335bd78?source=collection_archive---------1-----------------------#2020-09-30">https://towardsdatascience.com/softmax-activation-function-how-it-actually-works-d292d335bd78?source=collection_archive---------1-----------------------#2020-09-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/ffe9a50795624aadeb4e1727d8226fe5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HGa_oRKKoneAAqOo"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://unsplash.com/@fatosi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">法托斯Bytyqi </a>在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="6007" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在处理机器学习问题，具体来说，深度学习任务时，Softmax激活函数是一个流行的名称。它通常被放在深度学习模型的最后一层。</p><blockquote class="le lf lg"><p id="9f55" class="kg kh lh ki b kj kk kl km kn ko kp kq li ks kt ku lj kw kx ky lk la lb lc ld im bi translated">它通常用作神经网络的最后一个激活函数，将网络输出标准化为预测输出类别的概率分布。—维基百科[ <a class="ae kf" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank">链接</a></p></blockquote><p id="6137" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Softmax是一个将数字/对数转换成概率的激活函数。Softmax的输出是一个向量(比如说,<code class="fe ll lm ln lo b">v</code>),包含每种可能结果的概率。对于所有可能的结果或类别，向量<code class="fe ll lm ln lo b">v</code>中的概率总和为1。</p><p id="1649" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数学上，Softmax定义为:</p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lp"><img src="../Images/ee378ae055d1f0d748a532b982131e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*urluH774pTnXGerMubX0eA.png"/></div></div></figure></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><p id="ab53" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">例子</strong></p><p id="817d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑一个CNN模型，该模型旨在将图像分类为狗、猫、马或猎豹(4种可能的结果/类别)。CNN的最后(全连接)层输出logit向量L，该向量通过Softmax层将logit转换为概率p。这些概率是4个类别中每个类别的模型预测。</p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mb"><img src="../Images/558593edd95e6d5de751cff7beba76b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KvygqiInUpBzpknb-KVKJw.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">输入图片来源:Victor Grabarczyk 在<a class="ae kf" href="https://unsplash.com/s/photos/dog?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。作者图解。</p></figure><p id="1842" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们计算应用Softmax后第一个logit生成的概率</p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/a247a3b01d61ea401b1f21b541f32aaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*7GYzhELpAzBHfibnU3-R2w.png"/></div></figure><p id="e34a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以用同样的方式计算其他值。</p><p id="0f5b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在python中，我们可以如下实现Softmax</p><pre class="lq lr ls lt gt md lo me mf aw mg bi"><span id="bb5e" class="mh mi it lo b gy mj mk l ml mm">from math import exp</span><span id="a10c" class="mh mi it lo b gy mn mk l ml mm">def softmax(input_vector):<br/>    # Calculate the exponent of each element in the input vector<br/>    exponents = [exp(j) for j in input_vector]</span><span id="c0f8" class="mh mi it lo b gy mn mk l ml mm">    # divide the exponent of each value by the sum of the  <br/>    # exponents and round of to 3 decimal places<br/>    p = [round(exp(i)/sum(exponents),3) for i in input_vector]</span><span id="cd28" class="mh mi it lo b gy mn mk l ml mm">    return p</span><span id="c736" class="mh mi it lo b gy mn mk l ml mm">print(softmax([3.2,1.3,0.2,0.8]))</span></pre><p id="f678" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出:</p><pre class="lq lr ls lt gt md lo me mf aw mg bi"><span id="1a46" class="mh mi it lo b gy mj mk l ml mm">[0.775, 0.116, 0.039, 0.07]</span></pre><p id="a105" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">符号:</strong>我们可以将所有的logits表示为一个向量，<strong class="ki iu"> v </strong>，并在这个向量上应用激活函数，<strong class="ki iu"> S </strong>，以输出概率向量，<strong class="ki iu"> p </strong>，并表示操作如下</p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/874a275b09b3338fffb95fa6f985d998.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*BLN4P0B6_a95igWgEzB42A.png"/></div></figure><p id="ff0b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意标签:狗、猫、马、猎豹都是字符串格式。我们需要定义一种将这些值表示为数值的方式。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><p id="c254" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">将分类数据转化为数值数据</strong></p><p id="f44c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">真相标签是分类数据:任何特定的图像都可以被归类到这些组中的一组:狗、猫、马或猎豹。然而，计算机不理解这种数据，因此我们需要将它们转换成数字数据。有两种方法可以做到:</p><ol class=""><li id="9a3e" class="mp mq it ki b kj kk kn ko kr mr kv ms kz mt ld mu mv mw mx bi translated">整数编码</li><li id="4eac" class="mp mq it ki b kj my kn mz kr na kv nb kz nc ld mu mv mw mx bi translated">一键编码</li></ol><p id="ea07" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">整数编码(也叫标签编码)</strong></p><p id="af27" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种编码中，标签被赋予唯一的整数值。例如在我们的例子中，</p><p id="a1cb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 0 </strong>代表“狗”<strong class="ki iu"> 1 </strong>代表“猫”<strong class="ki iu"> 2 </strong>代表“马”<strong class="ki iu"> 3 </strong>代表“猎豹”。</p><p id="2417" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lh">何时使用整数编码:</em>当标签本质上是有序的，即具有某种顺序的标签时，使用整数编码。例如，考虑一个分类问题，其中我们想要将服务分类为差、中性或好，那么我们可以如下编码这些类</p><p id="4827" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 0 </strong>为“不良”，1<strong class="ki iu">为“空档”，2<strong class="ki iu">为“良好”。</strong></strong></p><p id="4cc0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">显然，标签有一定的顺序，并且标签相应地赋予标签权重。</p><p id="2cc9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">相反，当标签是名义上的(没有特定排序的名称)时，我们避免使用整数编码，例如，考虑花卉分类问题，其中我们有3个类别:鸢尾、杂色鸢尾和海滨鸢尾，</p><p id="abe0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 0 </strong>为“刚毛鸢尾”<strong class="ki iu"> 1 </strong>为“杂色鸢尾”<strong class="ki iu"> 2 </strong>为“海滨鸢尾”。</p><p id="b3b2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型可以采用标签的自然排序(2&gt;1&gt;0 ),并且给予一个类别比另一个类别更多的权重，而事实上这些只是没有暗示特定排序的标签。</p><p id="804b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">一键编码</strong></p><p id="2863" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于不存在这种顺序关系的分类变量，整数编码是不够的。独热编码是优选的。</p><p id="0ade" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在独热编码中，标签由二进制变量(1和0)表示，从而对于给定的类，生成二进制变量，其中1表示对应于该特定类的位置，0表示其他位置，例如，在我们的情况下，我们将为4个类生成以下标签</p><p id="ff61" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">【1，0，0，0】</strong>【狗】<strong class="ki iu">【0，1，0】</strong>【猫】<strong class="ki iu">【0，0，1，0】</strong>【马】<strong class="ki iu">【0，0，0，1】</strong>【猎豹】。</p><p id="24c8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">备注:</strong>尽管我们已经回答了“何时使用哪种类型的编码系统？”。有一种方法可以实际使用任何一种编码方法。对于TensorFlow和Keras来说，这取决于你如何定义你的损失函数。我们稍后会谈到这一点。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><p id="dcd3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回想一下:Softmax函数的分母是一个归一化项。它确保函数的输出是介于0和1之间的值。</p><figure class="lq lr ls lt gt ju gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/90bf648992b1b15f261b2a182624a89a.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*R1OWRSunCyW4FovTIrvueg.png"/></div></figure><p id="7add" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但有人可能会问，为什么不使用标准归一化，即取每个logit，然后除以所有logit的总和，以获得概率？为什么要拿指数？这里有两个原因。</p><ul class=""><li id="8c6e" class="mp mq it ki b kj kk kn ko kr mr kv ms kz mt ld ne mv mw mx bi translated">Softmax归一化对小的和大的变化/改变有不同的反应，但是标准归一化不通过强度区分刺激，因此最长比例是相同的，例如，</li></ul><p id="006e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"># Softmax标准化</p><p id="73a1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">softmax([2，4]) = [0.119，0.881]</p><p id="26f3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">softmax([4，8]) = [0.018，0.982]</p><p id="ef5e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">#标准标准化</p><pre class="lq lr ls lt gt md lo me mf aw mg bi"><span id="1f27" class="mh mi it lo b gy mj mk l ml mm">def std_norm(input_vector):<br/>    p = [round(i/sum(input_vector),3) for i in input_vector]<br/>    return p</span></pre><p id="226e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">std_norm([2，4]) = [0.333，0.667]</p><p id="33b6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">std_norm([4，8]) = [0.333，0.667]</p><p id="cf32" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意到区别了吗？对于标准归一化，一个矢量和由标量缩放的同一个矢量产生相同的输出。对于上述情况，第一个向量[2，4]乘以2得到[4，8]，两者产生相同的输出。根据相同的推理，以下对将产生相同的输出:{[8，24]，[2.4，7.199]}比例因子为0.3。事实上，任何按因子缩放的矢量都会产生与原始矢量相同的输出。</p><ul class=""><li id="e482" class="mp mq it ki b kj kk kn ko kr mr kv ms kz mt ld ne mv mw mx bi translated">当逻辑中有负值时，就会出现另一个问题。在这种情况下，您将在输出中以负概率结束。Softmax不受负值的影响，因为任何值(正或负)的指数总是正值。</li></ul><p id="f9ee" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望读完这篇文章后，你现在对Softmax激活功能实际上是如何工作的有一个更清晰的理解。</p><p id="12b0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可能也会对以下文章感兴趣</p><div class="nf ng gp gr nh ni"><a rel="noopener follow" target="_blank" href="/cross-entropy-loss-function-f38c4ec8643e"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">交叉熵损失函数</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">在大多数分类问题中用于优化机器学习模型的损失函数…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw jz ni"/></div></div></a></div><div class="nf ng gp gr nh ni"><a rel="noopener follow" target="_blank" href="/on-object-detection-metrics-with-worked-example-216f173ed31e"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">基于实例的目标检测度量</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">AP、mAP、AP50等指标，并举例说明。</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="nx l nt nu nv nr nw jz ni"/></div></div></a></div><div class="nf ng gp gr nh ni"><a rel="noopener follow" target="_blank" href="/end-to-end-machine-learning-project-reviews-classification-60666d90ec19"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">端到端机器学习项目:综述和分类</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">将评论分为正面或负面的项目</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="ny l nt nu nv nr nw jz ni"/></div></div></a></div><p id="65b5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<a class="ae kf" href="https://medium.com/@kiprono_65591/membership" rel="noopener">https://medium.com/@kiprono_65591/membership</a>加入medium，全面了解Medium上的每个故事。</p><p id="5d9b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每当我用这个链接发帖时，你也可以把文章发到你的邮箱里:【https://medium.com/subscribe/@kiprono_65591 T2】</p><p id="f3e8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您的阅读😊</p></div></div>    
</body>
</html>