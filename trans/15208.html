<html>
<head>
<title>Predict Home Runs in the World Series with R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用R预测世界大赛的本垒打</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predict-home-runs-in-the-world-series-with-r-d8c0bb2e6f02?source=collection_archive---------38-----------------------#2020-10-19">https://towardsdatascience.com/predict-home-runs-in-the-world-series-with-r-d8c0bb2e6f02?source=collection_archive---------38-----------------------#2020-10-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="26d4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用历史棒球数据和带R的逻辑回归来预测世界职业棒球大赛的得分。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d295fc58d9e7c72d2dae38d8aad6ed27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BX2QPbXV18RPe6_m"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">蒂姆·高在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="2da1" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="665e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">你有没有想过美国棒球、机器学习、统计学有什么共同点？嗯，你今天很幸运！</p><p id="17c8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这个项目中，我们将使用一些免费的历史棒球数据和R中的<em class="ms"> glm() </em>函数，来看看哪些变量在预测世界职业棒球大赛中有多少本垒打发生时起作用。</p><p id="f2b8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这个项目有几个假设。首先，您有一个R环境设置。对于这个项目，我将在Mac上的RStudio中使用R Markdown (RMD)文件，但代码在其他操作系统和环境下也能正常工作。第二，你至少对棒球有一个基本的了解。我绝不是棒球专家，但也不需要什么重要的知识。只要你知道什么是本垒打，我们就没事了！</p><p id="5208" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了您的方便，<a class="ae ky" href="https://github.com/ARIMA-Consulting/Baseball-Batting" rel="noopener ugc nofollow" target="_blank">RMD的文件可以在我的GitHub这里获得</a>。</p><p id="0e28" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，让我们进入目标，开始编写代码吧！</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="3de9" class="kz la it bd lb lc na le lf lg nb li lj jz nc ka ll kc nd kd ln kf ne kg lp lq bi translated">目标</h1><ol class=""><li id="84ef" class="nf ng it lt b lu lv lx ly ma nh me ni mi nj mm nk nl nm nn bi translated">了解如何在不使用本地文件或手动将数据加载到环境中的情况下导入数据</li><li id="02cb" class="nf ng it lt b lu no lx np ma nq me nr mi ns mm nk nl nm nn bi translated">将数据分成训练集和测试集，用于机器学习</li><li id="628d" class="nf ng it lt b lu no lx np ma nq me nr mi ns mm nk nl nm nn bi translated">使用非正态数据分布进行机器学习</li><li id="eb98" class="nf ng it lt b lu no lx np ma nq me nr mi ns mm nk nl nm nn bi translated">使用逐步回归方法创建逻辑回归模型</li><li id="88fb" class="nf ng it lt b lu no lx np ma nq me nr mi ns mm nk nl nm nn bi translated">使用模型进行预测，并检查我们的模型的准确性</li></ol></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="2cc0" class="kz la it bd lb lc na le lf lg nb li lj jz nc ka ll kc nd kd ln kf ne kg lp lq bi translated">数据</h1><p id="e4ea" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我们进入代码之前，我们需要谈谈肖恩·拉赫曼的惊人工作。他和他的团队已经创建并免费提供了数量惊人的棒球历史数据。他们还做了大量的工作，用其他几种编程语言制作了一个R包和易于使用的实现。我会经常引用他们的话，把数据归功于他们。他们的整个项目只靠他们网站上描述的捐赠来运作。如果你真的想帮助他们，体育分析领域的许多人会用这个数据集来以一种有趣的方式学习机器学习。</p><p id="54e9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这是肖恩的网站:<a class="ae ky" href="http://www.seanlahman.com/baseball-archive/statistics/" rel="noopener ugc nofollow" target="_blank">http://www.seanlahman.com/baseball-archive/statistics/</a></p><p id="9e18" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在该编码了！</p><h1 id="b504" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">代码</h1><h2 id="6e65" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">加载库</h2><p id="7d1b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们将在整个项目中使用<a class="ae ky" href="https://www.tidyverse.org/" rel="noopener ugc nofollow" target="_blank"> tidyverse </a>和<a class="ae ky" href="http://www.seanlahman.com/baseball-archive/statistics/" rel="noopener ugc nofollow" target="_blank"> Lahman </a>包。</p><p id="b136" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="291f" class="nt la it og b gy ok ol l om on"># Uncomment the commands below if you have not installed either the tidyverse or Lahman packages<br/># install.packages("tidyverse")<br/># install.packages("Lahman")</span><span id="c2f6" class="nt la it og b gy oo ol l om on"># Load Libraries<br/>require(tidyverse)<br/>require(Lahman)</span></pre><p id="be2f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您以前使用过R，请特别注意它明显缺少导入本地数据和命名对象的功能。我们只需要使用<em class="ms"> data() </em>函数从拉赫曼的数据集中拉出我们想要的表。默认情况下，对象将以数据框的形式出现，并被称为表的名称，对于我们的目的来说就是BattingPost。</p><p id="7868" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="fde7" class="nt la it og b gy ok ol l om on"># Imports the BattingPost data set from the Lahman database. Notice how there is not a file to read in. The data is part of the package!<br/>data(BattingPost)</span><span id="d17d" class="nt la it og b gy oo ol l om on"># Check the data import<br/># Notice again that we did not have create and object and assign it data like we normally do with R. It just knows to create a data frame called "BattingPost"<br/>head(BattingPost)</span></pre><p id="c4f2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/e655fe5f7251e17c9e1f76b6401a188d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RNf3s22SXEoWvXEwo-rzBg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从拉赫曼的数据库[1]导入BattingPost表</p></figure><h2 id="5eae" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">过滤数据</h2><p id="777b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们现在已经把数据输入R了。我们需要稍微清理一下。首先，由于这是一个关于世界职业棒球大赛的项目，我们需要确保我们的<em class="ms"> round </em>列中只有“WS”值。其次，我们需要确保yearID列大于或等于1920。我不是棒球历史学家，但那是现代“实况球时代”开始的时候[2]。如果你对那种历史感兴趣，可以看看Bradford Doolittle关于ESPN的文章。</p><p id="763a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="d5a3" class="nt la it og b gy ok ol l om on"># Filter down the data a bit. We went the year to be 1920 and later because that's when the "Live Ball Era" starts. We also want only WS in the round column because that's for the World Series.</span><span id="6d49" class="nt la it og b gy oo ol l om on">SlimBattingPost &lt;- BattingPost %&gt;%<br/>  filter(yearID &gt;= 1920) %&gt;%<br/>  filter(round == "WS")</span><span id="d6fb" class="nt la it og b gy oo ol l om on"># Check the data<br/>head(SlimBattingPost)</span></pre><p id="5316" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/a0210f807bc6727abadaa3ce0af9e6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JU9WCyQIYrb1R5tNnkHVTQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从拉赫曼的数据[1]中筛选出大于或等于1920年的数据和仅等于世界系列的舍入数据</p></figure><p id="27df" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们为跟随的人澄清一下。你经常看到的“%&gt;%”就是所谓的“管道”字符[3]。当使用<a class="ae ky" href="https://www.tidyverse.org/" rel="noopener ugc nofollow" target="_blank"> tidyverse </a>时，特别是其中的<a class="ae ky" href="https://dplyr.tidyverse.org/" rel="noopener ugc nofollow" target="_blank"> dplyr </a>部分，处理数据时，我喜欢把它理解为管道字符后面的每个函数或条件都会使假设的数据漏斗变小一点。</p><p id="44a5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们很少需要一个数据集中的所有数据，因此通过一个周长越来越小的“漏斗”来“倾倒”它是一种可视化这里正在发生什么的好方法。仅仅通过应用这两个过滤器，我们就从原始数据中的14，750行增加到了新数据中的4，280行。您可以通过查看RStudio中的对象或者使用<em class="ms"> nrow() </em>函数来获得这些数字。</p><p id="1540" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="9c3a" class="nt la it og b gy ok ol l om on"># Print number of rows in each data set<br/>nrow(BattingPost)<br/>nrow(SlimBattingPost)</span></pre><h2 id="c3ff" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">机器学习简介</h2><p id="993c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们用我们的例子用简单的英语来解释机器学习的含义。我们将要做的事情被称为“监督机器学习”，因为我们作为人类正在“监督”什么数据被输入到机器中[3]。</p><p id="a238" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当像这样使用真实数据时，我们想要做的是将整个数据集的一部分分割成“训练”数据，而将其余部分分割成“测试”数据[3]。这是出于一个非常合理的原因。如果你想让一台机器能够做出预测，你需要对照现实对它进行测试，以确保它实际上工作正常。</p><p id="275b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">传统上，我可以补充一个很好的理由，即80%的训练数据和20%的测试数据分开。我见过各种其他组合，如70/30和75/25，但我喜欢80/20的分割，因为我通常会得到最好的结果，听起来与帕累托原则相同[4]。拜托，我控制不了自己。我的学士学位是经济学。</p><p id="1201" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，在接下来的几段代码中，我们将把数据分成训练集和测试集，使用<em class="ms"> glm() </em>函数创建一个广义线性模型，然后随着时间的推移对其进行改进，以获得更好的结果。你会看到，我们可以让机器“学习”什么变量重要，什么不重要，以便随着时间的推移做出越来越好的预测。</p><h2 id="e8a1" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">播种</h2><p id="f535" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我们分割数据之前，我们真的应该设定一个种子[3]。我们将使用随机(嗯，伪随机，如果你想精确)分裂。这意味着代码每次都会将数据分成不同的集合，除非我们使用带有数字的<em class="ms"> set.seed() </em>函数，这样我们就能确保可再现性[3]。对于那些跟随的人来说，这意味着只要我们使用相同的数字，你的代码将与我的代码一致。</p><p id="e056" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="0c67" class="nt la it og b gy ok ol l om on"># Set Seed<br/>set.seed(1337)</span></pre><p id="9c32" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">设置种子没有任何输出。它只是确保幕后参数设置正确的东西[3]。</p><h2 id="2949" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">培训和测试数据</h2><p id="e708" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">有很多方法可以做到这一点，但这是我在实践中发现或看到的最简单的方法。这是秘密。我们将创建一个任意ID号的列，并将其添加到现有的数据中。这让我们可以轻松地使用R中最隐蔽的函数之一tidyverse中dplyr包中的<a class="ae ky" href="https://dplyr.tidyverse.org/reference/filter-joins.html?q=anti%20_%20join" rel="noopener ugc nofollow" target="_blank"> <em class="ms"> anti_join() </em> </a>函数。这样做的目的是从一个表中获取在另一个表中没有匹配项的所有行。太偷偷摸摸了。我喜欢它，你可以<a class="ae ky" href="https://dplyr.tidyverse.org/reference/filter-joins.html?q=anti%20_%20join" rel="noopener ugc nofollow" target="_blank">在这里的文档中阅读所有关于它的内容</a>。</p><p id="1ecc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="a279" class="nt la it og b gy ok ol l om on"># Creates an ID column so we can more easily sort train from test<br/>SlimBattingPost$id &lt;- 1:nrow(SlimBattingPost)</span><span id="65f4" class="nt la it og b gy oo ol l om on"># Creates set of data randomly sampling 80% of total data<br/>train &lt;- SlimBattingPost %&gt;% dplyr::sample_frac(.80)</span><span id="1691" class="nt la it og b gy oo ol l om on"># Creates set of data with other 20%<br/>test &lt;- dplyr::anti_join(SlimBattingPost, train, by = 'id')</span><span id="3321" class="nt la it og b gy oo ol l om on"># Check the data<br/>head(test)<br/>paste("The test data has this many rows:", nrow(test))<br/>head(train)<br/>paste("The train data has this many rows:",nrow(train))</span></pre><p id="9a0d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/8fd118de7444aeeb6e2f37d0bfad032c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E3K1jrVnpowPaRgE9OuWHw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自拉赫曼数据集[1]的过滤数据的前六行测试数据</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/d168bc9719e99941d90ee88b12ae23d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F4gE0z-lNa1CacthvdCKwA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们从拉赫曼数据集[1]中筛选出的前六行训练数据</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/8ab9619ecf351e631710f20105c94470.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iboY492qKXgX4EJWyWuEKA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">过滤后的拉赫曼数据[1]中每个测试和训练数据集中的行数</p></figure><h2 id="c0e5" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">确定分布</h2><p id="750d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">大多数时候，机器学习处理的是正态分布的数据[3]。当你想到一个我们都见过很多次的正态钟形曲线时，它被称为“高斯”分布，因为数学家这么说[3]。看起来是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/2ea9be56e23d6b35bb1ba15ca12bb7ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1_6ECXHdTw30C4uGAqEXHA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">泰勒·哈里斯绘制的正态钟形曲线</p></figure><p id="2e15" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在正态分布中，有一个平均值(μ，蓝线)和该平均值的标准偏差(σ，绿线)。进入细节并不是非常重要，但这意味着95%的数据都在平均值的2个标准差(2 sigma)以内[3]。机器学习想要正常数据的原因有很多，但有时我们会得到不正常的数据。</p><p id="47ec" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">另一种分布被称为“泊松”分布[3]。当然，它是以另一位数学家的名字命名的，但关键是，它是一种标准的分布类型，其中大多数数据都严重倾斜[3]。大多数时候，它看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/448f7d50c34a33762a37c49628802b11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PN9_xg_KWGihjxXCgOM5tQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">泰勒·哈里斯绘制的基本泊松分布</p></figure><p id="e55f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于机器学习，我们真正关心的是我们试图预测的变量的分布[3]。在我们的例子中，游程(R)将是因变量。让我们制作一个超级快速的直方图来检查我们是否有正态或泊松分布。</p><p id="8c60" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="c154" class="nt la it og b gy ok ol l om on"># Visually determine type of distribution of Runs (R) in dataset<br/>hist(SlimBattingPost$R)</span><span id="69c3" class="nt la it og b gy oo ol l om on"># Classic Poisson distribution. Almost all data is 0 or 1, heavily skewed</span></pre><p id="9c21" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/8574a14bd31c0abc205293683f4b65e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TAxejwgrl_EhpLore5P_nw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">过滤后的拉赫曼数据的基本运行直方图[1]</p></figure><p id="452e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对我来说，游程(R)变量看起来像一个非常经典的泊松分布！</p><h2 id="af98" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">建立模型</h2><p id="bdcc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">有趣的部分来了！我们现在开始建立逻辑回归模型！让我们先看看代码，然后再讨论它。</p><p id="7392" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="ff8c" class="nt la it og b gy ok ol l om on"># Start with everything else as independent variables with runs (R) as the dependent variable<br/># For a data dictionary about what each abbreviation means, go to: <a class="ae ky" href="http://www.seanlahman.com/files/database/readme2017.txt" rel="noopener ugc nofollow" target="_blank">http://www.seanlahman.com/files/database/readme2017.txt</a><br/># Search for "BattingPost" in that document and the third match should be the table where the abbreviations are defined. G = Games, AB = At Bats, etc.</span><span id="61b4" class="nt la it og b gy oo ol l om on"># Create the logistic regression with everything in it, make sure to include the Poisson distribution as the family. If we had normal data, we would use Gaussian in its place.</span><span id="a260" class="nt la it og b gy oo ol l om on">fitAll &lt;- glm(R ~ G + AB + H + X2B + X3B + HR + RBI + SB + CS + BB + SO + IBB + HBP + SH + SF + GIDP , data = train, family = "poisson")</span><span id="67d4" class="nt la it og b gy oo ol l om on">summary(fitAll)</span></pre><p id="3af5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/de3f5205f53d5dae608c3b7fe7bab5f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jWL61PEay5KN9ZtF6kCd7Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">包含所有独立变量的第一个glm()模型的输出</p></figure><p id="95bc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这里有很多东西需要打开。</p><p id="546e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">首先，我们创建了一个名为“fitAll”的模型对象，该对象使用了<em class="ms"> glm() </em>函数，其中R作为因变量，用~字符与所有用a +分隔的自变量分隔开，同时还使用了我们的训练数据(还记得前面的80%吗？)并使用泊松分布来获得更精确的结果[3]。</p><p id="5487" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一旦我们创建了模型，<em class="ms"> summary() </em>函数将以简单的形式给出上面的输出。</p><p id="4403" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">摘要的第一部分是“Call:”它只是说实际使用了什么模型。这里没什么可说的。</p><p id="e291" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">“偏差残差:”试图告诉我们在处理错误时现实和期望之间的差异[3]。实际上，在这一点上，这与学习逻辑回归并不完全相关，所以我们将继续前进。</p><p id="cfd3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">“系数:”部分是我们需要关注的地方。第一列是所有变量加上截距。还记得代数一课的公式“<em class="ms"> y = mx + b </em>”吗？这是截距[3]的<em class="ms"> b </em>值的极端版本。</p><p id="f8ea" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">“估计”栏告诉我们每个值对运行次数的影响是积极的还是消极的，以及它的系数有多大[3]。这类似于一堆不同的<em class="ms"> m </em>值，其中<em class="ms"> x </em>值是实际数据集中的数字。一个等式可能是这样的<em class="ms">y = m</em>₁<em class="ms">x+m</em>₂<em class="ms">x+m</em>₃x…<em class="ms"> + b </em>具有所有不同的系数和值【3】。</p><p id="9d79" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">“性病。“错误”栏是我们错误程度的统计指标[3]。z值在统计学中用于给出分布曲线上的z值[3]。现在对我们来说没那么重要。</p><p id="5ffb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">与我们最相关的是优雅地标记为“Pr(&gt;|z|)”的列，这是p值的一种非常复杂的表达方式[3]。对于p值，我们关心的是我们所说的是有意义的一定程度的信心[3]。此外，p值的范围在0和1之间，所以如果有负数或大于1的数字，数学在某个地方是错误的[3]。</p><p id="60c9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">例如，如果我们要至少95%确定一个自变量是因变量的一个统计上显著的预测因子，p值将小于0.05[3]。如果我们希望90%确定变量是显著的，那么我们需要看到一个小于0 . 10的p值[3]。要99%确定，我们需要看到小于. 01的p值[3]。明白我的意思了吗？</p><p id="58c3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">r为我们提供了一个方便的小功能，它标记了每个变量的显著性水平。放一个单曲“.”像<em class="ms"> SB </em>和<em class="ms"> SF </em>这样的变量意味着我们有90%到95%的把握这些变量在统计上是显著的[3]。变量旁边的“*”表示我们有95%到99%的把握该变量具有统计显著性，p值越小，其余变量的预测能力越强[3]。</p><p id="f838" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">目标是最终得到一个只有统计上显著的独立变量的模型。那么我们该怎么做呢？我们使用一种叫做“逐步回归”的方法[3]。</p><h2 id="1b89" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">逐步回归</h2><p id="319a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这是一个听起来很有趣的术语，简单地说就是我们取出一个最不重要的变量，然后重新运行我们的模型，重复这个过程，直到我们只剩下具有统计意义的独立变量[3]。我们来做一个例子。在继续之前，找到具有最大p值的变量。</p><p id="a712" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="d942" class="nt la it og b gy ok ol l om on"># Start step-wise regression.<br/># Looks like G is the least significant<br/># Make sure to create a new object name so we do not overwrite our models as we go along!</span><span id="630c" class="nt la it og b gy oo ol l om on">fit1 &lt;- glm(R ~ AB + H + X2B + X3B + HR + RBI + SB + CS + BB + SO + IBB + HBP + SH + SF + GIDP , data = train, family = "poisson")</span><span id="4f5f" class="nt la it og b gy oo ol l om on">summary(fit1)</span></pre><p id="4437" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/c5faa49bccf99ba46ef9d866da22a831.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y5Ursz7J1OB1_Jf-mGqotg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">删除最不重要变量后逻辑回归的新结果表</p></figure><p id="284e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">那么，你注意到了什么？在我们去掉了最不重要的变量<em class="ms"> G </em>之后，很多p值都变了！这很正常。当所有的数字都被处理后，那些被认为是统计上显著变化的变量就被拿走了[3]。这也有道理。当你想到这一点时，不管是第一场还是第三场还是第六场比赛都会影响得分，这是没有意义的。</p><blockquote class="ox oy oz"><p id="1392" class="lr ls ms lt b lu mn ju lw lx mo jx lz pa mp mc md pb mq mg mh pc mr mk ml mm im bi translated">注意:当你删除一个变量时，确保也从公式的自变量侧删除“+”so，以避免不必要的错误！此外，请务必将您的模型重命名为不同的对象名称，以避免在学习时覆盖过去的工作！</p></blockquote><p id="cb1d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然而，看起来我们仍然有不具有统计显著性的独立变量。看起来<em class="ms">是下一个要去的</em>变量。</p><p id="f608" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="bf47" class="nt la it og b gy ok ol l om on"># Looks like SO is the least significant<br/># Make sure to create a new object name so we do not overwrite our models as we go along!</span><span id="330d" class="nt la it og b gy oo ol l om on">fit2 &lt;- glm(R ~ AB + H + X2B + X3B + HR + RBI + SB + CS + BB + IBB + HBP + SH + SF + GIDP , data = train, family = "poisson")</span><span id="cec8" class="nt la it og b gy oo ol l om on">summary(fit2)</span></pre><p id="a8c1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/31498de58ea6aa45a7458074677bff09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v5ESiO87uriaYPDW1LBy_g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">移除SO后的第二个逐步回归摘要</p></figure><p id="e796" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">希望在这一点上，你得到了模式。直到模型只剩下统计上显著的变量达到95%的置信阈值(p值&lt; 0.05), we will look this process.</p><p id="09a5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Rather than take up a ton of space, I am going to skip ahead to the final model after going through the process of removing non-significant independent variables. On your end, do it until you match up with my answer for learning purposes.</p><p id="7881" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Here’s the code:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="98e2" class="nt la it og b gy ok ol l om on"># Final Fit<br/>fitFinal &lt;- glm(R ~ AB + H + X2B + X3B + HR + CS + BB + IBB + HBP + GIDP , data = train, family = "poisson")</span><span id="4ff0" class="nt la it og b gy oo ol l om on">summary(fitFinal)</span></pre><p id="ff6c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Here’s the output:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/ed676f535e61319baaa5b60110d54312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V6qdLQcNJKFGaCyuQbtlNg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Final logistic regression model after completing the step-wise regression process</p></figure><h2 id="cdc0" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">Make Predictions</h2><p id="1bf4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Now is the time where we see how well we did with our model. Fortunately for us, R has an easy-to-use tool for this — the <em class="ms">预测()</em>函数。我们现在将使用我们的最终逻辑回归模型，对照我们的测试数据(我们之前保留的20%)进行测试，然后看看我们有多准确！</p><p id="f797" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="4094" class="nt la it og b gy ok ol l om on"># Create predictions<br/>predictions &lt;- predict(fitFinal, test, type = 'response')</span><span id="ab78" class="nt la it og b gy oo ol l om on"># Check the output<br/>head(predictions)</span></pre><p id="36c6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/e8daf336d8219005095ee9ccd1012266.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yiTDO8Seg_k0hYKzK9-xxw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">逻辑回归的前6个预测</p></figure><p id="d0b5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我知道我将要向你们展示的过程并不是做到这一点的捷径。然而，我发现这是最容易一步一步形象化的，这更好地支持了我们学习技术的目标。</p><p id="44e7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在要做的是将我们刚刚做出的预测添加到我们的测试数据中，选择我们实际上想要生成较小数据集的列，在新列中对预测进行舍入，并创建一列真布尔值和假布尔值，以便您可以轻松地看到幕后。</p><p id="b7e6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="9a7d" class="nt la it og b gy ok ol l om on"># Add predictions to test data and create new data frame<br/>predictDF &lt;- data.frame(test, predictions)</span><span id="2bec" class="nt la it og b gy oo ol l om on"># Create new data frame with less columns<br/>SlimPredictDF &lt;- select(predictDF, "yearID", "round", "playerID", "teamID", "R", "predictions")</span><span id="2e78" class="nt la it og b gy oo ol l om on"># Add rounded predictions as a column<br/>SlimPredictDF$roundedPredictions &lt;- round(SlimPredictDF$predictions, 0)</span><span id="11ef" class="nt la it og b gy oo ol l om on"># Create Boolean Column to see if real and predictions match<br/>SlimPredictDF$TFmatch &lt;- SlimPredictDF$R == SlimPredictDF$roundedPredictions</span><span id="dfc7" class="nt la it og b gy oo ol l om on"># Check data structure <br/>head(SlimPredictDF)</span></pre><p id="d184" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/4e13182291237cafb595ee04c01a4dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PPeIzO2qJ-OCu4n7LNpg2g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拉赫曼数据测试部分的四舍五入预测表[1]</p></figure><h2 id="e3f7" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">结果</h2><p id="d936" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们可以使用tidyverse中的几个函数创建一个简单的表来计算匹配和未匹配的次数。</p><p id="8efa" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="2940" class="nt la it og b gy ok ol l om on"># Get the results!<br/>results_table &lt;- SlimPredictDF %&gt;%<br/>  group_by(TFmatch) %&gt;%<br/>  summarise(count = n())<br/>results_table</span></pre><p id="c8dd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/576fdae052a3cb775ee11782f20a040d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5qXM536_BVI0DcQj3ssbDQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">逻辑回归模型预测值的结果表</p></figure><p id="bbd7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">嗯，66%还不算太糟，对吧？只要将564除以856就可以得到结果。</p><h2 id="8aed" class="nt la it bd lb nu nv dn lf nw nx dp lj ma ny nz ll me oa ob ln mi oc od lp oe bi translated">结果—奖励积分</h2><p id="dc3e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们可以检查结果的另一种方法是使用<em class="ms"> lm() </em>函数制作一个快速线性模型，并查看我们的R平方值。我们会得到R平方的两个变量，但它们会很接近。这将告诉我们自变量(roundedPredictions)解释了因变量(R，runs)的多少。</p><p id="9301" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">代码如下:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="df98" class="nt la it og b gy ok ol l om on"># Simple linear model to get p-vale for whether real Runs (R) are significantly prediction by predictions</span><span id="291b" class="nt la it og b gy oo ol l om on">fitLM &lt;- lm(R ~ roundedPredictions, data = SlimPredictDF)<br/>summary(fitLM)</span></pre><p id="01ce" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是输出结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/1a00769822841e7a3bf42b680d0c1ab3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RvNtsa7yZfM-AwHOyz0gFw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用线性模型的结果版本</p></figure><p id="d826" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当以这种方式检查时，我们得到了大约63%正确的类似答案。</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="534c" class="kz la it bd lb lc na le lf lg nb li lj jz nc ka ll kc nd kd ln kf ne kg lp lq bi translated">结论</h1><p id="dd8e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这个项目旨在教育，有趣，真实。我们可以做很多实验，比如使用不同的分布，包括不仅仅是世界职业棒球大赛的季后赛，改变数据开始的年份等等。</p><p id="b627" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在一天结束的时候，我们使用真实的数据进行真实的预测，并获得了大约2/3的正确率。我们还逐步回归，并在此过程中学习了一些非标准的R技巧。</p><p id="a5f8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您有任何问题、意见或对未来探索的想法，请告诉我。享受使用你新发现的逻辑回归技巧来预测其他数据吧！</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="aa3e" class="kz la it bd lb lc na le lf lg nb li lj jz nc ka ll kc nd kd ln kf ne kg lp lq bi translated">参考</h1><p id="bb1f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">[1] S .拉赫曼，<em class="ms">下载拉赫曼的棒球数据库</em> (2020)，http://www.seanlahman.com/baseball-archive/statistics/<a class="ae ky" href="http://www.seanlahman.com/baseball-archive/statistics/" rel="noopener ugc nofollow" target="_blank"/></p><p id="73ae" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">直播球时代已经过去了一百年，棒球是一项更好的运动吗？ (2019)，<a class="ae ky" href="https://www.espn.com/mlb/story/_/id/27546614/one-hundred-years-live-ball-era-baseball-better-game" rel="noopener ugc nofollow" target="_blank">https://www . ESPN . com/MLB/story/_/id/27546614/100年-直播球时代-棒球-更好-游戏</a></p><p id="0fdc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[3] R. Kabacoff，<em class="ms"> R在行动(第二版。)</em> (2015)，纽约州谢尔特岛:曼宁出版公司</p><p id="691d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[4].K. Kruse，<em class="ms">80/20法则及其如何改变你的生活</em> (2016)，<a class="ae ky" href="https://www.forbes.com/sites/kevinkruse/2016/03/07/80-20-rule/#230185973814" rel="noopener ugc nofollow" target="_blank">https://www . Forbes . com/sites/kevinkruse/2016/03/07/80-20-Rule/# 230185973814</a></p></div></div>    
</body>
</html>